[
  {
    "objectID": "chapters/bayesian_inference/05_subj_prop.html",
    "href": "chapters/bayesian_inference/05_subj_prop.html",
    "title": "49  Aggiornare le credenze su un parametro: dal prior alla posterior",
    "section": "",
    "text": "49.1 Introduzione\nL’inferenza bayesiana offre un quadro formale per aggiornare le nostre convinzioni riguardo a un parametro incognito, come la probabilità \\(\\theta\\) di un evento, alla luce di nuove osservazioni. Questo approccio è basato sul teorema di Bayes, che combina in modo coerente le conoscenze iniziali—espresse attraverso una distribuzione a priori—con l’evidenza fornita dai dati, sintetizzata dalla funzione di verosimiglianza. Il risultato è una distribuzione a posteriori, che rappresenta le nostre credenze rivedute dopo aver considerato sia l’ipotesi iniziale sia i dati osservati.\nL’inferenza bayesiana si distingue per la sua flessibilità nel trattare l’incertezza: invece di fornire stime puntuali, lavora con distribuzioni di probabilità, permettendo di quantificare in modo esplicito la fiducia associata a ciascun valore possibile del parametro. Tale caratteristica la rende particolarmente utile in contesti in cui le informazioni sono incomplete o soggette a revisione, come spesso accade nella ricerca psicologica.\nIn questo capitolo esploreremo l’inferenza bayesiana attraverso il modello binomiale, particolarmente adatto per analizzare dati dicotomici. Inizieremo considerando un semplice caso con distribuzione a priori discreta, dove il parametro \\(\\theta\\) (probabilità di successo) può assumere solo valori predefiniti. Questo approccio ci permetterà di osservare come le nostre credenze su \\(\\theta\\) si modifichino gradualmente con l’arrivo di nuovi dati. Successivamente, estenderemo il discorso al caso più generale delle distribuzioni a priori continue, che meglio si adattano alla modellizzazione di problemi reali. L’obiettivo è fornire una comprensione intuitiva ma rigorosa del processo dell’aggiornamento bayesiano, evidenziandone sia la logica sottostante sia le potenzialità applicative.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Aggiornare le credenze su un parametro: dal prior alla posterior</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_subj_prop.html#verosimiglianza-binomiale",
    "href": "chapters/bayesian_inference/05_subj_prop.html#verosimiglianza-binomiale",
    "title": "49  Aggiornare le credenze su un parametro: dal prior alla posterior",
    "section": "\n49.2 Verosimiglianza Binomiale",
    "text": "49.2 Verosimiglianza Binomiale\nLa distribuzione binomiale descrive il numero di successi \\(y\\) in \\(n\\) prove indipendenti, ciascuna con probabilità di successo \\(\\theta\\). La sua funzione di verosimiglianza è:\n\\[\np(y \\mid \\theta) = \\text{Bin}(y \\mid n, \\theta) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n-y},\n\\]\ndove \\(\\theta\\) rappresenta la probabilità di successo per singola prova, \\(y\\) è il numero osservato di successi e \\(n\\) è il numero totale di prove (fissato a priori).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Aggiornare le credenze su un parametro: dal prior alla posterior</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_subj_prop.html#esempio-gono-go-task",
    "href": "chapters/bayesian_inference/05_subj_prop.html#esempio-gono-go-task",
    "title": "49  Pensare ad una proporzione in termini soggettivi",
    "section": "\n49.3 Esempio: Go/No-Go Task",
    "text": "49.3 Esempio: Go/No-Go Task\nNel classico Go/No-Go task (Shiffrin & Schneider, 1977), i partecipanti rispondono a stimoli (“Go”) ma devono inibire la risposta per uno specifico stimolo bersaglio (“No-Go”). Ogni prova è un evento bernoulliano: successo (risposta corretta) o fallimento (errore). L’obiettivo è studiare la capacità di inibizione, analizzando la proporzione di risposte corrette nelle prove No-Go.\nPrendiamo come esempio i risultati di un partecipante in un compito di inibizione della risposta. In 9 prove No-Go consecutive, il partecipante ha mostrato il seguente pattern di risposte: 1, 0, 1, 1, 1, 0, 1, 0, 1, dove 1 indica una corretta inibizione della risposta e 0 rappresenta un errore di inibizione. Complessivamente, si osservano 6 risposte corrette su 9 prove.\nIn questo contesto sperimentale, possiamo modellare la prestazione del partecipante utilizzando una distribuzione binomiale. Ogni prova costituisce un’osservazione indipendente che segue una distribuzione di Bernoulli con parametro \\(\\theta\\), dove \\(\\theta\\) rappresenta la probabilità sottostante di inibizione corretta. La variabile \\(\\theta\\) cattura quindi l’abilità inibitoria del partecipante nel compito No-Go.\nIl modello binomiale ci permette di stimare \\(\\theta\\) a partire dai dati osservati e di quantificare l’incertezza associata a questa stima. In particolare, la verosimiglianza dei dati osservati (6 successi su 9 prove) può essere espressa attraverso la funzione di massa di probabilità binomiale, che assegna una probabilità a ogni possibile valore di \\(\\theta\\) compreso tra 0 e 1.\nL’analisi bayesiana di questo problema prevede la combinazione di queste informazioni con una distribuzione a priori che rappresenta le nostre credenze iniziali sull’abilità inibitoria del partecipante. Questo approccio ci consentirà di ottenere una distribuzione a posteriori per \\(\\theta\\) che sintetizza sia le informazioni a priori sia l’evidenza fornita dai dati osservati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_subj_prop.html#metodo-basato-su-griglia-per-laggiornamento-bayesiano",
    "href": "chapters/bayesian_inference/05_subj_prop.html#metodo-basato-su-griglia-per-laggiornamento-bayesiano",
    "title": "49  Aggiornare le credenze su un parametro: dal prior alla posterior",
    "section": "\n49.4 Metodo Basato su Griglia per l’Aggiornamento Bayesiano",
    "text": "49.4 Metodo Basato su Griglia per l’Aggiornamento Bayesiano\nIl metodo basato su griglia rappresenta un approccio computazionalmente semplice per ottenere la distribuzione a posteriori quando non è disponibile una soluzione analitica diretta. Questo metodo risulta particolarmente utile per illustrare concretamente il processo di aggiornamento bayesiano.\nIl procedimento inizia definendo un intervallo plausibile per il parametro \\(\\theta\\), tipicamente compreso tra 0 e 1 nel caso di probabilità. All’interno di questo intervallo, viene costruita una griglia costituita da un insieme finito di valori equidistanti (ad esempio, \\(\\theta\\) = 0, 0.01, 0.02, …, 1). Per ciascun valore \\(\\theta\\) nella griglia, si calcola il prodotto della verosimiglianza dei dati osservati (data \\(\\theta\\)) e della densità a priori corrispondente.\nI valori così ottenuti vengono poi normalizzati dividendo ciascuno di essi per la somma totale dei prodotti calcolati su tutta la griglia. Questa operazione garantisce che l’area sotto la curva risultante sia pari a 1, trasformando così i valori in una vera distribuzione di probabilità. La distribuzione risultante rappresenta un’approssimazione discreta della vera distribuzione a posteriori continua.\nSebbene approssimato, questo metodo offre diversi vantaggi didattici: mantiene trasparente ogni fase del calcolo, permette di visualizzare direttamente l’effetto dell’aggiornamento bayesiano e non richiede conoscenze avanzate di metodi computazionali. La precisione dell’approssimazione può essere migliorata aumentando la densità dei punti nella griglia, a scapito però di un maggior costo computazionale.\nNel caso del nostro esempio con 22 successi su 30 prove, applicheremo questo metodo utilizzando come a priori una distribuzione uniforme, dimostrando come l’osservazione dei dati modifichi la nostra comprensione della probabilità \\(\\theta\\) di riconoscimento corretto di parole con contenuto emotivo positivo.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Aggiornare le credenze su un parametro: dal prior alla posterior</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_subj_prop.html#aggiornamento-bayesiano-con-priori-discreta",
    "href": "chapters/bayesian_inference/05_subj_prop.html#aggiornamento-bayesiano-con-priori-discreta",
    "title": "49  Aggiornare le credenze su un parametro: dal prior alla posterior",
    "section": "\n49.5 Aggiornamento Bayesiano con Priori Discreta",
    "text": "49.5 Aggiornamento Bayesiano con Priori Discreta\n\n49.5.1 Costruzione della Priori\nNel caso del compito di compito di memoria a lungo termine considerato, il parametro \\(theta\\) rappresenta la probabilità di un riconoscimento corretto di parole con contenuto emotivo positivo. In assenza di informazioni preliminari specifiche, potremmo inizialmente considerare tutti i valori di \\(\\theta\\) ugualmente plausibili. Per implementare concretamente questo approccio:\n\ndefiniamo un insieme discreto di valori possibili per \\(\\theta\\): {0, 0.1, 0.2, …, 1};\nassegniamo a ciascun valore la stessa probabilità a priori: \\(p(\\theta) = 1/11 \\approx 0.09\\).\n\nQuesta scelta rappresenta uno stato di massima incertezza iniziale, dove nessun valore di \\(\\theta\\) risulta a priori più plausibile di altri.\n\n49.5.2 Aggiornamento con i Dati\nSupponiamo di osservare 22 inibizioni corrette su 30 prove (\\(y\\)=22, \\(n\\)=30). Per ogni valore \\(\\theta\\) nella griglia:\n\ncalcoliamo la verosimiglianza binomiale: \\(p(y \\mid \\theta) = \\theta^{22}(1-\\theta)^8\\);\nmoltiplichiamo per la probabilità a priori;\nnormalizziamo dividendo per la somma totale di tutti i prodotti ottenuti.\n\nIl risultato è una distribuzione a posteriori discreta che mostra come l’osservazione di 22 successi su 30 prove modifica le nostre credenze iniziali su \\(\\theta\\). I valori più vicini a 22/30 \\(\\approx\\) 0.7 riceveranno maggiore probabilità a posteriori.\n\n49.5.3 Interpretazione\nQuesto processo dimostra come l’osservazione dei dati modifichi le nostre credenze iniziali. La distribuzione a posteriori si sposta gradualmente dalla configurazione iniziale uniforme verso una forma più informata, concentrandosi attorno ai valori di \\(\\theta\\) più compatibili con i dati osservati.\nIn particolare, dopo aver osservato 22 successi su 30 prove, valori come \\(\\theta\\) = 0.7 o 0.75 diventano più plausibili rispetto a valori estremi come \\(\\theta\\) = 0.2 o 0.9. Questo riflette il modo in cui l’evidenza empirica aggiorna le nostre aspettative iniziali.\nL’uso di una griglia discreta fornisce un’approssimazione della vera distribuzione continua, dove la precisione dell’approssimazione migliora quanto più fitta è la griglia di punti considerata. Questo approccio permette di visualizzare in modo concreto il meccanismo di aggiornamento bayesiano, mostrando come a ogni nuova osservazione corrisponda una revisione della nostra conoscenza del parametro \\(\\theta\\).\n\n49.5.4 Implementazione in R\n\n49.5.4.1 Definizione dei parametri\nIniziamo creando una griglia discreta per il parametro θ, che rappresenta la probabilità di successo nel nostro compito Go/No-Go:\n\ntheta &lt;- seq(0, 1, by = 0.1)  # Griglia di valori da 0 a 1 con passo 0.1\n\n\n49.5.4.2 Distribuzione a priori uniforme\nQuando non abbiamo informazioni preliminari, usiamo una distribuzione uniforme:\n\npriori_unif &lt;- rep(1 / length(theta), length(theta))  # Probabilità uniformi\n\nVisualizziamo questa distribuzione:\n\nggplot(data.frame(theta, prob = priori_unif), aes(x = theta, y = prob)) +\n  geom_col(width = 0.08) +\n  labs(title = \"Distribuzione a Priori Uniforme\",\n       x = expression(theta),\n       y = \"Densità di probabilità\")\n\n\n\n\n\n\n\n\n49.5.4.3 Distribuzione a priori informativa\nSe invece riteniamo più probabili valori centrali di \\(\\theta\\):\n\npriori_inf &lt;- c(\n  0, 0.05, 0.05, 0.05, 0.175, 0.175, 0.175, 0.175, 0.05, 0.05, 0.05\n)\n\nVisualizzazione:\n\nggplot(data.frame(theta, prob = priori_inf), aes(x = theta, y = prob)) +\n  geom_col(width = 0.08) +\n  labs(title = \"Distribuzione a Priori Informativa\",\n       x = expression(theta),\n       y = \"Densità di probabilità\")\n\n\n\n\n\n\n\n\n49.5.4.4 Calcolo della verosimiglianza\nPer i nostri dati (22 successi su 30 prove):\n\nverosimiglianza &lt;- dbinom(22, size = 30, prob = theta)\n\nVisualizzazione:\n\nggplot(data.frame(theta, prob = verosimiglianza), aes(x = theta, y = prob)) +\n  geom_col(width = 0.08) +\n  labs(title = \"Funzione di Verosimiglianza\",\n       x = expression(theta),\n       y = \"L(θ|dati)\")\n\n\n\n\n\n\n\n\n49.5.4.5 Calcolo della distribuzione a posteriori\nCombiniamo priori e verosimiglianza:\n\nposteriori_non_norm &lt;- priori_inf * verosimiglianza\nposteriori &lt;- posteriori_non_norm / sum(posteriori_non_norm)  # Normalizzazione\n\nVisualizzazione:\n\nggplot(data.frame(theta, prob = posteriori), aes(x = theta, y = prob)) +\n  geom_col(width = 0.08) +\n  labs(title = \"Distribuzione a Posteriori\",\n       x = expression(theta),\n       y = \"P(θ|dati)\")\n\n\n\n\n\n\n\n\n49.5.4.6 Statistiche descrittive\nCalcoliamo alcune quantità riassuntive:\n\nmedia_post &lt;- sum(theta * posteriori)\nvar_post &lt;- sum(theta^2 * posteriori) - media_post^2\nmoda_post &lt;- theta[which.max(posteriori)]\n\ncat(\"Media a posteriori:\", round(media_post, 3),\n    \"\\nVarianza a posteriori:\", round(var_post, 3),\n    \"\\nModa a posteriori:\", moda_post)\n#&gt; Media a posteriori: 0.689 \n#&gt; Varianza a posteriori: 0.005 \n#&gt; Moda a posteriori: 0.7\n\nL’implementazione illustra tre caratteristiche essenziali dell’inferenza bayesiana. La funzione di verosimiglianza attribuisce maggiore densità di probabilità a valori di \\(\\theta\\) compresi tra 0.6 e 0.8, in accordo con l’evidenza empirica dei 22 successi osservati su 30 prove. La distribuzione a priori contribuisce in modo determinante alla configurazione della distribuzione a posteriori risultante. Il processo di aggiornamento bayesiano integra in modo rigoroso queste due fonti informative mediante l’applicazione del teorema di Bayes.\nLa metodologia si distingue per la sua flessibilità applicativa, permettendo di adeguarsi a diverse esigenze analitiche. È possibile modificare facilmente i parametri osservati, come il numero di successi e prove registrate, per adattare l’analisi a diversi set di dati. La distribuzione a priori può essere calibrata in base alle specifiche ipotesi teoriche del ricercatore, offrendo la possibilità di incorporare conoscenze pregresse di varia natura. Un ulteriore vantaggio operativo consiste nella possibilità di aumentare la precisione delle stime semplicemente aggiungendo punti alla griglia di valori considerati per \\(\\theta\\), ottenendo così un’approssimazione più fedele della distribuzione continua. Questa combinazione di adattabilità e precisione rende l’approccio particolarmente efficace sia nelle fasi iniziali di analisi esplorativa, dove è necessario testare rapidamente diverse configurazioni, sia in contesti sperimentali controllati che richiedono modelli più sofisticati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Aggiornare le credenze su un parametro: dal prior alla posterior</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-continua",
    "href": "chapters/bayesian_inference/05_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-continua",
    "title": "49  Aggiornare le credenze su un parametro: dal prior alla posterior",
    "section": "\n49.6 Aggiornamento Bayesiano con una Distribuzione a Priori Continua",
    "text": "49.6 Aggiornamento Bayesiano con una Distribuzione a Priori Continua\nPassiamo ora a un’estensione naturale del metodo discreto: l’utilizzo di una distribuzione a priori continua. Questo approccio permette di modellare la probabilità di successo \\(\\theta\\) come una variabile continua definita sull’intervallo \\([0, 1]\\), consentendo maggiore precisione e flessibilità. In questo contesto, la distribuzione Beta rappresenta una scelta ideale per la prior su una proporzione, grazie alla sua versatilità e alla sua coniugatezza con la distribuzione binomiale.\n\n49.6.1 Scelta della Distribuzione a Priori\nIniziamo con una distribuzione Beta simmetrica, \\(\\text{Beta}(2, 2)\\), che riflette una credenza iniziale moderatamente incerta, ma senza una preferenza marcata per valori bassi o alti di \\(\\theta\\). Successivamente, considereremo anche un caso più informativo: \\(\\text{Beta}(2, 5)\\), che assegna maggiore probabilità a valori di \\(\\theta\\) vicini a zero, riflettendo un’aspettativa più pessimista.\n\n49.6.2 Costruzione della Densità a Priori\nCalcoliamo la densità della distribuzione \\(\\text{Beta}(2, 2)\\) su una griglia fine di valori di \\(\\theta\\):\n\ntheta &lt;- seq(0, 1, length.out = 1000)\nprior_beta_2_2 &lt;- dbeta(theta, 2, 2) / sum(dbeta(theta, 2, 2))\n\nVisualizziamo la forma della distribuzione:\n\nggplot(data.frame(theta, prior = prior_beta_2_2), aes(x = theta, y = prior)) +\n  geom_line(linewidth = 1.2) +\n  labs(title = \"Distribuzione a Priori Beta(2, 2)\", x = expression(theta), y = \"Densità\")\n\n\n\n\n\n\n\n\n49.6.3 Verosimiglianza per un Esperimento Binomiale\nSupponiamo che un partecipante abbia ottenuto 6 successi su 9 prove in un compito dicotomico (es. compito No-Go). La verosimiglianza associata a ciascun valore di \\(\\theta\\) è calcolata come:\n\nlikelihood &lt;- dbinom(22, size = 30, prob = theta)\nlikelihood &lt;- likelihood / sum(likelihood)  # normalizzazione opzionale\n\n\n49.6.4 Calcolo della Distribuzione a Posteriori\nPoiché il prior è continuo, otteniamo la distribuzione a posteriori moltiplicando punto a punto la densità a priori per la verosimiglianza, e normalizzando:\n\nposterior_unnorm &lt;- prior_beta_2_2 * likelihood\nposterior &lt;- posterior_unnorm / sum(posterior_unnorm)\n\nVisualizziamo le tre curve:\n\ndf &lt;- data.frame(theta, prior = prior_beta_2_2, likelihood, posterior)\n\ndf_long &lt;- df |&gt;\n  pivot_longer(cols = c(\"prior\", \"likelihood\", \"posterior\"),\n               names_to = \"Distribuzione\", values_to = \"Densità\")\n\nggplot(df_long, aes(x = theta, y = Densità, color = Distribuzione)) +\n  geom_line(size = 1.2) +\n  labs(title = \"Aggiornamento Bayesiano con Prior Continua\",\n       x = expression(theta), y = \"Densità\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n49.6.5 Distribuzione a Priori Non Simmetrica\nConsideriamo ora una distribuzione a priori non simmetrica, Beta(2, 5), per rappresentare credenze che privilegiano valori bassi di \\(\\theta\\).\n\nprior_2_5 &lt;- dbeta(theta, 2, 5) / sum(dbeta(theta, 2, 5))\n\n\n49.6.6 Distribuzione a Posteriori\nLa distribuzione a posteriori si ottiene moltiplicando la distribuzione a priori per la verosimiglianza e normalizzando il risultato.\n\nposterior &lt;- (prior_2_5 * likelihood) / sum(prior_2_5 * likelihood)\n\n\n# Uniamo tutti i dati in un dataframe per ggplot2\ndat &lt;- tibble(\n  theta,\n  prior_2_5,\n  likelihood,\n  posterior\n)\n\n# Preparazione dei dati per il plot\nlong_data &lt;- dat |&gt;\n  pivot_longer(\n    cols = c(prior_2_5, likelihood, posterior),\n    names_to = \"distribution\",\n    values_to = \"density\"\n  )\n\n# Grafico\nlong_data |&gt;\n  ggplot(aes(x = theta, y = density, color = distribution)) +\n  geom_line(size = 1.2) +\n  labs(\n    title = \"Distribuzioni Bayesiane\",\n    x = expression(theta),\n    y = \"Densità\"\n  ) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n49.6.7 Quantità a Posteriori\nCalcoliamo alcune quantità descrittive utili:\n\nposterior_mean &lt;- sum(theta * posterior)\nposterior_sd &lt;- sqrt(sum((theta^2) * posterior) - posterior_mean^2)\nposterior_mode &lt;- theta[which.max(posterior)]\nposterior_mean; posterior_sd; posterior_mode\n#&gt; [1] 0.6486\n#&gt; [1] 0.07744\n#&gt; [1] 0.6567\n\nPer stimare intervalli di credibilità, possiamo campionare dalla posteriori:\n\nsamples &lt;- sample(theta, size = 10000, replace = TRUE, prob = posterior)\nquantile(samples, probs = c(0.03, 0.97))  # intervallo al 94%\n#&gt;     3%    97% \n#&gt; 0.4955 0.7878\n\nSe desideriamo calcolare l’intervallo di densità più alta (HPDI), possiamo utilizzare pacchetti aggiuntivi come HDInterval.\n\n# Calcolo HPDI (richiede il pacchetto HDInterval)\nhdi(samples, credMass = 0.94)\n#&gt;  lower  upper \n#&gt; 0.5025 0.7928 \n#&gt; attr(,\"credMass\")\n#&gt; [1] 0.94\n\n\n49.6.8 Interpretazione\nL’aggiornamento bayesiano con una distribuzione a priori continua fornisce una stima aggiornata di \\(\\theta\\) che tiene conto sia della distribuzione a priori (conoscenza pregressa) sia della verosimiglianza (dati osservati). Nel nostro esempio, la curva a posteriori risulta spostata verso destra rispetto al prior simmetrico \\(\\text{Beta}(2,2)\\), riflettendo l’evidenza di 22 successi su 30 prove.\nIn alternativa, utilizzando un prior asimmetrico come \\(\\text{Beta}(2,5)\\), la distribuzione a posteriori mostra un compromesso tra la tendenza iniziale a credere in basse probabilità di successo e l’evidenza empirica più ottimista.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Aggiornare le credenze su un parametro: dal prior alla posterior</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_subj_prop.html#metodo-basato-su-griglia",
    "href": "chapters/bayesian_inference/05_subj_prop.html#metodo-basato-su-griglia",
    "title": "49  Pensare ad una proporzione in termini soggettivi",
    "section": "\n49.7 Metodo basato su griglia",
    "text": "49.7 Metodo basato su griglia\nIl metodo utilizzato in questo capitolo per generare la distribuzione a posteriori è noto come metodo basato su griglia. Questo metodo numerico esatto si basa sul calcolo della distribuzione a posteriori mediante una griglia di punti uniformemente spaziati. Nonostante la maggior parte dei parametri sia continua, l’approssimazione della distribuzione a posteriori può essere ottenuta considerando soltanto una griglia finita di valori dei parametri. Il metodo segue quattro fasi:\n\nFissare una griglia discreta di possibili valori dei parametri.\nValutare la distribuzione a priori e la funzione di verosimiglianza per ciascun valore della griglia.\nCalcolare l’approssimazione della densità a posteriori, ottenuta moltiplicando la distribuzione a priori per la funzione di verosimiglianza per ciascun valore della griglia e normalizzando i prodotti in modo che la loro somma sia uguale a 1.\nSelezionare \\(n\\) valori casuali dalla griglia per ottenere un campione casuale della densità a posteriori normalizzata.\n\nQuesto metodo può essere potenziato aumentando il numero di punti nella griglia, ma il limite principale risiede nel fatto che all’aumentare della dimensionalità dello spazio dei parametri, il numero di punti necessari per una stima accurata cresce in modo esponenziale, rendendo il metodo impraticabile per problemi complessi.\nIn sintesi, l’approccio basato sulla griglia è intuitivo e non richiede competenze di programmazione avanzate per l’implementazione. Inoltre, fornisce un risultato che può essere considerato, per tutti gli scopi pratici, come un campione casuale estratto dalla distribuzione di probabilità a posteriori condizionata ai dati. Tuttavia, questo metodo è limitato a causa della maledizione della dimensionalità1, il che significa che può essere applicato soltanto a modelli statistici semplici con non più di due parametri. Di conseguenza, in pratica, è spesso sostituito da altre tecniche più efficienti, poiché i modelli impiegati in psicologia richiedono frequentemente la stima di centinaia o anche migliaia di parametri.\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nIn uno studio sulla percezione delle emozioni, un partecipante osserva 10 fotografie di volti arrabbiati. Deve indicare se il volto esprime rabbia o no. Ogni risposta può essere corretta (1) o errata (0).\nI dati osservati del partecipante sono:\n1, 0, 1, 1, 1, 0, 0, 1, 1, 1\n→ Totale: 7 successi su 10 prove → \\(y = 7\\), \\(n = 10\\).\nObiettivo: stimare la probabilità \\(\\theta\\) che il partecipante riconosca correttamente un volto arrabbiato, tenendo conto sia dei dati osservati sia di conoscenze pregresse.\nPrior Informativo.\nSupponiamo di voler adottare un approccio cautamente pessimistico sulle capacità iniziali del partecipante, basandoci su studi precedenti che indicano un riconoscimento della rabbia non sempre accurato, ad esempio mediamente intorno al 40% con moderata incertezza.\nPer rappresentare questa convinzione, scegliamo come distribuzione a priori una Beta(4, 6):\n\n\nMedia: \\(\\mu = \\frac{4}{4+6} = 0.4\\)\n\n\nVarianza: \\(\\frac{4 \\cdot 6}{(10)^2 \\cdot 11} = 0.0218\\)\n\n\nQuesta prior concentra la massa di probabilità su valori inferiori a 0.5, ma lascia spazio anche a livelli di competenza superiori.\nCalcolo della Distribuzione a Posteriori con il Metodo Basato su Griglia.\n1. Griglia di valori per \\(\\theta\\).\n\ntheta &lt;- seq(0, 1, length.out = 1000)\nhead(theta)\n#&gt; [1] 0.000000 0.001001 0.002002 0.003003 0.004004 0.005005\ntail(theta)\n#&gt; [1] 0.995 0.996 0.997 0.998 0.999 1.000\n\n2. Calcolo della distribuzione a priori Beta(4, 6).\n\nprior &lt;- dbeta(theta, shape1 = 4, shape2 = 6)\nprior &lt;- prior / sum(prior)  # normalizzazione\n\nVisualizzazione:\n\nggplot(data.frame(theta, prior), aes(x = theta, y = prior)) +\n  geom_line(linewidth = 1.2, color = okabe_ito_palette[2]) +\n  labs(\n    title = \"Distribuzione a Priori Informativa: Beta(4, 6)\",\n    x = expression(theta),\n    y = \"Densità (normalizzata)\"\n  ) +\n  theme_minimal(base_size = 14)\n\n\n\n\n\n\n\n3. Calcolo della verosimiglianza per 7 successi su 10.\n\nlikelihood &lt;- dbinom(7, size = 10, prob = theta)\nlikelihood &lt;- likelihood / sum(likelihood)  # normalizzazione\n\nVisualizzazione:\n\nggplot(data.frame(theta, likelihood), aes(x = theta, y = likelihood)) +\n  geom_line(linewidth = 1.2, color = okabe_ito_palette[1]) +\n  labs(\n    title = \"Funzione di Verosimiglianza: 7 successi su 10\",\n    x = expression(theta),\n    y = \"Densità (normalizzata)\"\n  ) +\n  theme_minimal(base_size = 14)\n\n\n\n\n\n\n\n4. Calcolo della distribuzione a posteriori.\n\nunnormalized_posterior &lt;- prior * likelihood\nposterior &lt;- unnormalized_posterior / sum(unnormalized_posterior)\n\n5. Visualizzazione congiunta: prior, likelihood e posteriori.\n\ndata &lt;- data.frame(theta, prior, likelihood, posterior)\n\n# Imposta i livelli desiderati con nomi leggibili\nlong_data &lt;- pivot_longer(\n  data,\n  cols = c(\"prior\", \"likelihood\", \"posterior\"),\n  names_to = \"distribution\",\n  values_to = \"density\"\n) |&gt;\n  mutate(distribution = factor(\n    distribution,\n    levels = c(\"prior\", \"likelihood\", \"posterior\"),\n    labels = c(\"A Priori\", \"Verosimiglianza\", \"A Posteriori\")\n    )\n  )\n\nggplot(\n  long_data, \n  aes(x = theta, y = density, color = distribution)\n  ) +\n  geom_line(linewidth = 1.2) +\n  labs(\n    title = \"Distribuzioni Bayesiane: A Priori, Verosimiglianza e A Posteriori\",\n    x = expression(theta),\n    y = \"Densità (normalizzata)\",\n    color = NULL\n  ) +\n  scale_color_manual(\n    values = c(\n      \"A Priori\" = okabe_ito_palette[2],       # blu\n      \"Verosimiglianza\" = okabe_ito_palette[1],# arancione\n      \"A Posteriori\" = okabe_ito_palette[3]    # verde\n    )\n  ) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\nRiepilogo:\n\nla prior (Beta(4,6)) riflette una convinzione iniziale più scettica;\nla verosimiglianza è centrata su \\(\\theta = 0.7\\), corrispondente a 7 successi su 10;\nla posteriori media tra prior e dati, ma si sposta chiaramente verso destra, evidenziando l’effetto aggiornamento bayesiano.\n\nQuesto esempio mostra come l’approccio bayesiano:\n\n\nintegra in modo trasparente dati individuali e credenze pregresse;\n\nproduce una stima personalizzata della capacità del partecipante;\npermette di quantificare l’incertezza in modo completo, tramite la distribuzione a posteriori.\n\nQuantità a Posteriori.\nMedia:\n\nposterior_mean &lt;- sum(theta * posterior)\nposterior_mean\n#&gt; [1] 0.55\n\nDeviazione standard:\n\nposterior_sd &lt;- sqrt(sum((theta^2) * posterior) - posterior_mean^2)\nposterior_sd\n#&gt; [1] 0.1086\n\nModa:\n\nposterior_mode &lt;- theta[which.max(posterior)]\nposterior_mode\n#&gt; [1] 0.5556\n\nIntervallo di credibilità al 94%:\n\nsamples &lt;- sample(theta, size = 10000, replace = TRUE, prob = posterior)\nquantile(samples, probs = c(0.03, 0.97))\n#&gt;     3%    97% \n#&gt; 0.3433 0.7528\n\nQuesto esercizio mostra come:\n\nl’informazione pregressa può essere incorporata in modo trasparente in un modello bayesiano;\nla posteriori riflette una combinazione tra dati osservati e conoscenze precedenti.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_subj_prop.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/05_subj_prop.html#riflessioni-conclusive",
    "title": "49  Aggiornare le credenze su un parametro: dal prior alla posterior",
    "section": "\n49.8 Riflessioni conclusive",
    "text": "49.8 Riflessioni conclusive\nIn questo capitolo abbiamo esaminato l’aggiornamento bayesiano nel caso di distribuzioni a priori discrete, con un breve accenno alle prior continue. Mentre queste ultime richiedono solitamente metodi numerici per il calcolo della distribuzione a posteriori, esistono situazioni particolari—come l’inferenza su proporzioni con prior Beta e verosimiglianza binomiale—in cui la posterior è derivabile analiticamente. Questi casi saranno approfonditi nei capitoli successivi.\nL’approccio utilizzato qui si basa sul metodo basato su griglia, una tecnica numerica che approssima la posterior discretizzando lo spazio dei parametri. Il procedimento è semplice: si definisce una griglia di valori plausibili per il parametro, si valutano prior e verosimiglianza in ciascun punto, si calcola la posterior non normalizzata e infine la si normalizza per ottenere una distribuzione di probabilità valida. Questo metodo fornisce risultati esatti (a meno dell’approssimazione della griglia) e non richiede strumenti computazionali avanzati.\nIl metodo basato su griglia si applica anche a modelli continui con verosimiglianza gaussiana, come nel caso della stima della media. L’idea centrale resta invariata: valutare, per ciascun punto della griglia, il prodotto tra prior e verosimiglianza, e normalizzare. L’approccio mantiene una trasparenza didattica elevata, rendendolo ideale per introdurre l’inferenza bayesiana in contesti psicologici anche con variabili continue.\nTuttavia, l’utilità del metodo basato su griglia è limitata dalla maledizione della dimensionalità: mentre per uno o due parametri il metodo rimane efficiente, all’aumentare del loro numero il costo computazionale diventa rapidamente proibitivo. Basti pensare che, con una griglia di 100 punti per parametro, un modello a 10 parametri richiederebbe la valutazione di \\(10^{20}\\) combinazioni, rendendo l’approccio impraticabile. Per questo, nella statistica bayesiana applicata—dove i modelli spesso coinvolgono decine o centinaia di parametri—si preferiscono tecniche più efficienti, come il campionamento MCMC, che affronteremo in seguito.\nIn sintesi, il metodo a griglia rappresenta un’introduzione accessibile all’inferenza bayesiana, utile per comprendere i concetti fondamentali e applicabile a problemi semplici. Tuttavia, la sua scalabilità limitata ne riduce l’uso pratico, spingendo verso approcci più sofisticati quando si lavora con modelli realistici.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Aggiornare le credenze su un parametro: dal prior alla posterior</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_subj_prop.html#esercizi",
    "href": "chapters/bayesian_inference/05_subj_prop.html#esercizi",
    "title": "49  Aggiornare le credenze su un parametro: dal prior alla posterior",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nIn uno studio sulla percezione delle emozioni, un partecipante osserva 10 fotografie di volti arrabbiati. Deve indicare se il volto esprime rabbia o no. Ogni risposta può essere corretta (1) o errata (0).\nI dati osservati del partecipante sono:\n1, 0, 1, 1, 1, 0, 0, 1, 1, 1\n→ Totale: 7 successi su 10 prove → \\(y = 7\\), \\(n = 10\\).\nObiettivo: stimare la probabilità \\(\\theta\\) che il partecipante riconosca correttamente un volto arrabbiato, tenendo conto sia dei dati osservati sia di conoscenze pregresse.\nPrior Informativo.\nSupponiamo di voler adottare un approccio cautamente pessimistico sulle capacità iniziali del partecipante, basandoci su studi precedenti che indicano un riconoscimento della rabbia non sempre accurato, ad esempio mediamente intorno al 40% con moderata incertezza.\nPer rappresentare questa convinzione, scegliamo come distribuzione a priori una Beta(4, 6):\n\n\nMedia: \\(\\mu = \\frac{4}{4+6} = 0.4\\)\n\n\nVarianza: \\(\\frac{4 \\cdot 6}{(10)^2 \\cdot 11} = 0.0218\\)\n\n\nQuesta prior concentra la massa di probabilità su valori inferiori a 0.5, ma lascia spazio anche a livelli di competenza superiori.\nCalcolo della Distribuzione a Posteriori con il Metodo Basato su Griglia.\n1. Griglia di valori per \\(\\theta\\).\n\ntheta &lt;- seq(0, 1, length.out = 1000)\nhead(theta)\n#&gt; [1] 0.000000 0.001001 0.002002 0.003003 0.004004 0.005005\ntail(theta)\n#&gt; [1] 0.995 0.996 0.997 0.998 0.999 1.000\n\n2. Calcolo della distribuzione a priori Beta(4, 6).\n\nprior &lt;- dbeta(theta, shape1 = 4, shape2 = 6)\nprior &lt;- prior / sum(prior)  # normalizzazione\n\nVisualizzazione:\n\nggplot(data.frame(theta, prior), aes(x = theta, y = prior)) +\n  geom_line(linewidth = 1.2, color = okabe_ito_palette[2]) +\n  labs(\n    title = \"Distribuzione a Priori Informativa: Beta(4, 6)\",\n    x = expression(theta),\n    y = \"Densità (normalizzata)\"\n  ) +\n  theme_minimal(base_size = 14)\n\n\n\n\n\n\n\n3. Calcolo della verosimiglianza per 7 successi su 10.\n\nlikelihood &lt;- dbinom(7, size = 10, prob = theta)\nlikelihood &lt;- likelihood / sum(likelihood)  # normalizzazione\n\nVisualizzazione:\n\nggplot(data.frame(theta, likelihood), aes(x = theta, y = likelihood)) +\n  geom_line(linewidth = 1.2, color = okabe_ito_palette[1]) +\n  labs(\n    title = \"Funzione di Verosimiglianza: 7 successi su 10\",\n    x = expression(theta),\n    y = \"Densità (normalizzata)\"\n  ) +\n  theme_minimal(base_size = 14)\n\n\n\n\n\n\n\n4. Calcolo della distribuzione a posteriori.\n\nunnormalized_posterior &lt;- prior * likelihood\nposterior &lt;- unnormalized_posterior / sum(unnormalized_posterior)\n\n5. Visualizzazione congiunta: prior, likelihood e posteriori.\n\ndata &lt;- data.frame(theta, prior, likelihood, posterior)\n\n# Imposta i livelli desiderati con nomi leggibili\nlong_data &lt;- pivot_longer(\n  data,\n  cols = c(\"prior\", \"likelihood\", \"posterior\"),\n  names_to = \"distribution\",\n  values_to = \"density\"\n) |&gt;\n  mutate(distribution = factor(\n    distribution,\n    levels = c(\"prior\", \"likelihood\", \"posterior\"),\n    labels = c(\"A Priori\", \"Verosimiglianza\", \"A Posteriori\")\n    )\n  )\n\nggplot(\n  long_data, \n  aes(x = theta, y = density, color = distribution)\n  ) +\n  geom_line(linewidth = 1.2) +\n  labs(\n    title = \"Distribuzioni Bayesiane: A Priori, Verosimiglianza e A Posteriori\",\n    x = expression(theta),\n    y = \"Densità (normalizzata)\",\n    color = NULL\n  ) +\n  scale_color_manual(\n    values = c(\n      \"A Priori\" = okabe_ito_palette[2],       # blu\n      \"Verosimiglianza\" = okabe_ito_palette[1],# arancione\n      \"A Posteriori\" = okabe_ito_palette[3]    # verde\n    )\n  ) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\nRiepilogo:\n\nla prior (Beta(4,6)) riflette una convinzione iniziale più scettica;\nla verosimiglianza è centrata su \\(\\theta = 0.7\\), corrispondente a 7 successi su 10;\nla posteriori media tra prior e dati, ma si sposta chiaramente verso destra, evidenziando l’effetto aggiornamento bayesiano.\n\nQuesto esempio mostra come l’approccio bayesiano:\n\n\nintegra in modo trasparente dati individuali e credenze pregresse;\n\nproduce una stima personalizzata della capacità del partecipante;\npermette di quantificare l’incertezza in modo completo, tramite la distribuzione a posteriori.\n\nQuantità a Posteriori.\nMedia:\n\nposterior_mean &lt;- sum(theta * posterior)\nposterior_mean\n#&gt; [1] 0.55\n\nDeviazione standard:\n\nposterior_sd &lt;- sqrt(sum((theta^2) * posterior) - posterior_mean^2)\nposterior_sd\n#&gt; [1] 0.1086\n\nModa:\n\nposterior_mode &lt;- theta[which.max(posterior)]\nposterior_mode\n#&gt; [1] 0.5556\n\nIntervallo di credibilità al 94%:\n\nsamples &lt;- sample(theta, size = 10000, replace = TRUE, prob = posterior)\nquantile(samples, probs = c(0.03, 0.97))\n#&gt;     3%    97% \n#&gt; 0.3433 0.7528\n\nQuesto esercizio mostra come:\n\nl’informazione pregressa può essere incorporata in modo trasparente in un modello bayesiano;\nla posteriori riflette una combinazione tra dati osservati e conoscenze precedenti.\n\n\n\n\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nIn uno studio sull’analisi delle pratiche di trasparenza e riproducibilità nella ricerca in psicologia, Hardwicke et al. (2022) hanno riportato che la condivisione dei materiali di ricerca è stata rilevata nel 14% dei casi (26 su 183 studi), con un intervallo di confidenza al 95% pari a [10%, 19%]. Questo suggerisce che la condivisione di materiali è rara.\nIspirandoti ai risultati di questo studio, costruisci una distribuzione a priori per la probabilità \\(\\theta\\) che uno studio condivida i materiali di ricerca. Per semplicità, discretizza \\(\\theta\\) in 10 livelli equispaziati: \\(0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95\\).\nAttribuisci le seguenti probabilità a priori ai 10 livelli, basandoti sull’informazione che la condivisione dei materiali è un evento raro ma non trascurabile: \\(0.05, 0.20, 0.30, 0.15, 0.10, 0.08, 0.05, 0.03, 0.02, 0.02\\).\nSupponiamo che siano stati osservati 20 studi su 100 che hanno condiviso i materiali di ricerca. Calcola la distribuzione a posteriori utilizzando il metodo basato su griglia. Calcola la media della distribuzione a posteriori e l’intervallo di credibilità al 89%.\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\n# Definizione dei possibili valori di theta (probabilità discreta)\ntheta &lt;- seq(0.05, 0.95, by = 0.10)\n\n# Definizione della distribuzione a priori\nprior &lt;- c(0.05, 0.20, 0.30, 0.15, 0.10, 0.08, 0.05, 0.03, 0.02, 0.02)\n\n# Normalizzazione della prior (se necessario, ma in questo caso già normalizzata)\nprior &lt;- prior / sum(prior)\n\n# Dati osservati\nsuccessi &lt;- 20  # studi che hanno condiviso materiali\nn &lt;- 100        # studi totali\n\n# Calcolo della verosimiglianza usando la distribuzione binomiale\nlikelihood &lt;- dbinom(successi, size = n, prob = theta)\n\n# Calcolo della distribuzione a posteriori (applicazione del teorema di Bayes)\nposterior &lt;- likelihood * prior\nposterior &lt;- posterior / sum(posterior)  # Normalizzazione\n\n# Calcolo della media della distribuzione a posteriori\nposterior_mean &lt;- sum(theta * posterior)\n\n# Calcolo dell'intervallo di credibilità al 89%\ncdf &lt;- cumsum(posterior)  # Distribuzione cumulativa\nlower_bound &lt;- theta[which.min(abs(cdf - 0.055))]  # 5.5% quantile\nupper_bound &lt;- theta[which.min(abs(cdf - 0.945))]  # 94.5% quantile\n\n# Output dei risultati\nlist(\n  posterior_mean = posterior_mean,\n  credibility_interval_89 = c(lower_bound, upper_bound)\n)\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nL’obiettivo di questo esercizio è applicare il metodo basato su griglia per stimare la distribuzione a posteriori di una proporzione, utilizzando dati dalla Scala della Rete Sociale di Lubben (LSNS-6). Si assume che un punteggio LSNS-6 superiore a una soglia prefissata indichi isolamento sociale. Il compito è:\n\nScegliere una soglia per classificare i partecipanti in due gruppi (isolati vs. non isolati), garantendo che la proporzione osservata non sia inferiore a 0.1 o superiore a 0.9.\nCalcolare la distribuzione a posteriori della proporzione usando un’approssimazione discreta su una griglia di valori.\nDeterminare l’intervallo di credibilità all’89%.\nInterpretare i risultati.\n\nConsegna: caricare su Moodle il file .qmd compilato in pdf.\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\nDati e Modellizzazione\nSi assume che i dati siano rappresentati da una variabile binaria \\(y\\), con \\(y = 1\\) per individui classificati come isolati e \\(y = 0\\) altrimenti. Supponiamo che su un campione di \\(n\\) individui, \\(s\\) siano isolati.\nDefiniamo il modello statistico:\n\\[ y_i \\sim \\text{Bernoulli}(\\theta) \\]\ncon:\n\n\n\\(y_i \\in \\{0,1\\}\\) per \\(i=1,\\dots,n\\),\n\n\\(\\theta\\) proporzione di individui isolati nella popolazione.\n\nLa distribuzione a priori su \\(\\theta\\) è scelta come \\(\\text{Beta}(2,2)\\), che rappresenta una conoscenza iniziale moderata e non estrema.\nMetodo basato su griglia\nIl metodo a griglia approssima la distribuzione a posteriori calcolando la probabilità per una serie di valori discreti di \\(\\theta\\).\n\n\nDefinire una griglia di valori per \\(\\theta\\):\ntheta &lt;- seq(0, 1, length.out = 100)\n\n\nCalcolare la distribuzione a priori:\nprior &lt;- dbeta(theta, 2, 2)\nprior &lt;- prior / sum(prior)  # Normalizzazione\n\n\nCalcolare la verosimiglianza:\nlikelihood &lt;- dbinom(s, size = n, prob = theta)\nlikelihood &lt;- likelihood / sum(likelihood)  # Normalizzazione\n\n\nCalcolare la distribuzione a posteriori:\nposterior &lt;- prior * likelihood\nposterior &lt;- posterior / sum(posterior)  # Normalizzazione\n\n\n** Calcolo dell’intervallo di credibilità all’89%**\nL’intervallo di credibilità è calcolato come l’intervallo che contiene il 89% della probabilità a posteriori.\nci_89 &lt;- quantile(sample(theta, size = 10000, prob = posterior, replace = TRUE), probs = c(0.055, 0.945))\nci_89\nInterpretazione dei risultati\n\n\nValore atteso e moda a posteriori:\nmean_theta &lt;- sum(theta * posterior)\nmode_theta &lt;- theta[which.max(posterior)]\n\nIl valore atteso fornisce una stima puntuale di \\(\\theta\\).\nLa moda indica il valore più probabile della proporzione di isolamento sociale.\n\n\n\nIntervallo di credibilità:\n\nL’89% della probabilità a posteriori cade tra i valori dell’intervallo di credibilità.\nSe l’intervallo è stretto, c’è maggiore certezza sulla proporzione stimata.\nSe l’intervallo è ampio, vi è maggiore incertezza sulla proporzione.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Aggiornare le credenze su un parametro: dal prior alla posterior</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_subj_prop.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/05_subj_prop.html#informazioni-sullambiente-di-sviluppo",
    "title": "49  Aggiornare le credenze su un parametro: dal prior alla posterior",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] HDInterval_0.2.4 thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0\n#&gt;  [5] see_0.11.0       gridExtra_2.3    patchwork_1.3.0  bayesplot_1.12.0\n#&gt;  [9] psych_2.5.3      scales_1.4.0     markdown_2.0     knitr_1.50      \n#&gt; [13] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [17] purrr_1.0.4      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [21] ggplot2_3.5.2    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.4     stringi_1.8.7      lattice_0.22-7    \n#&gt;  [4] hms_1.1.3          digest_0.6.37      magrittr_2.0.3    \n#&gt;  [7] evaluate_1.0.3     grid_4.5.0         timechange_0.3.0  \n#&gt; [10] RColorBrewer_1.1-3 fastmap_1.2.0      rprojroot_2.0.4   \n#&gt; [13] jsonlite_2.0.0     mnormt_2.1.1       cli_3.6.5         \n#&gt; [16] rlang_1.1.6        withr_3.0.2        tools_4.5.0       \n#&gt; [19] parallel_4.5.0     tzdb_0.5.0         pacman_0.5.1      \n#&gt; [22] vctrs_0.6.5        R6_2.6.1           lifecycle_1.0.4   \n#&gt; [25] htmlwidgets_1.6.4  pkgconfig_2.0.3    pillar_1.10.2     \n#&gt; [28] gtable_0.3.6       glue_1.8.0         xfun_0.52         \n#&gt; [31] tidyselect_1.2.1   rstudioapi_0.17.1  farver_2.1.2      \n#&gt; [34] htmltools_0.5.8.1  nlme_3.1-168       labeling_0.4.3    \n#&gt; [37] rmarkdown_2.29     compiler_4.5.0",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Aggiornare le credenze su un parametro: dal prior alla posterior</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_subj_prop.html#bibliografia",
    "href": "chapters/bayesian_inference/05_subj_prop.html#bibliografia",
    "title": "49  Aggiornare le credenze su un parametro: dal prior alla posterior",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlbert, J., & Hu, J. (2019). Probability and Bayesian Modeling. CRC Press.\n\n\nHardwicke, T. E., Thibault, R. T., Kosie, J. E., Wallach, J. D., Kidwell, M. C., & Ioannidis, J. P. (2022). Estimating the prevalence of transparency and reproducibility-related research practices in psychology (2014–2017). Perspectives on Psychological Science, 17(1), 239–251.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Aggiornare le credenze su un parametro: dal prior alla posterior</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_subj_prop.html#footnotes",
    "href": "chapters/bayesian_inference/05_subj_prop.html#footnotes",
    "title": "49  Pensare ad una proporzione in termini soggettivi",
    "section": "",
    "text": "Per comprendere la maledizione della dimensionalità, possiamo considerare l’esempio di una griglia di 100 punti equispaziati. Nel caso di un solo parametro, sarebbe necessario calcolare solo 100 valori. Tuttavia, se abbiamo due parametri, il numero di valori da calcolare diventa \\(100^2\\). Se invece abbiamo 10 parametri, il numero di valori da calcolare sarebbe di \\(10^{10}\\). È evidente che la quantità di calcoli richiesta diventa troppo grande persino per un computer molto potente. Pertanto, per modelli che richiedono la stima di un numero significativo di parametri, è necessario utilizzare un approccio diverso.↩︎",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_grid_gauss.html",
    "href": "chapters/bayesian_inference/06_grid_gauss.html",
    "title": "50  Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia",
    "section": "",
    "text": "50.1 Introduzione\nIn questo capitolo, estenderemo la discussione precedente sul calcolo della distribuzione a posteriori utilizzando il metodo basato su griglia, applicandolo questa volta a un caso con verosimiglianza gaussiana. In particolare, ci concentreremo su come costruire un modello gaussiano per descrivere l’intelligenza.\nImmaginiamo di condurre uno studio sulla plusdotazione, considerando l’approccio psicometrico. Secondo questo approccio, una persona è considerata plusdotata se ha un QI (Quoziente Intellettivo) di 130 o superiore (Robinson, Zigler, & Gallagher, 2000). Anche se l’uso di un QI di 130 come soglia è il criterio più comune, non è universalmente accettato. L’intelligenza nei bambini plusdotati non è solo superiore rispetto a quella dei loro pari, ma è qualitativamente diversa (Lubart & Zenasni, 2010). I bambini plusdotati tendono a mostrare caratteristiche come un vocabolario ampio, un linguaggio molto sviluppato, processi di ragionamento avanzati, eccellente memoria, vasti interessi, forte curiosità, empatia, capacità di leadership, abilità visive elevate, impegno in situazioni sfidanti e un forte senso di giustizia (Song & Porath, 2005).\nNella simulazione che seguirà, assumeremo che i dati provengano da una distribuzione normale. Per semplicità, considereremo che la deviazione standard sia nota e pari a 5. Il parametro della media sarà l’oggetto della nostra inferenza.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_grid_gauss.html#dati",
    "href": "chapters/bayesian_inference/06_grid_gauss.html#dati",
    "title": "50  Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia",
    "section": "\n50.2 Dati",
    "text": "50.2 Dati\nSupponiamo di avere un campione di 10 osservazioni. I dati saranno generati casualmente da una distribuzione normale con media 130 e deviazione standard 5.\n\nset.seed(123) # Per la riproducibilità\nvera_media &lt;- 130 # Media vera\nsigma_conosciuta &lt;- 5 # Deviazione standard conosciuta\ndimensione_campione &lt;- 10 # Dimensione del campione\n\n# Generare un campione\ncampione &lt;- round(rnorm(n = dimensione_campione, mean = vera_media, sd = sigma_conosciuta))\ncampione\n#&gt;  [1] 127 129 138 130 131 139 132 124 127 128",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_grid_gauss.html#griglia",
    "href": "chapters/bayesian_inference/06_grid_gauss.html#griglia",
    "title": "50  Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia",
    "section": "\n50.3 Griglia",
    "text": "50.3 Griglia\nCreiamo ora una griglia di 100 valori compresi tra 110 e 150.\n\nmu_griglia &lt;- seq(110, 150, length.out = 100)\nmu_griglia\n#&gt;   [1] 110.0 110.4 110.8 111.2 111.6 112.0 112.4 112.8 113.2 113.6 114.0\n#&gt;  [12] 114.4 114.8 115.3 115.7 116.1 116.5 116.9 117.3 117.7 118.1 118.5\n#&gt;  [23] 118.9 119.3 119.7 120.1 120.5 120.9 121.3 121.7 122.1 122.5 122.9\n#&gt;  [34] 123.3 123.7 124.1 124.5 124.9 125.4 125.8 126.2 126.6 127.0 127.4\n#&gt;  [45] 127.8 128.2 128.6 129.0 129.4 129.8 130.2 130.6 131.0 131.4 131.8\n#&gt;  [56] 132.2 132.6 133.0 133.4 133.8 134.2 134.6 135.1 135.5 135.9 136.3\n#&gt;  [67] 136.7 137.1 137.5 137.9 138.3 138.7 139.1 139.5 139.9 140.3 140.7\n#&gt;  [78] 141.1 141.5 141.9 142.3 142.7 143.1 143.5 143.9 144.3 144.7 145.2\n#&gt;  [89] 145.6 146.0 146.4 146.8 147.2 147.6 148.0 148.4 148.8 149.2 149.6\n#&gt; [100] 150.0",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_grid_gauss.html#calcolo-della-verosimiglianza",
    "href": "chapters/bayesian_inference/06_grid_gauss.html#calcolo-della-verosimiglianza",
    "title": "50  Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia",
    "section": "\n50.4 Calcolo della Verosimiglianza",
    "text": "50.4 Calcolo della Verosimiglianza\nPer ogni valore della griglia, calcoliamo la verosimiglianza complessiva come prodotto delle densità di probabilità.\n\nlikelihood &lt;- sapply(mu_griglia, function(mu) {\n    prod(dnorm(campione, mean = mu, sd = sigma_conosciuta))\n})\nlikelihood\n#&gt;   [1] 5.288e-50 1.406e-48 3.502e-47 8.172e-46 1.786e-44 3.658e-43 7.016e-42\n#&gt;   [8] 1.261e-40 2.122e-39 3.347e-38 4.944e-37 6.842e-36 8.870e-35 1.077e-33\n#&gt;  [15] 1.226e-32 1.306e-31 1.304e-30 1.220e-29 1.069e-28 8.772e-28 6.745e-27\n#&gt;  [22] 4.858e-26 3.278e-25 2.072e-24 1.227e-23 6.807e-23 3.537e-22 1.722e-21\n#&gt;  [29] 7.852e-21 3.355e-20 1.343e-19 5.033e-19 1.768e-18 5.816e-18 1.792e-17\n#&gt;  [36] 5.175e-17 1.400e-16 3.547e-16 8.418e-16 1.872e-15 3.899e-15 7.608e-15\n#&gt;  [43] 1.391e-14 2.381e-14 3.820e-14 5.741e-14 8.082e-14 1.066e-13 1.317e-13\n#&gt;  [50] 1.524e-13 1.652e-13 1.678e-13 1.596e-13 1.423e-13 1.188e-13 9.293e-14\n#&gt;  [57] 6.809e-14 4.674e-14 3.005e-14 1.810e-14 1.022e-14 5.400e-15 2.674e-15\n#&gt;  [64] 1.240e-15 5.391e-16 2.195e-16 8.370e-17 2.990e-17 1.001e-17 3.138e-18\n#&gt;  [71] 9.215e-19 2.535e-19 6.535e-20 1.578e-20 3.569e-21 7.563e-22 1.501e-22\n#&gt;  [78] 2.791e-23 4.863e-24 7.935e-25 1.213e-25 1.737e-26 2.330e-27 2.929e-28\n#&gt;  [85] 3.448e-29 3.802e-30 3.929e-31 3.802e-32 3.447e-33 2.928e-34 2.330e-35\n#&gt;  [92] 1.736e-36 1.212e-37 7.931e-39 4.860e-40 2.790e-41 1.500e-42 7.557e-44\n#&gt;  [99] 3.566e-45 1.576e-46",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_grid_gauss.html#calcolo-della-distribuzione-a-posteriori",
    "href": "chapters/bayesian_inference/06_grid_gauss.html#calcolo-della-distribuzione-a-posteriori",
    "title": "50  Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia",
    "section": "\n50.5 Calcolo della Distribuzione a Posteriori",
    "text": "50.5 Calcolo della Distribuzione a Posteriori\nImpostiamo una prior uniforme e calcoliamo la distribuzione a posteriori normalizzata.\n\nprior &lt;- rep(1, length(mu_griglia)) # Prior uniforme\nposterior_non_norm &lt;- likelihood * prior\nposterior &lt;- posterior_non_norm / sum(posterior_non_norm) # Normalizzazione\n\nVisualizzazione:\n\n# Creazione del dataframe per il plot\ndat &lt;- tibble(\n  mu_griglia = mu_griglia, # Ascissa\n  posterior = posterior    # Ordinata\n)\n\n# Grafico con ggplot2\ndat |&gt;\n  ggplot(aes(x = mu_griglia, y = posterior)) +\n  geom_line(size = 1.2) + \n  labs(\n    title = \"Distribuzione a Posteriori della Media\",\n    x = \"Media\",\n    y = \"Probabilità\"\n  ) +\n  theme(\n    plot.title = element_text(hjust = 0.5), # Centra il titolo\n    legend.position = \"none\" \n  )\n\n\n\n\n\n\n\n\n50.5.1 Aggiunta di una Prior Informativa\nUsiamo una prior gaussiana con media 140 e deviazione standard 3.\n\n# Calcolo prior, posterior non normalizzato e posterior\nprior &lt;- dnorm(mu_griglia, mean = 140, sd = 3)\nposterior_non_norm &lt;- likelihood * prior\nposterior &lt;- posterior_non_norm / sum(posterior_non_norm)\n\n# Creazione del dataframe per il grafico\ndat &lt;- tibble(\n  mu_griglia = mu_griglia,\n  prior = prior / sum(prior),  # Normalizzazione del prior\n  posterior = posterior        # Posterior già normalizzato\n)\n\n# Preparazione dei dati in formato lungo per ggplot2\nlong_data &lt;- dat |&gt;\n  pivot_longer(\n    cols = c(prior, posterior),\n    names_to = \"distribution\",\n    values_to = \"density\"\n  )\n\n# Grafico con ggplot2\nlong_data |&gt;\n  ggplot(aes(x = mu_griglia, y = density, color = distribution, linetype = distribution)) +\n  geom_line(size = 1.2) +\n  labs(\n    title = \"Distribuzione a Posteriori e Prior della Media\",\n    x = \"Media\",\n    y = \"Densità\",\n    color = \"Distribuzione\",\n    linetype = \"Distribuzione\"\n  ) +\n  theme(\n    plot.title = element_text(hjust = 0.5),\n    legend.position = \"bottom\"\n  )",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_grid_gauss.html#campionamento-dalla-posterior",
    "href": "chapters/bayesian_inference/06_grid_gauss.html#campionamento-dalla-posterior",
    "title": "50  Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia",
    "section": "\n50.6 Campionamento dalla Posterior",
    "text": "50.6 Campionamento dalla Posterior\nGeneriamo un campione dalla distribuzione a posteriori.\n\n# Set seed for reproducibility\nset.seed(123)\n\n# Sampling from the posterior distribution\nindice_campionato &lt;- sample(1:length(mu_griglia), size = 1000, replace = TRUE, prob = posterior)\nmedia_campionata &lt;- mu_griglia[indice_campionato]\n\n# Create a dataframe for ggplot2\nsample_df &lt;- tibble(media_campionata = media_campionata)\n\n# Histogram using ggplot2\nggplot(sample_df, aes(x = media_campionata)) +\n  geom_histogram(\n    bins = 20, \n    color = \"white\", \n    alpha = 0.8\n  ) +\n  labs(\n    title = \"Campionamento dalla Posterior\",\n    x = \"Media\",\n    y = \"Frequenza\"\n  ) +\n  theme(\n    plot.title = element_text(hjust = 0.5)\n  )\n\n\n\n\n\n\n\n\n# Media e intervallo di credibilità\nmean(media_campionata)\n#&gt; [1] 132.6\nquantile(media_campionata, c(0.03, 0.97))\n#&gt;    3%   97% \n#&gt; 130.2 135.5",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_grid_gauss.html#calcolo-della-log-verosimiglianza",
    "href": "chapters/bayesian_inference/06_grid_gauss.html#calcolo-della-log-verosimiglianza",
    "title": "50  Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia",
    "section": "\n50.7 Calcolo della Log-Verosimiglianza",
    "text": "50.7 Calcolo della Log-Verosimiglianza\nUtilizziamo i logaritmi per migliorare la stabilità numerica.\n\n# Calcolo log-likelihood, log-prior e posterior\nlog_likelihood &lt;- sapply(mu_griglia, function(mu) {\n  sum(dnorm(campione, mean = mu, sd = sigma_conosciuta, log = TRUE))\n})\nlog_prior &lt;- dnorm(mu_griglia, mean = 140, sd = 3, log = TRUE)\nlog_posterior_non_norm &lt;- log_likelihood + log_prior\nlog_posterior &lt;- log_posterior_non_norm - max(log_posterior_non_norm) # Stabilizzazione numerica\nposterior &lt;- exp(log_posterior) / sum(exp(log_posterior))\n\n# Creazione del dataframe per il grafico\ndat &lt;- tibble(\n  mu_griglia = mu_griglia,\n  posterior = posterior\n)\n\n# Grafico con ggplot2\ndat |&gt;\n  ggplot(aes(x = mu_griglia, y = posterior)) +\n  geom_line(size = 1.2) + \n  labs(\n    title = \"Distribuzione a Posteriori con Log-Verosimiglianza\",\n    x = \"Media\",\n    y = \"Probabilità\"\n  ) +\n  theme(\n    plot.title = element_text(hjust = 0.5), # Centra il titolo\n    legend.position = \"none\"               # Rimuove la legenda per una linea singola\n  )",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_grid_gauss.html#estensione-alla-deviazione-standard-ignota",
    "href": "chapters/bayesian_inference/06_grid_gauss.html#estensione-alla-deviazione-standard-ignota",
    "title": "50  Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia",
    "section": "\n50.8 Estensione alla Deviazione Standard Ignota",
    "text": "50.8 Estensione alla Deviazione Standard Ignota\nPer una griglia bidimensionale di valori di \\(\\mu\\) e \\(\\sigma\\):\n\nmu_griglia &lt;- seq(110, 150, length.out = 100)\nsigma_griglia &lt;- seq(1, 10, length.out = 50)\n\n# Create combinations of mu and sigma using expand.grid\ngrid &lt;- expand.grid(mu = mu_griglia, sigma = sigma_griglia)\n\n# Compute the log-likelihood for each combination of mu and sigma\nlog_likelihood &lt;- apply(grid, 1, function(params) {\n    mu &lt;- params[\"mu\"]\n    sigma &lt;- params[\"sigma\"]\n    sum(dnorm(campione, mean = mu, sd = sigma, log = TRUE))\n})\n\n# Reshape log-likelihood into a matrix\nlog_likelihood_2d &lt;- matrix(log_likelihood, nrow = length(mu_griglia), ncol = length(sigma_griglia))\n\n# Compute priors for mu and sigma\nlog_prior_mu &lt;- dnorm(mu_griglia, mean = 140, sd = 5, log = TRUE)\nlog_prior_sigma &lt;- dnorm(sigma_griglia, mean = 5, sd = 2, log = TRUE)\n\n# Combine priors into a grid\nlog_prior_2d &lt;- outer(log_prior_mu, log_prior_sigma, \"+\")\n\n# Compute log-posterior\nlog_posterior_2d &lt;- log_likelihood_2d + log_prior_2d\nlog_posterior_2d &lt;- log_posterior_2d - max(log_posterior_2d) # Stabilize\nposterior_2d &lt;- exp(log_posterior_2d)\nposterior_2d &lt;- posterior_2d / sum(posterior_2d) # Normalize\n\n# Convert posterior_2d to a data frame for visualization\nposterior_df &lt;- reshape2::melt(posterior_2d)\nnames(posterior_df) &lt;- c(\"mu_idx\", \"sigma_idx\", \"posterior\")\nposterior_df$mu &lt;- mu_griglia[posterior_df$mu_idx]\nposterior_df$sigma &lt;- sigma_griglia[posterior_df$sigma_idx]\n\n# Plot the posterior distribution\nggplot(posterior_df, aes(x = mu, y = sigma, fill = posterior)) +\n  geom_tile() +\n  scale_fill_viridis_c(name = \"Posterior\") +\n  labs(\n    title = \"Distribuzione a Posteriori Bidimensionale\",\n    x = expression(mu), \n    y = expression(sigma)\n  ) +\n  theme(\n    plot.title = element_text(hjust = 0.5),\n    legend.position = \"right\"\n  )",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_grid_gauss.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/06_grid_gauss.html#riflessioni-conclusive",
    "title": "50  Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia",
    "section": "\n50.9 Riflessioni Conclusive",
    "text": "50.9 Riflessioni Conclusive\nQuando si passa alla stima simultanea di più parametri, come la media (\\(\\mu\\)) e la deviazione standard (\\(\\sigma\\)), l’analisi diventa notevolmente più complessa. Questo perché occorre considerare un numero molto maggiore di combinazioni di parametri rispetto alla stima di un solo parametro, aumentando così il carico computazionale. Inoltre, la scelta delle priors per ciascun parametro richiede particolare attenzione, poiché queste influenzeranno in modo diretto le stime a posteriori.\nIn scenari dove lo spazio dei parametri è multidimensionale o quando l’esplorazione della griglia diventa impraticabile, l’uso di metodi avanzati come il campionamento di Markov Chain Monte Carlo (MCMC) diventa indispensabile. Questi metodi permettono di campionare in modo efficiente dalla distribuzione a posteriori, senza la necessità di esplorare esplicitamente ogni combinazione possibile di parametri, rendendo l’analisi più gestibile anche in contesti complessi.\nIn conclusione, l’estensione dell’approccio bayesiano a problemi con più parametri sconosciuti richiede un’attenzione ancora maggiore nella definizione dello spazio dei parametri, nella selezione delle priors appropriate e nel calcolo delle distribuzioni a posteriori. L’adozione di tecniche come l’MCMC può facilitare questo processo, permettendo di affrontare in modo efficiente problemi che altrimenti sarebbero proibitivi dal punto di vista computazionale.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_grid_gauss.html#esercizi",
    "href": "chapters/bayesian_inference/06_grid_gauss.html#esercizi",
    "title": "50  Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nQuali sono i vantaggi dell’uso del metodo della griglia per il calcolo della distribuzione a posteriori? Quali sono le principali limitazioni di questo approccio?\nQual è il ruolo della funzione di verosimiglianza nell’inferenza bayesiana e come si combina con la distribuzione a priori per ottenere la distribuzione a posteriori?\nIn che modo l’uso di una distribuzione a priori informativa può influenzare l’inferenza bayesiana rispetto a una a priori uniforme? Fai riferimento a un esempio pratico.\nPerché in alcuni casi è preferibile lavorare con la log-verosimiglianza anziché con la verosimiglianza stessa? Spiega i vantaggi di questa trasformazione.\nQual è il significato del campionamento dalla distribuzione a posteriori e perché è utile in un’analisi bayesiana? Quali sono alcuni metodi alternativi per ottenere campioni dalla posterior quando il metodo della griglia non è praticabile?\nUtilizzando i dati della Satisfaction With Life Scale (SWLS) raccolti dagli studenti, costruisci un modello bayesiano per stimare la media della soddisfazione di vita. Segui questi passaggi:\n\n\n\nCarica i dati della SWLS e visualizza la distribuzione delle risposte.\n\n\nDefinisci una griglia di valori possibili per la media della soddisfazione di vita (ad esempio, da 1 a 7 se il punteggio della SWLS è su una scala Likert 1-7).\n\n\nAssumi che la deviazione standard sia nota (puoi stimarla dai dati o usare un valore ragionevole, come 1).\n\n\nCalcola la funzione di verosimiglianza per ogni valore della griglia assumendo una distribuzione normale.\n\n\nImposta una distribuzione a priori (uniforme o gaussiana centrata su un valore atteso, ad esempio 4).\n\n\nCalcola la distribuzione a posteriori e normalizzala.\n\n\nVisualizza la distribuzione a posteriori della media della soddisfazione di vita.\n\n\nEstrai campioni dalla distribuzione a posteriori e calcola un intervallo di credibilità al 94%.\n\nEsegui il codice in R e commenta i risultati ottenuti.\nConsegna: carica il file .qmd con le risposte, convertito in PDF, su Moodle.\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n\n\nIl metodo della griglia ha il vantaggio di essere intuitivo e facilmente implementabile, poiché calcola direttamente la distribuzione a posteriori valutando la funzione di verosimiglianza e il prior su una griglia di valori possibili per il parametro di interesse. Questo approccio permette una visualizzazione chiara della distribuzione a posteriori e facilita il confronto tra diversi prior.\nTuttavia, presenta alcune limitazioni:\n\n\nScalabilità: Diventa impraticabile quando il numero di parametri cresce, poiché il numero di combinazioni nella griglia aumenta esponenzialmente.\n\n\nRisoluzione: La precisione dell’inferenza dipende dalla densità della griglia, e una griglia troppo fine può essere computazionalmente costosa.\n\n\nDifficoltà per modelli complessi: Non è adatto per modelli con parametri ad alta dimensionalità o con distribuzioni a posteriori complesse.\n\n\n\nLa funzione di verosimiglianza rappresenta la probabilità di osservare i dati dati i valori del parametro di interesse. Nell’inferenza bayesiana, questa informazione viene combinata con la distribuzione a priori attraverso il teorema di Bayes, che permette di aggiornare la conoscenza pregressa con le nuove osservazioni.\nMatematicamente, la distribuzione a posteriori è data da:\n\\[\np(\\theta \\mid D) = \\frac{p(D \\mid \\theta) p(\\theta)}{p(D)}\n\\]\ndove:\n\n\n\\(p(D \\mid \\theta)\\) è la verosimiglianza, che misura quanto bene il parametro \\(\\theta\\) spiega i dati \\(D\\).\n\n\n\\(p(\\theta)\\) è il prior, che rappresenta la conoscenza iniziale sul parametro.\n\n\n\\(p(D)\\) è la costante di normalizzazione.\n\nL’aggiornamento bayesiano consente di affinare le stime dei parametri alla luce di nuove evidenze in modo sistematico e coerente.\n\n\nL’uso di un prior informativo consente di incorporare conoscenze pregresse nella stima dei parametri, riducendo l’incertezza quando i dati sono scarsi. Tuttavia, se il prior è troppo forte rispetto ai dati, potrebbe dominare la distribuzione a posteriori e introdurre un bias nelle stime.\nEsempio pratico: Supponiamo di voler stimare il QI medio di una popolazione sulla base di un piccolo campione. Se usiamo un prior informativo centrato su 140 con una deviazione standard di 3, la distribuzione a posteriori sarà fortemente influenzata da questa assunzione. Se invece utilizziamo un prior uniforme, i dati avranno un impatto maggiore sulla stima a posteriori.\nIn generale, i prior informativi sono utili quando abbiamo conoscenze affidabili da incorporare, mentre i prior non informativi sono preferibili quando vogliamo lasciare che i dati guidino l’inferenza.\n\n\nLavorare con la log-verosimiglianza presenta diversi vantaggi:\n\n\nStabilità numerica: La moltiplicazione di molte probabilità può portare a valori molto piccoli che causano underflow numerico. Usare il logaritmo trasforma i prodotti in somme, evitando questi problemi.\n\n\nEfficienza computazionale: Le somme sono più efficienti da calcolare rispetto ai prodotti, specialmente per modelli con molti dati.\n\n\nInterpretabilità: La log-verosimiglianza fornisce una misura più chiara della bontà di adattamento del modello, poiché la somma dei log-likelihood è direttamente proporzionale alla probabilità complessiva dei dati dato il parametro.\n\nPer questi motivi, la log-verosimiglianza è ampiamente usata in applicazioni statistiche e machine learning.\n\n\nIl campionamento dalla distribuzione a posteriori permette di ottenere stime dei parametri e di quantificare l’incertezza in modo efficace. Poiché la posterior rappresenta la nostra credenza aggiornata sul parametro dopo aver osservato i dati, il campionamento consente di generare simulazioni di possibili valori di \\(\\theta\\).\nUtilità del campionamento:\n\nPermette di calcolare intervalli di credibilità.\n\nConsente di effettuare inferenze basate sulla distribuzione completa, anziché su un singolo valore puntuale.\n\nÈ utile per simulare previsioni e testare ipotesi.\n\nMetodi alternativi per il campionamento dalla posterior:\n\n\nMetropolis-Hastings (MCMC): Un algoritmo di Markov Chain Monte Carlo che permette di esplorare distribuzioni complesse.\n\n\nGibbs Sampling: Un metodo MCMC particolarmente utile per modelli con più parametri condizionali noti.\n\n\nHamiltonian Monte Carlo (HMC): Utilizza gradienti per esplorare lo spazio dei parametri in modo efficiente, come implementato in Stan.\n\nQuando il metodo della griglia non è praticabile, questi metodi consentono di stimare la posterior in modo efficiente anche per modelli complessi e ad alta dimensionalità.\n\nEcco un codice in R che segue i passaggi richiesti.\n\n# Caricamento librerie necessarie\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tibble)\n\n# Dati SWLS\nswls_data &lt;- data.frame(\n  soddisfazione = c(4.2, 5.1, 4.7, 4.3, 5.5, 4.9, 4.8, 5.0, 4.6, 4.4)\n)\n\n# Usando la deviazione standard campionaria\nsigma_conosciuta &lt;- sd(swls_data$soddisfazione)  \nn &lt;- nrow(swls_data)\nmean_x &lt;- mean(swls_data$soddisfazione)\n\ncat(\"Deviazione standard campionaria:\", sigma_conosciuta, \"\\n\")\ncat(\"Media campionaria:\", mean_x, \"\\n\")\n\n# Definizione della griglia più fine e centrata intorno alla media campionaria\nmu_griglia &lt;- seq(mean_x - 3*sigma_conosciuta/sqrt(n), \n                 mean_x + 3*sigma_conosciuta/sqrt(n), \n                 length.out = 1000)\n\n# Calcolo della verosimiglianza\nlog_likelihood &lt;- numeric(length(mu_griglia))\nfor (i in seq_along(mu_griglia)) {\n  # Utilizzo della log-likelihood per evitare problemi numerici\n  log_likelihood[i] &lt;- sum(dnorm(swls_data$soddisfazione, \n                                mean = mu_griglia[i], \n                                sd = sigma_conosciuta, \n                                log = TRUE))\n}\n\n# Prior uniforme (in scala logaritmica)\nlog_prior &lt;- rep(0, length(mu_griglia))\n\n# Calcolo della posteriori\nlog_posterior &lt;- log_likelihood + log_prior\nposterior &lt;- exp(log_posterior - max(log_posterior))\nposterior &lt;- posterior / sum(posterior)\n\n# Campionamento e calcolo statistiche\nsamples_grid &lt;- sample(mu_griglia, size = 10000, replace = TRUE, prob = posterior)\nmean_post_grid &lt;- mean(samples_grid)\nsd_post_grid &lt;- sd(samples_grid)\nci_grid &lt;- quantile(samples_grid, c(0.03, 0.97))\n\nresults &lt;- tibble(\n  `Media Posteriori` = c(mean_post_grid),\n  `Dev. Std. Posteriori` = c(sd_post_grid)\n)\n\n# Visualizzazione risultati\nprint(results)\n\n# Plot della distribuzione a posteriori per entrambi i metodi\nggplot() +\n  geom_line(data = data.frame(mu = mu_griglia, density = posterior),\n            aes(x = mu, y = density, color = \"Griglia\")) +\n  labs(title = \"Distribuzione a Posteriori\",\n       x = \"Media\", y = \"Densità\")\n  \n# Stampa intervallo di credibilità al 94%\ncat(\"\\nIntervallo di credibilità al 94% (metodo griglia):\\n\")\nprint(ci_grid)\nConclusione:\nIl modello bayesiano ci fornisce una stima della media della soddisfazione di vita con un intervallo di credibilità, quantificando l’incertezza in modo rigoroso.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_grid_gauss.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/06_grid_gauss.html#informazioni-sullambiente-di-sviluppo",
    "title": "50  Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] reshape2_1.4.4   thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0\n#&gt;  [5] see_0.11.0       gridExtra_2.3    patchwork_1.3.0  bayesplot_1.12.0\n#&gt;  [9] psych_2.5.3      scales_1.4.0     markdown_2.0     knitr_1.50      \n#&gt; [13] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [17] purrr_1.0.4      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [21] ggplot2_3.5.2    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.4     stringi_1.8.7      lattice_0.22-7    \n#&gt;  [4] hms_1.1.3          digest_0.6.37      magrittr_2.0.3    \n#&gt;  [7] evaluate_1.0.3     grid_4.5.0         timechange_0.3.0  \n#&gt; [10] RColorBrewer_1.1-3 fastmap_1.2.0      plyr_1.8.9        \n#&gt; [13] rprojroot_2.0.4    jsonlite_2.0.0     viridisLite_0.4.2 \n#&gt; [16] mnormt_2.1.1       cli_3.6.5          rlang_1.1.6       \n#&gt; [19] withr_3.0.2        tools_4.5.0        parallel_4.5.0    \n#&gt; [22] tzdb_0.5.0         pacman_0.5.1       vctrs_0.6.5       \n#&gt; [25] R6_2.6.1           lifecycle_1.0.4    htmlwidgets_1.6.4 \n#&gt; [28] pkgconfig_2.0.3    pillar_1.10.2      gtable_0.3.6      \n#&gt; [31] Rcpp_1.0.14        glue_1.8.0         xfun_0.52         \n#&gt; [34] tidyselect_1.2.1   rstudioapi_0.17.1  farver_2.1.2      \n#&gt; [37] htmltools_0.5.8.1  nlme_3.1-168       labeling_0.4.3    \n#&gt; [40] rmarkdown_2.29     compiler_4.5.0",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_grid_gauss.html#bibliografia",
    "href": "chapters/bayesian_inference/06_grid_gauss.html#bibliografia",
    "title": "50  Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Calcolo della distribuzione a posteriori gaussiana tramite metodo a griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_conjugate_families_1.html",
    "href": "chapters/bayesian_inference/07_conjugate_families_1.html",
    "title": "51  Distribuzioni coniugate (1)",
    "section": "",
    "text": "51.1 Introduzione\nIn questo capitolo, esploriamo il concetto di distribuzioni a priori coniugate e il loro ruolo nell’inferenza bayesiana. Utilizzando il modello beta-binomiale come esempio paradigmatico, dimostreremo come queste distribuzioni semplifichino l’analisi attraverso calcoli analitici diretti. L’uso di una distribuzione a priori coniugata non solo rende l’inferenza più agevole, ma fornisce anche una chiara visione del modo in cui le credenze a priori influenzano le conclusioni.\nPer favorire la comprensione, procederemo in tre fasi principali:",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_conjugate_families_1.html#introduzione",
    "href": "chapters/bayesian_inference/07_conjugate_families_1.html#introduzione",
    "title": "51  Distribuzioni coniugate (1)",
    "section": "",
    "text": "Introduzione del modello beta-binomiale.\nAnalisi della distribuzione Beta e del suo ruolo come distribuzione a priori.\nDescrizione del processo di aggiornamento bayesiano e dei vantaggi derivanti dall’uso di distribuzioni coniugate.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_conjugate_families_1.html#il-modello-beta-binomiale",
    "href": "chapters/bayesian_inference/07_conjugate_families_1.html#il-modello-beta-binomiale",
    "title": "51  Distribuzioni coniugate (1)",
    "section": "\n51.2 Il Modello Beta-Binomiale",
    "text": "51.2 Il Modello Beta-Binomiale\nIl modello beta-binomiale è un esempio classico per analizzare una proporzione \\(\\theta\\), ossia la probabilità di successo in una sequenza di prove binarie (ad esempio, successo/fallimento). Supponiamo di osservare \\(y\\) successi su \\(n\\) prove, dove ogni prova è indipendente e con la stessa probabilità di successo \\(\\theta\\), che appartiene all’intervallo \\([0,1]\\).\nLa funzione di verosimiglianza, basata sulla distribuzione binomiale, è espressa come:\n\\[\n\\mathcal{Binomial}(y \\mid n, \\theta) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n - y},\n\\]\ndove \\(\\binom{n}{y}\\) è il coefficiente binomiale che conta il numero di modi in cui \\(y\\) successi possono verificarsi in \\(n\\) prove.\nPer modellare la nostra conoscenza preliminare su \\(\\theta\\), scegliamo una distribuzione a priori Beta, che rappresenta un’ampia gamma di credenze iniziali con parametri flessibili.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_conjugate_families_1.html#la-distribuzione-beta",
    "href": "chapters/bayesian_inference/07_conjugate_families_1.html#la-distribuzione-beta",
    "title": "51  Distribuzioni coniugate (1)",
    "section": "\n51.3 La Distribuzione Beta",
    "text": "51.3 La Distribuzione Beta\nLa distribuzione Beta è definita come:\n\\[\n\\mathcal{Beta}(\\theta \\mid \\alpha, \\beta) = \\frac{1}{B(\\alpha, \\beta)} \\theta^{\\alpha - 1} (1 - \\theta)^{\\beta - 1}, \\quad \\text{con } \\theta \\in (0, 1),\n\\]\ndove:\n\n\\(\\alpha &gt; 0\\) e \\(\\beta &gt; 0\\) sono i iperparametri, che determinano la forma della distribuzione.\n\n\\(B(\\alpha, \\beta)\\) è la funzione Beta di Eulero, calcolata come:\n\\[\n  B(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)},\n  \\]\ndove \\(\\Gamma(x)\\) è la funzione Gamma, una generalizzazione del fattoriale.\n\n\nNel contesto bayesiano:\n\n\n\\(\\alpha -1\\) rappresenta il numero ipotetico di “successi” a priori.\n\n\\(\\beta -1\\) rappresenta il numero ipotetico di “fallimenti” a priori.\n\nAd esempio:\n\nuna distribuzione Beta(1, 1) è uniforme (0 successi a priori e 0 fallimenti), indicando totale incertezza iniziale (assenza di credenze informate);\nuna distribuzione Beta(10, 20) rappresenta una conoscenza a priori basata su 9 successi e 19 fallimenti ipotizzati, indicando una convinzione iniziale relativamente solida, poiché deriva da un totale di 28 osservazioni virtuali che riflettono le credenze precedenti.\n\nQuesta interpretazione consente di calibrare le credenze a priori in base all’evidenza disponibile o alla fiducia nella stima.\nLa distribuzione Beta è estremamente versatile:\n\nvalori diversi di \\(\\alpha\\) e \\(\\beta\\) producono distribuzioni simmetriche, asimmetriche o uniformi;\nvalori elevati di \\(\\alpha\\) e \\(\\beta\\) riducono la varianza, riflettendo credenze più forti.\n\nQuesta flessibilità rende la distribuzione Beta una scelta ideale per rappresentare credenze iniziali su proporzioni.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_conjugate_families_1.html#aggiornamento-bayesiano",
    "href": "chapters/bayesian_inference/07_conjugate_families_1.html#aggiornamento-bayesiano",
    "title": "51  Distribuzioni coniugate (1)",
    "section": "\n51.4 Aggiornamento Bayesiano",
    "text": "51.4 Aggiornamento Bayesiano\nL’aggiornamento bayesiano combina le informazioni iniziali (priori) con i dati osservati (verosimiglianza) per produrre una nuova distribuzione delle credenze (posteriori). Nel caso del modello beta-binomiale, questo processo è particolarmente semplice grazie alla “coniugazione”: il prior Beta e la verosimiglianza Binomiale producono una distribuzione a posteriori che appartiene ancora alla famiglia Beta.\n\nTeorema 51.1 (Teorema) Sia \\(Y\\sim\\mathrm{Binomial}(n,\\theta)\\) il numero di successi \\(y\\) in \\(n\\) prove indipendenti con probabilità di successo \\(\\theta\\), e sia la nostra distribuzione a priori su \\(\\theta\\) una Beta\\(\\bigl(\\alpha,\\beta\\bigr).\\) Allora la distribuzione a posteriori di \\(\\theta\\) dato l’osservazione \\(Y=y\\) è\n\\[\n\\theta \\mid Y=y\n\\;\\sim\\;\n\\mathrm{Beta}\\bigl(\\alpha + y,\\;\\beta + (n - y)\\bigr),\n\\]\novvero i parametri si aggiornano come\n\\[\n\\alpha' = \\alpha + y,\n\\quad\n\\beta' = \\beta + n - y.\n\\]\n\n\n51.4.1 Dimostrazione\n1. Formula di Bayes (forma proporzionale).\nLa densità a posteriori si ottiene, a meno di una costante di normalizzazione, moltiplicando prior e verosimiglianza:\n\\[\np(\\theta\\mid y)\n\\;\\propto\\;\np(y\\mid\\theta)\\;\\times\\;p(\\theta).\n\\]\nIgnoriamo per ora i fattori che non dipendono da \\(\\theta\\).\n2. Verosimiglianza binomiale.\nLa probabilità di osservare \\(y\\) successi in \\(n\\) prove è\n\\[\np(y\\mid\\theta)\n=\\binom ny\\,\\theta^y\\,(1-\\theta)^{\\,n-y}.\n\\]\nPoiché \\(\\binom ny\\) non dipende da \\(\\theta\\), terremo solo\n\\[\np(y\\mid\\theta)\\;\\propto\\;\\theta^y\\,(1-\\theta)^{\\,n-y}.\n\\]\n3. Prior Beta.\nLa densità del prior è\n\\[\np(\\theta)\n=\\frac{1}{B(\\alpha,\\beta)}\\,\n\\theta^{\\,\\alpha-1}\\,(1-\\theta)^{\\,\\beta-1},\n\\]\ne quindi, a meno della costante \\(B(\\alpha,\\beta)\\),\n\\[\np(\\theta)\\;\\propto\\;\\theta^{\\,\\alpha-1}\\,(1-\\theta)^{\\,\\beta-1}.\n\\]\n4. Prodotto prior × verosimiglianza.\nMoltiplichiamo le due parti dipendenti da \\(\\theta\\):\n\\[\np(\\theta\\mid y)\n\\;\\propto\\;\n\\bigl[\\theta^y\\,(1-\\theta)^{\\,n-y}\\bigr]\\;\n\\bigl[\\theta^{\\,\\alpha-1}\\,(1-\\theta)^{\\,\\beta-1}\\bigr]\n=\n\\theta^{\\,(\\alpha-1)+y}\\;\\bigl(1-\\theta\\bigr)^{\\,(\\beta-1)+(n-y)}.\n\\]\n5. Riconoscere la forma Beta.\nUna Beta\\((a,b)\\) ha densità proporzionale a\n\\[\n\\theta^{\\,a-1}\\,(1-\\theta)^{\\,b-1}.\n\\]\nConfrontando esponenti:\n\n\nSull’esponenziale di \\(\\theta\\):\n\\[\n  (\\alpha-1)+y \\;=\\;(a-1)\n  \\quad\\Longrightarrow\\quad\n  a \\;=\\;\\alpha+y.\n\\]\n\n\nSull’esponenziale di \\((1-\\theta)\\):\n\\[\n  (\\beta-1)+(n-y) \\;=\\;(b-1)\n  \\quad\\Longrightarrow\\quad\n  b \\;=\\;\\beta+(n-y).\n\\]\n\n\nNe segue che\n\\[\np(\\theta\\mid y)\n\\;\\propto\\;\\theta^{\\,(\\alpha+y)-1}\\,(1-\\theta)^{\\,(\\beta+n-y)-1},\n\\]\ncioè\n\\[\n\\boxed{\n\\theta\\mid Y=y \\;\\sim\\;\\mathrm{Beta}\\bigl(\\alpha+y,\\;\\beta+n-y\\bigr).\n}\n\\]\n\n51.4.2 Proprietà del posterior\n\nMedia a posteriori\n\n\\[\n\\mathbb{E}[\\theta\\mid y]\n    = \\frac{\\alpha+y}{\\alpha+\\beta+n}.\n\\]\n\nVarianza a posteriori\n\n\\[\n\\mathrm{Var}[\\theta\\mid y]\n    = \\frac{(\\alpha+y)\\,(\\beta+n-y)}{\\bigl(\\alpha+\\beta+n\\bigr)^2\\,(\\alpha+\\beta+n+1)}.\n\\]\n\n51.4.3 Vantaggi del Modello Beta-Binomiale\n\n\nSemplicità analitica: La coniugatezza della distribuzione Beta-Binomiale semplifica i calcoli, rendendo immediato l’aggiornamento dei parametri.\n\nInterpretazione intuitiva: L’aggiornamento dei parametri \\(\\alpha\\) e \\(\\beta\\) mostra in modo trasparente come i dati influenzino le credenze.\n\nIn sintesi, il modello Beta-Binomiale è un esempio didattico fondamentale per comprendere l’inferenza bayesiana e rappresenta un punto di partenza ideale per approcci più avanzati.\n\nEsempio 51.1 Nel Capitolo 49 abbiamo utilizzato il metodo basato su griglia per determinare la distribuzione a posteriori nel caso di \\(y = 6\\) successi su \\(n = 9\\) prove (vedi anche McElreath, 2020 per una discussione dettagliata). Ora esploriamo un approccio alternativo, sfruttando le proprietà delle famiglie coniugate.\nLa verosimiglianza binomiale per questo esperimento è espressa dalla seguente funzione:\n\\[\n\\mathcal{L}(\\theta) \\propto \\theta^y (1-\\theta)^{n-y},\n\\]\ndove \\(y = 6\\) rappresenta il numero di successi e \\(n = 9\\) il numero totale di prove.\nScegliendo una distribuzione a priori Beta con parametri \\(\\alpha = 2\\) e \\(\\beta = 5\\), possiamo applicare il teorema di Bayes per calcolare i parametri aggiornati della distribuzione a posteriori. In base alla regola di aggiornamento per distribuzioni coniugate, otteniamo:\n\\[\n\\alpha' = \\alpha + y = 2 + 6 = 8.\n\\] \\[\n\\beta' = \\beta + n - y = 5 + 9 - 6 = 8.\n\\]\nLa distribuzione a posteriori risultante è quindi una distribuzione Beta con parametri \\(\\mathcal{Beta}(8, 8)\\).\nProcediamo ora a visualizzare le tre distribuzioni rilevanti:\n\n\nDistribuzione a priori: \\(\\mathcal{Beta}(2, 2)\\),\n\nVerosimiglianza binomiale: per \\(y = 6\\) e \\(n = 9\\),\n\nDistribuzione a posteriori: \\(\\text{Beta}(8, 5)\\).\n\nEcco il codice R per generare il grafico comparativo:\n\n# Definizione dei parametri\nalpha_prior &lt;- 2\nbeta_prior &lt;- 5\ny &lt;- 6\nn &lt;- 9\n\n# Parametri della distribuzione a posteriori\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + n - y\n\n# Sequenza di valori di theta\ntheta &lt;- seq(0, 1, length.out = 1000)\n\n# Calcolo delle PDF\nprior_pdf &lt;- dbeta(theta, shape1 = alpha_prior, shape2 = beta_prior)\nlikelihood &lt;- theta^y * (1 - theta)^(n - y)\n\n# Normalizzazione della verosimiglianza\nlikelihood_integral &lt;- sum(likelihood) * (theta[2] - theta[1])\nnormalized_likelihood &lt;- likelihood / likelihood_integral\n\nposterior_pdf &lt;- dbeta(theta, shape1 = alpha_post, shape2 = beta_post)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  theta = rep(theta, 3),\n  densita = c(prior_pdf, normalized_likelihood, posterior_pdf),\n  distribuzione = rep(c(\"Prior\", \"Likelihood\", \"Posterior\"), each = length(theta))\n)\n\n# Creare il grafico \nggplot(df, aes(x = theta, y = densita, color = distribuzione)) +\n  geom_line(size = 1) +  # Aggiungere le linee per le distribuzioni\n  scale_color_manual(values = c(\"Prior\" = \"blue\", \"Likelihood\" = \"green\", \"Posterior\" = \"red\")) +  # Assegnare i colori\n  labs(title = \"Distribuzioni Prior, Likelihood e Posterior\",\n       x = expression(theta),\n       y = \"Densità\",\n       color = \"Distribuzione\") +  # Aggiungere titoli e label\n  theme(legend.position = \"top\")  # Posizionare la legenda in alto\n\n\n\n\n\n\n\n\n\nCurva blu: Prior \\(\\mathcal{Beta}(2, 5)\\), che riflette le credenze iniziali prima dell’osservazione dei dati.\n\n\nCurva verde: Likelihood (normalizzata), rappresenta l’evidenza fornita dai dati osservati.\n\n\nCurva rossa: Posterior \\(\\mathcal{Beta}(8, 8)\\), risultato dell’aggiornamento bayesiano che combina prior e likelihood.\n\nNota sulla normalizzazione della verosimiglianza. La verosimiglianza binomiale non è una distribuzione di probabilità (il suo integrale non è pari a 1). Per rappresentarla visivamente accanto alla distribuzione a priori e a quella a posteriori, è necessario normalizzarla. Questo è fatto calcolando il suo integrale su \\(\\theta \\in [0, 1]\\) e dividendo la funzione per il risultato. La normalizzazione serve solo per la visualizzazione e non influisce sui calcoli analitici.\n\n\nEsempio 51.2 Esaminiamo ora un esempio discuso da Johnson et al. (2022). In uno studio molto famoso, Stanley Milgram ha studiato la propensione delle persone a obbedire agli ordini delle figure di autorità, anche quando tali ordini potrebbero danneggiare altre persone (Milgram 1963). Nell’articolo, Milgram descrive lo studio come\n\nconsistente nell’ordinare a un soggetto ingenuo di somministrare una scossa elettrica a una vittima. Viene utilizzato un generatore di scosse simulato, con 30 livelli di tensione chiaramente contrassegnati che vanno da IS a 450 volt. Lo strumento porta delle designazioni verbali che vanno da Scossa Lieve a Pericolo: Scossa Grave. Le risposte della vittima, che è un complice addestrato dell’esperimentatore, sono standardizzate. Gli ordini di somministrare scosse vengono dati al soggetto ingenuo nel contesto di un ‘esperimento di apprendimento’ apparentemente organizzato per studiare gli effetti della punizione sulla memoria. Man mano che l’esperimento procede, al soggetto ingenuo viene ordinato di somministrare scosse sempre più intense alla vittima, fino al punto di raggiungere il livello contrassegnato Pericolo: Scossa Grave.\n\nIn altre parole, ai partecipanti allo studio veniva dato il compito di testare un altro partecipante (che in realtà era un attore addestrato) sulla loro capacità di memorizzare una serie di item. Se l’attore non ricordava un item, al partecipante veniva ordinato di somministrare una scossa all’attore e di aumentare il livello della scossa con ogni fallimento successivo. I partecipanti non erano consapevoli del fatto che le scosse fossero finte e che l’attore stesse solo fingendo di provare dolore dalla scossa.\nNello studio di Milgram, 26 partecipanti su 40 hanno somministrato scosse al livello “Pericolo: Scossa Grave”. Il problema richiede di costruire la distribuzione a posteriori della probabilità \\(\\theta\\) di infliggere una scossa a l livello “Pericolo: Scossa Grave”, ipotizzando che uno studio precedente aveva stabilito che \\(\\theta\\) segue una distribuzione Beta(1, 10).\nIniziamo a fornire una rappresentazione grafica della distribuzione a priori.\n\n# Impostazione dei parametri della distribuzione Beta\nalpha &lt;- 1\nbeta_val &lt;- 10\n\n# Creazione di valori x per il plot\nx_values &lt;- seq(0, 1, length.out = 1000)\n\n# Calcolo della densità di probabilità per ogni valore di x\nbeta_pdf &lt;- dbeta(x_values, shape1 = alpha, shape2 = beta_val)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  x = x_values,\n  densita = beta_pdf\n)\n\n# Creare il grafico\nggplot(df, aes(x = x, y = densita)) +\n  geom_line(color = \"#b97c7c\", size = 1) +  # Aggiungere la linea per la densità\n  labs(title = \"Distribuzione Beta(1, 10)\",  # Aggiungere il titolo\n       x = \"x\",  # Label dell'asse x\n       y = \"Densità di probabilità\") +  # Label dell'asse y\n  theme(plot.title = element_text(hjust = 0.5)) +  # Centrare il titolo\n  geom_vline(xintercept = 0, color = \"black\", linetype = \"dashed\", size = 0.5) +  # Linea verticale opzionale\n  geom_vline(xintercept = 1, color = \"black\", linetype = \"dashed\", size = 0.5) +  # Linea verticale opzionale\n  annotate(\"text\", x = 0.8, y = max(beta_pdf) * 0.9, label = \"Beta(1, 10)\", color = \"#b97c7c\", size = 5)  # Aggiungere una legenda\n\n\n\n\n\n\n\nLa distribuzione a posteriori segue una distribuzione Beta con parametri aggiornati:\n\ny &lt;- 26\nn &lt;- 40\n\nalpha_prior &lt;- 1\nbeta_prior &lt;- 10\n\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + n - y\n\nalpha_post\n#&gt; [1] 27\nbeta_post\n#&gt; [1] 24\n\nCreazione di un grafico per la distribuzione a posteriori:\n\n# Creazione di valori x per il plot\nx_values &lt;- seq(0, 1, length.out = 1000)\n\n# Calcolo della densità di probabilità per ogni valore di x\nbeta_pdf &lt;- dbeta(x_values, alpha_post, beta_post)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  theta = x_values,\n  densita = beta_pdf\n)\n\n# Creare il grafico con ggplot2\nggplot(df, aes(x = theta, y = densita)) +\n  geom_line(color = \"blue\", size = 1) +  # Aggiungere la linea per la densità\n  labs(title = \"Distribuzione Beta(27, 24)\",  # Aggiungere il titolo\n       x = expression(theta),  # Label dell'asse x usando espressioni matematiche\n       y = \"Densità di probabilità\") +  # Label dell'asse y\n  theme(plot.title = element_text(hjust = 0.5)) +  # Centrare il titolo\n  annotate(\"text\", x = 0.8, y = max(beta_pdf) * 0.9, label = \"Beta(27, 24)\", color = \"blue\", size = 5)  \n\n\n\n\n\n\n\nCalcolo della media a posteriori di \\(\\theta\\):\n\nalpha_post / (alpha_post + beta_post)\n#&gt; [1] 0.5294\n\nCalcolo della moda a posteriori:\n\n(alpha_post - 1) / (alpha_post + beta_post - 2)\n#&gt; [1] 0.5306\n\nCalcolo della probabilità che \\(\\theta &gt; 0.6\\):\n\npbeta(0.6, alpha_post, beta_post, lower.tail = FALSE)\n#&gt; [1] 0.1562\n\nOvvero:\n\n1 - pbeta(0.6, alpha_post, beta_post)\n#&gt; [1] 0.1562\n\nEseguiamo il problema utilizzando il metodo basato su griglia. Definiamo la griglia di interesse:\n\ntheta &lt;- seq(0, 1, length.out = 100)\n\nCreiamo la distribuzione a priori:\n\nprior &lt;- dbeta(theta, alpha_prior, beta_prior)\n\n# Normalizzazione della densità per ottenere una somma pari a 1\nprior_normalized &lt;- prior / sum(prior)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  theta = theta,\n  probabilita = prior_normalized\n)\n\n# Creare il grafico con ggplot2\nggplot(df, aes(x = theta, y = probabilita)) +\n  geom_segment(aes(x = theta, xend = theta, y = 0, yend = probabilita), \n               color = \"blue\", size = 1) +  # Linee verticali per rappresentare le probabilità\n  labs(title = \"Distribuzione a priori\",  # Aggiungere il titolo\n       x = expression(theta),  # Label dell'asse x usando espressioni matematiche\n       y = \"Probabilità\") +  # Label dell'asse y\n  theme(plot.title = element_text(hjust = 0.5))  # Centrare il titolo\n\n\n\n\n\n\n\nCreiamo la verosimiglianza:\n\nlk &lt;- dbinom(y, n, theta)\n\n# Normalizzazione della verosimiglianza per ottenere una somma pari a 1\nlk_normalized &lt;- lk / sum(lk)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  theta = theta,\n  probabilita = lk_normalized\n)\n\n# Creare il grafico con ggplot2\nggplot(df, aes(x = theta, y = probabilita)) +\n  geom_segment(aes(x = theta, xend = theta, y = 0, yend = probabilita), \n               color = \"red\", size = 1) +  # Linee verticali per rappresentare la verosimiglianza\n  labs(title = \"Verosimiglianza\",  # Aggiungere il titolo\n       x = expression(theta),  # Label dell'asse x usando espressioni matematiche\n       y = \"Probabilità\") +  # Label dell'asse y\n  theme(plot.title = element_text(hjust = 0.5))  # Centrare il titolo\n\n\n\n\n\n\n\nCalcoliamo la distribuzione a posteriori:\n\npost &lt;- (prior * lk) / sum(prior * lk)\n\n# Normalizzazione della verosimiglianza per ottenere una somma pari a 1\nlk_normalized &lt;- lk / sum(lk)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  theta = theta,\n  probabilita = lk_normalized\n)\n\n# Creare il grafico con ggplot2\nggplot(df, aes(x = theta, y = probabilita)) +\n  geom_segment(aes(x = theta, xend = theta, y = 0, yend = probabilita), \n               color = \"green\", size = 1) +  # Linee verticali per rappresentare la verosimiglianza\n  labs(title = \"Distribuzione a posteriori\",  # Aggiungere il titolo\n       x = expression(theta),  # Label dell'asse x usando espressioni matematiche\n       y = \"Probabilità\") +  # Label dell'asse y\n  theme(plot.title = element_text(hjust = 0.5))  # Centrare il titolo\n\n\n\n\n\n\n\nEstrazione di un campione dalla distribuzione a posteriori:\n\nsamples &lt;- sample(theta, size = 1e6, replace = TRUE, prob = post)\n\nTroviamo la media a posteriori:\n\nmean(samples)\n#&gt; [1] 0.5295\n\nCalcoliamo la probabilità che \\(\\theta &gt; 0.6\\):\n\nmean(samples &gt; 0.6)\n#&gt; [1] 0.1527\n\nQuesto codice mantiene la struttura logica del problema e produce risultati equivalenti utilizzando R.\n\n\nEsempio 51.3 Consideriamo un esempio discusso da Nalborczyk (2018) nel quale, oltre all’applicazione del teorema beta-binimiale, viene anche introdotto il concetto di posterior-predictive check.\nSupponiamo di reclutare partecipanti per uno studio di mezza ora:\n\nPossiamo farlo fra le 9:00 e le 18:00, con sessioni ogni 30 minuti.\n\nIn una settimana lavorativa (lun–ven) otteniamo \\(n = 90\\) time slot.\n\nAd ogni slot, il partecipante o si presenta (\\(1\\)) o manca (\\(0\\)).\n\nVogliamo stimare la probabilità media di presenza, che chiameremo \\(\\theta\\).\nModello\n\\[\n\\begin{cases}\n    Y \\mid \\theta \\;\\sim\\;\\mathrm{Binomial}(n,\\theta),\\\\[6pt]\n    \\theta \\;\\sim\\;\\mathrm{Beta}(\\alpha,\\beta).\n    \\end{cases}\n\\]\nScelta del prior.\n\nConoscenze pregresse suggeriscono che \\(\\theta\\) sia intorno a 0.5.\n\nScegliamo quindi un prior \\(\\;\\mathrm{Beta}(2,2)\\), che ha media \\(0.5\\) e riflette incertezza moderata.\n\nDati osservati.\n\n# vettore di 0/1 con n = 90 osservazioni\ny &lt;- c(\n  0,0,0,1,1,1,0,0,0,1,1,1,1,1,1,1,0,0,\n  0,1,0,1,1,1,0,0,1,1,1,1,1,1,1,0,0,1,\n  1,0,0,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,\n  1,0,0,1,1,1,0,1,1,1,1,1,1,0,0,0,0,1,\n  0,1,0,1,1,1,0,0,0,0,0,1,1,1,1,1,1,0\n)\n\nCalcoliamo\n\nn &lt;- length(y)  # numero di slot = 90\nz &lt;- sum(y)     # numero di presenze = numero di 1\n\nPosterior Beta–Binomiale.\nI parametri aggiornati sono\n\\[\n\\alpha_{post} = \\alpha + z,\n\\quad\n\\beta_{post} = \\beta + (n - z).\n\\]\nIn particolare, con \\(\\alpha=\\beta=2\\):\n\na &lt;- b &lt;- 2\na_post &lt;- a + z\nb_post &lt;- b + (n - z)\n\nIl posterior è quindi\n\\[\n\\theta\\mid y \\;\\sim\\;\\mathrm{Beta}(a+z,\\;b+n-z).\n\\]\nVisualizzazione di prior e posterior.\n\n# griglia per theta\ngrid &lt;- seq(0, 1, length.out = 1000)\n\n# densità\nprior     &lt;- dbeta(grid, a,      b)\nposterior &lt;- dbeta(grid, a_post, b_post)\n\ndf &lt;- data.frame(theta = grid,\n                 prior = prior,\n                 posterior = posterior)\n\nggplot(df) +\n  geom_area(aes(x = theta, y = prior,\n                fill = \"Prior\", colour = \"Prior\"),\n            alpha = 0.5, size = 1) +\n  geom_area(aes(x = theta, y = posterior,\n                fill = \"Posterior\", colour = \"Posterior\"),\n            alpha = 0.5, size = 1) +\n  scale_fill_grey(name = \"\") +\n  scale_colour_grey(name = \"\") +\n  theme_bw(base_size = 12) +\n  xlab(expression(theta)) +\n  ylab(\"\") +\n  ggtitle(\"Densità Prior e Posterior\\nmodello Beta–Binomiale\")\n\n\n\n\n\n\n\nIntroduzione ai posterior predictive checks.\nIl modello assume indipendenza fra i time slot. Se questa assunzione è violata (ad es. presenza autocorrelata nel tempo), le nostre stime potrebbero essere fuorvianti.\nIdea:\n\nSimulare \\(\\theta\\) dal posterior.\n\nDato ciascun \\(\\theta\\), generare una nuova serie \\(y^{rep}\\) da\\(\\mathrm{Binomial}(n,\\theta)\\).\n\nCalcolare su ogni \\(y^{rep}\\) una test-quantità \\(T(y^{rep})\\).\n\nConfrontare la distribuzione di \\(T(y^{rep})\\) con il valore osservato \\(T(y)\\).\n\nSe \\(T(y)\\) è un outlier rispetto ai \\(T(y^{rep})\\), l’assunzione di indipendenza è sospetta.\nTest‐quantità: numero di “switch”.\nDefiniamo una funzione che conta quante volte la serie passa da 0→1 o da 1→0:\n\ncount_switches &lt;- function(x) {\n  sum(abs(diff(x)) == 1)\n}\n\n# valore osservato\nTy &lt;- count_switches(y)\ncat(\"Switch osservati:\", Ty, \"\\n\")\n#&gt; Switch osservati: 28\n\nSimulazione e istogramma.\n\nset.seed(123)      # per riproducibilità\nnsims &lt;- 10000     # numero di repliche\n\nsim_switches &lt;- replicate(nsims, {\n  # 1) estrai un theta dal posterior\n  theta_sim &lt;- rbeta(1, a_post, b_post)\n  # 2) genera y^rep ~ Bernoulli(theta_sim)\n  y_sim     &lt;- rbinom(n, size = 1, prob = theta_sim)\n  # 3) conta gli switch\n  count_switches(y_sim)\n})\n\n# Istogramma\nhist(sim_switches,\n     breaks = 30,\n     col    = \"lightgrey\",\n     main   = \"Distribuzione Posterior Predictive\\ndel numero di switch\",\n     xlab   = \"Numero di switch\",\n     ylab   = \"Frequenza\")\nabline(v = Ty, col = \"darkgreen\", lty = 2, lwd = 2)\n\n\n\n\n\n\n\nBayesian p‐value.\nCalcoliamo la probabilità di ottenere un numero di switch ≤ di quello osservato:\n\np_value &lt;- mean(sim_switches &lt;= Ty)\ncat(\"Bayesian p-value:\", round(p_value, 4), \"\\n\")\n#&gt; Bayesian p-value: 0.0073\n\n\nUn valore molto basso (es. \\(&lt;0.05\\)) indica che \\(T(y)\\) è sorprendente rispetto alle predizioni del modello.\n\nQui: se \\(p\\approx 0.01\\), la bassa variabilità di switch suggerisce dipendenza fra le osservazioni.\n\nInterpretazione.\n\n\nUn modello non è “giusto” o “sbagliato”, ma deve descrivere bene il processo che genera i dati.\n\nIl nostro check mostra che il numero di switch osservato è molto minore di quanto ci aspetteremmo sotto l’ipotesi di indipendenza.\n\nCon tutta probabilità c’è autocorrelazione temporale (le presenze dipendono dall’ora del giorno).\n\nPer tenerne conto, si potrebbero usare modelli più avanzati (es. processi gaussiani).\n\nIn sintesi, il posterior predictive checking ci offre un modo flessibile per diagnosticare diverse violazioni del modello, scegliendo test‐quantities adatte (media, varianza, max, autocorrelazione, …). Come scrivono Gelman et al. (2013), “i p-valori posteriori … possono essere calcolati per varie test-quantities per valutare più modi in cui un modello può fallire”.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_conjugate_families_1.html#principali-distribuzioni-coniugate",
    "href": "chapters/bayesian_inference/07_conjugate_families_1.html#principali-distribuzioni-coniugate",
    "title": "51  Distribuzioni coniugate (1)",
    "section": "\n51.5 Principali distribuzioni coniugate",
    "text": "51.5 Principali distribuzioni coniugate\nEsistono altre combinazioni di verosimiglianza e distribuzione a priori che producono una distribuzione a posteriori con la stessa forma della distribuzione a priori. Ecco alcune delle più note coniugazioni tra modelli statistici e distribuzioni a priori:\n\nNel modello Normale-Normale \\(\\mathcal{N}(\\mu, \\sigma^2_0)\\), la distribuzione a priori è \\(\\mathcal{N}(\\mu_0, \\tau^2)\\) e la distribuzione a posteriori è \\(\\mathcal{N}\\left(\\frac{\\mu_0\\sigma^2 + \\bar{y}n\\tau^2}{\\sigma^2 + n\\tau^2}, \\frac{\\sigma^2\\tau^2}{\\sigma^2 + n\\tau^2} \\right)\\).\nNel modello Poisson-gamma \\(\\text{Po}(\\theta)\\), la distribuzione a priori è \\(\\Gamma(\\lambda, \\delta)\\) e la distribuzione a posteriori è \\(\\Gamma(\\lambda + n \\bar{y}, \\delta +n)\\).\nNel modello esponenziale \\(\\text{Exp}(\\theta)\\), la distribuzione a priori è \\(\\Gamma(\\lambda, \\delta)\\) e la distribuzione a posteriori è \\(\\Gamma(\\lambda + n, \\delta +n\\bar{y})\\).\nNel modello uniforme-Pareto \\(\\text{U}(0, \\theta)\\), la distribuzione a priori è \\(\\text{Pa}(\\alpha, \\varepsilon)\\) e la distribuzione a posteriori è \\(\\text{Pa}(\\alpha + n, \\max(y_{(n)}, \\varepsilon))\\).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_conjugate_families_1.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/07_conjugate_families_1.html#riflessioni-conclusive",
    "title": "51  Distribuzioni coniugate (1)",
    "section": "\n51.6 Riflessioni Conclusive",
    "text": "51.6 Riflessioni Conclusive\nIn conclusione, l’utilizzo di priori coniugati presenta vantaggi e svantaggi. Cominciamo con i vantaggi principali. Il principale vantaggio dell’adozione di distribuzioni a priori coniugate risiede nella loro capacità di rendere l’analisi della distribuzione a posteriori trattabile da un punto di vista analitico. Ad esempio, nel corso di questo capitolo abbiamo esaminato come sia possibile formulare la distribuzione a posteriori in seguito a un esperimento composto da una serie di prove di Bernoulli (con una verosimiglianza binomiale), utilizzando una distribuzione Beta sia per la prior che per il posteriore.\nTuttavia, è cruciale riconoscere che i modelli basati sul concetto di famiglie coniugate presentano delle limitazioni intrinseche. Le distribuzioni coniugate a priori sono disponibili solamente per distribuzioni di verosimiglianza di base e relativamente semplici. Per modelli complessi e più realistici, la ricerca di priori coniugati diventa spesso un compito estremamente arduo, limitando quindi la loro utilità. Inoltre, anche quando le distribuzioni a priori coniugate sono disponibili, un modello che ne fa uso potrebbe non essere sufficientemente flessibile per adattarsi alle nostre credenze iniziali. Ad esempio, un modello basato su una distribuzione normale è sempre unimodale e simmetrico rispetto alla media \\(\\mu\\). Tuttavia, se le nostre conoscenze iniziali non sono simmetriche o non seguono una distribuzione unimodale, la scelta di una distribuzione a priori normale potrebbe non risultare la più adeguata (Johnson et al., 2022).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_conjugate_families_1.html#esercizi",
    "href": "chapters/bayesian_inference/07_conjugate_families_1.html#esercizi",
    "title": "51  Distribuzioni coniugate (1)",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nSi consideri lo studio “An excess of positive results: Comparing the standard psychology literature with registered reports” di Scheel et al. (2021). In questo lavoro, gli autori confrontano il tasso di risultati positivi \\(\\theta\\) ottenuti in studi psicologici pubblicati senza preregistrazione con quelli pubblicati con preregistrazione. Si utilizzi il tasso di successo riportato negli studi preregistrati per costruire una distribuzione a priori per il parametro \\(\\theta\\).\nSecondo i risultati degli studi preregistrati, gli autori riscontrano un tasso di successo del 43.66%, con un intervallo di confidenza al 95% [CI] = [31.91, 55.95]. Sulla base di questi dati, si costruisca una distribuzione beta come distribuzione a priori per \\(\\theta\\), seguendo il metodo illustrato da Johnson et al. (2022).\nSuccessivamente, utilizzando questa distribuzione beta come distribuzione a priori, si determini la distribuzione a posteriori utilizzando il metodo delle famiglie coniugate per due scenari distinti, basati su 152 studi osservati: (a) Un tasso di successo del 60% (b) Un tasso di successo del 96% (come riportato per gli studi non preregistrati da Scheel et al. (2021)).\nInfine, si commentino i risultati derivanti dall’analisi delle distribuzioni a posteriori ottenute per entrambi gli scenari.\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\n# Caricamento delle librerie necessarie\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(dplyr)\n\n# Funzione per trovare i parametri della distribuzione beta\nfind_beta_parameters &lt;- function(mean, lower, upper, conf_level = 0.95) {\n  # Funzione obiettivo da minimizzare\n  objective &lt;- function(alpha) {\n    beta &lt;- alpha * (1 - mean) / mean\n    predicted_ci &lt;- qbeta(c((1-conf_level)/2, 1-(1-conf_level)/2), alpha, beta)\n    error &lt;- (predicted_ci[1] - lower)^2 + (predicted_ci[2] - upper)^2\n    return(error)\n  }\n  \n  # Ottimizzazione per trovare alpha\n  result &lt;- optimize(objective, interval = c(0.1, 100))\n  alpha &lt;- result$minimum\n  beta &lt;- alpha * (1 - mean) / mean\n  \n  return(list(alpha = alpha, beta = beta))\n}\n\n# Parametri degli studi preregistrati\nmean_preregistered &lt;- 0.4366\nci_lower &lt;- 0.3191\nci_upper &lt;- 0.5595\n\n# Calcolo dei parametri della distribuzione beta a priori\nprior_params &lt;- find_beta_parameters(mean_preregistered, ci_lower, ci_upper)\nalpha_prior &lt;- prior_params$alpha\nbeta_prior &lt;- prior_params$beta\n\n# Dati osservati\nn &lt;- 152  # numero di studi\nsuccesses_60 &lt;- round(0.60 * n)  # scenario (a)\nsuccesses_96 &lt;- round(0.96 * n)  # scenario (b)\n\n# Calcolo delle distribuzioni a posteriori\nalpha_post_60 &lt;- alpha_prior + successes_60\nbeta_post_60 &lt;- beta_prior + (n - successes_60)\n\nalpha_post_96 &lt;- alpha_prior + successes_96\nbeta_post_96 &lt;- beta_prior + (n - successes_96)\n\n# Creazione del dataframe per il plotting\ntheta &lt;- seq(0, 1, length.out = 1000)\n\ndf &lt;- data.frame(\n  theta = rep(theta, 3),\n  density = c(\n    dbeta(theta, alpha_prior, beta_prior),\n    dbeta(theta, alpha_post_60, beta_post_60),\n    dbeta(theta, alpha_post_96, beta_post_96)\n  ),\n  distribution = rep(c(\"Priori\", \"Posteriori (60%)\", \"Posteriori (96%)\"), \n                    each = length(theta))\n)\n\n# Creazione del grafico\np &lt;- ggplot(df, aes(x = theta, y = density, color = distribution)) +\n  geom_line(size = 1) +\n  labs(\n    title = \"Distribuzioni a Priori e a Posteriori\",\n    x = expression(theta),\n    y = \"Densità\",\n    color = \"Distribuzione\"\n  ) +\n  theme(legend.position = \"bottom\")\n\n# Calcolo degli intervalli di credibilità al 95%\ncredible_intervals &lt;- data.frame(\n  Distribution = c(\"Priori\", \"Posteriori (60%)\", \"Posteriori (96%)\"),\n  Mean = c(\n    alpha_prior / (alpha_prior + beta_prior),\n    alpha_post_60 / (alpha_post_60 + beta_post_60),\n    alpha_post_96 / (alpha_post_96 + beta_post_96)\n  ),\n  Lower = c(\n    qbeta(0.025, alpha_prior, beta_prior),\n    qbeta(0.025, alpha_post_60, beta_post_60),\n    qbeta(0.025, alpha_post_96, beta_post_96)\n  ),\n  Upper = c(\n    qbeta(0.975, alpha_prior, beta_prior),\n    qbeta(0.975, alpha_post_60, beta_post_60),\n    qbeta(0.975, alpha_post_96, beta_post_96)\n  )\n)\n\n# Visualizzazione dei risultati\nprint(\"Parametri della distribuzione beta a priori:\")\nprint(paste(\"alpha =\", round(alpha_prior, 2)))\nprint(paste(\"beta =\", round(beta_prior, 2)))\n\nprint(\"\\nIntervalli di credibilità al 95%:\")\nprint(credible_intervals)\n\n# Visualizza il grafico\nprint(p)\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nTra i fattori che possono influenzare il rapporto tra i sessi alla nascita c’è la condizione materna di placenta previa, una condizione insolita della gravidanza in cui la placenta è impiantata in basso nell’utero, impedendo un normale parto vaginale del feto. Uno studio condotto in Germania ha esaminato il sesso dei neonati in casi di placenta previa e ha riscontrato che, su un totale di 980 nascite, 437 erano femmine.\nQuanta evidenza fornisce questo studio a supporto dell’ipotesi che la proporzione di nascite femminili nella popolazione di placenta previa sia inferiore a 0.485, che rappresenta la proporzione di nascite femminili nella popolazione generale? (Esercizio tratto da Gelman et al. (1995))\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\n# Caricamento delle librerie necessarie\nlibrary(ggplot2)\n\n# Dati osservati\nn &lt;- 980        # numero totale di nascite\ny &lt;- 437        # numero di femmine\np0 &lt;- 0.485     # proporzione nella popolazione generale\n\n# Calcolo della proporzione osservata\np_hat &lt;- y/n\nprint(paste(\"Proporzione osservata di femmine:\", round(p_hat, 3)))\n\n# Test dell'ipotesi utilizzando il Bayes Factor\n# H0: p = 0.485 vs H1: p &lt; 0.485\n\n# Funzione per calcolare la verosimiglianza marginale sotto H1\nmarginal_likelihood_h1 &lt;- function(y, n, p_max = 0.485) {\n  # Integrazione numerica sulla distribuzione uniforme tra 0 e p_max\n  p_grid &lt;- seq(0, p_max, length.out = 1000)\n  likelihood &lt;- dbinom(y, n, p_grid)\n  prior &lt;- dunif(p_grid, 0, p_max)\n  mean(likelihood * prior) * p_max\n}\n\n# Verosimiglianza sotto H0\nlikelihood_h0 &lt;- dbinom(y, n, p0)\n\n# Verosimiglianza marginale sotto H1\nmarg_lik_h1 &lt;- marginal_likelihood_h1(y, n)\n\n# Calcolo del Bayes Factor\nbf10 &lt;- marg_lik_h1 / likelihood_h0\nprint(paste(\"Bayes Factor (H1 vs H0):\", round(bf10, 2)))\n\n# Visualizzazione delle distribuzioni a posteriori\np_grid &lt;- seq(0, 1, length.out = 1000)\nlikelihood &lt;- dbinom(y, n, p_grid)\nprior &lt;- dunif(p_grid, 0, 1)\nposterior &lt;- likelihood * prior\nposterior &lt;- posterior / sum(posterior)\n\n# Creazione del dataframe per il plotting\ndf &lt;- data.frame(\n  p = p_grid,\n  Posterior = posterior / max(posterior)  # normalizzato per la visualizzazione\n)\n\n# Creazione del grafico\np &lt;- ggplot(df, aes(x = p, y = Posterior)) +\n  geom_line(size = 1) +\n  geom_vline(xintercept = p0, linetype = \"dashed\", color = \"red\") +\n  geom_vline(xintercept = p_hat, linetype = \"dashed\", color = \"blue\") +\n  labs(\n    title = \"Distribuzione a Posteriori della Proporzione di Nascite Femminili\",\n    x = \"Proporzione di Nascite Femminili (p)\",\n    y = \"Densità a Posteriori (normalizzata)\"\n  ) +\n  annotate(\"text\", x = p0, y = 0.1, \n           label = \"Popolazione Generale\", \n           angle = 90, vjust = -0.5, color = \"red\") +\n  annotate(\"text\", x = p_hat, y = 0.1, \n           label = \"Proporzione Osservata\", \n           angle = 90, vjust = -0.5, color = \"blue\")\n\n# Calcolo dell'intervallo di credibilità al 95%\nsorted_p &lt;- sort(p_grid)\ncum_post &lt;- cumsum(posterior)\nlower &lt;- sorted_p[which(cum_post &gt; 0.025)[1]]\nupper &lt;- sorted_p[which(cum_post &gt; 0.975)[1]]\n\nprint(paste(\"Intervallo di credibilità al 95%: [\", \n            round(lower, 3), \",\", round(upper, 3), \"]\"))\n\n# Calcolo della probabilità a posteriori che p &lt; 0.485\nprob_less_than_p0 &lt;- sum(posterior[p_grid &lt; p0])\nprint(paste(\"Probabilità a posteriori che p &lt; 0.485:\", \n            round(prob_less_than_p0, 3)))\n\n# Visualizza il grafico\nprint(p)\n\n\n\n\n\n\n\n\n\nProblemi 3\n\n\n\n\n\nPer valutare la sensibilità della soluzione precedente alla scelta della distribuzione a priori, ripetere l’esercizio utilizzando come distribuzione a priori per la proporzione di nascite femminili una distribuzione Beta(48.5, 51.5). Questa distribuzione è centrata su 0.485 e concentra la maggior parte della sua massa nell’intervallo [0.385, 0.585]. Interpretare i risultati ottenuti.\n\n\n\n\n\n\n\n\n\nSoluzioni 3\n\n\n\n\n\n# Caricamento delle librerie necessarie\nlibrary(ggplot2)\n\n# Dati osservati\nn &lt;- 980        # numero totale di nascite\ny &lt;- 437        # numero di femmine\np0 &lt;- 0.485     # proporzione nella popolazione generale\n\n# Parametri della distribuzione beta a priori\nalpha_prior &lt;- 48.5\nbeta_prior &lt;- 51.5\n\n# Calcolo dei parametri della distribuzione beta a posteriori\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + (n - y)\n\n# Creazione della griglia per il plotting\np_grid &lt;- seq(0, 1, length.out = 1000)\n\n# Calcolo delle densità\nprior_density &lt;- dbeta(p_grid, alpha_prior, beta_prior)\nposterior_density &lt;- dbeta(p_grid, alpha_post, beta_post)\n\n# Creazione del dataframe per il plotting\ndf &lt;- data.frame(\n  p = rep(p_grid, 2),\n  density = c(prior_density, posterior_density),\n  distribution = rep(c(\"Priori Beta(48.5, 51.5)\", \"Posteriori\"), each = length(p_grid))\n)\n\n# Creazione del grafico\np &lt;- ggplot(df, aes(x = p, y = density, color = distribution)) +\n  geom_line(size = 1) +\n  geom_vline(xintercept = p0, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Distribuzioni a Priori e a Posteriori\",\n    subtitle = \"Proporzione di Nascite Femminili con Placenta Previa\",\n    x = \"Proporzione di Nascite Femminili (p)\",\n    y = \"Densità\",\n    color = \"Distribuzione\"\n  ) +\n  theme(legend.position = \"bottom\") +\n  annotate(\"text\", x = p0, y = max(posterior_density)/2, \n           label = \"Popolazione Generale (0.485)\", \n           angle = 90, vjust = -0.5, color = \"red\")\n\n# Calcolo statistiche rilevanti\n# Media a priori e posteriori\nprior_mean &lt;- alpha_prior / (alpha_prior + beta_prior)\npost_mean &lt;- alpha_post / (alpha_post + beta_post)\n\n# Intervalli di credibilità al 95%\nprior_ci &lt;- qbeta(c(0.025, 0.975), alpha_prior, beta_prior)\npost_ci &lt;- qbeta(c(0.025, 0.975), alpha_post, beta_post)\n\n# Probabilità a posteriori che p &lt; 0.485\nprob_less_than_p0 &lt;- pbeta(p0, alpha_post, beta_post)\n\n# Output dei risultati\ncat(\"\\nRisultati dell'analisi:\\n\")\ncat(\"------------------------\\n\")\ncat(\"Dati osservati:\\n\")\ncat(sprintf(\"Numero totale di nascite: %d\\n\", n))\ncat(sprintf(\"Numero di femmine: %d\\n\", y))\ncat(sprintf(\"Proporzione osservata: %.3f\\n\\n\", y/n))\n\ncat(\"Analisi a priori:\\n\")\ncat(sprintf(\"Media a priori: %.3f\\n\", prior_mean))\ncat(sprintf(\"Intervallo di credibilità al 95%%: [%.3f, %.3f]\\n\\n\", \n            prior_ci[1], prior_ci[2]))\n\ncat(\"Analisi a posteriori:\\n\")\ncat(sprintf(\"Media a posteriori: %.3f\\n\", post_mean))\ncat(sprintf(\"Intervallo di credibilità al 95%%: [%.3f, %.3f]\\n\", \n            post_ci[1], post_ci[2]))\ncat(sprintf(\"Probabilità che p &lt; %.3f: %.3f\\n\", p0, prob_less_than_p0))\n\n# Visualizza il grafico\nprint(p)\n# Caricamento delle librerie necessarie\nlibrary(ggplot2)\n\n# Dati osservati\nn &lt;- 980        # numero totale di nascite\ny &lt;- 437        # numero di femmine\np0 &lt;- 0.485     # proporzione nella popolazione generale\n\n# Parametri della distribuzione beta a priori\nalpha_prior &lt;- 48.5\nbeta_prior &lt;- 51.5\n\n# Calcolo dei parametri della distribuzione beta a posteriori\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + (n - y)\n\n# Creazione della griglia per il plotting\np_grid &lt;- seq(0, 1, length.out = 1000)\n\n# Calcolo delle densità\nprior_density &lt;- dbeta(p_grid, alpha_prior, beta_prior)\nposterior_density &lt;- dbeta(p_grid, alpha_post, beta_post)\n\n# Creazione del dataframe per il plotting\ndf &lt;- data.frame(\n  p = rep(p_grid, 2),\n  density = c(prior_density, posterior_density),\n  distribution = rep(c(\"Priori Beta(48.5, 51.5)\", \"Posteriori\"), each = length(p_grid))\n)\n\n# Creazione del grafico\np &lt;- ggplot(df, aes(x = p, y = density, color = distribution)) +\n  geom_line(size = 1) +\n  geom_vline(xintercept = p0, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Distribuzioni a Priori e a Posteriori\",\n    subtitle = \"Proporzione di Nascite Femminili con Placenta Previa\",\n    x = \"Proporzione di Nascite Femminili (p)\",\n    y = \"Densità\",\n    color = \"Distribuzione\"\n  ) +\n  theme(legend.position = \"bottom\") +\n  annotate(\"text\", x = p0, y = max(posterior_density)/2, \n           label = \"Popolazione Generale (0.485)\", \n           angle = 90, vjust = -0.5, color = \"red\")\n\n# Calcolo statistiche rilevanti\n# Media a priori e posteriori\nprior_mean &lt;- alpha_prior / (alpha_prior + beta_prior)\npost_mean &lt;- alpha_post / (alpha_post + beta_post)\n\n# Intervalli di credibilità al 95%\nprior_ci &lt;- qbeta(c(0.025, 0.975), alpha_prior, beta_prior)\npost_ci &lt;- qbeta(c(0.025, 0.975), alpha_post, beta_post)\n\n# Probabilità a posteriori che p &lt; 0.485\nprob_less_than_p0 &lt;- pbeta(p0, alpha_post, beta_post)\n\n# Output dei risultati\ncat(\"\\nRisultati dell'analisi:\\n\")\ncat(\"------------------------\\n\")\ncat(\"Dati osservati:\\n\")\ncat(sprintf(\"Numero totale di nascite: %d\\n\", n))\ncat(sprintf(\"Numero di femmine: %d\\n\", y))\ncat(sprintf(\"Proporzione osservata: %.3f\\n\\n\", y/n))\n\ncat(\"Analisi a priori:\\n\")\ncat(sprintf(\"Media a priori: %.3f\\n\", prior_mean))\ncat(sprintf(\"Intervallo di credibilità al 95%%: [%.3f, %.3f]\\n\\n\", \n            prior_ci[1], prior_ci[2]))\n\ncat(\"Analisi a posteriori:\\n\")\ncat(sprintf(\"Media a posteriori: %.3f\\n\", post_mean))\ncat(sprintf(\"Intervallo di credibilità al 95%%: [%.3f, %.3f]\\n\", \n            post_ci[1], post_ci[2]))\ncat(sprintf(\"Probabilità che p &lt; %.3f: %.3f\\n\", p0, prob_less_than_p0))\n\n# Visualizza il grafico\nprint(p)\nI risultati mostrano che:\n\nLa proporzione osservata nel campione (0.446) è inferiore al valore di riferimento della popolazione generale (0.485)\nLa distribuzione a priori Beta(48.5, 51.5):\n\n\nHa media 0.485\nRiflette la nostra conoscenza iniziale sulla proporzione di nascite femminili\nFornisce un’incertezza ragionevole attorno al valore di riferimento\n\n\nLa distribuzione a posteriori:\n\n\nHa una media di circa 0.447\nL’intervallo di credibilità al 95% esclude il valore di riferimento 0.485\nIndica una probabilità elevata che la vera proporzione sia inferiore a 0.485\n\n\nQuesta analisi suggerisce che:\n\n\nEsiste un’associazione tra placenta previa e una minor proporzione di nascite femminili\nL’effetto è moderato ma statisticamente rilevante\nLa stima è abbastanza precisa grazie alla dimensione campionaria considerevole\n\n\n\n\n\n\n\n\n\n\nProblemi 4\n\n\n\n\n\nIn uno studio recente, Gori et al. (2024) hanno esaminato un campione di 202 adulti italiani e hanno riscontrato una prevalenza di mancini del 6.4%. Una meta-analisi di Papadatou-Pastou et al. (2020), condotta su un totale di 2,396,170 soggetti, riporta che la proporzione di mancini varia tra il 9.3% e il 18.1%, a seconda di come viene misurata la lateralità manuale. Inoltre, Papadatou-Pastou et al. (2020) mostrano che la prevalenza della lateralità manuale varia tra i paesi e nel tempo. Considerata questa incertezza, si determini la distribuzione a posteriori che combina i dati dello studio di Gori et al. (2024) con le informazioni pregresse fornite da Papadatou-Pastou et al. (2020). Le informazioni di Papadatou-Pastou et al. (2020) possono essere espresse in termini di una distribuzione Beta(8, 60).\n\n\n\n\n\n\n\n\n\nSoluzioni 4\n\n\n\n\n\n# Caricamento delle librerie necessarie\nlibrary(ggplot2)\n\n# Dati dello studio di Gori et al. (2024)\nn &lt;- 202       # dimensione del campione\ny &lt;- round(0.064 * n)  # numero di mancini (6.4% del campione)\n\n# Parametri della distribuzione beta a priori (da Papadatou-Pastou et al., 2020)\nalpha_prior &lt;- 8\nbeta_prior &lt;- 60\n\n# Calcolo dei parametri della distribuzione beta a posteriori\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + (n - y)\n\n# Creazione della griglia per il plotting\np_grid &lt;- seq(0, 0.3, length.out = 1000)  # limitato a 0.3 per migliore visualizzazione\n\n# Calcolo delle densità\nprior_density &lt;- dbeta(p_grid, alpha_prior, beta_prior)\nposterior_density &lt;- dbeta(p_grid, alpha_post, beta_post)\n\n# Creazione del dataframe per il plotting\ndf &lt;- data.frame(\n  p = rep(p_grid, 2),\n  density = c(prior_density, posterior_density),\n  distribution = rep(c(\"Priori (Papadatou-Pastou et al., 2020)\", \n                      \"Posteriori (con dati Gori et al., 2024)\"), \n                    each = length(p_grid))\n)\n\n# Calcolo statistiche rilevanti\nprior_mean &lt;- alpha_prior / (alpha_prior + beta_prior)\npost_mean &lt;- alpha_post / (alpha_post + beta_post)\n\nprior_ci &lt;- qbeta(c(0.025, 0.975), alpha_prior, beta_prior)\npost_ci &lt;- qbeta(c(0.025, 0.975), alpha_post, beta_post)\n\n# Creazione del grafico\np &lt;- ggplot(df, aes(x = p, y = density, color = distribution)) +\n  geom_line(size = 1) +\n  geom_vline(xintercept = 0.064, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Distribuzione della Prevalenza dei Mancini\",\n    subtitle = \"Confronto tra Distribuzione a Priori e a Posteriori\",\n    x = \"Proporzione di Mancini\",\n    y = \"Densità\",\n    color = \"Distribuzione\"\n  ) +\n  theme(legend.position = \"bottom\") +\n  annotate(\"text\", x = 0.064, y = max(posterior_density)/2, \n           label = \"Valore osservato (6.4%)\", \n           angle = 90, vjust = -0.5, color = \"red\")\n\n# Output dei risultati\ncat(\"\\nRisultati dell'analisi:\\n\")\ncat(\"------------------------\\n\")\ncat(\"Distribuzione a priori (Papadatou-Pastou et al., 2020):\\n\")\ncat(sprintf(\"Media: %.1f%%\\n\", prior_mean * 100))\ncat(sprintf(\"Intervallo di credibilità al 95%%: [%.1f%%, %.1f%%]\\n\\n\", \n            prior_ci[1] * 100, prior_ci[2] * 100))\n\ncat(\"Dati osservati (Gori et al., 2024):\\n\")\ncat(sprintf(\"Campione: %d individui\\n\", n))\ncat(sprintf(\"Mancini osservati: %d (%.1f%%)\\n\\n\", y, y/n * 100))\n\ncat(\"Distribuzione a posteriori:\\n\")\ncat(sprintf(\"Media: %.1f%%\\n\", post_mean * 100))\ncat(sprintf(\"Intervallo di credibilità al 95%%: [%.1f%%, %.1f%%]\\n\", \n            post_ci[1] * 100, post_ci[2] * 100))\n\n# Visualizza il grafico\nprint(p)\n# Caricamento delle librerie necessarie\nlibrary(ggplot2)\n\n# Dati dello studio di Gori et al. (2024)\nn &lt;- 202       # dimensione del campione\ny &lt;- round(0.064 * n)  # numero di mancini (6.4% del campione)\n\n# Parametri della distribuzione beta a priori (da Papadatou-Pastou et al., 2020)\nalpha_prior &lt;- 8\nbeta_prior &lt;- 60\n\n# Calcolo dei parametri della distribuzione beta a posteriori\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + (n - y)\n\n# Creazione della griglia per il plotting\np_grid &lt;- seq(0, 0.3, length.out = 1000)  # limitato a 0.3 per migliore visualizzazione\n\n# Calcolo delle densità\nprior_density &lt;- dbeta(p_grid, alpha_prior, beta_prior)\nposterior_density &lt;- dbeta(p_grid, alpha_post, beta_post)\n\n# Creazione del dataframe per il plotting\ndf &lt;- data.frame(\n  p = rep(p_grid, 2),\n  density = c(prior_density, posterior_density),\n  distribution = rep(c(\"Priori (Papadatou-Pastou et al., 2020)\", \n                      \"Posteriori (con dati Gori et al., 2024)\"), \n                    each = length(p_grid))\n)\n\n# Calcolo statistiche rilevanti\nprior_mean &lt;- alpha_prior / (alpha_prior + beta_prior)\npost_mean &lt;- alpha_post / (alpha_post + beta_post)\n\nprior_ci &lt;- qbeta(c(0.025, 0.975), alpha_prior, beta_prior)\npost_ci &lt;- qbeta(c(0.025, 0.975), alpha_post, beta_post)\n\n# Creazione del grafico\np &lt;- ggplot(df, aes(x = p, y = density, color = distribution)) +\n  geom_line(size = 1) +\n  geom_vline(xintercept = 0.064, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Distribuzione della Prevalenza dei Mancini\",\n    subtitle = \"Confronto tra Distribuzione a Priori e a Posteriori\",\n    x = \"Proporzione di Mancini\",\n    y = \"Densità\",\n    color = \"Distribuzione\"\n  ) +\n  theme(legend.position = \"bottom\") +\n  annotate(\"text\", x = 0.064, y = max(posterior_density)/2, \n           label = \"Valore osservato (6.4%)\", \n           angle = 90, vjust = -0.5, color = \"red\")\n\n# Output dei risultati\ncat(\"\\nRisultati dell'analisi:\\n\")\ncat(\"------------------------\\n\")\ncat(\"Distribuzione a priori (Papadatou-Pastou et al., 2020):\\n\")\ncat(sprintf(\"Media: %.1f%%\\n\", prior_mean * 100))\ncat(sprintf(\"Intervallo di credibilità al 95%%: [%.1f%%, %.1f%%]\\n\\n\", \n            prior_ci[1] * 100, prior_ci[2] * 100))\n\ncat(\"Dati osservati (Gori et al., 2024):\\n\")\ncat(sprintf(\"Campione: %d individui\\n\", n))\ncat(sprintf(\"Mancini osservati: %d (%.1f%%)\\n\\n\", y, y/n * 100))\n\ncat(\"Distribuzione a posteriori:\\n\")\ncat(sprintf(\"Media: %.1f%%\\n\", post_mean * 100))\ncat(sprintf(\"Intervallo di credibilità al 95%%: [%.1f%%, %.1f%%]\\n\", \n            post_ci[1] * 100, post_ci[2] * 100))\n\n# Visualizza il grafico\nprint(p)\nL’analisi bayesiana della prevalenza dei mancini combina le informazioni provenienti dalla meta-analisi di Papadatou-Pastou et al. (2020) con i dati più recenti di Gori et al. (2024). Di seguito sono riportati i principali risultati:\n\n\nDistribuzione a priori (basata su Papadatou-Pastou et al., 2020):\n\nModellata come una distribuzione Beta(8, 60).\n\nPresenta una media intorno all’11,8%.\n\nRiflette la variabilità osservata nella meta-analisi.\n\nL’intervallo di credibilità al 95% copre approssimativamente il range 9,3%-18,1%, come riportato nello studio.\n\n\n\nDati osservati (Gori et al., 2024):\n\n202 partecipanti italiani.\n\n13 mancini, corrispondenti al 6,4% del campione.\n\nQuesto valore è inferiore alla media stimata dalla meta-analisi globale.\n\n\n\nDistribuzione a posteriori:\n\nCombina le informazioni a priori con i nuovi dati osservati.\n\nLa media a posteriori si è spostata verso il basso rispetto alla distribuzione a priori.\n\nL’intervallo di credibilità si è ristretto, indicando una riduzione dell’incertezza.\n\nMaggiore peso è stato attribuito ai dati italiani rispetto alla meta-analisi globale.\n\n\n\nInterpretazione:\n\nLa stima finale suggerisce una prevalenza di mancini nella popolazione italiana inferiore alla media globale.\n\nQuesto risultato potrebbe riflettere specificità culturali o metodologiche dello studio italiano.\n\nL’incertezza nella stima finale è diminuita rispetto alla meta-analisi, ma rimane significativa.\n\nI risultati supportano l’ipotesi di una variabilità geografica nella prevalenza della mancinismo.\n\n\n\nLa distribuzione a posteriori fornisce una sintesi equilibrata tra le conoscenze globali precedenti e i dati specifici della popolazione italiana, suggerendo che potrebbero esistere peculiarità culturali o demografiche che influenzano la prevalenza del mancinismo in Italia.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_conjugate_families_1.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/07_conjugate_families_1.html#informazioni-sullambiente-di-sviluppo",
    "title": "51  Distribuzioni coniugate (1)",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.17.0      thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0\n#&gt;  [5] see_0.11.0       gridExtra_2.3    patchwork_1.3.0  bayesplot_1.12.0\n#&gt;  [9] psych_2.5.3      scales_1.4.0     markdown_2.0     knitr_1.50      \n#&gt; [13] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [17] purrr_1.0.4      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [21] ggplot2_3.5.2    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1   farver_2.1.2       fastmap_1.2.0     \n#&gt;  [4] pacman_0.5.1       digest_0.6.37      rpart_4.1.24      \n#&gt;  [7] timechange_0.3.0   lifecycle_1.0.4    survival_3.8-3    \n#&gt; [10] magrittr_2.0.3     compiler_4.5.0     rlang_1.1.6       \n#&gt; [13] tools_4.5.0        labeling_0.4.3     htmlwidgets_1.6.4 \n#&gt; [16] mnormt_2.1.1       RColorBrewer_1.1-3 withr_3.0.2       \n#&gt; [19] nnet_7.3-20        grid_4.5.0         jomo_2.7-6        \n#&gt; [22] iterators_1.0.14   MASS_7.3-65        cli_3.6.5         \n#&gt; [25] rmarkdown_2.29     reformulas_0.4.1   generics_0.1.4    \n#&gt; [28] rstudioapi_0.17.1  tzdb_0.5.0         minqa_1.2.8       \n#&gt; [31] splines_4.5.0      parallel_4.5.0     vctrs_0.6.5       \n#&gt; [34] boot_1.3-31        glmnet_4.1-8       Matrix_1.7-3      \n#&gt; [37] jsonlite_2.0.0     hms_1.1.3          mitml_0.4-5       \n#&gt; [40] foreach_1.5.2      glue_1.8.0         nloptr_2.2.1      \n#&gt; [43] pan_1.9            codetools_0.2-20   stringi_1.8.7     \n#&gt; [46] shape_1.4.6.1      gtable_0.3.6       lme4_1.1-37       \n#&gt; [49] pillar_1.10.2      htmltools_0.5.8.1  R6_2.6.1          \n#&gt; [52] Rdpack_2.6.4       rprojroot_2.0.4    evaluate_1.0.3    \n#&gt; [55] lattice_0.22-7     rbibutils_2.3      backports_1.5.0   \n#&gt; [58] broom_1.0.8        Rcpp_1.0.14        nlme_3.1-168      \n#&gt; [61] xfun_0.52          pkgconfig_2.0.3",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_conjugate_families_1.html#bibliografia",
    "href": "chapters/bayesian_inference/07_conjugate_families_1.html#bibliografia",
    "title": "51  Distribuzioni coniugate (1)",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (1995). Bayesian data analysis. Chapman; Hall/CRC.\n\n\nGori, B., Grippo, A., Focardi, M., & Lolli, F. (2024). The Italian version of Edinburgh Handedness Inventory: Translation, transcultural adaptation, and validation in healthy subjects. Laterality, 29(2), 151–168.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nNalborczyk, L. (2018, gennaio 23). Checking the Asumption of Independence in Binomial Trials Using Posterior Predictive Checking. https://lnalborczyk.github.io/blog/2018-01-23-ppc\n\n\nPapadatou-Pastou, M., Ntolka, E., Schmitz, J., Martin, M., Munafò, M. R., Ocklenburg, S., & Paracchini, S. (2020). Human handedness: A meta-analysis. Psychological bulletin, 146(6), 481–524.\n\n\nScheel, A. M., Schijen, M. R., & Lakens, D. (2021). An excess of positive results: Comparing the standard psychology literature with registered reports. Advances in Methods and Practices in Psychological Science, 4(2), 25152459211007467.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_conjugate_families_2.html",
    "href": "chapters/bayesian_inference/08_conjugate_families_2.html",
    "title": "52  Distribuzioni coniugate (2)",
    "section": "",
    "text": "52.1 Introduzione\nLa statistica bayesiana aggiorna ciò che credevamo prima, chiamato prior, con ciò che osserviamo ora, i dati, per produrre ciò che sappiamo dopo, la posteriori. In pratica:\nL’effetto principale è che l’incertezza, misurata dalla varianza, sulla stima di \\(\\mu\\) diminuisce: più dati abbiamo, più la distribuzione si restringe.\nIn questo capitolo esploriamo le famiglie coniugate (Capitolo 51), concentrandoci sul modello normale-normale. Quando sia la prior sia la verosimiglianza sono distribuzioni gaussiane, anche la distribuzione a posteriori risulta gaussiana.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_conjugate_families_2.html#introduzione",
    "href": "chapters/bayesian_inference/08_conjugate_families_2.html#introduzione",
    "title": "52  Distribuzioni coniugate (2)",
    "section": "",
    "text": "partiamo da una distribuzione a priori su un parametro, qui la media \\(\\mu\\);\n\nosserviamo un campione e ne calcoliamo la verosimiglianza;\n\ncombiniamo le due informazioni tramite il teorema di Bayes per ottenere la distribuzione a posteriori, che incorpora sia le conoscenze pregresse sia l’evidenza empirica.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_conjugate_families_2.html#vantaggi-della-scelta-gaussiana",
    "href": "chapters/bayesian_inference/08_conjugate_families_2.html#vantaggi-della-scelta-gaussiana",
    "title": "52  Distribuzioni coniugate (2)",
    "section": "\n52.2 Vantaggi della Scelta Gaussiana",
    "text": "52.2 Vantaggi della Scelta Gaussiana\n\nSimmetria e Universalità: La forma a campana simmetrica approssima adeguatamente molti fenomeni psicologici, ad esempio i tempi di reazione o i punteggi QI. La simmetria facilita l’interpretazione di media e varianza come parametri centrali.\nEconomia Parametrica: L’incertezza è catturata da un solo parametro, \\(\\sigma^2\\), semplificando la comunicazione dei risultati.\nConsistenza con l’Inferenza Frequentista: Per grandi campioni, le stime bayesiane convergono a quelle classiche, una proprietà nota come calibrazione frequente, offrendo un ponte tra paradigmi.\nTrattabilità Matematica: Le operazioni tra distribuzioni gaussiane rimangono in forma chiusa, evitando complessi calcoli numerici.\n\nMorale: se ci aspettiamo molti dati o una posteriori unimodale e simmetrica, la distribuzione normale è un ottimo lavoro di prima approssimazione.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_conjugate_families_2.html#inferenza-con-varianza-nota",
    "href": "chapters/bayesian_inference/08_conjugate_families_2.html#inferenza-con-varianza-nota",
    "title": "52  Distribuzioni coniugate (2)",
    "section": "\n52.3 Inferenza con varianza nota",
    "text": "52.3 Inferenza con varianza nota\nSupponiamo di aver misurato i tempi di reazione in millisecondi di 20 studenti durante un compito Stroop, volendo stimare il vero tempo medio \\(\\mu\\) della popolazione. Assumiamo nota la variabilità intrinseca del compito, \\(\\sigma = 50\\) ms.\n\n52.3.1 I tre passi dell’Inferenza Bayesiana\n\n\n\n\n\n\n\nPasso\nSignificato intuitivo\nNotazione\n\n\n\nA. Prior\nOpinione preliminare su \\(\\mu\\)\n\n\\(\\mu \\sim \\mathcal{N}(\\mu_0,\\sigma_0^2)\\)\n\n\nB. Verosimiglianza\nChe cosa dicono i dati\n\\(y_i \\stackrel{\\text{iid}}{\\sim} \\mathcal{N}(\\mu,\\sigma^2)\\)\n\n\nC. Posteriori\nOpinione aggiornata\n\\(\\mu \\mid y \\sim \\mathcal{N}(\\mu_p,\\sigma_p^2)\\)\n\n\n\nCon \\(\\sigma^2\\) fisso la distribuzione normale è coniugata: la forma rimane invariata in ogni passaggio.\n\n52.3.2 Distribuzione A priori\n\\(\\mu \\sim \\mathcal{N}(\\mu_0,\\sigma_0^2)\\): descrive dove crediamo sia \\(\\mu\\) e quanta incertezza abbiamo, una varianza grande significa poca informazione.\n\n52.3.3 Verosimiglianza\n\\[\np(y\\mid\\mu,\\sigma)=\\prod_{i=1}^{n}\\frac{1}{\\sigma\\sqrt{2\\pi}}\n                  \\exp\\!\\Bigl[-\\tfrac{(y_i-\\mu)^2}{2\\sigma^2}\\Bigr].\n\\]\n\n52.3.4 Teorema di Bayes\nIl teorema di Bayes combina prior e verosimiglianza attraverso un prodotto ponderato:\n\\[\np(\\mu\\mid y)=\\frac{p(y\\mid\\mu)\\,p(\\mu)}{p(y)} \\;\\; \\propto\\;\\;\n\\underbrace{\\mathcal{N}(\\mu_0,\\sigma_0^2)}_{\\text{prior}}\n\\; \\times \\;\n\\underbrace{\\mathcal{N}(\\bar y,\\sigma^2/n)}_{\\text{verosimiglianza}} .\n\\]\nIl prodotto di due distribuzioni gaussiane è una distribuzione gaussiana: basta aggiornare media e varianza.\n\n52.3.5 Media a posteriori\n\\[\n\\mu_p=\\frac{\\tfrac{1}{\\sigma_0^2}\\,\\mu_0 + \\tfrac{n}{\\sigma^2}\\,\\bar y}\n           {\\tfrac{1}{\\sigma_0^2} + \\tfrac{n}{\\sigma^2}},\n\\qquad\n\\bar y=\\frac{1}{n}\\sum_{i=1}^{n}y_i.\n\\]\n\n\\(\\mu_0\\): l’idea iniziale.\n\\(\\sigma_0^2\\): la fiducia in quell’idea.\n\\(\\bar y\\): ciò che dicono i dati.\n\\(n/\\sigma^2\\): la quantità di informazione empirica, aumenta con più casi e diminuisce con misure rumorose.\n\nInterpretazione: Il peso relativo di prior e dati dipende dalla loro credibilità:\n\nLa prior è influente se ha alta precisione, ovvero 1/\\(\\sigma_0^2\\) è grande, o se ci sono pochi dati, \\(n\\) piccolo.\nI dati sono dominanti se la prior ha bassa precisione o se c’è un ampio campione.\n\n\n\n52.3.6 Varianza a posteriori\n\\[\\sigma_p^2=\\frac{1}{\\tfrac{1}{\\sigma_0^2}+\\tfrac{n}{\\sigma^2}}.\\]\n\n\nProprietà Chiave: \\(\\sigma_p^2 \\le \\min(\\sigma_0^2, \\sigma^2/n)\\). L’incertezza diminuisce monotonicamente all’aumentare di \\(n\\).\n\n\nEsempio 52.1 Consideriamo l’esempio dei tempi di reazione nell’effetto Stroop. La prior e i dati osservati sono i seguenti:\n\n\nSimbolo\nValore\n\n\n\n\\(\\mu_0\\)\n500 ms\n\n\n\\(\\sigma_0\\)\n100 ms\n\n\n\\(\\sigma\\)\n50 ms\n\n\n\\(n\\)\n20\n\n\n\\(\\bar y\\)\n480 ms\n\n\n\n\n\nPesi\n\\[\n\\frac{1}{\\sigma_0^{2}}=\\frac{1}{100^{2}}=0.0001,\\quad\n\\frac{n}{\\sigma^{2}}=\\frac{20}{50^{2}}=0.008\n\\]\n\n\nMedia a posteriori\n\\[\n\\mu_p=\\frac{0.0001\\cdot500 + 0.008\\cdot480}{0.0081}\\approx 480.2\\text{ ms}\n\\]\n\n\nVarianza a posteriori\n\\[\n\\sigma_p^{2}=\\frac{1}{0.0081}\\approx 123\n\\implies \\sigma_p\\approx 11\\text{ ms}\n\\]\n\n\nRisultato: da circa \\(\\mu\\approx500\\pm100\\) ms a circa \\(\\mu\\approx480\\pm11\\) ms. Un salto enorme di precisione dopo sole 20 osservazioni.\n\n\n\n\n\n\nMessaggi chiave\n\n\n\n\nBayes è un dialogo fra ipotesi e dati.\nCon varianza nota i conti sono lineari e si fanno a mano.\nL’incertezza può solo scendere dopo aver visto i dati.\nCon pochi dati o molto rumore la prior pesa tanto; con molti dati precisi quasi scompare.\nLo stesso schema si applica a moltissimi problemi di psicologia sperimentale come tempi di reazione, punteggi o ampiezze EEG.\n\n\n\n\n# ---- Parametri dell'esempio -------------------------------------------\nmu0    &lt;- 500   # Media a priori (intuizione iniziale)\nsigma0 &lt;- 100   # Deviazione standard a priori (quanto siamo incerti)\nsigma  &lt;-  50   # Deviazione standard nota (errore di misura)\nn      &lt;-  20   # Dimensione del campione\nybar   &lt;- 480   # Media campionaria osservata\n\n# ---- Calcolo dei parametri a posteriori -------------------------------\nsigma_p2 &lt;- 1 / (1 / sigma0^2 + n / sigma^2)    # Varianza a posteriori\nsigma_p  &lt;- sqrt(sigma_p2)                      # Deviazione standard a posteriori\nmu_p     &lt;- (mu0 / sigma0^2 + n * ybar / sigma^2) /\n            (1 / sigma0^2 + n / sigma^2)        # Media a posteriori\n\n# ---- Griglia di valori per il parametro mu -----------------------------\nmu_grid &lt;- seq(400, 600, length.out = 1000)\n\n# ---- Calcolo delle densità delle tre curve -----------------------------\nprior_dens &lt;- dnorm(mu_grid, mean = mu0,  sd = sigma0)    # Densità a priori\npost_dens  &lt;- dnorm(mu_grid, mean = mu_p, sd = sigma_p)   # Densità a posteriori\n\n# Verosimiglianza (scalata per confrontabilità grafica)\nlik_prop &lt;- dnorm(mu_grid, mean = ybar, sd = sigma / sqrt(n))\nlik_dens &lt;- lik_prop * max(prior_dens) / max(lik_prop)\n\n# ---- Preparazione dati in formato \"lungo\" per ggplot2 ------------------\ndf &lt;- tibble(\n  mu         = mu_grid,\n  Prior      = prior_dens,\n  Likelihood = lik_dens,\n  Posterior  = post_dens\n)\n\ndf_long &lt;- pivot_longer(df, -mu, names_to = \"Curve\", values_to = \"Density\")\n\n# ---- Grafico delle distribuzioni ---------------------------------------\nggplot(df_long, aes(x = mu, y = Density, colour = Curve)) +\n  geom_line(linewidth = 1) +\n  labs(\n    x     = expression(mu),\n    y     = \"Densità (unità arbitrarie)\",\n    title = \"Distribuzioni a priori, verosimiglianza (riscalata)\\ne distribuzione a posteriori\"\n  ) +\n  theme(legend.title = element_blank())\n\n\n\n\n\n\n\n\n\nEsempio 52.2 I test standard di QI sono progettati per misurare l’intelligenza con una media di 100 e una deviazione standard di 15. Tuttavia, si dice anche che questi test presentino bias culturali che favoriscono alcuni gruppi rispetto ad altri. Un’ulteriore complicazione si verifica quando i punteggi di QI vengono aggregati a livello nazionale, poiché le caratteristiche interne ai paesi vengono mascherate. Questo esempio analizza i dati di QI raccolti a livello internazionale (Lynn e Vanhanen, 2001) per 80 paesi da fonti nazionali pubblicate e discussi da Gill (2015). L’idea chiave nella descrizione della distribuzione a posteriori è se le differenze tra le nazioni alterano la parametrizzazione prevista.\nI dati di Lynn e Vanhanen (2001) sono forniti di seguito:\n\n\n\n\n\n\n\n\n\n\n\n\nPaese\nIQ\nPaese\nIQ\nPaese\nIQ\nPaese\nIQ\n\n\n\nArgentina\n96\nAustralia\n98\nAustria\n102\nBarbados\n78\n\n\nBelgium\n100\nBrazil\n87\nBulgaria\n93\nCanada\n97\n\n\nChina\n100\nCongo (Br.)\n73\nCongo (Zr.)\n65\nCroatia\n90\n\n\nCuba\n85\nCzech Repub.\n97\nDenmark\n98\nEcuador\n80\n\n\nEgypt\n83\nEq. Guinea\n59\nEthiopia\n63\nFiji\n84\n\n\nFinland\n97\nFrance\n98\nGermany\n102\nGhana\n71\n\n\nGreece\n92\nGuatemala\n79\nGuinea\n66\nHong Kong\n107\n\n\nHungary\n99\nIndia\n81\nIndonesia\n89\nIran\n84\n\n\nIraq\n87\nIreland\n93\nIsrael\n94\nItaly\n102\n\n\nJamaica\n72\nJapan\n105\nKenya\n72\nKorea (S.)\n106\n\n\nLebanon\n86\nMalaysia\n92\nMarshall I.\n84\nMexico\n87\n\n\nMorocco\n85\nNepal\n78\nNetherlands\n102\nNew Zealand\n100\n\n\nNigeria\n67\nNorway\n98\nPeru\n90\nPhilippines\n86\n\n\nPoland\n99\nPortugal\n95\nPuerto Rico\n84\nQatar\n78\n\n\nRomania\n94\nRussia\n96\nSamoa\n87\nSierra Leone\n64\n\n\nSingapore\n103\nSlovakia\n96\nSlovenia\n95\nSouth Africa\n72\n\n\nSpain\n97\nSudan\n72\nSuriname\n89\nSweden\n101\n\n\nSwitzerland\n101\nTaiwan\n104\nTanzania\n72\nThailand\n91\n\n\nTonga\n87\nTurkey\n90\nUganda\n73\nU.K.\n100\n\n\nU.S.\n98\nUruguay\n96\nZambia\n77\nZimbabwe\n66\n\n\n\nImplementiamo le informazioni necessarie in R.\n\n# Dati IQ delle 80 nazioni\niq &lt;- c(\n  96, 100, 100, 85, 83, 97, 92, 99, 87, 72, 86, 85, 67, 99, 94, 103, 97, 101, \n  87, 98, 87, 73, 97, 59, 98, 79, 81, 93, 105, 92, 78, 98, 95, 96, 72, 104, \n  90, 96, 98, 102, 78, 90, 63, 84, 84, 107, 86, 102, 106, 94, 102, 72, 101, \n  89, 72, 101, 91, 100, 100, 66, 107, 86, 78, 84, 78, 64, 72, 101, 91, 100, \n  67, 86\n)\n\n\n# Numero di osservazioni\nn &lt;- length(iq)\n\n# Media campionaria\ny_bar &lt;- mean(iq)\n\n# Deviazione standard nota\nsigma &lt;- 15\n\n# Parametri a priori\nmu_0 &lt;- 100\nsigma_0 &lt;- 15\n\nCalcoliamo la media a posteriori con la formula discussa in precedenza\n\\[\n\\mu_p = \\frac{\\frac{1}{\\sigma_0^2}\\mu_0 + \\frac{n}{\\sigma^2}\\bar{y}}{\\frac {1}{\\sigma_0^2} + \\frac{n}{\\sigma^2}}\n\\]\ndove:\n\n\n\\(\\mu_0\\) è la media a priori\n\n\\(\\sigma_0\\) è la deviazione standard a priori\n\n\\(n\\) è il numero di osservazioni\n\n\\(\\sigma\\) è la deviazione standard delle osservazioni (nota)\n\n\\(\\bar{y}\\) è la media campionaria\n\n\nmu_p &lt;- ((1 / sigma_0^2) * mu_0 + (n / sigma^2) * y_bar) /\n  ((1 / sigma_0^2) + (n / sigma^2))\nprint(paste(\"Media a posteriori (mu_p):\", round(mu_p, 2)))\n#&gt; [1] \"Media a posteriori (mu_p): 89.36\"\n\nCalcoliamo la varianza a posteriori\n\\[\n\\sigma_p^2 = \\frac{1}{\\frac {1}{\\sigma_0^2}+ \\frac{n}{\\sigma^2}}\n\\]\n\nsigma_p_sq &lt;- 1 / ((1 / sigma_0^2) + (n / sigma^2))\nsigma_p &lt;- sqrt(sigma_p_sq)\nprint(paste(\"Varianza a posteriori (sigma_p_sq):\", round(sigma_p_sq, 2)))\n#&gt; [1] \"Varianza a posteriori (sigma_p_sq): 3.08\"\n\nGeneriamo una rappresentazione grafica della distribuzione a posteriori della media del IQ sulla base dei dati osservati, avendo assunto mu_0 = 100 e sigma_0 = 15 per la distribuzione a priori.\n\n# Definizione dei valori sull'asse x\nx &lt;- seq(mu_p - 4 * sigma_p, mu_p + 4 * sigma_p, length.out = 1000)\n\n# Calcolo della densità di probabilità\npdf &lt;- dnorm(x, mean = mu_p, sd = sigma_p)\n\n# Creazione del grafico\nggplot(data.frame(x = x, pdf = pdf), aes(x = x, y = pdf)) +\n  geom_line(color = \"blue\", linewidth = 1) +\n  geom_area(aes(fill = \"Posterior\"), alpha = 0.2) +\n  scale_fill_manual(values = c(\"blue\")) +\n  labs(\n    x = \"Media del Quoziente di Intelligenza\",\n    y = \"Densità di probabilità\"\n  ) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\nL’analisi condotta mediante un modello bayesiano basato sulla distribuzione normale ha prodotto un risultato interessante: la media stimata della distribuzione a posteriori del QI si attesta a 89.36, un valore sensibilmente inferiore ai 100 punti previsti come media standard.\nTuttavia, per un’interpretazione completa di questo dato, è fondamentale adottare un approccio critico che consideri alcuni aspetti cruciali:\n\nLa media a posteriori è ottenuta aggregando i dati QI di 80 nazioni diverse. Questo processo può innescare un effetto di aggregazione, dove la media “smussata” risultante non rispecchia accuratamente la distribuzione del QI a livello individuale in ogni singola nazione. Di conseguenza, le differenze tra le nazioni in termini di QI medio e variabilità potrebbero essere mascherate da questa media aggregata.\nÈ importante sottolineare che la media a posteriori viene calcolata utilizzando dati non ponderati per ogni nazione. Ciò significa che nazioni con popolazioni più piccole, anche se con punteggi QI mediamente più alti o più bassi, hanno lo stesso impatto sulla media aggregata rispetto a nazioni con popolazioni più grandi. Questo aspetto potrebbe ulteriormente distorcere la rappresentazione della vera distribuzione globale del QI.\nLa deviazione osservata dalla media standard di 100 potrebbe non riflettere esclusivamente differenze nell’intelligenza media tra le nazioni, ma anche differenze nei contesti sanitari, sociologici e politici in cui i test sono stati somministrati. Fattori quali l’accesso all’istruzione, la qualità della nutrizione e l’esposizione a stimoli cognitivi possono influenzare i punteggi QI ottenuti e contribuire alla variabilità osservata tra le nazioni.\nInoltre, è fondamentale considerare la possibilità di un bias culturale intrinseco allo strumento stesso. I test del QI sono stati originariamente progettati per un contesto specifico (paese industrializzato di lingua inglese) e potrebbero non essere adatti o culturalmente sensibili a contesti differenti. Questo potrebbe portare a una sottostima dei punteggi QI in alcune nazioni e influenzare la media a posteriori aggregata.\n\nQuesti risultati evidenziano l’importanza di un’attenta considerazione dei fattori metodologici quando si interpretano dati di test del QI a livello trans-culturale. L’effetto di aggregazione, l’utilizzo di medie non ponderate, le differenze nei contesti e il potenziale bias culturale richiedono un’analisi più approfondita che consideri questi fattori e utilizzi metodi statistici più sofisticati per ottenere una comprensione più completa delle differenze nel QI tra le nazioni.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_conjugate_families_2.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/08_conjugate_families_2.html#riflessioni-conclusive",
    "title": "52  Distribuzioni coniugate (2)",
    "section": "\n52.4 Riflessioni Conclusive",
    "text": "52.4 Riflessioni Conclusive\nIn questo capitolo, abbiamo approfondito il meccanismo dell’aggiornamento bayesiano attraverso l’implementazione del modello normale-normale. Il processo inizia definendo una distribuzione a priori per \\(\\mu\\), specificata da una media \\(\\mu_0\\) e una varianza \\(\\sigma_0^2\\). Dopo l’acquisizione di nuovi dati, ipotizzando che seguano una distribuzione Normale con media campionaria \\(\\bar{y}\\) e varianza nota \\(\\sigma^2\\), implementiamo il teorema normale-normale per derivare la distribuzione a posteriori del parametro.\nLa media della distribuzione a posteriori, denotata come \\(\\mu_{\\text{post}}\\), si configura come una media ponderata tra la media a priori \\(\\mu_0\\) e la media campionaria \\(\\bar{y}\\), dove il peso assegnato a ciascuna media è determinato dalle rispettive varianze \\(\\sigma_0^2\\) e \\(\\sigma^2\\) della distribuzione a priori e dei dati osservati. Analogamente, la varianza a posteriori \\(\\sigma_{\\text{post}}^2\\) è determinata utilizzando un’espressione che incorpora entrambe le varianze.\nIn sintesi, l’adozione del modello normale-normale in un contesto bayesiano facilita il calcolo delle distribuzioni a posteriori, grazie alla scelta di una distribuzione a priori Normale che mantiene la proprietà di coniugatezza, semplificando così l’intero processo analitico.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_conjugate_families_2.html#esercizi",
    "href": "chapters/bayesian_inference/08_conjugate_families_2.html#esercizi",
    "title": "52  Distribuzioni coniugate (2)",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nRiprendi i dati della SWLS che sono stati utilizzati nell’esercizio del Capitolo 50. Trova la media e la deviazione standard della distribuzione a posteriori usando il metodo delle distribuzioni coniugate. Confronta i risultati con quelli ottenuti con il metodo basato su griglia.\nConsegna: Carica il file .qmd, convertito in PDF, su Moodle.\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\nPer risolvere questo esercizio con il metodo delle distribuzioni coniugate, assumiamo che i dati provengano da una distribuzione normale con deviazione standard nota e media da stimare. Nel caso di una verosimiglianza gaussiana con prior gaussiano, la distribuzione a posteriori sarà ancora una distribuzione normale. Questo approccio è analitico e ci permette di ottenere la media e la deviazione standard della distribuzione a posteriori senza dover ricorrere a metodi numerici come la discretizzazione della griglia.\nPassaggi per il calcolo della distribuzione a posteriori\n\n\nDefiniamo i dati osservati:\n\nLa media campionaria: \\(\\bar{x}\\)\n\nLa deviazione standard nota dei dati: \\(\\sigma\\)\n\nIl numero di osservazioni: \\(n\\)\n\n\n\n\nScegliamo un prior gaussiano molto diffuso:\n\nMedia a priori: \\(\\mu_0\\)\n\nDeviazione standard a priori molto grande: \\(\\sigma_0\\)\n\n\n\n\nCalcoliamo la media e la varianza della distribuzione a posteriori:\n\n\nLa media a posteriori è:\n\\[\n\\mu_{\\text{post}} = \\frac{\\sigma^2_0 \\bar{x} + \\sigma^2 n \\mu_0}{\\sigma^2_0 + \\sigma^2 n}\n\\]\n\n\nLa varianza a posteriori è:\n\\[\n\\sigma^2_{\\text{post}} = \\frac{\\sigma^2_0 \\sigma^2}{\\sigma^2_0 + \\sigma^2 n}\n\\]\n\n\n\n\nImplementazione in R\n# Caricamento librerie necessarie\nlibrary(dplyr)\nlibrary(tibble)\n\n# Dati SWLS\nswls_data &lt;- data.frame(\n  soddisfazione = c(4.2, 5.1, 4.7, 4.3, 5.5, 4.9, 4.8, 5.0, 4.6, 4.4)\n)\n\n# Parametri comuni per entrambi i metodi\nsigma_conosciuta &lt;- sd(swls_data$soddisfazione)  # Usando la deviazione standard campionaria\nn &lt;- nrow(swls_data)\nmean_x &lt;- mean(swls_data$soddisfazione)\n\ncat(\"Deviazione standard campionaria:\", sigma_conosciuta, \"\\n\")\ncat(\"Media campionaria:\", mean_x, \"\\n\")\n\n# ---- Metodo 1: Griglia ----\n# Definizione della griglia più fine e centrata intorno alla media campionaria\nmu_griglia &lt;- seq(mean_x - 3*sigma_conosciuta/sqrt(n), \n                 mean_x + 3*sigma_conosciuta/sqrt(n), \n                 length.out = 1000)\n\n# Calcolo della verosimiglianza\nlog_likelihood &lt;- numeric(length(mu_griglia))\nfor (i in seq_along(mu_griglia)) {\n  # Utilizzo della log-likelihood per evitare problemi numerici\n  log_likelihood[i] &lt;- sum(dnorm(swls_data$soddisfazione, \n                                mean = mu_griglia[i], \n                                sd = sigma_conosciuta, \n                                log = TRUE))\n}\n\n# Prior uniforme (in scala logaritmica)\nlog_prior &lt;- rep(0, length(mu_griglia))\n\n# Calcolo della posteriori\nlog_posterior &lt;- log_likelihood + log_prior\nposterior &lt;- exp(log_posterior - max(log_posterior))\nposterior &lt;- posterior / sum(posterior)\n\n# Campionamento e calcolo statistiche\nsamples_grid &lt;- sample(mu_griglia, size = 10000, replace = TRUE, prob = posterior)\nmean_post_grid &lt;- mean(samples_grid)\nsd_post_grid &lt;- sd(samples_grid)\nci_grid &lt;- quantile(samples_grid, c(0.03, 0.97))\n\n# ---- Metodo 2: Soluzione analitica ----\n# Prior poco informativo ma non improprio\nmu_prior &lt;- mean_x\nsigma_prior &lt;- 10\n\n# Calcolo posteriori\nmu_post_analytic &lt;- (sigma_prior^2 * mean_x + sigma_conosciuta^2 * mu_prior/n) / \n                    (sigma_prior^2 + sigma_conosciuta^2/n)\nsigma_post_analytic &lt;- sqrt((sigma_prior^2 * sigma_conosciuta^2/n) / \n                           (sigma_prior^2 + sigma_conosciuta^2/n))\n\n# Confronto risultati\nresults &lt;- tibble(\n  Metodo = c(\"Griglia\", \"Analitico\"),\n  `Media Posteriori` = c(mean_post_grid, mu_post_analytic),\n  `Dev. Std. Posteriori` = c(sd_post_grid, sigma_post_analytic)\n)\nresults\nInterpretazione dei risultati\n\nLa media a posteriori rappresenta la miglior stima aggiornata della media della popolazione dopo aver osservato i dati.\nLa deviazione standard a posteriori ci dice quanto è incerta la nostra stima della media dopo aver integrato i dati e il prior.\n\nSiccome abbiamo scelto un prior molto diffuso (\\(\\sigma_0 = 10\\)), il risultato ottenuto è molto vicino a quello ottenuto con il metodo della griglia, dove il prior uniforme aveva un impatto minimo sulla distribuzione a posteriori.\nQuesta implementazione analitica permette di ottenere il risultato in modo efficiente senza necessità di metodi numerici approssimati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_conjugate_families_2.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/08_conjugate_families_2.html#informazioni-sullambiente-di-sviluppo",
    "title": "52  Distribuzioni coniugate (2)",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.17.0      thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0\n#&gt;  [5] see_0.11.0       gridExtra_2.3    patchwork_1.3.0  bayesplot_1.12.0\n#&gt;  [9] psych_2.5.3      scales_1.4.0     markdown_2.0     knitr_1.50      \n#&gt; [13] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [17] purrr_1.0.4      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [21] ggplot2_3.5.2    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1   farver_2.1.2       fastmap_1.2.0     \n#&gt;  [4] pacman_0.5.1       digest_0.6.37      rpart_4.1.24      \n#&gt;  [7] timechange_0.3.0   lifecycle_1.0.4    survival_3.8-3    \n#&gt; [10] magrittr_2.0.3     compiler_4.5.0     rlang_1.1.6       \n#&gt; [13] tools_4.5.0        labeling_0.4.3     htmlwidgets_1.6.4 \n#&gt; [16] mnormt_2.1.1       RColorBrewer_1.1-3 withr_3.0.2       \n#&gt; [19] nnet_7.3-20        grid_4.5.0         jomo_2.7-6        \n#&gt; [22] iterators_1.0.14   MASS_7.3-65        cli_3.6.5         \n#&gt; [25] rmarkdown_2.29     reformulas_0.4.1   generics_0.1.4    \n#&gt; [28] rstudioapi_0.17.1  tzdb_0.5.0         minqa_1.2.8       \n#&gt; [31] splines_4.5.0      parallel_4.5.0     vctrs_0.6.5       \n#&gt; [34] boot_1.3-31        glmnet_4.1-8       Matrix_1.7-3      \n#&gt; [37] jsonlite_2.0.0     hms_1.1.3          mitml_0.4-5       \n#&gt; [40] foreach_1.5.2      glue_1.8.0         nloptr_2.2.1      \n#&gt; [43] pan_1.9            codetools_0.2-20   stringi_1.8.7     \n#&gt; [46] shape_1.4.6.1      gtable_0.3.6       lme4_1.1-37       \n#&gt; [49] pillar_1.10.2      htmltools_0.5.8.1  R6_2.6.1          \n#&gt; [52] Rdpack_2.6.4       rprojroot_2.0.4    evaluate_1.0.3    \n#&gt; [55] lattice_0.22-7     rbibutils_2.3      backports_1.5.0   \n#&gt; [58] broom_1.0.8        Rcpp_1.0.14        nlme_3.1-168      \n#&gt; [61] xfun_0.52          pkgconfig_2.0.3",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_conjugate_families_2.html#bibliografia",
    "href": "chapters/bayesian_inference/08_conjugate_families_2.html#bibliografia",
    "title": "52  Distribuzioni coniugate (2)",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGill, J. (2015). Bayesian methods: A social and behavioral sciences approach (3rd Edition). Chapman; Hall/CRC.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_summary_posterior.html",
    "href": "chapters/bayesian_inference/09_summary_posterior.html",
    "title": "53  Sintesi a posteriori",
    "section": "",
    "text": "53.1 Introduzione\nIn questo capitolo, concentriamo la nostra attenzione sulla sintesi dell’informazione racchiusa nella distribuzione a posteriori, la quale rappresenta il nostro livello di incertezza riguardo al parametro o ai parametri incogniti oggetto dell’inferenza.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_summary_posterior.html#riepilogo-numerico",
    "href": "chapters/bayesian_inference/09_summary_posterior.html#riepilogo-numerico",
    "title": "53  Sintesi a posteriori",
    "section": "\n53.2 Riepilogo numerico",
    "text": "53.2 Riepilogo numerico\nLa distribuzione a posteriori contiene in sé tutte le informazioni disponibili sui potenziali valori del parametro. Nel caso di un parametro unidimensionale o bidimensionale, possiamo rappresentare la distribuzione a posteriori mediante un grafico \\(p(\\theta \\mid y)\\).\nTuttavia, quando ci troviamo di fronte a vettori di parametri con più di due dimensioni, risulta vantaggioso eseguire una sintesi numerica della distribuzione a posteriori. Possiamo distinguere due forme di sintesi numerica della distribuzione a posteriori:\n\nStima puntuale;\nIntervallo di credibilità.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_summary_posterior.html#stima-puntuale",
    "href": "chapters/bayesian_inference/09_summary_posterior.html#stima-puntuale",
    "title": "53  Sintesi a posteriori",
    "section": "\n53.3 Stima puntuale",
    "text": "53.3 Stima puntuale\nNel contesto dell’inferenza bayesiana, stimare il valore più credibile di un parametro \\(\\theta\\) a partire dalla distribuzione a posteriori può avvenire attraverso tre statistiche principali: moda, mediana e media. La scelta tra queste dipende dalla forma della distribuzione a posteriori.\nQueste statistiche forniscono una stima puntuale della tendenza centrale della distribuzione, ossia il valore a cui attribuiamo il massimo grado di fiducia soggettiva, basandoci sia sui dati osservati sia sulle credenze a priori.\n1. Moda (Massimo a Posteriori, MAP)\nLa moda è il valore più probabile del parametro, ovvero quello che massimizza la distribuzione a posteriori. Questo valore è noto come massimo a posteriori (MAP).\nIl concetto di MAP deriva dalla stima di massima verosimiglianza (MLE), che individua il valore di \\(\\theta\\) che massimizza la funzione di verosimiglianza:\n\\[\n\\hat{\\theta}_{ML} = \\arg \\max_\\theta L(\\theta \\mid y).  \n\\]\nNell’inferenza bayesiana, consideriamo \\(\\theta\\) come una variabile casuale con una distribuzione a priori \\(p(\\theta)\\). Incorporando questa informazione nella funzione di verosimiglianza, otteniamo la stima MAP:\n\\[\n\\hat{\\theta}_{MAP} = \\arg \\max_\\theta L(\\theta \\mid y)p(\\theta).  \n\\]\nQuesta formula mostra che il MAP è il valore che massimizza la densità a posteriori di \\(\\theta\\) dato il set di dati osservati \\(y\\).\nLimitazioni della stima MAP:\n\n\nDifficoltà computazionali: con metodi MCMC, è complesso individuare con precisione il MAP nello spazio delle distribuzioni posteriori.\n\n\nSensibilità alla forma della distribuzione: se la distribuzione a posteriori è asimmetrica o multimodale, il MAP potrebbe non rappresentare adeguatamente la tendenza centrale.\n\n\nMinor robustezza rispetto ad altre misure: il MAP si basa esclusivamente sul valore massimo della distribuzione e non tiene conto della distribuzione complessiva della probabilità.\n2. Media a posteriori\nLa media a posteriori è il valore atteso di \\(\\theta\\) secondo la distribuzione a posteriori:\n\\[\nE(\\theta \\mid y) = \\int_{-\\infty}^{\\infty} \\theta \\, p(\\theta \\mid y) \\, d\\theta.  \n\\]\nQuesta stima è spesso preferita perché considera l’intera distribuzione e minimizza l’errore quadratico medio (Mean Squared Error, MSE). Tuttavia, se la distribuzione a posteriori è asimmetrica, la media potrebbe non rappresentare bene la posizione della maggior parte della probabilità.\n3. Mediana a posteriori\nLa mediana a posteriori è il valore che divide la distribuzione a posteriori in due parti uguali, con il 50% della probabilità a sinistra e il 50% a destra.\nLa mediana è una stima robusta della tendenza centrale ed è particolarmente utile in distribuzioni asimmetriche o multimodali, dove la moda e la media potrebbero risultare fuorvianti.\nMisurare l’incertezza: varianza a posteriori\nOltre a stimare la tendenza centrale, è utile valutare l’incertezza associata alla stima di \\(\\theta\\). La varianza a posteriori misura la dispersione della distribuzione:\n\\[\nV(\\theta|y) = E[((\\theta - E[(\\theta|y)])^2 |y) = \\int_{-\\infty}^{\\infty} (\\theta - E[\\theta | y])^2 p(\\theta | y) d\\theta = E[\\theta^2 |y] - E[\\theta|y]^2.  \n\\]\nLa deviazione standard a posteriori (radice quadrata della varianza) esprime l’incertezza sulla stima \\(\\theta\\) con la stessa unità di misura dei dati.\nIn sintesi, la moda (MAP), la media e la mediana a posteriori offrono diverse prospettive sulla stima puntuale di un parametro \\(\\theta\\). Ciascuna ha vantaggi e limiti, e la scelta migliore dipende dalla forma della distribuzione a posteriori e dal contesto applicativo.\nInsieme alla varianza a posteriori, queste statistiche forniscono un quadro completo della distribuzione a posteriori, permettendo di esprimere non solo la stima più credibile, ma anche l’incertezza associata.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_summary_posterior.html#intervallo-di-credibilità",
    "href": "chapters/bayesian_inference/09_summary_posterior.html#intervallo-di-credibilità",
    "title": "53  Sintesi a posteriori",
    "section": "\n53.4 Intervallo di credibilità",
    "text": "53.4 Intervallo di credibilità\nNell’inferenza bayesiana, l’intervallo di credibilità è uno strumento utilizzato per definire un intervallo che contiene una determinata percentuale della massa della distribuzione a posteriori del parametro \\(\\theta\\). Questo intervallo riflette l’incertezza associata alla stima del parametro: un intervallo più ampio suggerisce una maggiore incertezza. Lo scopo principale dell’intervallo di credibilità è fornire una misura quantitativa dell’incertezza riguardante \\(\\theta\\).\nA differenza degli intervalli di confidenza frequentisti, non esiste un unico intervallo di credibilità per un dato livello di confidenza \\((1 - \\alpha) \\cdot 100\\%\\). In effetti, è possibile costruire un numero infinito di tali intervalli. Per questo motivo, è necessario stabilire criteri aggiuntivi per selezionare l’intervallo di credibilità più appropriato. Tra le opzioni più comuni ci sono l’intervallo di credibilità simmetrico e l’intervallo di massima densità posteriore (HPD).\n1. Intervallo di Credibilità Simmetrico\nQuesto tipo di intervallo è centrato rispetto al punto di stima puntuale. Se \\(\\hat{\\theta}\\) rappresenta la stima del parametro, l’intervallo simmetrico avrà la forma \\((\\hat{\\theta} - a, \\hat{\\theta} + a)\\), dove \\(a\\) è un valore positivo scelto in modo tale che la massa totale inclusa sia pari a \\((1 - \\alpha)\\). Più formalmente, un intervallo di credibilità simmetrico al livello \\(\\alpha\\) può essere espresso come:\n\\[\nI_{\\alpha} = [q_{\\alpha/2}, q_{1 - \\alpha/2}],\n\\]\ndove \\(q_z\\) rappresenta il quantile \\(z\\) della distribuzione a posteriori. Ad esempio, un intervallo di credibilità simmetrico al 94% sarà:\n\\[\nI_{0.06} = [q_{0.03}, q_{0.97}],\n\\]\ndove il 3% della massa a posteriori si trova in ciascuna delle due code della distribuzione.\n2. Intervallo di Credibilità Più Stretto (Intervallo di Massima Densità Posteriore, HPD)\nL’intervallo di massima densità posteriore (HPD) è l’intervallo più stretto possibile che contiene il \\((1 - \\alpha) \\cdot 100\\%\\) della massa a posteriori. A differenza dell’intervallo simmetrico, l’HPD include tutti i valori di \\(\\theta\\) che hanno la maggiore densità a posteriori. Per costruirlo, si disegna una linea orizzontale sulla distribuzione a posteriori e si regola l’altezza della linea in modo che l’area sotto la curva corrisponda a \\((1 - \\alpha)\\). L’HPD risulta essere il più stretto tra tutti gli intervalli possibili per lo stesso livello di confidenza. Nel caso di una distribuzione a posteriori unimodale e simmetrica, l’HPD coincide con l’intervallo di credibilità simmetrico.\n\n53.4.1 Interpretazione\nIl calcolo degli intervalli di credibilità—in particolare dell’intervallo di massima densità posteriore (HPD)—richiede quasi sempre l’utilizzo di software statistici specializzati. Questo perché, nei modelli bayesiani con distribuzioni posteriori articolate o che richiedono simulazioni numeriche (ad esempio tramite Markov Chain Monte Carlo), ricavare a mano i confini dell’intervallo può risultare molto laborioso.\n\n53.4.1.1 1. Incertezza nel paradigma frequentista\n\n\nParametro fisso: nel contesto frequentista, il parametro di interesse (ad esempio la media di popolazione \\(\\mu\\)) è un valore costante ma sconosciuto.\n\n\nRipetizione ipotetica: immaginiamo di ripetere all’infinito il prelievo di campioni dalla popolazione. Per ciascun campione otteniamo una media \\(\\bar{x}\\) e costruendo un intervallo di confidenza al \\(100(1-\\alpha)\\%\\) avremo che, nel lungo periodo, il \\(100(1-\\alpha)\\%\\) di questi intervalli conterrà il vero \\(\\mu\\).\n\n\nInterpretazione del singolo intervallo: per un singolo intervallo calcolato, la probabilità che contenga effettivamente \\(\\mu\\) è formalmente 0 o 1, perché \\(\\mu\\) non è soggetto a variabilità stocastica—siamo semplicemente ignari del suo valore reale.\n\n53.4.1.2 2. Incertezza nel paradigma bayesiano\n\n\nParametro come variabile aleatoria: qui \\(\\mu\\) non è più un valore fisso, ma possiede una distribuzione di probabilità che riflette sia l’informazione a priori sia quella fornita dai dati osservati.\n\n\nCampionamento dalla distribuzione a posteriori: grazie a tecniche di simulazione (ad es. MCMC), otteniamo un insieme di possibili valori di \\(\\mu\\) che segue la distribuzione posteriore.\n\n\nCostruzione diretta dell’intervallo: scegliendo i quantili al \\(2.5\\%\\) e al \\(97.5\\%\\) di questa distribuzione, otteniamo un intervallo di credibilità al 95%. In termini intuitivi, possiamo affermare che «c’è una probabilità del 95% che \\(\\mu\\) cada all’interno di questo intervallo, dati i dati e le ipotesi a priori».\n\n53.4.1.3 3. Confronto e considerazioni\n\n\nFrequentista: l’intervallo di confidenza è un costrutto legato alla frequenza di lungo periodo di un procedimento ipotetico di campionamento.\n\n\nBayesiano: l’intervallo di credibilità fornisce una misura puntuale dell’incertezza sul parametro, direttamente comprensibile come probabilità condizionata sui dati osservati.\n\n\nIntuizione: per molti, l’interpretazione bayesiana risulta più aderente al senso comune, perché traduce immediatamente il grado di fiducia che possiamo riporre nei valori ipotizzati per il parametro.\n\nIn sintesi, mentre la teoria frequentista quantifica l’affidabilità del metodo di stima nel lungo periodo, l’approccio bayesiano esprime senza ambiguità la probabilità attuale che il parametro si trovi in un certo intervallo, alla luce delle evidenze e delle conoscenze pregresse.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_summary_posterior.html#verifica-di-ipotesi-bayesiana",
    "href": "chapters/bayesian_inference/09_summary_posterior.html#verifica-di-ipotesi-bayesiana",
    "title": "53  Sintesi a posteriori",
    "section": "\n53.5 Verifica di ipotesi bayesiana",
    "text": "53.5 Verifica di ipotesi bayesiana\nL’inferenza bayesiana può essere applicata anche nel contesto della verifica di ipotesi, in un approccio noto come verifica di ipotesi bayesiana. In questo tipo di inferenza, l’obiettivo è valutare la plausibilità che un parametro \\(\\theta\\) assuma valori all’interno di un determinato intervallo. Ad esempio, possiamo voler sapere quanto è probabile che \\(\\theta\\) sia maggiore di 0.5 o che rientri in un intervallo specifico, come [0.5, 1.0].\nIn questo approccio, si calcola la probabilità a posteriori che \\(\\theta\\) si trovi all’interno dell’intervallo di interesse. Questa probabilità viene ottenuta integrando la distribuzione a posteriori su tale intervallo. Quindi, invece di rifiutare o accettare un’ipotesi come nel test di ipotesi frequentista, la verifica di ipotesi bayesiana fornisce una misura diretta della probabilità che un parametro rientri in un intervallo specifico, dato l’evidenza osservata e le informazioni a priori.\nIn altre parole, questo approccio consente di quantificare la nostra incertezza rispetto all’affermazione che \\(\\theta\\) rientri in un certo intervallo, fornendo una probabilità che rappresenta direttamente la plausibilità di quell’ipotesi.\n\nEsempio 53.1 Per illustrare l’approccio bayesiano, consideriamo i dati relativi ai punteggi del BDI-II (Beck Depression Inventory - Second Edition) di 30 soggetti clinici, come riportato nello studio condotto da Zetsche et al. (2019). Il BDI-II è uno strumento per valutare la gravità dei sintomi depressivi.\nI punteggi del BDI-II per i 30 soggetti sono:\n\n# Dati del BDI-II\nbdi &lt;- c(\n  26, 35, 30, 25, 44, 30, 33, 43, 22, 43, \n  24, 19, 39, 31, 25, 28, 35, 30, 26, 31, \n  41, 36, 26, 35, 33, 28, 27, 34, 27, 22\n)\nbdi\n#&gt;  [1] 26 35 30 25 44 30 33 43 22 43 24 19 39 31 25 28 35 30 26 31 41 36 26 35\n#&gt; [25] 33 28 27 34 27 22\n\nUn punteggio BDI-II \\(\\geq 30\\) indica un livello grave di depressione. Nel nostro campione, 17 pazienti su 30 manifestano un livello grave:\n\n# Conteggio di depressione grave\nsum(bdi &gt;= 30)\n#&gt; [1] 17\n\nStima della distribuzione a posteriori.\nSupponiamo di voler stimare la probabilità \\(\\theta\\) di depressione grave nei pazienti clinici utilizzando una distribuzione a priori \\(Beta(8, 2)\\). I dati possono essere visti come una sequenza di prove Bernoulliane indipendenti, dove la presenza di depressione grave è un “successo”. La verosimiglianza è quindi binomiale con parametri \\(n = 30\\) e \\(y = 17\\).\nCon una distribuzione a priori \\(Beta(8, 2)\\), la distribuzione a posteriori di \\(\\theta\\) sarà:\n\\[\n\\text{Beta}(\\alpha = 8 + 17, \\beta = 2 + 30 - 17) = \\text{Beta}(25, 15).\n\\]\nTracciamo la distribuzione a posteriori.\n\n# Parametri della distribuzione Beta\nalpha &lt;- 25\nbeta &lt;- 15\n\n# Calcolo della densità per valori di theta\ntheta &lt;- seq(0, 1, length.out = 200)\nposterior_density &lt;- dbeta(theta, alpha, beta)\n\n# Grafico della distribuzione a posteriori\nggplot(data = data.frame(theta, posterior_density), aes(x = theta, y = posterior_density)) +\n  geom_line() +\n  labs(\n    title = \"Distribuzione a Posteriori Beta(25, 15)\",\n    x = expression(theta),\n    y = \"Densità di probabilità\"\n  ) \n\n\n\n\n\n\n\nStime puntuali.\n\n\nMedia a Posteriori\nLa media della distribuzione a posteriori è calcolata come:\n\n\\[\n\\mathbb{E}(\\theta | y = 17) = \\frac{\\alpha}{\\alpha + \\beta} = \\frac{25}{25 + 15} = 0.625.\n\\]\nIn R:\n\n# Calcolo della media a posteriori\nposterior_mean &lt;- alpha / (alpha + beta)\nposterior_mean\n#&gt; [1] 0.625\n\n\n\nModa a Posteriori (MAP)\nLa moda della distribuzione a posteriori è:\n\n\\[\nMo(\\theta | y = 17) = \\frac{\\alpha - 1}{\\alpha + \\beta - 2} = \\frac{25 - 1}{25 + 15 - 2} = 0.6316.\n\\]\nIn R:\n\n# Calcolo della moda a posteriori\nposterior_mode &lt;- (alpha - 1) / (alpha + beta - 2)\nposterior_mode\n#&gt; [1] 0.6316\n\n\n\nMediana a Posteriori\nLa mediana si ottiene utilizzando la funzione di distribuzione cumulativa inversa:\n\n\n# Calcolo della mediana a posteriori\nposterior_median &lt;- qbeta(0.5, alpha, beta)\nposterior_median\n#&gt; [1] 0.6271\n\nIntervallo di credibilità.\nL’intervallo di credibilità simmetrico al 94% è dato dai percentili 3% e 97%:\n\n# Intervallo di credibilità simmetrico al 94%\ncred_interval &lt;- qbeta(c(0.03, 0.97), alpha, beta)\ncred_interval\n#&gt; [1] 0.4781 0.7613\n\nPossiamo interpretare questo intervallo come segue: c’è una certezza soggettiva del 94% che \\(\\theta\\) sia compreso tra 0.478 e 0.761.\nVerifica di ipotesi bayesiana.\nInfine, calcoliamo la probabilità che \\(\\theta &gt; 0.5\\):\n\\[\nP(\\theta &gt; 0.5 | y = 17) = \\int_{0.5}^1 f(\\theta | y = 17) d\\theta.\n\\]\nIn R:\n\n# Probabilità P(theta &gt; 0.5)\nprob_theta_greater_0_5 &lt;- pbeta(0.5, alpha, beta, lower.tail = FALSE)\nprob_theta_greater_0_5\n#&gt; [1] 0.9459\n\nIn conclusione, utilizzando un approccio bayesiano, abbiamo stimato la distribuzione a posteriori di \\(\\theta\\), ottenuto stime puntuali e costruito intervalli di credibilità. Abbiamo inoltre calcolato la probabilità che \\(\\theta\\) superi una soglia specifica, mostrando la flessibilità e l’interpretabilità delle analisi bayesiane.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_summary_posterior.html#sintesi-della-distribuzione-a-posteriori-questioni-multivariate",
    "href": "chapters/bayesian_inference/09_summary_posterior.html#sintesi-della-distribuzione-a-posteriori-questioni-multivariate",
    "title": "53  Sintesi a posteriori",
    "section": "\n53.6 Sintesi della distribuzione a posteriori: questioni multivariate",
    "text": "53.6 Sintesi della distribuzione a posteriori: questioni multivariate\nQuando si affronta un’analisi bayesiana con più parametri, la complessità aumenta. Le principali difficoltà riguardano le interazioni tra i parametri e il modo in cui queste influenzano le distribuzioni marginali. Questi fattori possono complicare notevolmente la sintesi della distribuzione a posteriori e, se non considerati attentamente, possono portare a interpretazioni errate.\n\n53.6.1 Correlazioni nascoste e distribuzioni marginali\nUn problema comune nelle analisi con più parametri è rappresentato dalle correlazioni tra i parametri. Le distribuzioni marginali a posteriori, spesso riportate nei riassunti statistici, possono essere molto fuorvianti se considerate isolatamente. Quando i parametri sono fortemente correlati, le distribuzioni marginali possono apparire piatte o poco informative, inducendo a pensare che non ci sia molta informazione nella verosimiglianza.\nTuttavia, le correlazioni tra parametri possono restringere notevolmente lo spazio delle combinazioni plausibili, escludendo vaste aree dello spazio dei parametri. Questo significa che, nonostante le marginali possano sembrare non informative, l’analisi congiunta dei parametri può rivelare una struttura sottostante che riduce l’incertezza su specifiche combinazioni. Pertanto, è essenziale esaminare le correlazioni congiunte tra i parametri per ottenere una visione più completa dell’incertezza.\nCon un numero maggiore di parametri, anche i grafici di correlazione bidimensionali possono diventare limitati, poiché potrebbero esistere correlazioni di ordine superiore che non emergono in rappresentazioni a due dimensioni.\n\n53.6.2 Correlazioni non lineari\nUn’altra difficoltà significativa riguarda le correlazioni non lineari tra i parametri. Quando queste correlazioni sono presenti, il massimo delle distribuzioni marginali non coincide necessariamente con il massimo della distribuzione congiunta. Per esempio, se due parametri presentano una correlazione complessa, come una forma a “banana”, il massimo delle distribuzioni marginali potrebbe trovarsi in una posizione diversa rispetto al massimo globale della distribuzione congiunta.\nQuesto fenomeno rende più difficile sintetizzare correttamente la distribuzione a posteriori. In tali casi, la stima del massimo a posteriori (MAP) o altri riassunti, come gli intervalli di credibilità (CI) o gli intervalli di massima densità a posteriori (HPD), calcolati sulle marginali, potrebbero essere fuorvianti. Quando la distribuzione a posteriori è asimmetrica nello spazio multivariato, le distribuzioni marginali non catturano adeguatamente le relazioni tra i parametri. Questa è una fonte comune di confusione, poiché si tende a sottovalutare l’importanza della struttura multivariata nella distribuzione a posteriori.\n\n53.6.3 Strategie per affrontare queste sfide\n\n\nConfronto tra distribuzioni predittive:\n\nConfrontare la distribuzione predittiva a priori con quella a posteriori offre una visione più completa della riduzione dell’incertezza.\nQuesto approccio è particolarmente utile in presenza di parametri multipli e correlazioni complesse, poiché la distribuzione predittiva a posteriori incorpora le interazioni tra i parametri, fornendo una rappresentazione più accurata della plausibilità dei diversi valori parametrici.\n\n\n\nAnalisi congiunta:\n\nEsaminare le distribuzioni congiunte dei parametri, oltre alle distribuzioni marginali.\nUtilizzare grafici di dispersione bivariati o multivariati per visualizzare le relazioni tra i parametri.\nTecniche avanzate di visualizzazione, come i pair plots o le heatmap, possono essere utili per esplorare relazioni in spazi ad alta dimensionalità.\n\n\n\nMisure di dipendenza:\n\nUtilizzare misure di dipendenza non lineare, come la correlazione di Spearman o l’informazione mutua, che possono catturare relazioni complesse che le misure lineari tradizionali potrebbero non rilevare.\n\n\n\nAnalisi di sensibilità:\n\nCondurre un’analisi di sensibilità per valutare come i cambiamenti in un parametro influenzano gli altri parametri e le previsioni del modello. Questo permette di capire meglio le relazioni tra i parametri e il loro impatto sulle inferenze.\n\n\n\nTecniche di riduzione della dimensionalità:\n\nQuando ci sono molti parametri, l’uso di metodi come l’analisi delle componenti principali (PCA) può aiutare a identificare strutture latenti e ridurre la complessità del problema, facilitando l’interpretazione dei risultati.\n\n\n\nIn sintesi, l’analisi multivariata in un contesto bayesiano richiede particolare attenzione nella sintesi delle distribuzioni a posteriori. Le distribuzioni marginali possono fornire informazioni utili, ma spesso nascondono importanti correlazioni e strutture di dipendenza tra i parametri. Un’analisi completa dovrebbe combinare l’esame delle marginali con una valutazione attenta delle relazioni congiunte tra i parametri, utilizzando tecniche di visualizzazione e misure di dipendenza adeguate. Questo approccio integrato permette di comprendere più a fondo la distribuzione a posteriori e di trarre inferenze più robuste e accurate.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_summary_posterior.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/09_summary_posterior.html#riflessioni-conclusive",
    "title": "53  Sintesi a posteriori",
    "section": "\n53.7 Riflessioni Conclusive",
    "text": "53.7 Riflessioni Conclusive\nIn conclusione, la distribuzione a posteriori rappresenta la nostra conoscenza aggiornata sui parametri sconosciuti. L’impiego delle statistiche descrittive e l’analisi degli intervalli di credibilità contribuiscono a tracciare un quadro completo della distribuzione a posteriori e delle nostre inferenze riguardo al parametro di interesse.\nLe stime puntuali, ottenute attraverso statistiche descrittive come media, mediana o moda a posteriori, offrono una singola valutazione numerica del parametro ignoto. Gli intervalli di credibilità forniscono un intervallo di valori all’interno del quale si ritiene, con un certo grado di probabilità soggettiva, che il parametro incognito possa rientrare. Questi intervalli quantificano l’incertezza associata al parametro e consentono di esprimere il livello di fiducia soggettiva riguardo ai possibili valori del parametro dopo l’analisi dei dati. Abbiamo inoltre esaminato il concetto di test di ipotesi bayesiano, il quale può essere condotto agevolmente calcolando l’area appropriata sotto la distribuzione a posteriori, in accordo con l’ipotesi in questione.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_summary_posterior.html#esercizi",
    "href": "chapters/bayesian_inference/09_summary_posterior.html#esercizi",
    "title": "53  Sintesi a posteriori",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n1. Quali sono le principali statistiche utilizzate per la stima puntuale di un parametro nella distribuzione a posteriori?\n\nSpiega le differenze tra moda (MAP), media a posteriori e mediana.\nIn quali contesti è preferibile utilizzare una di queste statistiche rispetto alle altre?\n\n2. Qual è la differenza tra un intervallo di credibilità bayesiano e un intervallo di confidenza frequentista?\n\nSpiega le differenze concettuali tra i due approcci.\nQuale dei due è più intuitivo in termini di incertezza sui parametri?\n\n3. Cos’è un intervallo di massima densità posteriore (HPD) e in cosa si differenzia dall’intervallo di credibilità simmetrico?\n\nSpiega il concetto di HPD e perché è più informativo in alcuni casi.\nIn quali situazioni l’HPD è preferibile rispetto all’intervallo di credibilità simmetrico?\n\n4. Quali sono le problematiche associate alla moda (MAP) come stima puntuale?\n\nPerché il MAP può essere meno affidabile rispetto ad altre statistiche?\nQuali problemi si possono incontrare nei modelli bayesiani complessi?\n\n5. In che modo la sintesi della distribuzione a posteriori cambia nel caso di più parametri incogniti?\n\nQuali sono le principali difficoltà nell’interpretare la distribuzione congiunta di più parametri?\nCome si possono visualizzare e sintetizzare distribuzioni posteriori multivariate?\n\n📌 Domande applicative in R\nPer queste domande, usa il dataset basato sulla Satisfaction with Life Scale (SWLS), supponendo che i dati seguano una distribuzione normale.\n1. Calcola la media, la mediana e la moda a posteriori della distribuzione della media SWLS, assumendo una distribuzione a priori gaussiana molto diffusa. - Usa il metodo delle distribuzioni coniugate per ottenere la distribuzione a posteriori.\n2. Costruisci un intervallo di credibilità simmetrico al 94% per la media SWLS.\n\nUsa la distribuzione normale a posteriori per calcolare l’intervallo.\n\n3. Visualizza la distribuzione a posteriori della media SWLS con un grafico di densità.\n\nGenera un campione dalla distribuzione a posteriori e rappresentalo con ggplot2.\n\n4. Confronta l’intervallo di credibilità simmetrico con l’intervallo di massima densità posteriore (HPD).\n\nUsa la funzione hdi() del pacchetto bayestestR per calcolare l’HPD.\n\n5. Calcola la probabilità a posteriori che la media SWLS sia minore di 23.\n\nUsa la distribuzione a posteriori per calcolare questa probabilità.\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n1. Quali sono le principali statistiche utilizzate per la stima puntuale di un parametro nella distribuzione a posteriori?\nLe tre principali statistiche usate per ottenere una stima puntuale del parametro \\(\\theta\\) nella distribuzione a posteriori sono:\n\n\nModa (Massimo a Posteriori, MAP)\n\nÈ il valore di \\(\\theta\\) che massimizza la distribuzione a posteriori \\(p(\\theta \\mid y)\\).\n\nSe la distribuzione è unimodale e simmetrica, il MAP coincide con la media a posteriori.\n\nIl MAP è spesso simile alla stima di massima verosimiglianza (MLE) quando il prior è uniforme.\n\n\n\nMedia a Posteriori\n\nÈ il valore atteso della distribuzione a posteriori:\\[\nE(\\theta \\mid y) = \\int \\theta \\, p(\\theta \\mid y) \\, d\\theta\n\\]\n\nÈ la stima più utile quando si vuole minimizzare l’errore quadratico medio (MSE).\n\nRisente dell’eventuale asimmetria della distribuzione, spostandosi verso le code.\n\n\n\nMediana a Posteriori\n\nÈ il valore che divide la distribuzione a posteriori in due parti uguali:\\[\nP(\\theta \\leq \\theta_{\\text{mediana}} \\mid y) = 0.5\n\\]\n\nÈ più robusta agli outlier rispetto alla media ed è utile quando la distribuzione è fortemente asimmetrica.\n\n\n\n💡 Quando usarle? - Se la distribuzione è simmetrica, tutte e tre le statistiche coincidono. - Se la distribuzione è asimmetrica, la mediana è più robusta, la media può essere influenzata dalle code e il MAP è utile se si vuole un valore più probabile.\n2. Qual è la differenza tra un intervallo di credibilità bayesiano e un intervallo di confidenza frequentista?\n\n\n\n\n\n\n\nCaratteristica\nIntervallo di Credibilità (Bayesiano)\nIntervallo di Confidenza (Frequentista)\n\n\n\nSignificato\nEsprime la probabilità che il parametro sia nell’intervallo, dati i dati osservati.\nÈ una proprietà di un metodo di campionamento: se si ripetesse l’esperimento infinite volte, il \\((1 - \\alpha)100\\%\\) degli intervalli conterrebbe il vero valore del parametro.\n\n\nApproccio\nAssume che il parametro sia una variabile casuale con una distribuzione di probabilità.\nAssume che il parametro sia fisso e sconosciuto, mentre i dati sono casuali.\n\n\nInterpretazione\n“C’è il 95% di probabilità che il parametro sia tra questi valori.”\n“Se ripetessimo l’esperimento molte volte, il 95% degli intervalli conterrebbe il vero parametro.”\n\n\n\n💡 Differenza fondamentale:\n\nL’intervallo di credibilità è probabilistico e più intuitivo: si può direttamente dire che il parametro ha il 95% di probabilità di trovarsi nell’intervallo.\n\nL’intervallo di confidenza è basato sulla ripetizione ipotetica dell’esperimento e non può essere interpretato in termini probabilistici sul singolo intervallo.\n\n3. Cos’è un intervallo di massima densità posteriore (HPD) e in cosa si differenzia dall’intervallo di credibilità simmetrico?\nL’intervallo di massima densità posteriore (HPD) è l’intervallo più stretto che contiene una percentuale fissata (es. 94%) della distribuzione a posteriori. Si distingue dall’intervallo di credibilità simmetrico perché:\n\n\n\n\n\n\n\nCaratteristica\nIntervallo HPD\nIntervallo di Credibilità Simmetrico\n\n\n\nDefinizione\nContiene il \\((1 - \\alpha)100\\%\\) della probabilità a posteriori, minimizzando la lunghezza dell’intervallo.\nÈ centrato attorno alla mediana e copre una frazione fissa della distribuzione.\n\n\nForma\nPuò essere asimmetrico e discontinuo se la distribuzione è multimodale.\nÈ sempre simmetrico.\n\n\nVantaggio\nÈ più informativo se la distribuzione è asimmetrica o multimodale.\nÈ più facile da calcolare, specialmente per distribuzioni unimodali.\n\n\n\n💡 Quando usarli?\n\nSe la distribuzione è simmetrica, entrambi gli intervalli danno risultati simili.\n\nSe la distribuzione è asimmetrica o multimodale, l’HPD è più informativo.\n\n4. Quali sono le problematiche associate alla moda (MAP) come stima puntuale?\nSebbene il MAP sia un concetto intuitivo (il valore più probabile della distribuzione a posteriori), presenta alcune limitazioni:\n\n\nDifficoltà computazionale con MCMC\n\nCon metodi di campionamento come Markov Chain Monte Carlo (MCMC), trovare il massimo della distribuzione a posteriori è difficile perché la funzione viene stimata in modo discreto.\nSpesso si preferisce stimare media o mediana, più facili da calcolare con MCMC.\n\n\n\nSensibilità ai dati e al prior\n\nIl MAP dipende fortemente dal prior scelto.\nSe il prior è informativo, il MAP può spostarsi troppo rispetto ai dati.\n\n\n\nProblemi con distribuzioni multimodali\n\nSe la distribuzione a posteriori ha più di un massimo (moda), il MAP potrebbe non essere una buona rappresentazione della distribuzione.\n\n\n\n💡 Quando evitarlo?\n- Se la distribuzione a posteriori è asimmetrica o multimodale. - Se si usa un metodo MCMC, dove la media o la mediana sono più semplici da stimare.\n5. In che modo la sintesi della distribuzione a posteriori cambia nel caso di più parametri incogniti?\nQuando l’inferenza bayesiana coinvolge più parametri (es. \\(\\mu\\) e \\(\\sigma\\)), l’analisi diventa più complessa per diversi motivi:\n\n\nInterazioni tra parametri\n\nI parametri spesso non sono indipendenti: la distribuzione a posteriori congiunta può mostrare correlazioni che non emergono dalle distribuzioni marginali.\n\n\n\nDifficoltà di visualizzazione\n\nPer un parametro si usa un istogramma o una funzione di densità.\nPer due parametri si usa un contour plot o un grafico 3D.\nCon più di due parametri, si ricorre a pair plots o matrici di correlazione.\n\n\n\nStimare margine e congiunta\n\nLa distribuzione marginale di un parametro si ottiene integrando la distribuzione congiunta rispetto agli altri parametri: \\[\np(\\theta_1) = \\int p(\\theta_1, \\theta_2) d\\theta_2\n\\]\n\nSe i parametri sono fortemente correlati, le marginali possono nascondere informazioni importanti.\n\n\n\nRischio di correlazioni non lineari\n\nLe correlazioni non lineari tra i parametri possono portare a distribuzioni con forme complesse (es. a banana), rendendo difficile la sintesi con MAP o media.\n\n\n\n💡 Strategie per affrontare il problema:\n- Visualizzare le correlazioni tra i parametri con scatter plot o heatmap.\n- Usare tecniche di riduzione della dimensionalità come PCA (Analisi delle Componenti Principali).\n- Utilizzare il MCMC per campionare direttamente dalla distribuzione congiunta.\nEsercizio in R con i dati SWLS\nNell’esercizio, usa i dati della SWLS che sono stati raccolti. Qui useremo i dati seguenti:\nswls_data &lt;- data.frame(\n  soddisfazione = c(4.2, 5.1, 4.7, 4.3, 5.5, 4.9, 4.8, 5.0, 4.6, 4.4)\n)\n1. Calcola la media, la mediana e la moda a posteriori della distribuzione della media SWLS, assumendo una distribuzione a priori gaussiana molto diffusa.\n\nUsa il metodo delle distribuzioni coniugate per ottenere la distribuzione a posteriori.\n\nlibrary(tibble)\n\n# Dati\nn &lt;- nrow(swls_data)\nmean_x &lt;- mean(swls_data$soddisfazione)\nsigma &lt;- 1  # Deviazione standard nota\n\n# Prior diffuso\nmu_prior &lt;- 4.5    \nsigma_prior &lt;- 10  \n\n# Media a posteriori\nmu_post &lt;- (sigma_prior^2 * mean_x + sigma^2 * n * mu_prior) / (sigma_prior^2 + sigma^2 * n)\n\n# Deviazione standard a posteriori\nsigma_post &lt;- sqrt((sigma_prior^2 * sigma^2) / (sigma_prior^2 + sigma^2 * n))\n\n# Moda (MAP)\nposterior_mode &lt;- mu_post  # Per una distribuzione normale, MAP coincide con la media\n\n# Mediana (simile alla media in una distribuzione normale)\nposterior_median &lt;- mu_post\n\ntibble(\"Media a Posteriori\" = mu_post,\n       \"Moda (MAP)\" = posterior_mode,\n       \"Mediana\" = posterior_median)\n2. Costruisci un intervallo di credibilità simmetrico al 94% per la media SWLS.\n\nUsa la distribuzione normale a posteriori per calcolare l’intervallo.\n\ncred_interval &lt;- qnorm(c(0.03, 0.97), mean = mu_post, sd = sigma_post)\ncred_interval\n3. Visualizza la distribuzione a posteriori della media SWLS con un grafico di densità.\n\nGenera un campione dalla distribuzione a posteriori e rappresentalo con ggplot2.\n\nlibrary(ggplot2)\n\n# Campionamento dalla distribuzione a posteriori\nset.seed(123)\nsamples &lt;- rnorm(1000, mean = mu_post, sd = sigma_post)\n\n# Creazione del dataframe\nsamples_df &lt;- tibble(media_campionata = samples)\n\n# Grafico della distribuzione a posteriori\nggplot(samples_df, aes(x = media_campionata)) +\n  geom_density(fill = \"blue\", alpha = 0.5) +\n  labs(title = \"Distribuzione a Posteriori della Media SWLS\",\n       x = \"Media\", y = \"Densità\")\n4. Confronta l’intervallo di credibilità simmetrico con l’intervallo di massima densità posteriore (HPD).\n\nUsa la funzione hdi() del pacchetto bayestestR per calcolare l’HPD.\n\nlibrary(bayestestR)\n\n# Calcolo intervallo HPD al 94%\nhpd_interval &lt;- hdi(samples, ci = 0.94)\nhpd_interval\n5. Calcola la probabilità a posteriori che la media SWLS sia minore di 23 – per fare un esempio, qui caloleremo per i dati simulati la probabilità a posteriori per la media SWLS maggiore di 4.7.\n\nUsa la distribuzione a posteriori per calcolare questa probabilità.\n\nprob_greater_4_7 &lt;- 1 - pnorm(4.7, mean = mu_post, sd = sigma_post)\nprob_greater_4_7",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_summary_posterior.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/09_summary_posterior.html#informazioni-sullambiente-di-sviluppo",
    "title": "53  Sintesi a posteriori",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.17.0      thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0\n#&gt;  [5] see_0.11.0       gridExtra_2.3    patchwork_1.3.0  bayesplot_1.12.0\n#&gt;  [9] psych_2.5.3      scales_1.4.0     markdown_2.0     knitr_1.50      \n#&gt; [13] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [17] purrr_1.0.4      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [21] ggplot2_3.5.2    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1   farver_2.1.2       fastmap_1.2.0     \n#&gt;  [4] pacman_0.5.1       digest_0.6.37      rpart_4.1.24      \n#&gt;  [7] timechange_0.3.0   lifecycle_1.0.4    survival_3.8-3    \n#&gt; [10] magrittr_2.0.3     compiler_4.5.0     rlang_1.1.6       \n#&gt; [13] tools_4.5.0        labeling_0.4.3     htmlwidgets_1.6.4 \n#&gt; [16] mnormt_2.1.1       RColorBrewer_1.1-3 withr_3.0.2       \n#&gt; [19] nnet_7.3-20        grid_4.5.0         jomo_2.7-6        \n#&gt; [22] iterators_1.0.14   MASS_7.3-65        cli_3.6.5         \n#&gt; [25] rmarkdown_2.29     reformulas_0.4.1   generics_0.1.4    \n#&gt; [28] rstudioapi_0.17.1  tzdb_0.5.0         minqa_1.2.8       \n#&gt; [31] splines_4.5.0      parallel_4.5.0     vctrs_0.6.5       \n#&gt; [34] boot_1.3-31        glmnet_4.1-8       Matrix_1.7-3      \n#&gt; [37] jsonlite_2.0.0     hms_1.1.3          mitml_0.4-5       \n#&gt; [40] foreach_1.5.2      glue_1.8.0         nloptr_2.2.1      \n#&gt; [43] pan_1.9            codetools_0.2-20   stringi_1.8.7     \n#&gt; [46] shape_1.4.6.1      gtable_0.3.6       lme4_1.1-37       \n#&gt; [49] pillar_1.10.2      htmltools_0.5.8.1  R6_2.6.1          \n#&gt; [52] Rdpack_2.6.4       rprojroot_2.0.4    evaluate_1.0.3    \n#&gt; [55] lattice_0.22-7     rbibutils_2.3      backports_1.5.0   \n#&gt; [58] broom_1.0.8        Rcpp_1.0.14        nlme_3.1-168      \n#&gt; [61] xfun_0.52          pkgconfig_2.0.3",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_summary_posterior.html#bibliografia",
    "href": "chapters/bayesian_inference/09_summary_posterior.html#bibliografia",
    "title": "53  Sintesi a posteriori",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nZetsche, U., Buerkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: biased or realistic? Journal of Abnormal Psychology, 128(7), 678–688.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_balance_prior_post.html",
    "href": "chapters/bayesian_inference/10_balance_prior_post.html",
    "title": "54  L’influenza della distribuzione a priori",
    "section": "",
    "text": "54.1 Introduzione\nConsideriamo un semplice scenario medico: un paziente si presenta dal dottore con un mal di testa. Il medico, per formulare una diagnosi accurata, dovrà considerare diversi fattori. Possiamo immaginare due medici con approcci leggermente differenti:\nQuale dei due medici è in grado di fornire una diagnosi più precisa? La risposta risiede nel concetto di probabilità a priori (o semplicemente prior), ovvero le credenze che un individuo ha su un evento prima di osservare nuovi dati.\nNel contesto medico, la storia clinica del paziente rappresenta una preziosa fonte di informazioni a priori. Conoscere gli antecedenti sanitari di un individuo permette al medico di formulare ipotesi più plausibili sulla causa del mal di testa. In termini bayesiani, i priori agiscono come una sorta di “lente” attraverso cui vengono interpretati i nuovi dati (in questo caso, i risultati dei test).\nQuando prendiamo decisioni nella vita quotidiana, utilizziamo costantemente le nostre conoscenze pregresse per interpretare nuove informazioni. Ad esempio, se vediamo una persona che indossa un camice bianco in un ospedale, inferiamo che si tratti di un medico, basandoci sulla nostra esperienza e sulle associazioni mentali che abbiamo costruito nel tempo. Questo processo di inferenza è molto simile a quello che avviene nell’aggiornamento bayesiano.\nLa scelta dei priori ha un impatto fondamentale sulla qualità delle inferenze che possiamo trarre dai dati. Questo capitolo si focalizza sull’importanza e sulle implicazioni che derivano dalla scelta dei priori sul processo di aggiornamento bayesiano. Per illustrare questi concetti, esamineremo alcuni esempi discussi da Johnson et al. (2022).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_balance_prior_post.html#introduzione",
    "href": "chapters/bayesian_inference/10_balance_prior_post.html#introduzione",
    "title": "54  L’influenza della distribuzione a priori",
    "section": "",
    "text": "Medico 1: Si basa principalmente sui risultati di test specifici, senza considerare una storia clinica pregressa del paziente.\n\nMedico 2: Oltre ai test, tiene conto della storia clinica del paziente, cercando di individuare eventuali fattori di rischio o condizioni preesistenti che potrebbero essere correlate al mal di testa.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_balance_prior_post.html#la-distribuzione-a-priori",
    "href": "chapters/bayesian_inference/10_balance_prior_post.html#la-distribuzione-a-priori",
    "title": "54  L’influenza della distribuzione a priori",
    "section": "\n54.2 La Distribuzione a Priori",
    "text": "54.2 La Distribuzione a Priori\nLa distribuzione a priori gioca un ruolo centrale nell’approccio bayesiano, poiché rappresenta le nostre conoscenze pregresse o le ipotesi sui parametri del modello prima di osservare i dati. Questo concetto è fondamentale perché permette di integrare le informazioni disponibili in precedenza con i dati osservati, fornendo così una stima più precisa e robusta dei parametri. Le distribuzioni a priori possono variare a seconda del grado di certezza che si attribuisce ai valori dei parametri.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_balance_prior_post.html#tipologie-di-distribuzioni-a-priori",
    "href": "chapters/bayesian_inference/10_balance_prior_post.html#tipologie-di-distribuzioni-a-priori",
    "title": "54  L’influenza della distribuzione a priori",
    "section": "\n54.3 Tipologie di Distribuzioni a Priori",
    "text": "54.3 Tipologie di Distribuzioni a Priori\nLa scelta della distribuzione a priori (nota come elicitazione della prior) è uno dei passaggi cruciali nell’analisi bayesiana ed è spesso vista come la fase più controversa, poiché è considerata “soggettiva”. Tuttavia, è importante sottolineare che la scelta della prior non è necessariamente soggettiva. A differenza dell’approccio frequentista, l’approccio bayesiano incoraggia la raccolta e l’integrazione di tutte le informazioni conosciute sul parametro in anticipo. Questo può essere fatto in modo oggettivo, basandosi su evidenze pregresse o raccomandazioni consolidate.\nEsistono tre principali categorie di distribuzioni a priori.\n\nDistribuzioni a Priori Non Informative. Le distribuzioni a priori non informative sono caratterizzate da una totale mancanza di conoscenza pregressa e assegnano la stessa credibilità a tutti i valori dei parametri. Un esempio comune di distribuzione a priori non informativa è la distribuzione uniforme, basata sul “Principio della Ragione Insufficiente” formulato da Laplace. Secondo questo principio, in assenza di evidenze rilevanti pregresse, tutte le possibili configurazioni dei parametri sono considerate equiprobabili.\n\nDistribuzioni a Priori Debolmente Informative. Le distribuzioni a priori debolmente informative consentendo di integrare una quantità limitata di informazioni pregresse nei modelli statistici. Queste distribuzioni sono progettate per riflettere le nostre assunzioni su quali possono essere i valori “ragionevoli” dei parametri del modello, tenendo conto delle incertezze presenti nell’analisi. L’uso di informazioni a priori debolmente informative può contribuire a migliorare la stabilità dell’analisi senza influenzare in modo significativo le conclusioni derivate da essa.\nLe distribuzioni a priori debolmente informative hanno la caratteristica di non “spostare” in modo significativo la distribuzione a posteriori in una direzione specifica. In altre parole, sono centrate su valori “neutri” dei parametri. Ad esempio, quando si trattano parametri che possono assumere valori positivi o negativi, la distribuzione a priori debolmente informativa potrebbe essere centrata sullo zero. Nel caso di parametri che rappresentano proporzioni, essa potrebbe essere centrata su 0.5.\nTuttavia, ciò che rende queste distribuzioni debolmente informative è la specifica definizione di un intervallo “plausibile” di valori dei parametri. Questo intervallo indica quali valori dei parametri sono considerati plausibili e quali sono invece considerati implausibili. Ad esempio, una distribuzione a priori debolmente informativa potrebbe suggerire che valori estremamente grandi o estremamente bassi dei parametri sono poco plausibili, concentrandosi su un intervallo più stretto di valori considerati ragionevoli.\nIn sintesi, le distribuzioni a priori debolmente informative sono utilizzate per incorporare informazioni pregresse limitate nei modelli bayesiani, contribuendo a stabilizzare le stime dei parametri senza influenzare in modo significativo le conclusioni derivate dai dati. Queste distribuzioni definiscono un intervallo plausibile di valori dei parametri, aiutando a guidare l’analisi verso soluzioni più verosimili senza imporre vincoli eccessivi sui risultati.\n\n\nDistribuzioni a Priori Informativa. Le conoscenze pregresse, acquisite attraverso ricerche precedenti, pareri esperti o una combinazione di entrambi, possono essere meticolosamente integrate nel processo di analisi mediante l’incorporazione nelle distribuzioni a priori. Queste distribuzioni sono comunemente conosciute come distribuzioni a priori informative. Esse rappresentano un mezzo per codificare in modo sistematico informazioni concrete e rilevanti che possono avere un notevole impatto sull’analisi statistica, fornendo una solida base di conoscenza su cui fondare l’inferenza bayesiana.\nLe distribuzioni a priori informative possono derivare da una vasta gamma di fonti, comprese ricerche pregresse, pareri di esperti nel campo e altre fonti affidabili. Questo approccio offre un metodo strutturato per integrare in modo coerente le conoscenze pregresse nel processo di analisi statistica. L’incorporazione di queste informazioni aggiuntive contribuisce notevolmente a migliorare la robustezza e l’accuratezza delle conclusioni derivate dai dati, fornendo una solida base empirica su cui basare le stime dei parametri del modello e le decisioni basate sull’analisi bayesiana.\nNell’ambito della ricerca psicologica, l’utilizzo di distribuzioni a priori informative è attualmente poco diffuso, tuttavia emergono segnali che all’interno della comunità statistica sta crescendo l’interesse per questa pratica, considerandola come un avanzamento promettente nel campo della data science.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_balance_prior_post.html#limportanza-della-prior-in-base-ai-dati",
    "href": "chapters/bayesian_inference/10_balance_prior_post.html#limportanza-della-prior-in-base-ai-dati",
    "title": "54  L’influenza della distribuzione a priori",
    "section": "\n54.4 L’importanza della Prior in base ai Dati",
    "text": "54.4 L’importanza della Prior in base ai Dati\nUn aspetto cruciale da considerare è che l’influenza della prior diminuisce all’aumentare del numero di dati osservati. In altre parole, con un numero infinito di dati, la verosimiglianza diventa estremamente precisa (o “affilata”), rendendo la scelta della prior irrilevante, a patto che la prior non assegni probabilità zero a regioni dello spazio parametri dove la verosimiglianza è positiva.\nTuttavia, la prior assume un’importanza fondamentale quando si lavora con dataset di piccole dimensioni. In questi casi, la distribuzione a priori può avere un’influenza significativa sulle stime, poiché i dati da soli non sono sufficienti per ottenere stime precise.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_balance_prior_post.html#effetti-del-cambiamento-di-scala-dei-parametri",
    "href": "chapters/bayesian_inference/10_balance_prior_post.html#effetti-del-cambiamento-di-scala-dei-parametri",
    "title": "54  L’influenza della distribuzione a priori",
    "section": "\n54.5 Effetti del Cambiamento di Scala dei Parametri",
    "text": "54.5 Effetti del Cambiamento di Scala dei Parametri\nUn altro aspetto da tenere a mente è che le priors possono cambiare quando si modificano le scale dei parametri. Se un parametro viene riscalato, ad esempio passando da metri a chilometri, anche la prior deve essere riscalata di conseguenza per mantenere la coerenza dell’inferenza.\n\n54.5.1 Scala e invariabilità della scelta delle distribuzioni a priori\nLa scelta delle distribuzioni a priori non informative non è sempre banale e non può sempre essere rappresentata da una prior piatta. Per capire questo concetto, è fondamentale comprendere il ruolo della scala. Vediamo un esempio per chiarire meglio questo aspetto.\nImmaginiamo di avere un dataset che contiene la media dei diametri di alcuni alberi, e vogliamo stimare la media di questi diametri utilizzando un metodo bayesiano. Prima di osservare i dati, dobbiamo specificare la nostra distribuzione a priori, poiché non vogliamo che i dati influenzino la nostra scelta. Supponiamo di scegliere una distribuzione a priori piatta tra 1 cm e 10 cm, per evitare di introdurre bias:\n\n# Creazione di un vettore da 1 a 5\nvalori &lt;- 1:5\n# Creazione di un vettore di 5 elementi, tutti uguali a 1/5\npesoPrior &lt;- rep(1/5, 5)\n# Mostra i risultati\npesoPrior\n#&gt; [1] 0.2 0.2 0.2 0.2 0.2\n\nIn questo caso, stiamo assegnando la stessa probabilità a ciascun diametro compreso tra 1 e 10 cm, senza dare più peso a un valore rispetto a un altro. Questa sembra una scelta ragionevole e “non informativa”, poiché non stiamo preferendo nessun diametro in particolare.\nOra, supponiamo di voler modificare leggermente la nostra analisi e di misurare la grandezza degli alberi in termini di area basale (cioè la sezione trasversale dell’albero alla base), che è proporzionale al quadrato del diametro (cioè \\(x^2\\)). Poiché abbiamo già specificato la nostra distribuzione a priori in termini di diametro, dovremmo trasformare questa distribuzione in modo coerente con la nuova scala (area basale).\nIl problema che emerge è il seguente: quando riscaliamo l’asse \\(x\\) per riflettere l’area basale (cioè, passiamo da cm a cm\\(^2\\)), i valori più grandi diventano più ampi (poiché l’area cresce con il quadrato del diametro), mentre i valori più piccoli diventano più stretti. Se vogliamo mantenere la stessa distribuzione a priori in termini di probabilità, dobbiamo modificare il peso di ciascun valore.\nDi conseguenza, una distribuzione a priori che inizialmente era piatta (uguale per tutti i valori di diametro) non rimane piatta dopo la trasformazione in area basale. I valori più grandi ora hanno un peso minore, mentre i valori più piccoli hanno un peso maggiore. Questo dimostra che una distribuzione a priori non può essere piatta per tutte le possibili trasformazioni dei parametri.\n\n54.5.2 Il concetto di invariabilità della scala\nUna delle chiavi per definire correttamente le distribuzioni a priori non informative è l’invariabilità rispetto alle trasformazioni dei parametri. Se possiamo scegliere liberamente come rappresentare i parametri (ad esempio, in termini di diametro o area basale), la nostra distribuzione a priori dovrebbe essere definita in modo che sia coerente indipendentemente dalla scala scelta.\n\n54.5.3 Attenzione alle trasformazioni dei parametri\nUn secondo messaggio importante riguarda la cautela nelle trasformazioni dei parametri nell’analisi bayesiana. Quando cambiamo i parametri del nostro modello, non stiamo semplicemente osservando un singolo valore, ma una distribuzione intera. La forma di questa distribuzione può cambiare notevolmente con la trasformazione dei parametri.\nAd esempio, se si sta conducendo uno studio psicologico e si vuole misurare un parametro legato alla gravità di un disturbo (ad esempio, la gravità della depressione su una scala numerica), e poi si decide di trasformare la scala in un’unità diversa (ad esempio, un punteggio quadratico per evidenziare differenze estreme), la distribuzione a priori che sembrava ragionevole prima della trasformazione potrebbe non esserlo più dopo. Questo significa che bisogna prestare attenzione a come si scelgono le priors e come queste si comportano sotto diverse rappresentazioni del problema.\nIn conclusione, la scelta delle distribuzioni a priori non può essere fatta superficialmente. Deve essere considerata con attenzione, tenendo conto delle possibili trasformazioni dei parametri e assicurandosi che le priors siano coerenti rispetto alla scala scelta. Questo rende evidente che le priors non informative non sono sempre piatte, e la loro scelta deve tenere conto della struttura del problema e delle variabili coinvolte.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_balance_prior_post.html#scelte-predefinite-per-le-distribuzioni-a-priori-non-informative",
    "href": "chapters/bayesian_inference/10_balance_prior_post.html#scelte-predefinite-per-le-distribuzioni-a-priori-non-informative",
    "title": "54  L’influenza della distribuzione a priori",
    "section": "\n54.6 Scelte predefinite per le distribuzioni a priori non informative",
    "text": "54.6 Scelte predefinite per le distribuzioni a priori non informative\nUna delle domande più ricorrenti nell’inferenza bayesiana riguarda la scelta delle distribuzioni a priori non informative. La risposta, però, è piuttosto complessa: non esiste una soluzione generalmente accettata. Questo è particolarmente importante perché, mentre le priors informative possono essere basate su conoscenze pregresse, una prior non informativa deve essere scelta con cura per evitare di influenzare eccessivamente i risultati.\nUna delle proposte più famose, che soddisfa molte delle proprietà desiderabili, è la prior di Jeffreys, definita come:\n\\[\np(\\phi) \\propto \\sqrt{ \\det (F(\\phi)) },\n\\]\ndove \\(F(\\phi)\\) è la matrice di informazione di Fisher, che misura quanto la verosimiglianza cambia quando variano i parametri. La prior di Jeffreys ha due caratteristiche fondamentali:\n\n\nInvarianza rispetto alla riscalatura dei parametri: Ciò significa che se trasformiamo la scala del parametro, la prior si adatta automaticamente, rimanendo coerente con il problema.\n\nProporzionalità all’influenza dei parametri sulla verosimiglianza: Parametri che influenzano maggiormente la verosimiglianza hanno una prior più informativa.\n\nQuesti aspetti sembrano coprire molti dei criteri comunemente accettati per la scelta delle distribuzioni a priori non informative. Tuttavia, la prior di Jeffreys presenta alcuni problemi nei modelli multivariati e gerarchici, il che limita la sua applicabilità come soluzione universale.\n\n54.6.1 Scelte predefinite comuni per le priors non informative\nNonostante le difficoltà legate alla prior di Jeffreys, sono emerse alcune scelte predefinite comuni per le priors non informative, basate su intuizioni derivanti proprio da questa distribuzione. Di seguito sono elencate alcune di queste scelte:\n\n\nParametri di scala (es. coefficiente angolare o intercetta in una regressione):\n\nPer i parametri di scala, che influenzano l’output in modo lineare, si utilizzano comunemente priors piatte o quasi piatte. Queste possono essere distribuzioni uniformi con limiti fissati o, più comunemente, una distribuzione normale ampia.\nUn esempio di prior modificata è l’uso di una normalità centrata su un valore neutro, come 0, per ottenere l’analogo bayesiano della regressione Lasso o Ridge, che introduce una penalizzazione sui parametri (Park & Casella, 2008; Kyung et al., 2010).\n\nSe questa penalizzazione è lieve, si parla di priors debolmente regolarizzanti.\nSe è forte, si parla di priors di riduzione (shrinkage), che possono essere fisse o adattative:\n\n\nShrinkage fisso: la forza della riduzione (ad es. controllata dalla deviazione standard nella prior normale) rimane costante.\n\nShrinkage adattativo: la prior di riduzione si adatta tramite un iperparametro (hyperprior), il che consente al modello di decidere autonomamente la forza della riduzione.\n\n\n\n\n\n\n\nParametri di varianza (es. la deviazione standard in una regressione lineare):\n\nPer i parametri di varianza, si utilizzano spesso priors che decrescono all’aumentare del valore. Un esempio classico è la prior di Jeffrey’s, che per la varianza assume la forma \\(1/x\\), oppure la distribuzione inversa-gamma, molto comune per via della sua proprietà di coniugazione, che semplifica il calcolo bayesiano.\n\n\n\nIperparametri di varianza nei modelli gerarchici:\n\nNei modelli gerarchici, gli iperparametri di varianza vengono trattati con priors decrescenti come l’inversa-gamma o la distribuzione half-t (Gelman, 2006). Queste priors sono progettate per gestire la varianza tra gruppi in modo efficace.\n\n\n\nDistribuzioni binomiali:\n\nPer una distribuzione binomiale, la prior di Jeffreys corrisponde a una distribuzione Beta(1/2, 1/2), che è considerata una buona scelta predefinita non informativa. Questo tipo di prior assegna un peso equo alle possibili probabilità di successo, riflettendo una distribuzione equilibrata senza favorire un particolare risultato.\n\n\n\n54.6.2 Attenzione alle trasformazioni dei parametri\nUn aspetto importante da considerare nell’uso delle priors non informative è che la loro forma può cambiare significativamente in seguito a trasformazioni dei parametri. Per esempio, passando dalla scala lineare alla scala quadratica di un parametro, la prior può assumere una forma diversa e introdurre involontariamente un bias. Pertanto, è essenziale prestare attenzione a come i parametri sono scalati e trasformati nel modello.\n\n54.6.3 Analisi di sensibilità\nInfine, quando si è incerti sulla scelta della prior, un buon approccio consiste nel condurre un’analisi di sensibilità. Questa tecnica prevede di variare la prior e osservare come ciò influenzi i risultati. Se i risultati sono robusti rispetto a diverse scelte di prior, ciò suggerisce che la prior scelta non sta influenzando in modo eccessivo l’inferenza finale. Questo è particolarmente utile nei casi in cui si dispone di pochi dati, situazione in cui la prior può avere un impatto maggiore.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_balance_prior_post.html#priori-coniugate",
    "href": "chapters/bayesian_inference/10_balance_prior_post.html#priori-coniugate",
    "title": "54  L’influenza della distribuzione a priori",
    "section": "\n54.7 Priori coniugate",
    "text": "54.7 Priori coniugate\nUna distribuzione a priori è detta coniugata rispetto a una funzione di verosimiglianza se la distribuzione a posteriori risultante ha la stessa forma funzionale della distribuzione a priori. In altre parole, la distribuzione a priori e quella a posteriori appartengono alla stessa famiglia di distribuzioni. Questo è particolarmente utile perché, quando si usano priori coniugate, si ottiene una distribuzione a posteriori che può essere espressa in forma chiusa, rendendo possibile risolverla analiticamente.\nUn esempio tipico è quello delle funzioni di verosimiglianza appartenenti alla famiglia esponenziale, per le quali esiste sempre una distribuzione a priori coniugata. Questo è uno dei motivi per cui le distribuzioni della famiglia esponenziale sono così rilevanti: in modelli semplici, l’uso di una prior coniugata consente di ottenere una soluzione analitica per la distribuzione a posteriori, noto come modello coniugato-esponenziale.\nTradizionalmente, si preferiva specificare priori coniugate quando possibile, proprio per la semplicità analitica che garantivano. Tuttavia, l’importanza delle priors coniugate è diminuita con l’evoluzione dei metodi di campionamento. Oggi, la maggior parte dei campionatori moderni (come i metodi MCMC) non richiede più la coniugazione per funzionare in modo efficiente, e l’uso di priors non coniugate è diventato comune senza compromettere la qualità delle stime.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_balance_prior_post.html#simulazioni",
    "href": "chapters/bayesian_inference/10_balance_prior_post.html#simulazioni",
    "title": "54  L’influenza della distribuzione a priori",
    "section": "\n54.8 Simulazioni",
    "text": "54.8 Simulazioni\nIn questa sezione, esploriamo come le distribuzioni a priori influenzano la distribuzione a posteriori attraverso una serie di simulazioni. La formula di Bayes, \\(p(\\theta \\mid y) \\propto p(\\theta) \\times p(y \\mid \\theta)\\), evidenzia come la distribuzione a posteriori sia il risultato della combinazione tra la distribuzione a priori e la funzione di verosimiglianza basata sui dati osservati. Se abbiamo le valutazioni puntuali della verosimiglianza e della distribuzione a priori, possiamo moltiplicarle punto per punto per ottenere la distribuzione a posteriori.\n\n54.8.1 Verosimiglianza Binomiale con Distribuzioni a Priori Arbitrari\nConsideriamo un caso in cui la verosimiglianza è binomiale, ma utilizziamo distribuzioni a priori non coniugate. Supponiamo che i dati consistano in 6 successi su 9 prove di tipo bernoulliano. Confronteremo l’effetto di tre distribuzioni a priori diverse sulla distribuzione a posteriori e analizzeremo come ciascuna influisce sull’inferenza finale.\n\n54.8.1.1 Creazione della Griglia e Calcolo della Verosimiglianza\nIniziamo definendo una griglia di valori per \\(\\theta\\) e calcolando la verosimiglianza a ciascun punto della griglia.\n\n# Dati\nsuccess &lt;- 6\ntosses &lt;- 9\n\n# Griglia di valori per theta\ngrid_points &lt;- 100\np_grid &lt;- seq(0, 1, length.out = grid_points)\n\n# Verosimiglianza binomiale\nlikelihood &lt;- dbinom(success, tosses, p_grid)\n\n\n54.8.1.2 Funzione per Calcolare e Visualizzare la Posteriori\nDefiniamo una funzione che calcola la distribuzione a posteriori in base alla verosimiglianza e al priore fornito. La funzione visualizza anche il priore, la verosimiglianza e la distribuzione a posteriori.\n\ncomputePosterior &lt;- function(likelihood, prior, p_grid) {\n  # Calcolo della distribuzione a posteriori non normalizzata\n  unstd_posterior &lt;- likelihood * prior\n  \n  # Normalizzazione\n  posterior &lt;- unstd_posterior / sum(unstd_posterior)\n  \n  # Creazione del dataframe per il plotting\n  data &lt;- tibble(\n    theta = p_grid,\n    Prior = prior,\n    Likelihood = likelihood,\n    Posterior = posterior\n  ) |&gt; \n    pivot_longer(cols = c(Prior, Likelihood, Posterior), \n                 names_to = \"distribution\", \n                 values_to = \"density\")\n  \n  # Grafico con ggplot2\n  p &lt;- ggplot(data, aes(x = theta, y = density, color = distribution)) +\n    geom_line(size = 1.2) +\n    scale_color_manual(\n      values = MetBrewer::met.brewer(\"Hiroshige\", 10)[1:3], \n      # Usa i primi 3 colori della palette\n      labels = c(\"Prior\", \"Likelihood\", \"Posterior\")\n    ) +\n    facet_wrap(~distribution, scales = \"free_y\", ncol = 3) +\n    labs(\n      title = \"Distribuzioni: Prior, Likelihood, e Posterior\",\n      x = expression(theta),\n      y = \"Densità\"\n    ) +\n    theme(\n      plot.title = element_text(hjust = 0.5),\n      legend.position = \"none\",\n      strip.text = element_text(size = 12, face = \"bold\")\n    )\n  \n  # Restituzione della distribuzione a posteriori\n  print(p)\n  return(posterior)\n}\n\n\n54.8.2 Priore Uniforme\nIl nostro primo priore è una distribuzione uniforme: \\(p(\\theta) = 1\\). Questo riflette una completa mancanza di informazioni a priori sulla probabilità di successo \\(\\theta\\).\n\n# Priore uniforme\nprior1 &lt;- rep(1, grid_points)\n\n# Calcolo e visualizzazione della distribuzione a posteriori\nposterior1 &lt;- computePosterior(likelihood, prior1, p_grid)\n\n\n\n\n\n\n\nCome previsto, la distribuzione a posteriori coincide con la verosimiglianza (a parte un fattore di scala), poiché non abbiamo aggiunto informazioni.\n\n54.8.3 Priore a Gradino\nIl secondo priore è una funzione a gradino che riflette la convinzione che \\(\\theta\\) sia almeno \\(0.5\\). Questo priore esprime la credenza che il successo (“testa”) sia più probabile, ma non specifica di quanto.\n\n# Priore a gradino\nprior2 &lt;- ifelse(p_grid &gt;= 0.5, 1, 0)\n\n# Calcolo e visualizzazione della distribuzione a posteriori\nposterior2 &lt;- computePosterior(likelihood, prior2, p_grid)\n\n\n\n\n\n\n\nLa distribuzione a posteriori risultante esclude completamente i valori di \\(\\theta\\) inferiori a 0.5, coerentemente con le ipotesi del priore.\n\n54.8.4 Priore Esponenziale\nIl terzo priore è una distribuzione centrata su 0.5, con un rapido decadimento esponenziale su entrambi i lati. Questo priore riflette la convinzione che \\(\\theta\\) sia vicina a 0.5.\n\n# Priore esponenziale\nprior3 &lt;- exp(-5 * abs(p_grid - 0.5))\n\n# Calcolo e visualizzazione della distribuzione a posteriori\nposterior3 &lt;- computePosterior(likelihood, prior3, p_grid)\n\n\n\n\n\n\n\nQuesto priore “attrare” la distribuzione a posteriori verso 0.5, a meno che i dati non forniscano evidenze contrarie molto forti.\n\n54.8.5 Analisi del Modello Beta-Binomiale\nConsideriamo ora il caso coniugato, in cui il priore è una distribuzione Beta e i dati seguono una distribuzione Binomiale.\nDefiniamo una funzione per visualizzare le distribuzioni del modello Beta-Binomiale: priore, verosimiglianza e posteriore.\n\nplot_beta_binomial &lt;- function(alpha, beta, y = NULL, n = NULL) {\n  # Griglia di valori per theta\n  theta &lt;- seq(0, 1, length.out = 100)\n  \n  # Priore\n  prior_density &lt;- dbeta(theta, alpha, beta)\n  \n  # Verosimiglianza e posterior\n  if (!is.null(y) && !is.null(n)) {\n    likelihood &lt;- dbinom(y, n, theta)\n    scaled_likelihood &lt;- likelihood / max(likelihood)\n    posterior_alpha &lt;- alpha + y\n    posterior_beta &lt;- beta + n - y\n    posterior_density &lt;- dbeta(theta, posterior_alpha, posterior_beta)\n  }\n  \n  # Creazione del dataframe\n  data &lt;- tibble(\n    theta = theta,\n    prior = prior_density,\n    likelihood = if (!is.null(y) && !is.null(n)) scaled_likelihood else NA,\n    posterior = if (!is.null(y) && !is.null(n)) posterior_density else NA\n  ) |&gt; \n    pivot_longer(cols = c(prior, likelihood, posterior), \n                 names_to = \"distribution\", \n                 values_to = \"density\")\n  \n  # Filtra i valori validi\n  data &lt;- data |&gt; filter(!is.na(density))\n  \n  # Grafico con ggplot2\n  ggplot(data, aes(x = theta, y = density, color = distribution)) +\n    geom_line(size = 1.2) +\n    scale_color_manual(\n      values = MetBrewer::met.brewer(\"Hiroshige\", 10)[c(1, 2, 3)], \n      # Usa la palette di MetBrewer\n      labels = c(\"Prior\", \"Likelihood (scaled)\", \"Posterior\")\n    ) +\n    labs(\n      title = \"Beta-Binomial Model\",\n      x = expression(theta),\n      y = \"Density\",\n      color = \"Distribution\"\n    ) +\n    theme(\n      plot.title = element_text(hjust = 0.5), # Centra il titolo\n      legend.position = \"bottom\",            # Posiziona la legenda in basso\n      legend.title = element_text(size = 12)\n    )\n}\n\n\n54.8.5.1 Priore Uniforme\n\nplot_beta_binomial(alpha = 1, beta = 1, y = 15, n = 20)\n\n\n\n\n\n\n\n\n54.8.5.2 Priore Informativo (Beta(2, 2))\n\nplot_beta_binomial(alpha = 2, beta = 2, y = 15, n = 20)\n\n\n\n\n\n\n\n\n54.8.5.3 Priore Fortemente Informativo (Beta(2, 5))\n\nplot_beta_binomial(alpha = 2, beta = 5, y = 15, n = 20)\n\n\n\n\n\n\n\nIn conclusione, abbiamo esplorato come i priori influenzano la distribuzione a posteriori in contesti binomiali, dimostrando che l’influenza del priore è maggiore nei campioni piccoli e diminuisce con campioni di grandi dimensioni. L’analisi bayesiana consente un’integrazione flessibile delle conoscenze pregresse con i dati osservati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_balance_prior_post.html#connessione-tra-intuizioni-e-teoria",
    "href": "chapters/bayesian_inference/10_balance_prior_post.html#connessione-tra-intuizioni-e-teoria",
    "title": "54  L’influenza della distribuzione a priori",
    "section": "\n54.9 Connessione tra Intuizioni e Teoria",
    "text": "54.9 Connessione tra Intuizioni e Teoria\nL’equilibrio tra la distribuzione a priori e le evidenze provenienti dai dati, come dimostrato negli esempi precedenti, non solo rispecchia le nostre intuizioni, ma rappresenta anche una necessità matematica. Questo concetto diventa chiaro esaminando la formula del valore atteso della distribuzione a posteriori nel contesto del caso beta-binomiale, che può essere riscritta come segue:\n\\[\n\\begin{aligned}\n\\mathbb{E}_{\\text{post}} &[\\text{Beta}(\\alpha + y, \\beta + n - y)] = \\frac{\\alpha + y}{\\alpha + \\beta + n} \\\\\n&= \\frac{a+b}{a+b+n} \\cdot \\frac{a}{a+b} + \\frac{n}{a+b+n} \\cdot \\frac{y}{n}.\n\\end{aligned}\n\\]\nL’equazione precedente rivela che il valore atteso a posteriori si ottiene come una media ponderata tra il valore atteso a priori \\(\\left( \\frac{\\alpha}{\\alpha+\\beta}\\right)\\) e la proporzione osservata dei successi \\(\\left(\\frac{y}{n}\\right)\\). I pesi sono dati da \\(\\left( \\frac{\\alpha+\\beta}{\\alpha+\\beta+n}\\right)\\) e \\(\\left( \\frac{n}{\\alpha+\\beta+n}\\right)\\). Pertanto, quando il numero di osservazioni \\(n\\) è significativo rispetto alla somma dei parametri \\(\\alpha + \\beta\\), la distribuzione a posteriori sarà principalmente influenzata dai dati osservati e in minor misura dalle credenze a priori. Al contrario, se \\(n\\) è piccolo rispetto a \\(\\alpha + \\beta\\), i dati avranno un peso inferiore rispetto alle credenze a priori.\nQueste considerazioni indicano come scegliere i parametri \\(\\alpha\\) e \\(\\beta\\): se desideriamo rappresentare una totale ignoranza sul fenomeno, una scelta coerente è \\(\\alpha = \\beta = 1\\) (attribuiamo uguale credibilità a ogni valore di \\(\\theta\\)). Se, invece, possediamo forti credenze a priori, possiamo selezionare \\(\\alpha\\) in modo da eguagliare il valore atteso a priori, mentre \\(\\alpha + \\beta\\) rifletterà l’importanza attribuita all’informazione a priori: maggiore è il valore di \\(\\alpha + \\beta\\), maggiore sarà il numero di dati necessari per influenzare significativamente la distribuzione a posteriori rispetto a quella a priori. In situazioni in cui \\(n\\) è considerevolmente grande, la distribuzione a posteriori avrà un impatto ridotto sulla distribuzione a priori, a meno che non si facciano scelte estreme per i parametri a priori.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_balance_prior_post.html#conflitto-tra-prior-e-verosimiglianza",
    "href": "chapters/bayesian_inference/10_balance_prior_post.html#conflitto-tra-prior-e-verosimiglianza",
    "title": "54  L’influenza della distribuzione a priori",
    "section": "\n54.10 Conflitto tra Prior e Verosimiglianza",
    "text": "54.10 Conflitto tra Prior e Verosimiglianza\nEsaminiamo ora un altro esempio proposto da McElreath:\n\nLesson: Don’t trust intuition, for even simple prior+likelihood scenarios defy it. Four examples below, each producing radically different posteriors. Can you guess what each does?\n\n\nNella figura successiva vediamo la risposta alla domanda precedente.\n\nMcElreath descrive le caratteristiche di quattro diversi modelli in cui si combinano distribuzioni normali (Gaussiane) e Student-t (con 2 gradi di libertà) per il prior e la likelihood. La distribuzione gaussiana ha code molto sottili, mentre quella di Student-t ha code più spesse.\n\n\nIn Alto a Sinistra: Prior Normale, Likelihood Normale\n\ny ~ Normal(mu,1)\nmu ~ Normal(10,1)\n\nIn questo scenario classico di aggiornamento bayesiano, il posterior risulta essere un compromesso tra il prior e la likelihood. La distribuzione normale, con le sue code sottili, contribuisce a un aggiornamento più “prevedibile” e concentrato attorno al valore medio.\n\n\nIn Alto a Destra: Prior Student, Likelihood Student (df=2)\n\ny ~ Student(2,mu,1)\nmu ~ Student(2,10,1)\n\nIn questo caso, entrambe le distribuzioni hanno code più spesse. La presenza di “extra massa” nelle code significa che ciascuna distribuzione trova il modo dell’altra più plausibile, portando a una media che non rappresenta il miglior “compromesso”. Questo scenario risulta in una maggiore incertezza e un posterior meno definito.\n\n\nIn Basso a Sinistra: Prior Student, Likelihood Normale\n\ny ~ Normal(mu,1)\nmu ~ Student(2,10,1)\n\nQui, la likelihood normale, con le sue code sottili, tende a dominare. Essa è molto scettica nei confronti del prior con code spesse, ma il prior di Student-t non è sorpreso dalla likelihood. Questo porta a un posterior che è più influenzato dalla likelihood normale.\n\n\nIn Basso a Destra: Prior Normale, Likelihood Student\n\ny ~ Student(2,mu,1)\nmu ~ Normal(10,1)\n\nIn questo ultimo scenario, è il prior normale a dominare. Il ragionamento è simile a quello del caso precedente, ma in senso inverso. Il prior normale, con le sue code sottili, impone una maggiore influenza sul posterior, rendendolo meno influenzato dalle code più spesse della likelihood di Student-t.\n\n\nIn sintesi, la combinazione di queste due distribuzioni in diversi modi porta a risultati di aggiornamento bayesiano molto differenti, a seconda di quale tra prior e likelihood abbia le code più spesse e quindi eserciti una maggiore influenza sul posterior.\nIn conclusione, questo esercizio mostra come, ad eccezione del caso gaussiano, i risultati non sono affatto intuitivi. Pertanto, in contesti come questi, affidarsi esclusivamente alle proprie intuizioni non è una scelta consigliabile. È invece fondamentale procedere con l’esecuzione dei calcoli.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_balance_prior_post.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/10_balance_prior_post.html#riflessioni-conclusive",
    "title": "54  L’influenza della distribuzione a priori",
    "section": "\n54.11 Riflessioni Conclusive",
    "text": "54.11 Riflessioni Conclusive\nLa scelta della distribuzione a priori è uno degli aspetti più cruciali nell’inferenza bayesiana. Da un lato, le priors non informative possono essere utilizzate per minimizzare l’influenza delle conoscenze pregresse, permettendo ai dati osservati di guidare l’inferenza. Dall’altro, le priors informative sono estremamente utili quando si dispone di informazioni affidabili sui parametri, consentendo una stima più precisa. È importante ricordare che, con un gran numero di dati, l’influenza della prior tende a ridursi, mentre nei contesti con pochi dati la scelta della prior può avere un impatto significativo.\nUn aspetto essenziale dell’approccio bayesiano, come evidenziato nell’esempio di Johnson (2022), è che il processo di aggiornamento bayesiano riflette il modo in cui le persone ragionano intuitivamente: di fronte a evidenze deboli, le credenze rimangono stabili, mentre nuove informazioni robuste portano a un aggiornamento significativo delle credenze. Questo meccanismo formalizza in modo quantitativo e rigoroso le intuizioni che utilizziamo quotidianamente. Al contrario, l’approccio frequentista ignora le conoscenze pregresse, il che può portare a cambiamenti nelle inferenze senza tener conto delle credenze già esistenti.\nTuttavia, come evidenziato dagli esempi di McElreath, la situazione può essere più complessa nei modelli non coniugati, dove l’intuizione può fallire nel prevedere correttamente la distribuzione a posteriori. Questo ci ricorda che il contesto e la struttura del modello giocano un ruolo determinante nell’inferenza bayesiana.\n\n54.11.1 Il Ruolo della Prior nella Regolarizzazione\nNel contesto bayesiano, le distribuzioni a priori debolmente informative fungono da meccanismo di regolarizzazione, limitando l’influenza delle osservazioni estreme e garantendo inferenze più stabili. Questo approccio è ormai ampiamente accettato nella comunità statistica, poiché permette di ottenere risultati più prudenti senza introdurre un forte bias.\n\n54.11.2 L’Importanza dei Prior Informativi\nNegli ultimi anni, l’uso di priori informativi ha guadagnato maggiore attenzione, soprattutto grazie all’integrazione delle conoscenze esperte nel processo inferenziale. Questa pratica, nota come elicitazione della conoscenza esperta, richiede un rigoroso approccio metodologico per evitare bias cognitivi e assicurare che le informazioni pregresse siano incorporate in modo accurato. Questo è particolarmente rilevante in campi come la psicologia, dove spesso la base teorica è incerta, e l’elicitazione esperta può contribuire a migliorare la solidità delle analisi bayesiane (O’Hagan, 2019).\n\n54.11.3 Conclusioni Finali\nIn conclusione, la scelta delle prior deve essere ponderata attentamente in base alla disponibilità di dati e al contesto dell’analisi. Sebbene l’uso di priors non informative possa sembrare una scelta “neutra”, è spesso sub-ottimale. Le priors debolmente informative rappresentano lo standard attuale, poiché favoriscono un’inferenza più robusta grazie alla loro capacità di regolarizzare l’influenza dei dati. Infine, l’uso di priori informativi, sviluppati attraverso protocolli rigorosi di elicitazione esperta, è una frontiera in crescita nell’analisi bayesiana, poiché consente di sfruttare al meglio le conoscenze pregresse per migliorare la qualità delle inferenze e ridurre l’incertezza.\nQuesto approccio, che bilancia conoscenza pregressa e nuovi dati, permette di sviluppare modelli bayesiani più solidi e informati, riflettendo accuratamente sia l’incertezza sia la competenza specifica del dominio di studio.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_balance_prior_post.html#esercizi",
    "href": "chapters/bayesian_inference/10_balance_prior_post.html#esercizi",
    "title": "54  L’influenza della distribuzione a priori",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nL’obiettivo di questo esercizio è comprendere come la distribuzione a priori influenzi la distribuzione a posteriori a seconda della grandezza del campione. Utilizzeremo dati raccolti della Satisfaction With Life Scale (SWLS), categorizzandoli in base a una soglia e analizzando la proporzione di risposte che superano tale soglia con un approccio bayesiano.\nFase 1: Raccolta e categorizzazione dei dati\n\nOgni studente utilizza i valori della scala SWLS che sono stati raccolti dal suo gruppo TPV.\nSi sceglie una soglia arbitraria (ad esempio, un punteggio superiore a 20 indica “elevata soddisfazione”).\n\nSi calcola la proporzione di persone con punteggi superiori alla soglia:\n\\[\n\\hat{p} = \\frac{k}{n}\n\\]\ndove \\(k\\) è il numero di persone con SWLS sopra la soglia e \\(n\\) è la dimensione del campione (circa 15).\n\n\nFase 2: Inferenza Bayesiana con un Prior Mediamente Informativo\n\n\nSi assume una distribuzione Beta come prior per la proporzione di persone con SWLS sopra la soglia:\n\\[\np \\sim \\text{Beta}(a, b)\n\\]\ndove \\(a = 2\\) e \\(b = 2\\), un prior mediamente informativo (distribuzione simmetrica centrata su 0.5).\n\n\nSi calcola la distribuzione a posteriori utilizzando la coniugazione della Beta con la distribuzione binomiale:\n\\[\np \\mid D \\sim \\text{Beta}(a + k, b + n - k)\n\\]\n\n\nSi calcolano:\n\n\nStima puntuale della proporzione (valore atteso della Beta a posteriori):\n\\[\nE[p \\mid D] = \\frac{a + k}{a + b + n}\n\\]\n\nIntervallo di credibilità (CI al 95%), utilizzando i quantili della distribuzione Beta a posteriori.\n\n\n\nFase 3: Analisi con un Campione Più Grande\n\nSi ripete lo stesso esercizio, ma immaginando che la stessa proporzione \\(\\hat{p}\\) provenga da un campione di n = 1000.\n\nSi calcola la nuova distribuzione a posteriori:\n\\[\np \\mid D \\sim \\text{Beta}(a + k', b + n' - k')\n\\] con \\(k' = \\hat{p} \\times 1000\\).\n\nSi ricalcolano stima puntuale e intervallo di credibilità.\n\nFase 4: Confronto e Interpretazione\n\n\nSi confrontano le due distribuzioni a posteriori:\n\nCome cambia la varianza della distribuzione a posteriori?\nCome cambia l’influenza del prior?\nQual è la differenza nella precisione della stima puntuale e dell’intervallo di credibilità?\n\n\nSi discute come, all’aumentare del campione, l’influenza della distribuzione a priori diminuisce, facendo emergere il ruolo della likelihood.\n\nConsegna: caricare su Moodle il file .qmd compilato in pdf.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_balance_prior_post.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/10_balance_prior_post.html#informazioni-sullambiente-di-sviluppo",
    "title": "54  L’influenza della distribuzione a priori",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.17.0      thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0\n#&gt;  [5] see_0.11.0       gridExtra_2.3    patchwork_1.3.0  bayesplot_1.12.0\n#&gt;  [9] psych_2.5.3      scales_1.4.0     markdown_2.0     knitr_1.50      \n#&gt; [13] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [17] purrr_1.0.4      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [21] ggplot2_3.5.2    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1   farver_2.1.2       fastmap_1.2.0     \n#&gt;  [4] pacman_0.5.1       digest_0.6.37      rpart_4.1.24      \n#&gt;  [7] timechange_0.3.0   lifecycle_1.0.4    survival_3.8-3    \n#&gt; [10] magrittr_2.0.3     compiler_4.5.0     rlang_1.1.6       \n#&gt; [13] tools_4.5.0        labeling_0.4.3     htmlwidgets_1.6.4 \n#&gt; [16] mnormt_2.1.1       RColorBrewer_1.1-3 withr_3.0.2       \n#&gt; [19] nnet_7.3-20        grid_4.5.0         jomo_2.7-6        \n#&gt; [22] iterators_1.0.14   MASS_7.3-65        cli_3.6.5         \n#&gt; [25] rmarkdown_2.29     reformulas_0.4.1   generics_0.1.4    \n#&gt; [28] rstudioapi_0.17.1  tzdb_0.5.0         minqa_1.2.8       \n#&gt; [31] splines_4.5.0      parallel_4.5.0     vctrs_0.6.5       \n#&gt; [34] boot_1.3-31        glmnet_4.1-8       Matrix_1.7-3      \n#&gt; [37] jsonlite_2.0.0     hms_1.1.3          mitml_0.4-5       \n#&gt; [40] foreach_1.5.2      glue_1.8.0         nloptr_2.2.1      \n#&gt; [43] pan_1.9            codetools_0.2-20   stringi_1.8.7     \n#&gt; [46] shape_1.4.6.1      gtable_0.3.6       lme4_1.1-37       \n#&gt; [49] pillar_1.10.2      htmltools_0.5.8.1  R6_2.6.1          \n#&gt; [52] Rdpack_2.6.4       rprojroot_2.0.4    evaluate_1.0.3    \n#&gt; [55] lattice_0.22-7     rbibutils_2.3      backports_1.5.0   \n#&gt; [58] broom_1.0.8        Rcpp_1.0.14        nlme_3.1-168      \n#&gt; [61] xfun_0.52          pkgconfig_2.0.3",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_balance_prior_post.html#bibliografia",
    "href": "chapters/bayesian_inference/10_balance_prior_post.html#bibliografia",
    "title": "54  L’influenza della distribuzione a priori",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A. (2006). Prior distributions for variance parameters in hierarchical models (comment on article by Browne and Draper). Bayesian Analysis, 1(3), 515–534. https://doi.org/10.1214/06-BA117A\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nO’Hagan, A. (2019). Expert knowledge elicitation: subjective but scientific. The American Statistician, 73(sup1), 69–81.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_gamma_poisson_model.html",
    "href": "chapters/bayesian_inference/11_gamma_poisson_model.html",
    "title": "55  Modello coniugato Gamma-Poisson",
    "section": "",
    "text": "55.1 Introduzione\nIn psicologia, le variabili di conteggio (\\(y\\)), che indicano il numero di occorrenze di un evento, trovano ampio impiego in diversi ambiti. Ad esempio, sono usate per quantificare la frequenza dei sintomi di un disturbo o per analizzare le frequenze delle parole negli studi di psicolinguistica. Queste variabili, assumendo valori discreti, richiedono modelli statistici specifici.\nQuesto capitolo si focalizza sulla stima del tasso medio di incidenza (\\(\\lambda_i\\)) di tali eventi, ovvero sul numero medio di occorrenze per unità di misura. Adotteremo un approccio bayesiano, utilizzando il modello di Poisson per descrivere la distribuzione di probabilità delle variabili di conteggio. In particolare, esploreremo la derivazione analitica della distribuzione a posteriori del parametro \\(\\lambda_i\\), considerando una distribuzione a priori Gamma. Successivamente, verificheremo la validità dei risultati analitici mediante simulazioni Monte Carlo.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_gamma_poisson_model.html#distribuzione-di-poisson",
    "href": "chapters/bayesian_inference/11_gamma_poisson_model.html#distribuzione-di-poisson",
    "title": "55  Modello coniugato Gamma-Poisson",
    "section": "\n55.2 Distribuzione di Poisson",
    "text": "55.2 Distribuzione di Poisson\nLa distribuzione di Poisson è un modello probabilistico utilizzato per descrivere il numero di eventi che si verificano in un intervallo di tempo o spazio fisso, partendo dall’assunto che tali eventi si verifichino con una frequenza media costante e in modo indipendente rispetto al tempo trascorso dall’ultimo evento. Se un dato \\(y\\) segue una distribuzione di Poisson con parametro \\(\\lambda\\), allora la probabilità di osservare un singolo valore \\(y_i\\) è data da:\n\\[\nf(y_i \\mid \\lambda) = \\frac{e^{-\\lambda} \\lambda^{y_i}}{y_i!},\n\\]\ndove \\(\\lambda &gt; 0\\) rappresenta la frequenza media di occorrenza degli eventi e \\(y_i\\) è il numero di eventi osservati. La distribuzione di Poisson ha la caratteristica che sia il valore atteso che la varianza di una variabile casuale \\(Y\\) che segue questa distribuzione sono pari a \\(\\lambda\\), cioè \\(E(Y) = \\lambda\\) e \\(\\text{Var}(Y) = \\lambda\\).\n\n55.2.1 Simulazione\nPer capire meglio come funziona la distribuzione di Poisson, immaginiamo un paziente con un disturbo ossessivo-compulsivo. Supponiamo che in media questo paziente ripeta un’azione compulsiva 2 volte ogni ora. In questo caso, il parametro della distribuzione di Poisson è λ = 2.\nLa probabilità di osservare esattamente \\(k\\) eventi in un’ora è calcolata dalla formula:\n\\[\nf(k \\mid \\lambda) = \\frac{e^{-\\lambda} \\lambda^k}{k!}.\n\\]\nNel caso specifico con \\(\\lambda = 2\\), le probabilità per i primi valori di \\(k\\) sono:\n\nLa probabilità di osservare 0 eventi in un’ora è \\(\\frac{e^{-2} \\cdot 2^0}{0!} = e^{-2} \\approx 0{.}1353\\).\nLa probabilità di osservare 1 evento in un’ora è \\(\\frac{e^{-2} \\cdot 2^1}{1!} = 2e^{-2} \\approx 0{.}2707\\).\nLa probabilità di osservare 2 eventi in un’ora è \\(\\frac{e^{-2} \\cdot 2^2}{2!} = 2e^{-2} \\approx 0{.}2707\\).\nE così via per \\(k = 3\\), \\(k = 4\\), \\(\\dots\\)\n\n\nQuesto esempio illustra come la distribuzione di Poisson possa essere utilizzata per modellare il numero di eventi rari che si verificano in un intervallo temporale fisso, con una frequenza media nota.\nSvolgiamo ora i calcoli utilizzando la funzione dpois in R:\n\nlam_true &lt;- 2\n# Creazione di un vettore di valori da 0 a 9\nk_values &lt;- 0:9\n\n# Calcolo delle probabilità per ogni valore in k_values\nprobabilities &lt;- dpois(k_values, lambda = lam_true)\n\n# Stampa delle probabilità\nfor (i in seq_along(k_values)) {\n  cat(sprintf(\"Probabilità di %d eventi: %.4f\\n\", k_values[i], probabilities[i]))\n}\n#&gt; Probabilità di 0 eventi: 0.1353\n#&gt; Probabilità di 1 eventi: 0.2707\n#&gt; Probabilità di 2 eventi: 0.2707\n#&gt; Probabilità di 3 eventi: 0.1804\n#&gt; Probabilità di 4 eventi: 0.0902\n#&gt; Probabilità di 5 eventi: 0.0361\n#&gt; Probabilità di 6 eventi: 0.0120\n#&gt; Probabilità di 7 eventi: 0.0034\n#&gt; Probabilità di 8 eventi: 0.0009\n#&gt; Probabilità di 9 eventi: 0.0002\n\nIl seguente codice R genera il grafico della funzione di massa di probabilità (PMF) di una distribuzione di Poisson con parametro \\(\\lambda = 2\\):\n\n# Definiamo il parametro lambda\nlambd &lt;- 2\n\n# Generiamo i valori sull'asse x (numero di eventi)\nx &lt;- 0:9  \n\n# Calcoliamo le probabilità corrispondenti \ny &lt;- dpois(x, lambda = lambd)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  numero_eventi = x,\n  probabilita = y\n)\n\n# Creare il grafico \nggplot(df, aes(x = numero_eventi, y = probabilita)) +\n  geom_segment(aes(x = numero_eventi, xend = numero_eventi, y = 0, yend = probabilita), \n               color = \"blue\", size = 1) +  # Segmenti verticali\n  geom_point(color = \"red\", size = 3) +  # Cerchi sulla cima dei segmenti\n  labs(title = \"Distribuzione di Poisson (λ = 2)\",  \n       x = \"Numero di eventi\", \n       y = \"Probabilità\") +  \n  theme(plot.title = element_text(hjust = 0.5))  # Centrare il titolo",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_gamma_poisson_model.html#distribuzione-gamma",
    "href": "chapters/bayesian_inference/11_gamma_poisson_model.html#distribuzione-gamma",
    "title": "55  Modello coniugato Gamma-Poisson",
    "section": "\n55.3 Distribuzione Gamma",
    "text": "55.3 Distribuzione Gamma\nLa distribuzione Gamma riveste un ruolo centrale nel modello coniugato Gamma-Poisson, poiché funge da distribuzione a priori per il parametro di tasso \\(\\lambda\\) della distribuzione di Poisson. La sua scelta è motivata dalla proprietà di coniugatezza, che consente di ottenere una distribuzione a posteriori appartenente alla stessa famiglia della prior, semplificando i calcoli inferenziali e aggiornando in modo diretto le credenze alla luce dei dati osservati.\nLa funzione di densità della distribuzione Gamma è definita come:\n\\[\nf(x \\mid \\alpha, \\beta) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} x^{\\alpha - 1} e^{-\\beta x},\n\\]\ndove:\n\n\n\\(\\alpha\\) (detto parametro di forma) determina la forma della distribuzione: valori più elevati di \\(\\alpha\\) tendono a rendere la distribuzione più simmetrica;\n\n\\(\\beta\\) (detto parametro di tasso o scala inversa) controlla la scala: valori più elevati di \\(\\beta\\) concentrano maggiormente la massa di probabilità vicino all’origine.\n\nAd esempio:\n\nUna distribuzione Gamma con \\(\\alpha = 2\\) e \\(\\beta = 3\\) rappresenta un processo in cui eventi relativamente rari si verificano occasionalmente.\nUna distribuzione Gamma con \\(\\alpha = 10\\) e \\(\\beta = 1\\) descrive un processo più regolare, con eventi che si verificano con maggiore frequenza e prevedibilità.\n\n\n\n\n\n\n\nIn R, la parametrizzazione della distribuzione Gamma utilizza direttamente il parametro \\(\\beta\\) come tasso (\\(rate\\)), che è l’inverso del parametro di scala (\\(scale = 1 / \\beta\\)).\n\n\n\nPer calcolare la densità di probabilità in R, si utilizza:\ndgamma(x, shape = alpha, rate = beta)\n\n# Definizione dei parametri\nalpha &lt;- 2\nbeta &lt;- 3\n\n# Generazione dei valori di x\nx &lt;- seq(0, 3, length.out = 500)\n\n# Calcolo della densità di probabilità\npdf &lt;- dgamma(x, shape = alpha, rate = beta)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  x = x,\n  densita = pdf\n)\n\n# Creare il grafico con ggplot2\nggplot(df, aes(x = x, y = densita)) +\n  geom_line(color = \"blue\", size = 1) +  # Aggiungere la linea per la densità\n  labs(\n    title = expression(\"Distribuzione Gamma (\" ~ alpha == 2 ~ \",\" ~ beta == 3 ~ \")\"),  # Titolo con espressioni matematiche\n    x = \"x\",  # Label dell'asse x\n    y = \"Densità di probabilità\"  # Label dell'asse y\n  ) +\n  theme(plot.title = element_text(hjust = 0.5))  # Centrare il titolo\n\n\n\n\n\n\n\nQuesto grafico mostra la densità di una distribuzione Gamma con \\(\\alpha = 2\\) e \\(\\beta = 3\\), calcolata su un intervallo \\([0, 3]\\).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_gamma_poisson_model.html#metodo-basato-su-griglia",
    "href": "chapters/bayesian_inference/11_gamma_poisson_model.html#metodo-basato-su-griglia",
    "title": "55  Modello coniugato Gamma-Poisson",
    "section": "\n55.4 Metodo Basato su Griglia",
    "text": "55.4 Metodo Basato su Griglia\nVogliamo calcolare la distribuzione a posteriori del parametro \\(\\lambda\\) di un modello di Poisson, usando una distribuzione a priori Gamma. Di seguito mostriamo come si può procedere numericamente, discretizzando lo spazio dei possibili valori di \\(\\lambda\\).\nDati e Assunzioni.\nI dati osservati sono:\n\ny &lt;- c(2, 1, 3, 2, 2, 1, 1, 1)\n\ne la nostra distribuzione a priori è \\(\\text{Gamma}(\\alpha=9, \\beta=2)\\).\n1. Definizione della Griglia e della Distribuzione A Priori.\n\nCreiamo una griglia di valori di \\(\\lambda\\), per esempio tra 0.01 e 10, con 1000 punti equidistanti.\n\nPer ciascun valore di \\(\\lambda\\), calcoliamo la densità della a priori Gamma corrispondente.\n\n\n# Parametri della distribuzione a priori Gamma\nalpha_prior &lt;- 9\nbeta_prior  &lt;- 2\n\n# Griglia di valori di lambda\nlambda_grid &lt;- seq(0.01, 10, length.out = 1000)\n\n# Densità della distribuzione a priori\nprior &lt;- dgamma(lambda_grid, shape = alpha_prior, rate = beta_prior)\n\nÈ spesso utile visualizzare questa a priori e confrontarla con altre informazioni, ad esempio la media di \\(\\lambda\\) secondo la a priori (\\(\\alpha/\\beta\\)) e la media campionaria (\\(\\bar{y}\\)):\n\n# Calcolo di media a priori (media di una Gamma) e media campionaria\nmedia_gamma       &lt;- alpha_prior / beta_prior\nmedia_campionaria &lt;- mean(y)\n\n# Creazione di un dataframe per ggplot\ndf_prior &lt;- data.frame(\n  lambda  = lambda_grid,\n  densita = prior\n)\n\nggplot(df_prior, aes(x = lambda, y = densita)) +\n  geom_line() +\n  geom_vline(xintercept = media_gamma,       linetype = \"dashed\") +\n  geom_vline(xintercept = media_campionaria, linetype = \"dashed\") +\n  labs(\n    title = \"Distribuzione Gamma a Priori\",\n    x = expression(lambda),\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\n2. Calcolo della Verosimiglianza.\nPer una famiglia di distribuzioni di Poisson, la verosimiglianza di un insieme di dati \\(y_1, y_2, \\dots, y_n\\) è il prodotto delle probabilità:\n\\[\n\\mathcal{L}(\\lambda) \\;=\\; \\prod_{i=1}^n \\mathrm{P}(Y=y_i \\mid \\lambda)\n\\;=\\; \\prod_{i=1}^n \\mathrm{dpois}(y_i, \\lambda).\n\\]\nIn R, possiamo calcolarla per tutti i valori di \\(\\lambda\\) della griglia in modo vettoriale:\n\n# Calcolo vettoriale della verosimiglianza\nlikelihood &lt;- sapply(lambda_grid, function(l) prod(dpois(y, l)))\n\nL’istruzione precedente fa questo:\n\n\nPasso su ciascun valore di \\(\\lambda\\) nella griglia (lambda_grid).\n\nPer ogni \\(\\lambda\\), calcola \\(\\mathrm{dpois}(y, \\lambda)\\), che restituisce un vettore di lunghezza \\(n\\) (il numero di osservazioni), ossia la probabilità di osservare ciascun \\(y_i\\) secondo una Poisson(\\(\\lambda\\)).\n\n\nMoltiplica insieme tutte queste probabilità con prod(...), ottenendo un singolo numero che è la verosimiglianza \\(\\mathcal{L}(\\lambda)\\) per quell’insieme di dati.\n\nRipete il procedimento per ogni \\(\\lambda\\) della griglia, restituendo un vettore di verosimiglianze (una per ciascun punto della griglia).\n\nIn altre parole, ogni elemento del vettore likelihood corrisponde alla verosimiglianza calcolata in un punto \\(\\lambda\\). E la verosimiglianza è appunto il prodotto delle probabilità di ciascuno dei valori \\(y_i\\), assumendo che i dati provengano da una \\(\\mathrm{Poisson}(\\lambda)\\) e che le osservazioni siano indipendenti.\n3. Calcolo della A Posteriori (non normalizzata).\nLa distribuzione a posteriori, a meno di una costante di normalizzazione, è data da:\n\\[\n\\pi(\\lambda \\mid y) \\; \\propto \\; \\mathcal{L}(\\lambda)\\,\\pi(\\lambda).\n\\]\nTradotto in codice:\n\nposterior_unnormalized &lt;- prior * likelihood\n\n4. Normalizzazione.\nPer ottenere la vera distribuzione di probabilità, dobbiamo normalizzare:\n\\[\n\\pi(\\lambda \\mid y) =\n  \\frac{\\mathcal{L}(\\lambda)\\,\\pi(\\lambda)}{\\int \\mathcal{L}(\\lambda)\\,\\pi(\\lambda)\\, d\\lambda}.\n\\]\nSul computer, l’integrale si trasforma in una somma pesata dallo “spessore” di ogni intervallo nella griglia:\n\n# Calcolo del fattore di normalizzazione\ngrid_width &lt;- lambda_grid[2] - lambda_grid[1]  # Ampiezza della griglia (costante)\nnormalization_factor &lt;- sum(posterior_unnormalized) * grid_width\n\n# Distribuzione a posteriori normalizzata\nposterior &lt;- posterior_unnormalized / normalization_factor\n\n5. Confronto Visivo: A Priori vs A Posteriori.\nInfine, possiamo confrontare le due curve (a priori e a posteriori) su un unico grafico:\n\n# Creazione del dataframe\ndf &lt;- data.frame(\n  lambda  = lambda_grid,\n  prior   = prior,\n  posterior = posterior\n)\n\n# Trasformiamo in formato \"lungo\" per ggplot\nlibrary(reshape2)\ndf_long &lt;- melt(\n  df, \n  id.vars = \"lambda\", \n  measure.vars = c(\"prior\", \"posterior\"),\n  variable.name = \"Distribuzione\", \n  value.name = \"Densita\"\n)\n\n# Grafico\nggplot(df_long, aes(x = lambda, y = Densita, color = Distribuzione)) +\n  geom_line() +\n  labs(\n    title = \"Distribuzione A Priori e A Posteriori\",\n    x = expression(lambda),\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\nInterpretazione.\n\nLa distribuzione a posteriori risulta spostata verso valori più bassi rispetto alla a priori. Questo indica che i dati osservati suggeriscono \\(\\lambda\\) più piccolo di quanto ipotizzato inizialmente dalla a priori.\nLa a posteriori appare più concentrata (più piccata) rispetto alla a priori. Ciò riflette la minor incertezza residua dopo aver incorporato l’informazione fornita dai dati.\n\nQuesto semplice approccio su griglia mostra chiaramente come la verosimiglianza, “pesata” dalla a priori, generi la nuova distribuzione a posteriori. È un metodo intuitivo che permette di visualizzare passo dopo passo in che modo i dati aggiornano le nostre credenze sul parametro \\(\\lambda\\).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_gamma_poisson_model.html#modello-coniugato-gamma-poission",
    "href": "chapters/bayesian_inference/11_gamma_poisson_model.html#modello-coniugato-gamma-poission",
    "title": "55  Modello coniugato Gamma-Poisson",
    "section": "\n55.5 Modello Coniugato Gamma-Poission",
    "text": "55.5 Modello Coniugato Gamma-Poission\nPer calcolare analiticamente la distribuzione a posteriori nel contesto di un modello gamma-Poisson possiamo seguire un processo diretto. Il modello Gamma-Poisson è coniugato, il che significa che la distribuzione a posteriori sarà ancora una distribuzione Gamma.\nSeguendo il teorema di Bayes, possiamo scrivere la distribuzione a posteriori come:\n\\(f(\\lambda \\mid y) \\propto f(y \\mid \\lambda) \\cdot f(\\lambda) ,\\)\ndove \\(f(\\lambda \\mid y)\\) è la distribuzione a posteriori, \\(f(y \\mid \\lambda)\\) è la verosimiglianza e \\(f(\\lambda)\\) è la distribuzione a priori.\nDefiniamo la verosimiglianza (distribuzione di Poisson):\n\\(f(y \\mid \\lambda) = \\prod_{i=1}^n \\frac{e^{-\\lambda}\\lambda^{y_i}}{y_i!} = \\frac{e^{-n\\lambda}\\lambda^{\\sum_{i=1}^n y_i}}{\\prod_{i=1}^n y_i!}.\\)\nDefiniamo la distribuzione a priori (distribuzione Gamma):\n\\(f(\\lambda) = \\frac{b^a}{\\Gamma(a)}\\lambda^{a-1}e^{-b\\lambda}.\\)\nOra, moltiplichiamo la verosimiglianza per la distribuzione a priori:\n\\(f(\\lambda|y) \\propto \\frac{e^{-n\\lambda}\\lambda^{\\sum_{i=1}^n y_i}}{\\prod_{i=1}^n y_i!} \\cdot \\frac{b^a}{\\Gamma(a)}\\lambda^{a-1}e^{-b\\lambda}.\\)\nSemplifichiamo, eliminando i termini costanti (che non dipendono da \\(\\lambda\\)):\n\\(f(\\lambda \\mid y) \\propto e^{-n\\lambda}\\lambda^{\\sum_{i=1}^n y_i} \\cdot \\lambda^{a-1}e^{-b\\lambda}.\\)\nRaggruppiamo i termini:\n\\(f(\\lambda|y) \\propto \\lambda^{\\sum_{i=1}^n y_i} \\cdot \\lambda^{a-1} \\cdot e^{-n\\lambda} \\cdot e^{-b\\lambda}.\\)\nSemplifichiamo ulteriormente:\n\\(f(\\lambda \\mid y) \\propto \\lambda^{\\sum_{i=1}^n y_i + a - 1} \\cdot e^{-(n+b)\\lambda}.\\)\nRiconosciamo che questa è la forma di una distribuzione Gamma con nuovi parametri:\n\\(f(\\lambda \\mid y) \\propto \\lambda^{(\\sum_{i=1}^n y_i + a) - 1} \\cdot e^{-(n+b)\\lambda}.\\)\nQuindi, la distribuzione a posteriori è una Gamma con parametri:\n\n\n\\(\\alpha_{post} = a + \\sum_{i=1}^n y_i\\),\n\n\\(\\beta_{post} = b + n\\),\n\ndove:\n\n\n\\(a\\) e \\(b\\) sono i parametri della distribuzione Gamma a priori,\n\n\\(\\sum_{i=1}^n y_i\\) è la somma di tutte le osservazioni,\n\n\\(n\\) è il numero di osservazioni.\n\nQuesta derivazione mostra come la distribuzione a posteriori mantiene la forma di una Gamma, ma con parametri aggiornati che incorporano l’informazione dai dati osservati.\nConsideriamo nuovamente l’esempio precedente. Utilizzando i parametri aggiornati, rappresentiamo graficamente la distribuzione a posteriori:\n\n# Parametri aggiornati della distribuzione a posteriori Gamma\nalpha_post &lt;- alpha_prior + sum(y)\nbeta_post &lt;- beta_prior + length(y)\n\n# Griglia dei valori di lambda\nlambda_grid &lt;- seq(0.01, 10, length.out = 1000)\n\n# Distribuzione a posteriori analitica\nposterior_analytic &lt;- dgamma(lambda_grid, shape = alpha_post, rate = beta_post)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  lambda = lambda_grid,\n  densita = posterior_analytic\n)\n\n# Calcolo della media a posteriori\nmedia_posterior &lt;- alpha_post / beta_post\n\n# Creare il grafico con ggplot2\nggplot(df, aes(x = lambda, y = densita)) +\n  geom_line(color = \"blue\", size = 1) +  # Aggiungere la linea per la densità a posteriori\n  geom_vline(xintercept = media_posterior, color = \"red\", linetype = \"dashed\", size = 1) +  # Linea verticale per la media a posteriori\n  labs(\n    title = \"Distribuzione a Posteriori Analitica Gamma-Poisson\",\n    x = expression(lambda),  # Label dell'asse x usando espressioni matematiche\n    y = \"Densità di probabilità\"  # Label dell'asse y\n  ) +\n  theme(plot.title = element_text(hjust = 0.5)) +  # Centrare il titolo\n  annotate(\"text\", x = media_posterior + 0.5, y = max(posterior_analytic) * 0.8, \n           label = \"Media a Posteriori\", color = \"red\", size = 4) +  # Etichetta per la media a posteriori\n  scale_x_continuous(expand = expansion(mult = c(0, 0.1)))  # Aumentare lo spazio sull'asse x per migliorare la visualizzazione\n\n\n\n\n\n\n\nIl grafico mostra la distribuzione a posteriori analitica del parametro di tasso \\(\\lambda\\) di un modello di Poisson, ottenuta utilizzando una distribuzione a priori Gamma e aggiornando i parametri alla luce dei dati osservati. La distribuzione a posteriori è calcolata come una Gamma aggiornata con i parametri \\(\\alpha_{\\text{post}}\\) e \\(\\beta_{\\text{post}}\\), e rappresenta la nostra conoscenza aggiornata dopo aver visto i dati. I risultati analitici concordano con quelli ottenuti tramite simulazione.\nProcediamo ora con il calcolo della soluzione analitica per la media della distribuzione a posteriori del parametro \\(\\lambda\\):\n\n# Media della distribuzione a posteriori\nposterior_mean &lt;- alpha_post / beta_post\ncat(sprintf(\"Media a Posteriori = %.3f\\n\", posterior_mean))\n#&gt; Media a Posteriori = 2.200\n\n# Parametri della distribuzione a posteriori\ncat(sprintf(\"Shape (α) = %.1f\\n\", alpha_post))\n#&gt; Shape (α) = 22.0\ncat(sprintf(\"Rate (β) = %.1f\\n\", beta_post))\n#&gt; Rate (β) = 10.0\n\nPossiamo calcolare la probabilità di qualsiasi evento di interesse. Per esempio, ci possiamo chiedere quale sia la probabilità di osservare più di 3 compulsioni per ora:\n\n# Probabilità di osservare più di 3 eventi\nprob_y_greater_than_3 &lt;- 1 - pgamma(3, shape = alpha_post, rate = beta_post)\ncat(sprintf(\"Probabilità di osservare più di 3 eventi = %.3f\\n\", prob_y_greater_than_3))\n#&gt; Probabilità di osservare più di 3 eventi = 0.054",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_gamma_poisson_model.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/11_gamma_poisson_model.html#riflessioni-conclusive",
    "title": "55  Modello coniugato Gamma-Poisson",
    "section": "\n55.6 Riflessioni Conclusive",
    "text": "55.6 Riflessioni Conclusive\nIl modello Gamma-Poisson offre un framework robusto per l’inferenza bayesiana su dati di conteggio in psicologia. Partendo da una distribuzione a priori Gamma, che rappresenta la nostra conoscenza iniziale sul tasso medio, siamo in grado di aggiornare questa conoscenza alla luce dei dati osservati, ottenendo una distribuzione a posteriori che riflette in modo più preciso la realtà sottostante. Questo approccio permette di quantificare l’incertezza associata alle nostre stime e di prendere decisioni informate sulla base dei dati disponibili.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_gamma_poisson_model.html#esercizi",
    "href": "chapters/bayesian_inference/11_gamma_poisson_model.html#esercizi",
    "title": "55  Modello coniugato Gamma-Poisson",
    "section": "\n55.7 Esercizi",
    "text": "55.7 Esercizi\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nConsideriamo uno studio longitudinale su coppie, dove i partecipanti registrano quotidianamente la frequenza con cui nascondono il loro comportamento di fumo al partner. Basandoci sui dati di Scholz et al. (2021), assumiamo che il tasso medio di nascondere il fumo sia di 1.52 volte al giorno. Supponiamo di avere i seguenti dati giornalieri per un partecipante:\n\nGiorno 1: 2 volte.\nGiorno 2: 0 volte.\nGiorno 3: 1 volta.\nGiorno 4: 3 volte.\n\nUtilizzare un modello Gamma-Poisson per stimare la distribuzione a posteriori del tasso individuale di nascondere il fumo per un partecipante specifico, dato il suo insieme di osservazioni giornaliere.\n\n\n\n\n\n\n\n\n\nSoluzione\n\n\n\n\n\nVogliamo stimare quante volte al giorno una persona tende a nascondere il proprio fumo al partner. Abbiamo quattro giorni di dati su questa persona e, grazie a un precedente studio, sappiamo che in media le persone lo fanno circa 1.52 volte al giorno.\nMa i dati di una sola persona sono pochi, quindi useremo un approccio bayesiano per combinare:\n\n\nLe informazioni preesistenti (dal precedente studio),\n\nLe nuove osservazioni (quanti eventi sono stati registrati nei quattro giorni).\n\nCon un modello Gamma-Poisson, possiamo aggiornare la nostra stima e ottenere una distribuzione a posteriori, che ci dirà quali sono i valori più probabili per il tasso di nascondimento di questa persona.\n# Dati osservati: numero di volte che la persona ha nascosto il fumo ogni giorno\nosservazioni &lt;- c(2, 0, 1, 3)\n\n# Numero totale di giorni osservati\nn_giorni &lt;- length(osservazioni)\n\n# Numero totale di eventi (quante volte ha nascosto il fumo in totale)\neventi_totali &lt;- sum(osservazioni)\n\n# Informazione a priori dallo studio precedente\nmedia_priori &lt;- 1.52\nforma_priori &lt;- 3   # Parametro di forma scelto per un'incertezza moderata\ntasso_priori &lt;- forma_priori / media_priori  # Parametro di scala\n\n# Aggiornamento bayesiano: parametri della distribuzione a posteriori\nforma_post &lt;- forma_priori + eventi_totali\ntasso_post &lt;- tasso_priori + n_giorni\n\n# Creazione della griglia di valori possibili per il tasso giornaliero (lambda)\nlambda_valori &lt;- seq(0, 5, length.out = 100)\n\n# Calcolo delle densità per le distribuzioni a priori e a posteriori\ndensita_priori &lt;- dgamma(lambda_valori, shape = forma_priori, rate = tasso_priori)\ndensita_post &lt;- dgamma(lambda_valori, shape = forma_post, rate = tasso_post)\n\n# Creazione di un dataframe per il grafico\ndati_plot &lt;- data.frame(\n  lambda = rep(lambda_valori, 2),\n  densita = c(densita_priori, densita_post),\n  distribuzione = rep(c(\"Priori\", \"Posteriori\"), each = length(lambda_valori))\n)\n\n# Creazione del grafico per confrontare la distribuzione a priori e quella aggiornata (posteriori)\nggplot(dati_plot, aes(x = lambda, y = densita, color = distribuzione)) +\n  geom_line(size = 1.2) +\n  labs(\n    title = \"Stima del tasso di nascondimento del fumo\",\n    x = \"Tasso giornaliero (λ)\",\n    y = \"Densità\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\nCosa fa questo codice\n\n\nCarica i dati: abbiamo registrato per 4 giorni quante volte questa persona ha nascosto il fumo.\n\nImposta una conoscenza iniziale (priori): basata sullo studio precedente.\n\nApplica il teorema di Bayes per aggiornare la stima con i nuovi dati.\n\nGenera il grafico: confronta la distribuzione prima e dopo l’aggiornamento con i dati osservati.\n\nInterpretazione del risultato\n\nLa curva rossa (priori) rappresenta la nostra stima iniziale, basata sullo studio precedente.\nLa curva blu (posteriori) è la nostra nuova stima dopo aver considerato i dati della persona.\nSe i dati raccolti sono molto diversi dal valore medio dello studio, la curva blu si sposterà rispetto alla rossa.\n\nQuesta analisi ci permette di stimare il comportamento specifico di una persona integrando dati generali e osservazioni individuali, in modo più informativo rispetto a una semplice media.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_gamma_poisson_model.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/11_gamma_poisson_model.html#informazioni-sullambiente-di-sviluppo",
    "title": "55  Modello coniugato Gamma-Poisson",
    "section": "\n55.8 Informazioni sull’Ambiente di Sviluppo",
    "text": "55.8 Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] reshape2_1.4.4   mice_3.17.0      thematic_0.1.6   MetBrewer_0.2.0 \n#&gt;  [5] ggokabeito_0.1.0 see_0.11.0       gridExtra_2.3    patchwork_1.3.0 \n#&gt;  [9] bayesplot_1.12.0 psych_2.5.3      scales_1.4.0     markdown_2.0    \n#&gt; [13] knitr_1.50       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   \n#&gt; [17] dplyr_1.1.4      purrr_1.0.4      readr_2.1.5      tidyr_1.3.1     \n#&gt; [21] tibble_3.2.1     ggplot2_3.5.2    tidyverse_2.0.0  rio_1.2.3       \n#&gt; [25] here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1   farver_2.1.2       fastmap_1.2.0     \n#&gt;  [4] pacman_0.5.1       digest_0.6.37      rpart_4.1.24      \n#&gt;  [7] timechange_0.3.0   lifecycle_1.0.4    survival_3.8-3    \n#&gt; [10] magrittr_2.0.3     compiler_4.5.0     rlang_1.1.6       \n#&gt; [13] tools_4.5.0        labeling_0.4.3     htmlwidgets_1.6.4 \n#&gt; [16] mnormt_2.1.1       plyr_1.8.9         RColorBrewer_1.1-3\n#&gt; [19] withr_3.0.2        nnet_7.3-20        grid_4.5.0        \n#&gt; [22] jomo_2.7-6         iterators_1.0.14   MASS_7.3-65       \n#&gt; [25] cli_3.6.5          rmarkdown_2.29     reformulas_0.4.1  \n#&gt; [28] generics_0.1.4     rstudioapi_0.17.1  tzdb_0.5.0        \n#&gt; [31] minqa_1.2.8        splines_4.5.0      parallel_4.5.0    \n#&gt; [34] vctrs_0.6.5        boot_1.3-31        glmnet_4.1-8      \n#&gt; [37] Matrix_1.7-3       jsonlite_2.0.0     hms_1.1.3         \n#&gt; [40] mitml_0.4-5        foreach_1.5.2      glue_1.8.0        \n#&gt; [43] nloptr_2.2.1       pan_1.9            codetools_0.2-20  \n#&gt; [46] stringi_1.8.7      shape_1.4.6.1      gtable_0.3.6      \n#&gt; [49] lme4_1.1-37        pillar_1.10.2      htmltools_0.5.8.1 \n#&gt; [52] R6_2.6.1           Rdpack_2.6.4       rprojroot_2.0.4   \n#&gt; [55] evaluate_1.0.3     lattice_0.22-7     rbibutils_2.3     \n#&gt; [58] backports_1.5.0    broom_1.0.8        Rcpp_1.0.14       \n#&gt; [61] nlme_3.1-168       xfun_0.52          pkgconfig_2.0.3",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_gamma_poisson_model.html#bibliografia",
    "href": "chapters/bayesian_inference/11_gamma_poisson_model.html#bibliografia",
    "title": "55  Modello coniugato Gamma-Poisson",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nScholz, U., Stadler, G., Berli, C., Lüscher, J., & Knoll, N. (2021). How do people experience and respond to social control from their partner? Three daily diary studies. Frontiers in Psychology, 11, 613546.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/12_gamma_exponential_model.html",
    "href": "chapters/bayesian_inference/12_gamma_exponential_model.html",
    "title": "56  Modello gamma-esponenziale",
    "section": "",
    "text": "56.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nNell’inferenza bayesiana, il modello coniugato Gamma-Esponenziale rappresenta un approccio analitico efficace per l’analisi di dati che seguono una distribuzione esponenziale. Questa distribuzione è comunemente utilizzata per modellare i tempi di attesa tra eventi in processi di Poisson, come ad esempio gli intervalli tra arrivi in un sistema a coda o la durata di eventi psicologici.\nConsideriamo, ad esempio, un esperimento in psicologia in cui si misurano i tempi di insorgenza di episodi di ansia in seguito a un evento stressante. In questo caso, si può ipotizzare che i tempi di insorgenza siano distribuiti esponenzialmente. Il parametro \\(\\lambda\\) della distribuzione esponenziale rappresenta il tasso medio con cui si verificano gli episodi di ansia.\nIl modello coniugato Gamma-Esponenziale consente di stimare il parametro \\(\\lambda\\) utilizzando i dati osservati. La distribuzione a priori Gamma viene utilizzata per rappresentare l’incertezza iniziale su \\(\\lambda\\), mentre la distribuzione esponenziale modella i dati osservati. Grazie a questa coniugazione, l’aggiornamento delle credenze sul parametro \\(\\lambda\\) avviene in modo semplice e analitico, permettendo di ottenere una stima bayesiana del tasso medio di occorrenza degli episodi di ansia, fornendo così una descrizione probabilistica accurata del fenomeno in esame.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>Modello gamma-esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/12_gamma_exponential_model.html#introduzione",
    "href": "chapters/bayesian_inference/12_gamma_exponential_model.html#introduzione",
    "title": "56  Modello gamma-esponenziale",
    "section": "",
    "text": "56.1.1 Il Modello Matematico\nCaso singolo. Supponiamo di osservare un singolo tempo di attesa \\(y_1\\) prima che si verifichi un evento, come un episodio di disagio psicologico. Assumiamo che questo tempo di attesa segua una distribuzione esponenziale con parametro \\(\\lambda\\). La funzione di densità di probabilità (pdf) della distribuzione esponenziale è data da:\n\\[\nf(y_1 \\mid \\lambda) = \\lambda e^{-\\lambda y_1},\n\\]\ndove:\n\n\n\\(y_1\\) rappresenta il tempo di attesa,\n\n\\(\\lambda\\) è il parametro della distribuzione, che rappresenta il tasso medio con cui gli eventi si verificano per unità di tempo.\n\nIn questa distribuzione, \\(\\lambda\\) è il tasso di occorrenza o tasso di decadimento, ed è l’inverso del tempo medio di attesa. Più precisamente:\n\nIl tempo medio di attesa è il valore medio del tempo che trascorre prima che l’evento si verifichi (ad esempio, quanto tempo ci si aspetta in media prima che arrivi un autobus).\nIl parametro \\(\\lambda\\) rappresenta la frequenza con cui l’evento si verifica per unità di tempo, e quindi \\(\\lambda = \\frac{1}{\\text{tempo medio}}\\).\n\nPertanto, nella funzione esponenziale \\(f(y_1 \\mid \\lambda) = \\lambda e^{-\\lambda y_1}\\), il parametro \\(\\lambda\\) è inversamente proporzionale al tempo medio di attesa: più grande è \\(\\lambda\\), più breve è il tempo medio di attesa tra gli eventi.\nQuesta funzione descrive la probabilità di osservare un tempo di attesa esattamente uguale a \\(y_1\\), dato un valore specifico di \\(\\lambda\\). Per la distribuzione esponenziale, la media è \\(\\frac{1}{\\lambda}\\) e la varianza è \\(\\frac{1}{\\lambda^2}\\), il che riflette l’influenza del tasso \\(\\lambda\\) sulla dispersione dei tempi di attesa.\nPer fare un esempio, supponiamo che il tempo medio di attesa sia 2 ore. In questo caso, il parametro \\(\\lambda\\) (l’inverso del tempo medio di attesa) è \\(\\frac{1}{2}\\).\n\n# Parametro lambda (l'inverso del tempo medio di attesa)\nlambda_value &lt;- 1 / 2\n\nDisegniamo la funzione di densità esponenziale per tempi di attesa compresi tra 0 e 10 ore.\n\n# Creazione dei valori di y1 su cui valutare la funzione\ny1_values &lt;- seq(0, 10, length.out = 500) # Intervallo da 0 a 10 ore\n\n# Definizione della funzione di densità esponenziale\nexponential_density &lt;- function(y1, lambda_value) {\n  lambda_value * exp(-lambda_value * y1)\n}\n\n# Calcolo dei valori di f(y1 | lambda)\nf_values &lt;- exponential_density(y1_values, lambda_value)\n\n# Creazione del grafico\nplot(\n  y1_values, f_values,\n  type = \"l\", lwd = 2,\n  main = expression(paste(\n    \"Funzione di Densità Esponenziale con \",\n    lambda, \" = 1/2\"\n  )),\n  xlab = \"Tempo di attesa (ore)\", ylab = \"Densità\"\n)\nlegend(\"topright\",\n  legend = expression(f(y[1] ~ \"|\" ~ lambda) == lambda ~ e^(-lambda * y[1])),\n  lty = 1, bty = \"n\"\n)\n\n\n\n\n\n\n\nQuesto codice crea un grafico della funzione di densità esponenziale per \\(\\lambda = 1/2\\) e tempi di attesa compresi tra 0 e 10 ore.\nIl caso di \\(n\\) osservazioni indipendenti. Consideriamo ora un campione di \\(n\\) osservazioni indipendenti \\(y_1, y_2, \\dots, y_n\\). L’indipendenza tra le osservazioni implica che il tempo di attesa osservato per un evento non influisce sulla probabilità di osservare altri tempi di attesa.\nPoiché le osservazioni sono indipendenti, la probabilità congiunta di osservare tutti i tempi di attesa nel campione è il prodotto delle probabilità individuali. Di conseguenza, la funzione di verosimiglianza per l’intero campione è data da:\n\\[\nf(y_1, y_2, \\dots, y_n \\mid \\lambda) = f(y_1 \\mid \\lambda) \\cdot f(y_2 \\mid \\lambda) \\cdot \\dots \\cdot f(y_n \\mid \\lambda).\n\\]\nSostituendo la funzione di densità della distribuzione esponenziale per ciascuna osservazione, otteniamo:\n\\[\nf(y \\mid \\lambda) = \\lambda e^{-\\lambda y_1} \\cdot \\lambda e^{-\\lambda y_2} \\cdot \\dots \\cdot \\lambda e^{-\\lambda y_n}.\n\\]\nRaccogliendo i termini comuni, possiamo riscrivere la funzione di verosimiglianza come:\n\\[\nf(y \\mid \\lambda) = \\lambda^n e^{-\\lambda (y_1 + y_2 + \\dots + y_n)}.\n\\]\nUtilizzando la notazione di sommatoria, possiamo esprimere la funzione di verosimiglianza in modo compatto come:\n\\[\nf(y \\mid \\lambda) = \\lambda^n e^{-\\lambda \\sum_{i=1}^{n} y_i}.\n\\]\nLa funzione di verosimiglianza \\(f(y \\mid \\lambda)\\) rappresenta la probabilità di osservare il campione \\(y_1, y_2, \\dots, y_n\\) dato un particolare valore del parametro \\(\\lambda\\). Un valore più alto della verosimiglianza indica una maggiore plausibilità del valore di \\(\\lambda\\), dato il campione osservato.\nSpesso è più conveniente lavorare con il logaritmo della funzione di verosimiglianza, poiché il logaritmo trasforma i prodotti in somme, semplificando i calcoli. Il logaritmo della funzione di verosimiglianza è:\n\\[\n\\log L(\\lambda \\mid y_1, y_2, \\dots, y_n) = n \\log \\lambda - \\lambda \\sum_{i=1}^{n} y_i.\n\\]\nQuesta forma semplificata della log-verosimiglianza è utile per stimare il parametro \\(\\lambda\\) tramite tecniche come la massimizzazione della verosimiglianza.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>Modello gamma-esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/12_gamma_exponential_model.html#aggiornare-le-nostre-credenze-con-linferenza-bayesiana",
    "href": "chapters/bayesian_inference/12_gamma_exponential_model.html#aggiornare-le-nostre-credenze-con-linferenza-bayesiana",
    "title": "56  Modello gamma-esponenziale",
    "section": "\n56.2 Aggiornare le Nostre Credenze con l’Inferenza Bayesiana",
    "text": "56.2 Aggiornare le Nostre Credenze con l’Inferenza Bayesiana\nNell’approccio bayesiano, non consideriamo solo i dati, ma anche le nostre conoscenze a priori sul parametro \\(\\lambda\\). Assegniamo a \\(\\lambda\\) una distribuzione a priori, tipicamente una distribuzione Gamma. Combinando la verosimiglianza con la distribuzione a priori, otteniamo la distribuzione a posteriori di \\(\\lambda\\), che rappresenta la nostra conoscenza aggiornata alla luce dei dati. La proprietà della coniugazione assicura che la distribuzione a posteriori sia anch’essa una Gamma, facilitando i calcoli.\nPer fare un esempio concreto, simuleremo un campione di dati. Immaginiamo di raccogliere dati che rappresentano il tempo, misurato in ore, che intercorre tra episodi di ansia in individui con disturbi d’ansia. La distribuzione esponenziale può essere utilizzata per modellare questo tempo di attesa tra un episodio di ansia e il successivo. Ad esempio, possiamo ipotizzare che, una volta concluso un episodio, l’insorgenza del prossimo segua un processo stocastico con un tasso costante, indipendentemente dal tempo trascorso dall’episodio precedente. In questo contesto, il parametro \\(\\lambda\\) della distribuzione esponenziale rappresenta il tasso medio di occorrenza degli episodi di ansia, ossia quanti episodi ci si aspetta in media in una certa unità di tempo (ad esempio, in un giorno).\nSe \\(\\lambda\\) è elevato, ciò indica che gli episodi di ansia sono più frequenti, con tempi di attesa più brevi tra un episodio e l’altro.\n\n# Impostiamo il seed per rendere i risultati riproducibili\nset.seed(42)\n\n# Parametro medio (tempo medio di attesa in ore)\nmean_time &lt;- 3.0\nlambda_param &lt;- 1 / mean_time # Parametro lambda per la distribuzione esponenziale\n\n# Numero di osservazioni nel campione\nn &lt;- 15\n\n# Generazione del campione casuale\ny &lt;- round(rexp(n, rate = lambda_param))\ny\n#&gt;  [1] 1 2 1 0 1 4 1 1 4 2 4 7 0 0 4\n\nImmaginiamo che questi dati rappresentino il tempo di attesa in ore tra episodi di ansia in 15 individui con disturbi d’ansia. Il tempo di attesa medio è:\n\nmean_time_observed &lt;- mean(y)\nmean_time_observed\n#&gt; [1] 2.133\n\nIl tasso di occorrenza, \\(\\lambda\\), calcolato sulla base dei dati osservati è:\n\nlambda_estimated &lt;- 1 / mean_time_observed\nlambda_estimated\n#&gt; [1] 0.4688\n\nOra possiamo procedere a trovare la distribuzione a posteriori per il tasso di occorrenza \\(\\lambda\\).\n\n56.2.1 Passi per definire un prior debolmente informativo\nIl primo passo consiste nel definire una distribuzione a priori per \\(\\lambda\\), il tasso di occorrenza degli episodi di ansia in individui con disturbi d’ansia. Se disponiamo di poche informazioni a priori riguardo al valore di \\(\\lambda\\), possiamo adottare una distribuzione a priori debolmente informativa. Un prior debolmente informativo ha lo scopo di esercitare una minima influenza sull’inferenza, consentendo ai dati osservati di guidare principalmente la stima del parametro.\nLa distribuzione a priori coniugata per la distribuzione esponenziale è la distribuzione Gamma. Un prior debolmente informativo per \\(\\lambda\\) potrebbe essere impostato in modo tale da riflettere una conoscenza vaga, con una media che rappresenta un tempo di attesa ragionevole (basato su qualche informazione preliminare o ipotesi generale), ma con una varianza ampia, in modo da non vincolare eccessivamente l’inferenza.\nSupponiamo di voler impostare una distribuzione a priori per il tasso di occorrenza \\(\\lambda\\), in modo tale che il tempo medio di attesa sia 3.33 ore, con una deviazione standard ampia, ad esempio 5 ore. Poiché \\(\\lambda\\) rappresenta il tasso di occorrenza (ovvero l’inverso del tempo medio di attesa), dobbiamo applicare la distribuzione Gamma ai valori di \\(\\lambda\\), non direttamente ai tempi di attesa.\nI parametri della distribuzione Gamma, \\(\\alpha\\) (forma) e \\(\\beta\\) (tasso), sono dati da:\n\n\\(\\alpha_{\\text{prior}} = 0.45\\)\n\\(\\beta_{\\text{prior}} = 1.5\\)\n\nVerifichiamo che questi parametri corrispondano alla media e alla varianza desiderate.\n\n# Parametri della distribuzione Gamma\nalpha_prior &lt;- 0.45 # Forma\nbeta_prior &lt;- 1.5 # Tasso (inverso della scala)\n\n# Calcolo della media e della varianza della distribuzione Gamma per λ\nmean_lambda &lt;- alpha_prior / beta_prior\nvariance_lambda &lt;- alpha_prior / (beta_prior^2)\n\n# Calcolo della media del tempo di attesa (E[Y] = 1 / E[λ])\nmean_waiting_time &lt;- 1 / mean_lambda\n\n# Stampiamo la media e la varianza di λ e del tempo di attesa\ncat(\"Media di λ:\", mean_lambda, \"\\n\")\n#&gt; Media di λ: 0.3\ncat(\"Varianza di λ:\", variance_lambda, \"\\n\")\n#&gt; Varianza di λ: 0.2\ncat(\"Media del tempo di attesa:\", mean_waiting_time, \"ore\\n\")\n#&gt; Media del tempo di attesa: 3.333 ore\n\nLa media del tempo di attesa è 3.33 ore, come desiderato. La varianza del tempo di attesa richiede un calcolo più complesso e non è semplicemente l’inverso della varianza di \\(\\lambda\\).\n\n56.2.2 Visualizzazione della Distribuzione a Priori\nDisegniamo la funzione di densità della distribuzione Gamma per \\(\\lambda\\), utilizzando i parametri specificati.\n\n# Creazione dei valori x per il grafico\nx &lt;- seq(0, 2, length.out = 500)\n\n# Funzione di densità della distribuzione Gamma con i parametri dati\ngamma_pdf &lt;- dgamma(x, shape = alpha_prior, rate = beta_prior)\n\n# Creazione del grafico\nplot(x, gamma_pdf,\n  type = \"l\", lwd = 2,\n  main = bquote(\"Funzione di Densità Gamma con \" ~ alpha == .(alpha_prior) ~ \",\" ~ beta == .(beta_prior)),\n  xlab = expression(lambda),\n  ylab = \"Densità di probabilità\"\n)\nlegend(\n  \"topright\",\n  legend = \"Distribuzione a Priori\",\n  lty = 1,\n  lwd = 2,\n  bty = \"n\"\n)",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>Modello gamma-esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/12_gamma_exponential_model.html#metodo-basato-su-griglia",
    "href": "chapters/bayesian_inference/12_gamma_exponential_model.html#metodo-basato-su-griglia",
    "title": "56  Modello gamma-esponenziale",
    "section": "\n56.3 Metodo Basato su Griglia",
    "text": "56.3 Metodo Basato su Griglia\nPoniamoci l’obiettivo di utilizzare il metodo basato su griglia per derivare la distribuzione a posteriori del parametro \\(\\lambda\\) della distribuzione esponenziale. Iniziamo creando una griglia per \\(\\lambda\\) nell’intervallo [0.01, 2].\n\n# Evitiamo zero per evitare divisione per zero\nlambda_grid &lt;- seq(0.01, 2, length.out = 1000)\n\n\n56.3.1 Calcolo della Distribuzione a Priori\n\n# Calcolo della distribuzione a priori\nprior &lt;- dgamma(lambda_grid, shape = alpha_prior, rate = beta_prior)\n\n\n56.3.2 Calcolo della Verosimiglianza\nImmaginiamo di avere i seguenti dati, che rappresentano i tempi di attesa (in ore) tra episodi di ansia per 15 individui:\n\n# Impostiamo il seed per rendere i risultati riproducibili\nset.seed(42)\n\n# Parametro medio (tempo medio di attesa in ore)\nmean_time &lt;- 3.0\nlambda_param &lt;- 1 / mean_time # Parametro λ per la distribuzione esponenziale\n\n# Numero di osservazioni nel campione\nn &lt;- 15\n\n# Generazione del campione casuale\ny &lt;- round(rexp(n, rate = lambda_param))\ny\n#&gt;  [1] 1 2 1 0 1 4 1 1 4 2 4 7 0 0 4\n\nCalcoliamo la log-verosimiglianza per ciascun valore di \\(\\lambda\\) nella griglia:\n\n# Calcolo della log-verosimiglianza per ciascun valore di lambda\nlog_likelihood &lt;- sapply(\n  lambda_grid,\n  function(lam) sum(dexp(y, rate = lam, log = TRUE))\n)\n\n\n56.3.3 Calcolo della Distribuzione a Posteriori\nCalcoliamo la distribuzione a posteriori non normalizzata in logaritmo per evitare problemi di underflow numerico:\n\n# Calcolo del log-posteriori non normalizzato\nlog_posterior_unnormalized &lt;- log_likelihood + log(prior)\n\n# Normalizzazione per stabilità numerica\nlog_posterior_unnormalized &lt;- log_posterior_unnormalized - max(log_posterior_unnormalized)\n\n# Convertiamo in scala normale\nposterior_unnormalized &lt;- exp(log_posterior_unnormalized)\n\nNormalizziamo la distribuzione a posteriori:\n\n# Calcolo del passo nella griglia\ndelta_lambda &lt;- diff(lambda_grid)[1] # Assumendo che la griglia sia equispaziata\n\n# Normalizzazione della distribuzione a posteriori\nposterior &lt;-\n  posterior_unnormalized / sum(posterior_unnormalized * delta_lambda)\n\n\n56.3.4 Visualizzazione dei Risultati\n\n# Grafico della distribuzione a posteriori e a priori\nplot(lambda_grid, posterior,\n  type = \"l\",\n  lwd = 2,\n  xlab = expression(lambda),\n  ylab = \"Densità di probabilità\",\n  main = \"Distribuzione a Posteriori di λ\"\n)\nlines(lambda_grid, prior, lwd = 2, lty = 2)\nlegend(\"topright\",\n  legend = c(\"Posteriori\", \"Priori\"),\n  lty = c(1, 2), \n  lwd = 2, \n  bty = \"n\"\n)\n\n\n\n\n\n\n\nDal grafico, possiamo osservare come la distribuzione a posteriori di \\(\\lambda\\) sia aggiornata rispetto alla distribuzione a priori in base ai dati osservati. La distribuzione a posteriori riflette sia le informazioni a priori sia l’evidenza fornita dai dati, fornendo una stima aggiornata del tasso di occorrenza degli episodi di ansia.\n\n56.3.5 Calcolo della Media e Varianza Posteriori\nPossiamo calcolare la media e la varianza a posteriori di \\(\\lambda\\) utilizzando la distribuzione a posteriori calcolata sulla griglia.\n\n# Calcolo della media a posteriori di λ\nposterior_mean_lambda &lt;- sum(lambda_grid * posterior * delta_lambda)\n\n# Calcolo della varianza a posteriori di λ\nposterior_variance_lambda &lt;-\n  sum((lambda_grid - posterior_mean_lambda)^2 * posterior * delta_lambda)\n\n# Stampiamo i risultati\ncat(\"Media a posteriori di λ:\", posterior_mean_lambda, \"\\n\")\n#&gt; Media a posteriori di λ: 0.4612\ncat(\"Varianza a posteriori di λ:\", posterior_variance_lambda, \"\\n\")\n#&gt; Varianza a posteriori di λ: 0.01377\n\n\n56.3.6 Stima del Tempo di Attesa Medio a Posteriori\nUtilizzando la media a posteriori di \\(\\lambda\\), possiamo stimare il tempo di attesa medio a posteriori:\n\n# Stima del tempo di attesa medio a posteriori\nposterior_mean_waiting_time &lt;- 1 / posterior_mean_lambda\ncat(\"Tempo di attesa medio a posteriori:\", posterior_mean_waiting_time, \"ore\\n\")\n#&gt; Tempo di attesa medio a posteriori: 2.168 ore\n\nIn conclusione, attraverso il metodo basato su griglia, abbiamo derivato la distribuzione a posteriori del tasso di occorrenza \\(\\lambda\\), tenendo conto della nostra conoscenza a priori e dei dati osservati. Questo approccio ci permette di aggiornare le nostre credenze su \\(\\lambda\\) in modo coerente con l’evidenza empirica, fornendo stime più accurate e affidabili.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>Modello gamma-esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/12_gamma_exponential_model.html#modello-coniugato-gamma-esponenziale",
    "href": "chapters/bayesian_inference/12_gamma_exponential_model.html#modello-coniugato-gamma-esponenziale",
    "title": "56  Modello gamma-esponenziale",
    "section": "\n56.4 Modello Coniugato Gamma-Esponenziale",
    "text": "56.4 Modello Coniugato Gamma-Esponenziale\nQuando utilizziamo una distribuzione \\(\\text{Gamma}(\\alpha, \\beta)\\) come distribuzione coniugata a priori, la distribuzione a posteriori risulta anch’essa essere una distribuzione Gamma, con parametri aggiornati \\(\\alpha + n\\) e \\(\\beta + \\sum_{i=1}^{n} x_{i}\\).\nIn altre parole, se il parametro \\(\\lambda\\) della distribuzione esponenziale segue una distribuzione a priori Gamma con parametri \\(\\alpha\\) e \\(\\beta\\), allora, dopo aver osservato un campione di \\(n\\) osservazioni \\(x_1, x_2, \\dots, x_n\\), la distribuzione a posteriori di \\(\\lambda\\) sarà ancora una distribuzione Gamma, ma con i parametri aggiornati:\n\\[\n\\lambda \\mid x \\sim \\text{Gamma}(\\alpha + n, \\beta + \\sum_{i=1}^{n} x_{i}).\n\\]\nQuesto aggiornamento dei parametri è una conseguenza della proprietà coniugata della distribuzione Gamma rispetto alla distribuzione esponenziale.\n\n56.4.1 Dimostrazione del Modello Coniugato Gamma-Esponenziale\nPer dimostrare questo risultato, partiamo dal teorema di Bayes:\n\\[\nf(\\lambda \\mid x) \\propto f(x \\mid \\lambda) \\cdot f(\\lambda),\n\\]\ndove \\(f(\\lambda \\mid x)\\) è la distribuzione a posteriori di \\(\\lambda\\) dato il campione \\(x\\), \\(f(x \\mid \\lambda)\\) è la verosimiglianza basata sul campione \\(x\\), e \\(f(\\lambda)\\) è la distribuzione a priori di \\(\\lambda\\).\nLa funzione di verosimiglianza per un campione di \\(n\\) osservazioni indipendenti \\(x_1, x_2, \\dots, x_n\\), che seguono una distribuzione esponenziale con parametro \\(\\lambda\\), è data da:\n\\[\nf(x \\mid \\lambda) = \\prod_{i=1}^{n} \\lambda e^{-\\lambda x_i} = \\lambda^n e^{-\\lambda \\sum_{i=1}^{n} x_i}.\n\\]\nSupponiamo che il parametro \\(\\lambda\\) segua una distribuzione a priori Gamma con parametri \\(\\alpha\\) e \\(\\beta\\):\n\\[\nf(\\lambda) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} \\lambda^{\\alpha - 1} e^{-\\beta \\lambda}.\n\\]\nMoltiplicando la verosimiglianza per la distribuzione a priori, otteniamo la distribuzione a posteriori:\n\\[\nf(\\lambda \\mid x) \\propto \\lambda^n e^{-\\lambda \\sum_{i=1}^{n} x_i} \\cdot \\lambda^{\\alpha - 1} e^{-\\beta \\lambda}.\n\\]\nSemplificando, si ottiene:\n\\[\nf(\\lambda \\mid x) \\propto \\lambda^{n + \\alpha - 1} e^{-\\lambda \\left(\\beta + \\sum_{i=1}^{n} x_i\\right)}.\n\\]\nQuesta espressione corrisponde alla forma di una distribuzione Gamma con parametri aggiornati:\n\nparametro della forma (alpha): \\(\\alpha_{\\text{post}} = \\alpha + n\\);\nparametro della scala (beta): \\(\\beta_{\\text{post}} = \\beta + \\sum_{i=1}^{n} x_i\\).\n\nQuindi, la distribuzione a posteriori di \\(\\lambda\\) dato il campione \\(x\\) segue una distribuzione Gamma con parametri aggiornati:\n\\[\n\\lambda \\mid x \\sim \\text{Gamma}(\\alpha + n, \\beta + \\sum_{i=1}^{n} x_i).\n\\]\nQuesta derivazione mostra come l’informazione contenuta nei dati osservati venga incorporata nei parametri della distribuzione a posteriori, mantenendo la forma della distribuzione a priori grazie alla proprietà coniugata.\n\n56.4.2 Calcolo dei Parametri Aggiornati\nPer il caso dell’esempio in discussione:\n\nIl numero di osservazioni nel campione \\(n\\) è 15;\nLa somma delle osservazioni nel campione è:\n\n\\[\n\\sum_{i=1}^{n} y_i =\n1 + 9 + 4 + 3 + 1 + 1 + 0 + 6 + 3 + 4 + 0 + 11 + 5 + 1 + 1 = 50.\n\\]\nLa distribuzione a posteriori per \\(\\lambda\\) segue una distribuzione Gamma aggiornata con i seguenti parametri:\n\\[\n\\alpha_{\\text{post}} = \\alpha_{\\text{prior}} + n,\n\\]\n\\[\n\\beta_{\\text{post}} = \\beta_{\\text{prior}} + \\sum_{i=1}^{n} y_i.\n\\]\nUsando i valori \\(\\alpha_{\\text{prior}} = 0.009\\) e \\(\\beta_{\\text{prior}} = 0.03\\), otteniamo:\n\\[\n\\alpha_{\\text{post}} = 0.009 + 15 = 15.009,\n\\]\n\\[\n\\beta_{\\text{post}} = 0.03 + 50 = 50.03.\n\\]\n\n# Dati iniziali\nalpha_prior &lt;- 0.009\nbeta_prior &lt;- 0.03\nn &lt;- 15\ny &lt;- c(1, 9, 4, 3, 1, 1, 0, 6, 3, 4, 0, 11, 5, 1, 1)\nsum_y &lt;- sum(y)\n\n# Parametri aggiornati\nalpha_post &lt;- alpha_prior + n\nbeta_post &lt;- beta_prior + sum_y\n\n# Stampa dei parametri aggiornati\ncat(sprintf(\"alpha_post = %.3f; beta_post = %.3f\\n\", alpha_post, beta_post))\n#&gt; alpha_post = 15.009; beta_post = 50.030\n\nGeneriamo il grafico della distribuzione a posteriori.\n\n# Griglia di valori di lambda per il grafico\nlambda_grid &lt;- seq(0, 2, length.out = 1000)\n\n# Calcolo della densità della distribuzione Gamma a posteriori\nposterior_pdf &lt;- dgamma(lambda_grid, shape = alpha_post, rate = beta_post)\n\n# Creazione del grafico\nplot(\n  lambda_grid, posterior_pdf,\n  type = \"l\", lwd = 2,\n  main = bquote(\n    \"Distribuzione Gamma a Posteriori con \" ~ alpha[post] ==\n      .(alpha_post) ~ \",\" ~ beta[post] == .(beta_post)\n  ),\n  xlab = expression(lambda), ylab = \"Densità di probabilità\"\n)\nlegend(\n  \"topright\",\n  legend = bquote(\n    Gamma(alpha[post] == .(alpha_post) ~ \",\" ~ beta[post] == .(beta_post))\n  ),\n  lty = 1,\n  lwd = 2,\n  bty = \"n\"\n)\n\n\n\n\n\n\n\n\n56.4.3 Calcolo della Media e della Varianza a Posteriori\nLa media e la varianza della distribuzione a posteriori sono calcolate come:\n\\[\n\\text{E}[\\lambda \\mid y] = \\frac{\\alpha_{\\text{post}}}{\\beta_{\\text{post}}},\n\\]\n\\[\n\\text{Var}[\\lambda \\mid y] = \\frac{\\alpha_{\\text{post}}}{\\beta_{\\text{post}}^2}.\n\\]\nIn R:\n\n# Calcolo della media e della varianza a posteriori\nposterior_mean &lt;- alpha_post / beta_post\nposterior_variance &lt;- alpha_post / (beta_post^2)\n\n# Stampa dei risultati\ncat(sprintf(\"Media a posteriori di λ: %.3f\\n\", posterior_mean))\n#&gt; Media a posteriori di λ: 0.300\ncat(sprintf(\"Varianza a posteriori di λ: %.6f\\n\", posterior_variance))\n#&gt; Varianza a posteriori di λ: 0.005996\n\nLa distribuzione a posteriori di \\(\\lambda\\) è aggiornata in base ai dati osservati e al prior. La media a posteriori rappresenta la stima del tasso di occorrenza degli episodi di ansia, mentre la varianza riflette l’incertezza nella stima.\n\n\nMedia a Posteriori: La media a posteriori di \\(\\lambda\\) è circa 0.3, indicando un tasso di occorrenza medio di 0.3 episodi per ora.\n\nVarianza a Posteriori: La varianza di 0.006 riflette una moderata incertezza nella stima di \\(\\lambda\\).\n\nQuesti risultati evidenziano come la distribuzione Gamma aggiornata combini informazioni a priori e dati osservati per ottenere stime robuste del tasso di occorrenza \\(\\lambda\\).\n\n56.4.4 Trasformazione della media e della varianza\nPer interpretare questi risultati in termini di tempi di attesa, dobbiamo trasformare i valori sulla scala inversa, cioè passare dal tasso \\(\\lambda\\) ai tempi di attesa \\(T = \\frac{1}{\\lambda}\\).\nLa media del tempo di attesa \\(T\\) è l’inverso della media del tasso di occorrenza \\(\\lambda\\). Pertanto, la media dei tempi di attesa sarà:\n\\[\n\\text{E}[T \\mid y] = \\frac{1}{\\text{E}[\\lambda \\mid y]} = \\frac{1}{0.3} \\approx 3.33 \\, \\text{ore}.\n\\]\nPer la varianza del tempo di attesa, dobbiamo applicare una trasformazione più complessa. La varianza del tempo di attesa \\(T\\) è legata alla varianza di \\(\\lambda\\) da:\n\\[\n\\text{Var}(T) = \\frac{\\text{Var}[\\lambda \\mid y]}{(\\text{E}[\\lambda \\mid y])^4}.\n\\]\nSostituendo i valori calcolati per la varianza e la media di \\(\\lambda\\), otteniamo:\n\\[\n\\text{Var}(T) \\approx \\frac{0.006}{(0.3)^4} \\approx 24.59 \\, \\text{ore}.\n\\]\nIn conclusione,\n\nla media del tempo di attesa a posteriori è di circa 3.33 ore;\nla varianza del tempo di attesa a posteriori è di circa 24.59 ore, che indica una certa dispersione dei tempi di attesa, con alcuni episodi che possono verificarsi molto più rapidamente o più lentamente rispetto alla media. Si noti che la distribuzione a posteriori è più concentrata rispetto al prior, poiché incorpora l’informazione aggiuntiva proveniente dai dati osservati.\n\nQuesta trasformazione ci permette di interpretare i risultati sulla scala dei tempi di attesa, che è più intuitiva per descrivere fenomeni psicologici come l’insorgenza di episodi di ansia.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>Modello gamma-esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/12_gamma_exponential_model.html#applicazioni",
    "href": "chapters/bayesian_inference/12_gamma_exponential_model.html#applicazioni",
    "title": "56  Modello gamma-esponenziale",
    "section": "\n56.5 Applicazioni",
    "text": "56.5 Applicazioni\nUna volta ottenuta la distribuzione a posteriori per λ, possiamo utilizzarla per rispondere a domande probabilistiche relative ai tempi di attesa tra episodi di ansia. Questo approccio ci consente di calcolare probabilità aggiornate alla luce dei dati osservati, rispecchiando meglio l’incertezza e le informazioni disponibili. Ad esempio, possiamo stimare la probabilità di osservare tempi di attesa compresi tra 2 e 5 ore.\nPer risolvere questo problema possiamo usare il metodo Monte Carlo:\n\nGeneriamo un gran numero di campioni dalla distribuzione Gamma a posteriori di \\(\\lambda\\), usando i parametri \\(\\alpha_{\\text{posteriori}}\\) e \\(\\beta_{\\text{posteriori}}\\).\nConvertiamo ciascun \\(\\lambda\\) campionato in un tempo di attesa \\(T = \\frac{1}{\\lambda}\\).\nCalcoliamo le probabilità richieste (ad esempio, \\(P(T &gt; 2)\\) e \\(P(T &lt; 5)\\)) semplicemente contando le proporzioni di campioni che soddisfano tali condizioni.\n\n\n56.5.1 Simulazione con Monte Carlo\nUtilizziamo i parametri posteriori della distribuzione Gamma per simulare campioni di \\(\\lambda\\) e calcolare la probabilità che il tempo di attesa tra due episodi di ansia sia compreso tra 2 e 5 ore.\n\n# Parametri posteriori per la distribuzione Gamma\nalpha_post &lt;- 15.009\nbeta_post &lt;- 50.03\n\n# Numero di campioni da generare\nn_samples &lt;- 100000\n\n# Simulazione di campioni dalla distribuzione Gamma per λ\nlambda_samples &lt;- rgamma(n_samples, shape = alpha_post, rate = beta_post)\n\n# Conversione dei campioni di λ in tempi di attesa T = 1/λ\nwaiting_time_samples &lt;- 1 / lambda_samples\n\n# Calcolo della probabilità che il tempo di attesa sia compreso tra 2 e 5 ore\nprob_between_2_and_5_mc &lt;-\n  mean(waiting_time_samples &gt;= 2 & waiting_time_samples &lt;= 5)\n\n# Stampa del risultato\ncat(sprintf(\"Probabilità che il tempo di attesa sia tra 2 e 5 ore: %.4f\\n\", prob_between_2_and_5_mc))\n#&gt; Probabilità che il tempo di attesa sia tra 2 e 5 ore: 0.9027\n\nLa probabilità che il tempo di attesa tra due episodi di ansia sia compreso tra 2 e 5 ore è di circa 0.9029, ovvero il 90.3%. Questa stima si basa su campioni simulati dalla distribuzione a posteriori di \\(\\lambda\\), trasformati nei corrispondenti tempi di attesa. L’approccio Monte Carlo è utile per calcolare probabilità che coinvolgono trasformazioni non lineari, come nel caso del tempo di attesa.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>Modello gamma-esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/12_gamma_exponential_model.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/12_gamma_exponential_model.html#riflessioni-conclusive",
    "title": "56  Modello gamma-esponenziale",
    "section": "\n56.6 Riflessioni Conclusive",
    "text": "56.6 Riflessioni Conclusive\nIl modello esponenziale si rivela uno strumento utile e versatile nella ricerca psicologica, in particolare per la modellazione di fenomeni caratterizzati da tempi di attesa o durate di eventi. È applicabile in vari contesti, tra cui l’analisi dei tempi di reazione, lo studio degli intervalli tra episodi di ansia o depressione e, più in generale, in tutti quei processi psicologici che possono essere descritti come il tempo trascorso fino al verificarsi di un evento.\nUn aspetto particolarmente vantaggioso dell’uso di modelli basati sulla distribuzione esponenziale nell’inferenza bayesiana è la possibilità di utilizzare le famiglie coniugate. Nella famiglia coniugata Gamma-Esponenziale, la distribuzione a priori Gamma per il tasso \\(\\lambda\\) si aggiorna in modo analitico quando si osservano nuovi dati esponenziali. Questo rende i calcoli bayesiani particolarmente efficienti e semplici da implementare, poiché la distribuzione a posteriori rimane della stessa forma della distribuzione a priori (ossia, una Gamma). Tale proprietà coniugata consente di ottenere una stima aggiornata del tasso \\(\\lambda\\) e di fare inferenze accurate sui tempi di attesa futuri.\nLa combinazione tra la distribuzione esponenziale e il prior Gamma non solo semplifica l’inferenza, ma fornisce anche una struttura interpretativa chiara. Ad esempio, il parametro \\(\\lambda\\), che rappresenta il tasso di occorrenza di un fenomeno, viene aggiornato sulla base dell’evidenza osservata, consentendo una stima dinamica della frequenza con cui gli episodi si verificano. Questo approccio bayesiano offre un’interpretazione probabilistica naturale dei tempi di attesa futuri, rispecchiando l’incertezza presente nei dati.\nInoltre, grazie alla flessibilità del metodo Monte Carlo, è possibile simulare campioni dalla distribuzione a posteriori di \\(\\lambda\\) e ottenere stime precise per una vasta gamma di probabilità, come la probabilità che il tempo di attesa sia compreso tra intervalli specifici. Questo approccio simulativo permette di rispondere a domande specifiche relative ai processi psicologici, ad esempio la probabilità che un episodio di ansia duri più di un certo numero di ore.\nIn conclusione, il modello esponenziale, integrato in un framework bayesiano con famiglie coniugate, rappresenta un utile strumento per la ricerca psicologica. Offre un modo rigoroso per modellare e analizzare dati su tempi di attesa e durate, fornendo al contempo una base solida per l’inferenza e la previsione dei processi psicologici.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>Modello gamma-esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/12_gamma_exponential_model.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/12_gamma_exponential_model.html#informazioni-sullambiente-di-sviluppo",
    "title": "56  Modello gamma-esponenziale",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.12.0 psych_2.5.3     \n#&gt;  [9] scales_1.4.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.2   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.4     stringi_1.8.7      lattice_0.22-7    \n#&gt;  [4] hms_1.1.3          digest_0.6.37      magrittr_2.0.3    \n#&gt;  [7] evaluate_1.0.3     grid_4.5.0         timechange_0.3.0  \n#&gt; [10] RColorBrewer_1.1-3 fastmap_1.2.0      rprojroot_2.0.4   \n#&gt; [13] jsonlite_2.0.0     mnormt_2.1.1       cli_3.6.5         \n#&gt; [16] rlang_1.1.6        withr_3.0.2        tools_4.5.0       \n#&gt; [19] parallel_4.5.0     tzdb_0.5.0         pacman_0.5.1      \n#&gt; [22] vctrs_0.6.5        R6_2.6.1           lifecycle_1.0.4   \n#&gt; [25] htmlwidgets_1.6.4  pkgconfig_2.0.3    pillar_1.10.2     \n#&gt; [28] gtable_0.3.6       glue_1.8.0         xfun_0.52         \n#&gt; [31] tidyselect_1.2.1   rstudioapi_0.17.1  farver_2.1.2      \n#&gt; [34] htmltools_0.5.8.1  nlme_3.1-168       rmarkdown_2.29    \n#&gt; [37] compiler_4.5.0",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>Modello gamma-esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/13_post_pred_distr.html",
    "href": "chapters/bayesian_inference/13_post_pred_distr.html",
    "title": "57  Distribuzione predittiva a posteriori",
    "section": "",
    "text": "57.1 Introduzione\nNel contesto dell’inferenza bayesiana, uno degli obiettivi principali è non solo stimare i parametri di un modello (ad esempio, la probabilità \\(p\\) di successo in un esperimento binomiale) ma anche fare previsioni su dati futuri basandosi su ciò che abbiamo osservato. La distribuzione predittiva a posteriori risponde proprio a questa esigenza, combinando:\nIn termini semplici, la distribuzione predittiva a posteriori ci dice quali risultati futuri sono plausibili, dato ciò che sappiamo dai dati osservati e dal modello.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/13_post_pred_distr.html#introduzione",
    "href": "chapters/bayesian_inference/13_post_pred_distr.html#introduzione",
    "title": "57  Distribuzione predittiva a posteriori",
    "section": "",
    "text": "La nostra incertezza sui parametri descritta dalla distribuzione a posteriori.\nLa variabilità intrinseca del processo che genera i dati futuri.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/13_post_pred_distr.html#definizione-formale",
    "href": "chapters/bayesian_inference/13_post_pred_distr.html#definizione-formale",
    "title": "57  Distribuzione predittiva a posteriori",
    "section": "\n57.2 Definizione Formale",
    "text": "57.2 Definizione Formale\nSupponiamo di avere un insieme di dati osservati \\(y = \\{y_1, y_2, \\ldots, y_n\\}\\), generati da un modello che dipende da un parametro sconosciuto \\(\\theta\\). Il parametro \\(\\theta\\) può rappresentare qualsiasi caratteristica del modello, come una probabilità di successo, una media, o un coefficiente in un modello di regressione. Inizialmente, la nostra conoscenza su \\(\\theta\\) è rappresentata dalla distribuzione a priori \\(p(\\theta)\\), che riflette ciò che sappiamo (o non sappiamo) su \\(\\theta\\) prima di osservare i dati.\nDopo aver osservato i dati \\(y\\), possiamo aggiornare la nostra conoscenza su \\(\\theta\\) utilizzando la formula di Bayes per calcolare la distribuzione a posteriori \\(p(\\theta \\mid y)\\):\n\\[\np(\\theta \\mid y) = \\frac{p(y \\mid \\theta) p(\\theta)}{p(y)},\n\\]\ndove:\n\n\\(p(\\theta \\mid y)\\): la distribuzione a posteriori rappresenta la nostra conoscenza aggiornata su \\(\\theta\\) dopo aver osservato i dati.\n\\(p(y \\mid \\theta)\\): la verosimiglianza è la probabilità di osservare i dati dati i parametri del modello.\n\\(p(\\theta)\\): la distribuzione a priori rappresenta la conoscenza iniziale su \\(\\theta\\).\n\n\\(p(y)\\): l’evidenza è la probabilità totale dei dati osservati, calcolata come:\n\\[\np(y) = \\int p(y \\mid \\theta) p(\\theta) \\, d\\theta.\n\\]\n\n\n\n57.2.1 Previsione di Nuovi Dati\n\nQuando vogliamo prevedere un nuovo dato, indicato con \\(\\tilde{y}\\), la nostra attenzione si sposta sulla distribuzione predittiva a posteriori, \\(p(\\tilde{y} \\mid y)\\).\n\n57.2.1.1 Cosa rappresenta \\(\\tilde{y}\\)?\n\n\n\\(\\tilde{y}\\) rappresenta un dato futuro o non osservato. Ad esempio, se i dati \\(y\\) rappresentano il numero di successi osservati in una serie di lanci di una moneta, \\(\\tilde{y}\\) potrebbe rappresentare il numero di successi in una nuova serie di lanci.\nL’obiettivo è stimare \\(p(\\tilde{y} \\mid y)\\), cioè la probabilità del nuovo dato \\(\\tilde{y}\\) dato ciò che abbiamo osservato in \\(y\\).\n\n57.2.1.2 Cosa rappresenta \\(p(\\tilde{y} \\mid \\theta)\\)?\n\n\n\\(p(\\tilde{y} \\mid \\theta)\\) è la probabilità del nuovo dato \\(\\tilde{y}\\) dato un particolare valore del parametro \\(\\theta\\).\nAd esempio, in un modello binomiale, \\(p(\\tilde{y} \\mid \\theta)\\) corrisponde alla probabilità di ottenere \\(\\tilde{y}\\) successi su \\(n_{\\text{new}}\\) prove, data la probabilità di successo \\(\\theta\\).\n\n57.2.1.3 Combinazione di \\(p(\\tilde{y} \\mid \\theta)\\) con \\(p(\\theta \\mid y)\\)\n\nPoiché non conosciamo esattamente \\(\\theta\\), dobbiamo considerare tutte le possibili ipotesi su \\(\\theta\\), pesandole in base alla loro probabilità a posteriori \\(p(\\theta \\mid y)\\). Questo porta alla formula per la distribuzione predittiva a posteriori:\n\\[\np(\\tilde{y} \\mid y) = \\int p(\\tilde{y} \\mid \\theta) p(\\theta \\mid y) \\, d\\theta.\n\\]\n\n57.2.1.4 Interpretazione\n\nLa distribuzione predittiva a posteriori, \\(p(\\tilde{y} \\mid y)\\), rappresenta la nostra miglior stima della probabilità del nuovo dato \\(\\tilde{y}\\), tenendo conto sia dei dati osservati \\(y\\) sia dell’incertezza su \\(\\theta\\).\n\n57.2.2 Caso Discreto\nSe il parametro \\(\\theta\\) assume un numero finito di valori, l’integrale si semplifica in una somma:\n\\[\np(\\tilde{y} \\mid y) = \\sum_{\\theta} p(\\tilde{y} \\mid \\theta) p(\\theta \\mid y).\n\\]\nQuesto approccio è utile nei modelli discreti o quando si approssimano i parametri con un numero finito di valori campionati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/13_post_pred_distr.html#il-caso-beta-binomiale",
    "href": "chapters/bayesian_inference/13_post_pred_distr.html#il-caso-beta-binomiale",
    "title": "57  Distribuzione predittiva a posteriori",
    "section": "\n57.3 Il Caso Beta-Binomiale",
    "text": "57.3 Il Caso Beta-Binomiale\nConsideriamo un classico esperimento binomiale: lanciare una moneta \\(n\\) volte e osservare il numero di successi \\(y\\) (ad esempio, il numero di “teste”). In un contesto bayesiano, il processo di analisi si articola in tre fasi:\n\n\nDistribuzione a Priori: Prima di osservare i dati, formuliamo una distribuzione a priori sulla probabilità \\(p\\) di successo, che riflette le nostre conoscenze iniziali (o la loro assenza). Una scelta comune è la distribuzione Beta(\\(\\alpha, \\beta\\)), perché è flessibile e ben definita per probabilità. Per esempio:\n\n\n\\(\\alpha\\) rappresenta il numero “fittizio” di successi osservati.\n\n\\(\\beta\\) rappresenta il numero “fittizio” di insuccessi osservati.\n\n\n\nDistribuzione a Posteriori: Dopo aver osservato \\(y\\) successi su \\(n\\) prove, aggiorniamo la distribuzione a priori combinandola con i dati osservati, ottenendo la distribuzione a posteriori di \\(p\\):\n\\[\n\\alpha_{\\text{post}} = \\alpha_{\\text{prior}} + y, \\quad \\beta_{\\text{post}} = \\beta_{\\text{prior}} + (n - y).\n\\]\nQuesta distribuzione rappresenta ciò che sappiamo di \\(p\\) dopo aver osservato i dati.\n\n\nDistribuzione Predittiva a Posteriori: Per prevedere il numero di successi futuri \\(y_{\\text{new}}\\) in un nuovo esperimento con \\(n_{\\text{new}}\\) prove, combiniamo la distribuzione a posteriori di \\(p\\) con la variabilità intrinseca del processo binomiale. In pratica:\n\nCampioniamo \\(p\\) dalla distribuzione a posteriori (\\(p \\sim \\text{Beta}(\\alpha_{\\text{post}}, \\beta_{\\text{post}})\\)).\nUsiamo ciascun campione di \\(p\\) per simulare nuovi dati (\\(y_{\\text{new}} \\sim \\text{Binomiale}(n_{\\text{new}}, p)\\)).\n\n\n\nQuesto processo tiene conto sia dell’incertezza sui parametri (\\(p\\)) sia della variabilità intrinseca nei dati futuri.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/13_post_pred_distr.html#simulazione-della-distribuzione-predittiva-a-posteriori",
    "href": "chapters/bayesian_inference/13_post_pred_distr.html#simulazione-della-distribuzione-predittiva-a-posteriori",
    "title": "57  Distribuzione predittiva a posteriori",
    "section": "\n57.4 Simulazione della Distribuzione Predittiva a Posteriori",
    "text": "57.4 Simulazione della Distribuzione Predittiva a Posteriori\n\n57.4.1 Impostazione dei Parametri\n\nSupponiamo di aver osservato \\(y = 70\\) successi su \\(n = 100\\) prove.\nUtilizziamo una distribuzione a priori Beta(\\(2, 2\\)), che rappresenta una conoscenza iniziale debolmente informativa, con una leggera preferenza per \\(p \\approx 0.5\\).\n\n57.4.2 Calcolo della Distribuzione a Posteriori\n\n\nAggiorniamo la distribuzione a priori con i dati osservati. I parametri aggiornati sono:\n\\[\n\\alpha_{\\text{post}} = \\alpha_{\\text{prior}} + y = 2 + 70 = 72, \\quad \\beta_{\\text{post}} = \\beta_{\\text{prior}} + (n - y) = 2 + 30 = 32.\n\\]\n\nLa distribuzione a posteriori è quindi \\(p \\sim \\text{Beta}(72, 32)\\), che descrive la probabilità aggiornata di successo basata sui dati.\n\n57.4.3 Simulazione dei Dati Futuri\n\nGeneriamo \\(n_{\\text{sim}} = 1000\\) campioni di \\(p\\) dalla distribuzione a posteriori Beta(72, 32).\n\nPer ogni campione di \\(p\\), simuliamo \\(y_{\\text{new}}\\), il numero di successi futuri su \\(n_{\\text{new}} = 10\\) prove, utilizzando la distribuzione binomiale:\n\\[\ny_{\\text{new}} \\sim \\text{Binomiale}(n_{\\text{new}} = 10, p).\n\\]\n\n\nInfine, convertiamo \\(y_{\\text{new}}\\) in proporzioni predette:\n\\[\n\\text{Proporzione predetta} = \\frac{y_{\\text{new}}}{n_{\\text{new}}}.\n\\]\n\n\n\n# Impostazione del seed per riproducibilità\nset.seed(123)\n\n# Parametri osservati\ny &lt;- 70\nn &lt;- 100\n\n# Parametri a priori\nalpha_prior &lt;- 2\nbeta_prior &lt;- 2\n\n# Calcolo dei parametri a posteriori\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + (n - y)\n\n# Simulazione della distribuzione a posteriori\np_samples &lt;- rbeta(1000, alpha_post, beta_post)\n\n# Simulazione di nuovi dati per n_new = 10\ny_preds &lt;- sapply(p_samples, function(p) {\n  rbinom(1, 10, p)\n})\n\n# Calcolo delle proporzioni predette\nprop_preds &lt;- y_preds / 10\n\n\n57.4.4 Risultati Attesi\n\n\nDistribuzione a Posteriori di \\(p\\):\n\nCentrata attorno a \\(0.7\\), con una varianza ridotta grazie alla dimensione del campione \\(n = 100\\).\n\n\n\nDistribuzione Predittiva per \\(n_{\\text{new}} = 10\\):\n\nVariabilità più ampia rispetto a \\(p\\), dovuta al numero ridotto di prove (\\(n_{\\text{new}} = 10\\)).\nRiflette sia l’incertezza su \\(p\\) sia la variabilità intrinseca dei dati futuri.\n\n\n\n\n# Visualizzazione\npar(mfrow = c(1, 2))\ncurve(dbeta(x, alpha_prior, beta_prior), from = 0, to = 1, \n      main = \"Distribuzione a Priori\", col = \"blue\", lwd = 2)\ncurve(dbeta(x, alpha_post, beta_post), from = 0, to = 1, \n      main = \"Distribuzione a Posteriori\", col = \"red\", lwd = 2)\n\n\n\n\n\n\n\n\nhist(prop_preds, breaks = 20, col = \"lightblue\", freq = FALSE,\n     main = \"Distribuzione Predittiva (n_new = 10)\",\n     xlab = \"Proporzione di Successi\")\nabline(v = y / n, col = \"blue\", lwd = 3, lty = 2)\n\n\n\n\n\n\n\n\n57.4.5 Spiegazione del Codice\nSimulazione di nuovi dati per \\(n_{\\text{new}} = 10\\):\ny_preds &lt;- sapply(p_samples, function(p) {\n  rbinom(1, 10, p)\n})\n\n\np_samples contiene \\(1000\\) valori di \\(p\\) simulati dalla distribuzione Beta(72, 32).\nPer ciascun \\(p\\), rbinom(1, 10, p) genera un valore di \\(y_{\\text{new}}\\), simulando il numero di successi futuri su \\(n_{\\text{new}} = 10\\) prove.\n\nRisultato: un vettore di 1000 valori di \\(y_{\\text{new}}\\), uno per ciascun campione di \\(p\\).\nCalcolo delle proporzioni predette:\nprop_preds &lt;- y_preds / 10\n\nDivide ciascun valore di \\(y_{\\text{new}}\\) per \\(n_{\\text{new}} = 10\\), ottenendo le proporzioni di successi predette.\n\nRisultato: un vettore di 1000 proporzioni predette (\\(y_{\\text{new}} / n_{\\text{new}}\\)).\n\n57.4.6 Interpretazione\n\nLa distribuzione a posteriori di \\(p\\), Beta(72, 32), è centrata attorno a \\(p \\approx 0.7\\), coerente con i dati osservati (\\(y / n = 0.7\\)).\nLe proporzioni predette mostrano la variabilità combinata dell’incertezza su \\(p\\) (dalla distribuzione a posteriori) e della variabilità binomiale per un campione futuro di 10 prove.\nL’istogramma delle proporzioni predette è più ampio rispetto alla distribuzione a posteriori di \\(p\\), riflettendo l’incertezza aggiuntiva derivante dal numero ridotto di prove (\\(n_{\\text{new}} = 10\\)).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/13_post_pred_distr.html#posterior-predictive-check-pp-check",
    "href": "chapters/bayesian_inference/13_post_pred_distr.html#posterior-predictive-check-pp-check",
    "title": "57  Distribuzione predittiva a posteriori",
    "section": "\n57.5 Posterior Predictive Check (PP-Check)",
    "text": "57.5 Posterior Predictive Check (PP-Check)\nLa distribuzione predittiva a posteriori ottenuta dalla simulazione (\\(n_{\\text{new}} = 10\\)) può essere utilizzata per effettuare un Posterior Predictive Check (PP-Check). Questo controllo confronta i dati osservati con i dati simulati dal modello per verificare se il modello è in grado di riprodurre caratteristiche rilevanti dei dati osservati.\nIn questa simulazione, il Posterior Predictive-Check suggerisce che il modello è ben specificato per i dati osservati (\\(y = 70\\), \\(n = 100\\)): la proporzione osservata (\\(0.7\\)) è vicina al centro della distribuzione predittiva. Questo significa che il modello può essere considerato valido per fare previsioni sui dati futuri, almeno nel contesto specificato.\n\n\n\n\n\n\nIl fatto che la distribuzione predittiva a posteriori rappresenti accuratamente la proporzione osservata può sembrare ovvio nel caso presente. Questo avviene perché stiamo lavorando con un modello semplice e ben specificato, utilizzato qui con l’intento di chiarire la logica del concetto di distribuzione predittiva a posteriori. Tuttavia, nei modelli più complessi, tipici delle indagini psicologiche, la corrispondenza tra i dati osservati e quelli predetti dal modello non può mai essere data per scontata. È essenziale verificarla attraverso la distribuzione predittiva a posteriori.\nSe i dati osservati non sono ben rappresentati dalla distribuzione predittiva a posteriori, ciò indica che il modello non è adeguato a spiegare i dati e necessita di revisione. Questo processo di verifica non solo garantisce la coerenza del modello con i dati disponibili, ma consente anche di identificare eventuali aree problematiche nella specificazione del modello, come prior inappropriati o assunzioni non realistiche. In definitiva, il confronto tra i dati osservati e quelli predetti è un passo fondamentale per la validazione di modelli complessi in contesti psicologici e scientifici.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/13_post_pred_distr.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/13_post_pred_distr.html#riflessioni-conclusive",
    "title": "57  Distribuzione predittiva a posteriori",
    "section": "\n57.6 Riflessioni Conclusive",
    "text": "57.6 Riflessioni Conclusive\nLa distribuzione predittiva a posteriori è uno strumento centrale nell’inferenza bayesiana, poiché consente di fare previsioni sui dati futuri integrando l’incertezza sui parametri del modello con la variabilità intrinseca del processo generativo. Questa capacità va oltre la semplice stima dei parametri, permettendo di confrontare le previsioni del modello con i dati reali, un passaggio fondamentale per verificare la coerenza e l’utilità del modello stesso.\nNel flusso di lavoro bayesiano, la distribuzione predittiva a posteriori svolge un ruolo chiave nella valutazione del modello. Ad esempio, consente di effettuare controlli predittivi a posteriori per identificare discrepanze tra i dati osservati e quelli previsti. Tali controlli aiutano a diagnosticare problemi di specificazione del modello, a valutare l’adeguatezza delle scelte a priori e a guidare eventuali revisioni del modello.\nInoltre, il caso beta-binomiale utilizzato in questo capitolo rappresenta un esempio intuitivo e potente: evidenzia come l’incertezza sui parametri possa essere tradotta in previsioni probabilistiche robuste, senza la necessità di fare assunzioni rigide o non realistiche. Questo approccio non solo formalizza l’incertezza in modo rigoroso, ma permette anche di comunicare le previsioni in modo trasparente e interpretabile, caratteristiche essenziali in ambito decisionale e scientifico.\nIn sintesi, la distribuzione predittiva a posteriori è un elemento fondamentale della modellazione bayesiana, che lega l’inferenza paramatrica alla previsione empirica, contribuendo a rendere l’intero processo inferenziale più affidabile, interpretabile e applicabile a scenari complessi.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/13_post_pred_distr.html#esercizi",
    "href": "chapters/bayesian_inference/13_post_pred_distr.html#esercizi",
    "title": "57  Distribuzione predittiva a posteriori",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nConsideriamo i dati della SWLS somministrata a un campione di studenti, ottenendo per ciascuno uno score complessivo. Per semplicità, vogliamo “dichiarare positivo” lo studente se il punteggio SWLS supera una determinata soglia (ad esempio, 20 su 35). In questo modo otteniamo una variabile dicotomica (0/1), che useremo come “successo” in un modello binomiale.\n\n\nDati e conteggio dei successi\n\nCarica il dataset con le risposte SWLS.\n\nCostruisci la variabile binaria (ad esempio SWLS_dich) che vale 1 se lo score ≥ 20, e 0 altrimenti.\n\nCalcola il numero di successi (numero di persone che superano la soglia) e il numero totale di osservazioni (N).\n\n\n\nModello beta-binomiale (approccio manuale via simulazione)\n\n\nSpecifica una distribuzione Beta(a, b) come prior per la probabilità di successo \\(p\\). Scegli una coppia \\((a, b)\\) relativamente poco informativa, ad esempio (2,2) o (1,1).\n\nOsservando \\(y\\) successi su \\(n\\) soggetti, aggiorna i parametri a posteriori: \\[\n  a_{\\text{post}} = a + y,\n  \\quad\n  b_{\\text{post}} = b + (n - y).\n\\]\n\nSimula un gran numero di campioni di \\(p\\) dalla distribuzione Beta\\(\\bigl(a_{\\text{post}},\\, b_{\\text{post}}\\bigr)\\).\n\nPer ciascun campione di \\(p\\), genera un valore \\(\\tilde{y}\\) da una Binomiale\\(\\bigl(n_{\\text{new}}, p\\bigr)\\), dove \\(n_{\\text{new}}\\) è la dimensione di un ipotetico nuovo campione (che puoi scegliere, ad esempio, uguale a \\(n\\) oppure un valore diverso). Otterrai così una posterior predictive distribution per \\(\\tilde{y}\\).\n\nInfine, calcola statistiche descrittive (media, varianza, intervalli) e/o disegna un istogramma di \\(\\tilde{y}\\) o della proporzione \\(\\tilde{y}/n_{\\text{new}}\\).\n\n\n\nReplicare con brms\n\n\nUsa il pacchetto brms per costruire un modello binomiale. Per esempio:\nlibrary(brms)\n\n# Crea un data frame con la variabile dicotomica\ndf_binom &lt;- data.frame(\n  successes = y,    # conteggio dei successi\n  failures  = n - y\n)\n\n# Modello binomiale con prior Beta(a,b) approssimato tramite logit\nfit_brms &lt;- brm(\n  bf(successes | trials(n) ~ 1), \n  data = df_binom,\n  family = binomial(link = \"logit\"),\n  prior = c(\n    prior(beta(2, 2), class = \"Intercept\", dpar = \"mu\") \n    # NOTA: la specifica di una \"beta(2,2)\" diretta sull'intercetta\n    # è un'approssimazione, tipicamente serve passare a una scala logit.\n    # In brms, di solito si usa prior su scale normali dell'intercetta.\n  ),\n  seed = 123\n)\n(Le specifiche del prior potrebbero richiedere una formulazione differente se vuoi rispettare esattamente la corrispondenza con Beta(a,b). In ogni caso, l’idea è mostrare come definire un prior e costruire un modello binomiale con brms.)\n\n\nVerifica la convergenza e poi estrai la posterior predictive distribution con le funzioni di brms:\npp_check(fit_brms, nsamples = 100)\nQuesto ti mostrerà come i dati predetti dal modello (in termini di binomiale) si confrontano con i dati osservati.\n\n\n\n\nConfronto e interpretazione\n\nMetti a confronto i risultati della simulazione “manuale” (Beta-Binomial) e quelli ottenuti con brms. Noterai che le distribuzioni predittive dovrebbero essere coerenti, se hai impostato un prior per brms simile a quello del modello Beta-Binomiale.\n\nDiscuti brevemente se la distribuzione predittiva a posteriori acquisita è plausibile rispetto ai dati osservati. Ad esempio, la probabilità di osservare \\(\\tilde{y}\\) simile a \\(y\\) dovrebbe essere relativamente alta se il modello è appropriato.\n\nSe vuoi, puoi cambiare \\(n_{\\text{new}}\\) (es. previsione su 200 soggetti futuri) per vedere come la variabilità della previsione si “ridimensiona” o cresce a seconda della taglia del campione.\n\n\n\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n\n\nCostruzione del dataset\n\n\nSe la SWLS varia tra 5 e 35, e la soglia è 20, puoi fare:\ndf$SWLS_dich &lt;- ifelse(df$SWLS_score &gt;= 20, 1, 0)\ny &lt;- sum(df$SWLS_dich)\nn &lt;- nrow(df)\n\n\n\n\nApproccio Beta-Binomial manuale\n\nPrior: \\((a, b) = (2, 2)\\)\nPosterior: \\((a_{\\text{post}}, b_{\\text{post}}) = (2 + y,\\, 2 + n - y)\\).\n\nGenerazione dei campioni:\nN_sim &lt;- 2000\np_post &lt;- rbeta(N_sim, a_post, b_post)\ny_pred &lt;- rbinom(N_sim, size = n_new, prob = p_post)\n\n# Se preferisci la proporzione futura:\nprop_pred &lt;- y_pred / n_new\n\n\nStatistiche:\nmean_p &lt;- mean(p_post) # media a posteriori di p\nquantile_p &lt;- quantile(p_post, c(0.025, 0.975))  \n\nmean_prop_pred &lt;- mean(prop_pred)\nquantile_prop_pred &lt;- quantile(prop_pred, c(0.025, 0.975))\n\n\nGrafici (istogramma e densità):\nhist(prop_pred, freq=FALSE, col='lightblue',\n     main='Posterior Predictive Distribution: prop. di successi')\n\n\n\n\nModello con brms\n\nUsa la sintassi di una binomiale con offset o con trials(n).\n\nSpecifica un prior che approssimi Beta(2,2) sullo scale logit, ad esempio:\n# Beta(2,2) ha media ~ 0.5, varianza relativamente ampia.\n# Approssimandola su scala logit ~ normal(0, 2.2) \n# (valore indicativo: la normal(0, 2) su logit copre un intervallo ampio).\n\nprior_approx &lt;- prior(normal(0, 2), class = \"Intercept\")\n\nEsegui pp_check(fit_brms) e interpreta.\n\n\n\nInterpretazione\n\nSe la soglia scelta per la SWLS cattura un “buon livello di soddisfazione”, potresti aspettarti una certa % di successi.\n\nSe i dati futuri simulati sono coerenti con i dati reali — ad esempio, la media di \\(\\tilde{y}\\) è vicina a \\(y\\) — allora il modello sembra descrivere bene la realtà. Altrimenti, potresti rivedere la soglia o la specifica del prior.\n\n\n\nL’elemento chiave è che la distribuzione predittiva a posteriori (posterior predictive distribution) non si limita a considerare un solo valore di \\(p\\), bensì campiona molteplici valori plausibili (dalla posterior), e per ciascuno simula un potenziale outcome. Così facendo, si riflette pienamente l’incertezza residua sul parametro e l’aleatorietà del processo binomiale.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/13_post_pred_distr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/13_post_pred_distr.html#informazioni-sullambiente-di-sviluppo",
    "title": "57  Distribuzione predittiva a posteriori",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.12.0 psych_2.5.3     \n#&gt;  [9] scales_1.4.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.2   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.4     stringi_1.8.7      lattice_0.22-7    \n#&gt;  [4] hms_1.1.3          digest_0.6.37      magrittr_2.0.3    \n#&gt;  [7] evaluate_1.0.3     grid_4.5.0         timechange_0.3.0  \n#&gt; [10] RColorBrewer_1.1-3 fastmap_1.2.0      rprojroot_2.0.4   \n#&gt; [13] jsonlite_2.0.0     mnormt_2.1.1       cli_3.6.5         \n#&gt; [16] rlang_1.1.6        withr_3.0.2        tools_4.5.0       \n#&gt; [19] parallel_4.5.0     tzdb_0.5.0         pacman_0.5.1      \n#&gt; [22] vctrs_0.6.5        R6_2.6.1           lifecycle_1.0.4   \n#&gt; [25] htmlwidgets_1.6.4  pkgconfig_2.0.3    pillar_1.10.2     \n#&gt; [28] gtable_0.3.6       glue_1.8.0         xfun_0.52         \n#&gt; [31] tidyselect_1.2.1   rstudioapi_0.17.1  farver_2.1.2      \n#&gt; [34] htmltools_0.5.8.1  nlme_3.1-168       rmarkdown_2.29    \n#&gt; [37] compiler_4.5.0",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/13_post_pred_distr.html#bibliografia",
    "href": "chapters/bayesian_inference/13_post_pred_distr.html#bibliografia",
    "title": "57  Distribuzione predittiva a posteriori",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nSchoot, R. van de, Depaoli, S., King, R., Kramer, B., Märtens, K., Tadesse, M. G., Vannucci, M., Gelman, A., Veen, D., Willemsen, J., et al. (2021). Bayesian statistics and modelling. Nature Reviews Methods Primers, 1(1), 1.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/introduction_mcmc.html",
    "href": "chapters/mcmc/introduction_mcmc.html",
    "title": "Introduzione",
    "section": "",
    "text": "In questa sezione della dispensa, ci concentreremo sulle procedure Monte Carlo a catena di Markov, con particolare attenzione all’algoritmo di Metropolis, che consente di approssimare la distribuzione a posteriori quando non è possibile ottenere una soluzione analitica. Esploreremo il concetto di predizione bayesiana, fondamentale per la costruzione della distribuzione predittiva a posteriori, e discuteremo anche la distribuzione predittiva a priori. Applicheremo l’inferenza bayesiana a diversi contesti, tra cui la stima di una proporzione, il confronto tra due proporzioni, la stima di una media da una distribuzione normale e il confronto tra due medie. Esamineremo inoltre il modello bayesiano di Poisson per l’analisi delle frequenze. Infine, introdurremo il modello gerarchico bayesiano, uno strumento potente per affrontare situazioni in cui le osservazioni sono strutturate su diversi livelli di incertezza.",
    "crumbs": [
      "MCMC",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html",
    "href": "chapters/mcmc/01_metropolis.html",
    "title": "58  L’algoritmo di Metropolis-Hastings",
    "section": "",
    "text": "58.1 Introduzione\nNelle lezioni precedenti abbiamo esaminato diversi esempi di inferenza bayesiana, concentrandoci su situazioni semplici, come il modello bernoulliano a un singolo parametro. In quei contesti, abbiamo utilizzato metodi come:\nQuesti approcci risultano efficaci per modelli elementari, ma diventano rapidamente impraticabili al crescere della complessità del modello o del numero di parametri. In tali situazioni, è necessario adottare metodi più flessibili ed efficienti.\nIn questo capitolo introdurremo una tecnica fondamentale per l’inferenza bayesiana moderna: il Metodo Monte Carlo a Catena di Markov (MCMC).",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#introduzione",
    "href": "chapters/mcmc/01_metropolis.html#introduzione",
    "title": "58  L’algoritmo di Metropolis-Hastings",
    "section": "",
    "text": "l’approssimazione tramite griglia, che consiste nel suddividere l’intervallo dei valori possibili in punti discreti e calcolare la distribuzione a posteriori su ciascun punto;\nl’impiego di distribuzioni a priori coniugate, che consentono di derivare la distribuzione a posteriori in modo analitico.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#lobiettivo-del-metodo-mcmc",
    "href": "chapters/mcmc/01_metropolis.html#lobiettivo-del-metodo-mcmc",
    "title": "58  L’algoritmo di Metropolis-Hastings",
    "section": "\n58.2 L’obiettivo del metodo MCMC",
    "text": "58.2 L’obiettivo del metodo MCMC\nIl metodo MCMC è un approccio computazionale che consente di approssimare distribuzioni di probabilità complesse, generando una sequenza di valori campionati che seguono la distribuzione a posteriori di interesse.\nL’idea di base è la seguente:\n\nconsideriamo la distribuzione a posteriori come una popolazione da cui desideriamo estrarre campioni;\ngenerando un numero sufficientemente grande di campioni (ad esempio, diverse migliaia), la distribuzione empirica dei campioni ottenuti si avvicina progressivamente alla distribuzione teorica a posteriori;\nin questo modo, possiamo stimare quantità di interesse, come la media, la varianza, o intervalli di credibilità, anche senza conoscere una forma analitica esplicita della distribuzione a posteriori.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#una-differenza-importante-rispetto-ai-metodi-precedenti",
    "href": "chapters/mcmc/01_metropolis.html#una-differenza-importante-rispetto-ai-metodi-precedenti",
    "title": "58  L’algoritmo di Metropolis-Hastings",
    "section": "\n58.3 Una differenza importante rispetto ai metodi precedenti",
    "text": "58.3 Una differenza importante rispetto ai metodi precedenti\nA differenza dei metodi visti finora, i campioni prodotti da MCMC non sono indipendenti: ciascun campione dipende dal campione precedente. In altre parole, il processo di campionamento segue una catena di Markov, in cui la generazione del valore successivo si basa unicamente sul valore corrente, senza dipendere dall’intera storia precedente.\nQuesta dipendenza introduce una correlazione tra i campioni successivi:\n\nse un campione assume un valore elevato, anche il successivo avrà una maggiore probabilità di essere vicino a quel valore;\ntale correlazione non costituisce un problema in sé, ma implica che per ottenere stime affidabili sia necessario generare un numero più elevato di campioni rispetto a quanto sarebbe richiesto con campioni indipendenti.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#perché-utilizzare-mcmc",
    "href": "chapters/mcmc/01_metropolis.html#perché-utilizzare-mcmc",
    "title": "58  L’algoritmo di Metropolis-Hastings",
    "section": "\n58.4 Perché utilizzare MCMC",
    "text": "58.4 Perché utilizzare MCMC\nIl metodo MCMC è diventato uno strumento centrale nell’inferenza bayesiana contemporanea perché:\n\nè in grado di affrontare problemi complessi, caratterizzati da distribuzioni a posteriori di forma irregolare o definite in spazi ad alta dimensione;\nnon richiede il calcolo diretto dell’integrale di normalizzazione che compare nel teorema di Bayes;\npermette di ottenere approssimazioni accurate della distribuzione a posteriori tramite simulazione numerica.\n\nNel seguito ci concentreremo sull’algoritmo di Metropolis, uno dei metodi più semplici ed essenziali per implementare il campionamento MCMC.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#lalgoritmo-di-metropolis-introduzione-intuitiva",
    "href": "chapters/mcmc/01_metropolis.html#lalgoritmo-di-metropolis-introduzione-intuitiva",
    "title": "58  L’algoritmo di Metropolis-Hastings",
    "section": "\n58.5 L’algoritmo di Metropolis: introduzione intuitiva",
    "text": "58.5 L’algoritmo di Metropolis: introduzione intuitiva\nL’algoritmo di Metropolis è un metodo MCMC che consente di esplorare una distribuzione di probabilità complessa costruendo una sequenza di campioni dipendenti tra loro.\nLa logica dell’algoritmo può essere riassunta nei seguenti passaggi fondamentali:\n\n\nPunto di partenza: si inizia da un valore iniziale \\(\\theta_0\\) scelto arbitrariamente.\n\nProposta di un nuovo punto: si genera un nuovo valore candidato \\(\\theta^*\\) partendo da \\(\\theta_0\\), utilizzando una distribuzione di proposta (ad esempio una distribuzione normale centrata su \\(\\theta_0\\)).\n\nValutazione della proposta: si confrontano le densità a posteriori associate al valore attuale \\(\\theta_0\\) e al valore proposto \\(\\theta^*\\).\n\nDecisione di accettazione:\n\nse \\(\\theta^*\\) ha una densità a posteriori più alta di \\(\\theta_0\\), viene accettato automaticamente;\nse \\(\\theta^*\\) ha una densità a posteriori inferiore, viene accettato con una certa probabilità proporzionale al rapporto delle densità.\n\n\n\nRegistrazione: in ogni caso, si registra la posizione attuale (sia che si sia accettato un nuovo punto, sia che si sia rimasti fermi).\n\nQuesto processo viene ripetuto per un numero elevato di iterazioni, generando una catena di campioni che, dopo un opportuno periodo iniziale (detto burn-in), approssima la distribuzione a posteriori.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#perché-accettiamo-anche-mosse-peggiori",
    "href": "chapters/mcmc/01_metropolis.html#perché-accettiamo-anche-mosse-peggiori",
    "title": "58  L’algoritmo di Metropolis-Hastings",
    "section": "\n58.6 Perché accettiamo anche mosse peggiori",
    "text": "58.6 Perché accettiamo anche mosse peggiori\nUno degli aspetti peculiari dell’algoritmo di Metropolis è la possibilità di accettare anche proposte peggiori, ossia punti \\(\\theta^*\\) associati a una densità a posteriori minore rispetto allo stato attuale.\nQuesta scelta ha una motivazione fondamentale:\n\nse accettassimo solo le mosse che migliorano la densità, l’algoritmo rischierebbe di bloccarsi in un massimo locale della distribuzione, senza esplorare altre aree che, pur avendo densità più bassa localmente, potrebbero condurre a regioni più interessanti globalmente;\naccettare occasionalmente mosse peggiori consente all’algoritmo di esplorare meglio tutto lo spazio dei parametri, evitando di rimanere intrappolato in una singola area.\n\nIn questo modo, la catena può attraversare regioni di bassa probabilità e raggiungere altre modalità della distribuzione, garantendo una copertura più completa dello spazio delle soluzioni plausibili.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#la-scelta-della-larghezza-della-proposta",
    "href": "chapters/mcmc/01_metropolis.html#la-scelta-della-larghezza-della-proposta",
    "title": "58  L’algoritmo di Metropolis-Hastings",
    "section": "\n58.7 La scelta della larghezza della proposta",
    "text": "58.7 La scelta della larghezza della proposta\nNell’algoritmo di Metropolis, la proposta di un nuovo valore \\(\\theta^*\\) viene solitamente generata a partire dallo stato corrente \\(\\theta_t\\) utilizzando una distribuzione di proposta simmetrica, ad esempio una distribuzione normale \\(\\mathcal{N}(\\theta_t, \\tau^2)\\), dove \\(\\tau\\) rappresenta la deviazione standard della proposta.\nLa scelta del valore di \\(\\tau\\) (ovvero della larghezza della proposta) è cruciale per il buon funzionamento dell’algoritmo:\n\nse \\(\\tau\\) è troppo piccolo, i passi proposti saranno molto vicini al punto attuale. In questo caso, molte proposte saranno accettate, ma la catena si muoverà lentamente nello spazio dei parametri, esplorandolo inefficientemente (alta correlazione tra i campioni);\nse \\(\\tau\\) è troppo grande, i passi proposti saranno molto lontani dal punto attuale. In questo caso, la maggior parte delle proposte cadrà in regioni di bassa densità, portando a un alto tasso di rifiuto delle proposte e quindi a una scarsa efficienza del campionamento.\n\nUn valore ottimale di \\(\\tau\\) deve bilanciare:\n\n\naccettazione sufficiente di nuove proposte;\n\nesplorazione efficiente dello spazio dei parametri.\n\nIn generale, si cerca di ottenere un tasso di accettazione compreso tra il 40% e il 50% per l’algoritmo di Metropolis a singolo parametro.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#limportanza-dei-grafici-diagnostici-trace-plot-e-correlogramma",
    "href": "chapters/mcmc/01_metropolis.html#limportanza-dei-grafici-diagnostici-trace-plot-e-correlogramma",
    "title": "58  L’algoritmo di Metropolis-Hastings",
    "section": "\n58.8 L’importanza dei grafici diagnostici: Trace plot e Correlogramma",
    "text": "58.8 L’importanza dei grafici diagnostici: Trace plot e Correlogramma\nPer valutare la qualità della catena generata dall’algoritmo di Metropolis, è fondamentale analizzare alcuni grafici diagnostici.\n\n58.8.1 Trace plot\nIl trace plot rappresenta i valori campionati di \\(\\theta\\) in funzione del numero di iterazioni.\nUn trace plot di buona qualità mostra:\n\noscillazioni attorno a un valore centrale stabile (assenza di trend sistematici);\nuna copertura adeguata dello spazio plausibile per \\(\\theta\\).\n\nUn trace plot problematico può rivelare:\n\nfasi iniziali instabili (burn-in non sufficientemente lungo);\nmancata esplorazione completa della distribuzione;\nconvergenza solo apparente, con la catena bloccata in una modalità.\n\n58.8.2 Correlogramma\nIl correlogramma mostra il grado di autocorrelazione dei campioni in funzione del numero di passi di lag.\nIdealmente:\n\nl’autocorrelazione dovrebbe decrescere rapidamente all’aumentare del lag;\nuna catena ben mescolata presenta un correlogramma che si avvicina rapidamente a zero.\n\nUna forte autocorrelazione indica che i campioni successivi sono troppo simili tra loro, riducendo l’efficienza dell’inferenza statistica.\nQuesti concetti costituiscono il fondamento necessario per affrontare la comprensione operativa e pratica dell’algoritmo di Metropolis che svilupperemo nei prossimi esempi. A questo fine, il capitolo è strutturato in varie sezioni che facilitano la comprensione progressiva del tema.\n\nInizieremo discutendo di come la distribuzione a posteriori possa essere approssimata mediante tecniche di simulazione convenzionali. Questa prima parte presuppone che la distribuzione target, o “a posteriori,” sia già conosciuta o disponibile per l’analisi.\nIn seguito, passeremo a illustrare come l’algoritmo di Metropolis possa essere utilizzato per affrontare situazioni in cui la distribuzione a posteriori non è direttamente nota. In questi casi, spesso abbiamo a disposizione informazioni riguardanti la distribuzione a priori e la funzione di verosimiglianza, che possono essere utilizzate per ottenere un’approssimazione efficace della distribuzione a posteriori.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#un-esempio-concreto",
    "href": "chapters/mcmc/01_metropolis.html#un-esempio-concreto",
    "title": "58  L’algoritmo di Metropolis-Hastings",
    "section": "\n58.9 Un Esempio Concreto",
    "text": "58.9 Un Esempio Concreto\nA titolo esemplificativo, utilizzeremo il dataset moma_sample.csv, il quale costituisce un campione casuale di 100 artisti provenienti dal Museo di Arte Moderna di New York (MoMA) e contiene diverse informazioni relative a ciascun artista.\nIl nostro interesse è focalizzato sulla determinazione della probabilità che un artista presente nel MoMA appartenga alla generazione X o a una generazione successiva (nati dopo il 1965). Questa probabilità sarà indicata come \\(\\pi\\).\nImportiamo i dati.\n\nmoma_sample &lt;- rio::import(here::here(\"data\", \"moma_sample.csv\"))\n\nEsaminiamo le prime cinque righe del DataFrame.\n\nmoma_sample |&gt; \n  head()\n#&gt;                artist  country birth death alive  genx gender count\n#&gt; 1        Ad Gerritsen    dutch  1940  2015 FALSE FALSE   male     1\n#&gt; 2 Kirstine Roepstorff   danish  1972    NA  TRUE  TRUE female     3\n#&gt; 3    Lisa Baumgardner american  1958  2015 FALSE FALSE female     2\n#&gt; 4         David Bates american  1952    NA  TRUE FALSE   male     1\n#&gt; 5          Simon Levy american  1946    NA  TRUE FALSE   male     1\n#&gt; 6      Pierre Mercure canadian  1927  1966 FALSE FALSE   male     8\n#&gt;   year_acquired_min year_acquired_max\n#&gt; 1              1981              1981\n#&gt; 2              2005              2005\n#&gt; 3              2016              2016\n#&gt; 4              2001              2001\n#&gt; 5              2012              2012\n#&gt; 6              2008              2008\n\nDai dati osserviamo che solo 14 artisti su 100 appartengono alla generazione X o a una generazione successiva.\n\n# Calcoliamo la distribuzione delle generazioni\nresult &lt;- table(moma_sample$genx)\nresult\n#&gt; \n#&gt; FALSE  TRUE \n#&gt;    86    14\n\nIl valore campionato \\(y = 14\\) riflette le caratteristiche del campione che è stato osservato. Tuttavia, poiché il MOMA contiene opere di migliaia di artisti, sorge una domanda riguardante il vero valore di \\(\\theta\\) (la probabilità di appartenere alla generazione X o a una generazione successiva) all’interno di questa popolazione.\nPossiamo interpretare i dati \\(y = 14\\) come l’esito di una variabile casuale Binomiale con parametri \\(N = 100\\) e \\(\\theta\\) sconosciuto.\nSupponiamo che le nostre credenze pregresse riguardo a \\(\\theta\\) possano essere modellate attraverso una distribuzione Beta(4, 6).\n\ntibble(x = seq(0, 1, .01),\n       y = dbeta(x, 4, 6)) |&gt;\n  ggplot(aes(x=x, y=y)) + \n  geom_line()\n\n\n\n\n\n\n\nSfruttando le proprietà delle distribuzioni coniugate, possiamo calcolare esattamente la distribuzione a posteriori:\n# Y ~ Binomiale(100, π)\n# θ ~ Beta(4, 6)\n# Posteriori: θ | (Y = 14) ~ Beta(4 + 14, 6 + 100 - 14) → Beta(18, 92)\nNella figura seguente, è rappresentata la distribuzione a posteriori del parametro \\(\\theta\\), insieme alla distribuzione a priori specificata.\n\n# Generiamo la sequenza dei valori per θ\nx &lt;- seq(0, 1, length.out = 1000)\n\n# Calcoliamo le densità della prior e della posterior\nprior_density &lt;- dbeta(x, 4, 6)\nposterior_density &lt;- dbeta(x, 18, 92)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  x = x,\n  prior = prior_density,\n  posterior = posterior_density\n)\n\n# Convertiamo i dati in formato \"lungo\" per facilitare la visualizzazione con ggplot2\ndf_long &lt;- reshape2::melt(df, id.vars = \"x\", \n                          measure.vars = c(\"prior\", \"posterior\"),\n                          variable.name = \"distribuzione\", value.name = \"densita\")\n\n# Creare il grafico con ggplot2\nggplot(df_long, aes(x = x, y = densita, fill = distribuzione)) +\n  geom_line(aes(color = distribuzione), size = 1) +  # Aggiungere le linee per le distribuzioni\n  geom_area(aes(fill = distribuzione), alpha = 0.5, position = \"identity\") +  # Aggiungere le aree sotto le curve\n  scale_fill_manual(\n    values = c(\"prior\" = adjustcolor(okabe_ito_palette[1], alpha.f = 0.5), \n               \"posterior\" = adjustcolor(okabe_ito_palette[2], alpha.f = 0.5)),\n    labels = c(\"Prior: Beta(4, 6)\", \"Posterior: Beta(18, 92)\")\n  ) +\n  scale_color_manual(\n    values = c(\"prior\" = okabe_ito_palette[1], \"posterior\" = okabe_ito_palette[2]),\n    labels = c(\"Prior: Beta(4, 6)\", \"Posterior: Beta(18, 92)\")\n  ) +\n  labs(\n    title = \"Densità a Priori e a Posteriori\",\n    x = \"Valore del Parametro\",\n    y = \"Densità\",\n    fill = NULL, color = NULL\n  ) +\n  theme(\n    plot.title = element_text(hjust = 0.5),  # Centrare il titolo\n    legend.position = \"top\"  # Posizionare la legenda in alto\n  )\n\n\n\n\n\n\n\nIn questo grafico, la curva blu rappresenta la distribuzione a priori \\(\\text{Beta}(4, 6)\\), mentre la curva rossa mostra la distribuzione a posteriori \\(\\text{Beta}(18, 92)\\). La sovrapposizione delle aree evidenzia come l’evidenza fornita dai dati modifichi la conoscenza iniziale sul parametro \\(\\theta\\).\nSe vogliamo conoscere il valore della media a posteriori di \\(\\theta\\), il risultato esatto è\n\\[\n\\bar{\\theta}_{post} = \\frac{\\alpha}{\\alpha + \\beta} = \\frac{18}{18 + 92} \\approx 0.1636.\n\\]\n\n58.9.1 Simulazione con distribuzione target nota\nUsiamo ora una simulazione numerica per stimare la media a posteriori di \\(\\theta\\). Conoscendo la forma della distribuzione a posteriori \\(Beta(18, 92)\\), possiamo generare un campione di osservazioni casuali da questa distribuzione. Successivamente, calcoliamo la media delle osservazioni ottenute per ottenere un’approssimazione della media a posteriori.\nSe vogliamo ottenere un risultato approssimato con un numero limitato di campioni (ad esempio, 10), possiamo utilizzare la seguente simulazione:\n\n# Generiamo 10 campioni dalla distribuzione Beta(18, 92)\nset.seed(1234)  # Per riproducibilità\ny &lt;- rbeta(10, shape1 = 18, shape2 = 92)\ny\n#&gt;  [1] 0.11831 0.17511 0.21473 0.07692 0.18174 0.18522 0.14156 0.14261 0.14194\n#&gt; [10] 0.12992\n\n\n# Calcoliamo la media dei campioni\nmean(y)\n#&gt; [1] 0.1508\n\nTuttavia, con soli 10 campioni, l’approssimazione potrebbe non essere molto accurata. Aumentando il numero di campioni, ad esempio a 10,000, possiamo ottenere una stima molto più precisa:\n\n# Generiamo 10000 campioni e calcoliamo la media\nset.seed(123)  # Per riproducibilità\nmean(rbeta(10000, shape1 = 18, shape2 = 92))\n#&gt; [1] 0.1637\n\nQuando il numero di campioni dalla distribuzione a posteriori diventa molto grande, la media campionaria converge al valore atteso della distribuzione della popolazione. Questo principio non si applica solo alla media, ma anche ad altre statistiche descrittive come la moda e la varianza.\nÈ importante sottolineare che l’applicazione della simulazione di Monte Carlo è efficace per calcolare distribuzioni a posteriori solo quando conosciamo la distribuzione stessa e possiamo utilizzare funzioni R per estrarre campioni casuali da tale distribuzione. Ciò è stato possibile nel caso della distribuzione a posteriori \\(Beta(18, 92)\\).\nTuttavia, questa situazione ideale non si verifica sempre nella pratica, poiché le distribuzioni a priori coniugate alla verosimiglianza sono spesso rare. Per esempio, nel caso di una verosimiglianza binomiale e una distribuzione a priori gaussiana, l’espressione\n\\[\np(\\theta \\mid y) = \\frac{\\mathrm{e}^{-(\\theta - 1 / 2)^2} \\theta^y (1 - \\theta)^{n - y}} {\\int_0^1 \\mathrm{e}^{-(t - 1 / 2)^2} t^y (1 - t)^{n - y} dt}\n\\]\nrende impossibile calcolare analiticamente la distribuzione a posteriori di \\(\\theta\\), precludendo quindi l’utilizzo diretto di R per generare campioni casuali.\nIn queste circostanze, però, è possibile ottenere campioni casuali dalla distribuzione a posteriori mediante l’uso di metodi Monte Carlo basati su Catena di Markov (MCMC). Gli algoritmi MCMC, come ad esempio l’algoritmo Metropolis, costituiscono una classe di metodi che consentono di estrarre campioni casuali dalla distribuzione a posteriori senza richiedere la conoscenza della sua rappresentazione analitica. Le tecniche MCMC sono ampiamente adottate per risolvere problemi di inferenza bayesiana e rappresentano il principale strumento computazionale per ottenere stime approssimate di distribuzioni a posteriori in situazioni complesse e non analiticamente trattabili.\n\n58.9.2 Algoritmo di Metropolis\nL’algoritmo di Metropolis appartiene alla famiglia dei metodi Monte Carlo basati su catene di Markov (MCMC), sfruttando le proprietà di queste catene per generare campioni da una distribuzione target. Il suo obiettivo principale è di esplorare lo spazio dei parametri in modo efficiente, producendo campioni che approssimano la distribuzione a posteriori di interesse.\n\n58.9.3 Principio di Funzionamento\nL’algoritmo inizia da un valore iniziale per i parametri e, in ogni iterazione, genera un nuovo campione tramite una distribuzione di proposta (solitamente una distribuzione normale centrata sul valore corrente). Successivamente, decide se accettare il nuovo campione in base al confronto tra le densità posteriori del nuovo campione e di quello precedente. Questa accettazione avviene in modo probabilistico, favorendo campioni con una densità più alta ma consentendo anche l’accettazione di campioni peggiori per evitare che la catena rimanga bloccata in minimi locali.\n\n58.9.4 Burn-in e Convergenza\nPoiché i primi campioni potrebbero non rappresentare bene la distribuzione target, si esclude spesso una porzione iniziale della catena (fase di burn-in). Con il progredire delle iterazioni, i campioni si distribuiscono in accordo con la distribuzione stazionaria desiderata, indipendentemente dallo stato iniziale scelto. Questo processo permette di esplorare lo spazio dei parametri in modo efficiente.\n\n58.9.5 Meccanismo di Accettazione e Rifiuto\nL’algoritmo di Metropolis bilancia due esigenze opposte:\n\n\nEsplorazione di nuove aree dello spazio dei parametri.\n\nSfruttamento delle informazioni già acquisite dai campioni precedenti.\n\nUtilizzando una regola probabilistica per accettare campioni peggiori (con minore densità a posteriori), l’algoritmo evita di restare intrappolato in minimi locali, esplorando così in modo più completo l’intera distribuzione.\n\n58.9.6 Passaggi Fondamentali dell’Algoritmo di Metropolis\n\n\nScelta di uno stato iniziale \\(\\theta_1\\) e impostazione del contatore \\(t = 1\\).\n\nQuesto è il punto di partenza della catena, dove \\(\\theta_1\\) rappresenta il primo campione.\n\n\n\nProposta di un nuovo campione \\(\\theta_p\\).\n\nUn nuovo valore \\(\\theta_p\\) viene generato da una distribuzione di proposta \\(g(\\theta_p \\mid \\theta_t)\\), solitamente una distribuzione normale centrata sul campione corrente \\(\\theta_t\\) con una deviazione standard \\(\\tau\\) che controlla l’ampiezza dei passi.\n\n\n\nVerifica dei vincoli del campione proposto.\n\nSe il nuovo campione deve rispettare dei vincoli (ad esempio, essere compreso tra 0 e 1 per probabilità), campioni non validi vengono automaticamente rifiutati.\n\n\n\nCalcolo del rapporto di accettazione \\(\\alpha\\).\n\nSi calcola \\(\\alpha = \\frac{p(\\theta_p \\mid y)}{p(\\theta_t \\mid y)}\\), che rappresenta il rapporto tra le densità a posteriori del nuovo campione \\(\\theta_p\\) e del campione corrente \\(\\theta_t\\). Questo valore guida la decisione di accettazione.\n\n\n\nDecisione di accettazione.\n\nSe \\(\\alpha \\geq 1\\), il nuovo campione \\(\\theta_p\\) viene accettato incondizionatamente.\nSe \\(\\alpha &lt; 1\\), il campione \\(\\theta_p\\) viene accettato con probabilità \\(\\alpha\\). In caso di rifiuto, si mantiene il campione corrente \\(\\theta_t\\) per la prossima iterazione.\n\n\n\nRipetizione del processo.\n\nSi ripetono i passaggi dal 2 al 5 fino a ottenere il numero desiderato di campioni.\n\n\n\n58.9.7 Dettagli Aggiuntivi\n\nDistribuzione di proposta: La distribuzione di proposta \\(g(\\theta_p \\mid \\theta_t)\\) genera nuovi campioni attorno a \\(\\theta_t\\). Tipicamente si usa una normale \\(N(\\theta_t, \\tau)\\), dove \\(\\tau\\) controlla quanto il nuovo campione si discosta da quello corrente. Scegliere un \\(\\tau\\) troppo piccolo può rendere l’esplorazione lenta, mentre un \\(\\tau\\) troppo grande può far rifiutare troppi campioni, riducendo l’efficienza.\nRapporto di accettazione \\(\\alpha\\): Se il nuovo campione ha una densità a posteriori maggiore del campione corrente, viene sempre accettato. Se ha una densità inferiore, viene accettato con probabilità \\(\\alpha\\), il che consente di esplorare anche regioni meno probabili della distribuzione.\nAccettazione probabilistica: Accettare campioni peggiori occasionalmente aiuta l’algoritmo a evitare di bloccarsi in minimi locali. Questo è uno dei punti di forza dell’algoritmo di Metropolis, che garantisce una buona esplorazione dello spazio dei parametri.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#esempio-di-implementazione",
    "href": "chapters/mcmc/01_metropolis.html#esempio-di-implementazione",
    "title": "58  L’algoritmo di Metropolis-Hastings",
    "section": "\n58.10 Esempio di Implementazione",
    "text": "58.10 Esempio di Implementazione\nSupponiamo di voler stimare la probabilità \\(\\theta\\) che un artista della Generazione X sia esposto al MoMA. Disponiamo di 14 successi (presenze) osservati su un campione di 100 artisti. Adottiamo un modello binomiale con distribuzione a priori Beta(4, 6) per \\(\\theta\\), integrando dati osservati e conoscenza a priori mediante l’algoritmo MCMC. Seguiremo l’impostazione metodologica proposta da Elizaveta Semenova, implementando l’algoritmo di Metropolis-Hastings in R. Cominciamo definendo alcune funzioni fondamentali.\n\n58.10.1 Definizione della Distribuzione a Priori\nLa funzione prior calcola la densità della distribuzione Beta(4, 6) per un dato \\(\\theta\\):\n\n# Distribuzione a priori Beta(4, 6)\nprior &lt;- function(p) {\n  dbeta(p, shape1 = 4, shape2 = 6)\n}\n\nQuesta distribuzione esprime la nostra plausibilità iniziale sui valori di \\(\\theta\\) prima di osservare i dati.\n\n58.10.2 Funzione di Verosimiglianza\nLa funzione likelihood modella la probabilità di osservare 14 successi su 100 prove:\n\n# Verosimiglianza binomiale (y = 14 successi su n = 100 prove)\nlikelihood &lt;- function(p) {\n  y &lt;- 14\n  n &lt;- 100\n  dbinom(y, size = n, prob = p)\n}\n\n\n58.10.3 Distribuzione a Posteriori Non Normalizzata\nLa posteriori si ottiene combinando priori e verosimiglianza:\n\n# Posteriori non normalizzata (prodotto tra verosimiglianza e priori)\nposterior &lt;- function(p) {\n  likelihood(p) * prior(p)\n}\n\n\n58.10.4 Distribuzione Proposta\nLa distribuzione proposta sarà una distribuzione normale centrata sullo stato corrente con una deviazione standard specificata:\n\n# Generazione proposta (normale con media sullo stato corrente)\nproposal_distribution &lt;- function(current_state, proposal_sigma) {\n  rnorm(1, mean = current_state, sd = proposal_sigma)\n}\n\n\n58.10.5 Implementazione dell’Algoritmo Metropolis-Hastings\nProcediamo ora con l’implementazione dell’algoritmo di Metropolis-Hastings, considerando i dati relativi agli artisti della Generazione X presenti al MoMA. La distribuzione a priori per \\(\\theta\\) è modellata come una Beta(4, 6).\n\n# Algoritmo Metropolis-Hastings\nmetropolis_hastings &lt;- function(n_samples, start, proposal_sigma) {\n  samples &lt;- numeric(n_samples)\n  current &lt;- start  # Stato iniziale\n\n  for (i in seq_len(n_samples)) {\n    proposal &lt;- proposal_distribution(current, proposal_sigma)\n    \n    # Verifica validità e calcolo rapporto di accettazione\n    if (proposal &gt;= 0 && proposal &lt;= 1) {\n      acceptance_ratio &lt;- min(1, posterior(proposal) / posterior(current))\n      # Accetta/rifiuta con probabilità acceptance_ratio\n      if (runif(1) &lt; acceptance_ratio) {\n        current &lt;- proposal\n      }\n    }\n    samples[i] &lt;- current  # Aggiorna la catena\n  }\n  return(samples)\n}\n\n\n\n\n\n\n\nInterpretazione intuitiva\n\n\n\n\n\nImmaginate di esplorare un paesaggio montuoso (la posteriori) avvolto dalla nebbia, dove le alture rappresentano regioni ad alta densità di probabilità. L’algoritmo replica il comportamento di un escursionista che:\n\n\nValuta la posizione corrente (current) tramite l’altezza locale (posterior(current)).\n\nPropone un passo casuale in una direzione vicina (proposal), determinata da una distribuzione normale.\n\nDecide il movimento confrontando le altezze relative:\n\nSe il nuovo punto è più alto (\\(R \\geq 1\\)), lo accetta immediatamente.\nSe è più basso (\\(R &lt; 1\\)), lo accetta con probabilità \\(R\\), simulando un’accettazione stocastica per evitare massimi locali.\n\n\n\nRegistra ogni posizione visitata, costruendo gradualmente una mappa proporzionale alla vera distribuzione.\n\n\n\n\n\n\n\n\n\n\nDettagli dell’implementazione (1)\n\n\n\n\n\nNel codice la “regola &gt; 1 → accetta” è incorporata in queste due istruzioni consecutive:\nacceptance_ratio &lt;- min(1, posterior(proposal) / posterior(current))\n...\nif (runif(1) &lt; acceptance_ratio) {\n    current &lt;- proposal\n}\n\n\nClipping a 1 con min(1, …)\n\nSe il rapporto \\(\\frac{\\text{posterior(proposal)}}{\\text{posterior(current)}}\\) è maggiore di 1 (cioè il nuovo punto ha densità a‐posteriori più alta), min() lo tronca a 1.\n\nQuindi acceptance_ratio vale esattamente 1 in tutti i casi in cui il “vero” rapporto sarebbe &gt; 1.\n\n\n\nAccettazione certa con il confronto runif(1) &lt; 1\n\n\nrunif(1) genera un numero uniforme in \\([0,1)\\); qualunque valore estratto sarà sempre &lt; 1.\n\nDi conseguenza, quando acceptance_ratio è 1 l’if è sempre vero e il punto proposto viene accettato con probabilità 1, esattamente come prescrive l’algoritmo di Metropolis (o di Metropolis-Hastings nel caso simmetrico).\n\n\n\nIn sintesi, la riga con min(1, …) traduce la regola teorica “accetta se il rapporto è &gt; 1” in una forma pratica che si integra con il test probabilistico successivo.\n\n\n\n\n\n\n\n\n\nDettagli dell’implementazione (2)\n\n\n\n\n\nProprietà della proposta simmetrica: L’algoritmo di Metropolis (quello base come questo) funziona bene se la maniera in cui proponi di “spostarti” da un punto A a un punto B è esattamente la stessa della maniera in cui proporresti di spostarti da B ad A. Pensa a una proposta “neutra” rispetto alla direzione. Questa “simmetria” nella proposta è utile perché ci permette di decidere se accettare un passo basandoci esclusivamente sul confronto della ‘probabilità’ (la densità) dei due punti (proposto e attuale) sotto la distribuzione che vogliamo esplorare. In pratica, non dobbiamo preoccuparci di ‘correggere’ il rapporto di accettazione per tenere conto di proposte che potrebbero essere più facili in una direzione che nell’altra. Questa semplicità aiuta l’algoritmo a trovare il giusto bilanciamento negli spostamenti, permettendogli di campionare correttamente dalla distribuzione desiderata nel lungo periodo.\n\n\n\n\n58.10.6 Esecuzione dell’Algoritmo\n\n# Parametri dell'algoritmo\nn_samples &lt;- 10000\nstart &lt;- 0.5\nproposal_sigma &lt;- 0.1\n\n# Esecuzione del campionamento\nset.seed(123)  # Per riproducibilità\nsamples &lt;- metropolis_hastings(n_samples, start, proposal_sigma)\n\n\n58.10.7 Analisi dei Risultati\nScartiamo i primi 5000 campioni per considerare solo quelli generati dopo il burn-in:\n\nburnin &lt;- floor(n_samples * 0.5)\npost_burnin_samples &lt;- samples[-seq_len(burnin)]\n\nCalcoliamo la media e la deviazione standard dei campioni:\n\n# Media a posteriori\nmean(post_burnin_samples)\n#&gt; [1] 0.1631\n\n# Deviazione standard a posteriori\nsd(post_burnin_samples)\n#&gt; [1] 0.03535\n\nVisualizziamo l’evoluzione della catena per i primi 200 campioni e per quelli post-burn-in:\n\ntibble(\n  Iterazione = 1:200,\n  Theta = samples[1:200]\n) |&gt; \n  ggplot(aes(x = Iterazione, y = Theta)) +\n    geom_line() + # Specifica che vuoi un grafico a linea\n    ggtitle(\"Trace Plot (Primi 200 Campioni)\") + # Aggiunge il titolo principale\n    xlab(\"Iterazioni\") + # Etichetta l'asse X\n    ylab(expression(theta)) # Etichetta l'asse Y usando l'espressione per theta\n\n\n\n\n\n\n\n\ntibble(\n  Iterazione = 1:length(post_burnin_samples), \n  Theta = post_burnin_samples\n) |&gt; \n  ggplot(aes(x = Iterazione, y = Theta)) +\n    geom_line() + # Specifica un grafico a linea\n    ggtitle(\"Trace Plot (Post Burn-in)\") + # Aggiunge il titolo\n    xlab(\"Iterazioni\") + # Indice all'interno della serie post-burn-in\n    ylab(expression(theta)) # Etichetta l'asse Y\n\n\n\n\n\n\n\nSovrapponiamo la distribuzione analitica \\(\\text{Beta}(18, 92)\\) all’istogramma dei campioni post-burn-in:\n\ntibble(Theta = post_burnin_samples) |&gt; \nggplot(aes(x = Theta)) +\n  geom_histogram(aes(y = after_stat(density), fill = \"Istogramma MCMC\"),\n                 bins = 30, \n                 color = \"black\", \n                 alpha = 0.7) + \n  stat_function(aes(color = \"Beta(18, 92)\"),\n                fun = dbeta, # Specifica la funzione da disegnare (densità Beta)\n                args = list(shape1 = 18, shape2 = 92), \n                linewidth = 1.2) + \n  labs(title = \"Istogramma e Distribuzione Posteriori\",\n       x = expression(theta),\n       y = \"Densità\",\n       fill = \"Distribuzione\", \n       color = \"Distribuzione\") +\n  scale_fill_manual(values = c(\"Istogramma MCMC\" = okabe_ito_palette[1])) +\n  scale_color_manual(values = c(\"Beta(18, 92)\" = okabe_ito_palette[2]))\n\n\n\n\n\n\n\nCalcoliamo l’intervallo di credibilità al 94%:\n\nquantile(post_burnin_samples, probs = c(0.03, 0.97))\n#&gt;     3%    97% \n#&gt; 0.1020 0.2347\n\nI valori ottenuti con l’algoritmo di Metropolis (usando solo un piccolo numero di iterazioni) sono quasi identici ai valori esatti:\n\nqbeta(c(0.03, 0.97), 18, 92)\n#&gt; [1] 0.1030 0.2346\n\nQuesta implementazione in R dimostra come utilizzare l’algoritmo di Metropolis per stimare una distribuzione a posteriori e analizzare i risultati in modo dettagliato e riproducibile.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#catene-di-markov-e-convergenza",
    "href": "chapters/mcmc/01_metropolis.html#catene-di-markov-e-convergenza",
    "title": "58  L’algoritmo di Metropolis-Hastings",
    "section": "\n58.11 Catene di Markov e Convergenza",
    "text": "58.11 Catene di Markov e Convergenza\nNell’ambito delle simulazioni Monte Carlo, una catena rappresenta una sequenza di valori campionati dall’algoritmo durante le sue iterazioni. Ogni valore nella catena corrisponde a un possibile stato del sistema che stiamo modellando. In altre parole, una catena traccia il percorso che l’algoritmo segue nello spazio dei parametri, esplorando le diverse configurazioni possibili.\nPer verificare se l’algoritmo ha raggiunto la convergenza e se i campioni generati rappresentano effettivamente la distribuzione di interesse, è utile eseguire multiple catene. Ogni catena parte da un punto iniziale diverso nello spazio dei parametri.\nI vantaggi delle multiple catene:\n\n\nDiagnostica della convergenza: Confrontando le diverse catene, possiamo valutare se si stabilizzano verso la stessa distribuzione. Se le catene si mescolano bene, ovvero si intersecano frequentemente nel grafico dei valori campionati (trace plot), è un forte indicatore di convergenza.\n\nRobustezza: L’utilizzo di multiple catene rende l’analisi meno sensibile alla scelta del punto di partenza. Se una singola catena potesse rimanere “intrappolata” in una regione dello spazio dei parametri, multiple catene aumentano la probabilità di esplorare lo spazio in modo più completo.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#diagnostiche-della-soluzione-mcmc",
    "href": "chapters/mcmc/01_metropolis.html#diagnostiche-della-soluzione-mcmc",
    "title": "58  L’algoritmo di Metropolis-Hastings",
    "section": "\n58.12 Diagnostiche della soluzione MCMC",
    "text": "58.12 Diagnostiche della soluzione MCMC\n\n58.12.1 Stazionarietà e Convergenza\nUn aspetto cruciale nell’analisi delle catene di Markov MCMC è la convergenza alla distribuzione stazionaria. Intuitivamente, la catena converge quando i campioni generati rappresentano fedelmente la distribuzione di interesse, indipendentemente dal punto di partenza. Questo fenomeno è spesso indicato come “mixing”.\n\n58.12.1.1 Valutazione Visuale: Trace Plots e Grafici di Densità\n\n\nTrace Plots: Questi grafici visualizzano l’evoluzione dei parametri nel tempo. Una catena convergente mostra tracce stabili e senza trend evidenti. Tracce irregolari o con andamenti sistematici suggeriscono problemi di convergenza.\n\nGrafici di Densità: Confrontando i grafici di densità dei campioni con la distribuzione teorica, è possibile valutare visivamente se la catena sta esplorando adeguatamente lo spazio dei parametri. Una buona convergenza si manifesta con una sovrapposizione tra i due grafici.\n\nSegni di Convergenza:\n\n\nStabilità: I valori campionati oscillano attorno a un valore medio costante, senza trend marcati.\n\nOmogeneità: La variabilità dei campioni rimane relativamente uniforme nel tempo.\n\nAssenza di Periodicità: Non si osservano pattern ciclici o ripetitivi.\n\nIn sintesi, i trace plots e i grafici di densità offrono strumenti visivi rapidi per valutare la convergenza di una catena di Markov MCMC. Una convergenza soddisfacente è fondamentale per garantire la validità delle inferenze statistiche basate sui campioni generati.\n\n58.12.2 Autocorrelazione nelle catene di Markov MCMC\nA differenza dei generatori di numeri casuali indipendenti, gli algoritmi MCMC producono una sequenza di campioni correlati. Ogni valore campionato dipende da quello precedente, formando una catena di Markov. Questa interdipendenza è un aspetto fondamentale dell’MCMC.\nL’autocorrelazione quantifica il grado di dipendenza tra valori distanti di una certa quantità (detta lag) nella catena. Un’alta autocorrelazione a lag bassi indica una forte dipendenza tra campioni successivi. Al contrario, una rapida diminuzione dell’autocorrelazione al crescere del lag suggerisce che la catena “miscela” bene, ovvero esplora lo spazio dei parametri in modo efficiente.\n\n\nLag 1: Misura la correlazione tra valori consecutivi nella catena.\n\nLag 2: Misura la correlazione tra valori separati da un passo intermedio.\n\nLag k: Generalizza il concetto ai valori separati da k passi.\n\nUn correlogramma è un grafico che mostra l’autocorrelazione in funzione del lag. Un decadimento rapido dell’autocorrelazione verso zero indica una buona convergenza della catena.\nL’autocorrelazione di ordine \\(k\\) è data da \\(\\rho_k\\) e può essere stimata come:\n\\[\n\\begin{aligned}\n\\rho_k &= \\frac{Cov(\\theta_m, \\theta_{m+k})}{Var(\\theta_m)}\\notag\\\\\n&= \\frac{\\sum_{m=1}^{n-k}(\\theta_m - \\bar{\\theta})(\\theta_{m-k} - \\bar{\\theta})}{\\sum_{m=1}^{n-k}(\\theta_m - \\bar{\\theta})^2} \\qquad\\text{con }\\quad \\bar{\\theta} = \\frac{1}{n}\\sum_{m=1}^{n}\\theta_m.\n\\end{aligned}\n\\tag{58.1}\\]\n\n58.12.3 Esempio di Simulazione di Dati Autocorrelati\nPer fare un esempio pratico, creiamo un vettore di dati autocorrelati:\n\n# Creiamo un vettore di dati\nx &lt;- c(22, 24, 25, 25, 28, 29, 34, 37, 40, 44, 51, 48, 47, 50, 51)\nx\n#&gt;  [1] 22 24 25 25 28 29 34 37 40 44 51 48 47 50 51\n\n\n58.12.3.1 Calcolo dell’Autocorrelazione\nL’autocorrelazione di ordine 1 è la correlazione tra ciascun elemento e il successivo nella sequenza. In R possiamo utilizzare la funzione acf() per calcolare l’autocorrelazione.\n\n# Calcolo dell'autocorrelazione\nacf_values &lt;- acf(x, plot = FALSE)\nacf_values\n#&gt; \n#&gt; Autocorrelations of series 'x', by lag\n#&gt; \n#&gt;      0      1      2      3      4      5      6      7      8      9 \n#&gt;  1.000  0.832  0.656  0.491  0.279  0.031 -0.165 -0.304 -0.401 -0.458 \n#&gt;     10     11 \n#&gt; -0.450 -0.369\n\nNell’esempio, il vettore x rappresenta una serie temporale di 15 elementi. Il calcolo dell’autocorrelazione restituisce i seguenti valori per i primi ritardi (lag):\n\n\n0.8317: autocorrelazione di ordine 1 (lag = 1),\n\n0.6563: autocorrelazione di ordine 2 (lag = 2),\n\n0.4910: autocorrelazione di ordine 3 (lag = 3),\necc.\n\n58.12.3.2 Specifica del Numero di Ritardi (Lag)\nPossiamo limitare il numero di ritardi calcolati utilizzando l’argomento lag.max nella funzione acf():\n\n# Calcolo dell'autocorrelazione per i primi 4 lag\nacf(x, lag.max = 4, plot = FALSE)\n#&gt; \n#&gt; Autocorrelations of series 'x', by lag\n#&gt; \n#&gt;     0     1     2     3     4 \n#&gt; 1.000 0.832 0.656 0.491 0.279\n\n\n58.12.3.3 Grafico della Funzione di Autocorrelazione (Correlogramma)\nIn R possiamo creare un correlogramma con la funzione acf():\n\n# Correlogramma per la serie temporale\nacf(x, main = \"Correlogramma della Serie Temporale\", lag.max = 9)\n\n\n\n\n\n\n\n\n58.12.4 Analisi della Catena di Markov\nApplichiamo lo stesso approccio alla catena di Markov ottenuta precedentemente, considerando i campioni post burn-in:\n\n# Definizione dei campioni post burn-in\npost_burnin_samples &lt;- samples[-seq_len(burnin)]\n\n# Correlogramma per i campioni post burn-in\nacf(\n  post_burnin_samples, \n  main = \"Correlogramma della Catena Post Burn-in\", \n  lag.max = 9\n)\n\n\n\n\n\n\n\nIn situazioni ideali, l’autocorrelazione diminuisce rapidamente, diventando insignificante per piccoli lag. Questo comportamento è un’indicazione del “mixing” efficace della catena, ossia della sua convergenza alla distribuzione stazionaria.\n\n58.12.5 Sottocampionamento (Thinning)\nPer ridurre l’autocorrelazione, possiamo applicare una strategia di sottocampionamento (thinning), memorizzando solo ogni \\(m\\)-esimo campione.\n\n# Sottocampionamento con un fattore di 5\nthin &lt;- 5\nsampsthin &lt;- \n  post_burnin_samples[seq(1, length(post_burnin_samples), by = thin)]\n\n# Correlogramma per i campioni sottocampionati\nacf(\n  sampsthin, \n  main = \"Correlogramma con Sottocampionamento (Thinning)\", \n  lag.max = 9\n)\n\n\n\n\n\n\n\nIn conclusione, il correlogramma con thinning mostra che l’autocorrelazione diminuisce più rapidamente rispetto ai campioni originali, suggerendo che la strategia di sottocampionamento è efficace nel migliorare l’indipendenza tra i campioni successivi. Questo migliora la qualità delle inferenze basate sulla catena di Markov.\n\n58.12.5.1 Tasso di accettazione\nQuando si utilizza l’algoritmo Metropolis, è importante monitorare il tasso di accettazione e assicurarsi che sia nell’intervallo ottimale. Se si accetta quasi sempre il candidato proposto, probabilmente significa che, in ogni iterazione, la catena salta solo di un piccolo passo (in modo che il rapporto di accettazione sia vicino a 1 ogni volta). Di conseguenza, la catena impiegherà molte iterazioni per raggiungere altre regioni della distribuzione stazionaria e i campioni consecutivi saranno molto fortemente correlati. D’altra parte, se il tasso di accettazione è molto basso, la catena rimarrà bloccata nella stessa posizione per molte iterazioni prima di spostarsi verso uno stato diverso. Per l’algoritmo Metropolis base con un singolo parametro con una distribuzione proposta Gaussiana normale, un tasso di accettazione ottimale è compreso tra il 40% e il 50%.\n\n58.12.6 Test Statistici per la Convergenza\nOltre agli approcci grafici, esistono test statistici specifici che possono aiutare a determinare se la catena ha raggiunto uno stato stazionario.\n\n58.12.6.1 Test di Geweke\nIl test di Geweke è una procedura che confronta le medie di due segmenti della catena di campionamento, tipicamente il primo 10% e l’ultimo 50% dei campioni, dopo aver escluso un iniziale periodo di “burn-in” (una fase iniziale durante la quale la catena potrebbe non essere ancora convergente). La premessa di base è che, se la catena è in uno stato stazionario, le medie di questi due segmenti dovrebbero essere sostanzialmente uguali. Differenze importanti tra queste medie possono indicare che la catena non ha ancora raggiunto la convergenza.\n\n58.12.6.2 Geweke Z-score\nUna variante del test di Geweke è lo z-score di Geweke, che offre un modo quantitativo per valutare le differenze tra i segmenti della catena. Questo test calcola uno z-score che confronta le medie dei due segmenti tenendo conto della varianza. Un valore di z-score:\n\n\nAl di sotto di 2 (in valore assoluto) suggerisce che non ci sono differenze degne di nota tra i segmenti, indicando che la catena potrebbe essere in stato stazionario.\n\nSuperiore a 2 (in valore assoluto) indica che esiste una differenza degna di nota tra i segmenti, suggerendo che la catena non ha raggiunto la convergenza e potrebbe essere necessario un periodo di burn-in più esteso.\n\nEntrambi i metodi forniscono strumenti utili per valutare la convergenza delle catene MCMC. È importante notare che nessun test può garantire con certezza la convergenza, ma l’utilizzo congiunto di approcci grafici e test statistici può offrire una buona indicazione dello stato della catena.\n\n58.12.7 Dimensione del campione effettiva (ESS)\nLa correlazione tra campioni consecutivi in una catena MCMC riduce l’informazione effettiva contenuta in ogni iterazione. La dimensione del campione effettiva (ESS) quantifica questa perdita di informazione dovuta alla dipendenza tra i campioni, stimando il numero equivalente di campioni indipendenti. Un valore basso di ESS indica una forte correlazione tra i campioni e una convergenza più lenta della catena.\nL’ESS descrive l’efficacia del campionamento dipendente in termini di campioni indipendenti estratti dalla stessa distribuzione. Rappresenta un indicatore dell’efficienza del campionamento e dell’autocorrelazione della catena.\nLa formula per stimare la dimensione del campione effettiva (ESS) di una catena di Markov è:\n\\[\n\\text{ESS} = \\frac{N}{1 + 2 \\sum_{t=1}^{T} \\rho_t},\n\\]\ndove:\n\n\n\\(N\\) è il numero totale di campioni nella catena,\n\n\\(T\\) è il lag, ovvero il numero massimo di termini di autocorrelazione considerati,\n\n\\(\\rho_t\\) è l’autocorrelazione al lag \\(t\\), ossia la correlazione tra due campioni consecutivi separati da \\(t\\) iterazioni.\n\nIn pratica, \\(T\\) viene scelto in modo tale che \\(\\rho_T\\) sia sufficientemente piccolo, indicando che l’autocorrelazione è quasi svanita. La somma \\(\\sum_{t=1}^T \\rho_t\\) viene quindi troncata approssimativamente a \\(T\\), poiché i contributi delle autocorrelazioni successive diventano trascurabili.\n\n58.12.8 Calcolo della Statistica di Gelman-Rubin (\\(\\hat{R}\\))\nPer calcolare la statistica di Gelman-Rubin (spesso indicata come \\(\\hat{R}\\)), è necessario eseguire più catene e confrontare la variabilità all’interno di ciascuna catena con la variabilità tra le catene. Ecco i passaggi per calcolare \\(\\hat{R}\\):\n\nEsegui \\(m\\) catene di Markov di lunghezza \\(n\\), dove \\(m\\) è solitamente maggiore di 1.\nPer ciascun parametro scalare \\(\\theta\\), calcola la varianza all’interno delle catene (\\(W\\)) e la varianza tra le catene (\\(B\\)).\nCalcola la varianza combinata \\(\\hat{V}\\) come media ponderata delle varianze all’interno delle catene.\nCalcola il fattore di riduzione della scala potenziale \\(\\hat{R}\\) come la radice quadrata del rapporto tra la varianza combinata \\(\\hat{V}\\) e la varianza all’interno delle catene \\(W\\):\n\n\\[\n\\hat{R} = \\sqrt{\\frac{\\hat{V}}{W}}.\n\\]\n\nSe \\(\\hat{R}\\) è vicino a 1, ciò indica che le catene sono in convergenza.\n\nLa statistica di Gelman-Rubin \\(\\hat{R}\\) è una misura di convergenza per le catene di Markov. Essa quantifica il grado di accordo tra più catene, fornendo uno strumento diagnostico per valutare la convergenza nelle simulazioni MCMC.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#vantaggi-del-campionamento-mcmc-rispetto-alle-soluzioni-analitiche",
    "href": "chapters/mcmc/01_metropolis.html#vantaggi-del-campionamento-mcmc-rispetto-alle-soluzioni-analitiche",
    "title": "58  L’algoritmo di Metropolis-Hastings",
    "section": "\n58.13 Vantaggi del Campionamento MCMC rispetto alle Soluzioni Analitiche",
    "text": "58.13 Vantaggi del Campionamento MCMC rispetto alle Soluzioni Analitiche\nIl campionamento MCMC offre notevoli vantaggi pratici rispetto alle soluzioni analitiche nella statistica bayesiana, in particolare quando si tratta di manipolare distribuzioni a posteriori. Sebbene l’impossibilità di calcolare analiticamente la distribuzione a posteriori sia spesso la motivazione principale per l’uso di MCMC, i benefici di questo approccio si estendono ben oltre questa necessità (Bürkner, 2024).\n\n58.13.1 Facilità di Manipolazione e Flessibilità\nIl vantaggio chiave del campionamento MCMC risiede nella semplicità con cui si possono manipolare i campioni ottenuti. Mentre le densità calcolate analiticamente possono richiedere trasformazioni matematiche complesse, i campioni MCMC possono essere facilmente trasformati con operazioni dirette.\nIn conclusione, il campionamento MCMC non è solo una necessità quando le soluzioni analitiche sono introvabili, ma offre vantaggi in termini di facilità di manipolazione, flessibilità computazionale e applicabilità pratica.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#caso-normale-normale-con-soluzione-analitica",
    "href": "chapters/mcmc/01_metropolis.html#caso-normale-normale-con-soluzione-analitica",
    "title": "58  L’algoritmo di Metropolis-Hastings",
    "section": "\n58.14 Caso Normale-Normale con Soluzione Analitica",
    "text": "58.14 Caso Normale-Normale con Soluzione Analitica\nApplichiamo ora l’algoritmo di Metropolis al caso Normale-Normale di cui conosciamo la soluzione analitica. In pratica, ci poniamo il problema di capire quale valore di \\(\\mu\\) (la media vera di una popolazione) sia più plausibile, dopo aver osservato alcuni dati. Abbiamo:\n\nun’idea iniziale (prior) che dice che \\(\\mu\\) dovrebbe stare attorno a 30, con una certa incertezza (deviazione standard 5),\ne abbiamo i dati osservati (\\(y\\)) che ci danno informazioni aggiuntive su dove si trova davvero \\(\\mu\\).\n\nMa non conosciamo esattamente la distribuzione a posteriori di \\(\\mu\\).\nVogliamo costruire una “nuvola” di valori plausibili per \\(\\mu\\) basandoci su dati e prior. Il metodo che usiamo per risolvere questo problema è l’algoritmo di Metropolis.\nStep 1. Partiamo da un punto.\nx_prev &lt;- xinit\n\n\nxinit è il valore iniziale: il nostro “primo sospetto” su dove si trovi \\(\\mu\\).\nÈ come partire da un punto sulla mappa (“Penso che \\(\\mu\\) sia circa qui”).\n\nStep 2. Proponiamo un nuovo punto vicino.\nx_star &lt;- rnorm(1, mean = x_prev, sd = 0.5)\n\nImmaginiamo di essere bendati e di provare a fare un piccolo passo a caso partendo da dove siamo ora.\nQuel passo è generato con una distribuzione normale centrata su x_prev e con una deviazione standard piccola (0.5): piccoli passi casuali attorno al punto attuale.\n\nNota intuitiva:\nIl valore 0.5 decide quanto “grandi” o “piccoli” sono i nostri passi. Più è grande, più possiamo saltare lontano; più è piccolo, più restiamo vicino.\nStep 3. Calcoliamo quanto è “buono” il nuovo punto.\nposterior(x_star, data)\nposterior(x_prev, data)\n\nOgni punto sulla mappa (\\(\\mu\\)) ha un certo valore di plausibilità: quanto è probabile dati i dati osservati e il prior.\n\nposterior(x_star, data) ci dice: “quanto è buono il nuovo punto?”\n\nposterior(x_prev, data) ci dice: “quanto era buono quello vecchio?”\n\nStep 4. Decidiamo se accettare il nuovo punto.\nif (runif(1) &lt; min(1, posterior(x_star, data) / posterior(x_prev, data))) {\n  x_prev &lt;- x_star\n}\nQui applichiamo il meccanismo di base dell’algoritmo di Metropolis per decidere sull’accettazione di un nuovo punto:\n\n\nse il nuovo punto è migliore (cioè, la probabilità a posteriori è maggiore), allora lo accettiamo sicuramente (\\(\\alpha &gt; 1\\), quindi \\(\\min(1, \\alpha) = 1\\));\n\nse il nuovo punto è peggiore, possiamo comunque accettarlo con una certa probabilità:\n\nla probabilità di accettazione diminuisce all’aumentare di quanto il punto è “peggiore”;\nciò è essenziale per non rimanere bloccati nei massimi locali.\n\n\n\nIn parole semplici:\n\nse troviamo un posto migliore, ci andiamo;\nse troviamo un posto peggiore, possiamo comunque andarci… ma tirando una monetina.\n\nStep 5. Registriamo il punto attuale\nDopo aver deciso se accettare o meno il nuovo valore proposto, salviamo sempre un punto nella catena.\nMa attenzione:\n\n\nse la proposta è stata accettata, ci spostiamo al nuovo punto e lo registriamo;\n\nse la proposta è stata rifiutata, restiamo fermi e registriamo di nuovo la posizione attuale.\n\nif (runif(1) &lt; min(1, posterior(x_star, data) / posterior(x_prev, data))) {\n  x_prev &lt;- x_star  # accettiamo: ci spostiamo\n}\nsamples[i] &lt;- x_prev  # salviamo dove ci troviamo ORA\nIn entrambi i casi, samples[i] tiene traccia della posizione in cui ci troviamo dopo l’iterazione.\nIntuizione: l’escursionista bendato.\nImmaginiamo un’escursionista bendato che vuole esplorare un paesaggio fatto di colline di plausibilità (la distribuzione a posteriori):\n\na ogni passo, prova a fare un salto in una nuova direzione (x_star);\nse quel punto è più alto o non troppo peggiore, accetta di andarci e si sposta.\nse il punto è troppo brutto, rimane fermo dov’è;\nin ogni caso, segna nel diario la sua posizione attuale.\n\nEcco perché, quando guardiamo la catena, possiamo trovare valori ripetuti consecutivi: l’escursionista non si è mosso.\nQuesta caratteristica – il fatto che i campioni non siano tutti diversi – non è un errore, ma una proprietà fondamentale dell’algoritmo Metropolis: i campioni sono dipendenti e possono ripetersi.\nStep 6. Ripetiamo tante volte.\nfor (i in seq_len(nsamp)) { ... }\n\nPiù a lungo ripetiamo il processo (più iterazioni), più densa e accurata sarà la nostra approssimazione della distribuzione a posteriori di \\(\\mu\\).\nDopo un po’, i valori salvati formeranno un disegno della distribuzione plausibile di \\(\\mu\\).\n\n🎯 Riassunto in 3 frasi:\n\n\nPartiamo da un valore sospettato di \\(\\mu\\).\n\n\nFacciamo piccoli passi casuali e decidiamo se accettarli in base a quanto sono “buoni” rispetto ai dati + prior.\n\n\nDopo molti passi, la sequenza dei punti disegna la distribuzione a posteriori di \\(\\mu\\).\n\n\n📈 Dopo il sampling:\n\npossiamo calcolare la media dei campioni = stima puntuale di \\(\\mu\\);\npossiamo costruire un intervallo di credibilità = incertezza su \\(\\mu\\);\npossiamo disegnare un istogramma dei campioni = forma della distribuzione a posteriori.\n\nAnche se l’algoritmo di Metropolis può sembrare “rozzo” (tanti piccoli passi + accettare/rifiutare), funziona benissimo ed è uno dei motivi per cui oggi possiamo applicare la statistica bayesiana a modelli anche molto complessi.\nApplichiamo dunque l’algoritmo di Metropolis all’esercizio in discussione. Iniziamo a definire le funzioni per il prior, la verosimiglianza e il posterior non normalizzato.\n\n# Prior: Normal(30, 5^2)\nprior &lt;- function(mu) {\n  dnorm(mu, mean = 30, sd = 5)\n}\n\n# Likelihood: Normal(mu, sigma^2) con sigma calcolata dai dati\nlikelihood &lt;- function(mu, data) {\n  sigma &lt;- sd(data)  # Deviazione standard dei dati\n  prod(dnorm(data, mean = mu, sd = sigma))\n}\n\n# Posterior non normalizzato\nposterior &lt;- function(mu, data) {\n  likelihood(mu, data) * prior(mu)\n}\n\nImplementiamo l’algoritmo di Metropolis per il caso normale-normale:\n\n# Algoritmo di Metropolis\nmetropolis_for_normal &lt;- function(nsamp, xinit, data) {\n  samples &lt;- numeric(nsamp)\n  x_prev &lt;- xinit\n  \n  for (i in seq_len(nsamp)) {\n    x_star &lt;- rnorm(1, mean = x_prev, sd = 0.5)  # Proposta\n    if (runif(1) &lt; min(1, posterior(x_star, data) / posterior(x_prev, data))) {\n      x_prev &lt;- x_star\n    }\n    samples[i] &lt;- x_prev\n  }\n  \n  samples\n}\n\nUtilizziamo un campione di 30 valori BDI-II forniti da Zetsche et al. (2019):\n\n# Dati osservati\ny &lt;- c(\n  26, 35, 30, 25, 44, 30, 33, 43, 22, 43, 24, 19, 39, 31, 25, \n  28, 35, 30, 26, 31, 41, 36, 26, 35, 33, 28, 27, 34, 27, 22\n)\n\nEsecuzione dell’algoritmo:\n\nsamples &lt;- metropolis_for_normal(100000, mean(y), y)\n\nNel caso normale-normale, il posterior può essere calcolato analiticamente come segue:\n\n# Parametri del prior\nmu_prior &lt;- 30\nstd_prior &lt;- 5\nvar_prior &lt;- std_prior^2\n\n# Calcolo dei parametri posterior\nn &lt;- length(y)\nsum_y &lt;- sum(y)\nvar_data &lt;- var(y)\n\nmu_post &lt;- (mu_prior / var_prior + sum_y / var_data) / (1 / var_prior + n / var_data)\nvar_post &lt;- 1 / (1 / var_prior + n / var_data)\nstd_post &lt;- sqrt(var_post)\n\nmu_post\n#&gt; [1] 30.88\nstd_post\n#&gt; [1] 1.173\n\nVisualizziamo i risultati con un istogramma dei campioni MCMC e la curva della distribuzione analitica:\n\n# Campioni post burn-in\nburnin &lt;- floor(length(samples) * 0.5)\npost_samples &lt;- samples[-seq_len(burnin)]\n\n# Dati per la curva analitica\nx &lt;- seq(mu_post - 4 * std_post, mu_post + 4 * std_post, length.out = 1000)\nanalytical_posterior &lt;- dnorm(x, mean = mu_post, sd = std_post)\n\n# Creazione del grafico\nggplot() +\n  geom_histogram(aes(x = post_samples, y = after_stat(density)), bins = 30, fill = \"blue\", alpha = 0.4) +\n  geom_line(aes(x = x, y = analytical_posterior), color = \"red\", size = 1) +\n  labs(title = \"Distribuzione Posterior: MCMC vs Analitico\",\n       x = expression(mu), y = \"Densità\") \n\n\n\n\n\n\n\nTroviamo le proprietà del Posterior derivato con MCMC:\n\nmean(samples)\n#&gt; [1] 30.91\n\n\nsd(samples)\n#&gt; [1] 1.177\n\nIn conclusione, questo esempio illustra l’applicazione dell’algoritmo di Metropolis per la stima di una distribuzione a posteriori nel caso Normale-Normale e dimostra come confrontare i risultati del campionamento con la soluzione analitica, confermando così la coerenza tra le due approcci.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#riflessioni-conclusive",
    "href": "chapters/mcmc/01_metropolis.html#riflessioni-conclusive",
    "title": "58  L’algoritmo di Metropolis-Hastings",
    "section": "\n58.15 Riflessioni Conclusive",
    "text": "58.15 Riflessioni Conclusive\nIn molti casi, la distribuzione a posteriori dei parametri di un modello statistico non ha una forma analitica risolvibile. Per affrontare questa limitazione, si utilizzano metodi Monte Carlo basati su catene di Markov (MCMC). Questi algoritmi permettono di campionare efficacemente dalla distribuzione a posteriori, anche per modelli complessi, generando una sequenza di valori che approssima la distribuzione desiderata. L’algoritmo di Metropolis-Hastings (Hastings, 1970), un’estensione dell’algoritmo di Metropolis originale (Metropolis et al., 1953), è uno dei metodi MCMC più ampiamente utilizzati.\nIn sintesi, l’algoritmo segue questi passaggi principali:\n\n\nGenerazione del nuovo stato proposto: Si crea un nuovo stato vicino a quello corrente utilizzando una distribuzione di proposta.\n\nConfronto tra densità posteriori: Si confrontano le densità a posteriori del nuovo stato proposto e dello stato corrente.\n\nAccettazione probabilistica: Il nuovo stato viene sempre accettato se ha una densità posteriore maggiore, oppure accettato con una certa probabilità se ha una densità minore.\n\nBurn-in e tasso di accettazione: I primi campioni vengono scartati (fase di burn-in) per garantire che la catena abbia raggiunto la distribuzione stazionaria, e si monitora il tasso di accettazione per ottimizzare l’efficienza del campionamento.\n\nQuesto approccio consente di ottenere campioni che approssimano la distribuzione a posteriori, ma l’algoritmo di Metropolis può presentare limiti di efficienza, soprattutto per problemi ad alta dimensionalità o distribuzioni con geometrie complesse. Un aspetto cruciale è il tasso di accettazione, che rappresenta il rapporto tra il numero di proposte accettate e il numero totale di proposte. Un tasso troppo basso può indicare che la catena esplora lo spazio dei parametri in modo inefficiente, mentre un tasso troppo alto può segnalare che i passi effettuati sono troppo piccoli per consentire una buona esplorazione.\nRispetto alle varianti più moderne, l’algoritmo di Metropolis tende a essere meno efficiente. Metodi come il No-U-Turn Sampler (NUTS) e l’Hamiltonian Monte Carlo (HMC) offrono importanti miglioramenti, specialmente in spazi di parametri di grandi dimensioni. NUTS, ad esempio, viene utilizzato in strumenti avanzati come Stan e PyMC (Hoffman et al., 2014), permettendo un’esplorazione più rapida e accurata della distribuzione a posteriori.\nTra gli altri algoritmi MCMC degni di nota troviamo il campionatore di Gibbs (Geman & Geman, 1984) e l’Hamiltonian Monte Carlo (Duane et al., 1987). Questi metodi, insieme a Metropolis-Hastings, formano la base di numerose tecniche moderne per il campionamento da distribuzioni complesse. Per un approfondimento dettagliato sulle tecniche MCMC, si consiglia di consultare Hanada & Matsuura (2022).\n\n\n\n\n\n\nEsercizio 1: Autostima negli Studenti Universitari\n\n\n\n\n\nIn un campione casuale di 100 studenti, 25 hanno mostrato livelli alti di autostima.\nSupponiamo un prior Beta(2,8) sulla proporzione \\(\\theta\\) di studenti con alta autostima.\nObiettivo: stimare la distribuzione a posteriori di \\(\\theta\\) usando l’algoritmo di Metropolis.\nDefinizione delle Funzioni.\n\nset.seed(123)  # per riproducibilità\n\n# Prior: Beta(2,8)\nprior &lt;- function(p) dbeta(p, shape1 = 2, shape2 = 8)\n\n# Likelihood: binomiale 25 successi su 100\nlikelihood &lt;- function(p) dbinom(25, size = 100, prob = p)\n\n# Posterior non normalizzata\nposterior &lt;- function(p) prior(p) * likelihood(p)\n\n# Distribuzione di proposta\nproposal_distribution &lt;- function(current, proposal_sigma) {\n  rnorm(1, mean = current, sd = proposal_sigma)\n}\n\n# Algoritmo di Metropolis\nmetropolis &lt;- function(n_samples, start, proposal_sigma) {\n  samples &lt;- numeric(n_samples)\n  current &lt;- start\n  \n  for (i in seq_len(n_samples)) {\n    proposal &lt;- proposal_distribution(current, proposal_sigma)\n    if (proposal &gt;= 0 && proposal &lt;= 1) {\n      acceptance_ratio &lt;- min(1, posterior(proposal) / posterior(current))\n      if (runif(1) &lt; acceptance_ratio) {\n        current &lt;- proposal\n      }\n    }\n    samples[i] &lt;- current\n  }\n  samples\n}\n\nEsecuzione dell’Algoritmo.\n\n# Parametri\nn_samples &lt;- 10000\nstart &lt;- 0.5\nproposal_sigma &lt;- 0.1\n\n# Esecuzione\nsamples &lt;- metropolis(n_samples, start, proposal_sigma)\n\n# Burn-in\nburnin &lt;- floor(n_samples * 0.5)\npost_samples &lt;- samples[-seq_len(burnin)]\n\nAnalisi dei Risultati.\n\n# Media e deviazione standard\nmean(post_samples)\n#&gt; [1] 0.2444\nsd(post_samples)\n#&gt; [1] 0.03947\n\nCalcolo dell’Intervallo di Credibilità al 94%.\n\nquantile(post_samples, probs = c(0.03, 0.97))\n#&gt;     3%    97% \n#&gt; 0.1699 0.3190\n\nConfronto con la Soluzione Analitica.\nLa distribuzione a posteriori teorica è:\n\\[\n\\theta \\sim \\text{Beta}(27, 83)\n\\]\n\n# Media teorica\nmean_beta &lt;- 27 / (27 + 83)\nmean_beta\n#&gt; [1] 0.2455\n\n# Intervallo teorico\nqbeta(c(0.03, 0.97), 27, 83)\n#&gt; [1] 0.1727 0.3260\n\nTrace Plot.\n\n# Trace plot\npost_samples |&gt; \n  tibble(Iteration = 1:length(post_samples), Theta = post_samples) |&gt; \n  ggplot(aes(x = Iteration, y = Theta)) +\n  geom_line() +\n  labs(title = \"Trace Plot dopo Burn-in\", x = \"Iterazione\", y = expression(theta))\n\n\n\n\n\n\n\nIstogramma e Curva Teorica.\n\n# Prima generiamo il dataset della curva teorica separatamente\nx &lt;- seq(0, 1, length.out = 1000)\ndens_teorica &lt;- dbeta(x, 27, 83)\ncurva_teorica &lt;- tibble(x = x, y = dens_teorica)\n\n# Ora costruiamo il grafico correttamente\ntibble(Theta = post_samples) |&gt; \n  ggplot(aes(x = Theta)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 30, \n                 color = \"black\", fill = \"lightblue\", alpha = 0.6) +\n  geom_line(data = curva_teorica, aes(x = x, y = y), \n            color = \"red\", size = 1) +\n  labs(title = \"Posterior: Campioni MCMC vs Beta(27,83)\", \n       x = expression(theta), y = \"Densità\")\n\n\n\n\n\n\n\nRisultati Riassunti.\n\n\nMetodo\nMedia\nIntervallo 94%\n\n\n\nMCMC (Metropolis)\ncirca 0.245\ncirca [0.176, 0.320]\n\n\nTeorico Beta(27,83)\n0.245\n[0.177, 0.318]\n\n\n\nSpiegazioni Didattiche Finali.\n\n\n\n\n\n\nDistribuzione a posteriori: interpretazione\n\n\n\nLa distribuzione a posteriori ci dice quanto sono plausibili i diversi valori di \\(\\theta\\) dopo aver osservato i dati.\n\nAd esempio: “C’è una probabilità del 94% che la vera proporzione di studenti con alta autostima sia tra 17% e 32%.”\n\n\n\n\n\n\n\n\n\nAccettare mosse peggiori: motivo\n\n\n\nAccettiamo campioni con probabilità più bassa per permettere alla catena di esplorare anche aree meno probabili e non restare bloccata nei massimi locali.\n\n\n\n\n\n\n\n\nLarghezza della proposta: trade-off\n\n\n\n\n\nProposta stretta (piccoli passi): alta accettazione, ma esplorazione lenta.\n\nProposta larga (grandi passi): bassa accettazione, ma esplorazione più ampia.\n\nSi cerca un tasso di accettazione tra 40% e 50%.\n\n\n\n\n\n\n\n\nDiagnostica grafica\n\n\n\n\n\nTrace plot: deve mostrare fluttuazioni stabili senza trend.\n\nCorrelogramma: l’autocorrelazione deve decrescere rapidamente.\n\nQuesti strumenti aiutano a diagnosticare una buona esplorazione della distribuzione a posteriori.\n\n\n\n\n\n\n\n\n\n\n\nEsercizio 2 - Depressione (BDI-II)\n\n\n\n\n\nIn uno studio clinico, sono stati raccolti i punteggi BDI-II (Beck Depression Inventory) di 30 pazienti. Vogliamo stimare il valore medio della depressione nella popolazione da cui provengono questi soggetti.\nSupponiamo di avere una conoscenza a priori modellata da una distribuzione Normale(30, 5²) per la media \\(\\mu\\).\nI dati osservati sono i seguenti:\n\ny &lt;- c(26, 35, 30, 25, 44, 30, 33, 43, 22, 43,\n       24, 19, 39, 31, 25, 28, 35, 30, 26, 31,\n       41, 36, 26, 35, 33, 28, 27, 34, 27, 22)\nlength(y)  \n#&gt; [1] 30\n\nFunzioni a priori, verosimiglianza e posteriori.\n\n# Prior: Normal(30, 5^2)\nprior &lt;- function(mu) {\n  dnorm(mu, mean = 30, sd = 5)\n}\n\n# Likelihood: Normal(mu, sigma^2), sigma stimato dai dati\nlikelihood &lt;- function(mu, data) {\n  sigma &lt;- sd(data)\n  prod(dnorm(data, mean = mu, sd = sigma))\n}\n\n# Posterior non normalizzata\nposterior &lt;- function(mu, data) {\n  likelihood(mu, data) * prior(mu)\n}\n\nAlgoritmo di Metropolis.\n\nmetropolis_for_normal &lt;- function(nsamp, xinit, data) {\n  samples &lt;- numeric(nsamp)\n  x_prev &lt;- xinit\n  \n  for (i in seq_len(nsamp)) {\n    x_star &lt;- rnorm(1, mean = x_prev, sd = 0.5)  # proposta\n    if (runif(1) &lt; min(1, posterior(x_star, data) / posterior(x_prev, data))) {\n      x_prev &lt;- x_star\n    }\n    samples[i] &lt;- x_prev\n  }\n  samples\n}\n\nEsecuzione dell’algoritmo.\n\nset.seed(123)\nsamples &lt;- metropolis_for_normal(100000, mean(y), y)\n\nburnin &lt;- 50000\npost_samples &lt;- samples[-seq_len(burnin)]\n\nConfronto con la soluzione analitica.\nNel caso prior Normale e likelihood Normale con varianza nota, la posterior è ancora Normale:\n\n# Prior\nmu_prior &lt;- 30\nstd_prior &lt;- 5\nvar_prior &lt;- std_prior^2\n\n# Likelihood\nn &lt;- length(y)\nsum_y &lt;- sum(y)\nvar_data &lt;- var(y)\n\nmu_post &lt;- (mu_prior / var_prior + sum_y / var_data) / (1 / var_prior + n / var_data)\nvar_post &lt;- 1 / (1 / var_prior + n / var_data)\nstd_post &lt;- sqrt(var_post)\n\nc(mu_post, std_post)\n#&gt; [1] 30.882  1.173\n\nTrace Plot.\n\n# Trace plot\npost_samples |&gt; \n  tibble(Iteration = 1:length(post_samples), Mu = post_samples) |&gt; \n  ggplot(aes(x = Iteration, y = Mu)) +\n  geom_line() +\n  labs(title = \"Trace Plot (Post Burn-in)\", x = \"Iterazione\", y = expression(mu))\n\n\n\n\n\n\n\nIstogramma vs Posterior Analitica.\n\nx &lt;- seq(mu_post - 4 * std_post, mu_post + 4 * std_post, length.out = 1000)\ndens_teorica &lt;- dnorm(x, mean = mu_post, sd = std_post)\ncurva_teorica &lt;- tibble(x = x, y = dens_teorica)\n\npost_samples |&gt; \n  tibble(Mu = post_samples) |&gt; \n  ggplot(aes(x = Mu)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 30, fill = \"skyblue\", color = \"black\", alpha = 0.6) +\n  geom_line(data = curva_teorica, aes(x = x, y = y), color = \"red\", linewidth = 1) +\n  labs(title = \"Posterior: MCMC vs Analitica\", x = expression(mu), y = \"Densit\\u00e0\")\n\n\n\n\n\n\n\nCosa significa la distribuzione a posteriori?\nIn termini concreti, la distribuzione a posteriori rappresenta la nostra incertezza residua sul valore di \\(\\mu\\), la media dei punteggi BDI-II nella popolazione, dopo aver visto i dati. Per esempio, se calcoliamo che il 94% della distribuzione a posteriori cade tra 27.5 e 32.3, possiamo dire:\n\n“Date le nostre ipotesi iniziali e i dati osservati, c’è una probabilità del 94% che il vero valore medio della depressione nella popolazione stia tra 27.5 e 32.3”.\n\nQuesta è una affermazione probabilistica sul parametro, che è una caratteristica distintiva dell’inferenza bayesiana.\nQuesta distribuzione combina:\n\nle credenze precedenti (il prior),\ncon l’evidenza osservata (i dati).\n\nIl risultato è una distribuzione che riflette cosa sappiamo del parametro dopo aver osservato i dati, e può essere usata per ottenere medie, intervalli di credibilità, probabilità soggettive, ecc.\n\n\n\n\n\n\nPerché accettare anche campioni con densità più bassa?\n\n\n\nNell’algoritmo di Metropolis, a ogni passo si propone un nuovo valore di \\(\\theta\\). Se questo valore ha una densità a posteriori più alta, viene accettato.\nMa se ha una densità più bassa, viene comunque accettato con una certa probabilità.\nPerché farlo?\nPer evitare che la catena si “blocchi” in un massimo locale. Per esplorare anche le aree meno probabili, ma comunque possibili, della distribuzione.\nÈ un meccanismo simile a quello con cui gli esseri umani esplorano: ogni tanto vale la pena provare strade meno promettenti, per evitare di restare intrappolati. Accettare “mosse peggiori” è quindi un meccanismo di esplorazione utile a garantire che la catena possa visitare l’intero spazio dei parametri e convergere correttamente alla distribuzione desiderata.\n\n\n\n\n\n\n\n\nLarghezza della proposta: un equilibrio delicato\n\n\n\nNel Metropolis, il nuovo valore proposto viene scelto spostandosi dal valore corrente secondo una distribuzione normale:\n\\[\\theta_{new} \\sim \\mathcal{N}(\\theta_{attuale}, \\sigma).\\]\nIl parametro \\(\\sigma\\) controlla la distanza dei passi.\nSe \\(\\sigma\\) è:\n\nPiccolo → i passi sono molto corti:\n\nMolte proposte vengono accettate (alta accettazione),\nMa la catena esplora lentamente → i campioni sono fortemente autocorrelati.\n\n\nGrande → i passi sono molto lunghi:\n\nSi propongono salti drastici → molte proposte vengono rifiutate,\nLa catena si muove poco → anche in questo caso, esplorazione inefficiente.\n\n\n\n🎯 Obiettivo: trovare un compromesso ottimale.\n\nPer un parametro unidimensionale, si consiglia spesso un tasso di accettazione tra 40% e 50%.\nNegli esercizi puoi provare diversi valori di proposal_sigma e osservare il tasso di accettazione per imparare.\n\n\n\nRisultati.\n\nmean(post_samples)\n#&gt; [1] 30.87\nsd(post_samples)\n#&gt; [1] 1.152\nquantile(post_samples, probs = c(0.03, 0.97))\n#&gt;    3%   97% \n#&gt; 28.71 33.06\n\nValori teorici:\n\nmu_post  # media teorica\n#&gt; [1] 30.88\nqnorm(c(0.03, 0.97), mean = mu_post, sd = std_post)\n#&gt; [1] 28.68 33.09\n\nSpiegazione Didattica.\n\nLa media \\(\\mu\\) rappresenta il livello medio di depressione nella popolazione.\nIl prior rappresenta la nostra credenza iniziale (Normale con media 30).\nL’evidenza fornita dai dati modifica questa credenza.\nL’algoritmo di Metropolis permette di campionare da una distribuzione posterior anche senza conoscere la forma analitica.\nIl confronto tra distribuzione teorica e campioni MCMC mostra un ottimo accordo.\n\nConclusione.\nIn questo esercizio abbiamo:\n\nimplementato l’algoritmo di Metropolis per un caso con prior e likelihood Normali;\nstimato la media della distribuzione posterior;\nconfrontato i risultati con la soluzione analitica;\nverificato la coerenza dei campioni MCMC con la distribuzione teorica.\n\nQuesto mostra la potenza dell’approccio MCMC anche in situazioni dove la soluzione analitica sarebbe disponibile, e pone le basi per affrontare problemi più complessi.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/01_metropolis.html#informazioni-sullambiente-di-sviluppo",
    "title": "58  L’algoritmo di Metropolis-Hastings",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] cmdstanr_0.9.0   thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0\n#&gt;  [5] see_0.11.0       gridExtra_2.3    patchwork_1.3.0  bayesplot_1.12.0\n#&gt;  [9] psych_2.5.3      scales_1.4.0     markdown_2.0     knitr_1.50      \n#&gt; [13] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [17] purrr_1.0.4      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [21] ggplot2_3.5.2    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6         tensorA_0.36.2.1     xfun_0.52           \n#&gt;  [4] htmlwidgets_1.6.4    processx_3.8.6       lattice_0.22-7      \n#&gt;  [7] tzdb_0.5.0           vctrs_0.6.5          tools_4.5.0         \n#&gt; [10] ps_1.9.1             generics_0.1.4       parallel_4.5.0      \n#&gt; [13] pacman_0.5.1         R.oo_1.27.1          pkgconfig_2.0.3     \n#&gt; [16] data.table_1.17.2    checkmate_2.3.2      RColorBrewer_1.1-3  \n#&gt; [19] distributional_0.5.0 lifecycle_1.0.4      compiler_4.5.0      \n#&gt; [22] farver_2.1.2         mnormt_2.1.1         htmltools_0.5.8.1   \n#&gt; [25] pillar_1.10.2        R.utils_2.13.0       abind_1.4-8         \n#&gt; [28] nlme_3.1-168         posterior_1.6.1      tidyselect_1.2.1    \n#&gt; [31] digest_0.6.37        stringi_1.8.7        reshape2_1.4.4      \n#&gt; [34] labeling_0.4.3       rprojroot_2.0.4      fastmap_1.2.0       \n#&gt; [37] grid_4.5.0           cli_3.6.5            magrittr_2.0.3      \n#&gt; [40] withr_3.0.2          backports_1.5.0      timechange_0.3.0    \n#&gt; [43] rmarkdown_2.29       R.methodsS3_1.8.2    hms_1.1.3           \n#&gt; [46] evaluate_1.0.3       rlang_1.1.6          Rcpp_1.0.14         \n#&gt; [49] glue_1.8.0           rstudioapi_0.17.1    jsonlite_2.0.0      \n#&gt; [52] plyr_1.8.9           R6_2.6.1",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#bibliografia",
    "href": "chapters/mcmc/01_metropolis.html#bibliografia",
    "title": "58  L’algoritmo di Metropolis-Hastings",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBürkner, P.-C. (2024). The brms Book: Applied Bayesian Regression Modelling Using R and Stan (Early Draft). https://paulbuerkner.com/software/brms-book\n\n\nDuane, S., Kennedy, A. D., Pendleton, B. J., & Roweth, D. (1987). Hybrid monte carlo. Physics letters B, 195(2), 216–222.\n\n\nGeman, S., & Geman, D. (1984). Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images. IEEE Transactions on pattern analysis and machine intelligence, 6, 721–741.\n\n\nHanada, M., & Matsuura, S. (2022). MCMC from Scratch. Springer.\n\n\nHastings, W. K. (1970). Monte Carlo sampling methods using Markov chains and their applications. Biometrika, 57(1), 97–109.\n\n\nHoffman, M. D., Gelman, A., et al. (2014). The No-U-Turn sampler: adaptively setting path lengths in Hamiltonian Monte Carlo. Journal of Machine Learning Research, 15(1), 1593–1623.\n\n\nMetropolis, N., Rosenbluth, A. W., Rosenbluth, M. N., Teller, A. H., & Teller, E. (1953). Equation of state calculations by fast computing machines. The Journal of Chemical Physics, 21(6), 1087–1092.\n\n\nZetsche, U., Buerkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: biased or realistic? Journal of Abnormal Psychology, 128(7), 678–688.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html",
    "href": "chapters/mcmc/02_ppl.html",
    "title": "59  Linguaggi di programmazione probabilistici",
    "section": "",
    "text": "59.1 Cos’è la programmazione probabilistica\nLa programmazione probabilistica è un paradigma della programmazione informatica che consente di creare modelli e algoritmi capaci di gestire l’incertezza e la casualità. Combina i principi della teoria delle probabilità con la programmazione, permettendo di costruire sistemi in grado di ragionare su dati incerti e di prendere decisioni informate. Questo approccio consente di esprimere modelli complessi in modo naturale e intuitivo, facilitando il processo di inferenza bayesiana.\nLa programmazione probabilistica si colloca all’intersezione tra algoritmi di machine learning, statistica e linguaggi di programmazione. I suoi obiettivi principali sono semplificare il processo di inferenza e automatizzarlo.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html#perché-abbiamo-bisogno-della-programmazione-probabilistica",
    "href": "chapters/mcmc/02_ppl.html#perché-abbiamo-bisogno-della-programmazione-probabilistica",
    "title": "59  Linguaggi di programmazione probabilistici",
    "section": "59.2 Perché abbiamo bisogno della programmazione probabilistica?",
    "text": "59.2 Perché abbiamo bisogno della programmazione probabilistica?\nScrivere un proprio campionatore per l’inferenza bayesiana è un compito estremamente difficile. Richiede competenze matematiche avanzate e una profonda conoscenza degli algoritmi di campionamento (sia MCMC che approssimati). Inoltre, ci sono numerosi problemi potenziali legati alla stabilità numerica e ai costi computazionali. Questo significa che per riuscirci bisogna essere allo stesso tempo degli ottimi sviluppatori e degli esperti statistici.\nÈ però possibile delegare tutti questi compiti a un sistema che li automatizzi, permettendoci di concentrarci sulla risoluzione dei problemi scientifici.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html#linguaggi-di-programmazione-probabilistica-ppls",
    "href": "chapters/mcmc/02_ppl.html#linguaggi-di-programmazione-probabilistica-ppls",
    "title": "59  Linguaggi di programmazione probabilistici",
    "section": "59.3 Linguaggi di programmazione probabilistica (PPLs)",
    "text": "59.3 Linguaggi di programmazione probabilistica (PPLs)\nIn questa sezione esamineremo il panorama moderno dei linguaggi di programmazione probabilistica (PPLs) e, nella sezione successiva, esploreremo le funzionalità di uno di questi, Stan.\n\n59.3.1 Linguaggi di Programmazione Probabilistica (PPL)\nUn linguaggio di programmazione probabilistica (PPL) consente di formalizzare modelli bayesiani e di eseguire inferenze utilizzando algoritmi avanzati. L’utente deve semplicemente definire il modello, selezionare un campionatore e avviare il processo di inferenza.\nIn generale, le funzionalità fondamentali richieste a un PPL sono:\n\ngenerare valori casuali da distribuzioni probabilistiche;\ncondizionare variabili su dati osservati.\n\nI primi linguaggi di programmazione probabilistica, come BUGS e WinBUGS, hanno gettato le basi offrendo tre capacità essenziali:\n\nrandom: per definire variabili casuali.\nconstraint: per vincolare variabili ai dati osservati.\ninfer: per calcolare e restituire la distribuzione delle variabili di interesse.\n\nNel corso del tempo, l’elenco dei PPL disponibili si è notevolmente ampliato, comprendendo una vasta gamma di strumenti in continua evoluzione. Ecco alcuni esempi rappresentativi:\n\nBUGS, WinBUGS, JAGS\nStan\nPyMC3, PyMC4, PyMC\nNimble\nPyro, NumPyro\nEdward, TensorFlow Probability, Edward 2\nGen\nTuring\nStheno\nSOSS\nOmega\nInfer.NET",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html#come-scegliere-un-ppl",
    "href": "chapters/mcmc/02_ppl.html#come-scegliere-un-ppl",
    "title": "59  Linguaggi di programmazione probabilistici",
    "section": "59.4 Come scegliere un PPL?",
    "text": "59.4 Come scegliere un PPL?\nDal punto di vista pratico, come si può decidere quale linguaggio di programmazione probabilistica utilizzare? Ecco alcuni fattori chiave da considerare:\n\nDocumentazione: La presenza di risorse ben strutturate, come guide, tutorial e documentazione ufficiale, è essenziale per facilitare l’apprendimento e migliorare la produttività. Un PPL con documentazione chiara e completa è sempre preferibile, specialmente per chi è alle prime armi.\nPerformance: Alcuni PPL sono ottimizzati per offrire prestazioni superiori, ad esempio mediante l’elaborazione parallela o l’uso di acceleratori hardware come le GPU. Valuta le prestazioni in relazione alla complessità e alla scala dei modelli che desideri costruire.\nFunzionalità: È importante verificare se il PPL offre un’ampia gamma di distribuzioni probabilistiche e campionatori, oltre a strumenti avanzati per personalizzare i modelli e implementare inferenze specifiche.\nSupporto della comunità: Una comunità attiva può fare la differenza quando incontri difficoltà. Forum, gruppi di discussione e risorse condivise dagli utenti (come esempi pratici o risposte a domande frequenti) sono fondamentali per risolvere problemi in modo rapido e imparare dalle esperienze di altri.\nIntegrazione: Considera quanto bene il PPL si integra con gli strumenti e i framework già in uso. Per esempio, se utilizzi librerie per la manipolazione dei dati, la visualizzazione o il machine learning, come pandas, ggplot o TensorFlow, verifica che il PPL scelto supporti queste interazioni senza complicazioni.\n\n\n59.4.1 API\nI linguaggi di programmazione probabilistica (PPL) permettono agli utenti di definire con precisione le caratteristiche dei priori, della verosimiglianza e dell’intero modello bayesiano. Inoltre, offrono strumenti per effettuare le necessarie trasformazioni sui dati, garantendo la flessibilità richiesta per affrontare una vasta gamma di problemi statistici. Tuttavia, anche se i PPL cercano di semplificare queste operazioni, l’utente deve comunque scrivere codice che rispetti i vincoli sintattici e logici specifici del linguaggio. Questo richiede non solo competenze di programmazione, ma anche una buona conoscenza dei principi statistici e bayesiani.\nPer venire incontro a utenti che desiderano utilizzare l’inferenza bayesiana senza doversi addentrare nella programmazione, sono state sviluppate interfacce di alto livello. Queste interfacce permettono di specificare modelli statistici comuni in modo intuitivo, utilizzando una sintassi semplificata. Sebbene offrano meno controllo sui dettagli tecnici del modello, garantiscono comunque la possibilità di personalizzare elementi cruciali, come i priori e la verosimiglianza, rendendo l’inferenza bayesiana accessibile anche a chi non ha competenze di programmazione.\n\n\n59.4.2 Principali Interfacce di Alto Livello\nTra le interfacce più popolari troviamo:\n\nbrms: utilizza Stan come motore sottostante per eseguire l’inferenza.\nBambi: si basa su PyMC per eseguire l’inferenza bayesiana.\n\nEntrambe queste librerie adottano una sintassi semplificata, nota come sintassi di Wilkinson (Wilkinson & Rogers, 1973). Questo approccio consente di specificare modelli in modo dichiarativo, usando una struttura simile a quella adottata da pacchetti R come lm (per modelli di regressione lineare) o lme4 (per modelli multilivello con lmer).\nAd esempio, in brms è possibile specificare un modello di regressione lineare con una sintassi simile a questa:\nfit &lt;- brm(y ~ x1 + x2, data = dataset)\nIn questo esempio y ~ x1 + x2 definisce la relazione tra la variabile dipendente (y) e le variabili indipendenti (x1 e x2).\n\n\n59.4.3 Vantaggi delle Interfacce di Alto Livello\n\nAccessibilità: Riduzione della complessità sintattica, rendendo l’inferenza bayesiana più accessibile a un pubblico più ampio, inclusi studenti e ricercatori con competenze di programmazione limitate.\nFlessibilità: Sebbene più semplici, le interfacce consentono di specificare prior distribuiti in modo personalizzato e di modificare molteplici aspetti del modello.\nEfficienza: Automatizzano molti passaggi tecnici, permettendo di concentrarsi sulla definizione del modello e sull’interpretazione dei risultati.\nCompatibilità: Integrazione con strumenti statistici familiari, come il framework di modelli lineari in R.\n\nIn questo corso, utilizzeremo principalmente brms per specificare e stimare modelli di regressione lineare e multilivello, sfruttandone la sintassi intuitiva e l’integrazione con R. Negli approfondimenti, invece, esploreremo come scrivere direttamente modelli in Stan, per comprendere meglio le basi dei PPL e avere maggiore controllo sui dettagli tecnici.\nQuesta combinazione ci permetterà di bilanciare semplicità e potenza, rendendo l’inferenza bayesiana sia accessibile che personalizzabile, a seconda delle esigenze specifiche del progetto o dell’analisi.\n\n\n59.4.4 Introduzione alla sintassi di Wilkinson\nLa sintassi di Wilkinson in R fornisce un modo semplice ed efficace per specificare modelli di regressione lineare, consentendo di descrivere relazioni tra una variabile dipendente (risposta) e una o più variabili indipendenti (predittori) utilizzando una notazione simbolica. Questa sintassi si allinea direttamente al modello matematico, rendendo immediata la corrispondenza tra i termini simbolici e il codice.\n\n59.4.4.1 Modello simbolico e modello Wilkinson\nSupponiamo di voler specificare un modello di regressione lineare multipla con la seguente formula:\n\\[\ny_i = \\alpha + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\varepsilon_i ,\n\\]\ndove:\n\n\\(y_i\\) è la variabile dipendente per l’osservazione \\(i\\),\n\\(\\alpha\\) è l’intercetta,\n\\(\\beta_1\\) e \\(\\beta_2\\) sono i coefficienti di regressione per i predittori \\(x_1\\) e \\(x_2\\),\n\\(\\varepsilon_i\\) rappresenta l’errore residuo, normalmente distribuito (\\(\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma^2)\\)).\n\nIn R, questo modello può essere specificato con la sintassi Wilkinson:\ny ~ x1 + x2\n\n\n59.4.4.2 Dettaglio dei componenti\n\nIntercetta implicita:\nLa sintassi R include automaticamente l’intercetta (\\(\\alpha\\)) quando si utilizza il simbolo +. Ad esempio:\ny ~ x1 + x2\nequivale al modello: \\[\ny_i = \\alpha + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\varepsilon_i\n\\]\nEsclusione dell’intercetta:\nSe si desidera escludere l’intercetta (\\(\\alpha\\)), si utilizza - 1 nella specifica:\ny ~ x1 + x2 - 1\nQuesto produce un modello senza intercetta: \\[\ny_i = \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\varepsilon_i\n\\]\nInclusione esplicita dell’intercetta:\nAnche se è implicita, l’intercetta può essere specificata esplicitamente con 1 +:\ny ~ 1 + x1 + x2\nQuesto è equivalente al modello con intercetta implicita.\nInterazione tra predittori:\nLa sintassi Wilkinson consente anche di specificare interazioni. Ad esempio, un’interazione tra \\(x_1\\) e \\(x_2\\):\ny ~ x1 * x2\nEspande automaticamente il modello per includere: \\[\ny_i = \\alpha + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\beta_3 (x_{1i} \\cdot x_{2i}) + \\varepsilon_i\n\\]\n\n\n\n59.4.4.3 Esempio pratico\nSupponiamo di avere un dataset con una variabile dipendente y e due predittori x1 e x2. Ecco come specificare e adattare un modello di regressione lineare multipla in R:\n# Specifica del modello\nmodello &lt;- lm(y ~ x1 + x2, data = dataset)\n\n# Sommario del modello\nsummary(modello)\nQuesto codice:\n\nSpecifica un modello con intercetta e due predittori.\nAdatta il modello ai dati contenuti in dataset.\nCalcola i coefficienti (\\(\\alpha, \\beta_1, \\beta_2\\)), i valori di errore standard, i p-value (frequentisti) e altre statistiche di sintesi.\n\nIn sintesi, la sintassi di Wilkinson in R permette di esprimere modelli di regressione lineare in modo conciso e leggibile, rendendo il passaggio dal modello matematico al codice intuitivo e diretto.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html#riflessioni-conclusive",
    "href": "chapters/mcmc/02_ppl.html#riflessioni-conclusive",
    "title": "59  Linguaggi di programmazione probabilistici",
    "section": "59.5 Riflessioni Conclusive",
    "text": "59.5 Riflessioni Conclusive\nI linguaggi di programmazione probabilistica (PPL) rappresentano strumenti potenti per la specificazione completa e flessibile di modelli bayesiani, consentendo agli utenti di definire ogni aspetto del modello, dai priori alla verosimiglianza, fino agli algoritmi di inferenza. Strumenti come Stan e PyMC permettono un controllo dettagliato sui modelli, rendendoli ideali per analisi avanzate e progetti personalizzati.\nTuttavia, questo livello di controllo richiede competenze di programmazione e una comprensione approfondita della statistica bayesiana. Per superare queste barriere e rendere l’inferenza bayesiana accessibile a un pubblico più ampio, sono state sviluppate interfacce di alto livello come brms (basata su Stan) e Bambi (basata su PyMC). Questi strumenti semplificano enormemente il processo, consentendo agli utenti di specificare modelli statistici complessi senza la necessità di scrivere codice dettagliato, grazie a una sintassi intuitiva come quella di Wilkinson.\nIn sintesi:\n\nI PPL offrono flessibilità massima e un controllo completo, ma richiedono esperienza nella programmazione.\nLe interfacce di alto livello rendono possibile l’inferenza bayesiana anche a chi preferisce evitare la programmazione, garantendo un compromesso tra semplicità e capacità di personalizzazione.\n\nLa scelta tra un PPL e un’interfaccia di alto livello dipende quindi dalle esigenze specifiche: chi necessita di modelli estremamente personalizzati e complessi opterà per un PPL come Stan o PyMC, mentre chi desidera facilità d’uso senza rinunciare alla potenza dell’inferenza bayesiana troverà in brms o Bambi strumenti ideali. In ogni caso, la crescente disponibilità di strumenti e risorse rende oggi l’inferenza bayesiana più accessibile che mai, anche per chi non ha un background tecnico avanzato.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html#bibliografia",
    "href": "chapters/mcmc/02_ppl.html#bibliografia",
    "title": "59  Linguaggi di programmazione probabilistici",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nWilkinson, G., & Rogers, C. (1973). Symbolic description of factorial models for analysis of variance. Journal of the Royal Statistical Society Series C: Applied Statistics, 22(3), 392–399.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html",
    "href": "chapters/mcmc/07_bayesian_workflow.html",
    "title": "60  Flusso di lavoro bayesiano",
    "section": "",
    "text": "60.1 Introduzione\nL’applicazione dell’inferenza bayesiana nella risoluzione di problemi reali richiede un approccio strutturato e multidisciplinare, noto come workflow bayesiano. Questo processo iterativo e complesso va ben oltre la semplice applicazione della regola di Bayes, che pur costituendo il fondamento teorico dell’inferenza bayesiana, rappresenta solo il punto di partenza di un percorso analitico più articolato.\nIl workflow bayesiano include molteplici fasi interconnesse, tra cui:\nPer esempio, immaginiamo di voler valutare l’efficacia di un intervento psicologico. Il ricercatore deve affrontare diverse decisioni: quali variabili includere (covariate), come modellare i dati gerarchici (ad esempio, individui e gruppi), e quali distribuzioni utilizzare per rappresentare incertezze (priori). Queste decisioni, lungi dall’essere definitive, richiedono continui aggiustamenti basati sui risultati intermedi.\nUn ulteriore aspetto critico è la gestione di possibili problemi computazionali. Ad esempio, il campionamento MCMC (Markov Chain Monte Carlo) potrebbe non convergere correttamente, richiedendo modifiche al modello o all’approccio algoritmico. Inoltre, il workflow bayesiano non si limita alla stima dei parametri: include la valutazione della capacità del modello di fare previsioni attendibili e il confronto tra modelli alternativi.\nInfine, è fondamentale bilanciare la complessità del modello con la rilevanza pratica dei risultati. Modelli troppo semplici possono portare a conclusioni distorte, mentre modelli troppo complessi possono diventare difficili da interpretare. Il workflow bayesiano aiuta i ricercatori a navigare queste sfide, fornendo un quadro metodologico flessibile e iterativo.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#introduzione",
    "href": "chapters/mcmc/07_bayesian_workflow.html#introduzione",
    "title": "60  Flusso di lavoro bayesiano",
    "section": "",
    "text": "Costruzione iterativa del modello: Definizione e revisione di modelli probabilistici che rappresentano i processi generativi dei dati.\nVerifica e validazione: Controllo della qualità delle stime e valutazione delle capacità predittive del modello.\nRisultati e interpretazione: Confronto tra modelli alternativi per trarre conclusioni solide.\nGestione di problemi computazionali: Identificazione e soluzione di eventuali difficoltà nell’adattamento del modello.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#principi-del-workflow-bayesiano",
    "href": "chapters/mcmc/07_bayesian_workflow.html#principi-del-workflow-bayesiano",
    "title": "60  Flusso di lavoro bayesiano",
    "section": "60.2 Principi del workflow bayesiano",
    "text": "60.2 Principi del workflow bayesiano\nUn workflow è una sequenza strutturata di passi che definisce cosa costituisce una “buona pratica” in un determinato ambito. Nel contesto dell’inferenza bayesiana, il workflow si ispira a concetti come il Ciclo di Box e le più recenti estensioni proposte da studiosi come Gelman e Riha.\n\n60.2.1 Il Ciclo di Box\nGeorge Box, uno dei pionieri della statistica moderna, ha sviluppato negli anni ’60 un approccio ciclico alla modellizzazione statistica, noto come Ciclo di Box. Questo paradigma sottolinea che la modellizzazione non è un processo lineare, ma un ciclo continuo di miglioramento.\n\n\n\nFigura tratta da Blei (2014).\n\n\nIl Ciclo di Box si articola in una serie di fasi iterative:\n\nFormulazione del modello: Si costruisce un modello basato sulle conoscenze disponibili e sui dati osservati.\nInferenza: Si stimano i parametri del modello e si valutano le incertezze associate.\nValutazione del modello: Si verifica quanto il modello si adatta ai dati.\nRevisione del modello: Si corregge il modello in base alle discrepanze identificate.\n\nQuesto approccio iterativo è il cuore del workflow bayesiano. La capacità dell’inferenza bayesiana di aggiornare le credenze a priori alla luce di nuovi dati lo rende particolarmente adatto a essere integrato nel Ciclo di Box. Più recentemente, Gelman et al. (2020) hanno proposto una versione estesa del Ciclo di Box, fornendo una guida dettagliata per implementare un workflow bayesiano completo.\n\n\n\nFigura tratta da Gelman et al. (2020).",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#costruzione-iterativa-del-modello",
    "href": "chapters/mcmc/07_bayesian_workflow.html#costruzione-iterativa-del-modello",
    "title": "60  Flusso di lavoro bayesiano",
    "section": "60.3 Costruzione iterativa del modello",
    "text": "60.3 Costruzione iterativa del modello\nIl processo di costruzione di un modello bayesiano può essere descritto attraverso i seguenti passaggi:\n\nComprensione del fenomeno e formulazione del problema: Il punto di partenza è definire chiaramente la domanda di ricerca. L’obiettivo non è semplicemente descrivere correlazioni tra variabili, ma comprendere i meccanismi generativi dei dati.\nFormulazione matematica: Si costruisce un modello probabilistico che rappresenti il processo generativo, spesso utilizzando linguaggi probabilistici (PPL) come Stan o PyMC.\nImplementazione: Il modello viene tradotto in codice utilizzando interfacce software come R, Python o Julia, che permettono di adattare modelli complessi ai dati.\nVerifiche predittive a priori: Si simulano dati basandosi sulle distribuzioni a priori per verificare che i parametri scelti siano ragionevoli.\nAdattamento del modello: Si utilizza un algoritmo di campionamento per stimare i parametri del modello dai dati osservati (ad esempio, cmdstanr o cmdstanpy).\nDiagnostiche di convergenza: Si verifica che le catene MCMC abbiano raggiunto la convergenza, utilizzando strumenti come il valore R-hat.\nVerifiche predittive a posteriori: Si generano dati simulati a partire dalla distribuzione a posteriori per confrontarli con i dati reali e valutare la bontà del modello.\nIterazione: Sulla base dei risultati, il modello viene raffinato e migliorato.\n\nQuesto processo iterativo consente di costruire modelli che siano sia robusti sia interpretabili.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#analisi-multiverso",
    "href": "chapters/mcmc/07_bayesian_workflow.html#analisi-multiverso",
    "title": "60  Flusso di lavoro bayesiano",
    "section": "60.4 Analisi Multiverso",
    "text": "60.4 Analisi Multiverso\nL’analisi multiverso, introdotta recentemente (Riha et al., 2024), amplia il workflow bayesiano, permettendo di esplorare simultaneamente molteplici modelli alternativi. Ogni modello rappresenta una combinazione unica di scelte modellistiche (ad esempio, covariate, distribuzioni a priori, o assunzioni sul processo generativo).\nI vantaggi principali dell’analisi multiverso includono:\n\nTrasparenza: Documenta tutte le scelte di modellizzazione.\nEsplorazione completa: Riduce il rischio di trascurare ipotesi rilevanti.\nConfronto diretto: Permette di identificare i modelli più adatti basandosi su criteri come l’Expected Log-Predictive Density (ELPD).\nRobustezza: Esamina come le conclusioni cambiano tra diversi modelli.\nReplicabilità: Fornisce informazioni dettagliate per riprodurre l’analisi e i risultati.\n\nQuesto approccio incorpora anche verifiche computazionali e analisi di sensibilità. Le prime identificano i modelli che necessitano di ulteriori verifiche per garantire l’affidabilità dei risultati, mentre le seconde esaminano la robustezza delle conclusioni rispetto alle diverse scelte di modellazione e all’influenza delle priori sulle stime posteriori.\nTuttavia, la generazione di numerosi modelli può complicare la gestione e l’interpretazione dei risultati. Per affrontare questa sfida, Riha et al. (2024) propongono un metodo di “iterative filtering” che comprende:\n\nCreazione di un multiverso iniziale di modelli.\nValutazione delle capacità predittive attraverso controlli predittivi posteriori (PPC) e calcolo dell’expected log point-wise predictive density (elpd).\nVerifica della qualità computazionale, esaminando convergenza ed efficienza del campionamento MCMC.\nFiltraggio iterativo basato su criteri di qualità predefiniti.\nPossibilità di estendere il multiverso e ripetere il processo.\n\nQuesto approccio mantiene i vantaggi della multiverse analysis riducendo al contempo la complessità attraverso un filtraggio sistematico. Il risultato è un workflow bayesiano più robusto e informativo, che bilancia la necessità di considerare molteplici ipotesi modellistiche con l’esigenza pratica di focalizzarsi sui modelli più promettenti per il problema in esame.\nUno dei casi di studio esaminati da Riha et al. (2024) riguarda l’analisi del numero di crisi epilettiche in relazione a diverse variabili (covariate) e scelte di modellazione. I dati utilizzati provengono dallo studio di Leppik et al. (1987) e sono disponibili nel pacchetto R brms.\nSono stati confrontati 24 modelli statistici, ciascuno con una specifica formulazione matematica (illustrata nella Tabella seguente). La scelta dei modelli ha riguardato diverse combinazioni di covariate e di distribuzioni di probabilità per descrivere il fenomeno in esame.\n\n\n\nTabella 1 ricavata da Riha et al. (2024).\n\n\nPer valutare la capacità predittiva dei modelli, è stato utilizzato il criterio ELPD (Expected Log-Predictive Density). I risultati sono riportati nel grafico seguente.\n\n\n\nFigura 12 ricavata da Riha et al. (2024).\n\n\nCome si può osservare, i modelli presentano performance predittive differenti.\nOltre all’ELPD, sono stati condotti controlli predittivi posteriori (PPC) per valutare la plausibilità dei modelli rispetto ai dati osservati. I risultati dei PPC sono visualizzati nella figura seguente.\n\n\n\nFigura 13 ricavata da Riha et al. (2024).\n\n\nIl modello selezionato è quello che ha mostrato il miglior valore di ELPD, evidenziando una buona capacità predittiva. Inoltre, i controlli PPC hanno confermato la plausibilità del modello rispetto ai dati osservati. Infine, il modello selezionato non ha presentato problemi computazionali durante la stima dei parametri.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#riflessioni-conclusive",
    "href": "chapters/mcmc/07_bayesian_workflow.html#riflessioni-conclusive",
    "title": "60  Flusso di lavoro bayesiano",
    "section": "60.5 Riflessioni Conclusive",
    "text": "60.5 Riflessioni Conclusive\nIl workflow bayesiano rappresenta una strategia strutturata e iterativa per affrontare l’analisi dei dati complessi. Attraverso strumenti come le verifiche predittive e l’analisi multiverso, consente di sviluppare modelli solidi e capaci di adattarsi a nuovi dati e conoscenze. La sua integrazione con linguaggi come Stan o PyMC ne facilita l’applicazione, rendendolo un approccio essenziale per la ricerca moderna.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#bibliografia",
    "href": "chapters/mcmc/07_bayesian_workflow.html#bibliografia",
    "title": "60  Flusso di lavoro bayesiano",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlei, D. M. (2014). Build, compute, critique, repeat: Data analysis with latent variable models. Annual Review of Statistics and Its Application, 1(1), 203–232.\n\n\nBulbulia, J. A. (2023). A workflow for causal inference in cross-cultural psychology. Religion, Brain & Behavior, 13(3), 291–306.\n\n\nGelman, A., Vehtari, A., Simpson, D., Margossian, C. C., Carpenter, B., Yao, Y., Kennedy, L., Gabry, J., Bürkner, P.-C., & Modrák, M. (2020). Bayesian workflow. arXiv preprint arXiv:2011.01808.\n\n\nLeppik, I., Dreifuss, F., Porter, R., Bowman, T., Santilli, N., Jacobs, M., Crosby, C., Cloyd, J., Stackman, J., Graves, N., et al. (1987). A controlled study of progabide in partial seizures: methodology and results. Neurology, 37(6), 963–963.\n\n\nRiha, A. E., Siccha, N., Oulasvirta, A., & Vehtari, A. (2024). Supporting Bayesian modelling workflows with iterative filtering for multiverse analysis. arXiv preprint arXiv:2404.01688.\n\n\nSteegen, S., Tuerlinckx, F., Gelman, A., & Vanpaemel, W. (2016). Increasing transparency through a multiverse analysis. Perspectives on Psychological Science, 11(5), 702–712.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/introduction_linear_models.html",
    "href": "chapters/linear_models/introduction_linear_models.html",
    "title": "Introduzione",
    "section": "",
    "text": "Gli obiettivi di questo insegnamento riguardano i casi più semplici di inferenza statistica, cioè l’inferenza su una singola media, la differenza tra due medie, e l’analisi del modello di regressione lineare (bivariato e multiplo) con predittori sia quantitativi sia qualitativi.\nTradizionalmente, l’inferenza su una media o sulla differenza tra due medie viene affrontata tramite il test t di Student, in un’ottica frequentista. In una prospettiva più moderna, tuttavia, questi argomenti possono essere inquadrati nel framework generale del modello lineare. Di conseguenza, in questa sezione della dispensa presenteremo il modello lineare sia dal punto di vista bayesiano sia frequentista, mostrando come l’inferenza su una o due medie rappresenti in realtà un caso particolare di questo impianto metodologico.",
    "crumbs": [
      "Regressione",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html",
    "href": "chapters/linear_models/01_reglin_frequentist.html",
    "title": "61  La regressione lineare bivariata: un approccio frequentista",
    "section": "",
    "text": "61.1 Introduzione\nLa regressione è una tecnica statistica che permette ai ricercatori di analizzare come i valori medi di una variabile risultato (o variabile dipendente) cambiano in relazione a un insieme di predittori (variabili indipendenti).\nSecondo Gelman et al. (2021), i principali utilizzi della regressione includono:\nIn tutti questi contesti, è essenziale che il modello includa tutte le variabili rilevanti per la variabile di interesse. Ad esempio, in uno studio sull’efficacia di una psicoterapia per la depressione, fattori come età, condizioni di salute preesistenti e supporto sociale possono influenzare significativamente i risultati e devono essere integrati nell’analisi. La trascuratezza di tali variabili può distorto le relazioni stimate tra predittori e risultato. L’accuratezza dei modelli di regressione dipende quindi sia dalla completezza del modello che dalla selezione mirata delle informazioni incluse.\nUn problema critico legato a questa scelta è il cosiddetto “errore di specificazione”, che si verifica quando uno o più predittori rilevanti vengono omessi dal modello. Questo porta a stime sistematicamente errate, compromettendo la validità delle conclusioni tratte. Approfondiremo questo concetto in seguito, esaminando le implicazioni pratiche e strategie per evitarlo.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#introduzione",
    "href": "chapters/linear_models/01_reglin_frequentist.html#introduzione",
    "title": "61  La regressione lineare bivariata: un approccio frequentista",
    "section": "",
    "text": "Previsione – Modellare dati esistenti o prevedere nuove osservazioni, sia continue che categoriche.\n\n\nEsempi: Prevedere punteggi futuri in un test, monitorare il benessere psicologico in uno studio longitudinale o classificare individui in base alla probabilità di successo in un compito cognitivo.\n\n\n\nEsplorazione delle associazioni – Identificare e quantificare le relazioni tra una o più variabili indipendenti e un risultato.\n\n\nEsempi: Analizzare i tratti di personalità legati alla resilienza allo stress, indagare la correlazione tra stili di attaccamento infantile e capacità relazionali in età adulta, o valutare l’influenza di fattori socio-economici sullo sviluppo cognitivo nei bambini.\n\n\n\nEstrapolazione – Estendere i risultati osservati in un campione a una popolazione più ampia.\n\n\nEsempi: Stimare l’efficacia di una terapia testata su studenti universitari alla popolazione generale, oppure prevedere l’impatto di un intervento scolastico su un intero distretto partendo dai dati di alcune scuole pilota.\n\n\n\nInferenza causale – Analizzare gli effetti di un trattamento o intervento, purché supportata da un disegno sperimentale adeguato.\n\n\nEsempi: Valutare l’efficacia di un programma di mindfulness sui livelli di ansia, stimare l’impatto di una psicoterapia per il disturbo post-traumatico da stress o determinare l’effetto di un intervento educativo su una popolazione diversificata.\n\n\n\n\n\n\n61.1.1 La storia dei modelli lineari\nI modelli lineari hanno una lunga storia nella statistica. Come riportato da Stigler (1986), il metodo dei minimi quadrati per adattare un modello di regressione lineare bivariata fu introdotto nel XVIII secolo per l’analisi dei dati astronomici. Gli astronomi lo utilizzavano, ad esempio, per determinare il moto della Luna o per modellare i movimenti non periodici di Giove e Saturno.\nL’adozione di questi metodi fu favorita dalla qualità e dall’omogeneità delle misurazioni astronomiche, raccolte con strumenti standardizzati e sotto condizioni controllate. Al contrario, nelle scienze sociali, l’elevata variabilità dei dati—derivante da differenze individuali, contesti mutevoli e strumenti di misura meno precisi—rese più complessa l’applicazione della regressione e ne ritardò la diffusione. Solo con lo sviluppo di tecniche statistiche più avanzate, capaci di gestire questa complessità, la regressione divenne uno strumento essenziale anche nelle scienze umane e sociali.\n\n61.1.2 Tipologie di regressione\nÈ utile distinguere tra tre principali categorie di regressione:\n\n\nRegressione bivariata – Un solo predittore e una sola variabile dipendente.\n\n\nRegressione multipla – Un solo risultato ma molteplici predittori.\n\n\nRegressione multivariata – Molteplici risultati, con uno o più predittori.\n\nIl caso bivariato, pur essendo il più semplice, è raramente sufficiente per descrivere fenomeni complessi, soprattutto in psicologia, dove molteplici fattori influenzano le variabili di interesse. Tuttavia, lo analizzeremo in dettaglio perché permette di comprendere la logica dell’analisi di regressione in un contesto semplificato, privo di complicazioni matematiche. I concetti appresi saranno poi estesi ai modelli più complessi, in cui la regressione multipla e la regressione multivariata richiederanno calcoli più articolati e un’interpretazione più sofisticata dei parametri.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#il-modello-lineare-bivariato",
    "href": "chapters/linear_models/01_reglin_frequentist.html#il-modello-lineare-bivariato",
    "title": "61  La regressione lineare bivariata: un approccio frequentista",
    "section": "\n61.2 Il modello lineare bivariato",
    "text": "61.2 Il modello lineare bivariato\nNel contesto frequentista, il modello di regressione lineare bivariata consente di predire una variabile continua \\(y\\) sulla base di un singolo predittore continuo \\(x\\). La relazione tra le due variabili è espressa dall’equazione della retta di regressione:\n\\[\ny_i = a + b x_i + e_i, \\quad i = 1, \\dots, n\n\\]\ndove:\n\n\n\\(a\\) è l’intercetta (il valore atteso di \\(y\\) quando \\(x = 0\\)),\n\n\\(b\\) è la pendenza della retta (coefficiente di regressione, che misura il cambiamento atteso in \\(y\\) per ogni unità di incremento in \\(x\\)),\n\n\\(e_i\\) è l’errore residuo (la differenza tra il valore osservato di \\(y_i\\) e il valore predetto dal modello).\n\n\n61.2.1 Aspetti principali\n\nStima dei coefficienti\nI coefficienti \\(a\\) e \\(b\\) vengono stimati mediante il metodo dei minimi quadrati, che minimizza la somma dei quadrati degli errori residui (\\(\\sum e_i^2\\)).\n\nInterpretazione dei coefficienti\n\n\n\\(a\\): rappresenta il valore medio previsto di \\(y\\) quando \\(x = 0\\).\n\n\n\\(b\\): indica la variazione media prevista in \\(y\\) per ogni unità di variazione in \\(x\\).\n\n\n\nValutazione del modello\nLa bontà di adattamento del modello viene valutata attraverso:\n\nL’indice di determinazione (\\(R^2\\)), che misura la proporzione della varianza di \\(y\\) spiegata dal modello.\nL’analisi dei residui, utile per individuare pattern non catturati dal modello e diagnosticare eventuali problemi.\n\n\n\n61.2.2 Verso modelli più complessi\nQuesto capitolo illustrerà come applicare e interpretare il modello di regressione bivariata, fornendo una base per comprendere il modello lineare multiplo e, più in generale, gli approcci avanzati per l’inferenza causale. La logica della regressione bivariata sarà estesa ai modelli con più predittori, dove sarà fondamentale distinguere tra relazioni spurie e reali effetti predittivi.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#la-predizione-dellintelligenza",
    "href": "chapters/linear_models/01_reglin_frequentist.html#la-predizione-dellintelligenza",
    "title": "61  La regressione lineare bivariata: un approccio frequentista",
    "section": "\n61.3 La Predizione dell’Intelligenza",
    "text": "61.3 La Predizione dell’Intelligenza\nNella presente discussione, esamineremo i dati kidiq che consistono in una raccolta di dati provenienti da un sondaggio su donne adulte americane e i loro figli, selezionati da un sotto-campione del National Longitudinal Survey of Youth (Gelman et al., 2021).\nNello specifico, ci concentreremo sulla relazione tra il punteggio di intelligenza del bambino (kid_score) e quello della madre (mom_iq). Ci proponiamo di valutare se e in quale misura l’intelligenza della madre possa prevedere l’intelligenza del bambino. Per fare ciò, inizieremo ad importare i dati nell’ambiente R.\n\n# Caricamento dei dati\nkidiq &lt;- rio::import(here::here(\"data\", \"kidiq.dta\"))\n\n\n# Anteprima dei dati\nhead(kidiq)\n#&gt;   kid_score mom_hs mom_iq mom_work mom_age\n#&gt; 1        65      1 121.12        4      27\n#&gt; 2        98      1  89.36        4      25\n#&gt; 3        85      1 115.44        4      27\n#&gt; 4        83      1  99.45        3      25\n#&gt; 5       115      1  92.75        4      27\n#&gt; 6        98      0 107.90        1      18\n\nUn diagramma a dispersione per i dati di questo campione suggerisce la presenza di un’associazione positiva tra l’intelligenza del bambino (kid_score) e l’intelligenza della madre (mom_iq).\n\nggplot(kidiq, aes(x = mom_iq, y = kid_score)) +\n  geom_point(alpha = 0.6) +\n  labs(x = \"QI della madre\", y = \"QI del bambino\") +\n  ggtitle(\"Diagramma a dispersione\")",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#stima-del-modello-di-regressione-lineare",
    "href": "chapters/linear_models/01_reglin_frequentist.html#stima-del-modello-di-regressione-lineare",
    "title": "61  La regressione lineare bivariata: un approccio frequentista",
    "section": "\n61.4 Stima del modello di regressione lineare",
    "text": "61.4 Stima del modello di regressione lineare\nCalcoliamo i coefficienti della retta di regressione utilizzando la funzione lm.\n\n# Modello di regressione lineare\nmod &lt;- lm(kid_score ~ mom_iq, data = kidiq)\n\n\n# Coefficienti stimati\ncoef(mod)\n#&gt; (Intercept)      mom_iq \n#&gt;       25.80        0.61\n\nCi sono però infinite rette che, in linea di principio, possono essere usate per “approssimare” la nube di punti nel diagramma a dispersione. È dunque necessario introdurre dei vincoli per selezionare una di queste possibili rette. Il vincolo che viene introdotto dal modello di regressione è quello di costringere la retta a passare per il punto \\((\\bar{x}, \\bar{y})\\).\n\n# Calcola le medie per mom_iq e kid_score\nmean_x &lt;- mean(kidiq$mom_iq, na.rm = TRUE)\nmean_y &lt;- mean(kidiq$kid_score, na.rm = TRUE)\n\n# Aggiungi il punto medio al grafico\nggplot(kidiq, aes(x = mom_iq, y = kid_score)) +\n  geom_point(alpha = 0.6) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"blue\") +\n  annotate(\n    \"point\", x = mean_x, y = mean_y, color = \"red\", size = 5, \n    shape = 4, stroke = 3) +\n  labs(x = \"QI della madre\", y = \"QI del bambino\") +\n  ggtitle(\"Retta di regressione\")\n\n\n\n\n\n\n\nUna retta di regressione che passa per il punto medio \\((\\bar{x}, \\bar{y})\\) (che rappresenta il centro di massa dei dati) è preferibile dal punto di vista statistico poiché minimizza la somma dei quadrati degli errori residui.\nIl campione è costituito da \\(n\\) coppie di osservazioni (\\(x, y\\)).\n\\[\n\\begin{array}{cc}\n\\hline\nx_1 & y_1 \\\\\nx_2 & y_2 \\\\\nx_3 & y_3 \\\\\n\\vdots & \\vdots \\\\\nx_n & y_n \\\\\n\\hline\n\\end{array}\n\\]\nPer ciascuna coppia di valori \\(x_i, y_i\\), il modello di regressione si aspetta che il valore \\(y_i\\) sia associato al corrispondente valore \\(x_i\\) come indicato dalla seguente equazione\n\\[\n\\mathbb{E}(y_i) = a + b x_i ,\n\\tag{61.1}\\]\novvero:\n\\[\n\\begin{array}{ccc}\n\\hline\nx_i & y_i & \\mathbb{E}(y_i) = a + b x_i \\\\\n\\hline\nx_1 & y_1 & a + b x_1 \\\\\nx_2 & y_2 & a + b x_2 \\\\\nx_3 & y_3 & a + b x_3 \\\\\n\\vdots & \\vdots & \\vdots \\\\\nx_n & y_n & a + b x_n \\\\\n\\hline\n\\end{array}\n\\]\nI valori \\(y_i\\) corrispondono, nell’esempio che stiamo discutendo, alla variabile kid_score. I primi 10 valori della variabile \\(y\\) sono i seguenti:\n\nkidiq$kid_score[0:10]\n#&gt;  [1]  65  98  85  83 115  98  69 106 102  95\n\nPer fare riferimento a ciascuna osservazione usiamo l’indice \\(i\\). Quindi, ad esempio, \\(y_2\\) è uguale a\n\nkidiq$kid_score[2]\n#&gt; [1] 98\n\nIl modello di regressione lineare bivariata, rappresentato dall’equazione \\(y_i = a + b x_i + e_i\\), descrive la relazione tra le variabili \\(x\\) e \\(y\\), dove \\(y\\) è la variabile dipendente (nel nostro esempio, la variabile kid_score) e \\(x\\) è la variabile indipendente (nel nostro esempio, la variabile mom_iq).\nIl valore di \\(y\\) è la somma di due componenti:\n\nla componente deterministica, \\(\\hat{y}_i = a + b x_i\\), rappresenta la porzione della \\(y\\) che è prevedibile conoscendo il valore di \\(x\\);\nla componente aleatoria, \\(e_i\\), rappresenta la porzione della \\(y\\) che non è prevedibile dal modello.\n\nIl modello lineare cerca di trovare i coefficienti \\(a\\) e \\(b\\) che permettono di prevedere la componente deterministica di \\(y\\) conoscendo il valore di \\(x\\). Tuttavia, poiché la retta è solo un’approssimazione della relazione tra \\(x\\) e \\(y\\), la componente deterministica rappresenta solo una stima approssimata della vera relazione tra le due variabili.\nPer valutare l’accuratezza del modello di regressione lineare, è necessario calcolare il residuo\n\\[\ne_i = y_i - (a + b x_i) ,\n\\tag{61.2}\\]\novvero la differenza tra il valore osservato di \\(y\\) e il valore previsto dal modello, \\(\\hat{y}\\). La dimensione del residuo indica quanto la componente aleatoria contribuisce al valore osservato di \\(y\\).\nIl modello di regressione lineare ha tre obiettivi (Fox, 2015):\n\nil primo è quello di trovare i coefficienti \\(a\\) e \\(b\\) che permettono di prevedere la componente deterministica di \\(y\\) conoscendo il valore di \\(x\\);\nil secondo obiettivo è quello di valutare l’accuratezza della predizione fornita dal modello di regressione lineare;\ninfine, il terzo obiettivo è quello dell’inferenza, ovvero quello di capire quali relazioni esistono tra la relazione tra \\(x\\) e \\(y\\) osservata nel campione e la relazione tra le due variabili nella popolazione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#stima-dei-coefficienti-di-regressione",
    "href": "chapters/linear_models/01_reglin_frequentist.html#stima-dei-coefficienti-di-regressione",
    "title": "61  La regressione lineare bivariata: un approccio frequentista",
    "section": "\n61.5 Stima dei coefficienti di regressione",
    "text": "61.5 Stima dei coefficienti di regressione\nIn breve, stiamo cercando di descrivere una relazione tra due variabili, il QI della madre e il QI del bambino, utilizzando un modello di regressione lineare. L’equazione lineare che descrive la relazione tra le due variabili è della forma \\(\\hat{y}_i = a_i + bx_i\\), dove \\(\\hat{y}_i\\) rappresenta la previsione per il QI del bambino \\(i\\)-esimo, \\(a_i\\) e \\(b\\) sono i coefficienti di regressione che vogliamo trovare e \\(x_i\\) è il QI della madre del bambino \\(i\\)-esimo.\nPer trovare i coefficienti di regressione, dobbiamo introdurre dei vincoli per limitare lo spazio delle possibili soluzioni. Il primo vincolo è che la retta di regressione deve passare per il baricentro del grafico a dispersione. Il secondo vincolo è che vogliamo minimizzare la somma dei quadrati dei residui, ovvero la differenza tra il valore osservato e il valore previsto dal modello. I coefficienti di regressione che soddisfano questi vincoli si chiamano coefficienti dei minimi quadrati.\nIl problema di trovare i coefficienti di regressione \\(a\\) e \\(b\\) che minimizzano la somma dei quadrati dei residui ha una soluzione analitica. Questa soluzione si ottiene trovando il punto di minimo di una superficie tridimensionale che rappresenta la somma dei quadrati dei residui. Il punto di minimo è quello per cui il piano tangente alla superficie nelle due direzioni \\(a\\) e \\(b\\) è piatto, cioè le derivate parziali rispetto ad \\(a\\) e \\(b\\) sono uguali a zero. In pratica, ciò significa risolvere un sistema di equazioni lineari con due incognite \\(a\\) e \\(b\\), noto come equazioni normali.\nLa soluzione delle equazioni normali ci fornisce i coefficienti di regressione stimati, che minimizzano la somma dei quadrati dei residui. La formula per il coefficiente \\(a\\) è\n\\[\na = \\bar{y} - b \\bar{x} ,\n\\tag{61.3}\\]\nla formula per il coefficiente \\(b\\) è\n\\[\nb = \\frac{Cov(x, y)}{Var(x)},\n\\tag{61.4}\\]\ndove \\(\\bar{x}\\) e \\(\\bar{y}\\) sono le medie delle variabili \\(x\\) e \\(y\\), \\(Cov(x,y)\\) è la covarianza tra \\(x\\) e \\(y\\) e \\(Var(x)\\) è la varianza di \\(x\\).\nQueste equazioni rappresentano la stima dei minimi quadrati dei coefficienti di regressione che ci permettono di trovare la retta che minimizza la somma dei quadrati dei residui.\n\n61.5.1 Calcolo manuale dei coefficienti di regressione\nCalcoliamo i coefficientii dei minimi quadrati con l’Equazione 61.3 e l’Equazione 61.4:\n\n# Calcolo manuale dei coefficienti\ncov_xy &lt;- cov(kidiq$kid_score, kidiq$mom_iq)  # Covarianza tra le due variabili\nvar_x &lt;- var(kidiq$mom_iq)  # Varianza della variabile indipendente\nb &lt;- cov_xy / var_x  # Pendenza (coefficiente b)\nb\n#&gt; [1] 0.61\n\n\n# Intercetta (coefficiente a)\na &lt;- mean(kidiq$kid_score) - b * mean(kidiq$mom_iq)\na\n#&gt; [1] 25.8\n\nI risultati replicano quelli ottenuti in precedenza con lm().\n\n61.5.2 Interpretazione\nIl coefficiente \\(a\\) indica l’intercetta della retta di regressione nel diagramma a dispersione. Questo valore rappresenta il punto in cui la retta di regressione interseca l’asse \\(y\\) del sistema di assi cartesiani. Tuttavia, in questo caso specifico, il valore di \\(a\\) non è di particolare interesse poiché corrisponde al valore della retta di regressione quando l’intelligenza della madre è pari a 0, il che non ha senso nella situazione reale. Successivamente, vedremo come è possibile trasformare i dati per fornire un’interpretazione utile del coefficiente \\(a\\).\nInvece, il coefficiente \\(b\\) indica la pendenza della retta di regressione, ovvero di quanto aumenta (se \\(b\\) è positivo) o diminuisce (se \\(b\\) è negativo) la retta di regressione in corrispondenza di un aumento di 1 punto della variabile \\(x\\). Nel caso specifico del QI delle madri e dei loro figli, il coefficiente \\(b\\) ci indica che un aumento di 1 punto del QI delle madri è associato, in media, a un aumento di 0.61 punti del QI dei loro figli.\nIn pratica, il modello di regressione lineare cerca di prevedere le medie dei punteggi del QI dei figli in base al QI delle madri. Ciò significa che non è in grado di prevedere esattamente il punteggio di ciascun bambino in funzione del QI della madre, ma solo una stima della media dei punteggi dei figli quando il QI delle madri aumenta o diminuisce di un punto.\nIl coefficiente \\(b\\) ci dice di quanto aumenta (o diminuisce) in media il QI dei figli per ogni unità di aumento (o diminuzione) del QI della madre. Nel nostro caso, se il QI della madre aumenta di un punto, il QI dei figli aumenta in media di 0.61 punti.\nÈ importante comprendere che il modello statistico di regressione lineare non è in grado di prevedere il valore preciso di ogni singolo bambino, ma solo una stima della media dei punteggi del QI dei figli quando il QI delle madri aumenta o diminuisce. Questa stima è basata su una distribuzione di valori possibili che si chiama distribuzione condizionata \\(p(y \\mid x_i)\\).\nUna rappresentazione grafica del valore predetto dal modello di regressione, \\(\\hat{y}_i = a + bx_i\\) è stato fornito in precedenza. Il diagramma presenta ciascun valore \\(\\hat{y}_i = a + b x_i\\) in funzione di \\(x_i\\). I valori predetti dal modello di regressione sono i punti che stanno sulla retta di regressione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#residui",
    "href": "chapters/linear_models/01_reglin_frequentist.html#residui",
    "title": "61  La regressione lineare bivariata: un approccio frequentista",
    "section": "\n61.6 Residui",
    "text": "61.6 Residui\nIn precedenza abbiamo detto che il residuo, ovvero la componente di ciascuna osservazione \\(y_i\\) che non viene predetta dal modello di regressione, corrisponde alla distanza verticale tra il valore \\(y_i\\) osservato e il valore \\(\\hat{y}_i\\) predetto dal modello di regressione:\n\\[\ne_i = y_i - (a + b x_i).\n\\]\nPer fare un esempio numerico, consideriamo il punteggio osservato del QI del primo bambino.\n\nkidiq$kid_score[1]\n#&gt; [1] 65\n\nIl QI della madre è\n\nkidiq$mom_iq[1]\n#&gt; [1] 121.1\n\nPer questo bambino, il valore predetto dal modello di regressione è\n\na + b * kidiq$mom_iq[1]\n#&gt; [1] 99.68\n\nL’errore che compiamo per predire il QI del bambino utilizzando il modello di regressione (ovvero, il residuo) è\n\nkidiq$kid_score[1] - (a + b * kidiq$mom_iq[1])\n#&gt; [1] -34.68\n\nPer tutte le osservazioni abbiamo\n\nres &lt;- kidiq$kid_score - (a + b * kidiq$mom_iq)\n\nÈ una proprietà del modello di regressione (calcolato con il metodo dei minimi quadrati) che la somma dei residui sia uguale a zero.\n\nsum(res)\n#&gt; [1] 1.444e-11\n\nQuesto significa che ogni valore osservato \\(y_i\\) viene scomposto dal modello di regressione in due componenti distinte. La componente deterministica \\(\\hat{y}_i\\), che è predicibile da \\(x_i\\), è data da \\(\\hat{y}_i = a + b x_i\\). Il residuo, invece, è dato da \\(e_i = y_i - \\hat{y}_i\\). La somma di queste due componenti, ovviamente, riproduce il valore osservato.\n\n# Creazione di un data frame con i valori calcolati\ndf &lt;- data.frame(\n  kid_score = kidiq$kid_score,\n  mom_iq = kidiq$mom_iq,\n  y_hat = a + b * kidiq$mom_iq,\n  e = kidiq$kid_score - (a + b * kidiq$mom_iq),\n  y_hat_plus_e = (a + b * kidiq$mom_iq) + (kidiq$kid_score - (a + b * kidiq$mom_iq))\n)\n\n# Visualizzazione dei primi 6 valori\nhead(df)\n#&gt;   kid_score mom_iq y_hat       e y_hat_plus_e\n#&gt; 1        65 121.12 99.68 -34.678           65\n#&gt; 2        98  89.36 80.31  17.692           98\n#&gt; 3        85 115.44 96.22 -11.217           85\n#&gt; 4        83  99.45 86.46  -3.462           83\n#&gt; 5       115  92.75 82.37  32.628          115\n#&gt; 6        98 107.90 91.62   6.383           98",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#trasformazione-dei-dati",
    "href": "chapters/linear_models/01_reglin_frequentist.html#trasformazione-dei-dati",
    "title": "61  La regressione lineare bivariata: un approccio frequentista",
    "section": "\n61.7 Trasformazione dei dati",
    "text": "61.7 Trasformazione dei dati\nIn generale, per variabili a livello di scala ad intervalli, l’intercetta del modello di regressione lineare non ha un’interpretazione utile. Questo perché l’intercetta indica il valore atteso di \\(y\\) quando \\(x = 0\\), ma in caso di variabili a scala di intervalli, il valore “0” di \\(x\\) è arbitrario e non corrisponde ad un “assenza” della variabile \\(x\\). Ad esempio, un QI della madre pari a 0 non indica un’assenza di intelligenza, ma solo un valore arbitrario del test usato per misurare il QI. Quindi, sapere il valore medio del QI dei bambini quando il QI della madre è 0 non è di alcun interesse.\nPer fornire all’intercetta del modello di regressione un’interpretazione più utile, dobbiamo trasformare le osservazioni di \\(x\\). Per esempio, esprimiamo \\(x\\) come differenza dalla media. Chiamiamo questa nuova variabile \\(xd\\):\n\nkidiq$xd &lt;- kidiq$mom_iq - mean(kidiq$mom_iq)\n\nkidiq |&gt; \n  head()\n#&gt;   kid_score mom_hs mom_iq mom_work mom_age       xd\n#&gt; 1        65      1 121.12        4      27  21.1175\n#&gt; 2        98      1  89.36        4      25 -10.6381\n#&gt; 3        85      1 115.44        4      27  15.4432\n#&gt; 4        83      1  99.45        3      25  -0.5504\n#&gt; 5       115      1  92.75        4      27  -7.2543\n#&gt; 6        98      0 107.90        1      18   7.9018\n\nSe ora usiamo le coppie di osservazioni \\((xd_i, y_i)\\), il diagramma a dispersione assume la forma seguente.\n\n# Aggiungiamo una nuova variabile centrata (scarti dalla media)\nkidiq &lt;- kidiq %&gt;%\n  mutate(xd = mom_iq - mean(mom_iq))\n\n# Calcolo della retta di regressione\nb &lt;- cov(kidiq$xd, kidiq$kid_score) / var(kidiq$xd)\na &lt;- mean(kidiq$kid_score) - b * mean(kidiq$xd)\n\n# Grafico con ggplot2\nggplot(kidiq, aes(x = xd, y = kid_score)) +\n  geom_point(alpha = 0.6) +  # Punti del grafico\n  geom_abline(intercept = a, slope = b, color = \"blue\") +  # Retta di regressione\n  labs(\n    x = \"QI della madre (scarti dalla media)\", \n    y = \"QI del bambino\"\n  ) +\n  ggtitle(\"Retta di regressione sui dati centrati\")\n\n\n\n\n\n\n\nIn pratica, abbiamo spostato tutti i punti del grafico lungo l’asse delle \\(x\\), in modo tale che la media dei valori di \\(x\\) sia uguale a 0. Questo non ha cambiato la forma dei punti nel grafico, ma ha solo spostato l’origine dell’asse \\(x\\). La pendenza della linea di regressione tra \\(x\\) e \\(y\\) rimane la stessa, sia per i dati originali che per quelli trasformati. L’unica cosa che cambia è il valore dell’intercetta della linea di regressione, che ora ha un’interpretazione più significativa.\n\nfm1 &lt;- lm(kid_score ~ xd, data = kidiq)\ncoef(fm1)\n#&gt; (Intercept)          xd \n#&gt;       86.80        0.61\n\nL’intercetta rappresenta il punto in cui la retta di regressione incontra l’asse \\(y\\) nel diagramma a dispersione. Nel caso dei dati trasformati, abbiamo spostato la nube di punti lungo l’asse \\(x\\) di una quantità pari a \\(x - \\bar{x}\\), ma le relazioni spaziali tra i punti rimangono invariate. Pertanto, la pendenza della retta di regressione non cambia rispetto ai dati non trasformati. Tuttavia, il valore dell’intercetta viene influenzato dalla trasformazione. In particolare, poiché \\(xd = 0\\) corrisponde a \\(x = \\bar{x}\\) nei dati grezzi, l’intercetta del modello di regressione lineare calcolata sui dati trasformati corrisponde al valore atteso di \\(y\\) quando \\(x\\) assume il valore medio sulla scala dei dati grezzi. In altre parole, l’intercetta del modello di regressione lineare sui dati trasformati rappresenta il valore atteso del QI dei bambini corrispondente al QI medio delle madri.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#il-metodo-dei-minimi-quadrati",
    "href": "chapters/linear_models/01_reglin_frequentist.html#il-metodo-dei-minimi-quadrati",
    "title": "61  La regressione lineare bivariata: un approccio frequentista",
    "section": "\n61.8 Il metodo dei minimi quadrati",
    "text": "61.8 Il metodo dei minimi quadrati\nPer stimare i coefficienti \\(a\\) e \\(b\\), possiamo minimizzare la somma dei quadrati dei residui tra i valori osservati \\(y_i\\) e quelli previsti \\(a + b x_i\\).\nIniziamo con il creare una griglia per i valori di \\(b\\). Supponiamo che il valore di \\(a\\) sia noto (\\(a = 25.79978\\)). Usiamo R per creare una griglia di valori possibili per \\(b\\).\n\n# Griglia di valori per b\nb_grid &lt;- seq(0, 1, length.out = 1001)\na &lt;- 25.79978  # Intercetta nota\n\nDefiniamo ora una funzione che calcola la somma dei quadrati dei residui (\\(SSE\\)) per ciascun valore di \\(b\\).\n\n# Funzione per la somma dei quadrati dei residui\nsse &lt;- function(a, b, x, y) {\n  sum((y - (a + b * x))^2)\n}\n\nApplichiamo la funzione sse alla griglia di valori \\(b\\) per calcolare la somma dei quadrati dei residui per ogni valore di \\(b\\).\n\n# Calcolo di SSE per ciascun valore di b\nsse_vals &lt;- sapply(\n  b_grid, \n  function(b) sse(a, b, kidiq$mom_iq, kidiq$kid_score)\n)\n\n\n\nsapply:\n\nÈ una funzione di R che applica una funzione ad ogni elemento di un vettore (o lista) e restituisce i risultati in un vettore.\nQui, applica la funzione sse a ciascun valore di \\(b\\) contenuto in b_grid.\n\n\n\nfunction(b):\n\nÈ una funzione anonima definita al volo per specificare come calcolare \\(SSE\\) per ciascun valore di \\(b\\).\nAll’interno, viene chiamata la funzione sse(a, b, x, y) con i seguenti parametri:\n\n\na: il valore dell’intercetta (fissato in precedenza o noto).\n\nb: il valore corrente nella griglia b_grid.\n\nx: la variabile indipendente del dataset (kidiq$mom_iq).\n\ny: la variabile dipendente del dataset (kidiq$kid_score).\n\n\n\n\nIl risultato è un vettore, sse_vals, che contiene i valori di \\(SSE\\) corrispondenti a ciascun valore di \\(b\\) in b_grid.\n\nTracciamo un grafico che mostra la somma dei quadrati dei residui (\\(SSE\\)) in funzione dei valori di \\(b\\), evidenziando il minimo.\n\n# Identificazione del valore di b che minimizza SSE\nb_min &lt;- b_grid[which.min(sse_vals)]\n\n# Creazione del dataframe per ggplot\ndat &lt;- data.frame(b_grid = b_grid, sse_vals = sse_vals)\n\n# Genera il grafico\nggplot(dat, aes(x = b_grid, y = sse_vals)) +\n  geom_line(color = \"blue\", linewidth = 1) +  \n  annotate(\n    \"point\", x = b_min, y = min(sse_vals),\n    color = \"red\", size = 3\n  ) +  # Punto minimo\n  labs(\n    x = expression(paste(\"Possibili valori di \", hat(beta))),\n    y = \"Somma dei quadrati dei residui\",\n    title = \"Minimizzazione dei residui quadratici\"\n  ) +\n  annotate(\n    \"text\", x = b_min, y = min(sse_vals), \n    label = expression(hat(beta)), color = \"red\", vjust = -1, hjust = 0.5\n  )\n\n\n\n\n\n\n\nInfine, identifichiamo il valore di \\(b\\) che minimizza la somma dei quadrati dei residui.\n\nb_min\n#&gt; [1] 0.61\n\nCon questa simulazione, abbiamo stimato il coefficiente \\(b\\) minimizzando la somma dei quadrati dei residui.\nQuesto approccio può essere esteso per stimare simultaneamente entrambi i coefficienti (\\(a\\) e \\(b\\)) utilizzando metodi di ottimizzazione più avanzati, come optim in R.\n\noptim_result &lt;- optim(\n  par = c(a = 25, b = 0.5),  # Valori iniziali\n  fn = function(params) {\n    a &lt;- params[1]\n    b &lt;- params[2]\n    sse(a, b, kidiq$mom_iq, kidiq$kid_score)\n  }\n)\n\n# Coefficienti stimati\noptim_result$par\n#&gt;       a       b \n#&gt; 25.7874  0.6101\n\nQuesta simulazione illustra come, tramite il metodo dei minimi quadrati, sia possibile stimare i parametri di un modello bivariato di regressione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#lerrore-standard-della-regressione",
    "href": "chapters/linear_models/01_reglin_frequentist.html#lerrore-standard-della-regressione",
    "title": "61  La regressione lineare bivariata: un approccio frequentista",
    "section": "\n61.9 L’errore standard della regressione",
    "text": "61.9 L’errore standard della regressione\nIl secondo obiettivo del modello di regressione lineare è quello di misurare quanto della variabilità di \\(y\\) possa essere spiegata dalla variabilità di \\(x\\) per ogni osservazione. L’indice di bontà di adattamento del modello viene fornito dalla deviazione standard dei residui, chiamata anche errore standard della stima (o errore standard della regressione), \\(s_e\\).\nPer calcolare \\(s_e\\), si sommano i quadrati dei residui \\(e_i\\) per ogni osservazione e si divide per \\(n-2\\), dove \\(n\\) rappresenta la numerosità del campione e \\(2\\) il numero di coefficienti stimati nel modello di regressione. Si prende poi la radice quadrata del risultato:\n\\[\n\\sqrt{\\frac{1}{n-2} \\sum_{i=1}^n \\big(y_i - (\\hat{a} + \\hat{b}x_i)\\big)^2},\n\\tag{61.5}\\]\nL’indice \\(s_e\\) possiede la stessa unità di misura di \\(y\\) ed è una stima della deviazione standard dei residui nella popolazione.\nIllustriamo il calcolo di \\(s_e\\) con i dati a disposizione. I residui \\(e\\) possono essere calcolati sottraendo ai valori osservati \\(y_i\\) i valori predetti dal modello \\(a + b x_i\\):\n\n# Calcolo dei residui\ne &lt;- kidiq$kid_score - (a + b * kidiq$mom_iq)\n\n# Mostriamo i primi 10 residui\nhead(e, 10)\n#&gt;  [1] -34.678  17.692 -11.217  -3.462  32.628   6.383 -41.521   3.865  26.414\n#&gt; [10]  11.208\n\nCalcoliamo il valore medio assoluto dei residui per avere un’indicazione della deviazione media rispetto alla retta di regressione.\n\n# Media assoluta dei residui\nmean(abs(e))\n#&gt; [1] 14.47\n\nL’errore standard della stima \\(s_e\\) si calcola come la radice quadrata della somma dei quadrati dei residui divisa per \\(n-2\\):\n\n# Calcolo di s_e\nse &lt;- sqrt(sum(e^2) / (length(e) - 2))\nse\n#&gt; [1] 18.27\n\nNotiamo che il valore medio assoluto dei residui e l’errore standard \\(s_e\\) non sono identici, ma hanno lo stesso ordine di grandezza. \\(s_e\\) è una misura più rigorosa della deviazione standard dei residui.\nQuesta analisi dimostra come \\(s_e\\) consenta di valutare quanto le previsioni del modello si discostino (in media) dai dati osservati.\n\n61.9.1 Sottostima dell’Errore nel Modello di Regressione\nCome discusso da Gelman et al. (2021), l’errore standard della regressione tende a sottostimare la vera deviazione standard \\(\\sigma\\) dell’errore nel modello di regressione nella popolazione. Questa sottostima è dovuta al fenomeno del sovradimensionamento, dato che i parametri \\(a\\) e \\(b\\) sono stimati utilizzando gli stessi \\(n\\) punti dati su cui vengono calcolati i residui. In altre parole, i residui non sono del tutto indipendenti dal modello.\nUn approccio alternativo per valutare l’errore predittivo e mitigare il problema del sovradimensionamento è la validazione incrociata. In particolare, l’approccio leave-one-out (LOOCV) offre una soluzione semplice ed efficace. Questo metodo consiste nell’adattare il modello \\(n\\) volte, escludendo ogni volta un punto dati, adattando il modello ai rimanenti \\(n-1\\) punti, e utilizzando tale modello per predire l’osservazione esclusa.\n\n61.9.1.1 Procedura Leave-One-Out:\n\n\nPer \\(i = 1, \\ldots, n\\):\n\nAdatta il modello \\(y = a + bx + \\text{errore}\\) ai \\(n-1\\) punti dati \\((x, y)_j, j \\neq i\\). Denomina i coefficienti stimati come \\(\\hat{a}_{-i}\\) e \\(\\hat{b}_{-i}\\).\n\nCalcola il residuo validato incrociato:\n\\[\ne_{\\text{CV}} = y_i - (\\hat{a}_{-i} + \\hat{b}_{-i} x_i).\n\\]\n\nSalva il residuo al quadrato per il calcolo successivo.\n\n\n\nCalcola infine la stima di \\(\\sigma_{\\text{CV}}\\) come:\n\\[\n\\sigma_{\\text{CV}} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n e_{\\text{CV}}^2}.\n\\]\n\n\n61.9.1.2 Applicazione Pratica:\nEcco un esempio applicato al modello che predice l’intelligenza del bambino (\\(\\texttt{kid\\_score}\\)) in funzione dell’intelligenza della madre (\\(\\texttt{mom\\_iq}\\)) utilizzando il dataset kidiq.\n\noptions(round = 5)\n\n# Array per salvare i residui validati incrociati\nresiduals_cv &lt;- numeric(nrow(kidiq))\n\n# Loop per la validazione incrociata leave-one-out\nfor (i in 1:nrow(kidiq)) {\n  # Dati di training escludendo l'i-esimo punto\n  train_data &lt;- kidiq[-i, ]\n  test_data &lt;- kidiq[i, ]\n  \n  # Addestramento del modello\n  model &lt;- lm(kid_score ~ mom_iq, data = train_data)\n  \n  # Predizione sull'i-esimo punto\n  y_pred &lt;- predict(model, newdata = test_data)\n  \n  # Calcolo del residuo validato incrociato\n  residual_cv &lt;- test_data$kid_score - y_pred\n  residuals_cv[i] &lt;- residual_cv^2\n}\n\n# Calcolo di sigma_cv\nsigma_cv &lt;- sqrt(mean(residuals_cv))\n\ncat(\"Stima di σ_CV:\", sigma_cv, \"\\n\")\n#&gt; Stima di σ_CV: 18.31\n\nCalcoliamo ora la stima tradizionale di \\(\\sigma\\) utilizzando il modello completo e confrontiamola con \\(\\sigma_{\\text{CV}}\\).\n\n# Modello completo\nfm2 &lt;- lm(kid_score ~ mom_iq, data = kidiq)\n\n# Stima tradizionale dell'errore standard della regressione\nres &lt;- summary(fm2)\ncat(\"Errore standard della regressione (tradizionale):\", res$sigma, \"\\n\")\n#&gt; Errore standard della regressione (tradizionale): 18.27\n\nNel caso analizzato, i valori stimati di \\(\\sigma_{\\text{CV}}\\) e \\(\\hat{\\sigma}_e\\) tradizionale possono risultare molto simili. Tuttavia, in generale, la stima di \\(\\sigma_{\\text{CV}}\\) tende a essere leggermente superiore, in quanto riflette meglio l’errore predittivo su dati non utilizzati per adattare il modello. Questo rende \\(\\sigma_{\\text{CV}}\\) una misura più robusta e conservativa dell’incertezza del modello.\nIn conclusione, la validazione incrociata, e in particolare l’approccio LOOCV, rappresenta uno strumento importante per valutare le performance predittive di un modello di regressione e per ottenere stime più affidabili della deviazione standard dell’errore.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#indice-di-determinazione",
    "href": "chapters/linear_models/01_reglin_frequentist.html#indice-di-determinazione",
    "title": "61  La regressione lineare bivariata: un approccio frequentista",
    "section": "\n61.10 Indice di determinazione",
    "text": "61.10 Indice di determinazione\nUn importante risultato dell’analisi di regressione riguarda la scomposizione della varianza della variabile dipendente \\(y\\) in due componenti: la varianza spiegata dal modello e la varianza residua. Questa scomposizione è descritta mediante l’indice di determinazione \\(R^2\\), che fornisce una misura della bontà di adattamento del modello ai dati del campione.\nPer una generica osservazione \\(x_i, y_i\\), la deviazione di \\(y_i\\) rispetto alla media \\(\\bar{y}\\) può essere espressa come la somma di due componenti: il residuo \\(e_i=y_i- \\hat{y}_i\\) e lo scarto di \\(\\hat{y}_i\\) rispetto alla media \\(\\bar{y}\\):\n\\[\ny_i - \\bar{y} = (y_i- \\hat{y}_i) + (\\hat{y}_i - \\bar{y}) = e_i + (\\hat{y}_i - \\bar{y}).\n\\]\nLa varianza totale di \\(y\\) può quindi essere scritta come:\n\\[\n\\sum_{i=1}^{n}(y_i - \\bar{y})^2 = \\sum_{i=1}^{n}(e_i + (\\hat{y}_i - \\bar{y}))^2.\n\\]\nSviluppando il quadrato e sommando, si ottiene:\n\\[\n\\sum_{i=1}^{n}(y_i - \\bar{y})^2 = \\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2 + \\sum_{i=1}^{n}(\\hat{y}_i - \\bar{y})^2.\n\\tag{61.6}\\]\nIl primo termine rappresenta la varianza residua, mentre il secondo termine rappresenta la varianza spiegata dal modello. Questa scomposizione della devianza va sotto il nome di teorema della scomposizione della devianza.\nL’indice di determinazione \\(R^2\\) è definito come il rapporto tra la varianza spiegata e la varianza totale:\n\\[\nR^2 = \\frac{\\sum_{i=1}^{n}(\\hat{y}_i - \\bar{y})^2}{\\sum_{i=1}^{n}(y_i - \\bar{y})^2}.\n\\tag{61.7}\\]\nQuesto indice varia tra 0 e 1 e indica la frazione di varianza totale di \\(y\\) spiegata dal modello di regressione lineare. Un valore alto di \\(R^2\\) indica che il modello di regressione lineare si adatta bene ai dati, in quanto una grande parte della varianza di \\(y\\) è spiegata dalla variabile indipendente \\(x\\).\nPer l’esempio in discussione, possiamo calcolare la devianza totale, la devianza spiegata e l’indice di determinazione \\(R^2\\) come segue:\nLa devianza totale misura la variabilità complessiva dei punteggi osservati \\(y\\) rispetto alla loro media:\n\n# Devianza totale\ndev_t &lt;- sum((kidiq$kid_score - mean(kidiq$kid_score))^2)\ndev_t\n#&gt; [1] 180386\n\nLa devianza spiegata misura la variabilità che il modello è in grado di spiegare, considerando i valori predetti \\(a + b x\\):\n\n# Devianza spiegata\ndev_r &lt;- sum(((a + b * kidiq$mom_iq) - mean(kidiq$kid_score))^2)\ndev_r\n#&gt; [1] 36249\n\nL’indice \\(R^2\\) è il rapporto tra la devianza spiegata e la devianza totale, e indica la frazione della variabilità totale che è spiegata dal modello di regressione:\n\n# Indice di determinazione\nR2 &lt;- dev_r / dev_t\nround(R2, 3)\n#&gt; [1] 0.201\n\nPer verificare i calcoli, utilizziamo il modello di regressione lineare in R e leggiamo \\(R^2\\) direttamente dal sommario del modello:\n\n# Modello di regressione lineare\nmod &lt;- lm(kid_score ~ mom_iq, data = kidiq)\n\n# Sommario del modello per leggere R^2\nsummary(mod)$r.squared\n#&gt; [1] 0.201\n\nIl risultato mostra che circa il 20% della variabilità nei punteggi del QI dei bambini è spiegabile conoscendo il QI delle madri. Questo significa che il modello cattura una porzione rilevante della relazione, ma lascia anche spazio a fattori non inclusi nel modello che influenzano il QI dei bambini.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#inferenza-sul-modello-di-regressione",
    "href": "chapters/linear_models/01_reglin_frequentist.html#inferenza-sul-modello-di-regressione",
    "title": "61  La regressione lineare bivariata: un approccio frequentista",
    "section": "\n61.11 Inferenza sul modello di regressione",
    "text": "61.11 Inferenza sul modello di regressione\nL’inferenza statistica sui coefficienti di regressione richiede la definizione della distribuzione campionaria dei coefficienti di regressione. Il modello di regressione bivariata (o lineare semplice) è:\n\\[Y_i = \\beta_0 + \\beta_1 X_i + \\varepsilon_i,\\]\ndove \\(Y_i\\) è la variabile dipendente per l’osservazione \\(i\\), \\(X_i\\) è la variabile indipendente, \\(\\beta_0\\) è l’intercetta (parametro ignoto), \\(\\beta_1\\) è il coefficiente angolare (il parametro che ci interessa stimare), e \\(\\varepsilon_i\\) è il termine di errore per l’osservazione \\(i\\).\nNell’inferenza, il nostro obiettivo è stimare i parametri ignoti \\(\\beta_0\\) e \\(\\beta_1\\) usando i dati campionari disponibili. Il metodo più comune è quello dei Minimi Quadrati Ordinari (OLS), che ci fornisce gli stimatori \\(\\hat{\\beta}_0\\) e \\(\\hat{\\beta}_1\\) (spesso indicati semplicemente con \\(b_0\\) e \\(b_1\\)). Lo stimatore per il coefficiente angolare è dato dalla formula:\n\\[\\hat{\\beta}_1 = b_1 = \\frac{\\sum_{i=1}^n (X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sum_{i=1}^n (X_i - \\bar{X})^2}.\\]",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#cosè-la-distribuzione-campionaria-di-b_1",
    "href": "chapters/linear_models/01_reglin_frequentist.html#cosè-la-distribuzione-campionaria-di-b_1",
    "title": "61  La regressione lineare bivariata: un approccio frequentista",
    "section": "\n61.12 Cos’è la Distribuzione Campionaria di \\(b_1\\) ?",
    "text": "61.12 Cos’è la Distribuzione Campionaria di \\(b_1\\) ?\nLo stimatore \\(b_1\\) è una variabile casuale. Perché? Perché il suo valore dipende dal campione casuale di dati \\((X_i, Y_i)\\) che abbiamo estratto dalla popolazione.\nImmaginiamo di poter ripetere il processo di campionamento e stima del modello infinite volte:\n\nEstraiamo un campione casuale di dimensione \\(n\\).\nCalcoliamo lo stimatore \\(b_1\\) per quel campione.\nRegistriamo il valore di \\(b_1\\).\nEstraiamo un nuovo campione casuale (indipendentemente dal primo).\nCalcoliamo il “nuovo” \\(b_1\\).\nRegistriamo il valore.\n… e così via, per infinite volte.\n\nLa distribuzione campionaria di \\(b_1\\) è la distribuzione di probabilità di tutti i valori di \\(b_1\\) che otterremmo da questi infiniti campioni casuali di dimensione \\(n\\) estratti dalla stessa popolazione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#proprietà-della-distribuzione-campionaria-di-b_1",
    "href": "chapters/linear_models/01_reglin_frequentist.html#proprietà-della-distribuzione-campionaria-di-b_1",
    "title": "61  La regressione lineare bivariata: un approccio frequentista",
    "section": "\n61.13 Proprietà della Distribuzione Campionaria di \\(b_1\\)\n",
    "text": "61.13 Proprietà della Distribuzione Campionaria di \\(b_1\\)\n\nIl modello statistico standard della regressione bivariata assume che:\n\n\n1. Linearità nei parametri: La relazione tra la variabile dipendente (\\(Y\\)) e la variabile indipendente (\\(X\\)) è lineare nei parametri (\\(\\beta_0\\) e \\(\\beta_1\\)). Questo implica che il valore atteso di \\(Y_i\\) condizionato a \\(X_i\\), indicato con \\(E(Y_i \\mid X_i)\\), sia espresso correttamente come \\(E(Y_i) = \\beta_0 + \\beta_1 X_i\\).\n\nÈ importante notare che questa assunzione non richiede che i singoli punti dati giacciano esattamente su una retta, ma che la funzione di regressione della popolazione (cioè la relazione tra la media di \\(Y\\) e \\(X\\)) sia lineare. L’impatto medio di una variazione unitaria in \\(X\\) su \\(Y\\), quantificato attraverso il parametro \\(\\beta_1\\), è additivo (contribuisce in modo indipendente da altre variabili) e costante (non dipende dal livello di \\(X\\)). Ad esempio, un aumento di 1 unità in \\(X\\) è associato sempre a un aumento di \\(\\beta_1\\) unità in \\(Y\\), indipendentemente dal valore iniziale di \\(X\\).\n\n\n2. Campionamento Casuale: I dati osservati \\((X_i, Y_i)\\) per \\(i = 1, \\dots, n\\) rappresentano un campione casuale estratto dalla popolazione di interesse. Questo implica che le osservazioni sono indipendenti l’una dall’altra e provengono dalla stessa distribuzione congiunta di \\((X, Y)\\).\n\n3. Esogeneità (o Media Condizionata degli Errori Nulla): Il valore atteso del termine di errore (\\(\\epsilon_i\\)) è zero, condizionatamente al valore della variabile indipendente (\\(X_i\\)). Formalmente: \\(E(\\epsilon_i \\mid X_i) = 0\\). Questa è un’assunzione cruciale. Implica che non ci siano altri fattori (contenuti nell’errore \\(\\epsilon_i\\)) che sono correlati con la variabile indipendente \\(X_i\\) e che influenzano anche \\(Y_i\\).\n\nSe questa assunzione è violata (ad esempio, a causa di variabili omesse correlate sia con \\(X\\) che con \\(Y\\)), lo stimatore OLS \\(b_1\\) sarà distorto e inconsistente.\n\n\n\n4. Omoschedasticità (Varianza Costante degli Errori): La varianza del termine di errore (\\(\\epsilon_i\\)) è costante per tutti i valori della variabile indipendente (\\(X_i\\)). Formalmente: \\(Var(\\epsilon_i \\mid X_i) = \\sigma^2\\), dove \\(\\sigma^2\\) è una costante sconosciuta e finita.\n\nQuesta assunzione implica che la dispersione degli errori attorno alla retta di regressione è la stessa lungo tutto il range di valori di \\(X\\). Se questa assunzione è violata (eteroschedasticità), lo stimatore OLS \\(b_1\\) rimane non distorto, ma i suoi errori standard stimati non saranno corretti, invalidando i test di ipotesi e gli intervalli di confidenza basati su di essi.\n\n\n\n5. Assenza di Collinearità Perfetta: Nel modello bivariato, questa assunzione si riduce semplicemente al fatto che la variabile indipendente \\(X_i\\) non deve essere una costante per tutte le osservazioni nel campione. Ovvero, \\(\\sum_{i=1}^n (X_i - \\bar{X})^2 &gt; 0\\).\n\nSe \\(X_i\\) fosse costante, non ci sarebbe variazione in \\(X\\) da cui stimare l’effetto sulla variazione in \\(Y\\), e la formula per \\(b_1\\) implicherebbe una divisione per zero.\n\n\n\n6. Normalità degli Errori (Opzionale per piccoli campioni): Il termine di errore (\\(\\epsilon_i\\)) è distribuito normalmente con media zero e varianza costante \\(\\sigma^2\\). Formalmente: \\(\\epsilon_i \\sim N(0, \\sigma^2)\\).\n\nQuesta assunzione non è necessaria perché gli stimatori OLS \\(b_0\\) e \\(b_1\\) siano non distorti e per le proprietà di grandi campioni (come la consistenza e la normalità asintotica). Tuttavia, è cruciale per derivare le distribuzioni di probabilità esatte (come la distribuzione t di Student per i test sui coefficienti) degli stimatori nei campioni di piccole dimensioni, permettendo un’inferenza valida in questi casi. Per grandi campioni, la distribuzione asintotica (approssimata) normale degli stimatori vale anche senza questa assunzione.\n\n\n\nSotto le precedenti assunzioni, chiamate assunzioni di Gauss-Markov, più l’assunzione di normalità degli errori per l’inferenza nei piccoli campioni, la distribuzione campionaria di \\(b_1\\) viene specificata come segue:\n\n\nMedia (o Valore Atteso): Unbiasedness (Non Distorsione) Sotto le prime tre assunzioni di Gauss-Markov (Linearità, Campionamento Casuale, Esogeneità dei regressori), lo stimatore OLS \\(b_1\\) è non distorto (unbiased) per il vero parametro di popolazione \\(\\beta_1\\). Questo significa che la media della distribuzione campionaria di \\(b_1\\) è uguale al vero valore di \\(\\beta_1\\):\n\\[E(b_1) = \\beta_1.\\]\nIn altre parole, se potessimo prendere infiniti campioni, la media degli stimatori \\(b_1\\) che otterremmo sarebbe esattamente il vero coefficiente angolare della popolazione. Il nostro singolo stimatore \\(b_1\\) calcolato su un campione specifico è solo una realizzazione di questa variabile casuale la cui distribuzione è centrata sul vero valore \\(\\beta_1\\).\n\n\nVarianza (o Errore Standard): Precisione dello Stimatore La varianza della distribuzione campionaria di \\(b_1\\) ci dice quanto sono dispersi i valori di \\(b_1\\) attorno alla loro media (che è \\(\\beta_1\\)). Una varianza minore indica che gli stimatori ottenuti da campioni diversi tendono ad essere più vicini al vero \\(\\beta_1\\), il che significa che lo stimatore è più preciso. Sotto le assunzioni di Gauss–Markov (inclusa l’omoschedasticità, ossia errori con varianza costante \\(\\sigma^2_\\varepsilon\\)), la varianza di \\(b_1\\) è data da:\n\\[\n\\mathrm{Var}(b_1) \\;=\\; \\frac{\\sigma^2_\\varepsilon}{\\sum_{i=1}^n (X_i - \\bar{X})^2}.\n\\]\nL’errore standard di \\(b_1\\), radice quadrata della varianza, è la misura più comunemente usata per indicare la precisione dello stimatore:\n\\[\nSE(b_1) \\;=\\; \\sqrt{\\frac{\\sigma^2_\\varepsilon}{\\sum_{i=1}^n (X_i - \\bar{X})^2}}.\n\\]\nDalla formula, possiamo osservare che la precisione di \\(b_1\\):\n\ndiminuisce all’aumentare della varianza degli errori (\\(\\sigma^2_\\varepsilon\\)): più “rumore” c’è nei dati, meno preciso sarà lo stimatore;\naumenta all’aumentare della variabilità della variabile indipendente \\(X\\) (misurata da \\(\\sum_{i=1}^n (X_i - \\bar{X})^2\\)): se i valori di \\(X\\) sono molto concentrati, è difficile stimare la pendenza; se sono ben distribuiti, la stima è più precisa;\naumenta all’aumentare della dimensione del campione (\\(n\\)): campioni più grandi forniscono più informazioni e quindi stime più precise.\n\nNella pratica, non conosciamo la vera varianza degli errori \\(\\sigma^2_\\varepsilon\\), perciò la stimiamo usando la varianza dei residui del modello (\\(s^2_e\\)), calcolata come:\n\\[\ns^2_e \\;=\\; \\frac{\\sum_{i=1}^n e_i^2}{n - 2},\n\\]\ndove \\(n - 2\\) riflette i gradi di libertà persi nella stima dei due parametri (\\(b_0\\) e \\(b_1\\)). L’errore standard stimato diventa quindi:\n\\[\nSE(b_1) \\;=\\; \\sqrt{\\frac{s^2_e}{\\sum_{i=1}^n (X_i - \\bar{X})^2}}.\n\\]\nQuesta è la formula riportata nei principali software statistici (R, Stata, Python).\n\n\nForma della Distribuzione:\n\nSotto le assunzioni di Gauss-Markov (ma senza assumere la normalità degli errori), per grandi campioni (in virtù del Teorema del Limite Centrale), la distribuzione campionaria di \\(b_1\\) è approssimativamente Normale.\nSe aggiungiamo l’assunzione che i termini di errore \\(\\varepsilon_i\\) si distribuiscano normalmente, \\(\\varepsilon_i \\sim N(0, \\sigma^2)\\), allora la distribuzione campionaria di \\(b_1\\) è esattamente Normale per qualsiasi dimensione del campione \\(n\\). Tuttavia, quando usiamo l’errore standard stimato (che dipende dalla stima della varianza degli errori), la statistica test (t-statistic) segue una distribuzione t di Student.\n\n\n\nImportanza della Distribuzione Campionaria di \\(b_1\\)\nConoscere la distribuzione campionaria di \\(b_1\\) permette all’approccio frequentista di:\n\n\nTestare Ipotesi: Possiamo testare se la variabile indipendente \\(X\\) ha un effetto statisticamente significativo sulla variabile dipendente \\(Y\\). L’ipotesi nulla più comune è \\(H_0: \\beta_1 = 0\\) (non c’è relazione lineare tra \\(X\\) e \\(Y\\)). Usiamo il valore stimato \\(b_1\\) e il suo errore standard per calcolare una statistica test (il \\(t\\)-value) e confrontarla con una distribuzione teorica (Normale o \\(t\\) di Student) per ottenere un \\(p\\)-value.\n\nCostruire Intervalli di Confidenza: Possiamo costruire un intervallo di valori plausibili per il vero parametro di popolazione \\(\\beta_1\\) basato sul nostro campione. Un intervallo di confidenza al 95% per \\(\\beta_1\\) significa che se ripetessimo il campionamento e la stima molte volte, il 95% degli intervalli costruiti in questo modo conterrebbe il vero valore di \\(\\beta_1\\).\n\nIn sintesi, la distribuzione campionaria di \\(b_1\\) descrive la variabilità attesa dello stimatore del coefficiente angolare attraverso diversi campioni casuali. Comprendere le sue proprietà (media, varianza, forma) è essenziale per interpretare correttamente i risultati di una regressione e trarre conclusioni affidabili sulla relazione nella popolazione.1",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#simulazione-in-r",
    "href": "chapters/linear_models/01_reglin_frequentist.html#simulazione-in-r",
    "title": "61  La regressione lineare bivariata: un approccio frequentista",
    "section": "\n61.14 Simulazione in R",
    "text": "61.14 Simulazione in R\nModello Simulato\nStudiamo il modello di regressione lineare senza intercetta, per variabili \\(X\\) e \\(Y\\) standardizzate:\n\\[\nY_i = \\beta X_i + \\varepsilon_i, \\quad \\varepsilon_i \\sim N(0, \\sigma_\\varepsilon = 0.5).\n\\] Fissiamo \\(\\beta = 1.5\\), \\(n = 30\\) (dimensione del campione) e ripetiamo la simulazione \\(100,\\!000\\) volte per approssimare la distribuzione campionaria di \\(\\hat{\\beta}_1\\).\n\n# Parametri del modello\nbeta &lt;- 1.5           # Vero valore del coefficiente\nsigma_e &lt;- 0.5        # Deviazione standard degli errori\nn_sample &lt;- 30        # Dimensione del campione per ogni simulazione\nnrep &lt;- 100000        # Numero di repliche (campioni) da generare\n\n# Preallocazione di un vettore per salvare gli stimatori\nb_hat &lt;- rep(NA, nrep)\n\n# Genera la variabile indipendente X una volta (fissa tra i campioni)\n# Questo corrisponde a condizionare sulle X, come nelle assunzioni di Gauss-Markov\nx &lt;- rnorm(n_sample, mean = 0, sd = 1)\n\n# Ciclo per replicare il processo di campionamento\nfor (i in 1:nrep) {\n  # 1. Genera errori casuali ε_i ~ N(0, σ_ε)\n  e &lt;- rnorm(n_sample, mean = 0, sd = sigma_e)\n  \n  # 2. Genera la variabile dipendente Y_i = β * X_i + ε_i\n  y &lt;- beta * x + e\n  \n  # 3. Stima β_1 usando la formula OLS: Cov(X,Y)/Var(X)\n  # Questa formula è valida per modelli con intercetta, ma qui X è centrata (media ≈ 0)\n  b_hat[i] &lt;- cov(x, y) / var(x)\n}\n\n\n# Analisi dei risultati\nhist(\n  b_hat, \n  breaks = 50, \n  col = \"lightblue\", \n  main = expression(\"Distribuzione Campionaria di\" ~ hat(beta)[1]), \n  xlab = expression(\"Valore Stimato\" ~ hat(beta)[1]),\n  freq = FALSE\n)\n\n# Sovrappone una curva normale con media teorica e deviazione standard osservata\ncurve(dnorm(x, mean = mean(b_hat), sd = sd(b_hat)), add = TRUE, col = \"red\", lwd = 2)\n\n\n\n\n\n\n\n\n# Media empirica di β̂₁ (dovrebbe essere vicina a β = 1.5)\nmean_b_hat &lt;- mean(b_hat)\ncat(\"Media empirica di β̂₁:\", round(mean_b_hat, 3), \"\\n\")\n#&gt; Media empirica di β̂₁: 1.5\n\n# Deviazione standard empirica di β̂₁ (confronto con teoria)\nsd_b_hat &lt;- sd(b_hat)\ncat(\"Deviazione standard empirica di β̂₁:\", round(sd_b_hat, 3), \"\\n\")\n#&gt; Deviazione standard empirica di β̂₁: 0.074\n\n# Calcolo dell'errore standard teorico\n# Var(β̂₁) = σ_ε² / Σ(X_i - X̄)²\ntheoretical_se &lt;- sqrt(sigma_e^2 / sum((x - mean(x))^2))\ncat(\"Errore standard teorico:\", round(theoretical_se, 3), \"\\n\")\n#&gt; Errore standard teorico: 0.074\n\nInterpretazione dei Risultati\n1. Non Distorsione (Unbiasedness)\n\nLa media empirica di \\(\\hat{\\beta}_1\\) (calcolata come mean(b_hat)) dovrebbe essere molto vicina al valore vero \\(\\beta = 1.5\\).\n\n\nTeoria: Sotto le assunzioni di Gauss-Markov (linearità, esogeneità, campionamento casuale), lo stimatore OLS è non distorto: \\(E(\\hat{\\beta}_1) = \\beta_1\\).\n\n\nSimulazione: Se la media è prossima a \\(1.5\\), confermiamo questa proprietà.\n\n2. Precisione (Varianza)\n\nLa deviazione standard empirica (sd(b_hat)) misura la dispersione dello stimatore attorno al valore vero.\n\n\nTeoria: La varianza di \\(\\hat{\\beta}_1\\) dipende da:\n\nLa varianza degli errori \\(\\sigma_\\varepsilon^2\\) (maggiore rumore → minore precisione),\nLa variabilità di \\(X\\) (\\(\\sum (X_i - \\bar{X})^2\\); maggiore variabilità → maggiore precisione).\n\n\n\nSimulazione: Confrontiamo sd(b_hat) con l’errore standard teorico calcolato come: \\[\nSE(\\hat{\\beta}_1) = \\sqrt{\\frac{\\sigma_\\varepsilon^2}{\\sum_{i=1}^n (X_i - \\bar{X})^2}}.\n\\] I valori dovrebbero essere simili.\n\n3. Normalità Asintotica\n\nL’istogramma mostra la distribuzione degli stimatori \\(\\hat{\\beta}_1\\) ottenuti nei \\(100,\\!000\\) campioni.\n\n\nTeoria: Per grandi campioni (o se gli errori sono normali), la distribuzione campionaria di \\(\\hat{\\beta}_1\\) è normale.\n\n\nSimulazione: La curva rossa (densità normale) dovrebbe sovrapporsi bene all’istogramma, confermando la forma normale.\n\nCollegamento con le Assunzioni del Modello\n\nEsogeneità (\\(E(\\varepsilon_i \\mid X_i) = 0\\)):\nNella simulazione, gli errori \\(\\varepsilon_i\\) sono generati indipendentemente da \\(X_i\\), soddisfacendo questa assunzione. Se invece \\(\\varepsilon_i\\) fosse correlato con \\(X_i\\) (es. \\(X_i\\) influenzasse \\(\\varepsilon_i\\)), lo stimatore sarebbe distorto.\nOmoschedasticità:\nLa varianza degli errori è costante (\\(\\sigma_\\varepsilon = 0.5\\)), garantendo che la formula dell’errore standard sia corretta. In presenza di eteroschedasticità, l’errore standard teorico non sarebbe più affidabile.\nNormalità degli Errori:\nGli errori sono generati da una distribuzione normale, ma la normalità asintotica della distribuzione campionaria di \\(\\hat{\\beta}_1\\) sarebbe comunque approssimativamente valida anche con errori non normali (per il Teorema del Limite Centrale).\n\nConclusione\nLa simulazione conferma le proprietà teoriche della distribuzione campionaria di \\(\\hat{\\beta}_1\\):\n\n\nnon distorsione: la media empirica coincide con il valore vero;\n\nprecisione: la varianza dello stimatore diminuisce con la variabilità di \\(X\\) e aumenta con la dimensione del campione;\n\nnormalità: la distribuzione è simmetrica e approssimativamente normale, anche per \\(n = 30\\).\n\nQuesto esempio pratico chiarisce come le assunzioni del modello influenzino la qualità delle stime e l’affidabilità dell’inferenza statistica.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#riflessioni-conclusive",
    "href": "chapters/linear_models/01_reglin_frequentist.html#riflessioni-conclusive",
    "title": "61  La regressione lineare bivariata: un approccio frequentista",
    "section": "\n61.15 Riflessioni conclusive ",
    "text": "61.15 Riflessioni conclusive \nIl modello lineare bivariato costituisce uno strumento basilare per analizzare la relazione tra due variabili e rappresenta una pietra miliare dell’approccio frequentista. In questo capitolo abbiamo mostrato come il modello permetta di quantificare l’associazione fra una variabile indipendente \\(X\\) e una variabile dipendente \\(Y\\) tramite una relazione lineare.\nNell’ambito frequentista, i coefficienti \\(b_0\\) (intercetta) e \\(b_1\\) (pendenza) vengono stimati con il metodo dei minimi quadrati, che minimizza la somma dei quadrati dei residui e individua la retta che meglio approssima i dati osservati. L’indice di determinazione (\\(R^2\\)) misura la bontà di adattamento del modello, indicando quale quota della variabilità di \\(Y\\) è spiegata da \\(X\\).\nIn pratica, il modello lineare bivariato consente di rispondere a domande fondamentali quali:\n\nCome varia la variabile dipendente al variare della variabile indipendente?\nQual è intensità e segno dell’associazione tra le due variabili?\n\nLa semplicità del modello lo rende utile non solo per descrivere e analizzare relazioni, ma anche per formulare previsioni. Pur limitandosi a un singolo predittore, costituisce la base concettuale per modelli più complessi (ad es. la regressione multipla).\nDerivare la distribuzione campionaria dei coefficienti permette di svolgere inferenza sui parametri. Tuttavia, nel paradigma frequentista l’inferenza si fonda:\n\nsul test dell’ipotesi nulla (che assume, nella popolazione, pendenza esattamente pari a zero);\nsulla costruzione degli intervalli di fiducia, i quali descrivono le proprietà a lungo termine della procedura di campionamento, ma non forniscono probabilità per il singolo intervallo.\n\nLa riflessione metodologica contemporanea ha evidenziato i limiti di questa impostazione, mostrando come l’inferenza frequentista sia vulnerabile a pratiche scorrette che hanno alimentato la crisi di riproducibilità in psicologia. Per tali motivi, risulta spesso più informativo riformulare l’inferenza in termini bayesiani, dove si ottengono distribuzioni a posteriori dei parametri che consentono interpretazioni probabilistiche dirette e maggior trasparenza nel processo inferenziale.\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n1 – Definizione e scopi della regressione\nSecondo Gelman et al. (2021), quali sono i quattro principali utilizzi della regressione? Fornisci una breve descrizione di ciascuno.\n2 – Errore di specificazione\nCos’è l’“errore di specificazione” in un modello di regressione? Quali effetti ha sulle stime dei parametri?\n3 – Stima del modello con lm()\nUsando il data‑set kidiq (variabili kid_score e mom_iq):\n\n# carica i dati\nkidiq &lt;- rio::import(here::here(\"data\", \"kidiq.dta\"))\n\nAdatta il modello kid_score ~ mom_iq e riporta intercetta e pendenza.\n4 – Interpretazione della pendenza\nInterpreta in parole la pendenza stimata al punto 3 nel contesto dei QI di madri e figli.\n5 – Indice R²\nCalcola l’R² del modello di cui al punto 3. Cosa indica il suo valore?\n6 – Centratura del predittore\nCrea la variabile centrata mom_iq_c = mom_iq - mean(mom_iq) e ri‑adatta il modello kid_score ~ mom_iq_c. Qual è la nuova intercetta e perché adesso è più interpretabile?\n7 – Calcolo manuale di \\(b\\)\nCalcola manualmente la pendenza con la formula\\(b = \\frac{\\text{Cov}(x,y)}{\\text{Var}(x)}\\)\ne confrontala col risultato di lm().\n8 – Confronto tra σ̂ (tradizionale) e σ_CV\n* (a) Calcola l’errore standard della regressione (σ̂) usando il modello completo.\n* (b) Esegui una validazione incrociata leave‑one‑out (LOOCV) e ottieni σ_CV.\n* (c) Spiega perché, in genere, σ_CV è ≥ σ̂.\n9 – Assunzioni di Gauss‑Markov\nElenca le cinque assunzioni di Gauss‑Markov per la regressione lineare semplice e indica quale, se violata, rende distorto lo stimatore OLS della pendenza.\n10 – Simulazione della distribuzione campionaria di \\(b\\)\nSimula 100 000 campioni (n = 30) dal modello\\(Y_i = 1.5\\,X_i + \\varepsilon_i,\\; X_i \\sim \\mathcal N(0,1),\\; \\varepsilon_i \\sim \\mathcal N(0,0.5^2)\\).\nPer ogni campione calcola \\(b̂\\). Rappresenta l’istogramma dei 100 000 \\(b̂\\), riporta media e deviazione standard empiriche e confrontale con l’errore standard teorico.\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n1 – Definizione e scopi\n1. Previsione – modellare / predire nuove osservazioni.\n2. Esplorazione delle associazioni – quantificare relazioni \\(X \\rightarrow Y\\).\n3. Estrapolazione – generalizzare dal campione alla popolazione.\n4. Inferenza causale – stimare l’effetto di un intervento quando il design lo consente.\n2 – Errore di specificazione\nOmettere un predittore rilevante ⇒ i residui assorbono la sua varianza ⇒ stime di \\(b\\) distorte (bias) e varianze sottostimate → inferenze non valide.\n3 – Stima del modello\n\nlibrary(rio); library(here)\nkidiq &lt;- import(here(\"data\",\"kidiq.dta\"))\n\nmod &lt;- lm(kid_score ~ mom_iq, data = kidiq)\ncoef(mod)\n#&gt; (Intercept)      mom_iq \n#&gt;       25.80        0.61\n\nEsempio di output\n(Intercept)     mom_iq \n 25.800        0.610 \n4 – Interpretazione della pendenza\nUn punto in più di QI materno è associato, in media, a 0.61 punti di QI del figlio.\n5 – Indice R²\n\nsummary(mod)$r.squared\n#&gt; [1] 0.201\n\nOutput ≈ 0.20 ⇒ il 20 % della varianza di kid_score è spiegato da mom_iq.\n6 – Centratura\n\nkidiq$mom_iq_c &lt;- kidiq$mom_iq - mean(kidiq$mom_iq)\nmod_c &lt;- lm(kid_score ~ mom_iq_c, data = kidiq)\ncoef(mod_c)\n#&gt; (Intercept)    mom_iq_c \n#&gt;       86.80        0.61\n\nL’intercetta ora ≈ media del QI dei bambini quando il QI materno è medio.\nLa pendenza resta 0.61.\n7 – Calcolo manuale di b\n\nb_manual &lt;- cov(kidiq$mom_iq, kidiq$kid_score) / var(kidiq$mom_iq)\nall.equal(b_manual, coef(mod)[\"mom_iq\"])\n#&gt; [1] \"names for current but not for target\"\n\nTRUE → concordanza perfetta (salvo arrotondamenti).\n8 – σ̂ vs σ_CV\n\n# (a) σ̂\nsigma_hat &lt;- summary(mod)$sigma\n\n# (b) LOOCV\nn &lt;- nrow(kidiq)\nres_cv2 &lt;- numeric(n)\nfor (i in seq_len(n)){\n  fit_i &lt;- lm(kid_score ~ mom_iq, data = kidiq[-i,])\n  res_cv2[i] &lt;- (kidiq$kid_score[i] - predict(fit_i, kidiq[i,]))^2\n}\nsigma_CV &lt;- sqrt(mean(res_cv2))\n\nc(sigma_hat = sigma_hat, sigma_CV = sigma_CV)\n#&gt; sigma_hat  sigma_CV \n#&gt;     18.27     18.31\n\nσ_CV tende a superare σ̂ perché ogni predizione è fatta su dati che non hanno “visto” quell’osservazione → niente sovradimensionamento.\n9 – Assunzioni Gauss‑Markov\n1. Linearità nei parametri\n2. Campionamento casuale IID\n3. Esogeneità \\(E(\\varepsilon_i\\!\\mid X_i)=0\\) ← questa garantisce non‑distorsione\n4. Omoschedasticità\n5. Assenza di collinearità perfetta\n10 – Simulazione\n\nset.seed(123)\nbeta  &lt;- 1.5; sigma_e &lt;- 0.5; n  &lt;- 30; nrep &lt;- 1e5\nx &lt;- rnorm(n)\nb_hat &lt;- replicate(nrep, {\n  y &lt;- beta * x + rnorm(n, sd = sigma_e)\n  cov(x,y) / var(x)\n})\n\nmean_emp &lt;- mean(b_hat)\nsd_emp   &lt;- sd(b_hat)\nse_theo  &lt;- sqrt(sigma_e^2 / sum((x - mean(x))^2))\nc(media_empirica = mean_emp, sd_empirica = sd_emp, SE_teorico = se_theo)\n#&gt; media_empirica    sd_empirica     SE_teorico \n#&gt;        1.50006        0.09477        0.09464\n\nL’istogramma (codice sotto) mostra la forma quasi normale centrata su 1.5.\n\nhist(b_hat, breaks = 60, freq = FALSE, main = \"Distribuzione campionaria di b̂\",\n     xlab = \"b̂\"); curve(dnorm(x, mean_emp, sd_emp), add = TRUE, lwd = 2)\n\n\n\n\n\n\n\n- La media empirica ≈ 1.5 ⇒ unbiased.\n- La sd empirica ≈ SE teorico ⇒ formula varianza confermata.\n- Distribuzione simmetrica ≈ Normale ⇒ normalità asintotica verificata.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/01_reglin_frequentist.html#informazioni-sullambiente-di-sviluppo",
    "title": "61  La regressione lineare bivariata: un approccio frequentista",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] broom_1.0.8      thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0\n#&gt;  [5] see_0.11.0       gridExtra_2.3    patchwork_1.3.0  bayesplot_1.12.0\n#&gt;  [9] psych_2.5.3      scales_1.4.0     markdown_2.0     knitr_1.50      \n#&gt; [13] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [17] purrr_1.0.4      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [21] ggplot2_3.5.2    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.4     stringi_1.8.7      lattice_0.22-7    \n#&gt;  [4] hms_1.1.3          digest_0.6.37      magrittr_2.0.3    \n#&gt;  [7] evaluate_1.0.3     grid_4.5.0         timechange_0.3.0  \n#&gt; [10] RColorBrewer_1.1-3 fastmap_1.2.0      Matrix_1.7-3      \n#&gt; [13] R.oo_1.27.1        rprojroot_2.0.4    jsonlite_2.0.0    \n#&gt; [16] R.utils_2.13.0     backports_1.5.0    mgcv_1.9-3        \n#&gt; [19] mnormt_2.1.1       cli_3.6.5          rlang_1.1.6       \n#&gt; [22] R.methodsS3_1.8.2  splines_4.5.0      withr_3.0.2       \n#&gt; [25] tools_4.5.0        parallel_4.5.0     tzdb_0.5.0        \n#&gt; [28] pacman_0.5.1       vctrs_0.6.5        R6_2.6.1          \n#&gt; [31] lifecycle_1.0.4    htmlwidgets_1.6.4  pkgconfig_2.0.3   \n#&gt; [34] pillar_1.10.2      gtable_0.3.6       glue_1.8.0        \n#&gt; [37] haven_2.5.4        xfun_0.52          tidyselect_1.2.1  \n#&gt; [40] rstudioapi_0.17.1  farver_2.1.2       htmltools_0.5.8.1 \n#&gt; [43] nlme_3.1-168       labeling_0.4.3     rmarkdown_2.29    \n#&gt; [46] compiler_4.5.0",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#bibliografia",
    "href": "chapters/linear_models/01_reglin_frequentist.html#bibliografia",
    "title": "61  La regressione lineare bivariata: un approccio frequentista",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlter, U., Too, M. A., & Cribbie, R. A. (2025). Navigating the Bayes maze: The psychologist’s guide to Bayesian statistics, a hands-on tutorial with R code. International Journal of Psychology, 60(1), e13271.\n\n\nCaudek, C., & Luccio, R. (2001). Statistica per psicologi (III rist. 2023, Vol. 11, p. 320). Laterza.\n\n\nFox, J. (2015). Applied regression analysis and generalized linear models. Sage publications.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:\n\n\nStigler, S. (1986). The History of Statistics. Belknap Harvard.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#footnotes",
    "href": "chapters/linear_models/01_reglin_frequentist.html#footnotes",
    "title": "61  La regressione lineare bivariata: un approccio frequentista",
    "section": "",
    "text": "Per un approfondimento sull’approccio frequentista alla regressione, si veda, per esempio, Caudek & Luccio (2001).↩︎",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_regr_toward_mean.html",
    "href": "chapters/linear_models/02_regr_toward_mean.html",
    "title": "62  La regressione verso la media",
    "section": "",
    "text": "62.1 Introduzione\nIl concetto di regressione verso la media è stato introdotto da Francis Galton, un pioniere della statistica, mentre studiava la trasmissione ereditaria di tratti fisici, in particolare l’altezza. Galton osservò che, quando si confronta l’altezza dei padri con quella dei figli, i figli tendono ad essere più vicini alla media della popolazione rispetto ai loro padri. Questo fenomeno è noto come regressione verso la media.\nImmaginiamo di avere un padre che è più alto della media della popolazione. Ci aspettiamo che suo figlio sia anch’esso più alto della media, ma non tanto quanto il padre. In altre parole, l’altezza del figlio “regredisce” parzialmente verso la media della popolazione. Lo stesso principio si applica ai padri più bassi della media: i loro figli tenderanno ad essere più bassi della media, ma non tanto quanto i padri.\nPerché succede? Quando un padre è alto 75 pollici (mentre la media magari è 69.1), essere così alto potrebbe essere dovuto a molti fattori “eccezionali” combinati (genetici, ambientali, casuali). Il figlio, tuttavia, eredita solo una parte di quei fattori, e probabilmente avrà altri fattori (positivi o negativi) in modo casuale, cosicché la sua altezza si sposta verso la media della popolazione. Questo non vuol dire che il figlio sia basso: rimane comunque al di sopra della media, ma non raggiunge l’estremo del padre.\nIl cuore statistico del fenomeno si trova nella correlazione tra due variabili (in questo caso, altezza del padre e altezza del figlio). Se la correlazione fosse 1 (perfetta), un padre alto in modo eccezionale avrebbe sempre un figlio proporzionalmente alto, senza “riavvicinarsi” alla media. Se invece la correlazione è minore di 1, come succede quasi sempre nel mondo reale, la relazione padre-figlio non è perfetta e vi è una certa variabilità.\nGalton misurò in media una correlazione di circa 0.5 tra altezza paterna e altezza del figlio maschio. Questo valore implica che, se un padre si discosta di 2-3 deviazioni standard sopra la media, il figlio di solito ne recupererà una parte, ma non interamente.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>La regressione verso la media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_regr_toward_mean.html#introduzione",
    "href": "chapters/linear_models/02_regr_toward_mean.html#introduzione",
    "title": "62  La regressione verso la media",
    "section": "",
    "text": "62.1.1 I Dati di Galton\nEsaminiamo il fenomeno della regressione verso la media usando i dati di Galton. Nel pacchetto HistData di R sono disponibili i dati originali raccolti da Galton, che includono informazioni sull’altezza di padri, madri, figli maschi e femmine. Per semplificare l’analisi, possiamo creare un dataset che include solo l’altezza del padre e l’altezza di un figlio maschio scelto casualmente da ogni famiglia:\n\nset.seed(1234)\n\ngalton_heights &lt;- GaltonFamilies |&gt;\n  filter(gender == \"male\") |&gt;\n  group_by(family) |&gt;\n  sample_n(1) |&gt;\n  ungroup() |&gt;\n  select(father, childHeight) |&gt;\n  rename(son = childHeight)\n\nQuesto dataset contiene due colonne: father (altezza del padre) e son (altezza del figlio maschio). Calcolando la media e la deviazione standard delle altezze dei padri e dei figli, otteniamo:\n\ngalton_heights |&gt; \n  summarize(\n    mean_father = mean(father), \n    sd_father   = sd(father),\n    mean_son    = mean(son), \n    sd_son      = sd(son)\n  )\n#&gt; # A tibble: 1 × 4\n#&gt;   mean_father sd_father mean_son sd_son\n#&gt;         &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1        69.1      2.55     69.1   2.62\n\nI risultati mostrano che, in media, i padri e i figli hanno altezze simili, anche se le distribuzioni non sono identiche. Un grafico di dispersione (scatterplot) evidenzia una chiara tendenza: padri più alti tendono ad avere figli più alti:\n\ngalton_heights |&gt;\n  ggplot(aes(father, son)) +\n  geom_point(alpha = 0.5)\n\n\n\n\n\n\n\n\n62.1.2 Il Coefficiente di Correlazione\nPer quantificare la relazione lineare tra l’altezza del padre e quella del figlio, utilizziamo il coefficiente di correlazione (indicato con \\(r\\) o \\(\\rho\\)). La formula del coefficiente di correlazione è:\n\\[\n\\rho = \\frac{1}{n}\\sum_{i=1}^n\n\\left(\\frac{x_i - \\mu_x}{\\sigma_x}\\right)\n\\left(\\frac{y_i - \\mu_y}{\\sigma_y}\\right).\n\\]\nIn R, possiamo calcolare la correlazione tra l’altezza del padre e quella del figlio con il seguente codice:\n\ngalton_heights |&gt; \n  summarize(r = cor(father, son)) |&gt; \n  pull(r)\n#&gt; [1] 0.4434\n\nNel nostro caso, la correlazione è circa 0.5. Questo valore positivo indica che padri più alti tendono ad avere figli più alti, ma la correlazione non è perfetta. Il coefficiente di correlazione varia tra -1 e 1, dove il valore assoluto misura la forza della relazione lineare.\n\n62.1.3 Stime Condizionate: Previsioni basate sull’Altezza del Padre\nUn modo per fare previsioni è chiedersi: “Se un padre è alto 72 pollici, quale sarà l’altezza media dei figli di tutti i padri di 72 pollici?” In termini statistici, questa è l’aspettativa condizionata \\(\\mathbb{E}(\\text{altezza figlio} \\mid \\text{altezza padre} = 72)\\).\n\nSe filtriamo i dati prendendo solo i padri di altezza 72 pollici, possiamo calcolare la media dell’altezza dei figli in quel sottogruppo.\nTuttavia, questo metodo può essere instabile se il numero di osservazioni nel sottogruppo è piccolo.\n\nAd esempio:\n\ngalton_heights |&gt; \n  filter(round(father) == 72) |&gt;\n  summarize(avg_son = mean(son))\n#&gt; # A tibble: 1 × 1\n#&gt;   avg_son\n#&gt;     &lt;dbl&gt;\n#&gt; 1    70.2\n\nQuesto ci dà la stima condizionata dell’altezza media del figlio di un padre di 72 pollici. Spesso, questa media è maggiore della media generale dei figli, ma meno di quanto il padre (72 pollici) sia sopra la media dei padri. Questo fenomeno è noto come regressione verso la media.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>La regressione verso la media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_regr_toward_mean.html#visualizzare-la-regressione-verso-la-media",
    "href": "chapters/linear_models/02_regr_toward_mean.html#visualizzare-la-regressione-verso-la-media",
    "title": "62  La regressione verso la media",
    "section": "\n62.2 Visualizzare la Regressione verso la Media",
    "text": "62.2 Visualizzare la Regressione verso la Media\nRipetiamo ora lo stesso procedimento per tutti i dati. Stratifichiamo i dati raggruppadoli in base a valori simili di altezza del padre. Calcoliamo poi in ogni gruppo la media dell’altezza del figlio:\n\ngalton_heights |&gt;\n  mutate(father_strata = factor(round(father))) |&gt;\n  group_by(father_strata) |&gt;\n  summarize(avg_son = mean(son)) |&gt;\n  ggplot(aes(x = father_strata, y = avg_son)) +\n  geom_point()\n\n\n\n\n\n\n\nNel grafico risultante, ogni punto rappresenta la media dei figli corrispondenti a un determinato “strato” di padri. Se tracciamo anche la retta di regressione, noteremo che i punti si dispongono in modo approssimativamente lineare: a padri più alti corrispondono figli più alti, ma in media meno alti di quanto ci si aspetterebbe se la correlazione fosse perfetta.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>La regressione verso la media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_regr_toward_mean.html#la-retta-di-regressione",
    "href": "chapters/linear_models/02_regr_toward_mean.html#la-retta-di-regressione",
    "title": "62  La regressione verso la media",
    "section": "\n62.3 La Retta di Regressione",
    "text": "62.3 La Retta di Regressione\nPer capire perché, dal punto di vista statistico, si verifica la regressione verso la media, consideriamo il modello di regressione lineare semplice che prevede l’altezza del figlio \\(\\hat{Y}\\) in base all’altezza del padre \\(X\\):\n\\[\n\\hat{Y} = \\beta_0 + \\beta_1 X.\n\\]\n\nQuando standardizziamo i dati (cioè trasformiamo sia \\(X\\) sia \\(Y\\) in “punti z”, sottraendo la media e dividendo per la deviazione standard), la pendenza \\(\\beta_1\\) della retta di regressione diventa esattamente la correlazione \\(\\rho\\).\n\nSe \\(\\rho = 1\\), la pendenza sarebbe 1 e non ci sarebbe alcun “riavvicinamento” alla media: i valori alti di \\(X\\) corrisponderebbero a valori altrettanto alti di \\(Y\\).\n\nSe \\(\\rho &lt; 1\\), la pendenza risulta minore di 1 e ciò significa che, partendo da un valore molto alto (o molto basso) di \\(X\\), la nostra previsione di \\(Y\\) si colloca in una posizione parzialmente più vicina alla media di \\(Y\\) rispetto alla distanza del padre dalla media di \\(X\\). È proprio questo il fenomeno della regressione verso la media.\n\n\n62.3.1 Forma non standardizzata\nNella forma originale (non standardizzata), i coefficienti si calcolano con:\n\\[\n\\beta_1\n= \\rho \\,\\frac{\\sigma_Y}{\\sigma_X},\n\\quad\n\\beta_0\n= \\mu_Y\n- \\beta_1 \\,\\mu_X,\n\\]\ndove:\n\n\n\\(\\mu_X, \\mu_Y\\) sono le medie di \\(X\\) (altezza del padre) e \\(Y\\) (altezza del figlio);\n\n\\(\\sigma_X, \\sigma_Y\\) sono le rispettive deviazioni standard;\n\n\\(\\rho\\) è la correlazione tra \\(X\\) e \\(Y\\).\n\n62.3.2 Forma standardizzata\nNella forma standardizzata, le deviazioni standard di \\(X\\) e \\(Y\\) sono pari a 1 e i coefficienti di regressione diventano:\n\\[\n\\beta_1\n= \\rho,\n\\quad\n\\beta_0\n= 0,\n\\]\ndato che le medie di \\(X\\) e \\(Y\\) sono uguali a zero.\n\n62.3.3 Regressione Verso la Media\nNe segue dunque che, se la correlazione tra le variabili è minore di 1, si verificherà necessariamente il fenomeno della regressione verso la media.\nIn R, possiamo stimare la retta di regressione tramite la stima dei minimi quadrati:\n\nfit &lt;- lm(son ~ father, data = galton_heights)\nfit$coefficients\n#&gt; (Intercept)      father \n#&gt;     37.6324      0.4559\n\nLa funzione lm calcola gli stimatori \\(\\hat{\\beta}_0\\) e \\(\\hat{\\beta}_1\\) che minimizzano la somma dei quadrati degli scarti:\n\\[\n\\text{RSS} = \\sum_{i} \\left[y_i - (\\beta_0 + \\beta_1 x_i)\\right]^2.\n\\]\nPossiamo quindi tracciare la retta sullo scatterplot dei dati:\n\ngalton_heights |&gt;\n  ggplot(aes(father, son)) +\n  geom_point(alpha = 0.5) +\n  geom_abline(\n    slope = coef(fit)[2], \n    intercept = coef(fit)[1],\n    color = \"blue\"\n  )\n\n\n\n\n\n\n\nSe standardizziamo i dati, la pendenza della retta di regressione diventa uguale alla correlazione:\n\nfit_2 &lt;- lm(scale(son) ~ scale(father), data = galton_heights)\nfit_2$coefficients\n#&gt;   (Intercept) scale(father) \n#&gt;    -7.598e-15     4.434e-01\n\n\ngalton_heights |&gt;\n  ggplot(aes(scale(father), scale(son))) +\n  geom_point(alpha = 0.5) +\n  geom_abline(\n    slope = coef(fit_2)[2], \n    intercept = coef(fit_2)[1],\n    color = \"blue\"\n  )\n\n\n\n\n\n\n\nIl punto cruciale è ricordare che la pendenza \\(\\beta_1\\) è proporzionale alla correlazione \\(\\rho\\). Se la correlazione non è perfetta (\\(\\rho &lt; 1\\)), allora qualsiasi previsione basata su \\(X\\) (ad esempio, l’altezza del padre) risulterà meno estrema di quanto sia \\(X\\) stesso rispetto alla sua media. In altre parole, un padre altissimo (molto sopra la media) avrà, in media, un figlio sopra la media ma non altrettanto estremo, “regredendo” parzialmente verso il centro della distribuzione.\nIn sintesi: la correlazione imperfetta (\\(\\rho &lt; 1\\)) è la ragione principale per cui un valore estremo di \\(X\\) (ad esempio, un padre molto alto) porta a un valore \\(\\hat{Y}\\) che è sì superiore (o inferiore) alla media, ma meno estremo del padre. Questo “ritorno verso il centro” è ciò che chiamiamo regressione verso la media.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>La regressione verso la media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_regr_toward_mean.html#riflessioni-conclusive",
    "href": "chapters/linear_models/02_regr_toward_mean.html#riflessioni-conclusive",
    "title": "62  La regressione verso la media",
    "section": "\n62.4 Riflessioni Conclusive",
    "text": "62.4 Riflessioni Conclusive\n\n\nGalton scoprì il fenomeno della regressione verso la media studiando l’altezza di padri e figli: un padre più alto della media tenderà ad avere un figlio più alto della media, ma non tanto quanto ci si aspetterebbe se la correlazione fosse perfetta.\nQuesto concetto è generale e applicabile in molti contesti. Spesso, un apparente “calo” o “miglioramento” delle prestazioni è semplicemente un effetto statistico di regressione verso la media, non un effetto causale.\nLa retta di regressione minimizza la somma dei quadrati degli errori e la sua pendenza è legata alla correlazione \\(\\rho\\) e al rapporto tra le deviazioni standard \\(\\sigma_Y\\) e \\(\\sigma_X\\).\n\nIn sintesi, la regressione verso la media è un fenomeno statistico che spiega perché, in media, i valori estremi tendono a “ritornare” verso la media della popolazione. Questo concetto è fondamentale per interpretare correttamente i dati e evitare errori di interpretazione causati da correlazioni imperfette.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>La regressione verso la media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_regr_toward_mean.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/02_regr_toward_mean.html#informazioni-sullambiente-di-sviluppo",
    "title": "62  La regressione verso la media",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] HistData_0.9-3   thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0\n#&gt;  [5] see_0.11.0       gridExtra_2.3    patchwork_1.3.0  bayesplot_1.12.0\n#&gt;  [9] psych_2.5.3      scales_1.4.0     markdown_2.0     knitr_1.50      \n#&gt; [13] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [17] purrr_1.0.4      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [21] ggplot2_3.5.2    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.4     stringi_1.8.7      lattice_0.22-7    \n#&gt;  [4] hms_1.1.3          digest_0.6.37      magrittr_2.0.3    \n#&gt;  [7] evaluate_1.0.3     grid_4.5.0         timechange_0.3.0  \n#&gt; [10] RColorBrewer_1.1-3 fastmap_1.2.0      rprojroot_2.0.4   \n#&gt; [13] jsonlite_2.0.0     mnormt_2.1.1       cli_3.6.5         \n#&gt; [16] rlang_1.1.6        withr_3.0.2        tools_4.5.0       \n#&gt; [19] parallel_4.5.0     tzdb_0.5.0         pacman_0.5.1      \n#&gt; [22] vctrs_0.6.5        R6_2.6.1           lifecycle_1.0.4   \n#&gt; [25] htmlwidgets_1.6.4  pkgconfig_2.0.3    pillar_1.10.2     \n#&gt; [28] gtable_0.3.6       glue_1.8.0         xfun_0.52         \n#&gt; [31] tidyselect_1.2.1   rstudioapi_0.17.1  farver_2.1.2      \n#&gt; [34] htmltools_0.5.8.1  nlme_3.1-168       labeling_0.4.3    \n#&gt; [37] rmarkdown_2.29     compiler_4.5.0",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>La regressione verso la media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_regr_toward_mean.html#bibliografia",
    "href": "chapters/linear_models/02_regr_toward_mean.html#bibliografia",
    "title": "62  La regressione verso la media",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>La regressione verso la media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html",
    "href": "chapters/linear_models/03_reglin_bayes.html",
    "title": "63  Modello bayesiano di regressione lineare bivariata",
    "section": "",
    "text": "63.1 Introduzione\nIn questa sezione della dispensa esploreremo il modello di regressione lineare bivariata (cioè con una sola variabile indipendente), ponendo particolare attenzione alla formulazione bayesiana. Confronteremo questo approccio con quello frequentista, così da mettere in luce i principali vantaggi dell’inferenza bayesiana, senza introdurre tecnicismi inutilmente complessi. Il nostro obiettivo comprendere come si costruisce un modello di regressione e come si interpretano i risultati nel contesto dell’incertezza.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#il-modello-di-regressione-lineare-semplice",
    "href": "chapters/linear_models/03_reglin_bayes.html#il-modello-di-regressione-lineare-semplice",
    "title": "63  Modello bayesiano di regressione lineare bivariata",
    "section": "\n63.2 Il modello di regressione lineare semplice",
    "text": "63.2 Il modello di regressione lineare semplice\nSupponiamo di voler prevedere una variabile quantitativa \\(y\\) (per esempio, il livello di ansia) a partire da una variabile esplicativa \\(x\\) (per esempio, il numero di ore di sonno). Il modello di regressione lineare assume che la relazione tra le due variabili sia descritta da:\n\\[\ny_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i\n\\]\ndove:\n\n\n\\(\\beta_0\\) è l’intercetta (valore medio di \\(y\\) quando \\(x = 0\\)),\n\n\\(\\beta_1\\) è il coefficiente di regressione (quanto cambia \\(y\\) per ogni unità di aumento di \\(x\\)),\n\n\\(\\varepsilon_i\\) è un termine di errore casuale, che tiene conto delle deviazioni impreviste rispetto alla linea di regressione.\n\nAssumiamo che gli errori \\(\\varepsilon_i\\) siano indipendenti e distribuiti normalmente con media zero e varianza costante \\(\\sigma^2\\). Questo implica che anche i valori di \\(y_i\\), condizionati ai rispettivi \\(x_i\\), seguano una distribuzione normale:\n\\[\ny_i \\sim \\mathcal{N}(\\mu_i, \\sigma^2), \\quad \\text{con} \\quad \\mu_i = \\beta_0 + \\beta_1 x_i .\n\\]",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#cosè-la-verosimiglianza",
    "href": "chapters/linear_models/03_reglin_bayes.html#cosè-la-verosimiglianza",
    "title": "63  Modello bayesiano di regressione lineare bivariata",
    "section": "\n63.3 Cos’è la verosimiglianza?",
    "text": "63.3 Cos’è la verosimiglianza?\nLa verosimiglianza è una funzione che misura quanto bene un certo insieme di parametri del modello (cioè \\(\\beta_0\\), \\(\\beta_1\\), \\(\\sigma\\)) riesce a spiegare i dati osservati \\((x_i, y_i)\\). Si tratta di un concetto centrale sia nell’inferenza frequentista sia in quella bayesiana.\nNel nostro caso, la probabilità di osservare un dato \\(y_i\\) condizionato a \\(x_i\\) è data dalla densità di una normale. Assumendo che tutte le osservazioni siano indipendenti, la funzione di verosimiglianza congiunta si ottiene moltiplicando le densità per ciascuna osservazione:\n\\[\n\\mathcal{L}(\\beta_0, \\beta_1, \\sigma \\mid \\mathbf{y}, \\mathbf{x}) = \\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi \\sigma^2}} \\exp\\left(-\\frac{(y_i - \\beta_0 - \\beta_1 x_i)^2}{2\\sigma^2}\\right) .\n\\]\nPoiché lavorare con prodotti può essere complicato, spesso si usa la log-verosimiglianza, che trasforma i prodotti in somme:\n\\[\n\\log \\mathcal{L}(\\beta_0, \\beta_1, \\sigma \\mid \\mathbf{y}, \\mathbf{x}) = -\\frac{n}{2} \\log(2\\pi) - n \\log \\sigma - \\frac{1}{2\\sigma^2} \\sum_{i=1}^n (y_i - \\beta_0 - \\beta_1 x_i)^2 .\n\\]",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#verosimiglianza-confronto-tra-approccio-frequentista-e-bayesiano",
    "href": "chapters/linear_models/03_reglin_bayes.html#verosimiglianza-confronto-tra-approccio-frequentista-e-bayesiano",
    "title": "63  Modello bayesiano di regressione lineare bivariata",
    "section": "\n63.4 Verosimiglianza: confronto tra approccio frequentista e bayesiano",
    "text": "63.4 Verosimiglianza: confronto tra approccio frequentista e bayesiano\n\nNell’approccio frequentista, l’obiettivo è trovare i valori dei parametri che massimizzano la verosimiglianza: è il metodo della massima verosimiglianza.\nNell’approccio bayesiano, la verosimiglianza non è sufficiente: viene combinata con una distribuzione a priori sui parametri, e il risultato è una distribuzione a posteriori che riflette sia le evidenze empiriche, sia le nostre ipotesi iniziali.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#le-distribuzioni-a-priori",
    "href": "chapters/linear_models/03_reglin_bayes.html#le-distribuzioni-a-priori",
    "title": "63  Modello bayesiano di regressione lineare bivariata",
    "section": "\n63.5 Le distribuzioni a priori",
    "text": "63.5 Le distribuzioni a priori\nUno degli aspetti distintivi del metodo bayesiano è la specificazione delle distribuzioni a priori, che riflettono ciò che si crede possibile per i parametri prima di osservare i dati. Esistono diversi tipi di priori:\n\nnon informativi, che riflettono un’assenza di conoscenza iniziale. Sono distribuzioni molto larghe o piatte, progettate per influenzare il meno possibile la distribuzione a posteriori. Un esempio è una distribuzione normale con varianza molto elevata, come \\(\\mathcal{N}(0, 1000)\\);\ndebolmente informativi, che introducono un minimo di informazione strutturale per evitare stime estreme o non plausibili. Sono particolarmente utili nei modelli complessi o quando il numero di dati è limitato. Un esempio comune è \\(\\mathcal{N}(0, 2.5)\\) per i coefficienti di regressione: consente ampio margine di variazione, ma previene valori irrealistici;\ninformativi, che riflettono una conoscenza specifica accumulata prima della raccolta dei dati, per esempio da ricerche precedenti, meta-analisi, o teorie ben consolidate. Questi priori sono più ristretti e centrati su valori considerati plausibili. Possono migliorare l’efficienza dell’inferenza, ma devono essere giustificati accuratamente per evitare di introdurre distorsioni arbitrarie.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#le-distribuzioni-a-posteriori",
    "href": "chapters/linear_models/03_reglin_bayes.html#le-distribuzioni-a-posteriori",
    "title": "63  Modello bayesiano di regressione lineare bivariata",
    "section": "\n63.6 Le distribuzioni a posteriori",
    "text": "63.6 Le distribuzioni a posteriori\nUna volta specificata:\n\nla verosimiglianza (basata sul modello e sui dati), e\nle distribuzioni a priori (che esprimono le nostre credenze iniziali),\n\nè possibile applicare il teorema di Bayes per ottenere la distribuzione a posteriori di ciascun parametro. Questa distribuzione rappresenta la nostra conoscenza aggiornata dopo aver osservato i dati.\nA differenza dell’approccio frequentista, che fornisce stime puntuali, l’approccio bayesiano restituisce intere distribuzioni, permettendo di valutare l’incertezza nei risultati (ad esempio, attraverso gli intervalli di credibilità).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#implementazione-con-brms-la-formula-di-wilkinson",
    "href": "chapters/linear_models/03_reglin_bayes.html#implementazione-con-brms-la-formula-di-wilkinson",
    "title": "63  Modello bayesiano di regressione lineare bivariata",
    "section": "\n63.7 Implementazione con brms: la formula di Wilkinson",
    "text": "63.7 Implementazione con brms: la formula di Wilkinson\nNel pacchetto brms (che usa Stan come motore di calcolo), non è necessario scrivere la funzione di verosimiglianza a mano. Basta specificare il modello nella classica forma di Wilkinson:\nbrm(y ~ x, data = dati)\nQuesta notazione compatta definisce:\n\nil modello di regressione,\nla verosimiglianza implicita,\ne consente a brms di costruire automaticamente il modello bayesiano.\n\nSe non si specificano i priori, brms utilizza prior debolmente informativi di default.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#come-vengono-stimate-le-distribuzioni-a-posteriori",
    "href": "chapters/linear_models/03_reglin_bayes.html#come-vengono-stimate-le-distribuzioni-a-posteriori",
    "title": "63  Modello bayesiano di regressione lineare bivariata",
    "section": "\n63.8 Come vengono stimate le distribuzioni a posteriori?",
    "text": "63.8 Come vengono stimate le distribuzioni a posteriori?\nPoiché la distribuzione a posteriori è spesso troppo complessa per essere calcolata esattamente, brms utilizza tecniche di campionamento numerico chiamate MCMC (Markov Chain Monte Carlo).\nIn particolare, utilizza l’algoritmo NUTS (No-U-Turn Sampler), una variante evoluta dell’algoritmo di Metropolis-Hastings, che esplora lo spazio dei parametri in modo efficiente e adattivo. Grazie a questo, otteniamo campioni dalla distribuzione a posteriori, dai quali è possibile calcolare medie, intervalli di credibilità e fare previsioni.\nIn sintesi, il modello di regressione bayesiano consente di incorporare in modo trasparente incertezze, conoscenze pregresse e informazioni contenute nei dati. Rispetto all’approccio classico, non restituisce una singola stima puntuale ma un’intera distribuzione per ogni parametro. Questo permette inferenze più flessibili e più ricche di informazioni, particolarmente utili nelle scienze psicologiche, dove l’incertezza è la regola più che l’eccezione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#un-esempio-concreto",
    "href": "chapters/linear_models/03_reglin_bayes.html#un-esempio-concreto",
    "title": "63  Modello bayesiano di regressione lineare bivariata",
    "section": "\n63.9 Un Esempio Concreto",
    "text": "63.9 Un Esempio Concreto\nDefiniamo i parametri e simuliamo i dati.\n\nset.seed(123)\n\n# Definizione delle variabili\nx &lt;- 1:100\nn &lt;- length(x)\na &lt;- 1.5\nb &lt;- 0.5\nsigma &lt;- 10\n\n# Generazione di y\ny &lt;- a + b * x + rnorm(n, 0, sigma)\n\n# Creazione del dataframe\nfake &lt;- tibble(x = x, y = y)\nhead(fake)\n#&gt; # A tibble: 6 × 2\n#&gt;       x      y\n#&gt;   &lt;int&gt;  &lt;dbl&gt;\n#&gt; 1     1 -3.60 \n#&gt; 2     2  0.198\n#&gt; 3     3 18.6  \n#&gt; 4     4  4.21 \n#&gt; 5     5  5.29 \n#&gt; 6     6 21.7\n\nIniziamo adattando ai dati un modello frequentista:\n\nfm1 &lt;- lm(y ~ x, data = fake)\n\n\nsummary(fm1)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = y ~ x, data = fake)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -24.536  -5.524  -0.346   6.485  20.949 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)\n#&gt; (Intercept)   1.1360     1.8429    0.62     0.54\n#&gt; x             0.5251     0.0317   16.57   &lt;2e-16\n#&gt; \n#&gt; Residual standard error: 9.15 on 98 degrees of freedom\n#&gt; Multiple R-squared:  0.737,  Adjusted R-squared:  0.734 \n#&gt; F-statistic:  275 on 1 and 98 DF,  p-value: &lt;2e-16\n\nPer ottenere l’intervallo di confidenza (nel senso frequentista) della stima dei parametri usiamo:\n\nconfint(fm1, level = 0.95)\n#&gt;               2.5 % 97.5 %\n#&gt; (Intercept) -2.5212  4.793\n#&gt; x            0.4622  0.588\n\nAdattiamo ora ai dati un modello di regressione bayesiano utilizzando brms. Si noti che, anche in questo caso, usiamo la sintassi di Wilkinson y ~ x, come per lm(). Eseguiamo il campionamento:\n\nfm2 &lt;- brm(\n  y ~ x, \n  data = fake,\n  backend = \"cmdstanr\"\n)\n\nCome discusso nell’analisi dell’algoritmo di Metropolis, il primo passo è esaminare le tracce dei parametri per verificare la convergenza dell’algoritmo. La convergenza può essere considerata raggiunta se le catene (nel caso di brm, sono 4 per impostazione predefinita) risultano ben mescolate. Questo si manifesta in un trace plot che mostra una distribuzione uniforme e casuale dei campioni attorno a un valore centrale, senza pattern evidenti o tendenze sistematiche.\nLe tracce dei parametri si ottengono nel modo seguente:\n\nmcmc_trace(\n  fm2, \n  pars = c(\"b_Intercept\", \"b_x\", \"sigma\"),\n  facet_args = list(nrow = 3)\n)\n\n\n\n\n\n\n\nGli istogrammi delle distribuzioni a posteriori dei parametri si generano nel modo seguente:\n\nmcmc_hist(\n  fm2, \n  pars =c(\"b_Intercept\", \"b_x\", \"sigma\"),\n  facet_args = list(nrow = 3)\n)\n\n\n\n\n\n\n\nPer valutare l’autocorrelazione tra i campioni a posteriori del parametro beta, possiamo utilizzare il seguente comando:\n\nmcmc_acf(fm2, \"b_x\")\n\n\n\n\n\n\n\nL’autocorrelazione fornisce informazioni sulla dipendenza tra campioni successivi nella catena di Markov. È normale che i campioni successivi non siano completamente indipendenti, poiché le catene di Markov generano campioni correlati per costruzione. Tuttavia, se l’algoritmo ha raggiunto la convergenza, l’autocorrelazione dovrebbe diminuire rapidamente e diventare trascurabile dopo un numero relativamente piccolo di lag. Questo significa che, dopo un certo numero di passi, i campioni diventano progressivamente meno correlati tra loro, comportandosi in modo simile a campioni indipendenti estratti dalla distribuzione target.\nUn’elevata autocorrelazione su lag più lunghi potrebbe invece indicare problemi di mescolamento delle catene o una mancata convergenza, richiedendo ulteriori verifiche o aggiustamenti, come l’aumento del numero di iterazioni o una diversa parametrizzazione del modello.\nNel caso presente, notiamo una rapida diminuzione dell’autocorrelazione in funzione del numero di passi. Ciò è indicativo del fatto che la convergenza è stata raggiunta.\nUna sintesi numerica dei risultati si trova nel modo seguente:\n\nsummary(fm2)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: y ~ x \n#&gt;    Data: fake (Number of observations: 100) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept     1.11      1.85    -2.55     4.77 1.00     3976     2968\n#&gt; x             0.53      0.03     0.46     0.59 1.00     4028     3041\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     9.26      0.69     7.99    10.75 1.00     3753     3097\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nConfrontiamo le stime ottenute con i valori reali dei parametri simulati. L’intercetta è stata stimata attorno a 1.14, con un’incertezza al 95% che varia tra -2.4 e 4.8. Questo risultato rientra negli intervalli di credibilità previsti, confermando l’accuratezza del modello. Analogamente, per la pendenza \\(b\\), l’intervallo di credibilità al 95% include il valore reale simulato, dimostrando come le stime bayesiane riflettano accuratamente l’incertezza sui parametri.\nSe si utilizza la funzione conditional_effects() viene prodotto un grafico che rappresenta la relazione stimata tra il predittore \\(x\\) e la variabile di risposta \\(y\\).\n\nconditional_effects(fm2) |&gt;\n  plot(points = TRUE)\n\n\n\n\n\n\n\n\n\nLinea stimata (effetto medio):\n\nLa linea centrale del grafico rappresenta il valore medio previsto di \\(y\\) per ogni valore di \\(x\\), dato dalla relazione \\(y = \\alpha + \\beta x\\).\nQuesta linea è calcolata usando i valori medi a posteriori stimati per \\(\\alpha\\) e \\(\\beta\\).\n\n\n\nBande di incertezza (intervalli di credibilità):\n\nLe bande attorno alla linea rappresentano gli intervalli di credibilità (ad esempio, al 95%). Questi mostrano l’incertezza associata alle stime del modello per ogni valore di \\(x\\).\nPiù strette sono le bande, maggiore è la certezza del modello riguardo alla relazione stimata.\n\n\n\nDati osservati:\n\nI punti rappresentano i valori effettivi di \\(y\\) osservati nei dati. Questo consente di confrontare visivamente come i dati reali si allineano con le previsioni del modello.\n\n\n\nIl grafico consente\n\nuna verifica visiva della relazione stimata tra \\(y\\) e \\(x\\);\ndi identificazione di eventuali discrepanze tra i dati osservati e le previsioni del modello;\nuna rappresentazione dell’incertezza nelle stime.\n\nAd esempio, il grafico può mostrare se \\(x\\) ha un effetto credibile su \\(y\\) e con quale livello di incertezza. Se l’effetto di \\(x\\) è debole o nullo, la linea stimata sarà piatta (vicina a zero) e le bande di incertezza saranno ampie.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#simulazione-di-livelli-di-copertura",
    "href": "chapters/linear_models/03_reglin_bayes.html#simulazione-di-livelli-di-copertura",
    "title": "63  Modello bayesiano di regressione lineare bivariata",
    "section": "\n63.10 Simulazione di Livelli di Copertura",
    "text": "63.10 Simulazione di Livelli di Copertura\nVerifichiamo la copertura degli intervalli di credibilità al 95% attraverso simulazioni ripetute.\n\nset.seed(42)\n# Parametri veri\na_true &lt;- 0.2\nb_true &lt;- 0.3\nsigma_true &lt;- 0.5\n# Numero di simulazioni\nnum_simulations &lt;- 100\n# Conteggio delle coperture\ncoverage_a &lt;- 0\ncoverage_b &lt;- 0\nfor (i in 1:num_simulations) {\n  # Generazione dei dati\n  x &lt;- 1:20\n  y &lt;- a_true + b_true * x + sigma_true * rnorm(length(x))\n  # Adattamento del modello\n  fit &lt;- lm(y ~ x)\n  ci &lt;- confint(fit) # Intervalli di confidenza\n  # Verifica delle coperture\n  if (ci[1,1] &lt;= a_true & ci[1, 2] &gt;= a_true) {\n    coverage_a &lt;- coverage_a + 1\n  }\n  if (ci[2,1] &lt;= b_true & ci[2, 2] &gt;= b_true) {\n    coverage_b &lt;- coverage_b + 1\n  }\n}\n\n\n# Risultati\ncat(\"Coverage for a:\", coverage_a / num_simulations, \"\\n\")\n#&gt; Coverage for a: 0.93\ncat(\"Coverage for b:\", coverage_b / num_simulations, \"\\n\")\n#&gt; Coverage for b: 0.96\n\nI risultati indicano che i livelli di copertura empirici ottenuti con l’approccio frequentista corrispondono strettamente ai livelli teorici attesi.\nPer proseguire, ripeteremo la simulazione adottando un approccio bayesiano. Useremo la funzione brm() del pacchetto brms al posto di lm().\n#| message: false\n#| warning: false\n#| output: false\n#| \nset.seed(23)\nn_fake   &lt;- 100\ncover_68 &lt;- logical(n_fake)\ncover_95 &lt;- logical(n_fake)\n\n# Veri parametri\na     &lt;- 0.2    # intercetta vera\nb     &lt;- 0.3    # pendenza vera\nsigma &lt;- 0.5    # deviazione standard vera\nx     &lt;- 1:20\nn     &lt;- length(x)\n\n# Priors con set_prior \npriors &lt;- c(\n  set_prior(\"normal(0, 2.5)\", class = \"Intercept\"),\n  set_prior(\"normal(0, 2.5)\", class = \"b\", coef = \"x\"),\n  set_prior(\"cauchy(0, 2.5)\", class = \"sigma\")\n)\n\nset.seed(23)\nn_fake   &lt;- 1000\ncover_68 &lt;- logical(n_fake)\ncover_95 &lt;- logical(n_fake)\n\na     &lt;- 0.2\nb     &lt;- 0.3\nsigma &lt;- 0.5\nx     &lt;- 1:20\nn     &lt;- length(x)\n\nfor (s in seq_len(n_fake)) {\n  y    &lt;- a + b * x + rnorm(n, 0, sigma)\n  fake &lt;- data.frame(x = x, y = y)\n\n  fit &lt;- brm(\n    y ~ 1 + x,\n    data    = fake,\n    family  = gaussian(),\n    prior   = priors,\n    iter    = 2000,\n    chains  = 2,\n    refresh = 0,\n    backend = \"cmdstanr\"\n  )\n\n  post &lt;- summary(fit)$fixed\n  b_hat &lt;- post[\"x\", \"Estimate\"]\n  b_se  &lt;- post[\"x\", \"Est.Error\"]\n\n  cover_68[s] &lt;- abs(b - b_hat) &lt; b_se\n  cover_95[s] &lt;- abs(b - b_hat) &lt; 2 * b_se\n}\n\ncat(\"Coverage 68%:\", mean(cover_68), \"\\n\")\ncat(\"Coverage 95%:\", mean(cover_95), \"\\n\")\nCon solo 100 iterazioni, i risultati sono i seguenti:\n&gt; cat(\"Coverage 68%:\", mean(cover_68), \"\\n\")\nCoverage 68%: 0.73 \n&gt; cat(\"Coverage 95%:\", mean(cover_95), \"\\n\")\nCoverage 95%: 0.953 \nQuesta seconda simulazione evidenzia che anche i livelli di copertura empirici ottenuti con l’approccio bayesiano si avvicinano ai valori teorici previsti.\nI risultati ottenuti confermano l’efficacia degli intervalli di confidenza e di credibilità stimati attraverso i modelli frequentisti e bayesiani.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#confronti-non-effetti",
    "href": "chapters/linear_models/03_reglin_bayes.html#confronti-non-effetti",
    "title": "63  Modello bayesiano di regressione lineare bivariata",
    "section": "\n63.11 Confronti, non Effetti",
    "text": "63.11 Confronti, non Effetti\nGelman et al. (2021) sottolineano che i coefficienti di regressione sono spesso denominati “effetti”, ma questa terminologia può trarre in inganno. Gli “effetti”, infatti, implicano una relazione causale. Tuttavia, ciò che un modello di regressione stima non è necessariamente un effetto causale, ma piuttosto un pattern osservazionale. In particolare, ciò che osserviamo è che la media della variabile dipendente nella sottopopolazione con \\(X = x + 1\\) è spesso maggiore o minore (a seconda del segno di \\(\\beta\\)) rispetto alla media della sottopopolazione con \\(X = x\\).\nLa regressione è uno strumento matematico utilizzato principalmente per fare previsioni. I coefficienti di regressione devono quindi essere interpretati come confronti medi. Solo in circostanze specifiche, quando la regressione descrive un processo causale ben definito, è possibile interpretarli come effetti. Tuttavia, questa interpretazione causale deve essere giustificata dal disegno dello studio e non può essere dedotta unicamente dall’uso del modello statistico.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#riflessioni-conclusive",
    "href": "chapters/linear_models/03_reglin_bayes.html#riflessioni-conclusive",
    "title": "63  Modello bayesiano di regressione lineare bivariata",
    "section": "\n63.12 Riflessioni Conclusive",
    "text": "63.12 Riflessioni Conclusive\nIn questo capitolo abbiamo esplorato il modello di regressione lineare bivariata adottando una prospettiva bayesiana. Abbiamo visto che, quando si utilizzano priori debolmente informativi, le stime bayesiane tendono a coincidere con quelle dell’approccio frequentista, specialmente in presenza di un numero consistente di dati. Tuttavia, il valore distintivo dell’approccio bayesiano non si limita alla stima dei parametri: esso risiede soprattutto nella possibilità di integrare conoscenze a priori e di rappresentare l’incertezza in modo esplicito e probabilistico.\nIndipendentemente dalla scelta tra approccio bayesiano o frequentista, è importante sottolineare che i modelli statistici non offrono verità definitive. Come ricordato da Alexander (2023), i modelli non sono specchi della realtà, ma strumenti concettuali per darle significato. Agiscono come lenti interpretative, attraverso cui possiamo mettere a fuoco specifici aspetti del fenomeno studiato.\nIn particolare, i modelli statistici possono essere utilizzati per due scopi principali, entrambi fondamentali nella ricerca psicologica:\n\nPrevisione: si concentra sulla capacità del modello di anticipare nuovi dati. È un uso pragmatico ed empirico della modellizzazione, in cui l’attenzione è rivolta alla bontà predittiva del modello, spesso valutata con tecniche di validazione incrociata.\nInferenza: mira a comprendere le relazioni causali tra variabili. Per rendere credibili le inferenze causali, la regressione deve essere accompagnata da una solida progettazione dello studio (es. esperimenti, disegni longitudinali, controllo di variabili confondenti) e da ipotesi teoriche ben motivate.\n\nLa regressione lineare, in ogni caso, rappresenta una forma di media ponderata tra le osservazioni, il che implica alcune limitazioni:\n\ni risultati possono essere distorti dalla presenza di variabili confondenti non incluse nel modello;\nla qualità dei dati e la verifica delle ipotesi del modello (normalità degli errori, indipendenza, omoschedasticità) giocano un ruolo cruciale nella validità delle stime;\nl’assunzione di linearità potrebbe non essere adatta a descrivere alcune relazioni psicologiche, che spesso sono complesse o non lineari.\n\nPertanto, è essenziale non assumere il modello come un fine, ma considerarlo uno strumento di esplorazione e interpretazione, da integrare in una riflessione teorica più ampia. I risultati di una regressione non parlano da soli: vanno interpretati alla luce del disegno dello studio, della letteratura scientifica, e delle ipotesi formulate dal ricercatore.\nPer chi desidera approfondire il modello bayesiano di regressione lineare, oltre al testo di Johnson et al. (2022), si consiglia la lettura del testo Regression and Other Stories. Quest’ultimo rappresenta una guida pratica e ricca di esempi applicati, ideale per comprendere come integrare i metodi bayesiani nell’analisi di regressione e interpretarne i risultati in contesti reali.\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nVerosimiglianza\nDefinire la funzione di verosimiglianza per il modello bayesiano di regressione lineare bivariata, esplicitando i parametri e la loro interpretazione.\nScelta dei prior\nProporre un set di prior debolmente informativi differenti da quelli riportati, motivando la scelta delle distribuzioni.\nSimulazione dati\nScrivere un blocco di codice in R/Quarto per simulare un dataset con \\(n=50\\), parametri \\(lpha=2\\), \\(eta=0.5\\), \\(\\sigma=1\\) e visualizzare un grafico dispersione con la retta di regressione vera.\nStima frequentista vs bayesiana\nUtilizzando i dati simulati, adattare un modello con lm() e uno con brm() (specificando i prior). Confrontare i risultati prodotti dai due approcci, riportando i valori stimati e gli intervalli di confidenza/credibilità.\nDiagnosi MCMC\nElencare e spiegare almeno tre controlli diagnostici da effettuare sulle catene MCMC per garantire la convergenza e un buon mescolamento.\nInterpretazione dei coefficienti\nIn un contesto osservazionale, discutere perché non è appropriato interpretare i coefficienti della regressione come effetti causali. Fare riferimento ai concetti di confondimento e disegno sperimentale.\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n\n\nVerosimiglianza\n\\[\n\\mathcal{L}(\\alpha, \\beta, \\sigma \\mid y, x) = \\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(-\\frac{(y_i - (\\alpha + \\beta x_i))^2}{2\\sigma^2}\\right).\n\\]\n\n\nScelta dei prior\nAd esempio:\n\n\n\\(\\alpha \\sim \\mathcal{N}(0, 5)\\): consente maggiore variabilità iniziale;\n\n\n\\(\\beta \\sim \\text{Student-}t(3, 0, 2)\\): robuste alle code pesanti;\n\n\n\\(\\sigma \\sim \\text{Half-}Cauchy(0, 1)\\): prior leggermente più stretto sulle deviazioni.\n\n\n\nSimulazione dati\nset.seed(42)\nn &lt;- 50\nalpha &lt;- 2\nbeta  &lt;- 0.5\nsigma &lt;- 1\nx &lt;- rnorm(n, 0, 1)\ny &lt;- alpha + beta * x + rnorm(n, 0, sigma)\nplot(x, y, main = \"Dati simulati\", xlab = \"x\", ylab = \"y\")\nabline(a = alpha, b = beta, col = \"blue\", lwd = 2)\n\n\nStima frequentista vs bayesiana\n\n\nFrequentista (lm()):\nfm_f &lt;- lm(y ~ x)\nsummary(fm_f)\nconfint(fm_f, level = 0.95)\n\n\nBayesiano (brm()):\nfm_b &lt;- brm(y ~ x, data = data.frame(x, y),\n            prior = c(set_prior(\"normal(0,5)\", class=\"Intercept\"),\n                      set_prior(\"normal(0,5)\", class=\"b\"),\n                      set_prior(\"cauchy(0,1)\", class=\"sigma\")),\n            iter = 2000, chains = 2)\nsummary(fm_b)\nConfronto: i valori medi a posteriori e gli intervalli di credibilità dovrebbero includere quelli di confidenza di lm().\n\n\n\n\nDiagnosi MCMC\n\n\nTrace plots: verificare mescolamento e stazionarietà delle catene;\n\n\nR-hat: valore vicino a 1 indica convergenza;\n\n\nEffective Sample Size (ESS): numero di campioni indipendenti effettivi.\n\n\nInterpretazione dei coefficienti\nLa regressione osservazionale non controlla automaticamente i potenziali confondenti; senza randomizzazione o disegno sperimentale rigoroso, non si può inferire causalità. Bisogna considerare variabili confondenti e criteri di validità interna.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/03_reglin_bayes.html#informazioni-sullambiente-di-sviluppo",
    "title": "63  Modello bayesiano di regressione lineare bivariata",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] brms_2.22.0      Rcpp_1.0.14      posterior_1.6.1  cmdstanr_0.9.0  \n#&gt;  [5] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [9] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.12.0 psych_2.5.3     \n#&gt; [13] scales_1.4.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [17] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [21] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.2   \n#&gt; [25] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1     farver_2.1.2         loo_2.8.0           \n#&gt;  [4] fastmap_1.2.0        tensorA_0.36.2.1     pacman_0.5.1        \n#&gt;  [7] digest_0.6.37        timechange_0.3.0     estimability_1.5.1  \n#&gt; [10] lifecycle_1.0.4      StanHeaders_2.32.10  processx_3.8.6      \n#&gt; [13] magrittr_2.0.3       compiler_4.5.0       rlang_1.1.6         \n#&gt; [16] tools_4.5.0          yaml_2.3.10          data.table_1.17.2   \n#&gt; [19] labeling_0.4.3       bridgesampling_1.1-2 htmlwidgets_1.6.4   \n#&gt; [22] curl_6.2.2           pkgbuild_1.4.7       mnormt_2.1.1        \n#&gt; [25] plyr_1.8.9           RColorBrewer_1.1-3   abind_1.4-8         \n#&gt; [28] withr_3.0.2          grid_4.5.0           stats4_4.5.0        \n#&gt; [31] colorspace_2.1-1     xtable_1.8-4         inline_0.3.21       \n#&gt; [34] emmeans_1.11.1       cli_3.6.5            mvtnorm_1.3-3       \n#&gt; [37] rmarkdown_2.29       generics_0.1.4       RcppParallel_5.1.10 \n#&gt; [40] rstudioapi_0.17.1    reshape2_1.4.4       tzdb_0.5.0          \n#&gt; [43] rstan_2.32.7         parallel_4.5.0       matrixStats_1.5.0   \n#&gt; [46] vctrs_0.6.5          V8_6.0.3             Matrix_1.7-3        \n#&gt; [49] jsonlite_2.0.0       hms_1.1.3            glue_1.8.0          \n#&gt; [52] codetools_0.2-20     ps_1.9.1             distributional_0.5.0\n#&gt; [55] stringi_1.8.7        gtable_0.3.6         QuickJSR_1.7.0      \n#&gt; [58] pillar_1.10.2        htmltools_0.5.8.1    Brobdingnag_1.2-9   \n#&gt; [61] R6_2.6.1             rprojroot_2.0.4      evaluate_1.0.3      \n#&gt; [64] lattice_0.22-7       backports_1.5.0      rstantools_2.4.0    \n#&gt; [67] coda_0.19-4.1        nlme_3.1-168         checkmate_2.3.2     \n#&gt; [70] xfun_0.52            pkgconfig_2.0.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#bibliografia",
    "href": "chapters/linear_models/03_reglin_bayes.html#bibliografia",
    "title": "63  Modello bayesiano di regressione lineare bivariata",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlexander, R. (2023). Telling Stories with Data: With Applications in R. Chapman; Hall/CRC.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html",
    "href": "chapters/linear_models/04_synt_sugar.html",
    "title": "64  Zucchero sintattico",
    "section": "",
    "text": "64.1 Introduzione\nI modelli lineari sono così ampiamente utilizzati che sono stati sviluppati appositamente una sintassi, dei metodi e delle librerie per la regressione. Una di queste librerie è brms (Bayesian Regression Models using Stan), già introdotta nel Capitolo 63. brms è un pacchetto R progettato per adattare modelli gerarchici generalizzati lineari (di cui il modello lineare bivariato è un caso particolare), utilizzando una sintassi simile a quella presente nei pacchetti R, come lm, lme4, nlme, rstanarm. brms si basa su Stan, ma offre un’API di livello superiore.\nIn questo capitolo esploreremo in maniera dettagliata come condurre un’analisi di regressione utilizzando brms invece di Stan.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html#interfaccia-brms",
    "href": "chapters/linear_models/04_synt_sugar.html#interfaccia-brms",
    "title": "64  Zucchero sintattico",
    "section": "\n64.2 Interfaccia brms\n",
    "text": "64.2 Interfaccia brms\n\nPer fare un esempio, applicheremo il modello di regressione bivariato alla relazione tra altezza e peso. I dati contenuti nel file Howell_18.csv sono parte di un censimento parziale della popolazione !Kung San dell’area di Dobe, raccolti tramite interviste condotte da Nancy Howell alla fine degli anni ’60 (McElreath, 2020). I !Kung San sono una delle popolazioni di raccoglitori-cacciatori più conosciute del ventesimo secolo e sono stati oggetto di numerosi studi antropologici. In questa analisi, consideriamo un sottocampione di dati relativi alla popolazione adulta (di età superiore ai 18 anni).\nImportiamo i dati contenuti nel file Howell_18.csv.\n\ndf &lt;- rio::import(here::here(\"data\", \"Howell_18.csv\"))\n\n\ndf |&gt; \n  head()\n#&gt;   height weight age male\n#&gt; 1  151.8  47.83  63    1\n#&gt; 2  139.7  36.49  63    0\n#&gt; 3  136.5  31.86  65    0\n#&gt; 4  156.8  53.04  41    1\n#&gt; 5  145.4  41.28  51    0\n#&gt; 6  163.8  62.99  35    1\n\nGeneriamo un diagramma a dispersione tra le variabili height (altezza) e weight (peso):\n\nggplot(df, aes(x = weight, y = height)) +\n  geom_point() +  \n  labs(x = \"Weight\", y = \"Height\") \n\n\n\n\n\n\n\nbrms si concentra sui modelli di regressione, e questa specializzazione permette di adottare una sintassi più semplice, conosciuta come sintassi di Wilkinson (Wilkinson & Rogers, 1973).\nAd esempio, il modello \\(y = \\alpha + \\beta x + \\varepsilon\\) si implementa come segue:\na_model = brm(y ∼ 1 + x, data = df)\nNella sintassi di Wilkinson, il simbolo tilde (∼) separa la variabile dipendente (a sinistra) dalle variabili indipendenti (a destra). In questo caso, stiamo specificando solo la media (\\(\\mu\\)) della \\(y\\).\nbrms assume di default che la distribuzione di verosimiglianza sia gaussiana, ma è possibile modificarla tramite l’argomento family.\nLa notazione 1 si riferisce all’intercetta. L’intercetta viene inclusa di default. Per cui il modello precedente si può anche scrivere, in maniera equivalente, come\na_model = brm(y ∼ x, data = df)\nSe desideriaamo escludere l’intercetta dal modello, possiamo farlo in questo modo\nno_intercept_model = brm(y ∼ 0 + x, data = df)\noppure in questo modo\nno_intercept_model = brm(y ∼ -1 + x, data = df)\nPer includere ulteriori variabili nel modello, possiamo procedere così:\nmodel_2 = brm(\"y ∼ x + z\", data)\nbrms consente anche di includere effetti a livello di gruppo (gerarchici). Ad esempio, se desideriamo un modello ad effetti misti nel quale abbiamo un effetto diverso di \\(x\\) in ciascun gruppo g, possiamo usare la seguente sintassi:\nmodel_h = brm(y ∼ x + z + (x | g), data = df)\nLa sintassi di Wilkinson non specifica le distribuzioni a priori, ma solo come le variabili dipendenti e indipendenti sono collegate. brms definirà automaticamente delle distribuzioni a priori debolmente informative per noi, rendendo superflua la loro definizione esplicita. Tuttavia, se preferiamo avere un maggiore controllo, possiamo specificarle manualmente, come vedremo in seguito.\n\n64.2.1 Centrare le Variabili\nPer interpretare più facilmente l’intercetta, centriamo la variabile weight rispetto alla media del campione:\n\ndf$weight_c &lt;- df$weight - mean(df$weight)\n\nOra, l’intercetta (\\(\\alpha\\)) rappresenterà l’altezza media quando il peso corrisponde alla media del campione.\nAdattiamo un modello lineare con la variabile weight centrata e esaminiamo i risultati:\n\nfit_1 = brm(\n  bf(height ~ 1 + weight_c, center = FALSE), \n  data = df, \n  backend = \"cmdstanr\", \n  silent = 0\n)\n\nUtilizzando center = FALSE nel modello Bayesiano garantiamo che il centraggio venga mantenuto e non applicato nuovamente da brms.\nL’argomento backend = \"cmdstanr\" indica a brms di usare cmdstan per il campionamento, al posto di Stan che è l’impostazione predefinita. Poiché in questo insegnamento utilizzeremo cmdstan, è essenziale specificare questo backend.\nLe tracce dei parametri si ottengono nel modo seguente:\n\nmcmc_trace(\n  fit_1, \n  pars = c(\"b_Intercept\", \"b_weight_c\", \"sigma\"),\n  facet_args = list(nrow = 3)\n)\n\n\n\n\n\n\n\n\nsummary(fit_1)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: height ~ 1 + weight_c \n#&gt;    Data: df (Number of observations: 352) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept   154.59      0.27   154.06   155.11 1.00     3947     2871\n#&gt; weight_c      0.91      0.04     0.82     0.99 1.00     3945     2996\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     5.10      0.20     4.74     5.51 1.00     4902     3275\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nLa stima dell’intercetta \\(\\alpha\\) = 154.60 suggerisce che, per le persone con un peso corrispondente al valore medio del campione analizzato, l’altezza prevista è di 154.60 cm.\nPossiamo confrontare i risultati ottenuti da brm() con quelli prodotti dall’approccio frequentista:\n\nfit_2 &lt;- lm(height ~ 1 + weight_c, data = df)\n\n\nsummary(fit_2)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = height ~ 1 + weight_c, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -19.746  -2.884   0.022   3.142  14.774 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)\n#&gt; (Intercept)  154.597      0.271   570.2   &lt;2e-16\n#&gt; weight_c       0.905      0.042    21.5   &lt;2e-16\n#&gt; \n#&gt; Residual standard error: 5.09 on 350 degrees of freedom\n#&gt; Multiple R-squared:  0.57,   Adjusted R-squared:  0.568 \n#&gt; F-statistic:  463 on 1 and 350 DF,  p-value: &lt;2e-16\n\nL’uso di prior debolmente informativi fa in modo che i risultati dei due approcci siano praticamente equivalenti.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html#visualizzazione-dei-risultati",
    "href": "chapters/linear_models/04_synt_sugar.html#visualizzazione-dei-risultati",
    "title": "64  Zucchero sintattico",
    "section": "\n64.3 Visualizzazione dei Risultati",
    "text": "64.3 Visualizzazione dei Risultati\nPer comprendere visivamente la relazione stimata tra peso e altezza nel nostro modello bayesiano, utilizziamo la funzione conditional_effects:\n\nconditional_effects(fit_1, effects = \"weight_c\")\n\n\n\n\n\n\n\nIl grafico generato fornisce una rappresentazione completa della relazione stimata:\n\n\nLinea centrale (media posteriore): rappresenta la stima più probabile dell’altezza per ciascun valore del peso centrato.\n\nArea colorata (intervallo di credibilità): mostra l’intervallo di densità più alta (HDI) al 95%, indicando l’incertezza attorno alla stima centrale.\n\nÈ possibile adattare il livello di incertezza mostrato modificando l’argomento prob:\n\n# Visualizzazione con intervallo di credibilità all'89%\nconditional_effects(fit_1, effects = \"weight_c\", prob = 0.89)\n\n\n\n\n\n\n\nRidurre il valore di prob (es. a 0.80 o 0.50) produce un intervallo più stretto, mentre aumentarlo (es. a 0.99) amplia l’area di incertezza visualizzata.\n\n64.3.1 Interpretazione Pratica del Grafico\nNel grafico:\n\nil punto dove la linea attraversa weight_c = 0 corrisponde all’altezza prevista per un individuo con peso medio (poiché abbiamo centrato la variabile);\nla pendenza della linea indica quanto ci aspettiamo che l’altezza aumenti per ogni kg di peso aggiuntivo;\nla larghezza dell’intervallo di credibilità indica la nostra certezza sulle stime: più stretto l’intervallo, maggiore la certezza.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html#due-tipi-di-incertezza-nei-modelli-bayesiani",
    "href": "chapters/linear_models/04_synt_sugar.html#due-tipi-di-incertezza-nei-modelli-bayesiani",
    "title": "64  Zucchero sintattico",
    "section": "\n64.4 Due Tipi di Incertezza nei Modelli Bayesiani",
    "text": "64.4 Due Tipi di Incertezza nei Modelli Bayesiani\nImmaginiamo di voler capire come il peso (variabile X) sia collegato all’altezza (variabile Y) in un gruppo di persone. Con un modello bayesiano ottieniamo due tipi distinti di informazioni incerte:\n\n\n\n\n\n\n\nChe cosa stiamo stimando?\nCome si chiama l’incertezza?\nChe intervallo disegniamo?\n\n\n\n\nLa media “vera” dell’altezza per ogni valore di peso\n\nIncertezza del parametro (o dell’effetto medio)\n\nIntervallo di credibilità (credibility/credible interval)\n\n\n\nLa singola osservazione futura (quanto sarà alta la prossima persona di quel peso)\nIncertezza predittiva\n\nIntervallo di predizione (prediction interval)\n\n\n\n\n64.4.1 Incertezza del parametro – «Quanto stiamo sbagliando la linea media?»\n\n\nChe cosa fa il codice\n\nconditional_effects(fit_1, effects = \"weight_c\")\n\n\n\n\n\n\n\n\nDisegna la linea di regressione (in pratica: la media stimata dell’altezza per ogni peso).\n\nAggiunge intorno una fascia stretta: è l’intervallo di credibilità al 95 %.\n\n\n\n\nCome leggerla\n\nSe la fascia copre, ad esempio, da 170 cm a 172 cm per un peso di 70 kg, significa che “con il 95 % di probabilità la vera media dell’altezza per quel peso sta lì dentro”.\n\nNon dice nulla sul fatto che le persone individuali possano essere molto più basse o molto più alte.\n\n\n\n\nMetafora veloce\nPensa a tirare freccette: la freccia media cade vicino al centro, ma ogni singola freccia può andare ovunque sul bersaglio. L’intervallo di credibilità descrive la posizione del centro.\n\n\n64.4.2 Incertezza predittiva – «Quanto potrebbe variare la prossima persona?»\n\n\nChe cosa fa il codice\n\nconditional_effects(fit_1, effects = \"weight_c\", method = \"predict\")\n\n\n\n\n\n\n\n\nRipropone la stessa linea media.\n\nDisegna però una fascia molto più larga: l’intervallo di predizione.\n\n\n\n\nPerché è più largo\n\nContiene le due fonti di variabilità:\n\n\nIncertezza sulla linea media (come sopra).\n\n\nVariabilità residua: le differenze naturali tra persone di uguale peso (chi è più muscoloso, chi ha ossa più leggere ecc.).\n\n\n\n\n\n\nMetafora veloce\nOra guardi non il centro del bersaglio, ma l’intero disco dove ogni freccia potrebbe atterrare. Quell’area è molto più grande.\n\n\n64.4.3 Quando usare l’una o l’altra fascia?\n\n\n\n\n\n\n\nObiettivo della tua domanda\nFunzione da usare\nChe fascia guardare\n\n\n\nCapire l’effetto medio (es. “quanto cresce in media l’altezza al crescere di 1 kg?”)\nconditional_effects(...)\nIntervallo di credibilità\n\n\nFare previsioni su nuovi casi (es. “quanto sarà alta Maria che pesa 70 kg?”)\nconditional_effects(..., method = \"predict\")\nIntervallo di predizione\n\n\n\n64.4.4 Riepilogo\n\n\nCredibilità = incertezza sul parametro medio → fascia stretta perché stiamo stimando solo la retta di regressione.\n\n\nPredizione = incertezza su osservazioni future → fascia larga perché somma l’incertezza della retta + la variabilità individuale.\n\nScegliamo la visualizzazione che risponde alla nostra domanda: “qual è la media?” (credibilità) o “dove cadrà il prossimo dato?” (predizione).\n\nIn sintesi, la differenza principale sta nell’inclusione o meno della variabilità residua. La visualizzazione predittiva è più onesta riguardo alla nostra capacità di fare previsioni per singole osservazioni, mentre quella standard è più adatta per comprendere la relazione generale tra le variabili.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html#distribuzione-a-posteriori-dei-parametri",
    "href": "chapters/linear_models/04_synt_sugar.html#distribuzione-a-posteriori-dei-parametri",
    "title": "64  Zucchero sintattico",
    "section": "\n64.5 Distribuzione a Posteriori dei Parametri",
    "text": "64.5 Distribuzione a Posteriori dei Parametri\nPer esaminare la distribuzione a posteriori dei parametri usiamo la funzione mcmc_plot():\n\nmcmc_plot(fit_1, type = \"dens\")\n\n\n\n\n\n\n\nEsaminiamo in maggiori dettagli il sommario numerico dei parametri stimati:\n\ndraws &lt;- posterior::as_draws(fit_1, variable = \"^b_\", regex = TRUE)\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 2 × 5\n#&gt;   variable       mean     sd mcse_mean  mcse_sd\n#&gt;   &lt;chr&gt;         &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 b_Intercept 155.    0.269   0.00428  0.00391 \n#&gt; 2 b_weight_c    0.906 0.0423  0.000675 0.000681\n\nUtilizziamo la funzione as_draws() che trasforma un oggetto R in un formato compatibile con posterior. Gli argomenti variable = \"^b_\" e regex = TRUEconsentono di selezionare solo i parametri il cui nome inizia con b_: nel nostro caso saranno l’intercetta e la pendenza del modello di regressione lineare.\nSuccessivamente usiamo la funzione summarise_draws() con gli argomenti specificati per un sommario della distribuzione a posteriori dei parametri prescelti.\n\n64.5.1 Spiegazione di mcse_mean e mcse_sd\n\nI valori mcse_mean e mcse_sd sono le Monte Carlo Standard Errors (errori standard Monte Carlo) per la stima della media (mean) e della deviazione standard (sd), rispettivamente. Questi valori quantificano l’incertezza associata al processo di campionamento effettuato durante l’analisi bayesiana, in particolare quando si utilizzano algoritmi Monte Carlo come MCMC (Markov Chain Monte Carlo).\n\n64.5.1.1 mcse_mean\n\n\nRappresenta l’errore standard Monte Carlo per la stima della media.\nIndica quanto la media stimata (\\(\\text{mean}\\)) potrebbe variare a causa della finitezza dei campioni generati dall’algoritmo MCMC.\nUn valore di mcse_mean basso rispetto alla deviazione standard (\\(\\text{sd}\\)) suggerisce che il numero di campioni generati è sufficiente per ottenere una stima accurata della media.\n\n64.5.1.2 mcse_sd\n\n\nRappresenta l’errore standard Monte Carlo per la stima della deviazione standard.\nIndica quanto potrebbe variare la stima della deviazione standard (\\(\\text{sd}\\)) a causa del numero finito di campioni generati.\nAnche qui, un valore basso di mcse_sd rispetto alla sd suggerisce che l’incertezza introdotta dal campionamento è trascurabile.\n\n64.5.2 Come interpretarli?\n\n\nProporzione rispetto alla sd:\n\n\nmcse_mean e mcse_sd dovrebbero essere molto più piccoli rispetto ai rispettivi parametri (mean e sd), idealmente almeno un ordine di grandezza inferiore.\nAd esempio, per b_Intercept, mcse_mean = 0.0044 è molto più piccolo rispetto a sd = 0.2695, indicando che la stima della media è robusta.\n\n\n\nIndicazione della qualità del campionamento:\n\nValori alti di mcse_mean o mcse_sd rispetto alla sd potrebbero indicare che il numero di iterazioni MCMC non è sufficiente, che le catene non sono ben mescolate o che ci sono problemi di convergenza.\n\n\n\nIn sintesi, mcse_mean e mcse_sd sono utili per valutare l’affidabilità delle stime derivate dal campionamento Monte Carlo. Se questi valori sono bassi, possiamo essere confidenti che il numero di campioni è sufficiente per rappresentare accuratamente la distribuzione a posteriori.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html#specificare-i-priors",
    "href": "chapters/linear_models/04_synt_sugar.html#specificare-i-priors",
    "title": "64  Zucchero sintattico",
    "section": "\n64.6 Specificare i Priors",
    "text": "64.6 Specificare i Priors\nSe vogliamo personalizzare i priors, possiamo utilizzare la funzione get_prior per esplorare quelli predefiniti:\n\nget_prior(height ~ 1 + weight_c, data = df)\n#&gt;                     prior     class     coef group resp dpar nlpar lb ub\n#&gt;  student_t(3, 154.3, 8.5) Intercept                                     \n#&gt;                    (flat)         b                                     \n#&gt;                    (flat)         b weight_c                            \n#&gt;      student_t(3, 0, 8.5)     sigma                                 0   \n#&gt;        source\n#&gt;       default\n#&gt;       default\n#&gt;  (vectorized)\n#&gt;       default\n\n\n\nprior: descrive il prior predefinito assegnato a ciascun parametro del modello. Ad esempio:\n\n\nstudent_t(3, 154.3, 8.5): prior t di Student per l’intercetta con 3 gradi di libertà, una media di 154.3, e una scala di 8.5.\n\n(flat): prior piatto (non informativo) per i coefficienti delle variabili predittive, come \\(b\\) e \\(b_{weight_c}\\).\n\nstudent_t(3, 0, 8.5): prior t di Student per il parametro \\(\\sigma\\) (deviazione standard residua), centrato su 0 con una scala di 8.5.\n\n\n\nclass: identifica la classe di parametro a cui il prior si applica:\n\n\nIntercept: prior per l’intercetta (\\(\\alpha\\)).\n\nb: prior per i coefficienti delle variabili predittive (\\(\\beta\\)).\n\nsigma: prior per il parametro della deviazione standard residua (\\(\\sigma\\)).\n\n\n\ncoef: specifica a quale predittore si riferisce il prior, se applicabile. Ad esempio:\n\nVuoto per l’intercetta (poiché non dipende da un predittore specifico).\n\nweight_c per il coefficiente relativo al predittore weight_c.\n\n\n\nlb e ub: rappresentano rispettivamente i limiti inferiori (lower bound) e superiori (upper bound) per il prior, se specificati. Ad esempio:\n\nPer sigma, il limite inferiore è \\(0\\), dato che la deviazione standard non può essere negativa.\n\n\n\nsource: indica l’origine del prior. Se il prior è predefinito (default), il valore sarà default. Se un prior è specificato manualmente dall’utente, sarà indicato come tale.\n\nOra impostiamo priors espliciti e adattiamo un nuovo modello:\n\nprior_guassian &lt;-\n  brms::prior(normal(160, 10), class = \"b\", coef = \"Intercept\") +\n  brms::prior(normal(0, 5), class = \"b\", coef = \"weight_c\") +\n  brms::prior(cauchy(0, 5), class = \"sigma\")\n\nSi noti l’uso di brms::prior(). Questa notazione specifica esplicitamente che stiamo utilizzando la funzione prior() propria del pacchetto brms, evitando potenziali conflitti con funzioni omonime presenti in altre librerie caricate.\n\nfit_2 = brm(\n  bf(height ~ 1 + weight_c, center = FALSE), \n  prior = prior_guassian,\n  data = df, \n  backend = \"cmdstanr\", \n  silent = 0\n)\n\nOtteniamo un sommario numerico dei parametri stimati:\n\ndraws &lt;- posterior::as_draws(fit_2, variable = \"^b_\", regex = TRUE)\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 2 × 5\n#&gt;   variable       mean     sd mcse_mean  mcse_sd\n#&gt;   &lt;chr&gt;         &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 b_Intercept 155.    0.273   0.00425  0.00409 \n#&gt; 2 b_weight_c    0.905 0.0428  0.000703 0.000678\n\nI prior che abbiamo specificato non cambiano in maniera rilevante la soluzione a posteriori.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html#predizioni-predittive-a-posteriori",
    "href": "chapters/linear_models/04_synt_sugar.html#predizioni-predittive-a-posteriori",
    "title": "64  Zucchero sintattico",
    "section": "\n64.7 Predizioni Predittive a Posteriori",
    "text": "64.7 Predizioni Predittive a Posteriori\nUn aspetto fondamentale nella valutazione di un modello statistico, sia frequentista che bayesiano, è verificare quanto bene i dati osservati siano rappresentati dalle predizioni del modello. Tuttavia, l’approccio e l’interpretazione differiscono tra i due paradigmi.\n\n64.7.1 Confronto Frequentista\nNel caso frequentista, si confrontano i valori predetti dal modello, \\(\\hat{y} = \\hat{\\alpha} + \\hat{\\beta}x\\), con i dati osservati. Questo confronto si basa sull’analisi di:\n\nla vicinanza della retta di regressione stimata ai dati osservati;\nl’eventuale presenza di pattern nei dati che si discostano da un andamento lineare;\nla variazione della dispersione dei valori di \\(y\\) rispetto a \\(x\\) (ad esempio, per verificare l’ipotesi di omoschedasticità).\n\n64.7.2 Approccio Bayesiano\nNell’approccio bayesiano, si eseguono le stesse verifiche di base, ma l’analisi si arricchisce attraverso l’uso delle Predizioni Predittive a Posteriori (Posterior Predictive Checks, PPCs). Questo metodo consente di confrontare i dati osservati con dati simulati dal modello, utilizzando l’incertezza stimata nelle distribuzioni a posteriori dei parametri.\n\n64.7.3 Costruzione delle Predizioni Predittive a Posteriori\nNel caso di un modello bivariato, il processo per generare un grafico delle Predizioni Predittive a Posteriori è il seguente:\n\nDati osservati: Si parte dall’istogramma lisciato dei dati osservati, che rappresenta la distribuzione empirica di \\(y\\).\n\nSimulazione di dati predetti:\n\nSi estrae un campione casuale di valori \\(\\alpha'\\), \\(\\beta'\\), e \\(\\sigma'\\) dalle distribuzioni a posteriori dei parametri (\\(\\alpha\\), \\(\\beta\\), e \\(\\sigma\\)).\nUsando questi valori, si calcolano dati simulati da una distribuzione normale: \\[\ny_{\\text{sim}} \\sim \\mathcal{N}(\\alpha' + \\beta'x, \\sigma')\n\\] dove \\(x\\) sono i valori predittori osservati.\n\n\nCreazione di istogrammi: Per ogni campione simulato, si costruisce un istogramma lisciato che rappresenta la distribuzione predetta dal modello.\nRipetizione: Il processo viene ripetuto più volte, generando molti istogrammi lisciati.\nConfronto: Tutti gli istogrammi predetti vengono sovrapposti all’istogramma dei dati osservati. Questo consente di confrontare visivamente la capacità del modello di rappresentare la distribuzione dei dati.\n\n64.7.4 Interpretazione\n\n\nBuona corrispondenza: Se gli istogrammi lisciati dei dati simulati si sovrappongono bene all’istogramma dei dati osservati, significa che il modello è in grado di rappresentare adeguatamente il campione corrente.\n\nDiscrepanze: Se vi sono discrepanze sistematiche (ad esempio, picchi o code mancanti nei dati predetti rispetto agli osservati), ciò indica che il modello potrebbe non essere adeguato o che vi sono aspetti dei dati non catturati dal modello.\n\nL’approccio delle Predizioni Predittive a Posteriori è particolarmente potente perché:\n\nintegra l’incertezza nei parametri del modello;\npermette di verificare non solo la bontà di adattamento complessiva, ma anche specifici aspetti delle distribuzioni predette;\nè visivo e intuitivo, facilitando l’identificazione di discrepanze tra modello e dati.\n\nIn conclusione, le Predizioni Predittive a Posteriori forniscono un modo robusto per valutare l’adeguatezza di un modello bayesiano rispetto ai dati osservati. Se il modello riproduce bene la distribuzione dei dati osservati, si può concludere che è adatto almeno per il campione corrente. In caso contrario, potrebbe essere necessario rivedere le specifiche del modello, come i priors o la struttura delle variabili.\nVerifichiamo dunque le predizioni del modello confrontandole con i dati osservati del campione corrente:\n\npp_check(fit_2)\n\n\n\n\n\n\n\nNel caso presente, vi è una buona corrispondenza tra i dati simulati dal modello e i dati osservati.\nIl grafico seguente analizza gli errori del modello rispetto alla retta di regressione stimata.\n\npp_check(fit_1, type = \"error_scatter_avg\")\n\n\n\n\n\n\n\nQuesto comando utilizza la funzione pp_check() per produrre un grafico che mostra i residui bayesiani, ovvero le differenze tra i dati osservati e quelli predetti dal modello. Nel tipo specifico di grafico scelto (\"error_scatter_avg\"), i residui sono rappresentati rispetto ai valori predetti, consentendo di valutare visivamente se sono distribuiti in modo uniforme.\nDal grafico, si osserva che i residui bayesiani appaiono distribuiti in modo omogeneo rispetto alla retta di regressione (che non è direttamente mostrata nel grafico). Questo suggerisce che:\n\nIl modello cattura correttamente la relazione tra la variabile predittiva e la variabile di risposta.\nNon ci sono pattern sistematici nei residui, come deviazioni non lineari o variazioni della dispersione (eteroschedasticità).\n\nSe fossero presenti pattern evidenti nei residui (ad esempio, una struttura curva o una variazione sistematica della dispersione), ciò indicherebbe che il modello potrebbe non essere adeguato, richiedendo una rivalutazione della sua struttura (ad esempio, aggiungendo termini non lineari o trasformando le variabili).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html#regressione-robusta",
    "href": "chapters/linear_models/04_synt_sugar.html#regressione-robusta",
    "title": "64  Zucchero sintattico",
    "section": "\n64.8 Regressione Robusta",
    "text": "64.8 Regressione Robusta\nIn questa sezione introduciamo la regressione robusta. Lo scopo è quello di mostrare quanto sia facile modificare il modello definito da brm per specificare una diversa distribuzione degli errori. Questo non è possibile nel caso dell’approccio frequentista.\nI modelli robusti sono utili in presenza di outlier. Ad esempio, introduciamo un outlier nei dati:\n\ndf_outlier &lt;- df\ndf_outlier$height[1] &lt;- 400\ndf_outlier$weight_c[1] &lt;- -25\n\n\ndf_outlier |&gt; \n  ggplot(aes(x = weight_c, y = height)) +\n    geom_point() +  \n    labs(x = \"Weight\", y = \"Height\") \n\n\n\n\n\n\n\nNotiamo come la presenza di un solo outlier introduce una distorsione nei risultati:\n\nfit_3 = brm(\n  bf(height ~ 1 + weight_c, center = FALSE), \n  prior = prior_guassian,\n  data = df_outlier, \n  backend = \"cmdstanr\", \n  silent = 0\n)\n\n\ndraws &lt;- posterior::as_draws(fit_3, variable = \"^b_\", regex = TRUE)\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 2 × 5\n#&gt;   variable       mean    sd mcse_mean mcse_sd\n#&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 b_Intercept 155.    0.795   0.0116  0.0122 \n#&gt; 2 b_weight_c    0.466 0.123   0.00183 0.00192\n\nSenza il valore outlier, la stima di beta è circa 0.9.\nAdattiamo ora un modello robusto utilizzando una distribuzione \\(t\\) di Student:\n\nfit_4 = brm(\n  bf(height ~ 1 + weight_c, center = FALSE), \n  prior = prior_guassian,\n  family = student(),\n  data = df_outlier, \n  backend = \"cmdstanr\", \n  silent = 0\n)\n\nI risultati mostrano che il modello \\(t\\) è meno influenzato dagli outlier rispetto al modello gaussiano.\n\ndraws &lt;- posterior::as_draws(fit_4, variable = \"^b_\", regex = TRUE)\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 2 × 5\n#&gt;   variable       mean     sd mcse_mean  mcse_sd\n#&gt;   &lt;chr&gt;         &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 b_Intercept 155.    0.256   0.00413  0.00410 \n#&gt; 2 b_weight_c    0.928 0.0392  0.000654 0.000634\n\nIl parametro \\(\\nu\\) della \\(t\\) di Student viene stimato dal modello. Nel caso presente\n\ndraws &lt;- posterior::as_draws(fit_4, variable = \"nu\")\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 1 × 5\n#&gt;   variable  mean    sd mcse_mean mcse_sd\n#&gt;   &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 nu        4.24 0.825    0.0147  0.0146\n\nCon un parametro \\(\\nu=4\\), la distribuzione \\(t\\) di Student presenta code molto più pesanti rispetto a una gaussiana. Questo la rende più robusta nel gestire la presenza di outliers rispetto al modello gaussiano.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html#indice-di-determinazione-bayesiano",
    "href": "chapters/linear_models/04_synt_sugar.html#indice-di-determinazione-bayesiano",
    "title": "64  Zucchero sintattico",
    "section": "\n64.9 Indice di Determinazione Bayesiano",
    "text": "64.9 Indice di Determinazione Bayesiano\nCon il pacchetto brms, possiamo calcolare il Bayes \\(R^2\\), che rappresenta l’equivalente bayesiano del classico indice di determinazione \\(R^2\\). Questo indice quantifica la proporzione di varianza spiegata dal modello, tenendo conto dell’incertezza intrinseca delle stime bayesiane.\nIl comando per calcolarlo è:\n\nbayes_R2(fit_2)\n#&gt;    Estimate Est.Error   Q2.5  Q97.5\n#&gt; R2    0.568   0.02331 0.5198 0.6085\n\nIl comando restituisce un tibble (una tabella ordinata) con le seguenti informazioni:\n\n\nEstimate: La stima media del Bayes \\(R^2\\), cioè la proporzione di varianza spiegata dal modello, basata sulle distribuzioni a posteriori dei parametri.\n\nEst.Error: L’errore standard associato alla stima del \\(R^2\\).\n\nQ2.5 e Q97.5: I limiti inferiore e superiore dell’intervallo di credibilità al 95% per il Bayes \\(R^2\\). Questi valori indicano l’incertezza sul \\(R^2\\), riflettendo la distribuzione a posteriori.\n\nNel caso presente\n\n\nStima del \\(R^2\\): Il modello spiega in media circa il 57% della varianza osservata nella variabile dipendente.\n\nErrore Standard: L’incertezza sulla stima è relativamente bassa (±0.02).\n\nIntervallo di Credibilità: C’è un 95% di probabilità che il vero valore del \\(R^2\\) si trovi tra 0.52 e 0.61.\n\n\n64.9.1 Differenze rispetto al Frequentista \\(R^2\\)\n\n\n\nIncertezza: Il Bayes \\(R^2\\) include un’intera distribuzione a posteriori, permettendo di rappresentare l’incertezza attraverso l’intervallo di credibilità. Questo non è possibile con il \\(R^2\\) frequentista, che fornisce una stima puntuale.\n\nPriors: Il Bayes \\(R^2\\) è influenzato dai priors scelti per i parametri del modello, il che consente una maggiore flessibilità e incorpora conoscenze preesistenti.\n\nIn conclusione, il Bayes \\(R^2\\) è uno strumento potente per valutare l’adattamento di un modello bayesiano, permettendo di quantificare non solo la proporzione di varianza spiegata, ma anche l’incertezza associata alla stima.\n\nr2_draws &lt;- bayes_R2(fit_2, summary = FALSE)\n\n\nr2_df &lt;- data.frame(R2 = as.numeric(r2_draws))\n\n\nggplot(r2_df, aes(x = R2)) +\n  geom_density(fill = \"skyblue\", alpha = 0.6) +\n  geom_rug(alpha = 0.2) +\n  labs(\n    title = \"Distribuzione a posteriori di R²\",\n    x = expression(R^2),\n    y = \"Densità\"\n  ) \n\n\n\n\n\n\n\n\nround(quantile(r2_df$R2, probs = c(.025, .5, .975)), 3)\n#&gt;  2.5%   50% 97.5% \n#&gt; 0.520 0.569 0.609\n\nLo stesso risultato si ottiene con la funzione mcmc_areas() di bayesplot:\n\nmcmc_areas(r2_draws, prob = 0.95) +\n  ggtitle(\"Posterior di R² (area = 95% CI)\")",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html#approfondimento-sulla-manipolazione-della-distribuzione-a-posteriori-con-brms",
    "href": "chapters/linear_models/04_synt_sugar.html#approfondimento-sulla-manipolazione-della-distribuzione-a-posteriori-con-brms",
    "title": "64  Zucchero sintattico",
    "section": "\n64.10 Approfondimento sulla manipolazione della distribuzione a posteriori con brms\n",
    "text": "64.10 Approfondimento sulla manipolazione della distribuzione a posteriori con brms\n\nDi seguito illustriamo come accedere e manipolare i campioni generati dal modello bayesiano in brms. Supponiamo di aver costruito un modello lineare semplice, dove vogliamo predire la variabile height in funzione di weight_c:\nfit_2 = brm(\n  bf(height ~ 1 + weight_c, center = FALSE), \n  prior = prior_guassian,\n  data = df, \n  backend = \"cmdstanr\", \n  silent = 0\n)\nUna volta che il modello è stato adattato e abbiamo ottenuto l’oggetto fit_2, possiamo estrarre le draws (ossia i campioni) della distribuzione a posteriori tramite la funzione as_draws():\n\nposterior_2 &lt;- as_draws(fit_2)\n\nL’oggetto posterior_2 ottenuto è di tipo draws (una struttura definita dal pacchetto posterior), che internamente può essere rappresentato come una lista o un array in cui sono memorizzati i campioni MCMC:\n\nstr(posterior_2)\n#&gt; List of 4\n#&gt;  $ 1:List of 5\n#&gt;   ..$ b_Intercept: num [1:1000] 154 154 155 154 154 ...\n#&gt;   ..$ b_weight_c : num [1:1000] 0.955 0.95 0.962 0.969 0.905 ...\n#&gt;   ..$ sigma      : num [1:1000] 5.42 5.31 5.54 5.4 5.22 ...\n#&gt;   ..$ lprior     : num [1:1000] -8.76 -8.75 -8.78 -8.76 -8.72 ...\n#&gt;   ..$ lp__       : num [1:1000] -1080 -1080 -1081 -1081 -1078 ...\n#&gt;  $ 2:List of 5\n#&gt;   ..$ b_Intercept: num [1:1000] 155 155 154 154 154 ...\n#&gt;   ..$ b_weight_c : num [1:1000] 0.922 0.804 0.933 0.933 0.925 ...\n#&gt;   ..$ sigma      : num [1:1000] 4.88 5.11 5 5 5.2 ...\n#&gt;   ..$ lprior     : num [1:1000] -8.61 -8.67 -8.67 -8.67 -8.75 ...\n#&gt;   ..$ lp__       : num [1:1000] -1082 -1081 -1078 -1078 -1082 ...\n#&gt;  $ 3:List of 5\n#&gt;   ..$ b_Intercept: num [1:1000] 154 154 154 155 155 ...\n#&gt;   ..$ b_weight_c : num [1:1000] 0.841 0.87 0.861 0.976 0.97 ...\n#&gt;   ..$ sigma      : num [1:1000] 5.2 5.08 5.06 5.17 5.31 ...\n#&gt;   ..$ lprior     : num [1:1000] -8.71 -8.7 -8.68 -8.69 -8.71 ...\n#&gt;   ..$ lp__       : num [1:1000] -1080 -1079 -1079 -1080 -1081 ...\n#&gt;  $ 4:List of 5\n#&gt;   ..$ b_Intercept: num [1:1000] 154 155 154 155 154 ...\n#&gt;   ..$ b_weight_c : num [1:1000] 0.821 0.981 0.863 0.933 0.954 ...\n#&gt;   ..$ sigma      : num [1:1000] 5.04 5.15 5.2 5.13 5 ...\n#&gt;   ..$ lprior     : num [1:1000] -8.69 -8.69 -8.72 -8.68 -8.68 ...\n#&gt;   ..$ lp__       : num [1:1000] -1081 -1080 -1079 -1079 -1079 ...\n#&gt;  - attr(*, \"class\")= chr [1:3] \"draws_list\" \"draws\" \"list\"\n\nQuesta ispezione ci permette di vedere che l’oggetto contiene le catene e i parametri campionati.\nPossiamo estrarre i nomi dei parametri del modello dall’oggetto creato da brm() nel modo seguente:\n\nvariables(fit_2)\n#&gt; [1] \"b_Intercept\" \"b_weight_c\"  \"sigma\"       \"lprior\"      \"lp__\"\n\nNel nostro esempio, siamo interessati al coefficiente di regressione associato a weight_c, che in brms è etichettato come b_weight_c. Per semplificare la manipolazione e l’analisi, possiamo servirci di tidybayes, un pacchetto che fornisce funzioni utili per trasformare i campioni in formati “tidy”.\n\nb_slope_draws &lt;- posterior_2 |&gt; \n  spread_draws(b_weight_c)\n\nLa funzione spread_draws() estrae e “srotola” le draw dei parametri in un tibble, che risulta più comodo da esplorare:\n\nhead(b_slope_draws)\n#&gt; # A tibble: 6 × 4\n#&gt;   .chain .iteration .draw b_weight_c\n#&gt;    &lt;int&gt;      &lt;int&gt; &lt;int&gt;      &lt;dbl&gt;\n#&gt; 1      1          1     1      0.955\n#&gt; 2      1          2     2      0.950\n#&gt; 3      1          3     3      0.962\n#&gt; 4      1          4     4      0.969\n#&gt; 5      1          5     5      0.905\n#&gt; 6      1          6     6      0.888\n\nIn questo modo, ogni riga corrisponde a un singolo campione della catena MCMC, per quel parametro.\nUna volta estratti i campioni del parametro di interesse (qui b_weight_c), possiamo calcolare facilmente statistiche come quantili e medie:\n\nquantile(b_slope_draws$b_weight_c, probs = c(0.03, 0.50, 0.97))\n#&gt;     3%    50%    97% \n#&gt; 0.8263 0.9037 0.9839\n\n\nmean(b_slope_draws$b_weight_c)\n#&gt; [1] 0.9047\n\n\nI quantili a 0.03, 0.50 e 0.97 forniscono, rispettivamente, un limite inferiore al 94% (0.03–0.97), la mediana a posteriori (0.50) e un limite superiore.\n\nLa funzione mean() restituisce la media a posteriori del coefficiente, un’altra statistica utile per la stima puntuale.\n\nPer comprendere meglio la forma della distribuzione a posteriori, è buona prassi tracciarne la densità. Con tidyverse e tidybayes, possiamo creare un grafico elegante in poche righe:\n\ntibble(beta = b_slope_draws$b_weight_c) %&gt;%\n  ggplot(aes(x = beta)) +\n  stat_halfeye(fill = \"skyblue\", alpha = 0.6) +\n  labs(\n    title = \"Distribuzione a posteriori di β (b_weight_c)\",\n    x = \"Valore di β\",\n    y = \"Densità a posteriori\"\n  )\n\n\n\n\n\n\n\n\n\nstat_halfeye() mostra la densità stimata dei campioni, evidenziando in modo intuitivo i valori più probabili.\n\nIl colore e l’alpha permettono di personalizzare l’aspetto del grafico.\n\nIn sintesi, utilizzando l’oggetto restituito da brm() e la funzione as_draws(), possiamo estrarre i campioni della distribuzione a posteriori e analizzare:\n\n\nstatistiche di sintesi, come media, mediana e quantili;\n\ndistribuzioni di densità, per una visualizzazione più immediata della variabilità e della forma della distribuzione a posteriori di un parametro.\n\nLa combinazione di posterior, tidybayes e tidyverse rende l’intero flusso di lavoro — dall’estrazione dei campioni fino alla creazione di grafici e statistiche — semplice e flessibile.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html#riflessioni-conclusive",
    "href": "chapters/linear_models/04_synt_sugar.html#riflessioni-conclusive",
    "title": "64  Zucchero sintattico",
    "section": "\n64.11 Riflessioni Conclusive",
    "text": "64.11 Riflessioni Conclusive\nQuesto capitolo ha mostrato come utilizzare brms per costruire e interpretare modelli lineari, evidenziando le sue capacità di gestione dei priors, diagnostica e modellizzazione robusta. Grazie alla sua semplicità e flessibilità, brms rappresenta un potente strumento per l’inferenza bayesiana.\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nModello base\nImporta il dataset Howell_18.csv, filtra gli individui di età ≥ 18 anni e adatta un modello bayesiano lineare height ∼ weight usando brm(). Visualizza il sommario.\nCentraggio del predittore\nCalcola la variabile centrata weight_c e adatta il modello height ∼ weight_c. Confronta l’intercetta (b_Intercept) con quella del modello non centrato. Spiega la differenza.\n\nSpecificazione dei prior\nUsa get_prior() per recuperare i prior di default, poi definisci manualmente prior debolmente informativi:\n\nIntercept ∼ Normal(150, 20)\nweight_c ∼ Normal(0, 10)\nsigma ∼ Cauchy(0, 5)\n\nAdatta il modello con questi prior e confronta le stime a posteriori con quelle del modello con prior di default.\n\n\nPredizioni predittive a posteriori\nPer il modello con prior personalizzati:\n\nEsegui pp_check() per la densità e per l’errore medio (type = \"error_scatter_avg\").\nDescrivi brevemente cosa mostrano i due grafici.\n\n\n\nModello robusto\nIntroduci un outlier modificando il primo record: imposta height = 400.\n\nAdatta prima un modello gaussiano e poi uno robusto con family = student().\nConfronta le stime di b_weight_c nei due modelli e discuti l’impatto dell’outlier.\n\n\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n\n\nModello base\nlibrary(brms)\ndf &lt;- rio::import(\"data/Howell_18.csv\")\ndf_adults &lt;- subset(df, age &gt;= 18)\nfit_base &lt;- brm(height ~ weight, data = df_adults, backend = \"cmdstanr\")\nsummary(fit_base)\n\n\nCentraggio del predittore\ndf_adults$weight_c &lt;- df_adults$weight - mean(df_adults$weight)\nfit_centered &lt;- brm(height ~ weight_c, data = df_adults, backend = \"cmdstanr\")\nsummary(fit_centered)\n\nIl b_Intercept nel modello non centrato è l’altezza prevista per peso = 0 (non interpretabile realisticamente).\n\nNel modello centrato, l’intercetta rappresenta l’altezza media alla media del peso del campione.\n\n\n\nSpecificazione dei prior\nget_prior(height ~ weight_c, data = df_adults)\n\npriors_custom &lt;- c(\n  prior(normal(150, 20), class = \"b\", coef = \"Intercept\"),\n  prior(normal(0, 10), class = \"b\", coef = \"weight_c\"),\n  prior(cauchy(0, 5), class = \"sigma\")\n)\nfit_priors &lt;- brm(\n  height ~ weight_c,\n  data = df_adults,\n  prior = priors_custom,\n  backend = \"cmdstanr\"\n)\nsummary(fit_priors)\n\nLe stime a posteriori rimangono simili, ma i prior personalizzati influenzano leggermente l’incertezza.\n\n\n\nPredizioni predittive a posteriori\npp_check(fit_priors)\npp_check(fit_priors, type = \"error_scatter_avg\")\n\nIl grafico di densità mostra se la distribuzione simulata riproduce quella osservata.\n\nIl grafico degli errori media evidenzia eventuali pattern sistematici nei residui.\n\n\n\nModello robusto\ndf_out &lt;- df_adults\ndf_out$height[1] &lt;- 400\nfit_gauss &lt;- brm(height ~ weight_c, data = df_out, backend = \"cmdstanr\")\nfit_student &lt;- brm(height ~ weight_c, family = student(),\n                   data = df_out, backend = \"cmdstanr\")\nsummary(fit_gauss)$fixed[\"weight_c\", ]\nsummary(fit_student)$fixed[\"weight_c\", ]\n\nIl modello gaussiano vede una variazione marcata di b_weight_c a causa dell’outlier.\n\nIl modello Student stima un coefficiente più vicino al valore senza outlier, dimostrando robustezza.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/04_synt_sugar.html#informazioni-sullambiente-di-sviluppo",
    "title": "64  Zucchero sintattico",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] tidybayes_3.0.7  cmdstanr_0.9.0   posterior_1.6.1  brms_2.22.0     \n#&gt;  [5] Rcpp_1.0.14      thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0\n#&gt;  [9] see_0.11.0       gridExtra_2.3    patchwork_1.3.0  bayesplot_1.12.0\n#&gt; [13] psych_2.5.3      scales_1.4.0     markdown_2.0     knitr_1.50      \n#&gt; [17] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [21] purrr_1.0.4      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [25] ggplot2_3.5.2    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] mnormt_2.1.1         inline_0.3.21        rlang_1.1.6         \n#&gt;  [4] magrittr_2.0.3       ggridges_0.5.6       matrixStats_1.5.0   \n#&gt;  [7] compiler_4.5.0       loo_2.8.0            vctrs_0.6.5         \n#&gt; [10] reshape2_1.4.4       pkgconfig_2.0.3      arrayhelpers_1.1-0  \n#&gt; [13] fastmap_1.2.0        backports_1.5.0      labeling_0.4.3      \n#&gt; [16] utf8_1.2.5           rmarkdown_2.29       tzdb_0.5.0          \n#&gt; [19] ps_1.9.1             xfun_0.52            jsonlite_2.0.0      \n#&gt; [22] parallel_4.5.0       R6_2.6.1             stringi_1.8.7       \n#&gt; [25] RColorBrewer_1.1-3   StanHeaders_2.32.10  estimability_1.5.1  \n#&gt; [28] rstan_2.32.7         pacman_0.5.1         R.utils_2.13.0      \n#&gt; [31] Matrix_1.7-3         timechange_0.3.0     tidyselect_1.2.1    \n#&gt; [34] rstudioapi_0.17.1    abind_1.4-8          yaml_2.3.10         \n#&gt; [37] codetools_0.2-20     curl_6.2.2           processx_3.8.6      \n#&gt; [40] pkgbuild_1.4.7       lattice_0.22-7       plyr_1.8.9          \n#&gt; [43] withr_3.0.2          bridgesampling_1.1-2 coda_0.19-4.1       \n#&gt; [46] evaluate_1.0.3       RcppParallel_5.1.10  ggdist_3.3.3        \n#&gt; [49] pillar_1.10.2        tensorA_0.36.2.1     checkmate_2.3.2     \n#&gt; [52] stats4_4.5.0         distributional_0.5.0 generics_0.1.4      \n#&gt; [55] rprojroot_2.0.4      hms_1.1.3            rstantools_2.4.0    \n#&gt; [58] xtable_1.8-4         glue_1.8.0           emmeans_1.11.1      \n#&gt; [61] tools_4.5.0          data.table_1.17.2    mvtnorm_1.3-3       \n#&gt; [64] grid_4.5.0           QuickJSR_1.7.0       colorspace_2.1-1    \n#&gt; [67] nlme_3.1-168         cli_3.6.5            svUnit_1.0.6        \n#&gt; [70] Brobdingnag_1.2-9    V8_6.0.3             gtable_0.3.6        \n#&gt; [73] R.methodsS3_1.8.2    digest_0.6.37        htmlwidgets_1.6.4   \n#&gt; [76] farver_2.1.2         htmltools_0.5.8.1    R.oo_1.27.1         \n#&gt; [79] lifecycle_1.0.4",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html#bibliografia",
    "href": "chapters/linear_models/04_synt_sugar.html#bibliografia",
    "title": "64  Zucchero sintattico",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlter, U., Too, M. A., & Cribbie, R. A. (2025). Navigating the Bayes maze: The psychologist’s guide to Bayesian statistics, a hands-on tutorial with R code. International Journal of Psychology, 60(1), e13271.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nWilkinson, G., & Rogers, C. (1973). Symbolic description of factorial models for analysis of variance. Journal of the Royal Statistical Society Series C: Applied Statistics, 22(3), 392–399.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html",
    "href": "chapters/linear_models/05_one_mean.html",
    "title": "65  Inferenza bayesiana su una media",
    "section": "",
    "text": "65.1 Preparazione del Notebook\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, posterior, bayestestR, brms, ggdist)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#introduzione",
    "href": "chapters/linear_models/05_one_mean.html#introduzione",
    "title": "65  Inferenza bayesiana su una media",
    "section": "\n65.2 Introduzione",
    "text": "65.2 Introduzione\nL’obiettivo principale di questo capitolo è esaminare un contesto che abbiamo già preso in considerazione in precedenza: ci troviamo di fronte a un campione di dati misurati su una scala a intervalli o rapporti e desideriamo effettuare inferenze sulla media della popolazione da cui il campione è stato estratto. Tuttavia, anziché procedere con una derivazione analitica della distribuzione a posteriori della media della popolazione, in questo caso utilizzeremo brms.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#il-modello-normale",
    "href": "chapters/linear_models/05_one_mean.html#il-modello-normale",
    "title": "65  Inferenza bayesiana su una media",
    "section": "\n65.3 Il modello Normale",
    "text": "65.3 Il modello Normale\nI priori coniugati Normali di una Normale non richiedono l’approssimazione numerica ottenuta mediante metodi MCMC. In questo capitolo, tuttavia, ripetiamo l’esercizio descritto nel Capitolo 52 usando brms.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#un-esempio-concreto",
    "href": "chapters/linear_models/05_one_mean.html#un-esempio-concreto",
    "title": "65  Inferenza bayesiana su una media",
    "section": "\n65.4 Un esempio concreto",
    "text": "65.4 Un esempio concreto\nPer applicare il modello Normale, utilizzeremo i dati del censimento parziale dell’area di Dobe dei !Kung San, raccolti attraverso interviste condotte da Nancy Howell alla fine degli anni ’60. I !Kung San sono una suddivisione della popolazione San, che vive nel deserto del Kalahari, tra Namibia, Botswana e Angola, e mantengono un’economia basata su caccia e raccolta. Riprodurremo l’analisi descritta da McElreath (2020), esaminando unicamente i valori dell’altezza di individui di età superiore ai 18 anni.\n\ndf &lt;- rio::import(here::here(\"data\", \"Howell_18.csv\"))\ndf |&gt; \n  head()\n#&gt;   height weight age male\n#&gt; 1  151.8  47.83  63    1\n#&gt; 2  139.7  36.49  63    0\n#&gt; 3  136.5  31.86  65    0\n#&gt; 4  156.8  53.04  41    1\n#&gt; 5  145.4  41.28  51    0\n#&gt; 6  163.8  62.99  35    1\n\nIl campione include 352 osservazioni:\n\nlength(df$height)\n#&gt; [1] 352\n\n\nggplot(df, aes(x = height)) +\n  geom_histogram(binwidth = 5, color = \"black\", fill = \"lightblue\") +\n  labs(title = \"Istogramma dell'Altezza\", x = \"Altezza (cm)\", y = \"Frequenza\") +\n  theme(\n    plot.title = element_text(hjust = 0.5)\n  )\n\n\n\n\n\n\n\nCome indicato dall’istogramma, i dati sono approssimativamente distribuiti in maniera gaussiana:\n\ndf |&gt;\n  ggplot(aes(sample = height)) +\n  stat_qq() +\n  stat_qq_line(colour = \"red\") +\n  labs(\n    title = \"Normal Q-Q plot\",\n    x = \"Teorici (Z-score)\",\n    y = \"Valori osservati\"\n  ) +\n  theme(\n    plot.title = element_text(hjust = 0.5)\n  )\n\n\n\n\n\n\n\nIn realtà, dal Q-Q plot si nota un piccolo scostamento sistematico. Quando la retta che approssima i punti empirici risulta più piatta rispetto alla diagonale teorica (che avrebbe pendenza 1 se i dati fossero perfettamente normali), la distribuzione empirica risulta meno dispersa di una Gaussiana di riferimento: i quantili empirici aumentano più lentamente di quelli teorici, indicando una varianza leggermente inferiore (o code meno ampie). Nel caso presente, tuttavia, questo scostamento è di modesta entità e si può comunque procedere all’adattamento di un modello gaussiano.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#modello-bayesiano-per-una-singola-media",
    "href": "chapters/linear_models/05_one_mean.html#modello-bayesiano-per-una-singola-media",
    "title": "65  Inferenza bayesiana su una media",
    "section": "\n65.5 Modello Bayesiano per una singola media",
    "text": "65.5 Modello Bayesiano per una singola media\nImmaginiamo di voler modellare l’altezza (in cm) di un gruppo di persone. Per ogni osservazione \\(y_n\\) (con \\(n=1,\\dots,N\\)) assumiamo:\n\\[\ny_n \\;\\sim\\; \\mathcal N\\!\\bigl(\\mu,\\;\\sigma\\bigr) ,\n\\]\ndove\n\n\n\\(\\mu\\) è la media vera (ignota) dell’altezza nella popolazione;\n\n\\(\\sigma\\) è la deviazione standard vera (anch’essa ignota), che misura quanto le altezze oscillano attorno a \\(\\mu\\).\n\n\n65.5.1 Cosa significa l’assunzione “iid”\n\nIdenticamente distribuiti – tutti i \\(t_n\\) provengono dalla stessa distribuzione normale \\(\\mathcal N(\\mu,\\sigma)\\).\n\nIndipendenti – conoscere l’errore commesso su un individuo non dà alcuna informazione sull’errore commesso su un altro:\n\\[\n  \\operatorname{cov}(y_i-\\mu,\\; y_j-\\mu)=0 \\quad\\text{per } i\\neq j.\n\\]\n\n\nScrivere “\\(y_n \\sim \\mathcal N(\\mu,\\sigma)\\)” è quindi un modo compatto per dire che i dati osservati sono iid dalla distribuzione normale parametrizzata da \\(\\mu\\) e \\(\\sigma\\).\n\n65.5.2 Esplorare i dati\nPrima di inserire priors ed eseguire l’inferenza Bayesiana può essere utile vedere che cosa raccontano i dati grezzi.\n\n# media campionaria\nmean(df$height)\n#&gt; [1] 154.6\n\n# deviazione standard campionaria\nsd(df$height)\n#&gt; [1] 7.742\n\n\n\nMedia campionaria: una stima preliminare di \\(\\mu\\).\n\nDeviazione standard campionaria: una stima preliminare di \\(\\sigma\\).\n\nQuesti riassunti non sostituiscono l’inferenza Bayesiana, ma aiutano a:\n\n\nscegliere priors ragionevoli (per esempio centrare la prior di \\(\\mu\\) vicino alla media campionaria).\n\ncontrollare outlier o errori di misura che, essendo la Normal sensibile agli estremi, potrebbero distorcere l’analisi.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#il-modello-frequentista",
    "href": "chapters/linear_models/05_one_mean.html#il-modello-frequentista",
    "title": "65  Inferenza bayesiana su una media",
    "section": "\n65.6 Il modello frequentista",
    "text": "65.6 Il modello frequentista\nNel contesto frequentista, se vogliamo stimare la media dell’altezza nella popolazione, possiamo usare un modello lineare molto semplice: un modello senza predittori, che stima solo l’intercetta.\nIn R, questo si traduce nella formula:\nheight ~ 1\nIl simbolo 1 indica che vogliamo stimare solo l’intercetta, cioè la media dell’altezza nel campione. Il modello si può specificare così:\n\nfm1 &lt;- lm(\n  formula = height ~ 1, \n  data = df\n)\n\n\n65.6.1 Interpretazione del modello\nL’output del comando:\n\nsummary(fm1)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = height ~ 1, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -18.072  -6.007  -0.292   6.058  24.473 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)\n#&gt; (Intercept)  154.597      0.413     375   &lt;2e-16\n#&gt; \n#&gt; Residual standard error: 7.74 on 351 degrees of freedom\n\nmostra:\n\nla stima puntuale dell’intercetta (\\(\\hat{\\alpha}\\)), che in questo caso coincide con la media campionaria di height;\nl’errore standard della stima;\nil p-value (relativo all’ipotesi nulla che la media sia zero, anche se raramente è di interesse reale);\nl’R-squared, che però non è informativo in un modello senza predittori.\n\n65.6.2 Intervallo di confidenza al 95% per la media\nPer ottenere l’intervallo di confidenza frequentista al 95% per \\(\\alpha\\) (cioè per la media campionaria), possiamo usare la funzione confint():\n\nconfint(fm1, level = 0.95)\n#&gt;             2.5 % 97.5 %\n#&gt; (Intercept) 153.8  155.4\n\nQuest’intervallo si basa sulla formula classica:\n\\[\n\\hat{\\alpha} \\pm t_{\\text{df}} \\cdot \\text{SE}(\\hat{\\alpha})\n\\]\ndove:\n\n\n\\(\\hat{\\alpha}\\) è la stima puntuale della media;\n\n\\(t_{\\text{df}}\\) è il quantile della distribuzione t di Student, con un numero di gradi di libertà pari a \\(n - 1\\);\n\n\\(\\text{SE}(\\hat{\\alpha})\\) è l’errore standard della stima.\n\n65.6.3 Calcolo manuale dell’intervallo\nSe vogliamo calcolare l’intervallo “a mano”, possiamo scrivere:\n\ncoef(fm1) + c(-1, 1) * qt(0.975, df.residual(fm1)) * 0.413\n#&gt; [1] 153.8 155.4\n\n\n\ncoef(fm1) restituisce la stima della media;\n\nqt(0.975, df.residual(fm1)) restituisce il valore critico della distribuzione \\(t\\) per un intervallo al 95%;\n\n0.413 è l’errore standard della stima (può essere sostituito con il valore esatto fornito da summary(fm1)).\n\nIn sintesi, questo è l’approccio frequentista classico per stimare la media e costruire un intervallo di confidenza. Si basa su:\n\nla distribuzione campionaria della media,\nl’assunzione di normalità e indipendenza degli errori.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#modello-bayesiano-senza-specificare-prior-prior-debolmente-informativi",
    "href": "chapters/linear_models/05_one_mean.html#modello-bayesiano-senza-specificare-prior-prior-debolmente-informativi",
    "title": "65  Inferenza bayesiana su una media",
    "section": "\n65.7 Modello Bayesiano senza specificare prior (prior debolmente informativi)",
    "text": "65.7 Modello Bayesiano senza specificare prior (prior debolmente informativi)\nDopo aver stimato la media dell’altezza con il modello frequentista, ora vogliamo replicare lo stesso modello usando un approccio bayesiano con il pacchetto brms.\nNel modello bayesiano, è sempre necessario specificare delle distribuzioni a priori per i parametri. Tuttavia, se non le specifichiamo esplicitamente, brms utilizzerà dei prior debolmente informativi: distribuzioni ampie e generiche, che influenzano poco l’inferenza quando i dati sono informativi. In pratica, è come dire “non abbiamo forti idee a priori, lasciamo che siano i dati a parlare”.\n\n65.7.1 Specifica del modello\nIl codice per stimare il modello è simile a quello usato con lm():\n\nfm2 &lt;- brm(\n  formula = height ~ 1,        # come prima, stimiamo solo l'intercetta\n  family = gaussian(),         # specifica la distribuzione dei dati (Normal)\n  data = df,                   # dataset\n  chains = 4,                  # numero di catene indipendenti\n  iter = 2000,                 # numero totale di iterazioni per catena\n  warmup = 1000,               # iterazioni iniziali usate per \"scaldare\" l'algoritmo\n  backend = \"cmdstanr\"         # motore di calcolo usato (più veloce e trasparente)\n)\n\nVediamo nel dettaglio alcune opzioni:\n\nformula = height ~ 1 Indica che stiamo stimando solo l’intercetta, cioè la media dell’altezza.\nfamily = gaussian() Rende esplicito che i dati seguono una distribuzione normale. (Con lm() era implicito.)\nprior = ... In questo caso non lo abbiamo specificato, quindi brms userà i prior di default (debolmente informativi).\n\nchains, iter, warmup Sono parametri che controllano come viene effettuato il campionamento Bayesiano, cioè la stima della distribuzione a posteriori dei parametri:\n\n\nchains: quante catene indipendenti vengono eseguite (default = 4).\n\niter: numero totale di iterazioni per catena.\n\nwarmup: prime iterazioni da scartare (servono ad “adattare” il campionatore).\n\n\n\nL’algoritmo usato da brms per il campionamento si chiama NUTS (No-U-Turn Sampler), un’evoluzione del metodo Hamiltonian Monte Carlo. È molto efficiente nel campionare distribuzioni complesse.\n\n65.7.2 Struttura del modello\nAnche in questo caso, il modello può essere scritto così:\n\\[\ny_i = \\alpha + \\varepsilon_i, \\quad \\varepsilon_i \\sim \\mathcal{N}(0, \\sigma)\n\\]\nLa differenza è che qui stiamo stimando la distribuzione a posteriori di \\(\\alpha\\) e \\(\\sigma\\), e non solo un valore puntuale.\n\n65.7.3 Analisi dell’output\nUna volta stimato il modello, possiamo esaminare i risultati con:\n\nsummary(fm2)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: height ~ 1 \n#&gt;    Data: df (Number of observations: 352) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept   154.59      0.41   153.76   155.38 1.00     2729     2179\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     7.77      0.30     7.20     8.37 1.00     3096     2129\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nL’output mostrerà:\n\nla media (o mediana) della distribuzione a posteriori per \\(\\alpha\\) (cioè la nostra stima della media dell’altezza),\nl’errore standard a posteriori,\nl’intervallo di credibilità al 95%, che rappresenta la zona in cui, dato il modello e i dati, si trova con alta probabilità il valore vero di \\(\\alpha\\).\n\nQuesto intervallo di credibilità è diverso dall’intervallo di confidenza frequentista: in ottica bayesiana possiamo davvero dire che “c’è il 95% di probabilità che \\(\\alpha\\) sia dentro l’intervallo”, dato che stiamo ragionando in termini di probabilità sui parametri.\nSe il modello converge correttamente (nessun avviso di problemi), il comando summary() fornisce un riassunto completo della stima Bayesiana, rendendo il passaggio dal mondo frequentista a quello bayesiano molto intuitivo.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#riportare-i-risultati",
    "href": "chapters/linear_models/05_one_mean.html#riportare-i-risultati",
    "title": "65  Inferenza bayesiana su una media",
    "section": "\n65.8 Riportare i Risultati",
    "text": "65.8 Riportare i Risultati\nNel caso frequentista, il risultato può essere riportato nel modo seguente:\n\nl’analisi ha fornito una stima puntuale di α pari a 154.6, con un intervallo di confidenza al 95% compreso tra [153.8; 155.4].\n\nNel caso bayesiano diciamo:\n\nl’analisi bayesiana, condotta con una prior non informativa, ha restituito una stima a posteriori di α pari a 154.6, con un intervallo di credibilità al 95% [153.8; 155.4].\n\n\n65.8.1 Analisi dei Campioni a Posteriori\nDopo aver stimato il modello con brm(), possiamo accedere ai campioni a posteriori dei parametri. Ogni campione rappresenta una possibile combinazione di valori plausibili di \\(\\alpha\\) (la media) e \\(\\sigma\\) (la deviazione standard), estratta dalla distribuzione a posteriori.\nPer esplorare questi campioni, usiamo:\n\nas_draws_df(fm2) %&gt;% \n  head(3)\n#&gt; # A draws_df: 3 iterations, 1 chains, and 5 variables\n#&gt;   b_Intercept sigma Intercept lprior  lp__\n#&gt; 1         155   8.0       155   -6.1 -1224\n#&gt; 2         155   7.5       155   -6.0 -1224\n#&gt; 3         155   8.1       155   -6.1 -1225\n#&gt; # ... hidden reserved variables {'.chain', '.iteration', '.draw'}\n\nNella tabella risultante, la colonna b_Intercept rappresenta i campioni per \\(\\mu\\), cioè la media dell’altezza stimata a posteriori.\nPossiamo ignorare le ultime tre colonne:\n\n\nIntercept: un’intercetta “ausiliaria” usata se ci fossero predittori centrati (coincide con b_Intercept in questo caso).\n\nlprior: la log-verosimiglianza del prior, utile per strumenti diagnostici (es. con il pacchetto priorsense).\n\nlp__: la log-verosimiglianza a posteriori non normalizzata, utile per il campionamento ma non per l’inferenza diretta.\n\n65.8.2 Calcoli riassuntivi sui campioni a posteriori\nPossiamo calcolare direttamente media, deviazione standard e intervallo di credibilità al 95% per \\(\\mu\\), usando i campioni della colonna b_Intercept:\n\n# Media a posteriori (stima puntuale)\nas_draws_df(fm2)$b_Intercept %&gt;% mean()\n#&gt; [1] 154.6\n\n\n# Deviazione standard a posteriori (errore standard)\nas_draws_df(fm2)$b_Intercept %&gt;% sd()\n#&gt; [1] 0.4117\n\n\n# Intervallo di credibilità al 95%\nas_draws_df(fm2)$b_Intercept %&gt;% quantile(c(0.025, 0.975))\n#&gt;  2.5% 97.5% \n#&gt; 153.8 155.4\n\n\n65.8.3 Conclusioni Intermedie\n\nCon lm() (modello frequentista), otteniamo una stima puntuale di \\(\\alpha\\) tramite il metodo della massima verosimiglianza, e un intervallo di confidenza al 95%, che esprime quanto sarebbe variabile la nostra stima in campioni ripetuti.\nCon brm() (modello bayesiano), otteniamo una distribuzione a posteriori per \\(\\alpha\\), che riflette l’incertezza residua dopo aver visto i dati. Anche usando un prior debolmente informativo, i risultati numerici sono molto simili a quelli frequentisti—ma la prospettiva interpretativa è diversa: un intervallo come \\([153.78,\\ 155.41]\\) significa che c’è il 95% di probabilità che il vero valore di \\(\\alpha\\) sia compreso in quell’intervallo.\nSe decidessimo di includere informazioni a priori specifiche (ad esempio, provenienti da studi precedenti), potremmo definire un prior informativo per \\(\\alpha\\) all’interno di brm(). In questo caso, i risultati potrebbero divergere sensibilmente da quelli frequentisti, soprattutto quando i dati sono scarsi o poco informativi.\n\nQuesto esempio mostra come il modello bayesiano generalizzi il caso frequentista, offrendo maggiore flessibilità e un’interpretazione probabilistica più diretta.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#uso-dei-prior-nel-modello-bayesiano",
    "href": "chapters/linear_models/05_one_mean.html#uso-dei-prior-nel-modello-bayesiano",
    "title": "65  Inferenza bayesiana su una media",
    "section": "\n65.9 Uso dei Prior nel Modello Bayesiano",
    "text": "65.9 Uso dei Prior nel Modello Bayesiano\nAbbiamo visto che è possibile stimare il nostro modello anche senza specificare esplicitamente le distribuzioni a priori, ottenendo comunque le distribuzioni a posteriori dei parametri. Tuttavia, prima di interpretare i risultati, è importante porsi alcune domande fondamentali:\n\nQuali informazioni stiamo introducendo attraverso i prior?\nI prior riflettono credenze plausibili e coerenti con il contesto del problema?\nLa funzione di verosimiglianza scelta è adatta ai dati osservati?\n\nPer rispondere a queste domande, nei prossimi passaggi esamineremo sia la distribuzione predittiva a priori sia quella a posteriori, e condurremo analisi di sensibilità ai prior. Questi strumenti permettono di valutare quanto le assunzioni iniziali influenzino i risultati finali.\n\n65.9.1 Specificare i priori: un esempio concreto\nNel paradigma bayesiano, possiamo incorporare conoscenze pregresse sotto forma di distribuzioni a priori. In questo esempio, ipotizziamo di avere qualche aspettativa informata sull’altezza media e sulla sua variabilità. Assegniamo:\n\nuna prior \\(\\mathcal{N}(181,\\ 30)\\) per \\(\\mu\\), la media dell’altezza,\nuna prior \\(\\mathcal{N}(0,\\ 20)\\), troncata inferiormente a zero, per \\(\\sigma\\), la deviazione standard.\n\nLa scelta del valore centrale di 181 cm per \\(\\mu\\) segue l’esempio di McElreath (2020), che ironicamente propone la propria altezza come ipotesi iniziale informata. È un modo per mostrare che anche una conoscenza soggettiva può entrare nel modello, purché dichiarata apertamente.\n\n65.9.2 Descrizione formale del modello\nIl modello bayesiano assume la seguente forma:\n\\[\n\\begin{aligned}\nY_i &\\sim \\mathcal{N}(\\mu, \\sigma) \\\\\n\\mu &\\sim \\mathcal{N}(181,\\ 30) \\\\\n\\sigma &\\sim \\mathcal{N}^+(0,\\ 20)\n\\end{aligned}\n\\]\ndove:\n\n\n\\(Y_i\\) rappresenta l’altezza osservata per l’individuo \\(i\\),\n\n\\(\\mu\\) è la media da stimare,\n\n\\(\\sigma\\) è la deviazione standard,\n\n\\(\\mathcal{N}^+\\) indica una normale troncata per garantire che \\(\\sigma &gt; 0\\).\n\nIn ambito bayesiano, \\(\\mu\\) e \\(\\sigma\\) sono trattati come variabili casuali: non esistono come valori fissi da scoprire, ma come quantità soggette a incertezza, aggiornabili in base ai dati.\n\n65.9.3 Implementazione in brms\n\nIl codice per stimare questo modello in brms è il seguente:\n\nfm3 &lt;- brm(\n  formula = height ~ 1,             # Modello con sola intercetta (μ)\n  data    = df,\n  family  = gaussian(),             # Modello normale\n  prior   = c(\n    prior(normal(181, 30), class = \"Intercept\"),  # Prior informativo su μ\n    prior(normal(0, 20), class = \"sigma\")         # Prior (troncato) su σ\n  ),\n  chains  = 4,\n  iter    = 2000,\n  seed    = 1234,\n  backend = \"cmdstanr\"\n)\n\nUna volta stimato il modello, possiamo ottenere un riepilogo dei risultati con:\n\nsummary(fm3)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: height ~ 1 \n#&gt;    Data: df (Number of observations: 352) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept   154.60      0.41   153.80   155.41 1.00     3156     2659\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     7.77      0.29     7.20     8.38 1.00     3256     2596\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n65.9.4 Risultati e interpretazione\nAnche con questi prior informativi ma ampi, i risultati per \\(\\mu\\) saranno simili a quelli del modello frequentista se i dati sono sufficientemente informativi. In questo caso, i dati “prevalgono” sul prior: è un comportamento desiderabile quando i prior non sono troppo restrittivi.\n\n65.9.5 Cambiare il livello dell’intervallo di credibilità\nPossiamo chiedere a brms di calcolare un intervallo di credibilità all’89% (anziché al consueto 95%):\n\nsummary(fm3, prob = 0.89)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: height ~ 1 \n#&gt;    Data: df (Number of observations: 352) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-89% CI u-89% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept   154.60      0.41   153.94   155.27 1.00     3156     2659\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-89% CI u-89% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     7.77      0.29     7.32     8.25 1.00     3256     2596\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nMcElreath (2020) suggerisce l’intervallo all’89% come default nel suo approccio didattico, per evitare che i lettori lo interpretino come un test di significatività mascherato. Aggiunge anche con ironia:\n\nWhy 89%? It’s just the default. It displays a quite wide interval, so it shows a high-probability range of parameter values. If you want another interval, such as the conventional and mindless 95%, you can use precis(m4.1, prob = 0.95). But I don’t recommend 95% intervals, because readers will have a hard time not viewing them as significance tests. 89 is also a prime number, so if someone asks you to justify it, you can stare at them meaningfully and incant, ‘Because it is prime.’ That’s no worse justification than the conventional justification for 95%.\n\nOltre all’ironia, il messaggio è chiaro: la scelta dell’intervallo di credibilità deve riflettere una rappresentazione onesta dell’incertezza, piuttosto che un’adesione meccanica a convenzioni statistiche.\nIn sintesi, l’uso dei prior consente di:\n\nincorporare conoscenze pregresse nel modello,\nrendere l’inferenza più robusta quando i dati sono scarsi,\nesplicitare le proprie ipotesi, invece di nasconderle dietro un’apparente “oggettività”.\n\nNel modello bayesiano, ogni assunzione è esplicita, e i risultati sono interpretati come distribuzioni di probabilità sui parametri, non come stime puntuali affette da errore. Questo rende l’approccio particolarmente adatto in contesti in cui la trasparenza dell’incertezza è essenziale.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#funzioni-bayesplot",
    "href": "chapters/linear_models/05_one_mean.html#funzioni-bayesplot",
    "title": "65  Inferenza bayesiana su una media",
    "section": "\n65.10 Funzioni bayesplot\n",
    "text": "65.10 Funzioni bayesplot\n\nIl pacchetto bayesplot mette a disposizione un insieme di funzioni molto utili per visualizzare la distribuzione a posteriori di uno o più parametri e per verificare la bontà di adattamento del modello ai dati.\n\n65.10.1 Traceplot\nUn traceplot consente di verificare la convergenza delle catene MCMC e di controllare l’autocorrelazione dei campioni a posteriori. Nel seguente esempio, si mostrano le tracce (i valori campionati lungo le iterazioni) per i parametri “Intercept” e “sigma”:\n\nmcmc_trace(\n  fm3, \n  pars = c(\"Intercept\", \"sigma\"),\n  facet_args = list(nrow = 2)\n)\n\n\n\n\n\n\n\n\nL’asse orizzontale indica il numero di iterazione MCMC,\n\nL’asse verticale mostra il valore assunto dal parametro in quella iterazione,\n\nAvere catene che si mescolano bene e appaiono “stazionarie” (senza trend crescenti o calanti) è un buon segnale di convergenza.\n\n65.10.2 Distribuzione a posteriori di un singolo parametro\nSe vogliamo visualizzare la distribuzione a posteriori di un singolo parametro (ad esempio l’intercetta, qui chiamata “b_Intercept” nel modello brms), possiamo usare:\n\nmcmc_areas(fm3, regex_pars = \"b_Intercept\", prob = 0.89)\n\n\n\n\n\n\n\n\nViene mostrata la densità a posteriori, con un’area evidenziata corrispondente all’89% di credibilità (specificabile con prob = 0.89 o un altro valore).\n\nSe desideriamo un intervallo di credibilità al 95%, useremo prob = 0.95.\n\n65.10.3 Rappresentazione congiunta di due parametri\nPer studiare la relazione tra due parametri (ad esempio “Intercept” e “sigma”):\n\nmcmc_scatter(fm3, pars = c(\"Intercept\", \"sigma\"))\n\n\n\n\n\n\n\n\nSi ottiene un diagramma di dispersione dei campioni a posteriori sui due assi, uno per ciascun parametro, con eventuali isodensità che mostrano le aree più probabili nella distribuzione congiunta.\n\n65.10.4 Posterior Predictive Check\nLa funzione pp_check() è utilizzata per valutare se il modello è in grado di riprodurre i dati osservati:\n\npp_check(fm3)\n\n\n\n\n\n\n\n\nQuesta funzione genera un confronto tra la distribuzione dei dati reali (rappresentati, ad esempio, con una linea nera su un istogramma) e la distribuzione di diversi dataset simulati dal modello, sfruttando la distribuzione a posteriori dei parametri (\\(\\alpha\\), \\(\\sigma\\), ecc.).\n\nPoiché il modello bayesiano è generativo, possiamo campionare nuovi dati “fittizi” a partire da ogni draw della posterior: in questo modo otteniamo molteplici dataset simulati, ognuno generato con un diverso valore di \\(\\alpha\\) e \\(\\sigma\\) estratto dalle distribuzioni posteriori.\n\nNel grafico prodotto da pp_check(), i dati osservati compaiono spesso come linea continua nera, mentre i dati simulati dal modello (ad esempio, 8 repliche di default) sono mostrati in colori più chiari o linee semitrasparenti. Se la distribuzione empirica si sovrappone bene a quelle generate, significa che il modello spiega adeguatamente i dati.\n\nNel nostro caso, notiamo che le distribuzioni simulate risultano molto simili a quella osservata, indicando che la stima di \\(\\alpha\\) e \\(\\sigma\\) cattura in modo soddisfacente la variabilità dei dati.\n\nSe invece avessimo osservato discrepanze sistematiche (ad esempio, dati reali con code più pesanti, oppure un picco in posizioni diverse rispetto alle distribuzioni simulate), ci saremmo insospettiti riguardo all’adeguatezza del modello. In situazioni del genere, conviene rivedere le assunzioni (e.g. normalità, varianza costante, eventuali covariate assenti, ecc.) prima di trarre conclusioni dai risultati a posteriori.\n\nIn sintesi, il pacchetto bayesplot fornisce strumenti fondamentali per:\n\n\nValutare la convergenza delle catene MCMC (traceplot, autocorrelation plots),\n\n\nEsplorare la distribuzione a posteriori dei parametri (mcmc_areas, mcmc_density, mcmc_scatter, …),\n\n\nVerificare la bontà del modello rispetto ai dati osservati mediante posterior predictive checks (pp_check).\n\nQueste analisi grafiche forniscono informazioni cruciali sia sulla qualità del campionamento (e dunque sulla stabilità delle stime) sia sull’adeguatezza delle ipotesi modellistiche adottate.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#lapproccio-tradizionale",
    "href": "chapters/linear_models/05_one_mean.html#lapproccio-tradizionale",
    "title": "65  Inferenza bayesiana su una media",
    "section": "\n65.11 L’approccio Tradizionale",
    "text": "65.11 L’approccio Tradizionale\nPrima dell’avvento dei metodi bayesiani e di altri approcci moderni, l’inferenza sulla media di una popolazione veniva spesso affrontata ricorrendo al test t di Student.\n\n65.11.1 La statistica T di Student\nIl test si basa sulla seguente statistica:\n\\[\nT = \\frac{\\bar{X} - \\mu_0}{s / \\sqrt{n}},\n\\]\ndove:\n\n\n\\(\\bar{X}\\) è la media campionaria di \\(n\\) osservazioni,\n\n\n\\(\\mu_0\\) è il valore ipotizzato dalla cosiddetta “ipotesi nulla” (solitamente \\(\\mu_0 = 0\\), ma può essere qualsiasi valore di riferimento),\n\n\n\\(s\\) è la deviazione standard campionaria corretta (ovvero stimatore di \\(\\sigma\\)),\n\n\n\\(n\\) è la dimensione del campione.\n\nQuando \\(\\sigma\\) (deviazione standard vera) è sconosciuta e sostituita da \\(s\\), la statistica \\(\\,T\\) segue (in teoria) una distribuzione t di Student con \\(n - 1\\) gradi di libertà:\n\\[\nT \\sim t_{(n-1)}.\n\\]\n\n65.11.2 Collegamento con la distribuzione Z\nSe \\(\\sigma\\) fosse nota, useremmo la statistica:\n\\[\nZ = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}},\n\\]\nla quale segue una distribuzione Normale Standard (\\(Z \\sim \\mathcal{N}(0,1)\\)). Quando invece \\(\\sigma\\) è sostituita da \\(s\\), la distribuzione di questa statistica diventa una t di Student (che, per \\(n\\) grande, si avvicina molto alla \\(\\mathcal{N}(0,1)\\)).\n\n65.11.3 Intervallo di confidenza\nCon il test t di Student, si ottiene anche il tradizionale intervallo di confidenza al 95% per \\(\\mu\\):\n\\[\n\\bar{X} \\pm t_{0.975,\\,n-1} \\cdot \\frac{s}{\\sqrt{n}},\n\\]\ndove \\(t_{0.975,\\,n-1}\\) è il quantile al 97.5% della distribuzione t con \\(n-1\\) gradi di libertà (circa 2.0 se \\(n\\) è sufficientemente grande, mentre 1.96 è il valore per la distribuzione normale standard).\n\n65.11.3.1 Esempio in R\nNell’esempio riportato, se vogliamo costruire l’intervallo di confidenza al 95% manualmente, possiamo scrivere:\n\nmean(df$height) + \n  c(-1, 1) * qt(0.975, length(df$height) - 1) * (sd(df$height) / sqrt(length(df$height)))\n#&gt; [1] 153.8 155.4\n\noppure usare direttamente la funzione:\n\nt.test(df$height, mu = 0)\n#&gt; \n#&gt;  One Sample t-test\n#&gt; \n#&gt; data:  df$height\n#&gt; t = 375, df = 351, p-value &lt;2e-16\n#&gt; alternative hypothesis: true mean is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  153.8 155.4\n#&gt; sample estimates:\n#&gt; mean of x \n#&gt;     154.6\n\nche restituisce sia il valore della statistica T, sia l’intervallo di confidenza e il p-value del test t (ipotizzando, in questo esempio, \\(\\mu_0 = 0\\) come ipotesi nulla).\n\n65.11.4 Confronto con il modello di regressione a sola intercetta\nSi noti che i risultati (media stimata e intervallo di confidenza) coincidono con quanto si otterrebbe usando una regressione lineare con sola intercetta (come lm(height ~ 1, data=df)) e richiedendo l’intervallo di confidenza con confint(). Sia il test \\(t\\) di Student sia la regressione lineare semplice (senza covariate) condividono infatti le stesse assunzioni di base e forniscono risultati equivalenti per quanto riguarda l’inferenza sulla media.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#riflessioni-conlusive",
    "href": "chapters/linear_models/05_one_mean.html#riflessioni-conlusive",
    "title": "65  Inferenza bayesiana su una media",
    "section": "\n65.12 Riflessioni Conlusive",
    "text": "65.12 Riflessioni Conlusive\nIn questo capitolo abbiamo esaminato l’inferenza sulla media di una popolazione partendo da un semplice modello con sola intercetta, sia nell’ottica frequentista che in quella bayesiana. Utilizzando lm(), abbiamo ricavato la stima puntuale della media campionaria e il corrispondente intervallo di confidenza al 95%, interpretato come proprietà della procedura di stima. Con brm(), abbiamo ottenuto risultati numericamente simili, ma con una diversa interpretazione epistemologica: l’intervallo di credibilità rappresenta il grado di incertezza a posteriori sulla media, dato il modello e i dati osservati. Infine, abbiamo mostrato come introdurre informazioni a priori nel modello bayesiano, evidenziando come i risultati possano discostarsi da quelli frequentisti soprattutto in presenza di campioni piccoli o dati poco informativi. In sintesi, la modellazione bayesiana offre un quadro più flessibile e trasparente, sia nell’incorporare conoscenze pregresse sia nel rappresentare incertezza, rendendola particolarmente adatta a contesti psicologici dove le fonti di variabilità sono spesso molteplici e complesse.\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nObiettivo: Utilizzare i dati dello studio di Tarrats-Pons et al. (2025) per replicare i risultati riportati nella Figura 2 , applicando sia l’approccio frequentista che il framework bayesiano. Calcolare inoltre la grandezza dell’effetto nel contesto bayesiano (Cohen’s \\(d\\)) e generare un grafico che visualizzi la distribuzione a posteriori della grandezza dell’effetto ottenuta.\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(brms)\nlibrary(posterior)\nlibrary(bayestestR)\n\ndf &lt;- read_excel(\n  here::here(\n    \"data\",\n    \"Tarrats-Pons.xlsx\"\n  ),\n  sheet = 3\n)\n\ndf |&gt;\n  group_by(Sample) |&gt;\n  summarize(\n    avg = mean(`CESS-D`),\n    n = n()\n  )\n\ndf_wide &lt;- df %&gt;%\n  select(IdentificationNumber, Sample, CESS_D = `CESS-D`) %&gt;%\n  pivot_wider(\n    names_from = Sample, # da POST/PRE\n    values_from = CESS_D, # i valori da mettere nelle colonne\n    names_prefix = \"CESSD_\" # opzionale, per nominare CESSD_POST, CESSD_PRE\n  )\n\n# Controlla il risultato\nhead(df_wide)\n\ndf_wide$diff &lt;- df_wide$CESSD_PRE - df_wide$CESSD_POST\n\nhist(df_wide$diff)\n\nt.test(df_wide$diff)\n\n# t-test sulle differenze\nres &lt;- t.test(df_wide$diff)\n\n# Numero di soggetti\nn &lt;- length(df_wide$diff)\n\n# Calcolo di Cohen's d\nd_t &lt;- as.numeric(res$statistic) / sqrt(n)\n\n# Mostro risultato\nd_t\n\nfm1 &lt;- brm(\n  formula = diff ~ 1, # Modello con sola intercetta (mu)\n  data = df_wide,\n  family = gaussian(), # Distribuzione Normale\n  prior = c(\n    brms::prior(normal(0, 10), class = \"Intercept\"), # Prior su mu\n    brms::prior(normal(0, 10), class = \"sigma\") # Prior su sigma\n  ),\n  chains = 4,\n  iter = 2000,\n  seed = 1234,\n  backend = \"cmdstanr\"\n)\nsummary(fm1)\npp_check(fm1)\n\nfm2 &lt;- brm(\n  formula = diff ~ 1, # Modello con sola intercetta (mu)\n  data = df_wide,\n  family = student(), # Distribuzione Normale\n  prior = c(\n    brms::prior(normal(0, 10), class = \"Intercept\"), # Prior su mu\n    brms::prior(normal(0, 10), class = \"sigma\") # Prior su sigma\n  ),\n  chains = 4,\n  iter = 2000,\n  seed = 1234,\n  backend = \"cmdstanr\"\n)\nsummary(fm2)\npp_check(fm2)\n\npost_samples &lt;- posterior::as_draws_df(fm1)\nhead(post_samples)\n\npost_samples$effect_size &lt;- post_samples$b_Intercept / post_samples$sigma\n\n# Calcolo diretto delle statistiche dell'effect size\nmean_effect_size &lt;- mean(post_samples$effect_size)\nsd_effect_size &lt;- sd(post_samples$effect_size)\nci_effect_size &lt;- quantile(post_samples$effect_size, probs = c(0.025, 0.975))\n\n# Stampa dei risultati\ncat(\"=== Statistiche dell'Effect Size Bayesiano ===\\n\")\ncat(\"Effect size medio:\", round(mean_effect_size, 2), \"\\n\")\ncat(\"SD dell'effect size:\", round(sd_effect_size, 2), \"\\n\")\ncat(\n  \"Intervallo di credibilità al 95%:\",\n  round(ci_effect_size[1], 2),\n  \"-\",\n  round(ci_effect_size[2], 2),\n  \"\\n\\n\"\n)\n\n# Interpretazione dell'effect size secondo le convenzioni di Cohen\nif (abs(mean_effect_size) &lt; 0.2) {\n  interpretation &lt;- \"piccolo\"\n} else if (abs(mean_effect_size) &lt; 0.5) {\n  interpretation &lt;- \"medio-piccolo\"\n} else if (abs(mean_effect_size) &lt; 0.8) {\n  interpretation &lt;- \"medio\"\n} else {\n  interpretation &lt;- \"grande\"\n}\ncat(\"Interpretazione (Cohen):\", interpretation, \"\\n\")\n\n# Calcola la probabilità che l'effect size sia maggiore di zero\nprob_positive &lt;- mean(post_samples$effect_size &gt; 0)\ncat(\n  \"Probabilità che l'effect size sia positivo:\",\n  round(prob_positive * 100, 2),\n  \"%\\n\"\n)\n\n# Se necessario, calcola probabilità per altre soglie\nprob_medium &lt;- mean(post_samples$effect_size &gt; 0.5)\ncat(\n  \"Probabilità che l'effect size sia &gt; 0.5 (medio):\",\n  round(prob_medium * 100, 2),\n  \"%\\n\"\n)\nprob_large &lt;- mean(post_samples$effect_size &gt; 0.8)\ncat(\n  \"Probabilità che l'effect size sia &gt; 0.8 (grande):\",\n  round(prob_large * 100, 2),\n  \"%\\n\"\n)\n\n# Visualizzazione della distribuzione posteriore dell'effect size\n# (Per eseguire questo blocco, devi avere ggplot2 installato e caricato)\n# library(ggplot2)\nggplot(post_samples, aes(x = effect_size)) +\n  geom_density(fill = \"skyblue\", alpha = 0.5) +\n  geom_vline(\n    xintercept = mean_effect_size,\n    color = \"red\",\n    linetype = \"dashed\"\n  ) +\n  geom_vline(\n    xintercept = ci_effect_size[1],\n    color = \"darkblue\",\n    linetype = \"dotted\"\n  ) +\n  geom_vline(\n    xintercept = ci_effect_size[2],\n    color = \"darkblue\",\n    linetype = \"dotted\"\n  ) +\n  labs(\n    title = \"Distribuzione posteriore dell'Effect Size\",\n    x = \"Effect Size (Cohen's d)\",\n    y = \"Densità\"\n  ) +\n  theme_minimal()",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/05_one_mean.html#informazioni-sullambiente-di-sviluppo",
    "title": "65  Inferenza bayesiana su una media",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] readxl_1.4.5      ggdist_3.3.3      brms_2.22.0       Rcpp_1.0.14      \n#&gt;  [5] bayestestR_0.15.3 posterior_1.6.1   cmdstanr_0.9.0    thematic_0.1.6   \n#&gt;  [9] MetBrewer_0.2.0   ggokabeito_0.1.0  see_0.11.0        gridExtra_2.3    \n#&gt; [13] patchwork_1.3.0   bayesplot_1.12.0  psych_2.5.3       scales_1.4.0     \n#&gt; [17] markdown_2.0      knitr_1.50        lubridate_1.9.4   forcats_1.0.0    \n#&gt; [21] stringr_1.5.1     dplyr_1.1.4       purrr_1.0.4       readr_2.1.5      \n#&gt; [25] tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.2     tidyverse_2.0.0  \n#&gt; [29] rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] mnormt_2.1.1         inline_0.3.21        rlang_1.1.6         \n#&gt;  [4] magrittr_2.0.3       matrixStats_1.5.0    ggridges_0.5.6      \n#&gt;  [7] compiler_4.5.0       loo_2.8.0            vctrs_0.6.5         \n#&gt; [10] reshape2_1.4.4       pkgconfig_2.0.3      fastmap_1.2.0       \n#&gt; [13] backports_1.5.0      labeling_0.4.3       utf8_1.2.5          \n#&gt; [16] rmarkdown_2.29       tzdb_0.5.0           ps_1.9.1            \n#&gt; [19] xfun_0.52            jsonlite_2.0.0       parallel_4.5.0      \n#&gt; [22] R6_2.6.1             stringi_1.8.7        RColorBrewer_1.1-3  \n#&gt; [25] StanHeaders_2.32.10  cellranger_1.1.0     estimability_1.5.1  \n#&gt; [28] rstan_2.32.7         pacman_0.5.1         R.utils_2.13.0      \n#&gt; [31] Matrix_1.7-3         timechange_0.3.0     tidyselect_1.2.1    \n#&gt; [34] rstudioapi_0.17.1    abind_1.4-8          yaml_2.3.10         \n#&gt; [37] codetools_0.2-20     curl_6.2.2           processx_3.8.6      \n#&gt; [40] pkgbuild_1.4.7       lattice_0.22-7       plyr_1.8.9          \n#&gt; [43] withr_3.0.2          bridgesampling_1.1-2 coda_0.19-4.1       \n#&gt; [46] evaluate_1.0.3       RcppParallel_5.1.10  pillar_1.10.2       \n#&gt; [49] tensorA_0.36.2.1     checkmate_2.3.2      stats4_4.5.0        \n#&gt; [52] insight_1.2.0        distributional_0.5.0 generics_0.1.4      \n#&gt; [55] rprojroot_2.0.4      hms_1.1.3            rstantools_2.4.0    \n#&gt; [58] xtable_1.8-4         glue_1.8.0           emmeans_1.11.1      \n#&gt; [61] tools_4.5.0          data.table_1.17.2    mvtnorm_1.3-3       \n#&gt; [64] grid_4.5.0           QuickJSR_1.7.0       colorspace_2.1-1    \n#&gt; [67] nlme_3.1-168         cli_3.6.5            Brobdingnag_1.2-9   \n#&gt; [70] V8_6.0.3             gtable_0.3.6         R.methodsS3_1.8.2   \n#&gt; [73] digest_0.6.37        htmlwidgets_1.6.4    farver_2.1.2        \n#&gt; [76] htmltools_0.5.8.1    R.oo_1.27.1          lifecycle_1.0.4",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#bibliografia",
    "href": "chapters/linear_models/05_one_mean.html#bibliografia",
    "title": "65  Inferenza bayesiana su una media",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nTarrats-Pons, E., Mussons-Torras, M., & Jiménez-Pérez, Y. (2025). Efficacy of a Positive Psychology Intervention in Enhancing Optimism and Reducing Depression Among University Students: A Quasi-Experimental Study. Behavioral Sciences, 15(5), 571.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction_stan.html",
    "href": "chapters/linear_models/06_prediction_stan.html",
    "title": "66  Predizione e inferenza",
    "section": "",
    "text": "66.1 Introduzione\nGelman et al. (2021) osservano che l’inferenza bayesiana si sviluppa in tre passaggi fondamentali, che vanno oltre la stima classica. In primo luogo, i dati e il modello vengono combinati per formare una distribuzione a posteriori, che solitamente viene riassunta tramite le distribuzioni a posteriori dei parametri del modello. In secondo luogo, è possibile propagare l’incertezza presente in questa distribuzione, ottenendo previsioni basate su simulazioni per risultati non osservati o futuri, tenendo conto dell’incertezza nei parametri del modello. Infine, è possibile integrare ulteriori informazioni nel modello utilizzando una distribuzione a priori. Questo capitolo si concentra sui temi della previsione e dell’inferenza, con particolare attenzione all’incertezza della retta di regressione e alle distribuzioni predittive.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Predizione e inferenza</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction_stan.html#predizione",
    "href": "chapters/linear_models/06_prediction_stan.html#predizione",
    "title": "66  Predizione e inferenza",
    "section": "\n66.2 Predizione",
    "text": "66.2 Predizione\nPer discutere i temi della predizione e dell’inferenza bayesiana nel contesto del modello bayesiano di regressione lineare bivariata, esamineremo nuovamente il set di dati relativo alla relazione tra Tense Arousal (TA1) e ansia di stato (state1).\n\ndf &lt;- rio::import(here::here(\"data\", \"affect.csv\")) |&gt; \n  dplyr::select(state1, TA1)\ndf |&gt; \n  head()\n#&gt;   state1 TA1\n#&gt; 1     41  11\n#&gt; 2     26   5\n#&gt; 3     31   8\n#&gt; 4     28   8\n#&gt; 5     47  12\n#&gt; 6     43  10",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Predizione e inferenza</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction_stan.html#distribuzione-predittiva-a-priori",
    "href": "chapters/linear_models/06_prediction_stan.html#distribuzione-predittiva-a-priori",
    "title": "66  Predizione e inferenza",
    "section": "\n66.3 Distribuzione Predittiva a Priori",
    "text": "66.3 Distribuzione Predittiva a Priori\nConsideriamo il modello bayesiano di regressione lineare bivariata che include prior uniformi per i parametri \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\). Utilizzeremo il pacchetto brms per specificare e adattare il modello, concentrandoci in particolare sulla distribuzione predittiva a priori, ovvero sulle previsioni generate dal modello basandosi esclusivamente sulle distribuzioni a priori, senza considerare i dati osservati.\n\n66.3.1 Specificazione del modello con prior predittivi\nPer esaminare la distribuzione predittiva a priori, specifichiamo il modello impostando l’argomento sample_prior = \"only\". Questo ci permette di generare previsioni basate solo sui prior, ignorando i dati del campione.\n\n# Prior predictive check con sample_prior = \"only\"\nmodel_prior &lt;- brm(\n  formula = TA1 ~ state1, \n  data = df, \n  prior = c(\n    prior(uniform(-50, 50), class = \"Intercept\"),  # Prior per alpha\n    prior(uniform(-50, 50), class = \"b\"),          # Prior per beta\n    prior(uniform(0, 50), class = \"sigma\")         # Prior per sigma\n  ), \n  sample_prior = \"only\",  # Campiona solo dai prior\n  backend = \"cmdstanr\",\n  silent = 0\n)\n\n\n66.3.2 Visualizzazione della distribuzione predittiva a priori\nUtilizziamo la funzione pp_check per visualizzare la distribuzione predittiva a priori e confrontarla con i dati osservati. Questo passaggio è fondamentale per valutare se i prior scelti sono realistici e appropriati per il contesto del problema.\n\n# Visualizzazione del prior predictive check\npp_check(model_prior) + xlim(-100, 100)\n\n\n\n\n\n\n\n\n66.3.3 Interpretazione dei risultati\nDalla visualizzazione, notiamo che la distribuzione dei dati previsti dal modello, basata esclusivamente sui prior e sul modello generativo ipotizzato, è molto più ampia rispetto alla distribuzione dei dati effettivi. Questo suggerisce che i prior scelti sono troppo ampi e poco informativi. In altre parole, le previsioni generate dai prior coprono un intervallo di valori eccessivamente vasto, che non riflette adeguatamente la variabilità osservata nei dati reali.\n\n66.3.3.1 Implicazioni\n\n\nPrior troppo ampi: Quando i prior sono troppo ampi, il modello genera previsioni che possono essere irrealistiche o eccessivamente disperse. Questo può portare a una scarsa capacità del modello di adattarsi ai dati osservati una volta che questi vengono incorporati.\n\nPrior informativi: Per migliorare il modello, potrebbe essere necessario utilizzare prior più informativi, che riflettano meglio la conoscenza preesistente sul fenomeno in studio. Ad esempio, limitare l’intervallo dei prior per \\(\\alpha\\) e \\(\\beta\\) o scegliere distribuzioni a priori più realistiche per \\(\\sigma\\).\n\nIn sintesi, il prior predictive check è uno strumento essenziale per valutare l’adeguatezza delle distribuzioni a priori scelte. Attraverso questo controllo, possiamo identificare prior troppo ampi o inappropriati, che potrebbero compromettere la qualità delle inferenze bayesiane. Nel nostro caso, i risultati suggeriscono la necessità di rivedere i prior, adottando scelte più informative e coerenti con la realtà dei dati.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Predizione e inferenza</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction_stan.html#modello-di-regressione-lineare-bayesiana",
    "href": "chapters/linear_models/06_prediction_stan.html#modello-di-regressione-lineare-bayesiana",
    "title": "66  Predizione e inferenza",
    "section": "\n66.4 Modello di Regressione Lineare Bayesiana",
    "text": "66.4 Modello di Regressione Lineare Bayesiana\nIn questa sezione, specifichiamo e adattiamo un modello di regressione lineare bivariata utilizzando prior uniformi per i parametri \\(\\alpha\\) (intercetta), \\(\\beta\\) (coefficiente angolare) e \\(\\sigma\\) (deviazione standard). L’obiettivo è ottenere la distribuzione a posteriori dei parametri del modello e confrontare i risultati con quelli ottenuti tramite il metodo di massima verosimiglianza.\n\n66.4.1 Specificazione del Modello con Prior Uniformi\nUtilizziamo il pacchetto brms per specificare il modello di regressione lineare. I prior scelti sono uniformi e coprono un intervallo ampio per ciascun parametro, riflettendo un approccio inizialmente non informativo.\n\n# Specificazione del modello con prior uniformi\nmodel &lt;- brm(\n  formula = TA1 ~ state1,  # Formula del modello\n  data = df,               # Dati\n  prior = c(\n    prior(uniform(-50, 50), class = \"Intercept\"),  # Prior per alpha\n    prior(uniform(-50, 50), class = \"b\"),          # Prior per beta\n    prior(uniform(0, 50), class = \"sigma\")         # Prior per sigma\n  ),\n  seed = 123,              # Seme per la riproducibilità\n  chains = 4,              # Numero di catene MCMC\n  iter = 4000,             # Numero totale di iterazioni (2000 warmup, 2000 sampling)\n  warmup = 2000,           # Iterazioni di warmup\n  backend = \"cmdstanr\",    # Backend per l'ottimizzazione\n  silent = 0               # Mostra messaggi di avviso\n)\n\n\n66.4.2 Esame delle Distribuzioni a Posteriori\nPer esaminare le distribuzioni a posteriori dei parametri, utilizziamo la funzione summary. Questo ci permette di ottenere stime puntuali, intervalli di credibilità e altre statistiche rilevanti.\n\nsummary(model)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: TA1 ~ state1 \n#&gt;    Data: df (Number of observations: 78) \n#&gt;   Draws: 4 chains, each with iter = 4000; warmup = 2000; thin = 1;\n#&gt;          total post-warmup draws = 8000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept     1.57      1.28    -1.01     4.07 1.00     8973     5508\n#&gt; state1        0.27      0.03     0.21     0.33 1.00     8503     4886\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     2.72      0.23     2.31     3.20 1.00     8001     6020\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nUn aspetto cruciale è che la distribuzione a posteriori non fornisce solo informazioni sui singoli parametri, ma anche sulle loro interdipendenze. Queste relazioni sono riflesse nei campioni a posteriori, che possono essere ulteriormente analizzati e trasformati.\n\n66.4.3 Confronto con il Metodo di Massima Verosimiglianza\nPer confrontare i risultati bayesiani con quelli classici, stimiamo il modello di regressione lineare utilizzando il metodo di massima verosimiglianza.\n\nsummary(lm(TA1 ~ state1, data = df))\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = TA1 ~ state1, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;    Min     1Q Median     3Q    Max \n#&gt; -7.238 -1.754  0.159  1.973  6.302 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)\n#&gt; (Intercept)   1.5555     1.2485    1.25     0.22\n#&gt; state1        0.2671     0.0292    9.14  7.3e-14\n#&gt; \n#&gt; Residual standard error: 2.67 on 76 degrees of freedom\n#&gt; Multiple R-squared:  0.523,  Adjusted R-squared:  0.517 \n#&gt; F-statistic: 83.5 on 1 and 76 DF,  p-value: 7.35e-14\n\nNel caso di prior uniformi, la soluzione bayesiana coincide con quella di massima verosimiglianza. Questo risultato è atteso, poiché prior non informativi portano a distribuzioni a posteriori dominate dai dati osservati.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Predizione e inferenza</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction_stan.html#predizione-a-posteriori",
    "href": "chapters/linear_models/06_prediction_stan.html#predizione-a-posteriori",
    "title": "66  Predizione e inferenza",
    "section": "\n66.5 Predizione a Posteriori",
    "text": "66.5 Predizione a Posteriori\nUna volta ottenuta la distribuzione a posteriori dei parametri, possiamo utilizzarla per fare previsioni. In particolare, siamo interessati a due scenari: 1. Predizione per un valore specifico del predittore. 2. Quantificazione dell’incertezza nelle previsioni per tutti i valori osservati del predittore.\n\n66.5.1 Predizione a Posteriori per un Valore Specifico\nPer ottenere la distribuzione a posteriori della predizione per un valore specifico del predittore (ad esempio, state1 = 30), utilizziamo la funzione posterior_predict.\n\n# Predizione a posteriori per ansia di stato pari a 30\nnew_data &lt;- data.frame(state1 = 30)\npost_pred &lt;- posterior_predict(model, newdata = new_data)\n\n# Esame della distribuzione a posteriori della predizione\nsummary(post_pred)\n#&gt;        V1       \n#&gt;  Min.   :-2.43  \n#&gt;  1st Qu.: 7.67  \n#&gt;  Median : 9.55  \n#&gt;  Mean   : 9.56  \n#&gt;  3rd Qu.:11.45  \n#&gt;  Max.   :19.11\n\nQuesto ci fornisce una distribuzione di valori predetti per TA1 quando state1 = 30, riflettendo l’incertezza associata ai parametri del modello.\n\n66.5.2 Quantificazione dell’Incertezza nelle Predizioni\nPer quantificare l’incertezza complessiva nelle previsioni del modello, calcoliamo la distribuzione a posteriori delle predizioni per tutti i valori osservati di \\(x\\). Questo ci permette di ottenere stime puntuali e intervalli di credibilità.\n\n# Predizione a posteriori per tutti i valori di x\npost_pred_all &lt;- posterior_predict(model)\n\n\n66.5.3 Visualizzazione dell’Incertezza delle Predizioni\nVisualizziamo l’incertezza delle predizioni utilizzando un grafico che mostra la linea di regressione media e gli intervalli di credibilità al 95%.\n\n# Creazione del data frame per ggplot\nplot_data &lt;- data.frame(\n  state1 = df$state1,\n  TA1 = df$TA1,\n  pred_mean = colMeans(post_pred_all),  # Media delle predizioni\n  pred_lower = apply(post_pred_all, 2, quantile, 0.025),  # Limite inferiore\n  pred_upper = apply(post_pred_all, 2, quantile, 0.975)   # Limite superiore\n)\n\n# Costruzione del grafico\nggplot(plot_data, aes(x = state1, y = TA1)) +\n  geom_point(color = \"blue\", size = 1) +  # Punti osservati\n  geom_line(aes(y = pred_mean), color = \"red\", size = 1, alpha = 0.8) +  # Linea di regressione\n  geom_ribbon(\n    aes(ymin = pred_lower, ymax = pred_upper), fill = \"gray\", alpha = 0.3) +  \n  # Intervalli di credibilità\n  labs(\n    title = \"Incertezza delle Predizioni del Modello\",\n    x = \"State Anxiety\",\n    y = \"Tense Arousal\"\n  )",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Predizione e inferenza</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction_stan.html#interpretazione-dei-risultati-1",
    "href": "chapters/linear_models/06_prediction_stan.html#interpretazione-dei-risultati-1",
    "title": "66  Predizione e inferenza",
    "section": "\n66.6 Interpretazione dei Risultati",
    "text": "66.6 Interpretazione dei Risultati\n\n66.6.1 Significato della Predizione a Posteriori\nIl comando posterior_predict(model) genera una matrice in cui:\n\nOgni riga rappresenta un campione della distribuzione a posteriori.\nOgni colonna rappresenta una predizione per un valore specifico di \\(x\\).\n\nQuesta matrice ci permette di:\n\n\nVisualizzare l’incertezza: Gli intervalli di credibilità riflettono l’incertezza associata alle previsioni.\n\nValutare la bontà del modello: Confrontando le predizioni con i dati osservati, possiamo verificare se il modello è adeguato.\n\nFare previsioni robuste: Generiamo previsioni per nuovi dati, tenendo conto dell’incertezza nei parametri.\n\n66.6.2 Esempio di Interpretazione\nSupponiamo che per state1 = 30, la media delle predizioni a posteriori sia 50, con un intervallo di credibilità al 95% compreso tra 45 e 55. Questo significa che, dato il modello e i dati, c’è una probabilità del 95% che il valore vero di TA1 per state1 = 30 sia compreso tra 45 e 55. L’ampiezza dell’intervallo riflette l’incertezza associata alla predizione.\n\n66.6.3 Confronto con l’Approccio Classico\nNell’approccio classico (frequentista), le predizioni sono accompagnate da intervalli di confidenza, che riflettono solo l’incertezza nella stima dei parametri. Al contrario, l’approccio bayesiano include sia l’incertezza nei parametri sia la variabilità residua, fornendo una visione più completa dell’incertezza predittiva.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Predizione e inferenza</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction_stan.html#distribuzione-predittiva-a-posteriori",
    "href": "chapters/linear_models/06_prediction_stan.html#distribuzione-predittiva-a-posteriori",
    "title": "66  Predizione e inferenza",
    "section": "\n66.7 Distribuzione Predittiva a Posteriori",
    "text": "66.7 Distribuzione Predittiva a Posteriori\nIl Posterior Predictive Check (PPC) è uno strumento fondamentale nella modellazione bayesiana, utilizzato per valutare la bontà di adattamento del modello ai dati osservati. Questo controllo consiste nel confrontare i dati predetti dal modello (basati sulla distribuzione a posteriori dei parametri) con i dati effettivamente osservati. Se il modello è adeguato, le previsioni generate dovrebbero essere coerenti con i dati reali.\n\n66.7.1 Esecuzione del Posterior Predictive Check\nPer eseguire un PPC, utilizziamo la funzione pp_check del pacchetto brms. Questa funzione genera un insieme di previsioni basate sulla distribuzione a posteriori e le confronta visivamente con i dati osservati.\n\npp_check(model, ndraws = 100)\n\n\n\n\n\n\n\n\n66.7.2 Interpretazione dei Risultati\nDall’output del PPC, notiamo che i dati predetti dal modello sono simili ai dati osservati nel campione. Questa corrispondenza suggerisce che il modello ipotizzato è in grado di riprodurre adeguatamente le caratteristiche principali dei dati. In altre parole, il modello sembra essere appropriato per descrivere la relazione tra le variabili analizzate.\n\n66.7.2.1 Cosa Significa “Simili”?\n\n\nCoerenza nella forma: La distribuzione dei dati predetti ha una forma simile a quella dei dati osservati, indicando che il modello cattura correttamente la struttura sottostante dei dati.\n\nVariabilità: La variabilità delle previsioni è in linea con quella dei dati osservati, suggerendo che il modello tiene conto adeguatamente dell’incertezza intrinseca nei dati.\n\nAssenza di discrepanze evidenti: Non ci sono differenze sistematiche tra le previsioni e i dati osservati, il che supporta l’ipotesi che il modello sia ben specificato.\n\n66.7.3 Importanza del PPC\nIl PPC è un passaggio cruciale perché:\n\n\nValuta l’adattamento del modello: Fornisce una verifica visiva e quantitativa della capacità del modello di riprodurre i dati osservati.\n\nIdentifica potenziali problemi: Se le previsioni non corrispondono ai dati osservati, ciò può indicare che il modello è mal specificato o che mancano componenti importanti.\n\nSupporta la validità del modello: Un buon adattamento tra previsioni e dati osservati aumenta la fiducia nelle inferenze e nelle previsioni del modello.\n\nIn sintesi, nel nostro caso, la somiglianza tra i dati predetti e quelli osservati è un’indicazione positiva che il modello di regressione lineare bivariata, con i prior uniformi specificati, è adeguato per descrivere la relazione tra state1 e TA1. Tuttavia, è sempre consigliabile eseguire ulteriori controlli e verifiche, come l’analisi dei residui o l’uso di metriche quantitative (ad esempio, il Bayesian R-squared), per confermare ulteriormente la bontà del modello.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Predizione e inferenza</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction_stan.html#riflessioni-conclusive",
    "href": "chapters/linear_models/06_prediction_stan.html#riflessioni-conclusive",
    "title": "66  Predizione e inferenza",
    "section": "\n66.8 Riflessioni Conclusive",
    "text": "66.8 Riflessioni Conclusive\nIn questo capitolo, abbiamo approfondito i temi della predizione bayesiana nel contesto del modello di regressione bivariato, evidenziando l’importanza delle verifiche predittive a priori e a posteriori per la valutazione e la validazione del modello.\nAbbiamo visto come il Prior Predictive Check sia essenziale per verificare che le distribuzioni a priori siano appropriate per il modello e i dati del campione. Questo passaggio consente di esaminare se le ipotesi iniziali sono coerenti con la conoscenza preesistente e con i risultati attesi. Un’adeguata verifica predittiva a priori aiuta a prevenire l’adozione di distribuzioni a priori che possano portare a previsioni irrealistiche o fuorvianti.\nSuccessivamente, abbiamo esaminato il Posterior Predictive Check come strumento per valutare la capacità del modello di adattarsi ai dati osservati. Dopo aver integrato le informazioni dei dati con le distribuzioni a priori, il posterior predictive check permette di confrontare le predizioni del modello con i dati effettivamente osservati. Se il modello è adeguato, le sue predizioni dovrebbero essere in linea con i dati reali.\nInoltre, abbiamo discusso l’incertezza della retta di regressione, mostrando come le distribuzioni a posteriori dei parametri possano essere utilizzate per quantificare l’incertezza nelle previsioni. Attraverso la visualizzazione degli intervalli di credibilità, abbiamo evidenziato come l’approccio bayesiano fornisca una misura più completa dell’incertezza rispetto ai metodi classici.\nIn conclusione, l’approccio bayesiano alla predizione e alla verifica dei modelli offre un framework robusto e flessibile per l’analisi statistica. I prior e posterior predictive checks non sono semplici passaggi tecnici, ma costituiscono una parte integrante del processo di modellizzazione, assicurando che il modello non solo sia ben adattato ai dati, ma anche che le sue assunzioni siano giustificate e realistiche. L’utilizzo di questi strumenti permette di costruire modelli che siano coerenti con la realtà che intendono rappresentare.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Predizione e inferenza</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction_stan.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/06_prediction_stan.html#informazioni-sullambiente-di-sviluppo",
    "title": "66  Predizione e inferenza",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] posterior_1.6.1  brms_2.22.0      Rcpp_1.0.14      thematic_0.1.6  \n#&gt;  [5] MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0       gridExtra_2.3   \n#&gt;  [9] patchwork_1.3.0  bayesplot_1.12.0 psych_2.5.3      scales_1.4.0    \n#&gt; [13] markdown_2.0     knitr_1.50       lubridate_1.9.4  forcats_1.0.0   \n#&gt; [17] stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4      readr_2.1.5     \n#&gt; [21] tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.2    tidyverse_2.0.0 \n#&gt; [25] rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1     farver_2.1.2         loo_2.8.0           \n#&gt;  [4] R.utils_2.13.0       fastmap_1.2.0        tensorA_0.36.2.1    \n#&gt;  [7] pacman_0.5.1         digest_0.6.37        timechange_0.3.0    \n#&gt; [10] estimability_1.5.1   lifecycle_1.0.4      StanHeaders_2.32.10 \n#&gt; [13] processx_3.8.6       magrittr_2.0.3       compiler_4.5.0      \n#&gt; [16] rlang_1.1.6          tools_4.5.0          yaml_2.3.10         \n#&gt; [19] data.table_1.17.2    labeling_0.4.3       bridgesampling_1.1-2\n#&gt; [22] htmlwidgets_1.6.4    curl_6.2.2           pkgbuild_1.4.7      \n#&gt; [25] mnormt_2.1.1         plyr_1.8.9           RColorBrewer_1.1-3  \n#&gt; [28] cmdstanr_0.9.0       abind_1.4-8          withr_3.0.2         \n#&gt; [31] R.oo_1.27.1          stats4_4.5.0         grid_4.5.0          \n#&gt; [34] colorspace_2.1-1     inline_0.3.21        xtable_1.8-4        \n#&gt; [37] emmeans_1.11.1       cli_3.6.5            mvtnorm_1.3-3       \n#&gt; [40] rmarkdown_2.29       generics_0.1.4       RcppParallel_5.1.10 \n#&gt; [43] rstudioapi_0.17.1    reshape2_1.4.4       tzdb_0.5.0          \n#&gt; [46] rstan_2.32.7         parallel_4.5.0       matrixStats_1.5.0   \n#&gt; [49] vctrs_0.6.5          V8_6.0.3             Matrix_1.7-3        \n#&gt; [52] jsonlite_2.0.0       hms_1.1.3            glue_1.8.0          \n#&gt; [55] codetools_0.2-20     ps_1.9.1             distributional_0.5.0\n#&gt; [58] stringi_1.8.7        gtable_0.3.6         QuickJSR_1.7.0      \n#&gt; [61] pillar_1.10.2        htmltools_0.5.8.1    Brobdingnag_1.2-9   \n#&gt; [64] R6_2.6.1             rprojroot_2.0.4      evaluate_1.0.3      \n#&gt; [67] lattice_0.22-7       R.methodsS3_1.8.2    backports_1.5.0     \n#&gt; [70] rstantools_2.4.0     coda_0.19-4.1        nlme_3.1-168        \n#&gt; [73] checkmate_2.3.2      xfun_0.52            pkgconfig_2.0.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Predizione e inferenza</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction_stan.html#bibliografia",
    "href": "chapters/linear_models/06_prediction_stan.html#bibliografia",
    "title": "66  Predizione e inferenza",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Predizione e inferenza</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html",
    "href": "chapters/linear_models/07_two_means.html",
    "title": "67  Confronto tra le medie di due gruppi",
    "section": "",
    "text": "67.1 Introduzione\nNella ricerca psicologica è comune voler confrontare due gruppi per verificare se, ad esempio, uno dei due presenta una media più elevata su una certa variabile. Tuttavia, le differenze osservate nei dati non riflettono sempre differenze reali: possono derivare anche da fluttuazioni casuali, errori di misurazione o variabilità intrinseca nei processi psicologici. Per valutare in modo rigoroso se una differenza osservata è compatibile con una reale differenza tra gruppi, è necessario ricorrere a un modello statistico.\nIl metodo tradizionale prevede l’uso di un test di ipotesi, in cui si formula un’ipotesi nulla (ad esempio: “non c’è differenza tra i gruppi”) e si calcola una statistica test per verificare quanto i dati siano compatibili con essa. Se la statistica supera una soglia prestabilita (tipicamente associata a un livello di significatività), si rifiuta l’ipotesi nulla.\nQuesto approccio, però, ha alcune limitazioni. Come sottolineano Johnson (1999) e Goodman (1999), la procedura è spesso influenzata da convenzioni arbitrarie (come il livello di significatività o la scelta del test) e produce un risultato binario (rifiuto o meno dell’ipotesi nulla), che può essere di difficile interpretazione e soggetto a fraintendimenti.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#introduzione",
    "href": "chapters/linear_models/07_two_means.html#introduzione",
    "title": "67  Confronto tra le medie di due gruppi",
    "section": "",
    "text": "67.1.1 Un’alternativa più informativa: la stima bayesiana\nUn approccio più trasparente e informativo consiste nel passare dal test alla stima: invece di domandarci “Esiste una differenza?”, ci chiediamo “Quanto è grande la differenza tra i gruppi?” e “Quanto siamo incerti su questa stima?”.\nIn questo contesto, l’approccio bayesiano offre un quadro concettualmente più chiaro, perché consente di quantificare esplicitamente l’incertezza. In particolare, distingue due tipi fondamentali di incertezza:\n\n\nIncertezza aleatoria (aleatory uncertainty): è l’incertezza dovuta alla variabilità intrinseca nei dati, cioè al fatto che gli individui all’interno di ciascun gruppo sono naturalmente diversi tra loro. È una proprietà del fenomeno osservato.\n\nIncertezza epistemica (epistemic uncertainty): riflette la nostra ignoranza o mancanza di conoscenza sul vero valore della differenza tra i gruppi. È una proprietà del nostro stato di informazione e può essere ridotta raccogliendo più dati o integrando conoscenze pregresse.\n\nNel paradigma bayesiano, l’incertezza epistemica è modellata in modo diretto tramite la distribuzione a posteriori, che combina i dati osservati con eventuali conoscenze pregresse espresse sotto forma di prior. Questo permette di ottenere una stima probabilistica della differenza tra gruppi, assieme a un intervallo di credibilità, che indica dove si concentra la maggior parte della nostra incertezza residua.\nIn questo capitolo, esploreremo come applicare questo approccio per il confronto tra due gruppi, utilizzando strumenti bayesiani che consentono di rappresentare chiaramente ciò che sappiamo — e ciò che non sappiamo — sulla differenza che ci interessa stimare.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#regressione-bayesiana-per-il-confronto-tra-due-gruppi",
    "href": "chapters/linear_models/07_two_means.html#regressione-bayesiana-per-il-confronto-tra-due-gruppi",
    "title": "67  Confronto tra le medie di due gruppi",
    "section": "\n67.2 Regressione bayesiana per il confronto tra due gruppi",
    "text": "67.2 Regressione bayesiana per il confronto tra due gruppi\nDopo aver introdotto l’approccio bayesiano come un’alternativa più informativa rispetto ai test di ipotesi, vediamo ora come modellare la differenza tra due gruppi utilizzando un semplice modello di regressione. Anche se il termine “regressione” può sembrare tecnico, in questo contesto si tratta di un modo molto naturale per rappresentare il confronto tra due medie.\nSupponiamo di avere una variabile quantitativa \\(y\\) (ad esempio, un punteggio cognitivo o un indice di stress), e di voler confrontare i valori medi di \\(y\\) in due gruppi distinti. Per rappresentare l’appartenenza di ciascun individuo a uno dei due gruppi, introduciamo una variabile indicatrice (dummy) \\(D_i\\), definita nel seguente modo:\n\n\n\\(D_i = 0\\) per gli individui del gruppo di riferimento (ad esempio, il gruppo di controllo),\n\n\\(D_i = 1\\) per gli individui del gruppo di confronto (ad esempio, il gruppo sperimentale).\n\nIl modello assume la forma:\n\\[\ny_i = \\alpha + \\gamma D_i + \\varepsilon_i,\n\\]\ndove:\n\n\n\\(y_i\\) è il valore osservato per l’individuo \\(i\\),\n\n\\(\\alpha\\) è la media del gruppo di riferimento (\\(D_i = 0\\)),\n\n\\(\\gamma\\) rappresenta la differenza tra le medie dei due gruppi,\n\n\\(\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma^2)\\) è un termine di errore casuale, che rappresenta la variabilità individuale non spiegata dal gruppo.\n\nIn questo modello:\n\nSe \\(D_i = 0\\), allora \\(\\mu_i = \\alpha\\), cioè la media del gruppo di riferimento.\nSe \\(D_i = 1\\), allora \\(\\mu_i = \\alpha + \\gamma\\), cioè la media del gruppo di confronto.\n\nIl parametro \\(\\gamma\\) è quindi l’elemento centrale dell’inferenza: misura la differenza tra le due medie, e l’obiettivo dell’analisi è stimarne il valore e la relativa incertezza.\n\n67.2.1 Formulazione bayesiana del modello\nNel quadro bayesiano, il confronto tra due gruppi può essere formalizzato nel seguente modo:\n\\[\n\\begin{aligned}\ny_i &\\sim \\mathcal{N}(\\mu_i, \\sigma), \\\\\n\\mu_i &= \\alpha + \\gamma D_i,\n\\end{aligned}\n\\]\ndove ogni osservazione \\(y_i\\) è modellata come proveniente da una distribuzione normale con media \\(\\mu_i\\) e deviazione standard \\(\\sigma\\). Il valore della media \\(\\mu_i\\) dipende dal gruppo a cui appartiene l’individuo, indicato dalla variabile dummy \\(D_i\\).\nCome visto in precedenza:\n\nper il gruppo di riferimento (\\(D_i = 0\\)), la media è \\(\\mu_i = \\alpha\\);\nper il gruppo di confronto (\\(D_i = 1\\)), la media è \\(\\mu_i = \\alpha + \\gamma\\).\n\nIl parametro \\(\\gamma\\) esprime quindi la differenza tra le due medie e rappresenta il principale oggetto di interesse dell’analisi.\nLa differenza rispetto all’approccio frequentista non riguarda la forma del modello, che è la stessa, ma l’interpretazione dell’inferenza. In ambito frequentista si ottiene una stima puntuale e un intervallo di confidenza, ma non si può attribuire una probabilità alla veridicità di una certa ipotesi sul parametro. Nel paradigma bayesiano, invece, otteniamo una distribuzione a posteriori per ciascun parametro, che riflette il nostro grado di incertezza dopo aver osservato i dati, integrando anche eventuali informazioni a priori.\nNel caso di \\(\\gamma\\), questa distribuzione ci permette di:\n\nindividuare i valori più plausibili per la differenza tra i gruppi;\nstimare direttamente la probabilità che \\(\\gamma\\) sia maggiore o minore di zero, ossia che esista una vera differenza (in un verso o nell’altro);\ncalcolare un intervallo di credibilità (ad esempio al 95%), che ci indica dove si concentra la maggior parte della probabilità a posteriori.\n\nIn conclusione, la regressione bayesiana con variabile dummy fornisce una struttura semplice ma potente per confrontare due gruppi, arricchita dalla possibilità di rappresentare in modo diretto e trasparente l’incertezza sulla stima della differenza. Questo rende il modello particolarmente utile in ambito psicologico, dove è spesso cruciale ragionare in termini di gradualità dell’evidenza e non di risposte sì/no. Ecco una versione rivista e migliorata della sezione sull’approccio frequentista, con maggiore chiarezza espositiva, uno stile più didattico e una transizione più naturale verso il confronto con l’approccio bayesiano. Tutte le informazioni originali sono mantenute, ma riorganizzate per migliorarne la leggibilità e la comprensione:",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#approccio-frequentista",
    "href": "chapters/linear_models/07_two_means.html#approccio-frequentista",
    "title": "67  Confronto tra le medie di due gruppi",
    "section": "\n67.3 Approccio frequentista",
    "text": "67.3 Approccio frequentista\nNel paradigma frequentista, l’inferenza sulla differenza tra due gruppi si basa sulla distribuzione campionaria della differenza tra le medie. L’idea di fondo è che, se ripetessimo il campionamento molte volte, otterremmo valori diversi per la differenza tra le medie campionarie, e questa variabilità può essere descritta attraverso una distribuzione probabilistica.\nSupponiamo di avere due popolazioni normali e indipendenti:\n\\[\nY_1 \\sim \\mathcal{N}(\\mu_1, \\sigma_1^2) \\quad \\text{e} \\quad Y_2 \\sim \\mathcal{N}(\\mu_2, \\sigma_2^2)\n\\]\ne di osservare due campioni indipendenti, rispettivamente di dimensione \\(n_1\\) e \\(n_2\\).\nSe assumiamo inoltre che le varianze siano uguali (\\(\\sigma_1^2 = \\sigma_2^2 = \\sigma^2\\)), possiamo utilizzare una versione semplificata del modello.\n\n67.3.1 Statistica di interesse\nIl nostro obiettivo è stimare la differenza tra le medie delle due popolazioni, ovvero:\n\\[\n\\mu_1 - \\mu_2.\n\\]\nLa stima di questa quantità è data dalla differenza tra le medie campionarie:\n\\[\n\\bar{Y}_1 - \\bar{Y}_2.\n\\]\n\n67.3.2 Proprietà della statistica campionaria\n\n67.3.2.1 Valore atteso\nNel caso di due campioni indipendenti:\n\\[\nE(\\bar{Y}_1 - \\bar{Y}_2) = \\mu_1 - \\mu_2.\n\\]\n\n\n\n\n\n\nDimostrazione\n\n\n\n\n\nSi parte dalla definizione di media campionaria per ciascun gruppo e si applica la linearità dell’operatore valore atteso:\n\\[\nE(\\bar{Y}_1 - \\bar{Y}_2) = E(\\bar{Y}_1) - E(\\bar{Y}_2) = \\mu_1 - \\mu_2.\n\\]\n\n\n\n\n67.3.2.2 Varianza\nLa varianza della differenza tra le medie campionarie è:\n\\[\n\\operatorname{Var}(\\bar{Y}_1 - \\bar{Y}_2) = \\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}.\n\\]\n\n\n\n\n\n\nDimostrazione\n\n\n\n\n\nPoiché i due campioni sono indipendenti, la varianza della differenza si ottiene sommando le varianze delle due medie:\n\\[\n\\operatorname{Var}(\\bar{Y}_1) = \\frac{\\sigma_1^2}{n_1}, \\quad \\operatorname{Var}(\\bar{Y}_2) = \\frac{\\sigma_2^2}{n_2}\n\\]\nquindi:\n\\[\n\\operatorname{Var}(\\bar{Y}_1 - \\bar{Y}_2) = \\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}.\n\\]\n\n\n\nSe assumiamo varianze uguali (\\(\\sigma_1 = \\sigma_2 = \\sigma\\)), possiamo scrivere:\n\\[\n\\operatorname{Var}(\\bar{Y}_1 - \\bar{Y}_2) = \\sigma^2 \\left( \\frac{1}{n_1} + \\frac{1}{n_2} \\right).\n\\]\nPoiché \\(\\sigma^2\\) è sconosciuta, la si stima tramite la varianza pooled:\n\\[\ns_p^2 = \\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2},\n\\]\ndove \\(s_1^2\\) e \\(s_2^2\\) sono le varianze campionarie:\n\\[\ns_j^2 = \\frac{1}{n_j - 1} \\sum_{i=1}^{n_j} (y_{j,i} - \\bar{y}_j)^2, \\quad j = 1,2.\n\\]\n\n67.3.3 Distribuzione della statistica\nSotto l’ipotesi di normalità e indipendenza, e assumendo varianze uguali, la statistica \\(\\bar{Y}_1 - \\bar{Y}_2\\) segue (almeno approssimativamente) una distribuzione normale:\n\\[\n\\bar{Y}_1 - \\bar{Y}_2 \\sim \\mathcal{N} \\left( \\mu_1 - \\mu_2,\\ \\sigma \\sqrt{ \\frac{1}{n_1} + \\frac{1}{n_2} } \\right).\n\\]\nQuesta proprietà permette di costruire un intervallo di confidenza al 95% per la differenza tra le medie, oppure di effettuare un test t per due campioni indipendenti, basato sulla seguente statistica:\n\\[\nt = \\frac{(\\bar{Y}_1 - \\bar{Y}_2) - (\\mu_1 - \\mu_2)}{s_p \\sqrt{ \\frac{1}{n_1} + \\frac{1}{n_2} }}.\n\\]\nQuesta statistica segue, sotto l’ipotesi nulla \\(\\mu_1 = \\mu_2\\), una distribuzione t di Student con \\(n_1 + n_2 - 2\\) gradi di libertà.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#differenze-interpretative-tra-approccio-frequentista-e-bayesiano",
    "href": "chapters/linear_models/07_two_means.html#differenze-interpretative-tra-approccio-frequentista-e-bayesiano",
    "title": "67  Confronto tra le medie di due gruppi",
    "section": "\n67.4 Differenze interpretative tra approccio frequentista e bayesiano",
    "text": "67.4 Differenze interpretative tra approccio frequentista e bayesiano\nIl confronto tra i due approcci non riguarda soltanto le formule utilizzate, ma soprattutto il modo in cui si interpreta il risultato dell’analisi:\n\nApproccio frequentista: l’intervallo di confidenza al 95% indica che, se ripetessimo l’esperimento moltissime volte, il 95% degli intervalli costruiti in questo modo conterrebbero la vera differenza tra \\(\\mu_1\\) e \\(\\mu_2\\). Tuttavia, non possiamo dire che c’è il 95% di probabilità che un dato intervallo contenga la vera differenza — perché nel frequentismo i parametri sono fissi, e solo i dati sono considerati aleatori.\nApproccio bayesiano: l’intervallo di credibilità al 95% indica che, dato il nostro stato di conoscenza attuale, c’è il 95% di probabilità che la differenza tra i gruppi si trovi in quell’intervallo. Qui la probabilità è attribuita al valore stesso del parametro, che è trattato come una variabile aleatoria soggetta a incertezza epistemica.\n\nQuesta distinzione può sembrare sottile, ma ha importanti conseguenze pratiche. Mentre l’approccio frequentista impone un’interpretazione indiretta dell’intervallo (basata su procedure ripetute), quello bayesiano consente di formulare affermazioni probabilistiche dirette sui parametri, e quindi sul fenomeno psicologico in studio.\n\n67.4.1 Sintesi\n\n\n\n\n\n\n\nAspetto\nApproccio frequentista\nApproccio bayesiano\n\n\n\nStima della differenza\n\\(\\bar{Y}_1 - \\bar{Y}_2\\)\nDistribuzione a posteriori di \\(\\gamma\\)\n\n\n\nIncertezza\nIntervallo di confidenza\nIntervallo di credibilità\n\n\nInterpretazione dell’intervallo\nValido in media su ripetizioni dell’esperimento\nValido condizionatamente ai dati osservati\n\n\nRuolo del parametro\nFisso ma ignoto\nVariabile aleatoria\n\n\nUso di informazioni pregresse\nNon previsto\nEsplicito tramite prior\n\n\n\nNelle sezioni successive vedremo come implementare entrambi gli approcci in R, e come confrontare i risultati ottenuti.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#un-esempio-illustrativo",
    "href": "chapters/linear_models/07_two_means.html#un-esempio-illustrativo",
    "title": "67  Confronto tra le medie di due gruppi",
    "section": "\n67.5 Un esempio illustrativo",
    "text": "67.5 Un esempio illustrativo\nDopo aver introdotto i due approcci — frequentista e bayesiano — e discusso come ciascuno tratti il problema del confronto tra due gruppi, passiamo ora a un esempio concreto che li metta a confronto sullo stesso set di dati.\nAnalizzeremo un campione di dati relativi al quoziente intellettivo (QI) di bambini, suddivisi in due gruppi in base al livello di istruzione delle madri:\n\n\nmadri diplomate (hanno completato la scuola superiore),\n\nmadri non diplomate (non hanno completato la scuola superiore).\n\nLa domanda centrale è: nella popolazione, il QI medio dei bambini varia a seconda che la madre abbia o meno un diploma?\nQuesto esempio ci guiderà attraverso l’implementazione pratica e il confronto tra i due approcci inferenziali.\n\n67.5.1 Esplorazione iniziale dei dati\nCarichiamo i dati e visualizziamo le prime righe per comprenderne la struttura:\n\nkidiq &lt;- rio::import(here::here(\"data\", \"kidiq.dta\"))\nkidiq |&gt; \n  head()\n#&gt;   kid_score mom_hs mom_iq mom_work mom_age\n#&gt; 1        65      1 121.12        4      27\n#&gt; 2        98      1  89.36        4      25\n#&gt; 3        85      1 115.44        4      27\n#&gt; 4        83      1  99.45        3      25\n#&gt; 5       115      1  92.75        4      27\n#&gt; 6        98      0 107.90        1      18\n\nEsploriamo poi le statistiche descrittive nei due gruppi:\n\nkidiq |&gt; \n  group_by(mom_hs) |&gt; \n  summarize(\n    avg = mean(kid_score),\n    std = sd(kid_score),\n    n = n()\n)\n#&gt; # A tibble: 2 × 4\n#&gt;   mom_hs   avg   std     n\n#&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1      0  77.5  22.6    93\n#&gt; 2      1  89.3  19.0   341\n\nI risultati mostrano:\n\n\n93 bambini con madri non diplomate,\n\n341 bambini con madri diplomate,\n\ncon QI medi e deviazioni standard diverse tra i due gruppi.\nLa differenza osservata tra le medie può essere calcolata direttamente:\n\nmean(kidiq[kidiq$mom_hs == 1, ]$kid_score) - mean(kidiq[kidiq$mom_hs == 0, ]$kid_score)\n#&gt; [1] 11.77\n\nQuesta analisi preliminare suggerisce una differenza tra i gruppi. Ma è sufficiente a concludere che esiste una vera differenza nella popolazione? Per rispondere, confrontiamo i due approcci.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#confronto-tra-approccio-frequentista-e-bayesiano",
    "href": "chapters/linear_models/07_two_means.html#confronto-tra-approccio-frequentista-e-bayesiano",
    "title": "67  Confronto tra le medie di due gruppi",
    "section": "\n67.6 Confronto tra approccio frequentista e bayesiano",
    "text": "67.6 Confronto tra approccio frequentista e bayesiano\n\n67.6.1 Approccio frequentista\nL’approccio frequentista si fonda sulla distribuzione campionaria della differenza tra le medie osservate:\n\\[\n\\bar{Y}_1 - \\bar{Y}_2 \\sim \\mathcal{N}\\left( \\mu_1 - \\mu_2,\\ \\sqrt{ \\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2} } \\right).\n\\]\nSe assumiamo varianze uguali, stimiamo la varianza comune con la varianza pooled:\n\\[\ns_p^2 = \\frac{ (n_1 - 1)s_1^2 + (n_2 - 1)s_2^2 }{n_1 + n_2 - 2}.\n\\]\n\n67.6.1.1 Applicazione ai dati\nUsiamo i seguenti valori osservati:\n\n\nmadri diplomate: \\(n_1 = 341\\), \\(\\bar{Y}_1 = 89.3\\), \\(s_1 = 19.0\\),\n\nmadri non diplomate: \\(n_2 = 93\\), \\(\\bar{Y}_2 = 77.5\\), \\(s_2 = 22.6\\).\n\nCalcoliamo la probabilità, sotto l’ipotesi nulla (\\(\\mu_1 = \\mu_2\\)), di osservare una differenza di almeno 5 punti:\n\nmean_1 &lt;- 89.3\nstd_1 &lt;- 19.0\nn_1 &lt;- 341\n\nmean_2 &lt;- 77.5\nstd_2 &lt;- 22.6\nn_2 &lt;- 93\n\npooled_var &lt;- (((n_1 - 1) * std_1^2) + ((n_2 - 1) * std_2^2)) / (n_1 + n_2 - 2)\nstd_diff &lt;- sqrt(pooled_var / n_1 + pooled_var / n_2)\n\npnorm(5, mean = 0, sd = std_diff, lower.tail = FALSE)\n#&gt; [1] 0.01553\n\nIl risultato rappresenta il p-value: la probabilità di osservare una differenza così grande (o più) se la vera differenza fosse zero.\n\n67.6.2 Approccio bayesiano\nNel paradigma bayesiano, non partiamo da un’ipotesi nulla. Invece, costruiamo un modello probabilistico che stima direttamente la distribuzione a posteriori della differenza tra i gruppi.\nFormuliamo un semplice modello di regressione con variabile dummy:\n\\[\n\\begin{aligned}\ny_i &\\sim \\mathcal{N}(\\mu_i, \\sigma), \\\\\n\\mu_i &= \\alpha + \\gamma D_i,\n\\end{aligned}\n\\]\ndove:\n\n\n\\(\\alpha\\) è la media per le madri non diplomate,\n\n\\(\\gamma\\) è la differenza tra i gruppi (cioè, l’effetto dell’istruzione della madre),\n\n\\(\\sigma\\) è la deviazione standard residua.\n\n\n67.6.2.1 Stima del modello\n\nfit_1 &lt;- brm(\n  kid_score ~ mom_hs, \n  data = kidiq, \n  backend = \"cmdstanr\",\n  silent = 0\n)\n\n\n67.6.2.2 Probabilità che la differenza superi 5 punti\n\nposterior_samples &lt;- as_draws_df(fit_1)\nmean(posterior_samples$b_mom_hs &gt; 5)\n#&gt; [1] 0.9975\n\nQuesto calcolo fornisce una stima diretta della probabilità che la differenza tra i gruppi (\\(\\gamma\\)) superi 5 punti.\n\n67.6.3 Visualizzazione delle distribuzioni\n\nggplot(kidiq, aes(x = as.factor(mom_hs), y = kid_score)) +\n  geom_violin(trim = FALSE, fill = \"skyblue\") +\n  geom_boxplot(width = 0.1, outlier.shape = NA, fill = \"white\", color = \"black\") +\n  labs(\n    x = \"Livello di istruzione della madre\",\n    y = \"QI del bambino\",\n    title = \"Distribuzione dei punteggi QI\\nin base all'istruzione materna\"\n  ) +\n  scale_x_discrete(labels = c(\"0\" = \"Non diplomata\", \"1\" = \"Diplomata\"))\n\n\n\n\n\n\n\nIl grafico mostra chiaramente una differenza tra i gruppi, con una maggiore concentrazione di punteggi elevati tra i figli di madri diplomate.\n\n67.6.4 Differenze concettuali tra gli approcci\n\n\n\n\n\n\n\nAspetto\nFrequentista\nBayesiano\n\n\n\nIpotesi iniziale\n\n\\(\\mu_1 = \\mu_2\\) (ipotesi nulla)\nNessuna ipotesi nulla\n\n\nObiettivo\nValutare quanto è improbabile la differenza osservata sotto \\(H_0\\)\n\nStimare la probabilità della differenza tra gruppi\n\n\nInterpretazione\nIl p-value è condizionato da \\(H_0\\)\n\nLa probabilità di \\(\\gamma &gt; 5\\) è condizionata dai dati\n\n\nIncertezza\nIntervallo di confidenza\nIntervallo di credibilità\n\n\nConoscenza pregressa\nNon utilizzata\nIntegrabile tramite prior\n\n\n\n67.6.5 Quale approccio scegliere?\nL’approccio frequentista è utile quando si vuole valutare la compatibilità dei dati con l’ipotesi di nessuna differenza, ma questa ipotesi è spesso irrealistica: due gruppi difficilmente saranno identici in ogni contesto reale.\nL’approccio bayesiano offre vantaggi notevoli:\n\n\nnon assume che la differenza sia nulla,\nfornisce stime probabilistiche dirette e interpretabili,\npermette di incorporare conoscenze pregresse (o usare prior debolmente informativi),\nquantifica in modo chiaro l’incertezza nella stima della differenza.\n\n67.6.6 Approfondimenti bayesiani\n\n67.6.6.1 Intervallo di credibilità all’89%\n\nbayestestR::hdi(fit_1, parameters = \"mom_hs\", ci = 0.89)\n#&gt; Highest Density Interval\n#&gt; \n#&gt; Parameter |       89% HDI\n#&gt; -------------------------\n#&gt; mom_hs    | [8.36, 15.66]\n\n\n67.6.6.2 Verifica predittiva\n\npp_check(fit_1)\n\n\n\n\n\n\n\nIl modello predice abbastanza bene la distribuzione osservata, ma si notano lievi discrepanze nelle code.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#una-parametrizzazione-alternativa-modello-skew-normal",
    "href": "chapters/linear_models/07_two_means.html#una-parametrizzazione-alternativa-modello-skew-normal",
    "title": "67  Confronto tra le medie di due gruppi",
    "section": "\n67.7 Una parametrizzazione alternativa: modello skew-normal",
    "text": "67.7 Una parametrizzazione alternativa: modello skew-normal\nPer migliorare l’adattamento, usiamo una distribuzione skew-normal che consente di modellare l’asimmetria:\n\nfit_2 &lt;- brm(\n  kid_score ~ mom_hs, \n  family = skew_normal(),\n  backend = \"cmdstanr\", \n  silent = 0,\n  data = kidiq\n)\n\n\n67.7.1 Controllo predittivo\n\npp_check(fit_2)\n\n\n\n\n\n\n\nIl modello skew-normal mostra un migliore adattamento alle code della distribuzione osservata.\n\n67.7.2 Stime posteriori\n\ndraws &lt;- posterior::as_draws(fit_2, variable = \"^b_\", regex = TRUE)\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 2 × 5\n#&gt;   variable     mean    sd mcse_mean mcse_sd\n#&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 b_Intercept 79.2   1.99    0.0325  0.0290\n#&gt; 2 b_mom_hs     9.65  2.24    0.0361  0.0321\n\n\n67.7.3 Intervallo di credibilità per la differenza\n\nbayestestR::hdi(fit_2, parameters = \"mom_hs\", ci = 0.89)\n#&gt; Highest Density Interval\n#&gt; \n#&gt; Parameter |       89% HDI\n#&gt; -------------------------\n#&gt; mom_hs    | [6.10, 13.27]\n\n\n67.7.4 Variabilità spiegata\n\nbayes_R2(fit_2)\n#&gt;    Estimate Est.Error    Q2.5   Q97.5\n#&gt; R2  0.04003   0.01711 0.01137 0.07688\n\n\n67.7.5 Sintesi\nIn questo esempio, entrambi i modelli suggeriscono una differenza nei punteggi QI tra i due gruppi. Tuttavia, l’approccio bayesiano fornisce:\n\nuna valutazione diretta della probabilità che la differenza sia superiore a una soglia,\nuna rappresentazione esplicita dell’incertezza,\nuna maggiore flessibilità modellistica (es. skew-normal).\n\nIn ambito psicologico, dove è spesso più utile stimare la grandezza di un effetto e comprendere il grado di incertezza, l’approccio bayesiano offre strumenti più adatti a una comunicazione chiara, informativa e interpretabile.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#prior-predictive-checks",
    "href": "chapters/linear_models/07_two_means.html#prior-predictive-checks",
    "title": "67  Confronto tra le medie di due gruppi",
    "section": "\n67.8 Prior Predictive Checks",
    "text": "67.8 Prior Predictive Checks\nUn aspetto cruciale della modellazione bayesiana consiste nel chiedersi: che tipo di dati ci aspettiamo di osservare sulla base dei soli prior, prima ancora di vedere i dati reali? Questo processo prende il nome di prior predictive check, ovvero controllo predittivo a priori.\nAttraverso questo controllo, possiamo verificare se i prior specificati producono previsioni compatibili con il fenomeno che stiamo studiando. In pratica, simuliamo dati fittizi partendo esclusivamente dalla distribuzione a priori dei parametri, senza usare alcuna informazione osservata.\nIn brms, questa operazione è analoga ai posterior predictive checks, con una differenza fondamentale: istruiamo il pacchetto a campionare solo dai prior, ignorando temporaneamente i dati. Questo richiede che tutti i parametri abbiano prior esplicitamente definiti e, idealmente, che tali prior siano anche plausibili.\n\n67.8.1 Specifica dei prior\nApplichiamo questo processo a un modello gaussiano sui dati kidiq. Cominciamo ispezionando i prior predefiniti che brms seleziona automaticamente:\n\nget_prior(kid_score ~ mom_hs, data = kidiq)\n#&gt;                   prior     class   coef group resp dpar nlpar lb ub\n#&gt;  student_t(3, 90, 19.3) Intercept                                   \n#&gt;                  (flat)         b                                   \n#&gt;                  (flat)         b mom_hs                            \n#&gt;   student_t(3, 0, 19.3)     sigma                               0   \n#&gt;        source\n#&gt;       default\n#&gt;       default\n#&gt;  (vectorized)\n#&gt;       default\n\nLi sostituiamo con prior debolmente informativi ma più riflessivi, basati su conoscenza generale:\n\nprior_gaussian &lt;- \n  prior(normal(90, 20), class = \"b\", coef = \"Intercept\") +\n  prior(normal(0, 15), class = \"b\", coef = \"mom_hs\") +\n  prior(cauchy(0, 20), class = \"sigma\")\n\nQuesti prior riflettono ipotesi deboli ma ragionevoli:\n\n\nIntercetta (β₀): il QI medio della popolazione è plausibilmente intorno a 90, ma lasciamo ampia incertezza.\n\nEffetto di mom_hs (β₁): l’effetto dell’istruzione materna potrebbe essere vicino a zero, ma è libero di essere anche ampio (positivo o negativo).\n\nDeviazione standard (σ): ci aspettiamo variabilità sostanziale, ma sempre positiva, coerente con il QI.\n\n67.8.2 Stima del modello con prior espliciti\nFit del modello ai dati, utilizzando i prior appena definiti:\n\nfit_3 &lt;- brm(\n  bf(kid_score ~ 1 + mom_hs, center = FALSE), \n  data = kidiq,\n  prior = prior_gaussian,\n  family = gaussian(),\n  backend = \"cmdstanr\", \n  silent = 0\n)\n\nVisualizziamo le stime posteriori dei parametri \\(\\beta_0\\) e \\(\\beta_1\\):\n\ndraws &lt;- posterior::as_draws(fit_3, variable = \"^b_\", regex = TRUE)\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 2 × 5\n#&gt;   variable     mean    sd mcse_mean mcse_sd\n#&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 b_Intercept  78.0  2.05    0.0534  0.0414\n#&gt; 2 b_mom_hs     11.2  2.29    0.0593  0.0469\n\n\n67.8.3 Simulazione dalla distribuzione a priori\nOra eseguiamo un vero e proprio prior predictive check: chiediamo a brms di ignorare i dati e campionare solo dai prior, generando simulazioni sulla base delle ipotesi a priori.\n\nfit_4 &lt;- brm(\n  bf(kid_score ~ 1 + mom_hs, center = FALSE), \n  data = kidiq,\n  prior = prior_gaussian,\n  family = gaussian(),\n  backend = \"cmdstanr\", \n  silent = 0,\n  sample_prior = \"only\"\n)\n\nPoiché i dati non sono utilizzati, i parametri stimati riflettono esattamente i prior:\n\nsummary(fit_4)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: kid_score ~ 1 + mom_hs \n#&gt;    Data: kidiq (Number of observations: 434) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept    89.89     20.01    50.65   128.40 1.00     3689     2858\n#&gt; mom_hs       -0.04     14.73   -27.63    28.42 1.00     3613     2922\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma   240.42   4297.30     0.66   578.48 1.00     3095     2039\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n67.8.4 Visualizzazione del prior predictive check\nUsiamo pp_check() per visualizzare le distribuzioni simulate:\n\npp_check(fit_4, ndraws = 100) + xlim(10, 180)\n\n\n\n\n\n\n\nNel grafico, la distribuzione dei punteggi simulati (in blu) rappresenta le predizioni del modello prima di vedere i dati. L’obiettivo è verificare se queste simulazioni sono compatibili con la scala del fenomeno osservato.\nNel nostro esempio, i dati simulati si estendono su un range ampio (in linea con la variabilità attesa del QI), ma restano entro limiti plausibili. Questo suggerisce che i prior scelti sono sufficientemente flessibili da coprire l’intervallo di valori attesi, senza però generare predizioni assurde (come QI negativi o superiori a 200 con alta probabilità).\n\n67.8.5 Perché i prior predictive checks sono importanti?\n\nCi permettono di verificare visivamente le implicazioni dei prior prima di usare i dati.\nCi aiutano a diagnosticare prior inadeguati, troppo vaghi (che generano predizioni implausibili) o troppo stretti (che limitano eccessivamente le possibili inferenze).\nSono particolarmente utili in contesti con campioni piccoli o informazione limitata, in cui i prior possono influenzare fortemente i risultati.\n\n\n⚠️ Anche prior che sembrano ragionevoli “sulla carta” possono produrre risultati irrealistici una volta combinati con la struttura del modello. Per questo motivo, il controllo predittivo a priori è una verifica fondamentale nella costruzione di un buon modello bayesiano.\n\nIn sintesi, i prior predictive checks offrono una lente critica con cui valutare se ciò che crediamo prima di osservare i dati è coerente con ciò che potremmo realisticamente osservare. Questa fase, spesso trascurata, rappresenta un passaggio chiave nella costruzione di modelli bayesiani robusti e trasparenti.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#esempio-con-prior-informativi",
    "href": "chapters/linear_models/07_two_means.html#esempio-con-prior-informativi",
    "title": "67  Confronto tra le medie di due gruppi",
    "section": "\n67.9 Esempio con prior informativi",
    "text": "67.9 Esempio con prior informativi\nUn ulteriore approfondimento dell’approccio bayesiano riguarda l’uso di prior informativi, ossia distribuzioni a priori costruite sulla base di evidenze precedenti, conoscenza teorica o risultati di studi passati.\nImmaginiamo, ad esempio, che studi precedenti abbiano suggerito che i figli di madri diplomate tendano ad avere, in media, un QI superiore di circa 10 punti rispetto ai figli di madri non diplomate. Possiamo incorporare questa conoscenza specificando un prior normale centrato su 10 per il coefficiente associato a mom_hs, con una deviazione standard di 5 per rappresentare un’incertezza moderata:\n\nfit_5 &lt;- brm(\n  kid_score ~ mom_hs,\n  data = kidiq,\n  prior = c(set_prior(\"normal(10, 5)\", class = \"b\", coef = \"mom_hs\")),\n  backend = \"cmdstanr\",\n  silent = 0\n)\n\n\nsummary(fit_5)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: kid_score ~ mom_hs \n#&gt;    Data: kidiq (Number of observations: 434) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept    77.81      1.92    74.07    81.58 1.00     4427     3120\n#&gt; mom_hs       11.43      2.12     7.37    15.60 1.00     4265     3078\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma    19.88      0.66    18.62    21.20 1.00     4270     3219\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nIn questo caso, la distribuzione a posteriori per il parametro $_1$ rifletterà una combinazione dell’evidenza fornita dai dati e della conoscenza pregressa espressa nel prior. Quando i dati sono abbondanti e informativi (come in questo esempio), l’influenza del prior tende a ridursi, ma in campioni più piccoli può risultare sostanziale, rendendo il ruolo del prior ancora più importante.\n\n67.9.1 Test di ipotesi bayesiano con hypothesis()\n\nIl pacchetto brms consente di eseguire test di ipotesi direttamente sulla distribuzione a posteriori tramite il comando hypothesis(). Questo strumento è particolarmente utile per valutare se un parametro supera (o è inferiore a) una soglia di interesse:\n\nhypothesis(fit_1, \"mom_hs &gt; 5\")\n#&gt; Hypothesis Tests for class b:\n#&gt;         Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio\n#&gt; 1 (mom_hs)-(5) &gt; 0     6.78      2.31     3.02    10.54        399\n#&gt;   Post.Prob Star\n#&gt; 1         1    *\n#&gt; ---\n#&gt; 'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses.\n#&gt; '*': For one-sided hypotheses, the posterior probability exceeds 95%;\n#&gt; for two-sided hypotheses, the value tested against lies outside the 95%-CI.\n#&gt; Posterior probabilities of point hypotheses assume equal prior probabilities.\n\nIl risultato di questo test fornisce:\n\nLa probabilità a posteriori che il parametro sia maggiore di 5,\nL’intervallo di credibilità (ad esempio, al 90%) entro cui si trova il parametro con elevata probabilità,\nUna valutazione sintetica dell’evidenza, formulata in termini diretti.\n\nA differenza del p-value frequentista, che esprime quanto sarebbe raro ottenere un certo risultato se l’ipotesi nulla fosse vera, l’approccio bayesiano permette di affermare, ad esempio:\n\nC’è una probabilità del 98% che la differenza media tra i gruppi superi i 5 punti.\n\nQuesta modalità comunicativa è più intuitiva e direttamente interpretabile, ed evita l’ambiguità che spesso accompagna i p-value.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#riflessioni-conclusive",
    "href": "chapters/linear_models/07_two_means.html#riflessioni-conclusive",
    "title": "67  Confronto tra le medie di due gruppi",
    "section": "\n67.10 Riflessioni Conclusive",
    "text": "67.10 Riflessioni Conclusive\nIn questo capitolo abbiamo esplorato il paradigma bayesiano attraverso l’uso del pacchetto brms, mostrando passo dopo passo come:\n\nformulare un modello statistico flessibile,\nspecificare prior deboli o informativi,\neseguire inferenze interpretabili in termini probabilistici,\ndiagnosticare il comportamento del modello attraverso verifiche predittive,\nconfrontare i risultati bayesiani con l’approccio frequentista.\n\nL’approccio bayesiano si distingue non solo per la forma dei risultati, ma per il cambio di prospettiva epistemologica che propone: invece di chiederci se un effetto “esiste” o meno secondo un criterio arbitrario (es. \\(\\alpha = 0.05\\)), ci invita a formulare e aggiornare credenze sulla base dei dati osservati, e a quantificare direttamente la nostra incertezza.\nIn sintesi, l’inferenza bayesiana:\n\nconsente di ottenere intervalli di credibilità con interpretazioni dirette e trasparenti,\npermette di esprimere probabilità su parametri o ipotesi, come la probabilità che una differenza sia maggiore di un valore rilevante,\nintegra in modo naturale e controllato informazioni pregresse, attraverso la scelta dei prior,\nsi adatta con grande flessibilità a modelli più complessi o a strutture dati non ideali (asimmetrie, varianze eterogenee, piccoli campioni).\n\nInoltre, strumenti come pp_check() e i prior predictive checks permettono di validare le assunzioni del modello in modo visivo e intuitivo, facilitando la costruzione di modelli più robusti e coerenti.\n\nL’approccio bayesiano non è semplicemente un’alternativa tecnica, ma una cornice concettuale più coerente e informativa per rispondere a domande complesse nel contesto della ricerca psicologica e sociale.\n\nIn conclusione, il pacchetto brms rende la modellazione bayesiana accessibile e potente, offrendo un’interfaccia intuitiva per definire, stimare e interpretare modelli complessi. Più che un semplice strumento computazionale, brms è un alleato metodologico che permette di adottare un modo di ragionare più flessibile, trasparente e rigoroso.\nQuesto capitolo ha posto le basi per utilizzare il pensiero bayesiano nella pratica, non solo per “ottenere risultati”, ma per pensare in modo più critico e profondo all’incertezza, alla variabilità e al significato delle evidenze empiriche.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/07_two_means.html#informazioni-sullambiente-di-sviluppo",
    "title": "67  Confronto tra le medie di due gruppi",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] insight_1.2.0     bayestestR_0.15.3 brms_2.22.0       Rcpp_1.0.14      \n#&gt;  [5] posterior_1.6.1   cmdstanr_0.9.0    thematic_0.1.6    MetBrewer_0.2.0  \n#&gt;  [9] ggokabeito_0.1.0  see_0.11.0        gridExtra_2.3     patchwork_1.3.0  \n#&gt; [13] bayesplot_1.12.0  psych_2.5.3       scales_1.4.0      markdown_2.0     \n#&gt; [17] knitr_1.50        lubridate_1.9.4   forcats_1.0.0     stringr_1.5.1    \n#&gt; [21] dplyr_1.1.4       purrr_1.0.4       readr_2.1.5       tidyr_1.3.1      \n#&gt; [25] tibble_3.2.1      ggplot2_3.5.2     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [29] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1     farver_2.1.2         loo_2.8.0           \n#&gt;  [4] R.utils_2.13.0       fastmap_1.2.0        tensorA_0.36.2.1    \n#&gt;  [7] pacman_0.5.1         digest_0.6.37        timechange_0.3.0    \n#&gt; [10] estimability_1.5.1   lifecycle_1.0.4      StanHeaders_2.32.10 \n#&gt; [13] processx_3.8.6       magrittr_2.0.3       compiler_4.5.0      \n#&gt; [16] rlang_1.1.6          tools_4.5.0          utf8_1.2.5          \n#&gt; [19] yaml_2.3.10          data.table_1.17.2    labeling_0.4.3      \n#&gt; [22] bridgesampling_1.1-2 htmlwidgets_1.6.4    curl_6.2.2          \n#&gt; [25] pkgbuild_1.4.7       mnormt_2.1.1         plyr_1.8.9          \n#&gt; [28] RColorBrewer_1.1-3   abind_1.4-8          withr_3.0.2         \n#&gt; [31] R.oo_1.27.1          datawizard_1.1.0     stats4_4.5.0        \n#&gt; [34] grid_4.5.0           colorspace_2.1-1     inline_0.3.21       \n#&gt; [37] xtable_1.8-4         emmeans_1.11.1       cli_3.6.5           \n#&gt; [40] mvtnorm_1.3-3        rmarkdown_2.29       generics_0.1.4      \n#&gt; [43] RcppParallel_5.1.10  rstudioapi_0.17.1    reshape2_1.4.4      \n#&gt; [46] tzdb_0.5.0           rstan_2.32.7         parallel_4.5.0      \n#&gt; [49] matrixStats_1.5.0    vctrs_0.6.5          V8_6.0.3            \n#&gt; [52] Matrix_1.7-3         jsonlite_2.0.0       hms_1.1.3           \n#&gt; [55] glue_1.8.0           codetools_0.2-20     ps_1.9.1            \n#&gt; [58] distributional_0.5.0 stringi_1.8.7        gtable_0.3.6        \n#&gt; [61] QuickJSR_1.7.0       pillar_1.10.2        htmltools_0.5.8.1   \n#&gt; [64] Brobdingnag_1.2-9    R6_2.6.1             rprojroot_2.0.4     \n#&gt; [67] evaluate_1.0.3       lattice_0.22-7       haven_2.5.4         \n#&gt; [70] R.methodsS3_1.8.2    backports_1.5.0      rstantools_2.4.0    \n#&gt; [73] coda_0.19-4.1        nlme_3.1-168         checkmate_2.3.2     \n#&gt; [76] xfun_0.52            pkgconfig_2.0.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#bibliografia",
    "href": "chapters/linear_models/07_two_means.html#bibliografia",
    "title": "67  Confronto tra le medie di due gruppi",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGoodman, S. N. (1999). Toward evidence-based medical statistics. 1: The P value fallacy. Annals of internal medicine, 130(12), 995–1004.\n\n\nJohnson, D. H. (1999). The insignificance of statistical significance testing. The journal of wildlife management, 763–772.\n\n\nKruschke, J. K. (2013). Bayesian estimation supersedes the t test. Journal of Experimental Psychology: General, 142(2), 573–603.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07a_effect_size.html",
    "href": "chapters/linear_models/07a_effect_size.html",
    "title": "68  Stima bayesiana della grandezza dell’effetto",
    "section": "",
    "text": "69 Introduzione\nNel capitolo precedente abbiamo esaminato il confronto tra due gruppi, stimando la differenza tra le medie dei punteggi di QI in base al livello di istruzione della madre. Abbiamo visto come l’approccio bayesiano consenta di ottenere la distribuzione a posteriori della differenza tra gruppi, formulare probabilità su ipotesi e generare intervalli di credibilità.\nIn questo capitolo approfondiamo un altro aspetto fondamentale dell’inferenza: la stima della grandezza dell’effetto (effect size), ovvero quanto è “grande” o “rilevante” l’effetto osservato. L’obiettivo non è soltanto sapere se esiste una differenza, ma valutare quanto è importante quella differenza in termini comparabili e interpretabili.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>Stima bayesiana della grandezza dell’effetto</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07a_effect_size.html#che-cosè-una-grandezza-delleffetto",
    "href": "chapters/linear_models/07a_effect_size.html#che-cosè-una-grandezza-delleffetto",
    "title": "68  Stima bayesiana della grandezza dell’effetto",
    "section": "\n69.1 Che cos’è una grandezza dell’effetto?",
    "text": "69.1 Che cos’è una grandezza dell’effetto?\nNel confronto tra due gruppi, una misura standard della grandezza dell’effetto è il Cohen’s d, che rappresenta la differenza tra le medie standardizzata rispetto alla deviazione standard complessiva:\n\\[\nd = \\frac{\\mu_1 - \\mu_2}{\\sigma},\n\\]\ndove:\n\n\n\\(\\mu_1\\) e \\(\\mu_2\\) sono le medie dei due gruppi,\n\n\\(\\sigma\\) è la deviazione standard pooled (una stima comune della variabilità nei due gruppi).\n\nNel contesto bayesiano, questa quantità può essere derivata a posteriori, a partire dai campioni MCMC della differenza tra le medie e della deviazione standard.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>Stima bayesiana della grandezza dell’effetto</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07a_effect_size.html#calcolo-di-cohens-d-in-brms",
    "href": "chapters/linear_models/07a_effect_size.html#calcolo-di-cohens-d-in-brms",
    "title": "68  Stima bayesiana della grandezza dell’effetto",
    "section": "\n69.2 Calcolo di Cohen’s d in brms\n",
    "text": "69.2 Calcolo di Cohen’s d in brms\n\nCarichiamo i dati e visualizziamo le prime righe per comprenderne la struttura:\n\nkidiq &lt;- rio::import(here::here(\"data\", \"kidiq.dta\"))\nkidiq |&gt; \n  head()\n#&gt;   kid_score mom_hs mom_iq mom_work mom_age\n#&gt; 1        65      1 121.12        4      27\n#&gt; 2        98      1  89.36        4      25\n#&gt; 3        85      1 115.44        4      27\n#&gt; 4        83      1  99.45        3      25\n#&gt; 5       115      1  92.75        4      27\n#&gt; 6        98      0 107.90        1      18\n\nPartiamo dal modello già stimato nel capitolo precedente:\n\nfit_1 &lt;- brm(\n  kid_score ~ mom_hs, \n  data = kidiq, \n  backend = \"cmdstanr\", \n  silent = 0\n)\n\nOtteniamo i campioni posteriori per il coefficiente \\(\\beta\\_1\\) (la differenza tra i gruppi) e per \\(\\sigma\\):\n\npost &lt;- as_draws_df(fit_1)\n\ndiff_samples &lt;- post$b_mom_hs\nsigma_samples &lt;- post$sigma\n\nCalcoliamo ora la distribuzione a posteriori di Cohen’s d:\n\nd_posterior &lt;- diff_samples / sigma_samples\n\n\n69.2.1 Visualizzazione della distribuzione di Cohen’s d\n\nmcmc_areas(as_draws_df(tibble(d = d_posterior)), pars = \"d\", prob = 0.89) +\n  labs(\n    title = \"Distribuzione a posteriori di Cohen's d\",\n    subtitle = \"Differenza standardizzata tra i gruppi (QI ~ mom_hs)\"\n  )\n\n\n\n\n\n\n\n\n69.2.2 Statistiche riassuntive\n\nbayestestR::describe_posterior(d_posterior, ci = 0.89)\n#&gt; Summary of Posterior Distribution\n#&gt; \n#&gt; Parameter | Median |       89% CI |   pd |          ROPE | % in ROPE\n#&gt; --------------------------------------------------------------------\n#&gt; Posterior |   0.59 | [0.41, 0.78] | 100% | [-0.10, 0.10] |        0%\n\nQueste statistiche ci permettono di interpretare:\n\nla media a posteriori di d (la stima puntuale),\nl’intervallo di credibilità (ad esempio all’89%),\nla probabilità a posteriori che l’effetto sia positivo e rilevante.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>Stima bayesiana della grandezza dell’effetto</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07a_effect_size.html#interpretazione-della-grandezza-delleffetto",
    "href": "chapters/linear_models/07a_effect_size.html#interpretazione-della-grandezza-delleffetto",
    "title": "68  Stima bayesiana della grandezza dell’effetto",
    "section": "\n69.3 Interpretazione della grandezza dell’effetto",
    "text": "69.3 Interpretazione della grandezza dell’effetto\nIl valore di Cohen’s d può essere interpretato secondo linee guida standard:\n\n\nValore di d\n\nInterpretazione\n\n\n\n0.2\nEffetto piccolo\n\n\n0.5\nEffetto medio\n\n\n0.8 o superiore\nEffetto grande\n\n\n\nTuttavia, nel contesto bayesiano non ci limitiamo a classificare, ma possiamo calcolare direttamente la probabilità che d superi una soglia rilevante, ad esempio:\n\nmean(d_posterior &gt; 0.5)  # Probabilità che l'effetto sia almeno medio\n#&gt; [1] 0.7873\n\nOppure:\n\nmean(d_posterior &gt; 0.8)  # Probabilità che l'effetto sia grande\n#&gt; [1] 0.037\n\nQueste probabilità permettono di rispondere a domande più precise e utili del tipo:\n\nQuanto è probabile che l’effetto dell’istruzione materna sul QI sia almeno medio?",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>Stima bayesiana della grandezza dell’effetto</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07a_effect_size.html#riflessioni-conclusive",
    "href": "chapters/linear_models/07a_effect_size.html#riflessioni-conclusive",
    "title": "68  Stima bayesiana della grandezza dell’effetto",
    "section": "\n69.4 Riflessioni conclusive",
    "text": "69.4 Riflessioni conclusive\nLa stima della grandezza dell’effetto è fondamentale per interpretare il significato pratico di una differenza. L’approccio bayesiano consente non solo di calcolare Cohen’s d, ma anche di quantificare l’incertezza sulla sua stima e valutare la probabilità che l’effetto sia superiore a soglie di interesse pratico.\nRispetto all’approccio frequentista, che spesso riporta un unico valore puntuale di d, il metodo bayesiano:\n\nrestituisce una distribuzione completa dell’effetto,\npermette di costruire intervalli di credibilità per d,\nconsente di stimare probabilità direttamente interpretabili, ad esempio: “C’è l’85% di probabilità che l’effetto sia almeno medio”.\n\nNel contesto psicologico, dove l’interesse principale è spesso legato alla rilevanza dell’effetto (e non solo alla sua esistenza), questa modalità di analisi si rivela particolarmente utile, comunicativa e rigorosa.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>Stima bayesiana della grandezza dell’effetto</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07a_effect_size.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/07a_effect_size.html#informazioni-sullambiente-di-sviluppo",
    "title": "68  Stima bayesiana della grandezza dell’effetto",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] insight_1.2.0     bayestestR_0.15.3 brms_2.22.0       Rcpp_1.0.14      \n#&gt;  [5] posterior_1.6.1   cmdstanr_0.9.0    thematic_0.1.6    MetBrewer_0.2.0  \n#&gt;  [9] ggokabeito_0.1.0  see_0.11.0        gridExtra_2.3     patchwork_1.3.0  \n#&gt; [13] bayesplot_1.12.0  psych_2.5.3       scales_1.4.0      markdown_2.0     \n#&gt; [17] knitr_1.50        lubridate_1.9.4   forcats_1.0.0     stringr_1.5.1    \n#&gt; [21] dplyr_1.1.4       purrr_1.0.4       readr_2.1.5       tidyr_1.3.1      \n#&gt; [25] tibble_3.2.1      ggplot2_3.5.2     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [29] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1     farver_2.1.2         loo_2.8.0           \n#&gt;  [4] R.utils_2.13.0       fastmap_1.2.0        tensorA_0.36.2.1    \n#&gt;  [7] pacman_0.5.1         digest_0.6.37        timechange_0.3.0    \n#&gt; [10] estimability_1.5.1   lifecycle_1.0.4      StanHeaders_2.32.10 \n#&gt; [13] processx_3.8.6       magrittr_2.0.3       compiler_4.5.0      \n#&gt; [16] rlang_1.1.6          tools_4.5.0          yaml_2.3.10         \n#&gt; [19] data.table_1.17.2    labeling_0.4.3       bridgesampling_1.1-2\n#&gt; [22] htmlwidgets_1.6.4    curl_6.2.2           pkgbuild_1.4.7      \n#&gt; [25] mnormt_2.1.1         plyr_1.8.9           RColorBrewer_1.1-3  \n#&gt; [28] abind_1.4-8          withr_3.0.2          R.oo_1.27.1         \n#&gt; [31] datawizard_1.1.0     stats4_4.5.0         grid_4.5.0          \n#&gt; [34] colorspace_2.1-1     inline_0.3.21        xtable_1.8-4        \n#&gt; [37] ggridges_0.5.6       emmeans_1.11.1       cli_3.6.5           \n#&gt; [40] mvtnorm_1.3-3        rmarkdown_2.29       generics_0.1.4      \n#&gt; [43] RcppParallel_5.1.10  rstudioapi_0.17.1    reshape2_1.4.4      \n#&gt; [46] tzdb_0.5.0           rstan_2.32.7         parallel_4.5.0      \n#&gt; [49] matrixStats_1.5.0    vctrs_0.6.5          V8_6.0.3            \n#&gt; [52] Matrix_1.7-3         jsonlite_2.0.0       hms_1.1.3           \n#&gt; [55] glue_1.8.0           codetools_0.2-20     ps_1.9.1            \n#&gt; [58] distributional_0.5.0 stringi_1.8.7        gtable_0.3.6        \n#&gt; [61] QuickJSR_1.7.0       pillar_1.10.2        htmltools_0.5.8.1   \n#&gt; [64] Brobdingnag_1.2-9    R6_2.6.1             rprojroot_2.0.4     \n#&gt; [67] evaluate_1.0.3       lattice_0.22-7       haven_2.5.4         \n#&gt; [70] R.methodsS3_1.8.2    backports_1.5.0      rstantools_2.4.0    \n#&gt; [73] coda_0.19-4.1        nlme_3.1-168         checkmate_2.3.2     \n#&gt; [76] xfun_0.52            pkgconfig_2.0.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>Stima bayesiana della grandezza dell’effetto</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07a_effect_size.html#bibliografia",
    "href": "chapters/linear_models/07a_effect_size.html#bibliografia",
    "title": "68  Stima bayesiana della grandezza dell’effetto",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nKruschke, J. K. (2013). Bayesian estimation supersedes the t test. Journal of Experimental Psychology: General, 142(2), 573–603.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>Stima bayesiana della grandezza dell’effetto</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07b_posterior_draws.html",
    "href": "chapters/linear_models/07b_posterior_draws.html",
    "title": "69  Manipolazione dei campioni a posteriori",
    "section": "",
    "text": "69.1 Introduzione\nL’inferenza bayesiana fornisce campioni a posteriori dei parametri del modello, ottenuti tramite tecniche MCMC. Questi campioni rappresentano la distribuzione della nostra incertezza dopo aver osservato i dati.\nQuando usiamo brms() (che si appoggia a Stan), i campioni vengono salvati in un oggetto complesso. Per manipolarli in modo semplice e intuitivo, possiamo utilizzare il pacchetto tidybayes, che permette di riformattare i campioni in uno stile “tidy” (long o wide), adatto per la visualizzazione e l’analisi descrittiva.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>Manipolazione dei campioni a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07b_posterior_draws.html#dati-ed-esplorazione-iniziale",
    "href": "chapters/linear_models/07b_posterior_draws.html#dati-ed-esplorazione-iniziale",
    "title": "69  Manipolazione dei campioni a posteriori",
    "section": "\n69.2 Dati ed esplorazione iniziale",
    "text": "69.2 Dati ed esplorazione iniziale\nImportiamo un dataset classico e costruiamo una variabile centrata:\n\ndat &lt;- rio::import(here::here(\"data\", \"Howell_18.csv\"))\nhead(dat)\n#&gt;   height weight age male\n#&gt; 1  151.8  47.83  63    1\n#&gt; 2  139.7  36.49  63    0\n#&gt; 3  136.5  31.86  65    0\n#&gt; 4  156.8  53.04  41    1\n#&gt; 5  145.4  41.28  51    0\n#&gt; 6  163.8  62.99  35    1\n\ndat$weight_c &lt;- dat$weight - mean(dat$weight)\n\nVisualizziamo la relazione tra peso centrato e altezza:\n\nggplot(data = dat, aes(x = weight_c, y = height)) + \n  geom_point(size = 3, alpha = 0.3)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>Manipolazione dei campioni a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07b_posterior_draws.html#stima-del-modello-bayesiano",
    "href": "chapters/linear_models/07b_posterior_draws.html#stima-del-modello-bayesiano",
    "title": "69  Manipolazione dei campioni a posteriori",
    "section": "\n69.3 Stima del modello bayesiano",
    "text": "69.3 Stima del modello bayesiano\nStimiamo un modello di regressione lineare semplice:\n\nmodel1 &lt;- brm(\n  height ~ weight_c, \n  data = dat,\n  backend = \"cmdstanr\"\n)\n\nVisualizziamo il riepilogo:\n\nsummary(model1)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: height ~ weight_c \n#&gt;    Data: dat (Number of observations: 352) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept   154.59      0.27   154.07   155.12 1.00     3688     2786\n#&gt; weight_c      0.91      0.04     0.82     0.99 1.00     4432     2649\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     5.11      0.19     4.75     5.49 1.00     4189     2812\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nPer una versione “tidy”, usiamo tidybayes::summarise_draws():\n\ntidybayes::summarise_draws(model1)\n#&gt; # A tibble: 6 × 10\n#&gt;   variable         mean    median     sd    mad        q5       q95  rhat\n#&gt;   &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 b_Intercept   155.      155.    0.268  0.259    154.      155.     1.00\n#&gt; 2 b_weight_c      0.905     0.905 0.0426 0.0425     0.836     0.976  1.00\n#&gt; 3 sigma           5.11      5.10  0.191  0.190      4.80      5.42   1.00\n#&gt; 4 Intercept     155.      155.    0.268  0.259    154.      155.     1.00\n#&gt; 5 lprior         -5.82     -5.82  0.0163 0.0161    -5.85     -5.79   1.00\n#&gt; 6 lp__        -1077.    -1076.    1.22   0.979  -1079.    -1075.     1.00\n#&gt;   ess_bulk ess_tail\n#&gt;      &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1    3688.    2786.\n#&gt; 2    4432.    2649.\n#&gt; 3    4189.    2812.\n#&gt; 4    3688.    2786.\n#&gt; 5    4121.    2829.\n#&gt; 6    1809.    2323.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>Manipolazione dei campioni a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07b_posterior_draws.html#estrazione-dei-campioni-a-posteriori",
    "href": "chapters/linear_models/07b_posterior_draws.html#estrazione-dei-campioni-a-posteriori",
    "title": "69  Manipolazione dei campioni a posteriori",
    "section": "\n69.4 Estrazione dei campioni a posteriori",
    "text": "69.4 Estrazione dei campioni a posteriori\n\n69.4.1 Campioni in formato wide\n\nUsiamo spread_draws() per ottenere un data frame con una colonna per ciascun parametro:\n\nposteriors1 &lt;- model1 |&gt;\n  tidybayes::spread_draws(b_weight_c, b_Intercept)\n\nhead(posteriors1)\n#&gt; # A tibble: 6 × 5\n#&gt;   .chain .iteration .draw b_weight_c b_Intercept\n#&gt;    &lt;int&gt;      &lt;int&gt; &lt;int&gt;      &lt;dbl&gt;       &lt;dbl&gt;\n#&gt; 1      1          1     1      0.932        155.\n#&gt; 2      1          2     2      0.931        155.\n#&gt; 3      1          3     3      0.912        155.\n#&gt; 4      1          4     4      0.900        154.\n#&gt; 5      1          5     5      0.900        155.\n#&gt; 6      1          6     6      0.936        154.\n\nSe ci interessano solo le due variabili principali:\n\nposteriors1 &lt;- posteriors1 |&gt;\n  dplyr::select(b_weight_c, b_Intercept)\nhead(posteriors1)\n#&gt; # A tibble: 6 × 2\n#&gt;   b_weight_c b_Intercept\n#&gt;        &lt;dbl&gt;       &lt;dbl&gt;\n#&gt; 1      0.932        155.\n#&gt; 2      0.931        155.\n#&gt; 3      0.912        155.\n#&gt; 4      0.900        154.\n#&gt; 5      0.900        155.\n#&gt; 6      0.936        154.\n\n\n69.4.2 Visualizzazione dell’incertezza\nSovrapponiamo al grafico dei dati grezzi alcune rette di regressione basate su 100 campioni a posteriori:\n\nposteriors2 &lt;- model1 |&gt;\n  tidybayes::spread_draws(b_weight_c, b_Intercept, ndraws = 100) |&gt;\n  dplyr::select(b_weight_c, b_Intercept)\n\nggplot(data = dat, aes(x = weight_c, y = height)) + \n  geom_abline(data = posteriors2,\n              aes(intercept = b_Intercept, slope = b_weight_c), \n              linewidth = 0.1, alpha = 0.4) +\n  geom_point(size = 3, alpha = 0.3)\n\n\n\n\n\n\n\nLe molte rette grigie rappresentano l’incertezza nella stima della relazione peso-altezza: ogni retta è una possibile “verità” compatibile con i dati.\n\n69.4.3 Campioni in formato long\n\nSe preferiamo lavorare con un formato “long” (una riga per ogni campione-variabile), usiamo gather_draws():\n\nposteriors3 &lt;- model1 |&gt;\n   tidybayes::gather_draws(b_weight_c) |&gt; \n   rename(parameter = .variable,\n          posterior = .value) |&gt; \n   dplyr::select(parameter, posterior)\n\nhead(posteriors3)\n#&gt; # A tibble: 6 × 2\n#&gt; # Groups:   parameter [1]\n#&gt;   parameter  posterior\n#&gt;   &lt;chr&gt;          &lt;dbl&gt;\n#&gt; 1 b_weight_c     0.932\n#&gt; 2 b_weight_c     0.931\n#&gt; 3 b_weight_c     0.912\n#&gt; 4 b_weight_c     0.900\n#&gt; 5 b_weight_c     0.900\n#&gt; 6 b_weight_c     0.936",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>Manipolazione dei campioni a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07b_posterior_draws.html#riassunto-dei-campioni-a-posteriori",
    "href": "chapters/linear_models/07b_posterior_draws.html#riassunto-dei-campioni-a-posteriori",
    "title": "69  Manipolazione dei campioni a posteriori",
    "section": "\n69.5 Riassunto dei campioni a posteriori",
    "text": "69.5 Riassunto dei campioni a posteriori\nCalcoliamo media e intervallo di credibilità al 89%:\n\nposteriors3_agg &lt;- posteriors3 |&gt; \n  group_by(parameter) |&gt; \n  summarise(\n    `89lowerCrI`   = tidybayes::hdi(posterior, credMass = 0.89)[1],\n    mean_posterior = mean(posterior),\n    `89higherCrI`  = tidybayes::hdi(posterior, credMass = 0.89)[2]\n  )\n\nposteriors3_agg \n#&gt; # A tibble: 1 × 4\n#&gt;   parameter  `89lowerCrI` mean_posterior `89higherCrI`\n#&gt;   &lt;chr&gt;             &lt;dbl&gt;          &lt;dbl&gt;         &lt;dbl&gt;\n#&gt; 1 b_weight_c        0.815          0.905         0.985\n\nQuesta tabella ci dice:\n\nqual è il valore medio a posteriori (stima puntuale),\nqual è l’intervallo di credibilità (stima dell’incertezza).\n\nLa distribuzione a posteriori della pendenza si genera nel modo seguente:\n\n# plot only the posterior distribution of the slope (b_weight_c)\nposteriors1 |&gt; \n  pivot_longer(cols = everything(), names_to = \"parameter\", values_to = \"posterior\") |&gt; \n  dplyr::filter(parameter == \"b_weight_c\") |&gt; \n  ggplot(aes(x = posterior, y = parameter, fill = parameter)) + \n    tidybayes::stat_halfeye(.width = 0.9) +\n    xlab(\"Valori della pendenza a posteriori\") +\n    ylab(\"\") +\n    scale_x_continuous(limits = c(-0.25, 1.5)) +\n    geom_segment(x = 0, xend = 0, y = Inf, yend = -Inf, lty = \"dashed\") +\n    theme(legend.position = \"none\")",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>Manipolazione dei campioni a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07b_posterior_draws.html#ipotesi-direzionali",
    "href": "chapters/linear_models/07b_posterior_draws.html#ipotesi-direzionali",
    "title": "69  Manipolazione dei campioni a posteriori",
    "section": "\n69.6 Ipotesi direzionali",
    "text": "69.6 Ipotesi direzionali\nInfine, possiamo testare un’ipotesi direzionale, ad esempio: “Il coefficiente del peso centrato è maggiore di 0.9”:\n\nhypothesis(model1, 'weight_c &gt; 0.9')\n#&gt; Hypothesis Tests for class b:\n#&gt;             Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio\n#&gt; 1 (weight_c)-(0.9) &gt; 0     0.01      0.04    -0.06     0.08        1.2\n#&gt;   Post.Prob Star\n#&gt; 1      0.55     \n#&gt; ---\n#&gt; 'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses.\n#&gt; '*': For one-sided hypotheses, the posterior probability exceeds 95%;\n#&gt; for two-sided hypotheses, the value tested against lies outside the 95%-CI.\n#&gt; Posterior probabilities of point hypotheses assume equal prior probabilities.\n\nIl risultato ci dirà con quale probabilità questa affermazione è vera, secondo la distribuzione a posteriori. Dai dati emerge che solo meno del 55% dei campioni a posteriori supera il valore di 0,9 (come indicato nella colonna Post.Prob).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>Manipolazione dei campioni a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07b_posterior_draws.html#confronto-tra-dati-predetti-dai-prior-e-dati-osservati",
    "href": "chapters/linear_models/07b_posterior_draws.html#confronto-tra-dati-predetti-dai-prior-e-dati-osservati",
    "title": "69  Manipolazione dei campioni a posteriori",
    "section": "\n69.7 Confronto tra dati predetti dai prior e dati osservati",
    "text": "69.7 Confronto tra dati predetti dai prior e dati osservati\nUna delle buone pratiche dell’inferenza bayesiana è il controllo predittivo a priori: si verifica cosa il modello si aspetta prima di vedere i dati. Questo consente di valutare se i prior siano ragionevoli o troppo restrittivi o permissivi rispetto ai dati reali.\n\n69.7.1 Definizione dei prior\nSpecifichiamo dei prior debolamente informativi:\n\nprior_baseline &lt;- c(\n  prior(\"normal(0, 2.5)\", class = \"b\"),               # prior sulla pendenza\n  prior(\"student_t(3, 150, 10)\", class = \"Intercept\") # prior sull'intercetta\n)\n\n\nLa pendenza (b) ha prior centrato su 0, con deviazione standard 2.5.\nL’intercetta ha prior Student-t (più flessibile della normale).\n\n69.7.2 Stima del modello sui dati osservati\nEseguiamo il modello completo per avere una base di riferimento:\n\nfit &lt;- brm(\n  height ~ weight_c,\n  prior = prior_baseline,\n  data = dat,\n  backend = \"cmdstanr\",\n  silent = TRUE,\n  refresh = 0\n)\n\nQuesto modello utilizza i dati reali per aggiornare i prior e ottenere la distribuzione a posteriori dei parametri.\n\n69.7.3 Stima basata solo sui prior\nQui aggiorniamo il modello chiedendo a brm() di ignorare i dati e campionare solo dalle distribuzioni a priori.\n\nfit_prior_only &lt;- update(\n  fit,\n  sample_prior = \"only\", # usa solo i prior per la simulazione\n  silent = TRUE,\n  refresh = 0\n)\n\n\n69.7.4 Generazione delle predizioni a partire dai prior\nSimuliamo la distribuzione predittiva del valore atteso (E[Y|X]) per ciascun valore osservato di weight_c, usando solo i prior:\n\npriorPred_linPredictor &lt;- tidybayes::add_linpred_draws(\n  fit_prior_only, \n  newdata = tibble(weight_c = dat$weight_c),\n  ndraws = 2000,\n  value = 'height' # nome della variabile predetta\n) |&gt; \n  ungroup() |&gt; \n  dplyr::select(weight_c, .draw, height)\n\n\nUsiamo add_linpred_draws() per simulare il valore atteso del modello lineare (senza rumore).\nOtteniamo 2000 simulazioni per ogni valore di weight_c.\n\n69.7.5 Predizione dai posterior (per confronto)\nOtteniamo una sola simulazione da posteriori aggiornati per ciascun valore di weight_c:\n\npostPred_linPredictor &lt;- tidybayes::add_predicted_draws(\n  fit, \n  newdata = tibble(weight_c = dat$weight_c),\n  ndraws = 1, \n  value = 'height'\n) |&gt; \n  ungroup() |&gt; \n  select(weight_c, .draw, height)\n\nQui includiamo anche l’errore residuo (non solo il valore atteso), per simulare l’output osservabile.\n\n69.7.6 Confronto grafico tra predizioni posteriori e dati osservati\nCreiamo un grafico che mostra:\n\nin blu scuro: i dati osservati reali\nin nero: le simulazioni generate dal modello dopo aver visto i dati\n\n\nggplot() + \n  geom_point(data = postPred_linPredictor, \n             aes(x = weight_c, y = height), \n             size = 2, alpha = 0.9) +\n  geom_point(data = dat, \n             aes(x = weight_c, y = height), \n             color = \"darkblue\", size = 1, alpha = 0.8) +\n  labs(\n    title = \"Confronto tra dati osservati e predizioni dal modello\",\n    subtitle = \"I punti neri sono simulazioni dal modello posteriore; quelli blu i dati reali\",\n    x = \"Peso centrato (weight_c)\",\n    y = \"Altezza\"\n  ) \n\n\n\n\n\n\n\n\n69.7.7 Mostrare le predizioni basate solo sui prior\n\nPer vedere cosa il modello “si aspettava” prima dei dati:\n\n# Campiona 1000 righe casuali dal data frame delle predizioni a priori\npriorPred_subset &lt;- priorPred_linPredictor |&gt; \n  dplyr::sample_n(1000)\n\nggplot() + \n  geom_point(data = priorPred_subset, \n             aes(x = weight_c, y = height), \n             color = \"red\", size = 2, alpha = 0.3) +\n  geom_point(data = dat, \n             aes(x = weight_c, y = height), \n             color = \"darkblue\", size = 1, alpha = 0.8) +\n  labs(\n    title = \"Confronto tra predizioni dai prior e dati osservati\",\n    subtitle = \"I punti rossi (subset) sono predizioni basate solo sui prior\",\n    x = \"Peso centrato (weight_c)\",\n    y = \"Altezza\"\n  ) \n\n\n\n\n\n\n\nQuesto confronto è molto utile per:\n\ncapire che tipo di relazioni sono compatibili con i prior scelti;\nverificare se i prior sono troppo ampi o troppo ristretti;\ngiustificare le scelte di modellazione in modo trasparente.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>Manipolazione dei campioni a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07b_posterior_draws.html#riflessioni-conclusive",
    "href": "chapters/linear_models/07b_posterior_draws.html#riflessioni-conclusive",
    "title": "69  Manipolazione dei campioni a posteriori",
    "section": "\n69.8 Riflessioni Conclusive",
    "text": "69.8 Riflessioni Conclusive\nIn questo capitolo hai imparato a:\n\nestrarre campioni a posteriori con tidybayes;\nvisualizzare l’incertezza sui parametri stimati;\nriassumere i campioni con intervalli di credibilità;\nverificare ipotesi specifiche in un contesto bayesiano.\n\nQuesti strumenti ti permettono di andare oltre la semplice “stima puntuale” e di ragionare in termini di distribuzioni: un passo essenziale per pensare in modo bayesiano.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>Manipolazione dei campioni a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07b_posterior_draws.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/07b_posterior_draws.html#informazioni-sullambiente-di-sviluppo",
    "title": "69  Manipolazione dei campioni a posteriori",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] insight_1.2.0     bayestestR_0.15.3 brms_2.22.0       Rcpp_1.0.14      \n#&gt;  [5] posterior_1.6.1   cmdstanr_0.9.0    thematic_0.1.6    MetBrewer_0.2.0  \n#&gt;  [9] ggokabeito_0.1.0  see_0.11.0        gridExtra_2.3     patchwork_1.3.0  \n#&gt; [13] bayesplot_1.12.0  psych_2.5.3       scales_1.4.0      markdown_2.0     \n#&gt; [17] knitr_1.50        lubridate_1.9.4   forcats_1.0.0     stringr_1.5.1    \n#&gt; [21] dplyr_1.1.4       purrr_1.0.4       readr_2.1.5       tidyr_1.3.1      \n#&gt; [25] tibble_3.2.1      ggplot2_3.5.2     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [29] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] mnormt_2.1.1         inline_0.3.21        rlang_1.1.6         \n#&gt;  [4] magrittr_2.0.3       matrixStats_1.5.0    compiler_4.5.0      \n#&gt;  [7] loo_2.8.0            vctrs_0.6.5          reshape2_1.4.4      \n#&gt; [10] pkgconfig_2.0.3      arrayhelpers_1.1-0   fastmap_1.2.0       \n#&gt; [13] backports_1.5.0      labeling_0.4.3       utf8_1.2.5          \n#&gt; [16] rmarkdown_2.29       tzdb_0.5.0           ps_1.9.1            \n#&gt; [19] xfun_0.52            jsonlite_2.0.0       tidybayes_3.0.7     \n#&gt; [22] parallel_4.5.0       R6_2.6.1             stringi_1.8.7       \n#&gt; [25] RColorBrewer_1.1-3   StanHeaders_2.32.10  estimability_1.5.1  \n#&gt; [28] rstan_2.32.7         pacman_0.5.1         R.utils_2.13.0      \n#&gt; [31] Matrix_1.7-3         timechange_0.3.0     tidyselect_1.2.1    \n#&gt; [34] rstudioapi_0.17.1    abind_1.4-8          yaml_2.3.10         \n#&gt; [37] codetools_0.2-20     curl_6.2.2           processx_3.8.6      \n#&gt; [40] pkgbuild_1.4.7       lattice_0.22-7       plyr_1.8.9          \n#&gt; [43] withr_3.0.2          bridgesampling_1.1-2 coda_0.19-4.1       \n#&gt; [46] evaluate_1.0.3       RcppParallel_5.1.10  ggdist_3.3.3        \n#&gt; [49] pillar_1.10.2        tensorA_0.36.2.1     checkmate_2.3.2     \n#&gt; [52] stats4_4.5.0         distributional_0.5.0 generics_0.1.4      \n#&gt; [55] rprojroot_2.0.4      hms_1.1.3            rstantools_2.4.0    \n#&gt; [58] xtable_1.8-4         glue_1.8.0           emmeans_1.11.1      \n#&gt; [61] tools_4.5.0          data.table_1.17.2    mvtnorm_1.3-3       \n#&gt; [64] grid_4.5.0           QuickJSR_1.7.0       colorspace_2.1-1    \n#&gt; [67] nlme_3.1-168         cli_3.6.5            svUnit_1.0.6        \n#&gt; [70] Brobdingnag_1.2-9    V8_6.0.3             gtable_0.3.6        \n#&gt; [73] R.methodsS3_1.8.2    digest_0.6.37        htmlwidgets_1.6.4   \n#&gt; [76] farver_2.1.2         htmltools_0.5.8.1    R.oo_1.27.1         \n#&gt; [79] lifecycle_1.0.4",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>Manipolazione dei campioni a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07b_posterior_draws.html#bibliografia",
    "href": "chapters/linear_models/07b_posterior_draws.html#bibliografia",
    "title": "69  Manipolazione dei campioni a posteriori",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nKruschke, J. K. (2013). Bayesian estimation supersedes the t test. Journal of Experimental Psychology: General, 142(2), 573–603.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>Manipolazione dei campioni a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_sample_size.html",
    "href": "chapters/linear_models/08_sample_size.html",
    "title": "70  Disegno della ricerca e potere statistico",
    "section": "",
    "text": "70.1 Introduzione\nLa potenza statistica è definita come la probabilità, calcolata prima che uno studio venga condotto, che un determinato confronto raggiunga un livello predefinito di “significatività statistica” (tipicamente un p-value inferiore a 0,05), dato un effetto reale ipotizzato. Per calcolare la potenza, si parte da un’ipotesi sulla dimensione dell’effetto, si fanno assunzioni sulla variabilità dei dati e sulla dimensione del campione, e si utilizzano calcoli probabilistici per determinare la probabilità che il p-value sia inferiore alla soglia stabilita.\nLa visione convenzionale sconsiglia di condurre studi con bassa potenza, poiché hanno basse probabilità di “successo”. Tuttavia, in casi in cui i costi sono molto bassi rispetto ai potenziali benefici, un ricercatore potrebbe decidere di correre il rischio. Come vedremo, però, questa scelta può nascondere insidie significative.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Disegno della ricerca e potere statistico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_sample_size.html#la-maledizione-del-vincitore-negli-studi-a-bassa-potenza",
    "href": "chapters/linear_models/08_sample_size.html#la-maledizione-del-vincitore-negli-studi-a-bassa-potenza",
    "title": "70  Disegno della ricerca e potere statistico",
    "section": "\n70.2 La maledizione del vincitore negli studi a bassa potenza",
    "text": "70.2 La maledizione del vincitore negli studi a bassa potenza\nIn uno studio con bassa potenza, il “successo” apparente di un risultato statisticamente significativo può essere ingannevole. Quando il segnale è debole e il rumore elevato, i risultati significativi tendono a essere erronei (esagerati o nel segno sbagliato), con scarse probabilità di replicabilità. Questi errori sono noti come errori di tipo M (esagerazione della dimensione dell’effetto) e di tipo S (errore nel segno dell’effetto). Di conseguenza, uno studio a bassa potenza rischia di generare informazioni fuorvianti, contribuendo alla crisi di replicazione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Disegno della ricerca e potere statistico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_sample_size.html#stimare-la-dimensione-del-campione",
    "href": "chapters/linear_models/08_sample_size.html#stimare-la-dimensione-del-campione",
    "title": "70  Disegno della ricerca e potere statistico",
    "section": "\n70.3 Stimare la dimensione del campione",
    "text": "70.3 Stimare la dimensione del campione\nPrima di raccogliere dati, è utile stimare la dimensione del campione necessaria per ottenere un certo livello di precisione o per garantire una potenza desiderata. Vediamo i calcoli dettagliati.\n\n70.3.1 Determinazione della dimensione del campione per un errore standard specifico\nSupponiamo di voler stimare un valore medio \\(\\theta\\) della popolazione utilizzando un campione casuale di dimensione \\(n\\). La stima \\(\\bar{y}\\), cioè la media campionaria, ha un errore standard dato da:\n\\[\n\\text{s.e.}(\\bar{y}) = \\frac{\\sigma}{\\sqrt{n}},\n\\]\ndove:\n\n\n\\(\\text{s.e.}(\\bar{y})\\) è l’errore standard della media campionaria,\n\n\\(\\sigma\\) è la deviazione standard della popolazione,\n\n\\(n\\) è la dimensione del campione.\n\nSe vogliamo ottenere un errore standard specifico, denotato con \\(\\text{s.e.}\\), impostiamo l’equazione:\n\\[\n\\text{s.e.} = \\frac{\\sigma}{\\sqrt{n}}.\n\\]\nPer risolvere rispetto a \\(n\\), procediamo come segue:\n\nMoltiplichiamo entrambi i lati per \\(\\sqrt{n}\\) per eliminare il denominatore: \\[\n\\text{s.e.} \\cdot \\sqrt{n} = \\sigma.\n\\]\nDividiamo entrambi i lati per \\(\\text{s.e.}\\): \\[\n\\sqrt{n} = \\frac{\\sigma}{\\text{s.e.}}.\n\\]\nEleviamo al quadrato entrambi i lati per eliminare la radice: \\[\nn = \\left(\\frac{\\sigma}{\\text{s.e.}}\\right)^2.\n\\]\n\nQuesta formula ci dice che la dimensione del campione necessaria per ottenere un determinato errore standard è proporzionale al quadrato del rapporto tra la deviazione standard \\(\\sigma\\) e l’errore standard desiderato \\(\\text{s.e.}\\).\n\n70.3.2 Dimensione del campione per una potenza dell’80%\nSupponiamo ora di voler determinare la dimensione del campione necessaria per ottenere l’80% di potenza nel distinguere un valore \\(\\theta\\) dalla media ipotizzata \\(\\theta_0\\).\nL’errore standard della differenza \\(\\theta - \\theta_0\\) è dato da:\n\\[\n\\text{s.e.} = \\frac{\\sigma}{\\sqrt{n}}.\n\\]\nPer ottenere l’80% di potenza, vogliamo che la differenza osservata \\(\\theta - \\theta_0\\) sia sufficientemente grande da essere rilevata con il livello di significatività prefissato (ad esempio, 5%).\n\n70.3.2.1 Passaggi algebrici per derivare la formula:\n\nPer una potenza dell’80%, la differenza \\(\\theta - \\theta_0\\) deve essere almeno 2,8 volte l’errore standard, dove il valore \\(2.8\\) è dato dalla somma dei quantili della distribuzione normale per il 95% di confidenza (\\(1.96\\)) e per l’80% di potenza (\\(0.84\\)): \\[\n\\theta - \\theta_0 = 2.8 \\cdot \\frac{\\sigma}{\\sqrt{n}}.\n\\]\nRisolviamo per \\(\\sqrt{n}\\): \\[\n\\sqrt{n} = \\frac{2.8 \\cdot \\sigma}{\\theta - \\theta_0}.\n\\]\nEleviamo al quadrato entrambi i lati: \\[\nn = \\left(\\frac{2.8 \\cdot \\sigma}{\\theta - \\theta_0}\\right)^2.\n\\]\n\nQuesta formula fornisce la dimensione del campione necessaria per ottenere l’80% di potenza, dove \\(2.8\\) rappresenta il valore soglia della distribuzione normale standard.\n\n70.3.2.2 Esempio pratico\nSe vogliamo distinguere \\(\\theta\\) da \\(\\theta_0\\) con \\(\\sigma = 10\\) e una differenza minima rilevabile di \\(\\theta - \\theta_0 = 5\\), possiamo calcolare \\(n\\) come segue:\n\\[\nn = \\left(\\frac{2.8 \\cdot 10}{5}\\right)^2 = \\left(5.6\\right)^2 = 31.36.\n\\]\nArrotondando, servono almeno 32 osservazioni.\n\n70.3.3 Correzione per campioni piccoli e distribuzione t\nPer studi con pochi gradi di libertà, l’incertezza sulla stima di \\(\\sigma\\) aumenta, e la distribuzione t di Student diventa più appropriata. In questi casi, il valore \\(2.8\\) deve essere sostituito con un valore più grande, dipendente dai gradi di libertà, per compensare l’incertezza aggiuntiva.\nAd esempio, per uno studio che confronta due gruppi di 6 pazienti ciascuno, i gradi di libertà sono 10. In R, la somma dei quantili della distribuzione t con 10 gradi di libertà per l’80% di potenza e il 95% di confidenza è \\(3.1\\), quindi \\(2.8\\) viene sostituito da \\(3.1\\) nei calcoli per la potenza dell’80%.\n\n# Gradi di libertà\ndf &lt;- 10\n\n# Calcola il quantile per l'80% di potenza (quindi 0.8) e il 95% di confidenza (quindi 0.975)\nt_value_80 &lt;- qt(0.8, df)\nt_value_95 &lt;- qt(0.975, df)\n\n# Somma dei due quantili\nt_total &lt;- t_value_80 + t_value_95\nt_total\n#&gt; [1] 3.107\n\nEseguendo questo codice in R, otteniamo il valore 3.107, che sostituisce il valore \\(2.8\\) nei calcoli per la potenza dell’80% quando si lavora con piccoli campioni e si utilizza la distribuzione t invece della normale standard.\n\n70.3.4 Nota\nQuesto esempio evidenzia come la distribuzione t tenga conto della maggiore variabilità introdotta dalla stima della deviazione standard in campioni di piccole dimensioni, aumentando leggermente il valore soglia richiesto per la potenza desiderata.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Disegno della ricerca e potere statistico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_sample_size.html#confronto-di-medie",
    "href": "chapters/linear_models/08_sample_size.html#confronto-di-medie",
    "title": "70  Disegno della ricerca e potere statistico",
    "section": "\n70.4 Confronto di Medie",
    "text": "70.4 Confronto di Medie\nEsaminiamo ora il caso del confronto tra le medie di due gruppi indipendenti. Vogliamo determinare la dimensione del campione necessaria per rilevare una differenza significativa \\(\\Delta\\) tra le due medie con una potenza statistica dell’80%.\n\n70.4.1 Errore Standard della Differenza tra Due Medie\nL’errore standard della differenza tra le medie campionarie \\(\\bar{y}_1\\) e \\(\\bar{y}_2\\) è dato da:\n\\[\n\\text{s.e.}(\\bar{y}_1 - \\bar{y}_2) = \\sqrt{\\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}},\n\\]\ndove:\n\n\n\\(\\sigma_1^2\\) e \\(\\sigma_2^2\\) sono le varianze delle popolazioni dei due gruppi,\n\n\\(n_1\\) e \\(n_2\\) sono le dimensioni dei campioni nei due gruppi.\n\n\n70.4.1.1 Caso di Varianze e Dimensioni del Campione Uguali\nSe assumiamo che:\n\nle varianze sono uguali: \\(\\sigma_1 = \\sigma_2 = \\sigma\\),\nle dimensioni dei campioni sono uguali: \\(n_1 = n_2 = n\\),\n\nl’errore standard diventa:\n\n\nSostituiamo le varianze e le dimensioni dei campioni:\n\\[\n\\text{s.e.} = \\sqrt{\\frac{\\sigma^2}{n} + \\frac{\\sigma^2}{n}} = \\sqrt{\\frac{2\\sigma^2}{n}}.\n\\]\n\n\nSemplifichiamo l’espressione:\n\\[\n\\text{s.e.} = \\frac{\\sqrt{2}\\sigma}{\\sqrt{n}}.\n\\]\n\n\n70.4.2 Dimensione del Campione per un Errore Standard Specifico\nSe desideriamo ottenere un errore standard specifico \\(\\text{s.e.}\\), possiamo determinare la dimensione del campione \\(n\\) seguendo questi passaggi:\n\n\nPartiamo dall’espressione dell’errore standard:\n\\[\n\\text{s.e.} = \\frac{\\sqrt{2}\\sigma}{\\sqrt{n}}.\n\\]\n\n\nRisolviamo per \\(\\sqrt{n}\\):\n\\[\n\\sqrt{n} = \\frac{\\sqrt{2}\\sigma}{\\text{s.e.}}.\n\\]\n\n\nEleviamo al quadrato entrambi i membri:\n\\[\nn = \\left( \\frac{\\sqrt{2}\\sigma}{\\text{s.e.}} \\right)^2 = \\frac{2\\sigma^2}{\\text{s.e.}^2}.\n\\]\n\n\n70.4.3 Dimensione del Campione per una Differenza \\(\\Delta\\) con l’80% di Potenza\nPer garantire una potenza dell’80% nel rilevare una differenza \\(\\Delta\\) tra le due medie, seguiamo questi passaggi:\n\n70.4.3.1 Determinazione del Valore Critico\nPer un test bilaterale al livello di significatività del 5%, i valori critici della distribuzione normale standard sono:\n\n\n\\(z_{\\alpha/2} = 1.96\\) (per il 95% di confidenza),\n\n\\(z_{\\text{potenza}} = 0.84\\) (per l’80% di potenza).\n\nLa somma totale è:\n\\[\nz_{\\text{totale}} = z_{\\alpha/2} + z_{\\text{potenza}} = 1.96 + 0.84 = 2.8.\n\\]\n\n70.4.3.2 Relazione tra \\(\\Delta\\) ed Errore Standard\nLa differenza minima rilevabile \\(\\Delta\\) è legata all’errore standard dalla relazione:\n\n\nImpostiamo l’equazione:\n\\[\n\\Delta = z_{\\text{totale}} \\times \\text{s.e.} = 2.8 \\times \\text{s.e.}.\n\\]\n\n\nSostituiamo l’espressione per \\(\\text{s.e.}\\):\n\\[\n\\Delta = 2.8 \\times \\frac{\\sqrt{2}\\sigma}{\\sqrt{n}}.\n\\]\n\n\nCalcoliamo il coefficiente:\n\\[\n2.8 \\times \\sqrt{2} = 2.8 \\times 1.4142 \\approx 3.96.\n\\]\nQuindi:\n\\[\n\\Delta = 3.96 \\times \\frac{\\sigma}{\\sqrt{n}}.\n\\]\n\n\nRisolviamo per \\(\\sqrt{n}\\):\n\\[\n\\sqrt{n} = \\frac{3.96 \\sigma}{\\Delta}.\n\\]\n\n\nEleviamo al quadrato entrambi i membri:\n\\[\nn = \\left( \\frac{3.96 \\sigma}{\\Delta} \\right)^2.\n\\]\n\n\n70.4.4 Formula Finale per la Dimensione del Campione\nLa dimensione del campione necessaria per ciascun gruppo è data da:\n\\[\nn = \\left( \\frac{3.96 \\sigma}{\\Delta} \\right)^2.\n\\]\nPer semplificare i calcoli, possiamo arrotondare \\(3.96\\) a \\(4\\):\n\\[\nn = \\left( \\frac{4 \\sigma}{\\Delta} \\right)^2.\n\\]\nNota Importante: Questa formula si applica quando:\n\n\nLe varianze delle popolazioni sono uguali (\\(\\sigma_1 = \\sigma_2 = \\sigma\\)).\n\nLe dimensioni dei campioni nei due gruppi sono uguali (\\(n_1 = n_2 = n\\)).\n\nIl totale dei campioni è \\(N = 2n\\).\n\n70.4.5 Interpretazione della Formula\n\n\nSe la deviazione standard \\(\\sigma\\) è elevata: C’è maggiore variabilità nei dati, quindi è necessario un campione più grande per rilevare una differenza \\(\\Delta\\) con la stessa potenza.\n\nSe la differenza \\(\\Delta\\) è piccola: Serve un campione più grande per garantire che la differenza sia rilevabile con l’80% di potenza.\n\n70.4.6 Esempio Pratico\nSupponiamo di voler rilevare una differenza \\(\\Delta = 5\\) unità tra due gruppi, con una deviazione standard comune \\(\\sigma = 10\\) unità.\nCalcolo della dimensione del campione per ciascun gruppo:\n\n\nUtilizziamo la formula:\n\\[\nn = \\left( \\frac{4 \\times 10}{5} \\right)^2 = \\left( \\frac{40}{5} \\right)^2 = \\left( 8 \\right)^2 = 64.\n\\]\n\n\nRisultato:\n\n\n64 partecipanti per gruppo.\n\nTotale di 128 partecipanti.\n\n\n\n70.4.7 Caso con Campione Totale Fissato\nSe il campione totale è fissato a \\(n\\), con dimensioni dei gruppi \\(n_1 = n_2 = n/2\\), l’errore standard cambia leggermente.\n\n70.4.7.1 Calcolo dell’Errore Standard\n\n\nSostituiamo \\(n_1 = n_2 = n/2\\) nell’errore standard:\n\\[\n\\text{s.e.} = \\sqrt{\\frac{\\sigma^2}{n/2} + \\frac{\\sigma^2}{n/2}} = \\sqrt{2 \\times \\frac{\\sigma^2}{n/2}}.\n\\]\n\n\nSemplifichiamo l’espressione:\n\\[\n\\text{s.e.} = \\sqrt{\\frac{4\\sigma^2}{n}} = \\frac{2\\sigma}{\\sqrt{n}}.\n\\]\n\n\n70.4.7.2 Dimensione del Campione\n\n\nRelazione tra \\(\\Delta\\) ed errore standard:\n\\[\n\\Delta = 2.8 \\times \\text{s.e.} = 2.8 \\times \\frac{2\\sigma}{\\sqrt{n}} = \\frac{5.6 \\sigma}{\\sqrt{n}}.\n\\]\n\n\nRisolviamo per \\(\\sqrt{n}\\):\n\\[\n\\sqrt{n} = \\frac{5.6 \\sigma}{\\Delta}.\n\\]\n\n\nEleviamo al quadrato:\n\\[\nn = \\left( \\frac{5.6 \\sigma}{\\Delta} \\right)^2.\n\\]\n\n\nIn questo scenario, la dimensione totale del campione è \\(n\\), con \\(n/2\\) partecipanti per ciascun gruppo.\n\n70.4.8 Scelta della Formula Adeguata\n\n\nSe \\(n\\) rappresenta la dimensione del campione per gruppo:\n\\[\nn = \\left( \\frac{4 \\sigma}{\\Delta} \\right)^2.\n\\]\n\n\nSe \\(n\\) rappresenta la dimensione totale del campione:\n\\[\nn = \\left( \\frac{5.6 \\sigma}{\\Delta} \\right)^2.\n\\]\n\n\nAssicurarsi di chiarire come si definisce \\(n\\) è fondamentale per applicare correttamente le formule.\n\n70.4.9 Sintesi\n\n\nVarianze e dimensioni uguali nei due gruppi semplificano i calcoli.\n\nLa dimensione del campione aumenta con l’aumentare della deviazione standard \\(\\sigma\\) e con la diminuzione della differenza \\(\\Delta\\) che si vuole rilevare.\n\nEssere chiari sulla definizione di \\(n\\) (per gruppo o totale) evita errori nei calcoli.\n\n\nEsempio 70.1 Se la differenza \\(\\Delta\\) che vogliamo rilevare è pari a metà della deviazione standard (\\(\\Delta = 0.5\\sigma\\)), allora la formula ci dirà quanti partecipanti sono necessari in ciascun gruppo per rilevare questa differenza con l’80% di potenza. Ad esempio, se \\(\\Delta = 0.5\\sigma\\), la dimensione totale del campione sarà:\n\\[\nn = \\left(\\frac{5.6 \\sigma}{0.5\\sigma}\\right)^2 = (11.2)^2 = 125.44 \\approx 126.\n\\]\nQuindi, servirebbero 63 partecipanti per gruppo.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Disegno della ricerca e potere statistico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_sample_size.html#riflessioni-conclusive",
    "href": "chapters/linear_models/08_sample_size.html#riflessioni-conclusive",
    "title": "70  Disegno della ricerca e potere statistico",
    "section": "\n70.5 Riflessioni Conclusive",
    "text": "70.5 Riflessioni Conclusive\nLa determinazione della dimensione del campione è un passaggio cruciale nella progettazione degli studi, poiché garantisce che le inferenze siano robuste e i risultati affidabili. Questo capitolo ha mostrato come le caratteristiche dei dati, come la deviazione standard e la differenza attesa tra i gruppi, influenzino direttamente la dimensione del campione necessaria per ottenere una potenza statistica adeguata. Inoltre, l’attenzione ai dettagli, come l’uso della distribuzione t per piccoli campioni, sottolinea l’importanza di considerare le fonti di variabilità e incertezza nei calcoli. Pianificare con rigore la dimensione del campione non solo aumenta la probabilità di rilevare effetti significativi, ma contribuisce anche a ridurre il rischio di risultati fuorvianti, migliorando così la qualità complessiva della ricerca scientifica.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Disegno della ricerca e potere statistico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_sample_size.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/08_sample_size.html#informazioni-sullambiente-di-sviluppo",
    "title": "70  Disegno della ricerca e potere statistico",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pointblank_0.12.2 haven_2.5.4       labelled_2.14.1   mice_3.17.0      \n#&gt;  [5] thematic_0.1.6    MetBrewer_0.2.0   ggokabeito_0.1.0  see_0.11.0       \n#&gt;  [9] gridExtra_2.3     patchwork_1.3.0   bayesplot_1.12.0  psych_2.5.3      \n#&gt; [13] scales_1.4.0      markdown_2.0      knitr_1.50        lubridate_1.9.4  \n#&gt; [17] forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4       purrr_1.0.4      \n#&gt; [21] readr_2.1.5       tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.2    \n#&gt; [25] tidyverse_2.0.0   rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1   farver_2.1.2       fastmap_1.2.0     \n#&gt;  [4] pacman_0.5.1       digest_0.6.37      rpart_4.1.24      \n#&gt;  [7] timechange_0.3.0   lifecycle_1.0.4    survival_3.8-3    \n#&gt; [10] magrittr_2.0.3     compiler_4.5.0     rlang_1.1.6       \n#&gt; [13] tools_4.5.0        htmlwidgets_1.6.4  mnormt_2.1.1      \n#&gt; [16] RColorBrewer_1.1-3 withr_3.0.2        nnet_7.3-20       \n#&gt; [19] grid_4.5.0         jomo_2.7-6         iterators_1.0.14  \n#&gt; [22] MASS_7.3-65        cli_3.6.5          rmarkdown_2.29    \n#&gt; [25] reformulas_0.4.1   generics_0.1.4     rstudioapi_0.17.1 \n#&gt; [28] tzdb_0.5.0         minqa_1.2.8        splines_4.5.0     \n#&gt; [31] parallel_4.5.0     vctrs_0.6.5        boot_1.3-31       \n#&gt; [34] glmnet_4.1-8       Matrix_1.7-3       jsonlite_2.0.0    \n#&gt; [37] hms_1.1.3          mitml_0.4-5        foreach_1.5.2     \n#&gt; [40] blastula_0.3.6     glue_1.8.0         nloptr_2.2.1      \n#&gt; [43] pan_1.9            codetools_0.2-20   stringi_1.8.7     \n#&gt; [46] shape_1.4.6.1      gtable_0.3.6       lme4_1.1-37       \n#&gt; [49] pillar_1.10.2      htmltools_0.5.8.1  R6_2.6.1          \n#&gt; [52] Rdpack_2.6.4       rprojroot_2.0.4    evaluate_1.0.3    \n#&gt; [55] lattice_0.22-7     rbibutils_2.3      backports_1.5.0   \n#&gt; [58] broom_1.0.8        Rcpp_1.0.14        nlme_3.1-168      \n#&gt; [61] xfun_0.52          pkgconfig_2.0.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Disegno della ricerca e potere statistico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_sample_size.html#bibliografia",
    "href": "chapters/linear_models/08_sample_size.html#bibliografia",
    "title": "70  Disegno della ricerca e potere statistico",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Disegno della ricerca e potere statistico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html",
    "href": "chapters/linear_models/09_anova_1via.html",
    "title": "71  ANOVA ad una via",
    "section": "",
    "text": "71.1 Preparazione del Notebook\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, posterior, bayestestR, brms, emmeans)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#introduzione",
    "href": "chapters/linear_models/09_anova_1via.html#introduzione",
    "title": "71  ANOVA ad una via",
    "section": "\n71.2 Introduzione",
    "text": "71.2 Introduzione\nNel Capitolo 67 abbiamo visto come rappresentare fattori a due livelli mediante variabili dummy, per includere effetti categoriali all’interno di un modello lineare. In questa sezione estendiamo tale approccio al caso in cui un singolo fattore abbia più di due categorie.\nSupponiamo, ad esempio, di voler analizzare un fattore con tre gruppi. In questo caso possiamo utilizzare due variabili dummy per rappresentare le prime due categorie, e assumere implicitamente la terza come categoria di riferimento. Il modello lineare diventa:\n\\[\nY_i = \\alpha + \\gamma_1 D_{i1} + \\gamma_2 D_{i2} + \\varepsilon_i\n\\tag{71.1}\\]\ndove:\n\n\n\\(\\alpha\\) è l’intercetta del modello,\n\n\\(\\gamma_1\\) e \\(\\gamma_2\\) sono i coefficienti associati alle variabili dummy,\n\n\\(D_{i1}\\) e \\(D_{i2}\\) indicano l’appartenenza dell’osservazione \\(i\\) ai gruppi 1 e 2, rispettivamente,\n\n\\(\\varepsilon_i\\) è l’errore aleatorio.\n\nLa seguente tabella mostra come codificare le dummy per ciascun gruppo:\n\\[\n\\begin{array}{c|cc}\n\\text{Gruppo} & D_{1} & D_{2} \\\\\n\\hline\n1 & 1 & 0 \\\\\n2 & 0 & 1 \\\\\n3 & 0 & 0\n\\end{array}\n\\tag{71.2}\\]\n\n71.2.1 Significato dei parametri\nL’obiettivo è stimare le medie di popolazione per ciascun gruppo, indicate con \\(\\mu_j\\) per il gruppo \\(j\\). Poiché l’errore \\(\\varepsilon\\) ha media zero, possiamo calcolare l’aspettativa del modello per ciascun gruppo:\n\\[\n\\begin{aligned}\n\\text{Gruppo 1: } \\mu_1 &= \\mathbb{E}(Y \\mid D_1 = 1, D_2 = 0) = \\alpha + \\gamma_1 \\\\\n\\text{Gruppo 2: } \\mu_2 &= \\mathbb{E}(Y \\mid D_1 = 0, D_2 = 1) = \\alpha + \\gamma_2 \\\\\n\\text{Gruppo 3: } \\mu_3 &= \\mathbb{E}(Y \\mid D_1 = 0, D_2 = 0) = \\alpha\n\\end{aligned}\n\\tag{71.3}\\]\nQueste espressioni mostrano come i coefficienti del modello siano relativi alla categoria di riferimento, cioè il Gruppo 3. Possiamo dunque esprimere i parametri del modello in funzione delle medie di gruppo:\n\\[\n\\alpha = \\mu_3, \\quad \\gamma_1 = \\mu_1 - \\mu_3, \\quad \\gamma_2 = \\mu_2 - \\mu_3 .\n\\tag{71.4}\\]\nIn sintesi:\n\n\n\\(\\alpha\\) rappresenta la media del gruppo di riferimento (Gruppo 3),\n\n\\(\\gamma_1\\) è la differenza tra la media del Gruppo 1 e quella del Gruppo 3,\n\n\\(\\gamma_2\\) è la differenza tra la media del Gruppo 2 e quella del Gruppo 3.\n\nQuesta struttura rende il modello facilmente interpretabile: i coefficienti delle dummy indicano quanto ciascun gruppo si discosta dalla categoria di riferimento, mentre l’intercetta fornisce direttamente la media di quest’ultima. Questo schema può essere esteso a fattori con un numero arbitrario di categorie.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#simulazione",
    "href": "chapters/linear_models/09_anova_1via.html#simulazione",
    "title": "71  ANOVA ad una via",
    "section": "\n71.3 Simulazione",
    "text": "71.3 Simulazione\nPer illustrare il funzionamento di un modello con un fattore a tre livelli, simuliamo un dataset con tre condizioni sperimentali: controllo, psicoterapia1 e psicoterapia2. Supponiamo che ogni gruppo abbia una diversa media, ma la stessa deviazione standard:\n\nset.seed(123)\n\nn &lt;- 30  # numero di osservazioni per gruppo\n\n# Medie di ciascun gruppo\nmean_control &lt;- 30\nmean_psico1  &lt;- 25\nmean_psico2  &lt;- 20\n\n# Deviazione standard comune\nsd_value &lt;- 5\n\n# Generazione dei dati\ncontrollo     &lt;- rnorm(n, mean_control, sd_value)\npsicoterapia1 &lt;- rnorm(n, mean_psico1,  sd_value)\npsicoterapia2 &lt;- rnorm(n, mean_psico2,  sd_value)\n\n# Creazione del data frame\ndf &lt;- data.frame(\n  condizione = rep(c(\"controllo\", \"psicoterapia1\", \"psicoterapia2\"), each = n),\n  punteggio  = c(controllo, psicoterapia1, psicoterapia2)\n)\n\ndf |&gt; head()\n#&gt;   condizione punteggio\n#&gt; 1  controllo     27.20\n#&gt; 2  controllo     28.85\n#&gt; 3  controllo     37.79\n#&gt; 4  controllo     30.35\n#&gt; 5  controllo     30.65\n#&gt; 6  controllo     38.58\n\n\n71.3.1 Esplorazione dei dati\nVisualizziamo le distribuzioni con un violin plot arricchito da un boxplot:\n\nggplot(df, aes(x = condizione, y = punteggio, fill = condizione)) +\n  geom_violin(trim = FALSE) +\n  geom_boxplot(width = 0.2, outlier.shape = NA) +\n  labs(\n    title = \"Distribuzione dei punteggi di depressione per gruppo\",\n    x = \"Condizione sperimentale\",\n    y = \"Punteggio di depressione\"\n  ) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\nCalcoliamo media e deviazione standard per ogni gruppo:\n\ndf |&gt; \n  group_by(condizione) |&gt; \n  summarize(\n    media = mean(punteggio),\n    sd = sd(punteggio)\n  )\n#&gt; # A tibble: 3 × 3\n#&gt;   condizione    media    sd\n#&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 controllo      29.8  4.91\n#&gt; 2 psicoterapia1  25.9  4.18\n#&gt; 3 psicoterapia2  20.1  4.35",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#codifica-con-variabili-dummy",
    "href": "chapters/linear_models/09_anova_1via.html#codifica-con-variabili-dummy",
    "title": "71  ANOVA ad una via",
    "section": "\n71.4 Codifica con variabili dummy",
    "text": "71.4 Codifica con variabili dummy\nConvertiamo condizione in fattore e definiamo controllo come categoria di riferimento:\n\ndf$condizione &lt;- factor(df$condizione)\ndf$condizione &lt;- relevel(df$condizione, ref = \"controllo\")\ncontrasts(df$condizione)\n#&gt;               psicoterapia1 psicoterapia2\n#&gt; controllo                 0             0\n#&gt; psicoterapia1             1             0\n#&gt; psicoterapia2             0             1\n\nIl modello di regressione con dummy sarà:\n\\[\nY_i = \\beta_0 + \\beta_1 \\cdot \\text{psicoterapia1}_i + \\beta_2 \\cdot \\text{psicoterapia2}_i + \\varepsilon_i,\n\\]\ndove:\n\n\n\\(\\beta_0\\) è la media del gruppo di controllo;\n\n\\(\\beta_1\\) e \\(\\beta_2\\) sono le differenze tra le rispettive psicoterapie e il gruppo di controllo.\n\n\n71.4.1 Stima del modello\nEseguiamo una prima analisi usando il metodo di massima verosimiglianza:\n\nfm1 &lt;- lm(punteggio ~ condizione, data = df)\n\n\nsummary(fm1)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = punteggio ~ condizione, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -11.668  -2.620  -0.183   2.681  10.128 \n#&gt; \n#&gt; Coefficients:\n#&gt;                         Estimate Std. Error t value Pr(&gt;|t|)\n#&gt; (Intercept)               29.764      0.819   36.33  &lt; 2e-16\n#&gt; condizionepsicoterapia1   -3.873      1.159   -3.34   0.0012\n#&gt; condizionepsicoterapia2   -9.642      1.159   -8.32  1.1e-12\n#&gt; \n#&gt; Residual standard error: 4.49 on 87 degrees of freedom\n#&gt; Multiple R-squared:  0.446,  Adjusted R-squared:  0.434 \n#&gt; F-statistic: 35.1 on 2 and 87 DF,  p-value: 6.75e-12\n\nVerifica delle medie e differenze tra gruppi:\n\nout &lt;- tapply(df$punteggio, df$condizione, mean)\nout[2] - out[1]  # psicoterapia1 - controllo\n#&gt; psicoterapia1 \n#&gt;        -3.873\nout[3] - out[1]  # psicoterapia2 - controllo\n#&gt; psicoterapia2 \n#&gt;        -9.642",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#contrasti-personalizzati",
    "href": "chapters/linear_models/09_anova_1via.html#contrasti-personalizzati",
    "title": "71  ANOVA ad una via",
    "section": "\n71.5 Contrasti personalizzati",
    "text": "71.5 Contrasti personalizzati\nL’uso di contrasti personalizzati ci permette di testare ipotesi più specifiche. Ad esempio:\n\n\ncontrasto 1: controllare se la media del gruppo controllo differisce dalla media combinata delle due psicoterapie;\n\ncontrasto 2: confrontare direttamente psicoterapia1 con psicoterapia2.\n\n\n71.5.1 Matrice dei contrasti\n\nmy_contrasts &lt;- matrix(c(\n  0.6667,  0,     # controllo\n -0.3333,  0.5,   # psicoterapia1\n -0.3333, -0.5    # psicoterapia2\n), ncol = 2, byrow = TRUE)\n\ncolnames(my_contrasts) &lt;- c(\"Ctrl_vs_PsicoMean\", \"P1_vs_P2\")\nrownames(my_contrasts) &lt;- c(\"controllo\", \"psicoterapia1\", \"psicoterapia2\")\n\ncontrasts(df$condizione) &lt;- my_contrasts\n\n\nmod_custom &lt;- lm(punteggio ~ condizione, data = df)\n\n\nsummary(mod_custom)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = punteggio ~ condizione, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -11.668  -2.620  -0.183   2.681  10.128 \n#&gt; \n#&gt; Coefficients:\n#&gt;                             Estimate Std. Error t value Pr(&gt;|t|)\n#&gt; (Intercept)                   25.259      0.473   53.40  &lt; 2e-16\n#&gt; condizioneCtrl_vs_PsicoMean    6.758      1.003    6.73  1.7e-09\n#&gt; condizioneP1_vs_P2             5.770      1.159    4.98  3.2e-06\n#&gt; \n#&gt; Residual standard error: 4.49 on 87 degrees of freedom\n#&gt; Multiple R-squared:  0.446,  Adjusted R-squared:  0.434 \n#&gt; F-statistic: 35.1 on 2 and 87 DF,  p-value: 6.75e-12",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#interpretazione-dei-coefficienti",
    "href": "chapters/linear_models/09_anova_1via.html#interpretazione-dei-coefficienti",
    "title": "71  ANOVA ad una via",
    "section": "\n71.6 Interpretazione dei coefficienti",
    "text": "71.6 Interpretazione dei coefficienti\n\n\nIntercetta: non rappresenta più una singola media, ma una combinazione lineare dei gruppi.\n\nCtrl_vs_PsicoMean: confronta la media di controllo con la media combinata delle due psicoterapie.\n\nP1_vs_P2: differenza tra le due psicoterapie.\n\nVerifica manuale:\n\n# Controllo - media delle psicoterapie\nout[1] - (out[2] + out[3]) / 2\n#&gt; controllo \n#&gt;     6.758\n\n\n# Psicoterapia1 - Psicoterapia2\nout[2] - out[3]\n#&gt; psicoterapia1 \n#&gt;          5.77",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#uso-del-pacchetto-emmeans",
    "href": "chapters/linear_models/09_anova_1via.html#uso-del-pacchetto-emmeans",
    "title": "71  ANOVA ad una via",
    "section": "\n71.7 Uso del pacchetto emmeans\n",
    "text": "71.7 Uso del pacchetto emmeans\n\nIl pacchetto emmeans consente di ottenere gli stessi risultati in modo più diretto e modulare.\n\n71.7.1 Stima con brms\n\nUsiamo ora emmeans con brms:\n\nmod &lt;- brm(punteggio ~ condizione, data = df, backend = \"cmdstanr\")\n\n\nsummary(mod)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: punteggio ~ condizione \n#&gt;    Data: df (Number of observations: 90) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;                             Estimate Est.Error l-95% CI u-95% CI Rhat\n#&gt; Intercept                      25.26      0.48    24.33    26.15 1.00\n#&gt; condizioneCtrl_vs_PsicoMean     6.78      1.04     4.73     8.85 1.00\n#&gt; condizioneP1_vs_P2              5.76      1.16     3.49     8.08 1.00\n#&gt;                             Bulk_ESS Tail_ESS\n#&gt; Intercept                       4321     2937\n#&gt; condizioneCtrl_vs_PsicoMean     4260     2964\n#&gt; condizioneP1_vs_P2              4598     2785\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     4.54      0.34     3.93     5.26 1.00     4287     3279\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n71.7.2 Calcolo delle medie marginali\n\nem &lt;- emmeans(mod, specs = \"condizione\")\nem\n#&gt;  condizione    emmean lower.HPD upper.HPD\n#&gt;  controllo       29.8      28.1      31.4\n#&gt;  psicoterapia1   25.9      24.3      27.5\n#&gt;  psicoterapia2   20.1      18.4      21.7\n#&gt; \n#&gt; Point estimate displayed: median \n#&gt; HPD interval probability: 0.95\n\n\n71.7.3 Confronti tra gruppi\n\npairs(em)  # confronti a coppie\n#&gt;  contrast                      estimate lower.HPD upper.HPD\n#&gt;  controllo - psicoterapia1         3.90      1.70      6.21\n#&gt;  controllo - psicoterapia2         9.65      7.31     12.03\n#&gt;  psicoterapia1 - psicoterapia2     5.75      3.57      8.14\n#&gt; \n#&gt; Point estimate displayed: median \n#&gt; HPD interval probability: 0.95\n\n\n71.7.4 Contrasti personalizzati con emmeans\n\n\nmy_list &lt;- list(\n  \"Ctrl_vs_PsicoMean\" = c(\n    \"controllo\" = 1, \"psicoterapia1\" = -0.5, \"psicoterapia2\" = -0.5\n  ),\n  \"P1_vs_P2\" = c(\n    \"controllo\" = 0, \"psicoterapia1\" = 1, \"psicoterapia2\" = -1\n  )\n)\n\n\ncontrast(em, method = my_list)\n#&gt;  contrast          estimate lower.HPD upper.HPD\n#&gt;  Ctrl_vs_PsicoMean     6.77      4.77      8.88\n#&gt;  P1_vs_P2              5.75      3.57      8.14\n#&gt; \n#&gt; Point estimate displayed: median \n#&gt; HPD interval probability: 0.95\n\n\n# Visualizzazione\nplot(em)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#riflessioni-conclusive",
    "href": "chapters/linear_models/09_anova_1via.html#riflessioni-conclusive",
    "title": "71  ANOVA ad una via",
    "section": "\n71.8 Riflessioni Conclusive",
    "text": "71.8 Riflessioni Conclusive\nUn’ANOVA a una via può essere vista come un caso speciale di regressione lineare, applicato a un fattore con più di due livelli. L’elemento più informativo dell’analisi non è tanto la verifica globale dell’effetto del fattore, ma l’esplorazione mirata di contrasti specifici tra le medie.\nLa possibilità di definire contrasti personalizzati, come quelli che confrontano un singolo gruppo con la media degli altri, oppure due gruppi tra loro, permette di rispondere a domande teoriche mirate. Questo approccio si integra perfettamente con il framework bayesiano, in cui i contrasti possono essere interpretati in termini di probabilità a posteriori, anziché solo di significatività.\nIl pacchetto emmeans rende questo processo ancora più accessibile, offrendo strumenti per:\n\ncalcolare medie marginali stimate;\nspecificare contrasti personalizzati;\nottenere intervalli di confidenza (o credibilità) e p-value corretti.\n\nIn definitiva, l’uso combinato di regressione, contrasti e strumenti come emmeans o brms fornisce un approccio potente, flessibile e interpretabile per analizzare l’effetto di fattori categoriali in modelli lineari.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/09_anova_1via.html#informazioni-sullambiente-di-sviluppo",
    "title": "71  ANOVA ad una via",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] emmeans_1.11.1    brms_2.22.0       Rcpp_1.0.14       bayestestR_0.15.3\n#&gt;  [5] posterior_1.6.1   cmdstanr_0.9.0    thematic_0.1.6    MetBrewer_0.2.0  \n#&gt;  [9] ggokabeito_0.1.0  see_0.11.0        gridExtra_2.3     patchwork_1.3.0  \n#&gt; [13] bayesplot_1.12.0  psych_2.5.3       scales_1.4.0      markdown_2.0     \n#&gt; [17] knitr_1.50        lubridate_1.9.4   forcats_1.0.0     stringr_1.5.1    \n#&gt; [21] dplyr_1.1.4       purrr_1.0.4       readr_2.1.5       tidyr_1.3.1      \n#&gt; [25] tibble_3.2.1      ggplot2_3.5.2     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [29] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1     farver_2.1.2         loo_2.8.0           \n#&gt;  [4] fastmap_1.2.0        tensorA_0.36.2.1     pacman_0.5.1        \n#&gt;  [7] digest_0.6.37        timechange_0.3.0     estimability_1.5.1  \n#&gt; [10] lifecycle_1.0.4      StanHeaders_2.32.10  processx_3.8.6      \n#&gt; [13] magrittr_2.0.3       compiler_4.5.0       rlang_1.1.6         \n#&gt; [16] tools_4.5.0          utf8_1.2.5           yaml_2.3.10         \n#&gt; [19] data.table_1.17.2    labeling_0.4.3       bridgesampling_1.1-2\n#&gt; [22] htmlwidgets_1.6.4    curl_6.2.2           pkgbuild_1.4.7      \n#&gt; [25] mnormt_2.1.1         plyr_1.8.9           RColorBrewer_1.1-3  \n#&gt; [28] abind_1.4-8          withr_3.0.2          grid_4.5.0          \n#&gt; [31] stats4_4.5.0         colorspace_2.1-1     xtable_1.8-4        \n#&gt; [34] inline_0.3.21        insight_1.2.0        cli_3.6.5           \n#&gt; [37] mvtnorm_1.3-3        rmarkdown_2.29       generics_0.1.4      \n#&gt; [40] RcppParallel_5.1.10  rstudioapi_0.17.1    reshape2_1.4.4      \n#&gt; [43] tzdb_0.5.0           rstan_2.32.7         parallel_4.5.0      \n#&gt; [46] matrixStats_1.5.0    vctrs_0.6.5          V8_6.0.3            \n#&gt; [49] Matrix_1.7-3         jsonlite_2.0.0       hms_1.1.3           \n#&gt; [52] glue_1.8.0           codetools_0.2-20     ps_1.9.1            \n#&gt; [55] distributional_0.5.0 stringi_1.8.7        gtable_0.3.6        \n#&gt; [58] QuickJSR_1.7.0       pillar_1.10.2        htmltools_0.5.8.1   \n#&gt; [61] Brobdingnag_1.2-9    R6_2.6.1             rprojroot_2.0.4     \n#&gt; [64] evaluate_1.0.3       lattice_0.22-7       backports_1.5.0     \n#&gt; [67] rstantools_2.4.0     coda_0.19-4.1        nlme_3.1-168        \n#&gt; [70] checkmate_2.3.2      xfun_0.52            pkgconfig_2.0.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#bibliografia",
    "href": "chapters/linear_models/09_anova_1via.html#bibliografia",
    "title": "71  ANOVA ad una via",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_2vie.html",
    "href": "chapters/linear_models/10_anova_2vie.html",
    "title": "72  ANOVA ad due vie",
    "section": "",
    "text": "72.1 Introduzione\nL’ANOVA a due vie estende il modello dell’ANOVA a una via alla situazione in cui la variabile dipendente è influenzata da due fattori distinti, ciascuno con due o più livelli. Questa estensione consente di analizzare non solo gli effetti principali di ciascun fattore, ma anche l’interazione tra i due.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_2vie.html#introduzione",
    "href": "chapters/linear_models/10_anova_2vie.html#introduzione",
    "title": "72  ANOVA ad due vie",
    "section": "",
    "text": "72.1.1 Medie di popolazione in una classificazione a due vie\nSupponiamo di conoscere le medie di popolazione per ciascuna combinazione dei livelli dei due fattori. La struttura può essere rappresentata in una tabella come la seguente:\n\n\n\n\n\n\n\n\n\n\n\n\\(C_1\\)\n\\(C_2\\)\n\\(\\dots\\)\n\\(C_c\\)\nMedia riga\n\n\n\n\\(R_1\\)\n\\(\\mu_{11}\\)\n\\(\\mu_{12}\\)\n\\(\\dots\\)\n\\(\\mu_{1c}\\)\n\\(\\mu_{1\\cdot}\\)\n\n\n\\(R_2\\)\n\\(\\mu_{21}\\)\n\\(\\mu_{22}\\)\n\\(\\dots\\)\n\\(\\mu_{2c}\\)\n\\(\\mu_{2\\cdot}\\)\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\ddots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\\(R_r\\)\n\\(\\mu_{r1}\\)\n\\(\\mu_{r2}\\)\n\\(\\dots\\)\n\\(\\mu_{rc}\\)\n\\(\\mu_{r\\cdot}\\)\n\n\nMedia colonna\n\\(\\mu_{\\cdot 1}\\)\n\\(\\mu_{\\cdot 2}\\)\n\\(\\dots\\)\n\\(\\mu_{\\cdot c}\\)\n\\(\\mu_{\\cdot\\cdot}\\)\n\n\n\ndove:\n\n\n\\(µ_{jk}\\) è la media della cella per il livello \\(j\\) del fattore R e \\(k\\) del fattore C.\n\n\\(µ_{j:}\\) è la media marginale per la riga \\(j\\).\n\n\\(µ_{:k}\\) è la media marginale per la colonna \\(k\\).\n\n\\(µ_{::}\\) è la media complessiva.\n\n72.1.2 Effetti principali e interazione\nSe non c’è interazione tra i due fattori, la differenza tra livelli di un fattore è costante a prescindere dal livello dell’altro fattore. In altre parole, le differenze tra medie di cella si riflettono esattamente nelle differenze tra le medie marginali.\nAd esempio, se il fattore R non interagisce con il fattore C, allora:\n\\[\nµ_{j1} - µ_{j'1} = µ_{j2} - µ_{j'2} = ... = µ_{j:} - µ_{j':}\n\\]\nQuando i profili delle medie sono paralleli, l’assenza di interazione è facilmente visibile. L’interazione si manifesta quando le differenze tra livelli di un fattore variano al variare dell’altro fattore.\nL’interazione è simmetrica: se R interagisce con C, allora C interagisce con R. Se invece non vi è interazione, gli effetti principali dei fattori corrispondono alle differenze tra le rispettive medie marginali.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_2vie.html#simulazione",
    "href": "chapters/linear_models/10_anova_2vie.html#simulazione",
    "title": "72  ANOVA ad due vie",
    "section": "\n72.2 Simulazione",
    "text": "72.2 Simulazione\nSimuliamo ora un dataset che rispecchi una struttura a due vie. Consideriamo:\n\nfattore 1: condizione (controllo, psicoterapia1, psicoterapia2)\nfattore 2: gravita (molto_gravi, poco_gravi)\n\nImpostiamo le medie di cella in modo che riflettano sia effetti principali sia un’interazione.\n\nset.seed(123)\nn &lt;- 30\ncondizione &lt;- c(\"controllo\", \"psicoterapia1\", \"psicoterapia2\")\ngravita &lt;- c(\"molto_gravi\", \"poco_gravi\")\nsd_value &lt;- 5\n\nmean_table &lt;- matrix(\n  c(30, 25, 20,\n    25, 20, 15),\n  nrow = 2, byrow = TRUE\n)\n\ndf &lt;- data.frame()\n\nfor (i in seq_along(gravita)) {\n  for (j in seq_along(condizione)) {\n    media &lt;- mean_table[i, j]\n    dati &lt;- rnorm(n, mean = media, sd = sd_value)\n    df &lt;- rbind(df, data.frame(\n      gravita = gravita[i],\n      condizione = condizione[j],\n      punteggio = dati\n    ))\n  }\n}\n\nVisualizziamo i dati:\n\nggplot(df, aes(x = condizione, y = punteggio, fill = gravita)) +\n  geom_boxplot(position = position_dodge()) +\n  labs(title = \"Distribuzione dei punteggi per gravita e condizione\")",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_2vie.html#modellazione-bayesiana",
    "href": "chapters/linear_models/10_anova_2vie.html#modellazione-bayesiana",
    "title": "72  ANOVA ad due vie",
    "section": "\n72.3 Modellazione Bayesiana",
    "text": "72.3 Modellazione Bayesiana\nAdattiamo ai dati un modello che includa interazione:\n\nmod &lt;- brm(punteggio ~ gravita * condizione, data = df, backend = \"cmdstanr\")\n\nEsploriamo gli effetti condizionati:\n\nconditional_effects(mod, \"condizione:gravita\")",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_2vie.html#confronto-tra-modelli",
    "href": "chapters/linear_models/10_anova_2vie.html#confronto-tra-modelli",
    "title": "72  ANOVA ad due vie",
    "section": "\n72.4 Confronto tra Modelli",
    "text": "72.4 Confronto tra Modelli\nConfrontiamo due modelli:\n\n\nmod: con interazione\n\nmod1: solo con effetti principali\n\n\nmod1 &lt;- brm(punteggio ~ gravita + condizione, data = df, backend = \"cmdstanr\")\n\n\n72.4.1 LOO (Leave-One-Out Cross Validation)\n\nloo_mod  &lt;- loo(mod)\nloo_mod1 &lt;- loo(mod1)\nloo_compare(loo_mod, loo_mod1)\n#&gt;      elpd_diff se_diff\n#&gt; mod1  0.0       0.0   \n#&gt; mod  -0.7       1.5\n\nInterpretazione:\n\nse elpd_diff è piccolo rispetto a se_diff, la differenza non è sostanziale;\nil modello più semplice è preferibile se non vi è evidenza chiara a favore dell’interazione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_2vie.html#conclusione",
    "href": "chapters/linear_models/10_anova_2vie.html#conclusione",
    "title": "72  ANOVA ad due vie",
    "section": "\n72.5 Conclusione",
    "text": "72.5 Conclusione\nL’ANOVA a due vie permette di esaminare sia gli effetti separati di due fattori sia la loro interazione. La modellazione bayesiana, combinata con il confronto tramite LOO, offre un approccio potente per valutare quale struttura descrive meglio i dati. Se l’interazione non migliora la predizione in modo credibile, è preferibile adottare il modello più parsimonioso.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_2vie.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/10_anova_2vie.html#informazioni-sullambiente-di-sviluppo",
    "title": "72  ANOVA ad due vie",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] bridgesampling_1.1-2 loo_2.8.0            emmeans_1.11.1      \n#&gt;  [4] brms_2.22.0          Rcpp_1.0.14          bayestestR_0.15.3   \n#&gt;  [7] posterior_1.6.1      cmdstanr_0.9.0       thematic_0.1.6      \n#&gt; [10] MetBrewer_0.2.0      ggokabeito_0.1.0     see_0.11.0          \n#&gt; [13] gridExtra_2.3        patchwork_1.3.0      bayesplot_1.12.0    \n#&gt; [16] psych_2.5.3          scales_1.4.0         markdown_2.0        \n#&gt; [19] knitr_1.50           lubridate_1.9.4      forcats_1.0.0       \n#&gt; [22] stringr_1.5.1        dplyr_1.1.4          purrr_1.0.4         \n#&gt; [25] readr_2.1.5          tidyr_1.3.1          tibble_3.2.1        \n#&gt; [28] ggplot2_3.5.2        tidyverse_2.0.0      rio_1.2.3           \n#&gt; [31] here_1.0.1          \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1     farver_2.1.2         fastmap_1.2.0       \n#&gt;  [4] tensorA_0.36.2.1     pacman_0.5.1         digest_0.6.37       \n#&gt;  [7] timechange_0.3.0     estimability_1.5.1   lifecycle_1.0.4     \n#&gt; [10] StanHeaders_2.32.10  processx_3.8.6       magrittr_2.0.3      \n#&gt; [13] compiler_4.5.0       rlang_1.1.6          tools_4.5.0         \n#&gt; [16] yaml_2.3.10          data.table_1.17.2    labeling_0.4.3      \n#&gt; [19] htmlwidgets_1.6.4    curl_6.2.2           pkgbuild_1.4.7      \n#&gt; [22] mnormt_2.1.1         RColorBrewer_1.1-3   abind_1.4-8         \n#&gt; [25] withr_3.0.2          grid_4.5.0           stats4_4.5.0        \n#&gt; [28] colorspace_2.1-1     xtable_1.8-4         inline_0.3.21       \n#&gt; [31] insight_1.2.0        cli_3.6.5            mvtnorm_1.3-3       \n#&gt; [34] rmarkdown_2.29       generics_0.1.4       RcppParallel_5.1.10 \n#&gt; [37] rstudioapi_0.17.1    tzdb_0.5.0           rstan_2.32.7        \n#&gt; [40] parallel_4.5.0       matrixStats_1.5.0    vctrs_0.6.5         \n#&gt; [43] V8_6.0.3             Matrix_1.7-3         jsonlite_2.0.0      \n#&gt; [46] hms_1.1.3            glue_1.8.0           codetools_0.2-20    \n#&gt; [49] ps_1.9.1             distributional_0.5.0 stringi_1.8.7       \n#&gt; [52] gtable_0.3.6         QuickJSR_1.7.0       pillar_1.10.2       \n#&gt; [55] htmltools_0.5.8.1    Brobdingnag_1.2-9    R6_2.6.1            \n#&gt; [58] rprojroot_2.0.4      evaluate_1.0.3       lattice_0.22-7      \n#&gt; [61] backports_1.5.0      rstantools_2.4.0     coda_0.19-4.1       \n#&gt; [64] nlme_3.1-168         checkmate_2.3.2      xfun_0.52           \n#&gt; [67] pkgconfig_2.0.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_2vie.html#bibliografia",
    "href": "chapters/linear_models/10_anova_2vie.html#bibliografia",
    "title": "72  ANOVA ad due vie",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_one_proportion.html",
    "href": "chapters/linear_models/11_one_proportion.html",
    "title": "73  Inferenza sulle proporzioni",
    "section": "",
    "text": "73.1 Introduzione\nSpesso ci troviamo ad affrontare la necessità di confrontare due gruppi di dati. Mentre nei capitoli precedenti abbiamo considerato il contronto tra le medie di due gruppi indipendenti, nel caso presente ci concentreremo sul confronto tra le proporzioni di due gruppi indipendenti. Per esempio, potrebbe interessarci sapere se la proporzione di un gruppo è maggiore o diversa rispetto a quella di un altro gruppo. Come in precedenza, per effettuare tale confronto, è fondamentale utilizzare un modello statistico, poiché le vere differenze tra i gruppi sono spesso accompagnate da rumore di misurazione o fluttuazioni casuali del fenomeno in esame. Questo rende difficile trarre conclusioni basandosi unicamente sulle differenze calcolate dai dati osservati.\nAnche nel caso delle proporzioni, il metodo tradizionale per confrontare statisticamente due o più gruppi consiste nell’utilizzare un test di ipotesi. Questo approccio prevede la definizione di un’ipotesi nulla, che tipicamente afferma l’assenza di differenze tra i gruppi, e l’uso di una statistica test per valutare se i dati osservati sono compatibili con tale ipotesi. Se la statistica test supera una soglia prestabilita, l’ipotesi nulla viene rifiutata, suggerendo che esiste una differenza significativa tra i gruppi.\nTuttavia, i test di ipotesi presentano diverse criticità, come vedremo in seguito. Un approccio alternativo e più informativo è quello basato sulla stima anziché sul test dell’ipotesi nulla, fondato sulla probabilità bayesiana piuttosto che su quella frequentista. In questo caso, l’obiettivo non è semplicemente verificare se esiste una differenza tra i gruppi, ma stimare quanto siano effettivamente diversi. Questo metodo è intrinsecamente più informativo, poiché fornisce una stima diretta della differenza tra i gruppi, accompagnata da una misura dell’incertezza associata. Tale incertezza riflette sia la nostra limitata conoscenza dei parametri del modello (incertezza epistemica) sia la variabilità intrinseca del sistema (incertezza aleatoria).\nIn sintesi, mentre i test di ipotesi si concentrano sul rigetto o meno di un’ipotesi nulla, l’approccio basato sulla stima offre una visione più completa e utile, permettendo di quantificare direttamente la differenza tra i gruppi e di valutare l’incertezza associata a tale stima. Questo rende l’analisi più adatta a supportare decisioni informate e basate sui dati.\nIn questo capitolo approfondiremo l’analisi bayesiana per il confronto tra due proporzioni, utilizzando il pacchetto brms in R. L’approccio bayesiano permette di ottenere una descrizione completa della distribuzione a posteriori del parametro di interesse, fornendo informazioni dettagliate sulla sua incertezza e variabilità, oltre a misure intuitive come intervalli di credibilità e probabilità dirette (es. la probabilità che la proporzione del gruppo A sia maggiore di quella del gruppo B).\nPer illustrare i vantaggi dell’approccio bayesiano, confronteremo i risultati con quelli ottenuti tramite l’analisi frequentista tradizionale. Per facilitare l’apprendimento, inizieremo con un caso più semplice: l’inferenza su una singola proporzione. Questo ci permetterà di familiarizzarci con i concetti fondamentali prima di estenderli al confronto tra due gruppi.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>Inferenza sulle proporzioni</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_one_proportion.html#inferenza-su-una-proporzione",
    "href": "chapters/linear_models/11_one_proportion.html#inferenza-su-una-proporzione",
    "title": "73  Inferenza sulle proporzioni",
    "section": "\n73.2 Inferenza su Una Proporzione",
    "text": "73.2 Inferenza su Una Proporzione\n\n73.2.1 Contesto e Dati\nCome esempio per l’inferenza su una proporzione, utilizzeremo i dati dello studio di Brückner & Bearman (2005), discussi anche da Wagenmakers et al. (2010). Nell’articolo “After the promise: the STD consequences of adolescent virginity pledges”, Brückner & Bearman (2005) analizzano una serie di interviste condotte nell’ambito del National Longitudinal Study of Adolescent Health (Add Health). Lo studio si concentra sul comportamento sessuale di adolescenti, di età compresa tra 18 e 24 anni, che hanno fatto un “virginity pledge”, ovvero una promessa pubblica o scritta di rimanere vergini fino al matrimonio. Studi scientifici indicano che il comportamento sessuale di questi adolescenti non sia statisticamente diverso da quello di chi non ha fatto tale promessa, con l’unica eccezione che i “pledgers” hanno una minore probabilità di utilizzare il preservativo durante il primo rapporto sessuale.\nI dati rilevanti per la nostra analisi sono i seguenti:\n\nsu 777 adolescenti che hanno fatto il “virginity pledge”, 424 (54.6%) hanno dichiarato di aver usato il preservativo durante il primo rapporto sessuale;\nsu 9072 adolescenti che non hanno fatto la promessa, 5416 (59.7%) hanno dichiarato di aver usato il preservativo.\n\n73.2.2 Obiettivo dell’Analisi\nNella prima analisi, ci concentreremo sul campione di adolescenti che hanno fatto il “virginity pledge”. Ci chiediamo se sia credibile pensare che questi adolescenti tendano ad avere un rapporto protetto, nel loro primo rapporto sessuale, in una proporzione minore di quella che ci si potrebbe aspettare in caso di casualità (ovvero, una proporzione di 0.5).\n\n73.2.3 Analisi Frequentista\nIniziamo con un test frequentista usando la funzione prop.test() per confrontare la proporzione osservata con il valore di riferimento 0.5.\n\nprop_test_freq_vol &lt;- prop.test(\n  x = 424,\n  n = 777,\n  p = 0.5\n)\n\ntidy(prop_test_freq_vol)\n#&gt; # A tibble: 1 × 8\n#&gt;   estimate statistic p.value parameter conf.low conf.high\n#&gt;      &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1    0.546      6.31  0.0120         1    0.510     0.581\n#&gt;   method                                               alternative\n#&gt;   &lt;chr&gt;                                                &lt;chr&gt;      \n#&gt; 1 1-sample proportions test with continuity correction two.sided\n\nL’intervallo di confidenza frequentista non include il valore di riferimento 0.5, quindi, in base a questa analisi, possiamo concludere che la proporzione osservata (0.546) sia maggiore del valore atteso in caso di casualità (0.5).\n\n73.2.4 Approccio Bayesiano con brms\n\nSe utilizziamo dei prior non informativi, ci aspettiamo di giungere alla stessa conclusione anche con un approccio bayesiano. Tuttavia, l’approccio bayesiano ci permette di ottenere una distribuzione completa della probabilità a posteriori del parametro di interesse, offrendo una visione più ricca e flessibile rispetto all’approccio frequentista.\n\n73.2.4.1 Preparazione dei Dati\nIniziamo creando un data frame che sarà utilizzato con la funzione brm().\n\npledge_binomial_df &lt;- tibble(\n  n_yes = 424,\n  n_total = 777\n)\n\n# tiny data\npledge_binomial_df\n#&gt; # A tibble: 1 × 2\n#&gt;   n_yes n_total\n#&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1   424     777\n\n\n73.2.4.2 Definizione delle Opzioni del Campionatore\nImpostiamo alcune opzioni globali per il campionatore Stan.\n\n# Set some global Stan options\nCHAINS &lt;- 4\nITER &lt;- 2000\nWARMUP &lt;- 1000\nBAYES_SEED &lt;- 1234\n\n\n73.2.4.3 Modello Bayesiano\nUtilizziamo un modello di regressione con una funzione link binomiale. Questo significa che stimeremo la proporzione \\(p\\) con un modello di regressione beta-binomiale bayesiano utilizzando brms. Useremo un prior non informativo \\(\\mathcal{Beta}(1, 1)\\). Questo è un modello solo con intercetta, senza altre covariate, poiché siamo interessati solo alla proporzione sottostante, senza condizionarla su altre variabili.\nIl modello può essere rappresentato come segue:\n\\[\n\\begin{aligned}\ny_{\\text{condom\\_use}} &\\sim \\mathcal{Binomial}(n, \\pi) \\\\\n\\pi &= \\beta_0 \\\\\n\\beta_0 &\\sim \\mathcal{Beta}(1, 1)\n\\end{aligned}\n\\]\nEseguiamo l’analisi bayesiana.\n\nmodel_pledge_binomial &lt;- brm(\n  n_yes | trials(n_total) ~ 1,\n  data = pledge_binomial_df,\n  family = binomial(link = \"identity\"),\n  prior = c(prior(beta(1, 1), class = \"Intercept\", lb = 0, ub = 1)),\n  chains = CHAINS, warmup = WARMUP, iter = ITER, seed = BAYES_SEED,\n  refresh = 0,\n  backend = \"cmdstanr\"\n)\n#&gt; Running MCMC with 4 sequential chains...\n#&gt; \n#&gt; Chain 1 finished in 0.0 seconds.\n#&gt; Chain 2 finished in 0.0 seconds.\n#&gt; Chain 3 finished in 0.0 seconds.\n#&gt; Chain 4 finished in 0.0 seconds.\n#&gt; \n#&gt; All 4 chains finished successfully.\n#&gt; Mean chain execution time: 0.0 seconds.\n#&gt; Total execution time: 0.5 seconds.\n\n\n73.2.4.4 Risultati del Modello\nPoiché questo è un modello di regressione, si comporta come qualsiasi altro modello brms. Il coefficiente per l’intercetta rappresenta la proporzione stimata di adolescenti tra i 18 e i 24 anni che hanno usato il preservativo durante il primo rapporto sessuale nel campione.\n\nsummary(model_pledge_binomial)\n#&gt;  Family: binomial \n#&gt;   Links: mu = identity \n#&gt; Formula: n_yes | trials(n_total) ~ 1 \n#&gt;    Data: pledge_binomial_df (Number of observations: 1) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept     0.55      0.02     0.51     0.58 1.00     1457     1756\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nSi noti come l’intervallo di credibilità al 95% riproduce l’intervallo frequentista calcolato in precedenza.\n\n73.2.5 Confronto tra i Due Approcci\nConfrontiamo ora i risultati ottenuti dai due approcci. L’analisi frequentista ha mostrato che la proporzione osservata (0.546) è significativamente maggiore del valore di riferimento 0.5. L’approccio bayesiano conferma questa conclusione, fornendo una distribuzione completa della probabilità a posteriori per la proporzione π. Uno dei vantaggi dell’approccio bayesiano è la possibilità di incorporare informazioni a priori, se disponibili, migliorando così la robustezza delle inferenze. Inoltre, l’intervallo di credibilità bayesiano fornisce una descrizione più completa della distribuzione dei parametri, consentendo una migliore interpretazione dei risultati.\n\n73.2.6 Modello Beta-Binomiale e Soluzione Analitica\nIn questo contesto, il problema può essere modellato utilizzando una distribuzione beta-binomiale, per la quale esiste una soluzione analitica per la distribuzione a posteriori. Il modello beta-binomiale è particolarmente adatto quando si lavora con dati binomiali (ad esempio, successi e fallimenti) e si desidera incorporare una distribuzione a priori coniugata per la proporzione \\(p\\).\n\n73.2.6.1 Contestualizzazione del Modello\nPer il gruppo “pledgers”, abbiamo \\(y_1\\) successi su \\(n_1\\) prove. Se assumiamo una distribuzione a priori Beta(\\(\\alpha\\), \\(\\beta\\)), la distribuzione a posteriori per la proporzione \\(p_1\\) sarà anch’essa una distribuzione Beta, data da:\n\\[\np_1 \\mid y_1, n_1 \\sim \\mathcal{Beta}(\\alpha + y_1, \\beta + n_1 - y_1).\n\\]\nNel nostro caso specifico, scegliamo una prior non informativa \\(\\mathcal{Beta}(1, 1)\\), che equivale a una distribuzione uniforme sull’intervallo [0, 1]. Questa scelta riflette l’assenza di informazioni pregresse sulla proporzione \\(p_1\\). Pertanto, la distribuzione a posteriori per il gruppo “pledgers” diventa:\n\\[\np_1 \\mid y_1, n_1 \\sim \\mathcal{Beta}(1 + 424, 1 + 777 - 424) = \\mathcal{Beta}(425, 354).\n\\]\n\n73.2.6.2 Calcolo dell’Intervallo di Credibilità\nUtilizziamo R per calcolare l’intervallo di credibilità al 95% basato sulla distribuzione a posteriori derivata analiticamente.\n\n# Parametri della distribuzione Beta\na_post &lt;- 425  # Parametro alpha\nb_post &lt;- 354  # Parametro beta\n\n# Calcolo dell'intervallo centrale al 95%\ncredibility_interval &lt;- qbeta(c(0.025, 0.975), shape1 = a_post, shape2 = b_post)\nprint(credibility_interval)\n#&gt; [1] 0.5105 0.5804\n\nIl risultato ottenuto dall’analisi bayesiana analitica replica quello ottenuto tramite il modello brm() implementato in precedenza. Questo confronto tra approcci dimostra la coerenza tra le tecniche frequentista, bayesiana numerica e bayesiana analitica.\n\n73.2.7 Discussione e Confronto tra Approcci\nL’utilizzo della distribuzione beta-binomiale e della soluzione analitica offre diversi vantaggi:\n\n\nSemplicità: La soluzione analitica è spesso più semplice da implementare rispetto ai metodi numerici, come quelli utilizzati in brms.\n\nVelocità: I calcoli sono generalmente più veloci poiché non richiedono iterazioni o campionamenti.\n\nInterpretazione: L’uso di distribuzioni coniugate facilita l’interpretazione dei risultati, fornendo direttamente la distribuzione a posteriori senza bisogno di complessi algoritmi di inferenza.\n\nTuttavia, l’approccio bayesiano numerico tramite brms presenta anche vantaggi significativi:\n\n\nFlessibilità: Può gestire modelli più complessi e includere covariate multiple.\n\nPriori informativi: Permette di incorporare facilmente informazioni a priori, se disponibili.\n\nEstensioni: Facilita l’estensione del modello a casi più complessi, come il confronto tra proporzioni di due gruppi.\n\n\n73.2.7.1 Analisi della Distribuzione a Posteriori\nEssendo un’analisi bayesiana, possiamo lavorare con l’intera distribuzione a posteriori e calcolare direttamente l’estimando, come la differenza tra la proporzione campionaria e la proporzione di riferimento (0.5).\n\npledge_draws &lt;- model_pledge_binomial |&gt; \n  spread_draws(b_Intercept) |&gt; \n  mutate(diff = b_Intercept - 0.5)\n\nVisualizziamo la distribuzione a posteriori della proporzione.\n\np1 &lt;- ggplot(pledge_draws, aes(x = b_Intercept, y = \"Age 18–24\")) + \n  stat_halfeye(fill = \"gray\") +\n  geom_vline(xintercept = 0.5) +\n  scale_x_continuous(labels = label_percent()) +\n  coord_cartesian(ylim = c(1.5, 1.5)) +\n  labs(x = \"Proportion used a condom at first sex\", y = NULL)\np1\n\n\n\n\n\n\n\nIl valore di riferimento (0.5) non è incluso nella distribuzione a posteriori, il che significa che la differenza tra la proporzione campionaria e la proporzione di riferimento non include lo zero, con un livello di credibilità del 95%. Possiamo quindi concludere, con un livello soggettivo di credibilità del 95%, che l’uso del preservativo durante il primo rapporto sessuale sia maggiore del caso, per gli adolescenti che hanno fatto il “virginity pledge”.\n\n73.2.8 La Regione di Equivalenza Pratica (ROPE)\nL’analisi precedente confronta la proporzione osservata con un singolo valore di riferimento (0.5). Un approccio alternativo è considerare un intervallo di valori attorno a 0.5 che possano essere considerati “praticamente equivalenti” al valore di riferimento. Questo intervallo è chiamato Regione di Equivalenza Pratica (ROPE).\nSecondo Kruschke & Liddell (2018), la ROPE può essere definita come un intervallo attorno al valore nullo (baseline) che corrisponde a un decimo della deviazione standard della distribuzione a posteriori del parametro di interesse. Nel nostro caso, il parametro di interesse è la proporzione \\(p\\), e il valore nullo è 0.5. Per calcolare la ROPE, estraiamo i campioni a posteriori dal modello.\n\nposterior_samples &lt;- as_draws_df(model_pledge_binomial)\n\nCalcoliamo la deviazione standard a posteriori di \\(p\\).\n\nposterior_std_dev &lt;- sd(posterior_samples$b_Intercept)\nposterior_std_dev\n#&gt; [1] 0.01809\n\nDefiniamo la ROPE come un intervallo attorno al valore di riferimento 0.5.\n\nbaseline &lt;- 0.5  # Valore nullo (baseline)\nrope_low &lt;- baseline - 0.1 * posterior_std_dev\nrope_high &lt;- baseline + 0.1 * posterior_std_dev\n\nCalcoliamo ora la probabilità che la proporzione \\(p\\) si trovi all’interno della ROPE.\n\nrope_probability &lt;-\n  mean(\n    posterior_samples$b_Intercept &gt;= rope_low &\n      posterior_samples$b_Intercept &lt;= rope_high\n  )\nrope_probability\n#&gt; [1] 0.00325\n\nVisualizziamo la distribuzione a posteriori di \\(p\\) insieme alla ROPE.\n\nggplot(posterior_samples, aes(x = b_Intercept)) +\n  geom_density(fill = \"gray\", alpha = 0.5) +\n  annotate(\n    geom = \"rect\", \n    xmin = rope_low, \n    xmax = rope_high, \n    ymin = 0, ymax = Inf, \n    fill = \"lightgray\", alpha = 0.2\n  ) +\n  geom_vline(xintercept = baseline, color = \"lightgray\") +\n  scale_x_continuous(labels = scales::percent) +\n  labs(x = \"Proportion used a condom at first sex\", y = \"Density\")\n\n\n\n\n\n\n\nIn conclusione, dato che solo lo 0.325% (meno dell’uno per cento) della distribuzione a posteriori di \\(p\\) si trova nella ROPE, possiamo concludere che ci sono evidenze credibili che la distribuzione a posteriori del parametro \\(p\\) (la proporzione di adolescenti, di età compresa tra 18 e 24 anni, che hanno fatto il “virginity pledge” e hanno usato il preservativo durante il primo rapporto sessuale) sia diversa dal valore di riferimento 0.5. Nel caso specifico, questa proporzione è più alta, indicando che la tendenza ad avere un rapporto protetto è maggiore rispetto al caso di casualità, per questa popolazione.\n\n73.2.8.1 Discussione sulla ROPE\nL’utilizzo della ROPE offre una prospettiva aggiuntiva nell’interpretazione delle inferenze bayesiane. Invece di semplicemente determinare se un parametro è statisticamente significativo rispetto a un valore di riferimento, la ROPE permette di valutare se le differenze osservate siano praticamente rilevanti in termini di impatto reale.\n\n\nSoglia di Rilevanza: L’impostazione di una ROPE consente di stabilire una soglia di rilevanza pratica. Se la maggior parte della distribuzione a posteriori cade al di fuori della ROPE, possiamo concludere che la differenza è non solo statistica ma anche pratica.\n\nInterpretazione Clinica: Nelle applicazioni pratiche, come in ambito medico o sociale, la ROPE aiuta a distinguere tra risultati statisticamente significativi ma clinicamente insignificanti e quelli che hanno un impatto rilevante.\n\nNel contesto dello studio sui “pledgers”, l’uso della ROPE fornisce una valutazione più completa della tendenza degli adolescenti a utilizzare il preservativo durante il primo rapporto sessuale, dimostrando che questa tendenza è non solo statisticamente diversa dal caso di casualità, ma anche significativa dal punto di vista pratico.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>Inferenza sulle proporzioni</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_one_proportion.html#inferenza-sulla-differenza-tra-due-proporzioni",
    "href": "chapters/linear_models/11_one_proportion.html#inferenza-sulla-differenza-tra-due-proporzioni",
    "title": "73  Inferenza sulle proporzioni",
    "section": "\n73.3 Inferenza sulla Differenza tra Due Proporzioni",
    "text": "73.3 Inferenza sulla Differenza tra Due Proporzioni\nEstendiamo ora l’analisi precedente per confrontare le proporzioni di due gruppi, un compito per il quale non esiste una soluzione analitica semplice. Nello studio in esame, ci poniamo la domanda: Fino a che punto l’analisi statistica supporta l’ipotesi che i “pledgers” abbiano una minore probabilità rispetto ai “non-pledgers” di usare il preservativo durante il primo rapporto sessuale?\nPer testare questa ipotesi utilizzando brms, estendiamo il modello bayesiano includendo due gruppi: i pledgers (che hanno fatto il voto di astinenza) e i non-pledgers (che non lo hanno fatto). L’obiettivo è stimare la differenza tra le due proporzioni e valutare se questa sia credibilmente diversa da zero.\n\n73.3.1 Creazione del Dataset\nCostruiamo un tibble con i dati relativi ai due gruppi:\n\npledge_data &lt;- tibble(\n  group = c(\"pledgers\", \"nonpledgers\"),\n  n_yes = c(424, 5416),   # Numero di partecipanti che hanno usato il preservativo\n  n_total = c(777, 9072)  # Totale dei partecipanti per ciascun gruppo\n)\nprint(pledge_data)\n#&gt; # A tibble: 2 × 3\n#&gt;   group       n_yes n_total\n#&gt;   &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 pledgers      424     777\n#&gt; 2 nonpledgers  5416    9072\n\n\n73.3.2 Specifica del Modello Bayesiano\nUtilizziamo un modello binomiale con un predittore categorico per distinguere tra i due gruppi. Il modello può essere rappresentato come:\n\\[\np_i \\sim \\text{Binomiale}(n_i, \\theta_i),\n\\]\ndove \\(\\theta_i\\) è la proporzione di utilizzo del preservativo nel gruppo \\(i\\), e modelliamo la probabilità di successo come:\n\\[\n\\theta = \\beta_0 + \\beta_1 \\cdot \\text{group},\n\\]\ndove:\n\n\n\\(\\beta_0\\) rappresenta la proporzione di non-pledgers che usano il preservativo.\n\n\\(\\beta_1\\) rappresenta la differenza tra pledgers e non-pledgers (cioè la variazione della proporzione di utilizzo del preservativo associata all’appartenenza al gruppo dei pledgers).\n\nLe caratteristiche di questo modello verranno approfondite nel capitolo successivo. Per ora, limitiamoci a stimare il modello in brms utilizzando una distribuzione binomiale e un link identità:\n\nmodel_pledge_diff &lt;- brm(\n  n_yes | trials(n_total) ~ group,\n  data = pledge_data,\n  family = binomial(link = \"identity\"),\n  prior = c(\n    prior(beta(1, 1), class = \"Intercept\", lb = 0, ub = 1),  \n    # Prior per la proporzione nei non-pledgers\n    prior(normal(0, 1), class = \"b\")  # Prior per la differenza tra gruppi\n  ),\n  chains = CHAINS, warmup = WARMUP, iter = ITER, seed = BAYES_SEED,\n  refresh = 0,\n  backend = \"cmdstanr\"\n)\n#&gt; Running MCMC with 4 sequential chains...\n#&gt; \n#&gt; Chain 1 finished in 0.1 seconds.\n#&gt; Chain 2 finished in 0.0 seconds.\n#&gt; Chain 3 finished in 0.1 seconds.\n#&gt; Chain 4 finished in 0.0 seconds.\n#&gt; \n#&gt; All 4 chains finished successfully.\n#&gt; Mean chain execution time: 0.1 seconds.\n#&gt; Total execution time: 0.8 seconds.\n\n\n73.3.3 Analisi della Distribuzione A Posteriori\nEsaminiamo il sommario del modello per valutare la stima della differenza tra le proporzioni:\n\nsummary(model_pledge_diff)\n#&gt;  Family: binomial \n#&gt;   Links: mu = identity \n#&gt; Formula: n_yes | trials(n_total) ~ group \n#&gt;    Data: pledge_data (Number of observations: 2) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept         0.60      0.01     0.59     0.61 1.00     4511     3068\n#&gt; grouppledgers    -0.05      0.02    -0.09    -0.01 1.01      889      793\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nPer interpretare meglio i risultati, estraiamo i campioni a posteriori per la differenza tra le due proporzioni:\n\npledge_diff_draws &lt;- model_pledge_diff |&gt; \n  spread_draws(b_Intercept, b_grouppledgers) |&gt; \n  mutate(\n    nonpledgers_prop = b_Intercept,  # Stima della proporzione nei non-pledgers\n    pledgers_prop = b_Intercept + b_grouppledgers,  # Stima della proporzione nei pledgers\n    diff = nonpledgers_prop - pledgers_prop  # Differenza tra le due proporzioni\n  )\n\nVisualizziamo la distribuzione a posteriori della differenza:\n\np3 &lt;- ggplot(pledge_diff_draws, aes(x = diff)) + \n  stat_halfeye(fill = \"gray\") +\n  geom_vline(xintercept = 0, linetype = \"dashed\") +\n  scale_x_continuous(labels = label_percent()) +\n  labs(x = \"Differenza nella proporzione di utilizzo del preservativo\", \n       y = \"Densità a posteriori\") \nprint(p3)\n\n\n\n\n\n\n\nCalcoliamo la probabilità che la differenza tra le proporzioni sia maggiore di zero:\n\ndiff_probability &lt;- mean(pledge_diff_draws$diff &gt; 0)\nprint(diff_probability)\n#&gt; [1] 0.997\n\n\n73.3.4 Interpretazione dei Risultati\nLa probabilità calcolata è 0.997; ciò significa che c’è una probabilità del 99.7% che la proporzione di non-pledgers che usano il preservativo sia maggiore rispetto a quella dei pledgers. Questo supporta con elevata credibilità l’ipotesi che i pledgers abbiano meno probabilità di utilizzare il preservativo durante il primo rapporto sessuale.\nPossiamo quindi concludere che la differenza tra le due proporzioni è credibilmente diversa da zero, con un’elevata probabilità a favore dell’ipotesi che i pledgers abbiano una minore propensione all’uso del preservativo rispetto ai non-pledgers. Questi risultati riproducono quelli riportati dalla letteratura precedente, come discusso da Brückner & Bearman (2005).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>Inferenza sulle proporzioni</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_one_proportion.html#riflessioni-conclusive",
    "href": "chapters/linear_models/11_one_proportion.html#riflessioni-conclusive",
    "title": "73  Inferenza sulle proporzioni",
    "section": "\n73.4 Riflessioni Conclusive",
    "text": "73.4 Riflessioni Conclusive\nL’inferenza su una proporzione tramite un approccio bayesiano offre una prospettiva più ricca e flessibile rispetto agli approcci frequentisti tradizionali. Utilizzando il pacchetto brms in R, abbiamo dimostrato come sia possibile modellare la proporzione di adolescenti che hanno usato il preservativo durante il primo rapporto sessuale, ottenendo risultati coerenti con quelli frequentisti. La capacità di ottenere una distribuzione completa della probabilità a posteriori consente non solo stime puntuali ma anche una comprensione approfondita dell’incertezza associata ai parametri stimati, rendendo l’approccio bayesiano uno strumento potente per l’analisi statistica avanzata.\nL’estensione dell’analisi alla differenza tra due proporzioni ha ulteriormente evidenziato i vantaggi dell’approccio bayesiano. Attraverso brms, abbiamo confrontato le proporzioni di utilizzo del preservativo tra i “pledgers” e i “non-pledgers”, ottenendo risultati coerenti e facilmente interpretabili. L’uso di distribuzioni a posteriori complete ci ha permesso di valutare in modo più dettagliato la plausibilità delle differenze osservate, offrendo una maggiore profondità di interpretazione rispetto agli intervalli di confidenza frequentisti.\n\n73.4.1 Vantaggi dell’Approccio Bayesiano\n\nDistribuzioni A Posteriori: L’approccio bayesiano fornisce una visione completa della distribuzione dei parametri stimati, permettendo di calcolare probabilità direttamente e quantificare l’incertezza in modo più intuitivo.\nFlessibilità Modellistica: brms consente di costruire modelli complessi, inclusi modelli gerarchici e multivariati, adattandosi alle specifiche esigenze dell’analisi senza perdere di generalità.\nPrior Informativi e Non Informativi: La possibilità di incorporare prior informativi o utilizzare prior non informativi permette di integrare conoscenze pregresse o lavorare in assenza di informazioni preliminari, aumentando la robustezza delle inferenze.\nIntegrazione con Stan: Sfruttando la potenza di Stan, brms offre algoritmi di campionamento efficienti e accurati per modelli complessi, garantendo risultati affidabili anche in situazioni di alta dimensionalità.\nVisualizzazione e Interpretazione: L’integrazione con pacchetti come tidyverse e ggplot2 facilita la visualizzazione e l’interpretazione dei risultati, rendendo più semplice comunicare le analisi bayesiane a un pubblico ampio e variegato.\n\n73.4.2 Applicazioni Pratiche\nI risultati ottenuti confermano che i “pledgers” hanno una minore propensione all’uso del preservativo rispetto ai “non-pledgers”, supportando con elevata credibilità l’ipotesi formulata. Questi risultati riproducono quelli riportati dalla letteratura precedente, rafforzando la validità dell’approccio bayesiano nelle applicazioni pratiche.\n\n73.4.3 Conclusione\nIn sintesi, l’approccio bayesiano, implementato attraverso il pacchetto brms, rappresenta uno strumento estremamente potente e flessibile per l’inferenza statistica. Offre una visione più dettagliata e comprensiva rispetto agli approcci frequentisti tradizionali, permettendo di ottenere risultati coerenti e facilmente interpretabili.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>Inferenza sulle proporzioni</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_one_proportion.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/11_one_proportion.html#informazioni-sullambiente-di-sviluppo",
    "title": "73  Inferenza sulle proporzioni",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] tidybayes_3.0.7   broom_1.0.8       brms_2.22.0       Rcpp_1.0.14      \n#&gt;  [5] bayestestR_0.15.3 posterior_1.6.1   cmdstanr_0.9.0    thematic_0.1.6   \n#&gt;  [9] MetBrewer_0.2.0   ggokabeito_0.1.0  see_0.11.0        gridExtra_2.3    \n#&gt; [13] patchwork_1.3.0   bayesplot_1.12.0  psych_2.5.3       scales_1.4.0     \n#&gt; [17] markdown_2.0      knitr_1.50        lubridate_1.9.4   forcats_1.0.0    \n#&gt; [21] stringr_1.5.1     dplyr_1.1.4       purrr_1.0.4       readr_2.1.5      \n#&gt; [25] tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.2     tidyverse_2.0.0  \n#&gt; [29] rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1     svUnit_1.0.6         farver_2.1.2        \n#&gt;  [4] loo_2.8.0            fastmap_1.2.0        tensorA_0.36.2.1    \n#&gt;  [7] pacman_0.5.1         digest_0.6.37        timechange_0.3.0    \n#&gt; [10] estimability_1.5.1   lifecycle_1.0.4      StanHeaders_2.32.10 \n#&gt; [13] processx_3.8.6       magrittr_2.0.3       compiler_4.5.0      \n#&gt; [16] rlang_1.1.6          tools_4.5.0          utf8_1.2.5          \n#&gt; [19] data.table_1.17.2    labeling_0.4.3       bridgesampling_1.1-2\n#&gt; [22] htmlwidgets_1.6.4    curl_6.2.2           pkgbuild_1.4.7      \n#&gt; [25] mnormt_2.1.1         plyr_1.8.9           RColorBrewer_1.1-3  \n#&gt; [28] abind_1.4-8          withr_3.0.2          stats4_4.5.0        \n#&gt; [31] grid_4.5.0           colorspace_2.1-1     inline_0.3.21       \n#&gt; [34] xtable_1.8-4         emmeans_1.11.1       insight_1.2.0       \n#&gt; [37] cli_3.6.5            mvtnorm_1.3-3        rmarkdown_2.29      \n#&gt; [40] generics_0.1.4       RcppParallel_5.1.10  rstudioapi_0.17.1   \n#&gt; [43] reshape2_1.4.4       tzdb_0.5.0           rstan_2.32.7        \n#&gt; [46] parallel_4.5.0       matrixStats_1.5.0    vctrs_0.6.5         \n#&gt; [49] V8_6.0.3             Matrix_1.7-3         jsonlite_2.0.0      \n#&gt; [52] hms_1.1.3            arrayhelpers_1.1-0   ggdist_3.3.3        \n#&gt; [55] glue_1.8.0           codetools_0.2-20     ps_1.9.1            \n#&gt; [58] distributional_0.5.0 stringi_1.8.7        gtable_0.3.6        \n#&gt; [61] QuickJSR_1.7.0       pillar_1.10.2        htmltools_0.5.8.1   \n#&gt; [64] Brobdingnag_1.2-9    R6_2.6.1             rprojroot_2.0.4     \n#&gt; [67] evaluate_1.0.3       lattice_0.22-7       backports_1.5.0     \n#&gt; [70] rstantools_2.4.0     coda_0.19-4.1        nlme_3.1-168        \n#&gt; [73] checkmate_2.3.2      xfun_0.52            pkgconfig_2.0.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>Inferenza sulle proporzioni</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_one_proportion.html#bibliografia",
    "href": "chapters/linear_models/11_one_proportion.html#bibliografia",
    "title": "73  Inferenza sulle proporzioni",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlbert, J., & Hu, J. (2019). Probability and Bayesian Modeling. CRC Press.\n\n\nBrückner, H., & Bearman, P. (2005). After the promise: The STD consequences of adolescent virginity pledges. Journal of Adolescent Health, 36(4), 271–278.\n\n\nKruschke, J. K., & Liddell, T. M. (2018). Bayesian data analysis for newcomers. Psychonomic Bulletin & Review, 25(1), 155–177.\n\n\nWagenmakers, E.-J., Lodewyckx, T., Kuriyal, H., & Grasman, R. (2010). Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method. Cognitive Psychology, 60(3), 158–189.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>Inferenza sulle proporzioni</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html",
    "href": "chapters/linear_models/12_two_proportions.html",
    "title": "74  Confronto tra due proporzioni indipendenti",
    "section": "",
    "text": "74.1 Introduzione\nSupponiamo di voler capire se due gruppi di persone hanno la stessa probabilità di “successo” in una certa attività. Per esempio, vogliamo sapere se due trattamenti diversi portano alla stessa percentuale di guarigione, oppure se studenti che seguono due metodi di studio differenti superano un esame con la stessa frequenza.\nQuando il risultato per ogni persona è un valore binario — successo o insuccesso, sì o no, guarito o non guarito — possiamo usare un modello statistico chiamato regressione logistica.\nIn particolare, se i due gruppi sono indipendenti e distinti (cioè ogni persona appartiene a uno solo dei due gruppi), possiamo usare una versione semplice della regressione logistica con una sola variabile esplicativa binaria (una “dummy”).\nAdottando un approccio bayesiano, possiamo:",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#introduzione",
    "href": "chapters/linear_models/12_two_proportions.html#introduzione",
    "title": "74  Confronto tra due proporzioni indipendenti",
    "section": "",
    "text": "rendere esplicita l’incertezza sulle nostre ipotesi iniziali tramite le distribuzioni a priori;\n\ndescrivere l’intera gamma di risultati plausibili, ottenendo una distribuzione a posteriori dei parametri invece di un singolo valore “stimato”.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#la-struttura-dei-dati",
    "href": "chapters/linear_models/12_two_proportions.html#la-struttura-dei-dati",
    "title": "74  Confronto tra due proporzioni indipendenti",
    "section": "\n74.2 La struttura dei dati",
    "text": "74.2 La struttura dei dati\nConsideriamo i dati che raccogliamo:\n\nogni partecipante è identificato da un indice \\(i = 1, 2, \\dots, N\\);\n\nper ciascuno osserviamo un esito binario:\n\\[\ny_i =\n  \\begin{cases}\n    1 & \\text{se c’è un successo},\\\\\n    0 & \\text{se c’è un insuccesso}.\n  \\end{cases}\n\\]\n\nogni partecipante appartiene a uno e un solo gruppo. Chiamiamo gruppo 0 il primo gruppo (ad esempio, il gruppo di controllo) e gruppo 1 il secondo gruppo (ad esempio, il gruppo che riceve un trattamento sperimentale).\n\nPer rappresentare questa appartenenza al gruppo, definiamo una variabile indicatrice:\n\\[\nD_i =\n  \\begin{cases}\n    0 & \\text{se il partecipante è nel gruppo 0},\\\\\n    1 & \\text{se il partecipante è nel gruppo 1}.\n  \\end{cases}\n\\]\nQuesta variabile ci permette di costruire un modello che distingue i due gruppi.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#un-modello-statistico-per-dati-binari",
    "href": "chapters/linear_models/12_two_proportions.html#un-modello-statistico-per-dati-binari",
    "title": "74  Confronto tra due proporzioni indipendenti",
    "section": "\n74.3 Un modello statistico per dati binari",
    "text": "74.3 Un modello statistico per dati binari\nPoiché il risultato \\(y\\_i\\) può essere solo 0 o 1, possiamo descriverlo con una distribuzione di Bernoulli, che rappresenta proprio questo tipo di variabili:\n\\[\ny_i \\sim \\text{Bernoulli}(p_i),\n\\]\ndove \\(p\\_i\\) è la probabilità che il partecipante \\(i\\) ottenga un successo (cioè che \\(y_i = 1\\)).\nA questo punto potremmo pensare di modellare direttamente \\(p_i\\) come una funzione di \\(D_i\\). Ma c’è un problema tecnico importante.\n\n74.3.1 Perché non modelliamo direttamente la probabilità \\(p_i\\)?\nLe probabilità devono sempre stare tra 0 e 1. Ma se usassimo un modello lineare classico (come \\(p\\_i = \\alpha + \\gamma D_i\\)), potremmo ottenere dei valori fuori da questo intervallo — ad esempio, una “probabilità” negativa o maggiore di 1, che non ha senso.\nPer evitare questo, si usa una trasformazione matematica chiamata logit, che ha due proprietà molto utili:\n\naccetta in ingresso solo valori tra 0 e 1 (cioè le probabilità),\nrestituisce un numero reale qualsiasi, da \\(-\\infty\\) a \\(+\\infty\\).\n\nLa trasformazione logit è definita così:\n\\[\n\\text{logit}(p_i) = \\log\\left(\\frac{p_i}{1 - p_i}\\right) .\n\\]\nQuesta quantità si chiama log-odds e rappresenta il logaritmo del rapporto tra la probabilità di successo e quella di insuccesso.\nEsempio:\n\nse \\(p_i = 0.5\\), allora \\(\\text{logit}(p_i) = \\log(1) = 0\\);\nse \\(p_i = 0.8\\), allora \\(\\text{logit}(p_i) = \\log(4) \\approx 1.39\\);\nse \\(p_i = 0.2\\), allora \\(\\text{logit}(p_i) = \\log(0.25) \\approx -1.39\\).\n\nGrazie a questa trasformazione, possiamo costruire un modello lineare senza rischiare di ottenere valori fuori dall’intervallo [0,1].",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#il-modello-di-regressione-logistica",
    "href": "chapters/linear_models/12_two_proportions.html#il-modello-di-regressione-logistica",
    "title": "74  Confronto tra due proporzioni indipendenti",
    "section": "\n74.4 Il modello di regressione logistica",
    "text": "74.4 Il modello di regressione logistica\nMettiamo insieme tutti i pezzi. Il nostro modello diventa:\n\\[\n\\begin{aligned}\ny_i &\\sim \\text{Bernoulli}(p_i), \\\\\n\\text{logit}(p_i) &= \\alpha + \\gamma D_i.\n\\end{aligned}\n\\]\nVediamo cosa significano i due parametri del modello:\n\n\n\\(\\alpha\\) è il log-odds di successo per il gruppo 0 (quando \\(D_i = 0\\)).\n\n\nLa probabilità di successo corrispondente si ottiene con la funzione logistica:\n\\[\np_0 = \\frac{e^{\\alpha}}{1 + e^{\\alpha}} = \\text{logistic}(\\alpha) .\n\\]\n\n\n\n\n\\(\\gamma\\) rappresenta la differenza nei log-odds tra il gruppo 1 e il gruppo 0.\n\n\nIl log-odds nel gruppo 1 è quindi $+ $, e la probabilità è:\n\\[\np_1 = \\frac{e^{\\alpha + \\gamma}}{1 + e^{\\alpha + \\gamma}} = \\text{logistic}(\\alpha + \\gamma) .\n\\]\n\n\n\n\n\n74.4.1 Interpretazione pratica\n\nSe \\(\\gamma &gt; 0\\), il gruppo 1 ha una probabilità di successo più alta rispetto al gruppo 0.\nSe \\(\\gamma &lt; 0\\), il gruppo 1 ha una probabilità più bassa.\nSe \\(\\gamma = 0\\), i due gruppi hanno la stessa probabilità di successo.\n\n74.4.2 Vantaggi dell’approccio bayesiano\nIn un’analisi bayesiana, non ci limitiamo a stimare un singolo valore per \\(\\gamma\\). Invece, otteniamo una distribuzione completa che rappresenta tutte le ipotesi plausibili sui valori di \\(\\gamma\\), tenendo conto:\n\ndella variabilità nei dati,\ndelle nostre ipotesi iniziali (le distribuzioni a priori),\ne delle informazioni che emergono dai dati osservati.\n\nQuesto ci permette di rispondere a domande come:\n\nQuanto è probabile che \\(\\gamma\\) sia maggiore di 0?\nQual è l’intervallo più credibile in cui può trovarsi \\(\\gamma\\) con il 95% di probabilità?\nQual è la probabilità che la differenza tra i gruppi sia sostanziale, non solo presente?\n\n74.4.3 Dai Logit alle Probabilità\nUna volta stimati i coefficienti del modello di regressione logistica — in particolare, l’intercetta \\(\\beta\\_0\\) e uno o più coefficienti \\(\\beta_j\\) associati ai predittori — questi si trovano sulla scala dei log-odds (cioè su scala logit). Per ottenere le probabilità previste per ciascuna combinazione di valori dei predittori, è sufficiente applicare la funzione logistica inversa, definita come:\n\\[\np = \\text{logistic}(\\eta) = \\frac{1}{1 + e^{-\\eta}},\n\\]\ndove \\(\\eta = \\beta_0 + \\beta_1 x_1 + \\dots + \\beta_k x_k\\) è il valore del predittore lineare per una certa combinazione dei predittori. Ad esempio, se si ha solo una variabile binaria \\(x\\) che vale 0 (gruppo di riferimento) o 1 (gruppo trattato), allora le probabilità nei due gruppi sono:\n\ngruppo di riferimento: \\(p_0 = \\frac{1}{1 + e^{-\\beta_0}}\\)\n\ngruppo trattamento:    \\(p_1 = \\frac{1}{1 + e^{-(\\beta\\_0 + \\beta_1)}}\\)\n\n\nIn questo modo, si può interpretare il modello non solo in termini di log-odds, ma anche come probabilità di successo, rendendo più intuitivo il significato pratico dei risultati.\n\n74.4.4 Inferenza bayesiana\n\n\nScelta delle prior\n\nUn’opzione comune è usare prior debolmente informative, ad esempio \\(\\alpha\\sim\\mathcal N(0,\\,2.5)\\) e \\(\\gamma\\sim\\mathcal N(0,\\,2.5)\\). Queste varianze larghe lasciano che i dati “parlino”, ma impediscono che le probabilità si avvicinino troppo a 0 o 1 senza evidenza.\n\n\n\nCalcolo della distribuzione a posteriori\n\nSi usa normalmente l’algoritmo MCMC (per es. No‑U‑Turn Sampler di Stan).\nOtteniamo campioni \\(\\{\\alpha^{(s)},\\gamma^{(s)}\\}_{s=1}^S\\).\n\n\n\nQuantità derivate di interesse\n\nProbabilità nei due gruppi: \\(p_0^{(s)}=\\operatorname{logistic}(\\alpha^{(s)})\\), \\(p_1^{(s)}=\\operatorname{logistic}(\\alpha^{(s)}+\\gamma^{(s)})\\).\n\nDifferenza di probabilità: \\(\\Delta^{(s)} = p_1^{(s)}-p_0^{(s)}\\). Mostra quanto, in media, il gruppo 1 supera (o non supera) il gruppo 0 in termini di proporzione.\n\nRapporto di odds: \\(\\text{OR}^{(s)} = e^{\\gamma^{(s)}}\\). Se \\(\\text{OR}=2\\) significa che gli odds di successo nel gruppo 1 sono il doppio di quelli nel gruppo 0.\n\n\n\nSintesi dei risultati\n\nMedia (o mediana) a posteriori per \\(p_0, p_1, \\Delta, \\text{OR}\\).\nIntervalli di credibilità al 95 %: tagliamo il 2.5 % di campioni in ciascuna coda.\nProbabilità che \\(\\Delta&gt;0\\) o che \\(\\text{OR}&gt;1\\): basta contare la frazione di campioni corrispondenti.\n\n\n\n74.4.5 Perché tutto questo funziona?\n\nIl logit “apre” l’intervallo (0, 1) rendendo possibile usare un modello lineare.\n\nLa regressione logistica con una dummy è l’esatto equivalente, in termini di parametri, al test bayesiano sulle due proporzioni, ma:\n\nconsente estensioni (più covariate, effetti casuali, interazioni);\npermette di riportare risultati direttamente interpretabili (differenza di probabilità, OR, predicted probabilities).\n\n\nL’approccio bayesiano produce output che si leggono come “date le nostre ipotesi preliminari e i dati, la plausibilità che la vera differenza di probabilità stia in questo intervallo è 95 %”, concetto spesso più intuitivo del valore‑p.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#inferenza-sulle-proporzioni",
    "href": "chapters/linear_models/12_two_proportions.html#inferenza-sulle-proporzioni",
    "title": "74  Confronto tra due proporzioni indipendenti",
    "section": "\n74.5 Inferenza sulle proporzioni",
    "text": "74.5 Inferenza sulle proporzioni\nIl confronto tra le proporzioni di due gruppi indipendenti può essere affrontato sia con un approccio frequentista, basato sulla distribuzione campionaria, sia con un approccio bayesiano. Vediamo i due approcci in dettaglio.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#approccio-frequentista",
    "href": "chapters/linear_models/12_two_proportions.html#approccio-frequentista",
    "title": "74  Confronto tra due proporzioni indipendenti",
    "section": "\n74.6 Approccio Frequentista",
    "text": "74.6 Approccio Frequentista\nQuando vogliamo confrontare le probabilità di successo in due gruppi distinti, possiamo analizzare la differenza tra le proporzioni di successo osservate. L’approccio frequentista affronta il problema studiando la distribuzione campionaria di questa differenza.\n\n74.6.1 Modello di riferimento\nSupponiamo di avere due gruppi indipendenti. In ciascun gruppo osserviamo esiti binari, come “successo” (1) o “insuccesso” (0), per ogni partecipante. Formalmente:\n\\[\nY_1 \\sim \\text{Bernoulli}(p_1), \\quad Y_2 \\sim \\text{Bernoulli}(p_2),\n\\]\ndove \\(p_1\\) e \\(p_2\\) sono le probabilità di successo nella popolazione del primo e del secondo gruppo, rispettivamente.\n\n74.6.2 Obiettivo dell’inferenza\nSiamo interessati a stimare e fare inferenza sulla differenza tra le due proporzioni:\n\\[\n\\Delta = p_1 - p_2.\n\\]\nPoiché non conosciamo \\(p_1\\) e \\(p_2\\), li stimiamo usando le proporzioni campionarie:\n\\[\n\\hat{p}_1 = \\frac{X_1}{n_1}, \\quad \\hat{p}_2 = \\frac{X_2}{n_2}, \\quad \\text{e dunque} \\quad \\hat{\\Delta} = \\hat{p}_1 - \\hat{p}_2.\n\\]\n\n74.6.3 Proprietà della distribuzione campionaria\nPer capire se la differenza osservata tra \\(\\hat{p}_1\\) e \\(\\hat{p}_2\\) è attribuibile al caso oppure riflette una differenza reale tra i gruppi, analizziamo la distribuzione campionaria di \\(\\hat{\\Delta}\\).\n\n74.6.3.1 Valore atteso\nIl valore atteso della differenza stimata è:\n\\[\nE(\\hat{p}_1 - \\hat{p}_2) = p_1 - p_2,\n\\]\ncioè, in media, la stima è corretta (è uno stimatore non distorto).\n\n\n\n\n\n\nDimostrazione\n\n\n\n\n\nSupponiamo di voler confrontare le proporzioni di successo in due popolazioni distinte. Sia:\n\n\n\\(X_1\\) il numero di successi osservati in un campione di dimensione \\(n_1\\) estratto dalla prima popolazione, in cui la proporzione di successo è \\(p_1\\);\n\n\\(X_2\\) il numero di successi osservati in un campione di dimensione \\(n_2\\) estratto dalla seconda popolazione, con proporzione di successo \\(p_2\\).\n\nAssumiamo che i due campioni siano indipendenti.\nLe proporzioni campionarie, che stimano rispettivamente \\(p_1\\) e \\(p_2\\), sono definite come:\n\\[\n\\hat{p}_1 = \\frac{X_1}{n_1}, \\quad \\hat{p}_2 = \\frac{X_2}{n_2}.\n\\]\nPoiché \\(X_1 \\sim \\text{Binomiale}(n_1, p_1)\\) e \\(X_2 \\sim \\text{Binomiale}(n_2, p_2)\\), possiamo determinare i valori attesi di \\(X_1\\) e \\(X_2\\) ricordando che per una variabile binomiale \\(X \\sim \\text{Bin}(n, p)\\), il valore atteso è:\n\\[\n\\mathbb{E}(X) = n p.\n\\]\nUna variabile binomiale può essere vista come la somma di \\(n\\) variabili di Bernoulli indipendenti:\n\\[\nX = X_1 + X_2 + \\dots + X_n, \\quad \\text{con } X_i \\sim \\text{Bernoulli}(p).\n\\]\nPer la linearità del valore atteso:\n\\[\n\\mathbb{E}(X) = \\sum_{i=1}^n \\mathbb{E}(X_i) = \\sum_{i=1}^n p = n p.\n\\]\nApplicando questa proprietà ai nostri due campioni:\n\\[\n\\mathbb{E}(X_1) = n_1 p_1, \\quad \\mathbb{E}(X_2) = n_2 p_2.\n\\]\nPer la prima proporzione campionaria:\n\\[\n\\mathbb{E}(\\hat{p}_1) = \\mathbb{E}\\left( \\frac{X_1}{n_1} \\right) = \\frac{1}{n_1} \\mathbb{E}(X_1) = \\frac{n_1 p_1}{n_1} = p_1.\n\\]\nAnalogamente, per la seconda:\n\\[\n\\mathbb{E}(\\hat{p}_2) = \\mathbb{E}\\left( \\frac{X_2}{n_2} \\right) = \\frac{1}{n_2} \\mathbb{E}(X_2) = \\frac{n_2 p_2}{n_2} = p_2.\n\\]\nDunque, sia \\(\\hat{p}_1\\) che \\(\\hat{p}_2\\) sono stimatori non distorti delle rispettive proporzioni della popolazione.\nInfine, calcoliamo il valore atteso della differenza tra le due proporzioni campionarie:\n\\[\n\\mathbb{E}(\\hat{p}_1 - \\hat{p}_2) = \\mathbb{E}(\\hat{p}_1) - \\mathbb{E}(\\hat{p}_2) = p_1 - p_2.\n\\]\nIn conclusione, la differenza tra le proporzioni campionarie, \\(\\hat{p}_1 - \\hat{p}_2\\), è uno stimatore non distorto della differenza tra le vere proporzioni, \\(p_1 - p_2\\).\n\n\n\n\n74.6.3.2 Varianza\nAssumendo che i campioni siano indipendenti, la varianza della differenza stimata è la somma delle varianze delle due proporzioni:\n\\[\n\\operatorname{Var}(\\hat{p}_1 - \\hat{p}_2) = \\frac{p_1(1 - p_1)}{n_1} + \\frac{p_2(1 - p_2)}{n_2}.\n\\]\nQuesta formula ci dice quanto può variare la differenza stimata da un campione all’altro.\nPoiché \\(p_1\\) e \\(p_2\\) sono ignoti, nella pratica li sostituiamo con le proporzioni osservate \\(\\hat{p}_1\\) e \\(\\hat{p}_2\\) per stimare la varianza.\n\n\n\n\n\n\nDimostrazione\n\n\n\n\n\nConsideriamo due campioni indipendenti:\n\nIl primo campione è estratto da una popolazione in cui la proporzione di successi è \\(p_1\\). Il numero di successi osservati è una variabile casuale \\(X_1 \\sim \\text{Binomiale}(n_1, p_1)\\).\nIl secondo campione proviene da una popolazione con proporzione di successi \\(p_2\\), e il numero di successi osservati è \\(X_2 \\sim \\text{Binomiale}(n_2, p_2)\\).\n\nDefiniamo le proporzioni campionarie (ovvero gli stimatori di \\(p_1\\) e \\(p_2\\)) come:\n\\[\n\\hat{p}_1 = \\frac{X_1}{n_1}, \\qquad \\hat{p}_2 = \\frac{X_2}{n_2}.\n\\]\nVogliamo calcolare la varianza della differenza tra le proporzioni campionarie:\n\\[\n\\operatorname{Var}(\\hat{p}_1 - \\hat{p}_2).\n\\]\nSe \\(Y\\) e \\(Z\\) sono variabili casuali indipendenti, allora:\n\\[\n\\operatorname{Var}(Y - Z) = \\operatorname{Var}(Y) + \\operatorname{Var}(Z).\n\\]\nNel nostro caso, \\(\\hat{p}_1\\) e \\(\\hat{p}_2\\) derivano da due campioni indipendenti, quindi possiamo applicare questa proprietà:\n\\[\n\\operatorname{Var}(\\hat{p}_1 - \\hat{p}_2) = \\operatorname{Var}(\\hat{p}_1) + \\operatorname{Var}(\\hat{p}_2).\n\\]\nPer calcolare \\(\\operatorname{Var}(\\hat{p})\\), partiamo dalla definizione di \\(\\hat{p} = X/n\\), dove \\(X \\sim \\text{Binomiale}(n, p)\\).\nÈ noto che la varianza di una binomiale (si veda Capitolo 39) è:\n\\[\n\\operatorname{Var}(X) = n p (1 - p).\n\\]\nOra applichiamo la proprietà di omogeneità della varianza: se \\(Y = cX\\), allora \\(\\operatorname{Var}(Y) = c^2 \\operatorname{Var}(X)\\). Quindi:\n\\[\n\\operatorname{Var}(\\hat{p}) = \\operatorname{Var}\\left(\\frac{X}{n}\\right) = \\frac{1}{n^2} \\cdot \\operatorname{Var}(X) = \\frac{1}{n^2} \\cdot n p (1 - p) = \\frac{p(1 - p)}{n}.\n\\]\nApplichiamo questa formula a ciascun campione:\n\\[\n\\operatorname{Var}(\\hat{p}_1) = \\frac{p_1 (1 - p_1)}{n_1}, \\qquad \\operatorname{Var}(\\hat{p}_2) = \\frac{p_2 (1 - p_2)}{n_2}.\n\\]\nSostituendo i valori ottenuti:\n\\[\n\\operatorname{Var}(\\hat{p}_1 - \\hat{p}_2) = \\frac{p_1 (1 - p_1)}{n_1} + \\frac{p_2 (1 - p_2)}{n_2}.\n\\]\nQuesta espressione rappresenta la varianza teorica della differenza tra le proporzioni campionarie, assumendo che i veri valori di \\(p_1\\) e \\(p_2\\) siano noti.\nNella realtà, i parametri \\(p_1\\) e \\(p_2\\) non sono noti, e quindi dobbiamo usare le stime campionarie al loro posto. Otteniamo così uno stimatore della varianza:\n\\[\n\\widehat{\\operatorname{Var}}(\\hat{p}_1 - \\hat{p}_2) = \\frac{\\hat{p}_1 (1 - \\hat{p}_1)}{n_1} + \\frac{\\hat{p}_2 (1 - \\hat{p}_2)}{n_2}.\n\\]\n\n\n\n\n74.6.4 Approssimazione normale\nQuando i campioni sono sufficientemente grandi, possiamo applicare il Teorema del Limite Centrale, che ci assicura che la distribuzione della differenza \\(\\hat{p}_1 - \\hat{p}_2\\) si avvicina a una distribuzione normale:\n\\[\n\\hat{p}_1 - \\hat{p}_2 \\sim \\mathcal{N}\\left(p_1 - p_2,\\ \\sqrt{\\frac{p_1(1 - p_1)}{n_1} + \\frac{p_2(1 - p_2)}{n_2}}\\right).\n\\tag{74.1}\\]\nNell’approccio frequentista, questa approssimazione è alla base della costruzione di:\n\n\nintervalli di confidenza per \\(p_1 - p_2\\),\n\ntest di ipotesi per verificare se la differenza tra le proporzioni è nulla.\n\n74.6.5 Test dell’ipotesi nulla\nLa formula Equazione 74.1 descrive la la distribuzione asintotica della differenza tra due proporzioni senza assumere che \\(p_1 = p_2\\). Si usa tipicamente per:\n\ncostruire intervalli di confidenza per \\(p_1 - p_2\\),\neffettuare test di ipotesi bilaterali, quando non si assume che le due proporzioni siano uguali sotto l’ipotesi nulla.\n\nIn alternativa, la formula\n\\[\n\\text{SE}_{\\text{pooled}} = \\sqrt{p_{\\text{pool}}(1 - p_{\\text{pool}})\\left(\\frac{1}{n_1} + \\frac{1}{n_2}\\right)}\n\\tag{74.2}\\]\nsi usa solo per testare l’ipotesi nulla \\(H_0: p_1 = p_2\\), ovvero sotto l’assunzione che \\(p_1 = p_2 = p\\), si stima questo valore comune con la proporzione combinata (pooled):\n\\[\n\\hat{p}_{\\text{pool}} = \\frac{x_1 + x_2}{n_1 + n_2}\n\\]\ne si calcola il test z usando questa stima comune.\n\n74.6.6 Quale formula usare e quando?\n\n\n\n\n\n\nScopo\nFormula da usare\n\n\n\nTest dell’ipotesi nulla \\(H_0: p_1 = p_2\\)\n\n✅ Usa la formula con pooled proportion\n\n\n\nCostruire intervallo di confidenza per \\(p_1 - p_2\\)\n\n✅ Usa la formula senza pooling, con \\(\\hat{p}_1\\) e \\(\\hat{p}_2\\)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#un-esempio-illustrativo",
    "href": "chapters/linear_models/12_two_proportions.html#un-esempio-illustrativo",
    "title": "74  Confronto tra due proporzioni indipendenti",
    "section": "\n74.7 Un esempio Illustrativo",
    "text": "74.7 Un esempio Illustrativo\nPer mettere in pratica quanto detto, consideriamo un caso reale tratto dallo studio di Banerjee et al. (2025). In questo studio vengono confrontate le abilità matematiche di:\n\n\nbambini lavoratori nei mercati di Kolkata e Delhi;\n\nbambini scolarizzati che non lavorano.\n\nL’obiettivo era valutare se le competenze sviluppate nel lavoro quotidiano (come dare il resto, sommare prezzi, ecc.) si trasferiscono al contesto scolastico e viceversa.\nI risultati principali mostrano come:\n\ni bambini lavoratori si sono dimostrati molto abili nel risolvere problemi matematici concreti, ma hanno faticato con problemi presentati in forma astratta (come quelli scolastici);\nal contrario, i bambini scolarizzati se la sono cavata meglio con problemi astratti, ma sono risultati poco efficaci nei problemi concreti del mercato.\n\nVediamo i dati raccolti per due tipi di problemi:\nProblemi astratti.\n\n\nGruppo\nSuccessi\nProve totali\nProporzione\n\n\n\nBambini lavoratori\n670\n1488\n0.45\n\n\nBambini scolarizzati\n320\n542\n0.59\n\n\n\nProblemi di mercato.\n\n\nGruppo\nSuccessi\nProve totali\nProporzione\n\n\n\nBambini lavoratori\n134\n373\n0.36\n\n\nBambini scolarizzati\n3\n271\n0.01\n\n\n\n\n74.7.1 Confronto per i problemi astratti\nUtilizzando l’approccio frequentista, vogliamo verificare se la differenza tra 0.45 (lavoratori) e 0.59 (scolarizzati) è spiegabile dal caso.\nIpotesi.\n\n\n\\(H_0\\): \\(p_1 = p_2\\) (nessuna differenza tra i gruppi);\n\n\\(H_1\\): \\(p_1 \\ne p_2\\) (esiste una differenza).\n\nCalcolo.\n\n\nProporzione combinata (pooled):\n\\[\n\\hat{p} = \\frac{670 + 320}{1488 + 542} = \\frac{990}{2030} \\approx 0.487.\n\\]\n\n\nVarianza stimata della differenza:\n\\[\n\\text{Var} = \\hat{p}(1 - \\hat{p}) \\left( \\frac{1}{1488} + \\frac{1}{542} \\right) \\approx 0.000629.\n\\]\n\nDeviazione standard: \\(\\sqrt{0.000629} \\approx 0.0251\\).\n\nStatistica z:\n\\[\nz = \\frac{0.45 - 0.59}{0.0251} \\approx -5.58.\n\\]\n\n\nIl valore z è molto lontano da 0: la probabilità di osservare una tale differenza per caso (p-value) è inferiore a 0.0001. Possiamo quindi rifiutare l’ipotesi nulla.\n\n74.7.2 Confronto per i problemi di mercato\nDati:\n\nLavoratori: 134 su 373 (\\(\\hat{p}_1 = 0.36\\))\nScolarizzati: 3 su 271 (\\(\\hat{p}_2 = 0.01\\))\n\nRipetiamo i passaggi:\n\n\\(\\hat{p} = \\frac{137}{644} \\approx 0.213\\)\n\\(\\text{Var} \\approx 0.001067\\)\nDeviazione standard: \\(\\sqrt{0.001067} \\approx 0.0327\\)\n\nStatistica z:\n\\[\nz = \\frac{0.36 - 0.01}{0.0327} \\approx 10.70\n\\]\n\n\nAnche qui, il p-value è praticamente zero: le differenze sono molto più grandi di quanto ci si aspetti per puro caso.\nIn sintesi, l’approccio frequentista ci consente di:\n\nstimare la differenza tra le proporzioni,\nquantificare l’incertezza (varianza e intervallo di confidenza),\ntestare ipotesi sul fatto che la differenza sia zero o meno.\n\nIn entrambi i confronti (problemi astratti e problemi concreti), abbiamo trovato evidenze chiare di una differenza tra i due gruppi.\n\n74.7.3 Svolgimento con R\nDi seguito mostriamo due modalità per replicare i calcoli in R: (1) passo passo usando le formule manuali, (2) usando la funzione prop.test() di R. Verranno illustrate entrambe le analisi: quella per i problemi astratti e quella per i problemi matematici di mercato.\n\n74.7.3.1 Problemi astratti\nDati\n\nBambini lavoratori (gruppo 1): 670 successi su 1488 prove.\nBambini scolarizzati (gruppo 2): 320 successi su 542 prove.\n\n\n##  Dati\nx_work   &lt;- 670   # successi (risposte corrette) tra i lavoratori\nn_work   &lt;- 1488  # totale lavoratori\n\nx_school &lt;- 320   # successi tra i non-lavoratori (scolarizzati)\nn_school &lt;- 542   # totale non-lavoratori\n\n##  Differenza di proporzioni \np_work   &lt;- x_work   / n_work\np_school &lt;- x_school / n_school\nrd       &lt;- p_school - p_work          \n\n##  Errore standard\n##  - Pooled SE per lo z-test (ipotesi H0: p1 = p2)\n##  - Unpooled SE per l’intervallo di confidenza\np_pool   &lt;- (x_work + x_school) / (n_work + n_school)\nse_test  &lt;- sqrt(p_pool * (1 - p_pool) * (1/n_work + 1/n_school))  # usato solo per lo z-test\nse_ci    &lt;- sqrt(p_work * (1 - p_work) / n_work +\n                 p_school * (1 - p_school) / n_school)  # migliore per il 95 % CI\n\n##  Inferenza\nz        &lt;- rd / se_test\np_value  &lt;- 2 * pnorm(-abs(z))\n\nalpha    &lt;- .05\nz_crit   &lt;- qnorm(1 - alpha/2)\nci_low   &lt;- rd - z_crit * se_ci\nci_high  &lt;- rd + z_crit * se_ci\n\n##  Stampa risultati\ncat(\n  sprintf(\n    \"Differenza assoluta:  %0.3f\\nErrore standard (CI): %0.3f\\nZ-test:            %0.2f\\nP-value:           %.3g\\n95%% CI:            [%0.2f, %0.2f]\\n\",\n    rd, se_ci, z, p_value, ci_low, ci_high\n  )\n)\n#&gt; Differenza assoluta:  0.140\n#&gt; Errore standard (CI): 0.025\n#&gt; Z-test:            5.59\n#&gt; P-value:           2.3e-08\n#&gt; 95% CI:            [0.09, 0.19]\n\nI valori ottenuti, 95% CI: 0.09 to 0.19, replicano quanto riportato da Banerjee et al. (2025) (la piccola differenza tra i risultati dipende dal fatto che gli autori hanno usato un metodo basato sulla regressione):\n\nOverall, 59% of non-working children correctly solved these problems compared with 45% of working children (β = –0.14, s.e.m. = 0.03, 95% CI = –0.20 to –0.08, P &lt; 0.001; Fig. 4, left).\n\n\n74.7.3.2 Analisi con funzione prop.test()\n\nPer ottenere direttamente il test di confronto di due proporzioni, possiamo usare la funzione prop.test di R. Attenzione che, di default, prop.test effettua una correzione per la continuità (Yates), che in questo contesto disattiviamo per confrontare i risultati con i calcoli manuali (impostando correct = FALSE).\n\n# Dati\nx  &lt;- c(670, 320)      # successi   (lavoratori, non-lavoratori)\nn  &lt;- c(1488, 542)     # denominatori\n\n# Test χ² / z-test per p1 = p2  ── senza correzione di continuità\nout &lt;- prop.test(x, n, correct = FALSE)\n\nout\n#&gt; \n#&gt;  2-sample test for equality of proportions without continuity\n#&gt;  correction\n#&gt; \n#&gt; data:  x out of n\n#&gt; X-squared = 31, df = 1, p-value = 2e-08\n#&gt; alternative hypothesis: two.sided\n#&gt; 95 percent confidence interval:\n#&gt;  -0.18864 -0.09163\n#&gt; sample estimates:\n#&gt; prop 1 prop 2 \n#&gt; 0.4503 0.5904\n\nInterpretazione dei risultati.\n\nIl test dell’ipotesi nulla porta al rifiuto di \\(H_0\\), suggerendo che le proporzioni di successo nei due gruppi non sono uguali.\nL’intervallo di confidenza calcolato non include lo zero, indicando che la differenza osservata è incompatibile con l’assenza di effetto.\nPossiamo quindi concludere che esiste una differenza rilevante tra le proporzioni di successo dei bambini lavoratori e di quelli scolarizzati.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#approccio-bayesiano",
    "href": "chapters/linear_models/12_two_proportions.html#approccio-bayesiano",
    "title": "74  Confronto tra due proporzioni indipendenti",
    "section": "\n74.8 Approccio Bayesiano",
    "text": "74.8 Approccio Bayesiano\nÈ possibile applicare l’approccio bayesiano al problema dell’inferenza sulla differenza tra due proporzioni indipendenti utilizzando un modello di regressione con una variabile indicatrice (dummy) per distinguere i due gruppi. Per fare un esempio, consideriamo qui i problemi astratti. Utilizziamo il pacchetto brms per stimare il modello, con distribuzioni a priori debolmente informative specificate di default.\n\n74.8.1 Dati\n\n# Successi e denominatori\nx_work   &lt;- 670 ; n_work   &lt;- 1488\nx_non    &lt;- 320 ; n_non    &lt;-  542\n\ndat_a &lt;- tibble(\n  count = c(x_work, x_non),\n  tot   = c(n_work, n_non),\n  group = factor(c(\"working\", \"non-working\"),\n                 levels = c(\"non-working\", \"working\"))  # “non-working” livello di riferimento\n)\n\ndat_a\n#&gt; # A tibble: 2 × 3\n#&gt;   count   tot group      \n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;      \n#&gt; 1   670  1488 working    \n#&gt; 2   320   542 non-working\n\n\n74.8.2 Prior debolmente informativi\n\n\nNormal (0, 2.5) sul logit corrisponde ai suggerimenti di Gelman et al. per logistic regression: – copre probabilità grossolanamente tra 0.004 e 0.996 sull’intercetta; – per il coefficiente di gruppo equivale a un odds-ratio plausibile entro ~ e±5.\n\n\npriors &lt;- c(\n  prior(normal(0, 2.5), class = \"Intercept\"),\n  prior(normal(0, 2.5), class = \"b\")\n)\n\n\n74.8.3 Stima del modello\n\nfit_a &lt;- brm(\n  count | trials(tot) ~ group,\n  data      = dat_a,\n  family    = binomial(),\n  prior     = priors,\n  backend   = \"cmdstanr\",\n  seed      = 1234,\n  iter      = 4000, chains = 4, cores = 4,\n  sample_prior = \"yes\"   # utile per i PPC sui prior\n)\n\nControlla rapidamente la convergenza:\n\nprint(fit_a, digits = 3)\n#&gt;  Family: binomial \n#&gt;   Links: mu = logit \n#&gt; Formula: count | trials(tot) ~ group \n#&gt;    Data: dat_a (Number of observations: 2) \n#&gt;   Draws: 4 chains, each with iter = 4000; warmup = 2000; thin = 1;\n#&gt;          total post-warmup draws = 8000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;              Estimate Est.Error l-95% CI u-95% CI  Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept       0.369     0.086    0.201    0.539 1.000     3230     3722\n#&gt; groupworking   -0.569     0.100   -0.766   -0.368 1.001     3929     3843\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\n\npp_check(fit_a, type = \"bars\")   \n\n\n\n\n\n\n\n\n74.8.4 Dalla scala logit alla scala delle probabilità\nIl modello stima\n\\[\n\\operatorname{logit}(p_i)=\\beta_0+\\beta_1\\; \\mathbf 1_{\\text{working},i},\n\\]\nperciò:\n\n\n\n\n\n\nParametro\nSignificato\n\n\n\nβ₀ (b_Intercept)\nlog-odds di successo per non-working\n\n\n\nβ₁ (b_groupworking)\ndifferenza di log-odds fra working e non-working\n\n\n\n\nPer ottenere proporzioni e differenza assoluta (Δ) dobbiamo trasformare ogni draw con l’inversa del logit, plogis().\n\npost &lt;- as_draws_df(fit_a, \n                    variables = c(\"b_Intercept\", \"b_groupworking\")) %&gt;% \n  mutate(\n    p_non  = plogis(b_Intercept),                       # Pr(corretto | non-working)\n    p_work = plogis(b_Intercept + b_groupworking),      # Pr(corretto | working)\n    diff   = p_non - p_work                             # risk-difference\n  )\n\nPerché non basta sottrarre β₁?\nPerché β₁ è una differenza di log-odds. La quantità di interesse qui è la differenza di probabilità. Le due scale sono non lineari e non confrontabili senza trasformazione.\n\n74.8.5 Sintesi della risk–difference\n\n\nsummary_diff &lt;- post %&gt;% \n  summarise(\n    mean     = mean(diff),\n    sd       = sd(diff),\n    `2.5%`   = quantile(diff, .025),\n    `97.5%`  = quantile(diff, .975),\n    prob_gt0 = mean(diff &gt; 0)      # P(Δ &gt; 0 | dati, prior)\n  )\n\nprint(summary_diff, digits = 3)\n#&gt; # A tibble: 1 × 5\n#&gt;    mean     sd `2.5%` `97.5%` prob_gt0\n#&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 0.141 0.0244 0.0918   0.188        1\n\n\n\nΔ (media)\nSD\n95 % CrI\nP(Δ &gt; 0)\n\n\n0.140\n0.025\n0.090 – 0.190\n1.000\n\n\nIl risultato replica quanto ottenuto con prop.test() (0.14 ± 0.025, IC 0.09–0.19).\n\n74.8.6 Confronto con l’approccio frequentista\n\nprop.test(c(x_work, x_non), c(n_work, n_non), correct = FALSE)\n#&gt; \n#&gt;  2-sample test for equality of proportions without continuity\n#&gt;  correction\n#&gt; \n#&gt; data:  c(x_work, x_non) out of c(n_work, n_non)\n#&gt; X-squared = 31, df = 1, p-value = 2e-08\n#&gt; alternative hypothesis: two.sided\n#&gt; 95 percent confidence interval:\n#&gt;  -0.18864 -0.09163\n#&gt; sample estimates:\n#&gt; prop 1 prop 2 \n#&gt; 0.4503 0.5904\n\n` Le due analisi coincidono: i bambini non-working hanno ~ 14 punti percentuali in più di probabilità di rispondere correttamente.\n\n74.8.7 Perché preferire il Bayesiano?\n\n\nNiente “ipotesi nulla” irreale – lavoriamo direttamente con la distribuzione di Δ.\n\nInterpretazione pronta – il 95 % CrI dice che, dati e prior, Δ è fra 9 e 19 punti %.\n\nFlessibilità – possiamo integrare conoscenza pregressa, fare previsioni, decision-making, ecc.\n\nCon prior debolmente informativi i risultati restano virtualmente identici all’approccio frequentista; in dataset più piccoli o modelli più complessi, la stabilizzazione offerta dai prior diventa però cruciale.\n\n74.8.8 Intervallo di credibilità a densità più alta\nPer ottenere l’intervallo di credibilità (Highest Density Interval, HDI) sulla scala delle probabilità (e non su quella logit), è necessario trasformare manualmente i draw a livello di probabilità e poi calcolare l’HDI su quei valori trasformati. In altre parole:\n\n\nestraiamo i draw posteriori di b_Intercept e b_groupworking;\n\n\ntrasformiamo i valori con la funzione logit-inversa (\\(\\operatorname{logistic}(x) = 1/(1+e^{-x})\\)) per ottenere le probabilità;\n\n\nse ci concentriamo sul solo effetto sulla scala della probabilità (e.g. differenza fra i due gruppi), calcoliamo la differenza tra la probabilità del gruppo “working” e quella del gruppo “reference” per ciascun draw;\n\n\napplichiamo hdi() su queste grandezze trasformate.\n\nDi seguito è fornito il codice R con il workflow completo.\n\nEstrazione draw posteriori.\n\n\npost &lt;- as_draws_df(fit_a)\n\n\n\nCalcolo delle probabilità per ciascun draw. La variabile ‘group’ abbia due livelli:\n\n“working” (effetto =&gt; b_groupworking)\n“non-working” (riferimento =&gt; b_Intercept)\n\n\n\n\npost &lt;- post %&gt;%\n  dplyr::mutate(\n    p_ref      = plogis(b_Intercept),                       # probabilità (referenza)\n    p_working  = plogis(b_Intercept + b_groupworking),      # prob. gruppo working\n    diff_working_ref = p_working - p_ref                    # differenza\n  )\n\n\nCalcolo dell’HDI sull’effetto (o sulle probabilità).\n\n\nHDI per la probabilità del gruppo “working”.\n\n\nhdi_working_prob &lt;- hdi(post$p_working, ci = 0.95)\nhdi_working_prob\n#&gt; 95% HDI: [0.43, 0.48]\n\n\nHDI per la probabilità del gruppo “non-working” (riferimento).\n\n\nhdi_ref_prob &lt;- hdi(post$p_ref, ci = 0.95)\nhdi_ref_prob\n#&gt; 95% HDI: [0.55, 0.63]\n\n\nHDI della differenza fra le due probabilità.\n\n\nhdi_diff &lt;- hdi(post$diff_working_ref, ci = 0.89)\nhdi_diff\n#&gt; 89% HDI: [-0.18, -0.10]\n\nInterpretazione\n\n\nhdi_working_prob fornisce l’HDI al 95% (o al livello che specificato) della probabilità di “successo” del gruppo “working”.\n\n\nhdi_ref_prob fa lo stesso per il gruppo di riferimento.\n\n\nhdi_diff restituisce l’HDI della differenza in probabilità tra “working” e “reference” (\\(p_{\\text{working}} - p_{\\text{reference}}\\)).\n\nIn questo modo ottieniamo l’intervallo di credibilità (HDI) sulla scala delle probabilità.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#riflessioni-conclusive",
    "href": "chapters/linear_models/12_two_proportions.html#riflessioni-conclusive",
    "title": "74  Confronto tra due proporzioni indipendenti",
    "section": "\n74.9 Riflessioni Conclusive",
    "text": "74.9 Riflessioni Conclusive\nIn questo capitolo abbiamo esplorato il confronto tra due proporzioni adottando sia l’approccio frequentista sia quello bayesiano. L’obiettivo principale era valutare se la proporzione di successi in un gruppo differisse da quella osservata nell’altro gruppo, e con quale grado di incertezza.\nNella procedura classica frequentista (test per due proporzioni), si calcola una statistica di test (ad esempio, un test z) e il relativo p-value, ossia la probabilità di osservare un risultato così estremo (o più) assumendo che le due proporzioni reali siano uguali (ipotesi nulla).\n\n\nIntervallo di confidenza: È possibile costruire un intervallo di confidenza (IC) per la differenza tra le due proporzioni. L’interpretazione frequentista di tale IC, però, si basa su un’ipotetica ripetizione di campionamenti ed è focalizzata sull’eventuale rifiuto o meno dell’ipotesi che la differenza sia zero.\n\n\nLimiti interpretativi: L’approccio frequentista si fonda sul concetto di ipotesi nulla “nessuna differenza” e non fornisce una probabilità diretta di quanto la differenza vera sia maggiore o minore di un certo valore, limitandosi a indicare se i dati sono inusuali qualora la differenza fosse zero.\n\nGrazie alla regola di Bayes, combiniamo informazioni a priori (sul probabile valore delle proporzioni) con i dati osservati, per ottenere una distribuzione a posteriori della differenza tra le due proporzioni. Questa distribuzione descrive i valori plausibili della differenza, insieme alle relative credibilità (probabilità).\n\n\nCredible Interval o Highest Density Interval (HDI): Al posto di un intervallo di confidenza, l’approccio bayesiano fornisce un intervallo di credibilità. Ad esempio, un 95% HDI indica i valori della differenza tra le proporzioni che cumulativamente contengono il 95% della probabilità a posteriori. È un costrutto immediatamente interpretabile: “Abbiamo una probabilità del 95% che la differenza vera cada all’interno di questo intervallo”.\n\n\nFlessibilità e interpretazione diretta: L’approccio bayesiano permette di rispondere in modo più naturale a domande come: “Qual è la probabilità che la differenza fra le due proporzioni sia maggiore di 0?” oppure “Qual è la probabilità che la proporzione di un gruppo superi quella dell’altro di almeno una certa soglia rilevante?”.\n\nConfronto tra i due approcci:\n\n\nInterpretazione dei risultati: Il p-value frequentista ci dice quanto il dato sia “improbabile” sotto l’ipotesi di uguaglianza delle proporzioni; il Bayesianesimo risponde direttamente a quanto è plausibile ogni possibile valore di differenza.\n\n\nCentralità dell’ipotesi nulla: Nel frequentismo, l’ipotesi nulla (differenza = 0) è centrale. Nel modello bayesiano, è invece possibile assegnare direttamente probabilità alla differenza e alla sua distanza da zero, evitando un focus eccessivo sull’uguaglianza perfetta delle due proporzioni.\n\n\nRuolo dei priors: L’uso di priors (non informativi o informativi) può influire sulle stime bayesiane quando i dati sono scarsi, rendendo evidente la necessità di scelte trasparenti e ben motivate. Tuttavia, con campioni ampi, l’influenza dei priors tende a ridursi e la stima a posteriori è dominata dai dati.\n\n\nCompletezza dell’inferenza: L’approccio bayesiano consente di integrare nuove informazioni e di aggiornare la distribuzione a posteriori man mano che arrivano dati aggiuntivi. Al contrario, l’approccio frequentista non fornisce un meccanismo diretto di “aggiornamento” delle stime alla luce di nuovi dati.\n\nIn sintesi,\n\n\napproccio frequentista: Si tratta di una metodologia consolidata e standard nella ricerca; fornisce risultati in termini di p-value e IC, ma l’interpretazione del p-value e dell’IC resta legata a procedure di campionamento ipotetico.\n\n\napproccio bayesiano: Offre una maniera più intuitiva di quantificare l’incertezza, assegnando probabilità dirette ai possibili valori di differenza fra le due proporzioni. Consente di formulare domande più specifiche (es. la probabilità che la differenza superi un valore definito) e di integrare in modo naturale informazioni a priori.\n\nNella pratica della ricerca, l’approccio frequentista rimane diffuso. Tuttavia, l’inferenza bayesiana fornisce un quadro interpretativo più ricco e flessibile. Utilizzare entrambi i metodi, quando appropriato, può potenziare l’analisi e la comprensione dei dati, permettendo di trarre conclusioni più robuste e trasparenti.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/12_two_proportions.html#informazioni-sullambiente-di-sviluppo",
    "title": "74  Confronto tra due proporzioni indipendenti",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] insight_1.2.0     bayestestR_0.15.3 posterior_1.6.1   cmdstanr_0.9.0   \n#&gt;  [5] brms_2.22.0       Rcpp_1.0.14       thematic_0.1.6    MetBrewer_0.2.0  \n#&gt;  [9] ggokabeito_0.1.0  see_0.11.0        gridExtra_2.3     patchwork_1.3.0  \n#&gt; [13] bayesplot_1.12.0  psych_2.5.3       scales_1.4.0      markdown_2.0     \n#&gt; [17] knitr_1.50        lubridate_1.9.4   forcats_1.0.0     stringr_1.5.1    \n#&gt; [21] dplyr_1.1.4       purrr_1.0.4       readr_2.1.5       tidyr_1.3.1      \n#&gt; [25] tibble_3.2.1      ggplot2_3.5.2     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [29] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1     farver_2.1.2         loo_2.8.0           \n#&gt;  [4] fastmap_1.2.0        tensorA_0.36.2.1     pacman_0.5.1        \n#&gt;  [7] digest_0.6.37        timechange_0.3.0     estimability_1.5.1  \n#&gt; [10] lifecycle_1.0.4      StanHeaders_2.32.10  processx_3.8.6      \n#&gt; [13] magrittr_2.0.3       compiler_4.5.0       rlang_1.1.6         \n#&gt; [16] tools_4.5.0          utf8_1.2.5           yaml_2.3.10         \n#&gt; [19] data.table_1.17.2    labeling_0.4.3       bridgesampling_1.1-2\n#&gt; [22] htmlwidgets_1.6.4    curl_6.2.2           pkgbuild_1.4.7      \n#&gt; [25] mnormt_2.1.1         plyr_1.8.9           RColorBrewer_1.1-3  \n#&gt; [28] abind_1.4-8          withr_3.0.2          stats4_4.5.0        \n#&gt; [31] grid_4.5.0           colorspace_2.1-1     inline_0.3.21       \n#&gt; [34] xtable_1.8-4         emmeans_1.11.1       cli_3.6.5           \n#&gt; [37] mvtnorm_1.3-3        rmarkdown_2.29       generics_0.1.4      \n#&gt; [40] RcppParallel_5.1.10  rstudioapi_0.17.1    reshape2_1.4.4      \n#&gt; [43] tzdb_0.5.0           rstan_2.32.7         parallel_4.5.0      \n#&gt; [46] matrixStats_1.5.0    vctrs_0.6.5          V8_6.0.3            \n#&gt; [49] Matrix_1.7-3         jsonlite_2.0.0       hms_1.1.3           \n#&gt; [52] glue_1.8.0           codetools_0.2-20     ps_1.9.1            \n#&gt; [55] distributional_0.5.0 stringi_1.8.7        gtable_0.3.6        \n#&gt; [58] QuickJSR_1.7.0       pillar_1.10.2        htmltools_0.5.8.1   \n#&gt; [61] Brobdingnag_1.2-9    R6_2.6.1             rprojroot_2.0.4     \n#&gt; [64] evaluate_1.0.3       lattice_0.22-7       backports_1.5.0     \n#&gt; [67] rstantools_2.4.0     coda_0.19-4.1        nlme_3.1-168        \n#&gt; [70] checkmate_2.3.2      xfun_0.52            pkgconfig_2.0.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#bibliografia",
    "href": "chapters/linear_models/12_two_proportions.html#bibliografia",
    "title": "74  Confronto tra due proporzioni indipendenti",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBanerjee, A. V., Bhattacharjee, S., Chattopadhyay, R., Duflo, E., Ganimian, A. J., Rajah, K., & Spelke, E. S. (2025). Children’s arithmetic skills do not transfer between applied and academic mathematics. Nature, 1–9.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html",
    "href": "chapters/linear_models/13_poisson_model.html",
    "title": "\n75  Modello di Poisson\n",
    "section": "",
    "text": "75.1 Introduzione\nIn questo capitolo percorriamo l’intero processo che porta dall’idea di contare un evento raro – le sparatorie fatali da parte della polizia statunitense – alla stima del suo tasso medio annuo attraverso un modello di Poisson implementato con il pacchetto brms. Per contestualizzare il fenomeno si suggerisce di leggere l’articolo Racial Disparities in Police Use of Deadly Force Against Unarmed Individuals Persist After Appropriately Benchmarking Shooting Data on Violent Crime Rates (Ross et al., 2021). Non è obbligatorio per seguire il capitolo, ma fornisce lo sfondo sociale e metodologico dei dati che stiamo per analizzare.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#perché-un-modello-di-poisson",
    "href": "chapters/linear_models/13_poisson_model.html#perché-un-modello-di-poisson",
    "title": "\n75  Modello di Poisson\n",
    "section": "\n75.2 Perché un modello di Poisson?",
    "text": "75.2 Perché un modello di Poisson?\nQuando il fenomeno di interesse è un conteggio – per esempio il numero di incidenti, diagnosi o, come nel nostro caso, sparatorie in un anno – la distribuzione di Poisson è spesso una scelta naturale. Questa distribuzione è definita da un solo parametro, \\(\\lambda\\), che rappresenta la media (e varianza) del conteggio. In altre parole, se conosci \\(\\lambda\\) conosci già la forma completa della distribuzione.\nPer non appesantire la lettura ricordiamo qui solo l’essenziale: se \\(Y\\) è il numero di eventi osservati in un certo intervallo di tempo, dire che\n\\[\nY \\sim \\text{Poisson}(\\lambda)\n\\]\nsignifica che la probabilità di osservare esattamente \\(k\\) eventi è\n\\[\nP(Y = k) = \\frac{e^{-\\lambda}\\, \\lambda^{k}}{k!}, \\quad k = 0,1,2,\\dots\n\\]",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#come-brms-codifica-lambda",
    "href": "chapters/linear_models/13_poisson_model.html#come-brms-codifica-lambda",
    "title": "\n75  Modello di Poisson\n",
    "section": "\n75.3 Come brms codifica \\(\\lambda\\)\n",
    "text": "75.3 Come brms codifica \\(\\lambda\\)\n\nIl pacchetto brms, così come la maggior parte dei software di regressione, non stima \\(\\lambda\\) direttamente. Per garantire che il tasso rimanga positivo adotta un link logaritmico: all’interno del modello viene quindi stimata la quantità\n\\[\n\\eta = \\log(\\lambda).\n\\]\nNel caso più semplice, senza predittori, brms utilizza un solo coefficiente, l’intercetta b_Intercept, che è proprio l’equivalente di \\(\\eta\\). Una volta ottenuti i campioni posteriori di b_Intercept è sufficiente applicare l’esponenziale per tornare sul piano di \\(\\lambda\\):\nlambda &lt;- exp(b_Intercept)  # trasforma log-lambda in lambda\nOgni volta che in questo capitolo nomineremo “campioni di \\(\\lambda\\)” sottintenderemo che abbiamo già eseguito questa trasformazione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#la-domanda-di-ricerca",
    "href": "chapters/linear_models/13_poisson_model.html#la-domanda-di-ricerca",
    "title": "\n75  Modello di Poisson\n",
    "section": "\n75.4 La domanda di ricerca",
    "text": "75.4 La domanda di ricerca\nGrazie all’archivio pubblico del Washington Post disponiamo di tutti i casi di sparatorie fatali accadute negli Stati Uniti dal 2015 in poi. L’interesse è stimare quante se ne verificano in media in un anno e descrivere l’incertezza associata a tale stima.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#importiamo-e-prepariamo-i-dati",
    "href": "chapters/linear_models/13_poisson_model.html#importiamo-e-prepariamo-i-dati",
    "title": "\n75  Modello di Poisson\n",
    "section": "\n75.5 Importiamo e prepariamo i dati",
    "text": "75.5 Importiamo e prepariamo i dati\n\nurl &lt;- \"https://raw.githubusercontent.com/washingtonpost/data-police-shootings/master/v2/fatal-police-shootings-data.csv\"\nraw &lt;- read.csv(url, stringsAsFactors = FALSE)\nraw$date &lt;- as.Date(raw$date)\nraw$year &lt;- lubridate::year(raw$date)\n\n# Escludiamo il 2025 perché l’anno è ancora in corso e i dati sarebbero incompleti\nshootings &lt;- subset(raw, year &lt; 2025)\n\ndf &lt;- shootings %&gt;%\n  dplyr::count(year, name = \"events\")\n\n\nhead(df)\n#&gt;   year events\n#&gt; 1 2015    995\n#&gt; 2 2016    959\n#&gt; 3 2017    984\n#&gt; 4 2018    992\n#&gt; 5 2019    993\n#&gt; 6 2020   1021\n\nA questo punto abbiamo una tabella df con due colonne: year, che va dal 2015 al 2024, ed events, che contiene il numero di sparatorie registrate in ciascun anno.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#specificare-la-distribuzione-a-priori",
    "href": "chapters/linear_models/13_poisson_model.html#specificare-la-distribuzione-a-priori",
    "title": "\n75  Modello di Poisson\n",
    "section": "\n75.6 Specificare la Distribuzione a Priori",
    "text": "75.6 Specificare la Distribuzione a Priori\nPrima di osservare i dati vogliamo dichiarare che, secondo la nostra conoscenza precedente, un intervallo plausibile per \\(\\lambda\\) va grosso modo da 400 a 900 casi l’anno, con media attorno a 600. Per ottenere una distribuzione lognormale con queste caratteristiche possiamo lavorare sulla scala logaritmica e scegliere normal(6.4, 0.3). Il valore 6.4 è infatti il logaritmo naturale di 600; la deviazione 0.3 produce l’ampiezza desiderata dell’intervallo. In brms la specifica è molto compatta:\n\nprior_lambda &lt;- prior(normal(6.4, 0.3), class = \"Intercept\")",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#adattare-il-modello-in-brms",
    "href": "chapters/linear_models/13_poisson_model.html#adattare-il-modello-in-brms",
    "title": "\n75  Modello di Poisson\n",
    "section": "\n75.7 Adattare il modello in brms\n",
    "text": "75.7 Adattare il modello in brms\n\nIl cuore dell’analisi si riduce a poche righe, perché il linguaggio di brms è pensato per assomigliare alla formula syntax di lm:\n\nm0 &lt;- brm(\n  events ~ 1,                  # ~1 indica solo l’intercetta\n  family = poisson(),          # distribuzione di errore\n  data   = df,\n  prior  = prior_lambda,\n  iter   = 3000,\n  warmup = 1000,\n  chains = 4,\n  seed   = 123,\n  backend = \"cmdstanr\"\n)\n\nIl comando produce più di quattromila campioni posteriori (\\(1000\\) di warm‑up per ciascuna delle quattro catene + \\(2000\\) validi) dell’intercetta logaritmica. Le diagnosi di convergenza – \\(\\hat R\\) vicino a 1, effective sample size buona – sono riportate da summary(m0).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#dalla-scala-log-a-lambda",
    "href": "chapters/linear_models/13_poisson_model.html#dalla-scala-log-a-lambda",
    "title": "\n75  Modello di Poisson\n",
    "section": "\n75.8 Dalla scala log a \\(\\lambda\\)\n",
    "text": "75.8 Dalla scala log a \\(\\lambda\\)\n\nPer passare dalla stima di b_Intercept alla stima di \\(\\lambda\\) basta eseguire l’esponenziale sui campioni posteriori. Usando tidybayes l’operazione è quasi in linguaggio naturale:\n\nposterior_lambda &lt;- m0 |&gt;\n  spread_draws(b_Intercept) |&gt;\n  mutate(lambda = exp(b_Intercept))\n\nposterior_lambda |&gt;\n  median_qi(lambda, .width = 0.94)\n#&gt; # A tibble: 1 × 6\n#&gt;   lambda .lower .upper .width .point .interval\n#&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    \n#&gt; 1  1043.  1023.  1062.   0.94 median qi\n\nL’output ci dice che il valore più credibile di \\(\\lambda\\) è intorno a 1043 casi l’anno, con un intervallo di credibilità al 94 % che va all’incirca da 1023 a 1062.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#visualizzare-la-distribuzione-a-posteriori",
    "href": "chapters/linear_models/13_poisson_model.html#visualizzare-la-distribuzione-a-posteriori",
    "title": "\n75  Modello di Poisson\n",
    "section": "\n75.9 Visualizzare la distribuzione a posteriori",
    "text": "75.9 Visualizzare la distribuzione a posteriori\nUn grafico spesso vale più di mille numeri. Con ggplot2 e il tema che abbiamo impostato all’inizio la figura è pronta in tre righe:\n\nposterior_lambda |&gt;\n  ggplot(aes(x = lambda)) +\n  stat_halfeye(fill = \"skyblue\", alpha = 0.6) +\n  labs(\n    title = \"Distribuzione a posteriori del tasso λ\",\n    x = \"Tasso annuo di sparatorie fatali (λ)\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\nL’area più scura al centro dell’half‑eye mette in evidenza l’intervallo più denso del 50 %; l’intera “pena” laterale dell’arco rappresenta invece il 94 %.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#unestensione-confronto-tra-gruppi",
    "href": "chapters/linear_models/13_poisson_model.html#unestensione-confronto-tra-gruppi",
    "title": "\n75  Modello di Poisson\n",
    "section": "\n75.10 Un’estensione: confronto tra gruppi",
    "text": "75.10 Un’estensione: confronto tra gruppi\nFinora abbiamo trattato tutte le sparatorie fatali come se provenissero da un’unica popolazione. Una domanda molto concreta, invece, è se il tasso di vittime disarmate differisce tra persone classificate come bianche (codice W nel dataset) e tutte le altre. Per rispondere ci basta duplicare lo schema già usato: al posto di un solo tasso medio (λ) ne stimiamo due, uno per ciascun gruppo.\n\n75.10.1 Costruire il dataset\nIl primo passo è filtrare le righe che ci interessano (vittime disarmate) e poi contare, per ogni anno, quante di queste vittime appartengono a ciascun gruppo. Il codice qui sotto svolge tutto il lavoro di preparazione in un’unica catena di operazioni:\n\nurl &lt;- \"https://raw.githubusercontent.com/washingtonpost/data-police-shootings/master/v2/fatal-police-shootings-data.csv\"\n\ndf_groups &lt;- read.csv(url, stringsAsFactors = FALSE) |&gt;\n  dplyr::mutate(\n    date  = as.Date(date),\n    year  = lubridate::year(date),\n    group = dplyr::if_else(race == \"W\", \"White\", \"NonWhite\")\n  ) |&gt;\n  dplyr::filter(year &lt; 2025, armed_with == \"unarmed\") |&gt;\n  dplyr::count(year, group, name = \"events\")\n\nIn df_groups ogni riga è l’abbinamento tra un anno e un gruppo, con il relativo conteggio di vittime disarmate.\n\n75.10.2 Specificare il modello\nLa formula events ~ 0 + group dice a brms di rinunciare a un’intercetta comune e di stimarne una diversa per ogni valore di group. Poiché l’intercetta è, in scala logaritmica, il nostro parametro centrale, otteniamo due log‑tassi distinti.\nPer la prior partiamo dall’idea che, in ciascun gruppo, potremmo aspettarci circa trenta vittime disarmate l’anno ma con incertezza ampia. Lavorando nella scala log questo si traduce in una distribuzione Normale con media 3.4 e deviazione 0.3 applicata indistintamente alle due intercette:\n\nprior_race &lt;- prior(normal(3.4, 0.3), class = \"b\")\n\nIl modello completo è ora immediato:\n\nm_groups &lt;- brm(\n  events ~ 0 + group,\n  family  = poisson(),\n  data    = df_groups,\n  prior   = prior_race,\n  iter    = 3000, warmup = 1000, chains = 4,\n  backend = \"cmdstanr\", seed = 123\n)\n\n\n75.10.3 Dal log‑tasso al tasso annuale\nDopo aver controllato che tutti gli indicatori di convergenza (in particolare R‑hat) siano a posto, trasformiamo i campioni posteriori con l’esponenziale così da tornare alla scala dei tassi veri e propri:\n\npost &lt;- as_draws_df(m_groups) |&gt;\n  dplyr::transmute(\n    lambda_White    = exp(b_groupWhite),\n    lambda_NonWhite = exp(b_groupNonWhite),\n    diff_lambda     = lambda_NonWhite - lambda_White\n  )\n\nCon tidybayes riassumiamo in una riga le quantità d’interesse, usando ad esempio un intervallo di credibilità al 94 %:\n\npost |&gt;\n  median_qi(lambda_White, lambda_NonWhite, diff_lambda, .width = 0.94)\n#&gt; # A tibble: 1 × 12\n#&gt;   lambda_White lambda_White.lower lambda_White.upper lambda_NonWhite\n#&gt;          &lt;dbl&gt;              &lt;dbl&gt;              &lt;dbl&gt;           &lt;dbl&gt;\n#&gt; 1         22.5               19.9               25.4            34.1\n#&gt;   lambda_NonWhite.lower lambda_NonWhite.upper diff_lambda diff_lambda.lower\n#&gt;                   &lt;dbl&gt;                 &lt;dbl&gt;       &lt;dbl&gt;             &lt;dbl&gt;\n#&gt; 1                  30.9                  37.6        11.6              7.21\n#&gt;   diff_lambda.upper .width .point .interval\n#&gt;               &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    \n#&gt; 1              16.0   0.94 median qi\n\nNe risulta che il gruppo NonWhite registra in media circa 12 vittime disarmate in più l’anno rispetto al gruppo White; l’intero intervallo di credibilità rimane sopra lo zero, perciò l’ipotesi di un tasso maggiore fra le persone non bianche è fortemente supportata dai dati.\nCon due soli cambiamenti – la variabile group nella formula e una prior ragionevole per ciascun gruppo – abbiamo esteso il modello di Poisson a una comparazione fra categorie. Tutto il resto resta identico: link logaritmico, diagnostica delle catene, trasformazione a valle dei campioni. Una volta compreso questo meccanismo, aggiungere ulteriori gruppi o predittori diventa un esercizio di routine.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#riflessioni-conclusive",
    "href": "chapters/linear_models/13_poisson_model.html#riflessioni-conclusive",
    "title": "\n75  Modello di Poisson\n",
    "section": "\n75.11 Riflessioni Conclusive",
    "text": "75.11 Riflessioni Conclusive\nIl modello di Poisson con prior informativa e link logaritmico è un punto di partenza potente e relativamente semplice per modellare conteggi. L’implementazione in brms riduce la complessità sintattica al minimo, ma non per questo dobbiamo tralasciare di capire cosa accade dietro le quinte:\n\n\n\\(\\lambda\\) è il vero protagonista, ma viene stimato indirettamente tramite la sua trasformazione logaritmica.\nLa scelta della prior su b_Intercept va fatta nella scala log, pensando però a cosa significa nella scala originale.\nUna volta compreso il passaggio dall’intercetta logaritmica al tasso \\(\\lambda\\), è possibile arricchire il modello con più predittori, sapendo esattamente come trasformare il modello.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#esercizi",
    "href": "chapters/linear_models/13_poisson_model.html#esercizi",
    "title": "\n75  Modello di Poisson\n",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nNella finale olimpica di calcio 2024, la Spagna ha sconfitto la Francia per 5 a 3. Supponiamo di voler calcolare la probabilità di superiorità della Spagna rispetto alla Francia utilizzando un modello coniugato Gamma-Poisson (o l’approssimazione brms con prior lognormale).\n\nConsidera che il numero di gol segnati da una squadra segua una Poisson con parametro \\(\\lambda\\).\n\nSpecifica un prior su \\(\\lambda\\) per entrambe le squadre, ad esempio \\(\\alpha=1\\) e \\(\\beta=1\\) nella parametrizzazione Gamma classica (oppure una Normal(0,1.4) sull’intercetta, in modo da avere una media a posteriori analoga).\n\nAggiorna la distribuzione a posteriori conoscendo i gol segnati (5 per la Spagna e 3 per la Francia in una singola partita).\n\nCalcola la probabilità che \\(\\lambda_{\\text{Spagna}} &gt; \\lambda_{\\text{Francia}}\\).\n\n(Ispirato a “The World Cup Problem”, (Downey, 2021).)\nSuggerimento: puoi risolvere il problema in modo analitico (Gamma-Poisson con un solo conteggio) oppure puoi usare brms costruendo un dataframe:\n\ndf_soccer &lt;- data.frame(\n  team = c(\"Spain\", \"France\"),\n  goals = c(5, 3)\n)\n\n\nModello: goals ~ 0 + team, family=poisson().\nPrior su b_teamSpain e b_teamFrance.\nInfine, estrai i draws e calcola la probabilità \\(\\Pr(\\exp(b_{\\text{Spain}}) &gt; \\exp(b_{\\text{France}}))\\).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/13_poisson_model.html#informazioni-sullambiente-di-sviluppo",
    "title": "\n75  Modello di Poisson\n",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] tidybayes_3.0.7  brms_2.22.0      Rcpp_1.0.14      HDInterval_0.2.4\n#&gt;  [5] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [9] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.12.0 psych_2.5.3     \n#&gt; [13] scales_1.4.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [17] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [21] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.2   \n#&gt; [25] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1     svUnit_1.0.6         farver_2.1.2        \n#&gt;  [4] loo_2.8.0            fastmap_1.2.0        tensorA_0.36.2.1    \n#&gt;  [7] pacman_0.5.1         digest_0.6.37        timechange_0.3.0    \n#&gt; [10] estimability_1.5.1   lifecycle_1.0.4      StanHeaders_2.32.10 \n#&gt; [13] processx_3.8.6       magrittr_2.0.3       posterior_1.6.1     \n#&gt; [16] compiler_4.5.0       rlang_1.1.6          tools_4.5.0         \n#&gt; [19] utf8_1.2.5           yaml_2.3.10          data.table_1.17.2   \n#&gt; [22] labeling_0.4.3       bridgesampling_1.1-2 htmlwidgets_1.6.4   \n#&gt; [25] curl_6.2.2           pkgbuild_1.4.7       mnormt_2.1.1        \n#&gt; [28] RColorBrewer_1.1-3   cmdstanr_0.9.0       abind_1.4-8         \n#&gt; [31] withr_3.0.2          stats4_4.5.0         grid_4.5.0          \n#&gt; [34] colorspace_2.1-1     inline_0.3.21        xtable_1.8-4        \n#&gt; [37] emmeans_1.11.1       cli_3.6.5            mvtnorm_1.3-3       \n#&gt; [40] rmarkdown_2.29       generics_0.1.4       RcppParallel_5.1.10 \n#&gt; [43] rstudioapi_0.17.1    tzdb_0.5.0           rstan_2.32.7        \n#&gt; [46] parallel_4.5.0       matrixStats_1.5.0    vctrs_0.6.5         \n#&gt; [49] V8_6.0.3             Matrix_1.7-3         jsonlite_2.0.0      \n#&gt; [52] hms_1.1.3            arrayhelpers_1.1-0   ggdist_3.3.3        \n#&gt; [55] glue_1.8.0           codetools_0.2-20     ps_1.9.1            \n#&gt; [58] distributional_0.5.0 stringi_1.8.7        gtable_0.3.6        \n#&gt; [61] QuickJSR_1.7.0       pillar_1.10.2        htmltools_0.5.8.1   \n#&gt; [64] Brobdingnag_1.2-9    R6_2.6.1             rprojroot_2.0.4     \n#&gt; [67] evaluate_1.0.3       lattice_0.22-7       backports_1.5.0     \n#&gt; [70] rstantools_2.4.0     coda_0.19-4.1        nlme_3.1-168        \n#&gt; [73] checkmate_2.3.2      xfun_0.52            pkgconfig_2.0.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#bibliografia",
    "href": "chapters/linear_models/13_poisson_model.html#bibliografia",
    "title": "\n75  Modello di Poisson\n",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nDowney, A. B. (2021). Think Bayes. \" O’Reilly Media, Inc.\".\n\n\nRoss, C. T., Winterhalder, B., & McElreath, R. (2021). Racial disparities in police use of deadly force against unarmed individuals persist after appropriately benchmarking shooting data on violent crime rates. Social Psychological and Personality Science, 12(3), 323–332.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/introduction_frequentist_inference.html",
    "href": "chapters/frequentist_inference/introduction_frequentist_inference.html",
    "title": "Introduzione",
    "section": "",
    "text": "Differenze fondamentali tra i due approcci\nCome discusso nel capitolo dedicato all’interpretazione delle probabilità (25  Interpretazione della probabilità), esistono due principali approcci nell’inferenza statistica: la statistica frequentista e la statistica bayesiana. Entrambi i metodi consentono di trarre conclusioni sulla popolazione di interesse attraverso l’analisi dei dati e vengono utilizzati per stimare quantità sconosciute, formulare previsioni e testare ipotesi. Tuttavia, differiscono nell’interpretazione della probabilità e nel modo in cui integrano le conoscenze pregresse e le evidenze disponibili.",
    "crumbs": [
      "Frequentismo",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/introduction_frequentist_inference.html#differenze-fondamentali-tra-i-due-approcci",
    "href": "chapters/frequentist_inference/introduction_frequentist_inference.html#differenze-fondamentali-tra-i-due-approcci",
    "title": "Introduzione",
    "section": "",
    "text": "Statistica frequentista\nNella statistica frequentista, la probabilità è interpretata come la frequenza relativa di un evento in un numero infinito di prove. Questo approccio assume che il valore vero di un parametro della popolazione sia fisso ma sconosciuto e che debba essere stimato esclusivamente dai dati osservati. Le inferenze statistiche vengono effettuate attraverso metodi quali:\n\nStima puntuale: fornisce un singolo valore come miglior stima del parametro.\nIntervalli di confidenza: definiscono un intervallo in cui il parametro si trova con una data probabilità, sotto ripetute campionature.\nTest di ipotesi: valutano la compatibilità dei dati con un’ipotesi nulla, attraverso il calcolo di p-value e statistiche test.\n\nQuesto approccio si basa su assunzioni riguardanti il processo che genera i dati e sull’idea che la verità statistica emerga dal comportamento asintotico di esperimenti ripetuti.\n\n\nStatistica bayesiana\nNella statistica bayesiana, la probabilità rappresenta un grado di credenza in un evento, soggetto ad aggiornamento alla luce di nuove evidenze (Jaynes, 2003). Questo approccio si fonda sull’applicazione del teorema di Bayes, che consente di aggiornare la conoscenza su un parametro in base ai dati osservati.\n\nIl valore del parametro è trattato come una variabile casuale con una distribuzione di probabilità.\nL’analisi parte da una distribuzione a priori, che rappresenta la conoscenza precedente.\nI nuovi dati vengono combinati con la distribuzione a priori tramite la verosimiglianza (likelihood).\nIl risultato è la distribuzione a posteriori, che sintetizza l’incertezza aggiornata sul parametro.\n\nQuesto approccio permette di incorporare informazioni pregresse ed è particolarmente utile in contesti con dati limitati o conoscenze precedenti rilevanti.",
    "crumbs": [
      "Frequentismo",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/introduction_frequentist_inference.html#il-problema-dellinduzione-di-hume",
    "href": "chapters/frequentist_inference/introduction_frequentist_inference.html#il-problema-dellinduzione-di-hume",
    "title": "Introduzione",
    "section": "Il problema dell’induzione di Hume",
    "text": "Il problema dell’induzione di Hume\nUna prospettiva utile per comprendere la differenza tra questi due approcci è il problema dell’induzione, formulato da David Hume nel 1739 nel suo A Treatise of Human Nature (Hacking, 2006). Hume solleva un dubbio fondamentale: come possiamo giustificare le inferenze dal passato al futuro? Nessuna quantità di osservazioni passate garantisce che il futuro seguirà lo stesso schema.\n\nL’approccio frequentista presuppone implicitamente che il mondo segua regolarità statistiche costanti. Tuttavia, questo assunto è vulnerabile alle critiche di Hume, poiché non offre una giustificazione epistemica all’estrapolazione del passato.\nL’approccio bayesiano integra l’incertezza nell’inferenza: la probabilità di un evento futuro è un riflesso delle nostre credenze attuali e viene aggiornata alla luce di nuove osservazioni. Questo approccio si adatta meglio a situazioni in cui il mondo potrebbe non seguire regolarità fisse.",
    "crumbs": [
      "Frequentismo",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/introduction_frequentist_inference.html#un-esempio-pratico-il-lancio-di-una-moneta",
    "href": "chapters/frequentist_inference/introduction_frequentist_inference.html#un-esempio-pratico-il-lancio-di-una-moneta",
    "title": "Introduzione",
    "section": "Un esempio pratico: il lancio di una moneta",
    "text": "Un esempio pratico: il lancio di una moneta\nConsideriamo il classico esempio del lancio di una moneta per illustrare le differenze tra i due approcci:\n\nFrequentista: definisce la probabilità di ottenere testa come la proporzione di teste osservate in un numero infinito di lanci. La probabilità è una proprietà intrinseca della moneta, indipendente dalle credenze dell’osservatore.\nBayesiano: parte da una distribuzione a priori sulla probabilità della moneta di cadere su testa. Dopo ogni lancio, aggiorna la credenza utilizzando la verosimiglianza, ottenendo una nuova distribuzione a posteriori. Questo metodo riflette un aggiornamento razionale delle credenze alla luce di nuove osservazioni.\n\nL’approccio bayesiano è quindi più flessibile e coerente con la prospettiva di Hume: accetta l’incertezza del futuro e la gestisce attraverso un meccanismo di aggiornamento continuo.",
    "crumbs": [
      "Frequentismo",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/introduction_frequentist_inference.html#obiettivo-di-questa-sezione",
    "href": "chapters/frequentist_inference/introduction_frequentist_inference.html#obiettivo-di-questa-sezione",
    "title": "Introduzione",
    "section": "Obiettivo di questa sezione",
    "text": "Obiettivo di questa sezione\nIn questa sezione della dispensa, esamineremo in dettaglio i metodi della statistica frequentista, tra cui la stima puntuale, gli intervalli di confidenza e il test di ipotesi. Questi strumenti costituiscono il nucleo dell’inferenza statistica tradizionale e offrono un quadro solido per analizzare i dati in assenza di informazioni pregresse. Tuttavia, come evidenziato dal problema di Hume, ogni approccio ha i suoi limiti e presupposti. La scelta tra frequentismo e bayesianesimo dipende dal contesto e dagli obiettivi dell’analisi.",
    "crumbs": [
      "Frequentismo",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/introduction_frequentist_inference.html#bibliografia",
    "href": "chapters/frequentist_inference/introduction_frequentist_inference.html#bibliografia",
    "title": "Introduzione",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nHacking, I. (2006). The emergence of probability: A philosophical study of early ideas about probability, induction and statistical inference. Cambridge University Press.\n\n\nJaynes, E. T. (2003). Probability theory: The logic of science. Cambridge University Press.",
    "crumbs": [
      "Frequentismo",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html",
    "title": "76  Inferenza frequentista",
    "section": "",
    "text": "76.1 Introduzione\nIn questo capitolo esamineremo le radici storiche della statistica frequentista e le sue connessioni con il movimento eugenetico. Vedremo come alcune idee sviluppate nel contesto di questa corrente abbiano influenzato l’elaborazione dei metodi statistici che molti di noi utilizzano ancora oggi.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>Inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#i-frequentisti-sono-razzisti",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#i-frequentisti-sono-razzisti",
    "title": "76  Inferenza frequentista",
    "section": "\n76.2 I Frequentisti sono Razzisti?",
    "text": "76.2 I Frequentisti sono Razzisti?\nNel Capitolo 30, abbiamo esplorato le origini storiche e il contesto culturale che hanno portato all’interpretazione del teorema di Bayes proposta da Richard Price. Quelle origini, legate alla rivoluzione americana, rappresentano il “lato luminoso” del liberalismo moderno.\nLe origini dell’approccio frequentista, invece, si collocano agli antipodi: sono strettamente intrecciate con ciò che potremmo definire la “parte oscura” della modernità. L’avversione per la soggettività, tipica del frequentismo, riflette una visione più rigida e deterministica, distante dall’apertura e dalla flessibilità del pensiero bayesiano.\n\n76.2.1 Francis Galton e l’Eugenetica\nFrancis Galton (1822-1911), cugino di Charles Darwin, fu un esploratore, un medico e un pioniere della meteorologia. Ma il suo contributo più importante, e anche più controverso, riguardò la statistica e lo studio dell’ereditarietà del talento.\n\n\nDistribuzione Normale e Regressione\nGalton formalizzò la distribuzione normale e introdusse il concetto di “regressione verso la media”, chiamata inizialmente “regressione verso la mediocrità”.\n\n\nHereditary Genius\nNel suo libro Hereditary Genius, Galton sosteneva che il talento fosse trasmesso all’interno di specifiche famiglie. Fu lui a coniare la famosa espressione “nature and nurture” per indicare il ruolo combinato di eredità e ambiente nello sviluppo umano.\n\n\nEugenetica\nGalton mirava a “migliorare la specie umana” promuovendo la riproduzione tra famiglie ritenute “di successo” e scoraggiandola tra quelle considerate “inferiori”. Le sue idee, fortemente razziste, includevano l’idea che gli africani fossero “inferiori” e “pigri”, gli arabi “semplici consumatori della produzione altrui” e che gli anglosassoni fossero la “razza superiore”.\n\n76.2.2 L’Impatto di Galton su Pearson e Fisher\nLe teorie di Galton influenzarono Karl Pearson (1857-1936) e Ronald Fisher (1890-1962), due figure chiave della statistica moderna. Entrambi condividevano idee razziste e appoggiavano l’eugenetica:\n\n\nKarl Pearson\nProfessore all’University College di Londra, sviluppò strumenti come il test del chi quadrato e la deviazione standard. Ereditò la cattedra di eugenetica fondata da Galton.\n\n\nRonald Fisher\nConsiderato uno dei padri della statistica moderna, sviluppò l’analisi della varianza (ANOVA), il concetto di significatività statistica e il metodo della massima verosimiglianza (MLE).\n\nQuesti autori cercarono di allontanare la statistica dalla prospettiva di Laplace e Bayes, rifiutando l’idea di introdurre componenti soggettive nella loro “scienza”. Volevano che la statistica apparisse del tutto “oggettiva” per sostenere teorie eugenetiche e gerarchie razziali come se fossero dimostrate scientificamente.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>Inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#implicazioni-per-le-pratiche-correnti",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#implicazioni-per-le-pratiche-correnti",
    "title": "76  Inferenza frequentista",
    "section": "\n76.3 Implicazioni per le Pratiche Correnti",
    "text": "76.3 Implicazioni per le Pratiche Correnti\nIn che misura dovremmo considerare le implicazioni storiche ed etiche del frequentismo quando lo utilizziamo oggi? Secondo (Chivers, 2024), sebbene sia evidente che l’ideologia razziale nazista possa essere collegata alle idee di Galton, la questione centrale in statistica rimane: “Quale approccio è metodologicamente corretto?” o, più pragmaticamente, “Quale approccio è più utile?”.\nTuttavia, limitarsi a un dibattito puramente metodologico rischia di trascurare il fatto che la scienza non si svolge in una “torre d’avorio” astratta, ma ha conseguenze concrete. Se una teoria A, pur essendo efficace in uno scenario ideale, ha effetti profondamente negativi nella realtà, dovremmo davvero adottarla acriticamente? La risposta, per molti, è no.\nNel caso del frequentismo, non solo emergono questioni etiche, ma – come vedremo in seguito – si evidenziano anche limiti metodologici. La sua pretesa di “oggettività” si rivela un’illusione quando si analizza in profondità il funzionamento reale delle procedure inferenziali. In psicologia, dove la variabilità individuale e le questioni etiche sono centrali, questi difetti possono avere conseguenze particolarmente dannose.\n\n\n\n\n\n\nNota didattica: L’approccio frequentista viene presentato qui soprattutto per mostrare perché il suo uso esclusivo sia problematico. In questo capitolo descriveremo i fondamenti statistici del frequentismo e la logica delle sue procedure inferenziali. Nel capitoli successivi discuteremo invece come le sue applicazioni pratiche possano ostacolare il progresso della psicologia.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>Inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#il-paradigma-frequentista",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#il-paradigma-frequentista",
    "title": "76  Inferenza frequentista",
    "section": "\n76.4 Il Paradigma Frequentista",
    "text": "76.4 Il Paradigma Frequentista\nL’obiettivo della statistica frequentista è trarre conclusioni su un’intera popolazione partendo da un campione di dati. In questo contesto:\n\nI dati osservati vengono considerati come un’estrazione casuale (un “campione”) da una popolazione più ampia.\n\nIl modello statistico assume che esista un processo generatore dei dati, descritto da una distribuzione di probabilità.\n\nQuando raccogliamo un campione di dati, dobbiamo tenere presente che avremmo potuto ottenere molti altri campioni diversi (il principio di ripetizione del campionamento).\n\n\n76.4.1 Probabilità e Ripetizione del Campionamento\nIl frequentismo adotta un’interpretazione della probabilità basata sulle frequenze: se ripetessimo un esperimento moltissime volte, la probabilità di un evento sarebbe il rapporto tra il numero di volte in cui l’evento si verifica e il numero totale di prove.\n\n76.4.2 Stima di un Parametro\nSupponiamo di voler stimare un parametro (ad esempio, la media di una popolazione). Il frequentismo cerca un stimatore – una funzione del campione – che abbia determinate proprietà, tra cui l’assenza di distorsione (l’unbiasedness) e la consistenza (la vicinanza alla realtà con l’aumentare del numero di dati).\nUn esempio comune è la stima della media della popolazione tramite la media del campione. Sotto certe condizioni, si può dimostrare che, ripetendo l’esperimento moltissime volte, la media del campione in media coinciderà con la vera media della popolazione.\n\n76.4.3 Intervalli di Confidenza\nNell’approccio frequentista, invece di fornire un singolo valore come stima di un parametro, si costruisce un intervallo di confidenza. L’idea fondamentale è che, se ripetessimo molte volte la stessa procedura di campionamento e di calcolo dell’intervallo, una certa percentuale di questi (ad esempio il 95%) conterrà effettivamente il valore vero del parametro.\nPrima di raccogliere i dati, gli estremi di questo intervallo (i “limiti di confidenza”) sono variabili casuali, perché dipendono dal campione che otterremo. Di conseguenza, la probabilità (per esempio, il 95%) si riferisce alla procedura di costruzione dell’intervallo, non all’intervallo in sé dopo l’osservazione dei dati. Una volta infatti che il campione è stato raccolto e l’intervallo è stato calcolato, quest’ultimo è un oggetto “fisso”: o contiene il valore vero del parametro, o non lo contiene; non è più possibile attribuirgli una probabilità di contenere il parametro. L’affermazione “intervallo di confidenza al 95%” significa dunque che, sul lungo periodo, usando sempre la stessa procedura, il 95% degli intervalli costruiti conterrà il parametro vero.\n\n76.4.4 Test delle Ipotesi: Approccio Frequentista e Limitazioni\nNel contesto del test di un’ipotesi (ad esempio, \\(H_0\\): “la media di una popolazione è uguale a 0”), l’approccio frequentista definisce una regione di rifiuto in base a un livello di significatività prefissato (ad esempio, \\(\\alpha = 0.05\\)). Se il risultato dell’analisi (come il p-value) cade all’interno di questa regione, si procede a rifiutare \\(H_0\\); altrimenti, si manca di rifiutare \\(H_0\\) (ovvero, non si rifiuta l’ipotesi nulla).\n\n\nErrore di tipo I (falso positivo): si verifica quando si rifiuta \\(H_0\\) nonostante essa sia vera.\n\n\nErrore di tipo II (falso negativo): si verifica quando non si rifiuta \\(H_0\\) nonostante essa sia falsa.\n\nNel paradigma frequentista, il ricercatore controlla la probabilità di questi errori, in particolare l’errore di tipo I, attraverso la scelta di \\(\\alpha\\) e il calcolo di indicatori come il p-value. Tuttavia, questo approccio presenta alcune criticità:\n\nDecisione dicotomica\nIl test conduce a una scelta binaria (rifiutare o non rifiutare \\(H_0\\)), che può risultare eccessivamente rigida. I fenomeni reali spesso non si prestano a una categorizzazione netta basata su una soglia arbitraria, rendendo la distinzione “significativo/non significativo” potenzialmente fuorviante. Una visione più sfumata, che consideri l’entità dell’effetto e l’incertezza, potrebbe essere più informativa.\nSoglia arbitraria\nIl valore di \\(\\alpha\\) (comunemente fissato a 0.05) è in gran parte una convenzione. Ad esempio, un valore-p di 0.049 porta al rifiuto di \\(H_0\\), mentre un valore-p di 0.051 non lo fa, nonostante la differenza tra i due casi sia minima. Questa arbitrarietà può influenzare in modo significativo l’interpretazione dei risultati, creando una discontinuità artificiale.\nNessuna prova diretta di verità/falsità\nUn valore-p basso non implica che \\(H_0\\) sia “falsa” o che un’ipotesi alternativa sia “vera”. Indica semplicemente che, assumendo \\(H_0\\) vera, dati simili (o più estremi) sarebbero rari sotto ripetuti campionamenti. Il test frequentista non fornisce una risposta alla domanda “Qual è la probabilità che \\(H_0\\) sia vera?”, limitando la sua capacità di supportare inferenze dirette sulla veridicità delle ipotesi.\n\nQueste criticità evidenziano come la rigidità del test (basato su una decisione binaria) e l’uso di soglie fisse possano risultare problematici, specialmente in discipline come la psicologia, dove le misurazioni sono spesso affette da rumore e le differenze tra condizioni possono essere sottili. Un approccio più flessibile, che integri la stima degli effetti, gli intervalli di confidenza e una valutazione contestuale, potrebbe offrire una comprensione più robusta e sfumata dei dati.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>Inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#riflessioni-conclusive",
    "title": "76  Inferenza frequentista",
    "section": "\n76.5 Riflessioni Conclusive",
    "text": "76.5 Riflessioni Conclusive\nIn questo capitolo abbiamo mostrato come la statistica frequentista, pur essendo stata un pilastro dell’inferenza moderna, affondi le proprie radici in idee profondamente problematiche, come l’eugenetica e il razzismo sostenuti da Galton, Pearson e Fisher. Sebbene oggi queste teorie sembrino superate e distanti dalle nostre pratiche di laboratorio, conoscerne la genesi aiuta a comprendere come l’idea di un’oggettività assoluta sia stata impiegata per legittimare visioni ideologiche discutibili.\nParallelamente, la riflessione storica solleva interrogativi sul metodo e sulle sue implicazioni pratiche. La metafora della “torre d’avorio” mostra quanto sia pericoloso trattare la scienza come un sistema chiuso, ignorando le conseguenze etiche e sociali. Nel campo della psicologia, in particolare, la crisi di replicabilità (McElreath, 2020) rivela come l’uso acritico di procedure frequentiste possa influire sulla validità dei risultati.\nIn definitiva, il frequentismo non va considerato solo come un insieme di tecniche, ma come un paradigma con implicazioni culturali, etiche e metodologiche. Nel prossimo capitolo mostreremo come le applicazioni pratiche dell’approccio frequentista possano risultare limitanti e, talvolta, dannose per il progresso della psicologia (Gelman et al., 1995). Conoscere le basi e le implicazioni di tale paradigma è il primo passo per un uso più consapevole e responsabile degli strumenti statistici.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>Inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#informazioni-sullambiente-di-sviluppo",
    "title": "76  Inferenza frequentista",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.12.0 psych_2.5.3     \n#&gt;  [9] scales_1.4.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.2   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.4     stringi_1.8.7      lattice_0.22-7    \n#&gt;  [4] hms_1.1.3          digest_0.6.37      magrittr_2.0.3    \n#&gt;  [7] evaluate_1.0.3     grid_4.5.0         timechange_0.3.0  \n#&gt; [10] RColorBrewer_1.1-3 fastmap_1.2.0      rprojroot_2.0.4   \n#&gt; [13] jsonlite_2.0.0     mnormt_2.1.1       cli_3.6.5         \n#&gt; [16] rlang_1.1.6        withr_3.0.2        tools_4.5.0       \n#&gt; [19] parallel_4.5.0     tzdb_0.5.0         pacman_0.5.1      \n#&gt; [22] vctrs_0.6.5        R6_2.6.1           lifecycle_1.0.4   \n#&gt; [25] htmlwidgets_1.6.4  pkgconfig_2.0.3    pillar_1.10.2     \n#&gt; [28] gtable_0.3.6       glue_1.8.0         xfun_0.52         \n#&gt; [31] tidyselect_1.2.1   rstudioapi_0.17.1  farver_2.1.2      \n#&gt; [34] htmltools_0.5.8.1  nlme_3.1-168       rmarkdown_2.29    \n#&gt; [37] compiler_4.5.0",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>Inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#bibliografia",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#bibliografia",
    "title": "76  Inferenza frequentista",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nChivers, T. (2024). Everything is Predictable: How Bayesian Statistics Explain Our World. Simon; Schuster.\n\n\nGelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (1995). Bayesian data analysis. Chapman; Hall/CRC.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>Inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01a_stime_parametri.html",
    "href": "chapters/frequentist_inference/01a_stime_parametri.html",
    "title": "77  Stime, stimatori e parametri",
    "section": "",
    "text": "77.1 Introduzione\nIn questo capitolo, ci concentreremo sul concetto di distribuzione campionaria, uno dei pilastri dell’inferenza statistica frequentista. La distribuzione campionaria descrive come le stime dei parametri della popolazione, come la media o la varianza, variano da campione a campione. Essa permette di stabilire proprietà probabilistiche delle stime campionarie, come la loro media e varianza, che sono fondamentali per costruire intervalli di confidenza e condurre test di ipotesi, strumenti essenziali dell’inferenza statistica frequentista.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01a_stime_parametri.html#introduzione",
    "href": "chapters/frequentist_inference/01a_stime_parametri.html#introduzione",
    "title": "77  Stime, stimatori e parametri",
    "section": "",
    "text": "Domande introduttive\n\n\n\nPrima di iniziare a esplorare il concetto di distribuzione campionaria e il suo ruolo nell’inferenza statistica, considera le seguenti domande. Prova a formulare una risposta intuitiva basata sulle tue conoscenze attuali prima di procedere con la lettura del capitolo. Le simulazioni che seguiranno ti aiuteranno a confermare o rivedere le tue risposte.\n\nSe estraiamo ripetutamente campioni casuali dalla stessa popolazione e calcoliamo la loro media, come saranno distribuite queste medie campionarie rispetto alla media della popolazione?\nSupponiamo di estrarre campioni di dimensione \\(n=2\\) da una popolazione. L’insieme delle medie campionarie sarà più concentrato intorno alla media della popolazione rispetto ai valori individuali della popolazione stessa?\nQuale relazione esiste tra la dimensione del campione \\(n\\) e la variabilità delle medie campionarie? In altre parole, se aumentiamo la dimensione del campione, cosa succede alla dispersione della distribuzione campionaria?\nLa distribuzione campionaria della media campionaria sarà sempre normale? Quali fattori influenzano la sua forma?\nLa media della distribuzione campionaria coincide sempre con la media della popolazione? E la sua varianza è maggiore o minore rispetto alla varianza della popolazione?\nSupponiamo di estrarre piccoli campioni da una popolazione che ha una distribuzione fortemente asimmetrica. Quale forma avrà la distribuzione delle medie campionarie per piccoli campioni? E per campioni più grandi?",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01a_stime_parametri.html#stime-stimatori-e-parametri",
    "href": "chapters/frequentist_inference/01a_stime_parametri.html#stime-stimatori-e-parametri",
    "title": "77  Stime, stimatori e parametri",
    "section": "\n77.2 Stime, stimatori e parametri",
    "text": "77.2 Stime, stimatori e parametri\nDopo aver esplorato il contesto culturale del frequentismo nel capitolo precedente, ci spostiamo ora su un piano strettamente statistico per introdurre il concetto di stima statistica.\nQuando si analizzano i dati, l’obiettivo è spesso quello di ottenere informazioni su una caratteristica della popolazione. Tuttavia, nella maggior parte dei casi, si ha accesso solo a un campione di osservazioni. La quantità sconosciuta che vogliamo stimare viene chiamata parametro, mentre il valore che calcoliamo dal campione per approssimare questo parametro è la stima. La formula o il procedimento matematico che utilizziamo per ottenere la stima è detto stimatore. Formalmente, uno stimatore è una funzione dei dati osservati utilizzata per produrre una stima di un parametro.\nIn altre parole, quando analizziamo un campione, cerchiamo di inferire proprietà della popolazione da cui il campione è tratto. Il parametro rappresenta una misura di queste proprietà, ma raramente può essere calcolato direttamente sulla popolazione intera. Pertanto, utilizziamo le osservazioni campionarie per ottenere una stima del parametro. La stima è quindi un’approssimazione del valore del parametro basata sui dati raccolti, mentre lo stimatore è la regola matematica o statistica che la produce.\nÈ importante sottolineare che le stime non coincidono necessariamente con il vero valore del parametro, poiché sono soggette a incertezza dovuta alla variabilità del campionamento. In questo capitolo esamineremo come l’approccio frequentista quantifica questa incertezza e come possiamo utilizzare tale quantificazione per trarre conclusioni affidabili sui parametri di interesse.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01a_stime_parametri.html#distribuzione-campionaria",
    "href": "chapters/frequentist_inference/01a_stime_parametri.html#distribuzione-campionaria",
    "title": "77  Stime, stimatori e parametri",
    "section": "\n77.3 Distribuzione campionaria",
    "text": "77.3 Distribuzione campionaria\nNell’inferenza frequentista applicata alla psicologia, il parametro di maggiore interesse è spesso la media della popolazione—si veda anche la discussione nella Sezione 19.9.1. In questo capitolo esploreremo come la media di un campione casuale possa essere utilizzata per stimare la media \\(\\mu\\) di una popolazione. Per valutare l’incertezza associata a questa stima, introdurremo il concetto di distribuzione campionaria, un principio fondamentale dell’approccio frequentista.\nPer chiarire questa idea, inizieremo con un esempio basato su una popolazione finita di piccole dimensioni, pur consapevoli che le proprietà illustrate si estendono anche a popolazioni di dimensioni maggiori.\n\n77.3.1 Esempio introduttivo\nConsideriamo la seguente popolazione:\n\nx &lt;- c(2, 4.5, 5, 5.5)\nx\n#&gt; [1] 2.0 4.5 5.0 5.5\n\nQuesti valori potrebbero rappresentare il tempo di reazione (in secondi) di quattro partecipanti a un esperimento di decisione rapida, in cui devono identificare il colore di uno stimolo visivo. In questo caso, l’intera popolazione è costituita da tutti i partecipanti disponibili per lo studio, ad esempio se l’esperimento è stato condotto in un piccolo gruppo di persone selezionate per caratteristiche specifiche, come quattro gemelli monozigoti in uno studio sulle differenze cognitive intra-familiari.\nL’istogramma sottostante rappresenta la distribuzione di frequenza della popolazione:\n\n# Creazione del dataframe\ndf &lt;- data.frame(Valori = c(2, 4.5, 5, 5.5))\n\n# Istogramma con ggplot2\nggplot(df, aes(x = Valori)) +\n  geom_histogram(bins = 5, aes(y = after_stat(density)), fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Distribuzione della popolazione\", x = \"Valori\", y = \"Densità\") \n\n\n\n\n\n\n\nCalcoliamo la media e la varianza della popolazione:\n\nmean(x)  # Media\n#&gt; [1] 4.25\nvar(x)   # Varianza\n#&gt; [1] 2.417\n\n\n77.3.2 Campionamento\nConsideriamo ora tutti i possibili campioni di dimensione \\(n = 2\\) che possiamo estrarre dalla popolazione. Poiché ogni valore può essere selezionato indipendentemente in entrambe le posizioni del campione, il numero totale di combinazioni possibili si ottiene con il calcolo combinatorio:\n\\[\n\\text{Numero totale di campioni} = k^n ,\n\\]\ndove \\(k\\) è la dimensione della popolazione e \\(n\\) è la dimensione del campione. Nel nostro caso, con \\(k = 4\\) e \\(n = 2\\), otteniamo:\n\\[\n4^2 = 16 .\n\\]\nPossiamo generare esplicitamente queste combinazioni con il seguente codice:\n\nsamples &lt;- expand.grid(x, x)\nsamples\n#&gt;    Var1 Var2\n#&gt; 1   2.0  2.0\n#&gt; 2   4.5  2.0\n#&gt; 3   5.0  2.0\n#&gt; 4   5.5  2.0\n#&gt; 5   2.0  4.5\n#&gt; 6   4.5  4.5\n#&gt; 7   5.0  4.5\n#&gt; 8   5.5  4.5\n#&gt; 9   2.0  5.0\n#&gt; 10  4.5  5.0\n#&gt; 11  5.0  5.0\n#&gt; 12  5.5  5.0\n#&gt; 13  2.0  5.5\n#&gt; 14  4.5  5.5\n#&gt; 15  5.0  5.5\n#&gt; 16  5.5  5.5\n\nOgni riga rappresenta un campione possibile. Confermiamo il numero totale di campioni con:\n\nnrow(samples)\n#&gt; [1] 16\n\nOra calcoliamo la media di ciascun campione, ottenendo la distribuzione campionaria delle medie per \\(n = 2\\):\n\nsample_means &lt;- rowMeans(samples)\nsample_means\n#&gt;  [1] 2.00 3.25 3.50 3.75 3.25 4.50 4.75 5.00 3.50 4.75 5.00 5.25 3.75 5.00\n#&gt; [15] 5.25 5.50\n\nQuesta distribuzione campionaria mostra tutte le possibili medie che possiamo ottenere estraendo campioni casuali di dimensione 2 dalla popolazione. Si tratta di un concetto fondamentale in inferenza statistica frequentista, poiché la distribuzione delle medie campionarie diventa progressivamente più simmetrica e concentrata attorno alla media della popolazione man mano che \\(n\\) aumenta, come previsto dal teorema del limite centrale.\n\n77.3.3 Visualizzazione della distribuzione campionaria\nPossiamo visualizzare la distribuzione campionaria delle medie con un istogramma:\n\n# Creazione del dataframe\ndf &lt;- data.frame(Valori = sample_means)\n\n# Istogramma con ggplot2\nggplot(df, aes(x = Valori)) +\n  geom_histogram(bins = 5, aes(y = after_stat(density)), fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Distribuzione campionaria delle medie (n = 2)\", x = \"Media campionaria\", y = \"Densità\") \n\n\n\n\n\n\n\nL’istogramma mostra come le medie campionarie non siano distribuite uniformemente, ma seguano una struttura precisa determinata dalla distribuzione dei valori originali della popolazione. Con un numero maggiore di osservazioni per campione (\\(n\\) più grande), la distribuzione campionaria delle medie tende a diventare più stretta e simmetrica attorno alla media della popolazione, illustrando così il principio alla base dell’inferenza statistica frequentista.\n\n77.3.4 Verifiche teoriche\n\n77.3.4.1 Media della distribuzione campionaria\nSecondo la teoria statistica, la media della distribuzione campionaria deve coincidere con la media della popolazione. Questo implica che, se prendiamo la media di tutti i campioni possibili di una certa dimensione, il valore risultante sarà uguale alla media della popolazione stessa. Possiamo verificarlo con il seguente calcolo:\n\nmean(x)  # Media della popolazione\n#&gt; [1] 4.25\nmean(sample_means)  # Media della distribuzione campionaria\n#&gt; [1] 4.25\n\n\n77.3.4.2 Varianza della distribuzione campionaria\nUn altro risultato importante è che la varianza della distribuzione campionaria delle medie è inferiore alla varianza della popolazione. In particolare, la teoria prevede che sia pari alla varianza della popolazione divisa per la dimensione del campione \\(n\\):\n\\[\n\\mathbb{V}(\\bar{X}) = \\frac{\\sigma^2}{n}\n\\]\nPoiché in questo caso \\(n = 2\\), confrontiamo la varianza teorica con quella empirica:\n\n# Funzione per calcolare la varianza senza la correzione di Bessel\nvariance &lt;- function(x) {\n  mean((x - mean(x))^2)\n}\n\n\nvariance(x) / 2  # Varianza teorica\n#&gt; [1] 0.9062\nvariance(sample_means)  # Varianza empirica\n#&gt; [1] 0.9062\n\nOsserviamo che la varianza delle medie campionarie è inferiore alla varianza della popolazione, confermando che le medie campionarie mostrano meno variabilità rispetto alle singole osservazioni.\n\n77.3.5 Esempio di campione osservato\nPer comprendere meglio questi concetti, consideriamo un singolo campione, ad esempio:\n\nobserved_sample &lt;- c(5, 5.5)\nobserved_sample\n#&gt; [1] 5.0 5.5\n\nCalcoliamo la sua media e deviazione standard:\n\nmean(observed_sample)  # Media del campione\n#&gt; [1] 5.25\nsqrt(variance(observed_sample))  # Deviazione standard del campione\n#&gt; [1] 0.25\n\nOra confrontiamo questi valori con quelli della popolazione:\n\nmean(x)  # Media della popolazione\n#&gt; [1] 4.25\nsqrt(variance(x))  # Deviazione standard della popolazione\n#&gt; [1] 1.346\n\nOsserviamo che la media del campione si avvicina a quella della popolazione, ma non coincide necessariamente con essa. Questo è del tutto normale: ogni campione rappresenta solo una porzione della popolazione e la sua media può variare leggermente a seconda delle osservazioni selezionate.\nPer quanto riguarda la deviazione standard, in questo caso specifico risulta inferiore a quella della popolazione. Tuttavia, in generale, la dispersione di un singolo campione può essere maggiore o minore rispetto a quella della popolazione, poiché dipende dalla variabilità casuale delle osservazioni estratte. Proprio per questo motivo, per trarre inferenze affidabili sulla popolazione, è più utile considerare la distribuzione campionaria delle medie piuttosto che un singolo campione isolato.\nQuesto esempio illustra bene il principio della stima campionaria: mentre un singolo campione fornisce un’informazione parziale, l’analisi di molteplici campioni consente di ottenere una stima più precisa e stabile della media della popolazione, riducendo l’incertezza e migliorando l’affidabilità dell’inferenza statistica.\n\n77.3.6 La Simulazione Illustra Due Principi\nDalla simulazione emergono due principi fondamentali dell’inferenza statistica:\n\n\nLa media della distribuzione campionaria coincide con la media della popolazione. Questo implica che se estraiamo molteplici campioni di dimensione \\(n\\) e calcoliamo la loro media, il valore atteso della media campionaria sarà uguale alla media della popolazione \\(\\mu\\). Formalmente:\n\\[\n\\mathbb{E}(\\bar{X}_n) = \\mu .\n\\]\nQuesto risultato conferma che la media campionaria è uno stimatore non distorto della media della popolazione.\n\n\nLa varianza della distribuzione campionaria è minore della varianza della popolazione. Questo riflette il fatto che le medie campionarie tendono a essere più stabili rispetto alle singole osservazioni. La relazione teorica che descrive questa proprietà è:\n\\[\n\\mathbb{V}(\\bar{X}) = \\frac{\\sigma^2}{n} .\n\\]\nCiò significa che, aumentando la dimensione del campione \\(n\\), la variabilità delle medie campionarie si riduce, rendendo la stima della media della popolazione più precisa. Questo concetto è alla base della teoria del teorema centrale del limite, che diventa sempre più evidente con campioni di dimensioni maggiori.\n\n\n\n\n\n\n\n\nDimostrazione che \\(\\bar{X}\\) è uno stimatore corretto della media della popolazione\n\n\n\n\n\nDato un campione casuale di \\(n\\) osservazioni \\(X_1, X_2, \\dots, X_n\\) estratte da una popolazione con media \\(\\mu\\) e varianza \\(\\sigma^2\\), la media campionaria è definita come:\n\\[\n\\bar{X}_n = \\frac{1}{n} \\sum_{i=1}^{n} X_i .\n\\]\nUtilizziamo la linearità dell’operatore di aspettativa:\n\\[\n\\mathbb{E}(\\bar{X}_n) = \\mathbb{E} \\left( \\frac{1}{n} \\sum_{i=1}^{n} X_i \\right) .\n\\]\nPer la proprietà della linearità dell’aspettativa, possiamo portare fuori il fattore costante \\(\\frac{1}{n}\\):\n\\[\n\\mathbb{E}(\\bar{X}_n) = \\frac{1}{n} \\sum_{i=1}^{n} \\mathbb{E}(X_i) .\n\\]\nPoiché ogni \\(X_i\\) proviene dalla stessa popolazione, ha la stessa aspettativa \\(\\mathbb{E}(X_i) = \\mu\\), quindi:\n\\[\n\\mathbb{E}(\\bar{X}_n) = \\frac{1}{n} \\sum_{i=1}^{n} \\mu .\n\\]\nSommando \\(n\\) volte \\(\\mu\\), otteniamo:\n\\[\n\\mathbb{E}(\\bar{X}_n) = \\frac{1}{n} (n \\mu) = \\mu .\n\\]\nIn conclusione, abbiamo dimostrato che:\n\\[\n\\mathbb{E}(\\bar{X}_n) = \\mu .\n\\]\nQuesto significa che la media campionaria \\(\\bar{X}_n\\) è uno stimatore corretto (non distorto) della media della popolazione \\(\\mu\\), poiché il suo valore atteso coincide esattamente con la quantità che vogliamo stimare.\n\n\n\n\n\n\n\n\n\nDimostrazione della riduzione della varianza nelle medie campionarie\n\n\n\n\n\nSia \\(X_1, X_2, \\dots, X_n\\) un campione casuale di \\(n\\) osservazioni indipendenti estratte da una popolazione con media \\(\\mu\\) e varianza \\(\\sigma^2\\). La media campionaria è definita come:\n\\[\n\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i.\n\\]\nPer definizione, la varianza di \\(\\bar{X}\\) è:\n\\[\n\\mathbb{V}(\\bar{X}) = \\mathbb{V}\\left(\\frac{1}{n} \\sum_{i=1}^n X_i\\right).\n\\]\nPoiché una costante moltiplicata da una variabile aleatoria può essere “estratta” dalla varianza, otteniamo:\n\\[\n\\mathbb{V}(\\bar{X}) = \\frac{1}{n^2} \\mathbb{V}\\left(\\sum_{i=1}^n X_i\\right).\n\\]\nOra dobbiamo calcolare \\(\\mathbb{V}\\left(\\sum_{i=1}^n X_i\\right)\\). Le variabili \\(X_1, X_2, \\dots, X_n\\) sono indipendenti, quindi la varianza della somma è la somma delle varianze:\n\\[\n\\mathbb{V}\\left(\\sum_{i=1}^n X_i\\right) = \\sum_{i=1}^n \\mathbb{V}(X_i).\n\\]\nPoiché tutte le variabili \\(X_i\\) hanno la stessa varianza \\(\\sigma^2\\):\n\\[\n\\mathbb{V}\\left(\\sum_{i=1}^n X_i\\right) = n \\sigma^2.\n\\]\nSostituendo nella formula precedente, otteniamo:\n\\[\n\\mathbb{V}(\\bar{X}) = \\frac{1}{n^2} \\cdot n \\sigma^2 = \\frac{\\sigma^2}{n}.\n\\]\nIn generale, dunque, per un campione di ampiezza \\(n\\), vale la relazione \\(\\mathbb{V}(\\bar{X}) = \\frac{\\sigma^2}{n}\\).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01a_stime_parametri.html#proprietà-della-distribuzione-campionaria",
    "href": "chapters/frequentist_inference/01a_stime_parametri.html#proprietà-della-distribuzione-campionaria",
    "title": "77  Stime, stimatori e parametri",
    "section": "\n77.4 Proprietà della distribuzione campionaria",
    "text": "77.4 Proprietà della distribuzione campionaria\nUna caratteristica fondamentale della distribuzione campionaria riguarda la sua forma e il modo in cui dipende dalla distribuzione della popolazione da cui vengono estratti i campioni. Possiamo distinguere due casi principali:\n\nSe la popolazione segue una distribuzione normale, allora anche la distribuzione delle medie campionarie sarà normalmente distribuita, indipendentemente dalla dimensione del campione \\(n\\). Questo significa che, anche con campioni molto piccoli, la media campionaria manterrà la stessa forma della distribuzione originale.\nSe la popolazione non segue una distribuzione normale, entra in gioco il teorema centrale del limite. Questo teorema afferma che, man mano che la dimensione del campione \\(n\\) aumenta, la distribuzione delle medie campionarie tenderà comunque a una distribuzione normale, indipendentemente dalla forma della distribuzione di partenza. In pratica, per campioni sufficientemente grandi, possiamo approssimare la distribuzione delle medie campionarie con una normale, anche se la popolazione da cui provengono i dati è asimmetrica o non gaussiana.\n\nQueste proprietà sono fondamentali nell’inferenza statistica frequentista: permettono di stimare e testare parametri della popolazione utilizzando campioni, facilitando l’applicazione di strumenti basati sulla distribuzione normale, come gli intervalli di confidenza e i test di ipotesi.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01a_stime_parametri.html#teorema-del-limite-centrale",
    "href": "chapters/frequentist_inference/01a_stime_parametri.html#teorema-del-limite-centrale",
    "title": "77  Stime, stimatori e parametri",
    "section": "\n77.5 Teorema del Limite Centrale",
    "text": "77.5 Teorema del Limite Centrale\nEsaminiamo ora più in dettaglio il Teorema del Limite Centrale (TLC). Nel 1812, Pierre-Simon Laplace dimostrò il TLC, che afferma che la somma (o la media) di una sequenza di variabili casuali indipendenti e identicamente distribuite (i.i.d.) tende a distribuirsi secondo una distribuzione Normale (o Gaussiana), al crescere della dimensione del campione. Inoltre, il TLC specifica i parametri della distribuzione Normale risultante in base ai valori attesi e alle varianze delle variabili casuali sommate.\n\nTeorema 77.1 Si consideri una sequenza di variabili aleatorie indipendenti e identicamente distribuite (i.i.d.) \\(Y_1, Y_2, \\dots, Y_n\\), con valore atteso \\(\\mathbb{E}(Y_i) = \\mu\\) e deviazione standard \\(\\text{SD}(Y_i) = \\sigma.\\) Si definisca una nuova variabile casuale come la media campionaria:\n\\[\nZ = \\frac{1}{n} \\sum_{i=1}^n Y_i.\n\\]\nAl tendere di \\(n\\) all’infinito (\\(n \\rightarrow \\infty\\)), la distribuzione di \\(Z\\) converge a una distribuzione Normale con valore atteso \\(\\mu\\) e deviazione standard \\(\\frac{\\sigma}{\\sqrt{n}}\\):\n\\[\nZ \\sim \\mathcal{N}\\left(\\mu, \\, \\frac{\\sigma}{\\sqrt{n}} \\right).\n\\]\nIn altre parole, la densità di probabilità di \\(Z\\) tende a:\n\\[\np_Z(z) \\rightarrow \\mathcal{N}\\left(z \\ \\Bigg| \\ \\mu, \\, \\frac{\\sigma}{\\sqrt{n}} \\right).\n\\]\n\nIl TLC può essere generalizzato anche a variabili casuali che non sono identicamente distribuite, purché siano indipendenti e abbiano valori attesi e varianze finite. Questo teorema spiega perché molti fenomeni naturali, come l’altezza degli adulti o il peso di una popolazione, tendono a seguire una distribuzione Normale. Infatti, tali fenomeni sono spesso il risultato di una combinazione di numerosi effetti additivi e indipendenti, ciascuno dei quali contribuisce in modo relativamente piccolo. Indipendentemente dalla distribuzione individuale di ciascun effetto, la loro somma (o media) tende a distribuirsi in modo Normale. Questa è la ragione per cui la distribuzione Normale fornisce una buona approssimazione per la distribuzione di molti fenomeni osservati in natura.\n\n77.5.1 Illustrazione del Teorema del Limite Centrale (TLC)\nPer comprendere il Teorema del Limite Centrale (TLC), consideriamo una popolazione iniziale che segue una distribuzione fortemente asimmetrica: la distribuzione Beta(2,1), caratterizzata da una forte asimmetria positiva.\n\n# Parametri della distribuzione Beta\na &lt;- 2\nb &lt;- 1\n\n# Genera valori per la distribuzione Beta\nx &lt;- seq(0, 1, length.out = 1000)  # Valori tra 0 e 1\ny &lt;- dbeta(x, shape1 = a, shape2 = b)  # Densità della distribuzione Beta\n\n# Crea un dataframe per qplot\ndata &lt;- data.frame(x = x, y = y)\n\n# Grafico con qplot\nqplot(x, y, data = data, geom = \"line\", \n      main = \"Distribuzione Beta(2, 1)\", \n      xlab = \"x\", \n      ylab = \"Densità\")\n\n\n\n\n\n\n\nEstrarremo più volte campioni casuali di ampiezza \\(n\\) da questa popolazione e calcoleremo le medie campionarie. Il TLC prevede che, all’aumentare della dimensione del campione, la distribuzione delle medie campionarie tenda a una distribuzione normale, indipendentemente dalla forma della popolazione di partenza.\nPer verificare questa proprietà, definiamo una funzione che genera campioni, calcola le medie e visualizza la loro distribuzione campionaria per diversi valori di \\(n\\):\n\n# Parametri della distribuzione Beta\nalpha &lt;- 2\nbeta &lt;- 1\n\n# Funzione per simulare e visualizzare la distribuzione campionaria\nplot_samples &lt;- function(n) {\n  # Media e deviazione standard della distribuzione Beta\n  mu &lt;- alpha / (alpha + beta)\n  sigma &lt;- sqrt(alpha * beta / ((alpha + beta)^2 * (alpha + beta + 1)))\n  \n  # Generazione di 50.000 campioni casuali di dimensione n\n  sample_means &lt;- replicate(50000, mean(rbeta(n, alpha, beta)))\n  \n  # Creazione del dataframe\n  df &lt;- data.frame(MediaCampionaria = sample_means)\n  \n  # Creazione del grafico con ggplot2\n  ggplot(df, aes(x = MediaCampionaria)) +\n    geom_histogram(aes(y = after_stat(density)), bins = 50, fill = \"lightblue\", color = \"black\") +\n    stat_function(fun = dnorm, args = list(mean = mu, sd = sigma / sqrt(n)), color = \"black\", lwd = 1.2) +\n    labs(title = paste(\"Distribuzione campionaria per n =\", n),\n         x = \"Media campionaria\",\n         y = \"Densità\") +\n    theme_minimal()\n}\n\n\n77.5.1.1 Visualizzazione della convergenza alla normalità\nAnalizziamo l’effetto della dimensione del campione sulle medie campionarie:\n\n\nCampioni di ampiezza \\(n = 1\\)\nSe \\(n = 1\\), la distribuzione campionaria coincide esattamente con la distribuzione della popolazione di partenza, che in questo caso è fortemente asimmetrica:\n\nplot_samples(1)\n\n\n\n\n\n\n\n\n\nCampioni di ampiezza \\(n = 2\\)\nCon \\(n = 2\\), la distribuzione delle medie campionarie inizia a perdere parte della sua asimmetria:\n\nplot_samples(2)\n\n\n\n\n\n\n\n\n\nCampioni di ampiezza \\(n = 4\\)\nPer \\(n = 4\\), la distribuzione delle medie campionarie diventa più simmetrica e tende già a una forma più vicina a quella normale:\n\nplot_samples(4)\n\n\n\n\n\n\n\n\n\nCampioni di ampiezza \\(n = 30\\)\nQuando \\(n\\) diventa sufficientemente grande (ad esempio \\(n = 30\\)), la distribuzione campionaria delle medie è praticamente indistinguibile da una normale:\n\nplot_samples(30)\n\n\n\n\n\n\n\n\n\n77.5.1.2 Conclusione\nIl Teorema del Limite Centrale (TLC) afferma che, indipendentemente dalla forma della distribuzione della popolazione:\n\nSe la dimensione del campione è sufficientemente grande, la distribuzione delle medie campionarie \\(\\bar{X}\\) sarà approssimativamente normale, anche se la popolazione di partenza non lo è.\n\nLa distribuzione delle medie campionarie avrà media uguale a quella della popolazione \\(\\mu\\) e deviazione standard pari a:\n\\[\n\\bar{X} \\sim \\mathcal{N}(\\mu, \\sigma / \\sqrt{n})\n\\]\ndove \\(\\sigma\\) è la deviazione standard della popolazione e \\(n\\) è la dimensione del campione.\n\n\n77.5.2 Implicazioni\n\nNormalità emergente\nIl TLC giustifica l’uso della distribuzione normale in molte applicazioni statistiche, anche quando i dati originali non seguono una distribuzione normale.\nErrore standard e precisione delle stime\nIl TLC fornisce una formula esplicita per calcolare l’errore standard \\(\\sigma / \\sqrt{n}\\), che quantifica l’incertezza associata alla media campionaria. All’aumentare di \\(n\\), l’errore standard diminuisce, migliorando la precisione della stima della media della popolazione.\n\nQuesta proprietà è alla base di molte tecniche statistiche, come gli intervalli di confidenza e i test di ipotesi, che assumono la normalità della distribuzione campionaria delle medie anche quando la popolazione di partenza non è normale.\n\n77.5.3 Applicazioni in psicologia\nMolti fenomeni psicologici che misuriamo (ad esempio, il QI come media di molte abilità cognitive) derivano dalla media di più variabili, e quindi seguono la distribuzione normale grazie al TLC. Questo spiega perché la distribuzione normale appare così frequentemente nei dati sperimentali di psicologia e in molte altre discipline scientifiche.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01a_stime_parametri.html#distribuzioni-campionarie-di-altre-statistiche",
    "href": "chapters/frequentist_inference/01a_stime_parametri.html#distribuzioni-campionarie-di-altre-statistiche",
    "title": "77  Stime, stimatori e parametri",
    "section": "\n77.6 Distribuzioni campionarie di altre statistiche",
    "text": "77.6 Distribuzioni campionarie di altre statistiche\nAbbiamo già analizzato la distribuzione campionaria della media dei campioni. Tuttavia, è possibile costruire distribuzioni campionarie per altre statistiche campionarie. Ad esempio, consideriamo la distribuzione campionaria del valore massimo e della varianza.\n\n77.6.1 Distribuzione campionaria del valore massimo\nSupponiamo di avere una popolazione normalmente distribuita con media \\(\\mu = 100\\) e deviazione standard \\(\\sigma = 15\\). Generiamo 10.000 campioni casuali di ampiezza \\(n = 5\\) e calcoliamo il valore massimo per ogni campione.\n\n77.6.1.1 Simulazione e visualizzazione\n\nset.seed(123)  # Per risultati riproducibili\n\n# Parametri della distribuzione\nmu &lt;- 100\nsigma &lt;- 15\n\n# Simulazione: calcolo del valore massimo per ciascun campione\nn_samples &lt;- 10000\nsample_maxes &lt;- replicate(\n  n_samples, \n  max(rnorm(5, mean = mu, sd = sigma))\n)\n\n# Creazione del dataframe\ndf &lt;- data.frame(ValoreMassimo = sample_maxes)\n\n# Istogramma con ggplot2\nggplot(df, aes(x = ValoreMassimo)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 50, fill = \"lightblue\", color = \"black\") +\n  stat_function(fun = dnorm, args = list(mean = mu, sd = sigma), color = \"black\", lwd = 1.2) +\n  labs(title = \"Distribuzione campionaria del valore massimo\",\n       x = \"Valore massimo\",\n       y = \"Densità\")\n\n\n\n\n\n\n\nOsserviamo che il valore atteso della distribuzione campionaria del massimo è maggiore della media della popolazione \\(\\mu\\).\n\n77.6.2 Distribuzione campionaria della varianza\nUn’altra statistica interessante è la varianza campionaria. La formula della varianza campionaria, basata sulla statistica descrittiva, è:\n\\[\nS^2 = \\frac{\\sum_{i=1}^n (Y_i - \\bar{Y})^2}{n}.\n\\]\nCalcoliamo la distribuzione campionaria della varianza per campioni di ampiezza \\(n = 5\\).\n\n77.6.2.1 Simulazione e visualizzazione\n\nset.seed(123)\n\n# Parametri della distribuzione\nmu &lt;- 100\nsigma &lt;- 15\nn_samples &lt;- 10000\n\n# Funzione per calcolare la varianza senza la correzione di Bessel\nvariance &lt;- function(x) {\n  mean((x - mean(x))^2)  # Divisione per n invece di (n-1)\n}\n\n# Simulazione: calcolo della varianza per ciascun campione\nsample_vars &lt;- replicate(\n  n_samples, \n  variance(rnorm(5, mean = mu, sd = sigma))\n)\n\n# Creazione del dataframe\ndf &lt;- data.frame(Varianza = sample_vars)\n\n# Istogramma con ggplot2\nggplot(df, aes(x = Varianza)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 50, fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Distribuzione campionaria della varianza\",\n       x = \"Varianza\",\n       y = \"Densità\")\n\n\n\n\n\n\n\n\n# Media empirica della varianza campionaria\nmean(sample_vars)\n#&gt; [1] 180.7\n\nSappiamo che la varianza della popolazione è \\(\\sigma^2 = 15^2 = 225\\). Tuttavia, il valore medio empirico delle varianze campionarie calcolate con \\(S^2\\) risulta minore di 225. Questo avviene perché lo stimatore \\(S^2\\) è distorto.\n\n77.6.3 Correzione della distorsione\nPer eliminare la distorsione, utilizziamo il seguente stimatore della varianza della popolazione:\n\\[\ns^2 = \\frac{\\sum_{i=1}^n (Y_i - \\bar{Y})^2}{n-1}.\n\\]\n\n77.6.3.1 Verifica con simulazione\n\nset.seed(123)\n\n# Simulazione: calcolo della varianza con la correzione\nsample_vars_unbiased &lt;- replicate(\n  n_samples, \n  var(rnorm(5, mean = mu, sd = sigma))\n)\n\n# Creazione del dataframe\ndf &lt;- data.frame(Varianza = sample_vars_unbiased)\n\n# Istogramma con ggplot2\nggplot(df, aes(x = Varianza)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 50, fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Distribuzione campionaria della varianza (corretta)\",\n       x = \"Varianza\",\n       y = \"Densità\")\n\n\n\n\n\n\n\n\n# Media empirica della varianza corretta\nmean(sample_vars_unbiased)\n#&gt; [1] 225.8\n\nCon questo stimatore, la media della distribuzione campionaria coincide con la varianza reale della popolazione \\(\\sigma^2 = 225\\).\nIn conclusione:\n\nLa distribuzione campionaria del massimo mostra che il valore massimo dei campioni è, in media, maggiore della media della popolazione.\nLa varianza campionaria non corretta (\\(S^2\\)) è uno stimatore distorto, poiché il suo valore atteso non coincide con la varianza della popolazione.\nLo stimatore corretto \\(s^2\\), che utilizza il divisore \\(n - 1\\), elimina la distorsione e fornisce una stima non distorta della varianza della popolazione.\n\nIn generale, uno stimatore è considerato non distorto quando il valore atteso delle sue stime coincide con il valore reale del parametro. Nel caso della media campionaria e della varianza corretta, entrambi gli stimatori sono non distorti.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01a_stime_parametri.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/01a_stime_parametri.html#riflessioni-conclusive",
    "title": "77  Stime, stimatori e parametri",
    "section": "\n77.7 Riflessioni Conclusive",
    "text": "77.7 Riflessioni Conclusive\nIn generale, i parametri della popolazione sono sconosciuti, ma possiamo stimarli utilizzando le informazioni del campione. Di seguito viene presentata una tabella che riassume i simboli comuni utilizzati per indicare le quantità note e sconosciute nel contesto dell’inferenza statistica. Questo ci aiuterà a tenere traccia di ciò che sappiamo e ciò che non sappiamo.\n\n\n\n\n\n\n\nSimbolo\nNome\nÈ qualcosa che conosciamo?\n\n\n\n\\(s\\)\nDeviazione standard del campione\nSì, la calcoliamo dai dati grezzi\n\n\n\\(\\sigma\\)\nDeviazione standard della popolazione\nNo, tranne in casi particolari o nelle simulazioni\n\n\n\\(\\hat{\\sigma}\\)\nStima della deviazione standard della popolazione\nSì, ma non è uguale a \\(\\sigma\\)\n\n\n\n\\(s^2\\)\nVarianza del campione\nSì, la calcoliamo dai dati grezzi\n\n\n\\(\\sigma^2\\)\nVarianza della popolazione\nNo, tranne in casi particolari o nelle simulazioni\n\n\n\\(\\hat{\\sigma}^2\\)\nStima della varianza della popolazione\nSì, ma non è uguale a \\(\\sigma^2\\)\n\n\n\n\n\nUtilizzando le informazioni di un campione casuale di ampiezza \\(n\\):\n\nLa stima migliore che possiamo ottenere per la media \\(\\mu\\) della popolazione è la media del campione \\(\\bar{Y}\\).\nLa stima migliore che possiamo ottenere per la varianza \\(\\sigma^2\\) della popolazione è:\n\n\\[\n\\hat{\\sigma}^2 = \\frac{1}{n-1} \\sum_{i=1}^n (Y_i - \\bar{Y})^2.\n\\]\n\n\n\n\n\n\nRisposte alle domande iniziali\n\n\n\n\n\nDopo aver esplorato il concetto di distribuzione campionaria attraverso simulazioni ed esempi pratici, possiamo ora confrontare le nostre risposte intuitive con quanto appreso:\n\nLe medie campionarie tendono a distribuirsi intorno alla media della popolazione, con una variabilità che dipende dalla dimensione del campione.\nSì, le medie campionarie sono meno disperse rispetto ai singoli valori della popolazione, il che significa che forniscono una stima più stabile della media della popolazione.\nAll’aumentare di \\(n\\), la distribuzione campionaria delle medie diventa più stretta, ossia la variabilità delle medie campionarie si riduce. La varianza della distribuzione campionaria è pari a \\(\\sigma^2 / n\\), dove \\(\\sigma^2\\) è la varianza della popolazione.\nNo, la distribuzione campionaria della media è normale solo se la popolazione di partenza è normale o se la dimensione del campione è sufficientemente grande (Teorema del Limite Centrale).\nSì, la media della distribuzione campionaria coincide con la media della popolazione. Tuttavia, la varianza della distribuzione campionaria è inferiore alla varianza della popolazione, poiché viene divisa per la dimensione del campione (\\(n\\)).\nPer campioni piccoli, la distribuzione delle medie campionarie somiglierà alla distribuzione della popolazione originale. Se la popolazione è fortemente asimmetrica, anche la distribuzione campionaria per piccoli campioni sarà asimmetrica. Tuttavia, aumentando \\(n\\), la distribuzione delle medie campionarie tenderà a una normale, indipendentemente dalla forma della popolazione di partenza.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01a_stime_parametri.html#esercizi",
    "href": "chapters/frequentist_inference/01a_stime_parametri.html#esercizi",
    "title": "77  Stime, stimatori e parametri",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nParte 1: Popolazione di Piccole Dimensioni Si consideri una popolazione con i seguenti valori:\n\\[\nx = \\{2, 4.5, 5, 5.5\\}\n\\]\n\nCalcolare la media e la varianza della popolazione.\nEstrarre tutti i possibili campioni di ampiezza \\(n = 2\\) con ripetizione e calcolare la media di ciascun campione.\nRappresentare graficamente la distribuzione campionaria delle medie.\nCalcolare la probabilità che la media campionaria sia inferiore a 3:\n\nEsattamente, utilizzando la distribuzione campionaria.\nApprossimativamente, assumendo una distribuzione normale se il campione fosse sufficientemente grande.\n\n\n\nParte 2: Popolazione di Grandi Dimensioni\nSi consideri ora una popolazione più grande, generata da una distribuzione normale con media \\(\\mu = 10\\) e deviazione standard \\(\\sigma = 3\\).\n\nGenerare una popolazione di 1000 osservazioni.\nCalcolare la media e la varianza della popolazione.\nEstrarre 10.000 campioni casuali di ampiezza \\(n = 15\\) e calcolare la media campionaria per ciascun campione.\nRappresentare graficamente la distribuzione campionaria delle medie.\nCalcolare la probabilità che la media campionaria sia inferiore a 9:\n\nEsattamente, utilizzando la distribuzione campionaria.\nApprossimativamente, utilizzando la distribuzione normale.\n\n\n\nObiettivo: Verificare sperimentalmente le proprietà della distribuzione campionaria della media e confrontare i risultati con le previsioni teoriche fornite dal Teorema del Limite Centrale.\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\nProprietà della Distribuzione Campionaria della Media\n\nMedia: La media della distribuzione campionaria coincide con la media della popolazione:\nVarianza: La varianza della distribuzione campionaria è pari alla varianza della popolazione divisa per la dimensione del campione:\nForma:\n\n\nSe la popolazione segue una distribuzione normale, anche la distribuzione campionaria della media sarà normale.\nSe la popolazione non è normale, il Teorema del Limite Centrale garantisce che la distribuzione campionaria della media sarà approssimativamente normale per campioni di dimensioni sufficientemente grandi (\\(n \\geq 30\\)).\n\nDefiniamo una popolazione e calcoliamo i parametri:\n\n# Popolazione\nx &lt;- c(2, 4.5, 5, 5.5)\nmean(x)  # Media della popolazione\n#&gt; [1] 4.25\nvar(x)   # Varianza della popolazione\n#&gt; [1] 2.417\n\nEstrarre tutti i possibili campioni di ampiezza \\(n = 2\\) e calcolare la media di ciascun campione:\n\n# Tutti i campioni di ampiezza 2\nsamples &lt;- expand.grid(x, x)\nsample_means &lt;- rowMeans(samples)\n\n# Visualizzare la distribuzione campionaria\ndf &lt;- data.frame(sample_means = sample_means)\n\nggplot(df, aes(x = sample_means)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 5, fill = \"blue\", alpha = 0.6) +\n  geom_density(color = \"red\", size = 1) +\n  labs(\n    title = \"Distribuzione campionaria delle medie\",\n    x = \"Media campionaria\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\nCalcoliamo la probabilità che, all’interno della distribuzione campionaria, la media del campione sia minore di 3. Troviamo il valore esatto nella simulazione. Approssimiamo il valore esatto con il valore atteso se il campione fosse sufficientemente grande da poter assumere una distribuzione campionaria normale:\n\n# Probabilità esatta dalla distribuzione campionaria\nexact_probability &lt;- mean(sample_means &lt; 3)\nexact_probability\n#&gt; [1] 0.0625\n\n# Approssimazione tramite distribuzione normale\nmu &lt;- mean(x)  # Media della popolazione\nsigma &lt;- sqrt(var(x) / 2)  # Deviazione standard della distribuzione campionaria\napprox_probability &lt;- pnorm(3, mean = mu, sd = sigma)\napprox_probability\n#&gt; [1] 0.1277\n\nRipetiamo ora l’esempio, mantenendo la stessa struttura della simulazione, ma considerando una popolazione più grande tale per cui si possa estrarre un campione di ampiezza 15:\n\n# Nuova popolazione\nset.seed(123)\nx_large &lt;- rnorm(1000, mean = 10, sd = 3)  # Popolazione più grande\nmean(x_large)  # Media della popolazione\n#&gt; [1] 10.05\nvar(x_large)   # Varianza della popolazione\n#&gt; [1] 8.851\n\n# Estrazione di campioni di ampiezza 15\nsamples_large &lt;- replicate(10000, mean(sample(x_large, size = 15)))\n\n# Creazione del data frame per ggplot2\ndf_large &lt;- data.frame(sample_means = samples_large)\n\n# Visualizzazione con ggplot2\nggplot(df_large, aes(x = sample_means)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 50, fill = \"blue\", alpha = 0.6) +\n  geom_density(color = \"red\", size = 1) +\n  labs(\n    title = \"Distribuzione campionaria delle medie (n = 15)\",\n    x = \"Media campionaria\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\n\n# Probabilità esatta dalla simulazione\nexact_probability_large &lt;- mean(samples_large &lt; 9)\nexact_probability_large\n#&gt; [1] 0.0834\n\n\n# Approssimazione tramite distribuzione normale\nmu_large &lt;- mean(x_large)\nsigma_large &lt;- sqrt(var(x_large) / 15)\napprox_probability_large &lt;- pnorm(9, mean = mu_large, sd = sigma_large)\napprox_probability_large\n#&gt; [1] 0.08616\n\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nDistribuzione Campionaria della Differenza tra Medie\nL’obiettivo di questo esercizio è esplorare le proprietà della distribuzione campionaria della differenza tra medie campionarie, analizzando sia il caso di popolazioni finite di piccole dimensioni sia il caso di popolazioni più grandi, con distribuzioni normali.\nEsercizio 1: Simulazione con Popolazioni di Piccole Dimensioni\nConsideriamo due popolazioni finite composte da un numero limitato di elementi:\n\n\nPopolazione 1: \\(x_1 = \\{2, 4.5, 5, 6\\}\\)\n\n\nPopolazione 2: \\(x_2 = \\{3, 3.5, 4, 7\\}\\)\n\n\n\n77.7.0.1 Compiti:\n\n\n\nCalcolo dei parametri delle popolazioni:\n\nDeterminare la media e la varianza di entrambe le popolazioni.\n\n\n\nEstrazione di campioni:\n\nEstrarre tutti i possibili campioni di ampiezza \\(n = 2\\) con ripetizione da entrambe le popolazioni.\nCalcolare la media campionaria di ciascun campione.\n\n\n\nDistribuzione campionaria della differenza tra le medie:\n\nCalcolare la differenza tra le medie di tutti i possibili campioni ottenuti dalle due popolazioni.\nRappresentare graficamente la distribuzione della differenza tra le medie.\n\n\n\nProbabilità della differenza tra le medie:\n\nCalcolare la probabilità che la differenza tra le medie campionarie sia maggiore di 1.\n\n\n\nEsercizio 2: Simulazione con Popolazioni di Grande Dimensione\nConsideriamo ora due popolazioni più grandi, distribuite normalmente:\n\n\nPopolazione 1: \\(X_1 \\sim N(10, 4^2)\\) (media = 10, deviazione standard = 4)\n\nPopolazione 2: \\(X_2 \\sim N(8, 3^2)\\) (media = 8, deviazione standard = 3)\n\nCompiti:\n\n\nGenerazione delle popolazioni:\n\nCreare due popolazioni casuali di 10.000 osservazioni ciascuna, distribuite normalmente.\n\n\n\nEstrazione di campioni:\n\nEstrarre 10.000 campioni casuali di ampiezza \\(n_1 = 15\\) dalla prima popolazione e \\(n_2 = 20\\) dalla seconda popolazione.\nCalcolare la media di ciascun campione.\n\n\n\nDistribuzione campionaria della differenza tra le medie:\n\nCalcolare la differenza tra le medie campionarie ottenute dalle due popolazioni.\nRappresentare graficamente la distribuzione della differenza tra le medie.\n\n\n\nProbabilità della differenza tra le medie:\n\nCalcolare la probabilità che la differenza tra le medie campionarie sia maggiore di 2 in due modi:\n\n\nMetodo empirico: utilizzando la distribuzione ottenuta nella simulazione.\n\nMetodo teorico: approssimando la distribuzione con una normale e calcolando la probabilità con la formula teorica della varianza della differenza tra le medie.\n\n\n\n\n\nDomande di Discussione\n\nCome cambia la forma della distribuzione campionaria al variare delle dimensioni dei campioni \\(n_1\\) e \\(n_2\\)?\nLa probabilità stimata tramite simulazione coincide con quella calcolata utilizzando l’approssimazione normale? Perché?\nCosa accadrebbe alla distribuzione campionaria se le popolazioni originali non fossero normali? Quale sarebbe il ruolo del Teorema del Limite Centrale?\n\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\nEsercizio 1: Simulazione con Popolazioni di Piccola Dimensione\nSupponiamo di avere due popolazioni finite definite come segue:\n\nPopolazione 1: \\(x_1 = \\{2, 4.5, 5, 6\\}\\)\n\nPopolazione 2: \\(x_2 = \\{3, 3.5, 4, 7\\}\\)\n\n\n\nCalcola le medie e le varianze delle due popolazioni:\n\n\n# Popolazione 1\nx1 &lt;- c(2, 4.5, 5, 6)\nmean(x1)  # Media di x1\n#&gt; [1] 4.375\nvar(x1)   # Varianza di x1\n#&gt; [1] 2.896\n\n\n# Popolazione 2\nx2 &lt;- c(3, 3.5, 4, 7)\nmean(x2)  # Media di x2\n#&gt; [1] 4.375\nvar(x2)   # Varianza di x2\n#&gt; [1] 3.229\n\n\nEstrai tutti i possibili campioni di ampiezza \\(n = 2\\) da entrambe le popolazioni:\n\n\n# Tutti i campioni di ampiezza 2\nsamples1 &lt;- expand.grid(x1, x1)\nsamples2 &lt;- expand.grid(x2, x2)\n\n# Medie campionarie\nsample_means1 &lt;- rowMeans(samples1)\nsample_means2 &lt;- rowMeans(samples2)\n\n\nCalcola la differenza tra le medie campionarie di ciascuna combinazione di campioni:\n\n\n# Differenze tra le medie campionarie\nsample_diff &lt;- as.vector(outer(sample_means1, sample_means2, \"-\"))\n\n\nVisualizza la distribuzione campionaria della differenza tra le medie:\n\n\n# Istogramma della differenza tra medie campionarie\n\n# Creazione del data frame per ggplot2\ndf_diff &lt;- data.frame(sample_diff = sample_diff)\n\n# Visualizzazione con ggplot2\nggplot(df_diff, aes(x = sample_diff)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 10, fill = \"blue\", alpha = 0.6) +\n  geom_density(color = \"red\", size = 1) +\n  labs(\n    title = \"Distribuzione campionaria della differenza tra medie\",\n    x = \"Differenza campionaria\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\n\nCalcola la probabilità che la differenza campionaria sia maggiore di 1:\n\n\n# Probabilità esatta dalla distribuzione campionaria\nexact_probability &lt;- mean(sample_diff &gt; 1)\nexact_probability\n#&gt; [1] 0.2656\n\nEsercizio 2: Simulazione con Popolazioni di Grande Dimensione\nOra considera due popolazioni più grandi con distribuzioni normali:\n\nPopolazione 1: \\(X_1 \\sim N(10, 4^2)\\)\n\nPopolazione 2: \\(X_2 \\sim N(8, 3^2)\\)\n\n\n\nGenera due popolazioni casuali:\n\n\nset.seed(123)\npop1 &lt;- rnorm(10000, mean = 10, sd = 4)\npop2 &lt;- rnorm(10000, mean = 8, sd = 3)\n\n\nEstrai 10.000 campioni casuali di ampiezza \\(n_1 = 15\\) e \\(n_2 = 20\\) rispettivamente:\n\n\n# Estrazione di campioni e calcolo delle medie\nsample_means1 &lt;- replicate(10000, mean(sample(pop1, size = 15)))\nsample_means2 &lt;- replicate(10000, mean(sample(pop2, size = 20)))\n\n\nCalcola la differenza tra le medie campionarie:\n\n\n# Differenze tra medie campionarie\nsample_diff_large &lt;- sample_means1 - sample_means2\n\n\nVisualizza la distribuzione campionaria della differenza tra le medie:\n\n\n# Istogramma della distribuzione campionaria\n\n# Creazione del data frame per ggplot2\ndf_diff_large &lt;- data.frame(sample_diff = sample_diff_large)\n\n# Visualizzazione con ggplot2\nggplot(df_diff_large, aes(x = sample_diff)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 50, fill = \"blue\", alpha = 0.6) +\n  geom_density(color = \"red\", size = 1) +\n  labs(\n    title = \"Distribuzione campionaria della differenza tra medie (n1 = 15, n2 = 20)\",\n    x = \"Differenza campionaria\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\n\n\nCalcola la probabilità che la differenza campionaria sia maggiore di 2 utilizzando:\n\nla simulazione;\nl’approssimazione normale.\n\n\n\n\n# Probabilità esatta\nexact_probability_large &lt;- mean(sample_diff_large &gt; 2)\nexact_probability_large\n#&gt; [1] 0.505\n\n\n# Approssimazione normale\nmu_diff &lt;- 10 - 8  # Differenza tra le medie delle popolazioni\nsigma_diff &lt;- sqrt(4^2 / 15 + 3^2 / 20)  # Deviazione standard della differenza\napprox_probability_large &lt;- 1 - pnorm(2, mean = mu_diff, sd = sigma_diff)\napprox_probability_large\n#&gt; [1] 0.5\n\nDomande di Discussione.\n\nCome cambia la forma della distribuzione campionaria al variare delle dimensioni campionarie \\(n_1\\) e \\(n_2\\)?\nLa probabilità calcolata tramite simulazione coincide con quella calcolata tramite approssimazione normale? Perché?\nCosa accadrebbe alla distribuzione campionaria se le popolazioni originali non fossero normali?\n\n\n\n\n\n\n\n\n\n\nProblemi 3\n\n\n\n\n\nProblema: Distribuzione Campionaria di una Proporzione\nL’obiettivo di questo esercizio è esplorare la distribuzione campionaria di una proporzione campionaria \\(\\hat{p}\\) e verificare l’applicabilità dell’approssimazione normale per grandi dimensioni campionarie, come previsto dal Teorema del Limite Centrale.\nSituazione\nSupponiamo di avere una popolazione infinita in cui ciascun individuo può appartenere a una di due categorie: “successo” (codificato come 1) o “insuccesso” (codificato come 0). La probabilità di successo nella popolazione è data da \\(p = 0.6\\).\nCompiti\n\n\nDefinizione della popolazione e dei parametri:\n\nLa popolazione ha una proporzione di successi pari a \\(p = 0.6\\).\nLa deviazione standard teorica della distribuzione campionaria della proporzione è calcolata come:\\[\n\\text{SD}(\\hat{p}) = \\sqrt{\\frac{p(1 - p)}{n}}\n\\]\n\nSi fissi una dimensione campionaria pari a \\(n = 100\\).\n\n\n\nSimulazione di campioni:\n\nGenerare 10.000 campioni casuali di ampiezza \\(n = 100\\).\nPer ogni campione, calcolare la proporzione campionaria \\(\\hat{p}\\), cioè la frazione di successi nel campione.\n\n\n\nDistribuzione campionaria delle proporzioni:\n\nRappresentare graficamente la distribuzione delle proporzioni campionarie con un istogramma.\nSovrapporre la distribuzione normale teorica \\(N(p, \\text{SD}(\\hat{p}))\\) per confrontare l’andamento empirico con quello teorico.\n\n\n\nAnalisi della distribuzione:\n\nValutare se la distribuzione campionaria ottenuta rispetta l’approssimazione normale.\nRiflettere su come la dimensione del campione e il valore di \\(p\\) influenzano questa approssimazione.\n\n\n\nDomande di Discussione\n\nLa distribuzione campionaria delle proporzioni \\(\\hat{p}\\) sembra approssimarsi a una distribuzione normale? Perché?\nCosa accadrebbe se la dimensione del campione fosse più piccola, ad esempio \\(n = 30\\)?\nSe la probabilità di successo \\(p\\) fosse molto vicina a 0 o 1, l’approssimazione normale sarebbe ancora valida? Perché?\n\n\n\n\n\n\n\n\n\n\nSoluzioni 3\n\n\n\n\n\nLa distribuzione campionaria di una proporzione descrive come la proporzione campionaria (\\(\\hat{p}\\)) varia tra campioni di una popolazione. Per campioni grandi, il Teorema del Limite Centrale garantisce che la distribuzione campionaria di \\(\\hat{p}\\) può essere approssimata con una distribuzione normale.\n\n\nSupponiamo una popolazione infinita in cui la probabilità di successo (\\(p\\)) è \\(p = 0.6\\). Scegli una dimensione campionaria \\(n = 100\\).\nSimula 10.000 campioni casuali di ampiezza \\(n\\) e calcola le proporzioni campionarie (\\(\\hat{p}\\)).\nConfronta l’istogramma delle proporzioni campionarie con la distribuzione normale teorica approssimativa.\n\n\n# Parametri della popolazione\np &lt;- 0.6  # Probabilità di successo nella popolazione\nn &lt;- 100  # Dimensione del campione\n\n# Simulazione di 10.000 campioni\nset.seed(123)\nsample_props &lt;- replicate(10000, mean(rbinom(n, size = 1, prob = p)))\n\n# Creazione di un data frame per ggplot2\ndf_props &lt;- data.frame(sample_props = sample_props)\n\n# Parametri della distribuzione normale teorica\nmean_theoretical &lt;- p\nsd_theoretical &lt;- sqrt(p * (1 - p) / n)\n\n# Visualizzazione con ggplot2\nggplot(df_props, aes(x = sample_props)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 40, fill = \"blue\", alpha = 0.6) +\n  stat_function(\n    fun = dnorm,\n    args = list(mean = mean_theoretical, sd = sd_theoretical),\n    color = \"red\",\n    size = 1\n  ) +\n  labs(\n    title = \"Distribuzione campionaria di una proporzione (n = 100)\",\n    x = \"Proporzione campionaria (\\u0302p)\",\n    y = \"Densità\"\n  ) \n\n\n\n\n\n\n\n\n\nPopolazione e parametri:\n\nLa popolazione è definita da \\(p = 0.6\\).\nLa deviazione standard teorica della distribuzione campionaria è calcolata come \\(\\text{SD}(\\hat{p}) = \\sqrt{\\frac{p(1-p)}{n}}\\).\n\n\n\nSimulazione:\n\nPer ogni campione, i successi (\\(0\\) o \\(1\\)) sono generati con rbinom, e la proporzione campionaria \\(\\hat{p}\\) è calcolata come media.\n\n\n\nGrafico:\n\nL’istogramma delle proporzioni campionarie è sovrapposto alla curva normale teorica (\\(N(p, \\text{SD}(\\hat{p}))\\)).\n\n\n\nDomande di Discussione.\n\nLa distribuzione campionaria di \\(\\hat{p}\\) sembra approssimarsi a una distribuzione normale? Perché?\nCosa accadrebbe se \\(n\\) fosse più piccolo (es. \\(n = 30\\))?\nSe \\(p\\) fosse più vicino a \\(0\\) o \\(1\\), l’approssimazione normale sarebbe ancora valida? Spiega.\n\n\n\n\n\n\n\n\n\n\nProblemi 4\n\n\n\n\n\nProblema: Distribuzione Campionaria della Differenza tra Due Proporzioni\nL’obiettivo di questo esercizio è esplorare la distribuzione campionaria della differenza tra due proporzioni campionarie, \\(\\hat{p}_1 - \\hat{p}_2\\), ottenute da due campioni indipendenti estratti da popolazioni diverse. Per campioni sufficientemente grandi, il Teorema del Limite Centrale garantisce che la distribuzione di \\(\\hat{p}_1 - \\hat{p}_2\\) può essere approssimata con una distribuzione normale.\nSituazione\nAbbiamo due popolazioni con proporzioni di successo diverse:\n\n\nPopolazione 1 ha una proporzione di successo \\(p_1 = 0.6\\).\n\nPopolazione 2 ha una proporzione di successo \\(p_2 = 0.4\\).\n\nVogliamo studiare il comportamento della distribuzione campionaria della differenza tra le proporzioni campionarie quando preleviamo campioni indipendenti da ciascuna popolazione.\nCompiti\n\n\nDefinizione delle popolazioni e dei parametri:\n\nLa proporzione di successi nelle due popolazioni è \\(p_1 = 0.6\\) e \\(p_2 = 0.4\\).\nEntrambi i campioni hanno dimensione \\(n_1 = n_2 = 150\\).\nLa deviazione standard teorica della distribuzione campionaria della differenza tra proporzioni è calcolata come: \\[\n\\text{SD}(\\hat{p}_1 - \\hat{p}_2) = \\sqrt{\\frac{p_1 (1-p_1)}{n_1} + \\frac{p_2 (1-p_2)}{n_2}}\n\\]\n\n\n\n\nSimulazione di campioni:\n\nGenerare 10.000 campioni indipendenti di ampiezza \\(n_1 = 150\\) dalla prima popolazione e \\(n_2 = 150\\) dalla seconda popolazione.\nCalcolare la proporzione campionaria \\(\\hat{p}_1\\) e \\(\\hat{p}_2\\) per ciascun campione.\nCalcolare la differenza tra le proporzioni campionarie.\n\n\n\nDistribuzione campionaria della differenza tra le proporzioni:\n\nRappresentare graficamente la distribuzione di \\(\\hat{p}_1 - \\hat{p}_2\\) con un istogramma.\nSovrapporre la distribuzione normale teorica \\(N(p_1 - p_2, \\text{SD}(\\hat{p}_1 - \\hat{p}_2))\\) per confrontare l’andamento empirico con quello teorico.\n\n\n\nCalcolo della probabilità che la differenza tra proporzioni sia maggiore di un valore specifico:\n\n\nMetodo empirico: calcolare la proporzione di campioni in cui \\(\\hat{p}_1 - \\hat{p}_2 &gt; 0.1\\).\n\nMetodo teorico: utilizzare la distribuzione normale approssimata per stimare la probabilità che \\(\\hat{p}_1 - \\hat{p}_2 &gt; 0.1\\).\n\n\n\nDomande di Discussione\n\nL’approssimazione normale è valida in questo caso? Perché?\nCome cambierebbe la distribuzione campionaria se la dimensione del campione \\(n_1\\) o \\(n_2\\) fosse più piccola?\nSe i valori di \\(p_1\\) o \\(p_2\\) fossero più vicini a 0 o 1, come cambierebbe la probabilità calcolata e l’accuratezza dell’approssimazione normale?\n\n\n\n\n\n\n\n\n\n\nSoluzioni 4\n\n\n\n\n\nLa distribuzione campionaria della differenza tra due proporzioni (\\(\\hat{p}_1 - \\hat{p}_2\\)) descrive come la differenza tra le proporzioni campionarie varia tra due campioni indipendenti estratti da due popolazioni.\nPer campioni grandi, il Teorema del Limite Centrale garantisce che \\(\\hat{p}_1 - \\hat{p}_2\\) segue approssimativamente una distribuzione normale con media e varianza calcolate dalle proporzioni della popolazione.\nObiettivo:\n\nSimulare due popolazioni con proporzioni \\(p_1\\) e \\(p_2\\).\nEstrarre campioni indipendenti da ciascuna popolazione.\nCalcolare la distribuzione campionaria di \\(\\hat{p}_1 - \\hat{p}_2\\).\nCalcolare la probabilità che la differenza campionaria sia maggiore di un valore specifico (es. \\(0.1\\)).\n\nParametri del Problema:\n\nPopolazione 1: \\(p_1 = 0.6\\)\n\nPopolazione 2: \\(p_2 = 0.4\\)\n\nDimensione campionaria: \\(n_1 = n_2 = 150\\)\n\nValore specifico: \\(0.1\\)\n\n\n\n# Parametri delle due popolazioni\np1 &lt;- 0.6  # Proporzione di successi nella Popolazione 1\np2 &lt;- 0.4  # Proporzione di successi nella Popolazione 2\nn1 &lt;- 150  # Dimensione campionaria per la Popolazione 1\nn2 &lt;- 150  # Dimensione campionaria per la Popolazione 2\n\n# Simulazione di 10.000 campioni indipendenti\nset.seed(123)\nsample_p1 &lt;- replicate(10000, mean(rbinom(n1, size = 1, prob = p1)))\nsample_p2 &lt;- replicate(10000, mean(rbinom(n2, size = 1, prob = p2)))\n\n# Calcolo della differenza tra proporzioni campionarie\nsample_diff &lt;- sample_p1 - sample_p2\n\n# Parametri teorici della distribuzione normale approssimata\nmean_diff &lt;- p1 - p2\nsd_diff &lt;- sqrt((p1 * (1 - p1) / n1) + (p2 * (1 - p2) / n2))\n\n# Creazione del data frame per ggplot2\ndf_diff &lt;- data.frame(sample_diff = sample_diff)\n\n# Visualizzazione con ggplot2\nggplot(df_diff, aes(x = sample_diff)) +\n  geom_histogram(\n    aes(y = after_stat(density)), bins = 40, fill = \"blue\", alpha = 0.6\n  ) +\n  stat_function(\n    fun = dnorm,\n    args = list(mean = mean_diff, sd = sd_diff),\n    color = \"red\",\n    size = 1\n  ) +\n  labs(\n    title = \"Distribuzione campionaria della differenza tra proporzioni\",\n    x = \"Differenza campionaria (p1 - p2)\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\n\n# Calcolo della probabilità che la differenza sia maggiore di 0.1\nexact_probability &lt;- mean(sample_diff &gt; 0.1)\nexact_probability\n#&gt; [1] 0.9599\n\n\n# Approssimazione tramite distribuzione normale\napprox_probability &lt;- 1 - pnorm(0.1, mean = mean_diff, sd = sd_diff)\napprox_probability\n#&gt; [1] 0.9615\n\n\n\nParametri delle popolazioni:\n\nDue popolazioni con proporzioni \\(p_1 = 0.6\\) e \\(p_2 = 0.4\\).\nDimensioni campionarie \\(n_1 = n_2 = 150\\).\n\n\n\nSimulazione:\n\nPer ogni campione, i successi (\\(0\\) o \\(1\\)) sono generati con rbinom.\nCalcoliamo le proporzioni campionarie e la differenza tra di esse.\n\n\n\nDistribuzione teorica:\n\nMedia teorica: \\(p_1 - p_2\\).\nDeviazione standard teorica: \\(\\sqrt{\\frac{p_1 (1-p_1)}{n_1} + \\frac{p_2 (1-p_2)}{n_2}}\\).\n\n\n\nVisualizzazione:\n\nUn istogramma di \\(\\hat{p}_1 - \\hat{p}_2\\) sovrapposto alla curva della distribuzione normale teorica.\n\n\n\nCalcolo della probabilità:\n\nProbabilità esatta dalla simulazione: proporzione di \\(\\hat{p}_1 - \\hat{p}_2 &gt; 0.1\\).\nProbabilità approssimata dalla distribuzione normale.\n\n\n\nDomande di Discussione.\n\nL’approssimazione normale è valida in questo caso? Perché?\nCome cambierebbe la distribuzione campionaria se \\(n_1\\) o \\(n_2\\) fossero più piccoli?\nCome influenzerebbe la probabilità calcolata un valore \\(p_1\\) o \\(p_2\\) più vicino a \\(0\\) o \\(1\\)?",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01a_stime_parametri.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/01a_stime_parametri.html#informazioni-sullambiente-di-sviluppo",
    "title": "77  Stime, stimatori e parametri",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.12.0 psych_2.5.3     \n#&gt;  [9] scales_1.4.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.2   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.4     stringi_1.8.7      lattice_0.22-7    \n#&gt;  [4] hms_1.1.3          digest_0.6.37      magrittr_2.0.3    \n#&gt;  [7] evaluate_1.0.3     grid_4.5.0         timechange_0.3.0  \n#&gt; [10] RColorBrewer_1.1-3 fastmap_1.2.0      rprojroot_2.0.4   \n#&gt; [13] jsonlite_2.0.0     mnormt_2.1.1       cli_3.6.5         \n#&gt; [16] rlang_1.1.6        withr_3.0.2        tools_4.5.0       \n#&gt; [19] parallel_4.5.0     tzdb_0.5.0         pacman_0.5.1      \n#&gt; [22] vctrs_0.6.5        R6_2.6.1           lifecycle_1.0.4   \n#&gt; [25] htmlwidgets_1.6.4  pkgconfig_2.0.3    pillar_1.10.2     \n#&gt; [28] gtable_0.3.6       glue_1.8.0         xfun_0.52         \n#&gt; [31] tidyselect_1.2.1   rstudioapi_0.17.1  farver_2.1.2      \n#&gt; [34] htmltools_0.5.8.1  nlme_3.1-168       labeling_0.4.3    \n#&gt; [37] rmarkdown_2.29     compiler_4.5.0",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html",
    "href": "chapters/frequentist_inference/02_conf_interv.html",
    "title": "78  Intervalli di fiducia",
    "section": "",
    "text": "78.1 Introduzione\nGli intervalli di confidenza sono uno strumento fondamentale nell’inferenza statistica frequentista. Essi consentono di stimare un parametro sconosciuto di una popolazione, come la media \\(\\mu\\), tenendo conto dell’incertezza derivante dal fatto che la stima si basa su un campione. Questo materiale didattico si propone di spiegare in modo dettagliato e chiaro la costruzione di un intervallo di confidenza per la media di una popolazione, sia nel caso di varianza nota sia in quello di varianza incognita.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#inferenza-statistica-frequentista-e-media-campionaria",
    "href": "chapters/frequentist_inference/02_conf_interv.html#inferenza-statistica-frequentista-e-media-campionaria",
    "title": "78  Intervalli di fiducia",
    "section": "\n78.2 Inferenza Statistica Frequentista e Media Campionaria",
    "text": "78.2 Inferenza Statistica Frequentista e Media Campionaria\nQuando estraiamo un campione casuale semplice \\(X_1, X_2, \\dots, X_n\\) da una popolazione con media \\(\\mu\\) e varianza \\(\\sigma^2\\), la media campionaria \\(\\bar{X}\\) è definita come:\n\\[\n\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i.\n\\]\nLa media campionaria \\(\\bar{X}\\) è una variabile casuale perché dipende dai valori osservati nel campione, che sono essi stessi casuali. Le proprietà della media campionaria sono le seguenti:\n\n\nMedia della distribuzione campionaria: \\(E[\\bar{X}] = \\mu\\). La media campionaria è uno stimatore non distorto della media della popolazione.\n\nVarianza della distribuzione campionaria: \\(\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n}\\). Questo significa che la precisione di \\(\\bar{X}\\) come stima di \\(\\mu\\) aumenta con il numero di osservazioni \\(n\\).\n\nQueste proprietà sono fondamentali per calcolare un intervallo di confidenza, poiché ci permettono di descrivere la distribuzione di \\(\\bar{X}\\).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#intervallo-di-confidenza-per-la-media-caso-di-varianza-nota",
    "href": "chapters/frequentist_inference/02_conf_interv.html#intervallo-di-confidenza-per-la-media-caso-di-varianza-nota",
    "title": "78  Intervalli di fiducia",
    "section": "\n78.3 Intervallo di Confidenza per la Media: Caso di Varianza Nota",
    "text": "78.3 Intervallo di Confidenza per la Media: Caso di Varianza Nota\nSupponiamo che la popolazione sia distribuita normalmente con media \\(\\mu\\) e varianza \\(\\sigma^2\\), e che \\(\\sigma^2\\) sia nota. La distribuzione della media campionaria \\(\\bar{X}\\) è anch’essa normale:\n\\[\n\\bar{X} \\sim \\mathcal{N}\\left(\\mu, \\frac{\\sigma^2}{n}\\right).\n\\]\nPasso 1: Standardizzazione della Media Campionaria.\nPer lavorare con una distribuzione normale standard (media 0 e varianza 1), standardizziamo \\(\\bar{X}\\) utilizzando la formula:\n\\[\nZ = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}}.\n\\]\nQui, \\(\\sigma / \\sqrt{n}\\) è la deviazione standard della distribuzione campionaria di \\(\\bar{X}\\).\nDopo questa trasformazione, la variabile \\(Z\\) segue una distribuzione normale standard:\n\\[\nZ \\sim \\mathcal{N}(0, 1).\n\\]\nPasso 2: Determinazione del Livello di Confidenza.\nScegliamo un livello di confidenza \\(\\gamma\\), ad esempio \\(\\gamma = 0.95\\). Per una distribuzione normale standard, troviamo il valore critico \\(z\\) tale che la probabilità tra \\(-z\\) e \\(+z\\) sia pari al livello di confidenza:\n\\[\nP(-z \\leq Z \\leq z) = \\gamma.\n\\]\nPer un livello di confidenza del 95%, \\(z \\approx 1.96\\).\nPasso 3: Formulazione dell’Intervallo di Confidenza.\nPartiamo dalla probabilità per \\(Z\\):\n\\[\nP(-z \\leq Z \\leq z) = \\gamma.\n\\]\nSostituiamo la definizione di \\(Z\\):\n\\[\nP\\left(-z \\leq \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}} \\leq z\\right) = \\gamma.\n\\]\nMoltiplichiamo tutti i membri per \\(\\sigma / \\sqrt{n}\\) per rimuovere il denominatore:\n\\[\nP\\left(-z \\cdot \\frac{\\sigma}{\\sqrt{n}} \\leq \\bar{X} - \\mu \\leq z \\cdot \\frac{\\sigma}{\\sqrt{n}}\\right) = \\gamma.\n\\]\nAggiungiamo \\(\\mu\\) a tutti i membri per isolare \\(\\mu\\):\n\\[\nP\\left(\\bar{X} - z \\cdot \\frac{\\sigma}{\\sqrt{n}} \\leq \\mu \\leq \\bar{X} + z \\cdot \\frac{\\sigma}{\\sqrt{n}}\\right) = \\gamma.\n\\]\nPasso 4: Limiti dell’Intervallo di Confidenza.\nDefiniamo i limiti inferiore e superiore dell’intervallo di confidenza:\n\\[\n\\hat{a} = \\bar{X} - z \\cdot \\frac{\\sigma}{\\sqrt{n}}, \\quad \\hat{b} = \\bar{X} + z \\cdot \\frac{\\sigma}{\\sqrt{n}}.\n\\]\nL’intervallo di confidenza per \\(\\mu\\) è quindi:\n\\[\n(\\hat{a}, \\hat{b}) = \\left(\\bar{X} - z \\cdot \\frac{\\sigma}{\\sqrt{n}}, \\bar{X} + z \\cdot \\frac{\\sigma}{\\sqrt{n}}\\right).\n\\]",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#intervallo-di-confidenza-per-la-media-caso-di-varianza-incognita",
    "href": "chapters/frequentist_inference/02_conf_interv.html#intervallo-di-confidenza-per-la-media-caso-di-varianza-incognita",
    "title": "78  Intervalli di fiducia",
    "section": "\n78.4 Intervallo di Confidenza per la Media: Caso di Varianza Incognita",
    "text": "78.4 Intervallo di Confidenza per la Media: Caso di Varianza Incognita\nNella maggior parte dei casi pratici, la varianza \\(\\sigma^2\\) non è nota. In questi casi, stimiamo \\(\\sigma\\) con la deviazione standard campionaria \\(s\\) e utilizziamo la distribuzione t di Student, che tiene conto dell’incertezza aggiuntiva.\nPasso 1: Distribuzione t di Student.\nLa statistica che seguiamo è:\n\\[\nT = \\frac{\\bar{X} - \\mu}{s / \\sqrt{n}},\n\\]\ndove \\(T\\) segue una distribuzione t con \\(n-1\\) gradi di libertà.\nPasso 2: Costruzione dell’Intervallo di Confidenza.\nAnalogamente al caso precedente, costruiamo l’intervallo partendo da:\n\\[\nP(-t^\\ast \\leq T \\leq t^\\ast) = \\gamma,\n\\]\ndove \\(t^\\ast\\) è il valore critico della distribuzione t per il livello di confidenza \\(\\gamma\\) e \\(n-1\\) gradi di libertà.\nSostituendo \\(T\\):\n\\[\nP\\left(-t^\\ast \\leq \\frac{\\bar{X} - \\mu}{s / \\sqrt{n}} \\leq t^\\ast\\right) = \\gamma.\n\\]\nMoltiplichiamo per \\(s / \\sqrt{n}\\):\n\\[\nP\\left(-t^\\ast \\cdot \\frac{s}{\\sqrt{n}} \\leq \\bar{X} - \\mu \\leq t^\\ast \\cdot \\frac{s}{\\sqrt{n}}\\right) = \\gamma.\n\\]\nAggiungiamo \\(\\mu\\):\n\\[\nP\\left(\\bar{X} - t^\\ast \\cdot \\frac{s}{\\sqrt{n}} \\leq \\mu \\leq \\bar{X} + t^\\ast \\cdot \\frac{s}{\\sqrt{n}}\\right) = \\gamma.\n\\]\nPasso 3: Limiti dell’Intervallo.\nI limiti dell’intervallo sono:\n\\[\n\\hat{a} = \\bar{X} - t^\\ast \\cdot \\frac{s}{\\sqrt{n}}, \\quad \\hat{b} = \\bar{X} + t^\\ast \\cdot \\frac{s}{\\sqrt{n}}.\n\\]\nIn conclusione, gli intervalli di confidenza forniscono un modo per quantificare l’incertezza nelle stime di parametri sconosciuti. La loro costruzione dipende dalla distribuzione campionaria dello stimatore e dall’informazione disponibile sulla varianza.\n\n78.4.1 Applicabilità e Limitazioni\n\nIl metodo presuppone che la popolazione segua una distribuzione normale e è valido anche per campioni di piccole dimensioni (ad esempio, \\(n &lt; 30\\)) prelevati da tale popolazione.\nSe la popolazione non è normalmente distribuita e la dimensione del campione è ridotta, questo metodo potrebbe non essere idoneo.\nTuttavia, per campioni di grandi dimensioni (\\(n \\geq 30\\)), questo approccio rimane valido per la stima dell’intervallo di confidenza grazie al teorema del limite centrale, che si applica anche a popolazioni con distribuzioni non normali.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#livello-di-copertura",
    "href": "chapters/frequentist_inference/02_conf_interv.html#livello-di-copertura",
    "title": "78  Intervalli di fiducia",
    "section": "\n78.5 Livello di Copertura",
    "text": "78.5 Livello di Copertura\nPer interpretare correttamente gli intervalli di fiducia è fondamentale considerare il concetto di “livello di copertura”. Questo livello indica la frequenza con cui l’intervallo di fiducia include il valore reale del parametro della popolazione, in una serie di esperimenti ripetuti.\nEsempio di Livello di Copertura:\n\nSe il livello di copertura è del 95%, significa che, nel lungo periodo, il 95% degli intervalli di fiducia costruiti conterrà il valore vero del parametro.\nImportante: Questo non implica che ci sia una probabilità del 95% che il valore vero del parametro cada in un particolare intervallo di fiducia. Infatti, il parametro della popolazione è un valore fisso e non soggetto a probabilità; piuttosto, l’incertezza risiede nell’intervallo di fiducia stesso.\n\nCome Funziona la Copertura:\n\nNel contesto frequentista, la “probabilità” si riferisce alla frequenza a lungo termine di un certo evento in un gran numero di ripetizioni dell’esperimento.\nNel caso degli intervalli di fiducia, l’“esperimento” è l’estrazione di un campione dalla popolazione, e l’“evento” è la generazione di un intervallo di fiducia che contiene il valore vero del parametro.\nIl livello di copertura, generalmente indicato come \\(1-\\alpha\\), rappresenta la probabilità a lungo termine che intervalli di fiducia costruiti con questa metodologia includano il vero valore del parametro.\n\n\n78.5.1 Simulazione\n\nPer illustrare questo concetto, eseguiamo una simulazione con la popolazione degli adulti maschi italiani, assunta come normalmente distribuita con media 175 cm e varianza 49 cm².\nEseguiamo 1000 ripetizioni di un esperimento, estraendo ogni volta un campione di 30 individui.\nPer ciascun campione, calcoliamo l’intervallo di fiducia al 95% usando la formula:\n\n\\[\n\\bar{X} \\pm t \\frac{s}{\\sqrt{n}},\n\\]\ndove \\(\\bar{X}\\) è la media campionaria, \\(s\\) è la deviazione standard campionaria e \\(t\\) è il valore critico della distribuzione t-Student per \\(n-1\\) gradi di libertà al livello di significatività \\(\\alpha/2 = 0.025\\). - Registriamo i limiti di ciascun intervallo e controlliamo quanti di essi includono effettivamente il vero valore medio della popolazione.\nAttraverso questa simulazione, possiamo visualizzare concretamente il concetto di livello di copertura e la sua importanza nella statistica frequentista.\nIn questa simulazione, genereremo 1000 campioni casuali di dimensione \\(n = 30\\) da una distribuzione normale con media \\(\\mu = 175\\) e deviazione standard \\(\\sigma = 7\\). Successivamente, calcoleremo gli intervalli di confidenza al 95% per ciascun campione e valuteremo il livello di copertura.\n\nset.seed(123)  # Per riproducibilità\n\n# Parametri della distribuzione\nmu &lt;- 175\nsigma &lt;- 7\nn &lt;- 30\nn_samples &lt;- 1000\n\n# Generazione dei campioni\nsamples &lt;- replicate(n_samples, rnorm(n, mean = mu, sd = sigma))\ndim(samples)  # Verifica dimensioni: 30 righe per 1000 colonne\n#&gt; [1]   30 1000\n\nIl primo campione di ampiezza \\(n = 30\\) che abbiamo ottenuto è il seguente:\n\nsamples[, 1]  # Primo campione\n#&gt;  [1] 171.1 173.4 185.9 175.5 175.9 187.0 178.2 166.1 170.2 171.9 183.6 177.5\n#&gt; [13] 177.8 175.8 171.1 187.5 178.5 161.2 179.9 171.7 167.5 173.5 167.8 169.9\n#&gt; [25] 170.6 163.2 180.9 176.1 167.0 183.8\n\nStampiamo le medie dei primi dieci campioni:\n\nsample_means &lt;- colMeans(samples)  # Medie di tutti i campioni\nsample_means[1:10]  # Prime dieci medie\n#&gt;  [1] 174.7 176.2 175.2 174.3 173.7 176.1 175.1 174.4 175.4 177.4\n\nTroviamo il valore critico della distribuzione \\(t\\) di Student con \\(n - 1\\) gradi di libertà e livello di confidenza del 95% (\\(\\alpha = 0.05\\)):\n\nalpha &lt;- 0.05\nt_critical &lt;- qt(1 - alpha / 2, df = n - 1)  # Valore critico\nt_critical\n#&gt; [1] 2.045\n\nUtilizzando il valore critico \\(t\\), calcoliamo 1000 intervalli di confidenza per la media della popolazione:\n\n# Calcolo della deviazione standard campionaria\nsample_sds &lt;- apply(samples, 2, sd)\n\n# Ampiezza degli intervalli\ninterval_width &lt;- t_critical * sample_sds / sqrt(n)\n\n# Limiti degli intervalli di confidenza\nCI_low &lt;- sample_means - interval_width\nCI_high &lt;- sample_means + interval_width\n\nTroviamo il livello di copertura, ovvero la proporzione di intervalli di confidenza che contengono il vero valore della media della popolazione \\(\\mu\\):\n\ncoverage &lt;- mean(CI_low &lt; mu & mu &lt; CI_high)  # Proporzione di copertura\ncoverage\n#&gt; [1] 0.956\n\nIn conclusione, ripetendo la simulazione per 1000 campioni, abbiamo ottenuto un livello di copertura molto vicino al valore nominale di \\(1 - \\alpha = 0.95\\). Questo risultato dimostra che, con un campione di dimensione \\(n = 30\\), gli intervalli di confidenza al 95% calcolati utilizzando la distribuzione \\(t\\) di Student forniscono stime accurate della media della popolazione.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#il-concetto-di-livello-di-confidenza",
    "href": "chapters/frequentist_inference/02_conf_interv.html#il-concetto-di-livello-di-confidenza",
    "title": "78  Intervalli di fiducia",
    "section": "\n78.6 Il Concetto di Livello di Confidenza",
    "text": "78.6 Il Concetto di Livello di Confidenza\nGli intervalli di confidenza sono range di valori che, con una certa sicurezza statistica, si ritiene includano il parametro di interesse.\nSecondo l’approccio frequentista, l’intervallo di confidenza si deve considerare come una metodologia:\n\nSe ripetiamo l’esperimento (estrarre un campione e calcolare l’intervallo di confidenza) molte volte, il metodo produce un intervallo che coprirà il valore vero del parametro nel 95% dei casi, assumendo un livello di confidenza del 95%.\n\n\n78.6.1 Un Malinteso Comune nell’Interpretazione degli Intervalli di Confidenza\nÈ inesatto affermare che un determinato intervallo di confidenza contenga il valore vero di un parametro con una probabilità del 95%. Questo è un errore diffuso, persino tra i ricercatori, che spesso interpretano l’intervallo di confidenza come indicativo della probabilità che il parametro (ad esempio, la media della popolazione \\(\\mu\\)) si trovi effettivamente all’interno di un dato intervallo (es. \\([\\hat{a}, \\hat{b}]\\)).\nLa descrizione corretta è la seguente:\n\n“La metodologia impiegata per calcolare l’intervallo \\([\\hat{a}, \\hat{b}]\\) ha il 95% di probabilità di generare un intervallo che include il vero valore del parametro”.\nCiò significa che l’intervallo di confidenza non esprime una probabilità circa la posizione precisa del parametro, ma riflette la probabilità che la procedura adottata per determinarlo generi un intervallo che lo includa.\n\nIn conclusione, l’intervallo di confidenza ci fornisce una garanzia statistica riguardo alla affidabilità del metodo usato per la sua stima, piuttosto che sulla esatta ubicazione del parametro in questione.\n\n78.6.2 Fraintendimenti Comuni sugli Intervalli di Confidenza\nNel loro lavoro, Hoekstra et al. (2014) evidenziano come, nonostante l’ampio riconoscimento dei limiti dei test di ipotesi nulle, gli intervalli di confidenza siano spesso consigliati per l’inferenza statistica. Anche l’American Psychological Association (APA) suggerisce che gli intervalli di confidenza siano “in generale, la migliore strategia di reportistica”. Tuttavia, Hoekstra et al. (2014) sottolineano che queste raccomandazioni non considerano la difficoltà nel fornire una corretta interpretazione degli intervalli di confidenza.\nPer indagare l’interpretazione degli intervalli di confidenza, Hoekstra et al. (2014) hanno condotto uno studio con due domande principali:\n\nQuanto frequentemente intervalli di confidenza sono mal interpretati da studenti e ricercatori?\nL’esperienza nella ricerca riduce le interpretazioni errate degli intervalli di confidenza?\n\nPrima di presentare lo studio, Hoekstra et al. (2014) ricordano qual è l’interpretazione corretta degli intervalli di confidenza.\n\nA CI is a numerical interval constructed around the estimate of a parameter. Such an interval does not, however, directly indicate a property of the parameter; instead, it indicates a property of the procedure, as is typical for a frequentist technique. Specifically, we may find that a particular procedure, when used repeatedly across a series of hypothetical data sets (i.e., the sample space), yields intervals that contain the true parameter value in 95% of the cases. When such a procedure is applied to a particular data set, the resulting interval is said to be a 95% CI. The key point is that the CIs do not provide for a statement about the parameter as it relates to the particular sample at hand; instead, they provide for a statement about the performance of the procedure of drawing such intervals in repeated use. Hence, it is incorrect to interpret a CI as the probability that the true value is within the interval (e.g., Berger & Wolpert, 1988). As is the case with \\(p\\)-values, CIs do not allow one to make probability statements about parameters or hypotheses.\n\nNel loro studio, Hoekstra et al. (2014) hanno presentato un questionario a 596 partecipanti, tra cui studenti universitari e ricercatori, con le seguenti affermazioni riguardanti l’interpretazione degli intervalli di confidenza.\n\nProfessor Bumbledorf conducts an experiment, analyzes the data, and reports: “The 95% confidence interval for the mean ranges from 0.1 to 0.4.” Please mark each of the statements below as ‘true’ or ‘false’.\n\n\n\nThe probability that the true mean is greater than 0 is at least 95%.\nThe probability that the true mean equals 0 is smaller than 5%.\nThe “null hypothesis” that the true mean equals 0 is likely to be incorrect.\nThere is a 95% probability that the true mean lies between 0.1 and 0.4.\nWe can be 95% confident that the true mean lies between 0.1 and 0.4.\nIf we were to repeat the experiment over and over, then 95% of the time the true mean falls between 0.1 and 0.4.\n\n\nSorprendentemente, anche se tutte le sei affermazioni nel questionario sono errate, molti partecipanti hanno concordato con esse. I risultati mostrano che, in media, i partecipanti hanno concordato con circa 3.5 affermazioni errate su 6. Non è stata rilevata una differenza di rilievo nell’interpretazione degli intervalli di confidenza tra studenti e ricercatori, suggerendo che l’esperienza nella ricerca non migliora la comprensione di questo concetto.\nI risultati indicano che molte persone interpretano erroneamente gli intervalli di confidenza, e che anche l’esperienza nella ricerca non garantisce una migliore comprensione. Questo solleva dubbi sull’efficacia degli intervalli di confidenza frequentisti e suggerisce che gli “intervalli di credibilità” bayesiani possano rappresentare un’alternativa più vantaggiosa. Quest’ultimi tendono ad essere più intuitivi e di più facile interpretazione corretta.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#confronto-tra-intervalli-frequentisti-e-bayesiani",
    "href": "chapters/frequentist_inference/02_conf_interv.html#confronto-tra-intervalli-frequentisti-e-bayesiani",
    "title": "78  Intervalli di fiducia",
    "section": "\n78.7 Confronto tra Intervalli Frequentisti e Bayesiani",
    "text": "78.7 Confronto tra Intervalli Frequentisti e Bayesiani\nConcludiamo questo capitolo esaminando le differenze tra l’intervallo di confidenza frequentista e l’intervallo di credibilità bayesiano, utilizzando lo stesso set di dati per entrambi i calcoli.\n\n78.7.1 Intervallo di confidenza frequentista\nImmaginiamo di avere un gruppo di 20 osservazioni relative alla performance in un test cognitivo. Il nostro obiettivo è stimare la media della popolazione da cui queste osservazioni sono tratte. Supponiamo che i dati provengano da una distribuzione normale con media \\(\\mu = 50\\) e deviazione standard \\(\\sigma = 10\\).\n\nset.seed(123)  # Per risultati riproducibili\n\n# Parametri della popolazione\nsample_size &lt;- 20\nmu &lt;- 50\nsigma &lt;- 10\n\n# Simulazione del campione\nsample_data &lt;- rnorm(sample_size, mean = mu, sd = sigma)\nprint(sample_data)\n#&gt;  [1] 44.40 47.70 65.59 50.71 51.29 67.15 54.61 37.35 43.13 45.54 62.24 53.60\n#&gt; [13] 54.01 51.11 44.44 67.87 54.98 30.33 57.01 45.27\n\nVisualizziamo la distribuzione dei dati:\n\ntibble(Valori = sample_data) |&gt;\n  ggplot(aes(x = Valori)) +\n  geom_histogram(aes(y = after_stat(density)),\n    bins = 30, # Puoi regolare il numero di bin\n    fill = \"skyblue\",\n    color = \"black\",\n    alpha = 0.7\n  ) +\n  labs(\n    title = \"Distribuzione dei dati campionari\",\n    x = \"Valori\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\nLa media campionaria (\\(\\hat{\\mu}\\)) viene calcolata come:\n\\[\n\\hat{\\mu} = \\frac{1}{n} \\sum_{i=1}^n X_i\n\\]\nIn R:\n\nsample_mean &lt;- mean(sample_data)\nsample_mean\n#&gt; [1] 51.42\n\nLa deviazione standard campionaria (\\(s\\)) si calcola come:\n\\[\ns = \\sqrt{\\frac{\\sum_{i=1}^n (X_i - \\bar{X})^2}{n-1}}\n\\]\nIn R:\n\nvariance &lt;- function(x) {\n  sum((x - mean(x))^2) / length(x)\n}\n\nsample_sd &lt;- sqrt(variance(sample_data))  # Deviazione standard campionaria\nsample_sd\n#&gt; [1] 9.48\n\nL’errore standard della media (\\(SE\\)) è:\n\\[\nSE = \\frac{s}{\\sqrt{n}}\n\\]\nIn R:\n\nstandard_error &lt;- sample_sd / sqrt(sample_size)\nstandard_error\n#&gt; [1] 2.12\n\nUn intervallo di confidenza è definito come:\n\\[\n\\bar{X} \\pm t_{\\text{critico}} \\cdot SE\n\\]\ndove \\(t_{\\text{critico}}\\) è il valore critico della distribuzione \\(t\\) di Student per un livello di confidenza del 95% (\\(\\alpha = 0.05\\)) e \\(n-1\\) gradi di libertà. In R:\n\nalpha &lt;- 0.05\ndf &lt;- sample_size - 1\nt_critical &lt;- qt(1 - alpha / 2, df)\nt_critical\n#&gt; [1] 2.093\n\nCalcoliamo il margine di errore:\n\nmargin_of_error &lt;- t_critical * standard_error\nmargin_of_error\n#&gt; [1] 4.437\n\nCalcoliamo i limiti inferiore e superiore dell’intervallo di confidenza:\n\nconfidence_interval &lt;- \n  c(sample_mean - margin_of_error, sample_mean + margin_of_error)\nconfidence_interval\n#&gt; [1] 46.98 55.85\n\nPossiamo interpretare questo risultato dicendo che la procedura utilizzata per calcolare l’intervallo include il valore vero della media della popolazione nel 95% dei casi.\nCreiamo un grafico per mostrare la distribuzione dei dati, la media campionaria e l’intervallo di confidenza:\n\ntibble(Valori = sample_data) |&gt;\n  ggplot(aes(x = Valori)) +\n  geom_histogram(aes(y = ..density..),\n    bins = 30, # Puoi regolare il numero di bin\n    fill = \"skyblue\",\n    color = \"black\",\n    alpha = 0.7\n  ) +\n\n  # Linea per la media campionaria\n  geom_vline(aes(xintercept = sample_mean),\n    color = \"blue\",\n    linetype = \"dashed\",\n    linewidth = 1.2\n  ) +\n\n  # Linee per l'intervallo di confidenza\n  geom_vline(aes(xintercept = confidence_interval[1]),\n    color = \"darkgreen\",\n    linewidth = 1.2\n  ) +\n  geom_vline(aes(xintercept = confidence_interval[2]),\n    color = \"darkgreen\",\n    linewidth = 1.2\n  ) +\n\n  # Titoli e assi\n  labs(\n    title = \"Intervallo di Confidenza per la Media\",\n    x = \"Valori\",\n    y = \"Densità\"\n  ) +\n\n  # Legenda personalizzata\n  annotate(\"text\",\n    x = sample_mean, y = 0.02, label = \"Media campionaria\",\n    color = \"blue\", angle = 90, vjust = -0.5\n  ) +\n  annotate(\"text\",\n    x = confidence_interval[1], y = 0.02, label = \"IC Inferiore\",\n    color = \"darkgreen\", angle = 90, vjust = -0.5\n  ) +\n  annotate(\"text\",\n    x = confidence_interval[2], y = 0.02, label = \"IC Superiore\",\n    color = \"darkgreen\", angle = 90, vjust = -0.5\n  )\n\n\n\n\n\n\n\n\n78.7.1.1 Confronto tra gli Approcci Frequentista e Bayesiano\nIntervallo di Credibilità Bayesiano:\n\nRappresenta il grado di credenza (posteriori) che il parametro \\(\\mu\\) si trovi all’interno dell’intervallo calcolato.\nDipende sia dai dati osservati sia dalle distribuzioni a priori utilizzate nel modello, che possono influenzare il risultato in base alla loro specificità o vaghezza.\n\nIntervallo di Confidenza Frequentista:\n\nNon esprime la probabilità che il parametro \\(\\mu\\) appartenga a un determinato intervallo.\nSi riferisce invece alla procedura di costruzione dell’intervallo: se il campionamento fosse ripetuto infinite volte, il 95% degli intervalli costruiti conterrebbe il vero valore di \\(\\mu\\).\n\nIn sintesi:\n\nL’intervallo di credibilità bayesiano fornisce una stima probabilistica diretta e interpretabile della posizione di \\(\\mu\\), basata su dati osservati e informazioni a priori.\nL’intervallo di confidenza frequentista, invece, valuta la affidabilità della procedura nel lungo termine, senza fare affermazioni dirette sulla probabilità che il parametro rientri nell’intervallo specifico.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/02_conf_interv.html#riflessioni-conclusive",
    "title": "78  Intervalli di fiducia",
    "section": "\n78.8 Riflessioni Conclusive",
    "text": "78.8 Riflessioni Conclusive\nCome sottolineato da Hoekstra et al. (2014), è comune riscontrare fraintendimenti riguardo agli intervalli di fiducia. Il “livello di confidenza del 95%” è da interpretarsi come la probabilità a lungo termine che, in una serie di intervalli di fiducia calcolati, il 95% di essi includa il vero valore del parametro sconosciuto. Tuttavia, per un singolo intervallo di fiducia, non è possibile dichiarare con sicurezza che questo contenga effettivamente il parametro di interesse. In altre parole, la certezza sulla presenza del parametro sconosciuto all’interno di un dato intervallo di fiducia non è garantita per ogni singolo caso analizzato.\nÈ inoltre inesatto presumere che esista un legame diretto tra la varianza e la media di un campione, ipotizzando che un intervallo di fiducia più ristretto implichi maggiore precisione. Nella prospettiva frequentista, la “precisione” è strettamente legata al livello di copertura a lungo termine assicurato dal metodo usato per creare gli intervalli di fiducia. Questo concetto non si applica al singolo intervallo di fiducia osservato. Dunque, un intervallo di fiducia che si presenta estremamente ristretto potrebbe in realtà essere significativamente lontano dal valore vero del parametro non noto.\nÈ importante sottolineare che l’approccio frequentista offre un metodo per calcolare gli intervalli di confidenza per una vasta gamma di statistiche. Questo include, ad esempio, la stima dell’intervallo di confidenza per la differenza tra due medie, per una proporzione o per la differenza tra due proporzioni. Ecco le formule per calcolare gli intervalli di confidenza per i casi menzionati:\nIntervallo di confidenza per la differenza tra due medie.\nSe abbiamo due campioni indipendenti di dimensione \\(n_1\\) e \\(n_2\\), con medie \\(\\bar{x}_1\\) e \\(\\bar{x}_2\\) e deviazioni standard \\(s_1\\) e \\(s_2\\), l’intervallo di confidenza per la differenza tra le medie è calcolato come:\n\\[\n(\\bar{x}_1 - \\bar{x}_2) \\pm t_{\\alpha/2} \\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}},\n\\]\ndove \\(t_{\\alpha/2}\\) è il valore critico della distribuzione t di Student con \\(\\alpha/2\\) di probabilità di coda e gradi di libertà \\(df = n_1 + n_2 - 2\\).\nIntervallo di confidenza per una proporzione.\nPer stimare l’intervallo di confidenza per una proporzione \\(p\\) in un campione binomiale di dimensione \\(n\\), la formula è:\n\\[\n\\hat{p} \\pm z_{\\alpha/2} \\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}},\n\\]\ndove \\(\\hat{p}\\) è la proporzione campionaria e \\(z_{\\alpha/2}\\) è il valore critico della distribuzione normale standard con \\(\\alpha/2\\) di probabilità di coda.\nIntervallo di confidenza per la differenza tra due proporzioni.\nPer stimare l’intervallo di confidenza per la differenza tra due proporzioni \\(p_1\\) e \\(p_2\\) in due campioni binomiali di dimensioni \\(n_1\\) e \\(n_2\\), la formula è:\n\\[\n(\\hat{p}_1 - \\hat{p}_2) \\pm z_{\\alpha/2} \\sqrt{\\frac{\\hat{p}_1(1 - \\hat{p}_1)}{n_1} + \\frac{\\hat{p}_2(1 - \\hat{p}_2)}{n_2}},\n\\]\ndove \\(\\hat{p}_1\\) e \\(\\hat{p}_2\\) sono le proporzioni campionarie e \\(z_{\\alpha/2}\\) è il valore critico della distribuzione normale standard con \\(\\alpha/2\\) di probabilità di coda.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#esercizi",
    "href": "chapters/frequentist_inference/02_conf_interv.html#esercizi",
    "title": "78  Intervalli di fiducia",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\n\nChe cos’è un intervallo di confidenza dal punto di vista frequentista?\nChe cosa significa la copertura al 95% di un intervallo di confidenza?\nPerché non è corretto dire che “c’è il 95% di probabilità che il valore vero di \\(\\mu\\) cada in questo intervallo di confidenza”?\nIn cosa consiste la differenza tra un intervallo di confidenza costruito con la distribuzione normale standard \\(Z\\) e uno costruito con la distribuzione \\(t\\) di Student?\nPerché, nel caso di varianza incognita, si usa la deviazione standard campionaria \\(s\\) al posto di \\(\\sigma\\)?\nCome influenza la dimensione del campione \\(n\\) l’ampiezza dell’intervallo di confidenza?\nPerché gli intervalli di confidenza frequentisti si basano su un concetto di “ripetizione dell’esperimento” nel lungo periodo?\nQuali sono due fraintendimenti comuni sugli intervalli di confidenza?\nCome si interpreta correttamente un intervallo di confidenza al 95%?\nQual è la differenza essenziale tra un intervallo di confidenza frequentista e un intervallo di credibilità bayesiano?\n\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\n\nChe cos’è un intervallo di confidenza dal punto di vista frequentista?\n\nRisposta\nUn intervallo di confidenza (IC) è un range di valori costruito attorno a una stima campionaria (ad esempio, la media campionaria) che, secondo il metodo frequentista adottato, conterrà il valore vero del parametro in una certa proporzione di casi (ad esempio il 95%) se si ripetesse l’esperimento (ossia il campionamento) un numero molto grande di volte. Non esprime dunque la “probabilità” che il parametro sia dentro l’intervallo in un singolo caso, ma una frequenza di successo nel lungo periodo.\n\nChe cosa significa la copertura al 95% di un intervallo di confidenza?\n\nRisposta\nIl livello di copertura (ad esempio, 95%) indica che, in una serie ipotetica di infiniti campioni indipendenti e nel calcolo ripetuto di infiniti intervalli di confidenza secondo la stessa procedura, il 95% di tali intervalli conterrà il valore vero del parametro. È una proprietà della procedura di costruzione degli intervalli, non di un singolo intervallo già calcolato.\n\nPerché non è corretto dire che “c’è il 95% di probabilità che il valore vero di \\(\\mu\\) cada in questo intervallo di confidenza”?\n\nRisposta\nNella prospettiva frequentista, il parametro \\(\\mu\\) è considerato un valore fisso (non una variabile casuale). L’incertezza risiede nel campione e nella procedura di costruzione dell’intervallo, non nel parametro. Di conseguenza, non si può associare una probabilità alla posizione di \\(\\mu\\) all’interno di un singolo intervallo: l’intervallo o contiene \\(\\mu\\) oppure no, senza mezze misure probabilistiche.\n\nIn cosa consiste la differenza tra un intervallo di confidenza costruito con la distribuzione normale standard \\(Z\\) e uno costruito con la distribuzione \\(t\\) di Student?\n\nRisposta\n- Distribuzione \\(Z\\): si utilizza quando la varianza della popolazione \\(\\sigma^2\\) è nota (o si approssima molto bene) e la popolazione è normalmente distribuita, o quando il campione è molto grande (per applicare il teorema del limite centrale).\n- Distribuzione \\(t\\): si impiega quando la varianza \\(\\sigma^2\\) non è nota e bisogna stimarla con la deviazione standard campionaria \\(s\\). La distribuzione \\(t\\) “corregge” per l’incertezza aggiuntiva dovuta alla stima di \\(\\sigma\\) e diventa progressivamente simile alla normale standard quando il numero di gradi di libertà (cioè la dimensione del campione meno uno) è elevato.\n\nPerché, nel caso di varianza incognita, si usa la deviazione standard campionaria \\(s\\) al posto di \\(\\sigma\\)?\n\nRisposta\nQuando \\(\\sigma\\) non è nota, la si sostituisce con la stima campionaria \\(s\\). Poiché \\(s\\) è anch’essa una variabile casuale (cioè dipende dai dati osservati), introduce un’ulteriore fonte di incertezza. Questo giustifica l’uso della distribuzione \\(t\\) di Student anziché della normale standard, poiché \\(t\\) ingloba tale incertezza aggiuntiva.\n\nCome influenza la dimensione del campione \\(n\\) l’ampiezza dell’intervallo di confidenza?\n\nRisposta\nAumentando \\(n\\), l’errore standard della media (cioè \\(\\frac{\\sigma}{\\sqrt{n}}\\) oppure \\(\\frac{s}{\\sqrt{n}}\\)) diminuisce. Di conseguenza, l’intervallo di confidenza si restringe (a parità di livello di confidenza). In altre parole, con più dati a disposizione la stima della media è più “precisa” nel senso frequentista, e ciò si riflette in un IC più stretto.\n\nPerché gli intervalli di confidenza frequentisti si basano su un concetto di “ripetizione dell’esperimento” nel lungo periodo?\n\nRisposta\nLa filosofia frequentista definisce la probabilità come una frequenza relativa di un evento dopo molteplici repliche dell’esperimento. Per gli intervalli di confidenza, ciò implica che la probabilità di copertura (ad esempio 95%) è intesa come la frequenza con cui, ripetendo infinite volte il campionamento e la costruzione di IC allo stesso modo, l’intervallo calcolato conterrà il vero parametro. Non riguarda invece la probabilità del parametro di trovarsi in un intervallo specifico.\n\nQuali sono due fraintendimenti comuni sugli intervalli di confidenza?\n\nRisposta\n1. Credere che l’IC fornisca una probabilità diretta di contenere il parametro (es. “c’è il 95% di probabilità che \\(\\mu\\) sia qui dentro”) – in realtà, nel frequentismo \\(\\mu\\) è fisso e l’IC varia.\n2. Pensare che l’intervallo di confidenza sia significativo per la singola stima più che per la procedura – in realtà, il 95% di copertura si riferisce alla ripetizione dell’esperimento, non a un singolo intervallo.\n\nCome si interpreta correttamente un intervallo di confidenza al 95%?\n\nRisposta\n“Se ripetiamo più volte l’esperimento, ossia estraiamo molti campioni indipendenti dalla popolazione e costruiamo ogni volta un intervallo di confidenza con la stessa procedura, allora il 95% di quegli intervalli conterrà il valore vero della media \\(\\mu\\).” È dunque una garanzia circa l’efficacia della metodologia nel lungo periodo.\n\nQual è la differenza essenziale tra un intervallo di confidenza frequentista e un intervallo di credibilità bayesiano?\n\nRisposta\n- Intervallo di confidenza frequentista: descrive la performance a lungo termine di una procedura; non permette di affermare “la probabilità che \\(\\mu\\) sia nell’intervallo è il 95%”.\n- Intervallo di credibilità bayesiano: esprime direttamente una credenza probabilistica a posteriori sul parametro (ad esempio, “c’è il 95% di probabilità che \\(\\mu\\) sia in questo intervallo”), perché il parametro è trattato come variabile casuale, con una distribuzione a priori che si aggiorna con i dati osservati.\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nDi seguito trovi 10 esercizi incentrati sulla costruzione di intervalli di confidenza. I primi 5 richiedono di svolgere i calcoli “a mano” (carta e penna o calcolatrice), gli ultimi 5 prevedono l’utilizzo di R.\nEsercizi da Risolvere “a Mano”\n\nIntervallo di Confidenza per la Media (Varianza Nota)\n\nUna ricercatrice vuole stimare la media di un punteggio di reattività emotiva (scala 0–100) in giovani adulti. Dai dati precedenti, si sa che la varianza vera (della popolazione) è \\(\\sigma^2 = 16\\). Si raccoglie un campione di \\(n=25\\) partecipanti e la media campionaria risulta \\(\\bar{X} = 45\\).\n1. Calcola l’intervallo di confidenza al 95% per la media della popolazione (\\(\\mu\\)).\n2. Fornisci un’interpretazione corretta (frequentista) del risultato.\n\nIntervallo di Confidenza per la Media (Varianza Incognita, 99%)\n\nIn un’indagine sulla soddisfazione lavorativa (scala da 1 a 7), vengono coinvolti \\(n=10\\) psicologi clinici. I dati raccolti forniscono:\n- Media campionaria \\(\\bar{X} = 5{,}6\\)\n- Deviazione standard campionaria \\(s=0{,}8\\)\nLa popolazione è considerata approssimativamente normale ma la varianza è ignota. Calcola l’IC al 99% per la vera media di soddisfazione \\(\\mu\\).\n\nIntervallo di Confidenza per la Differenza tra Due Medie (Varianze Incognite Uguali)\n\nUn team di psicologi del lavoro vuole confrontare i livelli di stress (scala 0–50) tra due gruppi di dipendenti di un’azienda (Campione 1: reparto A, Campione 2: reparto B). I dati sono:\n\nReparto A (\\(n_1=12\\)):\\(\\bar{X}_1 = 22\\), \\(s_1 = 4\\)\nReparto B (\\(n_2=10\\)):\\(\\bar{X}_2 = 19\\), \\(s_2 = 3{,}5\\)\n\nAssumi che le due popolazioni siano normali con varianze ignote ma uguali e calcola l’intervallo di confidenza al 95% per \\(\\mu_A - \\mu_B\\). (Usa quindi la formula con la varianza pooled.)\n\nIntervallo di Confidenza per una Proporzione\n\nUno studio pilota su un programma di training per la gestione dell’ansia vede 120 persone iscriversi. Alla fine del programma, 48 di loro riportano di aver diminuito la frequenza di attacchi di panico in modo “significativo”.\n1. Stima la proporzione campionaria \\(\\hat{p}\\).\n2. Calcola l’IC al 95% per la vera proporzione \\(p\\) di persone che trarrebbe beneficio “significativo” dal programma.\n\nIntervallo di Confidenza per la Differenza tra Due Proporzioni\n\nIn un esperimento, due gruppi di partecipanti ricevono diversi percorsi di psicoterapia per ridurre l’insonnia:\n\n\nGruppo 1 (\\(n_1=50\\)): 35 persone riportano un netto miglioramento del sonno.\n\n\nGruppo 2 (\\(n_2=40\\)): 20 persone riportano un netto miglioramento del sonno.\n\nSi vuole stimare la differenza \\((p_1 - p_2)\\) nelle proporzioni di successo dei due trattamenti. Calcola l’IC al 95%.\nEsercizi da Risolvere con R\nNei prossimi esercizi, utilizza R per effettuare i calcoli. I dati sono già contestualizzati in ambito psicologico.\n\nIntervallo di Confidenza per la Media (Varianza Incognita)\n\nHai misurato i tempi di reazione (in millisecondi) a uno stimolo di pericolo in un gruppo di 15 partecipanti. I dati (approssimati) sono:\nreaction_times &lt;- c(220, 250, 210, 240, 260, 270, 225, 255, 235, 245, 210, 270, 265, 220, 230)\n\nUtilizza R per calcolare la media e la deviazione standard campionaria.\n\nCostruisci (tramite t.test(reaction_times)) l’intervallo di confidenza al 95% per il tempo di reazione medio della popolazione.\n\n\nIntervallo di Confidenza per la Differenza tra Due Medie (Varianze Incognite)\n\nDue gruppi di studenti hanno svolto un test di memoria verbale dopo aver seguito differenti strategie di studio:\ngroupA &lt;- c(15, 12, 18, 10, 14, 16, 19, 11)\ngroupB &lt;- c(10, 9, 14, 11, 8, 12, 13, 15)\n\nCalcola in R le medie campionarie dei due gruppi.\n\nUtilizza t.test(groupA, groupB, var.equal = FALSE) per ottenere l’IC al 95% della differenza \\(\\mu_A - \\mu_B\\).\n\nRiporta i risultati numerici.\n\n\nIntervallo di Confidenza per una Proporzione (Studio su Fobia Specifica)\n\nIn un piccolo studio, hai i dati (binari: 1 = “attacco d’ansia”, 0 = “nessun attacco”) raccolti da 20 persone esposte a uno stimolo fobico:\nattacks &lt;- c(1,0,0,1,1,1,1,0,0,1,0,1,1,1,1,0,0,1,0,1)\n\nCalcola in R la proporzione campionaria di attacchi d’ansia.\n\nUtilizza prop.test() per costruire l’IC al 95% per la proporzione vera di attacchi d’ansia in questa specifica situazione.\n\n\nIntervallo di Confidenza per la Differenza tra Due Proporzioni (Test A/B di un Training Psicologico)\n\nDue versioni di un training psicologico anti-stress (A e B) sono state testate su studenti universitari, registrando (binario: 1/0) se al termine del corso mostrano ridotti livelli di stress:\nversionA &lt;- c(1,1,0,1,1,0,1,0,1,1,0,1)\nversionB &lt;- c(0,0,1,1,1,0,1,0,0,1,0,0)\n\nCalcola in R \\(\\hat{p}_A\\) e \\(\\hat{p}_B\\).\n\nUsa prop.test(x = ..., n = ...) per l’IC al 95% di \\((p_A - p_B)\\).\n\nRiporta i risultati.\n\n\nSimulazione di Copertura per l’IC sulla Media (Contesto Psicologico)\n\nScrivi (o completa) uno script in R che simuli 1000 campioni di punteggi di ansia (scala 0–80) estratti da una distribuzione approssimata come Normale, con media vera \\(\\mu=40\\) e \\(\\sigma=10\\). Per ogni campione di ampiezza \\(n=25\\):\n\nCalcola la media campionaria e la deviazione standard.\n\nCostruisci l’IC al 95% (usando la distribuzione t).\n\nVerifica quante volte l’intervallo contiene il vero valore \\(\\mu = 40\\).\n\nStima la proporzione di copertura e commenta se è prossima a 0,95.\n\nEsempio di traccia:\nset.seed(123)\nn_sims &lt;- 1000\nn &lt;- 25\nmu &lt;- 40\nsigma &lt;- 10\n\ncount_included &lt;- 0\n\nfor(i in 1:n_sims){\n  sample_data &lt;- rnorm(n, mean = mu, sd = sigma)\n  # calcola media, sd, IC, verifica se 40 è dentro l’IC\n}\n\ncoverage &lt;- count_included / n_sims\ncoverage\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\nSoluzioni Esercizi “a Mano”\nSoluzione 1\n\nDati: \\(\\sigma^2=16 \\implies \\sigma=4\\); \\(n=25\\); \\(\\bar{X}=45\\); livello di confidenza 95% (\\(\\alpha=0{,}05\\)).\n\nErrore standard:\\[\n\\text{SE} = \\frac{\\sigma}{\\sqrt{n}} = \\frac{4}{5} = 0{,}8.\n\\]\n\nValore critico \\(z_{\\alpha/2}\\approx 1{,}96\\).\n\nMargine di errore:\\[\nE = z_{\\alpha/2} \\times \\text{SE} \\approx 1{,}96 \\times 0{,}8 = 1{,}57.\n\\]\n\nIC 95%:\\[\n45 \\pm 1{,}57 \\quad \\Rightarrow \\quad (43{,}43;\\, 46{,}57).\n\\]\n\n\nSoluzione 2\n\nDati: \\(n=10\\), \\(\\bar{X}=5{,}6\\), \\(s=0{,}8\\), confidenza 99% (\\(\\alpha=0{,}01\\)).\n\nGradi di libertà \\(df = 9\\). Il valore di \\(t_{\\alpha/2, df=9}\\) (per \\(\\alpha/2=0{,}005\\)) è approssimativamente 3,25 (dipende dalla tabella).\n\nErrore standard:\\[\n\\text{SE} = \\frac{s}{\\sqrt{n}} = \\frac{0{,}8}{\\sqrt{10}} \\approx \\frac{0{,}8}{3{,}162} \\approx 0{,}253.\n\\]\n\nMargine di errore:\\[\nE = 3{,}25 \\times 0{,}253 \\approx 0{,}82.\n\\]\n\nIC al 99%:\\[\n5{,}6 \\pm 0{,}82 \\quad \\Rightarrow \\quad (4{,}78;\\, 6{,}42).\n\\]\n\n\nSoluzione 3\n\nDati:\n\nCampione 1 (A): \\(n_1=12\\), \\(\\bar{X}_1=22\\), \\(s_1=4\\).\n\nCampione 2 (B): \\(n_2=10\\), \\(\\bar{X}_2=19\\), \\(s_2=3{,}5\\).\n\nIC 95% \\(\\Rightarrow \\alpha=0{,}05\\).\n\nSi assume varianza uguale (\\(\\sigma_A^2 = \\sigma_B^2\\)) \\(\\Rightarrow\\) varianza pooled.\n\n\n\n\nVarianza campionaria: \\(s_1^2=16\\), \\(s_2^2=12{,}25\\).\n\nVarianza pooled:\\[\ns_p^2\n= \\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}\n= \\frac{(11 \\times 16) + (9 \\times 12{,}25)}{12 + 10 - 2}.\n\\] \\[\n= \\frac{176 + 110{,}25}{20}\n= \\frac{286{,}25}{20}\n= 14{,}3125.\n\\] \\[\ns_p = \\sqrt{14{,}3125} \\approx 3{,}785.\n\\]\n\nErrore standard della differenza:\\[\n\\text{SE}(\\bar{X}_1 - \\bar{X}_2)\n= \\sqrt{\\,s_p^2\\!\\left(\\tfrac{1}{n_1} + \\tfrac{1}{n_2}\\right)}\n= \\sqrt{\\,14{,}3125 \\times \\left(\\tfrac{1}{12} + \\tfrac{1}{10}\\right)}.\n\\] \\[\n\\tfrac{1}{12} + \\tfrac{1}{10} = 0{,}0833 + 0{,}1 = 0{,}1833.\n\\] \\[\n14{,}3125 \\times 0{,}1833 \\approx 2{,}624\n\\quad \\Rightarrow \\quad \\sqrt{2{,}624} \\approx 1{,}62.\n\\]\n\nDifferenza campionaria: \\(\\bar{X}_1 - \\bar{X}_2 = 3\\).\n\nValore critico \\(t_{\\alpha/2}\\) con \\(df = n_1 + n_2 - 2 = 20\\): circa 2,086.\n\nMargine di errore: \\(E \\approx 2{,}086 \\times 1{,}62 \\approx 3{,}38\\).\n\nIC 95%:\\[\n3 \\pm 3{,}38 \\quad \\Rightarrow \\quad (-0{,}38;\\, 6{,}38).\n\\] (Approssimando: i valori variano un po’ in base agli arrotondamenti.)\n\n\nSoluzione 4\n\nDati: \\(n=120\\), successo \\(x=48\\).\n\n\n\\(\\hat{p} = \\frac{48}{120}=0{,}4\\).\n\nErrore standard (approssimazione normale):\\[\n\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} = \\sqrt{\\frac{0{,}4 \\times 0{,}6}{120}} = \\sqrt{\\frac{0{,}24}{120}} = \\sqrt{0{,}002} \\approx 0{,}0447.\n\\]\n\nCon \\(\\alpha=0{,}05\\), \\(z_{\\alpha/2} \\approx 1{,}96\\).\n\nMargine di errore:\\[\nE = 1{,}96 \\times 0{,}0447 \\approx 0{,}0876.\n\\]\n\nIC 95%:\\[\n0{,}4 \\pm 0{,}0876 \\quad \\Rightarrow \\quad (0{,}3124;\\, 0{,}4876).\n\\]\n\n\nSoluzione 5\n\nDati:\n\nGruppo 1 (\\(n_1=50\\)): 35 successi \\(\\Rightarrow \\hat{p}_1=35/50=0{,}70\\).\n\nGruppo 2 (\\(n_2=40\\)): 20 successi \\(\\Rightarrow \\hat{p}_2=20/40=0{,}50\\).\n\n\n\nDifferenza: \\(\\hat{p}_1 - \\hat{p}_2=0{,}20\\).\n\nErrore standard:\\[\n\\sqrt{\\frac{0{,}70 \\cdot 0{,}30}{50} + \\frac{0{,}50 \\cdot 0{,}50}{40}}\n= \\sqrt{\\frac{0{,}21}{50} + \\frac{0{,}25}{40}}\n= \\sqrt{0{,}0042 + 0{,}00625}\n= \\sqrt{0{,}01045} \\approx 0{,}1022.\n\\]\n\nMargine di errore (al 95%, \\(z_{\\alpha/2}=1{,}96\\)):\\[\n1{,}96 \\times 0{,}1022 \\approx 0{,}200.\n\\]\n\nIC 95%:\\[\n0{,}20 \\pm 0{,}20 \\quad \\Rightarrow \\quad (0{,}00;\\, 0{,}40).\n\\] *(Può capitare un limite inferiore esattamente 0, se si arrotonda.)\n\nSoluzioni Esercizi con R\n(I risultati possono variare leggermente a seconda della versione di R e di eventuali correzioni di continuità nelle funzioni di test.)\nSoluzione 6\nreaction_times &lt;- c(220, 250, 210, 240, 260, 270, 225, 255, 235, 245, 210, 270, 265, 220, 230)\n\nmean(reaction_times)         # media\nsd(reaction_times)           # deviazione standard\nt.test(reaction_times)       # t.test con conf.level = 0.95 di default\n\nEsempio di risultato:\n\nMedia campionaria \\(\\bar{X}\\approx 240\\) (dipende dai dati esatti)\n\n\nt.test() riporta un IC 95% (ad es.): \\((230, 250)\\) [numeri a titolo di esempio].\n\n\n\nSoluzione 7\ngroupA &lt;- c(15, 12, 18, 10, 14, 16, 19, 11)\ngroupB &lt;- c(10, 9, 14, 11, 8, 12, 13, 15)\n\nmean(groupA)  # ~ 14.375\nmean(groupB)  # ~ 11.50\nt.test(groupA, groupB, var.equal = FALSE)\n\n\nEsempio di output (fittizio):\nWelch Two Sample t-test\ndata:  groupA and groupB\nt = 2.35, df = 13.7, p-value = 0.033\n95 percent confidence interval:\n  0.47  5.77\nsample estimates:\n  mean of x  mean of y \n      14.375     11.500\nQuindi l’IC 95% per \\(\\mu_A - \\mu_B\\) potrebbe essere circa \\((0{,}47;\\, 5{,}77)\\).\n\n\nSoluzione 8\nattacks &lt;- c(1,0,0,1,1,1,1,0,0,1,0,1,1,1,1,0,0,1,0,1)\n\nsum(attacks)        # conta quanti \"1\"\nlength(attacks)     # 20\n\nprop.test(sum(attacks), length(attacks), conf.level = 0.95)\n\nSe, ad esempio, vi fossero 12 “1” su 20, \\(\\hat{p}=0{,}60\\).\n\nL’intervallo di confidenza al 95% (a seconda della continuity correction) potrebbe essere indicativamente \\((0{,}36;\\, 0{,}80)\\).\n\nSoluzione 9\nversionA &lt;- c(1,1,0,1,1,0,1,0,1,1,0,1)\nversionB &lt;- c(0,0,1,1,1,0,1,0,0,1,0,0)\n\nsumA &lt;- sum(versionA)\nsumB &lt;- sum(versionB)\nnA   &lt;- length(versionA)\nnB   &lt;- length(versionB)\n\nprop.test(c(sumA,sumB), c(nA,nB), conf.level = 0.95)\n\nEsempio:\n\n\nsum(versionA) = 8 successi su 12 (\\(\\hat{p}_A=0{,}666...\\))\n\n\nsum(versionB) = 5 successi su 12 (\\(\\hat{p}_B=0{,}416...\\))\n\nL’IC per \\(\\hat{p}_A - \\hat{p}_B\\) potrebbe essere, ad esempio, \\((-0{,}05;\\, 0{,}61)\\).\n\n\n\n(I numeri esatti variano a seconda dell’eventuale correzione di continuità.)\nSoluzione 10\nUn possibile script:\nset.seed(123)\nn_sims &lt;- 1000\nn &lt;- 25\nmu &lt;- 40\nsigma &lt;- 10\n\ncount_included &lt;- 0\n\nfor(i in 1:n_sims){\n  sample_data &lt;- rnorm(n, mean = mu, sd = sigma)\n  xbar &lt;- mean(sample_data)\n  s &lt;- sd(sample_data)\n  \n  # t critico\n  t_crit &lt;- qt(0.975, df = n - 1)\n  \n  # IC\n  se &lt;- s / sqrt(n)\n  E &lt;- t_crit * se\n  lower &lt;- xbar - E\n  upper &lt;- xbar + E\n  \n  if(mu &gt;= lower & mu &lt;= upper){\n    count_included &lt;- count_included + 1\n  }\n}\n\ncoverage &lt;- count_included / n_sims\ncoverage\n\n\nEsempio di risultato:\n&gt; coverage\n[1] 0.948\nOvvero ~94,8% degli IC contengono il vero valore \\(\\mu=40\\), in linea con il 95% atteso (piccole differenze dovute al caso).\n\n\nCommento Conclusivo\nIn ogni caso, ricorda sempre che l’interpretazione frequentista di un intervallo di confidenza si basa sulla “copertura a lungo termine” del metodo di costruzione dell’IC, non sulla probabilità che il vero parametro cada nell’intervallo specifico appena calcolato.\n\n\n\n\n\n\n\n\n\nProblemi 3\n\n\n\n\n\nEsercizio 1 – Calcolo e interpretazione dell’IC frequentista per la media\n\n\nCalcola la media campionaria \\(\\bar{X}\\) e la deviazione standard campionaria \\(s\\).\n\nAssumendo che il punteggio SWLS nella popolazione di riferimento (ad esempio, “giovani adulti universitari”) sia approssimativamente normale ma con varianza sconosciuta, costruisci l’intervallo di confidenza al 95% per la media \\(\\mu\\) utilizzando la distribuzione \\(t\\) di Student con \\(n - 1\\) gradi di libertà (dove \\(n=10\\)).\n\n\nInterpreta questo intervallo di confidenza in ottica frequentista. Metti in evidenza la distinzione fra l’“interpretazione corretta” (copertura sul lungo periodo) e l’“interpretazione scorretta” (credere che ci sia il 95% di probabilità che \\(\\mu\\) stia nell’intervallo calcolato).\n\nSpunti di riflessione sui limiti:\n- Con un campione molto piccolo, l’intervallo di confidenza potrebbe essere molto ampio.\n- Se la popolazione non fosse davvero normale, la validità dell’IC con distribuzione \\(t\\) potrebbe essere compromessa.\n- In ottica frequentista, il singolo intervallo o contiene il vero valore di \\(\\mu\\) o non lo contiene: la “probabilità 95%” si riferisce alla procedura di costruzione, non a questo singolo intervallo specifico.\nEsercizio 2 – Sensibilità dell’IC a diversi livelli di confidenza\n\nUtilizzando gli stessi 10 dati, calcola:\n\nl’intervallo di confidenza all’80%\n\nl’intervallo di confidenza al 99%\n\n\n\nConfronta l’ampiezza dei tre intervalli (80%, 95%, 99%).\n\nCommenta dal punto di vista dell’interpretazione frequentista: perché l’IC al 99% è più ampio di quello al 95%, e quest’ultimo è più ampio di quello all’80%?\n\nSpunti di riflessione sui limiti:\n- Aumentare il livello di confidenza fa sì che l’IC si allarghi, spesso di molto se \\(n\\) è piccolo.\n- Un IC più ampio rassicura sulla “copertura” nel lungo periodo, ma è meno informativo per il singolo studio.\nEsercizio 3 – Utilizzo di software per il calcolo (ad esempio, R o altro)\n\n\nInserisci i dati in un software (come R). Puoi farlo in R con:\nswls_data &lt;- c(28, 22, 26, 18, 30, 24, 27, 17, 21, 25)\n\n\nCalcola la media e la deviazione standard in R, poi utilizza la funzione t.test():\nt.test(swls_data, conf.level = 0.95)\n\nRiporta l’intervallo di confidenza ottenuto e confrontalo con quello calcolato a mano.\nCommenta eventuali differenze (minime) dovute agli arrotondamenti o a correzioni interne di R.\nRibadisci la corretta interpretazione frequentista: se si ripetesse lo stesso studio molte volte (stessa dimensione campionaria, stesso contesto di popolazione, stessa procedura di calcolo), il 95% di questi IC conterrebbe il valore vero di \\(\\mu\\).\n\nEsercizio 4 – Confronto pratico e riflessioni critiche\n\nImmagina di avere un’ipotesi: “La media SWLS nella popolazione dei giovani adulti universitari è pari a 24” (un’ipotesi plausibile se la scala totale va da 5 a 35).\n\nOsserva l’IC al 95% che hai calcolato: contiene il valore 24?\n\nSe l’IC contiene 24, puoi dire che il valore “24” è “molto probabile”? (No, attenzione! Vedi interpretazione corretta vs. errata.)\n\nSe l’IC non contiene 24, puoi concludere che la media reale è “sicuramente” diversa da 24? (No, perché hai solo un campione piccolo e il concetto di significatività vs. copertura può essere fuorviante.)\n\nSpunti di riflessione sui limiti:\n- Il “livello di fiducia” dell’IC non è una “probabilità” che \\(\\mu\\) sia all’interno di un singolo intervallo: è una proprietà della procedura sul lungo periodo.\n- Con pochi dati, le assunzioni (come la normalità) e la variabilità casuale giocano un ruolo enorme: l’intervallo può risultare poco stabile e molto sensibile a pochi valori estremi.\n- L’IC non dice “quanto è plausibile 24” (questo sarebbe più vicino a un approccio bayesiano, che definisce un intervallo di credibilità). L’IC frequentista dice soltanto che, ripetendo molte volte la stessa procedura, nel 95% dei casi il vero \\(\\mu\\) cadrà entro l’intervallo calcolato in ciascuna ripetizione.\n\n\n\n\n\n\n\n\n\nSoluzioni 3\n\n\n\n\n\nSupponiamo siano stati raccolti i dati seguenti (sostituisci con i dati effettivi):\n28, 22, 26, 18, 30, 24, 27, 17, 21, 25\nEsercizio 1\n\nCalcolo di media e deviazione standard campionaria\n\nIndichiamo i punteggi come \\(X_1, X_2, \\dots, X_{10}\\). La media campionaria è:\n\\[\n\\bar{X} = \\frac{1}{n}\\sum_{i=1}^n X_i.\n\\]\nFacendo la somma \\(28 + 22 + 26 + 18 + 30 + 24 + 27 + 17 + 21 + 25 = 238\\).\nQuindi, con \\(n=10\\), otteniamo:\n\\[\n\\bar{X} = \\frac{238}{10} = 23.8.\n\\]\nPer la deviazione standard campionaria \\(s\\), si utilizza:\n\\[\ns = \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^n \\bigl(X_i - \\bar{X}\\bigr)^2}.\n\\]\nCalcolando (o usando un foglio di calcolo / software), si ricava approssimativamente:\n\\[\ns \\approx 4.26.\n\\]\n\nCostruzione dell’Intervallo di Confidenza al 95%\n\nPoiché la varianza è sconosciuta e il campione è piccolo, usiamo la distribuzione \\(t\\) di Student con \\(n-1 = 9\\) gradi di libertà.\n- Livello di confidenza: \\(95\\%\\).\n- \\(\\alpha = 0,05\\), quindi \\(\\alpha/2 = 0,025\\).\n- Il valore critico \\(t_{\\alpha/2,df=9}\\) è circa 2,262 (da tavole o software).\n\nErrore standard\n\n\\[\n\\text{SE} = \\frac{s}{\\sqrt{n}} = \\frac{4.26}{\\sqrt{10}} \\approx 4.26 / 3.162 \\approx 1.35.\n\\]\n\nMargine di errore\n\n\\[\nE = t_{\\alpha/2} \\times \\text{SE} \\approx 2.262 \\times 1.35 \\approx 3.05.\n\\]\n\nIntervallo di confidenza\n\n\\[\n\\bar{X} \\pm E \\quad \\Rightarrow \\quad 23.8 \\pm 3.05\n\\quad \\Rightarrow \\quad (20.75;\\, 26.85).\n\\]\n\nInterpretazione frequentista corretta\n\n\n\nInterpretazione corretta: se ripetessimo lo stesso tipo di studio molte volte (stessa procedura di campionamento, stesse dimensioni, stesso metodo di calcolo dell’IC), il 95% di questi intervalli conterrà il vero valore della media della popolazione (\\(\\mu\\)).\n\n\nInterpretazione scorretta (da evitare): “C’è il 95% di probabilità che la vera media sia qui dentro”. Nel frequentismo, \\(\\mu\\) è considerato un valore fisso e non aleatorio. L’incertezza riguarda l’intervallo, non il parametro.\n\nLimite: con poche osservazioni (n=10), l’intervallo può risultare piuttosto ampio. Inoltre, l’assunzione di normalità della popolazione di partenza potrebbe non essere pienamente soddisfatta.\nEsercizio 2\n\nCalcolo di due nuovi IC: 80% e 99%\n\nUtilizziamo gli stessi \\(\\bar{X} = 23.8\\), \\(s = 4.26\\), \\(n=10\\). Cambia solo il valore critico \\(t\\).\n\n\nIC all’80% (\\(\\alpha=0,20\\), \\(\\alpha/2 = 0,10\\)):\n\n\n\\(t_{0,10,df=9} \\approx 1.383\\)\n\n\n\\(\\text{SE} \\approx 1.35\\) (come prima)\n\nMargine di errore \\(E = 1.383 \\times 1.35 \\approx 1.87\\)\n\nIC 80%: \\((23.8 \\pm 1.87)\\) \\(\\Rightarrow\\) \\((21.93;\\, 25.67)\\).\n\n\n\nIC al 99% (\\(\\alpha=0,01\\), \\(\\alpha/2 = 0,005\\)):\n\n\n\\(t_{0,005,df=9} \\approx 3.25\\)\n\n\n\\(\\text{SE} \\approx 1.35\\)\n\nMargine di errore \\(E = 3.25 \\times 1.35 \\approx 4.39\\)\n\nIC 99%: \\((23.8 \\pm 4.39)\\) \\(\\Rightarrow\\) \\((19.41;\\, 28.19)\\).\n\n\n\n\nConfronto delle ampiezze\n\n\n\n80%: \\((21.93;\\, 25.67)\\) (più stretto)\n\n\n95%: \\((20.75;\\, 26.85)\\) (intermedio)\n\n\n99%: \\((19.41;\\, 28.19)\\) (più largo)\n\nAumentando il livello di confidenza, l’intervallo si espande. Per “coprire” il valore vero nel 99% delle volte, occorre un intervallo più ampio.\nEsercizio 3\n\nCalcolo in R\n\nSe in R inseriamo i dati:\nswls_data &lt;- c(28, 22, 26, 18, 30, 24, 27, 17, 21, 25)\n\nmean(swls_data)  # ~ 23.8\nsd(swls_data)    # ~ 4.26\nt.test(swls_data, conf.level = 0.95)\n\nConfronto con il calcolo “a mano”\n\nLa funzione t.test() (di default) eseguirà un One Sample t-test con confidenza 95%. Restituisce:\n\nUn IC molto simile a \\((20.75;\\, 26.85)\\), con possibili piccole differenze di arrotondamento.\n\n\nRibadire l’interpretazione\n\n\nIl risultato di t.test() potrebbe riportare:95 percent confidence interval: (20.72, 26.88)\n(o valori simili).\n\nAnche qui vale la regola: non è una probabilità che \\(\\mu\\) sia dentro, bensì una proprietà della procedura (lungo periodo).\n\nEsercizio 4\n\n\nIpotesi: “La media SWLS reale nella popolazione è 24”.\n\n\nVerifica se 24 è dentro l’IC al 95%. Dall’IC \\((20.75;\\, 26.85)\\), notiamo che 24 rientra in questo intervallo.\n\nSignifica che è “probabile” 24?\n\nAttenzione: l’IC frequentista non fornisce una probabilità su questo specifico valore. Dire che “24 è dentro l’intervallo” non equivale a dire “la probabilità che \\(\\mu\\) = 24 è 95%”.\n\n\n\nSe 24 fosse stato fuori dall’intervallo, non potremmo comunque affermare con certezza che \\(\\mu\\neq 24\\). Ricordiamo sempre che, con un campione così piccolo, l’incertezza è alta e l’IC si basa su assunzioni (normalità e stima corretta).\n\nLimiti dell’interpretazione\n\nCon campioni ridotti, basta poco (un outlier o una leggera deviazione dalla normalità) per alterare significativamente l’intervallo.\n\nIl livello di confidenza (ad es. 95%) è una proprietà della procedura: in una serie di infiniti studi simili, il 95% di quegli intervalli conterrebbe \\(\\mu\\). Non significa che, dato questo singolo intervallo, ci sia una “probabilità 95%” di includere il parametro.\n\nRiepilogo Finale\n\n\nValori Numerici:\n\nMedia \\(\\bar{X} = 23.8\\); dev. standard \\(s \\approx 4.26\\).\n\nIC 95% (a mano) \\(\\approx (20.75;\\, 26.85)\\).\n\nIC 80% \\(\\approx (21.93;\\, 25.67)\\); IC 99% \\(\\approx (19.41;\\, 28.19)\\).\n\n\n\n\nInterpretazione Frequentista:\n&gt; Nel lungo periodo, il 95% (o 99%, 80%, ecc.) degli intervalli calcolati con la stessa procedura conterrà il vero valore di \\(\\mu\\).\n\n\nLimiti (campioni piccoli, ipotesi di normalità, differenza tra “copertura ripetuta” e “probabilità che \\(\\mu\\) sia in un singolo IC”).\n\nIn questo modo, gli studenti vedono sia la parte di calcolo (formule, tabelle/valori critici, software) sia gli aspetti interpretativi (come evitare i fraintendimenti più comuni sul significato dell’IC frequentista).\nConclusioni generali\n\nCon un campione così piccolo (n=10), l’intervallo di confidenza può essere largo e sensibile a qualsiasi deviazione dall’assunzione di normalità.\n\nL’interpretazione frequentista si focalizza sulla “procedura” e sul “lungo periodo” (ripetizione dell’esperimento), non sulla probabilità che \\(\\mu\\) sia dentro questo intervallo specifico.\n\nÈ facile incorrere in fraintendimenti (“c’è il 95% di probabilità che la vera media sia qui dentro?”), occorre ribadire che la probabilità secondo il frequentismo riguarda il campionamento e la costruzione dell’intervallo, non la posizione fissa del parametro.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/02_conf_interv.html#informazioni-sullambiente-di-sviluppo",
    "title": "78  Intervalli di fiducia",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] bayestestR_0.15.3 posterior_1.6.1   cmdstanr_0.9.0    thematic_0.1.6   \n#&gt;  [5] MetBrewer_0.2.0   ggokabeito_0.1.0  see_0.11.0        gridExtra_2.3    \n#&gt;  [9] patchwork_1.3.0   bayesplot_1.12.0  psych_2.5.3       scales_1.4.0     \n#&gt; [13] markdown_2.0      knitr_1.50        lubridate_1.9.4   forcats_1.0.0    \n#&gt; [17] stringr_1.5.1     dplyr_1.1.4       purrr_1.0.4       readr_2.1.5      \n#&gt; [21] tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.2     tidyverse_2.0.0  \n#&gt; [25] rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6         tensorA_0.36.2.1     xfun_0.52           \n#&gt;  [4] htmlwidgets_1.6.4    insight_1.2.0        processx_3.8.6      \n#&gt;  [7] lattice_0.22-7       tzdb_0.5.0           vctrs_0.6.5         \n#&gt; [10] tools_4.5.0          ps_1.9.1             generics_0.1.4      \n#&gt; [13] parallel_4.5.0       pacman_0.5.1         pkgconfig_2.0.3     \n#&gt; [16] checkmate_2.3.2      RColorBrewer_1.1-3   distributional_0.5.0\n#&gt; [19] lifecycle_1.0.4      compiler_4.5.0       farver_2.1.2        \n#&gt; [22] mnormt_2.1.1         htmltools_0.5.8.1    pillar_1.10.2       \n#&gt; [25] abind_1.4-8          nlme_3.1-168         tidyselect_1.2.1    \n#&gt; [28] digest_0.6.37        stringi_1.8.7        labeling_0.4.3      \n#&gt; [31] rprojroot_2.0.4      fastmap_1.2.0        grid_4.5.0          \n#&gt; [34] cli_3.6.5            magrittr_2.0.3       withr_3.0.2         \n#&gt; [37] backports_1.5.0      timechange_0.3.0     rmarkdown_2.29      \n#&gt; [40] hms_1.1.3            evaluate_1.0.3       rlang_1.1.6         \n#&gt; [43] glue_1.8.0           rstudioapi_0.17.1    jsonlite_2.0.0      \n#&gt; [46] R6_2.6.1",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#bibliografia",
    "href": "chapters/frequentist_inference/02_conf_interv.html#bibliografia",
    "title": "78  Intervalli di fiducia",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nHoekstra, R., Morey, R. D., Rouder, J. N., & Wagenmakers, E.-J. (2014). Robust misinterpretation of confidence intervals. Psychonomic Bulletin & Review, 21(5), 1157–1164.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html",
    "href": "chapters/frequentist_inference/03_sample_size.html",
    "title": "79  La grandezza del campione",
    "section": "",
    "text": "79.1 Introduzione\nLa scelta della dimensione del campione è fondamentale per garantire che i risultati di uno studio siano affidabili, bilanciando precisione e costi. In questo capitolo, esamineremo come calcolare la dimensione minima del campione necessaria per stimare la media di una popolazione con un margine di errore prefissato e un determinato livello di confidenza. Utilizzeremo un esempio tratto dalla psicologia per illustrare il processo e fornire implementazioni pratiche in R.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#la-logica-dietro-la-scelta-della-dimensione-campionaria",
    "href": "chapters/frequentist_inference/03_sample_size.html#la-logica-dietro-la-scelta-della-dimensione-campionaria",
    "title": "79  La grandezza del campione",
    "section": "\n79.2 La Logica Dietro la Scelta della Dimensione Campionaria",
    "text": "79.2 La Logica Dietro la Scelta della Dimensione Campionaria\nIn psicologia, è comune stimare la media di una variabile (ad esempio, il punteggio medio di una scala psicometrica). I vantaggi di utilizzare campioni più grandi includono:\n\n\nStime più precise: Con un campione più grande, la varianza dell’estimatore diminuisce, rendendo le stime più accurate.\n\nMaggiore fiducia nei risultati: Un campione più grande riduce il margine di errore, aumentando la certezza dei risultati.\n\nTuttavia, i campioni più grandi richiedono risorse maggiori in termini di tempo e denaro. Pertanto, il problema si riduce spesso a trovare il campione più piccolo che garantisca la precisione desiderata.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#calcolo-della-dimensione-campionaria",
    "href": "chapters/frequentist_inference/03_sample_size.html#calcolo-della-dimensione-campionaria",
    "title": "79  La grandezza del campione",
    "section": "\n79.3 Calcolo della Dimensione Campionaria",
    "text": "79.3 Calcolo della Dimensione Campionaria\nPer campioni sufficientemente grandi, la media campionaria \\(\\bar{X}\\) segue una distribuzione normale:\n\\[\n\\bar{X} \\sim \\mathcal{N}\\left(\\mu, \\frac{\\sigma^2}{n}\\right),\n\\]\ndove:\n\n\n\\(n\\) è la dimensione del campione,\n\n\\(\\mu\\) è la vera media della popolazione,\n\n\\(\\sigma^2\\) è la varianza della popolazione.\n\nIl nostro obiettivo è trovare la dimensione campionaria \\(n\\) tale che:\n\\[\nP\\left(|\\bar{X} - \\mu| &lt; E\\right) \\geq 0.95,\n\\]\ndove:\n\n\n\\(\\bar{X}\\) è la media campionaria,\n\n\\(\\mu\\) è la media della popolazione,\n\n\\(E\\) è il margine di errore massimo accettabile.\n\nSappiamo che, per il teorema centrale del limite, la media campionaria \\(\\bar{X}\\) può essere standardizzata come segue:\n\\[\nZ = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}}.\n\\]\nQuesta quantità \\(Z\\) segue una distribuzione normale standard \\(\\mathcal{N}(0, 1)\\).\nQuindi, possiamo riscrivere la probabilità richiesta come:\n\\[\nP\\left(|\\bar{X} - \\mu| &lt; E\\right) = P\\left(|Z| &lt; z_{0.025}\\right),\n\\]\ndove \\(z_{0.025} = 1.96\\) è il quantile superiore della distribuzione normale standard corrispondente a un livello di confidenza del \\(95\\%\\).\nDalla definizione della variabile standardizzata \\(Z\\), possiamo ricavare la relazione per il margine di errore:\n\\[\n|\\bar{X} - \\mu| &lt; E \\implies Z = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}} \\implies \\left|\\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}}\\right| &lt; \\frac{E}{\\sigma / \\sqrt{n}}.\n\\]\nSostituendo la condizione \\(|Z| &lt; z_{0.025}\\), otteniamo:\n\\[\n\\frac{E}{\\sigma / \\sqrt{n}} = z_{0.025}.\n\\]\nRisolvendo per \\(\\sqrt{n}\\), moltiplichiamo entrambi i membri per \\(\\sigma / \\sqrt{n}\\):\n\\[\nE = z_{0.025} \\cdot \\frac{\\sigma}{\\sqrt{n}}.\n\\]\nIsoliamo \\(\\sqrt{n}\\) dividendo entrambi i membri per \\(z_{0.025} \\cdot \\sigma\\):\n\\[\n\\sqrt{n} = \\frac{z_{0.025} \\cdot \\sigma}{E}.\n\\]\nInfine, eleviamo entrambi i membri al quadrato per ottenere \\(n\\):\n\\[\nn = \\left(\\frac{z_{0.025} \\cdot \\sigma}{E}\\right)^2.\n\\]\nIn conclusione, la dimensione campionaria minima \\(n\\) necessaria per soddisfare il margine di errore \\(E\\) e il livello di confidenza richiesto è:\n\\[\nn = \\left(\\frac{z_{0.025} \\cdot \\sigma}{E}\\right)^2.\n\\]",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#stima-della-media-del-punteggio-di-autostima",
    "href": "chapters/frequentist_inference/03_sample_size.html#stima-della-media-del-punteggio-di-autostima",
    "title": "79  La grandezza del campione",
    "section": "\n79.4 Stima della Media del Punteggio di Autostima",
    "text": "79.4 Stima della Media del Punteggio di Autostima\nConsideriamo un esempio pratico: vogliamo stimare la media del punteggio di autostima in una popolazione di giovani adulti, utilizzando la Rosenberg Self-Esteem Scale (RSES), che assegna un punteggio compreso tra 0 e 30.\nDettagli del Problema:\n\nDeviazione standard del punteggio: \\(\\sigma = 6\\) (stimata da studi precedenti).\nMargine di errore massimo accettabile: \\(E = 2\\).\nLivello di confidenza: \\(95\\%\\).\n\nImplementiamo in R la formula derivata in precedenza.\n\n# Parametri del problema\nsigma &lt;- 6     # Deviazione standard del punteggio RSES\nE &lt;- 2         # Margine di errore desiderato\nz_alpha &lt;- qnorm(0.975)  # Quantile superiore della distribuzione normale (95% confidenza)\n\n# Calcolo della dimensione campionaria\nn &lt;- (z_alpha * sigma / E)^2\nn &lt;- ceiling(n)  # Arrotondamento all'intero successivo\nn\n#&gt; [1] 35\n\nIn conclusione, la dimensione campionaria minima necessaria per stimare la media del punteggio di autostima con un margine di errore massimo di 2 punti e un livello di confidenza del 95% è \\(n = 35\\).\n\n79.4.1 Approfondimenti\n\n\nPrecisione e Livello di Confidenza Aumentando \\(n\\), la varianza di \\(\\bar{X}\\) diminuisce:\n\\[\n\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n}.\n\\]\nQuesto restringe l’intervallo di confidenza e migliora la precisione.\n\nCosto e Praticità Un campione più grande comporta costi più elevati. È importante trovare il giusto compromesso tra precisione e fattibilità.\nAdattamento ad Altri Livelli di Confidenza Per altri livelli di confidenza, basta modificare il quantile \\(z_{\\alpha/2}\\). Ad esempio, per un livello di confidenza del 99%, \\(z_{0.005} \\approx\\) 2.576.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/03_sample_size.html#riflessioni-conclusive",
    "title": "79  La grandezza del campione",
    "section": "\n79.5 Riflessioni Conclusive",
    "text": "79.5 Riflessioni Conclusive\nDefinire la dimensione del campione rappresenta un passaggio cruciale nella progettazione di qualsiasi studio psicologico. Un approccio matematico rigoroso, fondato su analisi di potenza statistica e stime di effetti attesi, consente di ottimizzare il bilanciamento tra precisione dei risultati e limitazioni pratiche, come tempi, costi e disponibilità dei partecipanti. Questo equilibrio è fondamentale per garantire che i dati raccolti siano sufficientemente robusti da supportare conclusioni valide, senza tuttavia sprecare risorse in campioni eccessivamente ampi. Una corretta determinazione del campione contribuisce inoltre a ridurre il rischio di errori di tipo I e II, rafforzando l’integrità scientifica della ricerca.\nNel confronto tra paradigmi statistici, l’approccio frequentista si distingue per la sua enfasi sul controllo degli errori e sulla replicabilità attraverso il calcolo del valore p e della potenza statistica. Questo metodo richiede una rigorosa pianificazione preliminare, con la determinazione a priori della dimensione del campione basata su stime dell’effetto atteso e soglie prefissate di significatività e potenza. Tale rigidità metodologica, sebbene garantisca standardizzazione e controllo degli errori di Tipo I, può presentare notevoli limitazioni. In particolare, non permette modifiche alla dimensione del campione durante lo studio senza compromettere la validità statistica e può portare al problema dello “optional stopping”, dove il controllo ripetuto dei risultati aumenta il rischio di falsi positivi.\nL’approccio bayesiano, d’altra parte, offre una prospettiva complementare, ponendo l’accento sulla stima e sull’aggiornamento delle credenze in base ai dati osservati. Nel contesto bayesiano, la dimensione del campione non è solo uno strumento per garantire la significatività statistica, ma diventa un mezzo per affinare la precisione delle stime a posteriori. Questo approccio si caratterizza per una maggiore flessibilità, permettendo il monitoraggio continuo dell’evidenza attraverso i fattori di Bayes e l’aggiornamento sequenziale delle stime di probabilità. L’uso di distribuzioni a priori consente di incorporare conoscenze pregresse, portando a distribuzioni a posteriori che quantificano l’incertezza in modo più intuitivo e direttamente interpretabile.\nLa scelta di quando interrompere la raccolta dati rappresenta un esempio emblematico delle differenze tra i due approcci. Mentre il metodo frequentista richiede una dimensione campionaria fissa determinata a priori, l’approccio bayesiano permette una maggiore flessibilità, consentendo di interrompere la raccolta quando si raggiunge un livello desiderato di precisione nelle stime posteriori. Tuttavia, questa flessibilità comporta anche sfide specifiche, come la necessità di specificare distribuzioni a priori appropriate e una maggiore complessità computazionale.\nUna soluzione pragmatica potrebbe essere l’integrazione dei punti di forza di entrambi gli approcci. Si potrebbe utilizzare l’analisi della potenza frequentista per stabilire una dimensione minima del campione, implementando poi un monitoraggio bayesiano per valutare quando l’evidenza raccolta è sufficiente. Questo approccio integrato dovrebbe essere guidato da regole decisionali stabilite a priori e supportato da analisi di sensitività per valutare la robustezza delle conclusioni.\nIn sintesi, la scelta della dimensione del campione e la decisione su quando concludere la raccolta dati non dovrebbero essere viste solo come problemi tecnici, ma come opportunità per riflettere sulle priorità della ricerca, sul contesto teorico e sulle metodologie più adatte. La combinazione dei punti di forza degli approcci frequentista e bayesiano può portare a una ricerca più robusta, flessibile e informativa, contribuendo a un progresso scientifico più solido e sfaccettato. Tale scelta metodologica deve considerare gli obiettivi specifici dello studio, le risorse disponibili, i requisiti delle riviste scientifiche e la natura delle ipotesi da testare, bilanciando le esigenze di precisione con quelle di praticabilità. Pertanto, investire tempo nella pianificazione di questo aspetto non è solo una scelta metodologica, ma un imperativo etico per chiunque si impegni nella produzione di conoscenza psicologica.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#esercizi",
    "href": "chapters/frequentist_inference/03_sample_size.html#esercizi",
    "title": "79  La grandezza del campione",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nEsercizio 1: Dimensione del campione per un margine di errore prefissato\n\nEsaminando i dati raccolti, hai ottenuto una deviazione standard campionaria (stimata) \\(s \\approx 4{,}3\\) sui punteggi SWLS.\nHai stabilito di voler stimare la media SWLS con un margine di errore massimo \\(E = 2\\) punti e un livello di confidenza del 95%.\n\nUtilizzando il valore critico \\(z_{0.025} \\approx 1{,}96\\) (per il 95%), ipotizza che la deviazione standard di popolazione \\(\\sigma\\) possa essere approssimata da \\(s\\). Calcola quindi la dimensione del campione \\(n\\) necessaria:\n\\[\nn = \\left(\\frac{z_{\\alpha/2} \\times \\sigma}{E}\\right)^2.\n\\]\n\nInterpreta il risultato: è un campione grande o piccolo? Quali fattori potrebbero influenzarne la validità (ad es. la stima di \\(\\sigma\\) da soli 10 soggetti)?\n\nEsercizio 2: Aumento del livello di confidenza e influenza su \\(n\\)\n\nCon gli stessi dati dell’Esercizio 1 (stesso \\(\\sigma\\approx4{,}3\\), stesso \\(E=2\\)), calcola la dimensione \\(n\\) se volessi un livello di confidenza del 99%.\n\nConfronta tale dimensione con quella trovata al 95%.\n\nCommenta: perché un livello di confidenza più elevato richiede un campione più grande? E in che modo ciò può impattare sull’organizzazione pratica della ricerca (tempi, costi, disponibilità di partecipanti)?\n\nEsercizio 3: Potere statistico per rilevare una differenza dalla media di riferimento\n\nIpotizza che la media SWLS di riferimento (ad es. in letteratura) sia 24.\n\nVuoi un test a una coda (one-sample t-test o z-test) con \\(\\alpha = 0{,}05\\), e desideri un potere (\\(1-\\beta\\)) dell’80% di rivelare una differenza di 3 punti (cioè vuoi essere in grado di concludere che la vera media è almeno 3 punti più alta o più bassa di 24).\n\nUsa come stima della deviazione standard la stessa \\(s \\approx 4{,}3\\). Sulla base delle formule di potenza statistica per un test a una coda, calcola un numero approssimativo di soggetti \\(n\\) necessari. (Suggerimento: puoi usare formule di power analysis o fare riferimento a software R, es. power.t.test() o pwr.t.test().)\n\n\nInterpreta la dimensione campionaria trovata: è realistica per un esperimento in cui potresti raccogliere partecipanti simili a quelli del pilot? Oppure rappresenta un valore troppo elevato?\n\nEsercizio 4: Confronto tra due gruppi e potere statistico\n\nIpotizza di voler confrontare due gruppi indipendenti (ognuno con punteggi SWLS) e di voler rilevare una differenza media di 5 punti tra i due gruppi (Gruppo A vs Gruppo B).\n\nAssumi che ciascun gruppo abbia la stessa deviazione standard \\(\\sigma = 4{,}3\\).\n\nVuoi un test a due code, \\(\\alpha=0{,}05\\), e un potere dell’80%. Utilizza (se vuoi) la formula approssimata per due campioni indipendenti, oppure uno strumento in R (ad es. power.t.test con type=\"two.sample\").\n\nCalcola (o stima) la dimensione \\(n\\) per ciascun gruppo.\n\n\nCommenta: confronta il risultato con la disponibilità realistica dei partecipanti. Che implicazioni metodologiche o pratiche emergono?\n\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\nSoluzione Esercizio 1\nDati principali:\n- \\(\\sigma \\approx 4{,}3\\) (stimata dal pilot)\n- \\(E = 2\\) (margine di errore)\n- Livello di confidenza 95% \\(\\Rightarrow z_{\\alpha/2} \\approx 1{,}96\\)\nLa formula per la dimensione campionaria:\n\\[\nn = \\left(\\frac{z_{\\alpha/2} \\times \\sigma}{E}\\right)^2\n\\]\nCalcolo:\n\\[\nn\n= \\left(\\frac{1{,}96 \\times 4{,}3}{2}\\right)^2\n= \\left(\\frac{8{,}428}{2}\\right)^2\n= (4{,}214)^2\n\\approx 17{,}76.\n\\]\nArrotondando all’intero superiore:\n\\[\nn \\approx 18.\n\\]\nInterpretazione\n\nServirebbero circa 18 partecipanti (anziché 10) per ottenere un IC al 95% con margine d’errore 2, ipotizzando \\(\\sigma \\approx 4{,}3\\).\n\n\nLimiti: la \\(\\sigma\\) deriva da un campione di sole 10 persone e potrebbe non rappresentare bene la deviazione standard reale dell’intera popolazione. Se in realtà \\(\\sigma\\) fosse più grande, \\(n\\) andrebbe rivisto al rialzo; se fosse minore, 18 potrebbe essere anche sovrastimato.\n\n18 non è troppo elevato; potrebbe essere gestibile in uno studio con costi contenuti. Tuttavia, la validità dipende dalla solidità della stima di \\(\\sigma\\).\n\nSoluzione Esercizio 2\nCambio di livello di confidenza: da 95% a 99%. Ora \\(\\alpha=0{,}01\\) e \\(\\alpha/2=0{,}005\\).\nIl valore critico \\(z_{0.005}\\) è circa 2,576.\n\\[\nn = \\left(\\frac{2,576 \\times 4{,}3}{2}\\right)^2\n= \\left(\\frac{11{,}0768}{2}\\right)^2\n= (5{,}5384)^2\n\\approx 30{,}7.\n\\]\nArrotondato in eccesso:\n\\[\nn \\approx 31.\n\\]\nConfronto con i 18 trovati prima\n- Aumentando la confidenza dal 95% al 99%, la dimensione campionaria passa da ~18 a ~31, cioè un incremento notevole.\n- Motivo: per assicurare un intervallo che, nel lungo periodo, includa il vero valore nel 99% dei casi, occorre un margine di errore più “tollerante” (oppure un campione più grande per mantenere lo stesso \\(E\\)).\n- Impatto pratico: reclutare 31 soggetti (invece di 18) può pesare in termini di costi e disponibilità, ma riduce l’incertezza dell’IC dal punto di vista frequentista.\nSoluzione Esercizio 3\nPotere statistico (80%) per rilevare \\(\\Delta = 3\\) in un test a una coda contro il valore di riferimento 24.\n- \\(\\alpha=0{,}05\\) (quindi una coda, il valore critico si situa intorno a z=1.645 per la potenza, ma i calcoli precisi si fanno di solito con formule di power analysis).\n- \\(\\sigma \\approx 4{,}3\\).\n- \\(\\Delta = 3\\).\nIn R, con pwr.t.test() o power.t.test(), l’approssimazione verrebbe impostata come:\nlibrary(pwr)  # se usi pwr\npwr.t.test(d = 3/4.3, sig.level = 0.05, power = 0.80,\n           type = \"one.sample\", alternative=\"greater\")\noppure:\npower.t.test(delta = 3, sd = 4.3, sig.level = 0.05, \n             power = 0.80, type = \"one.sample\", \n             alternative = \"one.sided\")\nEsempio di risultato (numeri indicativi): potresti ottenere \\(n \\approx 20\\). (Il valore preciso cambia a seconda delle approssimazioni e del software.)\nInterpretazione\n- Con 20 soggetti, se \\(\\Delta\\) fosse veramente di 3 punti rispetto a 24, il test a una coda dovrebbe avere l’80% di chance di rigettare l’ipotesi nulla (cioè di rilevare la differenza) a \\(\\alpha=0{,}05\\).\n- Se cercassi di replicare il pilot (dove avevi 10 soggetti), probabilmente la potenza sarebbe inferiore.\n- Potresti chiederti se 20 partecipanti siano facili da reclutare o se, dal punto di vista pratico, 20 restino pochi per altre ragioni (ad es. robustezza dei modelli, normalità, outlier).\nSoluzione Esercizio 4\n\nDue campioni indipendenti, differenza attesa = 5 punti, potere = 80%, test a due code\n\nCon formula approssimata (oppure software R), i parametri tipici:\n\n\nDifferenza minima rilevabile: \\(\\Delta = 5\\)\n\n\n\\(\\sigma = 4{,}3\\) in ciascun gruppo\n\n\n\\(\\alpha = 0{,}05\\) (due code), potere = 80%\n\nTipo di test: “two-sample t test” (Gruppo A vs Gruppo B, varianze uguali)\n\nIn R con power.t.test():\npower.t.test(delta = 5, sd = 4.3, sig.level = 0.05,\n             power = 0.80, type = \"two.sample\",\n             alternative = \"two.sided\")\nEsempio di risultato: potresti ottenere \\(n \\approx 14\\) per gruppo (quindi 28 totali). (Il numero può variare leggermente a seconda delle approssimazioni.)\n\nCommento\n\n\n\n18 o 20 partecipanti totali potrebbero bastare per un one-sample test (Esercizi 1–3), ma qui servono 28 (14 per gruppo) per avere lo stesso potere su una differenza di 5 punti.\n\nIn pratica:\n\nSe hai risorse per arruolare solo 15–20 persone totali, potrebbe non esserci potere sufficiente (grande rischio di errore di tipo II).\n\nPotrebbe convenire ridurre la differenza minima desiderata (ma questo cambierebbe le conclusioni) o cercare un campione più grande.\n\n\n\nLe considerazioni metodologiche includono: “Posso davvero aspettarmi 5 punti di differenza?” Se la differenza reale fosse più piccola, servirebbe un campione ancora più grande per rilevarla con sufficiente potenza.\n\nConclusioni Finali\n\nLa dimensione del campione dipende da molti fattori:\n\nVarianza (o deviazione standard) stimata.\n\nMargine di errore desiderato (o differenza minima rilevabile).\n\nLivello di confidenza o \\(\\alpha\\).\n\nPotere statistico \\((1-\\beta)\\).\n\n\n\nI dati SWLS di un pilot di 10 persone forniscono un’indicazione iniziale (stima di \\(\\sigma\\)), ma la precisione di quella stima è limitata.\n\nPer studi sperimentali o correlazionali, i calcoli di dimensione campionaria andrebbero fatti a priori (idealmente ancor prima di raccogliere i dati) e basati su stime realistiche o su letteratura pre-esistente.\n\nSe la stima di \\(\\sigma\\) o della dimensione dell’effetto \\(\\Delta\\) è incerta, è utile svolgere analisi di sensitività, variando gli input per vedere come cambiano i risultati.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/03_sample_size.html#informazioni-sullambiente-di-sviluppo",
    "title": "79  La grandezza del campione",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.12.0 psych_2.5.3     \n#&gt;  [9] scales_1.4.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.2   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.4     stringi_1.8.7      lattice_0.22-7    \n#&gt;  [4] hms_1.1.3          digest_0.6.37      magrittr_2.0.3    \n#&gt;  [7] evaluate_1.0.3     grid_4.5.0         timechange_0.3.0  \n#&gt; [10] RColorBrewer_1.1-3 fastmap_1.2.0      rprojroot_2.0.4   \n#&gt; [13] jsonlite_2.0.0     mnormt_2.1.1       cli_3.6.5         \n#&gt; [16] rlang_1.1.6        withr_3.0.2        tools_4.5.0       \n#&gt; [19] parallel_4.5.0     tzdb_0.5.0         pacman_0.5.1      \n#&gt; [22] vctrs_0.6.5        R6_2.6.1           lifecycle_1.0.4   \n#&gt; [25] htmlwidgets_1.6.4  pkgconfig_2.0.3    pillar_1.10.2     \n#&gt; [28] gtable_0.3.6       glue_1.8.0         xfun_0.52         \n#&gt; [31] tidyselect_1.2.1   rstudioapi_0.17.1  farver_2.1.2      \n#&gt; [34] htmltools_0.5.8.1  nlme_3.1-168       rmarkdown_2.29    \n#&gt; [37] compiler_4.5.0",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#bibliografia",
    "href": "chapters/frequentist_inference/03_sample_size.html#bibliografia",
    "title": "79  La grandezza del campione",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGiner-Sorolla, R., Montoya, A. K., Reifman, A., Carpenter, T., Lewis Jr, N. A., Aberson, C. L., Bostyn, D. H., Conrique, B. G., Ng, B. W., Schoemann, A. M., et al. (2024). Power to detect what? Considerations for planning and evaluating sample size. Personality and Social Psychology Review, 28(3), 276–301.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html",
    "title": "\n80  Significatività statistica\n",
    "section": "",
    "text": "80.1 Introduzione\nIl test di ipotesi è un metodo fondamentale della ricerca scientifica, utilizzato per fare inferenze sui parametri della popolazione a partire dai dati campionari. Nel contesto della psicologia, questo approccio viene frequentemente impiegato per valutare l’efficacia di interventi psicologici, confrontare teorie o approcci, analizzare l’influenza di variabili psicologiche su comportamenti e processi cognitivi, e approfondire i meccanismi alla base di fenomeni complessi come apprendimento, memoria ed emozioni.\nIn questo capitolo ci focalizzeremo sul test di ipotesi frequentista, un metodo largamente utilizzato ma non privo di limiti. È importante sottolineare che la comunità statistica sconsiglia di affidarsi esclusivamente a questo approccio come criterio decisionale per valutare la validità di un risultato sperimentale.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#test-del-chi-quadrato",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#test-del-chi-quadrato",
    "title": "\n80  Significatività statistica\n",
    "section": "\n80.2 Test del Chi-Quadrato",
    "text": "80.2 Test del Chi-Quadrato\nPer introdurre il concetto di test di ipotesi nel contesto frequentista, iniziamo presentando uno dei test più semplici e utilizzati: il test del Chi-Quadrato. Questo test è particolarmente utile per valutare l’ipotesi di indipendenza tra due variabili categoriali organizzate in una tabella di contingenza (per ulteriori dettagli sulla struttura delle tabelle di contingenza, si veda il Capitolo 16).\nUna tabella di contingenza è una rappresentazione tabellare che mostra la distribuzione congiunta di due variabili categoriali. Ogni cella della tabella contiene la frequenza osservata delle combinazioni delle categorie delle due variabili. Inoltre, la tabella include i totali marginali, che rappresentano le somme delle frequenze per ciascuna riga e ciascuna colonna.\nIl test del Chi-Quadrato si pone una domanda fondamentale: “Come apparirebbe la tabella di contingenza se le due variabili fossero indipendenti?”. In altre parole, il test verifica se esiste una relazione significativa tra le due variabili o se, al contrario, le variabili sono indipendenti l’una dall’altra.\nCome già visto in precedenza analizzando la distribuzione di probabilità congiunta, si ha indipendenza quando le probabilità congiunte sono uguali al prodotto delle probabilità marginali. Partendo dalle proporzioni marginali, possiamo quindi calcolare i valori teorici attesi in ciascuna cella della tabella di contingenza, assumendo che le due variabili siano indipendenti.\nVa sottolineato che l’indipendenza è una proprietà della popolazione, non del campione. Pertanto, nei dati campionari, ci aspettiamo che i valori osservati nelle celle della tabella differiscano leggermente dai valori teorici attesi, anche se nella popolazione le variabili sono realmente indipendenti. La discrepanza complessiva tra i valori osservati e quelli attesi, calcolati sotto l’ipotesi di indipendenza, può essere misurata utilizzando una statistica chiamata Chi-Quadrato (\\(\\chi^2\\)).\nLa formula della statistica Chi-Quadrato è:\n\\[\n\\chi^2 = \\sum \\frac{(O_i - E_i)^2}{E_i} ,\n\\]\ndove:\n\n\n\\(O_i\\) rappresenta i valori osservati nelle celle della tabella,\n\n\n\\(E_i\\) rappresenta i valori attesi nelle celle, calcolati sotto l’ipotesi di indipendenza,\n\nLa somma (\\(\\sum\\)) viene effettuata su tutte le celle della tabella.\n\n\n80.2.1 Interpretazione della Statistica Chi-Quadrato\nLa statistica Chi-Quadrato misura la discrepanza complessiva tra i valori osservati e quelli attesi. Se non ci fosse differenza tra i valori congiunti osservati e quelli teorici, la statistica Chi-Quadrato sarebbe pari a zero. All’aumentare della discrepanza tra valori osservati e attesi, il valore della statistica Chi-Quadrato aumenta.\nPer valutare l’importanza della discrepanza osservata, utilizziamo la distribuzione campionaria della statistica Chi-Quadrato. Questa distribuzione descrive la probabilità di ottenere valori della statistica Chi-Quadrato sotto l’ipotesi nulla (indipendenza tra le variabili). La forma della distribuzione dipende dai gradi di libertà (\\(\\nu\\)), che si calcolano come:\n\\[\n\\nu = (n_{\\text{righe}} - 1)(n_{\\text{colonne}} - 1) ,\n\\]\ndove \\(n_{\\text{righe}}\\) e \\(n_{\\text{colonne}}\\) rappresentano rispettivamente il numero di righe e colonne della tabella di contingenza.\n\n80.2.2 Valutazione dell’Ipotesi di Indipendenza\nLa probabilità associata a una data discrepanza (\\(\\chi^2\\)) tra valori osservati e attesi, assumendo che l’ipotesi nulla sia vera, corrisponde all’area sotto la coda destra della distribuzione Chi-Quadrato, nell’intervallo [\\(C\\), \\(+\\infty\\)]. Questa probabilità è indicata come \\(p\\)-value.\nSe il \\(p\\)-value è molto piccolo (tipicamente inferiore a una soglia predefinita, come 0.05), possiamo rifiutare l’ipotesi nulla e concludere che è improbabile che le due variabili siano indipendenti nella popolazione.\n\n80.2.3 Riepilogo dei Passaggi del Test Chi-Quadrato\n\n\nCalcolo dei Valori Attesi: Per ogni cella, calcola \\(E_i\\) utilizzando la formula:\n\\[\nE_i = \\frac{\\text{Totale della Riga} \\times \\text{Totale della Colonna}}{\\text{Totale Complessivo}}\n\\]\n\n\nCalcolo della Statistica Chi-Quadrato: Usa la formula:\n\\[\n\\chi^2 = \\sum \\frac{(O_i - E_i)^2}{E_i}\n\\]\n\nDeterminazione dei Gradi di Libertà: Calcola \\(\\nu\\) come \\((n_{\\text{righe}} - 1)(n_{\\text{colonne}} - 1)\\).\nConfronto con la Distribuzione Chi-Quadrato: Determina il \\(p\\)-value associato al valore di \\(\\chi^2\\) calcolato e valuta l’ipotesi nulla.\n\nIn conclusione, il Test Chi-Quadrato rappresenta uno strumento per verificare l’indipendenza tra due variabili categoriali. Grazie alla sua semplicità di applicazione e interpretazione, costituisce un metodo di analisi largamente utilizzato in ambito psicologico, sociale e statistico. Tuttavia, è importante prestare attenzione ai presupposti del test, come la sufficienza dei dati in ogni cella, per garantire risultati affidabili e interpretabili.\n\n# Creare la tabella di contingenza\nobserved &lt;- matrix(c(44, 0, 119, \n                              55, 68, 0, \n                              47, 0, 0),\n                            nrow = 3, byrow = TRUE)\n\n# Aggiungere i nomi di righe e colonne\nrownames(observed) &lt;- c(\"Biscoe\", \"Dream\", \"Torgersen\")\ncolnames(observed) &lt;- c(\"Adelie\", \"Chinstrap\", \"Gentoo\")\n\n# Visualizzare la tabella\nprint(observed)\n#&gt;           Adelie Chinstrap Gentoo\n#&gt; Biscoe        44         0    119\n#&gt; Dream         55        68      0\n#&gt; Torgersen     47         0      0\n\n\nchi_square_result &lt;- chisq.test(observed)\nchi_square_result\n#&gt; \n#&gt;  Pearson's Chi-squared test\n#&gt; \n#&gt; data:  observed\n#&gt; X-squared = 285, df = 4, p-value &lt;2e-16\n\nSvolgiamo i calcoli “a mano” usando R. Per calcolare la statistica del test del Chi-Quadrato “a mano” in R, segui questi passaggi:\nCalcoliamo i totali per righe e colonne e il totale complessivo.\n\n# Totali marginali\nrow_totals &lt;- rowSums(observed)\ncol_totals &lt;- colSums(observed)\ngrand_total &lt;- sum(observed)\n\n# Visualizzare i totali\nprint(\"Totali marginali per righe:\")\n#&gt; [1] \"Totali marginali per righe:\"\nprint(row_totals)\n#&gt;    Biscoe     Dream Torgersen \n#&gt;       163       123        47\nprint(\"Totali marginali per colonne:\")\n#&gt; [1] \"Totali marginali per colonne:\"\nprint(col_totals)\n#&gt;    Adelie Chinstrap    Gentoo \n#&gt;       146        68       119\nprint(paste(\"Totale complessivo:\", grand_total))\n#&gt; [1] \"Totale complessivo: 333\"\n\nI valori attesi si calcolano come:\n\\[\nE_{ij} = \\frac{\\text{Totale riga} \\times \\text{Totale colonna}}{\\text{Totale complessivo}} .\n\\]\n\n# Calcolo dei valori attesi\nexpected &lt;- outer(row_totals, col_totals) / grand_total\n\n# Visualizzare i valori attesi\nprint(\"Valori attesi:\")\n#&gt; [1] \"Valori attesi:\"\nprint(expected)\n#&gt;           Adelie Chinstrap Gentoo\n#&gt; Biscoe     71.47    33.285  58.25\n#&gt; Dream      53.93    25.117  43.95\n#&gt; Torgersen  20.61     9.598  16.80\n\nLa statistica Chi-Quadrato si calcola con:\n\\[\n\\chi^2 = \\sum \\frac{(O_{ij} - E_{ij})^2}{E_{ij}} .\n\\]\n\n# Calcolo della statistica Chi-Quadrato\nchi_square_stat &lt;- sum((observed - expected)^2 / expected)\n\n# Visualizzare il risultato\nprint(paste(\"Statistica Chi-Quadrato:\", chi_square_stat))\n#&gt; [1] \"Statistica Chi-Quadrato: 284.590012688092\"\n\nI gradi di libertà si calcolano come:\n\\[\ndof = (\\text{n. righe} - 1) \\times (\\text{n. colonne} - 1) .\n\\]\n\n# Calcolo dei gradi di libertà\ndof &lt;- (nrow(observed) - 1) * (ncol(observed) - 1)\n\n# Visualizzare i gradi di libertà\nprint(paste(\"Gradi di libertà:\", dof))\n#&gt; [1] \"Gradi di libertà: 4\"\n\nConfrontiamo la statistica Chi-Quadrato con la distribuzione teorica per ottenere il p-value.\n\n# Calcolo del p-value\np_value &lt;- pchisq(chi_square_stat, df = dof, lower.tail = FALSE)\n\n# Visualizzare il p-value\nprint(paste(\"p-value:\", p_value))\n#&gt; [1] \"p-value: 2.28189154098739e-60\"\n\nInterpretazione:\nIl valore-\\(p\\) risulta molto piccolo, indicando che, se le variabili Isola e Specie fossero realmente indipendenti, sarebbe estremamente improbabile osservare una distribuzione delle specie di pinguini sulle tre isole così diversa da quella teoricamente attesa. In altre parole, il valore-\\(p\\) rappresenta la probabilità di ottenere, per puro caso, una discrepanza tra i valori osservati e quelli attesi pari o superiore a quella riscontrata nei dati.\nPoiché il valore-\\(p\\) è estremamente basso, possiamo concludere che l’ipotesi di indipendenza tra le variabili Isola e Specie non è plausibile. Questo indica che la distribuzione delle specie di pinguini varia in relazione all’isola, ovvero che conoscendo l’isola è possibile prevedere la distribuzione delle specie. In altre parole, le variabili Isola e Specie sono associate.\n\n80.2.4 Significatività Statistica: Un Concetto da Riconsiderare\nCome discusso nell’esempio precedente, un risultato è considerato “statisticamente significativo” se la probabilità che sia dovuto al caso è bassa, il che suggerisce che il risultato sia stabile o reale. Al contrario, risultati “non significativi” vengono spesso etichettati come privi di valore e ignorati. Questa semplificazione, però, può portare a gravi fraintendimenti. Ad esempio:\n\n\nDipendenza dal campione: La significatività statistica è fortemente influenzata dalla dimensione del campione; risultati apparentemente “significativi” possono emergere anche da effetti molto piccoli in campioni ampi.\n\nRisultati non significativi: Un risultato non significativo non implica che l’effetto sia nullo o irrilevante.\n\nScelte soggettive: Livelli di confidenza e test statistici differenti possono influenzare l’esito dell’analisi, portando a interpretazioni arbitrarie.\n\n80.2.5 Limiti e Applicazioni del Metodo Frequentista\nIl problema più grave dell’approccio frequentista è che esso non sempre mantiene la “promessa” di fornire una base oggettiva per la decisione statistica. Infatti, il ricorso esclusivo alla significatività statistica conduce a risultati opposti a quelli desiderati, aumentando il rischio di pubblicare risultati non replicabili o di trascurare evidenze importanti si veda il 85.\nIn alternativa, è più utile considerare il risultato osservato nel contesto scientifico più ampio, integrandolo con altre analisi. Questo approccio critico e completo consente di superare i limiti della significatività statistica e di interpretare i risultati con maggiore rigore.\n\n80.2.6 Un Caso Specifico: La Media del Campione\nTorniamo ora a esaminare il test di ipotesi all’interno del quadro frequentista, focalizzandoci sul caso di una variabile continua, diversamente dal contesto qualitativo trattato nel test del Chi-Quadrato. Per approfondire la comprensione della significatività statistica, analizzeremo in dettaglio l’utilizzo della media campionaria come stimatore della media della popolazione. Questa riflessione ci consentirà di esplorare sia i limiti che le applicazioni pratiche di tale strumento all’interno della statistica inferenziale frequentista. Attraverso questo esempio, potremo mettere in luce aspetti teorici e operativi dei test di ipotesi, nonché fornire indicazioni su come migliorare l’interpretazione dei risultati, con particolare riferimento al campo della ricerca psicologica.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#il-test-di-ipotesi",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#il-test-di-ipotesi",
    "title": "\n80  Significatività statistica\n",
    "section": "\n80.3 Il Test di Ipotesi",
    "text": "80.3 Il Test di Ipotesi\nIl test di ipotesi è un metodo statistico utilizzato per valutare se i dati sono coerenti con l’ipotesi nulla (\\(H_0\\)). L’ipotesi nulla solitamente afferma che non vi è alcun effetto o differenza significativa, mentre l’ipotesi alternativa (\\(H_1\\)) rappresenta l’affermazione che si desidera testare. I dati del campione vengono analizzati per determinare se forniscono prove sufficienti per rifiutare l’ipotesi nulla. Un passaggio cruciale consiste nel calcolare il value-p.\n\n80.3.1 La procedura di Test di Ipotesi\nEsaminiamo in dettaglio le varie fasi della procedura del test di ipotesi di stampo frequentista.\nPasso 1: Formulare l’ipotesi nulla (\\(H_0\\)) e l’ipotesi alternativa (\\(H_1\\)) basandosi sulla domanda di ricerca.\nPasso 2: Stabilire un livello di significatività, α (solitamente 0.05).\nPasso 3: Selezionare il Test Statistico appropriato, verificare eventuali assunzioni e calcolare il test statistico.\nPasso 4: Decidere se il risultato è “statisticamente significativo” secondo (a) la regione di rifiuto o (b) il valore-p.\n\nL’approccio della regione di rifiuto. Basandosi sulla distribuzione campionaria nota del test statistico, la regione di rifiuto è un insieme di valori per il test statistico per i quali l’ipotesi nulla viene rifiutata. Se il valore osservato del test statistico rientra nella regione di rifiuto, allora si rifiuta l’ipotesi nulla.\nL’approccio del valore-p. Il valore-p è la probabilità di ottenere i risultati osservati, o risultati ancora più estremi, se l’ipotesi nulla è vera.\n\nConfrontiamo il valore-p calcolato con il livello di significatività α:\n\nSe il valore-p &lt; α, si rifiuta l’ipotesi nulla (\\(H_0\\)).\nSe il valore-p ≥ α, non si rifiuta l’ipotesi nulla (\\(H_0\\)).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#il-test-di-ipotesi-nel-contesto-frequentista",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#il-test-di-ipotesi-nel-contesto-frequentista",
    "title": "\n80  Significatività statistica\n",
    "section": "\n80.4 Il Test di Ipotesi nel Contesto Frequentista",
    "text": "80.4 Il Test di Ipotesi nel Contesto Frequentista\nSi noti che i metodi bayesiani e frequentisti non sono semplicemente due approcci diversi per rispondere alla stessa domanda, ma formulano domande fondamentalmente diverse. Pertanto, per comprendere il test di ipotesi frequentista, è essenziale chiarire cosa si intende per valore-p.\nL’American Statistical Association (ASA) definisce il valore-p come:\n\nthe probability under a specified statistical model that a statistical summary of the data (e.g., the sample mean difference between two compared groups) would be equal to or more extreme than its observed value (Wasserstein e Lazar 2016).\n\nQuesta definizione può risultare difficile da comprendere perché contiene concetti complessi come “probabilità” e “modello statistico specificato”. Per capire meglio cosa rappresenta un valore-p, è necessario esaminare attentamente entrambi questi concetti. Questo ci porterà anche a una comprensione più profonda di altri concetti fondamentali per l’inferenza frequentista e ci aiuterà a distinguere tra inferenza frequentista e inferenza bayesiana.\nUna distinzione fondamentale tra l’approccio frequentista e quello bayesiano riguarda l’interpretazione della probabilità: il primo si basa sulla frequenza relativa degli eventi nel lungo periodo, mentre il secondo si basa sulla “certezza soggettiva” o sul grado di fiducia che un individuo attribuisce a un evento specifico.\nChiarito che la probabilità assume significati diversi nei contesti frequentista e bayesiano, possiamo chiederci quale nozione di probabilità sia implicita nella definizione del valore-p fornita dall’ASA. La visione comune suggerisce che si riferisca alle frequenze relative. Ma frequenze relative di cosa e ripetizioni di cosa?\nPossiamo riformulare la definizione dell’ASA in questo modo:\n\nIl valore-p si riferisce alla frequenza relativa di ottenere un riassunto statistico dei dati grande quanto o più grande del valore osservato in ripetizioni ipotetiche di un esperimento descritto da un modello statistico specificato.\n\nQuindi, l’approccio frequentista può essere descritto come un metodo per stimare il valore di un parametro attraverso esperimenti ipotetici, confrontando i nostri dati con i risultati di tali esperimenti per giudicare se i nostri dati sono sorprendenti o meno.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#applicazione-alla-media-campionaria",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#applicazione-alla-media-campionaria",
    "title": "\n80  Significatività statistica\n",
    "section": "\n80.5 Applicazione alla Media Campionaria",
    "text": "80.5 Applicazione alla Media Campionaria\nIn questo capitolo ci concentreremo sull’applicazione del processo di test di ipotesi frequentista alla media campionaria. Vedremo come la media di un campione possa essere impiegata per trarre inferenze sulla media di una popolazione, analizzandone limiti e possibili utilizzi nell’ambito dell’inferenza statistica frequentista.\nI test su uno o due campioni (one-sample e two-sample tests) hanno rappresentato le prime fondamenta dell’analisi statistica dei dati. Al giorno d’oggi, tuttavia, i nostri disegni sperimentali tendono a essere più complessi di quanto questi semplici test possano gestire. Nonostante ciò, tali test – in particolare il celebre t-test di Student – costituiscono ancora un’ottima porta d’ingresso alla modellazione statistica, poiché i principi su cui si basano sono relativamente intuitivi e consentono di familiarizzare con il processo di verifica dell’ipotesi.\nPer comprendere meglio i valori-p e la verifica del test di ipotesi, può essere molto utile ricorrere a simulazioni. Attraverso queste ultime è possibile ricreare condizioni sperimentali ipotetiche e osservare la variabilità dei risultati, fornendo così una prospettiva più chiara sulle implicazioni della statistica frequentista.\n\n80.5.1 La Distribuzione della Media Campionaria\nQuando consideriamo la media campionaria come stima della media di una popolazione, assumiamo che questa popolazione segua una distribuzione normale. Vogliamo quindi esplorare la distribuzione della media campionaria (\\(\\bar{X}\\)), che descrive la variazione di \\(\\bar{X}\\) attraverso infiniti campioni di dimensione \\(n\\). Abbiamo già dimostrato che, se la popolazione è normalmente distribuita, anche la distribuzione campionaria di \\(\\bar{X}\\) seguirà una distribuzione normale, con media \\(\\mu\\) (la media della popolazione) e deviazione standard \\(\\frac{\\sigma}{\\sqrt{n}}\\) (dove \\(\\sigma\\) è la deviazione standard della popolazione e \\(n\\) è la dimensione del campione).\n\n80.5.2 Test di Ipotesi sulla Media Campionaria\nSupponendo di conoscere \\(\\sigma\\) ma non \\(\\mu\\), utilizziamo i test di ipotesi per indagare quanto la media campionaria osservata si discosti da un valore ipotetico \\(\\mu_0\\), specificato dall’ipotesi nulla. Questo processo ci permette di valutare la plausibilità di \\(\\mu_0\\) come vera media della popolazione.\n\n80.5.3 Calcolo della Statistica del Test\nPer valutare quanto la media campionaria osservata si discosti dall’ipotesi nulla che propone \\(\\mu = \\mu_0\\), standardizziamo \\(\\bar{X}\\) usando la formula:\n\\[\nZ = \\frac{\\bar{X} - \\mu_0}{\\sigma/\\sqrt{n}}\n\\]\nQuesta trasformazione produce una variabile \\(Z\\) che segue una distribuzione normale standard \\(\\mathcal{N}(0, 1)\\). Valori estremi di \\(Z\\) (sia molto grandi che molto piccoli) suggeriscono che la media campionaria osservata è incompatibile con \\(\\mu_0\\), portando al rigetto dell’ipotesi nulla.\n\n80.5.3.1 Simulazione\nPer illustrare quanto espresso sopra attraverso una simulazione, consideriamo un esempio numerico. Supponiamo che \\(\\mu_0 = 100\\), \\(\\sigma = 15\\) e \\(n = 30\\). Vogliamo calcolare il valore-p per l’evento \\(\\bar{X} &gt; 105\\).\nLa simulazione può essere eseguita come segue:\n\n# To make the simulation reproducible\nset.seed(123)\n\nmu_0 &lt;- 100\nsigma &lt;- 15\nn &lt;- 30\nn_sim &lt;- 10000  # Number of simulations\n\n# Generate n_sim sample means from a N(mu_0, sigma/sqrt(n))\nsample_means &lt;- rnorm(n_sim, mean = mu_0, sd = sigma / sqrt(n))\n\n# Calculate the p-value as the proportion of sample means &gt; 105\np_value &lt;- mean(sample_means &gt; 105)\n\n# Print the p-value\nprint(p_value)\n#&gt; [1] 0.0339\n\nQuesto script simula la distribuzione campionaria di \\(\\bar{X}\\) sotto l’ipotesi nulla che \\(\\mu = \\mu_0\\) e calcola il valore-p per l’evento \\(\\bar{X} &gt; 105\\). Il valore-p indica la probabilità di osservare un valore di \\(\\bar{X}\\) così estremo (o più estremo) se l’ipotesi nulla fosse vera.\nIl risultato della simulazione può essere confrontato con il calcolo teorico del valore-p usando la distribuzione normale standard. Il valore \\(Z\\) per \\(\\bar{X} = 120\\) è calcolato come:\n\\[\nZ = \\frac{105 - 100}{15/\\sqrt{30}}\n\\]\nPossiamo usare la funzione stats.norm.sf() per trovare l’area sotto la curva normale standard a destra di questo valore \\(Z\\), che corrisponde al valore-p teorico.\n\n# Calculate the Z-score\nZ &lt;- (105 - 100) / (15 / sqrt(30))\nprint(Z)\n#&gt; [1] 1.826\n\n\n# Calculate the upper tail probability\nupper_tail_prob &lt;- pnorm(Z, lower.tail = FALSE)\n\nprint(upper_tail_prob)\n#&gt; [1] 0.03394\n\nOppure, in maniera equivalente\n\n# Calculate the upper tail probability\nupper_tail_prob &lt;- 1 - pnorm(105, mean = 100, sd = 15 / sqrt(30))\nprint(upper_tail_prob)\n#&gt; [1] 0.03394\n\nIl calcolo teorico mostra che il valore \\(Z\\) per una media campionaria di 105 è 1.82. Questo valore indica una deviazione sostanziale dalla media ipotizzata sotto l’ipotesi nulla (\\(\\mu_0 = 100\\)). Tale deviazione può essere quantificata dalla “sorpresa” indicata dal valore-p, dove valori-p piccoli rappresentano una maggiore sorpresa. Il valore-p ottenuto, pari a 0.0339, indica un elevato grado di sorpresa: come mostrato dalla simulazione, un valore di 105 o superiore si verifica solo nel 3.4% dei casi se l’esperimento viene ripetuto numerose volte sotto l’ipotesi nulla. Questo suggerisce che un risultato del genere è altamente improbabile se l’ipotesi nulla fosse vera.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#applicazioni-pratiche",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#applicazioni-pratiche",
    "title": "\n80  Significatività statistica\n",
    "section": "\n80.6 Applicazioni pratiche",
    "text": "80.6 Applicazioni pratiche\nNella precedente discussione, abbiamo supposto \\(\\sigma\\) nota. Tuttavia, poiché di solito non conosciamo il valore di \\(\\sigma\\) nella pratica, dobbiamo stimarlo utilizzando la deviazione standard campionaria \\(s\\). Pertanto, al posto di \\(\\sigma\\), possiamo utilizzare \\(s\\), ottenendo così la statistica:\n\\[\nT = \\frac{\\bar{X} - \\mu_0}{\\frac{s}{\\sqrt{n}}}.\n\\]\nSi può dimostrare che la statistica \\(T\\) segue una distribuzione \\(t\\) di Student con \\(n-1\\) gradi di libertà se il campione casuale è stato estratto da una popolazione normale.\nA questo punto, possiamo applicare la stessa logica descritta in precedenza e possiamom basarci sulla statistica \\(T\\) per testare un’ipotesi sulla media della popolazione. Utilizzando il valore critico appropriato dalla distribuzione \\(t\\) di Student con \\(n-1\\) gradi di libertà e un livello di significatività predefinito, possiamo determinare se i dati osservati supportano o respingono l’ipotesi nulla sulla media della popolazione.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#ipotesi-statistiche",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#ipotesi-statistiche",
    "title": "\n80  Significatività statistica\n",
    "section": "\n80.7 Ipotesi statistiche",
    "text": "80.7 Ipotesi statistiche\nEsaminiamo in maggior dettaglio la procedura di test di ipotesi statistiche nel contesto frequentista. Definiamo innanzitutto l’ipotesi statistica come una dichiarazione riguardante la distribuzione di probabilità di una variabile casuale. Tale ipotesi può riguardare la forma funzionale della distribuzione o i parametri che la caratterizzano.\nIn particolare, l’ipotesi che riguarda i parametri di una o più popolazioni viene denominata ipotesi nulla e viene rappresentata come \\(H_0\\). Per un parametro sconosciuto \\(\\theta\\), l’ipotesi nulla viene formulata come:\n\\[\nH_0: \\theta \\in \\Theta_0 \\subset \\Theta,\n\\]\ndove \\(\\Theta_0\\) è un sottoinsieme del dominio \\(\\Theta\\), che rappresenta tutti i possibili valori del parametro \\(\\theta\\) coerenti con il modello statistico adottato. L’ipotesi nulla può essere semplice se \\(\\Theta_0\\) contiene un unico elemento, oppure composta se contiene più di un elemento.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#i-passi-di-un-test-di-ipotesi",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#i-passi-di-un-test-di-ipotesi",
    "title": "\n80  Significatività statistica\n",
    "section": "\n80.8 I passi di un test di ipotesi",
    "text": "80.8 I passi di un test di ipotesi\nPer prendere una decisione tra accettare o respingere l’ipotesi nulla, i frequentisti utilizzano un test statistico. Un test statistico frequentista ci permette di valutare se i dati osservati forniscono prove sufficienti per respingere o accettare un’ipotesi riguardante una proprietà di una popolazione di interesse e si può descrivere nel modo seguente.\nIniziamo formulando l’ipotesi nulla \\(H_0\\), che rappresenta un’affermazione specifica sulla popolazione. L’ipotesi alternativa \\(H_1\\) viene formulata come l’evento complementare rispetto all’evento specificato dall’ipotesi nulla. Successivamente, definiamo una statistica campionaria \\(\\mathcal{G}_n(X_1, \\dots, X_n)\\) che viene calcolata a partire dai dati campionari e che ha una distribuzione nota quando l’ipotesi nulla è vera.\nSuccessivamente, suddividiamo l’insieme di tutte le possibili realizzazioni della statistica \\(\\mathcal{G}_n\\) in due insiemi disgiunti: la “regione di accettazione” \\(\\mathcal{A}\\) e la sua regione complementare, la “regione di rifiuto” \\(\\mathcal{R}\\). La regione di accettazione rappresenta l’insieme dei valori che la statistica può assumere sotto l’ipotesi nulla, mentre la regione di rifiuto rappresenta l’insieme dei valori che la statistica può assumere se l’ipotesi nulla è falsa.\nInfine, selezioniamo un livello di significatività \\(\\alpha\\), che rappresenta la massima probabilità di respingere erroneamente l’ipotesi nulla quando questa è vera. Se l’osservazione della statistica \\(\\mathcal{G}_n\\) rientra nella regione di accettazione, allora l’ipotesi nulla non viene respinta; altrimenti, viene respinta a favore dell’ipotesi alternativa.\nIn sintesi, il test statistico ci consente di stabilire se i dati osservati forniscono sufficienti evidenze per rifiutare l’ipotesi nulla a favore dell’ipotesi alternativa.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#ipotesi-alternativa",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#ipotesi-alternativa",
    "title": "\n80  Significatività statistica\n",
    "section": "\n80.9 Ipotesi alternativa",
    "text": "80.9 Ipotesi alternativa\nDurante un test di ipotesi, dopo aver definito l’ipotesi nulla \\(H_0\\), possono essere considerate diverse ipotesi alternative \\(H_1\\). Le ipotesi alternative più comuni si suddividono in tre tipi:\n\n\n\\(H_1: \\theta \\neq \\theta_0\\),\n\n\\(H_1: \\theta &gt; \\theta_0\\),\n\n\\(H_1: \\theta &lt; \\theta_0\\).\n\nQueste corrispondono rispettivamente a un test bidirezionale, un test unilaterale superiore (o destro) e un test unilaterale inferiore (o sinistro).\nLa scelta dell’ipotesi alternativa determina la definizione della regione di rifiuto \\(\\mathcal{R}\\) dell’ipotesi nulla \\(H_0\\). La regione di rifiuto rappresenta i valori estremi della distribuzione, nella direzione dell’ipotesi alternativa \\(H_1\\). Nel caso di un test unilaterale inferiore, \\(\\mathcal{R}\\) si trova nella coda sinistra della distribuzione, nell’intervallo [\\(-\\infty\\), \\(\\theta_0\\)]. Nel caso di un test unilaterale superiore, \\(\\mathcal{R}\\) si trova nella coda destra della distribuzione, nell’intervallo [\\(\\theta_0\\), \\(\\infty\\)].\nI valori critici sono i valori che delimitano la regione di rifiuto \\(\\mathcal{R}\\) in un test unilaterale e i valori che delimitano le regioni di rifiuto \\(\\mathcal{R}\\) in un test bidirezionale. Il risultato di un test viene considerato statisticamente significativo se il valore della statistica del test si trova nella regione di rifiuto \\(\\mathcal{R}\\).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#valore-p",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#valore-p",
    "title": "\n80  Significatività statistica\n",
    "section": "\n80.10 Valore-p",
    "text": "80.10 Valore-p\nIl valore-p è definito come la probabilità che la statistica del test assuma un valore uguale o più estremo di quello osservato, considerando la distribuzione campionaria costruita assumendo come vera l’ipotesi nulla. La significatività statistica viene convenzionalmente definita come un valore-p inferiore a 0.05, indicando che l’evidenza osservata è improbabile da ottenere se l’ipotesi nulla è vera. Se il risultato osservato non raggiunge la significatività statistica, significa che la stima non è statisticamente significativa e che il valore osservato può essere spiegato da una semplice variazione casuale.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#un-esempio-motivante",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#un-esempio-motivante",
    "title": "\n80  Significatività statistica\n",
    "section": "\n80.11 Un esempio motivante",
    "text": "80.11 Un esempio motivante\nPer esplorare il concetto di significatività statistica, possiamo prendere in considerazione uno studio svolto da Mehr et al. (2016) sul ruolo della musica nella trasmissione di messaggi sociali ai bambini. La musica è una forma d’arte presente in molte attività quotidiane e può trasmettere informazioni relative alla cultura e all’appartenenza sociale. Gli autori dello studio hanno voluto indagare se i bambini di soli 5 mesi avessero una preferenza per individui sconosciuti che cantavano loro una canzone familiare rispetto ad altri individui sconosciuti che cantavano una canzone simile, ma con una diversa melodia.\nDalle analisi condotte da Mehr et al. (2016) è emerso che la preferenza dei bambini si manifestava solo quando la canzone veniva cantata dai loro genitori durante la fase di familiarizzazione, ma non quando la stessa canzone veniva cantata da un estraneo. Secondo gli autori, questo dimostra che il significato sociale è un elemento chiave nella preferenza dei bambini, oltre alla familiarità con la canzone.\n\n80.11.1 Domanda della ricerca e ipotesi statistiche\nLa ricerca condotta da Mehr et al. (2016) si è concentrata sullo studio dell’influenza della musica sui messaggi sociali trasmessi ai bambini molto piccoli. Tuttavia, come molte altre ipotesi psicologiche, l’ipotesi principale non può essere valutata direttamente in termini quantitativi. Pertanto, i ricercatori devono formulare ipotesi statistiche, che, sebbene non coincidano con l’ipotesi della ricerca, possono essere esaminate in termini probabilistici.\nPer chiarire questo punto, consideriamo l’esperimento condotto sui bambini da Mehr et al. (2016). Dopo la fase di familiarizzazione con la canzone di prova, i bambini partecipanti sono stati sottoposti a un test in laboratorio, durante il quale sono stati mostrati due video. Nel primo video, un estraneo cantava la canzone di prova, mentre nel secondo video, un altro individuo cantava una canzone simile ma non familiare ai bambini. I ricercatori hanno misurato il tempo in cui i bambini fissavano ciascun video. Nel primo esperimento, la variabile dipendente era la media delle proporzioni di tempo che i bambini fissavano il video “familiare” rispetto al tempo di fissazione totale. Poiché l’ipotesi principale non può essere valutata direttamente, i ricercatori hanno formulato ipotesi statistiche che possono essere esaminate in termini probabilistici.\nPoiché nei tipici esperimenti psicologici, come nel caso della ricerca di Mehr et al. (2016), l’ipotesi della ricerca non può essere valutata direttamente, è necessario stabilire una connessione tra l’ipotesi della ricerca e l’ipotesi statistica. Nel caso specifico, ci sono tre possibili scenari da considerare:\n\nNel caso in cui i bambini non mostrino alcuna preferenza tra i due tipi di video-registrazione, la media delle proporzioni di tempo di fissazione per la popolazione sarà uguale a \\(\\mu = 0.5\\), in quanto i tempi di fissazione saranno uguali in media per le due video-registrazioni.\nSe invece gli autori della ricerca hanno ragione, i bambini mostreranno una preferenza per il video con la canzone familiare rispetto a quello con la canzone non familiare. In questo caso, l’ipotesi statistica sarà \\(\\mu &gt; 0.5\\), dove \\(\\mu = 0.5\\) rappresenta il livello di probabilità casuale.\nInfine, una terza possibilità è che i bambini siano maggiormente attratti da una melodia non familiare, contrariamente a quanto suggerito dagli autori della ricerca. In tal caso, l’ipotesi statistica diventa \\(\\mu &lt; 0.5\\).\n\nLe tre ipotesi precedenti sono esempi di ipotesi statistiche, che sono delle affermazioni riguardanti i valori di un parametro di un modello statistico. Nel caso dell’esperimento di Mehr et al. (2016), il modello statistico riguarda la distribuzione delle proporzioni dei tempi di fissazione di una popolazione virtuale di infiniti bambini di sei mesi di età. Ogni bambino avrà una proporzione di tempi di fissazione diversa dagli altri bambini. Il modello statistico descritto dai ricercatori rappresenta la distribuzione dei possibili valori della proporzione del tempo di fissazione nei confronti del video “familiare”. I dati raccolti dagli sperimentatori corrispondono alla media della proporzione del tempo di fissazione del video “familiare” e possono essere messi in relazione con il modello statistico.\n\n80.11.2 Domanda della ricerca e ipotesi statistiche\nLa distinzione tra l’ipotesi della ricerca e l’ipotesi statistica è cruciale durante il test delle ipotesi. L’ipotesi della ricerca riguarda l’affermazione che si intende testare sulla natura dei fenomeni psicologici, mentre l’ipotesi statistica riguarda il modello generativo dei dati, ovvero le proprietà della popolazione. Nel caso dell’esperimento condotto da Mehr e colleghi, l’ipotesi della ricerca afferma che la preferenza sociale dei bambini è influenzata dalla musica e, in particolare, dalla familiarità con i materiali musicali. L’ipotesi statistica, invece, sostiene che la media della proporzione del tempo di fissazione dei bambini sul video “familiare” sia maggiore di 0.5.\nI test di ipotesi vengono applicati alle ipotesi statistiche, non alle ipotesi della ricerca. Ciò significa che se l’esperimento non viene condotto nella maniera appropriata, il collegamento tra l’ipotesi statistica e la domanda della ricerca può essere spezzato. Ad esempio, se l’attore che canta la melodia familiare assomiglia ad uno dei genitori del bambino, mentre l’altro attore ha un aspetto molto diverso, allora potrebbe essere facile trovare evidenze a supporto dell’ipotesi statistica secondo cui la proporzione media del tempo di fissazione dei bambini nei confronti del video “familiare” è maggiore di 0.5, ma ciò non avrebbe nulla a che fare con la domanda della ricerca.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#ipotesi-nulla-e-ipotesi-alternativa",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#ipotesi-nulla-e-ipotesi-alternativa",
    "title": "\n80  Significatività statistica\n",
    "section": "\n80.12 Ipotesi nulla e ipotesi alternativa",
    "text": "80.12 Ipotesi nulla e ipotesi alternativa\nFino a qui il ragionamento è stato semplice: il ricercatore ha un’ipotesi a proposito dei fenomeni psicologici e a tale ipotesi di ricerca corrisponde un’ipotesi statistica che riguarda il meccanismo generativo dei dati. Se il fenomeno psicologico possiede le proprietà suggerite dall’ipotesi della ricerca, allora il ricercatore può aspettarsi che i dati osservati abbiano alcune specifiche caratteristiche. A questo punto, però, il ragionamento diventa contro-intuitivo perché non è possibile verificare direttamente l’ipotesi statistica che corrisponde alla domanda della ricerca.\n\n80.12.1 Apagogia\nIn linea di principio, non è mai possibile dimostrare direttamente la verità di una proposizione. Tuttavia, possiamo dimostrare la sua verità in modo indiretto, ovvero provando la falsità della sua proposizione complementare.\nL’esempio classico è il seguente. Consideriamo la seguente proposizione: “Tutti i cigni sono bianchi” (questo è l’esempio ornitologico preferito da Popper). L’osservazione di un numero qualsiasi di cigni bianchi non è sufficiente a dimostrare la verità di questa proposizione – infatti, ci potrebbe essere da qualche parte un cigno non bianco che non abbiamo osservato (e infatti c’è). D’altra parte, invece, l’osservazione di un solo cigno che non sia bianco (ovvero, per esempio, l’osservazione di un cigno nero proveniente dall’Australia) può falsificare la proposizione considerata. Questa è la logica del falsificazionismo di Popper.\nQuesto modo di pensare è stato trasferito nella procedura di test di ipotesi di stampo frequentista. Dato che non possiamo dimostrare vera l’ipotesi statistica associata alla domanda della ricerca, seguiamo il percorso opposto. Ovvero, ci poniamo l’obiettivo di dimostrare falso l’evento complementare a quello specificato dall’ipotesi statistica associata alla domanda della ricerca. L’ipotesi statistica che vorremmo falsificare si chiama “ipotesi nulla” e viene denotata con \\(H_0\\). Nel caso dell’esempio che stiamo discutendo, l’ipotesi nulla è: \\(\\mu \\leq 0.5\\). Si noti che l’ipotesi nulla include tutte le possibili ipotesi statistiche che si possono formulare (ovvero, \\(\\mu = 0.5\\) e \\(\\mu &lt; 0.5\\)), ad eccezione di quella che è associata all’ipotesi della ricerca (ovvero, \\(\\mu &gt; 0.5\\)). Questo definisce, nel caso presente, un test unilaterale.\nIn pratica, ciò che stiamo facendo è dividere tutti i possibili valori di \\(\\mu\\) in due gruppi: quei valori che sono coerenti con l’ipotesi della ricerca (ovvero, i valori che specificano l’ipotesi alternativa, denotata con \\(H_1\\)) e quei valori che non sono coerenti con l’ipotesi della ricerca (ovvero, i valori che specificano l’ipotesi nulla).\nAvendo detto questo, la cosa importante da riconoscere è che l’obiettivo di un test di ipotesi frequentista non è quello di dimostrare che l’ipotesi alternativa è (probabilmente) vera; l’obiettivo è mostrare che l’ipotesi nulla è (probabilmente) falsa. La maggior parte delle persone ritiene che questo modo di ragionare sia piuttosto strano.\n\n80.12.2 La similitudine del processo penale\nUn test di ipotesi è spesso comparato ad un processo penale, dove l’ipotesi nulla rappresenta l’imputato, il ricercatore il pubblico ministero, e il test statistico il giudice. Così come in un processo penale, anche in un test di ipotesi c’è una presunzione di innocenza, dove l’ipotesi nulla viene considerata vera a meno che il ricercatore non dimostri, con evidenza al di là di ogni ragionevole dubbio, che è falsa. Il ricercatore progetta l’esperimento in modo da massimizzare la possibilità che i dati producano una condanna dell’ipotesi nulla. Il test statistico, rappresentato dal giudice in questa metafora, stabilisce le regole che devono essere seguite per giungere al verdetto e tali regole sono pensate per proteggere l’ipotesi nulla. In particolare, sono studiate per garantire che la probabilità di una condanna sia bassa se l’ipotesi nulla è effettivamente vera. È importante sottolineare che l’ipotesi nulla deve essere protetta, poiché il ricercatore sta cercando di dimostrare che essa è falsa.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#due-tipi-di-errori",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#due-tipi-di-errori",
    "title": "\n80  Significatività statistica\n",
    "section": "\n80.13 Due tipi di errori",
    "text": "80.13 Due tipi di errori\nPrima di entrare nei dettagli su come viene costruito un test statistico è utile capire la logica su cui esso è basato. In precedenza abbiamo paragonato il test di ipotesi nulla ad un processo penale, ma ora dobbiamo essere più espliciti. Idealmente, vorremmo costruire il nostro test in modo da non commettere errori. Sfortunatamente, però, questo non è possibile: a volte il ricercatore è sfortunato e finisce per prendere la decisione sbagliata, anche se adotta un processo decisionale razionale. Ad esempio, può succedere che una moneta venga lanciata 10 volte di fila e produca testa tutte le 10 volte. Ciò sembra fornire una prova molto forte del fatto che la moneta è sbilanciata, ma c’è una possibilità su 1024 che ciò accada anche se la moneta è equilibrata. In altre parole, nella vita reale dobbiamo sempre accettare la possibilità che le nostre scelte siano sbagliate, anche quando sembrano ragionevoli. Di conseguenza, l’obiettivo dei test delle ipotesi statistiche non è quello di eliminare completamente gli errori (questo è impossibile), ma di ridurre gli errori al minimo.\nA questo punto, dobbiamo precisare meglio cosa intendiamo per “errori”. Iniziamo con il rendere esplicito quello che è ovvio: l’ipotesi nulla può essere vera o falsa, e il nostro test ci può condurre a rifiutare l’ipotesi nulla o a non rifiutarla. La decisione di rigettare o non rigettare l’ipotesi nulla ci espone dunque al rischio di commettere uno di due tipi di errore, come indicato nella figura seguente. L’errore di I tipo, denotato con \\(\\alpha\\), è quello che commettiamo se rigettiamo l’ipotesi nulla quando essa è vera; l’errore di II tipo, denotato con \\(\\beta\\), è quello che commettiamo se accettiamo l’ipotesi nulla mentre invece è vera l’ipotesi alternativa.\n\n\n80.13.1 Errore di I tipo: la protezione dei diritti dell’imputato\nIn precedenza abbiamo paragonato il test statistico ad un processo penale. Infatti, un processo penale richiede che si stabilisca la colpevolezza dell’imputato “oltre ogni ragionevole dubbio”. Le regole del processo penale sono state progettate per garantire che non ci sia (quasi) nessuna possibilità di condannare ingiustamente un imputato innocente: il processo penale è progettato (almeno in teoria) per proteggere i diritti dell’imputato. Detto in altri termini, il processo penale non mette sullo stesso piano i due tipi di errore che si possono commettere: punire un innocente o assolvere un colpevole. L’errore che consiste nel punire un innocente viene considerato assai più grave di quello che porta ad assolvere un colpevole.\nUn test statistico fa praticamente la stessa cosa: i test di ipotesi statistiche sono costruiti in modo tale da controllare la probabilità di un errore di I tipo, con l’obiettivo di mantenerla al di sotto di una certa soglia prefissata. Questa probabilità, denotata con \\(\\alpha\\), viene chiamata “livello di significatività del test”. Usando parole diverse, possiamo dire che un test di ipotesi ha un livello di significatività \\(\\alpha\\) se il tasso di errore di I tipo non è più grande di \\(\\alpha\\). Per convenzione, i ricercatori fanno uso di tre diversi livelli \\(\\alpha\\): 0.05, 0.01 e 0.001.\n\n80.13.2 Errore di II tipo: l’asimmetria del giudizio\nChe dire del tasso di errore di II tipo? In realtà, vorremmo tenere anche quello sotto controllo e denotiamo la probabilità di un errore di II tipo con \\(\\beta\\). Il livello d’errore \\(\\beta\\) viene raramente discusso ed è molto più comune fare riferimento alla potenza del test, che è la probabilità dell’evento complementare, ovvero la probabilità con cui rifiutiamo l’ipotesi nulla quando è realmente falsa, ovvero \\(1-\\beta\\). Un test viene detto “potente” quando è caratterizzato da un piccolo valore \\(\\beta\\) pur mantenendo il livello \\(\\alpha\\) sotto una piccola soglia di probabilità prefissata.\nSi noti l’asimmetria qui rivelata: i test di ipotesi sono progettati per garantire che il livello \\(\\alpha\\) sia mantenuto sotto la soglia prefissata, ma non esiste alcuna corrispondente garanzia a proposito di \\(\\beta\\). Sicuramente è preferibile che il tasso di errore di II tipo sia piccolo, e in generale i ricercatori cercano di progettare i loro esperimenti in maniera tale da avere una ragionevole potenza del test (\\(1 - \\beta\\)) – questo si ottiene utilizzando un campione sufficientemente grande – ma nella logica della costruzione del test di ipotesi questo aspetto è secondario rispetto alla necessità di controllare il tasso di errore di I tipo.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#come-si-costruisce-un-test-di-ipotesi",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#come-si-costruisce-un-test-di-ipotesi",
    "title": "\n80  Significatività statistica\n",
    "section": "\n80.14 Come si costruisce un test di ipotesi?",
    "text": "80.14 Come si costruisce un test di ipotesi?\nRitorniamo all’esempio relativo allo studio di Mehr et al. (2016). In questo caso, sulla base all’ipotesi della ricerca, l’ipotesi nulla può essere formulata come \\(H_0: \\mu \\leq 0.5\\). Esaminando un campione di 32 bambini di età media pari a 5.6 mesi, Mehr et al. (2016) hanno scoperto che, in media, i bambini dirigevano lo sguardo verso il video “familiare” nel 56% del tempo totale di fissazione. Dunque, la media campionaria è \\(\\bar{X} = 0.56\\) Questo è il valore campionario rilevante per il test dell’ipotesi nulla.\nIngenuamente, potremmo pensare che, per decidere se \\(H_0\\) sia falsa o meno, sia sufficiente confrontare la proporzione calcolata nel campione con il valore \\(\\pi\\) specificato dall’ipotesi nulla. Nel caso presente, l’ipotesi nulla non specifica un unico valore \\(\\mu\\) ma bensì un intervallo di valori: \\([0, 0.5]\\). I dati campionari specificano un valore \\(\\bar{X} = 0.56\\), ovvero un valore che non è incluso nell’intervallo specificato da \\(H_0\\). Questo è incoraggiante. Se invece avessimo osservato \\(\\bar{X} = 0.41\\), per esempio, allora non ci sarebbe stato nient’altro da dire: se i dati osservati sono compatibili con \\(H_0\\) non c’è bisogno di eseguire alcun test statistico – abbiamo già trovato la risposta alla domanda della ricerca.\n\n80.14.1 La variabilità campionaria\nNel caso dell’esperimento di Mehr et al. (2016) che stiamo discutendo, \\(\\bar{X}\\) non cade nell’intervallo specificato da \\(H_0\\). Sulla base del valore osservato \\(\\bar{X} = 0.56\\) possiamo dunque concludere che \\(H_0\\) è falsa? Non così presto. Non è sufficiente trovare una differenza \\(\\bar{X} - \\mu\\) nella direzione giusta (cioè positiva, nel nostro caso). È anche necessario tenere in considerazione il fenomeno della variabilità campionaria.\nInfatti, la media \\(\\bar{X}\\) osservata in ogni singolo campione di ampiezza \\(n=32\\) è una variabile aleatoria: in ciascun possibile campione di ampiezza 32 i bambini si comportano in maniera diversa e, di conseguenza, \\(\\bar{X}\\) assumerà un valore diverso da campione a campione. Le statistiche campionarie – nel nostro caso la media \\(\\bar{X}\\) – sono di necessità diverse dai parametri. Ciò a cui noi siamo interessati è la media della popolazione, ovvero \\(\\mu\\), ma sfortunatamente conosciamo solo una sua realizzazione campionaria, ovvero \\(\\bar{X}\\).\nRisulta dunque chiaro che la nostra decisione rispetto ad \\(H_0\\) non può essere unicamente basata sulla differenza tra \\(\\bar{X} - \\mu\\). Infatti, è ragionevole pensare che, indipendentemente dal fatto che l’ipotesi nulla sia vera o meno, in alcuni campioni la differenza \\(\\bar{X} - \\mu\\) sarà positive mentre in altri campioni sarà negativa. Dobbiamo dunque trovare una procedura che riduca la possibilità di rifiutare \\(H_0\\) per effetto del caso soltanto. Possiamo (e dobbiamo) fare di meglio che considerare unicamente la differenza \\(\\bar{X} - \\mu\\).\n\n80.14.2 Le distribuzioni delle statistiche test\nIl metodo seguito dall’approccio frequentista per affrontare questo problema è quello di costruire la distribuzione della statistica test \\(\\mathcal{G}_n\\), rilevante per il test di \\(H_0\\), assumendo come vera l’ipotesi nulla. Questo è il concetto più contro-intuitivo di tutta la procedura di test di ipotesi dell’approccio frequentista. Esaminiamolo più in dettaglio.\nLo scopo della procedura di test statistici dell’approccio frequentista non è quello di verificare l’ipotesi alternativa: questo non è logicamente possibile. Invece, come suggerito dalla similitudine del processo penale all’ipotesi nulla, l’approccio frequentista si pone l’obiettivo di determinare se ci siano indizi sufficienti per “condannare” l’ipotesi nulla, ovvero, per rigettarla. In questa reductio ad absurdum, la “presunzione di innocenza” di \\(H_0\\) corrisponde all’idea che dobbiamo assumere come vera l’ipotesi nulla fino a prova contraria.\nNell’esempio che stiamo discutendo, assumere come vera l’ipotesi nulla significa assumere che il parametro \\(\\mu\\) (la media della popolazione) sia uguale a 0.5. Sulla base di questa assunzione, per i dati dell’esempio presente, è possibile costruire la distribuzione delle medie dei campioni di ampiezza 32. Standardizzando poi la media del campione, è possibile stabilire quanto sia “distante” dal valore atteso della distribuzione campionaria costruita assumento come vera \\(H_0\\).\nLa standardizzazione di \\(\\bar{X}\\) si effettua mediante il rapporto\n\\[\nT = \\frac{\\bar{X} - \\mu}{\\frac{s}{\\sqrt{n}}},\n\\]\ndove \\(\\bar{X}\\) è la media del campione (nel nostro caso, 0.56), \\(s\\) è la deviazione standard del campione (gli autori riportano \\(s\\) = 0.179) e \\(n\\) è l’ampiezza del campione (ovvero, \\(n\\) = 32). Per il caso presente otteniamo:\n\nT &lt;- (0.56 - 0.50) / (0.179 / sqrt(32))\nprint(T)\n#&gt; [1] 1.896\n\n\n80.14.3 Regioni di rifiuto e regioni di non rifiuto\nConoscendo la distribuzione dei valori della statistica test (distribuzione determinata assumendo come vera \\(H_0\\)) diventa poi possibile dividere l’insieme dei valori possibili di \\(\\mathcal{G}_n\\) (il nome che abbiamo assegnato ad una generica statistica test) in due regioni: i valori che ci portano a rigettare \\(H_0\\) (regione di rifiuto) e quelli che non ci consentono di rigettare \\(H_0\\) (regione di non rifiuto).\nPer decidere quanto deve essere grande la regione di rifiuto di \\(H_0\\) è sufficiente collocare nella regione di rifiuto i valori estremi della statistica test \\(\\mathcal{G}_n\\), ovvero quelli che sarebbe molto improbabile osservare se \\(H_0\\) fosse vera.\n\n80.14.4 Quando rifiutare l’ipotesi nulla\nSupponiamo che la figura seguente rappresenti la distribuzione campionaria della statistica test \\(\\mathcal{G}_n\\).\n\nSe i dati producono la statistica test \\(\\mathcal{G}_n^1\\), non possiamo rifiutare l’ipotesi nulla \\(H_0\\). Se invece i dati producono \\(\\mathcal{G}_n^2\\) allora possiamo rifiutare l’ipotesi nulla in favore dell’ipotesi alternativa. Ci sono varie cose da notare.\n\nLa regione di rifiuto è costituita da valori lontani dal centro della distribuzione campionaria della statistica test, la quale è stata costruita assumendo come vera \\(H_0\\).\nLa regione di rifiuto è situata nelle code della distribuzione. Vedremo in seguito anche degli esempi di regioni di rifiuto unilaterali.\nIn questa discussione, l’ipotesi alternativa non è menzionata. Rifiutiamo o non rifiutiamo \\(H_0\\) basandoci unicamente sulla distribuzione campionaria \\(f(\\mathcal{G}_n \\mid H_0)\\), cioè sulla probabilità della statistica test condizionata all’ipotesi nulla \\(H_0\\). L’ipotesi alternativa \\(H_1\\) viene presa in considerazione quando si sceglie dove posizionare la regione di rifiuto di \\(H_0\\), ma formalmente non gioca alcun ruolo nel rigettare o meno \\(H_0\\).\n\n80.14.5 Specificazione delle regioni di rifiuto\nL’ipotesi alternativa \\(H_1\\) può assumere forme diverse e ciò conduce a specificazioni diverse della regione di rifiuto \\(\\mathcal{R}\\) di \\(H_0\\). La regione di rifiuto \\(\\mathcal{R}\\) dell’ipotesi nulla corrisponde ai valori collocati agli estremi della distribuzione secondo la direzione dell’ipotesi alternativa \\(H_1\\).\n\nSe l’ipotesi alternativa è \\(H_1: \\theta \\neq \\theta_0\\) (dove \\(\\theta\\) è un generico parametro e \\(\\theta_0\\) è uno specifico valore del parametro), allora le evidenze coerenti con l’ipotesi alternativa (e che portano al rigetto di \\(H_0\\)) sono contenute negli intervalli \\([-\\infty, \\theta_0]\\) e \\([\\theta_0, +\\infty]\\).\nSe l’ipotesi alternativa è \\(H_1: \\theta &lt; \\theta_0\\), allora le evidenze coerenti con l’ipotesi alternativa (e che portano al rigetto di \\(H_0\\)) sono contenute nell’intervallo \\([-\\infty, \\theta_0]\\) e l’intera regione di rifiuto \\(\\mathcal{R}\\) è collocata nella coda di sinistra della distribuzione.\nSe l’ipotesi alternativa è \\(H_1: \\theta &gt; \\theta_0\\), allora le evidenze coerenti con l’ipotesi alternativa (e che portano al rigetto di \\(H_0\\)) sono contenute nell’intervallo \\([\\theta_0, \\infty]\\) e l’intera regione di rifiuto \\(\\mathcal{R}\\) è collocata nella coda di destra della distribuzione.\n\nSi chiamano valori critici i valori che delimitano la regione di rifiuto \\(\\mathcal{R}\\) in un test unilaterale e i valori che delimitano le regioni di rifiuto \\(\\mathcal{R}\\) in un test bilaterale. In un test bidirezionale, i valori critici lasciano in ciascuna delle due code della distribuzione della statistica test una probabilità pari a \\(\\alpha/2\\); in un test unidirezionale lasciano una probabilità pari ad \\(\\alpha\\) in una sola coda. Il risultato di un test si dice statisticamente significativo quando il valore della statistica test ricade nella regione di rifiuto \\(\\mathcal{R}\\).\n\n80.14.6 La decisione statistica\nIl processo di decisione statistica viene descritto da von Mises (1964) nel modo seguente:\n\nControllare (checking) o saggiare (testing) ha la forma seguente: se il “risultato osservato” ha una ‘piccola’ probabilità subordinatamente all’ipotesi assunta, respingiamo l’ipotesi. (p. 441)\n\nOvviamente l’ipotesi a cui von Mises fa riferimento è l’ipotesi nulla.\nIn pratica, possiamo decidere se rigettare o meno l’ipotesi nulla in due modi: determinando se la statistica test \\(\\mathcal{G}_n\\) cade o meno nella regione di rifiuto (come abbiamo descritto sopra) o confrontando il valore-\\(p\\) con \\(\\alpha\\) – i due metodi sono equivalenti.\nIl valore-p rappresenta la probabilità di osservare un valore della statistica test \\(\\mathcal{G}_n\\) pari a quello effettivamente osservato, o maggiore, quanto l’ipotesi nulla è vera. Se il valore-\\(p\\) è minore del livello di significatività \\(\\alpha\\), allora la statistica test cade nella regione di rifiuto di \\(H_0\\) e ciò conduce al rifiuto dell’ipotesi nulla. Tali concetti sono riassunti nella tabella seguente.\n\nPer l’esempio in discussione, la statistica \\(T\\) calcolata sopra si distribuisce come \\(t\\) di Student con \\(\\nu = 31\\) gradi di libertà. Il valore-p corrisponde dunque all’area sottesa ad una \\(t_{31}\\) nell’intervallo \\([1.896, +\\infty]\\) (test unidirezionale destro), ovvero\n\n# Calculate the upper tail probability for the t-distribution\np &lt;- 1 - pt(T, df = 31)\nprint(p)\n#&gt; [1] 0.03365\n\nDato che il valore-p è minore di \\(\\alpha = 0.05\\), Mehr et al. (2016) rifiutano \\(H_0\\) (cioè che la proporzione media del tempo di fissazione dei bambini nei confronti del video “familiare” sia 0.5, o minore) e concludono che i bambini mostrano una preferenza per il video familiare.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#potenza-del-test",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#potenza-del-test",
    "title": "\n80  Significatività statistica\n",
    "section": "\n80.15 Potenza del test",
    "text": "80.15 Potenza del test\nRitorniamo ora al concetto di potenza del test. Il livello di significatività e la potenza del test vengono usati per quantificare la qualità dell’inferenza statistica. Idealmente, la procedura di test di ipotesi non dovrebbe giungere alla conclusione sbagliata. Ovvero, non dovrebbe respingere \\(H_0\\) quando essa è vera e dovrebbe respingere \\(H_0\\) in favore dell’alternativa quando \\(H_1\\) è vera. Ma questi sono solo due dei quattro esiti che, in principio, sono possibili, e corrispondono alle probabilità indicate di seguito.\n\nPossiamo pensare a \\(H_0\\) come all’ipotesi che descrive l’evento “nulla di interessante sta succedendo” – ad esempio, “la moneta è bilanciata”, “il trattamento non è migliore del placebo”, ecc. – e pensare ad \\(H_1\\) come al caso contrario, ovvero: “sta accadendo qualcosa di interessante”. Quindi la potenza del test, ovvero la probabilità \\(1 - \\beta\\) di rigettare \\(H_0\\) quando essa è falsa, corrisponde alla probabilità di rilevare qualcosa di interessante, quando qualcosa di interessante è effettivamente successo, mentre il livello di significatività corrisponde alla probabilità di affermare che qualcosa di interessante si è verificato, quando in realtà non è successo nulla di interessante.\nIl calcolo della potenza di un test è spesso difficile, perché richiede la conoscenza della distribuzione campionaria di \\(\\mathcal{G}_n\\) quando è vera l’ipotesi alternativa \\(H_1\\). Tipicamente possiamo aumentare la potenza di un test aumentando la numerosità del campione in maniera tale da diminuire la varianza delle distribuzioni della statistica test condizionate a \\(H_0\\) e ad \\(H_1\\). In un disegno sperimentale è importante determinare in anticipo il numero di prove o dei soggetti necessari per raggiungere la potenza desiderata.\n\n80.15.1 Neyman e Fisher\nLa procedura di test di ipotesi statistiche descritta sopra combina due approcci teorici diversi, proposti da Sir Ronald Fisher e Jerzy Neyman. La storia di questi due approcci non è lineare, poiché Fisher e Neyman hanno modificato le loro opinioni nel tempo, senza mai fornire una “verità definitiva” su come interpretare il loro lavoro.\nIn sintesi, Fisher considerava che il ricercatore avesse un’unica ipotesi (quella nulla) e che lo scopo fosse verificare se i dati fossero coerenti o meno con essa. In questo senso, il valore-\\(p\\) rappresenta la probabilità di osservare, sotto l’ipotesi nulla, il risultato ottenuto o uno ancora più estremo. Se il valore-\\(p\\) è piccolo, Fisher rifiutava l’ipotesi nulla. Tuttavia, poiché non venivano formulate altre ipotesi, non c’era modo di “accettare l’alternativa”.\nAl contrario, Neyman adottava un approccio più formale rispetto a Fisher e pensava che lo scopo della verifica delle ipotesi fosse quello di prendere decisioni. Secondo Neyman, il problema era decidere se accettare l’ipotesi nulla o l’alternativa e il test serviva a stabilire quale supporto venisse fornito alle due alternative. Per questo motivo, era fondamentale specificare in modo preciso l’ipotesi alternativa. Nel suo approccio, il valore-\\(p\\) non misurava la probabilità del risultato del test o di uno più estremo sotto l’ipotesi nulla, ma forniva una descrizione astratta dei “possibili test” che portavano all’accettazione dell’ipotesi nulla o dell’alternativa.\nAttualmente ci troviamo in una situazione strana e ambigua, dove sono presenti elementi di entrambi gli approcci. La procedura di verifica di ipotesi statistiche distingue tra un’ipotesi nulla e un’ipotesi alternativa, seguendo la visione di Neyman, ma definisce il valore-\\(p\\) in termini di dati estremi, come avrebbe fatto Fisher, in confronto con un livello \\(\\alpha\\) stabilito da Neyman. Alcuni test statistici specificano in modo chiaro l’ipotesi alternativa, mentre altri sono più vaghi in merito, adottando l’approccio di Fisher. Inoltre, c’è disaccordo tra i ricercatori riguardo alla possibilità di “accettare l’alternativa”, a seconda che si segua Neyman o Fisher. Questa confusione costituisce il “peccato originale” della procedura di verifica di ipotesi statistiche. Tuttavia, ci sono motivi più specifici per cui questo approccio, noto come significatività statistica, viene criticato da molti ricercatori come una delle cause principali della crisi della replicabilità dei risultati della ricerca in psicologia e in altri campi. Nel capitolo ?sec-errors-s-m esploreremo queste ragioni in dettaglio.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#la-storia-del-test-dellipotesi-nulla-di-fisher-e-le-sue-contraddizioni",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#la-storia-del-test-dellipotesi-nulla-di-fisher-e-le-sue-contraddizioni",
    "title": "\n80  Significatività statistica\n",
    "section": "\n80.16 La Storia del Test dell’Ipotesi Nulla di Fisher e le Sue Contraddizioni",
    "text": "80.16 La Storia del Test dell’Ipotesi Nulla di Fisher e le Sue Contraddizioni\nConcludiamo l’analisi della procedura dei test di ipotesi statistici esaminando l’evento che ha ispirato Ronald A. Fisher a sviluppare la sua teoria dell’inferenza statistica, focalizzata sul test dell’ipotesi nulla. Questo episodio è descritto dettagliatamente da Etz et al. (2018). L’aneddoto riguarda un tè che Fisher aveva offerto alla sua collega, la Dott.ssa Muriel Bristol. Durante la preparazione della bevanda, la Dr.ssa Bristol contestò il metodo adottato da Fisher, asserendo che il tè avrebbe avuto un gusto migliore se il latte fosse stato versato prima dell’acqua bollente. Per verificare l’affermazione della Dr.ssa Bristol, Fisher ideò un esperimento di discriminazione sensoriale. Nei test condotti, la Dr.ssa Bristol fu in grado di individuare correttamente il processo di preparazione del tè in cinque occasioni su sei.\nQuesto risultato pose Fisher di fronte a un interrogativo: la sua collega stava semplicemente facendo una supposizione fortunata, oppure era effettivamente in grado di discernere tra le due diverse modalità di preparazione? Per risolvere questa questione, Fisher elaborò la sua metodologia per il test dell’ipotesi nulla. Utilizzò un valore-\\(p\\) calcolato sulla base della probabilità dell’evento osservato, nonché di qualsiasi altro evento più estremo che potrebbe verificarsi sotto l’ipotesi nulla.\nTuttavia, è stato fatto notare che l’approccio di Fisher al test dell’ipotesi nulla può essere insufficiente e portare a conclusioni errate (Etz et al., 2018). Una delle questioni fondamentali riguarda la definizione di un evento “più estremo” rispetto a quello osservato.\nSupponiamo che lo scopo dell’esperimento casuale sia di determinare l’accuratezza delle riposte della Dr.ssa Bristol in esattamente sei tentativi (e non di più). In tale caso, con 5 risposte corrette, il valore-\\(p\\) è pari a 0.109, che non è statisticamente significativo. In questo scenario, secondo la logica di Fisher, non si dovrebbe respingere l’ipotesi nulla che la Dr. Bristol stesse semplicemente indovinando.\nSupponiamo ora che lo scopo dell’esperimento casuale sia di continuare a servire tè fino a quando la Dr.ssa Bristol non abbia raggiunto cinque risposte corrette (un risultato che, per coincidenza, si è verificato dopo sei tentativi). Se analizziamo i dati in questo secondo scenario, il valore-\\(p\\) diventa pari a 0.031, che è statisticamente significativo. In quest’ultimo caso, l’ipotesi nulla verrebbe respinta.\nQuello che emerge è che, nonostante i dati osservati nei due scenari siano identici, giungiamo a conclusioni opposte come conseguenza delle diverse modalità di campionamento impiegate. Questa variabilità è problematica poiché il valore-\\(p\\), e quindi la nostra valutazione delle capacità discriminative della Dr.ssa Bristol, dipendono non solo dai dati effettivamente raccolti, ma anche dal disegno sperimentale adottato. Questa constatazione mette in discussione la robustezza del test dell’ipotesi nulla come strumento fondamentale per l’inferenza scientifica.\nPer illustrare il problema, svolgiamo i calcoli utilizzando le distribuzioni statistiche richieste per i due tipi di campionamento: la distribuzione binomiale e la distribuzione geometrica negativa.\n\n80.16.1 Distribuzione Binomiale\nLa distribuzione binomiale è la distribuzione da utilizzare quando il numero di tentativi è prefissato e conosciuto a priori. Nel contesto dell’esempio del tè, assumiamo che siano state servite esattamente sei tazze. La formula per determinare la probabilità di registrare esattamente \\(k\\) successi in \\(n\\) tentativi è la seguente:\n\\[\nP(X = k) = \\binom{n}{k} \\times p^k \\times (1-p)^{(n-k)}\n\\]\nQui, \\(\\binom{n}{k}\\) rappresenta il coefficiente binomiale, \\(p\\) è la probabilità di un singolo successo (ossia di indovinare correttamente la preparazione del tè), e \\((1-p)\\) è la probabilità di un singolo fallimento.\nPer calcolare il valore-\\(p\\) in questo specifico contesto, dobbiamo sommare le probabilità di ottenere un risultato di 5 o più estremo su un totale di 6 tentativi.\n\n# Parameters\nn_binomial &lt;- 6  # Number of fixed trials for the binomial distribution\nn_success &lt;- 5  # Desired number of successes\np &lt;- 0.5  # Probability of success\n\n# Calculate the p-value for the binomial distribution\np_value_binomial &lt;- 1 - pbinom(n_success - 1, size = n_binomial, prob = p)\n\np_value_binomial\n#&gt; [1] 0.1094\n\n\n80.16.2 Distribuzione Geometrica Negativa\nNel contesto dell’esperimento del tè, quando il test continua fino al raggiungimento di un numero prefissato di successi (nel nostro caso, cinque identificazioni corrette), la distribuzione di riferimento appropriata è la distribuzione geometrica negativa.\nLa distribuzione geometrica negativa modella il numero di fallimenti \\(k\\) che si verificano prima di ottenere un numero prefissato \\(r\\) di successi in una sequenza di prove indipendenti di Bernoulli, dove ogni prova ha probabilità di successo \\(p\\).\nLa probabilità di osservare esattamente \\(k\\) fallimenti prima di ottenere \\(r\\) successi è data da:\n\\[\nP(X = k) = \\binom{k+r-1}{k} p^r (1-p)^k,\n\\]\ndove:\n\n\n\\(k\\) è il numero di fallimenti,\n\n\\(r\\) è il numero di successi desiderato,\n\n\\(p\\) è la probabilità di successo in ogni prova,\n\n\\(\\binom{k+r-1}{k}\\) è il coefficiente binomiale che rappresenta il numero di modi possibili in cui \\(k\\) fallimenti e \\(r\\) successi possono essere ordinati.\n\nNel nostro caso specifico:\n\n\n\\(r = 5\\) (successi desiderati),\n\n\\(p = 0.5\\) (probabilità di indovinare correttamente sotto l’ipotesi nulla),\n\n\\(k\\) varia da 0 a 1 (possibili fallimenti prima del quinto successo).\n\nIl valore-p si calcola sommando le probabilità per tutti i casi “più estremi” di quello osservato:\n\\[\n\\text{valore-p} = \\sum_{k=0}^{1} \\binom{k+5-1}{k} (0.5)^5 (0.5)^k.\n\\]\nImplementazione:\n\n# Parameters\nn_binomial &lt;- 6  # Number of fixed trials for the binomial distribution\nn_success &lt;- 5  # Desired number of successes\np &lt;- 0.5  # Probability of success (guessing the tea cup)\n\n# Calculate the p-value for the negative binomial distribution\np_value_geom_corrected &lt;- 0\nfor (k in 0:(n_binomial - n_success - 1)) {  # Number of failures before the 5th success\n  p_value_geom_corrected &lt;- p_value_geom_corrected + \n    choose(k + n_success - 1, k) * ((1 - p)^k) * (p^n_success)\n}\n\np_value_geom_corrected\n#&gt; [1] 0.03125\n\nIn conclusione,\n\nper la distribuzione binomiale, il p-value è \\(0.109\\), che non è statisticamente significativo (dato che è maggiore di 0.05); quindi, secondo Fisher, in questo caso non dovremmo rigettare l’ipotesi nulla che Dr. Bristol stia indovinando.\nper la distribuzione geometrica negativa, il p-value è \\(0.031\\), che è statisticamente significativo (dato che è minore di 0.05); in questo caso, dovremmo rigettare l’ipotesi nulla, suggerendo che Dr. Bristol non sta semplicemente indovinando.\n\nLa presente discussione mostra che, in base alla procedura del test dell’ipotesi nulla, la stessa sequenza di eventi (5 successi su 6 tentativi) può portare a conclusioni opposte a seconda delle ipotesi sul processo di campionamento. Questo paradosso è uno dei motivi (per ulteriori critiche, si veda Wasserstein & Lazar (2016); Benjamin et al. (2018)) per cui l’inferenza bayesiana è diventata più popolare negli ultimi anni come quadro alternativo per il test delle ipotesi e la stima dei parametri.\n\n80.16.3 Approccio Bayesiano\nNel loro lavoro, Etz et al. (2018) propongono un’alternativa bayesiana per risolvere il problema esaminato da Fisher. Questa soluzione bayesiana evita le contraddizioni che emergono quando si cercano di definire “risultati più estremi” che non sono stati osservati. L’approccio bayesiano si focalizza esclusivamente sui dati effettivamente raccolti e utilizza queste osservazioni per aggiornare le probabilità iniziali (o “a priori”) associate a diverse ipotesi. Il processo si basa sulla regola di Bayes e si sviluppa in tre fasi principali:\n\nStabilire Probabilità a Priori: Iniziamo assegnando una distribuzione di probabilità a priori a tutti i possibili tassi di successo che la Dr. Bristol potrebbe avere. Questo include una probabilità specifica per l’ipotesi nulla, che suggerisce che la Dr. Bristol stia semplicemente indovinando (con un tasso di successo del 50%).\nAggiornare le Probabilità con Dati Osservati: Utilizziamo i dati raccolti nell’esperimento per aggiornare le nostre probabilità a priori. Questo aggiornamento è fatto utilizzando la regola di Bayes.\nCalcolare il Fattore di Bayes: Questa metrica ci dice quanto i dati osservati influenzano le probabilità delle diverse ipotesi. Un Fattore di Bayes molto maggiore di 1 indicherebbe un forte supporto per l’ipotesi alternativa rispetto all’ipotesi nulla.\n\nNel caso specifico, il Fattore di Bayes calcolato è risultato essere circa 147.33, un valore notevolmente alto. Questo suggerisce che i dati osservati sono molto più compatibili con l’ipotesi che la Dr.ssa Bristol possa effettivamente distinguere tra le diverse preparazioni del tè, piuttosto che con l’ipotesi che stia indovinando.\nEtz et al. (2018) concludono che l’approccio bayesiano offre un quadro più robusto e coerente per il test delle ipotesi. A differenza del metodo frequentista, esso non dipende dalla definizione di “risultati più estremi” non osservati e si concentra invece esclusivamente sui dati effettivamente raccolti. Questa focalizzazione, in generale, rende l’approccio bayesiano una soluzione più solida per valutare le ipotesi scientifiche. Per una rivisitazione bayesiana dell’esperimento “The Lady Tasting Tea”, si veda anche la discussione di Doorn et al. (2020).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#malintesi-sul-valore-p",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#malintesi-sul-valore-p",
    "title": "\n80  Significatività statistica\n",
    "section": "\n80.17 Malintesi sul valore-p",
    "text": "80.17 Malintesi sul valore-p\nSono diffusi molti malintesi sul valore-p. Ne esaminiamo qui quelli più comuni.\nMalinteso 1: Un valore p non significativo significa che l’ipotesi nulla è vera.\nIl malinteso che un valore p non significativo (p &gt; 0.05) implichi l’assenza di effetto o la verità dell’ipotesi nulla è diffuso e porta a conclusioni errate. La chiave per evitare questo errore sta nel comprendere che i valori p riflettono la probabilità dei dati osservati sotto l’ipotesi nulla, e non la probabilità dell’ipotesi stessa. Un valore p elevato non dimostra che l’ipotesi nulla sia vera, ma indica semplicemente che i dati osservati non sono sufficientemente insoliti da rifiutare l’ipotesi nulla con un livello di confidenza predefinito.\nRisultati non significativi possono verificarsi anche quando esiste un effetto reale, ma i dati non sono abbastanza estremi da superare la soglia di significatività statistica.\nInvece di concludere affrettatamente l’assenza di effetto da un valore p non significativo, dovremmo riconoscere l’ambiguità e considerare altre possibilità. Dichiarazioni come “non c’era differenza” dovrebbero essere riformulate in termini di assenza di differenza statisticamente significativa, lasciando aperta la questione dell’esistenza di un effetto reale.\nL’approccio bayesiano offre una prospettiva diversa che può essere particolarmente utile per interpretare risultati non significativi. A differenza dei valori p, che si limitano a valutare la probabilità dei dati sotto l’ipotesi nulla, l’inferenza bayesiana permette di calcolare direttamente la probabilità delle ipotesi date i dati.\nL’approccio bayesiano, quindi, non si limita a rifiutare o non rifiutare l’ipotesi nulla, ma quantifica la forza dell’evidenza a favore di un’ipotesi rispetto all’altra, fornendo una conclusione più informativa rispetto al semplice “non posso rifiutare l’ipotesi nulla”.\nMalintesto 2: Un valore p significativo significa che l’ipotesi nulla è falsa.\nCome spiegato in precedenza, il valore-p quantifica la “sorpresa” suscitata dai dati, alla luce dell’ipotesi nulla. Non ci dice niente sull’ipotesi che abbiamo assunto per quantificare la “sorpresa”.\nMalinteso 3: Un valore p significativo significa che è stato scoperto un effetto importante.\nLa distinzione tra “significatività statistica” e “rilevanza pratica” è fondamentale: mentre la prima indica semplicemente che un risultato è improbabile sotto l’ipotesi nulla, la seconda valuta l’effetto nel contesto di applicazioni reali e le sue implicazioni.\nUn effetto statisticamente significativo non garantisce che l’effetto abbia un impatto pratico notevole o utile.\nInoltre, al di là della significatività pratica, l’abitudine di molti psicologi di escludere i predittori che non risultano “statisticamente significativi” è un grossolano errore: la significatività statistica non può essere usata come un metodo per la selezione di variabili in un modello statistico.\nUn p &lt; 0.05 indica che, se l’ipotesi nulla è vera, abbiamo osservato dati che dovrebbero essere considerati sorprendenti. Tuttavia, solo perché i dati sono sorprendenti, non significa che dobbiamo preoccuparcene. È principalmente l’etichetta verbale “significativo” che causa confusione qui: in un contesto frequentista, un effetto “significativo” è un effetto “sorprendente” alla luce di \\(H_0\\), non è necessariamente un effetto “importante”.\nMalinteso 4: Se avete osservato un risultato significativo, la probabilità che abbiate commesso un errore di Tipo 1 (un falso positivo) è del 5%.\nIl malinteso che la presenza di un risultato significativo (per esempio, p &lt; 0.05) indichi una probabilità del 5% di aver commesso un errore di Tipo 1 (falso positivo) riflette una comprensione errata della statistica frequentista. La probabilità del 5% si riferisce al tasso di errore di Tipo 1, che è la proporzione di volte che potremmo aspettarci di rifiutare erroneamente l’ipotesi nulla se questa fosse vera, su molteplici ripetizioni dell’esperimento sotto le stesse condizioni. In altre parole, se potessimo ripetere lo stesso studio infinite volte, osserveremmo risultati falsamente positivi nel 5% di questi studi, assumendo che l’ipotesi nulla sia effettivamente vera in ogni caso.\nTuttavia, una volta che abbiamo raccolto i dati e ottenuto un risultato significativo in un unico studio, non possiamo dire che “la probabilità che questo particolare risultato sia un errore di Tipo 1 è del 5%”. In realtà, in quel momento specifico, l’evento (commettere un errore di Tipo 1) è già accaduto o non è accaduto; la probabilità associata a quel singolo risultato non è più applicabile nel modo in cui potremmo aspettarci intuitivamente. Il risultato è, per così dire, una realtà fissa: o abbiamo rilevato un effetto che in realtà non esiste (errore di Tipo 1), oppure abbiamo correttamente identificato un effetto reale. Senza ulteriori esperimenti o dati, non possiamo determinare con certezza in quale di queste categorie cade il nostro risultato.\nIn breve, il tasso del 5% di errore di Tipo 1 non si applica retroattivamente a un singolo risultato ottenuto, ma piuttosto descrive il comportamento a lungo termine di un test statistico sotto ripetute campionature. Questa distinzione è cruciale per una corretta interpretazione dei risultati degli esperimenti e sottolinea l’importanza di non sovrastimare la certezza di un singolo risultato statistico significativo.\nMalinteso 5: Uno meno il valore p è la probabilità che l’effetto si replichi quando ripetuto.\nIl concetto che 1 meno il valore p rappresenti la probabilità di replicazione di un effetto è un malinteso diffuso. In realtà, la probabilità di replicazione di un effetto non può essere direttamente calcolata dal valore p di un singolo studio a causa della complessità dei fattori coinvolti, tra cui la vera differenza media tra i gruppi. La potenza statistica di un test, che dipende dalla dimensione dell’effetto, dalla dimensione del campione e dal livello di significatività α, fornisce una stima della probabilità di rilevare un effetto significativo se questo effetto esiste davvero. Tuttavia, osservare un effetto significativo in un unico studio (ad esempio, p = 0.03) non significa che vi sia una probabilità del 97% che tale effetto si replichi in studi futuri. La possibilità di replicare un risultato dipende dalla presenza di un vero effetto e dalla potenza statistica del test originale.\nIn sintesi, la replicabilità di un effetto è influenzata da molti fattori e non può essere inferita semplicemente dal valore p di un singolo risultato. La comprensione e l’interpretazione corrette della replicabilità richiedono un’analisi dettagliata della potenza statistica e della dimensione dell’effetto, oltre che della consistenza dei risultati attraverso studi multipli.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#riflessioni-conclusive",
    "title": "\n80  Significatività statistica\n",
    "section": "\n80.18 Riflessioni Conclusive",
    "text": "80.18 Riflessioni Conclusive\nIl presente capitolo ha messo in evidenza le numerose limitazioni e i potenziali pericoli dell’approccio frequentista al test dell’ipotesi nulla, portando alla luce una serie di paradossi e malintesi che minano la sua validità come strumento primario per l’inferenza scientifica. In particolare, abbiamo visto come il valore-p, spesso utilizzato come metro di giudizio assoluto per decidere se un risultato è significativo o meno, possa condurre a conclusioni fuorvianti, dipendendo non solo dai dati osservati ma anche dal contesto sperimentale e dalle scelte soggettive del ricercatore. Questo approccio, che si basa su una logica binaria di “accettare” o “rifiutare” l’ipotesi nulla, sembra incapace di cogliere la complessità delle relazioni causali e degli effetti reali presenti nei fenomeni psicologici e sociali. Più profondamente, emerge con chiarezza che il metodo frequentista, lungi dall’essere un sistema oggettivo per la decisione statistica, è invece intriso di convenzioni arbitrarie (come il livello di significatività α = 0.05) e di una visione riduzionistica della probabilità, concepita come frequenza relativa di eventi ripetibili nel tempo piuttosto che come misura della nostra incertezza riguardo a un evento specifico.\nTuttavia, al di là delle critiche tecniche, il problema più grave risiede nella tendenza a considerare il test dell’ipotesi nulla come uno strumento definitivo per valutare la veridicità di ipotesi scientifiche, anziché come un semplice punto di partenza per ulteriori indagini. La cultura prevalente nella comunità scientifica, che premia i risultati “statisticamente significativi”, ha contribuito a creare un ambiente in cui gli studi replicabili sono rari e dove molti risultati pubblicati sono fragili e difficilmente generalizzabili. È qui che l’approccio bayesiano entra in gioco, offrendo una soluzione coerente e robusta che supera molte delle carenze del frequentismo. Al contrario del metodo frequentista, che si concentra su ipotesi nulle arbitrariamente definite e sulle distribuzioni campionarie di statistiche teoriche, il bayesianesimo ci permette di incorporare informazioni pregresse (prior) e di aggiornare queste conoscenze in base ai dati osservati, fornendo una stima diretta della probabilità delle ipotesi di interesse. Questo approccio, che mette al centro la nozione di evidenza, permette di quantificare la forza delle prove a favore di diverse ipotesi, evitando così le dicotomie rigide tra “significativo” e “non significativo” e promuovendo una visione più sfumata e matematicamente fondata dell’inferenza statistica.\nIn conclusione, il test dell’ipotesi nulla frequentista, pur essendo ampiamente utilizzato, rappresenta uno degli aspetti più controversi e problematici dell’approccio tradizionale. La sua rigidità metodologica e la dipendenza da concetti come il valore p e la significatività statistica lo rendono non solo impreciso, ma anche inadeguato a cogliere la complessità dei fenomeni che la ricerca psicologica si propone di esplorare. Abbandonare questo paradigma non è solo una questione di precisione tecnica, ma di superare una mentalità riduzionista che limita la nostra capacità di interpretare i dati in modo sfumato e contestuale.\nL’adozione di metodologie bayesiane, al contrario, offre un quadro più dinamico e flessibile, in cui le ipotesi non sono semplicemente accettate o rifiutate, ma valutate in termini probabilistici. Questo approccio incoraggia un confronto diretto tra modelli e ipotesi contrapposte, permettendo di aggiornare le nostre credenze alla luce dei nuovi dati. Non si tratta solo di un miglioramento tecnico nelle inferenze scientifiche, ma di un invito a ripensare il modo in cui concepiamo la conoscenza e il processo di scoperta. La prospettiva bayesiana, infatti, enfatizza l’incertezza come parte intrinseca della ricerca, trasformandola in uno strumento per affinare le nostre comprensioni piuttosto che un ostacolo da superare.\nIn un contesto psicologico intrinsecamente complesso e caratterizzato da incertezza, l’approccio bayesiano rappresenta un’opportunità per adottare un’epistemologia più flessibile e razionale. La sua forza risiede nella capacità di adattarsi alla natura multifattoriale dei fenomeni psicologici, integrando in modo coerente e trasparente sia le conoscenze pregresse sia le nuove evidenze. In questo senso, l’adozione del paradigma bayesiano non è soltanto un avanzamento metodologico, ma anche un passo verso una scienza più consapevole, critica e adatta alle sfide della psicologia contemporanea.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#esercizi",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#esercizi",
    "title": "\n80  Significatività statistica\n",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\n\nL’Idea di Base del Test di Ipotesi\n\nSpiega il principio generale del test di ipotesi nulla in ambito frequentista. In che modo la logica dell’“assumere come vera l’ipotesi nulla fino a prova contraria” è paragonabile al concetto di “presunzione di innocenza” in un processo penale? Quali vantaggi e svantaggi comporta questa impostazione?\n\nIpotesi di Ricerca vs. Ipotesi Statistica\n\nSpiega in che modo l’ipotesi di ricerca (ad esempio, “esiste un effetto della musica sul comportamento dei bambini”) differisce dall’ipotesi statistica che si testa formalmente (ad esempio, “la media di un indice di preferenza è maggiore di 0.5”). Perché spesso la ricerca psicologica non può testare direttamente l’ipotesi di ricerca?\n\nSignificatività Statistica e Rilevanza Pratica\n\nChe differenza c’è tra “risultato statisticamente significativo” e “risultato rilevante (o importante) dal punto di vista pratico o teorico”? Porta un esempio in cui un test frequenzista possa dare un valore-\\(p\\) molto basso senza che l’effetto sia considerato rilevante nel contesto.\n\nMalinteso: Un Risultato non Significativo Implica Che \\(H_0\\) Sia Vera?\n\nPerché è errato concludere che l’ipotesi nulla sia vera quando il test non risulta significativo (cioè quando \\(p \\ge 0.05\\))? Quali altre spiegazioni potrebbero esserci se un esperimento produce un valore-\\(p\\) alto?\n\nIl Ruolo della Variabilità Campionaria\n\nIn che modo la variabilità campionaria (cioè il fatto che stime come la media campionaria varino da campione a campione) influisce sulla necessità di un test di ipotesi? Perché non è sufficiente confrontare la media osservata con il valore ipotizzato per concludere se \\(H_0\\) è falsa?\n\nErrori di I e II Tipo e Potenza del Test\n\nDescrivi i concetti di errore di I tipo (falso positivo) e errore di II tipo (falso negativo). Perché i test sono progettati primariamente per controllare l’errore di I tipo? Che cos’è la potenza (\\(1-\\beta\\)) di un test?\n\nIl Valore-\\(p\\): Che Cosa (non) Indica?\n\nSpiega la definizione di valore-\\(p\\) secondo l’approccio frequentista. Quali sono due malintesi comuni su ciò che il valore-\\(p\\) non rappresenta?\n\nCritica: Dipendenza dai “Risultati più Estremi Non Osservati”\n\nNell’esempio dell’episodio “The Lady Tasting Tea”, come mai il test di ipotesi frequentista può portare a conclusioni diverse pur avendo gli stessi dati osservati, a seconda di come è definito il “processo di campionamento”? Perché questa è una limitazione?\n\nControllo dell’Errore di I Tipo, ma Non dell’Errore di II Tipo\n\nPerché nel test di ipotesi frequentista esiste un’asimmetria per cui si controlla rigorosamente l’errore di I tipo (fissando \\(\\alpha\\)), ma non esiste un analogo vincolo obbligatorio sull’errore di II tipo (\\(\\beta\\))? Quali conseguenze pratiche ne derivano per la pianificazione di uno studio?\n\nLimiti dell’Approccio Frequentista e Alternative\n\nRiassumi in che senso il test di ipotesi nulla frequentista è ritenuto da alcuni ricercatori insufficiente o fuorviante (es. “dichotomania” del significato, p-value dipendente dal disegno, ecc.). Quali alternative o integrazioni sono state proposte in letteratura per superare questi limiti?\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\n\nL’Idea di Base del Test di Ipotesi\n\n\nL’ipotesi nulla (\\(H_0\\)) è considerata “innocente” fino a che l’evidenza non la “condanna”.\n\nIl test statistico stabilisce la probabilità di osservare dati così (o più) estremi assumendo che \\(H_0\\) sia vera.\n\nVantaggio: stabilire un controllo sul rischio di un falso positivo (errore di I tipo).\n\nSvantaggio: non si dimostra direttamente l’ipotesi di ricerca (\\(H_1\\)), ma si prova a “falsificare” \\(H_0\\).\n\n\nIpotesi di Ricerca vs. Ipotesi Statistica\n\n\nL’ipotesi statistica è una versione quantificabile (e falsificabile) dell’ipotesi di ricerca.\n\nLe ipotesi di ricerca in psicologia sono spesso complesse (costrutti non sempre direttamente misurabili).\n\nI ricercatori formulano un modello statistico semplificato per rendere l’ipotesi testabile.\n\n\nSignificatività Statistica e Rilevanza Pratica\n\n\n“Significativo” in senso frequentista significa “dati improbabili se \\(H_0\\) è vera”.\n\nNon implica necessariamente un effetto ampio o di importanza pratica.\n\nCon campioni molto grandi, si possono rilevare anche differenze piccolissime, magari prive di valore applicativo.\n\n\nMalinteso: Un Risultato non Significativo Implica Che \\(H_0\\) Sia Vera?\n\n\nUn valore-\\(p\\) “alto” segnala che i dati non forniscono sufficiente evidenza per rifiutare \\(H_0\\), non che \\(H_0\\) è vera.\n\nPossibile mancanza di potenza statistica (campione troppo piccolo) o presenza di effetti molto ridotti.\n\nL’approccio frequentista non quantifica la probabilità che \\(H_0\\) sia vera, ma la probabilità di osservare certi dati assumendo che \\(H_0\\) lo sia.\n\n\nIl Ruolo della Variabilità Campionaria\n\n\nAnche se la media campionaria si discosta da \\(H_0\\), potremmo aver ottenuto quella differenza per puro caso.\n\nOccorre stabilire quanto discostamento sia “raro” secondo la distribuzione campionaria ipotizzata da \\(H_0\\).\n\nIl test calcola quante volte, nel lungo periodo, si osservano dati così estremi casualmente.\n\n\nErrori di I e II Tipo e Potenza del Test\n\n\nErrore di I tipo: rigettare \\(H_0\\) quando è vera.\n\nErrore di II tipo: non rigettare \\(H_0\\) quando è falsa.\n\nIl test frequenzista fissa una soglia \\(\\alpha\\) (livello di significatività) per controllare l’errore di I tipo.\n\nLa potenza quantifica la probabilità di individuare realmente un effetto quando esso esiste.\n\n\nIl Valore-\\(p\\): Che Cosa (non) Indica?\n\n\nIl valore-\\(p\\) è la probabilità di ottenere un risultato almeno così estremo se \\(H_0\\) è vera.\n\nMalinteso 1: pensare che indichi la probabilità che \\(H_0\\) sia vera o falsa.\n\nMalinteso 2: confondere “\\(p &lt; 0.05\\) =&gt; probabilità 95% che l’effetto sia vero” (non è così!).\n\n\nCritica: Dipendenza dai “Risultati più Estremi Non Osservati”\n\n\nIl valore-\\(p\\) frequenzista include la probabilità di osservare anche “risultati più estremi” non avvenuti nell’esperimento.\n\nSe l’esperimento era “fissare a priori 6 tazze” vs. “continuare finché non ottiene 5 successi”, può cambiare la distribuzione usata (binomiale vs. geometrica negativa).\n\nQuesto mostra che il valore-\\(p\\) dipende dal contesto sperimentale, non solo dai dati effettivi.\n\n\nControllo dell’Errore di I Tipo, ma Non dell’Errore di II Tipo\n\n\nSi vuole evitare di “condannare” un’ipotesi nulla “innocente”.\n\nL’errore di II tipo spesso viene trascurato e può essere molto alto se il campione è piccolo.\n\nConseguenze: molti studi hanno potenza insufficiente; i “falsi negativi” rimangono frequenti.\n\n\nLimiti dell’Approccio Frequentista e Alternative\n\n\nCritiche: inflazione di falsi positivi, dipendenza arbitraria da \\(\\alpha=0.05\\), scarsa attenzione alla dimensione dell’effetto, interpretazioni errate del p-value.\n\nAlternative:\n\n\nApproccio bayesiano (fattori di Bayes, posteriori, credibilità).\n\n\nConfidence intervals ampliati da riflessioni su potenza e dimensione dell’effetto.\n\n\nMisure dell’effetto e analisi approfondite invece di un giudizio binario su “p&lt;0.05”.\n\n\n\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nEsercizi “A Mano”\nQuesti esercizi si possono affrontare con le formule del test di ipotesi (z-test o t-test per la media, test di proporzioni, ecc.), senza ricorrere a software.\nEsercizio 1: One-sample t-test sulla SWLS\n\n\nHai un piccolo campione di \\(n=9\\) studenti, con punteggi SWLS (ipotetici) riportati di seguito:\n\\[\n21, \\ 18, \\ 26, \\ 20, \\ 23, \\ 16, \\ 22, \\ 19, \\ 25\n\\]\n\nSupponi che, in letteratura, la media teorica su popolazioni simili sia di circa \\(\\mu_0 = 20\\).\nIpotesi nulla \\((H_0)\\): la media del campione non differisce da 20 (cioè \\(\\mu = 20\\)).Ipotesi alternativa \\((H_1)\\): la media del campione differisce da 20 (two-sided test).\n\nRichiesta:\n\nCalcola la media campionaria \\(\\bar{X}\\) e la deviazione standard campionaria \\(s\\).\n\nEsegui un t-test a mano (con formula \\(t = \\frac{\\bar{X} - \\mu_0}{s/\\sqrt{n}}\\)).\n\nStabilisci se, con \\(\\alpha=0.05\\) (test a due code), si rifiuta o meno \\(H_0\\).\n\n\nSuggerimento: Usa la tabella della distribuzione t (o ricorri a tavole semplificate) per trovare il valore critico a \\(df = n-1 = 8\\). Solo per questo step, usa R.\n\nEsercizio 22: One-sample t-test sulla LSNS-6\n\n\nHai un campione di \\(n=8\\) persone anziane, con punteggi LSNS-6 (Scala della Rete Sociale di Lubben) ipotetici (in realtà userai i dati raccolti):\n\\[\n10,\\ 14,\\ 8,\\ 13,\\ 12,\\ 7,\\ 15,\\ 9\n\\]\n\nIn letteratura si suppone che un punteggio medio su popolazioni simili sia \\(\\mu_0 = 12\\).\nIpotesi nulla: \\(\\mu = 12\\).Ipotesi alternativa: \\(\\mu \\neq 12\\).\n\nRichiesta:\n\nCalcola media e deviazione standard.\n\nCalcola la statistica \\(t\\) e confrontala con il valore critico per \\(\\alpha=0.05\\), two-sided, con \\(df = 7\\).\n\nConcludi se rifiuti l’ipotesi nulla o meno.\n\n\n\nEsercizio 3: Due campioni indipendenti (SWLS)\n\n\nConsidera i dati raccolti dal tuo gruppo e quelli di un altro gruppo TPV (es., Gruppo A = 6 persone, Gruppo B = 5 persone) che hanno compilato la SWLS. Riporta per ipotesi i seguenti punteggi medi e DS (usa i dati reali):\n\nGruppo A: \\(\\bar{X}_A = 24,\\ s_A=4,\\ n_A=6\\)\n\nGruppo B: \\(\\bar{X}_B = 19,\\ s_B=3,\\ n_B=5\\)\n\n\n\nVuoi testare se le due medie differiscono in modo significativo (\\(\\alpha=0.05\\), due code).\nIpotesi nulla: \\(\\mu_A = \\mu_B\\).Ipotesi alternativa: \\(\\mu_A \\neq \\mu_B\\).\n\nRichiesta:\n\nCalcola la statistica \\(t\\) di un two-sample t-test (varianze incognite, assunte uguali).\n\nUsa la formula con la “varianza pooled”.\n\nCalcola i \\(df\\) approssimati come \\(n_A + n_B - 2\\).\n\nConcludi se rifiuti \\(H_0\\).\n\n\n\nEsercizio 4: Test su una proporzione (SWLS recodificata)\n\nA volte si trasforma la SWLS in una variabile binaria es. “\\(\\mathrm{SWLS} \\ge 24\\) = soddisfatto, \\(\\mathrm{SWLS}&lt;24\\) = non soddisfatto”.\nConsidera i dati raccolti e i corrispondenti risultati binari (Sì/No) siano 4 “soddisfatti” e 6 “non soddisfatti”.\nIpotesi nulla: la proporzione di “soddisfatti” è \\(p_0 = 0.50\\) (ipotizzi che metà dei partecipanti sia soddisfatta).Ipotesi alternativa: la proporzione \\(\\neq 0.50\\).\nCalcola la statistica \\(Z\\) per una proporzione (usando la formula della normal approx. se \\(\\hat{p}=4/10\\)).\nConfronta \\(|Z|\\) con il valore critico a \\(\\alpha=0.05\\) (due code), \\(z_{0.025}\\approx 1.96\\). Concludi.\n\nEsercizio 5: Confronto fra due proporzioni (LSNS-6 recodificata)\n\nConsiderai dati di due gruppi TPV (Gruppo A, Gruppo B).\n\nSupponi che, per Gruppo A (\\(n_A=8\\)), 3 persone abbiano un punteggio \\(\\ge 12\\) (considerato “buon supporto”). Per Gruppo B (\\(n_B=10\\)), 7 persone siano \\(\\ge 12\\) – usa i dati reali.\n\nIpotesi nulla: \\(\\,p_A = p_B\\).Ipotesi alternativa: \\(\\,p_A \\neq p_B\\).\n\nCalcola \\(\\hat{p}_A = 3/8\\) e \\(\\hat{p}_B = 7/10\\).\n\nFai il test per il confronto di due proporzioni (con la formula per la “pooled proportion”). Decidi se c’è differenza significativa al 5%.\n\nEsercizi “Con R”\nOra proponiamo 5 esercizi da svolgere con il software R. Naturalmente, dovrete caricare il vostro dataset reale (ad esempio in formato CSV o XLS) e adattare i comandi di R.\nEsercizio 1: Calcolo e t-test di una sola media per la SWLS\n\n\nCaricate in R i vostri dati SWLS in un vettore, es.:\nswls_data &lt;- c(...)  # I vostri punteggi\n\n\nStampate la media e la deviazione standard:\nmean(swls_data)\nsd(swls_data)\n\nTest se la media differisce da 24, usando t.test(swls_data, mu = 24).\nOsservate il p-value e concludete se rifiutate \\(H_0\\): \\(\\mu=24\\) vs \\(H_1\\): \\(\\mu \\neq 24\\).\n\nEsercizio 2: Calcolo e t-test di una sola media per la LSNS-6\n\n\nFate lo stesso per la LSNS:\nlsns_data &lt;- c(...)  # I vostri punteggi\n\nCalcolate mean(lsns_data), sd(lsns_data).\nEseguite un test con t.test(lsns_data, mu = X) dove \\(X\\) è un valore teorico (ad es. 12 o 10, a seconda delle informazioni di letteratura).\nInterpretate l’output, guardando estimate, conf.int, p-value.\n\nEsercizio 3: Confronto di due medie (SWLS) con due gruppi\n\n\nConsiderate i dati di due gruppi TPV. Avete due vettori in R:\ngroupA &lt;- c(...)  # SWLS di chi appartiene al gruppo A\ngroupB &lt;- c(...)  # SWLS di chi appartiene al gruppo B\n\nCalcolate mean(groupA), mean(groupB).\n\nEseguite:\nt.test(groupA, groupB, var.equal = FALSE)  # Welch Two Sample t-test\n\nConfrontate la differenza delle medie riportata con l’intervallo di confidenza. Il p-value indica se la differenza è significativa (ipotesi nulla: medie uguali).\n\nEsercizio 4: Test su una proporzione (ricodifica SWLS)\n\n\nRicodificate i vostri punteggi SWLS in “1 = soddisfatto” / “0 = non soddisfatto”. Ad esempio:\nsatisfied &lt;- ifelse(swls_data &gt;= 24, 1, 0)\n\n\nContate la proporzione di “1”:\nmean(satisfied)\n\nEffettuate il test con prop.test(sum(satisfied), length(satisfied), p = 0.5) (se ipotizzate \\(p_0=0.5\\)).\nGuardate l’output e interpretate: l’intervallo di confidenza e il p-value.\n\nEsercizio 5: Confronto di due proporzioni (ricodifica LSNS)\n\n\nFate una ricodifica binaria sul vostro vettore LSNS, ad esempio “1 se \\(\\ge12\\), 0 se &lt;12”:\ngood_support &lt;- ifelse(lsns_data &gt;= 12, 1, 0)\n\n\nSeparate i partecipanti in due gruppi (ad esempio, un gruppo “A” e un gruppo “B”):\ngroupA_inds &lt;- (some condition)  # righe che corrispondono a Gruppo A\ngroupB_inds &lt;- (some other condition)\n\nCalcolate sum(good_support[groupA_inds]), length(groupA_inds) e idem per groupB.\nUsate prop.test(x = c(...), n = c(...)) per confrontare le due proporzioni.\nConcludete: se p-value &lt; 0.05, potete rifiutare \\(H_0\\) (le due proporzioni sono uguali).\n\n\n\n\n\n\n\n\n\n\nProblemi 3\n\n\n\n\n\nEsercizio 1 – P-value e Interpretazione Probabilistica\nSpiega perché il valore-\\(p\\) del test di ipotesi nulla (frequentista) non può essere interpretato come “probabilità che l’ipotesi nulla sia vera” e in che modo l’approccio bayesiano fornisce invece una “probabilità a posteriori” sull’ipotesi. Descrivi due possibili conseguenze pratiche di questa differenza di interpretazione.\nEsercizio 2 – Ruolo dei “Risultati più Estremi Non Osservati”\nNel test frequentista, il valore-\\(p\\) si basa anche sulla probabilità di risultati più estremi di quelli effettivamente osservati, ma che non si sono verificati. Perché questo è considerato un limite (o un paradosso) e in che modo un’analisi bayesiana eviterebbe (o ridurrebbe) questo problema?\nEsercizio 3 – Dipendenza dal Disegno Sperimentale e Optional Stopping\nNel test di ipotesi frequenzista, il valore-\\(p\\) può cambiare se il ricercatore modifica il piano di raccolta dati (ad es. fermare la raccolta quando si ottiene un certo risultato). Perché si parla di “problema dell’optional stopping”? Come gestisce invece l’approccio bayesiano la decisione di proseguire o fermare un esperimento sulla base dei dati via via raccolti?\nEsercizio 4 – Significatività Statistica vs. Dimensione dell’Effetto\nUno dei limiti dell’approccio frequentista è la confusione tra “significatività statistica” (p&lt;0.05) e “importanza/ampiezza dell’effetto”. Spiega in che modo l’approccio bayesiano può incorporare in modo più diretto la dimensione dell’effetto e l’incertezza a riguardo (tramite le “distribuzioni a posteriori” o “intervalli di credibilità”).\nEsercizio 5 – Problemi di Replicabilità: Come Confrontare Modelli?\nSi osserva spesso che i risultati frequentisti (p&lt;0.05) non si replicano bene in studi successivi. Descrivi come un’analisi bayesiana (con i “fattori di Bayes” o i “posterior odds”) possa dare un quadro più flessibile per confrontare ipotesi alternative, riducendo il rischio di eccessive conclusioni basate su un singolo p-value.\n\n\n\n\n\n\n\n\n\nSoluzioni 3\n\n\n\n\n\nSoluzione 1 – P-value e Probabilità dell’Ipotesi\n\n\nPunto chiave: Il valore-\\(p\\) è la probabilità di ottenere dati “uguali o più estremi” dando per vera l’ipotesi nulla. Invece, “probabilità che \\(H_0\\) sia vera” sarebbe un concetto diverso: è la probabilità dell’ipotesi data i dati osservati (interpretazione inversa).\n\n\nConseguenze pratiche:\n\nUn p-value “basso” non dice “quanto è probabile che \\(H_0\\) sia falsa”, ma solo che quei dati sarebbero rari sotto \\(H_0\\).\n\nI ricercatori spesso sovrastimano la “conferma” contro \\(H_0\\) o interpretano male un p&gt;0.05 come “ipotesi nulla vera”.\n\n\n\n\nApproccio bayesiano: Consente di calcolare una posterior probability di \\(H_0\\) (o di \\(H_1\\)) grazie alla regola di Bayes, purché si disponga di una prior e di un modello.\n\nSoluzione 2 – Risultati più Estremi Non Osservati\n\n\nProblema: Nel frequentismo, il valore-\\(p\\) integra la probabilità di dati che non si sono verificati (“what if scenario”). Ciò porta a dipendere da un insieme di risultati ipotetici e a potenziali paradossi (e.g. “Lady Tasting Tea”).\n\n\nLimite: Può capitare che stessi dati osservati, ma piani di raccolta diversi, generino p-value diversi.\n\n\nBayesian: Calcola la verosimiglianza solo sui dati effettivi e aggiorna la prior → “focus su ciò che è effettivamente avvenuto”. Non serve considerare a posteriori “risultati più estremi” che non si sono verificati, se non in misura minima (attraverso l’integrazione sulle possibili distribuzioni posteriori, ma con un meccanismo diverso dal p-value).\n\nSoluzione 3 – Optional Stopping e Disegno Sperimentale\n\n\nOptional Stopping: In un test frequentista, se continuiamo ad analizzare i dati e fermiamo la raccolta non appena otteniamo p&lt;0.05, si gonfia il rischio di errore di I tipo.\n\n\nLimite: Il p-value frequentista dipende dall’idea di un “protocollo fisso” a priori. Se si viola questo piano (aggiungendo dati finché non si ottiene “significatività”), il test non è più valido.\n\n\nBayesiano: L’approccio consente un monitoraggio sequenziale (monitoring) dei dati: si aggiorna la distribuzione a posteriori man mano che arrivano nuove osservazioni, e fermarsi quando la posterior probability (o il fattore di Bayes) supera (o non supera) una certa soglia. Questo non invalida formalmente l’inferenza perché si sta accumulando evidenza in modo coerente con Bayes.\n\nSoluzione 4 – Ampiezza dell’Effetto e Intervalli di Credibilità\n\n\nFrequenza: Un p-value significativo non dice quanto è grande l’effetto, solo che non si spiega “facilmente” con \\(H_0=0\\).\n\n\nLimite: Spesso si confonde “p&lt;0.05” con “effetto grande/impact significativo”: in realtà, la dimensione potrebbe essere piccola.\n\n\nBayesiano: Offre una distribuzione a posteriori sull’effetto (\\(\\theta\\)), da cui si può ricavare un intervallo di credibilità (dove, ad esempio, c’è il 95% di probabilità che \\(\\theta\\) si trovi in quell’intervallo). Consente di valutare se l’effetto è davvero grande o molto stretto attorno allo 0.\n\nSoluzione 5 – Replicabilità e Confronto di Ipotesi\n\n\nProblema di replicabilità: Molti studi con p&lt;0.05 non vengono replicati (forse per effetti piccoli, scarsa potenza, pubblicazione selettiva, etc.).\n\n\nLimite: Un singolo p-value non dà informazioni su “quanto credere a \\(H_1\\) rispetto a \\(H_0\\)” e non aiuta a cumulare evidenze in analisi meta-analitiche in modo flessibile.\n\n\nBayesiano: Utilizza fattori di Bayes (Bayes Factor) o “posterior odds”, confrontando due modelli (es. \\(H_0\\) vs \\(H_1\\)). Se i dati futuri confermano una delle ipotesi, la posterior si rafforza. È un sistema più graduale e cumulativo di aggiornamento della credenza, riducendo la tendenza a “collezionare p&lt;0.05”.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#informazioni-sullambiente-di-sviluppo",
    "title": "\n80  Significatività statistica\n",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.17.0      thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0\n#&gt;  [5] see_0.11.0       gridExtra_2.3    patchwork_1.3.0  bayesplot_1.12.0\n#&gt;  [9] psych_2.5.3      scales_1.4.0     markdown_2.0     knitr_1.50      \n#&gt; [13] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [17] purrr_1.0.4      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [21] ggplot2_3.5.2    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6       shape_1.4.6.1      xfun_0.52         \n#&gt;  [4] htmlwidgets_1.6.4  lattice_0.22-7     tzdb_0.5.0        \n#&gt;  [7] Rdpack_2.6.4       vctrs_0.6.5        tools_4.5.0       \n#&gt; [10] generics_0.1.4     parallel_4.5.0     pan_1.9           \n#&gt; [13] pacman_0.5.1       jomo_2.7-6         pkgconfig_2.0.3   \n#&gt; [16] Matrix_1.7-3       RColorBrewer_1.1-3 lifecycle_1.0.4   \n#&gt; [19] compiler_4.5.0     farver_2.1.2       mnormt_2.1.1      \n#&gt; [22] codetools_0.2-20   htmltools_0.5.8.1  glmnet_4.1-8      \n#&gt; [25] nloptr_2.2.1       pillar_1.10.2      MASS_7.3-65       \n#&gt; [28] reformulas_0.4.1   iterators_1.0.14   rpart_4.1.24      \n#&gt; [31] boot_1.3-31        mitml_0.4-5        foreach_1.5.2     \n#&gt; [34] nlme_3.1-168       tidyselect_1.2.1   digest_0.6.37     \n#&gt; [37] stringi_1.8.7      splines_4.5.0      rprojroot_2.0.4   \n#&gt; [40] fastmap_1.2.0      grid_4.5.0         cli_3.6.5         \n#&gt; [43] magrittr_2.0.3     survival_3.8-3     broom_1.0.8       \n#&gt; [46] withr_3.0.2        backports_1.5.0    timechange_0.3.0  \n#&gt; [49] rmarkdown_2.29     nnet_7.3-20        lme4_1.1-37       \n#&gt; [52] hms_1.1.3          evaluate_1.0.3     rbibutils_2.3     \n#&gt; [55] rlang_1.1.6        Rcpp_1.0.14        glue_1.8.0        \n#&gt; [58] minqa_1.2.8        rstudioapi_0.17.1  jsonlite_2.0.0    \n#&gt; [61] R6_2.6.1",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#bibliografia",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#bibliografia",
    "title": "\n80  Significatività statistica\n",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBenjamin, D. J., Berger, J. O., Johannesson, M., Nosek, B. A., Wagenmakers, E.-J., Berk, R., Bollen, K. A., Brembs, B., Brown, L., Camerer, C., et al. (2018). Redefine statistical significance. Nature Human Behaviour, 2(1), 6–10.\n\n\nDoorn, J. van, Matzke, D., & Wagenmakers, E.-J. (2020). An in-class demonstration of Bayesian inference. Psychology Learning & Teaching, 19(1), 36–45.\n\n\nEtz, A., Gronau, Q. F., Dablander, F., Edelsbrunner, P. A., & Baribault, B. (2018). How to become a Bayesian in eight easy steps: An annotated reading list. Psychonomic bulletin & review, 25(1), 219–234.\n\n\nMehr, S. A., Song, L. A., & Spelke, E. S. (2016). For 5-month-old infants, melodies are social. Psychological Science, 27(4), 486–501.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:\n\n\nWasserstein, R. L., & Lazar, N. A. (2016). The ASA’s statement on p-values: context, process, and purpose. The American Statistician, 70(2), 129–133.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html",
    "title": "\n81  Test t di Student per campioni indipendenti\n",
    "section": "",
    "text": "81.1 Introduzione\nQuesto capitolo è dedicato al test t di Student per campioni indipendenti, uno dei test statistici più utilizzati nella pratica frequentista. Il test t di Student è un metodo che permette di confrontare le medie di due gruppi diversi (o “campioni”) e determinare se la differenza osservata tra le medie sia statisticamente significativa o se possa essere attribuita a semplice casualità.\nIl test è particolarmente utile quando si ha accesso solo a piccoli campioni provenienti da popolazioni sconosciute, ma è importante comprendere bene i suoi principi fondamentali e limiti prima di applicarlo.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#applicazioni-del-test-t-di-student",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#applicazioni-del-test-t-di-student",
    "title": "\n81  Test t di Student per campioni indipendenti\n",
    "section": "\n81.2 Applicazioni del Test t di Student",
    "text": "81.2 Applicazioni del Test t di Student\nIl test t di Student per campioni indipendenti serve per rispondere alla domanda: “Le medie di due gruppi sono significativamente diverse?” Per esempio, potremmo voler sapere se ci sono differenze significative nel peso medio tra uomini e donne.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#assunzioni-principali",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#assunzioni-principali",
    "title": "\n81  Test t di Student per campioni indipendenti\n",
    "section": "\n81.3 Assunzioni Principali",
    "text": "81.3 Assunzioni Principali\nPrima di procedere con il test, è essenziale assicurarsi che siano valide le seguenti ipotesi:\n\n\nIndipendenza: Le osservazioni nei due campioni devono essere indipendenti.\n\nNormalità: I dati nei due campioni provengono da popolazioni distribuite normalmente.\n\nUguaglianza delle Varianze (Omoschedasticità): Le varianze delle due popolazioni da cui provengono i campioni sono uguali.\n\nSe queste condizioni non sono soddisfatte, potrebbe essere necessario considerare alternative come il test di Welch, che non richiede l’uguaglianza delle varianze.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#passaggi-del-test-t-di-student",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#passaggi-del-test-t-di-student",
    "title": "\n81  Test t di Student per campioni indipendenti\n",
    "section": "\n81.4 Passaggi del Test t di Student",
    "text": "81.4 Passaggi del Test t di Student\nEcco una panoramica dei passaggi chiave:\n\n\nCalcolare la Differenza tra le Medie: Si calcola la differenza tra le medie dei due campioni.\n\\[\n\\bar{x}_1 - \\bar{x}_2\n\\]\ndove \\(\\bar{x}_1\\) e \\(\\bar{x}_2\\) sono le medie dei due campioni.\n\n\nStimare la Deviazione Standard Combinata: Se assumiamo che le varianze siano uguali (omoschedasticità), possiamo usare una stima combinata della deviazione standard, chiamata deviazione standard pooled \\(s_p\\):\n\\[\ns_p = \\sqrt{\\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}}\n\\]\ndove \\(n_1\\) e \\(n_2\\) sono le dimensioni dei campioni, e \\(s_1^2\\) e \\(s_2^2\\) sono le varianze campionarie.\n\n\nCalcolare la Statistica t: La statistica t viene calcolata usando la formula seguente:\n\\[\nt = \\frac{(\\bar{x}_1 - \\bar{x}_2)}{s_p \\sqrt{\\left(\\frac{1}{n_1} + \\frac{1}{n_2}\\right)}}\n\\]\n\n\nDeterminare i Gradi di Libertà: I gradi di libertà (\\(df\\)) sono calcolati come:\n\\[\ndf = n_1 + n_2 - 2\n\\]\n\nCalcolare il Valore-p: Infine, si confronta la statistica t con la distribuzione t di Student per ottenere il valore-p. Questo valore indica la probabilità di osservare una differenza così estrema tra le medie dei campioni, dato che l’ipotesi nulla è vera.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#dimostrazione",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#dimostrazione",
    "title": "\n81  Test t di Student per campioni indipendenti\n",
    "section": "\n81.5 Dimostrazione",
    "text": "81.5 Dimostrazione\nPer dimostrare come calcolare la varianza della differenza tra due medie campionarie, consideriamo due campioni casuali indipendenti \\(X_1, X_2, \\dots, X_n\\) e \\(Y_1, Y_2, \\dots, Y_m\\), estratti dalla stessa popolazione con media \\(\\mu\\) e varianza \\(\\sigma^2\\). Definiamo \\(\\bar{X}\\) e \\(\\bar{Y}\\) come le medie campionarie di questi due campioni, rispettivamente.\nLe medie campionarie \\(\\bar{X}\\) e \\(\\bar{Y}\\) sono date da:\n\\[\n\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i ,\n\\] \\[\n\\bar{Y} = \\frac{1}{m} \\sum_{j=1}^m Y_j .\n\\]\nEntrambe le medie campionarie \\(\\bar{X}\\) e \\(\\bar{Y}\\) sono stimatori non distorti della media della popolazione \\(\\mu\\). Le loro varianze sono:\n\\[\n\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n} ,\n\\] \\[\n\\text{Var}(\\bar{Y}) = \\frac{\\sigma^2}{m} .\n\\]\nSiamo interessati a calcolare la varianza della differenza \\(\\bar{X} - \\bar{Y}\\). Utilizzando le proprietà della varianza per combinazioni lineari di variabili aleatorie indipendenti, otteniamo:\n\\[\n\\text{Var}(\\bar{X} - \\bar{Y}) = \\text{Var}(\\bar{X}) + \\text{Var}(\\bar{Y}) ,\n\\]\ndato che i termini incrociati si annullano per l’indipendenza di \\(\\bar{X}\\) e \\(\\bar{Y}\\). Sostituendo le varianze di \\(\\bar{X}\\) e \\(\\bar{Y}\\), abbiamo:\n\\[\n\\text{Var}(\\bar{X} - \\bar{Y}) = \\frac{\\sigma^2}{n} + \\frac{\\sigma^2}{m} ,\n\\] \\[\n\\text{Var}(\\bar{X} - \\bar{Y}) = \\sigma^2 \\left(\\frac{1}{n} + \\frac{1}{m}\\right) .\n\\]\nQuindi, la varianza della differenza tra le due medie campionarie è una combinazione delle varianze delle singole medie, ponderate in base alle dimensioni dei campioni corrispondenti.\nPer giungere alla formula del test \\(t\\) di Student per due campioni indipendenti, dobbiamo considerare l’incertezza aggiuntiva derivante dal fatto che non conosciamo \\(\\sigma\\). Il modo migliore per stimare \\(\\sigma\\) è utilizzare le due deviazioni standard dei campioni, ponderate per i rispettivi gradi di libertà, come indicato nella formula della deviazione standard pooled:\n\\[\ns_p = \\sqrt{\\frac{(n - 1)s^2_x + (m - 1)s^2_y}{n + m - 2}},\n\\]\ndove \\(s_x\\) e \\(s_y\\) sono le deviazioni standard dei due campioni, e \\(n\\) e \\(m\\) sono le numerosità dei due campioni.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#esempio-pratico",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#esempio-pratico",
    "title": "\n81  Test t di Student per campioni indipendenti\n",
    "section": "\n81.6 Esempio Pratico",
    "text": "81.6 Esempio Pratico\nSupponiamo di avere due campioni:\n\n\nDonne: Pesi = [38.9, 61.2, 73.3, 21.8, 63.4, 64.6, 48.4, 48.8, 48.5]\n\nUomini: Pesi = [67.8, 60, 63.4, 76, 89.4, 73.3, 67.3, 61.3, 62.4]\n\nCreiamo un DataFrame in R e calcoliamo la statistica t:\n\nwomen_weight &lt;- c(38.9, 61.2, 73.3, 21.8, 63.4, 64.6, 48.4, 48.8, 48.5)\nmen_weight &lt;- c(67.8, 60, 63.4, 76, 89.4, 73.3, 67.3, 61.3, 62.4)\n\nweight &lt;- c(women_weight, men_weight)\nis_female &lt;- rep(c(1, 0), each = 9)  # 1 = Femmina, 0 = Maschio\n\ndf &lt;- data.frame(is_female = is_female, weight = weight)\n\nPer calcolare manualmente la statistica t:\n\n# Estraiamo i pesi per ogni gruppo\nweight_f &lt;- df$weight[df$is_female == 1]\nweight_m &lt;- df$weight[df$is_female == 0]\n\n# Calcolo della deviazione standard pooled\ns_pool_num &lt;- ((length(weight_f) - 1) * var(weight_f)) + ((length(weight_m) - 1) * var(weight_m))\ns_pool_denom &lt;- length(weight_f) + length(weight_m) - 2\ns_pool &lt;- sqrt(s_pool_num / s_pool_denom)\n\n# Calcolo della statistica t\nt_num &lt;- mean(weight_f) - mean(weight_m)\nt_denom &lt;- s_pool * sqrt(1 / length(weight_f) + 1 / length(weight_m))\nT &lt;- t_num / t_denom\nT\n#&gt; [1] -2.784\n\n\n# Gradi di libertà\ndf_degrees &lt;- length(weight_f) + length(weight_m) - 2\ndf_degrees\n#&gt; [1] 16\n\n\n# Calcolo del valore-p\np_value &lt;- 2 * pt(abs(T), df = df_degrees, lower.tail = FALSE)\nprint(p_value)\n#&gt; [1] 0.01327\n\nIn alternativa, possiamo usare la funzione t.test di R:\n\nres &lt;- t.test(weight_f, weight_m, var.equal = TRUE)\nprint(res, digits = 7)\n#&gt; \n#&gt;  Two Sample t-test\n#&gt; \n#&gt; data:  weight_f and weight_m\n#&gt; t = -2.7842, df = 16, p-value = 0.01327\n#&gt; alternative hypothesis: true difference in means is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -29.748019  -4.029759\n#&gt; sample estimates:\n#&gt; mean of x mean of y \n#&gt;  52.10000  68.98889\n\n\n81.6.1 Interpretazione dei Risultati\nIl test t di Student ha generato un valore-p inferiore a 0.05, indicando che la differenza osservata tra i pesi medi delle donne e degli uomini è statisticamente significativa. Questo significa che, con un livello di confidenza del 95%, possiamo rifiutare l’ipotesi nulla secondo cui le medie dei due gruppi sono uguali.\nÈ importante ricordare che un basso valore-p suggerisce che la differenza osservata non è dovuta al caso. Tuttavia, ciò non prova automaticamente una relazione causale; piuttosto, apre la strada ad ulteriori indagini sulle cause della differenza.\n\n81.6.2 Riportare i Risultati\nQuando si riportano i risultati di un test t, è fondamentale adottare pratiche che favoriscano una comprensione approfondita e accurata dei dati. Di seguito viene presentato un confronto tra due versioni dei risultati: una da evitare, che si basa su un’interpretazione tradizionale della significatività statistica, e una versione migliorata che enfatizza l’intervallo di confidenza e l’ampiezza dell’effetto.\n\n81.6.2.1 Versione da Evitare\nLa seguente formulazione segue un approccio tradizionale incentrato sulla “significatività statistica,” che è oggi ritenuto inadeguato per una comunicazione efficace dei risultati:\n\nAbbiamo condotto un test t di Student per confrontare le medie dei due gruppi. I risultati mostrano una differenza significativa tra i pesi medi delle donne e degli uomini (t(16) = -2.78, p-value = 0.01). L’intervallo di confidenza al 95% per la differenza delle medie è [-29.75, -4.03]. L’ampiezza dell’effetto, misurata con Cohen’s d, è 1.31, indicando un effetto grande. La potenza statistica del test è stata stimata al 74.4%.\n\nIn questa versione, il focus è eccessivamente concentrato sul valore-p, che può portare a interpretazioni riduttive e distorte dei risultati.\n\n81.6.2.2 Versione Migliorata\nEcco invece una versione migliore che mantiene un approccio frequentista, ma sposta l’enfasi sull’intervallo di confidenza e sull’ampiezza dell’effetto, offrendo una descrizione più completa e informativa:\n\nÈ stato condotto un test t di Student per confrontare le medie dei due gruppi. La differenza tra i pesi medi delle donne e degli uomini è stata stimata in -16.89 kg (intervallo di confidenza al 95%: [-29.75, -4.03]), suggerendo che il peso medio degli uomini sia maggiore rispetto a quello delle donne nel campione analizzato. Questo intervallo indica che, con una fiducia del 95%, la differenza reale tra i pesi medi potrebbe variare tra circa -29.75 kg e -4.03 kg.\nL’ampiezza dell’effetto, misurata con Cohen’s d = 1.31, indica una differenza considerevole, equivalente a oltre una deviazione standard. Questo valore suggerisce che la differenza osservata non solo è statisticamente rilevante, ma anche sostanziale dal punto di vista pratico.\nInoltre, la potenza del test, considerando la dimensione dell’effetto osservata, è pari al 74.4%, suggerendo che il test ha una buona capacità di rilevare differenze di questa entità nel campione analizzato. Ciò significa che, se una differenza di tale magnitudine fosse presente nella popolazione, esisterebbe una probabilità superiore al 70% di rilevarla correttamente.\n\nQuesta modalità di reporting fornisce una descrizione più dettagliata ed esplicativa dei risultati, evitando interpretazioni basate esclusivamente sul valore-p e concentrandosi invece sulla grandezza e sull’incertezza della stima. Tale approccio consente una valutazione più equilibrata e informata dei dati, promuovendo una comprensione più approfondita delle implicazioni pratiche e scientifiche dei risultati ottenuti.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#riflessioni-conclusive",
    "title": "\n81  Test t di Student per campioni indipendenti\n",
    "section": "\n81.7 Riflessioni Conclusive",
    "text": "81.7 Riflessioni Conclusive\nIl test t di Student è uno strumento statistico ampiamente utilizzato per l’inferenza su una media o per confrontare le medie di due gruppi. È talmente importante che alcuni lo hanno definito il metodo statistico più importante nella scienza. Tuttavia, come osserva Andrew Gelman, questa affermazione non va accettata acriticamente. Benché il test t sia semplice ed efficace in molti contesti, presenta notevoli limitazioni che ne riducono l’affidabilità e l’applicabilità quando si affrontano problemi complessi o si desidera una comprensione più approfondita dei dati (Kruschke, 2013).\n\n81.7.1 Limiti del Test t di Student\nUno dei principali limiti del test t risiede nell’assunzione che i dati seguano una distribuzione normale (gaussiana). Questa assunzione è spesso violata in pratica, specialmente con campioni piccoli o quando i dati presentano asimmetrie o code pesanti. Inoltre, nel caso di campioni indipendenti, il test richiede l’omogeneità delle varianze, un’altra assunzione frequentemente infondata. Quando queste condizioni non sono soddisfatte, il test può fornire risultati distorti, necessitando di correzioni come quella di Welch per gestire differenze di varianza.\nUn ulteriore limite del test t è legato alla sua dipendenza dalla soglia di significatività \\(\\alpha\\), solitamente fissata a 0.05. Questa scelta è arbitraria e può influenzare criticamente le conclusioni. Il test valuta esclusivamente la compatibilità dei dati con l’ipotesi nulla (\\(H_0\\)) e fornisce solo un p-value, senza offrire informazioni dirette sulla plausibilità dell’ipotesi alternativa (\\(H_1\\)). Ciò significa che un p-value basso non garantisce che \\(H_1\\) sia vera o che i dati supportino tale ipotesi.\n\n81.7.2 L’Approccio Bayesiano: Una Soluzione Più Potente\nIn contrasto con il paradigma frequentista, l’approccio bayesiano offre un quadro statistico più flessibile e informativo. Attraverso il teorema di Bayes, è possibile calcolare direttamente la probabilità di un’ipotesi dato l’insieme dei dati osservati. Questo permette di quantificare la forza dell’evidenza a favore di un’ipotesi rispetto alle altre, superando le limitazioni intrinseche del test t.\n\n81.7.2.1 Vantaggi dell’Approccio Bayesiano\n\nNon richiede assunzioni rigide: A differenza del test t, che si basa su ipotesi restrittive come la normalità e l’omoschedasticità, l’inferenza bayesiana è in grado di gestire modelli più generali e robusti, adattandosi ai dati reali senza doverli forzare in strutture artificiali.\nIncorporazione delle informazioni pregresse: L’approccio bayesiano permette di integrare conoscenze pregresse attraverso distribuzioni a priori, migliorando la qualità delle stime e consentendo analisi più realistiche. Questo è particolarmente utile in situazioni dove i dati disponibili sono scarsi o rumorosi.\nInferenze più informative: Al posto di semplici decisioni binarie (“rifiuto” o “non rifiuto” di \\(H_0\\)), il bayesianismo fornisce distribuzioni a posteriori complete, che descrivono l’incertezza sui parametri di interesse. Questo consente inferenze più dettagliate e interpretabili.\nGestione della complessità: L’approccio bayesiano gestisce in modo naturale modelli complessi e gerarchici, rendendolo ideale per analisi avanzate. Ad esempio, Kruschke (2013) dimostra come tecniche bayesiane possano superare le limitazioni del test t anche in presenza di violazioni delle assunzioni classiche, producendo risultati più stabili e affidabili.\n\n81.7.2.2 Implementazione Pratica\nSebbene l’approccio bayesiano richieda una maggiore attenzione nella scelta delle distribuzioni a priori e nella specificazione del modello, l’avvento di software moderni come Stan, PyMC3 e JAGS ha reso l’implementazione di modelli bayesiani sempre più accessibile. Oggi, anche ricercatori con competenze statistiche moderate possono applicare metodi bayesiani per affrontare problemi complessi con maggiore precisione e coerenza.\n\n81.7.3 Conclusioni\nIl test t di Student rimane un valido strumento per analisi rapide e semplici, ma le sue limitazioni diventano evidenti quando si lavora con dati complessi o si cerca una comprensione più profonda delle relazioni sottostanti. L’approccio bayesiano rappresenta un’evoluzione concettuale e metodologica rispetto all’inferenza frequentista tradizionale, offrendo numerosi vantaggi: inferenze più ricche, integrazione di informazioni pregresse, gestione delle violazioni delle assunzioni e produzione di stime più robuste. Per questi motivi, il paradigma bayesiano è sempre più considerato come la scelta preferibile per chi desidera un’analisi statistica solida, flessibile e informativa.\nIn ultima analisi, mentre il test t resta un punto di partenza utile, l’adozione dell’approccio bayesiano permette di avanzare verso una comprensione più completa e accurata dei dati.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#informazioni-sullambiente-di-sviluppo",
    "title": "\n81  Test t di Student per campioni indipendenti\n",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.17.0      thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0\n#&gt;  [5] see_0.11.0       gridExtra_2.3    patchwork_1.3.0  bayesplot_1.12.0\n#&gt;  [9] psych_2.5.3      scales_1.4.0     markdown_2.0     knitr_1.50      \n#&gt; [13] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [17] purrr_1.0.4      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [21] ggplot2_3.5.2    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6       shape_1.4.6.1      xfun_0.52         \n#&gt;  [4] htmlwidgets_1.6.4  lattice_0.22-7     tzdb_0.5.0        \n#&gt;  [7] Rdpack_2.6.4       vctrs_0.6.5        tools_4.5.0       \n#&gt; [10] generics_0.1.4     parallel_4.5.0     pan_1.9           \n#&gt; [13] pacman_0.5.1       jomo_2.7-6         pkgconfig_2.0.3   \n#&gt; [16] Matrix_1.7-3       RColorBrewer_1.1-3 lifecycle_1.0.4   \n#&gt; [19] compiler_4.5.0     farver_2.1.2       mnormt_2.1.1      \n#&gt; [22] codetools_0.2-20   htmltools_0.5.8.1  glmnet_4.1-8      \n#&gt; [25] nloptr_2.2.1       pillar_1.10.2      MASS_7.3-65       \n#&gt; [28] reformulas_0.4.1   iterators_1.0.14   rpart_4.1.24      \n#&gt; [31] boot_1.3-31        mitml_0.4-5        foreach_1.5.2     \n#&gt; [34] nlme_3.1-168       tidyselect_1.2.1   digest_0.6.37     \n#&gt; [37] stringi_1.8.7      splines_4.5.0      rprojroot_2.0.4   \n#&gt; [40] fastmap_1.2.0      grid_4.5.0         cli_3.6.5         \n#&gt; [43] magrittr_2.0.3     survival_3.8-3     broom_1.0.8       \n#&gt; [46] withr_3.0.2        backports_1.5.0    timechange_0.3.0  \n#&gt; [49] rmarkdown_2.29     nnet_7.3-20        lme4_1.1-37       \n#&gt; [52] hms_1.1.3          evaluate_1.0.3     rbibutils_2.3     \n#&gt; [55] rlang_1.1.6        Rcpp_1.0.14        glue_1.8.0        \n#&gt; [58] minqa_1.2.8        rstudioapi_0.17.1  jsonlite_2.0.0    \n#&gt; [61] R6_2.6.1",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#bibliografia",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#bibliografia",
    "title": "\n81  Test t di Student per campioni indipendenti\n",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nKruschke, J. K. (2013). Bayesian estimation supersedes the t test. Journal of Experimental Psychology: General, 142(2), 573–603.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/introduction_replication_crisis.html",
    "href": "chapters/replication_crisis/introduction_replication_crisis.html",
    "title": "Introduzione",
    "section": "",
    "text": "Bibliografia\nLa psicologia, insieme ad altre discipline scientifiche, sta attraversando una Riforma Metodologica scaturita da una crisi profonda: l’incapacità di replicare risultati di ricerche precedentemente pubblicati. Questa crisi di replicazione, che mina la credibilità della scienza, ha portato a un ripensamento radicale delle pratiche di ricerca, degli standard metodologici e degli incentivi accademici (Korbmacher et al., 2023). Siti come Retraction Watch, che monitorano le ritrattazioni di studi scientifici, testimoniano l’entità del problema, evidenziando casi di frodi, manipolazioni statistiche e pratiche di ricerca opache.\nLe Cause della Crisi.\nTra le cause principali vi sono incentivi distorti (come la pressione a pubblicare rapidamente), l’utilizzo acritico di tecniche inferenziali frequentiste – che facilitano la proliferazione di falsi positivi – e la scarsa attenzione alla dimensione campionaria. Come dimostrato da Altmejd et al. (2019), alcuni elementi superficiali permettono di prevedere la replicabilità di uno studio:\nSorprendentemente, prevedere se uno studio sarà replicabile non richiede competenze avanzate. Camerer et al. (2018) ha mostrato che scienziati coinvolti in un “mercato delle scommesse” predicevano con precisione quali studi di scienze sociali si sarebbero replicati. Ancora più significativo è il lavoro di Hoogeveen et al. (2020): partecipanti senza formazione specifica, esposti a semplici descrizioni di studi psicologici, hanno identificato con successo ricerche a rischio di fallimento replicativo. Ciò suggerisce che molti studi presentano difetti metodologici evidenti, riconoscibili persino a un pubblico non esperto.\nLa Diffusione degli Errori nella Letteratura Scientifica.\nLa pubblicazione peer-reviewed non garantisce l’affidabilità di una ricerca. Yang et al. (2020) ha rilevato che studi non replicabili vengono citati con la stessa frequenza di quelli validi, alimentando un ciclo di errori. Questo paradosso – scienziati capaci di riconoscere studi fragili ma inclini a citarli – riflette una cultura accademica disfunzionale (Smaldino & McElreath, 2016), dove la quantità di pubblicazioni prevale sulla qualità e gli incentivi premiano scorciatoie metodologiche.\nEsempi Emblematici e la Crisi di Validità.\nLa crisi non riguarda solo la replicazione, ma anche la validità delle misure e delle teorie. Ricerche influenti, come quelle sul pre-cognition di Ritchie et al. (2012) o sugli effetti del priming inconscio di John Bargh, si sono rivelate basate su evidenze fragili (Schimmack, 2012). Anche concetti consolidati, come l’esaurimento dell’autocontrollo (ego depletion) legato ai livelli di glucosio, sono stati criticati per mancanza di supporto empirico (Vadillo et al., 2016). Persino opere di autori celebri, come Thinking: Fast and Slow di Daniel Kahneman, contengono affermazioni basate su risultati non replicabili (Schimmack, 2020).\nVerso una Soluzione: Oltre l’Inferenza Frequentista.\nQuesta sezione della dispensa si concentra su uno dei nodi metodologici alla base della crisi: i limiti dell’inferenza frequentista (Baker, 2016). Concetti come gli errori di tipo S (conclusioni errate sulla direzione di un effetto) e di tipo M (sovrastima dell’entità di un effetto), introdotti da Gelman & Carlin (2014), illuminano le insidie delle tecniche statistiche tradizionali. Per affrontare la crisi, è necessario adottare approcci alternativi: preregistrazione degli studi, utilizzo di metodi bayesiani, e una valutazione critica della credibilità cumulativa della letteratura (Schimmack, 2020).\nConclusioni.\nLa crisi della replicabilità non è solo un problema tecnico, ma il sintomo di un sistema scientifico da ripensare. Riviste accademiche, istituzioni e ricercatori devono promuovere integrità, trasparenza e una cultura che valorizzi la robustezza rispetto alla novità. Solo così la psicologia potrà riconquistare il ruolo di scienza empirica rigorosa, capace di produrre conoscenza affidabile.",
    "crumbs": [
      "Crisi",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/introduction_replication_crisis.html#bibliografia",
    "href": "chapters/replication_crisis/introduction_replication_crisis.html#bibliografia",
    "title": "Introduzione",
    "section": "",
    "text": "Altmejd, A., Dreber, A., Forsell, E., Huber, J., Imai, T., Johannesson, M., Kirchler, M., Nave, G., & Camerer, C. (2019). Predicting the replicability of social science lab experiments. PloS one, 14(12), e0225826.\n\n\nBaker, M. (2016). Reproducibility Crisis. Nature, 533(7604), 452–454.\n\n\nCamerer, C. F., Dreber, A., Holzmeister, F., Ho, T.-H., Huber, J., Johannesson, M., Kirchler, M., Nave, G., Nosek, B. A., Pfeiffer, T., et al. (2018). Evaluating the replicability of social science experiments in Nature and Science between 2010 and 2015. Nature human behaviour, 2(9), 637–644.\n\n\nGelman, A., & Carlin, J. (2014). Beyond Power Calculations: Assessing Type S (Sign) and Type M (Magnitude) Errors. Perspectives on Psychological Science, 9(6), 641–651.\n\n\nHoogeveen, S., Sarafoglou, A., & Wagenmakers, E.-J. (2020). Laypeople can predict which social-science studies will be replicated successfully. Advances in Methods and Practices in Psychological Science, 3(3), 267–285.\n\n\nKorbmacher, M., Azevedo, F., Pennington, C. R., Hartmann, H., Pownall, M., Schmidt, K., Elsherif, M., Breznau, N., Robertson, O., Kalandadze, T., et al. (2023). The replication crisis has led to positive structural, procedural, and community changes. Communications Psychology, 1(1), 3.\n\n\nRitchie, S. J., Wiseman, R., & French, C. C. (2012). Failing the future: Three unsuccessful attempts to replicate Bem’s ‘Retroactive Facilitation of Recall’Effect. PloS one, 7(3), e33423.\n\n\nSchimmack, U. (2012). The ironic effect of significant results on the credibility of multiple-study articles. Psychological methods, 17(4), 551–566.\n\n\nSchimmack, U. (2020). A meta-psychological perspective on the decade of replication failures in social psychology. Canadian Psychology/Psychologie Canadienne, 61(4), 364–376.\n\n\nSmaldino, P. E., & McElreath, R. (2016). The natural selection of bad science. Royal Society Open Science, 3(9), 160384.\n\n\nVadillo, M. A., Gold, N., & Osman, M. (2016). The bitter truth about sugar and willpower: The limited evidential value of the glucose model of ego depletion. Psychological Science, 27(9), 1207–1214.\n\n\nYang, Y., Youyou, W., & Uzzi, B. (2020). Estimating the deep replicability of scientific findings using human and artificial intelligence. Proceedings of the National Academy of Sciences, 117(20), 10762–10768.",
    "crumbs": [
      "Crisi",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html",
    "href": "chapters/replication_crisis/01_crisis.html",
    "title": "82  La crisi della replicazione",
    "section": "",
    "text": "82.1 Introduzione\nIl presente capitolo introduce la crisi di replicazione che affligge la ricerca psicologica, analizzandone le cause precipue e ponendo in rilievo il ruolo che l’approccio statistico frequentista ha avuto nel concorrere a tale problematica. Il contenuto di questo capitolo costituisce una sintesi rielaborata del testo A student’s guide to open science: Using the replication crisis to reform psychology (Pennington, 2023).",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#i-pilastri-della-scienza-psicologica-ideale",
    "href": "chapters/replication_crisis/01_crisis.html#i-pilastri-della-scienza-psicologica-ideale",
    "title": "82  La crisi della replicazione",
    "section": "\n82.2 I Pilastri della Scienza Psicologica Ideale",
    "text": "82.2 I Pilastri della Scienza Psicologica Ideale\nAffinché la psicologia sia riconosciuta come scienza rigorosa, deve aderire a principi fondamentali:\n\n82.2.1 A. Replicabilità e Riproducibilità\n\n\n\nDefinizione: Un effetto empirico è considerato valido solo se replicabile da ricercatori indipendenti, con metodologie analoghe e campioni adeguati.\n\n\nEsempio: Lo studio classico di Asch sul conformismo (1951) è stato replicato in contesti cross-culturali, rafforzandone la validità.\n\n82.2.2 B. Attributi Essenziali della Ricerca\n\nLa scienza ideale dovrebbe essere:\n\n\n\n\n\n\n\nPrincipio\nDescrizione\nImplicazioni per la Psicologia\n\n\n\nCredibile\nSottoposizione delle ipotesi a verifica rigorosa e peer review trasparente.\nEvitare p-hacking e HARKing (Hypothesizing After Results are Known).\n\n\nAffidabile\nRisultati accurati e privi di distorsioni (bias).\nUtilizzo di preregistrazione e open data.\n\n\nTrasparente\nDescrizione dettagliata di metodi, analisi e risultati.\nAdozione di registered reports e condivisione di materiali supplementari.\n\n\nAccessibile\nDemocratizzazione della conoscenza (es. open access).\nPiattaforme come PsyArXiv per preprint o OSF per la condivisione di protocolli.\n\n\nInclusiva\nPartecipazione equa di gruppi sottorappresentati (etnici, di genere, ecc.).\nStudi con campioni diversificati (es. non solo WEIRD: Western, Educated, Industrialized, Rich, Democratic).\n\n\nCollaborativa\nSuperamento della competizione accademica a favore di reti di ricerca.\nProgetti multi-lab (es. Many Labs in psicologia sociale).\n\n\nAutocorrettiva\nRevisione continua degli errori e ritrattazione di risultati non validi.\nDatabase come Retraction Watch e correzioni pubbliche negli articoli.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#la-disconnessione-tra-ideale-e-realtà",
    "href": "chapters/replication_crisis/01_crisis.html#la-disconnessione-tra-ideale-e-realtà",
    "title": "82  La crisi della replicazione",
    "section": "\n82.3 La Disconnessione tra Ideale e Realtà",
    "text": "82.3 La Disconnessione tra Ideale e Realtà\nPennington (2023) utilizza un esercizio retorico per criticare la prassi scientifica tradizionale:\n\nVisualizzate lo stereotipo dello scienziato: un uomo bianco, in un laboratorio con cartelli ‘DIVIETO DI ACCESSO’, che tratta i dati come proprietà privata. Questa immagine riflette una scienza chiusa, competitiva e non allineata ai valori di trasparenza e collaborazione.\n\n\n82.3.1 Problemi Emersi\n\n\nSegretezza: Ricercatori che occultano dati per paura di critiche o “furti” di idee.\n\n\nCrisi di replicazione: Il 50-70% degli studi psicologici non è replicabile (Collaboration, 2015).\n\n\nPressioni accademiche: Focus su pubblicazioni “rivoluzionarie” a scapito di solidità metodologica.\n\n82.3.2 Verso una Psicologia più Rigorosa\nPer affrontare le criticità emerse nella ricerca psicologica, sono state avanzate diverse proposte concrete. Una delle direzioni più promettenti è l’adozione diffusa delle pratiche di Open Science, che includono la preregistrazione degli studi (per evitare il p-hacking), la condivisione aperta dei dati (open data) e l’utilizzo di strumenti gratuiti e trasparenti, come il software JASP per le analisi statistiche. Questi approcci non solo aumentano l’affidabilità dei risultati, ma favoriscono anche una cultura di collaborazione anziché di segretezza.\nUn altro passo fondamentale riguarda la formazione dei ricercatori. Introdurre corsi obbligatori su etica della ricerca e metodi quantitativi avanzati potrebbe ridurre errori metodologici e comportamenti opportunistici, preparando una nuova generazione di psicologi a standard più rigorosi.\nInfine, è essenziale ripensare il sistema di valutazione accademica. Invece di premiare la mera quantità di pubblicazioni – che spesso spinge verso risultati “sensazionali” ma poco replicabili – sarebbe più produttivo incentivare la qualità, la trasparenza e l’impatto a lungo termine del lavoro scientifico.\nUn esempio concreto di questo cambiamento è il progetto ManyBabies, un’iniziativa internazionale che coinvolge decine di laboratori nello studio dello sviluppo infantile. Grazie alla collaborazione su larga scala e alla condivisione di protocolli standardizzati, ManyBabies ha dimostrato come sia possibile produrre risultati più solidi e generalizzabili, superando i limiti dei piccoli studi isolati. Questo caso illustra perfettamente i benefici di una psicologia più aperta, cooperativa e metodologicamente rigorosa.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#la-crisi-della-replicazione-in-psicologia",
    "href": "chapters/replication_crisis/01_crisis.html#la-crisi-della-replicazione-in-psicologia",
    "title": "82  La crisi della replicazione",
    "section": "\n82.4 La Crisi della Replicazione in Psicologia",
    "text": "82.4 La Crisi della Replicazione in Psicologia\nNegli ultimi decenni, la psicologia si è trovata al centro di una crisi che ha messo in discussione molte delle sue basi epistemologiche e metodologiche: la crisi della replicazione. Questo fenomeno indica l’incapacità di replicare con successo un’ampia parte degli studi pubblicati, con implicazioni rilevanti per la cultura accademica e il modo di concepire la ricerca scientifica (Parsons et al., 2022).\nPer fallimento della replicazione si intende il caso in cui uno studio, ripetuto da altri ricercatori seguendo le stesse procedure e utilizzando campioni simili, non riesce a ottenere risultati comparabili a quelli originali. Questo ha portato alla luce problemi sistemici legati alla metodologia di ricerca, all’interpretazione dei dati e alle dinamiche del sistema accademico. La crisi della replicazione ha dunque evidenziato la necessità di un cambiamento strutturale nella pratica scientifica, sottolineando l’urgenza di un approccio più trasparente, rigoroso e collaborativo.\nNelle sezioni seguenti vengono presentati gli eventi chiave di quella che possiamo chiamare la storia della crisi della replicazione.\n\n82.4.1 2005: “Perché la maggior parte dei risultati pubblicati è falsa” (Ioannidis)\nUn primo momento cruciale è stato l’articolo di “Why Most Published Research Findings Are False” (Ioannidis, 2005) che ha evidenziato come molti risultati scientifici fossero in realtà falsi positivi. Ioannidis attribuì questo fenomeno a campioni di piccole dimensioni, un’eccessiva enfasi sui valori-p per indicare significatività, flessibilità nei metodi di analisi e la competizione per produrre risultati “innovativi”. Questo articolo ha messo in luce problemi che trascendono la psicologia, ma che in seguito sarebbero emersi come centrali anche per questa disciplina.\n\n82.4.2 2011: Lo Studio di Daryl Bem, “Feeling the Future”\nUno degli eventi più controversi è stato lo studio di Daryl Bem “Feeling the Future” (Bem, 2011), che suggeriva l’esistenza della precognizione, ovvero la capacità di “sentire” eventi futuri. Attraverso nove esperimenti, Bem pubblicò risultati statisticamente significativi che sembravano sfidare le leggi della causalità.\nLo studio di Bem si inseriva nella tradizione degli esperimenti di “priming”, una tecnica ampiamente utilizzata in psicologia sociale dagli anni ’70. Gli esperimenti di priming tipicamente coinvolgevano studenti universitari, remunerati con modeste somme o crediti accademici. I partecipanti venivano esposti a determinati concetti per poi osservare come questi influenzassero il loro comportamento successivo. Un celebre esempio è lo studio di John Bargh del 1996, che dimostrò come l’esposizione a parole associate all’età avanzata inducesse i soggetti a camminare più lentamente (Bargh et al., 1996). Un altro studio del 2006 rivelò che il priming con concetti legati al denaro rendeva le persone meno propense ad aiutare gli altri. Questi studi sembravano dimostrare una straordinaria malleabilità della mente umana, suggerendo che il nostro comportamento potesse essere inconsciamente manipolato da sottili segnali ambientali (Leys, 2024). Tuttavia, lo studio di Bem introdusse un elemento nuovo in questo paradigma sperimentale.\nTra i vari esperimenti condotti da Bem, uno in particolare si distingueva. I soggetti venivano esposti a una parola con connotazione positiva o negativa e successivamente dovevano valutare rapidamente la piacevolezza di alcune immagini. Fin qui, nulla di insolito. La svolta radicale consisteva nel fatto che in metà delle prove, il priming avveniva dopo che i soggetti avevano già visto e valutato l’immagine (Bem, 2011).\nSorprendentemente, i risultati mostravano che il priming funzionava anche in queste condizioni: i partecipanti erano più veloci a giudicare piacevoli le immagini quando successivamente venivano esposti a una parola positiva. Questo effetto risultava statisticamente significativo, con un p-value di 0.01, sufficiente secondo gli standard correnti per rifiutare l’ipotesi nulla.\nBem interpretò questi risultati come prova della chiaroveggenza, una conclusione che suscitò notevoli controversie e ridicolizzò la psicologia. Gli altri otto esperimenti dello studio, tutti basati su classici paradigmi della psicologia sociale con l’ordine temporale invertito, mostrarono risultati altrettanto statisticamente significativi.\nQuesti risultati ponevano la comunità scientifica di fronte a un dilemma: accettare l’esistenza di fenomeni paranormali o mettere in discussione le pratiche statistiche e metodologiche consolidate nella disciplina. Bem stesso continua a sostenere la validità dei suoi risultati come prova dell’esistenza di capacità precognitive.\nSebbene pubblicato su una rivista prestigiosa, lo studio sollevò enormi dubbi metodologici. Le repliche successive non riuscirono a confermare i risultati di Bem, mostrando come pratiche discutibili, quali il p-hacking (modifiche al metodo di analisi per ottenere risultati significativi), potessero produrre falsi positivi apparentemente robusti.\n\n82.4.3 2011: Il Caso di Frode di Diederik Stapel\nNello stesso anno, Diederik Stapel, una figura di spicco della psicologia sociale, fu accusato di aver falsificato dati in decine di studi pubblicati. Tra i suoi esperimenti più famosi vi era quello secondo cui ambienti disordinati aumenterebbero il razzismo. Un altro studio suggeriva che mangiare carne rendeva le persone più antisociali. Tuttavia, si scoprì che per quegli studi, e molti altri, non aveva mai condotto gli esperimenti né raccolto i dati. Li aveva semplicemente inventati. A volte le frodi accadono. Stapel fu scoperto (alla fine), licenziato e decine dei suoi articoli furono ritirati. Questo scandalo scosse profondamente la comunità accademica e divenne un simbolo della crisi.\n\n82.4.4 2011: La Meta-ricerca e le Pratiche di Ricerca Discutibili (QRPs)\nLa meta-ricerca è un campo di studio che si concentra sul modo in cui viene condotta la ricerca scientifica. Comprende temi come i metodi, la trasparenza nella comunicazione, la riproducibilità, la valutazione e i sistemi di incentivi che regolano la scienza (Ioannidis et al., 2015). Questo ambito è emerso con urgenza dopo una serie di casi controversi e di frodi conclamate, come gli studi di Daryl Bem e Diederik Stapel, che hanno evidenziato falle nei processi di ricerca. I ricercatori hanno così iniziato ad analizzare pratiche note come Questionable Research Practices (QRPs, Pratiche di Ricerca Discutibili), che sfruttano aree grigie nelle norme scientifiche per raccogliere e analizzare i dati.\nSimmons et al. (2011) hanno dimostrato come la flessibilità nella raccolta, analisi e comunicazione dei dati permetta ai ricercatori di far apparire “significativo” praticamente qualsiasi risultato. Tra le pratiche discusse, spiccano:\n\n\nOptional stopping: Interrompere la raccolta dei dati non appena si raggiunge la significatività statistica, invece di seguire un piano prestabilito.\n\n\nP-hacking: Condurre molteplici test non pianificati, selezionando variabili o analisi solo quando producono un valore p inferiore a 0.05.\n\n\nHARKing (Hypothesizing After Results are Known): Modificare le ipotesi a posteriori per adattarle ai risultati ottenuti, presentandole come ipotesi iniziali.\n\nQueste pratiche non solo compromettono l’integrità scientifica, ma rendono estremamente facile produrre falsi positivi. Per dimostrarlo, Simmons e colleghi hanno condotto simulazioni al computer e due esperimenti, rivelando quanto fosse “troppo facile” raccogliere prove a sostegno di ipotesi false.\nLa portata di queste pratiche è sorprendente. Simmons et al. hanno scoperto che:\n\nUsare una sola QRP può quasi raddoppiare il tasso di falsi positivi, portandolo dal 5% al 10%.\n\nCombinare più QRPs può far salire questa percentuale oltre il 60%.\n\nPer sottolineare il problema, i ricercatori hanno dimostrato, in modo volutamente ironico, che ascoltare la canzone dei Beatles “When I’m Sixty-Four” potrebbe far apparire le persone più giovani di quanto fossero prima di ascoltarla. Questa dimostrazione satirica evidenziava che inseguire la significatività statistica senza un rigore metodologico può produrre risultati assurdi.\nJohn et al. (2012) hanno condotto un’indagine su larga scala, intervistando 2000 ricercatori per comprendere la diffusione delle QRPs. Con un approccio innovativo, hanno chiesto ai partecipanti non solo di riferire le proprie pratiche, ma anche quelle dei colleghi. I risultati sono stati sconvolgenti:\n\nOltre il 60% degli intervistati ha ammesso di non aver riportato tutte le variabili dipendenti misurate.\n\nPiù del 50% ha interrotto la raccolta dati non appena ottenuti risultati significativi (optional stopping).\n\nPiù del 40% ha selezionato e riportato solo esperimenti “riusciti”.\n\nSorprendentemente, i ricercatori tendevano a dichiarare che i colleghi adottavano queste pratiche più frequentemente di loro stessi. Molti giustificavano queste pratiche come “norme accademiche” del tempo.\nLa meta-ricerca ha giocato un ruolo cruciale nell’aprire gli occhi della comunità scientifica sui pericoli di queste decisioni apparentemente “banali”. In un contesto in cui le QRPs erano ampiamente accettate, la meta-ricerca ha evidenziato come queste pratiche possano seriamente danneggiare il progresso scientifico. Grazie al movimento dell’Open Science, si stanno introducendo norme che migliorano la credibilità della ricerca, spostando l’enfasi dalla produzione di risultati “significativi” alla conduzione di studi rigorosi e trasparenti.\n\n82.4.5 2012: La Crisi di Fiducia della Psicologia\nSiamo nel 2012, un anno segnato da una serie di eventi che spingono Harold Pashler ed Eric-Jan Wagenmakers a dichiarare che la psicologia sta affrontando una “crisi di fiducia”. In un numero speciale della rivista Perspectives on Psychological Science (PoPs), i due autori raccolgono una molteplicità di prospettive sulla nascente crisi della replicazione, cercando di individuarne le cause e le implicazioni.\nLe reazioni alla crisi sono variegate e, in alcuni casi, contrastanti. Alcuni studiosi sostengono che le affermazioni di una crisi siano premature (Stroebe e Strack, 2014) e che i problemi di replicazione non siano un fenomeno nuovo (Spellman, 2015). Altri, invece, sottolineano come incentivare e valorizzare gli studi di replicazione rappresenti un metodo efficace e diretto per migliorare la qualità della scienza psicologica (Koole e Lakens, 2012).\nIl numero speciale evidenzia anche iniziative in corso per affrontare il problema. Tra queste, l’Open Science Collaboration (OSC), un progetto di larga scala avviato nel 2012, si propone di verificare empiricamente se la psicologia sia effettivamente alle prese con una crisi della replicazione. L’obiettivo del progetto è ambizioso: replicare numerosi studi pubblicati per valutare la robustezza dei risultati originari. Sebbene i risultati di questa iniziativa non fossero ancora disponibili al momento della pubblicazione del numero speciale, il progetto rappresentava già una pietra miliare per la disciplina.\nNonostante le preoccupazioni, il numero speciale si chiude con una nota positiva, destinata a risuonare nella comunità scientifica. I casi di frode, le pratiche di ricerca discutibili (QRPs) e i fallimenti nei tentativi di replicazione, sebbene dannosi, hanno aperto la strada a una riflessione critica. Questo processo ha permesso alla psicologia di affrontare i propri limiti, correggere errori, superare i bias e costruire una letteratura più affidabile e trasparente.\nQuesto periodo storico segna un punto di svolta: la crisi di fiducia ha messo in discussione le fondamenta della disciplina, ma ha anche creato l’opportunità per un rinnovamento scientifico, stimolando pratiche più rigorose e una maggiore attenzione alla replicabilità e alla trasparenza.\n\n82.4.6 2014: Il Progetto “Many Labs”\nNel 2014 fu pubblicato il primo tentativo su larga scala di replicare risultati psicologici: il progetto “Many Labs”. Questo imponente sforzo collaborativo, guidato da Klein et al. (2014), testò la replicabilità di 13 risultati classici della psicologia, coinvolgendo 6344 partecipanti in 12 paesi. Gli studi selezionati rispettavano tre criteri principali: erano relativamente brevi, avevano un design semplice e potevano essere facilmente condotti online.\nTra i fenomeni esaminati figurava la fallacia del costo irrecuperabile (sunk cost fallacy), secondo cui le persone tendono a proseguire un’attività quando vi hanno già investito tempo, sforzi o denaro. Un esempio classico: se hai acquistato un biglietto per vedere la tua squadra di calcio preferita e, il giorno della partita, inizia a piovere a dirotto, sarai più propenso a partecipare perché hai già speso i soldi per il biglietto (Oppenheimer e Monin, 2009).\nAltri studi replicati includevano:\n\nL’influenza del framing dei guadagni e delle perdite sul rischio (Tversky e Kahneman, 1981).\n\nLe differenze di genere negli atteggiamenti impliciti verso la matematica e le arti (Nosek et al., 2002).\n\nI risultati sembravano promettenti: il 77% degli studi replicò con successo i risultati originali (10 su 13). Tuttavia, non tutti gli studi fornirono lo stesso livello di evidenza. Ad esempio:\n\nUno studio sull’efficacia del contatto sociale immaginato nel ridurre i pregiudizi (Husnu e Crisp, 2010) mostrò supporto limitato, con solo 4 campioni su 36 che evidenziarono un effetto significativo.\n\nDue studi di priming non furono replicati. Nel primo, i ricercatori non trovarono che l’esposizione alla bandiera americana aumentasse il conservatorismo (Carter et al., 2011). Nel secondo, il priming con concetti legati al denaro non portò a un incremento delle credenze o dei comportamenti capitalistici (Caruso et al., 2013).\n\nSebbene i risultati fossero accolti come una vittoria per la replicabilità, alcuni ricercatori sottolinearono limiti nel progetto Many Labs 1. Gli stessi autori riconobbero che molti degli studi selezionati erano già noti per essere altamente replicabili. Secondo alcuni critici, il principale contributo di questo progetto era dimostrare che almeno dieci effetti psicologici erano replicabili, ma non forniva una panoramica più ampia sulla replicabilità complessiva nella psicologia (Yarkoni, 2013).\nQuesto progetto rappresentò comunque un passo fondamentale per affrontare la crisi della replicazione, sottolineando l’importanza della collaborazione scientifica e del rigore metodologico.\n\n82.4.7 2015: Il Progetto di Riproducibilità della Open Science Collaboration\nNel 2015, la Open Science Collaboration (OSC) pubblicò i risultati del Reproducibility Project: Psychology, dimostrando che la buona scienza richiede tempo e rigore. Superando i limiti del progetto Many Labs 1, un team composto da oltre 270 ricercatori internazionali si impegnò a replicare 100 studi scelti casualmente da riviste di punta nel campo della psicologia.\nPer garantire risultati solidi e inattaccabili, il team adottò una metodologia rigorosa:\n- Consultazione con gli autori originali: gli autori degli studi originali furono coinvolti per confermare il design sperimentale e ridurre al minimo eventuali discrepanze.\n- Aumento delle dimensioni campionarie: i campioni furono ampliati per garantire una potenza statistica sufficiente.\n- Registrazione preventiva dei metodi: i piani di analisi e raccolta dati furono registrati in anticipo per prevenire bias da parte dei ricercatori.\nGli studi selezionati per la replicazione includevano domande di ricerca come:\n\nLa convinzione che il comportamento umano sia predeterminato incoraggia il tradimento?\n\nI bambini seguono automaticamente lo sguardo per trovare oggetti nascosti?\n\nÈ possibile osservare un “effetto after-motion” da fotografie fisse che rappresentano movimento?\n\nI risultati del progetto fecero scalpore e conquistarono i titoli dei giornali a livello globale. Solo il 36% degli studi replicò con successo, ottenendo un valore-p inferiore a 0.05. La psicologia sociale si rivelò particolarmente problematica, con un tasso di replicazione del 25%, rispetto al 50% degli studi di psicologia cognitiva.\nPer contestualizzare questi numeri, se gli effetti originali fossero stati realmente validi, il tasso minimo di replicazione atteso sarebbe stato dell’89% (Field et al., 2019). Anche tra gli studi replicati, le dimensioni degli effetti risultarono dimezzate rispetto a quelle riportate negli studi originali.\nQuesti risultati provocarono una forte reazione nella comunità scientifica. Ci si chiedeva: era la fine della psicologia? La disciplina avrebbe mai recuperato credibilità? Sebbene i dati fossero allarmanti, aprirono un dibattito più ampio. Come sottolineato da Kuhn (1962) e Redish et al. (2018), fallimenti nella replicazione possono segnare l’inizio di una rivoluzione scientifica, stimolando un ripensamento dei metodi, delle ipotesi e delle pratiche di ricerca.\nIl Reproducibility Project: Psychology non solo mise in luce le fragilità della disciplina, ma divenne un punto di partenza per migliorare la trasparenza, la collaborazione e la robustezza nella ricerca psicologica.\n\n82.4.7.1 Studi Successivi\nQuesti risultati sono stati ulteriormente corroborati da numerosi studi successivi, tra cui una ricerca più recente basata su tecniche di machine learning, che ha esaminato studi di psicologia pubblicati in sei importanti riviste nell’arco di vent’anni. Questa ricerca suggerisce che poco più della metà di questi articoli di psicologia non supererebbe i test di replicazione (Youyou et al., 2023). Discipline come la psicologia sociale sono state oggetto di particolare preoccupazione, con un tasso di replicazione del solo 25% riportato dal Progetto di Riproducibilità (Collaboration, 2015). Questo dato è in linea con il lavoro di Youyou et al. (2023), che ha mostrato come la replicabilità degli articoli di psicologia vari considerevolmente per sottocampo, con la psicologia sociale che mostra un tasso di replicazione stimato del 37%, un risultato leggermente più incoraggiante rispetto a quanto riportato in precedenza, ma ancora tra i più bassi dei sottocampi esaminati. Altri settori come la psicologia dello sviluppo, cognitiva e clinica hanno mostrato tassi di replicazione stimati rispettivamente del 36%, 42% e 44%, mentre aree come la psicologia delle organizzazioni e della personalità hanno mostrato tassi leggermente più incoraggianti (50% e 55%, rispettivamente). Complessivamente, le evidenze suggeriscono che le preoccupazioni diffuse sulla robustezza e replicabilità dei risultati della ricerca psicologica siano fondate. Sebbene il problema non sia limitato esclusivamente alla psicologia, le questioni rilevate in questo campo hanno ricevuto notevole attenzione a causa dell’apparente portata del fenomeno.\nQuesti risultati confermavano in modo drammatico le previsioni formulate anni prima da John Ioannidis e Dennis Lindley. Le loro avvertenze riguardo alla possibilità che una larga parte, se non la maggioranza, dei risultati scientifici pubblicati potesse essere falsa, si rivelavano ora profetiche.\nIl Progetto di Riproducibilità di Nosek ha segnato un punto di svolta nel dibattito sulla crisi della replicazione in psicologia e, più in generale, nelle scienze sociali e biomediche. Ha evidenziato non solo la fragilità di molti risultati ritenuti consolidati, ma anche la necessità di un riesame critico delle pratiche di ricerca e pubblicazione scientifica. Questo ripensamento delle metodologie scientifiche è ancora in atto.\n\n82.4.8 2015: 1500 Scienziati Sollevano il Velo sulla Riproducibilità\nI risultati del progetto Collaboration (2015) colpirono il mondo della psicologia come un fulmine a ciel sereno. Molti risultati psicologici, considerati affidabili, crollarono improvvisamente, generando un’ondata di discussioni nei dipartimenti universitari: quale sarebbe stato il prossimo “effetto” a fallire? Tuttavia, nonostante la psicologia fosse diventata l’emblema delle repliche fallite, presto si comprese che non era un problema esclusivo della disciplina.\nNel 2016, Baker condusse un’indagine su 1500 scienziati provenienti da diverse discipline, tra cui chimica, medicina, fisica e ingegneria, per esplorare le preoccupazioni riguardo alla replicazione e alla riproducibilità (Baker, 2016). I risultati furono sorprendenti: circa il 90% dei partecipanti concordò sull’esistenza di una crisi di riproducibilità, definita come significativa dal 52% e lieve dal 38%.\nUn dato particolarmente allarmante emerse dall’indagine:\n\nIn media, il 40% degli scienziati aveva riscontrato difficoltà nel riprodurre i propri esperimenti.\n\nQuesta percentuale saliva a oltre il 60% quando si tentava di riprodurre gli esperimenti di altri ricercatori.\n\nTra le discipline, la chimica risultò la più problematica, con oltre l’85% dei ricercatori che riportavano fallimenti nel riprodurre i risultati altrui.\nL’articolo di Baker riportava anche esperienze personali che riflettevano il senso di smarrimento generato da questa crisi. Il professor Marcus Munafò, per esempio, descrisse così il suo percorso:\n\nHo cercato di replicare ciò che dalla letteratura sembrava semplice, ma non ci sono riuscito. Ho avuto una crisi di fiducia, e poi ho scoperto che questa esperienza non era affatto rara. (Baker, 2016)\n\nL’indagine di Baker non si limitò a evidenziare il problema, ma esplorò anche le possibili cause della crisi, come pratiche metodologiche inadeguate e pressioni accademiche, offrendo al contempo suggerimenti per interventi correttivi.\nL’indagine segnò un momento cruciale: la crisi della riproducibilità, inizialmente confinata a discussioni accademiche, raggiunse una visibilità globale. Non era più solo un problema della psicologia, ma un fenomeno che colpiva l’intero mondo scientifico, portando con sé la necessità di una trasformazione radicale delle pratiche di ricerca.\nQuesto evento contribuì a consolidare il riconoscimento della crisi della riproducibilità come una sfida centrale per tutta la scienza, spingendo verso un cambiamento culturale che mettesse al centro trasparenza, rigore e collaborazione.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#la-cultura-della-frode-nel-sistema-accademico",
    "href": "chapters/replication_crisis/01_crisis.html#la-cultura-della-frode-nel-sistema-accademico",
    "title": "82  La crisi della replicazione",
    "section": "\n82.5 La Cultura della Frode nel Sistema Accademico",
    "text": "82.5 La Cultura della Frode nel Sistema Accademico\nIn alcuni casi, la crisi della replicazione si intreccia con episodi di frode scientifica, rivelando un lato oscuro della ricerca accademica. Uno degli aspetti più preoccupanti è che il sistema accademico, con i suoi meccanismi di incentivo basati su pubblicazioni frequenti e finanziamenti competitivi, può indirettamente favorire comportamenti disonesti. Questo sistema, orientato al publish or perish (pubblica o scompari), crea pressioni che talvolta spingono i ricercatori a compromettere l’integrità scientifica per raggiungere i propri obiettivi di carriera.\n\n82.5.1 Il Caso Brian Wansink\nUn caso emblematico è quello di Brian Wansink, ex ricercatore di spicco alla Cornell University, che ricevette cospicui finanziamenti federali durante l’amministrazione Obama. I suoi studi sul comportamento alimentare, come quello sugli uomini che mangiano di più in presenza di donne o sull’effetto dei nomi “attraenti” dati alle verdure sul consumo da parte dei bambini, attirarono grande attenzione mediatica ma si rivelarono in seguito non replicabili. Le conseguenze per Wansink furono severe: diciotto suoi articoli furono ritirati, sette ricevettero “espressioni di preoccupazione”, e quindici furono corretti. Nel 2019, Wansink si dimise dalla Cornell University dopo essere stato giudicato colpevole di cattiva condotta scientifica.\n\n82.5.2 Il Caso Sylvain Lesné\nUn altro esempio rilevante riguarda Sylvain Lesné e i suoi coautori che, nel 2006, pubblicarono su Nature un importante articolo sul morbo di Alzheimer. Questo lavoro era fondamentale per lo sviluppo dell’ipotesi amiloide, un meccanismo proposto per spiegare come la malattia affligge le sue vittime. La ricerca sulla malattia di Alzheimer, che colpisce oltre 50 milioni di persone nel mondo, ha ricevuto oltre un miliardo di dollari in finanziamenti governativi fino al 2022, incoraggiata da studi come quello di Lesné.\nNel 2022, il neuroscienziato Matthew Schrag scoprì immagini manipolate in questo e in molti altri articoli di Lesné, inclusi quelli che sostenevano l’ipotesi amiloide. Le immagini erano state manualmente modificate e accorpate per mostrare falsamente supporto alle ipotesi degli articoli. Queste frodi passarono inosservate attraverso i processi di peer review formali di Nature e di altre sei riviste accademiche, venendo infine scoperte solo tramite canali non ufficiali.\nLe conseguenze di queste scoperte furono lente e frammentarie. Gli altri coautori dell’articolo del 2006 alla fine accettarono di ritirarlo, ma non Lesné stesso. La lentezza della risposta a queste evidenze di frode, e il fatto che Lesné continui a essere finanziato dal National Institutes of Health e impiegato presso l’Università del Minnesota, dimostra un fallimento sistemico nell’affrontare la cattiva condotta scientifica.\n\n82.5.3 Altri Casi di Rilievo\nNel mondo accademico, diversi altri recenti scandali hanno messo in luce il problema della frode scientifica e le sue conseguenze spesso limitate per i responsabili. Ecco alcuni casi emblematici:\n\nMarc Tessier-Lavigne, ex presidente della Stanford University: Nel 2023, fu costretto a dimettersi dopo la rivelazione di dati falsificati in sue ricerche precedenti presso Genentech. Nonostante lo scandalo, Tessier-Lavigne ha subito conseguenze minime, diventando successivamente CEO di una nuova azienda di ricerca farmacologica. Lo scandalo fu portato alla luce grazie all’indagine condotta da Theo Baker, uno studente diciassettenne di Stanford.\n\nDan Ariely e Francesca Gino: Questi due rinomati psicologi, noti per le loro ricerche sulla disonestà e il comportamento non etico, sono stati coinvolti in uno scandalo di frode scientifica.\n\nDan Ariely, nel 2021, fu implicato nella fabbricazione di dati in un articolo del 2012 sulla disonestà.\nFrancesca Gino, docente presso la Harvard Business School, è stata accusata di aver presentato lavori contenenti risultati falsificati. Il sito del Dipartimento ora riporta che è in “administrative leave”.\n\n\n\nL’inefficacia delle istituzioni accademiche nel gestire la frode scientifica sembra riflettere un problema culturale di carattere sistemico. Gli incentivi attuali favoriscono la pubblicazione di risultati positivi e innovativi, spesso a scapito dell’integrità scientifica. Gli studiosi che resistono a queste pressioni rischiano di essere emarginati, mentre chi adotta pratiche discutibili per ottenere risultati desiderati viene premiato con finanziamenti, promozioni e prestigio accademico.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#cosa-significa-fallimento-della-replicazione",
    "href": "chapters/replication_crisis/01_crisis.html#cosa-significa-fallimento-della-replicazione",
    "title": "82  La crisi della replicazione",
    "section": "\n82.6 Cosa Significa “Fallimento della Replicazione”?",
    "text": "82.6 Cosa Significa “Fallimento della Replicazione”?\nIl fallimento della replicazione non coincide necessariamente con l’idea che il fenomeno studiato sia inesistente. Al contrario, le cause di un esito negativo in un tentativo di replicazione possono essere molteplici e spesso difficili da individuare con precisione. Comprendere queste ragioni è fondamentale per identificare le criticità metodologiche, migliorare il rigore scientifico e favorire il progresso della conoscenza. Al di là dei casi evidenti di frode, i fallimenti della replicazione rappresentano un’opportunità per riflettere sulla qualità delle pratiche di ricerca.\n\n82.6.1 Possibili Cause di Fallimento nella Replicazione\n\nFalsi positivi nello studio originale\nUn fallimento può indicare che lo studio originale abbia rilevato un effetto inesistente per puro caso. Questo rischio è particolarmente elevato in studi con campioni di piccole dimensioni e bassa potenza statistica, dove gli effetti riportati risultano spesso sovrastimati o instabili.\n\nFalsi negativi nella replica\nIl fallimento può derivare da un falso negativo, ovvero la mancata rilevazione di un effetto realmente esistente. Le cause principali includono:\n\nDifferenze metodologiche o di popolazione tra studio originale e replica.\n\nConfondenti metodologici o una potenza statistica insufficiente.\n\nPresenza di variabili moderatrici che influenzano l’intensità dell’effetto in determinati contesti.\n\n\n\n82.6.2 La Scienza tra Incertezza e Riproducibilità\nLa scienza raramente offre certezze assolute. Come evidenziato dall’Open Science Collaboration, un singolo studio, sia esso originale o di replica, non è sufficiente a fornire una risposta definitiva. Solo replicazioni multiple e sistematiche possono distinguere effetti reali da errori casuali, offrendo una visione più affidabile di un fenomeno. Questo approccio richiede tempo e risorse, ma rappresenta il cuore del metodo scientifico.\n\n82.6.3 Psicologia e Altri Campi\nSebbene la crisi della replicazione sia stata ampiamente discussa in psicologia, problemi simili affliggono molte altre discipline scientifiche. Studi di replicazione hanno evidenziato risultati preoccupanti: in oncologia, meno della metà degli studi replicati ha prodotto risultati coerenti, con tassi di riproducibilità estremamente bassi in alcuni casi; nelle neuroscienze, i tentativi di replicare correlazioni cervello-comportamento hanno mostrato un altissimo tasso di insuccesso. Anche in discipline come l’economia e la filosofia sperimentale, pur registrando tassi di replicazione relativamente più elevati, permangono dubbi sulla selezione degli studi replicati e sulla rappresentatività dei risultati (Pennington, 2023).\nQuesti dati dimostrano che la problematica della replicazione non è esclusiva della psicologia, ma comune a diverse aree del sapere. Tuttavia, sollevano anche un interrogativo critico: è corretto parlare di “crisi” o si tratta piuttosto di una fase di trasformazione necessaria per migliorare il rigore e la trasparenza nella ricerca scientifica?",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#dibattito-sulla-natura-della-crisi",
    "href": "chapters/replication_crisis/01_crisis.html#dibattito-sulla-natura-della-crisi",
    "title": "82  La crisi della replicazione",
    "section": "\n82.7 Dibattito sulla Natura della Crisi",
    "text": "82.7 Dibattito sulla Natura della Crisi\nIl tema della crisi della replicazione ha suscitato un dibattito acceso e opinioni contrastanti all’interno della comunità scientifica:\n\nApproccio alle repliche: Alcuni ricercatori ritengono che le repliche esatte siano poco significative, preferendo le repliche concettuali che possano approfondire la comprensione di un fenomeno. Altri, invece, sostengono che solo repliche rigorose ed esatte siano in grado di verificare la robustezza di un effetto, garantendo maggiore affidabilità.\nInterpretazione dei dati dell’Open Science Collaboration (OSC): Il tasso di successo delle repliche riportato dall’OSC, pari al 36%, ha alimentato ulteriori discussioni. Alcuni attribuiscono questo risultato a differenze metodologiche tra studi originali e tentativi di replica, come campioni diversi o contesti modificati. Tuttavia, ricerche successive hanno smentito queste ipotesi, indicando che tali variazioni non spiegano interamente i bassi tassi di replicazione.\n\nInvece di considerare i fallimenti di replicazione come una crisi, molti studiosi li interpretano come un’opportunità per rafforzare la scienza. La replicazione, infatti, rappresenta un elemento fondamentale del metodo scientifico: permette di identificare i limiti di un fenomeno e di migliorare la comprensione delle condizioni in cui si manifesta. Ogni fallimento diventa, così, uno stimolo per il progresso.\nQuesta visione ha dato origine a un movimento noto come “rivoluzione della credibilità”, che punta a migliorare la qualità della ricerca attraverso trasparenza, autocorrezione e valorizzazione delle repliche. Progetti come il Loss of Confidence dimostrano che riconoscere i limiti e le incertezze degli studi precedenti non rappresenta una debolezza, ma un segno di integrità scientifica.\nIl passaggio dalla percezione di crisi a una rivoluzione della credibilità rappresenta un profondo cambiamento culturale nella comunità accademica. La scienza non è un processo statico, ma un percorso dinamico che evolve grazie al confronto critico e alla riflessione. In questa prospettiva, ogni fallimento nella replicazione non è un punto d’arrivo, ma un trampolino di lancio verso una conoscenza più affidabile e trasparente.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#cause-della-crisi",
    "href": "chapters/replication_crisis/01_crisis.html#cause-della-crisi",
    "title": "82  La crisi della replicazione",
    "section": "\n82.8 Cause della Crisi",
    "text": "82.8 Cause della Crisi\n\n82.8.1 Incentivi Accademici e la Dominanza della Quantità sulla Qualità\nPer comprendere a fondo le problematiche che affliggono il mondo della ricerca, è essenziale considerare il contesto lavorativo in cui operano i ricercatori. Sebbene spesso vengano idealizzati come figure obiettive e razionali, è fondamentale ricordare che sono anche esseri umani, soggetti a pressioni professionali, responsabilità economiche e ambizioni di carriera. Il loro lavoro è costantemente sottoposto a valutazione: oltre a gestire attività didattiche e amministrative, devono pubblicare articoli su riviste di prestigio e assicurarsi finanziamenti per sostenere i loro gruppi di ricerca. Questo sistema premia la quantità a discapito della qualità, favorendo una mentalità di “pubblica o perisci”.\nLa pressione a pubblicare incessantemente è una delle principali cause dei problemi che alimentano la crisi di replicazione nella scienza. La cultura del “publish or perish” spinge i ricercatori a produrre rapidamente risultati rilevanti, spesso a scapito della rigorosità metodologica e della riproducibilità (Gopalakrishna et al., 2022; Grimes et al., 2018).\nQuesta situazione genera un paradosso: ciò che favorisce la carriera individuale di uno scienziato non sempre coincide con gli interessi del progresso scientifico. Le motivazioni intrinseche di contribuire alla conoscenza vengono spesso offuscate da motivazioni estrinseche legate a indicatori di produttività accademica. Non sorprende, quindi, che oltre il 60% dei ricercatori individui questa pressione come una delle principali cause dei problemi legati alla replicazione e alla riproducibilità.\n\n82.8.2 Bias Cognitivi e Distorsioni nella Ricerca\nI bias cognitivi rappresentano un ulteriore ostacolo alla qualità della ricerca. Tra i principali si trovano:\n\n\nBias di conferma: la tendenza a cercare o interpretare informazioni che confermano le proprie ipotesi iniziali, trascurando dati contrari.\n\nApofenia: il riconoscimento di schemi in dati casuali, spesso combinato con una preferenza per risultati positivi.\n\nBias retrospettivo: la convinzione che un evento fosse prevedibile solo dopo che si è verificato, portando i ricercatori a presentare risultati in modo fuorviante.\n\nQuesti bias favoriscono la ricerca di risultati positivi a scapito di quelli nulli o contrari, contribuendo a creare un problema più grande: il bias di pubblicazione.\n\n82.8.3 Bias di Pubblicazione e il Problema dei “File Drawer”\nIl sistema di pubblicazione accademica incentiva risultati innovativi e positivi, spesso trascurando studi con risultati nulli o repliche. Questo bias, noto come file drawer problem, descrive la tendenza a relegare nei “cassetti” studi non statisticamente significativi, rendendoli inaccessibili e distorcendo la letteratura scientifica.\nIn psicologia, l’impatto di questo fenomeno è particolarmente grave. Studi hanno rilevato che oltre il 90% degli articoli in psicologia riporta risultati positivi, una percentuale notevolmente più alta rispetto ad altre discipline. Questo non solo crea una rappresentazione distorta della realtà, ma amplifica il rischio di undead theories, teorie prive di solide basi empiriche che continuano a dominare il dibattito scientifico.\n\n82.8.4 Pratiche di Ricerca Dubbiamente Etiche\nLa pressione a pubblicare ha portato all’emergere di comportamenti noti come Questionable Research Practices (QRPs). Tra questi:\n\n\nP-hacking: manipolazione dei dati o analisi fino a ottenere un p-value significativo (&lt; 0.05).\n\nHARKing (Hypothesizing After Results are Known): modificare l’ipotesi iniziale per adattarla ai risultati ottenuti.\n\nStopping opzionale: interrompere la raccolta dei dati quando si raggiunge un p-value desiderato.\n\nQueste pratiche, pur non essendo sempre considerate frodi, distorcono i risultati e compromettono la replicabilità degli studi, creando teorie difficili da falsificare.\n\n82.8.5 La Centralità dei Valori-p e la Crisi della Significatività Statistica\nIl valore-p, elemento centrale della metodologia scientifica basata sull’ipotesi nulla (Null Hypothesis Significance Testing), è diventato una “valuta” per la pubblicazione. Tuttavia, affidarsi esclusivamente ai valori-p presenta gravi limiti:\n\n\nParadosso di Lindley: con campioni di grandi dimensioni, valori-p vicini a 0.05 possono supportare l’ipotesi nulla invece di confutarla.\n\nDistorsioni da QRPs: l’utilizzo di pratiche discutibili può produrre falsi positivi statisticamente significativi.\n\nBenché alcuni studiosi abbiano proposto l’abbassamento della soglia di significatività statistica a 0.005 o l’integrazione dei valori-p con stime degli effetti e intervalli di confidenza, il punto centrale continua ad essere il fatto che l’enfasi dovrebbe spostarsi dai risultati statistici alla qualità metodologica degli studi.\nPer affrontare questi problemi, è necessario un cambiamento culturale e strutturale. La trasparenza, l’autocorrezione e l’adozione di pratiche come la preregistrazione degli studi possono aiutare a ridurre l’impatto dei bias e delle QRPs. Inoltre, incentivare repliche rigorose e promuovere un sistema di pubblicazione che premi la qualità rispetto alla quantità sono passi fondamentali per migliorare la credibilità della scienza.\n\n82.8.6 Campioni Troppo Piccoli\nUno dei fattori chiave che contribuiscono alla crisi della replicazione in psicologia è l’uso di campioni di dimensioni ridotte. Questo approccio ha permesso ai ricercatori di massimizzare la quantità di pubblicazioni a scapito della qualità e dell’affidabilità degli effetti rilevati. Higginson e Munafò (2016) sottolineano come questo fenomeno rappresenti una “selezione naturale della cattiva scienza”, dove incentivi strutturali premiano metodologie di ricerca poco rigorose.\nContrariamente a quanto si potrebbe pensare, ottenere un effetto significativo con un campione piccolo non garantisce che lo stesso effetto rimanga significativo con un campione più grande. Questo problema è strettamente legato alla potenza statistica, che rappresenta la probabilità, nel lungo periodo, di rifiutare correttamente l’ipotesi nulla quando l’ipotesi alternativa è vera. Una potenza statistica bassa comporta un’elevata probabilità di errori di Tipo II (falsi negativi) e, allo stesso tempo, riduce la probabilità che un risultato significativo rifletta un effetto reale.\nIn psicologia, la potenza statistica viene solitamente fissata a un minimo dell’80%, il che significa che, nel lungo termine, uno studio dovrebbe avere l’80% di possibilità di rilevare un effetto reale. Tuttavia, molti studi più datati raramente menzionano la potenza statistica, nonostante il concetto sia noto dagli anni ’30. Questo ha contribuito a generare una letteratura scientifica con effetti sovrastimati o poco affidabili.\nIn un approccio frequentista, per calcolare la potenza di uno studio, è necessario conoscere almeno due dei seguenti tre parametri: dimensione dell’effetto atteso, criterio di significatività e dimensione del campione pianificata. Per esempio, un ricercatore che si aspetta di trovare un effetto “medio” (Cohen’s d = 0.50) con un criterio di significatività di p &lt; .05 può determinare la dimensione del campione necessaria per garantire una potenza sufficiente. Tuttavia, molti studi psicologici hanno ignorato questo tipo di pianificazione, basandosi su campioni troppo piccoli per rilevare effetti affidabili.\nL’uso di campioni piccoli, combinato con pratiche discutibili di ricerca (Questionable Research Practices, QRPs) e bias di pubblicazione, ha portato a una letteratura scientifica piena di effetti inflazionati. Ad esempio, meta-analisi iniziali sul concetto di esaurimento dell’ego (ego depletion) stimavano un effetto medio (d = 0.62). Tuttavia, repliche successive hanno trovato effetti molto più piccoli, spesso inferiori a d = 0.10. Allo stesso modo, il progetto dell’Open Science Collaboration (2015) ha evidenziato che le dimensioni degli effetti nelle repliche erano, in media, dimezzate rispetto agli studi originali.\nCampioni di piccole dimensioni non solo riducono la probabilità di rilevare effetti reali, ma compromettono anche la credibilità dei risultati significativi. Una bassa potenza statistica mina l’obiettivo fondamentale della ricerca scientifica, limitando la capacità di trarre conclusioni solide e contribuendo alla crisi della replicazione. Per migliorare la qualità della scienza, è essenziale adottare pratiche di ricerca più rigorose, pianificando adeguatamente la dimensione del campione e garantendo una potenza statistica sufficiente.\n\n82.8.7 La Misurazione: Un Problema Sottovalutato\nOltre alle dimensioni campionarie inadeguate, la psicologia potrebbe soffrire di problemi legati alla misurazione. Per rispondere a domande scientifiche, i ricercatori devono definire e misurare con precisione il costrutto oggetto di indagine. Ad esempio, per investigare se una mentalità di crescita possa migliorare l’intelligenza, un ricercatore deve prima definire e poi misurare sia la mentalità che l’intelligenza. Tuttavia, la misurazione è un processo complesso e impegnativo.\nL’intelligenza è un costrutto latente, il che significa che, a differenza dell’altezza di una persona, non può essere osservata o misurata direttamente. Gli psicologi inferiscono l’intelligenza stimando il quoziente intellettivo (QI) di un individuo, basandosi sulle risposte a numerose domande di un test di intelligenza, adattate all’età del partecipante. Ma come possiamo sapere se il QI rappresenta un buon indicatore dell’intelligenza? È necessario valutare la validità di costrutto, definita come la capacità di una misura di comportarsi in modo coerente con le ipotesi teoriche (Cronbach e Meehl, 1955; Fink, 2010). Alcuni ricercatori hanno sostenuto che una spiegazione spesso trascurata della crisi della replicazione risieda nella scarsa validità di costrutto delle nostre misure (Lilienfeld e Strother, 2020; Loken e Gelman, 2017).\nPer evidenziare il problema della misurazione in psicologia, Flake e colleghi hanno condotto una revisione di articoli pubblicati in una rivista prestigiosa. La loro analisi ha mostrato che molte scale di misurazione utilizzate non avevano una chiara fonte dichiarata, mentre altre erano state sviluppate senza una documentazione adeguata. Inoltre, una parte significativa delle scale citate era stata modificata rispetto alla versione originale, rendendo sconosciute le loro proprietà psicometriche.\nGli autori hanno anche rilevato l’uso di Pratiche di Misurazione Discutibili (Questionable Measurement Practices, QMPs), che includono la mancata divulgazione di informazioni sulla validità delle misure quando questa non risulta soddisfacente. Questi problemi suggeriscono che molti costrutti psicologici non siano adeguatamente validati, un fattore che potrebbe contribuire alle difficoltà di replicazione degli studi.\nAltri ricercatori hanno argomentato che problemi di validità interna ed esterna possano contribuire alla crisi della replicazione (Fabrigar et al., 2020). La validità interna si riferisce a come uno studio stabilisce una relazione di causa-effetto tra le variabili indipendenti e dipendenti (Cook e Campbell, 1979). Fabrigar et al. suggeriscono che un tentativo di replicazione possa fallire se:\n\nLo studio originale ha sofferto di minacce alla validità che hanno causato un effetto spurio (alta validità interna nella replica).\nI ricercatori introducono elementi assenti nello studio originale (bassa validità interna nella replica).\n\nLa validità esterna riguarda la possibilità di generalizzare i risultati di uno studio ad altri contesti o popolazioni. Questo può influenzare le repliche se, ad esempio, la replica viene condotta su una popolazione diversa o se i materiali dello studio sono tradotti da un’altra lingua, causando incomprensioni nei partecipanti.\nPer sintetizzare questi problemi, Flake e Fried (2020) li definiscono “measurement schmeasurement”, espressione che descrive la mancanza di attenzione verso la validità delle misure nella scienza psicologica. Se le misure utilizzate in uno studio non sono valide, ne consegue che anche i risultati e le conclusioni tratte non possono essere considerati affidabili. Quando tali studi vengono replicati, potrebbero essere destinati al fallimento ancor prima di iniziare.\n\n82.8.8 La Novità a Scapito della Replicazione: Una Distorsione nella Ricerca\nL’enfasi eccessiva sui risultati innovativi e il valore attribuito alle scoperte significative stanno incentivando pratiche di ricerca distorte, favorendo la sovrarappresentazione di risultati positivi e una mancanza di rigore metodologico (Ferguson & Heene, 2012; Ware & Munafò, 2015).\nLa psicologia sperimentale, nata nel 1879 con il primo laboratorio fondato da Wilhelm Wundt, si trova oggi a fronteggiare una crisi di replicazione nonostante oltre un secolo di progresso scientifico. Una delle principali cause è la scarsa attenzione dedicata agli studi di replicazione, storicamente poco valorizzati e raramente premiati nelle scienze sociali.\nLa cultura accademica attuale privilegia la novità e i risultati positivi, relegando i risultati nulli e gli studi di replicazione a un ruolo marginale. Questo fenomeno riflette ciò che Antonakis (2017) definisce significosis – un’ossessione per i risultati significativi – e neofilia – un’eccessiva enfasi sulla novità. Già Sterling (1959) aveva messo in guardia contro il rischio che i ricercatori testassero ripetutamente un’ipotesi fino a ottenere, per puro caso, un risultato significativo, senza verificarlo attraverso replicazioni. In assenza di queste verifiche, interi ambiti di studio possono essere costruiti su un numero allarmante di affermazioni non supportate da dati solidi.\nQuesto squilibrio si riflette non solo nella letteratura scientifica, ma anche nei progetti di ricerca condotti dagli studenti. Le tesi di laurea in psicologia, spesso realizzate in autonomia, senza finanziamenti e con tempistiche ridotte, soffrono degli stessi problemi della ricerca accademica: campioni di piccole dimensioni, studi sottopotenziati e un’elevata probabilità di falsi positivi. Se pubblicati selettivamente, questi progetti rischiano di premiare la fortuna più della qualità scientifica.\nIniziative come il Collaborative Replications and Education Project (CREP) rappresentano un passo verso un cambiamento culturale. CREP incoraggia gli studenti a condurre studi di replicazione come parte del loro percorso formativo, promuovendo una scienza più collaborativa, rigorosa e orientata alla verifica dei risultati, contrastando così la prevalenza della novità fine a se stessa.\n\n82.8.9 La scienza non si autocorregge come dovrebbe\nUn principio cardine della scienza è l’autocorrezione, ma nella pratica accademica moderna, questo processo sembra spesso ostacolato da incentivi e preoccupazioni reputazionali. I ricercatori, pressati dalle scadenze per nuovi progetti o richieste di finanziamento, raramente dedicano il tempo necessario a rivedere e correggere i propri lavori passati. Questo mancato impegno rappresenta una delle spiegazioni della crisi di replicazione.\nUn esempio significativo è il Registered Replication Report dello studio di Srull e Wyer (1979), replicato da McCarthy et al. (2018). Lo studio originale aveva mostrato che il priming con stimoli aggressivi portava i partecipanti a interpretare un comportamento ambiguo come più ostile. Tuttavia, il tentativo di replicazione ha rilevato un effetto trascurabile. Una possibile spiegazione è che alcune statistiche dello studio originale fossero riportate in modo errato, un errore che, nonostante tutto, non è mai stato corretto. Similmente, altri casi documentano gravi discrepanze nei dati riportati in letteratura, come dimostrato da van der Zee et al. (2017) nel loro riesame di articoli del Cornell Food Lab, che ha rivelato oltre 150 incongruenze.\nLa microbiologa Elizabeth Bik ha inoltre evidenziato che la manipolazione di immagini scientifiche è diventata una forma emergente di cattiva condotta, volta a rendere i risultati più impressionanti o a mascherare dati problematici. Sebbene alcuni casi di manipolazione portino a ritrazioni o correzioni, il lavoro di revisione è spesso svolto da altri ricercatori come attività volontaria, suggerendo che la scienza sia più “eterocorrettiva” che autocorrettiva.\nNonostante le difficoltà, il processo di autocorrezione è fondamentale per il progresso scientifico. Vazire (2020) sostiene che il disagio provocato dalla revisione critica sia salutare e necessiti di una maggiore umiltà intellettuale da parte dei ricercatori. Questo include il riconoscimento pubblico delle limitazioni dei propri studi e, quando necessario, la pubblicazione di correzioni o dichiarazioni di perdita di fiducia nei risultati originali.\n\n82.8.10 La Scienza Chiusa come Ostacolo alla Replicazione\nUno degli ostacoli principali alla replicazione è la mancanza di trasparenza e dettaglio negli studi precedenti. In un sistema di “scienza chiusa,” in cui dati e metodi sono trattati come segreti industriali, ricreare esperimenti e verificare analisi diventa un’impresa ardua, se non impossibile. Questa opacità interessa molti aspetti della ricerca, dai materiali utilizzati ai dati raccolti, fino alle scelte analitiche effettuate durante lo studio.\nPratiche come la reportistica selettiva e la flessibilità non dichiarata nei metodi e nei dati compromettono l’integrità della scienza. La riluttanza a condividere dati e materiali, insieme al bias di pubblicazione che favorisce i risultati significativi rispetto a quelli nulli, amplifica ulteriormente il problema (Bruton et al., 2020; Nosek et al., 2012).\nUn esempio concreto riguarda le decisioni prese durante l’analisi dei dati, come la gestione dei valori anomali o le correzioni per analisi multiple. Queste scelte possono avere un impatto notevole sui risultati, ma se non vengono documentate in modo trasparente, altri ricercatori non saranno in grado di replicare gli stessi risultati. Questo problema è noto come il giardino dei sentieri che si biforcano (garden of forking paths), dove una serie di decisioni non esplicitate porta a risultati divergenti e difficili da verificare (Gelman & Loken, 2013).\n\n\n\n\n\n\nLo psicologo Paul Meehl condusse uno studio su un campione di cinquantasettamila studenti delle scuole superiori del Minnesota, indagando su variabili quali religione, abitudini nel tempo libero, ordine di nascita, numero di fratelli, piani post-diploma e numerosi altri aspetti (Meehl, 2012). Complessivamente, le diverse risposte dei partecipanti potevano essere combinate in 990 modi distinti, permettendo analisi del tipo: “Gli studenti appassionati di cucina hanno una maggiore probabilità di essere figli unici?” o “Gli studenti provenienti da famiglie battiste sono più inclini a partecipare a club politici scolastici?”. Meehl evidenziò che, analizzando i dati, il 92% di queste possibili combinazioni risultava in correlazioni statisticamente significative. Queste differenze, sebbene reali, presumibilmente derivano da cause multifattoriali e complesse.\nAndrew Gelman ha denominato questo fenomeno Il Giardino dei Sentieri che si Biforcano [Garden of Forking Paths; Gelman & Loken (2013)], riferendosi ai molteplici gradi di libertà a disposizione del ricercatore nell’analisi dei dati. Come nell’esempio di Meehl, è possibile esaminare le differenze intergruppo (se questo è l’oggetto di interesse) da molteplici prospettive. Con un campione sufficientemente ampio, alcune di queste differenze risulteranno “statisticamente significative”. Ciò indica che, in quello specifico campione, quel particolare aspetto dei dati è rilevante. Tuttavia, questa differenza “statisticamente significativa” non sarà necessariamente generalizzabile ad un altro campione, il quale presenterà le proprie idiosincrasie.\nIn altri termini, come sottolineato da Gelman & Loken (2013), l’approccio basato sul test dell’ipotesi nulla si limita a “descrivere il rumore”. Da un punto di vista teorico, simili esercizi statistici risultano privi di valore euristico e non contribuiscono in nessun modo all’avanzamento delle conoscenze sul fenomeno oggetto di studio.\nIn un’ottica di inferenza statistica, questo problema è riconducibile al concetto di “p-hacking” o “data dredging”, dove l’esplorazione esaustiva di molteplici ipotesi statistiche su un singolo set di dati può portare a falsi positivi e a una sovrastima della significatività statistica.\n\n\n\nLa soluzione è chiara: promuovere una cultura di apertura, rendendo dati e metodi accessibili. Nonostante i progressi tecnologici che facilitano la condivisione, questa pratica rimane poco diffusa. Sebbene esistano ragioni valide per non condividere i dati, come la tutela dell’anonimato dei partecipanti, tali motivazioni dovrebbero essere dichiarate in modo esplicito e rigoroso.\nQuesti ostacoli sottolineano l’urgenza di una trasformazione culturale all’interno della comunità scientifica, che favorisca trasparenza e collaborazione. Affrontare queste limitazioni strutturali è essenziale per superare la crisi di replicazione, permettendo alla scienza di avanzare in modo più affidabile e autoregolarsi nel tempo.\n\n82.8.11 La Probabilità Inversa\nOltre a questi fattori, alcuni studiosi sostengono che la radice della crisi della replicazione sia ancora più profonda e risieda nell’approccio statistico stesso, ampiamente adottato dalla comunità scientifica (Chivers, 2024; Gelman & Loken, 2014; Loken & Gelman, 2017). Questo punto di vista suggerisce che le difficoltà nella replicazione dei risultati non siano solo il prodotto di comportamenti individuali discutibili, ma derivino in larga parte da un’interpretazione e un’applicazione problematica dei metodi statistici.\nPer comprendere meglio questa questione, dobbiamo tornare alle basi della statistica inferenziale. L’approccio frequentista, dominante nella ricerca scientifica, si basa sulle probabilità di campionamento. Questo metodo, che risale a Jakob Bernoulli nel XVIII secolo, calcola la probabilità di osservare certi dati assumendo che una determinata ipotesi sia vera. Il famoso “p-value” è un esempio di questa logica: esso indica la probabilità di ottenere risultati estremi quanto o più estremi di quelli osservati, supponendo che l’ipotesi nulla sia vera.\nTuttavia, questo approccio ha un limite fondamentale: non ci dice direttamente quanto è probabile che la nostra ipotesi sia vera alla luce dei dati raccolti. In altre parole, non fornisce una “probabilità inferenziale”, cioè la probabilità che l’ipotesi sia corretta in base ai risultati ottenuti. Qui entra in gioco l’approccio bayesiano. Il teorema di Bayes offre un metodo per calcolare proprio questa probabilità inferenziale. L’approccio bayesiano tiene conto non solo dei dati osservati, ma anche delle conoscenze pregresse (le “prior”) relative all’ipotesi in esame.\nLa differenza tra questi due approcci è cruciale. Mentre il p-value ci dice quanto sono improbabili i nostri dati se l’ipotesi nulla è vera, l’approccio bayesiano ci fornisce la probabilità che la nostra ipotesi sia vera alla luce dei dati raccolti e delle conoscenze precedenti.\n\n82.8.12 Implicazioni per la Pratica Scientifica\nQuesta distinzione ha implicazioni profonde per la pratica scientifica. L’uso esclusivo dell’approccio frequentista può portare a sovrastimare la forza delle evidenze a favore di un’ipotesi, specialmente quando si lavora con campioni piccoli o si conducono molti test statistici, come spesso accade in psicologia.\nAlcune soluzioni proposte per affrontare la crisi della replicazione includono:\n\nAbbassare la soglia di significatività statistica, rendendo più difficile dichiarare un risultato “significativo”.\nRichiedere la preregistrazione delle ipotesi per prevenire l’HARKing (Hypothesizing After Results are Known).\nFar sì che le riviste accettino gli articoli basandosi sui metodi piuttosto che sui risultati, per evitare il bias verso la pubblicazione di risultati solo “positivi” o “nuovi”.\n\nTuttavia, queste soluzioni, pur utili, non affrontano il problema fondamentale dell’interpretazione delle evidenze statistiche. L’adozione di un approccio bayesiano offre una soluzione più radicale, fornendo un quadro più completo e realistico della forza delle evidenze a favore o contro un’ipotesi scientifica.\n\n82.8.12.1 Guardare i Dati\nConsideriamo una simulazione, ispirata da Lakens (2015), che illustra come una pratica apparentemente innocua – osservare i risultati man mano che vengono raccolti nell’approccio frequentista – possa avere conseguenze significative sulle conclusioni di uno studio. In particolare, questa pratica può influire sulla probabilità di ottenere un risultato statisticamente significativo.\nNella simulazione seguente, due campioni casuali vengono estratti dalla stessa popolazione normale di partenza. Di conseguenza, l’“ipotesi nulla” è vera: non c’è differenza tra le medie delle popolazioni. Tuttavia, a causa della variabilità campionaria, il p-valore risulta fortemente influenzato da ogni singola osservazione aggiunta al campione.\n\nsimulate_t_tests &lt;- function(seed, max_sample_size, mu = 0, sigma = 1) {\n  set.seed(seed)\n\n  # Intervallo di grandezza campionaria\n  sample_sizes &lt;- seq(2, max_sample_size, by = 2)\n  p_values &lt;- numeric(length(sample_sizes))\n\n  # Genera due campioni grandi iniziali da una distribuzione normale\n  full_sample1 &lt;- rnorm(max_sample_size, mean = mu, sd = sigma)\n  full_sample2 &lt;- rnorm(max_sample_size, mean = mu, sd = sigma)\n\n  # Simulazione\n  for (i in seq_along(sample_sizes)) {\n    n &lt;- sample_sizes[i]\n\n    # Estrai sottoinsiemi incrementali dai campioni completi\n    sample1 &lt;- full_sample1[1:n]\n    sample2 &lt;- full_sample2[1:n]\n\n    # Esegui il t-test per il confronto delle medie di due gruppi indipendenti\n    t_test &lt;- t.test(sample1, sample2, var.equal = TRUE)\n    p_values[i] &lt;- t_test$p.value\n  }\n\n  # Crea il grafico del p-valore in funzione della grandezza campionaria\n  plot(\n    sample_sizes, p_values, type = \"l\", col = \"#b97c7c\",\n    xlab = \"Grandezza Campionaria\", ylab = \"P-valore\",\n    main = \"P-valore in funzione della grandezza campionaria\"\n  )\n  abline(h = 0.05, col = \"#8f2727\", lty = 2, lwd = 1.5)\n  legend(\"topright\", legend = \"Significatività a 0.05\", col = \"#8f2727\", lty = 2, cex = 0.8)\n}\n\nNelle due simulazioni seguenti, osserviamo come il p-valore cambi progressivamente aumentando la dimensione dei campioni casuali da \\(n = 2\\) a \\(n = 300\\). È evidente come il p-valore vari drasticamente con l’aggiunta di nuove osservazioni ai campioni. Inoltre, in alcune configurazioni, il p-valore può scendere al di sotto della soglia critica di 0.05 per puro caso. Se un ricercatore interrompesse la raccolta dei dati in quel momento, otterrebbe un risultato “statisticamente significativo”, pur avendo campioni estratti dalla stessa popolazione.\n\nsimulate_t_tests(seed = 1234, max_sample_size = 300, mu = 0, sigma = 2)\nsimulate_t_tests(seed = 2, max_sample_size = 300, mu = 0, sigma = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuesta simulazione mette in evidenza una limitazione fondamentale dell’approccio frequentista: ogni test statistico considera esclusivamente i dati del campione corrente, ignorando le conoscenze accumulate in precedenza. Questo rende il processo decisionale estremamente volatile, poiché, teoricamente, ad ogni nuovo studio si “dimentica” tutta l’informazione derivante dagli studi precedenti.\n\n82.8.12.2 Analisi Bayesiana\nL’approccio bayesiano offre una soluzione elegante a questo problema. Nel framework bayesiano, la distribuzione a posteriori (cioè, la nostra convinzione aggiornata dopo aver osservato i dati) bilancia sempre l’informazione a priori (ciò che sapevamo prima dell’esperimento) con la verosimiglianza (ciò che i dati ci dicono). Questo equilibrio è particolarmente prezioso quando i dati sono deboli o contengono molto rumore, come nel caso dei dati della simulazione che stiamo discutendo. In tali situazioni, l’informazione a priori assume un ruolo più rilevante, impedendo conclusioni affrettate basate su dati poco informativi.\nPer illustrare questa differenza, consideriamo l’analisi bayesiana dei dati simulati in precedenza. Se questi dati vengono analizzati con l’approccio frequentista, forniscono un risultato “statisticamente significativo”, suggerendo una differenza tra i due gruppi.\nTuttavia, analizzando gli stessi dati con un approccio bayesiano, otteniamo un intervallo di credibilità al 95% compreso tra -0.52 e 1.12. Poiché questo intervallo include lo zero, possiamo affermare, con un livello di certezza soggettiva del 95%, che non c’è una differenza sostanziale tra le medie delle due popolazioni da cui sono stati estratti i campioni.\nQuesta discrepanza nei risultati evidenzia un punto cruciale: l’approccio bayesiano è più resistente ai falsi positivi in presenza di dati rumorosi o campioni piccoli. Invece di forzare una decisione binaria (significativo/non significativo) basata su una soglia arbitraria, l’analisi bayesiana fornisce una rappresentazione più sfumata e realistica dell’incertezza associata alle nostre conclusioni.\nInoltre, l’approccio bayesiano offre il vantaggio di essere cumulativo: ogni nuovo studio non parte da zero, ma incorpora naturalmente le conoscenze precedenti attraverso la distribuzione a priori.\n\n# Imposta il seme per la riproducibilità\nset.seed(12)\n\n# Parametri della distribuzione normale\nmu &lt;- 0\nsigma &lt;- 2\nmax_sample_size &lt;- 50\n\n# Genera due campioni indipendenti\nfull_sample1 &lt;- rnorm(max_sample_size, mean = mu, sd = sigma)\nfull_sample2 &lt;- rnorm(max_sample_size, mean = mu, sd = sigma)\n\n\n# Prepara i dati per Stan\nstan_data &lt;- list(\n  N1 = length(full_sample1),\n  N2 = length(full_sample2),\n  y1 = full_sample1,\n  y2 = full_sample2\n)\n\n# Visualizza i dati preparati\nprint(stan_data)\n#&gt; $N1\n#&gt; [1] 50\n#&gt; \n#&gt; $N2\n#&gt; [1] 50\n#&gt; \n#&gt; $y1\n#&gt;  [1] -2.9611  3.1543 -1.9135 -1.8400 -3.9953 -0.5446 -0.6307 -1.2565 -0.2129\n#&gt; [10]  0.8560 -1.5554 -2.5878 -1.5591  0.0239 -0.3048 -1.4069  2.3778  0.6810\n#&gt; [19]  1.0139 -0.5866  0.4473  4.0144  2.0240 -0.6049 -2.0505 -0.5348 -0.3982\n#&gt; [28]  0.2622  0.2916  0.7241  1.3480  4.1441 -1.0821 -2.1410 -0.7449 -0.9703\n#&gt; [37]  0.5496 -0.9590  1.5962 -2.0089  0.2100 -2.3120  1.1563 -3.1913 -0.6170\n#&gt; [46]  0.8989 -1.9541  0.3800  1.4629 -0.9852\n#&gt; \n#&gt; $y2\n#&gt;  [1] -0.085370 -0.225341  0.913654  4.040670 -2.101780  1.469304  1.078499\n#&gt;  [8] -2.628546 -0.500077  0.628409  0.813093  1.988841  1.711537  0.394258\n#&gt; [15]  1.668650  1.693580  3.908211 -4.298520  1.942241  2.290123 -1.050801\n#&gt; [22]  0.500640 -0.858813 -0.365039 -0.206621 -1.267676 -2.542108 -0.767901\n#&gt; [29]  1.033512 -0.355937  0.008516 -2.548119 -0.404221  2.328932 -0.046759\n#&gt; [36]  1.794313 -0.353449  2.227418 -1.083778 -1.926797  0.752897 -1.969348\n#&gt; [43]  1.795119  0.258525  2.067406 -0.684579  0.904563 -1.389476 -0.478027\n#&gt; [50] -2.014598\n\n\n# Path to the Stan file\nstan_file &lt;- here::here(\"stan\", \"two_means_diff.stan\")\n\n# Create a CmdStanModel object\nmod &lt;- cmdstan_model(stan_file)\nmod$code() # Stampa il codice del modello\n#&gt;  [1] \"data {\"                                                                \n#&gt;  [2] \"  int&lt;lower=0&gt; N1; // Numero di osservazioni nel gruppo 1\"             \n#&gt;  [3] \"  int&lt;lower=0&gt; N2; // Numero di osservazioni nel gruppo 2\"             \n#&gt;  [4] \"  vector[N1] y1; // Dati del gruppo 1\"                                 \n#&gt;  [5] \"  vector[N2] y2; // Dati del gruppo 2\"                                 \n#&gt;  [6] \"}\"                                                                     \n#&gt;  [7] \"parameters {\"                                                          \n#&gt;  [8] \"  real mu1; // Media del gruppo 1\"                                     \n#&gt;  [9] \"  real delta; // Differenza tra le medie\"                              \n#&gt; [10] \"  real&lt;lower=0&gt; sigma; // Deviazione standard comune\"                  \n#&gt; [11] \"  real&lt;lower=0&gt; nu; // Gradi di libertà per la distribuzione t\"        \n#&gt; [12] \"}\"                                                                     \n#&gt; [13] \"transformed parameters {\"                                              \n#&gt; [14] \"  real mu2; // Media del gruppo 2\"                                     \n#&gt; [15] \"  mu2 = mu1 + delta;\"                                                  \n#&gt; [16] \"}\"                                                                     \n#&gt; [17] \"model {\"                                                               \n#&gt; [18] \"  // Priori\"                                                           \n#&gt; [19] \"  mu1 ~ normal(0, 5);\"                                                 \n#&gt; [20] \"  delta ~ normal(0, 2); // Priore su delta\"                            \n#&gt; [21] \"  sigma ~ cauchy(0, 5);\"                                               \n#&gt; [22] \"  nu ~ gamma(2, 0.1); // Priore sulla t-student\"                       \n#&gt; [23] \"  \"                                                                    \n#&gt; [24] \"  // Verosimiglianza\"                                                  \n#&gt; [25] \"  y1 ~ student_t(nu, mu1, sigma);\"                                     \n#&gt; [26] \"  y2 ~ student_t(nu, mu2, sigma);\"                                     \n#&gt; [27] \"}\"                                                                     \n#&gt; [28] \"generated quantities {\"                                                \n#&gt; [29] \"  real diff; // Differenza tra le medie (alias di delta per chiarezza)\"\n#&gt; [30] \"  diff = delta;\"                                                       \n#&gt; [31] \"}\"\n\nEsegui il campionamento:\n\nfit &lt;- mod$sample(\n  data = stan_data,\n  seed = 123,\n  chains = 4,\n  iter_sampling = 2000,\n  iter_warmup = 1000,\n  show_messages = FALSE\n)\n\nRiassumi i risultati per mu1, mu2 e delta:\n\nfit_summary &lt;- fit$summary(variables = c(\"mu1\", \"mu2\", \"delta\"))\nprint(fit_summary)\n#&gt; # A tibble: 3 × 10\n#&gt;   variable   mean median    sd   mad      q5    q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 mu1      -0.313 -0.312 0.241 0.238 -0.707  0.0818  1.00    5378.    5491.\n#&gt; 2 mu2       0.164  0.166 0.246 0.248 -0.235  0.568   1.00    9428.    6234.\n#&gt; 3 delta     0.477  0.474 0.341 0.344 -0.0887 1.04    1.00    5155.    5260.\n\nEstrai i campioni di delta:\n\ndelta_samples &lt;- fit$draws(variables = \"delta\", format = \"matrix\")[, 1]\n\nDisegna la distribuzione a posteriori di delta:\n\ndelta_df &lt;- data.frame(delta = delta_samples)\n\nggplot(delta_df, aes(x = delta)) +\n  geom_histogram(aes(y = ..density..), bins = 30, fill = \"#b97c7c\", alpha = 0.75) +\n  geom_vline(\n    xintercept = mean(delta_samples),\n    linetype = \"dashed\",\n    linewidth = 1.2,\n    label = paste(\"Mean:\", round(mean(delta_samples), 2))\n  ) +\n  labs(\n    x = \"delta\",\n    y = \"Density\",\n    title = \"Posterior distribution of delta\"\n  ) \n\n\n\n\n\n\n\nPuoi calcolare l’intervallo di credibilità usando per un intervallo al 95%:\n\nquantile(delta_samples, probs = c(0.025, 0.975))\n#&gt;    2.5%   97.5% \n#&gt; -0.1872  1.1553\n\n\n82.8.12.3 Garbage In, Garbage Out\nLa natura della statistica frequentista impone di prendere una decisione dicotomica: o si rifiuta l’ipotesi nulla o non la si rifiuta. Ciò implica che o esiste un effetto reale, oppure non esiste. Con un campione abbastanza grande, è inevitabile trovare qualche effetto, anche se di minima entità.\nUn approccio bayesiano, invece, permette di stimare la dimensione dell’effetto e di fornire una distribuzione di probabilità. Una distribuzione di probabilità è una rappresentazione grafica delle diverse possibilità che potrebbero verificarsi. In questo contesto, si tratta della “probabilità inversa”, ovvero della plausibilità dell’ipotesi alla luce dei dati osservati e delle conoscenze pregresse. Qui, il parametro \\(\\delta\\) rappresenta la differenza tra le due medie ed è il parametro di interesse. Le credenze precedenti su \\(\\delta\\) sono espresse tramite una distribuzione a priori: in questo caso, una distribuzione Normale centrata su 0 con una deviazione standard di 2. La distribuzione a posteriori rappresenta la nostra conoscenza aggiornata su \\(\\delta\\) dopo l’aggiornamento bayesiano. Il parametro \\(\\delta\\) è la nostra ipotesi sulla differenza tra le due medie, e l’inferenza bayesiana riguarda il cambiamento della nostra credenza dopo aver osservato i dati.\nL’approccio frequentista, al contrario, produce una decisione dicotomica che non modifica la nostra concezione dell’ipotesi dopo aver osservato i dati. Assume una determinata ipotesi come vera e verifica se i dati sono coerenti con essa. Tramite il concetto binario di “significatività statistica”, non si modificano le ipotesi di interesse, ma si accettano o si rifiutano le ipotesi nulle.\nSebbene l’approccio frequentista sia spesso considerato “ingenuo” da molti ricercatori, adottare l’approccio bayesiano non rappresenta una soluzione miracolosa ai problemi della scienza contemporanea. Risolve alcuni problemi, ma non altri. In particolare, non affronta la questione degli incentivi accademici che favoriscono la pubblicazione di un elevato numero di articoli, indipendentemente dalla loro qualità. Un principio fondamentale della ricerca è “Garbage in, garbage out”. Se i dati derivano da un disegno di ricerca fallace o poco creativo, se la ricerca non ha un solido fondamento teorico capace di avanzare le nostre conoscenze, o se la qualità delle misurazioni è insufficiente, i dati raccolti sono puro rumore. Nessun metodo statistico, nemmeno quello bayesiano, può trasformare la spazzatura in oro.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#esercizi",
    "href": "chapters/replication_crisis/01_crisis.html#esercizi",
    "title": "82  La crisi della replicazione",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nEsistono numerosi esempi di ricerche che non riescono a essere replicate (posso citare anche uno studio di replicazione che ho condotto io stesso: Caudek et al. (2017)). Un recente caso emblematico è rappresentato dallo studio di Karataş & Cutright (2023) e dal successivo tentativo di replicazione condotto da Moore et al. (2024). Analizzando le quattro principali argomentazioni sollevate da Gelman & Brown (2024) per criticare lo studio di Aungle & Langer (2023), si offra un’interpretazione del perché lo studio di Karataş & Cutright (2023) non sia stato replicato con successo.\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\n1) Sulla “Crisi della Replicazione” in Psicologia\nChe cosa si intende quando si parla di “crisi della replicazione” in psicologia?\n\n\nA. La difficoltà di molti laboratori nel reperire fondi per la ricerca.\n\n\nB. L’incapacità o la grave difficoltà di replicare, con risultati simili, una parte consistente degli studi pubblicati.\n\n\nC. La tendenza di alcuni scienziati a pubblicare risultati simili ad altri per sfruttare la loro notorietà.\n\n\nD. Lo scarso interesse degli editori di riviste nel pubblicare studi teorici.\n\n\nE. La mancanza di strumenti statistici adeguati per l’analisi dei dati qualitativi.\n\n2) Cosa significa “fallimento della replicazione”?\nQuale delle seguenti opzioni descrive correttamente il “fallimento della replicazione”?\n\n\nA. Non riuscire a pubblicare uno studio su una rivista ad alto impatto.\n\n\nB. Non riuscire a confermare la robustezza metodologica dello studio originale in sede di peer-review.\n\n\nC. Riportare risultati che confermano un’ipotesi già discussa in letteratura.\n\n\nD. Non ottenere, con procedure simili e campioni simili, risultati paragonabili a quelli dello studio originale.\n\n\nE. Non riuscire a reclutare un numero sufficiente di partecipanti in una nuova ricerca.\n\n3) Quale studio scatenò polemiche sulla precognizione?\nNel 2011, un autore pubblicò uno studio che sembrava dimostrare capacità “paranormali” nei partecipanti, scatenando polemiche e dubbi. Chi fu?\n\n\nA. Diederik Stapel, che usò dati inventati.\n\n\nB. John Ioannidis, autore di “Why Most Published Research Findings Are False”.\n\n\nC. Daryl Bem, con l’articolo “Feeling the Future” sulle facoltà precognitive.\n\n\nD. Brian Wansink, con studi su etichette “attraenti” delle verdure.\n\n\nE. Daniel Kahneman, con esperimenti sui bias cognitivi e di giudizio.\n\n4) Cosa si intende per “p-hacking”?\nLa pratica denominata p-hacking (nell’ambito della crisi di replicazione) consiste nel:\n\n\nA. Interrompere la raccolta dati nel momento in cui si ottiene un risultato in linea con l’ipotesi.\n\n\nB. Manipolare, in maniera fraudolenta, immagini o grafici.\n\n\nC. Tradurre erroneamente i questionari in più lingue, alterando i risultati.\n\n\nD. Utilizzare molteplici analisi e combinazioni di variabili fino a ottenere un valore-(p) inferiore a 0.05.\n\n\nE. Avere più autori su uno stesso manoscritto per dividerne la responsabilità.\n\n5) Qual è il tasso di replicazione emerso dal “Reproducibility Project: Psychology” (2015)?\nSecondo i dati dell’Open Science Collaboration (2015), approssimativamente quanti studi di psicologia replicarono con successo (ottenendo risultati “significativi” simili agli originali)?\n\n\nA. Circa il 36%.\n\n\nB. Circa il 65%.\n\n\nC. Quasi il 90%.\n\n\nD. Nessuno studio è stato replicato con successo.\n\n\nE. Circa il 10%.\n\n6) Cosa sono le Questionable Research Practices (QRPs)?\nQuale definizione descrive meglio le “QRPs” (Questionable Research Practices)?\n\n\nA. Pratiche statistiche avanzate che aumentano la robustezza dei risultati.\n\n\nB. Metodologie di campionamento probabilistico trasparenti e preregistrate.\n\n\nC. Pratiche di ricerca discutibili, come “optional stopping” e selezione post-hoc di ipotesi, che influiscono negativamente sull’integrità scientifica.\n\n\nD. Strumenti di meta-analisi per combinare risultati di studi diversi.\n\n\nE. Procedure di controllo etico per proteggere i diritti dei partecipanti.\n\n7) Perché i campioni troppo piccoli sono considerati problematici?\nNella letteratura sulla crisi di replicazione, perché avere campioni di dimensione ridotta costituisce una criticità?\n\n\nA. Perché rendono più facile l’analisi statistica, riducendo la possibilità di trovare p &lt; .05.\n\n\nB. Perché riducono la potenza statistica, aumentando il rischio di sovrastimare effetti e di ottenere risultati non replicabili.\n\n\nC. Perché il costo di reclutamento è troppo basso, compromettendo l’interesse dei revisori.\n\n\nD. Perché obbligano a utilizzare necessariamente test non-parametrici.\n\n\nE. Perché la psicologia preferisce dataset qualitativi, non quantitativi.\n\n8) Che cosa significa “bias di pubblicazione”?\nCon l’espressione “bias di pubblicazione” (o publication bias), ci si riferisce a:\n\n\nA. La tendenza dei revisori a selezionare articoli soltanto se ben scritti.\n\n\nB. L’inclinazione delle riviste di settore a pubblicare preferibilmente i lavori dei ricercatori senior.\n\n\nC. La propensione alla pubblicazione di studi con risultati innovativi e statisticamente positivi, trascurando invece studi con risultati nulli.\n\n\nD. L’obbligo di pubblicare i protocolli di studio in forma open.\n\n\nE. Una norma deontologica che impone di nascondere i metodi inediti per evitare furti di idee.\n\n9) Quale scopo principale ha il movimento dell’Open Science?\nNel contesto della crisi di replicazione, qual è l’obiettivo cardine promosso dal movimento per la Scienza Aperta (Open Science)?\n\n\nA. Aumentare il controllo sugli studi, rendendo segreti i metodi di analisi.\n\n\nB. Pubblicare soltanto studi che abbiano ottenuto finanziamenti pubblici.\n\n\nC. Rendere i dati, i materiali e le procedure il più possibile trasparenti e accessibili, favorendo le repliche e la verifica indipendente.\n\n\nD. Abolire completamente l’uso di test statistici e valori-p.\n\n\nE. Prediligere esclusivamente studi qualitativi in ambito psicologico.\n\n10) Perché la scienza non si autocorregge come si afferma?\nSecondo quanto discusso, come mai la scienza non risulta sempre “autocorrettiva” nella pratica reale?\n\n\nA. Perché gli editori impongono di inserire errori per testare la capacità dei revisori di individuarli.\n\n\nB. Perché è molto costoso usare software di statistica adeguati.\n\n\nC. Perché la pressione a pubblicare risultati nuovi prevale sull’attenzione a errori e correzioni; i ricercatori non hanno incentivi sufficienti a pubblicare smentite, ritrazioni o correzioni.\n\n\nD. Perché l’uso della statistica bayesiana ha complicato la procedura di revisione.\n\n\nE. Perché tutti gli studi di psicologia sono in realtà corretti al 99%.\n\n\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\n\n\nB\n\n\nD\n\n\nC\n\n\nD\n\n\nA\n\n\nC\n\n\nB\n\n\nC\n\n\nC\n\nC\n\nLa crisi della replicazione in psicologia è il risultato di una combinazione di fattori sistemici e metodologici:\n\n\nIncentivi distorti (“publish or perish”), che spingono a privilegiare la novità rispetto alla qualità e alla rigorosità delle ricerche.\n\n\nPratiche di ricerca discutibili (QRPs), tra cui p-hacking e optional stopping, che producono un numero elevato di falsi positivi.\n\n\nBias di pubblicazione, che favorisce i risultati statistici significativi a scapito di studi con esiti non significativi o repliche.\n\n\nBassa potenza statistica e campioni di piccole dimensioni, che gonfiano o sovrastimano l’effetto di fenomeni psicologici.\n\n\nScarsa trasparenza e accessibilità (scienza “chiusa”), che rende difficile verificare e replicare i risultati originari.\n\nNonostante i numeri allarmanti riportati da studi di vasta portata (come il Reproducibility Project), questa situazione può essere vista come un’opportunità di “rivoluzione della credibilità”:\n\nSi stanno diffondendo pratiche di Open Science, con la condivisione di dati, protocolli, codici e materiali, favorendo così la replica e la validazione indipendente.\n\nLa cultura della replicazione viene valorizzata, incentivando studi più rigorosi e focalizzati sulla robustezza degli effetti.\n\nL’approccio statistico tradizionale (frequentista) è posto in discussione, evidenziando la possibilità di integrare o sostituire i test di ipotesi nulla con metodologie più robuste, tra cui quelle bayesiane, le analisi preregistrate e la valorizzazione di stime degli effetti con intervalli di credibilità.\n\nLa crisi di replicazione, quindi, non deve essere intesa come un fallimento totale, bensì come un momento critico che ha avviato un rinnovamento, mirato a rendere la scienza psicologica (e altre discipline) più rigorosa, trasparente e affidabile.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/replication_crisis/01_crisis.html#informazioni-sullambiente-di-sviluppo",
    "title": "82  La crisi della replicazione",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] posterior_1.6.1  cmdstanr_0.9.0   thematic_0.1.6   MetBrewer_0.2.0 \n#&gt;  [5] ggokabeito_0.1.0 see_0.11.0       gridExtra_2.3    patchwork_1.3.0 \n#&gt;  [9] bayesplot_1.12.0 psych_2.5.3      scales_1.4.0     markdown_2.0    \n#&gt; [13] knitr_1.50       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   \n#&gt; [17] dplyr_1.1.4      purrr_1.0.4      readr_2.1.5      tidyr_1.3.1     \n#&gt; [21] tibble_3.2.1     ggplot2_3.5.2    tidyverse_2.0.0  rio_1.2.3       \n#&gt; [25] here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6         tensorA_0.36.2.1     xfun_0.52           \n#&gt;  [4] htmlwidgets_1.6.4    processx_3.8.6       lattice_0.22-7      \n#&gt;  [7] tzdb_0.5.0           vctrs_0.6.5          tools_4.5.0         \n#&gt; [10] ps_1.9.1             generics_0.1.4       parallel_4.5.0      \n#&gt; [13] pacman_0.5.1         pkgconfig_2.0.3      data.table_1.17.2   \n#&gt; [16] checkmate_2.3.2      RColorBrewer_1.1-3   distributional_0.5.0\n#&gt; [19] lifecycle_1.0.4      compiler_4.5.0       farver_2.1.2        \n#&gt; [22] mnormt_2.1.1         htmltools_0.5.8.1    yaml_2.3.10         \n#&gt; [25] pillar_1.10.2        abind_1.4-8          nlme_3.1-168        \n#&gt; [28] tidyselect_1.2.1     digest_0.6.37        stringi_1.8.7       \n#&gt; [31] labeling_0.4.3       rprojroot_2.0.4      fastmap_1.2.0       \n#&gt; [34] grid_4.5.0           cli_3.6.5            magrittr_2.0.3      \n#&gt; [37] utf8_1.2.5           withr_3.0.2          backports_1.5.0     \n#&gt; [40] timechange_0.3.0     rmarkdown_2.29       matrixStats_1.5.0   \n#&gt; [43] hms_1.1.3            evaluate_1.0.3       rlang_1.1.6         \n#&gt; [46] glue_1.8.0           rstudioapi_0.17.1    jsonlite_2.0.0      \n#&gt; [49] R6_2.6.1",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#bibliografia",
    "href": "chapters/replication_crisis/01_crisis.html#bibliografia",
    "title": "82  La crisi della replicazione",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAungle, P., & Langer, E. (2023). Physical healing as a function of perceived time. Scientific Reports, 13(1), 22432.\n\n\nBaker, M. (2016). 1,500 scientists lift the lid on reproducibility. Nature, 533(7604).\n\n\nBargh, J. A., Chen, M., & Burrows, L. (1996). Automaticity of social behavior: Direct effects of trait construct and stereotype activation on action. Journal of Personality and Social Psychology, 71(2), 230–244.\n\n\nBem, D. J. (2011). Feeling the future: experimental evidence for anomalous retroactive influences on cognition and affect. Journal of Personality and Social Psychology, 100(3), 407–425.\n\n\nBruton, S. V., Medlin, M., Brown, M., & Sacco, D. F. (2020). Personal motivations and systemic incentives: Scientists on questionable research practices. Science and Engineering Ethics, 26(3), 1531–1547.\n\n\nCaudek, C., Lorenzino, M., & Liperoti, R. (2017). Delta plots do not reveal response inhibition in lying. Consciousness and Cognition, 55, 232–244.\n\n\nChivers, T. (2024). Everything is Predictable: How Bayesian Statistics Explain Our World. Simon; Schuster.\n\n\nCollaboration, O. S. (2015). Estimating the reproducibility of psychological science. Science, 349(6251), aac4716.\n\n\nFerguson, C. J., & Heene, M. (2012). A vast graveyard of undead theories: Publication bias and psychological science’s aversion to the null. Perspectives on Psychological Science, 7(6), 555–561.\n\n\nGelman, A., & Brown, N. J. (2024). How statistical challenges and misreadings of the literature combine to produce unreplicable science: An example from psychology.\n\n\nGelman, A., & Loken, E. (2013). The garden of forking paths: Why multiple comparisons can be a problem, even when there is no «fishing expedition» or «p-hacking» and the research hypothesis was posited ahead of time. Department of Statistics, Columbia University, 348(1-17), 3.\n\n\nGelman, A., & Loken, E. (2014). The statistical crisis in science. American scientist, 102(6), 460–465.\n\n\nGopalakrishna, G., Ter Riet, G., Vink, G., Stoop, I., Wicherts, J. M., & Bouter, L. M. (2022). Prevalence of questionable research practices, research misconduct and their potential explanatory factors: A survey among academic researchers in The Netherlands. PloS one, 17(2), e0263023.\n\n\nGrimes, D. R., Bauch, C. T., & Ioannidis, J. P. (2018). Modelling science trustworthiness under publish or perish pressure. Royal Society open science, 5(1), 171511.\n\n\nIoannidis, J. P. (2005). Why most published research findings are false. PLoS medicine, 2(8), e124.\n\n\nKarataş, M., & Cutright, K. M. (2023). Thinking about God increases acceptance of artificial intelligence in decision-making. Proceedings of the National Academy of Sciences, 120(33), e2218961120.\n\n\nLakens, D. (2015). On the challenges of drawing conclusions from p-values just below 0.05. PeerJ, 3, e1142.\n\n\nLeys, R. (2024). Anatomy of a Train Wreck: The Rise and Fall of Priming Research. University of Chicago Press.\n\n\nLoken, E., & Gelman, A. (2017). Measurement Error and the Replication Crisis. Science, 355(6325), 584–585.\n\n\nMeehl, P. E. (2012). Why summaries of research on psychological theories are often uninterpretable. In Improving inquiry in social science (pp. 13–59). Routledge.\n\n\nMoore, D. A., Schroeder, J., Bailey, E. R., Gershon, R., Moore, J. E., & Simmons, J. P. (2024). Does thinking about God increase acceptance of artificial intelligence in decision-making? Proceedings of the National Academy of Sciences, 121(31), e2402315121.\n\n\nNosek, B. A., Spies, J. R., & Motyl, M. (2012). Scientific utopia: II. Restructuring incentives and practices to promote truth over publishability. Perspectives on Psychological Science, 7(6), 615–631.\n\n\nPennington, C. (2023). A student’s guide to open science: Using the replication crisis to reform psychology. McGraw-Hill Education (UK).\n\n\nWare, J. J., & Munafò, M. R. (2015). Significance chasing in research practice: causes, consequences and possible solutions. Addiction, 110(1), 4–8.\n\n\nYouyou, W., Yang, Y., & Uzzi, B. (2023). A discipline-wide investigation of the replicability of Psychology papers over the past two decades. Proceedings of the National Academy of Sciences, 120(6), e2208863120.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html",
    "title": "83  Limiti dell’inferenza frequentista",
    "section": "",
    "text": "Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nIn questa sezione della dispensa, abbiamo approfondito il metodo “tradizionale” per il test di significatività dell’ipotesi nulla (NHST). Comprendere la logica sottostante all’approccio NHST è fondamentale, poiché esso ha rappresentato il principale strumento della statistica inferenziale sin dalla sua introduzione all’inizio del XX secolo, e la maggior parte dei ricercatori continua a basarsi su questa procedura per l’analisi dei dati. Tuttavia, negli ultimi anni, l’NHST è stato oggetto di crescenti critiche, con molti studiosi che sostengono che questo approccio possa generare più problemi di quanti ne risolva. Per questo motivo, è cruciale esaminare le critiche avanzate dalla comunità scientifica nei confronti della procedura inferenziale NHST. In questa sezione, analizzeremo alcuni dei principali dubbi e limiti emersi riguardo a tale metodologia.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>83</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#luso-del-valore-p-nel-mondo-della-ricerca",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#luso-del-valore-p-nel-mondo-della-ricerca",
    "title": "83  Limiti dell’inferenza frequentista",
    "section": "83.1 L’uso del valore-\\(p\\) nel mondo della ricerca",
    "text": "83.1 L’uso del valore-\\(p\\) nel mondo della ricerca\nNel suo articolo “Statistical Errors” (2014), Nuzzo mette in luce i limiti dell’approccio NHST nella pratica scientifica Nuzzo (2014). Sebbene il valore-\\(p\\) sia stato introdotto da Ronald Fisher negli anni ’20, egli non lo concepì mai come un test formale. Fisher lo considerava piuttosto uno strumento informale per valutare se l’evidenza empirica fosse “significativa” in senso colloquiale, ovvero meritevole di ulteriore attenzione. Nella pratica, Fisher suggeriva di assumere un’ipotesi nulla e di calcolare la probabilità di osservare un risultato altrettanto estremo o più estremo di quello ottenuto, presupponendo che il risultato fosse interamente dovuto alla variabilità campionaria. Tuttavia, per Fisher, il valore-\\(p\\) non era una conclusione definitiva, ma uno strumento da integrare in un processo decisionale più ampio, che tenesse conto sia delle evidenze empiriche sia delle conoscenze pregresse del ricercatore. In altre parole, il valore-\\(p\\) era parte di un ragionamento scientifico, non il punto finale di tale ragionamento.\nVerso la fine degli anni ’20, Jerzy Neyman e Egon Pearson, rivali di Fisher, formalizzarono le procedure di decisione statistica con l’obiettivo di renderle più rigorose e oggettive. Introdussero concetti come il potere statistico e il tasso di falsi positivi, ma si distanziarono dall’uso del valore-\\(p\\) proposto da Fisher. Le divergenze tra Fisher, Neyman e Pearson diedero vita a un acceso dibattito: Neyman definì il lavoro di Fisher “matematicamente peggiore dell’inutilità”, mentre Fisher bollò l’approccio di Neyman come “infantile” e “dannoso per la libertà intellettuale dell’Occidente”.\nNel frattempo, altri autori iniziarono a scrivere manuali di statistica per guidare i ricercatori. Tuttavia, molti di questi autori non erano statistici e avevano una comprensione superficiale delle differenze tra i vari approcci. Il risultato fu un sistema ibrido che combinava il valore-\\(p\\) di Fisher con il framework rigoroso di Neyman e Pearson. Fu in questo contesto che la soglia di un valore-\\(p\\) pari a 0.05 venne arbitrariamente definita come “statisticamente significativa”.\nStoricamente, tuttavia, il valore-\\(p\\) proposto da Fisher aveva un significato molto diverso rispetto a quello che gli viene attribuito oggi. Come abbiamo visto, per Fisher era uno strumento informale, da utilizzare all’interno di un processo decisionale più ampio e non come un criterio meccanico per stabilire la verità scientifica. L’uso del valore-\\(p\\) nel sistema ibrido adottato dai manuali di statistica è quindi privo di una solida giustificazione teorica.\nNel 2016, l’American Statistical Association (ASA) ha espresso forti preoccupazioni riguardo all’uso inappropriato del valore-\\(p\\) nella pratica scientifica contemporanea Wasserstein & Lazar (2016):\n\n\\(P\\)-values do not measure the probability that the studied hypothesis is true, or the probability that the data were produced by random chance alone. Researchers often wish to turn a \\(p\\)-value into a statement about the truth of a null hypothesis, or about the probability that random chance produced the observed data. The \\(p\\)-value is neither. It is a statement about data in relation to a specified hypothetical explanation, and is not a statement about the explanation itself.\n\nL’articolo prosegue sottolineando che:\n\nScientific conclusions and business or policy decisions should not be based only on whether a \\(p\\)-value passes a specific threshold. Practices that reduce data analysis or scientific inference to mechanical “bright-line” rules (such as “\\(p &lt; 0.05\\)”) for justifying scientific claims or conclusions can lead to erroneous beliefs and poor decision making. A conclusion does not immediately become ‘true’ on one side of the divide and ‘false’ on the other. Researchers should bring many contextual factors into play to derive scientific inferences, including the design of a study, the quality of the measurements, the external evidence for the phenomenon under study, and the validity of assumptions that underlie the data analysis. Pragmatic considerations often require binary, ‘yes-no’ decisions, but this does not mean that \\(p\\)-values alone can ensure that a decision is correct or incorrect. The widespread use of “statistical significance” (generally interpreted as \\(p \\leq 0.05\\)) as a license for making a claim of a scientific finding (or implied truth) leads to considerable distortion of the scientific process.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>83</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#p-hacking",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#p-hacking",
    "title": "83  Limiti dell’inferenza frequentista",
    "section": "83.2 \\(P\\)-hacking",
    "text": "83.2 \\(P\\)-hacking\nLa pratica del \\(P\\)-hacking rappresenta una delle principali criticità associate all’uso del valore-\\(p\\) ed è conosciuta anche con termini come data-dredging, snooping, fishing, significance-chasing o double-dipping. Secondo Uri Simonsohn, professore all’Università della Pennsylvania, il \\(P\\)-hacking consiste nel manipolare i dati o le analisi fino a ottenere un risultato statisticamente significativo, tipicamente con un valore-\\(p\\) inferiore a 0.05. Ad esempio, si potrebbe dire: “Quel risultato sembra frutto di \\(P\\)-hacking; gli autori hanno escluso una condizione per far diminuire il valore-\\(p\\) sotto la soglia di 0.05” oppure “Lei è un \\(P\\)-hacker, controlla continuamente i dati durante la raccolta per trovare un risultato significativo”.\nQuesta pratica trasforma uno studio esplorativo, che dovrebbe essere interpretato con estrema cautela, in uno studio confermativo (apparentemente robusto), i cui risultati, tuttavia, hanno una probabilità molto bassa di essere replicati in ricerche successive. Secondo le simulazioni condotte da Simonsohn, piccole modifiche nelle scelte analitiche possono aumentare il tasso di falsi positivi fino al 60% in un singolo studio.\nIl \\(P\\)-hacking è particolarmente diffuso negli studi che cercano di dimostrare effetti di piccola entità utilizzando dati molto rumorosi. Un’analisi della letteratura psicologica ha rivelato che i valori-\\(p\\) riportati tendono a concentrarsi appena al di sotto della soglia di 0.05, un fenomeno che può essere interpretato come un segnale di \\(P\\)-hacking: i ricercatori eseguono molteplici test statistici fino a trovarne uno che raggiunge la “significatività statistica” e poi riportano solo quello. Come evidenziato in figura, questa pratica non è limitata alla psicologia, ma è ampiamente diffusa in tutti i campi della ricerca scientifica, contribuendo a minare l’affidabilità dei risultati pubblicati.\n\n\n\nDistribuzione dei valori-\\(p\\) nelle pubblicazioni scientifiche di economia, psicologia e biologia.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>83</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#critiche-al-valore-p",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#critiche-al-valore-p",
    "title": "83  Limiti dell’inferenza frequentista",
    "section": "83.3 Critiche al valore-\\(p\\)",
    "text": "83.3 Critiche al valore-\\(p\\)\nIl valore-\\(p\\) è stato spesso paragonato a creature fastidiose e persistenti come le zanzare, oppure ai “vestiti nuovi dell’imperatore”, metafora che rappresenta la tendenza a ignorare problemi evidenti preferendo fingere che tutto vada bene. È stato anche definito un intellectual rake sterile, un termine che sottolinea la sua incapacità di produrre risultati utili. Non manca nemmeno l’ironia sul fatto che la procedura di statistical hypothesis inference testing venga chiamata così principalmente per l’acronimo che genera.\nIl valore-\\(p\\) promuove un modo di pensare distorto, spostando l’attenzione dal cuore della ricerca, ovvero la forza della manipolazione sperimentale, verso la dimostrazione di un’ipotesi nulla che si sa già essere falsa. Ad esempio, uno studio condotto su oltre 19,000 individui ha mostrato che le coppie che si incontrano online hanno una probabilità inferiore di divorziare (\\(p &lt; 0.002\\)) e riportano una maggiore soddisfazione nella vita matrimoniale (\\(p &lt; 0.001\\)) rispetto a quelle che si sono conosciute offline. Sebbene questi risultati possano sembrare interessanti, senza considerare la dimensione dell’effetto – come la riduzione del tasso di divorzio dal 7.67% al 5.96% o l’aumento dell’indice di soddisfazione matrimoniale da 5.48 a 5.64 su una scala a sette punti – il loro impatto pratico rischia di essere sopravvalutato. In generale, la domanda chiave non dovrebbe essere “c’è un effetto?”, ma piuttosto “quanto è grande l’effetto?”. Questo approccio permette di valutare meglio l’effettiva rilevanza dei risultati, andando oltre la semplice significatività statistica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>83</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#leffetto-sperimentale-è-esattamente-nullo",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#leffetto-sperimentale-è-esattamente-nullo",
    "title": "83  Limiti dell’inferenza frequentista",
    "section": "83.4 L’effetto sperimentale è esattamente nullo?",
    "text": "83.4 L’effetto sperimentale è esattamente nullo?\nUna delle critiche più ricorrenti alla logica del test di verifica delle ipotesi statistiche riguarda l’assunzione irrealistica che l’effetto della manipolazione sperimentale sia esattamente nullo. Ad esempio, la fisica ci dimostra che persino lo spostamento di un grammo di massa in una stella distante anni luce dalla Terra può influenzare, seppur minimamente, il movimento delle molecole di un gas sul nostro pianeta (Borel, 1914). Questo esempio suggerisce che ogni manipolazione sperimentale, per quanto piccola, produca in qualche modo un effetto. Pertanto, come sottolinea Andrew Gelman, il problema non è tanto dimostrare che l’ipotesi nulla sia falsa – ovvero che la manipolazione sperimentale non abbia alcun effetto – quanto piuttosto valutare se la dimensione dell’effetto sia sufficientemente grande da avere un impatto pratico e se tale effetto sia riproducibile.\nIn questo contesto, la logica del test dell’ipotesi nulla risulta particolarmente problematica, specialmente quando si lavora con campioni piccoli ed effetti di modesta entità, come accade spesso negli studi psicologici. Questo approccio può portare a una sovrastima della dimensione dell’effetto e a una visione binaria dei risultati (vero/falso), distogliendo l’attenzione dalla stima accurata e non distorta della dimensione effettiva dell’effetto. In altre parole, la ricerca dovrebbe concentrarsi meno sul rifiutare un’ipotesi nulla spesso irrealistica e più sulla comprensione e quantificazione dell’impatto reale delle variabili studiate.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>83</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#attenti-al-valore-p",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#attenti-al-valore-p",
    "title": "83  Limiti dell’inferenza frequentista",
    "section": "83.5 Attenti al valore-\\(p\\)!",
    "text": "83.5 Attenti al valore-\\(p\\)!\nConsideriamo il seguente problema. Supponiamo di eseguire un \\(t\\)-test per due campioni indipendenti per verificare l’ipotesi nulla che le medie delle due popolazioni siano uguali. Fissiamo un livello di significatività \\(\\alpha = 0.05\\) e otteniamo un valore-\\(p\\) pari a \\(0.04\\). La domanda è: qual è la probabilità che i due campioni provengano da distribuzioni con la stessa media?\nLe opzioni sono:\n(a) \\(19/20\\); (b) \\(1/19\\); (c) \\(1/20\\); (d) \\(95/100\\); (e) sconosciuta.\nLa risposta corretta è: (e) sconosciuta. Questo perché la statistica frequentista calcola le probabilità dei dati condizionatamente alle ipotesi (assunte come vere), ma non permette di determinare la probabilità di un’ipotesi. In altre parole, il valore-\\(p\\) non fornisce informazioni sulla probabilità che l’ipotesi nulla sia vera o falsa; indica solo la probabilità di osservare i dati (o risultati più estremi) assumendo che l’ipotesi nulla sia vera.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>83</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#la-crisi-della-riprodicibilità-dei-risultati-della-ricerca",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#la-crisi-della-riprodicibilità-dei-risultati-della-ricerca",
    "title": "83  Limiti dell’inferenza frequentista",
    "section": "83.6 La crisi della riprodicibilità dei risultati della ricerca",
    "text": "83.6 La crisi della riprodicibilità dei risultati della ricerca\nNegli ultimi anni, la mancanza di replicabilità dei risultati della ricerca – inclusa quella psicologica – è emersa come un tema di grande rilevanza nel dibattito scientifico. In questo contesto, è stato evidenziato che alcuni aspetti del metodo scientifico, in particolare l’uso del valore-\\(p\\) e la pratica del test di significatività dell’ipotesi nulla (NHST, Null Hypothesis Significance Testing), potrebbero contribuire a quella che è stata definita una “crisi della ricerca scientifica”. Un’analisi approfondita di questo problema è stata proposta da Gelman (2016), il quale sostiene che la NHST sia intrinsecamente problematica. Questo approccio, infatti, spinge i ricercatori a cercare di rigettare un’ipotesi “fantoccio” (straw-man), spesso già falsa a priori o di scarso interesse scientifico, a favore di un’ipotesi alternativa che il ricercatore preferisce. In generale, è più ragionevole affermare che la differenza tra due condizioni sia molto piccola piuttosto che esattamente uguale a zero, ma la NHST non è progettata per cogliere questa sfumatura.\nNei libri di statistica, la NHST viene spesso presentata come una sorta di “alchimia” che trasforma la casualità in una falsa certezza, utilizzando termini come “confidenza” e “significatività” (Gelman, 2016). Il processo di raccolta dei dati, analisi e inferenza statistica viene sintetizzato in una conclusione espressa in termini di valore-\\(p\\) e intervalli di confidenza che escludono lo zero. Tuttavia, questo può creare l’impressione errata che il ricercatore abbia una comprensione completa del fenomeno studiato. Il problema principale della NHST è che spesso produce risultati “statisticamente significativi” in contesti in cui le caratteristiche del fenomeno non giustificano le conclusioni tratte. Questo può portare a una bassa replicabilità dei risultati, contribuendo alla crisi di fiducia nella ricerca.\nLa comunità statistica ha sottolineato come la non replicabilità sia particolarmente evidente quando i ricercatori, utilizzando la NHST, traggono conclusioni errate basate su piccoli campioni ed effetti di dimensioni ridotte. Queste condizioni, insieme ad altre, rendono l’applicazione della NHST estremamente problematica. Purtroppo, queste situazioni descrivono molte delle ricerche recenti in psicologia, un campo in cui gli effetti sono spesso modesti e i campioni limitati.\nLa statistica è stata definita come un metodo per prendere decisioni razionali in condizioni di incertezza. Gli statistici raccomandano ai ricercatori non solo di padroneggiare le tecniche statistiche, ma anche di imparare a convivere con l’incertezza, nonostante la crescente sofisticazione degli strumenti disponibili. Conviverci significa evitare di pensare che ottenere un valore-\\(p\\) “statisticamente significativo” equivalga a risolvere un problema scientifico. Ma allora, come possiamo avere fiducia in ciò che apprendiamo dai dati? Una possibile strategia è la replicazione e la convalida esterna dei risultati, sebbene nella ricerca psicologica e nelle scienze sociali questo sia spesso difficile da realizzare a causa degli elevati costi e delle complessità pratiche. Il problema di quali strumenti metodologici e metodi statistici siano più adatti per indagare i fenomeni psicologici, senza cadere in errori di interpretazione, rimane quindi una questione aperta e di cruciale importanza.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>83</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#commenti-e-considerazioni-finali",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#commenti-e-considerazioni-finali",
    "title": "83  Limiti dell’inferenza frequentista",
    "section": "83.7 Commenti e considerazioni finali",
    "text": "83.7 Commenti e considerazioni finali\nNon possiamo concludere senza affrontare la controversia che circonda il concetto di valore-\\(p\\). Nonostante sia ancora ampiamente utilizzato e spesso interpretato in modo errato, il valore-\\(p\\) conferisce solo una parvenza di legittimità a risultati dubbi, incoraggia cattive pratiche di ricerca e favorisce la produzione di falsi positivi. Inoltre, il suo significato è spesso frainteso, persino dagli esperti: quando chiamati a definire il valore-\\(p\\), molti forniscono risposte imprecise o sbagliate. Ciò che i ricercatori desiderano sapere è se i risultati di uno studio siano corretti o meno, ma il valore-\\(p\\) non fornisce questa informazione. Non dice nulla sulla dimensione dell’effetto, sulla forza dell’evidenza o sulla probabilità che il risultato sia frutto del caso. Allora, qual è il suo vero significato? Stuart Buck lo spiega in modo efficace:\n\nImmaginate di avere una moneta che sospettate sia truccata a favore della testa (l’ipotesi nulla è che la moneta sia equa). La lanciate 100 volte e ottenete più teste che croci. Il valore-\\(p\\) non vi dirà se la moneta è equa, ma vi indicherà la probabilità di ottenere almeno lo stesso numero di teste osservato se la moneta fosse equa. Questo è tutto – niente di più.\n\nIn sintesi, il valore-\\(p\\) risponde a una domanda molto specifica che, tuttavia, non ha alcuna rilevanza diretta per la validità scientifica dei risultati di una ricerca. In un’epoca in cui la crisi della riproducibilità dei risultati è sempre più evidente (Baker, 2016), il test dell’ipotesi nulla e gli intervalli di confidenza frequentisti sono stati identificati come una delle principali cause del problema. Questo ha spinto molti ricercatori a cercare alternative metodologiche più robuste e informative, in grado di superare i limiti intrinseci del valore-\\(p\\) e di promuovere una scienza più affidabile e trasparente.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>83</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#bibliografia",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#bibliografia",
    "title": "83  Limiti dell’inferenza frequentista",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBaker, M. (2016). Reproducibility Crisis. Nature, 533(7604), 452–454.\n\n\nBorel, E. (1914). Introduction Géométrique. G. Villars, New York.\n\n\nGelman, A. (2016). Commentary on «Crisis in Science? Or Crisis in Statistics! Mixed Messages in Statistics with Impact on Science». Journal of Statistical Research, 48-50(1), 11–12.\n\n\nGoligher, E. C., Heath, A., & Harhay, M. O. (2024). Bayesian statistics for clinical research. The Lancet, 404(10457), 1067–1076. https://doi.org/10.1016/S0140-6736(24)00055-9\n\n\nNuzzo, R. (2014). Statistical Errors. Nature, 506(7487), 150–152.\n\n\nWasserstein, R. L., & Lazar, N. A. (2016). The ASA’s statement on p-values: context, process, and purpose. The American Statistician, 70(2), 129–133.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>83</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html",
    "href": "chapters/replication_crisis/03_effect_size.html",
    "title": "84  La grandezza dell’effetto",
    "section": "",
    "text": "84.1 Introduzione\nLa dimensione dell’effetto (effect size) è un concetto chiave nella metodologia della ricerca, utilizzato per quantificare la forza della relazione statistica tra due variabili. Questa misura standardizzata descrive l’entità di un effetto, come quello di un intervento o di un trattamento, fornendo una valutazione quantitativa dell’importanza di un fenomeno osservato.\nÈ essenziale distinguere tra dimensione dell’effetto e significatività statistica. Un risultato può essere “statisticamente significativo” anche se l’effetto è di piccole dimensioni, e viceversa. La conoscenza di uno di questi aspetti non fornisce automaticamente informazioni sull’altro, evidenziando la necessità di considerare entrambi nell’analisi dei dati.\nL’importanza della dimensione dell’effetto è ampiamente riconosciuta nel mondo della ricerca scientifica. Il manuale dell’American Psychological Association (APA) del 2010 ne sottolinea la rilevanza, raccomandando di includere questa misura negli studi pubblicati. Di conseguenza, la maggior parte degli articoli nelle riviste associate all’APA riporta la dimensione dell’effetto, solitamente indicata tra parentesi accanto al valore-\\(p\\).\nNonostante la sua importanza e la prassi di riportarla, la psicologia scientifica spesso mostra una carenza nella corretta valutazione e interpretazione delle dimensioni dell’effetto. Molti ricercatori si limitano a comunicare questi valori senza analizzarli in profondità, portando a conclusioni che possono risultare superficiali, poco informative, fuorvianti o addirittura errate. Questa tendenza riflette una sottovalutazione sistematica e una diffusa incomprensione del concetto di dimensione dell’effetto, persino tra i professionisti della ricerca.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#misurazione-delleffetto-approcci-e-applicazioni",
    "href": "chapters/replication_crisis/03_effect_size.html#misurazione-delleffetto-approcci-e-applicazioni",
    "title": "84  La grandezza dell’effetto",
    "section": "84.2 Misurazione dell’Effetto: Approcci e Applicazioni",
    "text": "84.2 Misurazione dell’Effetto: Approcci e Applicazioni\nTra le metriche più utilizzate per quantificare l’effetto di un trattamento o di una differenza tra gruppi troviamo il \\(d\\) di Cohen e l’\\(r\\) di Pearson. Il \\(d\\) di Cohen è particolarmente utile per descrivere le differenze tra le medie di due gruppi sperimentali, esprimendo tale differenza in termini di deviazione standard aggregata.\nLa differenza standardizzata tra le medie di due gruppi può essere calcolata con la seguente formula (equazione 5.1, Glass et al., 1981):\n\\[\nd_p = \\frac{M_1 - M_2}{S_p},\n\\]\ndove:\n\n\\(M_1\\) e \\(M_2\\) sono le medie dei due gruppi,\n\\(S_p\\) è la deviazione standard combinata.\n\nUn valore positivo di \\(d_p\\) indica che la media del gruppo 1 è maggiore di quella del gruppo 2. La deviazione standard combinata \\(S_p\\) è calcolata come la radice quadrata della varianza media ponderata per i gradi di libertà (\\(df = n-1\\)) dei due gruppi (pp. 108, Glass et al., 1981):\n\\[\nS_p = \\sqrt{\\frac{(n_1 - 1) S_1^2 + (n_2 - 1) S_2^2}{n_1 + n_2 - 2}},\n\\]\ndove:\n\n\\(n_1\\) e \\(n_2\\) sono le dimensioni dei due gruppi,\n\\(S_1^2\\) e \\(S_2^2\\) sono le varianze (quadrato della deviazione standard) dei due gruppi.\n\nIl \\(d_p\\) di Cohen è strettamente correlato alla statistica \\(t\\) di un test \\(t\\) per campioni indipendenti. Infatti, è possibile calcolare \\(d_p\\) a partire dalla statistica \\(t\\) utilizzando la seguente formula (equazione 5.3, Glass et al., 1981):\n\\[\nd = t \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}.\n\\]\nL’errore standard di \\(d_p\\) è dato da:\n\\[\nSE_{d_p} = \\sqrt{\\frac{n_1 + n_2}{n_1 n_2} + \\frac{d_p^2}{2(n_1 + n_2)}}.\n\\]\nD’altra parte, la statistica \\(r\\) di Pearson misura il grado di correlazione lineare tra due variabili, indicando quanto una variabile possa predire l’altra. È interessante notare che queste due misure, \\(d\\) e \\(r\\), possono essere convertite l’una nell’altra attraverso la relazione:\n\\[\nd = \\frac{2r}{\\sqrt{1-r^2}}.\n\\]\nQuesta conversione permette di passare da una misura di differenza tra medie a una misura di correlazione, offrendo una maggiore flessibilità nell’interpretazione dei risultati.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#interpretazione-della-dimensione-delleffetto",
    "href": "chapters/replication_crisis/03_effect_size.html#interpretazione-della-dimensione-delleffetto",
    "title": "84  La grandezza dell’effetto",
    "section": "84.3 Interpretazione della Dimensione dell’Effetto",
    "text": "84.3 Interpretazione della Dimensione dell’Effetto\nL’interpretazione della dimensione dell’effetto è un aspetto cruciale nell’analisi statistica, ma spesso viene affrontata in modi che possono risultare privi di significato o addirittura fuorvianti. Di seguito, esploriamo due approcci comuni e le loro criticità.\n\n84.3.1 Gli Standard di Cohen\nUno dei metodi più diffusi per interpretare la dimensione dell’effetto si basa sugli standard proposti da Jacob Cohen (1977, 1988). Cohen ha suggerito delle soglie arbitrarie per classificare l’effetto:\n\nr = 0.10 → effetto piccolo,\nr = 0.30 → effetto medio,\nr = 0.50 → effetto grande.\n\nTuttavia, come sottolineato da Funder (2019), queste soglie sono spesso utilizzate in modo acritico, senza considerare il contesto specifico. Lo stesso Cohen ha espresso rammarico per aver introdotto queste categorie, precisando che dovrebbero essere adottate solo in assenza di criteri più solidi.\nLe etichette “piccolo”, “medio” e “grande” sono prive di significato se non vengono contestualizzate. Per un’interpretazione corretta, è essenziale porsi due domande fondamentali:\n\nRispetto a cosa? Cosa rappresenta un effetto piccolo, medio o grande nel contesto specifico dello studio?\nA quale scopo? Qual è l’impatto pratico o teorico dell’effetto osservato?\n\nSenza rispondere a queste domande, l’uso degli standard di Cohen rischia di essere poco informativo o addirittura ingannevole.\n\n\n84.3.2 Elevare al Quadrato la Correlazione\nUn altro approccio comune, ma altrettanto problematico, consiste nell’elevare al quadrato il coefficiente di correlazione \\(r\\) per ottenere \\(r^2\\), interpretato come la “proporzione di varianza spiegata”. Ad esempio, una correlazione \\(r = 0.30\\) corrisponde a \\(r^2 = 0.09\\), spesso descritto come “solo il 9% della varianza spiegata”.\nTuttavia, come evidenziato da Funder & Ozer (2019), questa pratica è criticabile per due motivi principali:\n\nMancanza di interpretabilità: Mentre \\(r\\) rappresenta la pendenza di una regressione standardizzata, \\(r^2\\) è molto meno intuitivo, poiché riflette solo la proporzione di varianza condivisa tra due variabili.\nPotenziale fuorviante: Elevare al quadrato \\(r\\) può distorcere la percezione dell’effetto. Ad esempio, una correlazione \\(r = 0.30\\) (effetto medio secondo Cohen) diventa \\(r^2 = 0.09\\), che sembra trascurabile, ma in realtà potrebbe avere un impatto significativo nel contesto applicativo.\n\nUn esempio chiaro è fornito da Darlington (1990). Consideriamo un gioco in cui si lanciano due monete: un nickel (5¢) e un dime (10¢). Se esce testa, si vincono rispettivamente 5¢ o 10¢. Le correlazioni tra il valore delle monete e il pagamento sono:\n\nNickel: \\(r = 0.4472\\) (\\(r^2 = 0.20\\)),\nDime: \\(r = 0.8944\\) (\\(r^2 = 0.80\\)).\n\nSe interpretassimo \\(r^2\\) in modo letterale, potremmo erroneamente concludere che il dime “conta quattro volte più” del nickel. Tuttavia, le correlazioni originali mostrano che \\(0.8944\\) è esattamente il doppio di \\(0.4472\\), offrendo un confronto più accurato e informativo.\nIn sintesi, l’interpretazione della dimensione dell’effetto richiede cautela e contestualizzazione. Gli standard di Cohen, sebbene ampiamente utilizzati, sono arbitrari e possono essere fuorvianti se applicati in modo acritico. Allo stesso modo, elevare al quadrato la correlazione \\(r\\) per ottenere \\(r^2\\) rischia di distorcere la percezione dell’effetto, rendendolo meno interpretabile e potenzialmente fuorviante. Per un’analisi robusta, è essenziale considerare il contesto e l’impatto pratico dell’effetto osservato, evitando di affidarsi esclusivamente a metriche standardizzate o trasformazioni matematiche poco informative.\n\n\n84.3.3 Alternative migliori\nÈ cruciale interpretare le dimensioni degli effetti in modo che ne arricchisca il significato. Funder & Ozer (2019) propongono due strategie principali: l’adozione di benchmark (criteri di riferimento) e la valutazione delle implicazioni pratiche dei risultati.\n\nUtilizzare criteri di riferimento significa confrontare l’entità di un risultato con quella di risultati ben noti e ampiamente compresi. Simile al modo in cui giudichiamo l’altezza di una persona basandoci su confronti con altri, i ricercatori possono ottenere una percezione accurata dell’importanza di un risultato confrontandolo con la dimensione di effetti noti, sia quelli tipici del campo di studio sia quelli emersi da ricerche passate.\nUn approccio al benchmarking può includere l’analisi di risultati considerati “classici” nel campo di interesse o la considerazione di dimensioni dell’effetto per risultati che hanno ottenuto un solido consenso nella comunità psicologica.\nIn un’ottica più ampia, alcuni ricercatori hanno proposto benchmark per la dimensione dell’effetto calcolando medie su vasti corpi di letteratura. Ad esempio, uno studio di psicologia sociale ha esaminato 708 correlazioni ottenute meta-analiticamente, rivelando che la dimensione media dell’effetto \\(r\\) era di .19.\nLa conoscenza comune o i risultati di ricerche non psicologiche possono offrire benchmark per valutare la forza di una relazione tra variabili. Un esempio è l’efficacia degli antistaminici contro il comune raffreddore, che corrisponde a un \\(r\\) di .11, mentre l’effetto degli anti-infiammatori non steroidei (come l’ibuprofene) sul dolore è di \\(r = .14\\).\n\nTali confronti illustrano come l’interpretazione delle dimensioni dell’effetto possa essere notevolmente approfondita e resa più significativa attraverso il riferimento a benchmark consolidati o intuitivamente comprensibili, sia dentro che fuori il campo della psicologia. Questo metodo consente di inserire i risultati di nuove ricerche in un contesto più vasto, favorendo una valutazione più consapevole della loro rilevanza relativa.\n\n\n84.3.4 Alternative Migliori per Interpretare la Dimensione dell’Effetto\nPer arricchire il significato delle dimensioni dell’effetto, è essenziale adottare approcci che vadano oltre le metriche standardizzate e si basino su criteri di riferimento concreti e contestualizzati. Funder & Ozer (2019) propone due strategie principali: l’uso di benchmark (criteri di riferimento) e la valutazione delle implicazioni pratiche dei risultati.\n\n84.3.4.1 1. Utilizzare Criteri di Riferimento (Benchmark)\nUn modo efficace per interpretare la dimensione dell’effetto è confrontarla con risultati ben noti e ampiamente compresi, sia all’interno del campo di studio che in contesti più generali. Questo approccio è simile a come giudichiamo l’altezza di una persona confrontandola con quella di altre persone.\n\nConfronto con Risultati Classici: I ricercatori possono ottenere una percezione più accurata dell’importanza di un risultato confrontandolo con dimensioni dell’effetto di studi considerati “classici” nel proprio campo. Ad esempio, in psicologia, è possibile fare riferimento a risultati che hanno ottenuto un solido consenso nella comunità scientifica.\nMedie da Meta-Analisi: Alcuni ricercatori hanno proposto benchmark calcolando medie su vasti corpi di letteratura. Ad esempio, uno studio di psicologia sociale ha analizzato 708 correlazioni ottenute meta-analiticamente, rilevando che la dimensione media dell’effetto \\(r\\) era di 0.19. Questo valore può servire come punto di riferimento per valutare l’entità di nuovi risultati.\nEsempi Trasversali: Anche conoscenze comuni o risultati di ricerche non psicologiche possono offrire benchmark utili. Ad esempio:\n\nL’efficacia degli antistaminici contro il comune raffreddore corrisponde a un \\(r = 0.11\\).\nL’effetto degli anti-infiammatori non steroidei (come l’ibuprofene) sul dolore è pari a \\(r = 0.14\\).\n\n\nQuesti confronti mostrano come l’interpretazione della dimensione dell’effetto possa essere notevolmente approfondita e resa più significativa attraverso il riferimento a benchmark consolidati o intuitivamente comprensibili.\n\n\n84.3.4.2 2. Valutare le Implicazioni Pratiche\nOltre ai benchmark, è fondamentale considerare le implicazioni pratiche dei risultati. Un effetto statisticamente piccolo può avere un impatto significativo se applicato a un contesto reale. Ad esempio:\n\nUn \\(r = 0.10\\) potrebbe sembrare trascurabile, ma se tradotto in un intervento su larga scala (ad esempio, un programma educativo o una politica sanitaria), potrebbe portare a benefici tangibili per un gran numero di persone.\n\nIn conclusione, l’interpretazione della dimensione dell’effetto può essere notevolmente migliorata attraverso l’uso di benchmark e la valutazione delle implicazioni pratiche. Confrontare i risultati con studi classici, medie di meta-analisi o esempi tratti da altri campi consente di inserire i nuovi risultati in un contesto più ampio e significativo. Questo approccio non solo arricchisce l’interpretazione, ma favorisce anche una valutazione più consapevole della rilevanza e dell’impatto delle scoperte scientifiche.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#riflessioni-conclusive",
    "href": "chapters/replication_crisis/03_effect_size.html#riflessioni-conclusive",
    "title": "84  La grandezza dell’effetto",
    "section": "84.4 Riflessioni Conclusive",
    "text": "84.4 Riflessioni Conclusive\nLa sovrastima della grandezza degli effetti in psicologia rappresenta un problema diffuso e significativo. Un principio spesso enfatizzato nella psicologia sociale e nell’economia comportamentale, specialmente nei media e nei corsi di business, è che piccoli interventi, o “nudge” (spinte gentili), possano produrre effetti sorprendentemente ampi sul comportamento. Questa idea ha portato a numerose affermazioni sensazionalistiche, come l’ipotesi che le elezioni possano essere influenzate dall’esito di partite di football o che stimoli subliminali, come una faccina sorridente, possano generare cambiamenti drastici negli atteggiamenti verso temi complessi come l’immigrazione.\nAlla base di queste affermazioni c’è un modello di mondo che non si limita al concetto di “effetto farfalla” (dove piccoli cambiamenti possono avere conseguenze imprevedibili e amplificate), ma suggerisce che piccoli interventi possano produrre effetti grandi e prevedibili. Questo approccio, talvolta definito “modello a pulsante” delle scienze sociali, presuppone che, facendo X, si possa aspettarsi di osservare Y in modo sistematico. Tuttavia, questa visione presenta diverse criticità:\n\n84.4.1 Problemi del Modello “a Pulsante”\n\nSovrastima degli effetti: Molti studi riportano effetti esagerati per interventi minimi, che spesso non vengono replicati in ricerche successive. Questo solleva dubbi sulla validità e sull’affidabilità di tali risultati.\nMancanza di considerazione delle interazioni: Se esistessero davvero molti effetti grandi e prevedibili, questi interferirebbero tra loro, rendendo difficile osservare risultati coerenti nei dati reali. La complessità del comportamento umano raramente si presta a relazioni lineari e isolate.\nInstabilità del sistema: Un sistema sociale caratterizzato da molti effetti grandi e prevedibili sarebbe intrinsecamente instabile e difficile da studiare, contraddicendo l’osservazione che le società tendono a mostrare una certa stabilità nel tempo.\nGeneralizzazione eccessiva: Spesso i risultati ottenuti in contesti di laboratorio altamente controllati vengono estesi a situazioni reali molto più complesse, senza considerare le differenze contestuali.\nBias di pubblicazione: Gli studi che riportano effetti grandi e statisticamente significativi hanno maggiori probabilità di essere pubblicati, creando una rappresentazione distorta della realtà e alimentando un ciclo di sovrastima.\n\n\n\n84.4.2 Verso un Approccio più Cauto e Sfumato\nNonostante queste criticità, è importante riconoscere che la psicologia ha identificato molti fenomeni robusti, specialmente in aree come la psicologia clinica e la psicologia della percezione. Tuttavia, è fondamentale adottare un approccio più cauto e riflessivo nell’interpretazione e nella comunicazione dei risultati della ricerca.\nLa consapevolezza di questi problemi ha portato a una serie di miglioramenti metodologici, tra cui:\n\nEnfasi sulla replicabilità: Maggiore attenzione alla riproducibilità degli studi per garantire che i risultati siano affidabili.\nUso di campioni più ampi: Studi condotti su campioni più grandi e diversificati per aumentare la validità esterna.\nMetodi statistici più robusti: Adozione di tecniche statistiche avanzate per ridurre il rischio di falsi positivi.\nApproccio critico e riflessivo: La comunità scientifica sta diventando sempre più consapevole della necessità di evitare semplificazioni eccessive e di riconoscere la complessità dei fenomeni psicologici.\n\nIn sintesi, mentre la psicologia offre intuizioni preziose sul comportamento umano, è essenziale mantenere un sano scetticismo verso affermazioni di effetti grandi e facilmente ottenibili. La realtà è spesso più complessa e sfumata di quanto suggerito da titoli sensazionalistici o da singoli studi. Un approccio equilibrato, che combina rigore metodologico, contestualizzazione e umiltà scientifica, è fondamentale per avanzare nella comprensione dei fenomeni psicologici e per evitare di cadere in trappole interpretative che possono distorcere la nostra visione del comportamento umano.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#bibliografia",
    "href": "chapters/replication_crisis/03_effect_size.html#bibliografia",
    "title": "84  La grandezza dell’effetto",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nFunder, D. C., & Ozer, D. J. (2019). Evaluating effect size in psychological research: Sense and nonsense. Advances in Methods and Practices in Psychological Science, 2(2), 156–168.\n\n\nGlass, G. V., McGaw, B., & Smith, M. L. (1981). Meta-analysis in Social Research. Sage Publications.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html",
    "href": "chapters/replication_crisis/04_s_m_errors.html",
    "title": "85  Errori di segno e errori di grandezza",
    "section": "",
    "text": "85.1 Introduzione\nIn questo capitolo analizzeremo la relazione tra la crisi della replicabilità e le procedure decisionali statistiche proprie dell’approccio frequentista. In particolare, approfondiremo gli errori di tipo M (magnitude) e di tipo S (sign), discussi da Loken & Gelman (2017), e il loro impatto sulla validità dei risultati scientifici.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>85</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#introduzione",
    "href": "chapters/replication_crisis/04_s_m_errors.html#introduzione",
    "title": "85  Errori di segno e errori di grandezza",
    "section": "",
    "text": "Domande Iniziali\n\n\n\nPrima di esplorare le simulazioni e i risultati discussi in questo capitolo, prova a riflettere sulle seguenti domande. Ti invitiamo a formulare delle ipotesi sui risultati delle simulazioni prima di leggere le spiegazioni:\n\nSe si effettuano molteplici studi su un effetto molto piccolo utilizzando campioni di dimensioni ridotte, cosa pensi che accadrà ai risultati pubblicati che ottengono significatività statistica? Saranno accurati rispetto alla vera grandezza dell’effetto?\nIn uno scenario in cui non esiste alcuna differenza tra due gruppi, quanto spesso credi che un test t fornisca un risultato statisticamente significativo che verrà pubblicato? Quali fattori potrebbero influenzare questa probabilità?\nSupponiamo che in una serie di esperimenti alcuni studi trovino effetti significativi e altri no. Quale pensi sia la tendenza degli studi pubblicati rispetto a quelli non pubblicati? Quale impatto può avere questa tendenza sulla percezione della realtà scientifica?\nSe dovessi valutare la replicabilità di uno studio basato sulla significatività statistica, quali problemi potresti incontrare se l’effetto sottostante è molto piccolo?\n\nTieni a mente le tue risposte mentre esplori le simulazioni presentate in questo capitolo. Alla fine del capitolo, confronteremo le previsioni con i risultati effettivi.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>85</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#il-filtro-della-significatività-statistica",
    "href": "chapters/replication_crisis/04_s_m_errors.html#il-filtro-della-significatività-statistica",
    "title": "85  Errori di segno e errori di grandezza",
    "section": "\n85.2 Il Filtro della Significatività Statistica",
    "text": "85.2 Il Filtro della Significatività Statistica\nNel ?sec-crisis abbiamo esplorato come la pratica scientifica contemporanea sia spesso compromessa da casi di frode, principalmente a causa delle significative implicazioni economiche legate alla pubblicazione su riviste scientifiche di alto prestigio. Questo fenomeno è spesso sottovalutato, poiché le riviste tendono a essere riluttanti nel riconoscere la necessità di correzioni o ritrattazioni degli articoli già pubblicati.\nLa frode scientifica rappresenta una minaccia evidente alla riproducibilità dei risultati, un pilastro fondamentale del metodo scientifico. Tuttavia, le difficoltà nel replicare i risultati pubblicati non sono attribuibili esclusivamente a frodi o a “pratiche di ricerca disoneste” (Nelson et al., 2018). Un problema intrinseco risiede nel metodo statistico ampiamente adottato dai ricercatori: l’approccio del test di ipotesi nulla e della significatività statistica di stampo fisheriano. Secondo questo metodo, i risultati che non raggiungono la soglia di “significatività statistica” vengono scartati, mentre quelli che la superano sono considerati credibili, basandosi esclusivamente su questo criterio (Wagenmakers et al., 2008).\nTuttavia, l’idea che la significatività statistica sia un filtro affidabile per distinguere i risultati di ricerca “validi” da quelli “non validi” è fondamentalmente errata. Numerose evidenze dimostrano i limiti di questo approccio. Per approfondire questa problematica, esamineremo lo studio di Loken & Gelman (2017), che mette in luce la relazione tra la crisi della replicabilità e le procedure decisionali statistiche dell’approccio frequentista.\nUno dei principali problemi evidenziati da Loken & Gelman (2017) è che, in contesti di ricerca complessi, la significatività statistica fornisce prove molto deboli riguardo al segno (sign) o all’entità (magnitude) degli effetti sottostanti. In altre parole, il raggiungimento della significatività statistica non garantisce né la rilevanza né la consistenza dei risultati ottenuti. Questo solleva seri dubbi sull’affidabilità di tale criterio come unico strumento per valutare la validità delle scoperte scientifiche.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>85</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#errori-di-tipo-m-e-s",
    "href": "chapters/replication_crisis/04_s_m_errors.html#errori-di-tipo-m-e-s",
    "title": "85  Errori di segno e errori di grandezza",
    "section": "\n85.3 Errori di tipo M e S\n",
    "text": "85.3 Errori di tipo M e S\n\nPer illustrare le implicazioni del processo decisionale basato sulla significatività statistica, Loken & Gelman (2017) hanno condotto una simulazione. In questa simulazione, hanno considerato uno scenario di ricerca ipotetico in cui era presente un effetto reale, sebbene molto debole, difficilmente rilevabile senza un ampio volume di dati. Utilizzando l’approccio frequentista, hanno cercato di identificare questo effetto valutando la significatività statistica.\nI risultati della simulazione hanno mostrato che, anche in presenza di un effetto reale (seppur debole), l’approccio frequentista riusciva a rilevare un effetto statisticamente significativo solo in una piccola percentuale dei casi. Inoltre, quando un effetto significativo veniva individuato, la stima della sua grandezza risultava altamente imprecisa e instabile.\nIn sintesi, la significatività statistica fornisce un’indicazione generica sulla presenza o assenza di un effetto, ma non offre informazioni affidabili sulla sua entità o replicabilità. Questo problema è particolarmente rilevante in campi come la psicologia e le scienze sociali, dove gli studi spesso si basano su campioni di dimensioni ridotte e gli effetti osservati tendono a essere modesti. In tali contesti, l’approccio frequentista rischia di produrre prove deboli e instabili, compromettendo la replicabilità e l’affidabilità dei risultati.\n\n85.3.1 Simulazione semplificata\nRiproduciamo qui, in forma semplificata, la simulazione condotta da Loken & Gelman (2017). Iniziamo importando le librerie necessarie.\nConsideriamo due campioni casuali indipendenti di dimensioni \\(n_1 = 20\\) e \\(n_2 = 25\\), estratti rispettivamente dalle distribuzioni normali \\(\\mathcal{N}(102, 10)\\) e \\(\\mathcal{N}(100, 10)\\). La dimensione effettiva dell’effetto (\\(d\\)) per la differenza tra le medie dei due campioni è calcolata utilizzando la formula:\n\\[\nd = \\frac{\\bar{y}_1 - \\bar{y}_2}{s_p},\n\\]\ndove \\(\\bar{y}_1\\) e \\(\\bar{y}_2\\) rappresentano le medie campionarie dei due gruppi, e \\(s_p\\) è la deviazione standard combinata, definita come:\n\\[\ns_p = \\sqrt{\\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1 + n_2 - 2}}.\n\\]\nIn questo caso specifico, la dimensione effettiva dell’effetto risulta molto piccola, indicando che la differenza osservata tra le medie dei due gruppi non ha una rilevanza pratica significativa. Ciò suggerisce che la distinzione tra i due gruppi, seppur statisticamente rilevabile, non ha un impatto sostanziale in contesti reali.\n\n# Parametri\nmu_1 &lt;- 102  # Media del primo gruppo\nmu_2 &lt;- 100  # Media del secondo gruppo\nsigma &lt;- 10  # Deviazione standard comune\nn1 &lt;- 20     # Numero di osservazioni nel primo gruppo\nn2 &lt;- 25     # Numero di osservazioni nel secondo gruppo\n\n# Calcolo della differenza media\nmean_difference &lt;- abs(mu_1 - mu_2)\n\n# Calcolo della deviazione standard pooled\npooled_sd &lt;- sqrt(((n1 - 1) * sigma^2 + (n2 - 1) * sigma^2) / (n1 + n2 - 2))\n\n# Calcolo di Cohen's d\ncohen_d &lt;- mean_difference / pooled_sd\n\n# Output del risultato\ncat(\"Dimensione dell'effetto (Cohen's d):\", cohen_d, \"\\n\")\n#&gt; Dimensione dell'effetto (Cohen's d): 0.2\n\nEsaminiamo ora le conclusioni che emergerebbero applicando l’approccio frequentista e la sua procedura di decisione statistica in questo contesto. Supponiamo di condurre una simulazione in cui vengono estratti due campioni: il primo composto da 20 osservazioni provenienti dalla prima popolazione e il secondo da 25 osservazioni provenienti dalla seconda popolazione. Successivamente, applichiamo il test \\(t\\) di Student per confrontare le medie dei due gruppi.\nNell’ambito dell’approccio frequentista, il valore-\\(p\\) ottenuto dal test determina la decisione statistica. Se il valore-\\(p\\) è superiore a 0.05, i risultati vengono considerati non significativi e, di conseguenza, scartati. Al contrario, se il valore-\\(p\\) è inferiore a 0.05, il risultato è ritenuto “pubblicabile” e si conclude che esiste una differenza statisticamente significativa tra i due gruppi.\nPer valutare in modo approfondito le conclusioni derivate da questa procedura, è necessario ripetere l’intero processo per un numero elevato di iterazioni, ad esempio 50.000 volte. Ciò significa che, in ciascuna iterazione, vengono estratti nuovi campioni, viene calcolato il test \\(t\\) di Student e viene determinato il corrispondente valore-\\(p\\). Ripetendo questo processo su larga scala, è possibile ottenere una distribuzione completa dei risultati, che consente di analizzare la frequenza con cui si ottengono risultati significativi e la stabilità delle stime prodotte dall’approccio frequentista in questo contesto.\n\n# Parametri\nn_samples &lt;- 50000\nmu_1 &lt;- 102\nmu_2 &lt;- 100\nsigma &lt;- 10\nn1 &lt;- 20\nn2 &lt;- 25\n\n# Inizializzazione del risultato\nres &lt;- c()\n\n# Simulazioni\nset.seed(123)  # Per la riproducibilità\nfor (i in 1:n_samples) {\n  # Generazione dei campioni casuali\n  y1 &lt;- rnorm(n1, mean = mu_1, sd = sigma)\n  y2 &lt;- rnorm(n2, mean = mu_2, sd = sigma)\n  \n  # Calcolo della dimensione dell'effetto\n  y1bar &lt;- mean(y1)\n  y2bar &lt;- mean(y2)\n  v1 &lt;- var(y1)\n  v2 &lt;- var(y2)\n  s &lt;- sqrt(((n1 - 1) * v1 + (n2 - 1) * v2) / (n1 + n2 - 2))\n  efsize &lt;- (y1bar - y2bar) / s\n  \n  # Calcolo del valore p\n  t_test &lt;- t.test(y1, y2, var.equal = TRUE)\n  \n  # Salvataggio della dimensione dell'effetto solo per risultati \"statisticamente significativi\"\n  if (t_test$p.value &lt; 0.05) {\n    res &lt;- c(res, efsize)\n  }\n}\n\n\nres_df &lt;- data.frame(effect_size = res)\n\nggplot(res_df, aes(x = effect_size)) +\n  geom_histogram(bins = 20, fill = \"blue\", color = \"black\", alpha = 0.7) +\n  geom_vline(\n    xintercept = 0.2, color = \"red\", linetype = \"dashed\", \n    size = 1.2, label = \"True Effect Size\") +\n  labs(\n    x = \"Effect Size\",\n    y = \"Frequency\",\n    title = \"Histogram of Effect Sizes for\\n'Statistically Significant' Results\"\n  ) \n\n\n\n\n\n\n\nCome evidenziato da Loken & Gelman (2017), l’applicazione dell’approccio frequentista nella procedura di decisione statistica può condurre a due tipi di errori rilevanti. Il primo, noto come errore di magnitude (grandezza), si manifesta quando i risultati pubblicati tendono a sovrastimare la reale entità dell’effetto. Nella simulazione condotta, nonostante la vera grandezza dell’effetto fosse modesta (0.2), la media della grandezza dell’effetto per i risultati classificati come “statisticamente significativi” era circa 0.8, suggerendo un effetto di entità “ampia”. Questo indica una distorsione sistematica verso stime esagerate.\nIl secondo errore, chiamato errore di segno, si verifica quando, a causa della variabilità campionaria, la direzione dell’effetto viene stimata in modo errato. In tali casi, il ricercatore potrebbe erroneamente concludere che \\(\\mu_2 &gt; \\mu_1\\), quando in realtà non è così. È importante sottolineare che, anche in queste situazioni, la grandezza assoluta dell’effetto risulta sovrastimata.\nUn aspetto degno di nota è che queste conclusioni rimarrebbero valide anche se si considerasse l’intervallo di confidenza per la differenza tra le medie. In sintesi, l’approccio frequentista introduce un errore sistematico nella stima della grandezza dell’effetto, che rappresenta la quantità più rilevante per il ricercatore. In alcuni casi, può persino portare a errori nella determinazione della direzione dell’effetto, compromettendo ulteriormente l’affidabilità delle conclusioni scientifiche.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>85</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#riflessioni-conclusive",
    "href": "chapters/replication_crisis/04_s_m_errors.html#riflessioni-conclusive",
    "title": "85  Errori di segno e errori di grandezza",
    "section": "\n85.4 Riflessioni Conclusive",
    "text": "85.4 Riflessioni Conclusive\nIn conclusione, l’approccio frequentista non rappresenta un metodo affidabile per valutare i risultati della ricerca e determinarne l’attendibilità o la necessità di scartarli (Gelman & Carlin, 2014; Loken & Gelman, 2017). Questa mancanza di affidabilità è dovuta all’introduzione di errori sistematici nella stima della grandezza degli effetti, che in alcuni casi possono persino portare a errori nella direzione dell’effetto stesso. Alla luce di queste criticità, non sembrano esserci motivi validi per continuare a fare affidamento su questo approccio.\nAl contrario, l’adozione dell’approccio bayesiano sembra offrire una soluzione più precisa e affidabile per l’analisi dei dati di ricerca. Questo metodo valuta la probabilità delle ipotesi alla luce dei dati osservati, evitando gli errori intrinseci dell’approccio frequentista e fornendo una base più solida per prendere decisioni informate sulla validità dei risultati. In questo modo, l’approccio bayesiano si presenta come un’alternativa più robusta e scientificamente rigorosa.\n\n\n\n\n\n\nRisposte alle domande iniziali\n\n\n\n\n\nOra confrontiamo le previsioni con i risultati ottenuti dalle simulazioni:\n\nSovrastima della grandezza dell’effetto: I risultati pubblicati tendono a essere selezionati sulla base della significatività statistica, il che porta a una sovrastima sistematica della grandezza dell’effetto rispetto alla realtà. Questo fenomeno, noto come errore di tipo M (magnitude), si verifica perché solo gli effetti con valori estremi (per caso) superano la soglia di significatività statistica e vengono pubblicati.\nFalsi positivi e loro frequenza: In uno scenario in cui non esiste alcuna differenza tra i due gruppi (cioè la vera differenza è zero), il test t ha fornito risultati statisticamente significativi nel 5% dei casi, come previsto dalla soglia di α = 0.05. Tuttavia, la selezione dei risultati pubblicati amplifica questo problema, rendendo più probabile che i lettori incontrino falsi positivi nella letteratura scientifica.\nBias nella pubblicazione: Gli studi che riportano risultati significativi hanno maggiore probabilità di essere pubblicati rispetto a quelli che non trovano un effetto significativo. Questo porta a un effetto distorsivo nella letteratura scientifica, in cui i risultati pubblicati tendono a sovrastimare l’effetto reale. Il “filtro della significatività statistica” crea una percezione distorta della realtà scientifica, poiché gli effetti nulli o piccoli tendono a essere sottorappresentati nella letteratura.\nReplicabilità e significatività statistica: Gli studi con effetti piccoli e campioni ridotti sono particolarmente vulnerabili al fallimento della replicazione. Anche quando un effetto reale esiste, la probabilità di ottenerne una stima precisa è bassa, e la replicazione potrebbe risultare in un valore non significativo, generando confusione nella comunità scientifica.\n\nConsiderazioni Finali\nLe simulazioni evidenziano come la significatività statistica, utilizzata come criterio per la pubblicazione, contribuisca a un bias nella selezione dei risultati, distorcendo la percezione della realtà scientifica. Questo fenomeno, noto come “filtro della significatività statistica”, è una delle cause principali della crisi della replicabilità, poiché induce i ricercatori e i lettori a sovrastimare la grandezza e la presenza di effetti studiati.\nPer affrontare queste problematiche, approcci alternativi, come quelli bayesiani, possono offrire soluzioni più robuste, permettendo una valutazione più affidabile delle ipotesi alla luce dei dati osservati.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>85</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#esercizi",
    "href": "chapters/replication_crisis/04_s_m_errors.html#esercizi",
    "title": "85  Errori di segno e errori di grandezza",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\n\nPerché la significatività statistica non è un criterio affidabile per valutare la validità dei risultati scientifici?\nSpiega il concetto di “filtro della significatività statistica” e il suo impatto sulla pubblicazione dei risultati.\nQual è la differenza tra errore di tipo M e errore di tipo S? Come influenzano l’interpretazione dei risultati?\nPerché i risultati pubblicati tendono a sovrastimare la grandezza dell’effetto rispetto alla realtà?\nQuali sono le conseguenze della pubblicazione selettiva dei risultati per la replicabilità degli studi?\nPerché gli studi con campioni di piccole dimensioni sono più vulnerabili a errori nella stima della grandezza dell’effetto?\nIn che modo la selezione dei risultati pubblicati altera la percezione della forza degli effetti studiati?\nPerché un test frequentista può portare a una falsa conclusione sulla direzione di un effetto?\nQuali sono le principali differenze tra l’approccio frequentista e quello bayesiano nella valutazione della significatività di un effetto?\nIn che modo l’approccio bayesiano può ridurre il rischio di errori dovuti alla selezione dei risultati basata sulla significatività statistica?\n\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\n\nLa significatività statistica non garantisce la validità di un risultato perché dipende dalla dimensione del campione e da soglie arbitrarie (come p &lt; 0.05). Inoltre, non misura la rilevanza pratica di un effetto, ma solo la probabilità che i dati osservati siano ottenuti sotto l’ipotesi nulla.\nIl “filtro della significatività statistica” si riferisce alla tendenza a pubblicare solo risultati con p &lt; 0.05, tralasciando studi con risultati non significativi. Questo porta a una distorsione nella letteratura scientifica e a una sovrastima della forza degli effetti riportati.\nErrore di tipo M (Magnitude) indica la sovrastima della grandezza dell’effetto nei risultati pubblicati, mentre errore di tipo S (Sign) si riferisce all’errata determinazione della direzione dell’effetto. Questi errori si verificano perché solo gli effetti più estremi tendono a superare il filtro della significatività statistica.\nI risultati pubblicati tendono a sovrastimare la grandezza dell’effetto perché solo gli effetti più grandi (anche per pura casualità) superano la soglia di significatività statistica e vengono pubblicati, mentre quelli più piccoli restano inediti.\nLa pubblicazione selettiva riduce la replicabilità perché introduce una distorsione sistematica nei risultati disponibili. Le repliche spesso non trovano effetti altrettanto grandi o significativi, creando instabilità nella conoscenza scientifica.\nI campioni piccoli aumentano la variabilità delle stime dell’effetto, rendendo più probabile che un risultato significativo sia solo un’oscillazione casuale dei dati piuttosto che un vero effetto replicabile.\nLa selezione dei risultati pubblicati altera la percezione della forza degli effetti perché induce i lettori a credere che gli effetti siano più forti e consistenti di quanto non siano realmente.\nUn test frequentista può portare a una falsa conclusione sulla direzione dell’effetto perché, in campioni piccoli, le stime dell’effetto possono essere fortemente influenzate dal rumore, portando a interpretazioni errate.\nL’approccio frequentista si basa sul valore-p e sulla soglia di significatività, mentre l’approccio bayesiano utilizza la probabilità a posteriori per aggiornare la credibilità delle ipotesi alla luce dei dati osservati. Il metodo bayesiano permette inferenze più flessibili e robuste.\nL’approccio bayesiano riduce il rischio di errori dovuti alla selezione dei risultati perché non si basa su una soglia arbitraria di significatività, ma fornisce un quadro probabilistico della forza dell’effetto, evitando distorsioni dovute alla pubblicazione selettiva.\n\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nIn questo esercizio simuleremo più esperimenti, ognuno con 15 osservazioni, per comprendere come il filtro della significatività statistica possa distorcere le nostre conclusioni sugli effetti osservati.\nObiettivo\n\nComprendere come l’approccio frequentista possa portare a stime errate dell’effetto reale.\nEsplorare gli errori di tipo M (magnitude) e S (sign), derivanti dal filtro della significatività statistica.\n\nStruttura dell’esercizio\n\nSimuliamo esperimenti in cui il vero effetto tra due gruppi è piccolo (Cohen’s d = 0.2). Consideriamo i dati SWLS e due popolazioni che differiscono nel modo indicato. Ipotizziamo che le due popolazioni SWLS siano normali.\nEstraiamo 15 osservazioni per gruppo.\nUsiamo un test t per verificare se la differenza tra i gruppi è significativa.\nRegistriamo solo i risultati con p &lt; 0.05, calcolando la distribuzione degli effetti significativi.\nValutiamo se la stima dell’effetto nei risultati pubblicabili è gonfiata rispetto al vero effetto.\nContiamo i casi in cui il segno dell’effetto è invertito.\n\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\n# Librerie necessarie\nlibrary(ggplot2)\n\n# Impostazioni della simulazione\nset.seed(42)         # Per la riproducibilità\nn_sims &lt;- 50000      # Numero di simulazioni\nn_per_group &lt;- 15    # Numero di osservazioni per gruppo\ntrue_d &lt;- 0.2        # Vero effetto (Cohen's d)\nswls_mean &lt;- 25      # Media ipotizzata per il primo gruppo\nswls_sd &lt;- 5         # Deviazione standard ipotizzata per la SWLS\n\n# Calcolo della media del secondo gruppo sulla base di Cohen's d\nswls_mean_2 &lt;- swls_mean + true_d * swls_sd\n\n# Inizializziamo i vettori per registrare i risultati\neffect_sizes &lt;- c()\nfalse_sign_count &lt;- 0\n\n# Simulazioni\nfor (i in 1:n_sims) {\n  # Generazione dei due gruppi da distribuzioni normali\n  group1 &lt;- rnorm(n_per_group, mean = swls_mean, sd = swls_sd)\n  group2 &lt;- rnorm(n_per_group, mean = swls_mean_2, sd = swls_sd)\n  \n  # Calcolo della dimensione dell'effetto (Cohen's d)\n  mean_diff &lt;- mean(group2) - mean(group1)\n  pooled_sd &lt;- sqrt(((n_per_group - 1) * var(group1) + (n_per_group - 1) * var(group2)) / (2 * n_per_group - 2))\n  d_estimated &lt;- mean_diff / pooled_sd\n  \n  # Test t per confrontare le medie\n  t_test &lt;- t.test(group1, group2, var.equal = TRUE)\n  \n  # Consideriamo solo i risultati statisticamente significativi\n  if (t_test$p.value &lt; 0.05) {\n    effect_sizes &lt;- c(effect_sizes, d_estimated)\n    \n    # Conta i casi in cui il segno è invertito\n    if (d_estimated &lt; 0) {\n      false_sign_count &lt;- false_sign_count + 1\n    }\n  }\n}\n\n# Creazione di un dataframe per la visualizzazione\nres_df &lt;- data.frame(effect_size = effect_sizes)\n\n# Istogramma della dimensione dell'effetto tra i risultati \"significativi\"\nggplot(res_df, aes(x = effect_size)) +\n  geom_histogram(bins = 30, fill = \"blue\", color = \"black\", alpha = 0.7) +\n  geom_vline(xintercept = true_d, color = \"red\", linetype = \"dashed\", size = 1.2) +\n  labs(\n    x = \"Dimensione dell'effetto stimata\",\n    y = \"Frequenza\",\n    title = \"Distribuzione degli effetti significativi (SWLS)\"\n  ) +\n  theme_minimal()\n\n# Output di sintesi\ncat(\"Numero di risultati statisticamente significativi:\", length(effect_sizes), \"\\n\")\ncat(\"Media della dimensione dell'effetto tra i risultati pubblicati:\", mean(effect_sizes), \"\\n\")\ncat(\"Numero di risultati con segno invertito:\", false_sign_count, \"\\n\")\ncat(\"Proporzione di risultati con segno invertito:\", false_sign_count / length(effect_sizes), \"\\n\")\nInterpretazione dei Risultati\n\n\nErrore di tipo M (Magnitude): La media degli effetti stimati nei risultati pubblicati sarà molto più grande di 0.2 (il vero effetto), dimostrando come il filtro della significatività tenda a sovrastimare gli effetti reali.\n\nErrore di tipo S (Sign): Una percentuale dei risultati pubblicabili mostrerà effetti nella direzione sbagliata (d &lt; 0), dimostrando che il processo decisionale basato su p &lt; 0.05 può portare a conclusioni errate.\n\nVisualizzazione: L’istogramma mostrerà che la distribuzione degli effetti significativi è spostata rispetto al vero effetto (linea rossa tratteggiata).\n\nDomande di discussione:\n\nPerché la stima dell’effetto è gonfiata nei risultati pubblicabili?\nCome cambia la situazione aumentando il numero di osservazioni per gruppo?\nQuali strategie alternative potrebbero ridurre questi errori?\n\nApprofondimento:\n\nRipetere l’esperimento con n_per_group = 50 e osservare se l’errore di tipo M diminuisce.\nConfrontare questo approccio con un’analisi Bayesiana per evidenziare il ruolo dell’inferenza basata su probabilità posteriori.\n\nConclusione\nQuesto esercizio mostra chiaramente i problemi dell’approccio frequentista basato su p &lt; 0.05, evidenziando i limiti dell’uso della significatività statistica come filtro decisionale.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>85</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/replication_crisis/04_s_m_errors.html#informazioni-sullambiente-di-sviluppo",
    "title": "85  Errori di segno e errori di grandezza",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.12.0 psych_2.5.3     \n#&gt;  [9] scales_1.4.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.2   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.4     stringi_1.8.7      lattice_0.22-7    \n#&gt;  [4] hms_1.1.3          digest_0.6.37      magrittr_2.0.3    \n#&gt;  [7] evaluate_1.0.3     grid_4.5.0         timechange_0.3.0  \n#&gt; [10] RColorBrewer_1.1-3 fastmap_1.2.0      rprojroot_2.0.4   \n#&gt; [13] jsonlite_2.0.0     mnormt_2.1.1       cli_3.6.5         \n#&gt; [16] rlang_1.1.6        withr_3.0.2        yaml_2.3.10       \n#&gt; [19] tools_4.5.0        parallel_4.5.0     tzdb_0.5.0        \n#&gt; [22] pacman_0.5.1       vctrs_0.6.5        R6_2.6.1          \n#&gt; [25] lifecycle_1.0.4    htmlwidgets_1.6.4  pkgconfig_2.0.3   \n#&gt; [28] pillar_1.10.2      gtable_0.3.6       glue_1.8.0        \n#&gt; [31] xfun_0.52          tidyselect_1.2.1   rstudioapi_0.17.1 \n#&gt; [34] farver_2.1.2       htmltools_0.5.8.1  nlme_3.1-168      \n#&gt; [37] labeling_0.4.3     rmarkdown_2.29     compiler_4.5.0",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>85</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#bibliografia",
    "href": "chapters/replication_crisis/04_s_m_errors.html#bibliografia",
    "title": "85  Errori di segno e errori di grandezza",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., & Carlin, J. (2014). Beyond Power Calculations: Assessing Type S (Sign) and Type M (Magnitude) Errors. Perspectives on Psychological Science, 9(6), 641–651.\n\n\nLoken, E., & Gelman, A. (2017). Measurement Error and the Replication Crisis. Science, 355(6325), 584–585.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nNelson, L. D., Simmons, J., & Simonsohn, U. (2018). Psychology’s renaissance. Annual review of psychology, 69(1), 511–534.\n\n\nWagenmakers, E.-J., Lee, M., Lodewyckx, T., & Iverson, G. J. (2008). Bayesian versus frequentist inference. Bayesian evaluation of informative hypotheses, 181–207.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>85</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_p_values.html",
    "href": "chapters/replication_crisis/05_p_values.html",
    "title": "\n86  La fragilità del p-valore\n",
    "section": "",
    "text": "86.1 Introduzione\nIl codice presentato è ispirato da un post sul blog di Andrew Gelman. L’obiettivo è esplorare la fragilità dei p-valori e la loro variabilità in diverse condizioni sperimentali.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>La fragilità del *p*-valore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_p_values.html#simulazione",
    "href": "chapters/replication_crisis/05_p_values.html#simulazione",
    "title": "\n86  La fragilità del p-valore\n",
    "section": "\n86.2 Simulazione",
    "text": "86.2 Simulazione\nQuesta simulazione mira a dimostrare quanto i p-valori possano essere instabili e variare significativamente da campione a campione, anche quando i dati provengono da una distribuzione con parametri molto simili. Questo evidenzia come il p-valore, comunemente utilizzato per valutare la significatività statistica di un effetto, possa essere fortemente influenzato dalla variabilità campionaria, specialmente in campioni di piccole dimensioni o con effetti deboli. Gelman & Stern (2006) esprimono questo concetto affermando che:\n\nla differenza tra “significativo” e “non significativo” non è di per sé statisticamente significativa.\n\n\n86.2.1 Logica della Simulazione\n\n\nObiettivo:\n\nDimostrare la variabilità dei p-valori calcolati su diversi campioni estratti da una popolazione con una media molto vicina a zero.\nMostrare come, nonostante l’effetto reale sia piccolo, i p-valori possano variare notevolmente a seconda della variabilità e delle dimensioni del campione.\n\n\n\nSetup della Simulazione:\n\nGeneriamo \\(J = 10\\) campioni indipendenti, ciascuno con un numero ridotto di osservazioni (\\(n = 10\\)), per massimizzare la variabilità dei risultati.\nOgni campione è generato da una distribuzione normale con una media vera di \\(\\mu = 0.05\\) e una deviazione standard di \\(\\sigma = 0.1\\). Questi parametri sono scelti per rendere la media dei campioni vicina a zero, mantenendo una certa variabilità.\n\n\n\nCalcolo della media campionaria:\n\nPer ciascun campione, calcoliamo la media (\\(\\hat{\\mu}\\)) e la deviazione standard (\\(\\hat{\\sigma}\\)).\nLa media del campione (\\(\\hat{\\mu}\\)) è utilizzata come stima del parametro.\n\n\n\nCalcolo del p-valore:\n\nApplichiamo un t-test per ciascun campione per verificare l’ipotesi nulla (\\(H_0\\)) che la media del campione sia zero.\n\nIl p-valore viene calcolato utilizzando la formula classica del t-test:\n\\[\nt = \\frac{\\hat{\\mu}}{\\frac{\\hat{\\sigma}}{\\sqrt{n}}}\n\\]\ndove:\n\n\n\\(\\hat{\\mu}\\) è la media del campione,\n\n\\(\\hat{\\sigma}\\) è la deviazione standard del campione,\n\n\\(n\\) è il numero di osservazioni per campione.\n\n\n\nSuccessivamente, il p-valore è calcolato come:\n\\[\n\\text{p-value} = 2 \\times (1 - \\text{CDF}(|t|))\n\\]\ndove \\(\\text{CDF}\\) è la funzione cumulativa della distribuzione t con \\(n-1\\) gradi di libertà.\n\n\n\n\n86.2.2 Descrizione della Sintassi\nIl codice R è strutturato come segue:\n\n\nGenerazione dei campioni:\n\nCreiamo una lista di campioni (10 campioni in totale), ciascuno con 10 osservazioni, utilizzando la distribuzione normale con media 0.05 e deviazione standard 0.1.\n\n\n\nCalcolo delle medie e dei p-valori:\n\nIteriamo su ciascun campione per calcolare la media (\\(\\hat{\\mu}\\)) e la deviazione standard (\\(\\hat{\\sigma}\\)).\nCalcoliamo il valore statistico \\(t\\) e il corrispondente p-valore utilizzando la distribuzione t.\n\n\n\nStampa dei risultati:\n\nI p-valori vengono arrotondati e stampati per osservare la loro variabilità.\n\n\n\n\n# Imposta il seme per riproducibilità\nset.seed(1234)\n\n# Parametri della simulazione\nJ &lt;- 10              # Numero di campioni indipendenti\nn &lt;- 10              # Numero di osservazioni per campione\ntrue_mean &lt;- 0.05    # Media vera della popolazione\ntrue_sd &lt;- 0.1       # Deviazione standard della popolazione\n\n# Genera i campioni casuali\nsamples &lt;- replicate(J, rnorm(n, mean = true_mean, sd = true_sd), simplify = FALSE)\n\n# Calcola statistiche campionarie e p-valori\nresults &lt;- lapply(samples, function(sample) {\n  sample_mean &lt;- mean(sample)                         # Media campionaria\n  sample_sd &lt;- sd(sample)                             # Deviazione standard campionaria\n  t_statistic &lt;- sample_mean / (sample_sd / sqrt(n))  # Statistica t\n  p_value &lt;- 2 * (1 - pt(abs(t_statistic), df = n - 1))  # p-valore bilaterale\n  list(mean = sample_mean, sd = sample_sd, t = t_statistic, p_value = p_value)\n})\n\n# Converti i risultati in un data frame per facilitarne la visualizzazione\nresults_df &lt;- do.call(rbind, lapply(results, as.data.frame))\nrownames(results_df) &lt;- paste(\"C\", 1:J)\n\n# Visualizza i risultati\nprint(results_df)\n#&gt;          mean      sd       t  p_value\n#&gt; C 1   0.01168 0.09958  0.3711 0.719183\n#&gt; C 2   0.03818 0.10673  1.1313 0.287183\n#&gt; C 3   0.01121 0.06660  0.5320 0.607576\n#&gt; C 4  -0.02662 0.08942 -0.9413 0.371116\n#&gt; C 5  -0.01098 0.07872 -0.4411 0.669552\n#&gt; C 6   0.02211 0.11860  0.5896 0.569941\n#&gt; C 7   0.11166 0.11442  3.0860 0.013013\n#&gt; C 8   0.04577 0.09237  1.5670 0.151566\n#&gt; C 9   0.03415 0.07349  1.4695 0.175755\n#&gt; C 10  0.10607 0.09840  3.4089 0.007763\n\n\nggplot(results_df, aes(x = rownames(results_df), y = p_value)) +\n  geom_point(size = 3, color = \"blue\") +\n  geom_hline(yintercept = 0.05, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Variabilità dei p-valori nei campioni\",\n    x = \"Campioni\",\n    y = \"p-valore\"\n  ) \n\n\n\n\n\n\n\n\n86.2.3 Interpretazione dei Risultati\nImmaginiamo che questo sia un esperimento reale. Alcuni campioni potrebbero mostrare risultati compatibili con il puro rumore, altri fornire deboli indicazioni contro l’ipotesi nulla, mentre altri ancora potrebbero sembrare altamente significativi dal punto di vista statistico. Tuttavia, la differenza tra “significativo” e “non significativo” non è di per sé statisticamente significativa. Ad esempio, una differenza tra un p-valore di 0.336 e uno di 0.003 potrebbe sembrare rilevante, ma non lo è.\nQuesto scenario estremo riflette una situazione in cui non c’è una reale variazione sottostante. Se si utilizzasse un modello multilivello, probabilmente emergerebbe l’assenza di una variazione effettiva significativa.\n\n86.2.4 Punti Chiave\n\nIl p-valore descrive solo l’ipotesi nulla: È una misura relativa all’assenza di effetto, ma non ha necessariamente un significato diretto rispetto a un effetto reale, anche se piccolo.\nIl p-valore è altamente variabile: Essendo una trasformazione non lineare dello z-score, il p-valore può comportarsi in modi non intuitivi, soprattutto con campioni piccoli.\nLe simulazioni sono istruttive: Anche esperimenti semplici come questo possono essere estremamente utili per comprendere le limitazioni e l’interpretazione dei risultati.\n\n86.2.5 Un Avvertimento Importante\nAnche le inferenze bayesiane sono soggette a variabilità. Qualsiasi sintesi dei dati porta con sé un certo grado di incertezza. Il problema non risiede nei p-valori in sé, ma nel loro utilizzo scorretto. Interpretare un p-valore come una dichiarazione forte sulla realtà, invece di considerarlo un riassunto rumoroso di un esperimento specifico, è un errore comune.\nAllo stesso modo, fraintendimenti e sovrainterpretazioni possono verificarsi anche con approcci bayesiani. Ad esempio, l’adattamento di un modello con prior non informativi e l’interpretazione della probabilità posteriore di un parametro (ad esempio, maggiore di zero) sulla base di una soglia arbitraria può portare a conclusioni altrettanto problematiche. Questi risultati ci ricordano l’importanza di una sana cautela nell’interpretazione statistica, indipendentemente dal metodo utilizzato.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>La fragilità del *p*-valore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_p_values.html#riflessioni-conclusive",
    "href": "chapters/replication_crisis/05_p_values.html#riflessioni-conclusive",
    "title": "\n86  La fragilità del p-valore\n",
    "section": "\n86.3 Riflessioni Conclusive",
    "text": "86.3 Riflessioni Conclusive\nLa simulazione mostra che, nonostante le medie dei campioni siano generate con una distribuzione simile, i p-valori possono variare drasticamente. Questo effetto è amplificato dalla scelta di campioni piccoli e di una media vera molto vicina all’ipotesi nulla (zero). Dimostra quanto il p-valore possa essere influenzato da piccole variazioni nei dati e perché non sia sempre un indicatore affidabile per valutare l’efficacia o la presenza di un effetto.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>La fragilità del *p*-valore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_p_values.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/replication_crisis/05_p_values.html#informazioni-sullambiente-di-sviluppo",
    "title": "\n86  La fragilità del p-valore\n",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.12.0 psych_2.5.3     \n#&gt;  [9] scales_1.4.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.2   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.4     stringi_1.8.7      lattice_0.22-7    \n#&gt;  [4] hms_1.1.3          digest_0.6.37      magrittr_2.0.3    \n#&gt;  [7] evaluate_1.0.3     grid_4.5.0         timechange_0.3.0  \n#&gt; [10] RColorBrewer_1.1-3 fastmap_1.2.0      rprojroot_2.0.4   \n#&gt; [13] jsonlite_2.0.0     mnormt_2.1.1       cli_3.6.5         \n#&gt; [16] rlang_1.1.6        withr_3.0.2        tools_4.5.0       \n#&gt; [19] parallel_4.5.0     tzdb_0.5.0         pacman_0.5.1      \n#&gt; [22] vctrs_0.6.5        R6_2.6.1           lifecycle_1.0.4   \n#&gt; [25] htmlwidgets_1.6.4  pkgconfig_2.0.3    pillar_1.10.2     \n#&gt; [28] gtable_0.3.6       glue_1.8.0         xfun_0.52         \n#&gt; [31] tidyselect_1.2.1   rstudioapi_0.17.1  farver_2.1.2      \n#&gt; [34] htmltools_0.5.8.1  nlme_3.1-168       labeling_0.4.3    \n#&gt; [37] rmarkdown_2.29     compiler_4.5.0",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>La fragilità del *p*-valore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_p_values.html#bibliografia",
    "href": "chapters/replication_crisis/05_p_values.html#bibliografia",
    "title": "\n86  La fragilità del p-valore\n",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., & Stern, H. (2006). The difference between «significant» and «not significant» is not itself statistically significant. The American Statistician, 60(4), 328–331.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>La fragilità del *p*-valore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html",
    "href": "chapters/replication_crisis/06_changes.html",
    "title": "87  Riforma",
    "section": "",
    "text": "87.1 Introduzione\nLa crisi della riproducibilità ha stimolato un profondo dibattito sullo stato della ricerca nelle scienze comportamentali, cognitive e sociali. La scoperta che molti studi pubblicati non sono replicabili ha minato la fiducia nella ricerca scientifica, evidenziando carenze metodologiche e strutturali nel sistema accademico. In risposta a questa crisi, sono state avanzate diverse proposte di riforma per migliorare la qualità e l’affidabilità della ricerca scientifica.\nSecondo Korbmacher et al. (2023), sono necessarie riforme strutturali, cambiamenti procedurali e trasformazioni nella comunità scientifica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#riforme-strutturali",
    "href": "chapters/replication_crisis/06_changes.html#riforme-strutturali",
    "title": "87  Riforma",
    "section": "87.2 Riforme Strutturali",
    "text": "87.2 Riforme Strutturali\n\n87.2.1 Integrazione della Riproducibilità nei Curriculum Educativi\nUna proposta chiave per affrontare la crisi della riproducibilità è l’integrazione delle pratiche di riproducibilità nei curriculum delle scienze psicologiche e affini. Attualmente, molti programmi di formazione non enfatizzano sufficientemente l’importanza della replicabilità e della trasparenza nella ricerca. Includere questi temi nei corsi di metodologia della ricerca può sensibilizzare le nuove generazioni di ricercatori sull’adozione di pratiche più rigorose e trasparenti. Alcuni programmi universitari hanno già iniziato a incorporare repliche di studi famosi nel percorso formativo, offrendo agli studenti l’opportunità di comprendere meglio i limiti e le potenzialità del processo scientifico.\n\n\n87.2.2 Incentivi per la Scienza Aperta\nUn altro aspetto cruciale è la riforma dei sistemi di incentivazione accademica. Tradizionalmente, il sistema accademico ha privilegiato la quantità di pubblicazioni e la novità dei risultati, piuttosto che la loro qualità e replicabilità. Per promuovere pratiche di scienza aperta, come la preregistrazione degli studi e la condivisione aperta dei dati, si propone l’introduzione di riconoscimenti ufficiali, come badge di “open science” o crediti accademici per la pubblicazione di rapporti registrati. Questi cambiamenti potrebbero favorire una maggiore adozione di pratiche che promuovono la trasparenza e rafforzano la fiducia nella ricerca scientifica.\nA tal proposito, uno studio di Scheel et al. (2021) ha confrontato i risultati di rapporti registrati pubblicati (N = 71) con un campione casuale di studi ipotetico-deduttivi della letteratura standard (N = 152) in psicologia. Analizzando la prima ipotesi di ciascun articolo, è emerso che il 96% dei risultati nei rapporti standard erano positivi, contro solo il 44% nei rapporti registrati.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#cambiamenti-procedurali",
    "href": "chapters/replication_crisis/06_changes.html#cambiamenti-procedurali",
    "title": "87  Riforma",
    "section": "87.3 Cambiamenti Procedurali",
    "text": "87.3 Cambiamenti Procedurali\n\n87.3.1 Mercati di Previsione per la Credibilità della Ricerca\nI mercati di previsione sono stati proposti come strumento innovativo per valutare la credibilità della ricerca. In questi mercati, esperti e non esperti scommettono sulla probabilità che i risultati di determinati studi siano replicabili. Questo approccio ha dimostrato un’elevata accuratezza nella classificazione della replicabilità degli studi, offrendo un metodo alternativo e complementare alla replicazione diretta. I mercati di previsione potrebbero essere particolarmente utili in contesti in cui la raccolta dati è costosa o difficile, fornendo una prima indicazione sulla solidità dei risultati di ricerca.\n\n\n87.3.2 Strumenti di Valutazione Statistica\nUn’altra proposta riguarda l’adozione di nuovi strumenti di valutazione statistica per identificare e correggere il bias di pubblicazione e migliorare la potenza degli studi. Strumenti come la curva-p e la curva-z sono stati sviluppati per analizzare la distribuzione dei valori p e identificare eventuali distorsioni nei risultati pubblicati. Inoltre, alcuni studiosi hanno suggerito di abbassare il livello di significatività statistica standard da 0,05 a 0,005 per ridurre il tasso di falsi positivi e aumentare la robustezza dei risultati. Queste proposte rappresentano passi importanti verso una maggiore precisione nelle analisi statistiche.\n\n\n87.3.3 Analisi Multiverso\nL’analisi multiverso è un’altra proposta innovativa che mira a gestire la molteplicità di scelte analitiche possibili in un singolo studio. Questa tecnica prevede l’esecuzione di molteplici analisi su uno stesso dataset, variando i parametri e le scelte metodologiche, per testare la stabilità dei risultati. L’adozione di questo approccio permette di evidenziare quanto i risultati siano sensibili alle scelte analitiche, contribuendo a una maggiore trasparenza e affidabilità nelle conclusioni tratte dagli studi.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#cambiamenti-nella-comunità",
    "href": "chapters/replication_crisis/06_changes.html#cambiamenti-nella-comunità",
    "title": "87  Riforma",
    "section": "87.4 Cambiamenti nella Comunità",
    "text": "87.4 Cambiamenti nella Comunità\n\n87.4.1 Big Team Science\nIl concetto di “Big Team Science” rappresenta un cambiamento significativo nella modalità di condurre ricerca. Questo approccio prevede la collaborazione su larga scala tra scienziati di diversi paesi e discipline, con l’obiettivo di replicare studi, raccogliere grandi campioni e condividere risorse. Questo modello di lavoro collettivo non solo aumenta l’efficienza della ricerca, ma promuove anche una maggiore diversità nei campioni e nei team di ricerca. Tuttavia, esistono anche criticità, come la possibilità di perpetuare disuguaglianze tra ricercatori di paesi sviluppati e in via di sviluppo, e la difficoltà nel riconoscere adeguatamente i contributi individuali all’interno di grandi consorzi.\n\n\n87.4.2 Collaborazioni Avversariali\nLe collaborazioni avversariali rappresentano un altro approccio interessante per migliorare la qualità della ricerca. In queste collaborazioni, ricercatori con visioni teoriche contrastanti lavorano insieme per progettare e condurre studi che testino le loro ipotesi in modo rigoroso. Questo tipo di collaborazione può ridurre i bias personali e promuovere un confronto costruttivo, portando a conclusioni più solide e condivise all’interno della comunità scientifica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#crisi-della-generalizzabilità",
    "href": "chapters/replication_crisis/06_changes.html#crisi-della-generalizzabilità",
    "title": "87  Riforma",
    "section": "87.5 Crisi della Generalizzabilità",
    "text": "87.5 Crisi della Generalizzabilità\nYarkoni (2022) affronta la questione critica della scarsa validità delle inferenze quantitative presenti nella letteratura psicologica pubblicata, proponendo tre strategie principali per migliorare la qualità della ricerca in psicologia.\n\n87.5.1 Do Something Else\nIl primo suggerimento è di considerare l’abbandono della ricerca psicologica quantitativa quando risulta troppo difficile estrarre conclusioni significative e generalizzabili da effetti complessi e variabili. L’autore critica la tendenza a concludere ogni contributo di ricerca con una nota positiva, indipendentemente dalle evidenze raccolte. In alcuni casi, potrebbe essere più saggio riconoscere i limiti della ricerca e scegliere percorsi di carriera alternativi, specialmente per i ricercatori alle prime armi.\n\n\n87.5.2 Abbracciare l’Analisi Qualitativa\nLa seconda opzione proposta è continuare a fare ricerca psicologica, ma abbandonando in gran parte i metodi statistici inferenziali a favore di metodi qualitativi. L’autore sostiene che gran parte della scienza quantitativa in psicologia sia in realtà un’analisi qualitativa mascherata. In molti casi, l’analisi qualitativa potrebbe fornire risposte più profonde e significative rispetto a un approccio quantitativo superficiale.\n\n\n87.5.3 Adottare Standard Migliori\nLa terza strategia consiste nel migliorare gli standard della ricerca quantitativa in psicologia per renderla più rigorosa e affidabile. L’autore propone diverse pratiche, tra cui:\n\nInferenze più conservative: Evitare generalizzazioni ampie basate su dati limitati.\nRicerca descrittiva: Prendere più seriamente la ricerca descrittiva, che si concentra sulla caratterizzazione delle relazioni tra variabili.\nModelli statistici più espansivi: Utilizzare modelli che considerino una più ampia gamma di variabili e fattori.\nProgettare con la variazione in mente: Abbracciare la variabilità naturale delle condizioni sperimentali.\nStime della varianza: Porre maggiore enfasi sull’analisi delle componenti della varianza.\nPredizioni più rischiose: Formulare predizioni teoriche che comportino un alto grado di rischio.\nUtilità predittiva pratica: Concentrarsi sull’utilità pratica delle predizioni piuttosto che su considerazioni puramente teoriche.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#sviluppare-teorie-formali",
    "href": "chapters/replication_crisis/06_changes.html#sviluppare-teorie-formali",
    "title": "87  Riforma",
    "section": "87.6 Sviluppare Teorie Formali",
    "text": "87.6 Sviluppare Teorie Formali\nOltre alle carenze metodologiche o statistiche, è stato spesso sottolineato che la crisi di replicabilità trova le sue radici nella mancanza di un quadro teorico cumulativo. Senza un quadro teorico generale che generi ipotesi in diversi ambiti, i programmi empirici si sviluppano a partire da intuizioni personali e teorie popolari influenzate culturalmente. Fornendo strumenti per formulare previsioni chiare, anche attraverso l’uso di modelli formali, i quadri teorici stabiliscono aspettative che permettono di determinare se un nuovo risultato conferma le ricerche esistenti, integrandosi con esse, oppure se è inaspettato e, pertanto, richiede ulteriori verifiche e approfondimenti (Muthukrishna & Henrich, 2019).",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#riflessioni-conclusive",
    "href": "chapters/replication_crisis/06_changes.html#riflessioni-conclusive",
    "title": "87  Riforma",
    "section": "87.7 Riflessioni Conclusive",
    "text": "87.7 Riflessioni Conclusive\nL’ampio utilizzo dei test statistici frequentisti in psicologia risulta spesso fuorviante, poiché attribuisce un’apparenza di rigore scientifico a inferenze che, in realtà, sono principalmente qualitative. Si rende quindi necessaria una profonda riforma delle pratiche di ricerca, volta a promuovere una maggiore trasparenza e precisione, oltre a incoraggiare la disponibilità a mettere in discussione e abbandonare approcci metodologici che non superano una rigorosa analisi critica (Yarkoni, 2022).\nLa crisi di replicabilità ha spinto verso una serie di riforme con il potenziale di trasformare positivamente la ricerca psicologica. Tra queste iniziative vi sono la promozione della scienza aperta, l’adozione di standard metodologici più rigorosi e una maggiore attenzione a pratiche di ricerca che privilegiano la qualità e la replicabilità dei risultati rispetto alla loro quantità e novità. Sebbene questi cambiamenti possano sembrare meno spettacolari rispetto ai metodi attualmente utilizzati, essi rappresentano un percorso fondamentale per garantire la credibilità e la sostenibilità a lungo termine della disciplina.\nAffinché queste riforme abbiano un impatto duraturo, è essenziale un cambiamento strutturale a tutti i livelli della comunità scientifica:\n\nI ricercatori devono impegnarsi ad adottare pratiche più rigorose e trasparenti, privilegiando la solidità metodologica e la replicabilità dei loro studi.\nGli enti finanziatori devono incentivare la qualità e la replicabilità degli studi, piuttosto che premiare esclusivamente la produzione di risultati innovativi o appariscenti.\nLe istituzioni accademiche devono rivedere i criteri di valutazione del merito scientifico, dando maggior peso all’impatto a lungo termine delle ricerche e alla loro solidità metodologica.\nLe riviste scientifiche devono assicurarsi che i risultati pubblicati siano realmente robusti e generalizzabili, anziché limitarsi a privilegiare i risultati nuovi o sorprendenti.\n\nQuesti cambiamenti, sebbene complessi e talvolta impopolari, sono fondamentali per ristabilire la fiducia nel processo scientifico e per garantire che la ricerca psicologica continui a offrire contributi utili e affidabili nella comprensione della mente umana e del comportamento.\nIn conclusione, la sfida posta dalla crisi di replicabilità offre un’opportunità unica per ridefinire e rafforzare le fondamenta metodologiche della ricerca psicologica. Abbracciando questi cambiamenti, la psicologia può emergere come una disciplina più robusta, trasparente e affidabile, capace di fornire intuizioni utili e durature sul funzionamento della mente e del comportamento umano.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#bibliografia",
    "href": "chapters/replication_crisis/06_changes.html#bibliografia",
    "title": "87  Riforma",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nKorbmacher, M., Azevedo, F., Pennington, C. R., Hartmann, H., Pownall, M., Schmidt, K., Elsherif, M., Breznau, N., Robertson, O., Kalandadze, T., et al. (2023). The replication crisis has led to positive structural, procedural, and community changes. Communications Psychology, 1(1), 3.\n\n\nMuthukrishna, M., & Henrich, J. (2019). A problem in theory. Nature Human Behaviour, 3(3), 221–229.\n\n\nScheel, A. M., Schijen, M. R., & Lakens, D. (2021). An excess of positive results: Comparing the standard psychology literature with registered reports. Advances in Methods and Practices in Psychological Science, 4(2), 25152459211007467.\n\n\nYarkoni, T. (2022). The generalizability crisis. Behavioral and Brain Sciences, 45, e1.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_piranha.html",
    "href": "chapters/replication_crisis/07_piranha.html",
    "title": "88  Il Problema del priming: sfide e paradossi nella psicologia sociale",
    "section": "",
    "text": "88.1 Introduzione\nUn recente articolo di Tosh et al. (2025) affronta una questione centrale per la psicologia e la crisi della replicabilità: il cosiddetto “problema del piranha”. Questo argomento riguarda la convinzione, diffusa in molti studi psicologici, che piccoli interventi (o “nudges”), apparentemente insignificanti, possano generare effetti notevoli sul comportamento. L’articolo dimostra formalmente, con il supporto del teorema di Van der Corput (Tao, 2014), che se tali effetti fossero davvero così grandi e consistenti, allora sarebbe possibile manipolare il comportamento umano in modi empiricamente irrealistici.\nIn altre parole, la letteratura psicologica spesso riporta effetti di dimensioni tali che richiederebbero assunzioni incompatibili con le evidenze empiriche. Questi risultati suggeriscono che le affermazioni di grandi effetti indipendenti sono più probabilmente attribuibili a problemi metodologici, come bassa potenza statistica o “gradi di libertà del ricercatore” (Simmons et al., 2011).",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>88</span>  <span class='chapter-title'>Il Problema del priming: sfide e paradossi nella psicologia sociale</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_piranha.html#il-problema-del-piranha",
    "href": "chapters/replication_crisis/07_piranha.html#il-problema-del-piranha",
    "title": "88  Il Problema del priming: sfide e paradossi nella psicologia sociale",
    "section": "88.2 Il problema del piranha",
    "text": "88.2 Il problema del piranha\nTosh et al. (2025) evidenziano che, in un sistema complesso, se molte variabili esplicative hanno un forte impatto su una singola variabile di esito, queste devono inevitabilmente mostrare interazioni o correlazioni rilevanti tra loro.\n\n88.2.1 Punti chiave del problema\n\nEffetti ampi e interazioni: Il “problema del piranha” sottolinea che è improbabile che molte variabili esplicative abbiano effetti ampi e indipendenti su una singola variabile di esito all’interno di un sistema stabile. Questo principio si basa sulla disuguaglianza di Van der Corput, che dimostra come l’aumento del numero di variabili con grandi effetti richieda una considerazione delle loro interazioni. Tali interazioni generano una rete complessa di influenze, rendendo difficile isolare l’impatto di un singolo fattore. Gli effetti osservati in un dato studio potrebbero non essere generalizzabili, poiché dipendono dai livelli di altre variabili presenti nello stesso contesto.\nAnalogia con i piranha: L’analogia del piranha descrive un sistema sovraffollato di variabili esplicative con grandi effetti, che interagiscono tra loro fino a ridurre la stabilità complessiva. Proprio come i piranha in un acquario competono tra loro fino a ridurre il loro numero, un sistema con molte variabili di forte impatto tende a generare interazioni che limitano la prevedibilità e la stabilità del sistema. In altre parole, gli effetti individuali vengono alterati, ridotti o cancellati attraverso la competizione tra variabili.\n\n\n\n88.2.2 Rilevanza per la crisi di replicabilità\nIl problema del piranha offre una prospettiva cruciale per comprendere le cause della crisi di replicabilità nella psicologia e nelle scienze sociali. Secondo Tosh et al. (2025), questa crisi non è attribuibile soltanto a problemi metodologici come la bassa potenza statistica, ma riflette un limite intrinseco dell’idea stessa che numerosi grandi effetti indipendenti possano coesistere in un sistema complesso.\nI teoremi discussi nell’articolo dimostrano che un sistema stabile non può contenere numerosi effetti forti e indipendenti senza generare predizioni empiricamente insostenibili. Ciò implica che la ricerca di molteplici “grandi effetti” rischia di essere basata su assunzioni irrealistiche riguardo alla natura delle interazioni tra variabili.\nIl problema del piranha è particolarmente rilevante per la psicologia, dove spesso si cercano numerose cause indipendenti per spiegare fenomeni complessi. Tosh et al. (2025) mettono in discussione non tanto i singoli effetti riportati, quanto l’assunzione di base secondo cui il comportamento umano e le interazioni sociali sarebbero influenzati da un gran numero di effetti indipendenti.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>88</span>  <span class='chapter-title'>Il Problema del priming: sfide e paradossi nella psicologia sociale</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_piranha.html#il-priming-nella-psicologia-sociale",
    "href": "chapters/replication_crisis/07_piranha.html#il-priming-nella-psicologia-sociale",
    "title": "88  Il Problema del priming: sfide e paradossi nella psicologia sociale",
    "section": "88.3 Il priming nella psicologia sociale",
    "text": "88.3 Il priming nella psicologia sociale\nUno degli esempi analizzati da Tosh et al. (2025) riguarda la ricerca sul priming sociale, una linea di indagine ampiamente discussa e criticata nella psicologia sociale (si veda anche Leys, 2024). Gli autori utilizzano uno studio classico per illustrare le loro argomentazioni: un esperimento del 1996 condotto da Bargh et al. (1996), in cui i partecipanti riorganizzavano frasi contenenti parole associate alla vecchiaia (ad esempio, “Florida” o “solo”). I risultati riportavano che questi partecipanti camminavano più lentamente rispetto a un gruppo di controllo, con una riduzione del 13% nella velocità di camminata (Bargh et al., 1996).\nL’idea che una manipolazione così semplice possa produrre un effetto tanto marcato è stata successivamente oggetto di numerose critiche. I tentativi di replicare lo studio non hanno avuto successo, e il lavoro di Bargh et al. (1996) è ora considerato un esempio emblematico di risultati impossibili da replicare. Questo studio rappresenta solo uno dei molti casi in cui sono stati riportati effetti sorprendentemente grandi per manipolazioni apparentemente insignificanti.\nTosh et al. (2025) sostengono che, se davvero piccoli interventi (nudges) producono effetti così rilevanti, emergerebbe inevitabilmente il problema delle interazioni con numerosi altri fattori già noti per influire sul comportamento umano. La letteratura psicologica include infatti studi che attribuiscono grandi effetti a fattori come ormoni, immagini subliminali, notizie di partite di calcio o attacchi di squali, incontri casuali con sconosciuti, stato socioeconomico dei genitori, condizioni meteorologiche, l’ultima cifra dell’età, il genere del nome di un uragano, e molti altri. Secondo gli autori, se tutti questi fattori influenzassero realmente un singolo esito, le loro interazioni diventerebbero incredibilmente complesse e imprevedibili, rendendo impossibile individuare effetti stabili e replicabili.\nPer illustrare l’assurdità di alcuni di questi risultati, Tosh et al. (2025) propongono un esempio ipotetico. Supponiamo che 100 nudges producano ciascuno un effetto del 13% sulla velocità di camminata, come riportato da Bargh et al. (1996). Se questi effetti fossero indipendenti, l’effetto combinato sarebbe enorme: la velocità di camminata potrebbe facilmente raddoppiare, dimezzarsi o variare ancora di più. Tuttavia, tali variazioni sono empiricamente irrealistiche. In altre parole, le assunzioni su cui si basano molte di queste ricerche porterebbero a predizioni che non trovano riscontro nei dati osservabili.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>88</span>  <span class='chapter-title'>Il Problema del priming: sfide e paradossi nella psicologia sociale</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_piranha.html#riflessioni-conclusive",
    "href": "chapters/replication_crisis/07_piranha.html#riflessioni-conclusive",
    "title": "88  Il Problema del priming: sfide e paradossi nella psicologia sociale",
    "section": "88.4 Riflessioni Conclusive",
    "text": "88.4 Riflessioni Conclusive\nIl “problema del piranha” evidenzia i limiti intrinseci nell’assumere che numerosi effetti indipendenti e di grande entità possano coesistere all’interno di un sistema complesso. In realtà, tali effetti devono necessariamente interagire tra loro o essere correlati, rendendo improbabile la loro indipendenza. Questa dinamica crea instabilità nel sistema e porta a variazioni degli effetti nel tempo o tra popolazioni, compromettendo la possibilità di generalizzarne i risultati.\nTosh et al. (2025) suggeriscono che molti risultati pubblicati, che riportano effetti improbabilmente grandi, siano attribuibili non tanto a reali fenomeni psicologici, quanto a problemi metodologici, come bassa potenza statistica e i “gradi di libertà del ricercatore” (Simmons et al., 2011). La proliferazione di questi risultati contribuisce alla crisi di replicabilità, poiché i presunti effetti si rivelano spesso instabili o non replicabili.\nLa consapevolezza dei limiti imposti dal problema del piranha invita la ricerca psicologica a focalizzarsi maggiormente sulla robustezza metodologica, sull’identificazione di effetti plausibili e sulla considerazione delle interazioni tra variabili. Piuttosto che cercare di identificare molteplici grandi effetti, è essenziale riconoscere che un sistema complesso, per essere stabile e prevedibile, richiede un approccio che consideri l’interdipendenza delle variabili e la struttura complessiva del sistema. Questo approccio può contribuire a migliorare la validità e la replicabilità della ricerca nelle scienze sociali.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>88</span>  <span class='chapter-title'>Il Problema del priming: sfide e paradossi nella psicologia sociale</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_piranha.html#bibliografia",
    "href": "chapters/replication_crisis/07_piranha.html#bibliografia",
    "title": "88  Il Problema del priming: sfide e paradossi nella psicologia sociale",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBargh, J. A., Chen, M., & Burrows, L. (1996). Automaticity of social behavior: Direct effects of trait construct and stereotype activation on action. Journal of Personality and Social Psychology, 71(2), 230–244.\n\n\nLeys, R. (2024). Anatomy of a Train Wreck: The Rise and Fall of Priming Research. University of Chicago Press.\n\n\nSimmons, J. P., Nelson, L. D., & Simonsohn, U. (2011). False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant. Psychological science, 22(11), 1359–1366.\n\n\nTosh, C., Greengard, P., Goodrich, B., Gelman, A., Vehtari, A., & Hsu, D. (2025). The Piranha Problem: Large Effects Swimming in a Small Pond. Notices of the American Mathematical Society.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>88</span>  <span class='chapter-title'>Il Problema del priming: sfide e paradossi nella psicologia sociale</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_degrees_of_freedom.html",
    "href": "chapters/replication_crisis/08_degrees_of_freedom.html",
    "title": "89  I gradi di libertà del ricercatore",
    "section": "",
    "text": "89.1 Introduzione\nLo studio di Gould et al. (2025), ripreso dalla rivista Science (O’Grady, 2025), mostra come le scelte analitiche dei ricercatori possano generare una variabilità significativa nei risultati, persino quando si utilizzano gli stessi dati e si affronta la medesima domanda di ricerca in ecologia e biologia evolutiva. Questa discrepanza supera di gran lunga l’errore statistico atteso, rivelando un problema sistemico che trascende i confini disciplinari.\nI risultati concordano con quelli di precedenti progetti “many analysts” – tra cui il pionieristico lavoro in psicologia di Silberzahn et al. (2018) – e sottolineano, come evidenziato dallo psicologo Eric Uhlmann, “il ruolo cruciale delle decisioni soggettive nella pratica scientifica”. Ciò conferma che la fragilità metodologica non è un’esclusiva della psicologia, ma riguarda settori come le neuroscienze, le scienze sociali e, appunto, l’ecologia.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>I gradi di libertà del ricercatore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_degrees_of_freedom.html#metodologia",
    "href": "chapters/replication_crisis/08_degrees_of_freedom.html#metodologia",
    "title": "89  I gradi di libertà del ricercatore",
    "section": "89.2 Metodologia",
    "text": "89.2 Metodologia\nGould et al. (2025) hanno coinvolto 174 team di ricerca (246 analisti) nell’analisi indipendente di due dataset inediti:\n\nEcologia evolutiva: relazione tra numero di fratelli e crescita dei pulcini di cinciallegra (Cyanistes caeruleus).\nEcologia della conservazione: impatto della copertura erbosa sul reclutamento di piantine di Eucalyptus.\n\nOgni team ha risposto a una domanda specifica:\n\nDataset cinciallegra: “Quanto la competizione tra fratelli influenza la crescita dei pulcini?”\nDataset eucalipto: “In che modo la copertura erbosa condiziona il reclutamento di piantine?”\n\nI ricercatori hanno fornito risultati, giustificazioni metodologiche, codice analitico e hanno sottoposto le procedure a peer review incrociata, creando un sistema di controllo reciproco.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>I gradi di libertà del ricercatore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_degrees_of_freedom.html#risultati",
    "href": "chapters/replication_crisis/08_degrees_of_freedom.html#risultati",
    "title": "89  I gradi di libertà del ricercatore",
    "section": "89.3 Risultati",
    "text": "89.3 Risultati\nLo studio ha evidenziato eterogeneità estrema nelle conclusioni, nonostante l’uniformità dei dati di partenza:\n\nCinciallegra: L’effetto medio negativo (più fratelli = minore crescita) nascondeva un’ampia dispersione, con stime da -0.8 a +0.2 (Figura 1a).\nEucalipto: La relazione media era debolmente negativa e non significativa, ma con outlier che invertivano la tendenza (Figura 1b).\n\n\n\n\n\n\n\nFigura 89.1: Distribuzione degli effetti standardizzati nei due dataset: crescita dei pulcini (sinistra) e reclutamento di piantine (destra) (adattata da Gould et al., 2025).\n\n\n\nSorprendentemente, né la selezione di variabili, né l’uso di effetti casuali, né il giudizio dei revisori correlavano con la distanza dalla media meta-analitica. In altre parole, risultati divergenti non erano associati a scelte metodologicamente “peggiori”, ma a combinazioni altrettanto valide di decisioni analitiche.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>I gradi di libertà del ricercatore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_degrees_of_freedom.html#il-problema-dei-gradi-di-libertà-del-ricercatore",
    "href": "chapters/replication_crisis/08_degrees_of_freedom.html#il-problema-dei-gradi-di-libertà-del-ricercatore",
    "title": "89  I gradi di libertà del ricercatore",
    "section": "89.4 Il Problema dei Gradi di Libertà del Ricercatore",
    "text": "89.4 Il Problema dei Gradi di Libertà del Ricercatore\nIl lavoro illustra chiaramente come i “gradi di libertà analitici” – le molteplici opzioni durante l’analisi dati – possano generare conclusioni divergenti. Tra le decisioni critiche:\n\nGestione di outlier e dati mancanti.\nDefinizione operativa delle variabili.\nScelta di modelli statistici e controlli.\n\nQueste scelte, spesso soggettive ma teoricamente giustificabili, definiscono un “spazio analitico” con migliaia di percorsi possibili. Ogni studio pubblicato rappresenta dunque una singola traiettoria in questo labirinto metodologico, rischiando di offrire una visione parziale e potenzialmente distorta.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>I gradi di libertà del ricercatore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_degrees_of_freedom.html#implicazioni-e-strategie-di-mitigazione",
    "href": "chapters/replication_crisis/08_degrees_of_freedom.html#implicazioni-e-strategie-di-mitigazione",
    "title": "89  I gradi di libertà del ricercatore",
    "section": "89.5 Implicazioni e Strategie di Mitigazione",
    "text": "89.5 Implicazioni e Strategie di Mitigazione\nLa variabilità sistematica impone una revisione delle pratiche di ricerca:\n\nAnalisi di sensibilità avanzate:\n\nAnalisi multiverso: testare tutte le combinazioni plausibili di scelte metodologiche.\nCurve di specificazione: mappare come i risultati variano al mutare delle assunzioni.\n\nModelli aggregati: Combinare stime da approcci diversi (es., Bayesian Model Averaging) per ridurre la dipendenza da singole specifiche.\n\nTrasparenza procedurale:\n\nPreregistrazione: fissare ipotesi e metodi prima di accedere ai dati.\nPubblicazione di codice e dati grezzi.\n\nFormazione metodologica: Rafforzare le competenze statistiche, con enfasi sulla gestione della complessità analitica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>I gradi di libertà del ricercatore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_degrees_of_freedom.html#riflessioni-conclusive",
    "href": "chapters/replication_crisis/08_degrees_of_freedom.html#riflessioni-conclusive",
    "title": "89  I gradi di libertà del ricercatore",
    "section": "89.6 Riflessioni Conclusive",
    "text": "89.6 Riflessioni Conclusive\nQuesto studio dimostra empiricamente che l’affidabilità della scienza dipende non solo dai dati, ma da come li analizziamo. La variabilità indotta dai gradi di libertà del ricercatore mina la riproducibilità, soprattutto in contesti con elevata discrezionalità analitica. La soluzione non è l’uniformità metodologica, ma una cultura della trasparenza e della pluralità analitica, dove ogni risultato sia esplicitamente contestualizzato nel suo spazio di scelte possibili. Solo così ecologia, psicologia e discipline affini potranno produrre conoscenze solide e autocritiche.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>I gradi di libertà del ricercatore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_degrees_of_freedom.html#bibliografia",
    "href": "chapters/replication_crisis/08_degrees_of_freedom.html#bibliografia",
    "title": "89  I gradi di libertà del ricercatore",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGould, E., Fraser, H. S., Parker, T. H., Nakagawa, S., Griffith, S. C., Vesk, P. A., Fidler, F., Hamilton, D. G., Abbey-Lee, R. N., Abbott, J. K., et al. (2025). Same data, different analysts: variation in effect sizes due to analytical decisions in ecology and evolutionary biology. BMC biology, 23(1), 35.\n\n\nO’Grady, C. (2025). Given the same data, ecologists arrive at different conclusions. Science, 387(6738), 1026.\n\n\nSilberzahn, R., Uhlmann, E. L., Martin, D. P., Anselmi, P., Aust, F., Awtrey, E., Bahnı́k, Š., Bai, F., Bannard, C., Bonnier, E., et al. (2018). Many analysts, one data set: Making transparent how variations in analytic choices affect results. Advances in Methods and Practices in Psychological Science, 1(3), 337–356.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>I gradi di libertà del ricercatore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/09_integrity.html",
    "href": "chapters/replication_crisis/09_integrity.html",
    "title": "90  Integrità della ricerca",
    "section": "",
    "text": "90.1 Introduzione\nL’integrità della ricerca si fonda su principi e standard professionali volti a garantire l’affidabilità e la qualità degli studi scientifici. Essa si distingue dall’etica della ricerca, che invece si concentra sui principi morali. Elementi chiave per l’integrità includono la condivisione dei dati, il consenso informato e la trasparenza nelle pratiche di ricerca. I codici di condotta svolgono un ruolo cruciale nel guidare i comportamenti etici sia dei ricercatori che delle istituzioni. Tra le principali sfide da affrontare vi sono le pratiche di ricerca discutibili, la fabbricazione e falsificazione dei dati, il plagio e la gestione dei conflitti di interesse. Promuovere una cultura della ricerca basata su onestà, trasparenza e rispetto dei principi etici è essenziale per preservare l’integrità scientifica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>Integrità della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/09_integrity.html#standard-professionali-nei-codici-di-condotta-per-lintegrità-della-ricerca",
    "href": "chapters/replication_crisis/09_integrity.html#standard-professionali-nei-codici-di-condotta-per-lintegrità-della-ricerca",
    "title": "90  Integrità della ricerca",
    "section": "90.2 Standard Professionali nei Codici di Condotta per l’Integrità della Ricerca",
    "text": "90.2 Standard Professionali nei Codici di Condotta per l’Integrità della Ricerca\nNel contesto della ricerca, aderire a principi di condotta responsabile è fondamentale. Questi principi, spesso definiti come buone pratiche di ricerca, stabiliscono standard professionali che mirano a ottimizzare la qualità e l’affidabilità degli studi. Sebbene i concetti di base su cosa costituisca una buona pratica di ricerca rimangano stabili nel tempo, la loro applicazione pratica si evolve in risposta a cambiamenti sociali, politici e tecnologici. Un esempio significativo di questa evoluzione è l’enfasi crescente sulla condivisione dei dati di ricerca, resa possibile dall’uso di repository online gratuiti. Ciò ha portato a un’aspettativa diffusa di trasparenza e accessibilità dei dati. Allo stesso modo, la condivisione del codice utilizzato per analizzare i dati è diventata una pratica sempre più incoraggiata.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>Integrità della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/09_integrity.html#differenziazione-tra-integrità-ed-etica-della-ricerca",
    "href": "chapters/replication_crisis/09_integrity.html#differenziazione-tra-integrità-ed-etica-della-ricerca",
    "title": "90  Integrità della ricerca",
    "section": "90.3 Differenziazione tra Integrità ed Etica della Ricerca",
    "text": "90.3 Differenziazione tra Integrità ed Etica della Ricerca\nL’integrità della ricerca si basa su standard professionali, mentre l’etica della ricerca si fonda su principi morali come l’autonomia, la beneficenza, la non-maleficenza e la giustizia. Questi principi etici si traducono in pratiche specifiche, quali il consenso informato e la garanzia di verità e riservatezza nei confronti dei partecipanti. I ricercatori hanno l’obbligo di evitare studi che possano causare danni o risultare eccessivamente onerosi per i soggetti coinvolti.\nI codici di condotta per l’integrità della ricerca presentano alcune variazioni tra le diverse fonti. Ad esempio, il Codice di condotta europeo per l’integrità della ricerca sottolinea l’importanza di principi come onestà, trasparenza, accuratezza, responsabilità, affidabilità, rispetto e indipendenza. Questi principi si traducono in comportamenti specifici attesi sia dai ricercatori che dalle istituzioni, come la condivisione dei dati nel rispetto delle normative sulla protezione dei dati, tra cui il GDPR europeo.\nUn esempio pratico di come gli standard si siano evoluti è rappresentato dalla condivisione dei dati di ricerca. In passato, questa pratica era limitata dalla mancanza di infrastrutture adeguate. Oggi, grazie ai repository online e alla pressione esercitata da riviste scientifiche e finanziatori, la condivisione dei dati è diventata una pratica standard, riflettendo un cambiamento verso una maggiore apertura e trasparenza.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>Integrità della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/09_integrity.html#pressioni-e-sfide-nelladesione-ai-codici-di-condotta",
    "href": "chapters/replication_crisis/09_integrity.html#pressioni-e-sfide-nelladesione-ai-codici-di-condotta",
    "title": "90  Integrità della ricerca",
    "section": "90.4 Pressioni e Sfide nell’Adesione ai Codici di Condotta",
    "text": "90.4 Pressioni e Sfide nell’Adesione ai Codici di Condotta\nNonostante l’esistenza di codici di condotta, i ricercatori, specialmente quelli all’inizio della carriera, possono subire pressioni da parte dei supervisori per adottare comportamenti che deviano dagli standard stabiliti. Questo è spesso dovuto alla competitività nel campo scientifico e al sistema di valutazione basato sul numero di pubblicazioni. Tali dinamiche possono portare a pratiche di ricerca discutibili (PRD), come la pubblicazione selettiva dei risultati o l’uso di analisi dei dati flessibili per ottenere risultati statisticamente significativi.\nPer preservare l’integrità della ricerca, è essenziale creare un ambiente di lavoro che promuova apertura, inclusività e discussione franca delle pressioni e delle sfide etiche. Ciò richiede non solo l’adesione ai codici di condotta esistenti, ma anche un impegno attivo delle istituzioni nel promuovere la formazione etica e l’integrità tra i ricercatori. Solo attraverso un approccio di questo tipo la comunità scientifica può aspirare a una ricerca di alta qualità, sia eticamente responsabile che metodologicamente solida.\nUn esempio emblematico delle tensioni nel mondo accademico è il gioco da tavolo Publish or Perish, recentemente promosso dalla prestigiosa rivista Nature. La descrizione del gioco è provocatoria:\n\n“Falsificare dati, screditare altri scienziati, pubblicare una montagna di articoli che ricevono una torre di citazioni: i cinici potrebbero descrivere questi come passi necessari per raggiungere il successo accademico.”\n\nQuesta iniziativa solleva interrogativi sullo stato attuale della ricerca scientifica. Il mondo accademico sembra offrire incentivi distorti, mentre il sistema economico delle riviste scientifiche presenta una componente di monetizzazione che spesso entra in conflitto con gli obiettivi fondamentali della ricerca. Questo contesto favorisce l’accettazione di pratiche disoneste, funzionali al mantenimento dello status quo.\nIn questo scenario complesso, emergono voci di dissenso che auspicano una riforma del sistema scientifico (McElreath, 2020; Smaldino & McElreath, 2016). È necessaria una riflessione profonda su come bilanciare la produttività accademica con l’etica e la qualità della ricerca, nonché sul ruolo delle riviste scientifiche nel plasmare il panorama della ricerca contemporanea.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>Integrità della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/09_integrity.html#bibliografia",
    "href": "chapters/replication_crisis/09_integrity.html#bibliografia",
    "title": "90  Integrità della ricerca",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nSmaldino, P. E., & McElreath, R. (2016). The natural selection of bad science. Royal Society Open Science, 3(9), 160384.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>Integrità della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html",
    "href": "chapters/epiloque/epiloque.html",
    "title": "Considerazioni Conclusive",
    "section": "",
    "text": "Limiti dell’Inferenza Frequentista\nL’inferenza bayesiana rappresenta un approccio rigoroso e trasparente per integrare conoscenze pregresse e dati empirici nell’analisi psicologica. A differenza dei metodi frequentisti, l’approccio bayesiano consente di quantificare l’incertezza e di costruire modelli che riflettono le nostre aspettative iniziali. Questa flessibilità è particolarmente preziosa in psicologia, dove teorie e ipotesi svolgono un ruolo centrale nel guidare la ricerca. L’inferenza bayesiana rende esplicite le nostre assunzioni a priori e ci permette di valutare come i dati influenzano la nostra comprensione dei fenomeni psicologici.\nIn questo corso, abbiamo esaminato i limiti dell’inferenza frequentista, specialmente quando utilizzata come “filtro” per distinguere risultati scientifici rilevanti da quelli trascurabili. L’eccessiva dipendenza dai valori-p è stata ampiamente criticata per la sua associazione con inferenze inadeguate. Gli effetti possono essere sovrastimati, talvolta anche nella direzione sbagliata, quando la stima è vincolata alla significatività statistica in presenza di dati altamente variabili (Loken & Gelman, 2017).\nNonostante le critiche di lunga data e i dibattiti sul loro uso improprio (Gardner e Altman, 1986; Cohen, 1994; Anderson et al., 2000; Fidler et al., 2004; Finch et al., 2004), i valori-p persistono come indicatore di significatività. Questa tenacia riflette forse la necessità dei ricercatori di avere strumenti intuitivi, sebbene semplificati, per interpretare i dati. Tuttavia, l’uso rigido di soglie arbitrarie (ad esempio, 0.05, 0.01, 0.001) ha trasformato il raggiungimento della significatività in un obiettivo fine a se stesso, piuttosto che in uno strumento per comprendere i fenomeni sottostanti (Cohen, 1994; Kirk, 1996). Inoltre, i valori-p possono solo rifiutare l’ipotesi nulla, ma non confermarla, poiché un risultato non significativo non implica l’assenza di effetti o differenze (Wagenmakers, 2007; Amrhein et al., 2019).\nL’uso improprio dei valori-p, noto come “p-hacking” (Simmons et al., 2011), ha favorito pratiche scientifiche discutibili, contribuendo alla crisi di riproducibilità nella psicologia (Chambers et al., 2014; Szucs e Ioannidis, 2016).",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html#la-crisi-della-replicabilità",
    "href": "chapters/epiloque/epiloque.html#la-crisi-della-replicabilità",
    "title": "Considerazioni Conclusive",
    "section": "La Crisi della Replicabilità",
    "text": "La Crisi della Replicabilità\nLa crisi della replicabilità rappresenta una delle principali sfide che affliggono la ricerca scientifica contemporanea, con effetti particolarmente rilevanti nel campo della psicologia. Quando i risultati di uno studio non possono essere riprodotti in condizioni simili, si mette in discussione non solo la validità delle teorie su cui si basano interventi clinici e politiche pubbliche, ma anche la fiducia generale nella scienza. Questo problema va oltre l’ambito accademico, influenzando direttamente l’efficacia delle applicazioni pratiche delle ricerche.\n\nLe Cause Sottostanti\nUno dei fattori principali della crisi è legato all’uso di metodologie di ricerca e analisi dei dati insufficientemente rigorose, che spesso portano a falsi positivi. Sebbene siano stati fatti appelli per migliorare le pratiche scientifiche, tali problemi persistono, indicando che il fenomeno non è semplicemente frutto di errori o mancanza di comprensione. Secondo Smaldino e McElreath (2016), la causa radicale risiede nei sistemi di incentivi distorti che favoriscono la quantità piuttosto che la qualità della ricerca. In questo contesto, la pressione a pubblicare risultati significativi diventa prioritaria rispetto alla rigorosità metodologica, alimentando un circolo vizioso in cui la “scienza scadente” si perpetua.\nPratiche comuni, come il p-hacking (manipolazione statistica per ottenere risultati significativi) o la selezione selettiva dei dati, vengono adottate inconsciamente o intenzionalmente per massimizzare le probabilità di pubblicazione. Questo meccanismo, descritto come una forma di “selezione naturale della scienza scadente”, premia approcci che facilitano la produzione di risultati spettacolari, ma non necessariamente veritieri.\n\n\nVerso una Soluzione: Cambiare la Cultura Scientifica\nPer superare questa crisi, è fondamentale operare un cambiamento culturale all’interno della comunità scientifica. Non basta correggere gli errori metodologici; occorre modificare radicalmente gli incentivi per premiare la qualità, la trasparenza e la replicabilità della ricerca. Alcune strategie chiave includono:\n\nPromozione di Pratiche Rigorose:\n\nAdottare protocolli trasparenti, preregistrare gli studi prima del loro avvio e condividere apertamente dati e materiali.\nImplementare procedure di peer review più severe e incoraggiare la revisione post-pubblicazione.\n\nValorizzazione della Replicazione:\n\nDare maggiore riconoscimento agli studi che replicano risultati precedenti, anziché privilegiare esclusivamente nuove scoperte.\nCreare riviste specializzate che si concentriano sulla verifica e sulla riproducibilità degli studi.\n\nRiforma dei Criteri di Valutazione:\n\nSpostare l’attenzione dalla quantità delle pubblicazioni alla loro qualità e impatto scientifico.\nIncorporare metriche alternative, come l’impatto sociale e la contribuzione alla conoscenza consolidata.\n\n\n\n\nNuovi Approcci Metodologici\nAlcune proposte innovative mirano a migliorare la qualità delle analisi statistiche e ridurre la propensione a falsi positivi. Un esempio è l’adozione dell’inferenza bayesiana, che offre vantaggi significativi rispetto ai metodi tradizionali:\n\nMaggiore flessibilità nell’analisi di dati rumorosi o campioni piccoli.\nMinore propensione agli errori di tipo I.\nPossibilità di incorporare conoscenze pregresse nel processo decisionale.\n\nTuttavia, l’inferenza bayesiana da sola non può risolvere completamente il problema. È necessario affrontare anche le cause strutturali, come il sistema accademico che premia la produttività quantitativa piuttosto che la qualità.\nUn’altra prospettiva promettente è quella avanzata da Richard McElreath, che suggerisce di passare da un approccio descrittivo a uno che descrive formalmente i meccanismi generativi dei dati. Questo significa formulare ipotesi esplicite sui processi sottostanti e testarle attraverso confronti quantitativi tra modelli. Tecniche come la validazione incrociata bayesiana Leave-One-Out (LOO) permettono di valutare la robustezza dei modelli e la loro capacità di generalizzare a nuovi contesti.\nInoltre, la “rivoluzione causale” cerca di identificare relazioni causali in contesti naturali, superando i limiti degli esperimenti controllati tradizionali. Questo approccio richiede ai ricercatori di formulare ipotesi causali esplicite e confrontare modelli alternativi, migliorando così la comprensione dei fenomeni studiati.\n\n\nImplicazioni Sociali e Educative\nLa crisi della replicabilità ha implicazioni concrete al di là del mondo accademico. Interventi clinici, politiche pubbliche e decisioni basate su ricerche non replicabili rischiano di essere inefficaci o dannose. Pertanto, garantire la replicabilità e l’affidabilità delle scoperte scientifiche è essenziale non solo per preservare l’integrità accademica, ma anche per assumersi responsabilità sociali.\nUna revisione dei metodi didattici e dei programmi accademici è altrettanto cruciale. Gli studenti devono essere formati per comprendere e applicare inferenze basate su dati empirici. Studiosi come Mine Dogucu hanno sottolineato l’importanza di integrare approcci bayesiani e causalità nei corsi di formazione, e la presente dispensa si inserisce in questo sforzo (Dogucu & Çetinkaya-Rundel, 2021; Dogucu & Hu, 2022; Johnson et al., 2022; Rosenberg et al., 2022).",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html#conclusioni",
    "href": "chapters/epiloque/epiloque.html#conclusioni",
    "title": "Considerazioni Conclusive",
    "section": "Conclusioni",
    "text": "Conclusioni\nAffrontare e superare la crisi della replicabilità rappresenta una sfida fondamentale per la comunità scientifica, richiedendo un impegno collettivo per riformare profondamente la cultura della ricerca. Modificare gli incentivi che favoriscono quantità piuttosto che qualità, promuovere pratiche metodologiche rigorose e valorizzare la replicazione sono passi essenziali per costruire una scienza più affidabile. Solo attraverso un approccio multidimensionale sarà possibile ripristinare la fiducia nella psicologia scientifica e garantire che le sue applicazioni pratiche siano fondate su basi solide e verificabili.\nIn questo contesto, l’inferenza bayesiana emerge come uno strumento di grande valore per l’analisi dei dati psicologici. Offrendo metodi avanzati per gestire l’incertezza, integrare conoscenze pregresse e adattarsi a modelli complessi, essa si dimostra particolarmente utile per esplorare i fenomeni legati alla mente umana e al comportamento. La sua capacità di fornire previsioni robuste e di aggiornare le ipotesi in base a nuovi dati la rende un approccio ideale per affrontare le sfide poste dalla natura intrinsecamente dinamica del campo psicologico.\nTuttavia, è importante sottolineare che l’adozione di metodi bayesiani non costituisce da sola una soluzione completa alla crisi della replicabilità. Per migliorare realmente la qualità della ricerca, è necessario integrare queste tecniche con pratiche metodologiche rigorose. Tra queste, spiccano la formalizzazione di modelli generativi, che consentono di descrivere esplicitamente i processi sottostanti ai dati osservati, e il confronto tra modelli alternativi, fondamentale per valutare l’adeguatezza delle teorie proposte. Inoltre, l’adozione di una prospettiva causale esplicita è cruciale per identificare correttamente le relazioni di causa-effetto, superando i limiti degli studi correlazionali o degli esperimenti tradizionali.\nIn conclusione, solo un approccio integrato, che combini l’inferenza bayesiana con pratiche metodologiche avanzate e una riflessione critica sui sistemi di incentivi accademici, permetterà di progredire verso una scienza psicologica più affidabile e riproducibile. Questo sforzo collettivo non solo migliorerà la qualità delle ricerche, ma contribuirà anche a fornire una comprensione più profonda e accurata del comportamento umano, consolidando così la posizione della psicologia come disciplina scientifica solida e credibile.",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html#bibliografia",
    "href": "chapters/epiloque/epiloque.html#bibliografia",
    "title": "Considerazioni Conclusive",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nDogucu, M., & Çetinkaya-Rundel, M. (2021). Web scraping in the statistics and data science curriculum: Challenges and opportunities. Journal of Statistics and Data Science Education, 29(sup1), S112–S122.\n\n\nDogucu, M., & Hu, J. (2022). The current state of undergraduate Bayesian education and recommendations for the future. The American Statistician, 76(4), 405–413.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nLoken, E., & Gelman, A. (2017). Measurement Error and the Replication Crisis. Science, 355(6325), 584–585.\n\n\nRosenberg, J. M., Kubsch, M., Wagenmakers, E.-J., & Dogucu, M. (2022). Making sense of uncertainty in the science classroom: A Bayesian approach. Science & Education, 31(5), 1239–1262.",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/appendix/a01_shell.html",
    "href": "chapters/appendix/a01_shell.html",
    "title": "Appendice A — La Shell",
    "section": "",
    "text": "A.1 Che cos’è una Shell?\nUna shell è un programma che riceve comandi dall’utente tramite tastiera (o da file) e li passa al sistema operativo per l’esecuzione. Può essere accessibile tramite un terminale (o un emulatore di terminale).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>La Shell</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01_shell.html#che-cosè-una-shell",
    "href": "chapters/appendix/a01_shell.html#che-cosè-una-shell",
    "title": "Appendice A — La Shell",
    "section": "",
    "text": "A.1.1 Breve Storia della Shell\n\n1971: Ken Thompson di Bell Labs sviluppa la shell per UNIX.\n1977: Stephen Bourne introduce la Bourne shell (sh).\nDopo il 1977: Viene sviluppata la C shell (csh) e tcsh.\nBash: Sviluppata da Brian Fox come sostituto migliorato della Bourne shell.\n1990: Paul Falsted sviluppa Zsh, che diventa la shell predefinita per macOS dal 2019.\n\n\n\nA.1.2 Windows vs macOS/Linux\n\nWindows 10: È possibile utilizzare Bash attivando il Windows Subsystem for Linux. Tuttavia, l’ambiente preferito è solitamente PowerShell.\nmacOS/Linux: Zsh è la shell predefinita in entrambi i sistemi. È consigliabile sfruttare l’applicazione warp per un’esperienza utente moderna e ottimizzata.\n\n\n\nA.1.3 Comandi di Base Unix\n\npwd: Mostra il percorso della directory corrente.\nls: Elenca file e cartelle nella directory corrente.\ncd: Cambia directory. Senza argomenti, ti porta alla directory home.\nmkdir: Crea una nuova directory.\nrmdir: Rimuove una directory vuota.\nImportante: Evitare spazi nei nomi di file e cartelle.\n\n\nA.1.3.1 Gestione File\n\nmv: Rinomina o sposta file (usa \\ o '' per i nomi di file con spazi).\ncp: Copia file o cartelle (usa -r per le cartelle).\nrm: Rimuove file o cartelle (usa -i per confermare prima di eliminare).\n\n\n\nA.1.3.2 Visualizzazione e Manipolazione Contenuti dei File\n\nless / more: Visualizza il contenuto dei file con possibilità di navigazione.\ncat: Mostra l’intero contenuto di un file.\nhead: Mostra le prime righe di un file.\ntail: Mostra le ultime righe di un file.\n\n\n\n\nA.1.4 Comandi di Base PowerShell\nPer adattare i comandi Unix per l’utilizzo in PowerShell di Windows, molti dei comandi rimangono simili grazie alla natura cross-platform di PowerShell e alla sua flessibilità nel gestire sia gli stili di comando Unix che quelli tradizionali di Windows. Ecco come si traducono i comandi:\n\nGet-Location o semplicemente pwd: Mostra il percorso della directory corrente, simile a pwd in Unix.\nGet-ChildItem o semplicemente ls: Elenca file e cartelle nella directory corrente, equivalente a ls in Unix.\nSet-Location o semplicemente cd: Cambia directory. cd senza argomenti ti porta alla directory home in PowerShell con cd ~.\nNew-Item -ItemType Directory -Name 'nomeDirectory': Crea una nuova directory, simile a mkdir in Unix.\nRemove-Item -Path 'nomeDirectory' -Force: Rimuove una directory, anche se non vuota. Equivalente a rmdir in Unix, ma più potente perché può rimuovere anche directory con contenuti utilizzando il parametro -Force.\n\n\nA.1.4.1 Gestione File\n\nMove-Item -Path 'origine' -Destination 'destinazione': Rinomina o sposta file, equivalente a mv in Unix.\nCopy-Item -Path 'origine' -Destination 'destinazione': Copia file o cartelle, simile a cp in Unix. Usa -Recurse per copiare cartelle.\nRemove-Item -Path 'file' -Force: Rimuove file o cartelle, simile a rm in Unix. Usa -Force per rimuovere senza conferme e -Recurse per rimuovere cartelle con contenuti.\n\n\n\nA.1.4.2 Visualizzazione e Manipolazione Contenuti dei File\n\nGet-Content 'file' | More: Visualizza il contenuto dei file con possibilità di navigazione, simile a less/more in Unix.\nGet-Content 'file': Mostra l’intero contenuto di un file, equivalente a cat in Unix.\nGet-Content 'file' -Head &lt;numero&gt;: Mostra le prime righe di un file, simile a head in Unix.\nGet-Content 'file' -Tail &lt;numero&gt;: Mostra le ultime righe di un file, equivalente a tail in Unix.\n\n\n\n\n\n\n\nÈ cruciale familiarizzarsi con l’utilizzo dei percorsi relativi per semplificare gli spostamenti tra le diverse directory. L’impiego dei percorsi relativi rende il processo di navigazione più intuitivo e meno incline agli errori.\n\nNomi Chiari e Concisi: Evitate di includere spazi nei nomi dei file e delle cartelle. Preferite l’utilizzo di trattini bassi (_) per separare le parole e mantenere una struttura leggibile e facilmente comprensibile.\nEvitare Caratteri Speciali: È importante evitare l’inserimento di caratteri speciali come asterischi (*), dollari ($), slash (/, \\), punti (.), virgole (,), punti e virgole (;), parentesi (()), parentesi quadre ([]), parentesi graffe ({}), ampersand (&), barre verticali (|), punti esclamativi (!), punti interrogativi (?) nei nomi dei file e delle cartelle. Talvolta, anche l’uso del trattino (-) può causare problemi; quindi è consigliabile evitarlo. Questi caratteri possono generare problemi di compatibilità con alcuni sistemi operativi o applicazioni, rendendo più complessa la gestione dei file.\nDifferenziazione tra Maiuscole e Minuscole: Unix distingue tra maiuscole e minuscole (tratta le lettere come oggetti distinti), mentre Windows non lo fa. Per evitare confusioni, è consigliabile adottare una politica conservativa: considerate i nomi che differiscono solo per la case delle lettere come distinti.\n\nSeguendo questi consigli, è possibile ottimizzare notevolmente l’organizzazione e la gestione dei propri file, migliorando l’efficienza del lavoro e riducendo il rischio di errori.\n\n\n\nCon la pratica, la riga di comando diventa uno strumento molto efficiente. Questa breve guida fornisce le basi per iniziare a esplorare e gestire i file dal terminale, offrendo una base di partenza per ulteriori apprendimenti (es., Robbins, 2016). La familiarità con la shell è fondamentale nella data science.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>La Shell</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01_shell.html#bibliografia",
    "href": "chapters/appendix/a01_shell.html#bibliografia",
    "title": "Appendice A — La Shell",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nRobbins, A. (2016). Bash Pocket Reference: Help for Power Users and Sys Admins. O’Reilly Media, Inc.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>La Shell</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01a_files.html",
    "href": "chapters/appendix/a01a_files.html",
    "title": "Appendice B — Cartelle e documenti",
    "section": "",
    "text": "B.1 Introduzione\nI file su un computer sono organizzati tramite una struttura gerarchica chiamata struttura ad albero, costituita da cartelle (o directory) e file. Questa organizzazione permette una gestione ordinata e intuitiva delle informazioni.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Cartelle e documenti</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01a_files.html#introduzione",
    "href": "chapters/appendix/a01a_files.html#introduzione",
    "title": "Appendice B — Cartelle e documenti",
    "section": "",
    "text": "Radice (Root): È il punto più alto dell’albero da cui partono tutte le ramificazioni.\nCartelle/Directory: Contenitori che possono includere file o altre cartelle.\nFile: Gli elementi finali che contengono dati.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Cartelle e documenti</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01a_files.html#unixlinuxmacos",
    "href": "chapters/appendix/a01a_files.html#unixlinuxmacos",
    "title": "Appendice B — Cartelle e documenti",
    "section": "B.2 Unix/Linux/macOS",
    "text": "B.2 Unix/Linux/macOS\nNei sistemi Unix, l’albero ha una struttura chiara che inizia sempre dalla radice indicata con lo slash /.\nEsempio semplificato:\n/\n├── bin             # programmi di sistema essenziali\n├── etc             # file di configurazione\n├── home            # cartelle personali degli utenti\n│   └── utente\n│       ├── Documenti\n│       ├── Immagini\n│       └── Scaricati\n├── usr             # applicazioni e librerie utente\n├── var             # dati variabili come log e cache\n└── tmp             # file temporanei\nNei sistemi Unix i percorsi dei file si scrivono utilizzando lo slash (/), ad esempio:\n/home/utente/Documenti/tesi.docx",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Cartelle e documenti</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01a_files.html#windows",
    "href": "chapters/appendix/a01a_files.html#windows",
    "title": "Appendice B — Cartelle e documenti",
    "section": "B.3 Windows",
    "text": "B.3 Windows\nWindows organizza i file in maniera simile ma partendo da una o più unità (dischi), tipicamente indicate da lettere come C:, D:, ecc. La radice di ogni albero corrisponde quindi all’unità disco.\nEsempio semplificato:\nC:\\\n├── Program Files   # applicazioni installate\n├── Windows         # sistema operativo e file di sistema\n├── Utenti          # dati degli utenti\n│   └── utente\n│       ├── Documenti\n│       ├── Immagini\n│       └── Download\n└── Temp            # file temporanei\nNei sistemi Windows i percorsi dei file si scrivono utilizzando il backslash (\\), ad esempio:\nC:\\Utenti\\utente\\Documenti\\tesi.docx",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Cartelle e documenti</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01a_files.html#principali-comandi",
    "href": "chapters/appendix/a01a_files.html#principali-comandi",
    "title": "Appendice B — Cartelle e documenti",
    "section": "B.4 Principali Comandi",
    "text": "B.4 Principali Comandi\nQui sotto viene presentata una panoramica sintetica dei principali comandi per gestire la struttura ad albero di file e cartelle nei sistemi Unix (Linux e macOS) e Windows.\n\nB.4.1 Unix/Linux/macOS (Terminale Bash o zsh)\n\n\n\n\n\n\n\n\nComando\nFunzione\nEsempio\n\n\n\n\npwd\nMostra la cartella corrente (Print Working Directory)\npwd → /home/utente/Documenti\n\n\ncd\nCambia la cartella corrente (Change Directory)\ncd /home/utente/Scaricati\n\n\nls\nElenca il contenuto di una cartella (List)\nls o ls -l\n\n\nmkdir\nCrea una nuova cartella (Make Directory)\nmkdir nuova_cartella\n\n\nmv\nSposta o rinomina file/cartelle (Move)\nmv file.txt Documenti/ oppure mv vecchio.txt nuovo.txt\n\n\ncp\nCopia file/cartelle (Copy)\ncp file.txt copia_file.txt\n\n\nrm\nRimuove file (Remove)\nrm file.txt\n\n\nrmdir\nRimuove una cartella vuota (Remove Directory)\nrmdir cartella_vuota\n\n\nwhoami\nMostra l’utente corrente\nwhoami → utente\n\n\n\nEsempio di uso dei comandi:\npwd\ncd /home/utente\nmkdir nuovo\ncd nuovo\ntouch prova.txt\nls\nmv prova.txt ../Documenti\ncd ../Documenti\ncp prova.txt copia_prova.txt\nrm prova.txt\nwhoami\n\n\nB.4.2 Windows (Prompt dei comandi, CMD)\n\n\n\n\n\n\n\n\nComando\nFunzione\nEsempio\n\n\n\n\ncd\nCambia la cartella corrente (Change Directory)\ncd C:\\Utenti\\utente\\Documenti\n\n\ncd\nMostra la cartella corrente\ncd → C:\\Utenti\\utente\\Documenti\n\n\ndir\nElenca il contenuto della cartella\ndir\n\n\nmkdir\nCrea una nuova cartella\nmkdir nuova_cartella\n\n\nmove\nSposta o rinomina file/cartelle\nmove file.txt Documenti\\ o move vecchio.txt nuovo.txt\n\n\ncopy\nCopia file\ncopy file.txt copia_file.txt\n\n\ndel\nRimuove file\ndel file.txt\n\n\nrmdir\nRimuove cartella vuota\nrmdir cartella_vuota\n\n\nwhoami\nMostra l’utente corrente\nwhoami → utente\n\n\n\nEsempio di uso dei comandi:\ncd C:\\Utenti\\utente\nmkdir nuovo\ncd nuovo\necho prova &gt; prova.txt\ndir\nmove prova.txt ..\\Documenti\ncd ..\\Documenti\ncopy prova.txt copia_prova.txt\ndel prova.txt\nwhoami\nNota finale.\nEntrambi i sistemi operativi consentono operazioni simili, ma hanno sintassi e convenzioni leggermente diverse. Questi comandi di base permettono una gestione essenziale e rapida della struttura ad albero.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Cartelle e documenti</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01a_files.html#conclusioni",
    "href": "chapters/appendix/a01a_files.html#conclusioni",
    "title": "Appendice B — Cartelle e documenti",
    "section": "Conclusioni",
    "text": "Conclusioni\nIn sintesi, entrambi i sistemi operativi utilizzano una struttura ad albero per facilitare la gestione, la navigazione e l’organizzazione dei file e delle cartelle. Cambiano principalmente la notazione (/ o \\) e la gestione della radice (una singola radice / in Unix, più radici contrassegnate da lettere come C: in Windows).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Cartelle e documenti</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a02_math_symbols.html",
    "href": "chapters/appendix/a02_math_symbols.html",
    "title": "Appendice C — Simbologia di base",
    "section": "",
    "text": "Per una scrittura più sintetica possono essere utilizzati alcuni simboli matematici.\n\n\\(\\log(x)\\): il logaritmo naturale di \\(x\\).\nL’operatore logico booleano \\(\\land\\) significa “e” (congiunzione forte) mentre il connettivo di disgiunzione \\(\\lor\\) significa “o” (oppure) (congiunzione debole).\nIl quantificatore esistenziale \\(\\exists\\) vuol dire “esiste almeno un” e indica l’esistenza di almeno una istanza del concetto/oggetto indicato. Il quantificatore esistenziale di unicità \\(\\exists!\\) (“esiste soltanto un”) indica l’esistenza di esattamente una istanza del concetto/oggetto indicato. Il quantificatore esistenziale \\(\\nexists\\) nega l’esistenza del concetto/oggetto indicato.\nIl quantificatore universale \\(\\forall\\) vuol dire “per ogni.”\n\\(\\mathcal{A, S}\\): insiemi.\n\\(x \\in A\\): \\(x\\) è un elemento dell’insieme \\(A\\).\nL’implicazione logica “\\(\\Rightarrow\\)” significa “implica” (se …allora). \\(P \\Rightarrow Q\\) vuol dire che \\(P\\) è condizione sufficiente per la verità di \\(Q\\) e che \\(Q\\) è condizione necessaria per la verità di \\(P\\).\nL’equivalenza matematica “\\(\\iff\\)” significa “se e solo se” e indica una condizione necessaria e sufficiente, o corrispondenza biunivoca.\nIl simbolo \\(\\vert\\) si legge “tale che.”\nIl simbolo \\(\\triangleq\\) (o \\(:=\\)) si legge “uguale per definizione.”\nIl simbolo \\(\\Delta\\) indica la differenza fra due valori della variabile scritta a destra del simbolo.\nIl simbolo \\(\\propto\\) si legge “proporzionale a.”\nIl simbolo \\(\\approx\\) si legge “circa.”\nIl simbolo \\(\\in\\) della teoria degli insiemi vuol dire “appartiene” e indica l’appartenenza di un elemento ad un insieme. Il simbolo \\(\\notin\\) vuol dire “non appartiene.”\nIl simbolo \\(\\subseteq\\) si legge “è un sottoinsieme di” (può coincidere con l’insieme stesso). Il simbolo \\(\\subset\\) si legge “è un sottoinsieme proprio di.”\nIl simbolo \\(\\#\\) indica la cardinalità di un insieme.\nIl simbolo \\(\\cap\\) indica l’intersezione di due insiemi. Il simbolo \\(\\cup\\) indica l’unione di due insiemi.\nIl simbolo \\(\\emptyset\\) indica l’insieme vuoto o evento impossibile.\nIn matematica, \\(\\mbox{argmax}\\) identifica l’insieme dei punti per i quali una data funzione raggiunge il suo massimo. In altre parole, \\(\\mbox{argmax}_x f(x)\\) è l’insieme dei valori di \\(x\\) per i quali \\(f(x)\\) raggiunge il valore più alto.\n\\(a, c, \\alpha, \\gamma\\): scalari.\n\\(\\boldsymbol{x}, \\boldsymbol{y}\\): vettori.\n\\(\\boldsymbol{X}, \\boldsymbol{Y}\\): matrici.\n\\(X \\sim p\\): la variabile casuale \\(X\\) si distribuisce come \\(p\\).\n\\(p(\\cdot)\\): distribuzione di massa o di densità di probabilità.\n\\(p(y \\mid \\boldsymbol{x})\\): la probabilità o densità di \\(y\\) dato \\(\\boldsymbol{x}\\), ovvero \\(p(y = \\boldsymbol{Y} \\mid x = \\boldsymbol{X})\\).\n\\(f(x)\\): una funzione arbitraria di \\(x\\).\n\\(f(\\boldsymbol{X}; \\theta, \\gamma)\\): \\(f\\) è una funzione di \\(\\boldsymbol{X}\\) con parametri \\(\\theta, \\gamma\\). Questa notazione indica che \\(\\boldsymbol{X}\\) sono i dati che vengono passati ad un modello di parametri \\(\\theta, \\gamma\\).\n\\(\\mathcal{N}(\\mu, \\sigma^2)\\): distribuzione gaussiana di media \\(\\mu\\) e varianza \\(sigma^2\\).\n\\(\\mbox{Beta}(\\alpha, \\beta)\\): distribuzione Beta di parametri \\(\\alpha\\) e \\(\\beta\\).\n\\(\\mathcal{U}(a, b)\\): distribuzione uniforme con limite inferiore \\(a\\) e limite superiore \\(b\\).\n\\(\\mbox{Cauchy}(\\alpha, \\beta)\\): distribuzione di Cauchy di parametri \\(\\alpha\\) (posizione: media) e \\(\\beta\\) (scala: radice quadrata della varianza).\n\\(\\mathcal{B}(p)\\): distribuzione di Bernoulli di parametro \\(p\\) (probabilità di successo).\n\\(\\mbox{Bin}(n, p)\\): distribuzione binomiale di parametri \\(n\\) (numero di prove) e \\(p\\) (probabilità di successo).\n\\(\\mathbb{KL} (p \\mid\\mid q)\\): la divergenza di Kullback-Leibler da \\(p\\) a \\(q\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Simbologia di base</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a03_latex.html",
    "href": "chapters/appendix/a03_latex.html",
    "title": "Appendice D — Equazioni Matematiche in LaTeX",
    "section": "",
    "text": "D.1 LaTeX\nLaTeX è un potente strumento di composizione tipografica, ampiamente utilizzato per la produzione di documenti scientifici e tecnici. Una delle sue caratteristiche più apprezzate è la capacità di gestire equazioni matematiche in modo elegante e preciso. In questo articolo, esploreremo come scrivere equazioni matematiche in LaTeX, coprendo i modi matematici, le operazioni di base, l’allineamento delle equazioni e molto altro.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Equazioni Matematiche in LaTeX</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a03_latex.html#modelli-matematici-in-latex",
    "href": "chapters/appendix/a03_latex.html#modelli-matematici-in-latex",
    "title": "Appendice D — Equazioni Matematiche in LaTeX",
    "section": "D.2 Modelli Matematici in LaTeX",
    "text": "D.2 Modelli Matematici in LaTeX\nPer scrivere equazioni matematiche in LaTeX, esistono due modalità principali: la modalità inline e la modalità display.\n\nModalità Inline: Utilizzata per inserire equazioni all’interno del testo. Le espressioni matematiche sono racchiuse tra simboli di dollaro ($), ad esempio $E=mc^2$ produce \\(E=mc^2\\).\nModalità Display: Utilizzata per equazioni che devono essere evidenziate e centrate su una nuova linea. Le espressioni possono essere racchiuse tra $$ e $$, o all’interno di ambienti come \\begin{equation} e \\end{equation}.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Equazioni Matematiche in LaTeX</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a03_latex.html#scrivere-costrutti-matematici-di-base",
    "href": "chapters/appendix/a03_latex.html#scrivere-costrutti-matematici-di-base",
    "title": "Appendice D — Equazioni Matematiche in LaTeX",
    "section": "D.3 Scrivere Costrutti Matematici di Base",
    "text": "D.3 Scrivere Costrutti Matematici di Base\n\nD.3.1 Operazioni Aritmetiche\nLe operazioni aritmetiche possono essere scritte direttamente all’interno del testo utilizzando il simbolo del dollaro. Ad esempio:\n\nAddizione: $a + b$ produce \\(a + b\\).\nMoltiplicazione: $a \\cdot b$ o $a \\times b$ produce \\(a \\cdot b\\) o \\(a \\times b\\).\nDivisione: $a / b$ o $a \\div b$ produce \\(a / b\\) o \\(a \\div b\\).\n\n\n\nD.3.2 Frazioni e Coefficienti Binomiali\nLe frazioni si scrivono utilizzando il comando \\frac{num}{den}. Ad esempio, $\\frac{a}{b}$ produce \\(\\frac{a}{b}\\).\nPer i coefficienti binomiali, si utilizza il comando \\binom{n}{k}. Ad esempio, $\\binom{n}{k}$ produce \\(\\binom{n}{k}\\).\n\n\nD.3.3 Pedici e Apici\nI pedici si ottengono con _, mentre gli apici con ^. Ad esempio:\n\n$a_{1}$ produce \\(a_{1}\\).\n$a^{2}$ produce \\(a^{2}\\).\n\n\n\nD.3.4 Integrali e Radici\nPer gli integrali, i limiti di integrazione si scrivono come pedici e apici. Ad esempio:\n\n$\\int_{a}^{b} f(x) \\, dx$ produce \\(\\int_{a}^{b} f(x) \\, dx\\).\n\nLe radici si ottengono con il comando \\sqrt{}. Ad esempio, $\\sqrt{a + b}$ produce \\(\\sqrt{a + b}\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Equazioni Matematiche in LaTeX</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a03_latex.html#allineamento-delle-equazioni",
    "href": "chapters/appendix/a03_latex.html#allineamento-delle-equazioni",
    "title": "Appendice D — Equazioni Matematiche in LaTeX",
    "section": "D.4 Allineamento delle Equazioni",
    "text": "D.4 Allineamento delle Equazioni\nPer allineare più equazioni, si utilizza l’ambiente align. Ad esempio:\n\\begin{align*}\na + b &= c \\\\\nd + e &= f\n\\end{align*}\nQuesto allinea le equazioni al segno di uguale.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Equazioni Matematiche in LaTeX</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a03_latex.html#parentesi-e-operatori",
    "href": "chapters/appendix/a03_latex.html#parentesi-e-operatori",
    "title": "Appendice D — Equazioni Matematiche in LaTeX",
    "section": "D.5 Parentesi e Operatori",
    "text": "D.5 Parentesi e Operatori\nLe parentesi possono essere ridimensionate utilizzando i comandi \\left( e \\right). Ad esempio:\n$$ \n\\left( \\frac{a}{b} \\right) \n$$\nGli operatori come seno, coseno e logaritmi si scrivono con comandi specifici come \\sin, \\cos, e \\log.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Equazioni Matematiche in LaTeX</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a03_latex.html#conclusione",
    "href": "chapters/appendix/a03_latex.html#conclusione",
    "title": "Appendice D — Equazioni Matematiche in LaTeX",
    "section": "D.6 Conclusione",
    "text": "D.6 Conclusione\nLaTeX offre una vasta gamma di strumenti per la scrittura di equazioni matematiche, rendendolo uno strumento indispensabile per chiunque lavori con documenti scientifici. Con un po’ di pratica, è possibile padroneggiare queste tecniche e produrre documenti di alta qualità con facilità.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Equazioni Matematiche in LaTeX</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html",
    "href": "chapters/appendix/a11_numbers.html",
    "title": "Appendice E — Numeri e intervalli",
    "section": "",
    "text": "E.1 Numeri binari\nI numeri binari rappresentano il sistema numerico più elementare utilizzato in informatica, poiché sono composti unicamente da due simboli: 0 e 1. Questa caratteristica li rende particolarmente adatti alla rappresentazione di situazioni dicotomiche (vero/falso, presente/assente) e consente ai computer di operare rapidamente ed efficacemente sui dati.\nUn esempio semplice d’impiego dei valori logici binari si ottiene quando raccogliamo risposte a una domanda chiusa. Immaginiamo, ad esempio, di porre la domanda “Ti piacciono i mirtilli?” a 10 studenti. Se le risposte vengono memorizzate in R come valori logici (TRUE per “Sì” e FALSE per “No”), potremmo avere:\nopinion &lt;- c(TRUE, FALSE, TRUE, TRUE, TRUE, FALSE, TRUE, TRUE, TRUE, FALSE)\nopinion\n\n [1]  TRUE FALSE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE FALSE\nIn questo caso, TRUE e FALSE corrispondono a 1 e 0 rispettivamente quando utilizzati in operazioni numeriche. Lo stesso avviene in Python, dove True è interpretato come 1 e False come 0. Questa rappresentazione binaria permette di ottenere facilmente statistiche sintetiche. Per esempio, per calcolare la proporzione di risposte positive rispetto al totale, è sufficiente sommare i valori (contando così il numero di TRUE) e dividere per la lunghezza del vettore:\nsum(opinion) / length(opinion)\n\n[1] 0.7\nQuesto fornisce immediatamente la percentuale di studenti che hanno risposto “Sì” alla domanda.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-interi",
    "href": "chapters/appendix/a11_numbers.html#numeri-interi",
    "title": "Appendice E — Numeri e intervalli",
    "section": "\nE.2 Numeri interi",
    "text": "E.2 Numeri interi\nI numeri interi sono caratterizzati dall’assenza di componenti decimali. Essi includono sia i numeri naturali (1, 2, 3, …), tradizionalmente utilizzati per il conteggio, sia i loro opposti negativi. L’insieme dei numeri naturali è indicato con \\(\\mathbb{N}\\), mentre l’insieme dei numeri interi (che include i numeri naturali, i loro negativi e lo zero) si denota con \\(\\mathbb{Z}\\):\n\\[\n\\mathbb{Z} = \\{0, \\pm 1, \\pm 2, \\pm 3, \\dots\\}\n\\]",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-razionali",
    "href": "chapters/appendix/a11_numbers.html#numeri-razionali",
    "title": "Appendice E — Numeri e intervalli",
    "section": "\nE.3 Numeri razionali",
    "text": "E.3 Numeri razionali\nI numeri razionali sono quei numeri che possono essere espressi come il rapporto tra due numeri interi, con il denominatore diverso da zero. Essi formano l’insieme:\n\\[\n\\mathbb{Q} = \\left\\{\\frac{m}{n} \\mid m,n \\in \\mathbb{Z}, n \\neq 0\\right\\}.\n\\]\nPoiché ogni numero naturale è anche un intero, e ogni intero può essere rappresentato come razionale (ad esempio \\(5 = \\frac{5}{1}\\)), si ha una catena d’inclusioni tra i diversi insiemi di numeri:\n\\[\n\\mathbb{N} \\subseteq \\mathbb{Z} \\subseteq \\mathbb{Q}.\n\\]\nSe si desidera considerare solo i numeri razionali non negativi, si utilizza la notazione:\n\\[\n\\mathbb{Q}^+ = \\{q \\in \\mathbb{Q} \\mid q \\geq 0\\}.\n\\]",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-irrazionali",
    "href": "chapters/appendix/a11_numbers.html#numeri-irrazionali",
    "title": "Appendice E — Numeri e intervalli",
    "section": "\nE.4 Numeri irrazionali",
    "text": "E.4 Numeri irrazionali\nNon tutti i numeri possono essere espressi come rapporto di due interi. I numeri che non hanno questa proprietà sono detti irrazionali. Essi non possono essere scritti in forma frazionaria e la loro espansione decimale è infinita e non periodica. Esempi tipici di numeri irrazionali sono:\n\n\\(\\sqrt{2}\\)\n\\(\\sqrt{3}\\)\n\\(\\pi = 3.141592...\\)",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-reali",
    "href": "chapters/appendix/a11_numbers.html#numeri-reali",
    "title": "Appendice E — Numeri e intervalli",
    "section": "\nE.5 Numeri reali",
    "text": "E.5 Numeri reali\nI numeri razionali non coprono tutti i possibili punti sulla retta reale. Per rappresentare ogni possibile misura, grandezza o punto su una linea continua, si considerano i numeri reali, denotati con \\(\\mathbb{R}\\). L’insieme dei numeri reali comprende sia i razionali sia gli irrazionali:\n\\[\n\\mathbb{N} \\subseteq \\mathbb{Z} \\subseteq \\mathbb{Q} \\subseteq \\mathbb{R}.\n\\]\nIn statistica, la precisione con cui si esprime una misura è spesso legata al numero di cifre decimali utilizzate, sfruttando così appieno la “continuità” offerta dai numeri reali.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#intervalli-numerici",
    "href": "chapters/appendix/a11_numbers.html#intervalli-numerici",
    "title": "Appendice E — Numeri e intervalli",
    "section": "\nE.6 Intervalli Numerici",
    "text": "E.6 Intervalli Numerici\nDefinizione: Un intervallo numerico è un sottoinsieme connesso della retta reale. Intuitivamente, rappresenta tutti i numeri reali compresi tra due estremi, che possono o meno essere inclusi nell’intervallo stesso.\nClassificazione degli intervalli: Gli intervalli vengono classificati in base all’inclusione o meno degli estremi:\n\n\nIntervallo chiuso: Include entrambi gli estremi. Si indica con \\([a, b]\\) e rappresenta l’insieme dei numeri reali \\(x\\) tali che \\(a \\leq x \\leq b\\).\n\nIntervallo aperto: Non include alcun estremo. Si indica con \\((a, b)\\) e rappresenta l’insieme dei numeri reali \\(x\\) tali che \\(a &lt; x &lt; b\\).\n\nIntervalli semiaperti:\n\n\nChiuso a sinistra e aperto a destra: Include l’estremo sinistro ma non quello destro. Si indica con \\([a, b)\\) e rappresenta l’insieme dei numeri reali \\(x\\) tali che \\(a \\leq x &lt; b\\).\n\nAperto a sinistra e chiuso a destra: Include l’estremo destro ma non quello sinistro. Si indica con \\((a, b]\\) e rappresenta l’insieme dei numeri reali \\(x\\) tali che \\(a &lt; x \\leq b\\).\n\n\n\nTabella riassuntiva:\n\n\nIntervallo\nNotazione\nCondizione\n\n\n\nChiuso\n\\([a, b]\\)\n\\(a \\leq x \\leq b\\)\n\n\nAperto\n\\((a, b)\\)\n\\(a &lt; x &lt; b\\)\n\n\nChiuso a sinistra, aperto a destra\n\\([a, b)\\)\n\\(a \\leq x &lt; b\\)\n\n\nAperto a sinistra, chiuso a destra\n\\((a, b]\\)\n\\(a &lt; x \\leq b\\)\n\n\n\nOsservazioni: * La scelta della notazione con parentesi quadre o tonde indica rispettivamente l’inclusione o l’esclusione degli estremi.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html",
    "href": "chapters/appendix/a12_sum_notation.html",
    "title": "Appendice F — Sommatorie",
    "section": "",
    "text": "F.1 Manipolazione di somme\nLe somme sono uno strumento fondamentale in molti contesti matematici e statistici, e per gestirle in modo efficace è essenziale disporre di una notazione chiara e precisa. Consideriamo, ad esempio, la somma dei primi \\(n\\) numeri interi, che può essere espressa come \\(1 + 2 + \\dots + (n-1) + n\\), dove i puntini di sospensione (\\(\\dots\\)) indicano che la sequenza deve essere completata seguendo il pattern definito dai termini precedenti e successivi. Tuttavia, una notazione come \\(1 + 7 + \\dots + 73.6\\) risulterebbe ambigua senza ulteriori specifiche. In generale, ci troveremo di fronte a somme della forma\n\\[\nx_1 + x_2 + \\dots + x_n,\n\\]\ndove \\(x_n\\) rappresenta un numero definito altrove. Sebbene questa notazione con i puntini di sospensione sia utile in alcuni contesti, può risultare poco chiara in altri. Per questo motivo, si preferisce utilizzare la notazione di sommatoria:\n\\[\n\\sum_{i=1}^n x_i,\n\\]\nche si legge “sommatoria per \\(i\\) che va da \\(1\\) a \\(n\\) di \\(x_i\\)”. Il simbolo \\(\\sum\\) (la lettera sigma maiuscola dell’alfabeto greco) rappresenta l’operazione di somma, \\(x_i\\) è il generico addendo, mentre \\(1\\) e \\(n\\) sono gli estremi della sommatoria, che definiscono l’intervallo di variazione dell’indice \\(i\\). Solitamente, l’estremo inferiore è \\(1\\), ma potrebbe essere qualsiasi altro numero \\(m &lt; n\\). Pertanto, possiamo scrivere:\n\\[\n\\sum_{i=1}^n x_i = x_1 + x_2 + \\dots + x_n.\n\\]\nAd esempio, se i valori di \\(x\\) sono \\(\\{3, 11, 4, 7\\}\\), avremo:\n\\[\n\\sum_{i=1}^4 x_i = 3 + 11 + 4 + 7 = 25,\n\\]\ndove \\(x_1 = 3\\), \\(x_2 = 11\\), e così via. La quantità \\(x_i\\) è detta argomento della sommatoria, mentre la variabile \\(i\\), che assume valori interi successivi, è chiamata indice della sommatoria.\nLa notazione di sommatoria può anche essere espressa nella forma:\n\\[\n\\sum_{P(i)} x_i,\n\\]\ndove \\(P(i)\\) è una proposizione logica riguardante \\(i\\) che può essere vera o falsa. Quando è evidente che si vogliono sommare tutte le \\(n\\) osservazioni, la notazione può essere semplificata in \\(\\sum_{i} x_i\\) o addirittura \\(\\sum x_i\\). L’indice \\(i\\) può essere sostituito da altre lettere, come \\(k, j, l, \\dots\\), a seconda del contesto.\nPer semplificare i calcoli che coinvolgono le sommatorie, è utile conoscere alcune proprietà fondamentali.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html#manipolazione-di-somme",
    "href": "chapters/appendix/a12_sum_notation.html#manipolazione-di-somme",
    "title": "Appendice F — Sommatorie",
    "section": "",
    "text": "F.1.1 Proprietà 1 (Somma di una costante)\nLa sommatoria di \\(n\\) valori tutti uguali a una costante \\(a\\) è pari a \\(n\\) volte la costante stessa:\n\\[\n\\sum_{i=1}^{n} a = \\underbrace{a + a + \\dots + a}_{n \\text{ volte}} = n a.\n\\]\n\n\nF.1.2 Proprietà 2 (Proprietà distributiva)\nSe l’argomento della sommatoria contiene una costante, è possibile fattorizzarla. Ad esempio:\n\\[\n\\sum_{i=1}^{n} a x_i = a x_1 + a x_2 + \\dots + a x_n = a (x_1 + x_2 + \\dots + x_n) = a \\sum_{i=1}^{n} x_i.\n\\]\n\n\nF.1.3 Proprietà 3 (Proprietà associativa)\nSe l’argomento della sommatoria è una somma, possiamo separare i termini:\n\\[\n\\sum_{i=1}^{n} (a + x_i) = (a + x_1) + (a + x_2) + \\dots + (a + x_n) = n a + \\sum_{i=1}^{n} x_i.\n\\]\nIn generale, possiamo scrivere:\n\\[\n\\sum_{i=1}^{n} (x_i + y_i) = \\sum_{i=1}^{n} x_i + \\sum_{i=1}^{n} y_i.\n\\]\n\n\nF.1.4 Proprietà 4 (Operazioni algebriche)\nSe è necessario eseguire un’operazione algebrica (come l’elevamento a potenza o il logaritmo) sull’argomento della sommatoria, questa operazione deve essere eseguita prima della somma. Ad esempio:\n\\[\n\\sum_{i=1}^{n} x_i^2 = x_1^2 + x_2^2 + \\dots + x_n^2 \\neq \\left( \\sum_{i=1}^{n} x_i \\right)^2.\n\\]\n\n\nF.1.5 Proprietà 5 (Prodotto di termini)\nNel caso di un prodotto tra termini, il prodotto deve essere eseguito prima della somma:\n\\[\n\\sum_{i=1}^{n} x_i y_i = x_1 y_1 + x_2 y_2 + \\dots + x_n y_n.\n\\]\nInfatti, \\(a_1 b_1 + a_2 b_2 \\neq (a_1 + a_2)(b_1 + b_2)\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html#doppia-sommatoria",
    "href": "chapters/appendix/a12_sum_notation.html#doppia-sommatoria",
    "title": "Appendice F — Sommatorie",
    "section": "F.2 Doppia sommatoria",
    "text": "F.2 Doppia sommatoria\nIn alcuni contesti, si incontrano espressioni con una doppia sommatoria e un doppio indice:\n\\[\n\\sum_{i=1}^{n} \\sum_{j=1}^{m} x_{ij}.\n\\]\nQuesta notazione implica che, per ogni valore dell’indice esterno \\(i\\) (da \\(1\\) a \\(n\\)), si deve sviluppare la sommatoria interna per \\(j\\) (da \\(1\\) a \\(m\\)). Ad esempio:\n\\[\n\\sum_{i=1}^{3} \\sum_{j=4}^{6} x_{ij} = (x_{1,4} + x_{1,5} + x_{1,6}) + (x_{2,4} + x_{2,5} + x_{2,6}) + (x_{3,4} + x_{3,5} + x_{3,6}).\n\\]\nUn caso particolare interessante è la doppia sommatoria del prodotto di due variabili:\n\\[\n\\sum_{i=1}^{n} \\sum_{j=1}^{n} x_i y_j.\n\\]\nIn questo caso, poiché \\(x_i\\) non dipende dall’indice \\(j\\), possiamo estrarre \\(x_i\\) dalla sommatoria interna:\n\\[\n\\sum_{i=1}^{n} \\left( x_i \\sum_{j=1}^{n} y_j \\right).\n\\]\nAllo stesso modo, la sommatoria interna \\(\\sum_{j=1}^{n} y_j\\) non dipende da \\(i\\), quindi può essere estratta dalla sommatoria esterna:\n\\[\n\\sum_{i=1}^{n} \\sum_{j=1}^{n} x_i y_j = \\left( \\sum_{i=1}^{n} x_i \\right) \\left( \\sum_{j=1}^{n} y_j \\right).\n\\]\n\nF.2.1 Esempio pratico\nConsideriamo i vettori \\(x = \\{2, 3, 1\\}\\) e \\(y = \\{1, 4, 9\\}\\). Calcoliamo la doppia sommatoria:\n\\[\n\\begin{aligned}\n\\sum_{i=1}^3 \\sum_{j=1}^3 x_i y_j &= x_1 y_1 + x_1 y_2 + x_1 y_3 + x_2 y_1 + x_2 y_2 + x_2 y_3 + x_3 y_1 + x_3 y_2 + x_3 y_3 \\\\\n&= 2 \\times (1 + 4 + 9) + 3 \\times (1 + 4 + 9) + 1 \\times (1 + 4 + 9) \\\\\n&= 2 \\times 14 + 3 \\times 14 + 1 \\times 14 = 84.\n\\end{aligned}\n\\]\nD’altra parte, il prodotto delle due sommatorie è:\n\\[\n\\left( \\sum_{i=1}^3 x_i \\right) \\left( \\sum_{j=1}^3 y_j \\right) = (2 + 3 + 1) \\times (1 + 4 + 9) = 6 \\times 14 = 84.\n\\]\nI due risultati coincidono, confermando la validità della proprietà.\nPer ulteriori approfondimenti, si consiglia la consultazione del testo Concrete Mathematics: A Foundation for Computer Science (Graham et al., 1994).\nEsercizi pratici sono disponibili sulla seguente pagina web.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html#bibliografia",
    "href": "chapters/appendix/a12_sum_notation.html#bibliografia",
    "title": "Appendice F — Sommatorie",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGraham, R. L., Knuth, D. E., & Patashnik, O. (1994). Concrete Mathematics: A Foundation for Computer Science (2nd ed.). Addison-Wesley.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html",
    "href": "chapters/appendix/a13_sets.html",
    "title": "Appendice G — Insiemi",
    "section": "",
    "text": "G.1 Diagrammi di Eulero-Venn\nUn insieme (o collezione, classe, gruppo, …) è stato definito da Georg Cantor nel modo seguente:\nMentre non è rilevante la natura degli oggetti che costituiscono l’insieme, ciò che importa è distinguere se un dato oggetto appartenga o meno ad un insieme. Deve essere vera una delle due possibilità: il dato oggetto è un elemento dell’insieme considerato oppure non è elemento dell’insieme considerato. Due insiemi \\(A\\) e \\(B\\) si dicono uguali se sono formati dagli stessi elementi, anche se disposti in ordine diverso: \\(A=B\\). Due insiemi \\(A\\) e \\(B\\) si dicono diversi se non contengono gli stessi elementi: \\(A \\neq B\\). Ad esempio, i seguenti insiemi sono uguali:\n\\[\n\\{1, 2, 3\\} = \\{3, 1, 2\\} = \\{1, 3, 2\\}= \\{1, 1, 1, 2, 3, 3, 3\\}.\n\\]\nGli insiemi sono denotati da una lettera maiuscola, mentre le lettere minuscole, di solito, designano gli elementi di un insieme. Per esempio, un generico insieme \\(A\\) si indica con\n\\[\nA = \\{a_1, a_2, \\dots, a_n\\}, \\quad \\text{con } n &gt; 0.\n\\]\nLa scrittura \\(a \\in A\\) dice che \\(a\\) è un elemento di \\(A\\). Per dire che \\(b\\) non è un elemento di \\(A\\) si scrive \\(b \\notin A.\\)\nPer quegli insiemi i cui elementi soddisfano una certa proprietà che li caratterizza, tale proprietà può essere usata per descrivere più sinteticamente l’insieme:\n\\[\nA = \\{x ~\\vert~ \\text{proprietà posseduta da } x\\},\n\\]\nche si legge come “\\(A\\) è l’insieme degli elementi \\(x\\) per cui è vera la proprietà indicata.” Per esempio, per indicare l’insieme \\(A\\) delle coppie di numeri reali \\((x,y)\\) che appartengono alla parabola \\(y = x^2 + 1\\) si può scrivere:\n\\[\nA = \\{(x,y) ~\\vert~ y = x^2 + 1\\}.\n\\]\nDati due insiemi \\(A\\) e \\(B\\), diremo che \\(A\\) è un sottoinsieme di \\(B\\) se e solo se tutti gli elementi di \\(A\\) sono anche elementi di \\(B\\):\n\\[\nA \\subseteq B \\iff (\\forall x \\in A \\Rightarrow x \\in B).\n\\]\nSe esiste almeno un elemento di \\(B\\) che non appartiene ad \\(A\\) allora diremo che \\(A\\) è un sottoinsieme proprio di \\(B\\):\n\\[\nA \\subset B \\iff (A \\subseteq B, \\exists~ x \\in B ~\\vert~ x \\notin A).\n\\]\nUn altro insieme, detto insieme delle parti, o insieme potenza, che si associa all’insieme \\(A\\) è l’insieme di tutti i sottoinsiemi di \\(A\\), inclusi l’insieme vuoto e \\(A\\) stesso. Per esempio, per l’insieme \\(A = \\{a, b, c\\}\\), l’insieme delle parti è:\n\\[\n\\mathcal{P}(A) = \\{\n\\emptyset, \\{a\\}, \\{b\\}, \\{c\\},\n\\{a, b\\}, \\{a, c\\}, \\{c, b\\},\n\\{a, b, c\\}\n\\}.\n\\]\nI diagrammi di Venn sono uno strumento grafico molto utile per rappresentare gli insiemi e per verificare le proprietà delle operazioni tra di essi. Questi diagrammi prendono il nome dal matematico inglese del 19° secolo John Venn, anche se rappresentazioni simili erano già state utilizzate in precedenza da Leibniz e Eulero.\nI diagrammi di Venn rappresentano gli insiemi come regioni del piano delimitate da una curva chiusa. Nel caso di insiemi finiti, è possibile evidenziare alcuni elementi di un insieme tramite punti, e in alcuni casi possono essere evidenziati tutti gli elementi degli insiemi considerati.\nIn sostanza, questi diagrammi sono un modo visuale per rappresentare le proprietà degli insiemi e delle operazioni tra di essi. Sono uno strumento molto utile per visualizzare la relazione tra gli insiemi e per capire meglio come si combinano gli elementi all’interno di essi.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#appartenenza-ad-un-insieme",
    "href": "chapters/appendix/a13_sets.html#appartenenza-ad-un-insieme",
    "title": "Appendice G — Insiemi",
    "section": "\nG.2 Appartenenza ad un insieme",
    "text": "G.2 Appartenenza ad un insieme\nUsiamo ora R\n\nSet1 &lt;- c(1, 2)\nprint(Set1)\n\n[1] 1 2\n\nprint(class(Set1))\n\n[1] \"numeric\"\n\n\n\nmy_list &lt;- c(1, 2, 3, 4)\nmy_set_from_list &lt;- unique(my_list)\nprint(my_set_from_list)\n\n[1] 1 2 3 4\n\n\nL’appartenenza ad un insieme si verifica con %in%.\n\nmy_set &lt;- c(1, 3, 5)\nprint(\"Ecco il mio insieme:\")\n\n[1] \"Ecco il mio insieme:\"\n\nprint(my_set)\n\n[1] 1 3 5\n\nprint(\"1 appartiene all'insieme:\")\n\n[1] \"1 appartiene all'insieme:\"\n\nprint(1 %in% my_set)\n\n[1] TRUE\n\nprint(\"2 non appartiene all'insieme:\")\n\n[1] \"2 non appartiene all'insieme:\"\n\nprint(2 %in% my_set)\n\n[1] FALSE\n\nprint(\"4 NON appartiene all'insieme:\")\n\n[1] \"4 NON appartiene all'insieme:\"\n\nprint(!(4 %in% my_set))\n\n[1] TRUE",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#relazioni-tra-insiemi",
    "href": "chapters/appendix/a13_sets.html#relazioni-tra-insiemi",
    "title": "Appendice G — Insiemi",
    "section": "\nG.3 Relazioni tra insiemi",
    "text": "G.3 Relazioni tra insiemi\nEsaminiamo le funzioni Python per descrivere le relazioni tra insiemi. In particolare, dopo avere definito l’insieme universo e l’insieme vuoto, considereremo la relazione di inclusione che conduce al concetto di sottoinsieme. Analogamente si definisce il concetto di sovrainsieme. Mostreremo anche come valutare se due insiemi sono disgiunti (si dicono disgiunti gli insiemi con intersezione vuota).\n\nUniv &lt;- 0:10\nSuper &lt;- Univ[Univ %% 2 == 0]\nDisj &lt;- Univ[Univ %% 2 == 1]\nSub &lt;- c(4, 6)\nNull &lt;- Univ[Univ &gt; 10]\n\n\nprint(\"Insieme Universo (tutti gli interi positivi fino a 10):\")\n\n[1] \"Insieme Universo (tutti gli interi positivi fino a 10):\"\n\nprint(Univ)\n\n [1]  0  1  2  3  4  5  6  7  8  9 10\n\nprint(\"Tutti gli interi positivi pari fino a 10:\")\n\n[1] \"Tutti gli interi positivi pari fino a 10:\"\n\nprint(Super)\n\n[1]  0  2  4  6  8 10\n\nprint(\"Tutti gli interi positivi dispari fino a 10:\")\n\n[1] \"Tutti gli interi positivi dispari fino a 10:\"\n\nprint(Disj)\n\n[1] 1 3 5 7 9\n\nprint(\"Insieme di due elementi, 4 e 6:\")\n\n[1] \"Insieme di due elementi, 4 e 6:\"\n\nprint(Sub)\n\n[1] 4 6\n\nprint(\"Un insieme vuoto:\")\n\n[1] \"Un insieme vuoto:\"\n\nprint(Null)\n\ninteger(0)\n\n\n\nprint('È \"Super\" un sovrainsieme di \"Sub\"?')\n\n[1] \"È \\\"Super\\\" un sovrainsieme di \\\"Sub\\\"?\"\n\nprint(all(Sub %in% Super))\n\n[1] TRUE\n\nprint('È \"Super\" un sottoinsieme di \"Univ\"?')\n\n[1] \"È \\\"Super\\\" un sottoinsieme di \\\"Univ\\\"?\"\n\nprint(all(Super %in% Univ))\n\n[1] TRUE\n\nprint('È \"Sub\" un sovrainsieme di \"Super\"?')\n\n[1] \"È \\\"Sub\\\" un sovrainsieme di \\\"Super\\\"?\"\n\nprint(all(Super %in% Sub))\n\n[1] FALSE\n\nprint('Sono \"Super\" e \"Disj\" insiemi disgiunti?')\n\n[1] \"Sono \\\"Super\\\" e \\\"Disj\\\" insiemi disgiunti?\"\n\nprint(length(intersect(Super, Disj)) == 0)\n\n[1] TRUE",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#operazioni-tra-insiemi",
    "href": "chapters/appendix/a13_sets.html#operazioni-tra-insiemi",
    "title": "Appendice G — Insiemi",
    "section": "\nG.4 Operazioni tra insiemi",
    "text": "G.4 Operazioni tra insiemi\nSi definisce intersezione di \\(A\\) e \\(B\\) l’insieme \\(A \\cap B\\) di tutti gli elementi \\(x\\) che appartengono ad \\(A\\) e contemporaneamente a \\(B\\):\n\\[\nA \\cap B = \\{x ~\\vert~ x \\in A \\land x \\in B\\}.\n\\]\nSi definisce unione di \\(A\\) e \\(B\\) l’insieme \\(A \\cup B\\) di tutti gli elementi \\(x\\) che appartengono ad \\(A\\) o a \\(B\\), cioè\n\\[\nA \\cup B = \\{x ~\\vert~ x \\in A \\lor x \\in B\\}.\n\\]\nDifferenza. Si indica con \\(A \\setminus B\\) l’insieme degli elementi di \\(A\\) che non appartengono a \\(B\\):\n\\[\nA \\setminus B = \\{x ~\\vert~ x \\in A \\land x \\notin B\\}.\n\\]\nInsieme complementare. Nel caso che sia \\(B \\subseteq A\\), l’insieme differenza \\(A \\setminus B\\) è detto insieme complementare di \\(B\\) in \\(A\\) e si indica con \\(B^C\\).\nDato un insieme \\(S\\), una partizione di \\(S\\) è una collezione di sottoinsiemi di \\(S\\), \\(S_1, \\dots, S_k\\), tali che\n\\[\nS = S_1 \\cup S_2 \\cup \\dots S_k\n\\]\ne\n\\[\nS_i \\cap S_j, \\quad \\text{con } i \\neq j.\n\\]\nLa relazione tra unione, intersezione e insieme complementare è data dalle leggi di DeMorgan:\n\\[\n(A \\cup B)^c = A^c \\cap B^c,\n\\]\n\\[\n(A \\cap B)^c = A^c \\cup B^c.\n\\]\nIn tutte le seguenti figure, \\(S\\) è la regione delimitata dal rettangolo, \\(L\\) è la regione all’interno del cerchio di sinistra e \\(R\\) è la regione all’interno del cerchio di destra. La regione evidenziata mostra l’insieme indicato sotto ciascuna figura.\n\n\nDiagrammi di Venn\n\nI diagrammi di Eulero-Venn che illustrano le leggi di DeMorgan sono forniti nella figura seguente.\n\n\nLeggi di DeMorgan\n\nVediamo ora come si eseguono le operazioni tra insiemi con R.\nIntersezione.\n\nS1 &lt;- seq(1, 10, by = 3)\nS2 &lt;- 1:6\nS_intersection &lt;- intersect(S1, S2)\nprint(\"Intersezione di S1 e S2:\")\n\n[1] \"Intersezione di S1 e S2:\"\n\nprint(S_intersection)\n\n[1] 1 4\n\n\nUnione. Si noti che il connettivo logico | corrisponde all’unione.\n\nS_union &lt;- union(S1, S2)\nprint(\"Unione di S1 e S2:\")\n\n[1] \"Unione di S1 e S2:\"\n\nprint(S_union)\n\n[1]  1  4  7 10  2  3  5  6\n\n\nInsieme complementare.\n\nS &lt;- seq(0, 20, by = 2)\nS_complement &lt;- setdiff(0:20, S)\nprint(\"S è l'insieme dei numeri interi pari tra 0 e 20:\")\n\n[1] \"S è l'insieme dei numeri interi pari tra 0 e 20:\"\n\nprint(S)\n\n [1]  0  2  4  6  8 10 12 14 16 18 20\n\nprint(\"S_complement è l'insieme dei numeri interi dispari tra 0 e 20:\")\n\n[1] \"S_complement è l'insieme dei numeri interi dispari tra 0 e 20:\"\n\nprint(S_complement)\n\n [1]  1  3  5  7  9 11 13 15 17 19\n\n\n\nprint(\"È l'unione di S e S_complement uguale a tutti i numeri interi tra 0 e 20?\")\n\n[1] \"È l'unione di S e S_complement uguale a tutti i numeri interi tra 0 e 20?\"\n\nprint(setequal(union(S, S_complement), 0:20))\n\n[1] TRUE\n\n\nDifferenza tra insiemi.\n\nS1 &lt;- seq(0, 30, by = 3)\nS2 &lt;- seq(0, 30, by = 5)\nprint(\"Differenza tra S2 e S1:\")\n\n[1] \"Differenza tra S2 e S1:\"\n\nprint(setdiff(S2, S1))\n\n[1]  5 10 20 25\n\nprint(\"Differenza tra S1 e S2:\")\n\n[1] \"Differenza tra S1 e S2:\"\n\nprint(setdiff(S1, S2))\n\n[1]  3  6  9 12 18 21 24 27\n\n\nDifferenza simmetrica. La differenza simmetrica, indicata con il simbolo Δ, è un’operazione insiemistica definita come unione tra la differenza tra il primo e il secondo insieme e la differenza tra il secondo e il primo insieme. In modo equivalente, la differenza simmetrica equivale all’unione tra i due insiemi meno la loro intersezione.\n\nsym_diff &lt;- union(setdiff(S1, S2), setdiff(S2, S1))\nprint(\"Differenza simmetrica:\")\n\n[1] \"Differenza simmetrica:\"\n\nprint(sym_diff)\n\n [1]  3  6  9 12 18 21 24 27  5 10 20 25",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#coppie-ordinate-e-prodotto-cartesiano",
    "href": "chapters/appendix/a13_sets.html#coppie-ordinate-e-prodotto-cartesiano",
    "title": "Appendice G — Insiemi",
    "section": "\nG.5 Coppie ordinate e prodotto cartesiano",
    "text": "G.5 Coppie ordinate e prodotto cartesiano\nUna coppia ordinata \\((x,y)\\) è l’insieme i cui elementi sono \\(x \\in A\\) e \\(y \\in B\\) e nella quale \\(x\\) è la prima componente (o prima coordinata) e \\(y\\) la seconda. L’insieme di tutte le coppie ordinate costruite a partire dagli insiemi \\(A\\) e \\(B\\) viene detto prodotto cartesiano:\n\\[\nA \\times B = \\{(x, y) ~\\vert~ x \\in A \\land y \\in B\\}.\n\\]\nAd esempio, sia \\(A = \\{1, 2, 3\\}\\) e \\(B = \\{a, b\\}\\). Allora,\n\\[\n\\{1, 2\\} \\times \\{a, b, c\\} = \\{(1, a), (1, b), (1, c), (2, a), (2, b), (2, c)\\}.\n\\]\nPiù in generale, un prodotto cartesiano di \\(n\\) insiemi può essere rappresentato da un array di \\(n\\) dimensioni, dove ogni elemento è una ennupla o tupla ordinata (ovvero, una collezione o un elenco ordinato di \\(n\\) oggetti). Una n-pla ordinata si distingue da un insieme di \\(n\\) elementi in quanto fra gli elementi di un insieme non è dato alcun ordine. Inoltre gli elementi di una ennupla possono anche essere ripetuti. Essendo la n-pla un elenco ordinato, in generale di ogni suo elemento è possibile dire se sia il primo, il secondo, il terzo, eccetera, fino all’n-esimo. Il prodotto cartesiano prende il nome da René Descartes la cui formulazione della geometria analitica ha dato origine al concetto.\n\nA &lt;- c(\"a\", \"b\", \"c\")\nS &lt;- 1:3\ncartesian_product &lt;- expand.grid(A, S)\nprint(\"Prodotto cartesiano di A e S:\")\n\n[1] \"Prodotto cartesiano di A e S:\"\n\nprint(cartesian_product)\n\n  Var1 Var2\n1    a    1\n2    b    1\n3    c    1\n4    a    2\n5    b    2\n6    c    2\n7    a    3\n8    b    3\n9    c    3\n\n\nSi definisce cardinalità (o potenza) di un insieme finito il numero degli elementi dell’insieme. Viene indicata con \\(\\vert A\\vert, \\#(A)\\) o \\(\\text{c}(A)\\).\n\nprint(\"La cardinalità dell'insieme prodotto cartesiano è:\")\n\n[1] \"La cardinalità dell'insieme prodotto cartesiano è:\"\n\nprint(nrow(cartesian_product))\n\n[1] 9\n\n\nPotenza del prodotto cartesiano\n\nA &lt;- c(\"Head\", \"Tail\")\np2 &lt;- expand.grid(A, A)\nprint(\"Il quadrato dell'insieme A è un insieme che contiene:\")\n\n[1] \"Il quadrato dell'insieme A è un insieme che contiene:\"\n\nprint(nrow(p2))\n\n[1] 4\n\nprint(p2)\n\n  Var1 Var2\n1 Head Head\n2 Tail Head\n3 Head Tail\n4 Tail Tail\n\n\n\np3 &lt;- expand.grid(A, A, A)\nprint(\"L'insieme A elevato alla terza potenza è costituito da:\")\n\n[1] \"L'insieme A elevato alla terza potenza è costituito da:\"\n\nprint(nrow(p3))\n\n[1] 8\n\nprint(p3)\n\n  Var1 Var2 Var3\n1 Head Head Head\n2 Tail Head Head\n3 Head Tail Head\n4 Tail Tail Head\n5 Head Head Tail\n6 Tail Head Tail\n7 Head Tail Tail\n8 Tail Tail Tail",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html",
    "href": "chapters/appendix/a14_combinatorics.html",
    "title": "Appendice H — Calcolo combinatorio",
    "section": "",
    "text": "H.1 Principio della somma\nIl calcolo combinatorio studia il numero di modi in cui è possibile combinare, ordinare o disporre elementi appartenenti a uno o più insiemi, seguendo regole ben definite. Molti problemi di probabilità richiedono strumenti combinatori per determinare la probabilità di eventi complessi. In questo capitolo, esploreremo i concetti fondamentali del calcolo combinatorio, illustrandoli attraverso il modello del campionamento dall’urna. Tratteremo i principi della somma e del prodotto, fondamentali per affrontare problemi più avanzati, come permutazioni, disposizioni e combinazioni.\nIl principio della somma si applica quando un insieme di elementi può essere suddiviso in sottoinsiemi disgiunti (ossia senza sovrapposizioni). In questo caso, il numero totale di elementi è dato dalla somma delle cardinalità dei sottoinsiemi:\n\\[\nn_{\\text{tot}} = n_1 + n_2 + \\dots + n_k .\n\\]\nEsempio\nUn distributore contiene tre scomparti di caramelle, ciascuno con un diverso tipo di dolci:\nQuante caramelle ci sono in totale nel distributore?\nSecondo il principio della somma, il numero totale di caramelle è:\n\\[\nn_{\\text{tot}} = n_A + n_B + n_C = 10 + 8 + 12 = 30.\n\\]\nCalcolo in R:\nA &lt;- 10\nB &lt;- 8\nC &lt;- 12\n\ntotale_caramelle &lt;- A + B + C\ntotale_caramelle\n#&gt; [1] 30\nRisultato: Nel distributore ci sono 30 caramelle in totale.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#principio-della-somma",
    "href": "chapters/appendix/a14_combinatorics.html#principio-della-somma",
    "title": "Appendice H — Calcolo combinatorio",
    "section": "",
    "text": "Scomparto A: 10 caramelle alla menta,\n\n\nScomparto B: 8 caramelle alla frutta,\n\n\nScomparto C: 12 caramelle al cioccolato.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#principio-del-prodotto",
    "href": "chapters/appendix/a14_combinatorics.html#principio-del-prodotto",
    "title": "Appendice H — Calcolo combinatorio",
    "section": "\nH.2 Principio del prodotto",
    "text": "H.2 Principio del prodotto\nIl principio del prodotto si applica quando un’operazione può essere suddivisa in più fasi indipendenti, ciascuna con un numero specifico di possibilità. In tal caso, il numero totale di combinazioni è dato dal prodotto delle possibilità offerte da ciascuna fase:\n\\[\nn_{\\text{tot}} = n_1 \\cdot n_2 \\cdot \\dots \\cdot n_k .\n\\]\nEsempio\nSupponiamo di avere quattro urne contenenti palline di diverso colore:\n\n\nUrna A: 5 palline,\n\n\nUrna B: 6 palline,\n\n\nUrna C: 3 palline,\n\n\nUrna D: 2 palline.\n\nVogliamo formare insiemi di due palline, ciascuna estratta da urne differenti.\nSecondo il principio del prodotto, per ogni coppia di urne, il numero di combinazioni è dato dal prodotto del numero di palline contenute nelle due urne. Utilizziamo poi il principio della somma per ottenere il totale complessivo:\n\\[\nn_{\\text{tot}} = AB + AC + AD + BC + BD + CD.\n\\]\nCalcolo in R:\n\nAB &lt;- 5 * 6\nAC &lt;- 5 * 3\nAD &lt;- 5 * 2\nBC &lt;- 6 * 3\nBD &lt;- 6 * 2\nCD &lt;- 3 * 2\n\ntotale_insiemi &lt;- AB + AC + AD + BC + BD + CD\ntotale_insiemi\n#&gt; [1] 91\n\nRisultato: È possibile formare 91 insiemi di due palline, ciascuna estratta da urne differenti.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#il-modello-dellurna-e-i-metodi-di-campionamento",
    "href": "chapters/appendix/a14_combinatorics.html#il-modello-dellurna-e-i-metodi-di-campionamento",
    "title": "Appendice H — Calcolo combinatorio",
    "section": "\nH.3 Il modello dell’urna e i metodi di campionamento",
    "text": "H.3 Il modello dell’urna e i metodi di campionamento\nMolti problemi di calcolo combinatorio possono essere interpretati come estrazioni di palline da un’urna. Esistono quattro modi fondamentali di effettuare un campionamento, a seconda che:\n\nle estrazioni siano con o senza ripetizione,\nl’ordine degli elementi conti o meno.\n\nQueste quattro combinazioni danno origine a quattro principali metodi di campionamento:\n\n\nCon ripetizione e con ordine: Dopo ogni estrazione, la pallina viene rimessa nell’urna. (Es. formazione di codici numerici con ripetizioni)\n\nSenza ripetizione e con ordine: Ogni estrazione rimuove definitivamente la pallina dall’urna. (Es. assegnare premi in una gara)\n\nCon ripetizione e senza ordine: Si considerano i gruppi di elementi senza preoccuparsi dell’ordine. (Es. selezionare un certo numero di ingredienti da una dispensa)\n\nSenza ripetizione e senza ordine: Si scelgono elementi distinti senza considerare l’ordine. (Es. formare squadre da un gruppo di persone)\n\n\nEsempio H.1  \n\nurna &lt;- c(\"a\", \"b\", \"c\")\n\n# Con ripetizione e ordine\ncampionamento1 &lt;- expand.grid(urna, urna) |&gt;\n    rename(Elemento1 = Var1, Elemento2 = Var2)\n\n# Senza ripetizione e con ordine\ncampionamento2 &lt;- permutations(n = length(urna), r = 2, v = urna) |&gt;\n    as.data.frame() |&gt;\n    rename(Elemento1 = V1, Elemento2 = V2)\n\n# Con ripetizione e senza ordine\ncampionamento3 &lt;- combinations(\n    n = length(urna), r = 2, v = urna, repeats.allowed = TRUE\n) |&gt;\n    as.data.frame() |&gt;\n    rename(Elemento1 = V1, Elemento2 = V2)\n\n# Senza ripetizione e senza ordine\ncampionamento4 &lt;- combinations(n = length(urna), r = 2, v = urna) |&gt;\n    as.data.frame() |&gt;\n    rename(Elemento1 = V1, Elemento2 = V2)\n\n# Risultati\nlist(\n    `Con ripetizione e ordine` = campionamento1,\n    `Senza ripetizione e con ordine` = campionamento2,\n    `Con ripetizione e senza ordine` = campionamento3,\n    `Senza ripetizione e senza ordine` = campionamento4\n)\n#&gt; $`Con ripetizione e ordine`\n#&gt;   Elemento1 Elemento2\n#&gt; 1         a         a\n#&gt; 2         b         a\n#&gt; 3         c         a\n#&gt; 4         a         b\n#&gt; 5         b         b\n#&gt; 6         c         b\n#&gt; 7         a         c\n#&gt; 8         b         c\n#&gt; 9         c         c\n#&gt; \n#&gt; $`Senza ripetizione e con ordine`\n#&gt;   Elemento1 Elemento2\n#&gt; 1         a         b\n#&gt; 2         a         c\n#&gt; 3         b         a\n#&gt; 4         b         c\n#&gt; 5         c         a\n#&gt; 6         c         b\n#&gt; \n#&gt; $`Con ripetizione e senza ordine`\n#&gt;   Elemento1 Elemento2\n#&gt; 1         a         a\n#&gt; 2         a         b\n#&gt; 3         a         c\n#&gt; 4         b         b\n#&gt; 5         b         c\n#&gt; 6         c         c\n#&gt; \n#&gt; $`Senza ripetizione e senza ordine`\n#&gt;   Elemento1 Elemento2\n#&gt; 1         a         b\n#&gt; 2         a         c\n#&gt; 3         b         c",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#permutazioni-disporre-tutti-gli-elementi-con-ordine",
    "href": "chapters/appendix/a14_combinatorics.html#permutazioni-disporre-tutti-gli-elementi-con-ordine",
    "title": "Appendice H — Calcolo combinatorio",
    "section": "\nH.4 Permutazioni: Disporre tutti gli elementi con ordine",
    "text": "H.4 Permutazioni: Disporre tutti gli elementi con ordine\nLe permutazioni rappresentano tutti i modi in cui è possibile ordinare \\(n\\) elementi distinti. Il numero di permutazioni è dato da:\n\\[\nP_n = n!\n\\]\ndove \\(n!\\) (n fattoriale) è il prodotto di tutti i numeri da 1 a \\(n\\):\n\\[\nn! = n \\cdot (n-1) \\cdot (n-2) \\cdot \\dots \\cdot 1.\n\\]\n\nH.4.1 Intuizione della formula\nImmaginiamo di avere \\(n\\) elementi distinti e di doverli disporre in una sequenza. Il primo elemento può essere scelto in \\(n\\) modi. Una volta scelto il primo, rimangono \\(n-1\\) possibilità per il secondo, poi \\(n-2\\) per il terzo e così via, fino all’ultimo elemento, che avrà 1 sola possibilità. Applicando il principio del prodotto, otteniamo:\n\\[\nP_n = n \\times (n-1) \\times (n-2) \\times \\dots \\times 1 = n!\n\\]\n\nH.4.2 Metodo di campionamento corrispondente\n\n\nCampionamento senza ripetizione e con ordine: si estrae una pallina, la si esclude dall’urna e si continua fino a esaurire gli elementi.\n\n\nEsempio pratico: Ordinare i partecipanti di una gara su un podio (primo, secondo e terzo classificato).\n\nH.4.3 Esempio in R: Permutazioni di tre elementi\nSe abbiamo tre lettere {a, b, c}, le possibili permutazioni sono:\n\\[\nP_3 = 3! = 3 \\times 2 \\times 1 = 6.\n\\]\n\nA &lt;- c(\"a\", \"b\", \"c\")\nperm &lt;- permutations(n = length(A), r = length(A), v = A)\nprint(perm)\n#&gt;      [,1] [,2] [,3]\n#&gt; [1,] \"a\"  \"b\"  \"c\" \n#&gt; [2,] \"a\"  \"c\"  \"b\" \n#&gt; [3,] \"b\"  \"a\"  \"c\" \n#&gt; [4,] \"b\"  \"c\"  \"a\" \n#&gt; [5,] \"c\"  \"a\"  \"b\" \n#&gt; [6,] \"c\"  \"b\"  \"a\"\nnrow(perm)  # Verifica del numero di permutazioni\n#&gt; [1] 6\n\nRisultato:\n\\[\n\\{a, b, c\\}, \\{a, c, b\\}, \\{b, a, c\\}, \\{b, c, a\\}, \\{c, a, b\\}, \\{c, b, a\\}.\n\\]",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#disposizioni-selezionare-alcuni-elementi-con-ordine",
    "href": "chapters/appendix/a14_combinatorics.html#disposizioni-selezionare-alcuni-elementi-con-ordine",
    "title": "Appendice H — Calcolo combinatorio",
    "section": "\nH.5 Disposizioni: Selezionare alcuni elementi con ordine",
    "text": "H.5 Disposizioni: Selezionare alcuni elementi con ordine\nLe disposizioni si usano quando si scelgono \\(k\\) elementi da un insieme di \\(n\\), rispettando l’ordine. Il numero totale di disposizioni è:\n\\[\nD_{n,k} = \\frac{n!}{(n-k)!} .\n\\]\n\nH.5.1 Intuizione della formula\nSupponiamo di avere \\(n\\) elementi e di voler scegliere solo \\(k\\) elementi, mantenendo l’ordine.\n\nil primo elemento può essere scelto in \\(n\\) modi;\nil secondo elemento può essere scelto tra gli \\(n-1\\) elementi rimanenti;\n\nil terzo tra gli \\(n-2\\) rimanenti.\n\nSi prosegue fino a quando si hanno scelto \\(k\\) elementi, fermandosi prima di esaurire tutti gli elementi.\n\\[\nD_{n,k} = n \\times (n-1) \\times (n-2) \\times \\dots \\times (n-k+1) .\n\\]\nQuesta espressione corrisponde alla divisione del fattoriale di \\(n\\) per il fattoriale degli elementi che non vengono selezionati:\n\\[\nD_{n,k} = \\frac{n!}{(n-k)!} .\n\\]\n\nH.5.2 Metodo di campionamento corrispondente\n\n\nCampionamento senza ripetizione e con ordine: si estrae una pallina, la si esclude dall’urna e si continua fino a raggiungere il numero desiderato di elementi, fermandosi prima di esaurire tutti gli elementi.\n\n\nEsempio pratico: Estrarre casualmente 2 studenti da una classe di 10 e assegnare loro i ruoli di rappresentante e vice-rappresentante (l’ordine conta).\n\nH.5.3 Esempio in R: Disposizioni di 2 elementi da {a, b, c}\nSe scegliamo 2 lettere su 3, il numero di disposizioni è:\n\\[\nD_{3,2} = \\frac{3!}{(3-2)!} = \\frac{3 \\times 2 \\times 1}{1} = 6.\n\\]\n\ndisp &lt;- permutations(n = length(A), r = 2, v = A)\nprint(disp)\n#&gt;      [,1] [,2]\n#&gt; [1,] \"a\"  \"b\" \n#&gt; [2,] \"a\"  \"c\" \n#&gt; [3,] \"b\"  \"a\" \n#&gt; [4,] \"b\"  \"c\" \n#&gt; [5,] \"c\"  \"a\" \n#&gt; [6,] \"c\"  \"b\"\nnrow(disp)  # Verifica del numero di disposizioni\n#&gt; [1] 6\n\nRisultato:\n\\[\n\\{a, b\\}, \\{a, c\\}, \\{b, a\\}, \\{b, c\\}, \\{c, a\\}, \\{c, b\\}.\n\\]\nLe disposizioni considerano l’ordine, quindi \\(\\{a, b\\}\\) è diverso da \\(\\{b, a\\}\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#combinazioni-selezionare-alcuni-elementi-senza-ordine",
    "href": "chapters/appendix/a14_combinatorics.html#combinazioni-selezionare-alcuni-elementi-senza-ordine",
    "title": "Appendice H — Calcolo combinatorio",
    "section": "\nH.6 Combinazioni: Selezionare alcuni elementi senza ordine",
    "text": "H.6 Combinazioni: Selezionare alcuni elementi senza ordine\nLe combinazioni rappresentano il numero di modi per scegliere \\(k\\) elementi da \\(n\\) senza considerare l’ordine. Il numero di combinazioni è dato da:\n\\[\nC_{n,k} = \\binom{n}{k} = \\frac{n!}{k!(n-k)!} .\n\\]\n\nH.6.1 Intuizione della formula\nSupponiamo di avere \\(n\\) elementi e di voler selezionare \\(k\\) elementi senza considerare l’ordine.\nCome nel caso delle disposizioni, il primo elemento può essere scelto in \\(n\\) modi, il secondo in \\(n-1\\), e così via fino a selezionare \\(k\\) elementi.\n\\[\nD_{n,k} = n \\times (n-1) \\times \\dots \\times (n-k+1) .\n\\]\nTuttavia, in questo caso, l’ordine non conta, quindi ogni selezione viene duplicata per il numero di modi in cui i \\(k\\) elementi possono essere ordinati, ossia \\(k!\\) permutazioni interne. Per correggere questa duplicazione, dobbiamo dividere per \\(k!\\):\n\\[\nC_{n,k} = \\frac{D_{n,k}}{k!} = \\frac{n!}{k!(n-k)!} .\n\\]\n\nH.6.2 Metodo di campionamento corrispondente\n\n\nCampionamento senza ripetizione e senza ordine: si estrae una pallina e la si esclude dall’urna, ma non importa l’ordine in cui le palline vengono estratte.\n\n\nEsempio pratico: Formare una squadra di 2 studenti da un gruppo di 10 senza assegnare ruoli specifici (quindi \\(\\{a, b\\}\\) è uguale a \\(\\{b, a\\}\\)).\n\nH.6.3 Esempio in R: Combinazioni di 2 elementi da {a, b, c}\nSe scegliamo 2 lettere su 3 senza considerare l’ordine, otteniamo:\n\\[\nC_{3,2} = \\binom{3}{2} = \\frac{3!}{2!(3-2)!} = \\frac{3 \\times 2 \\times 1}{2 \\times 1 \\times 1} = 3.\n\\]\n\ncomb &lt;- combinations(n = length(A), r = 2, v = A)\nprint(comb)\n#&gt;      [,1] [,2]\n#&gt; [1,] \"a\"  \"b\" \n#&gt; [2,] \"a\"  \"c\" \n#&gt; [3,] \"b\"  \"c\"\nnrow(comb)  # Verifica del numero di combinazioni\n#&gt; [1] 3\n\nRisultato:\n\\[\n\\{a, b\\}, \\{a, c\\}, \\{b, c\\}.\n\\]\nLe combinazioni non considerano l’ordine, quindi \\(\\{a, b\\}\\) è uguale a \\(\\{b, a\\}\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#sintesi-quando-usare-ciascun-metodo",
    "href": "chapters/appendix/a14_combinatorics.html#sintesi-quando-usare-ciascun-metodo",
    "title": "Appendice H — Calcolo combinatorio",
    "section": "\nH.7 Sintesi: Quando usare ciascun metodo?",
    "text": "H.7 Sintesi: Quando usare ciascun metodo?\n\n\n\n\n\n\n\n\n\nMetodo\nRipetizione?\nOrdine?\nFormula\nMetodo di campionamento\n\n\n\nPermutazioni\n❌ No\n✅ Sì\n\\(n!\\)\nSenza ripetizione e con ordine\n\n\nDisposizioni\n❌ No\n✅ Sì\n\\(\\frac{n!}{(n-k)!}\\)\nSenza ripetizione e con ordine\n\n\nCombinazioni\n❌ No\n❌ No\n\\(\\binom{n}{k} = \\frac{n!}{k!(n-k)!}\\)\nSenza ripetizione e senza ordine\n\n\n\nIn conclusione, abbiamo visto come il modello dell’urna aiuti a comprendere i problemi combinatori. Le differenze tra permutazioni, disposizioni e combinazioni dipendono da due fattori fondamentali: ripetizione e ordine.\nQuesta classificazione è essenziale per risolvere problemi di probabilità e statistica in modo rigoroso. Gli esempi e il codice R forniscono strumenti concreti per applicare questi concetti nella pratica.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a15_calculus.html",
    "href": "chapters/appendix/a15_calculus.html",
    "title": "Appendice I — Per liberarvi dai terrori preliminari",
    "section": "",
    "text": "I.1 Integrali\nIn questo capitolo, traduciamo e adattiamo il capitolo Per liberarvi dai terrori preliminari tratto da Calculus made easy.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>I</span>  <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a15_calculus.html#integrali",
    "href": "chapters/appendix/a15_calculus.html#integrali",
    "title": "Appendice I — Per liberarvi dai terrori preliminari",
    "section": "",
    "text": "Il terrore preliminare, che spesso impedisce agli studenti di avvicinarsi all’analisi matematica, può essere superato comprendendo il significato intuitivo dei due simboli principali utilizzati in questo campo.\nQuesti simboli, che possono sembrare intimidatori, sono in realtà molto semplici:\n\n\\(d\\): Questo simbolo significa semplicemente “un po’ di”. Ad esempio, \\(\\operatorname{d}\\!x\\) indica un piccolo incremento di \\(x\\), mentre \\(\\operatorname{d}\\!u\\) rappresenta un piccolo incremento di \\(u\\). I matematici preferiscono dire “un elemento di” invece di “un po’ di”, ma il concetto è lo stesso. Questi piccoli incrementi possono essere considerati infinitamente piccoli.\n\\(\\int\\): Questo simbolo è una S allungata e rappresenta “la somma di”. Quindi, \\(\\int \\operatorname{d}\\!x\\) significa la somma di tutti i piccoli incrementi di \\(x\\), mentre \\(\\int \\operatorname{d}\\!t\\) indica la somma di tutti i piccoli incrementi di \\(t\\). I matematici chiamano questo simbolo “integrale”. Se consideri \\(x\\) come composto da tanti piccoli pezzi \\(\\operatorname{d}\\!x\\), sommandoli tutti otterrai l’intero valore di \\(x\\). La parola “integrale” significa semplicemente “il tutto”. Ad esempio, se pensi a un’ora come composta da 3600 secondi, la somma di tutti questi secondi ti darà un’ora. Quando vedi un’espressione che inizia con \\(\\int\\), significa che devi sommare tutti i piccoli pezzi indicati dai simboli che seguono.\n\nEcco, il terrore è svanito!\n\n\n\n\nI.1.1 Verifica con Simulazioni in R\nPer calcolare e visualizzare l’integrale di una funzione di densità, possiamo utilizzare il linguaggio di programmazione R. Consideriamo come esempio la funzione di densità gaussiana, definita dalla seguente formula:\n\\[\nf(x; \\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{-\\frac{(x - \\mu)^2}{2 \\sigma^2}}.\n\\]\nIn R, possiamo definire questa funzione come segue:\n\ngaussian &lt;- function(x, mu, sigma) {\n  1 / (sigma * sqrt(2 * pi)) * exp(-((x - mu)^2) / (2 * sigma^2))\n}\n\nDefiniamo i parametri e generiamo i valori per il calcolo della funzione di densità su un intervallo:\n\nmu &lt;- 0      # Media\nsigma &lt;- 1   # Deviazione standard\na &lt;- -10     # Limite inferiore\nb &lt;- 10      # Limite superiore\nn &lt;- 10000   # Numero di punti\n\nx_range &lt;- seq(a, b, length.out = n)  # Valori x\nfx &lt;- gaussian(x_range, mu, sigma)   # Ordinata della funzione\n\nVisualizziamo la funzione utilizzando il pacchetto ggplot2:\n\nlibrary(ggplot2)\nlibrary(scales)\n\nggplot(data.frame(x = x_range, fx = fx), aes(x, fx)) +\n  geom_line(color = \"blue\") +\n  labs(\n    title = \"Funzione di densità gaussiana\", \n    x = \"x\", \n    y = \"f(x)\"\n  )\n\n\n\n\n\n\n\nCreiamo una funzione per approssimare l’integrale sommando i prodotti \\(\\Delta x \\cdot f(x)\\):\n\nintegral_approximation &lt;- function(f, a, b, n) {\n  delta &lt;- (b - a) / n\n  sum(delta * f)\n}\n\n# Calcolo dell'integrale approssimato\napprox &lt;- integral_approximation(fx, a, b, n)\napprox\n\n[1] 0.9999\n\n\nConfrontiamo il risultato con il calcolo fornito dalla funzione integrate di R:\n\nintegrate(\n  function(x) gaussian(x, mu, sigma),\n  lower = a,\n  upper = b\n)\n\n1 with absolute error &lt; 7.4e-05\n\n\nCalcoliamo l’area sotto la curva in intervalli di interesse. Ad esempio, per \\([-1.96, 1.96]\\), che corrisponde al 95% dell’area nella distribuzione normale standard:\n\na &lt;- -1.96\nb &lt;- 1.96\nx_range &lt;- seq(a, b, length.out = n)\nfx &lt;- gaussian(x_range, mu, sigma)\n\napprox &lt;- integral_approximation(fx, a, b, n)\napprox\n\n[1] 0.9499321\n\n\nConfrontiamo con il risultato fornito da integrate():\n\nintegrate(\n  function(x) gaussian(x, mu, sigma),\n  lower = a,\n  upper = b\n)\n\n0.9500042 with absolute error &lt; 1e-11\n\n\nVerifichiamo l’area sotto la curva per \\([-1, 1]\\), che rappresenta circa il 68% dell’area totale:\n\na &lt;- -1.0\nb &lt;- 1.0\nx_range &lt;- seq(a, b, length.out = n)\nfx &lt;- gaussian(x_range, mu, sigma)\n\napprox &lt;- integral_approximation(fx, a, b, n)\napprox\n\n[1] 0.6826696\n\n\nConfronto:\n\nintegrate(\n  function(x) gaussian(x, mu, sigma),\n  lower = a,\n  upper = b\n)\n\n0.6826895 with absolute error &lt; 7.6e-15\n\n\nIn sintesi, questo approccio dimostra come calcolare l’integrale di una funzione di densità in un intervallo utilizzando sia un metodo approssimativo basato sulla somma dei rettangoli sia il metodo numerico integrato. In entrambi i casi, l’obiettivo è calcolare l’area sotto la curva, che corrisponde all’integrale della funzione di densità.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>I</span>  <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a15_calculus.html#potenze",
    "href": "chapters/appendix/a15_calculus.html#potenze",
    "title": "Appendice I — Per liberarvi dai terrori preliminari",
    "section": "\nI.2 Potenze",
    "text": "I.2 Potenze\nLe potenze sono un’operazione matematica che rappresenta un prodotto ripetuto. Si indicano generalmente come:\n\\[\na^n,\n\\]\ndove:\n\n\n\\(a\\) è la base,\n\n\\(n\\) è l’esponente.\n\nLa potenza rappresenta il prodotto della base \\(a\\) ripetuto \\(n\\) volte.\n\nI.2.1 Definizione di potenza\n\\[\na^n = \\underbrace{a \\cdot a \\cdot \\dots \\cdot a}_{n \\text{ fattori}} \\quad \\text{con } n \\in \\mathbb{N}.\n\\]\nAd esempio:\n\n\n\\(2^3 = 2 \\cdot 2 \\cdot 2 = 8\\),\n\n\\(3^4 = 3 \\cdot 3 \\cdot 3 \\cdot 3 = 81\\).\n\n\nI.2.2 Proprietà delle potenze\n\n\nMoltiplicazione di potenze con la stessa base:\n\\[\na^m \\cdot a^n = a^{m+n}\n\\]\nEsempio: \\(2^3 \\cdot 2^2 = 2^{3+2} = 2^5 = 32\\).\n\n\nDivisione di potenze con la stessa base:\n\\[\n\\frac{a^m}{a^n} = a^{m-n}, \\quad \\text{con } m \\geq n.\n\\]\nEsempio: \\(\\frac{5^4}{5^2} = 5^{4-2} = 5^2 = 25\\).\n\n\nPotenze di potenze:\n\\[\n(a^m)^n = a^{m \\cdot n}.\n\\]\nEsempio: \\((3^2)^3 = 3^{2 \\cdot 3} = 3^6 = 729\\).\n\n\nProdotto di potenze con basi diverse ma lo stesso esponente:\n\\[\na^n \\cdot b^n = (a \\cdot b)^n.\n\\]\nEsempio: \\(2^3 \\cdot 3^3 = (2 \\cdot 3)^3 = 6^3 = 216\\).\n\n\nDivisione di potenze con basi diverse ma lo stesso esponente:\n\\[\n\\frac{a^n}{b^n} = \\left(\\frac{a}{b}\\right)^n.\n\\]\nEsempio: \\(\\frac{4^2}{2^2} = \\left(\\frac{4}{2}\\right)^2 = 2^2 = 4\\).\n\n\nEsponente zero:\n\\[\na^0 = 1, \\quad \\text{con } a \\neq 0.\n\\]\nEsempio: \\(5^0 = 1\\).\n\n\nEsponente negativo:\n\\[\na^{-n} = \\frac{1}{a^n}.\n\\]\nEsempio: \\(2^{-3} = \\frac{1}{2^3} = \\frac{1}{8}\\).\n\n\nRadice come potenza frazionaria:\n\\[\na^{\\frac{1}{n}} = \\sqrt[n]{a}, \\quad a^{\\frac{m}{n}} = \\sqrt[n]{a^m}.\n\\]\nEsempio: \\(8^{\\frac{1}{3}} = \\sqrt[3]{8} = 2\\).\n\n\n\nI.2.3 Esempi pratici\n\n\nCalcolo semplice:\n\\[\n4^3 = 4 \\cdot 4 \\cdot 4 = 64.\n\\]\n\n\nUtilizzo delle proprietà:\n\\[\n3^5 \\cdot 3^2 = 3^{5+2} = 3^7 = 2187.\n\\]\n\n\nDivisione:\n\\[\n\\frac{6^4}{6^2} = 6^{4-2} = 6^2 = 36.\n\\]\n\n\nEsponente negativo:\n\\[\n10^{-2} = \\frac{1}{10^2} = \\frac{1}{100} = 0.01.\n\\]\n\n\nRadice come potenza:\n\\[\n16^{\\frac{1}{2}} = \\sqrt{16} = 4.\n\\]\n\n\n\nI.2.4 Nota sui numeri razionali e reali\n\nLe potenze con esponenti interi sono definite per ogni base.\nLe potenze con esponenti frazionari o reali richiedono che la base sia positiva per evitare ambiguità.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>I</span>  <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a15_calculus.html#logaritmi",
    "href": "chapters/appendix/a15_calculus.html#logaritmi",
    "title": "Appendice I — Per liberarvi dai terrori preliminari",
    "section": "\nI.3 Logaritmi",
    "text": "I.3 Logaritmi\nIl logaritmo è una funzione matematica che risponde alla domanda: “quante volte devo moltiplicare un certo numero (chiamato”base”) per ottenere un altro numero?” Matematicamente, questo è espresso come:\n\\[\n\\log_b(a) = x \\iff b^x = a\n\\]\nAd esempio, \\(\\log_2(8) = 3\\) perché \\(2^3 = 8\\).\nNel contesto dei logaritmi, i valori molto piccoli (compresi tra 0 e 1) diventano più grandi (in termini assoluti) e negativi quando applichiamo una funzione logaritmica. Questo è utile per stabilizzare i calcoli, specialmente quando lavoriamo con prodotti di numeri molto piccoli che potrebbero portare a problemi di underflow.\nPer esempio:\n\n\\(\\log(1) = 0\\)\n\\(\\log(0.1) = -1\\)\n\\(\\log(0.01) = -2\\)\n\\(\\log(0.001) = -3\\)\n\nCome si può vedere, i valori assoluti dei logaritmi crescono man mano che il numero originale si avvicina a zero.\nUna delle proprietà più utili dei logaritmi è che consentono di trasformare un prodotto in una somma:\n\\[\n\\log_b(a \\times c) = \\log_b(a) + \\log_b(c)\n\\]\nQuesta proprietà è estremamente utile in calcoli complessi, come nella statistica bayesiana, dove il prodotto di molte probabilità potrebbe diventare un numero molto piccolo e causare problemi numerici.\nUn’altra proprietà utile dei logaritmi è che un rapporto tra due numeri diventa la differenza dei loro logaritmi:\n\\[\n\\log_b\\left(\\frac{a}{c}\\right) = \\log_b(a) - \\log_b(c)\n\\]\nAnche questa proprietà è molto utilizzata in matematica, specialmente in situazioni in cui è necessario normalizzare i dati.\nIn sintesi, i logaritmi sono strumenti potenti per semplificare e stabilizzare i calcoli matematici. Essi consentono di lavorare più agevolmente con numeri molto grandi o molto piccoli e di trasformare operazioni complesse come prodotti e divisioni in somme e differenze, rendendo i calcoli più gestibili e meno inclini a errori numerici.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>I</span>  <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a47_first_order_markov.html",
    "href": "chapters/appendix/a47_first_order_markov.html",
    "title": "Appendice J — Catene di Markov",
    "section": "",
    "text": "J.1 Classificazione degli Stati\nIl processo di Markov di primo ordine è un concetto fondamentale in molti campi, tra cui l’intelligenza artificiale, la statistica e la teoria delle probabilità. Questo modello probabilistico rappresenta un equilibrio tra la semplicità delle variabili casuali indipendenti e la complessità delle interazioni tra variabili. Per chiarire il concetto, consideriamo una sequenza temporale di eventi rappresentata da variabili casuali \\(X_0, X_1, ..., X_n, ...\\). In molti fenomeni reali, queste variabili non sono né completamente indipendenti né totalmente interdipendenti. Una catena di Markov rappresenta un compromesso tra questi due estremi.\nIn questo contesto, ci concentreremo su catene di Markov con stati discreti e tempo discreto. Ciò significa che le variabili \\(X_n\\) possono assumere valori in un insieme finito, tipicamente indicato come \\(\\{1, 2, ..., M\\}\\), e che gli eventi si verificano in momenti distinti e numerabili. La proprietà fondamentale di una catena di Markov può essere espressa matematicamente con la seguente equazione:\n\\[\nP(X_{n+1} = j | X_n = i, X_{n-1} = i_{n-1}, ..., X_0 = i_0) = P(X_{n+1} = j | X_n = i).\n\\]\nQuesta equazione indica che il futuro (rappresentato da \\(X_{n+1}\\)) dipende solo dal presente (\\(X_n\\)) e non dal passato (\\(X_{n-1}, ..., X_0\\)). La proprietà di Markov può essere vista come un primo allentamento dell’assunzione di indipendenza: le variabili casuali sono dipendenti in un modo specifico che risulta matematicamente conveniente.\nQuantità importanti associate a una catena di Markov sono le probabilità condizionate, chiamate probabilità di transizione:\n\\[\nP(X_{n+1} = j \\mid X_n = i).\n\\]\nLa probabilità \\(P(X_{n+1} = j \\mid X_n = i)\\), nota come probabilità di transizione, rappresenta la probabilità di passare dallo stato \\(i\\) allo stato \\(j\\) in un singolo passo.\nPer descrivere completamente una catena di Markov, si utilizza una matrice \\(Q\\), chiamata matrice di transizione. Questa è una matrice \\(M \\times M\\) in cui ogni elemento \\(q_{ij}\\) rappresenta la probabilità di transizione dallo stato \\(i\\) allo stato \\(j\\). Un’importante caratteristica della matrice di transizione è che la somma degli elementi di ogni riga deve essere pari a 1, poiché partendo da uno stato qualsiasi, il sistema deve necessariamente transitare in uno degli stati possibili.\nPer chiarire ulteriormente il concetto, consideriamo un modello di previsione del tempo a Firenze con tre possibili condizioni meteorologiche: soleggiato, piovoso e nebbioso. Di seguito è riportata una matrice di transizione che rappresenta le probabilità di passaggio da un tipo di tempo all’altro:\nVediamo come calcolare alcune probabilità:\nIl modello di Markov di base assume che le probabilità di transizione rimangano costanti nel tempo, una proprietà nota come omogeneità temporale. Questo significa che, per esempio, la probabilità di passare dallo stato “soleggiato” allo stato “piovoso” è la stessa in qualsiasi periodo dell’anno.\nIn sintesi, l’utilità del modello di Markov risiede nella sua capacità di semplificare notevolmente i calcoli probabilistici. Invece di considerare l’intera storia passata del sistema, è sufficiente conoscere solo lo stato attuale per fare previsioni sul futuro. Questa caratteristica, nota come “assenza di memoria”, rende il modello estremamente utile in molte applicazioni pratiche, dalla modellazione di fenomeni naturali alla progettazione di algoritmi di apprendimento automatico. Il processo di Markov di primo ordine offre uno strumento potente per analizzare e prevedere il comportamento di sistemi complessi nel tempo, bilanciando la necessità di catturare le dipendenze temporali con la semplicità computazionale. La sua versatilità e applicabilità in diversi campi lo rendono un concetto chiave per comprendere e modellare molti fenomeni del mondo reale.\nConsideriamo ora la terminologia usata per descrivere le varie caratteristiche di una catena di Markov.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>J</span>  <span class='chapter-title'>Catene di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a47_first_order_markov.html#classificazione-degli-stati",
    "href": "chapters/appendix/a47_first_order_markov.html#classificazione-degli-stati",
    "title": "Appendice J — Catene di Markov",
    "section": "",
    "text": "J.1.1 Catene di Markov Irriducibili\nUna catena di Markov è detta irriducibile se, per qualsiasi coppia di stati \\(i\\) e \\(j\\), esiste una probabilità positiva di passare dallo stato \\(i\\) allo stato \\(j\\) in un numero finito di passi. In altre parole, una catena irriducibile non ha stati isolati: ogni stato è raggiungibile da qualsiasi altro stato.\n\n\nJ.1.2 Stati Ricorrenti\nUno stato \\(i\\) di una catena di Markov si dice ricorrente se, partendo da \\(i\\), la probabilità di ritornarvi è uguale a 1. Questo implica che una volta raggiunto lo stato \\(i\\), è garantito che la catena tornerà in \\(i\\) prima o poi. Gli stati ricorrenti possono essere ulteriormente classificati come:\n\nPositivamente ricorrenti: uno stato è positivamente ricorrente se il tempo medio atteso per ritornare in quello stato, partendo da esso, è finito.\nNullamente ricorrenti: uno stato è nullamente ricorrente se il tempo medio atteso per ritornare in quello stato è infinito.\nRicorrenti di Harris: sono stati ricorrenti che vengono visitati infinite volte quando il tempo tende all’infinito, garantendo una certa frequenza di visita.\n\n\n\nJ.1.3 Aperiodicità\nUno stato \\(i\\) si dice aperiodico se il massimo comun divisore dei tempi di ritorno in \\(i\\) è 1. In altre parole, uno stato è aperiodico se non esiste un ciclo deterministico che vincola i tempi in cui la catena può ritornare in quello stato. Una catena di Markov è aperiodica se tutti i suoi stati sono aperiodici. L’aperiodicità evita che la catena rimanga bloccata in una sequenza ciclica fissa, permettendo un comportamento più variegato nel tempo.\n\n\nJ.1.4 Stazionarietà\nNella teoria delle catene di Markov, una distribuzione stazionaria \\(\\pi\\) è una distribuzione di probabilità sugli stati tale che, se la catena parte con questa distribuzione iniziale, la distribuzione delle probabilità rimane invariata nel tempo. Matematicamente, se \\(\\pi\\) è la distribuzione stazionaria, allora \\(\\pi P = \\pi\\), dove \\(P\\) è la matrice di transizione della catena di Markov. La stazionarietà è fondamentale per analizzare il comportamento a lungo termine della catena, poiché una volta raggiunta, la distribuzione di probabilità sugli stati rimane costante.\n\n\nJ.1.5 Ergodicità\nUna catena di Markov si dice ergodica se è irriducibile e aperiodica, e tutti i suoi stati sono positivamente ricorrenti. Questo implica che la catena, nel lungo termine, visita tutti gli stati secondo una distribuzione di probabilità che diventa stabile (stazionaria) e non dipende dallo stato iniziale. La proprietà di ergodicità è cruciale in quanto garantisce che le medie temporali di una funzione sugli stati della catena convergono alle medie rispetto alla distribuzione stazionaria.\n\n\nJ.1.6 Convergenza\nLa convergenza di una catena di Markov si riferisce al processo mediante il quale la distribuzione di probabilità degli stati si avvicina alla distribuzione stazionaria \\(\\pi\\) man mano che il numero di passi \\(n\\) tende all’infinito. In altre parole, indipendentemente dalla distribuzione iniziale degli stati, la distribuzione della catena dopo un lungo periodo di tempo sarà vicina a \\(\\pi\\). Questo concetto è strettamente legato alla stazionarietà, poiché la convergenza descrive il percorso verso l’equilibrio, mentre la stazionarietà rappresenta lo stato di equilibrio raggiunto.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>J</span>  <span class='chapter-title'>Catene di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a47_first_order_markov.html#sommario",
    "href": "chapters/appendix/a47_first_order_markov.html#sommario",
    "title": "Appendice J — Catene di Markov",
    "section": "J.2 Sommario",
    "text": "J.2 Sommario\nUna catena di Markov è una sequenza di variabili aleatorie \\(X_0, X_1, X_2, \\ldots\\) che soddisfa la cosiddetta proprietà di Markov. Questa proprietà stabilisce che, dato lo stato attuale della catena, il futuro è indipendente dal passato. Formalmente, questa proprietà si esprime come:\n\\[\nP(X_{n+1} = j \\mid X_n = i, X_{n-1} = i_{n-1}, \\ldots, X_0 = i_0) = P(X_{n+1} = j \\mid X_n = i) = q_{ij},\n\\]\ndove \\(q_{ij}\\) rappresenta la probabilità di passare dallo stato \\(i\\) allo stato \\(j\\) in un singolo passo. Queste probabilità di transizione sono organizzate in una matrice di transizione \\(Q = (q_{ij})\\), in cui ogni riga corrisponde a una distribuzione di probabilità condizionata sui possibili stati futuri dato l’attuale stato della catena.\nLa distribuzione di probabilità degli stati della catena dopo \\(n\\) passi può essere calcolata moltiplicando la matrice di transizione \\(Q\\) elevata alla potenza \\(n\\) per il vettore di probabilità iniziale \\(s\\), che descrive la distribuzione di probabilità degli stati al tempo \\(0\\). In simboli, questo è rappresentato da \\(sQ^n\\), che fornisce la distribuzione di probabilità marginale degli stati dopo \\(n\\) passi.\nGli stati di una catena di Markov possono essere classificati come ricorrenti o transitori. Uno stato è ricorrente se la catena torna a questo stato ripetutamente nel tempo; è transitorio se la catena potrebbe lasciare questo stato per non ritornarvi mai più. Gli stati possono anche avere un periodo associato, definito come il massimo comun divisore dei numeri di passi necessari per ritornare allo stato stesso. Una catena di Markov è detta irriducibile se è possibile raggiungere qualsiasi stato da qualsiasi altro stato in un numero finito di passi, ed è aperiodica se ogni stato ha periodo 1.\nUna distribuzione stazionaria di una catena di Markov è una distribuzione di probabilità che rimane invariata nel tempo. Se la catena inizia con questa distribuzione, continuerà a mantenerla in ogni passo successivo. Questa condizione si esprime matematicamente come \\(sQ = s\\), dove \\(s\\) è il vettore di probabilità stazionaria e \\(Q\\) è la matrice di transizione. Per una catena di Markov finita che è irriducibile e aperiodica, esiste una distribuzione stazionaria unica verso la quale la catena converge indipendentemente dalla distribuzione iniziale.\nUn concetto importante nelle catene di Markov è quello di reversibilità. Una catena di Markov è detta reversibile se esiste una distribuzione di probabilità \\(s\\) tale che, per ogni coppia di stati \\(i\\) e \\(j\\), la condizione di reversibilità \\(s_i q_{ij} = s_j q_{ji}\\) sia soddisfatta. Questa condizione garantisce che \\(s\\) sia una distribuzione stazionaria per la catena. Le catene di Markov reversibili sono particolarmente utili in applicazioni pratiche come gli algoritmi di simulazione Monte Carlo, ad esempio l’algoritmo di Metropolis-Hastings, poiché permettono di progettare catene che convergono rapidamente alla distribuzione di probabilità desiderata.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>J</span>  <span class='chapter-title'>Catene di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a47_first_order_markov.html#letteratura",
    "href": "chapters/appendix/a47_first_order_markov.html#letteratura",
    "title": "Appendice J — Catene di Markov",
    "section": "J.3 Letteratura",
    "text": "J.3 Letteratura\nI metodi markoviani sono stati ampiamente utilizzati in vari ambiti della psicologia e dell’educazione. Una delle applicazioni più comuni di questi metodi è il clustering dei dati sequenziali (Törmänen et al. (2022); Törmänen et al. (2023); Fincham et al. (2018)). Ad esempio, i modelli nascosti di Markov (HMM) sono stati utilizzati per raggruppare le sequenze di dati tracciati da sistemi di gestione dell’apprendimento (LMS) degli studenti, al fine di identificare i loro schemi di attività, ovvero le tattiche e strategie di apprendimento (Fincham et al. (2018)). Un uso molto diffuso dei modelli di Markov di primo ordine è quello di mappare le transizioni degli studenti tra diverse attività di apprendimento. Per esempio, Matcha et al. (2020) ha utilizzato modelli di Markov di primo ordine per studiare i processi di transizione degli studenti tra diverse strategie di apprendimento. Altri usi includono lo studio delle transizioni tra diverse strategie di scrittura accademica (Peeters et al. (2020)), tra eventi di apprendimento autoregolato (Lim et al. (2023)), o all’interno di contesti di apprendimento collaborativo (Saqr & López-Pernas (2023)). Esempi più specifici nell’ambito psicologico comprendono lo studio delle influenze reciproche tra stati affettivi (Cipresso et al. (2023)) e l’analisi degli effetti psicologici che dipendono dal tempo nelle sequenze di decision-making (Gunawan et al. (2022)).\n\n\n\n\nCipresso, P., Borghesi, F., & Chirico, A. (2023). Affects affect affects: A Markov chain. Frontiers in Psychology, 14, 1162655.\n\n\nFincham, E., Gašević, D., Jovanović, J., & Pardo, A. (2018). From study tactics to learning strategies: An analytical method for extracting interpretable representations. IEEE Transactions on Learning Technologies, 12(1), 59–72.\n\n\nGunawan, D., Hawkins, G. E., Kohn, R., Tran, M.-N., & Brown, S. D. (2022). Time-evolving psychological processes over repeated decisions. Psychological Review, 129(3), 438–456.\n\n\nLim, L., Bannert, M., Graaf, J. van der, Singh, S., Fan, Y., Surendrannair, S., Rakovic, M., Molenaar, I., Moore, J., & Gašević, D. (2023). Effects of real-time analytics-based personalized scaffolds on students’ self-regulated learning. Computers in Human Behavior, 139, 107547.\n\n\nMatcha, W., Gasevic, D., Jovanovic, J., Pardo, A., Lim, L., Maldonado-Mahauad, J., Gentili, S., Pérez-Sanagustı́n, M., Tsai, Y.-S., et al. (2020). Analytics of Learning Strategies: Role of Course Design and Delivery Modality Authors. Journal of Learning Analytics, 7(2), 45–71.\n\n\nPeeters, W., Saqr, M., & Viberg, O. (2020). Applying learning analytics to map students’ self-regulated learning tactics in an academic writing course. Proceedings of the 28th International Conference on Computers in Education, 1, 245–254.\n\n\nSaqr, M., & López-Pernas, S. (2023). The temporal dynamics of online problem-based learning: Why and when sequence matters. International Journal of Computer-Supported Collaborative Learning, 18(1), 11–37.\n\n\nTörmänen, T., Järvenoja, H., Saqr, M., Malmberg, J., & Järvelä, S. (2022). A person-centered approach to study students’ socio-emotional interaction profiles and regulation of collaborative learning. Frontiers in Education, 7, 866612.\n\n\nTörmänen, T., Järvenoja, H., Saqr, M., Malmberg, J., & Järvelä, S. (2023). Affective states and regulation of learning during socio-emotional interactions in secondary school collaborative groups. British Journal of Educational Psychology, 93, 48–70.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>J</span>  <span class='chapter-title'>Catene di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a50_lin_fun.html",
    "href": "chapters/appendix/a50_lin_fun.html",
    "title": "Appendice K — La funzione lineare",
    "section": "",
    "text": "K.1 Concetto di Funzione\nNello studio dei fenomeni naturali e nella risoluzione di problemi tecnici e matematici, è spesso necessario considerare la variazione di una grandezza come dipendente dalla variazione di un’altra. Ad esempio, nello studio del moto, il percorso compiuto da un oggetto può essere visto come una grandezza variabile in funzione del tempo: il cammino percorso è, dunque, una funzione del tempo.\nQuesta considerazione ci conduce alla seguente definizione:\nSe a ogni valore della variabile \\(x\\) (all’interno di un certo intervallo) corrisponde un valore ben definito di un’altra variabile \\(y\\), allora si dice che \\(y\\) è una funzione di \\(x\\). In notazione funzionale si scrive:\n\\[\ny = f(x) \\quad \\text{o anche} \\quad y = \\varphi(x).\n\\]\nLa variabile \\(x\\) è detta variabile indipendente o argomento della funzione. La relazione che lega \\(x\\) a \\(y\\) si chiama relazione funzionale. La lettera \\(f\\) nella notazione \\(y = f(x)\\) indica che per ottenere il valore di \\(y\\) a partire da \\(x\\) è necessario applicare una certa “regola” o “operazione”. In modo analogo, si possono utilizzare anche altre notazioni come \\(u = \\varphi(x)\\).\nLa notazione \\(y = C\\), dove \\(C\\) è una costante, indica una funzione il cui valore rimane invariato per qualunque valore di \\(x\\).\nL’insieme dei valori di \\(x\\) per cui la funzione \\(y = f(x)\\) è definita si chiama dominio di definizione della funzione.\nSe per valori crescenti della variabile indipendente \\(x\\) anche il valore della funzione \\(y = f(x)\\) aumenta, allora la funzione si dice crescente. Analogamente, se a valori crescenti di \\(x\\) corrispondono valori decrescenti della funzione \\(y = f(x)\\), la funzione si dice decrescente.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>K</span>  <span class='chapter-title'>La funzione lineare</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a50_lin_fun.html#la-retta",
    "href": "chapters/appendix/a50_lin_fun.html#la-retta",
    "title": "Appendice K — La funzione lineare",
    "section": "K.2 La Retta",
    "text": "K.2 La Retta\nLa funzione lineare è definita come:\n\\[\nf(x) = a + b x,\n\\]\ndove \\(a\\) e \\(b\\) sono costanti. Il grafico di tale funzione è una retta. Qui, \\(b\\) è detto coefficiente angolare, mentre \\(a\\) è l’intercetta con l’asse delle \\(y\\). In altri termini, la retta interseca l’asse \\(y\\) nel punto \\((0, a)\\).\nPer comprendere il ruolo di \\(a\\) e \\(b\\), consideriamo prima il caso particolare:\n\\[\ny = b x.\n\\]\nQuesta espressione rappresenta una proporzionalità diretta tra \\(x\\) e \\(y\\): al crescere di \\(x\\), \\(y\\) varia in proporzione. Nel caso generale:\n\\[\ny = a + b x,\n\\]\nil termine \\(a\\) “trasla” verticalmente il grafico, aggiungendo una costante a ogni valore \\(b x\\).\nIl segno del coefficiente \\(b\\) determina il comportamento della funzione lineare:\n\nSe \\(b &gt; 0\\), il valore di \\(y\\) aumenta all’aumentare di \\(x\\).\n\nSe \\(b &lt; 0\\), il valore di \\(y\\) diminuisce all’aumentare di \\(x\\).\n\nSe \\(b = 0\\), il grafico è una retta orizzontale e \\(y\\) rimane costante.\n\nPossiamo dare un’interpretazione geometrica ancora più intuitiva se consideriamo variazioni (incrementi) di \\(x\\). Preso un punto \\(x_0\\) e aggiungendo un piccolo incremento \\(\\varepsilon\\), definiamo:\n\\[\n\\Delta x = (x_0 + \\varepsilon) - x_0 = \\varepsilon,\n\\] \\[\n\\Delta y = f(x_0 + \\varepsilon) - f(x_0).\n\\]\nIl coefficiente angolare \\(b\\) può essere interpretato come il rapporto tra la variazione di \\(y\\) e la variazione di \\(x\\):\n\\[\nb = \\frac{\\Delta y}{\\Delta x} = \\frac{f(x_0 + \\varepsilon) - f(x_0)}{(x_0 + \\varepsilon) - x_0}.\n\\]\nQuesto rapporto è costante e non dipende dalla scelta di \\(x_0\\) o di \\(\\varepsilon\\). In particolare, se scegliamo \\(\\Delta x = 1\\), il coefficiente angolare \\(b\\) rappresenta semplicemente di quanto varia \\(y\\) quando \\(x\\) aumenta di un’unità.\n\n\n\n\n\n\n\nFigura K.1: La funzione lineare \\(y = a + bx\\).\n\n\n\nCome mostrato in figura, il coefficiente \\(b\\) indica la pendenza della retta, ossia quanto “ripida” è la sua inclinazione rispetto all’asse orizzontale.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>K</span>  <span class='chapter-title'>La funzione lineare</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a71_install_cmdstan.html",
    "href": "chapters/appendix/a71_install_cmdstan.html",
    "title": "Appendice L — Come installare CmdStan",
    "section": "",
    "text": "L.1 Windows\nSu macOS e Linux, questa configurazione dovrebbe essere già pronta di default.\nSu Windows è necessario installare RTools e configurare PATH:\nProblemi comuni:",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>L</span>  <span class='chapter-title'>Come installare CmdStan</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a71_install_cmdstan.html#windows",
    "href": "chapters/appendix/a71_install_cmdstan.html#windows",
    "title": "Appendice L — Come installare CmdStan",
    "section": "",
    "text": "Installazione di RTools:\n\nVai su https://cran.r-project.org/bin/windows/Rtools/\nScarica la versione di RTools compatibile con la tua versione di R (Generalmente, RTools 4.3 per R 4.3.x, RTools 4.2 per R 4.2.x, etc.)\nEsegui l’installer scaricato\nIMPORTANTE: Durante l’installazione, seleziona la casella “Add rtools to system PATH”\n\nVerifica dell’installazione e configurazione del PATH:\n\nApri PowerShell o Command Prompt\nVerifica se RTools è nel PATH digitando:\n\ngcc --version\nSe vedi la versione di gcc, RTools è nel PATH.\nSe RTools non è nel PATH, devi aggiungerlo manualmente:\n\nCerca “Impostazioni di Sistema” in Windows\nClicca su “Impostazioni di sistema avanzate”\nClicca su “Variabili d’ambiente”\nNella sezione “Variabili di sistema”, trova “Path”\nClicca “Modifica”\nClicca “Nuovo” e aggiungi questi percorsi (sostituisci X.X con la tua versione di RTools):\nC:\\rtools4X\\mingw64\\bin\nC:\\rtools4X\\usr\\bin\n\nVerifica finale:\n\nChiudi e riapri il terminale\nProva questi comandi:\n\ngcc --version\nmake --version\nSe entrambi i comandi mostrano le versioni, l’installazione è completa.\nTest in R:\n\nApri R o RStudio\nEsegui:\n\nSys.which(\"make\")\nDovrebbe mostrare il percorso di make.\n\n\n\nSe i comandi non vengono riconosciuti dopo aver aggiunto il PATH, prova a riavviare il computer.\nSe usi RStudio, potrebbe essere necessario riavviarlo dopo aver modificato il PATH.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>L</span>  <span class='chapter-title'>Come installare CmdStan</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_subj_prop.html#esempio-riconoscimento-di-parole-emozionanti",
    "href": "chapters/bayesian_inference/05_subj_prop.html#esempio-riconoscimento-di-parole-emozionanti",
    "title": "49  Aggiornare le credenze su un parametro: dal prior alla posterior",
    "section": "\n49.3 Esempio: Riconoscimento di Parole Emozionanti",
    "text": "49.3 Esempio: Riconoscimento di Parole Emozionanti\nUn ricercatore in psicologia cognitiva conduce uno studio per stimare la proporzione di adulti in grado di riconoscere correttamente parole con contenuto emotivo positivo (es. gioia, orgoglio, speranza) all’interno di un compito di memoria a lungo termine. Ogni partecipante riceve lo stesso test standardizzato e viene classificato come:\n\n1 = corretto riconoscimento (successo), oppure\n0 = mancato riconoscimento (fallimento).\n\nIn un campione di 30 soggetti indipendenti, 22 hanno riconosciuto correttamente le parole emozionanti.\nIn questo scenario:\n\nciascun soggetto è un’unità di osservazione indipendente;\nciascun soggetto può essere considerato come una prova di una variabile di Bernoulli con probabilità di successo \\(\\theta\\), dove \\(\\theta\\) rappresenta la proporzione vera nella popolazione di adulti in grado di riconoscere correttamente parole emotive.\n\nPertanto, il numero totale di successi in \\(n = 30\\) soggetti può essere modellato come:\n\\[\nY \\sim \\text{Binomiale}(n = 30, \\theta),\n\\]\ndove \\(Y = 22\\) è il numero di successi osservati.\n\n49.3.1 Obiettivo inferenziale\nVogliamo stimare il parametro \\(\\theta\\), che rappresenta la probabilità che un adulto, estratto a caso dalla popolazione, riconosca correttamente parole emotive. In un contesto bayesiano, il modello binomiale ci permette di stimare \\(\\theta\\) a partire dai dati osservati e di quantificare l’incertezza associata a questa stima. In particolare, la verosimiglianza dei dati osservati (22 successi su 30 prove) può essere espressa attraverso la funzione di massa di probabilità binomiale, che assegna una probabilità a ogni possibile valore di \\(\\theta\\) compreso tra 0 e 1.\nL’analisi bayesiana di questo problema prevede la combinazione di queste informazioni con una distribuzione a priori che rappresenta le nostre credenze iniziali sull’abilità inibitoria del partecipante. Questo approccio ci consentirà di ottenere una distribuzione a posteriori per \\(\\theta\\) che sintetizza sia le informazioni a priori sia l’evidenza fornita dai dati osservati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Aggiornare le credenze su un parametro: dal prior alla posterior</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_subj_prop.html#estensione-il-metodo-basato-su-griglia-per-il-modello-con-verosimiglianza-gaussiana",
    "href": "chapters/bayesian_inference/05_subj_prop.html#estensione-il-metodo-basato-su-griglia-per-il-modello-con-verosimiglianza-gaussiana",
    "title": "49  Aggiornare le credenze su un parametro: dal prior alla posterior",
    "section": "\n49.7 Estensione: Il Metodo Basato su Griglia per il Modello con Verosimiglianza Gaussiana",
    "text": "49.7 Estensione: Il Metodo Basato su Griglia per il Modello con Verosimiglianza Gaussiana\nFinora abbiamo applicato il metodo basato su griglia al caso della stima di una proporzione in un modello beta-binomiale. Tuttavia, lo stesso principio si estende in modo naturale anche a modelli con parametri continui e verosimiglianza diversa dalla binomiale, come nel caso della distribuzione normale.\nIn particolare, possiamo usare il metodo su griglia per stimare la media \\(\\mu\\) di una popolazione, assumendo che i dati seguano una distribuzione normale con deviazione standard nota. Anche in questo contesto, la procedura prevede di:\n\ndefinire una griglia di valori plausibili per il parametro \\(\\mu\\),\ncalcolare la verosimiglianza dei dati per ciascun valore della griglia,\nspecificare una distribuzione a priori per \\(\\mu\\),\ncombinare prior e verosimiglianza punto per punto,\nnormalizzare i risultati per ottenere una distribuzione a posteriori.\n\nL’uso della griglia permette di approssimare la distribuzione a posteriori in modo trasparente e intuitivo, anche quando il modello non ha una soluzione analitica semplice.\n\n49.7.1 Esempio: Stima Bayesiana della Media del QI\nImmaginiamo di condurre uno studio su bambini ad alto potenziale cognitivo. Per semplicità, ipotizziamo che il QI in questa popolazione segua una distribuzione normale con deviazione standard nota pari a 5, mentre la media \\(\\mu\\) è incognita e rappresenta il parametro di interesse.\nSupponiamo di osservare i seguenti 10 punteggi di QI (simulati da una normale con media 130 e sd = 5):\n\nset.seed(123)\ncampione &lt;- round(rnorm(10, mean = 130, sd = 5))\n\n\n49.7.2 Definizione della Griglia\nPer applicare il metodo bayesiano su griglia, costruiamo una sequenza di valori plausibili per \\(\\mu\\), ad esempio:\n\nmu_griglia &lt;- seq(110, 150, length.out = 100)\n\n\n49.7.3 Calcolo della Verosimiglianza\nLa verosimiglianza per ciascun valore di \\(\\mu\\) è il prodotto delle densità normali dei dati osservati, assumendo \\(\\sigma = 5\\):\n\nlikelihood &lt;- sapply(mu_griglia, function(mu) {\n  prod(dnorm(campione, mean = mu, sd = 5))\n})\n\n\n49.7.4 Prior Informativa\nSupponiamo ora di avere una convinzione iniziale secondo cui \\(\\mu\\) è centrata intorno a 140, con una deviazione standard pari a 3. Questa informazione può essere rappresentata con una distribuzione a priori gaussiana \\(\\mathcal{N}(140, 3^2)\\):\n\nprior &lt;- dnorm(mu_griglia, mean = 140, sd = 3)\n\nCombinando questa prior con la verosimiglianza calcolata in precedenza, otteniamo la distribuzione a posteriori:\n\nposterior &lt;- likelihood * prior\nposterior &lt;- posterior / sum(posterior)  # Normalizzazione\n\nQuesta posteriori riflette un compromesso tra i dati osservati e la credenza iniziale. Se i dati sono informativi (campione sufficientemente grande), l’influenza della prior si riduce; viceversa, con pochi dati, la prior può giocare un ruolo più rilevante.\n\n49.7.5 Campionamento dalla Posteriori\nPossiamo generare un campione dalla distribuzione a posteriori discreta per calcolare quantità riassuntive e costruire intervalli di credibilità:\n\nset.seed(123)\nsamples &lt;- sample(mu_griglia, size = 10000, replace = TRUE, prob = posterior)\n\nQuantità riassuntive:\n\nmean(samples)                         # media a posteriori\n#&gt; [1] 132.6\nquantile(samples, c(0.03, 0.97))      # intervallo di credibilità al 94%\n#&gt;    3%   97% \n#&gt; 129.8 135.1\n\n\n49.7.6 Visualizzazione congiunta: Prior, Verosimiglianza, Posteriori\nPer confrontare le tre distribuzioni, normalizziamo anche la verosimiglianza:\n\nlikelihood_std &lt;- likelihood / sum(likelihood)\n\ndat &lt;- tibble(\n  mu = mu_griglia,\n  Prior = prior / sum(prior),\n  Verosimiglianza = likelihood_std,\n  Posteriori = posterior\n)\n\n# Riorganizzazione in formato lungo\nlong_data &lt;- dat |&gt;\n  pivot_longer(cols = c(\"Prior\", \"Verosimiglianza\", \"Posteriori\"),\n               names_to = \"Distribuzione\",\n               values_to = \"Densità\")\n\nGrafico:\n\nggplot(long_data, aes(x = mu, y = Densità, color = Distribuzione)) +\n  geom_line(size = 1.2) +\n  labs(\n    title = \"Confronto tra Prior, Verosimiglianza e Posteriori\",\n    x = expression(mu),\n    y = \"Densità (normalizzata)\",\n    color = NULL\n  ) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n49.7.7 Interpretazione\n\n\nLa prior riflette una credenza iniziale centrata su \\(\\mu = 140\\), coerente con l’ipotesi che i bambini siano plusdotati.\n\nLa verosimiglianza riflette i dati osservati, tendendo a concentrare la densità intorno alla media campionaria.\n\nLa posteriori media tra queste due fonti di informazione, spostandosi più o meno verso la prior a seconda del numero di osservazioni e della forza dei dati.\n\nQuesto esempio mostra chiaramente come l’inferenza bayesiana combini in modo coerente dati e credenze preesistenti, rendendo il processo inferenziale trasparente e aggiornabile.\n\n49.7.8 Nota su Stabilità Numerica: Uso dei Logaritmi\nPer evitare problemi di underflow, è possibile calcolare i logaritmi delle densità:\n\nlog_likelihood &lt;- sapply(mu_griglia, function(mu) {\n  sum(dnorm(campione, mean = mu, sd = 5, log = TRUE))\n})\nlog_prior &lt;- dnorm(mu_griglia, mean = 140, sd = 3, log = TRUE)\n\nlog_posterior &lt;- log_likelihood + log_prior\nlog_posterior &lt;- log_posterior - max(log_posterior)  # stabilizzazione\nposterior &lt;- exp(log_posterior) / sum(exp(log_posterior))\n\nLe quantità riassuntive che otteniamo in questo modo coincidono con quelle trovate in precedenza:\n\nset.seed(123)\nsamples &lt;- sample(mu_griglia, size = 10000, replace = TRUE, prob = posterior)\nmean(samples)                         # media a posteriori\n#&gt; [1] 132.6\nquantile(samples, c(0.03, 0.97))      # intervallo di credibilità al 94%\n#&gt;    3%   97% \n#&gt; 129.8 135.1\n\n\n49.7.9 Estensione: Parametri Multipli\nNel caso in cui anche \\(\\sigma\\) sia ignota, possiamo estendere la griglia a due dimensioni:\n\n\\(\\mu \\in [110, 150]\\)\n\\(\\sigma \\in [1, 10]\\)\n\ne calcolare la verosimiglianza e la prior su ciascuna coppia \\((\\mu, \\sigma)\\). Tuttavia, il numero di combinazioni cresce rapidamente, evidenziando la maledizione della dimensionalità. In tali casi, è consigliabile usare metodi di approssimazione come l’MCMC.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Aggiornare le credenze su un parametro: dal prior alla posterior</span>"
    ]
  }
]