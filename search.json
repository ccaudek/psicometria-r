[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Psicometria",
    "section": "",
    "text": "Informazioni generali\n→ Introduzione → Syllabus → Calendario",
    "crumbs": [
      "Informazioni generali"
    ]
  },
  {
    "objectID": "index.html#informazioni-generali",
    "href": "index.html#informazioni-generali",
    "title": "Psicometria",
    "section": "",
    "text": "Anno Accademico: 2024–2025\n\nCodice Insegnamento: B000286 (coorte L–Z)",
    "crumbs": [
      "Informazioni generali"
    ]
  },
  {
    "objectID": "index.html#percorso-del-corso",
    "href": "index.html#percorso-del-corso",
    "title": "Psicometria",
    "section": "Percorso del corso",
    "text": "Percorso del corso\n\nNozioni chiave — dati, misurazione, disegno dello studio.\n\nEDA — pulizia dati, visualizzazioni, analisi esplorativa.\nProbabilità — variabili casuali, distribuzioni, teorema di Bayes.\n\nBayesian workflow — inferenza a posteriori, distribuzione predittiva posteriore, MCMC.\n\nModelli — regressione lineare (frequenstista e bayesiana), GLM, modelli dinamici.\n\nValidazione — LPPD/ELPD, LOO-CV, performance predittiva.\n\n\nOgni sezione contiene esempi riproducibili in R, con script essenziali e figure.",
    "crumbs": [
      "Informazioni generali"
    ]
  },
  {
    "objectID": "index.html#come-usare-questi-appunti",
    "href": "index.html#come-usare-questi-appunti",
    "title": "Psicometria",
    "section": "Come usare questi appunti",
    "text": "Come usare questi appunti\n\nSegui l’ordine capitolo → esercizi → verifica predittiva.\n\nCopia il codice e riproduci le figure; modifica i dati e osserva cosa cambia.\n\nQuando confronti modelli, interpreta sempre differenza ELPD ± SE.\n\nPrivilegia modelli semplici e interpretabili, anche a scapito di minimi guadagni predittivi.",
    "crumbs": [
      "Informazioni generali"
    ]
  },
  {
    "objectID": "index.html#strumenti-prerequisiti",
    "href": "index.html#strumenti-prerequisiti",
    "title": "Psicometria",
    "section": "Strumenti & prerequisiti",
    "text": "Strumenti & prerequisiti\n\nR ≥ 4.5 e RStudio (o un editor alternativo come VS Code).\n\nPacchetti: tidyverse, brms, cmdstanr, loo.\n\nCmdStan installato e configurato con il pacchetto cmdstanr (necessario per ottenere le massime prestazioni da brms). → Guida all’installazione.\nQuarto per la riproducibilità (render dei documenti).\n\nConoscenze preliminari: Non sono richieste competenze avanzate: i concetti matematici essenziali (algebra, probabilità) verranno richiamati quando necessario.",
    "crumbs": [
      "Informazioni generali"
    ]
  },
  {
    "objectID": "index.html#licenza-duso",
    "href": "index.html#licenza-duso",
    "title": "Psicometria",
    "section": "Licenza d’uso",
    "text": "Licenza d’uso\nMateriali rilasciati con licenza CC BY 4.0.\nÈ consentito qualsiasi utilizzo previa attribuzione.",
    "crumbs": [
      "Informazioni generali"
    ]
  },
  {
    "objectID": "prefazione.html",
    "href": "prefazione.html",
    "title": "Introduzione",
    "section": "",
    "text": "Bibliografia\nL’analisi dei dati rappresenta un insieme di pratiche fondamentali per estrarre significato, scoprire insight e guidare il processo decisionale sulla base delle evidenze. Ma come possiamo rendere l’analisi dei dati psicologici più affidabile e rigorosa? È sufficiente applicare algoritmi standard o seguire procedure predefinite? Oppure, ridurre l’analisi a un semplice insieme di “ricette” statistiche rischia di impoverire la nostra comprensione dei fenomeni psicologici (McElreath, 2020)?\nQueste domande ci invitano a riflettere sulla natura stessa della ricerca empirica in psicologia. Contrariamente a quanto suggerito dall’approccio frequentista del null hypothesis testing, l’analisi dei dati non è un processo meccanico e automatico. Considerarla tale contribuisce a uno dei problemi più urgenti della psicologia contemporanea: la crisi della replicabilità (Korbmacher et al., 2023).\nLa replicabilità costituisce un criterio epistemologico fondamentale nella ricerca psicologica, in quanto garantisce la validità delle inferenze scientifiche e la generalizzabilità dei risultati. L’incapacità di replicare i risultati empirici mina la robustezza delle teorie psicologiche, compromettendone la validità costruttiva ed esterna. Tale instabilità metodologica ha implicazioni sostanziali anche a livello applicativo: interventi clinici basati su evidenze non replicabili possono condurre a conclusioni erronee, mentre politiche educative e strategie organizzative fondate su risultati fragili rischiano di produrre effetti nulli o controproducenti (Funder et al., 2014; Ioannidis, 2019; Shrout & Rodgers, 2018; Tackett et al., 2019).\nIl paradigma frequentista può aver contribuito alla crisi della replicabilità attraverso la sua dipendenza da p-value soglia-dipendenti e la tendenza a favorire risultati statisticamente significativi ma potenzialmente spurii. Parallelamente, gli incentivi accademici—quali la pressione alla pubblicazione e la preferenza per risultati innovativi—hanno sistematicamente incentivato pratiche di ricerca discutibili, tra cui il p-hacking e la selezione selettiva di risultati. Per contrastare queste criticità, è necessario adottare framework analitici alternativi che garantiscano maggiore trasparenza e robustezza metodologica.\nL’inferenza bayesiana rappresenta un approccio promettente, poiché consente una quantificazione diretta della probabilità delle ipotesi e una gestione più flessibile dell’incertezza (Gelman et al., 2013). Tuttavia, la sua adozione richiede più della mera sostituzione dei metodi frequentisti: implica l’integrazione di tecniche avanzate—come la modellazione gerarchica bayesiana e l’identificazione di relazioni causali—con una rigorosa caratterizzazione dei processi generativi dei dati e delle assunzioni teoriche sottostanti (Oberauer & Lewandowsky, 2019; Wagenmakers et al., 2018; Yarkoni, 2022).\nIn questo testo, analizzeremo sistematicamente le limitazioni degli approcci tradizionali, esamineremo i fattori strutturali alla base della crisi di replicabilità e valuteremo l’efficacia di metodologie alternative nel migliorare l’affidabilità della ricerca psicologica. L’obiettivo è fornire un framework metodologico integrato, che combini rigore statistico, trasparenza analitica e coerenza teorica, orientando gli studenti verso pratiche di ricerca empiricamente e concettualmente più solide.",
    "crumbs": [
      "Introduzione"
    ]
  },
  {
    "objectID": "prefazione.html#bibliografia",
    "href": "prefazione.html#bibliografia",
    "title": "Introduzione",
    "section": "",
    "text": "Funder, D. C., Levine, J. M., Mackie, D. M., Morf, C. C., Sansone, C., Vazire, S., & West, S. G. (2014). Improving the dependability of research in personality and social psychology: Recommendations for research and educational practice. Personality and Social Psychology Review, 18(1), 3–12.\n\n\nGelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., & Rubin, D. B. (2013). Bayesian Data Analysis (3rd ed.). Chapman; Hall/CRC.\n\n\nIoannidis, J. P. (2019). What have we (not) learnt from millions of scientific papers with P values? The American Statistician, 73(sup1), 20–25.\n\n\nKorbmacher, M., Azevedo, F., Pennington, C. R., Hartmann, H., Pownall, M., Schmidt, K., Elsherif, M., Breznau, N., Robertson, O., Kalandadze, T., et al. (2023). The replication crisis has led to positive structural, procedural, and community changes. Communications Psychology, 1(1), 3.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nOberauer, K., & Lewandowsky, S. (2019). Addressing the theory crisis in psychology. Psychonomic Bulletin & Review, 26, 1596–1618.\n\n\nShrout, P. E., & Rodgers, J. L. (2018). Psychology, science, and knowledge construction: Broadening perspectives from the replication crisis. Annual Review of Psychology, 69(1), 487–510.\n\n\nTackett, J. L., Brandes, C. M., King, K. M., & Markon, K. E. (2019). Psychology’s replication crisis and clinical psychological science. Annual Review of Clinical Psychology, 15(1), 579–604.\n\n\nWagenmakers, E.-J., Marsman, M., Jamil, T., Ly, A., Verhagen, J., Love, J., Selker, R., Gronau, Q. F., Šmı́ra, M., Epskamp, S., et al. (2018). Bayesian inference for psychology. Part I: Theoretical advantages and practical ramifications. Psychonomic Bulletin & Review, 25, 35–57.\n\n\nYarkoni, T. (2022). The generalizability crisis. Behavioral and Brain Sciences, 45, e1.",
    "crumbs": [
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/key_notions/introduction_key_notions.html",
    "href": "chapters/key_notions/introduction_key_notions.html",
    "title": "Fondamenti",
    "section": "",
    "text": "La data science è un campo che si sviluppa all’intersezione tra la statistica e l’informatica. La statistica fornisce una serie di metodologie per analizzare i dati e ottenere informazioni significative, mentre l’informatica si occupa dello sviluppo di software e strumenti per implementare tali metodologie. In questa sezione della dispensa, approfondiremo alcuni concetti fondamentali della statistica e della misurazione psicologica. Considereremo anche in termini generali quali sono gli obiettivi e i limiti dell’analisi dei dati psicologici.",
    "crumbs": [
      "Fondamenti"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_data_analysis.html",
    "href": "chapters/key_notions/01_data_analysis.html",
    "title": "1  La crisi di replicazione e la riforma metodologica in psicologia",
    "section": "",
    "text": "1.1 Introduzione\nNegli ultimi vent’anni, la psicologia ha attraversato una trasformazione metodologica profonda, innescata da una crescente consapevolezza dei propri limiti empirici. Questa trasformazione prende il nome di crisi di replicazione (Baker, 2016; Bishop, 2019). Numerosi tentativi sistematici di replicare effetti pubblicati in studi classici hanno rivelato un tasso sorprendentemente alto di fallimenti. In molti casi, i risultati non solo non si replicano con la stessa ampiezza, ma talvolta non emergono affatto. Questa situazione ha costretto l’intera disciplina a interrogarsi sulla solidità delle proprie basi empiriche.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>La crisi di replicazione e la riforma metodologica in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_data_analysis.html#introduzione",
    "href": "chapters/key_notions/01_data_analysis.html#introduzione",
    "title": "1  La crisi di replicazione e la riforma metodologica in psicologia",
    "section": "",
    "text": "1.1.1 Che cos’è la replicazione\nReplicare un risultato non significa semplicemente ottenere un nuovo p-value inferiore a .05. Significa ripetere un esperimento in condizioni il più possibile simili all’originale e ottenere una stima dell’effetto compatibile con quella iniziale, in termini sia di direzione che di grandezza. La replicabilità è uno dei pilastri fondamentali della scienza empirica: se un risultato rappresenta un fenomeno reale e generalizzabile, dovrebbe emergere anche in campioni indipendenti.\n\n\n1.1.2 I numeri della crisi\nLa portata della crisi è stata messa in evidenza dall’Collaboration (2015), che ha tentato di replicare 100 studi pubblicati su riviste leader nel settore. Solo il 36% delle repliche ha prodotto risultati “significativi” nello stesso senso degli studi originali. Questo valore non va inteso come una misura bayesiana di probabilità, ma come un indicatore allarmante di quanto i risultati pubblicati siano sensibili alle condizioni sperimentali, ai campioni, e alle analisi.\nL’evidenza si è accumulata con studi successivi: Camerer et al. (2018) hanno mostrato una riproducibilità deludente anche in economia comportamentale, mentre Klein et al. (2014) hanno riportato effetti inconsistenti in psicologia sociale. In molti casi, i risultati originali si sono dimostrati fragili, condizionali, o il prodotto di scelte analitiche arbitrarie.\n\n\n1.1.3 Il fallimento della replicazione è un sintomo\nPiù che una patologia in sé, il fallimento della replicazione è un sintomo di un problema più ampio: un’adozione acritica e routinaria del paradigma frequentista, in particolare del Null Hypothesis Significance Testing (NHST). Questo approccio, se non applicato con estrema cautela, incentiva strategie di analisi discutibili. La dipendenza da soglie fisse come p &lt; .05, la flessibilità nel trattamento dei dati, e la pratica di adattare le ipotesi a posteriori (HARKing), contribuiscono ad amplificare l’illusione della scoperta anche in assenza di effetti reali.\nLa statistica frequentista tradizionale, centrata sul concetto di errore di I e II specie, può indurre a interpretazioni errate e a una eccessiva enfasi su esiti binari (significativo/non significativo). Questa mentalità ha contribuito alla diffusione di falsi positivi, alla scarsa trasparenza nelle analisi, e a una generale crisi di credibilità nella letteratura psicologica (Ioannidis, 2005; Meehl, 1967).\n\n\n1.1.4 Conseguenze scientifiche e sociali\nIl risultato è un panorama in cui non è più chiaro quali risultati siano attendibili. Gli effetti di questa incertezza non sono solo accademici: si riflettono nella perdita di fiducia da parte del pubblico, nello spreco di risorse su linee di ricerca inconsistenti, e in una generale difficoltà a costruire teorie cumulative. Tuttavia, questa crisi ha innescato una risposta positiva, nota come Credibility Revolution (Angrist & Pischke, 2010), che mira a riformare alla radice le pratiche di ricerca, ponendo l’accento su rigore metodologico, trasparenza, e apertura.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>La crisi di replicazione e la riforma metodologica in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_data_analysis.html#una-via-duscita-la-rivoluzione-bayesiana",
    "href": "chapters/key_notions/01_data_analysis.html#una-via-duscita-la-rivoluzione-bayesiana",
    "title": "1  La crisi di replicazione e la riforma metodologica in psicologia",
    "section": "1.2 Una via d’uscita: la rivoluzione bayesiana",
    "text": "1.2 Una via d’uscita: la rivoluzione bayesiana\nIn questo contesto, l’approccio bayesiano si è imposto come una delle risposte più promettenti. La statistica bayesiana si fonda sull’idea che la conoscenza scientifica non sia binaria (vero/falso), ma debba essere espressa in termini di gradi di credenza che evolvono nel tempo. L’inferenza diventa allora un processo di aggiornamento della conoscenza, in cui le distribuzioni di probabilità posteriori riflettono quanto siamo sicuri di una determinata ipotesi, alla luce dei dati e delle nostre conoscenze pregresse.\nA differenza dell’approccio NHST, che produce una decisione dicotomica, l’inferenza bayesiana restituisce un’intera distribuzione di credibilità sull’effetto. Questo consente di rispondere a domande più naturali e utili per la pratica scientifica, come ad esempio: “quanto è probabile che l’effetto superi una soglia di rilevanza pratica?”, oppure: “quanto si restringe la mia incertezza sull’effetto rispetto alla conoscenza pregressa?”",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>La crisi di replicazione e la riforma metodologica in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_data_analysis.html#il-problema-dei-piccoli-campioni-e-leterogeneità",
    "href": "chapters/key_notions/01_data_analysis.html#il-problema-dei-piccoli-campioni-e-leterogeneità",
    "title": "1  La crisi di replicazione e la riforma metodologica in psicologia",
    "section": "1.3 Il problema dei piccoli campioni e l’eterogeneità",
    "text": "1.3 Il problema dei piccoli campioni e l’eterogeneità\nUno dei limiti strutturali della ricerca psicologica riguarda la frequente presenza di campioni piccoli e popolazioni eterogenee. A causa della natura dei fenomeni studiati (ad esempio, patologie rare o condizioni sperimentali complesse), molti studi operano in condizioni di informazione limitata e con forte variabilità interindividuale. Questo porta a stime instabili, a bassa potenza statistica, e a risultati difficilmente replicabili.\nL’approccio bayesiano è particolarmente adatto a questi contesti. Permette di:\n\nintegrare conoscenze pregresse (priors) per aumentare la stabilità delle stime;\nmodellare esplicitamente l’incertezza e l’eterogeneità tra soggetti o studi;\nvalutare la robustezza dei risultati rispetto a diverse ipotesi a priori.\n\nIn altre parole, la statistica bayesiana rende possibile un’inferenza più solida in condizioni dove i metodi frequentisti si rivelano fragili, soprattutto nei casi in cui la variabilità è alta e i dati sono scarsi.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>La crisi di replicazione e la riforma metodologica in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_data_analysis.html#verso-una-scienza-cumulativa-e-trasparente",
    "href": "chapters/key_notions/01_data_analysis.html#verso-una-scienza-cumulativa-e-trasparente",
    "title": "1  La crisi di replicazione e la riforma metodologica in psicologia",
    "section": "1.4 Verso una scienza cumulativa e trasparente",
    "text": "1.4 Verso una scienza cumulativa e trasparente\nLa crisi di replicazione ha accelerato la transizione verso pratiche di ricerca più aperte, riproducibili e cumulative. In questo nuovo paradigma, l’approccio bayesiano si integra perfettamente con la Data Science e gli strumenti di Open Science: version control con GitHub, documentazione con Quarto, condivisione di dati e codice, preregistrazione delle ipotesi e confronto tra modelli. Questi strumenti, sempre più adottati, non sono semplici tecnicalità, ma elementi strutturali di un nuovo modello di scienza psicologica.\nInoltre, si sta assistendo a un rinnovato interesse per la modellazione formale, in cui le ipotesi teoriche vengono esplicitate attraverso modelli matematici interpretabili. La statistica bayesiana è il linguaggio naturale di questi modelli, poiché permette di confrontare teorie alternative, incorporare incertezza parametrica, e testare la coerenza predittiva in modo diretto.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>La crisi di replicazione e la riforma metodologica in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_data_analysis.html#conclusioni",
    "href": "chapters/key_notions/01_data_analysis.html#conclusioni",
    "title": "1  La crisi di replicazione e la riforma metodologica in psicologia",
    "section": "Conclusioni",
    "text": "Conclusioni\nLa crisi di replicazione ha messo a nudo i limiti di un certo modo di fare scienza: eccessiva fiducia nei risultati significativi, scarsa attenzione all’incertezza, e una concezione rigida dell’inferenza. Il paradigma bayesiano, affiancato da pratiche di ricerca aperta e strumenti di data science, offre un’alternativa concreta e operativa. Questo libro si propone come guida introduttiva a questo approccio, con l’obiettivo di formare ricercatori capaci di pensare in termini di variabilità, incertezza e aggiornamento continuo della conoscenza.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>La crisi di replicazione e la riforma metodologica in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_data_analysis.html#esercizi",
    "href": "chapters/key_notions/01_data_analysis.html#esercizi",
    "title": "1  La crisi di replicazione e la riforma metodologica in psicologia",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nQuali sono i principali fattori che hanno portato alla “Credibility Revolution” in psicologia e in che modo le nuove metodologie — in particolare l’approccio bayesiano e le buone pratiche di Data Science — mirano a superare i limiti che hanno contribuito alla “Replication Crisis”?\nIn che modo il paradigma bayesiano differisce dall’approccio frequentista nella gestione dell’incertezza e nell’aggiornamento della conoscenza, e quali vantaggi pratici offre quando si lavora con campioni di piccole dimensioni e popolazioni eterogenee?\nQual è il ruolo delle distribuzioni a priori nelle analisi bayesiane e come ci si assicura che l’uso di priors non introduca bias indesiderati, specialmente in un contesto come quello psicologico dove le teorie e i dati pregressi possono essere incompleti o controversi?\nPerché la modellazione formale e le buone pratiche di Data Science (ad es. condivisione di codice, controllo di versione, pipeline riproducibili) risultano fondamentali per una scienza cumulativa e per mitigare gli errori sistematici nella ricerca psicologica?\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n1. Quali sono i principali fattori che hanno portato alla “Credibility Revolution” in psicologia e in che modo le nuove metodologie — in particolare l’approccio bayesiano e le buone pratiche di Data Science — mirano a superare i limiti che hanno contribuito alla “Replication Crisis”?\nNegli ultimi decenni, la psicologia ha attraversato una “Replication Crisis” a causa di diverse pratiche di ricerca problematiche, tra cui l’utilizzo di campioni di piccole dimensioni, l’uso eccessivo di test di significatività frequentisti con p &lt; .05 come soglia rigida, il fenomeno del p-hacking (cioè l’adattamento delle analisi per ottenere risultati “significativi”), e la carenza di trasparenza e condivisione dei dati. Questi fattori hanno portato alla pubblicazione di molti falsi positivi e a un’erosione della fiducia nelle conclusioni psicologiche.\nLa “Credibility Revolution” nasce dalla presa di coscienza di questi problemi e dall’introduzione di nuove metodologie che offrono maggior rigore e trasparenza. L’approccio bayesiano, in particolare, consente di superare alcuni limiti della statistica frequentista, poiché fornisce distribuzioni posteriori di plausibilità per i parametri e non si affida a soglie arbitrarie di significatività. Inoltre, la Data Science ha promosso la diffusione di pipeline analitiche riproducibili (tramite il controllo di versione, la condivisione del codice e dei dati), contribuendo a ridurre errori, bias e a favorire la replicabilità. Insieme, queste innovazioni mirano a creare una scienza più aperta, solida e cumulativa.\n2. In che modo il paradigma bayesiano differisce dall’approccio frequentista nella gestione dell’incertezza e nell’aggiornamento della conoscenza, e quali vantaggi pratici offre quando si lavora con campioni di piccole dimensioni e popolazioni eterogenee?\nIl paradigma frequentista si basa sull’idea di ripetizione ipotetica degli esperimenti e sull’applicazione di test di significatività, focalizzandosi su p-value e intervalli di confidenza che rispondono a domande “se si ripetesse infinite volte l’esperimento, in media cosa accadrebbe?”. L’inferenza bayesiana, al contrario, concepisce la probabilità come uno stato di conoscenza (o di credenza) e integra le informazioni precedenti (priors) con i dati osservati per produrre una distribuzione posteriore. Ciò consente un aggiornamento continuo e iterativo delle ipotesi alla luce delle nuove evidenze.\nQuesta impostazione risulta particolarmente utile quando i campioni sono ridotti e le popolazioni indagate sono eterogenee. In tali condizioni, il paradigma frequentista rischia di generare stime instabili o intervalli di confidenza molto ampi. L’approccio bayesiano, invece, permette di incorporare informazioni pregresse e di ottenere stime più precise, a patto che le priors siano giustificate e non eccessivamente informative. L’attenzione alla distribuzione posteriore rende inoltre più chiaro il grado di incertezza associato ai parametri di interesse e favorisce la formulazione di inferenze più calibrate.\n3. Qual è il ruolo delle distribuzioni a priori nelle analisi bayesiane e come ci si assicura che l’uso di priors non introduca bias indesiderati, specialmente in un contesto come quello psicologico dove le teorie e i dati pregressi possono essere incompleti o controversi?\nNell’approccio bayesiano, le distribuzioni a priori (priors) rappresentano la conoscenza o le ipotesi iniziali di cui si dispone sui parametri in esame prima di raccogliere i dati. Se ben specificate, contribuiscono a rendere l’analisi più informativa, soprattutto quando il campione è di piccole dimensioni. Tuttavia, un uso improprio delle priors può introdurre bias, poiché priors troppo “forti” (ossia eccessivamente vincolanti) possono spingere i risultati verso determinate conclusioni.\nPer evitare questi rischi, i ricercatori devono adottare priors ben motivate e trasparenti. In psicologia, dove le teorie possono essere ancora in fase di sviluppo e i dati pregressi non sempre affidabili, è spesso utile iniziare con priors non informative o debolmente informative, per ridurre il rischio di forzare troppo il modello. È anche fondamentale effettuare analisi di sensibilità: testare differenti specificazioni di priors per verificare se i risultati sono robusti oppure fortemente dipendenti da particolari assunzioni iniziali. La documentazione delle scelte fatte (e le relative ragioni) è parte integrante di una buona pratica di ricerca trasparente.\n4. Perché la modellazione formale e le buone pratiche di Data Science (ad es. condivisione di codice, controllo di versione, pipeline riproducibili) risultano fondamentali per una scienza cumulativa e per mitigare gli errori sistematici nella ricerca psicologica?\nLa modellazione formale consente di superare la mera descrizione delle relazioni tra variabili (tipica dell’ANOVA o dei modelli lineari tradizionali) e di entrare nel merito dei meccanismi sottostanti i fenomeni psicologici, costruendo teorie più articolate e fondate. Questa prospettiva rende più esplicite le assunzioni e le ipotesi su cui si basa la ricerca, permettendo un confronto chiaro tra diverse spiegazioni concorrenti.\nParallelamente, l’adozione di strumenti e pratiche di Data Science come la condivisione di codice (in repository pubblici), l’uso del controllo di versione (es. Git) e pipeline analitiche riproducibili riducono gli errori e favoriscono la verifica indipendente dei risultati. Ciò aumenta la trasparenza, poiché altri ricercatori possono ispezionare i passaggi compiuti, e consente la replicazione degli studi. In una scienza cumulativa, infatti, la possibilità di riprodurre, criticare e migliorare i risultati di lavori precedenti è essenziale per costruire un corpus di conoscenze solido e affidabile.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>La crisi di replicazione e la riforma metodologica in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_data_analysis.html#bibliografia",
    "href": "chapters/key_notions/01_data_analysis.html#bibliografia",
    "title": "1  La crisi di replicazione e la riforma metodologica in psicologia",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAngrist, J. D., & Pischke, J.-S. (2010). The credibility revolution in empirical economics: How better research design is taking the con out of econometrics. Journal of economic perspectives, 24(2), 3–30.\n\n\nBaker, M. (2016). 1,500 scientists lift the lid on reproducibility. Nature, 533(7604).\n\n\nBishop, D. (2019). The psychology of experimental psychologists: Overcoming cognitive constraints to improve research.\n\n\nCollaboration, O. S. (2015). Estimating the reproducibility of psychological science. Science, 349(6251), aac4716.\n\n\nIoannidis, J. P. (2005). Why most published research findings are false. PLoS medicine, 2(8), e124.\n\n\nLabatut, B. (2021). Quando abbiamo smesso di capire il mondo. Adelphi Edizioni spa.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nMeehl, P. E. (1967). Theory-testing in psychology and physics: A methodological paradox. Philosophy of science, 34(2), 103–115.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>La crisi di replicazione e la riforma metodologica in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html",
    "href": "chapters/key_notions/02_key_notions.html",
    "title": "2  Concetti chiave",
    "section": "",
    "text": "Introduzione\nNella ricerca scientifica, la formulazione di risposte a specifiche domande di indagine avviene attraverso l’applicazione di metodologie rigorose e l’esecuzione di osservazioni accurate e controllate. Le informazioni raccolte mediante diverse tecniche di indagine—come ricerche sul campo, indagini campionarie e protocolli sperimentali—vengono definite con il termine tecnico di dati. Questo capitolo introduce i principi fondamentali dell’analisi dei dati, concentrandosi sia sulle caratteristiche dei dati stessi sia sui metodi di raccolta.\nL’analisi dei dati permette di sintetizzare grandi quantità di informazioni e di verificare le previsioni avanzate dalle teorie. Tuttavia, senza una teoria che dia significato ai dati, le osservazioni rimangono mere descrizioni prive di un contesto esplicativo. È attraverso l’integrazione tra dati e teoria che si raggiunge una comprensione profonda dei fenomeni e si favorisce l’avanzamento scientifico [es., Wertheimer (1880–1943), scoperta del movimento-\\(\\phi\\) e nascita del movimento della Gestalt; Steinman et al. (2000)].",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#introduzione",
    "href": "chapters/key_notions/02_key_notions.html#introduzione",
    "title": "2  Concetti chiave",
    "section": "",
    "text": "Statistica\n\n\n\n\n\nIl termine “statistica” può assumere diversi significati a seconda del contesto:\n\nPrimo significato: La statistica è una scienza che si occupa dello studio e dell’applicazione di metodi per la raccolta, organizzazione, analisi, interpretazione e presentazione dei dati.\nSecondo significato: Il termine si riferisce a una misura o valore numerico calcolato a partire da un campione di dati, come la media campionaria, la deviazione standard campionaria o il coefficiente di correlazione campionario.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#la-spiegazione-scientifica",
    "href": "chapters/key_notions/02_key_notions.html#la-spiegazione-scientifica",
    "title": "2  Concetti chiave",
    "section": "2.1 La spiegazione scientifica",
    "text": "2.1 La spiegazione scientifica\nLa scienza non si limita a descrivere o prevedere i fenomeni: il suo obiettivo principale è spiegare il perché degli eventi, offrendo una comprensione approfondita delle cause e dei meccanismi che li regolano. La spiegazione scientifica è cruciale per costruire teorie capaci non solo di descrivere e prevedere, ma anche di chiarire le dinamiche causali e le connessioni tra i fenomeni, contribuendo a un controllo più consapevole e informato su di essi.\nConsideriamo, ad esempio, il rapporto tra il background familiare e il rendimento scolastico. Numerose ricerche evidenziano una forte correlazione tra il livello di istruzione dei genitori e il successo accademico dei figli. Una prospettiva puramente descrittiva potrebbe limitarsi a constatare che: “Gli studenti provenienti da famiglie con basso livello di istruzione hanno minori probabilità di conseguire un titolo universitario”. Tuttavia, la vera sfida scientifica consiste nell’andare oltre questa previsione, ponendosi domande più profonde:\n\nquali meccanismi causali determinano questa disparità?\n\nquali interventi possono efficacemente ridurre tali disuguaglianze?\n\nPer superare il livello di semplice previsione, la ricerca deve identificare i fattori causali alla base del fenomeno, in modo da comprendere come l’azione su questi fattori possa modificare gli esiti. Nel caso dell’esempio sul rapporto tra background familiare e rendimento scolastico, ciò implica comprendere, ad esempio:\n\nse e in che modo il sostegno finanziario possa favorire il percorso degli studenti svantaggiati;\nquali politiche educative possano produrre effetti positivi sul lungo termine;\ncome i meccanismi sociali e individuali influenzino il processo educativo.\n\nAcquisire una conoscenza approfondita dei meccanismi causali permette di andare oltre la semplice previsione, rendendo possibile la progettazione di interventi mirati e strategici che possano realmente incidere sui fenomeni in modo efficace e duraturo.\n\n2.1.1 Elementi fondamentali della spiegazione scientifica\nLa filosofia della scienza identifica tre componenti fondamentali di una spiegazione scientifica:\n\nExplanandum. È il fenomeno che desideriamo comprendere, ovvero ciò di cui cerchiamo le cause o i meccanismi. Un esempio: “Gli studenti con alti livelli di ansia da prestazione ottengono punteggi più bassi nei test scolastici rispetto ai loro pari.”\nExplanans. È l’insieme dei fattori che spiegano il fenomeno. Nel caso dell’ansia da prestazione, un possibile explanans potrebbe essere: “L’ansia danneggia la concentrazione e la memoria di lavoro, influendo negativamente sulla performance nei test.”\nLegame esplicativo. Comprende i principi o i meccanismi che dimostrano come l’explanans produca l’explanandum. Seguendo l’esempio precedente: “Livelli elevati di ansia innescano il sistema nervoso simpatico, aumentando lo stress fisiologico e riducendo l’efficienza dei processi cognitivi necessari per compiti complessi.”\n\nQuesti tre elementi si combinano all’interno di modelli scientifici, che costituiscono le strutture teoriche e metodologiche impiegate per formulare e verificare spiegazioni. In psicologia, tali modelli includono:\n\nil fenomeno da spiegare (ad es. le prestazioni scolastiche);\ni fattori che lo influenzano (ad es. ansia, regolazione emotiva);\ni meccanismi sottostanti che collegano cause ed effetti (ad es. attivazione fisiologica, memoria di lavoro compromessa).\n\nUn modello psicologico sull’ansia da prestazione, ad esempio, potrebbe considerare la relazione tra livello di ansia percepita, capacità di regolazione emotiva e memoria di lavoro. A differenza di modelli esclusivamente descrittivi o predittivi, i modelli esplicativi rispondono a domande causali: non si limitano ad attestare che ansia e prestazioni sono correlate, ma mostrano come e perché l’ansia riduca il rendimento. Inoltre, tali modelli suggeriscono strategie d’intervento per attenuare l’effetto dell’ansia, come il potenziamento della regolazione emotiva o l’uso di tecniche di gestione dello stress.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#modelli-psicologici",
    "href": "chapters/key_notions/02_key_notions.html#modelli-psicologici",
    "title": "2  Concetti chiave",
    "section": "2.2 Modelli psicologici",
    "text": "2.2 Modelli psicologici\nUn modello è una rappresentazione concettuale – spesso supportata da formalismi matematici – di un fenomeno reale, basata su un insieme di equazioni e ipotesi che descrivono le relazioni tra variabili e la struttura probabilistica sottostante. L’obiettivo è coglierne gli aspetti essenziali senza includere ogni dettaglio superfluo, formulando predizioni quantitative che possano essere verificate empiricamente. Poiché spesso esistono molteplici modelli in grado di spiegare lo stesso fenomeno, il compito della ricerca consiste nel selezionare quello che meglio descrive i dati e soddisfa criteri di validità, accuratezza e parsimonia.\nI modelli psicologici, in particolare, sono strumenti teorici finalizzati a descrivere, spiegare e prevedere il comportamento umano e i processi mentali. Un modello ben costruito dovrebbe possedere le seguenti caratteristiche:\n\nCoerenza descrittiva. Il modello deve fornire una rappresentazione logica e coerente del fenomeno, includendo tutti gli elementi chiave del processo psicologico e organizzando le osservazioni in una struttura interpretativa chiara.\nCapacità predittiva. Deve essere in grado di formulare previsioni verificabili e di produrre ipotesi testabili sulla base dei dati raccolti, permettendo così di valutare la validità del modello.\nSupporto empirico. Le previsioni e le ipotesi del modello vanno confrontate con l’evidenza empirica, ottenuta attraverso ricerche sistematiche e rigorose. I dati devono corroborare le relazioni proposte dal modello.\nFalsificabilità. Il modello deve poter essere sottoposto a verifica empirica e, all’occorrenza, smentito. Se emergono osservazioni in conflitto con le sue previsioni, il modello deve essere revisionato o sostituito.\nParsimonia. La spiegazione deve risultare semplice e lineare, includendo solo gli elementi indispensabili per rendere conto del fenomeno. Assunzioni superflue o ridondanti ne riducono la robustezza.\nGeneralizzabilità. Il modello dovrebbe poter essere esteso a contesti e situazioni diverse, superando i limiti di specifiche condizioni sperimentali o campioni ristretti.\nUtilità pratica. Dovrebbe offrire linee guida concrete per l’applicazione nel mondo reale, ad esempio negli interventi clinici, nei programmi di prevenzione o nelle terapie, così da avere un impatto positivo sugli individui e sulla società.\n\nUno degli ostacoli maggiori nella costruzione di modelli in psicologia è la natura soggettiva, dinamica e variabile dell’esperienza umana. È quindi necessario bilanciare la precisione teorica (spesso supportata da formalizzazioni matematiche o computazionali) con la flessibilità necessaria a catturare l’eterogeneità dei fenomeni psicologici. A questo si aggiungono i vincoli etici della ricerca sull’essere umano e le potenziali ricadute sociali dei risultati.\nL’analisi quantitativa dei dati gioca un ruolo centrale nella validazione dei modelli psicologici: mediante metodologie statistiche e computazionali avanzate, i ricercatori possono verificare se le predizioni di un modello trovano riscontro nei dati empirici e se tali predizioni si mantengono valide in contesti diversi. Questo processo non solo consolida la comprensione del fenomeno, ma consente anche di anticipare e, in alcune circostanze, influenzare il comportamento e i processi mentali. Un modello rigorosamente formulato e testabile diviene quindi un potente strumento per lo sviluppo di interventi efficaci e il progresso teorico.\n\n2.2.1 Rappresentare i fenomeni per ragionare e comunicare\nLa spiegazione scientifica non si limita a far luce sui meccanismi causali, ma fornisce anche un linguaggio formale per analizzare e condividere conoscenze sui fenomeni. In psicologia, i modelli scientifici costituiscono strumenti fondamentali per descrivere i processi attraverso variabili, funzioni e parametri, offrendo una struttura che facilita l’individuazione di relazioni e proprietà essenziali. Un modello efficace semplifica la complessità del fenomeno, agevolando sia la comunicazione tra studiosi sia la comprensione intuitiva.\nInoltre, i modelli non si limitano a organizzare le informazioni esistenti: stimolano anche l’emergere di nuove ipotesi di ricerca, promuovono collegamenti tra concetti apparentemente lontani e consentono di trasferire conoscenze tra discipline, ampliando così l’orizzonte dell’indagine scientifica.\n\n\n2.2.2 Il ruolo dell’analisi dei dati\nL’analisi dei dati è parte integrante del metodo scientifico e, in psicologia, assolve due funzioni primarie:\n\nSemplificare e sintetizzare informazioni complesse\nAttraverso statistiche descrittive, rappresentazioni grafiche e altre tecniche di sintesi, l’analisi dei dati aiuta a individuare schemi, tendenze e anomalie. Questo passaggio è essenziale per comprendere le differenze tra individui o gruppi e per formulare ipotesi di ricerca più mirate.\nValutare le predizioni dei modelli\nConfrontando i dati raccolti con le previsioni teoriche, si misura la validità di un modello. Tale confronto è indispensabile per confermare, raffinare o rivedere le ipotesi di partenza, orientando così il progresso della conoscenza scientifica.\n\nTuttavia, limitarsi alla ricerca di correlazioni o di pattern nei dati, senza un solido quadro teorico, non basta a comprendere pienamente il fenomeno. Risultati empirici privi di spiegazioni causali rimangono frammentari. Per questo motivo, integrare i dati in un modello teorico esplicativo è cruciale: si possono così proporre meccanismi causali, identificare relazioni e avanzare nuove ipotesi di ricerca.\n\n\n2.2.3 Carattere multidisciplinare dell’analisi dei dati\nPer rispondere alle complesse domande poste in psicologia, l’analisi dei dati si fonda sull’integrazione di più discipline: statistica, teoria della probabilità e informatica. Ciascuna offre contributi indispensabili per affrontare la complessità dei processi psicologici:\n\nStatistica\nFornisce tecniche per la raccolta, l’organizzazione e l’interpretazione dei dati, consentendo di riassumere le informazioni, individuare pattern significativi e valutare empiricamente le ipotesi dei modelli psicologici.\nTeoria della probabilità\nCostituisce la base matematica della statistica e della modellazione scientifica, offrendo strumenti per quantificare l’incertezza, descrivere la variabilità delle osservazioni e costruire modelli predittivi rigorosi.\nInformatica\nContribuisce con strumenti per la gestione, l’analisi e la visualizzazione di grandi quantità di dati, nonché per l’implementazione di modelli computazionali sofisticati. Questi modelli si rivelano fondamentali nel simulare e testare dinamiche dei processi psicologici.\n\nLa natura multidisciplinare dell’analisi dei dati rispecchia l’esigenza di competenze diverse per comprendere e modellizzare i fenomeni psicologici in modo rigoroso. L’approccio quantitativo e computazionale ai modelli non si limita a descrivere e interpretare i dati, ma consente di formulare predizioni precise e sottoponibili a verifica, contribuendo così all’avanzamento della psicologia come scienza.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#concetti-chiave-nellanalisi-dei-dati",
    "href": "chapters/key_notions/02_key_notions.html#concetti-chiave-nellanalisi-dei-dati",
    "title": "2  Concetti chiave",
    "section": "2.3 Concetti chiave nell’analisi dei dati",
    "text": "2.3 Concetti chiave nell’analisi dei dati\nPer condurre un’analisi dei dati efficace, è fondamentale comprendere alcuni concetti chiave che guidano il processo di indagine, dall’identificazione del fenomeno alla formulazione di inferenze.\n\n2.3.1 Popolazioni e campioni\nL’analisi dei dati inizia con l’identificazione della popolazione di interesse, che rappresenta l’insieme completo degli individui o delle entità coinvolte nel fenomeno studiato. Poiché studiare un’intera popolazione è spesso impraticabile, si ricorre ai campioni, sottoinsiemi rappresentativi della popolazione. La qualità e la rappresentatività del campione sono cruciali: un campione non rappresentativo può portare a conclusioni errate, limitando la generalizzabilità dei risultati.\n\n\n\n\n\n\nParametri e statistiche\n\n\n\n\n\nUn parametro è una caratteristica numerica della popolazione (es. media \\(\\mu\\), deviazione standard \\(\\sigma\\)). Una statistica è una caratteristica numerica calcolata sul campione (es. media campionaria \\(\\bar{x}\\), deviazione standard campionaria \\(s\\)). L’inferenza statistica si occupa di stimare i parametri della popolazione a partire dalle statistiche campionarie.\n\n\n\n\n\n2.3.2 Bias nella raccolta dei dati\nI bias nella raccolta e interpretazione dei dati possono compromettere l’accuratezza dei risultati. Comprendere chi ha raccolto i dati, come e con quali scopi è essenziale per una corretta interpretazione (Johnson et al., 2022). I dati non sono mai completamente neutri; i metodi e gli obiettivi di raccolta influenzano i risultati. Ad esempio, selezionare partecipanti da una popolazione di studenti universitari potrebbe introdurre un bias sistematico, limitando la generalizzabilità ad altri contesti (Murray & Carr, 2024; Nobles, 2000).\n\n\n2.3.3 Variabili e costanti\nNell’analisi statistica, le variabili rappresentano le caratteristiche osservate che possono assumere diversi valori (numerici o categorici). Le costanti, al contrario, rimangono fisse in un determinato contesto. Le variabili si distinguono in:\n\nvariabili indipendenti (o predittive): influenzano altri fenomeni;\n\nvariabili dipendenti: rappresentano gli esiti di interesse influenzati dalle variabili indipendenti.\n\nAd esempio, in uno studio sugli effetti della terapia cognitivo-comportamentale, la variabile indipendente potrebbe essere la partecipazione alla terapia, mentre la variabile dipendente sarebbe la riduzione dei sintomi di ansia.\n\n\n2.3.4 Studi osservazionali ed esperimenti\nEsistono due principali metodi di raccolta dati.\n\nEsperimenti: I ricercatori manipolano una o più variabili per valutare il loro effetto su altre variabili, controllando per i fattori confondenti. Ad esempio, per valutare l’efficacia di un trattamento, i partecipanti possono essere assegnati casualmente a un gruppo di controllo (placebo) e a un gruppo sperimentale (trattamento attivo). La randomizzazione riduce il rischio di bias sistematici.\nStudi osservazionali: I dati vengono raccolti senza interferire con il fenomeno osservato. Ad esempio, un’indagine su come lo stress influenza la produttività lavorativa potrebbe basarsi su questionari senza manipolare lo stress dei partecipanti. Questi studi forniscono correlazioni tra variabili, ma non dimostrano relazioni causali.\n\n\n\n2.3.5 Effetti\nIn statistica, un effetto rappresenta il cambiamento osservato nella variabile dipendente in relazione a una variabile indipendente. Questo cambiamento può indicare un’associazione tra le due variabili, ma la sua interpretazione come relazione causale dipende strettamente dal disegno sperimentale con cui i dati sono stati raccolti.\nAd esempio, se si osserva una riduzione dei sintomi tra la fase pre-trattamento e quella post-trattamento in un gruppo di pazienti sottoposti a una terapia, è possibile identificare un effetto della terapia. Tuttavia, senza un disegno sperimentale adeguato – come un esperimento controllato randomizzato (RCT) – non è possibile stabilire con certezza che la riduzione dei sintomi sia causata dalla terapia e non da altri fattori, come il decorso naturale della malattia o l’effetto placebo (Huntington-Klein, 2021).\nI modelli statistici, da soli, non possono determinare relazioni causali: possono quantificare l’entità di un effetto e valutare la forza dell’associazione tra variabili, ma la causalità può essere inferita solo se i dati provengono da un disegno sperimentale che isola il meccanismo di interesse, controllando per possibili fattori di confondimento. Pertanto, per trarre conclusioni causali robuste, è essenziale integrare l’analisi statistica con un approccio metodologico rigoroso basato su strategie di manipolazione sperimentale, assegnazione casuale o tecniche avanzate per il controllo dei bias nei dati osservazionali.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#stima-e-inferenza-statistica-dal-campione-alla-popolazione",
    "href": "chapters/key_notions/02_key_notions.html#stima-e-inferenza-statistica-dal-campione-alla-popolazione",
    "title": "2  Concetti chiave",
    "section": "2.4 Stima e inferenza statistica: dal campione alla popolazione",
    "text": "2.4 Stima e inferenza statistica: dal campione alla popolazione\nLa stima e l’inferenza statistica costituiscono i pilastri della metodologia quantitativa, poiché permettono di estendere le conclusioni tratte da un campione – una porzione limitata di individui osservati – all’intera popolazione di interesse. L’uso dei campioni risulta indispensabile a causa dei vincoli di tempo, costi e risorse, che spesso rendono impossibile lo studio dell’intera popolazione.\nTuttavia, il ricorso al campione introduce inevitabilmente un’incertezza intrinseca: le statistiche campionarie (come media o varianza del campione) sono stime dei parametri della popolazione e di norma non coincidono esattamente con i valori “veri” della popolazione. Tale discrepanza è nota come errore di campionamento, la cui entità dipende, tra l’altro, dalla dimensione del campione e dalla strategia di campionamento adottata.\nLa teoria degli stimatori e gli strumenti di inferenza statistica (ad esempio, intervalli di confidenza in un approccio frequentista o intervalli di credibilità in un approccio bayesiano) consentono di quantificare e gestire quest’incertezza, fornendo un quadro che permette di trarre conclusioni credibili sulla popolazione partendo dai dati raccolti.\n\n2.4.1 Stima: inferire le caratteristiche della popolazione\nLa stima è il processo con cui, a partire dai dati di un campione, si inferiscono proprietà della popolazione, come la media o la varianza. Poiché ogni campione rappresenta solo una frazione della popolazione, può fornire stime diverse; questo fenomeno è noto come variabilità campionaria. Proprio tale variabilità costituisce la principale fonte di incertezza nelle inferenze: se un singolo campione non è sufficientemente ampio o rappresentativo, la stima potrebbe discostarsi in misura rilevante dai valori effettivi presenti nella popolazione.\n\n2.4.1.1 Fattori che influenzano l’accuratezza\nTre fattori fondamentali influiscono sull’accuratezza di una stima:\n\nDimensione del campione. Un campione più grande tende a ridurre la variabilità campionaria, aumentando la precisione delle stime.\nRappresentatività. Un campione ben progettato e rappresentativo rispecchia le caratteristiche essenziali della popolazione. Al contrario, un campione distorto (ad esempio, selezionato per convenienza) può condurre a stime fuorvianti.\nVariabilità della popolazione. Se la popolazione è estremamente eterogenea, sono necessari campioni più ampi per produrre stime affidabili.\n\n\n\n2.4.1.2 Gli stimatori: proprietà fondamentali\nGli stimatori sono formule matematiche o procedure statistiche usate per calcolare le stime. La loro qualità si valuta principalmente in base a:\n\nConsistenza. Uno stimatore è consistente se, all’aumentare della dimensione del campione, la stima tende a convergere verso il valore reale del parametro.\nNon distorsione (unbiasedness). Uno stimatore è non distorto se il suo valore atteso corrisponde al parametro della popolazione. In altri termini, in media, lo stimatore coincide con il valore reale.\nEfficienza. Tra stimatori non distorti, è più efficiente quello con varianza minore, poiché fornisce stime più stabili.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#inferenza-statistica",
    "href": "chapters/key_notions/02_key_notions.html#inferenza-statistica",
    "title": "2  Concetti chiave",
    "section": "2.5 Inferenza statistica",
    "text": "2.5 Inferenza statistica\nL’inferenza statistica si basa sulle stime campionarie per trarre conclusioni sull’intera popolazione. In particolare, risponde a tre grandi interrogativi:\n\nStima dei parametri della popolazione. Ottenere valori plausibili per parametri quali media, varianza e proporzioni, quantificando contestualmente l’incertezza (ad esempio, costruendo intervalli di confidenza o di credibilità).\nValutazione di ipotesi. Confrontare ipotesi rivali, come l’esistenza di differenze tra gruppi o di relazioni tra variabili. Attraverso il confronto tra ipotesi e dati, si determina quale ipotesi è meglio supportata.\nPrevisione. Utilizzare i dati esistenti per anticipare risultati futuri, tenendo conto delle fonti di incertezza legate sia alla variabilità intrinseca dei dati sia ai parametri non perfettamente noti.\n\nSia l’approccio frequentista sia quello bayesiano affrontano questi problemi in modo rigoroso, ma differiscono nel modo di concettualizzare l’incertezza e di incorporare l’informazione nei modelli.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#le-sfide-dellinferenza-statistica-in-psicologia",
    "href": "chapters/key_notions/02_key_notions.html#le-sfide-dellinferenza-statistica-in-psicologia",
    "title": "2  Concetti chiave",
    "section": "2.6 Le sfide dell’inferenza statistica in psicologia",
    "text": "2.6 Le sfide dell’inferenza statistica in psicologia\nIn psicologia e, più in generale, nelle scienze sociali, l’inferenza statistica incontra specifiche problematiche spesso connesse alla complessità dei fenomeni oggetto di studio (Gelman et al., 2021). Tra le sfide principali figurano:\n\nLimiti nella generalizzazione dei risultati. In molti studi psicologici, le condizioni sperimentali create in laboratorio o in ambienti altamente controllati non sempre rispecchiano le dinamiche reali in cui i fenomeni si manifestano. L’uso di procedure standardizzate e compiti artificiali può semplificare notevolmente le variabili in gioco, a scapito della validità esterna: i risultati ottenuti potrebbero non essere direttamente trasferibili a contesti naturali o situazioni di vita quotidiana. Inoltre, se i partecipanti vengono selezionati per ragioni pratiche (ad esempio, studenti universitari reclutati su base volontaria), ciò limita ulteriormente la rappresentatività del campione, rendendo più difficile estendere le conclusioni a gruppi più eterogenei o a popolazioni diverse.\nRischio di semplificare eccessivamente i meccanismi causali ipotizzati. L’inferenza causale – implicita o esplicita nella maggior parte delle ricerche in psicologia – mira a comprendere se e come un fattore influisca su un altro. Tuttavia, in contesti così complessi, i modelli causali proposti possono risultare eccessivamente semplificati, trascurando interazioni tra variabili, fattori contestuali o processi multilivello. Quando tali aspetti non vengono adeguatamente considerati, le conclusioni possono rivelarsi poco utili o non sufficientemente applicabili ai contesti reali.\nDistorsioni legate alla misurazione. Molti costrutti di interesse psicologico (es. ansia, autostima, intelligenza) non sono direttamente osservabili, bensì misurati attraverso questionari, test o altre metodologie indirette. Tale approccio introduce possibili errori di misurazione e distorsioni legate allo strumento di valutazione. L’inferenza statistica deve quindi tenere conto di questa complessità, collegando in modo rigoroso le osservazioni empiriche ai costrutti teorici sottostanti.\n\nIn sintesi, la stima e l’inferenza statistica rappresentano strumenti fondamentali per trasformare i dati campionari in conoscenza generalizzabile, soprattutto in un contesto come quello psicologico, caratterizzato da un’elevata variabilità nei comportamenti e nei processi mentali. Da un lato, la metodologia quantitativa offre un quadro consolidato per gestire l’incertezza e testare ipotesi; dall’altro, è cruciale prestare attenzione alla qualità del campione, alla validità degli strumenti di misura e all’intrinseca complessità dei costrutti indagati.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#la-quantificazione-dellincertezza",
    "href": "chapters/key_notions/02_key_notions.html#la-quantificazione-dellincertezza",
    "title": "2  Concetti chiave",
    "section": "2.7 La quantificazione dell’incertezza",
    "text": "2.7 La quantificazione dell’incertezza\nLe considerazioni introduttive di questo capitolo mettono in evidenza come la gestione e la quantificazione dell’incertezza rappresentino un aspetto cruciale della stima e dell’inferenza statistica. Qualunque stima ottenuta da un campione è inevitabilmente soggetta a errore, poiché il campione costituisce soltanto una frazione della popolazione di riferimento. L’inferenza statistica offre gli strumenti necessari per quantificare tale incertezza, ad esempio tramite gli intervalli di confidenza (nell’approccio frequentista) o le distribuzioni a posteriori (nell’approccio bayesiano), consentendo di esprimere in modo rigoroso il grado di fiducia nelle conclusioni raggiunte.\nIn conclusione, la stima e l’inferenza statistica rappresentano strumenti essenziali per trasformare i dati empirici in conoscenza solida e applicabile. È tuttavia indispensabile avvalersene in maniera critica, tenendo sempre presenti le possibili distorsioni insite nel processo di raccolta e analisi dei dati. Ciò significa prestare particolare attenzione alla rappresentatività del campione, alla validità delle misurazioni e all’interpretazione corretta dei risultati, così da evitare generalizzazioni indebite o conclusioni fuorvianti.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#riflessioni-conclusive",
    "href": "chapters/key_notions/02_key_notions.html#riflessioni-conclusive",
    "title": "2  Concetti chiave",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nL’analisi dei dati acquisisce valore solo quando è integrata con una solida teoria scientifica, che fornisce il contesto e il quadro interpretativo necessario per attribuire senso ai risultati. Ad esempio, osservare che un trattamento psicologico riduce i sintomi è un’osservazione empirica che, senza una teoria che chiarisca i meccanismi sottostanti, rimane priva di potere esplicativo. È la teoria che orienta il processo analitico, formulando ipotesi verificabili e offrendo interpretazioni che si inseriscono in un modello più ampio.\nIn definitiva, la relazione tra teoria e analisi dei dati è intrinsecamente circolare e dinamica: le teorie guidano la raccolta, l’analisi e l’interpretazione dei dati, mentre i dati, a loro volta, stimolano il perfezionamento e l’evoluzione delle teorie. Questo dialogo continuo è ciò che permette un progresso costante nella comprensione dei fenomeni psicologici.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#esercizi",
    "href": "chapters/key_notions/02_key_notions.html#esercizi",
    "title": "2  Concetti chiave",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nChe cos’è una spiegazione scientifica e in che modo si differenzia da una mera descrizione o previsione di un fenomeno?\nPerché, quando si parla di popolazione e campione, è fondamentale assicurarsi che il campione sia rappresentativo, e quali conseguenze possono derivare da un campione non rappresentativo?\nChe differenza c’è tra un parametro e una statistica, e perché in inferenza statistica si cerca di stimare il parametro sconosciuto a partire dalla statistica campionaria?\nCosa si intende per bias nella raccolta e interpretazione dei dati, e in che modo la consapevolezza dei possibili bias può migliorare la qualità della ricerca?\nPerché in psicologia e nelle scienze sociali risulta essenziale integrare l’analisi dei dati con un quadro teorico solido e coerente?\nQual è la differenza principale tra uno studio osservazionale e un esperimento, e perché la distinzione è importante per comprendere la causalità?\nChe ruolo svolgono i modelli scientifici in psicologia, e quali caratteristiche fondamentali dovrebbero possedere per essere considerati validi e utili?\nIn che modo l’analisi dei dati aiuta a passare dalle semplici correlazioni o tendenze osservate all’elaborazione di ipotesi e spiegazioni più profonde?\nChe differenza c’è tra variabili indipendenti e variabili dipendenti, e perché questa distinzione è cruciale per disegnare uno studio e interpretarne i risultati?\nPerché parlare di incertezza è inevitabile quando si utilizzano i dati di un campione, e come la statistica (frequentista o bayesiana) ci aiuta a gestirla?\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n1. Che cos’è una spiegazione scientifica e in che modo si differenzia da una mera descrizione o previsione di un fenomeno?\nUna spiegazione scientifica mira a individuare le cause e i meccanismi che generano o influenzano un fenomeno. Non si limita quindi a descrivere cosa accade o a prevedere ciò che potrebbe accadere (come una semplice correlazione o un modello predittivo), ma cerca di chiarire perché il fenomeno si verifica. Ad esempio, dire “i bambini con genitori laureati hanno migliori prestazioni scolastiche” è una descrizione (o previsione) utile; spiegare che ciò avviene a causa di un maggior sostegno nel percorso di studi, di un ambiente più ricco di stimoli culturali, o di un contesto socioeconomico facilitante, fornisce invece una spiegazione che va oltre la pura correlazione statistica.\n2. Perché, quando si parla di popolazione e campione, è fondamentale assicurarsi che il campione sia rappresentativo, e quali conseguenze possono derivare da un campione non rappresentativo?\nIl campione è il sottoinsieme di individui selezionati da una popolazione più ampia. Affinché i risultati di uno studio siano validi e generalizzabili, il campione deve rispecchiare le principali caratteristiche della popolazione (ad esempio in termini di età, genere, livello socioeconomico, ecc.). Se il campione non è rappresentativo (per esempio, se si reclutano solo studenti universitari per uno studio su tutta la popolazione italiana), possono emergere bias di selezione che rendono impossibile estendere correttamente i risultati a gruppi sociali diversi. Conseguenze tipiche di un campione non rappresentativo includono stime distorte dei parametri d’interesse, conclusioni fuorvianti e ridotta validità esterna della ricerca.\n3. Che differenza c’è tra un parametro e una statistica, e perché in inferenza statistica si cerca di stimare il parametro sconosciuto a partire dalla statistica campionaria?\n\nUn parametro è una caratteristica numerica della popolazione (ad esempio la media reale di un determinato tratto o la proporzione di individui con una certa caratteristica).\n\nUna statistica è una misura analoga, ma calcolata sul campione (ad esempio la media o la proporzione campionaria).\n\nPoiché in genere è impossibile o molto costoso misurare l’intera popolazione, si raccoglie un campione più piccolo e gestibile. La statistica del campione (ad es. la media campionaria) è quindi usata per stimare il parametro (ad es. la media della popolazione). L’obiettivo dell’inferenza statistica è fornire, insieme a questa stima, una misura dell’incertezza associata (per esempio un intervallo di confidenza), così da comprendere quanto la statistica campionaria potrebbe “avvicinarsi” al vero valore del parametro.\n4. Cosa si intende per bias nella raccolta e interpretazione dei dati, e in che modo la consapevolezza dei possibili bias può migliorare la qualità della ricerca?\nIl bias è un errore sistematico che altera i risultati di uno studio in una direzione specifica, dovuto a scelte o condizioni nel disegno della ricerca, nella selezione del campione, nella misurazione o nell’interpretazione dei dati. Ad esempio, se reclutiamo solo volontari particolarmente motivati a partecipare a una ricerca, potremmo ottenere risultati che sovrastimano un certo fenomeno e non rispecchiano la popolazione generale.\nEssere consapevoli di come i bias possano nascere aiuta i ricercatori a mitigarli (ad esempio, bilanciando il reclutamento dei partecipanti o rendendo anonima la compilazione di un questionario) e a tenere conto dei loro effetti quando si interpretano i risultati. Così, la ricerca risulta più affidabile e validamente interpretata.\n5. Perché in psicologia e nelle scienze sociali risulta essenziale integrare l’analisi dei dati con un quadro teorico solido e coerente?\nNelle scienze sociali e in psicologia, i fenomeni studiati sono spesso complessi e influenzati da molte variabili. I dati da soli, senza una teoria, forniscono soltanto una descrizione o una misurazione di ciò che accade in un dato momento. La teoria invece permette di:\n\nIdentificare le variabili rilevanti e formulare ipotesi specifiche;\n\nInterpretare i risultati, attribuendo un senso e un contesto alle relazioni osservate;\n\nComprendere i meccanismi causali e sviluppare spiegazioni che vadano oltre la pura descrizione.\n\nSenza un quadro teorico di riferimento, sarebbe difficile capire perché si osservano determinate relazioni e come possano cambiare in contesti diversi o in situazioni sperimentali alternative.\n6. Qual è la differenza principale tra uno studio osservazionale e un esperimento, e perché la distinzione è importante per comprendere la causalità?\n\nStudio osservazionale: Il ricercatore raccoglie i dati senza intervenire né manipolare alcuna variabile. Ad esempio, si misura il livello di stress delle persone e la loro produttività sul lavoro, senza modificare artificialmente il livello di stress. Questi studi mostrano correlazioni, ma è difficile stabilire con certezza relazioni di causa-effetto.\n\nEsperimento: Il ricercatore manipola una o più variabili (variabili indipendenti) e controlla le condizioni, ad esempio assegnando in modo casuale i partecipanti a un gruppo di trattamento e a uno di controllo. Ciò facilita la comprensione di eventuali nessi causali, perché la randomizzazione e il controllo degli altri fattori riducono il rischio che variabili esterne influenzino i risultati.\n\nLa distinzione è cruciale perché, nei fenomeni complessi della psicologia, gli studi osservazionali possono suggerire ipotesi di relazione, ma di solito occorre un disegno sperimentale (quando possibile) per trarre conclusioni più solide sulla causalità.\n7. Che ruolo svolgono i modelli scientifici in psicologia, e quali caratteristiche fondamentali dovrebbero possedere per essere considerati validi e utili?\nI modelli scientifici in psicologia forniscono una struttura concettuale e spesso formale (matematica o simulativa) per rappresentare e spiegare processi mentali e comportamentali. Servono a:\n\nOrganizzare osservazioni ed evidenze in un sistema coerente;\n\nFare previsioni verificabili empiricamente;\n\nGuidare l’interpretazione di nuovi dati e la progettazione di futuri studi.\n\nCaratteristiche di un buon modello sono:\n\nCoerenza descrittiva (rappresenta fedelmente il fenomeno);\n\nCapacità predittiva (prevede correttamente i risultati di situazioni nuove);\n\nSupporto empirico (confermato dai dati raccolti rigorosamente);\n\nFalsificabilità (dev’essere possibile smentirlo con evidenze contrarie);\n\nParsimonia (non dev’essere inutilmente complicato);\n\nGeneralizzabilità (applicabile a diversi contesti e situazioni);\n\nUtilità pratica (fornisce indicazioni utili per interventi o comprensione teorica).\n\n8. In che modo l’analisi dei dati aiuta a passare dalle semplici correlazioni o tendenze osservate all’elaborazione di ipotesi e spiegazioni più profonde?\nL’analisi dei dati non si limita a segnalare che “due variabili sono associate” (correlazioni), ma offre:\n\nStrumenti per isolare l’effetto di una variabile sulle altre (regressioni multiple, modelli a effetti misti, ecc.);\n\nMetodologie per la verifica di ipotesi specifiche sulla direzione e sulla natura delle relazioni (ad es. test statistici o modelli di mediazione-moderazione in psicologia);\n\nIndicatori dell’incertezza e della robustezza dei risultati (intervalli di confidenza, analisi della potenza, analisi bayesiane).\n\nCon questi strumenti, i ricercatori possono integrare i risultati quantitativi con le teorie esistenti, sviluppare nuove ipotesi su meccanismi causali e proporre spiegazioni più articolate su come e perché le variabili si influenzino reciprocamente.\n9. Che differenza c’è tra variabili indipendenti e variabili dipendenti, e perché questa distinzione è cruciale per disegnare uno studio e interpretarne i risultati?\n\nVariabile indipendente (VI): è quella che si sospetta abbia un effetto su un’altra variabile, o che si desidera manipolare in un disegno sperimentale (per esempio, l’introduzione di un nuovo metodo di studio).\n\nVariabile dipendente (VD): è la variabile che si misura per valutare l’eventuale effetto della variabile indipendente (ad esempio, i risultati di un test di apprendimento).\nLa distinzione è basilare perché chiarisce la direzione del rapporto di interesse e permette di formulare ipotesi come “VI → VD” (es. “il nuovo metodo di studio migliora i risultati del test”). Sbagliare a identificare quali sono le variabili indipendenti e dipendenti può portare a disegni di ricerca confusi e interpretazioni errate.\n\n10. Perché parlare di incertezza è inevitabile quando si utilizzano i dati di un campione, e come la statistica (frequentista o bayesiana) ci aiuta a gestirla?\nQuando raccogliamo dati da un campione (necessariamente limitato), non possiamo osservare l’intera popolazione. Questo introduce un margine di incertezza su quanto la misura campionaria (statistica) rispecchi il parametro reale della popolazione. Inoltre, possono sempre esserci fattori non controllati o errori di misurazione.\n\nNell’approccio frequentista, l’incertezza è gestita tramite concetti come gli intervalli di confidenza e i valori p, che quantificano la probabilità di osservare determinati risultati assumendo determinate ipotesi (per es. l’ipotesi nulla).\n\nNell’approccio bayesiano, l’incertezza è modellata tramite distribuzioni di probabilità (posteriori) che incorporano sia i dati osservati sia le informazioni pregresse (priors).\n\nEntrambi gli approcci forniscono metodologie per valutare quanto ci si possa fidare di una data conclusione, riconoscendo il carattere aleatorio e parziale dei dati e rendendo esplicito il grado di incertezza.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#bibliografia",
    "href": "chapters/key_notions/02_key_notions.html#bibliografia",
    "title": "2  Concetti chiave",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.\n\n\nHuntington-Klein, N. (2021). The effect: An introduction to research design and causality. Chapman; Hall/CRC.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nMurray, E. J., & Carr, K. C. (2024). Measuring Racial Sentiment Using Social Media Is Harder Than It Seems. Epidemiology, 35(1), 60–63.\n\n\nNobles, M. (2000). Shades of citizenship: Race and the census in modern politics. Stanford University Press.\n\n\nSteinman, R. M., Pizlo, Z., & Pizlo, F. J. (2000). Phi is not beta, and why Wertheimer’s discovery launched the Gestalt revolution. Vision research, 40(17), 2257–2264.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_design.html",
    "href": "chapters/key_notions/03_design.html",
    "title": "3  Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "",
    "text": "3.1 Introduzione\nQuesto capitolo si propone di approfondire i concetti introdotti in precedenza, concentrandosi in particolare sul processo di campionamento e sull’importanza delle diverse metodologie di ricerca in psicologia. Dopo aver compreso il ruolo fondamentale dei dati nella verifica delle teorie, emerge una questione cruciale: come vengono raccolti questi dati?\nLa raccolta dei dati non è un’attività neutra o priva di conseguenze metodologiche. I dati, infatti, non hanno lo stesso valore scientifico a seconda di come vengono ottenuti. Alcune modalità di raccolta generano informazioni preziose e utili per testare le teorie, mentre altre possono produrre risultati fuorvianti, distorti o addirittura dannosi per la validità della ricerca.\nIl metodo scientifico fornisce un quadro di riferimento che delinea le caratteristiche ideali di un processo di raccolta dati in grado di produrre informazioni valide e affidabili. Tuttavia, le prescrizioni del metodo scientifico sono per loro natura generali e astratte. Tradurre questi principi in procedure concrete e applicarli efficacemente in un contesto di ricerca specifico rappresenta una sfida significativa.\nQuesto passaggio, che collega la teoria alla pratica, dipende dalle risorse disponibili, dalla competenza metodologica e dalla creatività del ricercatore. La capacità di ideare e attuare strategie di raccolta dati adeguate al contesto specifico della ricerca è fondamentale per garantire la qualità e la validità dei risultati ottenuti. In questo capitolo, approfondiremo i principi del campionamento e introdurremo i concetti chiave relativi ai disegni di ricerca.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_design.html#popolazioni-e-campioni",
    "href": "chapters/key_notions/03_design.html#popolazioni-e-campioni",
    "title": "3  Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "3.2 Popolazioni e Campioni",
    "text": "3.2 Popolazioni e Campioni\nNella ricerca scientifica, è essenziale distinguere tra popolazione e campione.\n\nPopolazione: rappresenta l’insieme completo di unità che condividono una o più caratteristiche specifiche oggetto di studio. La dimensione della popolazione è indicata con N.\nCampione: è un sottoinsieme della popolazione, di dimensione n. L’obiettivo del campionamento è ottenere un campione rappresentativo, ovvero un sottoinsieme che rifletta accuratamente le caratteristiche della popolazione di riferimento.\n\n\n3.2.1 Metodi di Campionamento\nEsistono diverse strategie per selezionare un campione rappresentativo da una popolazione. Queste strategie si dividono principalmente in due categorie: campionamento probabilistico e campionamento non probabilistico.\n\n3.2.1.1 Campionamento Probabilistico\nNel campionamento probabilistico, ogni unità della popolazione ha una probabilità nota e non nulla di essere inclusa nel campione. Questo approccio minimizza il rischio di distorsioni sistematiche (bias) e consente di stimare l’errore di campionamento.\n\nCampionamento Casuale Semplice (CCS):\nOgni unità della popolazione ha la stessa probabilità di essere inclusa nel campione. Questo metodo richiede una lista completa di tutte le unità della popolazione, nota come frame di campionamento. La selezione può avvenire con o senza reinserimento. Il CCS senza reinserimento è il più comune nella pratica, ma nelle ricerche psicologiche è raramente utilizzabile a causa della difficoltà di ottenere un frame completo della popolazione.\nCampionamento Stratificato:\nLa popolazione viene divisa in strati (H), ovvero sottogruppi omogenei in base a una o più variabili rilevanti (es. età, genere, regione geografica). Da ogni strato h viene estratto un campione casuale semplice di dimensione nh. Questo metodo può essere:\n\nProporzionale: la dimensione del campione in ogni strato è proporzionale alla dimensione dello strato nella popolazione.\nNon proporzionale: utilizzato per sovra-campionare gruppi minoritari, consentendo analisi dettagliate di sottogruppi altrimenti poco rappresentati.\nNelle ricerche psicologiche, il campionamento stratificato è utile per garantire che variabili come il genere o l’età siano adeguatamente rappresentate, ma può essere complesso da implementare.\n\nCampionamento a Grappolo (Cluster Sampling):\nLa popolazione viene suddivisa in grappoli (cluster), che rappresentano gruppi eterogenei (es. scuole, ospedali, quartieri). Vengono selezionati casualmente alcuni grappoli, includendo tutte le unità al loro interno. Questo metodo è economico e pratico, specialmente in contesti dove accedere all’intera popolazione è difficile. Tuttavia, la precisione può essere ridotta se i grappoli differiscono notevolmente tra loro.\nCampionamento Multistadio:\nCombinazione di campionamento a grappolo e CCS. Vengono selezionati casualmente alcuni grappoli e, successivamente, all’interno di ciascun grappolo, si estrae un campione casuale di unità. Questo metodo bilancia costi e precisione, risultando particolarmente adatto a studi su larga scala, ad esempio a livello nazionale.\n\n\n\n3.2.1.2 Campionamento Non Probabilistico\nNel campionamento non probabilistico, la probabilità di inclusione di ogni unità nel campione non è nota. Questo approccio è spesso adottato per ragioni di praticità o quando non è disponibile un frame di campionamento. Tuttavia, aumenta il rischio di distorsioni e limita la generalizzabilità dei risultati alla popolazione.\n\nCampionamento di Convenienza:\nÈ il metodo più diffuso nella ricerca psicologica. I partecipanti vengono selezionati in base alla loro facile accessibilità (es., studenti universitari, volontari). Questo metodo è rapido ed economico, ma introduce significativi bias di selezione, poiché il campione non è rappresentativo della popolazione generale.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_design.html#il-campionamento-nella-ricerca-psicologica",
    "href": "chapters/key_notions/03_design.html#il-campionamento-nella-ricerca-psicologica",
    "title": "3  Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "3.3 Il Campionamento nella Ricerca Psicologica",
    "text": "3.3 Il Campionamento nella Ricerca Psicologica\nIl tema del campionamento nella ricerca psicologica è cruciale perché influisce in modo diretto sulla validità esterna e sulla generalizzabilità dei risultati. Nella pratica, però, l’ideale metodologico del campionamento probabilistico è spesso difficile da perseguire, a causa di vincoli di tempo, di risorse economiche e di accessibilità ai partecipanti (Henrich et al., 2010a). Per queste ragioni, molti studi in psicologia fanno ricorso al campionamento di convenienza, che prevede la selezione dei partecipanti sulla base della loro facile reperibilità, come studenti universitari o volontari reclutati online.\n\n3.3.1 Perché il Campionamento di Convenienza è così Diffuso?\n\nVincoli di Risorse\nLa ricerca psicologica, specie in ambito accademico, spesso non dispone di finanziamenti sufficienti per condurre campionamenti su larga scala. Reclutare partecipanti rappresentativi di un’intera popolazione richiederebbe budget, logistica e tempo ben superiori a quelli generalmente disponibili (Peterson & Merunka, 2014). Il campionamento di convenienza diventa quindi un compromesso “necessario” per poter portare avanti gli studi.\nAccessibilità ai Partecipanti\nNel contesto universitario, gli studenti rappresentano il bacino più facilmente accessibile e motivato a partecipare a studi psicologici, talvolta in cambio di crediti formativi o rimborsi simbolici (Sears, 1986). In altri contesti, si ricorre a piattaforme online che forniscono volontari in tempi brevi, consentendo di raccogliere dati in modo rapido e a costi contenuti.\nRapidità di Raccolta Dati\nIl vantaggio principale del campionamento di convenienza è la possibilità di raccogliere dati in tempi molto più ridotti rispetto a strategie di campionamento probabilistico. Tale rapidità può risultare essenziale per studi pilota o ricerche che richiedono analisi preliminari di fenomeni ancora poco esplorati.\n\n\n\n3.3.2 Limiti e Implicazioni\nIl ricorso al campionamento di convenienza comporta inevitabilmente dei limiti in termini di rappresentatività del campione. Gli individui che si prestano a partecipare a uno studio potrebbero avere caratteristiche socio-demografiche, cognitive o motivazionali peculiari (ad esempio, essere più giovani, con livelli di istruzione più alti, culturalmente più omogenei), portando ad un fenomeno noto come “campioni WEIRD” [Western, Educated, Industrialized, Rich, Democratic; Henrich et al. (2010b)]. Ciò significa che i risultati ottenuti potrebbero non riflettere adeguatamente l’intera variabilità della popolazione umana.\n\nGeneralizzabilità Ridotta: Uno studio condotto su studenti di psicologia in un’università europea può non essere applicabile a individui di diverse fasce di età, provenienti da altre aree geografiche o con retroterra socio-culturali differenti.\nBias di Selezione: I partecipanti volontari, specialmente online, possono essere attratti dallo studio per ragioni specifiche (ad esempio, curiosità verso la psicologia, tempo libero a disposizione, motivazione a ottenere un compenso), introducendo distorsioni non presenti nella popolazione più ampia.\nLimitazioni nei Risultati: Se i processi psicologici oggetto di indagine sono influenzati da cultura, età o altre variabili, lo studio potrebbe non catturare in modo esaustivo la complessità del fenomeno.\n\n\n\n3.3.3 Perché in Psicologia è (in Parte) Accettabile\nSebbene il campionamento di convenienza costituisca un limite, è bene ricordare che molti fenomeni psicologici presentano elementi di base che sono relativamente generali o universali nell’essere umano [ad esempio, i processi di percezione, l’apprendimento di base, alcune dinamiche emotive e motivazionali; cfr. Tooby & Cosmides (2005)]. Ciò significa che, entro certi confini, studiare un campione di convenienza può comunque fornire indicazioni utili e trasferibili ad altre popolazioni. Inoltre, buona parte delle ricerche in psicologia mira ad approfondire meccanismi e processi interna corporis – cioè aspetti di natura cognitiva, emotiva o sociale che, pur potendo variare in intensità o manifestazione, hanno basi comuni tra gli individui.\nIn altre parole, esiste un trade-off tra la necessità di disporre di campioni rappresentativi per garantire la massima generalizzabilità e la specificità dei fenomeni psicologici, che talvolta risiedono in processi considerati “universali”. Se lo scopo di uno studio è quello di testare meccanismi cognitivi di base (per esempio, l’elaborazione di stimoli visivi o di memoria), un campione di studenti potrebbe comunque fornire dati sufficientemente robusti, purché si riconoscano i limiti del contesto di raccolta.\n\n3.3.3.1 Considerazioni Etiche e Pratiche\nTalvolta, per ragioni etiche, non è semplice reperire partecipanti da particolari fasce di popolazione (ad esempio minori, pazienti clinici, soggetti in contesti istituzionali). In alcune ricerche, poi, l’uso di questionari lunghi o procedure sperimentali intense rende difficile attrarre volontari al di fuori dell’ambiente universitario. Da questo punto di vista, avere un bacino di partecipanti noti (ad es. studenti di psicologia) agevola la raccolta dei dati.\n\nRicompense: Spesso i dipartimenti offrono crediti formativi o piccoli compensi ai partecipanti, innescando un circolo virtuoso di interesse per la ricerca.\nLibertà di rifiuto: Le università dispongono di comitati etici che tutelano i diritti dei partecipanti, garantendo che anche i reclutamenti “di comodo” rispettino i principi etici fondamentali (consenso informato, anonimato, diritto al recesso, ecc.).\n\n\n\n\n3.3.4 Come Mitigare i Limiti del Campionamento di Convenienza\n\nReplicazione Incrociata (Cross-Replication)\nUn metodo efficace per aumentare la validità dei risultati è replicare lo stesso studio su campioni differenti, di età diversa o provenienti da contesti socio-culturali eterogenei. Ripetere la ricerca in più contesti e ottenere risultati simili fornisce evidenza della generalizzabilità del fenomeno.\nCampionamento Diversificato\nAnche se si ricorre a un campionamento di convenienza, si può tentare di diversificare la provenienza dei partecipanti (ad esempio, includendo studenti di diverse facoltà o atenei, oppure reclutando volontari su piattaforme online internazionali). Un campione che rifletta almeno in parte una maggiore varietà di background socio-culturali è comunque preferibile alla selezione di un solo gruppo omogeneo.\nCaratterizzazione Dettagliata del Campione\nÈ fondamentale fornire informazioni precise su età, genere, livello di istruzione, estrazione socio-culturale e altre variabili rilevanti. Questo permette ai lettori di valutare in che misura i risultati dello studio possano essere trasferiti ad altre popolazioni.\nIntegrazione di Metodi di Campionamento Misti\nAlcuni ricercatori scelgono di integrare campionamenti non probabilistici con piccole porzioni di campionamento più stratificato o di selezionare sotto-campioni rappresentativi per determinati sottogruppi. Non si tratta di un vero e proprio campionamento probabilistico, ma può comunque migliorare la robustezza dei risultati rispetto al puro campionamento di convenienza.\n\n\n\n3.3.5 Considerazioni Economiche e Future Prospettive\nAlla luce di questi punti, appare chiaro che il ricorso a metodi di campionamento probabilistici più rigorosi (campionamento casuale semplice, stratificato o a grappolo) richiederebbe aumenti significativi nei finanziamenti e un impegno logistico maggiore. Ciò non è sempre fattibile in contesti di ricerca accademica o quando i progetti sono condotti con budget limitati.\nD’altro canto, i finanziamenti aggiuntivi permetterebbero di:\n\nReclutare campioni più ampi e diversificati, ad esempio attraverso agenzie di rilevazione professionali o sondaggi a livello nazionale.\n\nImplementare studi longitudinali su popolazioni geograficamente distribuite, riducendo il rischio di raccogliere dati esclusivamente da aree limitrofe ai centri di ricerca.\nSostenere progetti multicentrici a livello internazionale, che consentono di testare l’universalità o la specificità culturale dei fenomeni psicologici.\n\nFino a quando queste risorse non saranno disponibili su larga scala, il campionamento di convenienza rimarrà la soluzione più diffusa e “realistica” nella ricerca psicologica. Tuttavia, non bisogna considerarlo esclusivamente un limite: la specificità dei fenomeni psicologici, legati a processi condivisi tra gli individui, talvolta permette di estrarre conclusioni valide anche da campioni meno rappresentativi, purché si utilizzino adeguate cautele nell’interpretazione e si persegua la replicazione come prassi consolidata.\nIn sintesi, il campionamento di convenienza è una strategia inevitabile nell’attuale panorama della ricerca psicologica, caratterizzato da forti limitazioni di risorse, ma in molti casi risulta comunque sufficiente per investigare dinamiche e processi psicologici di base. L’auspicio per il futuro è di poter disporre di finanziamenti e collaborazioni che permettano di ampliare il raggio d’azione e la diversità dei partecipanti, rafforzando la validità e la generalizzabilità della produzione scientifica in psicologia.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_design.html#metodologia-sperimentale",
    "href": "chapters/key_notions/03_design.html#metodologia-sperimentale",
    "title": "3  Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "3.4 Metodologia Sperimentale",
    "text": "3.4 Metodologia Sperimentale\n\n3.4.1 Principi Fondamentali del Disegno Sperimentale\n\nControllo\nL’obiettivo è ridurre l’influenza di variabili confondenti (Z) sulla relazione tra la variabile indipendente (X) e quella dipendente (Y). Utilizzare un gruppo di controllo consente di stabilire un riferimento per valutare l’effetto del trattamento.\nRandomizzazione\nL’assegnazione casuale dei partecipanti ai gruppi sperimentali distribuisce le variabili confondenti in modo equilibrato tra i gruppi, aumentando la credibilità dell’inferenza causale tra X e Y. Questo approccio garantisce che eventuali differenze osservate siano attribuibili al trattamento e non a fattori esterni.\n\n\n\n3.4.2 Strategie di Mitigazione dei Bias\n\nCecità (Blinding)\nStrumento chiave per minimizzare l’influenza di aspettative e pregiudizi, sia nei partecipanti che nei ricercatori. Le principali modalità includono:\n\nCecità singola: I partecipanti non sono consapevoli del trattamento assegnato.\nCecità doppia: Sia i partecipanti che i ricercatori che interagiscono direttamente con loro non conoscono l’assegnazione dei trattamenti.\nCecità tripla: Né i partecipanti, né i ricercatori, né gli analisti dei dati sono a conoscenza dei trattamenti durante la raccolta e l’analisi dei dati.\n\nGruppo di Controllo\nL’introduzione di un gruppo che riceve un trattamento inerte (controllo) consente di isolare gli effetti psicologici legati alle aspettative dei partecipanti, distinguendoli dagli effetti specifici del trattamento.\nStandardizzazione delle Procedure\nGarantire che tutte le condizioni sperimentali, eccetto la variabile manipolata, siano mantenute costanti tra i gruppi. Questo riduce la variabilità non controllata, migliorando la comparabilità dei risultati.\n\n\n\n3.4.3 Nota sulla Replicazione\nLa replicazione degli esperimenti non è una caratteristica intrinseca del metodo sperimentale, ma rappresenta una pratica fondamentale nella scienza per verificare l’affidabilità e la generalizzabilità dei risultati. Si distingue in:\n\nReplicazione diretta: Ripetere lo stesso studio con le stesse condizioni.\nReplicazione concettuale: Ripetere lo studio modificando aspetti specifici per testare la robustezza del risultato.\n\n\n\n3.4.4 Tipologie di Disegni Sperimentali\n\nDisegno a Gruppi Indipendenti (Between-Subjects):\nI partecipanti vengono assegnati a un unico gruppo e sono esposti a una sola condizione sperimentale. Questo disegno è utile quando l’esposizione multipla potrebbe introdurre confondenti, ma richiede un campione più ampio per raggiungere lo stesso livello di precisione.\nDisegno a Misure Ripetute (Within-Subjects):\nGli stessi partecipanti vengono esposti a tutte le condizioni sperimentali. Questo approccio riduce la variabilità tra soggetti, migliorando la precisione delle stime. Tuttavia, richiede attenzione nel controllare gli effetti di ordine, come affaticamento o apprendimento, spesso attraverso il bilanciamento dell’ordine di presentazione dei trattamenti.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_design.html#studi-osservazionali",
    "href": "chapters/key_notions/03_design.html#studi-osservazionali",
    "title": "3  Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "3.5 Studi Osservazionali",
    "text": "3.5 Studi Osservazionali\nGli studi osservazionali possono essere classificati in:\n\nStudi Trasversali (Cross-Sectional)\nI dati vengono raccolti in un singolo momento. Utili per stimare la prevalenza di una condizione, ma non permettono di stabilire relazioni causali.\nStudi di Coorte (Cohort Studies)\nUn gruppo di individui (coorte) viene seguito nel tempo per osservare l’incidenza di un evento. Permettono di studiare la relazione tra esposizione e outcome, ma possono essere costosi e richiedere molto tempo.\nStudi Caso-Controllo (Case-Control Studies)\nVengono confrontati individui con una determinata condizione (casi) con individui senza la condizione (controlli) per identificare possibili fattori di rischio. Utili per studiare malattie rare, ma soggetti a bias di selezione e di ricordo.\n\nLe principali limitazioni degli studi osservazionali sono la presenza di variabili confondenti e la difficoltà di stabilire relazioni causali.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_design.html#riflessioni-conclusive",
    "href": "chapters/key_notions/03_design.html#riflessioni-conclusive",
    "title": "3  Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "3.6 Riflessioni Conclusive",
    "text": "3.6 Riflessioni Conclusive\nNel corso di questo capitolo, abbiamo esplorato l’importanza del campionamento e delle diverse strategie di ricerca in psicologia, mettendo in luce i vincoli metodologici e le implicazioni derivanti da scelte spesso guidate dalle risorse a disposizione. Se da un lato i metodi di campionamento probabilistico garantiscono maggiore controllo sulla rappresentatività del campione, dall’altro, la realtà accademica e il contesto operativo di molti studi psicologici spingono verso soluzioni di comodo, inevitabilmente limitanti ma non per questo prive di valore scientifico.\nLe complessità intrinseche nello studio di fenomeni psicologici – spesso universali e al tempo stesso influenzati da variabili culturali e individuali – ci ricordano quanto sia importante mantenere un equilibrato senso critico. Da un punto di vista metodologico, l’esigenza di replicare gli studi in più contesti rimane la prassi fondamentale per rafforzare la credibilità dei risultati. Altrettanto cruciale è la volontà di caratterizzare in modo trasparente i propri campioni, rendendo chiaro in che misura siano (o non siano) rappresentativi della popolazione d’interesse. In tal modo, la comunità scientifica può valutare con maggiore consapevolezza la trasferibilità delle conclusioni a contesti diversi.\nUn ulteriore spunto di riflessione riguarda la tensione tra la desiderabilità di disegni di ricerca ideali (con campioni estesi e probabilistici) e le inevitabili restrizioni di tempo e budget. Se l’implementazione di studi su larga scala o a livello multicentrico consentirebbe di cogliere le sfumature culturali e socio-demografiche dei fenomeni, è altrettanto vero che, nel panorama attuale, molte ricerche non potrebbero essere realizzate senza ricorrere a partecipanti di più facile accesso, come gli studenti universitari o i volontari online. Tale flessibilità operativa può comunque produrre conoscenza significativa, a condizione che il ricercatore rimanga vigile rispetto ai possibili bias introdotti.\nIn definitiva, l’invito a chiunque conduca ricerche psicologiche è quello di coltivare una mentalità aperta, volta a bilanciare i limiti contingenti (economici, logistici, etici) con la necessità di mantenere standard metodologici solidi. Ciò implica sfruttare le potenzialità dell’integrazione tra disegni sperimentali e osservazionali, prestare attenzione alle forme di bias e, soprattutto, adottare la replicazione come pratica sistematica. Solo attraverso questa sinergia fra rigore scientifico e consapevolezza delle risorse disponibili è possibile far progredire la disciplina su basi empiriche sempre più solide e generalizzabili.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_design.html#esercizi",
    "href": "chapters/key_notions/03_design.html#esercizi",
    "title": "3  Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nPerché la fase di raccolta dei dati è considerata “non neutrale” e quali conseguenze può avere sull’affidabilità dei risultati di una ricerca psicologica?\nIn che modo i diversi metodi di campionamento (probabilistico vs. non probabilistico) influiscono sulla generalizzabilità delle conclusioni di uno studio e quali situazioni giustificano l’uso dell’uno o dell’altro?\nQuali sono i principali rischi nell’adottare un campionamento di convenienza in ricerche psicologiche, e quali strategie si possono utilizzare per mitigare questi rischi?\nIn che modo la randomizzazione e l’uso di gruppi di controllo supportano l’inferenza causale in un disegno sperimentale, e perché queste caratteristiche sono spesso più difficili da mantenere negli studi osservazionali?\nQuali sono i principali criteri da considerare quando si valuta la validità di uno studio in termini di campionamento, disegno di ricerca e replicabilità?\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n1. Perché la fase di raccolta dei dati è considerata “non neutrale” e quali conseguenze può avere sull’affidabilità dei risultati di una ricerca psicologica?\nLa raccolta dei dati non è mai un processo completamente neutrale perché comporta scelte metodologiche e pratiche che possono influenzare la qualità e la natura delle informazioni ottenute. Ad esempio:\n\nSelezione del campione: Scegliere chi includere o escludere nella ricerca incide sulla rappresentatività del campione. Un campione non rappresentativo può produrre risultati distorti e difficilmente generalizzabili.\n\nModalità di somministrazione degli strumenti: La maniera in cui vengono somministrati questionari, test o interviste può influire sulle risposte dei partecipanti (per esempio, differenze tra somministrazione online vs. cartacea, questionari anonimi vs. non anonimi, ecc.).\n\nContesto e tempistiche: Il contesto ambientale (es., rumori, distrazioni) o il momento in cui i dati vengono raccolti (es., in prossimità di esami universitari) possono influenzare lo stato emotivo o motivazionale dei partecipanti.\n\nCome conseguenza, tutte queste variabili possono introdurre bias – ossia distorsioni sistematiche – che compromettono l’affidabilità e la validità dei risultati, rendendo l’interpretazione dei dati più complessa e potenzialmente fuorviante. In altre parole, se la fase di raccolta dati non è accuratamente progettata e condotta, la ricerca potrebbe fornire conclusioni scorrette o di limitata utilità scientifica.\n2. In che modo i diversi metodi di campionamento (probabilistico vs. non probabilistico) influiscono sulla generalizzabilità delle conclusioni di uno studio e quali situazioni giustificano l’uso dell’uno o dell’altro?\n\nCampionamento probabilistico:\n\nOgni unità della popolazione ha una probabilità nota e non nulla di essere selezionata.\n\nMetodi come il campionamento casuale semplice, stratificato o a grappolo forniscono un quadro più solido per stimare l’errore di campionamento e minimizzare i bias.\n\nI risultati ottenuti sono, in linea di massima, più facilmente generalizzabili all’intera popolazione di riferimento.\n\nÈ preferibile in studi di larga scala, in cui esiste un buon frame di campionamento (lista esaustiva della popolazione) e le risorse (tempo, fondi) consentono di implementare un disegno rigoroso.\n\nCampionamento non probabilistico:\n\nLa probabilità di inclusione di un’unità non è nota, per cui non si possono calcolare in modo rigoroso le stime di errore.\n\nIl metodo più comune è il campionamento di convenienza, in cui vengono reclutate persone facilmente accessibili (es., studenti universitari, volontari, piattaforme online).\n\nLa generalizzabilità dei risultati è ridotta, poiché il campione potrebbe non rispecchiare le caratteristiche della popolazione di interesse.\n\nÈ spesso utilizzato per studi esplorativi, ricerche a budget limitato o quando non si dispone di un elenco completo della popolazione.\n\n\nIn sintesi, il campionamento probabilistico è preferibile quando si mira a ottenere risultati solidi e generalizzabili a una popolazione più ampia e le condizioni logistiche lo consentono. Il campionamento non probabilistico, invece, è giustificato in studi preliminari, in situazioni in cui la popolazione non è ben definita o difficilmente accessibile, o quando si hanno vincoli di risorse che rendono impraticabile un campionamento probabilistico.\n3. Quali sono i principali rischi nell’adottare un campionamento di convenienza in ricerche psicologiche, e quali strategie si possono utilizzare per mitigare questi rischi?\n\nPrincipali rischi:\n\nBias di selezione: I partecipanti reclutati con metodi di convenienza (ad es. studenti di psicologia) potrebbero non rispecchiare l’eterogeneità della popolazione generale, limitando la generalizzabilità dei risultati.\n\nOmogeneità del campione: Se il campione è molto omogeneo (per età, livello di istruzione, contesto culturale), diventa difficile estendere le conclusioni a gruppi con caratteristiche diverse.\n\nAutoselezione: I volontari che si offrono di partecipare potrebbero differire sistematicamente da coloro che non partecipano (ad esempio, maggiore interesse per il tema della ricerca o per la ricompensa economica offerta).\n\nStrategie di mitigazione:\n\nSovra-campionamento: Includere deliberatamente più partecipanti appartenenti a gruppi minoritari o sottorappresentati, per disporre di sottocampioni più completi.\n\nReplicazione: Ripetere l’esperimento con campioni diversi (per età, contesto geografico, cultura) per verificare se i risultati si mantengono coerenti.\n\nDescrizione dettagliata del campione: Fornire informazioni precise sulle caratteristiche sociodemografiche (età, genere, livello di istruzione, ecc.) in modo che altri ricercatori o lettori possano valutare la trasferibilità dei risultati.\n\nCautela nell’interpretazione: Esplicitare nelle conclusioni i limiti relativi alla natura del campionamento e invitare a considerare possibili fattori confondenti legati alla non rappresentatività del campione.\n\n\n4. In che modo la randomizzazione e l’uso di gruppi di controllo supportano l’inferenza causale in un disegno sperimentale, e perché queste caratteristiche sono spesso più difficili da mantenere negli studi osservazionali?\n\nRandomizzazione:\n\nAssegna i partecipanti ai gruppi sperimentali (condizione sperimentale vs. condizione di controllo) in maniera casuale.\n\nGarantisce che variabili potenzialmente confondenti vengano distribuite equamente tra i gruppi, aumentando la probabilità che eventuali differenze nelle misure di esito (variabile dipendente) siano dovute esclusivamente alla manipolazione sperimentale (variabile indipendente).\n\nQuesto processo riduce l’influenza di fattori esterni non misurati o non conosciuti, favorendo un’inferenza causale più solida.\n\nGruppi di controllo:\n\nConsentono di confrontare i risultati di chi riceve il trattamento/intervento con chi non lo riceve (o riceve un trattamento placebo).\n\nAiutano a isolare l’effetto “vero” del trattamento dalle variazioni dovute a effetti psicologici (ad es. effetto placebo), al passare del tempo o a eventi esterni.\n\nDifficoltà negli studi osservazionali:\n\nNon prevedono la manipolazione diretta di una variabile indipendente né l’assegnazione casuale dei partecipanti: le persone “si assegnano da sole” alle condizioni.\n\nManca il controllo sperimentale: non è sempre possibile includere un gruppo di controllo o applicare procedure di randomizzazione.\n\nLe variabili confondenti possono agire in modo non controllabile e compromettere l’interpretazione causale: anche con analisi statistiche sofisticate, è difficile escludere del tutto la presenza di fattori esterni che influenzano la relazione tra esposizione e outcome.\n\n\nPer questi motivi, gli studi sperimentali (con randomizzazione e controllo) rimangono il metodo privilegiato per stabilire nessi di causalità, mentre gli studi osservazionali servono principalmente a generare ipotesi, descrivere fenomeni, o analizzare relazioni di associazione più che di causalità.\n5. Quali sono i principali criteri da considerare quando si valuta la validità di uno studio in termini di campionamento, disegno di ricerca e replicabilità?\n\nRappresentatività del campione:\n\nIl campione rispecchia realmente le caratteristiche della popolazione di interesse?\n\nÈ stato usato un metodo di campionamento appropriato (probabilistico vs. non probabilistico)?\n\nControllo e randomizzazione (validità interna):\n\nLo studio ha previsto un disegno sperimentale con assegnazione casuale e gruppo di controllo?\n\nQuanto è efficace il controllo delle variabili confondenti (bias di selezione, aspettative, effetto placebo, ecc.)?\n\nGeneralizzabilità o validità esterna:\n\nI risultati dello studio sono applicabili oltre il contesto specifico in cui è stato condotto?\n\nVi sono limitazioni dovute all’uso di un campione di convenienza o di un contesto culturale molto particolare?\n\nStandardizzazione delle procedure:\n\nLe istruzioni, i tempi di raccolta dati, i materiali utilizzati sono stati gestiti in modo uniforme per tutti i partecipanti?\n\nReplicabilità:\n\nÈ possibile ripetere lo studio (replicazione diretta o concettuale) e ottenere risultati simili?\n\nGli autori forniscono informazioni sufficienti (materiali, protocolli, analisi) per consentire la replicazione?\n\nChiarezza nell’esposizione dei limiti:\n\nGli autori discutono apertamente le limitazioni del metodo di campionamento o del disegno di ricerca e suggeriscono possibili miglioramenti per studi futuri?\n\n\nNel complesso, una valutazione critica di uno studio deve integrare tutti questi aspetti (campionamento, disegno, replicabilità) per stabilire in che misura i risultati siano solidi, attendibili e utilmente generalizzabili.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_design.html#bibliografia",
    "href": "chapters/key_notions/03_design.html#bibliografia",
    "title": "3  Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nHenrich, J., Heine, S. J., & Norenzayan, A. (2010a). Most people are not WEIRD. Nature, 466(7302), 29–29.\n\n\nHenrich, J., Heine, S. J., & Norenzayan, A. (2010b). The weirdest people in the world? Behavioral and Brain Sciences, 33(2-3), 61–83.\n\n\nPeterson, R. A., & Merunka, D. R. (2014). Convenience samples of college students and research reproducibility. Journal of Business Research, 67(5), 1035–1041.\n\n\nTooby, J., & Cosmides, L. (2005). Evolutionary psychology: Conceptual foundations. In D. M. Buss (A c. Di), The Handbook of Evolutionary Psychology (pp. 5–67). Wiley.\n\n\nYouyou, W., Yang, Y., & Uzzi, B. (2023). A discipline-wide investigation of the replicability of Psychology papers over the past two decades. Proceedings of the National Academy of Sciences, 120(6), e2208863120.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_measurement.html",
    "href": "chapters/key_notions/04_measurement.html",
    "title": "4  La misurazione in psicologia",
    "section": "",
    "text": "4.1 Introduzione\nLa scienza si avvale di modelli per interpretare i dati, ma opera sempre con teorie incomplete e misurazioni soggette a errori. Di conseguenza, è fondamentale riconoscere le incertezze quando si cerca di estrarre informazioni dalle misurazioni utilizzando i nostri modelli. Nessuna misurazione, spiegazione o previsione è perfettamente accurata e precisa, e non possiamo mai conoscere con esattezza l’entità dei loro errori. Questo riconoscimento è alla base della teoria della misurazione, che cerca di quantificare e gestire queste incertezze per migliorare la qualità delle nostre conclusioni scientifiche.\nQuesta incertezza viene catturata in tre equazioni fondamentali. La prima è l’Equazione di Misurazione, che riconosce l’errore osservativo:\n\\[\ny = z + \\varepsilon_y,\n\\]\ndove \\(y\\) rappresenta il valore misurato, \\(z\\) il valore reale e \\(\\varepsilon_y\\) l’errore di misurazione. La seconda è l’Equazione di Modellazione, che esprime la presenza di un diverso tipo di errore:\n\\[\nz = f(x, \\theta) + \\varepsilon_\\text{model},\n\\]\ndove \\(f\\) è il modello, \\(x\\) sono le condizioni ambientali per cui eseguiamo il modello, \\(\\theta\\) sono i valori dei parametri del modello e \\(\\varepsilon_\\text{model}\\) rappresenta l’errore del modello, che sorge perché \\(f\\), \\(x\\) e \\(\\theta\\) saranno tutti in qualche misura imprecisi.\nCombinando queste due equazioni, otteniamo l’Equazione della Scienza:\n\\[\ny = f(x, \\theta) + \\varepsilon_\\text{model} + \\varepsilon_y.\n\\]\nLa scienza è il tentativo di spiegare le osservazioni \\(y\\) utilizzando un modello \\(f\\), cercando di minimizzare l’errore di misurazione \\(\\varepsilon_y\\) e l’errore del modello \\(\\varepsilon_\\text{model}\\), in modo che il modello possa essere utilizzato per fare previsioni sul mondo reale (\\(z\\)). L’approccio bayesiano alla scienza riconosce e quantifica le incertezze su tutti e sei gli elementi dell’Equazione della Scienza: \\(y\\), \\(f\\), \\(x\\), \\(\\theta\\), \\(\\varepsilon_\\text{model}\\) e \\(\\varepsilon_y\\).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_measurement.html#la-teoria-della-misurazione",
    "href": "chapters/key_notions/04_measurement.html#la-teoria-della-misurazione",
    "title": "4  La misurazione in psicologia",
    "section": "4.2 La teoria della Misurazione",
    "text": "4.2 La teoria della Misurazione\nLa teoria della misurazione, oggetto di questo capitolo, si concentra sull’errore di misurazione e sull’equazione fondamentale \\(y = z + \\varepsilon_y\\). Questa equazione può essere esaminata da tre prospettive distinte. La prima concerne l’affidabilità della misura, rappresentata dal termine \\(\\varepsilon_y\\). La psicometria, branca dedicata alla teoria della misurazione psicologica, si occupa di quantificare l’affidabilità delle misure psicologiche attraverso metodi come la Teoria Classica dei Test e la Teoria di Risposta all’Item.\nLa seconda prospettiva riguarda la validità delle misure psicologiche, ovvero quanto adeguatamente la misura \\(y\\) rappresenti il costrutto \\(z\\). Questo aspetto, più complesso dell’affidabilità, non può essere risolto meramente con metodi statistici, ma richiede una profonda comprensione delle teorie psicologiche e della loro capacità di descrivere e prevedere i fenomeni psicologici.\nLa terza prospettiva si concentra sulle procedure di assegnazione dei valori a \\(y\\), esplorando quali metodi (questionari, interviste, esperimenti) siano più appropriati e come valutarne l’adeguatezza.\n\n4.2.1 Costrutti Psicologici\nLa teoria della misurazione sottolinea l’importanza di distinguere tra la procedura di misurazione e il costrutto che si intende misurare. Ad esempio, mentre la temperatura è un costrutto, il termometro è lo strumento di misurazione. Analogamente, l’abilità matematica è un costrutto, mentre un test di matematica è la procedura per misurarla.\nNelle scienze psicologiche e sociali, la misurazione presenta sfide uniche rispetto alle scienze fisiche, poiché i costrutti in esame sono spesso astratti e non direttamente osservabili. Ciò richiede una particolare attenzione alla validità e all’affidabilità degli strumenti di misurazione, nonché una costante riflessione sulle limitazioni e le potenziali fonti di errore.\nIl capitolo introduce concetti fondamentali relativi alla misurazione quantitativa delle caratteristiche psicologiche, con un focus sulla teoria delle scale di misura di Stevens (1946). Questa teoria fornisce un quadro concettuale per comprendere i diversi tipi di scale di misurazione e le operazioni matematiche appropriate per ciascuna. Inoltre, vengono esplorate alcune procedure di scaling psicologico, ovvero l’assegnazione di numeri all’intensità di fenomeni psicologici.\n\n\n4.2.2 Scaling Psicologico\nLo scaling psicologico si occupa della trasformazione dei dati empirici raccolti durante uno studio psicologico in misure o punteggi che rappresentino accuratamente le caratteristiche psicologiche oggetto di indagine.\nScaling di Guttman. Uno dei metodi di scaling più noti è lo «Scaling di Guttman», che viene utilizzato per rappresentare relazioni ordinate tra gli elementi di una scala. Ad esempio, in un questionario sui sintomi dell’ansia, le domande possono essere disposte in ordine di intensità crescente dei sintomi. Secondo il modello di Guttman, se un partecipante risponde “sì” a una domanda che riflette un sintomo più intenso, ci si aspetta che abbia risposto “sì” anche a tutte le domande precedenti, che rappresentano sintomi di intensità minore. Questo approccio consente di costruire una scala che riflette in modo sistematico e coerente la gravità dei sintomi.\nScaling Thurstoniano. Lo «Scaling Thurstoniano» è un metodo utilizzato per misurare preferenze o giudizi soggettivi. Ad esempio, per valutare la preferenza tra diversi tipi di cibi, i partecipanti confrontano due cibi alla volta ed esprimono una preferenza. Le risposte vengono poi utilizzate per assegnare punteggi che riflettono la preferenza media per ciascun cibo.\nScaling Fechneriano. Lo scaling fechneriano si basa sulla legge di Fechner, secondo cui la percezione di uno stimolo aumenta in modo logaritmico rispetto alla sua intensità fisica. La misura fondamentale è la JND (Just Noticeable Difference), ovvero la minima differenza percepibile tra due stimoli. Secondo Fechner, sommando le JND si ottiene una scala psicologica dell’intensità percepita, utile per studiare grandezze sensoriali come luminosità, peso e suono (per es., Domini & Caudek, 2009).\nQuestionari Likert. I questionari Likert richiedono ai partecipanti di esprimere il loro grado di accordo con una serie di affermazioni su una scala a più livelli, che va da «fortemente in disaccordo» a «fortemente d’accordo». I punteggi ottenuti vengono sommati per rappresentare la posizione complessiva dell’individuo rispetto all’oggetto di studio.\n\n\n4.2.3 Metodi di Valutazione delle Scale Psicologiche\nPer valutare le proprietà delle scale psicologiche, vengono utilizzati vari metodi. Ad esempio, l’affidabilità delle misure può essere analizzata utilizzando il coefficiente alpha di Cronbach o il coefficiente Omega di McDonald, entrambi utilizzati per misurare la coerenza interna delle risposte ai diversi item di un questionario. Inoltre, la validità delle scale può essere esaminata confrontando i risultati ottenuti con misure simili o attraverso analisi statistiche che verificano se la scala cattura accuratamente il costrutto psicologico che si intende misurare. La validità di costrutto è particolarmente cruciale, poiché riguarda la capacità della scala di misurare effettivamente il concetto psicologico che si intende esplorare.\n\n\n4.2.4 Prospettive Moderne\nNegli ultimi anni, il dibattito sulla misurazione psicologica si è arricchito di nuove prospettive, grazie all’avvento di tecnologie avanzate e all’integrazione di approcci interdisciplinari. Ecco alcune delle tendenze più rilevanti.\nTeoria della Risposta agli Item. La Teoria della Risposta agli Item (IRT) ha guadagnato popolarità per la sua capacità di fornire stime più precise delle abilità latenti rispetto ai modelli classici. La IRT considera la probabilità che un individuo risponda correttamente a un item in funzione della sua abilità e delle caratteristiche dell’item stesso, offrendo una visione più dettagliata delle proprietà psicometriche degli strumenti di misurazione.\nApprocci Bayesiani. Gli approcci bayesiani stanno rivoluzionando il campo della psicometria, permettendo di incorporare informazioni a priori nelle stime e di aggiornare le credenze sulla base di nuovi dati. Questi metodi sono particolarmente utili per affrontare la complessità e l’incertezza inerenti alla misurazione psicologica.\nAnalisi di Rete. L’analisi di rete è un’altra metodologia emergente che vede i costrutti psicologici non come variabili latenti indipendenti, ma come reti di sintomi interconnessi. Questo approccio può offrire nuove intuizioni sulla struttura delle psicopatologie e sulla dinamica dei sintomi.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_measurement.html#le-scale-di-misurazione",
    "href": "chapters/key_notions/04_measurement.html#le-scale-di-misurazione",
    "title": "4  La misurazione in psicologia",
    "section": "4.3 Le scale di misurazione",
    "text": "4.3 Le scale di misurazione\nLe scale di misurazione sono strumenti fondamentali per assegnare numeri ai dati osservati, rappresentando le proprietà psicologiche. La teoria delle scale di Stevens (1946) identifica quattro tipi di scale di misurazione: nominali, ordinali, a intervalli e di rapporti. Ognuna di queste scale consente di effettuare operazioni aritmetiche diverse, poiché ciascuna di esse è in grado di “catturare” solo alcune delle proprietà dei fenomeni psicologici che si intende misurare.\n\n\n\nScale di misurazione.\n\n\n\n4.3.1 Scala nominale\nLa scala nominale è il livello di misurazione più semplice e corrisponde ad una tassonomia o classificazione delle categorie che utilizziamo per descrivere i fenomeni psicologici. I simboli o numeri che costituiscono questa scala rappresentano i nomi delle categorie e non hanno alcun valore numerico intrinseco. Con la scala nominale possiamo solo distinguere se una caratteristica psicologica è uguale o diversa da un’altra.\nI dati raccolti con la scala nominale sono suddivisi in categorie qualitative e mutuamente esclusive, in cui ogni dato appartiene ad una sola categoria. In questa scala, esiste solo la relazione di equivalenza tra le misure delle unità di studio: gli elementi del campione appartenenti a classi diverse sono differenti, mentre tutti quelli della stessa classe sono tra loro equivalenti.\nL’unica operazione algebrica consentita dalla scala nominale è quella di contare le unità di studio che appartengono ad ogni categoria e il numero totale di categorie. Di conseguenza, la descrizione dei dati avviene tramite le frequenze assolute e le frequenze relative.\nDalla scala nominale è possibile costruire altre scale nominali equivalenti alla prima, trasformando i valori della scala di partenza in modo tale da cambiare i nomi delle categorie, ma lasciando inalterata la suddivisione delle unità di studio nelle medesime classi di equivalenza. In altre parole, cambiando i nomi delle categorie di una variabile misurata su scala nominale, si ottiene una nuova variabile esattamente equivalente alla prima.\n\n\n4.3.2 Scala ordinale\nLa scala ordinale mantiene la caratteristica della scala nominale di classificare ogni unità di misura all’interno di una singola categoria, ma introduce la relazione di ordinamento tra le categorie. In quanto basata su una relazione di ordine, una scala ordinale descrive solo il rango di ordine tra le categorie e non fornisce informazioni sulla distanza tra di esse. Non ci dice, ad esempio, se la distanza tra le categorie \\(a\\) e \\(b\\) è uguale, maggiore o minore della distanza tra le categorie \\(b\\) e \\(c\\).\nUn esempio classico di scala ordinale è quello della scala Mohs per la determinazione della durezza dei minerali. Per stabilire la durezza dei minerali si usa il criterio empirico della scalfittura. Vengono stabiliti livelli di durezza crescente da 1 a 10 con riferimento a dieci minerali: talco, gesso, calcite, fluorite, apatite, ortoclasio, quarzo, topazio, corindone e diamante. Un minerale appartenente ad uno di questi livelli se scalfisce quello di livello inferiore ed è scalfito da quello di livello superiore.\n\n\n\nLa scala di durezza dei minerali di Mohs. Un oggetto è considerato più duro di X se graffia X. Sono incluse anche misure di durezza relativa utilizzando uno sclerometro, da cui emerge la non linearità della scala di Mohs (Burchard, 2004).\n\n\n\n\n4.3.3 Scala ad intervalli\nLa scala ad intervalli di misurazione include le proprietà della scala nominale e della scala ordinale e permette di misurare le distanze tra le coppie di unità statistiche in termini di un intervallo costante, chiamato “unità di misura”, a cui viene attribuito il valore “1”. L’origine della scala, ovvero il punto zero, è scelta arbitrariamente e non indica l’assenza della proprietà che si sta misurando. Ciò significa che la scala ad intervalli consente anche valori negativi e lo zero non viene attribuito all’unità statistica in cui la proprietà risulta assente.\nLa scala ad intervalli equivalenti consente l’esecuzione di operazioni algebriche basate sulla differenza tra i numeri associati ai diversi punti della scala, operazioni algebriche non possibili con le scale di misura nominale o ordinale. Tuttavia, il limite della scala ad intervalli è che non consente di calcolare il rapporto tra coppie di misure. È possibile affermare la differenza tra \\(a\\) e \\(b\\) come la metà della differenza tra \\(c\\) e \\(d\\) o che le due differenze sono uguali, ma non è possibile affermare che \\(a\\) abbia una proprietà misurata in quantità doppia rispetto a \\(b\\). In altre parole, non è possibile stabilire rapporti diretti tra le misure ottenute. Solo le differenze tra le modalità permettono tutte le operazioni aritmetiche, come la somma, l’elevazione a potenza o la divisione, che sono alla base della statistica inferenziale.\nNelle scale ad intervalli equivalenti, l’unità di misura è arbitraria e può essere cambiata attraverso una dilatazione, ovvero la moltiplicazione di tutti i valori della scala per una costante positiva. Inoltre, la traslazione, ovvero l’aggiunta di una costante a tutti i valori della scala, è ammessa poiché non altera le differenze tra i valori della scala. La scala rimane invariata rispetto a traslazioni e dilatazioni e dunque le uniche trasformazioni ammissibili sono le trasformazioni lineari:\n\\[\ny' = a + by, \\quad b &gt; 0.\n\\]\nInfatti, l’uguaglianza dei rapporti fra gli intervalli rimane invariata a seguito di una trasformazione lineare.\nEsempio di scala ad intervalli è la temperatura misurata in gradi Celsius o Fahrenheit, ma non Kelvin. Come per la scala nominale, è possibile stabilire se due modalità sono uguali o diverse: \\(30^\\circ C \\neq 20^\\circ C\\). Come per la scala ordinale è possibile mettere due modalità in una relazione d’ordine: \\(30^\\circ C &gt; 20^\\circ C\\). In aggiunta ai casi precedenti, però, è possibile definire una unità di misura per cui è possibile dire che tra \\(30^\\circ C\\) e \\(20^\\circ C\\) c’è una differenza di \\(30^\\circ - 20^\\circ = 10^\\circ C\\). I valori di temperatura, oltre a poter essere ordinati secondo l’intensità del fenomeno, godono della proprietà che le differenze tra loro sono direttamente confrontabili e quantificabili.\nIl limite della scala ad intervalli è quello di non consentire il calcolo del rapporto tra coppie di misure. Ad esempio, una temperatura di \\(80^\\circ C\\) non è il doppio di una di \\(40^\\circ C\\). Se infatti esprimiamo le stesse temperature nei termini della scala Fahrenheit, allora i due valori non saranno in rapporto di 1 a 2 tra loro. Infatti, \\(20^\\circ C = 68^\\circ F\\) e \\(40^\\circ C = 104^\\circ F\\). Questo significa che la relazione “il doppio di” che avevamo individuato in precedenza si applicava ai numeri della scala centigrada, ma non alla proprietà misurata (cioè la temperatura). La decisione di che scala usare (Centigrada vs. Fahrenheit) è arbitraria. Ma questa arbitrarietà non deve influenzare le inferenze che traiamo dai dati. Queste inferenze, infatti, devono dirci qualcosa a proposito della realtà empirica e non possono in nessun modo essere condizionate dalle nostre scelte arbitrarie che ci portano a scegliere la scala Centigrada piuttosto che quella Fahrenheit.\nConsideriamo ora l’aspetto invariante di una trasformazione lineare, ovvero l’uguaglianza dei rapporti fra intervalli. Prendiamo in esame, ad esempio, tre temperature: \\(20^\\circ C = 68^\\circ F\\), \\(15^\\circ C = 59^\\circ F\\), \\(10^\\circ C = 50 ^\\circ F\\).\nÈ facile rendersi conto del fatto che i rapporti fra intervalli restano costanti indipendentemente dall’unità di misura che è stata scelta:\n\\[\n  \\frac{20^\\circ C - 10^\\circ C}{20^\\circ C - 15^\\circ C} =\n  \\frac{68^\\circ F - 50^\\circ F}{68^\\circ F-59^\\circ F} = 2.\n\\]\n\n\n4.3.4 Scala di rapporti\nNella scala a rapporti equivalenti, lo zero non è arbitrario e rappresenta l’elemento che ha intensità nulla rispetto alla proprietà misurata. Per costruire questa scala, si associa il numero 0 all’elemento con intensità nulla e si sceglie un’unità di misura \\(u\\). Ad ogni elemento si assegna un numero \\(a\\) definito come \\(a = d / u\\), dove \\(d\\) rappresenta la distanza dall’origine. In questo modo, i numeri assegnati riflettono le differenze e i rapporti tra le intensità della proprietà misurata.\nIn questa scala, è possibile effettuare operazioni aritmetiche non solo sulle differenze tra i valori della scala, ma anche sui valori stessi della scala. L’unica scelta arbitraria è l’unità di misura, ma lo zero deve sempre rappresentare l’intensità nulla della proprietà considerata.\nLe trasformazioni ammissibili in questa scala sono chiamate trasformazioni di similarità e sono del tipo \\(y' = by\\), dove \\(b &gt; 0\\). In questa scala, i rapporti tra i valori rimangono invariati dopo le trasformazioni. In altre parole, se rapportiamo due valori originali e due valori trasformati, il rapporto rimane lo stesso: \\(\\frac{y_i}{y_j} = \\frac{y'_i}{y'_j}\\).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_measurement.html#gerarchia-dei-livelli-delle-scale-di-misurazione",
    "href": "chapters/key_notions/04_measurement.html#gerarchia-dei-livelli-delle-scale-di-misurazione",
    "title": "4  La misurazione in psicologia",
    "section": "4.4 Gerarchia dei livelli delle scale di misurazione",
    "text": "4.4 Gerarchia dei livelli delle scale di misurazione\nSecondo Stevens (1946), esiste una gerarchia dei livelli delle scale di misurazione, denominati “livelli di scala”. Questi livelli sono organizzati in modo gerarchico, in cui la scala nominale rappresenta il livello più basso della misurazione, mentre la scala a rapporti equivalenti rappresenta il livello più alto.\n\nScala nominale: Classifica le categorie senza un ordine specifico.\nScala ordinale: Classifica le categorie in un ordine specifico, ma senza una misura precisa delle distanze.\nScala a intervalli: Misura le distanze tra le categorie con un intervallo costante, ma senza un punto zero assoluto.\nScala di rapporti: Misura le distanze con un intervallo costante e un punto zero assoluto.\n\n\n\n\nRelazioni tra i livelli di misurazione.\n\n\nPassando da un livello di misurazione ad uno più alto aumenta il numero di operazioni aritmetiche che possono essere compiute sui valori della scala.\n\n4.4.1 Variabili Discrete e Continue\nLe variabili possono essere classificate come variabili a livello di intervalli o di rapporti e possono essere sia discrete che continue.\n\nVariabili discrete: Assumono valori specifici ma non possono assumere valori intermedi.\nVariabili continue: Possono assumere qualsiasi valore all’interno di un intervallo specificato.\n\n\n\n\nVariabili discrete e continue.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_measurement.html#interazione-tra-teoria-sostanziale-e-misurazione-nella-ricerca-scientifica",
    "href": "chapters/key_notions/04_measurement.html#interazione-tra-teoria-sostanziale-e-misurazione-nella-ricerca-scientifica",
    "title": "4  La misurazione in psicologia",
    "section": "4.5 Interazione tra Teoria Sostanziale e Misurazione nella Ricerca Scientifica",
    "text": "4.5 Interazione tra Teoria Sostanziale e Misurazione nella Ricerca Scientifica\n\n4.5.1 Un caso studio sul mind-body healing\nUn esempio di lettura critica della letteratura scientifica è offerto dall’analisi di uno studio sul mind-body healing pubblicato su Nature Aungle & Langer (2023). La ricerca riporta miglioramenti nella salute fisica associati a pratiche mente-corpo, ma è stata oggetto di severe critiche metodologiche da parte del statistico Andrew Gelman sul blog Statistical Modeling. Questo caso rivela due aspetti fondamentali spesso trascurati: il ruolo della teoria sostanziale e i criteri di misurazione rigorosa.\n\n\n4.5.2 La Teoria Sostanziale come Fondamento\nGelman evidenzia un deficit epistemologico centrale: l’assenza di un framework teorico convincente che spieghi i meccanismi causali ipotizzati. Senza una teoria che:\n\nDefinisca in modo univoco i costrutti (es.: “guarigione mente-corpo”)\n\nIdentifichi pathways biologici o psicologici plausibili\n\nSi integri con conoscenze consolidate (es.: neuroscienze, immunologia),\n\ni risultati empirici perdono significato scientifico, rischiando di degenerare in quella che Gelman definisce “junk science”. Una teoria solida non è solo un optional descrittivo, ma una precondizione per:\n\nFormulare ipotesi verificabili\n\nInterpretare correlazioni in termini causali\n\nEvitare inferenze speculative o tautologiche.\n\n\n\n4.5.3 Criticità nella Misurazione\nLo studio presenta inoltre problemi operazionali rilevanti:\n\n4.5.3.1 A. Validità degli strumenti\n\nLa misurazione delle pratiche mente-corpo non controlla adeguatamente:\n\nFattori confondenti (aspettative dei partecipanti, effetto placebo)\n\nBias di autovalutazione\n\n\nGli outcome clinici utilizzano scale non validate, compromettendo la comparabilità dei risultati.\n\n\n\n4.5.3.2 Questioni di validità\n\nInterna: L’assenza di blinding e randomizzazione rigorosa mina l’attribuzione causale.\n\nEsterna: Campioni non rappresentativi limitano la generalizzabilità (per approfondimenti, si veda Capitolo 34).\n\nCome discusso nella letteratura metodologica (Accuracy and Precision), la qualità delle misurazioni determina direttamente l’affidabilità delle conclusioni. Misure distorte o imprecise generano un “rumore” statistico che oscura eventuali segnali reali.\n\n\n\n4.5.4 Verso una Valutazione Integrata\nLa lettura critica di questo articolo mostra come la critica scientifica deve simultaneamente considerare due piani:\n\n\n\n\n\n\n\nDimensione\nRischi di Negligenza\n\n\n\n\nTeorica\nInterpretazioni ad hoc, ipotesi non falsificabili\n\n\nOperativa\nArtefatti metodologici, misurazioni inadeguate, conclusioni spurie\n\n\n\nUna ricerca rigorosa richiede un circolo ermeneutico tra teoria e dati: le misurazioni devono testare ipotesi derivate da framework teorici, mentre i risultati empirici devono raffinare le teorie stesse. Senza questo dialogo, si cade nel dualismo sterile tra:\n\nEmpirismo naïve (raccolta dati acritica)\n\nTeorizzazione dogmatica (slegata dall’evidenza).\n\nIn sintesi, la lettura critica di articoli scientifici esige:\n\ncompetenza transdisciplinare (statistica, epistemologia, conoscenze del dominio),\nconsapevolezza sui limiti della misurazione di costrutti.\n\nCome illustrato nell’analisi di Gelman, solo integrando valutazioni teoriche e metodologiche è possibile distinguere scienza robusta da pseudoscienza. Questo approccio non è meramente “difensivo”, ma costituisce il motore stesso del progresso scientifico, come approfondito nelle riflessioni su validità interna/esterna.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_measurement.html#riflessioni-conclusive",
    "href": "chapters/key_notions/04_measurement.html#riflessioni-conclusive",
    "title": "4  La misurazione in psicologia",
    "section": "4.6 Riflessioni Conclusive",
    "text": "4.6 Riflessioni Conclusive\nLa misurazione in psicologia non è un semplice atto di raccolta di dati, ma un processo fondamentale per garantire che le osservazioni empiriche siano interpretabili alla luce di modelli teorici solidi. Una buona misurazione non si limita a ridurre l’errore, ma consente di attribuire un significato coerente ai punteggi ottenuti, facilitando così il progresso della conoscenza scientifica. Senza strumenti adeguati per la misurazione, il rischio è quello di costruire teorie su basi incerte, compromettendo la validità delle conclusioni tratte.\nDue pilastri sostengono dunque una ricerca psicologica rigorosa: la teoria e la misurazione. La teoria fornisce il quadro concettuale entro cui si interpretano i dati, definendo le ipotesi e orientando le analisi. La misurazione, invece, è il ponte tra i costrutti astratti e le osservazioni empiriche, traducendo concetti complessi in variabili operative affidabili. Nessuna delle due componenti può reggersi senza l’altra: una teoria senza misurazione adeguata rischia di rimanere speculativa, mentre una misurazione priva di un solido fondamento teorico può portare a dati privi di significato.\nNella valutazione di un qualsiasi studio psicologico, un approccio critico richiede quindi di esaminare sia la solidità del quadro teorico sia la qualità degli strumenti di misurazione adottati. Il progresso della ricerca dipende dalla capacità di integrare questi due elementi, attraverso metodologie che riducano l’incertezza e migliorino la precisione delle inferenze. Le moderne tecniche di analisi dei dati, i modelli psicometrici avanzati e le tecnologie digitali stanno ampliando le possibilità di misurazione, offrendo strumenti più sensibili e adattabili alla complessità dei fenomeni psicologici. Tuttavia, la sfida principale rimane la stessa: garantire che la misurazione sia non solo accurata, ma anche teoricamente fondata, affinché le conoscenze acquisite possano davvero contribuire alla comprensione della mente e del comportamento umano.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_measurement.html#esercizi",
    "href": "chapters/key_notions/04_measurement.html#esercizi",
    "title": "4  La misurazione in psicologia",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nEsercizio 1: Identificazione del Livello di Misurazione\nObiettivo: Comprendere i diversi livelli di misurazione applicati alla psicologia.\n\nIdentifica il livello di misurazione (nominale, ordinale, intervalli, rapporti) per ciascuna delle seguenti variabili psicologiche:\n\n\nTipo di terapia psicologica (Cognitivo-comportamentale, Psicodinamica, Umanistica)\n\n\nLivello di ansia auto-riferito su una scala da 1 a 10\n\n\nNumero di episodi depressivi in un anno\n\n\nTempo di reazione in millisecondi in un test cognitivo\n\n\n\nEsercizio 2: Confronto tra Scale\nObiettivo: Comprendere le differenze tra le scale di misurazione.\n\nSpiega la differenza tra una scala ordinale e una scala a intervalli utilizzando l’esempio della soddisfazione lavorativa.\nPerché il punteggio QI è misurato su una scala a intervalli e non su una scala a rapporti?\nIn che modo il punteggio di una scala di autostima su una scala Likert differisce da una misurazione su una scala di rapporti?\n\nEsercizio 3: Operazioni Aritmetiche Consentite\nObiettivo: Comprendere le operazioni matematiche consentite per ciascun livello di misurazione.\n\nQuali operazioni aritmetiche sono ammissibili per una scala nominale?\nPuò avere senso calcolare la media di punteggi su una scala ordinale? Perché?\nSe hai misurato il tempo di reazione in secondi, quali operazioni aritmetiche puoi eseguire?\n\nEsercizio 4: Trasformazioni Ammissibili\nObiettivo: Comprendere le trasformazioni possibili per ogni scala di misurazione.\n\nSe una variabile è misurata su una scala nominale, quale tipo di trasformazione è consentita?\nPer una scala a intervalli, quali trasformazioni matematiche sono permesse senza alterare le proprietà della scala?\nQuale tipo di trasformazione è consentita su una scala di rapporti?\n\nEsercizio 5: Applicazione delle Scale a Dati Psicologici\nObiettivo: Applicare i concetti a contesti psicologici reali.\n\nUna scala di ansia clinica fornisce punteggi compresi tra 0 e 100. Quale livello di misurazione è più appropriato e perché?\nUn esperimento misura la memoria dichiarativa chiedendo ai partecipanti di ricordare un elenco di parole. Come dovrebbe essere misurata la variabile “numero di parole ricordate”?\nIn uno studio sulla personalità, i tratti vengono classificati come “estroverso” e “introverso”. Qual è il livello di misurazione?\n\nEsercizio 6: Valutazione della Scala di Misurazione\nObiettivo: Identificare la corretta scala di misurazione per vari fenomeni psicologici.\n\nIl livello di aggressività misurato su una scala da 1 a 5 è nominale, ordinale, intervalli o rapporti? Giustifica la tua risposta.\nIl numero di attacchi di panico in una settimana può essere considerato su scala ordinale? Perché sì o perché no?\nUn test di intelligenza misura il QI con una media di 100 e una deviazione standard di 15. Qual è il livello di misurazione e quali sono le implicazioni per l’analisi statistica?\n\nEsercizio 7: Costruzione di una Scala Psicologica\nObiettivo: Creare una scala di misurazione per una variabile psicologica.\n\nSe dovessi costruire una scala per misurare la resilienza, quale livello di misurazione sceglieresti e perché?\nCome potresti trasformare una scala nominale di preferenza musicale in una scala ordinale?\nUn questionario sulla qualità della vita chiede ai partecipanti di valutare la loro felicità su una scala da 1 a 10. È una scala a intervalli o ordinale? Giustifica.\n\nEsercizio 8: Interpretazione Statistica dei Dati\nObiettivo: Collegare il livello di misurazione alle tecniche statistiche appropriate.\n\nPerché una mediana è più appropriata della media per dati ordinali?\nQuale test statistico sarebbe più adatto per confrontare due gruppi su una variabile nominale?\nQuali analisi possono essere condotte su dati raccolti su una scala a rapporti?\n\nEsercizio 9: Misurazione e Inferenze Psicologiche\nObiettivo: Riflettere su come il livello di misurazione influisce sulle conclusioni di una ricerca.\n\nSe un test di personalità usa una scala Likert da 1 a 7, quali precauzioni devono essere prese nell’interpretare le differenze tra punteggi?\nUn questionario di benessere assegna punteggi tra 0 e 100, ma non ha uno zero assoluto. Quale scala è questa e quali sono le limitazioni?\nIn uno studio sulla depressione, i sintomi vengono codificati come “assenti”, “moderati” o “gravi”. Che tipo di scala è questa e quali statistiche possono essere usate per analizzarla?\n\nEsercizio 10: Esperimenti Psicologici e Misurazione\nObiettivo: Applicare la teoria della misurazione nella progettazione di esperimenti psicologici.\n\nSe un esperimento misura la memoria a breve termine con un compito di richiamo di parole, quale scala di misurazione utilizzeresti?\nCome la scelta della scala di misurazione può influenzare le inferenze che si possono trarre da un esperimento?\nQuali tipi di analisi statistica sono appropriati per dati misurati su scala ordinale rispetto a scala di rapporti?\n\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\nEsercizio 1: Identificazione del Livello di Misurazione\nObiettivo: Comprendere i diversi livelli di misurazione applicati alla psicologia.\n\nIdentifica il livello di misurazione (nominale, ordinale, intervalli, rapporti) per ciascuna delle seguenti variabili psicologiche:\n\n\nNominale (Tipo di terapia psicologica è una classificazione senza ordine)\n\n\nOrdinale (Scala da 1 a 10, con ordine ma senza distanze uguali)\n\n\nRapporti (Numero di episodi depressivi ha uno zero assoluto e si possono fare rapporti tra valori)\n\n\nRapporti (Tempo di reazione ha uno zero assoluto e permette operazioni di rapporto)\n\n\n\nEsercizio 2: Confronto tra Scale\nObiettivo: Comprendere le differenze tra le scale di misurazione.\n\nLa scala ordinale fornisce un ordine ma non permette di calcolare differenze precise, mentre la scala a intervalli ha differenze costanti tra i valori. Ad esempio, “soddisfazione lavorativa” su una scala da 1 a 5 è ordinale, mentre il punteggio di un test psicologico è a intervalli.\nIl punteggio QI è a intervalli perché la differenza tra punteggi è significativa, ma non ha uno zero assoluto che rappresenta l’assenza di intelligenza.\nUna scala Likert misura il livello di accordo con una dichiarazione, quindi è generalmente considerata ordinale, nonostante sia trattata spesso come una scala a intervalli.\n\nEsercizio 3: Operazioni Aritmetiche Consentite\nObiettivo: Comprendere le operazioni matematiche consentite per ciascun livello di misurazione.\n\nNella scala nominale si può solo contare la frequenza delle categorie (ad es., il numero di partecipanti che usano un tipo di terapia).\nNo, la media su dati ordinali può essere fuorviante perché le distanze tra le categorie non sono necessariamente uguali. Meglio usare la mediana.\nSul tempo di reazione si possono eseguire tutte le operazioni aritmetiche, inclusa la media, la moltiplicazione e i rapporti tra valori.\n\nEsercizio 4: Trasformazioni Ammissibili\nObiettivo: Comprendere le trasformazioni possibili per ogni scala di misurazione.\n\nSulla scala nominale, solo le trasformazioni di ricodifica (ad esempio, cambiare i nomi delle categorie) sono permesse.\nPer una scala a intervalli, si possono effettuare trasformazioni lineari della forma y’ = a + by con b &gt; 0.\nPer una scala di rapporti, sono consentite trasformazioni di similarità della forma y’ = by, dove b &gt; 0.\n\nEsercizio 5: Applicazione delle Scale a Dati Psicologici\nObiettivo: Applicare i concetti a contesti psicologici reali.\n\nScala a intervalli, perché ha differenze costanti tra i punteggi ma nessuno zero assoluto.\nScala di rapporti, perché il numero di parole ricordate ha uno zero assoluto e consente operazioni di rapporto.\nNominale, perché non vi è un ordine gerarchico tra le categorie “estroverso” e “introverso”.\n\nEsercizio 6: Valutazione della Scala di Misurazione\nObiettivo: Identificare la corretta scala di misurazione per vari fenomeni psicologici.\n\nOrdinale, perché il livello di aggressività segue un ordine, ma le differenze tra i livelli non sono necessariamente uguali.\nNo, perché il numero di attacchi di panico è una variabile discreta e misurabile su scala di rapporti.\nIntervalli, perché il punteggio QI ha distanze costanti tra i valori, ma non ha uno zero assoluto.\n\nEsercizio 7: Costruzione di una Scala Psicologica\nObiettivo: Creare una scala di misurazione per una variabile psicologica.\n\nOrdinale o a intervalli, a seconda della precisione della misurazione della resilienza.\nSi potrebbe assegnare un valore numerico crescente alle categorie di preferenza musicale per ottenere una scala ordinale.\nÈ una scala ordinale, perché la differenza tra livelli non è necessariamente costante.\n\nEsercizio 8: Interpretazione Statistica dei Dati\nObiettivo: Collegare il livello di misurazione alle tecniche statistiche appropriate.\n\nPerché la mediana è meno sensibile ai valori estremi rispetto alla media.\nUn test chi-quadrato è adatto per confrontare frequenze di dati nominali tra gruppi.\nSi possono calcolare media, deviazione standard e utilizzare test parametrici come t-test o ANOVA.\n\nEsercizio 9: Misurazione e Inferenze Psicologiche\nObiettivo: Riflettere su come il livello di misurazione influisce sulle conclusioni di una ricerca.\n\nI punteggi Likert sono ordinali, quindi confronti tra differenze di punteggio devono essere interpretati con cautela.\nIntervalli, perché non ha uno zero assoluto, il che limita l’uso di operazioni moltiplicative.\nOrdinale, e si possono usare test non parametrici come il test di Kruskal-Wallis o il test di Mann-Whitney.\n\nEsercizio 10: Esperimenti Psicologici e Misurazione\nObiettivo: Applicare la teoria della misurazione nella progettazione di esperimenti psicologici.\n\nRapporti, perché il numero di parole ricordate è una variabile discreta con uno zero assoluto.\nSe si usa una scala ordinale, bisogna essere cauti nell’uso della media e della deviazione standard.\nScala ordinale → test non parametrici (Mann-Whitney); scala di rapporti → test parametrici (t-test, ANOVA).\n\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nEsercizio 1 – Teoria Sostanziale e “Junk Science”\nObiettivo: Riconoscere il ruolo di una teoria sostanziale solida e comprendere come la sua assenza possa compromettere uno studio.\n\nLeggi la sezione in cui Gelman critica l’assenza di una teoria solida nello studio sulle pratiche mente-corpo.\n\nSpiega, in massimo 10 righe, perché secondo Gelman la mancanza di una teoria coerente rende i risultati del suddetto studio “poco significativi” o addirittura “junk science”.\n\nProponi un esempio ipotetico (non correlato al mind-body healing) di uno studio psicologico che, pur presentando dati numerosi e analizzati con metodi statistici sofisticati, risulti privo di una teoria solida. Descrivi sinteticamente perché questo potrebbe rientrare nel concetto di “junk science”.\n\nEsercizio 2 – Problemi di Misurazione\nObiettivo: Identificare le criticità più comuni nella misurazione dei fenomeni psicologici.\n\nElenca almeno tre possibili fattori confondenti che potrebbero influenzare la misurazione dell’efficacia di un intervento psicologico (ad esempio, l’effetto placebo, le aspettative dei partecipanti, ecc.).\n\nSpiega come questi fattori confondenti potrebbero compromettere la validità interna dello studio.\n\nIndica almeno due caratteristiche fondamentali che una buona scala di misurazione (per una variabile psicologica) dovrebbe possedere per essere ritenuta affidabile e valida.\n\nEsercizio 3 – Precisione e Bias\nObiettivo: Chiarire la distinzione tra precisione e distorsione (bias) e come questi aspetti si riflettano nella validità delle conclusioni.\n\nDefinisci, con parole tue, i concetti di precisione e bias in ambito psicometrico.\nFornisci un esempio concreto di uno strumento di misura preciso ma distorto (bias elevato) e di uno strumento poco preciso ma non distorto (bias basso).\n\nSpiega come la combinazione di scarsa precisione e alto bias possa influire sulla possibilità di trarre conclusioni affidabili in uno studio psicologico.\n\nEsercizio 4 – Validità Interna ed Esterna\nObiettivo: Approfondire come le scelte di misurazione influiscano sulla validità interna ed esterna di uno studio.\n\nIn riferimento allo studio sul mind-body healing discusso nel capitolo, identifica due fattori che potrebbero compromettere la validità interna e due fattori che potrebbero limitarne la validità esterna.\n\nDescrivi in 5-8 righe le differenze principali tra validità interna e validità esterna, utilizzando esempi presi sia dal contesto della guarigione mente-corpo sia da altri contesti psicologici (ad esempio, studi sull’apprendimento o sulla motivazione).\n\nProponi una modifica al disegno di ricerca (ipotetico) che potrebbe migliorare la validità interna dello studio originale. Spiega brevemente come questa modifica ne influenzerebbe anche la validità esterna.\n\nEsercizio 5 – Integrare Teoria e Misurazione: Breve Progetto di Ricerca\nObiettivo: Mettere in pratica i concetti di teoria e misurazione attraverso la progettazione di uno studio.\n\nImmagina di voler condurre uno studio su un intervento di “training di rilassamento mentale” finalizzato a ridurre l’ansia negli studenti universitari.\n\nSviluppa una breve traccia di progetto (massimo 15 righe) rispondendo ai seguenti punti:\n\nTeoria di base: Qual è la teoria sostanziale dietro l’efficacia del training di rilassamento? Quali meccanismi psicologici verrebbero attivati?\n\nIpotesi: Quale effetto prevedi sull’ansia degli studenti?\n\nMisurazione: Che tipo di strumento useresti per valutare il livello di ansia e perché (ad esempio, questionari self-report validati, misure fisiologiche come battito cardiaco, ecc.)?\n\nControllo dei confondenti: Quali variabili secondarie possono influire sui risultati e come intendi gestirle?\n\nValidità: Come assicureresti una buona validità interna? Che strategie adotteresti per aumentare la validità esterna?\n\nSpiega brevemente in che modo la combinazione di un solido quadro teorico e di una misurazione accurata permette di evitare che lo studio venga etichettato come “junk science”.\n\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\nEsercizio 1 – Teoria Sostanziale e “Junk Science”\n\nPerché la mancanza di una teoria solida rende i risultati poco significativi?\n\n\nGelman critica lo studio sul mind-body healing perché non vi è un modello teorico convincente che spieghi il meccanismo causale tra pratiche mente-corpo e miglioramenti di salute.\n\nSenza un quadro teorico robusto, i risultati sono interpretati in modo esplorativo e rischiano di essere attribuiti a variabili non controllate (effetto placebo, regressione alla media, ecc.).\n\nUna teoria ben formulata aiuta a delimitare le ipotesi, guidare il disegno di ricerca e interpretare correttamente i dati. In assenza di ciò, i numeri raccolti potrebbero essere viziati da fattori confondenti o da semplici correlazioni spurious.\n\n\n“Junk science” in massimo 10 righe\n\n\nEsempio di testo in 10 righe (circa)\n**Lo studio sul mind-body healing viene talvolta definito “junk science” da Gelman perché, in mancanza di una teoria sostanziale solida, i dati raccolti non forniscono indicazioni chiare sui processi psicologici o fisiologici coinvolti. Una ricerca classificata come “junk science” è priva di rigore metodologico o teorico, e può presentare gravi problemi di replicabilità o di interpretazione dei risultati. In particolare, se non vi è un modello plausibile che colleghi in modo coerente la pratica mente-corpo ai cambiamenti in variabili biologiche e comportamentali, i risultati empirici rischiano di essere semplici coincidenze. L’assenza di un costrutto ben definito e di ipotesi derivanti da una teoria coerente rende difficile capire se i cambiamenti osservati siano reali, casuali o dovuti ad altre cause non considerate (per esempio, l’effetto placebo). Infine, senza un’adeguata cornice teorica, gli studiosi non sanno come interpretare o generalizzare i dati, e la scienza non progredisce realmente.*\n\n\nEsempio di uno studio privo di teoria solida (ipotesi di “junk science”)\n\n\nSituazione ipotetica: Uno studio che raccoglie decine di variabili sulla personalità e sul benessere, poi usa tecniche statistiche sofisticate (analisi di big data, reti neurali, ecc.) per trovare correlazioni fra i tratti di personalità e centinaia di indicatori fisici.\nPerché “junk science”: Se lo studio non definisce a priori quali ipotesi testare e non ha una teoria chiara che spieghi perché certe caratteristiche di personalità dovrebbero correlarsi con determinati parametri fisici, i risultati trovati potrebbero essere frutto di coincidenze casuali. Inoltre, in assenza di un modello teorico solido, anche risultati statisticamente significativi possono essere privi di significato dal punto di vista psicologico.\n\nEsercizio 2 – Problemi di Misurazione\n\nTre possibili fattori confondenti nell’efficacia di un intervento psicologico\n\n\nEffetto placebo: I partecipanti migliorano perché si aspettano di migliorare, non per l’effettiva efficacia dell’intervento.\n\nAspettative dei partecipanti: Se sanno di partecipare a uno studio, potrebbero modificare il proprio comportamento (effetto Hawthorne).\n\nDesiderabilità sociale: I partecipanti forniscono risposte che ritengono socialmente desiderabili, falsando i risultati (ad esempio, sottostimando i livelli di ansia o stress).\n\n\nCome questi fattori confondenti compromettono la validità interna\n\n\nLa validità interna riguarda il grado in cui è possibile concludere che sia effettivamente la variabile indipendente (l’intervento) a causare le modifiche osservate nella variabile dipendente (es. livelli di ansia).\n\nSe subentrano l’effetto placebo, aspettative non controllate o tendenze alla desiderabilità sociale, diventa difficile stabilire un nesso causale chiaro. Esiste sempre il dubbio che altri processi cognitivi o sociali (non l’intervento in sé) abbiano prodotto il risultato.\n\n\nDue caratteristiche fondamentali di una buona scala di misurazione\n\n\nAffidabilità: Capacità dello strumento di fornire misure stabili e coerenti nel tempo (ad esempio, coerenza interna, stabilità test-retest).\n\nValidità: Capacità dello strumento di misurare effettivamente ciò che si propone di misurare (validità di contenuto, di costrutto, di criterio).\n\nEsercizio 3 – Precisione e Bias\n\nDefinizioni di precisione e bias\n\n\nPrecisione: Indica il grado di dispersione (o variabilità) delle misurazioni. Uno strumento preciso produce misure molto simili fra loro se ripetute nelle stesse condizioni (bassa varianza).\n\nBias (distorsione): Indica l’errore sistematico, ossia la tendenza a sovra- o sottostimare sistematicamente il fenomeno in esame. Uno strumento può essere molto coerente nelle misure, ma se è “tarato” male, darà sempre un risultato distorto.\n\n\nEsempio concreto di misura “precisa ma distorta” e “poco precisa ma non distorta”\n\n\nPrecisa ma distorta: Un cronometro che, a causa di un difetto di fabbricazione, parte sempre con 2 secondi di ritardo ma poi misura i tempi con estrema coerenza. Risultato: tutte le misure saranno molto simili (alta precisione), ma sempre sfasate di 2 secondi (alto bias).\n\nPoco precisa ma non distorta: Un termometro vecchio che a volte segna 36,2°C, altre 36,7°C, altre 37,1°C, senza un pattern sistematico. In media potrebbe risultare vicino ai 36,5°C, quindi senza un bias chiaro, ma con un’alta variabilità tra una misurazione e l’altra (bassa precisione).\n\n\nConseguenze di scarsa precisione e alto bias\n\n\nSe uno strumento è poco preciso (alta variabilità) e altamente distorto (bias elevato), i risultati ottenuti non solo oscillano in modo imprevedibile, ma sono costantemente lontani dal valore “vero”.\n\nIn queste condizioni, le conclusioni diventano inaffidabili, poiché è quasi impossibile distinguere l’effetto reale (casuale o causale) dalle deformazioni introdotte dallo strumento e dall’errore di misura.\n\nEsercizio 4 – Validità Interna ed Esterna\n\nDue fattori che compromettono la validità interna e due fattori che compromettono la validità esterna (nell’esempio del mind-body healing)\n\n\nValidità interna:\n\nAssegnazione non casuale ai gruppi: se i partecipanti scelgono autonomamente di aderire alle pratiche mente-corpo, potrebbero essere più motivati o avere caratteristiche iniziali diverse.\n\nMancata o inadeguata gestione dell’effetto placebo: non sapere se l’intervento “mente-corpo” sia stato percepito come particolarmente “speciale” dai partecipanti può introdurre differenze di aspettativa.\n\nValidità esterna:\n\nCampione non rappresentativo: se lo studio è condotto solo su persone che frequentano un determinato tipo di centro di benessere, i risultati potrebbero non essere generalizzabili all’intera popolazione.\n\nContesto specifico: pratiche mente-corpo svolte in un ambiente estremamente controllato (es. un laboratorio o un ritiro speciale) potrebbero non replicarsi nella vita quotidiana di chiunque.\n\n\n\nDifferenze tra validità interna ed esterna (5-8 righe di esempio)\n\n\nLa validità interna si riferisce alla correttezza del disegno di ricerca nel dimostrare un effetto causale. Un alto livello di validità interna implica che i ricercatori siano ragionevolmente sicuri che l’intervento (ad esempio, una tecnica mente-corpo) abbia causato i risultati osservati (miglioramento della salute). La validità esterna, invece, riguarda la possibilità di generalizzare i risultati a contesti, persone e tempi differenti. Se un intervento è stato testato in condizioni molto specifiche, potrebbe funzionare bene solo in quel contesto e con quel particolare campione. Per esempio, un intervento sul mind-body healing con individui altamente motivati potrebbe non dare gli stessi risultati in una popolazione generalizzata. Allo stesso modo, uno studio sull’apprendimento condotto in un laboratorio altamente controllato potrebbe non riflettere le reali dinamiche di un’aula scolastica.\n\n\nModifica al disegno di ricerca per migliorare la validità interna e conseguenze sulla validità esterna\n\n\nProposta: Introdurre un gruppo di controllo con un intervento placebo o un’attività simile ma priva di contenuto “mente-corpo” (ad es. sessioni di lettura rilassante). In questo modo, si può confrontare l’effetto “specífico” dell’intervento.\nCome influenza la validità interna: Con un gruppo di controllo placebo, diventa più semplice escludere che il miglioramento sia dovuto solo alle aspettative dei partecipanti. Questo riduce il rischio di confondenti e aumenta la validità interna.\nCome influenza la validità esterna: Potrebbe rendere il contesto dello studio più artificiale (un gruppo fa “meditazione”, l’altro legge in silenzio), il che potrebbe ridurre la naturalezza della situazione e potenzialmente limitare la generalizzabilità ad ambienti reali (validità esterna).\n\nEsercizio 5 – Integrare Teoria e Misurazione: Breve Progetto di Ricerca\n\nBreve traccia di progetto: “Training di rilassamento mentale per ridurre l’ansia negli studenti universitari”\n\n\nTeoria di base\nIl training di rilassamento mentale si fonda sul presupposto teorico che le tecniche di riduzione dello stress (es. respirazione consapevole, rilassamento muscolare progressivo) possano agire sui livelli di attivazione fisiologica e sui pensieri intrusivi. Riducendo l’iperattivazione del sistema nervoso simpatico e favorendo uno stato di calma, diminuisce l’ansia percepita.\nIpotesi\nGli studenti che seguono il training di rilassamento per 4 settimane mostreranno una riduzione significativa nei punteggi di ansia, rispetto a un gruppo di controllo che non partecipa al training.\nMisurazione\nUtilizzo di una scala validata come lo STAI (State-Trait Anxiety Inventory) per misurare il livello di ansia pre e post intervento. Possibile integrazione con misure fisiologiche (battito cardiaco a riposo) per avere dati oggettivi.\nControllo dei confondenti\n\nRegistrare la storia clinica dei partecipanti (per escludere coloro che assumono farmaci ansiolitici).\n\nRichiedere che i partecipanti non modifichino drasticamente le proprie abitudini di studio o di vita durante l’intervento.\n\nAssicurarsi che i valutatori non sappiano chi fa parte del gruppo di training o del gruppo di controllo (blinding parziale).\n\nValidità\n\nValidità interna: Uso di un gruppo di controllo e assegnazione casuale (randomizzazione) per assicurare che i due gruppi siano comparabili.\n\nValidità esterna: Inclusione di studenti provenienti da diverse facoltà, così da riflettere una maggiore eterogeneità di popolazione.\n\n\n\nCome teoria solida e misurazione accurata evitano la “junk science”\n\n\nUna solida cornice teorica spiega i meccanismi psicologici e fisiologici che legano l’intervento (training di rilassamento) all’esito (riduzione dell’ansia).\n\nUna misurazione accurata e validata (STAI, misure fisiologiche) riduce errori e distorsioni. Se le misure sono ripetute nel tempo (pre e post), si possono confrontare i cambiamenti effettivi.\n\nIntegrando teoria e misurazione, i risultati assumono un significato scientifico più robusto. Non basta osservare un miglioramento: occorre dimostrare come e perché tale miglioramento avvenga, evitando di cadere in semplici correlazioni prive di spiegazione (e quindi potenzialmente “junk science”).\n\n\n\n\n\n\n\n\n\n\nProblemi 3\n\n\n\n\n\nEsercizio 1 – Trasformazioni in Scala Nominale\nSituazione\nUn ricercatore vuole indagare la percezione di appartenenza sociale tra studenti universitari di Psicologia. A ciascuno studente viene chiesto di rispondere alla domanda: “Qual è il gruppo studentesco a cui ritieni di appartenere maggiormente?”, scegliendo una tra le seguenti categorie:\n\n\nGruppo A (focalizzato su ricerca e studio)\n\n\n\nGruppo B (focalizzato su attività ricreative)\n\n\n\nGruppo C (focalizzato su volontariato e progetti sociali)\n\n\nIstruzioni\n\nIdentifica la scala di misurazione utilizzata per classificare gli studenti (nominale, ordinale, a intervalli o di rapporti).\n\nIndica quali trasformazioni sono ammissibili su questa scala e spiega perché non è possibile applicare operazioni di tipo aritmetico (somme, differenze, etc.).\n\nProponi un esempio di nuova scala nominale equivalente, ossia una nuova denominazione delle categorie che rispetti la suddivisione originale. (Esempio: rinominarle in Gruppo X, Gruppo Y, Gruppo Z, oppure usare colori, animali-simbolo, ecc.). Spiega perché questa trasformazione non altera i risultati dell’indagine.\n\nEsercizio 2 – Trasformazioni in Scala Ordinale\nSituazione\nIn un questionario sul benessere psicologico, agli studenti viene chiesto di classificare il loro stato di motivazione allo studio su una scala da 1 (bassa motivazione) a 5 (alta motivazione). Si ottiene così un dato ordinalmente misurato.\nIstruzioni\n\nSpiega perché tale variabile (“livello di motivazione”) rappresenta una scala ordinale. Quali proprietà la rendono diversa da una semplice scala nominale?\n\nDescrivi in che modo è possibile ridenominare i valori della scala (ad esempio, da [1,2,3,4,5] a [“Molto bassa”, “Bassa”, “Media”, “Alta”, “Molto alta”]) senza alterare il rapporto d’ordine tra le categorie.\n\nProponi un esempio di trasformazione non ammissibile: qual è un’operazione aritmetica che non avrebbe senso applicare su una scala ordinale e perché (ad esempio, calcolare “il doppio di motivazione”)?\n\nEsercizio 3 – Trasformazioni in Scala ad Intervalli\nSituazione\nUn gruppo di ricercatori in Psicometria vuole confrontare i punteggi di un test d’intelligenza (misurati secondo la scala tradizionale del QI, con media 100 e deviazione standard 15) con un nuovo test sperimentale. Come ben noto, la scala del QI è considerata, nelle sue approssimazioni psicometriche, una scala ad intervalli.\nIstruzioni\n\nSpiega in cosa consiste la trasformazione lineare ammessa (del tipo \\(y' = a + b y\\), con \\(b &gt; 0\\)) e perché tale trasformazione preserva le differenze tra i punteggi.\n\nFai un esempio concreto di trasformazione lineare: supponi di voler “riscalare” i punteggi del QI in modo che la nuova media sia 50. Definisci i valori di \\(a\\) e \\(b\\) (indicando un’ipotesi di calcolo) e mostra come viene modificato il punteggio di un individuo con QI = 115.\n\nDiscuta perché, nonostante la somiglianza con le scale ordinale e nominale (puoi comunque distinguere punteggi e ordinarli), una scala ad intervalli consente operazioni matematiche più complesse (ad esempio, differenze) che non sarebbero valide negli altri due livelli.\n\nEsercizio 4 – Trasformazioni in Scala di Rapporti\nSituazione\nUn laboratorio di psicofisiologia misura i tempi di reazione (in millisecondi) a uno stimolo luminoso. Poiché il tempo di reazione pari a 0 ms significa realmente assenza di risposta (ovvero, impossibile da misurare in pratica, ma concettualmente corrisponde a intensità nulla del fenomeno “tempo di reazione”), ci troviamo in una scala di rapporti.\nIstruzioni\n\nSpiega perché il tempo di reazione soddisfa i requisiti di una scala di rapporti, inclusa la presenza di uno zero assoluto e la possibilità di confrontare i punteggi con rapporti (ad esempio, “il tempo di reazione del partecipante A è il doppio di quello del partecipante B”).\n\nQuali sono le trasformazioni ammissibili su una scala di rapporti? Fornisci un esempio numerico (per esempio, se moltiplichi tutti i tempi di reazione per 2, che cosa accade al rapporto tra i punteggi di due partecipanti?).\n\nDescrivi il motivo per cui è possibile dire che A ha una latenza doppia di B usando i millisecondi, ma non è sempre possibile fare asserzioni analoghe usando scale ad intervalli. Fai un parallelo, ad esempio, con le temperature in Celsius.\n\nEsercizio 5 – Riconoscere e Applicare le Trasformazioni nei Quattro Livelli di Scala\nSituazione\nUn docente di Psicologia sperimentale ha raccolto quattro serie di dati su vari aspetti:\n\nOrientamento politico (liberale, conservatore, centrista, ecc.).\n\nClassifica di soddisfazione sul tirocinio (1° posto, 2° posto, 3° posto, etc.).\n\nPunteggi di un test di personalità su un fattore (con media = 100, deviazione standard = 10) trattato come scala ad intervalli.\n\nFrequenza cardiaca a riposo misurata in battiti al minuto (bpm).\n\nIstruzioni\n\nIdentifica per ciascuno dei quattro insiemi di dati il livello di scala (nominale, ordinale, intervalli, rapporti).\n\nPer ognuno dei quattro livelli di scala elenca almeno una trasformazione ammessa (ad es. ridenominazione delle categorie per la nominale, traslazione e dilatazione per l’intervalli, ecc.) e una non ammessa (esempio: non puoi sommare categorie nominali, non puoi calcolare la radice quadrata di un rango ordinale dandogli significato, ecc.).\n\nRifletti in breve (2-3 righe) su come queste differenze nelle trasformazioni ammissibili incidano sull’interpretazione dei dati e sulle analisi statistiche che il docente potrà validamente utilizzare (ad esempio, test non parametrici per variabili ordinarie, test parametrici per scale ad intervalli/rapporti).\n\n\n\n\n\n\n\n\n\n\nSoluzioni 3\n\n\n\n\n\nEsercizio 1 – Trasformazioni in Scala Nominale\n\nIdentificazione della scala La classificazione degli studenti in “Gruppo A/B/C” è scala nominale. Non esiste alcun ordine intrinseco tra le categorie; si tratta semplicemente di etichette qualitative.\nTrasformazioni ammissibili\n\n\nTrasformazioni ammissibili: ridenominare o rinominare le categorie senza modificare la partizione del campione (esempio: A → “Studio”, B → “Ricreazione”, C → “Volontariato”).\n\nL’unica operazione aritmetica consentita è il conteggio delle frequenze nelle varie categorie.\n\n\nOperazioni non consentite: non è possibile sommare o sottrarre etichette, né confrontare categorie in termini di “più/meno grande” o “rapporto”.\n\n\nEsempio di nuova scala nominale equivalente\n\n\nPotresti chiamare i gruppi: “Alpha, Beta, Gamma” (oppure con colori: “Rosso, Blu, Verde”).\n\nQuesta trasformazione non altera la classificazione in sé: tutti gli studenti del Gruppo A rimangono nel “nuovo” gruppo Alpha, e così via.\n\nNon cambia la struttura dei dati e di conseguenza non altera i risultati della ricerca (restano invariate le frequenze e la suddivisione nelle categorie).\n\nEsercizio 2 – Trasformazioni in Scala Ordinale\n\nPerché è una scala ordinale? La variabile “livello di motivazione” da 1 (bassa) a 5 (alta) indica:\n\n\nClassificazione in categorie (come in una scala nominale).\n\nRelazione d’ordine chiara (1 &lt; 2 &lt; 3 &lt; 4 &lt; 5).\n\nNon fornisce alcuna informazione sulle distanze reali tra i punti (non è detto che la differenza tra 1 e 2 sia uguale a quella tra 3 e 4).\nÈ quindi una scala ordinale e non semplicemente nominale.\n\n\nRidenominazione dei valori mantenendo l’ordine\n\n\nPuoi sostituire i numeri con etichette testuali rispettando lo stesso ordine:\n1 → “Molto bassa”\n2 → “Bassa”\n3 → “Media”\n4 → “Alta”\n5 → “Molto alta”\n\nL’ordine rimane lo stesso: “Molto bassa” &lt; “Bassa” &lt; … &lt; “Molto alta”.\n\n\nEsempio di trasformazione non ammissibile\n\n\nCalcolare “il doppio di motivazione”: dire che la categoria 4 è “il doppio” della categoria 2 non ha senso, perché non c’è un’unità di misura fissa che quantifichi la differenza tra i livelli. Le categorie ordinali servono solo a ordinare, non a quantificare in modo assoluto.\n\nEsercizio 3 – Trasformazioni in Scala ad Intervalli\n\nTrasformazione lineare ammessa\n\n\nForma generale: \\(y' = a + b y\\), con \\(b &gt; 0\\).\n\nPreserva le differenze tra i valori (ad esempio, \\((y_2 - y_1) = (y'_2 - y'_1) / b\\)), perché la traslazione aggiunge una costante a tutti i punteggi e la dilatazione (moltiplicazione per \\(b\\)) mantiene le proporzioni fra gli intervalli.\n\n\nEsempio concreto\n\n\nScala QI: media = 100, deviazione standard = 15.\n\nVuoi che la nuova media sia 50.\n\nPer semplificare, supponiamo di voler “spostare” ogni valore verso una nuova scala centrata a 50, mantenendo una deviazione standard proporzionale.\n\nUna possibile trasformazione lineare:\n\\[\n  y' = (y - 100) + 50 = y - 50.\n\\]\nIn questo caso, \\(a = -50\\), \\(b = 1\\).\n\nSe un individuo ha QI = 115, allora \\(y' = 115 - 50 = 65\\).\n\n\nSe invece volessi anche cambiare la deviazione standard, potresti usare un fattore \\(b \\neq 1\\). Ad esempio, se desideri una deviazione standard = 10, potresti usare \\(b = \\frac{10}{15} \\approx 0.67\\).\n\n\nDifferenze rispetto alle scale nominali/ordinali\n\n\nCon una scala ad intervalli puoi:\n\nOrdinare i punteggi.\n\nStabilire differenze (es. un individuo A ha 15 punti in più di B).\n\n\nNon puoi invece stabilire rapporti (es. “A ha il doppio di X rispetto a B” non è lecito), perché lo zero è arbitrario e la distanza “0” non rappresenta l’assenza del fenomeno (come invece avviene nella scala di rapporti).\n\nEsercizio 4 – Trasformazioni in Scala di Rapporti\n\nPerché il tempo di reazione è in una scala di rapporti?\n\n\nZero assoluto: un tempo di reazione (teoricamente) pari a 0 ms significherebbe nessun tempo trascorso → totale assenza del fenomeno misurato (impossibile nella pratica, ma concettualmente definisce uno zero non arbitrario).\n\nPuoi confrontare i punteggi con rapporti: “il tempo di reazione di A è il doppio di quello di B” (200 ms vs. 100 ms).\n\n\nTrasformazioni ammissibili\n\n\nTrasformazione di similarità: \\(y' = b y\\) con \\(b &gt; 0\\).\n\nSe hai due tempi di reazione \\(y_1\\) e \\(y_2\\), il rapporto \\(\\frac{y_1}{y_2}\\) rimane invariato anche dopo la trasformazione:\n\\[\n  \\frac{y'_1}{y'_2} = \\frac{b y_1}{b y_2} = \\frac{y_1}{y_2}.\n\\]\nEsempio numerico: se i tempi di reazione di due partecipanti sono 100 ms e 200 ms, il rapporto è 2. Se moltiplichi entrambi per 2, ottieni 200 ms e 400 ms, e il rapporto rimane 2.\n\n\nConfronto con scala ad intervalli (esempio delle temperature)\n\n\nIn una scala di rapporti puoi dire “A ha una latenza doppia di B” perché lo zero non è arbitrario.\n\nCon la temperatura (scala ad intervalli) lo zero (es. 0°C) non rappresenta l’assenza di calore, quindi non ha senso dire che 80°C è “il doppio” di 40°C. Cambiando la scala (ad es. Fahrenheit) il rapporto cambia.\n\nEsercizio 5 – Riconoscere e Applicare le Trasformazioni nei Quattro Livelli di Scala\n\nIdentificazione del livello di scala\n\n\nOrientamento politico: scala nominale (categorie qualitative prive di ordine).\n\nClassifica di soddisfazione (1°, 2°, 3°, …): scala ordinale (c’è un ordine, ma non si conosce la “distanza” fra i posti).\n\nPunteggi di un test di personalità (con media=100, dev.st=10), considerati approssimazione di una scala ad intervalli (si assumono le differenze significative, lo zero è arbitrario).\n\nFrequenza cardiaca a riposo (bpm): scala di rapporti (zero assoluto e rapporti confrontabili).\n\n\nTrasformazioni ammesse e non ammesse\n\n\nNominale:\n\nAmmessa: cambiare etichette (A → “Liberale”, B → “Conservatore” ecc.).\n\nNon ammessa: sommare categorie, ordinare, calcolare media delle categorie.\n\n\nOrdinale:\n\nAmmessa: rietichettare i ranghi (1° → “Migliore”, 2° → “Secondo posto”…).\n\nNon ammessa: calcolare rapporti (il 2° posto non è “il doppio” del 1°), sommare posizioni in modo significativo.\n\n\nA intervalli:\n\nAmmessa: trasformazione lineare (traslazione + dilatazione).\n\nNon ammessa: dire che un punteggio è “tre volte” un altro; lo zero è arbitrario.\n\n\nA rapporti:\n\nAmmessa: trasformazione di similarità (\\(y' = b y\\)), in cui i rapporti rimangono invariati.\n\nNon ammessa: aggiunta di una costante a tutti i valori (questa sposterebbe lo zero, rendendolo arbitrario e trasformando la scala in una scala ad intervalli).\n\n\n\nImplicazioni per l’interpretazione e le analisi\n\n\nUna variabile nominale consente solo frequenze e test non parametrici basati su conteggi (es. Chi-quadrato).\n\nUna variabile ordinale permette test di ordinamento (es. test di rank, come il Wilcoxon), ma non calcoli di media con significato forte.\n\nUna scala ad intervalli permette di usare statistiche parametriche (calcolo di media, varianza, test come t-test, ANOVA), assumendo che l’interpretazione delle differenze sia coerente.\n\nUna scala di rapporti permette, in più, il confronto di rapporti (ad esempio, si possono applicare modelli parametrici che includano il concetto di proporzioni o slope logico su dati che abbiano senso a zero assoluto).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_measurement.html#bibliografia",
    "href": "chapters/key_notions/04_measurement.html#bibliografia",
    "title": "4  La misurazione in psicologia",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAungle, P., & Langer, E. (2023). Physical healing as a function of perceived time. Scientific Reports, 13(1), 22432.\n\n\nDomini, F., & Caudek, C. (2009). The intrinsic constraint model and Fechnerian sensory scaling. Journal of Vision, 9(2), 25–25.\n\n\nLilienfeld, S. O., & Strother, A. N. (2020). Psychological measurement and the replication crisis: Four sacred cows. Canadian Psychology/Psychologie Canadienne, 61(4), 281–288.\n\n\nMaul, A., Irribarra, D. T., & Wilson, M. (2016). On the philosophical foundations of psychological measurement. Measurement, 79, 311–320.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/05_cognitive_models.html",
    "href": "chapters/key_notions/05_cognitive_models.html",
    "title": "5  Dalla descrizione alla spiegazione: modelli meccanicistici e computazionali in psicologia",
    "section": "",
    "text": "5.1 Introduzione\nPer comprendere e spiegare i processi mentali in modo più rigoroso, è necessario adottare modelli che vadano oltre la semplice descrizione. Questo capitolo introduce i modelli meccanicistici e computazionali, mostrando come possano rafforzare la spiegazione psicologica. Negli ultimi anni, la psicologia ha attraversato una crisi profonda legata alla riproducibilità dei risultati sperimentali. Molti effetti classici non riescono a replicarsi in studi successivi, sollevando interrogativi sulla solidità delle teorie psicologiche. In questo contesto, è sempre più chiaro che il tipo di modelli utilizzati per spiegare i fenomeni psicologici ha un impatto cruciale sulla credibilità e robustezza della ricerca scientifica. Una distinzione centrale a questo riguardo è quella tra modelli fenomenologici e modelli meccanicistici.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Dalla descrizione alla spiegazione: modelli meccanicistici e computazionali in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/05_cognitive_models.html#introduzione",
    "href": "chapters/key_notions/05_cognitive_models.html#introduzione",
    "title": "5  Dalla descrizione alla spiegazione: modelli meccanicistici e computazionali in psicologia",
    "section": "",
    "text": "5.1.1 Modelli fenomenologici: descrivere senza spiegare\nI modelli fenomenologici si limitano a descrivere relazioni osservabili tra variabili psicologiche, spesso attraverso formule matematiche o rappresentazioni statistiche. Un esempio classico è una legge psicofisica che descrive la relazione tra stimolazione sensoriale e risposta percepita. Sebbene questi modelli possano essere estremamente predittivi, non forniscono informazioni sul “come” e “perché” un certo fenomeno si verifica. Non specificano, cioè, le entità e le attività organizzate che lo generano (es. meccanismi cognitivi, neuroni, moduli funzionali).\nCome sottolineato da Povich (2025), modelli fenomenologici come questi possono essere accurati, compatti, persino predittivi — ma non necessariamente esplicativi. In effetti, possono mancare della capacità di rispondere a domande controfattuali del tipo “che cosa succederebbe se…?” e non permettono un controllo diretto sul fenomeno. Questa limitazione si rivela particolarmente problematica in un’epoca in cui la replicabilità richiede non solo constatare un effetto, ma anche comprenderne le condizioni causali e contestuali.\n\n5.1.2 Dai modelli meccanicistici alla modellazione computazionale\nUn modello meccanicistico cerca di rappresentare le componenti causali di un fenomeno. Secondo una definizione ampiamente condivisa, un meccanismo è “una collezione organizzata di entità e attività che produce o mantiene un certo fenomeno” (Bechtel, 2009). I modelli meccanicistici hanno l’obiettivo di descrivere questi meccanismi, specificando in che modo le componenti interagiscono per generare il comportamento osservato.\nNel contesto della psicologia, i modelli meccanicistici vanno oltre la descrizione di correlazioni osservabili. Cercano di identificare strutture cognitive, processi neurali o dinamiche corpo-ambiente o interazioni tra livelli (funzionale, computazionale, implementazionale). Un esempio ben noto è il modello della long-term potentiation (LTP) nella memoria, che spiega come variazioni nei recettori NMDA e AMPA e nella concentrazione di ioni calcio e magnesio determinano il rafforzamento sinaptico — un chiaro caso di spiegazione meccanicistica.\nOggi, molti modelli meccanicistici in psicologia sono implementati come modelli computazionali, ovvero rappresentazioni formali che simulano i processi interni ipotizzati. Attraverso la simulazione e la stima dei parametri, questi modelli permettono di inferire il funzionamento dei meccanismi sottostanti a partire dal comportamento osservabile. I modelli computazionali soddisfano i criteri della spiegazione meccanicistica quando forniscono informazioni su entità ipotetiche (come credenze, soglie decisionali, accumulo di evidenza) e sulle loro interazioni causali.\n\n5.1.3 La differenza epistemica: come distinguere spiegazione da predizione\nUn punto chiave nella distinzione tra spiegazioni fenomenologiche e meccanicistiche è che solo le seconde soddisfano i criteri di potere esplicativo propriamente detto. Come chiarisce Povich (2025), un modello esplicativo deve permettere di:\n\nrispondere a domande controfattuali (“che cosa succederebbe se una componente fosse diversa?”);\nfornire la base per manipolare o controllare il fenomeno.\n\nQuesti criteri sono cruciali per superare la crisi della replicabilità: sapere che un effetto si verifica in certe condizioni è poco utile se non si capisce perché avviene e quali sono i meccanismi sottostanti che lo rendono stabile o instabile rispetto a cambiamenti contestuali.\n\n5.1.4 Oltre le metafore meccaniche: che cosa rende meccanicistico un modello?\nUna fonte comune di confusione riguarda l’idea che un modello, per essere meccanicistico, debba avere necessariamente la forma di una macchina, con entità concrete (es. neuroni, aree cerebrali) e connessioni visibili tra di esse. Ma questa è una semplificazione fuorviante. Ciò che rende un modello meccanicistico non è la sua forma visiva o metaforica, ma la sua capacità di rappresentare l’organizzazione causale del processo che genera un certo comportamento. Un modello può essere espresso con equazioni matematiche, algoritmi, reti neurali, simulazioni, eppure contribuire in modo decisivo a una spiegazione meccanicistica se specifica in che modo le componenti del sistema interagiscono per produrre l’effetto osservato.\nPer chiarire questa idea, possiamo richiamare i tre livelli di spiegazione proposti da David Marr (1982), uno dei riferimenti fondamentali nella psicologia cognitiva computazionale:\n\n\nLivello computazionale: Cosa fa il sistema e perché (qual è il problema che risolve?).\n\nLivello algoritmico: Come lo fa? Quali rappresentazioni interne e quali trasformazioni (regole di calcolo) sono coinvolte.\n\nLivello implementativo: Con quali mezzi fisici è realizzato (per esempio, circuiti neurali).\n\nQuesta distinzione aiuta a chiarire che un modello può essere meccanicistico anche se non rappresenta direttamente substrati biologici, purché descriva in modo formale come un sistema risolve un problema e quali regole seguono le sue componenti.\nNel contesto della psicologia, i modelli computazionali che operano al livello algoritmico o computazionale — come il modello di Rescorla-Wagner o il Drift Diffusion Model — sono perfettamente coerenti con un approccio meccanicistico, anche se non rappresentano esplicitamente l’implementazione biologica.\nQuesti modelli sono “meccanicistici” nel senso che:\n\n\ndescrivono entità funzionali (es. valore atteso, evidenza accumulata),\n\nspecificano regole di interazione tra queste entità (es. aggiornamento, accumulo, soglie),\n\nproducono il comportamento osservabile come risultato di queste interazioni.\n\nDunque, ciò che conta non è la forma del modello, ma la funzione esplicativa che svolge all’interno della teoria psicologica. Modelli formulati come sistemi dinamici, modelli bayesiani gerarchici, modelli di reti neurali artificiali o modelli simbolici possono tutti contribuire a spiegazioni meccanicistiche, se mostrano come un certo comportamento emerga da un’organizzazione di componenti in interazione.\n\n5.1.5 Perché i modelli meccanicistici rafforzano la riproducibilità\nLa crisi della riproducibilità può essere vista come il sintomo di un’eccessiva fiducia in modelli fenomenologici che mancano di profondità esplicativa. I modelli meccanicistici, al contrario:\n\nesplicitano gli assunti causali e strutturali;\npermettono verifiche controfattuali e manipolazioni;\nchiariscono quando e perché un effetto dovrebbe ripetersi o variare;\nsono meno vulnerabili al cherry picking e agli effetti di contesto non dichiarati;\ni modelli computazionali meccanicistici, come il DDM e il modello di Rescorla-Wagner, consentono di simulare e verificare quantitativamente ipotesi sui meccanismi interni, rendendo più trasparente e replicabile l’inferenza psicologica.\n\nIn breve, un modello meccanicistico non si limita a dire che “A predice B”, ma mostra come A produce B, e in quali condizioni questo accade.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Dalla descrizione alla spiegazione: modelli meccanicistici e computazionali in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/05_cognitive_models.html#esempi-di-modelli-computazionali-meccanicistici",
    "href": "chapters/key_notions/05_cognitive_models.html#esempi-di-modelli-computazionali-meccanicistici",
    "title": "5  Dalla descrizione alla spiegazione: modelli meccanicistici e computazionali in psicologia",
    "section": "\n5.2 Esempi di modelli computazionali meccanicistici",
    "text": "5.2 Esempi di modelli computazionali meccanicistici\nNel contesto della psicologia cognitiva e della neuroscienza computazionale, molti modelli meccanicistici assumono la forma di modelli computazionali. Questi modelli non si limitano a correlare input e output, ma simulano i processi interni che trasformano gli input (es. stimoli) in output (es. risposte comportamentali), ipotizzando una dinamica causale tra variabili latenti e osservabili.\n\n5.2.1 Il modello di Rescorla-Wagner: apprendimento associativo come aggiornamento predittivo\nUno dei modelli più influenti nello studio dell’apprendimento è il modello di Rescorla-Wagner. Questo modello descrive come gli individui apprendano le associazioni tra stimoli e risposte sulla base dell’errore di previsione. L’apprendimento avviene aggiornando le aspettative di ricompensa in base alle esperienze passate, utilizzando due parametri fondamentali:\n\n\n\\(\\alpha\\) (tasso di apprendimento): determina quanto l’errore di previsione influisce sull’aggiornamento dell’aspettativa.\n\n\\(\\beta\\) (temperatura della scelta): regola la probabilità di selezionare l’opzione con il valore atteso più alto rispetto a esplorare alternative.\n\n\n5.2.1.1 L’Apprendimento Associativo\nL’apprendimento per rinforzo studia come le persone imparano a massimizzare le ricompense in ambienti in cui la scelta ottimale è inizialmente sconosciuta. Immaginiamo un partecipante che deve scegliere ripetutamente tra due slot machine, ricevendo ricompense con probabilità diverse per ogni macchina. L’obiettivo è massimizzare le vincite nel tempo.\nPer illustrare il modello, si usa spesso la metafora delle slot machine. Nel caso più semplice, si immagina un agente che svolge il compito con \\(n\\) tentativi, due slot machine e probabilità di ricompensa fisse \\(\\mu = [0.2, 0.8]\\).\n\n5.2.1.2 Regola di Apprendimento per Rinforzo (\\(\\delta\\)-rule)\nIl modello di Rescorla-Wagner descrive l’apprendimento come un processo basato sull’errore di previsione. L’aggiornamento del valore di uno stimolo avviene secondo la seguente equazione:\n\\[\nV_{s,t} = V_{s,t-1} + \\alpha (r_{t-1} - V_{s,t-1})\n\\]\nDove:\n\n\n\\(V_{s,t}\\) è il valore atteso dello stimolo \\(s\\) al tempo \\(t\\).\n\n\\(r_{t-1}\\) è la ricompensa ottenuta alla prova precedente.\n\n\\(\\alpha\\) (tra 0 e 1) è il tasso di apprendimento, che determina la velocità con cui l’agente aggiorna le proprie aspettative.\n\nSe il valore di \\(\\alpha\\) è alto, l’apprendimento sarà rapido, mentre se è basso, l’agente si baserà maggiormente sulle esperienze passate.\n\n5.2.1.3 Modello di Scelta: Softmax\nDopo aver aggiornato i valori attesi delle opzioni, il partecipante deve scegliere tra esse.\nDue strategie possibili sono:\n\n\nsfruttamento: selezionare sempre l’opzione con il valore più alto;\n\nesplorazione: scegliere occasionalmente un’opzione con un valore più basso per verificare se potrebbe essere migliore.\n\nPer modellare questo comportamento si usa la funzione Softmax:\n\\[\np(s) = \\frac{\\exp(\\beta \\cdot V_{s})}{\\sum_i \\exp(\\beta \\cdot V_{i})},\n\\]\ndove \\(\\beta\\) è un parametro che determina il grado di esplorazione:\n\n\n\\(\\beta = 0\\): scelta completamente casuale.\n\n\\(\\beta \\to \\infty\\): scelta deterministica dell’opzione con il valore più alto.\n\nUn individuo con \\(\\beta\\) alto sceglierà quasi sempre l’opzione con il valore atteso più elevato, mentre con un \\(\\beta\\) basso esplorerà più frequentemente.\n\n5.2.1.4 Simulazione dell’Apprendimento con il Modello di Rescorla-Wagner\nPossiamo ora simulare questo processo in R. La funzione seguente implementa la regola di aggiornamento dell’aspettativa sulla base dell’errore di previsione:\n\nupdate_rw &lt;- function(value, alpha=0.15, lambda=1) {\n  value + alpha * (lambda - value)\n}\n\nSimuliamo ora l’apprendimento per 40 prove, assumendo che il partecipante riceva sempre una ricompensa:\n\nn_trials &lt;- 40\nstrength &lt;- numeric(n_trials)\nfor(trial in 2:n_trials) {\n  strength[trial] &lt;- update_rw(strength[trial-1])\n}\nplot(1:n_trials, strength, type = 'l', ylim = c(0,1), xlab = \"Prove\", ylab = \"Aspettativa di ricompensa\")\n\n\n\n\n\n\n\nL’aspettativa di ricompensa aumenta progressivamente fino a stabilizzarsi.\n\n5.2.1.5 Estinzione dell’Associazione\nModificando il valore del rinforzo, possiamo anche simulare l’estinzione dell’apprendimento. Se dopo 25 prove la ricompensa non viene più fornita, il valore associato allo stimolo diminuisce gradualmente:\n\nn_trials &lt;- 50                \nstrength &lt;- numeric(n_trials)\nlambda &lt;- 1\n\nfor(trial in 2:n_trials) {\n  if(trial &gt; 25) {\n    lambda &lt;- 0\n  }\n  strength[trial] &lt;- update_rw(value = strength[trial-1], lambda = lambda)\n}\n\nplot(1:n_trials, strength, type = 'l', ylim = c(0,1), xlab = \"Prove\", ylab = \"Aspettativa di ricompensa\")\n\n\n\n\n\n\n\nL’associazione si estingue gradualmente quando il rinforzo viene rimosso.\n\n5.2.1.6 Implementazione della Regola Softmax\nPer simulare le scelte di un partecipante utilizziamo la funzione Softmax:\n\nsoftmax &lt;- function(beta, x) {\n  1 / (1 + exp(-beta * x))\n}\n\nbeta &lt;- 5\nx &lt;- seq(-1, 1, length.out = 100)\ny &lt;- softmax(beta, x)\nplot(x, y, type = 'l', xlab = \"Valore (A) - valore (B)\", ylab = \"p(scelta = A)\")\n\n\n\n\n\n\n\nLa funzione mostra che:\n\nla probabilità di scegliere un’opzione aumenta con il suo valore atteso;\ncon \\(\\beta\\) elevato, il partecipante sceglie quasi sempre l’opzione migliore;\ncon \\(\\beta\\) basso, le scelte sono più casuali.\n\n5.2.1.7 Verifica e Applicazioni del Modello\nQuello descritto è il meccanismo generatore dei dati ipotizzato dal modello di Rescorla-Wagner. Per testare il modello, è necessario stimare i parametri \\(\\alpha\\) e \\(\\beta\\), e confrontare le previsioni del modello con i dati osservati. Tuttavia, in questo corso non affronteremo il problema della stima dei parametri del modello di Rescorla-Wagner. L’obiettivo principale è comprendere cosa significhi formalizzare quantitativamente un modello psicologico e in che modo questo approccio si differenzi da una semplice analisi delle associazioni tra variabili.\nIn sintesi, il modello di Rescorla-Wagner rappresenta uno strumento essenziale per lo studio dell’apprendimento associativo. Attraverso la simulazione dell’aggiornamento delle aspettative e delle strategie decisionali, possiamo descrivere il comportamento di individui che apprendono in contesti di rinforzo. Questo modello ha trovato applicazione in numerosi ambiti della psicologia cognitiva e delle neuroscienze, contribuendo alla comprensione dei processi di apprendimento e decisione.\n\n5.2.2 Il Drift Diffusion Model (DDM): decisione come accumulo stocastico di evidenza\nIl processo decisionale è uno dei temi centrali della psicologia cognitiva e delle neuroscienze. Ogni giorno prendiamo decisioni, dalle più semplici alle più complesse, influenzate da fattori come la percezione, la memoria, l’attenzione e il contesto in cui ci troviamo. Una domanda fondamentale è: Come prendiamo decisioni in condizioni di incertezza?\nUno dei modelli più utilizzati per rispondere a questa domanda è il Drift Diffusion Model (DDM), un modello matematico che descrive il processo di accumulo delle informazioni fino alla presa di una decisione. Questo modello consente di quantificare e comprendere i meccanismi alla base delle scelte umane.\n\n5.2.2.1 Cos’è il Drift Diffusion Model?\nIl DDM descrive come le persone raccolgono informazioni nel tempo per prendere una decisione tra due alternative. Immagina di dover stabilire se un punto si sta muovendo verso destra o verso sinistra. Non hai una risposta immediata, ma accumuli informazioni (o “evidenza”) nel tempo fino a quando non sei abbastanza sicuro per scegliere.\nQuesto processo è influenzato da vari fattori, come la chiarezza delle prove disponibili e l’incertezza associata alla decisione.\n\n5.2.2.2 Come Funziona il Processo di Accumulo dell’Evidenza?\nIl processo decisionale può essere paragonato a un accumulo graduale di informazioni a favore di una delle due opzioni disponibili. Ecco come funziona:\n\nRaccolta delle informazioni. Ogni nuova informazione che ricevi si accumula a favore di una delle due alternative. Ad esempio, se stai cercando di determinare la direzione del movimento di un punto, ogni piccolo dettaglio visivo ti aiuta ad avvicinarti a una decisione.\nVelocità di accumulo (Drift rate). La velocità con cui raccogli le informazioni dipende dalla qualità del segnale. Se le prove sono chiare e forti, l’accumulo sarà veloce. Se invece sono ambigue, il processo sarà più lento.\nRumore e incertezza. Durante l’accumulo, c’è sempre una componente casuale o “rumore”, che può causare fluttuazioni nel processo. Questo significa che l’informazione non si accumula in modo perfettamente lineare, ma può oscillare a causa di fattori casuali.\nSoglie decisionali. Prima di iniziare il compito, ci sono due “soglie” che rappresentano i punti di decisione. Quando l’evidenza accumulata raggiunge una di queste soglie, si prende la decisione corrispondente.\nTempo di reazione. Il tempo impiegato per raggiungere una delle soglie è il tempo di reazione. Se le informazioni sono chiare, la decisione sarà rapida; se sono ambigue, il tempo sarà più lungo.\n\nUna metafora utile per comprendere questo processo è quella di un secchio che si riempie goccia dopo goccia: ogni informazione raccolta corrisponde a una goccia. Quando il livello d’acqua supera una soglia, si prende la decisione.\n\n5.2.2.3 I Parametri del DDM\nIl DDM è caratterizzato da quattro parametri principali che descrivono diversi aspetti del processo decisionale.\n\nTasso di drift (\\(v\\)). Rappresenta la velocità con cui l’evidenza si accumula a favore di una decisione. Valori più alti indicano un processo decisionale più efficiente, mentre valori più bassi suggeriscono un’accumulazione lenta e incerta.\nSeparazione delle soglie (\\(a\\)). Indica la distanza tra le due soglie decisionali. Valori più alti corrispondono a decisioni più caute (tempi di reazione più lunghi ma minore probabilità di errore), mentre valori più bassi indicano decisioni più rapide ma potenzialmente meno accurate.\nTempo di non-decisione (\\(t_0\\)). Corrisponde al tempo necessario per processi che precedono e seguono l’accumulo di evidenza, come la percezione dello stimolo e l’esecuzione della risposta. Questo tempo è indipendente dall’accumulo delle informazioni.\nBias iniziale (\\(z\\)). Definisce il punto di partenza del processo di accumulo. Se è equidistante tra le due soglie, la decisione è imparziale. Se invece è spostato verso una delle due soglie, significa che la persona ha una predisposizione a scegliere una delle due alternative.\n\n5.2.2.4 Il Compromesso tra Velocità e Accuratezza\nUno degli aspetti più interessanti del DDM è il compromesso tra velocità e accuratezza:\n\nse una persona desidera rispondere rapidamente, può abbassare le soglie decisionali, ma questo aumenta la probabilità di errore;\n\nse invece punta a una maggiore accuratezza, può aumentare la distanza tra le soglie, rendendo il processo più lento ma più affidabile.\n\nQuesto compromesso è evidente in compiti sperimentali come:\n\nil compito di Stroop, dove bisogna ignorare un’informazione interferente (es. leggere il colore di una parola e non il significato della parola stessa);\n\nil compito di decisione lessicale, in cui si deve determinare se una stringa di lettere è una parola esistente o meno.\n\nIl DDM permette di capire se le differenze nei tempi di reazione tra gruppi dipendono da una strategia più cauta (maggiore \\(a\\)) o da una difficoltà nell’accumulare evidenza (minore \\(v\\)).\n\n5.2.2.5 Perché è Importante il DDM?\nIl DDM è uno strumento potente perché permette di quantificare aspetti del processo decisionale che altrimenti sarebbero difficili da misurare, come la velocità di accumulo dell’evidenza o l’effetto del rumore sulla decisione.\nÈ stato applicato in numerosi ambiti, tra cui:\n\n\ncompiti percettivi e decisionali: studi sulla discriminazione di stimoli visivi e uditivi;\n\nprocessi di controllo cognitivo: analisi delle differenze individuali nella regolazione dell’impulsività;\n\npsicopatologia: esplorazione delle alterazioni nel processo decisionale in condizioni come depressione, ansia e schizofrenia.\n\nIl Drift Diffusion Model offre dunque una rappresentazione chiara e quantitativa del processo decisionale in condizioni di incertezza. Descrivendo l’accumulo graduale delle informazioni e il raggiungimento delle soglie decisionali, il modello ci aiuta a comprendere il compromesso tra velocità e accuratezza e i fattori che influenzano le scelte.\nL’applicazione del DDM in psicologia cognitiva e neuroscienze permette di studiare non solo il comportamento umano, ma anche i meccanismi neurali che regolano il processo decisionale.\n\n5.2.2.6 Simulazione del DDM\nUna delle potenzialità del DDM è la possibilità di simulare dati sintetici per confrontare le predizioni del modello con dati empirici. In R, possiamo generare una simulazione semplificata del modello utilizzando pacchetti dedicati come rtdists o brms.\nUn esempio di codice per simulare dati con parametri definiti:\n\n# Nuova configurazione dei parametri\na &lt;- 1.2   # Separazione delle soglie (aumentato)\nv &lt;- 0.3   # Tasso di drift\nt0 &lt;- 0.2  # Tempo di non-decisione\nz &lt;- 0.5   # Bias iniziale (deve essere tra 0 e 1)\n\n# Generazione dei dati\nsim_data &lt;- rdiffusion(n = 1000, a = a, v = v, t0 = t0, z = z)\n\nQuesta funzione genera 1000 decisioni simulate, ciascuna con un tempo di reazione (rt) e una risposta (response) che dipendono dai parametri impostati.\n\n# Visualizzazione dei tempi di reazione\nhist(\n  sim_data$rt, \n  breaks = 30, \n  main = \"Distribuzione dei tempi di reazione\", \n  xlab = \"RT (s)\"\n)\n\n\n\n\n\n\n\nQuesto codice genera una distribuzione di tempi di reazione e scelte coerenti con le ipotesi del DDM, permettendo di esplorare l’effetto delle variazioni dei parametri sul comportamento del modello.\nIn sintesi, il Drift Diffusion Model fornisce un quadro teorico potente per l’analisi del processo decisionale in psicologia cognitiva. Modellando il tempo di reazione e la probabilità di risposta in termini di parametri interpretabili, il DDM permette di distinguere tra strategie decisionali e difficoltà cognitive, superando i limiti di un’analisi puramente descrittiva. Grazie alla sua capacità di catturare la dinamica dei processi decisionali, il DDM è oggi uno degli strumenti più utilizzati per studiare il comportamento umano in contesti sperimentali e applicativi.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Dalla descrizione alla spiegazione: modelli meccanicistici e computazionali in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/05_cognitive_models.html#riflessioni-conclusive",
    "href": "chapters/key_notions/05_cognitive_models.html#riflessioni-conclusive",
    "title": "5  Dalla descrizione alla spiegazione: modelli meccanicistici e computazionali in psicologia",
    "section": "\n5.3 Riflessioni Conclusive",
    "text": "5.3 Riflessioni Conclusive\nLa crisi di replicabilità che sta attraversando la psicologia contemporanea richiede un cambiamento di prospettiva: è necessario abbandonare i modelli puramente descrittivi a favore di approcci meccanicistici e computazionali. Questi ultimi, infatti, non si limitano a prevedere il comportamento, ma identificano i processi algoritmici che lo generano, trasformando domande vaghe in ipotesi formalizzate e verificabili.\nIn questo capitolo abbiamo introdotto due modelli fondamentali: il modello Rescorla-Wagner e il modello Drift Diffusion model.\nIl modello di Rescorla-Wagner illustra come l’apprendimento associativo derivi da un aggiornamento incrementale delle aspettative, guidato dall’errore di previsione. La sua forza risiede nella capacità di quantificare parametri psicologicamente significativi, come il tasso di apprendimento (α), che riflette la sensibilità individuale alle discrepanze tra aspettative e realtà. L’aggiunta della funzione softmax permette di modellare il conflitto tra esplorazione e sfruttamento, catturando la variabilità adattiva del comportamento.\nParallelamente, il Drift Diffusion Model (DDM) scompone la decisione in un processo dinamico di accumulo di evidenza, in cui parametri come la velocità di elaborazione (drift rate), la cautela decisionale (threshold separation) e i tempi non decisionali (non-decision time) permettono di distinguere componenti cognitive diverse. Questo approccio supera le descrizioni statiche, rivelando come diverse strategie emergano dall’interazione tra vincoli computazionali e contesto.\nEntrambi i modelli evidenziano il valore della formalizzazione matematica nello studio dei processi cognitivi. Il modello di Rescorla-Wagner è particolarmente utile per comprendere come gli individui apprendano e aggiornino le proprie credenze sulla base dell’esperienza, mentre il DDM fornisce una rappresentazione più dettagliata delle dinamiche della presa di decisione e del compromesso tra velocità e accuratezza.\nIn conclusione, l’approccio computazionale alla psicologia cognitiva permette di superare i limiti di un’analisi puramente descrittiva, fornendo strumenti matematici per testare le ipotesi sui processi cognitivi. L’uso combinato di modelli di apprendimento e decisionali consente di ottenere una visione più completa dei meccanismi che guidano il comportamento umano, con implicazioni sia per la ricerca di base che per le applicazioni cliniche.\nQuesto approccio si inserisce anche nel contesto più ampio della psichiatria computazionale e della modellazione bayesiana dei processi mentali, in cui l’obiettivo non è solo descrivere ciò che le persone fanno, ma inferire quali processi latenti sono più plausibili alla luce dei dati. In questo senso, la formalizzazione dei meccanismi non solo migliora la spiegazione, ma anche l’inferenza e la generalizzazione, che sono due ingredienti essenziali per una scienza psicologica cumulativa e replicabile.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Dalla descrizione alla spiegazione: modelli meccanicistici e computazionali in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/05_cognitive_models.html#esercizi",
    "href": "chapters/key_notions/05_cognitive_models.html#esercizi",
    "title": "5  Dalla descrizione alla spiegazione: modelli meccanicistici e computazionali in psicologia",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nChe cosa descrive il modello di Rescorla-Wagner?\nQual è il ruolo del parametro α nel modello di Rescorla-Wagner?\nQuale funzione matematica viene utilizzata per modellare il bilanciamento tra esplorazione ed esploitazione nel modello di Rescorla-Wagner?\nQuali sono i principali parametri del Drift Diffusion Model (DDM)?\nIn che modo il DDM spiega il compromesso tra velocità e accuratezza nelle decisioni?\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n\nIl modello di Rescorla-Wagner descrive come gli individui apprendano le associazioni tra stimoli e risposte in base all’errore di previsione. L’aspettativa di ricompensa viene aggiornata attraverso l’esperienza, con un processo regolato dal tasso di apprendimento (\\(\\alpha\\)).\nIl parametro \\(\\alpha\\) (tasso di apprendimento) determina quanto velocemente un individuo aggiorna le proprie aspettative in base all’errore di previsione. Se \\(\\alpha\\) è alto, l’apprendimento è rapido; se è basso, l’individuo si basa maggiormente sulle esperienze passate.\nLa funzione Softmax viene utilizzata per modellare il bilanciamento tra esplorazione e sfruttamento. Essa regola la probabilità di scegliere un’opzione in base al valore atteso e alla temperatura della scelta (\\(\\beta\\)).\n\nI principali parametri del DDM sono:\n\n\ntasso di drift (\\(v\\)): velocità con cui viene accumulata l’evidenza;\n\nseparazione delle soglie (\\(a\\)): distanza tra le soglie decisionali;\n\n\ntempo di non-decisione (\\(t_0\\)): tempo impiegato per processi indipendenti dall’accumulo dell’evidenza;\n\n\nbias iniziale (\\(z\\)): punto di partenza dell’accumulo dell’evidenza.\n\n\nIl DDM spiega il compromesso tra velocità e accuratezza attraverso la separazione delle soglie decisionali (\\(a\\)). Se le soglie sono più vicine, le decisioni sono più rapide ma meno accurate; se sono più distanti, le decisioni sono più lente ma più precise.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Dalla descrizione alla spiegazione: modelli meccanicistici e computazionali in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/05_cognitive_models.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/key_notions/05_cognitive_models.html#informazioni-sullambiente-di-sviluppo",
    "title": "5  Dalla descrizione alla spiegazione: modelli meccanicistici e computazionali in psicologia",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] rtdists_0.11-5   thematic_0.1.7   MetBrewer_0.2.0  ggokabeito_0.1.0\n#&gt;  [5] see_0.11.0       gridExtra_2.3    patchwork_1.3.1  bayesplot_1.13.0\n#&gt;  [9] psych_2.5.6      scales_1.4.0     markdown_2.0     knitr_1.50      \n#&gt; [13] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [17] purrr_1.1.0      readr_2.1.5      tidyr_1.3.1      tibble_3.3.0    \n#&gt; [21] ggplot2_3.5.2    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.4     stringi_1.8.7      lattice_0.22-7    \n#&gt;  [4] hms_1.1.3          digest_0.6.37      magrittr_2.0.3    \n#&gt;  [7] evaluate_1.0.4     grid_4.5.1         timechange_0.3.0  \n#&gt; [10] RColorBrewer_1.1-3 mvtnorm_1.3-3      fastmap_1.2.0     \n#&gt; [13] Matrix_1.7-3       rprojroot_2.1.0    jsonlite_2.0.0    \n#&gt; [16] survival_3.8-3     mnormt_2.1.1       cli_3.6.5         \n#&gt; [19] expm_1.0-0         rlang_1.1.6        splines_4.5.1     \n#&gt; [22] gsl_2.1-8          withr_3.0.2        tools_4.5.1       \n#&gt; [25] parallel_4.5.1     tzdb_0.5.0         pacman_0.5.1      \n#&gt; [28] vctrs_0.6.5        R6_2.6.1           lifecycle_1.0.4   \n#&gt; [31] htmlwidgets_1.6.4  pkgconfig_2.0.3    pillar_1.11.0     \n#&gt; [34] gtable_0.3.6       Rcpp_1.1.0         glue_1.8.0        \n#&gt; [37] xfun_0.52          tidyselect_1.2.1   msm_1.8.2         \n#&gt; [40] rstudioapi_0.17.1  farver_2.1.2       htmltools_0.5.8.1 \n#&gt; [43] nlme_3.1-168       rmarkdown_2.29     compiler_4.5.1    \n#&gt; [46] evd_2.3-7.1",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Dalla descrizione alla spiegazione: modelli meccanicistici e computazionali in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/05_cognitive_models.html#bibliografia",
    "href": "chapters/key_notions/05_cognitive_models.html#bibliografia",
    "title": "5  Dalla descrizione alla spiegazione: modelli meccanicistici e computazionali in psicologia",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBechtel, W. (2009). Looking down, around, and up: Mechanistic explanation in psychology. Philosophical Psychology, 22(5), 543–564.\n\n\nPovich, M. (2025). Mechanistic Explanation in Psychology. In H. Stam & H. Looren de Jong (A c. Di), The SAGE Handbook of Theoretical Psychology. SAGE Publications.\n\n\nSoto, F. A., Vogel, E. H., Uribe-Bahamonde, Y. E., & Perez, O. D. (2023). Why is the Rescorla-Wagner model so influential? Neurobiology of Learning and Memory, 204, 107794.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Dalla descrizione alla spiegazione: modelli meccanicistici e computazionali in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/R/introduction_r_lang.html",
    "href": "chapters/R/introduction_r_lang.html",
    "title": "R",
    "section": "",
    "text": "Scrivere Codice\nLa programmazione si fonda su un approccio strutturato che combina logica computazionale e strumenti tecnici, articolandosi su due piani complementari: il livello algoritmico e il livello sintattico.",
    "crumbs": [
      "R"
    ]
  },
  {
    "objectID": "chapters/R/introduction_r_lang.html#scrivere-codice",
    "href": "chapters/R/introduction_r_lang.html#scrivere-codice",
    "title": "R",
    "section": "",
    "text": "Livello algoritmico: l’astrazione del problema\nIn questa fase, si definisce la soluzione concettuale indipendentemente dal linguaggio, attraverso:\n\nanalisi degli input;\nspecifica dell’output;\n\nprogettazione dell’algoritmo.\n\nPer esempio, l’input può essere costituito da un insieme di valori numerici; l’output può corrispondere alla media aritmetica; l’algorimo può essere formalizzato come:\n\\[\n\\text{media} = \\frac{\\sum_{i=1}^{n} x_i}{n} .\n\\]\nQuesto processo richiede capacità di problem solving e modellizzazione astratta, competenze trasversali a qualsiasi linguaggio.\n\n\nLivello sintattico: l’implementazione pratica\nLa soluzione algoritmica viene poi tradotta in codice seguendo le regole specifiche del linguaggio scelto:\nEsempio in R\nmedia &lt;- sum(x) / length(x)\nEsempio in Python\nmedia = sum(x) / len(x)\nPur mantenendo la stessa logica, le differenze sintattiche evidenziano come l’implementazione sia vincolata allo strumento utilizzato.",
    "crumbs": [
      "R"
    ]
  },
  {
    "objectID": "chapters/R/introduction_r_lang.html#priorità-formative-nellera-dellia",
    "href": "chapters/R/introduction_r_lang.html#priorità-formative-nellera-dellia",
    "title": "R",
    "section": "Priorità formative nell’era dell’IA",
    "text": "Priorità formative nell’era dell’IA\nNell’attuale contesto tecnologico dominato dall’intelligenza artificiale, la formazione nella programmazione richiede una ridefinizione delle priorità. Abbiamo visto come sia necessario distinguere tra due dimensioni: da un lato, la capacità di pensare algoritmicamente, ossia l’abilità di scomporre problemi complessi in passaggi logici e astratti; dall’altro, la padronanza della sintassi, ovvero delle regole specifiche dei linguaggi di programmazione.\nIl pensiero algoritmico rappresenta il cuore creativo e critico della programmazione. È ciò che permette di trasformare un problema in una sequenza ordinata di operazioni risolutive. Questa competenza, radicata nella logica e nell’astrazione, rimane un dominio squisitamente umano: per quanto avanzate, le IA non possono sostituire la capacità di formulare domande pertinenti, riconoscere pattern originali o immaginare soluzioni innovative. Senza questa base concettuale, ogni tentativo di risolvere problemi computazionali sarebbe destinato a fallire, anche con gli strumenti più potenti a disposizione.\nLa sintassi computazionale, sebbene necessaria, assume oggi un ruolo diverso. Strumenti di code generation, stanno democratizzando l’accesso alla scrittura del codice: piattaforme intelligenti possono suggerire implementazioni, correggere errori e persino tradurre algoritmi tra linguaggi diversi (Cooper et al., 2024). Gli errori sintattici – un tempo ostacoli insormontabili per i principianti – diventano sempre più correggibili attraverso l’esperienza o l’automazione.\nQuesta gerarchia di competenze riecheggia il framework teorico di Marr, sviluppato nel campo della visione artificiale. Marr distingue tre livelli di analisi: il “perché” del sistema (l’obiettivo computazionale), il “come” logico (la progettazione algoritmica) e il “con cosa” concreto (l’implementazione fisica). Nell’educazione alla programmazione, questo si traduce in una scelta precisa: privilegiare la progettazione consapevole di algoritmi rispetto alla mera esecuzione tecnica.\nLa priorità formativa diventa quindi chiara. Coltivare il pensiero algoritmico significa allenare quella mentalità progettuale che permette di dialogare in modo critico con l’IA: formulare prompt efficaci richiede prima di tutto di comprendere a fondo la struttura del problema; valutare soluzioni proposte dall’intelligenza artificiale presuppone la capacità di riconoscere logiche difettose o approcci subottimali. Allo stesso tempo, questa competenza agisce come un “sesto senso tecnologico”, permettendo di adattarsi a linguaggi e strumenti in continua evoluzione.\nLa sintassi non viene certo abbandonata, ma contestualizzata. L’automazione non sostituisce l’apprendimento, ma lo rende più strategico: invece di memorizzare comandi, si impara a selezionarli e combinarli in modo funzionale agli obiettivi algoritmici.",
    "crumbs": [
      "R"
    ]
  },
  {
    "objectID": "chapters/R/introduction_r_lang.html#r-uno-strumento-per-lanalisi-dei-dati",
    "href": "chapters/R/introduction_r_lang.html#r-uno-strumento-per-lanalisi-dei-dati",
    "title": "R",
    "section": "R: Uno Strumento per l’Analisi dei Dati",
    "text": "R: Uno Strumento per l’Analisi dei Dati\nPer trovare la soluzione concreta a un problema di analisi dei dati, è necessario implementare l’algoritmo desiderato in un linguaggio di programmazione. In questo insegnamento, utilizzeremo R, uno dei linguaggi più utilizzati per l’analisi dei dati, apprezzato per la sua flessibilità, potenza e il supporto offerto da una vasta comunità di utenti e sviluppatori.\n\nPerché R?\n\nNato per l’analisi statistica: R è stato concepito specificamente per rispondere alle esigenze di analisi statistica e visualizzazione grafica, diventando rapidamente uno strumento essenziale nel panorama accademico e scientifico.\nGestione dei dati: R offre strumenti avanzati per gestire, manipolare e analizzare grandi quantità di dati, coprendo un’ampia gamma di tecniche statistiche, dalla modellazione lineare all’analisi delle serie temporali.\nVisualizzazione grafica: Con pacchetti come ggplot2 e plotly, R permette di creare grafici e visualizzazioni di alta qualità, fondamentali per comunicare risultati in modo efficace.\nComunità e pacchetti: L’ecosistema di R è arricchito da una vasta libreria di pacchetti, che estendono le capacità del linguaggio per soddisfare necessità specifiche e settoriali.\n\n\n\nR in Psicologia e nelle Scienze Sociali\nNato come linguaggio dedicato alla statistica, R si è evoluto fino a diventare un punto di riferimento per psicologi, ricercatori e professionisti impegnati nella valutazione psicometrica, nell’analisi del comportamento e nella modellizzazione di dati complessi. La sua flessibilità, unita alla vastissima collezione di pacchetti specifici, lo rende adatto a molteplici applicazioni in psicologia, dalla costruzione e validazione di test alla gestione di dati provenienti da studi sperimentali, longitudinali ed Ecological Momentary Assessment (EMA).",
    "crumbs": [
      "R"
    ]
  },
  {
    "objectID": "chapters/R/introduction_r_lang.html#riflessioni-conclusive",
    "href": "chapters/R/introduction_r_lang.html#riflessioni-conclusive",
    "title": "R",
    "section": "Riflessioni Conclusive",
    "text": "Riflessioni Conclusive\nImparare ad usare R non significa solo acquisire competenze tecniche, ma anche aprire le porte a nuove possibilità di analisi e ricerca. Tuttavia, è fondamentale ricordare che la vera sfida nella programmazione non è padroneggiare la sintassi di un linguaggio specifico, ma comprendere la logica algoritmica che sta alla base della soluzione di un problema. L’IA può aiutarci a trovare la sintassi corretta, ma spetta a noi decidere quale algoritmo implementare. Pertanto, i nostri sforzi devono essere rivolti a capire la logica del problema, piuttosto che concentrarci esclusivamente sull’implementazione sintattica.",
    "crumbs": [
      "R"
    ]
  },
  {
    "objectID": "chapters/R/introduction_r_lang.html#bibliografia",
    "href": "chapters/R/introduction_r_lang.html#bibliografia",
    "title": "R",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nCooper, N., Clark, A. T., Lecomte, N., Qiao, H., & Ellison, A. M. (2024). Harnessing large language models for coding, teaching and inclusion to empower research in ecology and evolution. Methods in Ecology and Evolution.",
    "crumbs": [
      "R"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html",
    "href": "chapters/R/01_r_syntax.html",
    "title": "6  Un approccio moderno all’analisi dei dati",
    "section": "",
    "text": "Introduzione\nNell’analisi dei dati psicologici, R non è solo uno strumento statistico avanzato, ma un vero e proprio linguaggio per organizzare il pensiero scientifico. La sua sintassi trasforma procedure complesse in passaggi chiari, verificabili e ripetibili, rispondendo alla crisi della replicabilità che ha coinvolto la psicologia negli ultimi anni (Obels et al., 2020). Imparare R significa quindi acquisire un metodo di lavoro rigoroso e trasparente.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#la-sintassi-di-r-come-garanzia-di-trasparenza",
    "href": "chapters/R/01_r_syntax.html#la-sintassi-di-r-come-garanzia-di-trasparenza",
    "title": "6  Un approccio moderno all’analisi dei dati",
    "section": "\n6.1 La Sintassi di R come Garanzia di Trasparenza",
    "text": "6.1 La Sintassi di R come Garanzia di Trasparenza\nA differenza dei software a menu grafici (come Excel o SPSS), dove le operazioni restano “nascoste” dietro click del mouse, R richiede di descrivere esplicitamente ogni passaggio. Prendiamo questo esempio base:\ndati &lt;- read.csv(\"esperimento1.csv\")\nmodello &lt;- lm(risposta ~ trattamento, data = dati)\nQuesto semplice script realizza tre cose fondamentali:\n\n\nDocumentazione automatica: Ogni operazione resta tracciata nel codice.\n\nVerifica immediata: È possibile ispezionare ogni passaggio (Cosa contiene dati? Come è definito modello?).\n\nModifiche controllate: Cambiare un parametro (es. il file di input) non richiede di rifare tutta l’analisi manualmente.\n\n\n6.1.1 Perché R Favorisce la Replicabilità\nTre caratteristiche di R facilitano direttamente la replicabilità:\n\n\nStruttura basata su script: Scrivere codice in file .R o .qmd crea una traccia completa e ordinata dell’analisi, integrando:\n\nistruzioni eseguibili,\nannotazioni metodologiche,\nvisualizzazione dei risultati.\n\n\nGestione esplicita dei pacchetti:\nComandi come library(lme4) o install.packages(\"brms\") rendono esplicite tutte le risorse usate, evitando il classico “Sul mio computer funzionava!”.\n\nLiterate programming tramite R Markdown:\nLa combinazione di codice, testo narrativo e risultati dinamici (Knuth, 1984) in documenti Quarto (o R Markdown) consente di generare report che combinano:\n\ntesto esplicativo,\nanalisi eseguibile,\nrisultati dinamici (grafici, tabelle).\n\n\n\n6.1.2 Buone Abitudini da Adottare Subito\n\n\nNomi descrittivi\nUtilizzare sempre nomi chiari per oggetti e dati:\n# Da evitare\nx &lt;- read.csv(\"file1.csv\")  \n\n# Preferibile\ndemographics_data &lt;- read.csv(\"demographic_questionnaire.csv\")  \n\nSalvataggio progressivo delle modifiche (versionamento)\nR permette di salvare e tenere traccia delle modifiche ai file con sistemi come Git. Non è necessario impararlo subito, ma è utile sapere che strumenti come GitHub consentono facilmente di archiviare versioni successive del proprio lavoro, facilitando il recupero di versioni precedenti in caso di necessità.\n\nChecklist pre-invio\nPrima di condividere un’analisi, è buona norma verificare:\n\neseguire lo script integralmente (Ctrl+Shift+Enter su RStudio);\ncontrollare che i percorsi dei file siano corretti (es.: “Il file dati.csv si trova nella cartella giusta?”);\naggiornare tutti i pacchetti installati con update.packages(ask = FALSE).\n\n\n\nQueste pratiche rendono il codice più robusto, l’analisi più affidabile e i risultati più facilmente verificabili.\n\n6.1.3 Perché Queste Regole Contano nella Ricerca Psicologica\nL’apprendimento di R va oltre l’acquisizione di competenze tecniche. Ogni scelta sintattica riflette un principio scientifico:\n\n\nElemento del codice\nPrincipio metodologico\n\n\n\nset.seed(123)\nControllo delle fonti di casualità\n\n\ndplyr::filter()\nTracciabilità delle esclusioni\n\n\nAPA_style()\nStandardizzazione della reportistica\n\n\n\nIn un contesto dove il 50% degli studi psicologici mostra difficoltà di replicazione (Collaboration, 2015), R offre un framework per costruire ricerche solide fin dalla fase di progettazione.\n\n6.1.4 Prossimi Passi\n\nScarica e installa R.\nVai al sito ufficiale di CRAN (https://cran.r-project.org/), scegli la versione per il tuo sistema operativo (Windows, Mac o Linux) e segui le istruzioni di installazione.\nScarica e installa RStudio.\nDopo aver installato R, scarica RStudio dal sito ufficiale (https://posit.co/download/rstudio-desktop/). Scegli la versione gratuita “RStudio Desktop” e segui le istruzioni per il tuo sistema operativo.\n\nUna spiegazione dettagliata del processo di installazione di R e RStudio è disponibile in Okoye & Hosseini (2024).",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#panoramica-sullinterfaccia-di-rstudio",
    "href": "chapters/R/01_r_syntax.html#panoramica-sullinterfaccia-di-rstudio",
    "title": "6  Un approccio moderno all’analisi dei dati",
    "section": "\n6.2 Panoramica sull’interfaccia di RStudio",
    "text": "6.2 Panoramica sull’interfaccia di RStudio\nRStudio rende l’uso di R più intuitivo grazie alla sua interfaccia divisa in quattro pannelli principali:\n\n\nPannello degli script: Qui puoi scrivere e modificare i tuoi script, cioè sequenze di comandi salvabili per analisi ripetibili e organizzate.\n\nConsole: Esegue i comandi scritti direttamente o lanciati dagli script, mostrando risultati, messaggi e errori.\n\nPannello dell’ambiente: Mostra i dataset, le variabili e gli oggetti caricati nella sessione di lavoro, permettendoti di gestire facilmente i dati.\n\nPannello grafici/aiuto/file: Visualizza grafici, fornisce accesso alla documentazione di R e consente di navigare tra file e cartelle sul tuo sistema.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#creare-un-nuovo-progetto-in-rstudio",
    "href": "chapters/R/01_r_syntax.html#creare-un-nuovo-progetto-in-rstudio",
    "title": "6  Un approccio moderno all’analisi dei dati",
    "section": "\n6.3 Creare un Nuovo Progetto in RStudio",
    "text": "6.3 Creare un Nuovo Progetto in RStudio\nAvviare un nuovo progetto\nDal menu di RStudio, seleziona File &gt; New Project… per creare un nuovo progetto. I progetti in RStudio sono uno strumento efficace per organizzare il lavoro relativo a una specifica analisi o domanda di ricerca. All’interno di un progetto puoi raccogliere script, file di dati e output, mantenendo tutto ben strutturato.\nScegliere la posizione del progetto\nPuoi creare una nuova directory dedicata al progetto oppure associare il progetto a una directory esistente. Organizzare i progetti in cartelle dedicate aiuta a mantenere i file in ordine e a utilizzare percorsi relativi, rendendo il tuo lavoro più facile da condividere con collaboratori e più portabile tra diversi sistemi.\nQuesta organizzazione è particolarmente utile per evitare confusione e assicurarsi che tutti i file necessari siano facilmente accessibili e collegati al progetto corretto.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#concetti-di-base-nella-programmazione-in-r",
    "href": "chapters/R/01_r_syntax.html#concetti-di-base-nella-programmazione-in-r",
    "title": "6  Un approccio moderno all’analisi dei dati",
    "section": "\n6.4 Concetti di Base nella Programmazione in R",
    "text": "6.4 Concetti di Base nella Programmazione in R\nIniziare a usare R, soprattutto per chi si avvicina per la prima volta a questo linguaggio nel contesto della psicologia, significa comprendere i concetti fondamentali che ne costituiscono la base. Questo capitolo introduce i principi essenziali della programmazione in R, tra cui:\n\nLa comprensione della sintassi di R.\nLa familiarizzazione con i principali tipi di dati e strutture.\nL’acquisizione delle operazioni di base.\n\nQuesti concetti sono fondamentali per manipolare efficacemente i dati e condurre analisi statistiche, rappresentando il punto di partenza per sfruttare al meglio le potenzialità di R.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#oggetti-in-r",
    "href": "chapters/R/01_r_syntax.html#oggetti-in-r",
    "title": "6  Un approccio moderno all’analisi dei dati",
    "section": "\n6.5 Oggetti in R",
    "text": "6.5 Oggetti in R\nIn R, tutto è un oggetto: dai numeri e stringhe di testo più semplici fino a strutture più complesse come vettori, data frame, funzioni, modelli statistici o persino grafici. Un oggetto in R è semplicemente un contenitore che memorizza un valore o una serie di valori, permettendoti di manipolarli e riutilizzarli nel codice.\n\n6.5.1 Creare oggetti\nPer creare un oggetto, è necessario assegnargli un nome e un valore utilizzando l’operatore di assegnazione &lt;- (consigliato) o = (meno utilizzato):\n\nmy_obj &lt;- 48\n\nIn questo esempio, abbiamo creato un oggetto chiamato my_obj e gli abbiamo assegnato il valore 48. Ora questo numero è memorizzato con quel nome e può essere richiamato facilmente.\nPer visualizzare il valore di un oggetto, basta scriverne il nome e premere Invio:\n\nmy_obj\n#&gt; [1] 48\n\n\n6.5.1.1 Dove vengono salvati gli oggetti?\nGli oggetti creati vengono memorizzati nell’ambiente di lavoro (workspace) e restano disponibili finché non vengono rimossi o finché la sessione di R non viene chiusa. Se stai usando RStudio, puoi vedere tutti gli oggetti attualmente presenti nella scheda Environment, dove vengono mostrati con dettagli come tipo, lunghezza e valore.\n\n6.5.1.2 Perché gli oggetti sono importanti?\nLavorare con oggetti in R permette di:\n\n\nRiutilizzare dati e risultati senza doverli digitare nuovamente.\n\n\nOrganizzare il codice in modo chiaro e leggibile, rendendo le analisi più strutturate.\n\n\nManipolare facilmente i dati, combinando, trasformando e analizzando gli oggetti in base alle esigenze.\n\n6.5.1.3 Stringhe\nÈ possibile assegnare a un oggetto anche una stringa di testo, racchiudendola tra virgolette:\n\nmy_obj2 &lt;- \"R è fantastico\"\nmy_obj2\n#&gt; [1] \"R è fantastico\"\n\nSe dimentichi le virgolette, R mostrerà un errore.\n\n6.5.1.4 Modificare Oggetti\nPer modificare il valore di un oggetto esistente, basta riassegnarlo:\n\nmy_obj2 &lt;- 1024\n\nOra il tipo di my_obj2 è cambiato da carattere a numerico. È anche possibile usare oggetti per crearne di nuovi:\n\nmy_obj3 &lt;- my_obj + my_obj2\nmy_obj3\n#&gt; [1] 1072\n\n\n6.5.1.5 Manipolare Oggetti\nSe provi a sommare oggetti di tipo diverso, R restituirà un errore:\nchar_obj &lt;- \"ciao\"\nchar_obj2 &lt;- \"mondo\"\nchar_obj3 &lt;- char_obj + char_obj2\n#&gt; Error in char_obj + char_obj2 : non-numeric argument to binary operator\nQuando incontri errori come questo, chiedi a AI la spiegazione del messaggio, per esempio: “non-numeric argument to binary operator error + r”. Un errore comune è anche:\nmy_obj &lt;- 48\nmy_obj4 &lt;- my_obj + no_obj\n#&gt; Error: object 'no_obj' not found\nR segnala che no_obj non è stato definito e, di conseguenza, l’oggetto my_obj4 non è stato creato.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#nomi-degli-oggetti",
    "href": "chapters/R/01_r_syntax.html#nomi-degli-oggetti",
    "title": "6  Un approccio moderno all’analisi dei dati",
    "section": "\n6.6 Nomi degli Oggetti",
    "text": "6.6 Nomi degli Oggetti\nAttribuire nomi agli oggetti potrebbe sembrare un dettaglio secondario, ma è fondamentale scegliere nomi brevi e informativi. Un buon nome migliora la leggibilità del codice e ne facilita la manutenzione. È importante adottare uno stile coerente, come uno dei seguenti:\n\n\nSnake case: output_summary\n\n\nDot case: output.summary\n\n\nCamel case: outputSummary\n\n\nIn questo corso useremo lo stile più diffuso, Snake Case, che separa le parole con il carattere di sottolineatura _.\nCi sono alcune regole fondamentali da rispettare nella scelta dei nomi:\n\nNon possono iniziare con un numero (ad esempio, 2my_variable non è valido).\n\nNon possono contenere caratteri speciali come &, ^, /, ecc.\n\nEvita di usare parole riservate (ad esempio, TRUE, NA) o nomi di funzioni esistenti (ad esempio, data).\n\nEsempio di cosa non fare:\ndata &lt;- read.table(\"mydatafile\", header = TRUE) # `data` è già una funzione!",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#commenti",
    "href": "chapters/R/01_r_syntax.html#commenti",
    "title": "6  Un approccio moderno all’analisi dei dati",
    "section": "\n6.7 Commenti",
    "text": "6.7 Commenti\nI commenti sono uno strumento essenziale per rendere il codice più chiaro e comprensibile, sia per te stesso sia per altri. Nel linguaggio R, i commenti iniziano con il simbolo #, e tutto ciò che lo segue sulla stessa riga viene ignorato dall’interprete durante l’esecuzione.\n\n6.7.1 Perché commentare?\nI commenti servono a spiegare perché il codice è scritto in un certo modo, non solo come funziona (questo è evidente leggendo il codice). Una buona pratica consiste nel commentare le decisioni o i passaggi che non risultano immediatamente evidenti.\nAd esempio, invece di scrivere un commento ridondante come:\n\n# Assegno 42 alla variabile x\nx &lt;- 42\n\nè più utile fornire un contesto:\n\n# Valore iniziale scelto per semplificare i calcoli successivi\nx &lt;- 42\n\n\n6.7.2 Vantaggi\nCommentare in modo appropriato aiuta a:\n\n\nRidurre il tempo necessario per comprendere o modificare il codice, anche mesi o anni dopo averlo scritto.\n\nFacilitare la collaborazione con altri, rendendo il codice leggibile e accessibile.\n\nMigliorare la manutenibilità e il riutilizzo del codice.\n\nUn codice ben commentato non è solo più facile da leggere, ma anche più professionale e robusto nel lungo termine.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#usare-r-come-calcolatore",
    "href": "chapters/R/01_r_syntax.html#usare-r-come-calcolatore",
    "title": "6  Un approccio moderno all’analisi dei dati",
    "section": "\n6.8 Usare R come Calcolatore",
    "text": "6.8 Usare R come Calcolatore\nR può essere utilizzato come un semplice calcolatore digitando direttamente nella console numeri e operatori aritmetici per eseguire operazioni come somma, sottrazione, moltiplicazione e divisione (+, -, *, /). Questo lo rende uno strumento immediato e versatile per calcoli di base e avanzati.\n\nEsempio 6.1 La Satisfaction With Life Scale (SWLS) contiene 5 item, ciascuno valutato con una scala Likert a 7 punti, dove:\n1 = “completamente in disaccordo” e 7 = “completamente d’accordo”.\nGli item sono:\n\nPer la maggior parte, la mia vita si avvicina al mio ideale.\n\nLe mie condizioni di vita sono eccellenti.\n\nSono soddisfatto della mia vita.\n\nFino ad ora, ho ottenuto le cose importanti che voglio nella vita.\n\nSe potessi vivere la mia vita di nuovo, non cambierei quasi nulla.\n\nSupponiamo che un individuo risponda nel seguente modo:\n\nItem 1: 5\n\nItem 2: 3\n\nItem 3: 4\n\nItem 4: 2\n\nItem 5: 2\n\nIl punteggio totale sulla SWLS si calcola sommando i punteggi di ciascun item:\n\nsogg1 &lt;- 5 + 3 + 4 + 2 + 2 \nsogg1\n#&gt; [1] 16\n\n\n\nEsempio 6.2 Il Body Mass Index (BMI) si calcola dividendo il peso, in chilogrammi, per il quadrato dell’altezza, in metri.\nLa formula è:\n\\[\n\\text{BMI} = \\frac{\\text{Peso (kg)}}{\\text{Altezza (m)}^2} .\n\\]\nSupponiamo che un individuo pesi 79000 grammi (79 kg) e sia alto 176 cm. Il calcolo in R sarà:\n\nbmi &lt;- (79000 / 1000) / (176 / 100)^2\nbmi\n#&gt; [1] 25.5\n\n\nNota. L’uso di parentesi è fondamentale per garantire che le operazioni vengano eseguite nell’ordine corretto. In R, come in matematica, le operazioni racchiuse tra parentesi hanno la precedenza rispetto ad altre operazioni. Ad esempio, nel calcolo del BMI, abbiamo usato le parentesi per calcolare prima la conversione dei valori nell’unità di misura appropriata.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#ordine-di-precedenza-degli-operatori",
    "href": "chapters/R/01_r_syntax.html#ordine-di-precedenza-degli-operatori",
    "title": "6  Un approccio moderno all’analisi dei dati",
    "section": "\n6.9 Ordine di precedenza degli operatori",
    "text": "6.9 Ordine di precedenza degli operatori\nLe operazioni algebriche vengono eseguite in una particolare sequenza in R, nota come ordine di precedenza degli operatori. Questo ordine determina quali operazioni vengono eseguite per prime quando un’espressione include più operatori. In assenza di parentesi, l’ordine di precedenza è il seguente (dal più alto al più basso):\n\n\nParentesi: Le operazioni racchiuse tra parentesi () vengono eseguite per prime. Questo permette di sovrascrivere l’ordine naturale delle operazioni.\n\nresult &lt;- (2 + 3) * 4  # Risultato: 20\n\n\n\nEsponenziazione: L’operatore ^ viene eseguito dopo le parentesi.\n\nresult &lt;- 2^3  # Risultato: 8\n\n\n\nSegni unari: Il segno meno - o più + applicato a un singolo valore.\n\nresult &lt;- -3 + 5  # Risultato: 2\n\n\n\nMoltiplicazione, divisione e modulo: Gli operatori *, /, %/% (divisione intera) e %% (resto) hanno la stessa precedenza e vengono eseguiti da sinistra a destra.\n\nresult &lt;- 10 / 2 * 3  # Risultato: 15\nresult &lt;- 10 %% 3     # Risultato: 1\n\n\n\nAddizione e sottrazione: Gli operatori + e - vengono eseguiti dopo quelli di moltiplicazione/divisione.\n\nresult &lt;- 5 + 3 - 2  # Risultato: 6\n\n\n\nOperatori di assegnazione: Gli operatori &lt;-, -&gt;, =, che assegnano valori a variabili, vengono valutati per ultimi.\n\nx &lt;- 2 + 3 * 4  # Risultato: 14\n\n\n\nNote importanti:\n\n\nAssociazione a sinistra: La maggior parte degli operatori in R viene valutata da sinistra a destra (ad esempio, +, *, /).\n\nUso delle parentesi: Quando l’ordine di precedenza non è immediatamente chiaro o si vuole assicurare un ordine specifico, è sempre buona pratica usare le parentesi.\n\nCapire l’ordine di precedenza è fondamentale per evitare errori logici e garantire che il codice funzioni come previsto.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#funzioni",
    "href": "chapters/R/01_r_syntax.html#funzioni",
    "title": "6  Un approccio moderno all’analisi dei dati",
    "section": "\n6.10 Funzioni",
    "text": "6.10 Funzioni\nFino ad ora abbiamo creato oggetti semplici assegnando loro direttamente un valore. Con l’aumento dell’esperienza in R, potresti voler creare oggetti più complessi. Per aiutarti, R offre numerose funzioni già disponibili nella sua installazione di base, e altre possono essere aggiunte installando pacchetti. Una funzione è un insieme di istruzioni che eseguono un compito specifico. Inoltre, è possibile creare funzioni personalizzate.\n\n6.10.1 La funzione c() per creare vettori\nLa prima funzione utile da imparare è c(), che serve a concatenare valori in un vettore. Ad esempio:\n\nmy_vec &lt;- c(2, 3, 1, 6, 4, 3, 3, 7)\n\nQuesto codice crea un oggetto chiamato my_vec che contiene una sequenza di numeri. Alcuni concetti fondamentali sulle funzioni in R:\n\n\nNome e parentesi: Le funzioni in R sono sempre seguite da parentesi tonde ().\n\nArgomenti: Gli elementi passati alla funzione (tra le parentesi) ne personalizzano il comportamento e sono separati da virgole.\n\nPer vedere il contenuto del vettore:\n\nmy_vec\n#&gt; [1] 2 3 1 6 4 3 3 7\n\n\n6.10.2 Funzioni per analizzare vettori\nPuoi utilizzare altre funzioni per calcolare statistiche sul vettore:\n\nmean(my_vec)    # Media\n#&gt; [1] 3.625\n\n\nvar(my_vec)     # Varianza\n#&gt; [1] 3.982\n\n\nsd(my_vec)      # Deviazione standard\n#&gt; [1] 1.996\n\n\nlength(my_vec)  # Numero di elementi\n#&gt; [1] 8\n\nPuoi anche salvare i risultati in nuovi oggetti per riutilizzarli:\n\nvec_mean &lt;- mean(my_vec)\nvec_mean\n#&gt; [1] 3.625\n\n\n\n\n\n\n\nConcetto Chiave\n\n\n\n\n\nLa varianza e la deviazione standard sono misure statistiche descrittive che sintetizzano in un unico valore numerico la variabilità di un insieme di dati. Questi indici, che verranno approfonditi nel Capitolo 19, forniscono informazioni su quanto i valori di un dataset siano simili o diversi tra loro.\nIn particolare:\n\nla varianza e la deviazione standard sono pari a 0 quando tutti i valori nel dataset sono identici, indicando assenza di variabilità;\nassumono valori più elevati all’aumentare delle differenze tra i dati, segnalando una maggiore dispersione.\n\nPer i nostri scopi attuali, è sufficiente comprendere che queste misure descrivono il grado di diversità o omogeneità dei dati.\n\n\n\n\n6.10.3 Creare sequenze regolari\nPer creare sequenze di numeri in passi regolari, puoi usare i seguenti comandi.\nSimbolo : per sequenze semplici:\n\nmy_seq &lt;- 1:10\nmy_seq\n#&gt;  [1]  1  2  3  4  5  6  7  8  9 10\n\nFunzione seq() per maggiore controllo:\n\nmy_seq2 &lt;- seq(from = 1, to = 5, by = 0.5)\nmy_seq2\n#&gt; [1] 1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0\n\n\n6.10.4 Ripetere valori\nPuoi ripetere valori o sequenze con la funzione rep().\nRipetere un valore:\n\nmy_seq3 &lt;- rep(2, times = 10)\nmy_seq3\n#&gt;  [1] 2 2 2 2 2 2 2 2 2 2\n\nRipetere una sequenza:\n\nmy_seq5 &lt;- rep(1:5, times = 3)\n\nRipetere ogni elemento di una sequenza:\n\nmy_seq6 &lt;- rep(1:5, each = 3)\nmy_seq6\n#&gt;  [1] 1 1 1 2 2 2 3 3 3 4 4 4 5 5 5\n\n\n6.10.5 Annidare funzioni\nÈ possibile combinare funzioni per creare comandi più complessi, come nell’esempio:\n\nmy_seq7 &lt;- rep(c(3, 1, 10, 7), each = 3)\nmy_seq7\n#&gt;  [1]  3  3  3  1  1  1 10 10 10  7  7  7\n\nPer maggiore leggibilità, puoi separare i passaggi:\n\nin_vec &lt;- c(3, 1, 10, 7)\nmy_seq7 &lt;- rep(in_vec, each = 3)\nmy_seq7\n#&gt;  [1]  3  3  3  1  1  1 10 10 10  7  7  7\n\nQuesta pratica facilita la comprensione del codice e lo rende più chiaro.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#lavorare-con-i-vettori-in-r",
    "href": "chapters/R/01_r_syntax.html#lavorare-con-i-vettori-in-r",
    "title": "6  Un approccio moderno all’analisi dei dati",
    "section": "\n6.11 Lavorare con i Vettori in R",
    "text": "6.11 Lavorare con i Vettori in R\nIn R, i vettori sono uno degli elementi fondamentali per manipolare, riassumere e ordinare i dati. Qui trovi una panoramica su come estrarre, sostituire, ordinare, lavorare con dati mancanti e sfruttare la vettorizzazione dei vettori.\n\n6.11.1 Estrarre elementi da un vettore\nPuoi estrarre uno o più elementi da un vettore usando le parentesi quadre [ ].\nPer posizione: Specifica la posizione degli elementi.\n\nmy_vec &lt;- c(2, 3, 1, 6, 4, 3, 3, 7)\nmy_vec[3]  # Terzo elemento\n#&gt; [1] 1\n\n\nmy_vec[c(1, 5, 6)]  # Elementi 1°, 5° e 6°\n#&gt; [1] 2 4 3\n\n\nmy_vec[3:8]  # Da 3° a 8°\n#&gt; [1] 1 6 4 3 3 7\n\nCon condizioni logiche: Usa espressioni logiche per selezionare elementi.\n\nmy_vec[my_vec &gt; 4]  # Elementi &gt; 4\n#&gt; [1] 6 7\n\n\nmy_vec[my_vec &lt;= 4]  # Elementi ≤ 4\n#&gt; [1] 2 3 1 4 3 3\n\n\nmy_vec[my_vec != 4]  # Elementi diversi da 4\n#&gt; [1] 2 3 1 6 3 3 7\n\nOperatori logici: Combina condizioni con & (AND) e | (OR).\n\nmy_vec[my_vec &gt; 2 & my_vec &lt; 6]  # Tra 2 e 6\n#&gt; [1] 3 4 3 3\n\n\n6.11.2 Sostituire Elementi in un Vettore\nPuoi modificare i valori di un vettore usando [ ] e l’operatore &lt;-.\nUn singolo elemento:\n\nmy_vec[4] &lt;- 500  # Cambia il 4° elemento\nmy_vec\n#&gt; [1]   2   3   1 500   4   3   3   7\n\nPiù elementi:\n\nmy_vec[c(6, 7)] &lt;- 100  # Cambia il 6° e 7° elemento\nmy_vec\n#&gt; [1]   2   3   1 500   4 100 100   7\n\nCon condizioni logiche:\n\nmy_vec[my_vec &lt;= 4] &lt;- 1000  # Cambia valori ≤ 4\nmy_vec\n#&gt; [1] 1000 1000 1000  500 1000  100  100    7\n\n\n6.11.3 Ordinare un Vettore\nDal più piccolo al più grande:\n\nvec_sort &lt;- sort(my_vec)\nvec_sort\n#&gt; [1]    7  100  100  500 1000 1000 1000 1000\n\nDal più grande al più piccolo:\n\nvec_sort2 &lt;- sort(my_vec, decreasing = TRUE)\nvec_sort2\n#&gt; [1] 1000 1000 1000 1000  500  100  100    7\n\nOrdinare un vettore in base a un altro:\n\nheight &lt;- c(180, 155, 160, 167, 181)\np.names &lt;- c(\"Joanna\", \"Charlotte\", \"Helen\", \"Karen\", \"Amy\")\nheight_ord &lt;- order(height)\nnames_ord &lt;- p.names[height_ord]\nnames_ord\n#&gt; [1] \"Charlotte\" \"Helen\"     \"Karen\"     \"Joanna\"    \"Amy\"",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#operazioni-vettoriali-e-vettorizzazione-in-r",
    "href": "chapters/R/01_r_syntax.html#operazioni-vettoriali-e-vettorizzazione-in-r",
    "title": "6  Un approccio moderno all’analisi dei dati",
    "section": "\n6.12 Operazioni Vettoriali e Vettorizzazione in R",
    "text": "6.12 Operazioni Vettoriali e Vettorizzazione in R\nLa vettorializzazione è una delle caratteristiche più potenti di R, che consente di applicare operazioni o funzioni direttamente a tutti gli elementi di un vettore in modo simultaneo, senza dover ricorrere a cicli espliciti. Questo approccio rende il codice più conciso, leggibile ed efficiente, sfruttando al meglio le capacità intrinseche del linguaggio.\n\n6.12.1 Operazioni Aritmetiche su Vettori\nLe operazioni algebriche in R, come addizione, sottrazione, moltiplicazione e divisione, sono vettorizzate. Questo significa che ogni operazione viene applicata “elemento per elemento” al vettore.\nConsideriamo ad esempio il seguente vettore:\n\nmy_vec &lt;- c(3, 5, 7, 1, 9, 20)\n\nSe vogliamo moltiplicare ciascun elemento di my_vec per 5, possiamo scrivere:\n\nmy_vec * 5\n#&gt; [1]  15  25  35   5  45 100\n\nAnalogamente, possiamo effettuare altre operazioni algebriche, come divisione o elevamento a potenza:\n\nmy_vec / 2\n#&gt; [1]  1.5  2.5  3.5  0.5  4.5 10.0\n\n\nmy_vec^2\n#&gt; [1]   9  25  49   1  81 400\n\nQueste operazioni vengono applicate automaticamente a ciascun elemento del vettore, senza dover iterare su di essi.\n\n6.12.2 Operazioni Elemento per Elemento tra Due Vettori\nLa vettorializzazione consente anche di eseguire operazioni tra due vettori, applicandole elemento per elemento. Supponiamo di avere un secondo vettore:\n\nmy_vec2 &lt;- c(17, 15, 13, 19, 11, 0)\n\nSe vogliamo sommare i due vettori, possiamo scrivere:\n\nmy_vec + my_vec2\n#&gt; [1] 20 20 20 20 20 20\n\nIn questo caso, il primo elemento di my_vec viene sommato al primo elemento di my_vec2, il secondo elemento al secondo, e così via.\n\nEsempio 6.3 Di seguito mostriamo come calcolare i punteggi totali per 10 individui che hanno risposto ai 5 item della Satisfaction With Life Scale (SWLS), utilizzando le formule e l’aritmetica vettorializzata di R.\nStep 1: Definiamo i punteggi per ciascun item. Ogni vettore contiene i punteggi dati dai 10 individui a uno specifico item della scala:\n\n# Punteggi dei 10 individui per ciascun item\nitem1 &lt;- c(5, 4, 6, 7, 3, 2, 5, 6, 4, 7)\nitem2 &lt;- c(3, 2, 4, 6, 2, 1, 4, 5, 3, 6)\nitem3 &lt;- c(4, 5, 6, 5, 3, 2, 5, 7, 4, 5)\nitem4 &lt;- c(2, 3, 4, 3, 2, 1, 3, 4, 2, 5)\nitem5 &lt;- c(2, 2, 3, 4, 1, 1, 3, 3, 2, 4)\n\nI valori 5, 3, 4, 2, 2 sono i punteggi del primo individuo sui 5 item; i punteggio 4, 2, 5, 3, 2 sono i punteggi del secondo individuo sui 5 item, e così via.\nStep 2: Sommiamo i punteggi per calcolare il totale. Il punteggio totale di ciascun individuo è la somma dei punteggi relativi ai 5 item. Formalmente, per l’individuo \\(i\\) (\\(i = 1, 2, \\ldots, 10\\)), il punteggio totale è calcolato come:\n\\[\n\\text{PunteggioTotale}_i = \\text{item1}_i + \\text{item2}_i + \\text{item3}_i + \\text{item4}_i + \\text{item5}_i .\n\\]\nIn R, possiamo sommare i vettori direttamente grazie all’aritmetica vettorializzata:\n\n# Calcolo dei punteggi totali per ciascun individuo\ntotal_scores &lt;- item1 + item2 + item3 + item4 + item5\ntotal_scores\n#&gt;  [1] 16 16 23 25 11  7 20 25 15 27\n\nIl risultato è un vettore con i punteggi totali per ciascun individuo.\nStep 3: Mostriamo i risultati. Per organizzare meglio i dati, creiamo una tabella che associa i punteggi totali agli individui:\n\n# Creiamo una tabella con i punteggi totali\nindividui &lt;- paste(\"Individuo\", 1:10)\nrisultati_swls &lt;- data.frame(Individuo = individui, PunteggioTotale = total_scores)\nprint(risultati_swls)\n#&gt;       Individuo PunteggioTotale\n#&gt; 1   Individuo 1              16\n#&gt; 2   Individuo 2              16\n#&gt; 3   Individuo 3              23\n#&gt; 4   Individuo 4              25\n#&gt; 5   Individuo 5              11\n#&gt; 6   Individuo 6               7\n#&gt; 7   Individuo 7              20\n#&gt; 8   Individuo 8              25\n#&gt; 9   Individuo 9              15\n#&gt; 10 Individuo 10              27\n\nSpiegazione delle operazioni:\n\nOgni vettore contiene i punteggi di 10 individui per un dato item. Ad esempio, il vettore item1 contiene i punteggi relativi al primo item, e così via.\n\nGrazie all’aritmetica vettorializzata, quando sommiamo i vettori \\(\\text{item1}\\), \\(\\text{item2}\\), \\(\\text{item3}\\), \\(\\text{item4}\\), \\(\\text{item5}\\), R somma elemento per elemento:\n\\[\n\\text{total\\_scores}_i = \\text{item1}_i + \\text{item2}_i + \\text{item3}_i + \\text{item4}_i + \\text{item5}_i\n\\]\n\nQuesta tecnica consente di calcolare rapidamente i punteggi totali per tutti gli individui senza dover scrivere un ciclo esplicito, rendendo il codice più semplice e leggibile.\n\nQuesto esempio illustra come R semplifichi operazioni complesse grazie al calcolo vettorializzato, migliorando l’efficienza e la chiarezza del codice.\n\n\n6.12.3 Attenzione al Riciclo dei Vettori\nSe i due vettori hanno lunghezze diverse, R applicherà il meccanismo di riciclo: gli elementi del vettore più corto verranno ripetuti ciclicamente per abbinarsi alla lunghezza del vettore più lungo. Questo comportamento, sebbene utile, richiede attenzione per evitare risultati inattesi.\nAd esempio:\n\nshort_vec &lt;- c(1, 2)\nmy_vec + short_vec\n#&gt; [1]  4  7  8  3 10 22\n\nIn questo caso, gli elementi di short_vec vengono riciclati per abbinarsi alla lunghezza di my_vec. Il risultato è:\n(3+1, 5+2, 7+1, 1+2, 9+1, 20+2)\n\n6.12.4 Applicazione di Funzioni su Vettori\nLa vettorializzazione non si limita alle operazioni algebriche, ma si estende anche all’uso di funzioni. Supponiamo di voler calcolare il logaritmo naturale di ciascun elemento di un vettore:\n\nlog(my_vec)\n#&gt; [1] 1.099 1.609 1.946 0.000 2.197 2.996\n\nLa funzione log() viene applicata automaticamente a ogni elemento del vettore. Analogamente, possiamo utilizzare altre funzioni predefinite di R, come:\n\nsqrt(my_vec)  # Calcola la radice quadrata di ciascun elemento\n#&gt; [1] 1.732 2.236 2.646 1.000 3.000 4.472\nexp(my_vec)   # Eleva e alla potenza specificata da ciascun elemento\n#&gt; [1] 2.009e+01 1.484e+02 1.097e+03 2.718e+00 8.103e+03 4.852e+08\n\nIn conclusione, la vettorializzazione in R rappresenta un approccio elegante ed efficiente per gestire calcoli su vettori. Che si tratti di operazioni algebriche, operazioni tra vettori o applicazione di funzioni, la possibilità di evitare cicli espliciti migliora la leggibilità e la velocità del codice. Tuttavia, è importante prestare attenzione al riciclo dei vettori per evitare errori non intenzionali.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#gestire-dati-mancanti-na",
    "href": "chapters/R/01_r_syntax.html#gestire-dati-mancanti-na",
    "title": "6  Un approccio moderno all’analisi dei dati",
    "section": "\n6.13 Gestire Dati Mancanti (NA)",
    "text": "6.13 Gestire Dati Mancanti (NA)\nR rappresenta i dati mancanti con NA. La gestione dei dati mancanti dipende dalla funzione utilizzata.\nCalcolo con dati mancanti:\n\ntemp &lt;- c(7.2, NA, 7.1, 6.9, 6.5, 5.8, 5.8, 5.5, NA, 5.5)\nmean(temp)  # Restituisce NA\n#&gt; [1] NA\n\n\nmean(temp, na.rm = TRUE)  # Ignora i valori mancanti\n#&gt; [1] 6.287\n\nNota: na.rm = TRUE è un argomento comune per ignorare i NA, ma non tutte le funzioni lo supportano. Consulta la documentazione della funzione per verificare come gestisce i dati mancanti.\nIn conclusione, manipolare vettori è un’abilità essenziale in R. Dalla selezione e modifica degli elementi all’ordinamento e gestione di dati mancanti, queste tecniche sono alla base dell’analisi dei dati in R.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#i-dati-in-r",
    "href": "chapters/R/01_r_syntax.html#i-dati-in-r",
    "title": "6  Un approccio moderno all’analisi dei dati",
    "section": "\n6.14 I Dati in R",
    "text": "6.14 I Dati in R\nIn R, i dati possono essere rappresentati in diversi tipi e strutture. Comprendere come gestirli è fondamentale per manipolare, analizzare e riassumere i dataset più complessi.\n\n6.14.1 Tipi di Dati in R\nR supporta diversi tipi di dati:\n\n\nNumeric: Numeri decimali (es. 2.5).\n\nInteger: Numeri interi (es. 3).\n\nLogical: Valori booleani (TRUE o FALSE) e NA per dati mancanti.\n\nCharacter: Stringhe di testo (es. \"hello\").\n\nFactor: Variabili categoriche (es. livelli come \"low\", \"medium\", \"high\").\n\nPuoi verificare il tipo di un oggetto con class() e controllare se appartiene a un tipo specifico con funzioni come is.numeric(). È anche possibile convertire un tipo in un altro con funzioni come as.character().\n\n6.14.2 Strutture di Dati in R\nVettori: Contengono dati dello stesso tipo (es. numeri, stringhe o logici).\n\nmy_vec &lt;- c(1, 2, 3)\nmy_vec\n#&gt; [1] 1 2 3\n\nMatrici e array: Strutture bidimensionali (matrici) o multidimensionali (array) con dati dello stesso tipo.\nCreare una matrice:\n\nmy_mat &lt;- matrix(1:12, nrow = 3, byrow = TRUE)\nmy_mat\n#&gt;      [,1] [,2] [,3] [,4]\n#&gt; [1,]    1    2    3    4\n#&gt; [2,]    5    6    7    8\n#&gt; [3,]    9   10   11   12\n\nOperazioni utili:\n\n\nTrasposizione: t(my_mat)\n\n\nDiagonale: diag(my_mat)\n\n\nMoltiplicazione matriciale: mat1 %*% mat2\n\n\nListe: Possono contenere elementi di tipi diversi, inclusi vettori, matrici o altre liste.\n\nmy_list &lt;- list(\n  numbers = c(1, 2), \n  text = \"hello\", \n  mat = matrix(1:4, nrow = 2)\n)\nmy_list$numbers  # Accedi agli elementi con il nome\n#&gt; [1] 1 2\n\nData frame: Strutture bidimensionali che possono contenere colonne di tipi diversi. Ideale per dataset strutturati.\nCreare un data frame:\n\nheight &lt;- c(180, 155, 160)\nweight &lt;- c(65, 50, 52)\nnames &lt;- c(\"Joanna\", \"Charlotte\", \"Helen\")\n\ndataf &lt;- data.frame(height = height, weight = weight, names = names)\nstr(dataf)  # Mostra la struttura del data frame\n#&gt; 'data.frame':    3 obs. of  3 variables:\n#&gt;  $ height: num  180 155 160\n#&gt;  $ weight: num  65 50 52\n#&gt;  $ names : chr  \"Joanna\" \"Charlotte\" \"Helen\"\n\nPer convertire le stringhe in fattori durante la creazione:\n\ndataf &lt;- data.frame(\n  height = height, \n  weight = weight, \n  names = names, \n  stringsAsFactors = TRUE\n)\n\ndataf\n#&gt;   height weight     names\n#&gt; 1    180     65    Joanna\n#&gt; 2    155     50 Charlotte\n#&gt; 3    160     52     Helen\n\n\n6.14.3 Operazioni Utili sui Data Frame\n\n\nVerificare dimensioni: dim(dataf)\n\n\nVisualizzare struttura: str(dataf)\n\n\nAccedere a colonne: dataf$height",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#operazioni-di-base-in-r",
    "href": "chapters/R/01_r_syntax.html#operazioni-di-base-in-r",
    "title": "6  Un approccio moderno all’analisi dei dati",
    "section": "\n6.15 Operazioni di Base in R",
    "text": "6.15 Operazioni di Base in R\n\n6.15.1 Operazioni Aritmetiche\nCome abbiamo visto in precedenza, R supporta le classiche operazioni aritmetiche come somma (+), sottrazione (-), moltiplicazione (*), divisione (/) ed esponenziazione (^).\n\n6.15.2 Operazioni Logiche\nLe operazioni logiche in R includono:\n\n\n&: “and” logico\n\n\n|: “or” logico\n\n\n!: “not” logico\n\n\n&gt;: maggiore di\n\n\n&lt;: minore di\n\n\n==: uguale a\n\n\n!=: diverso da\n\nPer esempio:\n\n# Maggiore di\n3 &gt; 2\n#&gt; [1] TRUE\n# Uguale a\n3 == 2\n#&gt; [1] FALSE\n\n\nEsempio 6.4 Consideriamo l’esempio precedente, in cui abbiamo calcolato i punteggi totali dei 10 individui sulla Satisfaction With Life Scale (SWLS). Ora vogliamo determinare la proporzione di individui nel campione che ha ottenuto un punteggio totale maggiore di 15.\nI punteggi totali dei 10 individui sono memorizzati nella colonna PunteggioTotale del data frame risultati_swls:\n\nrisultati_swls$PunteggioTotale\n#&gt;  [1] 16 16 23 25 11  7 20 25 15 27\n\nPossiamo creare un vettore logico che indica, per ciascun individuo, se il suo punteggio totale supera 15. In R, l’operatore di confronto &gt; restituisce un valore TRUE se la condizione è soddisfatta e FALSE altrimenti:\n\nrisultati_swls$PunteggioTotale &gt; 15\n#&gt;  [1]  TRUE  TRUE  TRUE  TRUE FALSE FALSE  TRUE  TRUE FALSE  TRUE\n\nIn R, i valori TRUE e FALSE possono essere trattati come numeri: TRUE equivale a 1 e FALSE equivale a 0. Questo ci permette di sommare i valori logici per contare quante volte la condizione è soddisfatta. Per calcolare la proporzione, dividiamo questa somma per il numero totale di individui:\n\nsum(risultati_swls$PunteggioTotale &gt; 15) / length(risultati_swls$PunteggioTotale)\n#&gt; [1] 0.7\n\nLa proporzione è calcolata come:\n\\[\n\\text{Proporzione} = \\frac{\\sum_{i=1}^{n} I(\\text{PunteggioTotale}_i &gt; 15)}{n} ,\n\\]\ndove:\n\n\n\\(n\\) è il numero totale di individui (in questo caso, 10),\n\n\\(I(\\text{PunteggioTotale}_i &gt; 15)\\) è una funzione indicatrice che vale 1 se il punteggio dell’individuo \\(i\\) è maggiore di 15, e 0 altrimenti.\n\nNel nostro esempio, la proporzione degli individui con punteggio totale maggiore di 15 è 0.7, cioè il 70% del campione soddisfa questa condizione.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#estrazione-di-sottoinsiemi-di-oggetti-in-r",
    "href": "chapters/R/01_r_syntax.html#estrazione-di-sottoinsiemi-di-oggetti-in-r",
    "title": "6  Un approccio moderno all’analisi dei dati",
    "section": "\n6.16 Estrazione di Sottoinsiemi di Oggetti in R",
    "text": "6.16 Estrazione di Sottoinsiemi di Oggetti in R\nIn R esistono tre operatori principali per estrarre sottoinsiemi di oggetti:\n\nOperatore [ ]\nQuesto operatore restituisce sempre un oggetto della stessa classe dell’originale. È utile per selezionare più elementi da un oggetto. È importante chiudere l’estrazione con ].\nOperatore [[ ]]\nQuesto operatore viene utilizzato per estrarre elementi da liste o data frame. A differenza di [ ], permette di estrarre un solo elemento alla volta e la classe dell’oggetto restituito non sarà necessariamente una lista o un data frame. L’estrazione va chiusa con ]].\nOperatore $\nCome visto in precedenza, questo operatore serve per estrarre elementi da una lista o un data frame utilizzando il loro nome letterale. Il comportamento semantico è simile a quello di [[ ]].\n\n\n6.16.1 Gli Indici di un Data Frame in R\nIn R, gli indici di un data frame sono utilizzati per selezionare righe e colonne. La sintassi generale è:\ndf[i, j]\ndove:\n\n\ni rappresenta l’indice o gli indici delle righe,\n\n\nj rappresenta l’indice o gli indici delle colonne.\n\nSe uno degli indici viene omesso, si considerano tutte le righe o tutte le colonne, a seconda della dimensione omessa.\n\n6.16.1.1 Esempi Pratici\n\n\nSelezione di righe specifiche su tutte le colonne\nSe vogliamo estrarre solo alcune righe, possiamo specificare gli indici delle righe nel primo argomento e lasciare vuoto il secondo. Ad esempio:\ndf[c(2, 3, 5), ]\nQuesto seleziona la seconda, terza e quinta riga del data frame df, includendo tutte le colonne.\n\n\nSelezione di colonne specifiche su tutte le righe\nPer selezionare solo alcune colonne, specifichiamo i loro indici nel secondo argomento e lasciamo vuoto il primo. Ad esempio:\ndf[, c(2, 3, 5)]\nQuesto seleziona la seconda, terza e quinta colonna del data frame df, includendo tutte le righe.\n\n\nSelezione di righe e colonne specifiche\nPossiamo combinare gli indici per selezionare una sotto-matrice specifica. Ad esempio:\ndf[c(2, 4), c(1, 3)]\nQuesto seleziona le righe 2 e 4 e le colonne 1 e 3.\n\n\n6.16.1.2 Ulteriori Dettagli\n\n\nSelezione singola di riga o colonna\nSe vogliamo estrarre una singola riga o colonna, possiamo specificare un solo valore per i o j. Ad esempio:\ndf[1, ]  # Prima riga, tutte le colonne\ndf[, 2]  # Seconda colonna, tutte le righe\n\n\nUso di nomi invece di indici\nSe il data frame ha nomi per righe o colonne, possiamo utilizzarli per la selezione. Ad esempio:\ndf[\"nome_riga\", ]        # Seleziona la riga con nome \"nome_riga\"\ndf[, \"nome_colonna\"]     # Seleziona la colonna con nome \"nome_colonna\"\n\n\nSelezione logica\nPossiamo utilizzare un vettore logico per selezionare righe o colonne. Ad esempio, per selezionare le righe dove il valore nella prima colonna è maggiore di 10:\ndf[df[, 1] &gt; 10, ]\n\n\n6.16.1.3 Sintesi Visiva\n\n\n\n\n\n\nSintassi\nDescrizione\n\n\n\ndf[i, ]\nSeleziona la riga i con tutte le colonne.\n\n\ndf[, j]\nSeleziona la colonna j con tutte le righe.\n\n\ndf[c(i1, i2), c(j1, j2)]\nSeleziona righe e colonne specifiche.\n\n\ndf[i, j]\nSeleziona l’intersezione di righe e colonne.\n\n\ndf[ , ]\nRestituisce l’intero data frame.\n\n\n\nQuesta flessibilità rende l’indicizzazione dei data frame in R potente ed efficace per manipolare e analizzare i dati.\n\nEsempio 6.5 Consideriamo il data frame iris incluso di default in base R.\n\niris |&gt; head()\n#&gt;   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n#&gt; 1          5.1         3.5          1.4         0.2  setosa\n#&gt; 2          4.9         3.0          1.4         0.2  setosa\n#&gt; 3          4.7         3.2          1.3         0.2  setosa\n#&gt; 4          4.6         3.1          1.5         0.2  setosa\n#&gt; 5          5.0         3.6          1.4         0.2  setosa\n#&gt; 6          5.4         3.9          1.7         0.4  setosa\n\nUsiamo la funzione head() per stampare le prime 6 righe del data frame.\nL’istruzione seguente restituisce le prime tre colonne del dataset iris.\n\niris[, 1:3] |&gt; head()\n#&gt;   Sepal.Length Sepal.Width Petal.Length\n#&gt; 1          5.1         3.5          1.4\n#&gt; 2          4.9         3.0          1.4\n#&gt; 3          4.7         3.2          1.3\n#&gt; 4          4.6         3.1          1.5\n#&gt; 5          5.0         3.6          1.4\n#&gt; 6          5.4         3.9          1.7\n\nSelezione di colonne specifiche per nome:\n\niris[, c('Sepal.Length', 'Petal.Length')] |&gt; \n  head()  \n#&gt;   Sepal.Length Petal.Length\n#&gt; 1          5.1          1.4\n#&gt; 2          4.9          1.4\n#&gt; 3          4.7          1.3\n#&gt; 4          4.6          1.5\n#&gt; 5          5.0          1.4\n#&gt; 6          5.4          1.7\n\nSelezione di una singola colonna:\n\niris[, 'Petal.Length'] \n#&gt;   [1] 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 1.5 1.6 1.4 1.1 1.2 1.5 1.3\n#&gt;  [18] 1.4 1.7 1.5 1.7 1.5 1.0 1.7 1.9 1.6 1.6 1.5 1.4 1.6 1.6 1.5 1.5 1.4\n#&gt;  [35] 1.5 1.2 1.3 1.4 1.3 1.5 1.3 1.3 1.3 1.6 1.9 1.4 1.6 1.4 1.5 1.4 4.7\n#&gt;  [52] 4.5 4.9 4.0 4.6 4.5 4.7 3.3 4.6 3.9 3.5 4.2 4.0 4.7 3.6 4.4 4.5 4.1\n#&gt;  [69] 4.5 3.9 4.8 4.0 4.9 4.7 4.3 4.4 4.8 5.0 4.5 3.5 3.8 3.7 3.9 5.1 4.5\n#&gt;  [86] 4.5 4.7 4.4 4.1 4.0 4.4 4.6 4.0 3.3 4.2 4.2 4.2 4.3 3.0 4.1 6.0 5.1\n#&gt; [103] 5.9 5.6 5.8 6.6 4.5 6.3 5.8 6.1 5.1 5.3 5.5 5.0 5.1 5.3 5.5 6.7 6.9\n#&gt; [120] 5.0 5.7 4.9 6.7 4.9 5.7 6.0 4.8 4.9 5.6 5.8 6.1 6.4 5.6 5.1 5.6 6.1\n#&gt; [137] 5.6 5.5 4.8 5.4 5.6 5.1 5.1 5.9 5.7 5.2 5.0 5.2 5.4 5.1\n\noppure\n\niris$Petal.Length\n#&gt;   [1] 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 1.5 1.6 1.4 1.1 1.2 1.5 1.3\n#&gt;  [18] 1.4 1.7 1.5 1.7 1.5 1.0 1.7 1.9 1.6 1.6 1.5 1.4 1.6 1.6 1.5 1.5 1.4\n#&gt;  [35] 1.5 1.2 1.3 1.4 1.3 1.5 1.3 1.3 1.3 1.6 1.9 1.4 1.6 1.4 1.5 1.4 4.7\n#&gt;  [52] 4.5 4.9 4.0 4.6 4.5 4.7 3.3 4.6 3.9 3.5 4.2 4.0 4.7 3.6 4.4 4.5 4.1\n#&gt;  [69] 4.5 3.9 4.8 4.0 4.9 4.7 4.3 4.4 4.8 5.0 4.5 3.5 3.8 3.7 3.9 5.1 4.5\n#&gt;  [86] 4.5 4.7 4.4 4.1 4.0 4.4 4.6 4.0 3.3 4.2 4.2 4.2 4.3 3.0 4.1 6.0 5.1\n#&gt; [103] 5.9 5.6 5.8 6.6 4.5 6.3 5.8 6.1 5.1 5.3 5.5 5.0 5.1 5.3 5.5 6.7 6.9\n#&gt; [120] 5.0 5.7 4.9 6.7 4.9 5.7 6.0 4.8 4.9 5.6 5.8 6.1 6.4 5.6 5.1 5.6 6.1\n#&gt; [137] 5.6 5.5 4.8 5.4 5.6 5.1 5.1 5.9 5.7 5.2 5.0 5.2 5.4 5.1\n\nPer selezionare righe specifiche, definiamo gli indici corrispondenti. Per esempio, l’istruzione seguente restituisce le righe 1 e 3.\n\niris[c(1, 3), ]\n#&gt;   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n#&gt; 1          5.1         3.5          1.4         0.2  setosa\n#&gt; 3          4.7         3.2          1.3         0.2  setosa\n\nFiltraggio logico di righe:\n\niris[iris$Species == 'versicolor', ] |&gt; head()\n#&gt;    Sepal.Length Sepal.Width Petal.Length Petal.Width    Species\n#&gt; 51          7.0         3.2          4.7         1.4 versicolor\n#&gt; 52          6.4         3.2          4.5         1.5 versicolor\n#&gt; 53          6.9         3.1          4.9         1.5 versicolor\n#&gt; 54          5.5         2.3          4.0         1.3 versicolor\n#&gt; 55          6.5         2.8          4.6         1.5 versicolor\n#&gt; 56          5.7         2.8          4.5         1.3 versicolor\n\nRestituisce le righe con Species uguale a “versicolor”. Numero di righe e colonne del sottoinsieme:\n\ndim(iris[iris$Species == 'versicolor', ])\n#&gt; [1] 50  5\n\n\n\n6.16.2 Filtraggio Avanzato con Operatori Logici\nGli operatori logici & (AND), | (OR) e ! (NOT) permettono un filtraggio più sofisticato.\nEsempio: Filtrare le osservazioni di specie “versicolor” con lunghezza del sepalo non superiore a 5.0:\n\niris[(iris$Species == 'versicolor') & (iris$Sepal.Length &lt;= 5.0), ]\n#&gt;    Sepal.Length Sepal.Width Petal.Length Petal.Width    Species\n#&gt; 58          4.9         2.4          3.3           1 versicolor\n#&gt; 61          5.0         2.0          3.5           1 versicolor\n#&gt; 94          5.0         2.3          3.3           1 versicolor\n\nNumero di osservazioni trovate:\n\ndim(iris[(iris$Species == 'versicolor') & (iris$Sepal.Length &lt;= 5.0), ])\n#&gt; [1] 3 5",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#riflessioni-conclusive",
    "href": "chapters/R/01_r_syntax.html#riflessioni-conclusive",
    "title": "6  Un approccio moderno all’analisi dei dati",
    "section": "\n6.17 Riflessioni Conclusive",
    "text": "6.17 Riflessioni Conclusive\nR non è soltanto un linguaggio di programmazione per la statistica, ma rappresenta una filosofia che si fonda su tre principi chiave: apertura, collaborazione e avanzamento della conoscenza scientifica.\nPer chi si avvicina a R, sia nel campo della comunicazione sia in altri ambiti, cogliere questa filosofia è essenziale per apprezzarne appieno il valore. R promuove non solo competenze tecniche, ma anche un impegno verso pratiche di ricerca trasparente e riproducibile, che costituiscono un pilastro fondamentale per una scienza rigorosa e affidabile.\nOpen Source\nR è un software open source, liberamente accessibile a tutti. Questo significa che chiunque può visualizzarne, modificarne e distribuirne il codice sorgente, promuovendo un ambiente trasparente e collaborativo. Essendo gratuito, R garantisce accessibilità a ricercatori di tutto il mondo, indipendentemente dal budget o dal supporto istituzionale. Inoltre, grazie alla sua natura aperta, R beneficia del contributo collettivo di una comunità globale eterogenea.\nContributi della Comunità\nLa comunità di R è uno dei suoi punti di forza principali. Statistici, ricercatori e data scientist di diverse discipline arricchiscono continuamente R sviluppando pacchetti: raccolte di funzioni, dati e codice che ampliano le sue funzionalità. Questa collaborazione ha portato alla creazione di migliaia di pacchetti che coprono tecniche statistiche, metodi grafici e strumenti per la manipolazione dei dati, rendendo R uno strumento sempre più versatile e adatto a un’ampia gamma di esigenze di ricerca.\nRicerca Riproducibile\nLa ricerca riproducibile consiste nel condurre studi in modo tale che altri possano replicarne i risultati utilizzando gli stessi dati e seguendo la stessa metodologia. Questo approccio è cruciale per la validazione delle scoperte scientifiche, permettendo la verifica dei risultati e la costruzione di nuove conoscenze su basi solide.\nR facilita la ricerca riproducibile grazie a:\n\nUn ecosistema completo di pacchetti per l’analisi dei dati e la generazione di report dinamici.\n\nStrumenti come R Markdown e Quarto, che permettono di integrare testo descrittivo e codice R in un unico documento. Questa integrazione consente di documentare ogni fase del processo di ricerca—dalla pulizia dei dati all’analisi e alla presentazione dei risultati—garantendo trasparenza e replicabilità.\n\nIn conclusione, comprendere la filosofia open source di R e il suo ruolo nella promozione della ricerca riproducibile fornisce un quadro chiaro del motivo per cui R è diventato uno strumento essenziale per ricercatori e statistici di diverse discipline. Per chi opera in psicologia, sfruttare le potenzialità di R significa produrre risultati di ricerca più trasparenti, replicabili e credibili, contribuendo alla robustezza e affidabilità della conoscenza scientifica nel settore.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#esercizi",
    "href": "chapters/R/01_r_syntax.html#esercizi",
    "title": "6  Un approccio moderno all’analisi dei dati",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nSvolgere gli esercizi da 1 a 38, sia in modo manuale che utilizzando R. Gli esercizi sono disponibili al seguente link:Esercizi su Summation Notation.\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nIn questo esercizio, lavorerai con i dati della Satisfaction With Life Scale (SWLS) raccolti da ciascuno degli studenti del gruppo TPV di appartenenza.\nIstruzioni SWLS: Di seguito sono riportate alcune affermazioni con cui puoi descrivere la tua soddisfazione rispetto alla tua vita. Indica quanto sei d’accordo con ciascuna affermazione utilizzando la scala di risposta fornita.\n\nIl più delle volte la mia vita è vicina al mio ideale di vita.\nLe condizioni della mia vita sono eccellenti.\nSono soddisfatto/a della mia vita.\nFinora ho ottenuto le cose importanti che voglio dalla vita.\nSe io potessi rivivere la mia vita, non cambierei quasi nulla.\n\nLa SWLS utilizza una scala Likert a 7 punti, con i seguenti ancoraggi:\n\nFortemente in disaccordo\nDisaccordo\nLeggermente in disaccordo\nNé d’accordo né in disaccordo\nLeggermente d’accordo\nD’accordo\nFortemente d’accordo\n\nIl tuo compito sarà analizzare i dati raccolti sia manualmente su carta che utilizzando R.\nParte 1: Calcolo Manuale\n\n\nCalcolo del punteggio totale\n\nLa SWLS è composta da 5 item, ciascuno valutato su una scala Likert da 1 a 7.\nSomma i punteggi dei 5 item per ciascun partecipante per ottenere il punteggio totale.\n\nRegistra i punteggi totali su carta.\n\n\n\nDeterminazione della media del campione\n\nCalcola la media aritmetica dei punteggi totali dei 10 studenti.\nScrivi il calcolo e il risultato.\n\n\n\nCalcolo della deviazione standard\n\n\nCalcola la deviazione standard dei punteggi totali manualmente utilizzando la formula:\n\\[\ns^2 = \\sqrt{\\frac{\\sum_{i=1}^n (x_i - \\bar{x})^2}{n-1}}.\n\\]\n\nRegistra il risultato.\n\n\n\nParte 2: Analisi con R\n\n\nCreazione del dataset in R\n\nInserisci i dati in R come un vettore chiamato swls_scores.\n\n\n\nCalcolo della media e della deviazione standard in R\n\nUsa le funzioni mean() e sd() per ottenere la media e la deviazione standard dei punteggi totali.\n\n\n\nVisualizzazione dei dati\n\nCrea un istogramma per visualizzare la distribuzione dei punteggi totali utilizzando hist(). Se non conosci l’istogramma, fai una ricerca su web; commenta il risultato ottenuto.\n\n\n\nIdentificazione dei punteggi superiori a 20\n\nUtilizza un’operazione logica per contare quanti partecipanti hanno un punteggio totale maggiore di 20.\n\n\n\nFiltraggio dei dati\n\nEstrai e visualizza solo i punteggi superiori alla media del campione.\n\n\n\nEsportazione dei risultati\n\nSalva i punteggi totali in un file CSV utilizzando la funzione write.csv().\n\n\n\nConsegna\n\nScrivi le risposte della Parte 1 su carta.\nScrivi il codice e i risultati della Parte 2 in un file .R e invialo come consegna.\n\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\nParte 1: Calcolo Manuale\n\n\nCalcolo del punteggio totale\n\n\nSupponiamo che i punteggi per 10 studenti siano:\n\n\nStudente\nItem 1\nItem 2\nItem 3\nItem 4\nItem 5\nTotale\n\n\n\n1\n5\n4\n6\n3\n2\n20\n\n\n2\n4\n2\n5\n3\n2\n16\n\n\n3\n6\n4\n6\n4\n3\n23\n\n\n4\n7\n6\n5\n3\n4\n25\n\n\n5\n3\n2\n3\n2\n1\n11\n\n\n6\n2\n1\n2\n1\n1\n7\n\n\n7\n5\n4\n5\n3\n3\n20\n\n\n8\n6\n5\n7\n4\n3\n25\n\n\n9\n4\n3\n4\n2\n2\n15\n\n\n10\n7\n6\n5\n5\n4\n27\n\n\n\n\n\n\n\nDeterminazione della media\n\n\nMedia:\n\\[\n\\bar{x} = \\frac{20+16+23+25+11+7+20+25+15+27}{10} = 18.9\n\\]\n\n\n\n\nCalcolo della deviazione standard\n\n\nLa deviazione standard è:\n\\[\ns = \\sqrt{\\frac{1}{9} \\sum (x_i - 18.9)^2} \\approx 6.56\n\\]\n\n\n\n\nParte 2: Analisi con R\n\n\nCreazione del dataset in R\nswls_scores &lt;- c(20, 16, 23, 25, 11, 7, 20, 25, 15, 27)\n\n\nCalcolo della media e della deviazione standard\nmean(swls_scores)  # Media\nsd(swls_scores)    # Deviazione standard\n\n\nVisualizzazione dei dati\nhist(swls_scores, main=\"Distribuzione SWLS\", xlab=\"Punteggi\", col=\"lightblue\", border=\"black\")\n\n\nIdentificazione dei punteggi superiori a 20\nsum(swls_scores &gt; 20)  # Numero di studenti con punteggio &gt; 20\n\n\nFiltraggio dei dati\nswls_scores[swls_scores &gt; mean(swls_scores)]\n\n\nEsportazione dei risultati\nwrite.csv(data.frame(Student=1:10, Score=swls_scores), \"swls_results.csv\", row.names=FALSE)\n\n\nConclusione Questi esercizi hanno permesso di confrontare il calcolo manuale con l’automatizzazione tramite R, facilitando l’analisi statistica della SWLS.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/R/01_r_syntax.html#informazioni-sullambiente-di-sviluppo",
    "title": "6  Un approccio moderno all’analisi dei dati",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.7   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.13.0 psych_2.5.3     \n#&gt;  [9] scales_1.4.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.3.0     ggplot2_3.5.2   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.4     stringi_1.8.7      lattice_0.22-7    \n#&gt;  [4] hms_1.1.3          digest_0.6.37      magrittr_2.0.3    \n#&gt;  [7] evaluate_1.0.4     grid_4.5.0         timechange_0.3.0  \n#&gt; [10] RColorBrewer_1.1-3 fastmap_1.2.0      rprojroot_2.0.4   \n#&gt; [13] jsonlite_2.0.0     mnormt_2.1.1       cli_3.6.5         \n#&gt; [16] rlang_1.1.6        withr_3.0.2        tools_4.5.0       \n#&gt; [19] parallel_4.5.0     tzdb_0.5.0         pacman_0.5.1      \n#&gt; [22] vctrs_0.6.5        R6_2.6.1           lifecycle_1.0.4   \n#&gt; [25] htmlwidgets_1.6.4  pkgconfig_2.0.3    pillar_1.10.2     \n#&gt; [28] gtable_0.3.6       glue_1.8.0         xfun_0.52         \n#&gt; [31] tidyselect_1.2.1   rstudioapi_0.17.1  farver_2.1.2      \n#&gt; [34] htmltools_0.5.8.1  nlme_3.1-168       rmarkdown_2.29    \n#&gt; [37] compiler_4.5.0",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#bibliografia",
    "href": "chapters/R/01_r_syntax.html#bibliografia",
    "title": "6  Un approccio moderno all’analisi dei dati",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nCollaboration, O. S. (2015). Estimating the reproducibility of psychological science. Science, 349(6251), aac4716.\n\n\nIrizarry, R. A. (2024). Introduction to Data Science: Data Wrangling and Visualization with R. CRC Press.\n\n\nKnuth, D. E. (1984). Literate programming. The Computer Journal, 27(2), 97–111.\n\n\nObels, P., Lakens, D., Coles, N. A., Gottfried, J., & Green, S. A. (2020). Analysis of open data and computational reproducibility in registered reports in psychology. Advances in Methods and Practices in Psychological Science, 3(2), 229–237.\n\n\nOkoye, K., & Hosseini, S. (2024). Introduction to R Programming and RStudio Integrated Development Environment (IDE). In R Programming: Statistical Data Analysis in Research (pp. 3–24). Springer.\n\n\nWickham, H., Çetinkaya-Rundel, M., & Grolemund, G. (2023). R for data science. \" O’Reilly Media, Inc.\".",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Un approccio moderno all'analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/R/02_utility_functions.html",
    "href": "chapters/R/02_utility_functions.html",
    "title": "7  Utility functions",
    "section": "",
    "text": "7.1 Introduzione\nIn questo capitolo, esploreremo le principali funzioni di utilità in R per l’importazione di dati da file esterni e la raccolta di statistiche descrittive, fornendo una panoramica generale sui data frame.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Utility functions</span>"
    ]
  },
  {
    "objectID": "chapters/R/02_utility_functions.html#importare-dati-in-r-con-rioimport",
    "href": "chapters/R/02_utility_functions.html#importare-dati-in-r-con-rioimport",
    "title": "7  Utility functions",
    "section": "\n7.2 Importare dati in R con rio::import()\n",
    "text": "7.2 Importare dati in R con rio::import()\n\nPrima di analizzare i dati, è necessario importarli in R.\n\n7.2.1 Il problema: Tanti Formati, un’Unica Soluzione\nNella ricerca psicologica i dati possono essere forniti in molti formati:\n\nFile Excel (.xlsx) da questionari compilati in laboratorio,\nCSV (.csv) da piattaforme online come Qualtrics,\nFile SPSS (.sav) per confrontare studi precedenti,\nSolo testo (.txt) da esperimenti comportamentali.\n\nInvece di imparare funzioni diverse, una specifica per ciascun formato, il pacchetto rio offre un solo comando universale per le importazioni.\n\n7.2.2 Come Funziona import()\n\n# Carica il pacchetto (installalo prima con install.packages(\"rio\"))\nlibrary(rio)\n\n# Importa un file CSV da una cartella \"dati\" nel tuo progetto\nrisposte &lt;- rio::import(\"dati/questionario.csv\")\n\n# Importa un foglio Excel con i tempi di reazione\ntempi_reazione &lt;- rio::import(\"dati/esperimento1.xlsx\")\n\n# Importa un file SPSS con dati demografici\ndati_demografici &lt;- rio::import(\"dati/partecipanti.sav\")\nPerché è utile:\n\nriconosce automaticamente il formato dal nome del file;\ntraduce i dati in un formato R pronto per l’analisi (data.frame);\nconserva le etichette delle variabili (cruciale per questionari!).\n\n7.2.3 Esportare Dati con rio::export()\n\nDopo aver pulito i dati, è possibile salvarli in qualsiasi formato usando rio::export():\nrio::export(risposte, \"dati/cleaned/dati_puliti.xlsx\")\nrio::export(tempi_reazione, \"dati/cleaned/tempi_reazione.sav\")",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Utility functions</span>"
    ]
  },
  {
    "objectID": "chapters/R/02_utility_functions.html#utilizzare-percorsi-relativi-con-herehere",
    "href": "chapters/R/02_utility_functions.html#utilizzare-percorsi-relativi-con-herehere",
    "title": "7  Utility functions",
    "section": "\n7.3 Utilizzare Percorsi Relativi con here::here()\n",
    "text": "7.3 Utilizzare Percorsi Relativi con here::here()\n\nQuando importiamo i dati da file esterni in R, succede spesso di commettere uno dei tre errori seguenti. Vediamo come eviarli.\n\n\nPercatori sbagliati\n# SBAGLIATO (il file non è nella cartella di lavoro)\nimport(\"questionario.csv\")  \n\n# CORRETTO: usa percorsi relativi o il pacchetto 'here'\nimport(\"dati/raw/questionario.csv\")  \n\nFile aperti in altri programmi\n“Errore: non posso aprire il file” → Chiudi Excel/SPSS e riprova\n\nCodifica caratteri strani\nSe vedi � nei testi, specifica l’encoding:\nimport(\"dati/testo.txt\", encoding = \"UTF-8\")\n\n\n\n7.3.1 Evitare Percorsi Assoluti\nCome vedremo meglio nel Capitolo 14, il primo passo di un progetto di analisi dei dati è l’organizzazione dei file in cartelle con una struttura chiara:\ntuo_progetto/\n├── dati/\n│   ├── raw/        # Dati originali\n│   └── cleaned/    # Dati elaborati\n├── script/\n└── rapporti/\nTutti i file e le cartelle devono essere contenuti nella directory del progetto.\nIl pacchetto here rende l’importazione dei dati più semplice, evitando problemi dovuti a percorsi assoluti che possono cambiare se si modifica la directory di lavoro o si sposta il progetto.\nLa funzione here() crea percorsi relativi a partire dalla radice del progetto (cioè dalla cartella che contiene il file .Rproj o da dove viene inizializzato il progetto RStudio).\nEsempio di utilizzo combinato con rio::import():\nlibrary(rio)\nlibrary(here)\n\n# Percorso robusto al file csv\ndati &lt;- import(here(\"data\", \"dati.csv\"))\n\n# Percorso robusto al file Excel\ndati_excel &lt;- import(here(\"data\", \"dati.xlsx\"))\nIn questo modo, l’importazione diventa indipendente dalla cartella di lavoro attuale e il codice sarà più facilmente condivisibile e riproducibile.\nVantaggi:\n\n\nSemplicità: rio::import() riconosce automaticamente il tipo di file.\n\nRobustezza: here::here() garantisce che il percorso sia sempre corretto, indipendentemente da dove viene eseguito lo script.\n\nQuesta combinazione rende le analisi riproducibili e consente di collaborare facilmente con altri ricercatori o studenti.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Utility functions</span>"
    ]
  },
  {
    "objectID": "chapters/R/02_utility_functions.html#funzioni-principali-e-loro-utilizzo",
    "href": "chapters/R/02_utility_functions.html#funzioni-principali-e-loro-utilizzo",
    "title": "7  Utility functions",
    "section": "\n7.4 Funzioni Principali e Loro Utilizzo",
    "text": "7.4 Funzioni Principali e Loro Utilizzo\nR offre una serie di funzioni per esplorare rapidamente i dati e comprenderne la struttura prima di passare a manipolazioni più avanzate.\n\n\n\n\n\n\nFunzione\nDescrizione\n\n\n\nsummary()\nRestituisce statistiche descrittive di base per ogni colonna di un data frame. Per le colonne numeriche, calcola valori come il minimo, massimo, media, mediana, primo e terzo quartile, e il numero di valori mancanti (se presenti). Per le colonne non numeriche, restituisce il tipo di dati (carattere, logico) e il conteggio delle categorie. Esempio: summary(iris) restituisce una sintesi delle colonne del dataset iris.\n\n\n\nstr() e glimpse()\n\nForniscono una rappresentazione sintetica delle informazioni di un data frame, come dimensione, nomi delle colonne, tipi di dati e valori iniziali. La funzione str() fa parte della configurazione base di R (pacchetto utils), mentre glimpse() è inclusa in dplyr (pacchetto tidyverse). Esempio: str(mtcars) o glimpse(mtcars).\n\n\n\nhead() e tail()\n\nPermettono di visualizzare rispettivamente le prime o ultime righe di un data frame. Utile per una rapida ispezione del contenuto. Si può specificare il numero di righe da mostrare (es. head(df, 10)), altrimenti il valore predefinito è sei righe. Esempio: head(iris) per vedere le prime righe del dataset iris.\n\n\n\nView() e view()\n\nVisualizzano un data frame in una finestra grafica tipo foglio di calcolo all’interno di RStudio. La funzione View() è parte della configurazione base di R, mentre view() è un alias fornito da tibble (pacchetto tidyverse). Utile per piccoli data frame, ma poco pratico per dataset di grandi dimensioni. Esempio: View(iris) apre il dataset iris nel visualizzatore di RStudio.\n\n\nunique()\nRestituisce i valori unici presenti in una colonna o in un vettore. Esempio: unique(iris$Species) restituisce le specie uniche nel dataset iris.\n\n\nnames()\nRestituisce i nomi delle colonne di un data frame. Esempio: names(mtcars) restituisce i nomi delle colonne del dataset mtcars.\n\n\nclass()\nIndica il tipo di dato di un oggetto in R, come numeric, character, logical, o data.frame. Esempio: class(iris) restituisce data.frame.\n\n\nlength()\nRestituisce il numero di elementi di un oggetto. Per i data frame, restituisce il numero di colonne. Esempio: length(iris) restituisce 5 (colonne).\n\n\n\nnrow() e ncol()\n\nRestituiscono rispettivamente il numero di righe e colonne di un data frame. Esempio: nrow(iris) restituisce 150 (righe), mentre ncol(iris) restituisce 5 (colonne).",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Utility functions</span>"
    ]
  },
  {
    "objectID": "chapters/R/02_utility_functions.html#illustrazione",
    "href": "chapters/R/02_utility_functions.html#illustrazione",
    "title": "7  Utility functions",
    "section": "\n7.5 Illustrazione",
    "text": "7.5 Illustrazione\nImmagina di dover analizzare i dati del tuo esperimento sul sonno e la memoria, salvati nel file msleep.csv. La struttura del tuo progetto RStudio è organizzata così:\nmio_esperimento/\n├── mio_esperimento.Rproj\n├── data/\n│   └── msleep.csv\n├── script/\n│   └── analisi.R\n└── output/\nLa prima cosa da fare è caricare i pacchetti necessari:\nlibrary(rio)    # Per importare i dati\nlibrary(here)   # Per gestire i percorsi in modo affidabile\nA questo punto possiamo importare i dati:\n\nmsleep &lt;- rio::import(\n  here::here(  # Costruisce il percorso automaticamente\n    \"data\",    # Cartella dei dati\n    \"msleep.csv\"  # Nome del file\n  )\n)\n\nControlli post-importazione (fondamentali!)\n\nhead(msleep)\n#&gt;                         name      genus  vore        order conservation\n#&gt; 1                    Cheetah   Acinonyx carni    Carnivora           lc\n#&gt; 2                 Owl monkey      Aotus  omni     Primates             \n#&gt; 3            Mountain beaver Aplodontia herbi     Rodentia           nt\n#&gt; 4 Greater short-tailed shrew    Blarina  omni Soricomorpha           lc\n#&gt; 5                        Cow        Bos herbi Artiodactyla domesticated\n#&gt; 6           Three-toed sloth   Bradypus herbi       Pilosa             \n#&gt;   sleep_total sleep_rem sleep_cycle awake brainwt  bodywt\n#&gt; 1        12.1        NA          NA  11.9      NA  50.000\n#&gt; 2        17.0       1.8          NA   7.0 0.01550   0.480\n#&gt; 3        14.4       2.4          NA   9.6      NA   1.350\n#&gt; 4        14.9       2.3      0.1333   9.1 0.00029   0.019\n#&gt; 5         4.0       0.7      0.6667  20.0 0.42300 600.000\n#&gt; 6        14.4       2.2      0.7667   9.6      NA   3.850\n\n\nstr(msleep)\n#&gt; 'data.frame':    83 obs. of  11 variables:\n#&gt;  $ name        : chr  \"Cheetah\" \"Owl monkey\" \"Mountain beaver\" \"Greater short-tailed shrew\" ...\n#&gt;  $ genus       : chr  \"Acinonyx\" \"Aotus\" \"Aplodontia\" \"Blarina\" ...\n#&gt;  $ vore        : chr  \"carni\" \"omni\" \"herbi\" \"omni\" ...\n#&gt;  $ order       : chr  \"Carnivora\" \"Primates\" \"Rodentia\" \"Soricomorpha\" ...\n#&gt;  $ conservation: chr  \"lc\" \"\" \"nt\" \"lc\" ...\n#&gt;  $ sleep_total : num  12.1 17 14.4 14.9 4 14.4 8.7 7 10.1 3 ...\n#&gt;  $ sleep_rem   : num  NA 1.8 2.4 2.3 0.7 2.2 1.4 NA 2.9 NA ...\n#&gt;  $ sleep_cycle : num  NA NA NA 0.133 0.667 ...\n#&gt;  $ awake       : num  11.9 7 9.6 9.1 20 9.6 15.3 17 13.9 21 ...\n#&gt;  $ brainwt     : num  NA 0.0155 NA 0.00029 0.423 NA NA NA 0.07 0.0982 ...\n#&gt;  $ bodywt      : num  50 0.48 1.35 0.019 600 ...\n\n\nglimpse(msleep)\n#&gt; Rows: 83\n#&gt; Columns: 11\n#&gt; $ name         &lt;chr&gt; \"Cheetah\", \"Owl monkey\", \"Mountain beaver\", \"Greater …\n#&gt; $ genus        &lt;chr&gt; \"Acinonyx\", \"Aotus\", \"Aplodontia\", \"Blarina\", \"Bos\", …\n#&gt; $ vore         &lt;chr&gt; \"carni\", \"omni\", \"herbi\", \"omni\", \"herbi\", \"herbi\", \"…\n#&gt; $ order        &lt;chr&gt; \"Carnivora\", \"Primates\", \"Rodentia\", \"Soricomorpha\", …\n#&gt; $ conservation &lt;chr&gt; \"lc\", \"\", \"nt\", \"lc\", \"domesticated\", \"\", \"vu\", \"\", \"…\n#&gt; $ sleep_total  &lt;dbl&gt; 12.1, 17.0, 14.4, 14.9, 4.0, 14.4, 8.7, 7.0, 10.1, 3.…\n#&gt; $ sleep_rem    &lt;dbl&gt; NA, 1.8, 2.4, 2.3, 0.7, 2.2, 1.4, NA, 2.9, NA, 0.6, 0…\n#&gt; $ sleep_cycle  &lt;dbl&gt; NA, NA, NA, 0.1333, 0.6667, 0.7667, 0.3833, NA, 0.333…\n#&gt; $ awake        &lt;dbl&gt; 11.9, 7.0, 9.6, 9.1, 20.0, 9.6, 15.3, 17.0, 13.9, 21.…\n#&gt; $ brainwt      &lt;dbl&gt; NA, 0.01550, NA, 0.00029, 0.42300, NA, NA, NA, 0.0700…\n#&gt; $ bodywt       &lt;dbl&gt; 50.000, 0.480, 1.350, 0.019, 600.000, 3.850, 20.490, …\n\n\nnames(msleep)\n#&gt;  [1] \"name\"         \"genus\"        \"vore\"         \"order\"       \n#&gt;  [5] \"conservation\" \"sleep_total\"  \"sleep_rem\"    \"sleep_cycle\" \n#&gt;  [9] \"awake\"        \"brainwt\"      \"bodywt\"\n\n\ndim(msleep)\n#&gt; [1] 83 11\n\nErrori comuni e soluzioni.\n\n\n“File not found”:\n\nVerifica che:\n\nil file sia realmente in data/;\nil nome del file sia esatto (attenzione a .csv vs .CSV);\n\nnon ci siano spazi nel nome del file.\n\n\n\n\n\nPacchetti non installati:\n# Esegui una volta\ninstall.packages(\"rio\")\ninstall.packages(\"here\")\n\n\nProgetto non aperto:\n\nAssicurati di aver aperto il file .Rproj prima di iniziare.\n\n\n\nEsaminiamo le modalità della variabile qualitativa vore:\n\nunique(msleep$vore)\n#&gt; [1] \"carni\"   \"omni\"    \"herbi\"   \"\"        \"insecti\"\n\nSe vogliamo la numerosità di ciascuna categoria, possiamo usare table():\n\ntable(msleep$vore)\n#&gt; \n#&gt;           carni   herbi insecti    omni \n#&gt;       7      19      32       5      20\n\nSi noti che table() esclude i dati mancanti.\nStampiamo i nomi delle colonne del data frame:\n\nnames(msleep)\n#&gt;  [1] \"name\"         \"genus\"        \"vore\"         \"order\"       \n#&gt;  [5] \"conservation\" \"sleep_total\"  \"sleep_rem\"    \"sleep_cycle\" \n#&gt;  [9] \"awake\"        \"brainwt\"      \"bodywt\"\n\nEsaminiamo il tipo di variabile della colonna vore:\n\nclass(msleep$vore)\n#&gt; [1] \"character\"\n\nLe dimensioni del data frame sono date da:\n\ndim(msleep)\n#&gt; [1] 83 11\n\nladdove il primo valore è il numero di righe e il secondo valore è il numero di colonne.\nIl numero di elementi di un vettore è dato da:\n\nlength(msleep$vore)\n#&gt; [1] 83\n\nIn alternativa, possiamo usare nrow()\n\nnrow(msleep)\n#&gt; [1] 83\n\nper il numero di righe e ncol()\n\nncol(msleep)\n#&gt; [1] 11\n\nper il numero di colonne. In maniera equivalente:\n\ndim(msleep)[2]\n#&gt; [1] 11",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Utility functions</span>"
    ]
  },
  {
    "objectID": "chapters/R/02_utility_functions.html#esercizi",
    "href": "chapters/R/02_utility_functions.html#esercizi",
    "title": "7  Utility functions",
    "section": "\n7.6 Esercizi",
    "text": "7.6 Esercizi\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nIn questo esercizio, utilizzerai R per esplorare i dati raccolti con il questionario Satisfaction With Life Scale (SWLS) dagli studenti del tuo gruppo TPV. L’obiettivo è familiarizzare con le funzioni di base di R per caricare, visualizzare e manipolare i dati.\nParte 1: Operazioni Manuali\n\n\nCreazione e gestione degli oggetti in R\n\nScrivi su carta i comandi R che creerebbero un oggetto chiamato swls_scores contenente i punteggi di 10 studenti.\nQuali sono le regole per assegnare un nome a un oggetto in R?\n\n\n\nVisualizzazione dei dati\n\nScrivi il comando R per visualizzare il contenuto dell’oggetto swls_scores.\nCome puoi visualizzare solo i primi 5 valori del vettore?\n\n\n\nEsplorazione della struttura dei dati\n\nScrivi i comandi R per verificare il tipo di dati contenuti in swls_scores.\nCome puoi verificare quanti elementi contiene?\n\n\n\nParte 2: Esecuzione in R\n\n\nCreazione del dataset in R\n\nInserisci i dati in un oggetto chiamato swls_scores in R.\n\n\n\nVerifica della struttura dei dati\n\nUsa le funzioni str(), class(), length(), nrow(), ncol() su swls_scores.\nAnnota i risultati e spiega a parole loro significato.\n\n\n\nVisualizzazione dei dati\n\nUsa head() e tail() per esplorare i dati.\n\nQual è la differenza tra le due funzioni?\n\n\n\nIdentificazione dei valori unici\n\nUsa unique(swls_scores) per individuare i punteggi distinti.\n\n\n\nCreazione di una tabella con i dati\n\nTrasforma swls_scores in un data frame con una colonna \"Punteggio\" e una colonna \"Studente\" (numerata da 1 a 10).\n\n\n\nEsportazione dei dati\n\nSalva il data frame in un file CSV chiamato \"swls_data.csv\" usando write.csv().\n\n\n\nConsegna\n\nScrivi le risposte della Parte 1 su carta.\nScrivi il codice e i risultati della Parte 2 in un file .R e invialo come consegna.\n\n\n\n\n\n\n\n\n\n\nSoluzione\n\n\n\n\n\nParte 1: Operazioni Manuali\n\n\nCreazione e gestione degli oggetti in R\n\n\nConsideriamo dei valori di risposta arbitrari. Il comando per creare l’oggetto swls_scores è:\nswls_scores &lt;- c(20, 16, 23, 25, 11, 7, 20, 25, 15, 27)\n\n\nRegole per assegnare un nome a un oggetto in R:\n\nNon può iniziare con un numero.\nNon può contenere spazi o caratteri speciali (tranne _ e .).\nNon deve avere lo stesso nome di funzioni già esistenti.\n\n\n\n\n\nVisualizzazione dei dati\n\n\nPer visualizzare il contenuto:\nswls_scores\n\n\nPer visualizzare solo i primi 5 valori:\nhead(swls_scores, 5)\n\n\n\n\nEsplorazione della struttura dei dati\n\n\nPer verificare il tipo di dati:\nclass(swls_scores)\n\n\nPer verificare il numero di elementi:\nlength(swls_scores)\n\n\n\n\nParte 2: Esecuzione in R\n\n\nCreazione del dataset in R\nswls_scores &lt;- c(20, 16, 23, 25, 11, 7, 20, 25, 15, 27)\n\n\nVerifica della struttura dei dati\nstr(swls_scores)\nclass(swls_scores)\nlength(swls_scores)\n\n\nstr() mostra che swls_scores è un vettore numerico.\n\nclass() conferma che è di tipo \"numeric\".\n\nlength() indica che il vettore ha 10 elementi.\n\n\n\nVisualizzazione dei dati\nhead(swls_scores)\ntail(swls_scores)\n\n\nhead() mostra i primi 6 elementi, tail() gli ultimi 6.\n\n\n\nIdentificazione dei valori unici\nunique(swls_scores)\n\nRestituisce: 7, 11, 15, 16, 20, 23, 25, 27.\n\n\n\nCreazione di una tabella con i dati\ndf_swls &lt;- data.frame(Studente = 1:10, Punteggio = swls_scores)\ndf_swls\n\n\nEsportazione dei dati\nwrite.csv(df_swls, \"swls_data.csv\", row.names=FALSE)\n\n\nConclusione\nQuesti esercizi hanno introdotto i comandi di base per creare, visualizzare e manipolare dati in R.\n\n\n\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.7   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.13.0 psych_2.5.3     \n#&gt;  [9] scales_1.4.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.3.0     ggplot2_3.5.2   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.4     stringi_1.8.7      lattice_0.22-7    \n#&gt;  [4] hms_1.1.3          digest_0.6.37      magrittr_2.0.3    \n#&gt;  [7] evaluate_1.0.4     grid_4.5.0         timechange_0.3.0  \n#&gt; [10] RColorBrewer_1.1-3 fastmap_1.2.0      R.oo_1.27.1       \n#&gt; [13] rprojroot_2.0.4    jsonlite_2.0.0     R.utils_2.13.0    \n#&gt; [16] mnormt_2.1.1       cli_3.6.5          rlang_1.1.6       \n#&gt; [19] R.methodsS3_1.8.2  withr_3.0.2        tools_4.5.0       \n#&gt; [22] parallel_4.5.0     tzdb_0.5.0         pacman_0.5.1      \n#&gt; [25] vctrs_0.6.5        R6_2.6.1           lifecycle_1.0.4   \n#&gt; [28] htmlwidgets_1.6.4  pkgconfig_2.0.3    pillar_1.10.2     \n#&gt; [31] gtable_0.3.6       data.table_1.17.6  glue_1.8.0        \n#&gt; [34] xfun_0.52          tidyselect_1.2.1   rstudioapi_0.17.1 \n#&gt; [37] farver_2.1.2       htmltools_0.5.8.1  nlme_3.1-168      \n#&gt; [40] rmarkdown_2.29     compiler_4.5.0",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Utility functions</span>"
    ]
  },
  {
    "objectID": "chapters/R/02_utility_functions.html#bibliografia",
    "href": "chapters/R/02_utility_functions.html#bibliografia",
    "title": "7  Utility functions",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nIrizarry, R. A. (2024). Introduction to Data Science: Data Wrangling and Visualization with R. CRC Press.\n\n\nWickham, H., Çetinkaya-Rundel, M., & Grolemund, G. (2023). R for data science. \" O’Reilly Media, Inc.\".",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Utility functions</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_programming.html",
    "href": "chapters/R/03_r_programming.html",
    "title": "8  Programmazione",
    "section": "",
    "text": "8.1 Introduzione\nIn questo capitolo esploreremo tre strumenti fondamentali per la scrittura di codice in R: le funzioni, le istruzioni condizionali e i cicli. Questi elementi costituiscono la base per sviluppare script flessibili, efficienti e riutilizzabili, essenziali per ogni programmatore o analista che utilizza R.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_programming.html#funzioni",
    "href": "chapters/R/03_r_programming.html#funzioni",
    "title": "8  Programmazione",
    "section": "\n8.2 Funzioni",
    "text": "8.2 Funzioni\nR offre un’ampia gamma di funzioni integrate per supportare l’analisi statistica, la manipolazione dei dati e la visualizzazione grafica, rendendolo uno strumento estremamente versatile per diverse esigenze.\nEsempi di funzioni comuni includono:\n\n# Sommare numeri\nsum(1, 2, 3)  # Restituisce la somma dei numeri\n#&gt; [1] 6\n\n\n# Creare un grafico semplice\nplot(1:10, 1:10)  # Crea un grafico a dispersione dei valori\n\n\n\n\n\n\n\nIn sostanza, una funzione è un blocco di codice progettato per svolgere un’operazione specifica. Puoi pensare a una funzione come a una “black box”: fornisci un input (i dati), la funzione elabora l’informazione attraverso le sue istruzioni e restituisce un output (il risultato). Questo approccio modulare semplifica il lavoro, permettendo di riutilizzare e combinare facilmente diverse operazioni.\n\n8.2.1 Creare Funzioni Personalizzate\nLa creazione di funzioni personalizzate in R è uno strumento essenziale per migliorare la programmazione, soprattutto per gestire operazioni ripetitive o complesse. Le funzioni consentono di rendere il codice più leggibile, efficiente e riutilizzabile, promuovendo un approccio organizzato e chiaro alla risoluzione dei problemi.\n\n8.2.1.1 Vantaggi delle Funzioni Personalizzate\nL’uso di funzioni personalizzate offre numerosi benefici:\n\n\nChiarezza e leggibilità: Un nome descrittivo permette di comprendere immediatamente lo scopo della funzione, anche a distanza di tempo o per altri utenti che leggono il codice.\n\n\nManutenzione semplificata: Modificare il codice all’interno di una funzione aggiorna automaticamente tutte le sue occorrenze, riducendo il rischio di errori e semplificando il debugging.\n\n\nRiduzione degli errori: Si evitano gli errori tipici del copia-e-incolla, come omissioni o incoerenze nei programmi complessi.\n\n\nRiutilizzabilità: Una funzione ben progettata può essere utilizzata in più contesti o progetti, risparmiando tempo e sforzi.\n\n8.2.1.2 Quando Creare una Funzione?\nUn buon criterio per decidere se creare una funzione è osservare se il medesimo blocco di codice viene copiato più volte. Se ti trovi a ripetere lo stesso codice più di due volte, probabilmente è il momento di creare una funzione. Questo aiuta a scrivere codice più pulito, scalabile e professionale, migliorando anche la sostenibilità del lavoro a lungo termine.\n\n8.2.2 Sintassi di una Funzione\nLa struttura base di una funzione in R è la seguente:\nnome_funzione &lt;- function(argomenti) {\n  # Corpo della funzione\n  codice\n  return(risultato)  # Facoltativo: restituisce il valore calcolato\n}\n\n\nnome_funzione: Nome della funzione, scelto per descrivere chiaramente la sua finalità.\n\n\nargomenti: Parametri necessari per eseguire le operazioni all’interno della funzione.\n\n\ncodice: Le istruzioni che definiscono il comportamento della funzione.\n\n\nrisultato: Il valore restituito dalla funzione. Se non si usa return(), R restituisce l’ultimo valore calcolato.\n\n\nEsempio 8.1 Immaginiamo di voler creare una funzione per sommare due numeri.\nsomma_due &lt;- function(a, b) {\n  a + b  # Restituisce la somma dei due numeri\n}\nPer utilizzarla, basta richiamarla specificando i parametri:\nsomma_due(5, 3)  # Restituisce 8\nQuesto approccio aiuta a scrivere codice più leggibile e facile da gestire. Ad esempio, se in futuro volessi modificare il comportamento della somma (ad esempio, aggiungere un messaggio di log), basterà intervenire solo all’interno della funzione.\n\n\nEsempio 8.2 Immaginiamo di avere un dataset con i punteggi di 10 individui su 3 subscale di un test psicometrico. L’obiettivo è:\n\nCreare una funzione per calcolare il punteggio totale di un individuo.\nCreare una funzione per trovare il massimo punteggio totale nel campione.\nCreare una funzione per individuare chi ha ottenuto il massimo punteggio.\n\nPasso 1: Simulazione dei Dati. Simuliamo i punteggi di 10 individui su 3 subscale:\n\n# Simulazione dei punteggi\nset.seed(123)\npunteggi &lt;- data.frame(\n  individuo = paste(\"Individuo\", 1:10),\n  subscale1 = sample(30:50, 10, replace = TRUE),\n  subscale2 = sample(40:60, 10, replace = TRUE),\n  subscale3 = sample(35:55, 10, replace = TRUE)\n)\nprint(punteggi)\n#&gt;       individuo subscale1 subscale2 subscale3\n#&gt; 1   Individuo 1        44        44        48\n#&gt; 2   Individuo 2        48        58        51\n#&gt; 3   Individuo 3        43        48        45\n#&gt; 4   Individuo 4        32        42        41\n#&gt; 5   Individuo 5        39        47        55\n#&gt; 6   Individuo 6        47        46        46\n#&gt; 7   Individuo 7        40        49        49\n#&gt; 8   Individuo 8        34        48        44\n#&gt; 9   Individuo 9        49        58        47\n#&gt; 10 Individuo 10        43        43        41\n\nLa funzione sample() in R è utilizzata per estrarre casualmente un sottoinsieme di valori da un vettore. Nell’esempio sopra, sample() viene utilizzata per generare casualmente i punteggi delle subscale dei test psicometrici.\nNell’istruzione subscale1 &lt;- sample(30:50, 10, replace = TRUE)\n\n\n30:50: Rappresenta il vettore di numeri interi da cui vengono estratti i punteggi (valori possibili tra 30 e 50).\n\n10: Indica che vogliamo estrarre 10 valori.\n\nreplace = TRUE: Consente che lo stesso valore possa essere estratto più volte (estrazione con ripetizione).\n\nPasso 2: Creazione delle Funzioni.\n\n\nCalcolo del punteggio totale per ogni individuo\nQuesta funzione somma i punteggi delle subscale di un individuo:\n\ncalcola_totale &lt;- function(subscale1, subscale2, subscale3) {\n  return(subscale1 + subscale2 + subscale3)\n}\n\n\n\nTrovare il punteggio massimo nel campione\nQuesta funzione accetta un vettore di punteggi totali e restituisce il valore massimo:\n\ntrova_massimo &lt;- function(punteggi_totali) {\n  return(max(punteggi_totali))\n}\n\n\n\nIndividuare l’individuo con il punteggio massimo\nQuesta funzione accetta un data frame con i punteggi e restituisce il nome dell’individuo con il punteggio più alto:\n\ntrova_individuo_massimo &lt;- function(punteggi) {\n  punteggi_totali &lt;- rowSums(punteggi[, c(\"subscale1\", \"subscale2\", \"subscale3\")])\n  indice_massimo &lt;- which.max(punteggi_totali)\n  return(punteggi$individuo[indice_massimo])\n}\n\nLa funzione which.max() restituisce l’indice della posizione in cui si trova il valore massimo in un vettore.\n\n\nPasso 3: Applicazione delle Funzioni\n\n\nCalcolo dei punteggi totali per ogni individuo\nApplichiamo la funzione ai dati simulati:\n\npunteggi$punteggio_totale &lt;- with(\n  punteggi, calcola_totale(subscale1, subscale2, subscale3)\n )\nprint(punteggi)\n#&gt;       individuo subscale1 subscale2 subscale3 punteggio_totale\n#&gt; 1   Individuo 1        44        44        48              136\n#&gt; 2   Individuo 2        48        58        51              157\n#&gt; 3   Individuo 3        43        48        45              136\n#&gt; 4   Individuo 4        32        42        41              115\n#&gt; 5   Individuo 5        39        47        55              141\n#&gt; 6   Individuo 6        47        46        46              139\n#&gt; 7   Individuo 7        40        49        49              138\n#&gt; 8   Individuo 8        34        48        44              126\n#&gt; 9   Individuo 9        49        58        47              154\n#&gt; 10 Individuo 10        43        43        41              127\n\n\n\nTroviamo il punteggio massimo nel campione\n\nmassimo &lt;- trova_massimo(punteggi$punteggio_totale)\nprint(massimo)\n#&gt; [1] 157\n\n\n\nTroviamo chi ha il punteggio massimo\n\nindividuo_massimo &lt;- trova_individuo_massimo(punteggi)\nprint(individuo_massimo)\n#&gt; [1] \"Individuo 2\"\n\n\n\n\n\n8.2.3 Stile\nÈ consigliato di usare nomi di funzioni chiari e descrittivi, preferibilmente verbi (es. compute_mean()). Inoltre, è importante mantenere una struttura leggibile, con spazi coerenti e indentazione.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_programming.html#istruzioni-condizionali-in-r",
    "href": "chapters/R/03_r_programming.html#istruzioni-condizionali-in-r",
    "title": "8  Programmazione",
    "section": "\n8.3 Istruzioni Condizionali in R",
    "text": "8.3 Istruzioni Condizionali in R\nLe istruzioni condizionali permettono di introdurre logica nel tuo codice. Ad esempio, l’operazione x * y si limita a moltiplicare i valori di x e y, senza alcuna logica aggiunta. Con le istruzioni condizionali, puoi dire al programma di eseguire diverse operazioni a seconda che una condizione sia vera (TRUE) o falsa (FALSE).\nL’istruzione condizionale più comune in R è if. Può essere letta come: “Se la condizione è vera, esegui un’azione”. Con else, si estende la logica: “Se la condizione è vera, fai qualcosa; altrimenti fai qualcos’altro”.\nLa struttura generale è questa:\nif (condizione) {\n  # Codice eseguito se la condizione è TRUE\n} else {\n  # Codice eseguito se la condizione è FALSE\n}\nImmagina questa situazione:\n\n“Se un partecipante al test psicologico riporta un punteggio elevato sulla scala di ansia (es. &gt; 15), consigliagli un esercizio di rilassamento. Altrimenti, non è necessario.”\n\nVediamo come rappresentare questa situazione in R.\n\nanxiety_score &lt;- 18 # Punteggio riportato dal partecipante\n\nif (anxiety_score &gt; 15) {\n    exercise &lt;- \"rilassamento\"\n} else {\n    exercise &lt;- \"nessun esercizio\"\n}\n\nexercise\n#&gt; [1] \"rilassamento\"\n\nSe il punteggio è maggiore di 15, il risultato sarà:\n[1] \"rilassamento\"\nSe il punteggio è inferiore o uguale a 15, il risultato sarà:\n[1] \"nessun esercizio\"\n\n8.3.1 Uso di ifelse()\n\nUn’alternativa più compatta a if e else è la funzione ifelse(), utile soprattutto per vettori. Ad esempio, supponiamo di avere i punteggi di ansia di un gruppo di partecipanti e vogliamo decidere se assegnare un esercizio di rilassamento a ciascuno:\n\nanxiety_scores &lt;- c(12, 18, 9, 22, 15)\nexercises &lt;- ifelse(anxiety_scores &gt; 15, \"rilassamento\", \"nessun esercizio\")\n\nIl risultato sarà:\n\nexercises\n#&gt; [1] \"nessun esercizio\" \"rilassamento\"     \"nessun esercizio\"\n#&gt; [4] \"rilassamento\"     \"nessun esercizio\"\n\n\n8.3.2 Creare una Funzione con Istruzioni Condizionali\nLe istruzioni condizionali possono essere racchiuse in una funzione per rendere il codice più flessibile e riutilizzabile. Ad esempio, supponiamo di voler personalizzare un feedback per un partecipante in base al punteggio ottenuto in un questionario:\n\nfeedback &lt;- function(score) {\n    if (score &gt; 15) {\n        \"Consigliamo un esercizio di rilassamento.\"\n    } else if (score &gt; 10) {\n        \"Monitoriamo la situazione, ma non è necessario alcun intervento.\"\n    } else {\n        \"Nessun intervento necessario.\"\n    }\n}\n\n\nfeedback(18)\n#&gt; [1] \"Consigliamo un esercizio di rilassamento.\"\n\n\nfeedback(12)\n#&gt; [1] \"Monitoriamo la situazione, ma non è necessario alcun intervento.\"\n\n\nfeedback(8)\n#&gt; [1] \"Nessun intervento necessario.\"\n\nIn conclusione, le istruzioni condizionali come if, else e ifelse() sono strumenti fondamentali per introdurre logica e controllo nel tuo codice. Puoi usarle per prendere decisioni, gestire errori e rendere il tuo codice più flessibile ed efficiente. Creare funzioni che incorporano queste istruzioni è un passo fondamentale per scrivere codice ordinato e riutilizzabile in contesti psicologici e non solo.\n\n8.3.3 Combinare Operatori Logici in R\nFinora abbiamo creato funzioni abbastanza semplici e mirate. Ora proviamo a realizzare una funzione leggermente più complessa. Immaginiamo di voler determinare se una persona ha avuto una buona giornata basandoci su due criteri:\n\n\nLivello di stress: basso (TRUE) o alto (FALSE).\n\nLivello di supporto sociale percepito: alto (TRUE) o basso (FALSE).\n\nVogliamo creare una funzione che prenda questi due fattori e restituisca un messaggio che descrive come potrebbe essere stata la giornata della persona.\nEcco come possiamo costruire la funzione:\n\ngood_day &lt;- function(low_stress, high_support) {\n    if (low_stress == TRUE && high_support == TRUE) {\n        \"Giornata fantastica! Ti senti calmo e supportato.\"\n    } else if (low_stress == FALSE && high_support == TRUE) {\n        \"Il supporto sociale ti aiuta a gestire lo stress elevato.\"\n    } else if (low_stress == TRUE && high_support == FALSE) {\n        \"Nonostante lo stress sia basso, la mancanza di supporto sociale pesa.\"\n    } else if (low_stress == FALSE && high_support == FALSE) {\n        \"Giornata difficile: stress elevato e poco supporto sociale.\"\n    }\n}\n\nEsempi di utilizzo.\nCaso 1: Stress basso e supporto sociale alto\n\ngood_day(low_stress = TRUE, high_support = TRUE)\n#&gt; [1] \"Giornata fantastica! Ti senti calmo e supportato.\"\n\nCaso 2: Stress elevato e supporto sociale alto.\n\ngood_day(FALSE, TRUE)\n#&gt; [1] \"Il supporto sociale ti aiuta a gestire lo stress elevato.\"\n\nCaso 3: Stress basso e supporto sociale basso.\n\ngood_day(TRUE, FALSE)\n#&gt; [1] \"Nonostante lo stress sia basso, la mancanza di supporto sociale pesa.\"\n\nCaso 4: Stress elevato e supporto sociale basso.\n\ngood_day(FALSE, FALSE)\n#&gt; [1] \"Giornata difficile: stress elevato e poco supporto sociale.\"\n\nLa funzione considera tutte le combinazioni di stress e supporto sociale:\n\n\nStress basso e supporto alto: giornata ideale.\n\nStress elevato e supporto alto: il supporto aiuta a mitigare lo stress.\n\nStress basso e supporto basso: la mancanza di supporto rovina una situazione potenzialmente buona.\n\nStress elevato e supporto basso: la situazione peggiore.\n\nNell’esempio abbiamo usato i seguenti operatori logici:\n\n\n&& (AND logico): Entrambe le condizioni devono essere vere.\n\n== (uguale a): Verifica se una variabile è vera o falsa.\n\nAd esempio, questa condizione:\nif (low_stress == TRUE && high_support == TRUE)\nverifica se il livello di stress è basso e il supporto sociale è alto.\nIn conclusione, questa funzione dimostra come combinare condizioni logiche complesse utilizzando operatori logici come && (AND) e || (OR). Grazie a questi strumenti, possiamo gestire facilmente logiche più articolate, mantenendo il codice leggibile e funzionale.\n\n8.3.4 Gli operatori Logici in R\nGli operatori logici sono essenziali per definire le condizioni nelle istruzioni if. Ecco una tabella riassuntiva con i principali operatori:\n\n\n\n\n\n\n\n\nOperatore\nDescrizione tecnica\nSignificato\nEsempio\n\n\n\n&&\nAND logico\nEntrambe le condizioni devono essere vere\nif(cond1 == test && cond2 == test)\n\n\n||\nOR logico\nAlmeno una condizione deve essere vera\nif(cond1 == test || cond2 == test)\n\n\n&lt;\nMinore di\nX è minore di Y\nif(X &lt; Y)\n\n\n&gt;\nMaggiore di\nX è maggiore di Y\nif(X &gt; Y)\n\n\n&lt;=\nMinore o uguale a\nX è minore o uguale a Y\nif(X &lt;= Y)\n\n\n&gt;=\nMaggiore o uguale a\nX è maggiore o uguale a Y\nif(X &gt;= Y)\n\n\n==\nUguale a\nX è uguale a Y\nif(X == Y)\n\n\n!=\nDiverso da\nX è diverso da Y\nif(X != Y)",
    "crumbs": [
      "R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_programming.html#cicli-in-r",
    "href": "chapters/R/03_r_programming.html#cicli-in-r",
    "title": "8  Programmazione",
    "section": "\n8.4 Cicli in R",
    "text": "8.4 Cicli in R\nR è particolarmente efficace nell’eseguire attività ripetitive. Quando dobbiamo ripetere un’operazione più volte, possiamo utilizzare un ciclo. I cicli eseguono un insieme di istruzioni per un numero specifico di volte o fino a quando una determinata condizione non è soddisfatta.\nIn R esistono tre tipi principali di cicli:\n\n\nCiclo for: ripete un’operazione per un numero definito di iterazioni.\n\nCiclo while: continua a eseguire le istruzioni fino a quando una condizione logica è soddisfatta.\n\nCiclo repeat: itera indefinitamente fino a quando non viene esplicitamente interrotto con un’istruzione break.\n\nI cicli sono strumenti essenziali in tutti i linguaggi di programmazione, ma in R il loro utilizzo dovrebbe essere valutato attentamente, poiché spesso esistono alternative più efficienti come le funzioni della famiglia apply.\n\n8.4.1 Il ciclo for\n\nIl ciclo for è il più utilizzato per eseguire un’operazione un numero definito di volte. Ecco un esempio base:\n\nfor (i in 1:5) {\n    print(i)\n}\n#&gt; [1] 1\n#&gt; [1] 2\n#&gt; [1] 3\n#&gt; [1] 4\n#&gt; [1] 5\n\nCome funziona?\n\nL’indice i prende il primo valore della sequenza 1:5 (cioè 1).\nIl corpo del ciclo, ovvero il codice tra { }, viene eseguito.\nAl termine di ogni iterazione, i assume il valore successivo nella sequenza, e il processo si ripete fino all’ultimo valore (5 in questo caso).\n\nAggiungere logica nel corpo del ciclo\nPossiamo aggiungere operazioni all’interno del ciclo, come ad esempio sommare 1 a ogni valore:\n\nfor (i in 1:5) {\n    print(i + 1)\n}\n#&gt; [1] 2\n#&gt; [1] 3\n#&gt; [1] 4\n#&gt; [1] 5\n#&gt; [1] 6\n\n\n8.4.2 Il ciclo while\n\nIl ciclo while continua a eseguire le istruzioni fino a quando una condizione logica è soddisfatta. Ecco un esempio:\n\ni &lt;- 0\nwhile (i &lt;= 4) {\n    i &lt;- i + 1\n    print(i)\n}\n#&gt; [1] 1\n#&gt; [1] 2\n#&gt; [1] 3\n#&gt; [1] 4\n#&gt; [1] 5\n\nCome funziona?\n\nLa condizione logica (i &lt;= 4) viene verificata prima di ogni iterazione.\nSe la condizione è vera, il ciclo esegue il codice tra { }.\nQuando la condizione diventa falsa (i &gt; 4), il ciclo si interrompe.\n\n8.4.3 Ciclo repeat\n\nIl ciclo repeat esegue il codice indefinitamente, a meno che non venga interrotto con un’istruzione break:\n\ni &lt;- 0\nrepeat {\n    i &lt;- i + 1\n    print(i)\n    if (i &gt;= 5) {\n        break\n    }\n}\n#&gt; [1] 1\n#&gt; [1] 2\n#&gt; [1] 3\n#&gt; [1] 4\n#&gt; [1] 5\n\nQuando usarlo?\nIl ciclo repeat è raro e viene utilizzato solo in situazioni molto particolari. Nella maggior parte dei casi, for o while sono più adatti.\n\n8.4.4 Evitare i cicli: la famiglia di funzioni apply\n\nI cicli in R sono relativamente lenti, specialmente con dataset di grandi dimensioni. Quando possibile, è preferibile usare funzioni della famiglia apply per ottenere lo stesso risultato in modo più efficiente e con meno rischi di errore.\n\n8.4.4.1 La funzione lapply()\n\nlapply() esegue una funzione su ciascun elemento di una lista o vettore e restituisce una lista con i risultati.\nEsempio:\n\nlapply(0:4, function(a) {\n    a + 1\n})\n#&gt; [[1]]\n#&gt; [1] 1\n#&gt; \n#&gt; [[2]]\n#&gt; [1] 2\n#&gt; \n#&gt; [[3]]\n#&gt; [1] 3\n#&gt; \n#&gt; [[4]]\n#&gt; [1] 4\n#&gt; \n#&gt; [[5]]\n#&gt; [1] 5\n\n\n8.4.4.2 La funzione sapply()\n\nlapply() restituisce una lista, ma se vuoi un vettore come output, usa sapply():\n\nsapply(0:4, function(a) {\n    a + 1\n})\n#&gt; [1] 1 2 3 4 5\n\n\n8.4.5 Quando usare i cicli?\nI cicli sono utili quando:\n\nDevi simulare modelli complessi (es. modelli ricorsivi).\nHai bisogno di operazioni che dipendono dai risultati delle iterazioni precedenti.\n\nIn tutti gli altri casi, considera alternative come apply(), lapply() o funzioni simili per un codice più efficiente e meno soggetto a errori.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_programming.html#linee-guida-per-scrivere-codice",
    "href": "chapters/R/03_r_programming.html#linee-guida-per-scrivere-codice",
    "title": "8  Programmazione",
    "section": "\n8.5 Linee Guida per Scrivere Codice",
    "text": "8.5 Linee Guida per Scrivere Codice\nDi seguito trovi alcune linee guida per scrivere codice chiaro, conciso e riutilizzabile:\n\nEvita di ripeterti: Segui il principio Don’t Repeat Yourself (DRY). Scrivi funzioni e utilizza funzioni come map (per applicare un pezzo di codice iterativamente a tutti gli elementi di un oggetto) per evitare di copiare e incollare variazioni minime dello stesso codice in più parti del progetto.\nSegui uno stile coerente: Adotta una guida di stile per mantenere uniformità nel tuo codice. Per R, raccomandiamo la guida di stile del “tidyverse”, scritta da Hadley Wickham. Questa guida, derivata dalla Google R Style Guide, fornisce istruzioni dettagliate su sintassi del codice, nomi delle variabili, spaziature, indentazioni, commenti, convenzioni per scrivere funzioni, utilizzo delle pipe (metodo per concatenare funzioni), e altro ancora.\nCommenta abbondantemente: Usa i commenti (ad esempio, con #) per spiegare perché ogni parte del codice è necessaria e cosa fa. I commenti rendono il codice più leggibile e facilitano la manutenzione futura.\nTesta il tuo codice: Ogni volta che scrivi codice, verifica che funzioni come previsto. Puoi farlo scrivendo funzioni di test specifiche o controllando manualmente che l’output corrisponda alle aspettative. Abituati a pensare a eventuali edge cases (casi limite) in cui il tuo codice potrebbe non comportarsi come previsto.\nEsegui una revisione del codice: Quando possibile, fai revisionare il tuo codice da un’altra persona per individuare errori e incoerenze. Se non hai nessuno a disposizione, puoi rivedere il tuo codice autonomamente: rileggendo con attenzione, è sorprendente il numero di errori che si possono individuare!\n\nSeguendo queste linee guida, potrai scrivere codice più robusto, leggibile e facile da mantenere nel tempo.1",
    "crumbs": [
      "R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_programming.html#riflessioni-conclusive",
    "href": "chapters/R/03_r_programming.html#riflessioni-conclusive",
    "title": "8  Programmazione",
    "section": "\n8.6 Riflessioni Conclusive",
    "text": "8.6 Riflessioni Conclusive\nScrivere funzioni è un passaggio essenziale per migliorare la leggibilità, l’efficienza e la riutilizzabilità del codice. Funzioni ben progettate semplificano le modifiche, riducono errori e rendono il lavoro più chiaro, sia per te stesso che per i collaboratori futuri. Se trovi che stai copiando e incollando codice più volte, è il momento di pensare a creare una funzione.\nLe istruzioni condizionali, come if, else e ifelse(), sono fondamentali per introdurre logica e controllo nel codice. Permettono di gestire scenari diversi e prendere decisioni dinamiche, migliorando la flessibilità e l’efficienza dei tuoi script. Combinando queste istruzioni con operatori logici come && e ||, puoi affrontare situazioni complesse con un codice chiaro e leggibile.\nI cicli sono potenti strumenti per eseguire operazioni ripetitive, ma in R il loro utilizzo dovrebbe essere limitato ai casi in cui non esistono alternative più efficienti. Le funzioni apply() e simili rappresentano spesso un’opzione migliore per manipolare dati in modo più rapido e leggibile.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_programming.html#esercizi",
    "href": "chapters/R/03_r_programming.html#esercizi",
    "title": "8  Programmazione",
    "section": "\n8.7 Esercizi",
    "text": "8.7 Esercizi\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nIn questo esercizio, utilizzerai R per praticare la creazione di funzioni, l’uso delle istruzioni condizionali e l’applicazione dei cicli. L’obiettivo è comprendere come scrivere codice più strutturato, riutilizzabile ed efficiente.\nParte 1: Comprensione Teorica\n\n\nCos’è una funzione in R?\n\nDescrivi con parole tue cosa fa una funzione e perché è utile.\n\n\n\nSintassi delle funzioni\n\nScrivi la struttura generale di una funzione in R.\n\n\n\nUso di istruzioni condizionali\n\nQual è la differenza tra if, else e ifelse()? Fornisci un esempio per ciascuno.\n\n\n\nCicli in R\n\nQual è la differenza tra for, while e repeat?\n\n\n\nParte 2: Creazione ed Esecuzione in R\n\n\nCreazione di una funzione per calcolare il punteggio totale SWLS\n\nScrivi una funzione in R chiamata calcola_SWLS() che accetta un vettore con 5 punteggi SWLS e restituisce il totale.\n\n\n\nCondizione per determinare la soddisfazione\n\nScrivi una funzione valuta_soddisfazione() che prende un punteggio SWLS totale e restituisce:\n\n\n\"Alta soddisfazione\" se il punteggio è sopra 24.\n\n\"Soddisfazione moderata\" se è tra 15 e 24.\n\n\"Bassa soddisfazione\" se è inferiore a 15.\n\n\n\n\n\nApplicare una funzione a più individui\n\nScrivi un ciclo for che calcola la soddisfazione per un gruppo di 5 persone e stampa il risultato.\n\n\n\nUso di ifelse()\n\nUsa ifelse() per determinare rapidamente se i punteggi di 5 individui indicano soddisfazione alta (&gt; 24) o bassa (≤ 24).\n\n\n\nCiclo while per controllare input\n\nScrivi un ciclo while che continua a chiedere all’utente di inserire un punteggio SWLS fino a quando non inserisce un valore valido (compreso tra 5 e 35).\n\n\n\nEsportazione dei dati\n\n\n\nSalva in un file CSV \"swls_results.csv\" un data frame contenente i punteggi SWLS e la valutazione della soddisfazione.\n\nConsegna\n\nScrivi le risposte della Parte 1 su carta.\nScrivi il codice e i risultati della Parte 2 in un file .R e invialo come consegna.\n\n\n\n\n\n\n\n\n\n\nSoluzione\n\n\n\n\n\nParte 1: Comprensione Teorica\n\n\nCos’è una funzione in R?\n\nUna funzione è un blocco di codice che esegue un’operazione specifica. Permette di scrivere codice riutilizzabile e più organizzato.\n\n\n\nSintassi delle funzioni\nnome_funzione &lt;- function(argomenti) {\n  # Corpo della funzione\n  return(risultato)\n}\n\n\nUso di istruzioni condizionali\n\n\nif: Controlla una condizione e esegue codice solo se è vera.\n\nif (x &gt; 10) { print(\"Maggiore di 10\") }\n\n\nelse: Esegue codice alternativo se la condizione è falsa.\n\nif (x &gt; 10) { print(\"Maggiore di 10\") } else { print(\"10 o meno\") }\n\n\nifelse(): Alternativa vettorializzata a if.\n\ny &lt;- ifelse(x &gt; 10, \"Alto\", \"Basso\")\n\n\nCicli in R\n\n\nfor: Itera su una sequenza.\n\nfor (i in 1:5) { print(i) }\n\n\nwhile: Continua fino a quando una condizione è vera.\n\ni &lt;- 1\nwhile (i &lt;= 5) { print(i); i &lt;- i + 1 }\n\n\nrepeat: Ripete fino a un break.\n\ni &lt;- 1\nrepeat { print(i); i &lt;- i + 1; if (i &gt; 5) break }\n\n\nParte 2: Creazione ed Esecuzione in R\n\n\nCreazione della funzione per il punteggio totale SWLS\ncalcola_SWLS &lt;- function(punteggi) {\n  return(sum(punteggi))\n}\n\n\nCondizione per determinare la soddisfazione\nvaluta_soddisfazione &lt;- function(score) {\n  if (score &gt; 24) {\n    return(\"Alta soddisfazione\")\n  } else if (score &gt;= 15) {\n    return(\"Soddisfazione moderata\")\n  } else {\n    return(\"Bassa soddisfazione\")\n  }\n}\n\n\nApplicazione della funzione a più individui\npunteggi_lista &lt;- list(c(25, 27, 22, 24, 28), c(18, 20, 17, 16, 19))\nfor (punteggi in punteggi_lista) {\n  print(valuta_soddisfazione(calcola_SWLS(punteggi)))\n}\n\n\nUso di ifelse()\npunteggi_totali &lt;- c(28, 19, 15, 10, 25)\nsoddisfazione &lt;- ifelse(punteggi_totali &gt; 24, \"Alta\", \"Bassa\")\nprint(soddisfazione)\n\n\nCiclo while per controllare input\nscore &lt;- 0\nwhile (score &lt; 5 || score &gt; 35) {\n  score &lt;- as.numeric(readline(prompt = \"Inserisci un punteggio SWLS (5-35): \"))\n}\n\nEsportazione dei dati\n\ndf &lt;- data.frame(Punteggio = punteggi_totali, Soddisfazione = soddisfazione)\nwrite.csv(df, \"swls_results.csv\", row.names = FALSE)\nConclusione\nQuesti esercizi hanno mostrato come scrivere funzioni, utilizzare condizioni e cicli per strutturare meglio il codice in R.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_programming.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/R/03_r_programming.html#informazioni-sullambiente-di-sviluppo",
    "title": "8  Programmazione",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.7   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.13.0 psych_2.5.3     \n#&gt;  [9] scales_1.4.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.3.0     ggplot2_3.5.2   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.4     stringi_1.8.7      lattice_0.22-7    \n#&gt;  [4] hms_1.1.3          digest_0.6.37      magrittr_2.0.3    \n#&gt;  [7] evaluate_1.0.4     grid_4.5.0         timechange_0.3.0  \n#&gt; [10] RColorBrewer_1.1-3 fastmap_1.2.0      rprojroot_2.0.4   \n#&gt; [13] jsonlite_2.0.0     mnormt_2.1.1       cli_3.6.5         \n#&gt; [16] rlang_1.1.6        withr_3.0.2        tools_4.5.0       \n#&gt; [19] parallel_4.5.0     tzdb_0.5.0         pacman_0.5.1      \n#&gt; [22] vctrs_0.6.5        R6_2.6.1           lifecycle_1.0.4   \n#&gt; [25] htmlwidgets_1.6.4  pkgconfig_2.0.3    pillar_1.10.2     \n#&gt; [28] gtable_0.3.6       glue_1.8.0         xfun_0.52         \n#&gt; [31] tidyselect_1.2.1   rstudioapi_0.17.1  farver_2.1.2      \n#&gt; [34] htmltools_0.5.8.1  nlme_3.1-168       rmarkdown_2.29    \n#&gt; [37] compiler_4.5.0",
    "crumbs": [
      "R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_programming.html#bibliografia",
    "href": "chapters/R/03_r_programming.html#bibliografia",
    "title": "8  Programmazione",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nIrizarry, R. A. (2024). Introduction to Data Science: Data Wrangling and Visualization with R. CRC Press.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_programming.html#footnotes",
    "href": "chapters/R/03_r_programming.html#footnotes",
    "title": "8  Programmazione",
    "section": "",
    "text": "Un’ottima introduzione alle regole di stile per un progetto di analisi dei dati è fornita in questo capitolo.↩︎",
    "crumbs": [
      "R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/04_r_packages.html",
    "href": "chapters/R/04_r_packages.html",
    "title": "9  Pacchetti",
    "section": "",
    "text": "9.1 Introduzione\nI pacchetti R sono estensioni del linguaggio di programmazione statistica R. Questi pacchetti forniscono una raccolta di risorse che possono essere utilizzate per ampliare le funzionalità di base di R. Ogni pacchetto generalmente include:\nI pacchetti R sono distribuiti e installati attraverso repository centralizzati, il più noto dei quali è CRAN (Comprehensive R Archive Network). CRAN garantisce la qualità e l’affidabilità dei pacchetti, sottoponendoli a controlli rigorosi prima della pubblicazione.\nLa vasta disponibilità di pacchetti è una delle ragioni principali della popolarità di R.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Pacchetti</span>"
    ]
  },
  {
    "objectID": "chapters/R/04_r_packages.html#introduzione",
    "href": "chapters/R/04_r_packages.html#introduzione",
    "title": "9  Pacchetti",
    "section": "",
    "text": "Codice: funzioni e script scritti in R (e talvolta in altri linguaggi come C++ o Fortran) che implementano specifiche analisi o strumenti.\nDati: dataset di esempio o utili per testare e dimostrare le funzionalità del pacchetto.\nDocumentazione: file descrittivi che spiegano come utilizzare il pacchetto, spesso in formato manuale o vignette (tutorial pratici).",
    "crumbs": [
      "R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Pacchetti</span>"
    ]
  },
  {
    "objectID": "chapters/R/04_r_packages.html#installare-i-pacchetti-r",
    "href": "chapters/R/04_r_packages.html#installare-i-pacchetti-r",
    "title": "9  Pacchetti",
    "section": "9.2 Installare i Pacchetti R",
    "text": "9.2 Installare i Pacchetti R\nQuando installi R, vengono installati automaticamente alcuni pacchetti base. Tuttavia, hai la possibilità di aggiungere ulteriori pacchetti che trovi utili per i tuoi scopi. Questi pacchetti sono memorizzati sui server di R (mirror), e l’installazione di un nuovo pacchetto richiede una connessione internet al mirror CRAN che hai scelto durante l’installazione di R.\nPer installare un pacchetto, utilizza il comando:\ninstall.packages(\"&lt;nome_pacchetto&gt;\")\nSostituisci &lt;nome_pacchetto&gt; con il nome del pacchetto che desideri installare. Ad esempio, se vuoi installare il pacchetto rio (utile per importare i dati in R), puoi digitare:\ninstall.packages(\"rio\")   # Non dimenticare le virgolette!",
    "crumbs": [
      "R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Pacchetti</span>"
    ]
  },
  {
    "objectID": "chapters/R/04_r_packages.html#caricamento-di-un-pacchetto",
    "href": "chapters/R/04_r_packages.html#caricamento-di-un-pacchetto",
    "title": "9  Pacchetti",
    "section": "9.3 Caricamento di un pacchetto",
    "text": "9.3 Caricamento di un pacchetto\nOgni volta che avvii una nuova sessione di R, se desideri utilizzare un pacchetto, devi caricarlo manualmente. Questo si fa con il comando library(). Ad esempio, dopo aver installato rio, per utilizzarlo digita:\nlibrary(rio)   # Nota: le virgolette non sono necessarie, ma puoi usarle se preferisci.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Pacchetti</span>"
    ]
  },
  {
    "objectID": "chapters/R/04_r_packages.html#utilizzo-delle-funzioni-di-un-pacchetto-senza-caricarlo",
    "href": "chapters/R/04_r_packages.html#utilizzo-delle-funzioni-di-un-pacchetto-senza-caricarlo",
    "title": "9  Pacchetti",
    "section": "9.4 Utilizzo delle funzioni di un pacchetto senza caricarlo",
    "text": "9.4 Utilizzo delle funzioni di un pacchetto senza caricarlo\nSe hai bisogno di utilizzare una funzione specifica di un pacchetto, ma sai che la userai solo una volta, puoi evitare di caricare l’intero pacchetto con library(). Ad esempio, invece di scrivere:\nlibrary(nome_pacchetto)\nfunzione_specifica(x = 2, sd = 3)\npuoi accedere direttamente alla funzione usando l’operatore ::, come indicato di segtuito:\nnome_pacchetto::funzione_specifica(x = 2, sd = 3)\nQuesto approccio è utile per funzioni che usi raramente o una sola volta. Personalmente, utilizzo :: anche quando ho già caricato il pacchetto, per ricordare ad un “me futuro” da quale pacchetto proviene una determinata funzione. Questo può rendere il codice più leggibile e comprensibile nel tempo.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Pacchetti</span>"
    ]
  },
  {
    "objectID": "chapters/R/04_r_packages.html#bibliografia",
    "href": "chapters/R/04_r_packages.html#bibliografia",
    "title": "9  Pacchetti",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nIrizarry, R. A. (2024). Introduction to Data Science: Data Wrangling and Visualization with R. CRC Press.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Pacchetti</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html",
    "href": "chapters/R/05_dplyr.html",
    "title": "10  Introduzione a dplyr",
    "section": "",
    "text": "Introduzione\nL’obiettivo di questo capitolo è fornire un’introduzione alle funzioni principali del pacchetto dplyr per le operazioni di data wrangling, cioè per il preprocessing e la pulizia dei dati. In R, queste operazioni sono strettamente legate al concetto di “data tidying”, che si riferisce all’organizzazione sistematica dei dati per facilitare l’analisi.\nPer comprendere meglio il concetto di “data tidying”, possiamo rifarci a una citazione tratta dal testo di riferimento R for Data Science (2e):\nL’essenza del “data tidying” è organizzare i dati in un formato che sia facile da gestire e analizzare. Anche se gli stessi dati possono essere rappresentati in vari modi, non tutte le rappresentazioni sono ugualmente efficienti o facili da usare. Un dataset “tidy” segue tre principi fondamentali che lo rendono particolarmente pratico:\nIl pacchetto R {dplyr} e gli altri pacchetti del tidyverse sono progettati specificamente per lavorare con dati in formato “tidy”, permettendo agli utenti di eseguire operazioni di manipolazione e visualizzazione in modo più intuitivo ed efficiente.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Introduzione a `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html#introduzione",
    "href": "chapters/R/05_dplyr.html#introduzione",
    "title": "10  Introduzione a dplyr",
    "section": "",
    "text": "“Happy families are all alike; every unhappy family is unhappy in its own way.” — Leo Tolstoy\n\n\n“Tidy datasets are all alike, but every messy dataset is messy in its own way.” — Hadley Wickham\n\n\n\n\nOgni variabile è una colonna: ogni colonna nel dataset rappresenta una singola variabile.\n\nOgni osservazione è una riga: ogni riga nel dataset rappresenta un’unica osservazione.\n\nOgni valore è una cella: ogni cella del dataset contiene un singolo valore.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Introduzione a `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html#pipe",
    "href": "chapters/R/05_dplyr.html#pipe",
    "title": "10  Introduzione a dplyr",
    "section": "\n10.1 Pipe",
    "text": "10.1 Pipe\nIl pacchetto dplyr, così come l’intero ecosistema tidyverse, fa largo uso dell’operatore pipe, che consente di concatenare una sequenza di operazioni in modo leggibile ed efficiente. In R, esistono due principali notazioni per il pipe:\n\n\n|&gt;: introdotto nativamente a partire dalla versione 4.1.0 di R.\n\n%&gt;%: introdotto dal pacchetto magrittr, ed è una delle componenti centrali del tidyverse.\n\nEntrambi gli operatori permettono di ottenere risultati simili e, per la maggior parte degli utilizzi, possono essere considerati intercambiabili. Tuttavia, è importante sottolineare alcune differenze:\n\n\n|&gt; è integrato nel linguaggio R e non richiede pacchetti aggiuntivi.\n\n%&gt;%, essendo parte di magrittr, richiede che il pacchetto sia installato e caricato (library(magrittr) o automaticamente tramite tidyverse).\n\nConsideriamo l’esempio seguente (che anticipa l’uso della funzione filter() che descriveremo in seguito). Un’operazione comune è filtrare un data frame e calcolare la media di una colonna. Con il pipe, questa sequenza di operazioni diventa più leggibile:\n\n# Usando %&gt;%\niris %&gt;%\n  dplyr::filter(Species == \"setosa\") |&gt; \n  summarise(\n    mean_sepal_length = mean(Sepal.Length)\n  ) \n#&gt;   mean_sepal_length\n#&gt; 1             5.006\n\n\n# Usando |&gt;\niris |&gt; \n  dplyr::filter(Species == \"setosa\") |&gt; \n  summarise(\n    mean_sepal_length = mean(Sepal.Length)\n  ) \n#&gt;   mean_sepal_length\n#&gt; 1             5.006\n\n\n10.1.1 Cosa Fa la Pipe?\nLa pipe è uno strumento potente che permette di collegare in modo diretto l’output di una funzione come input della funzione successiva. Questo approccio:\n\nRiduce la necessità di creare variabili intermedie.\nMigliora la leggibilità del codice.\nRende il flusso delle operazioni più chiaro e lineare.\n\nOgni funzione applicata con la pipe riceve automaticamente l’output della funzione precedente come suo primo argomento. Ciò consente di scrivere sequenze di operazioni in un formato compatto e intuitivo.\nEcco un altro esempio:\n\n# Utilizzo della pipe per trasformare un dataset\ndf &lt;- data.frame(\n  id = 1:5,\n  value = c(10, 20, 30, 40, 50)\n)\n\n# Filtra i dati, seleziona colonne e calcola nuovi valori\ndf_clean &lt;- df |&gt;\n  dplyr::filter(value &gt; 20) |&gt;\n  dplyr::select(id, value) |&gt;\n  mutate(squared_value = value^2)\n\nIn questa sequenza, il dataset originale df viene filtrato, le colonne desiderate vengono selezionate e viene aggiunta una nuova colonna con il valore al quadrato.\n\nhead(df_clean)\n#&gt;   id value squared_value\n#&gt; 1  3    30           900\n#&gt; 2  4    40          1600\n#&gt; 3  5    50          2500\n\nIn sintesi, la pipe è uno strumento fondamentale per scrivere codice R moderno e leggibile, indipendentemente dal fatto che si utilizzi |&gt; o %&gt;%.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Introduzione a `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html#verbi",
    "href": "chapters/R/05_dplyr.html#verbi",
    "title": "10  Introduzione a dplyr",
    "section": "\n10.2 Verbi",
    "text": "10.2 Verbi\nLe funzioni principali (“verbi) di dplyr sono le seguenti:\n\n\n\n\n\n\nVerbo dplyr\nDescrizione\n\n\n\nselect()\nSeleziona colonne\n\n\nfilter()\nFiltra righe\n\n\narrange()\nRiordina o organizza le righe\n\n\nmutate()\nCrea nuove colonne\n\n\nsummarise()\nRiassume i valori\n\n\ngroup_by()\nConsente di eseguire operazioni di gruppo\n\n\n\nI verbi di dplyr sono suddivisi in quattro gruppi, in base all’elemento su cui operano: righe, colonne, gruppi o tabelle.\nInoltre, le diverse funzioni bind_ e _joins permettono di combinare più tibbles (ovvero, data frame) in uno solo.\nPer fare un esempio prarico, usiamo nuovamente il dataset msleep.\n\ndata(msleep)\ndim(msleep)\n#&gt; [1] 83 11\n\nEsaminiamo i dati:\n\nglimpse(msleep)\n#&gt; Rows: 83\n#&gt; Columns: 11\n#&gt; $ name         &lt;chr&gt; \"Cheetah\", \"Owl monkey\", \"Mountain beaver\", \"Greater …\n#&gt; $ genus        &lt;chr&gt; \"Acinonyx\", \"Aotus\", \"Aplodontia\", \"Blarina\", \"Bos\", …\n#&gt; $ vore         &lt;chr&gt; \"carni\", \"omni\", \"herbi\", \"omni\", \"herbi\", \"herbi\", \"…\n#&gt; $ order        &lt;chr&gt; \"Carnivora\", \"Primates\", \"Rodentia\", \"Soricomorpha\", …\n#&gt; $ conservation &lt;chr&gt; \"lc\", NA, \"nt\", \"lc\", \"domesticated\", NA, \"vu\", NA, \"…\n#&gt; $ sleep_total  &lt;dbl&gt; 12.1, 17.0, 14.4, 14.9, 4.0, 14.4, 8.7, 7.0, 10.1, 3.…\n#&gt; $ sleep_rem    &lt;dbl&gt; NA, 1.8, 2.4, 2.3, 0.7, 2.2, 1.4, NA, 2.9, NA, 0.6, 0…\n#&gt; $ sleep_cycle  &lt;dbl&gt; NA, NA, NA, 0.1333, 0.6667, 0.7667, 0.3833, NA, 0.333…\n#&gt; $ awake        &lt;dbl&gt; 11.9, 7.0, 9.6, 9.1, 20.0, 9.6, 15.3, 17.0, 13.9, 21.…\n#&gt; $ brainwt      &lt;dbl&gt; NA, 0.01550, NA, 0.00029, 0.42300, NA, NA, NA, 0.0700…\n#&gt; $ bodywt       &lt;dbl&gt; 50.000, 0.480, 1.350, 0.019, 600.000, 3.850, 20.490, …\n\nLe colonne, nell’ordine, corrispondono a quanto segue:\n\n\nNome colonna\nDescrizione\n\n\n\nname\nNome comune\n\n\ngenus\nRango tassonomico\n\n\nvore\nCarnivoro, onnivoro o erbivoro?\n\n\norder\nRango tassonomico\n\n\nconservation\nStato di conservazione del mammifero\n\n\nsleep_total\nQuantità totale di sonno, in ore\n\n\nsleep_rem\nSonno REM, in ore\n\n\nsleep_cycle\nDurata del ciclo di sonno, in ore\n\n\nawake\nQuantità di tempo trascorso sveglio, in ore\n\n\nbrainwt\nPeso del cervello, in chilogrammi\n\n\nbodywt\nPeso corporeo, in chilogrammi",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Introduzione a `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html#righe",
    "href": "chapters/R/05_dplyr.html#righe",
    "title": "10  Introduzione a dplyr",
    "section": "\n10.3 Righe",
    "text": "10.3 Righe\nI verbi più importanti che operano sulle righe di un dataset sono filter(), che seleziona le righe da includere senza modificarne l’ordine, e arrange(), che cambia l’ordine delle righe senza alterare la selezione delle righe presenti.\n\nmsleep |&gt;\n  dplyr::filter(sleep_total &lt; 4) |&gt;\n  arrange(sleep_total)\n#&gt; # A tibble: 9 × 11\n#&gt;   name             genus         vore  order          conservation\n#&gt;   &lt;chr&gt;            &lt;chr&gt;         &lt;chr&gt; &lt;chr&gt;          &lt;chr&gt;       \n#&gt; 1 Giraffe          Giraffa       herbi Artiodactyla   cd          \n#&gt; 2 Pilot whale      Globicephalus carni Cetacea        cd          \n#&gt; 3 Horse            Equus         herbi Perissodactyla domesticated\n#&gt; 4 Roe deer         Capreolus     herbi Artiodactyla   lc          \n#&gt; 5 Donkey           Equus         herbi Perissodactyla domesticated\n#&gt; 6 African elephant Loxodonta     herbi Proboscidea    vu          \n#&gt; 7 Caspian seal     Phoca         carni Carnivora      vu          \n#&gt; 8 Sheep            Ovis          herbi Artiodactyla   domesticated\n#&gt; 9 Asian elephant   Elephas       herbi Proboscidea    en          \n#&gt;   sleep_total sleep_rem sleep_cycle awake brainwt bodywt\n#&gt;         &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1         1.9       0.4          NA  22.1 NA       900. \n#&gt; 2         2.7       0.1          NA  21.4 NA       800  \n#&gt; 3         2.9       0.6           1  21.1  0.655   521  \n#&gt; 4         3        NA            NA  21    0.0982   14.8\n#&gt; 5         3.1       0.4          NA  20.9  0.419   187  \n#&gt; 6         3.3      NA            NA  20.7  5.71   6654  \n#&gt; 7         3.5       0.4          NA  20.5 NA        86  \n#&gt; 8         3.8       0.6          NA  20.2  0.175    55.5\n#&gt; 9         3.9      NA            NA  20.1  4.60   2547\n\nPossiamo usare filter() speficicano più di una condizione logica.\n\nmsleep |&gt;\n  dplyr::filter((sleep_total &lt; 4 & bodywt &gt; 100) | brainwt &gt; 1) |&gt;\n  arrange(sleep_total)\n#&gt; # A tibble: 7 × 11\n#&gt;   name             genus         vore  order          conservation\n#&gt;   &lt;chr&gt;            &lt;chr&gt;         &lt;chr&gt; &lt;chr&gt;          &lt;chr&gt;       \n#&gt; 1 Giraffe          Giraffa       herbi Artiodactyla   cd          \n#&gt; 2 Pilot whale      Globicephalus carni Cetacea        cd          \n#&gt; 3 Horse            Equus         herbi Perissodactyla domesticated\n#&gt; 4 Donkey           Equus         herbi Perissodactyla domesticated\n#&gt; 5 African elephant Loxodonta     herbi Proboscidea    vu          \n#&gt; 6 Asian elephant   Elephas       herbi Proboscidea    en          \n#&gt; 7 Human            Homo          omni  Primates       &lt;NA&gt;        \n#&gt;   sleep_total sleep_rem sleep_cycle awake brainwt bodywt\n#&gt;         &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1         1.9       0.4        NA    22.1  NA       900.\n#&gt; 2         2.7       0.1        NA    21.4  NA       800 \n#&gt; 3         2.9       0.6         1    21.1   0.655   521 \n#&gt; 4         3.1       0.4        NA    20.9   0.419   187 \n#&gt; 5         3.3      NA          NA    20.7   5.71   6654 \n#&gt; 6         3.9      NA          NA    20.1   4.60   2547 \n#&gt; 7         8         1.9         1.5  16     1.32     62",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Introduzione a `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html#colonne",
    "href": "chapters/R/05_dplyr.html#colonne",
    "title": "10  Introduzione a dplyr",
    "section": "\n10.4 Colonne",
    "text": "10.4 Colonne\nEsistono quattro verbi principali che modificano le colonne di un dataset senza cambiare le righe:\n\n\nrelocate() cambia la posizione delle colonne;\n\nrename() modifica i nomi delle colonne;\n\nselect() seleziona le colonne da includere o escludere;\n\nmutate() crea nuove colonne a partire da quelle esistenti.\n\n\nmsleep2 &lt;- msleep |&gt;\n  mutate(\n    rem_prop = sleep_rem / sleep_total * 100\n  ) |&gt;\n  dplyr::select(name, vore, rem_prop, sleep_total) |&gt;\n  arrange(desc(rem_prop))\n\nglimpse(msleep2)\n#&gt; Rows: 83\n#&gt; Columns: 4\n#&gt; $ name        &lt;chr&gt; \"European hedgehog\", \"Thick-tailed opposum\", \"Giant ar…\n#&gt; $ vore        &lt;chr&gt; \"omni\", \"carni\", \"insecti\", \"omni\", \"carni\", \"omni\", \"…\n#&gt; $ rem_prop    &lt;dbl&gt; 34.65, 34.02, 33.70, 29.21, 28.71, 27.22, 26.37, 26.21…\n#&gt; $ sleep_total &lt;dbl&gt; 10.1, 19.4, 18.1, 8.9, 10.1, 18.0, 9.1, 10.3, 12.5, 8.…\n\nIn questo esempio, utilizziamo mutate() per creare una nuova colonna rem_prop che rappresenta la percentuale di sonno REM sul totale del sonno. Successivamente, select() viene utilizzato per scegliere solo alcune colonne del dataset, e infine desc(rem_prop) ordina i valori di rem_prop in ordine decrescente, dal valore maggiore a quello minore.\nPer cambiare il nome di una colonna possiamo usare rename(). Inoltre, possiamo cambiare l’ordine delle variabili con relocate().\n\nmsleep2 |&gt;\n  rename(rem_perc = rem_prop) |&gt;\n  relocate(rem_perc, .before = name)\n#&gt; # A tibble: 83 × 4\n#&gt;    rem_perc name                   vore    sleep_total\n#&gt;       &lt;dbl&gt; &lt;chr&gt;                  &lt;chr&gt;         &lt;dbl&gt;\n#&gt;  1     34.7 European hedgehog      omni           10.1\n#&gt;  2     34.0 Thick-tailed opposum   carni          19.4\n#&gt;  3     33.7 Giant armadillo        insecti        18.1\n#&gt;  4     29.2 Tree shrew             omni            8.9\n#&gt;  5     28.7 Dog                    carni          10.1\n#&gt;  6     27.2 North American Opossum omni           18  \n#&gt;  7     26.4 Pig                    omni            9.1\n#&gt;  8     26.2 Desert hedgehog        &lt;NA&gt;           10.3\n#&gt;  9     25.6 Domestic cat           carni          12.5\n#&gt; 10     25   Eastern american mole  insecti         8.4\n#&gt; # ℹ 73 more rows",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Introduzione a `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html#gruppi",
    "href": "chapters/R/05_dplyr.html#gruppi",
    "title": "10  Introduzione a dplyr",
    "section": "\n10.5 Gruppi",
    "text": "10.5 Gruppi\nIl verbo group_by() viene utilizzato per suddividere un dataset in gruppi, in base a una o più variabili, che siano rilevanti per l’analisi. Questo permette di eseguire operazioni di sintesi su ciascun gruppo separatamente, ottenendo informazioni aggregate.\nAd esempio, nel codice seguente:\n\nmsleep |&gt;\n  group_by(order) |&gt;\n  summarise(\n    avg_sleep = mean(sleep_total),\n    min_sleep = min(sleep_total),\n    max_sleep = max(sleep_total),\n    total = n()\n  ) |&gt;\n  arrange(desc(avg_sleep))\n#&gt; # A tibble: 19 × 5\n#&gt;    order           avg_sleep min_sleep max_sleep total\n#&gt;    &lt;chr&gt;               &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;int&gt;\n#&gt;  1 Chiroptera          19.8       19.7      19.9     2\n#&gt;  2 Didelphimorphia     18.7       18        19.4     2\n#&gt;  3 Cingulata           17.8       17.4      18.1     2\n#&gt;  4 Afrosoricida        15.6       15.6      15.6     1\n#&gt;  5 Pilosa              14.4       14.4      14.4     1\n#&gt;  6 Rodentia            12.5        7        16.6    22\n#&gt;  7 Diprotodontia       12.4       11.1      13.7     2\n#&gt;  8 Soricomorpha        11.1        8.4      14.9     5\n#&gt;  9 Primates            10.5        8        17      12\n#&gt; 10 Erinaceomorpha      10.2       10.1      10.3     2\n#&gt; 11 Carnivora           10.1        3.5      15.8    12\n#&gt; 12 Scandentia           8.9        8.9       8.9     1\n#&gt; 13 Monotremata          8.6        8.6       8.6     1\n#&gt; 14 Lagomorpha           8.4        8.4       8.4     1\n#&gt; 15 Hyracoidea           5.67       5.3       6.3     3\n#&gt; 16 Artiodactyla         4.52       1.9       9.1     6\n#&gt; 17 Cetacea              4.5        2.7       5.6     3\n#&gt; 18 Proboscidea          3.6        3.3       3.9     2\n#&gt; 19 Perissodactyla       3.47       2.9       4.4     3\n\n\ngroup_by(order) suddivide il dataset msleep in gruppi, ciascuno corrispondente a un valore distinto della variabile order.\n\nSuccessivamente, summarise() calcola diverse statistiche per ogni gruppo:\n\n\navg_sleep è la media del totale del sonno (sleep_total) all’interno di ciascun gruppo.\n\nmin_sleep è il valore minimo di sleep_total in ogni gruppo.\n\nmax_sleep è il valore massimo di sleep_total in ogni gruppo.\n\ntotal è il numero di osservazioni (o righe) per ciascun gruppo, calcolato con la funzione n().\n\n\nInfine, arrange(desc(avg_sleep)) ordina i risultati in ordine decrescente in base alla media del sonno totale (avg_sleep), mostrando prima i gruppi con la media di sonno più alta.\n\nQuesto tipo di approccio è utile quando si vuole analizzare come cambiano le caratteristiche dei dati a seconda dei gruppi specifici, fornendo una visione più dettagliata e utile.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Introduzione a `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html#riflessioni-conclusive",
    "href": "chapters/R/05_dplyr.html#riflessioni-conclusive",
    "title": "10  Introduzione a dplyr",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIl data wrangling è una delle fasi più importanti in qualsiasi pipeline di analisi dei dati. In questo capitolo abbiamo introdotto l’uso del pacchetto tidyverse di R per la manipolazione dei dati e il suo utilizzo in scenari di base. Tuttavia, il tidyverse è un ecosistema ampio e qui abbiamo trattato solo gli elementi fondamentali. Per approfondire, si consiglia di consultare ulteriori risorse come quelle disponibili sul sito web del tidyverse e il libro R for Data Science (2e), di cui esiste anche una traduzione italiana.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Introduzione a `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html#esercizi",
    "href": "chapters/R/05_dplyr.html#esercizi",
    "title": "10  Introduzione a dplyr",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nIn questo esercizio, utilizzerai il pacchetto dplyr per imparare a manipolare e trasformare i dati della SWLS (Satisfaction With Life Scale). Gli esercizi ti aiuteranno a consolidare la conoscenza dei principali verbi di dplyr, inclusi filter(), select(), mutate(), arrange() e group_by().\nParte 1: Comprensione Teorica\n\n\nCos’è un dataset “tidy”?\n\nDescrivi con parole tue cosa significa avere un dataset “tidy” e quali sono le sue tre caratteristiche principali.\n\n\n\nCos’è la pipe (%&gt;% o |&gt;) e perché è utile?\n\nSpiega a cosa serve l’operatore pipe e fornisci un esempio di utilizzo.\n\n\n\nQuali sono i verbi principali di dplyr?\n\nElenca e spiega brevemente i sei verbi principali di dplyr per la manipolazione dei dati.\n\n\n\nCosa fa il verbo group_by()?\n\nSpiega il suo scopo e come viene utilizzato in combinazione con summarise().\n\n\n\nParte 2: Applicazione Pratica con i Dati SWLS\n\n\nCaricamento dei dati SWLS\n\nCrea un data frame in R contenente i punteggi SWLS che hai raccolto.\n\n\n\nSelezione delle colonne\n\nUsa select() per mantenere solo le colonne con i punteggi degli item.\n\n\n\nFiltraggio dei dati\n\nUsa filter() per selezionare solo gli individui che hanno un punteggio totale superiore a 20.\n\n\n\nCreazione di una nuova colonna\n\nUsa mutate() per calcolare il punteggio totale della SWLS per ciascun individuo e salvarlo in una nuova colonna chiamata punteggio_totale.\n\n\n\nRiordinamento dei dati\n\nUsa arrange() per ordinare il dataset in base al punteggio totale, dal più alto al più basso.\n\n\n\nRaggruppamento e sintesi dei dati\n\n\n\nUsa group_by() e summarise() per calcolare la media e la deviazione standard del punteggio SWLS totale nel dataset.\n\nConsegna\n\nScrivi le risposte della Parte 1 su carta.\nScrivi il codice e i risultati della Parte 2 in un file .R e invialo come consegna.\n\n\n\n\n\n\n\n\n\n\nSoluzione\n\n\n\n\n\nParte 1: Comprensione Teorica\n\n\nCos’è un dataset “tidy”?\n\nUn dataset “tidy” è un dataset organizzato in modo sistematico per facilitare l’analisi. Le sue tre caratteristiche principali sono:\n\nOgni variabile è una colonna.\nOgni osservazione è una riga.\nOgni valore è una cella.\n\n\n\n\n\nCos’è la pipe (%&gt;% o |&gt;) e perché è utile?\n\nLa pipe (%&gt;% o |&gt;) permette di concatenare più operazioni di manipolazione dati in modo leggibile ed efficiente.\n\nEsempio:\ndf |&gt; \n  filter(score &gt; 20) |&gt; \n  select(name, score)\n\n\n\n\nQuali sono i verbi principali di dplyr?\n\n\nselect(): Seleziona colonne.\n\nfilter(): Filtra righe.\n\narrange(): Riordina le righe.\n\nmutate(): Crea nuove colonne.\n\nsummarise(): Riassume i dati.\n\ngroup_by(): Permette di raggruppare i dati.\n\n\n\nCosa fa il verbo group_by()?\n\ngroup_by() suddivide i dati in gruppi, permettendo di applicare funzioni di aggregazione con summarise().\n\nEsempio:\ndf |&gt; \n  group_by(gruppo) |&gt; \n  summarise(media = mean(score), sd = sd(score))\n\n\n\n\nParte 2: Applicazione Pratica con i Dati SWLS\n\n\nCaricamento dei dati SWLS Per svolgere l’esercizio, simuliamo i dati di 10 individui su 5 item (numeri casuali da 1 a 7):\nset.seed(123)\nswls &lt;- data.frame(\n  id = 1:10,\n  item1 = sample(1:7, 10, replace = TRUE),\n  item2 = sample(1:7, 10, replace = TRUE),\n  item3 = sample(1:7, 10, replace = TRUE),\n  item4 = sample(1:7, 10, replace = TRUE),\n  item5 = sample(1:7, 10, replace = TRUE)\n)\nprint(swls)\n\n\nSelezione delle colonne\nswls_selected &lt;- swls |&gt; select(item1:item5)\n\n\nFiltraggio dei dati\nswls_filtered &lt;- swls |&gt; filter(rowSums(select(swls, item1:item5)) &gt; 20)\n\n\nCreazione di una nuova colonna\nswls &lt;- swls |&gt; mutate(punteggio_totale = rowSums(select(swls, item1:item5)))\n\n\nRiordinamento dei dati\nswls_sorted &lt;- swls |&gt; arrange(desc(punteggio_totale))\n\nRaggruppamento e sintesi dei dati\n\nswls_summary &lt;- swls |&gt; \n  summarise(media = mean(punteggio_totale), sd = sd(punteggio_totale))\nConclusione\nQuesti esercizi hanno mostrato come usare dplyr per manipolare dati in modo efficace e leggibile.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Introduzione a `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/R/05_dplyr.html#informazioni-sullambiente-di-sviluppo",
    "title": "10  Introduzione a dplyr",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] missForest_1.5        mice_3.18.0           pillar_1.11.0        \n#&gt;  [4] tinytable_0.11.0      patchwork_1.3.1       ggdist_3.3.3         \n#&gt;  [7] tidybayes_3.0.7       bayesplot_1.13.0      ggplot2_3.5.2        \n#&gt; [10] reliabilitydiag_0.2.1 priorsense_1.1.0      posterior_1.6.1      \n#&gt; [13] loo_2.8.0             rstan_2.32.7          StanHeaders_2.32.10  \n#&gt; [16] brms_2.22.0           Rcpp_1.1.0            janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] Rdpack_2.6.4         gridExtra_2.3        inline_0.3.21       \n#&gt;  [4] sandwich_3.1-1       rlang_1.1.6          magrittr_2.0.3      \n#&gt;  [7] multcomp_1.4-28      snakecase_0.11.1     compiler_4.5.1      \n#&gt; [10] vctrs_0.6.5          stringr_1.5.1        pkgconfig_2.0.3     \n#&gt; [13] shape_1.4.6.1        arrayhelpers_1.1-0   fastmap_1.2.0       \n#&gt; [16] backports_1.5.0      utf8_1.2.6           rmarkdown_2.29      \n#&gt; [19] itertools_0.1-3      nloptr_2.2.1         purrr_1.1.0         \n#&gt; [22] xfun_0.52            glmnet_4.1-10        jomo_2.7-6          \n#&gt; [25] randomForest_4.7-1.2 jsonlite_2.0.0       pan_1.9             \n#&gt; [28] broom_1.0.9          parallel_4.5.1       R6_2.6.1            \n#&gt; [31] stringi_1.8.7        RColorBrewer_1.1-3   rpart_4.1.24        \n#&gt; [34] boot_1.3-31          lubridate_1.9.4      estimability_1.5.1  \n#&gt; [37] iterators_1.0.14     knitr_1.50           zoo_1.8-14          \n#&gt; [40] pacman_0.5.1         nnet_7.3-20          Matrix_1.7-3        \n#&gt; [43] splines_4.5.1        timechange_0.3.0     tidyselect_1.2.1    \n#&gt; [46] abind_1.4-8          codetools_0.2-20     curl_6.4.0          \n#&gt; [49] doRNG_1.8.6.2        pkgbuild_1.4.8       lattice_0.22-7      \n#&gt; [52] withr_3.0.2          bridgesampling_1.1-2 coda_0.19-4.1       \n#&gt; [55] evaluate_1.0.4       survival_3.8-3       RcppParallel_5.1.10 \n#&gt; [58] rngtools_1.5.2       tensorA_0.36.2.1     checkmate_2.3.2     \n#&gt; [61] foreach_1.5.2        stats4_4.5.1         reformulas_0.4.1    \n#&gt; [64] distributional_0.5.0 generics_0.1.4       rprojroot_2.1.0     \n#&gt; [67] rstantools_2.4.0     scales_1.4.0         minqa_1.2.8         \n#&gt; [70] xtable_1.8-4         glue_1.8.0           emmeans_1.11.2      \n#&gt; [73] tools_4.5.1          lme4_1.1-37          mvtnorm_1.3-3       \n#&gt; [76] grid_4.5.1           rbibutils_2.3        QuickJSR_1.8.0      \n#&gt; [79] colorspace_2.1-1     nlme_3.1-168         cli_3.6.5           \n#&gt; [82] svUnit_1.0.6         Brobdingnag_1.2-9    V8_6.0.5            \n#&gt; [85] gtable_0.3.6         digest_0.6.37        TH.data_1.1-3       \n#&gt; [88] htmlwidgets_1.6.4    farver_2.1.2         htmltools_0.5.8.1   \n#&gt; [91] lifecycle_1.0.4      mitml_0.4-5          MASS_7.3-65",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Introduzione a `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_dplyr.html#bibliografia",
    "href": "chapters/R/05_dplyr.html#bibliografia",
    "title": "10  Introduzione a dplyr",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nIrizarry, R. A. (2024). Introduction to Data Science: Data Wrangling and Visualization with R. CRC Press.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Introduzione a `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/R/06_quarto.html",
    "href": "chapters/R/06_quarto.html",
    "title": "11  Quarto",
    "section": "",
    "text": "11.1 Introduzione\nLa crisi della riproducibilità scientifica rappresenta una delle sfide più importanti della ricerca contemporanea. Con questo termine ci si riferisce alla difficoltà, riscontrata in diverse discipline, di replicare i risultati degli studi scientifici. Sebbene le definizioni di riproducibilità varino tra i diversi ambiti, un’interpretazione ampiamente condivisa la identifica come la capacità di ottenere gli stessi risultati utilizzando i medesimi dati di input e seguendo gli stessi passaggi computazionali nei metodi e nelle analisi.\nLa pratica scientifica è profondamente radicata nella formazione accademica: ciò che viene insegnato nelle aule universitarie si riflette direttamente nel lavoro svolto nei laboratori, sul campo e nell’analisi dei dati. Riconoscendo questo stretto legame tra didattica e ricerca, molti studiosi sostengono l’importanza di integrare i metodi di riproducibilità nei corsi universitari di data science, sia a livello undergraduate che graduate (Dogucu, 2024). L’educazione alla data science che incorpora la riproducibilità nell’analisi dei dati viene infatti considerata la “controffensiva statistica” alla crisi della riproducibilità.\nIn questo contesto si inserisce Quarto, uno strumento innovativo che affronta direttamente le sfide della crisi della riproducibilità. Quarto si colloca nella tradizione del literate programming, un approccio pioneristico introdotto da Donald Knuth negli anni ’80. Questa metodologia nasce dalla visione di unificare codice e testo descrittivo in un unico documento, rendendo i programmi non solo eseguibili ma anche comprensibili agli esseri umani. L’obiettivo è superare la tradizionale separazione tra codice e documentazione, permettendo di spiegare non solo il funzionamento tecnico di un programma, ma anche le ragioni delle scelte implementative.\nQuesta filosofia risulta particolarmente pertinente nell’ambito della data science e dell’analisi statistica, dove riproducibilità e trasparenza sono requisiti imprescindibili. Quarto eccelle in questo contesto, offrendo la possibilità di integrare in codice, risultati e narrazione. La sua versatilità si manifesta nella capacità di produrre diversi tipi di output - dai report agli articoli scientifici, dalle presentazioni ai documenti tecnici - in vari formati come HTML, PDF e Word, combinando efficacemente testo interpretativo, risultati numerici e visualizzazioni grafiche.\nUn punto di forza distintivo di Quarto è la sua flessibilità nel supportare molteplici linguaggi di programmazione, tra cui R, Python e Julia. Lo strumento può essere utilizzato secondo tre modalità principali: per presentare conclusioni condividendo i risultati senza esporre il codice sottostante; per documentare il processo analitico includendo sia il codice che i risultati, garantendo così piena trasparenza e riproducibilità; e per annotare l’analisi, integrando interpretazioni e motivazioni delle decisioni prese durante il processo analitico.\nNonostante Quarto sia tecnicamente uno strumento da riga di comando (CLI), l’integrazione con RStudio ne semplifica notevolmente l’utilizzo, rendendo l’installazione e l’operatività accessibili anche agli utenti meno esperti nell’uso del terminale. Questa caratteristica, unita alle sue potenti funzionalità, rende Quarto una naturale evoluzione del literate programming, offrendo un ambiente di lavoro che bilancia efficacemente praticità d’uso e rigore scientifico. In questo modo, Quarto si configura come una risposta concreta alle sfide della riproducibilità nella ricerca contemporanea, fornendo gli strumenti necessari per una scienza più trasparente e verificabile. L’obiettivo di questo capitolo è quello di fornire un’introduzione pratica a Quarto.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "chapters/R/06_quarto.html#introduzione",
    "href": "chapters/R/06_quarto.html#introduzione",
    "title": "11  Quarto",
    "section": "",
    "text": "11.1.1 Creare un documento Quarto\nUn file Quarto ha estensione .qmd e segue questa struttura:\n\nQuesto file include:\n\nUn’intestazione YAML (metadati del documento).\nBlocchi di codice delimitati da ```.\nTesto scritto in Markdown con formattazioni semplici come titoli (# Titolo), corsivi (*testo*), ecc.\n\n11.1.2 Editor visivo e sorgente\n\n\nEditor visivo: simile a Google Docs, offre un’interfaccia WYSIWYM (What You See Is What You Mean). Consente di inserire facilmente immagini, tabelle, citazioni e altro.\n\nEditor sorgente: consente un controllo diretto sul Markdown, utile per debug e personalizzazioni avanzate.\n\n11.1.3 Blocchi di codice\nI blocchi di codice (chiamati “chunks”) eseguono codice e visualizzano i risultati. Ogni chunk è delimitato da ``` e può includere opzioni specifiche:\n#| label: esempio\n#| echo: false\n1 + 1\nLe opzioni più comuni includono:\n\n\necho: false (nasconde il codice nel report),\n\neval: false (non esegue il codice),\n\nmessage: false e warning: false (nasconde messaggi o avvisi).\n\n11.1.4 Figure\nLe figure possono essere generate tramite codice (es. ggplot()) o inserite come file esterni. Le opzioni più comuni per il controllo delle dimensioni sono:\n\n\nfig-width e fig-height (dimensioni della figura in pollici),\n\nout-width (percentuale di larghezza del documento),\n\nfig-asp (rapporto d’aspetto, es. 0.618 per il rapporto aureo).\n\nEsempio:\n#| fig-width: 6\nggplot(data, aes(x, y)) + geom_point()\n\n11.1.5 Equazioni\nLe equazioni possono essere scritte in LaTeX, così come spiegato nell’Appendice D.\n\n11.1.6 Tabelle\nLe tabelle possono essere stampate direttamente o personalizzate con funzioni come knitr::kable() o pacchetti come gt:\n\nknitr::kable(head(mtcars))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\n\n\n\nMazda RX4\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\nMazda RX4 Wag\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\nDatsun 710\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\nHornet 4 Drive\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\nHornet Sportabout\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\nValiant\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n\n\n11.1.7 Caching\nPer velocizzare i documenti con calcoli complessi, Quarto supporta la memorizzazione dei risultati:\n\n\ncache: true salva i risultati di un chunk, evitando di ricalcolarli se il codice non cambia.\n\ndependson specifica dipendenze tra chunk.\n\n11.1.8 Gestione delle Citazioni e delle Bibliografie in Quarto\nQuarto offre un supporto avanzato per la generazione automatica di citazioni e bibliografie, consentendo l’applicazione di formati personalizzati come lo stile APA. Per includere riferimenti bibliografici, è necessario creare un file .bib (ad esempio, references.bib) contenente le citazioni nel formato BibTeX. Queste citazioni possono essere ottenute direttamente da Google Scholar o altri database accademici.\nEcco un esempio di una citazione in formato BibTeX:\n@article{ceccarini2024age,\n  title={Age-dependent changes in the anger superiority effect: Evidence from a visual search task},\n  author={Ceccarini, Francesco and Colpizzi, Ilaria and Caudek, Corrado},\n  journal={Psychonomic Bulletin \\& Review},\n  pages={1--10},\n  year={2024},\n  publisher={Springer}\n}\nQuesta citazione deve essere inserita in un file .bib, ad esempio, references.bib. Tale file dovrà poi essere specificato nell’intestazione del documento Quarto.\n\n11.1.8.1 Configurazione dell’Intestazione YAML\nNel file .qmd, è necessario aggiungere le seguenti righe all’intestazione YAML per collegare il file references.bib e configurare lo stile della bibliografia:\nbibliography: references.bib\nbiblio-style: apalike\ncsl: apa.csl\n\n\nbibliography: Specifica il percorso del file .bib. In questo esempio, si assume che il file si trovi nella stessa cartella del documento Quarto.\n\nbiblio-style: Imposta lo stile delle citazioni. Ad esempio, apalike è uno stile simile allo stile APA.\n\ncsl: Consente di utilizzare uno stile di citazione personalizzato, come apa.csl. Puoi scaricare facilmente questi stili dal Zotero Style Repository.\n\n11.1.8.2 Esempio Completo\nDi seguito è riportato un esempio completo di un documento Quarto che include una citazione e genera automaticamente la bibliografia:\n---\ntitle: \"Articolo di Esempio\"\nauthor: \"Autore di Esempio\"\ndate: \"2025-06-21\"\nbibliography: references.bib\nbiblio-style: apalike\ncsl: apa.csl\n---\n\n## Introduzione\n\nIn questo articolo, discutiamo i cambiamenti dipendenti dall'età nell'anger-superiority effect [@ceccarini2024age].\n\n## Risultati\n\nI risultati mostrano che...\n\n## Riferimenti\nIn questo esempio, l’identificatore @ceccarini2024age viene utilizzato per fare riferimento alla citazione contenuta nel file references.bib. Al momento della compilazione, Quarto genererà automaticamente la lista dei riferimenti bibliografici in base al formato specificato.\n\n11.1.8.3 Citazioni Inline\nAll’interno di un documento .qmd, le citazioni vengono aggiunte utilizzando il simbolo @ seguito dall’identificativo della citazione specificato nel file .bib. Ad esempio:\n... come evidenziato da @ceccarini2024age, si osserva che...\nQuarto genera automaticamente la bibliografia, includendo solo i riferimenti effettivamente citati nel documento. La bibliografia viene aggiunta alla fine del file renderizzato (ad esempio, in formato HTML o PDF).\nAd esempio, nel caso di un documento .qmd, il testo sopra sarà visualizzato così:\n\n… come evidenziato da Ceccarini et al. (2024), si osserva che…\n\nLa citazione completa sarà inclusa automaticamente nella bibliografia, posizionata alla fine della pagina web o del documento finale. Si noti che Quarto gestisce automaticamente la formattazione e la posizione della bibliografia, garantendo coerenza e precisione.\n\nEsempio 11.1 Per fare un esempio pratico, possiamo inserire la citazione @ceccarini2024age direttamente nel file .qmd di questa pagina web. Quando il documento viene compilato, Quarto renderà la citazione in modo appropriato, come mostrato qui: Ceccarini et al. (2024).\nSi noti che, in fondo a questa pagina web, è presente un riferimento bibliografico corrispondente. Questo riferimento è stato aggiunto automaticamente da Quarto in risposta all’uso della citazione @ceccarini2024age nel testo del documento. Questo processo automatizzato semplifica la gestione delle citazioni e garantisce che tutti i riferimenti siano correttamente inclusi e formattati.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "chapters/R/06_quarto.html#riflessioni-conclusive",
    "href": "chapters/R/06_quarto.html#riflessioni-conclusive",
    "title": "11  Quarto",
    "section": "\n11.2 Riflessioni Conclusive",
    "text": "11.2 Riflessioni Conclusive\nQuarto è uno strumento potente per la creazione di documenti riproducibili e ben strutturati, integrando codice, risultati e testo descrittivo in un unico file. Questa introduzione dovrebbe essere sufficiente per iniziare a lavorare con Quarto, ma c’è ancora molto da imparare. Il modo migliore per rimanere aggiornati è consultare il sito ufficiale di Quarto: https://quarto.org.\nUn argomento importante che non abbiamo trattato qui riguarda i dettagli di come comunicare in modo accurato le proprie idee agli altri. Per migliorare le proprie capacità di scrittura, Wickham et al. (2023) consigliano due libri: Style: Lessons in Clarity and Grace di Joseph M. Williams & Joseph Bizup, e The Sense of Structure: Writing from the Reader’s Perspective di George Gopen. Una serie di brevi articoli sulla scrittura sono offerti da George Gopen e sono disponibili su https://www.georgegopen.com/litigation-articles.html.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "chapters/R/06_quarto.html#esercizi",
    "href": "chapters/R/06_quarto.html#esercizi",
    "title": "11  Quarto",
    "section": "\n11.3 Esercizi",
    "text": "11.3 Esercizi\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nIn questo esercizio esplorerai l’importanza della riproducibilità nella scienza dei dati e le funzionalità principali di Quarto.\n1. Concetti di base sulla riproducibilità\n\nCos’è la crisi della riproducibilità e perché è rilevante nella scienza dei dati?\nIn che modo Quarto può aiutare ad affrontare la crisi della riproducibilità?\nSpiega il concetto di literate programming e come si collega a Quarto.\n\n2. Struttura di un file Quarto\n\nQual è l’estensione di un file Quarto e quali sono le sue tre sezioni principali?\nQual è la differenza tra editor visivo ed editor sorgente in Quarto?\nQual è la funzione dell’intestazione YAML in un file .qmd?\n\n3. Blocchi di codice e opzioni\n\nCome si scrive un blocco di codice in Quarto?\nQuali opzioni puoi utilizzare nei blocchi di codice per controllare l’esecuzione e la visualizzazione del codice e dei risultati?\nScrivi un blocco di codice Quarto che calcola la media di un vettore di numeri e stampa il risultato senza mostrare il codice.\n\n4. Figure e Tabelle\n\nQuali opzioni di formattazione delle figure offre Quarto?\nCome puoi creare una tabella formattata in Quarto usando knitr::kable()?\n\n5. Citazioni e Bibliografia\n\nCome si aggiunge una citazione bibliografica in Quarto?\nQuali file devono essere inclusi per gestire una bibliografia in Quarto?\nScrivi un esempio di citazione in formato BibTeX e mostra come collegarla a un documento .qmd.\n\n6. Considerazioni Finali\n\nQuali sono i vantaggi di usare Quarto rispetto a strumenti più tradizionali come Word per la creazione di report scientifici?\n\n\n\n\n\n\n\n\n\n\nSoluzione\n\n\n\n\n\n1. Concetti di base sulla riproducibilità\n\nLa crisi della riproducibilità è il fenomeno per cui molti studi scientifici non possono essere replicati con gli stessi metodi e dati. Questo mina la fiducia nella scienza e può portare a risultati non affidabili.\nQuarto aiuta la riproducibilità integrando codice, testo e risultati in un unico documento, rendendo più semplice verificare e riprodurre le analisi.\n\nLiterate programming è un approccio introdotto da Donald Knuth che combina codice e spiegazioni testuali nello stesso file, migliorando la comprensione e documentazione delle analisi. Quarto segue questa filosofia.\n\n2. Struttura di un file Quarto\n\n\nL’estensione di un file Quarto è .qmd. Le tre sezioni principali sono:\n\nL’intestazione YAML (metadati),\nIl codice (chunks),\nIl testo scritto in Markdown.\n\n\nL’editor visivo è un’interfaccia intuitiva simile a Google Docs, mentre l’editor sorgente permette di scrivere direttamente in Markdown e codice.\nL’intestazione YAML definisce le proprietà del documento come titolo, autore, formato di output e opzioni di rendering.\n\n3. Blocchi di codice e opzioni\n\n\nUn blocco di codice in Quarto si scrive con tripli backtick (```) e un linguaggio specificato:\n#| echo: true\nprint(\"Esempio di codice in Quarto\")\n\n\nAlcune opzioni utili nei blocchi di codice sono:\n\n\necho: false per nascondere il codice,\n\neval: false per non eseguire il codice,\n\nwarning: false e message: false per nascondere messaggi e avvisi.\n\n\n\nEsempio di blocco di codice che calcola una media senza mostrare il codice:\n#| echo: false\nmean(c(1, 2, 3, 4, 5))\n\n\n\n11.4 4. Figure e Tabelle\n\n\nLe opzioni principali per le figure includono:\n\n\nfig-width e fig-height per le dimensioni,\n\nout-width per la larghezza relativa,\n\nfig-asp per il rapporto d’aspetto.\n\n\n\nPer creare una tabella formattata con knitr::kable():\nknitr::kable(head(mtcars))\n\n\n5. Citazioni e Bibliografia\n\nLe citazioni in Quarto si aggiungono usando il simbolo @ seguito dal riferimento BibTeX (es. @ceccarini2024age).\n\nPer gestire la bibliografia in Quarto servono:\n\nUn file .bib con le citazioni,\nUn’intestazione YAML che collega il file .bib e specifica lo stile (csl).\n\n\n\nEsempio di citazione BibTeX e collegamento in YAML:\n@article{ceccarini2024age,\n  title={Age-dependent changes in the anger superiority effect},\n  author={Ceccarini, Francesco et al.},\n  journal={Psychonomic Bulletin & Review},\n  year={2024}\n}\nYAML:\nbibliography: references.bib\nbiblio-style: apalike\n\n\n6. Considerazioni Finali\n\n\nI vantaggi di Quarto rispetto a Word includono:\n\nmaggiore riproducibilità e trasparenza,\npossibilità di integrare codice ed esecuzione in un unico documento,\nfacilità di gestione delle citazioni automatiche,\nsupporto per diversi formati di output (HTML, PDF, Word).",
    "crumbs": [
      "R",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "chapters/R/06_quarto.html#figure-e-tabelle",
    "href": "chapters/R/06_quarto.html#figure-e-tabelle",
    "title": "11  Quarto",
    "section": "\n11.4 4. Figure e Tabelle",
    "text": "11.4 4. Figure e Tabelle\n\n\nLe opzioni principali per le figure includono:\n\n\nfig-width e fig-height per le dimensioni,\n\nout-width per la larghezza relativa,\n\nfig-asp per il rapporto d’aspetto.\n\n\n\nPer creare una tabella formattata con knitr::kable():\nknitr::kable(head(mtcars))\n\n\n5. Citazioni e Bibliografia\n\nLe citazioni in Quarto si aggiungono usando il simbolo @ seguito dal riferimento BibTeX (es. @ceccarini2024age).\n\nPer gestire la bibliografia in Quarto servono:\n\nUn file .bib con le citazioni,\nUn’intestazione YAML che collega il file .bib e specifica lo stile (csl).\n\n\n\nEsempio di citazione BibTeX e collegamento in YAML:\n@article{ceccarini2024age,\n  title={Age-dependent changes in the anger superiority effect},\n  author={Ceccarini, Francesco et al.},\n  journal={Psychonomic Bulletin & Review},\n  year={2024}\n}\nYAML:\nbibliography: references.bib\nbiblio-style: apalike\n\n\n6. Considerazioni Finali\n\n\nI vantaggi di Quarto rispetto a Word includono:\n\nmaggiore riproducibilità e trasparenza,\npossibilità di integrare codice ed esecuzione in un unico documento,\nfacilità di gestione delle citazioni automatiche,\nsupporto per diversi formati di output (HTML, PDF, Word).",
    "crumbs": [
      "R",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "chapters/R/06_quarto.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/R/06_quarto.html#informazioni-sullambiente-di-sviluppo",
    "title": "11  Quarto",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.7   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.13.0 psych_2.5.3     \n#&gt;  [9] scales_1.4.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.3.0     ggplot2_3.5.2   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.4     stringi_1.8.7      lattice_0.22-7    \n#&gt;  [4] hms_1.1.3          digest_0.6.37      magrittr_2.0.3    \n#&gt;  [7] evaluate_1.0.4     grid_4.5.0         timechange_0.3.0  \n#&gt; [10] RColorBrewer_1.1-3 fastmap_1.2.0      rprojroot_2.0.4   \n#&gt; [13] jsonlite_2.0.0     mnormt_2.1.1       cli_3.6.5         \n#&gt; [16] rlang_1.1.6        withr_3.0.2        tools_4.5.0       \n#&gt; [19] parallel_4.5.0     tzdb_0.5.0         pacman_0.5.1      \n#&gt; [22] vctrs_0.6.5        R6_2.6.1           lifecycle_1.0.4   \n#&gt; [25] htmlwidgets_1.6.4  pkgconfig_2.0.3    pillar_1.10.2     \n#&gt; [28] gtable_0.3.6       glue_1.8.0         xfun_0.52         \n#&gt; [31] tidyselect_1.2.1   rstudioapi_0.17.1  farver_2.1.2      \n#&gt; [34] htmltools_0.5.8.1  nlme_3.1-168       rmarkdown_2.29    \n#&gt; [37] compiler_4.5.0",
    "crumbs": [
      "R",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "chapters/R/06_quarto.html#bibliografia",
    "href": "chapters/R/06_quarto.html#bibliografia",
    "title": "11  Quarto",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nCeccarini, F., Colpizzi, I., & Caudek, C. (2024). Age-dependent changes in the anger superiority effect: Evidence from a visual search task. Psychonomic Bulletin & Review, 1–10.\n\n\nDogucu, M. (2024). Reproducibility in the Classroom. Annual Review of Statistics and Its Application, 12.\n\n\nWickham, H., Çetinkaya-Rundel, M., & Grolemund, G. (2023). R for data science. \" O’Reilly Media, Inc.\".",
    "crumbs": [
      "R",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "chapters/R/07_environment.html",
    "href": "chapters/R/07_environment.html",
    "title": "12  L’ambiente di programmazione",
    "section": "",
    "text": "12.1 Introduzione\nProgrammare presuppone necessariamente un ambiente di programmazione. Una cattiva gestione di questo ambiente può causare il malfunzionamento degli script, rendendo fondamentale imparare a gestirlo correttamente.\nL’ambiente può influenzare persino il comportamento delle funzioni più basilari. Considera il seguente esempio:\nQuesto potrebbe produrre il seguente output:\nTuttavia, modificando l’opzione di larghezza in R, il comportamento cambia:\nIn questo caso, l’output potrebbe essere:\nLa differenza è dovuta a un’opzione dell’ambiente, width, che regola il numero massimo di caratteri visualizzati per ogni riga.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>L'ambiente di programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/07_environment.html#introduzione",
    "href": "chapters/R/07_environment.html#introduzione",
    "title": "12  L’ambiente di programmazione",
    "section": "",
    "text": "Nota: In R, il termine “ambiente” ha un significato specifico, riferendosi allo spazio di lavoro in cui gli oggetti vengono memorizzati durante una sessione. In questo capitolo, tuttavia, il termine si riferisce allo stato complessivo del tuo computer mentre programmi, inclusa l’organizzazione dei file, la versione di R che stai usando e altre impostazioni.\n\n\nprint(1:9)\n\n[1] 1 2 3 4 5 6 7 8 9\n\n# Dopo aver modificato options(width)\noptions(width = 10)\nprint(1:9)\n\n[1] 1 2 3\n[4] 4 5 6\n[7] 7 8 9",
    "crumbs": [
      "R",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>L'ambiente di programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/07_environment.html#file-system",
    "href": "chapters/R/07_environment.html#file-system",
    "title": "12  L’ambiente di programmazione",
    "section": "\n12.2 File system",
    "text": "12.2 File system\nPrima di iniziare a organizzare un progetto in R, è fondamentale seguire alcune linee guida per strutturare e nominare i file in modo efficace. Spesso si tende a sottovalutare l’importanza di una buona organizzazione, ma adottare un sistema coerente può far risparmiare tempo prezioso nella ricerca e gestione dei progetti passati. Danielle Navarro ha creato una presentazione sulla struttura dei progetti, nella quale propone tre principi fondamentali per la gestione dei file:\n\nessere gentili con le macchine;\nessere gentili con gli esseri umani;\nfacilitare l’ordinamento e la ricerca.\n\n\n12.2.1 Essere gentili con le macchine\nLe macchine possono confondersi con spazi, caratteri speciali (come ^.*?+|$\"), e lettere accentate. Per evitare problemi:\n\nusa solo lettere minuscole, numeri, trattini _ o -;\nevita caratteri speciali e spazi nei nomi dei file;\nevita le lettere accentate;\nusa estensioni coerenti, come .R per gli script R.\n\nEsempi:\n# Buono\nprogetto01_analisi_dati.R\n\n# Cattivo\nProgetto \"Analisi Dati\".R\n\n12.2.2 Essere gentili con gli umani\nGli esseri umani hanno bisogno di contesto. Evita nomi vaghi e usa descrizioni significative.\n# Buono\nanalisi01_statistiche_descrittive.R\nnote02_intro_modello.docx\n\n# Cattivo\n01.R\nappunti.docx\n\n\n\n\n\n\nEvitate categoricamente l’uso di spazi nei nomi di file, cartelle o oggetti in R. Anche se il sistema operativo potrebbe consentirlo, questa pratica può generare problemi futuri, complicare il debugging e rendere il codice meno leggibile e portabile. Per evitare questi inconvenienti, adottate sempre nomi privi di spazi, preferendo separatori come trattini bassi (_) o trattini (-).\n\n\n\n\n12.2.3 Facilitare l’ordinamento e la ricerca\nSe i nomi dei file includono date, usa sempre il formato YYYY-MM-DD per permettere un ordinamento automatico.\n# Buono\n2024-01-01_analisi.R\n2024-02-15_riassunto.docx\n\n# Cattivo\n1-gennaio-2024.R\nriassunto-15-02-2024.docx\nSe devi ordinare i file in base a qualcosa di diverso dalle date, usa numeri con lo zero iniziale per mantenere l’ordine.\nreading01_shakespeare_romeo-and-juliet.docx\nreading02_shakespeare_romeo-and-juliet.docx\n...\nreading11_shakespeare_romeo-and-juliet.docx\nnotes01_shakespeare_romeo-and-juliet.docx\n...",
    "crumbs": [
      "R",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>L'ambiente di programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/07_environment.html#versioni-di-r-e-pacchetti",
    "href": "chapters/R/07_environment.html#versioni-di-r-e-pacchetti",
    "title": "12  L’ambiente di programmazione",
    "section": "\n12.3 Versioni di R e pacchetti",
    "text": "12.3 Versioni di R e pacchetti\nAggiornare regolarmente R e i pacchetti è essenziale per evitare bug e sfruttare le nuove funzionalità. Ecco alcune buone pratiche:\n\nEsegui update.packages() ogni poche settimane per aggiornare i pacchetti.\nAggiorna la versione di R ogni pochi mesi. Su Windows puoi usare il pacchetto installr, mentre su altri sistemi puoi scaricare l’ultima versione dal sito ufficiale di R.\nMantieni aggiornato anche il sistema operativo.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>L'ambiente di programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/07_environment.html#progetti-in-r",
    "href": "chapters/R/07_environment.html#progetti-in-r",
    "title": "12  L’ambiente di programmazione",
    "section": "\n12.4 Progetti in R",
    "text": "12.4 Progetti in R\nSe hai seguito i consigli finora, avrai creato una cartella per tutti i tuoi progetti di programmazione e la tua installazione di R sarà aggiornata. Ora è il momento di organizzare i tuoi progetti in R.\n\n12.4.1 Percorsi Assoluti e Relativi\nUn percorso assoluto parte dalla directory principale del tuo computer (ad esempio, / su Linux/MacOS o C:/ su Windows) e indica in modo completo e univoco la posizione di un file o di una cartella. Un percorso relativo, invece, parte dalla directory corrente del progetto o dalla directory di lavoro impostata e descrive la posizione di un file in relazione a questa.\nAd esempio, il percorso assoluto del file utilizzato per generare questa pagina HTML potrebbe essere ottenuto così:\n\nfs::path_abs(\"05_environment.qmd\")\n#&gt; /Users/corrado/_repositories/psicometria-r/chapters/R/05_environment.qmd",
    "crumbs": [
      "R",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>L'ambiente di programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/07_environment.html#funzione-here",
    "href": "chapters/R/07_environment.html#funzione-here",
    "title": "12  L’ambiente di programmazione",
    "section": "\n12.5 Funzione here()\n",
    "text": "12.5 Funzione here()\n\nSe il progetto si trova nella cartella psicometria-r, possiamo utilizzare la funzione here() del pacchetto here per indicare la posizione del file 05_environment.qmd in modo relativo. Ecco un esempio:\n\nfile.exists(here::here(\"chapters\", \"R\", \"07_environment.qmd\"))\n#&gt; [1] TRUE\n\nIn questo caso, il file 07_environment.qmd è contenuto nella cartella chapters/R, che si trova all’interno della directory principale del progetto. Grazie a here(), non è necessario specificare manualmente la posizione del progetto: questa funzione identifica automaticamente la directory principale e consente di indicare solo il percorso relativo del file rispetto ad essa. In altre parole, puoi riferirti al file 07_environment.qmd semplicemente fornendo il percorso relativo all’interno della struttura del progetto, lasciando a here() il compito di gestire il contesto globale.\n\n12.5.1 Perché preferire i percorsi relativi?\nL’utilizzo di percorsi relativi con here() offre numerosi vantaggi:\n\n\nPortabilità: Il codice diventa più semplice da condividere, poiché non dipende dalla struttura delle directory specifica del computer su cui è stato scritto.\n\nOrganizzazione: Favorisce una struttura chiara e coerente all’interno del progetto, rendendo più facile individuare e accedere ai file.\n\nAffidabilità: Riduce il rischio di errori dovuti a percorsi assoluti errati, soprattutto quando il progetto viene spostato o condiviso.\n\n12.5.2 Buone pratiche\n\n\nUsare sempre percorsi relativi: Questo assicura che il progetto sia facilmente eseguibile su altri sistemi senza necessità di modifiche ai percorsi.\n\nImpostare una struttura coerente del progetto: Organizzare i file in cartelle ben definite (ad esempio, data, scripts, outputs) facilita l’uso di percorsi relativi.\n\nIn sintesi, specificare i percorsi relativi rispetto alla directory principale del progetto è una buona pratica essenziale per garantire portabilità, organizzazione e riproducibilità del lavoro.\n\n12.5.3 Creare un progetto in R\nUn progetto R è semplicemente una cartella con un file .Rproj. Puoi crearne uno con RStudio o con il pacchetto usethis.\nIn RStudio:\n\nVai su File &gt; New Project.\nSeleziona New Directory &gt; New Project.\nDai un nome al progetto e scegli la sua posizione.\n\nCon usethis:\nusethis::create_project(\"path/alla/cartella\")\nEsempio:\nusethis::create_project(\"/Users/corrado/_repositories/psicometria-r\")\nVedremo nel Capitolo 14 come organizzare i file all’interno di un progetto.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>L'ambiente di programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/07_environment.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/R/07_environment.html#informazioni-sullambiente-di-sviluppo",
    "title": "12  L’ambiente di programmazione",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.7   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.13.0 psych_2.5.3     \n#&gt;  [9] scales_1.4.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.3.0     ggplot2_3.5.2   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.4     stringi_1.8.7      lattice_0.22-7    \n#&gt;  [4] hms_1.1.3          digest_0.6.37      magrittr_2.0.3    \n#&gt;  [7] evaluate_1.0.4     grid_4.5.0         timechange_0.3.0  \n#&gt; [10] RColorBrewer_1.1-3 fastmap_1.2.0      rprojroot_2.0.4   \n#&gt; [13] jsonlite_2.0.0     mnormt_2.1.1       cli_3.6.5         \n#&gt; [16] crayon_1.5.3       rlang_1.1.6        withr_3.0.2       \n#&gt; [19] tools_4.5.0        parallel_4.5.0     tzdb_0.5.0        \n#&gt; [22] pacman_0.5.1       vctrs_0.6.5        R6_2.6.1          \n#&gt; [25] lifecycle_1.0.4    fs_1.6.6           htmlwidgets_1.6.4 \n#&gt; [28] pkgconfig_2.0.3    pillar_1.10.2      gtable_0.3.6      \n#&gt; [31] glue_1.8.0         xfun_0.52          tidyselect_1.2.1  \n#&gt; [34] rstudioapi_0.17.1  farver_2.1.2       htmltools_0.5.8.1 \n#&gt; [37] nlme_3.1-168       rmarkdown_2.29     compiler_4.5.0",
    "crumbs": [
      "R",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>L'ambiente di programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/07_environment.html#bibliografia",
    "href": "chapters/R/07_environment.html#bibliografia",
    "title": "12  L’ambiente di programmazione",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nYu, B., & Barter, R. L. (2024). Veridical data science: The practice of responsible data analysis and decision making. MIT Press.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>L'ambiente di programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/08_ai.html",
    "href": "chapters/R/08_ai.html",
    "title": "13  Utilizzo di strumenti AI",
    "section": "",
    "text": "13.1 Introduzione\nIl panorama della programmazione sta attraversando una trasformazione radicale, guidata dall’avvento degli strumenti di intelligenza artificiale (AI). Questi assistenti innovativi stanno rivoluzionando il modo in cui sviluppatori, ricercatori e studenti scrivono, comprendono e ottimizzano il codice. Grazie a una nuova generazione di strumenti che vanno oltre i tradizionali ambienti di sviluppo, l’intelligenza artificiale sta aprendo possibilità inedite. Piattaforme come ChatGPT, Google Gemini, Claude.ai, DeepSeek e Qwen sono in grado di generare codice, spiegare concetti complessi e fornire supporto agli sviluppatori in modi che, fino a poco tempo fa, erano impensabili.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Utilizzo di strumenti AI</span>"
    ]
  },
  {
    "objectID": "chapters/R/08_ai.html#potenzialità-e-sfide-dellai-nella-programmazione",
    "href": "chapters/R/08_ai.html#potenzialità-e-sfide-dellai-nella-programmazione",
    "title": "13  Utilizzo di strumenti AI",
    "section": "13.2 Potenzialità e Sfide dell’AI nella Programmazione",
    "text": "13.2 Potenzialità e Sfide dell’AI nella Programmazione\nGli strumenti di intelligenza artificiale (AI) stanno trasformando radicalmente il modo in cui si programma, inclusa l’elaborazione di codice in linguaggi come R. Tuttavia, accanto alle immense potenzialità, emergono anche sfide significative. I modelli di linguaggio di grandi dimensioni (LLM, Large Language Models) possono ottimizzare e accelerare i flussi di lavoro, ma non sono privi di limitazioni. Tra queste, la possibilità di generare codice impreciso, introdurre bias involontari o produrre output che richiedono una verifica approfondita da parte dell’utente.\nNonostante queste sfide, gli strumenti di AI offrono un supporto prezioso in diverse aree chiave:\n\nSupporto Concettuale:\nGli LLM si dimostrano particolarmente efficaci nel rispondere a domande complesse su metodi statistici, algoritmi e tecniche di analisi dei dati. La qualità delle risposte migliora notevolmente quando le domande sono formulate in modo chiaro, specifico e dettagliato.\nGenerazione e Completamento del Codice:\nQuesti strumenti possono aiutare gli sviluppatori a scrivere codice più rapidamente, suggerendo completamenti automatici, identificando potenziali errori e persino generando interi script a partire da descrizioni testuali. Questo riduce il tempo dedicato alla scrittura manuale e permette di concentrarsi su aspetti più creativi o complessi del progetto.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Utilizzo di strumenti AI</span>"
    ]
  },
  {
    "objectID": "chapters/R/08_ai.html#panoramica-comparativa-dei-principali-strumenti-ai",
    "href": "chapters/R/08_ai.html#panoramica-comparativa-dei-principali-strumenti-ai",
    "title": "13  Utilizzo di strumenti AI",
    "section": "13.3 Panoramica Comparativa dei Principali Strumenti AI",
    "text": "13.3 Panoramica Comparativa dei Principali Strumenti AI\nCome scegliere il modello linguistico più adatto per un determinato compito? Nell’articolo di Gibney (2025), ricercatori condividono i loro strumenti preferiti attualmente in uso, offrendo una guida pratica a chi ha bisogno di orientarsi tra le varie opzioni.\n\n13.3.1 o3-mini (il ragionatore)\nOpenAI ha lanciato o3-mini, un modello di ragionamento gratuito per gli utenti registrati, sviluppato in risposta alla crescente concorrenza di DeepSeek. Questo modello si distingue per l’utilizzo di un processo di ragionamento a catena (chain-of-thought reasoning), che gli permette di affrontare problemi complessi in ambito matematico e scientifico con precisione. Oltre a eccellere nell’analisi tecnica e nella riformattazione dei dati, o3-mini è particolarmente efficace nel scomporre concetti intricati in passaggi più semplici. Tuttavia, nonostante le sue capacità avanzate, non è ancora in grado di eguagliare il ragionamento umano in contesti che richiedono creatività o intuizione profonda.\n\n\n13.3.2 DeepSeek (il tuttofare)\nDeepSeek-R1 è un modello open-weight paragonabile a o1 di OpenAI, ma disponibile a un costo inferiore attraverso API. La sua natura trasparente lo rende particolarmente attraente per i ricercatori, che possono adattarlo ai propri progetti specifici. DeepSeek è utile per generare ipotesi, migliorare la diagnostica medica e supportare attività di ricerca avanzate. Tuttavia, presenta alcuni limiti: il suo processo di ragionamento è più lento rispetto ad altri modelli e offre meno filtri contro output potenzialmente dannosi. Inoltre, OpenAI ha sollevato dubbi sulla legittimità del suo processo di addestramento, alimentando un dibattito sulla trasparenza e l’etica degli LLM.\n\n\n13.3.3 Llama (il cavallo di battaglia)\nSviluppato da Meta, Llama è uno dei modelli LLM più utilizzati nella ricerca grazie alla sua natura open-weight, che consente agli scienziati di personalizzarlo e impiegarlo in ambienti controllati. È stato applicato con successo in una vasta gamma di ambiti, dalla predizione delle strutture cristalline ai calcoli quantistici, dimostrando una grande versatilità. Tuttavia, l’accesso a Llama richiede un’autorizzazione specifica, rendendolo meno immediato rispetto ad altri modelli open-source emergenti che sono disponibili senza restrizioni.\n\n\n13.3.4 Claude (lo sviluppatore)\nClaude 3.5 Sonnet, prodotto da Anthropic, è particolarmente apprezzato per la sua capacità di scrivere codice e interpretare dati visivi. Questo modello si distingue per la sua abilità nel mantenere il significato tecnico anche durante la semplificazione del linguaggio, rendendolo ideale per redigere proposte di ricerca, annotare codice e supportare attività di sviluppo software. Tuttavia, l’accesso completo alle sue funzionalità richiede un’API a pagamento, il che lo rende meno competitivo rispetto ai modelli open-source in rapida crescita, soprattutto per utenti con budget limitati.\n\n\n13.3.5 OLMo (il veramente open)\nOLMo 2 rappresenta un passo avanti nella trasparenza degli LLM. Questo modello non solo fornisce i pesi del modello, ma anche i dati di addestramento e il codice di sviluppo, offrendo una visione completa del suo funzionamento. Questa apertura lo rende ideale per ricercatori e sviluppatori che desiderano analizzare bias, ottimizzare le prestazioni o comprendere a fondo il processo di creazione di un LLM. L’unico svantaggio è che richiede competenze tecniche avanzate per l’implementazione, sebbene il numero di risorse educative e tutorial disponibili stia crescendo rapidamente.\nOgni modello presenta punti di forza e limiti specifici, rendendoli adatti a contesti diversi. Mentre o3-mini e DeepSeek si concentrano su ragionamento e analisi tecnica, Llama e OLMo offrono maggiore flessibilità e trasparenza per la ricerca. Claude, d’altra parte, si distingue per le sue capacità di sviluppo e interpretazione di dati complessi. La scelta del modello dipende dalle esigenze specifiche dell’utente, dal budget disponibile e dalle competenze tecniche.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Utilizzo di strumenti AI</span>"
    ]
  },
  {
    "objectID": "chapters/R/08_ai.html#considerazioni-etiche-e-pratiche",
    "href": "chapters/R/08_ai.html#considerazioni-etiche-e-pratiche",
    "title": "13  Utilizzo di strumenti AI",
    "section": "13.4 Considerazioni Etiche e Pratiche",
    "text": "13.4 Considerazioni Etiche e Pratiche\nL’adozione di strumenti di intelligenza artificiale (AI) solleva questioni etiche e pratiche che richiedono un’attenta riflessione e un approccio responsabile.\n\nTrasparenza\nI dataset utilizzati per addestrare i modelli di AI sono spesso poco documentati e opachi, rendendo difficile valutarne la qualità e l’equità. Questo solleva interrogativi sulla presenza di bias involontari e sulla rappresentatività dei dati, con notevoli implicazioni per l’affidabilità dei risultati.\nEquità di Accesso\nNonostante le potenzialità rivoluzionarie degli strumenti di AI, l’accesso a queste tecnologie non è uniformemente distribuito. Disparità economiche, geografiche e infrastrutturali possono creare disuguaglianze, limitando l’adozione di queste risorse in contesti meno privilegiati e ampliando il divario digitale.\nResponsabilità\nUno dei dilemmi più complessi riguarda l’attribuzione della responsabilità per i risultati generati dai sistemi di AI. In caso di errori, bias o conseguenze indesiderate, non è sempre chiaro chi debba assumersi la responsabilità: gli sviluppatori del modello, gli utenti o le organizzazioni che lo implementano.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Utilizzo di strumenti AI</span>"
    ]
  },
  {
    "objectID": "chapters/R/08_ai.html#riflessioni-conclusive",
    "href": "chapters/R/08_ai.html#riflessioni-conclusive",
    "title": "13  Utilizzo di strumenti AI",
    "section": "13.5 Riflessioni Conclusive",
    "text": "13.5 Riflessioni Conclusive\nGli strumenti di intelligenza artificiale stanno rivoluzionando il mondo della programmazione, offrendo un supporto senza precedenti per la risoluzione di problemi complessi, la generazione di codice e l’ottimizzazione dei flussi di lavoro. Tuttavia, il loro utilizzo deve essere accompagnato da un approccio critico e consapevole. È essenziale verificare i risultati, valutare le implicazioni etiche e garantire che l’adozione di queste tecnologie avvenga in modo equo e responsabile.\nL’intelligenza artificiale non sostituirà gli sviluppatori, ma si affermerà come un alleato indispensabile, ampliando la creatività e le competenze umane. Questa collaborazione tra uomo e macchina ridefinirà il modo in cui affrontiamo le sfide del futuro, aprendo nuove opportunità e trasformando il panorama della tecnologia e della ricerca (Bonnefon et al., 2024; Liu & Li, 2024).",
    "crumbs": [
      "R",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Utilizzo di strumenti AI</span>"
    ]
  },
  {
    "objectID": "chapters/R/08_ai.html#bibliografia",
    "href": "chapters/R/08_ai.html#bibliografia",
    "title": "13  Utilizzo di strumenti AI",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBonnefon, J.-F., Rahwan, I., & Shariff, A. (2024). The moral psychology of Artificial Intelligence. Annual Review of Psychology, 75(1), 653–675.\n\n\nGibney, E. (2025). What are the best AI tools for research? Nature’s guide. Nature, 578(7795), 123–125. https://doi.org/10.1038/d41586-025-00437-0\n\n\nLiu, J., & Li, S. (2024). Toward Artificial Intelligence-Human Paired Programming: A Review of the Educational Applications and Research on Artificial Intelligence Code-Generation Tools. Journal of Educational Computing Research, 07356331241240460.\n\n\nMeskó, B. (2023). Prompt engineering as an important emerging skill for medical professionals: tutorial. Journal of Medical Internet Research, 25, e50638.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Utilizzo di strumenti AI</span>"
    ]
  },
  {
    "objectID": "chapters/eda/introduction_eda.html",
    "href": "chapters/eda/introduction_eda.html",
    "title": "EDA",
    "section": "",
    "text": "Il Ruolo Fondamentale dell’EDA\nL’analisi esplorativa dei dati (Exploratory Data Analysis, EDA) è un processo attivo di scoperta, un dialogo critico con i dati volto a rivelare ciò che è inatteso. Più che un insieme di tecniche, è un approccio mentale: un modo per mettere alla prova il proprio modello mentale attraverso il confronto sistematico tra aspettative e realtà. Prima di procedere con qualsiasi tipo di visualizzazione, è utile esplicitare le proprie aspettative, per poi verificare se i dati confermano, contraddicono o complicano tali ipotesi preliminari. In questo senso, l’EDA è una forma di model checking intuitivo, in cui l’intuizione viene continuamente affinata dall’evidenza empirica.\nUna volta raccolti i dati, il primo passo dell’analisi statistica consiste nel familiarizzare con essi: esplorarne la struttura, identificarne le regolarità e le anomalie e coglierne le dinamiche sottostanti. Questo processo, formalizzato da John Tukey negli anni ’70 (Tukey et al., 1977), rappresenta un antidoto alla rigidità dei modelli preconcetti. Tukey insisteva sull’importanza di “lasciar parlare i dati” prima di incasellarli in schemi teorici, perché è proprio nell’esplorazione che emergono pattern inattesi, relazioni non lineari o errori sistematici altrimenti invisibili.\nL’EDA non è in contrapposizione all’analisi confermativa (CDA), ma ne rappresenta il naturale complemento. Mentre l’analisi confermativa (CDA) testa ipotesi precise con metodi formali (ad esempio, test di ipotesi o modelli bayesiani), l’analisi esplorativa (EDA) genera tali ipotesi, verificando preliminarmente la plausibilità delle assunzioni di base. In campi come la psicologia, dove i dati sono spesso rumorosi e multidimensionali, questa fase è cruciale per evitare conclusioni fuorvianti.",
    "crumbs": [
      "EDA"
    ]
  },
  {
    "objectID": "chapters/eda/introduction_eda.html#strumenti-e-filosofia",
    "href": "chapters/eda/introduction_eda.html#strumenti-e-filosofia",
    "title": "EDA",
    "section": "Strumenti e Filosofia",
    "text": "Strumenti e Filosofia\nSebbene l’EDA includa strumenti quantitativi (statistiche descrittive, misure di dispersione), la sua essenza si esprime appieno nella visualizzazione. Un grafico ben progettato, che si tratti di un boxplot, di uno scatterplot o di un semplice istogramma, può rivelare asimmetrie, outlier o cluster che una tabella numerica non riuscirebbe a mostrare. Tuttavia, come sottolineato da Hullman & Gelman (2021), la vera forza dell’EDA non risiede nella produzione di immagini, ma nel collegare ciò che si osserva a un modello mentale del processo di generazione dei dati. Visualizzare non significa solo “vedere”, ma anche “confrontare”: ci si chiede se la distribuzione di una variabile corrisponda alle aspettative o se una correlazione apparente resista a un’analisi critica.\nIn questa prospettiva, anche il Posterior Predictive Checking (Gelman et al., 2013) può essere considerato una forma di EDA, in cui l’adeguatezza di un modello viene verificata attraverso confronti grafici tra dati osservati e simulati. Anche senza un modello formale, l’analista compie un esercizio simile, valutando implicitamente la coerenza tra i dati e le proprie aspettative.",
    "crumbs": [
      "EDA"
    ]
  },
  {
    "objectID": "chapters/eda/introduction_eda.html#obiettivi-di-questa-sezione",
    "href": "chapters/eda/introduction_eda.html#obiettivi-di-questa-sezione",
    "title": "EDA",
    "section": "Obiettivi di questa sezione",
    "text": "Obiettivi di questa sezione\nIn questa sezione, ci proponiamo di:\n\nIntrodurre i concetti base della statistica descrittiva (media, deviazione standard, correlazione) e le loro rappresentazioni grafiche (istogrammi, grafici a violino, matrici di scatterplot).\nMostrare applicazioni pratiche in R, utilizzando dataset psicologici reali o simulati, con un focus su come tradurre domande di ricerca in visualizzazioni efficaci.\nDiscutere i limiti dell’approccio puramente descrittivo, enfatizzando la necessità di integrare l’EDA con modelli teorici o causalità.\nCollegare esplorazione e inferenza, illustrando come l’EDA possa evolvere in un controllo modellistico esplicito, specie in contesti bayesiani dove le aspettative precedenti (prior) giocano un ruolo chiave.",
    "crumbs": [
      "EDA"
    ]
  },
  {
    "objectID": "chapters/eda/introduction_eda.html#leda-come-atteggiamento-scientifico",
    "href": "chapters/eda/introduction_eda.html#leda-come-atteggiamento-scientifico",
    "title": "EDA",
    "section": "L’EDA come atteggiamento scientifico",
    "text": "L’EDA come atteggiamento scientifico\nIn conclusione, l’EDA non è un semplice preludio tecnico all’analisi “seria”, ma una componente essenziale del pensiero statistico. Ci spinge a formulare domande migliori, a interpretare le risposte con umiltà e a resistere alla tentazione di cercare conferme facili. Come scrisse Tukey: “È meglio rispondere in modo approssimativo a una domanda giusta, piuttosto che rispondere in modo esatto a una domanda sbagliata”.",
    "crumbs": [
      "EDA"
    ]
  },
  {
    "objectID": "chapters/eda/introduction_eda.html#bibliografia",
    "href": "chapters/eda/introduction_eda.html#bibliografia",
    "title": "EDA",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., & Rubin, D. B. (2013). Bayesian Data Analysis (3rd ed.). Chapman; Hall/CRC.\n\n\nHullman, J., & Gelman, A. (2021). Challenges in Incorporating Exploratory Data Analysis Into Statistical Workflow. Harvard Data Science Review, 3(3).\n\n\nTukey, J. W. et al. (1977). Exploratory data analysis (Vol. 2). Springer.",
    "crumbs": [
      "EDA"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html",
    "href": "chapters/eda/01_project_structure.html",
    "title": "14  Le fasi del progetto di analisi dei dati",
    "section": "",
    "text": "14.1 Introduzione\nAffinché un dataset possa effettivamente sostenere un’analisi rigorosa, è indispensabile che esso sia strutturato in modo chiaro, privo di ambiguità, e accompagnato da una documentazione precisa delle operazioni effettuate. Questo vale non solo per la fase iniziale di raccolta dei dati, ma anche per tutte le successive trasformazioni — pulizia, codifica, fusione di fonti diverse — che spesso accompagnano il lavoro empirico. In assenza di tracciabilità, anche un’analisi tecnicamente corretta può risultare opaca o difficilmente replicabile.\nProprio la riproducibilità rappresenta oggi uno degli standard più elevati della buona ricerca scientifica. Disporre di dati ben documentati significa permettere ad altri studiosi — o a sé stessi in un secondo momento — di ricostruire il percorso analitico seguito, verificarne la solidità, e, se necessario, estenderlo o correggerlo. In questo senso, la qualità dei dati e la qualità dell’analisi non sono separabili.\nLa complessità crescente dei dati psicologici, spesso raccolti con strumenti digitali, in formato longitudinale o provenienti da più fonti, rende ancora più urgente adottare pratiche di gestione strutturate e coerenti. Un dataset non è mai un oggetto neutro: riflette scelte teoriche, operative, e tecniche. Riuscire a mantenere queste scelte visibili e accessibili nel tempo è ciò che permette di trasformare l’analisi dei dati in un processo scientificamente trasparente.\nIn questo capitolo, ci concentreremo su come impostare un progetto di analisi dei dati in modo da favorire fin dall’inizio chiarezza, rigore e tracciabilità. L’obiettivo non è solo tecnico, ma epistemologico: una buona gestione dei dati non serve solo a “fare funzionare il codice”, ma a costruire una relazione affidabile tra osservazione empirica e inferenza scientifica.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#introduzione",
    "href": "chapters/eda/01_project_structure.html#introduzione",
    "title": "14  Le fasi del progetto di analisi dei dati",
    "section": "",
    "text": "Nel contesto della ricerca psicologica, dove i dati rappresentano il tramite principale tra ipotesi teoriche e risultati empirici, la cura nella gestione delle informazioni raccolte è parte integrante del processo scientifico. Una gestione accurata dei dati non è solo una questione organizzativa: è una condizione necessaria per garantire l’affidabilità delle analisi e la credibilità delle conclusioni che ne derivano.\n\n\n\n\n\n\n\n\n\n\n\nDomande Iniziali\n\n\n\n\n\nPrima di immergerti nella lettura di questo capitolo, prenditi un momento per riflettere sulle seguenti domande. Quali risposte daresti prima di leggere il materiale?\n\nPerché è importante organizzare e documentare accuratamente i dati in un progetto di ricerca?\nQuali problemi possono emergere se si inizia a scrivere codice senza una pianificazione adeguata?\nQuali vantaggi offre R per la gestione dei dati rispetto ad altri strumenti?\nQuali strategie potrebbero migliorare la riproducibilità del tuo lavoro?\nCome struttureresti un progetto di analisi dati per mantenerlo chiaro e facilmente replicabile?\n\nOra, mentre leggi il capitolo, confronta le tue risposte con i concetti discussi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#pianificazione-del-flusso-di-lavoro-in-r-strategie-per-progetti-sostenibili",
    "href": "chapters/eda/01_project_structure.html#pianificazione-del-flusso-di-lavoro-in-r-strategie-per-progetti-sostenibili",
    "title": "14  Le fasi del progetto di analisi dei dati",
    "section": "\n14.2 Pianificazione del flusso di lavoro in R: strategie per progetti sostenibili",
    "text": "14.2 Pianificazione del flusso di lavoro in R: strategie per progetti sostenibili\n\n14.2.1 L’importanza della pianificazione iniziale\nAffrontare un progetto di analisi dei dati senza una pianificazione accurata è come condurre un esperimento psicologico senza un’ipotesi chiara: si rischia di procedere in modo confuso, accumulando errori, ripensamenti e soluzioni improvvisate che rendono il lavoro inefficiente e difficile da mantenere nel tempo. Contrariamente a quanto si possa pensare, scrivere codice rappresenta solo una parte marginale del lavoro analitico. Gran parte dello sforzo risiede infatti nella definizione degli obiettivi, nella scelta degli strumenti più adatti, nella costruzione di un percorso analitico coerente e nella prevenzione dei cosiddetti “debiti tecnici”, ovvero quelle scorciatoie momentanee che poi si rivelano difficili da correggere.\nUn approccio poco strutturato può portare, ad esempio, a importare i dati in modo disordinato, a mischiare versioni intermedie con file originali o a trascurare la documentazione delle trasformazioni applicate. In queste condizioni, anche un’ottima analisi rischia di diventare fragile e poco trasparente, rendendo difficile, se non impossibile, la replicazione dei risultati.\n\n14.2.2 Costruire un flusso di lavoro efficace\nUn progetto ben impostato parte da una fase iniziale di progettazione concettuale in cui si chiariscono le domande di ricerca, si identificano le variabili chiave e si ipotizzano i passaggi fondamentali dell’analisi. Anche uno schema semplice, disegnato su carta, può aiutare a visualizzare il flusso di lavoro: dalla pulizia dei dati all’inferenza statistica, fino alla comunicazione dei risultati. Questo tipo di rappresentazione, per quanto preliminare, fornisce un riferimento utile per evitare deviazioni inutili e mantenere la coerenza tra le fasi successive.\nParallelamente, è utile suddividere il lavoro in unità gestibili e definite, stimando in modo realistico il tempo necessario per ciascuna fase e specificando gli obiettivi in termini concreti. Ad esempio, invece di pianificare genericamente “l’analisi preliminare”, può essere più efficace definire l’obiettivo come “esplorare la distribuzione dei punteggi tra il gruppo sperimentale e quello di controllo, producendo un grafico interpretabile e documentato”. Questo tipo di specificità aiuta a monitorare i progressi e a distribuire i compiti in progetti collaborativi.\nAnche la scelta degli strumenti richiede attenzione: investire tempo all’inizio per selezionare i pacchetti R più adatti alle proprie esigenze, come “janitor” per la pulizia dei dati o “report” per la generazione automatica di output in stile APA, permette di evitare soluzioni artigianali poco sostenibili. Ma è la pratica quotidiana della documentazione a fare la differenza: annotare le motivazioni delle scelte nel codice, descrivere le trasformazioni effettuate e integrare il tutto in un documento Quarto che unisce testo, codice ed evidenza empirica rappresenta un potente alleato della trasparenza scientifica.\nInfine, un aspetto centrale ma spesso trascurato è la riproducibilità: organizzare il progetto secondo una struttura chiara, con cartelle distinte per dati, script, output e report, rende più semplice orientarsi nel tempo, collaborare con altri e condividere il lavoro in modo robusto. In quest’ottica, anche i dettagli apparentemente minori, come l’uso di nomi descrittivi per le variabili o la coerenza nell’indentazione, contribuiscono alla leggibilità e alla qualità complessiva del progetto.\n\n14.2.3 Prevenire e gestire il debito tecnico\nMan mano che il progetto cresce, diventa inevitabile confrontarsi con i problemi di manutenzione del codice. È importante, quindi, ritagliarsi del tempo, anche durante lo sviluppo, per semplificare le strutture ridondanti, riorganizzare gli script troppo lunghi e trasformare i blocchi ripetitivi in funzioni riutilizzabili. Un codice ben scritto non solo riduce il rischio di errori, ma facilita anche la collaborazione tra i membri del team e la futura espansione del progetto.\nUn’altra abitudine preziosa è mantenere la coerenza tra codice e commenti: ogni modifica significativa dovrebbe essere accompagnata da un aggiornamento delle annotazioni per evitare che il codice racconti una storia diversa da quella riportata nei commenti. Prima di condividere il progetto, è utile predisporre una verifica finale: controllare che i dati originali siano conservati separatamente, che l’ambiente di lavoro sia documentato (ad esempio, salvando l’output di sessionInfo()), e che ogni script sia leggibile e corredato delle spiegazioni necessarie.\nIn definitiva, pianificare un flusso di lavoro in R non significa complicare il lavoro, ma creare le condizioni per un’analisi più efficace, chiara e duratura. L’organizzazione del progetto, la cura nella scrittura del codice e l’adozione di buone pratiche tecniche non sono elementi opzionali, ma il fondamento di un approccio scientifico che mira a comprendere e non solo a calcolare.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#capacità-di-gestione-dei-dati-in-r",
    "href": "chapters/eda/01_project_structure.html#capacità-di-gestione-dei-dati-in-r",
    "title": "14  Le fasi del progetto di analisi dei dati",
    "section": "\n14.3 Capacità di gestione dei dati in R",
    "text": "14.3 Capacità di gestione dei dati in R\nDopo aver compreso l’importanza di una pianificazione strategica, il passo successivo è dotarsi di strumenti affidabili per gestire, analizzare e documentare i dati in modo efficace. In questo contesto, R si rivela uno strumento prezioso. Si tratta di un ambiente di programmazione concepito per accompagnare l’intero ciclo di vita dei dati: dalla loro importazione alla loro trasformazione, dall’analisi statistica alla produzione di report riproducibili. La sua versatilità lo rende uno strumento centrale in qualsiasi flusso di lavoro orientato alla qualità e alla trasparenza, in particolare nel settore psicologico, dove la complessità dei dataset richiede flessibilità e rigore metodologico.\nR consente, innanzitutto, di importare ed esportare dati in molti formati, grazie a pacchetti come readr e rio, che semplificano l’interazione con file CSV, database o persino fonti web. Una volta acquisiti, i dati possono essere rapidamente puliti e trasformati con strumenti come dplyr, tidyr e stringr, che offrono un linguaggio espressivo e intuitivo per filtrare osservazioni, ristrutturare tabelle, modificare valori testuali e preparare i dati per l’analisi. La fase esplorativa può quindi contare su strumenti come ggplot2 per la visualizzazione e il riconoscimento di pattern nei dati e per la sintesi di indicatori descrittivi in modo elegante e conciso.\nMa la vera forza di R emerge quando si tratta di documentare il processo analitico. Grazie a R Markdown e Quarto, è possibile integrare in un unico documento codice, testo esplicativo, tabelle e grafici, creando report dinamici che illustrano l’intero processo analitico e ne consentono la riproduzione semplice da parte di altri (o di sé stessi a distanza di tempo). A ciò si aggiunge la possibilità di utilizzare sistemi di controllo di versione come Git, direttamente integrati in RStudio, che consentono di tracciare le modifiche al codice, collaborare in modo strutturato e garantire la trasparenza del processo di analisi.\nL’integrazione tra strategia progettuale e strumenti tecnici rende R una piattaforma particolarmente adatta a chi desidera lavorare in modo affidabile, efficiente e metodologicamente solido. In progetti che coinvolgono dati complessi, questa combinazione rappresenta una garanzia per la qualità e la sostenibilità delle analisi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#configurare-lambiente-r",
    "href": "chapters/eda/01_project_structure.html#configurare-lambiente-r",
    "title": "14  Le fasi del progetto di analisi dei dati",
    "section": "\n14.4 Configurare l’ambiente R",
    "text": "14.4 Configurare l’ambiente R\nPer trarre il massimo vantaggio dall’uso di R, è fondamentale configurare correttamente l’ambiente di lavoro. RStudio, in particolare, offre un’interfaccia potente ma personalizzabile che consente di controllare con precisione il comportamento delle sessioni di lavoro. Un primo passo consiste nel disattivare il salvataggio automatico dell’ambiente: accedendo alle impostazioni generali (Tools &gt; Global Options &gt; General), è consigliabile deselezionare l’opzione di caricamento automatico del file .RData all’avvio e impostare la voce relativa al salvataggio del workspace su Never. Questo accorgimento incoraggia l’uso sistematico degli script come unico riferimento per l’analisi, evitando che i residui delle sessioni precedenti possano influenzare i risultati in modo incontrollato. In altre parole, si favorisce una gestione del lavoro basata su un codice esplicito e documentato piuttosto che su ambienti temporanei e invisibili.\nUn ambiente ben configurato deve includere anche i pacchetti essenziali per un’analisi efficace. Tra questi, tidyverse rappresenta un vero e proprio ecosistema integrato per la manipolazione, la visualizzazione e l’analisi dei dati: include strumenti come dplyr, ggplot2, readr e altri ancora, tutti progettati secondo una filosofia coerente e orientata alla leggibilità del codice. Il pacchetto here, invece, semplifica la gestione dei percorsi relativi, consentendo di scrivere script portabili che funzionano correttamente indipendentemente dal sistema operativo o dalla struttura dei file locali.\nPer assicurarsi che questi strumenti siano disponibili, è sufficiente installarli (una sola volta) con la funzione install.packages(), e poi caricarli all’inizio di ogni script. Un esempio di setup iniziale potrebbe essere il seguente:\n# install.packages(c(\"here\", \"tidyverse\"))  # solo la prima volta\nlibrary(here)\nlibrary(tidyverse)\nAdottare fin da subito queste buone pratiche di configurazione non solo aiuta a evitare errori, ma anche a creare un ambiente di lavoro solido, coerente e adatto alla produzione di analisi ripetibili e condivisibili. È in questa direzione che si sviluppa il metodo scientifico nell’era dei dati: attraverso strumenti in grado di coniugare potenza tecnica e trasparenza metodologica.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#gestione-dei-progetti",
    "href": "chapters/eda/01_project_structure.html#gestione-dei-progetti",
    "title": "14  Le fasi del progetto di analisi dei dati",
    "section": "\n14.5 Gestione dei Progetti",
    "text": "14.5 Gestione dei Progetti\nIn RStudio, l’utilizzo dei progetti è una pratica essenziale per mantenere l’ordine e la coerenza nel proprio lavoro. Ogni progetto crea un ambiente isolato e dedicato in cui tutti i file (dati, script, output e documentazione) sono raccolti all’interno di una singola directory. Questo approccio riduce notevolmente il rischio di confusione tra i file appartenenti a progetti diversi e favorisce una gestione più chiara dei percorsi relativi. Per creare un nuovo progetto, è sufficiente selezionare “File &gt; New Project”, scegliere la directory desiderata e salvare al suo interno tutti i file pertinenti.\nLavorare all’interno di un progetto non è solo una questione di ordine, ma anche una strategia per rafforzare la riproducibilità e l’efficienza del processo analitico. Ogni progetto diventa un’unità autosufficiente e replicabile, facilitando anche la collaborazione con altri ricercatori.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#il-ciclo-di-vita-di-un-progetto-di-data-science",
    "href": "chapters/eda/01_project_structure.html#il-ciclo-di-vita-di-un-progetto-di-data-science",
    "title": "14  Le fasi del progetto di analisi dei dati",
    "section": "\n14.6 Il Ciclo di Vita di un Progetto di Data Science",
    "text": "14.6 Il Ciclo di Vita di un Progetto di Data Science\nUna volta predisposto un ambiente di lavoro stabile e ben strutturato, è possibile affrontare con metodo le diverse fasi di un progetto di Data Science. Secondo la proposta di Yu & Barter (2024), un progetto ben condotto segue un ciclo di vita articolato in cinque fasi fondamentali: la formulazione della domanda di ricerca, la preparazione e l’analisi esplorativa dei dati, l’eventuale modellazione inferenziale o predittiva, la valutazione dei risultati e, infine, la comunicazione degli esiti.\nNon tutti i progetti prevedono una fase di modellazione vera e propria, ma tutti traggono vantaggio da un approccio ordinato che attraversi in modo coerente ciascuna di queste fasi. Questo approccio non solo migliora la qualità delle analisi, ma riduce anche il rischio di errori e ambiguità interpretative.\n\n14.6.1 Formulazione del Problema e Raccolta dei Dati\nLa prima fase consiste nella definizione chiara degli obiettivi del progetto. In ambito applicativo, ciò può tradursi nella necessità di redigere un report su un intervento specifico senza particolari ambizioni teoriche. In ambito accademico, invece, è fondamentale che le domande di ricerca siano ancorate alla letteratura e che le scelte metodologiche siano coerenti con le teorie di riferimento. In entrambi i casi, è essenziale che le domande siano precise e che si possano realisticamente affrontare con i dati disponibili.\nLa raccolta dei dati può avvenire attingendo a fonti già esistenti, come dataset pubblici o archivi di laboratorio, oppure tramite nuove rilevazioni. Qualunque sia la loro origine, è importante pianificare con attenzione le analisi prima di acquisire i dati, in modo da evitare la raccolta di informazioni superflue o, peggio, inadeguate rispetto agli obiettivi. È inoltre indispensabile documentare le modalità di raccolta e dichiarare eventuali limitazioni.\n\n14.6.2 Pulizia, Preprocessing e Analisi Esplorativa\nUna volta acquisiti i dati, è necessario importarli in R in un formato analizzabile, solitamente sotto forma di data frame. Il pacchetto rio semplifica questa operazione, mentre here facilita la gestione dei percorsi relativi, rendendo i progetti più portabili e riproducibili. I dati grezzi dovrebbero essere conservati separatamente rispetto a quelli puliti, idealmente in cartelle distinte all’interno del progetto.\nLa fase di pulizia è cruciale: bisogna individuare e correggere gli errori, gestire i valori mancanti o anomali, rimuovere i duplicati e uniformare le formattazioni. I file originali non devono mai essere modificati direttamente, ma tutte le trasformazioni devono essere effettuate tramite script per garantire la tracciabilità.\nIl preprocessing consiste nell’adattare i dati alle esigenze delle analisi successive. Alcune tecniche richiedono, ad esempio, la standardizzazione delle variabili o la generazione di nuove variabili derivate. Ogni trasformazione deve essere documentata con attenzione, in quanto può influire in modo significativo sull’interpretazione dei risultati.\nL’analisi esplorativa rappresenta un momento di osservazione attenta, durante il quale si calcolano statistiche descrittive, si effettuano visualizzazioni e si individuano pattern e anomalie. Si tratta di un passaggio fondamentale per comprendere la struttura dei dati e orientare le scelte metodologiche future.\n\n14.6.3 Analisi Predittiva e Inferenziale\nQuando previsto, il cuore del progetto può consistere nella costruzione di modelli statistici o predittivi. In ambito psicologico, si ricorre spesso a regressioni, test parametrici e non parametrici, modelli misti o tecniche di classificazione. L’obiettivo può essere inferenziale (trarre conclusioni su una popolazione) o predittivo (stimare il comportamento futuro di una variabile). In entrambi i casi, è essenziale che le scelte modellistiche siano motivate e che le ipotesi siano verificate.\n\n14.6.4 Valutazione dei Risultati\nL’interpretazione dei risultati richiede un duplice livello di attenzione: da un lato, la valutazione statistica, tramite test, intervalli di confidenza o misure di bontà del modello; dall’altro, la coerenza con la teoria o con il contesto applicativo. È importante ricollegarsi agli obiettivi iniziali e interrogarsi sull’eventuale presenza di limiti o ambiguità.\n\n14.6.5 Comunicazione dei Risultati\nLa fase finale riguarda la comunicazione, che può assumere forme diverse a seconda del pubblico di riferimento: articoli accademici, report aziendali, presentazioni pubbliche. Qualunque sia il formato, è necessario presentare le analisi in modo chiaro, motivato e trasparente. L’uso di visualizzazioni curate e di un linguaggio accessibile contribuisce a rendere il lavoro più comprensibile e più utile per chi lo riceve.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#organizzazione-del-progetto",
    "href": "chapters/eda/01_project_structure.html#organizzazione-del-progetto",
    "title": "14  Le fasi del progetto di analisi dei dati",
    "section": "\n14.7 Organizzazione del Progetto",
    "text": "14.7 Organizzazione del Progetto\nPer favorire la riproducibilità e la gestione a lungo termine, è buona norma strutturare il progetto in modo ordinato. RStudio consente di creare file .Rproj che definiscono una directory principale da cui partono tutti i percorsi relativi. Aprire il progetto tramite questo file garantisce coerenza e facilita la navigazione tra i file.\nUna struttura consigliata, ispirata al modello proposto da Yu & Barter (2024), prevede una directory principale contenente i dati (suddivisi in grezzi ed elaborati), la documentazione analitica, gli script e un file README che spieghi la struttura del progetto. La documentazione può essere realizzata in Quarto, Jupyter o altri formati, e organizzata in sottocartelle per una maggiore chiarezza. Ad esempio:\nnome_progetto/\n├── nome_progetto.Rproj\n├── data/\n│   ├── raw/\n│   │   └── my_data.csv\n│   ├── processed/\n├── src/\n│   ├── 01_data_cleaning.qmd\n│   ├── 02_analysis.qmd\n│   └── functions/\n└── README.md\nUna simile struttura favorisce l’efficienza, la tracciabilità delle operazioni e la collaborazione tra più persone. La separazione dei dati grezzi da quelli elaborati, la creazione di script modulari e la descrizione chiara delle scelte analitiche permettono di affrontare con rigore anche progetti complessi e di facilitarne la diffusione e la verifica.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#riflessioni-conclusive",
    "href": "chapters/eda/01_project_structure.html#riflessioni-conclusive",
    "title": "14  Le fasi del progetto di analisi dei dati",
    "section": "\n14.8 Riflessioni conclusive",
    "text": "14.8 Riflessioni conclusive\nUno dei principali vantaggi dell’uso del codice per l’analisi dei dati è la possibilità di ottenere risultati stabili e riproducibili nel tempo. In un ambiente ben configurato, l’esecuzione di uno script sugli stessi dati porta sempre agli stessi risultati. Questo aspetto, apparentemente tecnico, ha in realtà implicazioni profonde: si tratta del principio di riproducibilità computazionale, un pilastro della pratica scientifica contemporanea. In psicologia, come in tutte le scienze empiriche, la possibilità di risalire con precisione al processo analitico che ha condotto a una certa conclusione è una condizione necessaria per la trasparenza, la valutazione critica e l’accumulo di conoscenza.\nLa riproducibilità, tuttavia, non è solo un requisito per la comunicazione scientifica, ma anche uno strumento prezioso per il ricercatore stesso. In assenza di un flusso di lavoro tracciabile, anche lo stesso autore rischia di non riuscire più a interpretare correttamente il proprio lavoro a distanza di tempo. Tornare a un’analisi svolta mesi prima e trovare un codice leggibile, organizzato e funzionante significa poter rapidamente riappropriarsi del significato delle scelte fatte, correggere eventuali errori o estendere il progetto a nuovi dati o a nuove domande.\nLa condivisione di un progetto ben strutturato permette inoltre ad altri ricercatori di verificare, adattare e riutilizzare procedure analitiche già testate, evitando sprechi di tempo e favorendo un circolo virtuoso di apprendimento. In questo senso, la riproducibilità è anche una forma di collaborazione implicita: rendere chiaro il proprio processo analitico contribuisce a una scienza più cumulativa e aperta.\nTuttavia, affinché ciò sia possibile, è necessario adottare abitudini e strumenti coerenti con questi obiettivi. La cura nella documentazione, la definizione di una struttura di progetto chiara, l’uso del controllo di versione e l’attenzione all’integrità e alla trasformazione dei dati sono tutte pratiche che, anche se inizialmente possono sembrare secondarie rispetto alla statistica in senso stretto, costituiscono la base operativa di un’analisi di qualità. Queste non sono regole astratte, ma condizioni pratiche che rendono possibile un lavoro analitico credibile e duraturo.\nNel percorso finora affrontato, abbiamo visto come l’intero ciclo di vita di un’analisi, dalla raccolta dei dati alla loro esplorazione, dalla modellazione alla comunicazione dei risultati, richieda uno sguardo progettuale e non solo esecutivo. Un progetto ben condotto non è quello che produce semplicemente un risultato “corretto”, ma quello che può essere riutilizzato, aggiornato e compreso anche da chi non ha partecipato alla sua realizzazione.\nIn definitiva, la riproducibilità non è un vincolo esterno imposto dalla comunità scientifica, ma un investimento nella qualità del proprio pensiero. Rendere esplicite le fasi del lavoro, rendere trasparente il codice e usare strumenti come R in un ambiente ben organizzato non significa solo essere più ordinati, ma anche allenarsi a ragionare in modo più preciso, critico e consapevole. È in questo senso che la data analysis diventa a pieno titolo parte integrante del metodo scientifico.\n\n\n\n\n\n\nUn problema cruciale della psicologia contemporanea è la crisi di replicabilità, che evidenzia come molti risultati di ricerca non siano replicabili (Collaboration, 2015). La riproducibilità computazionale, pur avendo un obiettivo più ristretto, si concentra sulla possibilità di ottenere gli stessi risultati applicando lo stesso codice agli stessi dati. Questo approccio, sebbene non risolva completamente la crisi, rappresenta un passo fondamentale verso una scienza più trasparente e rigorosa.\n\n\n\n\n\n\n\n\n\nRisposte alle Domande Iniziali\n\n\n\n\n\nOra che hai completato il capitolo, confrontiamo le risposte alle domande iniziali con quanto appreso:\n\n\nPerché è importante organizzare e documentare accuratamente i dati in un progetto di ricerca?\n\nUna gestione strutturata dei dati riduce il rischio di errori, facilita l’analisi e migliora la riproducibilità, rendendo il lavoro scientifico più affidabile e trasparente.\n\n\n\nQuali problemi possono emergere se si inizia a scrivere codice senza una pianificazione adeguata?\n\nSenza una pianificazione strategica si rischia di incorrere nel “debito tecnico”, accumulando codice disordinato che richiede correzioni costose in termini di tempo e risorse. Inoltre, si potrebbero fare scelte subottimali che compromettono la scalabilità e manutenibilità del progetto.\n\n\n\nQuali vantaggi offre R per la gestione dei dati rispetto ad altri strumenti?\n\nR fornisce strumenti avanzati per importazione, pulizia, analisi e visualizzazione dei dati, oltre a supportare la documentazione dinamica e il controllo delle versioni con Git. La sua ampia comunità e la disponibilità di pacchetti specializzati lo rendono particolarmente adatto per l’analisi statistica e la ricerca.\n\n\n\nQuali strategie potrebbero migliorare la riproducibilità del tuo lavoro?\n\nUtilizzare strumenti come Quarto per documentare il codice e le analisi, adottare percorsi relativi con il pacchetto here, strutturare i dati in cartelle ben organizzate e integrare il controllo delle versioni con Git.\n\n\n\nCome struttureresti un progetto di analisi dati per mantenerlo chiaro e facilmente replicabile?\n\n\nAdottando una struttura chiara, ad esempio:\nnome_progetto/\n├── nome_progetto.Rproj\n├── data/\n│   ├── raw/\n│   │   └── my_data.csv\n│   ├── processed/\n├── dslc_documentation/\n│   ├── 01_data_cleaning.qmd\n│   ├── 02_analysis.qmd\n│   └── functions/\n└── README.md\n\nQuesta organizzazione separa i dati grezzi da quelli elaborati, include documentazione chiara e facilita la riproducibilità.\n\n\n\n\n\nConclusione: Riflettere in anticipo sui problemi e sulle strategie di gestione dei dati aiuta a costruire workflow più efficienti e affidabili. Se le tue risposte iniziali differivano da queste, quali nuovi spunti hai appreso da questo capitolo?",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#esercizi",
    "href": "chapters/eda/01_project_structure.html#esercizi",
    "title": "14  Le fasi del progetto di analisi dei dati",
    "section": "\n14.9 Esercizi",
    "text": "14.9 Esercizi\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nL’obiettivo di questo esercizio è comprendere il ciclo di vita di un progetto di analisi dei dati, l’organizzazione del progetto e la gestione della riproducibilità.\n\n\nGestione del progetto di analisi\n\nQuali sono le fasi principali di un progetto di analisi dei dati secondo Yu (2024)?\nSpiega il ruolo della fase di formulazione del problema e raccolta dei dati.\n\n\n\nOrganizzazione del workspace in R\n\nQuali impostazioni devono essere modificate in RStudio per favorire la riproducibilità?\nPerché è importante usare percorsi relativi nei progetti in RStudio?\nDescrivi il ruolo del pacchetto here nella gestione dei percorsi dei file.\n\n\n\nStruttura dei progetti in R\n\nQuali sono i vantaggi dell’utilizzo dei progetti in RStudio?\nQuali sono le cartelle principali in una struttura organizzata di un progetto?\nPerché è utile separare i dati grezzi dai dati processati?\n\n\n\nImportazione ed esportazione dei dati\n\nQuali pacchetti di R possono essere utilizzati per importare ed esportare dati?\n\nScrivi un esempio di codice per importare un file CSV usando rio e il pacchetto here.\n\nCome puoi esportare un dataset modificato in una cartella dedicata ai dati processati?\n\n\n\nPulizia e preprocessing dei dati\n\nQual è la differenza tra pulizia e preprocessing dei dati?\n\nQuali strumenti di dplyr sono comunemente usati per pulire e trasformare i dati?\n\n\n\nAnalisi esplorativa dei dati (EDA)\n\nQuali sono alcuni strumenti utilizzati in R per effettuare un’analisi esplorativa dei dati?\n\nScrivi un breve esempio di codice in R per calcolare statistiche descrittive di base su un dataset.\n\n\n\nRiproducibilità e comunicazione dei risultati\n\nPerché la riproducibilità è un elemento chiave nella scienza dei dati?\n\nQuali strumenti offre Quarto per la documentazione e la condivisione dei risultati di un’analisi?\n\n\n\n\n\n\n\n\n\n\n\n\nSoluzione\n\n\n\n\n\n1. Gestione del progetto di analisi\n\n\nFasi principali del progetto di analisi dei dati (Yu, 2024):\n\nFormulazione del problema e raccolta dei dati\n\nPulizia, preprocessing e analisi esplorativa\n\nAnalisi predittiva e/o inferenziale (se applicabile)\n\nValutazione dei risultati\n\nComunicazione dei risultati\n\n\n\nRuolo della fase di formulazione del problema:\nAiuta a definire gli obiettivi dell’analisi e a selezionare le fonti di dati adeguate. Una domanda di ricerca ben definita garantisce che i dati siano pertinenti e che le analisi siano mirate.\n\n2. Organizzazione del workspace in R\n\n\nImpostazioni da modificare in RStudio:\n\nDisabilitare Restore .RData into workspace at startup\n\nImpostare Save workspace to .RData on exit su “Never”\n\n\nImportanza dei percorsi relativi:\nPermettono di rendere il progetto portabile e riproducibile, evitando problemi di percorsi assoluti specifici per un computer.\nRuolo del pacchetto here\nAiuta a gestire i percorsi relativi all’interno del progetto senza dover specificare percorsi assoluti.\n\n3. Struttura dei progetti in R\n\nVantaggi dell’uso dei progetti in RStudio:\nMantengono ambienti separati, organizzano i file e facilitano la riproducibilità.\n\nCartelle principali in una struttura organizzata:\n\n\ndata/raw/ → Dati grezzi\n\n\ndata/processed/ → Dati elaborati\n\n\ndslc_documentation/ → Documentazione e script\n\n\nfunctions/ → Funzioni personalizzate\n\n\nSeparare dati grezzi da dati processati:\nEvita di modificare accidentalmente i dati originali, garantendo riproducibilità.\n\n4. Importazione ed esportazione dei dati\n\n\nPacchetti per importazione/esportazione:\n\n\nrio: unifica funzioni di import/export\n\n\nreadr: specifico per CSV e altri formati di testo\n\n\nhere: gestisce percorsi relativi\n\n\n\nEsempio di codice per importare dati CSV:\nlibrary(here)\nlibrary(rio)\ndf &lt;- rio::import(here(\"data\", \"raw\", \"my_data.csv\"))\n\n\nEsportare dati modificati:\nrio::export(df, here(\"data\", \"processed\", \"my_data_processed.csv\"))\n\n\n5. Pulizia e preprocessing dei dati\n\n\nDifferenza tra pulizia e preprocessing:\n\nPulizia: rimozione di errori, gestione dei dati mancanti, formattazione\n\nPreprocessing: trasformazione dei dati per adattarli a modelli specifici\n\n\n\nStrumenti di dplyr per pulizia e trasformazione:\n\n\nmutate(), filter(), select(), rename(), relocate()\n\n\n\n\n6. Analisi esplorativa dei dati (EDA)\n\n\nStrumenti comuni:\n\n\nsummary(), str(), glimpse(), ggplot2 per visualizzazione\n\n\n\nEsempio di codice per statistiche descrittive:\nsummary(df)\n\n\n7. Riproducibilità e comunicazione dei risultati\n\n\nImportanza della riproducibilità:\n\nFacilita la verifica e il miglioramento degli studi\n\nPreviene errori accidentali\n\nConsente a terzi di replicare e costruire su ricerche precedenti\n\n\n\nStrumenti di Quarto:\n\nPermette di combinare testo, codice e output in documenti riproducibili\n\nSupporta citazioni automatiche e gestione delle bibliografie",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/01_project_structure.html#informazioni-sullambiente-di-sviluppo",
    "title": "14  Le fasi del progetto di analisi dei dati",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pillar_1.11.0         tinytable_0.11.0      patchwork_1.3.1      \n#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.13.0     \n#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.0     \n#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [16] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [19] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [22] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.6         tidyselect_1.2.1     farver_2.1.2        \n#&gt;  [4] fastmap_1.2.0        TH.data_1.1-3        tensorA_0.36.2.1    \n#&gt;  [7] digest_0.6.37        estimability_1.5.1   timechange_0.3.0    \n#&gt; [10] lifecycle_1.0.4      survival_3.8-3       magrittr_2.0.3      \n#&gt; [13] compiler_4.5.1       rlang_1.1.6          tools_4.5.1         \n#&gt; [16] knitr_1.50           bridgesampling_1.1-2 htmlwidgets_1.6.4   \n#&gt; [19] pkgbuild_1.4.8       curl_6.4.0           RColorBrewer_1.1-3  \n#&gt; [22] abind_1.4-8          multcomp_1.4-28      withr_3.0.2         \n#&gt; [25] purrr_1.1.0          grid_4.5.1           stats4_4.5.1        \n#&gt; [28] xtable_1.8-4         colorspace_2.1-1     inline_0.3.21       \n#&gt; [31] emmeans_1.11.2       scales_1.4.0         MASS_7.3-65         \n#&gt; [34] cli_3.6.5            mvtnorm_1.3-3        rmarkdown_2.29      \n#&gt; [37] generics_0.1.4       RcppParallel_5.1.10  cachem_1.1.0        \n#&gt; [40] stringr_1.5.1        splines_4.5.1        parallel_4.5.1      \n#&gt; [43] vctrs_0.6.5          V8_6.0.5             Matrix_1.7-3        \n#&gt; [46] sandwich_3.1-1       jsonlite_2.0.0       arrayhelpers_1.1-0  \n#&gt; [49] glue_1.8.0           codetools_0.2-20     distributional_0.5.0\n#&gt; [52] lubridate_1.9.4      stringi_1.8.7        gtable_0.3.6        \n#&gt; [55] QuickJSR_1.8.0       htmltools_0.5.8.1    Brobdingnag_1.2-9   \n#&gt; [58] R6_2.6.1             rprojroot_2.1.0      evaluate_1.0.4      \n#&gt; [61] lattice_0.22-7       backports_1.5.0      memoise_2.0.1       \n#&gt; [64] broom_1.0.9          snakecase_0.11.1     rstantools_2.4.0    \n#&gt; [67] coda_0.19-4.1        gridExtra_2.3        nlme_3.1-168        \n#&gt; [70] checkmate_2.3.2      xfun_0.52            zoo_1.8-14          \n#&gt; [73] pkgconfig_2.0.3",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#bibliografia",
    "href": "chapters/eda/01_project_structure.html#bibliografia",
    "title": "14  Le fasi del progetto di analisi dei dati",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nCollaboration, O. S. (2015). Estimating the reproducibility of psychological science. Science, 349(6251), aac4716.\n\n\nYu, B., & Barter, R. L. (2024). Veridical data science: The practice of responsible data analysis and decision making. MIT Press.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html",
    "href": "chapters/eda/02_data_cleaning.html",
    "title": "15  Flusso di lavoro per la pulizia dei dati",
    "section": "",
    "text": "15.1 Introduzione\nIn questo capitolo, esamineremo un caso concreto di data cleaning e preprocessing, seguendo il tutorial di Crystal Lewis. Il problema viene presentato come segue:\nCrystal Lewis elenca i seguenti passaggi da seguire nel processo di data cleaning:\nSebbene l’ordine di questi passaggi sia flessibile e possa essere adattato alle esigenze specifiche, c’è un passaggio che non dovrebbe mai essere saltato: il primo, ovvero la revisione dei dati. Senza una revisione preliminare, l’analista rischia di sprecare ore a pulire i dati per poi scoprire che mancano dei partecipanti, che i dati non sono organizzati come previsto o, peggio ancora, che si sta lavorando con i dati sbagliati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#introduzione",
    "href": "chapters/eda/02_data_cleaning.html#introduzione",
    "title": "15  Flusso di lavoro per la pulizia dei dati",
    "section": "",
    "text": "Nonostante la fase più interessante di un progetto di analisi dei dati sia quella in cui si riesce a rispondere alla domanda che ha dato avvio all’indagine, gran parte del tempo di un analista è in realtà dedicata a una fase preliminare: la pulizia e il preprocessing dei dati, operazioni che vengono svolte ancor prima dell’analisi esplorativa.\n\n\n\nI am managing data for a longitudinal randomized controlled trial (RCT) study. For this RCT, schools are randomized to either a treatment or control group. Students who are in a treatment school receive a program to boost their math self-efficacy. Data is collected on all students in two waves (wave 1 is in the fall of a school year, and wave 2 is collected in the spring). At this point in time, we have collected wave 1 of our student survey on a paper form and we set up a data entry database for staff to enter the information into. Data has been double-entered, checked for entry errors, and has been exported in a csv format (“w1_mathproj_stu_svy_raw.csv”) to a folder (called “data”) where it is waiting to be cleaned.\n\n\n\nRevisione dei dati.\nRegolazione del numero di casi.\nDe-identificazione dei dati.\nEliminazione delle colonne irrilevanti.\nDivisione delle colonne, se necessario.\nRidenominazione delle variabili.\nTrasformazione/normalizzazione delle variabili.\nStandardizzazione delle variabili.\nAggiornamento dei tipi di variabili, se necessario.\nRicodifica delle variabili.\nCreazione di eventuali variabili necessarie.\nGestione dei valori mancanti, se necessario.\nAggiunta di metadati, se necessario.\nValidazione dei dati.\nFusione e/o unione dei dati, se necessario.\nTrasformazione dei dati, se necessario.\nSalvataggio dei dati puliti.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#tutorial",
    "href": "chapters/eda/02_data_cleaning.html#tutorial",
    "title": "15  Flusso di lavoro per la pulizia dei dati",
    "section": "\n15.2 Tutorial",
    "text": "15.2 Tutorial\nQuesto tutorial segue i passaggi descritti da Crystal Lewis per illustrare le buone pratiche nella gestione e pulizia dei dati.\n\n15.2.1 Organizzazione dei Dati\nUn principio fondamentale nella gestione dei dati è preservare l’integrità dei dati grezzi. I dati originali non devono mai essere modificati direttamente. È quindi consigliabile strutturare i dati in una directory denominata data, suddivisa in due sottocartelle:\n\n\nraw: contiene i dati originali, mantenuti inalterati.\n\n\nprocessed: destinata ai dati ripuliti e preprocessati.\n\nAd esempio, importiamo i dati da un file denominato w1_mathproj_stu_svy_raw.csv per avviare il processo di pulizia. Tutte le operazioni dovranno essere effettuate utilizzando percorsi relativi alla home directory del progetto, che definiremo come primo passo.\n\n15.2.2 Passaggi del Tutorial\n\n15.2.2.1 Importare e Esaminare i Dati\nImportiamo i dati utilizzando la funzione import() della libreria rio e visualizziamo i primi valori di ciascuna colonna per verificarne la corretta importazione:\n\n# Importa i dati\nsvy &lt;- rio::import(here::here(\"data\", \"w1_mathproj_stu_svy_raw.csv\"))\n\n# Esamina la struttura del dataset\nglimpse(svy)\n#&gt; Rows: 6\n#&gt; Columns: 7\n#&gt; $ stu_id      &lt;int&gt; 1347, 1368, 1377, 1387, 1347, 1399\n#&gt; $ svy_date    &lt;IDate&gt; 2023-02-13, 2023-02-13, 2023-02-13, 2023-02-13, 2023-0…\n#&gt; $ grade_level &lt;int&gt; 9, 10, 9, 11, 9, 12\n#&gt; $ math1       &lt;int&gt; 2, 3, 4, 3, 2, 4\n#&gt; $ math2       &lt;chr&gt; \"1\", \"2\", \"\\n4\", \"3\", \"2\", \"1\"\n#&gt; $ math3       &lt;int&gt; 3, 2, 4, NA, 4, 3\n#&gt; $ math4       &lt;int&gt; 3, 2, 4, NA, 2, 1\n\nPer controllare visivamente i dati, possiamo esaminare le prime e le ultime righe del data frame:\n\n# Visualizza le prime righe\nsvy |&gt; \n  head()\n#&gt;   stu_id   svy_date grade_level math1 math2 math3 math4\n#&gt; 1   1347 2023-02-13           9     2     1     3     3\n#&gt; 2   1368 2023-02-13          10     3     2     2     2\n#&gt; 3   1377 2023-02-13           9     4   \\n4     4     4\n#&gt; 4   1387 2023-02-13          11     3     3    NA    NA\n#&gt; 5   1347 2023-02-14           9     2     2     4     2\n#&gt; 6   1399 2023-02-14          12     4     1     3     1\n\n# Visualizza le ultime righe\nsvy |&gt; \n  tail()\n#&gt;   stu_id   svy_date grade_level math1 math2 math3 math4\n#&gt; 1   1347 2023-02-13           9     2     1     3     3\n#&gt; 2   1368 2023-02-13          10     3     2     2     2\n#&gt; 3   1377 2023-02-13           9     4   \\n4     4     4\n#&gt; 4   1387 2023-02-13          11     3     3    NA    NA\n#&gt; 5   1347 2023-02-14           9     2     2     4     2\n#&gt; 6   1399 2023-02-14          12     4     1     3     1\n\n\n15.2.2.2 Individuare e Rimuovere i Duplicati\nIn questa fase, eseguiamo alcune modifiche necessarie al data frame, come rimuovere duplicati e ordinare i dati:\n\n\nVerifica duplicati: controlliamo i record duplicati nel dataset.\n\nRimuovi duplicati: manteniamo solo la prima occorrenza.\n\nOrdina per data: organizziamo i record in ordine crescente rispetto alla variabile svy_date.\n\nEsamina i dati puliti: controlliamo il risultato delle modifiche.\n\n\n# Identifica i duplicati basati su 'stu_id'\nduplicates &lt;- \n  svy[duplicated(svy$stu_id) | duplicated(svy$stu_id, fromLast = TRUE), ]\n\n\n# Visualizza i duplicati trovati\nduplicates\n#&gt;   stu_id   svy_date grade_level math1 math2 math3 math4\n#&gt; 1   1347 2023-02-13           9     2     1     3     3\n#&gt; 5   1347 2023-02-14           9     2     2     4     2\n\n\n# Ordina per 'svy_date' in ordine crescente\nsvy &lt;- svy[order(svy$svy_date), ]\n\n\n# Rimuove i duplicati mantenendo la prima occorrenza\nsvy &lt;- svy[!duplicated(svy$stu_id), ]\n\n\n# Esamina il dataset finale\nprint(svy)\n#&gt;   stu_id   svy_date grade_level math1 math2 math3 math4\n#&gt; 1   1347 2023-02-13           9     2     1     3     3\n#&gt; 2   1368 2023-02-13          10     3     2     2     2\n#&gt; 3   1377 2023-02-13           9     4   \\n4     4     4\n#&gt; 4   1387 2023-02-13          11     3     3    NA    NA\n#&gt; 6   1399 2023-02-14          12     4     1     3     1\n\nVerifichiamo le dimensioni del dataset pulito per assicurarci che le operazioni siano state eseguite correttamente:\n\n# Controlla il numero di righe e colonne\nsvy |&gt; \n  dim()\n#&gt; [1] 5 7\n\n\n15.2.2.3 De-identificazione dei Dati\n\n# Rimuovi la colonna 'svy_date'\nsvy &lt;- svy |&gt;\n  dplyr::select(-svy_date)\n\n# Mostra i nomi delle colonne rimaste\nnames(svy)\n#&gt; [1] \"stu_id\"      \"grade_level\" \"math1\"       \"math2\"       \"math3\"      \n#&gt; [6] \"math4\"\n\n\n15.2.2.4 Rimuovere le Colonne non Necessarie\nNel caso presente, la rimozione di colonne non è necessaria. Tuttavia, in molti progetti di analisi dei dati, soprattutto quando i dati vengono raccolti utilizzando software di terze parti o strumenti specifici per esperimenti psicologici, è comune trovarsi con colonne che non sono pertinenti allo studio in corso.\nQueste colonne possono includere dati come identificatori interni, timestamp generati automaticamente, informazioni di debug, o variabili che non sono rilevanti per l’analisi che si intende condurre. Quando tali colonne sono irrilevanti per la ricerca, possono essere rimosse per semplificare il dataset e ridurre il rischio di confusione o errori durante l’analisi. Rimuovere le colonne non necessarie non solo rende il dataset più gestibile, ma aiuta anche a focalizzare l’analisi sulle variabili che realmente importano per rispondere alle domande di ricerca.\n\n15.2.2.5 Dividere le Colonne Secondo Necessità\nNel caso presente, questa operazione non è necessaria. Tuttavia, se si lavora con un dataset che include una colonna chiamata “NomeCompleto”, contenente sia il nome che il cognome di uno studente, per esempio, è buona pratica separare questa colonna in due colonne distinte, “Nome” e “Cognome”. Questa suddivisione facilita l’analisi e la manipolazione dei dati, rendendoli più organizzati e accessibili.\n\n15.2.2.6 Rinominare le Colonne\nÈ importante assegnare nomi chiari alle colonne del dataset. Utilizzare nomi di variabili comprensibili aiuta a rendere l’analisi dei dati più intuitiva e a ridurre il rischio di errori interpretativi.\nEsempi di buone pratiche:\n\nEvita nomi di colonne come “x” o acronimi incomprensibili. Questi possono creare confusione durante l’analisi, specialmente se il dataset viene condiviso con altri ricercatori o se viene ripreso dopo un lungo periodo di tempo.\nInvece, cerca di utilizzare nomi di variabili che descrivano chiaramente il contenuto della colonna. Ad esempio, invece di “x1” o “VAR123”, un nome come “ansia_base” o “liv_autoefficacia” è molto più comprensibile e immediato.\nPer i nomi composti, utilizza un separatore come il trattino basso _. Ad esempio, se stai lavorando con dati relativi a un test psicologico, potresti avere colonne chiamate “test_ansia_pre” e “test_ansia_post” per indicare i risultati del test di ansia prima e dopo un intervento.\n\nEsempi di nomi di colonne ben scelti:\n\n\nNome generico: TS, AE\n\n\nNome migliore: tempo_studio, auto_efficacia\n\n\n\n\nNome generico: S1, S2\n\n\nNome migliore: stress_situazione1, stress_situazione2\n\n\n\n\nNome generico: Q1, Q2\n\n\nNome migliore: qualità_sonno_sett1, qualità_sonno_sett2\n\n\n\n\n15.2.2.7 Trasformare le Variabili\nNel caso presente non si applica, ma è un passo importante in molte analisi dei dati.\nEsempi di trasformazione delle variabili:\n\nLogaritmo di una variabile: Immaginiamo di avere una variabile che misura i tempi di reazione dei partecipanti a un esperimento. Se i tempi di reazione hanno una distribuzione fortemente asimmetrica (con alcuni valori molto elevati), potrebbe essere utile applicare una trasformazione logaritmica per rendere la distribuzione più simmetrica e migliorare l’interpretabilità dei risultati.\nCodifica delle variabili categoriche: Se è presente una variabile categorica come il “tipo di intervento” con valori come “cognitivo”, “comportamentale” e “farmacologico”, potrebbe essere necessario trasformare questa variabile in variabili dummy (ad esempio, intervento_cognitivo, intervento_comportamentale, intervento_farmacologico), dove ogni variabile assume il valore 0 o 1 a seconda della presenza o meno di quel tipo di intervento. Questo è utile quando si utilizzano tecniche di regressione.\n\n15.2.2.8 Standardizzazione delle Variabili\nLa standardizzazione è utile quando si desidera rendere comparabili variabili misurate su scale diverse, ad esempio per confronti tra gruppi o per inclusione in modelli di regressione.\nEsempio. Supponiamo di avere una variabile che misura il livello di ansia su una scala da 0 a 100. Per standardizzarla:\n\n\nSottrai la media del campione dalla variabile.\n\n\nDividi per la deviazione standard.\n\nIl risultato è una variabile con media pari a 0 e deviazione standard pari a 1.\nVantaggi della standardizzazione:\n\nfacilita l’interpretazione dei coefficienti in un modello di regressione;\npermette un confronto diretto tra variabili che hanno unità di misura diverse.\n\n15.2.2.9 Normalizzazione delle Variabili\n\nLa normalizzazione consiste nel ridimensionare i dati su una scala predefinita, spesso compresa tra 0 e 1. Questo processo è particolarmente utile in analisi multivariate, dove variabili con scale molto diverse potrebbero influenzare in modo sproporzionato i risultati.\nEsempio. Hai dati su:\n\n\nOre di sonno (misurate in ore, da 0 a 24).\n\n\nLivello di stress (misurato su una scala da 1 a 50).\n\n\nAuto-efficacia (misurata su una scala da 0 a 100).\n\nPer garantire che ogni variabile abbia lo stesso peso nell’analisi, puoi normalizzarle usando una formula come:\n\\[\nx_{\\text{norm}} = \\frac{x - \\text{min}(x)}{\\text{max}(x) - \\text{min}(x)} .\n\\]\nPerché Standardizzare o Normalizzare?\nTrasformare le variabili è cruciale per:\n\n\nGestire scale diverse: Riduce il rischio che variabili con valori numericamente più grandi dominino i risultati.\n\n\nGarantire validità e interpretabilità: Facilita il confronto tra dati provenienti da fonti o gruppi diversi.\n\n\nEvitare problemi numerici nei modelli statistici: Alcuni algoritmi di machine learning o tecniche di ottimizzazione richiedono che i dati siano su scale simili per funzionare correttamente.\n\nIn conclusione, la scelta tra standardizzazione e normalizzazione dipende dal contesto dell’analisi e dagli obiettivi specifici. Entrambi i processi sono strumenti indispensabili per garantire che i dati siano trattati in modo adeguato, portando a risultati robusti e facilmente interpretabili.\n\n15.2.2.10 Aggiornare i Tipi delle Variabili\nNel caso presente non è necessario. Supponiamo invece di avere una colonna in un dataset psicologico che contiene punteggi di un questionario, ma i dati sono stati importati come stringhe (testo) invece che come numeri. Per eseguire calcoli statistici, sarà necessario convertire questa colonna da stringa a numerico.\nIn R, si potrebbe usare il seguente codice:\n\n# Supponiamo di avere un data frame chiamato 'df' con una colonna 'punteggio' importata come carattere\ndf$punteggio &lt;- as.numeric(df$punteggio)\n\n# Ora la colonna 'punteggio' è stata convertita in un tipo numerico ed è possibile eseguire calcoli su di essa\n\nIn questo esempio, la funzione as.numeric() viene utilizzata per convertire la colonna punteggio in un formato numerico, permettendo di eseguire analisi quantitative sui dati.\nUn altro caso molto comune si verifica quando si importano dati da file Excel. Spesso capita che, all’interno di una cella di una colonna che dovrebbe contenere solo valori numerici, venga inserito erroneamente uno o più caratteri alfanumerici. Di conseguenza, l’intera colonna viene interpretata come di tipo alfanumerico, anche se i valori dovrebbero essere numerici. In questi casi, è fondamentale individuare la cella problematica, correggere manualmente il valore errato, e poi riconvertire l’intera colonna da alfanumerica a numerica.\n\n15.2.2.11 Ricodificare le Variabili\nAnche se in questo caso non è necessario, la ricodifica delle variabili è una pratica molto comune nelle analisi dei dati psicologici.\nPer esempio, consideriamo una variabile categoriale con modalità descritte da stringhe poco comprensibili, che vengono ricodificate con nomi più chiari e comprensibili.\nSupponiamo di avere un DataFrame chiamato df con una colonna tipo_intervento che contiene le modalità \"CT\", \"BT\", e \"MT\" per rappresentare rispettivamente “Terapia Cognitiva”, “Terapia Comportamentale” e “Terapia Mista”. Queste abbreviazioni potrebbero non essere immediatamente chiare a chiunque analizzi i dati, quindi decidiamo di ricodificarle con nomi più espliciti. Ecco come farlo in R:\n\n# Tibble chiamato 'df' con una colonna 'tipo_intervento'\ndf &lt;- tibble(tipo_intervento = c(\"CT\", \"BT\", \"MT\", \"CT\", \"BT\"))\ndf\n#&gt; # A tibble: 5 × 1\n#&gt;   tipo_intervento\n#&gt;   &lt;chr&gt;          \n#&gt; 1 CT             \n#&gt; 2 BT             \n#&gt; 3 MT             \n#&gt; 4 CT             \n#&gt; 5 BT\n\n\n# Ricodifica delle modalità della variabile 'tipo_intervento' in nomi più comprensibili\ndf &lt;- df %&gt;%\n  mutate(tipo_intervento_ricodificato = dplyr::recode(\n    tipo_intervento,\n    \"CT\" = \"Terapia Cognitiva\",\n    \"BT\" = \"Terapia Comportamentale\",\n    \"MT\" = \"Terapia Mista\"\n  ))\n\n# Mostra il tibble con la nuova colonna ricodificata\ndf\n#&gt; # A tibble: 5 × 2\n#&gt;   tipo_intervento tipo_intervento_ricodificato\n#&gt;   &lt;chr&gt;           &lt;chr&gt;                       \n#&gt; 1 CT              Terapia Cognitiva           \n#&gt; 2 BT              Terapia Comportamentale     \n#&gt; 3 MT              Terapia Mista               \n#&gt; 4 CT              Terapia Cognitiva           \n#&gt; 5 BT              Terapia Comportamentale\n\n\n15.2.2.12 Aggiungere Nuove Variabili nel Data Frame\nNel caso presente non è richiesto, ma aggiungere nuove variabili a un DataFrame è un’operazione comune durante l’analisi dei dati. Un esempio è il calcolo dell’indice di massa corporea (BMI).\nSupponiamo di avere un DataFrame chiamato df che contiene le colonne peso_kg (peso in chilogrammi) e altezza_m (altezza in metri) per ciascun partecipante a uno studio psicologico. Per arricchire il dataset, possiamo calcolare il BMI per ogni partecipante e aggiungerlo come una nuova variabile.\nIl BMI si calcola con la formula:\n\\[ \\text{BMI} = \\frac{\\text{peso in kg}}{\\text{altezza in metri}^2} .\\]\nEcco come aggiungere la nuova colonna.\n\n# Supponiamo di avere un tibble chiamato 'df' con le colonne 'peso_kg' e 'altezza_m'\ndf &lt;- tibble(\n  peso_kg = c(70, 85, 60, 95),\n  altezza_m = c(1.75, 1.80, 1.65, 1.90)\n)\ndf\n#&gt; # A tibble: 4 × 2\n#&gt;   peso_kg altezza_m\n#&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1      70      1.75\n#&gt; 2      85      1.8 \n#&gt; 3      60      1.65\n#&gt; 4      95      1.9\n\n\n# Calcola il BMI e aggiungilo come una nuova colonna 'BMI'\ndf &lt;- df %&gt;%\n  mutate(BMI = peso_kg / (altezza_m^2))\n\n# Mostra il tibble con la nuova variabile aggiunta\ndf\n#&gt; # A tibble: 4 × 3\n#&gt;   peso_kg altezza_m   BMI\n#&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1      70      1.75  22.9\n#&gt; 2      85      1.8   26.2\n#&gt; 3      60      1.65  22.0\n#&gt; 4      95      1.9   26.3\n\n\n15.2.3 Affrontare il Problema dei Dati Mancanti\nI dati mancanti sono un problema comune nelle ricerche psicologiche e in molte altre discipline. Quando mancano delle informazioni in un dataset, possono verificarsi gravi problemi per l’analisi statistica, come risultati distorti, riduzione della precisione delle stime o, in alcuni casi, l’impossibilità di applicare alcuni algoritmi.\n\n15.2.3.1 Perché i Dati Mancanti Sono un Problema?\nImmagina di voler capire il rendimento medio di una classe in un test, ma alcuni studenti hanno lasciato delle risposte in bianco. Se ignoriamo le risposte mancanti o eliminiamo gli studenti con dati incompleti, rischiamo di ottenere una stima che non rappresenta correttamente la realtà. Questo succede perché:\n\n\nBias dei risultati: Se i dati mancanti non sono casuali (ad esempio, i dati mancanti sono presenti più spesso in studenti con basso rendimento), le conclusioni possono essere errate.\n\nRiduzione della potenza statistica: Eliminare dati incompleti riduce il numero totale di osservazioni, rendendo più difficile trovare risultati significativi.\n\nImpossibilità di applicare alcuni metodi: Molti algoritmi statistici richiedono dati completi e non funzionano con valori mancanti.\n\n15.2.3.2 Come Gestire i Dati Mancanti?\nCi sono diversi modi per affrontare i dati mancanti. Vediamo prima i metodi più semplici e poi quelli più avanzati.\nEsaminiamo il data frame iniziale:\n\nsvy |&gt; \n  summary()\n#&gt;      stu_id      grade_level       math1        math2          \n#&gt;  Min.   :1347   Min.   : 9.0   Min.   :2.0   Length:5          \n#&gt;  1st Qu.:1368   1st Qu.: 9.0   1st Qu.:3.0   Class :character  \n#&gt;  Median :1377   Median :10.0   Median :3.0   Mode  :character  \n#&gt;  Mean   :1376   Mean   :10.2   Mean   :3.2                     \n#&gt;  3rd Qu.:1387   3rd Qu.:11.0   3rd Qu.:4.0                     \n#&gt;  Max.   :1399   Max.   :12.0   Max.   :4.0                     \n#&gt;                                                                \n#&gt;      math3          math4     \n#&gt;  Min.   :2.00   Min.   :1.00  \n#&gt;  1st Qu.:2.75   1st Qu.:1.75  \n#&gt;  Median :3.00   Median :2.50  \n#&gt;  Mean   :3.00   Mean   :2.50  \n#&gt;  3rd Qu.:3.25   3rd Qu.:3.25  \n#&gt;  Max.   :4.00   Max.   :4.00  \n#&gt;  NA's   :1      NA's   :1\n\nSi noti la presenza di dati mancanti sulle variabili math3 e math4.\n\ndim(svy)\n#&gt; [1] 5 6\n\n\n\nEsclusione dei Casi Incompleti (Complete Case Analysis).\nUn approccio comune, ma spesso non ideale, è quello di analizzare solo i casi completi, eliminando tutte le righe con valori mancanti. In R, questo si può fare con il seguente comando:\n\nsvy_comp &lt;- svy |&gt;\n  drop_na()\n\nIn questo modo abbiamo escluso tutte le righe nelle quali sono presenti dei dati mancanti (in questo caso, una sola riga).\n\ndim(svy_comp)\n#&gt; [1] 4 6\n\nLimite: Questo metodo può introdurre bias se i dati mancanti non sono casuali e riduce il campione, compromettendo l’affidabilità delle analisi.\n\n\nImputazione Semplice\nSostituire i valori mancanti con stime semplici:\n\n\nMedia o mediana: Per le variabili numeriche, sostituire i valori mancanti con la media o la mediana. Questo metodo è facile da implementare, ma può ridurre la variabilità nei dati.\n\nModa: Per le variabili categoriche, sostituire i valori mancanti con il valore più frequente. Tuttavia, può introdurre distorsioni se i dati sono molto eterogenei.\n\n\n\nImputazione Multipla\nUn approccio più avanzato è l’imputazione multipla, che utilizza modelli statistici per stimare i valori mancanti in modo iterativo. L’idea di base è semplice: ogni valore mancante viene stimato tenendo conto delle relazioni con tutte le altre variabili.\nVantaggi:\n\nMantiene la variabilità dei dati.\nPreserva le relazioni tra le variabili.\nRiduce il rischio di bias rispetto ai metodi semplici.\n\n\n\n15.2.3.3 Applicazione Pratica: Imputazione Multipla con mice in R\nSupponiamo di avere un dataset con alcune colonne numeriche che contengono valori mancanti. Possiamo utilizzare il pacchetto mice per imputare i dati mancanti.\nSelezioniamo le colonne numeriche da imputare.\n\nnumeric_columns &lt;- c(\"math1\", \"math2\", \"math3\", \"math4\")\nsvy &lt;- svy %&gt;%\n  mutate(across(all_of(numeric_columns), as.numeric))\n\nEseguiamo l’imputazione multipla.\n\nimputed &lt;- mice(\n  svy[numeric_columns], \n  m = 1, \n  maxit = 10, \n  method = \"norm.predict\", \n  seed = 123\n)\n#&gt; \n#&gt;  iter imp variable\n#&gt;   1   1  math3  math4\n#&gt;   2   1  math3  math4\n#&gt;   3   1  math3  math4\n#&gt;   4   1  math3  math4\n#&gt;   5   1  math3  math4\n#&gt;   6   1  math3  math4\n#&gt;   7   1  math3  math4\n#&gt;   8   1  math3  math4\n#&gt;   9   1  math3  math4\n#&gt;   10   1  math3  math4\n\nOttieniamo il dataset con i valori imputati.\n\nsvy_imputed &lt;- complete(imputed)\n\nArrotondiamo i valori imputati (se necessario).\n\nsvy_imputed &lt;- svy_imputed %&gt;%\n  mutate(across(everything(), round))\n\nSostituiamo i valori imputati nel dataset originale.\n\nsvy[numeric_columns] &lt;- svy_imputed\n\nEsaminiamo il risultato ottenuto.\n\nsvy |&gt; \n  summary()\n#&gt;      stu_id      grade_level       math1         math2         math3    \n#&gt;  Min.   :1347   Min.   : 9.0   Min.   :2.0   Min.   :1.0   Min.   :2.0  \n#&gt;  1st Qu.:1368   1st Qu.: 9.0   1st Qu.:3.0   1st Qu.:1.0   1st Qu.:3.0  \n#&gt;  Median :1377   Median :10.0   Median :3.0   Median :2.0   Median :3.0  \n#&gt;  Mean   :1376   Mean   :10.2   Mean   :3.2   Mean   :2.2   Mean   :3.2  \n#&gt;  3rd Qu.:1387   3rd Qu.:11.0   3rd Qu.:4.0   3rd Qu.:3.0   3rd Qu.:4.0  \n#&gt;  Max.   :1399   Max.   :12.0   Max.   :4.0   Max.   :4.0   Max.   :4.0  \n#&gt;      math4    \n#&gt;  Min.   :1.0  \n#&gt;  1st Qu.:2.0  \n#&gt;  Median :3.0  \n#&gt;  Mean   :2.8  \n#&gt;  3rd Qu.:4.0  \n#&gt;  Max.   :4.0\n\n\n15.2.3.4 Come Funziona l’Imputazione Multipla?\n\nOgni variabile con valori mancanti viene modellata come funzione delle altre variabili.\nI valori mancanti vengono stimati iterativamente. In ogni iterazione, si utilizza l’output precedente come input per migliorare le stime.\nDopo un numero sufficiente di iterazioni, le stime si stabilizzano (convergenza).\n\nIn conclusione, l’imputazione multipla è una tecnica avanzata che permette di gestire i dati mancanti preservando la qualità delle analisi. Rispetto ai metodi semplici, consente di mantenere la variabilità e ridurre il rischio di bias, rendendola una scelta ideale per analisi psicologiche e di ricerca.\n\n15.2.3.5 Aggiungere i Metadati\nI metadati sono informazioni che descrivono i dati stessi, come etichette di variabili, etichette di valori, informazioni sull’origine dei dati, unità di misura e altro ancora. Questi metadati sono essenziali per comprendere, documentare e condividere correttamente un dataset.\nIn R, i metadati sono gestiti in modo molto dettagliato e strutturato attraverso pacchetti come haven, labelled, e Hmisc. Questi pacchetti consentono di associare etichette ai dati, come etichette di variabili e di valori, e persino di gestire i valori mancanti con etichette specifiche.\n\n\nEtichette di variabili: Si possono aggiungere direttamente alle colonne di un DataFrame usando funzioni come labelled::set_variable_labels().\n\nEtichette di valori: Possono essere aggiunte a variabili categoriali utilizzando labelled::labelled().\n\nValori mancanti: In R, è possibile etichettare specifici valori come mancanti usando labelled::na_values&lt;-.\n\nQuesti strumenti rendono molto facile documentare un dataset all’interno del processo di analisi, assicurando che tutte le informazioni critiche sui dati siano facilmente accessibili e ben documentate.\nEsaminiamo un esempio pratico. Consideriamo nuovamente il data set svy:\n\nglimpse(svy)\n#&gt; Rows: 5\n#&gt; Columns: 6\n#&gt; $ stu_id      &lt;int&gt; 1347, 1368, 1377, 1387, 1399\n#&gt; $ grade_level &lt;int&gt; 9, 10, 9, 11, 12\n#&gt; $ math1       &lt;dbl&gt; 2, 3, 4, 3, 4\n#&gt; $ math2       &lt;dbl&gt; 1, 2, 4, 3, 1\n#&gt; $ math3       &lt;dbl&gt; 3, 2, 4, 4, 3\n#&gt; $ math4       &lt;dbl&gt; 3, 2, 4, 4, 1\n\nSi noti che la variabile math2 contiene un valore inamissibile, probabilmente un errore di battitura. Questo fa in modo che math2 sia di tipo char mentre dovrebbe essere una variabile numerica. Correggiamo.\n\n# Correzione di `math2`: Rimuovi valori non validi e converti in numerico\nsvy$math2 &lt;- gsub(\"\\\\n\", \"\", svy$math2)  # Rimuovi caratteri non validi come '\\n'\nsvy$math2 &lt;- as.numeric(svy$math2)      # Converte la variabile in numerico\n\n# Visualizzazione del dataset corretto\nprint(svy)\n#&gt;   stu_id grade_level math1 math2 math3 math4\n#&gt; 1   1347           9     2     1     3     3\n#&gt; 2   1368          10     3     2     2     2\n#&gt; 3   1377           9     4     4     4     4\n#&gt; 4   1387          11     3     3     4     4\n#&gt; 6   1399          12     4     1     3     1\n\nDefiniamo le etichette di valore per le variabili math1:math4.\n\nvalue_labels_math &lt;- set_names(\n  as.numeric(names(c(\n    `1` = \"strongly disagree\",\n    `2` = \"disagree\",\n    `3` = \"agree\",\n    `4` = \"strongly agree\"\n  ))),\n  c(\"strongly disagree\", \"disagree\", \"agree\", \"strongly agree\")\n)\n\nAggiungiamo le etichette di valore alle colonne math1:math4.\n\nsvy &lt;- svy %&gt;%\n  mutate(across(starts_with(\"math\"), ~ labelled(., labels = value_labels_math)))\n\nVerifica delle etichette.\n\nval_labels(svy$math1)\n#&gt; strongly disagree          disagree             agree    strongly agree \n#&gt;                 1                 2                 3                 4\n\n\nsvy\n#&gt;   stu_id grade_level math1 math2 math3 math4\n#&gt; 1   1347           9     2     1     3     3\n#&gt; 2   1368          10     3     2     2     2\n#&gt; 3   1377           9     4     4     4     4\n#&gt; 4   1387          11     3     3     4     4\n#&gt; 6   1399          12     4     1     3     1\n\n\n15.2.3.5.1 Utilizzo delle Etichette in R con Variabili Numeriche\nLe etichette dei valori (value labels) vengono utilizzate per rendere più leggibili e interpretabili le variabili numeriche, associando ad ogni valore un’etichetta descrittiva. Questo approccio è particolarmente utile in ambiti come la ricerca psicologica, dove le risposte ai questionari sono spesso codificate con numeri (ad esempio, 1 = “Strongly Disagree”, 2 = “Disagree”, ecc.) ma rappresentano concetti qualitativi.\nVantaggi dell’Uso delle Etichette\n\n\nChiarezza nelle Analisi: Le etichette descrittive rendono i dati più facilmente comprensibili senza dover ricordare il significato numerico di ciascun valore.\n\n\nDocumentazione Integrata: Permettono di incorporare metadati direttamente nelle variabili, migliorando la trasparenza e riducendo il rischio di interpretazioni errate.\n\nCompatibilità con Software Statistici: Molti strumenti (ad esempio, SPSS o Stata) utilizzano etichette di valori. Il pacchetto haven in R consente di gestire facilmente i dati etichettati esportati/importati da questi software.\n\nManipolazione di Variabili Etichettate\nAnche se una variabile numerica è etichettata con labelled (ad esempio, tramite il pacchetto haven), essa conserva la sua natura numerica e può essere utilizzata in calcoli, modelli statistici, e trasformazioni. Le etichette non alterano il valore sottostante, ma lo arricchiscono con informazioni aggiuntive.\nIn conclusione, le etichette dei valori migliorano l’interpretabilità dei dati senza comprometterne la manipolabilità. Questo approccio è ideale per mantenere le variabili numeriche pienamente funzionali per analisi statistiche, mentre le etichette descrittive forniscono un contesto chiaro e leggibile.\n\n15.2.3.6 Validazione dei Dati\nLa validazione dei dati è un passaggio fondamentale per garantire che il dataset soddisfi i criteri previsti e sia pronto per le analisi successive. Questo processo include il controllo della coerenza e della correttezza dei dati in base a specifiche regole definite dal dizionario dei dati. Alcune verifiche comuni includono:\n\n\nUnicità delle righe: Assicurarsi che ogni riga sia unica, verificando l’assenza di ID duplicati.\n\nValidità degli ID: Controllare che gli ID rientrino in un intervallo previsto (es. numerico).\n\nValori accettabili nelle variabili categoriali: Verificare che variabili come grade_level, int e le colonne math contengano esclusivamente valori appartenenti a un set di valori validi.\n\nIl pacchetto pointblank fornisce strumenti flessibili e intuitivi per eseguire verifiche di validazione e generare report dettagliati. Questo pacchetto consente di:\n\n\nDefinire le regole di validazione: Specificare controlli come unicità, intervalli di valori e appartenenza a insiemi predefiniti.\n\nEseguire i controlli: Applicare le regole di validazione su un dataset per identificare eventuali discrepanze.\n\nGenerare report interattivi: Creare un riepilogo chiaro e visivo dei controlli, evidenziando eventuali errori o anomalie.\n\nCon pointblank, è possibile integrare la validazione dei dati come parte di un workflow strutturato, garantendo la qualità dei dati in modo sistematico e ripetibile.\ncreate_agent(svy) %&gt;%\n  rows_distinct(columns = vars(stu_id)) %&gt;%\n  col_vals_between(columns = c(stu_id), \n                   left = 1300, right = 1400, na_pass = TRUE) %&gt;%\n  col_vals_in_set(columns = c(grade_level), \n                  set = c(9, 10, 11, 12, NA)) %&gt;%\n  col_vals_in_set(columns = c(int),\n                  set = c(0, 1, NA)) %&gt;%\n  col_vals_in_set(columns = c(math1:math4),\n                  set = c(1, 2, 3, 4, NA)) %&gt;%\n  interrogate()\nIl dataset ripulito soddisfa tutte le aspettative delineate da Crystal Lewis.\n\n\nCompleto: Tutti i dati raccolti sono stati inseriti e/o recuperati. Non dovrebbero esserci dati estranei che non appartengono al dataset (come duplicati o partecipanti non autorizzati).\n\nValido: Le variabili rispettano i vincoli definiti nel tuo dizionario dei dati. Ricorda che il dizionario dei dati specifica i nomi delle variabili, i tipi, i range, le categorie e altre informazioni attese.\n\nAccurato: Sebbene non sia sempre possibile determinare l’accuratezza dei valori durante il processo di pulizia dei dati (ovvero, se un valore è realmente corretto o meno), in alcuni casi è possibile valutarla sulla base della conoscenza pregressa riguardante quel partecipante o caso specifico.\n\nCoerente: I valori sono allineati tra le varie fonti. Ad esempio, la data di nascita raccolta attraverso un sondaggio studentesco dovrebbe avere un formato corrispondere alla data di nascita raccolta dal distretto scolastico.\n\nUniforme: I dati sono standardizzati attraverso i moduli e nel tempo. Ad esempio, lo stato di partecipazione ai programmi di pranzo gratuito o a prezzo ridotto è sempre fornito come una variabile numerica con la stessa rappresentazione, oppure il nome della scuola è sempre scritto in modo coerente in tutto il dataset.\n\nDe-identificato: Tutte le informazioni personali identificabili (PII) sono state rimosse dal dataset per proteggere la riservatezza dei partecipanti (se richiesto dal comitato etico/consenso informato).\n\nInterpretabile: I dati hanno nomi di variabili leggibili sia da umani che dal computer, e sono presenti etichette di variabili e valori laddove necessario per facilitare l’interpretazione.\n\nAnalizzabile: Il dataset è in un formato rettangolare (righe e colonne), leggibile dal computer e conforme alle regole di base della struttura dei dati.\n\nUna volta completati i 14 passaggi precedenti, è possibile esportare questo dataset ripulito nella cartella processed per le successive analisi statistiche.\n\n15.2.3.7 Unire e/o aggiungere dati se necessario\nIn questo passaggio, è possibile unire o aggiungere colonne o righe presenti in file diversi. È importante eseguire nuovamente i controlli di validazione dopo l’unione/aggiunta di nuovi dati.\n\n15.2.3.8 Trasformare i dati se necessario\nEsistono vari motivi per cui potrebbe essere utile memorizzare i dati in formato long o wide. In questo passaggio, è possibile ristrutturare i dati secondo le esigenze.\n\n15.2.3.9 Salvare il dataset pulito finale\nL’ultimo passaggio del processo di pulizia consiste nell’esportare o salvare il dataset pulito. Come accennato in precedenza, può essere utile esportare/salvare il dataset in più di un formato di file (ad esempio, un file .csv e un file .parquet).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#organizzazione-dei-file-e-informazioni-aggiuntive",
    "href": "chapters/eda/02_data_cleaning.html#organizzazione-dei-file-e-informazioni-aggiuntive",
    "title": "15  Flusso di lavoro per la pulizia dei dati",
    "section": "\n15.3 Organizzazione dei file e informazioni aggiuntive",
    "text": "15.3 Organizzazione dei file e informazioni aggiuntive\nInfine, è essenziale includere una documentazione adeguata per garantire che le informazioni siano interpretate correttamente, sia da altri utenti che da te stesso, se dovessi tornare a lavorare su questo progetto in futuro. La documentazione minima da fornire dovrebbe includere:\n\n\nDocumentazione a livello di progetto: Questa sezione fornisce informazioni contestuali sul perché e come i dati sono stati raccolti. È utile per chiunque voglia comprendere lo scopo e la metodologia del progetto.\n\nMetadati a livello di progetto: Se condividi i dati in un repository pubblico o privato, è importante includere metadati a livello di progetto. Questi metadati forniscono informazioni dettagliate che facilitano la ricerca, la comprensione e la consultabilità dei dati. I metadati a livello di progetto possono includere descrizioni generali del progetto, parole chiave, e riferimenti bibliografici.\n\nDizionario dei dati: Un documento che descrive tutte le variabili presenti nel dataset, inclusi i loro nomi, tipi, range di valori, categorie e qualsiasi altra informazione rilevante. Questo strumento è fondamentale per chiunque voglia comprendere o analizzare i dati.\n\nREADME: Un file che fornisce una panoramica rapida dei file inclusi nel progetto, spiegando cosa contengono e come sono interconnessi. Il README è spesso il primo documento consultato e serve a orientare l’utente tra i vari file e risorse del progetto. Questa documentazione non solo aiuta a mantenere il progetto organizzato, ma è anche cruciale per facilitare la collaborazione e l’archiviazione a lungo termine.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#dizionario-dei-dati",
    "href": "chapters/eda/02_data_cleaning.html#dizionario-dei-dati",
    "title": "15  Flusso di lavoro per la pulizia dei dati",
    "section": "\n15.4 Dizionario dei Dati",
    "text": "15.4 Dizionario dei Dati\nApprofondiamo qui il problema della creazione del Dizionario dei dati.\nUn dizionario dei dati è un documento che descrive le caratteristiche di ciascuna variabile in un dataset. Include informazioni come il nome della variabile, il tipo di dato, il range di valori, le categorie (per le variabili categoriche), e altre informazioni rilevanti. Questo strumento è essenziale per comprendere e analizzare correttamente il dataset.\nSi presti particolare attenzione alle guide di stile per la denominazione delle variabili e la codifica dei valori delle risposte.\n\n15.4.1 Esempio in R\n\nEcco come tradurre i passi per creare un dizionario dei dati in R, utilizzando il pacchetto tibble per creare il dizionario e writexl o readr per esportarlo in formato .xlsx o .csv.\n\n\nIdentificare le variabili: Elencare tutte le variabili presenti nel dataset.\n\nDescrivere ogni variabile: Per ciascuna variabile, definire il tipo (ad esempio, integer, numeric, character), il range di valori accettabili o le categorie, e fornire una descrizione chiara.\n\nSalvare il dizionario dei dati: Il dizionario può essere salvato in un file .csv o .xlsx per una facile consultazione.\n\nsvy\nCreeremo un dizionario dei dati per un dataset di esempio e lo salveremo sia in formato CSV che Excel.\nlibrary(tibble)\nlibrary(readr)\nlibrary(writexl)\n\n# Creazione del Dizionario dei Dati\ndata_dict &lt;- tibble(\n  `Variable Name` = c(\n    \"stu_id\",\n    \"svy_date\",\n    \"grade_level\",\n    \"math1\",\n    \"math2\",\n    \"math3\",\n    \"math4\"\n  ),\n  `Type` = c(\n    \"integer\",\n    \"datetime\",\n    \"integer\",\n    \"integer\",\n    \"integer\",\n    \"numeric\",\n    \"numeric\"\n  ),\n  `Description` = c(\n    \"Student ID\",\n    \"Survey Date\",\n    \"Grade Level\",\n    \"Math Response 1 (1: Strongly Disagree, 4: Strongly Agree)\",\n    \"Math Response 2 (1: Strongly Disagree, 4: Strongly Agree)\",\n    \"Math Response 3 (1: Strongly Disagree, 4: Strongly Agree)\",\n    \"Math Response 4 (1: Strongly Disagree, 4: Strongly Agree)\"\n  ),\n  `Range/Values` = c(\n    \"1347-1399\",\n    \"2023-02-13 to 2023-02-14\",\n    \"9-12\",\n    \"1-4\",\n    \"1-4\",\n    \"1.0-4.0 (NA allowed)\",\n    \"1.0-4.0 (NA allowed)\"\n  )\n)\n\n# Visualizza il Dizionario dei Dati\nprint(data_dict)\n\n# Salva il Dizionario dei Dati in un file CSV\nwrite_csv(data_dict, here::here(\"data\", \"processed\", \"data_dictionary.csv\"))\n\n# Salva il Dizionario dei Dati in un file Excel\nwrite_xlsx(data_dict, here::here(\"data\", \"processed\", \"data_dictionary.xlsx\"))\nOutput Atteso: file CSV (data_dictionary.csv).\ndata_dict &lt;- rio::import(\n  here::here(\"data\", \"processed\", \"data_dictionary.csv\")\n)\nprint(data_dict)\n\n15.4.1.1 Uso del pacchetto dataMeta\n\nIl pacchetto dataMeta è progettato per generare metadati e dizionari dei dati in modo strutturato.\n\nlibrary(dataMeta)\nlibrary(tibble)\n\n# Descrizioni delle variabili\nvariable_descriptions &lt;- c(\n  \"Student ID\",\n  \"Grade Level\",\n  \"Math Response 1 (1: Strongly Disagree, 4: Strongly Agree)\",\n  \"Math Response 2 (1: Strongly Disagree, 4: Strongly Agree)\",\n  \"Math Response 3 (1: Strongly Disagree, 4: Strongly Agree)\",\n  \"Math Response 4 (1: Strongly Disagree, 4: Strongly Agree)\"\n)\n\nvar_type &lt;- c(1, 0, 0, 0, 0, 0)\n\nlinker &lt;- build_linker(\n  svy, \n  variable_description = variable_descriptions, \n  variable_type = var_type\n)\n\ndict &lt;- build_dict(\n  my.data = svy, \n  linker = linker, \n  option_description = NULL, \n  prompt_varopts = FALSE\n)\n\nkable(dict, format = \"html\", caption = \"Data dictionary for original dataset\")\n\n\nData dictionary for original dataset\n\nvariable_name\nvariable_description\nvariable_options\n\n\n\ngrade_level\nGrade Level\n9 to 12\n\n\nmath1\nMath Response 1 (1: Strongly Disagree, 4: Strongly Agree)\n2 to 4\n\n\nmath2\nMath Response 2 (1: Strongly Disagree, 4: Strongly Agree)\n1 to 4\n\n\nmath3\nMath Response 3 (1: Strongly Disagree, 4: Strongly Agree)\n2 to 4\n\n\nmath4\nMath Response 4 (1: Strongly Disagree, 4: Strongly Agree)\n1 to 4\n\n\nstu_id\nStudent ID\n1347\n\n\n\n\n1368\n\n\n\n\n1377\n\n\n\n\n1387\n\n\n\n\n1399\n\n\n\n\n\n\n15.4.1.2 Uso del pacchetto skimr\n\nIl pacchetto skimr è utile per generare riassunti dettagliati delle variabili, che possono essere utilizzati come base per un dizionario.\n\nlibrary(skimr)\n\n# Riassunto del dataset\nskim_dict &lt;- skim(svy)\n\nkable(skim_dict, format = \"html\", caption = \"Data dictionary for original dataset\")\n\n\nData dictionary for original dataset\n\nskim_type\nskim_variable\nn_missing\ncomplete_rate\nnumeric.mean\nnumeric.sd\nnumeric.p0\nnumeric.p25\nnumeric.p50\nnumeric.p75\nnumeric.p100\nnumeric.hist\n\n\n\nnumeric\nstu_id\n0\n1\n1375.6\n19.7180\n1347\n1368\n1377\n1387\n1399\n▃▁▇▃▃\n\n\nnumeric\ngrade_level\n0\n1\n10.2\n1.3038\n9\n9\n10\n11\n12\n▇▃▁▃▃\n\n\nnumeric\nmath1\n0\n1\n3.2\n0.8367\n2\n3\n3\n4\n4\n▃▁▇▁▇\n\n\nnumeric\nmath2\n0\n1\n2.2\n1.3038\n1\n1\n2\n3\n4\n▇▃▁▃▃\n\n\nnumeric\nmath3\n0\n1\n3.2\n0.8367\n2\n3\n3\n4\n4\n▃▁▇▁▇\n\n\nnumeric\nmath4\n0\n1\n2.8\n1.3038\n1\n2\n3\n4\n4\n▃▃▁▃▇",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#riflessioni-conclusive",
    "href": "chapters/eda/02_data_cleaning.html#riflessioni-conclusive",
    "title": "15  Flusso di lavoro per la pulizia dei dati",
    "section": "\n15.5 Riflessioni Conclusive",
    "text": "15.5 Riflessioni Conclusive\nNel processo di analisi dei dati, la fase di pulizia e pre-elaborazione è cruciale per garantire la qualità e l’integrità dei risultati finali. Sebbene questa fase possa sembrare meno interessante rispetto all’analisi vera e propria, essa costituisce la base su cui si costruiscono tutte le successive elaborazioni e interpretazioni. Attraverso una serie di passaggi strutturati, come quelli illustrati in questo capitolo, è possibile trasformare dati grezzi e disordinati in un dataset pulito, coerente e pronto per l’analisi. La cura nella gestione dei dati, dalla rimozione di duplicati alla creazione di un dizionario dei dati, è fondamentale per ottenere risultati affidabili e riproducibili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#esercizi",
    "href": "chapters/eda/02_data_cleaning.html#esercizi",
    "title": "15  Flusso di lavoro per la pulizia dei dati",
    "section": "\n15.6 Esercizi",
    "text": "15.6 Esercizi\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nIn questo esercizio, applicherai le tecniche di pulizia e preprocessing dei dati utilizzando il dataset SWLS. Il tuo compito è seguire i passaggi descritti per trasformare il dataset in una forma pronta per l’analisi.\nIstruzioni\n\n\nImporta i dati SWLS (Survey of Life Satisfaction Scale). Introduci almeno due dati mancanti nei dati e almeno un duplicato.\n\nControlla i dati: verifica la struttura e individua eventuali anomalie.\n\nPulisci i dati:\n\nRimuovi eventuali duplicati.\nGestisci i valori mancanti in modo appropriato.\nRinomina le variabili per una maggiore chiarezza.\nStandardizza alcune variabili per l’analisi.\n\n\n\nDocumenta le modifiche effettuate.\n\nEsporta il dataset pulito.\n\nConsegna\n\nSalva il tuo file Quarto con il nome swls_cleaning.qmd.\n\nUsa questo header YAML:\n---\ntitle: \"Assegnamento: Pulizia e Preprocessing dei Dati SWLS\"\nauthor: \"Nome Studente\"\ndate: \"2025-08-18\"\nformat: html\n---\n\nAssicurati che il codice sia commentato e spiegato chiaramente.\nEsporta il dataset pulito e allegalo alla consegna.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/02_data_cleaning.html#informazioni-sullambiente-di-sviluppo",
    "title": "15  Flusso di lavoro per la pulizia dei dati",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] skimr_2.2.1           dataMeta_0.1.1        knitr_1.50           \n#&gt;  [4] purrr_1.1.0           pointblank_0.12.2     haven_2.5.5          \n#&gt;  [7] labelled_2.14.1       mice_3.18.0           pillar_1.11.0        \n#&gt; [10] tinytable_0.11.0      patchwork_1.3.1       ggdist_3.3.3         \n#&gt; [13] tidybayes_3.0.7       bayesplot_1.13.0      ggplot2_3.5.2        \n#&gt; [16] reliabilitydiag_0.2.1 priorsense_1.1.0      posterior_1.6.1      \n#&gt; [19] loo_2.8.0             rstan_2.32.7          StanHeaders_2.32.10  \n#&gt; [22] brms_2.22.0           Rcpp_1.1.0            conflicted_1.2.0     \n#&gt; [25] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [28] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [31] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] RColorBrewer_1.1-3   tensorA_0.36.2.1     jsonlite_2.0.0      \n#&gt;  [4] shape_1.4.6.1        magrittr_2.0.3       TH.data_1.1-3       \n#&gt;  [7] estimability_1.5.1   jomo_2.7-6           farver_2.1.2        \n#&gt; [10] nloptr_2.2.1         rmarkdown_2.29       vctrs_0.6.5         \n#&gt; [13] memoise_2.0.1        minqa_1.2.8          base64enc_0.1-3     \n#&gt; [16] htmltools_0.5.8.1    forcats_1.0.0        distributional_0.5.0\n#&gt; [19] curl_6.4.0           broom_1.0.9          mitml_0.4-5         \n#&gt; [22] htmlwidgets_1.6.4    sandwich_3.1-1       emmeans_1.11.2      \n#&gt; [25] zoo_1.8-14           lubridate_1.9.4      cachem_1.1.0        \n#&gt; [28] lifecycle_1.0.4      iterators_1.0.14     pkgconfig_2.0.3     \n#&gt; [31] Matrix_1.7-3         R6_2.6.1             fastmap_1.2.0       \n#&gt; [34] rbibutils_2.3        snakecase_0.11.1     digest_0.6.37       \n#&gt; [37] colorspace_2.1-1     rprojroot_2.1.0      timechange_0.3.0    \n#&gt; [40] abind_1.4-8          compiler_4.5.1       withr_3.0.2         \n#&gt; [43] backports_1.5.0      inline_0.3.21        QuickJSR_1.8.0      \n#&gt; [46] pkgbuild_1.4.8       R.utils_2.13.0       pan_1.9             \n#&gt; [49] MASS_7.3-65          tools_4.5.1          nnet_7.3-20         \n#&gt; [52] R.oo_1.27.1          glue_1.8.0           nlme_3.1-168        \n#&gt; [55] grid_4.5.1           checkmate_2.3.2      generics_0.1.4      \n#&gt; [58] gtable_0.3.6         R.methodsS3_1.8.2    data.table_1.17.8   \n#&gt; [61] hms_1.1.3            utf8_1.2.6           foreach_1.5.2       \n#&gt; [64] stringr_1.5.1        splines_4.5.1        lattice_0.22-7      \n#&gt; [67] survival_3.8-3       tidyselect_1.2.1     reformulas_0.4.1    \n#&gt; [70] arrayhelpers_1.1-0   gridExtra_2.3        V8_6.0.5            \n#&gt; [73] stats4_4.5.1         xfun_0.52            bridgesampling_1.1-2\n#&gt; [76] stringi_1.8.7        pacman_0.5.1         boot_1.3-31         \n#&gt; [79] evaluate_1.0.4       codetools_0.2-20     cli_3.6.5           \n#&gt; [82] blastula_0.3.6       RcppParallel_5.1.10  rpart_4.1.24        \n#&gt; [85] xtable_1.8-4         Rdpack_2.6.4         repr_1.1.7          \n#&gt; [88] coda_0.19-4.1        svUnit_1.0.6         parallel_4.5.1      \n#&gt; [91] rstantools_2.4.0     Brobdingnag_1.2-9    lme4_1.1-37         \n#&gt; [94] glmnet_4.1-10        mvtnorm_1.3-3        scales_1.4.0        \n#&gt; [97] rlang_1.1.6          multcomp_1.4-28",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#bibliografia",
    "href": "chapters/eda/02_data_cleaning.html#bibliografia",
    "title": "15  Flusso di lavoro per la pulizia dei dati",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBuchanan, E. M., Crain, S. E., Cunningham, A. L., Johnson, H. R., Stash, H., Papadatou-Pastou, M., Isager, P. M., Carlsson, R., & Aczel, B. (2021). Getting started creating data dictionaries: How to create a shareable data set. Advances in Methods and Practices in Psychological Science, 4(1), 2515245920928007.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html",
    "href": "chapters/eda/04_exploring_qualitative_data.html",
    "title": "16  Esplorare i dati qualitativi",
    "section": "",
    "text": "Introduzione\nL’analisi esplorativa dei dati (EDA) rappresenta il primo passo di ogni studio empirico. Con grafici e tabelle di frequenza possiamo farci un’idea immediata della distribuzione delle risposte, verificare se i dati sono equilibrati tra categorie, e osservare come certe caratteristiche si combinano. Ad esempio, in un’indagine clinica potremmo voler capire se i livelli di ansia riportati dai pazienti variano in base al genere o alla fascia di età; in uno studio sperimentale, se il successo in un compito dipende dalla condizione a cui il partecipante è stato assegnato.\nIn questo capitolo impareremo dunque a esplorare e visualizzare i dati qualitativi, passando da strumenti descrittivi come le tabelle di frequenza e le percentuali cumulative, fino a grafici più sofisticati (barplot, mosaic plot) che consentono di cogliere a colpo d’occhio le relazioni tra più variabili. L’obiettivo non è soltanto acquisire dimestichezza con le tecniche, ma anche sviluppare un atteggiamento critico, capace di riconoscere i limiti e le potenzialità delle rappresentazioni grafiche quando applicate a dati che riflettono la complessità dell’esperienza psicologica.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#il-dataset-penguins",
    "href": "chapters/eda/04_exploring_qualitative_data.html#il-dataset-penguins",
    "title": "16  Esplorare i dati qualitativi",
    "section": "\n16.1 Il dataset penguins\n",
    "text": "16.1 Il dataset penguins\n\nPer fornire esempi pratici, in questo capitolo utilizzeremo il dataset palmerpenguins, messo a disposizione da Allison Horst. I dati sono stati raccolti e resi disponibili da Dr. Kristen Gorman e dalla Palmer Station, parte del programma di ricerca ecologica a lungo termine Long Term Ecological Research Network. Il dataset contiene informazioni su 344 pinguini, appartenenti a 3 diverse specie, raccolte su 3 isole dell’arcipelago di Palmer, in Antartide. Per semplicità, i dati sono organizzati nel file penguins.csv.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#importare-i-dati",
    "href": "chapters/eda/04_exploring_qualitative_data.html#importare-i-dati",
    "title": "16  Esplorare i dati qualitativi",
    "section": "\n16.2 Importare i Dati",
    "text": "16.2 Importare i Dati\nPossiamo caricare i dati grezzi dal file penguins.csv in un DataFrame con il seguente comando:\n\nd &lt;- rio::import(here::here(\"data\", \"penguins.csv\"))\n\nEsaminiamo i dati.\n\nglimpse(d)\n#&gt; Rows: 344\n#&gt; Columns: 8\n#&gt; $ species           &lt;chr&gt; \"Adelie\", \"Adelie\", \"Adelie\", \"Adelie\", \"Adelie\"…\n#&gt; $ island            &lt;chr&gt; \"Torgersen\", \"Torgersen\", \"Torgersen\", \"Torgerse…\n#&gt; $ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34…\n#&gt; $ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18…\n#&gt; $ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190,…\n#&gt; $ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 34…\n#&gt; $ sex               &lt;chr&gt; \"male\", \"female\", \"female\", NA, \"female\", \"male\"…\n#&gt; $ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, …\n\nPer semplicità, rimuoviamo le righe con valori mancanti con la seguente istruzione:\n\ndf &lt;- d |&gt;\n  drop_na()",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#tabelle-di-contingenza",
    "href": "chapters/eda/04_exploring_qualitative_data.html#tabelle-di-contingenza",
    "title": "16  Esplorare i dati qualitativi",
    "section": "\n16.3 Tabelle di contingenza",
    "text": "16.3 Tabelle di contingenza\nUna tabella di contingenza è uno strumento che riassume i dati di due variabili categoriali, cioè variabili qualitative che assumono valori in un numero finito di categorie. Ogni cella della tabella indica quante osservazioni ricadono in una specifica combinazione di categorie delle due variabili.\nPer esempio, supponiamo di avere due variabili del dataset df:\n\n\nisland: l’isola di provenienza dei pinguini,\n\nspecies: la specie di appartenenza (Adelie, Chinstrap, Gentoo).\n\nCon la funzione tabyl() del pacchetto janitor possiamo costruire una tabella che mostra quante osservazioni appartengono a ciascuna combinazione di isola e specie:\n\ndf |&gt; \n  tabyl(island, species) |&gt; \n  adorn_totals(c(\"row\", \"col\")) \n#&gt;     island Adelie Chinstrap Gentoo Total\n#&gt;     Biscoe     44         0    119   163\n#&gt;      Dream     55        68      0   123\n#&gt;  Torgersen     47         0      0    47\n#&gt;      Total    146        68    119   333\n\nLa tabella risultante riporta la distribuzione di tre specie di pinguini (Adelie, Chinstrap, Gentoo) rispetto a tre isole (Biscoe, Dream, Torgersen).\n\n16.3.1 Interpretazione\n\n\nIsola Biscoe: sono presenti 44 pinguini Adelie e 119 Gentoo. Nessun esemplare Chinstrap.\n\nIsola Dream: ospita 55 pinguini Adelie e 68 Chinstrap, ma nessun Gentoo.\n\nIsola Torgersen: conta solo 47 pinguini Adelie, senza esemplari delle altre specie.\n\n16.3.2 Osservazioni\n\nLa specie Adelie è l’unica distribuita su tutte e tre le isole (44 su Biscoe, 55 su Dream, 47 su Torgersen).\nLa specie Chinstrap compare esclusivamente su Dream (68 esemplari).\nLa specie Gentoo si trova soltanto su Biscoe (119 esemplari).\n\nQuesta tabella evidenzia che la distribuzione delle specie non è uniforme: alcune sono presenti solo in determinate isole, mentre altre (come gli Adelie) sono più diffuse. In termini di analisi esplorativa, le tabelle di contingenza permettono quindi di individuare pattern e differenze tra categorie, fornendo una prima descrizione della relazione tra due variabili qualitative.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#grafico-a-barre",
    "href": "chapters/eda/04_exploring_qualitative_data.html#grafico-a-barre",
    "title": "16  Esplorare i dati qualitativi",
    "section": "\n16.4 Grafico a barre",
    "text": "16.4 Grafico a barre\n\n16.4.1 Grafico a Barre con una Singola Variabile\nUn grafico a barre è uno strumento comunemente utilizzato per rappresentare visivamente una singola variabile categoriale. Questo tipo di grafico mostra le diverse categorie su uno degli assi (solitamente l’asse orizzontale) e utilizza barre di altezza proporzionale per rappresentare la frequenza o il conteggio di ciascuna categoria sull’altro asse (solitamente l’asse verticale).\nAd esempio, in un dataset che contiene informazioni su diverse specie di pinguini, un grafico a barre potrebbe mostrare il numero di pinguini per ciascuna specie. Le specie vengono visualizzate come etichette lungo l’asse delle ascisse, mentre l’altezza delle barre rappresenta il numero di pinguini osservati per ciascuna specie.\nIl grafico a barre consente di confrontare le dimensioni delle categorie in modo semplice e intuitivo.\nPer i dati in esame, creiamo un grafico a barre che rappresenta il numero totale di pinguini per isola.\n\nggplot(df, aes(x = island)) +\n  geom_bar() +\n  ggtitle(\"Numero totale di pinguini per isola\") +\n  xlab(\"Isola\") +\n  ylab(\"Numero di pinguini\") \n\n\n\n\n\n\n\nUn secondo grafico a barre mostra il numero totale di pinguini per specie.\n\nggplot(df, aes(x = species)) +\n  geom_bar() +\n  ggtitle(\"Numero totale di pinguini per specie\") +\n  xlab(\"Specie\") +\n  ylab(\"Numero di pinguini\")\n\n\n\n\n\n\n\n\n16.4.2 Grafico a Barre con Due Variabili\nÈ possibile visualizzare contemporaneamente le distribuzioni di due variabili categoriali utilizzando un grafico a barre. Questo tipo di grafico è particolarmente utile per esaminare la relazione tra due variabili categoriali.\nIn un grafico a barre con due variabili, una delle variabili viene rappresentata sull’asse orizzontale come categoria principale, mentre la seconda variabile è distinta tramite colori diversi o barre impilate. In questo modo, possiamo confrontare facilmente le frequenze o le proporzioni delle categorie della prima variabile, osservando allo stesso tempo come sono distribuite le categorie della seconda variabile all’interno di ciascuna categoria principale.\nAd esempio, visualizziamo il numero di pinguini per specie e isola. A qusto fine possiamo creare un grafico a barre dove le isole sono rappresentate sull’asse delle ascisse e i diversi colori delle barre mostrano la distribuzione delle specie su ciascuna isola. Questo approccio consente di esplorare come le due variabili categoriali (specie e isola) interagiscono visivamente.\n\nggplot(df, aes(x = island, fill = species)) +\n  geom_bar(position = \"stack\") +\n  ggtitle(\"Numero di pinguini per specie e isola\") +\n  xlab(\"Isola\") +\n  ylab(\"Numero di pinguini\") +\n  labs(fill = \"Specie\") \n\n\n\n\n\n\n\nIn alternativa, è possibile creare un grafico a barre dove le specie sono rappresentate sull’asse delle ascisse e i diversi colori delle barre mostrano la distribuzione delle isole per ciascuna specie.\n\nggplot(df, aes(x = species, fill = island)) +\n  geom_bar(position = \"stack\") +\n  ggtitle(\"Numero di pinguini per isola e specie\") +\n  xlab(\"Specie\") +\n  ylab(\"Numero di pinguini\") +\n  labs(fill = \"Isola\")\n\n\n\n\n\n\n\nIn alternativa all’uso delle frequenze assolute, possiamo rappresentare i dati utilizzando le frequenze relative. Questo approccio permette di confrontare meglio le categorie indipendentemente dal numero totale di osservazioni. Nella figura seguente, ad esempio, viene mostrata la proporzione di pinguini di ciascuna specie per ogni isola, evidenziando la distribuzione relativa delle specie su ogni isola, anziché il conteggio assoluto. Questa rappresentazione aiuta a visualizzare le differenze nella composizione delle specie, anche se il numero complessivo di pinguini varia tra le isole.\n\nggplot(df, aes(x = island, fill = species)) +\n  geom_bar(position = \"fill\") +\n  ggtitle(\"Proporzione di pinguini per specie e isola\") +\n  xlab(\"Isola\") +\n  ylab(\"Proporzione\") +\n  labs(fill = \"Specie\")",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#mosaic-plots",
    "href": "chapters/eda/04_exploring_qualitative_data.html#mosaic-plots",
    "title": "16  Esplorare i dati qualitativi",
    "section": "\n16.5 Mosaic plots",
    "text": "16.5 Mosaic plots\nIl Mosaic plot è una tecnica di visualizzazione particolarmente adatta per rappresentare tabelle di contingenza. Questo tipo di grafico somiglia a un grafico a barre impilate standard, ma con un vantaggio importante: oltre a visualizzare la suddivisione interna delle categorie, permette di vedere anche le dimensioni relative dei gruppi della variabile principale.\nIn altre parole, il Mosaic plot non solo mostra come si distribuiscono le categorie di una variabile secondaria all’interno di ogni gruppo della variabile principale, ma fornisce anche un’idea visiva della grandezza complessiva dei gruppi. Questo lo rende uno strumento utile per analizzare e interpretare le relazioni tra due variabili categoriali, evidenziando sia la proporzione all’interno di ciascun gruppo, sia la grandezza relativa tra i gruppi stessi.\n\nmosaic(\n  ~ species + island, \n  data = df, \n  main = \"Mosaic Plot of Species and Island\",\n  shade = TRUE\n)\n\n\n\n\n\n\n\n\n\nisland: Variabile rappresentata come suddivisione orizzontale all’interno di ogni gruppo di species (variabile principale).\n\nspecies: Variabile rappresentata lungo l’asse verticale (variabile secondaria suddivisa all’interno di ogni gruppo di island).\n\n\n16.5.0.1 Interpretazione\n\n\nDimensione dei Rettangoli:\n\nLa larghezza dei rettangoli corrisponde alla dimensione relativa dei gruppi della variabile island.\nL’altezza dei rettangoli rappresenta la proporzione delle categorie di species all’interno di ciascun gruppo di island.\n\n\n\nColorazione (se shade = TRUE):\n\nI colori indicano deviazioni rispetto all’indipendenza statistica tra le variabili.\nUn rettangolo scuro rappresenta una frequenza maggiore o minore di quella attesa in caso di indipendenza tra species e island.\n\n\n\nOsservazioni Specifiche:\n\n\nRettangoli alti e larghi: Indicano una categoria di species molto rappresentata su un’isola specifica.\n\nRettangoli sottili o stretti: Indicano una rappresentazione meno significativa o assente di una specie su un’isola.\n\n\n\nIn conclusione, il Mosaic plot è uno strumento grafico efficace per analizzare le relazioni tra due variabili categoriali. Ti permette di esplorare:\n\nLa proporzione interna delle categorie.\nLe dimensioni relative dei gruppi della variabile principale.\n\nQuesto grafico è particolarmente utile per individuare schemi o associazioni, come una specie predominante su un’isola specifica o una distribuzione equilibrata tra gruppi. La sua rappresentazione intuitiva lo rende ideale per ricerche in psicologia, scienze sociali e biologia.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#proporzioni-di-riga-e-colonna",
    "href": "chapters/eda/04_exploring_qualitative_data.html#proporzioni-di-riga-e-colonna",
    "title": "16  Esplorare i dati qualitativi",
    "section": "\n16.6 Proporzioni di Riga e Colonna",
    "text": "16.6 Proporzioni di Riga e Colonna\nNelle sezioni precedenti abbiamo esaminato la visualizzazione di due variabili categoriali utilizzando grafici a barre e Mosaic plot. Tuttavia, non abbiamo ancora discusso come vengono calcolate le proporzioni mostrate in questi grafici. In questa sezione ci concentreremo sulla suddivisione frazionaria di una variabile rispetto a un’altra, esplorando come possiamo modificare la nostra tabella di contingenza per ottenere una visione più dettagliata delle proporzioni.\nQuesto ci permetterà di comprendere meglio le relazioni tra le due variabili, visualizzando non solo i conteggi assoluti, ma anche le proporzioni relative per riga o per colonna. Le proporzioni di riga mostrano la distribuzione di una variabile all’interno delle categorie di un’altra, mentre le proporzioni di colonna evidenziano la distribuzione inversa.\nCalcoliamo le proporzioni di specie per isola.\n\ndf %&gt;%\n  tabyl(island, species) %&gt;%  # Crea la tabella di contingenza\n  adorn_percentages(\"row\") %&gt;%  # Calcola le proporzioni per riga\n  adorn_totals(\"col\") %&gt;%  # Aggiunge la colonna dei totali\n  adorn_pct_formatting(digits = 2)  # Formatta le percentuali con 2 decimali\n#&gt;     island  Adelie Chinstrap Gentoo   Total\n#&gt;     Biscoe  26.99%     0.00% 73.01% 100.00%\n#&gt;      Dream  44.72%    55.28%  0.00% 100.00%\n#&gt;  Torgersen 100.00%     0.00%  0.00% 100.00%\n\nCalcoliamo nuovamente le proporzioni, ma questa volta in funzione delle colonne (per isola).\n\ndf |&gt; \n  tabyl(island, species) |&gt; \n  adorn_percentages(\"col\") |&gt; \n  adorn_totals(\"row\") |&gt; \n  adorn_pct_formatting(digits = 2) # Formatta le percentuali con 2 decimali\n#&gt;     island  Adelie Chinstrap  Gentoo\n#&gt;     Biscoe  30.14%     0.00% 100.00%\n#&gt;      Dream  37.67%   100.00%   0.00%\n#&gt;  Torgersen  32.19%     0.00%   0.00%\n#&gt;      Total 100.00%   100.00% 100.00%",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#confronto-tra-gruppi",
    "href": "chapters/eda/04_exploring_qualitative_data.html#confronto-tra-gruppi",
    "title": "16  Esplorare i dati qualitativi",
    "section": "\n16.7 Confronto tra gruppi",
    "text": "16.7 Confronto tra gruppi\nUn aspetto centrale dell’analisi esplorativa consiste nel confrontare gruppi diversi. Questo ci permette di mettere in evidenza differenze e somiglianze, osservare variazioni e individuare tendenze. Il confronto può riguardare:\n\n\nvariabili categoriali tra loro (ad esempio distribuzione di genere nelle diverse specie), oppure\n\nvariabili numeriche rispetto a categorie (ad esempio come varia il peso corporeo tra specie e generi).\n\n\n16.7.1 Confronto tra variabili categoriali\nPer confrontare due variabili qualitative, possiamo utilizzare un grafico a barre con suddivisione per gruppi. Ad esempio, vediamo come si distribuisce il genere dei pinguini (maschio/femmina) all’interno delle tre specie:\n\nggplot(df, aes(x = species, fill = sex)) +\n  geom_bar(position = \"dodge\") +\n  ggtitle(\"Distribuzione del genere per specie\") +\n  xlab(\"Specie\") +\n  ylab(\"Conteggio\")\n\n\n\n\n\n\n\nIn questo grafico le barre affiancate permettono di confrontare facilmente, per ciascuna specie, il numero di maschi e femmine.\n\n16.7.2 Confronto tra variabili numeriche e categorie\nSpesso è ancora più interessante osservare come una variabile numerica varia tra gruppi. Questo approccio ci consente di capire se gruppi diversi tendono ad avere valori simili o differenti.\nPrendiamo come esempio la variabile body_mass_g (peso corporeo in grammi), e confrontiamola in base a specie e genere.\n\nggplot(df, aes(x = species, y = body_mass_g, fill = sex)) +\n  geom_violin(\n    position = position_dodge(width = 0.9), alpha = 0.5\n  ) +\n  geom_boxplot(\n    position = position_dodge(width = 0.9), width = 0.2, alpha = 0.8\n  ) +\n  ggtitle(\n    \"Distribuzione della massa corporea\\nin base alla specie e al genere\"\n  ) +\n  xlab(\"Specie\") +\n  ylab(\"Massa corporea (g)\") +\n  labs(fill = \"Genere\")\n\n\n\n\n\n\n\nQuesto grafico combina due livelli di informazione:\n\n\nGrafico a violino (aree colorate)\n\nMostra l’intera distribuzione dei pesi per ciascun gruppo (specie × genere).\nPiù l’area è larga in un punto, più pinguini hanno un peso vicino a quel valore.\n\n\n\nBoxplot (linee centrali)\n\nRiassume visivamente i dati, mostrando mediana, quartili e variabilità.\nAiuta a confrontare rapidamente i livelli tipici e la dispersione tra gruppi.\n\n\n\n16.7.3 Interpretazione\nDa questo tipo di grafico possiamo osservare:\n\n\nDifferenze tra generi all’interno di una specie: ad esempio, se i maschi tendono a essere più pesanti delle femmine.\n\nDifferenze tra specie: quali specie hanno in generale pinguini più pesanti o più leggeri.\n\nSovrapposizioni: se i pesi di maschi e femmine si distinguono nettamente o se i due gruppi hanno valori simili.\n\nIn questo modo, possiamo individuare sia differenze sistematiche sia aree di variabilità comune tra i gruppi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#esercizi",
    "href": "chapters/eda/04_exploring_qualitative_data.html#esercizi",
    "title": "16  Esplorare i dati qualitativi",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nIn questo esercizio analizzerai i dati qualitativi raccolti mediante la scala SWLS, concentrandoti su due variabili categoriali:\n\n\nGenere (gender): maschio / femmina.\n\nTipo di scuola superiore (school_type): liceo classico o scientifico vs tutto il resto.\n\nDovrai creare tabelle di contingenza e rappresentazioni grafiche per esplorare le relazioni tra queste variabili.\nImportazione dei dati\nImporta i dati da un file CSV e visualizza la loro struttura.\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(here)\n\n# Importa i dati\nswls_data &lt;- read_csv(here(\"data\", \"swls_students.csv\"))\n\n# Esamina i dati\nglimpse(swls_data)\nTabelle di Contingenza\n\nCrea una tabella di contingenza tra gender e school_type.\nCalcola le proporzioni di riga e colonna.\n\n# Tabella di contingenza\nswls_data |&gt; \n  tabyl(gender, school_type) |&gt; \n  adorn_totals(c(\"row\", \"col\"))\nCalcola ora le proporzioni relative.\n# Proporzioni di riga\nswls_data |&gt; \n  tabyl(gender, school_type) |&gt; \n  adorn_percentages(\"row\") |&gt; \n  adorn_pct_formatting(digits = 2)\n# Proporzioni di colonna\nswls_data |&gt; \n  tabyl(gender, school_type) |&gt; \n  adorn_percentages(\"col\") |&gt; \n  adorn_pct_formatting(digits = 2)\nVisualizzazione Grafica\n\nCrea un grafico a barre per visualizzare il numero di studenti per tipo di scuola.\nCrea un grafico a barre per la distribuzione del genere per tipo di scuola.\n\nggplot(swls_data, aes(x = school_type)) +\n  geom_bar() +\n  ggtitle(\"Numero di studenti per tipo di scuola\") +\n  xlab(\"Tipo di scuola\") +\n  ylab(\"Numero di studenti\")\nggplot(swls_data, aes(x = school_type, fill = gender)) +\n  geom_bar(position = \"dodge\") +\n  ggtitle(\"Distribuzione del genere per tipo di scuola\") +\n  xlab(\"Tipo di scuola\") +\n  ylab(\"Numero di studenti\") +\n  labs(fill = \"Genere\")\nDomande per la riflessione\n\nQuale tipo di scuola ha il maggior numero di studenti?\nCi sono differenze nella distribuzione del genere tra i tipi di scuola?\n\nConsegna\n\nCompila il file .qmd con il tuo codice e commenti.\nEsporta il documento in formato HTML o PDF.\nCarica il file su Moodle.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/04_exploring_qualitative_data.html#informazioni-sullambiente-di-sviluppo",
    "title": "16  Esplorare i dati qualitativi",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] grid      stats     graphics  grDevices utils     datasets  methods  \n#&gt; [8] base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] vcd_1.4-13            viridis_0.6.5         viridisLite_0.4.2    \n#&gt;  [4] pillar_1.11.0         tinytable_0.11.0      patchwork_1.3.1      \n#&gt;  [7] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.13.0     \n#&gt; [10] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.0     \n#&gt; [13] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [16] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [19] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [22] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [25] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3        inline_0.3.21        sandwich_3.1-1      \n#&gt;  [4] rlang_1.1.6          magrittr_2.0.3       multcomp_1.4-28     \n#&gt;  [7] snakecase_0.11.1     compiler_4.5.1       vctrs_0.6.5         \n#&gt; [10] stringr_1.5.1        pkgconfig_2.0.3      arrayhelpers_1.1-0  \n#&gt; [13] fastmap_1.2.0        backports_1.5.0      labeling_0.4.3      \n#&gt; [16] rmarkdown_2.29       purrr_1.1.0          xfun_0.52           \n#&gt; [19] cachem_1.1.0         jsonlite_2.0.0       broom_1.0.9         \n#&gt; [22] parallel_4.5.1       R6_2.6.1             stringi_1.8.7       \n#&gt; [25] RColorBrewer_1.1-3   lmtest_0.9-40        lubridate_1.9.4     \n#&gt; [28] estimability_1.5.1   knitr_1.50           zoo_1.8-14          \n#&gt; [31] pacman_0.5.1         R.utils_2.13.0       Matrix_1.7-3        \n#&gt; [34] splines_4.5.1        timechange_0.3.0     tidyselect_1.2.1    \n#&gt; [37] abind_1.4-8          yaml_2.3.10          codetools_0.2-20    \n#&gt; [40] curl_6.4.0           pkgbuild_1.4.8       lattice_0.22-7      \n#&gt; [43] withr_3.0.2          bridgesampling_1.1-2 coda_0.19-4.1       \n#&gt; [46] evaluate_1.0.4       survival_3.8-3       RcppParallel_5.1.10 \n#&gt; [49] tensorA_0.36.2.1     checkmate_2.3.2      stats4_4.5.1        \n#&gt; [52] distributional_0.5.0 generics_0.1.4       rprojroot_2.1.0     \n#&gt; [55] rstantools_2.4.0     scales_1.4.0         xtable_1.8-4        \n#&gt; [58] glue_1.8.0           emmeans_1.11.2       tools_4.5.1         \n#&gt; [61] data.table_1.17.8    mvtnorm_1.3-3        QuickJSR_1.8.0      \n#&gt; [64] colorspace_2.1-1     nlme_3.1-168         cli_3.6.5           \n#&gt; [67] svUnit_1.0.6         Brobdingnag_1.2-9    V8_6.0.5            \n#&gt; [70] gtable_0.3.6         R.methodsS3_1.8.2    digest_0.6.37       \n#&gt; [73] TH.data_1.1-3        htmlwidgets_1.6.4    farver_2.1.2        \n#&gt; [76] memoise_2.0.1        htmltools_0.5.8.1    R.oo_1.27.1         \n#&gt; [79] lifecycle_1.0.4      MASS_7.3-65",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html",
    "href": "chapters/eda/05_exploring_numeric_data.html",
    "title": "17  Esplorare i dati numerici",
    "section": "",
    "text": "Introduzione",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#i-dati-sulle-aspettative-negative-nella-depressione",
    "href": "chapters/eda/05_exploring_numeric_data.html#i-dati-sulle-aspettative-negative-nella-depressione",
    "title": "17  Esplorare i dati numerici",
    "section": "\n17.1 I dati sulle aspettative negative nella depressione",
    "text": "17.1 I dati sulle aspettative negative nella depressione\nConsideriamo i dati relativi alle aspettative negative, individuate come un meccanismo chiave nel mantenimento della depressione (Zetsche et al., 2019). Supponiamo di voler analizzare la distribuzione di una singola variabile quantitativa.\nImportiamo i dati:\n\ndf &lt;- rio::import(here::here(\"data\", \"data.mood.csv\"))\n\n\n17.1.1 Data Wrangling\nPer questo esercizio, ci concentreremo sulle variabili esm_id (il codice del soggetto), group (il gruppo) e bdi (il valore BDI-II).\n\ndf &lt;- df |&gt; \n  dplyr::select(\"esm_id\", \"group\", \"bdi\")\ndf |&gt; \n  head()\n#&gt;   esm_id group bdi\n#&gt; 1     10   mdd  25\n#&gt; 2     10   mdd  25\n#&gt; 3     10   mdd  25\n#&gt; 4     10   mdd  25\n#&gt; 5     10   mdd  25\n#&gt; 6     10   mdd  25\n\nSe elenchiamo le modalità presenti in group utilizzando il metodo unique(), scopriamo che corrispondono a mdd (pazienti) e ctl (controlli sani).\n\ndf$group |&gt; \n  unique()\n#&gt; [1] \"mdd\" \"ctl\"\n\nRimuoviamo i duplicati per ottenere un unico valore BDI-II per ogni soggetto:\n\ndf &lt;- df[!duplicated(df), ]\n\nVerifichiamo di avere ottenuto il risultato desiderato.\n\ndim(df)\n#&gt; [1] 67  3\n\n\nhead(df)\n#&gt;    esm_id group bdi\n#&gt; 1      10   mdd  25\n#&gt; 15      9   mdd  30\n#&gt; 30      6   mdd  26\n#&gt; 46      7   mdd  35\n#&gt; 65     12   mdd  44\n#&gt; 83     16   mdd  30\n\nSi noti che il nuovo DataFrame (con 67 righe) conserva il “nome” delle righe (ovvero, l’indice di riga) del DataFrame originario (con 1188 righe). Per esempio, il secondo soggetto (con codice identificativo 9) si trova sulla seconda riga del DataFrame, ma il suo indice di riga è 15. Questo non ha nessuna conseguenza perché non useremo l’indice di riga nelle analisi seguenti.\nEliminiamo eventuali valori mancanti:\n\ndf &lt;- df[!is.na(df$bdi), ]\n\nOtteniamo così il DataFrame finale per gli scopi presenti (66 righe e 3 colonne):\n\ndim(df)\n#&gt; [1] 66  3\n\n\n17.1.2 Anteprima dei Dati\nPrima di approfondire l’analisi, è fondamentale esaminare una anteprima dei dati per comprenderne struttura, formati e potenziali anomalie.\nLa funzione glimpse()\n\nglimpse(df)  \n#&gt; Rows: 66\n#&gt; Columns: 3\n#&gt; $ esm_id &lt;int&gt; 10, 9, 6, 7, 12, 16, 21, 18, 20, 22, 23, 25, 24, 26, 41, 31…\n#&gt; $ group  &lt;chr&gt; \"mdd\", \"mdd\", \"mdd\", \"mdd\", \"mdd\", \"mdd\", \"mdd\", \"mdd\", \"md…\n#&gt; $ bdi    &lt;int&gt; 25, 30, 26, 35, 44, 30, 22, 33, 43, 43, 24, 39, 19, 3, 0, 2…\n\nFornisce una panoramica compatta del dataset: numero di righe/colonne, tipo di variabili (es. chr, num, dbl) ed esempi di valori. Utile per identificare rapidamente formati errati o colonne non attese.\nLa funzione summary()\n\nsummary(df)  \n#&gt;      esm_id         group                bdi       \n#&gt;  Min.   :  6.0   Length:66          Min.   : 0.00  \n#&gt;  1st Qu.: 30.2   Class :character   1st Qu.: 0.25  \n#&gt;  Median : 46.5   Mode  :character   Median : 6.00  \n#&gt;  Mean   : 51.6                      Mean   :14.94  \n#&gt;  3rd Qu.: 76.8                      3rd Qu.:29.50  \n#&gt;  Max.   :104.0                      Max.   :44.00\n\nGenera statistiche descrittive per ogni colonna:\n\nPer variabili numeriche: media, mediana, quartili, min/max.\n\nPer variabili categoriche: frequenza dei livelli.\n\nSegnala valori mancanti (NA), aiutando a valutare la qualità dei dati.\n\nI comandi head() e tail() ci permettono di visualizzare le prime o le ultime righe di un dataset.\n\nhead(df)\n#&gt;    esm_id group bdi\n#&gt; 1      10   mdd  25\n#&gt; 15      9   mdd  30\n#&gt; 30      6   mdd  26\n#&gt; 46      7   mdd  35\n#&gt; 65     12   mdd  44\n#&gt; 83     16   mdd  30\n\n\ntail(df)\n#&gt;      esm_id group bdi\n#&gt; 1087    101   ctl   9\n#&gt; 1105     99   ctl   0\n#&gt; 1121    100   ctl   2\n#&gt; 1133    104   ctl   0\n#&gt; 1152    103   ctl   0\n#&gt; 1171    102   ctl   1\n\n\n17.1.3 Conversione da char a factor\n\nIn R, i tipi di dato character e factor rappresentano informazioni testuali, ma hanno utilizzi distinti:\n\n\ncharacter: è una semplice stringa di testo;\n\nfactor: è una variabile categoriale, ideale per rappresentare dati con un numero finito di categorie (livelli). I dati in formato factor sono utili per analisi statistiche, poiché trattano i valori come categorie discrete.\n\nNel seguente esempio, convertiamo una variabile group da character a factor, in modo da poterla utilizzare come variabile categoriale:\ndf$group &lt;- as.factor(df$group)  # Converte 'group' in un factor\nSuccessivamente, il comando summary() fornisce un riepilogo della variabile categoriale, mostrando il conteggio dei valori per ciascun livello:\nsummary(df$group)",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#distribuzioni-di-frequenza",
    "href": "chapters/eda/05_exploring_numeric_data.html#distribuzioni-di-frequenza",
    "title": "17  Esplorare i dati numerici",
    "section": "\n17.2 Distribuzioni di Frequenza",
    "text": "17.2 Distribuzioni di Frequenza\nLe distribuzioni di frequenza sono strumenti essenziali per visualizzare e comprendere la variabilità di una variabile. In questo capitolo verrà illustrato come costruire una distribuzione di frequenza e, successivamente, come generare in R una distribuzione cumulativa empirica, un istogramma, un Kernel Density Plot e un boxplot.\nA titolo esemplificativo, consideriamo i punteggi del BDI-II. Iniziamo ordinando i dati in ordine crescente:\n\ndf$bdi |&gt; sort()\n#&gt;  [1]  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  1  1  1  1  1\n#&gt; [25]  1  2  2  2  2  3  3  3  5  7  9 12 19 22 22 24 25 25 26 26 26 27 27 28\n#&gt; [49] 28 30 30 30 31 31 33 33 34 35 35 35 36 39 41 43 43 44\n\nUna distribuzione di frequenza evidenzia quante volte i valori di una variabile ricorrono in determinati intervalli. Ad esempio, per i punteggi del BDI-II è consuetudine raggruppare i dati nelle seguenti classi:\n\n\n0–13: depressione minima\n\n14–19: depressione lieve-moderata\n\n20–28: depressione moderata-severa\n\n29–63: depressione severa\n\nDefinendo ciascuna classe, indicata con \\(\\Delta_i\\), come un intervallo \\([a_i, b_i)\\) o \\((a_i, b_i]\\), possiamo calcolare le seguenti misure:\n\n\nFrequenza assoluta (\\(n_i\\)): numero di osservazioni in \\(\\Delta_i\\). La somma delle frequenze assolute corrisponde al totale delle osservazioni, \\(n\\).\n\nFrequenza relativa (\\(f_i\\)): proporzione di osservazioni in \\(\\Delta_i\\), calcolata come \\(f_i = n_i/n\\); la somma delle frequenze relative è pari a 1.\n\nFrequenza cumulata (\\(N_i\\)): somma delle frequenze assolute fino alla classe \\(i\\), ovvero \\(N_i = \\sum_{j=1}^i n_j\\).\n\nFrequenza cumulata relativa (\\(F_i\\)): somma delle frequenze relative fino alla classe \\(i\\), data da \\(F_i = \\sum_{j=1}^i f_j\\).\n\nQueste misure consentono di sintetizzare la distribuzione dei punteggi, facilitando l’interpretazione delle caratteristiche del campione.\n\n17.2.1 Frequenze Assolute e Relative\nPer analizzare la distribuzione dei punteggi BDI-II nel dataset di Zetsche et al. (2019), è utile creare una variabile categoriale che classifichi ogni osservazione in una delle quattro classi di gravità della depressione. A tal fine, utilizziamo la funzione cut(), che permette di suddividere il vettore dei punteggi (bdi) in intervalli definiti.\nNel comando seguente, il parametro breaks specifica i limiti degli intervalli, mentre include.lowest = TRUE garantisce che il valore minimo sia incluso nel primo intervallo:\n\n# Creazione della variabile categoriale per i livelli di depressione\ndf &lt;- df %&gt;% \n  mutate(\n    bdi_class = cut(\n      bdi, \n      breaks = c(0, 13.5, 19.5, 28.5, 63),\n      include.lowest = TRUE\n    )\n  )\n\nI punteggi vengono suddivisi nelle seguenti classi:\n\n\n0–13: depressione minima\n\n14–19: depressione lieve-moderata\n\n20–28: depressione moderata-severa\n\n29–63: depressione severa\n\nUna volta creata la variabile bdi_class, possiamo calcolare le frequenze assolute e relative.\n\n17.2.1.1 Frequenze Assolute\nUtilizzando la funzione table(), si ottiene il numero di osservazioni in ciascuna classe:\n\ntable(df$bdi_class)\n#&gt; \n#&gt;    [0,13.5] (13.5,19.5] (19.5,28.5]   (28.5,63] \n#&gt;          36           1          12          17\n\n\n17.2.1.2 Frequenze Relative\nCon prop.table() è possibile determinare la proporzione di osservazioni per ogni classe:\n\nprop.table(table(df$bdi_class))\n#&gt; \n#&gt;    [0,13.5] (13.5,19.5] (19.5,28.5]   (28.5,63] \n#&gt;     0.54545     0.01515     0.18182     0.25758\n\n\n17.2.2 Distribuzioni Congiunte\nLe distribuzioni congiunte di frequenze permettono di analizzare la relazione tra due variabili, considerando tutte le possibili combinazioni dei loro valori. Ad esempio, se analizziamo le variabili bdi_class e group, la tabella congiunta mostrerà la frequenza (assoluta o relativa) per ogni coppia di valori.\nPer ottenere la distribuzione congiunta relativa, utilizziamo:\n\nprop.table(table(df$bdi_class, df$group))\n#&gt;              \n#&gt;                   ctl     mdd\n#&gt;   [0,13.5]    0.54545 0.00000\n#&gt;   (13.5,19.5] 0.00000 0.01515\n#&gt;   (19.5,28.5] 0.00000 0.18182\n#&gt;   (28.5,63]   0.00000 0.25758\n\nIn questo modo, possiamo esaminare come le classi di punteggi BDI-II si distribuiscono all’interno dei diversi gruppi, con la somma complessiva delle frequenze relative pari a 1.\n\n17.2.3 La Distribuzione Cumulativa Empirica\nLa distribuzione cumulativa empirica (eCDF, empirical Cumulative Distribution Function) è un modo utile per rappresentare la distribuzione di dati numerici. Questa funzione indica la proporzione di dati che sono inferiori o uguali a un certo valore \\(a\\), per tutti i possibili valori di \\(a\\). Matematicamente, la eCDF è definita come:\n\\[\nF(a) = \\text{Proporzione dei dati con valore} \\leq a.\n\\]\nIn altre parole, la eCDF ci dice quale frazione dei dati osservati è minore o uguale a un determinato valore \\(a\\). Questo è particolarmente utile per comprendere come i dati sono distribuiti e per identificare pattern o caratteristiche specifiche della distribuzione, come la presenza di bimodalità (cioè, due picchi distinti nella distribuzione).\n\n17.2.3.1 Esempio con i dati di Zetsche et al. (2019)\n\nNel contesto dei dati di Zetsche et al. (2019), possiamo utilizzare la eCDF per visualizzare la distribuzione dei punteggi BDI-II. Ecco come viene rappresentata la eCDF per l’intero dataset:\n\ndf |&gt; \n  ggplot(aes(bdi)) + \n  stat_ecdf() +\n  labs(x = \"BDI\", y = \"F(BDI)\")\n\n\n\n\n\n\n\nIn questo grafico:\n\nL’asse \\(x\\) rappresenta i valori del BDI-II.\nL’asse \\(y\\) rappresenta la proporzione cumulativa dei dati, cioè \\(F(a)\\).\n\n17.2.3.2 Interpretazione del grafico\n\n\nCrescita della curva: La curva della eCDF parte da 0 (nessun dato è inferiore al valore minimo osservato) e cresce gradualmente fino a 1 (tutti i dati sono inferiori o uguali al valore massimo osservato).\n\nBimodalità: Se la curva presenta dei “gradini” o delle aree con una pendenza più ripida, questo può indicare la presenza di bimodalità, ovvero due gruppi distinti di dati con caratteristiche diverse. Nel caso dei dati BDI-II, la bimodalità potrebbe riflettere la presenza di due sottogruppi di partecipanti con livelli di depressione diversi.\n\n17.2.3.3 Filtrare i dati per il campione clinico\nSe vogliamo analizzare solo i dati relativi al campione clinico (ad esempio, i pazienti con depressione maggiore), possiamo filtrare i dati e rappresentare la eCDF solo per questo gruppo:\n\ndf |&gt; dplyr::filter(group == \"mdd\") |&gt; \n  ggplot(aes(bdi)) + \n  stat_ecdf() +\n  labs(x = \"a\", y = \"F(a)\")\n\n\n\n\n\n\n\nIn questo caso, la eCDF ci mostrerà come i punteggi BDI-II sono distribuiti tra i pazienti con depressione maggiore, permettendoci di identificare eventuali pattern specifici per questo gruppo.\nIn sintesi, la eCDF è uno strumento potente per analizzare e visualizzare la distribuzione di dati numerici, specialmente quando si vogliono identificare pattern specifici o confrontare distribuzioni tra diversi gruppi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#istogramma",
    "href": "chapters/eda/05_exploring_numeric_data.html#istogramma",
    "title": "17  Esplorare i dati numerici",
    "section": "\n17.3 Istogramma",
    "text": "17.3 Istogramma\nSebbene il concetto di Funzione di Distribuzione Empirica Cumulativa (eCDF) venga ampiamente discusso nei testi di statistica, in pratica tale rappresentazione non è molto diffusa. Il motivo principale è che l’eCDF non rende immediatamente visibili alcune caratteristiche fondamentali della distribuzione, come il valore intorno al quale essa è centrata, se la distribuzione sia simmetrica o quali intervalli contengano il 95% dei dati, ad esempio. Gli istogrammi, invece, sono molto più utilizzati perché facilitano notevolmente la comprensione di queste proprietà, sacrificando solo un po’ di informazione per fornire una rappresentazione più intuitiva.\nUn istogramma è un grafico che rappresenta la distribuzione delle frequenze di una variabile. Sull’asse orizzontale (ascisse) vengono indicati i limiti delle classi \\(\\Delta_i\\), mentre sull’asse verticale (ordinate) si riporta la densità della frequenza relativa della variabile \\(X\\) per ciascuna classe \\(\\Delta_i\\).\nPer descrivere formalmente la densità della frequenza relativa, si utilizza una funzione costante a tratti definita come:\n\\[\n\\varphi_n(x) = \\frac{f_i}{b_i - a_i},\n\\]\ndove:\n\n\n\\(f_i\\) è la frequenza relativa della classe \\(\\Delta_i\\),\n\n\\(b_i - a_i\\) è l’ampiezza della classe \\(\\Delta_i\\).\n\nIn questo modo, l’area del rettangolo corrispondente a \\(\\Delta_i\\) in un istogramma risulta proporzionale alla frequenza relativa \\(f_i\\). Poiché la somma delle frequenze relative deve essere pari a 1, l’area totale di un istogramma delle frequenze relative risulta anch’essa uguale a 1, corrispondendo alla somma delle aree di tutti i rettangoli.\nGli istogrammi costituiscono quindi uno strumento essenziale per visualizzare e comprendere le principali caratteristiche di una distribuzione, agevolando l’analisi della sua forma, della sua tendenza centrale e della sua dispersione.\nPer fare un esempio, costruiamo un istogramma per i valori BDI-II di Zetsche et al. (2019). Con i quattro intervalli individuati dai cut-off del BDI-II creiamo una prima versione dell’istogramma – si notino le frequenze assolute sull’asse delle ordinate.\n\nggplot(df, aes(x = bdi)) +\n  geom_histogram(\n    breaks = c(0, 13.5, 19.5, 28.5, 63),\n    aes(y = after_stat(density)),  # oppure after_stat(count / sum(count))\n    fill = palette_set1[\"due\"],    # usa un colore coerente dal tuo setup\n    color = \"white\",               # bordi bianchi per leggibilità\n    linewidth = 0.5\n  ) +\n  labs(\n    title = \"Istogramma delle frequenze relative\", \n    x = \"BDI-II\", \n    y = \"Densità\"\n  ) +\n  theme(\n    plot.title = element_text(face = \"bold\"),\n    axis.title = element_text(size = 12)\n  )\n\n\n\n\n\n\n\nAnche se nel caso presente è sensato usare ampiezze diverse per gli intervalli delle classi, in generale gli istogrammi si costruiscono utilizzando intervalli riportati sulle ascisse con un’ampiezza uguale.\n\nggplot(df, aes(x = bdi)) +\n  geom_histogram(\n    aes(y = after_stat(density)),\n    fill = palette_set1[\"due\"],\n    color = \"white\"\n  ) +\n  labs(\n    title = \"Istogramma delle frequenze relative\", \n    x = \"BDI-II\", \n    y = \"Densità\"\n  )",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#kernel-density-plot",
    "href": "chapters/eda/05_exploring_numeric_data.html#kernel-density-plot",
    "title": "17  Esplorare i dati numerici",
    "section": "\n17.4 Kernel Density Plot",
    "text": "17.4 Kernel Density Plot\nUn limite evidente degli istogrammi è che la loro forma dipende da scelte arbitrarie: il numero e l’ampiezza delle classi (o bin) può infatti influenzare in modo sostanziale l’aspetto finale del grafico, rendendo più difficile l’interpretazione della distribuzione dei dati. Una soluzione a questo problema è offerta dalla stima della densità kernel (Kernel Density Estimation, KDE), un metodo che fornisce un profilo continuo e smussato della distribuzione, meno condizionato dall’arbitrarietà delle classi.\n\n17.4.1 Differenza tra Istogramma e KDE\nNell’istogramma, dividiamo l’asse orizzontale in intervalli di ampiezza prefissata (i bin) e costruiamo rettangoli la cui altezza è proporzionale alla frequenza (o densità) dei dati che ricadono in ciascun intervallo. Se cambiamo il numero o la larghezza dei bin, la forma dell’istogramma può variare sensibilmente.\nLa KDE, invece, non suddivide i dati in intervalli fissi. Al contrario, “appoggia” una piccola curva (il kernel) su ogni singola osservazione. Le curve utilizzate (ad esempio di tipo gaussiano) hanno una larghezza, detta bandwidth, che controlla il grado di smussamento: con un bandwidth molto piccolo, la stima segue da vicino le singole osservazioni, generando un profilo più frastagliato; con un bandwidth più ampio, la curva risultante è più liscia, ma rischia di nascondere dettagli importanti.\nPer comprendere in modo intuitivo il concetto di KDE, possiamo partire da un esempio semplice. Immaginiamo di costruire un istogramma con classi di ampiezza sempre più piccola. Se avessimo a disposizione un numero enorme di dati (ad esempio, un milione di misurazioni dell’altezza di individui) e li rappresentassimo con bin sempre più stretti (0.1, 0.01, ecc.), l’istogramma diventerebbe sempre più levigato, avvicinandosi a una curva continua. Questo processo illustra l’idea alla base della KDE, che approssima la distribuzione dei dati in modo fluido e continuo.\nLa KDE, tuttavia, opera in modo più elegante e senza richiedere un numero enorme di punti: posiziona un piccolo “dosso di campana” (o un altro tipo di kernel) su ciascun punto dati e somma tutte queste curve in un’unica curva finale.\n\n\n\n\n\n\nChe cosa vuol dire “dosso di campana”?\n\n\n\nPossiamo immaginarlo come una piccola curva gaussiana: una curva simile alla forma di una campana che si innalza e poi discende dolcemente.\n\nOgni singolo dato viene “coperto” da questa mini-campana.\nL’ampiezza (o “larghezza”) della campana è regolata dal bandwidth, che stabilisce se la curva sarà più o meno “distesa” sul grafico.\nSommando tutte le piccole campane (una per ogni osservazione), otteniamo una curva di densità liscia e continua che rappresenta la distribuzione dei dati senza i “salti” tipici dell’istogramma.\n\n\n\nIl risultato è una curva di densità che:\n\n\nÈ continua: a differenza degli istogrammi, non presenta bruschi salti di altezza tra i bin: la curva scorre in modo uniforme lungo tutto l’asse orizzontale.\n\nMostra la proporzione di dati in ogni intervallo: l’area sotto la curva in un determinato range corrisponde alla percentuale (o probabilità) di dati che cadono in quell’intervallo.\n\nDipende dal bandwidth:\n\nUn bandwidth piccolo produce una curva più ondulata e “frastagliata” (poiché segue da vicino ogni singolo dato).\nUn bandwidth grande genera una curva più liscia e arrotondata, ma rischia di “coprire” troppi dettagli della distribuzione originaria.\n\n\n\nSi noti che la stima della densità kernel introduce, tuttavia, un’ipotesi di fondo: che la distribuzione dei dati “reali” sia “liscia” e non presenti discontinuità improvvise. Questo è spesso ragionevole (ad esempio per dati fisiologici come l’altezza), ma in altri casi potrebbe non esserlo. È quindi importante scegliere un bandwidth che rifletta adeguatamente il livello di dettaglio che vogliamo mostrare.\nInoltre, l’asse delle ordinate (l’asse y) rappresenta la densità, non la frequenza assoluta. È possibile costruire un istogramma in cui l’altezza dei rettangoli mostra quante osservazioni ricadono in ciascun bin. Nella KDE, l’altezza della curva è tale che l’area totale sotto di essa sia pari a 1, rispecchiando la natura di una funzione di densità di probabilità.\nDi seguito esaminiamo un esempio che mostra la costruzione passo dopo passo di istogrammi con diversi valori di binwidth, fino a passare a una stima di densità. Consideriemo un dataset con un numero di osservazioni molto elevato (i valori di altezza, heights, riportati da 1050 partecipanti, estratti dal pacchetto dslabs), suddiviso in due gruppi: maschi e femmine. Ecco come potremmo prima costruire un istogramma di altezze per i maschi, per poi tracciare una curva di densità smussata:\n\n# Istogramma con bin di ampiezza 1\nggplot(heights |&gt; dplyr::filter(sex == \"Male\"), aes(height)) +\n  geom_histogram(\n    binwidth = 1, color = \"white\", fill = palette_set1[\"due\"]\n  )\n\n\n\n\n\n\n\n\n# Aggiunta della curva di densità sopra l'istogramma\nggplot(heights |&gt; dplyr::filter(sex == \"Male\"), aes(height)) +\n  geom_histogram(\n    aes(y = after_stat(density)), \n    binwidth = 1, color = \"white\", fill = palette_set1[\"due\"]\n  ) +\n  geom_line(stat = 'density')\n\n\n\n\n\n\n\nVariando il parametro di regolazione (adjust o bandwidth) nella funzione geom_density(), possiamo modificare il livello di smussamento:\n\n# Istogramma base con alpha e colore coerente\np &lt;- ggplot(heights |&gt; filter(sex == \"Male\"), aes(x = height)) +\n  geom_histogram(\n    aes(y = after_stat(density)),\n    binwidth = 1,\n    fill = palette_set1[\"due\"],\n    color = \"white\"\n  ) +\n  labs(\n    title = \"Distribuzione altezze\",\n    x = \"Altezza\",\n    y = \"Densità\"\n  )\n\n# Più ondulato (banda piccola)\np1 &lt;- p +\n  geom_line(stat = \"density\", adjust = 0.5, color = palette_set1[\"uno\"]) +\n  labs(subtitle = \"Smoothing accentuato (adjust = 0.5)\")\n\n# Più liscio (banda larga)\np2 &lt;- p +\n  geom_line(stat = \"density\", adjust = 2, color = palette_set1[\"uno\"]) +\n  labs(subtitle = \"Smoothing attenuato (adjust = 2)\")\n\n# Composizione coerente con patchwork\np1 + p2\n\n\n\n\n\n\n\nPer illustrare ulteriormente l’uso della KDE, ora consideriamo i punteggi BDI-II di Zetsche et al. (2019). Con il codice seguente creiamo due curve di densità, una per ogni gruppo:\n\nggplot(df, aes(x = bdi, fill = group)) +\n  geom_density() +\n  labs(\n    title = \"Curva di densità (KDE) per i punteggi BDI-II\",\n    x = \"BDI-II\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\nQui, la sovrapposizione delle due curve ci consente di confrontare la distribuzione dei punteggi BDI-II tra i due gruppi in maniera molto più fluida e intuitiva rispetto a quanto faremmo con due istogrammi separati o con un istogramma combinato. Inoltre, non siamo più vincolati alla scelta dei bin: l’aspetto delle curve dipende soltanto dalla funzione kernel utilizzata e dal parametro di smussamento.\nIn conclusione,\n\nl’istogramma rimane uno strumento rapido e intuitivo, privo di assunzioni, ma sensibile alla scelta di numero e ampiezza dei bin;\nla stima della densità kernel (KDE) offre una rappresentazione continua della distribuzione dei dati, fornendo un quadro più “morbido” e spesso più informativo. Tuttavia, introduce alcune assunzioni e richiede la scelta del bandwidth ottimale.\n\nIn definitiva, è consigliabile usare entrambe le tecniche per ottenere una panoramica completa dei propri dati: l’istogramma permette di dare un primo sguardo alla loro distribuzione “grezza” (senza presupposti), mentre la KDE aiuta a comprenderne l’eventuale struttura “liscia” di fondo.\n\n17.4.2 Area Sottesa alla Curva di Densità: Un’Interpretazione Probabilistica\nQuando si lavora con una curva di densità, è importante capire che l’area totale sotto la curva rappresenta la probabilità totale, che è sempre pari a 1 (o 100%). Questo significa che l’area sotto la curva in un determinato intervallo corrisponde alla probabilità che un dato valore cada in quell’intervallo.\n\n17.4.2.1 Come Interpretare l’Asse Y\nL’asse y di un grafico di densità non rappresenta direttamente la probabilità, ma è scalato in modo che l’area totale sotto la curva sia uguale a 1. Se immaginiamo di creare un “bin” (un intervallo) con una base di 1 unità di lunghezza, il valore sull’asse y ci indica la proporzione di valori che cadono in quel bin. Tuttavia, questa interpretazione è valida solo per bin di dimensione 1. Per intervalli di altre dimensioni, il modo migliore per determinare la proporzione di dati in quell’intervallo è calcolare la proporzione dell’area totale sotto la curva che cade in quell’intervallo.\n\n17.4.2.2 Esempio Pratico\nConsideriamo un esempio con i dati delle altezze degli uomini. Supponiamo di voler sapere quale proporzione di uomini ha un’altezza compresa tra 65 e 68 pollici. Per farlo, calcoliamo l’area sotto la curva di densità in quell’intervallo.\nEcco come appare graficamente:\n\n\n\n\n\n\n\n\nL’area evidenziata in azzurro rappresenta la proporzione di uomini con altezza tra 65 e 68 pollici. Calcolando questa area, troviamo che circa il 0.3 (ovvero il 30% degli uomini ha un’altezza in questo intervallo.\n\n17.4.2.3 Utilizzo della Curva di Densità come Riepilogo\nComprendendo questo concetto, possiamo utilizzare la curva di densità come un efficace strumento di riepilogo. Per questo dataset, l’assunzione di smoothness (lisciatura) della curva è ragionevole, e possiamo condividere questa rappresentazione grafica per comunicare in modo chiaro e intuitivo la distribuzione delle altezze degli uomini.\nEcco un esempio di come appare la curva di densità smooth per le altezze degli uomini:\n\n\n\n\n\n\n\n\nIn sintesi, l’area sotto la curva di densità in un determinato intervallo rappresenta la probabilità che un valore casuale cada in quell’intervallo, rendendo la curva di densità uno strumento potente per comprendere e comunicare la distribuzione dei dati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#forma-di-una-distribuzione",
    "href": "chapters/eda/05_exploring_numeric_data.html#forma-di-una-distribuzione",
    "title": "17  Esplorare i dati numerici",
    "section": "\n17.5 Forma di una Distribuzione",
    "text": "17.5 Forma di una Distribuzione\nIn statistica, la forma di una distribuzione descrive come i dati sono distribuiti intorno ai valori centrali. Si distingue tra distribuzioni simmetriche e asimmetriche, e tra distribuzioni unimodali e multimodali. Un’illustrazione grafica è fornita nella figura seguente. Nel pannello 1, la distribuzione è unimodale con asimmetria negativa; nel pannello 2, la distribuzione è unimodale con asimmetria positiva; nel pannello 3, la distribuzione è simmetrica e unimodale; nel pannello 4, la distribuzione è bimodale.\n\n\nDistribuzioni\n\nIl grafico della densità di kernel (Kernel Density Plot) dei valori BDI-II nel campione di Zetsche et al. (2019) è bimodale. Questo indica che le osservazioni della distribuzione si raggruppano in due cluster distinti: un gruppo di osservazioni tende ad avere valori BDI-II bassi, mentre l’altro gruppo tende ad avere valori BDI-II alti. Questi due cluster di osservazioni corrispondono al gruppo di controllo e al gruppo clinico nel campione di dati esaminato da Zetsche et al. (2019).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#indici-di-posizione",
    "href": "chapters/eda/05_exploring_numeric_data.html#indici-di-posizione",
    "title": "17  Esplorare i dati numerici",
    "section": "\n17.6 Indici di posizione",
    "text": "17.6 Indici di posizione\n\n17.6.1 Quantili\nLa distribuzione dei valori BDI-II di Zetsche et al. (2019) può essere sintetizzata attraverso l’uso dei quantili, che sono valori caratteristici che suddividono i dati in parti ugualmente numerose. I quartili sono tre quantili specifici: il primo quartile, \\(q_1\\), divide i dati in due parti, lasciando a sinistra il 25% del campione; il secondo quartile, \\(q_2\\), corrisponde alla mediana e divide i dati in due parti uguali; il terzo quartile lascia a sinistra il 75% del campione.\nInoltre, ci sono altri indici di posizione chiamati decili e percentili che suddividono i dati in parti di dimensioni uguali a 10% e 1%, rispettivamente.\nPer calcolare i quantili, i dati vengono prima ordinati in modo crescente e poi viene determinato il valore di \\(np\\), dove \\(n\\) è la dimensione del campione e \\(p\\) è l’ordine del quantile. Se \\(np\\) non è un intero, il valore del quantile corrisponde al valore del dato che si trova alla posizione successiva alla parte intera di \\(np\\). Se \\(np\\) è un intero, il valore del quantile corrisponde alla media dei dati nelle posizioni \\(k\\) e \\(k+1\\), dove \\(k\\) è la parte intera di \\(np\\).\nGli indici di posizione possono essere utilizzati per creare un box-plot, una rappresentazione grafica della distribuzione dei dati che è molto popolare e può essere utilizzata in alternativa ad un istogramma.\nAd esempio, per calcolare la mediana della distribuzione dei nove soggetti con un unico episodio di depressione maggiore del campione clinico di Zetsche et al. (2019), si determina il valore di \\(np = 9 \\cdot 0.5 = 4.5\\), che non è un intero. Pertanto, il valore del secondo quartile è pari al valore del dato che si trova alla posizione successiva alla parte intera di \\(np\\), ovvero \\(q_2 = x_{4 + 1} = 27\\). Per calcolare il quantile di ordine \\(2/3\\), si determina il valore di \\(np = 9 \\cdot 2/3 = 6\\), che è un intero. Quindi, il valore del quantile corrisponde alla media dei dati nelle posizioni \\(6\\) e \\(7\\), ovvero \\(q_{\\frac{2}{3}} = \\frac{1}{2} (x_{6} + x_{7}) = \\frac{1}{2} (33 + 33) = 33\\).\nUsiamo quantile() per trovare la soluzione dell’esercizio precedente.\n\nx = c(19, 26, 27, 28, 28, 33, 33, 41, 43)\nquantile(x, 2 / 3)\n#&gt; 66.66667% \n#&gt;        33",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#mostrare-i-dati",
    "href": "chapters/eda/05_exploring_numeric_data.html#mostrare-i-dati",
    "title": "17  Esplorare i dati numerici",
    "section": "\n17.7 Mostrare i dati",
    "text": "17.7 Mostrare i dati\n\n17.7.1 Diagramma a scatola\nIl box plot è uno strumento grafico che visualizza la dispersione di una distribuzione. I boxplot forniscono una rappresentazione visiva sintetica di cinque valori caratteristici: minimo, primo quartile (25%), mediana (50%), terzo quartile (75%) e massimo. Spesso però, i boxplot “ignorano” i valori considerati anomali (outlier), segnalandoli con punti isolati.\nPer creare un box plot, si disegna un rettangolo (la “scatola”) di altezza arbitraria, basato sulla distanza interquartile (IQR), che corrisponde alla differenza tra il terzo quartile (\\(q_{0.75}\\)) e il primo quartile (\\(q_{0.25}\\)). La mediana (\\(q_{0.5}\\)) è rappresentata da una linea all’interno del rettangolo.\nAi lati della scatola, vengono tracciati due segmenti di retta, detti “baffi”, che rappresentano i valori adiacenti inferiore e superiore. Il valore adiacente inferiore è il valore più basso tra le osservazioni che è maggiore o uguale al primo quartile meno 1.5 volte la distanza interquartile. Il valore adiacente superiore è il valore più alto tra le osservazioni che è minore o uguale al terzo quartile più 1.5 volte la distanza interquartile.\nSe ci sono dei valori che cadono al di fuori dei valori adiacenti, vengono chiamati “valori anomali” e sono rappresentati individualmente nel box plot per evidenziare la loro presenza e posizione. In questo modo, il box plot fornisce una rappresentazione visiva della distribuzione dei dati, permettendo di individuare facilmente eventuali valori anomali e di comprendere la dispersione dei dati.\n\n\n17.7.2 Stratificazione\nNell’analisi dei dati, è comune suddividere le osservazioni in gruppi in base ai valori di una o più variabili associate a tali osservazioni. Questo processo è chiamato stratificazione, e i gruppi risultanti sono detti strati. Ad esempio, nella sezione successiva, dividiamo i valori dei punteggi BDI-II in due gruppi in base alla condizione sperimentale: campione clinico e campione di controllo.\nLa stratificazione è particolarmente utile nella visualizzazione dei dati, poiché spesso siamo interessati a comprendere come la distribuzione di una variabile differisca tra diversi sottogruppi.\nPer esempio, per rappresentare graficamente la distribuzione dei punteggi BDI-II nel gruppo dei pazienti e nel gruppo di controllo, possiamo utilizzare un box-plot. Questo tipo di grafico ci permette di confrontare visivamente la distribuzione dei punteggi tra i due gruppi, evidenziando eventuali differenze.\n\nggplot(df, aes(x = group, y = bdi)) +\n  geom_boxplot() +\n  labs(\n    title = \"Box plot per gruppo\", \n    x = \"Gruppo\", \n    y = \"BDI-II\"\n  )\n\n\n\n\n\n\n\nIn questo grafico:\n\nL’asse x rappresenta i due gruppi (pazienti e controllo).\nL’asse y rappresenta i punteggi BDI-II.\nI box (scatole) mostrano la distribuzione dei punteggi, con la linea centrale che indica la mediana e i “baffi” che rappresentano la variabilità dei dati.\n\nLa stratificazione ci aiuta a identificare rapidamente se ci sono differenze nella distribuzione dei punteggi BDI-II tra i due gruppi. Nel caso presente, il grafico mostra come non vi sia alcuna sovrapposizione tra le due distribuzioni.\nUn risultato migliore si ottiene utilizzando un grafico a violino (violin plot) e includendo anche i dati grezzi.\n\n17.7.3 Grafico a Violino\nI grafici a violino combinano le caratteristiche dei box plot e dei grafici di densità di kernel (KDE plot) per offrire una rappresentazione più dettagliata dei dati.\n\nggplot(df, aes(x = group, y = bdi, fill = group)) +\n  geom_violin() +\n  labs(\n    title = \"Violin plot con overlay dei punti grezzi\",\n    x = \"Gruppo\",\n    y = \"BDI-II\"\n  )\n\n\n\n\n\n\n\n\n17.7.4 Grafico Beeswarm\nIl pacchetto {ggbeeswarm} include una funzione chiamata geom_beeswarm, che può essere utilizzata per creare un grafico beeswarm in ggplot2. Un grafico beeswarm è una variazione del grafico a punti che disperde i dati in modo che non si sovrappongano, rendendo visibili tutti i singoli punti dati. Questo tipo di visualizzazione è particolarmente utile quando si desidera esaminare la distribuzione e la densità di un set di dati, senza ricorrere all’uso di barre d’errore o di scatole e baffi (boxplot), mantenendo un’alta leggibilità anche quando i set di dati sono densi.\n\nggplot(df, aes(x = group, y = bdi, color = group)) +\n  geom_beeswarm(cex = 2) +\n  labs(\n    title = \"Grafico Beeswarm\",\n    x = \"Gruppo\",\n    y = \"BDI-II\"\n  ) \n\n\n\n\n\n\n\n\n17.7.5 Raincloud Plot\nI grafici tradizionali, come i semplici istogrammi o i bar plot con barre d’errore, spesso non riescono a comunicare la vera natura dei dati. Queste rappresentazioni, sebbene intuitive, nascondono informazioni cruciali come la dispersione, la presenza di outlier o la forma della distribuzione. Per questo motivo, negli ultimi anni si è diffuso l’uso di visualizzazioni più ricche, tra cui il raincloud plot, che combina in un unico grafico i vantaggi di boxplot, violin plot e la rappresentazione dei dati grezzi (Spitzer et al., 2014).\nLa figura seguente (creata usando il codice fornito da Schubert et al. (2025)) mostra un confronto tra quattro approcci diversi per rappresentare gli stessi dati. Il classico bar plot (A) si limita a mostrare media e intervallo di confidenza, risultando spesso fuorviante perché non rivela asimmetrie, bimodalità o valori anomali. Il boxplot (B) rappresenta un passo avanti, mostrando mediana, quartili e outliers, ma resta comunque una sintesi parziale della distribuzione. Il violin plot (C) aggiunge una curva di densità, che aiuta a cogliere la forma della distribuzione, ma omette i singoli punti.\n\n# Palette coerente con i livelli di df$group\npalette_group &lt;- setNames(palette_set1[c(\"uno\", \"due\")], c(\"ctl\", \"mdd\"))\n\n# Rendi group un fattore con livelli coerenti (importante!)\ndf &lt;- df |&gt;\n  mutate(group = factor(group, levels = c(\"ctl\", \"mdd\")))\n\n# (A) Barplot con media e errore standard\nbar_plot &lt;- ggplot(df, aes(x = group, y = bdi)) +\n  stat_summary(\n    fun = mean,\n    geom = \"bar\",\n    aes(fill = group),\n    width = 0.7\n  ) +\n  stat_summary(\n    fun.data = mean_sdl,\n    fun.args = list(mult = 1),\n    geom = \"errorbar\",\n    width = 0.2,\n    color = \"black\",\n    linewidth = 0.7\n  ) +\n  scale_fill_manual(values = palette_group) +\n  labs(\n    x = \"Gruppo\",\n    y = \"BDI-II\",\n    title = \"(A) Media con errore standard\"\n  ) +\n  theme(plot.title = element_text(hjust = 0.5))\n\n# (B) Boxplot\nbox_plot &lt;- ggplot(df, aes(x = group, y = bdi, fill = group)) +\n  geom_boxplot() +\n  scale_fill_manual(values = palette_group) +\n  labs(\n    x = \"Gruppo\",\n    y = \"BDI-II\",\n    title = \"(B) Boxplot\"\n  ) +\n  theme(plot.title = element_text(hjust = 0.5))\n\n# (C) Violin plot\nviolin_plot &lt;- ggplot(df, aes(x = group, y = bdi, fill = group)) +\n  geom_violin() +\n  scale_fill_manual(values = palette_group) +\n  labs(\n    x = \"Gruppo\",\n    y = \"BDI-II\",\n    title = \"(C) Violin plot\"\n  ) +\n  theme(plot.title = element_text(hjust = 0.5))\n\n# (D) Raincloud plot\nraincloud_plot &lt;- ggplot(df, aes(x = group, y = bdi, fill = group)) +\n  ggdist::stat_halfeye(\n    adjust = 0.5,\n    justification = -0.3,\n    .width = 0,\n    point_color = NA\n  ) +\n  geom_jitter(\n    aes(color = group),\n    width = 0.1,\n    size = 1,\n    alpha = 0.6\n  ) +\n  geom_boxplot(\n    aes(x = as.numeric(group) + 0.2, fill = group),\n    width = 0.15,\n    outlier.size = 1\n  ) +\n  scale_fill_manual(values = palette_group) +\n  scale_color_manual(values = palette_group) +\n  labs(\n    x = \"Gruppo\",\n    y = \"BDI-II\",\n    title = \"(D) Raincloud plot\"\n  ) +\n  theme(plot.title = element_text(hjust = 0.5))\n\n# Composizione finale con patchwork\n(bar_plot + box_plot) / (violin_plot + raincloud_plot)\n\n\n\n\n\n\n\nIl raincloud plot (D) supera queste limitazioni integrando tre elementi chiave: una “nuvola” che rappresenta la densità dei dati (simile a un violin plot), una “pioggia” di punti che mostra i valori osservati, e un boxplot orizzontale (“suolo”) che riassume le statistiche principali. Questa combinazione lo rende particolarmente utile nell’analisi esplorativa, poiché permette di identificare a colpo d’occhio skewness, cluster e outliers, soprattutto quando si confrontano diversi gruppi.\nIl raincloud plot è uno strumento prezioso perché incoraggia gli studenti a pensare criticamente alla distribuzione dei dati, evitando la trappola delle semplificazioni eccessive. Diversi studi, tra cui Weissgerber et al. (2015) e Weissgerber et al. (2019), hanno dimostrato che visualizzazioni più ricche riducono il rischio di interpretazioni errate, specialmente in campi come le scienze biomediche.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#riflessioni-conclusive",
    "href": "chapters/eda/05_exploring_numeric_data.html#riflessioni-conclusive",
    "title": "17  Esplorare i dati numerici",
    "section": "\n17.8 Riflessioni Conclusive",
    "text": "17.8 Riflessioni Conclusive\nIn questo capitolo abbiamo illustrato una varietà di tecniche per sintetizzare e visualizzare i dati numerici, concentrandoci sia sugli aspetti descrittivi (come distribuzioni di frequenze, istogrammi e distribuzioni cumulative) sia su metodi più raffinati come la stima della densità kernel. Questi strumenti non solo facilitano la comprensione immediata dei pattern e delle caratteristiche fondamentali dei dati, ma rappresentano anche un passaggio essenziale per identificare anomalie e guidare ulteriori analisi statistiche.\nLa capacità di trasformare dati grezzi in rappresentazioni grafiche chiare e intuitive è fondamentale per comunicare in modo efficace i risultati dell’analisi, soprattutto quando si tratta di supportare decisioni pratiche o di sviluppare ipotesi di ricerca. In questo senso, una visualizzazione accurata e ben strutturata consente di evidenziare aspetti come la forma della distribuzione, la presenza di outlier e le differenze tra sottogruppi, contribuendo a una più profonda interpretazione dei fenomeni studiati.\nInfine, l’integrazione di tecniche di visualizzazione con analisi statistiche sintetiche migliora la trasparenza e l’interpretabilità dei dati, offrendo un quadro completo che supporta sia la valutazione critica che la comunicazione dei risultati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#esercizi",
    "href": "chapters/eda/05_exploring_numeric_data.html#esercizi",
    "title": "17  Esplorare i dati numerici",
    "section": "\n17.9 Esercizi",
    "text": "17.9 Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nIn questo esercizio, gli studenti raccoglieranno e analizzeranno dati relativi alla Satisfaction With Life Scale (SWLS) (Diener et al., 1985) e alla Scala della Rete Sociale di Lubben (LSNS-6) (Lubben et al., 2006). L’obiettivo è comprendere la relazione tra la soddisfazione di vita e la qualità delle relazioni sociali, esplorando la distribuzione delle variabili e le possibili associazioni tra di esse.\nLa Scala della Rete Sociale di Lubben a 6 item (LSNS-6) è uno strumento utilizzato per valutare l’isolamento sociale negli adulti più anziani, misurando il supporto sociale percepito sia da parte dei familiari che degli amici. La scala comprende sei domande suddivise in due sezioni:\nFAMIGLIA: Considerando le persone a cui sei legato per nascita, matrimonio, adozione, ecc.\n\nQuanti parenti vedi o senti almeno una volta al mese?\nCon quanti parenti ti senti a tuo agio nel parlare di questioni personali?\nCon quanti parenti ti senti così vicino da poter chiedere loro aiuto?\n\nAMICIZIE: Considerando tutti i tuoi amici, inclusi quelli che vivono nel tuo quartiere\n\nQuanti dei tuoi amici vedi o senti almeno una volta al mese?\nCon quanti amici ti senti a tuo agio nel parlare di questioni personali?\nCon quanti amici ti senti così vicino da poter chiedere loro aiuto?\n\nLa scala di risposta è:\n\n0 = nessuno\n1 = uno\n2 = due\n3 = tre o quattro\n4 = da cinque a otto\n5 = nove o più\n\nIl punteggio totale della LSNS-6 si ottiene sommando i punteggi dei sei item, con un range che va da 0 a 30. Un punteggio di 12 o inferiore indica un rischio di isolamento sociale.\nDati da Raccogliere\nOgni studente dovrà raccogliere i seguenti dati su se stesso e sui membri del proprio gruppo TPV:\n\n\nstudent_id: Identificativo univoco dello studente.\n\n\ngroup: Gruppo di appartenenza (es. Gruppo 1, Gruppo 2, ecc.).\n\n\nswls: Punteggio totale sulla Satisfaction With Life Scale (SWLS).\n\n\ngender: Genere (M, F).\n\n\nlsns_total: Punteggio totale della Scala della Rete Sociale di Lubben (LSNS-6).\n\n\nlsns_family: Punteggio della sottoscala engagement with family members (somma degli item 1-3).\n\n\nlsns_friends: Punteggio della sottoscala engagement with friends (somma degli item 4-6).\n\nQueste variabili permetteranno di investigare come la soddisfazione di vita sia associata alla quantità e qualità delle relazioni sociali, distinguendo tra contatti con la famiglia e con gli amici.\nObiettivi dell’Analisi\nL’esercizio è strutturato in tre parti:\n\n\nEsplorazione dei dati e distribuzione delle variabili\n\n\nVisualizzazione e confronto tra gruppi\n\nAnalisi delle possibili associazioni tra SWLS e le componenti della rete sociale\n\nParte 1: Esplorazione dei Dati\n1.1 Caricamento e preparazione del dataset\n\nImporta il dataset swls_lsns_students.csv.\n\nSeleziona le variabili indicate sopra.\n\nControlla ed elimina eventuali duplicati.\n\nControlla ed elimina eventuali valori mancanti.\n\n# Caricamento del dataset\ndf &lt;- rio::import(here::here(\"data\", \"swls_lsns_students.csv\"))\n\n# Selezione delle variabili\ndf &lt;- df |&gt; dplyr::select(student_id, group, swls, gender, \n                          lsns_total, lsns_family, lsns_friends)\n\n# Rimozione dei duplicati\ndf &lt;- df[!duplicated(df$student_id), ]\n\n# Rimozione dei valori mancanti\ndf &lt;- df[complete.cases(df), ]\n1.2 Distribuzione delle variabili\n\nCalcola la distribuzione di frequenza per swls, lsns_total, lsns_family e lsns_friends:\n\nFrequenze assolute e relative\n\nFrequenze cumulative\n\n\n\n# Frequenze assolute e relative\ntable(df$swls)\nprop.table(table(df$swls))\n\ntable(df$lsns_total)\nprop.table(table(df$lsns_total))\n\nCrea un istogramma della distribuzione delle variabili.\n\nggplot(df, aes(x = swls)) +\n  geom_histogram(bins = 10, fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Distribuzione dei punteggi SWLS\",\n       x = \"Punteggio SWLS\",\n       y = \"Frequenza\")\nggplot(df, aes(x = lsns_total)) +\n  geom_histogram(bins = 10, fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Distribuzione dei punteggi LSNS-6 (totale)\",\n       x = \"Punteggio LSNS-6\",\n       y = \"Frequenza\")\n\nCostruisci la funzione di distribuzione empirica cumulativa (eCDF).\n\nggplot(df, aes(x = swls)) +\n  stat_ecdf(geom = \"step\", color = \"blue\") +\n  labs(title = \"Funzione di distribuzione empirica cumulativa SWLS\",\n       x = \"Punteggio SWLS\",\n       y = \"F(x)\")\n\nGenera la curva di densità kernel (KDE) per ogni variabile.\n\nggplot(df, aes(x = swls)) +\n  geom_density(fill = \"lightblue\", alpha = 0.5) +\n  labs(title = \"Curva di densità dei punteggi SWLS\",\n       x = \"Punteggio SWLS\",\n       y = \"Densità\")\nggplot(df, aes(x = lsns_total)) +\n  geom_density(fill = \"lightblue\", alpha = 0.5) +\n  labs(title = \"Curva di densità LSNS-6 (totale)\",\n       x = \"Punteggio LSNS-6\",\n       y = \"Densità\")\nParte 2: Confronto tra Gruppi\n\nCostruisci una tabella di contingenza per gender e livello di rete sociale (alta o bassa, separando sopra e sotto la mediana di lsns_total).\n\ndf &lt;- df |&gt; \n  mutate(lsns_level = ifelse(lsns_total &gt;= median(lsns_total), \"Alto\", \"Basso\"))\n\ntable(df$gender, df$lsns_level)\nprop.table(table(df$gender, df$lsns_level), margin = 1)\n\nCrea un grafico a barre per la distribuzione di lsns_level per genere.\n\nggplot(df, aes(x = lsns_level, fill = gender)) +\n  geom_bar(position = \"dodge\") +\n  labs(title = \"Distribuzione del livello di rete sociale per genere\",\n       x = \"Livello LSNS\",\n       y = \"Conteggio\",\n       fill = \"Genere\")\n\nCostruisci un box plot per confrontare swls tra i gruppi di rete sociale.\n\nggplot(df, aes(x = lsns_level, y = swls, fill = lsns_level)) +\n  geom_boxplot() +\n  labs(title = \"Distribuzione dei punteggi SWLS per livello di rete sociale\",\n       x = \"Livello di rete sociale\",\n       y = \"Punteggio SWLS\")\n\nUsa un violin plot per visualizzare la distribuzione dettagliata.\n\nggplot(df, aes(x = lsns_level, y = swls, fill = lsns_level)) +\n  geom_violin(alpha = 0.5) +\n  geom_jitter(width = 0.1, alpha = 0.5) +\n  labs(title = \"Violin plot con dati grezzi sovrapposti\",\n       x = \"Livello di rete sociale\",\n       y = \"Punteggio SWLS\")\nParte 3: Analisi delle Associazioni tra SWLS e la Rete Sociale\nIl concetto di correlazione verrà approfondito nel Capitolo 21. Per i nostri scopi attuali, possiamo considerarlo come un indice numerico che misura l’intensità e la direzione dell’associazione tra due variabili. Un valore di 0 indica l’assenza di una relazione lineare tra le variabili, mentre i valori +1 e -1 indicano una relazione lineare perfetta, positiva o negativa rispettivamente. I valori intermedi tra -1 e +1 rappresentano associazioni più deboli o forti, a seconda della loro vicinanza agli estremi.\n\n\nCorrelazioni tra SWLS e le sottoscale della LSNS.\n\ncor(df$swls, df$lsns_total, method = \"pearson\")\ncor(df$swls, df$lsns_family, method = \"pearson\")\ncor(df$swls, df$lsns_friends, method = \"pearson\")\nSpiega in maniera inuitiva il significato dei valori ottenuti.\n\n\nGrafico di dispersione tra SWLS e LSNS-6 totale.\n\nUn grafico di dispersione è un diagramma cartesiano in cui ogni punto rappresenta un’osservazione (nel caso attuale, uno studente). Le coordinate dei punti sui due assi, X e Y, indicano i valori delle due variabili considerate per ciascuno studente.\nggplot(df, aes(x = lsns_total, y = swls)) +\n  geom_point(alpha = 0.7) +\n  geom_smooth(method = \"lm\", color = \"red\") +\n  labs(title = \"Relazione tra rete sociale totale e SWLS\",\n       x = \"Punteggio LSNS-6 Totale\",\n       y = \"Punteggio SWLS\")\nPer ogni grafico generato, includi una descrizione chiara e concisa del suo significato in relazione ai dati analizzati.\nConclusioni\nL’obiettivo è analizzare se e come la soddisfazione di vita degli studenti universitari è influenzata dalle relazioni sociali, distinguendo tra engagement con la famiglia e con gli amici.\nConsegna\nConsegna il file .qmd contenente il codice, le visualizzazioni e le interpretazioni.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/05_exploring_numeric_data.html#informazioni-sullambiente-di-sviluppo",
    "title": "17  Esplorare i dati numerici",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] viridis_0.6.5         viridisLite_0.4.2     cowplot_1.2.0        \n#&gt;  [4] ggpubr_0.6.1          gridExtra_2.3         dslabs_0.8.0         \n#&gt;  [7] ggbeeswarm_0.7.2      pillar_1.11.0         tinytable_0.11.0     \n#&gt; [10] patchwork_1.3.1       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt; [13] bayesplot_1.13.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [16] priorsense_1.1.0      posterior_1.6.1       loo_2.8.0            \n#&gt; [19] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [22] Rcpp_1.1.0            conflicted_1.2.0      janitor_2.2.1        \n#&gt; [25] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [28] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [31] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] RColorBrewer_1.1-3   rstudioapi_0.17.1    tensorA_0.36.2.1    \n#&gt;  [4] jsonlite_2.0.0       magrittr_2.0.3       TH.data_1.1-3       \n#&gt;  [7] estimability_1.5.1   farver_2.1.2         rmarkdown_2.29      \n#&gt; [10] vctrs_0.6.5          memoise_2.0.1        base64enc_0.1-3     \n#&gt; [13] rstatix_0.7.2        htmltools_0.5.8.1    distributional_0.5.0\n#&gt; [16] curl_6.4.0           broom_1.0.9          Formula_1.2-5       \n#&gt; [19] htmlwidgets_1.6.4    sandwich_3.1-1       emmeans_1.11.2      \n#&gt; [22] zoo_1.8-14           lubridate_1.9.4      cachem_1.1.0        \n#&gt; [25] lifecycle_1.0.4      pkgconfig_2.0.3      Matrix_1.7-3        \n#&gt; [28] R6_2.6.1             fastmap_1.2.0        snakecase_0.11.1    \n#&gt; [31] digest_0.6.37        colorspace_2.1-1     rprojroot_2.1.0     \n#&gt; [34] Hmisc_5.2-3          labeling_0.4.3       timechange_0.3.0    \n#&gt; [37] abind_1.4-8          compiler_4.5.1       withr_3.0.2         \n#&gt; [40] htmlTable_2.4.3      backports_1.5.0      inline_0.3.21       \n#&gt; [43] carData_3.0-5        QuickJSR_1.8.0       pkgbuild_1.4.8      \n#&gt; [46] R.utils_2.13.0       ggsignif_0.6.4       MASS_7.3-65         \n#&gt; [49] tools_4.5.1          vipor_0.4.7          foreign_0.8-90      \n#&gt; [52] beeswarm_0.4.0       nnet_7.3-20          R.oo_1.27.1         \n#&gt; [55] glue_1.8.0           nlme_3.1-168         grid_4.5.1          \n#&gt; [58] checkmate_2.3.2      cluster_2.1.8.1      generics_0.1.4      \n#&gt; [61] gtable_0.3.6         R.methodsS3_1.8.2    data.table_1.17.8   \n#&gt; [64] car_3.1-3            stringr_1.5.1        splines_4.5.1       \n#&gt; [67] lattice_0.22-7       survival_3.8-3       tidyselect_1.2.1    \n#&gt; [70] knitr_1.50           arrayhelpers_1.1-0   V8_6.0.5            \n#&gt; [73] stats4_4.5.1         xfun_0.52            bridgesampling_1.1-2\n#&gt; [76] stringi_1.8.7        yaml_2.3.10          pacman_0.5.1        \n#&gt; [79] evaluate_1.0.4       codetools_0.2-20     cli_3.6.5           \n#&gt; [82] RcppParallel_5.1.10  rpart_4.1.24         xtable_1.8-4        \n#&gt; [85] coda_0.19-4.1        svUnit_1.0.6         parallel_4.5.1      \n#&gt; [88] rstantools_2.4.0     Brobdingnag_1.2-9    mvtnorm_1.3-3       \n#&gt; [91] scales_1.4.0         purrr_1.1.0          rlang_1.1.6         \n#&gt; [94] multcomp_1.4-28",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#bibliografia",
    "href": "chapters/eda/05_exploring_numeric_data.html#bibliografia",
    "title": "17  Esplorare i dati numerici",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nDiener, E., Emmons, R. A., Larsen, R. J., & Griffin, S. (1985). The Satisfaction With Life Scale. Journal of Personality Assessment, 49(1), 71–75. https://doi.org/10.1207/s15327752jpa4901_13\n\n\nLubben, J., Blozik, E., Gillmann, G., Iliffe, S., Renteln Kruse, W. von, Beck, J. C., & Stuck, A. E. (2006). Performance of an abbreviated version of the Lubben Social Network Scale among three European community-dwelling older adult populations. The Gerontologist, 46(4), 503–513. https://doi.org/10.1093/geront/46.4.503\n\n\nSchubert, A.-L., Steinhilber, M., Kang, H., & Quintana, D. (2025). Improving Statistical Reporting in Psychology.\n\n\nSpitzer, M., Wildenhain, J., Rappsilber, J., & Tyers, M. (2014). BoxPlotR: a web tool for generation of box plots. Nature Methods, 11(2), 121–122.\n\n\nWeissgerber, T. L., Milic, N. M., Winham, S. J., & Garovic, V. D. (2015). Beyond bar and line graphs: time for a new data presentation paradigm. PLoS biology, 13(4), e1002128.\n\n\nWeissgerber, T. L., Winham, S. J., Heinzen, E. P., Milin-Lazovic, J. S., Garcia-Valencia, O., Bukumiric, Z., Savic, M. D., Garovic, V. D., & Milic, N. M. (2019). Reveal, don’t conceal: transforming data visualization to improve transparency. Circulation, 140(18), 1506–1518.\n\n\nZetsche, U., Buerkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: biased or realistic? Journal of Abnormal Psychology, 128(7), 678–688.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html",
    "href": "chapters/eda/06_data_visualization.html",
    "title": "18  Principi della visualizzazione dei dati",
    "section": "",
    "text": "Introduzione\nUn buon grafico permette di cogliere immediatamente pattern, anomalie e bias che resterebbero nascosti in una semplice tabella di valori. Per chi desidera un approfondimento sistematico, un riferimento utile è il capitolo Data Visualization del libro Introduction to Data Science..\nL’ampia disponibilità di dataset complessi e la diffusione di strumenti software sempre più accessibili hanno reso la visualizzazione un passaggio centrale in molti ambiti scientifici e professionali: non solo facilita la comunicazione dei risultati, ma stimola nuove domande e consente di individuare rapidamente errori o anomalie.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#unimmagine-vale-più-di-mille-parole",
    "href": "chapters/eda/06_data_visualization.html#unimmagine-vale-più-di-mille-parole",
    "title": "18  Principi della visualizzazione dei dati",
    "section": "\n18.1 Un’immagine vale più di mille parole",
    "text": "18.1 Un’immagine vale più di mille parole\nI numeri da soli raramente raccontano una storia chiara. Consideriamo, ad esempio, i dati sugli omicidi con armi da fuoco negli Stati Uniti. Una tabella con i valori grezzi permette di sapere, per ogni stato, popolazione e numero di omicidi. Tuttavia, osservandola è difficile farsi un’idea immediata della distribuzione: quali sono gli stati più popolosi o i meno popolosi? Qual è la dimensione “tipica” di uno stato? Esiste una relazione tra popolazione e numero totale di omicidi? E come si distribuiscono i tassi di omicidio tra le diverse regioni?\n\nhead(murders)\n#&gt;        state abb region population total\n#&gt; 1    Alabama  AL  South    4779736   135\n#&gt; 2     Alaska  AK   West     710231    19\n#&gt; 3    Arizona  AZ   West    6392017   232\n#&gt; 4   Arkansas  AR  South    2915918    93\n#&gt; 5 California  CA   West   37253956  1257\n#&gt; 6   Colorado  CO   West    5029196    65\n\nUn grafico, al contrario, rende queste relazioni visibili a colpo d’occhio. Nella figura che segue, la scala logaritmica su entrambi gli assi permette di rappresentare in modo compatto sia gli stati più grandi, come California, Texas e New York, sia quelli con popolazioni molto ridotte, come Wyoming, Vermont o Alaska. Si vede subito che la maggior parte degli stati ha una popolazione compresa tra uno e dieci milioni di abitanti, mentre gli stati più popolosi si collocano nettamente a destra del grafico.\n\n\n\n\n\n\n\n\nAllo stesso modo, la relazione tra popolazione e numero di omicidi appare chiara: più abitanti significa, in media, più omicidi. Tuttavia, si notano discrepanze: alcuni stati registrano più omicidi del previsto in rapporto alla popolazione, mentre altri ne hanno meno, segnalando l’influenza di fattori ulteriori. Anche la colorazione per regione rivela differenze interessanti: il Sud tende a registrare tassi più elevati, il Nord-Est valori relativamente bassi, l’Ovest mostra una grande variabilità, e il Midwest si colloca in posizione intermedia o bassa.\nIl detto “un’immagine vale più di mille parole” trova qui piena conferma: un buon grafico non solo comunica con immediatezza, ma spesso sostituisce lunghe spiegazioni numeriche, guidando lo sguardo verso i pattern più rilevanti e stimolando nuove domande di analisi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#codificare-i-dati-attraverso-segnali-visivi",
    "href": "chapters/eda/06_data_visualization.html#codificare-i-dati-attraverso-segnali-visivi",
    "title": "18  Principi della visualizzazione dei dati",
    "section": "\n18.2 Codificare i dati attraverso segnali visivi",
    "text": "18.2 Codificare i dati attraverso segnali visivi\nOgni visualizzazione si fonda sulla trasformazione dei dati in segnali visivi che il nostro sistema percettivo può elaborare con immediatezza. Gli elementi più comuni sono la posizione, la lunghezza, gli angoli, l’area, la luminosità e la tonalità del colore. Non tutti, però, hanno la stessa efficacia.\nIl nostro cervello è particolarmente sensibile alle differenze spaziali: per questo la posizione e la lunghezza sono i canali più potenti per trasmettere informazione quantitativa. Un grafico a barre, ad esempio, permette di confrontare valori in modo rapido e preciso proprio perché sfrutta la lunghezza come segnale visivo. Al contrario, angoli e aree sono molto meno intuitivi: grafici a torta o bolle possono risultare accattivanti, ma spesso portano a errori percettivi, soprattutto quando le differenze tra categorie sono ridotte.\nIl colore gioca un ruolo cruciale quando vogliamo distinguere categorie o rappresentare variabili qualitative. È un elemento indispensabile nelle visualizzazioni multidimensionali, come le heatmap, ma deve essere usato con attenzione. Alcune combinazioni, come il rosso e il verde, possono rendere il grafico illeggibile per persone con daltonismo, e in generale una palette mal progettata può distogliere l’attenzione dai contenuti principali.\nInfine, è importante distinguere tra strumenti di precisione e strumenti di sintesi. Le tabelle sono ideali quando è necessario leggere valori numerici esatti, mentre i grafici diventano insostituibili di fronte a dataset complessi, perché mettono in evidenza pattern, tendenze e anomalie che difficilmente emergerebbero da un elenco di numeri.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#scelta-della-visualizzazione-più-adeguata",
    "href": "chapters/eda/06_data_visualization.html#scelta-della-visualizzazione-più-adeguata",
    "title": "18  Principi della visualizzazione dei dati",
    "section": "\n18.3 Scelta della visualizzazione più adeguata",
    "text": "18.3 Scelta della visualizzazione più adeguata\nNon esiste una visualizzazione “migliore” in assoluto: la scelta dipende sempre dalla natura dei dati e dallo scopo comunicativo. Se l’obiettivo è confrontare valori quantitativi tra diverse categorie, i grafici a barre o i dot plot risultano particolarmente chiari. Quando invece vogliamo descrivere la distribuzione di una variabile continua, strumenti come l’istogramma, il boxplot o i più moderni raincloud plots permettono di cogliere rapidamente forma, variabilità e presenza di outlier. Per indagare relazioni tra due variabili continue, i grafici di dispersione offrono un’immediatezza che difficilmente può essere sostituita da altre rappresentazioni.\nQualunque sia il tipo di grafico scelto, rimane centrale il principio della chiarezza. Una visualizzazione sovraccarica di dettagli, effetti grafici o decorazioni rischia di distrarre e confondere, mentre una rappresentazione essenziale mette in risalto il messaggio principale e guida lo sguardo verso le informazioni rilevanti. In questo senso, un buon grafico non è solo corretto dal punto di vista tecnico, ma è anche uno strumento di comunicazione efficace.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#aspetti-tecnici-della-visualizzazione",
    "href": "chapters/eda/06_data_visualization.html#aspetti-tecnici-della-visualizzazione",
    "title": "18  Principi della visualizzazione dei dati",
    "section": "\n18.4 Aspetti tecnici della visualizzazione",
    "text": "18.4 Aspetti tecnici della visualizzazione\nUna buona visualizzazione non dipende soltanto dalla scelta del tipo di grafico, ma anche da una serie di accorgimenti tecnici che ne determinano chiarezza e correttezza percettiva. Alcune regole, spesso sottovalutate, possono fare la differenza tra un grafico informativo e uno fuorviante.\n\n18.4.1 Inclusione dello zero\nQuando la lunghezza viene utilizzata come segnale visivo – come accade nei grafici a barre – l’asse deve sempre partire da zero. In caso contrario, le differenze appariranno artificialmente amplificate, inducendo interpretazioni scorrette. Nei grafici che si basano sulla posizione, come gli scatter plot, questa regola non è altrettanto stringente: qui l’inclusione dello zero dipende piuttosto dal contesto e dal significato delle variabili rappresentate.\n\n18.4.2 Prevenire le distorsioni\nAlcuni grafici, come i bubble plot, rischiano di esagerare le differenze fra i valori perché utilizzano l’area come segnale visivo. La superficie di un cerchio cresce infatti con il quadrato del raggio, producendo sproporzioni difficili da cogliere a occhio nudo. Un esempio emblematico è il grafico mostrato durante il Discorso sullo Stato dell’Unione del 2011, in cui il PIL degli Stati Uniti appariva molto più grande di quello cinese o francese. In realtà, la distorsione derivava proprio dall’aver reso il raggio proporzionale al valore, trasformando implicitamente la scala in quadratica. La lezione che se ne ricava è semplice: per confronti accurati, meglio affidarsi a posizione e lunghezza, evitando aree o volumi.\n\n\n\n\n\n\nState of the Union\n\n\n\n\n\n\n\n\n\n\nFigura 18.1: Fonte: Irizarry (2024).\n\n\nIl confronto sottostante illustra l’impatto della scelta tra raggio e area nella rappresentazione grafica:\n\n\n\n\n\nFigura 18.2: Fonte: Irizarry (2024).\n\n\n\n\n\n\n\nFigura 18.3: Fonte: Irizarry (2024).\n\n\nQuesto caso dimostra chiaramente come, per evitare distorsioni percettive, sia una prassi consolidata ottimizzare la visualizzazione dei dati attraverso confronti basati su lunghezze (o posizioni) anziché su aree o volumi, come evidenziato dall’errata rappresentazione del PIL nel grafico originale.\n\n\n\n\n18.4.3 Ordinamento delle categorie\nNei grafici categoriali, disporre le categorie in ordine alfabetico può sembrare neutrale, ma raramente aiuta la comprensione. Ordinare le categorie in base al valore della variabile di interesse, invece, evidenzia immediatamente pattern e relazioni, rendendo la lettura molto più intuitiva.\n\n18.4.4 Mostrare i dati, non solo le sintesi\nI cosiddetti dynamite plots, che riportano medie ed errori standard, sono ancora molto diffusi ma comunicano poco e spesso in modo fuorviante. Guardando una semplice barra con un intervallo di errore, non è possibile capire se i dati siano distribuiti in modo simmetrico, se esistano outlier o se i gruppi si sovrappongano. Visualizzazioni che mostrano i singoli dati – ad esempio dot plot arricchiti da tecniche come jitter e trasparenza – permettono invece di cogliere la variabilità interna, facilitano il confronto e raccontano una storia molto più completa.\n\n\n\n\n\n\nMostrare i dati\n\n\n\n\n\nConsideriamo il seguente grafico a barre (dynamite plot) che mostra la media (estremità superiore delle barre) e gli errori standard.\n\n\n\n\n\nFigura 18.4: Fonte: Irizarry (2024).\n\n\nQuesta visualizzazione offre informazioni limitate:\n\nLe barre partono da 0, suggerendo erroneamente l’esistenza di esseri umani alti pochi centimetri.\n\nNon chiarisce se tutti i maschi siano più alti delle femmine o come siano distribuite le altezze.\n\nUn approccio migliore è quello di mostrare i dati:\n\n\n\n\n\nFigura 18.5: Fonte: Irizarry (2024).\n\n\nLa visualizzazione di tutti i punti (238 femmine e 812 maschi) rivela l’intervallo dei dati, ma persiste un problema: i punti sovrapposti ostacolano l’interpretazione.\nOttimizzazioni: jitter e trasparenza\n\n\n\n\n\nFigura 18.6: Fonte: Irizarry (2024).\n\n\nDue miglioramenti chiave:\n\n\nJitter orizzontale: spostamento casuale dei punti per ridurre la sovrapposizione.\n\n\nAlpha blending: trasparenza graduale: le aree con più dati appaiono più scure.\n\nRisultati:\n\nsi osserva che i maschi sono in media più alti;\nè chiaro che vi è una grande variabilità e una notevole sovrapposizione tra le due distribuzioni.\n\nIn sintesi, strumenti semplici, come jitter e trasparenza, migliorano drasticamente l’interpretazione della distribuzione dei dati.\n\n\n\n\n18.4.5 Confronti coerenti\nQuando si confrontano distribuzioni diverse, ad esempio con istogrammi affiancati, è indispensabile utilizzare la stessa scala sugli assi. Differenze apparenti potrebbero dipendere soltanto da un’incoerenza di rappresentazione. Anche l’allineamento dei grafici gioca un ruolo importante: disporli in verticale o in orizzontale con assi coerenti rende il confronto immediato e riduce il rischio di fraintendimenti.\n\n\n\n\n\n\nFacilitare i confronti\n\n\n\n\n\nPoiché ci sono molti punti, è più efficace mostrare la distribuzione dei dati anziché i singoli valori. Per questo motivo, utilizziamo istogrammi separati per ciascun gruppo:\n\n\n\n\n\nFigura 18.7: Fonte: Irizarry (2024).\n\n\nTuttavia, in questo grafico non è immediatamente evidente che, in media, gli uomini siano più alti delle donne. Per accorgersene, bisogna osservare con attenzione e notare che l’asse x del grafico maschile copre un intervallo di valori più ampio. Un principio fondamentale nella comparazione di dati tra due grafici è mantenere le stesse scale sugli assi.\nNegli istogrammi, l’altezza media si riflette in spostamenti orizzontali: valori più bassi a sinistra, valori più alti a destra. Allineare i grafici in verticale aiuta a visualizzare meglio questa differenza quando gli assi sono coerenti:\n\n\n\n\n\nFigura 18.8: Fonte: Irizarry (2024).\n\n\nQuesto secondo grafico rende molto più evidente che, in media, gli uomini sono più alti delle donne.\n\n\n\n\n18.4.6 Trasformazioni logaritmiche\nMolti dati reali coprono ordini di grandezza molto ampi. In questi casi, una scala lineare comprime la maggior parte delle osservazioni e rende invisibili le differenze più sottili. Le trasformazioni logaritmiche sono uno strumento efficace per restituire leggibilità a distribuzioni fortemente asimmetriche. Altre trasformazioni, come la logistica o la radice quadrata, sono utili rispettivamente per rappresentare rapporti di probabilità o stabilizzare la varianza in dati di conteggio. La scelta della trasformazione non è mai neutrale, ma può illuminare pattern altrimenti nascosti.\n\n\n\n\n\n\nTrasformazioni logaritmiche\n\n\n\n\n\nConsideriamo questo grafico a barre, che mostra la popolazione media dei paesi di ciascun continente nel 2015:\n\n\n\n\n\nFigura 18.9: Fonte: Irizarry (2024).\n\n\nA prima vista, sembrerebbe che i paesi dell’Asia siano molto più popolosi rispetto a quelli degli altri continenti. Tuttavia, applicando il principio che ci chiede di mostrare i dati, notiamo rapidamente che questa differenza è dovuta alla presenza di due paesi con una popolazione estremamente elevata, presumibilmente India e Cina:\n\n\n\n\n\nFigura 18.10: Fonte: Irizarry (2024).\n\n\nConsideriamo ora come la trasformazione logaritmica possa migliorare la visualizzazione di dati distribuiti in modo asimmetrico (right-skewed). Esistono anche altre trasformazioni utili, come la logistica (logit), impiegata per interpretare variazioni nei rapporti di probabilità (odds), e la radice quadrata (sqrt), spesso usata per stabilizzare la varianza nei dati basati su conteggi.\nNel caso della popolazione dei paesi, la distribuzione è fortemente asimmetrica: la maggior parte delle nazioni ha una popolazione relativamente piccola, mentre poche hanno numeri estremamente elevati. Come mostrato nel boxplot precedente, questa disparità comprime la maggior parte dei dati in una piccola area del grafico, lasciando molto spazio inutilizzato. Questo rende difficile cogliere le differenze tra la maggior parte dei paesi.\nUna trasformazione logaritmica migliora la leggibilità di uno scatter plot quando i dati mostrano una forte asimmetria. Qui, applicando questa tecnica alle popolazioni nazionali, otteniamo una rappresentazione molto più chiara e informativa. Di seguito, confrontiamo il barplot originale con un boxplot in cui l’asse y è stato trasformato con il logaritmo:\n\n\n\n\n\nFigura 18.11: Fonte: Irizarry (2024).\n\n\nGrazie a questa trasformazione, scopriamo che la mediana della popolazione nei paesi africani è in realtà più alta rispetto a quella dei paesi asiatici, un’informazione che il grafico iniziale non rendeva evidente.\n\n\n\n\n18.4.7 Codifica di variabili aggiuntive\nQuando si vogliono rappresentare più di due variabili nello stesso grafico, si possono sfruttare ulteriori canali visivi come colore, forma o dimensione dei punti. È però necessario bilanciare informazione e leggibilità: troppe codifiche simultanee generano confusione. Inoltre, la scelta delle palette cromatiche deve garantire accessibilità, ad esempio evitando combinazioni problematiche per persone con daltonismo.\n\n\n\n\n\n\nCodificare una terza variabile\n\n\n\n\n\nEsaminiamo la relazione tra sopravvivenza infantile e reddito medio. Il grafico seguente rappresenta questa relazione includendo tre variabili aggiuntive: appartenenza all’OPEC, regione geografica e popolazione.\n\n\n\n\n\nFigura 18.12: Fonte: Irizarry (2024).\n\n\nLe variabili categoriali sono rappresentate attraverso il colore e la forma dei punti. La forma può essere modificata utilizzando l’argomento shape.\n\n\n\n\n18.4.8 Evitare il 3D superfluo\nGrafici tridimensionali, come pie chart o barre in prospettiva, attirano l’occhio ma raramente aggiungono informazione. Anzi, introducono distorsioni che complicano la lettura. Nella maggior parte dei casi, una rappresentazione bidimensionale è più chiara, più fedele e più efficace.\n\n18.4.9 Cifre significative\nMostrare un numero eccessivo di decimali non aumenta la precisione, ma rischia di appesantire la lettura. Una o due cifre significative sono quasi sempre sufficienti per trasmettere il messaggio in modo accurato e comprensibile.\n\n18.4.10 Conoscere il pubblico\nInfine, una regola trasversale: ogni visualizzazione deve tenere conto del pubblico di riferimento. Un grafico pensato per un’analisi interna può includere dettagli tecnici e livelli di complessità elevati; al contrario, quando il pubblico non è specializzato, è preferibile semplificare, ridurre il rumore visivo e accompagnare la rappresentazione con spiegazioni chiare.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#introduzione-a-ggplot2",
    "href": "chapters/eda/06_data_visualization.html#introduzione-a-ggplot2",
    "title": "18  Principi della visualizzazione dei dati",
    "section": "\n18.5 Introduzione a ggplot2\n",
    "text": "18.5 Introduzione a ggplot2\n\nIn R esistono diversi strumenti per creare grafici, ma il pacchetto ggplot2 si distingue per flessibilità e chiarezza. È diventato lo standard per la visualizzazione dei dati in molti ambiti scientifici, inclusa la psicologia, perché consente di tradurre un dataset complesso in rappresentazioni immediate e leggibili.\n\n18.5.1 Perché usare ggplot2?\nImmaginiamo di voler analizzare i livelli di ansia di un gruppo di studenti prima di un esame. I dati raccolti in una tabella ci danno informazioni preziose, ma difficili da cogliere a colpo d’occhio. Con un grafico, invece, possiamo visualizzare subito quali studenti mostrano livelli di ansia particolarmente elevati e se l’ansia tende a variare in funzione di caratteristiche come l’intolleranza all’incertezza (IU).\nPer illustrare le potenzialità di ggplot2, costruiamo un piccolo dataset simulato:\n\nset.seed(123)\n\nn &lt;- 200\ngender &lt;- sample(c(0, 1), n, replace = TRUE)\nanxiety &lt;- rnorm(n, mean = 50 + 10 * gender, sd = 10)\nstudy_hours &lt;- rnorm(n, mean = 30 - 0.3 * anxiety, sd = 5)\nIU &lt;- rnorm(n, mean = 50 + 0.5 * anxiety, sd = 10)\n\ndf &lt;- data.frame(\n  id = 1:n,\n  gender = factor(gender, levels = c(0, 1), labels = c(\"Male\", \"Female\")),\n  anxiety = round(anxiety, 1),\n  study_hours = round(study_hours, 1),\n  IU = round(IU, 1)\n)\n\nhead(df)\n#&gt;   id gender anxiety study_hours   IU\n#&gt; 1  1   Male    42.9        13.6 65.4\n#&gt; 2  2   Male    52.6        10.5 66.3\n#&gt; 3  3   Male    47.5        11.0 84.0\n#&gt; 4  4 Female    56.5         7.8 85.8\n#&gt; 5  5   Male    40.5        15.7 55.2\n#&gt; 6  6 Female    59.5        13.8 78.8\n\n\n18.5.2 La logica di ggplot2\n\nAlla base di ogni grafico con ggplot2 ci sono tre elementi fondamentali:\n\n\ni dati, cioè il dataset da rappresentare;\n\nle geometrie, ossia il tipo di grafico scelto (punti, barre, linee, boxplot);\n\nla mappatura estetica, che stabilisce come i dati vengono tradotti in segnali visivi (posizione sugli assi, colore, forma, dimensione).\n\nQuesta struttura rende il pacchetto molto intuitivo: basta dire a ggplot2 quali dati usare, come rappresentarli e con quali convenzioni grafiche.\n\n18.5.3 Un primo esempio\nSupponiamo di voler capire se esiste una relazione tra ore di studio e livelli di ansia. Possiamo costruire un semplice grafico a dispersione:\n\nlibrary(ggplot2)\n\ndf |&gt;\n  ggplot(aes(x = study_hours, y = anxiety)) +\n  geom_point()\n\n\n\n\n\n\n\nIn questo codice stiamo dicendo a ggplot2 di prendere come riferimento il dataset df, di mettere le ore di studio sull’asse X, i livelli di ansia sull’asse Y e di rappresentare ogni osservazione con un punto.\n\n18.5.4 Personalizzare il grafico\nUn aspetto importante di ggplot2 è la possibilità di arricchire facilmente la rappresentazione. Aggiungiamo, per esempio, un colore che distingua maschi e femmine, rendiamo i punti più visibili e inseriamo un titolo e delle etichette agli assi:\n\ndf |&gt;\n  ggplot(aes(x = study_hours, y = anxiety, color = gender)) +\n  geom_point(size = 3) +\n  labs(\n    title = \"Relazione tra ore di studio e ansia\",\n    x = \"Ore di studio\",\n    y = \"Livello di ansia\",\n    color = \"Genere\"\n  )\n\n\n\n\n\n\n\nIl risultato è un grafico più leggibile, in cui la distinzione per genere appare immediatamente chiara.\n\n18.5.5 Altri esempi\nCon gli stessi dati possiamo costruire grafici diversi, ciascuno utile a rispondere a domande specifiche. Per esplorare la distribuzione dell’ansia, ad esempio, un istogramma è la scelta naturale:\n\ndf |&gt;\n  ggplot(aes(x = anxiety)) +\n  geom_histogram(binwidth = 5, fill = \"steelblue\", color = \"white\") +\n  labs(x = \"Livello di ansia\", y = \"Frequenza\")\n\n\n\n\n\n\n\nSe invece vogliamo confrontare i livelli di ansia tra maschi e femmine, un boxplot mette in evidenza la mediana, la variabilità e la presenza di eventuali valori estremi:\n\ndf |&gt;\n  ggplot(aes(x = gender, y = anxiety, fill = gender)) +\n  geom_boxplot(alpha = 0.7) +\n  labs(x = \"Genere\", y = \"Livello di ansia\") +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\nIn sintesi, con pochi comandi, ggplot2 consente di costruire grafici chiari e informativi. In psicologia, dove spesso si lavora con dataset complessi, è uno strumento prezioso per trasformare numeri in intuizioni: una buona visualizzazione permette non solo di comunicare risultati, ma anche di stimolare nuove domande di ricerca.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#riflessioni-conclusive",
    "href": "chapters/eda/06_data_visualization.html#riflessioni-conclusive",
    "title": "18  Principi della visualizzazione dei dati",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nUna visualizzazione ben progettata ha il potere di trasformare dati complessi in messaggi immediati, riducendo il carico cognitivo e facilitando decisioni più consapevoli. Disegnare un grafico non significa solo scegliere un formato piacevole: implica assumersi la responsabilità di comunicare i risultati in modo corretto, evitando di indurre interpretazioni fuorvianti.\nPer raggiungere questo obiettivo, occorre innanzitutto essere chiari sul messaggio che si vuole trasmettere. Un buon grafico è costruito intorno a una domanda precisa e guida lo sguardo del lettore verso gli elementi più rilevanti. Colori, forme e dimensioni non vanno scelti per decorare, ma per orientare l’attenzione: una palette limitata, ben calibrata e accessibile è spesso più efficace di combinazioni cromatiche elaborate. Allo stesso modo, titoli ed etichette devono essere semplici e intuitivi, evitando abbreviazioni o tecnicismi che potrebbero confondere.\nÈ importante anche saper gestire la densità dell’informazione. Quando i dati sono numerosi, tecniche come la trasparenza, il jitter o un eventuale sottocampionamento aiutano a prevenire il sovraccarico visivo e rendono le distribuzioni leggibili. Mostrare i dati grezzi, quando possibile, arricchisce l’interpretazione e riduce il rischio che le sintesi statistiche nascondano pattern interessanti.\nAlcune buone pratiche ricorrono in quasi tutte le situazioni: ordinare le categorie in base ai valori, e non alfabeticamente, facilita i confronti; mantenere assi coerenti rende più immediata la comparazione tra grafici; partire da zero negli assi dei barplot evita distorsioni nelle proporzioni; usare trasformazioni logaritmiche quando i valori coprono ordini di grandezza molto diversi permette di restituire visibilità anche ai dati più piccoli.\nAltre accortezze riguardano la scelta delle codifiche visive. L’aggiunta di variabili tramite colore, forma o dimensione può arricchire un grafico, ma solo se mantiene un equilibrio tra informazione e leggibilità. Le rappresentazioni tridimensionali, al contrario, raramente offrono un reale vantaggio: sono spesso più fuorvianti che utili. Infine, i numeri stessi vanno comunicati con sobrietà: un eccesso di decimali non rende il dato più preciso, ma soltanto più difficile da leggere.\nTutte queste regole devono sempre essere rapportate al pubblico a cui ci si rivolge. In un’analisi tecnica interna è possibile includere dettagli complessi, mentre per un pubblico non specializzato occorre semplificare, spiegare e accompagnare la visualizzazione con un linguaggio accessibile. In definitiva, progettare una buona visualizzazione non significa soltanto “disegnare un grafico”, ma costruire un ponte tra i dati e chi li interpreta, con l’obiettivo di rendere la conoscenza condivisibile e utile.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#esercizi",
    "href": "chapters/eda/06_data_visualization.html#esercizi",
    "title": "18  Principi della visualizzazione dei dati",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nEsercizi\n\n\n\n\n\nIn questo esercizio analizzerai i dati raccolti dagli studenti sulla Satisfaction With Life Scale (SWLS) e sulla Lubben Social Network Scale (LSNS-6). Le variabili incluse sono:\n\n\nSWLS: Punteggio totale della Scala di Soddisfazione per la Vita.\n\nLSNS-6: Punteggio totale sulla scala della rete sociale.\n\nGenere: Maschio/Femmina.\n\nTipo di scuola superiore: Liceo classico o scientifico vs. altro.\n\nNumero di amici: Auto-riferito.\n\nNumero di uscite settimanali con gli amici.\n\nUtilizzerai questi dati per esplorare le distribuzioni, creare visualizzazioni efficaci e interpretare i risultati.\nEsercizi Teorici\n\n\nPrincipi della visualizzazione\n\nQuali sono i principali segnali visivi utilizzati nella visualizzazione dei dati? Fornisci un esempio pratico per ognuno.\nPerché la posizione e la lunghezza sono considerati segnali visivi più efficaci rispetto all’area e agli angoli?\nSpiega perché i grafici tridimensionali (3D) sono spesso inutili o fuorvianti.\n\n\n\nScelta della visualizzazione\n\nQuale tipo di grafico useresti per mostrare la distribuzione della variabile SWLS? Giustifica la tua risposta.\nSe volessi confrontare la distribuzione della SWLS tra due gruppi (ad esempio, in base al genere), quale grafico useresti? Perché?\n\n\n\nErrori comuni nella visualizzazione\n\nPerché i dynamite plots (grafici a barre con errore standard) sono considerati una cattiva pratica?\nSpiega perché è importante iniziare l’asse Y da zero in un barplot.\nPerché è preferibile ordinare le categorie in base ai valori invece che alfabeticamente?\n\n\n\nEsercizi Pratici in R\n1. Caricamento e ispezione dei dati\nCarica il dataset raccolto dagli studenti (dati_SWLS_LSNS.csv) e stampa un’anteprima dei dati.\n# Caricamento dei dati\ndf &lt;- read.csv(\"dati_SWLS_LSNS.csv\")\n\n# Esamina le prime righe\nhead(df)\nRispondi alle seguenti domande:\n\nQuante osservazioni ci sono nel dataset?\nCi sono valori mancanti? Se sì, quanti?\n\n2. Distribuzione delle variabili\nCrea le seguenti visualizzazioni per analizzare la distribuzione di SWLS e LSNS-6:\n\n\nIstogramma con sovrapposta la curva di densità.\n\nFunzione di distribuzione cumulativa empirica (eCDF).\n\nBox plot per la variabile SWLS.\n\n3. Confronto tra gruppi\n\nCrea un box plot della SWLS per genere.\nCrea un violin plot della LSNS-6 in base al tipo di scuola superiore.\n\n4. Relazioni tra variabili\n\nCrea un grafico di dispersione (scatter plot) per verificare se c’è una relazione tra il punteggio SWLS e il numero di amici.\nAggiungi una linea di regressione al grafico per facilitare l’interpretazione.\n\nggplot(df, aes(x = numero_amici, y = SWLS)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(title = \"Relazione tra SWLS e numero di amici\",\n       x = \"Numero di amici\",\n       y = \"Satisfaction With Life Scale (SWLS)\")\nDomande:\n\nQuale relazione osservi tra il numero di amici e la SWLS?\nIl numero di amici è un buon predittore della soddisfazione per la vita?\n\n5. Esplorazione della rete sociale\n\nCrea un barplot per mostrare la distribuzione delle risposte medie ai sei item della LSNS-6.\nEsplora la relazione tra la frequenza delle uscite settimanali e il punteggio totale LSNS-6 utilizzando un box plot.\n\nConsegna\nSalva i grafici creati e rispondi alle domande in forma scritta. Carica il file su Moodle.\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n1. Risposte alle domande teoriche\nPrincipi della visualizzazione\n\nI segnali visivi principali sono posizione, lunghezza, angoli, area, luminosità e colore.\nLa posizione e lunghezza sono i segnali più efficaci perché l’occhio umano è molto preciso nel confrontare distanze e altezze, mentre è meno efficace nel confrontare angoli e aree.\nI grafici tridimensionali (3D) spesso aggiungono confusione senza migliorare la leggibilità.\n\nScelta della visualizzazione\n\nPer mostrare la distribuzione della SWLS, è preferibile usare istogrammi e box plot perché evidenziano la forma della distribuzione e la presenza di outlier.\nPer confrontare la SWLS tra generi, un box plot o violin plot è l’opzione migliore, perché mostra la distribuzione completa.\n\nErrori comuni\n\nI dynamite plots nascondono la distribuzione dei dati e non mostrano la variabilità interna ai gruppi.\nIn un barplot, l’asse Y deve iniziare da zero per evitare distorsioni visive.\nLe categorie nei barplot devono essere ordinate per valore per facilitare il confronto.\n\n2. Soluzioni pratiche in R\nCaricamento dei dati\ndf &lt;- read.csv(\"dati_SWLS_LSNS.csv\")\n\n# Esamina il dataset\ndim(df)  # Numero di righe e colonne\nsum(is.na(df))  # Conteggio valori mancanti\nDistribuzione delle variabili\nggplot(df, aes(x = SWLS)) +\n  geom_histogram(\n  aes(y = after_stat(density)), bins = 10, fill = \"blue\", alpha = 0.5\n  ) +\n  geom_density(color = \"red\", size = 1.2)\nggplot(df, aes(SWLS)) +\n  stat_ecdf(geom = \"step\")\nggplot(df, aes(x = \"\", y = SWLS)) +\n  geom_boxplot() +\n  coord_flip()\nConfronto tra gruppi\nggplot(df, aes(x = genere, y = SWLS, fill = genere)) +\n  geom_boxplot()\nggplot(df, aes(x = scuola, y = LSNS6, fill = scuola)) +\n  geom_violin()\nRelazioni tra variabili\nggplot(df, aes(x = numero_amici, y = SWLS)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE)\nggplot(df, aes(x = uscite_settimanali, y = LSNS6)) +\n  geom_boxplot()\nConclusioni\n(Ad esempio) Le visualizzazioni mostrano che:\n\nSWLS e LSNS-6 variano in base al genere e al tipo di scuola.\nIl numero di amici ha un impatto positivo sulla SWLS, ma la relazione è moderata.\nIl numero di uscite settimanali è correlato positivamente con la rete sociale (LSNS-6).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#bibliografia",
    "href": "chapters/eda/06_data_visualization.html#bibliografia",
    "title": "18  Principi della visualizzazione dei dati",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nHealy, K. (2018). Data visualization: a practical introduction. Princeton University Press.\n\n\nIrizarry, R. A. (2024). Introduction to Data Science: Data Wrangling and Visualization with R. CRC Press.\n\n\nWickham, H., Çetinkaya-Rundel, M., & Grolemund, G. (2023). R for data science. \" O’Reilly Media, Inc.\".\n\n\nWilke, C. O. (2019). Fundamentals of data visualization: a primer on making informative and compelling figures. O’Reilly Media.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html",
    "href": "chapters/eda/07_loc_scale.html",
    "title": "19  Indicatori di tendenza centrale e variabilità",
    "section": "",
    "text": "19.1 Introduzione\nLa visualizzazione grafica dei dati rappresenta il pilastro fondamentale di ogni analisi quantitativa. Grazie alle rappresentazioni grafiche adeguate, è possibile individuare importanti caratteristiche di una distribuzione, quali la simmetria o l’asimmetria, nonché la presenza di una o più mode. Successivamente, al fine di descrivere sinteticamente le principali caratteristiche dei dati, si rende necessario l’utilizzo di specifici indici numerici. In questo capitolo, verranno presentati i principali indicatori della statistica descrittiva.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#indici-di-tendenza-centrale",
    "href": "chapters/eda/07_loc_scale.html#indici-di-tendenza-centrale",
    "title": "19  Indicatori di tendenza centrale e variabilità",
    "section": "\n19.2 Indici di Tendenza Centrale",
    "text": "19.2 Indici di Tendenza Centrale\nGli indici di tendenza centrale sono misure statistiche che cercano di rappresentare un valore tipico o centrale all’interno di un insieme di dati. Sono utilizzati per ottenere una comprensione immediata della distribuzione dei dati senza dover analizzare l’intero insieme. Gli indici di tendenza centrale sono fondamentali nell’analisi statistica, in quanto forniscono una sintesi semplice e comprensibile delle caratteristiche principali di un insieme di dati. I principali indici di tendenza centrale sono:\n\n\nMedia: La media è la somma di tutti i valori divisa per il numero totale di valori. È spesso utilizzata come misura generale di tendenza centrale, ma è sensibile agli estremi (valori molto alti o molto bassi).\n\nMediana: La mediana è il valore che divide l’insieme di dati in due parti uguali. A differenza della media, non è influenzata da valori estremi ed è quindi più robusta in presenza di outlier.\n\nModa: La moda è il valore che appare più frequentemente in un insieme di dati. In alcuni casi, può non essere presente o esserci più di una moda.\n\nLa scelta dell’indice di tendenza centrale appropriato dipende dalla natura dei dati e dall’obiettivo dell’analisi. Ad esempio, la mediana potrebbe essere preferita alla media se l’insieme di dati contiene valori anomali che potrebbero distorcere la rappresentazione centrale. La conoscenza e l’applicazione corretta di questi indici possono fornire una preziosa intuizione sulle caratteristiche centrali di una distribuzione di dati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#moda",
    "href": "chapters/eda/07_loc_scale.html#moda",
    "title": "19  Indicatori di tendenza centrale e variabilità",
    "section": "\n19.3 Moda",
    "text": "19.3 Moda\nLa moda (\\(\\text{Mo}\\)) rappresenta il valore della variabile che compare con maggiore frequenza in una distribuzione. In altre parole, è il valore più ricorrente nei dati.\n- Nelle distribuzioni unimodali, esiste una sola moda, che coincide con il valore centrale della distribuzione più frequente.\n- Tuttavia, in alcune distribuzioni, possono emergere più di una moda, rendendole multimodali. In questi casi, la moda perde il suo significato di indicatore unico di tendenza centrale, poiché la presenza di più valori con frequenze elevate rende difficile individuare un singolo punto di riferimento.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#mediana",
    "href": "chapters/eda/07_loc_scale.html#mediana",
    "title": "19  Indicatori di tendenza centrale e variabilità",
    "section": "\n19.4 Mediana",
    "text": "19.4 Mediana\nLa mediana (\\(\\tilde{x}\\)) corrisponde al valore che divide il campione in due metà: il 50% dei dati è inferiore o uguale alla mediana e il restante 50% è superiore o uguale. A differenza della media, la mediana è meno influenzata dai valori estremi, rendendola una misura particolarmente robusta in presenza di dati asimmetrici o outlier.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#media",
    "href": "chapters/eda/07_loc_scale.html#media",
    "title": "19  Indicatori di tendenza centrale e variabilità",
    "section": "\n19.5 Media",
    "text": "19.5 Media\nLa media aritmetica di un insieme di valori rappresenta il punto centrale o il baricentro della distribuzione dei dati. È calcolata come la somma di tutti i valori divisa per il numero totale di valori, ed è espressa dalla formula:\n\\[\n\\bar{x}=\\frac{1}{n}\\sum_{i=1}^n x_i,\n\\tag{19.1}\\]\ndove \\(x_i\\) rappresenta i valori nell’insieme, \\(n\\) è il numero totale di valori, e \\(\\sum\\) indica la sommatoria.\n\n19.5.1 Calcolo della Media con R\n\nPer calcolare la media di un piccolo numero di valori in R, possiamo utilizzare la somma di questi valori e dividerla per il numero totale di elementi. Consideriamo ad esempio i valori 12, 44, 21, 62, 24:\n\n(12 + 44 + 21 + 62 + 24) / 5\n#&gt; [1] 32.6\n\novvero\n\nx &lt;- c(12, 44, 21, 62, 24)\nmean(x)\n#&gt; [1] 32.6\n\n\n19.5.2 Proprietà della Media\nUna proprietà fondamentale della media è che la somma degli scarti di ciascun valore dalla media è zero:\n\\[\n\\sum_{i=1}^n (x_i - \\bar{x}) = 0.\\notag\n\\tag{19.2}\\]\nInfatti,\n\\[\n\\begin{aligned}\n\\sum_{i=1}^n (x_i - \\bar{x}) &= \\sum_i x_i - \\sum_i \\bar{x}\\notag\\\\\n&= \\sum_i x_i - n \\bar{x}\\notag\\\\\n&= \\sum_i x_i - \\sum_i x_i = 0.\\notag\n\\end{aligned}\n\\]\nQuesta proprietà implica che i dati sono equamente distribuiti intorno alla media.\nIn R abbiamo:\n\nsum(x - mean(x))\n#&gt; [1] -7.105e-15\n\n\n\n\n\n\n\nNota\n\n\n\n\n\nQuando in un terminale viene visualizzato un numero come -7.105e-15 in notazione scientifica, esso corrisponde a \\(-7.105 \\cdot 10^{-15}\\), che è effettivamente zero nel contesto dei calcoli numerici.\nQuesta approssimazione è una conseguenza diretta della precisione finita dei calcolatori. I sistemi digitali, infatti, rappresentano i numeri reali attraverso una codifica in virgola mobile (floating point), che comporta inevitabili errori di arrotondamento. La ragione risiede nell’impossibilità di memorizzare numeri reali con precisione assoluta.\nLo standard IEEE 754 a doppia precisione (64 bit), ampiamente utilizzato, suddivide la memoria in tre componenti:\n\n1 bit per il segno (positivo/negativo),\n\n11 bit per l’esponente (intervallo di scala),\n\n52 bit per la mantissa (o significando), che definisce le cifre significative.\n\nGrazie a questa struttura, è possibile rappresentare numeri con una precisione di circa 15-17 cifre decimali. Tuttavia, qualsiasi valore non esprimibile in formato binario entro questi limiti subisce un troncamento o un arrotondamento, generando piccole discrepanze rispetto al risultato teorico.\n\n\n\n\n19.5.3 La media come Centro di Gravità dell’Istogramma\nLa media aritmetica può essere interpretata come il centro di gravità o il punto di equilibrio della distribuzione dei dati. In termini fisici, il centro di gravità è il punto in cui la massa di un sistema è equilibrata o concentrata.\nIn termini statistici, possiamo considerare la media come il punto in cui la distribuzione dei dati è in equilibrio. Ogni valore dell’insieme di dati può essere visto come un punto materiale con una massa proporzionale al suo valore. Se immaginiamo questi punti disposti su una linea, con valori più grandi a destra e più piccoli a sinistra, la media corrisponderà esattamente al punto in cui la distribuzione sarebbe in equilibrio.\n\n19.5.4 Principio dei Minimi Quadrati\nIl metodo dei minimi quadrati afferma che la posizione della media minimizza la somma dei quadrati delle distanze dai dati. Matematicamente, ciò significa che la somma dei quadrati degli scarti tra ciascun valore osservato e la media è minima. Questo principio è alla base dell’analisi statistica della regressione e conferma il ruolo della media come centro di gravità della distribuzione dei dati.\n\n19.5.4.1 Simulazione\nUtilizziamo una simulazione per verificare questo principio, calcolando la somma dei quadrati degli scarti per diversi valori e visualizzando il risultato con ggplot2.\n\n# Definizione dell'intervallo di valori da testare\nnrep &lt;- 10000\nM &lt;- seq(20, 40, length.out = nrep)\nres &lt;- rep(NA, nrep)\n\n# Calcolo della somma dei quadrati degli scarti per ciascun valore di M\nfor (i in 1:nrep) {\n  res[i] = sum((x - M[i])^2)\n}\n\n# Identificazione del valore minimo\nmin_index &lt;- which.min(res)\nmin_M &lt;- M[min_index]\n\n# Creazione del dataframe per ggplot\ndf &lt;- data.frame(M, res)\n\ndf |&gt; \n  ggplot(aes(x = M, y = res)) +\n  geom_line(color = \"blue\") +\n  geom_vline(xintercept = min_M, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Minimizzazione della somma dei quadrati\",\n    x = \"Valore di M\",\n    y = \"Somma dei quadrati degli scarti\"\n  ) \n\n\n\n\n\n\n\nStampiamo il minimo:\n\nmin_M\n#&gt; [1] 32.6\n\nConfronto con la media:\n\nmean(x)\n#&gt; [1] 32.6\n\nOsserviamo che il valore di M che minimizza la somma dei quadrati degli scarti coincide con la media dei dati, confermando il principio dei minimi quadrati.\n\n19.5.5 Le Proporzioni Sono Medie\nSe una collezione consiste solo di uni e zeri, allora la somma della collezione è il numero di uni in essa, e la media della collezione è la proporzione di uni.\n\nzero_one &lt;- c(1, 1, 1, 0)\nresult &lt;- mean(zero_one)\nresult\n#&gt; [1] 0.75\n\nÈ possibile sostituire 1 con il valore booleano True e 0 con False:\n\nmean(c(TRUE, TRUE, TRUE, FALSE))\n#&gt; [1] 0.75\n\n\n19.5.6 Limiti della Media Aritmetica\nLa media aritmetica, tuttavia, ha alcune limitazioni: non sempre è l’indice più adeguato per descrivere accuratamente la tendenza centrale della distribuzione, specialmente quando si verificano asimmetrie o valori anomali (outlier). In queste situazioni, è più indicato utilizzare la mediana o la media spuntata (come spiegheremo successivamente).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#come-descrivere-la-tendenza-centrale-in-distribuzioni-asimmetriche",
    "href": "chapters/eda/07_loc_scale.html#come-descrivere-la-tendenza-centrale-in-distribuzioni-asimmetriche",
    "title": "19  Indicatori di tendenza centrale e variabilità",
    "section": "\n19.6 Come Descrivere la Tendenza Centrale in Distribuzioni Asimmetriche",
    "text": "19.6 Come Descrivere la Tendenza Centrale in Distribuzioni Asimmetriche\nIl diverso significato degli indici di tendenza centrale – moda, media e mediana – diventa evidente quando si analizzano distribuzioni asimmetriche. Per illustrare questo concetto, utilizzeremo i dati del Progetto Natsal, contenuti nel file sexual-partners.csv.\nNegli anni ’80, con la crescente preoccupazione per l’AIDS, le autorità sanitarie del Regno Unito si resero conto della mancanza di dati affidabili sui comportamenti sessuali della popolazione. In particolare, vi erano dubbi sulla frequenza con cui le persone cambiavano partner, sul numero di partner simultanei e sulle pratiche sessuali adottate. Questa conoscenza era essenziale per prevedere la diffusione delle malattie sessualmente trasmissibili nella società e per pianificare adeguatamente i servizi sanitari. Tuttavia, si faceva ancora riferimento ai dati raccolti da Alfred Kinsey negli Stati Uniti negli anni ’40, che non tenevano conto della rappresentatività del campione.\nA partire dalla fine degli anni ’80, vennero dunque avviati nel Regno Unito e negli Stati Uniti ampi e rigorosi studi sui comportamenti sessuali, nonostante una forte opposizione in alcuni ambienti. Nel Regno Unito, il governo guidato da Margaret Thatcher ritirò il proprio sostegno a un’importante indagine sui comportamenti sessuali all’ultimo momento. Fortunatamente, i ricercatori riuscirono a ottenere finanziamenti da enti benefici, dando vita al National Sexual Attitudes and Lifestyles Survey (Natsal). Da allora, questa indagine viene condotta ogni dieci anni, a partire dal 1990. La terza rilevazione, denominata Natsal-3, è stata effettuata intorno al 2010.\nPoniamoci il problema di descrivere la tendenza centrale per i dati contenuti nel file sexual-partners.csv, separatamente per maschi e femmine. Il dataset fornisce la distribuzione del numero totale dichiarato di partner sessuali di sesso opposto nella vita per uomini e donne di età compresa tra 35 e 44 anni. I dati provengono dal sondaggio Natsal-3 e corrispondono a un totale di 796 uomini e 1193 donne.\nProcediamo all’importazione dei dati per iniziare l’analisi.\n\ndf &lt;- rio::import(here::here(\"data\", \"sexual-partners.csv\"))\n\nEsaminiamo alcune righe prese a caso dal data frame df:\n\ndf[sample(1:nrow(df), size = 10, replace = FALSE), ]\n#&gt;      Gender NumPartners\n#&gt; 561     Man          15\n#&gt; 321     Man           6\n#&gt; 1177  Woman           3\n#&gt; 1098  Woman           2\n#&gt; 1252  Woman           4\n#&gt; 1170  Woman           3\n#&gt; 634     Man          21\n#&gt; 49      Man           1\n#&gt; 1152  Woman           3\n#&gt; 1327  Woman           5\n\nLa colonna Gender riporta il genere del rispondente e la colonna NumPartners il numero di partner sessuali di sesso opposto dichiarati.\nEsaminiamo la numerosità di ciascun gruppo.\n\ndf |&gt; \n  group_by(Gender) |&gt; \n  summarize(count = n())\n#&gt; # A tibble: 2 × 2\n#&gt;   Gender count\n#&gt;   &lt;chr&gt;  &lt;int&gt;\n#&gt; 1 Man      796\n#&gt; 2 Woman   1193\n\nPoniamoci innnanzitutto il problema di visualizzare i dati con un istogramma, separatamente per maschi e femmine. Per ragioni di spazio ci limiteremo ad un numero massimo di partner sessuali di 50 (ma in questo campione il numero massimo arriva a 501 per gli uomini e 550 per le donne):\n\ndf |&gt; \n  group_by(Gender) |&gt; \n  summarize(maximum = max(NumPartners))\n#&gt; # A tibble: 2 × 2\n#&gt;   Gender maximum\n#&gt;   &lt;chr&gt;    &lt;int&gt;\n#&gt; 1 Man        501\n#&gt; 2 Woman      550\n\nIniziamo calcolando la percentuale di intervistati per ciascun valore possibile della variabile “numero di partner sessuali”, compreso tra 0 e 50. Il calcolo verrà svolto in due passaggi:\n\nConteggio delle frequenze assolute: Per ogni valore della variabile “numero di partner sessuali” e per ciascun gruppo di genere (uomini e donne), contiamo quante volte quel valore compare nei dati.\nCalcolo delle percentuali relative: Per ciascun gruppo di genere, dividiamo il conteggio di ogni valore per il totale delle osservazioni nel gruppo e moltiplichiamo per 100 per ottenere la percentuale.\n\n\n# Filtra i dati troncando il numero di partner a 50\ndf_truncated &lt;- df[df$NumPartners &lt;= 50, ]\n\n# Calcola il conteggio per ciascun genere e numero di partner\ncounts_data &lt;- df_truncated %&gt;%\n  group_by(Gender, NumPartners) %&gt;%  # Raggruppa per genere e numero di partner\n  summarise(Count = n(), .groups = \"drop\")  # Conta le occorrenze\n\n# Aggiunge la percentuale relativa per ciascun genere\npercentage_data &lt;- counts_data %&gt;%\n  group_by(Gender) %&gt;%  # Raggruppa nuovamente per genere\n  mutate(Percentage = Count / sum(Count) * 100)  # Calcola la percentuale\n\nhead(percentage_data)\n#&gt; # A tibble: 6 × 4\n#&gt; # Groups:   Gender [1]\n#&gt;   Gender NumPartners Count Percentage\n#&gt;   &lt;chr&gt;        &lt;int&gt; &lt;int&gt;      &lt;dbl&gt;\n#&gt; 1 Man              0     6      0.789\n#&gt; 2 Man              1   100     13.2  \n#&gt; 3 Man              2    44      5.79 \n#&gt; 4 Man              3    39      5.13 \n#&gt; 5 Man              4    58      7.63 \n#&gt; 6 Man              5    51      6.71\n\nPossiamo ora creare gli istogrammi per maschi e femmine:\n\n# Crea l'istogramma separato per maschi e femmine\ngender_labels &lt;- c(\"Man\" = \"Uomini 35-44\", \"Woman\" = \"Donne 35-44\")\n\n# Trova il massimo valore di Percentage per impostare lo stesso limite\ny_max &lt;- max(percentage_data$Percentage)\n\n# Grafico con limiti dell'asse y uguali nei due pannelli\npercentage_data |&gt;\n  ggplot(aes(NumPartners, Percentage, fill = Gender)) +\n  geom_col(position = \"dodge\", color = \"black\") +\n  facet_wrap(~Gender, labeller = labeller(Gender = gender_labels)) +\n  scale_y_continuous(limits = c(0, y_max)) +  # Imposta i limiti dell'asse y\n  labs(\n    x = \"Numero di partner sessuali di sesso opposto dichiarati nella vita\",\n    y = \"Percentuale\"\n  ) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\n\n\nSenza distinguere per genere, è possibile ottenere l’istogramma con il seguente codice:\n\ndf_truncated |&gt;\n  ggplot(\n    aes(\n      x = NumPartners,\n      y = after_stat(density)\n    )\n  ) +\n  geom_histogram(binwidth = 2, fill = \"lightblue\", color = \"black\", alpha = 0.7) +\n  labs(\n    title = \"Distribuzione del Numero di Partner Sessuali\",\n    x = \"Numero di Partner\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\nSi noti l’uso di y = after_stat(density) all’interno di aes(), che consente di normalizzare l’istogramma affinché l’area totale sia pari a 1. In questo modo, l’istogramma rappresenta una densità di probabilità anziché una semplice frequenza assoluta.\n\n\n\nNotiamo che la distribuzione è altamente asimmetrica positiva. Come possiamo descrivere la tendenza centrale di questi dati?\nCalcoliamo gli indici di tendenza centrale all’interno dei due gruppi. Per la moda utilizziamo una funzione personalizzata:\n\n# Funzione personalizzata per calcolare la moda\nget_mode &lt;- function(x) {\n  # Calcola la tabella di frequenza e restituisce il valore con frequenza massima\n  tbl &lt;- table(x)\n  as.numeric(names(tbl)[which.max(tbl)])\n}\n\n# Calcolo delle statistiche per Gender\ndf |&gt; \n  group_by(Gender) |&gt; \n  summarise(\n    mean_sex_partner = mean(NumPartners, na.rm = TRUE),\n    median_sex_partner = median(NumPartners, na.rm = TRUE),\n    mode_sex_partner = get_mode(NumPartners)  # Usa la funzione personalizzata per la moda\n  )\n#&gt; # A tibble: 2 × 4\n#&gt;   Gender mean_sex_partner median_sex_partner mode_sex_partner\n#&gt;   &lt;chr&gt;             &lt;dbl&gt;              &lt;dbl&gt;            &lt;dbl&gt;\n#&gt; 1 Man               17.0                   8                1\n#&gt; 2 Woman              8.23                  5                1\n\n\n\n\n\n\n\nNota\n\n\n\n\n\nPer trovare la moda, anziché definire una funzione personalizzata come get_mode() è anche possibile usare dplyr:\n\ndf |&gt; \n  group_by(Gender) |&gt; \n  summarise(\n    mean_sex_partner = mean(NumPartners, na.rm = TRUE),\n    median_sex_partner = median(NumPartners, na.rm = TRUE),\n    mode_sex_partner = as.numeric(names(which.max(table(NumPartners))))\n  )\n#&gt; # A tibble: 2 × 4\n#&gt;   Gender mean_sex_partner median_sex_partner mode_sex_partner\n#&gt;   &lt;chr&gt;             &lt;dbl&gt;              &lt;dbl&gt;            &lt;dbl&gt;\n#&gt; 1 Man               17.0                   8                1\n#&gt; 2 Woman              8.23                  5                1\n\nQuesta soluzione evita la definizione esplicita di una funzione get_mode(), ma il principio è lo stesso.\n\n\n\nÈ evidente che, quando la distribuzione dei dati è altamente asimmetrica, come nel caso attuale, gli indici di tendenza centrale – media, mediana e moda – possono fornire risultati molto diversi, rendendo difficile individuare una misura rappresentativa della tendenza centrale.\n\nLa media risulta più elevata rispetto alla mediana e alla moda. Questo è tipico di una distribuzione asimmetrica positiva, caratterizzata da una lunga coda destra: pochi individui con valori estremamente alti influenzano la media, spostandola verso destra.\n\nLa mediana, invece, rappresenta il valore centrale della distribuzione e risulta meno influenzata dai valori estremi. Per questo motivo, è spesso più vicina alla “realtà” dei dati, offrendo una stima più robusta della tendenza centrale per la maggior parte degli individui.\n\nLa moda, infine, corrisponde al valore più frequente nella distribuzione (in questo caso, 1 partner). Tuttavia, in presenza di un’elevata dispersione dei dati, la moda può risultare poco rappresentativa della distribuzione complessiva.\n\nIn conclusione, quando la distribuzione è fortemente asimmetrica, la mediana è generalmente l’indice di tendenza centrale più appropriato. Essendo insensibile ai valori estremi, fornisce una rappresentazione più robusta della “posizione centrale” dei dati. Tuttavia, è utile integrare la mediana con la media e la moda per offrire un quadro più completo della distribuzione.\nPer una descrizione efficace della tendenza centrale in distribuzioni asimmetriche, si consiglia dunque di seguire questa procedura:\n\nutilizzare la mediana come misura principale della tendenza centrale;\n\nriportare media e moda come complemento per confrontare i risultati e interpretare eventuali differenze.\n\nÈ comunque fondamentale visualizzare la distribuzione dei dati attraverso grafici appropriati, come istogrammi o boxplot. Questi strumenti consentono di evidenziare chiaramente l’asimmetria, identificare valori estremi e comprendere meglio la struttura dei dati.\nInoltre, per arricchire i sommari numerici, è importante associare indici di dispersione che tratteremo in seguito.\n\n19.6.1 Media Spuntata\nLa media spuntata, indicata come \\(\\bar{x}_t\\) o trimmed mean, è un metodo di calcolo della media che prevede l’eliminazione di una determinata percentuale di dati estremi prima di effettuare la media aritmetica. Solitamente, viene eliminato il 10% dei dati, ovvero il 5% all’inizio e alla fine della distribuzione. Per ottenere la media spuntata, i dati vengono ordinati in modo crescente, \\(x_1 \\leq x_2 \\leq x_3 \\leq \\dots \\leq x_n\\), e quindi viene eliminato il primo 5% e l’ultimo 5% dei dati nella sequenza ordinata. Infine, la media spuntata è calcolata come la media aritmetica dei dati rimanenti. Questo approccio è utile quando ci sono valori anomali o quando la distribuzione è asimmetrica e la media aritmetica non rappresenta adeguatamente la tendenza centrale dei dati.\n\nEsempio 19.1 A titolo di esempio, procediamo al calcolo della media spuntata dei valori NumPartners per i due gruppi definiti dalla variabile Gender, escludendo il 10% dei valori più estremi.\n\nglimpse(df)\n#&gt; Rows: 1,989\n#&gt; Columns: 2\n#&gt; $ Gender      &lt;chr&gt; \"Man\", \"Man\", \"Man\", \"Man\", \"Man\", \"Man\", \"Man\", \"Man\"…\n#&gt; $ NumPartners &lt;int&gt; 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n\nUomini:\n\nsex_partners_men &lt;- df[df$Gender == \"Man\", \"NumPartners\"]\nmean(sex_partners_men, trim = 0.10, na.rm = TRUE)\n#&gt; [1] 10.6\n\nDonne:\n\nsex_partners_women &lt;- df[df$Gender == \"Woman\", \"NumPartners\"]\nmean(sex_partners_women, trim = 0.10, na.rm = TRUE)\n#&gt; [1] 6.013\n\n\n\n19.6.2 Quando Usare Media, Media Spuntata, Moda e Mediana\nLa scelta della misura di tendenza centrale più appropriata dipende dal tipo di dati, dalla distribuzione e dalla presenza di valori anomali o asimmetrie.\n\n19.6.2.1 Moda\nLa moda è il valore che compare con maggiore frequenza nei dati ed è l’unica misura di tendenza centrale utilizzabile per dati a livello nominale (categorie senza ordine) o ordinale (categorie ordinate ma senza distanza definita). Tuttavia:\n- In una distribuzione unimodale, la moda può rappresentare un indicatore significativo della tendenza centrale.\n- In distribuzioni multimodali (con più valori ricorrenti), la moda diventa meno interpretabile, poiché l’esistenza di più “picchi” rende difficile individuare un singolo valore rappresentativo.\n- Nei dati continui, la moda può non essere definita o risultare meno informativa, soprattutto in presenza di valori unici.\n\n19.6.2.2 Media\nLa media aritmetica è una misura efficace di tendenza centrale se la distribuzione è simmetrica e priva di valori anomali. In tali condizioni, la media rappresenta il “baricentro” della distribuzione, equilibrando i valori a sinistra e a destra. Tuttavia:\n\nIn distribuzioni asimmetriche o con outlier, la media è fortemente influenzata dai valori estremi e tende a spostarsi nella direzione della coda più lunga (asimmetria positiva o negativa).\n\nIn questi casi, la media potrebbe non essere rappresentativa della tendenza centrale reale.\n\n19.6.2.3 Media Spuntata\nLa media spuntata è una versione modificata della media, calcolata dopo aver rimosso una certa percentuale di valori estremi (generalmente il 5% o il 10%) sia dalla coda inferiore che da quella superiore della distribuzione. Questa misura è particolarmente utile quando:\n- La distribuzione è asimmetrica o contiene outlier, ma si desidera comunque una stima della tendenza centrale che consideri gran parte dei dati.\n- La media spuntata è meno sensibile ai valori anomali rispetto alla media tradizionale, pur mantenendo il vantaggio di considerare un’ampia porzione dei dati.\n\n19.6.2.4 Mediana\nLa mediana è il valore centrale che divide il campione in due metà: il 50% dei dati è inferiore e il restante 50% è superiore. È una misura robusta della tendenza centrale, particolarmente adatta quando:\n- La distribuzione è asimmetrica o contiene valori anomali. Poiché si basa sulla posizione dei dati e non sulle loro dimensioni, la mediana non è influenzata da valori estremi.\n- Nei dati ordinali, la mediana è spesso più appropriata della media, poiché non richiede una scala numerica con distanze precise.\n\n19.6.2.5 Quale Misura Scegliere?\n\nDistribuzioni Simmetriche:\nLa media è la scelta più appropriata, poiché riflette bene la tendenza centrale.\nDistribuzioni Asimmetriche o con Outlier:\nLa mediana è preferibile perché è robusta e meno influenzata dai valori estremi. In alternativa, si può utilizzare la media spuntata per ottenere un compromesso tra media e mediana.\nDati Categoriali:\nLa moda è l’unica misura applicabile, ma è interpretabile solo in distribuzioni unimodali.\nDistribuzioni Multimodali:\nIn questo caso, è importante visualizzare i dati (ad esempio con un istogramma) e descrivere ciascun “picco” separatamente, poiché nessuna delle misure tradizionali (media, mediana, moda) sarà sufficiente da sola per rappresentare la tendenza centrale.\n\nIn conclusione\n\nLa media è ideale per distribuzioni simmetriche senza valori estremi.\n\nLa mediana è più robusta e appropriata in caso di asimmetria o outlier.\n\nLa media spuntata rappresenta una soluzione intermedia utile nei casi con pochi valori anomali.\n\nLa moda è rilevante solo per dati nominali o ordinale, ma perde significato in distribuzioni multimodali.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#quantili-e-misure-di-dispersione",
    "href": "chapters/eda/07_loc_scale.html#quantili-e-misure-di-dispersione",
    "title": "19  Indicatori di tendenza centrale e variabilità",
    "section": "\n19.7 Quantili e Misure di Dispersione",
    "text": "19.7 Quantili e Misure di Dispersione\nAccanto alle misure di tendenza centrale (media, mediana, moda), i quantili descrivono la posizione relativa di un’osservazione all’interno di una distribuzione. Mentre le misure di tendenza centrale identificano un “valore tipico”, i quantili rispondono alla domanda: Qual è il valore al di sotto del quale si trova una certa proporzione dei dati?\n\n19.7.1 Definizione Formale\nIl quantile non interpolato di ordine \\(p\\) (\\(0 &lt; p &lt; 1\\)) è il valore \\(q_p = x_{(k)}\\), dove:\n\n\n\\(x_{(k)}\\) è il \\(k\\)-esimo elemento nei dati ordinati in modo crescente.\n\n\\(k = \\lceil p \\cdot n \\rceil\\), con \\(n =\\) numero totale di osservazioni e \\(\\lceil \\cdot \\rceil\\) la funzione arrotondamento all’intero superiore.\n\n\n19.7.1.1 Esempio di Calcolo\nDati ordinati: \\(\\{15, 20, 23, 25, 28, 30, 35, 40, 45, 50\\}\\).\nCalcolo del 30° percentile (\\(p = 0.3\\)):\n\n\n\\(k = \\lceil 0.3 \\cdot 10 \\rceil = 3\\).\nIl quantile corrisponde al terzo valore: \\(q_{0.3} = 23\\).\n\n19.7.2 Tipologie di Quantili\n\n19.7.2.1 Quantili Interpolati\nQuando \\(p \\cdot n\\) non è un intero, si utilizza un quantile interpolato, calcolato con interpolazione lineare tra due valori consecutivi. Questo metodo è standard in software statistici (es. R, Python).\n\n19.7.2.2 Percentili\nCaso particolare di quantili, dividono i dati in 100 parti uguali:\n\n\n25° percentile (primo quartile \\(Q_1\\)): 25% dei dati è inferiore a questo valore.\n\n50° percentile (mediana): Divide la distribuzione in due metà uguali.\n\n75° percentile (terzo quartile \\(Q_3\\)): 75% dei dati è inferiore a questo valore.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#importanza-dei-quantili-nellanalisi-dei-dati",
    "href": "chapters/eda/07_loc_scale.html#importanza-dei-quantili-nellanalisi-dei-dati",
    "title": "19  Indicatori di tendenza centrale e variabilità",
    "section": "\n19.8 Importanza dei Quantili nell’Analisi dei Dati",
    "text": "19.8 Importanza dei Quantili nell’Analisi dei Dati\nI quantili permettono di:\n\n\nEsplorare la variabilità: Identificare range, asimmetrie e code della distribuzione.\n\nConfrontare gruppi: Analizzare differenze nella dispersione tra sottopopolazioni.\n\nRilevare valori anomali: Utilizzando regole come \\(\\text{valore anomalo} &gt; Q_3 + 1.5 \\cdot \\text{IQR}\\).\n\n\nEsempio 19.2 Consideriamo ora la variabile NumPartners per due gruppi definiti dalla variabile Gender (“Man” e “Woman”). Calcoleremo i quantili di ordine 0.1 e 0.9 per ciascun gruppo:\n\nIl quantile di ordine 0.1 rappresenta il valore al di sotto del quale si trova il 10% dei dati.\n\nIl quantile di ordine 0.9 rappresenta il valore al di sotto del quale si trova il 90% dei dati.\n\nCalcolo per il Gruppo “Man”:\n\n# Quantili di ordine 0.1 e 0.9 per i maschi\nquantile(df[df$Gender == \"Man\", \"NumPartners\"], probs = c(0.1, 0.9))\n#&gt;  10%  90% \n#&gt;  1.0 34.5\n\n\n10° percentile (0.1): \\(1.0\\) → Il 10% degli uomini ha dichiarato al massimo 1 partner sessuale.\n\n90° percentile (0.9): \\(34.5\\) → Il 10% degli uomini con i valori più alti ha dichiarato più di 34 partner sessuali.\n\nCalcolo per il Gruppo “Woman”:\n\n# Quantili di ordine 0.1 e 0.9 per le femmine\nquantile(df[df$Gender == \"Woman\", \"NumPartners\"], probs = c(0.1, 0.9))\n#&gt; 10% 90% \n#&gt;   1  18\n\n\n10° percentile (0.1): \\(1.0\\) → Anche per le donne, il 10% dei valori più bassi corrisponde a 1 partner sessuale.\n\n90° percentile (0.9): \\(18.0\\) → Il 10% delle donne con i valori più alti ha dichiarato più di 18 partner sessuali.\n\nI quantili calcolati forniscono una descrizione chiara della dispersione e della variabilità dei dati nei due gruppi:\n\nIl fatto che il 10° percentile sia identico per entrambi i gruppi suggerisce che una porzione simile di intervistati dichiara un numero molto basso di partner sessuali.\n\nLa differenza nel 90° percentile tra uomini e donne è significativa:\n\nPer gli uomini, il valore è più alto (\\(34.5\\)), indicando una maggiore presenza di valori estremi nella coda superiore della distribuzione.\n\nPer le donne, il valore (\\(18.0\\)) è inferiore, suggerendo una minore dispersione nella parte alta della distribuzione.\n\n\n\nQuesta differenza evidenzia una asimmetria positiva più pronunciata nel gruppo degli uomini, dove pochi individui con valori elevati “tirano” la coda della distribuzione verso destra.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#la-media-come-rappresentazione-della-psicologia-umana-unarma-a-doppio-taglio",
    "href": "chapters/eda/07_loc_scale.html#la-media-come-rappresentazione-della-psicologia-umana-unarma-a-doppio-taglio",
    "title": "19  Indicatori di tendenza centrale e variabilità",
    "section": "\n19.9 La Media come Rappresentazione della Psicologia Umana: Un’Arma a Doppio Taglio?",
    "text": "19.9 La Media come Rappresentazione della Psicologia Umana: Un’Arma a Doppio Taglio?\nLa media è uno degli strumenti statistici più semplici e intuitivi che i ricercatori utilizzano per sintetizzare i dati. È un indice di tendenza centrale familiare e intuitivo: se chiediamo a un gruppo di persone la loro età e calcoliamo la media, otteniamo un valore che sintetizza in un’unica cifra l’informazione disponibile. Ma cosa significa, in realtà, “riassumere” i dati con la media? E soprattutto, questa operazione ha senso quando si studiano i processi psicologici e il comportamento umano?\nIn molte discipline scientifiche, il concetto di media è utile perché descrive fenomeni che tendono a essere stabili e uniformi. Per esempio, se misuriamo l’altezza di un gruppo di persone, possiamo aspettarci che la distribuzione sia approssimativamente normale e che la media offra una stima ragionevole di un valore tipico. Tuttavia, la mente umana e i processi psicologici non funzionano come il sistema cardiovascolare o i muscoli. Ogni persona ha esperienze uniche che plasmano le sue risposte, i suoi pensieri e le sue emozioni.\nUn problema centrale, sollevato da Speelman & McGann (2013), riguarda l’implicita assunzione che ci sia un vero valore sottostante ai processi psicologici che possiamo stimare attraverso la media, come se il comportamento umano fosse determinato da meccanismi identici in ogni individuo, con le differenze attribuibili solo a “rumore” sperimentale. Questo approccio, tipico della psicologia sperimentale tradizionale, assume che testare un gruppo di persone e mediare i loro risultati ci permetta di rivelare la struttura comune della mente umana. Ma questa assunzione è davvero giustificata?\n\n19.9.1 La Fallacia Ergodica e l’Illusione dell’Universalità\nUn errore metodologico frequente nella psicologia è la cosiddetta fallacia ergodica, ovvero l’errata convinzione che le caratteristiche medie di un gruppo possano essere automaticamente applicate ai singoli individui che lo compongono (Speelman et al., 2024). Questo equivoco nasce dall’idea che la media descriva un valore “tipico” valido per tutti, senza considerare le differenze individuali o le variazioni nel tempo.\nImmaginiamo di studiare la felicità di un gruppo di persone nel corso di una settimana e di calcolare la media dei loro punteggi di benessere giornalieri. Se lunedì una persona ha un punteggio di 2 (molto infelice), mercoledì 5 (moderatamente felice) e sabato 8 (molto felice), il suo punteggio medio sarà 5. Tuttavia, questo valore intermedio non rappresenta in alcun modo la realtà soggettiva vissuta da quella persona nei singoli giorni. Lo stesso problema si pone quando si usano le medie per descrivere abilità cognitive, tratti di personalità o stati emotivi: la media può nascondere fluttuazioni e differenze individuali fondamentali per comprendere la psicologia umana.\nIl rischio, come sottolineato da Molden & Dweck (2006), è che il nostro desiderio di trovare universalità nei processi cognitivi ci porti a enfatizzare somiglianze tra le persone, ignorando le variazioni individuali che possono essere altrettanto, se non più, informative. Per esempio, due studenti con lo stesso punteggio medio in un test di memoria potrebbero aver ottenuto quel risultato in modi completamente diversi: uno potrebbe aver avuto prestazioni costantemente nella media, mentre l’altro potrebbe aver avuto picchi di eccellenza alternati a difficoltà estreme.\n\n19.9.2 La Media: Uno Strumento da Usare con Cautela\nQuesti problemi non significano che la media sia inutile in psicologia. È un indicatore potente e spesso informativo, ma deve essere interpretato con cautela. In particolare, non può essere usata per fare inferenze sui singoli individui senza considerare altre misure, come la varianza e la deviazione standard, che ci dicono quanto i dati siano dispersi intorno alla media.\nIn psicologia, comprendere la variabilità è tanto importante quanto individuare una tendenza centrale. Se vogliamo davvero capire il comportamento umano, dobbiamo chiederci non solo qual è il valore medio? ma anche quanto variano i dati? e cosa ci dice questa variabilità sulle differenze individuali? Nella prossima sezione, esamineremo questi concetti e vedremo come la varianza e la deviazione standard ci aiutano a catturare le differenze che la media, da sola, non può rivelare.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#la-variabilità-nei-dati-psicologici",
    "href": "chapters/eda/07_loc_scale.html#la-variabilità-nei-dati-psicologici",
    "title": "19  Indicatori di tendenza centrale e variabilità",
    "section": "\n19.10 La Variabilità nei Dati Psicologici",
    "text": "19.10 La Variabilità nei Dati Psicologici\nNei fenomeni psicologici e comportamentali, la variabilità è una caratteristica intrinseca. Ad esempio, se misuriamo il livello di stress percepito da una persona più volte nella stessa giornata, è raro osservare lo stesso valore anche utilizzando strumenti identici. Allo stesso modo, un questionario standardizzato sull’autostima somministrato a un gruppo di studenti universitari restituirà punteggi differenti per ciascun partecipante. Anche registrando i tempi di reazione in un compito cognitivo, noteremo fluttuazioni sia tra individui diversi sia nelle prestazioni dello stesso individuo in prove ripetute.\nQuesta dispersione sistematica non è un “rumore” da ignorare, ma un elemento informativo cruciale. L’analisi statistica in psicologia ha infatti uno scopo duplice: da un lato, quantificare la variabilità; dall’altro, identificarne le origini. Differenze individuali, contesto ambientale, errori di misurazione o interazioni tra fattori sono solo alcune delle possibili fonti che contribuiscono alla variazione osservata.\nIn questa sezione esploreremo:\n\n\nLa scomposizione della variabilità in componenti spiegate (attribuibili a fattori noti, come un intervento sperimentale) e non spiegate (legate a elementi casuali o non controllati).\n\n\nStrumenti per descriverla, sia attraverso rappresentazioni grafiche (boxplot, istogrammi) sia mediante indici numerici (differenza interquartile, varianza, deviazione standard).\n\nComprendere la variabilità non è un esercizio tecnico, ma un passo fondamentale per interpretare fenomeni complessi come le differenze di personalità, le oscillazioni emotive o l’efficacia di una terapia. Ogni modello psicologico, infatti, deve fare i conti con questa dimensione dinamica e multideterminata dei dati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#misure-di-dispersione-basate-sui-quantili",
    "href": "chapters/eda/07_loc_scale.html#misure-di-dispersione-basate-sui-quantili",
    "title": "19  Indicatori di tendenza centrale e variabilità",
    "section": "\n19.11 Misure di Dispersione Basate sui Quantili",
    "text": "19.11 Misure di Dispersione Basate sui Quantili\nPer descrivere la variabilità dei dati, uno dei metodi più semplici consiste nell’utilizzo di indici basati sui quantili. Questi indici forniscono informazioni sulla dispersione dei valori senza fare assunzioni sulla forma della distribuzione.\n\n19.11.1 Intervallo di Variazione\nL’intervallo di variazione è la differenza tra il valore massimo e il valore minimo dei dati:\n\\[\n\\text{Intervallo} = \\max(X) - \\min(X)\n\\]\nVantaggi:\n\nFacile da calcolare e interpretare.\n\nOffre un’indicazione immediata dell’ampiezza della distribuzione.\n\nLimitazioni:\n\nConsidera solo due valori estremi della distribuzione, ignorando tutti gli altri dati.\n\nÈ fortemente influenzato dalla presenza di valori anomali (outlier), risultando poco rappresentativo della variabilità generale.\n\nEsempio:\nSupponiamo di misurare i punteggi di autostima in un campione di adolescenti e di ottenere:\\[\n\\max(X) = 35, \\quad \\min(X) = 12 .\n\\]\nL’intervallo di variazione sarà:\n\\[\n35 - 12 = 23 .\n\\]\nQuesto valore indica che i punteggi variano su un intervallo di 23 punti.\n\n19.11.2 Differenza Interquartile (Interquartile Range, IQR)\nLa differenza interquartile (IQR) misura la dispersione del 50% centrale della distribuzione, escludendo i valori più estremi:\n\\[\n\\text{IQR} = Q_3 - Q_1 .\n\\]\ndove:\n\n\n\\(Q_1\\) è il primo quartile (25° percentile), ovvero il valore sotto il quale si trova il 25% dei dati;\n\n\n\\(Q_3\\) è il terzo quartile (75° percentile), ovvero il valore sotto il quale si trova il 75% dei dati.\n\nVantaggi:\n\n\nRobusto rispetto ai valori anomali, poiché considera solo la parte centrale della distribuzione.\n\nUtile per identificare asimmetrie e la presenza di outlier.\n\nLimitazioni:\n\nNon tiene conto della dispersione complessiva dei dati, ma solo di quella nella fascia centrale.\n\nPuò essere meno informativo in distribuzioni fortemente asimmetriche o con più picchi.\n\nEsempio:\nSe analizziamo il livello di ansia in un gruppo di studenti e troviamo:\n\\[\nQ_1 = 25, \\quad Q_3 = 40 .\n\\]\nallora la differenza interquartile sarà:\n\\[\nIQR = 40 - 25 = 15 .\n\\] Ciò significa che il 50% centrale dei punteggi di ansia si distribuisce in un intervallo di 15 unità.\n\n19.11.3 Considerazioni Finali\nL’intervallo di variazione e la differenza interquartile sono due strumenti utili per descrivere la dispersione di una distribuzione, ma presentano anche delle limitazioni. L’intervallo di variazione è molto sensibile ai valori estremi, mentre la differenza interquartile, pur essendo più robusta, considera solo una parte della distribuzione.\nPer ottenere una misura della dispersione più completa, che tenga conto di tutti i dati senza essere eccessivamente influenzata dagli outlier, si ricorre spesso a misure basate sulla deviazione dai valori medi, come la varianza e la deviazione standard. Queste ultime saranno oggetto della prossima sezione.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#la-varianza",
    "href": "chapters/eda/07_loc_scale.html#la-varianza",
    "title": "19  Indicatori di tendenza centrale e variabilità",
    "section": "\n19.12 La Varianza",
    "text": "19.12 La Varianza\nLa varianza è una delle misure di dispersione più utilizzate in statistica perché tiene conto di tutte le osservazioni e descrive quanto i valori si discostano dalla loro media. Formalmente, se abbiamo \\(n\\) osservazioni \\(x_1, x_2, \\dots, x_n\\) e indichiamo con \\(\\bar{x} = \\frac{1}{n} \\sum_{i=1}^n x_i\\) la loro media, la varianza (in versione descrittiva) si calcola così:\n\\[\nS^2 = \\frac{1}{n} \\sum_{i=1}^n (x_i - \\bar{x})^2.\n\\tag{19.3}\\]\nIn altre parole, per trovare la varianza:\n\nCalcoliamo la media di tutti i valori (\\(\\bar{x}\\)).\nSottraiamo la media a ciascun valore, ottenendo così lo scarto \\((x_i - \\bar{x})\\).\nEleviamo ogni scarto al quadrato, per rendere positivi i valori ed enfatizzare gli scostamenti più grandi.\nInfine, facciamo la media di questi quadrati.\n\nMaggiore è la varianza, maggiore è la variabilità (o dispersione) dei dati rispetto alla media. Al contrario, una varianza prossima allo zero indica che le osservazioni sono molto vicine tra loro e quasi coincidenti con la media.\n\nNota su popolazione e campione: spesso, nell’analisi di dati campionari, la varianza viene calcolata usando \\(\\frac{1}{n-1}\\) al denominatore al posto di \\(\\frac{1}{n}\\). In questo modo otteniamo una stima corretta (non distorta) della varianza della popolazione. Nel contesto della formula sopra riportata, invece, stiamo calcolando la varianza descrittiva (o popolazione completa).\n\n\n19.12.1 Esempio pratico\nImmaginiamo di aver misurato il numero di ore di studio giornaliere di un piccolo gruppo di partecipanti a un esperimento di psicologia. I dati raccolti sono:\n\\[\nx = \\{3,\\, 1,\\, 4,\\, 2\\}.\n\\]\nPasso 1: Calcolo della media\n\\[\n\\bar{x} = \\frac{3 + 1 + 4 + 2}{4} = \\frac{10}{4} = 2.5.\n\\]\nPasso 2: Scarti dalla media\n\nPer il primo valore (\\(x_1 = 3\\)): \\(3 - 2.5 = 0.5\\)\n\nPer il secondo valore (\\(x_2 = 1\\)): \\(1 - 2.5 = -1.5\\)\n\nPer il terzo valore (\\(x_3 = 4\\)): \\(4 - 2.5 = 1.5\\)\n\nPer il quarto valore (\\(x_4 = 2\\)): \\(2 - 2.5 = -0.5\\)\n\n\nPasso 3: Quadrati degli scarti\n\n\\((0.5)^2 = 0.25\\)\n\\((-1.5)^2 = 2.25\\)\n\\((1.5)^2 = 2.25\\)\n\\((-0.5)^2 = 0.25\\)\n\nPasso 4: Calcolo della varianza\nFacciamo la media di questi valori:\n\\[\nS^2 = \\frac{0.25 + 2.25 + 2.25 + 0.25}{4} = \\frac{5}{4} = 1.25.\n\\]\nDunque la varianza è 1.25.\n\n19.12.2 Interpretazione\nUna varianza pari a 1.25 indica che le ore di studio giornaliere si discostano, in media, di 1.25 unità quadrate dalla media di 2.5 ore. Per comprendere meglio l’ordine di grandezza di questa dispersione, solitamente si fa riferimento alla deviazione standard, che è la radice quadrata della varianza. In questo caso, \\(\\sqrt{1.25} \\approx 1.12\\) ore.\n\nSe la varianza (o la deviazione standard) fosse stata molto più grande, avremmo dedotto che gli studenti del campione presentano abitudini di studio molto diverse.\nAl contrario, se la varianza fosse prossima a 0, significherebbe che quasi tutti studiano un numero di ore molto simile a 2.5.\n\n19.12.3 Calcolo in R\nSe volessimo effettuare lo stesso calcolo in R, potremmo fare così:\n\n# Dati\nx &lt;- c(3, 1, 4, 2)\n\n# Calcolo manuale della media\nmedia_x &lt;- mean(x)\n\n# Calcolo manuale della varianza secondo la formula descrittiva\nvarianza_descr &lt;- mean((x - media_x)^2)\nvarianza_descr\n#&gt; [1] 1.25\n# [1] 1.25\n\n# Calcolo della varianza con la funzione var() di R\n# (Attenzione: per default var() usa n-1 al denominatore)\nvarianza_campionaria &lt;- var(x)\nvarianza_campionaria\n#&gt; [1] 1.667\n# [1] 1.666667\n\nOsserviamo che var(x) dà un valore di circa 1.67 perché R, di default, calcola la varianza campionaria (con \\(n-1\\) al denominatore). Se vogliamo la varianza descrittiva (come nella formula con \\(n\\) al denominatore), usiamo la nostra varianza_descr.\nIn sintesi, la varianza fornisce un modo per quantificare quanto siano diverse tra loro le osservazioni. Nel caso dell’esempio sulle ore di studio, abbiamo visto che i valori, pur non essendo tutti identici, non mostrano una dispersione eccessiva (la varianza è 1.25). Se i comportamenti di studio fossero estremamente diversificati (per esempio, se qualcuno studiasse 0 ore al giorno e qualcun altro 10), la varianza sarebbe molto più elevata, indicando una marcata eterogeneità nel campione.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#stima-della-varianza-della-popolazione",
    "href": "chapters/eda/07_loc_scale.html#stima-della-varianza-della-popolazione",
    "title": "19  Indicatori di tendenza centrale e variabilità",
    "section": "\n19.13 Stima della Varianza della Popolazione",
    "text": "19.13 Stima della Varianza della Popolazione\nSi noti il denominatore della formula della varianza. Nell’Equazione 19.3, ho utilizzato \\(n\\) come denominatore (l’ampiezza campionaria, ovvero il numero di osservazioni nel campione). In questo modo, otteniamo la varianza come statistica descrittiva del campione. Tuttavia, è possibile utilizzare \\(n-1\\) come denominatore alternativo:\n\\[\ns^2 = \\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\bar{x})^2 .\n\\tag{19.4}\\]\nIn questo secondo caso, otteniamo la varianza come stimatore della varianza della popolazione. Si può dimostrare che l’Equazione 19.4 fornisce una stima corretta (ovvero, non distorta) della varianza della popolazione da cui abbiamo ottenuto il campione, mentre l’Equazione 19.3 fornisce (in media) una stima troppo piccola della varianza della popolazione. Si presti attenzione alla notazione: \\(S^2\\) rappresenta la varianza come statistica descrittiva, mentre \\(s^2\\) rappresenta la varianza come stimatore.\n\n19.13.1 Simulazione\nPer illustrare questo punto, svolgiamo una simulazione. Consideriamo la distribuzione dei punteggi del quoziente di intelligenza (QI). I valori del QI seguono una particolare distribuzione chiamata distribuzione normale (v. Capitolo 20), con media 100 e deviazione standard 15. La forma di questa distribuzione è illustrata nella figura seguente.\n\n# Define parameters\nx &lt;- seq(100 - 4 * 15, 100 + 4 * 15, by = 0.001)\nmu &lt;- 100\nsigma &lt;- 15\n\n# Compute the PDF\npdf &lt;- dnorm(x, mean = mu, sd = sigma)\n\n# Plot using ggplot2\ndata &lt;- tibble(x = x, pdf = pdf)\nggplot(data, aes(x = x, y = pdf)) +\n  geom_line() +\n  labs(\n    x = \"QI\", \n    y = \"Densità\", \n    title = \"Distribuzione del QI nella popolazione\"\n  ) \n\n\n\n\n\n\n\nSupponiamo di estrarre un campione casuale di 4 osservazioni dalla popolazione del quoziente di intelligenza – in altre parole, supponiamo di misurare il quoziente di intelligenza di 4 persone prese a caso dalla popolazione.\n\nset.seed(123) \nx &lt;- rnorm(4, mean = 100, sd = 15)\nprint(x)\n#&gt; [1]  91.59  96.55 123.38 101.06\n\nCalcoliamo la varianza usando \\(n\\) al denominatore. Si noti che la vera varianza del quoziente di intelligenza è \\(15^2\\) = 225.\n\nvar(x)\n#&gt; [1] 196.9\n\nConsideriamo ora 10 campioni casuali del QI, ciascuno di ampiezza 4.\n\nmu &lt;- 100\nsigma &lt;- 15\nsize &lt;- 4\nniter &lt;- 10\nrandom_samples &lt;- list()\n\nset.seed(123) \n\nfor (i in 1:niter) {\n  one_sample &lt;- rnorm(size, mean = mu, sd = sigma)\n  random_samples[[i]] &lt;- one_sample\n}\n\nIl primo campione è\n\nrandom_samples[1]\n#&gt; [[1]]\n#&gt; [1]  91.59  96.55 123.38 101.06\n\nIl decimo campione è\n\nrandom_samples[10]\n#&gt; [[1]]\n#&gt; [1] 108.31  99.07  95.41  94.29\n\nStampiamo i valori di tutti i 10 campioni.\n\nrs &lt;- do.call(rbind, random_samples)\nrs\n#&gt;         [,1]   [,2]   [,3]   [,4]\n#&gt;  [1,]  91.59  96.55 123.38 101.06\n#&gt;  [2,] 101.94 125.73 106.91  81.02\n#&gt;  [3,]  89.70  93.32 118.36 105.40\n#&gt;  [4,] 106.01 101.66  91.66 126.80\n#&gt;  [5,] 107.47  70.50 110.52  92.91\n#&gt;  [6,]  83.98  96.73  84.61  89.07\n#&gt;  [7,]  90.62  74.70 112.57 102.30\n#&gt;  [8,]  82.93 118.81 106.40  95.57\n#&gt;  [9,] 113.43 113.17 112.32 110.33\n#&gt; [10,] 108.31  99.07  95.41  94.29\n\nPer ciascun campione (ovvero, per ciascuna riga della matrice precedente), calcoliamo la varianza usando la formula con \\(n\\) al denominatore. Otteniamo così 10 stime della varianza della popolazione del QI.\n\nx_var &lt;- apply(rs, 1, var)  # Applica la funzione var su ciascuna riga\nprint(x_var)\n#&gt;  [1] 196.940 337.536 168.547 218.684 333.476  34.520 264.378 234.081   1.971\n#&gt; [10]  40.468\n\nNotiamo due cose:\n\nle stime sono molto diverse tra loro; questo fenomeno è noto con il nome di variabilità campionaria;\nin media le stime sono troppo piccole.\n\nPer aumentare la sicurezza riguardo al secondo punto menzionato in precedenza, ripeteremo la simulazione utilizzando un numero di iterazioni maggiore.\n\nmu &lt;- 100\nsigma &lt;- 15\nsize &lt;- 4\nniter &lt;- 10000\nrandom_samples &lt;- list()\n\nset.seed(123) # Replace 123 with your desired seed for reproducibility\n\nfor (i in 1:niter) {\n  one_sample &lt;- rnorm(size, mean = mu, sd = sigma)\n  random_samples[[i]] &lt;- one_sample\n}\n\nrs &lt;- do.call(rbind, random_samples)\nx_var &lt;- apply(rs, 1, var) * (size - 1) / size  # Adjust for population variance (ddof = 0)\n\nEsaminiamo la distribuzione dei valori ottenuti.\n\n# Create a data frame for plotting\ndata &lt;- data.frame(x_var = x_var)\n\n# Plot the histogram using ggplot2\nggplot(data, aes(x = x_var)) +\n  geom_histogram(fill = \"lightblue\", bins = 30, color = \"black\") +\n  scale_x_continuous(limits = c(0, 1500)) +\n  scale_y_continuous(limits = c(0, 2250)) +\n  labs(\n    x = \"Varianza\", \n    y = \"Frequenza\", \n    title = \"Varianza del QI in campioni di n = 4\"\n  )\n\n\n\n\n\n\n\nLa stima più verosimile della varianza del QI è dato dalla media di questa distribuzione.\n\nmean(x_var)\n#&gt; [1] 168.9\n\nSi noti che il nostro spospetto è stato confermato: il valore medio della stima della varianza ottenuta con l’Equazione 19.3 è troppo piccolo rispetto al valore corretto di \\(15^2 = 225\\).\nRipetiamo ora la simulazione usando la formula della varianza con \\(n-1\\) al denominatore.\n\nset.seed(123) \n\nmu &lt;- 100\nsigma &lt;- 15\nsize &lt;- 4\nniter &lt;- 10000\nrandom_samples &lt;- list()\n\nfor (i in 1:niter) {\n  one_sample &lt;- rnorm(size, mean = mu, sd = sigma)\n  random_samples[[i]] &lt;- one_sample\n}\n\nrs &lt;- do.call(rbind, random_samples)\nx_var &lt;- apply(rs, 1, var)  # ddof = 1 is default for var in R\n\nEsaminiamo la distribuzione dei valori ottenuti.\n\n# Create a data frame for plotting\ndata &lt;- data.frame(x_var = x_var)\n\n# Plot the histogram using ggplot2\nggplot(data, aes(x = x_var)) +\n  geom_histogram(fill = \"lightblue\", bins = 30, color = \"black\") +\n  scale_x_continuous(limits = c(0, 1500)) +\n  scale_y_continuous(limits = c(0, 2250)) +\n  labs(\n    x = \"Varianza Corretta\", \n    y = \"Frequenza\", \n    title = \"Varianza corretta del QI in campioni di n = 4\"\n  )\n\n\n\n\n\n\n\nNel secondo caso, se utilizziamo \\(n-1\\) come denominatore per calcolare la stima della varianza, il valore atteso di questa stima è molto vicino al valore corretto di 225. Se il numero di campioni fosse infinito, i due valori sarebbero identici.\n\nmean(x_var)\n#&gt; [1] 225.2\n\nIn conclusione, le due formule della varianza hanno scopi diversi.\n\nLa formula della varianza con \\(n\\) al denominatore viene utilizzata come statistica descrittiva per descrivere la variabilità di un particolare campione di osservazioni.\nD’altro canto, la formula della varianza con \\(n-1\\) al denominatore viene utilizzata come stimatore per ottenere la migliore stima della varianza della popolazione da cui quel campione è stato estratto.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#deviazione-standard",
    "href": "chapters/eda/07_loc_scale.html#deviazione-standard",
    "title": "19  Indicatori di tendenza centrale e variabilità",
    "section": "\n19.14 Deviazione Standard",
    "text": "19.14 Deviazione Standard\nPer interpretare la varianza in modo più intuitivo, si può calcolare la deviazione standard (o scarto quadratico medio o scarto tipo) prendendo la radice quadrata della varianza. La deviazione standard è espressa nell’unità di misura originaria dei dati, a differenza della varianza che è espressa nel quadrato dell’unità di misura dei dati. La deviazione standard fornisce una misura della dispersione dei dati attorno alla media, rendendo più facile la comprensione della variabilità dei dati.\nLa deviazione standard (o scarto quadratico medio, o scarto tipo) è definita come:\n\\[\ns^2 = \\sqrt{(n-1)^{-1} \\sum_{i=1}^n (x_i - \\bar{x})^2}.\n\\tag{19.5}\\]\nQuando tutte le osservazioni sono uguali, \\(s = 0\\), altrimenti \\(s &gt; 0\\).\n\n\n\n\n\n\nIl termine standard deviation è stato introdotto in statistica da Pearson nel 1894 assieme alla lettera greca \\(\\sigma\\) che lo rappresenta. Il termine italiano “deviazione standard” ne è la traduzione più utilizzata nel linguaggio comune; il termine dell’Ente Nazionale Italiano di Unificazione è tuttavia “scarto tipo”, definito come la radice quadrata positiva della varianza.\n\n\n\nLa deviazione standard \\(s\\) dovrebbe essere utilizzata solo quando la media è una misura appropriata per descrivere il centro della distribuzione, ad esempio nel caso di distribuzioni simmetriche. Tuttavia, è importante tener conto che, come la media \\(\\bar{x}\\), anche la deviazione standard è fortemente influenzata dalla presenza di dati anomali, ovvero pochi valori che si discostano notevolmente dalla media rispetto agli altri dati della distribuzione. In presenza di dati anomali, la deviazione standard può risultare ingannevole e non rappresentare accuratamente la variabilità complessiva della distribuzione. Pertanto, è fondamentale considerare attentamente il contesto e le caratteristiche dei dati prima di utilizzare la deviazione standard come misura di dispersione. In alcune situazioni, potrebbe essere più appropriato ricorrere a misure di dispersione robuste o ad altre statistiche descrittive per caratterizzare la variabilità dei dati in modo più accurato e affidabile.\n\n19.14.1 Interpretazione\nLa deviazione standard misura la dispersione dei dati rispetto alla media aritmetica. In termini semplici, indica quanto, in media, ciascun valore osservato si discosta dalla media del campione. Anche se è simile allo scarto semplice medio campionario (la media dei valori assoluti degli scarti rispetto alla media), la deviazione standard utilizza lo scarto quadratico medio e produce un valore leggermente diverso.\n\nEsempio 19.3 Per verificare l’interpretazione della deviazione standard, utilizziamo i punteggi relativi alle ore di studio di un piccolo numero di studenti.\n\nx &lt;- c(3, 1, 4, 2)\n\nstd_x &lt;- sqrt(var(x) * 3 / 4)\nstd_x\n#&gt; [1] 1.118\n\nLa deviazione standard calcolata è 1.12. Questo valore ci dice che, in media, ciascun punteggio si discosta di circa 1.12 ore dalla media aritmetica delle ore di studio di questo gruppo di studenti.\n\nValore più alto: indica maggiore dispersione dei dati intorno alla media.\nValore più basso: i dati sono più concentrati vicino alla media.\n\nSe calcoliamo anche lo scarto semplice medio campionario per confronto, otteniamo:\n\nmean(abs(x - mean(x)))\n#&gt; [1] 1\n\nI due valori (deviazione standard e scarto semplice medio) sono simili ma non identici, a causa delle diverse definizioni matematiche.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#varianza-spiegata-e-non-spiegata",
    "href": "chapters/eda/07_loc_scale.html#varianza-spiegata-e-non-spiegata",
    "title": "19  Indicatori di tendenza centrale e variabilità",
    "section": "\n19.15 Varianza Spiegata e Non Spiegata",
    "text": "19.15 Varianza Spiegata e Non Spiegata\nLa varianza, come abbiamo visto, misura quanto i dati si disperdono attorno alla media. Un concetto fondamentale nei modelli statistici lineari è la distinzione tra varianza spiegata e varianza non spiegata, che ci permette di valutare quanto bene un modello teorico riesca a chiarire la variabilità osservata nei dati.\n\n19.15.1 Decomposizione della Varianza\nQuando osserviamo un fenomeno (ad esempio i risultati di un test), troviamo inevitabilmente differenze tra individui. Queste differenze possono essere suddivise in due componenti principali:\n\n\nvarianza spiegata: la parte di variabilità che può essere attribuita a fattori identificati e misurabili;\n\nvarianza non spiegata: la parte rimanente di variabilità che non è chiarita dai fattori considerati.\n\nFormalmente, questa decomposizione può essere espressa come:\n\\[\n\\sum_{i=1}^{n}(Y_i - \\bar{Y})^2 = \\sum_{i=1}^{n}(\\hat{Y}_i - \\bar{Y})^2 + \\sum_{i=1}^{n}(Y_i - \\hat{Y}_i)^2 ,\n\\]\ndove:\n\n\n\\(Y_i\\) sono i dati osservati,\n\n\\(\\bar{Y}\\) è la media dei dati osservati,\n\n\\(\\hat{Y}_i\\) sono i valori attesi (previsti) dal modello teorico.\n\nIntuitivamente:\n\nla varianza totale (lato sinistro della formula) rappresenta la dispersione complessiva dei dati attorno alla loro media;\nla varianza spiegata (primo termine a destra) indica quanto bene i valori previsti dal modello descrivono il comportamento dei dati;\nla varianza non spiegata (secondo termine a destra) riflette ciò che il modello non riesce a prevedere.\n\n19.15.2 Simulazione in R\nSupponiamo di analizzare i punteggi di un esame universitario di “Psicometria” ottenuti da 200 studenti. La nostra teoria indica che i punteggi dipendano da:\n\nOre settimanali dedicate allo studio;\nPresenza o assenza di “paura della matematica” (math anxiety) (Barroso et al., 2021).\n\nNello specifico, ipotizziamo:\n\nuna relazione positiva tra ore di studio e punteggio ottenuto;\nuna riduzione del 30% del punteggio per chi presenta paura della matematica rispetto agli altri studenti, a parità di ore di studio.\n\nEcco la simulazione in R:\n\nset.seed(123)\n\n# Simuliamo i dati per 200 studenti\nn &lt;- 200\nore_studio &lt;- runif(n, min = 2, max = 15) |&gt; round()\npaura_mat &lt;- rbinom(n, 1, prob = 0.3)\n\nk &lt;- 2  # Ogni ora di studio corrisponde a circa 2 punti\n\n# Calcoliamo i punteggi attesi, limitati a 30 punti massimo\npunteggio_atteso &lt;- ore_studio * k * ifelse(paura_mat == 1, 0.7, 1) |&gt; round()\npunteggio_atteso &lt;- ifelse(punteggio_atteso &gt; 30, 30, punteggio_atteso)\n\n# Generiamo punteggi reali aggiungendo casualità (tra 0 e 30 punti)\npunteggio_reale &lt;- (punteggio_atteso + rnorm(n, mean = 0, sd = 3)) |&gt; round()\npunteggio_reale &lt;- pmin(pmax(punteggio_reale, 0), 30)\n\n# Creiamo il dataset finale\ndata &lt;- data.frame(ore_studio, paura_mat, punteggio_atteso, punteggio_reale)\nhead(data)\n#&gt;   ore_studio paura_mat punteggio_atteso punteggio_reale\n#&gt; 1          6         0               12              19\n#&gt; 2         12         1               24              28\n#&gt; 3          7         0               14              13\n#&gt; 4         13         0               26              28\n#&gt; 5         14         0               28              27\n#&gt; 6          3         1                6               5\n\nCalcoliamo ora la decomposizione della varianza usando le formule indicate:\n\n# Media dei punteggi reali\nmedia_reale &lt;- mean(data$punteggio_reale)\n\n# Calcolo delle componenti della varianza\nvarianza_totale &lt;- mean((data$punteggio_reale - media_reale)^2)\nvarianza_spiegata &lt;- mean((data$punteggio_atteso - media_reale)^2)\nvarianza_non_spiegata &lt;- mean((data$punteggio_reale - data$punteggio_atteso)^2)\n\n# Risultati\nc(varianza_totale, varianza_spiegata, varianza_non_spiegata)\n#&gt; [1] 60.37 51.65  8.29\n\n\n19.15.3 Interpretazione dei Risultati\n\n\nVarianza totale indica quanto in generale i punteggi differiscono tra loro.\n\nVarianza spiegata rappresenta quanto della variabilità totale può essere attribuita ai fattori teorici (ore di studio e paura della matematica).\n\nVarianza non spiegata evidenzia la variabilità residua che il modello non riesce a cogliere.\n\nLa proporzione di varianza spiegata è data dal rapporto:\n\nprop_spiegata &lt;- varianza_spiegata / varianza_totale\nprop_spiegata\n#&gt; [1] 0.8555\n\nQuesta proporzione è sempre compresa tra 0 e 1:\n\nvalori vicini a 1 indicano che il modello è efficace nel descrivere i dati;\nvalori vicini a 0 suggeriscono che il modello non cattura adeguatamente la realtà osservata.\n\nQuesta decomposizione della varianza è uno strumento cruciale per valutare l’efficacia delle teorie e dei modelli statistici. Approfondiremo ulteriormente questi aspetti nel capitolo dedicato ai modelli di regressione (v. Capitolo 60).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#deviazione-mediana-assoluta",
    "href": "chapters/eda/07_loc_scale.html#deviazione-mediana-assoluta",
    "title": "19  Indicatori di tendenza centrale e variabilità",
    "section": "\n19.16 Deviazione Mediana Assoluta",
    "text": "19.16 Deviazione Mediana Assoluta\nLa deviazione mediana assoluta (MAD) è una misura robusta di dispersione basata sulla mediana. È definita come la mediana dei valori assoluti delle deviazioni dei dati rispetto alla mediana:\n\\[\n\\text{MAD} = \\text{median} \\left( |X_i - \\text{median}(X)| \\right)\n\\tag{19.6}\\]\nLa MAD è particolarmente utile per analizzare dati contenenti outlier o distribuzioni asimmetriche, poiché è meno influenzata dai valori estremi rispetto alla deviazione standard.\n\n19.16.1 Relazione tra MAD e Deviazione Standard in una Distribuzione Normale\nQuando i dati seguono una distribuzione normale (gaussiana), esiste una relazione approssimativa tra MAD e deviazione standard. La MAD può essere convertita in una stima della deviazione standard moltiplicandola per una costante di 1.4826:\n\\[\n\\sigma \\approx k \\times \\text{MAD},\n\\]\ndove:\n\n\n\\(\\sigma\\) è la deviazione standard,\nMAD è la Mediana della Deviazione Assoluta,\n\n\\(k\\) è una costante che, per una distribuzione normale, è tipicamente presa come circa 1.4826.\n\nQuesta costante deriva dalla proprietà della distribuzione normale, in cui circa il 50% dei valori si trova entro 0.6745 deviazioni standard dalla media.\nLa formula completa per convertire la MAD in una stima della deviazione standard in una distribuzione normale è:\n\\[\n\\sigma \\approx 1.4826 \\times \\text{MAD}\n\\]\nQuesta relazione è utile per stimare la deviazione standard in modo più robusto, specialmente quando si sospetta la presenza di outlier o si ha a che fare con campioni piccoli. Di conseguenza, molti software restituiscono il valore MAD moltiplicato per questa costante per fornire un’indicazione più intuitiva della variabilità dei dati. Tuttavia, è importante notare che questa relazione si mantiene accurata solo per le distribuzioni che sono effettivamente normali. In presenza di distribuzioni fortemente asimmetriche o con elevati outlier, la deviazione standard e la MAD possono fornire indicazioni molto diverse sulla variabilità dei dati.\n\nEsempio 19.4 Per verificare questo principio, usiamo un campione di dati simulati dalla distribuzione del QI:\n\nqi &lt;- rnorm(200, 100, 15)\n1.4826 * median(abs(qi - median(qi)), na.rm = TRUE)\n#&gt; [1] 14.06\n\nOtteniamo un valore che è simile alla deviazione standard calcolata con:\n\nsqrt(\n  var(qi) * (length(qi) - 1) / length(qi)\n)\n#&gt; [1] 14.44\n\nCiò conferma la relazione tra MAD e deviazione standard in distribuzioni gaussiane.\nSe invece usiamo dei dati non normali, l’approssimazione non è buona:\n\nset.seed(123) \ny &lt;- rchisq(200, 1)\n1.4826 * median(abs(y - median(y)))\n#&gt; [1] 0.4743\n\n\nsqrt(\n  var(y) * (length(y) - 1) / length(y)\n)\n#&gt; [1] 1.412\n\n\n\n19.16.2 Quando Usare Deviazione Standard e MAD\n\nDeviazione standard: È la misura più appropriata per dati normalmente distribuiti e situazioni in cui l’obiettivo è descrivere la dispersione dei dati rispetto alla media. Tuttavia, è sensibile ai valori anomali (outlier).\nDeviazione mediana assoluta: È ideale quando i dati sono non normali, asimmetrici o contengono outlier. La MAD è più robusta poiché utilizza la mediana anziché la media e non è influenzata da valori estremi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#indici-di-variabilità-relativi",
    "href": "chapters/eda/07_loc_scale.html#indici-di-variabilità-relativi",
    "title": "19  Indicatori di tendenza centrale e variabilità",
    "section": "\n19.17 Indici di Variabilità Relativi",
    "text": "19.17 Indici di Variabilità Relativi\nA volte può essere necessario confrontare la variabilità di grandezze incommensurabili, ovvero di caratteri misurati con differenti unità di misura. In queste situazioni, le misure di variabilità descritte in precedenza diventano inadeguate poiché dipendono dall’unità di misura utilizzata. Per superare questo problema, si ricorre a specifici numeri adimensionali chiamati indici relativi di variabilità.\nIl più importante di questi indici è il coefficiente di variazione (\\(C_v\\)), definito come il rapporto tra la deviazione standard (\\(\\sigma\\)) e la media dei dati (\\(\\bar{x}\\)):\n\\[\nC_v = \\frac{\\sigma}{\\bar{x}}.\n\\tag{19.7}\\]\nIl coefficiente di variazione è un numero puro e permette di confrontare la variabilità di distribuzioni con unità di misura diverse.\nUn altro indice relativo di variabilità è la differenza interquartile rapportata a uno dei tre quartili (primo quartile, terzo quartile o mediana). Questo indice è definito come:\n\\[\n\\frac{x_{0.75} - x_{0.25}}{x_{0.25}}, \\qquad \\frac{x_{0.75} - x_{0.25}}{x_{0.75}}, \\qquad \\frac{x_{0.75} - x_{0.25}}{x_{0.50}}.\n\\]\nQuesti indici relativi di variabilità forniscono una misura adimensionale della dispersione dei dati, rendendo possibile il confronto tra grandezze con diverse unità di misura e facilitando l’analisi delle differenze di variabilità tra i dati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#riflessioni-conclusive",
    "href": "chapters/eda/07_loc_scale.html#riflessioni-conclusive",
    "title": "19  Indicatori di tendenza centrale e variabilità",
    "section": "\n19.18 Riflessioni Conclusive",
    "text": "19.18 Riflessioni Conclusive\nLe statistiche descrittive forniscono strumenti essenziali per sintetizzare e comprendere i dati raccolti in psicologia e nelle scienze sociali. Le misure di tendenza centrale, come la media, la mediana e la moda, ci permettono di individuare un valore tipico o rappresentativo di una distribuzione, facilitando la sintesi e l’interpretazione generale dei dati raccolti. Parallelamente, gli indici di dispersione, come la deviazione standard, la varianza e l’intervallo interquartile, offrono informazioni cruciali sulla variabilità, mostrandoci quanto i singoli dati siano vicini o distanti da questa tendenza centrale.\nTuttavia, è fondamentale riflettere attentamente sulle implicazioni teoriche e metodologiche che accompagnano l’uso di queste misure. In particolare, è importante considerare il rischio della fallacia ergodica, ovvero l’errata convinzione che i risultati ottenuti da medie e statistiche aggregate possano automaticamente applicarsi ai singoli individui. Nella pratica psicologica, infatti, ogni persona è caratterizzata da una notevole variabilità intra- e inter-individuale, che spesso non può essere adeguatamente rappresentata da semplici indicatori aggregati.\nLe statistiche descrittive rappresentano quindi un primo e fondamentale passo nella comprensione dei dati psicologici, ma devono essere integrate da analisi più approfondite e attente alle differenze individuali. L’uso critico e consapevole di questi strumenti statistici ci consente di evitare generalizzazioni eccessive, fornendo una visione più accurata e realistica dei fenomeni psicologici e comportamentali che studiamo.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#esercizi",
    "href": "chapters/eda/07_loc_scale.html#esercizi",
    "title": "19  Indicatori di tendenza centrale e variabilità",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nParte 1: Domande Teoriche\n\n\nDefinizione e comprensione dei concetti\n\nSpiega la differenza tra media, mediana e moda.\nIn quali situazioni la mediana fornisce una misura della tendenza centrale migliore rispetto alla media?\nPerché la media è sensibile ai valori estremi?\nQuali sono i vantaggi della deviazione mediana assoluta (MAD) rispetto alla deviazione standard?\n\n\n\nInterpretazione della variabilità\n\nSpiega il concetto di varianza e la sua interpretazione.\nQual è la differenza tra varianza e deviazione standard?\nDescrivi in quali casi l’utilizzo del coefficiente di variazione è più appropriato rispetto alla deviazione standard.\nQuali sono i limiti della moda come indice di tendenza centrale?\n\n\n\nParte 2: Calcoli Manuali\n\n\nCalcolo della media, mediana e moda\n\n\nConsidera i seguenti punteggi totali della SWLS che sono stati raccolti in un campione di studenti. Calcola manualmente:\n\nLa media\nLa mediana\nLa moda\nIl range\n\n\n\n\n\nCalcolo della varianza e della deviazione standard\n\nUsando gli stessi dati dell’esercizio precedente, calcola:\n\nLa varianza\nLa deviazione standard\nLa deviazione mediana assoluta (MAD)\n\n\n\n\n\nParte 3: Esercizi con R\n\n\nAnalisi descrittiva con R\n\nCarica il dataset swls_scores.csv contenente i punteggi SWLS degli studenti.\nCalcola media, mediana e moda utilizzando R.\nCalcola la varianza e la deviazione standard utilizzando le funzioni appropriate in R.\n\nCodice suggerito:\nlibrary(tidyverse)\nlibrary(rio)\n\n# Caricamento del dataset\ndf &lt;- import(\"swls_scores.csv\")\n\n# Calcolo delle statistiche descrittive\nmean(df$swls_total)\nmedian(df$swls_total)\n\n# Moda (funzione personalizzata)\nget_mode &lt;- function(x) {\n  tbl &lt;- table(x)\n  as.numeric(names(tbl)[which.max(tbl)])\n}\nget_mode(df$swls_total)\n\n# Varianza e deviazione standard\nvar(df$swls_total)\nsd(df$swls_total)\n\n# Deviazione mediana assoluta\nmad(df$swls_total)\n\n\nVisualizzazione della distribuzione dei dati\n\nCrea un istogramma dei punteggi totali della SWLS.\nAggiungi una linea verticale che rappresenti la media e una che rappresenti la mediana.\n\nCodice suggerito:\nggplot(df, aes(x = swls_total)) +\n  geom_histogram(binwidth = 2, fill = \"blue\", alpha = 0.5, color = \"black\") +\n  geom_vline(aes(xintercept = mean(swls_total)), color = \"red\", linetype = \"dashed\", size = 1) +\n  geom_vline(aes(xintercept = median(swls_total)), color = \"green\", linetype = \"dotted\", size = 1) +\n  labs(title = \"Distribuzione dei punteggi SWLS\", x = \"Punteggio SWLS\", y = \"Frequenza\")\n\n\nParte 4: Domande di Comprensione\n\n\nAnalisi concettuale\n\nPerché la media aritmetica può essere considerata il “baricentro” della distribuzione dei dati?\nSe aggiungiamo un valore estremo al dataset, quale delle misure di tendenza centrale subirà il maggior impatto?\nIn quali situazioni la varianza campionaria è preferibile rispetto alla varianza della popolazione?\nQual è la relazione tra la deviazione standard e la varianza?\nFornisci un’interpretazione intuitiva della deviazione standard.\nDiscuti le differenze e le somiglianze tra la deviazione standard e MAD. Usa queste informazioni per ridescrivere in maniera intuitiva il significato di deviazione standard.\n\n\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\nPoniamo che i valori SWLS siano [ 18, 22, 26, 19, 24, 30, 26, 22, 18, 28, 21 ].\n\nMedia: \\[ \\bar{x} = \\frac{18 + 22 + 26 + 19 + 24 + 30 + 26 + 22 + 18 + 28 + 21}{11} = 23.36 \\]\nMediana: Ordinando i dati: [ 18, 18, 19, 21, 22, 22, 24, 26, 26, 28, 30 ] La mediana è il valore centrale: \\(22\\)\nModa: Il valore più frequente è 22 (appare due volte).\nVarianza: \\[ s^2 = \\frac{\\sum (x_i - \\bar{x})^2}{n-1} = 13.96 \\]\nDeviazione Standard: \\[ s = \\sqrt{13.96} = 3.73 \\]\nMAD: \\[ \\text{MAD} = \\text{mediana}(|X_i - \\text{mediana}(X)|) = 4 \\]\n\nSoluzioni con R\nI risultati eseguendo il codice R:\n\n\nMedia: 23.36\n\nMediana: 22\n\nModa: 22\n\nVarianza: 13.96\n\nDeviazione standard: 3.73\n\nMAD: 4\n\nSoluzioni alle Domande di Comprensione\n\nLa media è il baricentro poiché minimizza la somma degli scarti quadrati.\nLa media è più influenzata dai valori estremi rispetto alla mediana.\nLa varianza campionaria corregge la sottostima della varianza popolazionale.\nLa deviazione standard è la radice quadrata della varianza, consentendo un’interpretazione del risultato sulla scala dei dati grezzi.\nLa deviazione standard è simile, ma non identica, al valore medio degli scarti assoluti tra ciascun valore della distribuzione e la media. In altre parole, rappresenta la “distanza tipica” media tra le osservazioni e il valore medio della distribuzione.\nLa deviazione standard e il MAD (Median Absolute Deviation, o scarto medio assoluto) sono entrambi misure di variabilità che descrivono quanto i valori in un insieme di dati si discostino dal centro della distribuzione. Tuttavia, presentano alcune importanti differenze e somiglianze.\n\nSomiglianze\n\nEntrambe le misure quantificano la dispersione dei dati attorno a un punto centrale.\nSia la deviazione standard che il MAD utilizzano lo scarto (la differenza tra ciascun valore e un punto centrale) per calcolare la variabilità.\n\nDifferenze\n\n\nPunto centrale usato: La deviazione standard si basa sulla media aritmetica, mentre il MAD si basa sulla mediana.\n\nTrattamento degli scarti: Nella deviazione standard, gli scarti vengono elevati al quadrato prima di essere mediati, quindi la radice quadrata viene applicata al risultato finale. Questo processo penalizza maggiormente gli scarti più grandi, rendendo la deviazione standard più sensibile agli outlier. Il MAD, invece, considera semplicemente il valore assoluto degli scarti, rendendolo meno influenzato dagli estremi.\n\nSensibilità agli outlier: Poiché la deviazione standard dipende dai quadrati degli scarti, è più sensibile alle osservazioni estreme (outlier). Il MAD, essendo basato sulla mediana, è una misura più robusta e resiste meglio alla presenza di valori anomali.\n\nRidescrizione Intuitiva della Deviazione Standard\n\nLa deviazione standard può essere vista come una misura della “dispersione tipica” dei dati attorno alla media, ma con un’enfasi particolare sugli scarti più grandi. Immagina di prendere ogni valore del dataset, calcolarne la distanza dalla media, amplificare queste distanze attraverso il quadrato, poi trovare una sorta di “distanza media” ponderata. Questo processo dà maggiore peso agli scarti più grandi, fornendo così una visione della variabilità che tiene conto sia delle fluttuazioni ordinarie sia di eventuali valori estremi. In sintesi, mentre il MAD offre una visione più resistente e diretta della variabilità centrata sulla mediana, la deviazione standard fornisce una misura più dettagliata e sensibile alla forma complessiva della distribuzione, inclusi i suoi possibili outliers.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/07_loc_scale.html#informazioni-sullambiente-di-sviluppo",
    "title": "19  Indicatori di tendenza centrale e variabilità",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] grid      stats     graphics  grDevices utils     datasets  methods  \n#&gt; [8] base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] vcd_1.4-13        viridis_0.6.5     viridisLite_0.4.2 thematic_0.1.7   \n#&gt;  [5] MetBrewer_0.2.0   ggokabeito_0.1.0  see_0.11.0        gridExtra_2.3    \n#&gt;  [9] patchwork_1.3.0   bayesplot_1.13.0  psych_2.5.3       scales_1.4.0     \n#&gt; [13] markdown_2.0      knitr_1.50        lubridate_1.9.4   forcats_1.0.0    \n#&gt; [17] stringr_1.5.1     dplyr_1.1.4       purrr_1.0.4       readr_2.1.5      \n#&gt; [21] tidyr_1.3.1       tibble_3.3.0      ggplot2_3.5.2     tidyverse_2.0.0  \n#&gt; [25] rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6       xfun_0.52          htmlwidgets_1.6.4 \n#&gt;  [4] lattice_0.22-7     tzdb_0.5.0         vctrs_0.6.5       \n#&gt;  [7] tools_4.5.0        generics_0.1.4     parallel_4.5.0    \n#&gt; [10] pacman_0.5.1       pkgconfig_2.0.3    R.oo_1.27.1       \n#&gt; [13] data.table_1.17.6  RColorBrewer_1.1-3 lifecycle_1.0.4   \n#&gt; [16] compiler_4.5.0     farver_2.1.2       mnormt_2.1.1      \n#&gt; [19] htmltools_0.5.8.1  pillar_1.10.2      MASS_7.3-65       \n#&gt; [22] R.utils_2.13.0     nlme_3.1-168       tidyselect_1.2.1  \n#&gt; [25] digest_0.6.37      stringi_1.8.7      labeling_0.4.3    \n#&gt; [28] rprojroot_2.0.4    fastmap_1.2.0      colorspace_2.1-1  \n#&gt; [31] cli_3.6.5          magrittr_2.0.3     utf8_1.2.6        \n#&gt; [34] withr_3.0.2        timechange_0.3.0   rmarkdown_2.29    \n#&gt; [37] zoo_1.8-14         R.methodsS3_1.8.2  hms_1.1.3         \n#&gt; [40] evaluate_1.0.4     lmtest_0.9-40      rlang_1.1.6       \n#&gt; [43] glue_1.8.0         rstudioapi_0.17.1  jsonlite_2.0.0    \n#&gt; [46] R6_2.6.1",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#bibliografia",
    "href": "chapters/eda/07_loc_scale.html#bibliografia",
    "title": "19  Indicatori di tendenza centrale e variabilità",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBarroso, C., Ganley, C. M., McGraw, A. L., Geer, E. A., Hart, S. A., & Daucourt, M. C. (2021). A meta-analysis of the relation between math anxiety and math achievement. Psychological Bulletin, 147(2), 134–168.\n\n\nMolden, D. C., & Dweck, C. S. (2006). Finding\" meaning\" in psychology: a lay theories approach to self-regulation, social perception, and social development. American Psychologist, 61(3), 192–203.\n\n\nSpeelman, C. P., & McGann, M. (2013). How mean is the mean? Frontiers in Psychology, 4, 451.\n\n\nSpeelman, C. P., Parker, L., Rapley, B. J., & McGann, M. (2024). Most Psychological Researchers Assume Their Samples Are Ergodic: Evidence From a Year of Articles in Three Major Journals. Collabra: Psychology, 10(1).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07a_introduction_normal_distribution.html",
    "href": "chapters/eda/07a_introduction_normal_distribution.html",
    "title": "20  Introduzione alla distribuzione normale",
    "section": "",
    "text": "Introduzione",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Introduzione alla distribuzione normale</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07a_introduction_normal_distribution.html#introduzione",
    "href": "chapters/eda/07a_introduction_normal_distribution.html#introduzione",
    "title": "20  Introduzione alla distribuzione normale",
    "section": "",
    "text": "In questo capitolo forniremo un primo sguardo alla distribuzione normale, che sarà trattata in modo più approfondito nel Capitolo 40. Introduciamo la distribuzione normale a questo punto poiché essa spiega in modo chiaro perché, in molte analisi, media e deviazione standard siano impiegate come principali descrittori di una distribuzione.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Introduzione alla distribuzione normale</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07a_introduction_normal_distribution.html#sec-normal-distribution",
    "href": "chapters/eda/07a_introduction_normal_distribution.html#sec-normal-distribution",
    "title": "20  Introduzione alla distribuzione normale",
    "section": "\n20.1 La distribuzione normale",
    "text": "20.1 La distribuzione normale\nNel Capitolo 17, abbiamo visto come gli istogrammi e i grafici di densità forniscano utili riassunti visivi di una distribuzione. In questo capitolo, ci chiediamo se sia possibile riassumere una distribuzione in modo ancora più sintetico. Spesso si fa riferimento a media e deviazione standard come statistiche riassuntive fondamentali: in sostanza, un riassunto in due numeri. Per comprendere appieno il ruolo di questi valori, dobbiamo prima capire come è definita la distribuzione normale.\nLa distribuzione normale, nota anche come curva a campana o distribuzione gaussiana, è uno dei concetti matematici più conosciuti (si veda il Capitolo 40). Uno dei motivi della sua fama è che numerose variabili nella realtà seguono, almeno approssimativamente, una distribuzione normale. Esempi includono le vincite nel gioco d’azzardo, l’altezza e il peso delle persone, la pressione sanguigna, i punteggi di alcuni test standardizzati e gli errori di misura negli esperimenti. I motivi matematici e probabilistici di queste approssimazioni verranno discussi in seguito; qui ci concentreremo sul come la distribuzione normale aiuti a riassumere i dati.\nAnziché partire da dati empirici, la distribuzione normale si definisce tramite una formula matematica. Per un intervallo generico \\((a,b)\\), la proporzione di valori che cade in tale intervallo si ottiene mediante:\n\\[\n\\text{Pr}(a &lt; x \\leq b) \\;=\\; \\int_a^b \\frac{1}{\\sqrt{2\\pi}\\,\\sigma} \\, e^{-\\tfrac12\\,\\bigl(\\tfrac{x - \\mu}{\\sigma}\\bigr)^2}\\, dx .\n\\tag{20.1}\\]\nNon è necessario memorizzare o padroneggiare i dettagli di questa formula, ma è importante sapere che la distribuzione normale è completamente determinata da due soli parametri: \\(\\mu\\) e \\(\\sigma\\). Gli altri simboli nella formula (\\(\\pi\\), \\(e\\), \\(a\\), \\(b\\)) rappresentano costanti matematiche o gli estremi dell’intervallo. In particolare, \\(\\mu\\) è il valore medio (o media) e \\(\\sigma\\) è la deviazione standard.\nQuesta distribuzione è simmetrica, centrata sulla media \\(\\mu\\), e la maggior parte dei valori (circa il 95%) si trova entro 2 deviazioni standard dalla media, cioè nell’intervallo \\(\\mu \\pm 2\\sigma\\). Ecco un esempio di come appare la distribuzione normale quando \\(\\mu = 0\\) e \\(\\sigma = 1\\):\n\nm &lt;- 0; s &lt;- 1\nnorm_dist &lt;- tibble(x = seq(-4, 4, length.out = 50)*s + m) |&gt; \n  mutate(density = dnorm(x, m, s))\nnorm_dist |&gt; \n  ggplot(aes(x, density)) + geom_line()\n\n\n\n\n\n\n\nIl fatto che la distribuzione sia descritta da due parametri implica che, se un insieme di dati reali si approssima bene a una distribuzione normale, due soli numeri (media e deviazione standard) possono fornire un riassunto sintetico della distribuzione. Vediamo ora come si calcolano, in pratica, questi due parametri per una lista di valori arbitraria.\nSupponiamo di avere un vettore x che contiene una serie di valori numerici. Abbiamo visto come, in R, la media si trova come:\nm &lt;- sum(x) / length(x)\ne la deviazione standard è:\ns &lt;- sqrt(sum((x - m)^2) / length(x))\nLa deviazione standard si può interpretare come la distanza media dei valori dalla loro media.\n\n20.1.1 Un esempio con i dati di altezza\nPer calcolare media e deviazione standard dell’altezza maschile in un dataset, ipotizziamo che il vettore heights$height contenga le altezze di alcuni individui, mentre heights$sex contenga il genere corrispondente. Se vogliamo estrarre solo i valori relativi ai maschi, possiamo scrivere:\n\nindex &lt;- heights$sex == \"Male\"\nx &lt;- heights$height[index]\n\nQuindi usiamo le funzioni predefinite di R:\n\nm &lt;- mean(x)\ns &lt;- sd(x)\n\n\n\n\n\n\n\nNota: Per motivi che verranno chiariti in seguito, la funzione sd(x) effettua una divisione per \\(\\text{length}(x) - 1\\) invece che per \\(\\text{length}(x)\\). Tuttavia, se il numero di osservazioni è elevato, questa differenza è trascurabile.\n\n\n\nPossiamo ora mettere a confronto la curva di densità osservata dei dati (in blu) con quella teorica (in nero) della distribuzione normale con media e deviazione standard stimate:\n\nnorm_dist &lt;- tibble(\n  x = seq(-4, 4, length.out = 50)*s + m) |&gt; \n  mutate(density = dnorm(x, m, s))\n\nheights |&gt; \n  dplyr::filter(sex == \"Male\") |&gt; \n  ggplot(aes(height)) +\n  geom_density(fill = \"lightblue\") +\n  geom_line(aes(x, density), linewidth=1.5, data = norm_dist)\n\n\n\n\n\n\n\nCome si vede, la curva normale fornisce una buona approssimazione per i dati sull’altezza maschile. Vedremo ora come verificare l’aderenza di una distribuzione ai dati, osservando le proporzioni di valori entro intervalli specifici.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Introduzione alla distribuzione normale</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07a_introduction_normal_distribution.html#unità-standard",
    "href": "chapters/eda/07a_introduction_normal_distribution.html#unità-standard",
    "title": "20  Introduzione alla distribuzione normale",
    "section": "\n20.2 Unità standard",
    "text": "20.2 Unità standard\nPer i dati che seguono (o quasi) una distribuzione normale, è molto comodo utilizzare le cosiddette unità standard (Standard Units). Un valore \\(x\\) viene convertito in unità standard tramite la formula:\n\\[\nz = \\frac{x - m}{s} ,\n\\]\ndove \\(m\\) e \\(s\\) sono la media e la deviazione standard della distribuzione. Questa trasformazione ci dice di quante deviazioni standard un particolare valore si discosta dalla media. Ad esempio, se \\(z=0\\), il valore \\(x\\) corrisponde esattamente alla media; se \\(z = 2\\), il valore \\(x\\) si trova a due deviazioni standard sopra la media; se \\(z = -2\\), a due deviazioni standard sotto la media, e così via.\nIn R, possiamo calcolare le unità standard con la funzione:\n\nz &lt;- scale(x) |&gt; as.numeric()\nhead(z)\n#&gt; [1]  1.5744  0.1898 -0.3641  1.2975 -2.3026 -0.6410\n\nSe vogliamo sapere, ad esempio, quale frazione di individui si trova entro 2 deviazioni standard dalla media (cioè \\(|z| &lt; 2\\)), basta scrivere:\n\nmean(abs(z) &lt; 2)\n#&gt; [1] 0.9495\n\nVedremo, in molti casi, un valore intorno al 95%, in linea con quanto previsto dalla distribuzione normale. Per confermare la bontà dell’approssimazione, si usano spesso i grafici quantile-quantile, detti anche qqplot.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Introduzione alla distribuzione normale</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07a_introduction_normal_distribution.html#grafici-quantile-quantile-qqplot",
    "href": "chapters/eda/07a_introduction_normal_distribution.html#grafici-quantile-quantile-qqplot",
    "title": "20  Introduzione alla distribuzione normale",
    "section": "\n20.3 Grafici quantile-quantile (qqplot)",
    "text": "20.3 Grafici quantile-quantile (qqplot)\nUn modo sistematico per verificare quanto la distribuzione normale descriva bene i dati osservati consiste nel confrontare i quantili empirici con quelli teorici di una normale. Se i due insiemi di quantili sono molto simili, abbiamo un’ulteriore conferma dell’aderenza alla normalità.\n\nLa funzione di ripartizione della distribuzione normale standard si indica spesso con \\(\\Phi(x)\\). Ad esempio, \\(\\Phi(-1.96) \\approx 0.025\\) e \\(\\Phi(1.96) \\approx 0.975\\).\n\nL’inversa di \\(\\Phi\\), indicata come \\(\\Phi^{-1}(p)\\), ci dà il quantile corrispondente a una determinata probabilità \\(p\\). In R, pnorm calcola \\(\\Phi(x)\\) e qnorm calcola \\(\\Phi^{-1}(p)\\). Di default, pnorm e qnorm si riferiscono alla normale standard (media 0, deviazione standard 1), ma possiamo specificare valori diversi di media e deviazione standard tramite gli argomenti mean e sd.\n\nPer ottenere il quantile empirico da un vettore di dati in R, possiamo usare la funzione quantile. Ad esempio, se abbiamo un vettore x, il quantile associato alla probabilità \\(p\\) è il valore \\(q\\) per il quale mean(x &lt;= q) = p.\nEcco lo schema logico per costruire un qqplot:\n\nDefiniamo un vettore di proporzioni \\(p_1, p_2, \\dots, p_m\\).\n\nCalcoliamo i relativi quantili empirici dei nostri dati \\(\\{q_1, \\dots, q_m\\}\\) usando quantile(x, p_i).\n\nCalcoliamo i quantili teorici della normale (con la stessa media e la stessa deviazione standard dei dati) usando qnorm(p_i, mean, sd).\n\nRappresentiamo i punti \\((\\text{quantile teorico}, \\text{quantile empirico})\\). Se i dati sono davvero normali, tali punti si disporranno approssimativamente lungo la retta diagonale y = x.\n\nEsempio in R:\n\np &lt;- seq(0.05, 0.95, 0.05)\nsample_quantiles &lt;- quantile(x, p)\ntheoretical_quantiles &lt;- qnorm(p, mean = mean(x), sd = sd(x))\n\nqplot(theoretical_quantiles, sample_quantiles) + geom_abline()\n\n\n\n\n\n\n\nSe però abbiamo già convertito in unità standard (quindi \\(\\mu = 0\\) e \\(\\sigma = 1\\)), il confronto si semplifica:\n\nsample_quantiles &lt;- quantile(z, p)\ntheoretical_quantiles &lt;- qnorm(p)\nqplot(theoretical_quantiles, sample_quantiles) + geom_abline()\n\n\n\n\n\n\n\nIn pratica, per creare rapidamente un qqplot si usa spesso ggplot2 con la geometria geom_qq:\n\nheights |&gt; filter(sex == \"Male\") |&gt;\n  ggplot(aes(sample = scale(height))) + \n  geom_qq() +\n  geom_abline()\n\n\n\n\n\n\n\nCome abbiamo sottolineato, se i punti nel qqplot si dispongono lungo una retta, significa che la distribuzione dei dati è in accordo con la distribuzione teorica considerata (in questo caso, la normale). I qqplot possono essere usati anche per confrontare qualsiasi coppia di distribuzioni, non solo dati e normale teorica.\nQuesto indica che l’approssimazione normale è accurata per il gruppo maschile (nel nostro dataset).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Introduzione alla distribuzione normale</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07a_introduction_normal_distribution.html#media-e-deviazione-standard-come-statistiche-descrittive-della-distribuzione",
    "href": "chapters/eda/07a_introduction_normal_distribution.html#media-e-deviazione-standard-come-statistiche-descrittive-della-distribuzione",
    "title": "20  Introduzione alla distribuzione normale",
    "section": "\n20.4 Media e Deviazione Standard come Statistiche Descrittive della Distribuzione",
    "text": "20.4 Media e Deviazione Standard come Statistiche Descrittive della Distribuzione\nLa media e la deviazione standard sono due delle statistiche più comunemente utilizzate per descrivere la distribuzione di un insieme di dati. Queste misure sono particolarmente utili quando i dati seguono una distribuzione normale. In questo caso, la media e la deviazione standard contengono tutte le informazioni necessarie per caratterizzare completamente la forma della distribuzione.\n\n20.4.1 Distribuzione Normale e Statistiche Descrittive\nLa distribuzione normale è definita dalla sua media (\\(\\mu\\)) e dalla sua deviazione standard (\\(\\sigma\\)). La formula della densità di probabilità della distribuzione normale è data dall’Equazione 20.1. Questa formula mostra che, conoscendo solo \\(\\mu\\) e \\(\\sigma\\), possiamo ricostruire l’intera curva di densità. Pertanto, se i dati empirici sono ben approssimati da una distribuzione normale, la media e la deviazione standard sono sufficienti per descrivere la distribuzione.\nSupponiamo di avere un dataset che segue una distribuzione normale con media 50 e deviazione standard 10. Possiamo generare dati casuali e visualizzare la curva di densità in R:\n\n# Generiamo dati da una distribuzione normale\nset.seed(123)\ndati &lt;- rnorm(1000, mean = 50, sd = 10)\n\n# Calcoliamo media e deviazione standard\nmedia &lt;- mean(dati)\ndeviazione_standard &lt;- sd(dati)\n\n# Visualizziamo la curva di densità\nggplot(data.frame(dati), aes(x = dati)) +\n  geom_density(fill = \"lightblue\") +\n  geom_vline(xintercept = media, color = \"red\", linetype = \"dashed\") +\n  labs(title = \"Curva di Densità di una Distribuzione Normale\",\n       x = \"Valori\",\n       y = \"Densità\") +\n  annotate(\"text\", x = media + 5, y = 0.03, label = paste(\"Media =\", round(media, 2)), color = \"red\") +\n  annotate(\"text\", x = media + 5, y = 0.025, label = paste(\"Deviazione Standard =\", round(deviazione_standard, 2)), color = \"blue\")\n\n\n\n\n\n\n\nIn questo esempio:\n\nLa curva di densità è centrata attorno alla media (\\(\\mu = 50\\)).\nLa deviazione standard (\\(\\sigma = 10\\)) determina la dispersione dei dati attorno alla media.\n\n20.4.2 Quando Media e Deviazione Standard Non Sono Sufficienti\nSebbene media e deviazione standard siano strumenti estremamente utili per descrivere distribuzioni normali, non sempre bastano a cogliere tutte le caratteristiche di un insieme di dati. In particolare, ci sono situazioni in cui la forma della distribuzione rende necessario ricorrere a misure aggiuntive. Di seguito presentiamo alcuni casi tipici.\n\n\nDistribuzioni Asimmetriche\nUna distribuzione si dice asimmetrica (o skewed) quando una coda è più “estesa” dell’altra.\n\nSe la coda più lunga è a destra, la distribuzione è asimmetrica positiva (o a destra).\n\nSe la coda più lunga è a sinistra, la distribuzione è asimmetrica negativa (o a sinistra).\nIn queste circostanze, la media tende a spostarsi verso la coda più lunga, mentre la mediana rimane più stabile e rappresentativa del valore centrale.\n\n\nDistribuzioni Multimodali\nUna distribuzione è multimodale quando presenta più picchi (o “modi”). Ciò significa che i dati si concentrano attorno a più di un valore, formando veri e propri sotto-gruppi. In questi casi, media e deviazione standard possono risultare poco significative, poiché non colgono la presenza di più poli di concentrazione.\n\nKurtosi\nLa kurtosi descrive quanto una distribuzione sia “appuntita” o “piatta” rispetto a una normale.\n\n\nAlta kurtosi indica picchi molto accentuati e code più lunghe, con una maggiore probabilità di valori estremi.\n\n\nBassa kurtosi segnala una forma più appiattita, con code ridotte e meno outlier.\n\n\n\nQuando le distribuzioni mostrano una di queste peculiarità, altre statistiche possono rivelarsi più informative:\n\nLa mediana, insensibile ai valori estremi, fornisce una descrizione più robusta del centro.\n\nI quartili, e in particolare l’intervallo interquartile, danno un’idea della dispersione principale trascurando le code.\n\nL’indice di asimmetria (skewness) misura il grado di sbilanciamento della distribuzione.\n\nL’indice di curtosi (kurtosis) quantifica la “pesantezza” delle code.\n\nNel seguente esempio, generiamo dati da una distribuzione esponenziale, notoriamente asimmetrica:\n\n# Generiamo dati da una distribuzione esponenziale\nset.seed(123)\ndati_esponenziali &lt;- rexp(1000, rate = 0.5)\n\n# Calcoliamo media e deviazione standard\nmedia_esp &lt;- mean(dati_esponenziali)\ndeviazione_standard_esp &lt;- sd(dati_esponenziali)\n\n# Visualizziamo la curva di densità\nggplot(data.frame(dati_esponenziali), aes(x = dati_esponenziali)) +\n  geom_density(fill = \"#F8766D\", alpha = 0.6) +\n  geom_vline(xintercept = media_esp, color = \"red\", linetype = \"dashed\") +\n  labs(title = \"Curva di Densità di una Distribuzione Esponenziale\",\n       x = \"Valori\",\n       y = \"Densità\") +\n  annotate(\"text\", x = media_esp + 1, y = 0.2, \n           label = paste(\"Media =\", round(media_esp, 2)), \n           color = \"red\") +\n  annotate(\"text\", x = media_esp + 1, y = 0.18, \n           label = paste(\"Deviazione Standard =\", round(deviazione_standard_esp, 2)), \n           color = \"blue\")\n\n\n\n\n\n\n\nL’istogramma (o la densità) mostra chiaramente una coda lunga a destra, con molti valori piccoli e pochi valori grandi. In questo contesto:\n\nLa media tende a seguire la coda, diventando meno rappresentativa del “centro”.\n\nLa deviazione standard non descrive in modo efficace la variabilità, perché non considera adeguatamente la forte asimmetria.\n\nMisure alternative, come la mediana e i quartili, forniscono informazioni più affidabili:\n\n# Calcoliamo mediana e quartili\nmediana &lt;- median(dati_esponenziali)\nquartili &lt;- quantile(dati_esponenziali, probs = c(0.25, 0.75))\n\ncat(\"Mediana:\", mediana, \"\\n\")\n#&gt; Mediana: 1.462\ncat(\"Primo Quartile (Q1):\", quartili[1], \"\\n\")\n#&gt; Primo Quartile (Q1): 0.6134\ncat(\"Terzo Quartile (Q3):\", quartili[2], \"\\n\")\n#&gt; Terzo Quartile (Q3): 2.853\n\nIn conclusione, quando i dati non presentano una forma vicina alla normalità (ad esempio perché asimmetrici, multimodali o con kurtosi anomala), media e deviazione standard possono risultare fuorvianti o poco utili. In questi casi, è fondamentale adottare misure alternative o complementari (mediana, quartili, skewness, kurtosis) per ottenere una descrizione più accurata della distribuzione.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Introduzione alla distribuzione normale</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07a_introduction_normal_distribution.html#riflessioni-conclusive",
    "href": "chapters/eda/07a_introduction_normal_distribution.html#riflessioni-conclusive",
    "title": "20  Introduzione alla distribuzione normale",
    "section": "\n20.5 Riflessioni Conclusive",
    "text": "20.5 Riflessioni Conclusive\nIn questo capitolo, abbiamo esplorato alcuni concetti fondamentali per l’analisi dei dati e consolidato le basi per un’interpretazione più approfondita delle distribuzioni. In particolare, abbiamo:\n\n\nStudiato la distribuzione normale, una delle distribuzioni più importanti in statistica, e compreso perché la media e la deviazione standard siano parametri cruciali per descriverla. Questi indicatori ci permettono di riassumere in modo efficace le caratteristiche centrali e la variabilità dei dati.\n\nImparato a standardizzare i dati convertendoli in unità standard (z-score), il che ci consente di confrontare variabili con scale diverse o di valutare quanto un dato specifico si discosti dalla media in termini di deviazioni standard.\n\nIntrodotto il grafico quantile-quantile (QQ-plot), uno strumento visivo prezioso per verificare se i nostri dati seguono una distribuzione normale. Attraverso il QQ-plot, possiamo confrontare i quantili empirici dei nostri dati con quelli teorici della distribuzione normale, identificando eventuali deviazioni.\n\nGli strumenti descritti in questo capitolo rappresentano il primo passo essenziale nell’analisi esplorativa dei dati. Essi ci aiutano a formulare ipotesi solide e a riconoscere potenziali problemi o caratteristiche peculiari dei dati prima di applicare metodi statistici più avanzati, che approfondiremo nei prossimi capitoli.\nL’analisi esplorativa, combinando grafici intuitivi e statistiche descrittive appropriate, riveste quindi un ruolo fondamentale nel processo analitico. Essa non solo ci aiuta a comprendere meglio la natura dei dati, ma ci fornisce anche una base solida su cui costruire conclusioni statistiche attendibili e informate.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Introduzione alla distribuzione normale</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07a_introduction_normal_distribution.html#esercizi",
    "href": "chapters/eda/07a_introduction_normal_distribution.html#esercizi",
    "title": "20  Introduzione alla distribuzione normale",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nEsercizi\n\n\n\n\n\nEsercizi Teorici\n📌 Rispondi alle seguenti domande per consolidare la comprensione teorica della distribuzione normale e dei suoi concetti chiave.\n\n\nCaratteristiche della distribuzione normale\n\nQuali sono i due parametri principali della distribuzione normale?\n\nPerché la distribuzione normale è utilizzata così frequentemente in statistica?\n\nIn quali situazioni reali possiamo aspettarci che una variabile segua una distribuzione normale?\n\n\n\nMedia e deviazione standard\n\nQual è il significato della media in una distribuzione normale?\n\nCosa rappresenta la deviazione standard?\n\nIn che modo la deviazione standard influenza la forma della curva normale?\n\n\n\nZ-score e standardizzazione\n\nCos’è uno z-score e come si calcola?\n\nQual è il significato di un valore z=2? E di un valore z=-1.5?\n\nDopo la standardizzazione, quali saranno la media e la deviazione standard della variabile?\n\n\n\nVerifica della normalità\n\nSe hai un piccolo campione di dati (circa 15 osservazioni), quali metodi grafici puoi utilizzare per valutare se segue una distribuzione normale?\n\nQuali strumenti statistici puoi impiegare per testare la normalità?\n\nIn un QQ-plot, come puoi riconoscere se i dati seguono una distribuzione normale?\n\n\n\nEsercizi Pratici in R\n📌 Obiettivo: Analizzare i dati raccolti dagli studenti sulla Satisfaction With Life Scale (SWLS), comprendere la loro distribuzione e confrontarli con una distribuzione normale teorica.\n💾 Dati disponibili:\nUsa i dati della SWLS. I dati contengono anche informazioni sul genere e su un indice di rete sociale (LSNS).\n1. Esplorazione e Visualizzazione dei Dati SWLS\n\n\nCarica i dati raccolti dagli studenti e verifica la struttura del dataset.\n\n\nCalcola i valori di base: media, deviazione standard, minimo, massimo, e quantili della SWLS.\n\n\nCrea una rappresentazione visiva dei dati:\n\nIstogramma con sovrapposta una curva di densità.\n\nBoxplot per identificare eventuali outlier.\n\nViolin plot per osservare la distribuzione.\n\n\n\n2. Confronto con la Distribuzione Normale\n\n\nSovrapponi ai dati osservati una curva normale teorica basata su media e deviazione standard stimate dal campione.\n\n\nConfronta i quantili empirici con quelli teorici mediante un QQ-plot.\n\n\nCommenta il risultato: i dati SWLS seguono approssimativamente una normale? Se no, quali differenze noti?\n\n3. Standardizzazione dei Punteggi SWLS\n\n\nTrasforma i dati della SWLS in z-score per analizzarli in unità standardizzate.\n\nVerifica la nuova media e deviazione standard: dovrebbero essere 0 e 1 rispettivamente.\n\n\nConta quanti punteggi standardizzati si trovano entro 1, 2 e 3 deviazioni standard dalla media e confronta i valori attesi di 68%, 95% e 99.7%.\n\n4. Relazione tra SWLS e Interazione Sociale (LSNS)\n\n\nEsplora la relazione tra SWLS e il punteggio della Scala della Rete Sociale di Lubben (LSNS-6).\n\n\nCostruisci un grafico a dispersione per osservare la correlazione tra le due variabili.\n\n\nCalcola il coefficiente di correlazione di Pearson e commenta il risultato. Esiste una relazione tra soddisfazione della vita e supporto sociale?\n\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n1. Caratteristiche della distribuzione normale\na. Quali sono i due parametri principali della distribuzione normale?\nI due parametri principali che definiscono una distribuzione normale sono:\n\n\nLa media (μ): Indica il centro della distribuzione. Tutte le osservazioni si raggruppano attorno a questo valore.\n\nLa deviazione standard (σ): Descrive la dispersione o la variabilità dei dati attorno alla media.\n\nb. Perché la distribuzione normale è utilizzata così frequentemente in statistica?\nLa distribuzione normale è ampiamente usata per diversi motivi:\n\n\nTeorema del limite centrale: Afferma che, quando si sommano molte variabili casuali indipendenti, la loro distribuzione tende ad avvicinarsi a una normale, indipendentemente dalla forma originale delle singole distribuzioni.\n\nSemplicità matematica: La normale ha proprietà matematiche ben definite e permette di calcolare probabilità e intervalli con facilità.\n\nModellizzazione naturale: Molte variabili naturali e sociali (ad esempio, altezze, pesi, punteggi standardizzati) seguono approssimativamente una distribuzione normale.\n\nc. In quali situazioni reali possiamo aspettarci che una variabile segua una distribuzione normale?\nSi può aspettare una distribuzione normale in situazioni in cui:\n\nLe osservazioni sono influenzate da molti fattori casuali indipendenti (es. altezza di un individuo, errore di misurazione).\nI dati derivano da fenomeni naturali o biologici (es. pressione sanguigna, peso corporeo).\nSi analizzano medie campionarie di grandi dimensioni (grazie al teorema del limite centrale).\n\n2. Media e deviazione standard\na. Qual è il significato della media in una distribuzione normale?\nNella distribuzione normale, la media rappresenta il punto centrale della curva, ovvero il valore più probabile. È anche il punto di simmetria della distribuzione, dove metà delle osservazioni si trova a sinistra e l’altra metà a destra.\nb. Cosa rappresenta la deviazione standard?\nLa deviazione standard misura quanto i dati si discostano in media dalla media. Una deviazione standard bassa indica che i dati sono raggruppati strettamente attorno alla media, mentre una deviazione standard alta indica una maggiore dispersione.\nc. In che modo la deviazione standard influenza la forma della curva normale?\n\nUna deviazione standard piccola produce una curva alta e stretta, indicando una bassa variabilità.\nUna deviazione standard grande produce una curva bassa e larga, indicando una maggiore variabilità.\n\n3. Z-score e standardizzazione\na. Cos’è uno z-score e come si calcola?\nUno z-score misura quante deviazioni standard un dato si discosta dalla media. Viene calcolato come:\n\\[\nz = \\frac{x - \\mu}{\\sigma}\n\\]\ndove \\(x\\) è il valore osservato, \\(\\mu\\) è la media e \\(\\sigma\\) è la deviazione standard.\nb. Qual è il significato di un valore z=2? E di un valore z=-1.5?\n\nUn \\(z = 2\\) significa che il dato è posizionato a 2 deviazioni standard sopra la media.\nUn \\(z = -1.5\\) significa che il dato è posizionato a 1.5 deviazioni standard sotto la media.\n\nc. Dopo la standardizzazione, quali saranno la media e la deviazione standard della variabile?\nDopo la standardizzazione:\n\nLa media diventa \\(0\\).\nLa deviazione standard diventa \\(1\\).\n\n4. Verifica della normalità\na. Se hai un piccolo campione di dati (circa 15 osservazioni), quali metodi grafici puoi utilizzare per valutare se segue una distribuzione normale?\nPer piccoli campioni, i metodi grafici più utili sono:\n\n\nQQ-plot (Quantile-Quantile plot): Confronta i quantili dei dati con quelli di una distribuzione normale. Se i punti seguono una retta diagonale, i dati sono normali.\n\nIstogramma: Mostra la distribuzione dei dati, ma con campioni piccoli può essere meno preciso.\n\nb. Quali strumenti statistici puoi impiegare per testare la normalità?\nGli strumenti statistici più comuni per verificare la normalità sono:\n\n\nTest di Shapiro-Wilk: Ideale per piccoli campioni.\n\nTest di Kolmogorov-Smirnov: Usato per confrontare la distribuzione empirica con una normale.\n\nTest di Anderson-Darling: Sensibile alle code della distribuzione.\n\nc. In un QQ-plot, come puoi riconoscere se i dati seguono una distribuzione normale?\nIn un QQ-plot:\n\nSe i dati seguono una distribuzione normale, i punti si allineeranno lungo una retta diagonale.\nDeviazioni dalla retta indicano departi dalla normalità:\n\nCode pesanti: Punti esterni alla retta suggeriscono outlier.\nAsimmetria: Punti curvati suggeriscono skewness (asimmetria).\n\n\n\nEsplorazione e Visualizzazione dei Dati SWLS\nCaricamento e struttura dei dati\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Supponiamo che i dati siano i seguenti\nset.seed(42)\nswls &lt;- data.frame(\n  ID = 1:15,\n  SWLS = c(18, 22, 25, 21, 26, 19, 20, 23, 24, 17, 22, 27, 28, 21, 19),\n  Genere = c(\"M\", \"F\", \"F\", \"M\", \"F\", \"M\", \"M\", \"F\", \"M\", \"F\", \"M\", \"F\", \"F\", \"M\", \"M\"),\n  LSNS = c(16, 20, 22, 14, 19, 18, 17, 25, 23, 12, 21, 28, 26, 19, 15)\n)\n\nstr(swls)\nsummary(swls$SWLS)\nVisualizzazioni\n# Istogramma con curva di densità\nggplot(swls, aes(x = SWLS)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 6, fill = \"blue\", alpha = 0.5) +\n  geom_density(color = \"red\", size = 1) +\n  ggtitle(\"Distribuzione dei punteggi SWLS\")\n\n# Boxplot\nggplot(swls, aes(y = SWLS)) +\n  geom_boxplot(fill = \"cyan\") +\n  ggtitle(\"Boxplot dei punteggi SWLS\")\n2. Confronto con la Distribuzione Normale\n# QQ-plot per valutare la normalità\nggplot(swls, aes(sample = SWLS)) +\n  geom_qq() +\n  geom_abline() +\n  ggtitle(\"QQ-plot dei punteggi SWLS\") +\n  theme_minimal()\nOsservazione:\n\nSe i punti si allineano lungo la diagonale, i dati sono approssimativamente normali.\nSe ci sono deviazioni marcate, la distribuzione potrebbe essere asimmetrica o presentare code pesanti.\n\n3. Standardizzazione dei punteggi SWLS\nswls$Z_SWLS &lt;- scale(swls$SWLS)\n\nmean(swls$Z_SWLS)  # Dovrebbe essere circa 0\nsd(swls$Z_SWLS)    # Dovrebbe essere circa 1\n\n# Proporzione entro 1, 2, 3 deviazioni standard\nmean(abs(swls$Z_SWLS) &lt; 1)  # Atteso ~68%\nmean(abs(swls$Z_SWLS) &lt; 2)  # Atteso ~95%\nmean(abs(swls$Z_SWLS) &lt; 3)  # Atteso ~99.7%\n4. Relazione tra SWLS e LSNS\n# Grafico di dispersione\nggplot(swls, aes(x = LSNS, y = SWLS)) +\n  geom_point(color = \"blue\", size = 3) +\n  geom_smooth(method = \"lm\", color = \"red\", se = FALSE) +\n  ggtitle(\"Relazione tra SWLS e LSNS\") \n\n# Calcolo della correlazione\ncor(swls$SWLS, swls$LSNS)\nInterpretazione:\n\nUn valore di correlazione positivo indica che livelli più alti di supporto sociale (LSNS) sono associati a una maggiore soddisfazione della vita (SWLS).\n\nSe la correlazione è debole, il supporto sociale potrebbe non essere un predittore forte della soddisfazione della vita in questo campione ristretto.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Introduzione alla distribuzione normale</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07a_introduction_normal_distribution.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/07a_introduction_normal_distribution.html#informazioni-sullambiente-di-sviluppo",
    "title": "20  Introduzione alla distribuzione normale",
    "section": "Informazioni sull’ambiente di sviluppo",
    "text": "Informazioni sull’ambiente di sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] gridExtra_2.3         dslabs_0.8.0          ggbeeswarm_0.7.2     \n#&gt;  [4] pillar_1.11.0         tinytable_0.11.0      patchwork_1.3.1      \n#&gt;  [7] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.13.0     \n#&gt; [10] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.0     \n#&gt; [13] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [16] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [19] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [22] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [25] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.6         tidyselect_1.2.1     vipor_0.4.7         \n#&gt;  [4] farver_2.1.2         fastmap_1.2.0        TH.data_1.1-3       \n#&gt;  [7] tensorA_0.36.2.1     pacman_0.5.1         digest_0.6.37       \n#&gt; [10] estimability_1.5.1   timechange_0.3.0     lifecycle_1.0.4     \n#&gt; [13] survival_3.8-3       magrittr_2.0.3       compiler_4.5.1      \n#&gt; [16] rlang_1.1.6          tools_4.5.1          knitr_1.50          \n#&gt; [19] labeling_0.4.3       bridgesampling_1.1-2 htmlwidgets_1.6.4   \n#&gt; [22] pkgbuild_1.4.8       curl_6.4.0           RColorBrewer_1.1-3  \n#&gt; [25] abind_1.4-8          multcomp_1.4-28      withr_3.0.2         \n#&gt; [28] purrr_1.1.0          grid_4.5.1           stats4_4.5.1        \n#&gt; [31] xtable_1.8-4         colorspace_2.1-1     inline_0.3.21       \n#&gt; [34] emmeans_1.11.2       scales_1.4.0         MASS_7.3-65         \n#&gt; [37] cli_3.6.5            mvtnorm_1.3-3        rmarkdown_2.29      \n#&gt; [40] generics_0.1.4       RcppParallel_5.1.10  cachem_1.1.0        \n#&gt; [43] stringr_1.5.1        splines_4.5.1        parallel_4.5.1      \n#&gt; [46] vctrs_0.6.5          V8_6.0.5             Matrix_1.7-3        \n#&gt; [49] sandwich_3.1-1       jsonlite_2.0.0       arrayhelpers_1.1-0  \n#&gt; [52] beeswarm_0.4.0       glue_1.8.0           codetools_0.2-20    \n#&gt; [55] distributional_0.5.0 lubridate_1.9.4      stringi_1.8.7       \n#&gt; [58] gtable_0.3.6         QuickJSR_1.8.0       htmltools_0.5.8.1   \n#&gt; [61] Brobdingnag_1.2-9    R6_2.6.1             rprojroot_2.1.0     \n#&gt; [64] evaluate_1.0.4       lattice_0.22-7       backports_1.5.0     \n#&gt; [67] memoise_2.0.1        broom_1.0.9          snakecase_0.11.1    \n#&gt; [70] rstantools_2.4.0     coda_0.19-4.1        nlme_3.1-168        \n#&gt; [73] checkmate_2.3.2      xfun_0.52            zoo_1.8-14          \n#&gt; [76] pkgconfig_2.0.3",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Introduzione alla distribuzione normale</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07a_introduction_normal_distribution.html#bibliografia",
    "href": "chapters/eda/07a_introduction_normal_distribution.html#bibliografia",
    "title": "20  Introduzione alla distribuzione normale",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nIrizarry, R. A. (2024). Introduction to Data Science: Data Wrangling and Visualization with R. CRC Press.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Introduzione alla distribuzione normale</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html",
    "href": "chapters/eda/08_correlation.html",
    "title": "21  Relazioni tra variabili",
    "section": "",
    "text": "Introduzione\nStoricamente, in psicologia, l’analisi delle associazioni tra variabili è stata spesso considerata come l’obiettivo finale del processo di ricerca. Questa visione si basa sull’idea che la descrizione delle relazioni tra variabili possa fornire una spiegazione esaustiva dei fenomeni psicologici. Tale approccio affonda le sue radici nel pensiero di Karl Pearson (1911), il quale sosteneva che la spiegazione scientifica si esaurisse una volta delineate le associazioni tra le variabili osservate. Pearson affermava:\nSebbene sia indubbio che rispondere alla domanda posta da Pearson sia relativamente semplice, è altrettanto evidente che la nostra comprensione di un fenomeno non può dipendere unicamente dalle informazioni fornite dalle correlazioni. Le associazioni, infatti, non implicano causalità e possono risultare fuorvianti se interpretate in modo superficiale.\nIn contrasto con questa visione tradizionale, la cosiddetta “Causal Revolution” propone un paradigma radicalmente diverso, secondo il quale le associazioni tra variabili sono considerate come epifenomeni, ovvero manifestazioni superficiali di meccanismi più profondi. L’obiettivo principale della ricerca, in questo quadro, diventa l’identificazione e la comprensione delle relazioni causali. Per comprendere veramente i fenomeni psicologici, è essenziale indagare le cause sottostanti, andando oltre la mera descrizione delle associazioni.\nUn esempio emblematico è l’associazione tra il numero di scarpe e le abilità matematiche nei bambini. Questa correlazione è molto forte, ma se controlliamo per la variabile confondente “età”, l’associazione scompare. Questo dimostra che, in psicologia così come in altri campi, trovare correlazioni molto forti tra variabili non è necessariamente informativo riguardo ai meccanismi sottostanti al fenomeno studiato. È ovvio che il numero di scarpe non influisce sulle abilità matematiche, ma senza controllare per l’età, l’associazione rimane ingannevolmente forte.\nAllo stesso modo, può accadere che un’associazione apparentemente forte scompaia se non si tiene conto di variabili confondenti. Consideriamo, ad esempio, la relazione tra autostima e rendimento scolastico in un campione di adolescenti. Analizzando l’intera popolazione, la correlazione tra autostima e rendimento potrebbe risultare prossima a zero. Questo apparente risultato nullo, tuttavia, potrebbe nascondere una relazione più complessa, influenzata da un fattore confondente come il supporto familiare.\nQuando si controlla per il supporto familiare (ad esempio analizzando separatamente i gruppi con alto e basso sostegno), emerge una relazione positiva credibile tra autostima e rendimento scolastico all’interno del gruppo con supporto elevato. Questo esempio mostra come, a livello aggregato, l’effetto di due variabili possa apparire nullo, mentre il controllo per un confondente svela una relazione causale rilevante.\nIn conclusione, l’analisi delle associazioni rappresenta un punto di partenza fondamentale, ma non può sostituire l’indagine delle relazioni causali. Per progredire nella comprensione dei fenomeni psicologici, è necessario integrare l’analisi dei dati con modelli teorici robusti e un approccio critico volto a identificare e controllare i fattori confondenti. Solo così possiamo passare dalla semplice descrizione delle relazioni alla vera comprensione dei meccanismi causali che le governano.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#introduzione",
    "href": "chapters/eda/08_correlation.html#introduzione",
    "title": "21  Relazioni tra variabili",
    "section": "",
    "text": "L’analisi delle associazioni tra variabili è un’operazione fondamentale nell’ambito della ricerca psicologica, ma nonostante la sua apparente semplicità, rappresenta uno degli aspetti più controversi e metodologicamente complessi. Sebbene possa sembrare un passaggio naturale successivo all’analisi univariata, questo processo solleva numerose questioni concettuali e pratiche che richiedono un’attenta riflessione.\n\n\n\n“Quanto spesso, quando è stato osservato un nuovo fenomeno, sentiamo che viene posta la domanda: ‘qual è la sua causa?’. Questa è una domanda a cui potrebbe essere assolutamente impossibile rispondere. Invece, può essere più facile rispondere alla domanda: ‘in che misura altri fenomeni sono associati con esso?’. Dalla risposta a questa seconda domanda possono risultare molte preziose conoscenze.”\n\n\n\n\n\n\nIn presenza di un forte supporto familiare, una maggiore autostima potrebbe effettivamente favorire migliori risultati scolastici.\n\nAl contrario, in assenza di tale supporto, anche livelli elevati di autostima potrebbero non tradursi in un rendimento scolastico migliore, a causa di risorse emotive e pratiche limitate.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#terminologia",
    "href": "chapters/eda/08_correlation.html#terminologia",
    "title": "21  Relazioni tra variabili",
    "section": "\n21.1 Terminologia",
    "text": "21.1 Terminologia\nLa discussione dei metodi utilizzati per individuare le relazioni causali sarà trattata successivamente. In questo capitolo, ci concentreremo sui concetti statistici fondamentali necessari per descrivere le associazioni lineari tra variabili. È importante sottolineare che, sebbene esistano indici statistici per quantificare associazioni non lineari, la maggior parte degli psicologi si limita all’utilizzo di indici lineari.\nNel linguaggio comune, termini come “dipendenza”, “associazione” e “correlazione” vengono spesso usati in modo intercambiabile. Tuttavia, da un punto di vista tecnico, è importante distinguere questi concetti:\n\n\nAssociazione: questo termine indica una relazione generale tra variabili, dove la conoscenza del valore di una variabile fornisce informazioni su un’altra.\n\nCorrelazione: descrive una relazione specifica e quantificabile, indicando se due variabili tendono a variare insieme in modo sistematico. Ad esempio, in una correlazione positiva, se \\(X &gt; \\mu_X\\), è probabile che anche \\(Y &gt; \\mu_Y\\). La correlazione specifica il segno e l’intensità di una relazione lineare.\n\nDipendenza: indica una relazione causale tra le variabili, dove la variazione della variabile causale porta probabilisticamente alla variazione della variabile dipendente.\n\nÈ cruciale comprendere che non tutte le associazioni sono correlazioni e, soprattutto, che la correlazione non implica necessariamente causalità. Questa distinzione è fondamentale per interpretare correttamente i dati e evitare conclusioni errate sulle relazioni tra variabili.\nIn questo capitolo, esamineremo due misure statistiche fondamentali per valutare la relazione lineare tra due variabili: la covarianza e la correlazione. Questi indici ci permettono di descrivere il grado e la direzione dell’associazione lineare tra variabili, quantificando come queste variano congiuntamente.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#analisi-della-relazione-tra-due-misure-della-depressione",
    "href": "chapters/eda/08_correlation.html#analisi-della-relazione-tra-due-misure-della-depressione",
    "title": "21  Relazioni tra variabili",
    "section": "\n21.2 Analisi della relazione tra due misure della depressione",
    "text": "21.2 Analisi della relazione tra due misure della depressione\nL’obiettivo di questo esempio è esaminare la relazione tra due scale psicometriche che misurano la depressione: il Beck Depression Inventory II (BDI-II) e la Center for Epidemiologic Studies Depression Scale (CES-D). Lo studio di Zetsche et al. (2019) ha indagato se le aspettative negative possano costituire un meccanismo centrale nel mantenimento e nella reiterazione della depressione. In particolare, i ricercatori hanno confrontato 30 soggetti con almeno un episodio depressivo maggiore e 37 individui senza diagnosi depressiva.\n\n21.2.1 Strumenti di misurazione\n\nBDI-II:\nStrumento di autovalutazione che misura l’intensità dei sintomi depressivi riscontrati nelle ultime due settimane. Composto da 21 item, ciascuno valutato su una scala da 0 a 3, fornisce una stima della gravità della depressione.\nCES-D:\nScala anch’essa di autovalutazione, progettata per quantificare i sintomi depressivi sperimentati nella settimana precedente, principalmente in popolazioni generali, con particolare attenzione ad adolescenti e giovani adulti.\n\nPoiché entrambi gli strumenti mirano a misurare lo stesso costrutto, è ragionevole aspettarsi una relazione lineare tra i punteggi ottenuti, pur riconoscendo che errori di misurazione e unità di misura diverse possono generare discrepanze.\n\n21.2.2 Analisi statistica e visualizzazione\nPer verificare la relazione tra i punteggi BDI-II e CES-D, i dati sono stati processati come segue:\n\n# Leggi i dati dal file CSV\ndf &lt;- rio::import(here::here(\"data\", \"data.mood.csv\"))\n\n# Seleziona le colonne di interesse\ndf &lt;- df |&gt;\n  dplyr::select(\"esm_id\", \"group\", \"bdi\", \"cesd_sum\")\n\n# Rimuovi righe duplicate e casi con valori mancanti in 'bdi'\ndf &lt;- df[!duplicated(df), ]\ndf &lt;- df[!is.na(df$bdi), ]\n\nSuccessivamente, è stato realizzato un grafico a dispersione (scatterplot) in cui i valori del BDI-II sono stati posti sull’asse delle ascisse e quelli del CES-D sull’asse delle ordinate. Ogni punto rappresenta un partecipante, suddiviso per gruppo (soggetti depressi e controlli). L’aggiunta di una retta di regressione, ottenuta mediante un modello lineare, consente di valutare visivamente la tendenza di associazione tra le due misure.\n\n# Separazione dei dati per gruppo\nmdd_data &lt;- df[df$group == \"mdd\", ]\nctl_data &lt;- df[df$group == \"ctl\", ]\n\n# Calcolo dei coefficienti di regressione lineare\ncoeff_combined &lt;- lm(cesd_sum ~ bdi, data = df)$coefficients\n\n# Funzione per la retta di regressione\nline_combined &lt;- function(x) coeff_combined[1] + coeff_combined[2] * x\n\n# Generazione dei valori x per la retta\nx_values &lt;- seq(min(df$bdi), max(df$bdi), length.out = 100)\nokabe_ito_colors &lt;- c(\"Pazienti\" = \"#E69F00\",  # Arancione\n                      \"Controlli\" = \"#56B4E9\")  # Azzurro\n\n# Creazione del grafico a dispersione e della retta di regressione\nggplot() +\n  geom_point(\n    data = mdd_data,\n    aes(x = bdi, y = cesd_sum, color = \"Pazienti\"), alpha = 0.7\n  ) +\n  geom_point(\n    data = ctl_data,\n    aes(x = bdi, y = cesd_sum, color = \"Controlli\"), alpha = 0.7\n  ) +\n  geom_line(\n    aes(x = x_values, y = line_combined(x_values)),\n    linetype = \"dashed\", color = okabe_ito_colors[\"Pazienti\"]\n  ) +\n  geom_vline(\n    aes(xintercept = mean(mdd_data$bdi, na.rm = TRUE)),\n    color = okabe_ito_colors[\"Pazienti\"], alpha = 0.2\n  ) +\n  geom_vline(\n    aes(xintercept = mean(ctl_data$bdi, na.rm = TRUE)),\n    color = okabe_ito_colors[\"Controlli\"], alpha = 0.2\n  ) +\n  geom_hline(\n    aes(yintercept = mean(mdd_data$cesd_sum, na.rm = TRUE)),\n    color = okabe_ito_colors[\"Pazienti\"], alpha = 0.2\n  ) +\n  geom_hline(\n    aes(yintercept = mean(ctl_data$cesd_sum, na.rm = TRUE)),\n    color = okabe_ito_colors[\"Controlli\"], alpha = 0.2\n  ) +\n  labs(x = \"BDI-II\", y = \"CES-D\", color = \"Gruppo\") +\n  scale_color_manual(\n    values = okabe_ito_colors\n  )\n\n\n\n\n\n\n\n\n21.2.3 Interpretazione dei risultati\nIl grafico a dispersione evidenzia una tendenza approssimativamente lineare tra i punteggi del BDI-II e della CES-D, indicando che, in linea teorica, le due scale sono associate nel misurare il livello di depressione. Tuttavia, la presenza di una certa dispersione dei dati rispetto alla retta ideale sottolinea l’influenza degli errori di misurazione e della natura arbitraria delle unità di misura utilizzate. Per una valutazione più accurata della relazione, è necessario ricorrere a indici statistici in grado di quantificare sia la forza che la direzione dell’associazione.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#covarianza",
    "href": "chapters/eda/08_correlation.html#covarianza",
    "title": "21  Relazioni tra variabili",
    "section": "\n21.3 Covarianza",
    "text": "21.3 Covarianza\nIniziamo a considerare il più importante di tali indici, chiamato covarianza. In realtà la definizione di questo indice non ci sorprenderà più di tanto in quanto, in una forma solo apparentemente diversa, l’abbiamo già incontrata in precedenza. Ci ricordiamo infatti che la varianza di una generica variabile \\(X\\) è definita come la media degli scarti quadratici di ciascuna osservazione dalla media:\n\\[\nS_{XX} = \\frac{1}{n} \\sum_{i=1}^n(X_i - \\bar{X}) (X_i - \\bar{X}).\n\\tag{21.1}\\]\nLa varianza viene talvolta descritta come la “covarianza di una variabile con sé stessa”. Adesso facciamo un passo ulteriore. Invece di valutare la dispersione di una sola variabile, ci chiediamo come due variabili \\(X\\) e \\(Y\\) “variano insieme” (co-variano). È facile capire come una risposta a tale domanda possa essere fornita da una semplice trasformazione della formula precedente che diventa:\n\\[\nS_{XY} = \\frac{1}{n} \\sum_{i=1}^n(X_i - \\bar{X}) (Y_i - \\bar{Y}).\n\\tag{21.2}\\]\nL’Equazione 21.2 ci fornisce la definizione della covarianza.\n\n21.3.1 Interpretazione\nPer capire il significato dell’Equazione 21.2, supponiamo di dividere il grafico riportato nella Sezione 21.2.2 in quattro quadranti definiti da una retta verticale passante per la media dei valori BDI-II e da una retta orizzontale passante per la media dei valori CES-D. Numeriamo i quadranti partendo da quello in basso a sinistra e muovendoci in senso antiorario.\nSe prevalgono punti nel I e III quadrante, allora la nuvola di punti avrà un andamento crescente (per cui a valori bassi di \\(X\\) tendono ad associarsi valori bassi di \\(Y\\) e a valori elevati di \\(X\\) tendono ad associarsi valori elevati di \\(Y\\)) e la covarianza avrà segno positivo. Mentre se prevalgono punti nel II e IV quadrante la nuvola di punti avrà un andamento decrescente (per cui a valori bassi di \\(X\\) tendono ad associarsi valori elevati di \\(Y\\) e a valori elevati di \\(X\\) tendono ad associarsi valori bassi di \\(Y\\)) e la covarianza avrà segno negativo. Dunque, il segno della covarianza ci informa sulla direzione della relazione lineare tra due variabili: l’associazione lineare si dice positiva se la covarianza è positiva, negativa se la covarianza è negativa.\n\nEsempio 21.1 Implementiamo l’Equazione 21.2 in R.\n\ncov_value &lt;- function(x, y) {\n  mean_x &lt;- sum(x) / length(x)\n  mean_y &lt;- sum(y) / length(y)\n\n  sub_x &lt;- x - mean_x\n  sub_y &lt;- y - mean_y\n\n  sum_value &lt;- sum(sub_y * sub_x)\n  denom &lt;- length(x)\n\n  cov &lt;- sum_value / denom\n  return(cov)\n}\n\nPer i dati mostrati nel diagramma, la covarianza tra BDI-II e CESD è 207.4\n\nx &lt;- df$bdi\ny &lt;- df$cesd_sum\n\ncov_value(x, y)\n#&gt; [1] 207.4\n\nOppure, in maniera più semplice:\n\nmean((x - mean(x)) * (y - mean(y)))\n#&gt; [1] 207.4\n\nLo stesso risultato si ottiene con la funzione cov:\n\ncov(x, y) * (length(x) - 1) / length(x)\n#&gt; [1] 207.4\n\nLa funzione cov(x, y) calcola la covarianza tra due array, x e y utilizzando \\(n-1\\) al denominatore.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#correlazione",
    "href": "chapters/eda/08_correlation.html#correlazione",
    "title": "21  Relazioni tra variabili",
    "section": "\n21.4 Correlazione",
    "text": "21.4 Correlazione\nLa direzione della relazione tra le variabili è indicata dal segno della covarianza, ma il valore assoluto di questo indice non fornisce informazioni utili poiché dipende dall’unità di misura delle variabili. Ad esempio, considerando l’altezza e il peso delle persone, la covarianza sarà più grande se l’altezza è misurata in millimetri e il peso in grammi, rispetto al caso in cui l’altezza è in metri e il peso in chilogrammi. Pertanto, per descrivere la forza e la direzione della relazione lineare tra due variabili in modo adimensionale, si utilizza l’indice di correlazione.\nLa correlazione è ottenuta standardizzando la covarianza tramite la divisione delle deviazioni standard (\\(s_X\\), \\(s_Y\\)) delle due variabili:\n\\[\nr = \\frac{S_{XY}}{S_X S_Y}.\n\\tag{21.3}\\]\nLa quantità che si ottiene dall’Equazione 21.3 viene chiamata correlazione di Bravais-Pearson (dal nome degli autori che, indipendentemente l’uno dall’altro, l’hanno introdotta).\nIn maniera equivalente, per una lista di coppie di valori \\((x_1, y_1), \\dots, (x_n, y_n)\\), il coefficiente di correlazione è definito come la media del prodotto dei valori standardizzati:\n\\[\nr = \\frac{1}{n} \\sum_{i=1}^{n} \\left( \\frac{x_i - \\bar{x}}{\\sigma_x} \\right) \\left( \\frac{y_i - \\bar{y}}{\\sigma_y} \\right),\n\\tag{21.4}\\]\ndove \\(\\bar{x}\\) e \\(\\bar{y}\\) rappresentano, rispettivamente, le medie dei valori \\(x\\) e \\(y\\), e \\(\\sigma_x\\) e \\(\\sigma_y\\) sono le rispettive deviazioni standard.\nNell’Equazione 21.4, i valori \\(x_i\\) e \\(y_i\\) vengono prima standardizzati sottraendo la media e dividendo per la deviazione standard, e poi si calcola la media del prodotto di questi valori standardizzati.\n\n21.4.1 Proprietà\nIl coefficiente di correlazione ha le seguenti proprietà:\n\nha lo stesso segno della covarianza, dato che si ottiene dividendo la covarianza per due numeri positivi;\nè un numero puro, cioè non dipende dall’unità di misura delle variabili;\nassume valori compresi tra -1 e +1.\n\n21.4.2 Interpretazione\nAll’indice di correlazione possiamo assegnare la seguente interpretazione:\n\n\n\\(r_{XY} = -1\\) \\(\\rightarrow\\) perfetta relazione negativa: tutti i punti si trovano esattamente su una retta con pendenza negativa (dal quadrante in alto a sinistra al quadrante in basso a destra);\n\n\\(r_{XY} = +1\\) \\(\\rightarrow\\) perfetta relazione positiva: tutti i punti si trovano esattamente su una retta con pendenza positiva (dal quadrante in basso a sinistra al quadrante in alto a destra);\n\n\\(-1 &lt; r_{XY} &lt; +1\\) \\(\\rightarrow\\) presenza di una relazione lineare di intensità diversa;\n\n\\(r_{XY} = 0\\) \\(\\rightarrow\\) assenza di relazione lineare tra \\(X\\) e \\(Y\\).\n\n\nEsempio 21.2 Per i dati riportati nel diagramma della Sezione 21.2.2, la covarianza è 207.4. Il segno positivo della covarianza ci dice che tra le due variabili c’è un’associazione lineare positiva. Per capire quale sia l’intensità della relazione lineare calcoliamo la correlazione. Essendo le deviazioni standard del BDI-II e del CES-D rispettavamente uguali a 15.37 e 14.93, la correlazione diventa uguale a \\(\\frac{207.426}{15.38 \\cdot 14.93} = 0.904.\\) Tale valore è prossimo a 1.0, il che vuol dire che i punti del diagramma a dispersione non si discostano troppo da una retta con una pendenza positiva.\nTroviamo la correlazione con la funzione corrcoef():\n\ncor(x, y)\n#&gt; [1] 0.9041\n\nReplichiamo il risultato implementando l’Equazione 21.3:\n\ns_xy &lt;- mean((x - mean(x)) * (y - mean(y)))\ns_x &lt;- sqrt(mean((x - mean(x))^2)) # Deviazione standard popolazione\ns_y &lt;- sqrt(mean((y - mean(y))^2)) # Deviazione standard popolazione\nr_xy &lt;- s_xy / (s_x * s_y)\nprint(r_xy)\n#&gt; [1] 0.9041\n\nUn altro modo ancora per trovare la correlazione tra i punteggi BDI-II e CESD è quello di applicare l’Equazione 21.4:\n\nz_x &lt;- (x - mean(x)) / sqrt(mean((x - mean(x))^2)) \n# Standardizzazione con deviazione standard popolazione\nz_y &lt;- (y - mean(y)) / sqrt(mean((y - mean(y))^2)) \n# Standardizzazione con deviazione standard popolazione\nmean(z_x * z_y)\n#&gt; [1] 0.9041\n\n\n\nEsempio 21.3 Un uso interessante delle correlazioni viene fatto in un recente articolo di Guilbeault et al. (2024). Il concetto di “gender bias” si riferisce alla tendenza sistematica di favorire un sesso rispetto all’altro, spesso a scapito delle donne. Lo studio di Guilbeault et al. (2024) analizza come le immagini online influenzino la diffusione su vasta scala di questo preconcetto di genere.\nAttraverso un vasto insieme di immagini e testi raccolti online, gli autori dimostrano che sia le misurazioni basate sulle immagini che quelle basate sui testi catturano la frequenza con cui varie categorie sociali sono associate a rappresentazioni di genere, valutate su una scala da -1 (femminile) a 1 (maschile), con 0 che indica una neutralità di genere. Questo consente di quantificare il preconcetto di genere come una forma di bias statistico lungo tre dimensioni: la tendenza delle categorie sociali ad associarsi a un genere specifico nelle immagini e nei testi, la rappresentazione relativa delle donne rispetto agli uomini in tutte le categorie sociali nelle immagini e nei testi, e il confronto tra le associazioni di genere nei dati delle immagini e dei testi con la distribuzione empirica delle donne e degli uomini nella società. Il lavoro di Guilbeault et al. (2024) evidenzia che il preconcetto di genere è molto più evidente nelle immagini rispetto ai testi, come mostrato nel pannello C della figura.\nSi noti che, nel grafico del pannello C della figura, ogni punto può essere interpretato come una misura di correlazione. La misura utilizzata da Guilbeault et al. (2024) riflette il grado di associazione tra le categorie sociali e le rappresentazioni di genere presenti nelle immagini e nei testi analizzati. Quando la misura è vicina a +1, indica una forte associazione positiva tra una categoria sociale specifica e una rappresentazione di genere maschile, mentre un valore vicino a -1 indica una forte associazione negativa con una rappresentazione di genere femminile. Un valore di 0, invece, suggerisce che non vi è alcuna associazione tra la categoria sociale considerata e un genere specifico, indicando una sorta di neutralità di genere. In sostanza, questa misura di frequenza può essere interpretata come una correlazione che riflette la tendenza delle categorie sociali a essere rappresentate in un modo o nell’altro nelle immagini e nei testi analizzati, rispetto ai concetti di genere femminile e maschile.\n\n\nIl preconcetto di genere è più prevalente nelle immagini online (da Google Immagini) e nei testi online (da Google News). A. La correlazione tra le associazioni di genere nelle immagini da Google Immagini e nei testi da Google News per tutte le categorie sociali (n = 2.986), organizzate per decili. B. La forza dell’associazione di genere in queste immagini e testi online per tutte le categorie (n = 2.986), suddivisa in base al fatto che queste categorie siano inclinate verso il femminile o il maschile. C. Le associazioni di genere per un campione di occupazioni secondo queste immagini e testi online; questo campione è stato selezionato manualmente per evidenziare i tipi di categorie sociali e preconcetti di genere esaminati. (Figura tratta da Guilbeault et al. (2024)).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#correlazione-di-spearman",
    "href": "chapters/eda/08_correlation.html#correlazione-di-spearman",
    "title": "21  Relazioni tra variabili",
    "section": "\n21.5 Correlazione di Spearman",
    "text": "21.5 Correlazione di Spearman\nUn’alternativa per valutare la relazione lineare tra due variabili è il coefficiente di correlazione di Spearman, che si basa esclusivamente sull’ordine dei dati e non sugli specifici valori. Questo indice di associazione è particolarmente adatto quando gli psicologi sono in grado di misurare solo le relazioni di ordine tra diverse modalità di risposta dei soggetti, ma non l’intensità della risposta stessa. Tali variabili psicologiche che presentano questa caratteristica sono definite come “ordinali”.\n\n\n\n\n\n\nÈ importante ricordare che, nel caso di una variabile ordinale, non è possibile utilizzare le statistiche descrittive convenzionali come la media e la varianza per sintetizzare le osservazioni. Tuttavia, è possibile riassumere le osservazioni attraverso una distribuzione di frequenze delle diverse modalità di risposta. Come abbiamo appena visto, la direzione e l’intensità dell’associazione tra due variabili ordinali possono essere descritte utilizzando il coefficiente di correlazione di Spearman.\n\n\n\nPer fornire un esempio, consideriamo due variabili di scala ordinale e calcoliamo la correlazione di Spearman tra di esse.\n\ncor.test(c(1, 2, 3, 4, 5), c(5, 6, 7, 8, 7), method = \"spearman\")\n#&gt; \n#&gt;  Spearman's rank correlation rho\n#&gt; \n#&gt; data:  c(1, 2, 3, 4, 5) and c(5, 6, 7, 8, 7)\n#&gt; S = 3.6, p-value = 0.09\n#&gt; alternative hypothesis: true rho is not equal to 0\n#&gt; sample estimates:\n#&gt;    rho \n#&gt; 0.8208",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#oltre-la-correlazione-e-la-covarianza-quando-lassociazione-tra-variabili-è-più-complessa",
    "href": "chapters/eda/08_correlation.html#oltre-la-correlazione-e-la-covarianza-quando-lassociazione-tra-variabili-è-più-complessa",
    "title": "21  Relazioni tra variabili",
    "section": "\n21.6 Oltre la correlazione e la covarianza: quando l’associazione tra variabili è più complessa",
    "text": "21.6 Oltre la correlazione e la covarianza: quando l’associazione tra variabili è più complessa\nIn questo capitolo abbiamo introdotto due misure fondamentali per descrivere la relazione tra due variabili: covarianza e correlazione. La covarianza fornisce un’indicazione del modo in cui due variabili si discostano congiuntamente dalle proprie medie, mentre la correlazione ne standardizza i valori, permettendo un confronto più immediato tra diverse coppie di variabili e garantendo un indice compreso tra -1 e +1. Una correlazione vicina a +1 indica una forte relazione lineare positiva, vicina a -1 una forte relazione lineare negativa, mentre un valore vicino a 0 segnala l’assenza di una chiara relazione lineare.\nTuttavia, è cruciale comprendere che la correlazione descrive esclusivamente la dimensione lineare della relazione tra due variabili. Questo significa che una correlazione nulla (pari a zero) non implica affatto che non vi sia alcuna relazione tra le variabili, ma semplicemente che non esiste una relazione lineare. Possono esistere relazioni non lineari anche molto forti, non catturate da questo indice. Inoltre, altre situazioni possono trarre in inganno, come nei casi in cui i dati siano raggruppati in sottogruppi con proprietà differenti o siano frutto di particolari processi di selezione.\n\n21.6.1 Correlazione nulla e relazioni non lineari\nUna correlazione pari a zero può nascondere relazioni non lineari anche molto marcate. Per esempio, se una variabile Y aumenta solo quando X è molto alta o molto bassa, ma rimane costante per valori intermedi di X, questa curva a “U” può generare una correlazione vicina allo zero, pur esistendo un forte legame non lineare.\nUn esempio illustrativo è fornito dal cosiddetto Datasaurus Dozen, un insieme di tredici dataset con la stessa media, deviazione standard e correlazione tra le variabili, ma con distribuzioni visivamente e strutturalmente molto diverse. In ognuno di questi dataset la correlazione di Pearson è pari a zero, ma l’ispezione grafica rivela pattern e forme ben definite. Questo ci ricorda che è sempre bene accompagnare le misure numeriche con una visualizzazione grafica dei dati.\n\ndatasaurus_data &lt;- read.csv(\"../../data/datasaurus.csv\")\n\ndatasaurus_summary &lt;- datasaurus_data %&gt;%\n  group_by(dataset) %&gt;%\n  summarise(\n    x_count = n(),\n    x_mean = mean(x, na.rm = TRUE),\n    x_std = sd(x, na.rm = TRUE),\n    y_count = n(),\n    y_mean = mean(y, na.rm = TRUE),\n    y_std = sd(y, na.rm = TRUE)\n  )\n\ndatasaurus_summary\n#&gt; # A tibble: 13 × 7\n#&gt;    dataset    x_count x_mean x_std y_count y_mean y_std\n#&gt;    &lt;chr&gt;        &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt;\n#&gt;  1 away           142   54.3  16.8     142   47.8  26.9\n#&gt;  2 bullseye       142   54.3  16.8     142   47.8  26.9\n#&gt;  3 circle         142   54.3  16.8     142   47.8  26.9\n#&gt;  4 dino           142   54.3  16.8     142   47.8  26.9\n#&gt;  5 dots           142   54.3  16.8     142   47.8  26.9\n#&gt;  6 h_lines        142   54.3  16.8     142   47.8  26.9\n#&gt;  7 high_lines     142   54.3  16.8     142   47.8  26.9\n#&gt;  8 slant_down     142   54.3  16.8     142   47.8  26.9\n#&gt;  9 slant_up       142   54.3  16.8     142   47.8  26.9\n#&gt; 10 star           142   54.3  16.8     142   47.8  26.9\n#&gt; 11 v_lines        142   54.3  16.8     142   47.8  26.9\n#&gt; 12 wide_lines     142   54.3  16.8     142   47.8  26.9\n#&gt; 13 x_shape        142   54.3  16.8     142   47.8  26.9\n\n\ndatasaurus_data |&gt;\n  ggplot(aes(x = x, y = y)) +\n  geom_point(alpha = 0.7) +\n  facet_wrap(~dataset, nrow = 4, ncol = 4) +\n  labs(x = NULL, y = NULL)\n\n\n\n\n\n\n\nTutti questi esempi rafforzano l’idea che l’assenza di correlazione lineare non significa assenza di relazione: potremmo avere strutture curve, pattern complessi o punti anomali (outlier) capaci di modificare radicalmente la forma della relazione tra le variabili.\nOltre alle relazioni non lineari, esistono situazioni in cui la correlazione, da sola, può fornire un’immagine distorta dei dati. Tra queste ricordiamo due fenomeni noti come il paradosso di Simpson e il paradosso di Berkson.\n\n21.6.2 Paradosso di Simpson\nIl paradosso di Simpson si verifica quando, guardando i dati raggruppati per sottogruppi, si osserva una certa relazione tra due variabili, ma aggregando i dati di tutti i sottogruppi insieme emerge una relazione opposta. In altre parole, la tendenza che appare quando si considerano i dati divisi per gruppi scompare o si inverte quando si esamina l’intero campione senza tenere conto della suddivisione in sottogruppi.\nImmaginiamo di avere due dipartimenti universitari, A e B. All’interno di ciascun dipartimento, la relazione tra il voto di laurea (X) e la performance in un successivo programma di specializzazione (Y) è positiva: all’aumentare del voto di laurea aumenta, in media, la performance nella scuola di specializzazione.\nTuttavia, supponiamo che il Dipartimento A abbia in generale voti di laurea mediamente più bassi, ma ottime performance nella specializzazione; mentre il Dipartimento B abbia voti di laurea mediamente più alti, ma performance alla specializzazione un po’ più basse. Se uniamo tutti gli studenti dei due dipartimenti senza considerarne l’appartenenza, potremmo osservare una relazione negativa tra voto di laurea e performance, sovvertendo le conclusioni tratte guardando ai singoli sottogruppi.\nEcco come possiamo simulare questi dati in R:\n\nset.seed(123)\n\n# Numero di osservazioni per dipartimento\nn &lt;- 100\n\n# Dipartimento A:\n# Voti di laurea (X) più bassi, ma performance (Y) più alta.\n# Creiamo un legame positivo tra X e Y all'interno di A.\nX_A &lt;- rnorm(n, mean = 50, sd = 5)    # Voti laurea mediamente più bassi\nY_A &lt;- X_A + rnorm(n, mean = 20, sd = 5) # Performance alta e correlata positivamente con X\n\n# Dipartimento B:\n# Voti di laurea (X) più alti, ma performance (Y) più bassa.\n# Anche qui creiamo un legame positivo tra X e Y all'interno di B, \n# ma con un offset tale che globalmente i voti alti coincidano con performance minori.\nX_B &lt;- rnorm(n, mean = 60, sd = 5)    # Voti laurea mediamente più alti\nY_B &lt;- X_B - rnorm(n, mean = 10, sd = 5) # Performance più bassa ma comunque correlata positivamente con X all’interno di B\n\n# Creiamo un dataframe con tutti i dati\ndipartimento &lt;- c(rep(\"A\", n), rep(\"B\", n))\nX &lt;- c(X_A, X_B)\nY &lt;- c(Y_A, Y_B)\ndati &lt;- data.frame(dipartimento, X, Y)\n\n# Correlazioni all'interno dei dipartimenti\ncat(\"Correlazione nel Dipartimento A:\", cor(X_A, Y_A), \"\\n\")\n#&gt; Correlazione nel Dipartimento A: 0.6671\ncat(\"Correlazione nel Dipartimento B:\", cor(X_B, Y_B), \"\\n\")\n#&gt; Correlazione nel Dipartimento B: 0.6926\n\n# Correlazione sull'intero dataset (senza distinguere i dipartimenti)\ncat(\"Correlazione globale:\", cor(X, Y), \"\\n\")\n#&gt; Correlazione globale: -0.3353\n\n\n# Visualizziamo i dati\nggplot(dati, aes(x = X, y = Y, color = dipartimento)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(\n    title = \"Paradosso di Simpson\",\n    x = \"Voto di laurea\", \n    y = \"Performance nella specializzazione\",\n    color = \"Dipartimento\"\n  )\n\n\n\n\n\n\n\n\nAll’interno del Dipartimento A: la correlazione tra voto di laurea (X) e performance (Y) è positiva. Ciò significa che, per gli studenti di A, avere un voto di laurea più alto è associato a una performance maggiore nella specializzazione.\nAll’interno del Dipartimento B: la correlazione tra X e Y è anch’essa positiva, indicando che anche nel secondo dipartimento voti più alti tendono ad accompagnarsi a performance più alte.\nConsiderando entrambi i dipartimenti insieme: a causa delle differenze nei livelli medi di X e Y tra i dipartimenti, unendo i dati senza distinguere il gruppo di appartenenza otteniamo una correlazione globale negativa. Questo significa che, ignorando la suddivisione in dipartimenti, sembra che aumentare il voto di laurea sia associato a una diminuzione della performance nella specializzazione — una conclusione opposta a quella tratta dall’analisi separata dei due sottogruppi.\n\nQuesto è un esempio concreto del paradosso di Simpson: la relazione osservata in sottogruppi omogenei si inverte quando si aggregano i dati, mettendo in guardia sulla necessità di considerare con attenzione la struttura dei dati e i fattori confondenti prima di trarre conclusioni.\n\n21.6.3 Paradosso di Berkson\nIl paradosso di Berkson è un fenomeno legato alla selezione del campione. Se il dataset non è rappresentativo della popolazione generale, la relazione osservata può risultare artificiale o opposta a quella esistente su un campione più ampio. Per esempio, analizzando solo ciclisti professionisti, potremmo non vedere alcuna relazione tra VO2 max e probabilità di vincere una gara, poiché tutti hanno già superato una certa soglia di VO2 max. Considerando la popolazione generale, invece, potrebbe emergere chiaramente una relazione positiva tra questi due fattori. Questo paradosso evidenzia l’importanza di considerare il processo di selezione dei dati e di chiedersi se il campione analizzato sia adeguato a rispondere alla domanda di ricerca.\n\n21.6.4 Limiti delle statistiche riassuntive semplici\nUn esempio famoso che dimostra i limiti delle semplici statistiche descrittive — come media, deviazione standard e correlazione — è il quartetto di Anscombe. Questo insieme di quattro piccoli dataset possiede identiche medie, varianze e correlazioni tra variabili, ma rappresenta relazioni estremamente differenti tra X e Y (Anscombe, 1973).\nImportiamo il dataset anscombe già disponibile nel pacchetto datasets di R:\n\ndata(\"anscombe\")\n\nanscombe |&gt; \n  head()\n#&gt;   x1 x2 x3 x4   y1   y2    y3   y4\n#&gt; 1 10 10 10  8 8.04 9.14  7.46 6.58\n#&gt; 2  8  8  8  8 6.95 8.14  6.77 5.76\n#&gt; 3 13 13 13  8 7.58 8.74 12.74 7.71\n#&gt; 4  9  9  9  8 8.81 8.77  7.11 8.84\n#&gt; 5 11 11 11  8 8.33 9.26  7.81 8.47\n#&gt; 6 14 14 14  8 9.96 8.10  8.84 7.04\n\nIl dataset anscombe contiene quattro serie di dati (x1, y1), (x2, y2), (x3, y3) e (x4, y4), ognuna costituita da 11 coppie di valori (x, y). Per comprendere meglio le loro caratteristiche, iniziamo calcolando alcune statistiche descrittive. La funzione apply() consente di applicare una funzione (ad esempio, mean) a tutte le colonne di un data frame. Usandola sulle colonne di anscombe, otteniamo le medie di ciascuna delle otto variabili (le quattro x e le quattro y):\n\napply(anscombe, MARGIN = 2, mean)\n#&gt;    x1    x2    x3    x4    y1    y2    y3    y4 \n#&gt; 9.000 9.000 9.000 9.000 7.501 7.501 7.500 7.501\n\nOsserviamo che le medie delle quattro variabili x sono identiche fino a sei cifre decimali, e le medie delle quattro variabili y differiscono solo in modo trascurabile (circa lo 0.01%). Analogamente, se calcoliamo le deviazioni standard per ciascuna variabile, notiamo una notevole somiglianza:\n\napply(anscombe, MARGIN = 2, sd)\n#&gt;    x1    x2    x3    x4    y1    y2    y3    y4 \n#&gt; 3.317 3.317 3.317 3.317 2.032 2.032 2.030 2.031\n\nAnche in questo caso, le deviazioni standard per le x coincidono fino alla sesta cifra decimale, mentre quelle delle y differiscono di meno dello 0.06%. Inoltre, se calcoliamo i coefficienti di correlazione tra x e y in ognuno dei quattro dataset, scopriamo che sono quasi identici:\n\n# Calcoliamo la correlazione per ciascuna coppia (x1,y1), (x2,y2), (x3,y3), (x4,y4)\nfor (i in 1:4) {\n  x_var &lt;- anscombe[[paste0(\"x\", i)]]\n  y_var &lt;- anscombe[[paste0(\"y\", i)]]\n  \n  corr_value &lt;- cor(x_var, y_var)\n  cat(\"Correlazione tra x\", i, \"e y\", i, \":\", corr_value, \"\\n\")\n}\n#&gt; Correlazione tra x 1 e y 1 : 0.8164 \n#&gt; Correlazione tra x 2 e y 2 : 0.8162 \n#&gt; Correlazione tra x 3 e y 3 : 0.8163 \n#&gt; Correlazione tra x 4 e y 4 : 0.8165\n\nSe ci limitassimo a guardare queste statistiche (media, deviazione standard, correlazione), potremmo facilmente essere indotti a concludere che i quattro dataset sono tra loro sostanzialmente indistinguibili. Tuttavia, la realtà è molto diversa. Le statistiche descrittive, prese da sole, non offrono una visione completa e possono nascondere importanti differenze nella struttura dei dati.\nQuesta differenza diventa evidente non appena decidiamo di visualizzare i dati. La rappresentazione grafica fornisce informazioni che non emergono dalle sole statistiche riassuntive:\n\nanscombe_m &lt;- tibble()\n\nfor (i in 1:4) {\n  anscombe_m &lt;- rbind(\n    anscombe_m, tibble(set = i, x = anscombe[, i], y = anscombe[, i + 4])\n  )\n}\n\nggplot(anscombe_m, aes(x, y)) +\n  geom_point(size = 3, color = \"red\", fill = \"orange\", shape = 21) +\n  geom_smooth(method = \"lm\", fill = NA, fullrange = TRUE) +\n  facet_wrap(~set, ncol = 2)\n\n\n\n\n\n\n\nOsservando i grafici, notiamo subito che i quattro dataset sono profondamente diversi:\n\n\nDataset 1: Qui la relazione tra x e y è approssimativamente lineare, e la correlazione riflette in modo appropriato il legame tra le due variabili.\n\nDataset 2: Sebbene la correlazione sia simile a quella del Dataset 1, i dati mostrano una relazione curvilinea e non lineare. La semplice correlazione lineare non ne cattura la forma.\n\nDataset 3: La presenza di un singolo outlier distorce la percezione della relazione tra le variabili, altrimenti lineare. La correlazione alta è influenzata in modo sproporzionato da questo punto anomalo.\n\nDataset 4: Qui i dati non mostrano alcuna relazione lineare. La correlazione elevata è il frutto di un pattern fortemente atipico (ad esempio, una sola coppia di punti allineata).\n\nIl quartetto di Anscombe mette in luce un principio fondamentale: statistiche descrittive come media, deviazione standard e correlazione non sono sempre sufficienti per comprendere la natura dei dati. La visualizzazione grafica è essenziale per cogliere relazioni, pattern non lineari, outlier e altre caratteristiche che le semplici statistiche non riescono a rivelare. In definitiva, questo esempio dimostra che analizzare i dati soltanto attraverso poche statistiche di sintesi può portare a conclusioni fuorvianti, mentre l’integrazione con la rappresentazione grafica fornisce una visione più completa e accurata.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#riflessioni-conclusive",
    "href": "chapters/eda/08_correlation.html#riflessioni-conclusive",
    "title": "21  Relazioni tra variabili",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nLa covarianza e la correlazione sono strumenti preziosi per capire l’intensità e la direzione lineare di una relazione tra due variabili. Tuttavia, non dobbiamo confondere la loro semplicità con completezza d’informazione. Una correlazione nulla non implica assenza di relazione, ma solo assenza di una relazione lineare. Inoltre, il paradosso di Simpson e il paradosso di Berkson dimostrano che la semplice osservazione di correlazioni può essere fuorviante se non si tiene conto della struttura dei dati o del processo di selezione del campione.\nInfine, esempi come il quartetto di Anscombe sottolineano quanto sia fondamentale accompagnare le statistiche riassuntive con analisi grafiche e un’attenzione costante ai possibili pattern non lineari, agli outlier e alle caratteristiche peculiari del dataset. Nel prossimo capitolo esamineremo approcci che consentono di avvicinarsi alla comprensione causale dei fenomeni, andando oltre la semplice osservazione dell’associazione tra variabili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#esercizi",
    "href": "chapters/eda/08_correlation.html#esercizi",
    "title": "21  Relazioni tra variabili",
    "section": "\n21.7 Esercizi",
    "text": "21.7 Esercizi\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nEsercizi Teorici\n\n\nDefinizioni fondamentali\n\nQual è la differenza tra associazione, correlazione e dipendenza?\n\nPerché la correlazione non implica causalità? Fai un esempio.\n\nIn quali situazioni la correlazione di Spearman è preferibile rispetto alla correlazione di Pearson?\n\n\n\nInterpretazione della correlazione\n\nQual è il range dei valori che può assumere la correlazione di Pearson?\n\nSe il coefficiente di correlazione tra due variabili è 0.85, come interpreteresti la loro relazione?\n\nSe il coefficiente di correlazione è -0.60, che tipo di relazione esiste tra le due variabili?\n\nQuali fattori potrebbero influenzare il valore della correlazione?\n\n\n\nCovarianza vs Correlazione\n\nQual è la differenza tra covarianza e correlazione?\n\nPerché la covarianza non è sempre interpretabile come misura della forza della relazione tra due variabili?\n\nQuali sono i vantaggi di usare la correlazione al posto della covarianza?\n\n\n\nGrafico a dispersione e correlazione\n\nOsservando un grafico a dispersione, quali caratteristiche ti permettono di identificare una relazione lineare positiva o negativa?\n\nDisegna (o descrivi verbalmente) un esempio di un dataset con una correlazione di circa 0, ma con una chiara relazione non lineare tra le variabili.\n\n\n\nEsercizi Pratici in R\n📌 Obiettivo: Analizzare le relazioni tra Satisfaction With Life Scale (SWLS) e Scala della Rete Sociale di Lubben (LSNS-6), calcolare covarianza e correlazione, e visualizzare i dati per individuare pattern.\nDati disponibili:\nUsa i dati raccolti per le variabili SWLS e LSNS, oltre al genere dei partecipanti.\n1. Esplorazione e Visualizzazione della Relazione tra SWLS e LSNS\n\n\nCarica i dati raccolti dagli studenti e verifica la struttura del dataset.\n\n\nCalcola le statistiche descrittive: media, deviazione standard, minimo, massimo e quartili delle variabili SWLS e LSNS.\n\n\nCrea un grafico a dispersione tra SWLS e LSNS:\n\nColora i punti in base al genere del partecipante.\n\nAggiungi una linea di regressione per evidenziare il trend della relazione.\n\n\n\n2. Calcolo della Covarianza e della Correlazione tra SWLS e LSNS\n\n\nCalcola la covarianza tra SWLS e LSNS usando la formula matematica della covarianza e confrontala con il valore ottenuto con cov().\n\n\nCalcola la correlazione di Pearson e commenta il risultato:\n\nLa relazione è forte o debole?\n\nHa segno positivo o negativo?\n\nÈ coerente con quanto osservato nel grafico a dispersione?\n\n\n\n\nCalcola la correlazione di Spearman e confrontala con quella di Pearson. Quale delle due è più appropriata per questi dati?\n\n3. Analisi delle Associazioni per Gruppi\n\n\nCalcola la correlazione separatamente per i partecipanti di genere maschile e femminile.\n\n\nConfronta i risultati: la relazione tra SWLS e LSNS è simile nei due gruppi o ci sono differenze?\n\n\nVisualizza i dati con due grafici a dispersione distinti per maschi e femmine.\n\n4. Correlazione Nulla e Pattern Non Lineari\n\n\nSimula un dataset in cui la correlazione di Pearson è vicina a 0, ma esiste una chiara relazione non lineare tra le variabili.\n\n\nCostruisci un grafico a dispersione per osservare il pattern nei dati.\n\n\nCalcola la correlazione di Spearman e confrontala con quella di Pearson. Quale delle due cattura meglio la relazione nei dati?\n\nConsegna il file .qmd compilato in PDF contenente il codice, le visualizzazioni e le interpretazioni.\n\n\n\n\n\n\n\n\n\nSoluzione\n\n\n\n\n\n1. Definizioni fondamentali\n1.1 Differenza tra associazione, correlazione e dipendenza:\n\n\nAssociazione: Indica una relazione generica tra due variabili, senza specificare la natura o la direzione della relazione.\n\nCorrelazione: Misura la forza e la direzione di una relazione lineare tra due variabili. Può essere positiva (variabili aumentano insieme) o negativa (una variabile aumenta mentre l’altra diminuisce).\n\nDipendenza: Indica che una variabile è influenzata da un’altra, ma non implica necessariamente una relazione lineare. La dipendenza può essere causale o statistica.\n\n1.2 Perché la correlazione non implica causalità:\nLa correlazione misura solo la relazione lineare tra due variabili, ma non indica se una variabile causa l’altra. Un esempio classico è la correlazione tra il consumo di gelati e il numero di annegamenti: entrambi aumentano in estate, ma non c’è un nesso causale diretto. Un terzo fattore (il caldo) influenza entrambe le variabili.\n1.3 Quando preferire la correlazione di Spearman rispetto a quella di Pearson:\n\nQuando i dati non sono distribuiti normalmente.\nQuando ci sono outlier che potrebbero distorcere la correlazione di Pearson.\nQuando la relazione tra le variabili è monotona (sempre crescente o decrescente) ma non lineare.\n\n2. Interpretazione della correlazione\n2.1 Range dei valori della correlazione di Pearson:\nLa correlazione di Pearson assume valori compresi tra -1 e 1: - 1: Correlazione lineare positiva perfetta. - -1: Correlazione lineare negativa perfetta. - 0: Nessuna correlazione lineare.\n2.2 Interpretazione di un coefficiente di 0.85:\nUn coefficiente di 0.85 indica una forte relazione lineare positiva tra le due variabili. All’aumentare di una variabile, l’altra tende ad aumentare in modo consistente.\n2.3 Interpretazione di un coefficiente di -0.60:\nUn coefficiente di -0.60 indica una relazione lineare negativa moderata. All’aumentare di una variabile, l’altra tende a diminuire.\n2.4 Fattori che influenzano la correlazione:\n\n\nOutlier: Possono distorcere il valore della correlazione.\n\nDistribuzione non lineare: La correlazione di Pearson non cattura relazioni non lineari.\n\nRange ristretto delle variabili: Se i dati coprono solo una piccola parte del range possibile, la correlazione potrebbe essere sottostimata.\n\n3. Covarianza vs Correlazione\n3.1 Differenza tra covarianza e correlazione:\n\n\nCovarianza: Misura la direzione della relazione tra due variabili, ma il suo valore dipende dalle unità di misura delle variabili.\n\nCorrelazione: Standardizza la covarianza, rendendola adimensionale e consentendo confronti tra diverse coppie di variabili.\n\n3.2 Perché la covarianza non è sempre interpretabile:\nLa covarianza non è standardizzata, quindi il suo valore non fornisce informazioni sulla forza della relazione. Ad esempio, una covarianza di 1000 potrebbe indicare una relazione forte o debole, a seconda delle unità di misura.\n3.3 Vantaggi della correlazione rispetto alla covarianza:\n\nÈ adimensionale, quindi può essere confrontata tra diverse coppie di variabili.\nAssume valori compresi tra -1 e 1, facilitando l’interpretazione della forza e della direzione della relazione.\n\n4. Grafico a dispersione e correlazione\n4.1 Caratteristiche di un grafico a dispersione per identificare relazioni lineari:\n\n\nRelazione lineare positiva: I punti si dispongono lungo una linea retta con pendenza positiva.\n\nRelazione lineare negativa: I punti si dispongono lungo una linea retta con pendenza negativa.\n\nNessuna relazione lineare: I punti sono sparsi senza un pattern evidente.\n\n4.2 Esempio di dataset con correlazione circa 0 ma relazione non lineare:\nImmagina un dataset in cui una variabile \\(x\\) assume valori simmetrici intorno a 0 (ad esempio, da -5 a 5), e la variabile \\(y\\) è uguale a \\(x^2\\). In questo caso:\n\nLa correlazione di Pearson sarà circa 0, perché non c’è una relazione lineare.\nTuttavia, esiste una chiara relazione non lineare (quadratica) tra \\(x\\) e \\(y\\).\n\nDescrizione verbale:\nI punti formano una parabola, con \\(y\\) che aumenta sia quando \\(x\\) è positivo che negativo. La correlazione di Pearson non cattura questa relazione, mentre la correlazione di Spearman potrebbe farlo.\n1. Esplorazione e Visualizzazione della Relazione tra SWLS e LSNS\n1.1 Carica i dati raccolti dagli studenti e verifica la struttura del dataset Simuliamo un dataset con 100 partecipanti, includendo le variabili SWLS (Soddisfazione di Vita), LSNS (Rete Sociale), e Genere.\n# Simulazione dei dati\nset.seed(123)\nn &lt;- 100\ngenere &lt;- sample(c(\"Maschio\", \"Femmina\"), n, replace = TRUE)\nswls &lt;- round(rnorm(n, mean = 20, sd = 5), 1)  # SWLS: Scala 5-35\nlsns &lt;- round(rnorm(n, mean = 12, sd = 4), 1)   # LSNS: Scala 0-30\n\n# Creazione del dataset\ndati &lt;- data.frame(Genere = genere, SWLS = swls, LSNS = lsns)\n\n# Verifica della struttura\nstr(dati)\nhead(dati)\n1.2 Calcola le statistiche descrittive\n# Statistiche descrittive per SWLS e LSNS\nsummary(dati$SWLS)\nsummary(dati$LSNS)\n\n# Media e deviazione standard\nmean(dati$SWLS)\nsd(dati$SWLS)\nmean(dati$LSNS)\nsd(dati$LSNS)\n1.3 Crea un grafico a dispersione\nlibrary(ggplot2)\n\nggplot(dati, aes(x = SWLS, y = LSNS, color = Genere)) +\n  geom_point(size = 3) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"black\") +\n  labs(title = \"Relazione tra SWLS e LSNS\",\n       x = \"Soddisfazione di Vita (SWLS)\",\n       y = \"Rete Sociale (LSNS)\") +\n  theme_minimal()\n2. Calcolo della Covarianza e della Correlazione tra SWLS e LSNS\n2.1 Calcola la covarianza\n# Covarianza manuale\ncov_manual &lt;- sum((dati$SWLS - mean(dati$SWLS)) * (dati$LSNS - mean(dati$LSNS))) / (n - 1)\ncov_manual\n\n# Covarianza con funzione R\ncov(dati$SWLS, dati$LSNS)\n2.2 Calcola la correlazione di Pearson\ncor_pearson &lt;- cor(dati$SWLS, dati$LSNS, method = \"pearson\")\ncor_pearson\n\n\nCommento: La correlazione è [valore], indicando una relazione [forte/debole] e [positiva/negativa]. Questo è coerente con il grafico a dispersione.\n\n2.3 Calcola la correlazione di Spearman\ncor_spearman &lt;- cor(dati$SWLS, dati$LSNS, method = \"spearman\")\ncor_spearman\n\n\nConfronto: La correlazione di Spearman è più appropriata se i dati non sono distribuiti normalmente o presentano outlier.\n\n3. Analisi delle Associazioni per Gruppi\n3.1 Calcola la correlazione separatamente per genere\n# Maschi\ncor_maschi &lt;- cor(dati$SWLS[dati$Genere == \"Maschio\"], dati$LSNS[dati$Genere == \"Maschio\"], method = \"pearson\")\n\n# Femmine\ncor_femmine &lt;- cor(dati$SWLS[dati$Genere == \"Femmina\"], dati$LSNS[dati$Genere == \"Femmina\"], method = \"pearson\")\n\ncor_maschi\ncor_femmine\n3.2 Confronta i risultati\n\n\nCommento: La correlazione è [simile/diversa] tra maschi e femmine, suggerendo [presenza/assenza] di differenze di genere.\n\n3.3 Visualizza i dati con grafici distinti\nggplot(dati, aes(x = SWLS, y = LSNS, color = Genere)) +\n  geom_point(size = 3) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  facet_wrap(~ Genere) +\n  labs(title = \"Relazione tra SWLS e LSNS per Genere\",\n       x = \"Soddisfazione di Vita (SWLS)\",\n       y = \"Rete Sociale (LSNS)\") +\n  theme_minimal()\n4. Correlazione Nulla e Pattern Non Lineari\n4.1 Simula un dataset con correlazione nulla ma relazione non lineare\nset.seed(123)\nx &lt;- rnorm(100, mean = 0, sd = 1)\ny &lt;- x^2 + rnorm(100, mean = 0, sd = 0.5)  # Relazione quadratica\ndati_non_lineari &lt;- data.frame(x = x, y = y)\n\n# Correlazione di Pearson\ncor_pearson_non_lineare &lt;- cor(dati_non_lineari$x, dati_non_lineari$y, method = \"pearson\")\ncor_pearson_non_lineare  # Dovrebbe essere vicina a 0\n4.2 Costruisci un grafico a dispersione\nggplot(dati_non_lineari, aes(x = x, y = y)) +\n  geom_point(size = 3) +\n  labs(title = \"Relazione Non Lineare con Correlazione Nulla\",\n       x = \"Variabile X\",\n       y = \"Variabile Y\") +\n  theme_minimal()\n4.3 Calcola la correlazione di Spearman\ncor_spearman_non_lineare &lt;- cor(dati_non_lineari$x, dati_non_lineari$y, method = \"spearman\")\ncor_spearman_non_lineare  # Dovrebbe catturare la relazione non lineare\n\n\nConfronto: La correlazione di Spearman è più adatta per catturare relazioni non lineari.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/08_correlation.html#informazioni-sullambiente-di-sviluppo",
    "title": "21  Relazioni tra variabili",
    "section": "Informazioni sull’ambiente di sviluppo",
    "text": "Informazioni sull’ambiente di sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] readr_2.1.5           pillar_1.11.0         tinytable_0.11.0     \n#&gt;  [4] patchwork_1.3.1       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt;  [7] bayesplot_1.13.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [10] priorsense_1.1.0      posterior_1.6.1       loo_2.8.0            \n#&gt; [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [16] Rcpp_1.1.0            conflicted_1.2.0      janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3        inline_0.3.21        sandwich_3.1-1      \n#&gt;  [4] rlang_1.1.6          magrittr_2.0.3       multcomp_1.4-28     \n#&gt;  [7] snakecase_0.11.1     compiler_4.5.1       mgcv_1.9-3          \n#&gt; [10] vctrs_0.6.5          stringr_1.5.1        pkgconfig_2.0.3     \n#&gt; [13] arrayhelpers_1.1-0   fastmap_1.2.0        backports_1.5.0     \n#&gt; [16] labeling_0.4.3       utf8_1.2.6           rmarkdown_2.29      \n#&gt; [19] tzdb_0.5.0           purrr_1.1.0          xfun_0.52           \n#&gt; [22] cachem_1.1.0         jsonlite_2.0.0       broom_1.0.9         \n#&gt; [25] parallel_4.5.1       R6_2.6.1             stringi_1.8.7       \n#&gt; [28] RColorBrewer_1.1-3   lubridate_1.9.4      estimability_1.5.1  \n#&gt; [31] knitr_1.50           zoo_1.8-14           pacman_0.5.1        \n#&gt; [34] R.utils_2.13.0       Matrix_1.7-3         splines_4.5.1       \n#&gt; [37] timechange_0.3.0     tidyselect_1.2.1     abind_1.4-8         \n#&gt; [40] codetools_0.2-20     curl_6.4.0           pkgbuild_1.4.8      \n#&gt; [43] lattice_0.22-7       withr_3.0.2          bridgesampling_1.1-2\n#&gt; [46] coda_0.19-4.1        evaluate_1.0.4       survival_3.8-3      \n#&gt; [49] RcppParallel_5.1.10  tensorA_0.36.2.1     checkmate_2.3.2     \n#&gt; [52] stats4_4.5.1         distributional_0.5.0 generics_0.1.4      \n#&gt; [55] rprojroot_2.1.0      hms_1.1.3            rstantools_2.4.0    \n#&gt; [58] scales_1.4.0         xtable_1.8-4         glue_1.8.0          \n#&gt; [61] emmeans_1.11.2       tools_4.5.1          data.table_1.17.8   \n#&gt; [64] mvtnorm_1.3-3        grid_4.5.1           QuickJSR_1.8.0      \n#&gt; [67] colorspace_2.1-1     nlme_3.1-168         cli_3.6.5           \n#&gt; [70] svUnit_1.0.6         Brobdingnag_1.2-9    V8_6.0.5            \n#&gt; [73] gtable_0.3.6         R.methodsS3_1.8.2    digest_0.6.37       \n#&gt; [76] TH.data_1.1-3        htmlwidgets_1.6.4    farver_2.1.2        \n#&gt; [79] memoise_2.0.1        htmltools_0.5.8.1    R.oo_1.27.1         \n#&gt; [82] lifecycle_1.0.4      MASS_7.3-65",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#bibliografia",
    "href": "chapters/eda/08_correlation.html#bibliografia",
    "title": "21  Relazioni tra variabili",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAnscombe, F. J. (1973). Graphs in statistical analysis. The American Statistician, 27(1), 17–21.\n\n\nHamaker, E. (2024). The curious case of the cross-sectional correlation. Multivariate Behavioral Research, 59(6), 1111–1122.\n\n\nZetsche, U., Buerkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: biased or realistic? Journal of Abnormal Psychology, 128(7), 678–688.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html",
    "href": "chapters/eda/09_causality.html",
    "title": "22  Causalità dai dati osservazionali",
    "section": "",
    "text": "Introduzione\nLa pura osservazione dei dati può rivelare correlazioni e pattern nei dati, ma senza un’indagine sulle cause che stanno alla base di tali correlazioni, le conclusioni tratte possono essere fuorvianti o incomplete.\nRichard McElreath, nel suo libro “Statistical Rethinking” (McElreath, 2020), utilizza l’analogia dei Golem - creature potenti ma prive di saggezza - per descrivere un approccio metodologico che è stato a lungo predominante in psicologia. Questo approccio si basa esclusivamente sull’analisi delle associazioni statistiche tra variabili, trascurando considerazioni più profonde sulla causalità.\nIl metodo in questione si concentra principalmente sul test delle ipotesi nulle, senza stabilire una chiara connessione tra le domande di ricerca riguardanti le relazioni causali e i test statistici impiegati. Questa disconnessione è evidente nella figura successiva, tratta da un manuale di analisi dati di impostazione frequentista, che illustra la procedura raccomandata dai sostenitori di questo approccio per descrivere le associazioni tra variabili.\nÈ importante notare come tale procedura non fornisca strumenti utili per identificare le effettive cause sottostanti ai fenomeni osservati. Questa limitazione metodologica è stata identificata come uno dei fattori principali che hanno contribuito alla crisi di replicabilità nella ricerca psicologica, come approfondito nel Capitolo 91. L’approccio descritto sopra, pur essendo potente nell’individuare correlazioni, manca della “saggezza” necessaria per distinguere tra semplici associazioni e vere relazioni causali, analogamente ai Golem della metafora di McElreath.\nUn problema evidenziato da McElreath (2020) è che processi causali completamente distinti possono generare la stessa distribuzione di risultati osservati. Pertanto, un approccio focalizzato esclusivamente sull’analisi delle associazioni mediante il test dell’ipotesi nulla non è in grado di distinguere tra questi diversi scenari.\nL’approccio frequentista, che si limita a descrivere le associazioni tra le variabili, ha una scarsa capacità di rilevare le caratteristiche cruciali dei fenomeni studiati e tende a produrre un alto tasso di falsi positivi (Zwet et al., 2023). È invece necessario utilizzare una metodologia che non si limiti a confutare ipotesi nulle, ma sia in grado di sviluppare modelli causali che rispondano direttamente alle domande di ricerca. In questo capitolo, ci concentreremo sull’introduzione dei concetti fondamentali dell’analisi causale.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#introduzione",
    "href": "chapters/eda/09_causality.html#introduzione",
    "title": "22  Causalità dai dati osservazionali",
    "section": "",
    "text": "Esempio di albero decisionale per la selezione di una procedura statistica appropriata. Iniziando dall’alto, l’utente risponde a una serie di domande riguardanti la misurazione e l’intento, arrivando infine al nome di una procedura. Sono possibili molti alberi decisionali simili. (Figura tratta da McElreath (2020)).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#cosè-la-causalità",
    "href": "chapters/eda/09_causality.html#cosè-la-causalità",
    "title": "22  Causalità dai dati osservazionali",
    "section": "22.1 Cos’è la causalità?",
    "text": "22.1 Cos’è la causalità?\nHardt & Recht (2022) introducono il concetto di causalità distinguendo tra osservazione e azione. Ciò che vediamo nell’osservazione passiva è il modo in cui le persone seguono i loro comportamenti abituali, le loro inclinazioni naturali, proiettando lo stato del mondo su un insieme di caratteristiche che abbiamo scelto di evidenziare. Tuttavia, le domande più importanti spesso non riguardano semplici osservazioni.\n\nNon ci basta sapere che le persone che praticano regolarmente attività fisica soffrono meno d’ansia; vogliamo capire se l’attività fisica riduce effettivamente i livelli d’ansia.\nNon ci accontentiamo di osservare che chi segue una terapia cognitivo-comportamentale (CBT) presenta meno sintomi depressivi; desideriamo verificare se la CBT riduce realmente questi sintomi.\nNon ci limitiamo a constatare che l’uso frequente dei social media è associato a un calo del benessere mentale; vogliamo determinare se l’uso intensivo dei social media causa effettivamente una diminuzione del benessere mentale.\n\nAlla base, il ragionamento causale è un quadro concettuale per affrontare domande sugli effetti di azioni o interventi ipotetici. Una volta compreso quale sia l’effetto di un’azione, possiamo invertire la domanda e chiederci quale azione plausibile abbia causato un determinato evento.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#effetto-causale",
    "href": "chapters/eda/09_causality.html#effetto-causale",
    "title": "22  Causalità dai dati osservazionali",
    "section": "22.2 Effetto Causale",
    "text": "22.2 Effetto Causale\nLa causalità è un concetto fondamentale in molte discipline, ma non esiste una definizione univoca universalmente accettata. Tuttavia, possiamo adottare una definizione operativa utile per l’analisi empirica.\n\nDefinizione 22.1 Diciamo che \\(X\\) causa \\(Y\\) se, intervenendo e modificando il valore di \\(X\\) (il trattamento), la distribuzione di \\(Y\\) cambia di conseguenza.\n\nQuesta definizione enfatizza il ruolo centrale dell’intervento nel determinare una relazione causale. A differenza della correlazione, che si basa sull’osservazione passiva, la causalità implica un’azione attiva che modifica il sistema in esame.\n\n22.2.1 Effetto Medio del Trattamento\nSe \\(X\\) è una variabile binaria, rappresentante la presenza (\\(X=1\\)) o l’assenza (\\(X=0\\)) del trattamento, l’effetto dell’intervento è misurato tramite l’effetto medio del trattamento (Average Treatment Effect, ATE):\n\\[ ATE = \\mathbb{E}[Y \\mid X=1] - \\mathbb{E}[Y \\mid X=0] .\\]\nQuesto valore rappresenta quanto, in media, il trattamento modifica l’attesa di \\(Y\\). È essenziale notare che gli effetti causali sono definiti a livello di popolazione e possono variare tra individui o gruppi, dando origine a effetti di trattamento eterogenei.\n\n\n22.2.2 Esempio: Terapia Cognitivo-Comportamentale e Ansia\nConsideriamo un esempio concreto: supponiamo di voler studiare l’efficacia della terapia cognitivo-comportamentale (CBT) nella riduzione dell’ansia. Se un gruppo di persone ansiose non riceve alcun trattamento, il loro livello d’ansia rimarrà invariato in media. Se invece interveniamo introducendo la CBT (modificando \\(X\\) da 0 a 1), il livello medio d’ansia nel gruppo tenderà a diminuire (modificando così la distribuzione di \\(Y\\)).\nQuesto esempio chiarisce la distinzione tra correlazione e causalità:\n\nSe osserviamo che le persone che fanno CBT hanno meno ansia, potremmo erroneamente concludere che la CBT è efficace. Tuttavia, la riduzione dell’ansia potrebbe essere dovuta a fattori confondenti, come la maggiore motivazione delle persone che scelgono la terapia.\nSolo un intervento controllato (ad esempio, un esperimento randomizzato in cui è presente un gruppo di controllo) permette di stabilire con certezza l’effetto causale della CBT.\n\n\n\n22.2.3 Causalità Diretta e Indiretta\nIn alcuni casi, un effetto causale può non essere diretto, ma manifestarsi attraverso un meccanismo intermedio. Ad esempio, l’autoefficacia potrebbe non influenzare direttamente le prestazioni accademiche, ma se un intervento aumenta l’autoefficacia, potremmo osservare un miglioramento nell’impegno allo studio, che a sua volta porta a migliori prestazioni. In questo caso, possiamo dire che l’autoefficacia ha un effetto causale indiretto sulle prestazioni accademiche.\n\n\n22.2.4 Causalità Probabilistica\nÈ importante sottolineare che una relazione causale tra \\(X\\) e \\(Y\\) non implica necessariamente che ogni cambiamento in \\(X\\) porti a un cambiamento immediato o deterministico in \\(Y\\). In molti contesti, specialmente in psicologia, le relazioni causali sono probabilistiche: l’intervento su \\(X\\) altera la distribuzione di probabilità di \\(Y\\), senza garantire un esito certo per ogni individuo. Questo approccio probabilistico è cruciale per comprendere le dinamiche causali in sistemi complessi e multifattoriali.\nIn sintesi, l’analisi causale è uno strumento essenziale per la ricerca empirica, permettendo di andare oltre la semplice correlazione e comprendere i meccanismi che regolano i fenomeni osservati. La chiave per stabilire una relazione causale solida risiede nella progettazione di esperimenti o nell’uso di metodi statistici avanzati per identificare e correggere i possibili bias derivanti da fattori confondenti.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#i-limiti-dellosservazione",
    "href": "chapters/eda/09_causality.html#i-limiti-dellosservazione",
    "title": "22  Causalità dai dati osservazionali",
    "section": "22.3 I Limiti dell’Osservazione",
    "text": "22.3 I Limiti dell’Osservazione\nPer comprendere i limiti dell’osservazione passiva e la necessità di indagare le relazioni causali sottostanti, Hardt & Recht (2022) citano il celebre esempio delle ammissioni ai corsi di laurea dell’Università della California, Berkeley, nel 1973. In quell’anno, 12,763 candidati furono considerati per l’ammissione in uno dei 101 dipartimenti o major interdipartimentali. Di questi, 4,321 erano donne e 8,442 erano uomini. I dati aggregati mostrano che circa il 35% delle donne fu ammesso, rispetto al 44% degli uomini. Test statistici indicano che questa differenza non è attribuibile al caso, suggerendo una disparità nei tassi di ammissione tra i generi.\nUn’analisi simile si osserva considerando le decisioni aggregate di ammissione nei sei principali dipartimenti di UC Berkeley. Il tasso di ammissione complessivo per gli uomini era del 44%, mentre per le donne solo del 30%, una differenza statisticamente credibile.\nTuttavia, poiché ogni dipartimento ha autonomia nelle decisioni di ammissione, è utile esaminare il possibile bias di genere a livello di singolo dipartimento (dati disaggregati).\n\n22.3.1 Analisi dei Dati Disaggregati\nUomini\n\n\n\nDipartimento\nCandidati\nAmmessi (%)\n\n\n\n\nA\n825\n62\n\n\nB\n520\n60\n\n\nC\n325\n37\n\n\nD\n417\n33\n\n\nE\n191\n28\n\n\nF\n373\n6\n\n\n\nDonne\n\n\n\nDipartimento\nCandidati\nAmmessi (%)\n\n\n\n\nA\n108\n82\n\n\nB\n25\n68\n\n\nC\n593\n34\n\n\nD\n375\n35\n\n\nE\n393\n24\n\n\nF\n341\n7\n\n\n\nDall’analisi dei dati disaggregati emerge che, tra i sei dipartimenti più grandi, quattro presentano un tasso di ammissione più alto per le donne, mentre due favoriscono gli uomini. Tuttavia, questi due dipartimenti da soli non possono spiegare la grande differenza nei tassi di ammissione osservata nei dati aggregati. Questo suggerisce che la tendenza generale di un tasso di ammissione più alto per gli uomini si inverte quando si analizzano i dati suddivisi per dipartimento.\n\n\n22.3.2 La Vera Ragione della Differenza nei Tassi di Ammissione\nL’analisi di questi dati suggerisce che l’apparente svantaggio per le donne non derivava da una discriminazione diretta nei criteri di selezione, ma piuttosto da una scelta differente dei corsi di studio. In generale, le donne tendevano a candidarsi per dipartimenti con un numero elevato di concorrenti e tassi di ammissione più bassi (come lettere o psicologia), mentre gli uomini erano più propensi a fare domanda per dipartimenti con tassi di accettazione più alti (come ingegneria o fisica).\nQuesta dinamica riflette differenze sistemiche e strutturali nei percorsi educativi e professionali, più che una discriminazione esplicita nei criteri di ammissione. Lo studio originale evidenzia che le donne erano spesso indirizzate, fin dalla scuola, verso campi di studio con meno finanziamenti, prospettive di carriera più limitate e tassi di completamento inferiori.\nLa vera forma di discriminazione, dunque, non risiedeva nelle politiche di ammissione di UC Berkeley, ma in una cultura che alimentava aspettative diverse in base al genere, influenzando le scelte accademiche e professionali delle donne sin dall’infanzia.\n\n\n22.3.3 Perché il Paradosso di Simpson Inganna?\nIl paradosso di Simpson (che si manifesta nei dati sulle ammissioni ai corsi di laurea dell’Università della California, Berkeley, nel 1973) mette in luce un errore comune: assumere che una tendenza osservata nei dati aggregati sia necessariamente valida a livello di sottogruppi. L’intuizione ci porta a credere che, se nel complesso le donne hanno un tasso di ammissione più basso, questo debba essere vero anche per ciascun dipartimento. In realtà, il paradosso dimostra che le statistiche aggregate possono essere fuorvianti se non si tiene conto della distribuzione interna dei dati.\nQuesto caso ci ricorda anche l’importanza di distinguere tra correlazione e causalità. Osservare un dato (meno donne ammesse) non implica automaticamente una causa (discriminazione diretta). Solo un’analisi più approfondita, che consideri le scelte individuali e le strutture socio-culturali di riferimento, può portare a conclusioni più accurate.\nIn sintesi, i dati delle ammissioni a UC Berkeley non dimostrano necessariamente una discriminazione di genere diretta, ma sollevano questioni più ampie sulle differenze nei percorsi accademici di uomini e donne. Per comprendere realmente il fenomeno, servirebbero studi più approfonditi, capaci di analizzare le cause profonde di queste scelte educative. L’inferenza causale è uno strumento fondamentale in questo processo, poiché permette non solo di selezionare le variabili chiave da analizzare, ma anche di formulare spiegazioni più solide e plausibili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#come-scoprire-le-relazioni-causali",
    "href": "chapters/eda/09_causality.html#come-scoprire-le-relazioni-causali",
    "title": "22  Causalità dai dati osservazionali",
    "section": "22.4 Come Scoprire le Relazioni Causali?",
    "text": "22.4 Come Scoprire le Relazioni Causali?\nIl metodo più rigoroso per identificare relazioni causali è rappresentato dagli studi randomizzati controllati (RCT, Randomized Controlled Trials). La randomizzazione, ovvero l’assegnazione casuale dei partecipanti ai gruppi di trattamento e controllo, assicura che l’influenza di eventuali variabili confondenti sia equamente distribuita tra i gruppi. Di conseguenza, se dopo l’intervento si osserva una differenza sistematica tra i gruppi, questa può essere attribuita con elevata probabilità all’effetto del trattamento, poiché tutte le altre fonti di variazione sono state bilanciate grazie alla randomizzazione.\nGli RCT sono considerati il gold standard per l’inferenza causale, ma presentano alcuni limiti. In molti casi, l’implementazione di un esperimento controllato è impossibile per vincoli etici o pratici. Ad esempio, non si può randomizzare l’esposizione a fattori di rischio nocivi o imporre determinate condizioni di vita ai partecipanti. Inoltre, le condizioni sperimentali sono spesso artificiali, il che pone un problema di validità esterna: i risultati ottenuti in un contesto controllato potrebbero non generalizzarsi a contesti reali.\nQuando gli RCT non sono praticabili, i ricercatori ricorrono a disegni osservazionali, che offrono maggiore flessibilità e adattabilità ai contesti naturali. Tuttavia, il principale limite di questi studi è la difficoltà nell’identificazione causale, poiché l’assenza di randomizzazione espone i risultati al rischio di bias da confondimento. Per affrontare questa sfida, vengono adottate tecniche statistiche avanzate che permettono di avvicinarsi a stime causali più affidabili.\n\n22.4.1 Variabili Confondenti\nLe variabili confondenti rappresentano uno degli ostacoli principali nell’analisi causale. Una variabile confondente è un fattore che influenza sia la variabile indipendente (\\(X\\)) sia la variabile dipendente (\\(Y\\)), generando un’associazione spuria tra le due. In altre parole, la relazione osservata tra \\(X\\) e \\(Y\\) potrebbe non riflettere un nesso causale diretto, ma essere il risultato dell’influenza esercitata da una terza variabile.\nNegli studi osservazionali, se le variabili confondenti non vengono adeguatamente identificate e controllate, possono introdurre bias nelle stime degli effetti, portando a conclusioni errate. In assenza di un disegno sperimentale controllato, ciò che si osserva nei dati potrebbe non corrispondere a ciò che accadrebbe se si potesse manipolare direttamente \\(X\\) in un esperimento randomizzato.\n\n\n22.4.2 Approcci per il Controllo delle Variabili Confondenti\nPer stabilire relazioni causali affidabili, è fondamentale distinguere gli effetti della variabile indipendente (\\(X\\)) da quelli delle variabili confondenti (\\(Z\\)), che potrebbero generare associazioni spurie. Se le variabili confondenti non vengono adeguatamente controllate, possono introdurre bias nelle stime degli effetti e compromettere la validità delle conclusioni tratte dai dati osservazionali. Esistono due approcci principali per affrontare questo problema:\n\nControllo sperimentale: Questo metodo viene implementato attraverso il disegno dello studio e si basa sulla randomizzazione, che assicura una distribuzione casuale delle variabili confondenti tra il gruppo di trattamento e il gruppo di controllo. In questo modo, ogni differenza osservata tra i gruppi dopo il trattamento può essere attribuita con maggiore certezza all’intervento, poiché tutte le altre fonti di variazione sono bilanciate in media.\nControllo statistico: Quando la randomizzazione non è possibile, è necessario applicare tecniche statistiche per correggere il bias da confondimento. Questo approccio mira a stimare l’effetto causale di \\(X\\) su \\(Y\\) eliminando l’influenza di eventuali variabili confondenti attraverso modelli appropriati.\n\n\n22.4.2.1 Controllo Statistico e le sue Sfide\nUno dei metodi più comuni per il controllo statistico delle variabili confondenti è il condizionamento su \\(Z\\). Questo implica stimare l’effetto di \\(X\\) su \\(Y\\) all’interno di ciascun livello della variabile confondente \\(Z\\), per poi calcolare una media ponderata dell’effetto su tutta la popolazione. Tuttavia, questo approccio presenta due sfide fondamentali:\n\nIdentificazione delle variabili confondenti: È necessario conoscere e includere tutte le possibili variabili confondenti nel modello. Tuttavia, alcune potrebbero essere sconosciute o latenti, rendendo incompleto il controllo del confondimento.\nAccuratezza della misurazione: Anche quando le variabili confondenti sono note, la loro misurazione potrebbe essere imprecisa o soggetta a errori, compromettendo la validità dell’analisi e introducendo ulteriore bias.\n\nPer ovviare a questi problemi, vengono impiegate tecniche avanzate di controllo statistico, come:\n\nRegressione multipla: Include le variabili confondenti come covariate in un modello di regressione per stimare l’effetto netto di \\(X\\) su \\(Y\\).\nPropensity Score Matching (PSM): Confronta individui con caratteristiche simili nei gruppi di trattamento e controllo, riducendo il bias da confondimento.\nStratificazione: Suddivide il campione in sottogruppi omogenei rispetto alle variabili confondenti e stima l’effetto del trattamento all’interno di ciascun sottogruppo.\n\n\n\n22.4.2.2 Inferenza Causale nei Dati Osservazionali\nL’assenza di randomizzazione negli studi osservazionali ha portato alla famosa affermazione “la correlazione non implica causalità”. Tuttavia, questo non significa che l’inferenza causale sia impossibile senza esperimenti controllati. Esistono metodi statistici che permettono di affrontare il problema del confondimento e avvicinarsi a stime causali più affidabili. Tra questi:\n\nGrafi Aciclici Diretti (DAG): Strumenti grafici che rappresentano le relazioni causali tra variabili e aiutano a identificare le variabili confondenti che devono essere controllate.\nModelli Causali Strutturali (SCM): Formalismi matematici che descrivono le relazioni causali e stabiliscono le condizioni necessarie per l’identificazione degli effetti.\nDifferenze-differenze (DiD): Metodo che confronta l’evoluzione di \\(Y\\) prima e dopo il trattamento in gruppi esposti e non esposti, controllando per le tendenze temporali comuni.\nVariabili strumentali (IV): Tecnica che utilizza una variabile esogena correlata con \\(X\\) ma non direttamente con \\(Y\\), per isolare la parte di variazione di \\(X\\) non influenzata da confondenti.\nRegressione discontinua (RD): Metodo che sfrutta soglie arbitrarie per identificare effetti causali in situazioni quasi-sperimentali.\n\nIn sintesi, le variabili confondenti rappresentano una delle principali sfide nell’inferenza causale da dati osservazionali. Tuttavia, lo sviluppo di tecniche avanzate di analisi causale consente di ridurre il rischio di bias e migliorare l’affidabilità delle stime. Sebbene nessun metodo osservazionale possa replicare perfettamente i benefici della randomizzazione, l’utilizzo di strumenti come DAG, SCM e tecniche di identificazione causale permette di ottenere risultati più solidi e interpretabili. L’adozione di questi approcci è fondamentale per garantire che le conclusioni tratte dai dati osservazionali siano quanto più possibile accurate e prive di distorsioni.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#modelli-causali-strutturali",
    "href": "chapters/eda/09_causality.html#modelli-causali-strutturali",
    "title": "22  Causalità dai dati osservazionali",
    "section": "22.5 Modelli Causali Strutturali",
    "text": "22.5 Modelli Causali Strutturali\nI modelli causali strutturali (Structural Causal Models, SCM) sono strumenti fondamentali per l’inferenza causale nei dati osservazionali. Essi permettono di rappresentare il processo generativo sottostante a un fenomeno e di prevedere gli effetti di un intervento. Oltre a descrivere le relazioni causali tra variabili, gli SCM consentono di esplorare scenari controfattuali, ovvero ipotetiche alternative a ciò che è stato osservato, offrendo un quadro formale per rispondere a domande del tipo cosa sarebbe successo se…?\n\n22.5.1 Struttura di un Modello Causale Strutturale\nUn SCM è definito da un insieme di equazioni strutturali che descrivono come ciascuna variabile dipende causalmente dalle altre. Il modello è composto da:\n\nVariabili esogene: Fonti di variazione esterne al sistema modellato, che non dipendono da nessuna altra variabile del modello.\nVariabili endogene: Determinate dalle equazioni del modello e influenzate da altre variabili all’interno dello stesso.\nRelazioni causali esplicite: Specificate attraverso funzioni matematiche che descrivono i meccanismi di generazione dei dati.\n\nIl processo di costruzione di un SCM segue una logica ben definita: si parte dalle variabili esogene e, attraverso una serie di assegnazioni, si generano le variabili endogene, costruendo progressivamente una distribuzione congiunta delle variabili osservate.\n\n\n22.5.2 Vantaggi degli SCM\nUno degli aspetti distintivi degli SCM è la loro duplice funzione:\n\nDescrivono il processo generativo dei dati, rendendo esplicite le ipotesi sui meccanismi causali.\nInducono una distribuzione probabilistica congiunta, consentendo l’analisi sia delle relazioni statistiche tra le variabili sia delle connessioni causali sottostanti.\n\nQuesta struttura consente di superare i limiti dei modelli puramente correlazionali, offrendo un framework solido per distinguere tra causalità e semplice associazione.\n\n\n22.5.3 Rappresentazione Grafica: DAG\nGli SCM sono spesso rappresentati graficamente tramite Grafi Aciclici Diretti (Directed Acyclic Graphs, DAG). Un DAG è una rete di nodi (variabili) e archi direzionati che indicano relazioni causali. Questa rappresentazione:\n\nfacilita l’individuazione delle variabili confondenti e dei percorsi di causalità indiretti;\naiuta a identificare strategie per il controllo del confondimento, come il criterio di separazione (d-separation);\npermette di determinare se un effetto causale è identificabile o se è necessario raccogliere dati aggiuntivi.\n\nIn sintesi, gli SCM rappresentano un’evoluzione rispetto ai modelli statistici tradizionali, poiché incorporano esplicitamente informazioni sulle relazioni causali. L’uso combinato di equazioni strutturali e rappresentazioni grafiche tramite DAG consente di affrontare problemi di confondimento, identificare effetti causali e analizzare scenari controfattuali con maggiore rigore rispetto a modelli puramente correlazionali.\nL’adozione di SCM è particolarmente utile nei dati osservazionali, dove la mancanza di randomizzazione rende necessaria una modellazione esplicita delle relazioni causali per ottenere inferenze affidabili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#bias-da-variabile-omessa",
    "href": "chapters/eda/09_causality.html#bias-da-variabile-omessa",
    "title": "22  Causalità dai dati osservazionali",
    "section": "22.6 Bias da Variabile Omessa",
    "text": "22.6 Bias da Variabile Omessa\nL’omissione di variabili confondenti rappresenta una delle principali fonti di distorsione nelle stime statistiche. Il bias da variabile omessa [Omitted Variable Bias, OVB; Wilms et al. (2021)] si verifica quando una variabile confondente, nota ma non misurata, o sconosciuta, viene esclusa dall’analisi, alterando la stima dell’effetto causale. Come evidenziato da Byrnes & Dee (2024), l’OVB può portare a stime distorte della magnitudine degli effetti, inversioni del segno delle stime, correlazioni spurie e al mascheramento di reali relazioni causali.\nUn’illustrazione di questa problematica è mostrata nella Figura 22.1, che rappresenta tre scenari diversi in cui una variabile non osservata (\\(U\\)) può influenzare un modello causale:\n\nPannello di sinistra: La variabile non osservata \\(U\\) non è correlata con la variabile indipendente \\(X\\), quindi la sua omissione non introduce bias nella stima dell’effetto di \\(X\\) su \\(Y\\), ma può ridurre la precisione del modello aumentando l’errore standard della stima.\nPannello centrale: La variabile non osservata \\(U\\) è una variabile confondente, poiché influenza sia \\(X\\) che \\(Y\\). La sua omissione causa bias nella stima dell’effetto di \\(X\\) su \\(Y\\), alterando le conclusioni causali.\nPannello di destra: \\(U\\) e \\(X\\) sono entrambi influenzati da un fattore comune \\(Z\\), generando un confondimento indiretto. In questo caso, omettere \\(U\\) introduce distorsione nella stima dell’effetto di \\(X\\) su \\(Y\\).\n\n\n\n\n\n\n\nFigura 22.1: La figura mostra come l’omissione di una variabile confondente possa o meno introdurre bias nella stima dell’effetto di \\(X\\) su \\(Y\\). Nel pannello di sinistra, \\(X\\) e \\(U\\) sono indipendenti, quindi la mancata inclusione di \\(U\\) non altera la stima dell’effetto di \\(X\\) su \\(Y\\), ma riduce la precisione del modello. Nel pannello centrale, \\(U\\) influenza sia \\(X\\) che \\(Y\\), generando un bias da variabile omessa. Nel pannello di destra, \\(X\\) e \\(U\\) sono correlati tramite un fattore comune \\(Z\\), creando un confondimento indiretto. In entrambi questi ultimi casi, il controllo delle variabili confondenti è essenziale per effettuare inferenze causali affidabili. La figura è ispirata da Byrnes & Dee (2024).\n\n\n\n\n22.6.1 Superare il Bias da Variabile Omessa con gli SCM\nAffrontare il bias da variabile omessa è una delle sfide principali nell’inferenza causale dai dati osservazionali. A differenza dell’errore di misurazione nelle variabili predittive, che tende a ridurre l’ampiezza delle stime senza necessariamente invertirne il segno (McElreath, 2020; Schennach, 2016), il bias da variabile omessa può alterare in modo imprevedibile le stime, rendendole fuorvianti.\nNonostante queste difficoltà, i dati osservazionali possono comunque essere utilizzati per l’inferenza causale, a condizione che vengano applicate strategie adeguate. L’adozione dei modelli causali strutturali (SCM) consente di esplicitare il meccanismo generativo sottostante ai dati, permettendo di modellare le relazioni tra variabili e di controllare il confondimento in modo più rigoroso.\n\n\n22.6.2 Il Ruolo della Modellazione Esplicita\nL’uso degli SCM non elimina del tutto il problema delle variabili omesse, ma offre un quadro concettuale per affrontarlo. Questo approccio ha due vantaggi principali:\n\nEsplicitazione del modello generativo: Un SCM rende trasparente la struttura causale ipotizzata e permette di individuare le variabili mancanti che potrebbero influenzare le stime.\nPossibilità di affinamento progressivo: Ogni nuova evidenza empirica può essere utilizzata per migliorare il modello, testando ipotesi alternative e perfezionando la comprensione dei meccanismi causali sottostanti.\n\nIn sintesi, l’inferenza causale non può basarsi esclusivamente su correlazioni osservate tra variabili, poiché il confondimento dovuto a variabili omesse può distorcere le stime. L’utilizzo di modelli causali strutturali, supportati dall’analisi tramite DAG, consente di ridurre questi problemi e di formulare inferenze più affidabili. Sebbene nessun modello possa garantire conclusioni definitive, la costruzione di un quadro causale esplicito favorisce il progresso scientifico, permettendo di testare, correggere e affinare le ipotesi sui meccanismi che regolano i fenomeni psicologici.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#grafi-aciclici-diretti",
    "href": "chapters/eda/09_causality.html#grafi-aciclici-diretti",
    "title": "22  Causalità dai dati osservazionali",
    "section": "22.7 Grafi Aciclici Diretti",
    "text": "22.7 Grafi Aciclici Diretti\nI Grafi Aciclici Diretti (Directed Acyclic Graphs, DAG) sono strumenti fondamentali per rappresentare e analizzare relazioni causali. Offrono una rappresentazione visiva chiara delle ipotesi sui meccanismi causali e aiutano a identificare le variabili confondenti da controllare per ottenere stime causali affidabili.\nUn DAG è un grafo in cui:\n\ni nodi rappresentano le variabili coinvolte nel fenomeno studiato;\nle frecce direzionate tra i nodi indicano relazioni causali;\nil grafo è aciclico, il che significa che non si possono formare cicli: non esiste un percorso chiuso che permetta di tornare a un nodo di partenza seguendo le frecce.\n\n\n22.7.1 Terminologia nei DAG\n\nUn nodo \\(X\\) con una freccia diretta verso un altro nodo \\(Y\\) indica che \\(X\\) causa \\(Y\\).\nIl nodo che origina una freccia è detto genitore, mentre quello di destinazione è detto figlio.\nSe esiste un percorso tra un nodo \\(A\\) e un nodo \\(B\\), \\(A\\) è detto antenato di \\(B\\), e \\(B\\) è un discendente di \\(A\\).\n\nQuesta struttura permette di distinguere tra cause dirette e indirette: una causa diretta è un nodo genitore, mentre una causa indiretta è un qualsiasi antenato lungo un percorso nel grafo.\nI DAG sono particolarmente utili per l’identificazione delle variabili confondenti e per stabilire quali variabili devono essere controllate per ottenere inferenze causali non distorte.\n\n\n22.7.2 La d-separazione\nLa d-separazione è una regola che ci permette di capire se due variabili in un DAG sono indipendenti una volta che si è controllato per un insieme di altre variabili. In termini semplici, ci aiuta a rispondere alla domanda: possiamo dire che due variabili non sono collegate dopo aver considerato certe informazioni?\nImmaginiamo un DAG come un sistema di percorsi attraverso cui scorre l’informazione. Se due variabili sono collegate da un percorso aperto, significa che possono influenzarsi a vicenda, direttamente o indirettamente. Se invece il percorso è bloccato, l’informazione non può passare e possiamo considerarle indipendenti. La d-separazione ci indica quando un percorso è aperto e quando è bloccato.\nPer determinare se due variabili sono indipendenti, si deve controllare il percorso che le collega nel DAG e verificare se ci sono ostacoli che ne impediscono il flusso informativo. Un percorso può essere bloccato in tre modi principali:\n\nCatena (\\(X\\) → \\(Z\\) → \\(Y\\)): Il nodo intermedio (\\(Z\\)) è un mediatore. Se si controlla per \\(Z\\), il flusso di informazioni tra \\(X\\) e \\(Y\\) viene interrotto, rendendole indipendenti.\nFork (\\(X\\) ← \\(Z\\) → \\(Y\\)): \\(Z\\) è una causa comune di \\(X\\) e \\(Y\\). Se si controlla per \\(Z\\), si elimina la correlazione spuria tra \\(X\\) e \\(Y\\), bloccando il percorso.\nCollider (\\(X\\) → \\(Z\\) ← \\(Y\\)): \\(Z\\) è un effetto comune di \\(X\\) e \\(Y\\). Se non si controlla per \\(Z\\), il percorso è già bloccato e \\(X\\) e \\(Y\\) sono indipendenti. Attenzione! Controllare per \\(Z\\) (o per una sua conseguenza) apre il percorso e introduce una correlazione spuria tra \\(X\\) e \\(Y\\).\n\nLa d-separazione è cruciale perché ci permette di leggere direttamente dal DAG quali variabili dobbiamo controllare per ottenere inferenze causali affidabili, senza dover fare complessi calcoli probabilistici.\n\n\n22.7.3 Il Criterio del Back-Door e la d-separazione\nIl criterio del back-door è strettamente legato alla d-separazione e serve a identificare un insieme di variabili da controllare per ottenere una stima non distorta dell’effetto causale di \\(X\\) su \\(Y\\).\nUn back-door path è un percorso tra \\(X\\) e \\(Y\\) che inizia con una freccia entrante in \\(X\\). Questo tipo di percorso rappresenta una fonte di confondimento che deve essere bloccata per stimare correttamente l’effetto causale di \\(X\\) su \\(Y\\).\n\n22.7.3.1 Come bloccare i percorsi back-door\n\nSe il percorso contiene una catena (\\(X\\) ← \\(A\\) → \\(B\\) → \\(Y\\)), si blocca condizionando su una delle variabili intermedie (\\(A\\) o \\(B\\)).\nSe il percorso contiene un collider (\\(X\\) → \\(Z\\) ← \\(Y\\)), il percorso è già bloccato e non bisogna condizionare su \\(Z\\).\nSe il percorso contiene un fork (\\(X\\) ← \\(Z\\) → \\(Y\\)), il percorso si blocca condizionando su \\(Z\\).\n\n\n\n\n22.7.4 Relazione tra d-separazione e il criterio del back-door\nLa d-separazione ci permette di determinare se esiste un percorso aperto tra \\(X\\) e \\(Y\\). Se vogliamo stimare un effetto causale, dobbiamo assicurarci che tra \\(X\\) e \\(Y\\) esista solo il percorso causale diretto e che tutti gli altri percorsi (in particolare i back-door paths) siano bloccati.\nQuindi:\n\nse due variabili risultano d-separate dopo aver condizionato su un insieme di variabili di controllo, significa che ogni percorso non causale tra di esse è stato bloccato, permettendo un’interpretazione causale dell’effetto stimato;\nse invece esistono percorsi back-door non bloccati, la stima dell’effetto causale sarà distorta a causa della presenza di confondimento.\n\nIn sintesi, l’uso dei DAG consente di visualizzare in modo chiaro le relazioni causali tra le variabili e di determinare quali percorsi devono essere chiusi per ottenere inferenze non distorte. Strumenti come la d-separazione e il criterio del back-door permettono di evitare errori comuni nell’analisi causale e di migliorare la validità delle stime statistiche. L’adozione di questi metodi è essenziale per garantire che le conclusioni tratte dai dati osservazionali siano affidabili e prive di bias.\n\n\n22.7.5 Applicazioni\nConsideriamo la struttura causale illustrata nella Figura 22.1, pannello centrale. Dopo aver costruito un DAG come descritto nella sezione precedente, possiamo identificare le possibili fonti di bias da variabili omesse, incluse quelle non misurate (ad esempio, \\(U\\)). Se una variabile confondente non viene inclusa nell’analisi, si apre un back-door path, permettendo alla variazione confondente di influenzare la relazione tra la variabile causale e la variabile di risposta attraverso un percorso non controllato (Pearl, 2009).\nIn altre parole, omettere una variabile confondente come \\(U\\) nella Figura 22.1 (pannello centrale) implica che la sua influenza venga incorporata nel termine di errore del modello statistico, insieme ad altre fonti di errore casuali. Questo può distorcere la stima dell’effetto causale di \\(X\\) su \\(Y\\).\nLa Figura 22.2 illustra le conseguenze di un confondente \\(U\\) che ha un effetto positivo su \\(X\\) ma un effetto negativo su \\(Y\\):\n\nSe controlliamo per \\(U\\), come mostrato nella Figura 22.2 (Bi), l’effetto stimato di \\(X\\) su \\(Y\\) riflette la relazione causale effettiva.\nSe non controlliamo per \\(U\\), come mostrato nella Figura 22.2 (Bii), \\(U\\) viene inglobato nel termine di errore, creando una correlazione spuriosa tra l’errore e \\(X\\) (Figura 22.2, Biii). Questo induce una stima distorta dell’effetto di \\(X\\) su \\(Y\\), evidenziata in blu.\n\nL’omissione di una variabile indipendente che è correlata con altre variabili indipendenti nel modello e che ha un effetto diretto su \\(Y\\) costituisce un errore di specificazione. Nei modelli lineari, questa omissione viola un’ipotesi fondamentale del teorema di Gauss-Markov, secondo cui il termine di errore deve essere incorrelato con le variabili esplicative. Di conseguenza, la stima dell’effetto causale di \\(X\\) su \\(Y\\) risulta distorta, compromettendo l’affidabilità dell’analisi.\n\n\n\n\n\n\nFigura 22.2: Una visualizzazione del bias da variabile omessa e delle conseguenze per l’inferenza causale. (A) mostra un DAG di un sistema in cui \\(X\\) ha un effetto positivo su \\(Y\\), e una variabile confondente U ha un effetto positivo su \\(Y\\) ma un effetto negativo su \\(X\\). Le variabili non osservate (cioè non misurate) sono rappresentate in ellissi, come la variabile U e il termine di errore e nel pannello B. (B) illustra diverse stime del DAG in (A) utilizzando un’analisi del percorso. Vedi Bo\\(X\\) 1 per una breve spiegazione delle principali differenze tra DAG e diagrammi dei percorsi. Presumiamo che U non sia misurata. In (Bi), presumiamo di poter misurare e controllare U, rappresentata dalla freccia a doppia testa tra U e \\(X\\), che rappresenta la correlazione tra le due variabili considerata dal modello. La variabile non misurata e è la fonte residua di variazione che si presume non sia correlata con nessun predittore. La freccia rossa rappresenta il percorso stimato. Al contrario, (Bii) e (Biii) rappresentano la realtà, dove non abbiamo una misurazione di U e non la controlliamo nel modello dei percorsi. Il ricercatore pensa di adattare il modello in (Bii) ma in realtà sta adattando il modello in (Biii), dove il termine di errore non è solo e, ma la somma di e e la variazione dovuta alla variabile omessa U. A causa di ciò, c’è un percorso diretto dal termine di errore del modello a \\(X\\) (e quindi \\(X\\) è endogeno). (C) mostra le relazioni stimate risultanti dai modelli in (Bi) rispetto a (Bii). Le linee rappresentano la relazione stimata tra \\(X\\) e \\(Y\\) dai rispettivi modelli. La linea rossa è la vera relazione causale, stimata da (Bi), mentre la linea blu contiene il bias da variabile omessa, poiché non si tiene conto della variabile confondente U, come stimato dal modello in Bii/Biii (Figura tratta da Byrnes & Dee (2024)).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#le-pratiche-scientifiche-per-inferire-la-causalità",
    "href": "chapters/eda/09_causality.html#le-pratiche-scientifiche-per-inferire-la-causalità",
    "title": "22  Causalità dai dati osservazionali",
    "section": "22.8 Le Pratiche Scientifiche per Inferire la Causalità",
    "text": "22.8 Le Pratiche Scientifiche per Inferire la Causalità\nIn qualsiasi sistema complesso, possiamo osservare la distribuzione congiunta di due variabili, \\(X\\) e \\(Y\\), ma determinare se \\(X\\) causa \\(Y\\), se \\(Y\\) causa \\(X\\), o se una terza variabile \\(Z\\) influenza entrambe, è un problema complesso (Salmon, 1984). Questa difficoltà è alla base del dibattito filosofico sulla causalità e ha stimolato lo sviluppo di metodi scientifici rigorosi per decifrare i meccanismi causali. Ad esempio, per stabilire se la terapia cognitivo-comportamentale (CBT) riduce i sintomi di ansia o se l’attivazione di un neurone influenza il comportamento, è necessario adottare pratiche scientifiche che distinguano la correlazione dalla causalità.\n\n22.8.1 Il Framework Interventista di Judea Pearl\nIl lavoro di Judea Pearl ha rivoluzionato la formalizzazione dell’inferenza causale introducendo l’operatore “do”, che distingue tra correlazione osservata e causalità determinata da un intervento attivo (ricordiamo il punto di vista di Hardt & Recht, 2022 descritto in precedenza). La probabilità condizionale tradizionale, \\(p(Y \\mid X)\\), descrive l’associazione tra due variabili, ma non implica necessariamente causalità. L’operatore do, invece, introduce il concetto di intervento forzato: \\(p(Y \\mid do(X))\\) rappresenta la probabilità di \\(Y\\) quando \\(X\\) viene manipolato direttamente (Pearl, 2009).\nAd esempio, osservare che i pazienti che partecipano alla CBT tendono a mostrare una riduzione dell’ansia non è sufficiente per concludere che la CBT ne sia la causa. Il problema è che la decisione di seguire la CBT potrebbe dipendere da fattori come il livello di gravità dell’ansia, lo stato socioeconomico o la predisposizione genetica, che possono influenzare sia la scelta di intraprendere la terapia sia la variazione nei sintomi.\nUtilizzando un modello causale strutturale (SCM) completo, possiamo esprimere formalmente le relazioni tra le variabili e determinare se l’effetto di \\(X\\) su \\(Y\\) può essere identificato, ovvero stimato correttamente dai dati. L’operatore do ci consente di rispondere alla domanda: “Cosa accadrebbe se tutti i pazienti seguissero la CBT indipendentemente da altri fattori?”. In pratica, uno SCM ben specificato permette di controllare statisticamente le variabili di disturbo e di rimuovere i percorsi di confondimento, simulando una condizione sperimentale in cui l’assegnazione al trattamento è indipendente da fattori che influenzano sia la terapia sia l’outcome.\nQuesta capacità di simulare interventi e stimare effetti causali è ciò che distingue i modelli causali strutturali dagli approcci puramente correlazionali e permette di ottenere inferenze più affidabili anche in assenza di esperimenti randomizzati.\n\n\n22.8.2 Tre Fonti di Conoscenza Causale\nAlla luce delle considerazioni precedenti, possiamo individuare tre fonti fondamentali per inferire la causalità.\n\nEsperimenti Randomizzati Controllati (RCT). Gli RCT rappresentano il metodo più affidabile per stabilire relazioni causali, assegnando casualmente i partecipanti a gruppi di trattamento e controllo. Questo processo minimizza l’influenza di confondenti e garantisce stime non distorte dell’effetto di un intervento. Ad esempio, per verificare se il sonno migliora la memoria, possiamo assegnare casualmente alcuni volontari a dormire 8 ore e altri a restare svegli prima di un test cognitivo. Questo approccio elimina l’influenza di fattori come l’età o il livello di stress, consentendo di attribuire le differenze di performance esclusivamente alla quantità di sonno.\nConoscenza Specifica del Dominio. In discipline come la psicologia e le neuroscienze, la conoscenza specialistica permette di formulare ipotesi causali informate. Ad esempio, sebbene un semplice movimento della mano non causi direttamente l’accensione di una luce, sappiamo che chiudere un interruttore completa un circuito elettrico. Questa comprensione ci guida nella progettazione di esperimenti e nell’interpretazione dei risultati. Un esempio in neuroscienze è il ruolo dell’amigdala nella risposta alla paura. Studi su pazienti con danni all’amigdala mostrano una ridotta capacità di riconoscere espressioni di paura, suggerendo un legame causale tra l’attività dell’amigdala e la regolazione della paura. Allo stesso modo, la scoperta dell’afasia di Broca ha dimostrato il ruolo causale dell’area di Broca nella produzione del linguaggio. Questa conoscenza permette di formulare ipotesi precise anche in assenza di RCT, come nel caso di studi clinici su pazienti con condizioni neurologiche rare.\nProve Cumulative e Consenso Scientifico. La conoscenza scientifica avanza attraverso la validazione collettiva dei risultati. Quando numerosi studi indipendenti convergono su una relazione causale, la comunità scientifica acquisisce una comprensione più solida del fenomeno. Ad esempio, molteplici studi indicano che relazioni sociali positive aumentano il benessere psicologico. Anche se nessuno studio singolo può offrire una prova definitiva, la convergenza di evidenze rafforza l’ipotesi causale.\n\nSi noti che, mentre nel primo caso l’inferenza causale deriva direttamente da esperimenti randomizzati controllati (RCT), nei secondi due la conoscenza causale si basa su studi osservazionali e sulla convergenza di evidenze empiriche. La validità di queste inferenze dipende dall’uso di modelli adeguati, dal controllo delle variabili confondenti e dalla replicabilità dei risultati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#conciliare-pragmatismo-con-scetticismo-filosofico",
    "href": "chapters/eda/09_causality.html#conciliare-pragmatismo-con-scetticismo-filosofico",
    "title": "22  Causalità dai dati osservazionali",
    "section": "22.9 Conciliare Pragmatismo con Scetticismo Filosofico",
    "text": "22.9 Conciliare Pragmatismo con Scetticismo Filosofico\nNonostante l’efficacia degli RCT e degli strumenti teorici come l’operatore do, il problema epistemologico della causalità, sollevato da filosofi come Hume, rimane aperto. Hume sosteneva che la causalità non è direttamente osservabile, ma è inferita dall’esperienza e dalla regolarità delle osservazioni. Questo scetticismo ci ricorda che la nostra comprensione causale è sempre mediata da modelli, assunzioni e interpretazioni.\nTuttavia, l’approccio pragmatico alla causalità non richiede una dimostrazione metafisica assoluta, ma si concentra sulla sua utilità pratica: se un intervento produce risultati coerenti e prevedibili, allora possiamo considerarlo una causa per tutti gli scopi pratici.\nAd esempio, la nostra fiducia nel volo aereo non deriva da una prova definitiva della causalità tra il design di un aereo e la sua capacità di volare, ma dall’affidabilità e replicabilità delle leggi dell’aerodinamica. Analogamente, la CBT è riconosciuta come trattamento efficace per l’ansia non perché possiamo dimostrare una causalità assoluta, ma perché numerosi studi, tra cui RCT e analisi basate su modelli causali, ne confermano ripetutamente l’efficacia in diversi contesti.\nIn sintesi, l’inferenza causale è una delle sfide centrali della scienza, ma strumenti come gli RCT, i modelli causali strutturali, la conoscenza del dominio e le prove cumulative forniscono metodi robusti per affrontarla. L’approccio pragmatico ci consente di superare il problema filosofico della causalità, concentrandoci sulla replicabilità, sull’affidabilità e sull’applicabilità pratica dei risultati. Sebbene il dibattito sulla natura ultima della causalità rimanga aperto, le pratiche scientifiche ci permettono di prendere decisioni informate e mettere in atti interventi efficaci.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#riflessioni-conclusive",
    "href": "chapters/eda/09_causality.html#riflessioni-conclusive",
    "title": "22  Causalità dai dati osservazionali",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIl dibattito filosofico sulla causalità resta aperto, ma i progressi metodologici degli ultimi decenni hanno trasformato l’inferenza causale in una disciplina rigorosa e applicabile. L’uso di esperimenti randomizzati controllati (RCT), diagrammi causali (DAG) e l’operatore do di Judea Pearl ha reso possibile analizzare le relazioni causali in modo più trasparente e sistematico, senza dover risolvere le questioni metafisiche sulla natura ultima della causalità. La scienza, dunque, procede non con certezze assolute, ma con modelli sempre più raffinati e verificabili.\nI DAG si sono affermati come strumenti essenziali per visualizzare e analizzare i rapporti causali, permettendo di esplicitare le assunzioni e di individuare le fonti di bias. Tuttavia, la loro validità dipende strettamente dalla qualità delle conoscenze del dominio: un DAG ben costruito può guidare verso inferenze affidabili, ma un DAG con specificazioni errate o incomplete rischia di produrre conclusioni distorte. Per questa ragione, la loro applicazione richiede non solo competenza metodologica, ma anche un solido ancoraggio alla realtà empirica.\nL’approccio pragmatico alla causalità si fonda su un equilibrio tra fiducia nei modelli empirici e consapevolezza dei loro limiti. La nostra capacità di fare previsioni e intervenire sui fenomeni — dall’ingegneria aeronautica all’efficacia delle terapie psicologiche — non si basa su una conoscenza definitiva della causalità, ma sulla robustezza delle evidenze accumulate. Questo pragmatismo non è una debolezza, ma una strategia vincente per affrontare l’incertezza in modo efficace e produttivo.\nTuttavia, la solidità degli strumenti causali non è garantita a priori: la qualità delle inferenze dipende dalla cura con cui vengono costruiti e validati. Un uso acritico dei DAG, degli RCT o dei modelli causali strutturali può portare a interpretazioni fuorvianti, specialmente se si ignorano le limitazioni insite in ogni approccio. La ricerca causale, dunque, non è solo una questione di strumenti, ma di metodo: richiede una costante riflessione critica sulle ipotesi sottostanti e un rigoroso controllo empirico per evitare semplificazioni eccessive.\nIn definitiva, il progresso nella comprensione della causalità dipende dalla capacità di bilanciare pragmatismo e scetticismo epistemologico. Da un lato, dobbiamo costruire modelli che ci permettano di fare previsioni affidabili e di prendere decisioni informate; dall’altro, dobbiamo riconoscere che ogni modello è una rappresentazione semplificata della realtà e che le nostre inferenze devono essere costantemente riviste alla luce di nuove evidenze. Accettare questa tensione tra conoscenza e incertezza non è una limitazione, ma una condizione essenziale per il progresso scientifico. In questo equilibrio tra umiltà teorica e fiducia operativa risiede la vera forza dell’indagine causale.\nUn riassunto ironico di questi concetti è offerto dalla vignetta di xkcd.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#esercizi",
    "href": "chapters/eda/09_causality.html#esercizi",
    "title": "22  Causalità dai dati osservazionali",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nEsercizi teorici\nEsercizio 1: Concetti chiave della causalità\nPer ciascuna delle seguenti affermazioni, indica se è vera o falsa e spiega il motivo della tua risposta.\n\nSe \\(X\\) e \\(Y\\) sono correlate, allora \\(X\\) causa \\(Y\\).\n\nSe condizioniamo su una variabile collider, la correlazione tra \\(X\\) e \\(Y\\) aumenta.\n\nIl paradosso di Simpson dimostra che i risultati osservati in gruppi disaggregati devono sempre essere preferiti a quelli aggregati.\n\nGli esperimenti randomizzati controllati eliminano completamente il problema della confusione.\n\nUn DAG può rappresentare relazioni causali solo se tutte le variabili sono misurate.\n\nEsercizio 2: Interpretazione di un DAG\nConsidera il seguente DAG che rappresenta l’effetto dell’esercizio fisico (\\(X\\)) sulla salute cardiaca (\\(Y\\)):\n    $X$ → $Y$\n    Z → $X$\n    Z → $Y$\ndove:\n\n\\(X\\) = Esercizio fisico\n\n\\(Y\\) = Salute cardiaca\n\n\\(Z\\) = Predisposizione genetica\n\n\nQuale ruolo svolge \\(Z\\) in questo DAG? È una variabile confondente, collider o mediatore?\nPer stimare correttamente l’effetto causale di \\(X\\) su \\(Y\\), è necessario controllare per \\(Z\\)? Spiega il perché.\n\nSe aggiungiamo un’altra variabile W che influenza sia \\(Z\\) che \\(X\\), ma non direttamente \\(Y\\), come cambierebbe il DAG?\n\nEsercizio 3: Causalità nei dati osservazionali\nLeggi le seguenti situazioni e identifica quale problema potrebbe invalidare l’inferenza causale:\n\nUno studio osservazionale mostra che le persone che bevono caffè vivono più a lungo. Tuttavia, chi beve caffè tende ad avere un reddito più alto e accesso a migliori cure mediche.\nUn’azienda scopre che i dipendenti che frequentano corsi di formazione hanno salari più alti. Ma i corsi sono aperti solo a coloro che già hanno più esperienza lavorativa.\n\nUna ricerca mostra che gli studenti che usano di più il tablet per studiare hanno punteggi più bassi nei test. Tuttavia, gli studenti con difficoltà di apprendimento tendono a usare di più il tablet.\n\nPer ogni caso, identifica una possibile variabile confondente e suggerisci un metodo per controllare il bias.\nEsercizi pratici in R\nEsercizio 4: Paradosso di Simpson con dati reali\nUtilizziamo i dati delle ammissioni di UC Berkele\\(Y\\) per verificare il paradosso di Simpson.\n# Dati di UC Berkele$Y$\ndata(UCBAdmissions)\ndf &lt;- as.data.frame(UCBAdmissions)\n\n# Convertiamo i dati in formato long\ndf_long &lt;- df |&gt; tid$Y$r::pivot_wider(names_from = \"Admit\", values_from = \"Freq\") \n\n# Calcoliamo il tasso di ammissione per uomini e donne aggregati\ntotal_admitted_m &lt;- sum(df$Freq[df$Admit == \"Admitted\" & df$Gender == \"Male\"])\ntotal_applicants_m &lt;- sum(df$Freq[df$Gender == \"Male\"])\n\ntotal_admitted_f &lt;- sum(df$Freq[df$Admit == \"Admitted\" & df$Gender == \"Female\"])\ntotal_applicants_f &lt;- sum(df$Freq[df$Gender == \"Female\"])\n\nadmit_rate_m &lt;- total_admitted_m / total_applicants_m\nadmit_rate_f &lt;- total_admitted_f / total_applicants_f\n\nc(admit_rate_m, admit_rate_f)\n\n# Calcoliamo il tasso di ammissione per ogni dipartimento\ndf_long$rate_m &lt;- df_long$Admitted / (df_long$Admitted + df_long$Rejected)\n\ndf_long |&gt; dpl$Y$r::group_b$Y$(Dept) |&gt; dpl$Y$r::summarize(mean_rate_m = mean(rate_m))\n\n# Visualizziamo il tasso di ammissione per genere e dipartimento\nggplot(df_long, aes($X$ = Dept, $Y$ = rate_m, fill = Gender)) +\n  geom_bar(stat = \"identit$Y$\", position = \"dodge\") +\n  labs(title = \"Tasso di Ammissione per Genere nei Dipartimenti UC Berkele$Y$\",\n       $X$ = \"Dipartimento\", $Y$ = \"Tasso di Ammissione\")\nDomande:\n\nDai dati aggregati, sembra che le donne siano discriminate. Questo è confermato dall’analisi per dipartimento?\n\nQuale variabile confondente è responsabile del paradosso di Simpson in questo caso?\n\nCome potrebbe essere interpretato male un modello che considera solo i dati aggregati?\n\nEsercizio 5: Analisi causale con DAG\nUsiamo il pacchetto dagitt$Y$ per costruire e analizzare un DAG.\nlibrar$Y$(dagitt$Y$)\n\ndag &lt;- dagitt$Y$(\"dag {\n    E -&gt; H\n    G -&gt; E\n    G -&gt; H\n}\")\n\nplot(graphLa$Y$out(dag))\nDomande:\n\nQuali sono le variabili confondenti nel DAG?\n\nQuali percorsi sono back-door paths?\n\nQuale set di variabili dovremmo controllare per ottenere una stima non distorta dell’effetto di E su H?\n\n\n\n\n\n\n\n\n\n\n\nSoluzione\n\n\n\n\n\nEsercizio 1: Concetti chiave della causalità\n\nFalso – La correlazione non implica causalità. Potrebbero esserci variabili confondenti o una relazione di causalità inversa tra \\(X\\) e \\(Y\\).\n\nVero – Condizionare su un collider introduce un’associazione spuriosa tra \\(X\\) e \\(Y\\), aumentando la correlazione.\n\nFalso – Il paradosso di Simpson mostra che i dati aggregati possono essere fuorvianti, ma non significa che i dati disaggregati siano sempre più affidabili. È necessario analizzare il contesto e le possibili variabili confondenti.\n\nFalso – Gli RCT minimizzano i problemi di confondimento grazie alla randomizzazione, ma possono comunque avere limitazioni dovute a bias di selezione, mancate assegnazioni casuali, e problemi etici.\n\nFalso – Un DAG può rappresentare le relazioni causali anche se alcune variabili non sono misurate. Tuttavia, la validità dell’inferenza dipende dalla correttezza del DAG.\n\nEsercizio 2: Interpretazione di un DAG\n\nZ è una variabile confondente, poiché influenza sia \\(X\\) che \\(Y\\), creando un percorso di back-door.\n\nSì, per stimare correttamente l’effetto di \\(X\\) su \\(Y\\) dobbiamo controllare per Z. Se non lo facciamo, la relazione osservata tra \\(X\\) e \\(Y\\) includerà l’influenza di Z.\n\nSe aggiungiamo una variabile W che influenza Z e \\(X\\), il DAG diventa:\n    W → Z → $X$ → $Y$\n    W → $X$\n    Z → $Y$\nOra W è una variabile a monte di \\(X\\) e Z, ma non confonde direttamente la relazione tra \\(X\\) e \\(Y\\).\n\nEsercizio 3: Causalità nei dati osservazionali\n\nConfondente: reddito – Le persone con un reddito più alto possono avere accesso a cure migliori, che a loro volta migliorano la salute. Soluzione: Propensit\\(Y\\) Score Matching (PSM) o regressione con controllo per il reddito.\n\nConfondente: esperienza lavorativa – Chi ha più esperienza può già avere salari più alti. Soluzione: Matching o modello di regressione con controllo per esperienza lavorativa.\n\nConfondente: difficoltà di apprendimento – Studenti con difficoltà possono usare più il tablet e avere punteggi più bassi. Soluzione: Includere il livello di abilità di partenza nei modelli statistici.\n\nSoluzioni esercizi pratici in R\nEsercizio 4: Paradosso di Simpson con dati reali\n\nDifferenza nei tassi di ammissione aggregati:\nadmit_rate_m &lt;- total_admitted_m / total_applicants_m\nadmit_rate_f &lt;- total_admitted_f / total_applicants_f\nRisultato:\n\nTasso di ammissione uomini: ~44%\n\nTasso di ammissione donne: ~35%\n→ Sembra che le donne siano discriminate.\n\nAnalisi per dipartimento:\ndf_long |&gt; dpl$Y$r::group_b$Y$(Dept) |&gt; dpl$Y$r::summarize(mean_rate_m = mean(rate_m))\n\nNei singoli dipartimenti, le donne hanno tassi di ammissione uguali o superiori rispetto agli uomini.\n→ Il problema non è discriminazione diretta, ma la distribuzione delle domande nei dipartimenti.\n\nConclusione: Il paradosso di Simpson mostra che le donne tendono a candidarsi più spesso a dipartimenti molto competitivi con bassi tassi di ammissione, mentre gli uomini si candidano di più in dipartimenti con tassi di ammissione più alti.\n\nMoralità: Non sempre una differenza aggregata indica un bias. Bisogna analizzare i sottogruppi.\nEsercizio 5: Analisi causale con DAG\n\nVariabili confondenti\n\nG è una variabile confondente perché influenza sia E (esposizione) che H (esito).\n\nBack-door paths\n\nIl percorso E ← G → H è un back-door path che deve essere bloccato.\n\nSoluzione: controllare per G\nadjustmentSets(dag)\nOutput: {G}\n→ Controllare per G permette di ottenere una stima causale non distorta di E su H.\n\nConclusioni\n\nLa correlazione non implica causalità. Abbiamo visto come variabili confondenti possano generare relazioni spurie.\n\nIl paradosso di Simpson dimostra che i dati aggregati possono essere fuorvianti. Bisogna sempre analizzare i sottogruppi.\n\nI DAG aiutano a identificare le variabili da controllare per ottenere stime causali corrette.\n\nL’analisi causale è fondamentale per evitare inferenze errate e migliorare la qualità della ricerca.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#bibliografia",
    "href": "chapters/eda/09_causality.html#bibliografia",
    "title": "22  Causalità dai dati osservazionali",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlexander, R. (2023). Telling Stories with Data: With Applications in R. Chapman; Hall/CRC.\n\n\nByrnes, J. E., & Dee, L. E. (2024). Causal inference with observational data and unobserved confounding variables. bioRxiv, 2024–2002.\n\n\nHardt, M., & Recht, B. (2022). Patterns, Predictions, and Actions: Foundations of Machine Learning. Princeton University Press.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nPearl, J. (2009). Causality. Cambridge University Press.\n\n\nRiederer, E. (2021). Causal design patterns for data analysts. https://emilyriederer.netlify.app/post/causal-design-patterns/\n\n\nSchennach, S. M. (2016). Recent advances in the measurement error literature. Annual Review of Economics, 8(1), 341–377.\n\n\nWilms, R., Mäthner, E., Winnen, L., & Lanwehr, R. (2021). Omitted variable bias: A threat to estimating causal relationships. Methods in Psychology, 5, 100075.\n\n\nZwet, E. van, Gelman, A., Greenland, S., Imbens, G., Schwab, S., & Goodman, S. N. (2023). A New Look at P Values for Randomized Clinical Trials. NEJM Evidence, 3(1), EVIDoa2300003.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html",
    "href": "chapters/eda/10_estimand.html",
    "title": "23  Estimandi teorici e estimandi empirici",
    "section": "",
    "text": "23.1 Introduzione\nNei capitoli precedenti, abbiamo esaminato tecniche di analisi esplorativa dei dati, strumenti essenziali per sintetizzare informazioni e descrivere relazioni tra variabili. Tuttavia, queste metodologie presuppongono che le variabili siano misurate in modo coerente con la domanda teorica di ricerca. Emerge così un problema centrale: come collegare validamente i costrutti teorici ai dati osservati? La risposta risiede nella definizione rigorosa dell’estimando, il parametro che funge da ponte tra astrazione teorica e realtà empirica.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#introduzione",
    "href": "chapters/eda/10_estimand.html#introduzione",
    "title": "23  Estimandi teorici e estimandi empirici",
    "section": "",
    "text": "23.1.1 Che Cos’è l’Estimando?\nL’estimando rappresenta la quantità specifica che l’analisi statistica mira a stimare, definendo il “bersaglio” dell’inferenza. Nelle scienze psicologiche, dove fenomeni come intelligenza, emozioni o atteggiamenti sono costrutti latenti, questa definizione è cruciale per evitare discrepanze tra ipotesi teoriche e risultati empirici.\n\n23.1.1.1 Due Dimensioni dell’Estimando\nPer garantire rigore metodologico, è necessario distinguere due livelli:\n\nEstimando teorico: il costrutto astratto definito dalla teoria, non direttamente osservabile (es. ansia di tratto, autostima).\n\nEstimando empirico: la misura operazionale derivata da strumenti concreti (es. punteggi di questionari).\n\nEsempio.\nConsideriamo l’ansia di tratto, definita teoricamente come una tendenza stabile a sperimentare stati ansiosi. Pur essendo un costrutto centrale nella psicologia della personalità, non è osservabile direttamente. Per stimarla, si ricorre a strumenti come lo State-Trait Anxiety Inventory (STAI-T), un questionario che include item come “Mi sento spesso nervoso senza motivo apparente”. Le risposte aggregate generano un punteggio totale, che costituisce l’estimando empirico. Tuttavia, questo punteggio è solo una proxy del costrutto teorico: misura un aspetto specifico (es. autovalutazione soggettiva) senza esaurire la complessità dell’ansia di tratto.\n\n\n\n23.1.2 Rischi dello Story-Telling e Strategie di Mitigazione\nIn molte pubblicazioni psicologiche, il legame tra teoria e dati è costruito attraverso narrative persuasive (story-telling), approccio che sostituisce il rigore metodologico con metafore suggestive. Questa pratica espone a tre rischi principali:\n\ncircolarità argomentativa: interpretare i dati in modo coerente con la teoria, senza verificarne i limiti.\n\nfalsi positivi: selezionare misure empiriche che “sembrano” supportare l’ipotesi, ignorando proxy più appropriate.\n\ngeneralizzazioni indebite: estendere conclusioni valide per un contesto specifico a costrutti teorici più ampi.\n\nPer contrastare questi problemi, Lundberg et al. (2021) propone strategie chiave:\n\npreregistrazione dell’estimando: specificare a priori come il costrutto teorico viene tradotto in variabili osservabili (munafo2017manuscript?).\n\nmodelli statistici espliciti: utilizzare framework (es. modelli strutturali) che mappino trasparentemente le relazioni teoria-dati.\n\nvalidità convergente: verificare che diverse misure dello stesso costrutto producano risultati coerenti.\n\n\n\n23.1.3 Impatto sulla Replicabilità Scientifica\nLa mancata definizione dell’estimando contribuisce alla crisi di replicabilità nelle scienze sociali. Studi che confondono stimande empirici ristretti con costrutti teorici ampi generano risultati non riproducibili in contesti diversi. Come evidenzia (oberauer2019inferential?), una dichiarazione esplicita dell’estimando riduce l’ambiguità interpretativa e facilita la verifica indipendente, pilastro del metodo scientifico.\n\n\n23.1.4 Sintesi delle Differenze\nLa tabella seguente riassume le distinzioni critiche tra stimandi teorici ed empirici:\n\n\n\n\n\n\n\n\nAspetto\nEstimando Teorico\nEstimando Empirico\n\n\n\n\nNatura\nCostrutto latente, astratto\nMisura quantitativa, osservabile\n\n\nEsempi\nIntelligenza, resilienza\nPunteggi a test STAI-T, tempi di reazione\n\n\nMisurabilità\nInferito indirettamente\nDerivato da dati strumentali\n\n\nFonte\nTeoria psicologica\nStrumenti di rilevazione\n\n\n\nDefinire formalmente l’estimando non è un mero esercizio tecnico, ma un atto di trasparenza intellettuale. Abbandonando lo story-telling a favore di una pianificazione rigorosa, la psicologia può rafforzare il dialogo tra teoria e dati, elevando la sua credibilità come disciplina scientifica. Come dimostrano i casi discussi, solo attraverso questa chiarezza concettuale è possibile costruire evidenze replicabili e avanzare nella comprensione dei fenomeni mentali.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#le-sfide-della-stima-degli-estimandi",
    "href": "chapters/eda/10_estimand.html#le-sfide-della-stima-degli-estimandi",
    "title": "23  Estimandi teorici e estimandi empirici",
    "section": "23.2 Le Sfide della Stima degli Estimandi",
    "text": "23.2 Le Sfide della Stima degli Estimandi\nL’uso di estimandi empirici per inferire estimandi teorici presenta diverse sfide metodologiche:\n\nValidità della Misura\n\nIl test STAI-T misura veramente l’ansia di tratto o cattura solo un aspetto superficiale dell’ansia?\nIndicatori fisiologici come il cortisolo o la conduttanza cutanea possono offrire altre proxy dell’ansia, ma con significati differenti.\n\nAffidabilità della Misura\n\nIl punteggio ottenuto è stabile nel tempo?\nSe un soggetto compila il test in momenti diversi, ottiene risultati simili?\n\nDistorsioni e Errori di Misura\n\nGli item del questionario potrebbero influenzare le risposte?\nI soggetti rispondono in modo onesto o sono condizionati da desiderabilità sociale?\n\nModelli Statistici e Inferenza Bayesiana\n\nI modelli fattoriali, le equazioni strutturali (SEM) e i modelli bayesiani sono strumenti essenziali per inferire estimandi teorici dai dati empirici.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#il-modello-fattoriale-latente",
    "href": "chapters/eda/10_estimand.html#il-modello-fattoriale-latente",
    "title": "23  Estimandi teorici e estimandi empirici",
    "section": "23.3 Il Modello Fattoriale Latente",
    "text": "23.3 Il Modello Fattoriale Latente\nL’ansia di tratto (\\(\\theta\\)) può essere modellata come una variabile latente tramite l’analisi fattoriale. Il modello assume la seguente forma:\n\\[\ny_i = \\lambda_i \\theta + \\epsilon_i ,\n\\tag{23.1}\\]\ndove:\n\n\\(y_i\\) è la risposta osservabile al singolo item (estimando empirico),\n\\(\\theta\\) è il livello latente di ansia di tratto (estimando teorico),\n\\(\\lambda_i\\) è il peso fattoriale dell’item, che indica quanto l’item misura il costrutto latente.\n\\(\\epsilon_i\\) è l’errore di misurazione.\n\nL’analisi fattoriale permette di:\n\nidentificare la struttura del costrutto,\nquantificare il contributo di ciascun item attraverso i pesi fattoriali (\\(\\lambda_i\\)),\nseparare la variabilità spiegata dalla variabilità attribuibile all’errore (\\(\\epsilon_i\\)).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#framework-di-lundberg2021your-il-collegamento-tra-teoria-e-dati",
    "href": "chapters/eda/10_estimand.html#framework-di-lundberg2021your-il-collegamento-tra-teoria-e-dati",
    "title": "23  Estimandi teorici e estimandi empirici",
    "section": "23.4 Framework di Lundberg et al. (2021): Il Collegamento tra Teoria e Dati",
    "text": "23.4 Framework di Lundberg et al. (2021): Il Collegamento tra Teoria e Dati\nLundberg et al. (2021) propongono un approccio metodologico in tre fasi:\n\ndefinire l’estimando teorico, ancorandolo esplicitamente alla teoria di riferimento,\ntradurre l’estimando teorico in un estimando empirico, ovvero una misura osservabile,\nstimare l’estimando empirico, applicando procedure statistiche adeguate.\n\n\nEsempio 23.1 Un esempio concreto è fornito dal modello di Rescorla-Wagner, applicato a compiti di Probabilistic Reversal Learning (PRL): l’estimando empirico potrebbe corrispondere a parametri come il tasso di apprendimento \\(\\alpha\\) o la temperatura inversa \\(\\beta\\). Questi parametri riflettono quanto i partecipanti modifichino i valori associati agli stimoli o regolino la strategia di scelta (esplorazione rispetto a sfruttamento).\nÈ importante notare che l’estimando empirico può essere stimato in modi diversi, utilizzando modelli, metodi di stima e disegni sperimentali vari. Il modello di Rescorla-Wagner è solo una possibile rappresentazione dell’apprendimento associativo, e i suoi parametri possono essere ricavati con procedure differenti. Di conseguenza, il valore numerico che descrive la capacità di apprendimento associativo dipende dal modello, dalla tecnica di stima e dal contesto sperimentale.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#conclusioni",
    "href": "chapters/eda/10_estimand.html#conclusioni",
    "title": "23  Estimandi teorici e estimandi empirici",
    "section": "23.5 Conclusioni",
    "text": "23.5 Conclusioni\nDefinire chiaramente l’estimando teorico è un passo fondamentale per garantire la validità delle inferenze scientifiche. Il framework di Lundberg et al. (2021) fornisce un metodo rigoroso per legare teoria e dati, migliorando la replicabilità e la coerenza degli studi psicologici.\nL’adozione di un approccio strutturato nella definizione degli estimandi consente di:\n\nchiarire gli obiettivi della ricerca,\ngarantire la coerenza tra teoria e dati,\nmigliorare la qualità e l’interpretazione delle inferenze statistiche.\n\nIn questo modo, la ricerca quantitativa può produrre risultati più solidi e generalizzabili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#esercizi",
    "href": "chapters/eda/10_estimand.html#esercizi",
    "title": "23  Estimandi teorici e estimandi empirici",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nEsercizio 1: Distinguere Estimando Teorico ed Empirico\n\nObiettivo: Comprendere la differenza tra costrutti latenti e misure osservabili.\n\nAttività: Scegli tre costrutti psicologici (es. autostima, ansia di tratto, empatia). Per ciascuno:\n\nDescrivi l’estimando teorico (cioè il costrutto latente).\n\nIdentifica un possibile estimando empirico (es. punteggio a un questionario).\n\nSpiega in che modo il passaggio dal costrutto latente alla misura osservabile potrebbe introdurre errori o distorsioni.\n\n\nEsercizio 2: Validità e Affidabilità di una Scala di Misura\n\nObiettivo: Riflettere sugli aspetti di validità (contenuto, costrutto) e affidabilità (stabilità delle misure) di uno strumento.\n\nAttività: Immagina di dover stimare il costrutto “ansia di prestazione” in atleti. Proponi:\n\nUn questionario o scala con 5 item, descrivendo i contenuti di ciascun item.\n\nUna strategia per valutare la validità (es. confrontare con un altro test già validato, definire i criteri di inclusione degli item).\n\nUna procedura per valutare l’affidabilità (es. test-retest, consistenza interna).\n\nUna breve discussione su possibili fonti di errore di misurazione (desiderabilità sociale, bias di risposta).\n\n\nEsercizio 3: Modello Fattoriale Latente\n\nObiettivo: Comprendere come un modello fattoriale colleghi risposte osservate a un costrutto latente.\n\nAttività: Supponi di avere 4 item che misurano il costrutto “senso di autoefficacia”. I punteggi di ogni item vanno da 1 (per niente d’accordo) a 5 (molto d’accordo). Ti vengono forniti dati fittizi per 10 persone (es. risposte in tabella).\n\nProva a ipotizzare come si potrebbe rappresentare l’equazione di un modello fattoriale (simile all’esempio nel testo con \\(y_i = \\lambda_i \\theta + \\epsilon_i\\)).\n\nIndica in parole semplici che cosa rappresentano \\(\\theta\\), \\(\\lambda_i\\) ed \\(\\epsilon_i\\) nel tuo esempio.\n\nElenca due vantaggi che un modello fattoriale offre rispetto al calcolo semplice di una media su tutti gli item.\n\n\nEsercizio 4: Definire l’Estimando per un Compito di Apprendimento\n\nObiettivo: Legare un esperimento e un modello a un preciso estimando teorico ed empirico.\n\nAttività: Immagina uno studio sperimentale di apprendimento in cui i partecipanti devono imparare la regola di associazione tra uno stimolo visivo e una ricompensa. Hai deciso di usare il modello di Rescorla-Wagner per stimare il tasso di apprendimento (\\(\\alpha\\)) di ciascun partecipante.\n\nDescrivi l’estimando teorico che ti interessa (es. “capacità di aggiornare le aspettative in base al feedback”).\n\nSpiega in che modo l’estimando empirico (\\(\\alpha\\)) è derivato dai dati osservati (scelte del partecipante, errori, risposte corrette).\n\nElenca due possibili ragioni per cui il valore di \\(\\alpha\\) ottenuto può essere diverso in base alla procedura di stima (es. tipo di algoritmo, impostazioni iniziali).\n\n\nEsercizio 5: Criticità nell’Interpretazione degli Estimandi\n\nObiettivo: Riflettere sui possibili fattori che rendono complessa l’interpretazione del punteggio stimato.\n\nAttività: Scegli un qualsiasi costrutto psicologico (es. impulsività, motivazione al successo, stile di attaccamento). Immagina di avere uno strumento (questionario, test computerizzato o altro) che fornisce un punteggio finale come estimando empirico.\n\nSpiega come l’errore di misurazione (rumore, bias di risposta, item poco chiari) può influire sull’interpretazione del punteggio.\n\nDescrivi una situazione in cui il punteggio osservato potrebbe non riflettere correttamente il costrutto latente (es. persona che risponde in modo poco sincero).\n\nProponi due strategie per migliorare la validità della misura (es. aggiungere item, utilizzare misurazioni multiple, integrazione con misure fisiologiche, controlli statistici, ecc.).\n\n\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\nEsercizio 1: Distinguere Estimando Teorico ed Empirico\n\nAutostima\n\nEstimando teorico: L’idea di “auto-valutazione globale positiva o negativa di sé” (construct della psicologia della personalità). Non si misura direttamente, ma è un concetto chiave per spiegare comportamenti di auto-efficacia, soddisfazione, ecc.\n\nEstimando empirico: Punteggio ottenuto dal Rosenberg Self-Esteem Scale (RSES), una scala di 10 item con punteggi da 0 a 30.\n\nErrori/distorsioni: Possibile desiderabilità sociale: il partecipante potrebbe tendere a rispondere in modo da apparire migliore; eventuale variazione linguistica nella comprensione degli item.\n\nAnsia di tratto\n\nEstimando teorico: Tendenza stabile a sperimentare preoccupazione, nervosismo, e tensione in varie situazioni (componente relativamente stabile).\n\nEstimando empirico: Punteggio della sezione Trait (T) del State-Trait Anxiety Inventory (STAI-T).\n\nErrori/distorsioni: Bias di risposta (es. risposte casuali, eccessiva fretta), scarsa onestà, influenza dell’umore momentaneo (che dovrebbe riflettere l’ansia di stato, non di tratto).\n\nEmpatia\n\nEstimando teorico: Capacità di comprendere e condividere lo stato emotivo altrui, distinta in componente cognitiva e affettiva.\n\nEstimando empirico: Punteggio al Davis Interpersonal Reactivity Index (IRI) o un’altra scala self-report sull’empatia.\n\nErrori/distorsioni: Limitazione del formato self-report nel catturare l’aspetto empatico reale in situazioni quotidiane, possibili misunderstanding di alcuni item.\n\n\nEsercizio 2: Validità e Affidabilità di una Scala di Misura\n\nQuestionario a 5 item (risposte su scala Likert 1–5):\n\n“Prima di una gara, mi preoccupo di non riuscire a gestire la pressione.”\n\n“Penso spesso a come potrei sbagliare durante la competizione.”\n\n“Mi sento nervoso/a e teso/a molto tempo prima di iniziare la performance.”\n\n“Ho la sensazione di non essere all’altezza di ciò che ci si aspetta da me.”\n\n“Faccio fatica a concentrare l’attenzione sui miei obiettivi sportivi.”\n\nStrategia per valutare la validità\n\nValidità di contenuto: confrontare gli item con la letteratura specialistica sull’ansia di prestazione (chiedere feedback a esperti in psicologia dello sport).\n\nValidità concorrente: somministrare il questionario insieme a un altro strumento già validato per l’ansia di prestazione (o con una misura fisiologica di stress, come frequenza cardiaca a riposo).\n\nValidità di costrutto: correlare i punteggi con scale simili (es. STAI) e verificare che siano più alti in atleti di sport ad alta pressione (es. gare individuali).\n\nProcedura per valutare l’affidabilità\n\nTest-retest: somministrare la scala a un gruppo di atleti a distanza di 2 settimane, verificando la correlazione tra i punteggi.\n\nConsistenza interna: calcolare l’α di Cronbach per stimare in che misura gli item misurano un costrutto coerente.\n\nPossibili fonti di errore\n\nBias di desiderabilità sociale (l’atleta potrebbe minimizzare la propria ansia).\n\nStato emotivo contingente (per es., stress esterno non legato allo sport).\n\nSituazione specifica dell’atleta il giorno della compilazione (stanchezza, problemi personali, ecc.).\n\n\nEsercizio 3: Modello Fattoriale Latente\n\nEquazione di un modello fattoriale (semplificata)\n\\[\ny_i = \\lambda_i \\,\\theta + \\epsilon_i \\quad\\quad (i=1,2,3,4),\n\\]\ndove\n\n\\(y_i\\) è la risposta all’item \\(i\\),\n\n\\(\\theta\\) è il livello latente di autoefficacia,\n\n\\(\\lambda_i\\) è il peso fattoriale per l’item \\(i\\),\n\n\\(\\epsilon_i\\) è l’errore di misurazione per l’item \\(i\\).\n\nDescrizione dei termini:\n\n\\(\\theta\\): il “vero” senso di autoefficacia che non possiamo osservare direttamente.\n\n\\(\\lambda_i\\): indica quanto ciascun item riflette il costrutto; se \\(\\lambda_i\\) è alto, l’item è molto rappresentativo.\n\n\\(\\epsilon_i\\): comprende errori casuali, interpretazioni errate, ecc.\n\nDue vantaggi del modello fattoriale:\n\nGestione dell’errore: il modello separa la parte di variabilità dovuta al costrutto da quella dovuta all’errore (mentre la media “mescola” entrambe).\n\nIndagine del peso di ciascun item: possiamo capire se un item è fortemente o debolmente collegato al costrutto, migliorando la validità dello strumento.\n\n\nEsercizio 4: Definire l’Estimando per un Compito di Apprendimento\n\nEstimando teorico\n\nL’“abilità di adeguare il comportamento in funzione degli esiti passati” corrisponde al grado di plasticità dell’apprendimento. Non osserviamo “direttamente” questa abilità, che resta un costrutto astratto.\n\nEstimando empirico (\\(\\alpha\\))\n\nNel modello di Rescorla-Wagner, dopo ogni prova la stima del valore dello stimolo si aggiorna in base all’errore di predizione.\n\nDati osservati: scelte del partecipante, premio o penalità ricevuti, differenze tra aspettative e risultati effettivi.\n\n\\(\\alpha\\) si stima applicando un metodo di ottimizzazione (per es. regressione non lineare, massima verosimiglianza, o un approccio bayesiano) che riduce lo scarto tra le previsioni del modello e il comportamento (scelte corrette/errate) del partecipante.\n\nDue ragioni per cui \\(\\alpha\\) varia\n\nDifferenti procedure di ottimizzazione: alcuni algoritmi convergono a un valore locale invece che globale, oppure usano penali diverse per la complessità del modello.\n\nVarie formulazioni del modello: si potrebbero introdurre parametri addizionali (ad es. \\(\\beta\\) per la “temperatura inversa” o funzioni di apprendimento leggermente diverse) che modificano il valore ottimale di \\(\\alpha\\).\n\n\nEsercizio 5: Criticità nell’Interpretazione degli Estimandi\n\nCostrutto: Impulsività\n\nStrumento: Una scala di autovalutazione (es. Barratt Impulsiveness Scale)\n\n\nInfluenza dell’errore di misurazione\n\nSe un individuo compila la scala in un momento di forte stress o fretta, le sue risposte possono enfatizzare un aspetto temporaneo invece che stabile.\n\nPiccoli errori (item poco chiari, interpretazioni ambigue) si sommano, distorcendo il punteggio finale.\n\nSituazione in cui il punteggio non rispecchia il costrutto latente\n\nUna persona tende a presentarsi in modo socialmente desiderabile, dunque minimizza i comportamenti impulsivi. Di fatto, il punteggio osservato sarà basso, ma non rappresenta il vero livello di impulsività.\n\nDue strategie per migliorare la validità\n\nAggiungere item e fonti multiple: utilizzare più item su diverse sfaccettature dell’impulsività e integrare dati osservazionali o indicatori oggettivi (per es. tempi di reazione in un test computerizzato).\n\nRidurre la desiderabilità sociale: rendere le risposte anonime, istruendo i partecipanti sull’importanza di risposte autentiche, o aggiungere un indice di tendenza alla risposta “socialmente accettabile”.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#bibliografia",
    "href": "chapters/eda/10_estimand.html#bibliografia",
    "title": "23  Estimandi teorici e estimandi empirici",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nLundberg, I., Johnson, R., & Stewart, B. M. (2021). What is your estimand? Defining the target quantity connects statistical evidence to theory. American Sociological Review, 86(3), 532–565.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html",
    "href": "chapters/eda/11_outlier.html",
    "title": "24  Outlier",
    "section": "",
    "text": "24.1 Introduzione\nQuando analizziamo dati reali, ci imbattiamo spesso in osservazioni che sembrano molto diverse dalla maggior parte delle altre. Questi valori anomali, chiamati outlier, possono avere origini diverse. Ad esempio, potrebbero derivare da errori di misura o inserimento dati, oppure essere casi estremi ma comunque validi.\nIdentificare e trattare gli outlier in modo appropriato è importante per evitare che distorcano i risultati dell’analisi. Tuttavia, non esiste una definizione universale di outlier: dipende dal contesto e dall’obiettivo dell’analisi.\nIn questo capitolo, esploreremo diversi metodi per individuare gli outlier, concentrandoci su tecniche robuste che minimizzano l’influenza di questi valori anomali sulle statistiche descrittive (Simmons et al., 2011).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#individuare-e-gestire-gli-outlier",
    "href": "chapters/eda/11_outlier.html#individuare-e-gestire-gli-outlier",
    "title": "24  Outlier",
    "section": "\n24.2 Individuare e Gestire gli outlier",
    "text": "24.2 Individuare e Gestire gli outlier\nIdentificare ed eventualmente eliminare gli outlier rappresenta una fase cruciale dell’analisi dei dati, poiché la presenza di valori anomali può influenzare fortemente le conclusioni che si traggono da analisi statistiche. Gli outlier possono infatti alterare notevolmente statistiche descrittive come media e deviazione standard, ma anche misure di relazione come correlazioni e regressioni. Ciò avviene perché molte tecniche statistiche comuni (ad esempio, la media aritmetica o la regressione lineare con metodo dei minimi quadrati) sono particolarmente sensibili ai valori estremi.\nAd esempio, se stiamo analizzando il reddito medio di un gruppo di persone e includiamo erroneamente dati di reddito estremamente elevati o inseriti per errore, la media risultante sarà molto più alta del reale valore tipico del gruppo, producendo una rappresentazione fuorviante della situazione.\n\n24.2.1 L’importanza della Visualizzazione dei Dati\nLa rappresentazione grafica dei dati è uno strumento fondamentale per individuare rapidamente la presenza di outlier. Grafici come boxplot, istogrammi e scatterplot consentono di identificare visivamente valori anomali che si discostano dalla distribuzione generale.\nTuttavia, queste tecniche sono efficaci principalmente per outlier unidimensionali o bidimensionali. Nel caso di outlier multidimensionali, l’analisi visiva diventa insufficiente e si rende necessario l’utilizzo di metodi statistici più avanzati, come il calcolo della distanza di Mahalanobis.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#come-identificare-gli-outlier",
    "href": "chapters/eda/11_outlier.html#come-identificare-gli-outlier",
    "title": "24  Outlier",
    "section": "\n24.3 Come Identificare gli Outlier",
    "text": "24.3 Come Identificare gli Outlier\nOltre alla visualizzazione grafica, esistono tecniche statistiche specifiche che consentono di identificare gli outlier in modo sistematico.\n\n24.3.1 I Boxplot\nUno strumento semplice e intuitivo per individuare gli outlier è il boxplot. Il boxplot riassume la distribuzione di una variabile mostrando la mediana, il primo e il terzo quartile (Q1 e Q3) e due estremi, detti “whiskers”. I punti al di fuori di questi whiskers sono considerati potenziali outlier.\nEsempio in R:\n\ndata &lt;- data.frame(\n  value = c(rnorm(100, mean = 10, sd = 2), 30)\n  ) # Aggiungiamo un outlier\n\nggplot(data, aes(y = value)) +\n  geom_boxplot() +\n  coord_flip()\n\n\n\n\n\n\n\nSe il boxplot mostra un punto isolato lontano dagli altri dati, potrebbe essere un outlier.\n\n24.3.2 Metodi Basati sulla Variabilità\n\n24.3.2.1 Intervallo Interquartile (IQR)\nJohn Tukey ha introdotto una definizione operativa di outlier basata sull’Interquartile Range (IQR), ovvero la differenza tra il terzo e il primo quartile:\n\nI valori inferiori a \\(Q1 - 1.5 \\times IQR\\) o superiori a \\(Q3 + 1.5 \\times IQR\\) sono considerati outlier moderati.\nI valori oltre \\(Q1 - 3 \\times IQR\\) o \\(Q3 + 3 \\times IQR\\) sono definiti far out outliers.\n\nEsempio in R:\n\nQ1 &lt;- quantile(data$value, 0.25)\nQ3 &lt;- quantile(data$value, 0.75)\nIQR_value &lt;- Q3 - Q1\nlower_bound &lt;- Q1 - 1.5 * IQR_value\nupper_bound &lt;- Q3 + 1.5 * IQR_value\n\noutliers &lt;- data$value[data$value &lt; lower_bound | data$value &gt; upper_bound]\noutliers\n#&gt; [1]  4.687  4.014 30.000\n\nQuesto metodo è efficace per distribuzioni simmetriche, ma potrebbe non funzionare bene con dati asimmetrici.\n\n24.3.2.2 Median Absolute Deviation (MAD)\nUn metodo più robusto rispetto all’IQR è il Median Absolute Deviation (MAD), che utilizza la mediana anziché la media per stimare la dispersione:\n\nmad_value &lt;- mad(data$value)\nthreshold &lt;- 3 * mad_value # Soglia classica per gli outlier\n\noutliers_mad &lt;- data$value[abs(data$value - median(data$value)) &gt; threshold]\noutliers_mad\n#&gt; [1]  4.014 30.000\n\nIl MAD è meno sensibile agli outlier rispetto alla deviazione standard ed è spesso preferito per dati con distribuzioni non normali.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#outlier-multivariati",
    "href": "chapters/eda/11_outlier.html#outlier-multivariati",
    "title": "24  Outlier",
    "section": "\n24.4 Outlier Multivariati",
    "text": "24.4 Outlier Multivariati\nQuando si considerano più variabili contemporaneamente, un valore potrebbe non apparire anomalo su una singola variabile, ma esserlo nel contesto dell’intero dataset. Un metodo comune per individuare questi outlier è la Distanza di Mahalanobis, che tiene conto delle correlazioni tra variabili.\n\nCon la distanza “normale” (come quella che misuri con un righello), se una persona è più alta o più pesante della media, la distanza è calcolata in modo “isolato”, senza considerare che altezza e peso sono spesso correlate (persone più alte tendono a pesare di più).\nCon la distanza di Mahalanobis, invece, si osserva il “contesto” dei dati. Se tutti nel gruppo hanno un’altezza e un peso che crescono in modo coordinato (ad esempio, ogni 10 cm in più corrispondono a 8 kg in più), questa distanza valuta se la nuova persona si allontana da questo schema generale. Ad esempio, una persona molto alta ma con peso medio potrebbe essere considerata più “anomala” di una persona altrettanto alta ma più pesante, perché viola la relazione tipica del gruppo.\n\nPer comprendere intuitivamente la distanza di Mahalanobis, immaginiamo di avere una nube di punti che rappresentano individui, ciascuno con i propri valori di altezza e peso. Il “centro” di questa nube è un punto ideale che rappresenta una sorta di media multivariata (tenendo conto sia dell’altezza sia del peso). La distanza di Mahalanobis misura quanto ogni singolo individuo si allontana da questo centro, considerando la variabilità congiunta delle variabili (ad esempio, la correlazione tra altezza e peso). Se un individuo presenta caratteristiche molto diverse rispetto alla maggioranza, la sua distanza di Mahalanobis sarà elevata, segnalando un potenziale outlier.\n\n\n\n\n\nFigura 24.1: Soglie per la detezione degli outliers (bande grigie) nel caso di una metrica unidimensionale (pannello di sinistra) e nel caso di una rappresentazione multivariata della varianza (pannello di destra) – figura creata da Sergen Cansiz.\n\n\n\n\n\n\n\n\nDistanza di Mahalanobis\n\n\n\n\n\nConsideriamo ora una definizione della distanza di Mahalanobis nel caso bivariato (due variabili). Immaginiamo di avere due variabili come altezza (\\(X\\)) e peso (\\(Y\\)), con:\n\n\nMedie: \\(\\mu_X\\) (altezza media del gruppo), \\(\\mu_Y\\) (peso medio del gruppo).\n\n\nVarianze: \\(\\sigma_X^2\\) (quanto varia l’altezza), \\(\\sigma_Y^2\\) (quanto varia il peso).\n\n\nCorrelazione: \\(\\rho\\) (quanto \\(X\\) e \\(Y\\) sono legate, ad esempio: se l’altezza aumenta, di quanto aumenta solitamente il peso?).\n\nPer un nuovo individuo con altezza \\(x\\) e peso \\(y\\), la distanza di Mahalanobis (\\(D\\)) si calcola così:\n\n\nCalcolare le differenze rispetto alla media:\n\nQuanto si discosta l’altezza: \\((x - \\mu_X)\\).\nQuanto si discosta il peso: \\((y - \\mu_Y)\\).\n\n\n\nScalare le differenze con le varianze:\n\n\nDividere ogni differenza per la sua “variabilità tipica” (deviazione standard \\(\\sigma_X\\) e \\(\\sigma_Y\\)):\n\\[\n\\frac{(x - \\mu_X)}{\\sigma_X} \\quad \\text{e} \\quad \\frac{(y - \\mu_Y)}{\\sigma_Y} .\n\\]\n\n\n\n\nCorreggere per la correlazione:\n\nSe \\(X\\) e \\(Y\\) sono correlate (\\(\\rho \\neq 0\\)), modifica le differenze per tenere conto di come di solito si “muovono insieme”.\n\nLa formula finale combina tutto in un unico valore:\\[\nD = \\sqrt{ \\frac{ \\left( \\frac{(x - \\mu_X)}{\\sigma_X} \\right)^2 + \\left( \\frac{(y - \\mu_Y)}{\\sigma_Y} \\right)^2 - 2 \\rho \\left( \\frac{(x - \\mu_X)}{\\sigma_X} \\right)\\left( \\frac{(y - \\mu_Y)}{\\sigma_Y} \\right) }{1 - \\rho^2} }\n\\]\n\n\n\n\nSpiegazione:\n\nSenza correlazione (\\(\\rho = 0\\)), sarebbe come una distanza Euclidea “scalata” dalle varianze.\n\nCon correlazione (\\(\\rho \\neq 0\\)), sottrai un termine che “aggiusta” la distanza in base a quanto \\(X\\) e \\(Y\\) tendono a variare insieme.\n\nIl denominatore \\(1 - \\rho^2\\) normalizza il risultato, per evitare che la correlazione distorca troppo la misura.\n\nEsempio:\nSe tutti gli alti sono anche pesanti (\\(\\rho\\) positivo), un individuo alto ma magro avrà una distanza di Mahalanobis maggiore rispetto a uno altrettanto alto ma pesante, perché viola la relazione tipica del gruppo.\n\n\n\n\n\n\n\n\n\nDistanza Eucliea\n\n\n\n\n\nRicordiamo che la distanza euclidea tra due punti \\((x_1, y_1)\\) e \\((x_2, y_2)\\) in un piano cartesiano è definita come:\n\\[\nd = \\sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2}\n\\]\n\n\n\nEsempio in R:\n\nX &lt;- as.matrix(mtcars[, c(\"mpg\", \"hp\")])\ncenter &lt;- colMeans(X)\ncov_matrix &lt;- cov(X)\nmahal_dist &lt;- mahalanobis(X, center, cov_matrix)\n\nthreshold &lt;- qchisq(0.975, df = ncol(X)) # Soglia al 97.5%\noutliers_mahal &lt;- X[mahal_dist &gt; threshold, ]\noutliers_mahal\n#&gt; mpg  hp \n#&gt;  15 335\n\nQuesto metodo è utile per dataset con più variabili correlate, come misure biometriche (altezza e peso).\nTuttavia, la versione classica di questa misura non è particolarmente robusta: la presenza stessa di outlier può distorcere il calcolo del “centro” e della variabilità complessiva, rendendo meno affidabile l’individuazione di altri valori anomali. Per questo motivo, si preferisce utilizzare una variante più resistente, la Minimum Covariance Determinant (MCD), che diminuisce l’influenza degli outlier stessi nel processo di identificazione.\nAll’interno del pacchetto {performance} in R, è possibile applicare questa variante robusta utilizzando la funzione check_outliers() con l’argomento method = \"mcd\". In questo modo, è possibile individuare gli outlier multivariati in maniera più solida e coerente, anche quando si lavora con dati fortemente influenzati da valori estremi.\n\nd &lt;- mtcars[, c(\"mpg\", \"hp\")]\noutliers &lt;- performance::check_outliers(d, method = \"mcd\", verbose = FALSE)\noutliers\n#&gt; 2 outliers detected: cases 20, 31.\n#&gt; - Based on the following method and threshold: mcd (13.816).\n#&gt; - For variables: mpg, hp.\n\nSi possono poi visualizzare questi outlier:\n\nplot(outliers)\n\n\n\n\n\n\n\nSono disponibili anche altre varianti multivariate documentate nella help page della funzione.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#cosa-fare-con-gli-outlier",
    "href": "chapters/eda/11_outlier.html#cosa-fare-con-gli-outlier",
    "title": "24  Outlier",
    "section": "\n24.5 Cosa Fare con gli Outlier?",
    "text": "24.5 Cosa Fare con gli Outlier?\nUna volta identificati gli outlier, dobbiamo decidere se rimuoverli, correggerli o mantenerli (Leys et al., 2019). Alcuni approcci comuni includono:\n\n\nVerificare la fonte del dato: un errore di inserimento può essere corretto.\n\nRimuovere gli outlier estremi: utile se il valore è chiaramente un errore di misura.\n\nUsare metodi robusti: strumenti come la mediana o il MAD sono meno influenzati dagli outlier.\n\nTrasformare i dati: applicare logaritmi o altre trasformazioni può ridurre l’impatto degli outlier.\n\nWinsorizzazione: invece di rimuovere gli outlier, possiamo limitarli a un massimo accettabile.\n\n\n\n\n\n\n\nWinsorizzazione\n\n\n\n\n\nNella Winsorizzazione, invece di eliminare gli outlier, si sostituiscono i valori troppo alti o troppo bassi con i valori più vicini considerati “accettabili”, mantenendo però la struttura generale dei dati.\nCome funziona?\n1. Definisci i limiti:\n\nDecidi una “soglia” per identificare gli outlier, ad esempio il 5° percentile (valore sotto cui cade il 5% dei dati più bassi) e il 95° percentile (valore sopra cui cade il 5% dei dati più alti).\n\nQueste soglie dipendono dal contesto: puoi usare percentili diversi (es. 1° e 99°) in base a quanto vuoi essere severo nel definire gli outlier.\n\n\n\nSostituisci gli outlier:\n\n\nValori troppo bassi: Tutti i dati sotto il 5° percentile vengono sostituiti con il valore del 5° percentile.\n\n\nValori troppo alti: Tutti i dati sopra il 95° percentile vengono sostituiti con il valore del 95° percentile.\n\n\n\nEsempio concreto:\nSupponiamo di avere i seguenti dati su 10 esami (ordinati):40, 55, 60, 65, 70, 75, 80, 85, 90, 200\n\n\n5° percentile: 55 (il valore sotto cui cade il 5% dei dati).\n\n\n95° percentile: 90 (il valore sopra cui cade il 5% dei dati).\n\nDopo la Winsorizzazione:\n- Il valore più basso (40) diventa 55.\n- Il valore più alto (200) diventa 90.\nNuovi dati: 55, 55, 60, 65, 70, 75, 80, 85, 90, 90.\nPerché usarla?\n\n\nMantiene la dimensione del dataset: Non si eliminano dati, ma si modificano solo gli outlier.\n\nRiduce la distorsione: Gli outlier estremi non “trascinano” la media o altre statistiche.\n\n\nUtile in contesti sensibili: Ad esempio, in finanza (per gestire rendimenti anomali) o nelle analisi mediche (per evitare che valori estremi falsino i risultati).\n\n\n\n\nNel pacchetto easystats, la funzione winsorize() di datawizard semplifica il compito di Winsorizzazione:\nwinsorized_data &lt;- \n  winsorize(data$value, method = \"zscore\", robust = TRUE, threshold = 3)",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#importanza-della-trasparenza",
    "href": "chapters/eda/11_outlier.html#importanza-della-trasparenza",
    "title": "24  Outlier",
    "section": "\n24.6 Importanza della Trasparenza",
    "text": "24.6 Importanza della Trasparenza\nQualunque decisione va documentata chiaramente: quanti outlier sono stati individuati, con quale metodo, a quale threshold, come sono stati gestiti, e preferibilmente con il codice R utilizzato. La preregistrazione e la condivisione dei dati e del codice (ad es. su OSF) sono pratiche consigliate per garantire riproducibilità e trasparenza.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#riflessioni-conclusive",
    "href": "chapters/eda/11_outlier.html#riflessioni-conclusive",
    "title": "24  Outlier",
    "section": "\n24.7 Riflessioni Conclusive",
    "text": "24.7 Riflessioni Conclusive\nAbbiamo mostrato come identificare gli outlier in modo coerente e trasparente, allineandoci alle buone pratiche correnti. Tuttavia, la buona pratica non si limita alla scelta degli algoritmi: è fondamentale anche preregistrare le decisioni, essere coerenti, trasparenti e fornire giustificazioni.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#esercizi",
    "href": "chapters/eda/11_outlier.html#esercizi",
    "title": "24  Outlier",
    "section": "\n24.8 Esercizi",
    "text": "24.8 Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nDomande teoriche\n\nCos’è un outlier?\nPerché è importante identificare e trattare correttamente gli outlier?\nDescrivi brevemente il metodo del boxplot per identificare gli outlier.\nCosa si intende per Interquartile Range (IQR) e come viene utilizzato per individuare gli outlier?\nQual è la differenza tra il metodo IQR e il Median Absolute Deviation (MAD) per l’identificazione degli outlier?\nCos’è la distanza di Mahalanobis e in che modo può aiutare nell’identificazione degli outlier multivariati?\nPerché la distanza di Mahalanobis classica potrebbe non essere robusta? Come si può migliorare l’approccio?\nQuali sono le opzioni per gestire gli outlier una volta identificati?\nCos’è la Winsorizzazione e in quali casi potrebbe essere utile?\nPerché è importante la trasparenza nelle decisioni riguardanti gli outlier?\n\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\n\n\nCos’è un outlier?\n\nUn outlier è un’osservazione che si discosta significativamente dalla maggior parte delle altre osservazioni in un insieme di dati. Può essere dovuto ad errori di misura, errori di inserimento dati o a casi estremi ma validi.\n\n\n\nPerché è importante identificare e trattare correttamente gli outlier?\n\nGli outlier possono distorcere i risultati dell’analisi statistica, portando a conclusioni errate. Identificarli e trattarli correttamente aiuta a ridurre l’effetto di questi valori anomali sulle statistiche descrittive e sulle inferenze statistiche.\n\n\n\nDescrivi brevemente il metodo del boxplot per identificare gli outlier.\n\nIl boxplot visualizza la distribuzione di una variabile, mostrando la mediana, il primo e il terzo quartile, e due estremi (“whiskers”). I punti al di fuori di questi whiskers sono considerati potenziali outlier.\n\n\n\nCosa si intende per Interquartile Range (IQR) e come viene utilizzato per individuare gli outlier?\n\nL’IQR è la differenza tra il terzo e il primo quartile di un insieme di dati. Valori inferiori a \\(Q1 - 1.5 \\times IQR\\) o superiori a \\(Q3 + 1.5 \\times IQR\\) sono considerati outlier moderati. Valori oltre \\(Q1 - 3 \\times IQR\\) o \\(Q3 + 3 \\times IQR\\) sono definiti “far out” outliers.\n\n\n\nQual è la differenza tra il metodo IQR e il Median Absolute Deviation (MAD) per l’identificazione degli outlier?\n\nIl metodo IQR si basa sulla differenza tra il terzo e il primo quartile, mentre il MAD utilizza la mediana delle deviazioni assolute dalla mediana per stimare la dispersione. Il MAD è meno sensibile agli outlier rispetto all’IQR e alla deviazione standard, rendendolo preferibile per dati con distribuzioni non normali.\n\n\n\nCos’è la distanza di Mahalanobis e in che modo può aiutare nell’identificazione degli outlier multivariati?\n\nLa distanza di Mahalanobis misura quanto un punto si discosta dal centro della distribuzione di un set di dati multivariato, tenendo conto della correlazione tra le variabili. Valori con distanze di Mahalanobis elevate sono potenziali outlier multivariati.\n\n\n\nPerché la distanza di Mahalanobis classica potrebbe non essere robusta? Come si può migliorare l’approccio?\n\nLa distanza di Mahalanobis classica può essere distorta dalla presenza di outlier, che influenzano il calcolo del centro e della variabilità complessiva. Un approccio più robusto è la Minimum Covariance Determinant (MCD), che riduce l’influenza degli outlier nel processo di identificazione.\n\n\n\nQuali sono le opzioni per gestire gli outlier una volta identificati?\n\nLe opzioni includono: verificare la fonte del dato per possibili errori, rimuovere gli outlier estremi, usare metodi robusti come la mediana o il MAD, trasformare i dati (ad esempio, logaritmi), e limitare gli outlier attraverso la Winsorizzazione.\n\n\n\nCos’è la Winsorizzazione e in quali casi potrebbe essere utile?\n\nLa Winsorizzazione è una tecnica che consiste nel sostituire gli outlier estremi con il valore massimo o minimo accettabile. È utile quando si vuole mantenere la dimensione del dataset e ridurre l’impatto degli outlier senza rimuoverli completamente.\n\n\nPerché è importante la trasparenza nelle decisioni riguardanti gli outlier?\n\n\nLa trasparenza aiuta a garantire la riproducibilità e la validità dell’analisi. Documentare le decisioni, inclusi i metodi e i threshold utilizzati, consente ad altri di capire e valutare l’impatto di queste decisioni sui risultati dell’analisi.\n\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nEsercizio: Gestione degli Outlier nella Scala di Soddisfazione di Vita (SWLS)\nScopo:\nImparare a individuare e correggere gli outlier in un dataset che misura la soddisfazione di vita (SWLS). L’esercizio prevede l’inserimento artificiale di due outlier (uno molto alto e uno molto basso) nei dati raccolti, per poi gestirli con i metodi discussi nel capitolo. Infine, bisognerà consegnare:\n\nUn file .qmd (Quarto) con tutto il codice e i commenti delle operazioni svolte.\n\nUn file CSV finale con i dati “puliti” (ossia senza i due outlier anomali) o con i valori modificati mediante il metodo scelto (winsorizzazione, rimozione, correzione, ecc.).\n\nFasi e Istruzioni\n\n\nScarica o carica il dataset SWLS\n\nNominare il dataset originale, ad esempio SWLS_raw.csv, contenente i punteggi dei partecipanti sulla Scala di Soddisfazione di Vita (SWLS).\n\nAssicurati di avere nel dataset almeno le colonne:\n\n\nid (identificatore univoco del partecipante)\n\n\nswls_score (punteggio totale alla scala SWLS)\n\n\n\n\n\nCrea due outlier artificiali\n\nScegli un partecipante al quale assegnare un valore estremamente basso di swls_score (es. -999) e un altro partecipante con un valore estremamente alto (es. 999).\n\nSpiega brevemente nel .qmd dove e come hai inserito questi valori.\n\n\n\nAnalizza i dati alla ricerca di outlier\n\nVisualizza la distribuzione tramite un boxplot e/o un istogramma.\n\nCalcola i valori soglia utilizzando almeno uno dei metodi visti:\n\nIQR (intervallo interquartile)\n\nMAD (Median Absolute Deviation)\n\n\n\nMostra quali osservazioni vengono segnalate come potenziali outlier.\n\n\n\nDecidi come gestire gli outlier\n\nScegli se rimuoverli, winsorizzarli o correggerli.\n\nGiustifica la tua scelta: spiega perché quel metodo è appropriato per questi dati o perché preferisci un approccio rispetto a un altro.\n\n\n\nGenera i dati “puliti”\n\nApplica il metodo selezionato.\n\nSalva il dataset risultante (senza i valori anomali o con i valori modificati) in un file CSV chiamato SWLS_clean.csv.\n\n\n\nDocumenta tutto in un file .qmd\n\nIncludi codice R, commenti e brevi spiegazioni testuali dei vari passaggi.\n\nMostra i risultati rilevanti (boxplot, calcolo dei soglie IQR/MAD, elenco degli outlier individuati, ecc.).\n\nAssicurati di eseguire il rendering del .qmd in modo che l’istruttore possa vedere sia l’output che il codice.\n\n\n\nConsegnare i file\n\n\nFile .qmd: deve contenere tutto il codice e i passaggi effettuati (inclusi grafici, calcoli e spiegazioni).\n\n\nFile CSV “pulito” (SWLS_clean.csv): con i dati finali dopo il trattamento degli outlier.\n\n\n\nSuggerimenti\n\n\nStruttura il tuo .qmd in sezioni (ad es. Caricamento dati, Creazione outlier artificiali, Identificazione outlier, Gestione outlier, Salvataggio dati puliti).\n\n\nMotiva sempre le scelte, soprattutto se rimuovi o modifichi i dati originali: spiega perché il valore appare come un errore di misura o un valore estremo.\n\n\nFai controlli incrociati: potresti usare più di un metodo (boxplot, IQR, MAD) per vedere se l’outlier viene segnalato in tutti i casi.\n\n\nDocumenta la tua strategia di trasparenza nell’analisi: note sull’eventuale preregistrazione di come avresti gestito gli outlier o su come hai deciso i threshold.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/11_outlier.html#informazioni-sullambiente-di-sviluppo",
    "title": "24  Outlier",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] MASS_7.3-65        datawizard_1.1.0   performance_0.14.0\n#&gt;  [4] thematic_0.1.7     MetBrewer_0.2.0    ggokabeito_0.1.0  \n#&gt;  [7] see_0.11.0         gridExtra_2.3      patchwork_1.3.0   \n#&gt; [10] bayesplot_1.13.0   psych_2.5.3        scales_1.4.0      \n#&gt; [13] markdown_2.0       knitr_1.50         lubridate_1.9.4   \n#&gt; [16] forcats_1.0.0      stringr_1.5.1      dplyr_1.1.4       \n#&gt; [19] purrr_1.0.4        readr_2.1.5        tidyr_1.3.1       \n#&gt; [22] tibble_3.3.0       ggplot2_3.5.2      tidyverse_2.0.0   \n#&gt; [25] rio_1.2.3          here_1.0.1        \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.4     stringi_1.8.7      lattice_0.22-7    \n#&gt;  [4] hms_1.1.3          digest_0.6.37      magrittr_2.0.3    \n#&gt;  [7] evaluate_1.0.4     grid_4.5.0         timechange_0.3.0  \n#&gt; [10] RColorBrewer_1.1-3 fastmap_1.2.0      rprojroot_2.0.4   \n#&gt; [13] jsonlite_2.0.0     viridisLite_0.4.2  mnormt_2.1.1      \n#&gt; [16] cli_3.6.5          rlang_1.1.6        withr_3.0.2       \n#&gt; [19] tools_4.5.0        parallel_4.5.0     tzdb_0.5.0        \n#&gt; [22] pacman_0.5.1       vctrs_0.6.5        R6_2.6.1          \n#&gt; [25] lifecycle_1.0.4    htmlwidgets_1.6.4  insight_1.3.0     \n#&gt; [28] pkgconfig_2.0.3    pillar_1.10.2      gtable_0.3.6      \n#&gt; [31] glue_1.8.0         xfun_0.52          tidyselect_1.2.1  \n#&gt; [34] rstudioapi_0.17.1  farver_2.1.2       htmltools_0.5.8.1 \n#&gt; [37] nlme_3.1-168       labeling_0.4.3     rmarkdown_2.29    \n#&gt; [40] compiler_4.5.0",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#bibliografia",
    "href": "chapters/eda/11_outlier.html#bibliografia",
    "title": "24  Outlier",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nLeys, C., Delacre, M., Mora, Y. L., Lakens, D., & Ley, C. (2019). How to classify, detect, and manage univariate and multivariate outliers, with emphasis on pre-registration. International Review of Social Psychology, 32(1).\n\n\nSimmons, J. P., Nelson, L. D., & Simonsohn, U. (2011). False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant. Psychological science, 22(11), 1359–1366.\n\n\nThériault, R., Ben-Shachar, M. S., Patil, I., Lüdecke, D., Wiernik, B. M., & Makowski, D. (2024). Check your outliers! An introduction to identifying statistical outliers in R with easystats. Behavior Research Methods, 56(4), 4162–4172.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/probability/introduction_probability.html",
    "href": "chapters/probability/introduction_probability.html",
    "title": "Probabilità",
    "section": "",
    "text": "Questa sezione della dispensa introduce la teoria della probabilità, una componente essenziale per la ricerca scientifica. Nell’ambito della scienza, l’inferenza induttiva è di fondamentale importanza, e la probabilità svolge un ruolo cruciale in questo processo. Poiché la scienza non può garantire verità assolute, ma solo approssimazioni corroborate da evidenze, la probabilità diventa lo strumento chiave per quantificare il grado di incertezza associato a un’ipotesi, a una previsione o a un modello. Due scuole di pensiero dominano questo scenario: l’approccio bayesiano, che interpreta la probabilità come misura soggettiva del grado di fiducia in una proposizione, e l’approccio frequentista, che la definisce come frequenza relativa di un evento osservabile in condizioni ripetute. Sebbene queste prospettive differiscano radicalmente nell’interpretazione filosofica, entrambe poggiano sullo stesso formalismo matematico. Padroneggiare i concetti fondamentali della probabilità è dunque essenziale per comprendere sia gli strumenti dell’inferenza bayesiana, sia quelli classici dell’analisi statistica.\nQuesta sezione fornisce le basi teoriche necessarie per navigare entrambi i paradigmi. Partiremo dalle definizioni di probabilità e dalle sue regole fondamentali, per poi introdurre concetti come la probabilità condizionale e il teorema di Bayes, che stanno alla base dell’aggiornamento delle credenze alla luce di nuovi dati. Esploreremo inoltre le proprietà delle variabili casuali, distinguendo tra distribuzioni discrete (a massa di probabilità) e continue (a densità di probabilità). Infine, discuteremo la funzione di verosimiglianza, comune alle due scuole: mentre i bayesiani la integrano con informazioni a priori per costruire distribuzioni posteriori, i frequentisti ne sfruttano il principio della massima verosimiglianza per stimare parametri in modo puramente empirico, senza assumere conoscenze preliminari.",
    "crumbs": [
      "Probabilità"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html",
    "href": "chapters/probability/01_intro_prob.html",
    "title": "25  Interpretazione della probabilità",
    "section": "",
    "text": "25.1 Introduzione\nIn questo capitolo esamineremo come la teoria della probabilità si sia affermata come uno strumento per descrivere e interpretare l’incertezza, muovendoci tra diverse concezioni (classica, frequentista e bayesiana) e riconoscendo il ruolo fondamentale della simulazione nel chiarire concetti probabilistici, come la legge dei grandi numeri. Prima, però, è utile soffermarsi sull’idea di casualità e sul nesso che la lega all’incertezza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#casualità-e-incertezza",
    "href": "chapters/probability/01_intro_prob.html#casualità-e-incertezza",
    "title": "25  Interpretazione della probabilità",
    "section": "\n25.2 Casualità e Incertezza",
    "text": "25.2 Casualità e Incertezza\nDavid Spiegelhalter, in un recente articolo pubblicato su Nature, sottolinea come la vita sia pervasa dall’incertezza: non sappiamo con certezza cosa è accaduto in passato, cosa avverrà in futuro né abbiamo una completa comprensione di ciò che ci circonda (Spiegelhalter, 2024). Questa condizione di ignoranza spinge a interpretare la casualità come un modello che, pur non fornendo previsioni deterministiche, rivela spesso regolarità statistiche. In altre parole, i singoli eventi possono apparire imprevedibili, ma l’osservazione di molti casi analoghi svela andamenti medi stabili e quantificabili.\nDa questa prospettiva nasce la teoria della probabilità, intesa come linguaggio matematico rigoroso per quantificare e modellare l’incertezza. Attraverso concetti quali valore atteso, distribuzioni di probabilità e frequenze relative, la probabilità permette di passare dalla nozione intuitiva di caso all’analisi formale dei fenomeni incerti. Anche nell’ambito psicologico, la probabilità supporta la ricerca, l’interpretazione di dati sperimentali e la presa di decisioni cliniche, fornendo una base teorica su cui costruire ipotesi e valutare rischi e benefici.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#il-ruolo-della-probabilità-nello-studio-dei-fenomeni",
    "href": "chapters/probability/01_intro_prob.html#il-ruolo-della-probabilità-nello-studio-dei-fenomeni",
    "title": "25  Interpretazione della probabilità",
    "section": "\n25.3 Il ruolo della probabilità nello studio dei fenomeni",
    "text": "25.3 Il ruolo della probabilità nello studio dei fenomeni\nLa teoria della probabilità consente di trasformare le intuizioni sulla casualità in un linguaggio rigoroso. Tra le sue funzioni fondamentali si evidenziano:\n\nQuantificare l’incertezza\nAssegnare valori numerici agli esiti possibili rende esplicita la probabilità di ogni evento. Per esempio, nel lancio di un dado, dire che ogni faccia ha 1/6 di probabilità di uscire equivale a tradurre la casualità in un concetto misurabile.\nCombinare informazioni\nLe regole di somma e prodotto permettono di integrare probabilità relative a eventi diversi: la somma si utilizza per eventi mutualmente esclusivi (es. prendere o non prendere un voto specifico a un esame), mentre il prodotto si applica a eventi ritenuti indipendenti (es. risultati di più estrazioni da un’urna).\nAggiornare le credenze\nSecondo la prospettiva bayesiana, le probabilità non sono statiche, ma si modificano con il sopraggiungere di nuove evidenze. Un tipico esempio è la revisione di previsioni meteorologiche alla luce di dati più recenti, come la pressione atmosferica o l’umidità.\nOttimizzare le decisioni\nLa probabilità guida valutazioni di rischi e benefici, aiutando a scegliere in modo razionale quando l’esito di un’azione non è garantito. Questa idea si applica tanto in campo clinico, per decidere il protocollo di un trattamento sperimentale, quanto in ambito psicologico, per valutare il processo terapeutico per un disturbo alimentare.\n\nQueste funzioni costituiscono l’ossatura della teoria della probabilità e la rendono uno strumento essenziale per affrontare contesti in cui l’informazione è parziale o i fenomeni hanno una componente di casualità irriducibile.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#due-tipi-di-incertezza-epistemica-e-ontologica",
    "href": "chapters/probability/01_intro_prob.html#due-tipi-di-incertezza-epistemica-e-ontologica",
    "title": "25  Interpretazione della probabilità",
    "section": "\n25.4 Due tipi di incertezza: epistemica e ontologica",
    "text": "25.4 Due tipi di incertezza: epistemica e ontologica\nL’analisi probabilistica si confronta con due tipologie di incertezza:\n\nEpistemica\nDipende dai limiti della conoscenza o dai dati a disposizione. Se in un esperimento non si controllano adeguatamente variabili importanti, la nostra misura di probabilità risente di queste lacune. L’incertezza epistemica può ridursi affinando il disegno sperimentale o ampliando il numero di osservazioni.\nOntologica\nInerente al fenomeno stesso, è indipendente dal grado di controllo o di osservazione possibile. Il lancio di un dado rimane imprevedibile anche se conoscessimo le leggi fisiche in gioco e le condizioni iniziali con incredibile precisione. Questo tipo di casualità è connaturato al sistema, e dunque impossibile da eliminare del tutto.\n\nUn celebre riferimento in questo contesto è Niels Bohr, secondo il quale la scienza non fornisce verità assolute, ma costruisce modelli che descrivono la realtà entro i limiti concettuali di cui disponiamo. In questa prospettiva, l’incertezza ontologica segna il confine tra ciò che è conoscibile e la complessità insita nella natura dei fenomeni.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#cenni-storici",
    "href": "chapters/probability/01_intro_prob.html#cenni-storici",
    "title": "25  Interpretazione della probabilità",
    "section": "\n25.5 Cenni Storici",
    "text": "25.5 Cenni Storici\nLa teoria della probabilità affonda le sue radici nei giochi d’azzardo, pratiche antiche che stimolarono riflessioni sui meccanismi del caso. Fu però nel XVII secolo che iniziò a prendere forma una sistematizzazione scientifica, grazie al dialogo tra Blaise Pascal e Pierre de Fermat. I due matematici risposero alle questioni poste dal Chevalier de Méré, un aristocratico appassionato di scommesse. Tra i dilemmi più noti vi era il cosiddetto “problema della ripartizione equa”: come distribuire il premio di un torneo di dadi interrotto prematuramente, basandosi sulle chance residuali di vittoria dei giocatori?\n\nDue giocatori, A e B, stanno partecipando a un gioco in cui il primo a vincere sei round consecutivi ottiene il premio. Dopo sei round, A ha vinto cinque round e B uno. Poiché il gioco viene interrotto, come si dovrebbe dividere il premio in modo equo?\n\nQuesto problema spinse Pascal e Fermat a sviluppare i primi strumenti matematici per calcolare la probabilità degli eventi futuri, dando vita a un metodo rigoroso per affrontare l’incertezza. Stimando, ad esempio, che A avesse il 97% di probabilità di vincere e B il 3%, sembrava equo dividere il premio nella stessa proporzione. La soluzione, che prevedeva il calcolo degli esiti attesi e delle relative probabilità, segnò una svolta epocale, gettando le basi per la formalizzazione matematica della disciplina.\nChristian Huygens, con il trattato De Ratiociniis in Ludo Aleae (1657), approfondì le applicazioni nel gioco d’azzardo, mentre figure come Leibniz e John Graunt esplorarono rispettivamente la probabilità come strumento logico-giuridico e come frequenza statistica.\nJacob Bernoulli, nell’Ars Conjectandi (1713), formulò la legge dei grandi numeri, evidenziando come ripetute osservazioni empiriche rivelino regolarità nascoste, nonostante l’apparente imprevedibilità dei singoli eventi. Questo lavoro pose le basi per due visioni contrapposte: la probabilità come misura dell’incertezza epistemica (grado di fiducia razionale) e come proprietà oggettiva legata alla frequenza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#la-dualità-epistemologica-e-frequenziale",
    "href": "chapters/probability/01_intro_prob.html#la-dualità-epistemologica-e-frequenziale",
    "title": "25  Interpretazione della probabilità",
    "section": "\n25.6 La dualità Epistemologica e Frequenziale",
    "text": "25.6 La dualità Epistemologica e Frequenziale\nHacking (2006) ha sottolineato che, a partire dal contributo di Bernoulli, la probabilità si sviluppò storicamente lungo due assi: da un lato come misura della credibilità di un’ipotesi (prospettiva epistemologica), dall’altro come descrizione della frequenza con cui un evento compare in circostanze ripetute (prospettiva frequenziale). Questa tensione è tuttora visibile nella dicotomia fra metodi bayesiani e metodi frequentisti.\n\n25.6.1 Frequentismo\nIl frequentismo intende la probabilità come frequenza relativa dell’evento in un numero potenzialmente infinito di prove. I fondatori di questo approccio, tra cui Ronald A. Fisher e poi Jerzy Neyman ed Egon Pearson, hanno posto le basi dell’inferenza statistica classica (test di ipotesi, intervalli di confidenza, analisi di varianza).\nIl modello paradigmatico di questo approccio è il cosiddetto modello dell’urna. Si immagina di estrarre in modo casuale una pallina da un’urna contenente palline visivamente indistinguibili, ma numerate: ogni pallina ha la stessa probabilità di essere scelta, riproducendo così l’idea di eventi equiprobabili. Questa concezione si basa su una rappresentazione astratta e ideale della casualità che, nella realtà, trova riscontro in ambiti quali il campionamento statistico e gli studi clinici randomizzati (in cui ogni paziente ha la stessa probabilità di essere assegnato al gruppo sperimentale o di controllo). Il limite di questa visione emerge nei casi in cui non è possibile accumulare un gran numero di osservazioni o quando l’evento è unico e irripetibile.\n\n25.6.2 Bayesianesimo\nIl bayesianesimo si basa sull’idea di un continuo aggiornamento delle nostre credenze. Con il teorema di Bayes si parte da una conoscenza iniziale (detta prior) e la si aggiorna con i dati osservati (likelihood) per giungere a una stima a posteriori.\n\n25.6.2.1 Probabilità come Costruzione Soggettiva\nL’approccio bayesiano è basato su un’interpretazione soggettiva della probabilità, secondo cui tale concetto rappresenta il grado di fiducia (o credenza) che un individuo o un gruppo attribuisce al verificarsi di un evento, sulla base delle informazioni disponibili. Un esempio pratico è la previsione di pioggia al 70%: non si tratta di un fenomeno fisico oggettivo – come avverrebbe in un’ottica frequenzialista – bensì del risultato di dati storici, modelli climatici e continue rivalutazioni.\nBruno de Finetti ha spinto all’estremo questa prospettiva soggettivista, riassumendo il suo pensiero con la celebre affermazione: “La probabilità non esiste”. In altre parole, la probabilità non sarebbe una proprietà fisica intrinseca degli eventi, ma un indicatore di quanto “si è pronti a scommettere” sulla base delle informazioni e delle convinzioni possedute. Sebbene tali convinzioni debbano rispettare gli assiomi della probabilità per risultare logicamente coerenti, la definizione puntuale di quanto un evento sia “certo” o “probabile” dipende dalla prospettiva e dalle informazioni dell’osservatore.\nFrank Ramsey, nel 1926, fu uno dei primi a formalizzare questa idea, definendo la probabilità come grado di credenza individuale coerente con gli assiomi matematici (Ramsey, 1926). Pochi anni dopo, nel 1939, Jeffreys (1998) illustrò in “Theory of Probability” una tra le prime esposizioni moderne dei metodi bayesiani. Successivamente, Fishburn (1986) fornì una rigorosa formalizzazione matematica degli assiomi della probabilità soggettiva, mentre Press (2009) contribuì ad ampliare l’ambito di applicazione di questa prospettiva, dimostrando la sua importanza come strumento per affrontare l’incertezza in ambito scientifico. Per una panoramica storica sullo sviluppo del pensiero bayesiano, si vedano anche Bayesian Methods: General Background e Philosophy of Statistics.\nIn questo quadro, l’attenzione si sposta dalla realtà oggettiva alla costruzione umana della probabilità, ponendo in evidenza il ruolo dei giudizi, delle ipotesi e delle informazioni disponibili. La probabilità non è dunque una proprietà del mondo, ma una misura del grado di fiducia razionale che un soggetto idealizzato assegna all’affermazione di un evento, basandosi sulle conoscenze (spesso incomplete) di cui dispone. Questo soggetto ideale è concepito come privo di emozioni, pregiudizi o bias cognitivi, così da agire esclusivamente sulla base della logica e delle evidenze. Tale impostazione si applica in modo particolarmente efficace in contesti dove i dati sono limitati o l’incertezza è elevata, come spesso accade negli studi psicologici, in cui il comportamento umano mal si presta a una descrizione puramente frequenzialista.\n\n\n\n\n\n\nTerminologia\n\n\n\nIl termine probabilità soggettiva viene spesso frainteso come mancanza di rigore. Per questo motivo sono state proposte alternative:\n\n\nLindley (2013) adotta il termine probabilità personale, per sottolineare l’aspetto individuale (ma razionale) di tale definizione.\n\n\nHowson & Urbach (2006) preferisce probabilità epistemica, enfatizzando il legame con la conoscenza e l’incertezza dovuta a informazioni limitate.\n\nAutori come Kaplan (2023) utilizzano tali alternative terminologiche per evidenziare in modo più neutrale il ruolo fondamentale della probabilità come strumento scientifico.\n\n\nUn aspetto importante che ha contribuito a promuovere la diffusione contemporanea dell’approccio bayesiano è stata la scoperta, sul finire degli anni ’80, dei metodi Monte Carlo Markov chain (MCMC). Queste tecniche hanno reso computazionalmente accessibili modelli e calcoli altrimenti irrealizzabili, favorendo la rinascita e l’ulteriore evoluzione dei metodi bayesiani.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#i-due-paradigmi-della-probabilità-in-psicologia",
    "href": "chapters/probability/01_intro_prob.html#i-due-paradigmi-della-probabilità-in-psicologia",
    "title": "25  Interpretazione della probabilità",
    "section": "\n25.7 I Due Paradigmi della Probabilità in Psicologia",
    "text": "25.7 I Due Paradigmi della Probabilità in Psicologia\nIn psicologia, entrambi i paradigmi hanno risvolti importanti. L’approccio frequentista è ancora dominante nell’analisi dei dati (si pensi al largo uso dei test di significatività), ma il bayesianesimo sta guadagnando terreno, poiché permette di integrare informazioni pregresse in modo trasparente e di esprimere in modo diretto la probabilità di un’ipotesi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#dalla-teoria-alla-pratica-simulazioni-con-r",
    "href": "chapters/probability/01_intro_prob.html#dalla-teoria-alla-pratica-simulazioni-con-r",
    "title": "25  Interpretazione della probabilità",
    "section": "\n25.8 Dalla teoria alla Pratica: Simulazioni con R",
    "text": "25.8 Dalla teoria alla Pratica: Simulazioni con R\nNello studio della probabilità e della statistica, l’analisi analitica può risultare complessa in contesti con modelli intricati o distribuzioni non standard. In questi casi, la simulazione al computer emerge come strumento didattico e metodologico essenziale. Utilizzando linguaggi di programmazione come R, è possibile replicare virtualmente un esperimento migliaia di volte, osservando empiricamente la distribuzione degli esiti e stimando probabilità attraverso il metodo Monte Carlo. Questo approccio non solo facilita la comprensione di concetti astratti, ma consente anche di validare risultati teorici in scenari reali.\n\n25.8.1 Legge dei Grandi Numeri\nUn principio fondamentale esplorabile attraverso simulazioni è la legge dei grandi numeri (LLN), pilastro dell’approccio frequentista. La LLN stabilisce che la frequenza relativa di un evento converge alla sua probabilità teorica all’aumentare del numero di prove, pur preservando l’imprevedibilità dei singoli esiti. Ad esempio, in una sequenza di lanci di una moneta equa, la proporzione di “teste” oscillerà inizialmente in modo marcato, ma tenderà progressivamente a stabilizzarsi attorno al 50%.\nQuesto fenomeno riflette due aspetti chiave:\n\n\nRiduzione della variabilità: la media campionaria diventa sempre più affidabile con l’aumentare della numerosità del campione.\n\n\nSeparazione tra singoli eventi e comportamento aggregato: la LLN non elimina l’incertezza nei casi singoli (es., il risultato del prossimo lancio), ma descrive un pattern prevedibile a livello di popolazione.\n\nLa simulazione seguente illustra questo principio generando quattro sequenze indipendenti di lanci di moneta e calcolando la proporzione cumulativa di “teste”:\n\n\n\n\n\n\n\n\nIl grafico evidenzia due fenomeni: la convergenza verso il valore teorico (linea tratteggiata) e la variabilità iniziale tra le sequenze, che si attenua progressivamente. Questo esempio dimostra come la LLN fornisca un ponte tra modelli teorici (es., “moneta equa”) e osservazioni empiriche, pur rimanendo valida solo in condizioni di ripetibilità (stesse probabilità in ogni prova) e assenza di bias sistematici.\nLe simulazioni trovano ampio utilizzo in psicologia sia nella formazione che nella ricerca:\n\n\nDidattica: visualizzare il comportamento di indicatori statistici (es., media campionaria) al variare della dimensione del campione, rendendo tangibili concetti come “potenza statistica” o “errore standard”.\n\n\nRicerca: testare la robustezza di modelli psicometrici in condizioni controllate, simulando dati con specifiche caratteristiche (es., correlazioni deboli, rumore sperimentale).\n\nQuesti strumenti favoriscono un apprendimento attivo, invitando gli studenti a manipolare parametri (es., probabilità di successo, numerosità campionaria) e osservarne gli effetti, consolidando così l’intuizione statistica. Tuttavia, è cruciale ricordare che le simulazioni non sostituiscono la teoria, ma la completano, evidenziandone limiti e presupposti applicativi.\n\n\n\n\n\n\nApprofondimento critico\n\n\n\nLa LLN non elimina sfide metodologiche come bias di campionamento, misurazione imperfetta o fenomeni non stazionari. In psicologia, dove molti costrutti (es., emozioni, attitudini) sono intrinsecamente dinamici, l’applicazione della LLN richiede particolare attenzione.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#riflessioni-conclusive",
    "href": "chapters/probability/01_intro_prob.html#riflessioni-conclusive",
    "title": "25  Interpretazione della probabilità",
    "section": "\n25.9 Riflessioni Conclusive",
    "text": "25.9 Riflessioni Conclusive\nLa teoria della probabilità, nata originariamente per analizzare il gioco d’azzardo, si è gradualmente trasformata nel corso dei secoli in un pilastro metodologico per affrontare l’incertezza in un’ampia gamma di contesti, compresa la psicologia. La sua evoluzione storica testimonia un confronto continuo fra interpretazioni epistemiche e frequenzialiste, contribuendo all’elaborazione di strumenti analitici e pratiche operative — dalle procedure inferenziali alla simulazione computerizzata — che consentono di modellizzare sistemi complessi.\nDa un punto di vista filosofico, la probabilità può essere intesa sia come proprietà del mondo (in chiave frequenzialista), sia come misura della nostra conoscenza (nell’ottica bayesiana e soggettivista). Nel primo caso, le frequenze relative e la legge dei grandi numeri mostrano come, da una moltitudine di eventi, possano emergere regolarità e pattern stabili. Nel secondo, l’enfasi è posta sulla dimensione umana e fallibile dell’inferenza: le credenze e le informazioni disponibili influenzano in modo diretto la nostra stima della probabilità di un evento.\nAl di là di queste differenze interpretative, la probabilità si rivela uno strumento insostituibile per pianificare esperimenti, analizzare dati e prendere decisioni in condizioni di incertezza – attività centrali nel campo della psicologia. Inoltre, la possibilità di integrare metodologie teoriche e simulazioni amplia ulteriormente le prospettive di ricerca e la capacità di comprendere i fenomeni studiati. Lungi dall’essere un semplice calcolo combinatorio, la probabilità abbraccia così la complessità della realtà e la ricchezza della conoscenza umana, mostrando una versatilità che la rende uno dei fondamenti del pensiero scientifico contemporaneo.\n\n\n\n\n\n\nPer chi desidera approfondire, il primo capitolo del testo Bernoulli’s Fallacy (Clayton, 2021) offre un’introduzione molto leggibile alle tematiche della definizione della probabilità nella storia della scienza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#esercizi",
    "href": "chapters/probability/01_intro_prob.html#esercizi",
    "title": "25  Interpretazione della probabilità",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nQuali sono le principali concezioni della probabilità esplorate nel capitolo?\nCome viene definita l’incertezza secondo David Spiegelhalter?\nQual è il ruolo della casualità nella teoria della probabilità?\nCome funziona il modello dell’urna per rappresentare la casualità?\nQuali sono alcune applicazioni del modello della casualità?\nQuali sono le due principali fonti di incertezza nei fenomeni non deterministici?\nCome viene interpretata la probabilità secondo l’approccio soggettivista?\nQuali sono le due dimensioni principali del concetto di probabilità secondo Hacking?\nQual è stato il contributo di Pascal e Fermat alla teoria della probabilità?\nQuali sono le differenze tra l’approccio bayesiano e frequentista nella teoria della probabilità?\nQual è la Legge dei Grandi Numeri e come si applica?\nQuali sono i limiti dell’interpretazione frequentista della probabilità?\nCome ha influenzato Fisher lo sviluppo della statistica frequentista?\nQual è stato il ruolo di Jeffreys nella rinascita dell’approccio bayesiano?\nCome definisce Bruno de Finetti la probabilità?\nQuali sono i principi fondamentali della probabilità soggettivista secondo Jaynes?\nQuali sono le alternative terminologiche proposte per la “probabilità soggettiva”?\nQual è l’importanza della simulazione nella comprensione della probabilità?\nQuali sono le implicazioni filosofiche della dualità della probabilità?\nQuali sono i principali contributi storici alla teoria della probabilità?\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n\nLe principali concezioni della probabilità esplorate nel capitolo sono la visione classica, frequentista e bayesiana.\nSecondo David Spiegelhalter, l’incertezza è definita come la “consapevolezza cosciente dell’ignoranza”, riguardante eventi futuri o passati che non possiamo conoscere con certezza.\nLa casualità è un modello concettuale che aiuta a gestire e quantificare eventi imprevedibili, ma che seguono schemi regolari e riconoscibili.\nIl modello dell’urna rappresenta la casualità attraverso l’estrazione di palline numerate da un’urna, dove ogni pallina ha la stessa probabilità di essere estratta.\nAlcune applicazioni del modello della casualità includono indagini statistiche, sperimentazione scientifica e simulazioni in fisica e psicologia.\nLe due principali fonti di incertezza sono l’incertezza epistemica (derivante dalla conoscenza limitata) e l’incertezza ontologica (intrinseca al fenomeno stesso).\nSecondo l’approccio soggettivista, la probabilità è una misura del grado di fiducia o convinzione di un individuo riguardo al verificarsi di un evento, basata sulle informazioni disponibili.\nSecondo Hacking, le due dimensioni principali del concetto di probabilità sono quella epistemologica (misura della credibilità) e quella frequenziale (tendenza osservabile nei fenomeni aleatori).\nPascal e Fermat hanno sviluppato i primi strumenti matematici per calcolare la probabilità degli eventi futuri, risolvendo problemi legati al gioco d’azzardo.\nL’approccio bayesiano considera la probabilità come una misura soggettiva del grado di fiducia, mentre l’approccio frequentista la definisce come la frequenza relativa di un evento in una serie infinita di prove.\nLa Legge dei Grandi Numeri afferma che al crescere del numero di prove, la media dei risultati osservati si avvicina al valore atteso teorico.\nI limiti dell’interpretazione frequentista includono la difficoltà di applicarla a eventi singolari e non ripetibili, e la necessità di un numero infinito di prove per definire la probabilità.\nFisher ha introdotto concetti chiave come la massima verosimiglianza, i test di significatività e l’analisi della varianza, contribuendo allo sviluppo della statistica frequentista.\nJeffreys ha contribuito alla rinascita dell’approccio bayesiano con il suo libro “Theory of Probability”, che ha riportato l’attenzione sui metodi bayesiani.\nBruno de Finetti definisce la probabilità come una misura del grado di fiducia razionale basata su informazioni incomplete, affermando che “la probabilità non esiste” come proprietà oggettiva.\nSecondo Jaynes, i principi fondamentali della probabilità soggettivista includono l’intervallo numerico (0-1) e la coerenza logica, basandosi su informazioni disponibili.\nLe alternative terminologiche proposte per la “probabilità soggettiva” includono “probabilità personale” e “probabilità epistemica”.\nLa simulazione è importante per approssimare probabilità empiriche in contesti complessi, dove soluzioni analitiche non sono praticabili, e per comprendere fenomeni probabilistici attraverso modelli numerici.\nLe implicazioni filosofiche della dualità della probabilità riflettono la tensione tra una descrizione oggettiva della realtà e la soggettività del processo interpretativo.\nI principali contributi storici alla teoria della probabilità includono i lavori di Pascal, Fermat, Huygens, Bernoulli, Fisher, Jeffreys e de Finetti.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#bibliografia",
    "href": "chapters/probability/01_intro_prob.html#bibliografia",
    "title": "25  Interpretazione della probabilità",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nClayton, A. (2021). Bernoulli’s Fallacy: Statistical Illogic and the Crisis of Modern Science. Columbia University Press.\n\n\nFishburn, P. C. (1986). The axioms of subjective probability. Statistical Science, 1(3), 335–345.\n\n\nHacking, I. (2006). The emergence of probability: A philosophical study of early ideas about probability, induction and statistical inference. Cambridge University Press.\n\n\nHowson, C., & Urbach, P. (2006). Scientific reasoning: the Bayesian approach. Open Court Publishing.\n\n\nJeffreys, H. (1998). The theory of probability. OuP Oxford.\n\n\nKaplan, D. (2023). Bayesian statistics for the social sciences. Guilford Publications.\n\n\nLindley, D. V. (2013). Understanding uncertainty. John Wiley & Sons.\n\n\nPress, S. J. (2009). Subjective and objective Bayesian statistics: Principles, models, and applications. John Wiley & Sons.\n\n\nRamsey, F. P. (1926). Truth and probability. In Readings in Formal Epistemology: Sourcebook (pp. 21–45). Springer.\n\n\nSpiegelhalter, D. (2024). Why probability probably doesn’t exist (but it is useful to act like it does). Nature, 636(8043), 560–563.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html",
    "href": "chapters/probability/02_probability_models.html",
    "title": "26  Modelli probabilistici",
    "section": "",
    "text": "26.1 Introduzione\nDopo aver esaminato il significato filosofico della probabilità nel Capitolo 25, questo capitolo ne sviluppa una trattazione più formale, creando un collegamento tra la riflessione teorica e gli strumenti operativi. Partendo dalla definizione di esperimento casuale – come il lancio di una moneta o la somministrazione di un test psicologico – costruiremo un framework matematico per analizzare e quantificare le proprietà di tali esperimenti. In particolare, approfondiremo i concetti di spazio campionario, eventi e proprietà della probabilità, fornendo le basi per un’interpretazione rigorosa dei fenomeni complessi in psicologia e nelle scienze sociali.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#introduzione",
    "href": "chapters/probability/02_probability_models.html#introduzione",
    "title": "26  Modelli probabilistici",
    "section": "",
    "text": "Domande introduttive\n\n\n\nPrima di esaminare in maniera più formale le basi della teoria della probabilità, consideriamo un classico problema della teoria della probabilità:\n🔍 “Quante persone servono in una stanza perché ci sia almeno il 50% di probabilità che due condividano lo stesso compleanno?”\nQuesto problema, noto come problema dei compleanni, fu introdotto dal matematico Richard von Mises nel 1932. La sua soluzione sfida l’intuizione e rivela quanto le probabilità combinatorie possano essere ingannevoli.\nRispondi alle seguenti domande.\n\nCon quante persone pensi si superi il 50% di probabilità? (23? 100? 180?)\nCon 30 persone, quale probabilità stimi? (10%? 50%? 70%?)\n\nScrivi le tue risposte su un foglietto senza condividere con i compagni.\nPer svolgere un esercizio in classe, compila il seguente modulo su Google Forms.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#esperimenti-casuali",
    "href": "chapters/probability/02_probability_models.html#esperimenti-casuali",
    "title": "26  Modelli probabilistici",
    "section": "\n26.2 Esperimenti Casuali",
    "text": "26.2 Esperimenti Casuali\nIl concetto fondamentale della probabilità è l’esperimento casuale, ovvero un procedimento il cui esito non può essere previsto con certezza, ma che può essere analizzato quantitativamente. Alcuni esempi di esperimenti casuali includono:\n\nLanciare un dado e osservare il numero ottenuto sulla faccia superiore.\nEstrarre una carta a caso da un mazzo e registrarne il seme e il valore.\nMisurare il livello di stress percepito da un gruppo di individui in un determinato contesto, come durante un esame o un evento stressante.\nContare il numero di risposte corrette fornite dai partecipanti a un test di memoria entro un tempo prestabilito.\nSelezionare casualmente 50 persone e determinare quante mostrano una predisposizione alla creatività, misurata attraverso un questionario standardizzato.\nScegliere a caso dieci individui e valutare il loro grado di introversione mediante uno strumento di autovalutazione psicologica.\nSelezionare casualmente 50 persone e contare quante sono mancine.\nScegliere a caso dieci individui e misurarne l’altezza.\n\nL’analisi probabilistica ha lo scopo di comprendere il comportamento di tali esperimenti attraverso la costruzione di modelli matematici. Una volta formalizzato matematicamente un esperimento casuale, è possibile calcolare grandezze di interesse, come probabilità ed aspettative. Questi modelli possono essere implementati al computer per simulare l’esperimento e analizzarne i risultati. Inoltre, la modellizzazione matematica degli esperimenti casuali costituisce la base della statistica, disciplina che permette di confrontare diversi modelli e identificare quello più adeguato ai dati osservati.\n\n26.2.1 Il Lancio di una Moneta\nUno degli esperimenti casuali più semplici e fondamentali è il lancio ripetuto di una moneta. Molti concetti chiave della teoria della probabilità possono essere illustrati partendo da questo esperimento elementare. Per studiarne il comportamento, possiamo simularlo al computer utilizzando il linguaggio R.\nDi seguito, un semplice script in R simula 100 lanci di una moneta equa (cioè con probabilità uguali di ottenere Testa o Croce) e rappresenta graficamente la distribuzione dei risultati mediante un diagramma a barre.\n\nset.seed(123) # Imposta il seed per garantire la riproducibilità\nx &lt;- runif(100) &lt; 0.5 # Genera 100 numeri casuali e verifica se sono minori di 0.5\nx\n#&gt;   [1]  TRUE FALSE  TRUE FALSE FALSE  TRUE FALSE FALSE FALSE  TRUE FALSE\n#&gt;  [12]  TRUE FALSE FALSE  TRUE FALSE  TRUE  TRUE  TRUE FALSE FALSE FALSE\n#&gt;  [23] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE FALSE FALSE FALSE\n#&gt;  [34] FALSE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n#&gt;  [45]  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE FALSE  TRUE FALSE\n#&gt;  [56]  TRUE  TRUE FALSE FALSE  TRUE FALSE  TRUE  TRUE  TRUE FALSE  TRUE\n#&gt;  [67] FALSE FALSE FALSE  TRUE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE\n#&gt;  [78] FALSE  TRUE  TRUE  TRUE FALSE  TRUE FALSE  TRUE  TRUE FALSE FALSE\n#&gt;  [89] FALSE  TRUE  TRUE FALSE  TRUE FALSE  TRUE  TRUE FALSE  TRUE  TRUE\n#&gt; [100] FALSE\n\nNel codice, la funzione runif genera 100 numeri casuali distribuiti uniformemente nell’intervallo [0, 1]. Confrontando ciascun numero con 0.5, otteniamo un vettore logico che rappresenta il risultato di ogni lancio: Testa (TRUE) o Croce (FALSE).\n\nt &lt;- 1:100 # Sequenza degli indici dei lanci\n\n# Creazione del dataframe per ggplot2\ndat &lt;- tibble(\n  Lancio = t,\n  Risultato = ifelse(x, \"Testa\", \"Croce\")\n)\nhead(dat)\n#&gt; # A tibble: 6 × 2\n#&gt;   Lancio Risultato\n#&gt;    &lt;int&gt; &lt;chr&gt;    \n#&gt; 1      1 Testa    \n#&gt; 2      2 Croce    \n#&gt; 3      3 Testa    \n#&gt; 4      4 Croce    \n#&gt; 5      5 Croce    \n#&gt; 6      6 Testa\n\nIl grafico a barre mostra la distribuzione osservata degli esiti.\n\n# Creazione del grafico a barre della distribuzione dei risultati\ndat |&gt;\n  ggplot(aes(x = Risultato)) +\n  geom_bar(aes(y = after_stat(prop), group = 1),\n           fill = \"lightblue\", color = \"black\", width = 0.5) +\n  labs(\n    title = \"Distribuzione dei risultati del lancio della moneta\",\n    x = \"Risultato\",\n    y = \"Frequenza relativa\"\n  )\n\n\n\n\n\n\n\nUn aspetto rilevante di questo esperimento è l’andamento della proporzione osservata di esiti “Testa” in funzione del numero di lanci. Il grafico riportato di seguito illustra l’evoluzione della media cumulativa degli esiti “Testa”, che, in accordo con la legge dei grandi numeri, dovrebbe convergere al valore teorico di 0.5.\n\ny &lt;- cumsum(x) / t # Calcola la media cumulativa delle Teste\n\n# Creazione del dataframe per il grafico della media mobile\ndata_mean &lt;- tibble(\n  Lancio = t, \n  Media_Testa = y\n)\n\n# Creazione del grafico della media cumulativa\ndata_mean |&gt;\n  ggplot(\n    aes(x = Lancio, y = Media_Testa)\n  ) +\n  geom_line(linewidth = 1.5) +\n  geom_hline(yintercept = 0.5, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Media cumulativa del numero di Teste\",\n    x = \"Numero di lanci\",\n    y = \"Frequenza cumulativa di Teste\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nMedia cumulata\n\n\n\n\n\nLa media cumulata (o cumulativa) è una media che si calcola progressivamente, aggiungendo un nuovo dato alla volta e ricalcolando la media considerando tutti i valori precedenti insieme al nuovo.\nIn pratica, mostra come la media si evolve man mano che vengono inclusi nuovi dati nella serie.\nCome si calcola?\n\nAl primo dato, la media cumulata è il dato stesso.\n\nAl secondo dato, è la media tra il primo e il secondo.\n\nAl terzo dato, è la media tra il primo, il secondo e il terzo.\n\nE così via…\n\nFormula intuitiva:\n\\[\n\\text{Media cumulata al passo } n = \\frac{\\text{somma di tutti i dati fino al passo } n}{n}\n\\]\nEsempio pratico:\nSupponiamo di avere i voti di uno studente in 3 verifiche:\n\nVerifica 1: 7\n\nVerifica 2: 6\n\nVerifica 3: 8\n\nLe medie cumulate saranno:\n\nDopo la 1ª verifica: \\(\\frac{7}{1} = 7\\).\n\nDopo la 2ª verifica: \\(\\frac{7 + 6}{2} = 6.5\\).\n\nDopo la 3ª verifica: \\(\\frac{7 + 6 + 8}{3} = 7\\).\n\nA cosa serve?\n\n\nTracciare l’andamento nel tempo (es.: mostrare come la frequenza di “Testa” si avvicina gradualmente al 50% teorico man mano che aumentano i lanci).\n\n\nLisciare le fluttuazioni: riduce l’impatto di picchi temporanei, mostrando un trend più stabile.\n\n\nValutare prestazioni progressive (es.: un atleta che migliora gradualmente).\n\n\n\n\n\nIl grafico mostra come la media delle Teste oscilla inizialmente a causa della variabilità intrinseca dell’esperimento, ma tende progressivamente a stabilizzarsi intorno a 0.5. Questo fenomeno è un esempio della Legge dei Grandi Numeri, secondo cui, ripetendo un esperimento casuale un numero sempre maggiore di volte, la frequenza relativa di un evento si avvicina alla sua probabilità teorica.\n\n26.2.2 Domande di Interesse\nL’esperimento casuale del lancio di una moneta porta a numerose domande, tra cui:\n\nQual è la probabilità di ottenere un certo numero \\(x\\) di Teste in 100 lanci?\nQual è il numero atteso di Teste in un esperimento di 100 lanci?\n\nDal punto di vista statistico, quando osserviamo i risultati di un esperimento reale (ad esempio, 100 lanci di una moneta), possiamo anche porci domande come:\n\nLa moneta è davvero equa o è sbilanciata?\nQual è il miglior metodo per stimare la probabilità \\(p\\) di ottenere Testa dalla sequenza osservata di lanci?\nQuanto è precisa la stima ottenuta e con quale livello di incertezza?\n\nQuesti interrogativi costituiscono la base della statistica inferenziale, che permette di testare ipotesi sulla probabilità di un evento e stimare parametri sconosciuti sulla base di dati osservati.\n\n26.2.3 Modellizzazione\n\nLa descrizione matematica di un esperimento casuale si basa su tre elementi fondamentali:\n\nLo spazio campionario: rappresenta l’insieme di tutti i possibili esiti dell’esperimento. Nel caso di esperimenti semplici, lo spazio campionario è immediato da individuare, mentre in situazioni più complesse è necessario applicare i principi del calcolo combinatorio.\nGli eventi: sono sottoinsiemi dello spazio campionario e rappresentano gli esiti di interesse. Per analizzare e manipolare gli eventi, utilizziamo gli strumenti della teoria degli insiemi.\nLa probabilità: assegna un valore numerico a ciascun evento, indicando la sua probabilità di verificarsi. L’assegnazione delle probabilità avviene secondo gli assiomi di Kolmogorov.\n\nNei paragrafi seguenti, analizzeremo ciascuna di queste componenti in dettaglio.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#spazio-campionario",
    "href": "chapters/probability/02_probability_models.html#spazio-campionario",
    "title": "26  Modelli probabilistici",
    "section": "\n26.3 Spazio Campionario",
    "text": "26.3 Spazio Campionario\nAnche se non possiamo prevedere con esattezza l’esito di un singolo esperimento casuale, possiamo comunque definire tutti i risultati che potrebbero verificarsi. L’insieme completo di questi esiti possibili si chiama spazio campionario.\n\nDefinizione 26.1 Lo spazio campionario \\(\\Omega\\) di un esperimento casuale è l’insieme di tutti i possibili esiti dell’esperimento.\n\n\n26.3.1 Esempi di Spazi Campionari\nConsideriamo lo spazio campionario di alcuni esperimenti casuali.\n\nLancio di due dadi consecutivi: \\[\n\\Omega = \\{(1,1), (1,2), \\dots, (6,6)\\}.\n\\]\nTempo di reazione a uno stimolo visivo: \\[\\Omega = \\mathbb{R}^+,\\] ovvero l’insieme dei numeri reali positivi.\nNumero di errori in un test di memoria a breve termine: \\[\\Omega = \\{0, 1, 2, \\dots\\}.\\]\nMisurazione delle altezze di dieci persone: \\[\\Omega = \\{(x_1, \\dots, x_{10}) : x_i \\ge 0, \\; i=1,\\dots,10\\} \\subset \\mathbb{R}^{10}.\\]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#eventi",
    "href": "chapters/probability/02_probability_models.html#eventi",
    "title": "26  Modelli probabilistici",
    "section": "\n26.4 Eventi",
    "text": "26.4 Eventi\nSolitamente non siamo interessati a un singolo esito, ma a un insieme di essi. Un evento è un sottoinsieme dello spazio campionario a cui possiamo assegnare una probabilità.\n\nDefinizione 26.2 Un evento è un sottoinsieme \\(A \\subseteq \\Omega\\) al quale viene assegnata una probabilità. Indichiamo gli eventi con lettere maiuscole \\(A, B, C, \\dots\\). Diciamo che l’evento \\(A\\) si verifica se l’esito dell’esperimento appartiene a \\(A\\).\n\n\n26.4.1 Esempi di Eventi\nConsideriamo alcuni possibili eventi definiti sugli spazi campionari descritti sopra.\n\nLancio di due dadi consecutivi.Evento: “La somma dei due dadi è uguale a 7”\\[\nA = \\{(1,6), (2,5), (3,4), (4,3), (5,2), (6,1)\\}.\n\\]\nTempo di reazione a uno stimolo visivo.Evento: “Il tempo di reazione è inferiore a 2 secondi”\\[\nA = [0, 2).\n\\]\nNumero di errori in un test di memoria a breve termine.Evento: “Il numero di errori è al massimo 3”\\[\nA = \\{0, 1, 2, 3\\}.\n\\]\nMisurazione delle altezze di dieci persone.Evento: “Almeno due persone hanno un’altezza superiore a 180 cm”\\[\nA = \\{(x_1, \\dots, x_{10}) : \\text{almeno due } x_i &gt; 180\\}.\n\\]\n\nQuesti esempi mostrano come gli eventi possano essere definiti in modo diverso a seconda della natura dello spazio campionario e del contesto di interesse.\n\nEsempio 26.1 Supponiamo di lanciare una moneta tre volte e di annotare se esce Testa (\\(H\\)) o Croce (\\(T\\)) in ogni lancio. Lo spazio campionario è:\n\\[\n\\Omega = \\{HHH, HHT, HTH, HTT, THH, THT, TTH, TTT\\},\n\\]\ndove, ad esempio, \\(HTH\\) indica che il primo lancio dà Testa, il secondo Croce e il terzo Testa.\nUn’alternativa è rappresentare lo spazio campionario come l’insieme dei vettori binari di lunghezza 3, \\(\\{0,1\\}^3\\), dove Testa (\\(H\\)) corrisponde a 1 e Croce (\\(T\\)) a 0.\nL’evento \\(A\\) “il terzo lancio è Testa” si esprime come:\n\\[\nA = \\{HHH, HTH, THH, TTH\\}.\n\\]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#operazioni-sugli-eventi",
    "href": "chapters/probability/02_probability_models.html#operazioni-sugli-eventi",
    "title": "26  Modelli probabilistici",
    "section": "\n26.5 Operazioni sugli Eventi",
    "text": "26.5 Operazioni sugli Eventi\nPoiché gli eventi sono definiti come insiemi, possiamo applicare loro le classiche operazioni insiemistiche.\nUnione (\\(\\cup\\)). L’unione di due eventi \\(A\\) e \\(B\\) è l’insieme di tutti gli esiti che appartengono almeno a uno dei due:\n\\[\nA \\cup B = \\{\\omega \\in \\Omega : \\omega \\in A \\text{ oppure } \\omega \\in B\\}.\n\\]\nIntersezione (\\(\\cap\\)). L’intersezione di due eventi è l’insieme degli esiti comuni:\n\\[\nA \\cap B = \\{\\omega \\in \\Omega : \\omega \\in A \\text{ e } \\omega \\in B\\}.\n\\]\nComplemento (\\(A^c\\)). Il complemento di un evento \\(A\\) è l’insieme di tutti gli esiti che non appartengono ad \\(A\\):\n\\[\nA^c = \\{\\omega \\in \\Omega : \\omega \\notin A\\}.\n\\]\nEventi mutuamente esclusivi. Due eventi sono mutuamente esclusivi se non hanno esiti in comune, ovvero:\n\\[\nA \\cap B = \\emptyset.\n\\]\n\nEsempio 26.2  \n\n# Universo\nU &lt;- 1:10  \n\n# Definizione degli insiemi A e B\nA &lt;- c(1, 2, 3, 4, 5)\nB &lt;- c(4, 5, 6, 7, 8)\n\n# Calcolare l'unione, l'intersezione e il complemento relativo a un universo U\nunion_AB &lt;- union(A, B)\nintersect_AB &lt;- intersect(A, B)\ncomplement_A &lt;- setdiff(U, A)\ncomplement_B &lt;- setdiff(U, B)\n\n# Visualizzazione testuale\ncat(\"Unione A ∪ B:\", union_AB, \"\\n\")\n#&gt; Unione A ∪ B: 1 2 3 4 5 6 7 8\ncat(\"Intersezione A ∩ B:\", intersect_AB, \"\\n\")\n#&gt; Intersezione A ∩ B: 4 5\ncat(\"Complemento di A:\", complement_A, \"\\n\")\n#&gt; Complemento di A: 6 7 8 9 10\ncat(\"Complemento di B:\", complement_B, \"\\n\")\n#&gt; Complemento di B: 1 2 3 9 10\n\n\n# Visualizzazione con diagrammi di Venn\nvenn.plot &lt;- draw.pairwise.venn(\n  area1 = length(A),\n  area2 = length(B),\n  cross.area = length(intersect_AB),\n  category = c(\"A\", \"B\"),\n  fill = c(\"blue\", \"red\"),\n  alpha = 0.5,\n  cat.col = c(\"blue\", \"red\")\n)\ngrid.draw(venn.plot)\n\n\n\n\n\n\n\n\n# Esempio di eventi mutualmente esclusivi\nC &lt;- c(9, 10)  # Insieme disgiunto da A e B\nintersect_AC &lt;- intersect(A, C)  # Deve essere vuoto\n\ncat(\"Intersezione A ∩ C (eventi mutualmente esclusivi):\", intersect_AC, \"\\n\")\n#&gt; Intersezione A ∩ C (eventi mutualmente esclusivi):\n\n\n# Visualizzazione di eventi mutualmente esclusivi\nvenn.plot2 &lt;- draw.pairwise.venn(\n  area1 = length(A),\n  area2 = length(C),\n  cross.area = 0,  # Nessuna intersezione\n  category = c(\"A\", \"C\"),\n  fill = c(\"blue\", \"green\"),\n  alpha = 0.5,\n  cat.col = c(\"blue\", \"green\")\n)\ngrid.draw(venn.plot2)\n\n\n\n\n\n\n\n\n\n26.5.1 Proprietà Fondamentali delle Operazioni su Eventi\n\nIdempotenza: \\[\nA \\cup A = A, \\quad A \\cap A = A.\n\\]\nLeggi di De Morgan: \\[\n(A \\cup B)^c = A^c \\cap B^c, \\quad (A \\cap B)^c = A^c \\cup B^c.\n\\]\nUnione e Intersezione con l’insieme vuoto: \\[\nA \\cup \\emptyset = A, \\quad A \\cap \\emptyset = \\emptyset.\n\\]\nUnione e Intersezione con lo spazio campionario: \\[\nA \\cup \\Omega = \\Omega, \\quad A \\cap \\Omega = A.\n\\]\n\nQueste operazioni forniscono la base per costruire e manipolare eventi in contesti probabilistici, permettendo di calcolare probabilità e prendere decisioni basate sull’analisi degli esiti possibili.\n\nEsempio 26.3 Per gli insiemi definiti nell’esempio precedente, possiamo verificare la prima legge di De Morgan in R confrontando il complemento dell’unione con l’intersezione dei complementi:\n\ncomplemento dell’unione: \\((A \\cup B)^c\\),\nintersezione dei complementi: \\(A^c \\cap B^c\\).\n\nEseguiamo i calcoli in R:\n\n# Complemento dell'unione: (A ∪ B)^c\nsetdiff(U, union(A, B))\n#&gt; [1]  9 10\n\n\n# Intersezione dei complementi: A^c ∩ B^c\nintersect(setdiff(U, A), setdiff(U, B))\n#&gt; [1]  9 10\n\nSecondo la legge di De Morgan, i due risultati devono coincidere.\n\n\nEsempio 26.4 Consideriamo l’esperimento del lancio di due dadi. Lo spazio campionario \\(\\Omega\\) è costituito da tutte le possibili coppie di risultati che possono verificarsi. Ogni dado ha 6 facce, quindi lo spazio campionario è:\n\\[\n\\Omega = \\{(1,1), (1,2), \\dots, (6,6)\\},\n\\]\nper un totale di \\(6 \\times 6 = 36\\) esiti possibili.\nSiamo interessati all’evento \\(A\\): “la somma dei due dadi è almeno 10”. Questo evento include tutte le coppie di risultati la cui somma è 10, 11 o 12. Gli esiti che soddisfano questa condizione sono:\n\\[\nA = \\{(4,6), (5,5), (5,6), (6,4), (6,5), (6,6)\\}.\n\\]\nEcco come generare lo spazio campionario in R in modo algoritmico e definire l’evento “la somma dei due dadi è almeno 10”:\nLo spazio campionario \\(\\Omega\\) è costituito da tutte le possibili coppie di risultati del lancio di due dadi. In R, possiamo generarlo utilizzando la funzione expand.grid, che crea tutte le combinazioni possibili tra i valori dei due dadi.\n\n# Generazione dello spazio campionario Omega\ndado &lt;- 1:6 # Facce di un dado\nOmega &lt;- expand.grid(Dado1 = dado, Dado2 = dado) # Tutte le combinazioni possibili\n\nL’output sarà una tabella con 36 righe, una per ogni combinazione possibile:\n\n# Visualizzazione dello spazio campionario\nprint(Omega)\n#&gt;    Dado1 Dado2\n#&gt; 1      1     1\n#&gt; 2      2     1\n#&gt; 3      3     1\n#&gt; 4      4     1\n#&gt; 5      5     1\n#&gt; 6      6     1\n#&gt; 7      1     2\n#&gt; 8      2     2\n#&gt; 9      3     2\n#&gt; 10     4     2\n#&gt; 11     5     2\n#&gt; 12     6     2\n#&gt; 13     1     3\n#&gt; 14     2     3\n#&gt; 15     3     3\n#&gt; 16     4     3\n#&gt; 17     5     3\n#&gt; 18     6     3\n#&gt; 19     1     4\n#&gt; 20     2     4\n#&gt; 21     3     4\n#&gt; 22     4     4\n#&gt; 23     5     4\n#&gt; 24     6     4\n#&gt; 25     1     5\n#&gt; 26     2     5\n#&gt; 27     3     5\n#&gt; 28     4     5\n#&gt; 29     5     5\n#&gt; 30     6     5\n#&gt; 31     1     6\n#&gt; 32     2     6\n#&gt; 33     3     6\n#&gt; 34     4     6\n#&gt; 35     5     6\n#&gt; 36     6     6\n\nL’evento \\(A\\) è definito come “la somma dei due dadi è almeno 10”. Per identificare queste combinazioni, aggiungiamo una colonna che calcola la somma dei due dadi e filtriamo le righe in cui la somma è maggiore o uguale a 10.\n\n# Aggiunta di una colonna per la somma dei due dadi\nOmega$Somma &lt;- Omega$Dado1 + Omega$Dado2\n\n# Definizione dell'evento A: somma dei due dadi almeno 10\nA &lt;- Omega[Omega$Somma &gt;= 10, ]\n\nL’output sarà un data frame con le combinazioni in cui la somma è almeno 10:\n\n# Visualizzazione dell'evento A\nprint(A)\n#&gt;    Dado1 Dado2 Somma\n#&gt; 24     6     4    10\n#&gt; 29     5     5    10\n#&gt; 30     6     5    11\n#&gt; 34     4     6    10\n#&gt; 35     5     6    11\n#&gt; 36     6     6    12\n\nIn sintesi,\n\nlo spazio campionario \\(\\Omega\\) è stato generato algoritmicamente utilizzando expand.grid;\nl’evento \\(A\\) è stato definito filtrando le combinazioni in cui la somma dei due dadi è almeno 10.\n\n\n\nEsempio 26.5 Consideriamo un esperimento in cui lanciamo una moneta tre volte consecutivamente. Ogni lancio può risultare in Testa (H) o Croce (T). Lo spazio campionario \\(\\Omega\\) è costituito da tutte le possibili sequenze di risultati dei tre lanci. Ci sono \\(2^3 = 8\\) possibili esiti, che possono essere rappresentati come:\n\\[\n\\Omega = \\{\\text{HHH}, \\text{HHT}, \\text{HTH}, \\text{HTT}, \\text{THH}, \\text{THT}, \\text{TTH}, \\text{TTT}\\}.\n\\]\nVogliamo definire in R l’evento \\(A\\): “Il terzo lancio della moneta dia Testa (H)”. Questo evento include tutte le sequenze in cui il terzo carattere è “H”.\nIn R, possiamo rappresentare lo spazio campionario \\(\\Omega\\) come un vettore di stringhe, dove ogni stringa corrisponde a una sequenza di risultati.\n\n# Definizione dello spazio campionario Omega\nomega &lt;- c(\"HHH\", \"HHT\", \"HTH\", \"HTT\", \"THH\", \"THT\", \"TTH\", \"TTT\")\nomega\n#&gt; [1] \"HHH\" \"HHT\" \"HTH\" \"HTT\" \"THH\" \"THT\" \"TTH\" \"TTT\"\n\nL’evento \\(A\\) è costituito da tutte le sequenze in cui il terzo lancio è Testa (H). Per identificare queste sequenze, utilizziamo la funzione substr, che estrae il terzo carattere da ciascuna stringa e verifica se è uguale a “H”.\n\n# Definizione dell'evento A: terzo lancio è Testa (H)\nA &lt;- omega[substr(omega, 3, 3) == \"H\"]\n\nSpiegazione del codice:\n\n\nsubstr(omega, 3, 3) estrae il terzo carattere da ciascuna stringa nel vettore omega.\n\nsubstr(omega, 3, 3) == \"H\" crea un vettore logico (vero/falso) che indica se il terzo carattere è “H”.\n\nomega[...] filtra il vettore omega, mantenendo solo le sequenze che soddisfano la condizione.\n\nL’output sarà:\n\n# Visualizzazione dell'evento A\nA\n#&gt; [1] \"HHH\" \"HTH\" \"THH\" \"TTH\"\n\nQueste sono le sequenze in cui il terzo lancio è Testa (H).\nIn sintesi,\n\nlo spazio campionario \\(\\Omega\\) è stato definito come un vettore di stringhe in R;\nl’evento \\(A\\) è stato costruito filtrando le sequenze in cui il terzo carattere è “H”, utilizzando la funzione substr(x, start, stop);\nl’evento \\(A\\) corrisponde alle sequenze: HHH, HTH, THH, TTH.\n\nQuesto esercizio illustra come definire e manipolare eventi in R, utilizzando operazioni di base su stringhe e vettori.\n\n\nEsempio 26.6 Consideriamo l’esperimento del lancio consecutivo di due dadi. Lo spazio campionario \\(\\Omega\\) è costituito da tutte le possibili coppie di risultati:\n\\[\n\\Omega = \\{(1, 1), (1, 2), \\dots, (6, 6)\\}.\n\\]\nDefiniamo due eventi:\n\nEvento \\(A\\): “Il primo dado mostra un 6”.\nQuesto evento include tutte le coppie in cui il primo dado è 6:\\[\nA = \\{(6, 1), (6, 2), (6, 3), (6, 4), (6, 5), (6, 6)\\}.\n\\]\nEvento \\(B\\): “Il secondo dado mostra un 6”.\nQuesto evento include tutte le coppie in cui il secondo dado è 6:\\[\nB = \\{(1, 6), (2, 6), (3, 6), (4, 6), (5, 6), (6, 6)\\}.\n\\]\n\nL’intersezione \\(A \\cap B\\) rappresenta l’evento in cui entrambi i dadi mostrano un 6:\n\\[\nA \\cap B = \\{(6, 6)\\}.\n\\]\nImplementazione in R\nPer analizzare gli eventi legati al lancio di due dadi, utilizziamo R per simulare lo spazio campionario e manipolare gli eventi.\n1. Generazione dello spazio campionario\nLa funzione expand.grid crea tutte le combinazioni possibili tra gli elementi di due vettori. Nel nostro caso, generiamo tutte le coppie (Dado1, Dado2):\n\n# Definizione delle facce dei dadi (1-6)\ndado &lt;- 1:6\n\n# Creazione di tutte le 36 combinazioni possibili\nOmega &lt;- expand.grid(\n  Dado1 = dado,\n  Dado2 = dado\n)\n\n# Visualizzazione delle prime 6 righe\nhead(Omega)\n#&gt;   Dado1 Dado2\n#&gt; 1     1     1\n#&gt; 2     2     1\n#&gt; 3     3     1\n#&gt; 4     4     1\n#&gt; 5     5     1\n#&gt; 6     6     1\n\n2. Definizione degli eventi\nEvento A - “Primo dado = 6”:\nFiltriamo le righe dove la colonna Dado1 è uguale a 6:\n\nA &lt;- Omega[Omega$Dado1 == 6, ] # Selezione condizionale\nprint(\"Evento A:\")\n#&gt; [1] \"Evento A:\"\nA\n#&gt;    Dado1 Dado2\n#&gt; 6      6     1\n#&gt; 12     6     2\n#&gt; 18     6     3\n#&gt; 24     6     4\n#&gt; 30     6     5\n#&gt; 36     6     6\n\nEvento B - “Secondo dado = 6”:\nFiltriamo le righe dove la colonna Dado2 è uguale a 6:\n\nB &lt;- Omega[Omega$Dado2 == 6, ]\nprint(\"Evento B:\")\n#&gt; [1] \"Evento B:\"\nB\n#&gt;    Dado1 Dado2\n#&gt; 31     1     6\n#&gt; 32     2     6\n#&gt; 33     3     6\n#&gt; 34     4     6\n#&gt; 35     5     6\n#&gt; 36     6     6\n\n3. Calcolo dell’intersezione A ∩ B\nMetodo 1: Funzione intersect()\nLa funzione base intersect() confronta intere righe tra due dataframe e restituisce quelle comuni:\n\nA_intersezione_B &lt;- intersect(A, B)\nprint(\"Intersezione con intersect():\")\n#&gt; [1] \"Intersezione con intersect():\"\nA_intersezione_B\n#&gt;   Dado1 Dado2\n#&gt; 1     6     6\n\nMetodo 2: Funzione merge()\nLa funzione base merge() esegue una join naturale sulle colonne con lo stesso nome:\n\nA_intersezione_B &lt;- merge(A, B)\nprint(\"Intersezione con merge():\")\n#&gt; [1] \"Intersezione con merge():\"\nA_intersezione_B\n#&gt;   Dado1 Dado2\n#&gt; 1     6     6\n\nMetodo 3: Pacchetto dplyr\nLa funzione inner_join() mantiene solo le righe presenti in entrambi i dataframe:\n\nA_intersezione_B &lt;- inner_join(A, B, by = c(\"Dado1\", \"Dado2\"))\nprint(\"Intersezione con dplyr:\")\n#&gt; [1] \"Intersezione con dplyr:\"\nA_intersezione_B\n#&gt;   Dado1 Dado2\n#&gt; 1     6     6\n\nIn sintesi,\n\nlo spazio campionario \\(\\Omega\\) è stato generato algoritmicamente in R;\ngli eventi \\(A\\) e \\(B\\) sono stati definiti filtrando lo spazio campionario;\nl’intersezione \\(A \\cap B\\) corrisponde all’evento in cui entrambi i dadi mostrano un 6: \\(\\{(6, 6)\\}.\\)",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#sec-probabilita",
    "href": "chapters/probability/02_probability_models.html#sec-probabilita",
    "title": "26  Modelli probabilistici",
    "section": "\n26.6 Probabilità",
    "text": "26.6 Probabilità\nIl terzo elemento fondamentale del modello probabilistico è la funzione di probabilità, che quantifica numericamente la possibilità di occorrenza degli eventi.\n\nDefinizione 26.3 Una probabilità \\(P\\) è una funzione \\(P: \\mathcal{F} \\to [0,1]\\) definita su una \\(\\sigma\\)-algebra \\(\\mathcal{F}\\) di sottoinsiemi di \\(\\Omega\\). A ogni evento \\(A \\in \\mathcal{F}\\), la funzione assegna un valore reale compreso tra 0 e 1, rispettando i seguenti assiomi di Kolmogorov:\n\nNon-negatività\nPer ogni \\(A \\subseteq \\Omega\\), si richiede che \\(0 \\leq P(A) \\leq 1\\).\nNormalizzazione (evento certo)\\(P(\\Omega) = 1\\).\nAdditività numerabile\nSe \\(A_1, A_2, \\dots\\) sono eventi mutuamente esclusivi (cioè \\(A_i \\cap A_j = \\emptyset\\) per \\(i \\neq j\\)), allora: \\[\nP\\!\\Bigl(\\bigcup_{i=1}^{\\infty} A_i\\Bigr) \\;=\\; \\sum_{i=1}^{\\infty} P(A_i).\n\\]\n\nIn altre parole, una misura di probabilità non solo assegna numeri nell’intervallo \\([0,1]\\) a ogni evento, ma richiede che l’evento “certo” \\(\\Omega\\) abbia probabilità 1 e che la probabilità di un’unione numerabile di eventi disgiunti sia la somma delle loro probabilità. Queste condizioni garantiscono la coerenza formale e l’interpretazione intuitiva del concetto di probabilità.\n\n\n26.6.1 Interpretazione degli Assiomi di Kolmogorov\n\nAssioma 1 (Non-negatività e limiti 0–1)\nLa probabilità di un evento è sempre un numero reale compreso tra 0 e 1. Se la probabilità è 0, l’evento può considerarsi impossibile; se è 1, l’evento è certo.Esempio: Nel lancio di un dado a sei facce, l’evento “Esce 7” non può verificarsi e ha probabilità 0, mentre l’evento “Esce un numero tra 1 e 6” ha probabilità 1.\nAssioma 2 (Evento certo)\nLo spazio campionario \\(\\Omega\\) è l’insieme di tutti i possibili esiti dell’esperimento. Poiché in ogni prova deve accadere almeno uno degli esiti contenuti in \\(\\Omega\\), la probabilità di \\(\\Omega\\) è necessariamente 1.Esempio: Nel lancio di un dado, lo spazio campionario \\(\\Omega\\) è \\(\\{1,2,3,4,5,6\\}\\). L’evento “esce un numero tra 1 e 6” coincide con l’intero spazio campionario, quindi \\(P(\\Omega) = 1\\).\nAssioma 3 (Additività per eventi incompatibili)\nSe due o più eventi sono mutuamente esclusivi (o incompatibili) — cioè non possono verificarsi contemporaneamente — la probabilità della loro unione è la somma delle probabilità di ciascuno.Esempio: Con un dado, l’evento “esce un numero pari” e l’evento “esce un numero dispari” non possono verificarsi nello stesso lancio. Di conseguenza,\\[\nP(\\text{“pari”} \\cup \\text{“dispari”}) \\;=\\; P(\\text{“pari”}) + P(\\text{“dispari”})\\,.\n\\]\n\nQuesti assiomi assicurano che la probabilità, intesa come funzione che assegna valori tra 0 e 1 a ogni evento, rispetti la coerenza matematica e l’interpretazione intuitiva: non esistono eventi “negativi” o “più che certi”, e la probabilità totale dell’intero spazio dei possibili risultati deve sempre essere uguale a 1.\n\n26.6.2 Proprietà Fondamentali\nDagli assiomi di Kolmogorov discendono alcune proprietà fondamentali che descrivono come la probabilità si comporti in varie situazioni. Le principali sono elencate di seguito.\n\nTeorema 26.1 Siano \\(A\\) e \\(B\\) eventi qualsiasi nello spazio campionario \\(\\Omega\\). Allora valgono le seguenti relazioni:\n\nProbabilità dell’evento impossibile\\[\nP(\\emptyset) = 0.\n\\] Poiché l’insieme vuoto non include alcun esito sperimentale, non può mai verificarsi.\nMonotonicità\\[\nA \\subseteq B \\quad \\Longrightarrow \\quad P(A) \\le P(B).\n\\] Se un evento è interamente contenuto in un altro, non può avere probabilità maggiore dell’evento che lo comprende.\nProbabilità del complementare\\[\nP(A^c) = 1 - P(A).\n\\] Poiché \\(A\\) e il suo complementare \\(A^c\\) coprono l’intero spazio \\(\\Omega\\), la probabilità di \\(A^c\\) è la parte “rimanente” fino a 1.\nRegola dell’inclusione–esclusione\\[\nP(A \\cup B) \\;=\\; P(A) + P(B) \\;-\\; P(A \\cap B).\n\\] Per calcolare la probabilità dell’unione di due eventi qualsiasi, si sommano le probabilità di ciascun evento e si sottrae la probabilità della loro intersezione (altrimenti verrebbe conteggiata due volte).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#case-discreto-continuo",
    "href": "chapters/probability/02_probability_models.html#case-discreto-continuo",
    "title": "26  Modelli probabilistici",
    "section": "\n26.7 Spazi Discreti vs. Continui",
    "text": "26.7 Spazi Discreti vs. Continui\nLa natura dello spazio campionario determina come definiamo e calcoliamo le probabilità. Distinguiamo i due casi fondamentali: lo spazio campionario discreto\n\\[\n\\Omega = \\{a_1, a_2, \\dots, a_n\\} \\quad \\text{oppure} \\quad \\Omega = \\{a_1, a_2, \\dots\\}\n\\]\ne lo spazio campionario continuo\n\\[\n\\Omega = \\mathbb{R} .\n\\]\n\n26.7.1 Spazi Campionari Discreti\nCaratteristiche:\n\nGli esiti sono numerabili (finiti o infiniti ma separabili).\n\nEsempi:\n\nLancio di un dado: \\(\\Omega = \\{1, 2, 3, 4, 5, 6\\}\\).\n\nNumero di clienti in un negozio in un’ora: \\(\\Omega = \\{0, 1, 2, \\dots\\}\\).\n\n\n\nDefinizione di Probabilità:\n\n\nAssegniamo una probabilità puntuale \\(p_i \\geq 0\\) a ogni esito \\(\\omega_i\\), con:\n\\[\n\\sum_{\\text{tutti gli } i} p_i = 1 \\quad \\text{(normalizzazione)}.\n\\]\n\n\nLa probabilità di un evento \\(A\\) si ottiene sommando le probabilità degli esiti in \\(A\\):\n\\[\nP(A) = \\sum_{\\omega_i \\in A} p_i.\n\\]\n\n\n\nEsempio 26.7 Lancio di un dado equilibrato.\n\nLa probabilità di ciascuna faccia è uniforme: \\(p_i = \\frac{1}{6}\\), con \\(i = 1, 2, \\dots, 6\\).\nConsideriamo l’evento \\(A = \\text{“Esce un numero pari\"}\\).\n\nPertanto, calcoliamo la probabilità di \\(A\\):\n\n\\[\nP(A) = p_2 + p_4 + p_6 = \\frac{1}{6} + \\frac{1}{6} + \\frac{1}{6} = \\frac{3}{6} = \\frac{1}{2}.\n\\]\nL’evento \\(A\\) ha dunque probabilità \\(\\frac{1}{2}\\).\n\n\n26.7.2 Spazi Campionari Continui\nCaratteristiche:\n\nGli esiti sono non numerabili (infiniti e “densi”).\n\nEsempi:\n\ntempo di attesa all’autobus: \\(\\Omega = [0, \\infty)\\);\n\naltezza di una persona: \\(\\Omega = [50\\, \\text{cm}, 250\\, \\text{cm}]\\).\n\n\n\nDefinizione di Probabilità:\n\nUsiamo una funzione di densità di probabilità (PDF) \\(f(x) \\geq 0\\), con:\\[\n\\int_{-\\infty}^{\\infty} f(x)\\, dx = 1 \\quad \\text{(normalizzazione)}.\n\\]\n\nLa probabilità di un evento \\(A\\) si ottiene integrando la PDF su \\(A\\):\\[\nP(A) = \\int_{A} f(x)\\, dx.\n\\]\n\n\n\nEsempio 26.8 Misurazione dell’altezza degli uomini adulti, modellata come variabile aleatoria continua \\(X\\) (in cm) con distribuzione normale \\(\\mathcal{N}(170, 7^2)\\) (si veda la Sezione Capitolo 40):\nLa funzione di densità (PDF) corrispondente è:\n\\[\nf(x)\n= \\frac{1}{7\\sqrt{2\\pi}} \\exp\\!\\Bigl(-\\frac{(x - 170)^2}{2 \\cdot 7^2}\\Bigr),\n\\quad\nX \\sim \\mathcal{N}(170,\\, 7^2).\n\\]\nEvento di interesse:\\[\nA = \\text{“Altezza compresa tra 160 cm e 180 cm”}.\n\\]\nCalcolo della probabilità:\nLa probabilità di \\(A\\) è l’area sotto la curva della densità tra 160 cm e 180 cm:\n\\[\nP(A) \\;=\\; \\int_{160}^{180} \\frac{1}{7\\sqrt{2\\pi}}\n\\exp\\!\\Bigl(-\\frac{(x - 170)^2}{98}\\Bigr)\\,\\mathrm{d}x.\n\\]\nIn alternativa, si può scrivere:\n\\[\nP(160 \\leq X \\leq 180) \\;\\approx\\; 0.847 \\quad (84.7\\%).\n\\]\nPiù avanti vedremo come calcolare facilmente questa probabilità tramite R, ad esempio con il comando:\n\npnorm(180, 170, 7) - pnorm(160, 170, 7)\n#&gt; [1] 0.8469\n\nQuesto codice restituisce la differenza tra le funzioni di ripartizione (CDF) a 180 e a 160, corrispondente proprio all’area desiderata sotto la PDF.\n\n\n26.7.3 Confronto Chiave\n\n\n\n\n\n\n\nCaratteristica\nSpazio Discreto\nSpazio Continuo\n\n\n\nEsiti\nNumerabili (es: 1, 2, 3)\nNon numerabili (es: intervalli)\n\n\nProbabilità di un singolo punto\n\n\\(P(\\{\\omega_i\\}) = p_i\\) (\\(\\geq\\) 0)\n\n\\(P(\\{x\\}) = 0\\) (sempre zero)\n\n\nStrumento matematico\nSomma \\(\\sum\\)\n\nIntegrale \\(\\int\\)\n\n\n\nEsempi comuni\nDadi, monete, conteggi\nMisure fisiche, tempi, temperature\n\n\n\n\n\n\n\n\n\nProprietà della PDF\n\n\n\n\nNegli spazi continui, la PDF non è una probabilità (può essere &gt; 1), ma la sua area sottesa su un intervallo fornisce la probabilità.\n\nPer eventi continui, ha senso solo calcolare probabilità su intervalli (es: \\(P(160 \\leq X \\leq 180)\\)).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#dai-concetti-base-alle-proprietà-fondamentali-della-probabilità",
    "href": "chapters/probability/02_probability_models.html#dai-concetti-base-alle-proprietà-fondamentali-della-probabilità",
    "title": "26  Modelli probabilistici",
    "section": "\n26.8 Dai Concetti Base alle Proprietà Fondamentali della Probabilità",
    "text": "26.8 Dai Concetti Base alle Proprietà Fondamentali della Probabilità\nAbbiamo visto come un esperimento casuale possa essere formalizzato matematicamente attraverso tre elementi chiave:\n\n\nSpazio campionario (\\(\\Omega\\)): l’insieme di tutti i possibili esiti dell’esperimento.\n\nEventi: sottoinsiemi di \\(\\Omega\\) che rappresentano combinazioni di esiti di interesse.\n\nProbabilità: una funzione \\(P\\) che assegna a ogni evento un valore numerico compreso tra 0 e 1, misurandone il grado di verosimiglianza.\n\nPartendo da queste definizioni, è possibile derivare proprietà essenziali per il calcolo e l’analisi probabilistica. Queste proprietà consentono di determinare la probabilità di eventi complessi a partire da eventi elementari e di stabilire relazioni logiche tra di essi.\nIn questo corso, approfondiremo quattro teoremi fondamentali:\n\nteorema della somma;\nteorema del prodotto;\nteorema della probabilità totale;\nteorema di Bayes.\n\nL’introduzione di operazioni sugli eventi (unione, intersezione, complemento) e delle proprietà della probabilità (teorema della somma, probabilità condizionata, teorema della probabilità totale, …) ci consente di costruire modelli probabilistici più complessi e applicabili a problemi reali.\nQui di seguito, approfondiamo il teorema della somma.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#teorema-della-somma",
    "href": "chapters/probability/02_probability_models.html#teorema-della-somma",
    "title": "26  Modelli probabilistici",
    "section": "\n26.9 Teorema della Somma",
    "text": "26.9 Teorema della Somma\nIl teorema della somma (o regola additiva) permette di determinare la probabilità che si verifichi almeno uno tra due eventi \\(A\\) e \\(B\\). La sua formulazione dipende dalla relazione tra i due eventi:\nCaso 1: Eventi Mutuamente Esclusivi. Se \\(A\\) e \\(B\\) non possono verificarsi insieme (ossia \\(A \\cap B = \\emptyset\\)), la probabilità dell’unione è la somma delle singole probabilità:\n\\[\nP(A \\cup B) = P(A) + P(B).\n\\tag{26.1}\\]\nCaso 2: Eventi Non Esclusivi. Se \\(A\\) e \\(B\\) possono coesistere, è necessario evitare di contare due volte la loro intersezione:\n\\[\nP(A \\cup B) = P(A) + P(B) - P(A \\cap B).\n\\tag{26.2}\\]\nPerché questa differenza?\nLa probabilità è una funzione d’insieme coerente con le operazioni insiemistiche. L’addizione diretta \\(P(A) + P(B)\\) conteggia due volte gli esiti comuni a \\(A\\) e \\(B\\) (rappresentati da \\(A \\cap B\\)). La sottrazione di \\(P(A \\cap B)\\) garantisce che ogni esito sia considerato una sola volta.\nIl teorema della somma sottolinea come le operazioni logiche tra eventi (unione, intersezione) si riflettano in relazioni algebriche tra le loro probabilità, fornendo uno strumento operativo per modellare scenari reali.\n\nEsempio 26.9 In uno studio sulla salute mentale, supponiamo di avere i seguenti dati relativi a un campione di partecipanti:\n\nla probabilità che un individuo soffra di ansia è \\(P(A) = 0.30\\);\n\nla probabilità che un individuo soffra di depressione è \\(P(B) = 0.25\\);\nla probabilità che un individuo soffra contemporaneamente di ansia e depressione è \\(P(A \\cap B) = 0.15\\).\n\nVogliamo calcolare la probabilità che un individuo soffra di almeno uno dei due disturbi (ansia o depressione), ovvero \\(P(A \\cup B)\\).\nUtilizziamo la regola della somma per eventi non mutuamente esclusivi:\n\\[\nP(A \\cup B) = P(A) + P(B) - P(A \\cap B)\n\\]\nSvolgiamo questo calcolo in R:\n\n# Definiamo le probabilità\nP_A &lt;- 0.30 # Probabilità di soffrire di ansia\nP_B &lt;- 0.25 # Probabilità di soffrire di depressione\nP_A_intersect_B &lt;- 0.15 # Probabilità di soffrire di entrambi i disturbi\n\n# Applichiamo la formula della regola della somma\nP_A_union_B &lt;- P_A + P_B - P_A_intersect_B\nP_A_union_B\n#&gt; [1] 0.4\n\nInterpretazione: il 40% dei partecipanti soffre di almeno uno tra ansia e depressione. L’intersezione \\(P(A \\cap B) = 0.15\\) è fondamentale, poiché senza sottrarla avremmo contato due volte i soggetti che soffrono contemporaneamente di entrambi i disturbi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#probabilità-calcolo-combinatorio-e-simulazioni",
    "href": "chapters/probability/02_probability_models.html#probabilità-calcolo-combinatorio-e-simulazioni",
    "title": "26  Modelli probabilistici",
    "section": "\n26.10 Probabilità, Calcolo Combinatorio e Simulazioni",
    "text": "26.10 Probabilità, Calcolo Combinatorio e Simulazioni\nIn molti problemi di probabilità, soprattutto quelli di taglio scolastico o introduttivo, si assume che ogni evento elementare abbia la stessa probabilità di verificarsi (equiprobabilità). In queste situazioni, il calcolo combinatorio risulta particolarmente utile per determinare la probabilità di un evento, poiché basta:\n\n\nDefinire gli eventi di successo: identificare tutte le configurazioni compatibili con l’evento di interesse.\n\n\nContare le possibilità: calcolare il numero di eventi di successo e rapportarlo al numero totale di eventi nello spazio campionario.\n\n\nEsempio 26.10 Estrazione di una pallina da un’urna\nSupponiamo di avere un’urna con 10 palline numerate da 1 a 10, da cui estraiamo una sola pallina in modo casuale. Assumendo che ogni pallina abbia la stessa probabilità di essere estratta, calcoliamo la probabilità di estrarre un numero pari.\n\n\nEventi di successo: \\(\\{\\;2, 4, 6, 8, 10\\}\\) (5 casi)\n\n\nEventi totali: \\(\\{\\;1, 2, 3, 4, 5, 6, 7, 8, 9, 10\\}\\) (10 casi)\n\nLa probabilità cercata è quindi:\n\\[\nP(\\text{numero pari}) \\;=\\; \\frac{\\text{numero di eventi di successo}}{\\text{numero totale di eventi}}\n\\;=\\; \\frac{5}{10} \\;=\\; 0.5.\n\\]\n\nNelle applicazioni più complesse, come il calcolo della probabilità di ottenere una determinata combinazione di carte o il formare gruppi specifici partendo da una popolazione, utilizzeremo tecniche combinatorie più avanzate — ad esempio permutazioni e combinazioni (si veda la Sezione Appendice H) — che consentono di contare in modo sistematico gli eventi possibili e quelli di successo.\n\n26.10.1 Simulazioni Monte Carlo\nUno degli aspetti più impegnativi della probabilità è che molti problemi non si prestano a soluzioni immediate o intuitive. Per affrontarli, si possono adottare due approcci principali. Il primo consiste nell’applicare i teoremi della teoria della probabilità, un metodo rigoroso ma spesso controintuitivo. Il secondo approccio è quello della simulazione Monte Carlo, che permette di ottenere una soluzione approssimata, ma molto vicina al valore reale, seguendo una procedura più accessibile e intuitiva. Questo metodo prende il nome dal famoso Casinò di Monte Carlo a Monaco, anche se può essere semplicemente definito come “metodo di simulazione.”\nLa simulazione Monte Carlo appartiene a una classe generale di metodi stocastici che si contrappongono ai metodi deterministici. Questi metodi consentono di risolvere approssimativamente problemi analitici attraverso la generazione casuale delle quantità di interesse. Tra le tecniche comunemente utilizzate troviamo il campionamento con reinserimento, in cui la stessa unità può essere selezionata più volte, e il campionamento senza reinserimento, dove ogni unità può essere selezionata una sola volta. Questi strumenti rappresentano un mezzo potente e pratico per affrontare problemi complessi.\n\n26.10.2 Il Problema dei Complenni\nUn esempio classico di applicazione del metodo Monte Carlo è il calcolo delle probabilità relative a vari eventi definiti attraverso il modello dell’urna. Tra questi, abbiamo il celebre problema dei compleanni.\nIl problema dei compleanni esplora la probabilità che, in un gruppo di \\(n\\) persone, almeno due persone condividano la stessa data di nascita. Supponendo che i compleanni siano distribuiti uniformemente su 365 giorni (ignorando anni bisestili), il problema sorprende molte persone per il fatto che già con 23 persone la probabilità di una coincidenza è superiore al 50%.\n\n26.10.2.1 Soluzione analitica\nQuesto problema può essere risolto utilizzando il concetto di probabilità complementari. Infatti, il problema può essere visto da due prospettive complementari:\n\n\nCaso 1: tutti i compleanni sono diversi (nessuna persona condivide il compleanno con un’altra);\n\nCaso 2: almeno due persone condividono lo stesso compleanno.\n\nQuesti due casi sono mutuamente esclusivi (non possono verificarsi contemporaneamente) ed esaustivi (coprono tutte le possibilità). Pertanto, la somma delle loro probabilità deve essere uguale a 1:\n\\[\nP(\\text{almeno un compleanno in comune}) = 1 - P(\\text{nessun compleanno in comune}).\n\\]\nIn altre parole, per calcolare la probabilità che almeno due persone abbiano lo stesso compleanno, possiamo prima calcolare la probabilità che tutti i compleanni siano diversi e poi sottrarre questo valore da 1.\nCaso 1: probabilità che tutti i compleanni siano diversi.\nPer calcolare \\(P(\\text{nessun compleanno in comune})\\), seguiamo questo ragionamento:\n\nPrima persona: Può scegliere liberamente un giorno del calendario. Ci sono 365 possibilità (ignoriamo gli anni bisestili per semplicità).\nSeconda persona: Deve avere un compleanno diverso dalla prima persona. Quindi, ci sono 364 giorni disponibili.\nTerza persona: Deve avere un compleanno diverso dai primi due. Ci sono 363 giorni disponibili.\n\nQuesto processo continua fino alla \\(n\\)-esima persona, che avrà \\(365 - n + 1\\) giorni disponibili.\nLa probabilità che tutti i compleanni siano diversi si ottiene moltiplicando le probabilità individuali di ogni persona di avere un compleanno diverso dai precedenti. Poiché ogni scelta è indipendente, possiamo scrivere:\n\\[\nP(\\text{nessun compleanno in comune}) = \\frac{365}{365} \\cdot \\frac{364}{365} \\cdot \\frac{363}{365} \\cdot \\ldots \\cdot \\frac{365-n+1}{365}.\n\\]\nQuesto prodotto può essere espresso in forma compatta utilizzando il fattoriale:\n\\[\nP(\\text{nessun compleanno in comune}) = \\frac{365!}{(365-n)! \\cdot 365^n} ,\n\\]\ndove:\n\n\n\\(365!\\) è il fattoriale di 365 (il prodotto di tutti i numeri interi da 1 a 365).\n\n\\((365-n)!\\) è il fattoriale di \\(365 - n\\).\n\n\\(365^n\\) rappresenta tutte le possibili combinazioni di compleanni per \\(n\\) persone.\n\nCaso 2. Probabilità di almeno un compleanno in comune.\nOra che abbiamo calcolato la probabilità che tutti i compleanni siano diversi, possiamo trovare la probabilità che almeno due persone abbiano lo stesso compleanno come il complemento:\n\\[\nP(\\text{almeno un compleanno in comune}) = 1 - P(\\text{nessun compleanno in comune}).\n\\]\nSostituendo l’espressione precedente, otteniamo:\n\\[\nP(\\text{almeno un compleanno in comune}) = 1 - \\frac{365!}{(365-n)! \\cdot 365^n}.\n\\]\nOra che abbiamo le formule per i due eventi complementari, come funzione di \\(n\\), applichiamole al caso specifico in cui \\(n\\) = 23. Questo è un valore interessante perché, come vedremo, la probabilità che almeno due persone su 23 condividano lo stesso compleanno supera il 50%.\nLa formula per la probabilità che tutti i compleanni siano diversi è:\n\\[\nP(\\text{nessun compleanno in comune}) = \\frac{365!}{(365-n)! \\cdot 365^n}.\n\\]\nPer \\(n = 23\\), sostituiamo il valore nella formula:\n\\[\nP(\\text{nessun compleanno in comune}) = \\frac{365!}{(365-23)! \\cdot 365^{23}}.\n\\]\nSemplifichiamo:\n\\[\nP(\\text{nessun compleanno in comune}) = \\frac{365!}{342! \\cdot 365^{23}}.\n\\]\nUtilizzando R, troviamo:\n\n# Numero di persone\nn &lt;- 23\n\n# Calcolo della probabilità che tutti abbiano compleanni diversi\nnumeratore &lt;- prod(365:(365 - n + 1))\ndenominatore &lt;- 365^n\n\nP_diversi &lt;- numeratore / denominatore\nP_diversi  # stampa la probabilità\n#&gt; [1] 0.4927\n\n\\[\nP(\\text{nessun compleanno in comune}) \\approx 0{,}4927.\n\\]\nCiò implica che la probabilità che 23 persone abbiano compleanni distinti sia approssimativamente 0.4927 (pari al 49.27%).\nLa probabilità che almeno due persone (su 23) condividano lo stesso compleanno corrisponde al complemento della probabilità appena calcolata:\n\\[\nP(\\text{almeno un compleanno in comune}) = 1 - P(\\text{nessun compleanno in comune}).\n\\]\nSostituendo il valore ottenuto:\n\\[\nP(\\text{almeno un compleanno in comune}) = 1 - 0{.}4927 = 0{.}5073.\n\\]\nRisultato finale:\nCon \\(n = 23\\), la probabilità che almeno una coppia condivida il compleanno supera il 50%, attestandosi intorno a 0.5073 (50.73%). Questo esito è spesso sorprendente, poiché intuitivamente si tende a sottostimare l’effetto della combinatoria: sebbene 23 possano sembrare poche, le \\(\\binom{23}{2} = 253\\) possibili coppie rendono statisticamente probabile una corrispondenza.\n\n26.10.2.2 Soluzione con Simulazione in R\nPer risolvere il problema tramite simulazione, possiamo generare gruppi casuali di \\(n\\) persone, assegnando loro un compleanno casuale tra 1 e 365. Per ogni gruppo, verifichiamo se almeno due persone condividono lo stesso compleanno.\nEcco il codice R:\n\n# Numero di simulazioni\nnum_simulazioni &lt;- 10000\n\n# Funzione per simulare il problema del compleanno\nsimula_compleanno &lt;- function(n) {\n  # Conta il numero di successi (almeno un compleanno in comune)\n  successi &lt;- 0\n\n  # Loop per il numero di simulazioni\n  for (i in 1:num_simulazioni) {\n    # Genera n compleanni casuali\n    compleanni &lt;- sample(1:365, n, replace = TRUE)\n\n    # Verifica se ci sono duplicati\n    if (any(duplicated(compleanni))) {\n      successi &lt;- successi + 1\n    }\n  }\n\n  # Calcola la probabilità stimata\n  return(successi / num_simulazioni)\n}\n\nProviamo con diversi valori di n.\n\nset.seed(123) # Fissiamo il seme per la riproducibilità\nrisultati &lt;- sapply(1:50, simula_compleanno)\n\n# Creiamo un data frame con i risultati\ndf &lt;- data.frame(\n  n = 1:50,\n  prob = risultati\n)\n\n# Creiamo il grafico\nggplot(df, aes(x = n, y = prob)) +\n  geom_line(color = \"blue\") +\n  geom_point(color = \"blue\") +\n  geom_hline(yintercept = 0.5, color = \"red\", linetype = \"dashed\") +\n  labs(\n    x = \"Numero di persone (n)\",\n    y = \"Probabilità stimata\",\n    title = \"Problema del Compleanno (Simulazione)\"\n  )\n\n\n\n\n\n\n\n\n\nSimulazioni: Per ogni gruppo di \\(n\\), si eseguono 10000 simulazioni, in cui si generano \\(n\\) compleanni casuali tra 1 e 365.\n\nDuplicati: La funzione duplicated() verifica se ci sono compleanni ripetuti.\n\nCalcolo della probabilità: La proporzione di simulazioni in cui si verifica almeno un compleanno condiviso rappresenta la probabilità stimata.\n\nVisualizzazione: Si tracciano le probabilità per diversi valori di \\(n\\), evidenziando il punto in cui la probabilità supera il 50%.\n\nRisultati attesi:\n\ncon circa 23 persone, la probabilità stimata sarà superiore a 0.5;\nil grafico mostra una curva crescente con un rapido aumento della probabilità per \\(n\\) piccoli e un asintoto vicino a 1 per \\(n\\) grandi.\n\nQuesto approccio permette di comprendere intuitivamente il problema e di verificare i risultati teorici con la simulazione.\n\n26.10.2.3 Assunzioni\nIl problema dei compleanni evidenzia non solo l’efficacia dell’approccio simulativo nel semplificare la soluzione rispetto all’analisi formale, ma anche l’importanza delle assunzioni che entrambi i metodi condividono. In questo caso, l’assunzione è che la probabilità di nascita sia uniformemente distribuita nei 365 giorni dell’anno — un’ipotesi semplificativa che non rispecchia la realtà.\nQuesto esempio sottolinea un principio fondamentale dei modelli probabilistici (e scientifici in generale): ogni modello si basa su un insieme di assunzioni che ne delimitano la validità e l’applicabilità. Valutare criticamente la plausibilità di tali assunzioni è dunque essenziale per garantire che il modello fornisca una rappresentazione utile del fenomeno studiato.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#riflessioni-conclusive",
    "href": "chapters/probability/02_probability_models.html#riflessioni-conclusive",
    "title": "26  Modelli probabilistici",
    "section": "\n26.11 Riflessioni Conclusive",
    "text": "26.11 Riflessioni Conclusive\nLa teoria della probabilità fornisce un quadro rigoroso per descrivere e analizzare fenomeni caratterizzati dall’incertezza. In questo capitolo abbiamo introdotto i concetti fondamentali del calcolo delle probabilità, evidenziando come la modellazione matematica degli esperimenti casuali consenta di quantificare e prevedere eventi incerti. Abbiamo esplorato strumenti essenziali come la definizione di spazio campionario, la nozione di evento e le regole della probabilità, illustrando il loro utilizzo sia attraverso esempi teorici sia mediante simulazioni computazionali.\nUn aspetto cruciale della modellazione probabilistica è il ruolo delle assunzioni su cui si basano i modelli. Ogni modello probabilistico si fonda su ipotesi specifiche riguardanti la natura del fenomeno studiato e il modo in cui gli esiti vengono generati. Queste ipotesi determinano non solo la validità del modello, ma anche il tipo di risposte che esso può fornire. Ad esempio, nel problema del compleanno, abbiamo ipotizzato che i compleanni siano distribuiti in modo uniforme nei 365 giorni dell’anno. Sebbene questa assunzione semplifichi notevolmente i calcoli, sappiamo che nella realtà esistono fluttuazioni stagionali nelle nascite che possono influenzare le probabilità effettive.\nQuesto ci porta a una considerazione più ampia: la probabilità non è solo un insieme di formule, ma uno strumento per rappresentare l’incertezza e prendere decisioni informate. Tuttavia, l’accuratezza di qualsiasi modello probabilistico dipende strettamente dalla plausibilità delle ipotesi adottate. Modelli diversi, basati su ipotesi differenti, possono portare a risultati diversi, e l’interpretazione dei risultati deve sempre tenere conto di queste assunzioni.\nIn definitiva, lo studio della probabilità non si limita alla manipolazione di formule, ma richiede un’attenta riflessione sulla relazione tra modelli teorici e fenomeni reali. Una comprensione critica delle assunzioni alla base di un modello è essenziale per applicare correttamente i concetti probabilistici in contesti pratici, sia in ambito scientifico che nelle decisioni quotidiane.\n\n\n\n\n\n\nRisposte alle domande iniziali\n\n\n\nIl 92% delle persone sovrastima il numero necessario per la prima domanda e sottostima la seconda probabilità. Questo problema mostra come l’intuizione umana fallisca con eventi apparentemente “rari”.\n\nLa risposta è 23 persone.\nLa probabilità è \\(\\sim 0.7\\)",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#esercizi",
    "href": "chapters/probability/02_probability_models.html#esercizi",
    "title": "26  Modelli probabilistici",
    "section": "\n26.12 Esercizi",
    "text": "26.12 Esercizi\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nQui di seguito sono presentati una serie di esercizi sbasati sulla Satisfaction with Life Scale (SWLS).\nEsercizi sullo Spazio Campionario e Eventi\n\n\nDefinizione dello Spazio Campionario\nSupponiamo che i punteggi della Satisfaction with Life Scale (SWLS) siano numeri interi compresi tra 5 e 35.\n\nQual è lo spazio campionario \\(\\Omega\\) per questo esperimento?\nSe hai raccolto i dati di 15 studenti, come potresti rappresentare lo spazio campionario con i loro punteggi osservati?\n\n\n\nDefinizione di un Evento\nConsideriamo l’evento A: “Uno studente ha un punteggio SWLS superiore a 25”.\n\nEsprimi l’evento A come un sottoinsieme dello spazio campionario.\nSe tra i 15 studenti osservati, 4 hanno punteggi superiori a 25, qual è la proporzione sperimentale per l’evento A?\n\n\n\nEventi Complementari\nDefiniamo l’evento B: “Uno studente ha un punteggio SWLS inferiore o uguale a 25”.\n\nScrivi l’evento B in relazione all’evento A.\nQual è la probabilità empirica di B, sapendo che 4 studenti hanno punteggi superiori a 25?\n\n\n\nEsercizi sulle Operazioni tra Eventi\n\n\nUnione di Eventi\nDefiniamo due eventi:\n\n\nA: “Il punteggio SWLS è superiore a 25”.\n\n\nC: “Il punteggio SWLS è inferiore a 15”.\n\nScrivi l’evento A ∪ C (“Lo studente ha un punteggio maggiore di 25 o minore di 15”).\nSe nel campione di 15 studenti, 4 studenti hanno punteggi superiori a 25 e 3 hanno punteggi inferiori a 15, qual è la proporzione empirica di A ∪ C?\n\n\n\nIntersezione di Eventi e Eventi Disgiunti\nSupponiamo che l’evento D sia: “Uno studente ha un punteggio pari a 20”.\n\nL’evento D e l’evento A sono disgiunti?\nSe nessuno degli studenti ha ottenuto esattamente 20, qual è la probabilità empirica di A ∩ D?\n\n\n\nEsercizi sulle Regole della Probabilità 6. Probabilità dell’Unione di Eventi\nSupponiamo di avere:\n\n\nP(A) = 0.3 (probabilità che un punteggio sia superiore a 25).\n\n\nP(C) = 0.2 (probabilità che un punteggio sia inferiore a 15).\n\n\nP(A ∩ C) = 0 (perché un punteggio non può essere contemporaneamente superiore a 25 e inferiore a 15).\n\nUsa la regola dell’unione per calcolare P(A ∪ C).\n\n\n\nProbabilità Condizionata\nConsideriamo:\n\n\nP(A) = 0.3 (probabilità che un punteggio sia superiore a 25).\n\n\nP(E) = 0.5 (probabilità che uno studente abbia più di 20 anni).\n\n\nP(A | E) = 0.4 (probabilità che un soggetto con più di 20 anni abbia un punteggio superiore a 25).\n\nUsa la formula della probabilità condizionata per calcolare P(A ∩ E).\n\n\n\nEsercizi su Permutazioni e Combinazioni\n\n\nSelezione Casuale di Studenti\nDal campione di 15 studenti, supponiamo di voler selezionare casualmente 3 studenti per partecipare a un’intervista sulla loro soddisfazione di vita.\n\nQuanti modi ci sono per selezionare 3 studenti su 15?\n\n\n\nOrdinare gli Studenti per Discussione\nSupponiamo di voler formare un piccolo gruppo di discussione con 3 studenti, scegliendoli in ordine di intervento.\n\nQuante diverse sequenze di 3 studenti possiamo ottenere?\n\n\nFormare Coppie di Studenti\nSe vogliamo formare coppie di studenti per un esercizio collaborativo, senza considerare l’ordine, quanti modi ci sono per farlo?\n\n\n\n\n\n\n\n\n\n\nSoluzione\n\n\n\n\n\n1. Definizione dello Spazio Campionario\n\n\nLo spazio campionario \\(\\Omega\\) per questo esperimento è l’insieme di tutti i possibili punteggi della Satisfaction with Life Scale (SWLS), quindi:\n\\[ \\Omega = \\{5, 6, 7, ..., 35\\} \\]\n\nSe abbiamo raccolto i dati di 15 studenti con punteggi osservati \\(\\{27, 21, 15, 30, 18, 23, 26, 35, 20, 22, 19, 25, 32, 29, 28\\}\\), possiamo considerare \\(\\Omega\\) come questo insieme specifico.\n\n2. Definizione di un Evento\n\n\nL’evento \\(A\\) “Uno studente ha un punteggio SWLS superiore a 25” è il sottoinsieme:\n\\[ A = \\{27, 30, 26, 35, 32, 29, 28\\}\\]\n\n\nSe 7 studenti su 15 hanno punteggi superiori a 25, la probabilità empirica è:\n\\[ P(A) = \\frac{7}{15} = 0.467 \\]\n\n\n3. Eventi Complementari\n\n\nL’evento complementare \\(B\\) “Uno studente ha un punteggio SWLS inferiore o uguale a 25” è:\n\\[ B = \\{21, 15, 18, 23, 20, 22, 19, 25\\}\\]\n\n\nSe 8 studenti su 15 rientrano in \\(B\\), la probabilità empirica è:\n\\[ P(B) = 1 - P(A) = \\frac{8}{15} = 0.533 \\]\n\n\nSoluzioni agli Esercizi sulle Operazioni tra Eventi\n4. Unione di Eventi\n\n\nL’evento \\(A \\cup C\\) (“Lo studente ha un punteggio maggiore di 25 o minore di 15”) è:\n\\[ A \\cup C = \\{27, 30, 26, 35, 32, 29, 28, 15\\}\\]\n\n\nSe 8 studenti su 15 appartengono a \\(A \\cup C\\), la probabilità empirica è:\n\\[ P(A \\cup C) = \\frac{8}{15} = 0.533 \\]\n\n\n5. Intersezione di Eventi e Eventi Disgiunti\n\nL’evento \\(D\\) “Uno studente ha un punteggio pari a 20” è \\(D = \\{20\\}\\).\n\nL’evento \\(A \\cap D\\) è l’insieme degli elementi comuni a \\(A\\) e \\(D\\), ma \\(D\\) non ha elementi in \\(A\\), quindi:\n\\[ A \\cap D = \\emptyset \\]\n\nEssendo \\(A \\cap D = \\emptyset\\), gli eventi sono disgiunti e \\(P(A \\cap D) = 0\\).\n\nSoluzioni agli Esercizi sulle Regole della Probabilità\n6. Probabilità dell’Unione di Eventi\nUsiamo la formula:\n\\[ P(A \\cup C) = P(A) + P(C) - P(A \\cap C) \\]\nDato che \\(P(A \\cap C) = 0\\), abbiamo:\n\\[ P(A \\cup C) = 0.3 + 0.2 - 0 = 0.5 \\]\n7. Probabilità Condizionata\nLa probabilità congiunta \\(P(A \\cap E)\\) si calcola con:\n\\[ P(A \\cap E) = P(A | E) \\cdot P(E) \\]\nSostituendo i valori:\n\\[ P(A \\cap E) = 0.4 \\times 0.5 = 0.2 \\]\nSoluzioni agli Esercizi su Permutazioni e Combinazioni\n8. Selezione Casuale di Studenti\nIl numero di modi per scegliere 3 studenti su 15 (combinazioni) è:\n\\[ C_{15,3} = \\frac{15!}{3!(15-3)!} = \\frac{15!}{3!12!} = \\frac{15 \\times 14 \\times 13}{3 \\times 2 \\times 1} = 455 \\]\n9. Ordinare gli Studenti per Discussione\nIl numero di modi per scegliere e ordinare 3 studenti su 15 (disposizioni) è:\n\\[ D_{15,3} = \\frac{15!}{(15-3)!} = \\frac{15!}{12!} = 15 \\times 14 \\times 13 = 2730 \\]\n10. Formare Coppie di Studenti\nIl numero di modi per formare coppie (combinazioni di 2 studenti su 15) è:\n\\[ C_{15,2} = \\frac{15!}{2!(15-2)!} = \\frac{15 \\times 14}{2 \\times 1} = 105 \\]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_probability_models.html#bibliografia",
    "href": "chapters/probability/02_probability_models.html#bibliografia",
    "title": "26  Modelli probabilistici",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nChan, J. C. C., & Kroese, D. P. (2025). Statistical Modeling and Computation (2ª ed.). Springer.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Modelli probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_spaces.html",
    "href": "chapters/probability/03_prob_spaces.html",
    "title": "27  La Probabilità come misura della certezza razionale: un’interpretazione Bayesiana",
    "section": "",
    "text": "27.1 Introduzione\nNel Capitolo 26 abbiamo introdotto il concetto di probabilità come una funzione che soddisfa gli assiomi di Kolmogorov:\nSebbene questa formalizzazione matematica sia essenziale, rimane aperta una questione fondamentale: qual è il significato intrinseco dei valori numerici che chiamiamo “probabilità”? Questo interrogativo ha alimentato un secolare dibattito filosofico che esploreremo in questo capitolo attraverso la lente dell’interpretazione bayesiana.\nAdotteremo una prospettiva in cui la probabilità non descrive frequenze osservabili, bensì quantifica il grado di convinzione razionale di un agente epistemico. In questa visione soggettivista, la probabilità diventa una misura normativa di come dovremmo allocare la nostra certezza totale (normalizzata a 1) tra proposizioni mutualmente esclusive ed esaustive.\nPer rendere operativo questo framework, seguiremo la trattazione proposta da Michael Betancourt. Ci concentreremo qui sull’interpretazione della probabilità come distribuzione della nostra certezza soggettiva.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>La Probabilità come misura della certezza razionale: un'interpretazione Bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_spaces.html#introduzione",
    "href": "chapters/probability/03_prob_spaces.html#introduzione",
    "title": "27  La Probabilità come misura della certezza razionale: un’interpretazione Bayesiana",
    "section": "",
    "text": "Non-negatività e normalizzazione: \\(0 \\leq P(A) \\leq 1\\) per ogni evento \\(A\\), con \\(P(\\Omega) = 1\\).\nAdditività numerabile: Per una successione di eventi disgiunti \\(\\{A_i\\}\\), \\[\nP\\Bigl(\\bigcup_{i} A_i\\Bigr) = \\sum_{i} P(A_i) .\n\\]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>La Probabilità come misura della certezza razionale: un'interpretazione Bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_spaces.html#distribuzione-della-certezza-soggettiva-sugli-elementi",
    "href": "chapters/probability/03_prob_spaces.html#distribuzione-della-certezza-soggettiva-sugli-elementi",
    "title": "27  La Probabilità come misura della certezza razionale: un’interpretazione Bayesiana",
    "section": "27.2 Distribuzione della Certezza Soggettiva sugli Elementi",
    "text": "27.2 Distribuzione della Certezza Soggettiva sugli Elementi\nIn un approccio bayesiano, la probabilità rappresenta il grado di certezza soggettiva che attribuiamo al verificarsi di un certo evento. Immaginiamo di possedere una certezza totale pari a 1, che corrisponde alla nostra convinzione complessiva che, tra tutti gli esiti possibili, qualcosa avverrà. Questa certezza totale deve essere ripartita tra i diversi eventi.\nConsideriamo il seguente spazio campionario discreto:\n\\[\nX = \\{\\Box, \\clubsuit, \\diamondsuit, \\heartsuit, \\spadesuit\\}.\n\\]\nAd ogni elemento \\(x_n \\in X\\) associamo un valore \\(p_n \\geq 0\\), interpretato come la frazione della nostra certezza totale che assegnamo a quell’evento. Poiché la certezza complessiva è 1, la somma dei valori deve essere:\n\\[\np_{\\Box} + p_{\\clubsuit} + p_{\\diamondsuit} + p_{\\heartsuit} + p_{\\spadesuit} = 1.\n\\]\nQuesta collezione \\(\\{ p_{\\Box}, p_{\\clubsuit}, p_{\\diamondsuit}, p_{\\heartsuit}, p_{\\spadesuit} \\}\\), in cui ciascun valore è compreso tra 0 e 1, è quella che chiamiamo distribuzione di probabilità. Ogni \\(p_n\\) esprime il grado di certezza (in termini relativi) che attribuiamo all’evento corrispondente a \\(x_n\\).\n\n\n\n\n\n\nFigura 27.1: Un’allocazione proporzionale è anche conosciuta come distribuzione di probabilità.\n\n\n\nQuesta visione ci permette di passare da una certezza assoluta (1) a una distribuzione in cui la certezza è divisa in porzioni proporzionali tra i vari eventi. Per esempio, se siamo particolarmente convinti che l’evento \\(\\Box\\) si verifichi, potremmo assegnargli un valore alto, mentre a un evento meno probabile corrisponderà un valore più basso.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>La Probabilità come misura della certezza razionale: un'interpretazione Bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_spaces.html#distribuzione-della-certezza-sugli-sottoinsiemi",
    "href": "chapters/probability/03_prob_spaces.html#distribuzione-della-certezza-sugli-sottoinsiemi",
    "title": "27  La Probabilità come misura della certezza razionale: un’interpretazione Bayesiana",
    "section": "27.3 Distribuzione della Certezza Sugli Sottoinsiemi",
    "text": "27.3 Distribuzione della Certezza Sugli Sottoinsiemi\nUna volta che abbiamo assegnato un grado di certezza soggettiva a ciascun elemento di \\(X\\), possiamo estendere questa assegnazione a qualsiasi sottoinsieme di \\(X\\). In altre parole, se ad ogni elemento \\(x_n \\in X\\) assegniamo la probabilità (cioè, il grado di certezza) \\(p_n\\), la certezza complessiva che un sottoinsieme \\(\\mathsf{x} \\subset X\\) si realizzi è data dalla somma dei gradi di certezza dei suoi elementi:\n\\[\nP(\\mathsf{x}) = \\sum_{x_n \\in \\mathsf{x}} p_n.\n\\]\nPer costruzione, valgono le seguenti proprietà:\n\nLa certezza associata all’insieme vuoto è zero:\n\\[\nP(\\emptyset) = 0.\n\\]\nLa certezza associata all’intero spazio campionario è 1:\n\\[\nP(X) = \\sum_{n} p_n = 1.\n\\]\n\nQueste proprietà sono in linea con l’idea che la nostra certezza totale (pari a 1) venga completamente distribuita tra tutti gli eventi possibili.\n\n27.3.1 Additività\nSe un sottoinsieme può essere suddiviso in parti che non si sovrappongono, il grado di certezza dell’intero sottoinsieme è la somma dei gradi di certezza delle parti. Ad esempio, se \\(\\mathsf{x}_1\\) e \\(\\mathsf{x}_2\\) sono sottoinsiemi disgiunti (cioè, non hanno elementi in comune), allora:\n\\[\nP(\\mathsf{x}_1 \\cup \\mathsf{x}_2) = P(\\mathsf{x}_1) + P(\\mathsf{x}_2).\n\\]\nIn particolare, se \\(\\mathsf{x}\\) è un sottoinsieme di \\(X\\), il complemento \\(\\mathsf{x}^c\\) (cioè, tutti gli elementi non in \\(\\mathsf{x}\\)) è disgiunto da \\(\\mathsf{x}\\) e la loro unione dà \\(X\\). Quindi:\n\\[\nP(\\mathsf{x}) + P(\\mathsf{x}^c) = 1 \\quad \\Longrightarrow \\quad P(\\mathsf{x}^c) = 1 - P(\\mathsf{x}).\n\\]\n\n\n27.3.2 Sovrapposizione di Sottoinsiemi\nQuando due sottoinsiemi si sovrappongono, la certezza degli elementi comuni viene conteggiata in entrambe le somme. Per chiarire, consideriamo:\n\n\\(\\mathsf{x}_1 = \\{\\Box, \\heartsuit\\}\\),\n\\(\\mathsf{x}_2 = \\{\\Box, \\spadesuit\\}\\).\n\nAllora:\n\nLa certezza di \\(\\mathsf{x}_1\\) è \\(P(\\mathsf{x}_1) = p_{\\Box} + p_{\\heartsuit}\\).\nLa certezza di \\(\\mathsf{x}_2\\) è \\(P(\\mathsf{x}_2) = p_{\\Box} + p_{\\spadesuit}\\).\nL’intersezione è \\(\\mathsf{x}_1 \\cap \\mathsf{x}_2 = \\{\\Box\\}\\), con certezza \\(p_{\\Box}\\).\nL’unione è \\(\\mathsf{x}_1 \\cup \\mathsf{x}_2 = \\{\\Box, \\heartsuit, \\spadesuit\\}\\), con certezza\n\\[\nP(\\mathsf{x}_1 \\cup \\mathsf{x}_2) = p_{\\Box} + p_{\\heartsuit} + p_{\\spadesuit}.\n\\]\n\nNotiamo che:\n\\[\nP(\\mathsf{x}_1) + P(\\mathsf{x}_2) = P(\\mathsf{x}_1 \\cup \\mathsf{x}_2) + p_{\\Box} = P(\\mathsf{x}_1 \\cup \\mathsf{x}_2) + P(\\mathsf{x}_1 \\cap \\mathsf{x}_2).\n\\]\nQuesto è un esempio del principio di inclusione-esclusione, che garantisce che non contiamo più volte la certezza degli elementi comuni.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>La Probabilità come misura della certezza razionale: un'interpretazione Bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_spaces.html#costruzione-delle-distribuzioni-di-certezza",
    "href": "chapters/probability/03_prob_spaces.html#costruzione-delle-distribuzioni-di-certezza",
    "title": "27  La Probabilità come misura della certezza razionale: un’interpretazione Bayesiana",
    "section": "27.4 Costruzione delle Distribuzioni di Certezza",
    "text": "27.4 Costruzione delle Distribuzioni di Certezza\nEsistono diversi modi per “costruire” una distribuzione di certezza (cioè, una distribuzione di probabilità) su uno spazio finito \\(X\\):\n\nDistribuzione globale:\nPossiamo assegnare simultaneamente il grado di certezza a tutti gli elementi di \\(X\\). In questo approccio si specifica direttamente la distribuzione \\(\\{p(x_n)\\}\\) per ciascun \\(x_n \\in X\\), in modo tale che\n\\[\n\\sum_{x_n \\in X} p(x_n) = 1.\n\\]\n\n\n\n\n\n\n\nFigura 27.2: Le misure possono essere costruite specificando le allocazioni degli elementi individuali tutte insieme.\n\n\n\n\nDistribuzione locale:\nPossiamo assegnare il grado di certezza a ciascun elemento uno alla volta, procedendo in maniera sequenziale. Questo metodo ci permette di “costruire” la distribuzione gradualmente, concentrandoci su un elemento alla volta.\n\n\n\n\n\n\n\nFigura 27.3: Le misure possono essere costruite specificando le allocazioni degli elementi individuali uno alla volta.\n\n\n\n\nDistribuzione iterativa:\nUn altro metodo consiste nel suddividere lo spazio campionario in sottoinsiemi disgiunti, assegnare ad ognuno un certo grado di certezza, e poi ripartire iterativamente la certezza all’interno di ciascun sottoinsieme fino a raggiungere gli elementi individuali.\n\n\n\n\n\n\n\nFigura 27.4: Le misure possono essere costruite allocando la misura totale a sottoinsiemi disgiunti e poi raffinando iterativamente tale allocazione a sottoinsiemi sempre più piccoli.\n\n\n\n\n\nQuesta flessibilità consente di adattare l’approccio alle esigenze specifiche del problema in esame.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>La Probabilità come misura della certezza razionale: un'interpretazione Bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_spaces.html#riflessioni-conclusive",
    "href": "chapters/probability/03_prob_spaces.html#riflessioni-conclusive",
    "title": "27  La Probabilità come misura della certezza razionale: un’interpretazione Bayesiana",
    "section": "27.5 Riflessioni Conclusive",
    "text": "27.5 Riflessioni Conclusive\nL’interpretazione della probabilità come grado di certezza soggettiva ci offre un modo intuitivo per ragionare su eventi incerti. La nostra certezza totale, pari a 1, viene distribuita tra i vari possibili esiti secondo una distribuzione di probabilità:\n\\[\n\\{p_1, p_2, \\dots, p_N\\} \\quad \\text{con} \\quad 0 \\leq p_n \\leq 1 \\quad \\text{e} \\quad \\sum_{n=1}^{N} p_n = 1.\n\\]\nOgni valore \\(p_n\\) rappresenta la frazione della nostra certezza che attribuiamo all’evento corrispondente a \\(x_n\\). Questo approccio è particolarmente utile nella statistica bayesiana, dove le probabilità vengono interpretate non come frequenze oggettive, ma come gradi di convinzione soggettivi basati sulle informazioni a nostra disposizione.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>La Probabilità come misura della certezza razionale: un'interpretazione Bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_spaces.html#esercizi",
    "href": "chapters/probability/03_prob_spaces.html#esercizi",
    "title": "27  La Probabilità come misura della certezza razionale: un’interpretazione Bayesiana",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nEsercizi\n\n\n\n\n\nDal testo di Blitzstein & Hwang (2019), svolgere i seguenti esercizi: 1.4.3, 1.4.4, 1.4.5, 1.4.6, 1.4.9, 1.4.12, 1.4.13.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>La Probabilità come misura della certezza razionale: un'interpretazione Bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_spaces.html#bibliografia",
    "href": "chapters/probability/03_prob_spaces.html#bibliografia",
    "title": "27  La Probabilità come misura della certezza razionale: un’interpretazione Bayesiana",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>La Probabilità come misura della certezza razionale: un'interpretazione Bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_sigma-algebra.html",
    "href": "chapters/probability/04_sigma-algebra.html",
    "title": "28  Dal Discreto al Continuo: la \\(\\sigma\\)-algebra",
    "section": "",
    "text": "28.1 Introduzione\nNel Capitolo 27 abbiamo visto come definire la probabilità su insiemi finiti, ossia in situazioni dove ci sono un numero limitato di esiti (ad esempio, i risultati di un lancio di dado). In quel contesto, la probabilità di ogni evento veniva spesso assegnata contando i casi favorevoli su quelli totali.\nTuttavia, in molti casi reali, lo spazio degli esiti non è finito, ma infinito (ad esempio, l’insieme degli interi, o addirittura la retta reale). In queste situazioni, la somma dei casi favorevoli su quelli totali non ha più senso o diventa tecnicamente inapplicabile. Per passare dal caso discreto a quello continuo, abbiamo quindi bisogno di strumenti più sofisticati.\nUno di questi strumenti è la \\(\\sigma\\)-algebra, che ci aiuta a definire in maniera rigorosa quali sottoinsiemi di uno spazio possiamo considerare “misurabili” e a cui possiamo assegnare una probabilità. In combinazione con gli assiomi di Kolmogorov, la \\(\\sigma\\)-algebra permette di estendere la teoria della probabilità dal caso discreto (discusso nel Capitolo 27) al caso continuo, dove la situazione è più delicata e non tutti i sottoinsiemi possono ricevere una probabilità.\nIn questo capitolo, dunque, approfondiremo:",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Dal Discreto al Continuo: la $\\sigma$-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_sigma-algebra.html#introduzione",
    "href": "chapters/probability/04_sigma-algebra.html#introduzione",
    "title": "28  Dal Discreto al Continuo: la \\(\\sigma\\)-algebra",
    "section": "",
    "text": "perché non possiamo sempre “misurare tutto” nello spazio continuo;\ncome la \\(\\sigma\\)-algebra ci fornisce un metodo per assegnare le probabilità negli spazi continui;\nin che modo la \\(\\sigma\\)-algebra sia cruciale per soddisfare gli assiomi di Kolmogorov;\nle differenze principali rispetto al caso discreto.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Dal Discreto al Continuo: la $\\sigma$-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_sigma-algebra.html#la-struttura-della-sigma-algebra",
    "href": "chapters/probability/04_sigma-algebra.html#la-struttura-della-sigma-algebra",
    "title": "28  Dal Discreto al Continuo: la \\(\\sigma\\)-algebra",
    "section": "\n28.2 La Struttura della \\(\\sigma\\)-Algebra",
    "text": "28.2 La Struttura della \\(\\sigma\\)-Algebra\nUna \\(\\sigma\\)-algebra \\(\\mathcal{F}\\) su uno spazio campionario \\(\\Omega\\) è una collezione di sottoinsiemi (eventi) che soddisfa le seguenti proprietà.\n\nInclusione dello spazio campionario:\\[\n  \\Omega \\in \\mathcal{F}.\n  \\]\nSignifica che l’evento “qualcosa accade” è sempre misurabile.\nChiusura rispetto al complemento:\\[\n\\text{Se } A \\in \\mathcal{F} \\text{ allora } A^c = \\Omega \\setminus A \\in \\mathcal{F}.\n\\]\nSe possiamo misurare la probabilità di un evento, dobbiamo anche poter misurare la probabilità che l’evento non accada.\nChiusura rispetto a unioni (anche numerabili):\\[\n\\text{Se } A_1, A_2, \\dots \\in \\mathcal{F}, \\text{ allora } \\bigcup_{i=1}^{\\infty} A_i \\in \\mathcal{F}.\n\\]\nSe possiamo misurare una collezione (anche infinita) di eventi, dobbiamo poter misurare anche l’evento “almeno uno di essi si verifica”.\n\nTali proprietà non sono un semplice dettaglio tecnico, ma garantiscono la coerenza del sistema probabilistico: ci assicurano che certe operazioni sugli eventi (complementi, unioni) non producano risultati “senza senso” per la probabilità.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Dal Discreto al Continuo: la $\\sigma$-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_sigma-algebra.html#relazione-tra-la-sigma-algebra-e-gli-assiomi-di-kolmogorov",
    "href": "chapters/probability/04_sigma-algebra.html#relazione-tra-la-sigma-algebra-e-gli-assiomi-di-kolmogorov",
    "title": "28  Dal Discreto al Continuo: la \\(\\sigma\\)-algebra",
    "section": "\n28.3 Relazione tra la \\(\\sigma\\)-algebra e gli Assiomi di Kolmogorov",
    "text": "28.3 Relazione tra la \\(\\sigma\\)-algebra e gli Assiomi di Kolmogorov\nL’introduzione della \\(\\sigma\\)-algebra è necessaria per garantire la coerenza del modello probabilistico. In sintesi:\n\nLa \\(\\sigma\\)-algebra delimita l’insieme degli eventi ammessi, ossia quegli insiemi per cui possiamo calcolare la probabilità.\nGli assiomi di Kolmogorov specificano le proprietà che la funzione di probabilità \\(P\\) deve rispettare su questi eventi.\nSenza la struttura di \\(\\sigma\\)-algebra, l’assioma di additività numerabile non sarebbe formulabile in modo rigoroso, poiché non avremmo garanzia che le operazioni di unione preservino l’appartenenza all’insieme degli eventi ammessi.\n\nIn conclusione, la costruzione formale della probabilità richiede non solo una funzione che assegni valori compresi tra 0 e 1 agli eventi, ma anche una struttura matematica che garantisca la coerenza di tali assegnazioni. La \\(\\sigma\\)-algebra assicura che ogni operazione insiemistica fondamentale per il calcolo della probabilità sia ben definita, permettendo agli assiomi di Kolmogorov di essere applicati senza ambiguità.\n\nEsempio 28.1 (Costruzione di una \\(\\sigma\\)-algebra discreta) Consideriamo lo spazio campionario discreto:\n\\[\n\\Omega = \\{1,2,3\\}.\n\\]\nDefinizione della \\(\\sigma\\)-algebra discreta. La \\(\\sigma\\)-algebra discreta corrisponde all’insieme di tutte le parti di \\(\\Omega\\), ovvero l’insieme di tutti i suoi sottoinsiemi:\n\\[\n\\mathcal{F} = \\bigl\\{\\varnothing, \\{1\\}, \\{2\\}, \\{3\\}, \\{1,2\\}, \\{1,3\\}, \\{2,3\\}, \\Omega \\bigr\\}.\n\\]\nVerifica delle proprietà della \\(\\sigma\\)-algebra. Per verificare che \\(\\mathcal{F}\\) sia effettivamente una \\(\\sigma\\)-algebra, controlliamo che soddisfi le seguenti proprietà:\n\n\nInclusione dell’insieme campionario e dell’insieme vuoto:\n\nPer definizione, \\(\\Omega \\in \\mathcal{F}\\) e \\(\\varnothing \\in \\mathcal{F}\\).\n\n\n\nChiusura rispetto ai complementi:\n\n\nSe un insieme \\(A\\) appartiene a \\(\\mathcal{F}\\), anche il suo complemento \\(A^c\\) rispetto a \\(\\Omega\\) deve appartenere a \\(\\mathcal{F}\\). Ad esempio:\n\nSe \\(\\{1,2\\} \\in \\mathcal{F}\\), allora \\(\\{1,2\\}^c = \\{3\\} \\in \\mathcal{F}\\).\nAnalogamente, per ogni altro sottoinsieme di \\(\\mathcal{F}\\) il complemento appartiene sempre a \\(\\mathcal{F}\\).\n\n\n\n\n\nChiusura rispetto alle unioni numerabili:\n\n\nNel caso discreto e finito, ogni unione di elementi in \\(\\mathcal{F}\\) appartiene ancora a \\(\\mathcal{F}\\). Ad esempio:\n\n\n\\(\\{1\\} \\cup \\{2\\} = \\{1,2\\} \\in \\mathcal{F}\\).\n\n\\(\\{1,3\\} \\cup \\{2\\} = \\{1,2,3\\} = \\Omega \\in \\mathcal{F}\\).\nPoiché \\(\\mathcal{F}\\) contiene tutti i possibili sottoinsiemi di \\(\\Omega\\), l’unione di qualsiasi collezione di elementi di \\(\\mathcal{F}\\) rimane in \\(\\mathcal{F}\\).\n\n\n\n\n\nInterpretazione intuitiva. Poiché ogni sottoinsieme di \\(\\Omega\\) appartiene a \\(\\mathcal{F}\\), tutti gli eventi possibili sono misurabili. Ad esempio:\n\nL’evento “esce 1 o 2” è rappresentato da \\(\\{1,2\\}\\).\nL’evento “non esce 3” è lo stesso evento \\(\\{1,2\\}\\), che è complementare a \\(\\{3\\}\\).\n\nEsempio di funzione di probabilità. Una possibile assegnazione di probabilità è quella di un dado equo a tre facce, dove ogni esito elementare ha la stessa probabilità:\n\\[\nP(\\{1\\}) = P(\\{2\\}) = P(\\{3\\}) = \\tfrac{1}{3}.\n\\]\nLe probabilità di eventi più complessi si ottengono sommando le probabilità degli esiti contenuti nell’evento:\n\\[\nP(\\{1,2\\}) = P(\\{1\\}) + P(\\{2\\}) = \\tfrac{1}{3} + \\tfrac{1}{3} = \\tfrac{2}{3}.\n\\]\nI valori fondamentali della funzione di probabilità rispettano gli assiomi di Kolmogorov:\n\\[\nP(\\Omega) = 1, \\quad P(\\varnothing) = 0.\n\\]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Dal Discreto al Continuo: la $\\sigma$-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_sigma-algebra.html#dal-discreto-al-continuo",
    "href": "chapters/probability/04_sigma-algebra.html#dal-discreto-al-continuo",
    "title": "28  Dal Discreto al Continuo: la \\(\\sigma\\)-algebra",
    "section": "\n28.4 Dal Discreto al Continuo",
    "text": "28.4 Dal Discreto al Continuo\nDopo aver introdotto il concetto di \\(\\sigma\\)-algebra e il suo ruolo negli assiomi di Kolmogorov, analizziamo le differenze essenziali tra il caso discreto e quello continuo.\n\n28.4.1 Caso Discreto\nQuando lo spazio campionario \\(\\Omega\\) è finito o numerabile (ad esempio, \\(\\{1, 2, 3, \\dots\\}\\)), la \\(\\sigma\\)-algebra può coincidere con l’insieme di tutte le parti di \\(\\Omega\\). In questo contesto:\n\nOgni sottoinsieme di \\(\\Omega\\) è misurabile.\nGli eventi possono essere definiti in modo esplicito senza ambiguità.\nGli assiomi di Kolmogorov si applicano direttamente.\nLa probabilità di ogni singolo punto può essere positiva.\n\n28.4.2 Caso Continuo\nQuando lo spazio campionario è un insieme non numerabile come \\(\\Omega = [0,1]\\) o \\(\\mathbb{R}\\), la costruzione della \\(\\sigma\\)-algebra diventa più complessa. Non è possibile includere tutti i sottoinsiemi di \\(\\Omega\\) senza generare contraddizioni logiche. Un esempio classico è il paradosso di Vitali, che mostra come alcuni insiemi non possano essere misurati in modo coerente.\n\n28.4.3 La \\(\\sigma\\)-algebra di Borel\nPer evitare tali problemi, nel caso continuo si utilizza la \\(\\sigma\\)-algebra di Borel, che include solo i sottoinsiemi “ben misurabili” di \\(\\Omega\\), escludendo quelli che potrebbero portare a incoerenze matematiche. Ad esempio:\n\nIntervalli del tipo \\([a,b]\\), \\((-\\infty, 0]\\).\nUnioni numerabili di intervalli.\nComplementi di insiemi misurabili.\n\nInvece, insiemi come quello di Vitali non sono inclusi nella \\(\\sigma\\)-algebra di Borel perché non ammettono una misura coerente.\nConfronto tra il caso discreto e il caso continuo.\n\n\n\n\n\n\n\nCaratteristica\nCaso Discreto\nCaso Continuo\n\n\n\nStruttura di \\(\\Omega\\)\nFinito o numerabile (\\(\\{1,2,3,\\dots\\}\\))\nNon numerabile (\\(\\mathbb{R}\\), \\([0,1]\\), ecc.)\n\n\n\\(\\sigma\\)-algebra naturale\nInsieme di tutte le parti di \\(\\Omega\\)\n\n\n\\(\\sigma\\)-algebra di Borel\n\n\nEsempio di evento\n\n\\(\\{\\omega\\}\\), \\(\\{\\omega_1, \\omega_2\\}\\)\n\n\n\\([a,b]\\), \\((-\\infty, 0]\\), unione di intervalli\n\n\nProbabilità di un singolo punto\nPuò essere \\(&gt;0\\) (ad es. \\(P(\\{\\omega\\})=1/6\\))\nGeneralmente \\(0\\) se il fenomeno è continuo\n\n\nProblemi di misurabilità\nNon presenti\nNecessaria selezione di insiemi misurabili\n\n\n\nIn sintesi, nel caso discreto, la costruzione della \\(\\sigma\\)-algebra è immediata: includere tutti i sottoinsiemi non crea difficoltà, portando alla cosiddetta \\(\\sigma\\)-algebra discreta (o triviale se \\(\\Omega\\) ha un solo elemento).\nNel caso continuo, invece, la costruzione è più delicata. Non tutti i sottoinsiemi possono essere inclusi nella \\(\\sigma\\)-algebra senza compromettere la coerenza matematica. Per questo motivo, si utilizza la \\(\\sigma\\)-algebra di Borel, che permette di definire correttamente la misura di probabilità evitando paradossi.\n\n\n\n\n\n\nCostruzione della \\(\\sigma\\)-algebra di Borel\n\n\n\n\n\nPer costruire la \\(\\sigma\\)-algebra di Borel in \\([0,1]\\) o in \\(\\mathbb{R}\\), si parte dagli intervalli e si aggiungono tutte le unioni e intersezioni numerabili di questi intervalli. Questa procedura genera la più piccola collezione di sottoinsiemi che soddisfa le proprietà di una \\(\\sigma\\)-algebra.\n\n\nInclusi: Intervalli aperti, chiusi, segmenti, unioni di segmenti, ecc.\n\nEsclusi: Strutture “patologiche” come l’insieme di Vitali, che non possono essere misurate in modo coerente.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Dal Discreto al Continuo: la $\\sigma$-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_sigma-algebra.html#riflessioni-conclusive",
    "href": "chapters/probability/04_sigma-algebra.html#riflessioni-conclusive",
    "title": "28  Dal Discreto al Continuo: la \\(\\sigma\\)-algebra",
    "section": "\n28.5 Riflessioni Conclusive",
    "text": "28.5 Riflessioni Conclusive\nIn questo capitolo, abbiamo esplorato come la probabilità possa essere estesa dal caso discreto, dove possiamo tranquillamente lavorare con insiemi finiti, al caso continuo, dove ci si confronta con spazi infinitamente densi. Abbiamo compreso che, in questa transizione, la \\(\\sigma\\)-algebra gioca un ruolo cruciale, definendo quali sottoinsiemi sono “misurabili”, ovvero a quali possiamo assegnare una probabilità senza incappare in contraddizioni logiche o matematiche.\nAttraverso la formalizzazione delle \\(\\sigma\\)-algebre e l’applicazione degli assiomi di Kolmogorov, abbiamo stabilito le basi per un sistema probabilistico coerente e completo. Nel caso discreto, la costruzione della \\(\\sigma\\)-algebra è diretta, potendo includere tutti i sottoinsiemi di uno spazio campionario finito o numerabile. Tuttavia, nel caso continuo, abbiamo appreso che non tutti i sottoinsiemi possono essere misurati con coerenza. La \\(\\sigma\\)-algebra di Borel emerge come uno strumento essenziale per navigare questo terreno più complesso.\nLa distinzione tra il caso discreto e il continuo ci dimostra come la matematica possa affrontare con eleganza problemi di diversa natura. Nel discreto, ogni evento può avere una probabilità positiva e ogni sottoinsieme è misurabile. Nel continuo, invece, dobbiamo procedere con cautela, selezionando gli insiemi che possiamo “misurare” in modo coerente. In conclusione, la \\(\\sigma\\)-algebra non è soltanto un artificio tecnico, ma un elemento fondamentale che permette di costruire un ponte tra il discreto e il continuo, garantendo la coerenza della teoria della probabilità.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Dal Discreto al Continuo: la $\\sigma$-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_sigma-algebra.html#esercizi",
    "href": "chapters/probability/04_sigma-algebra.html#esercizi",
    "title": "28  Dal Discreto al Continuo: la \\(\\sigma\\)-algebra",
    "section": "\n28.6 Esercizi",
    "text": "28.6 Esercizi\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nConsidera i seguenti esercizi basati sulla Satisfaction with Life Scale (SWLS).\n\n\nQuali sottoinsiemi sono eventi ammissibili?\nSupponiamo che i punteggi SWLS raccolti siano numeri interi tra 5 e 35.\n\nTra i seguenti insiemi, quali potrebbero essere inclusi in una \\(\\sigma\\)-algebra su questo spazio campionario?\n\n\nA: Tutti gli studenti con punteggio pari o superiore a 25.\n\n\nB: Studenti con punteggio pari.\n\n\nC: Studenti con punteggio multiplo di 3.\n\n\nD: Studenti con punteggio superiore all’altezza media degli unicorni.\n\n\n\nQuale criterio potremmo usare per decidere se un insieme è ammissibile in una \\(\\sigma\\)-algebra?\n\n\n\nChiusura rispetto al complemento\nSe l’evento A rappresenta gli studenti con punteggio SWLS ≥ 25, quale sarà l’evento complementare Aᶜ?\n\nEsprimilo in termini di punteggi.\n\nSe il 40% degli studenti ha punteggi ≥ 25, qual è la probabilità empirica dell’evento Aᶜ?\n\n\n\nEsercizi sulle Operazioni tra Eventi 3. Unione di Eventi\nConsideriamo i seguenti eventi:\n\n\nB: “Studente ha un punteggio SWLS pari”.\n\n\nC: “Studente ha un punteggio multiplo di 3”.\n\nElenca i punteggi che appartengono a B ∪ C (cioè lo studente ha un punteggio pari o multiplo di 3).\n\nSe nel campione di 15 studenti, 8 hanno un punteggio in B e 5 in C, e 3 di essi appartengono a entrambi gli insiemi, calcola la probabilità empirica di B ∪ C usando la formula dell’unione.\n\n\n\nIntersezione e additività numerabile\n\nSe un evento D rappresenta gli studenti con punteggio ≥20 e ≤30, possiamo dire che è incluso nella \\(\\sigma\\)-algebra se B e C lo sono? Perché?\nCalcola l’intersezione B ∩ C e verifica se i dati raccolti rispettano l’additività.\n\n\n\nEsercizi sugli Assiomi di Kolmogorov 5. Assioma della Normalizzazione\n\nSupponiamo di assegnare probabilità a eventi definiti sui punteggi SWLS dei 15 studenti.\n\nSe la somma delle probabilità di tutti gli eventi possibili non è 1, cosa significa?\n\nDai un esempio di una distribuzione di probabilità su SWLS che rispetti la normalizzazione.\n\n\n\nAssioma dell’Additività\n\nSupponiamo che P(A) = 0.4 e P(Aᶜ) = 0.6.\n\nVerifica se questa distribuzione soddisfa l’assioma di Kolmogorov.\n\nSe introduciamo un terzo evento E (punteggi tra 15 e 20), come possiamo calcolare P(A ∪ E) rispettando gli assiomi?\n\n\n\nEsercizi su Spazi Misurabili e Applicazioni\n\n\nDefinire uno Spazio Misurabile\n\n\nConsideriamo lo spazio campionario \\(\\Omega\\) dei punteggi SWLS e la \\(\\sigma\\)-algebra \\(\\mathcal{F}\\) formata dai sottoinsiemi:\n\n{Punteggi pari}\n\n{Punteggi multipli di 5}\n\n{Punteggi ≥ 25}\n\n\n\nQuesta collezione rispetta le condizioni di una \\(\\sigma\\)-algebra? Perché?\n\n\n\nEsempio di Probabilità in un Caso Continuo\n\nSe invece di punteggi discreti avessimo misurato il tempo di risposta a un questionario SWLS (espresso in secondi con valori reali), il modello discreto funzionerebbe?\n\nProva a descrivere un possibile evento misurabile in un caso continuo e spiega perché sarebbe più complesso da gestire rispetto al caso discreto.\n\n\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n1. Quali sottoinsiemi sono eventi ammissibili?\n\nGli insiemi che possono essere inclusi in una \\(\\sigma\\)-algebra devono essere chiusi rispetto a unioni, intersezioni e complementi.\n\nA (punteggi ≥ 25), B (punteggi pari), e C (punteggi multipli di 3) possono essere inclusi in una \\(\\sigma\\)-algebra, perché sono definiti su criteri chiari e permettono operazioni insiemistiche.\n\nD (punteggi superiori alla media degli unicorni) non è un evento misurabile, poiché dipende da valori soggettivi e non da una regola fissa applicabile all’intero spazio campionario.\n\n2. Chiusura rispetto al complemento\n\nL’evento complementare di A (punteggi ≥ 25) è Aᶜ (punteggi &lt; 25).\nSe la probabilità empirica di A è 0.4, la probabilità empirica di Aᶜ è: \\[ P(Aᶜ) = 1 - P(A) = 1 - 0.4 = 0.6 \\]\n\n\nSoluzioni agli Esercizi sulle Operazioni tra Eventi\n3. Unione di Eventi\n\nI punteggi in B sono {6, 8, 10, 12, …, 34} e quelli in C sono {6, 9, 12, …, 33}.\n\nB ∪ C è l’insieme {6, 8, 9, 10, 12, …, 34}.\nApplicando la formula dell’unione: \\[ P(B ∪ C) = P(B) + P(C) - P(B ∩ C) \\] \\[ P(B ∪ C) = \\frac{8}{15} + \\frac{5}{15} - \\frac{3}{15} = \\frac{10}{15} = 0.667 \\]\n\n\n4. Intersezione e additività numerabile\n\nL’evento D (20 ≤ SWLS ≤ 30) è un sottoinsieme di B ∪ C, quindi se B e C sono inclusi in una \\(\\sigma\\)-algebra, anche D lo sarà.\n\nB ∩ C (punteggi pari e multipli di 3) = {6, 12, 18, …}.\nDalla distribuzione empirica, P(B ∩ C) = \\(\\frac{3}{15} = 0.2\\).\n\nSoluzioni agli Esercizi sugli Assiomi di Kolmogorov\n5. Assioma della Normalizzazione\n\nSe la somma delle probabilità degli eventi possibili non è 1, significa che il sistema di probabilità è mal definito.\nEsempio corretto di distribuzione: \\[ P(A) = 0.4, P(B) = 0.3, P(Aᶜ) = 0.6, P(Bᶜ) = 0.7 \\] Tutti gli eventi coprono l’intero spazio campionario senza sovrapposizioni non gestite.\n\n6. Assioma dell’Additività\n\nSe P(A) = 0.4 e P(Aᶜ) = 0.6, allora: \\[ P(A) + P(Aᶜ) = 1 \\] Quindi gli assiomi di Kolmogorov sono rispettati.\nSe introduciamo un evento E (SWLS tra 15 e 20) con P(E) = 0.2, possiamo usare la formula dell’unione per calcolare P(A ∪ E) se A ed E non sono disgiunti.\n\nSoluzioni agli Esercizi su Spazi Misurabili e Applicazioni\n7. Definire uno Spazio Misurabile\n\nL’insieme \\(\\mathcal{F}\\) con {Punteggi pari, Punteggi multipli di 5, Punteggi ≥ 25} rispetta:\n\nInclusione di \\(\\Omega\\).\nChiusura rispetto al complemento.\nChiusura rispetto all’unione.\n\n\nQuindi è una \\(\\sigma\\)-algebra valida.\n\n8. Probabilità nel Caso Continuo\n\nSe misurassimo tempo di risposta al questionario SWLS in secondi (con valori reali), avremmo bisogno di una densità di probabilità anziché probabilità discrete.\nUn evento misurabile potrebbe essere: “Tempo di risposta compreso tra 10 e 15 secondi”.\nLa probabilità di un singolo valore (es. esattamente 12 secondi) sarebbe zero nel caso continuo.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Dal Discreto al Continuo: la $\\sigma$-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_sigma-algebra.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/04_sigma-algebra.html#informazioni-sullambiente-di-sviluppo",
    "title": "28  Dal Discreto al Continuo: la \\(\\sigma\\)-algebra",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] grid      stats     graphics  grDevices utils     datasets  methods  \n#&gt; [8] base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] VennDiagram_1.7.3   futile.logger_1.4.3 reshape2_1.4.4     \n#&gt;  [4] thematic_0.1.7      MetBrewer_0.2.0     ggokabeito_0.1.0   \n#&gt;  [7] see_0.11.0          gridExtra_2.3       patchwork_1.3.0    \n#&gt; [10] bayesplot_1.13.0    psych_2.5.3         scales_1.4.0       \n#&gt; [13] markdown_2.0        knitr_1.50          lubridate_1.9.4    \n#&gt; [16] forcats_1.0.0       stringr_1.5.1       dplyr_1.1.4        \n#&gt; [19] purrr_1.0.4         readr_2.1.5         tidyr_1.3.1        \n#&gt; [22] tibble_3.3.0        ggplot2_3.5.2       tidyverse_2.0.0    \n#&gt; [25] rio_1.2.3           here_1.0.1         \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.4       futile.options_1.0.1 stringi_1.8.7       \n#&gt;  [4] lattice_0.22-7       hms_1.1.3            digest_0.6.37       \n#&gt;  [7] magrittr_2.0.3       evaluate_1.0.4       timechange_0.3.0    \n#&gt; [10] RColorBrewer_1.1-3   fastmap_1.2.0        plyr_1.8.9          \n#&gt; [13] rprojroot_2.0.4      jsonlite_2.0.0       formatR_1.14        \n#&gt; [16] mnormt_2.1.1         cli_3.6.5            rlang_1.1.6         \n#&gt; [19] withr_3.0.2          tools_4.5.0          parallel_4.5.0      \n#&gt; [22] tzdb_0.5.0           pacman_0.5.1         lambda.r_1.2.4      \n#&gt; [25] vctrs_0.6.5          R6_2.6.1             lifecycle_1.0.4     \n#&gt; [28] htmlwidgets_1.6.4    pkgconfig_2.0.3      pillar_1.10.2       \n#&gt; [31] gtable_0.3.6         Rcpp_1.0.14          glue_1.8.0          \n#&gt; [34] xfun_0.52            tidyselect_1.2.1     rstudioapi_0.17.1   \n#&gt; [37] farver_2.1.2         htmltools_0.5.8.1    nlme_3.1-168        \n#&gt; [40] rmarkdown_2.29       compiler_4.5.0",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Dal Discreto al Continuo: la $\\sigma$-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_sigma-algebra.html#bibliografia",
    "href": "chapters/probability/04_sigma-algebra.html#bibliografia",
    "title": "28  Dal Discreto al Continuo: la \\(\\sigma\\)-algebra",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.\n\n\nChan, J. C. C., & Kroese, D. P. (2025). Statistical Modeling and Computation (2ª ed.). Springer.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Dal Discreto al Continuo: la $\\sigma$-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_conditional_prob.html",
    "href": "chapters/probability/05_conditional_prob.html",
    "title": "29  Probabilità condizionata",
    "section": "",
    "text": "29.1 Introduzione\nLa probabilità condizionata esprime la probabilità di un evento tenendo conto del verificarsi di un altro evento. Questo concetto è fondamentale perché riflette il modo in cui aggiorniamo le nostre credenze alla luce di nuove informazioni. Ad esempio, la probabilità che piova domani può essere diversa a seconda delle condizioni atmosferiche di oggi: osservare un cielo nuvoloso modifica la nostra valutazione della probabilità di pioggia. In questo senso, ogni nuova informazione può confermare, rafforzare o mettere in discussione le credenze preesistenti.\nLa probabilità condizionata ha un ruolo centrale non solo nella teoria della probabilità, ma anche nelle applicazioni quotidiane e scientifiche. In molti contesti, le probabilità sono implicitamente condizionate da informazioni preesistenti, anche quando non lo esplicitiamo formalmente. Comprendere e quantificare questo processo di aggiornamento delle credenze ci consente di gestire in modo più efficace l’incertezza, rendendo la probabilità uno strumento dinamico per la decisione e l’inferenza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_conditional_prob.html#indipendenza-stocastica",
    "href": "chapters/probability/05_conditional_prob.html#indipendenza-stocastica",
    "title": "29  Probabilità condizionata",
    "section": "\n29.2 Indipendenza Stocastica",
    "text": "29.2 Indipendenza Stocastica\nUn caso particolare di aggiornamento delle probabilità si verifica quando due eventi non si influenzano a vicenda. In tal caso, la probabilità congiunta di più eventi si calcola in modo molto più semplice, grazie alla proprietà di indipendenza.\n\n29.2.1 Indipendenza di Due Eventi\n\nDefinizione 29.1 Due eventi \\(A\\) e \\(B\\) si dicono indipendenti se la probabilità che si verifichino entrambi è uguale al prodotto delle probabilità dei singoli eventi:\n\\[\nP(A \\cap B) \\;=\\; P(A)\\, P(B).\n\\tag{29.1}\\]\n\nIn altre parole, sapere che \\(A\\) si è verificato non influisce sul valore di \\(P(B)\\), e viceversa. Quando questa condizione è soddisfatta, si scrive \\(A \\perp B\\) per indicare l’indipendenza dei due eventi.\n\nEsempio 29.1 Supponiamo di lanciare due monete distinte e di considerare i seguenti eventi:\n\n\n\\(A\\) = “La prima moneta mostra Testa”\n\n\n\\(B\\) = “La seconda moneta mostra Testa”\n\nPoiché il risultato della prima moneta non influisce in alcun modo su quello della seconda, i due eventi sono indipendenti. In particolare, la probabilità di ottenere “Testa” su una moneta è:\n\\[\nP(A) \\;=\\; P(B) \\;=\\; \\frac{1}{2}.\n\\]\nLa probabilità che entrambe le monete mostrino Testa (cioè che si verifichino contemporaneamente gli eventi \\(A\\) e \\(B\\)) è data dal prodotto delle loro probabilità:\n\\[\nP(A \\cap B) \\;=\\; P(A)\\,P(B)\n\\;=\\; \\frac{1}{2} \\times \\frac{1}{2}\n\\;=\\; \\frac{1}{4}.\n\\]\nPoiché questa relazione è soddisfatta, possiamo concludere che \\(A\\) e \\(B\\) sono eventi indipendenti.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_conditional_prob.html#indipendenza-di-un-insieme-di-eventi",
    "href": "chapters/probability/05_conditional_prob.html#indipendenza-di-un-insieme-di-eventi",
    "title": "29  Probabilità condizionata",
    "section": "\n29.3 Indipendenza di un Insieme di Eventi",
    "text": "29.3 Indipendenza di un Insieme di Eventi\nIl concetto di indipendenza non si limita a due soli eventi, ma può estendersi a un insieme arbitrario di eventi. In generale, diciamo che \\(\\{A_i : i \\in I\\}\\) è un insieme di eventi indipendente se, per ogni sottoinsieme finito \\(J \\subseteq I\\), la probabilità dell’intersezione degli eventi in \\(J\\) coincide con il prodotto delle probabilità di ciascun evento:\n\\[\nP \\Bigl(\\bigcap_{i \\in J} A_i\\Bigr)\n\\;=\\;\n\\prod_{i \\in J} P(A_i).\n\\tag{29.2}\\]\nQuesta condizione richiede che ogni combinazione di eventi presenti la stessa proprietà di non influenzarsi a vicenda. L’indipendenza può essere:\n\nun’assunzione semplificante in molti modelli (ad esempio, ipotizzare che le variabili di un questionario misurino proprietà “indipendenti” dei partecipanti);\n\nuna caratteristica empirica emersa dai dati, da verificare attraverso analisi apposite.\n\n\nEsempio 29.2 Consideriamo una sequenza di tre lanci di una moneta equilibrata e definiamo gli eventi:\n\n\n\\(A_1\\) = “Il primo lancio mostra Testa”.\n\n\\(A_2\\) = “Il secondo lancio mostra Testa”.\n\n\\(A_3\\) = “Il terzo lancio mostra Testa”.\n\nCiascuno di questi eventi ha probabilità \\(1/2\\). Poiché ogni lancio non influenza gli altri, l’insieme \\(\\{A_1, A_2, A_3\\}\\) è indipendente nel senso più ampio: non solo \\(P(A_1 \\cap A_2) = P(A_1)P(A_2)\\) e simili per coppie, ma vale anche\n\\[\nP(A_1 \\cap A_2 \\cap A_3)\n\\;=\\;\nP(A_1)\\,P(A_2)\\,P(A_3)\n\\;=\\;\n\\left(\\tfrac12\\right)\\left(\\tfrac12\\right)\\left(\\tfrac12\\right)\n\\;=\\;\n\\tfrac18.\n\\]\nIn effetti, per qualunque combinazione di Testa e Croce (ad esempio, “Testa al primo e terzo lancio, Croce al secondo”), la probabilità risulta sempre il prodotto delle probabilità dei singoli esiti, confermando l’indipendenza.\n\n\n29.3.1 Quando gli Eventi Non Sono Indipendenti\nSe per due eventi \\(A\\) e \\(B\\) si ha \\(P(A \\cap B) \\neq P(A) P(B)\\), essi non sono indipendenti. In tal caso, conoscere l’esito di uno fornisce informazioni sul probabile verificarsi dell’altro, e occorre tenere conto di questa dipendenza nei calcoli (ad esempio, usando la probabilità condizionata).\n\n29.3.2 Differenza tra Indipendenza ed Eventi Disgiunti\nUn errore frequente è confondere “indipendenti” con “disgiunti (o mutuamente esclusivi)”. Due eventi sono disgiunti se non possono avvenire contemporaneamente, cioè\n\\[\nP(A \\cap B) \\;=\\; 0.\n\\]\nSe \\(P(A)&gt;0\\) e \\(P(B)&gt;0\\) e gli eventi sono disgiunti, non possono essere indipendenti. Infatti, l’indipendenza richiederebbe\n\\[\nP(A \\cap B) \\;=\\; P(A)\\,P(B),\n\\]\nma, poiché \\(P(A \\cap B)=0\\) e \\(P(A) P(B)\\) sarebbe positivo, la relazione non può valere. Quindi, la disgiunzione implica l’esclusione reciproca, mentre l’indipendenza significa che la probabilità di uno non risente in alcun modo dell’altro.\n\nEsempio 29.3 Nel lancio di un dado a sei facce:\n\n\n\\(C\\) = “Esce un numero pari” \\(\\{\\;2,4,6\\}\\).\n\n\\(D\\) = “Esce un numero dispari” \\(\\{\\;1,3,5\\}\\).\n\nI due eventi sono disgiunti, poiché un numero non può essere contemporaneamente pari e dispari; dunque \\(P(C \\cap D)=0\\).\nTuttavia, non sono indipendenti: se lo fossero, si dovrebbe avere \\(P(C \\cap D) = P(C)P(D)\\). Invece,\n\\[\n0 \\;\\neq\\; \\tfrac12 \\,\\times\\, \\tfrac12 \\;=\\; \\tfrac14,\n\\]\nda cui segue che \\(C\\) e \\(D\\) non sono eventi indipendenti.\n\nIn sintesi, gli eventi disgiunti non possono verificarsi insieme, mentre gli eventi indipendenti non influiscono uno sulla probabilità dell’altro. Entrambe le proprietà sono importanti ma rispondono a concetti nettamente diversi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_conditional_prob.html#probabilità-condizionata",
    "href": "chapters/probability/05_conditional_prob.html#probabilità-condizionata",
    "title": "29  Probabilità condizionata",
    "section": "\n29.4 Probabilità Condizionata",
    "text": "29.4 Probabilità Condizionata\nLa probabilità condizionata esprime la probabilità di un evento \\(A\\) una volta che si sappia che un altro evento \\(B\\) è già avvenuto.\n\nDefinizione 29.2 Se \\(P(B) &gt; 0\\), si definisce:\n\\[\nP(A \\mid B)\n\\;=\\;\n\\frac{P(A \\cap B)}{P(B)}.\n\\tag{29.3}\\]\n\nQuesta formula può essere letta come un “ricalcolo” della probabilità di \\(A\\) limitandosi al sottoinsieme di esiti in cui \\(B\\) è vero.\n\n29.4.1 Interpretazione della Probabilità Condizionata\nLa probabilità condizionata funge da meccanismo di aggiornamento delle nostre conoscenze. Inizialmente, si dispone di una stima di \\(P(A)\\); dopo aver appreso che un evento correlato \\(B\\) si è verificato, si “restringe” il campo agli esiti compatibili con \\(B\\) e si riassegna la probabilità di \\(A\\) su questa base.\n\n\nEsempio intuitivo: Se si sa che una persona ha la febbre (\\(B\\)), la probabilità che abbia l’influenza (\\(A\\)) aumenta rispetto a quella calcolata sull’intera popolazione.\n\nQuesta capacità di “aggiornare le credenze” fa della probabilità condizionata uno strumento fondamentale in:\n\n\ninferenze statistiche, per gestire informazioni parziali o acquisite progressivamente;\n\n\nteoria dell’apprendimento, quando si valutano ipotesi o modelli a fronte di nuovi dati;\n\n\nmodellizzazione delle dipendenze tra eventi, in cui la conoscenza di un evento influenza la probabilità di un altro.\n\n\nEsempio 29.4 Lanciamo due dadi equilibrati consecutivamente.\nDato che la somma dei dadi è 10, qual è la probabilità che uno dei due dadi mostri un 6?\nDefiniamo:\n\n\nB come l’evento che la somma sia 10:\\[ B = \\{(4, 6), (5, 5), (6, 4)\\}. \\]\n\n\nA come l’evento che uno dei due dadi mostri un 6:\\[ A = \\{(1, 6), \\dots, (5, 6), (6, 1), \\dots, (6, 5)\\}. \\]\n\n\nL’intersezione tra A e B è:\\[ A \\cap B = \\{(4, 6), (6, 4)\\}. \\]\nPoiché in questo esperimento tutti gli eventi elementari sono equiprobabili, la probabilità condizionata \\(P(A | B)\\) è data da:\\[\nP(A | B) = \\frac{P(A \\cap B)}{P(B)} = \\frac{\\frac{2}{36}}{\\frac{3}{36}} = \\frac{2}{3}.\n\\]\nQuindi, la probabilità che uno dei due dadi mostri un 6, sapendo che la somma è 10, è \\(\\frac{2}{3}\\).\n\n\nEsempio 29.5 Somma di due dadi\nConsideriamo il lancio di due dadi equilibrati e calcoliamo la probabilità che la somma dei punteggi risulti minore di 8.\n\n\nSenza informazioni aggiuntive\n\nOgni dado può assumere valori da 1 a 6, per un totale di 36 possibili combinazioni \\((6 \\times 6)\\).\n\nTra queste 36, esistono 21 combinazioni in cui la somma è minore di 8.\n\nDunque la probabilità iniziale è: \\[\nP(\\text{Somma} &lt; 8)\n\\;=\\;\n\\frac{21}{36}\n\\;\\approx\\; 0{.}58.\n\\]\n\n\n\n\nCon informazione aggiuntiva\nSupponiamo di sapere che la somma uscita è dispari. Questa nuova informazione restringe lo spazio degli esiti possibili:\n\nSolo 18 combinazioni su 36 producono un risultato dispari.\n\nTra queste 18, 12 combinazioni hanno somma minore di 8.\n\nPertanto, la probabilità condizionata diventa: \\[\nP(\\text{Somma} &lt; 8 \\,\\mid\\, \\text{Somma dispari})\n\\;=\\;\n\\frac{12}{18}\n\\;=\\;\n0{.}67.\n\\]\n\n\n\n\nConfrontando i due risultati (\\(0{,}58\\) senza informazioni contro \\(0{,}67\\) con l’informazione “somma dispari”), osserviamo come la probabilità di un evento possa cambiare una volta ottenuta un’informazione aggiuntiva.\nCodice in R.\nNel codice R che segue, utilizziamo l’insieme di tutte le combinazioni di lanci per verificare numericamente i risultati:\n\n# 1. Definiamo i possibili valori di un dado\nr &lt;- 1:6  \n\n# 2. Costruiamo tutte le combinazioni possibili (i, j)\n#    in cui i e j vanno da 1 a 6.\n#    In totale ci aspettiamo 36 combinazioni (6 x 6).\nsample &lt;- expand.grid(i = r, j = r)  \nnrow(sample)  # Contiamo quante sono: dovrebbero essere 36\n#&gt; [1] 36\n\n# 3. Selezioniamo solo le coppie (i, j) in cui la somma è minore di 8.\n#    Verifichiamo quante sono e le confrontiamo con il totale.\nevent &lt;- subset(sample, i + j &lt; 8)\ncat(nrow(event), \"/\", nrow(sample), \"\\n\")  # Dovrebbe stampare 21 / 36\n#&gt; 21 / 36\n\n# 4. Selezioniamo ora solo le coppie con somma dispari.\n#    %% è l’operatore \"modulo\": (i + j) %% 2 != 0 verifica se la somma è dispari.\nsample_odd &lt;- subset(sample, (i + j) %% 2 != 0)\nnrow(sample_odd)  # Dovrebbe essere 18\n#&gt; [1] 18\n\n# 5. Calcoliamo quante coppie hanno somma minore di 8 tra quelle con somma dispari.\nevent_odd &lt;- subset(sample_odd, i + j &lt; 8)\ncat(nrow(event_odd), \"/\", nrow(sample_odd), \"\\n\")  # Dovrebbe stampare 12 / 18\n#&gt; 12 / 18\n\nSecondo la Equazione 29.3, se definiamo\n\n\n\\(A\\) = “Somma &lt; 8”\n\n\n\\(B\\) = “Somma dispari”,\n\nallora \\(P(A \\cap B) = 12/36\\) e \\(P(B) = 18/36\\). Di conseguenza,\n\\[\nP(A \\mid B)\n\\;=\\;\n\\frac{P(A \\cap B)}{P(B)}\n\\;=\\;\n\\frac{12/36}{18/36}\n\\;=\\;\n\\frac{12}{18}\n\\;=\\;\n0{.}67.\n\\]\nQuesto esempio dimostra come la probabilità condizionata consenta di aggiornare la stima di un evento alla luce di nuove informazioni.\n\n\n\n\n\n\n\nScreening per la diagnosi precoce del tumore mammario\n\n\n\n\n\nSupponiamo di utilizzare un test diagnostico con le seguenti caratteristiche:\n\n\nSensibilità (probabilità di test positivo fra le donne malate): 90%.\n\n\nSpecificità (probabilità di test negativo fra le donne sane): 90%.\n\n\nPrevalenza (percentuale di donne effettivamente malate nella popolazione): 1%.\n\n1. Esempio con 1000 donne.\nPer semplificare i calcoli, immaginiamo di sottoporre a screening 1000 donne a caso:\n\n\nDonne malate (1%): 10 su 1000.\n\nCon una sensibilità del 90%, circa 9 di queste 10 donne avranno un esito positivo al test (vere positive).\n\nCirca 1 donna avrà invece un risultato negativo (falso negativo).\n\n\n\nDonne sane (99%): 990 su 1000.\n\nCon una specificità del 90%, circa 891 di queste 990 risulteranno negative al test (vere negative).\n\nLe restanti 99 donne avranno un esito positivo (false positive).\n\n\n\nQuesto ci permette di costruire uno schema riassuntivo (spesso rappresentato sotto forma di tabella o diagramma a blocchi):\n\n\npositive: \\(9\\) (vere positive) + \\(99\\) (false positive) = 108,\n\n\nnegative: \\(1\\) (falso negativo) + \\(891\\) (vero negativo) = 892.\n\n2. Probabilità non condizionata di un test positivo.\nLa probabilità che una donna, scelta a caso, risulti positiva allo screening (indipendentemente dal fatto che sia malata o sana) si ottiene rapportando il numero di test positivi al totale:\n\\[\nP(\\text{Test positivo})\n\\;=\\;\n\\frac{108}{1000}\n\\;=\\;\n0{.}108\n\\;\\; (10{.}8\\%).\n\\]\nQuesta è una probabilità non condizionata, in quanto considera l’intera popolazione delle 1000 donne, senza ulteriori informazioni.\n3. Probabilità condizionata di essere malate dato un test positivo.\nCi interessa ora sapere: Se una donna ha appena ricevuto un risultato positivo, qual è la probabilità che abbia davvero il cancro al seno?\nMatematicamente, riformuliamo la domanda come:\\[\nP(\\text{Cancro} \\mid \\text{Test positivo}).\n\\]\nOsservando il nostro esempio di 1000 donne:\n\nAbbiamo 108 test positivi in tutto.\n\nSolo 9 di questi test positivi provengono effettivamente da donne malate.\n\nPertanto,\n\\[\nP(\\text{Cancro} \\mid \\text{Test positivo})\n\\;=\\;\n\\frac{9}{108}\n\\;=\\;\n0{.}083\n\\;\\; (8{.}3\\%).\n\\]\nQuesta è una probabilità condizionata, poiché riguarda soltanto quelle donne già selezionate in base all’esito positivo del test.\n4. Confronto fra probabilità non condizionata e condizionata.\n\n\nProbabilità non condizionata (esito positivo): \\(0{.}108\\) (10.8%).\n\n\nProbabilità condizionata (avere un tumore, sapendo che il test è positivo): \\(0{.}083\\) (8.3%).\n\nNotiamo come l’informazione aggiuntiva (“il test è risultato positivo”) riduca il numero di casi osservati, focalizzando l’attenzione su un sottoinsieme della popolazione. In altre parole, la conoscenza di un test positivo aggiorna la nostra stima della probabilità di avere la malattia, mostrandoci che, nonostante l’alta sensibilità e specificità, la maggior parte dei test positivi riguarda donne sane (false positive), a causa della bassa prevalenza (1%).\nQuesto esempio illustra in modo tangibile la distinzione fra:\n\n\nprobabilità non condizionata: la probabilità di un evento considerando l’intera popolazione,\n\n\nprobabilità condizionata: la probabilità di un evento una volta appresa un’informazione aggiuntiva (qui, l’esito positivo del test).\n\nQuesta differenza è fondamentale nell’interpretazione dei test diagnostici, specialmente quando la malattia è relativamente rara.\n\n\n\n\n\n\n\n\n\nIl Problema di Monty Hall\n\n\n\n\n\nIl problema di Monty Hall è un famoso quesito di teoria della probabilità che illustra in modo efficace il concetto di probabilità condizionata. Questo problema è diventato celebre grazie a una rubrica tenuta da Marilyn vos Savant nella rivista Parade, in cui rispose a una lettera pubblicata il 9 settembre 1990:\n\n“Supponiamo di partecipare a un quiz televisivo e di dover scegliere tra tre porte. Dietro una di esse c’è un’auto, mentre dietro le altre due ci sono delle capre. Scegli una porta, ad esempio la numero 1, e il conduttore, che sa cosa c’è dietro ogni porta, ne apre un’altra, diciamo la numero 3, rivelando una capra. A questo punto, ti chiede se vuoi cambiare la tua scelta e passare alla porta numero 2. È vantaggioso cambiare porta?” Craig. F. Whitaker, Columbia, MD\n\nLa situazione descritta ricorda quella del popolare quiz televisivo degli anni ’70 Let’s Make a Deal, condotto da Monty Hall e Carol Merrill. Marilyn vos Savant rispose che il concorrente dovrebbe cambiare porta, poiché la probabilità di vincere l’auto raddoppia passando da 1/3 a 2/3. Tuttavia, la sua risposta suscitò un acceso dibattito, con molte persone, inclusi alcuni matematici, che sostenevano che cambiare porta non avrebbe offerto alcun vantaggio. Questo episodio ha reso il problema di Monty Hall uno dei più famosi esempi di come l’intuizione possa portare a conclusioni errate in ambito probabilistico.\nChiarire il Problema.\nLa lettera originale di Craig Whitaker è piuttosto vaga, quindi per analizzare il problema in modo rigoroso è necessario fare alcune ipotesi:\n\n\nPosizione dell’auto: L’auto è nascosta in modo casuale ed equiprobabile dietro una delle tre porte.\n\nScelta iniziale del giocatore: Il giocatore sceglie una porta in modo casuale, indipendentemente dalla posizione dell’auto.\n\nAzione del conduttore: Dopo la scelta del giocatore, il conduttore apre una delle due porte rimanenti, rivelando una capra, e offre al giocatore la possibilità di cambiare porta.\n\nScelta del conduttore: Se il conduttore ha la possibilità di scegliere tra due porte (entrambe con capre), ne apre una in modo casuale.\n\nCon queste assunzioni, possiamo rispondere alla domanda: Qual è la probabilità che il giocatore vinca l’auto se decide di cambiare porta?\nDi seguito, esploreremo tre metodi per risolvere il problema di Monty Hall: il diagramma ad albero, l’analisi delle probabilità e una simulazione.\nMetodo 1: diagramma ad albero.\nIl diagramma ad albero è uno strumento utile per visualizzare tutti i possibili esiti di un esperimento probabilistico. Nel caso del problema di Monty Hall, possiamo suddividere il processo in tre fasi:\n\n\nPosizione dell’auto: L’auto può trovarsi dietro una delle tre porte (A, B o C), ciascuna con probabilità 1/3.\n\nScelta del giocatore: Il giocatore sceglie una porta in modo casuale, indipendentemente dalla posizione dell’auto.\n\nAzione del conduttore: Il conduttore apre una delle due porte rimanenti, rivelando una capra.\n\nIl diagramma ad albero mostra tutte le possibili combinazioni di questi eventi. Ad esempio, se l’auto è dietro la porta A e il giocatore sceglie la porta B, il conduttore aprirà la porta C (l’unica porta rimanente con una capra).\nPasso 1: Identificare lo spazio campionario\nLo spazio campionario è composto da 12 esiti possibili, rappresentati dalle combinazioni di:\n\nPosizione dell’auto (A, B, C).\nScelta iniziale del giocatore (A, B, C).\nPorta aperta dal conduttore (una delle due rimanenti con una capra).\n\nEcco un diagramma ad albero che rappresenta questa situazione:\n\n\n\n\n\nFigura 29.1: Il diagramma ad albero per il Problema di Monty Hall mostra le probabilità associate a ogni possibile esito. I pesi sugli archi rappresentano la probabilità di seguire quel particolare percorso, dato che ci troviamo nel nodo padre. Ad esempio, se l’auto si trova dietro la porta A, la probabilità che il giocatore scelga inizialmente la porta B è pari a 1/3. La colonna più a destra del diagramma mostra la probabilità di ciascun esito finale. Ogni probabilità di esito è calcolata moltiplicando le probabilità lungo il percorso che parte dalla radice (auto dietro una certa porta) e termina alla foglia (esito finale) (Figura tratta da Lehman, Leighton e Meyer, 2018).\n\n\nPasso 2: Definire l’evento di interesse\nL’evento di interesse è “il giocatore vince cambiando porta”. Questo si verifica quando la porta inizialmente scelta dal giocatore non nasconde l’auto, e il giocatore decide di cambiare porta.\nGli esiti che soddisfano questa condizione sono:\n\n(Auto A, Scelta B, Apertura C)\n(Auto A, Scelta C, Apertura B)\n(Auto B, Scelta A, Apertura C)\n(Auto B, Scelta C, Apertura A)\n(Auto C, Scelta A, Apertura B)\n(Auto C, Scelta B, Apertura A)\n\nQuesti esiti sono in totale 6.\nPasso 3: Calcolare le probabilità degli esiti\nOgni esito ha una probabilità specifica, calcolata moltiplicando le probabilità lungo il percorso nel diagramma ad albero.\nEsempio di calcolo per l’esito (Auto A, Scelta B, Apertura C):\n\nLa probabilità che l’auto sia dietro la porta A è \\(\\frac{1}{3}\\).\nLa probabilità che il giocatore scelga la porta B è \\(\\frac{1}{3}\\).\nLa probabilità che il conduttore apra la porta C (che contiene una capra) è \\(1\\) (poiché il conduttore deve aprire una porta con una capra, e la porta C è l’unica possibile).\n\nLa probabilità totale per questo esito è:\n\\[\nP(\\text{Auto A, Scelta B, Apertura C}) = \\frac{1}{3} \\times \\frac{1}{3} \\times 1 = \\frac{1}{9}.\n\\]\nProcedendo in modo simile per tutti gli altri esiti, otteniamo le probabilità per tutti i 12 esiti.\nPasso 4: Calcolare la probabilità dell’evento\nLa probabilità di vincere cambiando porta è la somma delle probabilità degli esiti favorevoli.\n\\[\n\\begin{aligned}\nP&(\\text{vincere cambiando porta}) = \\notag \\\\\n&\\quad P(\\text{Auto A, Scelta B, Apertura C}) + P(\\text{Auto A, Scelta C, Apertura B}) + \\notag\\\\  \n&\\quad P(\\text{Auto B, Scelta A, Apertura C}) + \\dots \\notag\n\\end{aligned}\n\\]\n\\[\n= \\frac{1}{9} + \\frac{1}{9} + \\frac{1}{9} + \\frac{1}{9} + \\frac{1}{9} + \\frac{1}{9} = \\frac{6}{9} = \\frac{2}{3}.\n\\]\nLa probabilità di vincere mantenendo la scelta originale è il complemento:\n\\[\nP(\\text{vincere mantenendo la scelta}) = 1 - P(\\text{vincere cambiando porta}) = 1 - \\frac{2}{3} = \\frac{1}{3}.\n\\]\nLa conclusione è che il giocatore ha una probabilità di vincere pari a \\(\\frac{2}{3}\\) se cambia porta, contro una probabilità di \\(\\frac{1}{3}\\) se mantiene la sua scelta iniziale. Cambiare porta è quindi la strategia vincente.\nMetodo 2: analisi delle probabilità.\nIl problema di Monty Hall può essere chiarito analizzando i tre scenari possibili, immaginando di essere osservatori esterni che sanno cosa si nasconde dietro ogni porta:\n\n\nPrimo scenario:\n\nIl giocatore sceglie inizialmente la porta con una capra (chiamiamola “capra 1”).\n\nIl conduttore apre l’altra porta con la “capra 2”.\n\nSe il giocatore cambia porta, vince l’automobile.\n\n\n\nSecondo scenario:\n\nIl giocatore sceglie inizialmente la porta con l’altra capra (“capra 2”).\n\nIl conduttore apre la porta con la “capra 1”.\n\nSe il giocatore cambia porta, vince l’automobile.\n\n\n\nTerzo scenario:\n\nIl giocatore sceglie inizialmente la porta con l’automobile.\n\nIl conduttore apre una delle due porte con una capra (non importa quale).\n\nSe il giocatore cambia porta, perde l’automobile.\n\n\n\nAll’inizio del gioco, il giocatore ha:\n\n\n1/3 di probabilità di scegliere l’automobile.\n\n\n2/3 di probabilità di scegliere una capra.\n\nDopo la scelta iniziale, il conduttore apre una porta con una capra, ma questa azione non altera le probabilità iniziali. Il giocatore si trova quindi con due porte chiuse: quella scelta inizialmente e una rimanente.\n\nSe il giocatore ha scelto l’automobile inizialmente (1/3 di probabilità), cambiando porta perde.\n\nSe il giocatore ha scelto una capra inizialmente (2/3 di probabilità), cambiando porta vince l’automobile.\n\nIn sintesi, cambiando porta, il giocatore ha 2/3 di probabilità di vincere l’automobile, mentre mantenendo la scelta iniziale ha solo 1/3 di probabilità. Pertanto, la strategia migliore è cambiare porta per massimizzare le possibilità di vittoria.\nMetodo 3: simulazione.\nPer confermare il risultato, possiamo eseguire una simulazione. Ripetendo il gioco migliaia di volte, possiamo confrontare la frequenza con cui il giocatore vince cambiando porta rispetto a quando mantiene la scelta iniziale.\nEcco un esempio di codice in R per la simulazione:\n\n# Numero di simulazioni da effettuare.\n# Più è grande B, più precisa sarà la stima.\nB &lt;- 10000  \n\n# Definiamo una funzione \"monty_hall\" che\n# a) simula un gioco\n# b) restituisce TRUE/FALSE a seconda che il giocatore vinca l'auto o no.\nmonty_hall &lt;- function(strategy){\n  \n  # 1. Dichiariamo le porte possibili, in forma di stringhe.\n  doors &lt;- c(\"1\", \"2\", \"3\")\n  \n  # 2. Stabiliamo dove si trova il premio (auto) e le capre.\n  #    \"prize\" sarà un vettore con dentro \"car\" per la porta con l’auto \n  #    e \"goat\" per quelle con la capra.\n  #    La funzione sample() crea una distribuzione casuale di \"car\" e \"goat\".\n  prize &lt;- sample(c(\"car\", \"goat\", \"goat\"))\n  \n  # 3. Troviamo qual è la porta che ha la macchina.\n  prize_door &lt;- doors[ prize == \"car\" ]\n  \n  # 4. Il giocatore fa la sua prima scelta, pescando a caso fra le 3 porte.\n  my_pick &lt;- sample(doors, 1)\n  \n  # 5. Il conduttore deve aprire una porta che:\n  #    - non sia la mia (my_pick)\n  #    - non abbia la macchina (prize_door)\n  #    Così facendo, rivela una porta con la capra.\n  #    Se ci sono due porte con capra, ne sceglie una a caso.\n  show &lt;- sample(doors[!doors %in% c(my_pick, prize_door)], 1)\n  \n  # 6. La strategia \"stick\" significa: RESTARE sulla scelta iniziale (my_pick).\n  #    La strategia \"switch\" significa: CAMBIARE porta, passando a quella\n  #    rimasta tra le due che NON sono state aperte.\n  stick &lt;- my_pick\n  switch &lt;- doors[!doors %in% c(my_pick, show)]\n  \n  # 7. Se la strategia scelta (in input) è \"stick\", la mia scelta finale è \"stick\".\n  #    Altrimenti, è \"switch\".\n  final_choice &lt;- ifelse(strategy == \"stick\", stick, switch)\n  \n  # 8. La funzione restituisce TRUE se la scelta finale coincide con la porta premiata,\n  #    altrimenti FALSE.\n  return(final_choice == prize_door)\n}\n\nNel codice qui sopra:\n\n\nmy_pick è la porta che il giocatore sceglie subito.\n\nshow è la porta che il conduttore mostra, rivelando la capra.\n\nstick rimane la scelta iniziale (quindi è my_pick).\n\nswitch è la porta che rimane fra le non aperte e non scelte inizialmente.\n\nAl termine, la funzione monty_hall() stabilisce se, con la strategia considerata, si vince (TRUE) o si perde (FALSE).\n\n# Simuliamo B volte la strategia \"stick\" (non cambiare mai la scelta iniziale).\nstick_results &lt;- replicate(B, monty_hall(\"stick\"))\n\n# stick_results è un vettore di TRUE/FALSE lungo B.\n# Per scoprire la percentuale di vittorie, calcoliamo la media dei TRUE.\nmean(stick_results)\n#&gt; [1] 0.3278\n\n\n# Simuliamo B volte la strategia \"switch\" (cambiare sempre la scelta iniziale).\nswitch_results &lt;- replicate(B, monty_hall(\"switch\"))\n\n# Anche qui, calcoliamo la media per sapere quante volte abbiamo vinto l’auto.\nmean(switch_results)\n#&gt; [1] 0.6678\n\n\nLa media di un vettore di TRUE/FALSE in R è pari alla frazione di TRUE.\nIn questo modo, mean(stick_results) ci dice la probabilità di vincere restando sulla scelta iniziale.\n\nmean(switch_results) ci dice la probabilità di vincere se si cambia sempre porta dopo l’intervento del conduttore.\n\nRisultati attesi:\n\n\nMantenere la Scelta Iniziale: La frequenza di vittoria dovrebbe essere circa 1/3 (33.3%).\n\nCambiare Porta: La frequenza di vittoria dovrebbe essere circa 2/3 (66.6%).\n\nLa simulazione conferma che cambiare porta aumenta la probabilità di vincere da 1/3 a 2/3, dimostrando che la strategia ottimale nel problema di Monty Hall è quella di cambiare porta dopo che il conduttore ha rivelato una capra.\nIn sintesi, il problema di Monty Hall mette in luce come l’intuizione possa trarci in inganno quando ci confrontiamo con scenari probabilistici. Attraverso l’uso del diagramma ad albero, un’analisi delle probabilità e l’esecuzione di simulazioni, abbiamo dimostrato che cambiare porta raddoppia le possibilità di vincita, facendole passare da 1/3 a 2/3. Questo risultato, in apparente contrasto con ciò che potrebbe sembrare intuitivo, costituisce un esempio emblematico dell’importanza di adottare un approccio formale nella valutazione delle probabilità, anziché affidarsi esclusivamente a impressioni iniziali che spesso si rivelano fuorvianti.\n\n\n\n\n\n\n\n\n\nIl paradosso di Simpson\n\n\n\n\n\nNel contesto della probabilità condizionata, un fenomeno particolarmente interessante e, al tempo stesso, controintuitivo è il paradosso di Simpson. Questo paradosso si verifica quando una tendenza osservata in diversi gruppi di dati separati scompare o addirittura si inverte una volta che i gruppi vengono combinati.\nIl paradosso di Simpson evidenzia l’importanza di considerare le variabili confondenti e di analizzare i dati con grande attenzione per evitare di trarre conclusioni errate o fuorvianti. È un esempio emblematico di come l’interpretazione dei dati statistici richieda non solo strumenti matematici, ma anche una profonda comprensione del contesto e delle relazioni tra le variabili coinvolte.\nUn caso storico di paradosso di Simpson riguarda l’applicazione della pena di morte negli Stati Uniti (Radelet & Pierce, 1991). Questo studio analizza 674 processi per omicidio in Florida tra il 1976 e il 1987, esaminando l’influenza della razza dell’imputato e della vittima sulla probabilità di ricevere la pena di morte. I dati riportano il numero di condannati alla pena di morte in base alla razza dell’imputato e della vittima:\n\n\n\n\n\n\n\n\n\nRazza dell’imputato\nRazza della vittima\nPena di morte\nNo pena di morte\nTasso di condanna\n\n\n\nBianco\nBianco\n19\n132\n19 / 151 ≈ 12.6%\n\n\nBianco\nNero\n11\n52\n11 / 63 ≈ 17.5%\n\n\nNero\nBianco\n6\n37\n6 / 43 ≈ 14.0%\n\n\nNero\nNero\n1\n9\n1 / 10 = 10.0%\n\n\n\nSe analizziamo i dati separatamente per la razza della vittima, emerge che la probabilità di ricevere la pena di morte è più alta per gli imputati bianchi rispetto agli imputati neri, sia nei casi in cui la vittima era bianca (12.6% vs 14.0%) sia nei casi in cui la vittima era nera (17.5% vs 10.0%).\nTuttavia, quando i dati vengono aggregati senza tenere conto della razza della vittima, si osserva una tendenza opposta:\n\n\n\n\n\n\n\n\nRazza dell’imputato\nPena di morte\nNo pena di morte\nTasso di condanna\n\n\n\nBianco\n30\n184\n30 / 214 ≈ 14.0%\n\n\nNero\n7\n46\n7 / 53 ≈ 13.2%\n\n\n\nAggregando i dati, sembra che gli imputati neri abbiano meno probabilità di ricevere la pena di morte rispetto agli imputati bianchi (13.2% vs 14.0%).\nQuesta apparente contraddizione è il risultato del paradosso di Simpson. La variabile confondente in questo caso è la razza della vittima: gli omicidi con vittime bianche avevano una probabilità molto più alta di portare alla pena di morte rispetto agli omicidi con vittime nere. Poiché gli imputati bianchi erano più spesso accusati di aver ucciso vittime bianche (per cui la probabilità di pena di morte era maggiore), il loro tasso di condanna complessivo risultava più alto. Viceversa, gli imputati neri erano più spesso accusati di aver ucciso vittime nere (per cui la probabilità di pena di morte era inferiore), abbassando il loro tasso di condanna complessivo.\nQuesto caso dimostra come l’aggregazione dei dati senza considerare una variabile confondente (in questo caso, la razza della vittima) possa portare a una conclusione errata e fuorviante. È essenziale analizzare i dati in modo stratificato per evitare interpretazioni distorte e per comprendere i reali meccanismi sottostanti un fenomeno.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_conditional_prob.html#indipendenza-e-probabilità-condizionata",
    "href": "chapters/probability/05_conditional_prob.html#indipendenza-e-probabilità-condizionata",
    "title": "29  Probabilità condizionata",
    "section": "\n29.5 Indipendenza e Probabilità Condizionata",
    "text": "29.5 Indipendenza e Probabilità Condizionata\nL’indipendenza tra due eventi \\(A\\) e \\(B\\) può essere interpretata intuitivamente attraverso la probabilità condizionata. Due eventi sono indipendenti se il verificarsi di uno non influenza la probabilità di verificarsi dell’altro. In altre parole, conoscere che \\(B\\) è accaduto non modifica la probabilità di \\(A\\), e viceversa.\nQuesta relazione può essere formalizzata con le seguenti equazioni:\n\\[\nP(A \\mid B) = \\frac{P(A \\cap B)}{P(B)} = P(A),\n\\]\n\\[\nP(B \\mid A) = \\frac{P(A \\cap B)}{P(A)} = P(B).\n\\]\nPertanto, \\(A\\) e \\(B\\) sono indipendenti se e solo se:\n\\[\nP(A \\mid B) = P(A),\n\\]\n\\[\nP(B \\mid A) = P(B).\n\\]\nQueste condizioni significano che la probabilità di \\(A\\) non cambia, indipendentemente dal fatto che \\(B\\) sia accaduto, e lo stesso vale per \\(B\\).\n\n29.5.1 Indipendenza di Tre Eventi\nLa definizione di indipendenza si estende naturalmente a tre eventi \\(A\\), \\(B\\), e \\(C\\), ma con condizioni aggiuntive. Tre eventi sono indipendenti se:\n\n\nOgni coppia di eventi è indipendente:\n\\[\n\\begin{aligned}\nP(A \\cap B) &= P(A) P(B), \\\\\nP(A \\cap C) &= P(A) P(C), \\\\\nP(B \\cap C) &= P(B) P(C).\n\\end{aligned}\n\\]\n\n\nLa probabilità congiunta di tutti e tre gli eventi è uguale al prodotto delle loro probabilità individuali:\n\\[\nP(A \\cap B \\cap C) = P(A) P(B) P(C).\n\\]\n\n\nLe prime tre condizioni verificano l’indipendenza a coppie (indipendenza a due a due), mentre l’ultima condizione garantisce che i tre eventi siano completamente indipendenti. È importante notare che l’indipendenza a due a due non implica necessariamente l’indipendenza completa: per essere indipendenti nel senso completo, tutte e quattro le condizioni devono essere soddisfatte.\nIn sintesi, l’indipendenza tra eventi implica che il verificarsi di uno di essi non fornisce alcuna informazione sulla probabilità del verificarsi degli altri. Nel caso di due eventi, questa proprietà si traduce nell’invarianza della probabilità condizionata. Per tre o più eventi, l’indipendenza richiede sia l’indipendenza a coppie sia la condizione più forte sull’intersezione di tutti gli eventi.\nQuesti concetti sono fondamentali nella probabilità e nella statistica, poiché semplificano molti calcoli e forniscono una base per modelli più complessi.\n\nEsempio 29.6 Indipendenza tra Eventi in un Mazzo di Carte\nScenario 1: Mazzo Completo (52 Carte)\nConsideriamo un mazzo standard di 52 carte. Ogni seme (picche, cuori, quadri, fiori) contiene 13 carte, e nel mazzo ci sono 4 Regine in totale. Definiamo i seguenti eventi:\n\n\n\\(A\\) = “Pescare una carta di picche”,\n\n\n\\(B\\) = “Pescare una carta Regina”.\n\n\nProbabilità di \\(A\\). Poiché ci sono 13 picche in un mazzo di 52 carte, \\[\nP(A) = \\frac{13}{52} = \\frac{1}{4}.\n\\]\nProbabilità di \\(B\\). Ci sono 4 Regine su 52 carte, quindi \\[\nP(B) = \\frac{4}{52} = \\frac{1}{13}.\n\\]\nProbabilità congiunta \\(P(A \\cap B)\\). L’unica carta che è contemporaneamente “picche” e “Regina” è la Regina di picche, perciò: \\[\nP(A \\cap B) = \\frac{1}{52}.\n\\]\n\nPer verificare l’indipendenza di \\(A\\) e \\(B\\), confrontiamo \\(P(A \\cap B)\\) con \\(P(A)\\,P(B)\\):\n\\[\nP(A)\\,P(B)\n= \\frac{1}{4} \\times \\frac{1}{13}\n= \\frac{1}{52},\n\\] \\[\nP(A \\cap B)\n= \\frac{1}{52}.\n\\]\nPoiché \\(P(A \\cap B) = P(A)\\,P(B)\\), i due eventi sono indipendenti quando il mazzo è completo.\nScenario 2: Mazzo Ridotto (51 Carte)\nOra rimuoviamo una carta qualunque dal mazzo — ad esempio il “2 di quadri” — portando il totale a 51 carte. Notiamo che la Regina di picche non è stata rimossa, ma il cambio di composizione potrebbe comunque influire sulle probabilità.\n\nProbabilità di \\(A \\cap B\\). Poiché la Regina di picche è ancora presente, pescare quella carta specifica ha ora probabilità \\[\nP(A \\cap B) = \\frac{1}{51}.\n\\]\nProbabilità di \\(A\\). Il seme di picche non è stato modificato (restano 13 picche), ma il denominatore è passato a 51 carte: \\[\nP(A) = \\frac{13}{51}.\n\\]\nProbabilità di \\(B\\). Nel mazzo restano ancora 4 Regine (nessuna è stata rimossa), su 51 carte totali: \\[\nP(B) = \\frac{4}{51}.\n\\]\nProdotto \\(P(A)\\,P(B)\\). Calcolando: \\[\nP(A)\\,P(B)\n= \\frac{13}{51} \\times \\frac{4}{51}\n= \\frac{52}{2601}.\n\\]\n\nConfrontando:\n\\[\nP(A \\cap B)\n= \\frac{1}{51},\n\\quad\\text{mentre}\\quad\nP(A)\\,P(B)\n= \\frac{52}{2601}.\n\\]\nSi verifica che\n\\[\n\\frac{1}{51}\n\\;\\neq\\;\n\\frac{52}{2601}.\n\\]\nPertanto, \\(A\\) e \\(B\\) non sono più indipendenti nel mazzo ridotto.\nIn sintesi, questo esempio mostra come l’indipendenza tra due eventi dipenda dal contesto:\n\ncon un mazzo completo (52 carte), “pescare picche” e “pescare una Regina” sono eventi indipendenti;\nbasta rimuovere una carta qualunque (anche non correlata direttamente a “picche” o “Regine”) perché le probabilità cambino e gli stessi eventi cessino di essere indipendenti.\n\nIn altre parole, ogni modifica alla composizione del mazzo può influire sulle probabilità dei singoli eventi e, di conseguenza, sulle loro relazioni di dipendenza o indipendenza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_conditional_prob.html#teorema-del-prodotto",
    "href": "chapters/probability/05_conditional_prob.html#teorema-del-prodotto",
    "title": "29  Probabilità condizionata",
    "section": "\n29.6 Teorema del Prodotto",
    "text": "29.6 Teorema del Prodotto\nA partire dalla definizione di probabilità condizionata, possiamo derivare quello che viene chiamato Teorema del Prodotto, noto anche come teorema della probabilità composta, regola moltiplicativa o regola della catena. Questo risultato permette di esprimere la probabilità congiunta di due o più eventi come il prodotto di probabilità condizionate.\n\n29.6.1 Caso di Due Eventi\nPer due eventi \\(A\\) e \\(B\\), il Teorema del Prodotto asserisce che:\n\\[\nP(A \\cap B)\n\\;=\\;\nP(B) \\,\\cdot\\, P(A \\mid B)\n\\;=\\;\nP(A) \\,\\cdot\\, P(B \\mid A).\n\\tag{29.4}\\]\nIn altre parole, la probabilità che \\(A\\) e \\(B\\) si verifichino contemporaneamente può essere calcolata in due modi equivalenti:\n\n\nprimo modo: prendi la probabilità di \\(B\\), quindi moltiplicala per la probabilità di \\(A\\), sapendo già che \\(B\\) è accaduto;\n\nsecondo modo: prendi la probabilità di \\(A\\), quindi moltiplicala per la probabilità di \\(B\\), sapendo già che \\(A\\) è accaduto.\n\nL’ordine degli eventi in cui si applica la condizione è arbitrario, a patto di rispettare la formula e scegliere la condizione corrispondente.\n\n29.6.2 Generalizzazione a \\(n\\) Eventi\nIl Teorema del Prodotto si estende naturalmente al caso di più di due eventi. Se consideriamo \\(n\\) eventi \\(A_1, A_2, \\dots, A_n\\), e assumiamo che\n\\[\nP(A_1 \\cap A_2 \\cap \\cdots \\cap A_{n-1}) \\;&gt;\\; 0,\n\\]\nallora la probabilità che tutti questi eventi si verifichino è data da:\n\\[\n\\begin{aligned}\nP(A_1 \\,\\cap\\, A_2 \\,\\cap\\, \\cdots \\,\\cap\\, A_n)\n&= P(A_1)\n\\;\\times\\; P(A_2 \\mid A_1)\n\\;\\times\\; P(A_3 \\mid A_1 \\cap A_2)\n\\;\\times\\; \\cdots \\\\\n&\\quad \\cdots \\times\\; P(A_n \\mid A_1 \\cap A_2 \\cap \\cdots \\cap A_{n-1}).\n\\end{aligned}\n\\tag{29.5}\\]\nIn pratica, ciascun fattore si ottiene considerando la probabilità dell’evento successivo, condizionata sul verificarsi di tutti gli eventi precedenti. Questa formulazione è cruciale, ad esempio, nelle analisi di sequenze di eventi o in modelli statistici in cui le probabilità vengono “aggiornate” gradualmente mano a mano che si verificano nuove condizioni.\nIl Teorema del Prodotto rappresenta uno dei fondamenti teorici più importanti della probabilità e trova applicazioni in numerosi contesti, quali:\n\nla modellazione di processi sequenziali o temporali;\nla scomposizione di problemi complessi in calcoli più semplici e gestibili;\nla teoria delle reti bayesiane e l’analisi della probabilità condizionata.\n\nGrazie a questo teorema, è possibile affrontare problemi complessi suddividendoli in passaggi progressivi, in cui ogni probabilità condizionata contribuisce alla costruzione della soluzione complessiva in maniera sistematica.\n\n29.6.2.1 Procedura di calcolo\nPer applicare la regola:\n\n\nparti dal primo evento: usa la probabilità incondizionata \\(P(A_1)\\);\n\n\ncondiziona progressivamente: moltiplica per \\(P(A_2 \\mid A_1)\\), poi per \\(P(A_3 \\mid A_1 \\cap A_2)\\), e così via;\n\ntermina con l’ultimo evento: includi \\(P(A_n \\mid A_1 \\cap \\cdots \\cap A_{n-1})\\).\n\n\nEsempio 29.7 Da un’urna contenente 6 palline bianche e 4 nere si estrae una pallina per volta, senza reintrodurla nell’urna. Indichiamo con \\(B_i\\) l’evento: “esce una pallina bianca alla \\(i\\)-esima estrazione” e con \\(N_i\\) l’estrazione di una pallina nera. L’evento: “escono due palline bianche nelle prime due estrazioni” è rappresentato dalla intersezione \\(\\{B_1 \\cap B_2\\}\\) e, per l’Equazione 29.4, la sua probabilità vale\n\\[\nP(B_1 \\cap B_2) = P(B_1)P(B_2 \\mid B_1).\n\\]\n\\(P(B_1)\\) vale 6/10, perché nella prima estrazione \\(\\Omega\\) è costituito da 10 elementi: 6 palline bianche e 4 nere. La probabilità condizionata \\(P(B_2 \\mid B_1)\\) vale 5/9, perché nella seconda estrazione, se è verificato l’evento \\(B_1\\), lo spazio campionario consiste di 5 palline bianche e 4 nere. Si ricava pertanto:\n\\[\nP(B_1 \\cap B_2) = \\frac{6}{10} \\cdot \\frac{5}{9} = \\frac{1}{3}.\n\\]\nIn modo analogo si ha che\n\\[\nP(N_1 \\cap N_2) = P(N_1)P(N_2 \\mid N_1) = \\frac{4}{10} \\cdot \\frac{3}{9} = \\frac{4}{30}.\n\\]\nSe l’esperimento consiste nell’estrazione successiva di 3 palline, la probabilità che queste siano tutte bianche, per l’Equazione 29.5, vale\n\\[\n\\begin{aligned}\nP(B_1 \\cap B_2 \\cap B_3) &=P(B_1)P(B_2 \\mid B_1)P(B_3 \\mid B_1 \\cap B_2) \\notag\\\\\n&=\\frac{6}{10}\\cdot\\frac{5}{9} \\cdot\\frac{4}{8} \\notag\\\\\n&= \\frac{1}{6}.\n\\end{aligned}\n\\]\nLa probabilità dell’estrazione di tre palline nere è invece:\n\\[\n\\begin{aligned}\nP(N_1 \\cap N_2 \\cap N_3) &= P(N_1)P(N_2 \\mid N_1)P(N_3 \\mid N_1 \\cap N_2)\\notag\\\\\n&= \\frac{4}{10} \\cdot \\frac{3}{9} \\cdot \\frac{2}{8} \\notag\\\\\n&= \\frac{1}{30}.\\notag\n\\end{aligned}\n\\]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_conditional_prob.html#teorema-della-probabilità-totale",
    "href": "chapters/probability/05_conditional_prob.html#teorema-della-probabilità-totale",
    "title": "29  Probabilità condizionata",
    "section": "\n29.7 Teorema della Probabilità Totale",
    "text": "29.7 Teorema della Probabilità Totale\nIl Teorema della Probabilità Totale — anche detto legge della probabilità totale — permette di calcolare la probabilità di un evento \\(A\\) scomponendola rispetto a una partizione di sottoinsiemi che coprono l’intero spazio campionario. È particolarmente utile quando si affrontano situazioni con più scenari, categorie o gruppi nei quali ripartire il calcolo di probabilità.\n\n29.7.1 Enunciato Generale\n\nDefinizione 29.3 Supponiamo che lo spazio campionario \\(\\Omega\\) sia suddiviso in una partizione di eventi \\(B_1, B_2, \\dots, B_n\\), ossia:\n\n\nmutua esclusività: \\(B_i \\cap B_j = \\varnothing\\) per \\(i \\neq j\\);\n\n\ncopertura totale: \\(\\bigcup_{i=1}^n B_i = \\Omega\\).\n\nAllora, per un qualsiasi evento \\(A \\subseteq \\Omega\\) vale:\n\\[\nP(A)\n\\;=\\;\n\\sum_{i=1}^n P(A \\cap B_i)\n\\;=\\;\n\\sum_{i=1}^n P(A \\mid B_i)\\, P(B_i).\n\\tag{29.6}\\]\nIn altre parole, \\(P(A)\\) può essere visto come una media pesata delle probabilità condizionate \\(P(A \\mid B_i)\\), con pesi \\(P(B_i)\\).\n\n\n29.7.2 Caso di Due Partizioni\nQuando lo spazio campionario è ripartito in due soli eventi, \\(B\\) e il suo complementare \\(B^c\\), la formula si semplifica in:\n\\[\n\\begin{aligned}\nP(A)\n&= P(A \\cap B) + P(A \\cap B^c) \\\\\n&= P(A \\mid B)\\,P(B) \\;+\\; P(A \\mid B^c)\\,P(B^c).\n\\end{aligned}\n\\tag{29.7}\\]\n\nEsempio 29.8 Test medico\nAbbiamo:\n\n\n\\(B\\): “Una persona è malata”;\n\n\\(B^c\\): “Una persona è sana”;\n\n\n\\(A\\): “Test positivo”.\n\nSecondo il Teorema della Probabilità Totale, la probabilità di un risultato positivo si ottiene sommando:\n\\[\nP(A)\n= P(\\text{Positivo} \\mid \\text{Malato}) \\,P(\\text{Malato})\n\\;+\\;\nP(\\text{Positivo} \\mid \\text{Sano}) \\,P(\\text{Sano}).\n\\]\n\n\n29.7.3 Applicazioni Principali\n\nAnalisi per Categorie\nQuando la popolazione è divisa in gruppi \\(B_1, \\dots, B_n\\) (ad esempio, fasce d’età o regioni), la probabilità di un evento \\(A\\) si ottiene sommando le probabilità di \\(A\\) condizionate a ciascun gruppo, moltiplicate per la frequenza di quel gruppo.\nTeorema di Bayes\nIl denominatore della formula di Bayes è la somma \\(\\sum_{j=1}^n P(E \\mid H_j)\\,P(H_j)\\), che è appunto un’applicazione della probabilità totale. Qui, \\(H_1, \\dots, H_n\\) rappresentano ipotesi alternative (partizione) e \\(E\\) un dato osservato.\n\n\nEsempio 29.9 Urne con Palline di Colori Diversi\nAbbiamo 3 urne, ciascuna con 100 palline:\n\nUrna 1: 75 rosse, 25 blu\n\nUrna 2: 60 rosse, 40 blu\n\nUrna 3: 45 rosse, 55 blu\n\nL’urna viene scelta a caso (probabilità \\(1/3\\) per ciascuna). Qual è la probabilità di estrarre una pallina rossa?\nDefinisco:\n\n\n\\(R\\): “Estraggo una pallina rossa”;\n\n\n\\(U_i\\): “Seleziono l’Urna \\(i\\)”.\n\nLe urne \\(U_1, U_2, U_3\\) costituiscono una partizione (disgiunte e coprenti \\(\\Omega\\)). Sappiamo:\n\\[\nP(R \\mid U_1)=0.75,\n\\quad\nP(R \\mid U_2)=0.60,\n\\quad\nP(R \\mid U_3)=0.45.\n\\]\nApplicando la probabilità totale:\n\\[\n\\begin{aligned}\nP(R)\n&= P(R \\mid U_1)\\,P(U_1) + P(R \\mid U_2)\\,P(U_2) + P(R \\mid U_3)\\,P(U_3)\\\\\n&= 0.75 \\times \\tfrac13 + 0.60 \\times \\tfrac13 + 0.45 \\times \\tfrac13\n= 0.60.\n\\end{aligned}\n\\]\n\n\nEsempio 29.10 Probabilità della Depressione in Diverse Fasce d’Età\nUna popolazione è suddivisa in 3 gruppi:\n\ngiovani (30%),\nadulti (40%),\n\nanziani (30%).\n\nLe probabilità condizionate di soffrire di depressione sono:\n\\[\nP(D \\mid \\text{Giovane}) = 0.10, \\quad\nP(D \\mid \\text{Adulto}) = 0.20, \\quad\nP(D \\mid \\text{Anziano}) = 0.35.\n\\]\nUsando la probabilità totale:\n\\[\nP(D)\n= 0.10\\times0.30 + 0.20\\times0.40 + 0.35\\times0.30\n= 0.215.\n\\]\nDunque, circa il 21.5% della popolazione totale soffre di depressione, combinando i tassi per ciascuna fascia.\n\nIn breve, il Teorema della Probabilità Totale “scompone” un problema globale in sotto-problemi più specifici, ciascuno condizionato su una porzione dello spazio campionario, permettendo di sommare i risultati finali per ottenere \\(P(A)\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_conditional_prob.html#riflessioni-conclusive",
    "href": "chapters/probability/05_conditional_prob.html#riflessioni-conclusive",
    "title": "29  Probabilità condizionata",
    "section": "\n29.8 Riflessioni Conclusive",
    "text": "29.8 Riflessioni Conclusive\nLa probabilità condizionata è uno dei concetti più importanti in statistica, poiché fornisce il quadro teorico per:\n\ncomprendere e formalizzare l’indipendenza tra eventi o variabili (assenza di ogni tipo di relazione);\nespandere e generalizzare il calcolo delle probabilità (ad esempio, la legge della probabilità totale, che scompone in modo sistematico eventi complessi);\n\nalimentare metodi inferenziali avanzati, come il Teorema di Bayes.\n\nIn particolare, il Teorema di Bayes rappresenta uno strumento cardine dell’inferenza statistica: grazie alla probabilità condizionata, è possibile “aggiornare” in modo continuo le credenze sulle ipotesi (o sui parametri di un modello) alla luce di nuove osservazioni. Tale caratteristica di “apprendimento” graduale rende l’inferenza bayesiana flessibile e potente, ideale per affrontare situazioni in cui vengono resi disponibili dati aggiuntivi o in cui le condizioni iniziali possono cambiare.\nIn definitiva, la probabilità condizionata non solo chiarisce la nozione di indipendenza e getta le fondamenta di metodi inferenziali evoluti, ma soprattutto rappresenta il “motore” di modelli che si adattano dinamicamente alle nuove informazioni. Questa prospettiva “attiva” nell’aggiornamento delle probabilità è ciò che rende l’analisi statistica uno strumento versatile per descrivere e interpretare il mondo reale.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_conditional_prob.html#esercizi",
    "href": "chapters/probability/05_conditional_prob.html#esercizi",
    "title": "29  Probabilità condizionata",
    "section": "\n29.9 Esercizi",
    "text": "29.9 Esercizi\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nEsercizio 1: Soddisfazione con la Vita e Stress Accademico\nUn gruppo di studenti ha compilato la Satisfaction with Life Scale (SWLS) e un questionario sullo stress accademico. Dai dati raccolti emerge che:\n\nIl 40% degli studenti ha riportato un alto livello di stress accademico.\nIl 60% degli studenti ha riportato un basso livello di stress accademico.\nTra gli studenti con alto stress, il 30% ha riportato una soddisfazione con la vita elevata.\nTra gli studenti con basso stress, il 70% ha riportato una soddisfazione con la vita elevata.\n\nCalcola la probabilità che uno studente scelto a caso abbia:\n\nUn alto livello di stress e una soddisfazione elevata.\nUna soddisfazione elevata.\nUn alto livello di stress, dato che ha una soddisfazione elevata.\n\nEsercizio 2: Studio del Paradosso di Simpson\nUn’università vuole valutare la relazione tra la frequenza di partecipazione alle lezioni e il successo negli esami finali. I dati raccolti mostrano che:\n\n\n\n\n\n\n\n\nGruppo\nStudenti con alta frequenza\nSuperano l’esame\nNon superano l’esame\n\n\n\nA\n40\n30\n10\n\n\nB\n60\n20\n40\n\n\n\n\nCalcola la probabilità di superare l’esame per ciascun gruppo separatamente.\nCalcola la probabilità totale di superare l’esame.\nSpiega se il Paradosso di Simpson si manifesta in questi dati.\n\nEsercizio 3: Il Problema di Monty Hall\nIn un quiz televisivo, un concorrente deve scegliere tra tre porte: dietro una c’è un’auto e dietro le altre due ci sono capre. Dopo la scelta iniziale, il conduttore, che sa cosa c’è dietro ogni porta, apre una delle due porte rimanenti rivelando una capra. Il concorrente ha ora la possibilità di cambiare la sua scelta.\n\nQual è la probabilità di vincere l’auto se il concorrente non cambia la sua scelta?\nQual è la probabilità di vincere l’auto se il concorrente cambia la sua scelta?\nSpiega perché cambiare porta è la strategia migliore.\n\nEsercizio 4: Teorema della Probabilità Totale\nUn’università ha tre dipartimenti: Psicologia, Economia e Ingegneria. Le proporzioni di studenti iscritti sono:\n\nPsicologia: 40%\nEconomia: 35%\nIngegneria: 25%\n\nLa probabilità di laurearsi in tempo varia per ogni dipartimento:\n\nPsicologia: 70%\nEconomia: 60%\nIngegneria: 80%\n\nCalcola la probabilità che uno studente scelto a caso si laurei in tempo.\nEsercizio 5: Urne e Palline\nUn’urna contiene 5 palline rosse e 7 blu. Si estrae una pallina, si osserva il colore e poi la pallina viene rimessa nell’urna. Quindi si estrae una seconda pallina.\n\nQual è la probabilità di estrarre due palline rosse?\nQual è la probabilità di estrarre almeno una pallina blu?\nQual è la probabilità di estrarre una pallina rossa alla seconda estrazione, dato che la prima estratta era blu?\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\nEsercizio 1: Soddisfazione con la Vita e Stress Accademico\n\n\nLa probabilità che uno studente abbia alto stress e soddisfazione elevata si calcola moltiplicando la probabilità condizionata di avere soddisfazione elevata dato l’alto stress per la probabilità di avere alto stress:\n\\[\nP(S \\cap V) = P(V | S) P(S) = 0.30 \\times 0.40 = 0.12.\n\\]\n\n\nLa probabilità che uno studente abbia una soddisfazione elevata, indipendentemente dal livello di stress, si ottiene applicando la legge della probabilità totale:\n\\[\nP(V) = P(V | S) P(S) + P(V | \\neg S) P(\\neg S)\n\\]\n\\[\n= (0.30 \\times 0.40) + (0.70 \\times 0.60) = 0.12 + 0.42 = 0.54.\n\\]\n\n\nLa probabilità che uno studente abbia alto stress sapendo che ha una soddisfazione elevata si calcola utilizzando la formula della probabilità condizionata:\n\\[\nP(S | V) = \\frac{P(S \\cap V)}{P(V)} = \\frac{0.12}{0.54} \\approx 0.22.\n\\]\n\n\nEsercizio 2: Studio del Paradosso di Simpson\n\n\n\\(P(E | A) = \\frac{30}{40} = 0.75\\), \\(P(E | B) = \\frac{20}{60} = 0.33\\)\n\n\\(P(E) = P(E | A) P(A) + P(E | B) P(B) = (0.75 \\times 0.40) + (0.33 \\times 0.60) = 0.30 + 0.198 = 0.498\\)\nSe i tassi di successo aggregati mostrano una relazione invertita, il Paradosso di Simpson si manifesta.\n\nEsercizio 3: Il Problema di Monty Hall\n\n\\(P(V | S) = \\frac{1}{3}\\)\n\\(P(V | C) = \\frac{2}{3}\\)\nCambiare porta aumenta le probabilità di vincita da \\(1/3\\) a \\(2/3\\), quindi conviene sempre cambiare.\n\nEsercizio 4: Teorema della Probabilità Totale\n\\(P(L) = (0.70 \\times 0.40) + (0.60 \\times 0.35) + (0.80 \\times 0.25) = 0.28 + 0.21 + 0.20 = 0.69\\)\nEsercizio 5: Urne e Palline\n\n\\(P(R_1 \\cap R_2) = (5/12) \\times (5/12) = 25/144\\)\n\\(1 - P(R_1 \\cap R_2) = 1 - 25/144 = 119/144\\)\n\\(P(R_2 | B_1) = 5/12\\)",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_conditional_prob.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/05_conditional_prob.html#informazioni-sullambiente-di-sviluppo",
    "title": "29  Probabilità condizionata",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.7   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.13.0 psych_2.5.3     \n#&gt;  [9] scales_1.4.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.3.0     ggplot2_3.5.2   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.4     stringi_1.8.7      lattice_0.22-7    \n#&gt;  [4] hms_1.1.3          digest_0.6.37      magrittr_2.0.3    \n#&gt;  [7] evaluate_1.0.4     grid_4.5.0         timechange_0.3.0  \n#&gt; [10] RColorBrewer_1.1-3 fastmap_1.2.0      rprojroot_2.0.4   \n#&gt; [13] jsonlite_2.0.0     mnormt_2.1.1       cli_3.6.5         \n#&gt; [16] rlang_1.1.6        withr_3.0.2        tools_4.5.0       \n#&gt; [19] parallel_4.5.0     tzdb_0.5.0         pacman_0.5.1      \n#&gt; [22] vctrs_0.6.5        R6_2.6.1           lifecycle_1.0.4   \n#&gt; [25] htmlwidgets_1.6.4  pkgconfig_2.0.3    pillar_1.10.2     \n#&gt; [28] gtable_0.3.6       glue_1.8.0         xfun_0.52         \n#&gt; [31] tidyselect_1.2.1   rstudioapi_0.17.1  farver_2.1.2      \n#&gt; [34] htmltools_0.5.8.1  nlme_3.1-168       rmarkdown_2.29    \n#&gt; [37] compiler_4.5.0",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_conditional_prob.html#bibliografia",
    "href": "chapters/probability/05_conditional_prob.html#bibliografia",
    "title": "29  Probabilità condizionata",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.\n\n\nRadelet, M. L., & Pierce, G. L. (1991). Choosing Those Who Will Die: Race and the Death Penalty in Florida. Florida Law Review, 43(1), 1–34.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_bayes_theorem.html",
    "href": "chapters/probability/06_bayes_theorem.html",
    "title": "30  Il teorema di Bayes",
    "section": "",
    "text": "30.1 Introduzione\nIl teorema di Bayes costituisce un metodo matematico ottimale per risolvere problemi di inferenza induttiva, ovvero situazioni in cui si deducono cause sottostanti, principi generali o strutture complesse a partire da dati parziali e incerti. Trova applicazione in scenari disparati: dalla ricostruzione della percezione tridimensionale basata su segnali retinici all’interpretazione degli stati mentali altrui attraverso il comportamento osservabile, fino alla stima di parametri fisici in condizioni sperimentali rumorose (Baker et al., 2011; Ma et al., 2023). La sua efficacia emerge soprattutto in contesti dove le evidenze disponibili non permettono di discriminare univocamente tra ipotesi concorrenti.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_bayes_theorem.html#introduzione",
    "href": "chapters/probability/06_bayes_theorem.html#introduzione",
    "title": "30  Il teorema di Bayes",
    "section": "",
    "text": "30.1.1 Incertezza come Fondamento dell’Inferenza\nUn principio cardine del ragionamento bayesiano è il riconoscimento dell’incertezza intrinseca a qualsiasi processo conoscitivo. Anche in un universo deterministico, la complessità dei sistemi e i limiti dei nostri sensi rendono impossibile una conoscenza completa. Ad esempio, non possiamo determinare con esattezza infiniti dettagli (come posizione e stato di ogni neurone nel cervello di un interlocutore) né accedere direttamente a variabili latenti (come emozioni o intenzioni). Di conseguenza, ogni inferenza conserva un margine probabilistico, che Bayes quantifica e trasforma in uno strumento operativo.\n\n30.1.2 Dinamica Bayesiana: Aggiornare le Credenze\nLa realtà può essere paragonata a una partita di poker più che a una di scacchi: operiamo sempre in condizioni di informazione imperfetta. Le decisioni si basano su un bilanciamento tra conoscenze pregresse (prior) e nuovi indizi (likelihood), in un processo dinamico formalizzato dall’equazione:\n\\[\nP(H \\mid E) = \\frac{P(E \\mid H) \\cdot P(H)}{P(E)} ,\n\\]\ndove:\n\n\n\\(P(H \\mid E)\\) (posterior): plausibilità rivista dell’ipotesi \\(H\\) dopo aver osservato l’evidenza \\(E\\);\n\n\n\\(P(E \\mid H)\\) (likelihood): probabilità di osservare \\(E\\) se \\(H\\) fosse vera;\n\n\n\\(P(H)\\) (prior): fiducia iniziale in \\(H\\);\n\n\n\\(P(E)\\): fattore di normalizzazione.\n\nQuesto meccanismo permette di ricalibrare razionalmente le convinzioni, riducendo l’incertezza man mano che nuovi dati vengono integrati.\n\n30.1.3 Inferenza Induttiva e Razionalità Adattiva\nL’inferenza induttiva bayesiana rappresenta un pilastro della razionalità scientifica e quotidiana. A differenza della logica deduttiva (dove le conclusioni derivano necessariamente dalle premesse), Bayes riconcilia teoria ed evidenza empirica, consentendo previsioni robuste nonostante dati incompleti. Le applicazioni spaziano:\n\nIn psicologia cognitiva, modellando come il cervello interpreta segnali ambigui (Caudek & Bruno, 2024; Domini & Caudek, 2003);\n\nIn intelligenza artificiale, guidando algoritmi di apprendimento automatico (Chivers, 2024);\n\nNelle scienze sociali, per stimare preferenze nascoste da comportamenti osservati.\n\nIl teorema non elimina l’incertezza, ma fornisce un protocollo formale per gestirla, trasformando l’induzione da atto intuitivo a procedura rigorosa. In questo senso, incarna un principio di razionalità adattiva, dove l’ottimalità non richiede onniscienza, bensì un aggiornamento coerente delle credenze in risposta all’esperienza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_bayes_theorem.html#sec-bayes-rescorla-wagner",
    "href": "chapters/probability/06_bayes_theorem.html#sec-bayes-rescorla-wagner",
    "title": "30  Il teorema di Bayes",
    "section": "\n30.2 Il Teorema di Bayes nella Psicologia: il Modello Rescorla-Wagner come Esempio di Adattamento all’Ambiente",
    "text": "30.2 Il Teorema di Bayes nella Psicologia: il Modello Rescorla-Wagner come Esempio di Adattamento all’Ambiente\nPer illustrare concretamente il ruolo del teorema di Bayes in psicologia, possiamo considerare un fenomeno molto comune nella vita quotidiana: l’apprendimento associativo. Questa capacità permette a esseri umani e altri organismi viventi di prevedere eventi futuri sulla base delle esperienze passate, adattando continuamente il proprio comportamento a un ambiente in costante mutamento.\nUn modello psicologico particolarmente influente che formalizza questo processo è il modello Rescorla-Wagner. Nato inizialmente per spiegare come gli animali apprendano ad associare segnali ambientali a specifiche conseguenze, questo modello si è rivelato utile anche per comprendere l’apprendimento umano. Esso mostra chiaramente come le persone aggiornino le proprie aspettative ogni volta che si trovano davanti a nuove informazioni o situazioni inattese, evidenziando un processo continuo di adattamento alle condizioni mutevoli dell’ambiente circostante.\n\n30.2.1 Il Modello Rescorla-Wagner e l’Adattamento all’Ambiente\nSecondo il modello Rescorla-Wagner, quando ci troviamo di fronte a situazioni nuove o imprevedibili, sviluppiamo aspettative su ciò che potrebbe accadere. Se queste aspettative vengono disattese (ad esempio, ricevendo una ricompensa diversa da quella prevista), sperimentiamo quello che il modello definisce “errore di previsione”. Questo errore, fondamentale per l’apprendimento, funge da meccanismo chiave per aggiornare rapidamente la nostra comprensione della realtà.\nFacciamo un esempio: immaginiamo un agente che, in un contesto in cui premere un pulsante genera solitamente una ricompensa (una moneta, una caramella, ecc.), si trovi improvvisamente a non riceverla più. L’errore di previsione generato da questa discrepanza modifica le aspettative dell’agente. Di conseguenza, nelle occasioni successive, le sue previsioni si adatteranno alla nuova realtà, riducendo la probabilità attesa della ricompensa.\nIl principale vantaggio del modello Rescorla-Wagner risiede nella sua essenzialità: basandosi su pochi principi fondamentali, riesce a descrivere in modo efficace come gli individui regolino le proprie aspettative in risposta a cambiamenti ambientali, garantendo un adattamento rapido e dinamico.\n\n30.2.2 Una Prospettiva Bayesiana sull’Apprendimento\nAnche se il modello di Rescorla-Wagner non nasce direttamente dal teorema di Bayes, può essere interpretato facilmente come un caso speciale di aggiornamento bayesiano. Il teorema di Bayes, infatti, descrive come dovremmo modificare razionalmente le nostre credenze alla luce di nuove evidenze. In psicologia, questa “evidenza” può essere pensata come la differenza tra ciò che ci aspettavamo e ciò che realmente accade—proprio come fa il modello Rescorla-Wagner.\nNella prospettiva bayesiana, le aspettative di una persona vengono considerate come “credenze” che vengono aggiornate costantemente sulla base delle nuove informazioni che emergono. Ogni volta che riceviamo un’informazione che contraddice le nostre aspettative iniziali, la nostra credenza viene rivista. Questo processo bayesiano permette di adattarsi in modo ottimale alle situazioni nuove o incerte, proprio come avviene con il modello Rescorla-Wagner (si veda l’esempio presentato nella Sezione 30.4).\nIn sintesi, il modello Rescorla-Wagner non solo rappresenta efficacemente come avviene l’apprendimento associativo nella vita quotidiana, ma fornisce anche un esempio pratico e intuitivo del ruolo del teorema di Bayes in psicologia: aiuta a capire come la nostra mente sia continuamente impegnata ad adattarsi razionalmente e rapidamente ai cambiamenti di un ambiente imprevedibile.\n\n30.2.3 Una Rivoluzione nel Pensiero Probabilistico\nPer comprendere appieno il teorema di Bayes, è necessario delineare le sue origini storiche. Nel XVIII secolo, Thomas Bayes (1701-1761), ecclesiastico presbiteriano e matematico britannico, pose le basi di una rivoluzione concettuale nel campo della probabilità e della statistica. Il suo contributo teorico, passato alla storia come teorema di Bayes, ha plasmato in modo decisivo lo sviluppo scientifico e tecnologico dei secoli successivi, influenzando discipline che spaziano dalla medicina all’intelligenza artificiale (Chivers, 2024).\n\n30.2.4 La Figura di Thomas Bayes\nBayes proveniva da una famiglia benestante e studiò teologia a Edimburgo, preparandosi al ministero religioso. Come ricorda il biografo David Bellhouse, Bayes non era un accademico nel senso moderno del termine, ma un erudito libero, interessato alla conoscenza per passione personale (Bellhouse, 2004).\nDurante la sua vita, Bayes pubblicò due testi:\n\n\nUn trattato di teologia: Divine Benevolence: Or, an Attempt to Prove that the Principal End of the Divine Providence and Government is the Happiness of His Creatures (1731), una teodicea che cerca di spiegare come la legge naturale possa ottimizzare il benessere universale.\n\n\nUna difesa del calcolo infinitesimale: An Introduction to the Doctrine of Fluxions (1736), in risposta alle critiche di George Berkeley sugli infinitesimi e i concetti fondamentali del calcolo newtoniano (Jesseph, 1993).\n\nIl lavoro che segnò la svolta nella teoria della probabilità fu però pubblicato postumo, nel 1763, sulle Philosophical Transactions of the Royal Society: An Essay towards Solving a Problem in the Doctrine of Chances. Per la prima volta, si formalizzava un metodo per aggiornare le ipotesi probabilistiche alla luce di nuove evidenze, ponendo le fondamenta dell’inferenza bayesiana (Stigler, 1990).\n\n30.2.5 Bayes e il Ruolo Culturale della Scienza\nCome sottolinea ancora Bellhouse, nel XVIII secolo era comune, tra le élite colte, dedicarsi allo studio di discipline scientifiche per prestigio sociale. Per Bayes, la matematica era dunque una passione coltivata con spirito libero. Il suo merito straordinario fu di spingere l’interpretazione della probabilità verso una prospettiva epistemologica innovativa, dove la probabilità diventa espressione quantitativa della nostra ignoranza sul mondo.\nIn contrapposizione alla visione “classica”, che vedeva la probabilità come frequenza osservabile in eventi ripetuti, Bayes propose che essa potesse rappresentare il grado di fiducia di un osservatore, inevitabilmente influenzato da conoscenze pregresse e da pregiudizi individuali. In questo senso, la probabilità assume un carattere dinamico e soggettivo, configurandosi come uno strumento di conoscenza che si aggiorna di continuo al variare dei dati (Spiegelhalter, 2019).\n\n30.2.5.1 Un Esperimento Mentale Illuminante\nPer illustrare la sua idea, Bayes propose un semplice esempio: immagina di lanciare alcune palline su un tavolo da biliardo. Dopo aver segnato con una linea il punto in cui si ferma una pallina bianca (e averla poi rimossa), si lanciano altre palline rosse e si conta quante cadono a destra e quante a sinistra di quella linea. Sulla base di queste osservazioni, come si può “indovinare” la posizione della linea? E con quale probabilità la prossima pallina rossa cadrà a sinistra di essa?\nLa soluzione di Bayes combina i dati osservati (numero di palline cadute a sinistra o a destra) con le convinzioni iniziali dell’osservatore (il cosiddetto “prior”), delineando un processo di apprendimento graduale che guida la revisione critica delle ipotesi.\n\n30.2.6 Il Ruolo di Richard Price\nDopo la morte di Bayes, fu un altro ecclesiastico, Richard Price (1723-1791), a dare impulso alla diffusione del saggio bayesiano. Price aveva un’ottima reputazione negli ambienti intellettuali dell’epoca, grazie anche alle sue relazioni con figure di spicco come Benjamin Franklin, Thomas Jefferson e John Adams.\nPrice prese in carico il manoscritto di Bayes, lo sottopose al fisico John Canton e ne curò la pubblicazione postuma, operando modifiche significative. Rispetto alla versione originale di Bayes, concentrata quasi esclusivamente sugli aspetti teorici, Price aggiunse una parte dedicata alle applicazioni pratiche, rendendo il testo più fruibile a un pubblico più ampio. Per questo motivo, lo storico Stephen Stigler lo definisce «il primo bayesiano della storia».\n\n30.2.7 Dal Silenzio alla Riscoperta\nPer oltre cinquant’anni, il lavoro di Bayes rimase in ombra, oscurato dall’opera pionieristica di Pierre-Simon Laplace. Già nel 1774, Laplace pervenne indipendentemente a principi analoghi, e successivamente li sistematizzò nella monumentale Théorie analytique des probabilités (1812). Solo in tempi più recenti, con l’avvento dei metodi di calcolo moderno e dell’informatica, la statura del teorema di Bayes è emersa in tutta la sua importanza.\nOggi, il teorema di Bayes è considerato un cardine della statistica moderna: formalizza il modo in cui aggiorniamo le nostre credenze alla luce di nuovi dati. Questo schema è cruciale in ogni disciplina scientifica e tecnologica che debba fare i conti con incertezza e dati incompleti. Dalla genomica all’econometria, dalla fisica delle particelle alle scienze cognitive, il paradigma bayesiano risulta prezioso per gestire e interpretare informazioni in continuo aggiornamento.\n\n30.2.8 L’Eredità di Bayes nell’Era Digitale\nNell’intelligenza artificiale, le idee bayesiane sono alla base di sistemi di apprendimento automatico e modelli probabilistici complessi. Strumenti come i moderni modelli linguistici (ad esempio ChatGPT e Claude) sfruttano strategie di inferenza bayesiana – anche se in forme estremamente avanzate – per generare risposte, fare previsioni e adattarsi costantemente agli input degli utenti.\nLa parabola storica di questo teorema, nato dalle speculazioni di un pastore presbiteriano del Settecento, mostra chiaramente il potenziale trasformativo delle idee matematiche. Come sottolinea Tom Chivers nel suo Everything Is Predictable: How Bayesian Statistics Explain Our World, la statistica bayesiana è diventata una sorta di “grammatica universale” per interpretare la realtà, permettendoci di affrontare con metodo situazioni complesse, modellare l’incertezza e formulare previsioni in contesti dove l’informazione è inevitabilmente limitata (Chivers, 2024).\nIn sintesi, la forza del teorema di Bayes non risiede soltanto nella sua eleganza formale, ma soprattutto nella sua portata epistemologica: esso traduce in termini matematici la nostra naturale tendenza ad apprendere da ciò che osserviamo e a rivedere continuamente ciò che crediamo. Per questo rimane, ancora oggi, un punto di riferimento fondamentale in qualunque disciplina che affronti il problema della conoscenza in condizioni di incertezza. ## La Regola di Bayes e l’inferenza probabilistica\nL’inferenza bayesiana utilizza un principio centrale della teoria delle probabilità noto come regola di Bayes. Questo principio consente di aggiornare in modo razionale le nostre credenze sulla base di nuovi dati osservati, integrandoli con conoscenze pregresse.\n\n30.2.9 Derivazione della Regola di Bayes\nConsideriamo due eventi casuali, \\(A\\) e \\(B\\). La probabilità congiunta \\(P(A, B)\\), ossia la probabilità che entrambi gli eventi accadano simultaneamente, può essere espressa in due modi equivalenti:\n\nTramite la regola della catena, possiamo scrivere: \\[\nP(A, B) = P(A \\mid B)P(B).\n\\] Qui, \\(P(A \\mid B)\\) è la probabilità condizionata che si verifichi l’evento \\(A\\) sapendo che l’evento \\(B\\) è avvenuto, mentre \\(P(B)\\) è la probabilità marginale di \\(B\\), indipendente da \\(A\\).\nUtilizzando la simmetria della probabilità congiunta, possiamo invertire gli eventi: \\[\nP(A, B) = P(B \\mid A)P(A).\n\\]\n\nDato che entrambe le espressioni rappresentano la stessa probabilità congiunta, possiamo eguagliarle:\n\\[\nP(A \\mid B)P(B) = P(B \\mid A)P(A).\n\\]\nRisolvendo per \\(P(B \\mid A)\\) otteniamo la regola di Bayes:\n\\[\nP(B \\mid A) = \\frac{P(A \\mid B) P(B)}{P(A)}.\n\\tag{30.1}\\]\n\n30.2.10 Interpretazione dei termini della regola di Bayes\nLa regola di Bayes permette di aggiornare la nostra credenza sulla probabilità di un’ipotesi o evento (\\(B\\)), dopo aver osservato un dato o evidenza (\\(A\\)):\n\n\n\\(P(B)\\) (prior): è la probabilità iniziale assegnata all’evento \\(B\\) prima di osservare il dato \\(A\\). Rappresenta la nostra conoscenza pregressa o il nostro grado iniziale di fiducia.\n\n\\(P(A \\mid B)\\) (verosimiglianza): è la probabilità di osservare il dato \\(A\\) nell’ipotesi che \\(B\\) sia vero. Indica quanto il dato sia compatibile con l’ipotesi.\n\n\\(P(B \\mid A)\\) (posterior): è la probabilità aggiornata, cioè la nostra nuova credenza sull’evento \\(B\\) dopo aver osservato il dato \\(A\\).\n\n\\(P(A)\\) (evidenza): è la probabilità marginale del dato osservato, calcolata sommando o integrando su tutte le possibili ipotesi alternative che potrebbero aver generato tale dato. Agisce da termine di normalizzazione per garantire che la somma delle probabilità a posteriori sia uguale a 1.\n\n30.2.11 Applicazioni della Regola di Bayes\nNella pratica, l’inferenza bayesiana si svolge tipicamente nel seguente modo:\n\nSi parte da uno spazio delle ipotesi \\(\\mathcal{H}\\), ovvero un insieme di tutte le possibili spiegazioni o modelli che potrebbero aver generato i dati osservati \\(D\\).\nA ciascuna ipotesi \\(H \\in \\mathcal{H}\\) viene assegnata una probabilità a priori \\(P(H)\\) che riflette la nostra fiducia iniziale.\nUna volta raccolti i dati \\(D\\), aggiorniamo le probabilità delle ipotesi usando la formula:\n\n\\[\nP(H \\mid D) = \\frac{P(D \\mid H) \\, P(H)}{P(D)},\n\\tag{30.2}\\]\ndove:\n\n\n\\(P(D \\mid H)\\) è la verosimiglianza, cioè la probabilità che l’ipotesi \\(H\\) abbia generato i dati \\(D\\);\n\n\\(P(D)\\) è la probabilità marginale (evidenza), calcolata considerando tutte le possibili ipotesi:\n\n\\[\nP(D) = \\sum_{H' \\in \\mathcal{H}} P(D \\mid H')P(H'),\n\\]\nnel caso discreto, oppure:\n\\[\nP(D) = \\int_{\\mathcal{H}} P(D \\mid H')P(H') \\, dH',\n\\]\nnel caso continuo.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_bayes_theorem.html#sec-bayes-message",
    "href": "chapters/probability/06_bayes_theorem.html#sec-bayes-message",
    "title": "30  Il teorema di Bayes",
    "section": "\n30.3 Esempio: Chi mi ha mandato un messaggio?",
    "text": "30.3 Esempio: Chi mi ha mandato un messaggio?\nImmagina di avere ricevuto un messaggio anonimo sul tuo cellulare con scritto solo “Ci vediamo stasera!”. Vuoi capire chi può essere stato a mandartelo. In questo esempio, il tuo “spazio delle ipotesi” sarà rappresentato da tre persone possibili:\n\n\nAlice\n\n\nBruno\n\nCarla\n\nQuindi, hai un insieme di ipotesi molto semplice:\n\\[\n\\mathcal{H} = \\{\\text{Alice},\\, \\text{Bruno},\\, \\text{Carla}\\} .\n\\]\n1. Probabilità a priori (prima di guardare i dati).\nSupponi che ciascuna persona abbia una probabilità diversa di scriverti:\n\n\nIpotesi\n\\(P(H)\\)\n\n\n\nAlice\n0.5\n\n\nBruno\n0.3\n\n\nCarla\n0.2\n\n\n\nQueste sono le tue probabilità a priori, basate sulla tua esperienza o conoscenza passata (ad esempio, Alice tende a scriverti spesso, Carla raramente).\n2. Come le ipotesi generano i dati (informazioni aggiuntive).\nOra raccogli alcune informazioni utili (i tuoi dati \\(D\\)):\n\nIl messaggio dice “Ci vediamo stasera!”.\n\nRifletti sul fatto che ciascuna delle tre persone usa questa frase con frequenze diverse (sai, ad esempio, che Alice usa spesso frasi brevi come questa, mentre Bruno e Carla la usano meno spesso, ovvero tendono a scrivere messaggi più lunghi):\n\n\n\n\n\n\nIpotesi\nProbabilità di inviare questa specifica frase (\\(P(D \\mid H)\\))\n\n\n\nAlice\n0.7\n\n\nBruno\n0.4\n\n\nCarla\n0.1\n\n\n\nQueste probabilità rappresentano il “meccanismo generatore dei dati”, ovvero come ciascuna persona (ipotesi) potrebbe generare proprio il messaggio che hai ricevuto.\n3. Aggiornamento delle probabilità a posteriori (dopo aver osservato il messaggio).\nOra applichiamo la formula di Bayes per aggiornare la nostra fiducia iniziale:\n\\[\nP(H \\mid D) = \\frac{P(D \\mid H) \\, P(H)}{P(D)} .\n\\]\nPrima calcoliamo la probabilità totale di ricevere quello specifico messaggio, indipendentemente da chi l’ha inviato. Usiamo il teorema della probabilità totale:\n\\[\nP(D) = P(D\\mid\\text{Alice})P(\\text{Alice}) + P(D\\mid\\text{Bruno})P(\\text{Bruno}) + P(D\\mid\\text{Carla})P(\\text{Carla}) .\n\\]\nCioè:\n\\[\nP(D) = (0.7 \\times 0.5) + (0.4 \\times 0.3) + (0.1 \\times 0.2)\n= 0.35 + 0.12 + 0.02\n= 0.49 .\n\\]\nOra aggiorniamo ciascuna ipotesi:\n\nAlice:\n\n\\[\nP(\\text{Alice}\\mid D) = \\frac{0.7\\times0.5}{0.49} = \\frac{0.35}{0.49} \\approx 0.714 .\n\\]\n\nBruno:\n\n\\[\nP(\\text{Bruno}\\mid D) = \\frac{0.4\\times0.3}{0.49} = \\frac{0.12}{0.49} \\approx 0.245 .\n\\]\n\nCarla:\n\n\\[\nP(\\text{Carla}\\mid D) = \\frac{0.1\\times0.2}{0.49} = \\frac{0.02}{0.49} \\approx 0.041 .\n\\]\n4. Interpretazione finale (intuizione bayesiana).\nDopo aver osservato il messaggio (“dati”), la tua fiducia si è aggiornata rispetto alle probabilità iniziali:\n\n\nIpotesi\nProbabilità a priori\nProbabilità a posteriori\n\n\n\nAlice\n0.5\n0.714\n\n\nBruno\n0.3\n0.245\n\n\nCarla\n0.2\n0.041\n\n\n\nOra credi molto più fortemente che sia stata Alice a scriverti.\nIn sintesi, in questo esempio semplice, lo spazio delle ipotesi era costituito da tre persone possibili. Ciascuna ipotesi poteva “generare” (cioè produrre o inviare) lo specifico messaggio che hai ricevuto con una diversa probabilità (“meccanismo generatore dei dati”). Prima dei dati avevi delle credenze su chi poteva averti scritto (“probabilità a priori”), poi lo specifico messaggio osservato (“i dati”) ha modificato le tue convinzioni (“probabilità a posteriori”), secondo la logica della Regola di Bayes.\nQuesto esempio chiarisce intuitivamente il significato di:\n\n\nspazio delle ipotesi (le possibili spiegazioni);\n\nmeccanismo generatore dei dati (la probabilità con cui ciascuna ipotesi produce il dato osservato);\n\naggiornamento bayesiano (come cambia la fiducia nelle ipotesi dopo aver visto i dati).\n\n\n30.3.1 Il Processo Iterativo dell’Aggiornamento Bayesiano\nL’inferenza bayesiana è intrinsecamente iterativa. Ogni volta che emergono nuovi dati, la distribuzione a posteriori \\(P(H \\mid D)\\) ottenuta diventa il nuovo prior per aggiornamenti successivi. Questo permette un affinamento continuo delle credenze, adattando la nostra comprensione del mondo in modo dinamico e coerente con le nuove evidenze.\n\n30.3.2 Considerazioni Pratiche\nSpesso, il calcolo diretto della probabilità marginale \\(P(D)\\) — corrispondente, nell’esempio illustrato nella Sezione 30.3, alla probabilità di osservare lo specifico messaggio ricevuto sul dispositivo mobile — risulta computazionalmente oneroso, in particolare quando lo spazio delle ipotesi è discreto o continuo di alta dimensionalità. Per ovviare a questa limitazione, vengono impiegati metodi numerici approssimativi come il Campionamento Monte Carlo o le inferenze variazionali, tecniche che permettono di stimare in modo efficiente tali grandezze probabilistiche anche in scenari reali complessi, senza ricorrere a calcoli analitici esatti.\nIn sintesi, la regola di Bayes fornisce uno schema formale e razionale per integrare informazioni pregresse con nuove osservazioni. Questa capacità di aggiornare continuamente le nostre credenze rappresenta il cuore del ragionamento probabilistico e rende l’approccio bayesiano uno strumento fondamentale in molte discipline scientifiche e applicazioni pratiche.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_bayes_theorem.html#sec-bayes-coin-hypotheses",
    "href": "chapters/probability/06_bayes_theorem.html#sec-bayes-coin-hypotheses",
    "title": "30  Il teorema di Bayes",
    "section": "\n30.4 Un Esempio Intuitivo: la Moneta Bilanciata o Truccata",
    "text": "30.4 Un Esempio Intuitivo: la Moneta Bilanciata o Truccata\nImmaginiamo questo scenario: sospettiamo che una moneta possa essere truccata e vogliamo verificarlo attraverso due lanci. Utilizzeremo il ragionamento bayesiano per combinare le nostre convinzioni iniziali con i dati osservati.\nLe Due Ipotesi.\nSupponiamo che la moneta possa essere:\n\n\nbilanciata (pari probabilità di Testa e Croce: 50% ciascuna);\n\ntruccata (sbilanciata, con probabilità di Testa del 80% e Croce del 20%).\n\nIl nostro obiettivo è capire quale ipotesi sia più plausibile dopo ogni lancio.\n\n30.4.1 Fase 1: Credenze Iniziali (Prior).\nPrima di lanciare la moneta, abbiamo una certa idea di quanto sia probabile ciascuna ipotesi:\n\\[\nP(\\text{Bilanciata}) = 0.85 \\quad\\text{e}\\quad P(\\text{Truccata}) = 0.15.\n\\]\nQueste probabilità rappresentano il prior, ovvero le nostre convinzioni iniziali prima di osservare qualunque risultato.\n\n30.4.2 Fase 2: Primo Lancio - Esce Testa\nLanciamo la moneta una volta e osserviamo il risultato: esce Testa.\nCi chiediamo: “Quanto è probabile osservare Testa se ciascuna delle due ipotesi fosse vera?”\n\nSe la moneta è bilanciata, la probabilità di osservare Testa è 0.5 (50%).\nSe la moneta è truccata, la probabilità di osservare Testa è 0.8 (80%).\n\nQueste due probabilità rappresentano la verosimiglianza:\n\\[\nP(\\text{Testa} \\mid \\text{Bilanciata}) = 0.5 \\quad\\text{e}\\quad P(\\text{Testa} \\mid \\text{Truccata}) = 0.8.\n\\]\nEvidenza: Probabilità Complessiva dell’Evento Osservato.\nVogliamo ora sapere quanto sia probabile osservare Testa in generale, considerando entrambe le ipotesi possibili. Per calcolarlo, usiamo la probabilità totale, che tiene conto di tutte le possibili ipotesi:\n\\[\nP(\\text{Testa}) = P(\\text{Testa} \\mid \\text{Bilanciata}) \\times P(\\text{Bilanciata}) + P(\\text{Testa} \\mid \\text{Truccata}) \\times P(\\text{Truccata}).\n\\]\nSostituiamo i valori numerici:\n\\[\nP(\\text{Testa}) = (0.5 \\times 0.85) + (0.8 \\times 0.15) = 0.425 + 0.12 = 0.545.\n\\]\nQuesta è la probabilità marginale o evidenza del risultato osservato.\nPosterior: Aggiornamento delle Credenze dopo l’Evidenza.\nOra possiamo usare il Teorema di Bayes per aggiornare le nostre credenze iniziali alla luce dell’evento osservato (Testa):\n\\[\n\\begin{aligned}\nP(\\text{Bilanciata} \\mid \\text{Testa}) &= \\frac{P(\\text{Testa} \\mid \\text{Bilanciata}) \\times P(\\text{Bilanciata})}{P(\\text{Testa})}\\notag\\\\\n&= \\frac{0.5 \\times 0.85}{0.545} \\notag\\\\\n&= 0.7798 \\quad (77.98\\%).\n\\end{aligned} \\notag\n\\]\n\\[\n\\begin{aligned}\nP(\\text{Truccata} \\mid \\text{Testa}) &= \\frac{P(\\text{Testa} \\mid \\text{Truccata}) \\times P(\\text{Truccata})}{P(\\text{Testa})} \\notag\\\\\n&= \\frac{0.8 \\times 0.15}{0.545} \\notag\\\\\n&= 0.2202 \\quad (22.02\\%). \\notag\n\\end{aligned}\n\\]\nInterpretazione Intuitiva.\nPrima del lancio, eravamo abbastanza sicuri (85%) che la moneta fosse bilanciata. Dopo aver osservato un singolo lancio che mostra Testa, questa certezza diminuisce (passa a circa 77.98%), mentre la probabilità che la moneta sia truccata aumenta (passa da 15% a circa 22.02%).\nQuesto esempio mostra come il prior, la verosimiglianza e l’evidenza si combinino nel ragionamento bayesiano per produrre un aggiornamento razionale e coerente delle credenze.\n\n30.4.3 Fase 3: Secondo Lancio - Esce Testa\nSupponiamo ora di lanciare la moneta una seconda volta, osservando ancora Testa. Usiamo le nuove probabilità ottenute (posterior) come prior aggiornati:\n\\[\nP(\\text{Bilanciata}) = 0.7798 \\quad\\text{e}\\quad P(\\text{Truccata}) = 0.2202.\n\\]\nCalcoliamo nuovamente l’evidenza:\n\\[\nP(\\text{Testa}) = (0.5 \\times 0.7798) + (0.8 \\times 0.2202) = 0.3899 + 0.1762 = 0.5661.\n\\]\nAggiorniamo quindi le credenze con il teorema di Bayes:\n\\[\nP(\\text{Bilanciata} \\mid \\text{Testa}) = \\frac{0.5 \\times 0.7798}{0.5661} = 0.6887 \\quad (68.87\\%).\n\\]\n\\[\nP(\\text{Truccata} \\mid \\text{Testa}) = \\frac{0.8 \\times 0.2202}{0.5661} = 0.3113 \\quad (31.13\\%).\n\\]\nInterpretazione del Secondo Aggiornamento.\nDopo il secondo lancio che mostra ancora Testa, la probabilità che la moneta sia bilanciata scende ulteriormente da 0.7798 a 0.6887, mentre la probabilità che la moneta sia truccata sale a 0.3113. Questo esempio mostra come l’aggiornamento bayesiano consenta di modificare progressivamente le nostre credenze, adattandole coerentemente a ogni nuova evidenza osservata.\n\n30.4.4 Applicazioni in Psicologia\nNegli ultimi anni, i modelli bayesiani hanno acquisito un ruolo centrale nello studio della cognizione umana, fornendo una struttura formale per comprendere come il cervello costruisca rappresentazioni del mondo e prenda decisioni sulla base di dati incerti. Come discusso da Griffiths et al. (2024), questi modelli sono stati applicati a una vasta gamma di processi cognitivi, tra cui:\n\n\nApprendimento e generalizzazione: i modelli bayesiani descrivono come gli individui apprendano nuove categorie e concetti sulla base di dati limitati e rumorosi (Tenenbaum, Griffiths, & Kemp, 2006).\n\nPercezione e interpretazione sensoriale: la percezione visiva e il riconoscimento di oggetti possono essere spiegati come un’inferenza bayesiana sulla base di segnali sensoriali ambigui (Domini & Caudek, 2003; Yuille & Kersten, 2006).\n\nControllo motorio: il sistema motorio umano sembra ottimizzare i movimenti attraverso una combinazione di modelli interni e aggiornamenti bayesiani (Kording & Wolpert, 2006).\n\nMemoria e recupero delle informazioni: i processi mnemonici, come il richiamo della memoria semantica, possono essere modellati come inferenze bayesiane basate su conoscenze pregresse (Steyvers, Griffiths, & Dennis, 2006).\n\nAcquisizione del linguaggio: l’apprendimento del linguaggio nei bambini può essere descritto attraverso processi probabilistici che permettono di inferire le strutture grammaticali sulla base di dati linguistici limitati (Chater & Manning, 2006; Xu & Tenenbaum, in press).\n\nApprendimento causale: la capacità di inferire relazioni causali dagli eventi osservati è coerente con un modello bayesiano, in cui la mente valuta la probabilità di una relazione causale sulla base dell’evidenza disponibile (Griffiths & Tenenbaum, 2005, 2007).\n\nRagionamento e decisione: il ragionamento simbolico e il processo decisionale possono essere formalizzati come un aggiornamento bayesiano delle credenze sulla base di nuove informazioni (Oaksford & Chater, 2001).\n\nCognizione sociale: le inferenze sulle intenzioni e credenze altrui possono essere modellate attraverso processi bayesiani, permettendo di spiegare come le persone comprendano il comportamento altrui (Baker, Tenenbaum, & Saxe, 2007).\n\n30.4.5 L’Inferenza Bayesiana nella Cognizione Umana\nUn tema centrale che emerge da questi programmi di ricerca è la seguente domanda: come fa la mente umana ad andare oltre i dati dell’esperienza? In altre parole, come riesce il cervello a costruire modelli complessi del mondo a partire da informazioni limitate e spesso ambigue?\nL’approccio bayesiano propone che il cervello utilizzi un processo di inferenza probabilistica per aggiornare continuamente le proprie credenze, combinando informazioni pregresse con nuove osservazioni per affinare le proprie rappresentazioni mentali. Questo meccanismo consente di spiegare molte delle capacità cognitive umane, dall’apprendimento rapido di nuove categorie alla capacità di adattarsi a un ambiente mutevole, fino alla formulazione di inferenze sociali e alla presa di decisioni in condizioni di incertezza (si veda la Sezione 30.2).\nL’adozione dei modelli bayesiani nella psicologia cognitiva ha portato a una nuova comprensione della mente come sistema predittivo, in grado di formulare ipotesi probabilistiche sugli eventi futuri e di correggerle dinamicamente sulla base dell’esperienza. Questo approccio ha profonde implicazioni per lo studio del comportamento umano e per lo sviluppo di nuove tecniche di modellizzazione nei campi della psicologia, delle neuroscienze e dell’intelligenza artificiale.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_bayes_theorem.html#test-medici",
    "href": "chapters/probability/06_bayes_theorem.html#test-medici",
    "title": "30  Il teorema di Bayes",
    "section": "\n30.5 Test Medici",
    "text": "30.5 Test Medici\nUno degli esempi più comuni per comprendere il teorema di Bayes riguarda i test diagnostici.\n\nEsempio 30.1 Consideriamo un test di mammografia utilizzato per diagnosticare il cancro al seno che abbiamo già discusso nel Capitolo 29. Definiamo le seguenti ipotesi:\n\n\n\\(M^+\\): la persona ha il cancro al seno;\n\n\\(M^-\\): la persona non ha il cancro al seno.\n\nL’evidenza è il risultato positivo del test, indicato con \\(T^+\\). Il nostro obiettivo è calcolare la probabilità che una persona abbia il cancro al seno, dato un risultato positivo al test, ovvero \\(P(M^+ \\mid T^+)\\).\nDefinizione dei termini nella regola di Bayes.\nIl teorema di Bayes afferma che:\n\\[\nP(M^+ \\mid T^+) = \\frac{P(T^+ \\mid M^+) P(M^+)}{P(T^+)} ,\n\\]\ndove:\n\n\n\\(P(T^+ \\mid M^+)\\) è la sensibilità del test, cioè la probabilità che il test risulti positivo se la persona ha effettivamente il cancro. Nel nostro caso, \\(P(T^+ \\mid M^+) = 0.90\\).\n\n\\(P(M^+)\\) è la probabilità a priori di avere il cancro al seno, ovvero la prevalenza della malattia nella popolazione. Supponiamo che sia \\(P(M^+) = 0.01\\) (1%).\n\n\\(P(T^+ \\mid M^-)\\) è la probabilità di un falso positivo, cioè la probabilità che il test risulti positivo anche in assenza di malattia. Questa è complementare alla specificità del test:\n\n\\[\n  P(T^+ \\mid M^-) = 1 - \\text{Specificità} = 1 - 0.90 = 0.10.\n\\]\n\n\n\\(P(M^-)\\) è la probabilità a priori che una persona non abbia il cancro, ovvero:\n\n\\[\n  P(M^-) = 1 - P(M^+) = 1 - 0.01 = 0.99.\n\\]\n\n\n\\(P(T^+)\\) è la probabilità marginale che il test risulti positivo, calcolata considerando entrambe le possibilità (cioè che la persona abbia o non abbia il cancro):\n\n\\[\n  P(T^+) = P(T^+ \\mid M^+) P(M^+) + P(T^+ \\mid M^-) P(M^-).\n\\]\nSostituendo i valori numerici:\n\\[\n  P(T^+) = (0.90 \\cdot 0.01) + (0.10 \\cdot 0.99) = 0.009 + 0.099 = 0.108.\n\\]\nApplicazione della Regola di Bayes.\nOra possiamo calcolare la probabilità a posteriori \\(P(M^+ \\mid T^+)\\):\n\\[\nP(M^+ \\mid T^+) = \\frac{0.90 \\cdot 0.01}{0.108} = \\frac{0.009}{0.108} = 0.0833.\n\\]\nInterpretazione del Risultato.\nQuesto risultato indica che, nonostante il test abbia una sensibilità e una specificità del 90%, la probabilità che una persona con un test positivo abbia effettivamente il cancro è solo dell’8.3%. Questo effetto è dovuto alla bassa prevalenza della malattia: anche se il test è relativamente accurato, il numero di falsi positivi è ancora alto rispetto ai veri positivi. Tale risultato conferma quanto precedentemente ottenuto nel Capitolo 29, attraverso un metodo di calcolo alternativo.\nQuesta formulazione mostra come la regola di Bayes permetta di aggiornare la probabilità di avere la malattia dopo aver osservato il risultato del test, combinando la sensibilità, la specificità e la prevalenza della malattia nella popolazione.\n\n\n30.5.1 Affidabilità di un Test HIV e Aggiornamento Bayesiano\nVogliamo valutare l’affidabilità di un test per l’HIV e capire come la nostra stima di infezione cambia dopo due test consecutivi positivi. Utilizzeremo la regola di Bayes per aggiornare la probabilità di avere l’HIV man mano che otteniamo nuovi risultati.\n\nEsempio 30.2 Immaginiamo che una persona esegua due volte un test per l’HIV.\nNotazione e dati iniziali.\nIndichiamo con:\n\n\n\\(M^+\\): la persona ha l’HIV;\n\n\\(M^-\\): la persona non ha l’HIV;\n\n\\(T^+\\): il test è positivo;\n\n\\(T^-\\): il test è negativo.\n\nAbbiamo inoltre i seguenti dati:\n\nPrevalenza (probabilità a priori di avere l’HIV):\\[\nP(M^+) = 0.003 \\quad (0.3\\%).\n\\]\nSensibilità del test (probabilità che il test sia positivo se la persona è malata):\\[\nP(T^+ \\mid M^+) = 0.95.\n\\]\nSpecificità del test (probabilità che il test sia negativo se la persona è sana):\\[\nP(T^- \\mid M^-) = 0.9928 \\quad \\Longrightarrow \\quad P(T^+ \\mid M^-) = 0.0072.\n\\]\n\nPasso 1: dopo il primo test positivo.\nUsiamo la regola di Bayes per aggiornare la probabilità di essere malati, dopo un primo risultato positivo:\n\\[\nP(M^+ \\mid T^+) = \\frac{P(T^+ \\mid M^+)P(M^+)}{P(T^+)}.\n\\]\nCalcoliamo la probabilità marginale di un test positivo, considerando entrambe le ipotesi:\n\\[\nP(T^+) = P(T^+ \\mid M^+)P(M^+) + P(T^+ \\mid M^-)P(M^-).\n\\]\nSostituendo i valori noti, otteniamo:\n\\[\nP(T^+) = (0.95 \\times 0.003) + (0.0072 \\times 0.997) = 0.00285 + 0.00718 = 0.01003.\n\\]\nLa probabilità aggiornata (posterior) diventa quindi:\n\\[\nP(M^+ \\mid T^+) = \\frac{0.00285}{0.01003} \\approx 0.2844 \\quad (28.44\\%).\n\\]\nDopo un primo test positivo, la probabilità che la persona sia effettivamente HIV-positiva sale da un valore iniziale molto basso (0.3%) a 28.44%, aumentando notevolmente ma senza ancora garantire la certezza.\nPasso 2: aggiornamento dopo un secondo test positivo.\nAdesso immaginiamo di ripetere il test e ottenere nuovamente un risultato positivo. La nuova probabilità si calcola applicando ancora la regola di Bayes, utilizzando come prior il risultato appena trovato:\n\\[\nP(M^+ \\mid T_1^+, T_2^+) = \\frac{P(T_2^+ \\mid M^+, T_1^+)P(M^+ \\mid T_1^+)}{P(T_2^+ \\mid T_1^+)}.\n\\]\nAssumendo che i risultati dei test siano indipendenti dato lo stato di malattia o meno, possiamo semplificare:\n\n\\(P(T_2^+ \\mid M^+, T_1^+) = P(T^+ \\mid M^+) = 0.95\\)\n\\(P(T_2^+ \\mid M^-, T_1^+) = P(T^+ \\mid M^-) = 0.0072\\)\n\nLa probabilità di ottenere un secondo test positivo diventa quindi:\n\\[\nP(T_2^+ \\mid T_1^+) = P(T^+ \\mid M^+)P(M^+ \\mid T_1^+) + P(T^+ \\mid M^-)P(M^- \\mid T_1^+).\n\\]\nSostituendo i valori numerici calcolati in precedenza:\n\\[\nP(T_2^+ \\mid T_1^+) = (0.95 \\times 0.2844) + (0.0072 \\times 0.7156) = 0.2702 + 0.00515 = 0.27535.\n\\]\nOra calcoliamo la nuova probabilità a posteriori dopo due test positivi:\n\\[\nP(M^+ \\mid T_1^+, T_2^+) = \\frac{0.95 \\times 0.2844}{0.27535} \\approx 0.981 \\quad (98.1\\%).\n\\]\nInterpretazione finale.\n\nDopo il primo test positivo, la probabilità passa dallo 0.3% iniziale a circa il 28.44%, aumentando notevolmente ma restando incerta.\nDopo il secondo test positivo, la probabilità sale drasticamente al 98.1%, rendendo quasi certa la diagnosi.\n\nQuesto esempio dimostra chiaramente il valore dell’aggiornamento bayesiano: un singolo risultato positivo incrementa la probabilità, ma in presenza di una bassa prevalenza non basta per una diagnosi certa. Ripetere il test e ottenere conferme successive permette invece di raggiungere una certezza diagnostica molto elevata.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_bayes_theorem.html#la-fallacia-del-procuratore-e-il-teorema-di-bayes",
    "href": "chapters/probability/06_bayes_theorem.html#la-fallacia-del-procuratore-e-il-teorema-di-bayes",
    "title": "30  Il teorema di Bayes",
    "section": "\n30.6 La Fallacia del Procuratore e il Teorema di Bayes",
    "text": "30.6 La Fallacia del Procuratore e il Teorema di Bayes\nIl teorema di Bayes non trova applicazione solo in campo medico, ma è essenziale anche nei procedimenti giudiziari. Infatti, fraintendimenti nell’interpretazione di probabilità e statistiche possono portare a gravi errori di giudizio. Uno degli errori più comuni in questo contesto è la fallacia del procuratore.\n\n30.6.1 Che cos’è la Fallacia del Procuratore?\nLa fallacia del procuratore consiste nel confondere la probabilità di osservare una certa evidenza se una persona è innocente, \\(P(T^+ \\mid I)\\), con la probabilità che una persona sia innocente dopo aver osservato quella evidenza, \\(P(I \\mid T^+)\\).\n\nIn termini giudiziari, questo equivale a dire: “Poiché è estremamente improbabile ottenere un certo riscontro (ad es. un test positivo) se la persona è innocente, allora è estremamente improbabile che la persona sia innocente se si è ottenuto un esito positivo”.\nIn realtà, per stabilire se la persona è innocente o colpevole dopo aver visto il risultato, occorre considerare sia la bassa frequenza delle persone effettivamente colpevoli nella popolazione (prevalenza) sia la possibilità di falsi positivi. Il teorema di Bayes fornisce lo strumento formale per integrare questi elementi.\n\n30.6.2 Esempio di Test del DNA\nSupponiamo di utilizzare un test del DNA per identificare un sospetto tra 65 milioni di persone. Il test ha:\n\n\nSensibilità (\\(P(T^+ \\mid C)\\)) = 99%\\(\\rightarrow\\) Se la persona è effettivamente colpevole, il test risulta positivo il 99% delle volte.\n\nSpecificità (\\(P(T^- \\mid I)\\)) = 99.99997%\\(\\rightarrow\\) Se la persona è innocente, il test risulta negativo il 99.99997% delle volte.\nDa cui segue che il tasso di falso positivo è \\(1 - 0.9999997 = 0.0000003 = 0.00003\\%\\).\n\nPrevalenza (\\(P(C)\\)) = \\(1/65{,}000{,}000 \\approx 1.54 \\times 10^{-8}\\)\\(\\rightarrow\\) Un individuo scelto a caso ha una probabilità di circa \\(1.54 \\times 10^{-8}\\) (cioè 1 su 65 milioni) di essere il vero colpevole.\n\nUn campione di DNA coincide con quello di una persona trovata nel database e il test dà risultato positivo. Qual è la probabilità che costui sia davvero colpevole? Formalmente, vogliamo \\(P(C \\mid T^+)\\).\nPasso 1: Calcolare \\(P(T^+)\\), la probabilità di un test positivo.\nLa probabilità complessiva di un esito positivo deriva da due scenari alternativi:\n\n\nLa persona è colpevole e il test è positivo:\\(P(T^+ \\mid C) \\times P(C)\\).\n\nLa persona è innocente e il test è positivo per errore (falso positivo):\\(P(T^+ \\mid I) \\times P(I)\\).\n\nPerciò, usando la regola della probabilità totale:\n\\[\nP(T^+)\n= P(T^+ \\mid C) \\, P(C) \\;+\\; P(T^+ \\mid I) \\, P(I).\n\\]\nAssegniamo i valori numerici:\n\n\n\\(P(T^+ \\mid C) = 0.99\\) (sensibilità).\n\n\\(P(C) = 1.54 \\times 10^{-8}\\).\n\n\\(P(T^+ \\mid I) = 1 - P(T^- \\mid I) = 1 - 0.9999997 = 0.0000003\\).\n\n\\(P(I) = 1 - P(C) \\approx 0.99999998\\).\n\nEseguiamo il calcolo:\n\\[\n\\begin{aligned}\nP(T^+)\n&= (0.99 \\times 1.54 \\times 10^{-8}) + (0.0000003 \\times 0.99999998)\\\\\n&= 1.5231 \\times 10^{-8} + 2.9999994 \\times 10^{-7}\\\\\n&= 3.1523 \\times 10^{-7}.\n\\end{aligned}\n\\]\nPasso 2: Applicare la regola di Bayes per \\(P(C \\mid T^+)\\).\nOra possiamo calcolare la probabilità di essere colpevoli dato che il test è positivo:\n\\[\nP(C \\mid T^+)\n= \\frac{P(T^+ \\mid C)\\,P(C)}{P(T^+)}.\n\\]\nInseriamo i valori:\n\\[\n\\begin{aligned}\nP(C \\mid T^+)\n&= \\frac{(0.99 \\times 1.54 \\times 10^{-8})}{3.1523 \\times 10^{-7}}\\\\\n&= \\frac{1.5231 \\times 10^{-8}}{3.1523 \\times 10^{-7}}\\\\\n&\\approx 0.0483 \\quad (\\text{cioè } 4.83\\%).\n\\end{aligned}\n\\]\nInterpretazione: perché è “solo” il 4.83%?\nSebbene sensibilità e specificità del test siano entrambe molto alte, la prevalenza estremamente bassa del colpevole (1 su 65 milioni) riduce notevolmente la probabilità a posteriori \\(P(C \\mid T^+)\\). In una popolazione di 65 milioni di individui, anche un esiguo tasso di falsi positivi (\\(0.0000003\\)) genera un numero assoluto di risultati positivi fra gli innocenti molto più grande del numero di colpevoli reali.\nIn pratica, pur avendo un test positivo, la probabilità che la persona sia davvero colpevole resta modesta (circa 4.83%), perché i “falsi allarmi” nella massa di individui innocenti superano di gran lunga i (pochi) veri positivi.\n\n30.6.3 Evitare la Fallacia del Procuratore\nLa fallacia del procuratore consiste nel confondere:\n\n\n\\(P(T^+ \\mid I)\\): la probabilità che un innocente risulti positivo (falso positivo),\n\n\\(P(I \\mid T^+)\\): la probabilità di essere innocenti dopo un test positivo.\n\nQuesta confusione porta a sovrastimare la colpevolezza di un individuo basandosi su una singola evidenza statistica. Applicando il teorema di Bayes, invece, si comprende che un test positivo non implica automaticamente colpevolezza, soprattutto quando la malattia (o il reato, in questo caso) è molto raro. Nei processi giudiziari, ciò significa che un dato probabilistico deve sempre essere contestualizzato alla popolazione di riferimento: la corretta interpretazione delle prove è fondamentale per evitare errori giudiziari.\n\n30.6.3.1 Conclusione Epistemologica\nL’impiego di test probabilistici in ambito giudiziario richiede un’applicazione rigorosa del teorema di Bayes per evitare distorsioni interpretative. Solo un corretto aggiornamento delle credenze, integrando:\n\n\nla probabilità pre-test (\\(P(C)\\), prevalenza del colpevole nella popolazione investigata),\n\n\nla potenza diagnostica del test (sensibilità e specificità),\n\n\nil tasso di errore strumentale (falsi positivi e falsi negativi),\n\nconsente di ridurre il rischio di errori giudiziari sistematici. In assenza di questa integrazione, anche test estremamente precisi possono condurre a ingiuste condanne, trasformando strumenti scientifici affidabili in fonti di distorsione probatoria.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_bayes_theorem.html#probabilità-inversa-dal-problema-classico-allinferenza-bayesiana",
    "href": "chapters/probability/06_bayes_theorem.html#probabilità-inversa-dal-problema-classico-allinferenza-bayesiana",
    "title": "30  Il teorema di Bayes",
    "section": "\n30.7 Probabilità Inversa: Dal Problema Classico all’Inferenza Bayesiana",
    "text": "30.7 Probabilità Inversa: Dal Problema Classico all’Inferenza Bayesiana\nGli esempi precedenti mostrano due tipi di domande probabilistiche fondamentali:\n\n\nProbabilità diretta\n\n“Qual è la probabilità di osservare un certo risultato, supponendo che l’ipotesi sia vera?”\n\n\n\nProbabilità inversa\n\n“Qual è la probabilità che un’ipotesi sia vera, dati i risultati osservati?”\n\n\n\nQuesta distinzione è cruciale per comprendere il teorema di Bayes e le differenze tra l’approccio frequentista e quello bayesiano alla probabilità.\n\n30.7.1 Esempi di Probabilità Diretta e Inversa\nPrendiamo come esempio il lancio di una moneta:\n\nProbabilità diretta:\nSe riteniamo che la moneta sia equa (cioè \\(P(\\text{Testa}) = 0{.}5\\)), qual è la probabilità di osservare zero teste in cinque lanci? In questo caso, stiamo calcolando \\[\nP(D \\mid H) = (0.5)^5 = 0.03125,\n\\] dove \\(D\\) rappresenta il dato (“zero teste in cinque lanci”) e \\(H\\) l’ipotesi (“la moneta è equa”).\nProbabilità inversa:\nOra poniamo la domanda opposta. Abbiamo lanciato una moneta cinque volte e osservato zero teste. Quanto è probabile che la moneta sia davvero equa?\nQui vogliamo conoscere \\(\\displaystyle P(H \\mid D)\\) (l’ipotesi “la moneta è equa” dopo aver visto il risultato) anziché \\(P(D \\mid H)\\). Per rispondere correttamente, ci occorre il teorema di Bayes, che combina la probabilità dei dati (\\(P(D \\mid H)\\)) con una stima iniziale (il prior) su quanto riteniamo probabile l’ipotesi prima dell’osservazione.\n\n30.7.2 Dalla Probabilità Diretta alla Probabilità Inversa: Il Contributo di Bayes\nPer lungo tempo, la teoria della probabilità si è occupata quasi esclusivamente di probabilità diretta: “se l’ipotesi è vera, qual è la probabilità di osservare un certo esito?”.\nNel XVIII secolo, Thomas Bayes capovolse la prospettiva, concentrandosi su come determinare la probabilità dell’ipotesi a partire dalle evidenze disponibili, introdusse cioè l’idea di probabilità inversa. Questa svolta ha aperto la strada a ciò che oggi chiamiamo inferenza bayesiana, permettendo di aggiornare in modo sistematico e rigoroso la credibilità di un’ipotesi dopo aver osservato nuovi dati.\n\n30.7.3 L’Impatto della Probabilità Inversa\nLa possibilità di stimare \\(\\displaystyle P(H \\mid D)\\), cioè la probabilità di un’ipotesi data l’evidenza osservata, si è rivelata fondamentale in molti ambiti:\n\n\nScienza e sperimentazione: quanto è probabile che un’ipotesi sia vera dopo aver raccolto i dati di un esperimento?\n\n\nMedicina: quanto è probabile che un paziente abbia una certa malattia, se il test diagnostico è positivo?\n\n\nGiustizia: quanto è probabile che una persona sia colpevole, se il DNA trovato sulla scena del crimine combacia col suo?\n\nIn tutti questi casi non basta calcolare la probabilità dei dati “dato un’ipotesi” \\(\\bigl(P(D \\mid H)\\bigr)\\); occorre invece aggiornare la stima della probabilità dell’ipotesi alla luce dei dati \\(\\bigl(P(H \\mid D)\\bigr)\\).\nIn sintesi, l’inferenza bayesiana risponde appunto a questa seconda domanda, passando dalla probabilità diretta alla probabilità inversa in modo rigoroso. Grazie al teorema di Bayes, possiamo combinare in modo coerente le nostre conoscenze pregresse (il cosiddetto prior) con le evidenze raccolte, ottenendo una probabilità a posteriori che rappresenta la nostra nuova convinzione. Senza questa prospettiva, gran parte dei problemi scientifici e delle decisioni pratiche resterebbe priva di un metodo per collegare razionalmente le evidenze empiriche alle ipotesi da verificare.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_bayes_theorem.html#riflessioni-conclusive",
    "href": "chapters/probability/06_bayes_theorem.html#riflessioni-conclusive",
    "title": "30  Il teorema di Bayes",
    "section": "\n30.8 Riflessioni Conclusive",
    "text": "30.8 Riflessioni Conclusive\nIn questo capitolo abbiamo esplorato vari esempi, principalmente nel campo medico e forense, per illustrare come il teorema di Bayes permetta di combinare le informazioni derivate dalle osservazioni con le conoscenze precedenti (priori), aggiornando così il nostro grado di convinzione rispetto a un’ipotesi. Il teorema di Bayes fornisce un meccanismo razionale, noto come “aggiornamento bayesiano”, che ci consente di ricalibrare le nostre convinzioni iniziali alla luce di nuove evidenze.\nUna lezione fondamentale che il teorema di Bayes ci insegna, sia nella ricerca scientifica che nella vita quotidiana, è che spesso non ci interessa tanto conoscere la probabilità che qualcosa accada assumendo vera un’ipotesi, quanto piuttosto la probabilità che un’ipotesi sia vera, dato che abbiamo osservato una certa evidenza. In altre parole, la forza del teorema di Bayes sta nella sua capacità di affrontare direttamente il problema inverso, cioè come dedurre la verità di un’ipotesi a partire dalle osservazioni.\nIl framework bayesiano per l’inferenza probabilistica offre un approccio generale per comprendere come i problemi di induzione possano essere risolti in linea di principio e, forse, anche come possano essere affrontati dalla mente umana.\nIn questo capitolo ci siamo concentrati sull’applicazione del teorema di Bayes utilizzando probabilità puntuali. Tuttavia, il teorema esprime pienamente il suo potenziale quando sia l’evidenza che i gradi di certezza a priori delle ipotesi sono rappresentati attraverso distribuzioni di probabilità continue. Questo sarà l’argomento centrale nella prossima sezione della dispensa, dove approfondiremo il flusso di lavoro bayesiano e l’uso di distribuzioni continue nell’aggiornamento bayesiano.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_bayes_theorem.html#esercizi",
    "href": "chapters/probability/06_bayes_theorem.html#esercizi",
    "title": "30  Il teorema di Bayes",
    "section": "\n30.9 Esercizi",
    "text": "30.9 Esercizi\nÈ facile trovare online esercizi sull’applicazione del teorema di Bayes. Ad esempio, consiglio gli esercizi da 1 a 6 disponibili sulla seguente pagina web.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_bayes_theorem.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/06_bayes_theorem.html#informazioni-sullambiente-di-sviluppo",
    "title": "30  Il teorema di Bayes",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.7   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.13.0 psych_2.5.3     \n#&gt;  [9] scales_1.4.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.3.0     ggplot2_3.5.2   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.4     stringi_1.8.7      lattice_0.22-7    \n#&gt;  [4] hms_1.1.3          digest_0.6.37      magrittr_2.0.3    \n#&gt;  [7] evaluate_1.0.4     grid_4.5.0         timechange_0.3.0  \n#&gt; [10] RColorBrewer_1.1-3 fastmap_1.2.0      rprojroot_2.0.4   \n#&gt; [13] jsonlite_2.0.0     mnormt_2.1.1       cli_3.6.5         \n#&gt; [16] rlang_1.1.6        withr_3.0.2        tools_4.5.0       \n#&gt; [19] parallel_4.5.0     tzdb_0.5.0         pacman_0.5.1      \n#&gt; [22] vctrs_0.6.5        R6_2.6.1           lifecycle_1.0.4   \n#&gt; [25] htmlwidgets_1.6.4  pkgconfig_2.0.3    pillar_1.10.2     \n#&gt; [28] gtable_0.3.6       glue_1.8.0         xfun_0.52         \n#&gt; [31] tidyselect_1.2.1   rstudioapi_0.17.1  farver_2.1.2      \n#&gt; [34] htmltools_0.5.8.1  nlme_3.1-168       rmarkdown_2.29    \n#&gt; [37] compiler_4.5.0",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_bayes_theorem.html#bibliografia",
    "href": "chapters/probability/06_bayes_theorem.html#bibliografia",
    "title": "30  Il teorema di Bayes",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBaker, C., Saxe, R., & Tenenbaum, J. (2011). Bayesian theory of mind: Modeling joint belief-desire attribution. Proceedings of the annual meeting of the cognitive science society, 33.\n\n\nBellhouse, D. R. (2004). The Reverend Thomas Bayes, FRS: a biography to celebrate the tercentenary of his birth.\n\n\nCaudek, C., & Bruno, N. (2024). Fenomeni stereocinetici, teorie della percezione e sociologia della scienza. Giornale italiano di psicologia, 51(3), 451–466.\n\n\nChivers, T. (2024). Everything is Predictable: How Bayesian Statistics Explain Our World. Simon; Schuster.\n\n\nDomini, F., & Caudek, C. (2003). 3-D structure perceived from dynamic information: A new theory. Trends in Cognitive Sciences, 7(10), 444–449.\n\n\nGriffiths, T. L., Chater, N., & Tenenbaum, J. B. (2024). Bayesian models of cognition: reverse engineering the mind. MIT Press.\n\n\nJesseph, D. M. (1993). Berkeley’s philosophy of mathematics. University of Chicago Press.\n\n\nMa, W. J., Kording, K. P., & Goldreich, D. (2023). Bayesian models of perception and action: An introduction. MIT press.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:\n\n\nSpiegelhalter, D. (2019). The art of statistics: Learning from data. Penguin UK.\n\n\nStigler, S. M. (1990). The history of statistics: The measurement of uncertainty before 1900. Harvard University Press.\n\n\nYuille, A., & Kersten, D. (2006). Vision as Bayesian inference: analysis by synthesis? Trends in cognitive sciences, 10(7), 301–308.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_random_var.html",
    "href": "chapters/probability/07_random_var.html",
    "title": "31  Variabili casuali",
    "section": "",
    "text": "31.1 Introduzione\nFino ad ora abbiamo studiato le probabilità associate a eventi, come la possibilità di vincere il gioco di Monty Hall o di avere una rara condizione medica in seguito a un test positivo. Tuttavia, in molte situazioni pratiche vogliamo conoscere aspetti più dettagliati. Ad esempio, potremmo chiederci:\nPer rispondere a tali domande è necessario lavorare con le variabili casuali. In questo capitolo introdurremo il concetto di variabile casuale e ne analizzeremo le proprietà fondamentali.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_random_var.html#introduzione",
    "href": "chapters/probability/07_random_var.html#introduzione",
    "title": "31  Variabili casuali",
    "section": "",
    "text": "quanti tentativi occorrono affinché, in un gioco simile a Monty Hall, un concorrente vinca?\nquanto durerà un determinato evento o condizione?\nqual è la perdita attesa giocando d’azzardo con un dado sbilanciato per molte ore?",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_random_var.html#definizione-di-variabile-casuale",
    "href": "chapters/probability/07_random_var.html#definizione-di-variabile-casuale",
    "title": "31  Variabili casuali",
    "section": "\n31.2 Definizione di Variabile Casuale",
    "text": "31.2 Definizione di Variabile Casuale\nUna variabile casuale è una funzione che associa ogni elemento di uno spazio campionario a un valore numerico. Questo strumento permette di trasformare esiti qualitativi (ad esempio, il risultato di un lancio di carte, come cuori, quadri, fiori, picche) in valori numerici, facilitando così l’analisi matematica.\n\nDefinizione 31.1 Sia \\(S\\) lo spazio campionario di un esperimento aleatorio. Una variabile casuale \\(X\\) è una funzione\\[\nX: S \\longrightarrow \\mathbb{R},\n\\] che associa ad ogni esito \\(s \\in S\\) un numero reale \\(X(s)\\).\n\n\nEsempio 31.1 Lanciamo due dadi equilibrati e annotiamo la somma dei valori delle loro facce. Ogni lancio genera una coppia di valori \\((i,j)\\), dove \\(i\\) è il risultato del primo dado e \\(j\\) il risultato del secondo dado. Lo spazio campionario completo dei possibili esiti è:\n\\[\n\\Omega = \\{(1,1), (1,2), \\dots, (6,5), (6,6)\\}.\n\\]\nDefiniamo una variabile casuale \\(X\\) che associa ciascun esito \\((i,j)\\) alla somma dei valori ottenuti dai due dadi, cioè:\n\\[\nX(i,j) = i + j.\n\\]\nAd esempio, se il primo dado mostra 4 e il secondo dado mostra 4, allora l’esito è \\((4,4)\\) e la variabile casuale \\(X\\) assume il valore 8.\n\n\nLa variabile aleatoria \\(X\\) rappresenta la somma di due dadi (figura tratta da Chan & Kroese, 2025).\n\nConsideriamo il valore specifico \\(X=8\\): questo valore può essere ottenuto attraverso cinque diversi esiti dello spazio campionario: \\((2,6), (3,5), (4,4), (5,3), (6,2)\\). Indichiamo con \\(\\{X=8\\}\\) l’insieme di questi esiti. Poiché tutti gli esiti in \\(\\Omega\\) sono equiprobabili, possiamo calcolare la probabilità di ottenere una somma pari a 8 come:\n\\[\nP(X=8) = \\frac{5}{36}.\n\\]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_random_var.html#tipologie-di-variabili-casuali",
    "href": "chapters/probability/07_random_var.html#tipologie-di-variabili-casuali",
    "title": "31  Variabili casuali",
    "section": "\n31.3 Tipologie di Variabili Casuali",
    "text": "31.3 Tipologie di Variabili Casuali\nLe variabili casuali si dividono in due categorie principali:\n\n31.3.1 Variabili Casuali Discrete\nUna variabile casuale discreta assume un insieme finito o numerabile di valori. Gli esempi includono il numero di teste ottenute in lanci di moneta o la somma dei risultati di due dadi. Per queste variabili, la funzione di massa di probabilità (PMF) assegna a ciascun valore \\(x\\) la probabilità \\(P(X = x)\\).\n\nEsempio 31.2 Nel lancio di due dadi, la variabile \\(X\\) (somma dei punti) può assumere valori interi da 2 a 12. La distribuzione di \\(X\\) si ottiene contando i casi favorevoli per ciascun valore e dividendo per il numero totale di esiti (36).\n\n\n31.3.2 Variabili Casuali Continue\nUna variabile casuale continua può assumere infiniti valori in un intervallo (ad esempio, l’altezza di una persona). In questo caso non si assegna una probabilità a un singolo valore (che risulterebbe essere zero), ma si definisce una funzione di densità di probabilità (PDF), tale che l’integrale della funzione su un intervallo fornisce la probabilità che la variabile cada in quell’intervallo.\n\nEsempio 31.3 Considera una variabile \\(X\\) che rappresenta l’altezza in centimetri. Invece di \\(P(X = 170)\\), calcoliamo probabilità come \\(P(170 \\leq X \\leq 180)\\) mediante l’integrale della PDF in quell’intervallo.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_random_var.html#notazione-convenzionale",
    "href": "chapters/probability/07_random_var.html#notazione-convenzionale",
    "title": "31  Variabili casuali",
    "section": "\n31.4 Notazione Convenzionale",
    "text": "31.4 Notazione Convenzionale\nNella teoria della probabilità si adotta una convenzione chiara per distinguere una variabile casuale dal suo valore osservato o realizzato:\n\nla variabile casuale viene indicata con lettere maiuscole (es. \\(X\\));\nil valore specifico assunto dalla variabile casuale viene indicato con lettere minuscole (es. \\(x\\)).\n\nQuesta convenzione aiuta a evitare ambiguità, soprattutto quando si definiscono:\n\nprobabilità cumulative: \\(P(X \\leq x)\\);\nvalore atteso: \\(E[X]\\);\nfunzioni di densità o massa di probabilità: \\(f_X(x)\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_random_var.html#variabili-casuali-multiple",
    "href": "chapters/probability/07_random_var.html#variabili-casuali-multiple",
    "title": "31  Variabili casuali",
    "section": "\n31.5 Variabili Casuali Multiple",
    "text": "31.5 Variabili Casuali Multiple\nIn molti esperimenti, è utile considerare contemporaneamente più variabili casuali. Ad esempio, supponiamo di lanciare una moneta equilibrata tre volte. Definiamo tre variabili casuali indipendenti \\(X_1\\), \\(X_2\\) e \\(X_3\\), ciascuna associata all’esito di un lancio:\n\\[\nP(X_n = 1) = 0.5 \\quad (\\text{testa}), \\qquad P(X_n = 0) = 0.5 \\quad (\\text{croce}), \\quad n = 1, 2, 3.\n\\]\nPossiamo poi definire una nuova variabile casuale derivata, ad esempio:\n\\[\nZ = X_1 + X_2 + X_3,\n\\]\nche rappresenta il numero totale di teste ottenute nei tre lanci. In questo scenario, \\(Z\\) è una variabile casuale discreta che può assumere esclusivamente i valori 0, 1, 2 o 3.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_random_var.html#distribuzione-di-probabilità",
    "href": "chapters/probability/07_random_var.html#distribuzione-di-probabilità",
    "title": "31  Variabili casuali",
    "section": "\n31.6 Distribuzione di Probabilità",
    "text": "31.6 Distribuzione di Probabilità\n\nDefinizione 31.2 La distribuzione di probabilità di una variabile casuale descrive come le probabilità sono assegnate ai possibili valori (o intervalli di valori) della variabile.\n\n\n31.6.1 Funzione di Massa di Probabilità (PMF) per Variabili Discrete\nPer una variabile casuale discreta \\(X\\), la distribuzione è definita tramite la funzione di massa di probabilità (PMF), indicata con \\(f(x)\\), dove:\n\\[\nf(x) = P(X = x).\n\\]\nNota la PMF, è possibile calcolare la probabilità di qualsiasi evento associato a \\(X\\). Ad esempio, per un insieme \\(B\\) di valori:\n\\[\nP(X \\in B) = \\sum_{x \\in B} f(x).\n\\]\n\nEsempio 31.4 Consideriamo nuovamente il lancio di due dadi, definendo \\(X\\) come la somma dei loro valori. La tabella seguente mostra chiaramente tutti i casi possibili, il numero di combinazioni per ogni somma, e la relativa probabilità:\n\n\n\n\n\n\n\n\n\\(X\\)\nCasi Favorevoli\nNumero di Casi\n\\(P(X = x)\\)\n\n\n\n2\n\\((1,1)\\)\n1\n\\(\\frac{1}{36}\\)\n\n\n3\n\\((1,2), (2,1)\\)\n2\n\\(\\frac{2}{36} = \\frac{1}{18}\\)\n\n\n4\n\\((1,3), (2,2), (3,1)\\)\n3\n\\(\\frac{3}{36} = \\frac{1}{12}\\)\n\n\n5\n\\((1,4), (2,3), (3,2), (4,1)\\)\n4\n\\(\\frac{4}{36} = \\frac{1}{9}\\)\n\n\n6\n\\((1,5), (2,4), (3,3), (4,2), (5,1)\\)\n5\n\\(\\frac{5}{36}\\)\n\n\n7\n\\((1,6), (2,5), (3,4), (4,3), (5,2), (6,1)\\)\n6\n\\(\\frac{6}{36} = \\frac{1}{6}\\)\n\n\n8\n\\((2,6), (3,5), (4,4), (5,3), (6,2)\\)\n5\n\\(\\frac{5}{36}\\)\n\n\n9\n\\((3,6), (4,5), (5,4), (6,3)\\)\n4\n\\(\\frac{4}{36} = \\frac{1}{9}\\)\n\n\n10\n\\((4,6), (5,5), (6,4)\\)\n3\n\\(\\frac{3}{36} = \\frac{1}{12}\\)\n\n\n11\n\\((5,6), (6,5)\\)\n2\n\\(\\frac{2}{36} = \\frac{1}{18}\\)\n\n\n12\n\\((6,6)\\)\n1\n\\(\\frac{1}{36}\\)\n\n\n\nPer esempio, la probabilità di ottenere una somma pari a 7 è \\(\\frac{1}{6}\\) perché ci sono 6 combinazioni favorevoli su 36 possibili.\n\n\n31.6.2 Funzione di Distribuzione Cumulativa (CDF)\n\nDefinizione 31.3 La funzione di distribuzione cumulativa (CDF) di una variabile casuale \\(X\\) è definita come: \\[\nF(x) = P(X \\leq x).\n\\] La CDF indica la probabilità che \\(X\\) assuma valori minori o uguali a un valore specifico \\(x\\).\n\n\n31.6.3 Proprietà della CDF (Funzione di Ripartizione)\nLa CDF descrive la probabilità che una variabile casuale \\(X\\) assuma un valore minore o uguale a \\(x\\). Per capirla in psicologia (ad esempio, per analizzare dati di test, questionari, o esperimenti), bastano tre idee chiave:\n\n\nNon diminuisce mai:\nSe consideriamo valori \\(x\\) sempre più grandi, la probabilità cumulata non può diminuire.\n\n\nEsempio: Se la CDF a \\(x = 50\\) in un test è \\(0.7\\), a \\(x = 60\\) sarà almeno \\(0.7\\) (potrebbe salire, ma non scendere).\n\n\nPerché? Aggiungendo nuovi risultati (es.: punteggi più alti), la probabilità totale può solo aumentare o restare uguale.\n\n\n\nEstremi prevedibili:\n\nPer valori molto bassi (es.: \\(x \\to -\\infty\\)), la probabilità cumulata è 0: non esistono punteggi infinitamente bassi.\n\nPer valori molto alti (es.: \\(x \\to +\\infty\\)), la probabilità cumulata è 1: tutti i possibili risultati sono inclusi.\n\n\nEsempio: In una scala Likert da 1 a 5, la CDF a \\(x = 0\\) è 0, e a \\(x = 10\\) è 1.\n\n\n\nNiente salti “a sorpresa” verso destra:\nLa CDF è costruita in modo che, se ci spostiamo di pochissimo a destra di un punto \\(x\\), la probabilità cumulata non crolla improvvisamente.\n\n\nEsempio pratico:\nSupponiamo che in un questionario, il punteggio \\(x = 10\\) corrisponda a una certa probabilità cumulata (es.: \\(0.8\\)). Se ci spostiamo di un millesimo a destra (es.: \\(x = 10.001\\)), la probabilità rimane \\(0.8\\), a meno che \\(10.001\\) non sia un punteggio valido.\n\n\nA cosa serve? Garantisce coerenza: se un punteggio \\(x\\) ha una certa probabilità, questa non viene “persa” spostandosi di poco a destra.\n\n\n\n31.6.4 CDF per variabili discrete (es.: scale psicologiche)\nIn psicologia, spesso lavoriamo con dati discreti (es.: risposte a item di un test, come “1 = Mai” a “5 = Sempre”). In questi casi:\n\nLa CDF si calcola sommando le probabilità di tutti i valori \\(\\leq x\\).\n\n\nEsempio: Se in una scala da 1 a 5, il 30% degli studenti risponde 1 o 2, allora \\(F(2) = 0.3\\).\n\n\nGraficamente: La CDF avrà “gradini” nei punti corrispondenti ai valori possibili (es.: 1, 2, 3, 4, 5).\n\n\n31.6.4.1 Perché serve saperlo?\nQueste proprietà aiutano a:\n\nInterpretare grafici cumulativi (es.: quanto è probabile che un partecipante abbia un punteggio \\(\\leq\\) 20?).\n\nEvitare errori logici (es.: non ha senso aspettarsi un calo della probabilità cumulata all’aumentare di \\(x\\)).\n\nLeggere correttamente salti nei dati discreti (es.: un gradino in \\(x = 4\\) indica un accumulo di probabilità in quel punto).\n\n\nEsempio 31.5 Riprendendo l’esempio della variabile casuale \\(X\\) definita come la somma di due dadi, possiamo riassumere PMF e CDF in una tabella unica:\n\n\n\\(x\\)\n\\(P(X = x)\\)\n\\(F(x)\\)\n\n\n\n2\n\\(\\frac{1}{36}\\)\n\\(\\frac{1}{36}\\)\n\n\n3\n\\(\\frac{2}{36}\\)\n\\(\\frac{3}{36}\\)\n\n\n4\n\\(\\frac{3}{36}\\)\n\\(\\frac{6}{36}\\)\n\n\n5\n\\(\\frac{4}{36}\\)\n\\(\\frac{10}{36}\\)\n\n\n6\n\\(\\frac{5}{36}\\)\n\\(\\frac{15}{36}\\)\n\n\n7\n\\(\\frac{6}{36}\\)\n\\(\\frac{21}{36}\\)\n\n\n8\n\\(\\frac{5}{36}\\)\n\\(\\frac{26}{36}\\)\n\n\n9\n\\(\\frac{4}{36}\\)\n\\(\\frac{30}{36}\\)\n\n\n10\n\\(\\frac{3}{36}\\)\n\\(\\frac{33}{36}\\)\n\n\n11\n\\(\\frac{2}{36}\\)\n\\(\\frac{35}{36}\\)\n\n\n12\n\\(\\frac{1}{36}\\)\n\\(1\\)",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_random_var.html#simulazione-della-distribuzione-di-probabilità",
    "href": "chapters/probability/07_random_var.html#simulazione-della-distribuzione-di-probabilità",
    "title": "31  Variabili casuali",
    "section": "\n31.7 Simulazione della Distribuzione di Probabilità",
    "text": "31.7 Simulazione della Distribuzione di Probabilità\nSpesso, anche se è possibile calcolare analiticamente la distribuzione di probabilità (come nel caso dei due dadi), può essere utile ottenere una stima empirica attraverso la simulazione. Questo approccio prevede di ripetere l’esperimento molte volte e di analizzare le frequenze relative dei risultati ottenuti.\n\nEsempio 31.6 Simulazione del lancio di due dadi in R.\n1. Simulare il lancio di un singolo dado\n\n# Funzione per simulare un dado a sei facce\nlancia_dado &lt;- function() {\n  sample(1:6, 1)\n}\n\n2. Simulare il lancio di due dadi\n\n# Funzione per simulare il lancio di due dadi ripetuto n volte\nlancia_due_dadi &lt;- function(n) {\n  risultati &lt;- numeric(n)\n  \n  for (i in 1:n) {\n    risultati[i] &lt;- lancia_dado() + lancia_dado()\n  }\n  \n  risultati\n}\n\n3. Eseguire la simulazione\n\n# Numero totale di simulazioni\nnumero_lanci &lt;- 100000\n\n# Simulazione dei lanci\nrisultati_simulazione &lt;- lancia_due_dadi(numero_lanci)\n\n# Visualizza i primi 20 risultati\ncat(\"Primi 20 risultati:\", risultati_simulazione[1:20], \"\\n\")\n#&gt; Primi 20 risultati: 6 2 6 4 5 6 10 4 4 4 9 10 6 7 3 8 9 6 10 7\n\n4. Calcolare e visualizzare la distribuzione empirica\n\n# Calcola la frequenza assoluta per ciascuna somma\nfrequenze_assolute &lt;- table(risultati_simulazione)\nfrequenze_assolute\n#&gt; risultati_simulazione\n#&gt;     2     3     4     5     6     7     8     9    10    11    12 \n#&gt;  2824  5655  8486 11128 13948 16526 13797 11024  8303  5458  2851\n\n# Calcola direttamente le frequenze relative (probabilità empiriche)\nprobabilita_empiriche &lt;- frequenze_assolute / numero_lanci\nprobabilita_empiriche\n#&gt; risultati_simulazione\n#&gt;       2       3       4       5       6       7       8       9      10 \n#&gt; 0.02824 0.05655 0.08486 0.11128 0.13948 0.16526 0.13797 0.11024 0.08303 \n#&gt;      11      12 \n#&gt; 0.05458 0.02851\n\n# Crea una tabella finale chiara e semplice\ndistribuzione_empirica &lt;- data.frame(\n  Somma = as.numeric(names(probabilita_empiriche)),\n  Probabilita = as.vector(probabilita_empiriche)\n)\n\n# Mostra la distribuzione empirica\nprint(distribuzione_empirica)\n#&gt;    Somma Probabilita\n#&gt; 1      2     0.02824\n#&gt; 2      3     0.05655\n#&gt; 3      4     0.08486\n#&gt; 4      5     0.11128\n#&gt; 5      6     0.13948\n#&gt; 6      7     0.16526\n#&gt; 7      8     0.13797\n#&gt; 8      9     0.11024\n#&gt; 9     10     0.08303\n#&gt; 10    11     0.05458\n#&gt; 11    12     0.02851\n\nChiarimento sintetico dei concetti chiave.\n\nCos’è una simulazione?\nÈ un esperimento realizzato al computer che replica più volte un evento casuale per osservare i possibili risultati e la loro frequenza.\nDistribuzione empirica\nÈ la frequenza con cui ogni risultato (in questo caso, la somma di due dadi) appare nella simulazione. Con più simulazioni, questa distribuzione si avvicina sempre di più a quella prevista dalla teoria.\nProbabilità teorica ed empirica\nLa probabilità teorica è calcolata matematicamente: ad esempio, la somma “7” è teoricamente più frequente perché ci sono più modi di ottenerla (6+1, 5+2, 4+3, ecc.).\nLa probabilità empirica, invece, si ottiene dalla simulazione pratica, ed è una buona approssimazione della probabilità teorica quando il numero di prove è grande.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_random_var.html#distribuzioni-per-variabili-continue",
    "href": "chapters/probability/07_random_var.html#distribuzioni-per-variabili-continue",
    "title": "31  Variabili casuali",
    "section": "\n31.8 Distribuzioni per Variabili Continue",
    "text": "31.8 Distribuzioni per Variabili Continue\n\nDefinizione 31.4 Una variabile casuale continua è una variabile aleatoria \\(X\\) caratterizzata da una distribuzione di probabilità continua. Formalmente, \\(X\\) si definisce continua se soddisfa le seguenti proprietà:\n\n\nEsistenza della funzione di densità (pdf):\nEsiste una funzione non negativa \\(f(x)\\), detta funzione di densità di probabilità (pdf, dall’inglese probability density function), tale che:\n\n\n\\(f(x) \\geq 0\\) per ogni \\(x \\in \\mathbb{R}\\);\n\nL’area totale sotto la curva di \\(f(x)\\) è pari a 1:\\[\n\\int_{-\\infty}^{+\\infty} f(x) \\, dx = 1.\n\\]\n\n\n\n\nCalcolo delle probabilità tramite integrazione:\nPer ogni intervallo \\((a, b] \\subseteq \\mathbb{R}\\) (con \\(a &lt; b\\)), la probabilità che \\(X\\) assuma valori in \\((a, b]\\) è data dall’integrale della pdf su tale intervallo:\n\\[\nP(a &lt; X \\leq b) = \\int_{a}^{b} f(x) \\, dx.\n\\]\nQuesta probabilità coincide anche con la differenza della funzione di ripartizione (CDF, cumulative distribution function) \\(F(x) = P(X \\leq x)\\) agli estremi dell’intervallo:\n\\[\nP(a &lt; X \\leq b) = F(b) - F(a).\n\\]\n\n\n\n\n31.8.1 Proprietà Chiave delle Variabili Continue\n\n\nProbabilità in un punto nulla:\nA differenza delle variabili discrete, per una variabile continua la probabilità di assumere un valore esatto \\(x_0\\) è sempre zero:\n\\[\nP(X = x_0) = 0.\n\\]\nQuesto avviene perché la probabilità è legata all’area sotto la curva \\(f(x)\\), e un singolo punto ha “larghezza zero”, risultando in un’area nulla. Di conseguenza, per variabili continue:\n\\[\nP(a \\leq X \\leq b) = P(a &lt; X \\leq b) = P(a \\leq X &lt; b) = P(a &lt; X &lt; b).\n\\]\n\nInterpretazione della densità:\nLa funzione \\(f(x)\\) non rappresenta direttamente una probabilità, ma descrive come la probabilità si distribuisce nello spazio campionario. Valori maggiori di \\(f(x)\\) indicano regioni in cui è più probabile che \\(X\\) assuma valori (densità di probabilità).\nModellizzazione di fenomeni continui:\nLe distribuzioni continue sono utilizzate per rappresentare grandezze misurabili con precisione arbitraria, come tempo, lunghezze, o temperature. Esempi comuni includono la distribuzione normale, esponenziale e uniforme continua.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_random_var.html#riflessioni-conclusive",
    "href": "chapters/probability/07_random_var.html#riflessioni-conclusive",
    "title": "31  Variabili casuali",
    "section": "\n31.9 Riflessioni Conclusive",
    "text": "31.9 Riflessioni Conclusive\nIn questo capitolo abbiamo introdotto e approfondito il concetto fondamentale di variabile casuale, illustrando come questo strumento permetta di formalizzare e analizzare matematicamente fenomeni casuali complessi. Attraverso esempi intuitivi, come il lancio di dadi o la simulazione di situazioni reali, abbiamo osservato come le variabili casuali consentano di tradurre domande astratte in analisi concrete e interpretabili.\nAbbiamo esaminato le due principali tipologie di variabili casuali—discrete e continue—e discusso le relative distribuzioni di probabilità. Le distribuzioni discrete, caratterizzate da una funzione di massa di probabilità (PMF), si prestano particolarmente bene a modellare situazioni in cui gli eventi possono essere enumerati (come punteggi in test psicologici o risultati di giochi). Al contrario, le distribuzioni continue, descritte dalla funzione di densità di probabilità (PDF), sono essenziali per modellare misure precise, come l’altezza o il tempo, dove il numero di possibili valori è teoricamente infinito.\nUn aspetto importante trattato è la funzione di distribuzione cumulativa (CDF), che fornisce una descrizione completa della distribuzione di una variabile casuale, facilitando la comprensione intuitiva della probabilità che un evento accada entro certi limiti. Conoscere le proprietà della CDF aiuta a prevenire errori comuni nella sua interpretazione e a trarre conclusioni più affidabili dai dati empirici.\nInfine, attraverso l’utilizzo della simulazione, abbiamo mostrato come sia possibile avvicinarsi empiricamente a una distribuzione teorica, confermando e visualizzando in modo pratico e immediato concetti astratti. Questa capacità di simulare e verificare empiricamente le distribuzioni è estremamente utile, soprattutto quando i modelli teorici diventano troppo complessi da risolvere analiticamente.\nNei prossimi capitoli approfondiremo ulteriormente questi concetti, esaminando alcune distribuzioni di probabilità specifiche che sono comunemente usate nella ricerca psicologica e nelle applicazioni pratiche. Questo ci permetterà di passare da una conoscenza teorica delle variabili casuali a una competenza concreta nel loro utilizzo e nella loro interpretazione, sviluppando strumenti che miglioreranno le nostre capacità di analisi e di decisione in ambito psicologico e statistico.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_random_var.html#esercizi",
    "href": "chapters/probability/07_random_var.html#esercizi",
    "title": "31  Variabili casuali",
    "section": "\n31.10 Esercizi",
    "text": "31.10 Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nConsiglio gli esercizi di base disponibili nella seguente pagina web.\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nEsercizi sulla distribuzione normale, risolvibili usando R, sono disponibili sulla seguente pagina web.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_random_var.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/07_random_var.html#informazioni-sullambiente-di-sviluppo",
    "title": "31  Variabili casuali",
    "section": "\n31.11 Informazioni sull’Ambiente di Sviluppo",
    "text": "31.11 Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.7   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.13.0 psych_2.5.3     \n#&gt;  [9] scales_1.4.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.3.0     ggplot2_3.5.2   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.4     stringi_1.8.7      lattice_0.22-7    \n#&gt;  [4] hms_1.1.3          digest_0.6.37      magrittr_2.0.3    \n#&gt;  [7] evaluate_1.0.4     grid_4.5.0         timechange_0.3.0  \n#&gt; [10] RColorBrewer_1.1-3 fastmap_1.2.0      rprojroot_2.0.4   \n#&gt; [13] jsonlite_2.0.0     mnormt_2.1.1       cli_3.6.5         \n#&gt; [16] rlang_1.1.6        withr_3.0.2        tools_4.5.0       \n#&gt; [19] parallel_4.5.0     tzdb_0.5.0         pacman_0.5.1      \n#&gt; [22] vctrs_0.6.5        R6_2.6.1           lifecycle_1.0.4   \n#&gt; [25] htmlwidgets_1.6.4  pkgconfig_2.0.3    pillar_1.10.2     \n#&gt; [28] gtable_0.3.6       glue_1.8.0         xfun_0.52         \n#&gt; [31] tidyselect_1.2.1   rstudioapi_0.17.1  farver_2.1.2      \n#&gt; [34] htmltools_0.5.8.1  nlme_3.1-168       rmarkdown_2.29    \n#&gt; [37] compiler_4.5.0",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_random_var.html#bibliografia",
    "href": "chapters/probability/07_random_var.html#bibliografia",
    "title": "31  Variabili casuali",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.\n\n\nChan, J. C. C., & Kroese, D. P. (2025). Statistical Modeling and Computation (2ª ed.). Springer.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_prob_distributions.html",
    "href": "chapters/probability/08_prob_distributions.html",
    "title": "32  Distribuzioni di massa e di densità",
    "section": "",
    "text": "32.1 Introduzione\nNel Capitolo 31 abbiamo introdotto il concetto di variabile casuale, distinguendo tra variabili casuali discrete e continue. Per le prime, abbiamo descritto formalmente come assegnare una distribuzione di massa di probabilità, mentre per le seconde abbiamo introdotto la nozione di funzione di densità di probabilità. Fino a questo punto, i concetti di distribuzione di massa e densità sono stati trattati in termini prevalentemente formali e matematici.\nLo scopo di questo capitolo è quello di approfondire queste idee, fornendo un’interpretazione più intuitiva e concreta di tali concetti. Attraverso esempi ed analisi pratiche, cercheremo di chiarire il significato sottostante alle distribuzioni di probabilità, rendendo più accessibili queste fondamentali strutture della teoria delle probabilità.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_prob_distributions.html#variabili-casuali-discrete-e-continue",
    "href": "chapters/probability/08_prob_distributions.html#variabili-casuali-discrete-e-continue",
    "title": "32  Distribuzioni di massa e di densità",
    "section": "\n32.2 Variabili Casuali Discrete e Continue",
    "text": "32.2 Variabili Casuali Discrete e Continue\nUn elemento fondamentale nella comprensione delle distribuzioni di probabilità è la distinzione tra variabili casuali discrete e continue, poiché le distribuzioni di probabilità associate differiscono in modo sostanziale.\n\n\nVariabili Casuali Discrete: assumono un numero finito o numerabile di valori. Ad esempio, il numero di successi in una serie di esperimenti o il risultato del lancio di un dado.\n\nVariabili Casuali Continue: possono assumere un numero infinito di valori all’interno di un intervallo. Esempi includono il tempo di attesa per un evento o il quoziente intellettivo (QI) di una persona.\n\nQuesta distinzione è fondamentale perché le relative distribuzioni probabilistiche si comportano in modi diversi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_prob_distributions.html#distribuzioni-di-probabilità-discrete",
    "href": "chapters/probability/08_prob_distributions.html#distribuzioni-di-probabilità-discrete",
    "title": "32  Distribuzioni di massa e di densità",
    "section": "\n32.3 Distribuzioni di Probabilità Discrete",
    "text": "32.3 Distribuzioni di Probabilità Discrete\nLe distribuzioni di probabilità discrete descrivono fenomeni aleatori con un numero finito o numerabile di esiti possibili. Queste distribuzioni sono rappresentate da una funzione di massa di probabilità (PMF), che assegna una probabilità a ciascun valore della variabile casuale.\n\nEsempio 32.1 Consideriamo un dado sbilanciato con la seguente distribuzione di probabilità:\n\n\nValore di \\(X\\)\n\nProbabilità \\(p(x)\\)\n\n\n\n\n1\n0.10\n\n\n2\n0.15\n\n\n3\n0.20\n\n\n4\n0.25\n\n\n5\n0.20\n\n\n6\n0.10\n\n\n\nQuesta tabella rappresenta la funzione di massa di probabilità (PMF).\nPer visualizzare questa distribuzione, possiamo simulare 1000 lanci del dado e creare un diagramma a barre che rappresenta le frequenze relative osservate. In R:\n\n# Dati\nset.seed(123)\nprob &lt;- c(0.10, 0.15, 0.20, 0.25, 0.20, 0.10)\nlanci &lt;- sample(1:6, size = 1000, replace = TRUE, prob = prob)\n\n# Creazione di un data frame\ndf &lt;- data.frame(Valore = factor(lanci))\n\n# Creazione del diagramma a barre\nggplot(df, aes(x = Valore)) +\n  geom_bar(aes(y = after_stat(count) / sum(after_stat(count))), fill = \"lightblue\", color=\"black\") +\n  labs(\n    title = \"Distribuzione empirica dei lanci\",\n    x = \"Valore\",\n    y = \"Frequenza relativa\"\n  )\n\n\n\n\n\n\n\nQuando il numero di lanci aumenta, le frequenze relative si avvicinano sempre più alle probabilità teoriche.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_prob_distributions.html#distribuzioni-di-probabilità-continue",
    "href": "chapters/probability/08_prob_distributions.html#distribuzioni-di-probabilità-continue",
    "title": "32  Distribuzioni di massa e di densità",
    "section": "\n32.4 Distribuzioni di Probabilità Continue",
    "text": "32.4 Distribuzioni di Probabilità Continue\nLe distribuzioni di probabilità continue descrivono variabili casuali che possono assumere un numero infinito di valori in un intervallo. In questo caso, la probabilità è rappresentata da una funzione di densità di probabilità (PDF), che descrive la probabilità che la variabile assuma valori in un dato intervallo.\n\n32.4.1 Probabilità come Area Sotto la Curva\nLe distribuzioni continue sono descritte dalla funzione di densità di probabilità (PDF). Per una variabile casuale continua \\(X\\), la probabilità che \\(X\\) assuma un valore compreso tra \\(a\\) e \\(b\\) è data dall’area sotto la curva della PDF tra \\(a\\) e \\(b\\):\n\\[\nP(a \\leq X \\leq b) = \\int_a^b f(x) \\, dx.\n\\]\n\nEsempio 32.2 Il quoziente intellettivo (QI) è spesso modellato come una variabile casuale continua con distribuzione normale, con media \\(\\mu = 100\\) e deviazione standard \\(\\sigma = 15\\). Possiamo simulare questa distribuzione e confrontare l’istogramma dei dati con la PDF teorica.\nSimulazione con 50 osservazioni.\n\n# Parametri della distribuzione normale\nmu &lt;- 100\nsigma &lt;- 15\nsize &lt;- 50\n\n# Generare i dati\nset.seed(123)\nx &lt;- rnorm(size, mean = mu, sd = sigma)\n\n# Istogramma e densità\ndata_frame &lt;- data.frame(X = x)\nxmin &lt;- min(x)\nxmax &lt;- max(x)\ndensity_data &lt;- data.frame(\n  X = seq(xmin, xmax, length.out = 100),\n  Density = dnorm(seq(xmin, xmax, length.out = 100), mean = mu, sd = sigma)\n)\n\nggplot(data_frame, aes(x = X)) +\n  geom_histogram(\n    aes(y = after_stat(density)),\n    bins = 25,\n    fill = \"lightblue\", color = \"black\"\n  ) +\n  geom_line(\n    data = density_data,\n    aes(x = X, y = Density),\n    color = \"black\",\n    size = 1\n  ) +\n  labs(\n    title = \"Distribuzione del QI (50 osservazioni)\",\n    x = \"Valori del QI\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\nCon un campione piccolo, l’istogramma non corrisponde perfettamente alla PDF teorica. Tuttavia, aumentando il numero di osservazioni, l’approssimazione migliora.\nSimulazione con 20000 osservazioni.\n\n# Generare un campione più grande\nsize &lt;- 20000\nset.seed(123)\nx &lt;- rnorm(size, mean = mu, sd = sigma)\n\n# Aggiornare media e deviazione standard\nmu &lt;- mean(x)\nsigma &lt;- sd(x)\n\n# Creare il grafico\ndata_frame &lt;- data.frame(X = x)\nxmin &lt;- min(x)\nxmax &lt;- max(x)\ndensity_data &lt;- data.frame(\n  X = seq(xmin, xmax, length.out = 100),\n  Density = dnorm(seq(xmin, xmax, length.out = 100), mean = mu, sd = sigma)\n)\n\nggplot(data_frame, aes(x = X)) +\n  geom_histogram(\n    aes(y = after_stat(density)),\n    bins = 25,\n    fill = \"lightblue\",\n    color = \"black\"\n  ) +\n  geom_line(\n    data = density_data,\n    aes(x = X, y = Density),\n    color = \"black\",\n    size = 1\n  ) +\n  labs(\n    title = sprintf(\"Distribuzione del QI (%d osservazioni)\", size),\n    x = \"Valori del QI\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\nCon un campione di grandi dimensioni, l’istogramma riflette molto meglio la PDF teorica.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_prob_distributions.html#interpretazione-della-funzione-di-densità",
    "href": "chapters/probability/08_prob_distributions.html#interpretazione-della-funzione-di-densità",
    "title": "32  Distribuzioni di massa e di densità",
    "section": "\n32.5 Interpretazione della Funzione di Densità",
    "text": "32.5 Interpretazione della Funzione di Densità\nLa funzione di densità di probabilità (PDF) rappresenta un’astrazione continua dell’istogramma. Quando il numero di osservazioni tende a infinito e la larghezza degli intervalli tende a zero, il profilo dell’istogramma si avvicina alla PDF.\n\n32.5.1 Proprietà della PDF\n\n\nArea Totale: L’area totale sotto la curva della PDF è uguale a 1, poiché rappresenta la probabilità totale.\n\nProbabilità per Intervalli: La probabilità che la variabile assuma un valore in un intervallo \\([a, b]\\) è data dall’area sotto la curva tra \\(a\\) e \\(b\\).\n\nProbabilità per Singoli Valori: Per una variabile continua, la probabilità di un singolo valore è sempre zero, poiché corrisponde all’area sotto la curva in un punto.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_prob_distributions.html#parametri-delle-distribuzioni-di-probabilità",
    "href": "chapters/probability/08_prob_distributions.html#parametri-delle-distribuzioni-di-probabilità",
    "title": "32  Distribuzioni di massa e di densità",
    "section": "\n32.6 Parametri delle Distribuzioni di Probabilità",
    "text": "32.6 Parametri delle Distribuzioni di Probabilità\nLe distribuzioni di probabilità, sia discrete che continue, sono definite da parametri che ne determinano le proprietà fondamentali. Questi parametri consentono di adattare il modello probabilistico ai dati osservati.\n\n32.6.1 Proprietà Influenzate dai Parametri\n\n\nPosizione (Tendenza Centrale): Indica il valore attorno al quale si concentra la distribuzione. Ad esempio, nella distribuzione normale, la media (\\(\\mu\\)) rappresenta il centro della distribuzione.\n\nDispersione: Misura quanto i valori della distribuzione si allontanano dalla posizione centrale. Nella distribuzione normale, la deviazione standard (\\(\\sigma\\)) controlla la larghezza della curva.\n\nForma: Determina l’asimmetria o la curtosi della distribuzione. Alcune distribuzioni, come quella gamma o beta, hanno parametri specifici per regolare la forma.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_prob_distributions.html#il-paradosso-delle-variabili-casuali-continue",
    "href": "chapters/probability/08_prob_distributions.html#il-paradosso-delle-variabili-casuali-continue",
    "title": "32  Distribuzioni di massa e di densità",
    "section": "\n32.7 Il Paradosso delle Variabili Casuali Continue",
    "text": "32.7 Il Paradosso delle Variabili Casuali Continue\nUn aspetto controintuitivo delle variabili casuali continue è che la probabilità di osservare esattamente un determinato valore è sempre pari a zero. Per esempio, se consideriamo una variabile continua che rappresenta l’altezza di una persona, la probabilità che l’altezza sia esattamente 170 cm è espressa da\n\\[\nP(X = 170) = 0.\n\\]\nPerché accade questo? La risposta sta nel concetto di “esattezza”. Se riscriviamo 170 cm come 170.00000000000000000000000000000000000 cm (con infiniti decimali), diventa chiaro che stiamo cercando un singolo punto in un continuum infinito.\nQuesto non significa che l’evento sia impossibile, ma che nelle variabili continue la probabilità ha senso solo se riferita a intervalli di valori. Infatti, se sommiamo infinite probabilità diverse da zero, supereremmo 1, cosa impossibile.\n\n32.7.1 Due Implicazioni Importanti\nQuesto modo di definire la probabilità nelle variabili continue comporta due implicazioni chiave:\n\n\nCalcolo della probabilità su intervalli:\nNelle variabili continue, le probabilità si calcolano solo su intervalli (es.: tra 169.5 cm e 170.5 cm). Questo perché, se ogni singolo valore avesse probabilità &gt; 0, la somma di infiniti valori supererebbe 1 (il che è impossibile).\n\nEventi con probabilità zero:\nIl fatto che un evento (ad esempio, \\(X = 170\\)) abbia probabilità zero non implica che l’evento sia impossibile. È come cercare un granello di sabbia specifico su una spiaggia infinita: tecnicamente possibile, ma praticamente improbabile.\n\n32.7.2 Il Paradosso della Probabilità Zero\nQuesto ragionamento porta a un apparente paradosso: se la probabilità che l’altezza di una persona sia esattamente 170 è zero, come possiamo mai osservare un valore specifico, come 170 (o un qualsiasi altro valore), nella realtà?\nUna metafora utile per comprendere questo fenomeno è data dal celebre paradosso di Zenone della freccia. Nel paradosso, si sostiene che, in ogni istante, la freccia sia immobile, e dunque non si dovrebbe mai muovere. Analogamente, ogni singolo valore (es.: 170 cm) ha probabilità zero, ma l’insieme di infiniti valori in un intervallo crea un’area sotto la curva (probabilità) misurabile.\n\n32.7.3 La Prospettiva degli Infinitesimi\nNegli anni ’60, il matematico Abraham Robinson sviluppò una teoria matematica rigorosa degli infinitesimi, ovvero numeri infinitamente piccoli, diversi da zero. In questo quadro, possiamo reinterpretare la probabilità dei singoli punti nel seguente modo:\n\n\nProbabilità infinitesimale:\nUn singolo valore puntuale non ha probabilità strettamente zero, bensì infinitamente piccola (un infinitesimo). Pur essendo praticamente indistinguibile da zero nella teoria classica, l’aggregazione (tramite integrazione) di infiniti eventi con probabilità infinitesimali può produrre un valore di probabilità finito e positivo per un intervallo. In altre parole, infiniti punti infinitamente piccoli sommati insieme generano un intervallo di probabilità misurabile e significativa.\n\nIn conclusione, il cosiddetto “paradosso della probabilità zero” non rappresenta un vero paradosso, ma evidenzia piuttosto i limiti delle nostre intuizioni quando affrontiamo concetti inerenti variabili continue. La chiave per la comprensione risiede nella distinzione tra il contributo di un singolo punto (infinitesimale o zero, nell’analisi classica) e l’area complessiva calcolata mediante l’integrazione.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_prob_distributions.html#la-funzione-di-ripartizione-per-una-variabile-casuale-continua",
    "href": "chapters/probability/08_prob_distributions.html#la-funzione-di-ripartizione-per-una-variabile-casuale-continua",
    "title": "32  Distribuzioni di massa e di densità",
    "section": "\n32.8 La Funzione di Ripartizione per una Variabile Casuale Continua",
    "text": "32.8 La Funzione di Ripartizione per una Variabile Casuale Continua\nLa funzione di ripartizione, nota anche come distribuzione cumulativa, è uno strumento fondamentale per descrivere il comportamento di una variabile casuale, sia essa discreta o continua. Per una variabile casuale continua \\(\\Theta\\), la funzione di ripartizione \\(F_{\\Theta}(\\theta)\\) è definita come:\n\\[\nF_{\\Theta}(\\theta) = P(\\Theta \\leq \\theta).\n\\]\nIn altre parole, \\(F_{\\Theta}(\\theta)\\) rappresenta la probabilità che la variabile \\(\\Theta\\) assuma un valore minore o uguale a \\(\\theta\\). Questa definizione è identica a quella utilizzata per le variabili casuali discrete, ma nel caso continuo assume un significato particolare a causa della natura continua della variabile.\n\n32.8.1 Proprietà della Funzione di Ripartizione\nLa funzione di ripartizione per una variabile casuale continua gode di alcune proprietà importanti:\n\n\nMonotonicità Crescente: \\(F_{\\Theta}(\\theta)\\) è una funzione non decrescente. Ciò significa che, all’aumentare di \\(\\theta\\), la probabilità \\(P(\\Theta \\leq \\theta)\\) non diminuisce.\n\nLimiti agli Estremi:\n\nQuando \\(\\theta \\to -\\infty\\), \\(F_{\\Theta}(\\theta) \\to 0\\).\nQuando \\(\\theta \\to +\\infty\\), \\(F_{\\Theta}(\\theta) \\to 1\\).\n\n\n\nContinuità: Per una variabile casuale continua, \\(F_{\\Theta}(\\theta)\\) è una funzione continua. Questo differisce dal caso discreto, dove la funzione di ripartizione è a gradini.\n\n32.8.2 Calcolo delle Probabilità per Intervalli\nUna delle applicazioni più utili della funzione di ripartizione è il calcolo della probabilità che la variabile casuale \\(\\Theta\\) assuma valori all’interno di un intervallo specifico. Dati due valori \\(\\theta_1\\) e \\(\\theta_2\\) (con \\(\\theta_1 &lt; \\theta_2\\)), la probabilità che \\(\\Theta\\) sia compreso tra \\(\\theta_1\\) e \\(\\theta_2\\) è data da:\n\\[\nP(\\theta_1 &lt; \\Theta \\leq \\theta_2) = F_{\\Theta}(\\theta_2) - F_{\\Theta}(\\theta_1).\n\\]\nQuesta formula è particolarmente utile perché, nel caso delle variabili continue, la probabilità di un singolo punto è sempre zero. Pertanto, per calcolare probabilità significative, è necessario considerare intervalli di valori.\n\n32.8.3 Relazione con la Funzione di Densità di Probabilità (PDF)\nLa funzione di ripartizione è strettamente legata alla funzione di densità di probabilità (PDF), \\(f(\\theta)\\). Mentre la PDF descrive la densità di probabilità in ogni punto, la funzione di ripartizione rappresenta l’area sotto la curva della PDF fino a un certo valore \\(\\theta\\). Formalmente, la funzione di ripartizione si ottiene integrando la PDF:\n\\[\nF_{\\Theta}(\\theta) = \\int_{-\\infty}^{\\theta} f(t) \\, dt.\n\\]\nQuesta relazione evidenzia come la funzione di ripartizione sia una rappresentazione cumulativa della probabilità, ottenuta sommando (o integrando) i contributi della densità di probabilità fino al valore \\(\\theta\\).\n\nEsempio 32.3 Consideriamo una variabile casuale \\(\\Theta\\) con distribuzione normale standard (media \\(\\mu = 0\\) e deviazione standard \\(\\sigma = 1\\)). La PDF è data da:\n\\[\nf(\\theta) = \\frac{1}{\\sqrt{2\\pi}} e^{-\\theta^2 / 2}.\n\\]\nLa funzione di ripartizione \\(F_{\\Theta}(\\theta)\\) è l’integrale di questa funzione da \\(-\\infty\\) a \\(\\theta\\):\n\\[\nF_{\\Theta}(\\theta) = \\int_{-\\infty}^{\\theta} \\frac{1}{\\sqrt{2\\pi}} e^{-t^2 / 2} \\, dt.\n\\]\nQuesta funzione non ha una forma chiusa semplice, ma può essere calcolata numericamente o consultata in tabelle statistiche. Ad esempio, per \\(\\theta = 1\\), \\(F_{\\Theta}(1) \\approx 0.8413\\), il che significa che la probabilità che \\(\\Theta\\) sia minore o uguale a 1 è circa l’84.13%.\n\n\n32.8.4 Interpretazione Grafica\nGraficamente, la funzione di ripartizione rappresenta l’area sotto la curva della PDF a sinistra del valore \\(\\theta\\). Ad esempio, se consideriamo la distribuzione normale standard:\n\nPer \\(\\theta = 0\\), \\(F_{\\Theta}(0) = 0.5\\), poiché la media della distribuzione è 0 e la curva è simmetrica.\nPer \\(\\theta = 1\\), \\(F_{\\Theta}(1) \\approx 0.8413\\), come visto sopra.\nPer \\(\\theta = -1\\), \\(F_{\\Theta}(-1) \\approx 0.1587\\), poiché la coda sinistra della distribuzione contiene il 15.87% della probabilità.\n\n\n# Definisci i parametri della distribuzione normale standard\nmu &lt;- 0\nsigma &lt;- 1\n\n# Definisci i valori di theta\ntheta_values &lt;- c(-1, 0, 1)\n\n# Crea un data frame per la PDF e la CDF\nx &lt;- seq(-4, 4, length.out = 1000)  # Valori sull'asse x\npdf_values &lt;- dnorm(x, mean = mu, sd = sigma)  # Valori della PDF\ncdf_values &lt;- pnorm(x, mean = mu, sd = sigma)  # Valori della CDF\n\ndata &lt;- data.frame(x = x, PDF = pdf_values, CDF = cdf_values)\n\n# Crea il grafico\nggplot(data, aes(x = x)) +\n  # Plot della PDF\n  geom_line(aes(y = PDF), color = \"blue\", linewidth = 1) +\n  # Aggiungi aree sotto la PDF per i valori di theta\n  geom_area(data = subset(data, x &lt;= theta_values[1]), aes(y = PDF), fill = \"red\", alpha = 0.5) +\n  geom_area(data = subset(data, x &lt;= theta_values[2]), aes(y = PDF), fill = \"green\", alpha = 0.5) +\n  geom_area(data = subset(data, x &lt;= theta_values[3]), aes(y = PDF), fill = \"purple\", alpha = 0.5) +\n  # Plot della CDF\n  geom_line(aes(y = CDF), color = \"black\", linewidth = 1, linetype = \"dashed\") +\n  # Aggiungi linee verticali per i valori di theta\n  geom_vline(xintercept = theta_values, color = \"gray\", linetype = \"dotted\") +\n  # Aggiungi annotazioni per i valori di theta\n  annotate(\"text\", x = theta_values[1], y = 0, label = paste(\"θ =\", theta_values[1]), vjust = 2, hjust = 1.2, color = \"red\") +\n  annotate(\"text\", x = theta_values[2], y = 0, label = paste(\"θ =\", theta_values[2]), vjust = 2, hjust = 1.2, color = \"green\") +\n  annotate(\"text\", x = theta_values[3], y = 0, label = paste(\"θ =\", theta_values[3]), vjust = 2, hjust = -0.2, color = \"purple\") +\n  # Aggiungi titoli e etichette\n  labs(\n    title = \"Funzione di Densità di Probabilità (PDF) e\\nFunzione di Ripartizione (CDF)\",\n    subtitle = \"Distribuzione Normale Standard\",\n    x = \"Valori di θ\",\n    y = \"Densità / Probabilità Cumulativa\"\n  )\n\n\n\n\n\n\n\nIn conclusione, la funzione di ripartizione è uno strumento essenziale per comprendere e lavorare con variabili casuali continue. Essa non solo fornisce una rappresentazione cumulativa della probabilità, ma permette anche di calcolare probabilità per intervalli e di collegare la PDF alla distribuzione complessiva della variabile. Attraverso la sua relazione con la PDF, la funzione di ripartizione offre un ponte tra la descrizione locale (densità) e quella globale (probabilità cumulativa) di una variabile casuale continua.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_prob_distributions.html#interpretazioni-bayesiana-e-frequentista-della-pdf",
    "href": "chapters/probability/08_prob_distributions.html#interpretazioni-bayesiana-e-frequentista-della-pdf",
    "title": "32  Distribuzioni di massa e di densità",
    "section": "\n32.9 Interpretazioni Bayesiana e Frequentista della PDF",
    "text": "32.9 Interpretazioni Bayesiana e Frequentista della PDF\nIn questo capitolo, abbiamo introdotto la funzione di densità di probabilità come limite del profilo di un istogramma, una descrizione intuitiva e utile per comprendere il concetto di densità. Questa interpretazione corrisponde, tuttavia, alla visione frequentista della densità di probabilità. Nella statistica Bayesiana, l’interpretazione è diversa e merita una spiegazione separata.\n\n32.9.1 Interpretazione Frequentista\nConcetto di ripetizione degli esperimenti:\n\nIdea di frequenza relativa:\nNel paradigma frequentista la probabilità è intesa come il limite della frequenza relativa di un evento ottenuto al ripetere un esperimento un numero molto elevato di volte. Immaginiamo di eseguire un esperimento molte volte, ad ogni ripetizione si ottiene un valore di \\(x\\). Se costruiamo un istogramma di questi valori, questo istogramma diventa sempre più “liscio” man mano che il numero delle ripetizioni aumenta, fino a convergere alla PDF \\(p(x)\\).\nPDF come istogramma limite:\nLa PDF rappresenta la distribuzione dei valori osservati in una serie di ripetizioni dell’esperimento. In altre parole, essa descrive quanto frequentemente, in una ipotetica serie infinita di esperimenti, il valore \\(x\\) assume un determinato intervallo.\nEsempio intuitivo:\nSe misuriamo l’altezza degli individui in una popolazione, nel contesto frequentista, la PDF ci dice quale frazione di individui cade in un certo intervallo di altezza se potessimo misurare ogni possibile individuo (o eseguire ripetutamente misurazioni indipendenti in una popolazione “ideale”).\n\n32.9.2 Interpretazione Bayesiana\nConcetto di incertezza e credenza:\n\n\nParametro come variabile casuale:\nIn statistica bayesiana, i parametri non sono visti come quantità fisse, ma come incerti. Si assume che ogni parametro (o dato osservato) abbia una propria distribuzione che riflette la nostra incertezza su di esso.\n\nAd esempio, se stiamo stimando un parametro \\(\\theta\\) (ad esempio la media di una distribuzione), in un approccio bayesiano attribuiamo a \\(\\theta\\) una distribuzione di probabilità che esprime quanto sia plausibile ciascun valore di \\(\\theta\\), dati i dati osservati e le nostre conoscenze pregresse.\n\n\n\nPDF come distribuzione di credenze:\nLa PDF, in questo contesto, non descrive una frequenza relativa osservabile sperimentalmente (perché l’esperimento non viene ripetuto infinite volte, o perché \\(x\\) è un valore fisso ma incerto), ma esprime il grado di fiducia o la plausibilità che il valore “vero” di \\(x\\) (o di un parametro) si trovi in un certo intervallo.\n\nÈ come “spalmare” la nostra incertezza su tutti i valori possibili: la sfumatura lungo l’asse \\(x\\) rappresenta la distribuzione delle nostre credenze.\n\n\nAnalogia con la densità di materia:\nUn’utile analogia è quella della densità di materia \\(\\rho(x)\\) in meccanica classica: la densità non descrive la posizione precisa di ogni atomo, ma come la materia (o, in questo caso, la probabilità) è distribuita lungo l’asse \\(x\\). Allo stesso modo, in una PDF bayesiana, non sono i “valori di \\(x\\)” ad essere distribuiti (in termini di frequenza osservabile), ma è la nostra “incertezza” a essere distribuita sui possibili valori.\nEsempio intuitivo:\nImmagina di dover stimare la probabilità che una certa ipotesi sia vera, ad esempio la media dell’altezza in una popolazione. Invece di pensare a misurazioni ripetute, consideri il valore medio come fisso ma incerto. La PDF bayesiana esprime il grado di credenza per ciascun possibile valore della media, in base ai dati raccolti e alle informazioni a priori.\n\n32.9.3 Confronto\n\n\nFrequentista:\n\n\nFocus: Distribuzione dei dati.\n\nInterpretazione: La PDF descrive come i valori di \\(x\\) sarebbero distribuiti se ripetessimo l’esperimento infinite volte.\n\nEsempio: L’istogramma dei dati osservati in una lunga serie di esperimenti.\n\n\n\nBayesiano:\n\n\nFocus: Distribuzione della nostra incertezza o credenza.\n\nInterpretazione: La PDF riflette quanto sia plausibile ciascun valore di \\(x\\) (o di un parametro) dato l’informazione disponibile, senza necessità di ripetere l’esperimento.\n\nEsempio: La distribuzione a posteriori di un parametro dopo aver combinato dati osservati e informazioni a priori.\n\n\n\n\n\n\n\n\nFigura 32.1: Interpretazioni frequentista e bayesiana di una PDF (curva blu) per una quantità reale \\(x\\). A sinistra: interpretazione frequentista come istogramma limite dei valori di \\(x\\) nelle ripetizioni; i valori di \\(x\\) sono distribuiti secondo la PDF. A destra: interpretazione bayesiana, con \\(x\\) che assume un valore fisso ma incerto per il caso specifico (rappresentato dal punto sull’asse \\(x\\)), con la probabilità distribuita sui valori possibili (raffigurata con una sfumatura lungo l’asse \\(x\\)). (Figura tratta da Loredo & Wolpert, 2024)\n\n\nIn sintesi, questa distinzione tra interpretazioni non è solo una questione di semantica, ma ha implicazioni pratiche nella formulazione di modelli statistici e nell’interpretazione dei risultati. Mentre l’approccio frequentista è spesso utilizzato quando si può concettualmente pensare a ripetizioni infinite dell’esperimento, l’approccio bayesiano è particolarmente utile quando si vuole esprimere e aggiornare la propria incertezza su una quantità basandosi sia su dati che su conoscenze pregresse.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_prob_distributions.html#riflessioni-conclusive",
    "href": "chapters/probability/08_prob_distributions.html#riflessioni-conclusive",
    "title": "32  Distribuzioni di massa e di densità",
    "section": "\n32.10 Riflessioni Conclusive",
    "text": "32.10 Riflessioni Conclusive\nLa funzione di densità di probabilità (PDF) costituisce il fondamento per la descrizione delle variabili casuali continue, consentendo di associare le probabilità ad intervalli, tramite il calcolo dell’area sottesa alla curva. In questo contesto, la probabilità di osservare un valore esatto risulta zero, non per impossibilità dell’evento, ma perché in un insieme continuo ogni singolo punto contribuisce con un’area infinitesimale.\nIl paradosso apparente, secondo cui la somma di infiniti contributi nulli porta a una probabilità totale positiva, si risolve grazie alla teoria dell’integrazione. Integrando i contributi infinitesimali lungo un intervallo, si ottiene una quantità finita che rappresenta la probabilità complessiva dell’evento. Un’interpretazione alternativa, fornita dalla teoria degli infinitesimi di Abraham Robinson, consente di attribuire a tali eventi probabilità infinitesimali, distinguendo tra diverse “grandezze” e chiarendo ulteriormente il processo di aggregazione verso un valore unitario.\nNel campo della data science, le distribuzioni di probabilità—formalmente rappresentate da \\(p(x)\\)—sono strumenti indispensabili per modellare la variabilità osservabile in una popolazione. Queste distribuzioni non mirano a riprodurre in maniera dettagliata ogni aspetto della realtà, ma offrono un modello semplificato che consente di generalizzare i dati osservati e di formulare previsioni rigorose sui fenomeni futuri. In altre parole, \\(p(x)\\) non rappresenta la popolazione nel suo complesso, bensì un’astrazione matematica che cattura l’incertezza e la variabilità del fenomeno studiato.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_prob_distributions.html#esercizi",
    "href": "chapters/probability/08_prob_distributions.html#esercizi",
    "title": "32  Distribuzioni di massa e di densità",
    "section": "\n32.11 Esercizi",
    "text": "32.11 Esercizi\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nEsercizio 1: Variabili Casuali Discrete e Continue\nUtilizzando i dati raccolti sulla Satisfaction with Life Scale (SWLS) e sulla Scala della Rete Sociale di Lubben a 6 item (LSNS-6), classifica le seguenti variabili come discrete o continue:\n\nIl punteggio totale della SWLS.\nIl numero di amici con cui uno studente si sente a proprio agio nel parlare di questioni personali.\nIl tempo (in minuti) che uno studente trascorre con amici durante una settimana.\nIl numero di volte che uno studente ha contattato un parente nell’ultimo mese.\nIl livello di soddisfazione della vita misurato su una scala da 1 a 7.\n\nSpiega il motivo della tua classificazione per ciascuna variabile.\nEsercizio 2: Distribuzioni di Probabilità Discrete\nConsideriamo la distribuzione del numero di amici con cui uno studente si sente a proprio agio nel parlare di questioni personali, misurata attraverso la LSNS-6. Supponiamo che la distribuzione sia la seguente (ma nell’esercizio usa le frequenze relative trovate nel campione di dati raccolto):\n\n\nNumero di amici\nProbabilità\n\n\n\n0\n0.05\n\n\n1\n0.15\n\n\n2\n0.25\n\n\n3\n0.30\n\n\n4\n0.15\n\n\n5\n0.10\n\n\n\n\nVerifica che questa sia una distribuzione di probabilità valida.\nQual è la probabilità che uno studente abbia almeno 3 amici con cui si sente a proprio agio nel parlare di questioni personali?\nQual è la probabilità che abbia meno di 2 amici?\nCalcola il valore atteso (media) e la varianza di questa distribuzione.\n\nEsercizio 3: Distribuzioni di Probabilità Continue\nIl punteggio totale della SWLS può essere approssimato da una distribuzione normale con media 20 e deviazione standard 5.\n\nQual è la probabilità che un individuo scelto a caso abbia un punteggio superiore a 25?\nQual è la probabilità che un individuo abbia un punteggio compreso tra 15 e 25?\nQual è il valore del punteggio che delimita il 10% superiore della distribuzione?\n\n(Suggerimento: utilizza la funzione di ripartizione della distribuzione normale standard per calcolare queste probabilità.)\nEsercizio 4: Legge della Probabilità Totale\nSi sa che il 60% degli studenti proviene da un ambiente con un forte supporto sociale, mentre il 40% ha un supporto sociale limitato. Inoltre, si sa che: - La probabilità che uno studente con forte supporto sociale abbia un punteggio SWLS superiore a 20 è 0.75. - La probabilità che uno studente con supporto sociale limitato abbia un punteggio SWLS superiore a 20 è 0.50.\nQual è la probabilità che uno studente scelto a caso abbia un punteggio SWLS superiore a 20?\nEsercizio 5: Teorema di Bayes e Supporto Sociale\nRiprendendo l’esercizio precedente, calcola la probabilità che uno studente provenga da un ambiente con forte supporto sociale dato che il suo punteggio SWLS è superiore a 20.\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\nEsercizio 1: Variabili Casuali Discrete e Continue\nUtilizzando i dati raccolti sulla Satisfaction with Life Scale (SWLS) e sulla Scala della Rete Sociale di Lubben a 6 item (LSNS-6), classifica le seguenti variabili come discrete o continue:\n\nIl punteggio totale della SWLS. (Continuo)\nIl numero di amici con cui uno studente si sente a proprio agio nel parlare di questioni personali. (Discreto)\nIl tempo (in minuti) che uno studente trascorre con amici durante una settimana. (Continuo)\nIl numero di volte che uno studente ha contattato un parente nell’ultimo mese. (Discreto)\nIl livello di soddisfazione della vita misurato su una scala da 1 a 7. (Discreto)\n\nEsercizio 2: Distribuzioni di Probabilità Discrete\nConsideriamo la distribuzione del numero di amici con cui uno studente si sente a proprio agio nel parlare di questioni personali, misurata attraverso la LSNS-6. Supponiamo che la distribuzione sia la seguente:\n\n\nNumero di amici\nProbabilità\n\n\n\n0\n0.05\n\n\n1\n0.15\n\n\n2\n0.25\n\n\n3\n0.30\n\n\n4\n0.15\n\n\n5\n0.10\n\n\n\n\n\nVerifica della distribuzione: La somma delle probabilità deve essere 1:\n\\[ 0.05 + 0.15 + 0.25 + 0.30 + 0.15 + 0.10 = 1.00 \\]\nPoiché la somma è 1, la distribuzione è valida.\n\n\nProbabilità di almeno 3 amici:\n\\[ P(X \\geq 3) = P(3) + P(4) + P(5) = 0.30 + 0.15 + 0.10 = 0.55 \\]\n\n\nProbabilità di meno di 2 amici:\n\\[ P(X &lt; 2) = P(0) + P(1) = 0.05 + 0.15 = 0.20 \\]\n\n\nValore atteso e varianza:\n\\[ E(X) = \\sum x P(x) = (0 \\times 0.05) + (1 \\times 0.15) + (2 \\times 0.25) + (3 \\times 0.30) + (4 \\times 0.15) + (5 \\times 0.10) = 2.65 \\]\n\\[ Var(X) = E(X^2) - (E(X))^2 \\]\n\\[ E(X^2) = (0^2 \\times 0.05) + (1^2 \\times 0.15) + (2^2 \\times 0.25) + (3^2 \\times 0.30) + (4^2 \\times 0.15) + (5^2 \\times 0.10) = 8.05 \\]\n\\[ Var(X) = 8.05 - (2.65)^2 = 1.06 \\]\n\n\nEsercizio 3: Distribuzioni di Probabilità Continue\nIl punteggio totale della SWLS può essere approssimato da una distribuzione normale con media 20 e deviazione standard 5.\n\n\nProbabilità che il punteggio sia superiore a 25:\n\\[ P(X &gt; 25) = 1 - P(X \\leq 25) \\]\nStandardizziamo:\n\\[ Z = \\frac{25 - 20}{5} = 1 \\]\nUsando le tabelle della distribuzione normale:\n\\[ P(Z \\leq 1) = 0.8413 \\Rightarrow P(X &gt; 25) = 1 - 0.8413 = 0.1587 \\]\n\n\nProbabilità che il punteggio sia tra 15 e 25:\n\\[ P(15 \\leq X \\leq 25) = P(Z \\leq 1) - P(Z \\leq -1) \\]\n\\[ = 0.8413 - 0.1587 = 0.6826 \\]\n\n\nPercentile 90 della distribuzione:\nIl valore di Z per il 90% è 1.28.\n\\[ X = 20 + (1.28 \\times 5) = 26.4 \\]\n\n\nEsercizio 4: Legge della Probabilità Totale\n\\[ P(SWLS &gt; 20) = P(SWLS &gt; 20 | S) P(S) + P(SWLS &gt; 20 | \\neg S) P(\\neg S) \\]\n\\[ = (0.75 \\times 0.60) + (0.50 \\times 0.40) \\]\n\\[ = 0.45 + 0.20 = 0.65 \\]\nEsercizio 5: Teorema di Bayes e Supporto Sociale\n\\[ P(S | SWLS &gt; 20) = \\frac{P(SWLS &gt; 20 | S) P(S)}{P(SWLS &gt; 20)} \\]\n\\[ = \\frac{(0.75 \\times 0.60)}{0.65} \\]\n\\[ = \\frac{0.45}{0.65} = 0.6923 \\]\nQuindi, la probabilità che uno studente provenga da un ambiente con forte supporto sociale dato che il suo punteggio SWLS è superiore a 20 è circa 69.2%.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_prob_distributions.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/08_prob_distributions.html#informazioni-sullambiente-di-sviluppo",
    "title": "32  Distribuzioni di massa e di densità",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.7   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.13.0 psych_2.5.3     \n#&gt;  [9] scales_1.4.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.3.0     ggplot2_3.5.2   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.4     stringi_1.8.7      lattice_0.22-7    \n#&gt;  [4] hms_1.1.3          digest_0.6.37      magrittr_2.0.3    \n#&gt;  [7] evaluate_1.0.4     grid_4.5.0         timechange_0.3.0  \n#&gt; [10] RColorBrewer_1.1-3 fastmap_1.2.0      rprojroot_2.0.4   \n#&gt; [13] jsonlite_2.0.0     mnormt_2.1.1       cli_3.6.5         \n#&gt; [16] rlang_1.1.6        withr_3.0.2        yaml_2.3.10       \n#&gt; [19] tools_4.5.0        parallel_4.5.0     tzdb_0.5.0        \n#&gt; [22] pacman_0.5.1       vctrs_0.6.5        R6_2.6.1          \n#&gt; [25] lifecycle_1.0.4    htmlwidgets_1.6.4  pkgconfig_2.0.3   \n#&gt; [28] pillar_1.10.2      gtable_0.3.6       glue_1.8.0        \n#&gt; [31] xfun_0.52          tidyselect_1.2.1   rstudioapi_0.17.1 \n#&gt; [34] farver_2.1.2       htmltools_0.5.8.1  nlme_3.1-168      \n#&gt; [37] labeling_0.4.3     rmarkdown_2.29     compiler_4.5.0",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_prob_distributions.html#bibliografia",
    "href": "chapters/probability/08_prob_distributions.html#bibliografia",
    "title": "32  Distribuzioni di massa e di densità",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.\n\n\nLoredo, T. J., & Wolpert, R. L. (2024). Bayesian inference: more than Bayes’s theorem. Frontiers in Astronomy and Space Sciences, 11, 1326926.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Distribuzioni di massa e di densità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_expval_var.html",
    "href": "chapters/probability/09_expval_var.html",
    "title": "33  Proprietà delle variabili casuali",
    "section": "",
    "text": "33.1 Introduzione\nÈ spesso molto utile sintetizzare la distribuzione di una variabile casuale attraverso indicatori caratteristici. Questi indicatori consentono di cogliere le principali proprietà della distribuzione, come la posizione centrale (ovvero il “baricentro”) e la variabilità (ossia la dispersione attorno al centro). In questo modo, è possibile ottenere una descrizione sintetica e significativa della distribuzione di probabilità della variabile casuale.\nIn questo capitolo, introdurremo i concetti fondamentali di valore atteso e varianza di una variabile casuale, che sono strumenti essenziali per comprendere e riassumere le proprietà di una distribuzione probabilistica.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_expval_var.html#tendenza-centrale",
    "href": "chapters/probability/09_expval_var.html#tendenza-centrale",
    "title": "33  Proprietà delle variabili casuali",
    "section": "\n33.2 Tendenza Centrale",
    "text": "33.2 Tendenza Centrale\nQuando vogliamo comprendere il comportamento tipico di una variabile casuale, ci interessa spesso determinare il suo “valore tipico”. Tuttavia, questa nozione può essere interpretata in diversi modi:\n\n\nMedia: La somma dei valori divisa per il numero dei valori.\n\nMediana: Il valore centrale della distribuzione, quando i dati sono ordinati in senso crescente o decrescente.\n\nModa: Il valore che si verifica con maggiore frequenza.\n\nAd esempio, per il set di valori \\(\\{3, 1, 4, 1, 5\\}\\), la media è \\(\\frac{3+1+4+1+5}{5} = 2.8\\), la mediana è 3, e la moda è 1. Tuttavia, quando ci occupiamo di variabili casuali, anziché di semplici sequenze di numeri, diventa necessario chiarire cosa intendiamo per “valore tipico” in questo contesto. Questo ci porta alla definizione formale del valore atteso.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_expval_var.html#valore-atteso",
    "href": "chapters/probability/09_expval_var.html#valore-atteso",
    "title": "33  Proprietà delle variabili casuali",
    "section": "\n33.3 Valore Atteso",
    "text": "33.3 Valore Atteso\n\nDefinizione 33.1 Sia \\(X\\) una variabile casuale discreta che assume i valori \\(x_1, \\dots, x_n\\) con probabilità \\(P(X = x_i) = p(x_i)\\). Il valore atteso di \\(X\\), denotato con \\(\\mathbb{E}(X)\\), è definito come:\n\\[\n\\mathbb{E}(X) = \\sum_{i=1}^n x_i \\cdot p(x_i).\n\\]\n\nIn altre parole, il valore atteso (noto anche come speranza matematica o aspettazione) di una variabile casuale è la somma di tutti i valori che la variabile può assumere, ciascuno ponderato dalla probabilità con cui esso si verifica.\n\nEsempio 33.1 Calcoliamo il valore atteso della variabile casuale \\(X\\) corrispondente al lancio di una moneta equilibrata, dove testa corrisponde a \\(X = 1\\) e croce corrisponde a \\(X = 0\\):\n\\[\n\\mathbb{E}(X) = \\sum_{i=1}^{2} x_i \\cdot P(x_i) = 0 \\cdot \\frac{1}{2} + 1 \\cdot \\frac{1}{2} = 0.5.\n\\]\n\n\nEsempio 33.2 Calcoliamo il valore atteso della variabile casuale \\(X\\) che rappresenta la somma dei punti ottenuti dal lancio di due dadi equilibrati a sei facce.\nLa variabile casuale \\(X\\) può assumere i seguenti valori:\n\\[\n\\{2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\\}.\n\\]\nLa probabilità associata a ciascun valore è data dalla distribuzione di massa di probabilità. Ad esempio, il valore \\(X = 2\\) si ottiene solo se entrambi i dadi mostrano 1, quindi ha probabilità:\n\\[\nP(X = 2) = \\frac{1}{36}.\n\\]\nAnalogamente, \\(X = 7\\) può essere ottenuto con sei combinazioni diverse: (1,6), (2,5), (3,4), (4,3), (5,2), (6,1), quindi:\n\\[\nP(X = 7) = \\frac{6}{36}.\n\\]\nLa distribuzione di massa di probabilità completa è:\n\\[\nP(X) = \\left\\{\\frac{1}{36}, \\frac{2}{36}, \\frac{3}{36}, \\frac{4}{36}, \\frac{5}{36}, \\frac{6}{36}, \\frac{5}{36}, \\frac{4}{36}, \\frac{3}{36}, \\frac{2}{36}, \\frac{1}{36}\\right\\}.\n\\]\nIl valore atteso \\(\\mathbb{E}[X]\\) è definito come:\n\\[\n\\mathbb{E}[X] = \\sum_{x} x \\cdot P(X = x).\n\\]\nApplicando questa formula:\n\\[\n\\mathbb{E}[X] = 2 \\cdot \\frac{1}{36} + 3 \\cdot \\frac{2}{36} + 4 \\cdot \\frac{3}{36} + \\cdots + 12 \\cdot \\frac{1}{36} = 7.\n\\]\nEcco come calcolarlo utilizzando R:\n\n# Valori di X e le loro probabilità\nvalori &lt;- 2:12\nprob &lt;- c(1, 2, 3, 4, 5, 6, 5, 4, 3, 2, 1) / 36\n\n# Calcolo del valore atteso\nvalore_atteso &lt;- sum(valori * prob)\nvalore_atteso\n#&gt; [1] 7\n\nIl risultato sarà: \\[\n\\mathbb{E}[X] = 7.\n\\]\nPer rappresentare graficamente la distribuzione di massa di probabilità:\n\n# Creazione di un data frame\ndati &lt;- data.frame(Valore = valori, Probabilità = prob)\n\n# Plot\nggplot(dati, aes(x = Valore, y = Probabilità)) +\n  geom_col(fill = \"lightblue\") +\n  labs(\n    title = \"Distribuzione di Massa di Probabilità per X\",\n    x = \"Valore della Somma (X)\",\n    y = \"Probabilità\"\n  ) \n\n\n\n\n\n\n\n\n\n33.3.1 Interpretazione\nNel suo Ars conjectandi, Bernoulli introduce la nozione di valore atteso con le seguenti parole:\n\nil termine “aspettativa” non deve essere inteso nel suo significato comune […], bensì come la speranza di ottenere il meglio diminuita dalla paura di ottenere il peggio. Pertanto, il valore della nostra aspettativa rappresenta sempre qualcosa di intermedio tra il meglio che possiamo sperare e il peggio che possiamo temere (Hacking, 2006).\n\nIn termini moderni, questa intuizione può essere rappresentata in modo più chiaro attraverso una simulazione. Possiamo affermare, infatti, che il valore atteso di una variabile casuale corrisponde alla media aritmetica di un gran numero di realizzazioni indipendenti della variabile stessa.\nPer fare un esempio concreto, consideriamo nuovamente il caso del lancio di due dadi bilanciati a sei facce, dove la variabile casuale \\(X\\) rappresenta la “somma dei due dadi”. Simuliamo un numero elevato di realizzazioni indipendenti di \\(X\\).\n\nset.seed(123)  \nx_samples &lt;- sample(valori, size = 1e6, replace = TRUE, prob = prob)\n\nL’istruzione sample(x, size = 1e6, replace = TRUE, prob = px)) utilizza R per generare un array di 1.000.000 di elementi (specificato dal parametro size), selezionati casualmente dall’array x secondo le probabilità specificate nell’array px.\nQuando il numero di realizzazioni indipendenti è sufficientemente grande, la media aritmetica dei campioni generati si avvicina al valore atteso della variabile casuale:\n\nmean(x_samples)\n#&gt; [1] 6.998\n\nQuesto risultato conferma che il valore atteso \\(\\mathbb{E}[X] = 7\\) rappresenta la somma media dei punti ottenuti nel lancio di due dadi equilibrati su un numero elevato di prove. Anche se ogni singola somma può variare tra 2 e 12, in media ci aspettiamo una somma di 7.\nL’aspettativa può anche essere interpretata come un centro di massa. Immagina che delle masse puntiformi con pesi \\(p_1, p_2, \\dots, p_n\\) siano posizionate alle posizioni \\(x_1, x_2, \\dots, x_n\\) sulla retta reale. Il centro di massa—il punto in cui i pesi sono bilanciati—è dato da:\n\\[\n\\text{centro di massa} = x_1 p_1 + x_2 p_2 + \\dots + x_n p_n,\n\\]\nche corrisponde esattamente all’aspettativa della variabile discreta \\(X\\), che assume valori \\(x_1, \\dots, x_n\\) con probabilità \\(p_1, \\dots, p_n\\). Una conseguenza ovvia di questa interpretazione è che, per una funzione di densità di probabilità (pdf) simmetrica, l’aspettativa coincide con il punto di simmetria (a patto che l’aspettativa esista).\n\n\n\n\n\nFigura 33.1: L’aspettativa come centro di massa (figura tratta da Chan & Kroese, 2025).\n\n\n\n33.3.2 Proprietà del Valore Atteso\nUna delle proprietà più importanti del valore atteso è la sua linearità: il valore atteso della somma di due variabili casuali è uguale alla somma dei loro rispettivi valori attesi:\n\\[\n\\mathbb{E}(X + Y) = \\mathbb{E}(X) + \\mathbb{E}(Y).\n\\tag{33.1}\\]\nQuesta proprietà, espressa dalla formula sopra, è intuitiva quando \\(X\\) e \\(Y\\) sono variabili casuali indipendenti, ma è valida anche nel caso in cui \\(X\\) e \\(Y\\) siano correlate.\nInoltre, se moltiplichiamo una variabile casuale per una costante \\(c\\), il valore atteso del prodotto è uguale alla costante moltiplicata per il valore atteso della variabile casuale:\n\\[\n\\mathbb{E}(cY) = c \\mathbb{E}(Y).\n\\tag{33.2}\\]\nQuesta proprietà ci dice che una costante può essere “estratta” dall’operatore di valore atteso, e si applica a qualunque numero di variabili casuali.\nUn’altra proprietà significativa riguarda il prodotto di variabili casuali indipendenti. Se \\(X\\) e \\(Y\\) sono indipendenti, allora il valore atteso del loro prodotto è uguale al prodotto dei loro valori attesi:\n\\[\n\\mathbb{E}(XY) = \\mathbb{E}(X) \\mathbb{E}(Y).\n\\tag{33.3}\\]\nInfine, consideriamo la media aritmetica \\(\\bar{X} = \\frac{X_1 + \\ldots + X_n}{n}\\) di \\(n\\) variabili casuali indipendenti con la stessa distribuzione e con valore atteso \\(\\mu\\). Il valore atteso della media aritmetica è:\n\\[\n\\mathbb{E}(\\bar{X}) = \\frac{1}{n} \\left(\\mathbb{E}(X_1) + \\dots + \\mathbb{E}(X_n)\\right) = \\frac{1}{n} \\cdot n \\cdot \\mathbb{E}(X) = \\mu.\n\\]\nQuesto risultato conferma che la media aritmetica di un campione di variabili casuali indipendenti ha lo stesso valore atteso della distribuzione originaria, rendendo il valore atteso uno strumento cruciale per l’analisi statistica e probabilistica.\n\nEsempio 33.3 Consideriamo il seguente esperimento casuale. Sia \\(Y\\) il numero che si ottiene dal lancio di un dado equilibrato a sei facce e \\(Y\\) il numero di teste prodotto dal lancio di una moneta equilibrata (0 oppure 1). Troviamo il valore atteso di \\(X+Y\\).\nPer risolvere il problema iniziamo a costruire lo spazio campione dell’esperimento casuale.\n\n\n\n\n\n\n\n\n\n\n\n\\(x /\\ y\\)\n1\n2\n3\n4\n5\n6\n\n\n\n0\n(0, 1)\n(0, 2)\n(0, 3)\n(0, 4)\n(0, 5)\n(0, 6)\n\n\n1\n(1, 1)\n(1, 2)\n(1, 3)\n(1, 4)\n(1, 5)\n(1, 6)\n\n\n\novvero\n\n\n\\(x /\\ y\\)\n1\n2\n3\n4\n5\n6\n\n\n\n0\n1\n2\n3\n4\n5\n6\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\nIl risultato del lancio del dado è indipendente dal risultato del lancio della moneta. Pertanto, ciascun evento elementare dello spazio campione avrà la stessa probabilità di verificarsi, ovvero \\(P(\\omega) = \\frac{1}{12}\\). Il valore atteso di \\(X+Y\\) è dunque uguale a:\n\\[\n\\mathbb{E}(X+Y) = 1 \\cdot \\frac{1}{12} + 2 \\cdot \\frac{1}{12} + \\dots + 7 \\cdot \\frac{1}{12} = 4.0.\n\\]\nSi ottiene lo stesso risultato usando l’Equazione 33.1:\n\\[\n\\mathbb{E}(X+Y) = \\mathbb{E}(X) + E(Y) = 3.5 + 0.5 = 4.0.\n\\]\n\n\nEsempio 33.4 Svolgiamo ora l’esercizio in R\n\ncoin &lt;- 0:1  # Valori della moneta: testa (0) e croce (1)\ndie &lt;- 1:6   # Valori del dado: da 1 a 6\n\n# Creazione del campione come combinazione di valori (moneta, dado)\nsample &lt;- expand.grid(coin = coin, die = die)\nprint(sample)\n#&gt;    coin die\n#&gt; 1     0   1\n#&gt; 2     1   1\n#&gt; 3     0   2\n#&gt; 4     1   2\n#&gt; 5     0   3\n#&gt; 6     1   3\n#&gt; 7     0   4\n#&gt; 8     1   4\n#&gt; 9     0   5\n#&gt; 10    1   5\n#&gt; 11    0   6\n#&gt; 12    1   6\n\n\npx &lt;- numeric()  # Vettore per memorizzare le probabilità\n\nfor (i in 1:7) {\n  # Filtrare le combinazioni in cui la somma è uguale a 'i'\n  event &lt;- subset(sample, coin + die == i)\n  # Calcolare la probabilità\n  prob &lt;- nrow(event) / nrow(sample)\n  px &lt;- c(px, prob)\n  \n  # Stampare la probabilità\n  cat(sprintf(\"P(X + Y = %d) = %d / %d\\n\", i, nrow(event), nrow(sample)))\n}\n#&gt; P(X + Y = 1) = 1 / 12\n#&gt; P(X + Y = 2) = 2 / 12\n#&gt; P(X + Y = 3) = 2 / 12\n#&gt; P(X + Y = 4) = 2 / 12\n#&gt; P(X + Y = 5) = 2 / 12\n#&gt; P(X + Y = 6) = 2 / 12\n#&gt; P(X + Y = 7) = 1 / 12\n\n\nx &lt;- 1:7  # Valori della variabile casuale (somma di moneta e dado)\nexpected_value &lt;- sum(x * px)\nexpected_value\n#&gt; [1] 4\n\n\n\nEsempio 33.5 Consideriamo le variabili casuali \\(X\\) e \\(Y\\) definite nel caso del lancio di tre monete equilibrate, dove \\(X\\) conta il numero delle teste nei tre lanci e \\(Y\\) conta il numero delle teste al primo lancio. Si calcoli il valore atteso di \\(Z = X \\cdot Y\\).\nLa distribuzione di probabilità congiunta \\(P(X, Y)\\) è fornita nella tabella seguente.\n\n\n\\(x /\\ y\\)\n0\n1\n\\(p(Y)\\)\n\n\n\n0\n1/8\n0\n1/8\n\n\n1\n2/8\n1/8\n3/8\n\n\n2\n1/8\n2/8\n3/8\n\n\n3\n0\n1/8\n1/8\n\n\n\\(p(y)\\)\n4/8\n4/8\n1.0\n\n\n\nIl calcolo del valore atteso di \\(XY\\) si riduce a\n\\[\n\\mathbb{E}(Z) = 1 \\cdot \\frac{1}{8} + 2 \\cdot \\frac{2}{8} + 3 \\cdot \\frac{1}{8} = 1.0.\n\\]\nSi noti che le variabili casuali \\(Y\\) e \\(Y\\) non sono indipendenti. Dunque non possiamo usare l’Equazione 33.3. Infatti, il valore atteso di \\(X\\) è\n\\[\n\\mathbb{E}(X) = 1 \\cdot \\frac{3}{8} + 2 \\cdot \\frac{3}{8} + 3 \\cdot \\frac{1}{8} = 1.5\n\\]\ne il valore atteso di \\(Y\\) è\n\\[\n\\mathbb{E}(Y) = 0 \\cdot \\frac{4}{8} + 1 \\cdot \\frac{4}{8} = 0.5.\n\\]\nPerciò\n\\[\n1.5 \\cdot 0.5 \\neq 1.0.\n\\]\n\n\n33.3.3 Variabili casuali continue\nNel caso di una variabile casuale continua \\(X\\), il valore atteso è definito come:\n\\[\n\\mathbb{E}(X) = \\int_{-\\infty}^{+\\infty} x \\cdot p(x) \\, \\mathrm{d}x.\n\\]\nAnche in questo contesto, il valore atteso rappresenta una media ponderata dei valori di \\(x\\), dove ogni possibile valore di \\(x\\) è ponderato in base alla densità di probabilità \\(p(x)\\).\nL’integrale può essere interpretato analogamente a una somma continua, in cui \\(x\\) rappresenta la posizione delle barre infinitamente strette di un istogramma, e \\(p(x)\\) rappresenta l’altezza di tali barre. La notazione \\(\\int_{-\\infty}^{+\\infty}\\) indica che si sta sommando il contributo di ogni valore possibile di \\(x\\) lungo l’intero asse reale.\nQuesta interpretazione rende chiaro come l’integrale calcoli una somma ponderata che si estende su tutti i possibili valori di \\(x\\), fornendo una misura centrale della distribuzione della variabile casuale continua. Per ulteriori dettagli sulla notazione dell’integrale, si veda l’?sec-calculus.\n\n33.3.3.1 Moda\nUn’altra misura di tendenza centrale delle variabili casuali continue è la moda. La moda di \\(Y\\) individua il valore \\(y\\) più plausibile, ovvero il valore \\(y\\) che massimizza la funzione di densità \\(p(y)\\):\n\\[\nMo(Y) = \\text{argmax}_y p(y).\n\\tag{33.4}\\]\n\n\n\n\n\n\nLa notazione \\(\\text{argmax}_y p(y)\\) significa: il valore \\(y\\) tale per cui la funzione \\(p(y)\\) assume il suo valore massimo.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_expval_var.html#varianza",
    "href": "chapters/probability/09_expval_var.html#varianza",
    "title": "33  Proprietà delle variabili casuali",
    "section": "\n33.4 Varianza",
    "text": "33.4 Varianza\nDopo il valore atteso, la seconda proprietà più importante di una variabile casuale è la varianza.\n\nDefinizione 33.2 Se \\(X\\) è una variabile casuale discreta con distribuzione \\(p(x)\\), la varianza di \\(X\\), denotata con \\(\\mathbb{V}(X)\\), è definita come:\n\\[\n\\mathbb{V}(X) = \\mathbb{E}\\Big[\\big(X - \\mathbb{E}(X)\\big)^2\\Big].\n\\tag{33.5}\\]\n\nIn altre parole, la varianza misura la deviazione media quadratica dei valori della variabile rispetto alla sua media. Se denotiamo il valore atteso di \\(X\\) con \\(\\mu = \\mathbb{E}(X)\\), la varianza \\(\\mathbb{V}(X)\\) diventa il valore atteso di \\((X - \\mu)^2\\).\n\n33.4.1 Interpretazione della Varianza\nLa varianza rappresenta una misura della “dispersione” dei valori di \\(X\\) intorno al suo valore atteso. Quando calcoliamo la varianza, stiamo effettivamente misurando quanto i valori di \\(X\\) tendono a differire dalla media \\(\\mu\\).\nPer capire meglio, consideriamo la variabile casuale \\(X - \\mathbb{E}(X)\\), detta scarto o deviazione dalla media. Questa variabile rappresenta le “distanze” tra i valori di \\(X\\) e il valore atteso \\(\\mathbb{E}(X)\\). Tuttavia, poiché lo scarto può essere positivo o negativo, la media dello scarto è sempre zero, il che lo rende inadatto a quantificare la dispersione.\nPer risolvere questo problema, eleviamo al quadrato gli scarti, ottenendo \\((X - \\mathbb{E}(X))^2\\), che rende tutte le deviazioni positive. La varianza è quindi la media di questi scarti al quadrato, fornendo una misura efficace della dispersione complessiva dei valori di \\(X\\) rispetto alla sua media.\nQuesto concetto è fondamentale per comprendere la variabilità di una distribuzione e per applicare strumenti statistici che richiedono una conoscenza approfondita della distribuzione dei dati.\n\nEsempio 33.6 Posta \\(S\\) uguale alla somma dei punti ottenuti nel lancio di due dadi equilibrati, si calcoli la varianza di \\(S\\).\nLa variabile casuale \\(S\\) ha la seguente distribuzione di probabilità:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(s\\)\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\\(P(S = s)\\)\n\\(\\frac{1}{36}\\)\n\\(\\frac{2}{36}\\)\n\\(\\frac{3}{36}\\)\n\\(\\frac{4}{36}\\)\n\\(\\frac{5}{36}\\)\n\\(\\frac{6}{36}\\)\n\\(\\frac{5}{36}\\)\n\\(\\frac{4}{36}\\)\n\\(\\frac{3}{36}\\)\n\\(\\frac{2}{36}\\)\n\\(\\frac{1}{36}\\)\n\n\nEssendo \\(\\mathbb{E}(S) = 7\\), la varianza diventa\n\\[\n\\begin{aligned}\n\\mathbb{V}(S) &= \\sum \\left(s - \\mathbb{E}(S)\\right)^2 \\cdot P(s) \\notag\\\\\n&= (2 - 7)^2 \\cdot \\frac{1}{36} + (3-7)^2 \\cdot \\frac{3}{36} + \\dots + (12 - 7)^2 \\cdot \\frac{1}{36} \\notag\\\\\n&= 5.8333.\\notag\n\\end{aligned}\n\\]\n\n\nEsempio 33.7 Svolgiamo l’esercizio in R\n\n# Definire i valori di x e le loro probabilità px\nx &lt;- 2:12\npx &lt;- c(\n  1 / 36, 2 / 36, 3 / 36, 4 / 36, 5 / 36, 6 / 36,\n  5 / 36, 4 / 36, 3 / 36, 2 / 36, 1 / 36\n)\n\n# Calcolare il valore atteso\nex &lt;- sum(x * px)\nex\n#&gt; [1] 7\n\nApplichiamo l’Equazione 33.5:\n\n# Calcolo della varianza utilizzando la definizione\nvariance &lt;- sum((x - ex)^2 * px)\nvariance\n#&gt; [1] 5.833\n\nUsiamo la funzione var() di rv_discrete:\n\n# Calcolo della varianza con pesi\nvariance_check &lt;- weighted.mean((x - ex)^2, w = px)\nvariance_check\n#&gt; [1] 5.833\n\n\n\n33.4.2 Formula Alternativa per la Varianza\nLa varianza di una variabile casuale \\(X\\), indicata come \\(\\mathbb{V}(X)\\), misura la dispersione dei valori attorno alla media. La definizione classica è:\n\\[\n\\mathbb{V}(X) = \\mathbb{E}\\Big[\\big(X - \\mathbb{E}(X)\\big)^2\\Big].\n\\]\nEsiste però una formula alternativa che semplifica il calcolo.\n\nDimostrazione. \n\nEspansione del quadrato\nConsideriamo la varianza, definita come \\(\\mathbb{V}(X) = \\mathbb{E}\\big[(X - \\mathbb{E}(X))^2\\big]\\).\nEspandiamo il quadrato \\((X - \\mathbb{E}(X))^2\\) utilizzando la regola \\((a - b)^2 = a^2 - 2ab + b^2\\): \\[\n(X - \\mathbb{E}(X))^2 = X^2 - 2\\,X\\,\\mathbb{E}(X) + \\big(\\mathbb{E}(X)\\big)^2.\n\\]\nApplicazione dell’aspettativa\nApplichiamo \\(\\mathbb{E}[\\cdot]\\) a ciascun termine, ricordando che l’aspettativa è un operatore lineare: \\[\n\\mathbb{E}\\big[(X - \\mathbb{E}(X))^2\\big]\n= \\mathbb{E}\\big[X^2\\big]\n  \\;-\\; 2 \\,\\mathbb{E}\\big[X\\,\\mathbb{E}(X)\\big]\n  \\;+\\; \\mathbb{E}\\big[\\big(\\mathbb{E}(X)\\big)^2\\big].\n\\]\n\nGestione dei termini costanti\nL’aspettativa \\(\\mathbb{E}(X)\\) è una costante (indipendente da \\(X\\)). Indichiamola con \\(\\mu\\). Quindi:\n\n\n\\(\\mathbb{E}(X^2)\\) resta com’è.\n\n\\(\\mathbb{E}[X \\cdot \\mu] = \\mu \\, \\mathbb{E}[X] = \\mu \\cdot \\mu = \\mu^2\\).\n\n\\(\\mathbb{E}\\big(\\mu^2\\big) = \\mu^2\\).\n\n\n\nSostituzione e semplificazione\nRimpiazzando i risultati nel secondo passaggio si ottiene: \\[\n\\mathbb{E}(X^2) \\;-\\; 2\\,\\mu^2 \\;+\\; \\mu^2\n\\;=\\; \\mathbb{E}(X^2) - \\mu^2.\n\\]\nPoiché \\(\\mu = \\mathbb{E}(X)\\), la varianza può quindi essere scritta come:\n\\[\n\\boxed{\n\\mathbb{V}(X) = \\mathbb{E}(X^2) \\;-\\; \\bigl(\\mathbb{E}(X)\\bigr)^2.\n}\n\\tag{33.6}\\]\n\n\n\nQuesta forma risulta molto utile per ragioni di efficienza computazionale: invece di calcolare gli scarti \\((X - \\mu)\\) per ogni osservazione, è sufficiente trovare \\(\\mathbb{E}(X^2)\\) e poi sottrarre \\(\\mu^2\\). In tal modo si riducono i passaggi intermedi e, di conseguenza, si minimizzano gli errori pratici. Inoltre, nelle dimostrazioni che richiedono manipolazioni algebriche – come quelle tipiche della Teoria Classica dei Test – questa espressione semplifica notevolmente le trasformazioni.\n\nEsempio 33.8 Consideriamo la variabile casuale \\(X\\) che corrisponde al numero di teste che si osservano nel lancio di una moneta truccata con probabilità di testa uguale a 0.8. Si trovi la varianza di \\(Y\\).\nIl valore atteso di \\(X\\) è\n\\[\n\\mathbb{E}(X) = 0 \\cdot 0.2 + 1 \\cdot 0.8 = 0.8.\n\\]\nUsando la formula tradizionale della varianza otteniamo:\n\\[\n\\mathbb{V}(X) = (0 - 0.8)^2 \\cdot 0.2 + (1 - 0.8)^2 \\cdot 0.8 = 0.16.\n\\]\nLo stesso risultato si trova con la formula alternativa della varianza. Il valore atteso di \\(X^2\\) è\n\\[\n\\mathbb{E}(X^2) = 0^2 \\cdot 0.2 + 1^2 \\cdot 0.8 = 0.8.\n\\]\ne la varianza diventa\n\\[\n\\mathbb{V}(X) = \\mathbb{E}(X^2) - \\big(\\mathbb{E}(Y) \\big)^2 = 0.8 - 0.8^2 = 0.16.\n\\]\n\n\nEsempio 33.9 Svolgiamo l’esercizio in R:\n\n# Definire i valori di x e le probabilità px\nx &lt;- c(0, 1)\npx &lt;- c(0.2, 0.8)\n\n# Calcolare il risultato\nresult &lt;- sum(x^2 * px) - (sum(x * px))^2\nresult\n#&gt; [1] 0.16\n\n\n\n33.4.3 Proprietà\nSegno della varianza. La varianza di una variabile aleatoria non è mai negativa, ed è zero solamente quando la variabile assume un solo valore.\nInvarianza per traslazione. La varianza è invariante per traslazione, che lascia fisse le distanze dalla media, e cambia quadraticamente per riscalamento:\n\\[\n\\mathbb{V}(a + bX) = b^2\\mathbb{V}(X).\n\\]\nDimostrazione. Iniziamo a scrivere\n\\[\n(aX+b)-{\\mathbb{E}}[aX+b]=aX+b-a{\\mathbb{E}}[X]-b=a(X-{\\mathbb  {E}}[X]).\n\\]\nQuindi\n\\[\n\\sigma _{{aX+b}}^{2}={\\mathbb{E}}[a^{2}(X-{\\mathbb  {E}}[X])^{2}]=a^{2}\\sigma _{X}^{2}.\n\\]\nEsaminiamo una dimostrazione numerica.\n\n# Definire i valori di x\nx &lt;- c(2, 1, 4, 7)\n\n# Calcolare y\ny &lt;- 100 + 2 * x\n\n# Verificare la relazione tra le varianze\nresult &lt;- var(y) == 2^2 * var(x)\nresult\n#&gt; [1] TRUE\n\nVarianza della somma di due variabili indipendenti. La varianza della somma di due variabili indipendenti o anche solo incorrelate è pari alla somma delle loro varianze:\n\\[\n\\mathbb{V}(X+Y) = \\mathbb{V}(X) + \\mathbb{V}(Y).\n\\]\nDimostrazione. Se \\(\\mathbb{E}(X) = \\mathbb{E}(Y) = 0\\), allora \\(\\mathbb{E}(X+Y) = 0\\) e\n\\[\\mathbb{V}(X+Y) = \\mathbb{E}((X+Y)^2) = \\mathbb{E}(X^2) + 2 \\mathbb{E}(XY) + \\mathbb{E}(Y^2).\\]\nSiccome le variabili sono indipendenti risulta \\(\\mathbb{E}(XY) = \\mathbb{E}(X)\\mathbb{E}(Y) = 0\\).\nVarianza della differenza di due variabili indipendenti. La varianza della differenza di due variabili indipendenti è pari alla somma delle loro varianze:\n\\[\n\\mathbb{V}(X-Y) = \\mathbb{V}(X) + \\mathbb{V}(Y).\n\\]\nDimostrazione.\n\\[\n\\mathbb{V}(X-Y) = \\mathbb{V}(X +(-Y)) = \\mathbb{V}(X) + \\mathbb{V}(-Y) = \\mathbb{V}(X) + \\mathbb{V}(Y).\n\\]\nVarianza della somma di due variabili non indipendenti. Se \\(X\\) e \\(Y\\) non sono indipendenti, la formula viene corretta dalla loro covarianza:\n\\[\n\\mathbb{V}(X+Y) = \\mathbb{V}(X) + \\mathbb{V}(Y) + 2 Cov(X,Y),\n\\]\ndove \\(Cov(X,Y) = \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y)\\).\nUna dimostrazione numerica di questo principio è fornita sotto.\n\n# Definire i valori di x e y\nx &lt;- c(2, 1, 4, 7)\ny &lt;- c(1, 3, 5, 11)\n\n# Calcolare la varianza di x + y con ddof = 0\nvar_x_y &lt;- mean((x + y - mean(x + y))^2)\nvar_x_y\n#&gt; [1] 35.25\n\n\n# Definire i valori di x e y\nx &lt;- c(2, 1, 4, 7)\ny &lt;- c(1, 3, 5, 11)\n\n# Calcolo della varianza combinata\nresult &lt;- mean((x - mean(x))^2) + \n          mean((y - mean(y))^2) + \n          2 * cov(x, y) * (length(x) - 1) / length(x)\nresult\n#&gt; [1] 35.25\n\nVarianza della media di variabili indipendenti. La media aritmetica \\(\\textstyle {\\bar  {X}}={\\frac  {X_{1}+\\ldots +X_{n}}{n}}\\) di \\(n\\) variabili casuali indipendenti aventi la medesima distribuzione, ha varianza\n\\[\n\\mathbb{V}(\\bar{X}) = \\frac{1}{n^2} \\mathbb{V}(X_1)+ \\dots \\mathbb{V}(X_n) = \\frac{1}{n^2} n \\mathbb{V}(X) = \\frac{1}{n} \\mathbb{V}(X).\n\\]\nIl principio precedente è illustrato dalla seguente simulazione.\n\n# Creare la popolazione\nset.seed(123)  # Per riproducibilità\npopulation &lt;- rnorm(10000, mean = 50, sd = 10)\n\n# Definire dimensione del campione e numero di campioni\nsample_size &lt;- 30\nnum_samples &lt;- 100000\n\n# Creare un vettore per memorizzare le medie campionarie\nsample_means &lt;- numeric(num_samples)\n\n# Generare i campioni e calcolare le medie\nfor (i in 1:num_samples) {\n  sample &lt;- sample(population, size = sample_size, replace = TRUE)\n  sample_means[i] &lt;- mean(sample)\n}\n\n# Calcolare la varianza delle medie campionarie\nsampling_dist_mean_var &lt;- var(sample_means) * ((num_samples - 1) / num_samples)  # ddof = 0\nsampling_dist_mean_var\n#&gt; [1] 3.331\n\nIl valore teorico della varianza della distribuzione campionaria della media è\n\n10^2 / 30\n#&gt; [1] 3.333\n\n\n33.4.4 Variabili casuali continue\nPer una variabile casuale continua \\(X\\), la varianza è definita come:\n\\[\n\\mathbb{V}(X) = \\int_{-\\infty}^{+\\infty} \\large[x - \\mathbb{E}(X)\\large]^2 p(x) \\,\\operatorname {d}\\!x.\n\\tag{33.7}\\]\nAnalogamente al caso discreto, la varianza di una variabile casuale continua \\(X\\) una misura della dispersione, ovvero la “distanza” media quadratica attesa dei valori \\(x\\) rispetto alla loro media \\(\\mathbb{E}(X)\\). In altre parole, la varianza quantifica quanto i valori della variabile casuale si discostano tipicamente dal loro valore medio.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_expval_var.html#deviazione-standard",
    "href": "chapters/probability/09_expval_var.html#deviazione-standard",
    "title": "33  Proprietà delle variabili casuali",
    "section": "\n33.5 Deviazione Standard",
    "text": "33.5 Deviazione Standard\nQuando si lavora con le varianze, i valori sono elevati al quadrato, il che può rendere i numeri significativamente più grandi (o più piccoli) rispetto ai dati originali. Per riportare questi valori all’unità di misura della scala originale, si prende la radice quadrata della varianza. Il risultato ottenuto è chiamato deviazione standard ed è comunemente indicato con la lettera greca \\(\\sigma\\).\n\nDefinizione 33.3 La deviazione standard, o scarto quadratico medio, è definita come la radice quadrata della varianza:\n\\[\n\\sigma_X = \\sqrt{\\mathbb{V}(X)}.\n\\tag{33.8}\\]\n\nCome nella statistica descrittiva, la deviazione standard di una variabile casuale fornisce una misura della dispersione, ossia la “distanza” tipica o prevista dei valori \\(x\\) rispetto alla loro media.\n\nEsempio 33.10 Per i dadi equilibrati dell’esempio precedente, la deviazione standard della variabile casuale \\(S\\) è pari a \\(\\sqrt{5.833} = 2.415\\). Questo valore indica quanto i risultati della somma dei due dadi tendono a variare attorno alla loro media.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_expval_var.html#standardizzazione",
    "href": "chapters/probability/09_expval_var.html#standardizzazione",
    "title": "33  Proprietà delle variabili casuali",
    "section": "\n33.6 Standardizzazione",
    "text": "33.6 Standardizzazione\n\nDefinizione 33.4 Data una variabile casuale \\(X\\), si dice variabile standardizzata di \\(X\\) l’espressione\n\\[\nZ = \\frac{X - \\mathbb{E}(X)}{\\sigma_X}.\n\\tag{33.9}\\]\n\nSolitamente, una variabile standardizzata viene denotata con la lettera \\(Z\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_expval_var.html#il-teorema-di-chebyshev",
    "href": "chapters/probability/09_expval_var.html#il-teorema-di-chebyshev",
    "title": "33  Proprietà delle variabili casuali",
    "section": "\n33.7 Il Teorema di Chebyshev",
    "text": "33.7 Il Teorema di Chebyshev\nIl Teorema di Chebyshev ci permette di stimare la probabilità che una variabile aleatoria si discosti dal suo valore atteso (media) di una certa quantità. In altre parole, ci fornisce un limite superiore alla probabilità che una variabile aleatoria assuma valori “estremi”.\nIl teorema di Chebyshev afferma che, per qualsiasi variabile aleatoria X con media E(X) e varianza Var(X), e per qualsiasi numero reale k &gt; 0, si ha:\n\\[\nP(\\mid X - E(X)\\mid \\geq k \\sigma) \\leq 1/k^2,\n\\tag{33.10}\\]\ndove:\n\n\n\\(P(\\mid X - E(X)\\mid \\geq k \\sigma)\\) è la probabilità che lo scarto assoluto tra X e la sua media sia maggiore o uguale a k volte la deviazione standard (σ).\nσ è la radice quadrata della varianza, ovvero la deviazione standard.\n\nCosa ci dice questo teorema?\n\n\nLimite superiore: Il teorema ci fornisce un limite superiore alla probabilità che una variabile aleatoria si discosti dalla sua media di più di k deviazioni standard.\n\nQualsiasi distribuzione: La bellezza di questo teorema è che vale per qualsiasi distribuzione di probabilità, a patto che la media e la varianza esistano.\n\nUtilizzo: Il teorema di Chebyshev è molto utile quando non conosciamo la distribuzione esatta di una variabile aleatoria, ma conosciamo la sua media e la sua varianza.\n\nIn sintesi, il teorema di Chebyshev ci fornisce un limite superiore alla probabilità che una variabile aleatoria si discosti dalla sua media di una certa quantità, in base alla sua varianza. Il teorema di Chebyshev ci permette quindi di fare inferenze sulla distribuzione di una variabile aleatoria anche quando abbiamo informazioni limitate.\n\nEsempio 33.11 Supponiamo di avere una variabile aleatoria \\(X\\) con media 100 e varianza 25. Vogliamo stimare la probabilità che \\(X\\) assuma valori al di fuori dell’intervallo [90, 110].\nIn questo caso, \\(k\\) = 2 (poiché 10 è uguale a 2 volte la deviazione standard, che è 5). Applicando il teorema di Chebyshev, otteniamo:\n\\[\nP(\\mid X - 100 \\mid \\geq 10) \\leq \\left( \\frac{1}{2} \\right)^2 = 0.25\n\\]\nQuindi, possiamo affermare con certezza che al massimo il 25% dei valori di X saranno al di fuori dell’intervallo [90, 110].",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_expval_var.html#momenti-di-variabili-casuali",
    "href": "chapters/probability/09_expval_var.html#momenti-di-variabili-casuali",
    "title": "33  Proprietà delle variabili casuali",
    "section": "\n33.8 Momenti di variabili casuali",
    "text": "33.8 Momenti di variabili casuali\n\nDefinizione 33.5 Si chiama momento di ordine \\(q\\) di una v.c. \\(X\\), dotata di densità \\(p(x)\\), la quantità\n\\[\n\\mathbb{E}(X^q) = \\int_{-\\infty}^{+\\infty} x^q p(x) \\; dx.\n\\tag{33.11}\\]\nSe \\(X\\) è una v.c. discreta, i suoi momenti valgono:\n\\[\n\\mathbb{E}(X^q) = \\sum_i x_i^q P(x_i),\n\\tag{33.12}\\]\ndove:\n\n\n\\(E(X^q)\\) rappresenta il valore atteso di \\(X\\) elevato alla \\(q\\)-esima potenza.\n\n\\(x_i\\) sono i possibili valori della variabile discreta.\n\n\\(P(x_i)\\) è la probabilità associata a ciascun valore discreto.\n\n\nI momenti sono parametri statistici che forniscono informazioni importanti sulle caratteristiche di una variabile casuale. Tra questi, i più noti e utilizzati sono:\n\nIl momento del primo ordine (\\(q\\) = 1): corrisponde al valore atteso (o media) della variabile casuale \\(X\\).\nIl momento del secondo ordine (\\(q\\) = 2): quando calcolato rispetto alla media, corrisponde alla varianza.\n\nPer i momenti di ordine superiore al primo, è comune calcolarli rispetto al valore medio di \\(X\\). Questo si ottiene applicando una traslazione: \\(x_0 = x − \\mathbb{E}(X)\\), dove \\(x_0\\) rappresenta lo scarto dalla media. In particolare, il momento centrale del secondo ordine, calcolato con questa traslazione, corrisponde alla definizione di varianza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_expval_var.html#alcuni-esempi-in-r",
    "href": "chapters/probability/09_expval_var.html#alcuni-esempi-in-r",
    "title": "33  Proprietà delle variabili casuali",
    "section": "\n33.9 Alcuni esempi in R",
    "text": "33.9 Alcuni esempi in R\nIn R, possiamo calcolare il valore atteso e la varianza di variabili casuali discrete utilizzando vettori di valori e probabilità.\nConsideriamo una variabile casuale \\(X\\) che rappresenta i valori ottenuti dal lancio di un dado non equilibrato, con valori possibili da 0 a 6, e con la seguente distribuzione di massa di probabilità: 0.1, 0.2, 0.3, 0.1, 0.1, 0.0, 0.2.\nIniziamo a definire un vettore che contiene i valori della v.c.:\n\nx &lt;- 0:6\nprint(x)\n#&gt; [1] 0 1 2 3 4 5 6\n\nIl vettore px conterrà le probabilità associate ai valori x:\n\npx &lt;- c(0.1, 0.2, 0.3, 0.1, 0.1, 0.0, 0.2)\nprint(px)\n#&gt; [1] 0.1 0.2 0.3 0.1 0.1 0.0 0.2\n\nControlliamo che la somma sia 1:\n\nsum(px)\n#&gt; [1] 1\n\nCalcoliamo il valore atteso di \\(X\\) implementando la formula del valore atteso utilizzando i vettori x e px:\n\nx_ev &lt;- sum(x * px)\nx_ev\n#&gt; [1] 2.7\n\nCalcoliamo la varianza di \\(X\\) usando i vettori x e px:\n\nx_var &lt;- sum((x - x_ev)^2 * px)\nx_var\n#&gt; [1] 3.81\n\nCalcoliamo la deviazione standard di \\(X\\) prendendo la radice quadrata della varianza:\n\nx_sd &lt;- sqrt(x_var)\nx_sd\n#&gt; [1] 1.952\n\nPer rappresentare graficamente la distribuzione di massa, possiamo usare ggplot2:\n\ndf &lt;- data.frame(x = x, pmf = px)\nggplot(df, aes(x = x, y = pmf)) +\n  geom_point(color = \"#832F2B\", size = 3) +\n  geom_segment(aes(xend = x, yend = 0), linewidth = 1) +\n  labs(title = \"Distribuzione di massa di probabilità\", \n       x = \"Valori\", y = \"Probabilità\")\n\n\n\n\n\n\n\nQuesto codice calcola il valore atteso, la varianza e la deviazione standard di una variabile casuale discreta e rappresenta graficamente la distribuzione di massa, tutto in R.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_expval_var.html#applicazioni-psicologiche",
    "href": "chapters/probability/09_expval_var.html#applicazioni-psicologiche",
    "title": "33  Proprietà delle variabili casuali",
    "section": "\n33.10 Applicazioni Psicologiche",
    "text": "33.10 Applicazioni Psicologiche\nUn esempio pratico dell’uso del valore atteso e della varianza in psicologia è rappresentato dagli studi sulla memoria episodica, in particolare attraverso il paradigma sperimentale delle risposte “Remember-Know”. Questo paradigma permette di esplorare come le persone riconoscano eventi passati, distinguendo tra ricordi dettagliati e semplici sensazioni di familiarità.\nIl Paradigma “Remember-Know”\nIn un tipico esperimento di memoria episodica:\n\nAi partecipanti viene presentata una lista di stimoli (es. parole o immagini).\nDopo un intervallo di tempo, viene mostrata una nuova lista contenente elementi precedentemente visti (old) e elementi nuovi (new).\n\nPer ogni stimolo old riconosciuto, i soggetti devono specificare se:\n\n\nRemember (R): Ricordano consapevolmente dettagli contestuali dell’episodio di encoding (es. “Ricordo che questa parola era scritta in rosso”).\n\nKnow (K): Avvertono familiarità con lo stimolo, ma senza accesso a dettagli specifici (es. “Sembra conosciuto, ma non so perché”).\n\n\nMiss: Non riconoscono lo stimolo.\n\n\n\nLa variabile in gioco è quindi categorica e discreta, con tre possibili esiti per gli stimoli old: {R, K, Miss}.\nModelli Teorici e Previsioni Statistiche\nDue importanti teorie cercano di spiegare come avviene questo riconoscimento:\nTeoria del Processo Unico (Strength Theory) (e.g., Wixted & Mickes, 2010)\n\n\nIpotesi centrale:\nC’è una sola dimensione continua (la “forza mnemonica”) che determina il tipo di risposta.\n\nLe risposte Remember derivano da tracce molto forti, quelle Know da tracce di forza intermedia, e i Miss da tracce troppo deboli.\n\n\n\nImplicazioni statistiche: molte risposte Know, meno risposte Remember, bassa varianza.\n\nTeoria del Doppio Processo (Dual-Process) (e.g., Yonelinas, 2002)\n\n\nIpotesi centrale:\nCi sono due processi indipendenti:\n\n\nRecollection (R): Processo qualitativo e binario (presente/assente), legato al ricordo consapevole di dettagli contestuali.\n\n\nFamiliarità (K): Processo continuo, basato su una sensazione generica di familiarità.\n\n\n\nImplicazioni statistiche: numero simile di risposte Remember e Know, alta varianza.\n\nQui entrano in gioco i concetti statistici: ogni teoria formula previsioni diverse sul valore atteso (es. proporzione attesa di risposte R o K) e sulla varianza (dispersione dei dati attorno a questi valori). Confrontando le osservazioni sperimentali con le aspettative teoriche, è possibile testare quale modello sia più coerente con i dati empirici, illustrando come strumenti probabilistici possano chiarire meccanismi cognitivi complessi.\nConfronto Statistico: Previsioni Teoriche\nPer confrontare quantitativamente le previsioni dei due modelli, consideriamo un esperimento ipotetico con 100 stimoli old. Assegniamo punteggi numerici alle categorie di risposta per trasformarle in una variabile discreta, facilitando il calcolo di valore atteso e varianza:\n\n\nRemember (R) = 2\n\n\nKnow (K) = 1\n\nMiss = 0\n\nQuesta codifica riflette l’intensità mnemonica associata a ciascuna risposta, permettendo di quantificare le differenze teoriche tra i modelli.\n1. Modello Single-Process (Forza continua)\nSecondo questa teoria, la distribuzione attesa delle risposte è:\n\n\nCategoria\nR\nK\nMiss\n\n\n% Prevista\n25%\n60%\n15%\n\n\nCalcoli statistici:\n- Valore atteso (media ponderata):\\[\n  E(X) = (2 \\cdot 0.25) + (1 \\cdot 0.60) + (0 \\cdot 0.15) = 1.10\n  \\]\n- Varianza (dispersione attorno alla media):\\[\n  \\begin{aligned}\n  Var(X) &= (2-1.10)^2 \\cdot 0.25 + (1-1.10)^2 \\cdot 0.60 + (0-1.10)^2 \\cdot 0.15 \\\\\n  &= 0.2025 + 0.006 + 0.1815 = 0.39\n  \\end{aligned}\n  \\]\n2. Modello Dual-Process (Recollection e Familiarità)\nLa teoria prevede una distribuzione basata su due meccanismi indipendenti:\n\n\nCategoria\nR\nK\nMiss\n\n\n% Prevista\n40%\n40%\n20%\n\n\nCalcoli statistici:\n- Valore atteso:\\[\n  E(X) = (2 \\cdot 0.40) + (1 \\cdot 0.40) + (0 \\cdot 0.20) = 1.20\n  \\]\n- Varianza:\\[\n  \\begin{aligned}\n  Var(X) &= (2-1.20)^2 \\cdot 0.40 + (1-1.20)^2 \\cdot 0.40 + (0-1.20)^2 \\cdot 0.20 \\\\\n  &= 0.256 + 0.016 + 0.288 = 0.56\n  \\end{aligned}\n  \\]\nSintesi del Confronto\nI due modelli generano previsioni distinte, riassunte nella tabella seguente:\n\n\n\n\n\n\n\n\nModello\nValore Atteso\nVarianza\nInterpretazione\n\n\n\nSingle-Process\n1.10\n0.39\nMedia più bassa, varianza ridotta (distribuzione concentrata attorno a K).\n\n\nDual-Process\n1.20\n0.56\nMedia più alta, varianza elevata (effetto della miscela tra due processi).\n\n\n\n\n\nValore atteso: Il modello dual-process predice una media superiore, coerente con la maggiore proporzione attesa di risposte Remember.\n\n\nVarianza: La differenza nella dispersione (0.39 vs. 0.56) riflette l’eterogeneità introdotta dalla separazione tra recollection e familiarità nel modello duale.\n\nApplicazione a Dati Empirici\nSupponiamo ora di aver raccolto dati reali da 100 soggetti che hanno prodotto questa distribuzione:\n\n\nR\nK\nMiss\n\n\n38%\n42%\n20%\n\n\nCalcoliamo il valore atteso e la varianza empiriche:\n\\[\n  E(X) = 2 \\cdot 0.38 + 1 \\cdot 0.42 + 0 \\cdot 0.20 = 1.18\n  \\]\n\\[\n  Var(X) = (2-1.18)^2 \\cdot 0.38 + (1-1.18)^2 \\cdot 0.42 + (0-1.18)^2 \\cdot 0.20 = 0.55\n  \\]\nRisultati:\n\n\nDati\nValore Atteso\nVarianza\n\n\nEmpirici\n1.18\n0.55\n\n\nConfrontando questi risultati con le previsioni teoriche, notiamo che i dati empirici si avvicinano molto più al modello dual-process (valore atteso: 1.20 vs. 1.18; varianza: 0.56 vs. 0.55).\nImplicazioni Psicologiche e Cliniche\n\nTeoriche: Il confronto tra distribuzioni osservate e teoriche, usando valore atteso e varianza, consente di identificare quale teoria cognitiva spieghi meglio i dati.\nCliniche: In contesti clinici (es. valutazione di deficit cognitivi), questo approccio consente di identificare se un paziente mostra un profilo riconducibile a un danno selettivo della recollection (R ↓) o della familiarità (K ↓).\n\nQuesto framework illustra come strumenti probabilistici di base possano tradurre ipotesi psicologiche complesse in predizioni quantitative verificabili, avanzando la comprensione dei meccanismi cognitivi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_expval_var.html#riflessioni-conclusive",
    "href": "chapters/probability/09_expval_var.html#riflessioni-conclusive",
    "title": "33  Proprietà delle variabili casuali",
    "section": "\n33.11 Riflessioni Conclusive",
    "text": "33.11 Riflessioni Conclusive\nIn conclusione, i concetti di valore atteso e varianza sono fondamentali per comprendere il comportamento delle variabili casuali. Il valore atteso fornisce una misura centrale, rappresentando il “valore tipico” che ci si aspetta di osservare, mentre la varianza quantifica la dispersione dei valori attorno a questa media, offrendo una visione più completa della distribuzione. Questi strumenti sono essenziali per l’analisi e la modellizzazione statistica, fornendo le basi per valutare e interpretare la variabilità nei fenomeni aleatori.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_expval_var.html#esercizi",
    "href": "chapters/probability/09_expval_var.html#esercizi",
    "title": "33  Proprietà delle variabili casuali",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nEsercizio 1: Calcolo del Valore Atteso per Variabili Discrete\nUtilizzando i dati raccolti dagli studenti sulla SWLS, calcola il valore atteso della soddisfazione con la vita (\\(X\\)). Organizza i dati come nell’esempio seguente e interpretalo come se fosse la distribuzione di probabilità nella popolazione:\n\n\nSWLS Score\nProbabilità \\(P(X)\\)\n\n\n\n\n5\n0.05\n\n\n10\n0.10\n\n\n15\n0.20\n\n\n20\n0.30\n\n\n25\n0.20\n\n\n30\n0.10\n\n\n35\n0.05\n\n\n\n\nCalcola il valore atteso di \\(X\\), \\(\\mathbb{E}(X)\\).\nInterpreta il risultato ottenuto.\n\nEsercizio 2: Varianza e Deviazione Standard\nData la stessa distribuzione della SWLS utilizzata nell’esercizio precedente:\n\nCalcola la varianza \\(\\mathbb{V}(X)\\).\nCalcola la deviazione standard \\(\\sigma_X\\).\nCommenta il significato della dispersione dei valori rispetto alla media.\n\nEsercizio 3: Proprietà del Valore Atteso\nUtilizzando la distribuzione della LSNS-6:\n\nDefinisci una nuova variabile casuale \\(Y = 2X + 3\\).\nCalcola il valore atteso di \\(Y\\), \\(\\mathbb{E}(Y)\\), utilizzando la linearità dell’operatore di aspettazione.\nVerifica il risultato calcolando direttamente \\(\\mathbb{E}(Y)\\) dalla distribuzione di probabilità di \\(Y\\).\n\nUtilizza una distribuzione della LSNS-6 organizzata come segue (sostituisci i valori presenti con quelli del campione):\n\n\nLSNS-6 Score\nProbabilità \\(P(Y)\\)\n\n\n\n\n5\n0.10\n\n\n10\n0.15\n\n\n15\n0.25\n\n\n20\n0.25\n\n\n25\n0.15\n\n\n30\n0.10\n\n\n\nEsercizio 4: Applicazione del Teorema di Chebyshev\nSia la soddisfazione con la vita (SWLS) distribuita con media \\(\\mu = 3.2\\) e deviazione standard \\(\\sigma = 0.8\\).\n\nUsa il teorema di Chebyshev per trovare un limite superiore alla probabilità che un valore di SWLS sia oltre due deviazioni standard dalla media.\nConfronta questo risultato con la probabilità empirica calcolata utilizzando i dati raccolti.\n\nEsercizio 5: Standardizzazione e Distribuzione Normale\n# Definizione dei dati osservati della LSNS-6 (sostituisci con i dati reali se disponibili)\nlsns6_scores &lt;- c(5, 8, 10, 12, 15, 18, 20, 22, 25, 28)\n\n# Parametri della distribuzione\nmu &lt;- 12   # Media della LSNS-6\nsigma &lt;- 4  # Deviazione standard della LSNS-6\n\n# Standardizzazione dei valori osservati\nz_scores &lt;- (lsns6_scores - mu) / sigma\n\n# Creazione dell'istogramma della distribuzione standardizzata\nhist(z_scores, \n     breaks = 10, \n     col = \"lightblue\", \n     main = \"Istogramma della distribuzione standardizzata di LSNS-6\", \n     xlab = \"Z-score\", \n     ylab = \"Frequenza\",\n     probability = TRUE)\n\n# Sovrapposizione della curva normale standard\ncurve(dnorm(x, mean = 0, sd = 1), col = \"red\", lwd = 2, add = TRUE)\n\nStandardizzazione: La trasformazione dei punteggi della LSNS-6 in Z-score permette di esprimere ogni valore in termini di deviazioni standard rispetto alla media. Un valore \\(Z = 1\\) significa che il punteggio di LSNS-6 è una deviazione standard sopra la media, mentre \\(Z = -1\\) significa che è una deviazione standard sotto la media.\nIstogramma della distribuzione standardizzata: Il grafico mostra la distribuzione dei punteggi standardizzati. Se la distribuzione originale è simile a una normale, l’istogramma dei punteggi standardizzati dovrebbe assomigliare a una distribuzione normale standard.\nConfronto con la distribuzione normale standard: La curva rossa rappresenta la densità di una normale standard (\\(\\mathcal{N}(0,1)\\)). Se i dati sono approssimativamente normali, l’istogramma dei punteggi standardizzati dovrebbe seguire la forma della curva normale standard. Differenze marcate potrebbero indicare asimmetria o curtosi anomale nella distribuzione dei punteggi LSNS-6.\n\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\nEsercizio 1: Calcolo del Valore Atteso della SWLS\nLa Satisfaction With Life Scale (SWLS) è composta da 5 item, ciascuno valutato su una scala Likert da 1 a 7. Supponiamo di avere la seguente distribuzione di probabilità per il punteggio totale della SWLS basata su un campione di studenti:\n\n\nSWLS Score\nProbabilità \\(P(X)\\)\n\n\n\n\n5\n0.05\n\n\n10\n0.10\n\n\n15\n0.20\n\n\n20\n0.30\n\n\n25\n0.20\n\n\n30\n0.10\n\n\n35\n0.05\n\n\n\nDomanda:\nCalcola il valore atteso \\(\\mathbb{E}[X]\\) del punteggio SWLS.\nSoluzione: Il valore atteso si calcola come:\n\\[\n\\mathbb{E}[X] = \\sum x_i P(x_i)\n\\]\nCalcoliamo in R:\n# Definizione dei valori SWLS e delle probabilità\nswls_scores &lt;- c(5, 10, 15, 20, 25, 30, 35)\nprob_swls &lt;- c(0.05, 0.10, 0.20, 0.30, 0.20, 0.10, 0.05)\n\n# Calcolo del valore atteso\nexpected_swls &lt;- sum(swls_scores * prob_swls)\nexpected_swls\nRisultato:\\[\n\\mathbb{E}[X] = 20\n\\]\nIl valore atteso rappresenta la media teorica della soddisfazione con la vita nella popolazione, assumendo che la distribuzione dei punteggi SWLS segua esattamente le probabilità fornite. In altre parole, se prendessimo un numero molto grande di individui con questa distribuzione di probabilità, il punteggio medio atteso sarebbe 20. Questo suggerisce che, nella popolazione considerata, il livello medio di soddisfazione con la vita si colloca al centro della scala SWLS.\nEsercizio 2: Calcolo della Varianza e Deviazione Standard della SWLS\n# Definizione dei dati\nswls_scores &lt;- c(5, 10, 15, 20, 25, 30, 35)\nprobabilities &lt;- c(0.05, 0.10, 0.20, 0.30, 0.20, 0.10, 0.05)\n\n# Calcolo del valore atteso (media attesa)\nexpected_value &lt;- sum(swls_scores * probabilities)\n\n# Calcolo della varianza\nvariance &lt;- sum((swls_scores - expected_value)^2 * probabilities)\n\n# Calcolo della deviazione standard\nstd_deviation &lt;- sqrt(variance)\n\n# Stampa dei risultati\ncat(\"Valore atteso (E[X]):\", expected_value, \"\\n\")\ncat(\"Varianza (Var[X]):\", variance, \"\\n\")\ncat(\"Deviazione standard (σ_X):\", std_deviation, \"\\n\")\n\n\nVarianza: Misura la dispersione dei punteggi SWLS rispetto alla media attesa. Se la varianza è alta, significa che i punteggi sono molto variabili; se è bassa, significa che i punteggi sono più concentrati attorno al valore atteso.\n\nDeviazione standard: È la radice quadrata della varianza e ha la stessa unità di misura dei dati originali. Fornisce un’indicazione della dispersione media dei punteggi rispetto alla media.\n\nSe la deviazione standard è elevata, significa che nella popolazione ci sono sia individui con livelli di soddisfazione molto bassi sia individui con livelli molto alti. Se è bassa, i punteggi sono più omogenei intorno alla media.\nEsercizio 3: Calcolo del Valore Atteso della Scala della Rete Sociale di Lubben (LSNS-6)\n# Definizione dei dati della LSNS-6\nlsns_scores &lt;- c(5, 10, 15, 20, 25, 30)\nprobabilities &lt;- c(0.10, 0.15, 0.25, 0.25, 0.15, 0.10)\n\n# Definizione della trasformazione della variabile casuale Y = 2X + 3\ny_values &lt;- 2 * lsns_scores + 3\n\n# Calcolo del valore atteso di X\nexpected_x &lt;- sum(lsns_scores * probabilities)\n\n# Utilizzo della linearità dell'operatore di aspettazione: E[Y] = 2E[X] + 3\nexpected_y_from_x &lt;- 2 * expected_x + 3\n\n# Calcolo diretto del valore atteso di Y\nexpected_y_direct &lt;- sum(y_values * probabilities)\n\n# Stampa dei risultati\ncat(\"Valore atteso di X (E[X]):\", expected_x, \"\\n\")\ncat(\"Valore atteso di Y calcolato con la linearità (E[Y] = 2E[X] + 3):\", expected_y_from_x, \"\\n\")\ncat(\"Valore atteso di Y calcolato direttamente dalla distribuzione di probabilità di Y:\", expected_y_direct, \"\\n\")\n\n\nLinearità dell’operatore di aspettazione: Questo principio afferma che se una variabile casuale \\(X\\) viene trasformata linearmente in \\(Y = aX + b\\), allora il valore atteso di \\(Y\\) è dato da:\n\\[\n\\mathbb{E}(Y) = a \\mathbb{E}(X) + b\n\\]\nQuesto semplifica il calcolo senza dover ridefinire una nuova distribuzione di probabilità.\n\nVerifica del risultato: Dopo aver calcolato \\(\\mathbb{E}(Y)\\) con la proprietà di linearità, lo confrontiamo con il calcolo diretto utilizzando la distribuzione trasformata. Se i due valori coincidono, confermiamo che la proprietà di linearità è rispettata.\nSignificato pratico: La trasformazione lineare di una variabile casuale può rappresentare un’operazione reale come la conversione di punteggi da una scala all’altra. Il valore atteso si comporta linearmente, il che è utile per interpretare trasformazioni senza dover ricalcolare completamente la distribuzione.\n\nEsercizio 4: Probabilità secondo il Teorema di Chebyshev\nIl Teorema di Chebyshev afferma che per qualsiasi distribuzione, la probabilità che un valore sia oltre \\(k\\) deviazioni standard dalla media è al massimo:\n\\[\nP(|X - \\mu| \\geq k\\sigma) \\leq \\frac{1}{k^2}\n\\]\nSostituendo \\(k = 2\\):\n\\[\nP(|X - 3.2| \\geq 2 \\cdot 0.8) \\leq \\frac{1}{2^2} = \\frac{1}{4} = 0.25\n\\]\nQuindi, il Teorema di Chebyshev fornisce un limite superiore del 25% alla probabilità che un valore di SWLS sia oltre due deviazioni standard dalla media.\nPer confrontare questo risultato con la probabilità empirica, è necessaro usare i dati raccolti sulla SWLS.\nEsercizio 5: Standardizzazione del Punteggio LSNS-6\nDomanda:\nStandardizza il punteggio LSNS-6 trasformandolo nella variabile standardizzata \\(Z\\).\n\\[\nZ = \\frac{Y - \\mathbb{E}(Y)}{\\sigma_Y}\n\\]\nSoluzione: Calcoliamo in R:\n# Standardizzazione dei punteggi LSNS-6\nz_lsns &lt;- (lsns_scores - expected_lsns) / sd_lsns\nz_lsns\nRisultato:\n\n\nLSNS-6 Score\nZ-Score\n\n\n\n5\n-2.23\n\n\n10\n-1.34\n\n\n15\n-0.45\n\n\n20\n0.45\n\n\n25\n1.34\n\n\n30\n2.23\n\n\n\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nEsercizio 6: Personalizzazione degli Interventi Basati sulla Probabilità Condizionata\nUno psicologo scolastico vuole identificare quali studenti potrebbero trarre maggiore beneficio da un programma di supporto psicologico. Dalla letteratura, si sa che la probabilità di avere livelli bassi di soddisfazione con la vita (SWLS ≤ 15) è più alta tra gli studenti che riportano elevati livelli di stress accademico.\nDai dati raccolti su un campione di studenti:\n\n\\(P(\\text{SWLS} \\leq 15) = 0.35\\)\n\\(P(\\text{Stress Alto}) = 0.40\\)\n\\(P(\\text{SWLS} \\leq 15 \\mid \\text{Stress Alto}) = 0.60\\)\n\nDomanda Se uno studente è scelto a caso, qual è la probabilità che abbia un alto livello di stress dato che il suo punteggio SWLS è ≤ 15?\nEsercizio 7: Prevedere il Successo di un Intervento Psicologico Uno psicologo clinico sta valutando l’efficacia di un intervento sulla riduzione dell’ansia. Ha raccolto i dati di 100 pazienti e ha osservato che il miglioramento medio nei punteggi di ansia (misurati con DASS-21) è di 5 punti con una deviazione standard di 2.5.\nSupponiamo che il miglioramento sia una variabile aleatoria normale con media 5 e deviazione standard 2.5.\nDomanda Qual è la probabilità che un paziente scelto a caso migliori di almeno 7 punti?\nEsercizio 8: Allocazione Ottimale delle Risorse in un Programma di Prevenzione Uno psicologo organizza un programma di sensibilizzazione sulla salute mentale in diverse scuole. Ha raccolto dati sulla frequenza con cui gli studenti si rivolgono allo sportello di ascolto, con la seguente distribuzione:\n\n\nNumero di Visite\nProbabilità\n\n\n\n0\n0.40\n\n\n1\n0.30\n\n\n2\n0.15\n\n\n3+\n0.15\n\n\n\nDomanda Se lo psicologo ha risorse per organizzare colloqui individuali solo per il 30% degli studenti, quale soglia può usare per selezionare gli studenti più bisognosi in base alla distribuzione delle visite?\nEsercizio 9: Misurare la Variabilità della Risposta a un Trattamento Uno psicologo somministra un trattamento per la depressione e misura la variazione nei punteggi di depressione su un campione di pazienti prima e dopo l’intervento.\nLe variazioni seguono questa distribuzione:\n\n\nΔ Punteggio DASS-21\nProbabilità\n\n\n\n-10\n0.10\n\n\n-5\n0.20\n\n\n0\n0.40\n\n\n+5\n0.20\n\n\n+10\n0.10\n\n\n\nDomanda Qual è la deviazione standard della variazione nei punteggi di depressione?\nEsercizio 10: Probabilità di un Fallimento in un Programma di Sensibilizzazione Uno psicologo organizza un programma per ridurre il pregiudizio sulla salute mentale. Dai dati precedenti, la probabilità di successo di ogni evento di sensibilizzazione è del 70%. Se organizza 5 eventi indipendenti, qual è la probabilità che almeno 1 fallisca?\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\nEsercizio 6: Personalizzazione degli Interventi Basati sulla Probabilità Condizionata\nUtilizziamo la formula della probabilità condizionata:\n\\[\nP(\\text{Stress Alto} \\mid \\text{SWLS} \\leq 15) = \\frac{P(\\text{SWLS} \\leq 15 \\mid \\text{Stress Alto}) P(\\text{Stress Alto})}{P(\\text{SWLS} \\leq 15)}\n\\]\nCalcoliamo in R:\np_swls_low &lt;- 0.35\np_stress_high &lt;- 0.40\np_swls_given_stress &lt;- 0.60\n\np_stress_given_swls &lt;- (p_swls_given_stress * p_stress_high) / p_swls_low\np_stress_given_swls\nRisultato Lo psicologo può usare questa informazione per identificare studenti con alta probabilità di avere stress elevato, anche se non hanno segnalato direttamente il problema, e offrire supporto mirato.\nEsercizio 7: Prevedere il Successo di un Intervento Psicologico\nUsiamo la normalizzazione:\n\\[\nZ = \\frac{X - \\mu}{\\sigma}\n\\]\ne calcoliamo la probabilità corrispondente:\nmean_improvement &lt;- 5\nsd_improvement &lt;- 2.5\nthreshold &lt;- 7\n\np_improve_7 &lt;- 1 - pnorm(threshold, mean = mean_improvement, sd = sd_improvement)\np_improve_7\nRisultato Questo aiuta lo psicologo a comunicare ai pazienti la probabilità di ottenere miglioramenti significativi e ad adattare le aspettative dell’intervento.\nEsercizio 8: Allocazione Ottimale delle Risorse in un Programma di Prevenzione\nSoluzione Calcoliamo la probabilità cumulativa:\nvisits &lt;- c(0, 1, 2, 3)\nprobabilities &lt;- c(0.40, 0.30, 0.15, 0.15)\ncumulative_prob &lt;- cumsum(probabilities)\n\n# Determinare la soglia per il 30% più bisognoso\nthreshold &lt;- visits[min(which(cumulative_prob &gt;= 0.70))]\nthreshold\nRisultato Lo psicologo può decidere di offrire supporto prioritario a studenti con almeno 2 visite, massimizzando l’impatto con risorse limitate.\nEsercizio 9: Misurare la Variabilità della Risposta a un Trattamento\nSoluzione Calcoliamo la varianza e la deviazione standard:\nscore_changes &lt;- c(-10, -5, 0, 5, 10)\nprobabilities &lt;- c(0.10, 0.20, 0.40, 0.20, 0.10)\n\n# Media attesa\nexpected_change &lt;- sum(score_changes * probabilities)\n\n# Varianza\nvariance_change &lt;- sum((score_changes - expected_change)^2 * probabilities)\n\n# Deviazione standard\nsd_change &lt;- sqrt(variance_change)\nsd_change\nRisultato Se la deviazione standard è grande, significa che l’effetto del trattamento è molto variabile e potrebbero essere necessarie strategie personalizzate.\nEsercizio 10: Probabilità di un Fallimento in un Programma di Sensibilizzazione\nUsiamo la distribuzione binomiale:\np_success &lt;- 0.70\nn_events &lt;- 5\n\np_failure_at_least_one &lt;- 1 - dbinom(5, n_events, p_success)\np_failure_at_least_one\nRisultato Lo psicologo può pianificare strategie di miglioramento sapendo la probabilità di un fallimento.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_expval_var.html#esercizi-1",
    "href": "chapters/probability/09_expval_var.html#esercizi-1",
    "title": "33  Proprietà delle variabili casuali",
    "section": "\n33.12 Esercizi",
    "text": "33.12 Esercizi\nConsiglio gli esercizi di base disponibili nella seguente pagina web.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_expval_var.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/09_expval_var.html#informazioni-sullambiente-di-sviluppo",
    "title": "33  Proprietà delle variabili casuali",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.7   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.13.0 psych_2.5.3     \n#&gt;  [9] scales_1.4.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.3.0     ggplot2_3.5.2   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.4     stringi_1.8.7      lattice_0.22-7    \n#&gt;  [4] hms_1.1.3          digest_0.6.37      magrittr_2.0.3    \n#&gt;  [7] evaluate_1.0.4     grid_4.5.0         timechange_0.3.0  \n#&gt; [10] RColorBrewer_1.1-3 fastmap_1.2.0      rprojroot_2.0.4   \n#&gt; [13] jsonlite_2.0.0     mnormt_2.1.1       cli_3.6.5         \n#&gt; [16] rlang_1.1.6        withr_3.0.2        tools_4.5.0       \n#&gt; [19] parallel_4.5.0     tzdb_0.5.0         pacman_0.5.1      \n#&gt; [22] vctrs_0.6.5        R6_2.6.1           lifecycle_1.0.4   \n#&gt; [25] htmlwidgets_1.6.4  pkgconfig_2.0.3    pillar_1.10.2     \n#&gt; [28] gtable_0.3.6       glue_1.8.0         xfun_0.52         \n#&gt; [31] tidyselect_1.2.1   rstudioapi_0.17.1  farver_2.1.2      \n#&gt; [34] htmltools_0.5.8.1  nlme_3.1-168       labeling_0.4.3    \n#&gt; [37] rmarkdown_2.29     compiler_4.5.0",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_expval_var.html#bibliografia",
    "href": "chapters/probability/09_expval_var.html#bibliografia",
    "title": "33  Proprietà delle variabili casuali",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nChan, J. C. C., & Kroese, D. P. (2025). Statistical Modeling and Computation (2ª ed.). Springer.\n\n\nHacking, I. (2006). The emergence of probability: A philosophical study of early ideas about probability, induction and statistical inference. Cambridge University Press.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:\n\n\nWixted, J. T., & Mickes, L. (2010). A continuous dual-process model of remember/know judgments. Psychological Review, 117(4), 1025–1054.\n\n\nYonelinas, A. P. (2002). The nature of recollection and familiarity: A review of 30 years of research. Journal of Memory and Language, 46(3), 441–517.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_sampling_distr.html",
    "href": "chapters/probability/10_sampling_distr.html",
    "title": "34  Stime, stimatori e parametri",
    "section": "",
    "text": "34.1 Introduzione\nIn psicologia – come in molte altre discipline – ci si trova spesso nella situazione di voler comprendere una particolare caratteristica di un’intera popolazione. Tuttavia, difficilmente è possibile raccogliere dati da tutti i membri di tale popolazione, a causa di limiti di tempo, risorse o accessibilità. Ad esempio, potremmo voler stimare la percentuale di persone che soffrono di un determinato disturbo d’ansia oppure la media di un punteggio di memoria a breve termine, ma non siamo in grado di testare ogni singolo individuo appartenente al gruppo di interesse. Per far fronte a questo limite, si sceglie di selezionare un campione di partecipanti (idealmente in modo casuale), dal quale si ricavano le informazioni utili a inferire la caratteristica dell’intera popolazione, riconoscendo un certo grado di incertezza.\nNel linguaggio statistico:\nCome esempio, immaginiamo di voler conoscere la proporzione di adulti che manifestano un certo sintomo d’ansia, indicandola con \\(p\\). Poiché non possiamo (o non vogliamo) esaminare tutta la popolazione, estraiamo un campione casuale di \\(N\\) individui, verifichiamo quanti di loro presentino il sintomo e calcoliamo:\n\\[\n\\hat{p} = \\frac{\\text{numero di individui con il sintomo}}{N}.\n\\]\nQuesto rapporto (detto stima campionaria di \\(p\\)) difficilmente coinciderà esattamente con \\(p\\), ma la teoria probabilistica mostra che, in assenza di distorsioni sistematiche, \\(\\hat{p}\\) tenderà ad avvicinarsi al valore reale al crescere della dimensione del campione.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_sampling_distr.html#introduzione",
    "href": "chapters/probability/10_sampling_distr.html#introduzione",
    "title": "34  Stime, stimatori e parametri",
    "section": "",
    "text": "Popolazione: l’insieme completo degli individui (o unità) di interesse. Esempi: tutte le persone che soddisfano certi criteri diagnostici, tutti gli studenti di una scuola, tutte le misurazioni di reazione a uno stimolo sperimentale.\n\nParametro: la quantità (sconosciuta) che descrive la caratteristica d’interesse nella popolazione (esempio: la “vera” proporzione di soggetti con un certo disturbo, oppure la “vera” media di un test cognitivo).\n\nCampione: un sottoinsieme di individui (idealmente estratto in modo casuale) dalla popolazione di interesse.\n\nStima: il valore numerico, calcolato sul campione, che approssima il parametro.\n\nStimatore: la regola o funzione matematica con cui, a partire dai dati del campione, si ottiene la stima.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_sampling_distr.html#popolazione-e-campione",
    "href": "chapters/probability/10_sampling_distr.html#popolazione-e-campione",
    "title": "34  Stime, stimatori e parametri",
    "section": "\n34.2 Popolazione e campione",
    "text": "34.2 Popolazione e campione\nPer rendere tutto più concreto, supponiamo di voler stimare la frequenza di un sintomo ansioso in un’ampia popolazione, ad esempio l’insieme di tutti gli studenti universitari di un paese. Non potendo sottoporre un questionario a ogni studente, scegliamo un sottoinsieme di individui in modo casuale (cioè il nostro campione) e a ciascuno somministriamo uno strumento standardizzato volto a rilevare la presenza/assenza del sintomo. Il nostro obiettivo finale è utilizzare i dati campionari per trarre inferenze sulla popolazione complessiva, cioè per stimare la vera proporzione \\(p\\) di studenti che manifestano il sintomo.\nQuesta operazione di estrarre un sottogruppo rappresentativo si chiama campionamento. La proporzione di individui con il sintomo d’ansia calcolata nel campione è la nostra stima campionaria (simbolizzata con \\(\\bar{X}\\) o, più spesso in contesto di proporzioni, con \\(\\hat{p}\\)). Se il campione è selezionato in modo corretto e rappresentativo, ci aspettiamo che \\(\\bar{X}\\) rispecchi, con un certo margine di errore, il vero valore di \\(p\\) (il parametro).\n\n34.2.1 Lo stimatore: la proporzione campionaria\nPer formalizzare ulteriormente, consideriamo un modello “urna” in cui la popolazione è immaginata come un’urna piena di “biglie” di due colori (ad esempio, “blu” per sintomo presente, “rosso” per sintomo assente). Estraendo a caso \\(N\\) biglie (cioè selezionando \\(N\\) soggetti), definiamo la variabile casuale \\(X_i\\) come:\n\\[\nX_i =\n\\begin{cases}\n1 & \\text{se l’individuo } i \\text{ presenta il sintomo (biglia blu),}\\\\\n0 & \\text{se l’individuo } i \\text{ non presenta il sintomo (biglia rossa).}\n\\end{cases}\n\\]\nLa proporzione campionaria – ossia la nostra stima empirica di \\(p\\) – è data da:\n\\[\n\\bar{X} \\;=\\; \\frac{1}{N}\\sum_{i=1}^N X_i.\n\\]\nDal punto di vista interpretativo:\n\n\n\\(p\\) è la vera proporzione di studenti (biglie “blu”) nella popolazione;\n\n\\(\\bar{X}\\) è la proporzione di studenti con il sintomo riscontrata nel campione.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_sampling_distr.html#distribuzione-campionaria-valore-atteso-e-varianza",
    "href": "chapters/probability/10_sampling_distr.html#distribuzione-campionaria-valore-atteso-e-varianza",
    "title": "34  Stime, stimatori e parametri",
    "section": "\n34.3 Distribuzione campionaria: valore atteso e varianza",
    "text": "34.3 Distribuzione campionaria: valore atteso e varianza\nIl passo cruciale per il ragionamento inferenziale è capire come varia \\(\\bar{X}\\) se ripetiamo la procedura di campionamento molte volte. In altre parole, se estraessimo più volte (indipendentemente) un campione di ampiezza \\(N\\), otterremmo ogni volta un valore di \\(\\bar{X}\\) in genere diverso. La collezione di tutti questi possibili valori (con le rispettive probabilità) si chiama distribuzione campionaria di \\(\\bar{X}\\).\n\n34.3.1 Valore atteso della media (o proporzione) campionaria\nSe \\(X_1, X_2, \\dots, X_n\\) sono variabili aleatorie indipendenti e identicamente distribuite (i.i.d.), ognuna con valore atteso \\(\\mathbb{E}[X_i] = \\mu\\), allora la loro media campionaria\n\\[\n\\bar{X} \\;=\\; \\frac{1}{n}\\sum_{i=1}^n X_i\n\\]\npossiede a sua volta valore atteso\n\\[\n\\mathbb{E}[\\bar{X}] \\;=\\; \\mu.\n\\]\nQuesta semplice formula rivela che \\(\\bar{X}\\) è uno stimatore non distorto per \\(\\mu\\): in media, se ripetessimo infinite volte lo stesso tipo di campionamento, otterremmo una stima che coincide con il vero valore del parametro. Nel caso di variabili 0-1 (come presenza/assenza di sintomo), abbiamo \\(\\mu \\equiv p\\).\n\nDimostrazione. Consideriamo un campione casuale \\(X_1, X_2, \\dots, X_n\\) di variabili aleatorie indipendenti e identicamente distribuite (i.i.d.), ognuna con valore atteso \\(\\mathbb{E}[X_i] = \\mu\\). Vogliamo dimostrare che il valore atteso della media campionaria \\(\\bar{X}\\) è uguale a \\(\\mu\\):\n\\[\n\\mathbb{E}[\\bar{X}] = \\mu.\n\\]\nPasso 1: Definizione di media campionaria.\nLa media campionaria è definita come:\\[\n\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i.\n\\]\nPasso 2: Applicazione del valore atteso.\nCalcoliamo il valore atteso di \\(\\bar{X}\\), sfruttando la linearità del valore atteso (l’aspettativa di una somma è la somma delle aspettative):\\[\n\\mathbb{E}[\\bar{X}] = \\mathbb{E}\\left[\\frac{1}{n} \\sum_{i=1}^n X_i\\right].\n\\]\nPasso 3: Portare fuori le costanti.\nIl fattore \\(\\frac{1}{n}\\) è una costante rispetto all’operatore \\(\\mathbb{E}\\):\\[\n\\mathbb{E}[\\bar{X}] = \\frac{1}{n} \\mathbb{E}\\left[\\sum_{i=1}^n X_i\\right].\n\\]\nPasso 4: Separare la somma.\nPer linearità, l’aspettativa della somma è la somma delle aspettative:\\[\n\\mathbb{E}\\left[\\sum_{i=1}^n X_i\\right] = \\sum_{i=1}^n \\mathbb{E}[X_i].\n\\]\nPasso 5: Sfruttare l’identica distribuzione.\nPoiché tutte le \\(X_i\\) sono identicamente distribuite, \\(\\mathbb{E}[X_i] = \\mu\\) per ogni \\(i\\):\\[\n\\sum_{i=1}^n \\mathbb{E}[X_i] = \\sum_{i=1}^n \\mu = n\\mu.\n\\]\nPasso 6: Combinare i risultati.\nSostituendo nel Passo 3:\\[\n\\mathbb{E}[\\bar{X}] = \\frac{1}{n} \\cdot n\\mu = \\mu.\n\\]\nInterpretazione e Significato.\n\n\nNon distorsione (Unbiasedness):\nLa dimostrazione mostra che \\(\\bar{X}\\) è uno stimatore non distorto di \\(\\mu\\). Questo significa che, in media su infinite replicazioni del campionamento, \\(\\bar{X}\\) coincide con il vero valore \\(\\mu\\).\n\n\nIndipendenza non necessaria per l’aspettativa:\nL’indipendenza tra le \\(X_i\\) non è richiesta per questa dimostrazione. Bastano l’identica distribuzione (per garantire \\(\\mathbb{E}[X_i] = \\mu\\)) e la linearità del valore atteso.\n\n\nCaso speciale: proporzione campionaria\nSe le \\(X_i\\) sono variabili di Bernoulli (0-1) con \\(\\mathbb{E}[X_i] = p\\), allora \\(\\bar{X} = \\frac{\\text{numero di successi}}{n}\\) stima la proporzione \\(p\\), e \\(\\mathbb{E}[\\bar{X}] = p\\).\n\nPerché è importante?\nQuesta proprietà è alla base dell’inferenza statistica:\n\nGiustifica l’uso della media campionaria come stima affidabile di \\(\\mu\\).\n\nÈ il fondamento della Legge dei Grandi Numeri: all’aumentare di \\(n\\), \\(\\bar{X}\\) converge a \\(\\mu\\).\n\n\n\n34.3.2 Varianza della media (o proporzione) campionaria\nOltre al valore atteso, un’altra misura fondamentale è la varianza della distribuzione campionaria, che quantifica quanto \\(\\bar{X}\\) tenda a fluttuare attorno a \\(\\mu\\). Se la varianza individuale di ciascun \\(X_i\\) è \\(\\sigma^2\\), allora per la media campionaria si ha:\n\\[\n\\mathrm{Var}(\\bar{X}) \\;=\\; \\frac{\\sigma^2}{n}.\n\\tag{34.1}\\]\nNel caso Bernoulliano (variabili 0-1) con \\(\\mathbb{E}[X_i] = p\\), sappiamo che\n\\[\n\\sigma^2 \\;=\\; p(1-p).\n\\]\nPertanto:\n\\[\n\\mathrm{Var}(\\bar{X}) \\;=\\; \\frac{p \\bigl(1-p\\bigr)}{n}.\n\\]\nLa radice quadrata di questa varianza prende il nome di errore standard (in inglese Standard Error, SE) della media (o della proporzione), e risulta:\n\\[\n\\mathrm{SE}(\\bar{X}) \\;=\\; \\sqrt{\\frac{p\\,(1-p)}{n}}.\n\\]\nCon l’aumentare di \\(n\\), la varianza di \\(\\bar{X}\\) diminuisce, e quindi la nostra stima diventa più “precisa” (in un senso statistico). Ciò spiega perché, anche nella pratica psicologica, aumentare la dimensione del campione riduce l’incertezza nella stima e migliora l’affidabilità dei risultati.\nOsservazione: nella ricerca psicologica, l’errore standard fornisce un’indicazione chiara di quanto, in media, la nostra stima potrebbe deviare dal vero parametro, se ripetessimo il campionamento molte volte. Questo concetto è centrale in molte procedure inferenziali, come la costruzione di intervalli di confidenza o il test di ipotesi, e prepara il terreno per comprendere la cosiddetta distribuzione campionaria della media (argomento che il capitolo proseguirà a trattare).\n\nDimostrazione. Forniamo qui la dimostrazione dell’Equazione 34.1. Assumiamo che \\(X_1, X_2, \\dots, X_n\\) siano variabili casuali indipendenti e identicamente distribuite (i.i.d.) con media \\(\\mu\\) e varianza \\(\\sigma^2\\). Definiamo la media campionaria\n\\[\n\\bar{X} \\;=\\; \\frac{1}{n}\\sum_{i=1}^n X_i.\n\\]\nVogliamo calcolare \\(\\mathrm{Var}(\\bar{X})\\). Per prima cosa, notiamo che:\n\\[\n\\mathrm{Var}(a\\,Y) \\;=\\; a^2 \\,\\mathrm{Var}(Y)\n\\]\nper qualunque costante \\(a\\). Nel nostro caso, poniamo \\(a = \\frac{1}{n}\\) e \\(Y = \\sum_{i=1}^n X_i\\). Otteniamo quindi:\n\\[\n\\mathrm{Var}(\\bar{X})\n\\;=\\;\n\\mathrm{Var}\\!\\Bigl(\\tfrac{1}{n}\\sum_{i=1}^n X_i\\Bigr)\n\\;=\\;\n\\frac{1}{n^2} \\, \\mathrm{Var}\\!\\Bigl(\\sum_{i=1}^n X_i\\Bigr).\n\\]\nOra sfruttiamo il fatto che \\(X_1, X_2, \\dots, X_n\\) siano indipendenti. In tal caso, la varianza della somma è la somma delle varianze:\n\\[\n\\mathrm{Var}\\Bigl(\\sum_{i=1}^n X_i\\Bigr)\n\\;=\\;\n\\sum_{i=1}^n \\mathrm{Var}(X_i)\n\\;=\\;\nn \\,\\sigma^2,\n\\]\npoiché \\(\\mathrm{Var}(X_i) = \\sigma^2\\) per tutti gli \\(i\\). Combiniamo dunque i due risultati:\n\\[\n\\mathrm{Var}(\\bar{X})\n\\;=\\;\n\\frac{1}{n^2}\\,\\bigl(n \\,\\sigma^2\\bigr)\n\\;=\\;\n\\frac{\\sigma^2}{n}.\n\\]\nIn sintesi, la chiave della dimostrazione sta nel fattore \\(\\tfrac{1}{n^2}\\) e nel fatto che, per variabili indipendenti, la varianza di una somma è la somma delle varianze. Questo ci consente di concludere che la varianza della media campionaria è \\(\\tfrac{\\sigma^2}{n}\\).\n\nQuesto risultato riflette un’importante proprietà statistica:\n\nall’aumentare di \\(n\\), la varianza della media campionaria diminuisce, rendendo la media campionaria una stima più precisa del valore atteso \\(\\mu\\). La riduzione della varianza è proporzionale a \\(1/n\\), quindi raddoppiare il campione riduce la varianza della media campionaria di un fattore 2.\n\nIn conclusione, la formula \\(\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n}\\) mostra che la precisione della media campionaria aumenta con la dimensione del campione, poiché la varianza diminuisce. Questo principio è alla base dell’importanza di campioni più grandi nella stima statistica.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_sampling_distr.html#la-distribuzione-campionaria-della-media",
    "href": "chapters/probability/10_sampling_distr.html#la-distribuzione-campionaria-della-media",
    "title": "34  Stime, stimatori e parametri",
    "section": "\n34.4 La Distribuzione Campionaria della Media",
    "text": "34.4 La Distribuzione Campionaria della Media\nPer illustrare ulteriormente il concetto di distribuzione campionaria, consideriamo un caso semplice e specifico: una popolazione finita di dimensioni ridotte. Sebbene stiamo esaminando un caso particolare, è fondamentale notare che le proprietà e i principi che analizzeremo in questo contesto sono perfettamente applicabili a popolazioni di qualsiasi dimensione.\nLa distribuzione campionaria ci dà una visione della variazione che potremmo aspettarci nelle stime derivate da diversi campioni estratti dalla stessa popolazione. Ogni volta che preleviamo un campione, otteniamo una stima diversa per il parametro di interesse (come la media). La distribuzione campionaria ci mostra come queste stime sono distribuite e ci aiuta a comprendere quanto siano affidabili.\nIn termini pratici, se vogliamo calcolare la media della popolazione, non possiamo farlo direttamente (a meno di non avere accesso all’intera popolazione). Invece, possiamo estrarre un campione casuale e calcolare la media del campione come stima di \\(\\mu\\). Tuttavia, un altro campione fornirà una stima leggermente diversa. La distribuzione campionaria ci aiuta a capire quanto queste stime varino da campione a campione e ci fornisce un quadro completo dell’incertezza legata al processo di stima.\nNella simulazione seguente, ipotizziamo la seguente popolazione:\n\nx &lt;- c(2, 4.5, 5, 5.5)\nx\n#&gt; [1] 2.0 4.5 5.0 5.5\n\nL’istogramma seguente descrive la distribuzione della popolazione.\n\nggplot(data.frame(x = x), aes(x)) +\n  geom_histogram(\n    bins = 5,\n    aes(y = after_stat(density)),\n    fill = \"lightblue\",\n    color = \"black\"\n  )\n\n\n\n\n\n\n\nCalcoliamo la media e la varianza della popolazione. Media:\n\nmean_x &lt;- mean(x) # Media della popolazione\nmean_x\n#&gt; [1] 4.25\n\nVarianza:\n\nvar_x &lt;- var(x) * ((length(x) - 1) / length(x)) # Varianza popolazione\nvar_x\n#&gt; [1] 1.812\n\nConsideriamo tutti i possibili campioni di dimensione \\(n = 2\\) che possono essere estratti dalla popolazione rappresentata dal vettore x. Per generare questi campioni, utilizziamo la funzione expand.grid in R, che consente di creare tutte le combinazioni possibili di valori, includendo le ripetizioni.\nIl risultato sarà un data frame con 16 righe e 2 colonne, dove ogni riga rappresenta una coppia possibile di valori estratti dal vettore x. Questo risultato è in linea con il principio del calcolo combinatorio: quando selezioniamo \\(n\\) elementi da un insieme di \\(k\\) elementi e permettiamo ripetizioni, il numero totale di combinazioni è dato da \\(k^n\\). Nel nostro caso, con \\(k = 4\\) e \\(n = 2\\), otteniamo:\n\\[\n4^2 = 16 \\text{ combinazioni}.\n\\]\nUtilizzando expand.grid, possiamo verificare questo risultato in R:\n\n# Generazione delle combinazioni con ripetizione\nsamples &lt;- expand.grid(x, x)\n\n# Visualizzazione del risultato\nprint(samples)\n#&gt;    Var1 Var2\n#&gt; 1   2.0  2.0\n#&gt; 2   4.5  2.0\n#&gt; 3   5.0  2.0\n#&gt; 4   5.5  2.0\n#&gt; 5   2.0  4.5\n#&gt; 6   4.5  4.5\n#&gt; 7   5.0  4.5\n#&gt; 8   5.5  4.5\n#&gt; 9   2.0  5.0\n#&gt; 10  4.5  5.0\n#&gt; 11  5.0  5.0\n#&gt; 12  5.5  5.0\n#&gt; 13  2.0  5.5\n#&gt; 14  4.5  5.5\n#&gt; 15  5.0  5.5\n#&gt; 16  5.5  5.5\n\nIl data frame risultante mostrerà tutte le possibili coppie \\((x_1, x_2)\\), dove \\(x_1\\) e \\(x_2\\) possono essere scelti indipendentemente dalla popolazione \\(x = \\{2, 4.5, 5, 5.5\\}\\).\nPer calcolare la media di ogni campione di ampiezza \\(n = 2\\), possiamo utilizzare la funzione rowMeans, che calcola la media per ogni riga di una matrice. In questo modo, otteniamo un vettore contenente la media di ciascuna coppia di valori. Questo insieme di valori costituisce la distribuzione campionaria delle medie dei campioni di ampiezza \\(n = 2\\) che possono essere estratti dalla popolazione x.\n\n# Calcolare la media di ciascun campione\nsample_means &lt;- rowMeans(samples)\nprint(sample_means)\n#&gt;  [1] 2.00 3.25 3.50 3.75 3.25 4.50 4.75 5.00 3.50 4.75 5.00 5.25 3.75 5.00\n#&gt; [15] 5.25 5.50\n\nUna rappresentazione grafica della distribuzione campionaria delle medie dei campioni di ampiezza \\(n = 2\\) che possono essere estratti dalla popolazione x è fornita qui sotto.\n\n# Istogramma delle medie campionarie\nggplot(data.frame(sample_means), aes(x = sample_means)) +\n  geom_histogram(\n    bins = 5,\n    aes(y = after_stat(density)),\n    fill = \"lightblue\",\n    color = \"black\"\n)\n\n\n\n\n\n\n\nMostriamo qui nuovamente la lista di tutti i possibili campioni di ampiezza 2 insieme alla media di ciascun campione.\n\n# Creare un data frame con i campioni e le loro medie\ndf &lt;- data.frame(\n  Samples = apply(samples, 1, paste, collapse = \", \"),\n  x_bar = rowMeans(samples)\n)\nprint(df)\n#&gt;     Samples x_bar\n#&gt; 1      2, 2  2.00\n#&gt; 2    4.5, 2  3.25\n#&gt; 3      5, 2  3.50\n#&gt; 4    5.5, 2  3.75\n#&gt; 5    2, 4.5  3.25\n#&gt; 6  4.5, 4.5  4.50\n#&gt; 7    5, 4.5  4.75\n#&gt; 8  5.5, 4.5  5.00\n#&gt; 9      2, 5  3.50\n#&gt; 10   4.5, 5  4.75\n#&gt; 11     5, 5  5.00\n#&gt; 12   5.5, 5  5.25\n#&gt; 13   2, 5.5  3.75\n#&gt; 14 4.5, 5.5  5.00\n#&gt; 15   5, 5.5  5.25\n#&gt; 16 5.5, 5.5  5.50\n\nProcediamo ora al calcolo della media della distribuzione campionaria delle medie di campioni di ampiezza \\(n = 2\\) che possono essere estratti dalla popolazione x.\n\n# Calcolare la media delle medie campionarie\nmean(sample_means)\n#&gt; [1] 4.25\n\nSi noti che questo valore coincide con la media della popolazione.\nLa varianza delle medie campionarie, calcolata empiricamente, può essere ottenuta direttamente dai dati utilizzando la seguente formula:\n\nvar(x) * (length(x) - 1) / length(x) / length(x)\n#&gt; [1] 0.4531\n\nQuesto calcolo riflette la formula teorica per la varianza della media campionaria, definita come la varianza dei dati divisa per la dimensione del campione \\(n\\). Tuttavia, poiché la funzione var() in R utilizza \\(n-1\\) al denominatore per fornire una stima non distorta della varianza della popolazione, è necessario applicare un fattore di correzione \\(\\frac{n-1}{n}\\) per ottenere la varianza campionaria corretta. Successivamente, questa varianza viene divisa per \\(n\\) per ottenere la varianza della media campionaria.\nIn alternativa, possiamo calcolare lo stesso valore prendendo la varianza delle medie di tutti i campioni (16 in questo caso):\n\nvar(sample_means) * ((length(sample_means) - 1) / length(sample_means))\n#&gt; [1] 0.9062\n\nAnche in questo caso applichiamo il fattore di correzione \\(\\frac{n-1}{n}\\) per ottenere il calcolo corretto della varianza usando la funzione var() in R.\nEntrambi i calcoli forniscono risultati coerenti con la teoria, dimostrando che la varianza delle medie campionarie è inferiore a quella della popolazione.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_sampling_distr.html#sec-lln",
    "href": "chapters/probability/10_sampling_distr.html#sec-lln",
    "title": "34  Stime, stimatori e parametri",
    "section": "\n34.5 Legge dei Grandi Numeri",
    "text": "34.5 Legge dei Grandi Numeri\nLa Legge dei Grandi Numeri (LLN, dall’inglese Law of Large Numbers) è uno dei pilastri fondamentali della teoria della probabilità. Essa descrive come, all’aumentare del numero di osservazioni, la media campionaria si avvicini stabilmente al valore atteso teorico. In termini formali, se \\(\\bar{X}_n\\) rappresenta la media di \\(n\\) osservazioni indipendenti e identicamente distribuite (i.i.d.) con valore atteso \\(\\mu\\), allora \\(\\bar{X}_n \\to \\mu\\) quando \\(n \\to \\infty\\). Questo principio è cruciale per comprendere la relazione tra dati empirici e modelli teorici, come discusso nella sezione sull’interpretazione della probabilità (Capitolo 25).\nEsistono due versioni principali della Legge dei Grandi Numeri:\n\nLegge Forte: La media campionaria \\(\\bar{X}_n\\) converge quasi certamente a \\(\\mu\\), il che significa che, con probabilità 1, la media osservata si avvicina indefinitamente al valore teorico al crescere di \\(n\\).\n\nLegge Debole: La media campionaria \\(\\bar{X}_n\\) converge a \\(\\mu\\) in probabilità, ovvero, per ogni \\(\\varepsilon &gt; 0\\), la probabilità che la differenza tra \\(\\bar{X}_n\\) e \\(\\mu\\) superi \\(\\varepsilon\\) tende a zero al crescere di \\(n\\). Formalmente:\n\\[\n\\Pr\\bigl(| \\bar{X}_n - \\mu| &gt; \\varepsilon\\bigr) \\to 0 \\quad \\text{al crescere di }n.\n\\]\n\n\n\n34.5.1 Applicazioni in Psicologia\nIn psicologia, la Legge dei Grandi Numeri ha implicazioni significative. Ad esempio, se si vuole stimare con precisione la proporzione di individui che manifestano un determinato comportamento o la media di un test cognitivo in una popolazione, è necessario raccogliere un numero sufficiente di osservazioni. Solo con un campione ampio la media campionaria si avvicinerà alla media “vera” della popolazione, riducendo l’incertezza e migliorando l’affidabilità delle stime.\n\n34.5.2 Forma Debole della Legge dei Grandi Numeri\nLa forma debole della LGN, dimostrata per la prima volta da Jacob Bernoulli nel suo lavoro Ars Conjectandi, afferma che la media campionaria converge in probabilità alla media teorica (Hacking, 2006). In termini pratici, questo significa che, man mano che il numero di osservazioni aumenta, la probabilità che la differenza tra la media osservata e la media teorica superi un margine di errore \\(\\varepsilon\\) diventa sempre più piccola. Formalmente:\n\\[\n\\lim_{{n \\to \\infty}} P\\left(\\left|\\frac{1}{n} \\sum_{i=1}^n X_i - \\mu\\right| \\geq \\varepsilon\\right) = 0,\n\\]\ndove:\n\n\n\\(X_1, X_2, \\ldots, X_n\\) sono variabili casuali indipendenti e identicamente distribuite (i.i.d.),\n\n\\(\\mu\\) è la media teorica,\n\n\\(\\varepsilon\\) è un numero positivo arbitrariamente piccolo.\n\n34.5.3 Forma Forte della Legge dei Grandi Numeri\nLa forma forte della LGN, sviluppata successivamente da matematici come Kolmogorov, è un enunciato più potente. Essa stabilisce che la media campionaria converge quasi sicuramente alla media teorica. Questo implica che, con probabilità 1, la media osservata si avvicina indefinitamente al valore teorico man mano che il numero di prove tende all’infinito. Formalmente:\n\\[\nP\\left(\\lim_{{n \\to \\infty}} \\frac{1}{n} \\sum_{i=1}^n X_i = \\mu\\right) = 1.\n\\]\n\n34.5.4 Importanza e Critiche\nLa Legge dei Grandi Numeri è fondamentale per garantire la validità delle stime empiriche, ma la sua applicazione pratica richiede attenzione. Ad esempio, in psicologia, la raccolta di un numero sufficiente di osservazioni può essere costosa o difficile, specialmente quando si studiano fenomeni rari o popolazioni specifiche. Inoltre, l’assunzione di indipendenza e identica distribuzione delle osservazioni potrebbe non essere sempre realistica in contesti applicativi complessi. Nonostante queste sfide, la LGN rimane un principio essenziale per comprendere come i dati empirici possano avvicinarsi alle proprietà teoriche di una popolazione.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_sampling_distr.html#teorema-del-limite-centrale",
    "href": "chapters/probability/10_sampling_distr.html#teorema-del-limite-centrale",
    "title": "34  Stime, stimatori e parametri",
    "section": "\n34.6 Teorema del Limite Centrale",
    "text": "34.6 Teorema del Limite Centrale\nOltre alla convergenza, un ulteriore risultato importante è che la distribuzione di \\(\\bar{X}_n\\) si approssima alla normale man mano che \\(n\\) cresce, anche se i singoli \\(X_i\\) non sono distribuiti normalmente.\n\nTeorema 34.1 Se \\(X_1, X_2, \\ldots, X_n\\) sono variabili iid con media \\(\\mu\\) e deviazione standard \\(\\sigma\\), la distribuzione di\n\\[\n\\bar{X}_n = \\frac{1}{n}\\sum_{i=1}^n X_i\n\\] diventa approssimativamente normale con media \\(\\mu\\) e deviazione standard \\(\\tfrac{\\sigma}{\\sqrt{n}}\\) quando \\(n\\) è sufficientemente grande.\n\nPer il caso 0-1 (presenza/assenza di un tratto), \\(\\bar{X}\\) è quindi circa normale con media \\(p\\) e varianza \\(\\frac{p(1-p)}{n}\\). Il TLC consente, tra l’altro, di costruire intervalli di confidenza e di calcolare probabilità che la stima si discosti di una certa quantità dal vero valore.\n\nEsempio 34.1 Per visualizzare il Teorema del Limite Centrale (TLC) in azione, possiamo condurre una simulazione. Immaginiamo una popolazione distribuita in modo uniforme. Estraiamo 300 campioni di dimensione \\(n = 30\\) da questa popolazione e osserviamo come la distribuzione campionaria delle medie di questi campioni converga a una distribuzione normale. Questa simulazione fornirà un’illustrazione concreta dell’efficacia del TLC nell’approssimare distribuzioni reali.\n\n# Impostiamo il seed per la riproducibilità dei risultati\nset.seed(42)\n\n# Generiamo una popolazione con distribuzione uniforme\npopulation &lt;- runif(5000, min = 0, max = 1)\n\n# Passo 1: Visualizziamo l'istogramma della popolazione utilizzando ggplot2\nggplot(data.frame(population), aes(x = population)) +\n  geom_histogram(\n    aes(y = after_stat(density)),\n    bins = 30, fill = \"lightblue\", color = \"black\"\n  ) +\n  labs(title = \"Distribuzione della Popolazione\", x = \"Valore\", y = \"Densità\")\n\n\n\n\n\n\n\n\n# Passo 2 e 3: Estraiamo campioni casuali e calcoliamo le medie campionarie\nsample_size &lt;- 30\nnum_samples &lt;- 300\n\n# Vettore vuoto per memorizzare le medie campionarie\nsample_means &lt;- c()\n\nfor (i in 1:num_samples) {\n  # Estraiamo un campione casuale\n  sample &lt;- sample(population, size = sample_size, replace = TRUE)\n  \n  # Calcoliamo la media del campione\n  sample_means[i] &lt;- mean(sample)\n}\n\n# Calcoliamo media e varianza delle medie campionarie\nx_bar &lt;- mean(sample_means)\nstd &lt;- sd(sample_means)\n\nprint('Media e Varianza delle Medie Campionarie')\n#&gt; [1] \"Media e Varianza delle Medie Campionarie\"\nprint(x_bar)\n#&gt; [1] 0.501\nprint(std**2)\n#&gt; [1] 0.002745\n\n\n# Calcoliamo media e varianza della popolazione\nmu &lt;- mean(population)\nsigma &lt;- sd(population)\n\nprint('Media e Varianza della Popolazione')\n#&gt; [1] \"Media e Varianza della Popolazione\"\nprint(mu)\n#&gt; [1] 0.5032\nprint((sigma**2)/sample_size)\n#&gt; [1] 0.002824\n\n\n# Passo 4: Visualizziamo l'istogramma delle medie campionarie utilizzando ggplot2\nggplot(data.frame(sample_means), aes(x = sample_means)) +\n  geom_histogram(\n    aes(y = after_stat(density)),\n    bins = 30, fill = \"lightblue\", color = \"black\"\n  ) +\n  stat_function(\n    fun = dnorm, args = list(mean = x_bar, sd = std), color = \"black\", size = 1\n  ) +\n  labs(\n    title = \"Distribuzione delle Medie Campionarie\", x = \"Media Campionaria\", y = \"Densità\"\n  ) +\n  theme(legend.position = \"top\") \n\n\n\n\n\n\n\nSpiegazione del codice e dei risultati\n\nPopolazione: Abbiamo generato una popolazione di 5000 osservazioni distribuite uniformemente tra 0 e 1. La distribuzione uniforme è stata scelta perché è chiaramente non normale, il che rende più evidente l’effetto del TLC.\nCampionamento: Abbiamo estratto 300 campioni casuali, ciascuno di dimensione \\(n = 30\\), dalla popolazione. Per ogni campione, abbiamo calcolato la media.\nDistribuzione delle Medie Campionarie: Le medie dei campioni sono state raccolte e la loro distribuzione è stata visualizzata tramite un istogramma. Nonostante la popolazione originale non fosse normale, la distribuzione delle medie campionarie si avvicina a una distribuzione normale, dimostrando il TLC.\nConfronto tra Popolazione e Campioni: Abbiamo confrontato la media e la varianza della popolazione con quelle delle medie campionarie. Come previsto dal TLC, la media delle medie campionarie è molto vicina alla media della popolazione, mentre la varianza delle medie campionarie è ridotta di un fattore pari alla dimensione del campione (\\(n = 30\\)).\n\nQuesta simulazione illustra chiaramente come il TLC permetta di approssimare la distribuzione delle medie campionarie a una distribuzione normale, anche quando la popolazione originale non è normale. Questo risultato è fondamentale per molte applicazioni pratiche della statistica inferenziale.\n\n\nEsempio 34.2 Sebbene i risultati teorici siano solidi, è comune utilizzare la simulazione Monte Carlo per verificarne la validità in contesti pratici. Supponiamo, ad esempio, che la proporzione reale di individui che soffrono di un certo sintomo in una popolazione sia \\(p = 0.45\\). Possiamo simulare campioni di dimensione \\(n\\) e calcolare la media campionaria \\(\\bar{X}\\) (ovvero la proporzione osservata in ciascun campione). Ripetendo questo processo molte volte, otteniamo una distribuzione empirica delle \\(\\bar{X}\\). Se l’approssimazione normale fornita dal Teorema del Limite Centrale (TLC) è valida, ci aspettiamo che:\n\nLa media delle \\(\\bar{X}\\) sia molto vicina al valore teorico \\(p = 0.45\\).\nLa varianza delle \\(\\bar{X}\\) sia approssimativamente uguale a \\(p(1-p)/n\\), come previsto dalla teoria.\n\nUn esempio di codice in R per questa simulazione è il seguente:\n\np &lt;- 0.45  # Proporzione reale nella popolazione\nn &lt;- 1000  # Dimensione del campione\nB &lt;- 10000 # Numero di campioni simulati\n\n# Simulazione Monte Carlo: generiamo B campioni e calcoliamo le medie campionarie\nx_hat &lt;- replicate(B, {\n  x &lt;- sample(c(0, 1), size = n, replace = TRUE, prob = c(1-p, p))\n  mean(x)\n})\n\n# Media delle medie campionarie (dovrebbe essere vicina a p)\nmean(x_hat)  # Risultato atteso: ~ 0.45\n#&gt; [1] 0.4501\n\n# Deviazione standard delle medie campionarie (dovrebbe essere vicina a sqrt(p*(1-p)/n))\nsd(x_hat)    # Risultato atteso: ~ sqrt(0.45 * 0.55 / 1000)\n#&gt; [1] 0.0157\n\nRisultati attesi e interpretazione:\n\n\nMedia delle medie campionarie: Il valore medio di x_hat dovrebbe essere molto vicino a \\(0.45\\), confermando che la media campionaria è uno stimatore non distorto della proporzione reale \\(p\\).\n\nDeviazione standard delle medie campionarie: La deviazione standard di x_hat dovrebbe avvicinarsi a \\(\\sqrt{0.45 \\times 0.55 / 1000} \\approx 0.0157\\), in linea con la formula teorica \\(\\sqrt{p(1-p)/n}\\). Questo valore rappresenta l’incertezza associata alla stima della proporzione.\n\nEffetto della dimensione del campione:\n\nAumentando la dimensione del campione \\(n\\), l’ampiezza della distribuzione delle medie campionarie (e quindi l’incertezza di \\(\\bar{X}\\)) diminuisce. Questo è coerente con la teoria, poiché la varianza delle medie campionarie è inversamente proporzionale a \\(n\\). In altre parole, campioni più grandi forniscono stime più precise del parametro della popolazione.\n\nQuesta simulazione dimostra concretamente come il Teorema del Limite Centrale garantisca che, anche per popolazioni non normali (come in questo caso, dove i dati sono binari), la distribuzione delle medie campionarie si avvicini a una distribuzione normale con media \\(p\\) e varianza \\(p(1-p)/n\\), purché \\(n\\) sia sufficientemente grande.\n\n\n34.6.1 Margine di errore e intervalli di confidenza\nSe \\(\\bar{X}\\) è approssimato da \\(\\mathcal{N}(p, \\frac{p(1-p)}{n})\\), allora \\[\nZ = \\frac{\\bar{X} - p}{\\sqrt{p(1-p)/n}}\n\\] segue (approssimativamente) la distribuzione normale standard \\(\\mathcal{N}(0,1)\\). In pratica, non conoscendo \\(p\\), possiamo sostituirlo con \\(\\bar{X}\\) nello stimatore di errore standard (\\(\\mathrm{plug\\text{-}in}\\)):\n\\[\n\\hat{\\mathrm{SE}}(\\bar{X}) = \\sqrt{\\frac{\\bar{X}(1-\\bar{X})}{n}}.\n\\] Spesso si costruisce un intervallo di confidenza approssimato al 95% come:\n\\[\n\\bar{X} \\,\\pm\\, 1.96 \\times \\hat{\\mathrm{SE}}(\\bar{X}),\n\\] dove 1.96 deriva dal fatto che circa il 95% della distribuzione normale standard sta nell’intervallo \\([-1.96,+1.96]\\). Questo intervallo rappresenta la fascia di incertezza attorno alla stima, che si restringe all’aumentare di \\(n\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_sampling_distr.html#oltre-la-media-altre-distribuzioni-campionarie",
    "href": "chapters/probability/10_sampling_distr.html#oltre-la-media-altre-distribuzioni-campionarie",
    "title": "34  Stime, stimatori e parametri",
    "section": "\n34.7 Oltre la Media: Altre Distribuzioni Campionarie",
    "text": "34.7 Oltre la Media: Altre Distribuzioni Campionarie\nFinora ci siamo concentrati sulla media campionaria (o proporzione), ma in molti casi di interesse psicologico o più in generale statistico, potremmo voler studiare altre statistiche tratte da un campione. Due esempi importanti sono il massimo campionario (utile per analisi di eventi estremi, punteggi massimi nei test, tempi di reazione record, ecc.) e la varianza campionaria (fondamentale per misurare la variabilità dei punteggi in un test psicometrico, ad esempio).\n\n34.7.1 Massimo campionario\nQuando siamo interessati a misurare la performance “estrema” di un gruppo (ad esempio il punteggio più elevato in un test cognitivo, oppure la latenza di reazione più veloce se si ragiona in termini di minimi), la statistica di riferimento è il massimo (o il minimo) nel campione.\n\n34.7.1.1 Teoria e concetti chiave\n\nDefinizione: Dato un campione \\(\\{X_1, X_2, \\dots, X_n\\}\\), il massimo campionario è \\[\nM = \\max\\{X_1, X_2, \\dots, X_n\\}.\n\\] Questa variabile casuale dipende ovviamente dalla distribuzione dei singoli \\(X_i\\).\n\nProprietà:\n\nLa distribuzione di \\(M\\) spesso risulta asimmetrica e “spostata a destra” rispetto alla distribuzione di partenza. Anche se la popolazione originaria fosse normalmente distribuita, la distribuzione del massimo non sarà normale.\n\nIl valore atteso \\(E[M]\\) supera la media \\(\\mu\\) della popolazione perché, fra i \\(n\\) individui osservati, “vince” sempre il più grande.\n\n\n\nImplicazioni pratiche:\n\nAnalizzare i massimi (o i minimi) è cruciale nello studio di fenomeni estremi (per esempio, individuare il picco di stress in un compito cognitivo o la più alta temperatura registrata in una sperimentazione ambientale).\nLa cosiddetta teoria degli estremi si fonda proprio sull’analisi di come i massimi (o minimi) si distribuiscono al crescere di \\(n\\). Questa ha applicazioni in diverse discipline: dalla psicologia (prestazione massima) all’ingegneria (carichi estremi) fino alla finanza (rischi estremi).\n\n\n\n\nEsempio 34.3 Nel seguente esempio, simuliamo 10.000 esperimenti. In ognuno:\n\nGeneriamo 5 osservazioni da una popolazione normale con media \\(\\mu = 100\\) e deviazione standard \\(\\sigma = 15\\).\n\nNe calcoliamo il massimo campionario.\n\nInfine, confrontiamo la distribuzione di questi massimi con la densità della distribuzione di partenza (cioè la normale \\(\\mathcal{N}(100, 15^2)\\)).\n\n# Impostazioni iniziali\nmu &lt;- 100\nsigma &lt;- 15\nx &lt;- seq(mu - 3 * sigma, mu + 3 * sigma, length.out = 100)\ny &lt;- dnorm(x, mean = mu, sd = sigma)\n\n# Simulazione di 10.000 esperimenti con campioni di 5 osservazioni\nset.seed(123)  # Per riproducibilità\nsample_maxes &lt;- replicate(10000, max(rnorm(5, mean = mu, sd = sigma)))\n\n# Creiamo un data frame per il grafico\ndata &lt;- data.frame(SampleMaxes = sample_maxes)\ndensity_data &lt;- data.frame(x = x, y = y)\n\n# Grafico con ggplot2\nggplot(data, aes(x = SampleMaxes)) +\n  geom_histogram(\n    aes(y = after_stat(density)),\n    bins = 30,\n    fill = \"lightblue\",\n    color = \"black\",\n    alpha = 0.7\n  ) +\n  geom_line(data = density_data, aes(x = x, y = y), size = 1, color = \"black\") +\n  labs(\n    title = \"Distribuzione dei massimi campionari\",\n    subtitle = \"Confronto con la distribuzione originale\",\n    x = \"Massimo campionario\",\n    y = \"Densità\"\n  ) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = \"bold\"),\n    plot.subtitle = element_text(hjust = 0.5)\n  )\n\n\n\n\n\n\n\nOsservazioni:\n\nL’istogramma, che rappresenta la distribuzione dei massimi campionari, è spostato a destra rispetto alla distribuzione della popolazione (tracciata in rosso).\nCiò evidenzia che \\(M\\) tende a fornire valori più alti della media \\(\\mu = 100\\). Se ripetessimo l’esperimento con campioni di dimensione maggiore di 5, questo effetto si accentuerebbe ulteriormente.\n\n\n\n34.7.2 2. Varianza campionaria\nLo studio della varianza (o in generale della variabilità) è un altro esempio cruciale in contesti psicologici. Se vogliamo descrivere quanto differiscono i punteggi di un test di personalità, o di un test cognitivo, non basta guardare solo alla media campionaria: ci interessa anche la dispersione.\n\n34.7.2.1 Teoria e concetti chiave\n\nStima della varianza:\nStimare la varianza \\(\\sigma^2\\) di una popolazione non è banale. La formula \\[\nS^2 = \\frac{1}{n} \\sum_{i=1}^n (Y_i - \\bar{Y})^2\n\\] tende a sottostimare \\(\\sigma^2\\). Per ottenere uno stimatore non distorto, si usa invece: \\[\nS^2 = \\frac{1}{n-1} \\sum_{i=1}^n (Y_i - \\bar{Y})^2.\n\\] L’uso di \\(n-1\\) serve a correggere la perdita di un grado di libertà (poiché \\(\\bar{Y}\\) è calcolata sui dati) e garantisce che \\(E[S^2] = \\sigma^2\\).\nConcetto di distorsione:\nChiamiamo uno stimatore \\(\\hat{\\theta}\\) non distorto se il suo valore atteso è uguale al parametro vero \\(\\theta\\): \\(E[\\hat{\\theta}] = \\theta\\). Con la formula a denominatore \\(n-1\\), la varianza campionaria risulta appunto non distorta.\n\n\nEsempio 34.4 Simuliamo 10.000 esperimenti, ognuno con \\(n=5\\) osservazioni generate da \\(\\mathcal{N}(100, 15^2)\\). Per ciascun campione, calcoliamo: 1. La varianza “distorta” \\(\\frac{1}{n}\\sum_i (X_i - \\bar{X})^2\\). 2. La varianza “corretta” con \\(n-1\\).\n\nset.seed(123)  # Per riproducibilità\n\n# Funzione per calcolare varianze con n e con n-1\ncalc_vars &lt;- function(n = 5, mu = 100, sigma = 15) {\n  sample_data &lt;- rnorm(n, mean = mu, sd = sigma)\n  var_n &lt;- sum((sample_data - mean(sample_data))^2) / n\n  var_n_minus_1 &lt;- var(sample_data)  # In R, var() usa di default n-1\n  c(var_n, var_n_minus_1)\n}\n\n# Simuliamo 10.000 campioni\nB &lt;- 10000\nvars_matrix &lt;- replicate(B, calc_vars())\nsample_vars_n &lt;- vars_matrix[1, ]\nsample_vars_n_minus_1 &lt;- vars_matrix[2, ]\n\n# Confrontiamo graficamente\ndata_n &lt;- data.frame(SampleVars = sample_vars_n, Type = \"Con n\")\ndata_n_minus_1 &lt;- data.frame(SampleVars = sample_vars_n_minus_1, Type = \"Con n-1\")\ncombined_data &lt;- rbind(data_n, data_n_minus_1)\n\nggplot(combined_data, aes(x = SampleVars, color = Type)) +\n  geom_density(size = 1.1) +\n  labs(\n    title = \"Distribuzione delle varianze campionarie\",\n    subtitle = \"Confronto: denominatore n vs. n-1\",\n    x = \"Varianza campionaria\",\n    y = \"Densità\"\n  ) +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = \"bold\"),\n    plot.subtitle = element_text(hjust = 0.5)\n  ) +\n  scale_color_manual(values = c(\"Con n\" = \"gray\", \"Con n-1\" = \"black\"))\n\n\n\n\n\n\n\nOsservazioni:\n\nLa curva corrispondente a “Con \\(n\\)” tende a sottostimare la varianza, mentre quella “Con \\(n-1\\)” si centra meglio attorno a \\(\\sigma^2 = 15^2 = 225\\).\n\nSe verifichiamo le medie delle due distribuzioni:\n\nmean(sample_vars_n)\n#&gt; [1] 180.7\nmean(sample_vars_n_minus_1)\n#&gt; [1] 225.8\n\ntroveremo che la prima è sensibilmente inferiore a 225, mentre la seconda si avvicina di più al valore vero.\n\n\n\nSia il massimo campionario sia la varianza campionaria dimostrano come non tutte le distribuzioni campionarie ereditino le stesse proprietà della media. Nel caso del massimo, la variabile risulta spostata verso valori elevati e non segue una forma gaussiana; nel caso della varianza, si deve porre attenzione alla formula usata, per evitare distorsioni sistematiche.\nIn sintesi:\n\n\nMassimo campionario: utile per l’analisi di fenomeni estremi (o massimi prestazionali), con una distribuzione tipicamente asimmetrica.\n\n\nVarianza campionaria: richiede la correzione di Bessel (denominatore \\(n-1\\)) per essere uno stimatore non distorto di \\(\\sigma^2\\).\n\nCapire le proprietà di queste (e altre) distribuzioni campionarie consente allo sperimentatore di valutare correttamente le incertezze nelle stime, di evitare errori di interpretazione e di utilizzare gli stimatori più appropriati in base al tipo di fenomeno studiato.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_sampling_distr.html#errore-standard-incertezza-inferenziale-e-bias",
    "href": "chapters/probability/10_sampling_distr.html#errore-standard-incertezza-inferenziale-e-bias",
    "title": "34  Stime, stimatori e parametri",
    "section": "\n34.8 Errore standard, incertezza inferenziale e bias",
    "text": "34.8 Errore standard, incertezza inferenziale e bias\n\n34.8.1 Errore standard e incertezza\nL’errore standard (SE) è la misura di quanto una data statistica (ad esempio la media) può variare da un campione all’altro per pura casualità di campionamento. In un contesto psicologico, può essere usato per mostrare graficamente l’affidabilità di una misura. Esporre i risultati di un test psicometrico riportando solo la media, senza un’idea dell’errore standard o di un intervallo di confidenza, rischia di dare un’illusione di precisione non giustificata.\n\n34.8.2 Bias: perché non basta un campione grandissimo\nAumentare la dimensione campionaria \\(n\\) riduce l’errore standard, ma non elimina possibili bias sistematici (si veda, ad esempio, la disussione fornita dal Andrew Gelman su questo tema). Ad esempio:\n\nSe i partecipanti più ansiosi evitano di partecipare allo studio (bias di selezione), la proporzione \\(\\bar{X}\\) sarà sistematicamente sottostimata.\nSe qualcuno falsifica le risposte per desiderabilità sociale (bias di risposta), la media misurata può allontanarsi dal valore vero in maniera non corretta da un semplice aumento del campione.\nSe lo strumento di misura (ad es. un questionario) è mal tarato o concettualmente scorretto, l’intero studio può soffrirne (misurazione errata).\n\nQuando è presente un bias, nessun aumento del numero di partecipanti potrà rimuoverlo: si otterranno stime molto “precise” (varianza piccola) ma sistematicamente lontane dal valore reale.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_sampling_distr.html#la-prospettiva-bayesiana",
    "href": "chapters/probability/10_sampling_distr.html#la-prospettiva-bayesiana",
    "title": "34  Stime, stimatori e parametri",
    "section": "\n34.9 La Prospettiva Bayesiana",
    "text": "34.9 La Prospettiva Bayesiana\nNelle sezioni precedenti abbiamo discusso il concetto di distribuzione campionaria da una prospettiva frequentista. Questo approccio considera il parametro della popolazione (come la proporzione \\(p\\) o la media \\(\\mu\\)) come una quantità fissa, sebbene sconosciuta. L’incertezza deriva esclusivamente dalla variabilità del processo di campionamento ripetuto.\nLa statistica bayesiana, invece, offre una prospettiva complementare e interpretativamente diversa:\n\nParametri come variabili casuali: Nel quadro bayesiano, i parametri non sono considerati quantità fisse, ma variabili aleatorie descritte da una distribuzione di probabilità. Questa distribuzione riflette il grado di convinzione (o conoscenza) del ricercatore rispetto al valore del parametro, prima di osservare i dati (distribuzione a priori), e viene aggiornata alla luce dei dati osservati per produrre una distribuzione a posteriori.\nDistribuzione a posteriori: Dopo aver osservato i dati campionari, la distribuzione a posteriori descrive completamente l’incertezza sul parametro. A differenza dell’approccio frequentista, in cui l’incertezza è quantificata considerando ripetizioni ipotetiche dell’esperimento, l’incertezza bayesiana riflette direttamente lo stato attuale della nostra conoscenza.\n\n\n34.9.1 Esempio concreto\nRiprendiamo l’esempio precedente sulla proporzione di adulti che manifestano un certo sintomo ansioso. Consideriamo che prima di raccogliere i dati dal campione, abbiamo una credenza iniziale (a priori) sulla proporzione \\(p\\). Potremmo assumere una distribuzione a priori Beta(\\(\\alpha\\), \\(\\beta\\)), scelta comunemente perché flessibile e comoda da aggiornare (si veda il Capitolo 40):\n\\[\np \\sim \\text{Beta}(\\alpha, \\beta).\n\\]\nSupponiamo ora di estrarre un campione di dimensione \\(N\\) e osservare \\(y\\) individui che manifestano il sintomo. La distribuzione a posteriori sarà allora:\n\\[\np \\mid y, N \\sim \\text{Beta}(\\alpha + y, \\beta + N - y) .\n\\]\nQuesta distribuzione incorpora sia le informazioni iniziali sia i dati osservati (si veda il Capitolo 48). Aumentando il numero di osservazioni, l’influenza della distribuzione a priori si riduce, e la distribuzione a posteriori converge verso il valore effettivo di \\(p\\), riflettendo un comportamento analogo alla Legge dei Grandi Numeri.\n\n34.9.1.1 Interpretazione bayesiana dei risultati\n\nIntervallo di credibilità: Al posto dell’intervallo di confidenza frequentista (si veda il Capitolo 87), che descrive la probabilità di copertura considerando ripetizioni ipotetiche del campionamento, il bayesiano utilizza un intervallo di credibilità (si veda il Capitolo 50), il quale indica direttamente l’intervallo entro cui il parametro cade con una data probabilità, date le osservazioni effettivamente raccolte.\nConvergenza della distribuzione a posteriori: In analogia alla Legge dei Grandi Numeri e al Teorema del Limite Centrale, anche nel quadro bayesiano, all’aumentare della dimensione del campione, la distribuzione a posteriori diventa sempre più concentrata intorno al parametro vero, riducendo l’incertezza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_sampling_distr.html#riflessioni-conclusive",
    "href": "chapters/probability/10_sampling_distr.html#riflessioni-conclusive",
    "title": "34  Stime, stimatori e parametri",
    "section": "\n34.10 Riflessioni Conclusive",
    "text": "34.10 Riflessioni Conclusive\nQuesto percorso illustra come, in un contesto frequentista, sia essenziale distinguere fra:\n\n\nPopolazione e parametro (ad es. la vera proporzione di un sintomo psicologico, o la vera media di un punteggio): entità teoriche che non osserviamo direttamente.\n\nCampione e stima (il dato empirico raccolto su un campione, e il calcolo – ad esempio la media – derivato dal campione).\n\nLa distribuzione campionaria di una statistica, specialmente la media o la proporzione, rivela:\n\nChe la media campionaria è uno stimatore non distorto (il suo valore atteso coincide con quello della popolazione).\nChe la sua precisione (cioè \\(\\frac{1}{\\mathrm{Var}(\\bar{X})}\\)) aumenta con la dimensione del campione.\nChe il Teorema del Limite Centrale garantisce un’approssimazione normale per \\(\\bar{X}\\) se \\(n\\) è sufficientemente ampio, consentendo di costruire intervalli di confidenza e valutare probabilisticamente le stime.\nChe l’errore standard (SE) descrive la variabilità dovuta al campionamento, mentre i bias sistematici non vengono rimossi aumentando \\(n\\).\n\nIl punto di vista bayesiano completa quello frequentista enfatizzando come l’incertezza inferenziale sia direttamente legata alla nostra conoscenza, rappresentata esplicitamente attraverso la distribuzione a posteriori. Questa interpretazione rende il quadro bayesiano particolarmente intuitivo in contesti applicativi in psicologia, dove l’obiettivo è aggiornare continuamente la conoscenza dei fenomeni studiati man mano che si accumulano nuove evidenze.\nIn sostanza, chi effettua ricerche in psicologia – come in qualunque altra disciplina – deve considerare sia l’incertezza intrinseca (errore casuale di campionamento) sia l’eventuale presenza di bias strutturali. Solo in questo modo si possono interpretare in modo appropriato i risultati delle analisi e valutare correttamente la credibilità delle conclusioni sui processi psicologici o sui fenomeni clinici d’interesse.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_sampling_distr.html#esercizi",
    "href": "chapters/probability/10_sampling_distr.html#esercizi",
    "title": "34  Stime, stimatori e parametri",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nEsercizi sulla distribuzione campionaria sono disponibili sulla seguente pagina web.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_sampling_distr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/10_sampling_distr.html#informazioni-sullambiente-di-sviluppo",
    "title": "34  Stime, stimatori e parametri",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.7   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.13.0 psych_2.5.3     \n#&gt;  [9] scales_1.4.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.3.0     ggplot2_3.5.2   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.4     stringi_1.8.7      lattice_0.22-7    \n#&gt;  [4] hms_1.1.3          digest_0.6.37      magrittr_2.0.3    \n#&gt;  [7] evaluate_1.0.4     grid_4.5.0         timechange_0.3.0  \n#&gt; [10] RColorBrewer_1.1-3 fastmap_1.2.0      rprojroot_2.0.4   \n#&gt; [13] jsonlite_2.0.0     mnormt_2.1.1       cli_3.6.5         \n#&gt; [16] rlang_1.1.6        withr_3.0.2        tools_4.5.0       \n#&gt; [19] parallel_4.5.0     tzdb_0.5.0         pacman_0.5.1      \n#&gt; [22] vctrs_0.6.5        R6_2.6.1           lifecycle_1.0.4   \n#&gt; [25] htmlwidgets_1.6.4  pkgconfig_2.0.3    pillar_1.10.2     \n#&gt; [28] gtable_0.3.6       glue_1.8.0         xfun_0.52         \n#&gt; [31] tidyselect_1.2.1   rstudioapi_0.17.1  farver_2.1.2      \n#&gt; [34] htmltools_0.5.8.1  nlme_3.1-168       labeling_0.4.3    \n#&gt; [37] rmarkdown_2.29     compiler_4.5.0",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_sampling_distr.html#bibliografia",
    "href": "chapters/probability/10_sampling_distr.html#bibliografia",
    "title": "34  Stime, stimatori e parametri",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nHacking, I. (2006). The emergence of probability: A philosophical study of early ideas about probability, induction and statistical inference. Cambridge University Press.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11a_joint_prob.html",
    "href": "chapters/probability/11a_joint_prob.html",
    "title": "35  Probabilità congiunta",
    "section": "",
    "text": "35.1 Introduzione\nFino a questo momento abbiamo considerato il concetto di probabilità associato a singole variabili casuali. Tuttavia, in molte situazioni pratiche e psicologiche, è fondamentale analizzare come due o più variabili casuali interagiscono tra loro. La distribuzione congiunta ci permette di descrivere la probabilità che più variabili aleatorie assumano contemporaneamente specifici valori.\nQuesto capitolo introduce e approfondisce il concetto di distribuzione congiunta attraverso definizioni, proprietà essenziali e un esempio concreto basato sulla letteratura psicologica.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11a_joint_prob.html#cosè-la-distribuzione-congiunta",
    "href": "chapters/probability/11a_joint_prob.html#cosè-la-distribuzione-congiunta",
    "title": "35  Probabilità congiunta",
    "section": "\n35.2 Cos’è la Distribuzione Congiunta?",
    "text": "35.2 Cos’è la Distribuzione Congiunta?\nLa distribuzione congiunta di due variabili casuali, denotate con \\(X\\) e \\(Y\\), rappresenta la probabilità che queste variabili assumano simultaneamente determinati valori. Si distinguono due casi fondamentali:\n\n\nCaso discreto: definita attraverso la funzione di massa di probabilità congiunta:\n\n\\[\np(x, y) = P(X = x, Y = y) .\n\\]\n\n\nCaso continuo: definita tramite la funzione di densità di probabilità congiunta:\n\n\\[\nf(x, y) .\n\\]\nQueste funzioni ci permettono di rispondere a domande riguardanti la probabilità che eventi relativi a più variabili si verifichino simultaneamente.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11a_joint_prob.html#proprietà-della-distribuzione-congiunta",
    "href": "chapters/probability/11a_joint_prob.html#proprietà-della-distribuzione-congiunta",
    "title": "35  Probabilità congiunta",
    "section": "\n35.3 Proprietà della Distribuzione Congiunta",
    "text": "35.3 Proprietà della Distribuzione Congiunta\nUna distribuzione di probabilità congiunta deve soddisfare alcune proprietà essenziali:\n\nNon-negatività: \\[\np(x,y) \\geq 0, \\quad \\text{oppure} \\quad f(x,y) \\geq 0 .\n\\]\nNormalizzazione:\n\n\nCaso discreto: \\[\n\\sum_{x}\\sum_{y} p(x,y) = 1 .\n\\]\n\nCaso continuo: \\[\n\\int_{-\\infty}^{+\\infty}\\int_{-\\infty}^{+\\infty} f(x,y)\\,dx\\,dy = 1 .\n\\]\n\n\nQueste proprietà assicurano che le funzioni rappresentino correttamente una distribuzione di probabilità.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11a_joint_prob.html#esempio-psicologico-ansia-e-prestazione-cognitiva",
    "href": "chapters/probability/11a_joint_prob.html#esempio-psicologico-ansia-e-prestazione-cognitiva",
    "title": "35  Probabilità congiunta",
    "section": "\n35.4 Esempio Psicologico: Ansia e Prestazione Cognitiva",
    "text": "35.4 Esempio Psicologico: Ansia e Prestazione Cognitiva\nConsideriamo un esempio tratto dalla letteratura psicologica: la relazione tra ansia (Y) e prestazione cognitiva (X) in studenti universitari. La ricerca psicologica indica spesso una relazione negativa tra questi due fattori: livelli elevati di ansia possono associarsi a prestazioni cognitive inferiori (Eysenck et al., 2007).\nSupponiamo di aver valutato due variabili discrete in un gruppo di studenti:\n\n\nAnsia: bassa, media, alta (codificata come Y = 0, 1, 2);\n\nPrestazione cognitiva: insufficiente, sufficiente, buona (codificata come X = 0, 1, 2).\n\nLa distribuzione congiunta potrebbe essere rappresentata nella seguente tabella (i dati sono ipotetici ma coerenti con la letteratura):\n\n\n\n\n\n\n\n\n\nAnsia Bassa (0)\nAnsia Media (1)\nAnsia Alta (2)\n\n\n\nInsufficiente (0)\n0.05\n0.10\n0.15\n\n\nSufficiente (1)\n0.15\n0.20\n0.10\n\n\nBuona (2)\n0.10\n0.10\n0.05\n\n\n\nI valori nella tabella rappresentano stime empiriche delle probabilità congiunte, ovvero le proporzioni osservate di studenti che hanno manifestato una specifica combinazione di livelli delle due variabili. Ad esempio, la cella corrispondente a “Ansia Media” e “Prestazione Sufficiente” indica che il 20% degli studenti nel campione considerato ha un livello medio di ansia ed ha ottenuto prestazioni sufficienti nel compito cognitivo.\nDa questa distribuzione, possiamo rispondere a domande specifiche come:\n\nQual è la probabilità che uno studente ottenga una prestazione cognitiva almeno sufficiente indipendentemente dal livello di ansia?\n\n\\[\nP(X \\geq 1) = 0.15 + 0.20 + 0.10 + 0.10 + 0.10 + 0.05 = 0.70 .\n\\]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11a_joint_prob.html#distribuzioni-marginali",
    "href": "chapters/probability/11a_joint_prob.html#distribuzioni-marginali",
    "title": "35  Probabilità congiunta",
    "section": "\n35.5 Distribuzioni Marginali",
    "text": "35.5 Distribuzioni Marginali\nA partire dalla distribuzione congiunta, è possibile ottenere le distribuzioni marginali per ciascuna variabile sommando (nel caso discreto) o integrando (nel caso continuo) sulla variabile che vogliamo marginalizzare.\nAd esempio, la distribuzione marginale di ansia (Y) si ottiene sommando su tutti i valori possibili della prestazione cognitiva:\n\nAnsia bassa: \\[P(Y=0)=0.05+0.15+0.10=0.30 .\\]\n\nAnsia media: \\[P(Y=1)=0.10+0.20+0.10=0.40 .\\]\n\nAnsia alta: \\[P(Y=2)=0.15+0.10+0.05=0.30 .\\]\n\n\nLe probabilità marginali permettono di considerare la distribuzione di una singola variabile indipendentemente dall’altra.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11a_joint_prob.html#indipendenza-e-dipendenza-tra-variabili",
    "href": "chapters/probability/11a_joint_prob.html#indipendenza-e-dipendenza-tra-variabili",
    "title": "35  Probabilità congiunta",
    "section": "\n35.6 Indipendenza e Dipendenza tra Variabili",
    "text": "35.6 Indipendenza e Dipendenza tra Variabili\nDue variabili casuali \\(X\\) e \\(Y\\) si dicono indipendenti se la loro distribuzione congiunta si fattorizza nelle rispettive distribuzioni marginali:\n\\[p(x,y)=p(x)p(y) \\quad \\text{oppure} \\quad f(x,y)=f(x)f(y) .\\]\nNel nostro esempio, verificare l’indipendenza equivale a controllare se, ad esempio:\n\\[P(X=0,Y=2)=P(X=0)P(Y=2) .\\]\nSe tale condizione non è soddisfatta, le variabili sono dipendenti. Tipicamente, nel contesto psicologico dell’esempio proposto, ansia e prestazione cognitiva risultano dipendenti.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11a_joint_prob.html#riflessioni-conclusive",
    "href": "chapters/probability/11a_joint_prob.html#riflessioni-conclusive",
    "title": "35  Probabilità congiunta",
    "section": "\n35.7 Riflessioni Conclusive",
    "text": "35.7 Riflessioni Conclusive\nLa distribuzione congiunta fornisce uno strumento per analizzare simultaneamente più variabili aleatorie e la loro interazione. È cruciale nella ricerca psicologica, dove è comune studiare relazioni tra variabili psicologiche come ansia, prestazione, motivazione e molti altri costrutti. Il passaggio successivo, affrontato nei capitoli seguenti, sarà quello di quantificare la forza e la direzione di queste relazioni mediante indici come la covarianza e la correlazione.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11a_joint_prob.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/11a_joint_prob.html#informazioni-sullambiente-di-sviluppo",
    "title": "35  Probabilità congiunta",
    "section": "\n35.8 Informazioni sull’Ambiente di Sviluppo",
    "text": "35.8 Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.7   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.13.0 psych_2.5.3     \n#&gt;  [9] scales_1.4.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.3.0     ggplot2_3.5.2   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.4     stringi_1.8.7      lattice_0.22-7    \n#&gt;  [4] hms_1.1.3          digest_0.6.37      magrittr_2.0.3    \n#&gt;  [7] evaluate_1.0.4     grid_4.5.0         timechange_0.3.0  \n#&gt; [10] RColorBrewer_1.1-3 fastmap_1.2.0      rprojroot_2.0.4   \n#&gt; [13] jsonlite_2.0.0     mnormt_2.1.1       cli_3.6.5         \n#&gt; [16] rlang_1.1.6        withr_3.0.2        tools_4.5.0       \n#&gt; [19] parallel_4.5.0     tzdb_0.5.0         pacman_0.5.1      \n#&gt; [22] vctrs_0.6.5        R6_2.6.1           lifecycle_1.0.4   \n#&gt; [25] htmlwidgets_1.6.4  pkgconfig_2.0.3    pillar_1.10.2     \n#&gt; [28] gtable_0.3.6       glue_1.8.0         xfun_0.52         \n#&gt; [31] tidyselect_1.2.1   rstudioapi_0.17.1  farver_2.1.2      \n#&gt; [34] htmltools_0.5.8.1  nlme_3.1-168       rmarkdown_2.29    \n#&gt; [37] compiler_4.5.0",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11a_joint_prob.html#bibliografia",
    "href": "chapters/probability/11a_joint_prob.html#bibliografia",
    "title": "35  Probabilità congiunta",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.\n\n\nChan, J. C. C., & Kroese, D. P. (2025). Statistical Modeling and Computation (2ª ed.). Springer.\n\n\nEysenck, M. W., Derakshan, N., Santos, R., & Calvo, M. G. (2007). Anxiety and cognitive performance: attentional control theory. Emotion, 7(2), 336–353.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11b_cov_cor.html",
    "href": "chapters/probability/11b_cov_cor.html",
    "title": "36  Covarianza e correlazione",
    "section": "",
    "text": "36.1 Introduzione\nQuando due variabili casuali non sono indipendenti, diciamo che esse sono associate o dipendenti. È importante non solo stabilire se tale relazione esista, ma anche quantificare la sua intensità e la sua direzione. A tal fine, utilizziamo due misure chiave: la covarianza e la correlazione.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Covarianza e correlazione</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11b_cov_cor.html#covarianza",
    "href": "chapters/probability/11b_cov_cor.html#covarianza",
    "title": "36  Covarianza e correlazione",
    "section": "\n36.2 Covarianza",
    "text": "36.2 Covarianza\nLa covarianza misura il grado e la direzione della relazione lineare tra due variabili casuali. Una covarianza positiva indica che le due variabili tendono ad aumentare o diminuire insieme, mentre una covarianza negativa indica che una variabile tende ad aumentare quando l’altra diminuisce.\n\n36.2.1 Definizione di Covarianza\nLa covarianza tra due variabili casuali discrete \\(X\\) e \\(Y\\) è definita come:\n\\[\n\\text{Cov}(X, Y) = \\mathbb{E}\\left[(X - \\mathbb{E}[X])(Y - \\mathbb{E}[Y])\\right] .\n\\]\nEsplicitamente, questa definizione può essere riscritta come:\n\\[\n\\text{Cov}(X, Y) = \\sum_{x}\\sum_{y}(x - \\mu_X)(y - \\mu_Y)p(x, y) .\n\\]\ndove \\(\\mu_X\\) e \\(\\mu_Y\\) sono le medie delle variabili \\(X\\) e \\(Y\\) e \\(p(x,y)\\) è la funzione di massa di probabilità congiunta.\nQuesta definizione mostra una stretta analogia con la varianza, che è la covarianza di una variabile con se stessa:\n\\[\n\\mathbb{V}(X) = Cov(X, X).\n\\]\nInoltre, la covarianza può essere calcolata attraverso la relazione:\n\\[\nCov(X, Y) = \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y).\n\\]\n\n36.2.2 Dimostrazione\nLa formula alternativa per la covarianza si dimostra come segue.\nPer definizione, la covarianza tra due variabili casuali \\(X\\) e \\(Y\\) è:\n\\[\n\\mathrm{Cov}(X, Y) \\;=\\; \\mathbb{E}\\Bigl[\\bigl(X - \\mathbb{E}[X]\\bigr)\\,\\bigl(Y - \\mathbb{E}[Y]\\bigr)\\Bigr].\n\\]\nQuesta è semplicemente la definizione formale, in cui consideriamo la “deviazione” di \\(X\\) dal proprio valor medio (\\(\\mathbb{E}[X]\\)) e la “deviazione” di \\(Y\\) dal proprio valor medio (\\(\\mathbb{E}[Y]\\)), e ne calcoliamo l’aspettativa del prodotto.\nConsideriamo l’argomento dell’aspettativa: \\(\\bigl(X - \\mathbb{E}[X]\\bigr)\\,\\bigl(Y - \\mathbb{E}[Y]\\bigr)\\).\nPer prima cosa espandiamo il prodotto come faremmo con normali variabili algebriche:\n\\[\n\\bigl(X - \\mathbb{E}[X]\\bigr)\\,\\bigl(Y - \\mathbb{E}[Y]\\bigr)\n= X\\,Y \\;-\\; X\\,\\mathbb{E}[Y] \\;-\\; \\mathbb{E}[X]\\,Y \\;+\\; \\mathbb{E}[X]\\mathbb{E}[Y].\n\\]\nAdesso prendiamo l’aspettativa (o valore atteso) di ciascun termine che abbiamo ottenuto. Indichiamo con \\(\\mathbb{E}\\) l’operatore di aspettativa:\n\\[\n\\mathbb{E}\\Bigl[\\bigl(X - \\mathbb{E}[X]\\bigr)\\,\\bigl(Y - \\mathbb{E}[Y]\\bigr)\\Bigr]\n= \\mathbb{E}[\\,X\\,Y \\;-\\; X\\,\\mathbb{E}[Y] \\;-\\; \\mathbb{E}[X]\\,Y \\;+\\; \\mathbb{E}[X]\\mathbb{E}[Y]\\,].\n\\]\nGrazie alla linearità dell’aspettativa, possiamo scindere questa grande aspettativa in una somma (e differenza) di aspettative di singoli termini:\n\\[\n= \\mathbb{E}[XY]\n\\;-\\; \\mathbb{E}[X\\,\\mathbb{E}[Y]]\n\\;-\\; \\mathbb{E}[\\mathbb{E}[X]\\,Y]\n\\;+\\; \\mathbb{E}[\\mathbb{E}[X]\\mathbb{E}[Y]].\n\\]\nRicordiamo che \\(\\mathbb{E}[X]\\) e \\(\\mathbb{E}[Y]\\) sono numeri (costanti) e non variabili casuali. Dunque, quando nell’aspettativa compare un fattore costante, possiamo estrarlo fuori dall’operatore \\(\\mathbb{E}[\\cdot]\\).\n\n\\(\\mathbb{E}[X\\,\\mathbb{E}[Y]]\\) si semplifica in \\(\\mathbb{E}[Y]\\cdot \\mathbb{E}[X]\\) perché \\(\\mathbb{E}[Y]\\) è una costante. In formula: \\[\n\\mathbb{E}[X\\,\\mathbb{E}[Y]]\n= \\mathbb{E}[Y] \\,\\mathbb{E}[X].\n\\]\nAllo stesso modo, \\(\\mathbb{E}[\\mathbb{E}[X]\\,Y]\\) si semplifica in \\(\\mathbb{E}[X]\\cdot \\mathbb{E}[Y]\\).\nInfine, \\(\\mathbb{E}[\\mathbb{E}[X]\\mathbb{E}[Y]]\\) è \\(\\mathbb{E}[X]\\mathbb{E}[Y]\\) in quanto \\(\\mathbb{E}[X]\\mathbb{E}[Y]\\) è già una costante.\n\nUsando queste regole, riscriviamo i termini:\n\\[\n\\mathbb{E}[XY]\n\\;-\\; \\mathbb{E}[X]\\mathbb{E}[Y]\n\\;-\\; \\mathbb{E}[X]\\mathbb{E}[Y]\n\\;+\\; \\mathbb{E}[X]\\mathbb{E}[Y].\n\\]\nOsserviamo i termini rimanenti:\n\\[\n\\mathbb{E}[XY] \\;-\\; \\mathbb{E}[X]\\mathbb{E}[Y]\n\\;-\\; \\mathbb{E}[X]\\mathbb{E}[Y]\n\\;+\\; \\mathbb{E}[X]\\mathbb{E}[Y].\n\\]\n\nIl termine \\(\\mathbb{E}[X]\\mathbb{E}[Y]\\) compare due volte in negativo (\\(-\\,\\mathbb{E}[X]\\mathbb{E}[Y]\\)) e una volta in positivo (\\(+\\,\\mathbb{E}[X]\\mathbb{E}[Y]\\)).\n\nFacendo la somma algebrica, ne rimane solo \\(-\\,\\mathbb{E}[X]\\mathbb{E}[Y]\\) (perché \\(-\\,1 -\\,1 +\\,1 = -\\,1\\)).\n\nQuindi il risultato è:\n\\[\n\\mathbb{E}[XY]\n\\;-\\; \\mathbb{E}[X]\\mathbb{E}[Y].\n\\]\nAbbiamo quindi dimostrato in maniera esplicita che:\n\\[\n\\mathrm{Cov}(X, Y)\n= \\mathbb{E}\\bigl[(X - \\mathbb{E}[X]) (Y - \\mathbb{E}[Y])\\bigr]\n= \\mathbb{E}[XY] - \\mathbb{E}[X]\\mathbb{E}[Y].\n\\]\n\n36.2.3 Esempio Psicologico: Covarianza tra Ansia e Prestazione Cognitiva\nRiprendendo i dati del capitolo precedente sulla relazione tra ansia (Y) e prestazione cognitiva (X), calcoliamo ora la covarianza.\nMedie marginali:\n\nPrestazione cognitiva \\(X\\):\\[\\mathbb{E}(X)=0\\times0.30 + 1\\times0.45 + 2\\times0.25=0.95\\]\n\nAnsia \\(Y\\):\\[\\mathbb{E}(Y)=0\\times0.30 + 1\\times0.40 + 2\\times0.30=1.00\\]\n\n\nCalcoliamo \\(\\mathbb{E}(XY)\\):\n\\[\n\\begin{aligned}\n\\mathbb{E}(XY) &= (0\\times0\\times0.05)+(0\\times1\\times0.10)+(0\\times2\\times0.15)+\n\\notag\\\\\n& \\quad (1\\times0\\times0.15)+(1\\times1\\times0.20)+(1\\times2\\times0.10)+\n\\notag\\\\\n& \\quad(2\\times0\\times0.10)+(2\\times1\\times0.10)+(2\\times2\\times0.05)\n\\end{aligned}\n\\]\nSimplificando:\n\\[\\mathbb{E}(XY)=0.00+0.00+0.00+0.00+0.20+0.20+0.00+0.20+0.20=0.80\\]\nQuindi, la covarianza sarà:\n\\[\\text{Cov}(X,Y)=\\mathbb{E}(XY)-\\mathbb{E}(X)\\mathbb{E}(Y)=0.80-(0.95\\times1.00)=-0.15\\]\nLa covarianza negativa indica che all’aumentare del livello di ansia tende a corrispondere una diminuzione della prestazione cognitiva, coerentemente con quanto spesso riscontrato nella letteratura psicologica.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Covarianza e correlazione</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11b_cov_cor.html#correlazione",
    "href": "chapters/probability/11b_cov_cor.html#correlazione",
    "title": "36  Covarianza e correlazione",
    "section": "\n36.3 Correlazione",
    "text": "36.3 Correlazione\nLa correlazione standardizza la covarianza, rendendola indipendente dalle unità di misura delle variabili. Essa varia tra -1 e 1 ed è definita come:\n\\[\n\\rho(X,Y)=\\frac{\\text{Cov}(X,Y)}{\\sqrt{\\text{Var}(X)\\text{Var}(Y)}} .\n\\]\ndove \\(\\mathbb{V}(X)\\) e \\(\\mathbb{V}(Y)\\) rappresentano le varianze di \\(X\\) e \\(Y\\), rispettivamente.\nIl coefficiente di correlazione \\(\\rho_{xy}\\) è un valore adimensionale, ovvero non dipende dalle unità di misura delle variabili, e varia nell’intervallo \\(-1 \\leq \\rho \\leq 1\\).\n\n36.3.1 Calcolo della Correlazione\nPer calcolare la correlazione tra ansia e prestazione cognitiva, dobbiamo prima ottenere le varianze di ciascuna variabile.\n\nVarianza di X (prestazione cognitiva):\n\n\\[\n\\begin{aligned}\n\\text{Var}(X) &=\\sum_{x}(x-\\mu_X)^2p(x)\n\\notag\\\\\n&= (0-0.95)^2\\times0.30+(1-0.95)^2\\times0.45+(2-0.95)^2\\times0.25=0.5475 \\notag\n\\end{aligned}\n\\]\n\nVarianza di Y (ansia):\n\n\\[\n\\begin{aligned}\n\\text{Var}(Y) &=\\sum_{y}(y-\\mu_Y)^2p(y) \\notag\\\\\n&= (0-1.00)^2\\times0.30+(1-1.00)^2\\times0.40+(2-1.00)^2\\times0.30=0.60 \\notag\n\\end{aligned}\n\\]\nQuindi, il coefficiente di correlazione è:\n\\[\n\\rho(X,Y)=\\frac{-0.15}{\\sqrt{0.5475\\times0.60}}=-0.261\n\\]\nIl valore negativo della correlazione conferma che ansia e prestazione cognitiva presentano una relazione inversa: all’aumentare dell’ansia, la prestazione tende a diminuire.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Covarianza e correlazione</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11b_cov_cor.html#interpretazione-della-correlazione",
    "href": "chapters/probability/11b_cov_cor.html#interpretazione-della-correlazione",
    "title": "36  Covarianza e correlazione",
    "section": "\n36.4 Interpretazione della Correlazione",
    "text": "36.4 Interpretazione della Correlazione\nIl coefficiente di correlazione è una misura standardizzata e facile da interpretare:\n\n\n\\(\\rho = 1\\): perfetta relazione lineare positiva\n\n\\(\\rho = -1\\): perfetta relazione lineare negativa\n\n\\(\\rho = 0\\): assenza di relazione lineare\n\nNel nostro esempio, il valore \\(-0.261\\) indica una relazione lineare negativa moderata tra ansia e prestazione.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Covarianza e correlazione</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11b_cov_cor.html#proprietà",
    "href": "chapters/probability/11b_cov_cor.html#proprietà",
    "title": "36  Covarianza e correlazione",
    "section": "\n36.5 Proprietà",
    "text": "36.5 Proprietà\n\n\nCovarianza con una Costante: La covarianza tra una variabile aleatoria \\(X\\) e una costante \\(c\\) è sempre nulla: \\(Cov(c, X) = 0\\).\n\nSimmetria: La covarianza è simmetrica: \\(Cov(X,Y) = Cov(Y,X)\\).\n\nIntervallo di Correlazione: Il coefficiente di correlazione \\(\\rho\\) varia tra -1 e 1: \\(-1 \\leq \\rho(X,Y) \\leq 1\\).\n\nIndipendenza dalle Unità di Misura: La correlazione è indipendente dalle unità di misura: \\(\\rho(aX, bY) = \\rho(X,Y)\\) per ogni \\(a, b &gt; 0\\).\n\nRelazione Lineare Perfetta: Se \\(Y = a + bX\\) è una funzione lineare di \\(X\\), allora \\(\\rho(X,Y) = \\pm 1\\), a seconda del segno di \\(b\\).\n\nCovarianza e Costanti: La covarianza tra \\(X\\) e \\(Y\\), ciascuna moltiplicata per una costante, è \\(Cov(aX, bY) = ab \\, Cov(X,Y)\\).\n\nVarianza della Somma/Differenza: \\(\\mathbb{V}(X \\pm Y) = \\mathbb{V}(X) + \\mathbb{V}(Y) \\pm 2Cov(X,Y)\\).\n\nCovarianza e Somma di Variabili: \\(Cov(X + Y, Z) = Cov(X,Z) + Cov(Y,Z)\\).\n\nVarianza di una Somma di Variabili Aleatorie: Per variabili aleatorie \\(X_1, \\dots, X_n\\), si ha \\(\\mathbb{V}(\\sum_{i=1}^n X_i) = \\sum_{i=1}^n \\mathbb{V}(X_i) + 2\\sum_{i&lt;j} Cov(X_i, X_j)\\).\n\nCovarianza e Somme di Prodotti: \\(Cov(\\sum_{i=1}^n a_i X_i, \\sum_{j=1}^m b_j Y_j) = \\sum_{i=1}^n \\sum_{j=1}^m a_i b_j Cov(X_i, Y_j)\\).\n\nIndipendenza e Covarianza di Somme: Se \\(X_1, X_2, \\dots, X_n\\) sono indipendenti, allora \\(Cov(\\sum_{i=1}^n a_i X_i, \\sum_{j=1}^n b_j X_j) = \\sum_{i=1}^n a_i b_i \\mathbb{V}(X_i)\\).\n\n\n36.5.1 Incorrelazione\nDue variabili casuali \\(X\\) ed \\(Y\\) si dicono incorrelate, o linearmente indipendenti, se la loro covarianza è nulla:\n\\[\nCov(X,Y) = \\mathbb{E}[(X - \\mu_X)(Y - \\mu_Y)] = 0,\n\\]\nequivalente a dire che \\(\\rho_{XY} = 0\\) e \\(\\mathbb{E}(XY) = \\mathbb{E}(X)\\mathbb{E}(Y)\\).\nQuesta condizione indica una forma di indipendenza più debole rispetto all’indipendenza stocastica. Tuttavia, \\(Cov(X, Y) = 0\\) non implica necessariamente che \\(X\\) ed \\(Y\\) siano stocasticamente indipendenti.\n\nEsempio 36.1 Consideriamo una distribuzione di probabilità congiunta di due variabili aleatorie, \\(X\\) e \\(Y\\), definita come:\n\\[\nf_{XY}(x,y) = \\left\\{\n\\begin{array}{ll}\n\\frac{1}{4} & \\text{per } (x,y) \\in \\{(0,0), (1,1), (1, -1), (2,0) \\}, \\\\\n0 & \\text{altrimenti.}\n\\end{array}\n\\right.\n\\]\nQuesto implica che le variabili aleatorie \\(X\\) e \\(Y\\) assumono valori specifici con probabilità uniforme solo per determinate coppie \\((x, y)\\) e zero in tutti gli altri casi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Covarianza e correlazione</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11b_cov_cor.html#conclusioni",
    "href": "chapters/probability/11b_cov_cor.html#conclusioni",
    "title": "36  Covarianza e correlazione",
    "section": "\n36.6 Conclusioni",
    "text": "36.6 Conclusioni\nLa covarianza e la correlazione forniscono strumenti essenziali per quantificare le relazioni tra variabili casuali. Utilizzare queste misure permette di approfondire la comprensione delle relazioni psicologiche, come quella tra ansia e prestazione, facilitando ulteriori analisi statistiche e interpretazioni teoriche.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Covarianza e correlazione</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11b_cov_cor.html#esercizi",
    "href": "chapters/probability/11b_cov_cor.html#esercizi",
    "title": "36  Covarianza e correlazione",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nEsercizio 1: Distribuzione congiunta di due lanci di dado\nSi lancia due volte un dado a sei facce equilibrato. Siano:\n\n\n\\(X\\) il risultato del primo lancio.\n\n\\(Y\\) il risultato del secondo lancio.\n\n\nCostruisci la tabella della distribuzione congiunta \\(P(X, Y)\\), considerando che tutti i risultati possibili hanno la stessa probabilità.\nVerifica che la somma delle probabilità sia 1.\nDetermina la distribuzione marginale di \\(X\\) e di \\(Y\\).\nLe variabili \\(X\\) e \\(Y\\) sono indipendenti? Giustifica la risposta.\n\nEsercizio 2: Somma di due dadi\nSi lancia due volte un dado a sei facce. Definiamo:\n\n\n\\(S = X + Y\\), la somma dei due risultati.\n\n\nCostruisci la tabella di probabilità congiunta \\(P(X, Y)\\).\nCalcola la distribuzione di probabilità della variabile aleatoria \\(S\\).\nDetermina \\(P(S = 7)\\) e \\(P(S \\leq 5)\\).\nQual è il valore più probabile di \\(S\\)? E il meno probabile?\n\nEsercizio 3: Lancio di tre monete\nSi lanciano tre monete equilibrate. Definiamo:\n\n\n\\(X\\) il numero di teste ottenute.\n\n\\(Y\\) il risultato del primo lancio (1 se testa, 0 se croce).\n\n\nDetermina lo spazio campionario e associa i valori delle variabili aleatorie \\(X\\) e \\(Y\\).\nCostruisci la distribuzione congiunta \\(P(X, Y)\\).\nCalcola \\(P(X = 2 \\mid Y = 1)\\) e \\(P(Y = 1 \\mid X = 2)\\).\nLe variabili \\(X\\) e \\(Y\\) sono indipendenti?\n\nEsercizio 4: Minimo e massimo tra due dadi\nSi lancia due volte un dado a sei facce. Definiamo:\n\n\n\\(X = \\min \\{X_1, X_2\\}\\), il valore minimo tra i due lanci.\n\n\\(Y = \\max \\{X_1, X_2\\}\\), il valore massimo tra i due lanci.\n\n\nCostruisci la tabella della distribuzione congiunta \\(P(X, Y)\\).\nCalcola \\(P(X = 3, Y = 5)\\) e \\(P(X \\geq 3, Y \\leq 4)\\).\nDetermina la distribuzione marginale di \\(X\\) e di \\(Y\\).\nCalcola la covarianza tra \\(X\\) e \\(Y\\).\n\nEsercizio 5: Differenza tra due dadi\nSi lanciano due dadi a sei facce. Definiamo:\n\n\n\\(X\\) il risultato del primo lancio.\n\n\\(Y\\) la differenza assoluta tra i due risultati, ovvero \\(Y = |X - X_2|\\).\n\n\nDetermina la tabella della distribuzione congiunta \\(P(X, Y)\\).\nCalcola la distribuzione marginale di \\(Y\\).\nDetermina \\(P(Y = 0)\\) e \\(P(Y = 3)\\).\nLe variabili \\(X\\) e \\(Y\\) sono indipendenti? Giustifica la risposta.\n\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\nEsercizio 1: Distribuzione congiunta di due lanci di dado\nAbbiamo due variabili aleatorie discrete: - \\(X\\), risultato del primo lancio di un dado a sei facce. - \\(Y\\), risultato del secondo lancio.\n1. Tabella della distribuzione congiunta \\(P(X, Y)\\) Poiché il dado è equo, ogni coppia di risultati \\((x, y)\\) ha la stessa probabilità. Esistono \\(6 \\times 6 = 36\\) combinazioni possibili, e ognuna ha probabilità:\n\\[\nP(X = x, Y = y) = \\frac{1}{36}, \\quad \\text{per ogni } x, y \\in \\{1, 2, 3, 4, 5, 6\\}\n\\]\nLa tabella della distribuzione congiunta è:\n\n\n\n\\(X\\)  \\(Y\\)\n\n1\n2\n3\n4\n5\n6\n\n\n\n1\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n\n\n2\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n\n\n3\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n\n\n4\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n\n\n5\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n\n\n6\n1/36\n1/36\n1/36\n1/36\n1/36\n1/36\n\n\n\n2. Verifica che la somma delle probabilità sia 1 La somma di tutte le probabilità è:\n\\[\n\\sum_{x=1}^{6} \\sum_{y=1}^{6} P(X = x, Y = y) = 36 \\times \\frac{1}{36} = 1.\n\\]\n3. Distribuzione marginale di \\(X\\) e \\(Y\\) Per ottenere la distribuzione marginale di \\(X\\):\n\\[\nP(X = x) = \\sum_{y=1}^{6} P(X = x, Y = y) = 6 \\times \\frac{1}{36} = \\frac{1}{6}, \\quad \\forall x.\n\\]\nAnalogamente, per \\(Y\\):\n\\[\nP(Y = y) = \\sum_{x=1}^{6} P(X = x, Y = y) = \\frac{1}{6}, \\quad \\forall y.\n\\]\nEntrambe seguono una distribuzione uniforme su \\(\\{1, 2, 3, 4, 5, 6\\}\\).\n4. Indipendenza di \\(X\\) e \\(Y\\) Due variabili sono indipendenti se \\(P(X = x, Y = y) = P(X = x) P(Y = y)\\).\n\\[\n\\frac{1}{36} = \\frac{1}{6} \\times \\frac{1}{6} = \\frac{1}{36}, \\quad \\forall x, y.\n\\]\nPoiché questa relazione vale per tutti i valori, \\(X\\) e \\(Y\\) sono indipendenti.\nEsercizio 2: Somma di due dadi\nAbbiamo:\n\\[\nS = X + Y\n\\]\n1. Tabella di probabilità congiunta \\(P(X, Y)\\) È la stessa tabella costruita nel primo esercizio.\n2. Distribuzione di probabilità di \\(S\\) La somma \\(S\\) assume valori da \\(2\\) (1+1) a \\(12\\) (6+6). La probabilità di ogni valore di \\(S\\) si ottiene contando le coppie \\((x, y)\\) che lo producono:\n\n\n\\(S\\)\n\\(P(S)\\)\n\n\n\n2\n1/36\n\n\n3\n2/36\n\n\n4\n3/36\n\n\n5\n4/36\n\n\n6\n5/36\n\n\n7\n6/36\n\n\n8\n5/36\n\n\n9\n4/36\n\n\n10\n3/36\n\n\n11\n2/36\n\n\n12\n1/36\n\n\n\n3. Calcolo di \\(P(S = 7)\\) e \\(P(S \\leq 5)\\) - \\(P(S = 7) = 6/36 = 1/6\\). - \\(P(S \\leq 5) = P(S = 2) + P(S = 3) + P(S = 4) + P(S = 5)\\)\n\\[\n\\frac{1}{36} + \\frac{2}{36} + \\frac{3}{36} + \\frac{4}{36} = \\frac{10}{36} = \\frac{5}{18}.\n\\]\n4. Valori più probabili e meno probabili - Il valore più probabile è \\(S = 7\\) (\\(P(S=7) = 1/6\\)). - I valori meno probabili sono \\(S = 2\\) e \\(S = 12\\) (\\(P(S) = 1/36\\)).\nEsercizio 3: Lancio di tre monete\nAbbiamo:\n\nTre monete equilibrare.\nVariabili:\n\n\n\\(X\\): numero di teste ottenute.\n\n\\(Y\\): risultato del primo lancio (1 se testa, 0 se croce).\n\n\n\n1. Spazio campionario e valori di \\(X\\) e \\(Y\\)\nLo spazio campionario dei lanci è:\n\\[\n\\{ (C, C, C), (C, C, T), (C, T, C), (C, T, T), (T, C, C), (T, C, T), (T, T, C), (T, T, T) \\}\n\\]\nOra assegniamo \\(X\\) e \\(Y\\):\n\n\nLancio\n\n\\(X\\) (num. teste)\n\n\\(Y\\) (primo lancio)\n\n\n\nC, C, C\n0\n0\n\n\nC, C, T\n1\n0\n\n\nC, T, C\n1\n0\n\n\nC, T, T\n2\n0\n\n\nT, C, C\n1\n1\n\n\nT, C, T\n2\n1\n\n\nT, T, C\n2\n1\n\n\nT, T, T\n3\n1\n\n\n\n2. Distribuzione congiunta \\(P(X, Y)\\)\nPoiché ogni lancio ha probabilità \\(\\frac{1}{8}\\), la tabella di probabilità congiunta è:\n\n\n\n\\(X\\)  \\(Y\\)\n\n0\n1\n\n\n\n0\n1/8\n0\n\n\n1\n2/8\n1/8\n\n\n2\n1/8\n3/8\n\n\n3\n0\n1/8\n\n\n\n3. Probabilità condizionate \\(P(X = 2 \\mid Y = 1)\\) \\[\nP(X = 2 \\mid Y = 1) = \\frac{P(X = 2, Y = 1)}{P(Y = 1)} = \\frac{3/8}{5/8} = \\frac{3}{5}.\n\\]\n\\(P(Y = 1 \\mid X = 2)\\) \\[\nP(Y = 1 \\mid X = 2) = \\frac{P(X = 2, Y = 1)}{P(X = 2)} = \\frac{3/8}{4/8} = \\frac{3}{4}.\n\\]\n4. Indipendenza di \\(X\\) e \\(Y\\)\nVerifichiamo se \\(P(X = x, Y = y) = P(X = x) P(Y = y)\\) per ogni coppia.\nEsempio: \\(P(X = 2, Y = 1) = 3/8\\) ma \\(P(X=2) P(Y=1) = (4/8)(5/8) = 20/64 = 5/16 \\neq 3/8\\).\nQuindi \\(X\\) e \\(Y\\) non sono indipendenti.\nEsercizio 4: Minimo e massimo tra due dadi\nAbbiamo:\n\n\n\\(X = \\min(X_1, X_2)\\), il minimo tra i due lanci.\n\n\\(Y = \\max(X_1, X_2)\\), il massimo tra i due lanci.\n\n1. Tabella della distribuzione congiunta\nPoiché i due lanci sono indipendenti e simmetrici, ci sono 36 coppie \\((X_1, X_2)\\), e ogni coppia ha probabilità \\(\\frac{1}{36}\\).\nLa tabella congiunta si costruisce considerando che \\(X = \\min(X_1, X_2)\\) e \\(Y = \\max(X_1, X_2)\\):\n\n\n\n\\(X\\)  \\(Y\\)\n\n1\n2\n3\n4\n5\n6\n\n\n\n1\n1/36\n2/36\n3/36\n4/36\n5/36\n6/36\n\n\n2\n-\n1/36\n2/36\n3/36\n4/36\n5/36\n\n\n3\n-\n-\n1/36\n2/36\n3/36\n4/36\n\n\n4\n-\n-\n-\n1/36\n2/36\n3/36\n\n\n5\n-\n-\n-\n-\n1/36\n2/36\n\n\n6\n-\n-\n-\n-\n-\n1/36\n\n\n\n2. Probabilità richieste\n\n\n\\(P(X = 3, Y = 5) = 3/36\\).\n\n\\(P(X \\geq 3, Y \\leq 4) = P(X = 3, Y = 3) + P(X = 3, Y = 4) + P(X = 4, Y = 4) = 1/36 + 2/36 + 1/36 = 4/36 = 1/9\\).\n\nEsercizio 5: Differenza tra due dadi\nAbbiamo:\n\n\n\\(X\\) = primo lancio.\n\n\\(Y = |X - X_2|\\).\n\n1. Tabella della distribuzione congiunta \\(P(X, Y)\\)\n\\(Y\\) assume valori da 0 a 5, a seconda della differenza tra i due dadi:\n\n\n\n\\(X\\)  \\(Y\\)\n\n0\n1\n2\n3\n4\n5\n\n\n\n1\n1/6\n1/6\n1/6\n1/6\n1/6\n1/6\n\n\n2\n1/6\n2/6\n1/6\n1/6\n1/6\n0\n\n\n3\n1/6\n2/6\n2/6\n1/6\n0\n0\n\n\n4\n1/6\n2/6\n2/6\n1/6\n0\n0\n\n\n5\n1/6\n2/6\n1/6\n1/6\n0\n0\n\n\n6\n1/6\n1/6\n1/6\n1/6\n0\n0\n\n\n\n2. Distribuzione marginale di \\(Y\\)\nSommiamo lungo \\(X\\):\n\n\n\\(Y\\)\n\\(P(Y)\\)\n\n\n\n0\n6/36\n\n\n1\n10/36\n\n\n2\n8/36\n\n\n3\n6/36\n\n\n4\n4/36\n\n\n5\n2/36\n\n\n\n3. Probabilità richieste\n\n\n\\(P(Y = 0) = 6/36 = 1/6\\).\n\n\\(P(Y = 3) = 6/36 = 1/6\\).\n\n4. Indipendenza di \\(X\\) e \\(Y\\)\nCome nell’esercizio 3, verifichiamo che \\(P(X, Y) \\neq P(X) P(Y)\\) per alcune coppie. Essendo la tabella non simmetrica, \\(X\\) e \\(Y\\) non sono indipendenti.\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nConsidera il seguente esperimento casuale: si estrae una pallina da un’urna contenente tre palline numerate con i valori \\(1\\), \\(2\\) e \\(3\\).\nDopo l’estrazione, si definiscono due variabili casuali:\n\n\n\\(X\\), il valore della pallina estratta.\n\n\\(Y\\), il valore di un’altra variabile definita come \\(Y = X^2\\).\n\n\nCostruisci la distribuzione congiunta di \\(X\\) e \\(Y\\).\nCalcola il valore atteso di \\(X\\) e \\(Y\\), ossia \\(E[X]\\) e \\(E[Y]\\).\nCalcola la covarianza tra \\(X\\) e \\(Y\\), ossia \\(\\text{Cov}(X, Y)\\).\nCalcola la correlazione tra \\(X\\) e \\(Y\\), ossia \\(\\rho(X, Y)\\).\nInterpreta il valore della correlazione: cosa indica il segno e il valore ottenuto?\n\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\n1. Distribuzione congiunta di \\(X\\) e \\(Y\\)\nPoiché ogni pallina ha la stessa probabilità di essere estratta, la distribuzione congiunta è:\n\n\n\\(X\\)\n\\(Y = X^2\\)\n\\(P(X, Y)\\)\n\n\n\n1\n1\n\\(\\frac{1}{3}\\)\n\n\n2\n4\n\\(\\frac{1}{3}\\)\n\n\n3\n9\n\\(\\frac{1}{3}\\)\n\n\n\n2. Calcolo di \\(E[X]\\) e \\(E[Y]\\)\n\\[\nE[X] = \\sum_{i} x_i P(X = x_i) = 1 \\cdot \\frac{1}{3} + 2 \\cdot \\frac{1}{3} + 3 \\cdot \\frac{1}{3} = \\frac{1 + 2 + 3}{3} = 2\n\\]\n\\[\nE[Y] = \\sum_{i} y_i P(Y = y_i) = 1 \\cdot \\frac{1}{3} + 4 \\cdot \\frac{1}{3} + 9 \\cdot \\frac{1}{3} = \\frac{1 + 4 + 9}{3} = \\frac{14}{3}\n\\]\n3. Calcolo della covarianza \\(\\text{Cov}(X, Y)\\)\nLa covarianza è definita come:\n\\[\n\\text{Cov}(X, Y) = E[XY] - E[X]E[Y]\n\\]\nPrima calcoliamo \\(E[XY]\\):\n\\[\nE[XY] = \\sum_{i} x_i y_i P(X = x_i, Y = y_i) = 1 \\cdot 1 \\cdot \\frac{1}{3} + 2 \\cdot 4 \\cdot \\frac{1}{3} + 3 \\cdot 9 \\cdot \\frac{1}{3}\n\\]\n\\[\n= \\frac{1 + 8 + 27}{3} = \\frac{36}{3} = 12\n\\]\nOra possiamo calcolare la covarianza:\n\\[\n\\text{Cov}(X, Y) = E[XY] - E[X]E[Y] = 12 - \\left(2 \\cdot \\frac{14}{3}\\right) = 12 - \\frac{28}{3} = \\frac{36 - 28}{3} = \\frac{8}{3}\n\\]\n4. Calcolo della correlazione \\(\\rho(X, Y)\\)\nLa correlazione è definita come:\n\\[\n\\rho(X, Y) = \\frac{\\text{Cov}(X, Y)}{\\sigma_X \\cdot \\sigma_Y}\n\\]\nCalcoliamo prima le varianze:\n\\[\n\\text{Var}(X) = E[X^2] - (E[X])^2\n\\]\n\\[\nE[X^2] = 1^2 \\cdot \\frac{1}{3} + 2^2 \\cdot \\frac{1}{3} + 3^2 \\cdot \\frac{1}{3} = \\frac{1 + 4 + 9}{3} = \\frac{14}{3}\n\\]\n\\[\n\\text{Var}(X) = \\frac{14}{3} - 2^2 = \\frac{14}{3} - 4 = \\frac{14 - 12}{3} = \\frac{2}{3}\n\\]\nOra la varianza di \\(Y\\):\n\\[\n\\text{Var}(Y) = E[Y^2] - (E[Y])^2\n\\]\n\\[\nE[Y^2] = 1^2 \\cdot \\frac{1}{3} + 4^2 \\cdot \\frac{1}{3} + 9^2 \\cdot \\frac{1}{3} = \\frac{1 + 16 + 81}{3} = \\frac{98}{3}\n\\]\n\\[\n\\text{Var}(Y) = \\frac{98}{3} - \\left(\\frac{14}{3}\\right)^2 = \\frac{98}{3} - \\frac{196}{9} = \\frac{98 \\cdot 3 - 196}{9} = \\frac{294 - 196}{9} = \\frac{98}{9}\n\\]\nCalcoliamo le deviazioni standard:\n\\[\n\\sigma_X = \\sqrt{\\text{Var}(X)} = \\sqrt{\\frac{2}{3}} = \\frac{\\sqrt{6}}{3}\n\\]\n\\[\n\\sigma_Y = \\sqrt{\\text{Var}(Y)} = \\sqrt{\\frac{98}{9}} = \\frac{\\sqrt{98}}{3}\n\\]\nOra possiamo calcolare la correlazione:\n\\[\n\\rho(X, Y) = \\frac{\\text{Cov}(X, Y)}{\\sigma_X \\cdot \\sigma_Y} = \\frac{\\frac{8}{3}}{\\frac{\\sqrt{6}}{3} \\cdot \\frac{\\sqrt{98}}{3}}\n\\]\n\\[\n= \\frac{\\frac{8}{3}}{\\frac{\\sqrt{6 \\cdot 98}}{9}} = \\frac{8 \\cdot 9}{3 \\cdot \\sqrt{6 \\cdot 98}} = \\frac{24}{\\sqrt{588}}\n\\]\nPoiché \\(\\sqrt{588} = \\sqrt{4 \\cdot 147} = 2\\sqrt{147} = 2\\sqrt{49 \\cdot 3} = 2 \\cdot 7 \\cdot \\sqrt{3} = 14\\sqrt{3}\\):\n\\[\n\\rho(X, Y) = \\frac{24}{14\\sqrt{3}} = \\frac{12}{7\\sqrt{3}} = \\frac{12\\sqrt{3}}{21} \\approx 0.995\n\\]\n5. Interpretazione della correlazione\n\nIl valore \\(\\rho(X, Y) \\approx 0.995\\) è molto vicino a 1, indicando una correlazione positiva quasi perfetta tra \\(X\\) e \\(Y\\).\nIl segno positivo indica che all’aumentare di \\(X\\), anche \\(Y\\) tende ad aumentare.\nL’alto valore (prossimo a 1) indica che la relazione tra \\(X\\) e \\(Y\\) è quasi perfettamente lineare, il che è coerente con la definizione \\(Y = X^2\\) nell’intervallo considerato (piccoli valori positivi di \\(X\\)).\n\n\n\n\n\n\n\n\n\n\nProblemi 3\n\n\n\n\n\nEsercizi sulla distribuzione di probabilità congiunta sono disponibili sulla seguente pagina web.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Covarianza e correlazione</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11b_cov_cor.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/11b_cov_cor.html#informazioni-sullambiente-di-sviluppo",
    "title": "36  Covarianza e correlazione",
    "section": "\n36.7 Informazioni sull’Ambiente di Sviluppo",
    "text": "36.7 Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.7   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.13.0 psych_2.5.3     \n#&gt;  [9] scales_1.4.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.3.0     ggplot2_3.5.2   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.4     stringi_1.8.7      lattice_0.22-7    \n#&gt;  [4] hms_1.1.3          digest_0.6.37      magrittr_2.0.3    \n#&gt;  [7] evaluate_1.0.4     grid_4.5.0         timechange_0.3.0  \n#&gt; [10] RColorBrewer_1.1-3 fastmap_1.2.0      rprojroot_2.0.4   \n#&gt; [13] jsonlite_2.0.0     mnormt_2.1.1       cli_3.6.5         \n#&gt; [16] rlang_1.1.6        withr_3.0.2        tools_4.5.0       \n#&gt; [19] parallel_4.5.0     tzdb_0.5.0         pacman_0.5.1      \n#&gt; [22] vctrs_0.6.5        R6_2.6.1           lifecycle_1.0.4   \n#&gt; [25] htmlwidgets_1.6.4  pkgconfig_2.0.3    pillar_1.10.2     \n#&gt; [28] gtable_0.3.6       glue_1.8.0         xfun_0.52         \n#&gt; [31] tidyselect_1.2.1   rstudioapi_0.17.1  farver_2.1.2      \n#&gt; [34] htmltools_0.5.8.1  nlme_3.1-168       rmarkdown_2.29    \n#&gt; [37] compiler_4.5.0",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Covarianza e correlazione</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11b_cov_cor.html#bibliografia",
    "href": "chapters/probability/11b_cov_cor.html#bibliografia",
    "title": "36  Covarianza e correlazione",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.\n\n\nChan, J. C. C., & Kroese, D. P. (2025). Statistical Modeling and Computation (2ª ed.). Springer.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Covarianza e correlazione</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11c_joint_prob_cont.html",
    "href": "chapters/probability/11c_joint_prob_cont.html",
    "title": "37  Caso continuo",
    "section": "",
    "text": "37.1 Introduzione\nImmaginate di voler studiare la relazione tra due caratteristiche psicologiche, ad esempio:\nQueste variabili sono chiamate continue perché possono assumere qualsiasi valore all’interno di certi intervalli, e non solo valori specifici come accade con le variabili discrete (es. numero di risposte corrette a un quiz).\nQuando consideriamo contemporaneamente due variabili continue, parliamo di densità di probabilità congiunta. Questa ci permette di visualizzare e analizzare come le due variabili tendono a manifestarsi insieme.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Caso continuo</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11c_joint_prob_cont.html#introduzione",
    "href": "chapters/probability/11c_joint_prob_cont.html#introduzione",
    "title": "37  Caso continuo",
    "section": "",
    "text": "livello di ansia (da 20 a 80 punti su una scala analogica visiva);\n\nprestazione cognitiva (da 0 a 100 punti su un test di memoria in cui sono possibili punteggi frazionari).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Caso continuo</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11c_joint_prob_cont.html#la-densità-congiunta-continua-come-una-mappa-termica",
    "href": "chapters/probability/11c_joint_prob_cont.html#la-densità-congiunta-continua-come-una-mappa-termica",
    "title": "37  Caso continuo",
    "section": "\n37.2 La Densità Congiunta Continua come una Mappa Termica",
    "text": "37.2 La Densità Congiunta Continua come una Mappa Termica\nPer capire meglio, immaginate la densità congiunta come una mappa termica (heatplot) in cui:\n\nl’asse orizzontale (asse X) rappresenta il livello di ansia (0-100);\nl’asse verticale (asse Y) rappresenta la prestazione cognitiva (0-100);\nle zone più calde indicano combinazioni più frequenti e dunque più probabili.\n\n\n# Parametri\nmu &lt;- c(30, 70)\nsigma_x &lt;- 10\nsigma_y &lt;- 15\nrho &lt;- -0.7\n\n# Matrice di covarianza\nSigma &lt;- matrix(\n  c(\n    sigma_x^2, rho * sigma_x * sigma_y,\n    rho * sigma_x * sigma_y, sigma_y^2\n  ),\n  nrow = 2\n)\n\n# Generiamo 500 osservazioni casuali\nset.seed(123)\ndati &lt;- as.data.frame(mvrnorm(500, mu, Sigma))\ncolnames(dati) &lt;- c(\"Ansia\", \"Prestazione\")\n\n# Grafico con mappa termica della densità congiunta e punti\ngrafico &lt;- ggplot(\n  dati, aes(x = Ansia, y = Prestazione)\n) +\n  stat_density_2d(\n    aes(fill = ..density..),\n    geom = \"raster\", contour = FALSE\n  ) +\n  scale_fill_viridis(option = \"viridis\") +\n  geom_density_2d(\n    color = \"black\", linewidth = 0.5, linetype = \"dotted\"\n  ) +\n  geom_point(alpha = 0.3, size = 0.8) +\n  labs(\n    title = \"Mappa termica\\ndella densità congiunta\",\n    x = \"Punteggio Ansia\",\n    y = \"Punteggio Prestazione Cognitiva\"\n  )\n\n# Aggiungere grafici marginali delle densità\ngrafico_finale &lt;- ggMarginal(\n  grafico,\n  type = \"density\",\n  fill = \"lightblue\", color = \"black\"\n)\n\n# Visualizza il grafico\ngrafico_finale\n\n\n\n\n\n\n\nSulla mappa termica la zona più calda è intorno a “ansia = 30” e “prestazione = 70”. Questo significa che la maggior parte dei soggetti mostra un livello di ansia relativamente bassa e tende a mostrare una prestazione cognitiva relativamente alta. Tuttavia, all’aumentare dell’ansia, la prestazione cognitiva tende a diminuire (Eysenck et al., 2007).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Caso continuo</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11c_joint_prob_cont.html#come-interpretare-la-probabilità",
    "href": "chapters/probability/11c_joint_prob_cont.html#come-interpretare-la-probabilità",
    "title": "37  Caso continuo",
    "section": "\n37.3 Come Interpretare la Probabilità?",
    "text": "37.3 Come Interpretare la Probabilità?\nQuando lavoriamo con variabili continue, non possiamo semplicemente contare le combinazioni come nel caso discreto (ad esempio, lanci di un dado). Invece, misuriamo la probabilità calcolando l’area della regione interessata sulla nostra mappa termica:\n\nla probabilità che l’ansia sia tra 50 e 55, e la prestazione tra 30 e 50, è rappresentata dall’area della regione corrispondente nella mappa termica;\ngli integrali (strumenti matematici per calcolare aree) sono semplicemente un modo preciso per fare questa operazione.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Caso continuo</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11c_joint_prob_cont.html#densità-marginale-proiettare-la-mappa-su-un-asse",
    "href": "chapters/probability/11c_joint_prob_cont.html#densità-marginale-proiettare-la-mappa-su-un-asse",
    "title": "37  Caso continuo",
    "section": "\n37.4 Densità Marginale: Proiettare la Mappa su un Asse",
    "text": "37.4 Densità Marginale: Proiettare la Mappa su un Asse\nLa densità marginale descrive come si distribuisce una singola variabile, prescindendo completamente dall’altra. Possiamo immaginare questo processo come la proiezione della mappa termica su uno degli assi, ottenendo così un’ombra o una proiezione dell’intera distribuzione:\n\nproiettando tutti i valori sull’asse dell’ansia, si ottiene la densità marginale dell’ansia;\nproiettando tutti i valori sull’asse della prestazione, si ottiene la densità marginale della prestazione.\n\nQueste proiezioni rivelano la distribuzione di ciascuna variabile considerata isolatamente. Nella figura a cui si fa riferimento, le distribuzioni marginali sono state elaborate utilizzando in modo indipendente i dati relativi a ciascuna variabile, senza considerare le loro interrelazioni.\nInfatti, i colori più caldi nella mappa termica indicano zone con maggiore densità di osservazioni. Quando proiettiamo questi valori su un asse, otteniamo una curva di densità che rappresenta la distribuzione della variabile. Le aree dove la curva raggiunge valori più alti corrispondono ai valori più frequenti della variabile nella popolazione studiata.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Caso continuo</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11c_joint_prob_cont.html#densità-condizionale-fette-della-mappa-termica",
    "href": "chapters/probability/11c_joint_prob_cont.html#densità-condizionale-fette-della-mappa-termica",
    "title": "37  Caso continuo",
    "section": "\n37.5 Densità Condizionale: Fette della Mappa Termica",
    "text": "37.5 Densità Condizionale: Fette della Mappa Termica\nLa densità condizionale risponde alla domanda: “Se osservo persone con un determinato punteggio di prestazione cognitiva (ad esempio 40 punti), qual è la distribuzione dell’ansia tra queste persone?”\n\nImmaginate di prendere una fetta verticale della mappa termica in corrispondenza della prestazione = 40 punti. Questa fetta mostra la distribuzione dell’ansia soltanto tra coloro che hanno esattamente quella prestazione cognitiva.\nPer rendere questa distribuzione coerente, normalizziamo (cioè “aggiustiamo”) la fetta rispetto alla probabilità complessiva della prestazione a quel livello.\n\nQuesta fetta verticale con i suoi vari colori (più caldi dove c’è maggiore densità) può essere convertita in una curva di densità che mostra come si distribuisce l’ansia specificamente per le persone con quel determinato livello di prestazione cognitiva. Il processo di normalizzazione assicura che l’area sotto questa curva di densità condizionale sia uguale a 1, consentendo confronti tra diverse condizioni.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Caso continuo</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11c_joint_prob_cont.html#perché-tutto-questo-è-importante",
    "href": "chapters/probability/11c_joint_prob_cont.html#perché-tutto-questo-è-importante",
    "title": "37  Caso continuo",
    "section": "\n37.6 Perché Tutto Questo è Importante?",
    "text": "37.6 Perché Tutto Questo è Importante?\nLa densità congiunta ci permette di identificare relazioni complesse e non lineari tra variabili psicologiche che potrebbero rimanere nascoste con analisi più semplici. Nel nostro esempio:\n\n\npotremmo scoprire varie tipologie di relazioni tra ansia e prestazione cognitiva:\n\nuna relazione negativa lineare (maggiore ansia associata a minore prestazione cognitiva);\nrelazioni curvilinee (come la relazione a U rovesciata della legge di Yerkes-Dodson);\npattern bimodali dove l’ansia elevata si associa sia a prestazioni molto basse che molto alte, suggerendo l’esistenza di diversi sottogruppi nella popolazione studiata;\ncluster o addensamenti che indicano tipologie specifiche di individui con particolari combinazioni di ansia e prestazione;\n\n\nanalizzare solo le densità marginali (cioè ciascuna variabile separatamente) ci farebbe perdere queste informazioni cruciali sulle interrelazioni tra le variabili, portando potenzialmente a conclusioni incomplete o fuorvianti;\nle densità condizionali ci permettono di esaminare come una variabile si comporta in presenza di specifici valori dell’altra, rivelando dipendenze contestuali che arricchiscono la nostra comprensione dei fenomeni psicologici.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Caso continuo</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11c_joint_prob_cont.html#riflessioni-conclusive",
    "href": "chapters/probability/11c_joint_prob_cont.html#riflessioni-conclusive",
    "title": "37  Caso continuo",
    "section": "\n37.7 Riflessioni Conclusive",
    "text": "37.7 Riflessioni Conclusive\nI concetti di densità congiunta, marginale e condizionale ci permettono di esplorare con chiarezza e precisione come variabili psicologiche continue interagiscono fra loro. Comprendere queste densità ci aiuta a individuare relazioni complesse, come quelle che spesso emergono nello studio di fenomeni psicologici reali. Sebbene il passaggio dalle variabili discrete a quelle continue richieda strumenti matematici diversi (integrali anziché somme), l’intuizione e il significato concettuale di queste misure rimangono invariati. In questo modo, la logica che avete imparato nel caso discreto vi sarà sempre utile anche per affrontare fenomeni continui, più realistici e comuni in psicologia.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Caso continuo</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11c_joint_prob_cont.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/11c_joint_prob_cont.html#informazioni-sullambiente-di-sviluppo",
    "title": "37  Caso continuo",
    "section": "\n37.8 Informazioni sull’Ambiente di Sviluppo",
    "text": "37.8 Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] ggExtra_0.10.1    viridis_0.6.5     viridisLite_0.4.2 MASS_7.3-65      \n#&gt;  [5] thematic_0.1.7    MetBrewer_0.2.0   ggokabeito_0.1.0  see_0.11.0       \n#&gt;  [9] gridExtra_2.3     patchwork_1.3.0   bayesplot_1.13.0  psych_2.5.3      \n#&gt; [13] scales_1.4.0      markdown_2.0      knitr_1.50        lubridate_1.9.4  \n#&gt; [17] forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4       purrr_1.0.4      \n#&gt; [21] readr_2.1.5       tidyr_1.3.1       tibble_3.3.0      ggplot2_3.5.2    \n#&gt; [25] tidyverse_2.0.0   rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6       xfun_0.52          htmlwidgets_1.6.4 \n#&gt;  [4] lattice_0.22-7     tzdb_0.5.0         vctrs_0.6.5       \n#&gt;  [7] tools_4.5.0        generics_0.1.4     parallel_4.5.0    \n#&gt; [10] pacman_0.5.1       pkgconfig_2.0.3    RColorBrewer_1.1-3\n#&gt; [13] lifecycle_1.0.4    compiler_4.5.0     farver_2.1.2      \n#&gt; [16] mnormt_2.1.1       httpuv_1.6.16      htmltools_0.5.8.1 \n#&gt; [19] pillar_1.10.2      later_1.4.2        nlme_3.1-168      \n#&gt; [22] mime_0.13          tidyselect_1.2.1   digest_0.6.37     \n#&gt; [25] stringi_1.8.7      labeling_0.4.3     rprojroot_2.0.4   \n#&gt; [28] fastmap_1.2.0      grid_4.5.0         cli_3.6.5         \n#&gt; [31] magrittr_2.0.3     withr_3.0.2        promises_1.3.3    \n#&gt; [34] timechange_0.3.0   rmarkdown_2.29     hms_1.1.3         \n#&gt; [37] shiny_1.10.0       evaluate_1.0.4     miniUI_0.1.2      \n#&gt; [40] rlang_1.1.6        isoband_0.2.7      Rcpp_1.0.14       \n#&gt; [43] xtable_1.8-4       glue_1.8.0         rstudioapi_0.17.1 \n#&gt; [46] jsonlite_2.0.0     R6_2.6.1",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Caso continuo</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11c_joint_prob_cont.html#bibliografia",
    "href": "chapters/probability/11c_joint_prob_cont.html#bibliografia",
    "title": "37  Caso continuo",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.\n\n\nChan, J. C. C., & Kroese, D. P. (2025). Statistical Modeling and Computation (2ª ed.). Springer.\n\n\nEysenck, M. W., Derakshan, N., Santos, R., & Calvo, M. G. (2007). Anxiety and cognitive performance: attentional control theory. Emotion, 7(2), 336–353.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Caso continuo</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12a_intro_distributions.html",
    "href": "chapters/probability/12a_intro_distributions.html",
    "title": "38  Introduzione alle distribuzioni di probabilità",
    "section": "",
    "text": "38.1 Introduzione\nLe distribuzioni di probabilità – discrete (a massa) e continue (a densità) – rappresentano un pilastro dell’analisi quantitativa. Strumenti come la distribuzione normale o binomiale non sono semplici modelli teorici, ma strutture matematiche che permettono di decodificare fenomeni dominati dalla variabilità. In psicologia, disciplina focalizzata sulla comprensione della mente e del comportamento, potrebbe apparire paradossale ricorrere a questi strumenti che sembrano lontani dai fenomeni oggetti del nostro interesse. Tuttavia, è proprio l’intrinseca variabilità dei processi psicologici a renderli indispensabili: senza modelli in grado di mappare e interpretare la variabilità, ogni generalizzazione rischia di ridursi a un’approssimazione inefficace.\nQuesta riflessione è ben espressa in un recente articolo di Segal et al. (2025) sui disturbi mentali. L’autore osserva come i limiti nella comprensione della loro eziologia derivino dalla sottovalutazione della variabilità. Storicamente, la ricerca in psichiatria e psicologia ha confrontato gruppi clinici con controlli sani, identificando marcatori medi (biologici o comportamentali) come tratti distintivi. Sebbene utile, questo approccio trascura un dato fondamentale: i disturbi psichiatrici, come gran parte dei fenomeni psicologici, sono caratterizzati da un’eterogeneità interindividuale estrema, incompatibile con modelli basati su medie di gruppo.\nLa variabilità, dunque, non è un “rumore di fondo” da eliminare, ma un elemento informativo cruciale. Integrare questa prospettiva richiede non solo strumenti statistici avanzati, ma una riconfigurazione metodologica che ponga la diversità individuale al centro dell’indagine.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Introduzione alle distribuzioni di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12a_intro_distributions.html#la-variabilità-come-fattore-costitutivo-dei-disturbi-mentali",
    "href": "chapters/probability/12a_intro_distributions.html#la-variabilità-come-fattore-costitutivo-dei-disturbi-mentali",
    "title": "38  Introduzione alle distribuzioni di probabilità",
    "section": "\n38.2 La Variabilità come Fattore Costitutivo dei Disturbi Mentali",
    "text": "38.2 La Variabilità come Fattore Costitutivo dei Disturbi Mentali\nI disturbi psichiatrici sfuggono a definizioni rigide. Persone con la stessa diagnosi mostrano profili sintomatologici radicalmente diversi: ad esempio, nel disturbo da stress post-traumatico si osservano oltre 636,000 possibili combinazioni di sintomi, mentre nella depressione più di 16,000. Uno studio discusso da Segal et al. (2025) rivela che meno del 50% dei pazienti depressi presenta un’unica configurazione di sintomi. Questa variabilità si estende all’età di esordio, alla gravità, alla durata e alla dinamica temporale dei sintomi.\nUn singolo sintomo può inoltre comparire in più disturbi, spiegando i tassi elevati di comorbilità: circa il 50% dei pazienti soddisfa criteri diagnostici multipli. Questa sovrapposizione suggerisce che i disturbi non siano entità discrete, ma manifestazioni diverse di meccanismi psicopatologici condivisi. Non a caso, il 37% dei sintomi presenti nel DSM-5 non è specifico di un singolo disturbo e, complessivamente, rappresenta il 72% di tutti i sintomi inclusi nei criteri diagnostici, evidenziando una significativa mancanza di specificità sintomatologica.\nFocalizzarsi sulle medie di gruppo, tuttavia, rischia di occultare questa complessità, producendo risultati inconsistenti. Come osservato da Thomas Insel nel riepilogare il suo mandato alla guida dei National Institutes of Mental Health (NIMH) degli Stati Uniti, nonostante i consistenti investimenti in neuroscienze e genetica, i progressi nella riduzione dei suicidi, nella diminuzione dei ricoveri e nel miglioramento delle prognosi sono stati limitati.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Introduzione alle distribuzioni di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12a_intro_distributions.html#verso-un-cambiamento-di-prospettiva",
    "href": "chapters/probability/12a_intro_distributions.html#verso-un-cambiamento-di-prospettiva",
    "title": "38  Introduzione alle distribuzioni di probabilità",
    "section": "\n38.3 Verso un Cambiamento di Prospettiva",
    "text": "38.3 Verso un Cambiamento di Prospettiva\nPer superare queste criticità, secondo Segal et al. (2025), è necessario riconoscere la variabilità come proprietà costitutiva dei fenomeni psicologici. Ciò implica:\n\n\nAdottare approcci analitici che quantifichino la variabilità biologica e comportamentale a livello individuale, anziché di gruppo.\n\n\nUtilizzare modelli normativi per identificare deviazioni significative dalle traiettorie attese, anziché classificare soggetti in categorie rigide.\n\n\nAbbandonare l’idea di causalità univoca: una singola regione cerebrale può contribuire a sintomi multipli, così come meccanismi eterogenei possono generare lo stesso disturbo.\n\n\nAdottare framework dimensionali come l’HiTOP (Hierarchical Taxonomy of Psychopathology), che organizza i sintomi in dimensioni gerarchiche, massimizzando la cattura della variabilità fenotipica.\n\nIn questo contesto, le distribuzioni di probabilità diventano alleati indispensabili. Consentono di modellare la dispersione dei dati, identificare outlier e mappare traiettorie individuali, trasformando la variabilità da “problema” a “chiave interpretativa”. Analizzare la distribuzione di sintomi, tratti o risposte comportamentali permette di superare le medie di gruppo, consentendoci una migliore comprensione dei fenomeni psicologici.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Introduzione alle distribuzioni di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12a_intro_distributions.html#riflessioni-conclusive",
    "href": "chapters/probability/12a_intro_distributions.html#riflessioni-conclusive",
    "title": "38  Introduzione alle distribuzioni di probabilità",
    "section": "\n38.4 Riflessioni Conclusive",
    "text": "38.4 Riflessioni Conclusive\nLa teoria della probabilità offre gli strumenti concettuali per navigare la complessità dei dati psicologici. Come sottolineato da Segal et al. (2025), solo integrando sistematicamente la variabilità nell’analisi empirica è possibile sviluppare modelli predittivi robusti e interventi terapeutici mirati. La sfida non è eliminare l’incertezza, ma rendere conto della variabilità attraverso modelli che riflettano la complessità dei fenomeni psicologici.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Introduzione alle distribuzioni di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12a_intro_distributions.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/12a_intro_distributions.html#informazioni-sullambiente-di-sviluppo",
    "title": "38  Introduzione alle distribuzioni di probabilità",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.7   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.13.0 psych_2.5.3     \n#&gt;  [9] scales_1.4.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.3.0     ggplot2_3.5.2   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.4     stringi_1.8.7      lattice_0.22-7    \n#&gt;  [4] hms_1.1.3          digest_0.6.37      magrittr_2.0.3    \n#&gt;  [7] evaluate_1.0.4     grid_4.5.0         timechange_0.3.0  \n#&gt; [10] RColorBrewer_1.1-3 fastmap_1.2.0      rprojroot_2.0.4   \n#&gt; [13] jsonlite_2.0.0     mnormt_2.1.1       cli_3.6.5         \n#&gt; [16] rlang_1.1.6        withr_3.0.2        tools_4.5.0       \n#&gt; [19] parallel_4.5.0     tzdb_0.5.0         pacman_0.5.1      \n#&gt; [22] vctrs_0.6.5        R6_2.6.1           lifecycle_1.0.4   \n#&gt; [25] htmlwidgets_1.6.4  pkgconfig_2.0.3    pillar_1.10.2     \n#&gt; [28] gtable_0.3.6       glue_1.8.0         xfun_0.52         \n#&gt; [31] tidyselect_1.2.1   rstudioapi_0.17.1  farver_2.1.2      \n#&gt; [34] htmltools_0.5.8.1  nlme_3.1-168       rmarkdown_2.29    \n#&gt; [37] compiler_4.5.0",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Introduzione alle distribuzioni di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12a_intro_distributions.html#bibliografia",
    "href": "chapters/probability/12a_intro_distributions.html#bibliografia",
    "title": "38  Introduzione alle distribuzioni di probabilità",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nSegal, A., Tiego, J., Parkes, L., Holmes, A. J., Marquand, A. F., & Fornito, A. (2025). Embracing variability in the search for biological mechanisms of psychiatric illness. Trends in Cognitive Sciences, 29(1), 85–99.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Introduzione alle distribuzioni di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html",
    "href": "chapters/probability/12_discr_rv_distr.html",
    "title": "39  Distribuzioni di v.c. discrete",
    "section": "",
    "text": "39.1 Introduzione\nÈ importante distinguere tra variabili casuali discrete e continue, perché le distribuzioni di probabilità associate sono molto diverse nei due casi si veda il 31.\nIn questo capitolo ci focalizzeremo sulle distribuzioni di probabilità discrete, strumenti fondamentali per modellare fenomeni aleatori che generano un numero finito o numerabile di possibili esiti. Queste distribuzioni risultano particolarmente efficaci per descrivere eventi che si verificano in contesti discreti, come il numero di successi in un esperimento, l’occorrenza di un evento, o la selezione casuale da un insieme di opzioni finite.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html#introduzione",
    "href": "chapters/probability/12_discr_rv_distr.html#introduzione",
    "title": "39  Distribuzioni di v.c. discrete",
    "section": "",
    "text": "39.1.1 Panoramica delle Distribuzioni Discrete\nDi seguito, vengono presentate alcune delle principali distribuzioni discrete utilizzate in statistica e nella ricerca psicologica Ogni distribuzione è descritta in termini di caratteristiche fondamentali, applicazioni pratiche e importanza teorica.\n\n39.1.1.1 Distribuzione Uniforme Discreta\n\n\nDescrizione: La distribuzione uniforme discreta rappresenta situazioni in cui tutti gli eventi all’interno di un insieme finito hanno la stessa probabilità di verificarsi.\n\nApplicazioni: Si applica in contesti di scelta casuale equiprobabile, come:\n\nLa selezione casuale di uno stimolo da una lista di parole in un esperimento di memoria.\nL’assegnazione casuale di partecipanti a gruppi sperimentali in uno studio di psicologia sociale.\nLa scelta di un’immagine tra un insieme di stimoli visivi in una ricerca sull’attenzione.\nLa probabilità uniforme che un partecipante scelga una delle opzioni in un questionario a risposte multiple, in assenza di preferenze o conoscenze specifiche.\n\n\n\nParametri:\n\nIntervallo di supporto: l’insieme finito di valori possibili (ad esempio, \\(\\{1, 2, \\dots, k\\}\\)).\n\n\n\nImportanza: Funziona come modello di riferimento in situazioni di massima incertezza o mancanza di preferenze. È utile per definire un punto di partenza in analisi più complesse e per studiare comportamenti casuali.\n\n39.1.1.2 Distribuzione di Bernoulli\n\n\nDescrizione: La distribuzione di Bernoulli modella esperimenti con due possibili esiti, generalmente etichettati come “successo” (con probabilità \\(p\\)) e “fallimento” (con probabilità \\(1-p\\)).\n\nApplicazioni: Si applica a situazioni binarie, come il lancio di una moneta (testa/croce), la risposta a domande dicotomiche (sì/no), o l’esito di un evento che può verificarsi o meno.\n\nParametro:\n\n\n\\(p\\): probabilità di successo.\n\n\n\nImportanza: Costituisce la base per molte altre distribuzioni discrete, come la distribuzione binomiale e geometrica. È fondamentale per comprendere fenomeni con esiti dichotomici.\n\n39.1.1.3 Distribuzione Binomiale\n\n\nDescrizione: La distribuzione binomiale descrive il numero totale di successi in un numero fisso \\(n\\) di prove indipendenti, ciascuna governata da una distribuzione di Bernoulli con probabilità di successo \\(p\\).\n\nApplicazioni: Viene utilizzata per analizzare processi ripetuti con esiti binari, ad esempio:\n\nIl numero di voti favorevoli in un campione di opinione.\nIl numero di sintomi osservati in un gruppo di pazienti.\nIl conteggio di errori in un test di accuratezza.\n\n\n\nParametri:\n\n\n\\(n\\): numero di prove.\n\n\\(p\\): probabilità di successo in ogni prova.\n\n\n\nImportanza: Fornisce uno strumento essenziale per modellare fenomeni ripetuti in condizioni identiche, consentendo analisi probabilistiche avanzate e previsioni statistiche.\n\n39.1.1.4 Distribuzione di Poisson\n\n\nDescrizione: La distribuzione di Poisson modella il numero di eventi che si verificano in un intervallo fissato di tempo o spazio, quando tali eventi sono rari, indipendenti e accadono a un tasso medio costante \\(\\lambda\\).\n\nApplicazioni: Trova impiego in contesti dove gli eventi sono sporadici ma prevedibili, ad esempio:\n\nIl numero di episodi di ansia riportati in una settimana.\nIl numero di interazioni sociali spontanee di un bambino con disturbo dello spettro autistico durante una sessione di osservazione.\nLa frequenza di lapsus verbali durante una presentazione pubblica.\nIl numero di sogni vividi riportati durante una serie di notti consecutive in uno studio sul sonno.\n\n\n\nParametro:\n\n\n\\(\\lambda\\): tasso medio di eventi per unità di tempo o spazio.\n\n\n\nImportanza: È cruciale per analizzare fenomeni psicologici o comportamentali rari ma significativi. Aiuta a comprendere i meccanismi sottostanti e a modellare la variabilità osservata in contesti clinici, sperimentali o quotidiani.\n\nIn conclusione, le distribuzioni discrete sopra descritte rappresentano strumenti fondamentali per modellare una vasta gamma di fenomeni osservati in ambito scientifico, psicologico e applicativo. Ciascuna distribuzione offre una cornice teorica ben definita per interpretare e analizzare situazioni caratterizzate da variabili aleatorie discrete, fornendo così le basi per inferenze statistiche robuste e previsioni quantitative affidabili.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html#distribuzioni-in-r",
    "href": "chapters/probability/12_discr_rv_distr.html#distribuzioni-in-r",
    "title": "39  Distribuzioni di v.c. discrete",
    "section": "\n39.2 Distribuzioni in R",
    "text": "39.2 Distribuzioni in R\nIn R, per ogni distribuzione sono disponibili quattro funzioni principali, i cui nomi iniziano con le lettere:\n\n\nd (density): per calcolare i valori teorici relativi alla distribuzione,\n\n\np (probability): per ottenere la probabilità cumulativa,\n\n\nq (quantile): per determinare i quantili,\n\n\nr (random): per generare campioni casuali.\n\nIl pacchetto di base stats include numerose funzioni dedicate alle principali distribuzioni statistiche, permettendo di calcolare valori teorici e simulare dati in modo semplice e flessibile. Per ulteriori dettagli sulle distribuzioni disponibili e sull’uso delle relative funzioni, è possibile consultare la documentazione con il comando ?Distributions.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html#distribuzione-uniforme-discreta-1",
    "href": "chapters/probability/12_discr_rv_distr.html#distribuzione-uniforme-discreta-1",
    "title": "39  Distribuzioni di v.c. discrete",
    "section": "\n39.3 Distribuzione Uniforme Discreta",
    "text": "39.3 Distribuzione Uniforme Discreta\nLa distribuzione uniforme discreta è una delle più semplici e intuitive distribuzioni di probabilità. È utilizzata per modellare situazioni in cui tutti gli esiti possibili sono ugualmente probabili. Si applica, ad esempio, quando si estrae un numero a caso da un insieme finito di interi senza alcuna preferenza.\n\nDefinizione 39.1 Sia \\(X\\) una variabile casuale che può assumere i valori interi da 1 a \\(N\\), tutti con la stessa probabilità. Allora diciamo che \\(X\\) ha una distribuzione uniforme discreta sull’intervallo \\(\\{1, 2, \\dots, N\\}\\). In simboli:\n\\[\nX \\sim \\text{Uniforme Discreta}(1, N) .\n\\]\nPoiché ci sono \\(N\\) valori possibili e ciascuno ha la stessa probabilità, ogni valore ha probabilità:\n\\[\nP(X = x) = \\frac{1}{N}, \\quad \\text{per } x \\in \\{1, 2, \\dots, N\\}.\n\\]\n\n\n39.3.1 Proprietà di normalizzazione\nLa somma delle probabilità di tutti gli esiti deve essere pari a 1:\n\\[\n\\sum_{x = 1}^{N} P(X = x) = \\sum_{x = 1}^{N} \\frac{1}{N} = \\frac{1}{N} \\cdot N = 1.\n\\]\nQuesta è una proprietà fondamentale di ogni distribuzione di probabilità.\n\n39.3.2 Valore atteso\nIl valore atteso (o media) ci dice qual è il risultato medio atteso nel lungo periodo. Si calcola come:\n\\[\n\\mathbb{E}(X) = \\sum_{x = 1}^{N} x \\cdot P(X = x) = \\frac{1}{N} \\sum_{x = 1}^{N} x.\n\\]\nLa somma dei primi \\(N\\) numeri naturali è:\n\\[\n\\sum_{x = 1}^{N} x = \\frac{N(N + 1)}{2}.\n\\]\nQuindi:\n\\[\n\\mathbb{E}(X) = \\frac{1}{N} \\cdot \\frac{N(N + 1)}{2} = \\frac{N + 1}{2}.\n\\]\nIn conclusione, il valore atteso di una variabile uniforme discreta su \\(\\{1, \\dots, N\\}\\) è \\(\\frac{N + 1}{2}\\).\n\n39.3.3 Varianza\nLa varianza della distribuzione uniforme discreta è:\n\\[\n\\mathbb{V}(X) = \\frac{(N + 1)(N - 1)}{12}.\n\\]\n\n\n\n\n\n\nDimostrazione\n\n\n\n\n\nLa varianza misura quanto i valori di \\(X\\) si discostano in media dalla media \\(\\mathbb{E}(X)\\). Si calcola come:\n\\[\n\\mathbb{V}(X) = \\mathbb{E}(X^2) - \\left[\\mathbb{E}(X)\\right]^2.\n\\]\n\nCalcolo di \\(\\mathbb{E}(X^2)\\).\n\nPoiché tutti i valori hanno la stessa probabilità \\(\\frac{1}{N}\\), otteniamo:\n\\[\n\\mathbb{E}(X^2) = \\frac{1}{N} \\sum_{x = 1}^{N} x^2.\n\\]\nLa somma dei quadrati dei primi \\(N\\) interi è:\n\\[\n\\sum_{x = 1}^{N} x^2 = \\frac{N(N + 1)(2N + 1)}{6}\n\\]\n(per una dimostrazione, si veda la pagina di Wikipedia sui numeri piramidali quadrati).\nQuindi:\n\\[\n\\mathbb{E}(X^2) = \\frac{1}{N} \\cdot \\frac{N(N + 1)(2N + 1)}{6} = \\frac{(N + 1)(2N + 1)}{6}.\n\\]\n\nCalcolo della varianza.\n\nSostituendo nella formula della varianza:\n\\[\n\\begin{aligned}\n\\mathbb{V}(X) &= \\frac{(N + 1)(2N + 1)}{6} - \\left(\\frac{N + 1}{2}\\right)^2 \\\\\n&= \\frac{(N + 1)(2N + 1)}{6} - \\frac{(N + 1)^2}{4}\n\\end{aligned}\n\\]\nPer semplificare, portiamo tutto allo stesso denominatore:\n\\[\n\\begin{aligned}\n\\mathbb{V}(X) &= \\frac{2(N + 1)(2N + 1)}{12} - \\frac{3(N + 1)^2}{12} \\\\\n&= \\frac{(N + 1) \\left[2(2N + 1) - 3(N + 1)\\right]}{12} \\\\\n&= \\frac{(N + 1)(4N + 2 - 3N - 3)}{12} \\\\\n&= \\frac{(N + 1)(N - 1)}{12}.\n\\end{aligned}\n\\]\nIn conclusione, la varianza della distribuzione uniforme discreta è:\n\\[\n\\mathbb{V}(X) = \\frac{(N + 1)(N - 1)}{12}.\n\\]\n\n\n\nIn sintesi, per una variabile casuale \\(X\\) uniformemente distribuita su \\(\\{1, 2, \\dots, N\\}\\):\n\n\nProprietà\nFormula\n\n\n\nMedia\n\\(\\mathbb{E}(X) = \\dfrac{N + 1}{2}\\)\n\n\nVarianza\n\\(\\mathbb{V}(X) = \\dfrac{(N + 1)(N - 1)}{12}\\)\n\n\n\nQuesta distribuzione è utile ogni volta che non c’è alcuna ragione per preferire un valore a un altro all’interno di un insieme finito di numeri interi.\n\nEsempio 39.1 Supponiamo che \\(X\\) sia una variabile casuale con distribuzione uniforme discreta tra 1 e 10, ovvero:\n\\[\nX \\sim \\text{Uniforme Discreta}(1, 10) .\n\\]\nVogliamo:\n\ngenerare un grande campione casuale,\ncalcolare la media e la varianza osservate,\nconfrontarle con i valori teorici.\n\nCodice R.\n\nset.seed(123)  # Per rendere la simulazione riproducibile\n\n# Parametro N\nN &lt;- 10\n\n# Simulazione: 100.000 osservazioni dalla distribuzione uniforme discreta\nx &lt;- sample(1:N, size = 100000, replace = TRUE)\n\n# Media e varianza empiriche\nmedia_empirica &lt;- mean(x)\nvarianza_empirica &lt;- var(x)\n\n# Valori teorici\nmedia_teorica &lt;- (N + 1) / 2\nvarianza_teorica &lt;- ((N + 1) * (N - 1)) / 12\n\n# Risultati\ntibble(\n  `Media empirica` = media_empirica,\n  `Media teorica` = media_teorica,\n  `Varianza empirica` = varianza_empirica,\n  `Varianza teorica` = varianza_teorica\n)\n#&gt; # A tibble: 1 × 4\n#&gt;   `Media empirica` `Media teorica` `Varianza empirica` `Varianza teorica`\n#&gt;              &lt;dbl&gt;           &lt;dbl&gt;               &lt;dbl&gt;              &lt;dbl&gt;\n#&gt; 1             5.51             5.5                8.26               8.25\n\nCon un campione molto grande, le statistiche empiriche (cioè calcolate dai dati simulati) saranno molto vicine ai valori teorici:\n\n\n\nValore\n\n\n\nMedia teorica\n5.5\n\n\nMedia empirica\n≈ 5.5\n\n\nVarianza teorica\n8.25\n\n\nVarianza empirica\n≈ 8.25\n\n\n\n\nIn sintesi, a simulazione conferma che:\n\nla media empirica converge verso \\(\\mathbb{E}(X) = \\frac{N + 1}{2}\\),\nla varianza empirica converge verso \\(\\mathbb{V}(X) = \\frac{(N + 1)(N - 1)}{12}\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html#distribuzione-di-bernoulli-1",
    "href": "chapters/probability/12_discr_rv_distr.html#distribuzione-di-bernoulli-1",
    "title": "39  Distribuzioni di v.c. discrete",
    "section": "\n39.4 Distribuzione di Bernoulli",
    "text": "39.4 Distribuzione di Bernoulli\nIn statistica, un esperimento che ammette solo due esiti possibili è modellato attraverso quella che viene chiamata “prova Bernoulliana”. Un esempio tipico è il lancio di una moneta, che può dare come risultato testa o croce.\n\nDefinizione 39.2 Una variabile casuale \\(X\\) che assume valori in \\(\\{0, 1\\}\\) è detta variabile di Bernoulli. La sua distribuzione di probabilità è definita come:\n\\[\nP(X \\mid \\theta) =\n  \\begin{cases}\n    p     & \\text{se $X = 1$ (successo)}, \\\\\n    1 - p & \\text{se $X = 0$ (insuccesso)},\n  \\end{cases}\n\\]\ndove \\(0 \\leq p \\leq 1\\). Il parametro \\(p\\) rappresenta la probabilità del “successo” (\\(X = 1\\)), mentre \\(1 - p\\) è la probabilità dell’“insuccesso” (\\(X = 0\\)).\n\nLa distribuzione di Bernoulli descrive quindi un contesto in cui la probabilità di osservare l’esito 1 è \\(p\\) e quella di osservare l’esito 0 è \\(1 - p\\). Viene utilizzata per modellare situazioni binarie, come una risposta “sì” o “no”, oppure un “successo” o “insuccesso”.\nCalcolando il valore atteso e la varianza, otteniamo:\n\\[\n\\begin{aligned}\n\\mathbb{E}(X) &= 0 \\cdot P(X=0) + 1 \\cdot P(X=1) = p, \\\\\n\\mathbb{V}(X) &= (0 - p)^2 \\cdot P(X=0) + (1 - p)^2 \\cdot P(X=1) = p(1-p).\n\\end{aligned}\n\\tag{39.1}\\]\n\n\n\n\n\n\nDimostrazione\n\n\n\nEsaminiamo la dimostrazione algebrica del calcolo della varianza.\nEspandiamo il calcolo della somma, considerando i due possibili valori di \\(X\\) (0 e 1).\n\n\nPrimo termine (\\(X = 0\\)):\n\\[\n(0 - \\mathbb{E}(X))^2 \\cdot P(X = 0) = (0 - p)^2 \\cdot (1 - p).\n\\]\nSemplificando \\((0 - p)^2 = p^2\\), quindi:\n\\[\n(0 - \\mathbb{E}(X))^2 \\cdot P(X = 0) = p^2 \\cdot (1 - p).\n\\]\n\n\nSecondo termine (\\(X = 1\\)):\n\\[\n(1 - \\mathbb{E}(X))^2 \\cdot P(X = 1) = (1 - p)^2 \\cdot p.\n\\]\nSemplificando \\((1 - p)^2 = 1 - 2p + p^2\\), quindi:\n\\[\n(1 - \\mathbb{E}(X))^2 \\cdot P(X = 1) = (1 - 2p + p^2) \\cdot p = p - 2p^2 + p^3.\n\\]\n\n\nSomma dei termini\nOra sommiamo i due contributi:\n\\[\n\\mathbb{V}(X) = p^2 \\cdot (1 - p) + (p - 2p^2 + p^3).\n\\]\nEspandendo il primo termine:\n\\[\np^2 \\cdot (1 - p) = p^2 - p^3.\n\\]\nSomma completa:\n\\[\n\\mathbb{V}(X) = (p^2 - p^3) + (p - 2p^2 + p^3).\n\\]\n\n\nRaggruppiamo i termini\n\\[\n\\mathbb{V}(X) = p - p^2.\n\\]\nRisultato finale:\n\\[\n\\mathbb{V}(X) = p(1 - p).\n\\]\n\n\nIn sintesi, la varianza di una variabile aleatoria binaria \\(X\\), distribuita secondo Bernoulli con parametro \\(p\\), è data da \\(p(1-p)\\).\n\n\nTale risultato mostra come la varianza massima si ottenga per \\(p = 0.5\\), condizione che corrisponde alla massima incertezza intrinseca nel processo, ossia quando la probabilità di successo eguaglia quella di insuccesso.\n\n# Valori di p tra 0 e 1\np &lt;- seq(0, 1, length.out = 100)\nvariance &lt;- p * (1 - p)\ndata &lt;- data.frame(p = p, Variance = variance)\n\n# Creazione del grafico\nggplot(data, aes(x = p, y = Variance)) +\n  geom_line(color = okabe_ito_palette[2], linewidth = 1.2) +\n  labs(\n    x = expression(p),\n    y = \"Varianza\",\n    title = \"Varianza di una Variabile Bernoulliana in funzione di p\"\n  )\n\n\n\n\n\n\n\n\n39.4.1 Notazione\nPer indicare che la variabile casuale \\(X\\) segue una distribuzione Bernoulliana di parametro \\(p\\) Utilizziamo la notazione \\(X \\sim \\mathcal{Bern}(p)\\), o in maniera equivalente \\(\\mathcal{Bern}(X \\mid p)\\).\n\nEsempio 39.2 Nel caso del lancio di una moneta equilibrata, la variabile di Bernoulli assume i valori \\(0\\) e \\(1\\) con uguale probabilità di \\(\\frac{1}{2}\\). Pertanto, la funzione di massa di probabilità assegna una probabilità di \\(\\frac{1}{2}\\) sia per \\(X = 0\\) che per \\(X = 1\\), mentre la funzione di distribuzione cumulativa risulta essere \\(\\frac{1}{2}\\) per \\(X = 0\\) e \\(1\\) per \\(X = 1\\).\nGeneriamo dei valori casuali dalla distribuzione di Bernoulli. Iniziamo con un singolo valore:\n\n# Probabilità di successo\np &lt;- 0.5\n\n# Genera un singolo valore\nbernoulli_sample &lt;- rbinom(n = 1, size = 1, prob = p)\nprint(bernoulli_sample)\n#&gt; [1] 1\n\n# Genera un campione di 10 valori\nbernoulli_sample &lt;- rbinom(n = 10, size = 1, prob = p)\nprint(bernoulli_sample)\n#&gt;  [1] 1 0 1 1 1 1 0 1 1 0",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html#distribuzione-binomiale-1",
    "href": "chapters/probability/12_discr_rv_distr.html#distribuzione-binomiale-1",
    "title": "39  Distribuzioni di v.c. discrete",
    "section": "\n39.5 Distribuzione Binomiale",
    "text": "39.5 Distribuzione Binomiale\nLa distribuzione binomiale è una distribuzione di probabilità discreta che modella il numero di successi \\(y\\) in un numero fissato \\(n\\) di prove di Bernoulli indipendenti e identiche, dove ciascuna prova ha solo due esiti possibili: “successo” (rappresentato da “1”) con probabilità \\(p\\) o “insuccesso” (rappresentato da “0”) con probabilità \\(1 - p\\). La notazione utilizzata è la seguente:\n\\[\nY \\sim \\mathcal{Binom}(n, p).\n\\]\n\nDefinizione 39.3 La distribuzione binomiale descrive la probabilità di osservare esattamente \\(y\\) successi in \\(n\\) prove di Bernoulli indipendenti:\n\\[\nP(Y = y) = \\binom{n}{y} p^{y} (1 - p)^{n - y} = \\frac{n!}{y!(n - y)!} p^{y} (1 - p)^{n - y},\n\\tag{39.2}\\]\ndove \\(\\binom{n}{y}\\), noto come coefficiente binomiale, rappresenta il numero di modi possibili per ottenere \\(y\\) successi in \\(n\\) prove, e \\(p\\) è la probabilità di successo in ciascuna prova.\n\nLa distribuzione binomiale si presta bene a esempi classici come il lancio ripetuto di una moneta o l’estrazione di biglie da un’urna. Ad esempio, nel caso del lancio di una moneta, questa distribuzione descrive la probabilità di ottenere un determinato numero di “teste” in un certo numero di lanci, con ogni lancio che segue una distribuzione di Bernoulli con probabilità di successo \\(p\\).\nUna caratteristica interessante della distribuzione binomiale è la sua proprietà di riproducibilità: se due variabili casuali indipendenti, \\(y_1\\) e \\(y_2\\), seguono entrambe distribuzioni binomiali con lo stesso parametro \\(p\\), ma con un diverso numero di prove (\\(n_1\\) e \\(n_2\\)), la loro somma, \\(y = y_1 + y_2\\), sarà ancora distribuita binomialmente, con parametri \\(n_1 + n_2\\) e \\(p\\).\n\n\n\n\n\n\nDimostrazione\n\n\n\nPer chiarire il calcolo delle probabilità nella distribuzione binomiale, consideriamo una serie di prove di Bernoulli. Supponiamo di avere \\(n\\) prove indipendenti, ciascuna con probabilità \\(p\\) di successo, e di osservare esattamente \\(y\\) successi.\nUna possibile configurazione dei risultati può essere rappresentata come:\n\\[\n\\overbrace{SS\\dots S}^\\text{$y$ successi} \\, \\overbrace{II\\dots I}^\\text{$n - y$ insuccessi}\n\\]\nLa probabilità di ottenere esattamente \\(y\\) successi in una sequenza specifica (cioè in un ordine fissato) è:\n\\[\np^y \\cdot (1 - p)^{n - y},\n\\]\ndove \\(p^y\\) è la probabilità dei \\(y\\) successi e \\((1 - p)^{n - y}\\) quella dei \\(n - y\\) insuccessi.\nTuttavia, ciò che ci interessa è la probabilità complessiva di ottenere \\(y\\) successi in qualsiasi ordine. In altre parole, vogliamo calcolare la probabilità dell’unione di tutte le possibili sequenze di \\(n\\) prove che contengono esattamente \\(y\\) successi.\nIl numero di tali sequenze è dato dal coefficiente binomiale \\(\\binom{n}{y}\\), che rappresenta il numero di modi diversi in cui possiamo scegliere le \\(y\\) posizioni dei successi tra le \\(n\\) prove.\nMoltiplicando la probabilità di una singola sequenza per il numero totale di sequenze possibili, otteniamo la funzione di probabilità della distribuzione binomiale:\n\\[\nP(Y = y) = \\binom{n}{y} p^y (1 - p)^{n - y}.\n\\]\n\n\n\n39.5.1 Caso particolare \\(n = 1\\)\n\nOra consideriamo il caso particolare in cui \\(n = 1\\). Quando \\(n = 1\\), il coefficiente binomiale diventa:\n\\[\n\\binom{1}{y} = \\frac{1!}{y! (1-y)!}.\n\\]\nEspandiamo i fattoriali per i due possibili valori di \\(y\\), che può assumere solo 0 o 1 (poiché \\(y \\in \\{0, 1, \\dots, n\\}\\)).\nCaso 1: \\(y = 0\\)\n\\[\n\\binom{1}{0} = \\frac{1!}{0! (1-0)!} = \\frac{1}{1 \\cdot 1} = 1.\n\\]\nQuindi, per \\(y = 0\\): \\[\nP(Y = 0) = \\binom{1}{0} p^0 (1-p)^{1-0} = 1 \\cdot 1 \\cdot (1-p) = 1-p.\n\\]\nCaso 2: \\(y = 1\\)\n\\[\n\\binom{1}{1} = \\frac{1!}{1! (1-1)!} = \\frac{1}{1 \\cdot 1} = 1.\n\\]\nQuindi, per \\(y = 1\\): \\[\nP(Y = 1) = \\binom{1}{1} p^1 (1-p)^{1-1} = 1 \\cdot p \\cdot 1 = p.\n\\]\nIn conclusione, la PMF per la distribuzione binomiale con \\(n = 1\\) diventa:\n\\[\nP(Y = y) =\n\\begin{cases}\n1-p, & \\text{se } y = 0, \\\\\np, & \\text{se } y = 1.\n\\end{cases}\n\\]\nQuesta è esattamente la PMF della distribuzione di Bernoulli con parametro \\(p\\):\n\\[\nP(Y = y) = p^y (1-p)^{1-y}, \\quad y \\in \\{0, 1\\}.\n\\]\nPertanto, la distribuzione binomiale con \\(n = 1\\) è equivalente alla distribuzione di Bernoulli con parametro \\(p\\).\n\n39.5.2 Applicazioni Pratiche della Distribuzione Binomiale\nPer illustrare l’applicazione della distribuzione binomiale, consideriamo un esempio semplice. Supponiamo di osservare 2 successi su 4 prove di Bernoulli, dove la probabilità di successo in ogni prova è \\(p = 0.2\\). La probabilità di ottenere esattamente questo risultato si calcola con la formula:\n\\[\nP(Y = 2) = \\binom{4}{2} \\cdot 0.2^2 \\cdot (1 - 0.2)^{2} = 0.1536.\n\\]\nIn R, questo calcolo si può fare in modo diretto:\n\n# Parametri\nn &lt;- 4\np &lt;- 0.2\ny &lt;- 2\n\n# Calcolo della probabilità esatta\nprob &lt;- choose(n, y) * p^y * (1 - p)^(n - y)\nprint(prob)\n#&gt; [1] 0.1536\n\nIn alternativa, possiamo usare la funzione dbinom() per ottenere la stessa probabilità:\n\nprob &lt;- dbinom(x = y, size = n, prob = p)\nprint(prob)\n#&gt; [1] 0.1536\n\n\n39.5.2.1 Visualizzazione della distribuzione di probabilità\nPossiamo rappresentare graficamente la distribuzione di massa di probabilità per tutti i possibili valori di \\(y\\) da \\(0\\) a \\(n\\):\n\ny &lt;- 0:n\nprobabilities &lt;- dbinom(y, size = n, prob = p)\n\ndf &lt;- data.frame(Successi = y, Probabilità = probabilities)\n\ndf |&gt;\n  ggplot(aes(x = Successi, y = Probabilità)) +\n    geom_segment(\n      aes(xend = Successi, yend = 0), lwd = 1.2, \n      color = okabe_ito_palette[2]\n      ) +\n    geom_point(size = 3, color = okabe_ito_palette[2]) +\n    labs(\n      x = \"Numero di successi y\",\n      y = \"Probabilità\",\n      title = paste(\"Distribuzione binomiale: n =\", n, \", p =\", p)\n    )\n\n\n\n\n\n\n\n\n39.5.2.2 Generazione di un campione casuale\nLa funzione rbinom() permette di generare un campione casuale da una distribuzione binomiale:\n\nset.seed(42)\nsamples &lt;- rbinom(n = 30, size = 5, prob = 0.5)\nprint(samples)\n#&gt;  [1] 4 4 2 4 3 3 3 1 3 3 2 3 4 2 2 4 5 1 2 3 4 1 5 4 1 3 2 4 2 4\n\n\n39.5.2.3 Variazione della distribuzione al variare di \\(p\\)\n\nPer esplorare l’effetto di diversi valori di \\(p\\) sulla forma della distribuzione, possiamo visualizzare più curve binomiali per \\(n = 20\\) e \\(p\\) variabile:\n\nn &lt;- 20\np_values &lt;- seq(0.3, 0.9, by = 0.3)\ny &lt;- 0:25\n\ndf &lt;- data.frame()\n\nfor (p in p_values) {\n  binom_dist &lt;- dbinom(y, size = n, prob = p)\n  df &lt;- rbind(df, data.frame(y = y, Prob = binom_dist, p = factor(p)))\n}\n\ndf |&gt;\n  ggplot(aes(x = y, y = Prob, color = p)) +\n    geom_point() +\n    geom_line() +\n    labs(\n      x = \"Numero di successi y\",\n      y = \"Probabilità\",\n      title = \"Distribuzioni binomiali con diversi valori di p\",\n      color = expression(p)\n    )\n\n\n\n\n\n\n\n\n39.5.2.4 Funzione di ripartizione cumulativa\nPossiamo anche rappresentare la funzione di distribuzione cumulativa (CDF) per \\(n = 5\\) e \\(p = 0.5\\):\n\nn &lt;- 5\np &lt;- 0.5\ny &lt;- 0:n\n\ncdf_values &lt;- pbinom(y, size = n, prob = p)\ndf &lt;- data.frame(y = y, cdf = cdf_values)\n\ndf |&gt;\n  ggplot(aes(x = y, y = cdf)) +\n    geom_line() +\n    geom_point() +\n    geom_hline(\n      yintercept = 1, linetype = \"dashed\", color = \"black\", alpha = 0.7\n    ) +\n    labs(\n      title = paste(\"Funzione di ripartizione: n =\", n, \", p =\", p),\n      x = \"Numero di successi y\",\n      y = \"Probabilità cumulativa\"\n    )\n\n\n\n\n\n\n\n\nEsempio 39.3 Supponiamo di lanciare una moneta equa (cioè con probabilità \\(p = 0.5\\) di ottenere testa) 5 volte. Vogliamo calcolare la probabilità di ottenere almeno 2 teste, ovvero:\n\\[\nP(Y \\geq 2) = P(Y = 2) + P(Y = 3) + P(Y = 4) + P(Y = 5).\n\\]\nPossiamo sommare direttamente queste probabilità usando dbinom():\n\nresult &lt;- sum(dbinom(2:5, size = 5, prob = 0.5))\nprint(result)\n#&gt; [1] 0.8125\n\nUn modo alternativo, più efficiente, consiste nel calcolare il complemento della probabilità di ottenere meno di 2 teste (cioè 0 o 1):\n\\[\nP(Y \\geq 2) = 1 - P(Y \\leq 1)\n\\]\nIn R, possiamo usare la funzione pbinom() per calcolare questa probabilità cumulativa:\n\nresult &lt;- 1 - pbinom(q = 1, size = 5, prob = 0.5)\nprint(result)\n#&gt; [1] 0.8125\n\nEntrambi i metodi restituiscono lo stesso risultato numerico, ma il secondo è spesso preferibile quando \\(n\\) è grande o quando si vuole calcolare una probabilità di coda.\n\n\n39.5.2.5 Quantili di una distribuzione binomiale\nHai perfettamente ragione — grazie per l’osservazione!\nInfatti, con i parametri size = 5, prob = 0.5 e target_probability = 0.60, la funzione qbinom() restituisce 3, non 2. Questo perché qbinom() restituisce il più piccolo valore di \\(y\\) tale che \\(P(Y \\leq y) \\geq p\\). Verifichiamolo in R:\npbinom(2, 5, 0.5)  # = 0.5\npbinom(3, 5, 0.5)  # = 0.8125\nQuindi:\n\n\n\\(P(Y \\leq 2) = 0.5\\) → troppo poco\n\n\\(P(Y \\leq 3) = 0.8125\\) → supera il 60%\n\nPertanto, qbinom(0.6, 5, 0.5) restituisce 3.\n\n39.5.2.6 Quantili di una distribuzione binomiale\nLa funzione qbinom() permette di calcolare il quantile di una distribuzione binomiale, cioè il numero minimo di successi \\(y\\) tale che la probabilità cumulativa \\(P(Y \\leq y)\\) sia maggiore o uguale a una certa soglia.\nAd esempio, supponiamo di voler sapere qual è il numero minimo di successi tale che la probabilità cumulativa sia almeno 60%. Possiamo usare:\n\n# Probabilità cumulativa desiderata\ntarget_probability &lt;- 0.60\n\n# Calcolo del quantile\nresult &lt;- qbinom(p = target_probability, size = 5, prob = 0.5)\nprint(result)\n#&gt; [1] 3\n\nIl risultato è 3, il che significa che:\n\\[\nP(Y \\leq 3) = 0.8125 \\geq 0.60,\n\\]\nmentre\n\\[\nP(Y \\leq 2) = 0.5 &lt; 0.60.\n\\]\nQuindi, servono almeno 3 successi per superare la soglia del 60% di probabilità cumulativa.\n\n🔎 qbinom(p, size, prob) restituisce il più piccolo valore di \\(y\\) tale che \\(P(Y \\leq y) \\geq p\\).\n\n\n39.5.2.7 Rappresentazione grafica del quantile\nPer visualizzare il comportamento della funzione di ripartizione cumulativa e individuare il quantile per \\(p = 0.60\\), possiamo usare il seguente codice in R:\n\n# Parametri\nn &lt;- 5\np &lt;- 0.5\ntarget_probability &lt;- 0.60\n\n# Asse y: numero di successi\ny &lt;- 0:n\n\n# Calcolo dei valori cumulativi\ncdf &lt;- pbinom(y, size = n, prob = p)\n\n# Calcolo del quantile\nq &lt;- qbinom(target_probability, size = n, prob = p)\n\n# Data frame\ndf &lt;- data.frame(Successi = y, CDF = cdf)\n\n# Grafico\ndf |&gt;\n  ggplot(aes(x = Successi, y = CDF)) +\n  geom_step(direction = \"hv\", linewidth = 1.1) +\n  geom_point(size = 2) +\n  geom_hline(\n    yintercept = target_probability, linetype = \"dashed\", color = \"red\"\n  ) +\n  geom_vline(xintercept = q, linetype = \"dotted\", color = \"blue\") +\n  annotate(\n    \"text\",\n    x = q + 0.4, y = 0.05, label = paste(\"quantile =\", q),\n    color = \"blue\"\n  ) +\n  annotate(\n    \"text\",\n    x = 0.5, y = target_probability + 0.05,\n    label = paste(\"soglia =\", target_probability), color = \"red\"\n  ) +\n  labs(\n    title = paste(\n      \"Funzione di ripartizione cumulativa (n =\", n, \", p =\", p, \")\"\n    ),\n    x = \"Numero di successi\",\n    y = \"Probabilità cumulativa\"\n  ) +\n  ylim(0, 1.05)\n\n\n\n\n\n\n\nIn questo grafico:\n\nla linea rossa tratteggiata rappresenta la soglia di probabilità desiderata (es. 0.60);\nla linea blu tratteggiata verticale indica il quantile corrispondente, cioè il più piccolo valore di \\(y\\) per cui \\(P(Y \\leq y) \\geq 0.60\\);\nil valore calcolato è 3, quindi con al massimo 3 successi, la probabilità cumulativa supera il 60%.\n\n\nEsempio 39.4 Consideriamo una distribuzione binomiale con \\(n = 10\\) prove e probabilità di successo \\(p = 0.2\\). Supponiamo di voler calcolare la probabilità di ottenere al massimo 4 successi. In termini matematici, vogliamo calcolare:\n\\[\nP(Y \\leq 4) .\n\\]\nIn R, questo si ottiene con la funzione pbinom():\n\n# Calcolo della probabilità cumulativa fino a 4 successi\np_cumulativa &lt;- pbinom(4, size = 10, prob = 0.2)\nprint(p_cumulativa)\n#&gt; [1] 0.9672\n\nIl risultato indica che c’è circa l’97% di probabilità di ottenere 4 o meno successi su 10 prove, quando la probabilità di successo in ciascuna prova è 0.2.\nOra facciamo il passaggio inverso: immaginiamo di conoscere la probabilità cumulativa (per esempio, 0.97) e vogliamo sapere quanti successi bisogna considerare per raggiungere quella probabilità.\nPer questo usiamo la funzione qbinom(), che ci restituisce il più piccolo numero di successi \\(y\\) tale che \\(P(Y \\leq y) \\geq\\) quella probabilità:\n\n# Calcolo del numero di successi associato alla probabilità cumulativa\nnumero_successi &lt;- qbinom(p_cumulativa, size = 10, prob = 0.2)\nprint(numero_successi)\n#&gt; [1] 4\n\nIl valore ottenuto sarà 4, cioè il minimo numero di successi per cui la probabilità cumulativa è almeno il 97%.\nRiepilogo concetti chiave:\n\n\npbinom(y, n, p) calcola la probabilità di ottenere al massimo \\(y\\) successi;\n\nqbinom(prob, n, p) calcola il numero minimo di successi necessari per raggiungere almeno quella probabilità.\n\nIn sintesi, pbinom() e qbinom() sono strumenti complementari: pbinom ci dà la probabilità di ottenere fino a un certo numero di successi, mentre qbinom ci dice fino a quanti successi possiamo ottenere per raggiungere una certa probabilità. Nell’analisi di una distribuzione binomiale (e di molte altre distribuzioni) queste funzioni aiutano a calcolare e interpretare facilmente probabilità cumulate e quantili in R, rendendo più semplice l’analisi di eventi aleatori.\n\n\n39.5.3 Valore atteso e deviazione standard nella distribuzione binomiale\nNella distribuzione binomiale, possiamo calcolare facilmente due quantità molto importanti:\n\n\nil valore atteso (o media), che ci dice quanti successi ci aspettiamo in media su un certo numero di prove;\n\nla deviazione standard, che ci dice quanto i risultati tendono a variare attorno alla media.\n\nLe formule sono le seguenti:\n\\[\n\\text{Media (valore atteso):} \\quad \\mu = n p ,\n\\tag{39.3}\\]\n\\[\n\\text{Deviazione standard:} \\quad \\sigma = \\sqrt{n p (1 - p)} ,\n\\tag{39.4}\\]\ndove:\n\n\n\\(n\\) è il numero di prove (per esempio, il numero di lanci di una moneta),\n\n\\(p\\) è la probabilità di successo in ogni prova.\n\n\n\n\n\n\n\nDimostrazione.\nLa variabile \\(Y\\) rappresenta il numero di successi in \\(n\\) prove di Bernoulli indipendenti. Possiamo scriverla come somma di \\(n\\) variabili casuali indipendenti:\n\\[\nY = Y_1 + Y_2 + \\cdots + Y_n,\n\\]\ndove ciascuna \\(Y_i \\sim \\text{Bernoulli}(p)\\), cioè:\n\\[\nY_i =\n\\begin{cases}\n1 & \\text{con probabilità } p \\\\\n0 & \\text{con probabilità } 1 - p\n\\end{cases}\n\\]\nValore atteso di \\(Y_i\\).\nPer definizione del valore atteso:\n\\[\n\\mathbb{E}(Y_i) = 1 \\cdot p + 0 \\cdot (1 - p) = p.\n\\]\nValore atteso di \\(Y_i^2\\).\nPoiché \\(Y_i\\) assume solo i valori 0 e 1, si ha \\(Y_i^2 = Y_i\\). Quindi:\n\\[\n\\mathbb{E}(Y_i^2) = \\mathbb{E}(Y_i) = p.\n\\]\nLa varianza di una variabile casuale si definisce come:\n\\[\n\\operatorname{Var}(Y_i) = \\mathbb{E}(Y_i^2) - [\\mathbb{E}(Y_i)]^2.\n\\]\nSostituendo i valori trovati sopra:\n\\[\n\\operatorname{Var}(Y_i) = p - p^2 = p(1 - p).\n\\]\nRicordiamo che \\(Y = \\sum_{i=1}^{n} Y_i\\) e che le \\(Y_i\\) sono indipendenti. Una proprietà fondamentale della varianza è che se \\(Z_1, \\dots, Z_n\\) sono indipendenti:\n\\[\n\\operatorname{Var}(Z_1 + \\cdots + Z_n) = \\operatorname{Var}(Z_1) + \\cdots + \\operatorname{Var}(Z_n).\n\\]\nApplichiamola al nostro caso:\n\\[\n\\operatorname{Var}(Y) = \\sum_{i=1}^{n} \\operatorname{Var}(Y_i).\n\\]\nPoiché tutte le \\(Y_i\\) hanno la stessa varianza \\(p(1 - p)\\), la somma diventa:\n\\[\n\\operatorname{Var}(Y) = n \\cdot p(1 - p).\n\\]\nAbbiamo dimostrato da definizione che, se \\(Y \\sim \\text{Bin}(n, p)\\), allora:\n\\[\n\\operatorname{Var}(Y) = n \\cdot p \\cdot (1 - p).\n\\]\nQuesta formula descrive la dispersione attesa nel numero di successi su \\(n\\) prove indipendenti, ciascuna con probabilità di successo \\(p\\).\n\n\n\n\nEsempio 39.5 Supponiamo di lanciare 4 volte una moneta truccata che ha una probabilità di successo (es. ottenere testa) pari a \\(p = 0.2\\).\nVogliamo calcolare:\n\nla media attesa del numero di teste,\nla varianza,\ne la deviazione standard.\n\n\nCalcolo del valore atteso (media):\n\n\\[\n\\mu = n \\cdot p = 4 \\cdot 0.2 = 0.8 .\n\\]\nQuindi, in media, ci aspettiamo di ottenere 0.8 teste ogni 4 lanci (cioè meno di 1, ma ricordiamo che si tratta di una media).\n\nCalcolo della varianza:\n\n\\[\n\\text{Varianza} = n \\cdot p \\cdot (1 - p) = 4 \\cdot 0.2 \\cdot 0.8 = 0.64 .\n\\]\n\nCalcolo della deviazione standard:\n\n\\[\n\\sigma = \\sqrt{0.64} \\approx 0.8 .\n\\]\nLa deviazione standard ci dà un’idea della variabilità dei risultati: in questo caso, i valori osservati (numero di teste su 4 lanci) si discostano dalla media di circa 0.8 in media.\n\n\n39.5.4 Verifica con una simulazione in R\nPer vedere se i calcoli teorici dell’Esempio 39.5 funzionano anche nella pratica, possiamo simulare l’esperimento in R: lanciamo 4 monete, ma lo facciamo tantissime volte (ad esempio 1 milione) e calcoliamo la media e la varianza dei risultati ottenuti.\n\nset.seed(42)\n\n# Generiamo 1 milione di esperimenti: 4 lanci con probabilità di successo 0.2\nx &lt;- rbinom(n = 1e6, size = 4, prob = 0.2)\n\n# Calcoliamo la media empirica\nmean(x)\n#&gt; [1] 0.8002\n# [1] circa 0.8\n\n# Calcoliamo la varianza empirica\nvar(x)\n#&gt; [1] 0.639\n# [1] circa 0.64\n\nCome possiamo vedere, i risultati ottenuti dalla simulazione sono molto vicini ai valori teorici: la media è circa \\(\\mu = 0.8\\) e la varianza circa \\(0.64\\), proprio come previsto dalle formule.\nQuesto non solo conferma che le formule per media e varianza nella distribuzione binomiale sono corrette, ma ci aiuta anche a capire meglio cosa significano:\n\nil valore atteso rappresenta la media dei risultati se ripetiamo l’esperimento moltissime volte;\n\nla varianza (e la sua radice quadrata, la deviazione standard) misura quanto i risultati si allontanano dalla media.\n\nLa simulazione mostra quindi in modo concreto che il valore atteso e la varianza descrivono il comportamento “medio” della variabile aleatoria, quando viene osservata in un numero molto grande di situazioni. In altre parole, questi concetti non sono solo teorici: ci dicono cosa aspettarci nella pratica, se ripetiamo molte volte lo stesso esperimento.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html#funzioni-r-per-le-distribuzioni-di-probabilità",
    "href": "chapters/probability/12_discr_rv_distr.html#funzioni-r-per-le-distribuzioni-di-probabilità",
    "title": "39  Distribuzioni di v.c. discrete",
    "section": "\n39.6 Funzioni R per le distribuzioni di probabilità",
    "text": "39.6 Funzioni R per le distribuzioni di probabilità\nIn R, le distribuzioni di probabilità (sia discrete che continue) sono gestite in modo sistematico. Per ogni distribuzione, esistono quattro funzioni principali, ognuna con un prefisso diverso che indica il tipo di operazione desiderata:\n\n\nd*: calcola la densità (per distribuzioni continue) o la probabilità (per distribuzioni discrete);\n\n\np*: calcola la funzione di ripartizione cumulativa (CDF), cioè \\(P(Y \\leq y)\\);\n\n\nq*: calcola la funzione quantile (inversa della CDF);\n\n\nr*: genera valori casuali secondo la distribuzione specificata.\n\nQuesta struttura è identica per tutte le distribuzioni implementate in R. La tabella seguente mostra un confronto tra le funzioni disponibili per due distribuzioni fondamentali: la binomiale (discreta) e la normale (continua).\n\n\n\n\n\n\n\nTipo di funzione\nBinomiale (\\(Y \\sim \\text{Bin}(n, p)\\))\nNormale (\\(Y \\sim \\mathcal{N}(\\mu, \\sigma)\\))\n\n\n\nDensità o probabilità esatta\ndbinom(y, size = n, prob = p)\ndnorm(y, mean = mu, sd = sigma)\n\n\n\\(P(Y = y)\\)\ndbinom(...)\n❌ Non definita: per variabili continue si usa la densità\n\n\nProbabilità cumulativa\npbinom(y, size = n, prob = p)\npnorm(y, mean = mu, sd = sigma)\n\n\n\\(P(Y \\geq y)\\)\n1 - pbinom(y - 1, ...)\n1 - pnorm(y, ...)\n\n\n\\(P(y_1 &lt; Y &lt; y_2)\\)\npbinom(y2, ...) - pbinom(y1, ...)\npnorm(y2, ...) - pnorm(y1, ...)\n\n\nQuantile (inversa della CDF)\nqbinom(q, size = n, prob = p)\nqnorm(q, mean = mu, sd = sigma)\n\n\nSimulazione di dati casuali\nrbinom(n, size = trials, prob = p)\nrnorm(n, mean = mu, sd = sigma)\n\n\n\n\n\n\n\n\n\nNota\n\n\n\n\nPer le distribuzioni discrete (come la binomiale), dbinom(y, ...) restituisce la probabilità esatta di osservare il valore \\(y\\): ad esempio, \\(P(Y = 2)\\).\nPer le distribuzioni continue (come la normale), dnorm(y, ...) restituisce la densità in \\(y\\), che non rappresenta direttamente una probabilità, ma è utile per visualizzare la forma della distribuzione.\nLe probabilità cumulative (funzioni p*) e i quantili (funzioni q*) sono sempre definiti, sia per distribuzioni discrete che continue.\nLa generazione di dati casuali con r* è molto utile per simulazioni e verifiche empiriche.\n\nPiù avanti, vedremo altre distribuzioni (Uniforme, Beta, Poisson, ecc.), tutte con lo stesso schema di funzioni: d, p, q, r.\nQuesta coerenza rende molto semplice imparare a usare le distribuzioni in R: una volta compreso lo schema, lo si può applicare a qualsiasi caso.\n\n\n\nEsempio 39.6  \n\nCalcolare la probabilità di esattamente \\(y = 3\\) successi su \\(n = 5\\) prove con \\(p = 0.5\\):\n\n\ndbinom(3, size = 5, prob = 0.5)\n#&gt; [1] 0.3125\n\n\nCalcolare la probabilità cumulativa \\(P(Y \\leq 3)\\):\n\n\npbinom(3, size = 5, prob = 0.5)\n#&gt; [1] 0.8125\n\n\nCalcolare il valore minimo \\(y\\) tale che \\(P(Y \\leq y) \\geq 0.9\\):\n\n\nqbinom(0.9, size = 5, prob = 0.5)\n#&gt; [1] 4\n\n\nGenerare un campione di 100 numeri casuali da una distribuzione binomiale:\n\n\nrbinom(100, size = 5, prob = 0.5)\n#&gt;   [1] 2 2 4 1 3 2 3 2 2 2 3 3 3 3 1 4 1 1 0 2 2 2 4 1 2 3 3 1 5 2 3 3 0 3 2\n#&gt;  [36] 3 4 2 3 3 3 3 1 5 3 3 2 3 1 2 1 3 3 2 2 4 1 4 2 3 1 4 2 2 3 4 1 1 4 2\n#&gt;  [71] 3 2 3 3 3 1 4 4 3 3 4 3 3 3 2 2 3 3 2 4 4 3 2 2 0 3 1 3 1 2",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html#distribuzione-di-poisson-1",
    "href": "chapters/probability/12_discr_rv_distr.html#distribuzione-di-poisson-1",
    "title": "39  Distribuzioni di v.c. discrete",
    "section": "\n39.7 Distribuzione di Poisson",
    "text": "39.7 Distribuzione di Poisson\nLa distribuzione di Poisson è utilizzata per modellare il numero di eventi che si verificano in un determinato intervallo di tempo o spazio, con eventi indipendenti e un tasso costante di occorrenza.\nLa funzione di massa di probabilità (PMF) è data da:\n\\[\nP(Y = y \\mid \\lambda) = \\frac{\\lambda^y \\cdot e^{-\\lambda}}{y!}, \\quad y = 0, 1, 2, \\ldots\n\\]\ndove \\(\\lambda\\) rappresenta il tasso medio di eventi e \\(y\\) è il numero di eventi.\nLa distribuzione di Poisson può essere derivata come il limite di una distribuzione binomiale quando il numero di prove, \\(n\\), tende all’infinito e la probabilità di successo in ciascuna prova, \\(p\\), tende a zero, in modo tale che \\(np = \\lambda\\).\n\n\n\n\n\n\nDimostrazione\n\n\n\nPartiamo dalla funzione di probabilità binomiale:\n\\[\np(k) = \\frac{n!}{k!(n - k)!} p^k (1 - p)^{n - k}.\n\\]\nImpostiamo \\(np = \\lambda\\), il che implica che \\(p = \\frac{\\lambda}{n}\\). Sostituendo \\(p\\) con \\(\\frac{\\lambda}{n}\\) nella formula binomiale, otteniamo:\n\\[\np(k) = \\frac{n!}{k!(n - k)!} \\left(\\frac{\\lambda}{n}\\right)^k \\left(1 - \\frac{\\lambda}{n}\\right)^{n - k}.\n\\]\nOra, separiamo i termini per rendere più chiara la semplificazione. Possiamo riscrivere \\(\\left(\\frac{\\lambda}{n}\\right)^k\\) come \\(\\frac{\\lambda^k}{n^k}\\), e \\(\\left(1 - \\frac{\\lambda}{n}\\right)^{n - k}\\) come \\(\\left(1 - \\frac{\\lambda}{n}\\right)^n \\cdot \\left(1 - \\frac{\\lambda}{n}\\right)^{-k}\\). Quindi, l’espressione diventa:\n\\[\np(k) = \\frac{n!}{k!(n - k)!} \\cdot \\frac{\\lambda^k}{n^k} \\cdot \\left(1 - \\frac{\\lambda}{n}\\right)^n \\cdot \\left(1 - \\frac{\\lambda}{n}\\right)^{-k}.\n\\]\nOra, separiamo ulteriormente i termini:\n\\[\np(k) = \\frac{\\lambda^k}{k!} \\cdot \\frac{n!}{(n - k)! n^k} \\cdot \\left(1 - \\frac{\\lambda}{n}\\right)^n \\cdot \\left(1 - \\frac{\\lambda}{n}\\right)^{-k}.\n\\]\nQuesto passaggio mostra come la funzione di probabilità binomiale, sotto le condizioni \\(np = \\lambda\\) e \\(n \\to \\infty\\), si trasformi gradualmente nella forma che conduce alla distribuzione di Poisson.\nQuando \\(n \\to \\infty\\):\n\\[\n\\frac{\\lambda}{n} \\to 0\n\\]\n\\[\n\\frac{n!}{(n - k)! n^k} \\to 1\n\\]\n\\[\n\\left(1 - \\frac{\\lambda}{n}\\right)^n \\to e^{-\\lambda}\n\\]\n\\[\n\\left(1 - \\frac{\\lambda}{n}\\right)^{-k} \\to 1\n\\]\nSi ottiene quindi:\n\\[\np(k) \\to \\frac{\\lambda^k e^{-\\lambda}}{k!}\n\\]\nche è la funzione di Poisson.\n\n\n\n\n\n\n\n\nDimostrazione\n\n\n\nAnalizziamo il limite:\n\\[\n\\left(1 - \\frac{\\lambda}{n}\\right)^n \\to e^{-\\lambda} \\quad \\text{quando} \\quad n \\to \\infty.\n\\]\nUn limite fondamentale in analisi matematica è:\n\\[\n\\lim_{n \\to \\infty} \\left(1 + \\frac{a}{n}\\right)^n = e^a,\n\\]\ndove \\(e\\) è la base del logaritmo naturale (\\(e \\approx 2.71828\\)) e \\(a\\) è una costante. Questo limite è alla base della definizione della funzione esponenziale.\nNel nostro caso, abbiamo l’espressione:\n\\[\n\\left(1 - \\frac{\\lambda}{n}\\right)^n .\n\\]\nNotiamo che questa è molto simile al limite notevole, ma con un segno negativo. Possiamo riscriverla come:\n\\[\n\\left(1 - \\frac{\\lambda}{n}\\right)^n = \\left(1 + \\frac{-\\lambda}{n}\\right)^n.\n\\]\nApplicando il limite notevole con \\(a = -\\lambda\\), otteniamo:\n\\[\n\\lim_{n \\to \\infty} \\left(1 + \\frac{-\\lambda}{n}\\right)^n = e^{-\\lambda}.\n\\]\nQuindi, quando \\(n\\) diventa molto grande, l’espressione \\(\\left(1 - \\frac{\\lambda}{n}\\right)^n\\) si avvicina sempre di più a \\(e^{-\\lambda}\\).\n\n\n\n39.7.1 Proprietà principali\n\n\nMedia: \\(\\mathbb{E}[Y] = \\lambda\\)\n\n\nVarianza: \\(\\text{Var}(Y) = \\lambda\\)\n\n\nDi seguito, presentiamo esempi di calcolo e simulazione con R.\n\n39.7.2 Grafico della distribuzione di Poisson con \\(\\lambda = 2\\)\n\n\n# Parametro lambda\nlambda &lt;- 2\n\n# Valori di y (numero di eventi)\ny &lt;- 0:10\n\n# Calcolo delle probabilità\nprobabilities &lt;- dpois(y, lambda = lambda)\n\n# Creazione di un dataframe per ggplot\ndata &lt;- data.frame(\n  Numero_eventi = y,\n  Probabilita = probabilities\n)\n\n# Grafico della funzione di massa di probabilità \nggplot(data, aes(x = Numero_eventi, y = Probabilita)) +\n  geom_col(fill = okabe_ito_palette[2]) +  \n  labs(\n    title = \"Distribuzione di Massa di Probabilità di Poisson\",\n    x = \"Numero di eventi (k)\",\n    y = \"Probabilità\"\n  ) \n\n\n\n\n\n\n\n\n39.7.3 Calcolo della probabilità per un numero specifico di eventi\nPer calcolare la probabilità di osservare esattamente 3 eventi con \\(\\lambda = 2\\):\n\nprob &lt;- dpois(3, lambda = 2)\nprint(prob)\n#&gt; [1] 0.1804\n\n\n39.7.4 Calcolo della probabilità cumulativa \\(P(Y \\leq 3)\\)\n\nPer calcolare \\(P(Y \\leq 3)\\), la probabilità cumulativa:\n\ncum_prob &lt;- ppois(3, lambda = 2)\nprint(cum_prob)\n#&gt; [1] 0.8571\n\n\n39.7.5 Trovare il quantile corrispondente a una probabilità data\nPer trovare il numero massimo di eventi per cui la probabilità cumulativa è al massimo \\(0.8125\\):\n\nquantile &lt;- qpois(0.8125, lambda = 2)\nprint(quantile)\n#&gt; [1] 3\n\n\n39.7.6 Generazione di numeri casuali\nPer generare un campione di 1.000.000 di osservazioni da una distribuzione di Poisson con \\(\\lambda = 2\\):\n\nset.seed(42)\nsample &lt;- rpois(1000000, lambda = 2)\n\n# Calcolo di media e varianza del campione\nmean_sample &lt;- mean(sample)\nvar_sample &lt;- var(sample)\n\nprint(mean_sample)\n#&gt; [1] 2\nprint(var_sample)\n#&gt; [1] 1.996\n\n\nEsempio 39.7 Un esempio classico dell’uso della distribuzione di Poisson viene dalla Seconda Guerra Mondiale.\nIl contesto storico. Tra il 1944 e il 1945, Londra fu colpita da centinaia di missili V1 e V2 lanciati dalla Germania nazista. Le autorità britanniche si chiesero se i bombardamenti seguissero una strategia mirata: i missili venivano forse lanciati intenzionalmente su certi quartieri? O si trattava invece di un comportamento casuale, come se fossero stati distribuiti a caso?\nPer rispondere a questa domanda, il Ministero della Guerra britannico divise Londra in 576 aree di uguale superficie (ogni area misurava 0.25 km²) e registrò quanti missili avevano colpito ciascuna area. I dati furono poi analizzati dal matematico R. D. Clarke, che li pubblicò nel 1946.\nI dati osservati. Ecco una sintesi della distribuzione osservata:\n\n\nMissili per area\nNumero di aree\nFrequenza relativa\n\n\n\n0\n229\n0.398\n\n\n1\n211\n0.367\n\n\n2\n93\n0.161\n\n\n3\n35\n0.061\n\n\n4\n7\n0.012\n\n\n≥5\n1\n0.002\n\n\n\nIl numero medio di missili per area era \\(\\lambda \\approx 0.93\\). L’idea era confrontare queste frequenze con le probabilità teoriche previste da una distribuzione di Poisson con media \\(\\lambda = 0.93\\).\nInterpretazione con la distribuzione di Poisson. Utilizzando la funzione dpois() in R, possiamo calcolare le probabilità teoriche per ciascun valore osservato, da 0 a 4 missili per area (valori superiori sono troppo rari per essere trattati separatamente).\n\n# Parametro medio osservato\nlambda &lt;- 0.93\n\n# Valori possibili di missili per area\ny &lt;- 0:4\n\n# Probabilità teoriche secondo la distribuzione di Poisson\nprob_teoriche &lt;- dpois(y, lambda = lambda)\n\n# Aggiungiamo la probabilità per y &gt;= 5\nprob_teoriche &lt;- c(prob_teoriche, 1 - sum(prob_teoriche))  # y &gt;= 5\n\n# Visualizziamo\ndata.frame(\n  Missili_per_area = c(0:4, \"&gt;=5\"),\n  Probabilita_teorica = round(prob_teoriche, 3)\n)\n#&gt;   Missili_per_area Probabilita_teorica\n#&gt; 1                0               0.395\n#&gt; 2                1               0.367\n#&gt; 3                2               0.171\n#&gt; 4                3               0.053\n#&gt; 5                4               0.012\n#&gt; 6              &gt;=5               0.003\n\nConfrontando le probabilità teoriche della Poisson con quelle osservate nei dati reali, i risultati erano sorprendentemente simili. Questo suggeriva che i missili non erano lanciati su bersagli specifici, ma seguivano un comportamento statisticamente compatibile con una distribuzione casuale.\n\n# Frequenze osservate (dati originali di Clarke, 1946)\nfrequenze_osservate &lt;- c(229, 211, 93, 35, 7, 1)\nvalori_missili &lt;- c(0, 1, 2, 3, 4, \"≥5\")\n\n# Calcolo frequenze teoriche con Poisson (lambda = 0.93)\nlambda &lt;- 0.93\nprob_teoriche &lt;- dpois(0:4, lambda)\nprob_teoriche &lt;- c(prob_teoriche, 1 - sum(prob_teoriche))  # Per y &gt;= 5\n\n# Numero totale di aree (come somma delle osservazioni)\nn_aree &lt;- sum(frequenze_osservate)\n\n# Frequenze attese = probabilità teoriche * numero totale di aree\nfrequenze_attese &lt;- round(prob_teoriche * n_aree)\n\n# Costruzione del data frame\ndf &lt;- data.frame(\n  Missili_per_area = factor(valori_missili, levels = c(\"0\", \"1\", \"2\", \"3\", \"4\", \"≥5\")),\n  Osservate = frequenze_osservate,\n  Attese = frequenze_attese\n)\n\n# Conversione in formato lungo per ggplot2\ndf_long &lt;- reshape2::melt(df, id.vars = \"Missili_per_area\", variable.name = \"Tipo\", value.name = \"Frequenza\")\n\n# Creazione del grafico\nggplot(df_long, aes(x = Missili_per_area, y = Frequenza, fill = Tipo)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(\n    title = \n      \"Distribuzione dei missili su Londra:\\nosservato vs atteso (Poisson)\",\n    x = \"Numero di missili per area\",\n    y = \"Numero di aree\",\n    fill = \"Frequenza\"\n  ) \n\n\n\n\n\n\n\n\nLe barre blu rappresentano le frequenze osservate (quante aree hanno ricevuto 0, 1, 2… missili).\nLe barre rosse mostrano le frequenze attese se i missili fossero stati lanciati in modo completamente casuale, seguendo una distribuzione di Poisson con \\(\\lambda = 0.93\\).\n\nLa sovrapposizione tra i due andamenti è molto buona, il che rafforza l’idea che i bombardamenti fossero distribuiti casualmente — senza un pattern strategico apparente.\nCosa ci insegna questo esempio?\n\nLa distribuzione di Poisson è adatta quando vogliamo modellare eventi rari e indipendenti nello spazio o nel tempo.\nI dati dei missili su Londra mostrano come un fenomeno che a prima vista potrebbe sembrare non casuale (per via della concentrazione locale degli eventi) possa invece essere ben descritto da un modello probabilistico semplice, se considerato su una scala adatta.\n\n\n\nEsempio 39.8 Supponiamo di avere osservato, nel corso degli anni, che la frequenza relativa di bocciature all’esame di Psicometria è di circa 10% (cioè \\(p = 0.1\\)). Tuttavia, il numero di studenti iscritti a ciascun appello varia in modo estremo: al primo appello dell’anno partecipano più di 200 studenti, mentre negli ultimi appelli solo 2 o 3.\nQuesto rende inadeguato l’uso della distribuzione binomiale, che richiede un numero di prove (\\(n\\)) fisso o noto per ciascun appello.\nIn questi casi, possiamo modellare il numero di bocciature per appello usando una distribuzione di Poisson.\nPer ogni appello, possiamo stimare \\(\\lambda\\) moltiplicando il numero di studenti iscritti (\\(n\\)) per la frequenza attesa di bocciature (\\(p = 0.1\\)). A quel punto, il numero di bocciature osservate può essere approssimato da:\n\\[\nY \\sim \\text{Poisson}(\\lambda = n \\cdot p) .\n\\]\nQuindi la distribuzione cambia da appello ad appello, perché \\(\\lambda\\) cambia con \\(n\\), ma il modello rimane Poissoniano.\nSupponiamo di avere osservato i seguenti dati.\n\n\n\n\n\n\n\n\nAppello\nNumero iscritti (\\(n\\))\n\\(\\lambda = n \\cdot p\\)\nDistribuzione di bocciature\n\n\n\n1\n220\n\\(220 \\cdot 0.1 = 22\\)\n\\(Y \\sim \\text{Poisson}(22)\\)\n\n\n2\n95\n\\(95 \\cdot 0.1 = 9.5\\)\n\\(Y \\sim \\text{Poisson}(9.5)\\)\n\n\n8\n3\n\\(3 \\cdot 0.1 = 0.3\\)\n\\(Y \\sim \\text{Poisson}(0.3)\\)\n\n\n\nPer ogni appello, possiamo usare la funzione dpois() in R per calcolare la probabilità di osservare un certo numero di bocciature, dato il valore di \\(\\lambda\\) specifico per quell’appello.\nAd esempio, possiamo chiederci quale sia la probabilità che, nel secondo appello (95 iscritti), si registrino esattamente 8 bocciature.\n\nlambda &lt;- 95 * 0.1  # = 9.5\ndpois(8, lambda = lambda)\n#&gt; [1] 0.1232\n\nQuesta funzione calcola \\(P(Y = 8)\\) per una variabile \\(Y \\sim \\text{Poisson}(9.5)\\), cioè la probabilità di osservare esattamente 8 bocciature su 95 iscritti.\nSupponiamo di voler simulare il numero di bocciature in 8 appelli con numeri di iscritti variabili. Possiamo fare così:\n\nset.seed(42)\n\n# Numero iscritti per ciascun appello\nn_iscritti &lt;- c(220, 95, 60, 45, 20, 12, 6, 3)\n\n# Probabilità storica di bocciatura\np &lt;- 0.1\n\n# Parametri lambda per ogni appello\nlambda &lt;- n_iscritti * p\n\n# Simulazione delle bocciature per ciascun appello\nbocciature &lt;- rpois(length(lambda), lambda = lambda)\n\ndata.frame(\n  Appello = 1:8, \n  Iscritti = n_iscritti, \n  Lambda = lambda, \n  Bocciature = bocciature\n)\n#&gt;   Appello Iscritti Lambda Bocciature\n#&gt; 1       1      220   22.0         28\n#&gt; 2       2       95    9.5          8\n#&gt; 3       3       60    6.0          8\n#&gt; 4       4       45    4.5          5\n#&gt; 5       5       20    2.0          2\n#&gt; 6       6       12    1.2          2\n#&gt; 7       7        6    0.6          0\n#&gt; 8       8        3    0.3          0\n\n📈 Visualizzazione.\n\ndf &lt;- data.frame(Appello = factor(1:8), Bocciature = bocciature)\n\nggplot(df, aes(x = Appello, y = Bocciature)) +\n  geom_col(fill = okabe_ito_palette[2]) +\n  labs(\n    title = \"Bocciature attese per ciascun appello\",\n    x = \"Appello\",\n    y = \"Numero di bocciature\"\n  )\n\n\n\n\n\n\n\nIn sintesi,\n\nquando il numero di studenti iscritti a un appello non è noto a priori o varia fortemente, non è adeguato usare la distribuzione binomiale;\nse conosciamo la frequenza relativa di bocciature (es. \\(p = 0.1\\)), possiamo usare la distribuzione di Poisson con \\(\\lambda = n \\cdot p\\), adattandola a ciascun appello;\nquesto approccio è particolarmente utile per fare stima e simulazione del numero di bocciature attese, senza dover modellare tutti i singoli esiti.\n\n\n\nEsempio 39.9 Uno degli esempi più comuni per introdurre la distribuzione di Poisson riguarda il numero di nascite giornaliere in un ospedale.\nSupponiamo che, in un grande ospedale, la media storica sia di 4.5 nascite al giorno. Possiamo allora descrivere il numero di nascite in un giorno con una variabile casuale Poisson con parametro \\(\\lambda = 4.5\\):\n\\[\nY \\sim \\text{Poisson}(\\lambda = 4.5) .\n\\]\nCi chiediamo, ad esempio: qual è la probabilità che in un giorno nascano esattamente 6 bambini?\nPossiamo calcolarla con la funzione dpois():\n\n# Parametro medio: 4.5 nascite al giorno\nlambda &lt;- 4.5\n\n# Probabilità di osservare esattamente 6 nascite\nprob &lt;- dpois(6, lambda = lambda)\nprint(prob)\n#&gt; [1] 0.1281\n\nQuesto valore rappresenta la probabilità che, in un giorno qualsiasi, si verifichino esattamente 6 nascite.\nSimulazione. Simuliamo ora il numero di nascite in 365 giorni consecutivi, supponendo che la media rimanga costante a 4.5:\n\nset.seed(42)  # Per rendere i risultati riproducibili\n\nn_days &lt;- 365\nsimulated_births &lt;- rpois(n_days, lambda = lambda)\n\n# Proporzione di giorni con esattamente 6 nascite\nproportion_six_births &lt;- mean(simulated_births == 6)\nprint(proportion_six_births)\n#&gt; [1] 0.1397\n\nQuesto ci dice, tra i 365 giorni simulati, quanta parte dell’anno ha avuto esattamente 6 nascite. Il valore ottenuto può essere confrontato con la probabilità teorica calcolata prima.\nVisualizzazione. Possiamo rappresentiamo graficamente i dati simulati con un istogramma:\n\n# Costruzione del data frame\ndata &lt;- data.frame(Nascite = simulated_births)\n\n# Istogramma\nggplot(data, aes(x = Nascite)) +\n  geom_histogram(\n    breaks = seq(-0.5, max(simulated_births) + 0.5, by = 1),\n    fill = okabe_ito_palette[2],\n    color = \"black\"\n  ) +\n  labs(\n    title = \"Distribuzione simulata delle nascite in 365 giorni\",\n    x = \"Numero di nascite per giorno\",\n    y = \"Frequenza (numero di giorni)\"\n  )\n\n\n\n\n\n\n\nL’istogramma mostra quante volte si sono verificati 0, 1, 2, …, 10 o più nascite in un giorno, evidenziando la variabilità naturale attorno alla media.\nCalcoliamo ora quanto è probabile che si verifichino più di 6 nascite in un giorno.\nProbabilità teorica:\n\nprob_more_than_six &lt;- 1 - ppois(6, lambda = lambda)\nprint(prob_more_than_six)\n#&gt; [1] 0.1689\n\nProporzione osservata nella simulazione:\n\nproportion_more_than_six &lt;- mean(simulated_births &gt; 6)\nprint(proportion_more_than_six)\n#&gt; [1] 0.1699\n\nIl confronto tra probabilità teorica e proporzione simulata mostra come la distribuzione di Poisson riproduca bene i fenomeni reali, quando gli eventi sono indipendenti, discreti e relativamente frequenti ma non troppo.\n\n\nEsempio 39.10 Questo esempio è tratto dal celebre lavoro di Ladislaus von Bortkiewicz del 1898, spesso citato come una delle prime applicazioni reali della distribuzione di Poisson.\nVon Bortkiewicz studiò un evento piuttosto inusuale: le morti causate da calci di cavallo all’interno della cavalleria dell’esercito prussiano. L’obiettivo era capire se questi eventi, seppur rari, potessero essere considerati casuali e indipendenti, oppure se fossero distribuiti in modo irregolare e non prevedibile.\nPer farlo, raccolse i dati su 10 squadroni osservati per 20 anni consecutivi, ottenendo così 200 unità di osservazione, che possiamo chiamare “squadroni-anno”.\nI dati raccolti. Per ogni squadrone-anno, fu registrato il numero di morti per calci di cavallo. I dati furono poi raggruppati per numero di decessi:\n\n\n\n\n\n\n\n\nNumero di decessi annui\nFrequenza osservata\nFrequenza relativa\nProbabilità teorica (Poisson)\n\n\n\n0\n109\n0.545\n0.543\n\n\n1\n65\n0.325\n0.331\n\n\n2\n22\n0.110\n0.101\n\n\n3\n3\n0.015\n0.021\n\n\n4\n1\n0.005\n0.003\n\n\n\n\n\nFrequenza osservata: Quante volte ciascun numero di decessi è stato osservato tra i 200 squadroni-anno.\n\nFrequenza relativa: Frequenza osservata divisa per 200.\n\nProbabilità teorica: Calcolata con la distribuzione di Poisson con parametro \\(\\lambda = 0.61\\), pari alla media osservata dei decessi annui.\n\nLa distribuzione di Poisson è perfetta per questo tipo di situazione perché:\n\nstiamo contando il numero di eventi rari (decessi accidentali),\nche si verificano in unità di tempo o spazio fisse (lo “squadrone-anno”),\ne presumiamo che questi eventi siano indipendenti tra loro.\n\nIn questo caso, \\(\\lambda = 0.61\\) rappresenta il numero medio di decessi per squadrone in un anno. La variabilità intorno a questo valore può essere descritta dalla distribuzione di Poisson, che assegna a ciascun possibile numero di decessi (0, 1, 2, …) una probabilità teorica.\nConfronto tra dati osservati e modello di Poisson. Come si può notare dalla tabella, le frequenze osservate sono sorprendentemente simili alle probabilità teoriche ottenute dal modello di Poisson. Ad esempio:\n\nla proporzione di squadroni-anno con zero decessi è 0.545, contro una probabilità teorica di 0.543;\nper un decesso, la frequenza relativa è 0.325, vicina alla probabilità teorica di 0.331;\nanche le classi meno frequenti (2, 3 e 4 decessi) sono coerenti con i valori attesi.\n\nQuesto esempio dimostra che la distribuzione di Poisson non solo è utile per modellare eventi rari, ma fornisce anche una buona descrizione quantitativa del comportamento osservato nel mondo reale.\nIn sintesi,\n\nil lavoro di von Bortkiewicz è uno dei primi esempi storici di modellizzazione di dati reali con la teoria delle probabilità;\nla distribuzione di Poisson si è rivelata efficace nel descrivere un fenomeno raro, ma regolare, suggerendo che i decessi fossero eventi casuali e indipendenti, non dovuti a fattori sistematici;\nancora oggi, questo esempio viene usato per insegnare che anche gli eventi accidentali e poco frequenti possono essere prevedibili in media e descritti in modo elegante da un modello probabilistico.\n\nQui di seguito viene fornito il codice R che riproduce l’analisi di von Bortkiewicz, calcola le probabilità teoriche secondo la distribuzione di Poisson con parametro \\(\\lambda = 0.61\\) e confronta visivamente le frequenze osservate con le frequenze attese.\n\n# Dati osservati da von Bortkiewicz\ndecessi &lt;- 0:4\nfrequenze_osservate &lt;- c(109, 65, 22, 3, 1)\nn_total &lt;- sum(frequenze_osservate)  # Totale = 200 squadroni-anno\n\n# Frequenze relative\nfrequenze_relative &lt;- frequenze_osservate / n_total\n\nCalcolo delle probabilità teoriche con la distribuzione di Poisson:\n\n# Parametro medio osservato\nlambda &lt;- 0.61\n\n# Calcolo delle probabilità teoriche di Poisson\nprob_poisson &lt;- dpois(decessi, lambda = lambda)\n\nConfronto: osservato vs teorico.\n\n# Frequenze attese = probabilità teoriche * numero totale di casi\nfrequenze_attese &lt;- round(prob_poisson * n_total)\n\n# Creazione del data frame per il confronto\ndf &lt;- data.frame(\n  Decessi = factor(decessi),\n  Osservato = frequenze_osservate,\n  Atteso = frequenze_attese\n)\ndf\n#&gt;   Decessi Osservato Atteso\n#&gt; 1       0       109    109\n#&gt; 2       1        65     66\n#&gt; 3       2        22     20\n#&gt; 4       3         3      4\n#&gt; 5       4         1      1\n\nVisualizzazione: confronto tra frequenze osservate e attese.\n\n# Conversione da wide a long format con pivot_longer()\ndf_long &lt;- df |&gt; \n  pivot_longer(\n    cols = c(Osservato, Atteso),\n    names_to = \"Tipo\",\n    values_to = \"Frequenza\"\n  )\n\n# Mostra le prime righe\nhead(df_long)\n#&gt; # A tibble: 6 × 3\n#&gt;   Decessi Tipo      Frequenza\n#&gt;   &lt;fct&gt;   &lt;chr&gt;         &lt;dbl&gt;\n#&gt; 1 0       Osservato       109\n#&gt; 2 0       Atteso          109\n#&gt; 3 1       Osservato        65\n#&gt; 4 1       Atteso           66\n#&gt; 5 2       Osservato        22\n#&gt; 6 2       Atteso           20\n\n\n# Grafico a barre affiancate\nggplot(df_long, aes(x = Decessi, y = Frequenza, fill = Tipo)) +\n  geom_bar(stat = \"identity\", position = \"dodge\", color = \"black\") +\n  labs(\n    title = \"Confronto tra frequenze osservate e attese (Poisson)\",\n    subtitle = expression(lambda == 0.61 ~ \"(von Bortkiewicz, 1898)\"),\n    x = \"Numero di decessi per squadrone-anno\",\n    y = \"Frequenza\",\n    fill = \"Tipo\"\n  ) \n\n\n\n\n\n\n\n\nLe barre blu mostrano i dati osservati da von Bortkiewicz.\nLe barre rosse indicano le frequenze attese se il numero di decessi segue una distribuzione di Poisson con media \\(\\lambda = 0.61\\).\nLa buona corrispondenza visiva tra le due serie supporta l’idea che i decessi siano eventi rari, indipendenti e distribuiti casualmente.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html#distribuzione-beta-binomiale",
    "href": "chapters/probability/12_discr_rv_distr.html#distribuzione-beta-binomiale",
    "title": "39  Distribuzioni di v.c. discrete",
    "section": "\n39.8 Distribuzione Beta-Binomiale",
    "text": "39.8 Distribuzione Beta-Binomiale\nLa distribuzione beta-binomiale rappresenta una estensione della distribuzione binomiale che tiene conto della variabilità nella probabilità di successo tra i vari tentativi. Viene descritta da tre parametri principali: \\(N\\), \\(\\alpha\\) e \\(\\beta\\).\nNel dettaglio, la funzione di massa di probabilità per la distribuzione beta-binomiale è data da:\n\\[\n\\text{BetaBinomiale}(y | N, \\alpha, \\beta) = \\binom{N}{y} \\cdot \\frac{B(y + \\alpha, N - y + \\beta)}{B(\\alpha, \\beta)},\n\\tag{39.5}\\]\ndove:\n\n\n\\(y\\) indica il numero di successi osservati.\n\n\\(N\\) rappresenta il numero totale di tentativi.\n\n\\(\\alpha\\) e \\(\\beta\\) sono i parametri della distribuzione beta, che modellano la variabilità nella probabilità di successo tra i tentativi.\n\nLa funzione \\(B(u, v)\\), nota come funzione beta, è definita tramite l’uso della funzione gamma \\(\\Gamma\\), secondo la formula:\n\\[\nB(u, v) = \\frac{\\Gamma(u) \\Gamma(v)}{\\Gamma(u + v)},\n\\]\ndove la funzione gamma \\(\\Gamma\\) generalizza il concetto di fattoriale a numeri reali e complessi.\nL’importanza della distribuzione beta-binomiale deriva dalla sua capacità di modellare situazioni in cui la probabilità di successo non è fissa, ma segue una distribuzione di probabilità, specificatamente una distribuzione beta. Ciò la rende particolarmente adatta per applicazioni in cui le probabilità di successo cambiano in maniera incerta da un tentativo all’altro, come può avvenire in contesti di ricerca clinica o in studi comportamentali. Rispetto alla distribuzione binomiale, che assume una probabilità di successo costante per tutti i tentativi, la beta-binomiale offre una rappresentazione più realistica e flessibile per dati empirici che presentano variabilità nelle probabilità di successo.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html#riflessioni-conclusive",
    "href": "chapters/probability/12_discr_rv_distr.html#riflessioni-conclusive",
    "title": "39  Distribuzioni di v.c. discrete",
    "section": "\n39.9 Riflessioni Conclusive",
    "text": "39.9 Riflessioni Conclusive\nIn questo capitolo, abbiamo approfondito alcune delle distribuzioni discrete più importanti, ognuna con caratteristiche uniche e campi di applicazione specifici. Abbiamo iniziato con la distribuzione di Bernoulli, che modella esperimenti con due soli esiti possibili, per poi passare alla distribuzione Binomiale, che generalizza la Bernoulli considerando un numero fisso di prove indipendenti. Successivamente, abbiamo esaminato la distribuzione di Poisson, utile per descrivere eventi rari in un intervallo di tempo o spazio, e la distribuzione Beta-Binomiale, un’estensione della Binomiale che incorpora la variabilità nella probabilità di successo, rendendola particolarmente adatta per modellare situazioni in cui tale probabilità non è fissa. Infine, abbiamo discusso la distribuzione Discreta Uniforme, che assegna la stessa probabilità a ciascun evento in un insieme finito e discreto.\nQueste distribuzioni rappresentano il fondamento dell’analisi statistica discreta e trovano applicazione in numerosi ambiti. In particolare, nel contesto dell’inferenza bayesiana, la comprensione della distribuzione Binomiale e della sua estensione Beta-Binomiale è essenziale. Queste distribuzioni, infatti, forniscono gli strumenti necessari per l’aggiornamento bayesiano, un processo chiave che permette di rivedere le nostre credenze iniziali alla luce di nuovi dati. Questo concetto sarà ulteriormente esplorato nei capitoli successivi, dove approfondiremo come le distribuzioni a priori e a posteriori interagiscono nel quadro bayesiano.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html#esercitazione-in-classe",
    "href": "chapters/probability/12_discr_rv_distr.html#esercitazione-in-classe",
    "title": "39  Distribuzioni di v.c. discrete",
    "section": "\n39.10 Esercitazione in Classe",
    "text": "39.10 Esercitazione in Classe\nValutate le emozioni che verranno presentate sullo schermo usando questo link.\nScala di risposta:\n\nRabbia: 1\nDisgusto: 2\nPaura: 3\nFelicità: 4\nTristezza: 5",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html#esercizi",
    "href": "chapters/probability/12_discr_rv_distr.html#esercizi",
    "title": "39  Distribuzioni di v.c. discrete",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nPer ciascuna delle distribuzioni di massa di probabilità discusse, utilizzare R per:\n\ncreare un grafico della funzione, scegliendo opportunamente i parametri;\nestrarre un campione di 1000 valori casuali dalla distribuzione e visualizzarlo con un istogramma;\ncalcolare la media e la deviazione standard dei campioni e confrontarle con i valori teorici attesi;\nstimare l’intervallo centrale del 94% utilizzando i campioni simulati;\ndeterminare i quantili della distribuzione per gli ordini 0.05, 0.25, 0.75 e 0.95;\nscegliendo un valore della distribuzione pari alla media più una deviazione standard, calcolare la probabilità che la variabile aleatoria assuma un valore minore o uguale a questo valore.\n\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nEsercizi sulla distribuzione binomiale, risolvibili usando R, sono disponibili sulla seguente pagina web.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/12_discr_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "title": "39  Distribuzioni di v.c. discrete",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] reshape2_1.4.4   thematic_0.1.7   MetBrewer_0.2.0  ggokabeito_0.1.0\n#&gt;  [5] see_0.11.0       gridExtra_2.3    patchwork_1.3.0  bayesplot_1.13.0\n#&gt;  [9] psych_2.5.3      scales_1.4.0     markdown_2.0     knitr_1.50      \n#&gt; [13] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [17] purrr_1.0.4      readr_2.1.5      tidyr_1.3.1      tibble_3.3.0    \n#&gt; [21] ggplot2_3.5.2    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] utf8_1.2.6         generics_0.1.4     stringi_1.8.7     \n#&gt;  [4] lattice_0.22-7     hms_1.1.3          digest_0.6.37     \n#&gt;  [7] magrittr_2.0.3     evaluate_1.0.4     grid_4.5.0        \n#&gt; [10] timechange_0.3.0   RColorBrewer_1.1-3 fastmap_1.2.0     \n#&gt; [13] plyr_1.8.9         rprojroot_2.0.4    jsonlite_2.0.0    \n#&gt; [16] mnormt_2.1.1       cli_3.6.5          rlang_1.1.6       \n#&gt; [19] withr_3.0.2        yaml_2.3.10        tools_4.5.0       \n#&gt; [22] parallel_4.5.0     tzdb_0.5.0         pacman_0.5.1      \n#&gt; [25] vctrs_0.6.5        R6_2.6.1           lifecycle_1.0.4   \n#&gt; [28] htmlwidgets_1.6.4  pkgconfig_2.0.3    pillar_1.10.2     \n#&gt; [31] gtable_0.3.6       Rcpp_1.0.14        glue_1.8.0        \n#&gt; [34] xfun_0.52          tidyselect_1.2.1   rstudioapi_0.17.1 \n#&gt; [37] farver_2.1.2       htmltools_0.5.8.1  nlme_3.1-168      \n#&gt; [40] labeling_0.4.3     rmarkdown_2.29     compiler_4.5.0",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_discr_rv_distr.html#bibliografia",
    "href": "chapters/probability/12_discr_rv_distr.html#bibliografia",
    "title": "39  Distribuzioni di v.c. discrete",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html",
    "href": "chapters/probability/13_cont_rv_distr.html",
    "title": "40  Distribuzioni di v.c. continue",
    "section": "",
    "text": "40.1 Introduzione\nProprio come per le variabili casuali discrete, anche per le variabili casuali continue è possibile rappresentare la variabilità di una popolazione attraverso un modello statistico. Tuttavia, mentre le distribuzioni discrete si applicano a fenomeni con un numero finito o numerabile di esiti, le variabili casuali continue richiedono l’uso di funzioni di densità di probabilità (pdf), che descrivono fenomeni in cui i valori possono assumere un continuum di possibilità. Queste funzioni ci permettono di modellare e analizzare situazioni in cui i risultati non sono discreti, ma possono variare in modo continuo.\nLa funzione di densità di probabilità \\(f(x)\\) associata a una variabile casuale continua \\(X\\) rappresenta la distribuzione della probabilità all’interno della popolazione. A differenza delle distribuzioni discrete, dove la probabilità è assegnata direttamente a singoli valori, la pdf non fornisce la probabilità di un singolo punto, ma descrive la probabilità che \\(X\\) assuma valori all’interno di un intervallo specifico. Questo approccio consente di costruire un modello matematico della popolazione, utile per fare previsioni e comprendere meglio i fenomeni aleatori continui.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html#la-distribuzione-uniforme-continua",
    "href": "chapters/probability/13_cont_rv_distr.html#la-distribuzione-uniforme-continua",
    "title": "40  Distribuzioni di v.c. continue",
    "section": "\n40.2 La Distribuzione Uniforme Continua",
    "text": "40.2 La Distribuzione Uniforme Continua\nLa distribuzione uniforme continua rappresenta un pilastro della teoria delle probabilità, caratterizzata da una densità di probabilità costante su un intervallo definito. Questo modello è particolarmente utile per descrivere fenomeni casuali dove ogni esito possibile ha identica probabilità di verificarsi, come nel caso di uno spinner perfettamente bilanciato o di un generatore di numeri casuali ideale.\n\n40.2.1 Un esempio intuitivo: lo spinner\nConsideriamo uno spinner circolare con valori angolari compresi tra 0° e 360°. Se il dispositivo è perfettamente equilibrato, ogni angolo ha la stessa probabilità di essere selezionato dopo una rotazione. Questo esperimento costituisce un’implementazione concreta della distribuzione uniforme sull’intervallo \\([0, 360)\\).\n\n40.2.2 Simulazione della distribuzione: dal campione piccolo alla convergenza teorica\nPer illustrare il comportamento della distribuzione, analizziamo due scenari distinti attraverso simulazioni numeriche.\nCaso 1: Campione piccolo (n = 20)\nGeneriamo 20 valori casuali e visualizziamoli con un istogramma:\n\nset.seed(123)  # Riproducibilità dei risultati\nspinner_results &lt;- runif(20, min = 0, max = 360)\nprint(spinner_results)  # Output dei dati\n#&gt;  [1] 103.53 283.79 147.23 317.89 338.57  16.40 190.12 321.27 198.52 164.38\n#&gt; [11] 344.46 163.20 243.93 206.15  37.05 323.94  88.59  15.14 118.05 343.62\n\n# Creazione dell'istogramma\nggplot(data.frame(Valori = spinner_results), aes(x = Valori)) +\n  geom_histogram(\n    binwidth = 10, \n    fill = \"skyblue\", \n    color = \"black\", \n    alpha = 0.5\n  ) +\n  labs(\n    x = \"Angolo (gradi)\", \n    y = \"Frequenza relativa\",\n    title = \"Distribuzione con 20 simulazioni\"\n  ) \n\n\n\n\n\n\n\nL’istogramma mostra un andamento irregolare, riflettendo la variabilità intrinseca dei piccoli campioni. Questa disomogeneità è attesa e diminuisce all’aumentare della dimensione campionaria.\nCaso 2: Campione grande (n = 100,000)\nRipetiamo la simulazione con un campione esteso:\n\nspinner_results_large &lt;- runif(100000, min = 0, max = 360)\n\nggplot(data.frame(Valori = spinner_results_large), aes(x = Valori)) +\n  geom_histogram(\n    binwidth = 10, \n    fill = \"skyblue\", \n    color = \"black\", \n    alpha = 0.5\n  ) +\n  labs(\n    x = \"Angolo (gradi)\", \n    y = \"Frequenza relativa\",\n    title = \"Distribuzione con 100.000 simulazioni\"\n  ) \n\n\n\n\n\n\n\nL’istogramma ora rivela un profilo piatto e regolare, in accordo con la forma teorica della distribuzione. Questo risultato dimostra empiricamente la Legge dei Grandi Numeri, dove all’aumentare delle osservazioni la distribuzione empirica converge a quella teorica.\n\n40.2.3 La Funzione di Densità di Probabilità (PDF)\nPer una variabile casuale \\(X \\sim \\mathcal{U}(a, b)\\), la PDF è definita come:\n\\[\nf(x) =\n\\begin{cases}\n  \\displaystyle \\frac{1}{b - a} & \\text{se } x \\in [a, b], \\\\\n  0 & \\text{altrimenti}.\n\\end{cases}\n\\]\nProprietà chiave:\n\nl’area totale sotto la curva è unitaria: \\(\\int_{a}^{b} \\frac{1}{b - a} \\, dx = 1\\);\n\nla densità è nulla al di fuori dell’intervallo \\([a, b]\\).\n\nApplicazione allo spinner:\n\\[\nf(x) = \\frac{1}{360} \\quad \\text{per } x \\in [0, 360].\n\\]\nVisualizzazione grafica in R:\n\nx &lt;- seq(-50, 410, length.out = 500)  \ndensity_uniform &lt;- dunif(x, min = 0, max = 360)\n\nggplot(data.frame(x = x, y = density_uniform), aes(x = x, y = y)) +\n  geom_line(linewidth = 1.2, color = \"blue\") +\n  geom_vline(xintercept = c(0, 360), linetype = \"dashed\", color = \"red\") +\n  labs(\n    x = \"x (gradi)\", \n    y = \"Densità f(x)\", \n    title = \"PDF della distribuzione uniforme\"\n  ) +\n  xlim(-50, 410) \n\n\n\n\n\n\n\nIl grafico evidenzia la densità costante nell’intervallo \\([0, 360]\\) e l’assenza di probabilità al di fuori di esso.\n\n40.2.4 Calcolo delle Probabilità: Metodo Geometrico e Funzionale\nLa probabilità che \\(X\\) assuma valori in un sottointervallo \\([c, d] \\subseteq [a, b]\\) è data da:\n\\[\nP(c \\leq X \\leq d) = \\frac{d - c}{b - a}.\n\\]\nEsempio applicativo:\nCalcoliamo la probabilità che lo spinner si fermi tra 150° e 250°:\n\\[\nP(150 \\leq X \\leq 250) = \\frac{250 - 150}{360} = \\frac{100}{360} = \\frac{5}{18} \\approx 0.2778.\n\\]\nConferma numerica in R:\n\n# Approccio manuale\nprob_manuale &lt;- (250 - 150) / 360  \n\n# Utilizzo della funzione cumulativa (CDF)\nprob_cdf &lt;- punif(250, min = 0, max = 360) - punif(150, min = 0, max = 360)  \n\nRappresentazione grafica dell’area di probabilità:\n\nggplot(data.frame(x = x, fx = density_uniform), aes(x = x, y = fx)) +\n  geom_line(linewidth = 1.2, color = \"blue\") +\n  geom_area(\n    data = subset(data.frame(x, fx = density_uniform), x &gt;= 150 & x &lt;= 250),\n    aes(x = x, y = fx), \n    fill = \"gray\", \n    alpha = 0.5\n  ) +\n  labs(\n    x = \"x (gradi)\", \n    y = \"Densità f(x)\", \n    title = \"Area corrispondente a P(150 ≤ X ≤ 250)\"\n  ) \n\n\n\n\n\n\n\nL’area grigia corrisponde esattamente al valore di probabilità calcolato, illustrando visivamente il concetto di integrazione della PDF.\n\n40.2.5 Proprietà Fondamentali: Media e Varianza\nPer \\(X \\sim \\mathcal{U}(a, b)\\) valgono le seguenti relazioni:\n\n\nValore atteso (centro della distribuzione):\n\\[\nE(X) = \\frac{a + b}{2}.\n\\]\nEsempio: Per lo spinner, \\(E(X) = (0 + 360)/2 = 180\\) gradi.\n\n\nVarianza (misura di dispersione):\n\\[\n\\text{Var}(X) = \\frac{(b - a)^2}{12}.\n\\]\nEsempio: Per lo spinner, \\(\\text{Var}(X) = (360 - 0)^2 / 12 = 10,\\!800\\) gradi².\n\n\n40.2.6 Implementazione in R: Funzioni Principali\nR fornisce quattro funzioni per lavorare con la distribuzione uniforme:\n\n\n\n\n\n\n\nFunzione\nDescrizione\nEsempio d’uso\n\n\n\nrunif()\nGenera valori casuali\nrunif(5, min=0, max=1)\n\n\ndunif()\nCalcola la densità \\(f(x)\\)\n\ndunif(180, min=0, max=360)\n\n\npunif()\nCalcola la CDF \\(P(X \\leq x)\\)\n\npunif(250, min=0, max=360)\n\n\nqunif()\nDetermina il quantile per una probabilità\nqunif(0.9, min=0, max=360)\n\n\n\nEsempi operativi:\n\n# 1. Generazione di 5 numeri casuali in [0, 1]\nrunif(5, min = 0, max = 1)  \n#&gt; [1] 0.03716 0.92779 0.44799 0.91590 0.35575\n\n# 2. Valore della densità in x = 0.5 per U(0,1)\ndunif(0.5, min = 0, max = 1)  \n#&gt; [1] 1\n\n# 3. Probabilità cumulativa fino a x = 0.8 per U(0,1)\npunif(0.8, min = 0, max = 1)  \n#&gt; [1] 0.8\n\n# 4. Calcolo del quantile corrispondente al 50° percentile (mediana)\nqunif(0.5, min = 0, max = 360)  \n#&gt; [1] 180",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html#la-distribuzione-esponenziale",
    "href": "chapters/probability/13_cont_rv_distr.html#la-distribuzione-esponenziale",
    "title": "40  Distribuzioni di v.c. continue",
    "section": "\n40.3 La Distribuzione Esponenziale",
    "text": "40.3 La Distribuzione Esponenziale\nLa distribuzione esponenziale è una distribuzione continua fondamentale per modellare il tempo di attesa fino al verificarsi di un evento casuale. La sua caratteristica distintiva è la proprietà di assenza di memoria, che la rende unica nel panorama delle distribuzioni probabilistiche.\n\n40.3.1 La proprietà di assenza di memoria: un concetto chiave\nL’assenza di memoria implica che la probabilità che un evento si verifichi in un intervallo futuro è indipendente dal tempo già trascorso.\nEsempio intuitivo:\nimmaginiamo una persona che sperimenta attacchi di ansia improvvisi, il cui tempo tra un episodio e il successivo segue una distribuzione esponenziale. Se l’individuo non ha avuto un attacco nelle ultime 2 settimane, la probabilità che ne sperimenti uno nei prossimi 3 giorni è identica a quella di una persona appena uscita da un episodio, nel medesimo intervallo di 3 giorni.\nQuesta analogia illustra la proprietà di assenza di memoria: il “tempo trascorso dall’ultimo evento” (in questo caso, un attacco di ansia) non influenza la probabilità futura. Il sistema non “accumula stress” né riduce il rischio col passare del tempo senza episodi, riflettendo dinamiche tipiche di processi psicologici non legati a meccanismi di apprendimento o adattamento.\nParametri chiave nell’esempio:\n\n\n\\(\\lambda\\) (tasso): Frequenza media degli attacchi (es. 0.1 episodi/giorno).\n\n\\(\\mu = 1/\\lambda\\) (media): Tempo medio tra due episodi (es. 10 giorni).\n\nLa distribuzione esponenziale modellizza così situazioni in cui il comportamento è puramente stocastico e non influenzato dalla storia precedente, come certi pattern di ansia, impulsività o reazioni fisiologiche a stimoli neutri.\n\n40.3.2 Struttura matematica: PDF e parametri\nLa funzione di densità di probabilità (PDF) di una variabile \\(X \\sim \\text{Exp}(\\lambda)\\) è:\n\\[\nf(x) =\n\\begin{cases}\n\\lambda e^{-\\lambda x} & \\text{se } x \\geq 0, \\\\\n0 & \\text{altrimenti},\n\\end{cases}\n\\]\ndove:\n\n\n\\(\\lambda\\) (tasso): numero medio di eventi per unità di tempo (es. 0.25 episodi/ora).\n\n\n\\(\\mu = 1/\\lambda\\) (media): tempo medio di attesa per l’evento (es. 4 ore/episodio).\n\nForma alternativa con \\(\\mu\\):\n\\[\nf(x) = \\frac{1}{\\mu} e^{-x/\\mu} \\quad \\text{per } x \\geq 0.\n\\]\n\n40.3.3 Proprietà fondamentali\nPer \\(X \\sim \\text{Exp}(\\lambda)\\):\n\n\n\n\n\n\n\nProprietà\nFormula\nInterpretazione\n\n\n\nValore atteso (μ)\n\\(E(X) = \\frac{1}{\\lambda}\\)\nTempo medio di attesa per l’evento.\n\n\nVarianza\n\\(\\text{Var}(X) = \\frac{1}{\\lambda^2}\\)\nDispersione cresce col quadrato di 1/λ.\n\n\nDeviazione standard\n\\(\\sigma_X = \\frac{1}{\\lambda}\\)\nSpread lineare attorno alla media.\n\n\n\nEsempio applicato.\nSe il tempo medio di pubblicazione dei voti di un esame universitario è \\(\\mu = 4\\) giorni (\\(\\lambda = 0.25\\)), la PDF è:\n\\[\nf(x) = \\frac{1}{4} e^{-x/4} \\quad (x \\geq 0).\n\\]\n\n40.3.4 Visualizzazione della densità in R\n\n# Definizione dei parametri\nmu &lt;- 4\nlambda &lt;- 1 / mu  # 0.25\n\n# Generazione dei punti per il grafico\nx &lt;- seq(0, 20, by = 0.1)\npdf &lt;- dexp(x, rate = lambda)\n\n# Creazione del grafico\nggplot(data.frame(x = x, y = pdf), aes(x = x, y = y)) +\n  geom_line(linewidth = 1.2, color = \"darkblue\") +\n  labs(\n    x = \"Tempo di attesa (giorni)\", \n    y = \"Densità f(x)\",\n    title = paste(\"PDF esponenziale (μ =\", mu, \"giorni)\")\n  ) \n\n\n\n\n\n\n\nIl grafico mostra un decadimento esponenziale: la probabilità decresce rapidamente all’aumentare del tempo.\n\n40.3.5 Calcolo delle Probabilità: Tre Scenari\n1. Probabilità cumulativa: \\(P(X \\leq 1.5)\\) – qual è la probabilità che il voto venga pubblicato entro un giorno e mezzo?\nUtilizziamo la funzione di ripartizione (CDF):\n\\[\nP(X \\leq 1.5) = 1 - e^{-\\lambda \\cdot 1.5} = 1 - e^{-0.25 \\cdot 1.5} \\approx 0.312.\n\\]\nCodice R:\n\npexp(1.5, rate = lambda)  # Restituisce 0.312\n#&gt; [1] 0.3127\n\nVisualizzazione:\n\n# Area sotto la curva per X &lt;= 1.5\nggplot(data.frame(x = x, y = pdf), aes(x = x, y = y)) +\n  geom_line(linewidth = 1.2, color = \"darkblue\") +\n  geom_area(\n    data = subset(data.frame(x, y = pdf), x &lt;= 1.5),\n    aes(x = x, y = y), \n    fill = \"gray\", \n    alpha = 0.5\n  ) +\n  labs(\n    x = \"Tempo (giorni)\", \n    y = \"Densità\",\n    title = \"Probabilità P(X ≤ 1.5)\"\n  )\n\n\n\n\n\n\n\n2. Probabilità intervallo: \\(P(1 \\leq X \\leq 6)\\) – qual è la probabilità che il voto venga pubblicato in un intervallo compreso tra 1 e 6 giorni dopo l’esame?\nCalcoliamo la differenza tra due CDF:\n\\[\nP(1 \\leq X \\leq 6) = F(6) - F(1) = e^{-0.25 \\cdot 1} - e^{-0.25 \\cdot 6} \\approx 0.491.\n\\]\nCodice R:\n\npexp(6, rate = lambda) - pexp(1, rate = lambda)  # 0.491\n#&gt; [1] 0.5557\n\nVisualizzazione:\n\n# Area per 1 &lt;= X &lt;= 6\nggplot(data.frame(x = x, y = pdf), aes(x = x, y = y)) +\n  geom_line(linewidth = 1.2, color = \"darkblue\") +\n  geom_area(\n    data = subset(data.frame(x, y = pdf), x &gt;= 1 & x &lt;= 6),\n    aes(x = x, y = y), \n    fill = \"gray\", \n    alpha = 0.5\n  ) +\n  labs(\n    x = \"Tempo (giorni)\", \n    y = \"Densità\",\n    title = \"Probabilità P(1 ≤ X ≤ 6)\"\n  )\n\n\n\n\n\n\n\n3. Probabilità della coda: \\(P(X \\geq 5.5)\\) – qual è la probabilità di un ritardo nella pubblicazione del voto superiore a 5.5 giorni dall’esame?\nUsiamo il complemento della CDF:\n\\[\nP(X \\geq 5.5) = 1 - P(X \\leq 5.5) = e^{-0.25 \\cdot 5.5} \\approx 0.252.\n\\]\nCodice R:\n\n1 - pexp(5.5, rate = lambda)  # 0.252\n#&gt; [1] 0.2528\n# Alternativa equivalente:\npexp(5.5, rate = lambda, lower.tail = FALSE)\n#&gt; [1] 0.2528\n\nVisualizzazione:\n\n# Area per X &gt;= 5.5\nggplot(data.frame(x = x, y = pdf), aes(x = x, y = y)) +\n  geom_line(linewidth = 1.2, color = \"darkblue\") +\n  geom_area(\n    data = subset(data.frame(x, y = pdf), x &gt;= 5.5),\n    aes(x = x, y = y), \n    fill = \"gray\", \n    alpha = 0.5\n  ) +\n  labs(\n    x = \"Tempo (giorni)\", \n    y = \"Densità\",\n    title = \"Probabilità P(X ≥ 5.5)\"\n  )\n\n\n\n\n\n\n\n\n40.3.6 Simulazione e convergenza alla teoria\nGeneriamo 1,000,000 di osservazioni da \\(\\text{Exp}(\\lambda = 0.25)\\) e confrontiamo l’istogramma con la PDF teorica:\n\nset.seed(123)\nsimulated_data &lt;- rexp(1e6, rate = lambda)\n\nggplot(data.frame(x = simulated_data), aes(x = x)) +\n  geom_histogram(\n    aes(y = after_stat(density)), \n    bins = 100, \n    fill = \"skyblue\", \n    color = \"black\",\n    alpha = 0.6\n  ) +\n  geom_line(\n    data = data.frame(x = x, y = pdf),\n    aes(x = x, y = y), \n    color = \"red\", \n    linewidth = 1.2\n  ) +\n  coord_cartesian(xlim = c(0, 20)) +  # Escludiamo code estreme\n  labs(\n    x = \"Tempo di attesa (giorni)\", \n    y = \"Densità\",\n    title = \"Confronto dati simulati e PDF teorica\"\n  ) \n\n\n\n\n\n\n\nL’istogramma si allinea perfettamente alla curva rossa, dimostrando la Legge dei Grandi Numeri.\n\n40.3.7 Funzioni R per la distribuzione esponenziale\nR offre quattro funzioni essenziali:\n\n\n\n\n\n\n\n\nFunzione\nDescrizione\nEsempio d’uso\nOutput Esempio\n\n\n\ndexp()\nCalcola la densità \\(f(x)\\)\n\ndexp(2, rate = 0.25)\n0.1516\n\n\npexp()\nCalcola la CDF \\(P(X \\leq x)\\)\n\npexp(4, rate = 0.25)\n0.632 (≈1 - e⁻¹)\n\n\nqexp()\nTrova il quantile \\(x\\) per una probabilità\nqexp(0.5, rate = 0.25)\n~2.773 (mediana)\n\n\nrexp()\nGenera valori casuali\nrexp(5, rate = 0.25)\n[3.1, 0.8, 5.2, …]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html#distribuzione-normale",
    "href": "chapters/probability/13_cont_rv_distr.html#distribuzione-normale",
    "title": "40  Distribuzioni di v.c. continue",
    "section": "\n40.4 Distribuzione Normale",
    "text": "40.4 Distribuzione Normale\nLa distribuzione normale (o gaussiana) è fondamentale in statistica per modellare fenomeni naturali, sociali e psicologici. La sua importanza deriva dal Teorema del Limite Centrale, che garantisce la convergenza alla normalità per somme di variabili casuali indipendenti.\n\n40.4.1 La Famiglia delle Distribuzioni Normali\nOgni distribuzione normale è definita da due parametri:\n\n\n\\(\\mu\\) (media): centro della distribuzione;\n\n\n\\(\\sigma\\) (deviazione standard): dispersione dei dati attorno alla media.\n\nLa funzione di densità è:\n\\[\nf(y; \\mu, \\sigma) = \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{-\\frac{(y - \\mu)^2}{2\\sigma^2}}.\n\\tag{40.1}\\]\n\n40.4.2 Distribuzione Normale Standardizzata\nLa normale standardizzata è un caso speciale con \\(\\mu = 0\\) e \\(\\sigma = 1\\). Qualsiasi variabile \\(Y \\sim \\mathcal{N}(\\mu, \\sigma)\\) può essere standardizzata tramite:\n\\[\nZ = \\frac{Y - \\mu}{\\sigma}.\n\\tag{40.2}\\]\nQuesta trasformazione preserva la forma della distribuzione ma riporta i valori in unità di deviazione standard (Z-score), permettendo confronti universali.\n\n40.4.2.1 Relazione tra Deviazione Standard e Distribuzione\nLa regola empirica 68-95-99.7 vale per tutte le distribuzioni normali, indipendentemente da \\(\\mu\\) e \\(\\sigma\\):\n\n\n68.3% dei dati cade entro \\(\\pm 1\\sigma\\) dalla media;\n\n\n95.4% entro \\(\\pm 2\\sigma\\);\n\n\n99.7% entro \\(\\pm 3\\sigma\\).\n\nPer intervalli specifici legati a test statistici:\n\n\n\\(\\pm 1.96\\sigma\\) copre il 95% dei dati (intervallo di confidenza al 95%);\n\n\\(\\pm 2.576\\sigma\\) copre il 99% (intervallo al 99%).\n\n40.4.3 Origini storiche e connessione alla binomiale\nAbraham de Moivre osservò che distribuzioni binomiali con \\(n\\) elevato approssimano una normale. Ad esempio:\n\ncon \\(n=10\\) e \\(p=0.9\\), la distribuzione è asimmetrica;\ncon \\(n=1000\\), la forma diventa simmetrica e campanulare.\n\n40.4.4 Simulazione di Passeggiate Casuali\nLa distribuzione normale emerge naturalmente come risultato della somma di un gran numero di effetti casuali indipendenti, un principio formalizzato dal Teorema del Limite Centrale. Questo la rende ideale per modellare:\n\n\nerrori di misurazione, dove piccole fluttuazioni casuali (strumentali, ambientali, umane) si combinano;\n\n\nfenomeni biologici multifattoriali come altezza, peso o QI, influenzati da decine di fattori genetici, ambientali e nutrizionali che interagiscono in modo additivo;\n\n\nprocessi sociali come i punteggi dei test, dove il risultato finale è il prodotto cumulativo di abilità innate, studio, stato emotivo e altro.\n\nSimulazione con passeggiate casuali\nPer visualizzare concretamente questo fenomeno, consideriamo una passeggiata casuale unidimensionale semplificata:\n\n\nImpostazione:\n\n1,000 partecipanti partono dalla posizione 0;\n\nogni partecipante compie 16 passi consecutivi;\n\nogni passo è determinato da un generatore casuale che assegna uno spostamento compreso tra -1 e +1 unità (simulando l’effetto di piccole perturbazioni indipendenti).\n\n\n\nDinamica:\nla posizione finale di ciascun partecipante è la somma algebrica degli spostamenti casuali. Nonostante ogni passo individuale segua una distribuzione uniforme, la posizione finale aggregata di tutti i partecipanti mostrerà una distribuzione a campana tipica della normale.\n\n\n# Parametri\nnumero_passi &lt;- 16\nripetizioni &lt;- 1000\n\n# Generazione di passeggiate casuali\nset.seed(123)\nx &lt;- matrix(0, nrow = numero_passi + 1, ncol = ripetizioni)\n\nfor (i in 1:ripetizioni) {\n  passi &lt;- runif(numero_passi, min = -1, max = 1)\n  x[-1, i] &lt;- cumsum(passi)\n}\n\n# Grafico delle passeggiate casuali\ndf &lt;- data.frame(\n  Passo = rep(0:numero_passi, times = ripetizioni), \n  Distanza = as.vector(x)\n)\n\nggplot(\n  df, \n  aes(\n    x = Passo, \n    y = Distanza, \n    group = rep(1:ripetizioni, each = numero_passi + 1))\n  ) +\n  geom_line(color = \"blue\", alpha = 0.05) +\n  labs(\n    title = \"Passeggiate Casuali\", \n    x = \"Numero di Passi\", y = \"Distanza dall'Origine\"\n  )\n\n\n\n\n\n\n\n\n# Codice di simulazione (esempio concettuale)  \nset.seed(123)  \nn_partecipanti &lt;- 1000  \nn_passi &lt;- 16  \n\n# Genera spostamenti casuali (-1 a +1)  \nspostamenti &lt;- matrix(runif(n_partecipanti * n_passi, min = -1, max = 1), ncol = n_passi)  \n\n# Calcola le posizioni finali  \nposizioni_finali &lt;- rowSums(spostamenti)  \n\n# Visualizzazione  \nggplot(data.frame(Posizione = posizioni_finali), aes(x = Posizione)) +  \n  geom_histogram(aes(y = after_stat(density)), bins = 30, fill = \"lightblue\", alpha = 0.7) +  \n  stat_function(fun = dnorm, args = list(mean = mean(posizioni_finali), sd = sd(posizioni_finali)), color = \"red\", linewidth = 1) +  \n  labs(title = \"Distribuzione delle posizioni finali\", x = \"Posizione\", y = \"Densità\")  \n\n\n\n\n\n\n\nRisultato atteso:\nl’istogramma delle posizioni finali aderirà alla curva rossa (normale teorica), dimostrando come la combinazione di piccole variazioni casuali produca una distribuzione gaussiana, anche partendo da passi non-normali. Questo esperimento illustra l’onnipresenza della normale in contesti reali governati da molteplici fattori indipendenti.\nPerché 16 passi?\nLa scelta di 16 passi non è arbitraria:\n\nun numero ridotto di passi (es. 3-5) produrrebbe una distribuzione ancora vicina all’uniforme;\ncon 16 passi, la simmetria e la curvatura tipica della gaussiana diventano chiaramente riconoscibili senza richiedere simulazioni massicce.\n\n40.4.5 Proprietà fondamentali\n\n\nMedia: \\(\\mathbb{E}(Y) = \\mu\\);\n\n\nVarianza: \\(\\mathbb{V}(Y) = \\sigma^2\\).\n\n40.4.6 Funzioni R per la Normale\n\n\n\n\n\n\n\nFunzione\nDescrizione\nEsempio\n\n\n\ndnorm()\nDensità a un punto \\(y\\)\n\ndnorm(115, mean=100, sd=15)\n\n\npnorm()\nProbabilità cumulativa \\(P(Y \\leq y)\\)\n\npnorm(115, mean=100, sd=15)\n\n\nqnorm()\nQuantile per una probabilità \\(p\\)\n\nqnorm(0.975, mean=100, sd=15)\n\n\nrnorm()\nGenera valori casuali\nrnorm(10, mean=100, sd=15)\n\n\n\n40.4.7 Visualizzazione delle aree critiche\nLe aree sotto la curva corrispondenti a \\(\\pm 1\\sigma\\), \\(\\pm 1.96\\sigma\\), e \\(\\pm 3\\sigma\\) possono essere visualizzate in R:\n\n# Esempio per ±1.96σ (95% di confidenza)  \nmu &lt;- 100  \nsigma &lt;- 15  \nx &lt;- seq(mu - 4*sigma, mu + 4*sigma, length.out=1000)  \ndf &lt;- data.frame(x=x, pdf=dnorm(x, mu, sigma))  \n\nggplot(df, aes(x=x, y=pdf)) +  \n  geom_line(color=\"blue\") +  \n  geom_area(data=subset(df, x &gt;= mu - 1.96*sigma & x &lt;= mu + 1.96*sigma),  \n            fill=\"gray\", alpha=0.5) +  \n  labs(title=\"95% dei dati entro ±1.96σ\", x=\"Valori\", y=\"Densità\")  \n\n\n\n\n\n\n\nIn sintesi, la distribuzione normale standardizzata permette di standardizzare qualsiasi fenomeno Gaussiano, rendendo confrontabili dati eterogenei. La relazione tra deviazioni standard e aree sottese è universale: indipendentemente dalla media e varianza originale, il 68-95-99.7% dei dati cadrà sempre entro 1-2-3σ.\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nUna psicologa vuole studiare i livelli di ansia tra gli studenti universitari durante la settimana degli esami. Dalle ricerche precedenti si sa che nella popolazione universitaria:\n\nil punteggio medio di ansia è di 50 punti su una scala da 0 a 100;\nla deviazione standard dei punteggi di ansia è 10 punti.\n\nLa psicologa decide di estrarre un campione casuale di 25 studenti.\nVogliamo usare la distribuzione campionaria della media per rispondere a due domande:\n\nQual è la probabilità di ottenere una media campionaria maggiore di 54 punti?\nQuale media campionaria rappresenta il 95° percentile della distribuzione campionaria?\n\n📘 Concetti chiave.\nLa distribuzione campionaria della media ha:\n\nla stessa media della popolazione (\\(\\mu\\)),\nuna deviazione standard più piccola, detta errore standard della media (SE):\n\n\\[\nSE = \\frac{\\sigma}{\\sqrt{n}} = \\frac{10}{\\sqrt{25}} = 2 .\n\\]\nUseremo due funzioni importanti in R:\n\n\ndnorm(x, mean, sd): calcola la densità della normale in un punto \\(x\\).\n\nqnorm(p, mean, sd): calcola il valore di \\(x\\) corrispondente a una certa probabilità cumulativa \\(p\\).\n\n✅ Codice base.\n\n# Parametri della popolazione e del campione\nmu &lt;- 50       # media della popolazione\nsigma &lt;- 10    # deviazione standard\nn &lt;- 25        # dimensione campione\n\n# Errore standard della media\nSE &lt;- sigma / sqrt(n)\nSE\n#&gt; [1] 2\n\n🔍 Domanda 1: Probabilità di ottenere una media &gt; 54.\n\n# Probabilità che la media campionaria sia maggiore di 54\np_oltre_54 &lt;- pnorm(54, mean = mu, sd = SE, lower.tail = FALSE)\np_oltre_54\n#&gt; [1] 0.02275\n\nLa probabilità è molto bassa. Questo vuol dire che, se la vera media della popolazione fosse 50, ottenere una media campionaria superiore a 54 sarebbe raro.\n🔍 Domanda 2: Media al 95° percentile.\n\n# Calcolo del valore soglia al 95° percentile\nq_95 &lt;- qnorm(0.95, mean = mu, sd = SE)\nq_95\n#&gt; [1] 53.29\n\nAll’interno della distribuzione campionaria, solo il 5% dei campioni ha una media superiore a questo valore.\n📊 Grafico 1: Probabilità di media &gt; 54\n\n# Dati per la distribuzione normale\nx_vals &lt;- seq(44, 56, length.out = 300)\ndens_vals &lt;- dnorm(x_vals, mean = mu, sd = SE)\ndf &lt;- data.frame(x = x_vals, y = dens_vals)\n\n# Grafico\nggplot(df, aes(x, y)) +\n  geom_line(color = \"black\") +\n  geom_area(data = subset(df, x &gt;= 54), aes(x, y), fill = \"red\", alpha = 0.4) +\n  geom_vline(xintercept = 54, color = \"red\", linetype = \"dashed\") +\n  labs(\n    title = \"Distribuzione campionaria della media (n = 25)\",\n    subtitle = \"Area rossa = P(media &gt; 54)\",\n    x = \"Media campionaria\",\n    y = \"Densità\"\n  ) \n\n\n\n\n\n\n\n📊 Grafico 2: Valore al 95° percentile\n\n# Grafico con il 95° percentile evidenziato\nggplot(df, aes(x, y)) +\n  geom_line(color = \"black\") +\n  geom_area(data = subset(df, x &lt;= q_95), aes(x, y), fill = \"blue\", alpha = 0.4) +\n  geom_vline(xintercept = q_95, color = \"blue\", linetype = \"dashed\") +\n  labs(\n    title = \"Distribuzione campionaria della media (n = 25)\",\n    subtitle = \"Area blu = 95% dei campioni (valore critico ≈ 53.29)\",\n    x = \"Media campionaria\",\n    y = \"Densità\"\n  ) \n\n\n\n\n\n\n\nDomande di approfondimento.\n\nPerché l’errore standard della media è più piccolo della deviazione standard della popolazione?\nSe la dimensione del campione aumentasse a 100, come cambierebbe l’errore standard?\nChe cosa rappresenta pnorm(54, ...) nel nostro contesto?\nIn quali casi, in psicologia, potresti voler calcolare il 95° percentile di una distribuzione campionaria?\n\nSimulazione Monte Carlo.\nSimuliamo 10.000 campioni casuali, ciascuno di 25 studenti, estratti da una popolazione normale con media = 50 e deviazione standard = 10. Per ogni campione calcoliamo la media. Alla fine, visualizziamo la distribuzione di queste medie.\n\nset.seed(123)  # per rendere la simulazione replicabile\n\n# Parametri\nmu &lt;- 50\nsigma &lt;- 10\nn &lt;- 25\nn_sim &lt;- 10000  # numero di campioni\n\n# Simulazione: 10.000 medie campionarie\ncampioni &lt;- replicate(n_sim, mean(rnorm(n, mean = mu, sd = sigma)))\n\n# Visualizza le prime 5 medie\nhead(campioni)\n#&gt; [1] 49.67 51.02 50.10 52.83 47.23 47.69\n\n📊 Istogramma delle medie campionarie.\n\n\ndf_sim &lt;- data.frame(media_campionaria = campioni)\n\nggplot(df_sim, aes(x = media_campionaria)) +\n  geom_histogram(aes(y = ..density..), bins = 40, fill = \"lightblue\", color = \"black\") +\n  stat_function(fun = dnorm, args = list(mean = mu, sd = sigma / sqrt(n)),\n                color = \"red\", size = 1) +\n  labs(\n    title = \"Distribuzione delle medie campionarie (Simulazione Monte Carlo)\",\n    subtitle = \"Istogramma di 10.000 medie di campioni di 25 studenti\",\n    x = \"Media campionaria\",\n    y = \"Densità\"\n  ) \n\n\n\n\n\n\n\nCosa si osserva?\n\nLe medie non sono tutte uguali, ma si distribuiscono intorno alla media vera (50).\nLa forma della distribuzione delle medie è normale, anche se i dati originali non devono necessariamente esserlo (grazie al Teorema del Limite Centrale).\nLa deviazione standard della distribuzione simulata è vicina all’errore standard teorico:\n\n\n# Confronto tra errore standard teorico e osservato\nSE_teorico &lt;- sigma / sqrt(n)\nSE_osservato &lt;- sd(campioni)\n\nc(SE_teorico = SE_teorico, SE_osservato = SE_osservato)\n#&gt;   SE_teorico SE_osservato \n#&gt;        2.000        1.966\n\nDomande di approfondimento.\n\nPerché la forma dell’istogramma è simile a una curva normale?\nCosa succederebbe alla larghezza della distribuzione se aumentassimo la dimensione del campione?\nSe la media osservata in un esperimento reale fosse fuori dalla zona centrale, come potremmo interpretarla?\n\n\n\n\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nConsideriamo un esercizio in cui si utilizza la distribuzione normale e si consultano le tavole della normale standard (z) per risolvere il problema dopo la standardizzazione.\nIn uno studio su un campione di 600 studenti universitari, i punteggi ottenuti a un test di ansia da esame seguono una distribuzione normale con media \\(\\mu = 50\\) e deviazione standard \\(\\sigma = 10\\).\n\nQual è la probabilità che uno studente scelto a caso ottenga un punteggio inferiore a 65?\nQual è la percentuale di studenti che ottengono un punteggio compreso tra 45 e 60?\nQual è il punteggio minimo che uno studente deve ottenere per rientrare nel 10% superiore della distribuzione?\n\n1. Probabilità che \\(X &lt; 65\\).\nStandardizziamo:\n\\[\nZ = \\frac{X - \\mu}{\\sigma} = \\frac{65 - 50}{10} = \\frac{15}{10} = 1.5 .\n\\]\nCerchiamo \\(P(Z &lt; 1.5)\\) nella tavola della normale standard:\n\\[\nP(Z &lt; 1.5) \\approx 0.9332 .\n\\]\nRisposta: La probabilità che uno studente ottenga meno di 65 è circa 93.32%.\n2. Probabilità che \\(45 &lt; X &lt; 60\\).\nCalcoliamo gli z-score:\n\\[\nZ_1 = \\frac{45 - 50}{10} = -0.5 \\quad ; \\quad Z_2 = \\frac{60 - 50}{10} = 1.0 .\n\\]\nCerchiamo nelle tavole:\n\n\\(P(Z &lt; 1.0) \\approx 0.8413\\)\n\\(P(Z &lt; -0.5) \\approx 0.3085\\)\n\nQuindi:\n\\[\nP(45 &lt; X &lt; 60) = P(Z &lt; 1.0) - P(Z &lt; -0.5) = 0.8413 - 0.3085 = 0.5328\n\\]\nRisposta: Circa il 53.28% degli studenti ha un punteggio tra 45 e 60.\n3. Punteggio minimo per rientrare nel 10% superiore.\nIl 10% superiore corrisponde a:\n\\[\nP(Z &gt; z) = 0.10 \\Rightarrow P(Z &lt; z) = 0.90 .\n\\]\nDalla tavola:\\(P(Z &lt; 1.28) \\approx 0.8997\\),\\(P(Z &lt; 1.29) \\approx 0.9015\\)\nPrendiamo \\(z = 1.28\\)\nOra risolviamo per \\(X\\):\n\\[\nX = z \\cdot \\sigma + \\mu = 1.28 \\cdot 10 + 50 = 62.8\n\\]\nRisposta: Il punteggio minimo per rientrare nel 10% superiore è circa 62.8.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html#distribuzione-chi-quadrato",
    "href": "chapters/probability/13_cont_rv_distr.html#distribuzione-chi-quadrato",
    "title": "40  Distribuzioni di v.c. continue",
    "section": "\n40.5 Distribuzione Chi-Quadrato",
    "text": "40.5 Distribuzione Chi-Quadrato\nLa distribuzione \\(\\chi^2\\) deriva dalla distribuzione normale e descrive la somma dei quadrati di \\(k\\) variabili casuali indipendenti e identicamente distribuite (i.i.d.) che seguono la distribuzione normale standard \\(\\mathcal{N}(0, 1)\\). Una variabile casuale \\(\\chi^2_{~k}\\) con \\(k\\) gradi di libertà è definita come:\n\\[\nZ_1^2 + Z_2^2 + \\dots + Z_k^2,\n\\tag{40.3}\\]\ndove \\(Z_1, Z_2, \\dots, Z_k \\sim \\mathcal{N}(0, 1)\\). Il parametro \\(k\\), detto gradi di libertà (\\(\\nu\\)), determina la forma della distribuzione.\n\n40.5.1 Funzione di densità\nLa densità di probabilità della distribuzione \\(\\chi^2_{~\\nu}\\) è data da:\n\\[\nf(x) = C_{\\nu} x^{\\nu/2 - 1} \\exp(-x/2), \\quad \\text{per } x &gt; 0,\n\\tag{40.4}\\]\ndove \\(C_{\\nu}\\) è una costante di normalizzazione.\n\n40.5.2 Simulazione della Distribuzione Chi-Quadrato\nUtilizziamo la definizione per simulare la distribuzione \\(\\chi^2\\) con 3 gradi di libertà.\n\n# Impostare il seed per la riproducibilità\nset.seed(1234)\n\n# Generare 1000 valori casuali per 3 variabili gaussiane standard\nn &lt;- 1000\nvar1 &lt;- rnorm(n, mean = 0, sd = 1)\nvar2 &lt;- rnorm(n, mean = 0, sd = 1)\nvar3 &lt;- rnorm(n, mean = 0, sd = 1)\n\n# Calcolare la somma dei quadrati\nchi_sq_values &lt;- var1^2 + var2^2 + var3^2\n\n# Creare un dataframe per il grafico\ndata &lt;- data.frame(chi_sq_values = chi_sq_values)\n\n# Istogramma e densità teorica\nggplot(data, aes(x = chi_sq_values)) +\n  geom_histogram(\n    aes(y = after_stat(density)), \n    bins = 30, fill = \"lightblue\", color = \"black\", alpha = 0.7\n    ) +\n  stat_function(fun = dchisq, args = list(df = 3), color = \"red\", size = 1) +\n  labs(\n    title = \"Distribuzione Chi-Quadrato (df = 3)\",\n    x = \"Valore\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\n\nL’istogramma rappresenta i valori empirici simulati;\nla curva rossa rappresenta la densità teorica della distribuzione \\(\\chi^2_{~3}\\).\n\n40.5.3 Media e Varianza Empiriche\nCalcoliamo la media e la varianza dei valori simulati:\n\n# Media empirica\nmean(chi_sq_values)\n#&gt; [1] 2.981\n\n# Varianza empirica\nvar(chi_sq_values)\n#&gt; [1] 5.968\n\nQuesti valori possono essere confrontati con le proprietà teoriche della distribuzione \\(\\chi^2\\):\n\n\nmedia: \\(\\nu = 3\\);\n\nvarianza: \\(2\\nu = 6\\).\n\n40.5.4 Grafico per Diversi Gradi di Libertà\nConfrontiamo le distribuzioni \\(\\chi^2\\) per diversi valori di \\(\\nu\\).\n\n# Intervallo di x\nx &lt;- seq(0, 40, by = 0.1)\n\n# Gradi di libertà\nnus &lt;- c(2, 4, 8, 16)\n\n# Creare un dataframe\ndata &lt;- do.call(rbind, lapply(nus, function(nu) {\n  data.frame(x = x, f_x = dchisq(x, df = nu), nu = as.factor(nu))\n}))\n\n# Grafico\nggplot(data, aes(x = x, y = f_x, color = nu)) +\n  geom_line(size = 1) +\n  labs(\n    title = \"Distribuzioni Chi-Quadrato per Diversi Valori di \\u03bd\",\n    x = \"x\",\n    y = \"f(x)\",\n    color = expression(nu)\n  ) \n\n\n\n\n\n\n\n\n40.5.5 Proprietà della Distribuzione Chi-Quadrato\n\n\nAsimmetria: La distribuzione \\(\\chi^2_{\\nu}\\) è asimmetrica, ma diventa più simmetrica al crescere di \\(\\nu\\).\n\nMedia: \\(\\mathbb{E}[\\chi^2_{\\nu}] = \\nu\\).\n\nVarianza: \\(\\mathbb{V}[\\chi^2_{\\nu}] = 2\\nu\\).\n\nConvergenza: Per \\(\\nu \\to \\infty\\), \\(\\chi^2_{\\nu} \\to \\mathcal{N}(\\nu, 2\\nu)\\).\n\nSomma: La somma di variabili \\(\\chi^2\\) indipendenti con gradi di libertà \\(\\nu_1, \\nu_2, \\dots, \\nu_k\\) segue una distribuzione \\(\\chi^2\\) con \\(\\nu = \\sum_{i=1}^k \\nu_i\\).\n\n40.5.6 Applicazioni\nLa distribuzione \\(\\chi^2\\) è utilizzata in molteplici ambiti statistici, tra cui:\n\n\ntest di indipendenza: per verificare se due variabili categoriche sono indipendenti;\n\ntest di adattamento: per confrontare una distribuzione empirica con una teorica.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html#distribuzione-t-di-student",
    "href": "chapters/probability/13_cont_rv_distr.html#distribuzione-t-di-student",
    "title": "40  Distribuzioni di v.c. continue",
    "section": "\n40.6 Distribuzione \\(t\\) di Student",
    "text": "40.6 Distribuzione \\(t\\) di Student\nLa distribuzione \\(t\\) di Student è una delle distribuzioni fondamentali della statistica inferenziale. Deriva dalle distribuzioni Normale e Chi-quadrato ed è particolarmente utile per analizzare campioni di piccole dimensioni o situazioni in cui la varianza della popolazione è sconosciuta.\n\n40.6.1 Definizione Formale\nSe:\n\n\n\\(Z \\sim \\mathcal{N}(0, 1)\\) (distribuzione Normale standard),\n\n\\(W \\sim \\chi^2_{\\nu}\\) (distribuzione Chi-quadrato con \\(\\nu\\) gradi di libertà),\n\ne \\(Z\\) e \\(W\\) sono indipendenti, allora la variabile casuale\n\\[\nT = \\frac{Z}{\\sqrt{\\frac{W}{\\nu}}}\n\\tag{40.5}\\]\nsegue una distribuzione \\(t\\) di Student con \\(\\nu\\) gradi di libertà. Si indica come \\(T \\sim t_{\\nu}\\).\n\n40.6.2 Proprietà della Distribuzione \\(t\\) di Student\n\n\nForma della distribuzione:\n\nla distribuzione \\(t\\) è simmetrica rispetto a zero, come la Normale standard (\\(\\mathcal{N}(0, 1)\\));\npresenta code più pesanti rispetto alla Normale, riflettendo una maggiore probabilità di osservare valori estremi.\n\n\n\nCode pesanti e gradi di libertà:\n\nla pesantezza delle code diminuisce con l’aumentare dei gradi di libertà (\\(\\nu\\));\nper \\(\\nu \\to \\infty\\), la distribuzione \\(t\\) converge alla distribuzione Normale standard.\n\n\n\nMedia e varianza:\n\nla media è \\(0\\) per \\(\\nu &gt; 1\\);\n\nla varianza è:\n\\[\n\\text{Var}(T) = \\frac{\\nu}{\\nu - 2}, \\quad \\text{per } \\nu &gt; 2.\n\\]\nPer \\(\\nu \\leq 2\\), la varianza non è definita.\n\n\n\n\nApplicazioni principali:\n\n\ntest t di Student: Confronto delle medie di due gruppi o test per una singola media;\n\nintervalli di confidenza: Stima dell’intervallo per la media quando la varianza è sconosciuta.\n\n\n\n40.6.3 Differenze tra la Distribuzione \\(t\\) e la Normale\n\n\n\n\n\n\n\nCaratteristica\nDistribuzione Normale\nDistribuzione \\(t\\) di Student\n\n\n\nForma\nSimmetrica, a campana\nSimmetrica, a campana\n\n\nCode\nSottili\nPesanti\n\n\nDipendenza dai gradi di libertà\nNo\nSì\n\n\nConvergenza\nNon varia\nCon \\(\\nu \\to \\infty\\), converge alla Normale\n\n\n\n40.6.4 Visualizzazione della Distribuzione \\(t\\)\n\nConfrontiamo graficamente la distribuzione \\(t\\) con diversi gradi di libertà e la distribuzione Normale standard:\n\n# Creazione dei dati\nx &lt;- seq(-4, 4, length.out = 1000)\ndf &lt;- c(1, 2, 5, 10)  # Gradi di libertà\n\n# Dataframe con curve di densità\ndata &lt;- data.frame(\n  x = rep(x, length(df) + 1),\n  density = c(\n    dnorm(x),\n    dt(x, df[1]),\n    dt(x, df[2]),\n    dt(x, df[3]),\n    dt(x, df[4])\n  ),\n  distribution = rep(c(\"Normale\", paste(\"t (df =\", df, \")\")), each = length(x))\n)\n\n# Plot\nggplot(data, aes(x = x, y = density, color = distribution)) +\n  geom_line(size = 1) +\n  labs(\n    title = \"Distribuzione Normale e distribuzioni $t$ di Student\",\n    x = \"Valore\",\n    y = \"Densità\",\n    color = \"Distribuzione\"\n  ) \n\n\n\n\n\n\n\n\n40.6.5 Simulazione della Distribuzione \\(t\\)\n\nSimuliamo una distribuzione \\(t\\) con 10 gradi di libertà e confrontiamola con la densità teorica.\n\n# Impostare il seed per la riproducibilità\nset.seed(123)\n\n# Simulare 1000 valori da una distribuzione t\nn &lt;- 1000\ndf &lt;- 10  # Gradi di libertà\nt_values &lt;- rt(n, df = df)\n\n# Creare un dataframe per il grafico\ndata &lt;- data.frame(t_values = t_values)\n\n# Istogramma con densità teorica\nggplot(data, aes(x = t_values)) +\n  geom_histogram(\n    aes(y = after_stat(density)), \n    bins = 30, fill = \"lightblue\", color = \"black\", alpha = 0.7\n  ) +\n  stat_function(fun = dt, args = list(df = df), color = \"red\", size = 1) +\n  labs(\n    title = paste(\"Distribuzione $t$ di Student (df =\", df, \")\"),\n    x = \"Valore\",\n    y = \"Densità\"\n  ) \n\n\n\n\n\n\n\n\n40.6.6 Proprietà Teoriche della Distribuzione \\(t\\)\n\n\nMedia: \\[\n\\mathbb{E}[T] = 0, \\quad \\text{per } \\nu &gt; 1.\n\\]\nVarianza: \\[\n\\mathbb{V}[T] = \\frac{\\nu}{\\nu - 2}, \\quad \\text{per } \\nu &gt; 2.\n\\]\n\nSimmetria:\n\nla distribuzione è simmetrica rispetto a zero, come la Normale.\n\n\n\nCode:\n\nle code sono più pesanti rispetto alla Normale, riflettendo una maggiore incertezza per piccoli campioni.\n\n\n\nIn conclusione, la distribuzione \\(t\\) di Student è uno strumento versatile nell’inferenza statistica, trovando applicazione in contesti sia frequentisti che bayesiani. È particolarmente utile in situazioni in cui la conoscenza della varianza è limitata o i campioni sono di dimensioni ridotte. Grazie alla sua forma simmetrica e alle code più pesanti rispetto alla distribuzione Normale, la distribuzione \\(t\\) può modellare meglio l’incertezza, includendo una maggiore probabilità per valori estremi.\nNel contesto bayesiano, la distribuzione \\(t\\) viene utilizzata come:\n\n\nprior informativo robusto, per modellare parametri con valori plausibili lontani dalla media ma con una penalizzazione graduale per valori estremi.\n\ndistribuzione predittiva per sintetizzare l’incertezza derivante da campioni piccoli o con variabilità elevata.\n\nIn entrambi i paradigmi, la distribuzione \\(t\\) rappresenta una scelta robusta, capace di riflettere in modo flessibile la natura dei dati. Inoltre, per valori elevati dei gradi di libertà, la distribuzione \\(t\\) converge alla distribuzione Normale, un caso limite che ne estende ulteriormente l’utilità in vari contesti analitici.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html#funzione-beta-di-eulero",
    "href": "chapters/probability/13_cont_rv_distr.html#funzione-beta-di-eulero",
    "title": "40  Distribuzioni di v.c. continue",
    "section": "\n40.7 Funzione Beta di Eulero",
    "text": "40.7 Funzione Beta di Eulero\nLa funzione Beta di Eulero è una funzione matematica, non una densità di probabilità, ma è strettamente collegata alla distribuzione Beta, poiché appare nella sua definizione. Indicata comunemente con il simbolo \\(\\mathcal{B}(\\alpha, \\beta)\\), la funzione Beta può essere espressa in vari modi. Per i nostri scopi, utilizziamo la seguente definizione:\n\\[\n\\mathcal{B}(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}\\,,\n\\tag{40.6}\\]\ndove \\(\\Gamma(x)\\) rappresenta la funzione Gamma, una generalizzazione del fattoriale definita per numeri reali positivi. Quando \\(x\\) è un numero intero, la funzione Gamma si riduce al fattoriale traslato:\n\\[\n\\Gamma(x) = (x-1)!.\n\\]\n\nEsempio 40.1 Supponiamo di voler calcolare \\(\\mathcal{B}(3, 9)\\). Utilizzando la definizione, abbiamo:\n\\[\n\\mathcal{B}(3, 9) = \\frac{\\Gamma(3) \\cdot \\Gamma(9)}{\\Gamma(3 + 9)}.\n\\]\nIn R, possiamo calcolarla in tre modi diversi.\n\nUtilizzando la definizione con la funzione gamma():\n\n\nalpha &lt;- 3\nbeta &lt;- 9\n\nbeta_function &lt;- gamma(alpha) * gamma(beta) / gamma(alpha + beta)\nbeta_function\n#&gt; [1] 0.00202\n\n\nUtilizzando direttamente la funzione beta() di R:\n\n\nbeta(alpha, beta)\n#&gt; [1] 0.00202\n\n\nCalcolo manuale con fattoriali:\n\n\n(factorial(alpha - 1) * factorial(beta - 1)) / factorial(alpha + beta - 1)\n#&gt; [1] 0.00202\n\nTutti e tre i metodi restituiscono lo stesso risultato, confermando la correttezza della definizione.\n\nLa funzione Beta è utilizzata nella definizione della densità di probabilità Beta. Essa serve a normalizzare la densità, garantendo che l’area sotto la curva sia pari a \\(1\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html#distribuzione-beta",
    "href": "chapters/probability/13_cont_rv_distr.html#distribuzione-beta",
    "title": "40  Distribuzioni di v.c. continue",
    "section": "\n40.8 Distribuzione Beta",
    "text": "40.8 Distribuzione Beta\nLa distribuzione Beta, indicata come \\(\\mathcal{Beta}(\\alpha, \\beta)\\), è una distribuzione di probabilità continua definita sull’intervallo \\((0, 1)\\). È particolarmente utile per modellare proporzioni, probabilità, o in generale qualsiasi fenomeno che assume valori compresi tra 0 e 1.\nQuesta distribuzione è molto flessibile: a seconda dei valori dei parametri \\(\\alpha\\) e \\(\\beta\\), può assumere forme simmetriche, asimmetriche, concave, convesse, ecc. È frequentemente utilizzata come distribuzione a priori nei modelli bayesiani per parametri che rappresentano probabilità.\n\n40.8.1 Definizione\n\nDefinizione 40.1 Sia \\(\\theta\\) una variabile casuale continua. Se \\(\\theta\\) segue una distribuzione Beta con parametri \\(\\alpha &gt; 0\\) e \\(\\beta &gt; 0\\), scriviamo:\n\\[\n\\theta \\sim \\mathcal{Beta}(\\alpha, \\beta),\n\\]\ne la sua funzione di densità di probabilità (pdf) è data da:\n\\[\n\\mathcal{Beta}(\\theta \\mid \\alpha, \\beta) = \\frac{1}{\\mathcal{B}(\\alpha, \\beta)} \\, \\theta^{\\alpha - 1} (1 - \\theta)^{\\beta - 1}, \\quad \\text{per } \\theta \\in (0, 1),\n\\tag{40.7}\\]\ndove \\(\\mathcal{B}(\\alpha, \\beta)\\) è la funzione Beta (o funzione beta di Eulero).\n\n\n40.8.2 Rappresentazione alternativa\nUn’espressione equivalente della densità, che mette in evidenza il legame con la funzione Gamma, è:\n\\[\n\\mathcal{Beta}(\\theta \\mid \\alpha, \\beta) = \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha) \\, \\Gamma(\\beta)} \\, \\theta^{\\alpha - 1} (1 - \\theta)^{\\beta - 1}, \\quad \\text{per } \\theta \\in (0, 1),\n\\tag{40.8}\\]\ndove \\(\\Gamma(\\cdot)\\) è la funzione Gamma, che generalizza il fattoriale: \\(\\Gamma(n) = (n - 1)!\\) per ogni intero positivo \\(n\\).\n\n40.8.3 Ruolo dei Parametri \\(\\alpha\\) e \\(\\beta\\)\n\nI parametri \\(\\alpha\\) e \\(\\beta\\) determinano la forma della distribuzione:\n\n\n\\(\\alpha &gt; 1\\): favorisce valori di \\(\\theta\\) vicini a 1.\n\n\\(\\beta &gt; 1\\): favorisce valori di \\(\\theta\\) vicini a 0.\n\n\\(\\alpha = \\beta = 1\\): corrisponde alla distribuzione uniforme sull’intervallo \\([0, 1]\\).\n\n\\(\\alpha, \\beta &lt; 1\\): la distribuzione è bimodale, concentrandosi agli estremi (vicino a 0 e 1).\n\n40.8.4 Proprietà della Distribuzione Beta\n\nValore atteso: \\[\n\\mathbb{E}(\\theta) = \\frac{\\alpha}{\\alpha + \\beta}.\n\\]\nVarianza: \\[\n\\mathbb{V}(\\theta) = \\frac{\\alpha \\beta}{(\\alpha + \\beta)^2 (\\alpha + \\beta + 1)}.\n\\]\nModa (se \\(\\alpha, \\beta &gt; 1\\)): \\[\n\\text{Moda}(\\theta) = \\frac{\\alpha - 1}{\\alpha + \\beta - 2}.\n\\]\n\nQueste proprietà evidenziano come \\(\\alpha\\) e \\(\\beta\\) possano essere interpretati come “successi” e “fallimenti” in una serie di prove, fornendo un collegamento intuitivo con la distribuzione binomiale.\n\n40.8.5 Relazione con la Distribuzione Binomiale\nLa distribuzione Beta può essere interpretata come una generalizzazione continua della distribuzione binomiale. Mentre la distribuzione binomiale descrive la probabilità di osservare un certo numero di successi in un numero fissato di prove (\\(n\\)), la distribuzione Beta descrive l’incertezza sulla probabilità di successo \\(\\theta\\) stessa, trattandola come una variabile casuale.\n\n40.8.5.1 Contesto bayesiano\nIn un contesto di inferenza bayesiana, la distribuzione Beta viene comunemente utilizzata come distribuzione a priori coniugata per il modello binomiale. Ciò significa che, se si assume una distribuzione Beta come prior per \\(\\theta\\), anche la distribuzione a posteriori (dopo aver osservato i dati) sarà una Beta, ma con parametri aggiornati.\nSupponiamo:\n\nche \\(\\theta\\) sia la probabilità di successo in un compito con esiti binari (es. risposta corretta o errata),\ndi assumere una distribuzione a priori:\\[\n\\theta \\sim \\mathcal{Beta}(\\alpha, \\beta),\n\\]\n\ne di osservare \\(y\\) successi su \\(n\\) prove, con modello di verosimiglianza: \\[\ny \\sim \\mathcal{Binom}(n, \\theta).\n\\]\n\n\nAllora, per il teorema di Bayes, la distribuzione a posteriori di \\(\\theta\\) sarà:\n\\[\n\\theta \\mid \\text{dati} \\sim \\mathcal{Beta}(\\alpha + y, \\beta + n - y).\n\\]\n\n40.8.5.2 Vantaggi della coniugatezza\nQuesto aggiornamento è particolarmente comodo perché:\n\nsi ottiene in forma chiusa (senza dover ricorrere a metodi numerici),\ni parametri \\(\\alpha\\) e \\(\\beta\\) possono essere interpretati come conteggi fittizi di successi e insuccessi prima dell’osservazione dei dati,\nl’informazione a priori e quella empirica si combinano sommando i rispettivi “conteggi.”\n\nQuesta proprietà rende la distribuzione Beta una scelta naturale nei modelli bayesiani con dati binomiali, come in contesti psicologici in cui si vogliono modellare incertezze sulla probabilità di una risposta corretta, sull’esito di una scelta, o sul successo di un comportamento.\n\n40.8.6 Visualizzazione della Distribuzione Beta\nDi seguito mostriamo come la forma della distribuzione Beta varia al variare dei parametri \\(\\alpha\\) e \\(\\beta\\):\n\n# Parametri\nx &lt;- seq(0, 1, length.out = 200)\nalphas &lt;- c(0.5, 5.0, 1.0, 2.0, 2.0)\nbetas &lt;- c(0.5, 1.0, 3.0, 2.0, 5.0)\n\n# Creare un dataframe\ndf &lt;- do.call(rbind, lapply(1:length(alphas), function(i) {\n  data.frame(\n    x = x,\n    density = dbeta(x, alphas[i], betas[i]),\n    label = paste0(\"α = \", alphas[i], \", β = \", betas[i])\n  )\n}))\n\n# Plot\nggplot(df, aes(x = x, y = density, color = label)) +\n  geom_line(size = 1) +\n  labs(\n    x = \"x\",\n    y = \"f(x)\",\n    title = \"Distribuzioni Beta\"\n  ) +\n  theme(legend.title = element_blank())\n\n\n\n\n\n\n\n\n40.8.7 Costante di Normalizzazione\nLa costante di normalizzazione della distribuzione Beta è il reciproco della funzione Beta di Eulero, \\(B(\\alpha, \\beta)\\). Questa garantisce che:\n\\[\n\\int_0^1 \\mathcal{Beta}(\\theta \\mid \\alpha, \\beta) \\, d\\theta = 1.\n\\]\n\nEsempio 40.2 Di seguito viene proposto un esempio in R per calcolare l’area sottesa alla distribuzione Beta non normalizzata e, con gli stessi parametri, ottenere il valore della funzione Beta di Eulero. L’obiettivo è mostrare come la costante di normalizzazione, pari al reciproco di \\(B(\\alpha, \\beta)\\), garantisca che l’integrale della densità normalizzata su \\([0,1]\\) sia pari a 1.\nSupponiamo di voler utilizzare i parametri:\n\n\\(\\alpha = 2\\)\n\\(\\beta = 5\\)\n\n\n# Parametri della distribuzione Beta\nalpha &lt;- 2\nbeta  &lt;- 5\n\n# Definiamo la funzione non normalizzata della distribuzione Beta\nunnormalized_beta &lt;- function(theta) {\n  theta^(alpha - 1) * (1 - theta)^(beta - 1)\n}\n\n# Calcoliamo l'integrale della funzione non normalizzata su [0, 1]\nintegrale &lt;- integrate(unnormalized_beta, lower = 0, upper = 1)$value\ncat(\"Integrale della funzione non normalizzata:\", integrale, \"\\n\")\n#&gt; Integrale della funzione non normalizzata: 0.03333\n\n# Calcoliamo il valore della funzione Beta usando la funzione beta() di R\nvalore_beta &lt;- beta(alpha, beta)\ncat(\"Valore della funzione Beta B(alpha, beta):\", valore_beta, \"\\n\")\n#&gt; Valore della funzione Beta B(alpha, beta): 0.03333\n\nSpiegazione del Codice\n\nDefinizione dei Parametri e della Funzione\nImpostiamo \\(\\alpha = 2\\) e \\(\\beta = 5\\) e definiamo la funzione non normalizzata: \\[\nf(\\theta) = \\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}.\n\\]\nCalcolo dell’Integrale\nUtilizzando la funzione integrate(), calcoliamo l’area sottesa a \\(f(\\theta)\\) nell’intervallo \\([0,1]\\), che corrisponde a \\(\\mathcal{B}(\\alpha, \\beta)\\).\nVerifica con la Funzione Beta\nLa funzione beta(alpha, beta) di R restituisce direttamente il valore di \\(\\mathcal{B}(\\alpha, \\beta)\\). La stampa dei due valori conferma che l’integrale calcolato e il valore della funzione Beta coincidono.\nCostante di Normalizzazione\nIl reciproco di \\(\\mathcal{B}(\\alpha, \\beta)\\) è calcolato e utilizzato per definire la densità normalizzata della distribuzione Beta. L’integrazione della densità normalizzata su \\([0,1]\\) restituisce 1, confermando la corretta normalizzazione.\n\nQuesto esempio in R mostra in modo pratico come la costante di normalizzazione derivi dalla funzione Beta di Eulero e come essa venga applicata per ottenere una densità di probabilità correttamente normalizzata.\n\nIn conclusione, la distribuzione Beta si rivela particolarmente utile per modellare variabili continue comprese nell’intervallo [0, 1]. Grazie alla sua parametrizzazione tramite \\(\\alpha\\) e \\(\\beta\\), consente di adattare la forma della densità in modo specifico alle caratteristiche osservate dei dati, facilitando la stima di proporzioni. Inoltre, essendo il coniugato della distribuzione binomiale, permette un aggiornamento analitico nei modelli bayesiani, semplificando l’inferenza quando si raccolgono dati incrementali, come nella stima della probabilità di successo in esperimenti o studi psicologici.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html#distribuzione-di-cauchy",
    "href": "chapters/probability/13_cont_rv_distr.html#distribuzione-di-cauchy",
    "title": "40  Distribuzioni di v.c. continue",
    "section": "\n40.9 Distribuzione di Cauchy",
    "text": "40.9 Distribuzione di Cauchy\nLa distribuzione di Cauchy è un caso speciale della distribuzione \\(t\\) di Student con un solo grado di libertà (\\(t_1\\)). Questa distribuzione è caratterizzata da code molto pesanti e da una media e varianza non definite, rendendola particolarmente utile in contesti dove valori estremi possono avere un’influenza importante.\n\nDefinizione 40.2 La funzione di densità di probabilità della distribuzione di Cauchy è definita da due parametri:\n\n\n\\(\\alpha\\): posizione (location), che determina il centro della distribuzione.\n\n\\(\\beta &gt; 0\\): scala (scale), che controlla la larghezza della distribuzione.\n\nLa densità è data da:\n\\[\nf(x \\mid \\alpha, \\beta) = \\frac{1}{\\pi \\beta \\left[1 + \\left( \\frac{x - \\alpha}{\\beta} \\right)^2\\right]} ,\n\\]\ndove:\n\n\n\\(x \\in \\mathbb{R}\\),\n\n\\(\\alpha \\in \\mathbb{R}\\),\n\n\\(\\beta &gt; 0\\).\n\nQuesta funzione descrive una distribuzione simmetrica attorno a \\(\\alpha\\), con code più pesanti rispetto alla distribuzione Normale.\n\n\n40.9.1 Proprietà della Distribuzione di Cauchy\n\n\nSimmetria: La distribuzione è simmetrica rispetto a \\(\\alpha\\).\n\nCode Pesanti: Le code sono significativamente più pesanti rispetto alla distribuzione Normale, con una decrescita più lenta (\\(\\propto x^{-2}\\)).\n\nMedia e Varianza: La distribuzione non ha una media né una varianza definita.\n\nRelazione con \\(t_1\\): La distribuzione di Cauchy è equivalente a una distribuzione \\(t\\) di Student con 1 grado di libertà.\n\nCaratteristiche Estreme: I valori estremi hanno una probabilità più alta rispetto ad altre distribuzioni comuni, rendendola utile per modellare fenomeni con outlier significativi.\n\n40.9.2 Visualizzazione della Distribuzione di Cauchy\nPer comprendere l’effetto dei parametri \\(\\alpha\\) e \\(\\beta\\) sulla forma della distribuzione, consideriamo alcuni esempi con:\n\n\n\\(\\alpha = 0.0, 0.0, 0.0, -2.0\\),\n\n\\(\\beta = 0.5, 1.0, 2.0, 1.0\\).\n\n\n# Definire i parametri\nx &lt;- seq(-5, 5, length.out = 500)\nalphas &lt;- c(0.0, 0.0, 0.0, -2.0)\nbetas &lt;- c(0.5, 1.0, 2.0, 1.0)\n\n# Creare un data frame per i risultati\ndf &lt;- do.call(rbind, lapply(1:length(alphas), function(i) {\n  data.frame(\n    x = x,\n    density = dcauchy(x, location = alphas[i], scale = betas[i]),\n    label = paste0(\"α = \", alphas[i], \", β = \", betas[i])\n  )\n}))\n\n# Grafico\nggplot(df, aes(x = x, y = density, color = label)) +\n  geom_line(size = 1) +\n  labs(\n    x = \"x\",\n    y = \"f(x)\",\n    title = \"Distribuzioni di Cauchy con diversi parametri\"\n  ) +\n  theme(\n    legend.title = element_blank()\n  )\n\n\n\n\n\n\n\n\n40.9.3 Applicazioni della Distribuzione di Cauchy\n\n\nInferenza Bayesiana:\n\nUtilizzata come prior robusto in modelli bayesiani, particolarmente quando si vuole attribuire una probabilità maggiore a valori estremi rispetto a una distribuzione Normale.\n\n\n\nModellazione di Fenomeni con Outlier:\n\nLa distribuzione di Cauchy è adatta per descrivere dati con valori estremi significativi che possono influenzare fortemente altre distribuzioni.\n\n\n\nIn conclusione, la distribuzione di Cauchy, con le sue proprietà uniche come code pesanti e l’assenza di media e varianza definite, è uno strumento fondamentale per modellare fenomeni in cui i valori estremi giocano un ruolo importante. La sua relazione con la distribuzione \\(t\\) di Student e la sua utilità nei modelli bayesiani ne ampliano ulteriormente le applicazioni in contesti statistici e probabilistici avanzati.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html#distribuzione-gamma",
    "href": "chapters/probability/13_cont_rv_distr.html#distribuzione-gamma",
    "title": "40  Distribuzioni di v.c. continue",
    "section": "\n40.10 Distribuzione Gamma",
    "text": "40.10 Distribuzione Gamma\nLa distribuzione Gamma è una distribuzione di probabilità continua utilizzata principalmente per modellare variabili strettamente positive, come tassi, varianze, o tempi di attesa. È usata nella statistica bayesiana come distribuzione a priori per parametri positivi e trova applicazione in ambiti come la modellazione di eventi rari.\n\nDefinizione 40.3 La distribuzione Gamma è caratterizzata da due parametri principali:\n\n\nParametro di forma (\\(\\alpha\\)): determina la forma generale della distribuzione.\n\nParametro di scala (\\(\\theta\\)) o, alternativamente, il parametro di tasso (\\(\\beta = 1/\\theta\\)): regola la larghezza o la dispersione della distribuzione.\n\nLa funzione di densità di probabilità (PDF) è data da:\n\\[\nf(x \\mid \\alpha, \\theta) = \\frac{x^{\\alpha-1} e^{-x/\\theta}}{\\theta^\\alpha \\Gamma(\\alpha)}, \\quad x &gt; 0,\n\\]\ndove:\n\n\n\\(x\\) è la variabile casuale continua,\n\n\\(\\Gamma(\\alpha)\\) è la funzione Gamma di Eulero, definita come:\n\n\\[\n\\Gamma(\\alpha) = \\int_0^\\infty t^{\\alpha-1} e^{-t} dt.\n\\]\nSe utilizziamo il parametro di tasso \\(\\beta = 1/\\theta\\), la PDF può essere scritta come:\n\\[\nf(x \\mid \\alpha, \\beta) = \\frac{\\beta^\\alpha x^{\\alpha-1} e^{-\\beta x}}{\\Gamma(\\alpha)}, \\quad x &gt; 0.\n\\]\n\n\n40.10.1 Proprietà della Distribuzione Gamma\n\nMedia: \\[\n\\mathbb{E}[X] = \\alpha \\cdot \\theta = \\frac{\\alpha}{\\beta}.\n\\]\nVarianza: \\[\n\\text{Var}(X) = \\alpha \\cdot \\theta^2 = \\frac{\\alpha}{\\beta^2}.\n\\]\nModa (per \\(\\alpha &gt; 1\\)): \\[\n\\text{Moda}(X) = (\\alpha - 1) \\cdot \\theta.\n\\]\n\nDi seguito, mostriamo un esempio per \\(\\alpha = 3\\) e \\(\\beta = 5/3\\), calcolando e rappresentando graficamente la distribuzione.\n\n\nCalcolo della Media e della Deviazione Standard:\n\n# Parametri\nalpha &lt;- 3\nbeta &lt;- 5 / 3\n\n# Calcolo\nmean &lt;- alpha / beta\nsigma &lt;- sqrt(alpha / beta^2)\n\ncat(\"Media:\", mean, \"\\n\")\n#&gt; Media: 1.8\ncat(\"Deviazione Standard:\", sigma, \"\\n\")\n#&gt; Deviazione Standard: 1.039\n\n\n\nGenerazione e Plot dei Dati:\n\n# Generazione di dati\nset.seed(123)\ndata &lt;- rgamma(100000, shape = alpha, rate = beta)\n\n# Data frame per ggplot\ndf &lt;- data.frame(values = data)\n\n# Plot\nggplot(df, aes(x = values)) +\n  geom_histogram(aes(y = ..density..), bins = 30, fill = \"green\", alpha = 0.6) +\n  stat_function(fun = function(x) dgamma(x, shape = alpha, rate = beta),\n                color = \"red\", size = 1) +\n  labs(\n    x = \"Valore\",\n    y = \"Densità di probabilità\",\n    title = \"Distribuzione Gamma con α=3 e β=5/3\"\n  ) \n\n\n\n\n\n\n\n\n\n40.10.2 Applicazioni della Distribuzione Gamma\n\nModellazione del Tempo di Attesa:\nLa distribuzione Gamma è ideale per modellare tempi di attesa, ad esempio, il tempo necessario affinché si verifichino \\(n\\) eventi in un processo di Poisson.\n\nInferenza Bayesiana:\n\nUtilizzata come prior per parametri positivi, come tassi (\\(\\lambda\\)) o varianze (\\(\\sigma^2\\)).\nAd esempio, nella modellazione bayesiana dei processi di Poisson, una distribuzione Gamma è una scelta naturale per il prior su \\(\\lambda\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html#riflessioni-conclusive",
    "href": "chapters/probability/13_cont_rv_distr.html#riflessioni-conclusive",
    "title": "40  Distribuzioni di v.c. continue",
    "section": "\n40.11 Riflessioni conclusive",
    "text": "40.11 Riflessioni conclusive\nLe distribuzioni di probabilità costituiscono il cuore dell’inferenza statistica, sia bayesiana che frequentista. In questo capitolo, abbiamo esplorato come R offre un insieme completo di strumenti per lavorare con diverse distribuzioni, permettendo di modellare e analizzare una vasta gamma di fenomeni.\n\n40.11.1 Principali Applicazioni\n\n\nInferenza Bayesiana:\nLe distribuzioni di probabilità, come la Beta, la Gamma e la Normale, sono essenziali per definire priors, calcolare posteriori e quantificare l’incertezza nei modelli bayesiani. Ad esempio:\n\nLa distribuzione Beta è ideale per modellare credenze a priori su proporzioni o probabilità.\nLa distribuzione Gamma è ampiamente usata per modellare parametri positivi come tassi o varianze.\n\n\nAnalisi Statistica e Modellazione:\nLe distribuzioni, come la \\(t\\) di Student, sono fondamentali per il confronto tra campioni, mentre la Normale è indispensabile per modellare fenomeni che seguono la legge del limite centrale.\nGenerazione e Simulazione di Dati:\nR permette di generare campioni casuali da distribuzioni comuni, utili per simulazioni, bootstrap e validazione di modelli.\n\n40.11.2 Funzionalità di R\nCon poche funzioni, R consente di:\n\n\nGenerare campioni casuali: con funzioni come rnorm, rgamma, rbeta, possiamo simulare dati da distribuzioni specifiche.\n\nCalcolare densità: ad esempio, con dnorm, dgamma, dbeta, possiamo visualizzare le funzioni di densità.\n\nCalcolare probabilità cumulate: con funzioni come pnorm, pbeta, possiamo determinare probabilità su intervalli specifici.\n\nDeterminare quantili: con funzioni come qnorm, qgamma, possiamo calcolare i punti corrispondenti a specifici livelli di probabilità.\n\n40.11.3 Versatilità delle Distribuzioni\nLe distribuzioni esplorate non solo descrivono fenomeni naturali, ma sono anche i “mattoncini” per costruire modelli statistici complessi. Le loro proprietà, come la media, la varianza, la simmetria o le code pesanti, consentono di adattare il modello al fenomeno studiato.\nIn conclusione, il linguaggio R, con la sua flessibilità e ricchezza di strumenti, permette di padroneggiare le distribuzioni di probabilità, non solo come oggetti matematici, ma anche come strumenti pratici per rispondere a domande complesse. La comprensione e l’uso delle distribuzioni presentate costituiscono le fondamenta per avanzare verso tecniche più sofisticate, come l’inferenza bayesiana avanzata o la modellazione gerarchica.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html#esercizi",
    "href": "chapters/probability/13_cont_rv_distr.html#esercizi",
    "title": "40  Distribuzioni di v.c. continue",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nEsercizi sulla distribuzione normale, risolvibili usando R, sono disponibili sulla seguente pagina web.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/13_cont_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "title": "40  Distribuzioni di v.c. continue",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.7   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.13.0 psych_2.5.3     \n#&gt;  [9] scales_1.4.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.3.0     ggplot2_3.5.2   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.4     stringi_1.8.7      lattice_0.22-7    \n#&gt;  [4] hms_1.1.3          digest_0.6.37      magrittr_2.0.3    \n#&gt;  [7] evaluate_1.0.4     grid_4.5.0         timechange_0.3.0  \n#&gt; [10] RColorBrewer_1.1-3 fastmap_1.2.0      rprojroot_2.0.4   \n#&gt; [13] jsonlite_2.0.0     mnormt_2.1.1       cli_3.6.5         \n#&gt; [16] rlang_1.1.6        withr_3.0.2        tools_4.5.0       \n#&gt; [19] parallel_4.5.0     tzdb_0.5.0         pacman_0.5.1      \n#&gt; [22] vctrs_0.6.5        R6_2.6.1           lifecycle_1.0.4   \n#&gt; [25] htmlwidgets_1.6.4  pkgconfig_2.0.3    pillar_1.10.2     \n#&gt; [28] gtable_0.3.6       glue_1.8.0         xfun_0.52         \n#&gt; [31] tidyselect_1.2.1   rstudioapi_0.17.1  farver_2.1.2      \n#&gt; [34] htmltools_0.5.8.1  nlme_3.1-168       labeling_0.4.3    \n#&gt; [37] rmarkdown_2.29     compiler_4.5.0",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_cont_rv_distr.html#bibliografia",
    "href": "chapters/probability/13_cont_rv_distr.html#bibliografia",
    "title": "40  Distribuzioni di v.c. continue",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlitzstein, J. K., & Hwang, J. (2019). Introduction to probability. CRC Press.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_gauss.html",
    "href": "chapters/probability/14_gauss.html",
    "title": "41  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "",
    "text": "41.1 Introduzione\nNell’analisi dei dati numerici, un aspetto cruciale da affrontare è l’imprecisione delle misurazioni, una caratteristica intrinseca dei dati reali. Anche in condizioni ottimali, le misure sono soggette a incertezze: i dati rappresentano sempre una stima approssimativa della realtà, accurata solo entro un certo margine (ad esempio, pochi punti percentuali). Inoltre, in molti contesti, come quelli demografici, commerciali o sociali, i dati possono essere arrotondati intenzionalmente o risultare imprecisi a causa di stime indirette, incompletezza delle informazioni o altri fattori.\nRiconoscere e gestire questa incertezza è una componente essenziale del processo analitico. Gli strumenti statistici forniscono un framework formale per descrivere e quantificare l’incertezza, consentendo di trarre inferenze robuste dai dati. Tra le distribuzioni di probabilità, la distribuzione normale (o gaussiana) occupa un posto centrale per la sua ubiquità e versatilità. Spesso rappresentata dalla caratteristica “curva a campana,” questa distribuzione è utilizzata per descrivere molte variabili naturali. Quando i dati approssimano una distribuzione normale, gran parte dei valori si concentra intorno alla media, con una diminuzione progressiva della probabilità di valori estremi.\nUna delle proprietà più utili della distribuzione normale è la possibilità di esprimere affermazioni quantitative rigorose. Ad esempio, si può calcolare la probabilità che un valore cada entro un determinato intervallo dalla media utilizzando parametri semplici come media (\\(\\mu\\)) e deviazione standard (\\(\\sigma\\)):\npnorm(1) - pnorm(-1)\n#&gt; [1] 0.6827\npnorm(3) - pnorm(-3)\n#&gt; [1] 0.9973\nQuesti calcoli costituiscono la base della “regola delle tre sigma,” una strategia utilizzata per identificare valori anomali (outlier), come discusso nel Capitolo 24. Tuttavia, tale regola può risultare fuorviante se i dati non seguono effettivamente una distribuzione normale.\nLa densità della distribuzione normale è definita dalla formula:\n\\[\np(x) = \\frac{1}{\\sqrt{2\\pi}\\,\\sigma} \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right),\n\\]\ndove \\(\\mu\\) rappresenta la media e \\(\\sigma\\) la deviazione standard. Conoscere questi due parametri permette di calcolare proprietà fondamentali della distribuzione e di stimare probabilità associate a intervalli specifici.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_gauss.html#introduzione",
    "href": "chapters/probability/14_gauss.html#introduzione",
    "title": "41  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "",
    "text": "Circa il 68.3% dei valori cade entro una deviazione standard dalla media:\n\n\n\nCirca il 99.7% cade entro tre deviazioni standard:\n\n\n\n\n\n\n\n41.1.1 Gaussianità e Inferenza Statistica\nLa distribuzione normale è particolarmente rilevante per molti metodi statistici, in particolare nell’approccio frequentista. Gran parte dei test di ipotesi e delle procedure inferenziali assume che i dati siano distribuiti normalmente, una condizione necessaria per derivare formalmente i risultati di molti test. Ad esempio, i test t di Student e l’ANOVA richiedono la normalità delle variabili o dei residui. Quando questa assunzione è soddisfatta, tali strumenti offrono inferenze precise e affidabili.\nTuttavia, se i dati non sono gaussiani, molti test perdono validità. Sebbene si siano proposti approcci che dimostrano la robustezza di alcuni test a deviazioni moderate dalla normalità (Shatz, 2024), tale robustezza non è garantita in tutte le situazioni. Inoltre, l’enfasi sui valori-p complica la questione, poiché violazioni dell’assunzione di normalità possono compromettere l’interpretazione di questi indicatori.\nUna strategia comune per affrontare la non-gaussianità è l’applicazione di trasformazioni dei dati, come la trasformazione logaritmica o quella della radice quadrata, per avvicinare i dati alla distribuzione normale (Osborne, 2002). Ad esempio, distribuzioni asimmetriche come quelle dei tempi di reazione possono essere rese più gaussiane attraverso trasformazioni adeguate, rendendo applicabili i test frequentisti standard. Tuttavia, l’uso delle trasformazioni ha un costo: la perdita di interpretabilità. Se i dati originali avevano un significato chiaro e intuitivo, la trasformazione può rendere i risultati più difficili da collegare al fenomeno studiato.\nIn questo capitolo, esploreremo come verificare se i dati seguono una distribuzione normale, discuteremo l’impatto di questa assunzione sui metodi frequentisti e valuteremo il ruolo delle trasformazioni. Il nostro obiettivo è fornire al data analyst una guida pratica per decidere come trattare i dati non gaussiani, considerando sia i vantaggi che i limiti di ciascun approccio.\n\n41.1.2 L’assunzione di Gaussianità: Quando è valida?\nSebbene la distribuzione normale sia spesso un buon modello per i dati numerici, non è sempre una rappresentazione adeguata. Questo può dipendere da caratteristiche intrinseche dei dati, come asimmetrie, code lunghe o la presenza di valori anomali. Valutare l’appropriatezza dell’assunzione di normalità è un passaggio critico in qualsiasi analisi statistica.\nPer diagnosticare la normalità, presenteremo tre strumenti grafici:\n\n\nIstogrammi, una visualizzazione semplice ma spesso limitata.\n\nGrafici di densità, che forniscono un confronto più fluido rispetto agli istogrammi.\n\nQQ-plot (Quantile-Quantile plot), uno strumento visivo particolarmente efficace per rilevare deviazioni dalla normalità.\n\nQuesti strumenti possono anche essere affiancati da test formali per consentire una diagnosi robusta e guidare le decisioni sul trattamento dei dati.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_gauss.html#istogramma",
    "href": "chapters/probability/14_gauss.html#istogramma",
    "title": "41  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "\n41.2 Istogramma",
    "text": "41.2 Istogramma\nPer illustrare il concetto, utilizziamo un set di dati simulati che hanno proprietà simili a quelle dei tempi di reazione. Creeremo un istogramma e vi sovrapporremo la curva di densità normale calcolata in base ai dati.\n\n# Dati simulati di tempi di reazione\nset.seed(123)\nrt &lt;- c(rexp(100, rate = 0.2), 50, 60) # Aggiunti valori estremi\n\n# Calcolare la media e la deviazione standard per sovrapporre la densità normale\nmean_rt &lt;- mean(rt, na.rm = TRUE)\nsd_rt &lt;- sd(rt, na.rm = TRUE)\n\n# Creare l'istogramma e sovrapporre la densità normale\nggplot(tibble(rt=rt), aes(x = rt)) +\n  geom_histogram(\n    aes(y = ..density..),\n    bins = 30, color = \"black\"\n  ) +\n  stat_function(\n    fun = dnorm,\n    args = list(mean = mean_rt, sd = sd_rt),\n    size = 1\n  ) +\n  labs(\n    title = \"Istogramma dei Tempi di Reazione\\ne Densità Normale\",\n    x = \"Tempi di Reazione\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\nL’istogramma mostra la distribuzione empirica dei dati, mentre la curva rossa rappresenta la densità normale con la stessa media e deviazione standard. Nel nostro caso, è evidente una discrepanza tra la distribuzione empirica e la densità normale, indicando che l’assunzione di normalità non è appropriata.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_gauss.html#grafico-di-densità",
    "href": "chapters/probability/14_gauss.html#grafico-di-densità",
    "title": "41  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "\n41.3 Grafico di densità",
    "text": "41.3 Grafico di densità\nUn grafico di densità è una versione lisciata dell’istogramma che facilita il confronto con la distribuzione normale. Utilizzando il dataset precedente, possiamo creare un grafico di densità sovrapposto alla curva gaussiana.\n\nggplot(tibble(rt=rt), aes(x = rt)) +\n  geom_density(alpha = 0.5) +\n  stat_function(\n    fun = dnorm,\n    args = list(mean = mean_rt, sd = sd_rt),\n    size = 1\n  ) +\n  labs(\n    title = \"Grafico di Densità del Peso dei Pulcini e\\nDensità Normale\",\n    x = \"Peso\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\nAnche questa rappresentazione rende chiaro come l’assunzione di normalità non sia appropriata.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_gauss.html#diagramma-quantile-quantile",
    "href": "chapters/probability/14_gauss.html#diagramma-quantile-quantile",
    "title": "41  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "\n41.4 Diagramma quantile-quantile",
    "text": "41.4 Diagramma quantile-quantile\nIl diagramma quantile-quantile (QQ-plot) è lo strumento più utile per analizzare visivamente la conformità di un dataset a una distribuzione teorica, in particolare alla distribuzione normale. Il QQ-plot è una tecnica essenziale per chi lavora con dati che si presume seguano una distribuzione specifica, e rappresenta un passaggio cruciale in molte analisi statistiche, soprattutto per verificare l’assunto di normalità.\nUn QQ-plot permette di:\n\n\nValutare graficamente la normalità dei dati: Se i punti nel diagramma seguono approssimativamente una linea retta, i dati possono essere considerati normalmente distribuiti. In caso contrario, il QQ-plot rivela deviazioni dalla normalità, come code pesanti o asimmetrie.\n\nConfrontare distribuzioni: Il QQ-plot non si limita solo alla distribuzione normale, ma può essere utilizzato per confrontare la distribuzione del campione con qualsiasi distribuzione teorica, facilitando l’analisi di dati con forme di distribuzione complesse.\n\nIdentificare outlier: Gli outlier nei dati saranno visibili come punti che si discostano significativamente dalla linea retta del QQ-plot.\n\nIl QQ-plot è costruito tracciando i quantili del campione contro i quantili teorici di una distribuzione di riferimento. L’interpretazione è piuttosto semplice:\n\nSe il campione segue la distribuzione teorica, i punti nel QQ-plot si allineano lungo una linea retta di pendenza 1 (e intercetta 0 nel caso di distribuzione normale standardizzata).\nLa deviazione dalla linea retta indica differenze nella distribuzione del campione rispetto alla distribuzione teorica:\n\n\nIntercetta diversa da 0: indica che la media del campione differisce dalla media della distribuzione teorica.\n\nPendenza diversa da 1: indica una differenza nella varianza tra il campione e la distribuzione teorica.\n\nCurve: indicano deviazioni sistematiche, come code pesanti o distribuzioni asimmetriche.\n\n\n\nNella discussione seguente, costruiremo e analizzeremo QQ-plot per tre casi tipici:\n\n\nCampione con stessa media e varianza della distribuzione teorica.\n\nCampione con media diversa ma stessa varianza.\n\nCampione con media e varianza diverse.\n\nSimuleremo i dati, li ordineremo, calcoleremo manualmente i quantili teorici e infine utilizzeremo librerie specializzate per replicare e confrontare i risultati. Questo approccio pratico ci permetterà di comprendere a fondo l’utilità e il funzionamento del QQ-plot.\n\n41.4.1 Comprendere e Costruire un QQ-Plot (Distribuzione Normale)\nUn QQ-plot (Quantile-Quantile plot) è uno strumento grafico utilizzato per confrontare la distribuzione di un campione con una distribuzione teorica, spesso la distribuzione normale. Il QQ-plot aiuta a visualizzare se un dataset segue una distribuzione specifica, tracciando i quantili del campione contro i quantili della distribuzione teorica.\n\n41.4.2 Passi per Costruire un QQ-Plot\n\n\nOrdinare i Dati: Disporre i dati del campione in ordine crescente.\n\nDeterminare i Quantili Teorici: Per una distribuzione normale, i quantili corrispondono all’inverso della funzione di distribuzione cumulativa (CDF) della distribuzione normale.\n\nConfrontare i Quantili: Tracciare i quantili del campione rispetto ai quantili della distribuzione teorica. Se il campione proviene dalla distribuzione teorica, i punti dovrebbero trovarsi approssimativamente su una linea retta.\n\n41.4.3 Caso 1: Campione con Stessa Media e Varianza della Distribuzione Normale\nSupponiamo che il campione provenga da una distribuzione normale \\(N(\\mu = 0, \\sigma^2 = 1)\\), esattamente come la distribuzione teorica.\n\n41.4.3.1 Simulazione dei Dati\nIniziamo simulando un piccolo dataset da \\(N(0, 1)\\):\n\n# Generiamo 20 punti dati da N(0, 1)\nset.seed(42)  # Per garantire la riproducibilità\ndati_campione &lt;- rnorm(20, mean = 0, sd = 1)\n\n# Ordiniamo i dati del campione\ncampione_ordinato &lt;- sort(dati_campione)\n\n# Calcoliamo i quantili teorici da N(0, 1)\nquantili_teorici &lt;- qnorm((seq(1, 20) - 0.5) / 20)\n\n# Tracciamo il QQ-plot\nplot(quantili_teorici, campione_ordinato,\n     xlab = \"Quantili Teorici\", ylab = \"Quantili del Campione\",\n     main = \"QQ-Plot: Stessa Media e Varianza\", pch = 16)\nabline(0, 1, lwd = 2)  # Linea y = x\n\n\n\n\n\n\n\nIn questo caso, i punti del QQ-plot dovrebbero allinearsi alla linea rossa, indicando che la distribuzione del campione corrisponde a quella teorica.\n\n41.4.4 Caso 2: Campione con Media Diversa (Intercetta ≠ 0)\nSimuliamo un campione da \\(N(2, 1)\\), con una media diversa ma la stessa varianza:\n\n# Generiamo 20 punti dati da N(2, 1)\ndati_campione_media_spostata &lt;- rnorm(20, mean = 2, sd = 1)\n\n# Ordiniamo i dati del campione\ncampione_ordinato_media_spostata &lt;- sort(dati_campione_media_spostata)\n\n# Tracciamo il QQ-plot\nplot(quantili_teorici, campione_ordinato_media_spostata,\n     xlab = \"Quantili Teorici\", ylab = \"Quantili del Campione\",\n     main = \"QQ-Plot: Media Diversa (Intercetta ≠ 0)\", pch = 16)\nabline(0, 1, lwd = 2)  # Linea y = x\n\n\n\n\n\n\n\nIn questo caso, i punti dovrebbero seguire una linea retta ma essere spostati verticalmente, indicando una media diversa (intercetta ≠ 0).\n\n41.4.5 Caso 3: Campione con Media e Varianza Diverse (Pendenza ≠ 1)\nSimuliamo un campione da \\(N(2, 2^2)\\), con una media e una varianza diverse:\n\n# Generiamo 20 punti dati da N(2, 2^2)\ndati_campione_varianza_spostata &lt;- rnorm(20, mean = 2, sd = 2)\n\n# Ordiniamo i dati del campione\ncampione_ordinato_varianza_spostata &lt;- sort(dati_campione_varianza_spostata)\n\n# Tracciamo il QQ-plot\nplot(quantili_teorici, campione_ordinato_varianza_spostata,\n     xlab = \"Quantili Teorici\", ylab = \"Quantili del Campione\",\n     main = \"QQ-Plot: Media e Varianza Diverse (Pendenza ≠ 1)\", pch = 16)\nabline(0, 1, lwd = 2)  # Linea y = x\n\n\n\n\n\n\n\nIn questo caso, i punti si discosteranno sia verticalmente (per la media diversa) sia rispetto alla pendenza della linea (per la varianza diversa).\n\n41.4.6 Calcolo Manuale del QQ-Plot\nPer ciascun caso sopra, i passaggi sono i seguenti:\n\n\nOrdinamento dei dati del campione: Questo fornisce i quantili del campione.\n\nCalcolo dei quantili teorici: Utilizzando la funzione inversa della CDF per la distribuzione normale.\n\nEsempio in R:\n\n# Calcolo manuale dei quantili teorici\nquantili_teorici_manuali &lt;- function(n) {\n  sapply(1:n, function(i) qnorm((i - 0.5) / n))\n}\n\nn &lt;- length(dati_campione)\nquantili_teorici_calcolati &lt;- quantili_teorici_manuali(n)\nquantili_teorici_calcolati\n#&gt;  [1] -1.95996 -1.43953 -1.15035 -0.93459 -0.75542 -0.59776 -0.45376 -0.31864\n#&gt;  [9] -0.18912 -0.06271  0.06271  0.18912  0.31864  0.45376  0.59776  0.75542\n#&gt; [17]  0.93459  1.15035  1.43953  1.95996\n\n\n41.4.7 Utilizzo di Funzioni Specializzate\nIn R, il pacchetto base offre la funzione qqnorm() per generare QQ-plot. Ad esempio:\n\n# Generazione del QQ-plot con qqnorm\nqqnorm(dati_campione, main = \"QQ-Plot: Stessa Media e Varianza\")\nqqline(dati_campione, lwd = 2)  # Linea di riferimento\n\n\n\n\n\n\n\nPossiamo ripetere lo stesso per i campioni con media e varianza spostate.\n\nQuesto approccio fornisce un’analisi completa della corrispondenza tra distribuzioni teoriche e campioni simulati utilizzando QQ-plot.\nPer concludere, esaminiamo la distribuzione dei tempi di reazione simulati con il qq-plot.\n\nqqnorm(rt, main = \"Tempi di Reazione\")\n\n\n\n\n\n\n\nIl diagramma quantile-quantile rende molto chiaro che la distribuzione del peso dei pulcini non è gaussiana.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_gauss.html#valutare-la-normalità-test-statistici",
    "href": "chapters/probability/14_gauss.html#valutare-la-normalità-test-statistici",
    "title": "41  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "\n41.5 Valutare la Normalità: Test Statistici",
    "text": "41.5 Valutare la Normalità: Test Statistici\nSebbene esistano numerosi test statistici formali per valutare la conformità dei dati alla distribuzione normale, questi sono spesso troppo conservativi o sensibili a lievi deviazioni, e nella pratica sono frequentemente sostituiti da metodi visivi più flessibili ed efficaci.\nIn R sono disponibili diversi test per verificare la normalità dei dati. Di seguito presentiamo i più comuni, insieme a un esempio pratico basato sul dataset ChickWeight.\n\n41.5.1 Test di Shapiro-Wilk\nIl test di Shapiro-Wilk è uno dei test più utilizzati per verificare la normalità. Valuta l’ipotesi nulla che i dati seguano una distribuzione normale.\n\nshapiro_test &lt;- shapiro.test(rt)\nshapiro_test\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  rt\n#&gt; W = 0.56, p-value = 5e-16\n\n\nIl p-value è inferiore a 0.05 → Rifiutiamo l’ipotesi nulla, i dati non sono normali.\nIl p-value è maggiore di 0.05 → Non rifiutiamo l’ipotesi nulla, i dati possono essere considerati normali.\n\n41.5.2 Test di Kolmogorov-Smirnov\nQuesto test confronta la distribuzione cumulativa dei dati con una distribuzione teorica, come la normale. Tuttavia, è meno sensibile rispetto al test di Shapiro-Wilk.\n\nks_test &lt;- ks.test(\n  rt, \n  \"pnorm\", \n  mean = mean(rt), \n  sd = sd(rt)\n)\nks_test\n#&gt; \n#&gt;  Asymptotic one-sample Kolmogorov-Smirnov test\n#&gt; \n#&gt; data:  rt\n#&gt; D = 0.25, p-value = 5e-06\n#&gt; alternative hypothesis: two-sided\n\nIl test di Kolmogorov-Smirnov è più adatto per grandi dataset, ma è noto per essere eccessivamente conservativo.\n\n41.5.3 Limitazioni dei test statistici\nNonostante la loro precisione formale, i test statistici per la normalità notevoli limitazioni:\n\nEccessiva sensibilità ai grandi campioni: Quando il campione è ampio, anche lievi deviazioni dalla normalità, non rilevanti per l’analisi, possono portare a un risultato di non-normalità.\nMancanza di sensibilità nei piccoli campioni: Con campioni ridotti, i test possono mancare di potere statistico, portando a falsi negativi (ovvero, non rilevare deviazioni significative dalla normalità).\n\n\nset.seed(123)\nshapiro.test(rchisq(20, 4))\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  rchisq(20, 4)\n#&gt; W = 0.94, p-value = 0.3\n\nIn questo esempio, vediamo come, con un campione di 20 osservazioni da una distribuzione \\(\\chi^2_4\\) si produca un falso negativo.\n\n\nDifficoltà interpretative: Un p-value elevato non implica che i dati siano esattamente normali; semplicemente, non c’è evidenza sufficiente per rifiutare l’ipotesi di normalità.\n\nI metodi visivi, sebbene meno formali, sono spesso più pratici ed efficaci per diagnosticare deviazioni dalla normalità.I metodi visivi sono preferibili sono preferibili perché\n\nforniscono una diagnosi immediata, che consente di identificare deviazioni rilevanti senza dipendere da un p-value.\nrivelano non solo se i dati non sono normali, ma anche come e dove differiscono dalla normalità (ad esempio, asimmetria o code pesanti).\noffrono indicazioni utili anche in presenza di grandi campioni, dove i test statistici possono risultare eccessivamente conservativi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_gauss.html#trasformazione-dei-dati-affrontare-la-non-normalità",
    "href": "chapters/probability/14_gauss.html#trasformazione-dei-dati-affrontare-la-non-normalità",
    "title": "41  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "\n41.6 Trasformazione dei dati: affrontare la non-normalità",
    "text": "41.6 Trasformazione dei dati: affrontare la non-normalità\nQuando i dati non rispettano l’assunzione di normalità, è possibile utilizzare diverse strategie per affrontare questa violazione. Una delle più comuni è l’uso di trasformazioni dei dati, che permettono di adattare la distribuzione dei dati a una forma più vicina a quella normale, mantenendo comunque la validità dell’analisi che richiede l’assunzione di normalità. Due approcci comuni sono Winsorizing e trimming.\n\n41.6.1 Winsorizing e Trimming\nQuesti metodi si concentrano sulla gestione degli outlier, ossia valori estremi che possono distorcere la distribuzione dei dati. Entrambi gli approcci presumono che la non-normalità sia dovuta a dati contaminanti e agiscono in modo differente:\n\n\nWinsorizing: Sostituisce i valori estremi con valori meno estremi, come i percentili limite della distribuzione.\n\nTrimming: Rimuove completamente i valori estremi dalla distribuzione.\n\nConsideriamo i seguenti dati di esempio:\n\ndati &lt;- c(\n  1.0, 2.2, 3.0, 3.1, 4.0, 4.0, 4.1, 5.3, 6.5, 8.3,\n  10.9, 20.4, 21.4, 34.\n)\n\n# Winsorizing al 20%\ndati_winsorized &lt;- winsorize(\n  dati,\n  method = \"percentile\", percentile = 20\n)\nprint(dati_winsorized)\n#&gt;  [1]  3.0  3.0  3.0  3.1  4.0  4.0  4.1  5.3  6.5  8.3 10.9 20.4 20.4 20.4\n\n\n# Trimming al 20%\ndati_trimmed &lt;- dati[\n  dati &gt;= quantile(dati, 0.2) & dati &lt;= quantile(dati, 0.8)\n]\nprint(dati_trimmed)\n#&gt; [1]  3.1  4.0  4.0  4.1  5.3  6.5  8.3 10.9\n\n\n\nDati Winsorized: I valori estremi (inferiori e superiori ai percentili 20° e 80°) sono sostituiti dai valori limite.\n\nDati Trimmed: I valori fuori dai percentili 20° e 80° sono completamente rimossi.\n\nQuesti metodi riducono l’impatto degli outlier, ma possono introdurre bias se i valori estremi sono effettivamente parte della popolazione target.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_gauss.html#trasformazioni-comuni",
    "href": "chapters/probability/14_gauss.html#trasformazioni-comuni",
    "title": "41  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "\n41.7 Trasformazioni comuni",
    "text": "41.7 Trasformazioni comuni\nQuando i dati non rispettano l’assunzione di normalità, è possibile applicare trasformazioni matematiche per modificarne la forma e migliorare l’adattamento a una distribuzione normale. Di seguito, presentiamo le trasformazioni più utilizzate.\nTrasformazione logaritmica.\nLa trasformazione logaritmica è particolarmente utile per variabili con asimmetria positiva (code lunghe a destra), come i tempi di reazione.\n\n# Trasformazione logaritmica\ndati_log &lt;- log(rt)\nplot(density(dati_log), main = \"Densità dei dati log-transformati\")\n\n\n\n\n\n\n\nTrasformazione radice quadrata.\nAdatta per variabili di conteggio o proporzioni con valori vicini a zero.\n\ndati_sqrt &lt;- sqrt(rt)\nplot(density(dati_sqrt), main = \"Densità dei dati trasformati con radice quadrata\")\n\n\n\n\n\n\n\nTrasformazione inversa.\nEfficace per dati con forte asimmetria positiva, ma può complicare l’interpretazione.\n\ndati_inv &lt;- 1 / rt\nplot(density(dati_inv), main = \"Densità dei dati trasformati inversamente\")\n\n\n\n\n\n\n\nTrasformazione Box-Cox.\nLa trasformazione Box-Cox è una tecnica parametrica che generalizza le precedenti. Utilizza il massimo della verosimiglianza per determinare la trasformazione ottimale per normalizzare i dati. La funzione di trasformazione dipende da un parametro \\(\\lambda\\):\n\\[\ny(\\lambda) =\n\\begin{cases}\n\\frac{y^\\lambda - 1}{\\lambda} & \\text{se } \\lambda \\neq 0, \\\\\n\\log(y) & \\text{se } \\lambda = 0.\n\\end{cases}\n\\]\n\nb &lt;- boxcox(lm(rt ~ 1))\n\n\n\n\n\n\n\n\n# Exact lambda\nlambda &lt;- b$x[which.max(b$y)]\nlambda\n#&gt; [1] 0.1818\n\nTrasformiamo i dati utilizzando lambda.\n\nrt_boxcox &lt;- (rt^lambda - 1) / lambda\nrt_boxcox |&gt; head()\n#&gt; [1]  1.6450  1.1676  2.2609 -1.5681 -1.1334  0.4787\n\n\nplot(\n  density(rt_boxcox), \n  main = \"Densità dei dati trasformati con Box-Cox\"\n)\n\n\n\n\n\n\n\n\n# Generazione del QQ-plot con qqnorm\nqqnorm(rt_boxcox, main = \"QQ-Plot\")\nqqline(rt_boxcox, lwd = 2) \n\n\n\n\n\n\n\n\n\n41.7.1 Pro e contro delle trasformazioni\nVantaggi:\nLe trasformazioni dei dati offrono molteplici benefici nell’analisi statistica. In primo luogo, possono migliorare l’aderenza alla normalità, un requisito fondamentale per l’applicazione di molti test statistici. Inoltre, contribuiscono a stabilizzare la varianza e a mitigare l’impatto dei valori estremi, riducendo il rischio che questi ultimi influenzino eccessivamente i risultati. Tali vantaggi migliorano la robustezza e l’accuratezza delle analisi.\nSvantaggi:\nNonostante i benefici, le trasformazioni presentano limitazioni rilevanti. La perdita di interpretabilità è uno degli aspetti più critici: i risultati su dati trasformati possono risultare meno intuitivi. Ad esempio, in un modello di regressione applicato a dati trasformati con il logaritmo, il coefficiente rappresenta un cambiamento percentuale anziché assoluto, rendendo l’interpretazione meno diretta per i non esperti.\nInoltre, l’applicazione di una trasformazione deve essere attentamente motivata in base alla natura dei dati e agli obiettivi dell’analisi. Una trasformazione inappropriata può introdurre distorsioni indesiderate, compromettendo la validità dei risultati e portando a conclusioni fuorvianti. Per questo motivo, è essenziale valutare attentamente i costi e i benefici della trasformazione nel contesto specifico della ricerca.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_gauss.html#riflessioni-conclusive",
    "href": "chapters/probability/14_gauss.html#riflessioni-conclusive",
    "title": "41  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "\n41.8 Riflessioni Conclusive",
    "text": "41.8 Riflessioni Conclusive\nLa verifica della normalità dei dati e l’eventuale utilizzo di trasformazioni matematiche costituiscono fasi fondamentali nell’analisi statistica. Sebbene i test formali (come Shapiro-Wilk o Kolmogorov-Smirnov) offrano una valutazione strutturata, essi possono risultare troppo sensibili, portando a rigettare l’assunto di normalità anche in presenza di lievi deviazioni non rilevanti dal punto di vista pratico. In questi casi, l’impiego di strumenti visivi—come istogrammi, grafici di densità o QQ-plot—si rivela spesso più informativo e flessibile, consentendo di individuare la natura e l’entità delle deviazioni.\nLe trasformazioni dei dati rappresentano una strategia utile per normalizzare la distribuzione, ma richiedono una scelta oculata. È essenziale verificare che la trasformazione adottata non comprometta il significato teorico della variabile in esame. Quando l’interpretabilità risulta compromessa, potrebbe essere preferibile ricorrere a metodi robusti o modelli alternativi (ad esempio, approcci bayesiani) che non presuppongono la normalità. In definitiva, la decisione finale dipenderà dal contesto di ricerca, dalla natura dei dati e dagli obiettivi analitici, privilegiando sempre un equilibrio tra rigore statistico e interpretabilità dei risultati.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_gauss.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/14_gauss.html#informazioni-sullambiente-di-sviluppo",
    "title": "41  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] MASS_7.3-65      datawizard_1.1.0 thematic_0.1.7   MetBrewer_0.2.0 \n#&gt;  [5] ggokabeito_0.1.0 see_0.11.0       gridExtra_2.3    patchwork_1.3.0 \n#&gt;  [9] bayesplot_1.13.0 psych_2.5.3      scales_1.4.0     markdown_2.0    \n#&gt; [13] knitr_1.50       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   \n#&gt; [17] dplyr_1.1.4      purrr_1.0.4      readr_2.1.5      tidyr_1.3.1     \n#&gt; [21] tibble_3.3.0     ggplot2_3.5.2    tidyverse_2.0.0  rio_1.2.3       \n#&gt; [25] here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.4     stringi_1.8.7      lattice_0.22-7    \n#&gt;  [4] hms_1.1.3          digest_0.6.37      magrittr_2.0.3    \n#&gt;  [7] evaluate_1.0.4     grid_4.5.0         timechange_0.3.0  \n#&gt; [10] RColorBrewer_1.1-3 fastmap_1.2.0      rprojroot_2.0.4   \n#&gt; [13] jsonlite_2.0.0     mnormt_2.1.1       cli_3.6.5         \n#&gt; [16] rlang_1.1.6        withr_3.0.2        yaml_2.3.10       \n#&gt; [19] tools_4.5.0        parallel_4.5.0     tzdb_0.5.0        \n#&gt; [22] pacman_0.5.1       vctrs_0.6.5        R6_2.6.1          \n#&gt; [25] lifecycle_1.0.4    htmlwidgets_1.6.4  insight_1.3.0     \n#&gt; [28] pkgconfig_2.0.3    pillar_1.10.2      gtable_0.3.6      \n#&gt; [31] glue_1.8.0         xfun_0.52          tidyselect_1.2.1  \n#&gt; [34] rstudioapi_0.17.1  farver_2.1.2       htmltools_0.5.8.1 \n#&gt; [37] nlme_3.1-168       labeling_0.4.3     rmarkdown_2.29    \n#&gt; [40] compiler_4.5.0",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_gauss.html#bibliografia",
    "href": "chapters/probability/14_gauss.html#bibliografia",
    "title": "41  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nOsborne, J. (2002). Notes on the use of data transformations. Practical Assessment, Research, and Evaluation, 8(1).\n\n\nShatz, I. (2024). Assumption-checking rather than (just) testing: The importance of visualization and effect size in statistical diagnostics. Behavior Research Methods, 56(2), 826–845.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html",
    "href": "chapters/probability/15_likelihood.html",
    "title": "42  La verosimiglianza",
    "section": "",
    "text": "42.1 Introduzione\nIn questo processo di valutazione, la funzione di verosimiglianza svolge un ruolo fondamentale: per ciascun possibile valore dei parametri, essa quantifica la plausibilità dei dati osservati qualora questi fossero effettivamente generati dal modello in esame. In altri termini, la verosimiglianza costruisce una vera e propria mappa di plausibilità parametrica, consentendo di identificare le combinazioni di parametri che massimizzano la coerenza tra modello e realtà osservata.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#introduzione",
    "href": "chapters/probability/15_likelihood.html#introduzione",
    "title": "42  La verosimiglianza",
    "section": "",
    "text": "I ricercatori impiegano una varietà di modelli matematici per descrivere e prevedere il comportamento dei dati osservati. Questi modelli si differenziano principalmente per la loro struttura funzionale, ossia per il modo in cui stabiliscono relazioni tra le variabili osservate e i parametri teorici. La selezione del modello ottimale avviene mediante un confronto sistematico tra le previsioni teoriche generate dai diversi modelli e i dati empirici. Il modello le cui previsioni mostrano il miglior accordo con le osservazioni sperimentali viene considerato la rappresentazione più adeguata del fenomeno in esame.\n\n\n\n42.1.1 Il principio della verosimiglianza\nLa verosimiglianza quantifica la plausibilità di ciascun valore parametrico condizionatamente ai dati osservati. In termini intuitivi, essa rappresenta una misura di coerenza tra i parametri del modello e l’evidenza empirica disponibile.\n\nDefinizione 42.1 Sia \\(Y\\) un vettore aleatorio la cui distribuzione è caratterizzata da una funzione di densità (per variabili continue) o di massa di probabilità (per variabili discrete), denotata da \\(f(y \\mid \\theta),\\) dove \\(\\theta \\in \\Theta\\) è un vettore di parametri definito nello spazio parametrico \\(\\Theta\\).\nDopo aver osservato una realizzazione concreta \\(y\\) di \\(Y\\), la funzione di verosimiglianza è definita come:\n\\[\nL(\\theta; y) = f(y \\mid \\theta),\n\\]\ndove:\n\n\n\\(y\\) è fissato (corrisponde ai dati osservati),\n\n\n\\(\\theta\\) è variabile (rappresenta l’oggetto di inferenza).\n\nQuesta funzione assegna a ogni possibile configurazione parametrica un grado di supporto empirico, rivelando quali valori di \\(\\theta\\) siano più consoni con l’evidenza sperimentale.\n\n\n42.1.2 Relazione tra verosimiglianza e funzione di probabilità\nSebbene la funzione di probabilità (o densità) e la funzione di verosimiglianza condividano la stessa forma matematica – \\(f(y \\mid \\theta)\\) – il loro significato concettuale differisce sostanzialmente in base al contesto inferenziale.\n\n42.1.2.1 Due prospettive a confronto\n\n\nFunzione di probabilità (densità/massa)\n\n\nParametri (\\(\\theta\\)) fissi: assumiamo che siano noti o ipotizzati.\n\n\nDati (\\(y\\)) aleatori: descrive la distribuzione dei possibili risultati.\n\n\nInterpretazione: \\(f(y \\mid \\theta)\\) quantifica la probabilità (o densità) di osservare \\(y\\) sotto un modello con parametri \\(\\theta\\).\n\n\nDomanda chiave: “Se il modello fosse \\(\\theta\\), quanto sarebbero probabili questi dati?”\n\n\n\n\nFunzione di verosimiglianza\n\n\nDati (\\(y\\)) fissi: corrispondono alle osservazioni effettive.\n\n\nParametri (\\(\\theta\\)) variabili: rappresentano l’incertezza da risolvere.\n\n\nInterpretazione: \\(L(\\theta; y) = f(y \\mid \\theta)\\) misura la plausibilità relativa di \\(\\theta\\) alla luce di \\(y\\).\n\n\nDomanda chiave: “Alla luce di questi dati, quanto sono credibili i diversi \\(\\theta\\)?”\n\n\n\n\n42.1.2.2 Implicazioni per l’inferenza statistica\n\nApproccio frequentista: la verosimiglianza è uno strumento per stimare i parametri (es. stima di massima verosimiglianza), senza assegnare loro una distribuzione di probabilità.\n\nApproccio bayesiano: la verosimiglianza agisce come ponte tra dati e parametri, combinando l’informazione empirica con le credenze iniziali (prior) per derivare la distribuzione a posteriori:\n\\[\nP(\\theta \\mid y) \\propto L(\\theta; y) \\cdot P(\\theta).\n\\]\nIn questa visione, i dati aggiornano la nostra conoscenza su \\(\\theta\\) attraverso la verosimiglianza.\n\n\n42.1.2.3 Sintesi delle differenze\n\n\n\n\n\n\n\nCaratteristica\nFunzione di probabilità\nFunzione di verosimiglianza\n\n\n\nVariabile di interesse\n\n\\(y\\) (aleatoria)\n\n\\(\\theta\\) (incognita)\n\n\nRuolo epistemologico\nGenera dati ipotetici\nValuta parametri plausibili\n\n\nContesto d’uso\nModellistica predittiva\nInferenza parametrica\n\n\n\nQuesta dualità riflette un principio fondamentale: la stessa formula matematica assume significati distinti a seconda che l’obiettivo sia la descrizione del processo generativo o l’inferenza sui suoi parametri. La verosimiglianza, in particolare, è il motore dell’apprendimento statistico, trasformando dati in conoscenza.\n\n42.1.3 La log-verosimiglianza\nIn molti contesti statistici e computazionali, risulta conveniente lavorare con la log-verosimiglianza, definita come il logaritmo (naturale) della funzione di verosimiglianza:\n\\[\n\\ell(\\theta; y) = \\log L(\\theta; y) = \\log f(y \\mid \\theta).\n\\]\nQuesta trasformazione offre notevoli vantaggi sotto diversi aspetti:\n\n42.1.3.1 Vantaggi computazionali\n\nStabilità numerica: il prodotto di probabilità molto piccole può portare a valori numericamente instabili (underflow). Il logaritmo converte questi prodotti in somme, più gestibili dal punto di vista computazionale.\n\nEfficienza nei modelli con dati indipendenti: nel caso di osservazioni indipendenti e identicamente distribuite (i.i.d.), la log-verosimiglianza complessiva diventa la somma dei contributi individuali:\n\\[\n\\ell(\\theta; y_1, \\dots, y_n) = \\sum_{i=1}^n \\log f(y_i \\mid \\theta),\n\\]\nsemplificando notevolmente i calcoli.\n\n\n42.1.3.2 Vantaggi analitici\n\nOttimizzazione più semplice: le derivate della log-verosimiglianza presentano un’espressione matematica più semplice rispetto a quelle della verosimiglianza originale, grazie alle proprietà del logaritmo che trasformano prodotti in somme. Questa semplificazione è particolarmente vantaggiosa nei metodi di ottimizzazione numerica come la massimizzazione della verosimiglianza (MLE), dove la stima dei parametri avviene risolvendo il sistema di equazioni ottenuto uguagliando a zero il gradiente (derivate prime).\nProprietà additive: la forma additiva della log-verosimiglianza è particolarmente utile nei modelli gerarchici o nei casi in cui i dati provengono da più fonti indipendenti.\n\n42.1.3.3 Equivalenza con la massimizzazione della verosimiglianza\nPoiché il logaritmo è una funzione monotona crescente, massimizzare \\(\\ell(\\theta; y)\\) equivale a massimizzare \\(L(\\theta; y)\\). Pertanto, le stime di massima verosimiglianza (MLE) possono essere ottenute indifferentemente dall’una o dall’altra.\nIn sintesi, la log-verosimiglianza combina efficienza computazionale e semplicità analitica, rendendola uno strumento fondamentale per l’inferenza statistica e l’analisi dati moderna.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#modellazione-statistica-del-lancio-di-una-moneta",
    "href": "chapters/probability/15_likelihood.html#modellazione-statistica-del-lancio-di-una-moneta",
    "title": "42  La verosimiglianza",
    "section": "\n42.2 Modellazione statistica del lancio di una moneta",
    "text": "42.2 Modellazione statistica del lancio di una moneta\nPer illustrare concretamente il concetto di verosimiglianza, consideriamo il classico problema della stima della probabilità di ottenere “testa” in una moneta. Sia \\(\\theta\\) questa probabilità incognita.\n\n42.2.1 Modello probabilistico\nAssumiamo:\n\n\nIndipendenza: ogni lancio è statisticamente indipendente\n\nStazionarietà: la probabilità \\(\\theta\\) rimane costante per tutti i lanci\n\nPer una sequenza di n lanci con y teste, la probabilità congiunta è:\n\\[\nP(\\text{dati}|\\theta) = \\prod_{i=1}^n P(\\text{esito}_i|\\theta) = \\theta^y(1-\\theta)^{n-y}\n\\]\n\n42.2.2 Verosimiglianza e sua interpretazione\nLa funzione di verosimiglianza:\n\\[\nL(\\theta|\\text{dati}) \\propto \\theta^y(1-\\theta)^{n-y}\n\\]\nrappresenta la plausibilità relativa dei diversi valori di \\(\\theta\\) alla luce dei dati osservati. Notiamo che:\n\n\nForma funzionale: corrisponde al nucleo della distribuzione binomiale\n\nCostante di proporzionalità: il coefficiente binomiale è omesso poiché non influenza la stima di massima verosimiglianza\n\nInterpretazione: valori di \\(\\theta\\) che massimizzano \\(L(\\theta \\mid \\text{dati})\\) sono quelli che meglio “spiegano” i dati osservati\n\n42.2.3 Esempio 1: due lanci\nImmaginiamo di lanciare una moneta due volte e di osservare una testa e una croce. Il nostro obiettivo è stimare \\(p_H\\), cioè la probabilità che la moneta cada su testa. Per iniziare, valutiamo quanto sono plausibili due diversi valori di \\(p_H\\) alla luce dei dati osservati, calcolando la funzione di verosimiglianza.\n\n\nSe \\(p_H = 0.5\\) (una moneta equa), allora:\n\\[\nL(0.5) = 0.5^1 \\cdot (1 - 0.5)^1 = 0.25 .\n\\]\n\n\nSe \\(p_H = 0.4\\), allora:\n\\[\nL(0.4) = 0.4^1 \\cdot 0.6^1 = 0.24 .\n\\]\n\n\nIn entrambi i casi, la funzione di verosimiglianza ci dice quanto sia plausibile quel valore di \\(p_H\\), dati i risultati che abbiamo osservato (una testa e una croce). Come possiamo notare, il valore \\(p_H = 0.5\\) è più compatibile con i dati osservati rispetto a \\(p_H = 0.4\\).\n\n42.2.4 Calcolo della verosimiglianza su una griglia di valori\nOra ripetiamo questo calcolo per molti valori diversi di \\(p_H\\), compresi tra 0 e 1. Questo ci permette di visualizzare la funzione di verosimiglianza e di vedere per quali valori di \\(p_H\\) essa è più alta.\n\n# Parametri osservati\nn &lt;- 2             # Numero totale di lanci\ny &lt;- 1             # Numero di teste osservate\n\n# Griglia di valori per p_H da 0 a 1\np_H &lt;- seq(0, 1, length.out = 100)\n\n# Calcolo della funzione di verosimiglianza\nlikelihood &lt;- p_H^y * (1 - p_H)^(n - y)\n\n\n42.2.5 Rappresentazione grafica\nIl grafico seguente mostra la funzione di verosimiglianza per i 100 valori di \\(p_H\\). Ogni punto della curva indica quanto è compatibile quel valore di \\(p_H\\) con i dati che abbiamo osservato.\n\nggplot(data.frame(p_H, likelihood), aes(x = p_H, y = likelihood)) +\n  geom_line(linewidth = 1.2) +\n  labs(\n    title = \"Funzione di Verosimiglianza per 2 Lanci\\n(1 Testa, 1 Croce)\",\n    x = expression(p[H]),\n    y = \"Verosimiglianza\"\n  )\n\n\n\n\n\n\n\n\n42.2.6 Cosa ci dice il grafico?\n\nLa funzione di verosimiglianza raggiunge il suo massimo per \\(p_H = 0.5\\), che corrisponde alla proporzione osservata (1 testa su 2 lanci).\nQuesto valore di \\(p_H\\) è quindi il più plausibile secondo i dati: rappresenta la stima di massima verosimiglianza.\nI valori estremi (vicini a 0 o a 1) hanno verosimiglianza molto bassa: non spiegano bene il fatto che abbiamo ottenuto una testa e una croce.\n\n42.2.7 Esempio 2: tre lanci\nProseguiamo con un secondo esperimento: lanciamo una moneta tre volte, e otteniamo una testa e due croci. Anche in questo caso, vogliamo stimare \\(p_H\\), la probabilità che la moneta cada su testa, e valutare quali valori di \\(p_H\\) sono più compatibili con i dati osservati.\nIniziamo calcolando la verosimiglianza per due valori specifici:\n\nSe \\(p_H = 0.5\\) (moneta equa): \\[\nL(0.5) = 0.5^1 \\cdot (1 - 0.5)^2 = 0.5 \\cdot 0.25 = 0.125\n\\]\nSe \\(p_H = 0.4\\): \\[\nL(0.4) = 0.4^1 \\cdot 0.6^2 = 0.4 \\cdot 0.36 = 0.144\n\\]\n\nCome vediamo, in questo caso \\(p_H = 0.4\\) ha una verosimiglianza maggiore rispetto a \\(p_H = 0.5\\): questo suggerisce che il valore 0.4 spiega meglio i dati (1 testa su 3 lanci) rispetto alla moneta equa.\n\n42.2.8 Calcolo su una griglia di valori\nCalcoliamo ora la verosimiglianza per 100 valori compresi tra 0 e 1 per visualizzare la funzione su tutto l’intervallo di probabilità.\n\n# Parametri osservati\nn &lt;- 3             # Numero totale di lanci\ny &lt;- 1             # Numero di teste osservate\n\n# Sequenza di valori possibili per p_H\np_H &lt;- seq(0, 1, length.out = 100)\n\n# Calcolo della funzione di verosimiglianza\nlikelihood &lt;- p_H^y * (1 - p_H)^(n - y)\n\n\n42.2.9 Rappresentazione grafica\nIl grafico seguente mostra la funzione di verosimiglianza: ci dice quanto ogni valore di \\(p_H\\) è compatibile con l’osservazione di 1 testa e 2 croci.\n\n# Mostra la curva della verosimiglianza\nggplot(data.frame(p_H, likelihood), aes(x = p_H, y = likelihood)) +\n  geom_line(linewidth = 1.2) +\n  labs(\n    title = \"Funzione di Verosimiglianza per 3 Lanci\\n(1 Testa, 2 Croci)\",\n    x = expression(p[H]),\n    y = \"Verosimiglianza\"\n  )\n\n\n\n\n\n\n\n\n42.2.10 Cosa osserviamo?\n\nIl massimo della funzione di verosimiglianza non è più in \\(p_H = 0.5\\), ma più vicino a 0.33, cioè alla proporzione osservata (1 testa su 3 lanci).\nQuesto riflette il fatto che il valore di \\(p_H\\) che meglio spiega i dati è quello che riproduce la frequenza osservata.\nLa curva è più stretta rispetto al caso con 2 lanci: abbiamo più informazioni, quindi possiamo stimare \\(p_H\\) con maggiore precisione.\nAnche qui, i valori estremi di \\(p_H\\) (vicino a 0 o 1) hanno verosimiglianze basse, perché non giustificano bene l’osservazione di una testa e due croci.\n\n42.2.11 Interpretazione dei risultati\n\nLa funzione di verosimiglianza raggiunge il massimo per valori di \\(p_H\\) vicini alla proporzione di teste osservata.\nQuando il numero di lanci aumenta, la curva diventa più “stretta”: i dati ci permettono di stimare \\(p_H\\) in modo più preciso.\nValori estremi di \\(p_H\\) (vicini a 0 o 1) hanno verosimiglianze basse: non spiegano bene i dati osservati.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#verosimiglianza-binomiale",
    "href": "chapters/probability/15_likelihood.html#verosimiglianza-binomiale",
    "title": "42  La verosimiglianza",
    "section": "\n42.3 Verosimiglianza binomiale",
    "text": "42.3 Verosimiglianza binomiale\nTorniamo al nostro esperimento con la moneta, ma questa volta lo rendiamo un po’ più realistico: lanciamo la moneta \\(n = 30\\) volte e otteniamo \\(y = 23\\) teste. Per modellare il numero totale di teste osservate, utilizziamo la distribuzione binomiale, che ci dice qual è la probabilità di ottenere esattamente \\(y\\) successi su \\(n\\) prove, quando la probabilità di successo in ogni singolo lancio è \\(\\theta\\):\n\\[\nP(Y = y \\mid \\theta) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n - y}.\n\\]\nIn questo contesto:\n\n\n\\(Y\\) è una variabile casuale che rappresenta il numero di teste ottenute,\n\n\\(y = 23\\) è il valore osservato,\n\n\\(\\theta\\) (o \\(p_H\\)) è la probabilità incognita di ottenere testa in un singolo lancio.\n\n\n42.3.1 Dalla distribuzione alla verosimiglianza\nUna volta osservati i dati (\\(y = 23\\)), possiamo considerarli fissati e analizzare quanto ciascun valore possibile del parametro \\(\\theta\\) (la probabilità di ottenere testa) sia compatibile con questi dati. Per farlo, possiamo riutilizzare direttamente la formula della distribuzione binomiale, trattandola come funzione di \\(\\theta\\) anziché come funzione di \\(y\\):\n\\[\nL(\\theta \\mid y = 23) = \\binom{30}{23} \\theta^{23} (1 - \\theta)^7.\n\\]\nQuesta è la funzione di verosimiglianza, che ci dice quanto ogni valore di \\(\\theta\\) sia plausibile alla luce dei dati osservati. A differenza degli esempi precedenti (in cui abbiamo ignorato le costanti moltiplicative), qui non abbiamo bisogno di semplificare la formula: la funzione dbinom() in R calcola automaticamente l’intera espressione, costante inclusa.\n\n42.3.2 Visualizzazione della funzione di verosimiglianza\nIl codice seguente costruisce il grafico della funzione di verosimiglianza, calcolando per ogni valore di \\(\\theta\\) la probabilità di osservare 23 successi su 30 prove:\n\n# Parametri osservati\nn &lt;- 30  # Numero totale di lanci\ny &lt;- 23  # Numero di teste osservate\n\n# Griglia di valori possibili per p_H\np_H &lt;- seq(0, 1, length.out = 1000)\n\n# Calcolo della funzione di verosimiglianza (usando la binomiale completa)\nlikelihood &lt;- dbinom(y, size = n, prob = p_H)\n\n# Creazione del data frame\ndata &lt;- data.frame(p_H, likelihood)\n\n# Grafico della funzione di verosimiglianza\nggplot(data, aes(x = p_H, y = likelihood)) +\n  geom_line(linewidth = 1.2) +\n  labs(\n    title = \"Funzione di Verosimiglianza per 30 Lanci di Moneta (23 Teste)\",\n    x = expression(p[H]),\n    y = \"Verosimiglianza\"\n  )\n\n\n\n\n\n\n\n\n42.3.3 Interpretazione del risultato\nOsservando il grafico, vediamo che:\n\nla funzione di verosimiglianza raggiunge il suo massimo in corrispondenza di \\(p_H \\approx 0.77\\);\nquesto significa che il valore di \\(\\theta\\) (cioè \\(p_H\\)) che rende più plausibile l’osservazione di 23 teste su 30 è circa 0.77;\nin altre parole, la stima di massima verosimiglianza (MLE) per la probabilità di ottenere testa è: \\[\n\\hat{p}_H = \\frac{23}{30} \\approx 0.767.\n\\]\n\n\nQuesto risultato è del tutto intuitivo: la stima migliore è la proporzione osservata di teste.\nLa verosimiglianza ci mostra quali altri valori di \\(\\theta\\) sono meno compatibili con i dati.\nIn sintesi, abbiamo visto come utilizzare direttamente la distribuzione binomiale per costruire la funzione di verosimiglianza. Questa funzione è uno strumento fondamentale per confrontare diversi valori possibili del parametro \\(\\theta\\) (cioè la probabilità di successo) alla luce dei dati osservati.\nNel caso della moneta lanciata 30 volte con 23 teste, abbiamo trattato il numero di successi osservati (\\(y = 23\\)) come un dato fisso, e abbiamo valutato per quali valori di \\(\\theta\\) questa osservazione sarebbe più plausibile.\nIn R, per calcolare la funzione di verosimiglianza non serve riscrivere manualmente la formula della binomiale. Possiamo usare la funzione dbinom(), che calcola le probabilità (o masse) della distribuzione binomiale per un dato numero di successi \\(y\\), un numero totale di prove \\(n\\), e una certa probabilità di successo \\(\\theta\\).\nAd esempio, nel codice:\nlikelihood &lt;- dbinom(y, size = n, prob = p_H)\n\n\ny è il numero di successi osservati (23),\n\nn è il numero totale di prove (30),\n\np_H è un vettore di valori di \\(\\theta\\) tra 0 e 1.\n\nIl risultato likelihood è un vettore che contiene, per ciascun valore di \\(\\theta\\), la verosimiglianza associata a quel valore: cioè, quanto quel valore di \\(\\theta\\) è compatibile con i dati che abbiamo osservato.\nRiassumendo:\n\n\ndbinom() fornisce la funzione di probabilità della binomiale,\nfissando \\(y\\) e variando \\(\\theta\\), usiamo dbinom() per costruire la funzione di verosimiglianza,\npossiamo poi tracciare un grafico di questa funzione per visualizzare quali valori di \\(\\theta\\) sono più plausibili.\n\nQuesta strategia mostra come la verosimiglianza possa essere costruita direttamente a partire da una distribuzione conosciuta (in questo caso, la binomiale) e implementata facilmente in R con strumenti standard.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#la-stima-di-massima-verosimiglianza",
    "href": "chapters/probability/15_likelihood.html#la-stima-di-massima-verosimiglianza",
    "title": "42  La verosimiglianza",
    "section": "\n42.4 La Stima di massima verosimiglianza",
    "text": "42.4 La Stima di massima verosimiglianza\nNel momento in cui osserviamo dei dati e vogliamo stimare un parametro incognito (ad esempio, la probabilità \\(\\theta\\) che una moneta dia “testa”), un metodo classico è la stima di massima verosimiglianza (Maximum Likelihood Estimation, o MLE).\nAnche se nella prospettiva bayesiana ci interessa la distribuzione completa dei valori plausibili del parametro (e non un singolo valore stimato), è utile conoscere il concetto di MLE, che rappresenta il valore di \\(\\theta\\) che rende i dati osservati più compatibili con il modello. Più avanti vedremo come la MLE corrisponde, nel caso di una prior uniforme, al valore massimo della distribuzione a posteriori.\n\n42.4.1 L’idea di fondo\nLa logica è semplice. Una volta osservati i dati, ci chiediamo: quali valori del parametro sono più compatibili con ciò che abbiamo visto? Il valore che risulta più plausibile è la stima di massima verosimiglianza. Immaginiamo di “provare” tanti valori di \\(\\theta\\), e per ciascuno chiederci: “se fosse questo il vero valore di \\(\\theta\\), quanto sarebbe plausibile osservare questi dati?” Il valore che meglio spiega i dati è quello scelto come stima.\n\n42.4.2 Un esempio concreto\nSupponiamo di lanciare una moneta 30 volte ottenendo 23 teste. Un risultato così estremo ci fa dubitare dell’onestà della moneta. Come stimare la sua effettiva probabilità di produrre testa?\nPer rispondere, utilizziamo un concetto chiave: la funzione di verosimiglianza. Questa funzione ci permette di quantificare quanto ciascun possibile valore della probabilità di testa (che indichiamo con \\(\\theta\\)) sia compatibile con i 23 risultati osservati su 30 lanci. In parole semplici: più alta è la verosimiglianza per un certo valore di \\(\\theta\\), più quel valore è plausibile data l’evidenza che abbiamo raccolto.\n\n42.4.3 Visualizzazione della verosimiglianza\nConsidera una curva a campana che rappresenta la verosimiglianza \\(L(\\theta)\\) in funzione del parametro \\(\\theta\\). La curva sale gradualmente fino a raggiunge un massimo globale, poi decresce progressivamente. Il vertice della curva rappresenta la stima di massima verosimiglianza (MLE) e corrisponde al valore di \\(\\theta\\) che massimizza la probabilità di osservare i dati. Nel grafico, è letteralmente la “cima della collina” della verosimiglianza.\nInterpretazione geometrica:\n\nla pendenza della curva indica la certezza della stima,\nuna curva “appuntita” suggerisce una stima precisa,\nuna curva “piatta” indica maggiore incertezza.\n\n42.4.4 Come si trova il massimo?\nDal punto di vista matematico, il massimo di una funzione si trova dove la sua pendenza (la derivata) è zero: cioè, dove smette di salire e inizia a scendere. Per la verosimiglianza binomiale (trasformata in log-verosimiglianza), questo calcolo si può fare in modo esatto. Se hai osservato \\(y\\) successi su \\(n\\) prove, la log-verosimiglianza è:\n\\[\n\\ell(\\theta) = y \\log \\theta + (n - y) \\log(1 - \\theta),\n\\]\ne la derivata si annulla quando:\n\\[\n\\hat{\\theta} = \\frac{y}{n}.\n\\]\nIn altre parole, la MLE è semplicemente la proporzione osservata di successi.\n\n42.4.5 Un punto importante per l’approccio bayesiano\nNel contesto bayesiano, non ci limitiamo a cercare il valore più plausibile del parametro, ma costruiamo una distribuzione completa che rappresenta l’incertezza su \\(\\theta\\). Tuttavia, il punto in cui la distribuzione a posteriori raggiunge il suo massimo viene chiamato MAP (Maximum A Posteriori), e se assumiamo una distribuzione a priori uniforme, MLE e MAP coincidono. Quindi, la MLE può essere vista come un caso speciale del ragionamento bayesiano, utile per introdurre il concetto di compatibilità tra parametri e dati.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#calcolare-la-mle-in-r",
    "href": "chapters/probability/15_likelihood.html#calcolare-la-mle-in-r",
    "title": "42  La verosimiglianza",
    "section": "\n42.5 Calcolare la MLE in R",
    "text": "42.5 Calcolare la MLE in R\n\n42.5.1 Metodo 1: valutazione su griglia\n\n# Parametri\nn &lt;- 30\ny &lt;- 23\ntheta &lt;- seq(0, 1, length.out = 10000)\n\n# Calcolo della verosimiglianza binomiale\nlikelihood &lt;- dbinom(y, size = n, prob = theta)\n\n# Trova il massimo\nmax_index &lt;- which.max(likelihood)\noptimal_theta &lt;- theta[max_index]\n\n# Risultato\noptimal_theta\n#&gt; [1] 0.7667\n\nSpiegazione:\n\n\ndbinom() calcola la verosimiglianza per ogni valore di \\(\\theta\\);\n\nwhich.max() individua il massimo;\n\ntheta[max_index] restituisce la stima MLE.\n\n42.5.2 Metodo 2: ottimizzazione numerica\nIn alternativa, possiamo trovare la MLE senza usare griglie, con un approccio più efficiente.\n\n# Funzione log-verosimiglianza negativa\nneg_log_likelihood &lt;- function(theta) {\n  - (y * log(theta) + (n - y) * log(1 - theta))\n}\n\n# Ottimizzazione numerica\nresult &lt;- optim(\n  par = 0.5,\n  fn = neg_log_likelihood,\n  method = \"Brent\",\n  lower = 1e-6,\n  upper = 1 - 1e-6\n)\n\noptimal_theta_numerical &lt;- result$par\noptimal_theta_numerical\n#&gt; [1] 0.7667\n\nNota: abbiamo calcolato la log-verosimiglianza negativa, perché optim() cerca minimi per default.\n\n42.5.3 Confronto tra le soluzioni\n\nc(\n  \"Griglia\" = optimal_theta, \n  \"Ottimizzazione\" = optimal_theta_numerical, \n  \"Analitica\" = y / n\n)\n#&gt;        Griglia Ottimizzazione      Analitica \n#&gt;         0.7667         0.7667         0.7667\n\nTutti i metodi restituiscono lo stesso risultato:\\[\n\\hat{\\theta} = \\frac{23}{30} \\approx 0.767.\n\\]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#verosimiglianza-congiunta",
    "href": "chapters/probability/15_likelihood.html#verosimiglianza-congiunta",
    "title": "42  La verosimiglianza",
    "section": "\n42.6 Verosimiglianza congiunta",
    "text": "42.6 Verosimiglianza congiunta\nAbbiamo visto che, nel caso di una sequenza di \\(n\\) lanci di una moneta, la funzione di verosimiglianza si basa sulla distribuzione binomiale. In questo caso, trattiamo un esperimento Bernoulliano ripetuto \\(n\\) volte, e la nostra osservazione è il numero totale di successi (teste). Il numero complessivo di successi segue una distribuzione binomiale, e la funzione di verosimiglianza assume la forma:\n\\[\n\\mathcal{L}(\\theta) = P(Y = y \\mid \\theta) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n - y}.\n\\]\nQui la verosimiglianza è espressa direttamente in termini del numero totale di successi e insuccessi, senza dover scrivere il contributo di ogni singolo lancio.\nTuttavia, possiamo affrontare la questione da una prospettiva diversa: invece di considerare il numero totale di successi, possiamo pensare alla verosimiglianza come il prodotto delle probabilità di ogni singolo lancio. Questo ci porta a una generalizzazione importante: la verosimiglianza congiunta di più osservazioni indipendenti.\n\n42.6.1 Dal caso binomiale alla verosimiglianza congiunta\nNel caso dei lanci della moneta, le singole osservazioni sono prove Bernoulliane indipendenti, ovvero ogni singolo lancio è un’osservazione indipendente che segue una distribuzione Bernoulli con parametro \\(\\theta\\):\n\\[\nP(Y_i = 1 \\mid \\theta) = \\theta, \\quad P(Y_i = 0 \\mid \\theta) = 1 - \\theta.\n\\]\nSe trattiamo ogni prova individualmente, la funzione di verosimiglianza per una singola osservazione è:\n\\[\n\\mathcal{L}(\\theta \\mid y_i) = \\theta^{y_i} (1 - \\theta)^{1 - y_i}.\n\\]\nOra, per un campione di \\(n\\) osservazioni indipendenti, la verosimiglianza congiunta è il prodotto delle verosimiglianze delle singole osservazioni:\n\\[\n\\mathcal{L}(\\theta \\mid y_1, y_2, \\dots, y_n) = \\prod_{i=1}^{n} \\theta^{y_i} (1 - \\theta)^{1 - y_i}.\n\\]\nRiconosciamo che questa espressione è identica alla funzione di verosimiglianza della distribuzione binomiale, perché il numero totale di successi è:\n\\[\ny = \\sum_{i=1}^{n} y_i.\n\\]\nQuindi, riscrivendo la verosimiglianza congiunta, otteniamo:\n\\[\n\\mathcal{L}(\\theta) = \\theta^{\\sum y_i} (1 - \\theta)^{n - \\sum y_i} = \\theta^y (1 - \\theta)^{n - y}.\n\\]\nQuesta è proprio la verosimiglianza della distribuzione binomiale! Questo mostra che il caso binomiale può essere visto come una forma compatta di verosimiglianza congiunta per prove Bernoulliane indipendenti.\n\n42.6.2 Perché è importante la verosimiglianza congiunta?\nL’idea della verosimiglianza congiunta è fondamentale perché ci permette di estendere i concetti di verosimiglianza dal caso di una singola osservazione al caso di molte osservazioni indipendenti. Questo è utile in molti contesti statistici:\n\n\nstimare parametri basandosi su un intero campione invece che su una singola osservazione;\n\ndefinire modelli statistici più complessi, in cui le osservazioni sono indipendenti ma possono avere diverse distribuzioni.\n\nIn sintesi, l’esempio binomiale mostra che la verosimiglianza congiunta di prove Bernoulliane indipendenti si riconduce alla verosimiglianza binomiale. Tuttavia, la vera potenza della verosimiglianza congiunta si manifesta in distribuzioni continue come la normale, dove la produttoria delle densità di probabilità per singole osservazioni è chiaramente distinta dalla funzione di verosimiglianza per il campione intero.\nLa chiave per comprendere il concetto è rendersi conto che la verosimiglianza di un’intera sequenza di prove indipendenti è il prodotto delle singole verosimiglianze.\n\n42.6.3 Esempio: osservazioni raggruppate\nPer illustrare il concetto di verosimiglianza congiunta nel caso della distribuzione binomiale, consideriamo quattro gruppi distinti di osservazioni binomiali indipendenti:\n\n\ngruppo 1: 23 successi su 30 prove,\n\ngruppo 2: 20 successi su 28 prove,\n\ngruppo 3: 29 successi su 40 prove,\n\ngruppo 4: 29 successi su 36 prove.\n\nPoiché ogni gruppo segue una distribuzione binomiale indipendente con lo stesso parametro \\(\\theta\\), la log-verosimiglianza congiunta si ottiene sommando le log-verosimiglianze di ciascun gruppo:\n\\[\n\\log \\mathcal{L}(\\theta) = \\sum_{i=1}^{4} \\left[ y_i \\log(\\theta) + (n_i - y_i) \\log(1 - \\theta) \\right],\n\\]\ndove:\n\n\n\\(n_i\\) è il numero totale di prove nel gruppo \\(i\\),\n\n\\(y_i\\) è il numero di successi nel gruppo \\(i\\).\n\nSostituendo i valori specifici:\n\\[\n\\begin{aligned}\n\\log \\mathcal{L}(\\theta) &= [23\\log(\\theta) + (30-23)\\log(1 - \\theta)] \\\\\n&\\quad + [20\\log(\\theta) + (28-20)\\log(1 - \\theta)] \\\\\n&\\quad + [29\\log(\\theta) + (40-29)\\log(1 - \\theta)] \\\\\n&\\quad + [29\\log(\\theta) + (36-29)\\log(1 - \\theta)].\n\\end{aligned}\n\\]\nQuesta formula ci permette di calcolare quanto è plausibile il valore del parametro \\(\\theta\\), tenendo conto simultaneamente di tutte le osservazioni nei quattro gruppi.\n\n42.6.4 Implementazione in R\nSupponiamo di avere i dati di quattro gruppi indipendenti, e vogliamo trovare la stima del parametro \\(\\theta\\) che massimizza la log-verosimiglianza congiunta. Procederemo passo dopo passo.\n1. Definire una funzione per la log-verosimiglianza congiunta.\nQuesta funzione riceve un valore di \\(\\theta\\) e una lista di gruppi. Ogni gruppo contiene il numero totale di prove e il numero di successi. La funzione calcola la somma delle log-verosimiglianze per ciascun gruppo.\n\n# Funzione che calcola la log-verosimiglianza congiunta\nlog_verosimiglianza_congiunta &lt;- function(theta, dati) {\n  # Limitiamo theta per evitare log(0)\n  if (theta &lt;= 0) theta &lt;- 1e-10\n  if (theta &gt;= 1) theta &lt;- 1 - 1e-10\n\n  # Inizializziamo il totale\n  somma_loglik &lt;- 0\n\n  # Per ogni gruppo, calcoliamo il contributo alla log-verosimiglianza\n  for (i in 1:length(dati)) {\n    gruppo &lt;- dati[[i]]   # Estrae il gruppo i-esimo\n    n &lt;- gruppo[1]        # Numero totale di prove\n    y &lt;- gruppo[2]        # Numero di successi\n\n    # Aggiunge il contributo del gruppo alla somma totale\n    somma_loglik &lt;- somma_loglik + y * log(theta) + (n - y) * log(1 - theta)\n  }\n\n  # Restituiamo il valore negativo (perché optim() cerca minimi)\n  return(-somma_loglik)\n}\n\n2. Inserire i dati.\nQui definiamo i dati per ciascun gruppo come coppie (numero di prove, numero di successi):\n\n# Dati osservati per ciascun gruppo\ndati_gruppi &lt;- list(\n  c(30, 23),\n  c(28, 20),\n  c(40, 29),\n  c(36, 29)\n)\n\n3. Trovare la stima di θ che massimizza la verosimiglianza.\nUsiamo optim() per trovare numericamente il valore di \\(\\theta\\) che minimizza il valore negativo della log-verosimiglianza, ovvero che massimizza la log-verosimiglianza.\n\n# Ricerca del valore ottimale di theta\nresult &lt;- optim(\n  par = 0.5,                            # Valore iniziale\n  fn = log_verosimiglianza_congiunta,  # Funzione da minimizzare\n  dati = dati_gruppi,                  # Passiamo i dati\n  method = \"L-BFGS-B\",                 # Metodo con vincoli\n  lower = 0, upper = 1                 # Vincoli: theta tra 0 e 1\n)\n\n# Stima ottimale trovata\nresult$par\n#&gt; [1] 0.7537\n\n4. Visualizzare la log-verosimiglianza.\nCostruiamo ora un grafico che mostri come varia la log-verosimiglianza al variare di \\(\\theta\\).\n\n# Valori di theta da esplorare\ntheta_values &lt;- seq(0.01, 0.99, length.out = 100)\n\n# Vettore per salvare i valori di log-verosimiglianza\nlog_likelihood_values &lt;- numeric(length(theta_values))\n\n# Calcoliamo il valore della funzione per ogni valore di theta\nfor (i in 1:length(theta_values)) {\n  t &lt;- theta_values[i]\n  log_likelihood_values[i] &lt;- log_verosimiglianza_congiunta(t, dati_gruppi)\n}\n\nOra costruiamo il grafico:\n\nggplot(\n  data.frame(theta = theta_values, log_likelihood = log_likelihood_values),\n  aes(x = theta, y = log_likelihood)\n) +\n  geom_line(linewidth = 1.2) +\n  labs(\n    title = \"Funzione di Log-Verosimiglianza Congiunta\",\n    x = expression(theta),\n    y = \"Log-verosimiglianza negativa\"\n  )\n\n\n\n\n\n\n\nCon questo esempio abbiamo visto che:\n\nla log-verosimiglianza congiunta si ottiene sommando le log-verosimiglianze dei singoli gruppi;\nè possibile trovare la stima ottimale di \\(\\theta\\) numericamente, senza formule complicate;\nil grafico della log-verosimiglianza ci aiuta a visualizzare il punto in cui il modello è più compatibile con i dati.\n\nQuesto approccio — basato sull’uso della verosimiglianza e della sua somma tra gruppi indipendenti — sarà anche la base per il passaggio all’inferenza bayesiana, dove aggiungeremo una distribuzione a priori per ottenere una distribuzione a posteriori di \\(\\theta\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#la-verosimiglianza-marginale",
    "href": "chapters/probability/15_likelihood.html#la-verosimiglianza-marginale",
    "title": "42  La verosimiglianza",
    "section": "\n42.7 La verosimiglianza marginale",
    "text": "42.7 La verosimiglianza marginale\nLa verosimiglianza marginale è un concetto fondamentale nell’inferenza bayesiana, utilizzato per valutare quanto un modello sia compatibile con i dati osservati, tenendo conto dell’incertezza sui parametri.\nA differenza della verosimiglianza standard, che misura la plausibilità dei dati per un valore fisso del parametro, la verosimiglianza marginale considera tutti i possibili valori del parametro, pesandoli in base alla loro probabilità a priori. Questo approccio permette di integrare l’incertezza nella valutazione del modello.\n\n42.7.1 Caso con parametri discreti\nPer comprendere meglio il concetto, consideriamo un esperimento in cui eseguiamo 10 tentativi e otteniamo 7 successi. Supponiamo che la probabilità di successo \\(\\theta\\) possa assumere solo tre valori discreti:\n\\[\n\\theta \\in \\{0.1, 0.5, 0.9\\}.\n\\]\nPer calcolare la verosimiglianza marginale, dobbiamo:\n\n\nAssegnare una probabilità a priori a ciascun valore di \\(\\theta\\), ad esempio:\n\nDistribuzione uniforme: \\[\np(\\theta = 0.1) = p(\\theta = 0.5) = p(\\theta = 0.9) = \\frac{1}{3}.\n\\]\n\nDistribuzione non uniforme (ad esempio, dando più peso a \\(\\theta = 0.5\\)): \\[\np(\\theta = 0.1) = \\frac{1}{4}, \\quad p(\\theta = 0.5) = \\frac{1}{2}, \\quad p(\\theta = 0.9) = \\frac{1}{4}.\n\\]\n\n\n\n\nCalcolare la probabilità di osservare 7 successi su 10 prove per ogni valore di \\(\\theta\\):\n\\[\np(k=7 \\mid \\theta) = \\binom{10}{7} \\theta^7 (1 - \\theta)^3.\n\\]\n\n\nMoltiplicare ciascuna di queste probabilità per la corrispondente probabilità a priori e sommare i risultati:\n\\[\np(k=7 \\mid n=10) = \\sum_{i} p(k=7 \\mid \\theta_i) p(\\theta_i).\n\\]\n\n\nSostituendo i valori per la distribuzione uniforme:\n\\[\np(k=7 \\mid n=10) = \\binom{10}{7} 0.1^7 (0.9)^3 \\cdot \\frac{1}{3} +\n\\binom{10}{7} 0.5^7 (0.5)^3 \\cdot \\frac{1}{3} +\n\\binom{10}{7} 0.9^7 (0.1)^3 \\cdot \\frac{1}{3}.\n\\]\nQuesta somma rappresenta la verosimiglianza marginale, ossia la probabilità di ottenere 7 successi su 10, considerando tutte le possibili incertezze su \\(\\theta\\).\n\n42.7.2 Caso con parametri continui\nNella maggior parte delle situazioni, il parametro \\(\\theta\\) non assume solo pochi valori discreti, ma può variare continuamente in un intervallo (ad esempio, tra 0 e 1). In questo caso, invece di sommare, dobbiamo integrare:\n\\[\np(k=7 \\mid n=10) = \\int_{0}^{1} \\binom{10}{7} \\theta^7 (1 - \\theta)^3 p(\\theta) \\, d\\theta.\n\\]\nQui:\n\n\n\\(p(\\theta)\\) è la distribuzione a priori di \\(\\theta\\).\nL’integrale rappresenta una media ponderata della probabilità di ottenere i dati, considerando tutti i valori di \\(\\theta\\).\n\nAd esempio, se \\(\\theta \\sim \\text{Beta}(2,2)\\), la verosimiglianza marginale diventa:\n\\[\np(k=7 \\mid n=10) = \\int_{0}^{1} \\binom{10}{7} \\theta^7 (1 - \\theta)^3 \\frac{\\theta (1-\\theta)}{B(2,2)} \\, d\\theta.\n\\]\nQuesto tipo di calcolo viene spesso risolto numericamente.\n\n42.7.3 Calcolo numerico della verosimiglianza marginale in R\nSe vogliamo calcolare la verosimiglianza marginale numericamente, possiamo usare l’integrazione numerica in R.\nCaso con Parametri Discreti.\n\n# Definiamo i valori possibili di theta e le probabilità a priori\ntheta_vals &lt;- c(0.1, 0.5, 0.9)\nprior_probs &lt;- c(1/3, 1/3, 1/3)  # Distribuzione uniforme\n\n# Calcoliamo la verosimiglianza per ciascun valore di theta\nlikelihoods &lt;- dbinom(7, size = 10, prob = theta_vals)\n\n# Calcoliamo la verosimiglianza marginale sommando i contributi ponderati\nmarginal_likelihood &lt;- sum(likelihoods * prior_probs)\nprint(marginal_likelihood)\n#&gt; [1] 0.0582\n\nCaso con Parametri Continui.\n\n# Definiamo la funzione di verosimiglianza pesata dalla prior\nintegrand &lt;- function(theta) {\n  dbinom(7, size = 10, prob = theta) * dbeta(theta, shape1 = 2, shape2 = 2)\n}\n\n# Eseguiamo l'integrazione numerica\nmarginal_likelihood &lt;- integrate(integrand, lower = 0, upper = 1)$value\nprint(marginal_likelihood)\n#&gt; [1] 0.1119\n\n\n42.7.4 Interpretazione della verosimiglianza marginale\nLa verosimiglianza marginale rappresenta la probabilità complessiva dei dati, tenendo conto di tutte le possibili incertezze sul parametro \\(\\theta\\).\n\nSe la verosimiglianza marginale è alta, significa che il modello nel suo insieme è compatibile con i dati osservati.\nSe la verosimiglianza marginale è bassa, significa che, indipendentemente dal valore di \\(\\theta\\), il modello non spiega bene i dati.\n\nA differenza della verosimiglianza classica, che valuta quanto siano probabili i dati per un singolo valore di \\(\\theta\\), la verosimiglianza marginale considera tutte le possibili ipotesi sul parametro.\n\n42.7.5 Ruolo nella statistica bayesiana\nLa verosimiglianza marginale svolge un ruolo cruciale nell’inferenza bayesiana perché appare nella formula di Bayes:\n\\[\np(\\theta \\mid D) = \\frac{p(D \\mid \\theta) p(\\theta)}{p(D)},\n\\]\ndove \\(p(D)\\) è la verosimiglianza marginale. Questa quantità:\n\nserve da fattore di normalizzazione per la distribuzione a posteriori \\(p(\\theta \\mid D)\\);\n\npermette di confrontare modelli diversi, attraverso il fattore di Bayes:\n\\[\nBF = \\frac{p(D \\mid M_1)}{p(D \\mid M_2)},\n\\]\ndove \\(M_1\\) e \\(M_2\\) sono due modelli diversi.\n\n\nIn conclusione, la verosimiglianza marginale è un concetto chiave nell’inferenza bayesiana, che ci permette di valutare quanto un modello sia coerente con i dati, tenendo conto di tutte le possibili incertezze sui parametri:\n\nper parametri discreti, si calcola come una somma ponderata;\nper parametri continui, si calcola con un integrale;\nè essenziale per il calcolo della distribuzione a posteriori e per il confronto tra modelli.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#verosimiglianza-gaussiana",
    "href": "chapters/probability/15_likelihood.html#verosimiglianza-gaussiana",
    "title": "42  La verosimiglianza",
    "section": "\n42.8 Verosimiglianza gaussiana",
    "text": "42.8 Verosimiglianza gaussiana\nLa distribuzione gaussiana (o distribuzione normale) è una delle distribuzioni più utilizzate in statistica perché descrive molti fenomeni naturali e psicologici. In questo capitolo esploreremo come si calcola la verosimiglianza, ovvero la plausibilità dei parametri, nel caso della distribuzione normale.\n\n42.8.1 Caso di una singola osservazione\nImmaginiamo di misurare il Quoziente Intellettivo (QI) di una persona e ottenere un valore specifico, ad esempio 114. Assumiamo che il QI segua una distribuzione normale con media \\(\\mu\\) sconosciuta e deviazione standard \\(\\sigma\\) nota (ad esempio \\(\\sigma = 15\\)).\nLa funzione di densità di probabilità per una distribuzione normale è:\n\\[\nf(y \\mid \\mu, \\sigma) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(-\\frac{(y-\\mu)^2}{2\\sigma^2}\\right) ,\n\\]\ndove:\n\n\n\\(y\\) è il valore osservato,\n\n\\(\\mu\\) è la media (il parametro che vogliamo stimare),\n\n\\(\\sigma\\) è la deviazione standard (conosciuta).\n\nLa verosimiglianza misura quanto diversi valori di \\(\\mu\\) sono plausibili, dato il valore osservato (114).\nEsempio pratico in R:\n\n# Dati iniziali\ny_obs &lt;- 114\nsigma &lt;- 15\nmu_values &lt;- seq(70, 160, length.out = 1000)\n\n# Calcolo della verosimiglianza\nlikelihood &lt;- dnorm(y_obs, mean = mu_values, sd = sigma)\n\n# Grafico della verosimiglianza\nggplot(data.frame(mu = mu_values, likelihood = likelihood), aes(x = mu, y = likelihood)) +\n  geom_line(linewidth = 1.2) +\n  labs(\n    title = \"Verosimiglianza per un singolo valore di QI (114)\",\n    x = \"Media (μ)\",\n    y = \"Verosimiglianza\"\n  )\n\n\n\n\n\n\n\nQual è il valore migliore per \\(\\mu\\)?\nIl valore migliore di \\(\\mu\\) sarà quello che rende massima la verosimiglianza. In questo semplice caso, è esattamente il valore osservato (114):\n\nmu_ottimale &lt;- mu_values[which.max(likelihood)]\ncat(\"Il valore ottimale di μ è:\", mu_ottimale)\n#&gt; Il valore ottimale di μ è: 114\n\n\n42.8.2 Log-verosimiglianza\nSpesso, per semplicità di calcolo, si usa la log-verosimiglianza, che trasforma i prodotti in somme, rendendo i calcoli più semplici e stabili:\n\\[\n\\log L(\\mu \\mid y, \\sigma) = -\\frac{1}{2}\\log(2\\pi) - \\log(\\sigma) - \\frac{(y-\\mu)^2}{2\\sigma^2}.\n\\]\nCalcolo pratico con R:\n\n# Funzione di log-verosimiglianza negativa usando dnorm()\nnegative_log_likelihood &lt;- function(mu, y, sigma) {\n  # Ritorniamo il valore negativo della log-verosimiglianza\n  -dnorm(y, mean = mu, sd = sigma, log = TRUE)\n}\n\nresult &lt;- optim(\n  par = 100, # Valore iniziale\n  fn = negative_log_likelihood,\n  y = y_obs,\n  sigma = sigma,\n  method = \"L-BFGS-B\",\n  lower = 70,\n  upper = 160\n)\n\nmu_max_loglik &lt;- result$par\ncat(\"Il valore ottimale di μ dalla log-verosimiglianza è:\", mu_max_loglik)\n#&gt; Il valore ottimale di μ dalla log-verosimiglianza è: 114\n\nIn questo caso, otteniamo nuovamente \\(\\mu = 114\\).\n\n42.8.3 Campione di osservazioni indipendenti\nSupponiamo di aver raccolto i punteggi alla scala BDI-II per 30 persone. Ciascun punteggio è un’osservazione indipendente da una distribuzione normale con media incognita \\(\\mu\\) e deviazione standard nota \\(\\sigma = 6.5\\).\n\n# Dati osservati (punteggi BDI-II)\ny &lt;- c(\n  26, 35, 30, 25, 44, 30, 33, 43, 22, 43, 24, 19, 39, 31, 25, \n  28, 35, 30, 26, 31, 41, 36, 26, 35, 33, 28, 27, 34, 27, 22\n)\n\nsigma &lt;- 6.5\n\n\n42.8.4 Calcolo della log-verosimiglianza\nDefiniamo una funzione che calcola la log-verosimiglianza totale:\n\nlog_likelihood &lt;- function(mu, y, sigma) {\n  sum(dnorm(y, mean = mu, sd = sigma, log = TRUE))\n}\n\nEsploriamo ora un intervallo di valori plausibili per \\(\\mu\\) e calcoliamo la log-verosimiglianza per ciascun valore:\n\n# Intervallo di valori possibili per μ\nmu_range &lt;- seq(mean(y) - 2 * sigma, mean(y) + 2 * sigma, length.out = 1000)\n\n# Inizializza vettore dei risultati\nlog_lik_values &lt;- numeric(length(mu_range))\n\n# Ciclo esplicito per chiarezza didattica\nfor (i in seq_along(mu_range)) {\n  mu_val &lt;- mu_range[i]\n  log_lik_values[i] &lt;- log_likelihood(mu_val, y, sigma)\n}\n\n\n42.8.5 Visualizzazione della log-verosimiglianza\n\nggplot(\n  data.frame(mu = mu_range, log_likelihood = log_lik_values),\n  aes(x = mu, y = log_likelihood)\n) +\n  geom_line(linewidth = 1.2) +\n  geom_vline(xintercept = mean(y), linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Log-verosimiglianza per punteggi BDI-II\",\n    x = expression(mu),\n    y = \"Log-verosimiglianza\"\n  )\n\n\n\n\n\n\n\nLa linea tratteggiata rossa indica la media campionaria, che — come ci aspettiamo — è anche il valore che massimizza la log-verosimiglianza.\n\n42.8.6 Ottimizzazione numerica\nSe volessimo calcolare il valore ottimale di \\(\\mu\\) in modo automatico:\n\n# Funzione negativa da minimizzare\nnegative_log_likelihood &lt;- function(mu, y, sigma) {\n  -sum(dnorm(y, mean = mu, sd = sigma, log = TRUE))\n}\n\n# Ottimizzazione con limiti\nresult &lt;- optim(\n  par = mean(y),                   # Valore iniziale\n  fn = negative_log_likelihood,   # Funzione da minimizzare\n  y = y,\n  sigma = sigma,\n  method = \"L-BFGS-B\",\n  lower = min(mu_range),\n  upper = max(mu_range)\n)\n\nmu_optimal &lt;- result$par\ncat(\"Il valore ottimale di μ è:\", mu_optimal)\n#&gt; Il valore ottimale di μ è: 30.93\n\n\nAbbiamo utilizzato dnorm(..., log = TRUE) per calcolare in modo semplice e numericamente stabile la log-verosimiglianza.\nIl valore di \\(\\mu\\) che massimizza la log-verosimiglianza corrisponde alla media campionaria.\nQuesto è un caso in cui la stima di massima verosimiglianza ha una forma chiusa, ma l’approccio numerico resta utile e generalizzabile.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#il-rapporto-di-verosimiglianze",
    "href": "chapters/probability/15_likelihood.html#il-rapporto-di-verosimiglianze",
    "title": "42  La verosimiglianza",
    "section": "\n42.9 Il rapporto di verosimiglianze",
    "text": "42.9 Il rapporto di verosimiglianze\nQuando conduciamo un’analisi statistica, spesso ci troviamo di fronte alla necessità di confrontare due modelli che cercano di spiegare gli stessi dati. Immaginiamo, ad esempio, di voler capire qual è la media di una certa variabile (come il punteggio a un test, il tempo di reazione, ecc.). Potremmo avere due ipotesi alternative sull’effettivo valore della media:\n\nsecondo un primo modello, la media è \\(\\mu_1\\) (ad esempio, l’ipotesi “nulla”, che rappresenta uno stato di riferimento o di assenza di effetto),\nsecondo un secondo modello, la media è \\(\\mu_2\\) (ad esempio, l’ipotesi “alternativa”, che rappresenta un cambiamento o un effetto).\n\nPer decidere quale modello è più compatibile con i dati osservati, possiamo usare la verosimiglianza (likelihood). La verosimiglianza misura quanto bene un certo valore del parametro spiega i dati osservati. Più la verosimiglianza è alta, più i dati sono “coerenti” con quel valore.\n\n42.9.1 Il confronto\nPer confrontare i due modelli, calcoliamo la verosimiglianza dei dati in ciascun caso, e ne facciamo il rapporto:\n\\[\n\\lambda = \\frac{L(\\mu_2 \\mid \\text{dati})}{L(\\mu_1 \\mid \\text{dati})}\n\\tag{42.1}\\]\ndove:\n\n\n\\(L(\\mu_2 \\mid \\text{dati})\\) è la verosimiglianza del modello alternativo (cioè, quanto sono compatibili i dati con \\(\\mu_2\\)),\n\n\\(L(\\mu_1 \\mid \\text{dati})\\) è la verosimiglianza del modello nullo (cioè, quanto sono compatibili i dati con \\(\\mu_1\\)).\n\nQuesta quantità si chiama rapporto di verosimiglianze (likelihood ratio, LR), e rappresenta uno strumento per quantificare quanto i dati favoriscono un modello rispetto all’altro.\n\n42.9.2 Come si interpreta \\(\\lambda\\)?\n\nSe \\(\\lambda &gt; 1\\), significa che i dati supportano più il modello alternativo: i dati sono più probabili sotto \\(\\mu_2\\) che sotto \\(\\mu_1\\).\nSe \\(\\lambda &lt; 1\\), significa che i dati supportano più il modello nullo: i dati sono più probabili sotto \\(\\mu_1\\) che sotto \\(\\mu_2\\).\nSe \\(\\lambda \\approx 1\\), allora i dati non permettono di distinguere chiaramente tra i due modelli.\n\nIl rapporto di verosimiglianze ci dice quale modello rende i dati osservati più “plausibili”.\n\n42.9.3 Un esempio\nImmagina di aver lanciato una moneta 10 volte e di aver ottenuto 7 teste. Ti chiedi ora quale tra questi due modelli spiega meglio i dati:\n\n\nModello 1 (nullo): la moneta è equa, quindi la probabilità di testa è \\(\\mu_1 = 0.5\\);\n\nModello 2 (alternativo): la moneta è truccata a favore delle teste, e la probabilità di testa è \\(\\mu_2 = 0.7\\).\n\n42.9.4 Calcolo delle verosimiglianze\nUseremo la distribuzione binomiale, che descrive il numero di successi (in questo caso, teste) in un numero fisso di prove (10 lanci), dato un certo valore di probabilità.\nLa verosimiglianza è semplicemente la probabilità di ottenere 7 teste su 10 lanci, sotto ciascun modello:\n\n\nsotto il modello nullo (\\(\\mu_1 = 0.5\\)):\n\\[\nL(0.5 \\mid \\text{7 teste}) = \\binom{10}{7} (0.5)^7 (1 - 0.5)^3 = 120 \\cdot (0.5)^{10} \\approx 0.117\n\\]\n\n\nsotto il modello alternativo (\\(\\mu_2 = 0.7\\)):\n\\[\nL(0.7 \\mid \\text{7 teste}) = \\binom{10}{7} (0.7)^7 (0.3)^3 \\approx 120 \\cdot 0.0824 \\cdot 0.027 = 0.267\n\\]\n\n\n42.9.5 Calcolo del rapporto di verosimiglianze\nOra possiamo calcolare il rapporto:\n\\[\n\\lambda = \\frac{L(0.7 \\mid \\text{7 teste})}{L(0.5 \\mid \\text{7 teste})} \\approx \\frac{0.267}{0.117} \\approx 2.28\n\\]\nQuesto significa che i dati sono circa 2.3 volte più compatibili con l’ipotesi che la moneta sia truccata (con \\(\\mu = 0.7\\)) rispetto a quella che sia equa (\\(\\mu = 0.5\\)).\n\n42.9.6 Visualizzare le funzioni di verosimiglianza\nPossiamo visualizzare graficamente come cambia la verosimiglianza al variare della probabilità di testa (\\(\\theta\\)), mantenendo fisso il numero di lanci e il numero di teste osservate.\n\n42.9.6.1 Codice R\n\n# Parametri osservati\nn &lt;- 10        # numero totale di lanci\nx &lt;- 7         # numero di teste osservate\n\n# Sequenza di probabilità (theta)\ntheta &lt;- seq(0, 1, length.out = 100)\n\n# Verosimiglianza per ogni theta\nlikelihood &lt;- dbinom(x, size = n, prob = theta)\n\n# Crea dataframe per ggplot\ndf &lt;- data.frame(theta = theta, likelihood = likelihood)\n\n# Verosimiglianza nei due modelli\nL_0.5 &lt;- dbinom(x, size = n, prob = 0.5)\nL_0.7 &lt;- dbinom(x, size = n, prob = 0.7)\nLR &lt;- L_0.7 / L_0.5\n\n# Crea grafico\nggplot(df, aes(x = theta, y = likelihood)) +\n  geom_line(linewidth = 1.2) +\n  geom_vline(xintercept = 0.5, linetype = \"dashed\", color = \"red\") +\n  geom_vline(xintercept = 0.7, linetype = \"dashed\", color = \"darkgreen\") +\n  geom_point(aes(x = 0.5, y = L_0.5), color = \"red\", size = 3) +\n  geom_point(aes(x = 0.7, y = L_0.7), color = \"darkgreen\", size = 3) +\n  labs(\n    title = \"Funzione di verosimiglianza per 7 teste su 10 lanci\",\n    x = expression(theta),\n    y = \"Verosimiglianza\"\n  ) +\n  annotate(\n    \"text\", x = 0.5, y = L_0.5 + 0.01, \n    label = \"mu == 0.5\", \n    parse = TRUE, hjust = -0.2, color = \"red\"\n  ) +\n  annotate(\n    \"text\", x = 0.7, y = L_0.7 + 0.01, \n    label = \"mu == 0.7\", parse = TRUE, hjust = -0.2, color = \"darkgreen\")\n\n\n\n\n\n\n\n\n# Stampa dei risultati numerici\ncat(\"L(mu = 0.5) =\", round(L_0.5, 3), \"\\n\")\n#&gt; L(mu = 0.5) = 0.117\ncat(\"L(mu = 0.7) =\", round(L_0.7, 3), \"\\n\")\n#&gt; L(mu = 0.7) = 0.267\ncat(\"Likelihood Ratio =\", round(LR, 2), \"\\n\")\n#&gt; Likelihood Ratio = 2.28\n\nIl grafico mostra come cambia la verosimiglianza al variare di \\(\\theta\\), e indica visivamente i valori assunti nei due modelli specifici. Si vede chiaramente che \\(\\theta = 0.7\\) è più compatibile con l’osservazione di 7 teste.\nIn sintesi, il rapporto di verosimiglianze è uno strumento per confrontare due ipotesi. Non richiede che una delle due sia vera, ma solo di confrontare quanto bene ciascuna spiega i dati osservati. In questo esempio, i dati favoriscono l’ipotesi che la moneta sia truccata, ma non in modo schiacciante. Il valore di \\(\\lambda = 2.28\\) indica un’evidenza moderata a favore del modello alternativo.\n\n42.9.7 Rapporti di verosimiglianza aggiustati e criterio di Akaike\nSpesso il rapporto di verosimiglianza “grezzo” (\\(\\lambda\\)) deve essere aggiustato per tenere conto della differenza nel numero di parametri tra i modelli confrontati. Infatti, quando confrontiamo due modelli, quello con più parametri tende quasi sempre a descrivere meglio i dati osservati, ma ciò può essere dovuto semplicemente alla sua maggiore complessità. Questo fenomeno è noto come sovradattamento (overfitting).\nPer correggere questa tendenza, si usa un rapporto di verosimiglianza aggiustato (Adjusted Likelihood Ratio, indicato con \\(\\lambda_{\\text{adj}}\\). Questo tipo di aggiustamento penalizza i modelli più complessi, rendendo il confronto tra modelli più equo e affidabile.\n\n42.9.8 Relazione con il criterio di Akaike (AIC)\nUna modalità comune per effettuare questa correzione è tramite il Criterio di Akaike (AIC). L’AIC è definito come:\n\\[\n\\text{AIC} = 2k - 2\\log(\\lambda),\n\\tag{42.2}\\]\nin cui:\n\n\n\\(k\\) è il numero dei parametri del modello.\n\n\\(\\lambda\\) è il rapporto di verosimiglianza grezzo.\n\nDa questa equazione possiamo ricavare una formula per calcolare il rapporto di verosimiglianza aggiustato utilizzando l’AIC:\n\\[\n\\lambda_{\\text{adj}} = \\lambda \\times e^{(k_1 - k_2)},\n\\]\ndove:\n\n\n\\(k_1\\) è il numero di parametri del modello più semplice,\n\n\\(k_2\\) è il numero di parametri del modello più complesso,\n\n\\(e^{(k_1 - k_2)}\\) è il fattore correttivo che penalizza il modello più complesso.\n\nIn breve, più parametri ha un modello, maggiore sarà la penalizzazione applicata.\n\n42.9.9 Rapporto tra Likelihood Ratio e AIC\nIl rapporto di verosimiglianza aggiustato tramite l’AIC consente di confrontare in modo equo modelli con un numero differente di parametri. Senza questa correzione, rischieremmo di scegliere sempre modelli più complessi, indipendentemente dalla loro reale capacità esplicativa, con il rischio di sovrastimare la qualità della loro spiegazione.\nUtilizzare il rapporto di verosimiglianza aggiustato, quindi, permette di scegliere il modello migliore considerando sia la capacità di adattarsi ai dati, sia la semplicità del modello stesso.\n\n42.9.10 Illustrazione\nImmaginiamo un semplice esperimento psicologico sulla memoria visiva. Vogliamo capire se mostrare immagini emotivamente intense aiuta le persone a ricordare meglio, rispetto a immagini neutre.\nAbbiamo due gruppi di partecipanti:\n\nil gruppo neutro vede 30 immagini neutre e ne ricorda correttamente 14;\nil gruppo emozionale vede 30 immagini emotivamente intense e ne ricorda 22.\n\n42.9.11 Obiettivo\nVogliamo confrontare due modelli alternativi:\n\n\nmodello nullo (H₀): la probabilità di ricordare un’immagine è uguale nei due gruppi;\n\nmodello alternativo (H₁): la probabilità di ricordare è diversa nei due gruppi.\n\n42.9.12 Dati osservati\n\nsuccessi_neutro &lt;- 14\nsuccessi_emozione &lt;- 22\nprove &lt;- 30\n\n\n42.9.13 1. Calcolo della verosimiglianza\nIpotesi nulla: probabilità comune.\nSe la probabilità è la stessa in entrambi i gruppi, possiamo stimarla combinando i successi totali:\n\np_null &lt;- (successi_neutro + successi_emozione) / (2 * prove)\n\nLog-verosimiglianza sotto H₀.\nSotto l’ipotesi nulla, i dati di entrambi i gruppi devono essere spiegati da una sola probabilità:\n\nll_null &lt;- dbinom(successi_neutro, prove, p_null, log = TRUE) + \n           dbinom(successi_emozione, prove, p_null, log = TRUE)\n\nIpotesi alternativa: probabilità diversa per ogni gruppo.\nStimiamo separatamente la probabilità di ricordare in ciascun gruppo:\n\np_neutro &lt;- successi_neutro / prove\np_emozione &lt;- successi_emozione / prove\n\nLog-verosimiglianza sotto H₁.\nOgni gruppo ha la propria verosimiglianza:\n\nll_alt &lt;- dbinom(successi_neutro, prove, p_neutro, log = TRUE) + \n          dbinom(successi_emozione, prove, p_emozione, log = TRUE)\n\n\n42.9.14 2. Confronto tra modelli\nRapporto di verosimiglianza (non penalizzato).\nCalcoliamo il rapporto tra le due verosimiglianze:\n\nlr &lt;- exp(ll_alt - ll_null)\n\nQuesto ci dice quanto meglio il modello alternativo spiega i dati rispetto al modello nullo.\n\n42.9.15 3. Penalizzazione per la complessità\nI modelli più complessi tendono a spiegare meglio i dati, ma rischiano di adattarsi troppo. Per questo, usiamo un criterio che penalizza la complessità: l’AIC (Akaike Information Criterion).\nNumero di parametri:\n\nk_null &lt;- 1  # un'unica probabilità per entrambi i gruppi\nk_alt &lt;- 2   # probabilità distinte per ciascun gruppo\n\nCalcolo dell’AIC per ciascun modello:\n\nAIC_null &lt;- 2 * k_null - 2 * ll_null\nAIC_alt &lt;- 2 * k_alt - 2 * ll_alt\n\nRapporto di verosimiglianza aggiustato.\nUsiamo l’AIC per calcolare una versione penalizzata del rapporto di verosimiglianze:\n\nlr_adj &lt;- exp((AIC_null - AIC_alt) / 2)\n\nRisultati:\n\ncat(\"Rapporto di verosimiglianza grezzo:\", round(lr, 2), \"\\n\")\n#&gt; Rapporto di verosimiglianza grezzo: 9.54\ncat(\"Rapporto di verosimiglianza aggiustato (λ_adj):\", round(lr_adj, 2), \"\\n\")\n#&gt; Rapporto di verosimiglianza aggiustato (λ_adj): 3.51\n\nInterpretazione:\n\nse λ_adj &gt; 1, i dati sono più compatibili con il modello alternativo (due probabilità distinte);\nse λ_adj ≈ 1, non c’è abbastanza evidenza per preferire un modello all’altro.\n\n42.9.16 4. Test del rapporto di verosimiglianza\nPossiamo testare formalmente se la differenza tra i modelli è rilevante o potrebbe essere dovuta al caso.\nLa statistica test è:\n\\[\n-2 \\cdot (\\log L_{H_0} - \\log L_{H_1})\n\\]\nQuesta statistica segue (approssimativamente) una distribuzione chi-quadrato con un numero di gradi di libertà pari alla differenza nel numero di parametri tra i modelli:\n\nLR_test &lt;- -2 * (ll_null - ll_alt)\ndf &lt;- k_alt - k_null\np_value &lt;- 1 - pchisq(LR_test, df)\n\ncat(\"Statistica test (-2 log LR):\", round(LR_test, 2), \"\\n\")\n#&gt; Statistica test (-2 log LR): 4.51\ncat(\"Gradi di libertà:\", df, \"\\n\")\n#&gt; Gradi di libertà: 1\ncat(\"Valore p del test:\", round(p_value, 4), \"\\n\")\n#&gt; Valore p del test: 0.0337\n\nIn sintesi,\n\nse p &lt; 0.05, possiamo concludere che il modello alternativo è da preferire: i dati sono difficilmente compatibili con l’ipotesi di probabilità uguali nei due gruppi;\nse p &gt; 0.05, non abbiamo evidenza sufficiente per preferire il modello alternativo.\n\nNel nostro esempio:\n\nla statistica test è ≈ 4.48;\nil valore-p è ≈ 0.0337.\n\nPoiché il valore-p è inferiore a 0.05, possiamo concludere che il gruppo emozionale ha una probabilità di ricordare credibilmente diversa da quella del gruppo neutro.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#riflessioni-conclusive",
    "href": "chapters/probability/15_likelihood.html#riflessioni-conclusive",
    "title": "42  La verosimiglianza",
    "section": "\n42.10 Riflessioni conclusive",
    "text": "42.10 Riflessioni conclusive\nLa funzione di verosimiglianza costituisce il fulcro dell’inferenza statistica, permettendo di quantificare la plausibilità dei parametri di un modello alla luce dei dati osservati. La sua costruzione poggia su tre elementi fondamentali: la scelta del modello generatore dei dati, lo spazio dei parametri e le evidenze empiriche.\nNel caso di modelli binomiali e gaussiani, la verosimiglianza assume forme analiticamente maneggevoli, facilitando sia la stima puntuale che la valutazione di ipotesi. In particolare:\n\n\nPer la distribuzione normale, la stima di massima verosimiglianza di \\(\\mu\\) coincide con la media campionaria, mentre la sua rappresentazione grafica fornisce un’indicazione visiva della precisione della stima.\n\n\nL’uso della log-verosimiglianza non solo semplifica i calcoli, ma migliora anche la stabilità numerica, specialmente in contesti con campioni di grandi dimensioni.\n\n\nIl rapporto di verosimiglianza emerge come strumento versatile, capace di coniugare bontà di adattamento e parsimonia, come dimostrato da criteri quali l’AIC.\n\nIn definitiva, la verosimiglianza – nelle sue diverse forme – non solo funge da ponte tra modelli teorici e dati empirici, ma (come vedremo in seguito) è anche il motore dell’inferenza bayesiana, trasformando l’informazione a priori in distribuzioni posteriori attraverso il teorema di Bayes.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#esercizi",
    "href": "chapters/probability/15_likelihood.html#esercizi",
    "title": "42  La verosimiglianza",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nSpiega ciascuno dei concetti seguenti con una frase:\n\nprobabilità.\nfunzione di massa di probabilità.\nfunzione di densità di probabilità.\ndistribuzione di probabilità.\ndistribuzione di probabilità discreta.\ndistribuzione di probabilità continua.\nfunzione di distribuzione cumulativa (cdf).\nverosimiglianza\n\n\n\n\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nSupponi di aver misurato il livello di ansia (ad esempio usando una scala standardizzata) in un campione di 15 persone con i seguenti punteggi:\nansia &lt;- c(23, 27, 30, 29, 25, 28, 26, 24, 31, 29, 27, 26, 28, 30, 25)\nAssumendo che la deviazione standard sia nota e pari a 3.5, svolgi le seguenti attività in R:\n\nCalcola la funzione di verosimiglianza gaussiana per diversi valori di \\(\\mu\\) nell’intervallo da 20 a 35.\nTrova numericamente il valore di \\(\\mu\\) che rende massima la verosimiglianza (stima di massima verosimiglianza, MLE).\nDisegna un grafico della funzione di verosimiglianza per visualizzare il risultato.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/15_likelihood.html#informazioni-sullambiente-di-sviluppo",
    "title": "42  La verosimiglianza",
    "section": "Informazioni sull’ambiente di sviluppo",
    "text": "Informazioni sull’ambiente di sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pillar_1.11.0         tinytable_0.11.0      patchwork_1.3.1      \n#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.13.0     \n#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.0     \n#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [16] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [19] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [22] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.6         tidyselect_1.2.1     farver_2.1.2        \n#&gt;  [4] fastmap_1.2.0        TH.data_1.1-3        tensorA_0.36.2.1    \n#&gt;  [7] digest_0.6.37        estimability_1.5.1   timechange_0.3.0    \n#&gt; [10] lifecycle_1.0.4      survival_3.8-3       magrittr_2.0.3      \n#&gt; [13] compiler_4.5.1       rlang_1.1.6          tools_4.5.1         \n#&gt; [16] knitr_1.50           labeling_0.4.3       bridgesampling_1.1-2\n#&gt; [19] htmlwidgets_1.6.4    pkgbuild_1.4.8       curl_6.4.0          \n#&gt; [22] RColorBrewer_1.1-3   abind_1.4-8          multcomp_1.4-28     \n#&gt; [25] withr_3.0.2          purrr_1.1.0          grid_4.5.1          \n#&gt; [28] stats4_4.5.1         xtable_1.8-4         colorspace_2.1-1    \n#&gt; [31] inline_0.3.21        emmeans_1.11.2       scales_1.4.0        \n#&gt; [34] MASS_7.3-65          cli_3.6.5            mvtnorm_1.3-3       \n#&gt; [37] rmarkdown_2.29       generics_0.1.4       RcppParallel_5.1.10 \n#&gt; [40] cachem_1.1.0         stringr_1.5.1        splines_4.5.1       \n#&gt; [43] parallel_4.5.1       vctrs_0.6.5          V8_6.0.5            \n#&gt; [46] Matrix_1.7-3         sandwich_3.1-1       jsonlite_2.0.0      \n#&gt; [49] arrayhelpers_1.1-0   glue_1.8.0           codetools_0.2-20    \n#&gt; [52] distributional_0.5.0 lubridate_1.9.4      stringi_1.8.7       \n#&gt; [55] gtable_0.3.6         QuickJSR_1.8.0       htmltools_0.5.8.1   \n#&gt; [58] Brobdingnag_1.2-9    R6_2.6.1             rprojroot_2.1.0     \n#&gt; [61] evaluate_1.0.4       lattice_0.22-7       backports_1.5.0     \n#&gt; [64] memoise_2.0.1        broom_1.0.9          snakecase_0.11.1    \n#&gt; [67] rstantools_2.4.0     coda_0.19-4.1        gridExtra_2.3       \n#&gt; [70] nlme_3.1-168         checkmate_2.3.2      xfun_0.52           \n#&gt; [73] zoo_1.8-14           pkgconfig_2.0.3",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#bibliografia",
    "href": "chapters/probability/15_likelihood.html#bibliografia",
    "title": "42  La verosimiglianza",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/introduction_bayes_inference.html",
    "href": "chapters/bayesian_inference/introduction_bayes_inference.html",
    "title": "Introduzione",
    "section": "",
    "text": "L’Inferenza Bayesiana nella Ricerca Psicologica: Un Approccio Integrato\nNel campo della psicologia, la valutazione dell’efficacia di un trattamento clinico rappresenta una sfida metodologica centrale. Immaginiamo, per esempio, di voler testare l’utilità di una nuova psicoterapia per la depressione. Come possiamo concludere, in modo credibile, che il trattamento funzioni? L’approccio tradizionale, di matrice frequentista, risponde a questa domanda confrontando le medie dei punteggi tra un gruppo sperimentale e un gruppo di controllo, producendo un p-value. Questo valore quantifica quanto sarebbe improbabile osservare una differenza così grande o più estrema se il trattamento non avesse alcun effetto. Tuttavia, tale procedura presenta limiti sostanziali, soprattutto quando applicata a fenomeni complessi e variabili come quelli psicologici.",
    "crumbs": [
      "Inferenza",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/introduction_bayes_inference.html#linferenza-bayesiana-nella-ricerca-psicologica-un-approccio-integrato",
    "href": "chapters/bayesian_inference/introduction_bayes_inference.html#linferenza-bayesiana-nella-ricerca-psicologica-un-approccio-integrato",
    "title": "Introduzione",
    "section": "",
    "text": "Limiti dell’approccio frequentista nella ricerca applicata\nL’inferenza frequentista, pur ampiamente diffusa, non fornisce risposte alla domanda che davvero interessa chi fa ricerca: qual è la probabilità che il trattamento sia efficace, dati i risultati osservati? Il p-value non esprime questa probabilità, ma si riferisce alla possibilità di osservare i dati ottenuti assumendo che l’effetto non esista, ovvero sotto l’ipotesi nulla. È una misura indiretta e controfattuale, che spesso viene fraintesa.\nUn secondo limite importante è l’incapacità dell’approccio frequentista di integrare conoscenze pregresse. Ogni studio viene trattato come un evento isolato, ignorando le evidenze precedenti e le ipotesi teoriche consolidate. Inoltre, il confronto tra medie non permette di modellare i meccanismi psicologici sottostanti, come i processi di mediazione o moderazione, che sono invece centrali per comprendere il funzionamento degli interventi.\nVa considerato anche che la significatività statistica dipende fortemente dalla dimensione campionaria: un effetto piccolo può risultare “statisticamente significativo” in un campione molto ampio, e viceversa. Infine, la logica binaria “significativo/non significativo” imposta una dicotomia artificiosa su fenomeni che sono, per loro natura, continui e incerti. In psicologia, dove le sfumature e le differenze individuali sono cruciali, questa rigidità metodologica si rivela particolarmente problematica.\nL’approccio bayesiano: un’alternativa coerente e flessibile\nL’inferenza bayesiana propone un modo differente di pensare l’analisi dei dati: più naturale, flessibile e informativo. Si basa sull’idea che possiamo iniziare con una convinzione preliminare — rappresentata da una distribuzione a priori — e aggiornarla alla luce delle nuove osservazioni — attraverso la verosimiglianza — per ottenere una distribuzione a posteriori. Questo procedimento riflette il modo in cui ragioniamo quotidianamente. Per esempio, se ci svegliamo e vediamo il cielo coperto, possiamo stimare intuitivamente che c’è una probabilità del 70% che piova: un’inferenza soggettiva basata su esperienze pregresse, che può essere aggiornata osservando altri segnali, come il meteo sul telefono.\nApplicando questo approccio alla ricerca psicologica, possiamo non solo rispondere alla domanda se un trattamento funziona, ma anche formulare stime probabilistiche dirette sull’efficacia, integrare conoscenze precedenti e modellare i processi psicologici sottostanti. In questo contesto, il modello bayesiano consente una lettura più profonda dei dati, sia teoricamente che praticamente.\nUn Esempio Concreto: Modellizzazione di un Effetto di Mediazione con un Approccio Bayesiano\nIn psicologia clinica, spesso si ipotizza che un intervento non agisca direttamente su un esito, ma attraverso un meccanismo intermedio. Questo è noto come effetto di mediazione.\nConsideriamo un’ipotesi di ricerca comune: una psicoterapia (variabile indipendente, \\(X\\)) non riduce i sintomi depressivi (variabile dipendente, \\(Y\\)) in modo diretto, ma agendo su una variabile mediatrice, come l’autoefficacia (mediatore, \\(M\\)).\nIl modello di mediazione può essere scomposto in tre percorsi:\n\n\nPercorso a: L’effetto del trattamento (\\(X\\)) sul mediatore (\\(M\\)). La psicoterapia aumenta l’autoefficacia?\n\nPercorso b: L’effetto del mediatore (\\(M\\)) sull’esito (\\(Y\\)), tenendo sotto controllo l’effetto del trattamento. Una maggiore autoefficacia riduce la depressione?\n\nPercorso c’ (c-primo): L’effetto diretto del trattamento (\\(X\\)) sull’esito (\\(Y\\)), al netto del mediatore.\n\nL’effetto indiretto (o mediato) è quantificato dal prodotto dei percorsi a e b (\\(a \\times b\\)). L’approccio bayesiano è particolarmente potente per stimare questo effetto, poiché ci permette di ottenere una distribuzione di probabilità completa per \\(a \\times b\\), invece di un singolo valore puntuale e un p-value.\nPer illustrare, simuliamo dei dati in R che rispecchino la nostra ipotesi.\n\nset.seed(42)\nn_per_group &lt;- 40\nn &lt;- n_per_group * 2\n\n# Gruppo 0: Controllo, Gruppo 1: Trattamento\ngroup &lt;- rep(c(0, 1), each = n_per_group)\n\n# Path 'a': Il trattamento aumenta l'autoefficacia di circa 8 punti.\n# Aggiungiamo un termine di errore con deviazione standard 5.\na_path &lt;- 8\nself_efficacy &lt;- rnorm(n, mean = 40 + a_path * group, sd = 5)\n\n# Path 'b': Ogni punto di autoefficacia riduce la depressione di 0.7 punti.\n# Path 'c'': Ipotizziamo un piccolo effetto diretto del trattamento (-1.5 punti).\n# Aggiungiamo un termine di errore con deviazione standard 4.\nb_path &lt;- -0.7\nc_prime_path &lt;- -1.5\ndepression &lt;- rnorm(n, mean = 30 + b_path * self_efficacy + c_prime_path * group, sd = 4)\n\n# Creazione del dataframe\ndati &lt;- tibble(\n  group = factor(group, labels = c(\"Controllo\", \"Psicoterapia\")),\n  self_efficacy,\n  depression\n)\n\nUn Primo Sguardo: Confronto tra le Medie\nUn’analisi preliminare può confrontare i livelli medi di depressione tra i due gruppi.\n\ndati %&gt;%\n  group_by(group) %&gt;%\n  summarise(\n    media_depressione = mean(depression),\n    sd_depressione = sd(depression)\n  )\n#&gt; # A tibble: 2 × 3\n#&gt;   group        media_depressione sd_depressione\n#&gt;   &lt;fct&gt;                    &lt;dbl&gt;          &lt;dbl&gt;\n#&gt; 1 Controllo                 2.33           5.31\n#&gt; 2 Psicoterapia             -6.41           4.49\n\nQuesto mostra un effetto complessivo (il gruppo “Psicoterapia” ha una media di depressione più bassa), ma non ci permette di capire come l’intervento funzioni, ovvero se l’effetto sia mediato dall’autoefficacia.\nCostruzione del Modello di Mediazione Bayesiano\nPer stimare l’effetto indiretto, definiamo un sistema di due equazioni di regressione che corrispondono ai percorsi del nostro modello:\n\n\nModello per il mediatore (\\(M\\)): \\(self\\_efficacy \\sim \\mathcal{N}(\\alpha_M + a \\cdot group, \\sigma_M)\\)\n\n\nModello per l’esito (\\(Y\\)): \\(depression \\sim \\mathcal{N}(\\alpha_Y + c' \\cdot group + b \\cdot self\\_efficacy, \\sigma_Y)\\)\n\n\nUsiamo il pacchetto brms per fittare questi due modelli.\n\n# Modello 1: Stima del percorso 'a' (group -&gt; self_efficacy)\nfit1 &lt;- brm(\n  bf(self_efficacy ~ group),\n  data = dati,\n  family = gaussian(),\n  seed = 42,\n  refresh = 0,\n  backend = \"cmdstanr\"\n)\n\n# Modello 2: Stima dei percorsi 'b' (self_efficacy -&gt; depression) e 'c'' (group -&gt; depression)\nfit2 &lt;- brm(\n  bf(depression ~ self_efficacy + group),\n  data = dati,\n  family = gaussian(),\n  seed = 42,\n  refresh = 0,\n  backend = \"cmdstanr\"\n)\n\nStima e Interpretazione dell’Effetto Indiretto\nOra combiniamo i risultati. Estraiamo i campioni dalla distribuzione a posteriori per il coefficiente del percorso a (b_groupPsicoterapia da fit1) e per il percorso b (b_self_efficacy da fit2). Il loro prodotto ci fornirà la distribuzione a posteriori dell’effetto indiretto (\\(a \\times b\\)).\n\n# Estrazione dei campioni dalle distribuzioni a posteriori\npost_fit1 &lt;- as_draws_df(fit1)\npost_fit2 &lt;- as_draws_df(fit2)\n\n# Calcolo della distribuzione a posteriori dell'effetto indiretto\nindirect_effect &lt;- post_fit1$b_groupPsicoterapia * post_fit2$b_self_efficacy\n\nAnalizziamo la distribuzione dell’effetto indiretto calcolandone la media e l’intervallo di credibilità al 95%.\n\n# Media a posteriori\nmean(indirect_effect)\n#&gt; [1] -5.308\n\n# Intervallo di Credibilità al 95%\nquantile(indirect_effect, probs = c(0.025, 0.975))\n#&gt;   2.5%  97.5% \n#&gt; -7.416 -3.442\n\nL’analisi bayesiana restituisce una stima media dell’effetto indiretto di circa -5.4 e un intervallo di credibilità al 95% che va da circa -7.7 a -3.4.\nInterpretazione Clinica\nPoiché l’intervallo di credibilità non contiene lo zero, abbiamo una forte evidenza a favore di un effetto di mediazione. Possiamo comunicare il risultato in modo intuitivo e probabilistico:\n\n“C’è una probabilità del 95% che la riduzione media dei sintomi depressivi, attribuibile all’aumento di autoefficacia indotto dalla psicoterapia, sia compresa tra 3.4 e 7.7 punti sulla scala della depressione.”\n\nQuesta formulazione è più informativa di un semplice p-value. Non solo ci dice che l’effetto è “statisticamente significativo”, ma ne quantifica la magnitudine e la nostra incertezza su di essa, fornendo uno strumento molto più ricco per la valutazione clinica e la presa di decisioni. Invece di un p-value, otteniamo un intervallo di credibilità, ad esempio: “Con probabilità del 95%, l’intervento riduce la depressione attraverso l’autoefficacia di almeno 3.4 punti.” Questa formulazione è più intuitiva e direttamente utile per decisioni cliniche.\nVantaggi principali dell’inferenza bayesiana\nL’approccio bayesiano presenta diversi vantaggi chiave: le assunzioni del modello sono esplicitate attraverso le distribuzioni a priori; la modellizzazione è flessibile e adattabile a processi psicologici complessi; le conclusioni si esprimono in termini probabilistici e non binari; l’approccio si adatta bene anche a campioni piccoli, grazie all’incorporazione di conoscenze pregresse.\nApplicazioni pratiche\nL’inferenza bayesiana non è una curiosità teorica: è ampiamente utilizzata in moltissimi contesti applicativi. Nei sistemi di raccomandazione (Netflix, Spotify), le preferenze degli utenti vengono aggiornate in tempo reale attraverso modelli bayesiani. Nei test A/B su larga scala (Google, Meta), il framework bayesiano consente di monitorare gli esperimenti in tempo reale, di interromperli precocemente se necessario, e di sfruttare esperienze passate per informare nuovi studi.\nIn medicina, l’approccio bayesiano è implicito nel modo in cui i medici interpretano i test diagnostici: combinano la prevalenza della malattia, la sensibilità e la specificità del test per stimare la probabilità che il paziente sia malato. Lo stesso accade nella finanza comportamentale, nella guida autonoma e nell’epidemiologia, come dimostrato durante la pandemia da COVID-19, dove i modelli bayesiani hanno permesso di stimare in tempo reale la diffusione del virus e l’efficacia delle misure di contenimento.\nAnche nella ricerca psicologica l’inferenza bayesiana offre strumenti preziosi: consente di aggregare evidenze da studi precedenti, modellare la variabilità individuale, personalizzare gli interventi in tempo reale e formulare inferenze utili per la pratica clinica. È uno strumento che rafforza il legame tra teoria, dati e decisione.\nPerché queste applicazioni funzionano?\nIl successo dei metodi bayesiani si fonda su tre caratteristiche fondamentali: la capacità di aggiornarsi continuamente con l’arrivo di nuovi dati, l’integrazione sistematica delle conoscenze pregresse, e una gestione sofisticata dell’incertezza, che non si riduce a un singolo valore ma si esprime come una distribuzione completa.",
    "crumbs": [
      "Inferenza",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/introduction_bayes_inference.html#oltre-la-differenza-tra-medie-inferenza-bayesiana-unidimensionale",
    "href": "chapters/bayesian_inference/introduction_bayes_inference.html#oltre-la-differenza-tra-medie-inferenza-bayesiana-unidimensionale",
    "title": "Introduzione",
    "section": "Oltre la differenza tra medie: inferenza bayesiana unidimensionale",
    "text": "Oltre la differenza tra medie: inferenza bayesiana unidimensionale\nIn questa sezione esploreremo i fondamenti dell’inferenza bayesiana applicata alla stima di un singolo parametro scalare, una situazione molto frequente nella ricerca psicologica e nelle scienze sociali. Esempi tipici includono la stima della proporzione di pazienti che rispondono a un trattamento, della media di un punteggio di ansia in una popolazione, della frequenza di un evento raro, o della durata media di un episodio clinico.\nAnalizzeremo quattro modelli statistici fondamentali:\n\nil modello binomiale per la stima di proporzioni;\nil modello normale per la stima di medie di variabili continue;\nil modello di Poisson per il conteggio di eventi;\nil modello esponenziale per l’analisi del tempo tra eventi.\n\nPer ciascuno di questi modelli, approfondiremo il processo di aggiornamento bayesiano: come la verosimiglianza interagisce con la distribuzione a priori per produrre la distribuzione a posteriori. Presenteremo due metodi principali per ottenere quest’ultima: l’approssimazione numerica tramite griglia, adatta per problemi didattici e semplici, e l’impiego delle distribuzioni coniugate, che permettono soluzioni analitiche eleganti ed efficienti.\nDedicheremo particolare attenzione all’influenza delle scelte a priori, alla sintesi della distribuzione a posteriori attraverso medie, intervalli di credibilità e rappresentazioni grafiche, e al significato delle inferenze bayesiane in un contesto psicologico.\nNel quadro della crisi di replicabilità che ha colpito la psicologia, l’inferenza bayesiana si distingue come una risposta metodologica matura. Essa evita le decisioni arbitrarie basate su soglie di significatività e promuove un’interpretazione più sfumata, trasparente e cumulativa dei risultati empirici, aprendo la strada a una scienza psicologica più affidabile e teoricamente informata (Gelman et al., 2013; McElreath, 2020).",
    "crumbs": [
      "Inferenza",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/introduction_bayes_inference.html#bibliografia",
    "href": "chapters/bayesian_inference/introduction_bayes_inference.html#bibliografia",
    "title": "Introduzione",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., & Rubin, D. B. (2013). Bayesian Data Analysis (3rd ed.). Chapman; Hall/CRC.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "Inferenza",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_uncertainty.html",
    "href": "chapters/bayesian_inference/01_uncertainty.html",
    "title": "43  Abbracciare l’incertezza",
    "section": "",
    "text": "Introduzione",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_uncertainty.html#lincertezza-nella-ricerca-psicologica",
    "href": "chapters/bayesian_inference/01_uncertainty.html#lincertezza-nella-ricerca-psicologica",
    "title": "43  Abbracciare l’incertezza",
    "section": "43.1 L’incertezza nella ricerca psicologica",
    "text": "43.1 L’incertezza nella ricerca psicologica\nL’incertezza è un elemento centrale non solo nella statistica, ma in tutte le discipline scientifiche, con un’importanza particolare in psicologia, dove si studiano fenomeni complessi e difficili da misurare. Nell’indagare processi cognitivi, emozioni e comportamenti, i ricercatori si trovano spesso ad affrontare dati intricati, ambigui e suscettibili di molteplici interpretazioni. Sebbene alcune affermazioni possano essere sostenute con elevata confidenza o confutate con certezza, la maggior parte delle ipotesi scientifiche si colloca in un’area grigia dominata dall’incertezza.\nL’obiettivo di questo corso è guidare gli studenti nella comprensione e nella gestione dell’incertezza nella ricerca psicologica, adottando l’approccio bayesiano all’analisi dei dati. Questo metodo, basato sulla quantificazione e sull’aggiornamento delle credenze alla luce di nuove evidenze, fornirà agli studenti gli strumenti per affrontare l’incertezza in modo rigoroso e sistematico, sia nella carriera accademica sia nella pratica clinica.\n\n43.1.1 La natura soggettiva dell’incertezza\nUn aspetto cruciale dell’incertezza, spesso trascurato, è la sua dimensione soggettiva. De Finetti (Finetti, 1970) ha sottolineato come l’incertezza sia, almeno in parte, una questione personale: ciò che è incerto per uno psicologo potrebbe non esserlo per un altro, in funzione delle loro esperienze, conoscenze pregresse e interpretazioni dei dati disponibili. Anche di fronte alla stessa questione, due ricercatori possono condividere un’incertezza comune, ma con gradi di intensità diversi.\nQuesta componente soggettiva è particolarmente rilevante in psicologia, dove le differenze individuali e culturali influenzano la percezione e l’interpretazione dei fenomeni. L’approccio bayesiano offre un potente strumento per affrontare questa soggettività, consentendo di quantificare le differenze tra credenze individuali e di aggiornarle in modo coerente sulla base di nuove evidenze oggettive.\n\n\n43.1.2 L’onnipresenza dell’incertezza\nL’incertezza permea ogni aspetto della ricerca psicologica. Ogni esperimento, misurazione o interpretazione dei dati comporta un margine di incertezza. Questa condizione è particolarmente evidente nello studio di fenomeni complessi come il comportamento umano o i processi mentali, dove innumerevoli variabili interagiscono, molte delle quali difficili da misurare o controllare con precisione.\nTuttavia, l’incertezza non deve essere vista come un ostacolo insormontabile. Al contrario, riconoscerla e quantificarla può favorire una comprensione più profonda e realistica dei fenomeni psicologici. Attraverso l’approccio bayesiano, diventa possibile integrare l’incertezza nel processo di indagine scientifica, trattandola non come un limite, ma come una risorsa (Koetke et al., 2024).\n\n\n43.1.3 Superare la soppressione dell’incertezza\nNonostante la sua onnipresenza, l’incertezza è spesso ignorata o minimizzata nella comunicazione scientifica. Questo può avvenire attraverso interpretazioni eccessivamente ottimistiche dei risultati, la presentazione di conclusioni come fatti certi, o una riluttanza a riconoscere i limiti degli studi condotti. Tale atteggiamento, sebbene comprensibile, può condurre a conclusioni errate e a una visione distorta della realtà.\nL’approccio bayesiano permette di affrontare l’incertezza in modo esplicito e costruttivo. Fornendo un quadro rigoroso per quantificarla, analizzarla e comunicarla chiaramente, migliora la trasparenza della ricerca e promuove conclusioni più oneste e accurate.\n\n\n43.1.4 I benefici dell’incertezza\nContrariamente a quanto si possa pensare, l’incertezza offre numerosi vantaggi per la ricerca psicologica:\n\nStimola l’esplorazione scientifica: La consapevolezza dell’incertezza incoraggia i ricercatori a formulare nuove ipotesi e a migliorare i metodi di studio.\nPromuove l’onestà intellettuale: Accettare l’incertezza rende i ricercatori più cauti e aperti a prospettive alternative.\nMigliora la qualità delle analisi: Integrare l’incertezza porta a disegni sperimentali più robusti e interpretazioni più accurate.\nFacilita la collaborazione interdisciplinare: Riconoscere i limiti delle proprie conoscenze stimola la ricerca di input da altri esperti.\nRiflette la complessità dei fenomeni psicologici: L’incertezza è intrinseca ai processi mentali e riconoscerla consente di rappresentarli in modo più realistico.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_uncertainty.html#la-natura-soggettiva-dellincertezza",
    "href": "chapters/bayesian_inference/01_uncertainty.html#la-natura-soggettiva-dellincertezza",
    "title": "43  Abbracciare l’incertezza",
    "section": "43.3 La natura soggettiva dell’incertezza",
    "text": "43.3 La natura soggettiva dell’incertezza\nUn aspetto cruciale dell’incertezza, spesso trascurato, è la sua dimensione soggettiva. De Finetti (Finetti, 1970) ha sottolineato come l’incertezza sia, almeno in parte, una questione personale: ciò che è incerto per uno psicologo potrebbe non esserlo per un altro, in funzione delle loro esperienze, conoscenze pregresse e interpretazioni dei dati disponibili. Anche di fronte alla stessa questione, due ricercatori possono condividere un’incertezza comune, ma con gradi di intensità diversi.\nQuesta componente soggettiva è particolarmente rilevante in psicologia, dove le differenze individuali e culturali influenzano la percezione e l’interpretazione dei fenomeni. L’approccio bayesiano offre un potente strumento per affrontare questa soggettività, consentendo di quantificare le differenze tra credenze individuali e di aggiornarle in modo coerente sulla base di nuove evidenze oggettive.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_uncertainty.html#lonnipresenza-dellincertezza",
    "href": "chapters/bayesian_inference/01_uncertainty.html#lonnipresenza-dellincertezza",
    "title": "43  Abbracciare l’incertezza",
    "section": "43.4 L’onnipresenza dell’incertezza",
    "text": "43.4 L’onnipresenza dell’incertezza\nL’incertezza permea ogni aspetto della ricerca psicologica. Ogni esperimento, misurazione o interpretazione dei dati comporta un margine di incertezza. Questa condizione è particolarmente evidente nello studio di fenomeni complessi come il comportamento umano o i processi mentali, dove innumerevoli variabili interagiscono, molte delle quali difficili da misurare o controllare con precisione.\nTuttavia, l’incertezza non deve essere vista come un ostacolo insormontabile. Al contrario, riconoscerla e quantificarla può favorire una comprensione più profonda e realistica dei fenomeni psicologici. Attraverso l’approccio bayesiano, diventa possibile integrare l’incertezza nel processo di indagine scientifica, trattandola non come un limite, ma come una risorsa (Koetke et al., 2024).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_uncertainty.html#superare-la-soppressione-dellincertezza",
    "href": "chapters/bayesian_inference/01_uncertainty.html#superare-la-soppressione-dellincertezza",
    "title": "43  Abbracciare l’incertezza",
    "section": "43.5 Superare la soppressione dell’incertezza",
    "text": "43.5 Superare la soppressione dell’incertezza\nNonostante la sua onnipresenza, l’incertezza è spesso ignorata o minimizzata nella comunicazione scientifica. Questo può avvenire attraverso interpretazioni eccessivamente ottimistiche dei risultati, la presentazione di conclusioni come fatti certi, o una riluttanza a riconoscere i limiti degli studi condotti. Tale atteggiamento, sebbene comprensibile, può condurre a conclusioni errate e a una visione distorta della realtà.\nL’approccio bayesiano permette di affrontare l’incertezza in modo esplicito e costruttivo. Fornendo un quadro rigoroso per quantificarla, analizzarla e comunicarla chiaramente, migliora la trasparenza della ricerca e promuove conclusioni più oneste e accurate.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_uncertainty.html#i-benefici-dellincertezza",
    "href": "chapters/bayesian_inference/01_uncertainty.html#i-benefici-dellincertezza",
    "title": "43  Abbracciare l’incertezza",
    "section": "43.6 I benefici dell’incertezza",
    "text": "43.6 I benefici dell’incertezza\nContrariamente a quanto si possa pensare, l’incertezza offre numerosi vantaggi per la ricerca psicologica:\n\nStimola l’esplorazione scientifica: La consapevolezza dell’incertezza incoraggia i ricercatori a formulare nuove ipotesi e a migliorare i metodi di studio.\nPromuove l’onestà intellettuale: Accettare l’incertezza rende i ricercatori più cauti e aperti a prospettive alternative.\nMigliora la qualità delle analisi: Integrare l’incertezza porta a disegni sperimentali più robusti e interpretazioni più accurate.\nFacilita la collaborazione interdisciplinare: Riconoscere i limiti delle proprie conoscenze stimola la ricerca di input da altri esperti.\nRiflette la complessità dei fenomeni psicologici: L’incertezza è intrinseca ai processi mentali e riconoscerla consente di rappresentarli in modo più realistico.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_uncertainty.html#tipi-di-incertezza",
    "href": "chapters/bayesian_inference/01_uncertainty.html#tipi-di-incertezza",
    "title": "43  Abbracciare l’incertezza",
    "section": "43.2 Tipi di incertezza",
    "text": "43.2 Tipi di incertezza\nL’incertezza nella ricerca può essere classificata in tre categorie principali, in base alla sua origine: aleatoria, epistemica e ontologica (Gansch & Adee, 2020).\n\n43.2.1 Incertezza aleatoria\nL’incertezza aleatoria è intrinseca alla natura casuale di un processo e non può essere eliminata per un dato modello probabilistico. Essa è considerata irreducibile e viene quantificata tramite distribuzioni probabilistiche. Ad esempio, nella misurazione della risposta di un individuo a uno stimolo, la variabilità intrinseca nel comportamento umano, dovuta a fattori imprevedibili, rappresenta un caso di incertezza aleatoria. Questo tipo di incertezza è una caratteristica fondamentale di molti fenomeni psicologici e biologici.\n\n\n43.2.2 Incertezza epistemica\nL’incertezza epistemica deriva dalla conoscenza limitata o incompleta di un fenomeno. Essa rappresenta il “noto-ignoto”, cioè ciò che sappiamo di non sapere, ed è legata alle semplificazioni insite in ogni modello scientifico. Ad esempio, un modello psicologico che non consideri le influenze culturali o ambientali potrebbe risultare incompleto, introducendo incertezza epistemica. Diversamente dall’incertezza aleatoria, l’incertezza epistemica può essere ridotta attraverso il miglioramento dei modelli, l’inclusione di variabili rilevanti o la raccolta di ulteriori dati.\n\n\n43.2.3 Incertezza ontologica\nL’incertezza ontologica riguarda l’“ignoto-ignoto”, ovvero aspetti di un sistema che non sono ancora stati identificati. In psicologia, questo potrebbe riferirsi a variabili o processi non ancora scoperti che influenzano un comportamento. Ad esempio, studiando i disturbi mentali, potrebbero emergere nuovi fattori di rischio precedentemente sconosciuti.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_uncertainty.html#il-calcolo-dellincertezza-nellapproccio-bayesiano",
    "href": "chapters/bayesian_inference/01_uncertainty.html#il-calcolo-dellincertezza-nellapproccio-bayesiano",
    "title": "43  Abbracciare l’incertezza",
    "section": "43.3 Il calcolo dell’incertezza nell’approccio bayesiano",
    "text": "43.3 Il calcolo dell’incertezza nell’approccio bayesiano\nL’insegnamento si propone di fornire agli studenti strumenti per affrontare e quantificare l’incertezza attraverso l’approccio bayesiano (Gelman et al., 2013). Fondato sul teorema di Bayes, questo metodo rappresenta un quadro teorico rigoroso e sistematico per aggiornare le credenze alla luce di nuove evidenze, configurandosi come una componente centrale della metodologia scientifica.\nIl processo si basa su quattro passaggi essenziali. In primo luogo, si parte dalla quantificazione delle credenze iniziali, note come prior, che rappresentano le conoscenze pregresse o le ipotesi relative a un determinato fenomeno psicologico. Successivamente, si analizza la forza delle evidenze empiriche fornite dai dati raccolti, formalizzata nella likelihood. Queste due informazioni vengono combinate per generare le credenze aggiornate, chiamate posterior, che sintetizzano la conoscenza disponibile integrando i dati empirici e le ipotesi iniziali. Infine, le credenze aggiornate possono essere utilizzate per prendere decisioni più informate, pianificare ricerche future e orientare interventi.\n\n43.3.1 Il ruolo delle credenze e delle decisioni nella ricerca psicologica\nLe credenze rivestono un ruolo fondamentale nella ricerca psicologica, influenzando tutte le fasi del processo scientifico, dalla progettazione degli esperimenti all’interpretazione dei risultati, fino alla scelta di interventi clinici. L’approccio bayesiano si distingue per la sua capacità di esplicitare e formalizzare queste credenze, consentendo di aggiornare il loro contenuto in modo coerente e trasparente man mano che emergono nuove evidenze.\nQuesto metodo permette non solo di ottimizzare le decisioni basandosi su informazioni aggiornate, ma anche di comunicare chiaramente l’incertezza associata alle conclusioni, evidenziandone i limiti e garantendo maggiore trasparenza scientifica. Affrontare l’incertezza come una componente intrinseca della ricerca non solo migliora la qualità dell’analisi, ma consente anche di promuovere un approccio più realistico e rigoroso nello studio dei fenomeni psicologici.\nIn sintesi, l’approccio bayesiano offre un modello operativo per integrare l’incertezza nel processo decisionale, trattandola non come un ostacolo, ma come un elemento essenziale per una comprensione più sfumata e accurata della realtà.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_uncertainty.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/01_uncertainty.html#riflessioni-conclusive",
    "title": "43  Abbracciare l’incertezza",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nQuesto insegnamento fornisce gli strumenti per applicare l’analisi bayesiana nell’ambito dei dati psicologici, insegnando a considerare l’incertezza come una parte integrante e preziosa del processo scientifico. Attraverso questo approccio, gli studenti potranno acquisire una comprensione più raffinata e strutturata dei fenomeni psicologici, integrando l’incertezza come elemento fondamentale per interpretare i dati e formulare inferenze rigorose.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_uncertainty.html#esercizi",
    "href": "chapters/bayesian_inference/01_uncertainty.html#esercizi",
    "title": "43  Abbracciare l’incertezza",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nChe cosa significa “abbracciare l’incertezza” nel contesto della statistica bayesiana e perché è particolarmente rilevante nella ricerca psicologica?\nQuali sono le tre principali categorie di incertezza nella ricerca psicologica e come si differenziano tra loro?\nIn che modo l’approccio bayesiano consente di affrontare l’incertezza in modo sistematico e rigoroso?\nQual è il ruolo della soggettività nell’incertezza secondo l’approccio bayesiano, e perché questo è particolarmente rilevante in psicologia?\nQuali sono alcuni dei principali vantaggi dell’incertezza nella ricerca psicologica e come può essere utilizzata per migliorare la qualità della scienza?\n\nConsegna: Rispondi con parole tue e carica il file .qmd, convertito in PDF su Moodle.\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n\nAbbracciare l’incertezza nella statistica bayesiana significa riconoscerla come una parte inevitabile della ricerca e trattarla in modo esplicito e formale, anziché ignorarla o minimizzarla. Nella ricerca psicologica, l’incertezza è centrale perché si studiano fenomeni complessi e difficili da misurare, come emozioni e processi cognitivi. L’approccio bayesiano consente di quantificare e aggiornare l’incertezza in modo sistematico, offrendo un metodo più realistico per interpretare i dati e formulare inferenze.\nLe tre principali categorie di incertezza sono:\n\nIncertezza aleatoria: è intrinseca alla natura casuale di un fenomeno e non può essere eliminata (es. variabilità nelle risposte di un individuo a uno stesso stimolo).\n\nIncertezza epistemica: deriva da una conoscenza incompleta del fenomeno studiato e può essere ridotta con migliori modelli e raccolta di dati (es. omissione di variabili importanti in un modello psicologico).\n\nIncertezza ontologica: si riferisce a variabili o aspetti del sistema ancora sconosciuti (es. fattori di rischio per disturbi mentali non ancora identificati).\n\nL’approccio bayesiano affronta l’incertezza attraverso quattro fasi fondamentali: (1) definizione delle credenze iniziali (prior), (2) valutazione delle nuove evidenze (likelihood), (3) aggiornamento delle credenze (posterior), e (4) utilizzo delle credenze aggiornate per prendere decisioni più informate. Questo processo consente di integrare sistematicamente nuove informazioni e di migliorare continuamente la comprensione di un fenomeno.\nSecondo De Finetti, l’incertezza ha una componente soggettiva, poiché le credenze degli individui influenzano il modo in cui interpretano i dati. Due ricercatori con esperienze diverse possono avere livelli di incertezza differenti riguardo allo stesso fenomeno. In psicologia, questa soggettività è particolarmente rilevante perché le percezioni e le interpretazioni dei fenomeni sono spesso influenzate da differenze individuali e culturali. L’approccio bayesiano permette di quantificare e aggiornare queste credenze in modo formale e trasparente.\nL’incertezza offre diversi vantaggi nella ricerca psicologica:\n\nStimola l’esplorazione scientifica, incoraggiando nuove ipotesi e metodi.\n\nPromuove l’onestà intellettuale, rendendo i ricercatori più cauti e aperti a spiegazioni alternative.\n\nMigliora la qualità delle analisi, portando a modelli più robusti e interpretazioni più accurate.\n\nFacilita la collaborazione interdisciplinare, spingendo a integrare competenze diverse.\nRiflette meglio la complessità della psicologia, permettendo una rappresentazione più realistica dei fenomeni studiati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_uncertainty.html#bibliografia",
    "href": "chapters/bayesian_inference/01_uncertainty.html#bibliografia",
    "title": "43  Abbracciare l’incertezza",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nFinetti, B. de. (1970). Teoria delle probabilità: sintesi introduttiva con appendice critica. Einaudi.\n\n\nGansch, R., & Adee, A. (2020). System theoretic view on uncertainties. 2020 Design, Automation & Test in Europe Conference & Exhibition (DATE), 1345–1350.\n\n\nGelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., & Rubin, D. B. (2013). Bayesian Data Analysis (3rd ed.). Chapman; Hall/CRC.\n\n\nKoetke, J., Schumann, K., Bowes, S. M., & Vaupotič, N. (2024). The effect of seeing scientists as intellectually humble on trust in scientists and their research. Nature Human Behaviour, 1–14.\n\n\nLindley, D. V. (2013). Understanding uncertainty. John Wiley & Sons.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_intro_bayes.html",
    "href": "chapters/bayesian_inference/02_intro_bayes.html",
    "title": "44  La quantificazione dell’incertezza",
    "section": "",
    "text": "Introduzione\nSe nel Capitolo 43 abbiamo definito che cosa intendiamo per incertezza, in questo capitolo vediamo come rappresentarla matematicamente e come aggiornarla sistematicamente quando raccogliamo nuovi dati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_intro_bayes.html#introduzione",
    "href": "chapters/bayesian_inference/02_intro_bayes.html#introduzione",
    "title": "44  La quantificazione dell’incertezza",
    "section": "",
    "text": "“Quindi non avete una sola risposta alle vostre domande?”\n“Adson, se l’avessi insegnerei teologia a Parigi.”\n“A Parigi hanno sempre la risposta vera?”\n“Mai,” disse Guglielmo, “ma sono molto sicuri dei loro errori.”\n— Umberto Eco (Il Nome della Rosa)\n\n\nNel Capitolo 43 abbiamo visto come l’incertezza sia un aspetto inevitabile della ricerca psicologica e più in generale della conoscenza scientifica. Abbiamo distinto diversi tipi di incertezza e sottolineato la necessità di strumenti per gestirla in maniera coerente. Questo ci porta naturalmente al cuore dell’approccio bayesiano: come quantificare matematicamente l’incertezza e come aggiornarla quando osserviamo nuove evidenze.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_intro_bayes.html#il-valore-dellincertezza",
    "href": "chapters/bayesian_inference/02_intro_bayes.html#il-valore-dellincertezza",
    "title": "44  La quantificazione dell’incertezza",
    "section": "\n44.1 Il valore dell’incertezza",
    "text": "44.1 Il valore dell’incertezza\nNelle scienze psicologiche lavoriamo spesso con variabili latenti – ansia, motivazione, autostima – che non sono osservabili direttamente. Le nostre misure (questionari, tempi di reazione, scelte) sono parziali e imperfette. La probabilità fornisce un linguaggio per rappresentare questa incertezza in modo rigoroso.\nL’inferenza bayesiana utilizza le distribuzioni di probabilità per quantificare sia ciò che sappiamo, sia ciò che non sappiamo. Ogni stima diventa una distribuzione e non un singolo numero, riflettendo così l’incertezza associata (Jaynes, 2003).\nA differenza dei modelli deterministici, i modelli probabilistici – in particolare quelli bayesiani – non cercano di eliminare l’incertezza, ma la assumono come parte integrante della spiegazione.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_intro_bayes.html#interpretazione-frequentista-vs.-bayesiana-dellincertezza",
    "href": "chapters/bayesian_inference/02_intro_bayes.html#interpretazione-frequentista-vs.-bayesiana-dellincertezza",
    "title": "44  La quantificazione dell’incertezza",
    "section": "\n44.2 Interpretazione frequentista vs. bayesiana dell’incertezza",
    "text": "44.2 Interpretazione frequentista vs. bayesiana dell’incertezza\n\n44.2.1 Interpretazione frequentista\nL’approccio frequentista definisce la probabilità come la frequenza relativa con cui un evento si verifica nel lungo periodo, in un gran numero di prove simili. Per esempio, se si vuole stimare la probabilità che un individuo superi una certa soglia di ansia, si osserverebbe un ampio numero di individui simili e si calcolerebbe la proporzione di successi (\\(E\\)) rispetto al totale delle prove (\\(N\\)):\n\\[\n\\text{Pr}(E) = \\lim_{N \\to \\infty} \\frac{\\text{numero di volte in cui } E \\text{ si verifica}}{N}.\n\\]\nNel frequentismo, l’incertezza non è rappresentata direttamente, ma emerge dall’impossibilità pratica di osservare un numero infinito di eventi in condizioni identiche. Questo approccio presenta due limiti principali:\n\n\nOsservazioni infinite: Non è realistico osservare un evento infinite volte.\n\nDefinizione del gruppo di riferimento: È spesso difficile identificare con precisione le condizioni rilevanti che caratterizzano il fenomeno (la reference class).\n\nQuesti limiti rendono l’approccio frequentista meno applicabile in psicologia, dove le condizioni sperimentali sono spesso uniche e non ripetibili.\n\n44.2.2 Interpretazione bayesiana\nL’approccio bayesiano interpreta la probabilità come una misura soggettiva del grado di fiducia in un evento, un’ipotesi o un parametro. La probabilità riflette quindi la nostra incertezza riguardo a un fenomeno, tenendo conto sia delle conoscenze precedenti (priori) sia delle nuove evidenze (dati). Questo legame diretto tra probabilità e incertezza consente di aggiornare le credenze man mano che emergono nuove informazioni.\nIl teorema di Bayes formalizza questo processo:\n\\[\np(\\theta \\mid D) = \\frac{p(D \\mid \\theta) \\cdot p(\\theta)}{p(D)},\n\\]\ndove:\n\n\n\\(p(\\theta \\mid D)\\): probabilità a posteriori di \\(\\theta\\), aggiornata in base ai dati \\(D\\),\n\n\\(p(\\theta)\\): probabilità a priori di \\(\\theta\\),\n\n\\(p(D \\mid \\theta)\\): verosimiglianza dei dati dato \\(\\theta\\),\n\n\\(p(D)\\): probabilità totale dei dati.\n\nL’approccio bayesiano rappresenta esplicitamente l’incertezza attraverso distribuzioni probabilistiche. Ogni stima incorpora la variabilità intrinseca dei dati e il grado di fiducia associato.\n\n\n\n\n\n\n\nCaratteristica\nFrequentismo\nBayesiano\n\n\n\nProbabilità\nFrequenza relativa nel lungo periodo\nGrado di credenza soggettiva\n\n\nIncertezza\nNon rappresentata esplicitamente\nModello centrale delle distribuzioni\n\n\nAggiornamento\nNon dinamico\nContinuo, basato sul Teorema di Bayes\n\n\nApplicabilità in Psicologia\nLimitata: richiede condizioni ripetibili\nFlessibile: integra dati e conoscenze\n\n\n\nIn conclusione, l’inferenza bayesiana offre un collegamento diretto tra incertezza e probabilità, rappresentando quest’ultima come una misura della conoscenza attuale su un fenomeno. Questa flessibilità rende l’approccio particolarmente potente per affrontare i problemi complessi della psicologia, dove variabili latenti e incertezza sono elementi centrali. Integrando dati empirici e conoscenze pregresse, l’inferenza bayesiana non solo migliora la precisione delle stime, ma fornisce anche un quadro intuitivo e rigoroso per la comprensione e la modellazione dell’incertezza.\n\nEsempio 44.1 Quando si misura l’ansia tramite questionari, l’incertezza può derivare da:\n\n\nSoggettività delle risposte: L’interpretazione delle domande varia tra individui.\n\nIncompletezza delle misure: Il questionario può non cogliere tutte le sfumature dell’ansia.\n\nRumore nei dati: Errori minori possono influenzare i risultati.\n\nL’inferenza bayesiana consente di rappresentare queste fonti di incertezza con una distribuzione a priori basata su studi precedenti. Man mano che si raccolgono nuovi dati, la distribuzione a posteriori fornisce stime aggiornate e più affidabili.\n\n\nEsempio 44.2 In uno studio sull’effetto del rinforzo negativo sulla motivazione, la “motivazione interna” è una variabile latente non osservabile direttamente. Possiamo inferirla attraverso:\n\n\nMisure indirette: Tempo speso sul compito, velocità di risposta.\n\nModelli bayesiani: Collegano queste variabili osservabili alla motivazione latente, rappresentando l’incertezza individuale e il contributo del rinforzo.\n\nAd esempio, se un modello bayesiano stima che un individuo ha l’80% di probabilità di rispondere positivamente al rinforzo negativo, questa probabilità può essere aggiornata con nuovi dati sperimentali, affinando la comprensione del fenomeno.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_intro_bayes.html#inferenza-bayesiana-e-incertezza-nelle-stime",
    "href": "chapters/bayesian_inference/02_intro_bayes.html#inferenza-bayesiana-e-incertezza-nelle-stime",
    "title": "44  La quantificazione dell’incertezza",
    "section": "\n44.3 Inferenza bayesiana e incertezza nelle stime",
    "text": "44.3 Inferenza bayesiana e incertezza nelle stime\nL’inferenza bayesiana utilizza le probabilità per aggiornare le credenze sui parametri di un modello basandosi sui dati osservati. Queste credenze sono rappresentate da distribuzioni di probabilità, e l’ampiezza di queste distribuzioni riflette l’incertezza associata alle stime. In psicologia, dove spesso si lavora con campioni limitati e misurazioni indirette di variabili latenti, questa gestione dell’incertezza è fondamentale per interpretare i risultati in modo robusto e realistico.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_intro_bayes.html#il-modello-bayesiano",
    "href": "chapters/bayesian_inference/02_intro_bayes.html#il-modello-bayesiano",
    "title": "44  La quantificazione dell’incertezza",
    "section": "\n44.2 Il modello bayesiano",
    "text": "44.2 Il modello bayesiano\nUn modello statistico bayesiano comprende tre componenti:\n\n\nDistribuzione a Priori (Prior): Rappresenta le credenze iniziali sui valori dei parametri del modello, informate da ricerche precedenti o da assunzioni neutre.\n\nVerosimiglianza (Likelihood): Descrive la probabilità di osservare i dati dati i parametri del modello, riflettendo il processo che genera i dati.\n\nDistribuzione a Posteriori (Posterior): È la distribuzione aggiornata dei parametri dopo aver osservato i dati, ottenuta combinando la prior e la verosimiglianza mediante il teorema di Bayes. La posterior rappresenta la conoscenza aggiornata dopo aver integrato le informazioni fornite dai dati.\n\nLa modellazione bayesiana descrive il processo generativo che ha prodotto i dati osservati, incorporando l’incertezza nei parametri e aggiornando continuamente le stime man mano che emergono nuovi dati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_intro_bayes.html#componenti-chiave-della-modellazione-probabilistica",
    "href": "chapters/bayesian_inference/02_intro_bayes.html#componenti-chiave-della-modellazione-probabilistica",
    "title": "44  La quantificazione dell’incertezza",
    "section": "\n44.5 Componenti chiave della modellazione probabilistica",
    "text": "44.5 Componenti chiave della modellazione probabilistica\n\nVariabili Aleatorie: Quantità incerte che assumono diversi valori secondo una distribuzione di probabilità. Ad esempio, il livello di depressione di un paziente può essere trattato come una variabile aleatoria.\nDistribuzioni di Probabilità: Descrivono come i valori di una variabile aleatoria sono distribuiti. Ad esempio, una distribuzione normale può essere utilizzata per modellare la variabilità dell’ansia in una popolazione.\nInferenza Bayesiana: Aggiorna la distribuzione di probabilità delle variabili di interesse sulla base dei nuovi dati, migliorando progressivamente le stime.\n\n\nEsempio 44.3 In uno studio clinico sulla depressione, possiamo utilizzare l’inferenza bayesiana per stimare il livello di depressione di un paziente partendo da una distribuzione a priori informata da studi precedenti. Ogni nuovo dato raccolto (come punteggi a questionari o osservazioni) permette di aggiornare questa stima, affinando progressivamente la comprensione del fenomeno.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_intro_bayes.html#il-potere-dellaggiornamento-bayesiano",
    "href": "chapters/bayesian_inference/02_intro_bayes.html#il-potere-dellaggiornamento-bayesiano",
    "title": "44  La quantificazione dell’incertezza",
    "section": "\n44.6 Il potere dell’aggiornamento bayesiano",
    "text": "44.6 Il potere dell’aggiornamento bayesiano\nIl vero punto di forza della modellazione bayesiana risiede nella sua capacità di aggiornare continuamente le credenze sui parametri del modello man mano che si raccolgono nuovi dati. Questo processo iterativo, basato sul teorema di Bayes, consente di integrare sia le credenze iniziali (a priori) sia le evidenze empiriche (verosimiglianza) per ottenere stime sempre più precise.\n\nEsempio 44.4 Un esempio intuitivo per spiegare l’aggiornamento bayesiano è quello proposto da McElreath (2020). Supponiamo di voler stimare la proporzione della superficie terrestre coperta d’acqua. L’esperimento consiste nel lanciare un globo terrestre in aria, afferrarlo e osservare se la superficie sotto il dito è acqua o terra. Dopo ogni osservazione, possiamo aggiornare le nostre credenze sulla proporzione d’acqua (p).\nIniziamo con una distribuzione a priori che assegna la stessa probabilità a tutti i valori possibili di \\(p\\) (proporzione d’acqua). Dopo il primo lancio, in cui osserviamo acqua (“W”), la probabilità che \\(p\\) sia zero diminuisce, mentre quella che \\(p\\) sia maggiore aumenta. Man mano che raccogliamo più dati, la distribuzione si aggiorna, riducendo l’incertezza e convergendo verso una stima più precisa di \\(p\\).\nCon l’aumento dei dati osservati, la distribuzione a posteriori si concentra sempre di più attorno ai valori di \\(p\\) che meglio spiegano i dati. Questo processo rappresenta il continuo affinamento delle stime bayesiane, che diventano più accurate man mano che le evidenze si accumulano.\nIn sintesi, l’aggiornamento bayesiano fornisce un quadro flessibile e sistematico per trattare l’incertezza e integrare nuove informazioni. È particolarmente utile nelle scienze psicologiche e sociali, dove la complessità e la variabilità dei fenomeni rendono difficile ottenere stime precise. Questo approccio consente di migliorare costantemente la comprensione dei fenomeni, adattando le credenze man mano che emergono nuovi dati.\n\n\n\n\n\n\n\n\nIl grafico precedente illustra un processo di aggiornamento bayesiano, in cui vengono progressivamente aggiornate le credenze sulla proporzione di superficie coperta d’acqua (\\(p\\)) del globo terrestre, man mano che vengono raccolti nuovi dati. Dopo ogni lancio, le probabilità sui possibili valori di \\(p\\) vengono aggiornate sulla base delle osservazioni, utilizzando il teorema di Bayes. Il processo è visualizzato attraverso una serie di grafici, organizzati in una griglia 3x3, con ogni pannello che rappresenta un’osservazione aggiuntiva.\nNota sui grafici.\n\n\nLinea Blu: La distribuzione a posteriori calcolata per il pannello corrente.\n\nLinea Grigia: La distribuzione a priori utilizzata, che è il posterior del pannello precedente.\n\nAggiornamento Bayesiano: Ogni volta che vengono osservati nuovi dati, la distribuzione a posteriori diventa il a priori per il passo successivo, consentendo di incorporare progressivamente l’informazione osservata.\n\n\n\n\n\n\n\n\nApprofondimento\n\n\n\n\n\nA una prima lettura, è sufficiente focalizzarsi sul significato dell’aggiornamento bayesiano e sulle conseguenze che questo produce rispetto alle nostre credenze su \\(p\\), man mano che vengono osservati nuovi dati. Per il momento, il meccanismo dettagliato attraverso cui l’aggiornamento bayesiano viene realizzato non è ancora stato esplicitato, e quindi gli studenti possono inizialmente tralasciare la spiegazione approfondita contenuta in questo riquadro.\nDopo aver letto il contenuto di Capitolo 48, sarà possibile tornare sull’esempio discusso qui e comprenderne appieno l’aggiornamento bayesiano, interpretandolo alla luce delle proprietà delle famiglie coniugate. Questo consentirà di cogliere non solo il significato generale dell’aggiornamento, ma anche i dettagli tecnici che lo rendono particolarmente efficiente in contesti come quello descritto.\nPrimo Pannello.\n\n\nOsservazione iniziale: Abbiamo il primo dato, un successo (“W”).\n\nA priori: La distribuzione a priori iniziale è una distribuzione Beta(1, 1). Questa rappresenta una conoscenza iniziale non informativa, ovvero l’ipotesi che qualsiasi proporzione di successi (\\(p\\)) sia ugualmente probabile.\n\nA posteriori: Con un successo su una prova: \\[\n\\text{Posterior} \\sim \\mathcal{Beta}(1 + 1, 1 + 0) = \\mathcal{Beta}(2, 1).\n\\] La distribuzione risultante è concentrata verso i valori più alti di \\(p\\), riflettendo il successo osservato.\n\nSecondo Pannello.\n\n\nOsservazioni: Ora abbiamo due dati, “W” e “L”, quindi un successo su due prove.\n\nA priori: La distribuzione a priori per questo passo è il posterior del pannello precedente, ovvero \\(\\mathcal{Beta}(2, 1)\\).\n\nA posteriori: Con un successo (\\(W = 1\\)) e un insuccesso (\\(L = 1\\)): \\[\n\\text{Posterior} \\sim \\mathcal{Beta}(2 + 1, 1 + 1) = \\mathcal{Beta}(3, 2).\n\\] La nuova distribuzione riflette un aggiornamento che tiene conto sia del successo che dell’insuccesso.\n\nTerzo Pannello.\n\n\nOsservazioni: Ora abbiamo tre dati, “W”, “L”, “W”, quindi due successi su tre prove.\n\nA priori: La distribuzione a priori è il posterior del pannello precedente, \\(\\mathcal{Beta}(3, 2)\\).\n\nA posteriori: Con due successi (\\(W = 2\\)) e un insuccesso (\\(L = 1\\)): \\[\n\\text{Posterior} \\sim \\mathcal{Beta}(3 + 1, 2 + 0) = \\mathcal{Beta}(4, 2).\n\\]\n\n\nQuarto Pannello.\n\n\nOsservazioni: Ora abbiamo quattro dati, “W”, “L”, “W”, “W”, quindi tre successi su quattro prove.\n\nA priori: La distribuzione a priori è il posterior del pannello precedente, \\(\\mathcal{Beta}(4, 2)\\).\n\nA posteriori: Con tre successi (\\(W = 3\\)) e un insuccesso (\\(L = 1\\)): \\[\n\\text{Posterior} \\sim \\mathcal{Beta}(4 + 1, 2 + 0) = \\mathcal{Beta}(5, 2).\n\\]\n\n\nQuinto Pannello.\n\n\nOsservazioni: Ora abbiamo cinque dati, “W”, “L”, “W”, “W”, “L”, quindi tre successi su cinque prove.\n\nA priori: La distribuzione a priori è il posterior del pannello precedente, \\(\\mathcal{Beta}(5, 2)\\).\n\nA posteriori: Con tre successi (\\(W = 3\\)) e due insuccessi (\\(L = 2\\)): \\[\n\\text{Posterior} \\sim \\mathcal{Beta}(5 + 0, 2 + 1) = \\mathcal{Beta}(5, 3).\n\\]\n\n\nSesto Pannello.\n\n\nOsservazioni: Ora abbiamo sei dati, “W”, “L”, “W”, “W”, “L”, “W”, quindi quattro successi su sei prove.\n\nA priori: La distribuzione a priori è il posterior del pannello precedente, \\(\\mathcal{Beta}(5, 3)\\).\n\nA posteriori: Con quattro successi (\\(W = 4\\)) e due insuccessi (\\(L = 2\\)): \\[\n\\text{Posterior} \\sim \\mathcal{Beta}(5 + 1, 3 + 0) = \\mathcal{Beta}(6, 3).\n\\]\n\n\nSettimo Pannello.\n\n\nOsservazioni: Ora abbiamo sette dati, “W”, “L”, “W”, “W”, “L”, “W”, “L”, quindi quattro successi su sette prove.\n\nA priori: La distribuzione a priori è il posterior del pannello precedente, \\(\\mathcal{Beta}(6, 3)\\).\n\nA posteriori: Con quattro successi (\\(W = 4\\)) e tre insuccessi (\\(L = 3\\)): \\[\n\\text{Posterior} \\sim \\mathcal{Beta}(6 + 0, 3 + 1) = \\mathcal{Beta}(6, 4).\n\\]\n\n\nOttavo Pannello.\n\n\nOsservazioni: Ora abbiamo otto dati, “W”, “L”, “W”, “W”, “L”, “W”, “L”, “W”, quindi cinque successi su otto prove.\n\nA priori: La distribuzione a priori è il posterior del pannello precedente, \\(\\mathcal{Beta}(6, 4)\\).\n\nA posteriori: Con cinque successi (\\(W = 5\\)) e tre insuccessi (\\(L = 3\\)): \\[\n\\text{Posterior} \\sim \\mathcal{Beta}(6 + 1, 4 + 0) = \\mathcal{Beta}(7, 4).\n\\]\n\n\nNono Pannello.\n\n\nOsservazioni: Ora abbiamo nove dati, “W”, “L”, “W”, “W”, “L”, “W”, “L”, “W”, “W”, quindi sei successi su nove prove.\n\nA priori: La distribuzione a priori è il posterior del pannello precedente, \\(\\mathcal{Beta}(7, 4)\\).\n\nA posteriori: Con sei successi (\\(W = 6\\)) e tre insuccessi (\\(L = 3\\)): \\[\n\\text{Posterior} \\sim \\mathcal{Beta}(7 + 1, 4 + 0) = \\mathcal{Beta}(8, 4).\n\\]\n\n\n\n\n\nQuesto processo mostra come il modello bayesiano aggiorna continuamente le credenze man mano che i dati vengono osservati. Ogni nuovo pannello segue lo stesso schema: la distribuzione a priori (linea tratteggiata) viene aggiornata con la nuova osservazione (linea continua). Se viene osservata acqua (W), il picco della distribuzione si sposta a destra; se viene osservata terra (L), il picco si sposta a sinistra. In ogni caso, la curva diventa progressivamente più “appuntita”, indicando che l’incertezza sulla vera proporzione di acqua diminuisce con l’aumentare del numero di osservazioni.\nL’aspetto fondamentale dell’approccio bayesiano è che ogni distribuzione a posteriori aggiornata (linea continua) diventa la nuova distribuzione a priori per la successiva osservazione. Questo processo iterativo permette di apprendere progressivamente dai dati, integrando ogni nuova informazione per affinare la stima di \\(p\\). Alla fine, la distribuzione diventa sempre più concentrata intorno al valore più probabile di \\(p\\), man mano che raccogliamo più dati.\nIn conclusione, l’esempio illustra come l’aggiornamento bayesiano modifichi le nostre credenze sulla proporzione d’acqua (\\(p\\)) sulla superficie del globo, basandosi sulle osservazioni raccolte. Ogni curva rappresenta la sintesi delle conoscenze attuali, combinando le osservazioni precedenti con l’ultima evidenza raccolta. Il grafico dimostra visivamente come l’approccio bayesiano consenta di trattare l’incertezza e aggiornare le stime in modo coerente e progressivo.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_intro_bayes.html#il-processo-generatore-dei-dati",
    "href": "chapters/bayesian_inference/02_intro_bayes.html#il-processo-generatore-dei-dati",
    "title": "44  La quantificazione dell’incertezza",
    "section": "\n44.4 Il processo generatore dei dati",
    "text": "44.4 Il processo generatore dei dati\nL’esempio precedente mette in evidenza come, nel contesto dell’aggiornamento bayesiano, sia cruciale fare un’assunzione sul processo generatore dei dati, ovvero il meccanismo che collega i parametri sconosciuti ai dati osservati. Questo processo è formalizzato attraverso la funzione di verosimiglianza, che esprime la probabilità di osservare i dati disponibili per ogni valore possibile del parametro incognito.\nNel caso degli esperimenti bernoulliani, come il lancio del globo, ogni prova ha due possibili esiti: un successo (acqua) o un fallimento (terra). L’obiettivo è stimare la probabilità di successo, denotata con \\(\\theta\\). Il processo generatore dei dati per questo tipo di esperimento è ben rappresentato dalla distribuzione binomiale, che modella il numero di successi osservati su un certo numero di prove indipendenti, ciascuna con probabilità di successo pari a \\(\\theta\\):\n\\[\nP(W \\mid \\theta, n) = \\binom{n}{W} \\theta^W (1 - \\theta)^{n-W},\n\\]\ndove \\(\\binom{n}{W}\\) è il coefficiente binomiale che calcola il numero di combinazioni possibili di \\(W\\) successi in \\(n\\) prove.\nIn questo contesto, \\(\\theta\\) rappresenta la proporzione di superficie coperta d’acqua sul globo. L’assunzione fondamentale è che \\(\\theta\\) sia costante durante l’intero esperimento, garantendo che tutte le prove siano indipendenti e identicamente distribuite. Questo implica che ogni osservazione porta informazioni utili per aggiornare le nostre credenze su \\(\\theta\\), che si riflettono nella distribuzione a posteriori ad ogni passo.\nGrazie a questa struttura probabilistica, il processo di aggiornamento bayesiano ci consente di:\n\nIniziare con una distribuzione a priori che riflette le nostre conoscenze o ipotesi iniziali su \\(\\theta\\).\nUtilizzare la funzione di verosimiglianza per incorporare i dati osservati.\nCalcolare la distribuzione a posteriori, che sintetizza le nostre credenze aggiornate su \\(\\theta\\).\n\nQuesto processo iterativo consente di affinare progressivamente la stima del parametro \\(\\theta\\), integrando in modo rigoroso le informazioni provenienti dai dati.\n\n\n\n\n\nFigura 44.1: Gli stessi dati possono essere coerenti con diverse ipotesi riguardanti il processo che li ha generati (Figura tratta da Freiesleben & Molnar, 2024).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_intro_bayes.html#interpretazione-della-distribuzione-a-posteriori",
    "href": "chapters/bayesian_inference/02_intro_bayes.html#interpretazione-della-distribuzione-a-posteriori",
    "title": "44  La quantificazione dell’incertezza",
    "section": "\n44.5 Interpretazione della distribuzione a posteriori",
    "text": "44.5 Interpretazione della distribuzione a posteriori\nLa distribuzione a posteriori rappresenta l’aggiornamento delle nostre credenze su \\(\\theta\\) alla luce dei dati osservati. Questa distribuzione non solo sintetizza le informazioni provenienti dall’esperimento, ma ci permette anche di fare inferenze più robuste e quantitative su \\(\\theta\\).\nLa distribuzione a posteriori può essere interpretata utilizzando diverse statistiche riassuntive:\n\n\nModa: È il valore di \\(\\theta\\) con la massima densità di probabilità. Questo rappresenta la stima più plausibile di \\(\\theta\\) dato il modello e i dati osservati.\n\nMedia e Mediana: La media della distribuzione a posteriori fornisce una stima centrale ponderata da tutta la distribuzione, mentre la mediana individua il valore che divide la distribuzione in due metà uguali. Queste misure possono variare leggermente a seconda della simmetria o asimmetria della distribuzione.\n\nL’incertezza associata alla stima di \\(\\theta\\) è rappresentata dalla larghezza della distribuzione a posteriori:\n\nUna distribuzione stretta indica una bassa incertezza: la probabilità si concentra in un intervallo ristretto di valori, riflettendo una maggiore fiducia nella stima di \\(\\theta\\).\nUna distribuzione ampia suggerisce una maggiore incertezza: i dati osservati non sono sufficienti per restringere l’intervallo delle credenze su \\(\\theta\\).\n\nCon l’aumentare dei dati raccolti, la distribuzione a posteriori diventa progressivamente più concentrata attorno al valore più probabile di \\(\\theta\\), riducendo l’incertezza e migliorando la precisione delle inferenze.\n\nEsempio 44.1 Nel contesto dei lanci del globo, supponiamo che la distribuzione a posteriori abbia un picco vicino a \\(\\theta = 0.67\\). Questo significa che la stima più plausibile della proporzione di superficie coperta d’acqua sul globo è il 67%. Se la distribuzione è stretta, possiamo affermare con maggiore sicurezza che la vera proporzione è vicina a questo valore. Al contrario, una distribuzione più ampia rifletterebbe una maggiore incertezza, indicando che ulteriori osservazioni sono necessarie per affinare la stima.\n\nIn conclusione, la distribuzione a posteriori non solo fornisce una stima puntuale di \\(\\theta\\), ma cattura anche l’incertezza associata a questa stima. Attraverso il suo utilizzo, possiamo integrare rigorosamente i dati con le ipotesi iniziali e ottenere inferenze che riflettono sia le informazioni disponibili sia la variabilità residua.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_intro_bayes.html#influenza-delle-distribuzioni-a-priori",
    "href": "chapters/bayesian_inference/02_intro_bayes.html#influenza-delle-distribuzioni-a-priori",
    "title": "44  La quantificazione dell’incertezza",
    "section": "\n44.6 Influenza delle distribuzioni a priori",
    "text": "44.6 Influenza delle distribuzioni a priori\nIn questo esempio, abbiamo utilizzato una distribuzione a priori uniforme, che esprime una totale mancanza di conoscenza iniziale su \\(\\theta\\). Tuttavia, in contesti in cui abbiamo informazioni preesistenti, è possibile utilizzare distribuzioni a priori più informative. Ad esempio, se sappiamo da studi precedenti che circa il 70% della superficie terrestre è coperta d’acqua, possiamo utilizzare una distribuzione a priori che rifletta questa conoscenza. Questo tipo di distribuzione a priori informativa può rendere l’aggiornamento bayesiano più efficiente, portando a stime più precise con meno dati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_intro_bayes.html#vantaggi-dellaggiornamento-bayesiano",
    "href": "chapters/bayesian_inference/02_intro_bayes.html#vantaggi-dellaggiornamento-bayesiano",
    "title": "44  La quantificazione dell’incertezza",
    "section": "\n44.7 Vantaggi dell’aggiornamento bayesiano",
    "text": "44.7 Vantaggi dell’aggiornamento bayesiano\nUno dei principali vantaggi dell’approccio bayesiano è che ogni nuova osservazione aggiorna automaticamente le credenze preesistenti, integrando le informazioni precedenti con i nuovi dati. Questo processo consente un apprendimento iterativo e progressivo, che diventa più efficiente man mano che si accumulano dati. Inoltre, la flessibilità nella scelta della distribuzione a priori consente al ricercatore di adattare l’inferenza bayesiana al contesto specifico, migliorando ulteriormente la precisione delle stime.\nIn sintesi, il processo generatore dei dati, modellato tramite la verosimiglianza, gioca un ruolo centrale nell’aggiornamento bayesiano. Nel caso del globo, abbiamo modellato il fenomeno utilizzando una distribuzione binomiale e, attraverso l’applicazione del Teorema di Bayes, abbiamo aggiornato progressivamente le nostre credenze sulla proporzione di acqua osservata. Il risultato è una stima sempre più precisa di \\(\\theta\\), con una distribuzione a posteriori che riflette sia le osservazioni passate sia le nuove evidenze, riducendo progressivamente l’incertezza.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_intro_bayes.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/02_intro_bayes.html#riflessioni-conclusive",
    "title": "44  La quantificazione dell’incertezza",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nL’approccio bayesiano alla statistica rappresenta più di un semplice insieme di tecniche analitiche alternative: offre un paradigma fondamentalmente diverso per pensare all’incertezza, all’evidenza, e al processo di scoperta scientifica. Trattando i parametri come quantità incerte caratterizzate da distribuzioni di probabilità, fornendo meccanismi sistematici per l’aggiornamento delle credenze, e integrando naturalmente conoscenze preesistenti con nuove osservazioni, l’inferenza bayesiana si allinea più strettamente con il modo in cui gli scienziati pensano realmente al processo di ricerca.\nNella psicologia contemporanea, dove questioni di riproducibilità e comunicazione dell’incertezza sono al centro del dibattito metodologico, l’approccio bayesiano offre strumenti particolarmente rilevanti. Non è una panacea per tutti i problemi metodologici della disciplina, ma fornisce un quadro concettuale più ricco e strumenti analitici più flessibili per affrontare la complessità intrinseca dei fenomeni psicologici.\nL’obiettivo di questo capitolo non è stato quello di fornire ricette procedurali per l’analisi bayesiana - quello verrà nei capitoli successivi - ma di costruire le fondamenta concettuali necessarie per apprezzare perché l’approccio bayesiano sta diventando sempre più importante nella ricerca psicologica contemporanea. Comprendere l’incertezza come distribuzione di probabilità, il meccanismo dell’aggiornamento bayesiano, e il ruolo del processo generatore dei dati ci prepara per esplorare applicazioni più specifiche e tecniche di questi principi fondamentali.\n\n\n\n\n\n\nApprofondimento\n\n\n\n\n\nA una prima lettura, è sufficiente focalizzarsi sul significato dell’aggiornamento bayesiano e sulle conseguenze che questo produce rispetto alle nostre credenze sui parametri, man mano che vengono osservati nuovi dati. Per il momento, il meccanismo dettagliato attraverso cui l’aggiornamento bayesiano viene realizzato non è ancora stato esplicitato, e quindi gli studenti possono inizialmente tralasciare la spiegazione approfondita contenuta in questo riquadro.\nDopo aver letto il contenuto relativo alle famiglie coniugate nei capitoli successivi, sarà possibile tornare sull’esempio discusso qui e comprenderne appieno l’aggiornamento bayesiano, interpretandolo alla luce delle proprietà delle famiglie coniugate. Questo consentirà di cogliere non solo il significato generale dell’aggiornamento, ma anche i dettagli tecnici che lo rendono particolarmente efficiente in contesti come quello descritto.\nL’esempio del globo che abbiamo discusso utilizza quello che i statistici chiamano modello “Beta-Binomiale”. In questo modello, la distribuzione a priori per la proporzione pp p è una distribuzione Beta, e la verosimiglianza per le osservazioni è una distribuzione Binomiale. Questa combinazione ha una proprietà matematica elegante chiamata “coniugazione”: quando combiniamo una distribuzione a priori Beta con una verosimiglianza Binomiale usando il teorema di Bayes, la distribuzione a posteriori risultante è anch’essa una Beta.\nPrimo Pannello: l’inizio dell’esperimento\n\n\nOsservazione iniziale: Abbiamo il primo dato, un successo (“W”).\n\nA priori: La distribuzione a priori iniziale è una distribuzione Beta(1, 1). Questa rappresenta una conoscenza iniziale non informativa, ovvero l’ipotesi che qualsiasi proporzione di successi (\\(p\\)) sia ugualmente probabile.\n\nA posteriori: Con un successo su una prova: \\[\n\\text{Posterior} \\sim \\mathcal{Beta}(1 + 1, 1 + 0) = \\mathcal{Beta}(2, 1).\n\\] La distribuzione risultante è concentrata verso i valori più alti di \\(p\\), riflettendo il successo osservato.\n\nSecondo Pannello: bilanciamento dell’evidenza.\n\n\nOsservazioni: Ora abbiamo due dati, “W” e “L”, quindi un successo su due prove.\n\nA priori: La distribuzione a priori per questo passo è il posterior del pannello precedente, ovvero \\(\\mathcal{Beta}(2, 1)\\).\n\nA posteriori: Con un successo (\\(W = 1\\)) e un insuccesso (\\(L = 1\\)): \\[\n\\text{Posterior} \\sim \\mathcal{Beta}(2 + 1, 1 + 1) = \\mathcal{Beta}(3, 2).\n\\] La nuova distribuzione riflette un aggiornamento che tiene conto sia del successo che dell’insuccesso.\n\n\n\n\n\n\n\nEffetto del prior sulla distribuzione a posteriori\n\n\n\nCambiare il prior significa cambiare l’aggiornamento:\n- con un prior uniforme, la posterior riflette quasi solo la verosimiglianza;\n- con un prior informativo, la posterior “media” l’informazione dei dati con quella preesistente.\nEsempio: osservando 8 successi su 10 lanci di moneta:\n- con un prior \\(Beta(1,1)\\) la posterior è \\(Beta(9,3)\\);\n- con un prior \\(Beta(20,20)\\) la posterior è \\(Beta(28,22)\\), più “conservativa” verso 0.5.\nIl grafico mostra come due priors diversi possano produrre posteriori con varianze molto differenti.\n\n\nTerzo Pannello: accumulo progressivo.\n\n\nOsservazioni: Ora abbiamo tre dati, “W”, “L”, “W”, quindi due successi su tre prove.\n\nA priori: La distribuzione a priori è il posterior del pannello precedente, \\(\\mathcal{Beta}(3, 2)\\).\n\nA posteriori: Con due successi (\\(W = 2\\)) e un insuccesso (\\(L = 1\\)): \\[\n\\text{Posterior} \\sim \\mathcal{Beta}(3 + 1, 2 + 0) = \\mathcal{Beta}(4, 2).\n\\]\n\n\nQuarto Pannello.\n\n\nOsservazioni: Ora abbiamo quattro dati, “W”, “L”, “W”, “W”, quindi tre successi su quattro prove.\n\nA priori: La distribuzione a priori è il posterior del pannello precedente, \\(\\mathcal{Beta}(4, 2)\\).\n\nA posteriori: Con tre successi (\\(W = 3\\)) e un insuccesso (\\(L = 1\\)): \\[\n\\text{Posterior} \\sim \\mathcal{Beta}(4 + 1, 2 + 0) = \\mathcal{Beta}(5, 2).\n\\]\n\n\nQuinto Pannello.\n\n\nOsservazioni: Ora abbiamo cinque dati, “W”, “L”, “W”, “W”, “L”, quindi tre successi su cinque prove.\n\nA priori: La distribuzione a priori è il posterior del pannello precedente, \\(\\mathcal{Beta}(5, 2)\\).\n\nA posteriori: Con tre successi (\\(W = 3\\)) e due insuccessi (\\(L = 2\\)): \\[\n\\text{Posterior} \\sim \\mathcal{Beta}(5 + 0, 2 + 1) = \\mathcal{Beta}(5, 3).\n\\]\n\n\nSesto Pannello.\n\n\nOsservazioni: Ora abbiamo sei dati, “W”, “L”, “W”, “W”, “L”, “W”, quindi quattro successi su sei prove.\n\nA priori: La distribuzione a priori è il posterior del pannello precedente, \\(\\mathcal{Beta}(5, 3)\\).\n\nA posteriori: Con quattro successi (\\(W = 4\\)) e due insuccessi (\\(L = 2\\)): \\[\n\\text{Posterior} \\sim \\mathcal{Beta}(5 + 1, 3 + 0) = \\mathcal{Beta}(6, 3).\n\\]\n\n\nSettimo Pannello.\n\n\nOsservazioni: Ora abbiamo sette dati, “W”, “L”, “W”, “W”, “L”, “W”, “L”, quindi quattro successi su sette prove.\n\nA priori: La distribuzione a priori è il posterior del pannello precedente, \\(\\mathcal{Beta}(6, 3)\\).\n\nA posteriori: Con quattro successi (\\(W = 4\\)) e tre insuccessi (\\(L = 3\\)): \\[\n\\text{Posterior} \\sim \\mathcal{Beta}(6 + 0, 3 + 1) = \\mathcal{Beta}(6, 4).\n\\]\n\n\nOttavo Pannello.\n\n\nOsservazioni: Ora abbiamo otto dati, “W”, “L”, “W”, “W”, “L”, “W”, “L”, “W”, quindi cinque successi su otto prove.\n\nA priori: La distribuzione a priori è il posterior del pannello precedente, \\(\\mathcal{Beta}(6, 4)\\).\n\nA posteriori: Con cinque successi (\\(W = 5\\)) e tre insuccessi (\\(L = 3\\)): \\[\n\\text{Posterior} \\sim \\mathcal{Beta}(6 + 1, 4 + 0) = \\mathcal{Beta}(7, 4).\n\\]\n\n\nNono Pannello.\n\n\nOsservazioni: Ora abbiamo nove dati, “W”, “L”, “W”, “W”, “L”, “W”, “L”, “W”, “W”, quindi sei successi su nove prove.\n\nA priori: La distribuzione a priori è il posterior del pannello precedente, \\(\\mathcal{Beta}(7, 4)\\).\n\nA posteriori: Con sei successi (\\(W = 6\\)) e tre insuccessi (\\(L = 3\\)): \\[\n\\text{Posterior} \\sim \\mathcal{Beta}(7 + 1, 4 + 0) = \\mathcal{Beta}(8, 4).\n\\]\n\n\nIn sintesi, man mano che raccogliamo più dati, la distribuzione Beta diventa più concentrata attorno al valore di \\(p\\) che meglio spiega le osservazioni accumulate, riducendo progressivamente l’incertezza e fornendo stime sempre più precise della vera proporzione di superficie coperta d’acqua.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_intro_bayes.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/02_intro_bayes.html#informazioni-sullambiente-di-sviluppo",
    "title": "44  La quantificazione dell’incertezza",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pillar_1.11.0         tinytable_0.11.0      patchwork_1.3.1      \n#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.13.0     \n#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.0     \n#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [16] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [19] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [22] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.6         tidyselect_1.2.1     farver_2.1.2        \n#&gt;  [4] fastmap_1.2.0        TH.data_1.1-3        tensorA_0.36.2.1    \n#&gt;  [7] digest_0.6.37        estimability_1.5.1   timechange_0.3.0    \n#&gt; [10] lifecycle_1.0.4      survival_3.8-3       magrittr_2.0.3      \n#&gt; [13] compiler_4.5.1       rlang_1.1.6          tools_4.5.1         \n#&gt; [16] yaml_2.3.10          knitr_1.50           labeling_0.4.3      \n#&gt; [19] bridgesampling_1.1-2 htmlwidgets_1.6.4    pkgbuild_1.4.8      \n#&gt; [22] curl_6.4.0           RColorBrewer_1.1-3   abind_1.4-8         \n#&gt; [25] multcomp_1.4-28      withr_3.0.2          purrr_1.1.0         \n#&gt; [28] grid_4.5.1           stats4_4.5.1         xtable_1.8-4        \n#&gt; [31] colorspace_2.1-1     inline_0.3.21        emmeans_1.11.2      \n#&gt; [34] scales_1.4.0         MASS_7.3-65          cli_3.6.5           \n#&gt; [37] mvtnorm_1.3-3        rmarkdown_2.29       generics_0.1.4      \n#&gt; [40] RcppParallel_5.1.10  cachem_1.1.0         stringr_1.5.1       \n#&gt; [43] splines_4.5.1        parallel_4.5.1       vctrs_0.6.5         \n#&gt; [46] V8_6.0.5             Matrix_1.7-3         sandwich_3.1-1      \n#&gt; [49] jsonlite_2.0.0       arrayhelpers_1.1-0   glue_1.8.0          \n#&gt; [52] codetools_0.2-20     distributional_0.5.0 lubridate_1.9.4     \n#&gt; [55] stringi_1.8.7        gtable_0.3.6         QuickJSR_1.8.0      \n#&gt; [58] htmltools_0.5.8.1    Brobdingnag_1.2-9    R6_2.6.1            \n#&gt; [61] rprojroot_2.1.0      evaluate_1.0.4       lattice_0.22-7      \n#&gt; [64] backports_1.5.0      memoise_2.0.1        broom_1.0.9         \n#&gt; [67] snakecase_0.11.1     rstantools_2.4.0     coda_0.19-4.1       \n#&gt; [70] gridExtra_2.3        nlme_3.1-168         checkmate_2.3.2     \n#&gt; [73] xfun_0.52            zoo_1.8-14           pkgconfig_2.0.3",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_intro_bayes.html#bibliografia",
    "href": "chapters/bayesian_inference/02_intro_bayes.html#bibliografia",
    "title": "44  La quantificazione dell’incertezza",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGoligher, E. C., Heath, A., & Harhay, M. O. (2024). Bayesian statistics for clinical research. The Lancet, 404(10457), 1067–1076. https://doi.org/10.1016/S0140-6736(24)00055-9\n\n\nKruschke, J. (2014). Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan. Academic Press.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_statistical_models.html",
    "href": "chapters/bayesian_inference/03_statistical_models.html",
    "title": "45  Modelli statistici",
    "section": "",
    "text": "Introduzione\nQuando utilizziamo modelli statistici, il nostro obiettivo non è semplicemente descrivere i dati, ma soprattutto comprendere i processi che li hanno generati.\nQuesta distinzione porta a differenziare due famiglie di modelli:\nIl quadro concettuale per la modellizzazione e l’analisi statistica è illustrato nella figura seguente. Il punto di partenza è un problema reale e un corrispondente insieme di dati. Sulla base dei dati, costruiamo un modello probabilistico che riflette sia ciò che sappiamo sulla realtà, sia le ipotesi implicite del nostro ragionamento. All’interno del modello eseguiamo analisi e calcoli, che portano a conclusioni sul modello stesso. Infine, traduciamo queste conclusioni in affermazioni sulla realtà.\nLa statistica matematica utilizza la teoria della probabilità e altri rami della matematica per studiare i dati. In questo approccio, i dati sono considerati come realizzazioni di variabili casuali la cui distribuzione congiunta è specificata (almeno in parte) dal modello. Alcuni parametri della distribuzione restano sconosciuti e vanno stimati.\nL’analisi si concentra quindi sul modello e sui suoi parametri, con l’obiettivo di avvicinarsi al processo reale che ha generato i dati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_statistical_models.html#introduzione",
    "href": "chapters/bayesian_inference/03_statistical_models.html#introduzione",
    "title": "45  Modelli statistici",
    "section": "",
    "text": "i modelli fenomenologici, che si limitano a rappresentare le associazioni osservabili tra variabili. Sono descrittivi, ma spesso vulnerabili a errori di specificazione;\n\ni modelli meccanicistici, che cercano invece di formalizzare il processo generativo sottostante ai dati. Sono più impegnativi da costruire, ma hanno un potenziale esplicativo molto maggiore.\n\n\n\n\n\n\n\nAttenzione\n\n\n\nI modelli fenomenologici (come la regressione) possono adattarsi bene ai dati osservati, ma rischiano di fallire completamente quando applicati a nuove situazioni. Per avanzare nella conoscenza scientifica è cruciale sviluppare e confrontare modelli che riflettano i processi reali.\n\n\n\n\n\n\n\n\nFigura 45.1: Modellizzazione e analisi statistica (figura tratta da Chan & Kroese, 2025).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_statistical_models.html#campionamento-indipendente-da-una-distribuzione-fissa",
    "href": "chapters/bayesian_inference/03_statistical_models.html#campionamento-indipendente-da-una-distribuzione-fissa",
    "title": "45  Modelli statistici",
    "section": "\n45.1 Campionamento indipendente da una distribuzione fissa",
    "text": "45.1 Campionamento indipendente da una distribuzione fissa\nUno dei modelli più semplici è quello in cui i dati \\(X_1, \\ldots, X_n\\) sono considerati indipendenti e identicamente distribuiti (iid).\n\\[\nX_1, \\ldots, X_n \\stackrel{\\text{iid}}{\\sim} f \\quad \\text{oppure} \\quad X_1, \\ldots, X_n \\stackrel{\\text{iid}}{\\sim} \\text{Dist} .\n\\]\ndove \\(f\\) rappresenta la funzione di densità di probabilità (pdf) e “Dist” indica una generica distribuzione.\nPoiché le variabili sono indipendenti e identicamente distribuite, la distribuzione congiunta si scrive come prodotto delle pdf individuali:\n\\[\nf(x_1, \\ldots, x_n) = f(x_1) \\cdot f(x_2) \\cdot \\ldots \\cdot f(x_n).\n\\]\nQuesta ipotesi (iid) è alla base di moltissimi modelli statistici di uso comune.\n\n\n\n\n\n\nEsempio\n\n\n\nPensiamo a un test psicologico somministrato a 100 persone. Se assumiamo che ciascuna risposta sia indipendente dalle altre e provenga dalla stessa distribuzione, stiamo implicitamente adottando un modello iid.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_statistical_models.html#campioni-multipli-indipendenti",
    "href": "chapters/bayesian_inference/03_statistical_models.html#campioni-multipli-indipendenti",
    "title": "45  Modelli statistici",
    "section": "\n45.3 Campioni Multipli Indipendenti",
    "text": "45.3 Campioni Multipli Indipendenti\nIl caso di un singolo campione I.I.D. (indipendente e identicamente distribuito), descritto nella Sezione 4.1, può essere facilmente generalizzato a più campioni I.I.D. I modelli più comuni coinvolgono variabili casuali di Bernoulli e normali.\n\nEsempio 45.2 Per valutare se esista una differenza tra i ragazzi e le ragazze riguardo alla propensione a rispondere “sì” a una domanda su un particolare tratto di personalità (ad esempio, “Ti consideri una persona empatica?”), selezioniamo casualmente 100 ragazzi e 100 ragazze e chiediamo loro di rispondere “sì” o “no” alla domanda. Questo scenario può essere modellato tramite due campioni indipendenti di variabili casuali di Bernoulli.\nSpecificamente, per\\(i = 1, \\dots, 100\\):\n\nSia \\(X_i = 1\\) se il ragazzo i-esimo risponde “sì” alla domanda, e \\(X_i = 0\\) altrimenti.\n\nSia \\(Y_i = 1\\) se la ragazza i-esima risponde “sì” alla domanda, e \\(Y_i = 0\\) altrimenti.\n\nIn questo modo, otteniamo il seguente modello:\n\\[\nX_1, \\dots, X_{100} \\sim \\text{Ber}(p_1) \\quad \\text{(I.I.D.)},\n\\]\n\\[\nY_1, \\dots, Y_{100} \\sim \\text{Ber}(p_2) \\quad \\text{(I.I.D.)},\n\\]\ndove \\(X_1, \\dots, X_{100}, Y_1, \\dots, Y_{100}\\) sono variabili indipendenti, e \\(p_1\\) e \\(p_2\\) sono parametri sconosciuti che rappresentano, rispettivamente, la probabilità che un ragazzo o una ragazza risponda “sì” alla domanda.\nL’obiettivo è stimare la differenza \\(p_1 - p_2\\) basandosi sui valori osservati di \\(X_1, \\dots, X_{100}\\) e \\(Y_1, \\dots, Y_{100}\\). Nota che è sufficiente registrare il numero totale di ragazzi e ragazze che rispondono “sì” in ciascun gruppo, ovvero:\n\\[\nX = \\sum_{i=1}^{100} X_i \\quad \\text{e} \\quad Y = \\sum_{i=1}^{100} Y_i.\n\\]\nQuesto porta al modello binomiale a due campioni:\n\\[\nX \\sim \\text{Bin}(100, p_1), \\quad Y \\sim \\text{Bin}(100, p_2),\n\\]\ndove \\(X\\) e \\(Y\\) sono indipendenti, e \\(p_1\\) e \\(p_2\\) sono sconosciuti.\n\n\nEsempio 45.3 Da una popolazione ampia, selezioniamo 200 uomini tra i 25 e i 30 anni e misuriamo le loro altezze. Per ogni persona, registreremo anche se la madre ha fumato durante la gravidanza o meno. Supponiamo che 60 madri abbiano fumato durante la gravidanza.\nSia:\n\n\n\\(X_1, \\dots, X_{60}\\) le altezze degli uomini le cui madri hanno fumato,\n\n\\(Y_1, \\dots, Y_{140}\\) le altezze degli uomini le cui madri non hanno fumato.\n\nUn possibile modello è quello normale a due campioni: \\[\nX_1, \\dots, X_{60} \\sim N(\\mu_1, \\sigma_1^2) \\quad \\text{(I.I.D.)},\n\\]\n\\[\nY_1, \\dots, Y_{140} \\sim N(\\mu_2, \\sigma_2^2) \\quad \\text{(I.I.D.)},\n\\]\ndove \\(X_1, \\dots, X_{60}, Y_1, \\dots, Y_{140}\\) sono variabili indipendenti, e i parametri \\(\\mu_1, \\mu_2, \\sigma_1^2, \\sigma_2^2\\) sono sconosciuti.\nTipicamente, si vorrebbe valutare la differenza \\(\\mu_1 - \\mu_2\\), ovvero se il fumo durante la gravidanza influisce sull’altezza media dei figli. Invece di dividere i dati in due gruppi (madri fumatrici e non fumatrici), sarebbe possibile suddividere ulteriormente il gruppo “madri fumatrici” in sottogruppi in base all’intensità del fumo, ad esempio: raramente, moderatamente e intensamente. In tal caso, i dati potrebbero essere modellati tramite quattro campioni indipendenti da una distribuzione normale. Tale modello dipenderebbe, in generale, da otto parametri sconosciuti: quattro medie (\\(\\mu_1, \\mu_2, \\mu_3, \\mu_4\\)) e quattro varianze (\\(\\sigma_1^2, \\sigma_2^2, \\sigma_3^2, \\sigma_4^2\\)).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_statistical_models.html#modelli-di-regressione-lineare",
    "href": "chapters/bayesian_inference/03_statistical_models.html#modelli-di-regressione-lineare",
    "title": "45  Modelli statistici",
    "section": "\n45.4 Modelli di Regressione Lineare",
    "text": "45.4 Modelli di Regressione Lineare\nL’analisi della regressione riguarda la ricerca di relazioni tra diverse variabili. In particolare, c’è una variabile di risposta (o dipendente) che si vuole “spiegare” tramite una o più variabili esplicative (o indipendenti). Le variabili esplicative vengono anche chiamate predittori, covariate o variabili indipendenti. Nell’ultimo caso, la variabile di risposta è detta variabile dipendente. La regressione viene generalmente vista come una relazione funzionale tra variabili continue.\n\n45.4.1 Regressione Lineare Semplice\nIl modello di regressione più basilare prevede una relazione lineare tra la variabile di risposta e una singola variabile esplicativa. Come nei dati sull’altezza forniti da Pearson, abbiamo misurazioni \\((x_1, y_1), \\dots, (x_n, y_n)\\) che giacciono approssimativamente su una retta. Si assume che queste misurazioni siano realizzazioni di coppie \\((x_1, Y_1), \\dots, (x_n, Y_n)\\), dove, per ogni variabile esplicativa deterministica \\(x_i\\), la variabile di risposta \\(Y_i\\) è una variabile casuale con:\n\\[\n\\mathbb{E}[Y_i] = \\beta_0 + \\beta_1 x_i, \\quad i = 1, \\dots, n,\n\\]\ndove \\(\\beta_0\\) e \\(\\beta_1\\) sono parametri sconosciuti. La retta sconosciuta:\n\\[\ny = \\beta_0 + \\beta_1 x\n\\]\nè detta retta di regressione. Per specificare completamente il modello, è necessario definire la distribuzione congiunta di \\(Y_1, \\dots, Y_n\\). Il modello di regressione lineare più comune è descritto di seguito. L’aggettivo “semplice” si riferisce al fatto che viene utilizzata una sola variabile esplicativa per spiegare la risposta.\n\n45.4.2 Regressione Lineare Multipla\nUn modello di regressione lineare che include più di una variabile esplicativa è detto modello di regressione lineare multipla. In un modello di regressione lineare multipla gaussiana, i dati di risposta \\(Y_1, \\dots, Y_n\\) dipendono da variabili esplicative multidimensionali \\(x_1, \\dots, x_n\\), con \\(x_i = [x_{i1}, \\dots, x_{id}]^T\\), attraverso la relazione lineare:\n\\[\nY_i = \\beta_0 + \\beta_1 x_{i1} + \\cdots + \\beta_d x_{id} + \\varepsilon_i, \\quad \\varepsilon_1, \\dots, \\varepsilon_n \\sim \\text{i.i.d. } N(0, \\sigma^2),\n\\]\ndove \\(\\varepsilon_i\\) rappresenta il termine di errore.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_statistical_models.html#regressione-generale",
    "href": "chapters/bayesian_inference/03_statistical_models.html#regressione-generale",
    "title": "45  Modelli statistici",
    "section": "\n45.5 Regressione Generale",
    "text": "45.5 Regressione Generale\n\n45.5.1 Modelli di Regressione Non Lineari\nLa regressione generale si occupa di modellare la relazione tra una variabile risposta \\(Y\\) e una o più variabili esplicative \\(x\\). In molti casi, la relazione tra le variabili non è lineare, ma può essere descritta da funzioni più complesse. Un modello di regressione generale può essere espresso nella forma:\n\\[\nY_i = g(x_i; \\beta) + \\varepsilon_i, \\quad i = 1, \\dots, n,\n\\]\ndove:\n\n\n\\(g(x; \\beta)\\) è una funzione nota che descrive la relazione tra la variabile risposta \\(Y\\) e le variabili esplicative \\(x\\), dipendente dai parametri \\(\\beta\\).\n\n\\(\\varepsilon_i\\) rappresenta il termine di errore, solitamente assunto indipendente e identicamente distribuito (i.i.d.) con media nulla.\n\nSe la funzione \\(g(x; \\beta)\\) è lineare nei parametri \\(\\beta\\), il modello è detto modello di regressione lineare. Tuttavia, quando \\(g(x; \\beta)\\) è una funzione non lineare in \\(\\beta\\), il modello è definito come modello di regressione non lineare.\n\n45.5.1.0.1 Esempi di Modelli Non Lineari\nAlcuni esempi comuni di modelli di regressione non lineari includono:\n\n\nModello Esponenziale\n\\[\ny = a e^{bx},\n\\]\ndove \\(a\\) e \\(b\\) sono parametri da stimare.\n\n\nModello di Legge di Potenza\n\\[\ny = a x^b,\n\\] utile per descrivere fenomeni in cui la relazione tra \\(y\\) e \\(x\\) è proporzionale a una potenza di \\(x\\).\n\n\nModello Logistico\n\\[\ny = \\frac{L}{1 + e^{-(a + bx)}},\n\\]\nspesso utilizzato per modellare crescita limitata o curve a “S”.\n\n\nModello di Weibull\n\\[\ny = 1 - e^{-\\left(\\frac{x}{a}\\right)^b},\n\\]\ncomunemente usato in analisi della sopravvivenza e affidabilità.\n\n\nIn questi modelli, la funzione \\(g(x; \\beta)\\) non è lineare nei parametri \\(\\beta\\), richiedendo metodi di stima specifici, come la minimizzazione della somma dei quadrati ponderati o l’uso di algoritmi iterativi.\n\n45.5.2 Modello Lineare Generalizzato (GLM)\nNel contesto dei modelli lineari standard, si assume che gli errori \\(\\varepsilon_i\\) siano distribuiti normalmente con media zero e varianza costante (\\(\\varepsilon_i \\sim N(0, \\sigma^2)\\)). Tuttavia, in molte applicazioni reali, questa ipotesi non è soddisfatta. Ad esempio:\n\nLe variabili risposta possono essere binarie (successo/fallimento), conteggiate (numeri interi non negativi), o positive e skewed.\nLa varianza degli errori può non essere costante (eteroschedasticità).\n\nPer affrontare queste situazioni, si utilizzano i modelli lineari generalizzati (GLM), che estendono i modelli lineari tradizionali rilassando l’ipotesi di normalità sugli errori e consentendo relazioni non lineari tra la media della variabile risposta e le variabili esplicative.\nUn GLM è definito da tre componenti principali:\n\n\nFunzione di Link: Una funzione \\(h(\\cdot)\\) che collega la media della variabile risposta \\(\\mu = \\mathbb{E}[Y]\\) alle variabili esplicative tramite un modello lineare:\n\\[\nh(\\mu) = \\mathbf{x}^T \\beta.\n\\]\nAd esempio, nel caso del modello logistico, la funzione di link è il logit:\n\\[\nh(\\mu) = \\log\\left(\\frac{\\mu}{1 - \\mu}\\right).\n\\]\n\nDistribuzione della Variabile Risposta: Si assume che \\(Y\\) segua una distribuzione appartenente alla famiglia esponenziale, come Bernoulli, Poisson, Gamma, o Binomiale Negativa.\n\nRelazione di Varianza: La varianza di \\(Y\\) è funzione della sua media \\(\\mu\\), ad esempio:\n\nPer la distribuzione Poisson: \\(\\text{Var}(Y) = \\mu\\),\nPer la distribuzione Gamma: \\(\\text{Var}(Y) = \\phi \\mu^2\\).\n\n\n\n\n45.5.2.0.1 Esempi di GLM\n\n\nRegressione Logistica\nUtilizzata quando la variabile risposta è binaria (\\(Y \\in \\{0, 1\\}\\)):\n\\[\n\\log\\left(\\frac{\\mu}{1 - \\mu}\\right) = \\mathbf{x}^T \\beta,\n\\]\ndove \\(\\mu = \\mathbb{P}(Y = 1)\\).\n\n\nRegressione di Poisson\nUtilizzata per dati di conteggio (\\(Y \\in \\{0, 1, 2, \\dots\\}\\)):\n\\[\n\\log(\\mu) = \\mathbf{x}^T \\beta,\n\\]\ndove \\(\\mu = \\mathbb{E}[Y]\\).\n\n\nRegressione Gamma\nUtilizzata per dati continui positivi e skewed:\n\\[\n\\log(\\mu) = \\mathbf{x}^T \\beta.\n\\]\n\n\n45.5.3 Confronto tra Modelli Non Lineari e GLM\n\n\n\n\n\n\n\nCaratteristica\nModelli Non Lineari\nGLM\n\n\n\nFunzione di Relazione\nNon lineare nei parametri\nLineare dopo trasformazione (funzione di link)\n\n\nDistribuzione degli Errori\nSolitamente normale\nFamiglia esponenziale\n\n\nStima\nMetodi iterativi (ad es., NLSS)\nMassima verosimiglianza\n\n\nApplicazioni\nCurve di crescita, leggi fisiche\nDati binari, conteggi, positivi\n\n\n\nIn sintesi, i modelli non lineari permettono di catturare relazioni complesse tra le variabili, mentre i GLM forniscono una struttura flessibile per gestire distribuzioni non gaussiane delle variabili risposta. Entrambi i tipi di modelli sono fondamentali per l’analisi statistica moderna.\n\n45.5.4 Modelli Psicologici\nI modelli di regressione descritti in precedenza rappresentano uno strumento essenziale per l’analisi statistica, in quanto permettono di identificare e quantificare le relazioni tra variabili. Tuttavia, questi modelli hanno un carattere prevalentemente descrittivo: si limitano a evidenziare associazioni tra i dati senza fornire spiegazioni sui meccanismi causali o sui processi psicologici che le generano. Per comprendere appieno i fenomeni psicologici, è necessario andare oltre l’analisi delle associazioni statistiche e adottare modelli che descrivano i processi cognitivi e comportamentali sottostanti.\nIn questo contesto, i modelli computazionali sviluppati nell’ambito della psichiatria computazionale e della psicologia cognitiva assumono un ruolo centrale (Hitchcock et al., 2022). A differenza dei modelli statistici tradizionali, i modelli computazionali cercano di simulare i processi mentali e decisionali, offrendo una rappresentazione dinamica e meccanicistica del comportamento umano. Due esempi particolarmente rilevanti sono:\n\nModello di Apprendimento Associativo:\nQuesto modello descrive come gli individui apprendono a associare stimoli e risposte attraverso meccanismi di condizionamento. Basato su principi derivati dalla psicologia comportamentale, il modello spiega come le esperienze passate influenzino le risposte future, modulando la forza delle associazioni tra stimoli e comportamenti. È ampiamente utilizzato per studiare fenomeni come l’apprendimento per tentativi ed errori, il condizionamento classico e operante, e la formazione di abitudini.\nModello Drift-Diffusion:\nQuesto modello rappresenta il processo decisionale come un’accumulazione progressiva di evidenza verso una soglia di decisione. Simula come le informazioni vengono integrate nel tempo, tenendo conto della velocità e dell’accuratezza delle scelte. Il modello è particolarmente utile per studiare situazioni in cui gli individui devono prendere decisioni in condizioni di incertezza, come nei compiti di discriminazione percettiva o nei test di attenzione e memoria.\n\nQuesti modelli computazionali non solo permettono di descrivere il comportamento osservato, ma offrono anche una finestra sui processi cognitivi e neurali che lo guidano. Attraverso la simulazione e la previsione del comportamento, è possibile formulare ipotesi verificabili sui meccanismi interni che regolano l’apprendimento, la decisione e altre funzioni cognitive.\nPer chi desidera approfondire questi temi, è disponibile una risorsa introduttiva sui modelli computazionali in psicologia al seguente sito. Questi strumenti rappresentano un ponte tra la teoria psicologica e l’analisi empirica, contribuendo a una comprensione più profonda e dinamica dei fenomeni mentali e comportamentali.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_statistical_models.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/03_statistical_models.html#riflessioni-conclusive",
    "title": "45  Modelli statistici",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nLa distinzione tra modelli fenomenologici e meccanicistici è centrale per la ricerca psicologica:\n\nI modelli fenomenologici sono utili come strumenti descrittivi e predittivi a breve termine, ma rischiano di produrre conclusioni fuorvianti se presi come spiegazioni.\n\nI modelli meccanicistici permettono di andare oltre la descrizione, offrendo ipotesi concrete sui processi psicologici che generano i dati.\n\nLa modellazione bayesiana fornisce strumenti potenti per confrontare modelli alternativi, scegliere quelli più predittivi e verificare la loro generalizzabilità.\n\nIn sintesi, il compito della scienza psicologica non è trovare correlazioni, ma sviluppare e testare modelli dei processi. È lì che si decide se la conoscenza prodotta è robusta e utile.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_statistical_models.html#esercizi",
    "href": "chapters/bayesian_inference/03_statistical_models.html#esercizi",
    "title": "45  Modelli statistici",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nQual è il processo concettuale alla base della modellizzazione e dell’analisi statistica?\nCosa significa che un campione è indipendente e identicamente distribuito (iid) e perché questa assunzione è importante nei modelli statistici?\nCome si differenziano i modelli di campionamento da una singola distribuzione rispetto ai modelli di campioni multipli indipendenti?\nQual è la differenza tra regressione lineare semplice e regressione lineare multipla?\nIn che modo i modelli computazionali, come il modello di apprendimento associativo e il modello drift-diffusion, si differenziano dai modelli statistici tradizionali?\n\nConsegna: Rispondi con parole tue e carica il file .qmd, convertito in PDF su Moodle.\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n\nIl processo concettuale della modellizzazione e analisi statistica inizia con un problema reale e i dati raccolti su tale problema. Si costruisce quindi un modello probabilistico che rappresenta le conoscenze disponibili e il modo in cui i dati sono stati ottenuti. L’analisi viene condotta all’interno del modello, producendo conclusioni sui suoi parametri. Infine, i risultati vengono tradotti in inferenze sulla realtà, con lo scopo di migliorare la comprensione del fenomeno studiato.\nUn campione è detto indipendente e identicamente distribuito (iid) se le osservazioni sono indipendenti tra loro e seguono la stessa distribuzione di probabilità. Questa assunzione è fondamentale perché semplifica le analisi statistiche e permette di applicare risultati teorici importanti, come la legge dei grandi numeri e il teorema del limite centrale.\nNei modelli di campionamento da una singola distribuzione, si assume che tutte le osservazioni provengano da una stessa popolazione e seguano la stessa distribuzione. Nei modelli di campioni multipli indipendenti, invece, si confrontano più gruppi distinti, ciascuno con la propria distribuzione, per studiare differenze tra le popolazioni. Un esempio è il confronto tra altezze di individui con madri fumatrici e non fumatrici.\nLa regressione lineare semplice analizza la relazione tra una variabile dipendente e una sola variabile indipendente attraverso una relazione lineare. La regressione lineare multipla, invece, estende questo concetto a più variabili indipendenti, permettendo di modellare fenomeni più complessi e controllare l’effetto di più fattori simultaneamente.\nI modelli computazionali, come il modello di apprendimento associativo e il modello drift-diffusion, differiscono dai modelli statistici tradizionali perché mirano a simulare i processi mentali e decisionali sottostanti il comportamento umano. I modelli statistici descrivono principalmente relazioni tra variabili nei dati osservati, mentre i modelli computazionali cercano di rappresentare dinamicamente i meccanismi cognitivi e comportamentali che generano tali dati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_statistical_models.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/03_statistical_models.html#informazioni-sullambiente-di-sviluppo",
    "title": "45  Modelli statistici",
    "section": "Informazioni sull’ambiente di sviluppo",
    "text": "Informazioni sull’ambiente di sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pillar_1.11.0         tinytable_0.11.0      patchwork_1.3.1      \n#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.13.0     \n#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.0     \n#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [16] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [19] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [22] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.6         tidyselect_1.2.1     farver_2.1.2        \n#&gt;  [4] fastmap_1.2.0        TH.data_1.1-3        tensorA_0.36.2.1    \n#&gt;  [7] digest_0.6.37        estimability_1.5.1   timechange_0.3.0    \n#&gt; [10] lifecycle_1.0.4      survival_3.8-3       magrittr_2.0.3      \n#&gt; [13] compiler_4.5.1       rlang_1.1.6          tools_4.5.1         \n#&gt; [16] knitr_1.50           bridgesampling_1.1-2 htmlwidgets_1.6.4   \n#&gt; [19] pkgbuild_1.4.8       curl_6.4.0           RColorBrewer_1.1-3  \n#&gt; [22] abind_1.4-8          multcomp_1.4-28      withr_3.0.2         \n#&gt; [25] purrr_1.1.0          grid_4.5.1           stats4_4.5.1        \n#&gt; [28] xtable_1.8-4         colorspace_2.1-1     inline_0.3.21       \n#&gt; [31] emmeans_1.11.2       scales_1.4.0         MASS_7.3-65         \n#&gt; [34] cli_3.6.5            mvtnorm_1.3-3        rmarkdown_2.29      \n#&gt; [37] generics_0.1.4       RcppParallel_5.1.10  cachem_1.1.0        \n#&gt; [40] stringr_1.5.1        splines_4.5.1        parallel_4.5.1      \n#&gt; [43] vctrs_0.6.5          V8_6.0.5             Matrix_1.7-3        \n#&gt; [46] sandwich_3.1-1       jsonlite_2.0.0       arrayhelpers_1.1-0  \n#&gt; [49] glue_1.8.0           codetools_0.2-20     distributional_0.5.0\n#&gt; [52] lubridate_1.9.4      stringi_1.8.7        gtable_0.3.6        \n#&gt; [55] QuickJSR_1.8.0       htmltools_0.5.8.1    Brobdingnag_1.2-9   \n#&gt; [58] R6_2.6.1             rprojroot_2.1.0      evaluate_1.0.4      \n#&gt; [61] lattice_0.22-7       backports_1.5.0      memoise_2.0.1       \n#&gt; [64] broom_1.0.9          snakecase_0.11.1     rstantools_2.4.0    \n#&gt; [67] coda_0.19-4.1        gridExtra_2.3        nlme_3.1-168        \n#&gt; [70] checkmate_2.3.2      xfun_0.52            zoo_1.8-14          \n#&gt; [73] pkgconfig_2.0.3",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_statistical_models.html#bibliografia",
    "href": "chapters/bayesian_inference/03_statistical_models.html#bibliografia",
    "title": "45  Modelli statistici",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nChan, J. C. C., & Kroese, D. P. (2025). Statistical Modeling and Computation (2ª ed.). Springer.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_bayesian_inference.html",
    "href": "chapters/bayesian_inference/04_bayesian_inference.html",
    "title": "46  Inferenza bayesiana",
    "section": "",
    "text": "Introduzione\nPer uno studente di psicologia la curva di apprendimento può sembrare ripida. In realtà non lo è: i concetti chiave si acquisiscono gradualmente e si ripagano in fretta. In questo capitolo iniziamo ad esplorarli.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_bayesian_inference.html#introduzione",
    "href": "chapters/bayesian_inference/04_bayesian_inference.html#introduzione",
    "title": "46  Inferenza bayesiana",
    "section": "",
    "text": "Negli ultimi vent’anni l’inferenza bayesiana è passata da “curiosità matematica” a strumento di lavoro quotidiano in campi che vanno dalla biologia all’economia, dalla medicina alle scienze cognitive. In psicologia la sua popolarità è legata a due vantaggi pratici: la possibilità di integrare conoscenze pregresse (per esempio risultati di studi precedenti o expertise clinica) all’interno dell’analisi, e la capacità di gestire al meglio campioni piccoli o rumorosi, frequenti nei contesti sperimentali e clinici.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_bayesian_inference.html#dove-si-colloca-linferenza-nel-processo-di-ricerca",
    "href": "chapters/bayesian_inference/04_bayesian_inference.html#dove-si-colloca-linferenza-nel-processo-di-ricerca",
    "title": "46  Inferenza bayesiana",
    "section": "\n46.1 Dove si colloca l’inferenza nel processo di ricerca?",
    "text": "46.1 Dove si colloca l’inferenza nel processo di ricerca?\nRichiamiamo il diagramma di modellizzazione e analisi introdotto in Figura 45.1. L’inferenza occupa la parte centrale: partendo dai dati osservati vogliamo trarre conclusioni sul modello e sui suoi parametri \\(\\boldsymbol\\theta\\). Esistono due cornici teoriche principali:\n\n\n\n\n\n\n\n\nStatistica Bayesiana\nStatistica Frequentista\n\n\n\nNatura di \\(\\boldsymbol\\theta\\)\nvariabile aleatoria con distribuzione a priori\n\nvalore fisso ma ignoto\n\n\nUso di informazioni pregresse\nsì (explicita nella prior)\nno (basata solo sui dati)\n\n\nObiettivi tipici\nposteriore, previsione, decisione\nstima, test d’ipotesi\n\n\nFondamento concettuale\nprobabilità come grado di credenza soggettivo\nprobabilità come frequenza a lungo termine\n\n\n\nNel prosieguo ci concentreremo sul paradigma bayesiano, rimandando più avanti al confronto con l’approccio frequentista.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_bayesian_inference.html#il-teorema-di-bayes-come-regola-di-aggiornamento",
    "href": "chapters/bayesian_inference/04_bayesian_inference.html#il-teorema-di-bayes-come-regola-di-aggiornamento",
    "title": "46  Inferenza bayesiana",
    "section": "\n46.2 Il teorema di Bayes come regola di aggiornamento",
    "text": "46.2 Il teorema di Bayes come regola di aggiornamento\nL’idea centrale è semplice: si parte da una distribuzione a priori sui parametri, si osservano i dati, si ottiene una distribuzione a posteriori:\n\\[\np(\\boldsymbol\\theta\\mid\\mathbf{x})=\\frac{p(\\mathbf{x}\\mid\\boldsymbol\\theta)\\,p(\\boldsymbol\\theta)}{p(\\mathbf{x})}.\n\\]\nQui \\(p(\\mathbf{x}\\mid\\boldsymbol\\theta)\\) è la verosimiglianza, cioè il modello generativo dei dati; \\(p(\\boldsymbol\\theta)\\) rappresenta ciò che sapevamo prima, la nostra conoscenza iniziale; \\(p(\\mathbf{x})\\) è la probabilità dei dati, una costante di normalizzazione.\nIl risultato è un meccanismo di apprendimento cumulativo: ogni nuova evidenza aggiorna coerentemente le nostre credenze. In psicologia ciò è particolarmente naturale, perché gli studi spesso si accumulano su temi simili: pensiamo ad esempio agli effetti di un trattamento cognitivo-comportamentale, che vengono valutati e raffinati attraverso molte ricerche successive.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_bayesian_inference.html#un-esempio-intuitivo-la-moneta-sbilanciata",
    "href": "chapters/bayesian_inference/04_bayesian_inference.html#un-esempio-intuitivo-la-moneta-sbilanciata",
    "title": "46  Inferenza bayesiana",
    "section": "\n46.3 Un esempio intuitivo: la moneta sbilanciata",
    "text": "46.3 Un esempio intuitivo: la moneta sbilanciata\nImmaginiamo di lanciare una moneta dieci volte e ottenere otto teste. Vogliamo stimare la probabilità \\(\\theta\\) di ottenere “testa”. Possiamo rappresentare il numero di successi con una distribuzione binomiale:\n\\[\ny \\sim \\text{Binomiale}(N, \\theta).\n\\]\nPer la prior possiamo scegliere una distribuzione uniforme su [0,1], che non favorisce nessun valore, oppure una distribuzione Beta(2,2) se riteniamo più plausibile che le monete siano quasi eque.\nCombinando la prior con la verosimiglianza binomiale, otteniamo una distribuzione a posteriori ancora di tipo Beta:\n\\[\n\\theta \\mid y \\sim \\text{Beta}(\\alpha+y, \\; \\beta+N-y).\n\\]\nCon i nostri dati, la media della posteriore è circa 0.73: ci aspettiamo che la moneta cada su “testa” nel 73% dei casi. Possiamo anche calcolare la probabilità che \\(\\theta &gt; 0.5\\), che risulta circa 0.97. In altre parole, i dati ci danno forte evidenza che la moneta sia sbilanciata.\nQuesto procedimento è facilmente automatizzabile in software come R (pacchetto brms), Stan o PyMC: basta definire il modello e la prior, e il programma calcola per noi la distribuzione a posteriori.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_bayesian_inference.html#perché-usare-le-probabilità-come-gradi-di-credenza",
    "href": "chapters/bayesian_inference/04_bayesian_inference.html#perché-usare-le-probabilità-come-gradi-di-credenza",
    "title": "46  Inferenza bayesiana",
    "section": "\n46.4 Perché usare le probabilità come gradi di credenza?",
    "text": "46.4 Perché usare le probabilità come gradi di credenza?\nLe probabilità non sono solo strumenti matematici: rappresentano il modo più razionale per esprimere l’incertezza. Se le nostre valutazioni violano le regole della probabilità diventiamo vulnerabili a incoerenze logiche e decisioni subottimali, mentre rispettando gli assiomi della probabilità possiamo aggiornare in modo coerente le nostre convinzioni.\nL’approccio bayesiano sfrutta proprio questo vantaggio: ogni nuova informazione modifica le nostre credenze in modo rigoroso, senza contraddizioni. In psicologia clinica, ad esempio, un terapeuta non decide sulla base di una singola osservazione, ma integra ciò che ha visto in seduta con la propria esperienza e con la letteratura scientifica. L’aggiornamento bayesiano formalizza esattamente questo processo.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_bayesian_inference.html#il-paradigma-bayesiano-nellinferenza-statistica",
    "href": "chapters/bayesian_inference/04_bayesian_inference.html#il-paradigma-bayesiano-nellinferenza-statistica",
    "title": "46  Inferenza bayesiana",
    "section": "\n46.5 Il paradigma bayesiano nell’inferenza statistica",
    "text": "46.5 Il paradigma bayesiano nell’inferenza statistica\nL’inferenza bayesiana si fonda su tre elementi: credenze iniziali (a priori), dati osservati e credenze aggiornate (a posteriori).\nIl modello generativo rappresenta il cuore matematico del processo: specifica come i parametri non osservabili generano i dati empirici. Nel caso della moneta, la distribuzione binomiale funge da modello generativo e \\(\\theta\\) (la probabilità di testa) è il parametro chiave da stimare.\nIl paradigma bayesiano si distingue dall’approccio frequentista perché tratta i parametri come variabili casuali. La distribuzione a posteriori non fornisce soltanto una stima puntuale, ma descrive l’intera gamma di valori plausibili per i parametri. Da qui possiamo calcolare intervalli credibili, probabilità di eventi complessi e prendere decisioni basate sull’intero spettro delle possibilità.\nQuesta caratteristica è particolarmente utile in psicologia, dove i fenomeni sono incerti e complessi. La possibilità di integrare conoscenze pregresse e di quantificare rigorosamente l’incertezza rende il bayesiano uno strumento prezioso sia per la ricerca di base che per la pratica clinica.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_bayesian_inference.html#la-distribuzione-a-priori-nellinferenza-bayesiana",
    "href": "chapters/bayesian_inference/04_bayesian_inference.html#la-distribuzione-a-priori-nellinferenza-bayesiana",
    "title": "46  Inferenza bayesiana",
    "section": "\n46.6 La distribuzione a priori nell’inferenza bayesiana",
    "text": "46.6 La distribuzione a priori nell’inferenza bayesiana\nUna peculiarità del bayesiano è l’uso esplicito delle distribuzioni a priori. Esse formalizzano matematicamente le nostre conoscenze o ipotesi prima di osservare i dati. Quando non sappiamo nulla possiamo usare prior non informative, che assegnano la stessa probabilità a un ampio intervallo di valori. In altri casi è utile adottare prior debolmente informative, che escludono scenari poco plausibili ma non forzano troppo l’inferenza. Infine, se abbiamo conoscenze consolidate (per esempio da meta-analisi o da lunga esperienza clinica) possiamo usare prior informative, che incorporano in modo esplicito tali evidenze.\nUn caso speciale sono i cosiddetti priori coniugati, che hanno la proprietà di produrre una posterior appartenente alla stessa famiglia della prior. Questo semplifica molto i calcoli e rende più trasparente il processo di aggiornamento. Il classico esempio è proprio quello visto con moneta e distribuzione Beta-Binomiale.\nPer valutare se una prior sia ragionevole si usano i cosiddetti prior predictive check: si simulano dati ipotetici dalla distribuzione a priori e si controlla che i valori generati siano psicologicamente plausibili. Se, ad esempio, una prior assegna alta probabilità a tempi di reazione negativi, sappiamo che va modificata.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_bayesian_inference.html#metodi-computazionali-per-linferenza-bayesiana",
    "href": "chapters/bayesian_inference/04_bayesian_inference.html#metodi-computazionali-per-linferenza-bayesiana",
    "title": "46  Inferenza bayesiana",
    "section": "\n46.7 Metodi computazionali per l’inferenza bayesiana",
    "text": "46.7 Metodi computazionali per l’inferenza bayesiana\n\n46.7.1 La sfida computazionale nel teorema di Bayes\nIl teorema di Bayes nasconde una difficoltà pratica: la costante di normalizzazione, cioè la probabilità dei dati. Nei modelli semplici la possiamo calcolare, ma quando la complessità aumenta diventa impraticabile. Da qui nasce l’uso di metodi numerici per approssimare la distribuzione a posteriori.\n\n46.7.2 L’idea degli algoritmi MCMC\nIl metodo più diffuso è quello delle catene di Markov Monte Carlo, o MCMC. Invece di calcolare la distribuzione a posteriori in modo esplicito, si costruisce una catena di valori che, col tempo, visita lo spazio dei parametri nello stesso modo in cui essi sono distribuiti secondo la posteriori. È come avere un esploratore che si muove nello spazio dei parametri: all’inizio vaga a caso, ma dopo un po’ inizia a frequentare le zone più probabili.\nDue versioni classiche sono l’algoritmo di Metropolis-Hastings, che propone un nuovo valore del parametro e decide se accettarlo o meno, e il Gibbs sampling, che aggiorna i parametri uno alla volta estraendoli dalle distribuzioni condizionali.\n\n46.7.3 Come usare bene l’MCMC\nPerché l’MCMC funzioni è necessario qualche accorgimento. Le prime iterazioni, dette warm-up, non rappresentano bene la distribuzione e vengono scartate. Poi occorre monitorare la catena con strumenti diagnostici, osservando i tracciati o misurando l’autocorrelazione. In alcuni casi si mantiene solo un campione ogni certo numero di passi, per ridurre la dipendenza tra osservazioni consecutive.\n\n46.7.4 Alternative computazionali\nL’MCMC non è l’unica strada. Il Variational Bayes trasforma il problema in un’ottimizzazione, cercando una distribuzione semplice che approssimi la posterior: è veloce, ma tende a sottostimare l’incertezza. L’approssimazione di Laplace, invece, usa uno sviluppo matematico attorno alla moda della distribuzione per ottenere una forma gaussiana: funziona bene se la posterior è quasi normale, ma può diventare fuorviante in casi complessi.\nLa scelta dipende dal problema: MCMC per modelli complessi e quando serve precisione, VB per dataset enormi, Laplace per distribuzioni ben comportate. Negli ultimi anni, librerie come Stan, PyMC o TensorFlow Probability hanno reso queste tecniche accessibili anche a chi non è specialista di algoritmi numerici.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_bayesian_inference.html#linguaggi-di-programmazione-probabilistica-ppl",
    "href": "chapters/bayesian_inference/04_bayesian_inference.html#linguaggi-di-programmazione-probabilistica-ppl",
    "title": "46  Inferenza bayesiana",
    "section": "\n46.8 Linguaggi di programmazione probabilistica (PPL)",
    "text": "46.8 Linguaggi di programmazione probabilistica (PPL)\nPer facilitare l’uso di questi metodi sono stati sviluppati i linguaggi di programmazione probabilistica (PPL). Essi permettono di scrivere il modello in una forma molto vicina alla notazione matematica, lasciando al software il compito di occuparsi dei calcoli.\nTra i più diffusi troviamo Stan, apprezzato in ambito accademico per la sua efficienza e flessibilità; PyMC, che si integra con l’ecosistema Python e offre un’interfaccia accessibile; e TensorFlow Probability, che unisce modellizzazione probabilistica e apprendimento automatico.\nUn esempio semplice di notazione è il seguente:\n\\[\ny \\sim \\mathrm{normal}(\\mu, \\sigma), \\quad\n\\mu \\sim \\mathrm{normal}(0, 10), \\quad\n\\sigma \\sim \\mathrm{normal}^+(0, 1).\n\\]\nQui \\(y\\) rappresenta i dati, \\(\\mu\\) e \\(\\sigma\\) i parametri, e il simbolo \\(\\sim\\) si legge come “è distribuito secondo”. La stessa idea può essere scritta con le funzioni di probabilità:\n\\[\np(y \\mid \\mu, \\sigma) = \\mathrm{normal}(y \\mid \\mu, \\sigma), \\quad\np(\\mu) = \\mathrm{normal}(\\mu \\mid 0, 10), \\quad\np(\\sigma) = \\mathrm{normal}^+(\\sigma \\mid 0, 1).\n\\]\nI PPL traducono queste specifiche in codice, applicano gli algoritmi più adatti (MCMC, VB, Laplace) e restituiscono la distribuzione a posteriori.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_bayesian_inference.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/04_bayesian_inference.html#riflessioni-conclusive",
    "title": "46  Inferenza bayesiana",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nL’inferenza bayesiana ci permette di rispondere a una domanda centrale nella scienza: qual è la probabilità di un’ipotesi, dati i dati osservati? A differenza dell’approccio frequentista, che si concentra sulla probabilità dei dati sotto un’ipotesi, il bayesiano mette al centro le ipotesi stesse.\nQuesto approccio integra in modo naturale conoscenze pregresse, quantifica l’incertezza in modo rigoroso e rende possibili analisi anche con campioni piccoli o rumorosi. Non è solo una tecnica statistica, ma un modo di ragionare che rispecchia il processo stesso con cui le persone apprendono dall’esperienza: accumulando informazioni, correggendo errori, aggiornando progressivamente le proprie convinzioni.\nPer questo motivo il paradigma bayesiano non è solo uno strumento tecnico, ma un elemento sempre più essenziale della pratica scientifica in psicologia e nelle scienze della mente.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_bayesian_inference.html#esercizi",
    "href": "chapters/bayesian_inference/04_bayesian_inference.html#esercizi",
    "title": "46  Inferenza bayesiana",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nQual è la differenza principale tra l’approccio bayesiano e l’approccio frequentista all’inferenza statistica?\nCosa rappresenta la distribuzione a priori in inferenza bayesiana e quale ruolo svolge nel processo inferenziale?\nCome si calcola la distribuzione a posteriori in inferenza bayesiana e quali sono i suoi elementi principali?\nQual è il significato della funzione di verosimiglianza nel teorema di Bayes?\nCome viene interpretata la probabilità nell’approccio bayesiano rispetto a quello frequentista?\nQuali sono i vantaggi principali dell’inferenza bayesiana rispetto all’inferenza frequentista?\nCos’è una distribuzione a priori coniugata e quali vantaggi offre nel calcolo della distribuzione a posteriori?\nQuali sono i principali metodi numerici utilizzati per approssimare la distribuzione a posteriori quando i calcoli analitici non sono possibili?\nCosa sono i modelli generativi dei dati e quale ruolo svolgono nell’inferenza bayesiana?\nQuali sono le tre principali giustificazioni teoriche per l’uso delle probabilità come misura di credenza nell’inferenza bayesiana?\n\nConsegna: Rispondi con parole tue e carica il file .qmd, convertito in PDF su Moodle.\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n\nLa differenza principale tra l’approccio bayesiano e quello frequentista riguarda l’interpretazione del parametro \\(\\theta\\). Nell’approccio bayesiano, il parametro è considerato una variabile aleatoria con una distribuzione a priori, mentre nell’approccio frequentista il parametro è una quantità fissa e sconosciuta. Inoltre, l’inferenza bayesiana aggiorna le credenze attraverso il teorema di Bayes, mentre l’inferenza frequentista basa le proprie conclusioni solo sui dati osservati.\nLa distribuzione a priori rappresenta le credenze iniziali riguardo al parametro \\(\\theta\\) prima di osservare i dati. Essa consente di integrare informazioni pregresse o conoscenze esterne nel processo inferenziale, influenzando la distribuzione a posteriori e permettendo di aggiornare le credenze alla luce di nuove evidenze.\n\nLa distribuzione a posteriori si calcola applicando il teorema di Bayes:\n\\[\nf(\\theta \\mid x) = \\frac{f(x \\mid \\theta) f(\\theta)}{f(x)}\n\\]\nI suoi elementi principali sono:\n\nLa funzione di verosimiglianza \\(f(x \\mid \\theta)\\), che esprime la probabilità di osservare i dati dato un valore del parametro.\n\nLa distribuzione a priori \\(f(\\theta)\\), che rappresenta le credenze iniziali sul parametro.\n\nLa costante di normalizzazione \\(f(x)\\), che garantisce che la distribuzione a posteriori sia una distribuzione di probabilità valida.\n\n\nLa funzione di verosimiglianza, \\(f(x \\mid \\theta)\\), rappresenta la probabilità di osservare i dati dati i valori del parametro \\(\\theta\\). Essa è fondamentale nel teorema di Bayes perché determina quanto bene un certo valore di \\(\\theta\\) spiega i dati osservati, contribuendo alla determinazione della distribuzione a posteriori.\nNell’approccio bayesiano, la probabilità è interpretata come un grado di credenza soggettivo su un evento o un parametro incerto. Nell’approccio frequentista, invece, la probabilità è definita come il limite della frequenza relativa di un evento dopo un numero infinito di ripetizioni. Questo porta a differenze metodologiche nel modo in cui vengono effettuate le inferenze.\n\nI principali vantaggi dell’inferenza bayesiana sono:\n\n\nIntegrazione di informazioni pregresse: Permette di combinare dati osservati con conoscenze precedenti.\n\n\nQuantificazione dell’incertezza: Fornisce una distribuzione completa dei parametri, anziché un singolo valore stimato.\n\n\nFlessibilità: Può essere applicata a modelli complessi e a problemi con pochi dati.\n\n\nInterpretazione intuitiva: Le probabilità risultanti rappresentano direttamente il grado di credenza sui parametri.\n\n\nUna distribuzione a priori coniugata è una scelta specifica di distribuzione a priori che, quando combinata con una verosimiglianza di una certa famiglia, produce una distribuzione a posteriori della stessa famiglia. Ad esempio, una distribuzione Beta come prior per un parametro binomiale produce una distribuzione Beta come a posteriori. Questo semplifica enormemente i calcoli, poiché la distribuzione a posteriori può essere determinata in modo analitico senza necessità di metodi numerici complessi.\n\nQuando non è possibile calcolare la distribuzione a posteriori in modo analitico, si utilizzano metodi numerici come:\n\n\nMarkov Chain Monte Carlo (MCMC): Un insieme di algoritmi di campionamento (ad esempio, Metropolis-Hastings e Gibbs Sampling) che permette di stimare la distribuzione a posteriori generando campioni iterativi.\n\n\nInferenza Variazionale: Un metodo di approssimazione che ottimizza una distribuzione più semplice per avvicinarsi alla distribuzione a posteriori.\n\n\nApprossimazione di Laplace: Un’approssimazione basata sulla normalizzazione locale intorno al massimo a posteriori (MAP).\n\n\nUn modello generativo dei dati è una rappresentazione matematica del processo che ha generato i dati osservati. Esso definisce la relazione tra il parametro sconosciuto \\(\\theta\\) e i dati \\(\\mathbf{x}\\) attraverso una distribuzione di probabilità. Nell’inferenza bayesiana, il modello generativo aiuta a formulare la funzione di verosimiglianza e a inferire i parametri che meglio spiegano i dati.\nLe tre principali giustificazioni per l’uso delle probabilità come misura di credenza nell’inferenza bayesiana sono:\n\n\n\nArgomento della scommessa olandese (Dutch Book): Se i gradi di credenza non rispettano le regole della probabilità, si possono costruire scommesse che garantiscono una perdita certa, dimostrando che è irrazionale non seguire le leggi della probabilità.\n\n\nArgomento decisionistico: Per massimizzare l’utilità attesa nelle scelte razionali, i gradi di credenza devono seguire le regole della probabilità. Se non lo fanno, si possono prendere decisioni incoerenti o subottimali.\n\n\nArgomento epistemico: Le funzioni di probabilità minimizzano l’errore epistemico rispetto alla verità oggettiva, rendendole la struttura più razionale per rappresentare le credenze in condizioni di incertezza.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_bayesian_inference.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/04_bayesian_inference.html#informazioni-sullambiente-di-sviluppo",
    "title": "46  Inferenza bayesiana",
    "section": "Informazioni sull’ambiente di sviluppo",
    "text": "Informazioni sull’ambiente di sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pillar_1.11.0         tinytable_0.11.0      patchwork_1.3.1      \n#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.13.0     \n#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.0     \n#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [16] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [19] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [22] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.6         tidyselect_1.2.1     farver_2.1.2        \n#&gt;  [4] fastmap_1.2.0        TH.data_1.1-3        tensorA_0.36.2.1    \n#&gt;  [7] digest_0.6.37        estimability_1.5.1   timechange_0.3.0    \n#&gt; [10] lifecycle_1.0.4      survival_3.8-3       magrittr_2.0.3      \n#&gt; [13] compiler_4.5.1       rlang_1.1.6          tools_4.5.1         \n#&gt; [16] knitr_1.50           bridgesampling_1.1-2 htmlwidgets_1.6.4   \n#&gt; [19] pkgbuild_1.4.8       curl_6.4.0           RColorBrewer_1.1-3  \n#&gt; [22] abind_1.4-8          multcomp_1.4-28      withr_3.0.2         \n#&gt; [25] purrr_1.1.0          grid_4.5.1           stats4_4.5.1        \n#&gt; [28] xtable_1.8-4         colorspace_2.1-1     inline_0.3.21       \n#&gt; [31] emmeans_1.11.2       scales_1.4.0         MASS_7.3-65         \n#&gt; [34] cli_3.6.5            mvtnorm_1.3-3        rmarkdown_2.29      \n#&gt; [37] generics_0.1.4       RcppParallel_5.1.10  cachem_1.1.0        \n#&gt; [40] stringr_1.5.1        splines_4.5.1        parallel_4.5.1      \n#&gt; [43] vctrs_0.6.5          V8_6.0.5             Matrix_1.7-3        \n#&gt; [46] sandwich_3.1-1       jsonlite_2.0.0       arrayhelpers_1.1-0  \n#&gt; [49] glue_1.8.0           codetools_0.2-20     distributional_0.5.0\n#&gt; [52] lubridate_1.9.4      stringi_1.8.7        gtable_0.3.6        \n#&gt; [55] QuickJSR_1.8.0       htmltools_0.5.8.1    Brobdingnag_1.2-9   \n#&gt; [58] R6_2.6.1             rprojroot_2.1.0      evaluate_1.0.4      \n#&gt; [61] lattice_0.22-7       backports_1.5.0      memoise_2.0.1       \n#&gt; [64] broom_1.0.9          snakecase_0.11.1     rstantools_2.4.0    \n#&gt; [67] coda_0.19-4.1        gridExtra_2.3        nlme_3.1-168        \n#&gt; [70] checkmate_2.3.2      xfun_0.52            zoo_1.8-14          \n#&gt; [73] pkgconfig_2.0.3",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_bayesian_inference.html#bibliografia",
    "href": "chapters/bayesian_inference/04_bayesian_inference.html#bibliografia",
    "title": "46  Inferenza bayesiana",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlter, U., Too, M. A., & Cribbie, R. A. (2025). Navigating the Bayes maze: The psychologist’s guide to Bayesian statistics, a hands-on tutorial with R code. International Journal of Psychology, 60(1), e13271.\n\n\nGimenez, O., Royle, A., Kéry, M., & Nater, C. R. (2025). Ten quick tips to get you started with Bayesian statistics. PLOS Computational Biology, 21(4), e1012898.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_subj_prop.html",
    "href": "chapters/bayesian_inference/05_subj_prop.html",
    "title": "46  Aggiornare le credenze su un parametro: dal prior alla posterior",
    "section": "",
    "text": "Introduzione",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Aggiornare le credenze su un parametro: dal prior alla posterior</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_subj_prop.html#introduzione",
    "href": "chapters/bayesian_inference/05_subj_prop.html#introduzione",
    "title": "46  Aggiornare le credenze su un parametro: dal prior alla posterior",
    "section": "",
    "text": "In questo capitolo esploreremo l’inferenza bayesiana attraverso il modello binomiale, particolarmente adatto per analizzare dati dicotomici (successo/fallimento, sì/no, corretto/errato). Inizieremo con un caso molto semplice: una distribuzione a priori discreta, dove il parametro \\(\\theta\\) (la probabilità di successo) può assumere solo un numero limitato di valori predefiniti. Questo ci permetterà di vedere, passo dopo passo, come le nostre credenze su \\(\\theta\\) cambiano quando arrivano nuovi dati. Successivamente passeremo al caso più generale delle distribuzioni a priori continue, molto più adatte a modellizzare problemi reali. In particolare useremo la distribuzione Beta, che si combina perfettamente con la distribuzione Binomiale. L’obiettivo è fornire una comprensione intuitiva ma rigorosa del processo di aggiornamento bayesiano, mettendo in luce sia la logica di fondo sia le potenzialità applicative.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Aggiornare le credenze su un parametro: dal prior alla posterior</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_subj_prop.html#verosimiglianza-binomiale",
    "href": "chapters/bayesian_inference/05_subj_prop.html#verosimiglianza-binomiale",
    "title": "46  Aggiornare le credenze su un parametro: dal prior alla posterior",
    "section": "\n46.1 Verosimiglianza binomiale",
    "text": "46.1 Verosimiglianza binomiale\nLa distribuzione binomiale descrive il numero di successi \\(y\\) in \\(n\\) prove indipendenti, ciascuna con probabilità di successo \\(\\theta\\):\n\\[\np(y \\mid \\theta) = \\text{Bin}(y \\mid n, \\theta) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n-y},\n\\]\ndove \\(\\theta\\) rappresenta la probabilità di successo per singola prova, \\(y\\) è il numero osservato di successi e \\(n\\) è il numero totale di prove (fissato a priori).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Aggiornare le credenze su un parametro: dal prior alla posterior</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_subj_prop.html#esempio-psicologico-riconoscimento-di-parole-emotive",
    "href": "chapters/bayesian_inference/05_subj_prop.html#esempio-psicologico-riconoscimento-di-parole-emotive",
    "title": "46  Aggiornare le credenze su un parametro: dal prior alla posterior",
    "section": "\n46.2 Esempio psicologico: riconoscimento di parole emotive",
    "text": "46.2 Esempio psicologico: riconoscimento di parole emotive\nUn ricercatore in psicologia cognitiva conduce uno studio per stimare la proporzione di adulti in grado di riconoscere correttamente parole con contenuto emotivo positivo (es. gioia, orgoglio, speranza) all’interno di un compito di memoria a lungo termine. Ogni partecipante riceve lo stesso test standardizzato e viene classificato come:\n\n1 = corretto riconoscimento (successo), oppure\n0 = mancato riconoscimento (fallimento).\n\nIn un campione di 30 soggetti indipendenti, 22 hanno riconosciuto correttamente le parole emozionanti.\nIn questo scenario:\n\nciascun soggetto è un’unità di osservazione indipendente;\nciascun soggetto può essere considerato come una prova di una variabile di Bernoulli con probabilità di successo \\(\\theta\\), dove \\(\\theta\\) rappresenta la proporzione vera nella popolazione di adulti in grado di riconoscere correttamente parole emotive.\n\nPertanto, il numero totale di successi in \\(n = 30\\) soggetti può essere modellato come:\n\\[\nY \\sim \\text{Binomiale}(n = 30, \\theta),\n\\]\ndove \\(Y = 22\\) è il numero di successi osservati.\n\n46.2.1 Obiettivo inferenziale\nIl nostro scopo è stimare \\(\\theta\\): la probabilità che un adulto, scelto a caso dalla popolazione, riconosca correttamente le parole emotive. Nel quadro bayesiano combiniamo:\n\nla verosimiglianza (dati osservati: 22 su 30),\nuna distribuzione a priori (credenze iniziali su \\(\\theta\\)),\n\nottenendo la distribuzione a posteriori, che rappresenta la nostra conoscenza aggiornata.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Aggiornare le credenze su un parametro: dal prior alla posterior</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_subj_prop.html#metodo-basato-su-griglia",
    "href": "chapters/bayesian_inference/05_subj_prop.html#metodo-basato-su-griglia",
    "title": "46  Aggiornare le credenze su un parametro: dal prior alla posterior",
    "section": "\n46.3 Metodo basato su griglia",
    "text": "46.3 Metodo basato su griglia\nIl metodo su griglia è un approccio semplice per calcolare la distribuzione a posteriori. È didatticamente utile perché rende espliciti tutti i passaggi.\nPassaggi:\n\nDefinire una griglia di valori plausibili per \\(\\theta\\) (da 0 a 1).\nCalcolare la verosimiglianza per ogni valore di \\(\\theta\\).\nMoltiplicare verosimiglianza e priori.\nNormalizzare i valori ottenuti in modo che la somma sia 1.\n\nIl risultato è una distribuzione a posteriori che mostra come l’evidenza aggiorna le credenze iniziali.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Aggiornare le credenze su un parametro: dal prior alla posterior</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-discreta",
    "href": "chapters/bayesian_inference/05_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-discreta",
    "title": "46  Aggiornare le credenze su un parametro: dal prior alla posterior",
    "section": "\n46.4 Aggiornamento bayesiano con una distribuzione a priori discreta",
    "text": "46.4 Aggiornamento bayesiano con una distribuzione a priori discreta\n\n46.4.1 Costruzione della distribuzione a priori\nIn assenza di informazioni specifiche, possiamo assumere che tutti i valori di \\(\\theta\\) siano ugualmente plausibili. Per implementare concretamente questo approccio:\n\ndefiniamo un insieme discreto di valori possibili per \\(\\theta\\): {0, 0.1, 0.2, …, 1};\nassegniamo a ciascun valore la stessa probabilità a priori: \\(p(\\theta) = 1/11 \\approx 0.09\\).\n\nQuesta scelta rappresenta uno stato di massima incertezza iniziale, dove nessun valore di \\(\\theta\\) risulta a priori più plausibile di altri.\n\n46.4.2 Aggiornamento con i dati\nAbbiamo osservato \\(y = 22\\) successi su \\(n = 30\\). Per ogni valore \\(\\theta\\) nella griglia:\n\ncalcoliamo la verosimiglianza binomiale: \\(p(y \\mid \\theta) = \\theta^{22}(1-\\theta)^8\\);\nmoltiplichiamo per la probabilità a priori;\n\nnormalizziamo dividendo per la somma totale di tutti i prodotti ottenuti.\n\nIl risultato è una distribuzione a posteriori discreta che mostra come l’osservazione di 22 successi su 30 prove modifica le nostre credenze iniziali su \\(\\theta\\). I valori più vicini a 22/30 \\(\\approx\\) 0.7 riceveranno una maggiore probabilità a posteriori.\n\n46.4.3 Interpretazione\n\nPrima dei dati, ogni valore di \\(\\theta\\) era ugualmente plausibile.\nDopo i dati, valori come \\(\\theta = 0.7\\) o \\(0.75\\) hanno alta probabilità a posteriori.\nValori estremi (\\(0.2\\), \\(0.9\\)) diventano poco plausibili.\n\n46.4.4 Implementazione in R\nDefinizione della griglia:\n\ntheta &lt;- seq(0, 1, by = 0.1)  # Griglia di valori da 0 a 1 con passo 0.1\n\nQuando non abbiamo informazioni preliminari, usiamo una distribuzione uniforme:\n\npriori_unif &lt;- rep(1 / length(theta), length(theta))  # Probabilità uniformi\n\nVisualizziamo questa distribuzione:\n\nggplot(data.frame(theta, prob = priori_unif), aes(x = theta, y = prob)) +\n  geom_col(width = 0.08) +\n  labs(title = \"Distribuzione a Priori Uniforme\",\n       x = expression(theta),\n       y = \"Densità di probabilità\")\n\n\n\n\n\n\n\nSe invece riteniamo più probabili valori centrali di \\(\\theta\\):\n\npriori_inf &lt;- c(\n  0, 0.05, 0.05, 0.05, 0.175, 0.175, 0.175, 0.175, 0.05, 0.05, 0.05\n)\n\nVisualizzazione:\n\nggplot(data.frame(theta, prob = priori_inf), aes(x = theta, y = prob)) +\n  geom_col(width = 0.08) +\n  labs(title = \"Distribuzione a Priori Informativa\",\n       x = expression(theta),\n       y = \"Densità di probabilità\")\n\n\n\n\n\n\n\nVerosimiglianza:\n\nverosimiglianza &lt;- dbinom(22, size = 30, prob = theta)\n\nVisualizzazione:\n\nggplot(data.frame(theta, prob = verosimiglianza), aes(x = theta, y = prob)) +\n  geom_col(width = 0.08) +\n  labs(title = \"Funzione di Verosimiglianza\",\n       x = expression(theta),\n       y = \"L(θ|dati)\")\n\n\n\n\n\n\n\nCalcolo della distribuzione a posteriori:\n\nposteriori_non_norm &lt;- priori_inf * verosimiglianza\nposteriori &lt;- posteriori_non_norm / sum(posteriori_non_norm)  # Normalizzazione\n\nVisualizzazione:\n\nggplot(data.frame(theta, prob = posteriori), aes(x = theta, y = prob)) +\n  geom_col(width = 0.08) +\n  labs(title = \"Distribuzione a Posteriori\",\n       x = expression(theta),\n       y = \"P(θ|dati)\")\n\n\n\n\n\n\n\nStatistiche descrittive:\n\nmedia_post &lt;- sum(theta * posteriori)\nvar_post &lt;- sum(theta^2 * posteriori) - media_post^2\nmoda_post &lt;- theta[which.max(posteriori)]\n\ncat(\"Media a posteriori:\", round(media_post, 3),\n    \"\\nVarianza a posteriori:\", round(var_post, 3),\n    \"\\nModa a posteriori:\", moda_post)\n#&gt; Media a posteriori: 0.689 \n#&gt; Varianza a posteriori: 0.005 \n#&gt; Moda a posteriori: 0.7\n\nL’implementazione illustra tre caratteristiche essenziali dell’inferenza bayesiana. La funzione di verosimiglianza attribuisce maggiore densità di probabilità a valori di \\(\\theta\\) compresi tra 0.6 e 0.8, in accordo con l’evidenza empirica dei 22 successi osservati su 30 prove. La distribuzione a priori contribuisce in modo determinante alla configurazione della distribuzione a posteriori risultante. Il processo di aggiornamento bayesiano integra in modo rigoroso queste due fonti informative mediante l’applicazione del teorema di Bayes.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Aggiornare le credenze su un parametro: dal prior alla posterior</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-continua",
    "href": "chapters/bayesian_inference/05_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-continua",
    "title": "46  Aggiornare le credenze su un parametro: dal prior alla posterior",
    "section": "\n46.5 Aggiornamento bayesiano con una distribuzione a priori continua",
    "text": "46.5 Aggiornamento bayesiano con una distribuzione a priori continua\nUn’estensione naturale è usare una distribuzione continua come priori. La più adatta nel caso di proporzioni è la Beta.\n\nSupporto: \\([0,1]\\) (come \\(\\theta\\)).\nConiugata della Binomiale (la posteriori è ancora una Beta).\nParametri: \\(\\text{Beta}(\\alpha, \\beta)\\).\n\nEsempi:\n\n\n\\(\\text{Beta}(2,2)\\): priori simmetrica e non troppo informativa.\n\n\\(\\text{Beta}(2,5)\\): priori che privilegia valori bassi di \\(\\theta\\).\n\n\n46.5.1 Implementazione in R\nCalcoliamo la densità della distribuzione \\(\\text{Beta}(2, 2)\\) su una griglia fine di valori di \\(\\theta\\):\n\ntheta &lt;- seq(0, 1, length.out = 1000)\nprior_beta_2_2 &lt;- dbeta(theta, 2, 2) / sum(dbeta(theta, 2, 2))\n\nVisualizzazione:\n\nggplot(data.frame(theta, prior = prior_beta_2_2), aes(x = theta, y = prior)) +\n  geom_line(linewidth = 1.2) +\n  labs(title = \"Distribuzione a Priori Beta(2, 2)\", x = expression(theta), y = \"Densità\")\n\n\n\n\n\n\n\nContinuiamo con l’esempio precedente, con 22 successi in 30 prove. La verosimiglianza associata a ciascun valore di \\(\\theta\\) è calcolata come:\n\nlikelihood &lt;- dbinom(22, size = 30, prob = theta)\nlikelihood &lt;- likelihood / sum(likelihood)  # normalizzazione opzionale\n\nPoiché il prior è continuo, otteniamo la distribuzione a posteriori moltiplicando punto a punto la densità a priori per la verosimiglianza, e normalizzando:\n\nposterior_unnorm &lt;- prior_beta_2_2 * likelihood\nposterior &lt;- posterior_unnorm / sum(posterior_unnorm)\n\nVisualizziamo le tre curve:\n\ndf &lt;- data.frame(theta, prior = prior_beta_2_2, likelihood, posterior)\n\ndf_long &lt;- df |&gt;\n  pivot_longer(cols = c(\"prior\", \"likelihood\", \"posterior\"),\n               names_to = \"Distribuzione\", values_to = \"Densità\")\n\nggplot(df_long, aes(x = theta, y = Densità, color = Distribuzione)) +\n  geom_line(size = 1.2) +\n  labs(title = \"Aggiornamento Bayesiano con Prior Continua\",\n       x = expression(theta), y = \"Densità\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\nConsideriamo ora una distribuzione a priori non simmetrica, Beta(2, 5), per rappresentare credenze che privilegiano valori bassi di \\(\\theta\\).\n\nprior_2_5 &lt;- dbeta(theta, 2, 5) / sum(dbeta(theta, 2, 5))\n\nLa distribuzione a posteriori si ottiene moltiplicando la distribuzione a priori per la verosimiglianza e normalizzando il risultato:\n\nposterior &lt;- (prior_2_5 * likelihood) / sum(prior_2_5 * likelihood)\n\n\n# Uniamo tutti i dati in un dataframe per ggplot2\ndat &lt;- tibble(\n  theta,\n  prior_2_5,\n  likelihood,\n  posterior\n)\n\n# Preparazione dei dati per il plot\nlong_data &lt;- dat |&gt;\n  pivot_longer(\n    cols = c(prior_2_5, likelihood, posterior),\n    names_to = \"distribution\",\n    values_to = \"density\"\n  )\n\n# Grafico\nlong_data |&gt;\n  ggplot(aes(x = theta, y = density, color = distribution)) +\n  geom_line(size = 1.2) +\n  labs(\n    title = \"Distribuzioni Bayesiane\",\n    x = expression(theta),\n    y = \"Densità\"\n  ) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\nCalcoliamo alcune quantità descrittive utili:\n\nposterior_mean &lt;- sum(theta * posterior)\nposterior_sd &lt;- sqrt(sum((theta^2) * posterior) - posterior_mean^2)\nposterior_mode &lt;- theta[which.max(posterior)]\nposterior_mean; posterior_sd; posterior_mode\n#&gt; [1] 0.6486\n#&gt; [1] 0.07744\n#&gt; [1] 0.6567\n\nPer stimare intervalli di credibilità, possiamo campionare dalla distribuzione a posteriori:\n\nsamples &lt;- sample(theta, size = 10000, replace = TRUE, prob = posterior)\nquantile(samples, probs = c(0.03, 0.97))  # intervallo al 94%\n#&gt;     3%    97% \n#&gt; 0.4955 0.7878\n\nSe desideriamo calcolare l’intervallo di densità più alta (HPDI), possiamo utilizzare pacchetti aggiuntivi come HDInterval.\n\n# Calcolo HPDI (richiede il pacchetto HDInterval)\nhdi(samples, credMass = 0.94)\n#&gt;  lower  upper \n#&gt; 0.5025 0.7928 \n#&gt; attr(,\"credMass\")\n#&gt; [1] 0.94\n\nInterpretazione. L’aggiornamento bayesiano con una distribuzione a priori continua fornisce una stima aggiornata di \\(\\theta\\) che tiene conto sia della distribuzione a priori (conoscenza pregressa) sia della verosimiglianza (dati osservati). Nel nostro esempio, la curva a posteriori risulta spostata verso destra rispetto al prior simmetrico \\(\\text{Beta}(2,2)\\), riflettendo l’evidenza di 22 successi su 30 prove. In alternativa, utilizzando un prior asimmetrico come \\(\\text{Beta}(2,5)\\), la distribuzione a posteriori mostra un compromesso tra la tendenza iniziale a credere in basse probabilità di successo e l’evidenza empirica più ottimista.\n\n\n\n\n\n\nEstensione: media gaussiana con metodo a griglia\n\n\n\n\n\nIl metodo basato su griglia si estende anche ad altri modelli, come il caso della distribuzione normale. Per esempio, possiamo usare il metodo su griglia per stimare la media \\(\\mu\\) di una popolazione, assumendo che i dati seguano una distribuzione normale con deviazione standard nota. Anche in questo contesto, la procedura prevede di:\n\ndefinire una griglia di valori plausibili per il parametro \\(\\mu\\),\ncalcolare la verosimiglianza dei dati per ciascun valore della griglia,\nspecificare una distribuzione a priori per \\(\\mu\\),\ncombinare prior e verosimiglianza punto per punto,\nnormalizzare i risultati per ottenere una distribuzione a posteriori.\n\nEsempio: Stima bayesiana della media del QI.\nImmaginiamo di condurre uno studio su bambini ad alto potenziale cognitivo. Per semplicità, ipotizziamo che il QI in questa popolazione segua una distribuzione normale con deviazione standard nota pari a 5, mentre la media \\(\\mu\\) è incognita e rappresenta il parametro di interesse.\nSupponiamo di osservare i seguenti 10 punteggi di QI (simulati da una normale con media 130 e sd = 5):\n\nset.seed(123)\ncampione &lt;- round(rnorm(10, mean = 130, sd = 5))\n\nDefinizione della griglia per \\(\\mu\\):\n\nmu_griglia &lt;- seq(110, 150, length.out = 100)\n\nLa verosimiglianza per ciascun valore di \\(\\mu\\) è il prodotto delle densità normali dei dati osservati, assumendo \\(\\sigma = 5\\):\n\nlikelihood &lt;- sapply(mu_griglia, function(mu) {\n  prod(dnorm(campione, mean = mu, sd = 5))\n})\n\nSupponiamo ora di avere una convinzione iniziale secondo cui \\(\\mu\\) è centrata intorno a 140, con una deviazione standard pari a 3. Questa informazione può essere rappresentata con una distribuzione a priori gaussiana \\(\\mathcal{N}(140, 3^2)\\):\n\nprior &lt;- dnorm(mu_griglia, mean = 140, sd = 3)\n\nCombinando questa prior con la verosimiglianza calcolata in precedenza, otteniamo la distribuzione a posteriori:\n\nposterior &lt;- likelihood * prior\nposterior &lt;- posterior / sum(posterior)  # Normalizzazione\n\nInfine, possiamo generare un campione dalla distribuzione a posteriori discreta per calcolare quantità riassuntive e costruire intervalli di credibilità:\n\nset.seed(123)\nsamples &lt;- sample(mu_griglia, size = 10000, replace = TRUE, prob = posterior)\n\nQuantità riassuntive:\n\nmean(samples)                         # media a posteriori\n#&gt; [1] 132.6\nquantile(samples, c(0.03, 0.97))      # intervallo di credibilità al 94%\n#&gt;    3%   97% \n#&gt; 129.8 135.1\n\nVisualizzazione:\n\nlikelihood_std &lt;- likelihood / sum(likelihood)\n\ndat &lt;- tibble(\n  mu = mu_griglia,\n  Prior = prior / sum(prior),\n  Verosimiglianza = likelihood_std,\n  Posteriori = posterior\n)\n\n# Riorganizzazione in formato lungo\nlong_data &lt;- dat |&gt;\n  pivot_longer(cols = c(\"Prior\", \"Verosimiglianza\", \"Posteriori\"),\n               names_to = \"Distribuzione\",\n               values_to = \"Densità\")\n\n\nggplot(long_data, aes(x = mu, y = Densità, color = Distribuzione)) +\n  geom_line(size = 1.2) +\n  labs(\n    title = \"Confronto tra Prior, Verosimiglianza e Posteriori\",\n    x = expression(mu),\n    y = \"Densità (normalizzata)\",\n    color = NULL\n  ) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\nInterpretazione:\n\n\nLa prior riflette una credenza iniziale centrata su \\(\\mu = 140\\), coerente con l’ipotesi che i bambini siano plusdotati.\n\nLa verosimiglianza riflette i dati osservati, tendendo a concentrare la densità intorno alla media campionaria.\n\nLa posterior media tra queste due fonti di informazione, spostandosi più o meno verso la prior a seconda del numero di osservazioni e della forza dei dati.\n\nNota su stabilità numerica: uso dei logaritmi.\nPer evitare problemi di underflow, è possibile calcolare i logaritmi delle densità:\n\nlog_likelihood &lt;- sapply(mu_griglia, function(mu) {\n  sum(dnorm(campione, mean = mu, sd = 5, log = TRUE))\n})\nlog_prior &lt;- dnorm(mu_griglia, mean = 140, sd = 3, log = TRUE)\n\nlog_posterior &lt;- log_likelihood + log_prior\nlog_posterior &lt;- log_posterior - max(log_posterior)  # stabilizzazione\nposterior &lt;- exp(log_posterior) / sum(exp(log_posterior))\n\nLe quantità riassuntive che otteniamo in questo modo coincidono con quelle trovate in precedenza:\n\nset.seed(123)\nsamples &lt;- sample(mu_griglia, size = 10000, replace = TRUE, prob = posterior)\nmean(samples)                         # media a posteriori\n#&gt; [1] 132.6\nquantile(samples, c(0.03, 0.97))      # intervallo di credibilità al 94%\n#&gt;    3%   97% \n#&gt; 129.8 135.1\n\nEstensione: parametri multipli.\nNel caso in cui anche \\(\\sigma\\) sia ignota, possiamo estendere la griglia a due dimensioni:\n\n\\(\\mu \\in [110, 150]\\)\n\\(\\sigma \\in [1, 10]\\)\n\ne calcolare la verosimiglianza e la prior su ciascuna coppia \\((\\mu, \\sigma)\\). Tuttavia, il numero di combinazioni cresce rapidamente, evidenziando la maledizione della dimensionalità. In tali casi, è consigliabile usare metodi di approssimazione come l’MCMC.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Aggiornare le credenze su un parametro: dal prior alla posterior</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_subj_prop.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/05_subj_prop.html#riflessioni-conclusive",
    "title": "46  Aggiornare le credenze su un parametro: dal prior alla posterior",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nL’analisi presentata ha illustrato il processo di aggiornamento bayesiano sia per distribuzioni a priori discrete che continue, con particolare attenzione ai casi speciali che ammettono soluzioni analitiche. Questi casi, come la combinazione di priori Beta con verosimiglianze binomiali, offrono esempi particolarmente istruttivi del meccanismo bayesiano in azione.\nIl metodo basato su griglia si è rivelato uno strumento didatticamente efficace per approssimare le distribuzioni a posteriori. La sua implementazione segue un percorso logico chiaro: si discretizza lo spazio dei parametri, si valutano prior e verosimiglianza in ciascun punto della griglia, e infine si normalizzano i risultati per ottenere una distribuzione di probabilità valida. Questo approccio mantiene una trasparenza concettuale che lo rende particolarmente adatto all’introduzione dei principi bayesiani.\nTuttavia, l’utilità pratica del metodo a griglia diminuisce rapidamente con l’aumentare della complessità del modello. La cosiddetta maledizione della dimensionalità rende proibitivo il costo computazionale quando si lavora con più di pochi parametri. Un modello con appena 10 parametri, utilizzando una griglia di 100 punti per ciascuno, richiederebbe la valutazione di un numero astronomico di combinazioni (\\(10^{20}\\)), dimostrando chiaramente i limiti di scalabilità di questo approccio.\nQuesta constatazione spiega perché nella pratica statistica avanzata si preferiscano tecniche più sofisticate come il campionamento MCMC. Tali metodi, pur essendo concettualmente più complessi, offrono la flessibilità e l’efficienza necessarie per affrontare problemi reali di moderata e alta dimensionalità. Il metodo a griglia rimane comunque prezioso come strumento didattico e per analisi preliminari in contesti semplici, rappresentando una porta d’accesso comprensibile al ricco panorama dell’inferenza bayesiana.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Aggiornare le credenze su un parametro: dal prior alla posterior</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_subj_prop.html#esercizi",
    "href": "chapters/bayesian_inference/05_subj_prop.html#esercizi",
    "title": "46  Aggiornare le credenze su un parametro: dal prior alla posterior",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nIn uno studio sulla percezione delle emozioni, un partecipante osserva 10 fotografie di volti arrabbiati. Deve indicare se il volto esprime rabbia o no. Ogni risposta può essere corretta (1) o errata (0).\nI dati osservati del partecipante sono:\n1, 0, 1, 1, 1, 0, 0, 1, 1, 1\n→ Totale: 7 successi su 10 prove → \\(y = 7\\), \\(n = 10\\).\nObiettivo: stimare la probabilità \\(\\theta\\) che il partecipante riconosca correttamente un volto arrabbiato, tenendo conto sia dei dati osservati sia di conoscenze pregresse.\nPrior Informativo.\nSupponiamo di voler adottare un approccio cautamente pessimistico sulle capacità iniziali del partecipante, basandoci su studi precedenti che indicano un riconoscimento della rabbia non sempre accurato, ad esempio mediamente intorno al 40% con moderata incertezza.\nPer rappresentare questa convinzione, scegliamo come distribuzione a priori una Beta(4, 6):\n\n\nMedia: \\(\\mu = \\frac{4}{4+6} = 0.4\\)\n\n\nVarianza: \\(\\frac{4 \\cdot 6}{(10)^2 \\cdot 11} = 0.0218\\)\n\n\nQuesta prior concentra la massa di probabilità su valori inferiori a 0.5, ma lascia spazio anche a livelli di competenza superiori.\nCalcolo della Distribuzione a Posteriori con il Metodo Basato su Griglia.\n1. Griglia di valori per \\(\\theta\\).\n\ntheta &lt;- seq(0, 1, length.out = 1000)\nhead(theta)\n#&gt; [1] 0.000000 0.001001 0.002002 0.003003 0.004004 0.005005\ntail(theta)\n#&gt; [1] 0.995 0.996 0.997 0.998 0.999 1.000\n\n2. Calcolo della distribuzione a priori Beta(4, 6).\n\nprior &lt;- dbeta(theta, shape1 = 4, shape2 = 6)\nprior &lt;- prior / sum(prior)  # normalizzazione\n\nVisualizzazione:\n\nggplot(data.frame(theta, prior), aes(x = theta, y = prior)) +\n  geom_line(linewidth = 1.2) +\n  labs(\n    title = \"Distribuzione a Priori Informativa: Beta(4, 6)\",\n    x = expression(theta),\n    y = \"Densità (normalizzata)\"\n  ) +\n  theme_minimal(base_size = 14)\n\n\n\n\n\n\n\n3. Calcolo della verosimiglianza per 7 successi su 10.\n\nlikelihood &lt;- dbinom(7, size = 10, prob = theta)\nlikelihood &lt;- likelihood / sum(likelihood)  # normalizzazione\n\nVisualizzazione:\n\nggplot(data.frame(theta, likelihood), aes(x = theta, y = likelihood)) +\n  geom_line(linewidth = 1.2) +\n  labs(\n    title = \"Funzione di Verosimiglianza: 7 successi su 10\",\n    x = expression(theta),\n    y = \"Densità (normalizzata)\"\n  ) +\n  theme_minimal(base_size = 14)\n\n\n\n\n\n\n\n4. Calcolo della distribuzione a posteriori.\n\nunnormalized_posterior &lt;- prior * likelihood\nposterior &lt;- unnormalized_posterior / sum(unnormalized_posterior)\n\n5. Visualizzazione congiunta: prior, likelihood e posteriori.\n\ndata &lt;- data.frame(theta, prior, likelihood, posterior)\n\n# Imposta i livelli desiderati con nomi leggibili\nlong_data &lt;- pivot_longer(\n  data,\n  cols = c(\"prior\", \"likelihood\", \"posterior\"),\n  names_to = \"distribution\",\n  values_to = \"density\"\n) |&gt;\n  mutate(distribution = factor(\n    distribution,\n    levels = c(\"prior\", \"likelihood\", \"posterior\"),\n    labels = c(\"A Priori\", \"Verosimiglianza\", \"A Posteriori\")\n    )\n  )\n\nggplot(\n  long_data, \n  aes(x = theta, y = density, color = distribution)\n  ) +\n  geom_line(linewidth = 1.2) +\n  labs(\n    title = \"Distribuzioni Bayesiane: A Priori, Verosimiglianza e A Posteriori\",\n    x = expression(theta),\n    y = \"Densità (normalizzata)\",\n    color = NULL\n  ) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\nRiepilogo:\n\nla prior (Beta(4,6)) riflette una convinzione iniziale più scettica;\nla verosimiglianza è centrata su \\(\\theta = 0.7\\), corrispondente a 7 successi su 10;\nla posteriori media tra prior e dati, ma si sposta chiaramente verso destra, evidenziando l’effetto aggiornamento bayesiano.\n\nQuesto esempio mostra come l’approccio bayesiano:\n\n\nintegra in modo trasparente dati individuali e credenze pregresse;\n\nproduce una stima personalizzata della capacità del partecipante;\npermette di quantificare l’incertezza in modo completo, tramite la distribuzione a posteriori.\n\nQuantità a Posteriori.\nMedia:\n\nposterior_mean &lt;- sum(theta * posterior)\nposterior_mean\n#&gt; [1] 0.55\n\nDeviazione standard:\n\nposterior_sd &lt;- sqrt(sum((theta^2) * posterior) - posterior_mean^2)\nposterior_sd\n#&gt; [1] 0.1086\n\nModa:\n\nposterior_mode &lt;- theta[which.max(posterior)]\nposterior_mode\n#&gt; [1] 0.5556\n\nIntervallo di credibilità al 94%:\n\nsamples &lt;- sample(theta, size = 10000, replace = TRUE, prob = posterior)\nquantile(samples, probs = c(0.03, 0.97))\n#&gt;     3%    97% \n#&gt; 0.3433 0.7528\n\nQuesto esercizio mostra come:\n\nl’informazione pregressa può essere incorporata in modo trasparente in un modello bayesiano;\nla posteriori riflette una combinazione tra dati osservati e conoscenze precedenti.\n\n\n\n\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nIn uno studio sull’analisi delle pratiche di trasparenza e riproducibilità nella ricerca in psicologia, Hardwicke et al. (2022) hanno riportato che la condivisione dei materiali di ricerca è stata rilevata nel 14% dei casi (26 su 183 studi), con un intervallo di confidenza al 95% pari a [10%, 19%]. Questo suggerisce che la condivisione di materiali è rara.\nIspirandoti ai risultati di questo studio, costruisci una distribuzione a priori per la probabilità \\(\\theta\\) che uno studio condivida i materiali di ricerca. Per semplicità, discretizza \\(\\theta\\) in 10 livelli equispaziati: \\(0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95\\).\nAttribuisci le seguenti probabilità a priori ai 10 livelli, basandoti sull’informazione che la condivisione dei materiali è un evento raro ma non trascurabile: \\(0.05, 0.20, 0.30, 0.15, 0.10, 0.08, 0.05, 0.03, 0.02, 0.02\\).\nSupponiamo che siano stati osservati 20 studi su 100 che hanno condiviso i materiali di ricerca. Calcola la distribuzione a posteriori utilizzando il metodo basato su griglia. Calcola la media della distribuzione a posteriori e l’intervallo di credibilità al 89%.\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\n# Definizione dei possibili valori di theta (probabilità discreta)\ntheta &lt;- seq(0.05, 0.95, by = 0.10)\n\n# Definizione della distribuzione a priori\nprior &lt;- c(0.05, 0.20, 0.30, 0.15, 0.10, 0.08, 0.05, 0.03, 0.02, 0.02)\n\n# Normalizzazione della prior (se necessario, ma in questo caso già normalizzata)\nprior &lt;- prior / sum(prior)\n\n# Dati osservati\nsuccessi &lt;- 20  # studi che hanno condiviso materiali\nn &lt;- 100        # studi totali\n\n# Calcolo della verosimiglianza usando la distribuzione binomiale\nlikelihood &lt;- dbinom(successi, size = n, prob = theta)\n\n# Calcolo della distribuzione a posteriori (applicazione del teorema di Bayes)\nposterior &lt;- likelihood * prior\nposterior &lt;- posterior / sum(posterior)  # Normalizzazione\n\n# Calcolo della media della distribuzione a posteriori\nposterior_mean &lt;- sum(theta * posterior)\n\n# Calcolo dell'intervallo di credibilità al 89%\ncdf &lt;- cumsum(posterior)  # Distribuzione cumulativa\nlower_bound &lt;- theta[which.min(abs(cdf - 0.055))]  # 5.5% quantile\nupper_bound &lt;- theta[which.min(abs(cdf - 0.945))]  # 94.5% quantile\n\n# Output dei risultati\nlist(\n  posterior_mean = posterior_mean,\n  credibility_interval_89 = c(lower_bound, upper_bound)\n)\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nL’obiettivo di questo esercizio è applicare il metodo basato su griglia per stimare la distribuzione a posteriori di una proporzione, utilizzando dati dalla Scala della Rete Sociale di Lubben (LSNS-6). Si assume che un punteggio LSNS-6 superiore a una soglia prefissata indichi isolamento sociale. Il compito è:\n\nScegliere una soglia per classificare i partecipanti in due gruppi (isolati vs. non isolati), garantendo che la proporzione osservata non sia inferiore a 0.1 o superiore a 0.9.\nCalcolare la distribuzione a posteriori della proporzione usando un’approssimazione discreta su una griglia di valori.\nDeterminare l’intervallo di credibilità all’89%.\nInterpretare i risultati.\n\nConsegna: caricare su Moodle il file .qmd compilato in pdf.\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\nDati e Modellizzazione\nSi assume che i dati siano rappresentati da una variabile binaria \\(y\\), con \\(y = 1\\) per individui classificati come isolati e \\(y = 0\\) altrimenti. Supponiamo che su un campione di \\(n\\) individui, \\(s\\) siano isolati.\nDefiniamo il modello statistico:\n\\[ y_i \\sim \\text{Bernoulli}(\\theta) \\]\ncon:\n\n\n\\(y_i \\in \\{0,1\\}\\) per \\(i=1,\\dots,n\\),\n\n\\(\\theta\\) proporzione di individui isolati nella popolazione.\n\nLa distribuzione a priori su \\(\\theta\\) è scelta come \\(\\text{Beta}(2,2)\\), che rappresenta una conoscenza iniziale moderata e non estrema.\nMetodo basato su griglia\nIl metodo a griglia approssima la distribuzione a posteriori calcolando la probabilità per una serie di valori discreti di \\(\\theta\\).\n\n\nDefinire una griglia di valori per \\(\\theta\\):\ntheta &lt;- seq(0, 1, length.out = 100)\n\n\nCalcolare la distribuzione a priori:\nprior &lt;- dbeta(theta, 2, 2)\nprior &lt;- prior / sum(prior)  # Normalizzazione\n\n\nCalcolare la verosimiglianza:\nlikelihood &lt;- dbinom(s, size = n, prob = theta)\nlikelihood &lt;- likelihood / sum(likelihood)  # Normalizzazione\n\n\nCalcolare la distribuzione a posteriori:\nposterior &lt;- prior * likelihood\nposterior &lt;- posterior / sum(posterior)  # Normalizzazione\n\n\n** Calcolo dell’intervallo di credibilità all’89%**\nL’intervallo di credibilità è calcolato come l’intervallo che contiene il 89% della probabilità a posteriori.\nci_89 &lt;- quantile(sample(theta, size = 10000, prob = posterior, replace = TRUE), probs = c(0.055, 0.945))\nci_89\nInterpretazione dei risultati\n\n\nValore atteso e moda a posteriori:\nmean_theta &lt;- sum(theta * posterior)\nmode_theta &lt;- theta[which.max(posterior)]\n\nIl valore atteso fornisce una stima puntuale di \\(\\theta\\).\nLa moda indica il valore più probabile della proporzione di isolamento sociale.\n\n\n\nIntervallo di credibilità:\n\nL’89% della probabilità a posteriori cade tra i valori dell’intervallo di credibilità.\nSe l’intervallo è stretto, c’è maggiore certezza sulla proporzione stimata.\nSe l’intervallo è ampio, vi è maggiore incertezza sulla proporzione.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Aggiornare le credenze su un parametro: dal prior alla posterior</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_subj_prop.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/05_subj_prop.html#informazioni-sullambiente-di-sviluppo",
    "title": "46  Aggiornare le credenze su un parametro: dal prior alla posterior",
    "section": "Informazioni sull’ambiente di sviluppo",
    "text": "Informazioni sull’ambiente di sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] HDInterval_0.2.4      pillar_1.11.0         tinytable_0.11.0     \n#&gt;  [4] patchwork_1.3.1       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt;  [7] bayesplot_1.13.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [10] priorsense_1.1.0      posterior_1.6.1       loo_2.8.0            \n#&gt; [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [16] Rcpp_1.1.0            conflicted_1.2.0      janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.6         tidyselect_1.2.1     farver_2.1.2        \n#&gt;  [4] fastmap_1.2.0        TH.data_1.1-3        tensorA_0.36.2.1    \n#&gt;  [7] pacman_0.5.1         digest_0.6.37        estimability_1.5.1  \n#&gt; [10] timechange_0.3.0     lifecycle_1.0.4      survival_3.8-3      \n#&gt; [13] magrittr_2.0.3       compiler_4.5.1       rlang_1.1.6         \n#&gt; [16] tools_4.5.1          knitr_1.50           labeling_0.4.3      \n#&gt; [19] bridgesampling_1.1-2 htmlwidgets_1.6.4    pkgbuild_1.4.8      \n#&gt; [22] curl_6.4.0           RColorBrewer_1.1-3   abind_1.4-8         \n#&gt; [25] multcomp_1.4-28      withr_3.0.2          purrr_1.1.0         \n#&gt; [28] grid_4.5.1           stats4_4.5.1         xtable_1.8-4        \n#&gt; [31] colorspace_2.1-1     inline_0.3.21        emmeans_1.11.2      \n#&gt; [34] scales_1.4.0         MASS_7.3-65          cli_3.6.5           \n#&gt; [37] mvtnorm_1.3-3        rmarkdown_2.29       generics_0.1.4      \n#&gt; [40] RcppParallel_5.1.10  cachem_1.1.0         stringr_1.5.1       \n#&gt; [43] splines_4.5.1        parallel_4.5.1       vctrs_0.6.5         \n#&gt; [46] V8_6.0.5             Matrix_1.7-3         sandwich_3.1-1      \n#&gt; [49] jsonlite_2.0.0       arrayhelpers_1.1-0   glue_1.8.0          \n#&gt; [52] codetools_0.2-20     distributional_0.5.0 lubridate_1.9.4     \n#&gt; [55] stringi_1.8.7        gtable_0.3.6         QuickJSR_1.8.0      \n#&gt; [58] htmltools_0.5.8.1    Brobdingnag_1.2-9    R6_2.6.1            \n#&gt; [61] rprojroot_2.1.0      evaluate_1.0.4       lattice_0.22-7      \n#&gt; [64] backports_1.5.0      memoise_2.0.1        broom_1.0.9         \n#&gt; [67] snakecase_0.11.1     rstantools_2.4.0     coda_0.19-4.1       \n#&gt; [70] gridExtra_2.3        nlme_3.1-168         checkmate_2.3.2     \n#&gt; [73] xfun_0.52            zoo_1.8-14           pkgconfig_2.0.3",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Aggiornare le credenze su un parametro: dal prior alla posterior</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_subj_prop.html#bibliografia",
    "href": "chapters/bayesian_inference/05_subj_prop.html#bibliografia",
    "title": "46  Aggiornare le credenze su un parametro: dal prior alla posterior",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlbert, J., & Hu, J. (2019). Probability and Bayesian Modeling. CRC Press.\n\n\nHardwicke, T. E., Thibault, R. T., Kosie, J. E., Wallach, J. D., Kidwell, M. C., & Ioannidis, J. P. (2022). Estimating the prevalence of transparency and reproducibility-related research practices in psychology (2014–2017). Perspectives on Psychological Science, 17(1), 239–251.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Aggiornare le credenze su un parametro: dal prior alla posterior</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_conjugate_families_1.html",
    "href": "chapters/bayesian_inference/07_conjugate_families_1.html",
    "title": "48  Distribuzioni coniugate (1)",
    "section": "",
    "text": "Introduzione\nPer favorire la comprensione, procederemo in tre fasi principali:",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_conjugate_families_1.html#introduzione",
    "href": "chapters/bayesian_inference/07_conjugate_families_1.html#introduzione",
    "title": "48  Distribuzioni coniugate (1)",
    "section": "",
    "text": "In questo capitolo, esploriamo il concetto di distribuzioni a priori coniugate e il loro ruolo nell’inferenza bayesiana. Utilizzando il modello beta-binomiale come esempio paradigmatico, dimostreremo come queste distribuzioni semplificano l’analisi attraverso calcoli analitici diretti. L’uso di una distribuzione a priori coniugata non solo rende l’inferenza più agevole, ma fornisce anche una chiara visione del modo in cui le credenze a priori influenzano le conclusioni.\n\n\n\nIntroduzione del modello beta-binomiale.\nAnalisi della distribuzione Beta e del suo ruolo come distribuzione a priori.\nDescrizione del processo di aggiornamento bayesiano e dei vantaggi derivanti dall’uso di distribuzioni coniugate.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_conjugate_families_1.html#il-modello-beta-binomiale",
    "href": "chapters/bayesian_inference/07_conjugate_families_1.html#il-modello-beta-binomiale",
    "title": "48  Distribuzioni coniugate (1)",
    "section": "\n48.1 Il Modello Beta-Binomiale",
    "text": "48.1 Il Modello Beta-Binomiale\nIl modello beta-binomiale è un esempio classico per analizzare una proporzione \\(\\theta\\), ossia la probabilità di successo in una sequenza di prove binarie (ad esempio, successo/fallimento). Supponiamo di osservare \\(y\\) successi su \\(n\\) prove, dove ogni prova è indipendente e con la stessa probabilità di successo \\(\\theta\\), che appartiene all’intervallo \\([0,1]\\).\nLa funzione di verosimiglianza, basata sulla distribuzione binomiale, è espressa come:\n\\[\n\\mathcal{Binomial}(y \\mid n, \\theta) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n - y},\n\\]\ndove \\(\\binom{n}{y}\\) è il coefficiente binomiale che conta il numero di modi in cui \\(y\\) successi possono verificarsi in \\(n\\) prove.\nPer modellare la nostra conoscenza preliminare su \\(\\theta\\), scegliamo una distribuzione a priori Beta, che rappresenta un’ampia gamma di credenze iniziali con parametri flessibili.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_conjugate_families_1.html#la-distribuzione-beta",
    "href": "chapters/bayesian_inference/07_conjugate_families_1.html#la-distribuzione-beta",
    "title": "48  Distribuzioni coniugate (1)",
    "section": "\n48.2 La Distribuzione Beta",
    "text": "48.2 La Distribuzione Beta\nLa distribuzione Beta è definita come:\n\\[\n\\mathcal{Beta}(\\theta \\mid \\alpha, \\beta) = \\frac{1}{B(\\alpha, \\beta)} \\theta^{\\alpha - 1} (1 - \\theta)^{\\beta - 1}, \\quad \\text{con } \\theta \\in (0, 1),\n\\]\ndove:\n\n\\(\\alpha &gt; 0\\) e \\(\\beta &gt; 0\\) sono i iperparametri, che determinano la forma della distribuzione.\n\n\\(B(\\alpha, \\beta)\\) è la funzione Beta di Eulero, calcolata come:\n\\[\n  B(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)},\n  \\]\ndove \\(\\Gamma(x)\\) è la funzione Gamma, una generalizzazione del fattoriale.\n\n\nNel contesto bayesiano:\n\n\n\\(\\alpha -1\\) rappresenta il numero ipotetico di “successi” a priori.\n\n\\(\\beta -1\\) rappresenta il numero ipotetico di “fallimenti” a priori.\n\nAd esempio:\n\nuna distribuzione Beta(1, 1) è uniforme (0 successi a priori e 0 fallimenti), indicando totale incertezza iniziale (assenza di credenze informate);\nuna distribuzione Beta(10, 20) rappresenta una conoscenza a priori basata su 9 successi e 19 fallimenti ipotizzati, indicando una convinzione iniziale relativamente solida, poiché deriva da un totale di 28 osservazioni virtuali che riflettono le credenze precedenti.\n\nQuesta interpretazione consente di calibrare le credenze a priori in base all’evidenza disponibile o alla fiducia nella stima.\nLa distribuzione Beta è estremamente versatile:\n\nvalori diversi di \\(\\alpha\\) e \\(\\beta\\) producono distribuzioni simmetriche, asimmetriche o uniformi;\nvalori elevati di \\(\\alpha\\) e \\(\\beta\\) riducono la varianza, riflettendo credenze più forti.\n\nQuesta flessibilità rende la distribuzione Beta una scelta ideale per rappresentare credenze iniziali su proporzioni.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_conjugate_families_1.html#aggiornamento-bayesiano",
    "href": "chapters/bayesian_inference/07_conjugate_families_1.html#aggiornamento-bayesiano",
    "title": "48  Distribuzioni coniugate (1)",
    "section": "\n48.3 Aggiornamento bayesiano",
    "text": "48.3 Aggiornamento bayesiano\nL’aggiornamento bayesiano combina le informazioni iniziali (priori) con i dati osservati (verosimiglianza) per produrre una nuova distribuzione delle credenze (posteriori). Nel caso del modello beta-binomiale, questo processo è particolarmente semplice grazie alla “coniugazione”: il prior Beta e la verosimiglianza Binomiale producono una distribuzione a posteriori che appartiene ancora alla famiglia Beta.\n\nTeorema 48.1 Sia \\(Y\\sim\\mathrm{Binomial}(n,\\theta)\\) il numero di successi \\(y\\) in \\(n\\) prove indipendenti con probabilità di successo \\(\\theta\\), e sia la nostra distribuzione a priori su \\(\\theta\\) una Beta\\(\\bigl(\\alpha,\\beta\\bigr).\\) Allora la distribuzione a posteriori di \\(\\theta\\) dato l’osservazione \\(Y=y\\) è\n\\[\n\\theta \\mid Y=y\n\\;\\sim\\;\n\\mathrm{Beta}\\bigl(\\alpha + y,\\;\\beta + (n - y)\\bigr),\n\\]\novvero i parametri si aggiornano come\n\\[\n\\alpha' = \\alpha + y,\n\\quad\n\\beta' = \\beta + n - y.\n\\]\n\n\n48.3.1 Dimostrazione\n1. Formula di Bayes (forma proporzionale).\nLa densità a posteriori si ottiene, a meno di una costante di normalizzazione, moltiplicando prior e verosimiglianza:\n\\[\np(\\theta\\mid y)\n\\;\\propto\\;\np(y\\mid\\theta)\\;\\times\\;p(\\theta).\n\\]\nIgnoriamo per ora i fattori che non dipendono da \\(\\theta\\).\n2. Verosimiglianza binomiale.\nLa probabilità di osservare \\(y\\) successi in \\(n\\) prove è\n\\[\np(y\\mid\\theta)\n=\\binom ny\\,\\theta^y\\,(1-\\theta)^{\\,n-y}.\n\\]\nPoiché \\(\\binom ny\\) non dipende da \\(\\theta\\), terremo solo\n\\[\np(y\\mid\\theta)\\;\\propto\\;\\theta^y\\,(1-\\theta)^{\\,n-y}.\n\\]\n3. Prior Beta.\nLa densità del prior è\n\\[\np(\\theta)\n=\\frac{1}{B(\\alpha,\\beta)}\\,\n\\theta^{\\,\\alpha-1}\\,(1-\\theta)^{\\,\\beta-1},\n\\]\ne quindi, a meno della costante \\(B(\\alpha,\\beta)\\),\n\\[\np(\\theta)\\;\\propto\\;\\theta^{\\,\\alpha-1}\\,(1-\\theta)^{\\,\\beta-1}.\n\\]\n4. Prodotto prior × verosimiglianza.\nMoltiplichiamo le due parti dipendenti da \\(\\theta\\):\n\\[\np(\\theta\\mid y)\n\\;\\propto\\;\n\\bigl[\\theta^y\\,(1-\\theta)^{\\,n-y}\\bigr]\\;\n\\bigl[\\theta^{\\,\\alpha-1}\\,(1-\\theta)^{\\,\\beta-1}\\bigr]\n=\n\\theta^{\\,(\\alpha-1)+y}\\;\\bigl(1-\\theta\\bigr)^{\\,(\\beta-1)+(n-y)}.\n\\]\n5. Riconoscere la forma Beta.\nUna Beta\\((a,b)\\) ha densità proporzionale a\n\\[\n\\theta^{\\,a-1}\\,(1-\\theta)^{\\,b-1}.\n\\]\nConfrontando esponenti:\n\n\nSull’esponenziale di \\(\\theta\\):\n\\[\n  (\\alpha-1)+y \\;=\\;(a-1)\n  \\quad\\Longrightarrow\\quad\n  a \\;=\\;\\alpha+y.\n\\]\n\n\nSull’esponenziale di \\((1-\\theta)\\):\n\\[\n  (\\beta-1)+(n-y) \\;=\\;(b-1)\n  \\quad\\Longrightarrow\\quad\n  b \\;=\\;\\beta+(n-y).\n\\]\n\n\nNe segue che\n\\[\np(\\theta\\mid y)\n\\;\\propto\\;\\theta^{\\,(\\alpha+y)-1}\\,(1-\\theta)^{\\,(\\beta+n-y)-1},\n\\]\ncioè\n\\[\n\\boxed{\n\\theta\\mid Y=y \\;\\sim\\;\\mathrm{Beta}\\bigl(\\alpha+y,\\;\\beta+n-y\\bigr).\n}\n\\]\n\n48.3.2 Proprietà del posterior\n\nMedia a posteriori\n\n\\[\n\\mathbb{E}[\\theta\\mid y]\n    = \\frac{\\alpha+y}{\\alpha+\\beta+n}.\n\\]\n\nVarianza a posteriori\n\n\\[\n\\mathrm{Var}[\\theta\\mid y]\n    = \\frac{(\\alpha+y)\\,(\\beta+n-y)}{\\bigl(\\alpha+\\beta+n\\bigr)^2\\,(\\alpha+\\beta+n+1)}.\n\\]\n\n48.3.3 Vantaggi del modello Beta-Binomiale\n\n\nSemplicità analitica: La coniugatezza della distribuzione Beta-Binomiale semplifica i calcoli, rendendo immediato l’aggiornamento dei parametri.\n\nInterpretazione intuitiva: L’aggiornamento dei parametri \\(\\alpha\\) e \\(\\beta\\) mostra in modo trasparente come i dati influenzino le credenze.\n\nIn sintesi, il modello Beta-Binomiale è un esempio didattico fondamentale per comprendere l’inferenza bayesiana e rappresenta un punto di partenza ideale per approcci più avanzati.\n\nEsempio 48.1 Nel Capitolo 47 abbiamo utilizzato il metodo basato su griglia per determinare la distribuzione a posteriori nel caso di \\(y = 6\\) successi su \\(n = 9\\) prove (vedi anche McElreath, 2020 per una discussione dettagliata). Ora esploriamo un approccio alternativo, sfruttando le proprietà delle famiglie coniugate.\nLa verosimiglianza binomiale per questo esperimento è espressa dalla seguente funzione:\n\\[\n\\mathcal{L}(\\theta) \\propto \\theta^y (1-\\theta)^{n-y},\n\\]\ndove \\(y = 6\\) rappresenta il numero di successi e \\(n = 9\\) il numero totale di prove.\nScegliendo una distribuzione a priori Beta con parametri \\(\\alpha = 2\\) e \\(\\beta = 5\\), possiamo applicare il teorema di Bayes per calcolare i parametri aggiornati della distribuzione a posteriori. In base alla regola di aggiornamento per distribuzioni coniugate, otteniamo:\n\\[\n\\alpha' = \\alpha + y = 2 + 6 = 8.\n\\] \\[\n\\beta' = \\beta + n - y = 5 + 9 - 6 = 8.\n\\]\nLa distribuzione a posteriori risultante è quindi una distribuzione Beta con parametri \\(\\mathcal{Beta}(8, 8)\\).\nProcediamo ora a visualizzare le tre distribuzioni rilevanti:\n\n\nDistribuzione a priori: \\(\\mathcal{Beta}(2, 2)\\),\n\nVerosimiglianza binomiale: per \\(y = 6\\) e \\(n = 9\\),\n\nDistribuzione a posteriori: \\(\\text{Beta}(8, 5)\\).\n\nEcco il codice R per generare il grafico comparativo:\n\n# Definizione dei parametri\nalpha_prior &lt;- 2\nbeta_prior &lt;- 5\ny &lt;- 6\nn &lt;- 9\n\n# Parametri della distribuzione a posteriori\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + n - y\n\n# Sequenza di valori di theta\ntheta &lt;- seq(0, 1, length.out = 1000)\n\n# Calcolo delle PDF\nprior_pdf &lt;- dbeta(theta, shape1 = alpha_prior, shape2 = beta_prior)\nlikelihood &lt;- theta^y * (1 - theta)^(n - y)\n\n# Normalizzazione della verosimiglianza\nlikelihood_integral &lt;- sum(likelihood) * (theta[2] - theta[1])\nnormalized_likelihood &lt;- likelihood / likelihood_integral\n\nposterior_pdf &lt;- dbeta(theta, shape1 = alpha_post, shape2 = beta_post)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  theta = rep(theta, 3),\n  densita = c(prior_pdf, normalized_likelihood, posterior_pdf),\n  distribuzione = rep(c(\"Prior\", \"Likelihood\", \"Posterior\"), each = length(theta))\n)\n\n# Creare il grafico \nggplot(df, aes(x = theta, y = densita, color = distribuzione)) +\n  geom_line(size = 1) +  # Aggiungere le linee per le distribuzioni\n  scale_color_manual(values = c(\"Prior\" = \"blue\", \"Likelihood\" = \"green\", \"Posterior\" = \"red\")) +  # Assegnare i colori\n  labs(title = \"Distribuzioni Prior, Likelihood e Posterior\",\n       x = expression(theta),\n       y = \"Densità\",\n       color = \"Distribuzione\") +  # Aggiungere titoli e label\n  theme(legend.position = \"top\")  # Posizionare la legenda in alto\n\n\n\n\n\n\n\n\n\nCurva blu: Prior \\(\\mathcal{Beta}(2, 5)\\), che riflette le credenze iniziali prima dell’osservazione dei dati.\n\n\nCurva verde: Likelihood (normalizzata), rappresenta l’evidenza fornita dai dati osservati.\n\n\nCurva rossa: Posterior \\(\\mathcal{Beta}(8, 8)\\), risultato dell’aggiornamento bayesiano che combina prior e likelihood.\n\nNota sulla normalizzazione della verosimiglianza. La verosimiglianza binomiale non è una distribuzione di probabilità (il suo integrale non è pari a 1). Per rappresentarla visivamente accanto alla distribuzione a priori e a quella a posteriori, è necessario normalizzarla. Questo è fatto calcolando il suo integrale su \\(\\theta \\in [0, 1]\\) e dividendo la funzione per il risultato. La normalizzazione serve solo per la visualizzazione e non influisce sui calcoli analitici.\n\n\nEsempio 48.2 Esaminiamo ora un esempio discuso da Johnson et al. (2022). In uno studio molto famoso, Stanley Milgram ha studiato la propensione delle persone a obbedire agli ordini delle figure di autorità, anche quando tali ordini potrebbero danneggiare altre persone (Milgram 1963). Nell’articolo, Milgram descrive lo studio come\n\nconsistente nell’ordinare a un soggetto ingenuo di somministrare una scossa elettrica a una vittima. Viene utilizzato un generatore di scosse simulato, con 30 livelli di tensione chiaramente contrassegnati che vanno da IS a 450 volt. Lo strumento porta delle designazioni verbali che vanno da Scossa Lieve a Pericolo: Scossa Grave. Le risposte della vittima, che è un complice addestrato dell’esperimentatore, sono standardizzate. Gli ordini di somministrare scosse vengono dati al soggetto ingenuo nel contesto di un ‘esperimento di apprendimento’ apparentemente organizzato per studiare gli effetti della punizione sulla memoria. Man mano che l’esperimento procede, al soggetto ingenuo viene ordinato di somministrare scosse sempre più intense alla vittima, fino al punto di raggiungere il livello contrassegnato Pericolo: Scossa Grave.\n\nIn altre parole, ai partecipanti allo studio veniva dato il compito di testare un altro partecipante (che in realtà era un attore addestrato) sulla loro capacità di memorizzare una serie di item. Se l’attore non ricordava un item, al partecipante veniva ordinato di somministrare una scossa all’attore e di aumentare il livello della scossa con ogni fallimento successivo. I partecipanti non erano consapevoli del fatto che le scosse fossero finte e che l’attore stesse solo fingendo di provare dolore dalla scossa.\nNello studio di Milgram, 26 partecipanti su 40 hanno somministrato scosse al livello “Pericolo: Scossa Grave”. Il problema richiede di costruire la distribuzione a posteriori della probabilità \\(\\theta\\) di infliggere una scossa a l livello “Pericolo: Scossa Grave”, ipotizzando che uno studio precedente aveva stabilito che \\(\\theta\\) segue una distribuzione Beta(1, 10).\nIniziamo a fornire una rappresentazione grafica della distribuzione a priori.\n\n# Impostazione dei parametri della distribuzione Beta\nalpha &lt;- 1\nbeta_val &lt;- 10\n\n# Creazione di valori x per il plot\nx_values &lt;- seq(0, 1, length.out = 1000)\n\n# Calcolo della densità di probabilità per ogni valore di x\nbeta_pdf &lt;- dbeta(x_values, shape1 = alpha, shape2 = beta_val)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  x = x_values,\n  densita = beta_pdf\n)\n\n# Creare il grafico\nggplot(df, aes(x = x, y = densita)) +\n  geom_line(color = \"#b97c7c\", size = 1) +  # Aggiungere la linea per la densità\n  labs(title = \"Distribuzione Beta(1, 10)\",  # Aggiungere il titolo\n       x = \"x\",  # Label dell'asse x\n       y = \"Densità di probabilità\") +  # Label dell'asse y\n  theme(plot.title = element_text(hjust = 0.5)) +  # Centrare il titolo\n  geom_vline(xintercept = 0, color = \"black\", linetype = \"dashed\", size = 0.5) +  # Linea verticale opzionale\n  geom_vline(xintercept = 1, color = \"black\", linetype = \"dashed\", size = 0.5) +  # Linea verticale opzionale\n  annotate(\"text\", x = 0.8, y = max(beta_pdf) * 0.9, label = \"Beta(1, 10)\", color = \"#b97c7c\", size = 5)  # Aggiungere una legenda\n\n\n\n\n\n\n\nLa distribuzione a posteriori segue una distribuzione Beta con parametri aggiornati:\n\ny &lt;- 26\nn &lt;- 40\n\nalpha_prior &lt;- 1\nbeta_prior &lt;- 10\n\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + n - y\n\nalpha_post\n#&gt; [1] 27\nbeta_post\n#&gt; [1] 24\n\nCreazione di un grafico per la distribuzione a posteriori:\n\n# Creazione di valori x per il plot\nx_values &lt;- seq(0, 1, length.out = 1000)\n\n# Calcolo della densità di probabilità per ogni valore di x\nbeta_pdf &lt;- dbeta(x_values, alpha_post, beta_post)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  theta = x_values,\n  densita = beta_pdf\n)\n\n# Creare il grafico con ggplot2\nggplot(df, aes(x = theta, y = densita)) +\n  geom_line(color = \"blue\", size = 1) +  # Aggiungere la linea per la densità\n  labs(title = \"Distribuzione Beta(27, 24)\",  # Aggiungere il titolo\n       x = expression(theta),  # Label dell'asse x usando espressioni matematiche\n       y = \"Densità di probabilità\") +  # Label dell'asse y\n  theme(plot.title = element_text(hjust = 0.5)) +  # Centrare il titolo\n  annotate(\"text\", x = 0.8, y = max(beta_pdf) * 0.9, label = \"Beta(27, 24)\", color = \"blue\", size = 5)  \n\n\n\n\n\n\n\nCalcolo della media a posteriori di \\(\\theta\\):\n\nalpha_post / (alpha_post + beta_post)\n#&gt; [1] 0.5294\n\nCalcolo della moda a posteriori:\n\n(alpha_post - 1) / (alpha_post + beta_post - 2)\n#&gt; [1] 0.5306\n\nCalcolo della probabilità che \\(\\theta &gt; 0.6\\):\n\npbeta(0.6, alpha_post, beta_post, lower.tail = FALSE)\n#&gt; [1] 0.1562\n\nOvvero:\n\n1 - pbeta(0.6, alpha_post, beta_post)\n#&gt; [1] 0.1562\n\nEseguiamo il problema utilizzando il metodo basato su griglia. Definiamo la griglia di interesse:\n\ntheta &lt;- seq(0, 1, length.out = 100)\n\nCreiamo la distribuzione a priori:\n\nprior &lt;- dbeta(theta, alpha_prior, beta_prior)\n\n# Normalizzazione della densità per ottenere una somma pari a 1\nprior_normalized &lt;- prior / sum(prior)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  theta = theta,\n  probabilita = prior_normalized\n)\n\n# Creare il grafico con ggplot2\nggplot(df, aes(x = theta, y = probabilita)) +\n  geom_segment(aes(x = theta, xend = theta, y = 0, yend = probabilita), \n               color = \"blue\", size = 1) +  # Linee verticali per rappresentare le probabilità\n  labs(title = \"Distribuzione a priori\",  # Aggiungere il titolo\n       x = expression(theta),  # Label dell'asse x usando espressioni matematiche\n       y = \"Probabilità\") +  # Label dell'asse y\n  theme(plot.title = element_text(hjust = 0.5))  # Centrare il titolo\n\n\n\n\n\n\n\nCreiamo la verosimiglianza:\n\nlk &lt;- dbinom(y, n, theta)\n\n# Normalizzazione della verosimiglianza per ottenere una somma pari a 1\nlk_normalized &lt;- lk / sum(lk)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  theta = theta,\n  probabilita = lk_normalized\n)\n\n# Creare il grafico con ggplot2\nggplot(df, aes(x = theta, y = probabilita)) +\n  geom_segment(aes(x = theta, xend = theta, y = 0, yend = probabilita), \n               color = \"red\", size = 1) +  # Linee verticali per rappresentare la verosimiglianza\n  labs(title = \"Verosimiglianza\",  # Aggiungere il titolo\n       x = expression(theta),  # Label dell'asse x usando espressioni matematiche\n       y = \"Probabilità\") +  # Label dell'asse y\n  theme(plot.title = element_text(hjust = 0.5))  # Centrare il titolo\n\n\n\n\n\n\n\nCalcoliamo la distribuzione a posteriori:\n\npost &lt;- (prior * lk) / sum(prior * lk)\n\n# Normalizzazione della verosimiglianza per ottenere una somma pari a 1\nlk_normalized &lt;- lk / sum(lk)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  theta = theta,\n  probabilita = lk_normalized\n)\n\n# Creare il grafico con ggplot2\nggplot(df, aes(x = theta, y = probabilita)) +\n  geom_segment(aes(x = theta, xend = theta, y = 0, yend = probabilita), \n               color = \"green\", size = 1) +  # Linee verticali per rappresentare la verosimiglianza\n  labs(title = \"Distribuzione a posteriori\",  # Aggiungere il titolo\n       x = expression(theta),  # Label dell'asse x usando espressioni matematiche\n       y = \"Probabilità\") +  # Label dell'asse y\n  theme(plot.title = element_text(hjust = 0.5))  # Centrare il titolo\n\n\n\n\n\n\n\nEstrazione di un campione dalla distribuzione a posteriori:\n\nsamples &lt;- sample(theta, size = 1e6, replace = TRUE, prob = post)\n\nTroviamo la media a posteriori:\n\nmean(samples)\n#&gt; [1] 0.5295\n\nCalcoliamo la probabilità che \\(\\theta &gt; 0.6\\):\n\nmean(samples &gt; 0.6)\n#&gt; [1] 0.1527\n\nQuesto codice mantiene la struttura logica del problema e produce risultati equivalenti utilizzando R.\n\n\nEsempio 48.3 Consideriamo un esempio discusso da Nalborczyk (2018) nel quale, oltre all’applicazione del teorema beta-binimiale, viene anche introdotto il concetto di posterior-predictive check.\nSupponiamo di reclutare partecipanti per uno studio di mezza ora:\n\nPossiamo farlo fra le 9:00 e le 18:00, con sessioni ogni 30 minuti.\n\nIn una settimana lavorativa (lun–ven) otteniamo \\(n = 90\\) time slot.\n\nAd ogni slot, il partecipante o si presenta (\\(1\\)) o manca (\\(0\\)).\n\nVogliamo stimare la probabilità media di presenza, che chiameremo \\(\\theta\\).\nModello:\n\\[\n\\begin{cases}\n    Y \\mid \\theta \\;\\sim\\;\\mathrm{Binomial}(n,\\theta),\\\\[6pt]\n    \\theta \\;\\sim\\;\\mathrm{Beta}(\\alpha,\\beta).\n    \\end{cases}\n\\]\nScelta del prior:\n\nconoscenze pregresse suggeriscono che \\(\\theta\\) sia intorno a 0.5;\n\nscegliamo quindi un prior \\(\\;\\mathrm{Beta}(2,2)\\), che ha media \\(0.5\\) e riflette incertezza moderata.\n\nDati osservati:\n\n# vettore di 0/1 con n = 90 osservazioni\ny &lt;- c(\n  0,0,0,1,1,1,0,0,0,1,1,1,1,1,1,1,0,0,\n  0,1,0,1,1,1,0,0,1,1,1,1,1,1,1,0,0,1,\n  1,0,0,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,\n  1,0,0,1,1,1,0,1,1,1,1,1,1,0,0,0,0,1,\n  0,1,0,1,1,1,0,0,0,0,0,1,1,1,1,1,1,0\n)\n\nCalcoliamo\n\nn &lt;- length(y)  # numero di slot = 90\nz &lt;- sum(y)     # numero di presenze = numero di 1\n\nPosterior Beta–Binomiale.\nI parametri aggiornati sono\n\\[\n\\alpha_{post} = \\alpha + z,\n\\quad\n\\beta_{post} = \\beta + (n - z).\n\\]\nIn particolare, con \\(\\alpha=\\beta=2\\):\n\na &lt;- b &lt;- 2\na_post &lt;- a + z\nb_post &lt;- b + (n - z)\n\nIl posterior è quindi\n\\[\n\\theta\\mid y \\;\\sim\\;\\mathrm{Beta}(a+z,\\;b+n-z).\n\\]\nVisualizzazione:\n\n# griglia per theta\ngrid &lt;- seq(0, 1, length.out = 1000)\n\n# densità\nprior     &lt;- dbeta(grid, a,      b)\nposterior &lt;- dbeta(grid, a_post, b_post)\n\ndf &lt;- data.frame(theta = grid,\n                 prior = prior,\n                 posterior = posterior)\n\nggplot(df) +\n  geom_area(aes(x = theta, y = prior,\n                fill = \"Prior\", colour = \"Prior\"),\n            alpha = 0.5, size = 1) +\n  geom_area(aes(x = theta, y = posterior,\n                fill = \"Posterior\", colour = \"Posterior\"),\n            alpha = 0.5, size = 1) +\n  scale_fill_grey(name = \"\") +\n  scale_colour_grey(name = \"\") +\n  theme_bw(base_size = 12) +\n  xlab(expression(theta)) +\n  ylab(\"\") +\n  ggtitle(\"Densità Prior e Posterior\\nmodello Beta–Binomiale\")\n\n\n\n\n\n\n\nIntroduzione ai posterior predictive checks.\nIl modello assume indipendenza fra i time slot. Se questa assunzione è violata (ad es. presenza autocorrelata nel tempo), le nostre stime potrebbero essere fuorvianti.\nIdea:\n\nSimulare \\(\\theta\\) dal posterior.\n\nDato ciascun \\(\\theta\\), generare una nuova serie \\(y^{rep}\\) da\\(\\mathrm{Binomial}(n,\\theta)\\).\n\nCalcolare su ogni \\(y^{rep}\\) una test-quantità \\(T(y^{rep})\\).\n\nConfrontare la distribuzione di \\(T(y^{rep})\\) con il valore osservato \\(T(y)\\).\n\nSe \\(T(y)\\) è un outlier rispetto ai \\(T(y^{rep})\\), l’assunzione di indipendenza è sospetta.\nTest‐quantità: numero di “switch”.\nDefiniamo una funzione che conta quante volte la serie passa da 0→1 o da 1→0:\n\ncount_switches &lt;- function(x) {\n  sum(abs(diff(x)) == 1)\n}\n\n# valore osservato\nTy &lt;- count_switches(y)\ncat(\"Switch osservati:\", Ty, \"\\n\")\n#&gt; Switch osservati: 28\n\nSimulazione e istogramma.\n\nset.seed(123)      # per riproducibilità\nnsims &lt;- 10000     # numero di repliche\n\nsim_switches &lt;- replicate(nsims, {\n  # 1) estrai un theta dal posterior\n  theta_sim &lt;- rbeta(1, a_post, b_post)\n  # 2) genera y^rep ~ Bernoulli(theta_sim)\n  y_sim     &lt;- rbinom(n, size = 1, prob = theta_sim)\n  # 3) conta gli switch\n  count_switches(y_sim)\n})\n\n# Istogramma\nhist(sim_switches,\n     breaks = 30,\n     col    = \"lightgrey\",\n     main   = \"Distribuzione Posterior Predictive\\ndel numero di switch\",\n     xlab   = \"Numero di switch\",\n     ylab   = \"Frequenza\")\nabline(v = Ty, col = \"darkgreen\", lty = 2, lwd = 2)\n\n\n\n\n\n\n\nBayesian p‐value.\nCalcoliamo la probabilità di ottenere un numero di switch ≤ di quello osservato:\n\np_value &lt;- mean(sim_switches &lt;= Ty)\ncat(\"Bayesian p-value:\", round(p_value, 4), \"\\n\")\n#&gt; Bayesian p-value: 0.0073\n\n\nUn valore molto basso (es. \\(&lt;0.05\\)) indica che \\(T(y)\\) è sorprendente rispetto alle predizioni del modello.\n\nQui: se \\(p\\approx 0.01\\), la bassa variabilità di switch suggerisce dipendenza fra le osservazioni.\n\nInterpretazione.\n\n\nUn modello non è “giusto” o “sbagliato”, ma deve descrivere bene il processo che genera i dati.\n\nIl nostro check mostra che il numero di switch osservato è molto minore di quanto ci aspetteremmo sotto l’ipotesi di indipendenza.\n\nCon tutta probabilità c’è autocorrelazione temporale (le presenze dipendono dall’ora del giorno).\n\nPer tenerne conto, si potrebbero usare modelli più avanzati (es. processi gaussiani).\n\nIn sintesi, il posterior predictive checking ci offre un modo flessibile per diagnosticare diverse violazioni del modello, scegliendo test‐quantities adatte (media, varianza, max, autocorrelazione, …). Come scrivono Gelman et al. (2013), “i p-valori posteriori … possono essere calcolati per varie test-quantities per valutare più modi in cui un modello può fallire”.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_conjugate_families_1.html#principali-distribuzioni-coniugate",
    "href": "chapters/bayesian_inference/07_conjugate_families_1.html#principali-distribuzioni-coniugate",
    "title": "48  Distribuzioni coniugate (1)",
    "section": "\n48.4 Principali distribuzioni coniugate",
    "text": "48.4 Principali distribuzioni coniugate\nEsistono altre combinazioni di verosimiglianza e distribuzione a priori che producono una distribuzione a posteriori con la stessa forma della distribuzione a priori. Ecco alcune delle più note coniugazioni tra modelli statistici e distribuzioni a priori:\n\nNel modello Normale-Normale \\(\\mathcal{N}(\\mu, \\sigma^2_0)\\), la distribuzione a priori è \\(\\mathcal{N}(\\mu_0, \\tau^2)\\) e la distribuzione a posteriori è \\(\\mathcal{N}\\left(\\frac{\\mu_0\\sigma^2 + \\bar{y}n\\tau^2}{\\sigma^2 + n\\tau^2}, \\frac{\\sigma^2\\tau^2}{\\sigma^2 + n\\tau^2} \\right)\\).\nNel modello Poisson-gamma \\(\\text{Po}(\\theta)\\), la distribuzione a priori è \\(\\Gamma(\\lambda, \\delta)\\) e la distribuzione a posteriori è \\(\\Gamma(\\lambda + n \\bar{y}, \\delta +n)\\).\nNel modello esponenziale \\(\\text{Exp}(\\theta)\\), la distribuzione a priori è \\(\\Gamma(\\lambda, \\delta)\\) e la distribuzione a posteriori è \\(\\Gamma(\\lambda + n, \\delta +n\\bar{y})\\).\nNel modello uniforme-Pareto \\(\\text{U}(0, \\theta)\\), la distribuzione a priori è \\(\\text{Pa}(\\alpha, \\varepsilon)\\) e la distribuzione a posteriori è \\(\\text{Pa}(\\alpha + n, \\max(y_{(n)}, \\varepsilon))\\).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_conjugate_families_1.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/07_conjugate_families_1.html#riflessioni-conclusive",
    "title": "48  Distribuzioni coniugate (1)",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn conclusione, l’utilizzo di priori coniugati presenta vantaggi e svantaggi. Cominciamo con i vantaggi principali. Il principale vantaggio dell’adozione di distribuzioni a priori coniugate risiede nella loro capacità di rendere l’analisi della distribuzione a posteriori trattabile da un punto di vista analitico. Ad esempio, nel corso di questo capitolo abbiamo esaminato come sia possibile formulare la distribuzione a posteriori in seguito a un esperimento composto da una serie di prove di Bernoulli (con una verosimiglianza binomiale), utilizzando una distribuzione Beta sia per la prior che per il posteriore.\nTuttavia, è cruciale riconoscere che i modelli basati sul concetto di famiglie coniugate presentano delle limitazioni intrinseche. Le distribuzioni coniugate a priori sono disponibili solamente per distribuzioni di verosimiglianza di base e relativamente semplici. Per modelli complessi e più realistici, la ricerca di priori coniugati diventa spesso un compito estremamente arduo, limitando quindi la loro utilità. Inoltre, anche quando le distribuzioni a priori coniugate sono disponibili, un modello che ne fa uso potrebbe non essere sufficientemente flessibile per adattarsi alle nostre credenze iniziali. Ad esempio, un modello basato su una distribuzione normale è sempre unimodale e simmetrico rispetto alla media \\(\\mu\\). Tuttavia, se le nostre conoscenze iniziali non sono simmetriche o non seguono una distribuzione unimodale, la scelta di una distribuzione a priori normale potrebbe non risultare la più adeguata (Johnson et al., 2022).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_conjugate_families_1.html#esercizi",
    "href": "chapters/bayesian_inference/07_conjugate_families_1.html#esercizi",
    "title": "48  Distribuzioni coniugate (1)",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nSi consideri lo studio “An excess of positive results: Comparing the standard psychology literature with registered reports” di Scheel et al. (2021). In questo lavoro, gli autori confrontano il tasso di risultati positivi \\(\\theta\\) ottenuti in studi psicologici pubblicati senza preregistrazione con quelli pubblicati con preregistrazione. Si utilizzi il tasso di successo riportato negli studi preregistrati per costruire una distribuzione a priori per il parametro \\(\\theta\\).\nSecondo i risultati degli studi preregistrati, gli autori riscontrano un tasso di successo del 43.66%, con un intervallo di confidenza al 95% [CI] = [31.91, 55.95]. Sulla base di questi dati, si costruisca una distribuzione beta come distribuzione a priori per \\(\\theta\\), seguendo il metodo illustrato da Johnson et al. (2022).\nSuccessivamente, utilizzando questa distribuzione beta come distribuzione a priori, si determini la distribuzione a posteriori utilizzando il metodo delle famiglie coniugate per due scenari distinti, basati su 152 studi osservati: (a) Un tasso di successo del 60% (b) Un tasso di successo del 96% (come riportato per gli studi non preregistrati da Scheel et al. (2021)).\nInfine, si commentino i risultati derivanti dall’analisi delle distribuzioni a posteriori ottenute per entrambi gli scenari.\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\n# Caricamento delle librerie necessarie\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(dplyr)\n\n# Funzione per trovare i parametri della distribuzione beta\nfind_beta_parameters &lt;- function(mean, lower, upper, conf_level = 0.95) {\n  # Funzione obiettivo da minimizzare\n  objective &lt;- function(alpha) {\n    beta &lt;- alpha * (1 - mean) / mean\n    predicted_ci &lt;- qbeta(c((1-conf_level)/2, 1-(1-conf_level)/2), alpha, beta)\n    error &lt;- (predicted_ci[1] - lower)^2 + (predicted_ci[2] - upper)^2\n    return(error)\n  }\n  \n  # Ottimizzazione per trovare alpha\n  result &lt;- optimize(objective, interval = c(0.1, 100))\n  alpha &lt;- result$minimum\n  beta &lt;- alpha * (1 - mean) / mean\n  \n  return(list(alpha = alpha, beta = beta))\n}\n\n# Parametri degli studi preregistrati\nmean_preregistered &lt;- 0.4366\nci_lower &lt;- 0.3191\nci_upper &lt;- 0.5595\n\n# Calcolo dei parametri della distribuzione beta a priori\nprior_params &lt;- find_beta_parameters(mean_preregistered, ci_lower, ci_upper)\nalpha_prior &lt;- prior_params$alpha\nbeta_prior &lt;- prior_params$beta\n\n# Dati osservati\nn &lt;- 152  # numero di studi\nsuccesses_60 &lt;- round(0.60 * n)  # scenario (a)\nsuccesses_96 &lt;- round(0.96 * n)  # scenario (b)\n\n# Calcolo delle distribuzioni a posteriori\nalpha_post_60 &lt;- alpha_prior + successes_60\nbeta_post_60 &lt;- beta_prior + (n - successes_60)\n\nalpha_post_96 &lt;- alpha_prior + successes_96\nbeta_post_96 &lt;- beta_prior + (n - successes_96)\n\n# Creazione del dataframe per il plotting\ntheta &lt;- seq(0, 1, length.out = 1000)\n\ndf &lt;- data.frame(\n  theta = rep(theta, 3),\n  density = c(\n    dbeta(theta, alpha_prior, beta_prior),\n    dbeta(theta, alpha_post_60, beta_post_60),\n    dbeta(theta, alpha_post_96, beta_post_96)\n  ),\n  distribution = rep(c(\"Priori\", \"Posteriori (60%)\", \"Posteriori (96%)\"), \n                    each = length(theta))\n)\n\n# Creazione del grafico\np &lt;- ggplot(df, aes(x = theta, y = density, color = distribution)) +\n  geom_line(size = 1) +\n  labs(\n    title = \"Distribuzioni a Priori e a Posteriori\",\n    x = expression(theta),\n    y = \"Densità\",\n    color = \"Distribuzione\"\n  ) +\n  theme(legend.position = \"bottom\")\n\n# Calcolo degli intervalli di credibilità al 95%\ncredible_intervals &lt;- data.frame(\n  Distribution = c(\"Priori\", \"Posteriori (60%)\", \"Posteriori (96%)\"),\n  Mean = c(\n    alpha_prior / (alpha_prior + beta_prior),\n    alpha_post_60 / (alpha_post_60 + beta_post_60),\n    alpha_post_96 / (alpha_post_96 + beta_post_96)\n  ),\n  Lower = c(\n    qbeta(0.025, alpha_prior, beta_prior),\n    qbeta(0.025, alpha_post_60, beta_post_60),\n    qbeta(0.025, alpha_post_96, beta_post_96)\n  ),\n  Upper = c(\n    qbeta(0.975, alpha_prior, beta_prior),\n    qbeta(0.975, alpha_post_60, beta_post_60),\n    qbeta(0.975, alpha_post_96, beta_post_96)\n  )\n)\n\n# Visualizzazione dei risultati\nprint(\"Parametri della distribuzione beta a priori:\")\nprint(paste(\"alpha =\", round(alpha_prior, 2)))\nprint(paste(\"beta =\", round(beta_prior, 2)))\n\nprint(\"\\nIntervalli di credibilità al 95%:\")\nprint(credible_intervals)\n\n# Visualizza il grafico\nprint(p)\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nTra i fattori che possono influenzare il rapporto tra i sessi alla nascita c’è la condizione materna di placenta previa, una condizione insolita della gravidanza in cui la placenta è impiantata in basso nell’utero, impedendo un normale parto vaginale del feto. Uno studio condotto in Germania ha esaminato il sesso dei neonati in casi di placenta previa e ha riscontrato che, su un totale di 980 nascite, 437 erano femmine.\nQuanta evidenza fornisce questo studio a supporto dell’ipotesi che la proporzione di nascite femminili nella popolazione di placenta previa sia inferiore a 0.485, che rappresenta la proporzione di nascite femminili nella popolazione generale? (Esercizio tratto da Gelman et al. (2013))\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\n# Caricamento delle librerie necessarie\nlibrary(ggplot2)\n\n# Dati osservati\nn &lt;- 980        # numero totale di nascite\ny &lt;- 437        # numero di femmine\np0 &lt;- 0.485     # proporzione nella popolazione generale\n\n# Calcolo della proporzione osservata\np_hat &lt;- y/n\nprint(paste(\"Proporzione osservata di femmine:\", round(p_hat, 3)))\n\n# Test dell'ipotesi utilizzando il Bayes Factor\n# H0: p = 0.485 vs H1: p &lt; 0.485\n\n# Funzione per calcolare la verosimiglianza marginale sotto H1\nmarginal_likelihood_h1 &lt;- function(y, n, p_max = 0.485) {\n  # Integrazione numerica sulla distribuzione uniforme tra 0 e p_max\n  p_grid &lt;- seq(0, p_max, length.out = 1000)\n  likelihood &lt;- dbinom(y, n, p_grid)\n  prior &lt;- dunif(p_grid, 0, p_max)\n  mean(likelihood * prior) * p_max\n}\n\n# Verosimiglianza sotto H0\nlikelihood_h0 &lt;- dbinom(y, n, p0)\n\n# Verosimiglianza marginale sotto H1\nmarg_lik_h1 &lt;- marginal_likelihood_h1(y, n)\n\n# Calcolo del Bayes Factor\nbf10 &lt;- marg_lik_h1 / likelihood_h0\nprint(paste(\"Bayes Factor (H1 vs H0):\", round(bf10, 2)))\n\n# Visualizzazione delle distribuzioni a posteriori\np_grid &lt;- seq(0, 1, length.out = 1000)\nlikelihood &lt;- dbinom(y, n, p_grid)\nprior &lt;- dunif(p_grid, 0, 1)\nposterior &lt;- likelihood * prior\nposterior &lt;- posterior / sum(posterior)\n\n# Creazione del dataframe per il plotting\ndf &lt;- data.frame(\n  p = p_grid,\n  Posterior = posterior / max(posterior)  # normalizzato per la visualizzazione\n)\n\n# Creazione del grafico\np &lt;- ggplot(df, aes(x = p, y = Posterior)) +\n  geom_line(size = 1) +\n  geom_vline(xintercept = p0, linetype = \"dashed\", color = \"red\") +\n  geom_vline(xintercept = p_hat, linetype = \"dashed\", color = \"blue\") +\n  labs(\n    title = \"Distribuzione a Posteriori della Proporzione di Nascite Femminili\",\n    x = \"Proporzione di Nascite Femminili (p)\",\n    y = \"Densità a Posteriori (normalizzata)\"\n  ) +\n  annotate(\"text\", x = p0, y = 0.1, \n           label = \"Popolazione Generale\", \n           angle = 90, vjust = -0.5, color = \"red\") +\n  annotate(\"text\", x = p_hat, y = 0.1, \n           label = \"Proporzione Osservata\", \n           angle = 90, vjust = -0.5, color = \"blue\")\n\n# Calcolo dell'intervallo di credibilità al 95%\nsorted_p &lt;- sort(p_grid)\ncum_post &lt;- cumsum(posterior)\nlower &lt;- sorted_p[which(cum_post &gt; 0.025)[1]]\nupper &lt;- sorted_p[which(cum_post &gt; 0.975)[1]]\n\nprint(paste(\"Intervallo di credibilità al 95%: [\", \n            round(lower, 3), \",\", round(upper, 3), \"]\"))\n\n# Calcolo della probabilità a posteriori che p &lt; 0.485\nprob_less_than_p0 &lt;- sum(posterior[p_grid &lt; p0])\nprint(paste(\"Probabilità a posteriori che p &lt; 0.485:\", \n            round(prob_less_than_p0, 3)))\n\n# Visualizza il grafico\nprint(p)\n\n\n\n\n\n\n\n\n\nProblemi 3\n\n\n\n\n\nPer valutare la sensibilità della soluzione precedente alla scelta della distribuzione a priori, ripetere l’esercizio utilizzando come distribuzione a priori per la proporzione di nascite femminili una distribuzione Beta(48.5, 51.5). Questa distribuzione è centrata su 0.485 e concentra la maggior parte della sua massa nell’intervallo [0.385, 0.585]. Interpretare i risultati ottenuti.\n\n\n\n\n\n\n\n\n\nSoluzioni 3\n\n\n\n\n\n# Caricamento delle librerie necessarie\nlibrary(ggplot2)\n\n# Dati osservati\nn &lt;- 980        # numero totale di nascite\ny &lt;- 437        # numero di femmine\np0 &lt;- 0.485     # proporzione nella popolazione generale\n\n# Parametri della distribuzione beta a priori\nalpha_prior &lt;- 48.5\nbeta_prior &lt;- 51.5\n\n# Calcolo dei parametri della distribuzione beta a posteriori\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + (n - y)\n\n# Creazione della griglia per il plotting\np_grid &lt;- seq(0, 1, length.out = 1000)\n\n# Calcolo delle densità\nprior_density &lt;- dbeta(p_grid, alpha_prior, beta_prior)\nposterior_density &lt;- dbeta(p_grid, alpha_post, beta_post)\n\n# Creazione del dataframe per il plotting\ndf &lt;- data.frame(\n  p = rep(p_grid, 2),\n  density = c(prior_density, posterior_density),\n  distribution = rep(c(\"Priori Beta(48.5, 51.5)\", \"Posteriori\"), each = length(p_grid))\n)\n\n# Creazione del grafico\np &lt;- ggplot(df, aes(x = p, y = density, color = distribution)) +\n  geom_line(size = 1) +\n  geom_vline(xintercept = p0, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Distribuzioni a Priori e a Posteriori\",\n    subtitle = \"Proporzione di Nascite Femminili con Placenta Previa\",\n    x = \"Proporzione di Nascite Femminili (p)\",\n    y = \"Densità\",\n    color = \"Distribuzione\"\n  ) +\n  theme(legend.position = \"bottom\") +\n  annotate(\"text\", x = p0, y = max(posterior_density)/2, \n           label = \"Popolazione Generale (0.485)\", \n           angle = 90, vjust = -0.5, color = \"red\")\n\n# Calcolo statistiche rilevanti\n# Media a priori e posteriori\nprior_mean &lt;- alpha_prior / (alpha_prior + beta_prior)\npost_mean &lt;- alpha_post / (alpha_post + beta_post)\n\n# Intervalli di credibilità al 95%\nprior_ci &lt;- qbeta(c(0.025, 0.975), alpha_prior, beta_prior)\npost_ci &lt;- qbeta(c(0.025, 0.975), alpha_post, beta_post)\n\n# Probabilità a posteriori che p &lt; 0.485\nprob_less_than_p0 &lt;- pbeta(p0, alpha_post, beta_post)\n\n# Output dei risultati\ncat(\"\\nRisultati dell'analisi:\\n\")\ncat(\"------------------------\\n\")\ncat(\"Dati osservati:\\n\")\ncat(sprintf(\"Numero totale di nascite: %d\\n\", n))\ncat(sprintf(\"Numero di femmine: %d\\n\", y))\ncat(sprintf(\"Proporzione osservata: %.3f\\n\\n\", y/n))\n\ncat(\"Analisi a priori:\\n\")\ncat(sprintf(\"Media a priori: %.3f\\n\", prior_mean))\ncat(sprintf(\"Intervallo di credibilità al 95%%: [%.3f, %.3f]\\n\\n\", \n            prior_ci[1], prior_ci[2]))\n\ncat(\"Analisi a posteriori:\\n\")\ncat(sprintf(\"Media a posteriori: %.3f\\n\", post_mean))\ncat(sprintf(\"Intervallo di credibilità al 95%%: [%.3f, %.3f]\\n\", \n            post_ci[1], post_ci[2]))\ncat(sprintf(\"Probabilità che p &lt; %.3f: %.3f\\n\", p0, prob_less_than_p0))\n\n# Visualizza il grafico\nprint(p)\n# Caricamento delle librerie necessarie\nlibrary(ggplot2)\n\n# Dati osservati\nn &lt;- 980        # numero totale di nascite\ny &lt;- 437        # numero di femmine\np0 &lt;- 0.485     # proporzione nella popolazione generale\n\n# Parametri della distribuzione beta a priori\nalpha_prior &lt;- 48.5\nbeta_prior &lt;- 51.5\n\n# Calcolo dei parametri della distribuzione beta a posteriori\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + (n - y)\n\n# Creazione della griglia per il plotting\np_grid &lt;- seq(0, 1, length.out = 1000)\n\n# Calcolo delle densità\nprior_density &lt;- dbeta(p_grid, alpha_prior, beta_prior)\nposterior_density &lt;- dbeta(p_grid, alpha_post, beta_post)\n\n# Creazione del dataframe per il plotting\ndf &lt;- data.frame(\n  p = rep(p_grid, 2),\n  density = c(prior_density, posterior_density),\n  distribution = rep(c(\"Priori Beta(48.5, 51.5)\", \"Posteriori\"), each = length(p_grid))\n)\n\n# Creazione del grafico\np &lt;- ggplot(df, aes(x = p, y = density, color = distribution)) +\n  geom_line(size = 1) +\n  geom_vline(xintercept = p0, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Distribuzioni a Priori e a Posteriori\",\n    subtitle = \"Proporzione di Nascite Femminili con Placenta Previa\",\n    x = \"Proporzione di Nascite Femminili (p)\",\n    y = \"Densità\",\n    color = \"Distribuzione\"\n  ) +\n  theme(legend.position = \"bottom\") +\n  annotate(\"text\", x = p0, y = max(posterior_density)/2, \n           label = \"Popolazione Generale (0.485)\", \n           angle = 90, vjust = -0.5, color = \"red\")\n\n# Calcolo statistiche rilevanti\n# Media a priori e posteriori\nprior_mean &lt;- alpha_prior / (alpha_prior + beta_prior)\npost_mean &lt;- alpha_post / (alpha_post + beta_post)\n\n# Intervalli di credibilità al 95%\nprior_ci &lt;- qbeta(c(0.025, 0.975), alpha_prior, beta_prior)\npost_ci &lt;- qbeta(c(0.025, 0.975), alpha_post, beta_post)\n\n# Probabilità a posteriori che p &lt; 0.485\nprob_less_than_p0 &lt;- pbeta(p0, alpha_post, beta_post)\n\n# Output dei risultati\ncat(\"\\nRisultati dell'analisi:\\n\")\ncat(\"------------------------\\n\")\ncat(\"Dati osservati:\\n\")\ncat(sprintf(\"Numero totale di nascite: %d\\n\", n))\ncat(sprintf(\"Numero di femmine: %d\\n\", y))\ncat(sprintf(\"Proporzione osservata: %.3f\\n\\n\", y/n))\n\ncat(\"Analisi a priori:\\n\")\ncat(sprintf(\"Media a priori: %.3f\\n\", prior_mean))\ncat(sprintf(\"Intervallo di credibilità al 95%%: [%.3f, %.3f]\\n\\n\", \n            prior_ci[1], prior_ci[2]))\n\ncat(\"Analisi a posteriori:\\n\")\ncat(sprintf(\"Media a posteriori: %.3f\\n\", post_mean))\ncat(sprintf(\"Intervallo di credibilità al 95%%: [%.3f, %.3f]\\n\", \n            post_ci[1], post_ci[2]))\ncat(sprintf(\"Probabilità che p &lt; %.3f: %.3f\\n\", p0, prob_less_than_p0))\n\n# Visualizza il grafico\nprint(p)\nI risultati mostrano che:\n\nLa proporzione osservata nel campione (0.446) è inferiore al valore di riferimento della popolazione generale (0.485)\nLa distribuzione a priori Beta(48.5, 51.5):\n\n\nHa media 0.485\nRiflette la nostra conoscenza iniziale sulla proporzione di nascite femminili\nFornisce un’incertezza ragionevole attorno al valore di riferimento\n\n\nLa distribuzione a posteriori:\n\n\nHa una media di circa 0.447\nL’intervallo di credibilità al 95% esclude il valore di riferimento 0.485\nIndica una probabilità elevata che la vera proporzione sia inferiore a 0.485\n\n\nQuesta analisi suggerisce che:\n\n\nEsiste un’associazione tra placenta previa e una minor proporzione di nascite femminili\nL’effetto è moderato ma statisticamente rilevante\nLa stima è abbastanza precisa grazie alla dimensione campionaria considerevole\n\n\n\n\n\n\n\n\n\n\nProblemi 4\n\n\n\n\n\nIn uno studio recente, Gori et al. (2024) hanno esaminato un campione di 202 adulti italiani e hanno riscontrato una prevalenza di mancini del 6.4%. Una meta-analisi di Papadatou-Pastou et al. (2020), condotta su un totale di 2,396,170 soggetti, riporta che la proporzione di mancini varia tra il 9.3% e il 18.1%, a seconda di come viene misurata la lateralità manuale. Inoltre, Papadatou-Pastou et al. (2020) mostrano che la prevalenza della lateralità manuale varia tra i paesi e nel tempo. Considerata questa incertezza, si determini la distribuzione a posteriori che combina i dati dello studio di Gori et al. (2024) con le informazioni pregresse fornite da Papadatou-Pastou et al. (2020). Le informazioni di Papadatou-Pastou et al. (2020) possono essere espresse in termini di una distribuzione Beta(8, 60).\n\n\n\n\n\n\n\n\n\nSoluzioni 4\n\n\n\n\n\n# Caricamento delle librerie necessarie\nlibrary(ggplot2)\n\n# Dati dello studio di Gori et al. (2024)\nn &lt;- 202       # dimensione del campione\ny &lt;- round(0.064 * n)  # numero di mancini (6.4% del campione)\n\n# Parametri della distribuzione beta a priori (da Papadatou-Pastou et al., 2020)\nalpha_prior &lt;- 8\nbeta_prior &lt;- 60\n\n# Calcolo dei parametri della distribuzione beta a posteriori\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + (n - y)\n\n# Creazione della griglia per il plotting\np_grid &lt;- seq(0, 0.3, length.out = 1000)  # limitato a 0.3 per migliore visualizzazione\n\n# Calcolo delle densità\nprior_density &lt;- dbeta(p_grid, alpha_prior, beta_prior)\nposterior_density &lt;- dbeta(p_grid, alpha_post, beta_post)\n\n# Creazione del dataframe per il plotting\ndf &lt;- data.frame(\n  p = rep(p_grid, 2),\n  density = c(prior_density, posterior_density),\n  distribution = rep(c(\"Priori (Papadatou-Pastou et al., 2020)\", \n                      \"Posteriori (con dati Gori et al., 2024)\"), \n                    each = length(p_grid))\n)\n\n# Calcolo statistiche rilevanti\nprior_mean &lt;- alpha_prior / (alpha_prior + beta_prior)\npost_mean &lt;- alpha_post / (alpha_post + beta_post)\n\nprior_ci &lt;- qbeta(c(0.025, 0.975), alpha_prior, beta_prior)\npost_ci &lt;- qbeta(c(0.025, 0.975), alpha_post, beta_post)\n\n# Creazione del grafico\np &lt;- ggplot(df, aes(x = p, y = density, color = distribution)) +\n  geom_line(size = 1) +\n  geom_vline(xintercept = 0.064, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Distribuzione della Prevalenza dei Mancini\",\n    subtitle = \"Confronto tra Distribuzione a Priori e a Posteriori\",\n    x = \"Proporzione di Mancini\",\n    y = \"Densità\",\n    color = \"Distribuzione\"\n  ) +\n  theme(legend.position = \"bottom\") +\n  annotate(\"text\", x = 0.064, y = max(posterior_density)/2, \n           label = \"Valore osservato (6.4%)\", \n           angle = 90, vjust = -0.5, color = \"red\")\n\n# Output dei risultati\ncat(\"\\nRisultati dell'analisi:\\n\")\ncat(\"------------------------\\n\")\ncat(\"Distribuzione a priori (Papadatou-Pastou et al., 2020):\\n\")\ncat(sprintf(\"Media: %.1f%%\\n\", prior_mean * 100))\ncat(sprintf(\"Intervallo di credibilità al 95%%: [%.1f%%, %.1f%%]\\n\\n\", \n            prior_ci[1] * 100, prior_ci[2] * 100))\n\ncat(\"Dati osservati (Gori et al., 2024):\\n\")\ncat(sprintf(\"Campione: %d individui\\n\", n))\ncat(sprintf(\"Mancini osservati: %d (%.1f%%)\\n\\n\", y, y/n * 100))\n\ncat(\"Distribuzione a posteriori:\\n\")\ncat(sprintf(\"Media: %.1f%%\\n\", post_mean * 100))\ncat(sprintf(\"Intervallo di credibilità al 95%%: [%.1f%%, %.1f%%]\\n\", \n            post_ci[1] * 100, post_ci[2] * 100))\n\n# Visualizza il grafico\nprint(p)\n# Caricamento delle librerie necessarie\nlibrary(ggplot2)\n\n# Dati dello studio di Gori et al. (2024)\nn &lt;- 202       # dimensione del campione\ny &lt;- round(0.064 * n)  # numero di mancini (6.4% del campione)\n\n# Parametri della distribuzione beta a priori (da Papadatou-Pastou et al., 2020)\nalpha_prior &lt;- 8\nbeta_prior &lt;- 60\n\n# Calcolo dei parametri della distribuzione beta a posteriori\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + (n - y)\n\n# Creazione della griglia per il plotting\np_grid &lt;- seq(0, 0.3, length.out = 1000)  # limitato a 0.3 per migliore visualizzazione\n\n# Calcolo delle densità\nprior_density &lt;- dbeta(p_grid, alpha_prior, beta_prior)\nposterior_density &lt;- dbeta(p_grid, alpha_post, beta_post)\n\n# Creazione del dataframe per il plotting\ndf &lt;- data.frame(\n  p = rep(p_grid, 2),\n  density = c(prior_density, posterior_density),\n  distribution = rep(c(\"Priori (Papadatou-Pastou et al., 2020)\", \n                      \"Posteriori (con dati Gori et al., 2024)\"), \n                    each = length(p_grid))\n)\n\n# Calcolo statistiche rilevanti\nprior_mean &lt;- alpha_prior / (alpha_prior + beta_prior)\npost_mean &lt;- alpha_post / (alpha_post + beta_post)\n\nprior_ci &lt;- qbeta(c(0.025, 0.975), alpha_prior, beta_prior)\npost_ci &lt;- qbeta(c(0.025, 0.975), alpha_post, beta_post)\n\n# Creazione del grafico\np &lt;- ggplot(df, aes(x = p, y = density, color = distribution)) +\n  geom_line(size = 1) +\n  geom_vline(xintercept = 0.064, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Distribuzione della Prevalenza dei Mancini\",\n    subtitle = \"Confronto tra Distribuzione a Priori e a Posteriori\",\n    x = \"Proporzione di Mancini\",\n    y = \"Densità\",\n    color = \"Distribuzione\"\n  ) +\n  theme(legend.position = \"bottom\") +\n  annotate(\"text\", x = 0.064, y = max(posterior_density)/2, \n           label = \"Valore osservato (6.4%)\", \n           angle = 90, vjust = -0.5, color = \"red\")\n\n# Output dei risultati\ncat(\"\\nRisultati dell'analisi:\\n\")\ncat(\"------------------------\\n\")\ncat(\"Distribuzione a priori (Papadatou-Pastou et al., 2020):\\n\")\ncat(sprintf(\"Media: %.1f%%\\n\", prior_mean * 100))\ncat(sprintf(\"Intervallo di credibilità al 95%%: [%.1f%%, %.1f%%]\\n\\n\", \n            prior_ci[1] * 100, prior_ci[2] * 100))\n\ncat(\"Dati osservati (Gori et al., 2024):\\n\")\ncat(sprintf(\"Campione: %d individui\\n\", n))\ncat(sprintf(\"Mancini osservati: %d (%.1f%%)\\n\\n\", y, y/n * 100))\n\ncat(\"Distribuzione a posteriori:\\n\")\ncat(sprintf(\"Media: %.1f%%\\n\", post_mean * 100))\ncat(sprintf(\"Intervallo di credibilità al 95%%: [%.1f%%, %.1f%%]\\n\", \n            post_ci[1] * 100, post_ci[2] * 100))\n\n# Visualizza il grafico\nprint(p)\nL’analisi bayesiana della prevalenza dei mancini combina le informazioni provenienti dalla meta-analisi di Papadatou-Pastou et al. (2020) con i dati più recenti di Gori et al. (2024). Di seguito sono riportati i principali risultati:\n\n\nDistribuzione a priori (basata su Papadatou-Pastou et al., 2020):\n\nModellata come una distribuzione Beta(8, 60).\n\nPresenta una media intorno all’11,8%.\n\nRiflette la variabilità osservata nella meta-analisi.\n\nL’intervallo di credibilità al 95% copre approssimativamente il range 9,3%-18,1%, come riportato nello studio.\n\n\n\nDati osservati (Gori et al., 2024):\n\n202 partecipanti italiani.\n\n13 mancini, corrispondenti al 6,4% del campione.\n\nQuesto valore è inferiore alla media stimata dalla meta-analisi globale.\n\n\n\nDistribuzione a posteriori:\n\nCombina le informazioni a priori con i nuovi dati osservati.\n\nLa media a posteriori si è spostata verso il basso rispetto alla distribuzione a priori.\n\nL’intervallo di credibilità si è ristretto, indicando una riduzione dell’incertezza.\n\nMaggiore peso è stato attribuito ai dati italiani rispetto alla meta-analisi globale.\n\n\n\nInterpretazione:\n\nLa stima finale suggerisce una prevalenza di mancini nella popolazione italiana inferiore alla media globale.\n\nQuesto risultato potrebbe riflettere specificità culturali o metodologiche dello studio italiano.\n\nL’incertezza nella stima finale è diminuita rispetto alla meta-analisi, ma rimane significativa.\n\nI risultati supportano l’ipotesi di una variabilità geografica nella prevalenza della mancinismo.\n\n\n\nLa distribuzione a posteriori fornisce una sintesi equilibrata tra le conoscenze globali precedenti e i dati specifici della popolazione italiana, suggerendo che potrebbero esistere peculiarità culturali o demografiche che influenzano la prevalenza del mancinismo in Italia.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_conjugate_families_1.html#informazioni-sullambiente-di-dviluppo",
    "href": "chapters/bayesian_inference/07_conjugate_families_1.html#informazioni-sullambiente-di-dviluppo",
    "title": "48  Distribuzioni coniugate (1)",
    "section": "Informazioni sull’ambiente di dviluppo",
    "text": "Informazioni sull’ambiente di dviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.18.0           pillar_1.11.0         tinytable_0.11.0     \n#&gt;  [4] patchwork_1.3.1       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt;  [7] bayesplot_1.13.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [10] priorsense_1.1.0      posterior_1.6.1       loo_2.8.0            \n#&gt; [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [16] Rcpp_1.1.0            conflicted_1.2.0      janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] Rdpack_2.6.4         gridExtra_2.3        inline_0.3.21       \n#&gt;  [4] sandwich_3.1-1       rlang_1.1.6          magrittr_2.0.3      \n#&gt;  [7] multcomp_1.4-28      snakecase_0.11.1     compiler_4.5.1      \n#&gt; [10] vctrs_0.6.5          stringr_1.5.1        pkgconfig_2.0.3     \n#&gt; [13] shape_1.4.6.1        arrayhelpers_1.1-0   fastmap_1.2.0       \n#&gt; [16] backports_1.5.0      labeling_0.4.3       rmarkdown_2.29      \n#&gt; [19] nloptr_2.2.1         purrr_1.1.0          xfun_0.52           \n#&gt; [22] glmnet_4.1-10        jomo_2.7-6           cachem_1.1.0        \n#&gt; [25] jsonlite_2.0.0       pan_1.9              broom_1.0.9         \n#&gt; [28] parallel_4.5.1       R6_2.6.1             stringi_1.8.7       \n#&gt; [31] RColorBrewer_1.1-3   rpart_4.1.24         boot_1.3-31         \n#&gt; [34] lubridate_1.9.4      estimability_1.5.1   iterators_1.0.14    \n#&gt; [37] knitr_1.50           zoo_1.8-14           pacman_0.5.1        \n#&gt; [40] nnet_7.3-20          Matrix_1.7-3         splines_4.5.1       \n#&gt; [43] timechange_0.3.0     tidyselect_1.2.1     abind_1.4-8         \n#&gt; [46] codetools_0.2-20     curl_6.4.0           pkgbuild_1.4.8      \n#&gt; [49] lattice_0.22-7       withr_3.0.2          bridgesampling_1.1-2\n#&gt; [52] coda_0.19-4.1        evaluate_1.0.4       survival_3.8-3      \n#&gt; [55] RcppParallel_5.1.10  tensorA_0.36.2.1     checkmate_2.3.2     \n#&gt; [58] foreach_1.5.2        stats4_4.5.1         reformulas_0.4.1    \n#&gt; [61] distributional_0.5.0 generics_0.1.4       rprojroot_2.1.0     \n#&gt; [64] rstantools_2.4.0     scales_1.4.0         minqa_1.2.8         \n#&gt; [67] xtable_1.8-4         glue_1.8.0           emmeans_1.11.2      \n#&gt; [70] tools_4.5.1          lme4_1.1-37          mvtnorm_1.3-3       \n#&gt; [73] grid_4.5.1           rbibutils_2.3        QuickJSR_1.8.0      \n#&gt; [76] colorspace_2.1-1     nlme_3.1-168         cli_3.6.5           \n#&gt; [79] svUnit_1.0.6         Brobdingnag_1.2-9    V8_6.0.5            \n#&gt; [82] gtable_0.3.6         digest_0.6.37        TH.data_1.1-3       \n#&gt; [85] htmlwidgets_1.6.4    farver_2.1.2         memoise_2.0.1       \n#&gt; [88] htmltools_0.5.8.1    lifecycle_1.0.4      mitml_0.4-5         \n#&gt; [91] MASS_7.3-65",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_conjugate_families_1.html#bibliografia",
    "href": "chapters/bayesian_inference/07_conjugate_families_1.html#bibliografia",
    "title": "48  Distribuzioni coniugate (1)",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., & Rubin, D. B. (2013). Bayesian Data Analysis (3rd ed.). Chapman; Hall/CRC.\n\n\nGori, B., Grippo, A., Focardi, M., & Lolli, F. (2024). The Italian version of Edinburgh Handedness Inventory: Translation, transcultural adaptation, and validation in healthy subjects. Laterality, 29(2), 151–168.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nNalborczyk, L. (2018, gennaio 23). Checking the Asumption of Independence in Binomial Trials Using Posterior Predictive Checking. https://lnalborczyk.github.io/blog/2018-01-23-ppc\n\n\nPapadatou-Pastou, M., Ntolka, E., Schmitz, J., Martin, M., Munafò, M. R., Ocklenburg, S., & Paracchini, S. (2020). Human handedness: A meta-analysis. Psychological bulletin, 146(6), 481–524.\n\n\nScheel, A. M., Schijen, M. R., & Lakens, D. (2021). An excess of positive results: Comparing the standard psychology literature with registered reports. Advances in Methods and Practices in Psychological Science, 4(2), 25152459211007467.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_conjugate_families_2.html",
    "href": "chapters/bayesian_inference/08_conjugate_families_2.html",
    "title": "49  Distribuzioni coniugate (2)",
    "section": "",
    "text": "Introduzione\nNel capitolo precedente abbiamo esplorato il modello Beta-Binomiale, un esempio paradigmatico di coniugazione nel contesto dei dati discreti. Ora, ci addentriamo nel dominio continuo con il modello Normale-Normale. Grazie alla sua eleganza analitica e alla sua trattabilità, questo modello rappresenta uno strumento cardine nell’inferenza bayesiana.\nConsideriamo di avere \\(n\\) osservazioni \\(y_1, \\dots, y_n\\) che assumiamo essere indipendenti e identicamente distribuite (iid) secondo una distribuzione Normale (o Gaussiana) con media \\(\\mu\\) e varianza \\(\\sigma^2\\), ossia \\(y_i \\stackrel{\\text{iid}}{\\sim} \\mathcal{N}(\\mu, \\sigma^2)\\). Nell’approccio bayesiano, esprimiamo le nostre conoscenze preliminari su \\(\\mu\\) (e, se necessario, su \\(\\sigma^2\\)) attraverso una distribuzione a priori, tipicamente anch’essa Gaussiana. La magia di questo modello risiede nella coniugazione: se la distribuzione a priori è Normale e la verosimiglianza è Normale, anche la distribuzione a posteriori per \\(\\mu\\) sarà Normale.\nL’inferenza bayesiana è un processo iterativo di apprendimento che combina in modo sistematico:\nUn beneficio chiave di questo approccio è la progressiva riduzione dell’incertezza. All’aumentare del numero di osservazioni, la varianza della distribuzione a posteriori tende a diminuire, fornendo una stima sempre più precisa (cioè con un intervallo di plausibilità più ristretto) per \\(\\mu\\).\nIn questo capitolo, ci concentreremo sulle famiglie coniugate (per approfondimenti, si veda Capitolo 48), con un focus specifico sul modello Normale-Normale. Vedremo come, partendo da una prior Normale e una verosimiglianza Normale, la distribuzione a posteriori per la media \\(\\mu\\) risulti anch’essa Normale, semplificando notevolmente i calcoli.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_conjugate_families_2.html#introduzione",
    "href": "chapters/bayesian_inference/08_conjugate_families_2.html#introduzione",
    "title": "49  Distribuzioni coniugate (2)",
    "section": "",
    "text": "Convinzioni Iniziali (Distribuzione a Priori): Definiamo una distribuzione a priori per il parametro di nostro interesse, in questo caso la media \\(\\mu\\). Questa riflette la nostra incertezza o conoscenza su \\(\\mu\\) prima di osservare i dati.\n\nEvidenza Empirica (Funzione di Verosimiglianza): Osserviamo i dati e costruiamo la funzione di verosimiglianza, che ci dice quanto sono probabili i dati osservati per diversi valori possibili di \\(\\mu\\).\n\nAggiornamento della Conoscenza (Distribuzione a Posteriori): Applichiamo il teorema di Bayes per combinare la prior e la verosimiglianza. Il risultato è la distribuzione a posteriori, che rappresenta la nostra conoscenza aggiornata su \\(\\mu\\) dopo aver considerato i dati.\n\n\n\n\n49.0.1 Perché Scegliere una Distribuzione Normale?\nLa scelta di una distribuzione a priori (e di una verosimiglianza) Normale offre numerosi vantaggi, sia dal punto di vista teorico che pratico:\n\nSimmetria e Adattabilità: La caratteristica forma “a campana” e simmetrica della distribuzione Normale ben si adatta a descrivere molti fenomeni naturali, psicologici e cognitivi, come i tempi di reazione, i punteggi di abilità, o gli errori di misurazione. Questa simmetria facilita l’interpretazione della media \\(\\mu\\) come misura di tendenza centrale e della varianza \\(\\sigma^2\\) come misura della dispersione o incertezza.\nEfficienza Parametrica: Nel modello Normale-Normale con varianza nota, l’incertezza sulla media \\(\\mu\\) nella distribuzione a priori è descritta dal singolo parametro \\(\\sigma_0^2\\) (la varianza della prior). Analogamente, la variabilità dei dati è descritta da \\(\\sigma^2\\). Questa parsimonia parametrica semplifica sia la fase di modellizzazione sia la comunicazione dei risultati.\nConvergenza con l’Inferenza Classica: Per campioni di dati sufficientemente ampi, le stime bayesiane ottenute con il modello Normale tendono a convergere verso quelle dell’inferenza frequentista. Questa proprietà, legata al teorema di Bernstein-von Mises, è talvolta indicata come calibrazione asintotica e fa sì che il modello Normale-Normale possa agire da ponte tra i due paradigmi inferenziali.\nSemplicità Computazionale: Le operazioni matematiche tra distribuzioni Normali (come il prodotto richiesto dal teorema di Bayes) risultano in un’altra distribuzione Normale. Questo permette di ottenere soluzioni analitiche in forma chiusa per i parametri della distribuzione a posteriori, evitando la necessità di ricorrere a metodi di approssimazione numerica complessi, come le simulazioni Monte Carlo Markov Chain (MCMC), almeno nei casi più semplici.\n\nIn sintesi: se le nostre conoscenze preliminari suggeriscono una distribuzione unimodale e simmetrica per il parametro di interesse, o se ci aspettiamo che la distribuzione a posteriori abbia tali caratteristiche (cosa spesso favorita dal Teorema del Limite Centrale quando si ha un campione ampio), la distribuzione Normale rappresenta una scelta robusta, elegante e computazionalmente vantaggiosa per condurre un’inferenza rigorosa.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_conjugate_families_2.html#inferenza-bayesiana-per-la-media-di-una-popolazione-normale-varianza-nota",
    "href": "chapters/bayesian_inference/08_conjugate_families_2.html#inferenza-bayesiana-per-la-media-di-una-popolazione-normale-varianza-nota",
    "title": "49  Distribuzioni coniugate (2)",
    "section": "\n49.1 Inferenza Bayesiana per la Media di una Popolazione Normale (Varianza Nota)",
    "text": "49.1 Inferenza Bayesiana per la Media di una Popolazione Normale (Varianza Nota)\nImmaginiamo di voler stimare il tempo medio di reazione \\(\\mu\\) (in millisecondi, ms) di una popolazione di studenti impegnati in un compito Stroop. Supponiamo di aver raccolto i tempi di reazione \\(y_1, \\dots, y_n\\) da un campione di \\(n\\) studenti. Assumiamo che questi dati provengano da una distribuzione Normale \\(y_i \\sim \\mathcal{N}(\\mu, \\sigma^2)\\) e, per semplificare inizialmente il modello, assumiamo che la varianza \\(\\sigma^2\\) della popolazione sia nota (ad esempio, da studi precedenti o dalla natura standardizzata del compito). Sia \\(\\sigma = 50\\) ms la deviazione standard nota.\n\n49.1.1 I Tre Passi Fondamentali dell’Inferenza Bayesiana\nIl processo di inferenza bayesiana si articola nei seguenti passaggi chiave:\n\n\n\n\n\n\n\nPasso\nSignificato Intuitivo\nFormalizzazione Matematica (Modello Normale-Normale)\n\n\n\nA. Distribuzione a Priori\nLe nostre convinzioni iniziali sulla media \\(\\mu\\).\n\\(\\mu \\sim \\mathcal{N}(\\mu_0, \\sigma_0^2)\\)\n\n\nB. Verosimiglianza dei Dati\nL’informazione su \\(\\mu\\) contenuta nei dati osservati.\n\\(y_i \\stackrel{\\text{iid}}{\\sim} \\mathcal{N}(\\mu, \\sigma^2)\\)\n\n\nC. Distribuzione a Posteriori\nLe nostre convinzioni aggiornate su \\(\\mu\\) dopo i dati.\n\\(\\mu \\mid \\mathbf{y} \\sim \\mathcal{N}(\\mu_p, \\sigma_p^2)\\)\n\n\n\nQuando la varianza \\(\\sigma^2\\) dei dati è nota e la prior per \\(\\mu\\) è Normale, la distribuzione Normale è coniugata per la media \\(\\mu\\). Ciò significa che la distribuzione a posteriori per \\(\\mu\\) sarà anch’essa Normale, mantenendo la stessa forma funzionale attraverso l’aggiornamento bayesiano.\n\n49.1.2 Distribuzione A priori\n\\(\\mu \\sim \\mathcal{N}(\\mu_0,\\sigma_0^2)\\): descrive dove crediamo sia \\(\\mu\\) e quanta incertezza abbiamo, una varianza grande significa poca informazione.\n\n49.1.3 Verosimiglianza\n\\[\np(y\\mid\\mu,\\sigma)=\\prod_{i=1}^{n}\\frac{1}{\\sigma\\sqrt{2\\pi}}\n                  \\exp\\!\\Bigl[-\\tfrac{(y_i-\\mu)^2}{2\\sigma^2}\\Bigr].\n\\]\n\n49.1.4 Teorema di Bayes\nIl teorema di Bayes combina prior e verosimiglianza attraverso un prodotto ponderato:\n\\[\np(\\mu\\mid y)=\\frac{p(y\\mid\\mu)\\,p(\\mu)}{p(y)} \\;\\; \\propto\\;\\;\n\\underbrace{\\mathcal{N}(\\mu_0,\\sigma_0^2)}_{\\text{prior}}\n\\; \\times \\;\n\\underbrace{\\mathcal{N}(\\bar y,\\sigma^2/n)}_{\\text{verosimiglianza}} .\n\\]\nIl prodotto di due distribuzioni gaussiane è una distribuzione gaussiana: basta aggiornare media e varianza.\n\n49.1.5 Media a posteriori\n\\[\n\\mu_p=\\frac{\\tfrac{1}{\\sigma_0^2}\\,\\mu_0 + \\tfrac{n}{\\sigma^2}\\,\\bar y}\n           {\\tfrac{1}{\\sigma_0^2} + \\tfrac{n}{\\sigma^2}},\n\\qquad\n\\bar y=\\frac{1}{n}\\sum_{i=1}^{n}y_i.\n\\]\n\n\\(\\mu_0\\): l’idea iniziale.\n\\(\\sigma_0^2\\): la fiducia in quell’idea.\n\\(\\bar y\\): ciò che dicono i dati.\n\\(n/\\sigma^2\\): la quantità di informazione empirica, aumenta con più casi e diminuisce con misure rumorose.\n\nInterpretazione: Il peso relativo di prior e dati dipende dalla loro credibilità:\n\nLa prior è influente se ha alta precisione, ovvero 1/\\(\\sigma_0^2\\) è grande, o se ci sono pochi dati, \\(n\\) piccolo.\nI dati sono dominanti se la prior ha bassa precisione o se c’è un ampio campione.\n\n\n\n49.1.6 Varianza a posteriori\n\\[\\sigma_p^2=\\frac{1}{\\tfrac{1}{\\sigma_0^2}+\\tfrac{n}{\\sigma^2}}.\\]\n\n\nProprietà Chiave: \\(\\sigma_p^2 \\le \\min(\\sigma_0^2, \\sigma^2/n)\\). L’incertezza diminuisce monotonicamente all’aumentare di \\(n\\).\n\n\nEsempio 49.1 Supponiamo di voler stimare il tempo medio di reazione \\(\\mu\\) (in millisecondi) di un gruppo di studenti a un compito Stroop. Dalla letteratura o da esperienze precedenti, assumiamo che la deviazione standard dei tempi di reazione per questo tipo di compito sia \\(\\sigma = 50\\) ms.\nDefiniamo la nostra distribuzione a priori per \\(\\mu\\) basandoci su una nostra conoscenza preliminare o un’ipotesi plausibile. Ad esempio, potremmo ipotizzare che il tempo medio sia attorno ai 500 ms, con una certa incertezza: * Media a priori: \\(\\mu_0 = 500\\) ms * Deviazione standard a priori: \\(\\sigma_0 = 100\\) ms (quindi varianza a priori \\(\\sigma_0^2 = 100^2 = 10000\\))\nSuccessivamente, raccogliamo i dati da \\(n=20\\) studenti e osserviamo una media campionaria dei tempi di reazione \\(\\bar{y} = 480\\) ms.\nRiepilogo dei parametri:\n\n\nSimbolo\nDescrizione\nValore\n\n\n\n\\(\\mu_0\\)\nMedia a priori\n500 ms\n\n\n\\(\\sigma_0\\)\nDev. std. a priori\n100 ms\n\n\n\\(\\sigma_0^2\\)\nVarianza a priori\n10000 ms²\n\n\n\\(\\sigma\\)\nDev. std. dei dati (nota)\n50 ms\n\n\n\\(\\sigma^2\\)\nVarianza dei dati (nota)\n2500 ms²\n\n\n\\(n\\)\nNumero di osservazioni\n20\n\n\n\\(\\bar{y}\\)\nMedia campionaria osservata\n480 ms\n\n\n\n1. Calcolo delle Precisioni (Pesi):\n\nPrecisione a priori: \\(w_0 = \\frac{1}{\\sigma_0^2} = \\frac{1}{100^2} = \\frac{1}{10000} = 0.0001\\)\n\nPrecisione dei dati: \\(w_{\\text{dati}} = \\frac{n}{\\sigma^2} = \\frac{20}{50^2} = \\frac{20}{2500} = 0.008\\)\n\n\n2. Calcolo della Media a Posteriori (\\(\\mu_n\\)): \\[ \\mu_n = \\frac{w_0 \\mu_0 + w_{\\text{dati}} \\bar{y}}{w_0 + w_{\\text{dati}}} = \\frac{0.0001 \\times 500 + 0.008 \\times 480}{0.0001 + 0.008} = \\frac{0.05 + 3.84}{0.0081} = \\frac{3.89}{0.0081} \\approx 480.247 \\text{ ms} \\]\n3. Calcolo della Varianza a Posteriori (\\(\\sigma_n^2\\)): \\[ \\sigma_n^2 = \\frac{1}{w_0 + w_{\\text{dati}}} = \\frac{1}{0.0001 + 0.008} = \\frac{1}{0.0081} \\approx 123.457 \\text{ ms}^2 \\] La deviazione standard a posteriori è \\(\\sigma_n = \\sqrt{\\sigma_n^2} \\approx \\sqrt{123.457} \\approx 11.11 \\text{ ms}\\).\nRisultato e Interpretazione: Siamo partiti da una stima a priori di \\(\\mu \\approx 500 \\pm 100\\) ms. Dopo aver osservato 20 tempi di reazione con una media di 480 ms (e sapendo che \\(\\sigma=50\\) ms), la nostra stima aggiornata per la media dei tempi di reazione è \\(\\mu_n \\approx 480.25 \\pm 11.11\\) ms. Notiamo che la media a posteriori (480.25 ms) è molto più vicina alla media campionaria (480 ms) che alla media a priori (500 ms). Questo perché la precisione dei dati (0.008) è significativamente maggiore della precisione a priori (0.0001). Inoltre, la nostra incertezza si è drasticamente ridotta: la deviazione standard è passata da 100 ms a circa 11 ms dopo sole 20 osservazioni. Questo illustra il potere dell’aggiornamento bayesiano nel raffinare le nostre stime e ridurre l’incertezza.\n\n# ---- Parametri dell'esempio -------------------------------------------\nmu0    &lt;- 500   # Media a priori\nsigma0 &lt;- 100   # Deviazione standard a priori\nsigma  &lt;- 50    # Deviazione standard nota dei dati\nn      &lt;- 20    # Dimensione del campione\nybar   &lt;- 480   # Media campionaria osservata\n\n# ---- Calcolo dei parametri a posteriori -------------------------------\n# Precisioni\nprec_prior &lt;- 1 / sigma0^2\nprec_data  &lt;- n / sigma^2\n\n# Parametri posteriori\nsigma_p2 &lt;- 1 / (prec_prior + prec_data)  # Varianza a posteriori\nsigma_p  &lt;- sqrt(sigma_p2)                # Deviazione standard a posteriori\nmu_p     &lt;- (mu0 * prec_prior + ybar * prec_data) / (prec_prior + prec_data) # Media a posteriori\n\n# ---- Griglia di valori per il parametro mu -----------------------------\n# Definiamo un range che copra bene tutte e tre le distribuzioni\nmin_mu &lt;- min(mu0 - 3*sigma0, ybar - 3*sigma/sqrt(n), mu_p - 3*sigma_p)\nmax_mu &lt;- max(mu0 + 3*sigma0, ybar + 3*sigma/sqrt(n), mu_p + 3*sigma_p)\nmu_grid &lt;- seq(min_mu, max_mu, length.out = 1000)\n\n# ---- Calcolo delle densità delle tre curve -----------------------------\nprior_dens &lt;- dnorm(mu_grid, mean = mu0,  sd = sigma0)            # Densità a priori\npost_dens  &lt;- dnorm(mu_grid, mean = mu_p, sd = sigma_p)           # Densità a posteriori\n\n# Verosimiglianza (standardizzata per mu, basata sulla media campionaria)\n# La sd per la verosimiglianza di mu è sigma/sqrt(n)\nlik_dens_raw &lt;- dnorm(mu_grid, mean = ybar, sd = sigma / sqrt(n))\n# Riscaliamo la verosimiglianza per renderla graficamente confrontabile con la prior\n# Questo è solo per visualizzazione, la verosimiglianza non è una densità per mu in senso stretto\nlik_dens_scaled &lt;- lik_dens_raw * (max(prior_dens) / max(lik_dens_raw))\n\n\n# ---- Preparazione dati in formato \"lungo\" per ggplot2 ------------------\ndf &lt;- data.frame(\n  mu         = mu_grid,\n  Prior      = prior_dens,\n  Likelihood_scaled = lik_dens_scaled, # Usiamo quella riscalata\n  Posterior  = post_dens\n)\n\ndf_long &lt;- pivot_longer(df, -mu, names_to = \"Distribuzione\", values_to = \"Densita\")\ndf_long$Distribuzione &lt;- factor(df_long$Distribuzione, \n                                levels = c(\"Prior\", \"Likelihood_scaled\", \"Posterior\"),\n                                labels = c(\"A Priori\", \"Verosimiglianza (riscalata)\", \"A Posteriori\"))\n\n\n# ---- Grafico delle distribuzioni ---------------------------------------\nggplot(df_long, aes(x = mu, y = Densita, colour = Distribuzione)) +\n  geom_line(linewidth = 1.2) +\n  labs(\n    x      = expression(paste(\"Media dei Tempi di Reazione \", mu, \" (ms)\")),\n    y      = \"Densità\",\n    title  = \"Aggiornamento Bayesiano: dal Prior al Posteriori\",\n    subtitle = paste0(\"Prior: N(\", mu0, \", \", sigma0^2, \"), \",\n                      \"Verosimiglianza (per μ): N(\", ybar, \", \", round((sigma^2/n),2), \"), \",\n                      \"Posteriori: N(\", round(mu_p,2), \", \", round(sigma_p2,2), \")\")\n  ) +\n  scale_color_manual(values = c(\"A Priori\" = \"dodgerblue\", \n                                \"Verosimiglianza (riscalata)\" = \"forestgreen\", \n                                \"A Posteriori\" = \"orangered\")) +\n  theme(legend.title = element_blank(), legend.position = \"top\")\n\n\n\n\n\n\nFigura 49.1: Distribuzioni a priori, verosimiglianza (standardizzata e riscalata) e a posteriori per la media dei tempi di reazione (μ).\n\n\n\n\nIl grafico Figura 49.1 illustra chiaramente come la distribuzione a posteriori sia “spostata” verso la verosimiglianza (che è più informativa della prior in questo caso) e come la sua varianza sia notevolmente ridotta rispetto a entrambe.\n\n\n\n\n\n\n\nMessaggi Chiave sull’Inferenza con Varianza Nota\n\n\n\n\nDialogo Costruttivo: L’inferenza bayesiana è un processo dinamico di dialogo tra le nostre ipotesi iniziali (prior) e l’evidenza empirica (dati/verosimiglianza).\nCalcoli Trasparenti: Con la varianza della popolazione \\(\\sigma^2\\) nota, i calcoli per la media e la varianza a posteriori sono diretti e possono essere eseguiti analiticamente (anche “a mano” per esempi semplici).\nRiduzione Garantita dell’Incertezza: Dopo aver osservato i dati, l’incertezza sul parametro (misurata dalla varianza a posteriori) non può che diminuire o, al limite, rimanere uguale (caso teorico di dati non informativi), rispetto alla varianza a priori.\nPeso dell’Evidenza: Con pochi dati o dati molto “rumorosi” (alta \\(\\sigma^2\\)), la distribuzione a priori esercita un’influenza maggiore sulla stima finale. Con molti dati o dati molto precisi (bassa \\(\\sigma^2\\)), l’informazione proveniente dai dati tende a dominare, e l’influenza della prior sulla stima a posteriori diminuisce.\nApplicabilità Vasta: Lo schema concettuale e matematico del modello Normale-Normale si applica a una vasta gamma di problemi in diverse discipline, inclusa la psicologia sperimentale (es. tempi di reazione, punteggi a test, ampiezze di segnali EEG), l’ingegneria, l’economia, e molte altre aree dove si misurano quantità continue. :::\n\n\n\n\nEsempio 49.2 I test standard di Quoziente Intellettivo (QI) sono generalmente calibrati per avere una media di 100 e una deviazione standard di 15 nella popolazione di riferimento. Tuttavia, sono state sollevate questioni riguardo a possibili bias culturali che potrebbero favorire alcuni gruppi rispetto ad altri. Un’ulteriore complicazione sorge quando i punteggi QI vengono aggregati a livello nazionale, poiché le medie nazionali possono mascherare eterogeneità intra-paese significative.\nQuesto esempio, ispirato da Gill (2015) (che discute i dati di Lynn e Vanhanen, 2001), analizza i dati di QI medio riportati per 80 nazioni. L’obiettivo è stimare un QI medio “globale” \\(\\mu\\) utilizzando un approccio bayesiano Normale-Normale, e riflettere criticamente sul risultato.\nAssumiamo una deviazione standard nota \\(\\sigma = 15\\) per i punteggi QI (questa è una semplificazione, poiché la variabilità delle medie nazionali potrebbe essere diversa dalla variabilità individuale).\nDati: I dati di QI medio per \\(n=80\\) nazioni sono forniti di seguito:\n\n\n\n\n\n\n\n\n\n\n\n\nPaese\nIQ\nPaese\nIQ\nPaese\nIQ\nPaese\nIQ\n\n\n\nArgentina\n96\nAustralia\n98\nAustria\n102\nBarbados\n78\n\n\nBelgium\n100\nBrazil\n87\nBulgaria\n93\nCanada\n97\n\n\nChina\n100\nCongo (Br.)\n73\nCongo (Zr.)\n65\nCroatia\n90\n\n\nCuba\n85\nCzech Repub.\n97\nDenmark\n98\nEcuador\n80\n\n\nEgypt\n83\nEq. Guinea\n59\nEthiopia\n63\nFiji\n84\n\n\nFinland\n97\nFrance\n98\nGermany\n102\nGhana\n71\n\n\nGreece\n92\nGuatemala\n79\nGuinea\n66\nHong Kong\n107\n\n\nHungary\n99\nIndia\n81\nIndonesia\n89\nIran\n84\n\n\nIraq\n87\nIreland\n93\nIsrael\n94\nItaly\n102\n\n\nJamaica\n72\nJapan\n105\nKenya\n72\nKorea (S.)\n106\n\n\nLebanon\n86\nMalaysia\n92\nMarshall I.\n84\nMexico\n87\n\n\nMorocco\n85\nNepal\n78\nNetherlands\n102\nNew Zealand\n100\n\n\nNigeria\n67\nNorway\n98\nPeru\n90\nPhilippines\n86\n\n\nPoland\n99\nPortugal\n95\nPuerto Rico\n84\nQatar\n78\n\n\nRomania\n94\nRussia\n96\nSamoa\n87\nSierra Leone\n64\n\n\nSingapore\n103\nSlovakia\n96\nSlovenia\n95\nSouth Africa\n72\n\n\nSpain\n97\nSudan\n72\nSuriname\n89\nSweden\n101\n\n\nSwitzerland\n101\nTaiwan\n104\nTanzania\n72\nThailand\n91\n\n\nTonga\n87\nTurkey\n90\nUganda\n73\nU.K.\n100\n\n\nU.S.\n98\nUruguay\n96\nZambia\n77\nZimbabwe\n66\n\n\n\nImpostazione del Modello Bayesiano:\n\nPrior per \\(\\mu\\): Stabiliamo una prior basata sulla standardizzazione tipica dei test QI:\n\n\n\n\\(\\mu_0 = 100\\) (media a priori)\n\n\\(\\sigma_0 = 15\\) (deviazione standard a priori, che riflette una certa incertezza sulla media globale, o la stessa scala della \\(\\sigma\\) individuale). Quindi, \\(\\mu \\sim \\mathcal{N}(100, 15^2)\\).\n\n\nVerosimiglianza: Ogni QI nazionale \\(y_i\\) è considerato come un’osservazione della media “vera” \\(\\mu\\) con varianza \\(\\sigma^2 = 15^2\\). La media campionaria dei QI nazionali sarà \\(\\bar{y}\\). (Nota: Questa è una semplificazione. Idealmente, ogni \\(y_i\\) è già una media, e dovremmo considerare la sua precisione \\(N_i/\\sigma^2\\) se \\(N_i\\) fosse la dimensione del campione per quella nazione. Qui, trattiamo ogni media nazionale come un singolo dato \\(y_i\\) proveniente da \\(\\mathcal{N}(\\mu, \\sigma^2)\\)).\n\nImplementiamo le informazioni necessarie in R.\n\n# Dati IQ delle 80 nazioni (valori aggregati per paese)\niq &lt;- c(\n  96, 100, 100, 85, 83, 97, 92, 99, 87, 72, 86, 85, 67, 99, 94, 103, 97, 101, \n  87, 98, 87, 73, 97, 59, 98, 79, 81, 93, 105, 92, 78, 98, 95, 96, 72, 104, \n  90, 96, 98, 102, 78, 90, 63, 84, 84, 107, 86, 102, 106, 94, 102, 72, 101, \n  89, 72, 101, 91, 100, 100, 66, 107, 86, 78, 84, 78, 64, 72, 101, 91, 100, \n  67, 86\n) # Dati da Lynn e Vanhanen (2001) come presentati in Gill (2015)\n\n# Numero di osservazioni (nazioni)\nn &lt;- length(iq)\n\n# Media campionaria dei QI nazionali\ny_bar &lt;- mean(iq)\n\n# Deviazione standard assunta nota (per la \"popolazione\" da cui provengono le medie nazionali)\nsigma &lt;- 15\n\n# Parametri a priori\nmu_0 &lt;- 100    # Media a priori\nsigma_0 &lt;- 15  # Dev. std. a priori\n\ncat(paste(\"Numero di nazioni (n):\", n))\n#&gt; Numero di nazioni (n): 72\ncat(paste(\"\\nMedia campionaria dei QI nazionali (y_bar):\", round(y_bar, 2)))\n#&gt; \n#&gt; Media campionaria dei QI nazionali (y_bar): 89.21\n\nCalcolo dei Parametri a Posteriori:\nUtilizziamo le formule derivate precedentemente:\n\\[\\mu_n = \\frac{\\frac{1}{\\sigma_0^2}\\mu_0 + \\frac{n}{\\sigma^2}\\bar{y}}{\\frac {1}{\\sigma_0^2} + \\frac{n}{\\sigma^2}}\n\\]\n\\[\n\\sigma_n^2 = \\frac{1}{\\frac {1}{\\sigma_0^2}+ \\frac{n}{\\sigma^2}}\n\\]\n\n# Precisioni\nprec_prior_iq &lt;- 1 / sigma_0^2\nprec_data_iq  &lt;- n / sigma^2\n\n# Parametri posteriori\nmu_p_iq     &lt;- (mu_0 * prec_prior_iq + y_bar * prec_data_iq) / (prec_prior_iq + prec_data_iq)\nsigma_p_sq_iq &lt;- 1 / (prec_prior_iq + prec_data_iq)\nsigma_p_iq    &lt;- sqrt(sigma_p_sq_iq)\n\ncat(paste(\"Media a posteriori (mu_n):\", round(mu_p_iq, 2)))\n#&gt; Media a posteriori (mu_n): 89.36\ncat(paste(\"\\nVarianza a posteriori (sigma_n^2):\", round(sigma_p_sq_iq, 2)))\n#&gt; \n#&gt; Varianza a posteriori (sigma_n^2): 3.08\ncat(paste(\"\\nDeviazione standard a posteriori (sigma_n):\", round(sigma_p_iq, 2)))\n#&gt; \n#&gt; Deviazione standard a posteriori (sigma_n): 1.76\n\nGeneriamo una rappresentazione grafica della distribuzione a posteriori della media del IQ sulla base dei dati osservati, avendo assunto mu_0 = 100 e sigma_0 = 15 per la distribuzione a priori.\n\n# Definizione dei valori sull'asse x per il grafico della posteriori\nx_qi &lt;- seq(mu_p_iq - 4 * sigma_p_iq, mu_p_iq + 4 * sigma_p_iq, length.out = 1000)\n\n# Calcolo della densità di probabilità per la posteriori\npdf_qi &lt;- dnorm(x_qi, mean = mu_p_iq, sd = sigma_p_iq)\n\n# Creazione del grafico\nggplot(data.frame(x = x_qi, pdf = pdf_qi), aes(x = x, y = pdf)) +\n  geom_line(color = \"darkslateblue\", linewidth = 1.2) +\n  geom_area(fill = \"darkslateblue\", alpha = 0.3) +\n  labs(\n    x = \"Media 'Globale' del Quoziente di Intelligenza (μ)\",\n    y = \"Densità di Probabilità\",\n    title = \"Distribuzione a Posteriori del QI Medio Globale\",\n    subtitle = paste0(\"Posteriori: N(\", round(mu_p_iq, 2), \", \", round(sigma_p_sq_iq, 2), \")\")\n  ) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\nFigura 49.2: Distribuzione a posteriori per la media ‘globale’ del QI (μ), basata sui dati di 80 nazioni.\n\n\n\n\nPer completezza, visualizziamo anche prior, likelihood e posterior:\n\nmu_grid_iq &lt;- seq(min(mu_0 - 3 * sigma_0, y_bar - 3 * sigma / sqrt(n), mu_p_iq - 3 * sigma_p_iq),\n  max(mu_0 + 3 * sigma_0, y_bar + 3 * sigma / sqrt(n), mu_p_iq + 3 * sigma_p_iq),\n  length.out = 1000\n)\n\nprior_dens_iq &lt;- dnorm(mu_grid_iq, mean = mu_0, sd = sigma_0)\nlik_dens_raw_iq &lt;- dnorm(mu_grid_iq, mean = y_bar, sd = sigma / sqrt(n)) # SD della media campionaria\nlik_dens_scaled_iq &lt;- lik_dens_raw_iq * (max(prior_dens_iq) / max(lik_dens_raw_iq, na.rm = TRUE)) # Scalata\npost_dens_iq &lt;- dnorm(mu_grid_iq, mean = mu_p_iq, sd = sigma_p_iq)\n\ndf_iq &lt;- data.frame(\n  mu = mu_grid_iq,\n  Prior = prior_dens_iq,\n  Likelihood_scaled = lik_dens_scaled_iq,\n  Posterior = post_dens_iq\n)\n\ndf_long_iq &lt;- pivot_longer(df_iq, -mu, names_to = \"Distribuzione\", values_to = \"Densita\")\ndf_long_iq$Distribuzione &lt;- factor(df_long_iq$Distribuzione,\n  levels = c(\"Prior\", \"Likelihood_scaled\", \"Posterior\"),\n  labels = c(\"A Priori\", \"Verosimiglianza (riscalata)\", \"A Posteriori\")\n)\n\nggplot(df_long_iq, aes(x = mu, y = Densita, colour = Distribuzione)) +\n  geom_line(linewidth = 1.2) +\n  labs(\n    x = expression(paste(\"Media QI \", mu)),\n    y = \"Densità\",\n    title = \"Aggiornamento Bayesiano per il QI Medio 'Globale'\",\n    subtitle = paste0(\n      \"Prior: N(\", mu_0, \", \", sigma_0^2, \"), \",\n      \"Verosimiglianza (per μ): N(\", round(y_bar, 2), \", \", round((sigma^2 / n), 2), \"), \",\n      \"Posteriori: N(\", round(mu_p_iq, 2), \", \", round(sigma_p_sq_iq, 2), \")\"\n    )\n  ) +\n  scale_color_manual(values = c(\n    \"A Priori\" = \"dodgerblue\",\n    \"Verosimiglianza (riscalata)\" = \"forestgreen\",\n    \"A Posteriori\" = \"orangered\"\n  )) +\n  theme(legend.title = element_blank(), legend.position = \"top\")\n\n\n\n\n\n\n\nDiscussione Critica dei Risultati\nL’analisi bayesiana ha prodotto una media a posteriori per il QI “globale” di \\(\\mu_n \\approx 89.36\\), con una deviazione standard a posteriori molto piccola (\\(\\sigma_n \\approx 1.66\\)). Questo valore è notevolmente inferiore alla media standard di 100.\nTuttavia, è cruciale interpretare questo risultato con estrema cautela, considerando diversi fattori limitanti e criticità:\n\n\nEffetto di Aggregazione (Ecological Fallacy): La media a posteriori è calcolata aggregando i dati QI medi di 80 nazioni. Questa media aggregata potrebbe non riflettere accuratamente la distribuzione del QI a livello individuale all’interno delle singole nazioni, né la vera distribuzione “globale” se si potessero testare tutti gli individui. Le differenze significative tra le nazioni (in termini di medie, varianze, e contesti socio-culturali) vengono “appiattite” in un unico valore, potenzialmente mascherando eterogeneità importanti.\n\nDati Non Ponderati: L’analisi tratta ogni nazione come un’singola osservazione, indipendentemente dalla sua popolazione. Nazioni con popolazioni molto diverse contribuiscono allo stesso modo alla stima della media \\(\\bar{y}\\). Una media ponderata per la popolazione potrebbe fornire un quadro diverso, sebbene anch’esso soggetto a critiche.\n\nContesto e Fattori Concomitanti: La deviazione dalla media standard di 100 potrebbe riflettere non solo (o non principalmente) differenze “reali” nell’intelligenza media, ma anche enormi disparità nei contesti sanitari, educativi, socio-economici e politici in cui i test sono stati (eventualmente) somministrati o i dati raccolti. Fattori come l’accesso all’istruzione di qualità, la nutrizione, la salute pubblica, e l’esposizione a stimoli cognitivi variano drasticamente tra le nazioni e possono influenzare significativamente i punteggi medi.\n\nBias Culturale dei Test: I test del QI sono stati storicamente sviluppati e standardizzati in contesti culturali specifici (principalmente occidentali, industrializzati). La loro applicabilità e validità cross-culturale è oggetto di un acceso dibattito. È possibile che i test stessi presentino bias culturali che portano a sottostimare le capacità cognitive in contesti culturali diversi da quello di origine, influenzando così le medie nazionali riportate.\n\nQualità e Origine dei Dati: I dati originali di Lynn e Vanhanen sono stati oggetto di numerose critiche metodologiche riguardanti la raccolta, la comparabilità e la qualità dei punteggi QI tra diverse nazioni. Utilizzare questi dati senza un esame approfondito delle loro limitazioni può portare a conclusioni fuorvianti.\n\nAssunzione di \\(\\sigma\\) Nota e Uguale: L’assunzione che \\(\\sigma=15\\) sia la deviazione standard rilevante per le medie nazionali è una forte semplificazione. La variabilità tra le medie nazionali potrebbe essere diversa dalla variabilità individuale all’interno di una popolazione di riferimento.\n\nIn conclusione, sebbene il modello Normale-Normale fornisca una stima quantitativa (\\(\\mu_n \\approx 89.36\\)), le profonde questioni metodologiche, concettuali ed etiche legate ai dati sul QI internazionale rendono problematica un’interpretazione diretta di questo valore come “vera” media globale dell’intelligenza. Questo esempio serve più come illustrazione meccanica dell’aggiornamento bayesiano che come un’affermazione sostanziale sul QI globale. Un’analisi seria richiederebbe modelli gerarchici più complessi, una discussione approfondita della validità dei dati e una considerazione attenta dei fattori contestuali.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_conjugate_families_2.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/08_conjugate_families_2.html#riflessioni-conclusive",
    "title": "49  Distribuzioni coniugate (2)",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo, abbiamo esplorato il meccanismo dell’aggiornamento bayesiano attraverso l’applicazione del modello Normale-Normale, specificamente nel caso in cui la varianza \\(\\sigma^2\\) della popolazione da cui provengono i dati sia considerata nota.\nIl processo inizia con la definizione di una distribuzione a priori per la media incognita \\(\\mu\\). Questa prior, \\(\\mu \\sim \\mathcal{N}(\\mu_0, \\sigma_0^2)\\), quantifica le nostre conoscenze o ipotesi iniziali su \\(\\mu\\) attraverso la sua media \\(\\mu_0\\) e la sua varianza \\(\\sigma_0^2\\).\nSuccessivamente, acquisiamo nuovi dati \\(y_1, \\dots, y_n\\), che assumiamo essere campionati da una distribuzione Normale \\(\\mathcal{N}(\\mu, \\sigma^2)\\). L’informazione contenuta nei dati viene sintetizzata dalla media campionaria \\(\\bar{y}\\) e dalla dimensione del campione \\(n\\), che, insieme alla varianza nota \\(\\sigma^2\\), determinano la forma della funzione di verosimiglianza (proporzionale a \\(\\mathcal{N}(\\bar{y}, \\sigma^2/n)\\) come funzione di \\(\\mu\\)).\nApplicando il Teorema di Bayes, combiniamo la prior e la verosimiglianza. Grazie alla proprietà di coniugatezza tra la distribuzione Normale (per la prior) e la verosimiglianza Normale (per i dati), la distribuzione a posteriori per \\(\\mu\\) risulta anch’essa Normale: \\(\\mu \\mid \\mathbf{y} \\sim \\mathcal{N}(\\mu_n, \\sigma_n^2)\\).\nLa media a posteriori \\(\\mu_n\\) è una media ponderata della media a priori \\(\\mu_0\\) e della media campionaria \\(\\bar{y}\\). I pesi sono determinati dalle rispettive precisioni (il reciproco delle varianze):\n\\[\n\\mu_n = \\frac{\\left(\\frac{1}{\\sigma_0^2}\\right)\\mu_0 + \\left(\\frac{n}{\\sigma^2}\\right)\\bar{y}}{\\frac{1}{\\sigma_0^2} + \\frac{n}{\\sigma^2}}\n\\]\nLa varianza a posteriori \\(\\sigma_n^2\\) è calcolata in modo che la sua precisione sia la somma delle precisioni della prior e dei dati:\n\\[\n\\frac{1}{\\sigma_n^2} = \\frac{1}{\\sigma_0^2} + \\frac{n}{\\sigma^2} \\quad \\implies \\quad \\sigma_n^2 = \\left(\\frac{1}{\\sigma_0^2} + \\frac{n}{\\sigma^2}\\right)^{-1}\n\\]\nUn aspetto fondamentale è che la varianza a posteriori \\(\\sigma_n^2\\) è sempre minore o uguale sia a \\(\\sigma_0^2\\) sia a \\(\\sigma^2/n\\), indicando che l’incorporazione dei dati porta a una riduzione (o al più, a nessuna variazione) dell’incertezza su \\(\\mu\\).\nIn sintesi, il modello Normale-Normale con varianza nota offre un quadro analiticamente trattabile e intuitivo per l’aggiornamento bayesiano. La coniugatezza semplifica i calcoli, permettendo di concentrarsi sull’interpretazione di come le credenze iniziali vengono modificate dall’evidenza empirica. Sebbene l’assunzione di varianza nota sia una semplificazione, questo modello getta le basi per comprendere modelli più complessi in cui anche la varianza è incognita e stimata.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_conjugate_families_2.html#esercizi",
    "href": "chapters/bayesian_inference/08_conjugate_families_2.html#esercizi",
    "title": "49  Distribuzioni coniugate (2)",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nRiprendi i dati della SWLS che sono stati utilizzati nell’esercizio del ?sec-gauss-grid. Trova la media e la deviazione standard della distribuzione a posteriori usando il metodo delle distribuzioni coniugate. Confronta i risultati con quelli ottenuti con il metodo basato su griglia.\nConsegna: Carica il file .qmd, convertito in PDF, su Moodle.\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\nPer risolvere questo esercizio con il metodo delle distribuzioni coniugate, assumiamo che i dati provengano da una distribuzione normale con deviazione standard nota e media da stimare. Nel caso di una verosimiglianza gaussiana con prior gaussiano, la distribuzione a posteriori sarà ancora una distribuzione normale. Questo approccio è analitico e ci permette di ottenere la media e la deviazione standard della distribuzione a posteriori senza dover ricorrere a metodi numerici come la discretizzazione della griglia.\nPassaggi per il calcolo della distribuzione a posteriori\n\n\nDefiniamo i dati osservati:\n\nLa media campionaria: \\(\\bar{x}\\)\n\nLa deviazione standard nota dei dati: \\(\\sigma\\)\n\nIl numero di osservazioni: \\(n\\)\n\n\n\n\nScegliamo un prior gaussiano molto diffuso:\n\nMedia a priori: \\(\\mu_0\\)\n\nDeviazione standard a priori molto grande: \\(\\sigma_0\\)\n\n\n\n\nCalcoliamo la media e la varianza della distribuzione a posteriori:\n\n\nLa media a posteriori è:\n\\[\n\\mu_{\\text{post}} = \\frac{\\sigma^2_0 \\bar{x} + \\sigma^2 n \\mu_0}{\\sigma^2_0 + \\sigma^2 n}\n\\]\n\n\nLa varianza a posteriori è:\n\\[\n\\sigma^2_{\\text{post}} = \\frac{\\sigma^2_0 \\sigma^2}{\\sigma^2_0 + \\sigma^2 n}\n\\]\n\n\n\n\nImplementazione in R\n# Caricamento librerie necessarie\nlibrary(dplyr)\nlibrary(tibble)\n\n# Dati SWLS\nswls_data &lt;- data.frame(\n  soddisfazione = c(4.2, 5.1, 4.7, 4.3, 5.5, 4.9, 4.8, 5.0, 4.6, 4.4)\n)\n\n# Parametri comuni per entrambi i metodi\nsigma_conosciuta &lt;- sd(swls_data$soddisfazione)  # Usando la deviazione standard campionaria\nn &lt;- nrow(swls_data)\nmean_x &lt;- mean(swls_data$soddisfazione)\n\ncat(\"Deviazione standard campionaria:\", sigma_conosciuta, \"\\n\")\ncat(\"Media campionaria:\", mean_x, \"\\n\")\n\n# ---- Metodo 1: Griglia ----\n# Definizione della griglia più fine e centrata intorno alla media campionaria\nmu_griglia &lt;- seq(mean_x - 3*sigma_conosciuta/sqrt(n), \n                 mean_x + 3*sigma_conosciuta/sqrt(n), \n                 length.out = 1000)\n\n# Calcolo della verosimiglianza\nlog_likelihood &lt;- numeric(length(mu_griglia))\nfor (i in seq_along(mu_griglia)) {\n  # Utilizzo della log-likelihood per evitare problemi numerici\n  log_likelihood[i] &lt;- sum(dnorm(swls_data$soddisfazione, \n                                mean = mu_griglia[i], \n                                sd = sigma_conosciuta, \n                                log = TRUE))\n}\n\n# Prior uniforme (in scala logaritmica)\nlog_prior &lt;- rep(0, length(mu_griglia))\n\n# Calcolo della posteriori\nlog_posterior &lt;- log_likelihood + log_prior\nposterior &lt;- exp(log_posterior - max(log_posterior))\nposterior &lt;- posterior / sum(posterior)\n\n# Campionamento e calcolo statistiche\nsamples_grid &lt;- sample(mu_griglia, size = 10000, replace = TRUE, prob = posterior)\nmean_post_grid &lt;- mean(samples_grid)\nsd_post_grid &lt;- sd(samples_grid)\nci_grid &lt;- quantile(samples_grid, c(0.03, 0.97))\n\n# ---- Metodo 2: Soluzione analitica ----\n# Prior poco informativo ma non improprio\nmu_prior &lt;- mean_x\nsigma_prior &lt;- 10\n\n# Calcolo posteriori\nmu_post_analytic &lt;- (sigma_prior^2 * mean_x + sigma_conosciuta^2 * mu_prior/n) / \n                    (sigma_prior^2 + sigma_conosciuta^2/n)\nsigma_post_analytic &lt;- sqrt((sigma_prior^2 * sigma_conosciuta^2/n) / \n                           (sigma_prior^2 + sigma_conosciuta^2/n))\n\n# Confronto risultati\nresults &lt;- tibble(\n  Metodo = c(\"Griglia\", \"Analitico\"),\n  `Media Posteriori` = c(mean_post_grid, mu_post_analytic),\n  `Dev. Std. Posteriori` = c(sd_post_grid, sigma_post_analytic)\n)\nresults\nInterpretazione dei risultati\n\nLa media a posteriori rappresenta la miglior stima aggiornata della media della popolazione dopo aver osservato i dati.\nLa deviazione standard a posteriori ci dice quanto è incerta la nostra stima della media dopo aver integrato i dati e il prior.\n\nSiccome abbiamo scelto un prior molto diffuso (\\(\\sigma_0 = 10\\)), il risultato ottenuto è molto vicino a quello ottenuto con il metodo della griglia, dove il prior uniforme aveva un impatto minimo sulla distribuzione a posteriori.\nQuesta implementazione analitica permette di ottenere il risultato in modo efficiente senza necessità di metodi numerici approssimati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_conjugate_families_2.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/08_conjugate_families_2.html#informazioni-sullambiente-di-sviluppo",
    "title": "49  Distribuzioni coniugate (2)",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.18.0           pillar_1.11.0         tinytable_0.11.0     \n#&gt;  [4] conflicted_1.2.0      patchwork_1.3.1       ggdist_3.3.3         \n#&gt;  [7] tidybayes_3.0.7       bayesplot_1.13.0      ggplot2_3.5.2        \n#&gt; [10] reliabilitydiag_0.2.1 priorsense_1.1.0      posterior_1.6.1      \n#&gt; [13] loo_2.8.0             rstan_2.32.7          StanHeaders_2.32.10  \n#&gt; [16] brms_2.22.0           Rcpp_1.1.0            janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] Rdpack_2.6.4         gridExtra_2.3        inline_0.3.21       \n#&gt;  [4] sandwich_3.1-1       rlang_1.1.6          magrittr_2.0.3      \n#&gt;  [7] multcomp_1.4-28      snakecase_0.11.1     compiler_4.5.1      \n#&gt; [10] vctrs_0.6.5          stringr_1.5.1        pkgconfig_2.0.3     \n#&gt; [13] shape_1.4.6.1        arrayhelpers_1.1-0   fastmap_1.2.0       \n#&gt; [16] backports_1.5.0      labeling_0.4.3       rmarkdown_2.29      \n#&gt; [19] nloptr_2.2.1         purrr_1.1.0          xfun_0.52           \n#&gt; [22] glmnet_4.1-10        jomo_2.7-6           cachem_1.1.0        \n#&gt; [25] jsonlite_2.0.0       pan_1.9              broom_1.0.9         \n#&gt; [28] parallel_4.5.1       R6_2.6.1             stringi_1.8.7       \n#&gt; [31] RColorBrewer_1.1-3   rpart_4.1.24         boot_1.3-31         \n#&gt; [34] lubridate_1.9.4      estimability_1.5.1   iterators_1.0.14    \n#&gt; [37] knitr_1.50           zoo_1.8-14           pacman_0.5.1        \n#&gt; [40] nnet_7.3-20          Matrix_1.7-3         splines_4.5.1       \n#&gt; [43] timechange_0.3.0     tidyselect_1.2.1     abind_1.4-8         \n#&gt; [46] yaml_2.3.10          codetools_0.2-20     curl_6.4.0          \n#&gt; [49] pkgbuild_1.4.8       lattice_0.22-7       withr_3.0.2         \n#&gt; [52] bridgesampling_1.1-2 coda_0.19-4.1        evaluate_1.0.4      \n#&gt; [55] survival_3.8-3       RcppParallel_5.1.10  tensorA_0.36.2.1    \n#&gt; [58] checkmate_2.3.2      foreach_1.5.2        stats4_4.5.1        \n#&gt; [61] reformulas_0.4.1     distributional_0.5.0 generics_0.1.4      \n#&gt; [64] rprojroot_2.1.0      rstantools_2.4.0     scales_1.4.0        \n#&gt; [67] minqa_1.2.8          xtable_1.8-4         glue_1.8.0          \n#&gt; [70] emmeans_1.11.2       tools_4.5.1          lme4_1.1-37         \n#&gt; [73] mvtnorm_1.3-3        grid_4.5.1           rbibutils_2.3       \n#&gt; [76] QuickJSR_1.8.0       colorspace_2.1-1     nlme_3.1-168        \n#&gt; [79] cli_3.6.5            svUnit_1.0.6         Brobdingnag_1.2-9   \n#&gt; [82] V8_6.0.5             gtable_0.3.6         digest_0.6.37       \n#&gt; [85] TH.data_1.1-3        htmlwidgets_1.6.4    farver_2.1.2        \n#&gt; [88] memoise_2.0.1        htmltools_0.5.8.1    lifecycle_1.0.4     \n#&gt; [91] mitml_0.4-5          MASS_7.3-65",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_conjugate_families_2.html#bibliografia",
    "href": "chapters/bayesian_inference/08_conjugate_families_2.html#bibliografia",
    "title": "49  Distribuzioni coniugate (2)",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGill, J. (2015). Bayesian methods: A social and behavioral sciences approach (3rd Edition). Chapman; Hall/CRC.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_summary_posterior.html",
    "href": "chapters/bayesian_inference/09_summary_posterior.html",
    "title": "50  Sintesi a posteriori",
    "section": "",
    "text": "Introduzione\nIn questo capitolo, concentriamo la nostra attenzione sulla sintesi dell’informazione racchiusa nella distribuzione a posteriori, la quale rappresenta il nostro livello di incertezza riguardo al parametro o ai parametri incogniti oggetto dell’inferenza.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_summary_posterior.html#riepilogo-numerico",
    "href": "chapters/bayesian_inference/09_summary_posterior.html#riepilogo-numerico",
    "title": "50  Sintesi a posteriori",
    "section": "\n50.1 Riepilogo numerico",
    "text": "50.1 Riepilogo numerico\nLa distribuzione a posteriori contiene in sé tutte le informazioni disponibili sui potenziali valori del parametro. Nel caso di un parametro unidimensionale o bidimensionale, possiamo rappresentare la distribuzione a posteriori mediante un grafico \\(p(\\theta \\mid y)\\).\nTuttavia, quando ci troviamo di fronte a vettori di parametri con più di due dimensioni, risulta vantaggioso eseguire una sintesi numerica della distribuzione a posteriori. Possiamo distinguere due forme di sintesi numerica della distribuzione a posteriori:\n\nStima puntuale;\nIntervallo di credibilità.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_summary_posterior.html#stima-puntuale",
    "href": "chapters/bayesian_inference/09_summary_posterior.html#stima-puntuale",
    "title": "50  Sintesi a posteriori",
    "section": "\n50.2 Stima puntuale",
    "text": "50.2 Stima puntuale\nNel contesto dell’inferenza bayesiana, stimare il valore più credibile di un parametro \\(\\theta\\) a partire dalla distribuzione a posteriori può avvenire attraverso tre statistiche principali: moda, mediana e media. La scelta tra queste dipende dalla forma della distribuzione a posteriori.\nQueste statistiche forniscono una stima puntuale della tendenza centrale della distribuzione, ossia il valore a cui attribuiamo il massimo grado di fiducia soggettiva, basandoci sia sui dati osservati sia sulle credenze a priori.\n1. Moda (Massimo a Posteriori, MAP)\nLa moda è il valore più probabile del parametro, ovvero quello che massimizza la distribuzione a posteriori. Questo valore è noto come massimo a posteriori (MAP).\nIl concetto di MAP deriva dalla stima di massima verosimiglianza (MLE), che individua il valore di \\(\\theta\\) che massimizza la funzione di verosimiglianza:\n\\[\n\\hat{\\theta}_{ML} = \\arg \\max_\\theta L(\\theta \\mid y).  \n\\]\nNell’inferenza bayesiana, consideriamo \\(\\theta\\) come una variabile casuale con una distribuzione a priori \\(p(\\theta)\\). Incorporando questa informazione nella funzione di verosimiglianza, otteniamo la stima MAP:\n\\[\n\\hat{\\theta}_{MAP} = \\arg \\max_\\theta L(\\theta \\mid y)p(\\theta).  \n\\]\nQuesta formula mostra che il MAP è il valore che massimizza la densità a posteriori di \\(\\theta\\) dato il set di dati osservati \\(y\\).\nLimitazioni della stima MAP:\n\n\nDifficoltà computazionali: con metodi MCMC, è complesso individuare con precisione il MAP nello spazio delle distribuzioni posteriori.\n\n\nSensibilità alla forma della distribuzione: se la distribuzione a posteriori è asimmetrica o multimodale, il MAP potrebbe non rappresentare adeguatamente la tendenza centrale.\n\n\nMinor robustezza rispetto ad altre misure: il MAP si basa esclusivamente sul valore massimo della distribuzione e non tiene conto della distribuzione complessiva della probabilità.\n2. Media a posteriori\nLa media a posteriori è il valore atteso di \\(\\theta\\) secondo la distribuzione a posteriori:\n\\[\nE(\\theta \\mid y) = \\int_{-\\infty}^{\\infty} \\theta \\, p(\\theta \\mid y) \\, d\\theta.  \n\\]\nQuesta stima è spesso preferita perché considera l’intera distribuzione e minimizza l’errore quadratico medio (Mean Squared Error, MSE). Tuttavia, se la distribuzione a posteriori è asimmetrica, la media potrebbe non rappresentare bene la posizione della maggior parte della probabilità.\n3. Mediana a posteriori\nLa mediana a posteriori è il valore che divide la distribuzione a posteriori in due parti uguali, con il 50% della probabilità a sinistra e il 50% a destra.\nLa mediana è una stima robusta della tendenza centrale ed è particolarmente utile in distribuzioni asimmetriche o multimodali, dove la moda e la media potrebbero risultare fuorvianti.\nMisurare l’incertezza: varianza a posteriori\nOltre a stimare la tendenza centrale, è utile valutare l’incertezza associata alla stima di \\(\\theta\\). La varianza a posteriori misura la dispersione della distribuzione:\n\\[\nV(\\theta|y) = E[((\\theta - E[(\\theta|y)])^2 |y) = \\int_{-\\infty}^{\\infty} (\\theta - E[\\theta | y])^2 p(\\theta | y) d\\theta = E[\\theta^2 |y] - E[\\theta|y]^2.  \n\\]\nLa deviazione standard a posteriori (radice quadrata della varianza) esprime l’incertezza sulla stima \\(\\theta\\) con la stessa unità di misura dei dati.\nIn sintesi, la moda (MAP), la media e la mediana a posteriori offrono diverse prospettive sulla stima puntuale di un parametro \\(\\theta\\). Ciascuna ha vantaggi e limiti, e la scelta migliore dipende dalla forma della distribuzione a posteriori e dal contesto applicativo.\nInsieme alla varianza a posteriori, queste statistiche forniscono un quadro completo della distribuzione a posteriori, permettendo di esprimere non solo la stima più credibile, ma anche l’incertezza associata.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_summary_posterior.html#intervallo-di-credibilità",
    "href": "chapters/bayesian_inference/09_summary_posterior.html#intervallo-di-credibilità",
    "title": "50  Sintesi a posteriori",
    "section": "\n50.3 Intervallo di credibilità",
    "text": "50.3 Intervallo di credibilità\nNell’inferenza bayesiana, l’intervallo di credibilità è uno strumento utilizzato per definire un intervallo che contiene una determinata percentuale della massa della distribuzione a posteriori del parametro \\(\\theta\\). Questo intervallo riflette l’incertezza associata alla stima del parametro: un intervallo più ampio suggerisce una maggiore incertezza. Lo scopo principale dell’intervallo di credibilità è fornire una misura quantitativa dell’incertezza riguardante \\(\\theta\\).\nA differenza degli intervalli di confidenza frequentisti, non esiste un unico intervallo di credibilità per un dato livello di confidenza \\((1 - \\alpha) \\cdot 100\\%\\). In effetti, è possibile costruire un numero infinito di tali intervalli. Per questo motivo, è necessario stabilire criteri aggiuntivi per selezionare l’intervallo di credibilità più appropriato. Tra le opzioni più comuni ci sono l’intervallo di credibilità simmetrico e l’intervallo di massima densità posteriore (HPD).\n1. Intervallo di Credibilità Simmetrico\nQuesto tipo di intervallo è centrato rispetto al punto di stima puntuale. Se \\(\\hat{\\theta}\\) rappresenta la stima del parametro, l’intervallo simmetrico avrà la forma \\((\\hat{\\theta} - a, \\hat{\\theta} + a)\\), dove \\(a\\) è un valore positivo scelto in modo tale che la massa totale inclusa sia pari a \\((1 - \\alpha)\\). Più formalmente, un intervallo di credibilità simmetrico al livello \\(\\alpha\\) può essere espresso come:\n\\[\nI_{\\alpha} = [q_{\\alpha/2}, q_{1 - \\alpha/2}],\n\\]\ndove \\(q_z\\) rappresenta il quantile \\(z\\) della distribuzione a posteriori. Ad esempio, un intervallo di credibilità simmetrico al 94% sarà:\n\\[\nI_{0.06} = [q_{0.03}, q_{0.97}],\n\\]\ndove il 3% della massa a posteriori si trova in ciascuna delle due code della distribuzione.\n2. Intervallo di Credibilità Più Stretto (Intervallo di Massima Densità Posteriore, HPD)\nL’intervallo di massima densità posteriore (HPD) è l’intervallo più stretto possibile che contiene il \\((1 - \\alpha) \\cdot 100\\%\\) della massa a posteriori. A differenza dell’intervallo simmetrico, l’HPD include tutti i valori di \\(\\theta\\) che hanno la maggiore densità a posteriori. Per costruirlo, si disegna una linea orizzontale sulla distribuzione a posteriori e si regola l’altezza della linea in modo che l’area sotto la curva corrisponda a \\((1 - \\alpha)\\). L’HPD risulta essere il più stretto tra tutti gli intervalli possibili per lo stesso livello di confidenza. Nel caso di una distribuzione a posteriori unimodale e simmetrica, l’HPD coincide con l’intervallo di credibilità simmetrico.\n\n50.3.1 Interpretazione\nIl calcolo degli intervalli di credibilità—in particolare dell’intervallo di massima densità posteriore (HPD)—richiede quasi sempre l’utilizzo di software statistici specializzati. Questo perché, nei modelli bayesiani con distribuzioni posteriori articolate o che richiedono simulazioni numeriche (ad esempio tramite Markov Chain Monte Carlo), ricavare a mano i confini dell’intervallo può risultare molto laborioso.\n\n50.3.1.1 1. Incertezza nel paradigma frequentista\n\n\nParametro fisso: nel contesto frequentista, il parametro di interesse (ad esempio la media di popolazione \\(\\mu\\)) è un valore costante ma sconosciuto.\n\n\nRipetizione ipotetica: immaginiamo di ripetere all’infinito il prelievo di campioni dalla popolazione. Per ciascun campione otteniamo una media \\(\\bar{x}\\) e costruendo un intervallo di confidenza al \\(100(1-\\alpha)\\%\\) avremo che, nel lungo periodo, il \\(100(1-\\alpha)\\%\\) di questi intervalli conterrà il vero \\(\\mu\\).\n\n\nInterpretazione del singolo intervallo: per un singolo intervallo calcolato, la probabilità che contenga effettivamente \\(\\mu\\) è formalmente 0 o 1, perché \\(\\mu\\) non è soggetto a variabilità stocastica—siamo semplicemente ignari del suo valore reale.\n\n50.3.1.2 2. Incertezza nel paradigma bayesiano\n\n\nParametro come variabile aleatoria: qui \\(\\mu\\) non è più un valore fisso, ma possiede una distribuzione di probabilità che riflette sia l’informazione a priori sia quella fornita dai dati osservati.\n\n\nCampionamento dalla distribuzione a posteriori: grazie a tecniche di simulazione (ad es. MCMC), otteniamo un insieme di possibili valori di \\(\\mu\\) che segue la distribuzione posteriore.\n\n\nCostruzione diretta dell’intervallo: scegliendo i quantili al \\(2.5\\%\\) e al \\(97.5\\%\\) di questa distribuzione, otteniamo un intervallo di credibilità al 95%. In termini intuitivi, possiamo affermare che «c’è una probabilità del 95% che \\(\\mu\\) cada all’interno di questo intervallo, dati i dati e le ipotesi a priori».\n\n50.3.1.3 3. Confronto e considerazioni\n\n\nFrequentista: l’intervallo di confidenza è un costrutto legato alla frequenza di lungo periodo di un procedimento ipotetico di campionamento.\n\n\nBayesiano: l’intervallo di credibilità fornisce una misura puntuale dell’incertezza sul parametro, direttamente comprensibile come probabilità condizionata sui dati osservati.\n\n\nIntuizione: per molti, l’interpretazione bayesiana risulta più aderente al senso comune, perché traduce immediatamente il grado di fiducia che possiamo riporre nei valori ipotizzati per il parametro.\n\nIn sintesi, mentre la teoria frequentista quantifica l’affidabilità del metodo di stima nel lungo periodo, l’approccio bayesiano esprime senza ambiguità la probabilità attuale che il parametro si trovi in un certo intervallo, alla luce delle evidenze e delle conoscenze pregresse.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_summary_posterior.html#verifica-di-ipotesi-bayesiana",
    "href": "chapters/bayesian_inference/09_summary_posterior.html#verifica-di-ipotesi-bayesiana",
    "title": "50  Sintesi a posteriori",
    "section": "\n50.4 Verifica di ipotesi bayesiana",
    "text": "50.4 Verifica di ipotesi bayesiana\nL’inferenza bayesiana può essere applicata anche nel contesto della verifica di ipotesi, in un approccio noto come verifica di ipotesi bayesiana. In questo tipo di inferenza, l’obiettivo è valutare la plausibilità che un parametro \\(\\theta\\) assuma valori all’interno di un determinato intervallo. Ad esempio, possiamo voler sapere quanto è probabile che \\(\\theta\\) sia maggiore di 0.5 o che rientri in un intervallo specifico, come [0.5, 1.0].\nIn questo approccio, si calcola la probabilità a posteriori che \\(\\theta\\) si trovi all’interno dell’intervallo di interesse. Questa probabilità viene ottenuta integrando la distribuzione a posteriori su tale intervallo. Quindi, invece di rifiutare o accettare un’ipotesi come nel test di ipotesi frequentista, la verifica di ipotesi bayesiana fornisce una misura diretta della probabilità che un parametro rientri in un intervallo specifico, dato l’evidenza osservata e le informazioni a priori.\nIn altre parole, questo approccio consente di quantificare la nostra incertezza rispetto all’affermazione che \\(\\theta\\) rientri in un certo intervallo, fornendo una probabilità che rappresenta direttamente la plausibilità di quell’ipotesi.\n\nEsempio 50.1 Per illustrare l’approccio bayesiano, consideriamo i dati relativi ai punteggi del BDI-II (Beck Depression Inventory - Second Edition) di 30 soggetti clinici, come riportato nello studio condotto da Zetsche et al. (2019). Il BDI-II è uno strumento per valutare la gravità dei sintomi depressivi.\nI punteggi del BDI-II per i 30 soggetti sono:\n\n# Dati del BDI-II\nbdi &lt;- c(\n  26, 35, 30, 25, 44, 30, 33, 43, 22, 43, \n  24, 19, 39, 31, 25, 28, 35, 30, 26, 31, \n  41, 36, 26, 35, 33, 28, 27, 34, 27, 22\n)\nbdi\n#&gt;  [1] 26 35 30 25 44 30 33 43 22 43 24 19 39 31 25 28 35 30 26 31 41 36 26 35\n#&gt; [25] 33 28 27 34 27 22\n\nUn punteggio BDI-II \\(\\geq 30\\) indica un livello grave di depressione. Nel nostro campione, 17 pazienti su 30 manifestano un livello grave:\n\n# Conteggio di depressione grave\nsum(bdi &gt;= 30)\n#&gt; [1] 17\n\nStima della distribuzione a posteriori.\nSupponiamo di voler stimare la probabilità \\(\\theta\\) di depressione grave nei pazienti clinici utilizzando una distribuzione a priori \\(Beta(8, 2)\\). I dati possono essere visti come una sequenza di prove Bernoulliane indipendenti, dove la presenza di depressione grave è un “successo”. La verosimiglianza è quindi binomiale con parametri \\(n = 30\\) e \\(y = 17\\).\nCon una distribuzione a priori \\(Beta(8, 2)\\), la distribuzione a posteriori di \\(\\theta\\) sarà:\n\\[\n\\text{Beta}(\\alpha = 8 + 17, \\beta = 2 + 30 - 17) = \\text{Beta}(25, 15).\n\\]\nTracciamo la distribuzione a posteriori.\n\n# Parametri della distribuzione Beta\nalpha &lt;- 25\nbeta &lt;- 15\n\n# Calcolo della densità per valori di theta\ntheta &lt;- seq(0, 1, length.out = 200)\nposterior_density &lt;- dbeta(theta, alpha, beta)\n\n# Grafico della distribuzione a posteriori\nggplot(data = data.frame(theta, posterior_density), aes(x = theta, y = posterior_density)) +\n  geom_line() +\n  labs(\n    title = \"Distribuzione a Posteriori Beta(25, 15)\",\n    x = expression(theta),\n    y = \"Densità di probabilità\"\n  ) \n\n\n\n\n\n\n\nStime puntuali.\n\n\nMedia a Posteriori\nLa media della distribuzione a posteriori è calcolata come:\n\n\\[\n\\mathbb{E}(\\theta | y = 17) = \\frac{\\alpha}{\\alpha + \\beta} = \\frac{25}{25 + 15} = 0.625.\n\\]\nIn R:\n\n# Calcolo della media a posteriori\nposterior_mean &lt;- alpha / (alpha + beta)\nposterior_mean\n#&gt; [1] 0.625\n\n\n\nModa a Posteriori (MAP)\nLa moda della distribuzione a posteriori è:\n\n\\[\nMo(\\theta | y = 17) = \\frac{\\alpha - 1}{\\alpha + \\beta - 2} = \\frac{25 - 1}{25 + 15 - 2} = 0.6316.\n\\]\nIn R:\n\n# Calcolo della moda a posteriori\nposterior_mode &lt;- (alpha - 1) / (alpha + beta - 2)\nposterior_mode\n#&gt; [1] 0.6316\n\n\n\nMediana a Posteriori\nLa mediana si ottiene utilizzando la funzione di distribuzione cumulativa inversa:\n\n\n# Calcolo della mediana a posteriori\nposterior_median &lt;- qbeta(0.5, alpha, beta)\nposterior_median\n#&gt; [1] 0.6271\n\nIntervallo di credibilità.\n\nIntervallo di credibilità simmetrico.\n\nL’intervallo di credibilità simmetrico al 94% è dato dai percentili 3% e 97%:\n\n# Intervallo di credibilità simmetrico al 94%\ncred_interval &lt;- qbeta(c(0.03, 0.97), alpha, beta)\ncred_interval\n#&gt; [1] 0.4781 0.7613\n\nPossiamo interpretare questo intervallo come segue: c’è una certezza soggettiva del 94% che \\(\\theta\\) sia compreso tra 0.478 e 0.761.\nVerifica di ipotesi bayesiana.\nInfine, calcoliamo la probabilità che \\(\\theta &gt; 0.5\\):\n\\[\nP(\\theta &gt; 0.5 | y = 17) = \\int_{0.5}^1 f(\\theta | y = 17) d\\theta.\n\\]\nIn R:\n\n# Probabilità P(theta &gt; 0.5)\nprob_theta_greater_0_5 &lt;- pbeta(0.5, alpha, beta, lower.tail = FALSE)\nprob_theta_greater_0_5\n#&gt; [1] 0.9459\n\nIn conclusione, utilizzando un approccio bayesiano, abbiamo stimato la distribuzione a posteriori di \\(\\theta\\), ottenuto stime puntuali e costruito intervalli di credibilità. Abbiamo inoltre calcolato la probabilità che \\(\\theta\\) superi una soglia specifica, mostrando la flessibilità e l’interpretabilità delle analisi bayesiane.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_summary_posterior.html#sintesi-della-distribuzione-a-posteriori-questioni-multivariate",
    "href": "chapters/bayesian_inference/09_summary_posterior.html#sintesi-della-distribuzione-a-posteriori-questioni-multivariate",
    "title": "50  Sintesi a posteriori",
    "section": "\n50.5 Sintesi della distribuzione a posteriori: questioni multivariate",
    "text": "50.5 Sintesi della distribuzione a posteriori: questioni multivariate\nQuando si affronta un’analisi bayesiana con più parametri, la complessità aumenta. Le principali difficoltà riguardano le interazioni tra i parametri e il modo in cui queste influenzano le distribuzioni marginali. Questi fattori possono complicare notevolmente la sintesi della distribuzione a posteriori e, se non considerati attentamente, possono portare a interpretazioni errate.\n\n50.5.1 Correlazioni nascoste e distribuzioni marginali\nUn problema comune nelle analisi con più parametri è rappresentato dalle correlazioni tra i parametri. Le distribuzioni marginali a posteriori, spesso riportate nei riassunti statistici, possono essere molto fuorvianti se considerate isolatamente. Quando i parametri sono fortemente correlati, le distribuzioni marginali possono apparire piatte o poco informative, inducendo a pensare che non ci sia molta informazione nella verosimiglianza.\nTuttavia, le correlazioni tra parametri possono restringere notevolmente lo spazio delle combinazioni plausibili, escludendo vaste aree dello spazio dei parametri. Questo significa che, nonostante le marginali possano sembrare non informative, l’analisi congiunta dei parametri può rivelare una struttura sottostante che riduce l’incertezza su specifiche combinazioni. Pertanto, è essenziale esaminare le correlazioni congiunte tra i parametri per ottenere una visione più completa dell’incertezza.\nCon un numero maggiore di parametri, anche i grafici di correlazione bidimensionali possono diventare limitati, poiché potrebbero esistere correlazioni di ordine superiore che non emergono in rappresentazioni a due dimensioni.\n\n50.5.2 Correlazioni non lineari\nUn’altra difficoltà significativa riguarda le correlazioni non lineari tra i parametri. Quando queste correlazioni sono presenti, il massimo delle distribuzioni marginali non coincide necessariamente con il massimo della distribuzione congiunta. Per esempio, se due parametri presentano una correlazione complessa, come una forma a “banana”, il massimo delle distribuzioni marginali potrebbe trovarsi in una posizione diversa rispetto al massimo globale della distribuzione congiunta.\nQuesto fenomeno rende più difficile sintetizzare correttamente la distribuzione a posteriori. In tali casi, la stima del massimo a posteriori (MAP) o altri riassunti, come gli intervalli di credibilità (CI) o gli intervalli di massima densità a posteriori (HPD), calcolati sulle marginali, potrebbero essere fuorvianti. Quando la distribuzione a posteriori è asimmetrica nello spazio multivariato, le distribuzioni marginali non catturano adeguatamente le relazioni tra i parametri. Questa è una fonte comune di confusione, poiché si tende a sottovalutare l’importanza della struttura multivariata nella distribuzione a posteriori.\n\n50.5.3 Strategie per affrontare queste sfide\n\n\nConfronto tra distribuzioni predittive:\n\nConfrontare la distribuzione predittiva a priori con quella a posteriori offre una visione più completa della riduzione dell’incertezza.\nQuesto approccio è particolarmente utile in presenza di parametri multipli e correlazioni complesse, poiché la distribuzione predittiva a posteriori incorpora le interazioni tra i parametri, fornendo una rappresentazione più accurata della plausibilità dei diversi valori parametrici.\n\n\n\nAnalisi congiunta:\n\nEsaminare le distribuzioni congiunte dei parametri, oltre alle distribuzioni marginali.\nUtilizzare grafici di dispersione bivariati o multivariati per visualizzare le relazioni tra i parametri.\nTecniche avanzate di visualizzazione, come i pair plots o le heatmap, possono essere utili per esplorare relazioni in spazi ad alta dimensionalità.\n\n\n\nMisure di dipendenza:\n\nUtilizzare misure di dipendenza non lineare, come la correlazione di Spearman o l’informazione mutua, che possono catturare relazioni complesse che le misure lineari tradizionali potrebbero non rilevare.\n\n\n\nAnalisi di sensibilità:\n\nCondurre un’analisi di sensibilità per valutare come i cambiamenti in un parametro influenzano gli altri parametri e le previsioni del modello. Questo permette di capire meglio le relazioni tra i parametri e il loro impatto sulle inferenze.\n\n\n\nTecniche di riduzione della dimensionalità:\n\nQuando ci sono molti parametri, l’uso di metodi come l’analisi delle componenti principali (PCA) può aiutare a identificare strutture latenti e ridurre la complessità del problema, facilitando l’interpretazione dei risultati.\n\n\n\nIn sintesi, l’analisi multivariata in un contesto bayesiano richiede particolare attenzione nella sintesi delle distribuzioni a posteriori. Le distribuzioni marginali possono fornire informazioni utili, ma spesso nascondono importanti correlazioni e strutture di dipendenza tra i parametri. Un’analisi completa dovrebbe combinare l’esame delle marginali con una valutazione attenta delle relazioni congiunte tra i parametri, utilizzando tecniche di visualizzazione e misure di dipendenza adeguate. Questo approccio integrato permette di comprendere più a fondo la distribuzione a posteriori e di trarre inferenze più robuste e accurate.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_summary_posterior.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/09_summary_posterior.html#riflessioni-conclusive",
    "title": "50  Sintesi a posteriori",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn conclusione, la distribuzione a posteriori rappresenta la nostra conoscenza aggiornata sui parametri sconosciuti. L’impiego delle statistiche descrittive e l’analisi degli intervalli di credibilità contribuiscono a tracciare un quadro completo della distribuzione a posteriori e delle nostre inferenze riguardo al parametro di interesse.\nLe stime puntuali, ottenute attraverso statistiche descrittive come media, mediana o moda a posteriori, offrono una singola valutazione numerica del parametro ignoto. Gli intervalli di credibilità forniscono un intervallo di valori all’interno del quale si ritiene, con un certo grado di probabilità soggettiva, che il parametro incognito possa rientrare. Questi intervalli quantificano l’incertezza associata al parametro e consentono di esprimere il livello di fiducia soggettiva riguardo ai possibili valori del parametro dopo l’analisi dei dati. Abbiamo inoltre esaminato il concetto di test di ipotesi bayesiano, il quale può essere condotto agevolmente calcolando l’area appropriata sotto la distribuzione a posteriori, in accordo con l’ipotesi in questione.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_summary_posterior.html#esercizi",
    "href": "chapters/bayesian_inference/09_summary_posterior.html#esercizi",
    "title": "50  Sintesi a posteriori",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n1. Quali sono le principali statistiche utilizzate per la stima puntuale di un parametro nella distribuzione a posteriori?\n\nSpiega le differenze tra moda (MAP), media a posteriori e mediana.\nIn quali contesti è preferibile utilizzare una di queste statistiche rispetto alle altre?\n\n2. Qual è la differenza tra un intervallo di credibilità bayesiano e un intervallo di confidenza frequentista?\n\nSpiega le differenze concettuali tra i due approcci.\nQuale dei due è più intuitivo in termini di incertezza sui parametri?\n\n3. Cos’è un intervallo di massima densità posteriore (HPD) e in cosa si differenzia dall’intervallo di credibilità simmetrico?\n\nSpiega il concetto di HPD e perché è più informativo in alcuni casi.\nIn quali situazioni l’HPD è preferibile rispetto all’intervallo di credibilità simmetrico?\n\n4. Quali sono le problematiche associate alla moda (MAP) come stima puntuale?\n\nPerché il MAP può essere meno affidabile rispetto ad altre statistiche?\nQuali problemi si possono incontrare nei modelli bayesiani complessi?\n\n5. In che modo la sintesi della distribuzione a posteriori cambia nel caso di più parametri incogniti?\n\nQuali sono le principali difficoltà nell’interpretare la distribuzione congiunta di più parametri?\nCome si possono visualizzare e sintetizzare distribuzioni posteriori multivariate?\n\nDomande applicative in R\nPer queste domande, usa il dataset basato sulla Satisfaction with Life Scale (SWLS), supponendo che i dati seguano una distribuzione normale.\n1. Calcola la media, la mediana e la moda a posteriori della distribuzione della media SWLS, assumendo una distribuzione a priori gaussiana molto diffusa. - Usa il metodo delle distribuzioni coniugate per ottenere la distribuzione a posteriori.\n2. Costruisci un intervallo di credibilità simmetrico al 94% per la media SWLS.\n\nUsa la distribuzione normale a posteriori per calcolare l’intervallo.\n\n3. Visualizza la distribuzione a posteriori della media SWLS con un grafico di densità.\n\nGenera un campione dalla distribuzione a posteriori e rappresentalo con ggplot2.\n\n4. Confronta l’intervallo di credibilità simmetrico con l’intervallo di massima densità posteriore (HPD).\n\nUsa la funzione hdi() del pacchetto bayestestR per calcolare l’HPD.\n\n5. Calcola la probabilità a posteriori che la media SWLS sia minore di 23.\n\nUsa la distribuzione a posteriori per calcolare questa probabilità.\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n1. Quali sono le principali statistiche utilizzate per la stima puntuale di un parametro nella distribuzione a posteriori?\nLe tre principali statistiche usate per ottenere una stima puntuale del parametro \\(\\theta\\) nella distribuzione a posteriori sono:\n\n\nModa (Massimo a Posteriori, MAP)\n\nÈ il valore di \\(\\theta\\) che massimizza la distribuzione a posteriori \\(p(\\theta \\mid y)\\).\n\nSe la distribuzione è unimodale e simmetrica, il MAP coincide con la media a posteriori.\n\nIl MAP è spesso simile alla stima di massima verosimiglianza (MLE) quando il prior è uniforme.\n\n\n\nMedia a Posteriori\n\nÈ il valore atteso della distribuzione a posteriori:\\[\nE(\\theta \\mid y) = \\int \\theta \\, p(\\theta \\mid y) \\, d\\theta\n\\]\n\nÈ la stima più utile quando si vuole minimizzare l’errore quadratico medio (MSE).\n\nRisente dell’eventuale asimmetria della distribuzione, spostandosi verso le code.\n\n\n\nMediana a Posteriori\n\nÈ il valore che divide la distribuzione a posteriori in due parti uguali:\\[\nP(\\theta \\leq \\theta_{\\text{mediana}} \\mid y) = 0.5\n\\]\n\nÈ più robusta agli outlier rispetto alla media ed è utile quando la distribuzione è fortemente asimmetrica.\n\n\n\n💡 Quando usarle? - Se la distribuzione è simmetrica, tutte e tre le statistiche coincidono. - Se la distribuzione è asimmetrica, la mediana è più robusta, la media può essere influenzata dalle code e il MAP è utile se si vuole un valore più probabile.\n2. Qual è la differenza tra un intervallo di credibilità bayesiano e un intervallo di confidenza frequentista?\n\n\n\n\n\n\n\nCaratteristica\nIntervallo di Credibilità (Bayesiano)\nIntervallo di Confidenza (Frequentista)\n\n\n\nSignificato\nEsprime la probabilità che il parametro sia nell’intervallo, dati i dati osservati.\nÈ una proprietà di un metodo di campionamento: se si ripetesse l’esperimento infinite volte, il \\((1 - \\alpha)100\\%\\) degli intervalli conterrebbe il vero valore del parametro.\n\n\nApproccio\nAssume che il parametro sia una variabile casuale con una distribuzione di probabilità.\nAssume che il parametro sia fisso e sconosciuto, mentre i dati sono casuali.\n\n\nInterpretazione\n“C’è il 95% di probabilità che il parametro sia tra questi valori.”\n“Se ripetessimo l’esperimento molte volte, il 95% degli intervalli conterrebbe il vero parametro.”\n\n\n\n💡 Differenza fondamentale:\n\nL’intervallo di credibilità è probabilistico e più intuitivo: si può direttamente dire che il parametro ha il 95% di probabilità di trovarsi nell’intervallo.\n\nL’intervallo di confidenza è basato sulla ripetizione ipotetica dell’esperimento e non può essere interpretato in termini probabilistici sul singolo intervallo.\n\n3. Cos’è un intervallo di massima densità posteriore (HPD) e in cosa si differenzia dall’intervallo di credibilità simmetrico?\nL’intervallo di massima densità posteriore (HPD) è l’intervallo più stretto che contiene una percentuale fissata (es. 94%) della distribuzione a posteriori. Si distingue dall’intervallo di credibilità simmetrico perché:\n\n\n\n\n\n\n\nCaratteristica\nIntervallo HPD\nIntervallo di Credibilità Simmetrico\n\n\n\nDefinizione\nContiene il \\((1 - \\alpha)100\\%\\) della probabilità a posteriori, minimizzando la lunghezza dell’intervallo.\nÈ centrato attorno alla mediana e copre una frazione fissa della distribuzione.\n\n\nForma\nPuò essere asimmetrico e discontinuo se la distribuzione è multimodale.\nÈ sempre simmetrico.\n\n\nVantaggio\nÈ più informativo se la distribuzione è asimmetrica o multimodale.\nÈ più facile da calcolare, specialmente per distribuzioni unimodali.\n\n\n\n💡 Quando usarli?\n\nSe la distribuzione è simmetrica, entrambi gli intervalli danno risultati simili.\n\nSe la distribuzione è asimmetrica o multimodale, l’HPD è più informativo.\n\n4. Quali sono le problematiche associate alla moda (MAP) come stima puntuale?\nSebbene il MAP sia un concetto intuitivo (il valore più probabile della distribuzione a posteriori), presenta alcune limitazioni:\n\n\nDifficoltà computazionale con MCMC\n\nCon metodi di campionamento come Markov Chain Monte Carlo (MCMC), trovare il massimo della distribuzione a posteriori è difficile perché la funzione viene stimata in modo discreto.\nSpesso si preferisce stimare media o mediana, più facili da calcolare con MCMC.\n\n\n\nSensibilità ai dati e al prior\n\nIl MAP dipende fortemente dal prior scelto.\nSe il prior è informativo, il MAP può spostarsi troppo rispetto ai dati.\n\n\n\nProblemi con distribuzioni multimodali\n\nSe la distribuzione a posteriori ha più di un massimo (moda), il MAP potrebbe non essere una buona rappresentazione della distribuzione.\n\n\n\n💡 Quando evitarlo?\n- Se la distribuzione a posteriori è asimmetrica o multimodale. - Se si usa un metodo MCMC, dove la media o la mediana sono più semplici da stimare.\n5. In che modo la sintesi della distribuzione a posteriori cambia nel caso di più parametri incogniti?\nQuando l’inferenza bayesiana coinvolge più parametri (es. \\(\\mu\\) e \\(\\sigma\\)), l’analisi diventa più complessa per diversi motivi:\n\n\nInterazioni tra parametri\n\nI parametri spesso non sono indipendenti: la distribuzione a posteriori congiunta può mostrare correlazioni che non emergono dalle distribuzioni marginali.\n\n\n\nDifficoltà di visualizzazione\n\nPer un parametro si usa un istogramma o una funzione di densità.\nPer due parametri si usa un contour plot o un grafico 3D.\nCon più di due parametri, si ricorre a pair plots o matrici di correlazione.\n\n\n\nStimare margine e congiunta\n\nLa distribuzione marginale di un parametro si ottiene integrando la distribuzione congiunta rispetto agli altri parametri: \\[\np(\\theta_1) = \\int p(\\theta_1, \\theta_2) d\\theta_2\n\\]\n\nSe i parametri sono fortemente correlati, le marginali possono nascondere informazioni importanti.\n\n\n\nRischio di correlazioni non lineari\n\nLe correlazioni non lineari tra i parametri possono portare a distribuzioni con forme complesse (es. a banana), rendendo difficile la sintesi con MAP o media.\n\n\n\n💡 Strategie per affrontare il problema:\n- Visualizzare le correlazioni tra i parametri con scatter plot o heatmap.\n- Usare tecniche di riduzione della dimensionalità come PCA (Analisi delle Componenti Principali).\n- Utilizzare il MCMC per campionare direttamente dalla distribuzione congiunta.\nEsercizio in R con i dati SWLS\nNell’esercizio, usa i dati della SWLS che sono stati raccolti. Qui useremo i dati seguenti:\nswls_data &lt;- data.frame(\n  soddisfazione = c(4.2, 5.1, 4.7, 4.3, 5.5, 4.9, 4.8, 5.0, 4.6, 4.4)\n)\n1. Calcola la media, la mediana e la moda a posteriori della distribuzione della media SWLS, assumendo una distribuzione a priori gaussiana molto diffusa.\n\nUsa il metodo delle distribuzioni coniugate per ottenere la distribuzione a posteriori.\n\nlibrary(tibble)\n\n# Dati\nn &lt;- nrow(swls_data)\nmean_x &lt;- mean(swls_data$soddisfazione)\nsigma &lt;- 1  # Deviazione standard nota\n\n# Prior diffuso\nmu_prior &lt;- 4.5    \nsigma_prior &lt;- 10  \n\n# Media a posteriori\nmu_post &lt;- (sigma_prior^2 * mean_x + sigma^2 * n * mu_prior) / (sigma_prior^2 + sigma^2 * n)\n\n# Deviazione standard a posteriori\nsigma_post &lt;- sqrt((sigma_prior^2 * sigma^2) / (sigma_prior^2 + sigma^2 * n))\n\n# Moda (MAP)\nposterior_mode &lt;- mu_post  # Per una distribuzione normale, MAP coincide con la media\n\n# Mediana (simile alla media in una distribuzione normale)\nposterior_median &lt;- mu_post\n\ntibble(\"Media a Posteriori\" = mu_post,\n       \"Moda (MAP)\" = posterior_mode,\n       \"Mediana\" = posterior_median)\n2. Costruisci un intervallo di credibilità simmetrico al 94% per la media SWLS.\n\nUsa la distribuzione normale a posteriori per calcolare l’intervallo.\n\ncred_interval &lt;- qnorm(c(0.03, 0.97), mean = mu_post, sd = sigma_post)\ncred_interval\n3. Visualizza la distribuzione a posteriori della media SWLS con un grafico di densità.\n\nGenera un campione dalla distribuzione a posteriori e rappresentalo con ggplot2.\n\nlibrary(ggplot2)\n\n# Campionamento dalla distribuzione a posteriori\nset.seed(123)\nsamples &lt;- rnorm(1000, mean = mu_post, sd = sigma_post)\n\n# Creazione del dataframe\nsamples_df &lt;- tibble(media_campionata = samples)\n\n# Grafico della distribuzione a posteriori\nggplot(samples_df, aes(x = media_campionata)) +\n  geom_density(fill = \"blue\", alpha = 0.5) +\n  labs(title = \"Distribuzione a Posteriori della Media SWLS\",\n       x = \"Media\", y = \"Densità\")\n4. Confronta l’intervallo di credibilità simmetrico con l’intervallo di massima densità posteriore (HPD).\n\nUsa la funzione hdi() del pacchetto bayestestR per calcolare l’HPD.\n\nlibrary(bayestestR)\n\n# Calcolo intervallo HPD al 94%\nhpd_interval &lt;- hdi(samples, ci = 0.94)\nhpd_interval\n5. Calcola la probabilità a posteriori che la media SWLS sia minore di 23 – per fare un esempio, qui caloleremo per i dati simulati la probabilità a posteriori per la media SWLS maggiore di 4.7.\n\nUsa la distribuzione a posteriori per calcolare questa probabilità.\n\nprob_greater_4_7 &lt;- 1 - pnorm(4.7, mean = mu_post, sd = sigma_post)\nprob_greater_4_7",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_summary_posterior.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/09_summary_posterior.html#informazioni-sullambiente-di-sviluppo",
    "title": "50  Sintesi a posteriori",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.18.0           pillar_1.11.0         tinytable_0.11.0     \n#&gt;  [4] conflicted_1.2.0      patchwork_1.3.1       ggdist_3.3.3         \n#&gt;  [7] tidybayes_3.0.7       bayesplot_1.13.0      ggplot2_3.5.2        \n#&gt; [10] reliabilitydiag_0.2.1 priorsense_1.1.0      posterior_1.6.1      \n#&gt; [13] loo_2.8.0             rstan_2.32.7          StanHeaders_2.32.10  \n#&gt; [16] brms_2.22.0           Rcpp_1.1.0            janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] Rdpack_2.6.4         gridExtra_2.3        inline_0.3.21       \n#&gt;  [4] sandwich_3.1-1       rlang_1.1.6          magrittr_2.0.3      \n#&gt;  [7] multcomp_1.4-28      snakecase_0.11.1     compiler_4.5.1      \n#&gt; [10] vctrs_0.6.5          stringr_1.5.1        pkgconfig_2.0.3     \n#&gt; [13] shape_1.4.6.1        arrayhelpers_1.1-0   fastmap_1.2.0       \n#&gt; [16] backports_1.5.0      labeling_0.4.3       rmarkdown_2.29      \n#&gt; [19] nloptr_2.2.1         purrr_1.1.0          xfun_0.52           \n#&gt; [22] glmnet_4.1-10        jomo_2.7-6           cachem_1.1.0        \n#&gt; [25] jsonlite_2.0.0       pan_1.9              broom_1.0.9         \n#&gt; [28] parallel_4.5.1       R6_2.6.1             stringi_1.8.7       \n#&gt; [31] RColorBrewer_1.1-3   rpart_4.1.24         boot_1.3-31         \n#&gt; [34] lubridate_1.9.4      estimability_1.5.1   iterators_1.0.14    \n#&gt; [37] knitr_1.50           zoo_1.8-14           pacman_0.5.1        \n#&gt; [40] nnet_7.3-20          Matrix_1.7-3         splines_4.5.1       \n#&gt; [43] timechange_0.3.0     tidyselect_1.2.1     abind_1.4-8         \n#&gt; [46] codetools_0.2-20     curl_6.4.0           pkgbuild_1.4.8      \n#&gt; [49] lattice_0.22-7       withr_3.0.2          bridgesampling_1.1-2\n#&gt; [52] coda_0.19-4.1        evaluate_1.0.4       survival_3.8-3      \n#&gt; [55] RcppParallel_5.1.10  tensorA_0.36.2.1     checkmate_2.3.2     \n#&gt; [58] foreach_1.5.2        stats4_4.5.1         reformulas_0.4.1    \n#&gt; [61] distributional_0.5.0 generics_0.1.4       rprojroot_2.1.0     \n#&gt; [64] rstantools_2.4.0     scales_1.4.0         minqa_1.2.8         \n#&gt; [67] xtable_1.8-4         glue_1.8.0           emmeans_1.11.2      \n#&gt; [70] tools_4.5.1          lme4_1.1-37          mvtnorm_1.3-3       \n#&gt; [73] grid_4.5.1           rbibutils_2.3        QuickJSR_1.8.0      \n#&gt; [76] colorspace_2.1-1     nlme_3.1-168         cli_3.6.5           \n#&gt; [79] svUnit_1.0.6         Brobdingnag_1.2-9    V8_6.0.5            \n#&gt; [82] gtable_0.3.6         digest_0.6.37        TH.data_1.1-3       \n#&gt; [85] htmlwidgets_1.6.4    farver_2.1.2         memoise_2.0.1       \n#&gt; [88] htmltools_0.5.8.1    lifecycle_1.0.4      mitml_0.4-5         \n#&gt; [91] MASS_7.3-65",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_summary_posterior.html#bibliografia",
    "href": "chapters/bayesian_inference/09_summary_posterior.html#bibliografia",
    "title": "50  Sintesi a posteriori",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nZetsche, U., Buerkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: biased or realistic? Journal of Abnormal Psychology, 128(7), 678–688.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_balance_prior_post.html",
    "href": "chapters/bayesian_inference/10_balance_prior_post.html",
    "title": "51  L’influenza della distribuzione a priori",
    "section": "",
    "text": "Introduzione\nQuale approccio garantisce una valutazione più accurata?\nLa risposta risiede nel concetto fondamentale di probabilità a priori (o prior), che rappresenta l’insieme delle conoscenze e delle evidenze disponibili prima di raccogliere nuovi dati. Nel nostro esempio:\nNell’approccio bayesiano in psicologia clinica, il prior agisce come una lente di ingrandimento che:\nTuttavia, è cruciale bilanciare:\nQuesto meccanismo non riguarda solo i contesti clinici. Nella vita quotidiana ci affidiamo continuamente alle nostre conoscenze pregresse per interpretare nuove informazioni. Ad esempio, se in aula vediamo una persona con un libro di metodologia statistica aperto, siamo portati a pensare che sia uno studente di psicologia, basandoci sull’esperienza accumulata.\nL’obiettivo di questo capitolo è mostrare quanto la scelta delle priori sia cruciale nel processo di aggiornamento bayesiano. In particolare vedremo:",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_balance_prior_post.html#introduzione",
    "href": "chapters/bayesian_inference/10_balance_prior_post.html#introduzione",
    "title": "51  L’influenza della distribuzione a priori",
    "section": "",
    "text": "Consideriamo un tipico scenario di valutazione psicologica: uno psicologo clinico deve valutare la possibile presenza di sintomi depressivi in un paziente. Confrontiamo due approcci:\n\n\nPsicologo 1: basa la valutazione esclusivamente su un test psicometrico standardizzato; non considera altri fattori contestuali o anamnestici.\n\nPsicologo 2: integra i risultati del test con:\n\nstoria personale (eventi di vita recenti, stress cronico),\nstoria clinica (precedenti episodi depressivi),\nfattori di rischio (familiarità, comorbidità).\n\n\n\n\n\n\n\nla storia clinica del paziente (precedenti episodi, familiarità, fattori di rischio) costituisce un’informazione a priori essenziale,\nil test psicometrico fornisce invece i dati osservati (evidenza).\n\n\n\nmigliora la sensibilità diagnostica: contestualizza i punteggi dei test,\nriduce gli errori: evita interpretazioni letterali dei risultati,\npersonalizza la valutazione: adatta l’interpretazione al caso specifico.\n\n\n\nsolidità del prior: deve basarsi su evidenze scientifiche e dati anamnestici accurati,\nrigidità del prior: un preconcetto troppo forte può distorcere l’interpretazione.\n\n\n\n\ncome le priori rappresentino le nostre ipotesi iniziali sui parametri;\nquali tipologie di priori possiamo utilizzare (non informative, debolmente informative, informative);\nin che modo la loro influenza cambia al variare della quantità di dati disponibili;\nperché la scala di misura dei parametri può modificare il significato della prior.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_balance_prior_post.html#la-distribuzione-a-priori",
    "href": "chapters/bayesian_inference/10_balance_prior_post.html#la-distribuzione-a-priori",
    "title": "51  L’influenza della distribuzione a priori",
    "section": "\n51.1 La distribuzione a priori",
    "text": "51.1 La distribuzione a priori\nLa distribuzione a priori descrive ciò che sappiamo o ipotizziamo su un parametro prima di osservare i dati. In psicologia, questo significa poter integrare la conoscenza accumulata da studi precedenti o da esperienze cliniche nelle nostre analisi. Ad esempio, se stiamo studiando l’efficacia di un intervento di mindfulness sulla riduzione dell’ansia, potremmo già sapere da ricerche precedenti che l’effetto tipico si colloca intorno a una riduzione moderata dei sintomi. Una distribuzione a priori ben scelta ci consente di incorporare questa informazione e di rafforzare la plausibilità delle stime.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_balance_prior_post.html#tipologie-di-distribuzioni-a-priori",
    "href": "chapters/bayesian_inference/10_balance_prior_post.html#tipologie-di-distribuzioni-a-priori",
    "title": "51  L’influenza della distribuzione a priori",
    "section": "\n51.2 Tipologie di distribuzioni a priori",
    "text": "51.2 Tipologie di distribuzioni a priori\nLa scelta della prior (nota come elicitazione) è uno dei passaggi più delicati dell’approccio bayesiano. Non va intesa come un atto puramente soggettivo: spesso può e deve basarsi su dati empirici e conoscenze consolidate.\nSi distinguono tre categorie principali:\n\nPriori non informative. Servono quando non abbiamo conoscenze pregresse. Assegnano la stessa credibilità a tutti i valori di un parametro. Esempio: se studiamo la correlazione tra due nuove variabili psicologiche mai indagate prima, potremmo iniziare assumendo che tutte le correlazioni da –1 a +1 siano ugualmente probabili.\nPriori debolmente informative. Introducono ipotesi “di buon senso” senza imporre vincoli rigidi. Esempio: nella ricerca psicologica è improbabile che un trattamento aumenti l’ansia in modo enorme (ad es. di 10 deviazioni standard). Una prior debolmente informativa può limitare la stima a un intervallo plausibile (ad es. effetti compresi tra –2 e +2 deviazioni standard), escludendo valori assurdi.\nPriori informative. Riflettono conoscenze specifiche derivanti da studi precedenti o meta-analisi. Esempio: se una meta-analisi mostra che gli interventi di terapia cognitivo-comportamentale riducono in media i sintomi depressivi con un effetto di circa 0.5 deviazioni standard, possiamo usare questa informazione per formulare una prior centrata intorno a 0.5.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_balance_prior_post.html#limportanza-della-prior-in-base-ai-dati",
    "href": "chapters/bayesian_inference/10_balance_prior_post.html#limportanza-della-prior-in-base-ai-dati",
    "title": "51  L’influenza della distribuzione a priori",
    "section": "\n51.3 L’importanza della prior in base ai dati",
    "text": "51.3 L’importanza della prior in base ai dati\nUn principio fondamentale è che più dati osserviamo, meno la prior influisce sulle stime. Se raccogliamo centinaia di osservazioni, la verosimiglianza domina l’inferenza, rendendo meno rilevante la scelta della prior. Viceversa, con pochi dati la prior può avere un peso notevole. Questo è frequente in psicologia quando lavoriamo con campioni ridotti, ad esempio con pazienti affetti da un disturbo raro. In tali casi, una prior ben scelta può rendere le stime più stabili e coerenti.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_balance_prior_post.html#effetti-del-cambiamento-di-scala-dei-parametri",
    "href": "chapters/bayesian_inference/10_balance_prior_post.html#effetti-del-cambiamento-di-scala-dei-parametri",
    "title": "51  L’influenza della distribuzione a priori",
    "section": "\n51.5 Effetti del Cambiamento di Scala dei Parametri",
    "text": "51.5 Effetti del Cambiamento di Scala dei Parametri\nUn altro aspetto da tenere a mente è che le priors possono cambiare quando si modificano le scale dei parametri. Se un parametro viene riscalato, ad esempio passando da metri a chilometri, anche la prior deve essere riscalata di conseguenza per mantenere la coerenza dell’inferenza.\n\n51.5.1 Scala e invariabilità della scelta delle distribuzioni a priori\nLa scelta delle distribuzioni a priori non informative non è sempre banale e non può sempre essere rappresentata da una prior piatta. Per capire questo concetto, è fondamentale comprendere il ruolo della scala. Vediamo un esempio per chiarire meglio questo aspetto.\nImmaginiamo di avere un dataset che contiene la media dei diametri di alcuni alberi, e vogliamo stimare la media di questi diametri utilizzando un metodo bayesiano. Prima di osservare i dati, dobbiamo specificare la nostra distribuzione a priori, poiché non vogliamo che i dati influenzino la nostra scelta. Supponiamo di scegliere una distribuzione a priori piatta tra 1 cm e 10 cm, per evitare di introdurre bias:\n\n# Creazione di un vettore da 1 a 5\nvalori &lt;- 1:5\n# Creazione di un vettore di 5 elementi, tutti uguali a 1/5\npesoPrior &lt;- rep(1/5, 5)\n# Mostra i risultati\npesoPrior\n#&gt; [1] 0.2 0.2 0.2 0.2 0.2\n\nIn questo caso, stiamo assegnando la stessa probabilità a ciascun diametro compreso tra 1 e 10 cm, senza dare più peso a un valore rispetto a un altro. Questa sembra una scelta ragionevole e “non informativa”, poiché non stiamo preferendo nessun diametro in particolare.\nOra, supponiamo di voler modificare leggermente la nostra analisi e di misurare la grandezza degli alberi in termini di area basale (cioè la sezione trasversale dell’albero alla base), che è proporzionale al quadrato del diametro (cioè \\(x^2\\)). Poiché abbiamo già specificato la nostra distribuzione a priori in termini di diametro, dovremmo trasformare questa distribuzione in modo coerente con la nuova scala (area basale).\nIl problema che emerge è il seguente: quando riscaliamo l’asse \\(x\\) per riflettere l’area basale (cioè, passiamo da cm a cm\\(^2\\)), i valori più grandi diventano più ampi (poiché l’area cresce con il quadrato del diametro), mentre i valori più piccoli diventano più stretti. Se vogliamo mantenere la stessa distribuzione a priori in termini di probabilità, dobbiamo modificare il peso di ciascun valore.\nDi conseguenza, una distribuzione a priori che inizialmente era piatta (uguale per tutti i valori di diametro) non rimane piatta dopo la trasformazione in area basale. I valori più grandi ora hanno un peso minore, mentre i valori più piccoli hanno un peso maggiore. Questo dimostra che una distribuzione a priori non può essere piatta per tutte le possibili trasformazioni dei parametri.\n\n51.5.2 Il concetto di invariabilità della scala\nUna delle chiavi per definire correttamente le distribuzioni a priori non informative è l’invariabilità rispetto alle trasformazioni dei parametri. Se possiamo scegliere liberamente come rappresentare i parametri (ad esempio, in termini di diametro o area basale), la nostra distribuzione a priori dovrebbe essere definita in modo che sia coerente indipendentemente dalla scala scelta.\n\n51.5.3 Attenzione alle trasformazioni dei parametri\nUn secondo messaggio importante riguarda la cautela nelle trasformazioni dei parametri nell’analisi bayesiana. Quando cambiamo i parametri del nostro modello, non stiamo semplicemente osservando un singolo valore, ma una distribuzione intera. La forma di questa distribuzione può cambiare notevolmente con la trasformazione dei parametri.\nAd esempio, se si sta conducendo uno studio psicologico e si vuole misurare un parametro legato alla gravità di un disturbo (ad esempio, la gravità della depressione su una scala numerica), e poi si decide di trasformare la scala in un’unità diversa (ad esempio, un punteggio quadratico per evidenziare differenze estreme), la distribuzione a priori che sembrava ragionevole prima della trasformazione potrebbe non esserlo più dopo. Questo significa che bisogna prestare attenzione a come si scelgono le priors e come queste si comportano sotto diverse rappresentazioni del problema.\nIn conclusione, la scelta delle distribuzioni a priori non può essere fatta superficialmente. Deve essere considerata con attenzione, tenendo conto delle possibili trasformazioni dei parametri e assicurandosi che le priors siano coerenti rispetto alla scala scelta. Questo rende evidente che le priors non informative non sono sempre piatte, e la loro scelta deve tenere conto della struttura del problema e delle variabili coinvolte.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_balance_prior_post.html#scelte-predefinite-per-le-distribuzioni-a-priori-non-informative",
    "href": "chapters/bayesian_inference/10_balance_prior_post.html#scelte-predefinite-per-le-distribuzioni-a-priori-non-informative",
    "title": "51  L’influenza della distribuzione a priori",
    "section": "\n51.6 Scelte predefinite per le distribuzioni a priori non informative",
    "text": "51.6 Scelte predefinite per le distribuzioni a priori non informative\nUna delle domande più ricorrenti nell’inferenza bayesiana riguarda la scelta delle distribuzioni a priori non informative. La risposta, però, è piuttosto complessa: non esiste una soluzione generalmente accettata. Questo è particolarmente importante perché, mentre le priors informative possono essere basate su conoscenze pregresse, una prior non informativa deve essere scelta con cura per evitare di influenzare eccessivamente i risultati.\nUna delle proposte più famose, che soddisfa molte delle proprietà desiderabili, è la prior di Jeffreys, definita come:\n\\[\np(\\phi) \\propto \\sqrt{ \\det (F(\\phi)) },\n\\]\ndove \\(F(\\phi)\\) è la matrice di informazione di Fisher, che misura quanto la verosimiglianza cambia quando variano i parametri. La prior di Jeffreys ha due caratteristiche fondamentali:\n\n\nInvarianza rispetto alla riscalatura dei parametri: Ciò significa che se trasformiamo la scala del parametro, la prior si adatta automaticamente, rimanendo coerente con il problema.\n\nProporzionalità all’influenza dei parametri sulla verosimiglianza: Parametri che influenzano maggiormente la verosimiglianza hanno una prior più informativa.\n\nQuesti aspetti sembrano coprire molti dei criteri comunemente accettati per la scelta delle distribuzioni a priori non informative. Tuttavia, la prior di Jeffreys presenta alcuni problemi nei modelli multivariati e gerarchici, il che limita la sua applicabilità come soluzione universale.\n\n51.6.1 Scelte predefinite comuni per le priors non informative\nNonostante le difficoltà legate alla prior di Jeffreys, sono emerse alcune scelte predefinite comuni per le priors non informative, basate su intuizioni derivanti proprio da questa distribuzione. Di seguito sono elencate alcune di queste scelte:\n\n\nParametri di scala (es. coefficiente angolare o intercetta in una regressione):\n\nPer i parametri di scala, che influenzano l’output in modo lineare, si utilizzano comunemente priors piatte o quasi piatte. Queste possono essere distribuzioni uniformi con limiti fissati o, più comunemente, una distribuzione normale ampia.\nUn esempio di prior modificata è l’uso di una normalità centrata su un valore neutro, come 0, per ottenere l’analogo bayesiano della regressione Lasso o Ridge, che introduce una penalizzazione sui parametri (Park & Casella, 2008; Kyung et al., 2010).\n\nSe questa penalizzazione è lieve, si parla di priors debolmente regolarizzanti.\nSe è forte, si parla di priors di riduzione (shrinkage), che possono essere fisse o adattative:\n\n\nShrinkage fisso: la forza della riduzione (ad es. controllata dalla deviazione standard nella prior normale) rimane costante.\n\nShrinkage adattativo: la prior di riduzione si adatta tramite un iperparametro (hyperprior), il che consente al modello di decidere autonomamente la forza della riduzione.\n\n\n\n\n\n\n\nParametri di varianza (es. la deviazione standard in una regressione lineare):\n\nPer i parametri di varianza, si utilizzano spesso priors che decrescono all’aumentare del valore. Un esempio classico è la prior di Jeffrey’s, che per la varianza assume la forma \\(1/x\\), oppure la distribuzione inversa-gamma, molto comune per via della sua proprietà di coniugazione, che semplifica il calcolo bayesiano.\n\n\n\nIperparametri di varianza nei modelli gerarchici:\n\nNei modelli gerarchici, gli iperparametri di varianza vengono trattati con priors decrescenti come l’inversa-gamma o la distribuzione half-t (Gelman, 2006). Queste priors sono progettate per gestire la varianza tra gruppi in modo efficace.\n\n\n\nDistribuzioni binomiali:\n\nPer una distribuzione binomiale, la prior di Jeffreys corrisponde a una distribuzione Beta(1/2, 1/2), che è considerata una buona scelta predefinita non informativa. Questo tipo di prior assegna un peso equo alle possibili probabilità di successo, riflettendo una distribuzione equilibrata senza favorire un particolare risultato.\n\n\n\n51.6.2 Attenzione alle trasformazioni dei parametri\nUn aspetto importante da considerare nell’uso delle priors non informative è che la loro forma può cambiare significativamente in seguito a trasformazioni dei parametri. Per esempio, passando dalla scala lineare alla scala quadratica di un parametro, la prior può assumere una forma diversa e introdurre involontariamente un bias. Pertanto, è essenziale prestare attenzione a come i parametri sono scalati e trasformati nel modello.\n\n51.6.3 Analisi di sensibilità\nInfine, quando si è incerti sulla scelta della prior, un buon approccio consiste nel condurre un’analisi di sensibilità. Questa tecnica prevede di variare la prior e osservare come ciò influenzi i risultati. Se i risultati sono robusti rispetto a diverse scelte di prior, ciò suggerisce che la prior scelta non sta influenzando in modo eccessivo l’inferenza finale. Questo è particolarmente utile nei casi in cui si dispone di pochi dati, situazione in cui la prior può avere un impatto maggiore.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_balance_prior_post.html#priori-coniugate",
    "href": "chapters/bayesian_inference/10_balance_prior_post.html#priori-coniugate",
    "title": "51  L’influenza della distribuzione a priori",
    "section": "\n51.7 Priori coniugate",
    "text": "51.7 Priori coniugate\nUna distribuzione a priori è detta coniugata rispetto a una funzione di verosimiglianza se la distribuzione a posteriori risultante ha la stessa forma funzionale della distribuzione a priori. In altre parole, la distribuzione a priori e quella a posteriori appartengono alla stessa famiglia di distribuzioni. Questo è particolarmente utile perché, quando si usano priori coniugate, si ottiene una distribuzione a posteriori che può essere espressa in forma chiusa, rendendo possibile risolverla analiticamente.\nUn esempio tipico è quello delle funzioni di verosimiglianza appartenenti alla famiglia esponenziale, per le quali esiste sempre una distribuzione a priori coniugata. Questo è uno dei motivi per cui le distribuzioni della famiglia esponenziale sono così rilevanti: in modelli semplici, l’uso di una prior coniugata consente di ottenere una soluzione analitica per la distribuzione a posteriori, noto come modello coniugato-esponenziale.\nTradizionalmente, si preferiva specificare priori coniugate quando possibile, proprio per la semplicità analitica che garantivano. Tuttavia, l’importanza delle priors coniugate è diminuita con l’evoluzione dei metodi di campionamento. Oggi, la maggior parte dei campionatori moderni (come i metodi MCMC) non richiede più la coniugazione per funzionare in modo efficiente, e l’uso di priors non coniugate è diventato comune senza compromettere la qualità delle stime.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_balance_prior_post.html#simulazioni",
    "href": "chapters/bayesian_inference/10_balance_prior_post.html#simulazioni",
    "title": "51  L’influenza della distribuzione a priori",
    "section": "\n51.6 Simulazioni",
    "text": "51.6 Simulazioni\nPer comprendere meglio come le distribuzioni a priori influenzano le nostre conclusioni, possiamo usare delle simulazioni. La formula di Bayes\n\\[\np(\\theta \\mid y) \\propto p(\\theta) \\times p(y \\mid \\theta)\n\\]\nci dice che la distribuzione a posteriori nasce dalla combinazione di due elementi:\n\nla distribuzione a priori, cioè ciò che crediamo prima di osservare i dati;\nla verosimiglianza, cioè quanto i dati osservati sono compatibili con ciascun valore possibile del parametro \\(\\theta\\).\n\nIn pratica, se abbiamo i valori della verosimiglianza e della prior su una griglia di possibili valori di \\(\\theta\\), possiamo moltiplicarli “punto per punto” e ottenere così la distribuzione a posteriori.\n\n51.6.1 Un esempio psicologico: tassi di risposta corretta\nImmaginiamo di voler stimare la probabilità $$ che uno studente risponda correttamente a una domanda di un test di memoria. Abbiamo osservato che, su 9 domande, lo studente ha risposto correttamente a 6. Questo può essere modellato con una verosimiglianza binomiale. Ora ci chiediamo: come cambiano le nostre conclusioni se assumiamo priori differenti?\n\n51.6.2 Passo 1: definire la verosimiglianza\n\n# Dati osservati: 6 risposte corrette su 9\nsuccess &lt;- 6\ntosses &lt;- 9\n\n# Griglia di possibili valori di theta\ngrid_points &lt;- 100\np_grid &lt;- seq(0, 1, length.out = grid_points)\n\n# Verosimiglianza binomiale\nlikelihood &lt;- dbinom(success, tosses, p_grid)\n\nLa verosimiglianza indica quali valori di $$ (probabilità di risposta corretta) sono più compatibili con i dati. In questo caso, i valori intorno a 0.67 (6/9) hanno la probabilità più alta.\n\n51.6.3 Passo 2: funzione per calcolare e visualizzare la posteriori\n\ncomputePosterior &lt;- function(likelihood, prior, p_grid) {\n  # Calcolo della posteriori non normalizzata\n  unstd_posterior &lt;- likelihood * prior\n  # Normalizzazione\n  posterior &lt;- unstd_posterior / sum(unstd_posterior)\n  \n  # Preparazione dati per il grafico\n  data &lt;- tibble(\n    theta = p_grid,\n    Prior = prior,\n    Likelihood = likelihood,\n    Posterior = posterior\n  ) |&gt; \n    pivot_longer(cols = c(Prior, Likelihood, Posterior), \n                 names_to = \"distribution\", \n                 values_to = \"density\")\n  \n  # Grafico\n  g &lt;- ggplot(data, aes(x = theta, y = density, color = distribution)) +\n    geom_line(size = 1.2) +\n    facet_wrap(~distribution, scales = \"free_y\", ncol = 3) +\n    labs(\n      title = \"Distribuzioni: Prior, Likelihood, e Posterior\",\n      x = expression(theta),\n      y = \"Densità\"\n    ) +\n    theme(plot.title = element_text(hjust = 0.5),\n          legend.position = \"none\",\n          strip.text = element_text(size = 12, face = \"bold\"))\n  \n  print(g)\n  return(posterior)\n}\n\nLa funzione non solo calcola la distribuzione a posteriori, ma produce anche un grafico comparativo di prior, likelihood e posterior.\n\n51.6.4 Priore uniforme\n\nprior1 &lt;- rep(1, grid_points)\nposterior1 &lt;- computePosterior(likelihood, prior1, p_grid)\n\n\n\n\n\n\n\nCommento: la prior uniforme assegna uguale credibilità a tutti i valori di $$. Il risultato è che la posteriori coincide quasi con la verosimiglianza: senza conoscenze pregresse, sono i dati (6 risposte corrette su 9) a guidare completamente l’inferenza.\n\n51.6.5 Priore a gradino\n\nprior2 &lt;- ifelse(p_grid &gt;= 0.5, 1, 0)\nposterior2 &lt;- computePosterior(likelihood, prior2, p_grid)\n\n\n\n\n\n\n\nCommento: qui assumiamo che $$ non possa essere inferiore a 0.5 (cioè lo studente deve rispondere almeno come “a caso”). La posteriori esclude quindi qualsiasi valore sotto 0.5, anche se la verosimiglianza avrebbe assegnato loro un po’ di probabilità. Questo esempio mostra come una convinzione forte possa vincolare pesantemente le conclusioni.\n\n51.6.6 Priore esponenziale centrata su 0.5\n\nprior3 &lt;- exp(-5 * abs(p_grid - 0.5))\nposterior3 &lt;- computePosterior(likelihood, prior3, p_grid)\n\n\n\n\n\n\n\nCommento: questa prior esprime l’idea che lo studente abbia circa il 50% di probabilità di rispondere correttamente. La posteriori viene “attirata” verso 0.5, pur tenendo conto dei dati (6 su 9 ≈ 0.67). Il risultato finale è un compromesso: né tutto nei dati, né tutto nella prior.\nQuesto esercizio mostra chiaramente il ruolo delle prior:\n\ncon una prior piatta prevalgono i dati,\ncon una prior vincolante (gradino) le ipotesi iniziali dominano,\ncon una prior moderata (esponenziale) si ottiene un compromesso.\n\nIn psicologia, dove spesso i campioni sono piccoli, la scelta della prior può cambiare molto le conclusioni: un motivo in più per rendere trasparenti e motivate le ipotesi di partenza.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_balance_prior_post.html#connessione-tra-intuizioni-e-teoria",
    "href": "chapters/bayesian_inference/10_balance_prior_post.html#connessione-tra-intuizioni-e-teoria",
    "title": "51  L’influenza della distribuzione a priori",
    "section": "\n51.8 Connessione tra Intuizioni e Teoria",
    "text": "51.8 Connessione tra Intuizioni e Teoria\nL’equilibrio tra ciò che crediamo prima (la distribuzione a priori) e ciò che osserviamo dopo (i dati) non è solo una metafora utile: è una vera e propria necessità matematica. Questo diventa evidente guardando al caso della distribuzione Beta-Binomiale, uno dei modelli più semplici e didattici.\nIl valore atteso della distribuzione a posteriori può essere riscritto in questa forma:\n\\[\n\\begin{aligned}\n\\mathbb{E}_{\\text{post}}[\\theta] &= \\frac{\\alpha + y}{\\alpha + \\beta + n} \\\\[6pt]\n&= \\underbrace{\\frac{\\alpha+\\beta}{\\alpha+\\beta+n}}_{\\text{peso del priore}} \\cdot\n\\underbrace{\\frac{\\alpha}{\\alpha+\\beta}}_{\\text{media a priori}}\n\\;+\\;\n\\underbrace{\\frac{n}{\\alpha+\\beta+n}}_{\\text{peso dei dati}} \\cdot\n\\underbrace{\\frac{y}{n}}_{\\text{media osservata}} .\n\\end{aligned}\n\\]\nQuesta equazione ci mostra che il valore atteso a posteriori è sempre una media ponderata di due elementi:\n\nla media a priori (\\(\\alpha/(\\alpha+\\beta)\\)), cioè ciò che pensavamo prima di raccogliere i dati;\nla proporzione osservata (\\(y/n\\)), cioè ciò che i dati suggeriscono.\n\nI pesi che regolano il compromesso dipendono dal rapporto tra il numero di osservazioni \\(n\\) e la somma \\(\\alpha+\\beta\\) (che misura quanto “forte” è l’informazione contenuta nella prior).\n\nSe \\(n\\) è molto grande, prevalgono i dati: la posteriori riflette quasi esclusivamente le osservazioni empiriche.\nSe \\(n\\) è piccolo, prevale la prior: la stima finale risente molto delle convinzioni iniziali.\n\n\n51.8.1 Un’analogia psicologica\nPensiamo a uno psicologo che vuole stimare la probabilità che uno studente ricordi correttamente un concetto dopo una lezione.\n\nSe ha già osservato centinaia di risposte di quello studente, i dati domineranno l’inferenza, e la sua idea iniziale (la prior) conterà poco.\nSe invece ha visto solo poche risposte, tenderà ad affidarsi molto di più alle convinzioni iniziali (per esempio, che lo studente abbia in generale una buona memoria).\n\n51.8.2 Come scegliere \\(\\alpha\\) e \\(\\beta\\)\n\n\nSe vogliamo esprimere completa incertezza, possiamo usare \\(\\alpha = \\beta = 1\\), che assegna la stessa probabilità a tutti i valori possibili di \\(\\theta\\) (da 0 a 1).\nSe abbiamo informazioni pregresse (es. da studi precedenti o da esperienza clinica), scegliamo \\(\\alpha/(\\alpha+\\beta)\\) in modo che coincida con il valore atteso a priori desiderato.\nLa quantità \\(\\alpha+\\beta\\) regola invece “quanto ci crediamo”: più è grande, più dati serviranno per spostare la nostra convinzione iniziale.\n\nIn sintesi, questa formulazione mostra in modo chiaro che l’approccio bayesiano è una combinazione bilanciata tra teoria e dati. Il risultato non è mai solo la nostra ipotesi iniziale, né solo l’evidenza empirica, ma un’integrazione delle due. Questo rende l’inferenza bayesiana particolarmente adatta alle scienze psicologiche, dove spesso lavoriamo con campioni piccoli e dove le conoscenze accumulate in precedenza sono preziose per guidare l’interpretazione dei dati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_balance_prior_post.html#conflitto-tra-prior-e-verosimiglianza",
    "href": "chapters/bayesian_inference/10_balance_prior_post.html#conflitto-tra-prior-e-verosimiglianza",
    "title": "51  L’influenza della distribuzione a priori",
    "section": "\n51.9 Conflitto tra Prior e Verosimiglianza",
    "text": "51.9 Conflitto tra Prior e Verosimiglianza\nConsideriamo un esempio discusso da McElreath, che mette in luce un punto importante: anche in situazioni semplici, la combinazione tra distribuzione a priori e verosimiglianza può produrre risultati poco intuitivi.\n\nLesson: Don’t trust intuition, for even simple prior+likelihood scenarios defy it. Four examples below, each producing radically different posteriors. Can you guess what each does?\n\nNella prima figura McElreath invita a riflettere su quattro diversi casi:\n\nNella seconda figura mostra i risultati effettivi delle combinazioni di prior e likelihood:\n\nL’idea centrale è confrontare il comportamento della distribuzione normale (con code sottili) e della distribuzione di Student-t con 2 gradi di libertà (con code molto più spesse). Le code indicano quanto la distribuzione attribuisce ancora una certa plausibilità a valori estremi.\n\n\nIn Alto a Sinistra: Prior Normale, Likelihood Normale\n\ny ~ Normal(mu,1)\nmu ~ Normal(10,1)\n\nQuesto è lo scenario “classico”. La posteriori si colloca a metà strada tra prior e likelihood, bilanciando le due informazioni. L’aggiornamento è regolare e prevedibile: i dati spostano la nostra convinzione iniziale, ma senza sorprese.\n\n\nIn Alto a Destra: Prior Student, Likelihood Student (df=2)\n\ny ~ Student(2,mu,1)\nmu ~ Student(2,10,1)\n\nQui entrambe le distribuzioni hanno code spesse. Ciò significa che attribuiscono alta plausibilità anche a valori molto lontani dal centro. Il risultato è che la posteriori diventa più incerta e “larga”, con un compromesso meno definito. Non esiste un punto centrale netto, ma piuttosto una distribuzione che riflette la forte apertura a valori estremi.\n\n\nIn Basso a Sinistra: Prior Student, Likelihood Normale\n\ny ~ Normal(mu,1)\nmu ~ Student(2,10,1)\n\nIn questo caso, la likelihood normale (con code sottili) è molto rigida: penalizza i valori lontani. Il prior Student-t, invece, non è sorpreso da valori estremi. Il risultato è che la posteriori viene guidata soprattutto dalla likelihood normale, con un effetto limitato del prior.\n\n\nIn Basso a Destra: Prior Normale, Likelihood Student\n\ny ~ Student(2,mu,1)\nmu ~ Normal(10,1)\n\nQui accade l’opposto: il prior normale, con le sue code sottili, esercita un’influenza dominante. La likelihood Student-t, che accetterebbe valori estremi, viene “corretta” dal prior, che restringe la plausibilità attorno al proprio centro.\n\n\nIn sintesi, questo esercizio mostra come il comportamento della posteriori dipenda in modo cruciale dalla forma relativa di prior e likelihood. Con prior e likelihood gaussiane, l’aggiornamento è intuitivo. Appena introduciamo distribuzioni con code spesse (Student-t), la dinamica cambia: a volte prevale la prior, a volte la likelihood, e il risultato può essere molto diverso da quello che ci aspetteremmo a intuito.\nMorale: in Bayes non basta “affidarsi al buon senso”. Quando prior e likelihood hanno forme diverse, il risultato dell’aggiornamento può essere sorprendente. Per questo è sempre necessario eseguire i calcoli, non solo ragionare intuitivamente.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_balance_prior_post.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/10_balance_prior_post.html#riflessioni-conclusive",
    "title": "51  L’influenza della distribuzione a priori",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nLa scelta della distribuzione a priori è uno degli aspetti più delicati e decisivi nell’inferenza bayesiana. Con una prior non informativa, lasciamo che siano i dati a guidare le conclusioni; con una prior informativa, possiamo invece sfruttare conoscenze pregresse per affinare le stime. È utile ricordare che, quando i dati sono numerosi, la prior ha un peso minore, mentre con campioni piccoli la sua influenza diventa cruciale.\nUn punto di forza dell’approccio bayesiano, come sottolinea Johnson (2022), è che il meccanismo di aggiornamento riflette il nostro modo intuitivo di ragionare: di fronte a evidenze deboli, le credenze rimangono stabili; se le evidenze sono solide, le credenze vengono aggiornate in misura significativa. In questo senso, il metodo bayesiano formalizza in modo matematico un processo cognitivo che utilizziamo tutti i giorni. Al contrario, l’approccio frequentista ignora le conoscenze pregresse, rischiando di produrre inferenze che cambiano bruscamente senza tener conto del contesto.\nGli esempi discussi da McElreath mostrano però che non sempre l’intuizione è affidabile: nei modelli non coniugati, le interazioni tra prior e likelihood possono produrre posteriori sorprendenti. Ciò ricorda quanto il contesto e la struttura del modello siano determinanti nelle analisi bayesiane.\nUn ruolo particolarmente rilevante è svolto dalle priori debolmente informative, oggi considerate lo standard in molte applicazioni. Esse agiscono come un meccanismo di regolarizzazione: limitano l’impatto di osservazioni estreme e favoriscono inferenze più stabili, senza introdurre un pregiudizio eccessivo.\nNegli ultimi anni è cresciuto l’interesse per le priori informative, soprattutto attraverso procedure di elicitazione esperta. Si tratta di un approccio rigoroso volto a trasformare le conoscenze di ricercatori o clinici in distribuzioni utilizzabili nei modelli. In psicologia, dove spesso le basi teoriche sono incerte o i dati scarsi, questo strumento può rafforzare l’affidabilità delle analisi e ridurre l’incertezza [O’Hagan (2019)].\nIn definitiva, la scelta della prior non dovrebbe mai essere trattata come un dettaglio tecnico. Una prior “piatta” può sembrare neutra, ma raramente lo è. Le priori debolmente informative rappresentano oggi un equilibrio efficace tra prudenza e robustezza, mentre le priori informative, se costruite con protocolli accurati, aprono la strada a un’integrazione sistematica della conoscenza pregressa.\nQuesto bilanciamento tra dati nuovi e informazioni già disponibili consente di costruire modelli bayesiani più solidi, capaci di riflettere in modo realistico sia l’incertezza sia la competenza accumulata nel dominio di studio.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_balance_prior_post.html#esercizi",
    "href": "chapters/bayesian_inference/10_balance_prior_post.html#esercizi",
    "title": "51  L’influenza della distribuzione a priori",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nL’obiettivo di questo esercizio è comprendere come la distribuzione a priori influenzi la distribuzione a posteriori a seconda della grandezza del campione. Utilizzeremo dati raccolti della Satisfaction With Life Scale (SWLS), categorizzandoli in base a una soglia e analizzando la proporzione di risposte che superano tale soglia con un approccio bayesiano.\nFase 1: Raccolta e categorizzazione dei dati\n\nOgni studente utilizza i valori della scala SWLS che sono stati raccolti dal suo gruppo TPV.\nSi sceglie una soglia arbitraria (ad esempio, un punteggio superiore a 20 indica “elevata soddisfazione”).\n\nSi calcola la proporzione di persone con punteggi superiori alla soglia:\n\\[\n\\hat{p} = \\frac{k}{n}\n\\]\ndove \\(k\\) è il numero di persone con SWLS sopra la soglia e \\(n\\) è la dimensione del campione (circa 15).\n\n\nFase 2: Inferenza Bayesiana con un Prior Mediamente Informativo\n\n\nSi assume una distribuzione Beta come prior per la proporzione di persone con SWLS sopra la soglia:\n\\[\np \\sim \\text{Beta}(a, b)\n\\]\ndove \\(a = 2\\) e \\(b = 2\\), un prior mediamente informativo (distribuzione simmetrica centrata su 0.5).\n\n\nSi calcola la distribuzione a posteriori utilizzando la coniugazione della Beta con la distribuzione binomiale:\n\\[\np \\mid D \\sim \\text{Beta}(a + k, b + n - k)\n\\]\n\n\nSi calcolano:\n\n\nStima puntuale della proporzione (valore atteso della Beta a posteriori):\n\\[\nE[p \\mid D] = \\frac{a + k}{a + b + n}\n\\]\n\nIntervallo di credibilità (CI al 95%), utilizzando i quantili della distribuzione Beta a posteriori.\n\n\n\nFase 3: Analisi con un Campione Più Grande\n\nSi ripete lo stesso esercizio, ma immaginando che la stessa proporzione \\(\\hat{p}\\) provenga da un campione di n = 1000.\n\nSi calcola la nuova distribuzione a posteriori:\n\\[\np \\mid D \\sim \\text{Beta}(a + k', b + n' - k')\n\\] con \\(k' = \\hat{p} \\times 1000\\).\n\nSi ricalcolano stima puntuale e intervallo di credibilità.\n\nFase 4: Confronto e Interpretazione\n\n\nSi confrontano le due distribuzioni a posteriori:\n\nCome cambia la varianza della distribuzione a posteriori?\nCome cambia l’influenza del prior?\nQual è la differenza nella precisione della stima puntuale e dell’intervallo di credibilità?\n\n\nSi discute come, all’aumentare del campione, l’influenza della distribuzione a priori diminuisce, facendo emergere il ruolo della likelihood.\n\nConsegna: caricare su Moodle il file .qmd compilato in pdf.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_balance_prior_post.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/10_balance_prior_post.html#informazioni-sullambiente-di-sviluppo",
    "title": "51  L’influenza della distribuzione a priori",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.18.0           pillar_1.11.0         tinytable_0.11.0     \n#&gt;  [4] patchwork_1.3.1       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt;  [7] bayesplot_1.13.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [10] priorsense_1.1.0      posterior_1.6.1       loo_2.8.0            \n#&gt; [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [16] Rcpp_1.1.0            conflicted_1.2.0      janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] Rdpack_2.6.4         gridExtra_2.3        inline_0.3.21       \n#&gt;  [4] sandwich_3.1-1       rlang_1.1.6          magrittr_2.0.3      \n#&gt;  [7] multcomp_1.4-28      snakecase_0.11.1     compiler_4.5.1      \n#&gt; [10] vctrs_0.6.5          stringr_1.5.1        pkgconfig_2.0.3     \n#&gt; [13] shape_1.4.6.1        arrayhelpers_1.1-0   fastmap_1.2.0       \n#&gt; [16] backports_1.5.0      labeling_0.4.3       rmarkdown_2.29      \n#&gt; [19] nloptr_2.2.1         purrr_1.1.0          xfun_0.52           \n#&gt; [22] glmnet_4.1-10        jomo_2.7-6           cachem_1.1.0        \n#&gt; [25] jsonlite_2.0.0       pan_1.9              broom_1.0.9         \n#&gt; [28] parallel_4.5.1       R6_2.6.1             stringi_1.8.7       \n#&gt; [31] RColorBrewer_1.1-3   rpart_4.1.24         boot_1.3-31         \n#&gt; [34] lubridate_1.9.4      estimability_1.5.1   iterators_1.0.14    \n#&gt; [37] knitr_1.50           zoo_1.8-14           pacman_0.5.1        \n#&gt; [40] nnet_7.3-20          Matrix_1.7-3         splines_4.5.1       \n#&gt; [43] timechange_0.3.0     tidyselect_1.2.1     abind_1.4-8         \n#&gt; [46] codetools_0.2-20     curl_6.4.0           pkgbuild_1.4.8      \n#&gt; [49] lattice_0.22-7       withr_3.0.2          bridgesampling_1.1-2\n#&gt; [52] coda_0.19-4.1        evaluate_1.0.4       survival_3.8-3      \n#&gt; [55] RcppParallel_5.1.10  tensorA_0.36.2.1     checkmate_2.3.2     \n#&gt; [58] foreach_1.5.2        stats4_4.5.1         reformulas_0.4.1    \n#&gt; [61] distributional_0.5.0 generics_0.1.4       rprojroot_2.1.0     \n#&gt; [64] rstantools_2.4.0     scales_1.4.0         minqa_1.2.8         \n#&gt; [67] xtable_1.8-4         glue_1.8.0           emmeans_1.11.2      \n#&gt; [70] tools_4.5.1          lme4_1.1-37          mvtnorm_1.3-3       \n#&gt; [73] grid_4.5.1           rbibutils_2.3        QuickJSR_1.8.0      \n#&gt; [76] colorspace_2.1-1     nlme_3.1-168         cli_3.6.5           \n#&gt; [79] svUnit_1.0.6         Brobdingnag_1.2-9    V8_6.0.5            \n#&gt; [82] gtable_0.3.6         digest_0.6.37        TH.data_1.1-3       \n#&gt; [85] htmlwidgets_1.6.4    farver_2.1.2         memoise_2.0.1       \n#&gt; [88] htmltools_0.5.8.1    lifecycle_1.0.4      mitml_0.4-5         \n#&gt; [91] MASS_7.3-65",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_balance_prior_post.html#bibliografia",
    "href": "chapters/bayesian_inference/10_balance_prior_post.html#bibliografia",
    "title": "51  L’influenza della distribuzione a priori",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nO’Hagan, A. (2019). Expert knowledge elicitation: subjective but scientific. The American Statistician, 73(sup1), 69–81.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_gamma_poisson_model.html",
    "href": "chapters/bayesian_inference/11_gamma_poisson_model.html",
    "title": "52  Modello coniugato Gamma-Poisson",
    "section": "",
    "text": "Introduzione\nQueste variabili hanno una caratteristica importante: possono assumere solo valori interi non negativi (0, 1, 2, …). Non possiamo trattarle come se fossero variabili continue, perché la loro natura discreta richiede modelli statistici specifici. Il modello di riferimento per questo tipo di dati è la distribuzione di Poisson, che descrive la probabilità di osservare un certo numero di eventi in un intervallo di tempo (o di spazio), dato un tasso medio di incidenza.\nIl parametro centrale della distribuzione di Poisson è \\(\\lambda\\), che rappresenta proprio il numero medio di eventi per unità di misura (ad esempio, la media di compulsioni per ora, oppure la media di parole per frase). Stimare questo parametro significa, in pratica, descrivere l’intensità con cui l’evento che ci interessa tende a verificarsi.\nIn questo capitolo ci proponiamo due obiettivi:\nQuesto doppio percorso è molto utile per chi studia: ci consente infatti di verificare che i metodi numerici funzionano correttamente in un caso semplice, dove conosciamo già la soluzione analitica, e ci prepara ad affrontare situazioni più complesse in cui la soluzione chiusa non esiste e la simulazione diventa indispensabile.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_gamma_poisson_model.html#distribuzione-di-poisson",
    "href": "chapters/bayesian_inference/11_gamma_poisson_model.html#distribuzione-di-poisson",
    "title": "52  Modello coniugato Gamma-Poisson",
    "section": "\n52.1 Distribuzione di Poisson",
    "text": "52.1 Distribuzione di Poisson\nLa distribuzione di Poisson è uno degli strumenti fondamentali per descrivere fenomeni di conteggio, cioè situazioni in cui vogliamo sapere quante volte un certo evento si verifica in un intervallo di tempo (o di spazio) fissato. L’idea di fondo è semplice: immaginiamo che gli eventi si verifichino con una frequenza media costante e che ogni evento avvenga in modo indipendente dagli altri.\nSe una variabile casuale \\(Y\\) segue una distribuzione di Poisson con parametro \\(\\lambda\\), la probabilità di osservare un certo numero \\(y_i\\) di eventi è data da:\n\\[\nf(y_i \\mid \\lambda) = \\frac{e^{-\\lambda} \\lambda^{y_i}}{y_i!}, \\quad y_i \\in \\{0,1,2,\\dots\\},\\ \\lambda &gt; 0.\n\\]\nIl parametro \\(\\lambda\\) rappresenta il tasso medio di occorrenza degli eventi. Una caratteristica importante della distribuzione di Poisson è che la sua media e la sua varianza coincidono:\n\\[\nE(Y) = \\lambda, \\qquad \\text{Var}(Y) = \\lambda.\n\\]\nQuesto significa che, se in media osserviamo 2 eventi per intervallo, anche la variabilità attesa attorno a questo valore sarà pari a 2.\n\n52.1.1 Un esempio psicologico\nPer rendere più concreta l’idea, immaginiamo un paziente con disturbo ossessivo-compulsivo. Supponiamo che, in media, questo paziente compia 2 azioni compulsive all’ora. In questo caso il parametro della distribuzione di Poisson è \\(\\lambda = 2\\).\nLa formula ci permette di calcolare la probabilità di osservare esattamente \\(k\\) eventi in un’ora. Ad esempio:\n\nla probabilità di osservare 0 eventi è \\(\\frac{e^{-2} \\cdot 2^0}{0!} = e^{-2} \\approx 0.1353\\);\nla probabilità di osservare 1 evento è \\(\\frac{e^{-2} \\cdot 2^1}{1!} = 2e^{-2} \\approx 0.2707\\);\nla probabilità di osservare 2 eventi è \\(\\frac{e^{-2} \\cdot 2^2}{2!} = 2e^{-2} \\approx 0.2707\\).\n\n52.1.2 Calcoli in R\nPossiamo calcolare queste probabilità direttamente con R, usando la funzione dpois:\n\nlam_true &lt;- 2\nk_values &lt;- 0:9\n\nprobabilities &lt;- dpois(k_values, lambda = lam_true)\n\nfor (i in seq_along(k_values)) {\n  cat(sprintf(\"Probabilità di %d eventi: %.4f\\n\", k_values[i], probabilities[i]))\n}\n#&gt; Probabilità di 0 eventi: 0.1353\n#&gt; Probabilità di 1 eventi: 0.2707\n#&gt; Probabilità di 2 eventi: 0.2707\n#&gt; Probabilità di 3 eventi: 0.1804\n#&gt; Probabilità di 4 eventi: 0.0902\n#&gt; Probabilità di 5 eventi: 0.0361\n#&gt; Probabilità di 6 eventi: 0.0120\n#&gt; Probabilità di 7 eventi: 0.0034\n#&gt; Probabilità di 8 eventi: 0.0009\n#&gt; Probabilità di 9 eventi: 0.0002\n\nQuesto codice calcola la probabilità di osservare tra 0 e 9 eventi in un’ora, dato che il tasso medio è 2.\nNotiamo che i valori più probabili sono proprio 1 o 2 eventi per ora, mentre la probabilità di osservare molti più eventi diminuisce rapidamente.\n\n52.1.3 Visualizzazione grafica\nUn modo ancora più intuitivo per comprendere la distribuzione di Poisson è guardare il suo grafico. Con il seguente codice possiamo rappresentare la funzione di massa di probabilità (PMF) per \\(\\lambda = 2\\):\n\nlambd &lt;- 2\nx &lt;- 0:9  \ny &lt;- dpois(x, lambda = lambd)\n\ndf &lt;- data.frame(\n  numero_eventi = x,\n  probabilita = y\n)\n\nggplot(df, aes(x = numero_eventi, y = probabilita)) +\n  geom_segment(aes(x = numero_eventi, xend = numero_eventi, y = 0, yend = probabilita)) +\n  geom_point(size = 3) +\n  labs(title = \"Distribuzione di Poisson (λ = 2)\",  \n       x = \"Numero di eventi\", \n       y = \"Probabilità\") +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nIl grafico mostra con chiarezza che i valori centrati attorno a 2 hanno probabilità maggiore, mentre la probabilità decresce rapidamente per valori più alti.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_gamma_poisson_model.html#distribuzione-gamma",
    "href": "chapters/bayesian_inference/11_gamma_poisson_model.html#distribuzione-gamma",
    "title": "52  Modello coniugato Gamma-Poisson",
    "section": "\n52.2 Distribuzione Gamma",
    "text": "52.2 Distribuzione Gamma\nPer costruire un modello bayesiano con dati di tipo Poisson abbiamo bisogno di scegliere una distribuzione a priori per il parametro di tasso, \\(\\lambda\\). La scelta più comune – e anche la più conveniente dal punto di vista matematico – è la distribuzione Gamma. Questa distribuzione, infatti, è coniugata alla Poisson: significa che, partendo da una prior Gamma e aggiornandola con dati che seguono una Poisson, la distribuzione a posteriori appartiene ancora alla famiglia delle Gamma. In pratica, la coniugatezza ci permette di aggiornare le nostre credenze in modo molto semplice e diretto, senza doverci avventurare in calcoli complicati.\nLa densità della distribuzione Gamma è definita dalla formula:\n\\[\nf(x \\mid \\alpha, \\beta) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} x^{\\alpha - 1} e^{-\\beta x}, \\quad x &gt; 0\n\\]\ndove compaiono due parametri fondamentali:\n\n\n\\(\\alpha\\) (forma): controlla la forma della distribuzione. Con valori piccoli, la distribuzione è molto asimmetrica, concentrata vicino allo zero; aumentando \\(\\alpha\\), la distribuzione diventa più regolare e tende ad assumere una forma simile a una normale.\n\n\\(\\beta\\) (tasso o “rate”): regola la scala della distribuzione. Con valori alti, la probabilità si concentra verso valori più piccoli di \\(x\\); con valori bassi, la distribuzione si allarga e assegna probabilità a valori più grandi.\n\nAlcuni esempi aiutano a chiarire:\n\ncon \\(\\alpha = 2\\) e \\(\\beta = 3\\), la distribuzione descrive un processo in cui gli eventi sono relativamente rari, ma non impossibili;\ncon \\(\\alpha = 10\\) e \\(\\beta = 1\\), invece, la distribuzione è molto più concentrata e simmetrica, riflettendo un processo più regolare e prevedibile.\n\n\n\n\n\n\n\nIn R la distribuzione Gamma è parametrizzata usando direttamente \\(\\beta\\) come rate. Attenzione: a volte, in altri contesti, la stessa distribuzione viene scritta usando il parametro di scala (scale), che è semplicemente l’inverso del rate: \\(scale = 1/\\beta\\).\n\n\n\nIn R possiamo calcolare la densità della distribuzione Gamma con la funzione dgamma:\ndgamma(x, shape = alpha, rate = beta)\nAd esempio, per una Gamma con \\(\\alpha = 2\\) e \\(\\beta = 3\\) possiamo scrivere:\n\nalpha &lt;- 2\nbeta &lt;- 3\n\nggplot(data.frame(x = c(0, 3)), aes(x = x)) +\n  stat_function(\n    fun = dgamma,\n    args = list(shape = alpha, rate = beta)\n  ) +\n  labs(\n    title = expression(\"Distribuzione Gamma con \" ~ alpha == 2 ~ \",\" ~ beta == 3),\n    x = \"x\",\n    y = \"Densità di probabilità\"\n  ) +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nIl grafico mostra come la distribuzione si concentri vicino a valori piccoli di \\(x\\), ma lasci comunque una coda lunga verso destra. È proprio questa flessibilità che rende la distribuzione Gamma molto utile come modello a priori: può descrivere sia situazioni in cui ci aspettiamo valori piccoli ma incerti, sia casi in cui prevediamo valori medi o alti con maggiore regolarità.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_gamma_poisson_model.html#metodo-basato-su-griglia",
    "href": "chapters/bayesian_inference/11_gamma_poisson_model.html#metodo-basato-su-griglia",
    "title": "52  Modello coniugato Gamma-Poisson",
    "section": "\n52.4 Metodo basato su griglia",
    "text": "52.4 Metodo basato su griglia\nOra che abbiamo introdotto il modello Gamma–Poisson, possiamo provare a calcolare la distribuzione a posteriori del parametro \\(\\lambda\\) non con formule chiuse, ma con un procedimento puramente numerico. Questo approccio prende il nome di metodo su griglia (grid approximation), ed è molto utile come strumento didattico: ci mostra, passo dopo passo, come funziona l’aggiornamento bayesiano, trasformando le regole matematiche in un algoritmo semplice da eseguire al computer.\nL’idea è la seguente:\n\nfissiamo una “griglia” di possibili valori per \\(\\lambda\\);\ncalcoliamo la probabilità di ciascun valore secondo la priori;\ncalcoliamo, per gli stessi valori, la verosimiglianza dei dati osservati;\nmoltiplichiamo i due risultati per ottenere la distribuzione a posteriori (non ancora normalizzata);\nnormalizziamo in modo che la somma totale sia pari a 1.\n\n\n52.4.1 1. I dati e la priori\nPrendiamo gli stessi dati già usati in precedenza, cioè il numero di compulsioni osservate in otto intervalli di tempo:\n\ny &lt;- c(2, 1, 3, 2, 2, 1, 1, 1)\n\nLa priori scelta per \\(\\lambda\\) è una Gamma con parametri \\(\\alpha = 9\\) e \\(\\beta = 2\\), che riflette la nostra convinzione iniziale che il tasso medio sia intorno a 4–5 eventi, con un certo margine di incertezza.\nCreiamo una griglia di valori plausibili di \\(\\lambda\\), ad esempio da 0 a 10, divisa in 1000 punti:\n\nalpha_prior &lt;- 9\nbeta_prior  &lt;- 2\n\nlambda_grid &lt;- seq(0.01, 10, length.out = 1000)\n\nprior &lt;- dgamma(lambda_grid, shape = alpha_prior, rate = beta_prior)\n\nQuesta curva rappresenta ciò che crediamo possibile prima di vedere i dati.\n\n52.4.2 2. La verosimiglianza\nLa seconda componente è la verosimiglianza, cioè quanto ciascun valore ipotetico di \\(\\lambda\\) rende probabili i dati osservati. Per una Poisson, la verosimiglianza è il prodotto delle probabilità individuali:\n\\[\n\\mathcal{L}(\\lambda) = \\prod_{i=1}^N P(Y = y_i \\mid \\lambda).\n\\]\nIn R possiamo calcolarla in modo vettoriale:\n\nlikelihood &lt;- sapply(lambda_grid, function(l) prod(dpois(y, l)))\n\nCosì, per ogni punto della griglia otteniamo il valore della verosimiglianza: se il dato osservato è molto coerente con un certo \\(\\lambda\\), la verosimiglianza sarà alta; altrimenti sarà vicina a zero.\n\n52.4.3 3. La distribuzione a posteriori\nIl passo successivo è combinare priori e verosimiglianza. La regola di Bayes ci dice che:\n\\[\np(\\lambda \\mid y) \\propto p(\\lambda) \\cdot \\mathcal{L}(\\lambda).\n\\]\nIn pratica, moltiplichiamo i valori calcolati ai due passi precedenti:\n\nposterior_unnormalized &lt;- prior * likelihood\n\nQuesto ci dà una curva che ha la forma giusta, ma che non è ancora una vera distribuzione di probabilità: non somma a 1.\n\n52.4.4 4. Normalizzazione\nPer trasformarla in una distribuzione valida, dobbiamo normalizzare, cioè dividere per la somma totale (che qui approssimiamo come una somma numerica sulla griglia):\n\ngrid_width &lt;- lambda_grid[2] - lambda_grid[1]\nnormalization_factor &lt;- sum(posterior_unnormalized) * grid_width\n\nposterior &lt;- posterior_unnormalized / normalization_factor\n\nOra abbiamo davvero la distribuzione a posteriori di \\(\\lambda\\).\n\n52.4.5 5. Interpretazione e confronto visivo\nA questo punto possiamo confrontare la priori e la posteriori in un unico grafico:\n\ndf &lt;- data.frame(\n  lambda     = lambda_grid,\n  Prior      = prior,\n  Posteriori = posterior\n)\n\ndf_long &lt;- pivot_longer(df, cols = c(\"Prior\", \"Posteriori\"),\n                        names_to = \"Distribuzione\",\n                        values_to = \"Densita\")\n\nggplot(df_long, aes(x = lambda, y = Densita, color = Distribuzione)) +\n  geom_line(size = 1) +\n  labs(title = \"Aggiornamento bayesiano con il metodo su griglia\",\n       x = expression(lambda),\n       y = \"Densità\")\n\n\n\n\n\n\n\nIl grafico rivela due aspetti fondamentali:\n\nla posteriori è spostata rispetto alla priori, perché i dati suggeriscono valori di \\(\\lambda\\) più bassi di quanto ci aspettassimo inizialmente;\nla posteriori è anche più concentrata, cioè meno incerta: dopo aver osservato i dati, non solo abbiamo aggiornato la nostra convinzione, ma siamo anche diventati più sicuri del valore plausibile di \\(\\lambda\\).\n\n52.4.6 Perché è utile il metodo su griglia?\nQuesto metodo non è molto efficiente in problemi complessi (dove i parametri sono tanti e lo spazio da esplorare è enorme), ma è molto utile a scopo didattico. Ci mostra infatti in modo visivo e intuitivo come funziona l’aggiornamento bayesiano: partiamo da una convinzione iniziale (la prior), la confrontiamo con i dati (la likelihood) e otteniamo una nuova convinzione aggiornata (la posterior).\nNei prossimi capitoli vedremo come affrontare lo stesso problema con strumenti più generali, come il campionamento MCMC in Stan, che diventano indispensabili quando i modelli si complicano e il metodo su griglia non è più praticabile.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_gamma_poisson_model.html#modello-coniugato-gamma-poission",
    "href": "chapters/bayesian_inference/11_gamma_poisson_model.html#modello-coniugato-gamma-poission",
    "title": "52  Modello coniugato Gamma-Poisson",
    "section": "\n52.5 Modello Coniugato Gamma-Poission",
    "text": "52.5 Modello Coniugato Gamma-Poission\nPer calcolare analiticamente la distribuzione a posteriori nel contesto di un modello gamma-Poisson possiamo seguire un processo diretto. Il modello Gamma-Poisson è coniugato, il che significa che la distribuzione a posteriori sarà ancora una distribuzione Gamma.\nSeguendo il teorema di Bayes, possiamo scrivere la distribuzione a posteriori come:\n\\(f(\\lambda \\mid y) \\propto f(y \\mid \\lambda) \\cdot f(\\lambda) ,\\)\ndove \\(f(\\lambda \\mid y)\\) è la distribuzione a posteriori, \\(f(y \\mid \\lambda)\\) è la verosimiglianza e \\(f(\\lambda)\\) è la distribuzione a priori.\nDefiniamo la verosimiglianza (distribuzione di Poisson):\n\\(f(y \\mid \\lambda) = \\prod_{i=1}^n \\frac{e^{-\\lambda}\\lambda^{y_i}}{y_i!} = \\frac{e^{-n\\lambda}\\lambda^{\\sum_{i=1}^n y_i}}{\\prod_{i=1}^n y_i!}.\\)\nDefiniamo la distribuzione a priori (distribuzione Gamma):\n\\(f(\\lambda) = \\frac{b^a}{\\Gamma(a)}\\lambda^{a-1}e^{-b\\lambda}.\\)\nOra, moltiplichiamo la verosimiglianza per la distribuzione a priori:\n\\(f(\\lambda|y) \\propto \\frac{e^{-n\\lambda}\\lambda^{\\sum_{i=1}^n y_i}}{\\prod_{i=1}^n y_i!} \\cdot \\frac{b^a}{\\Gamma(a)}\\lambda^{a-1}e^{-b\\lambda}.\\)\nSemplifichiamo, eliminando i termini costanti (che non dipendono da \\(\\lambda\\)):\n\\(f(\\lambda \\mid y) \\propto e^{-n\\lambda}\\lambda^{\\sum_{i=1}^n y_i} \\cdot \\lambda^{a-1}e^{-b\\lambda}.\\)\nRaggruppiamo i termini:\n\\(f(\\lambda|y) \\propto \\lambda^{\\sum_{i=1}^n y_i} \\cdot \\lambda^{a-1} \\cdot e^{-n\\lambda} \\cdot e^{-b\\lambda}.\\)\nSemplifichiamo ulteriormente:\n\\(f(\\lambda \\mid y) \\propto \\lambda^{\\sum_{i=1}^n y_i + a - 1} \\cdot e^{-(n+b)\\lambda}.\\)\nRiconosciamo che questa è la forma di una distribuzione Gamma con nuovi parametri:\n\\(f(\\lambda \\mid y) \\propto \\lambda^{(\\sum_{i=1}^n y_i + a) - 1} \\cdot e^{-(n+b)\\lambda}.\\)\nQuindi, la distribuzione a posteriori è una Gamma con parametri:\n\n\n\\(\\alpha_{post} = a + \\sum_{i=1}^n y_i\\),\n\n\\(\\beta_{post} = b + n\\),\n\ndove:\n\n\n\\(a\\) e \\(b\\) sono i parametri della distribuzione Gamma a priori,\n\n\\(\\sum_{i=1}^n y_i\\) è la somma di tutte le osservazioni,\n\n\\(n\\) è il numero di osservazioni.\n\nQuesta derivazione mostra come la distribuzione a posteriori mantiene la forma di una Gamma, ma con parametri aggiornati che incorporano l’informazione dai dati osservati.\nConsideriamo nuovamente l’esempio precedente. Utilizzando i parametri aggiornati, rappresentiamo graficamente la distribuzione a posteriori:\n\n# Parametri aggiornati della distribuzione a posteriori Gamma\nalpha_post &lt;- alpha_prior + sum(y)\nbeta_post &lt;- beta_prior + length(y)\n\n# Griglia dei valori di lambda\nlambda_grid &lt;- seq(0.01, 10, length.out = 1000)\n\n# Distribuzione a posteriori analitica\nposterior_analytic &lt;- dgamma(lambda_grid, shape = alpha_post, rate = beta_post)\n\n# Creare un dataframe contenente i dati per il grafico\ndf &lt;- data.frame(\n  lambda = lambda_grid,\n  densita = posterior_analytic\n)\n\n# Calcolo della media a posteriori\nmedia_posterior &lt;- alpha_post / beta_post\n\n# Creare il grafico con ggplot2\nggplot(df, aes(x = lambda, y = densita)) +\n  geom_line(color = \"blue\", size = 1) +  # Aggiungere la linea per la densità a posteriori\n  geom_vline(xintercept = media_posterior, color = \"red\", linetype = \"dashed\", size = 1) +  # Linea verticale per la media a posteriori\n  labs(\n    title = \"Distribuzione a Posteriori Analitica Gamma-Poisson\",\n    x = expression(lambda),  # Label dell'asse x usando espressioni matematiche\n    y = \"Densità di probabilità\"  # Label dell'asse y\n  ) +\n  theme(plot.title = element_text(hjust = 0.5)) +  # Centrare il titolo\n  annotate(\"text\", x = media_posterior + 0.5, y = max(posterior_analytic) * 0.8, \n           label = \"Media a Posteriori\", color = \"red\", size = 4) +  # Etichetta per la media a posteriori\n  scale_x_continuous(expand = expansion(mult = c(0, 0.1)))  # Aumentare lo spazio sull'asse x per migliorare la visualizzazione\n\n\n\n\n\n\n\nIl grafico mostra la distribuzione a posteriori analitica del parametro di tasso \\(\\lambda\\) di un modello di Poisson, ottenuta utilizzando una distribuzione a priori Gamma e aggiornando i parametri alla luce dei dati osservati. La distribuzione a posteriori è calcolata come una Gamma aggiornata con i parametri \\(\\alpha_{\\text{post}}\\) e \\(\\beta_{\\text{post}}\\), e rappresenta la nostra conoscenza aggiornata dopo aver visto i dati. I risultati analitici concordano con quelli ottenuti tramite simulazione.\nProcediamo ora con il calcolo della soluzione analitica per la media della distribuzione a posteriori del parametro \\(\\lambda\\):\n\n# Media della distribuzione a posteriori\nposterior_mean &lt;- alpha_post / beta_post\ncat(sprintf(\"Media a Posteriori = %.3f\\n\", posterior_mean))\n#&gt; Media a Posteriori = 2.200\n\n# Parametri della distribuzione a posteriori\ncat(sprintf(\"Shape (α) = %.1f\\n\", alpha_post))\n#&gt; Shape (α) = 22.0\ncat(sprintf(\"Rate (β) = %.1f\\n\", beta_post))\n#&gt; Rate (β) = 10.0\n\nPossiamo calcolare la probabilità di qualsiasi evento di interesse. Per esempio, ci possiamo chiedere quale sia la probabilità di osservare più di 3 compulsioni per ora:\n\n# Probabilità di osservare più di 3 eventi\nprob_y_greater_than_3 &lt;- 1 - pgamma(3, shape = alpha_post, rate = beta_post)\ncat(sprintf(\"Probabilità di osservare più di 3 eventi = %.3f\\n\", prob_y_greater_than_3))\n#&gt; Probabilità di osservare più di 3 eventi = 0.054",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_gamma_poisson_model.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/11_gamma_poisson_model.html#riflessioni-conclusive",
    "title": "52  Modello coniugato Gamma-Poisson",
    "section": "\n52.5 Riflessioni conclusive",
    "text": "52.5 Riflessioni conclusive\nIl modello Gamma–Poisson rappresenta un esempio chiaro ed elegante di come l’inferenza bayesiana possa essere applicata ai dati di conteggio, molto frequenti in psicologia. L’idea di fondo è semplice: partiamo da una convinzione iniziale sul tasso medio di occorrenza degli eventi, espressa attraverso una distribuzione a priori di tipo Gamma. Quando osserviamo nuovi dati, questa convinzione viene aggiornata in modo sistematico, e il risultato è una nuova distribuzione, la a posteriori, che incorpora sia ciò che sapevamo prima sia l’informazione proveniente dai dati.\nQuesto meccanismo ha due grandi vantaggi. Da un lato, ci fornisce stime più realistiche del parametro $$, perché non si limita a un singolo numero ma restituisce una distribuzione che descrive tutti i valori plausibili. Dall’altro, ci permette di quantificare l’incertezza: non diciamo soltanto “qual è” il tasso medio, ma anche “quanto siamo incerti” sulla sua stima.\nIn questo modo, il modello Gamma–Poisson non è soltanto un esercizio teorico: diventa uno strumento pratico che ci aiuta a ragionare in modo più cauto e informato quando prendiamo decisioni basate sui dati psicologici. È un primo passo per comprendere il potere dell’approccio bayesiano, che non si limita a calcolare parametri, ma ci offre un vero e proprio linguaggio per descrivere e aggiornare le nostre conoscenze.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_gamma_poisson_model.html#esercizi",
    "href": "chapters/bayesian_inference/11_gamma_poisson_model.html#esercizi",
    "title": "52  Modello coniugato Gamma-Poisson",
    "section": "\n52.6 Esercizi",
    "text": "52.6 Esercizi\n\n\n\n\n\n\nEsercizio\n\n\n\n\n\nConsideriamo uno studio longitudinale su coppie, dove i partecipanti registrano quotidianamente la frequenza con cui nascondono il loro comportamento di fumo al partner. Basandoci sui dati di Scholz et al. (2021), assumiamo che il tasso medio di nascondere il fumo sia di 1.52 volte al giorno. Supponiamo di avere i seguenti dati giornalieri per un partecipante:\n\nGiorno 1: 2 volte.\nGiorno 2: 0 volte.\nGiorno 3: 1 volta.\nGiorno 4: 3 volte.\n\nUtilizzare un modello Gamma-Poisson per stimare la distribuzione a posteriori del tasso individuale di nascondere il fumo per un partecipante specifico, dato il suo insieme di osservazioni giornaliere.\n\n\n\n\n\n\n\n\n\nSoluzione\n\n\n\n\n\nVogliamo stimare quante volte al giorno una persona tende a nascondere il proprio fumo al partner. Abbiamo quattro giorni di dati su questa persona e, grazie a un precedente studio, sappiamo che in media le persone lo fanno circa 1.52 volte al giorno.\nMa i dati di una sola persona sono pochi, quindi useremo un approccio bayesiano per combinare:\n\n\nLe informazioni preesistenti (dal precedente studio),\n\nLe nuove osservazioni (quanti eventi sono stati registrati nei quattro giorni).\n\nCon un modello Gamma-Poisson, possiamo aggiornare la nostra stima e ottenere una distribuzione a posteriori, che ci dirà quali sono i valori più probabili per il tasso di nascondimento di questa persona.\n# Dati osservati: numero di volte che la persona ha nascosto il fumo ogni giorno\nosservazioni &lt;- c(2, 0, 1, 3)\n\n# Numero totale di giorni osservati\nn_giorni &lt;- length(osservazioni)\n\n# Numero totale di eventi (quante volte ha nascosto il fumo in totale)\neventi_totali &lt;- sum(osservazioni)\n\n# Informazione a priori dallo studio precedente\nmedia_priori &lt;- 1.52\nforma_priori &lt;- 3   # Parametro di forma scelto per un'incertezza moderata\ntasso_priori &lt;- forma_priori / media_priori  # Parametro di scala\n\n# Aggiornamento bayesiano: parametri della distribuzione a posteriori\nforma_post &lt;- forma_priori + eventi_totali\ntasso_post &lt;- tasso_priori + n_giorni\n\n# Creazione della griglia di valori possibili per il tasso giornaliero (lambda)\nlambda_valori &lt;- seq(0, 5, length.out = 100)\n\n# Calcolo delle densità per le distribuzioni a priori e a posteriori\ndensita_priori &lt;- dgamma(lambda_valori, shape = forma_priori, rate = tasso_priori)\ndensita_post &lt;- dgamma(lambda_valori, shape = forma_post, rate = tasso_post)\n\n# Creazione di un dataframe per il grafico\ndati_plot &lt;- data.frame(\n  lambda = rep(lambda_valori, 2),\n  densita = c(densita_priori, densita_post),\n  distribuzione = rep(c(\"Priori\", \"Posteriori\"), each = length(lambda_valori))\n)\n\n# Creazione del grafico per confrontare la distribuzione a priori e quella aggiornata (posteriori)\nggplot(dati_plot, aes(x = lambda, y = densita, color = distribuzione)) +\n  geom_line(size = 1.2) +\n  labs(\n    title = \"Stima del tasso di nascondimento del fumo\",\n    x = \"Tasso giornaliero (λ)\",\n    y = \"Densità\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\nCosa fa questo codice\n\n\nCarica i dati: abbiamo registrato per 4 giorni quante volte questa persona ha nascosto il fumo.\n\nImposta una conoscenza iniziale (priori): basata sullo studio precedente.\n\nApplica il teorema di Bayes per aggiornare la stima con i nuovi dati.\n\nGenera il grafico: confronta la distribuzione prima e dopo l’aggiornamento con i dati osservati.\n\nInterpretazione del risultato\n\nLa curva rossa (priori) rappresenta la nostra stima iniziale, basata sullo studio precedente.\nLa curva blu (posteriori) è la nostra nuova stima dopo aver considerato i dati della persona.\nSe i dati raccolti sono molto diversi dal valore medio dello studio, la curva blu si sposterà rispetto alla rossa.\n\nQuesta analisi ci permette di stimare il comportamento specifico di una persona integrando dati generali e osservazioni individuali, in modo più informativo rispetto a una semplice media.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_gamma_poisson_model.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/11_gamma_poisson_model.html#informazioni-sullambiente-di-sviluppo",
    "title": "52  Modello coniugato Gamma-Poisson",
    "section": "Informazioni sull’ambiente di sviluppo",
    "text": "Informazioni sull’ambiente di sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pillar_1.11.0         tinytable_0.11.0      patchwork_1.3.1      \n#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.13.0     \n#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.0     \n#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [16] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [19] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [22] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.6         tidyselect_1.2.1     farver_2.1.2        \n#&gt;  [4] fastmap_1.2.0        TH.data_1.1-3        tensorA_0.36.2.1    \n#&gt;  [7] pacman_0.5.1         digest_0.6.37        estimability_1.5.1  \n#&gt; [10] timechange_0.3.0     lifecycle_1.0.4      survival_3.8-3      \n#&gt; [13] magrittr_2.0.3       compiler_4.5.1       rlang_1.1.6         \n#&gt; [16] tools_4.5.1          knitr_1.50           labeling_0.4.3      \n#&gt; [19] bridgesampling_1.1-2 htmlwidgets_1.6.4    pkgbuild_1.4.8      \n#&gt; [22] curl_6.4.0           RColorBrewer_1.1-3   abind_1.4-8         \n#&gt; [25] multcomp_1.4-28      withr_3.0.2          purrr_1.1.0         \n#&gt; [28] grid_4.5.1           stats4_4.5.1         xtable_1.8-4        \n#&gt; [31] colorspace_2.1-1     inline_0.3.21        emmeans_1.11.2      \n#&gt; [34] scales_1.4.0         MASS_7.3-65          cli_3.6.5           \n#&gt; [37] mvtnorm_1.3-3        rmarkdown_2.29       generics_0.1.4      \n#&gt; [40] RcppParallel_5.1.10  cachem_1.1.0         stringr_1.5.1       \n#&gt; [43] splines_4.5.1        parallel_4.5.1       vctrs_0.6.5         \n#&gt; [46] V8_6.0.5             Matrix_1.7-3         sandwich_3.1-1      \n#&gt; [49] jsonlite_2.0.0       arrayhelpers_1.1-0   glue_1.8.0          \n#&gt; [52] codetools_0.2-20     distributional_0.5.0 lubridate_1.9.4     \n#&gt; [55] stringi_1.8.7        gtable_0.3.6         QuickJSR_1.8.0      \n#&gt; [58] htmltools_0.5.8.1    Brobdingnag_1.2-9    R6_2.6.1            \n#&gt; [61] rprojroot_2.1.0      evaluate_1.0.4       lattice_0.22-7      \n#&gt; [64] backports_1.5.0      memoise_2.0.1        broom_1.0.9         \n#&gt; [67] snakecase_0.11.1     rstantools_2.4.0     coda_0.19-4.1       \n#&gt; [70] gridExtra_2.3        nlme_3.1-168         checkmate_2.3.2     \n#&gt; [73] xfun_0.52            zoo_1.8-14           pkgconfig_2.0.3",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_gamma_poisson_model.html#bibliografia",
    "href": "chapters/bayesian_inference/11_gamma_poisson_model.html#bibliografia",
    "title": "52  Modello coniugato Gamma-Poisson",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nScholz, U., Stadler, G., Berli, C., Lüscher, J., & Knoll, N. (2021). How do people experience and respond to social control from their partner? Three daily diary studies. Frontiers in Psychology, 11, 613546.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/12_gamma_exponential_model.html",
    "href": "chapters/bayesian_inference/12_gamma_exponential_model.html",
    "title": "53  Modello gamma-esponenziale",
    "section": "",
    "text": "53.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nNell’inferenza bayesiana, il modello coniugato Gamma-Esponenziale rappresenta un approccio analitico efficace per l’analisi di dati che seguono una distribuzione esponenziale. Questa distribuzione è comunemente utilizzata per modellare i tempi di attesa tra eventi in processi di Poisson, come ad esempio gli intervalli tra arrivi in un sistema a coda o la durata di eventi psicologici.\nConsideriamo, ad esempio, un esperimento in psicologia in cui si misurano i tempi di insorgenza di episodi di ansia in seguito a un evento stressante. In questo caso, si può ipotizzare che i tempi di insorgenza siano distribuiti esponenzialmente. Il parametro \\(\\lambda\\) della distribuzione esponenziale rappresenta il tasso medio con cui si verificano gli episodi di ansia.\nIl modello coniugato Gamma-Esponenziale consente di stimare il parametro \\(\\lambda\\) utilizzando i dati osservati. La distribuzione a priori Gamma viene utilizzata per rappresentare l’incertezza iniziale su \\(\\lambda\\), mentre la distribuzione esponenziale modella i dati osservati. Grazie a questa coniugazione, l’aggiornamento delle credenze sul parametro \\(\\lambda\\) avviene in modo semplice e analitico, permettendo di ottenere una stima bayesiana del tasso medio di occorrenza degli episodi di ansia, fornendo così una descrizione probabilistica accurata del fenomeno in esame.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Modello gamma-esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/12_gamma_exponential_model.html#introduzione",
    "href": "chapters/bayesian_inference/12_gamma_exponential_model.html#introduzione",
    "title": "53  Modello gamma-esponenziale",
    "section": "",
    "text": "53.1.1 Il Modello Matematico\nCaso singolo. Supponiamo di osservare un singolo tempo di attesa \\(y_1\\) prima che si verifichi un evento, come un episodio di disagio psicologico. Assumiamo che questo tempo di attesa segua una distribuzione esponenziale con parametro \\(\\lambda\\). La funzione di densità di probabilità (pdf) della distribuzione esponenziale è data da:\n\\[\nf(y_1 \\mid \\lambda) = \\lambda e^{-\\lambda y_1},\n\\]\ndove:\n\n\n\\(y_1\\) rappresenta il tempo di attesa,\n\n\\(\\lambda\\) è il parametro della distribuzione, che rappresenta il tasso medio con cui gli eventi si verificano per unità di tempo.\n\nIn questa distribuzione, \\(\\lambda\\) è il tasso di occorrenza o tasso di decadimento, ed è l’inverso del tempo medio di attesa. Più precisamente:\n\nIl tempo medio di attesa è il valore medio del tempo che trascorre prima che l’evento si verifichi (ad esempio, quanto tempo ci si aspetta in media prima che arrivi un autobus).\nIl parametro \\(\\lambda\\) rappresenta la frequenza con cui l’evento si verifica per unità di tempo, e quindi \\(\\lambda = \\frac{1}{\\text{tempo medio}}\\).\n\nPertanto, nella funzione esponenziale \\(f(y_1 \\mid \\lambda) = \\lambda e^{-\\lambda y_1}\\), il parametro \\(\\lambda\\) è inversamente proporzionale al tempo medio di attesa: più grande è \\(\\lambda\\), più breve è il tempo medio di attesa tra gli eventi.\nQuesta funzione descrive la probabilità di osservare un tempo di attesa esattamente uguale a \\(y_1\\), dato un valore specifico di \\(\\lambda\\). Per la distribuzione esponenziale, la media è \\(\\frac{1}{\\lambda}\\) e la varianza è \\(\\frac{1}{\\lambda^2}\\), il che riflette l’influenza del tasso \\(\\lambda\\) sulla dispersione dei tempi di attesa.\nPer fare un esempio, supponiamo che il tempo medio di attesa sia 2 ore. In questo caso, il parametro \\(\\lambda\\) (l’inverso del tempo medio di attesa) è \\(\\frac{1}{2}\\).\n\n# Parametro lambda (l'inverso del tempo medio di attesa)\nlambda_value &lt;- 1 / 2\n\nDisegniamo la funzione di densità esponenziale per tempi di attesa compresi tra 0 e 10 ore.\n\n# Creazione dei valori di y1 su cui valutare la funzione\ny1_values &lt;- seq(0, 10, length.out = 500) # Intervallo da 0 a 10 ore\n\n# Definizione della funzione di densità esponenziale\nexponential_density &lt;- function(y1, lambda_value) {\n  lambda_value * exp(-lambda_value * y1)\n}\n\n# Calcolo dei valori di f(y1 | lambda)\nf_values &lt;- exponential_density(y1_values, lambda_value)\n\n# Creazione del grafico\nplot(\n  y1_values, f_values,\n  type = \"l\", lwd = 2,\n  main = expression(paste(\n    \"Funzione di Densità Esponenziale con \",\n    lambda, \" = 1/2\"\n  )),\n  xlab = \"Tempo di attesa (ore)\", ylab = \"Densità\"\n)\nlegend(\"topright\",\n  legend = expression(f(y[1] ~ \"|\" ~ lambda) == lambda ~ e^(-lambda * y[1])),\n  lty = 1, bty = \"n\"\n)\n\n\n\n\n\n\n\nQuesto codice crea un grafico della funzione di densità esponenziale per \\(\\lambda = 1/2\\) e tempi di attesa compresi tra 0 e 10 ore.\nIl caso di \\(n\\) osservazioni indipendenti. Consideriamo ora un campione di \\(n\\) osservazioni indipendenti \\(y_1, y_2, \\dots, y_n\\). L’indipendenza tra le osservazioni implica che il tempo di attesa osservato per un evento non influisce sulla probabilità di osservare altri tempi di attesa.\nPoiché le osservazioni sono indipendenti, la probabilità congiunta di osservare tutti i tempi di attesa nel campione è il prodotto delle probabilità individuali. Di conseguenza, la funzione di verosimiglianza per l’intero campione è data da:\n\\[\nf(y_1, y_2, \\dots, y_n \\mid \\lambda) = f(y_1 \\mid \\lambda) \\cdot f(y_2 \\mid \\lambda) \\cdot \\dots \\cdot f(y_n \\mid \\lambda).\n\\]\nSostituendo la funzione di densità della distribuzione esponenziale per ciascuna osservazione, otteniamo:\n\\[\nf(y \\mid \\lambda) = \\lambda e^{-\\lambda y_1} \\cdot \\lambda e^{-\\lambda y_2} \\cdot \\dots \\cdot \\lambda e^{-\\lambda y_n}.\n\\]\nRaccogliendo i termini comuni, possiamo riscrivere la funzione di verosimiglianza come:\n\\[\nf(y \\mid \\lambda) = \\lambda^n e^{-\\lambda (y_1 + y_2 + \\dots + y_n)}.\n\\]\nUtilizzando la notazione di sommatoria, possiamo esprimere la funzione di verosimiglianza in modo compatto come:\n\\[\nf(y \\mid \\lambda) = \\lambda^n e^{-\\lambda \\sum_{i=1}^{n} y_i}.\n\\]\nLa funzione di verosimiglianza \\(f(y \\mid \\lambda)\\) rappresenta la probabilità di osservare il campione \\(y_1, y_2, \\dots, y_n\\) dato un particolare valore del parametro \\(\\lambda\\). Un valore più alto della verosimiglianza indica una maggiore plausibilità del valore di \\(\\lambda\\), dato il campione osservato.\nSpesso è più conveniente lavorare con il logaritmo della funzione di verosimiglianza, poiché il logaritmo trasforma i prodotti in somme, semplificando i calcoli. Il logaritmo della funzione di verosimiglianza è:\n\\[\n\\log L(\\lambda \\mid y_1, y_2, \\dots, y_n) = n \\log \\lambda - \\lambda \\sum_{i=1}^{n} y_i.\n\\]\nQuesta forma semplificata della log-verosimiglianza è utile per stimare il parametro \\(\\lambda\\) tramite tecniche come la massimizzazione della verosimiglianza.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Modello gamma-esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/12_gamma_exponential_model.html#aggiornare-le-nostre-credenze-con-linferenza-bayesiana",
    "href": "chapters/bayesian_inference/12_gamma_exponential_model.html#aggiornare-le-nostre-credenze-con-linferenza-bayesiana",
    "title": "53  Modello gamma-esponenziale",
    "section": "\n53.2 Aggiornare le Nostre Credenze con l’Inferenza Bayesiana",
    "text": "53.2 Aggiornare le Nostre Credenze con l’Inferenza Bayesiana\nNell’approccio bayesiano, non consideriamo solo i dati, ma anche le nostre conoscenze a priori sul parametro \\(\\lambda\\). Assegniamo a \\(\\lambda\\) una distribuzione a priori, tipicamente una distribuzione Gamma. Combinando la verosimiglianza con la distribuzione a priori, otteniamo la distribuzione a posteriori di \\(\\lambda\\), che rappresenta la nostra conoscenza aggiornata alla luce dei dati. La proprietà della coniugazione assicura che la distribuzione a posteriori sia anch’essa una Gamma, facilitando i calcoli.\nPer fare un esempio concreto, simuleremo un campione di dati. Immaginiamo di raccogliere dati che rappresentano il tempo, misurato in ore, che intercorre tra episodi di ansia in individui con disturbi d’ansia. La distribuzione esponenziale può essere utilizzata per modellare questo tempo di attesa tra un episodio di ansia e il successivo. Ad esempio, possiamo ipotizzare che, una volta concluso un episodio, l’insorgenza del prossimo segua un processo stocastico con un tasso costante, indipendentemente dal tempo trascorso dall’episodio precedente. In questo contesto, il parametro \\(\\lambda\\) della distribuzione esponenziale rappresenta il tasso medio di occorrenza degli episodi di ansia, ossia quanti episodi ci si aspetta in media in una certa unità di tempo (ad esempio, in un giorno).\nSe \\(\\lambda\\) è elevato, ciò indica che gli episodi di ansia sono più frequenti, con tempi di attesa più brevi tra un episodio e l’altro.\n\n# Impostiamo il seed per rendere i risultati riproducibili\nset.seed(42)\n\n# Parametro medio (tempo medio di attesa in ore)\nmean_time &lt;- 3.0\nlambda_param &lt;- 1 / mean_time # Parametro lambda per la distribuzione esponenziale\n\n# Numero di osservazioni nel campione\nn &lt;- 15\n\n# Generazione del campione casuale\ny &lt;- round(rexp(n, rate = lambda_param))\ny\n#&gt;  [1] 1 2 1 0 1 4 1 1 4 2 4 7 0 0 4\n\nImmaginiamo che questi dati rappresentino il tempo di attesa in ore tra episodi di ansia in 15 individui con disturbi d’ansia. Il tempo di attesa medio è:\n\nmean_time_observed &lt;- mean(y)\nmean_time_observed\n#&gt; [1] 2.133\n\nIl tasso di occorrenza, \\(\\lambda\\), calcolato sulla base dei dati osservati è:\n\nlambda_estimated &lt;- 1 / mean_time_observed\nlambda_estimated\n#&gt; [1] 0.4688\n\nOra possiamo procedere a trovare la distribuzione a posteriori per il tasso di occorrenza \\(\\lambda\\).\n\n53.2.1 Passi per definire un prior debolmente informativo\nIl primo passo consiste nel definire una distribuzione a priori per \\(\\lambda\\), il tasso di occorrenza degli episodi di ansia in individui con disturbi d’ansia. Se disponiamo di poche informazioni a priori riguardo al valore di \\(\\lambda\\), possiamo adottare una distribuzione a priori debolmente informativa. Un prior debolmente informativo ha lo scopo di esercitare una minima influenza sull’inferenza, consentendo ai dati osservati di guidare principalmente la stima del parametro.\nLa distribuzione a priori coniugata per la distribuzione esponenziale è la distribuzione Gamma. Un prior debolmente informativo per \\(\\lambda\\) potrebbe essere impostato in modo tale da riflettere una conoscenza vaga, con una media che rappresenta un tempo di attesa ragionevole (basato su qualche informazione preliminare o ipotesi generale), ma con una varianza ampia, in modo da non vincolare eccessivamente l’inferenza.\nSupponiamo di voler impostare una distribuzione a priori per il tasso di occorrenza \\(\\lambda\\), in modo tale che il tempo medio di attesa sia 3.33 ore, con una deviazione standard ampia, ad esempio 5 ore. Poiché \\(\\lambda\\) rappresenta il tasso di occorrenza (ovvero l’inverso del tempo medio di attesa), dobbiamo applicare la distribuzione Gamma ai valori di \\(\\lambda\\), non direttamente ai tempi di attesa.\nI parametri della distribuzione Gamma, \\(\\alpha\\) (forma) e \\(\\beta\\) (tasso), sono dati da:\n\n\\(\\alpha_{\\text{prior}} = 0.45\\)\n\\(\\beta_{\\text{prior}} = 1.5\\)\n\nVerifichiamo che questi parametri corrispondano alla media e alla varianza desiderate.\n\n# Parametri della distribuzione Gamma\nalpha_prior &lt;- 0.45 # Forma\nbeta_prior &lt;- 1.5 # Tasso (inverso della scala)\n\n# Calcolo della media e della varianza della distribuzione Gamma per λ\nmean_lambda &lt;- alpha_prior / beta_prior\nvariance_lambda &lt;- alpha_prior / (beta_prior^2)\n\n# Calcolo della media del tempo di attesa (E[Y] = 1 / E[λ])\nmean_waiting_time &lt;- 1 / mean_lambda\n\n# Stampiamo la media e la varianza di λ e del tempo di attesa\ncat(\"Media di λ:\", mean_lambda, \"\\n\")\n#&gt; Media di λ: 0.3\ncat(\"Varianza di λ:\", variance_lambda, \"\\n\")\n#&gt; Varianza di λ: 0.2\ncat(\"Media del tempo di attesa:\", mean_waiting_time, \"ore\\n\")\n#&gt; Media del tempo di attesa: 3.333 ore\n\nLa media del tempo di attesa è 3.33 ore, come desiderato. La varianza del tempo di attesa richiede un calcolo più complesso e non è semplicemente l’inverso della varianza di \\(\\lambda\\).\n\n53.2.2 Visualizzazione della Distribuzione a Priori\nDisegniamo la funzione di densità della distribuzione Gamma per \\(\\lambda\\), utilizzando i parametri specificati.\n\n# Creazione dei valori x per il grafico\nx &lt;- seq(0, 2, length.out = 500)\n\n# Funzione di densità della distribuzione Gamma con i parametri dati\ngamma_pdf &lt;- dgamma(x, shape = alpha_prior, rate = beta_prior)\n\n# Creazione del grafico\nplot(x, gamma_pdf,\n  type = \"l\", lwd = 2,\n  main = bquote(\"Funzione di Densità Gamma con \" ~ alpha == .(alpha_prior) ~ \",\" ~ beta == .(beta_prior)),\n  xlab = expression(lambda),\n  ylab = \"Densità di probabilità\"\n)\nlegend(\n  \"topright\",\n  legend = \"Distribuzione a Priori\",\n  lty = 1,\n  lwd = 2,\n  bty = \"n\"\n)",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Modello gamma-esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/12_gamma_exponential_model.html#metodo-basato-su-griglia",
    "href": "chapters/bayesian_inference/12_gamma_exponential_model.html#metodo-basato-su-griglia",
    "title": "53  Modello gamma-esponenziale",
    "section": "\n53.3 Metodo Basato su Griglia",
    "text": "53.3 Metodo Basato su Griglia\nPoniamoci l’obiettivo di utilizzare il metodo basato su griglia per derivare la distribuzione a posteriori del parametro \\(\\lambda\\) della distribuzione esponenziale. Iniziamo creando una griglia per \\(\\lambda\\) nell’intervallo [0.01, 2].\n\n# Evitiamo zero per evitare divisione per zero\nlambda_grid &lt;- seq(0.01, 2, length.out = 1000)\n\n\n53.3.1 Calcolo della Distribuzione a Priori\n\n# Calcolo della distribuzione a priori\nprior &lt;- dgamma(lambda_grid, shape = alpha_prior, rate = beta_prior)\n\n\n53.3.2 Calcolo della Verosimiglianza\nImmaginiamo di avere i seguenti dati, che rappresentano i tempi di attesa (in ore) tra episodi di ansia per 15 individui:\n\n# Impostiamo il seed per rendere i risultati riproducibili\nset.seed(42)\n\n# Parametro medio (tempo medio di attesa in ore)\nmean_time &lt;- 3.0\nlambda_param &lt;- 1 / mean_time # Parametro λ per la distribuzione esponenziale\n\n# Numero di osservazioni nel campione\nn &lt;- 15\n\n# Generazione del campione casuale\ny &lt;- round(rexp(n, rate = lambda_param))\ny\n#&gt;  [1] 1 2 1 0 1 4 1 1 4 2 4 7 0 0 4\n\nCalcoliamo la log-verosimiglianza per ciascun valore di \\(\\lambda\\) nella griglia:\n\n# Calcolo della log-verosimiglianza per ciascun valore di lambda\nlog_likelihood &lt;- sapply(\n  lambda_grid,\n  function(lam) sum(dexp(y, rate = lam, log = TRUE))\n)\n\n\n53.3.3 Calcolo della Distribuzione a Posteriori\nCalcoliamo la distribuzione a posteriori non normalizzata in logaritmo per evitare problemi di underflow numerico:\n\n# Calcolo del log-posteriori non normalizzato\nlog_posterior_unnormalized &lt;- log_likelihood + log(prior)\n\n# Normalizzazione per stabilità numerica\nlog_posterior_unnormalized &lt;- log_posterior_unnormalized - max(log_posterior_unnormalized)\n\n# Convertiamo in scala normale\nposterior_unnormalized &lt;- exp(log_posterior_unnormalized)\n\nNormalizziamo la distribuzione a posteriori:\n\n# Calcolo del passo nella griglia\ndelta_lambda &lt;- diff(lambda_grid)[1] # Assumendo che la griglia sia equispaziata\n\n# Normalizzazione della distribuzione a posteriori\nposterior &lt;-\n  posterior_unnormalized / sum(posterior_unnormalized * delta_lambda)\n\n\n53.3.4 Visualizzazione dei Risultati\n\n# Grafico della distribuzione a posteriori e a priori\nplot(lambda_grid, posterior,\n  type = \"l\",\n  lwd = 2,\n  xlab = expression(lambda),\n  ylab = \"Densità di probabilità\",\n  main = \"Distribuzione a Posteriori di λ\"\n)\nlines(lambda_grid, prior, lwd = 2, lty = 2)\nlegend(\"topright\",\n  legend = c(\"Posteriori\", \"Priori\"),\n  lty = c(1, 2), \n  lwd = 2, \n  bty = \"n\"\n)\n\n\n\n\n\n\n\nDal grafico, possiamo osservare come la distribuzione a posteriori di \\(\\lambda\\) sia aggiornata rispetto alla distribuzione a priori in base ai dati osservati. La distribuzione a posteriori riflette sia le informazioni a priori sia l’evidenza fornita dai dati, fornendo una stima aggiornata del tasso di occorrenza degli episodi di ansia.\n\n53.3.5 Calcolo della Media e Varianza Posteriori\nPossiamo calcolare la media e la varianza a posteriori di \\(\\lambda\\) utilizzando la distribuzione a posteriori calcolata sulla griglia.\n\n# Calcolo della media a posteriori di λ\nposterior_mean_lambda &lt;- sum(lambda_grid * posterior * delta_lambda)\n\n# Calcolo della varianza a posteriori di λ\nposterior_variance_lambda &lt;-\n  sum((lambda_grid - posterior_mean_lambda)^2 * posterior * delta_lambda)\n\n# Stampiamo i risultati\ncat(\"Media a posteriori di λ:\", posterior_mean_lambda, \"\\n\")\n#&gt; Media a posteriori di λ: 0.4612\ncat(\"Varianza a posteriori di λ:\", posterior_variance_lambda, \"\\n\")\n#&gt; Varianza a posteriori di λ: 0.01377\n\n\n53.3.6 Stima del Tempo di Attesa Medio a Posteriori\nUtilizzando la media a posteriori di \\(\\lambda\\), possiamo stimare il tempo di attesa medio a posteriori:\n\n# Stima del tempo di attesa medio a posteriori\nposterior_mean_waiting_time &lt;- 1 / posterior_mean_lambda\ncat(\"Tempo di attesa medio a posteriori:\", posterior_mean_waiting_time, \"ore\\n\")\n#&gt; Tempo di attesa medio a posteriori: 2.168 ore\n\nIn conclusione, attraverso il metodo basato su griglia, abbiamo derivato la distribuzione a posteriori del tasso di occorrenza \\(\\lambda\\), tenendo conto della nostra conoscenza a priori e dei dati osservati. Questo approccio ci permette di aggiornare le nostre credenze su \\(\\lambda\\) in modo coerente con l’evidenza empirica, fornendo stime più accurate e affidabili.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Modello gamma-esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/12_gamma_exponential_model.html#modello-coniugato-gamma-esponenziale",
    "href": "chapters/bayesian_inference/12_gamma_exponential_model.html#modello-coniugato-gamma-esponenziale",
    "title": "53  Modello gamma-esponenziale",
    "section": "\n53.4 Modello Coniugato Gamma-Esponenziale",
    "text": "53.4 Modello Coniugato Gamma-Esponenziale\nQuando utilizziamo una distribuzione \\(\\text{Gamma}(\\alpha, \\beta)\\) come distribuzione coniugata a priori, la distribuzione a posteriori risulta anch’essa essere una distribuzione Gamma, con parametri aggiornati \\(\\alpha + n\\) e \\(\\beta + \\sum_{i=1}^{n} x_{i}\\).\nIn altre parole, se il parametro \\(\\lambda\\) della distribuzione esponenziale segue una distribuzione a priori Gamma con parametri \\(\\alpha\\) e \\(\\beta\\), allora, dopo aver osservato un campione di \\(n\\) osservazioni \\(x_1, x_2, \\dots, x_n\\), la distribuzione a posteriori di \\(\\lambda\\) sarà ancora una distribuzione Gamma, ma con i parametri aggiornati:\n\\[\n\\lambda \\mid x \\sim \\text{Gamma}(\\alpha + n, \\beta + \\sum_{i=1}^{n} x_{i}).\n\\]\nQuesto aggiornamento dei parametri è una conseguenza della proprietà coniugata della distribuzione Gamma rispetto alla distribuzione esponenziale.\n\n53.4.1 Dimostrazione del Modello Coniugato Gamma-Esponenziale\nPer dimostrare questo risultato, partiamo dal teorema di Bayes:\n\\[\nf(\\lambda \\mid x) \\propto f(x \\mid \\lambda) \\cdot f(\\lambda),\n\\]\ndove \\(f(\\lambda \\mid x)\\) è la distribuzione a posteriori di \\(\\lambda\\) dato il campione \\(x\\), \\(f(x \\mid \\lambda)\\) è la verosimiglianza basata sul campione \\(x\\), e \\(f(\\lambda)\\) è la distribuzione a priori di \\(\\lambda\\).\nLa funzione di verosimiglianza per un campione di \\(n\\) osservazioni indipendenti \\(x_1, x_2, \\dots, x_n\\), che seguono una distribuzione esponenziale con parametro \\(\\lambda\\), è data da:\n\\[\nf(x \\mid \\lambda) = \\prod_{i=1}^{n} \\lambda e^{-\\lambda x_i} = \\lambda^n e^{-\\lambda \\sum_{i=1}^{n} x_i}.\n\\]\nSupponiamo che il parametro \\(\\lambda\\) segua una distribuzione a priori Gamma con parametri \\(\\alpha\\) e \\(\\beta\\):\n\\[\nf(\\lambda) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} \\lambda^{\\alpha - 1} e^{-\\beta \\lambda}.\n\\]\nMoltiplicando la verosimiglianza per la distribuzione a priori, otteniamo la distribuzione a posteriori:\n\\[\nf(\\lambda \\mid x) \\propto \\lambda^n e^{-\\lambda \\sum_{i=1}^{n} x_i} \\cdot \\lambda^{\\alpha - 1} e^{-\\beta \\lambda}.\n\\]\nSemplificando, si ottiene:\n\\[\nf(\\lambda \\mid x) \\propto \\lambda^{n + \\alpha - 1} e^{-\\lambda \\left(\\beta + \\sum_{i=1}^{n} x_i\\right)}.\n\\]\nQuesta espressione corrisponde alla forma di una distribuzione Gamma con parametri aggiornati:\n\nparametro della forma (alpha): \\(\\alpha_{\\text{post}} = \\alpha + n\\);\nparametro della scala (beta): \\(\\beta_{\\text{post}} = \\beta + \\sum_{i=1}^{n} x_i\\).\n\nQuindi, la distribuzione a posteriori di \\(\\lambda\\) dato il campione \\(x\\) segue una distribuzione Gamma con parametri aggiornati:\n\\[\n\\lambda \\mid x \\sim \\text{Gamma}(\\alpha + n, \\beta + \\sum_{i=1}^{n} x_i).\n\\]\nQuesta derivazione mostra come l’informazione contenuta nei dati osservati venga incorporata nei parametri della distribuzione a posteriori, mantenendo la forma della distribuzione a priori grazie alla proprietà coniugata.\n\n53.4.2 Calcolo dei Parametri Aggiornati\nPer il caso dell’esempio in discussione:\n\nIl numero di osservazioni nel campione \\(n\\) è 15;\nLa somma delle osservazioni nel campione è:\n\n\\[\n\\sum_{i=1}^{n} y_i =\n1 + 9 + 4 + 3 + 1 + 1 + 0 + 6 + 3 + 4 + 0 + 11 + 5 + 1 + 1 = 50.\n\\]\nLa distribuzione a posteriori per \\(\\lambda\\) segue una distribuzione Gamma aggiornata con i seguenti parametri:\n\\[\n\\alpha_{\\text{post}} = \\alpha_{\\text{prior}} + n,\n\\]\n\\[\n\\beta_{\\text{post}} = \\beta_{\\text{prior}} + \\sum_{i=1}^{n} y_i.\n\\]\nUsando i valori \\(\\alpha_{\\text{prior}} = 0.009\\) e \\(\\beta_{\\text{prior}} = 0.03\\), otteniamo:\n\\[\n\\alpha_{\\text{post}} = 0.009 + 15 = 15.009,\n\\]\n\\[\n\\beta_{\\text{post}} = 0.03 + 50 = 50.03.\n\\]\n\n# Dati iniziali\nalpha_prior &lt;- 0.009\nbeta_prior &lt;- 0.03\nn &lt;- 15\ny &lt;- c(1, 9, 4, 3, 1, 1, 0, 6, 3, 4, 0, 11, 5, 1, 1)\nsum_y &lt;- sum(y)\n\n# Parametri aggiornati\nalpha_post &lt;- alpha_prior + n\nbeta_post &lt;- beta_prior + sum_y\n\n# Stampa dei parametri aggiornati\ncat(sprintf(\"alpha_post = %.3f; beta_post = %.3f\\n\", alpha_post, beta_post))\n#&gt; alpha_post = 15.009; beta_post = 50.030\n\nGeneriamo il grafico della distribuzione a posteriori.\n\n# Griglia di valori di lambda per il grafico\nlambda_grid &lt;- seq(0, 2, length.out = 1000)\n\n# Calcolo della densità della distribuzione Gamma a posteriori\nposterior_pdf &lt;- dgamma(lambda_grid, shape = alpha_post, rate = beta_post)\n\n# Creazione del grafico\nplot(\n  lambda_grid, posterior_pdf,\n  type = \"l\", lwd = 2,\n  main = bquote(\n    \"Distribuzione Gamma a Posteriori con \" ~ alpha[post] ==\n      .(alpha_post) ~ \",\" ~ beta[post] == .(beta_post)\n  ),\n  xlab = expression(lambda), ylab = \"Densità di probabilità\"\n)\nlegend(\n  \"topright\",\n  legend = bquote(\n    Gamma(alpha[post] == .(alpha_post) ~ \",\" ~ beta[post] == .(beta_post))\n  ),\n  lty = 1,\n  lwd = 2,\n  bty = \"n\"\n)\n\n\n\n\n\n\n\n\n53.4.3 Calcolo della Media e della Varianza a Posteriori\nLa media e la varianza della distribuzione a posteriori sono calcolate come:\n\\[\n\\text{E}[\\lambda \\mid y] = \\frac{\\alpha_{\\text{post}}}{\\beta_{\\text{post}}},\n\\]\n\\[\n\\text{Var}[\\lambda \\mid y] = \\frac{\\alpha_{\\text{post}}}{\\beta_{\\text{post}}^2}.\n\\]\nIn R:\n\n# Calcolo della media e della varianza a posteriori\nposterior_mean &lt;- alpha_post / beta_post\nposterior_variance &lt;- alpha_post / (beta_post^2)\n\n# Stampa dei risultati\ncat(sprintf(\"Media a posteriori di λ: %.3f\\n\", posterior_mean))\n#&gt; Media a posteriori di λ: 0.300\ncat(sprintf(\"Varianza a posteriori di λ: %.6f\\n\", posterior_variance))\n#&gt; Varianza a posteriori di λ: 0.005996\n\nLa distribuzione a posteriori di \\(\\lambda\\) è aggiornata in base ai dati osservati e al prior. La media a posteriori rappresenta la stima del tasso di occorrenza degli episodi di ansia, mentre la varianza riflette l’incertezza nella stima.\n\n\nMedia a Posteriori: La media a posteriori di \\(\\lambda\\) è circa 0.3, indicando un tasso di occorrenza medio di 0.3 episodi per ora.\n\nVarianza a Posteriori: La varianza di 0.006 riflette una moderata incertezza nella stima di \\(\\lambda\\).\n\nQuesti risultati evidenziano come la distribuzione Gamma aggiornata combini informazioni a priori e dati osservati per ottenere stime robuste del tasso di occorrenza \\(\\lambda\\).\n\n53.4.4 Trasformazione della media e della varianza\nPer interpretare questi risultati in termini di tempi di attesa, dobbiamo trasformare i valori sulla scala inversa, cioè passare dal tasso \\(\\lambda\\) ai tempi di attesa \\(T = \\frac{1}{\\lambda}\\).\nLa media del tempo di attesa \\(T\\) è l’inverso della media del tasso di occorrenza \\(\\lambda\\). Pertanto, la media dei tempi di attesa sarà:\n\\[\n\\text{E}[T \\mid y] = \\frac{1}{\\text{E}[\\lambda \\mid y]} = \\frac{1}{0.3} \\approx 3.33 \\, \\text{ore}.\n\\]\nPer la varianza del tempo di attesa, dobbiamo applicare una trasformazione più complessa. La varianza del tempo di attesa \\(T\\) è legata alla varianza di \\(\\lambda\\) da:\n\\[\n\\text{Var}(T) = \\frac{\\text{Var}[\\lambda \\mid y]}{(\\text{E}[\\lambda \\mid y])^4}.\n\\]\nSostituendo i valori calcolati per la varianza e la media di \\(\\lambda\\), otteniamo:\n\\[\n\\text{Var}(T) \\approx \\frac{0.006}{(0.3)^4} \\approx 24.59 \\, \\text{ore}.\n\\]\nIn conclusione,\n\nla media del tempo di attesa a posteriori è di circa 3.33 ore;\nla varianza del tempo di attesa a posteriori è di circa 24.59 ore, che indica una certa dispersione dei tempi di attesa, con alcuni episodi che possono verificarsi molto più rapidamente o più lentamente rispetto alla media. Si noti che la distribuzione a posteriori è più concentrata rispetto al prior, poiché incorpora l’informazione aggiuntiva proveniente dai dati osservati.\n\nQuesta trasformazione ci permette di interpretare i risultati sulla scala dei tempi di attesa, che è più intuitiva per descrivere fenomeni psicologici come l’insorgenza di episodi di ansia.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Modello gamma-esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/12_gamma_exponential_model.html#applicazioni",
    "href": "chapters/bayesian_inference/12_gamma_exponential_model.html#applicazioni",
    "title": "53  Modello gamma-esponenziale",
    "section": "\n53.5 Applicazioni",
    "text": "53.5 Applicazioni\nUna volta ottenuta la distribuzione a posteriori per λ, possiamo utilizzarla per rispondere a domande probabilistiche relative ai tempi di attesa tra episodi di ansia. Questo approccio ci consente di calcolare probabilità aggiornate alla luce dei dati osservati, rispecchiando meglio l’incertezza e le informazioni disponibili. Ad esempio, possiamo stimare la probabilità di osservare tempi di attesa compresi tra 2 e 5 ore.\nPer risolvere questo problema possiamo usare il metodo Monte Carlo:\n\nGeneriamo un gran numero di campioni dalla distribuzione Gamma a posteriori di \\(\\lambda\\), usando i parametri \\(\\alpha_{\\text{posteriori}}\\) e \\(\\beta_{\\text{posteriori}}\\).\nConvertiamo ciascun \\(\\lambda\\) campionato in un tempo di attesa \\(T = \\frac{1}{\\lambda}\\).\nCalcoliamo le probabilità richieste (ad esempio, \\(P(T &gt; 2)\\) e \\(P(T &lt; 5)\\)) semplicemente contando le proporzioni di campioni che soddisfano tali condizioni.\n\n\n53.5.1 Simulazione con Monte Carlo\nUtilizziamo i parametri posteriori della distribuzione Gamma per simulare campioni di \\(\\lambda\\) e calcolare la probabilità che il tempo di attesa tra due episodi di ansia sia compreso tra 2 e 5 ore.\n\n# Parametri posteriori per la distribuzione Gamma\nalpha_post &lt;- 15.009\nbeta_post &lt;- 50.03\n\n# Numero di campioni da generare\nn_samples &lt;- 100000\n\n# Simulazione di campioni dalla distribuzione Gamma per λ\nlambda_samples &lt;- rgamma(n_samples, shape = alpha_post, rate = beta_post)\n\n# Conversione dei campioni di λ in tempi di attesa T = 1/λ\nwaiting_time_samples &lt;- 1 / lambda_samples\n\n# Calcolo della probabilità che il tempo di attesa sia compreso tra 2 e 5 ore\nprob_between_2_and_5_mc &lt;-\n  mean(waiting_time_samples &gt;= 2 & waiting_time_samples &lt;= 5)\n\n# Stampa del risultato\ncat(sprintf(\"Probabilità che il tempo di attesa sia tra 2 e 5 ore: %.4f\\n\", prob_between_2_and_5_mc))\n#&gt; Probabilità che il tempo di attesa sia tra 2 e 5 ore: 0.9027\n\nLa probabilità che il tempo di attesa tra due episodi di ansia sia compreso tra 2 e 5 ore è di circa 0.9029, ovvero il 90.3%. Questa stima si basa su campioni simulati dalla distribuzione a posteriori di \\(\\lambda\\), trasformati nei corrispondenti tempi di attesa. L’approccio Monte Carlo è utile per calcolare probabilità che coinvolgono trasformazioni non lineari, come nel caso del tempo di attesa.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Modello gamma-esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/12_gamma_exponential_model.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/12_gamma_exponential_model.html#riflessioni-conclusive",
    "title": "53  Modello gamma-esponenziale",
    "section": "\n53.6 Riflessioni Conclusive",
    "text": "53.6 Riflessioni Conclusive\nIl modello esponenziale si rivela uno strumento utile e versatile nella ricerca psicologica, in particolare per la modellazione di fenomeni caratterizzati da tempi di attesa o durate di eventi. È applicabile in vari contesti, tra cui l’analisi dei tempi di reazione, lo studio degli intervalli tra episodi di ansia o depressione e, più in generale, in tutti quei processi psicologici che possono essere descritti come il tempo trascorso fino al verificarsi di un evento.\nUn aspetto particolarmente vantaggioso dell’uso di modelli basati sulla distribuzione esponenziale nell’inferenza bayesiana è la possibilità di utilizzare le famiglie coniugate. Nella famiglia coniugata Gamma-Esponenziale, la distribuzione a priori Gamma per il tasso \\(\\lambda\\) si aggiorna in modo analitico quando si osservano nuovi dati esponenziali. Questo rende i calcoli bayesiani particolarmente efficienti e semplici da implementare, poiché la distribuzione a posteriori rimane della stessa forma della distribuzione a priori (ossia, una Gamma). Tale proprietà coniugata consente di ottenere una stima aggiornata del tasso \\(\\lambda\\) e di fare inferenze accurate sui tempi di attesa futuri.\nLa combinazione tra la distribuzione esponenziale e il prior Gamma non solo semplifica l’inferenza, ma fornisce anche una struttura interpretativa chiara. Ad esempio, il parametro \\(\\lambda\\), che rappresenta il tasso di occorrenza di un fenomeno, viene aggiornato sulla base dell’evidenza osservata, consentendo una stima dinamica della frequenza con cui gli episodi si verificano. Questo approccio bayesiano offre un’interpretazione probabilistica naturale dei tempi di attesa futuri, rispecchiando l’incertezza presente nei dati.\nInoltre, grazie alla flessibilità del metodo Monte Carlo, è possibile simulare campioni dalla distribuzione a posteriori di \\(\\lambda\\) e ottenere stime precise per una vasta gamma di probabilità, come la probabilità che il tempo di attesa sia compreso tra intervalli specifici. Questo approccio simulativo permette di rispondere a domande specifiche relative ai processi psicologici, ad esempio la probabilità che un episodio di ansia duri più di un certo numero di ore.\nIn conclusione, il modello esponenziale, integrato in un framework bayesiano con famiglie coniugate, rappresenta un utile strumento per la ricerca psicologica. Offre un modo rigoroso per modellare e analizzare dati su tempi di attesa e durate, fornendo al contempo una base solida per l’inferenza e la previsione dei processi psicologici.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Modello gamma-esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/12_gamma_exponential_model.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/12_gamma_exponential_model.html#informazioni-sullambiente-di-sviluppo",
    "title": "53  Modello gamma-esponenziale",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.7   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.13.0 psych_2.5.3     \n#&gt;  [9] scales_1.4.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.3.0     ggplot2_3.5.2   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.4     stringi_1.8.7      lattice_0.22-7    \n#&gt;  [4] hms_1.1.3          digest_0.6.37      magrittr_2.0.3    \n#&gt;  [7] evaluate_1.0.4     grid_4.5.0         timechange_0.3.0  \n#&gt; [10] RColorBrewer_1.1-3 fastmap_1.2.0      rprojroot_2.0.4   \n#&gt; [13] jsonlite_2.0.0     mnormt_2.1.1       cli_3.6.5         \n#&gt; [16] rlang_1.1.6        withr_3.0.2        tools_4.5.0       \n#&gt; [19] parallel_4.5.0     tzdb_0.5.0         pacman_0.5.1      \n#&gt; [22] vctrs_0.6.5        R6_2.6.1           lifecycle_1.0.4   \n#&gt; [25] htmlwidgets_1.6.4  pkgconfig_2.0.3    pillar_1.10.2     \n#&gt; [28] gtable_0.3.6       glue_1.8.0         xfun_0.52         \n#&gt; [31] tidyselect_1.2.1   rstudioapi_0.17.1  farver_2.1.2      \n#&gt; [34] htmltools_0.5.8.1  nlme_3.1-168       rmarkdown_2.29    \n#&gt; [37] compiler_4.5.0",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Modello gamma-esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/13_prior_pred_check.html",
    "href": "chapters/bayesian_inference/13_prior_pred_check.html",
    "title": "54  Controllo predittivo a priori",
    "section": "",
    "text": "Introduzione\nUno strumento essenziale per questa verifica è il controllo predittivo a priori (prior predictive check, PPC; Gelman et al. (2020)).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Controllo predittivo a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/13_prior_pred_check.html#introduzione",
    "href": "chapters/bayesian_inference/13_prior_pred_check.html#introduzione",
    "title": "54  Controllo predittivo a priori",
    "section": "",
    "text": "Nell’analisi bayesiana, la specificazione della distribuzione a priori (prior) rappresenta un passaggio cruciale e delicato. Attraverso la prior, formalizziamo matematicamente le nostre convinzioni o aspettative riguardo ai parametri del modello prima di osservare i dati. Ma come possiamo valutare se la nostra scelta è appropriata?\n\n\n\n54.0.1 L’idea fondamentale\nIl prior predictive check si basa su una domanda chiave:\n\nSe questa distribuzione a priori riflette davvero le nostre aspettative, quali dati dovremmo osservare in pratica?\n\nIn altre parole, simuliamo dati plausibili generati dal modello prima di analizzare i dati reali, per verificare se le nostre assunzioni iniziali producono risultati coerenti con la realtà teorica o empirica del fenomeno studiato.\n\n54.0.2 Perché è importante?\nNei modelli bayesiani, le distribuzioni a priori codificano la nostra conoscenza (o ignoranza) preliminare. Tuttavia:\n\n\nprior apparentemente innocue possono, combinate con il modello di verosimiglianza, generare previsioni implausibili (es., valori al di fuori del range possibile, comportamenti estremi non realistici);\n\n\nprior troppo informative possono dominare ingiustificatamente l’evidenza dei dati, mentre prior troppo vaghe possono portare a stime instabili.\n\nIl prior predictive check ci permette di esplorare la distribuzione predittiva a priori, \\(p(\\tilde{y})\\), dove \\(\\tilde{y}\\) sono dati simulati, per identificare incongruenze prima della fase inferenziale.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Controllo predittivo a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/13_prior_pred_check.html#la-definizione-formale",
    "href": "chapters/bayesian_inference/13_prior_pred_check.html#la-definizione-formale",
    "title": "54  Controllo predittivo a priori",
    "section": "\n54.1 La definizione formale",
    "text": "54.1 La definizione formale\nNon conoscendo i parametri \\(\\theta\\), non possiamo formulare un’unica predizione \\(p(\\tilde y \\mid \\theta)\\). Invece, la distribuzione predittiva a priori \\(p(\\tilde y)\\) combina le predizioni di tutti i possibili valori di \\(\\theta\\), pesandoli in base alla loro plausibilità a priori.\nÈ come consultare un gruppo di esperti (i possibili \\(\\theta\\)) e aggregare i loro giudizi, ponderandoli in base a quanto li riteniamo affidabili prima di osservare qualsiasi dato. La formula che descrive questo processo è:\n\\[\np(\\tilde y \\mid \\text{prior}) = \\int p(\\tilde y \\mid \\theta)\\, p(\\theta)\\, d\\theta .\n\\tag{54.1}\\]\nQuesto integrale rappresenta una combinazione (mixture) di distribuzioni.1 Non stiamo calcolando una media aritmetica di singoli valori di \\(\\tilde y\\), ma piuttosto mescolando intere distribuzioni condizionate \\(p(\\tilde y \\mid \\theta)\\), ciascuna ponderata dalla sua probabilità a priori \\(p(\\theta)\\).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Controllo predittivo a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/13_prior_pred_check.html#implementazione-e-valutazione-del-ppc",
    "href": "chapters/bayesian_inference/13_prior_pred_check.html#implementazione-e-valutazione-del-ppc",
    "title": "54  Controllo predittivo a priori",
    "section": "\n54.2 Implementazione e valutazione del PPC",
    "text": "54.2 Implementazione e valutazione del PPC\nPer verificare l’adeguatezza della distribuzione a priori, seguiamo un approccio sistematico:\n\nDefinizione del modello generativo\nSi stabilisce la relazione tra parametri e dati attraverso la verosimiglianza \\(p(y \\mid \\theta)\\), includendo eventuali funzioni di collegamento (logit, log) necessarie per garantire coerenza con il dominio delle variabili.\nSpecificazione della distribuzione a priori\nLe prior dovrebbero riflettere conoscenze preliminari debolmente informative, adattate alla scala naturale del problema. Per parametri con vincoli naturali (es., deviazioni standard positive), si utilizzano distribuzioni a supporto ristretto (half-normal, esponenziale).\n\nSimulazione della distribuzione predittiva\nPer ciascuna iterazione:\n\nsi campiona un insieme di parametri \\(\\theta^{(s)}\\) dalla prior \\(p(\\theta)\\),\n\nsi generano dati sintetici \\(\\tilde{y}^{(s)}\\) dalla verosimiglianza \\(p(y \\mid \\theta^{(s)})\\).\nL’insieme delle simulazioni \\(\\{\\tilde{y}^{(s)}\\}_{s=1}^S\\) approssima la distribuzione predittiva a priori.\n\n\n\nValidazione empirica\nLe simulazioni vengono confrontate con i vinciti teorici del problema:\n\n\nAderenza al dominio: I valori simulati devono rispettare i limiti naturali della variabile (es., probabilità in [0,1], tempi positivi).\n\n\nRealismo quantitativo: Gli ordini di grandezza devono essere plausibili per il fenomeno studiato.\n\n\nComportamento distributivo: La dispersione e la forma della distribuzione devono essere coerenti con l’aspettativa teorica.\n\n\n\n\n\n\n\n\n\nCaso studio: modellazione di risposte dicotomiche\n\n\n\n\n\nSupponiamo di analizzare la probabilità \\(p\\) di successo in un test psicometrico. La scelta della prior per \\(p\\) influenza direttamente le previsioni del modello:\n\nPrior estrema (es. Beta(0.1, 0.1)):\nAssume che le risposte siano quasi sempre corrette o quasi sempre errate, implicando una popolazione con prestazioni polarizzate. Le simulazioni mostrerebbero prevalentemente tassi di successo vicini a 0% o 100%, scenario spesso irrealistico in contesti educativi.\nPrior bilanciata (es. Beta(2, 2)):\nRiflette l’aspettativa che le risposte siano distribuite attorno al 50%, analogamente al lancio di una moneta equa. Le simulazioni genererebbero una variabilità più plausibile per popolazioni eterogenee.\n\nValidazione attraverso simulazioni.\nIl prior predictive check rivela queste implicazioni:\n\nGenerando dati sintetici con la prior estrema, si osserverebbero distribuzioni bimodali con picchi agli estremi, incongruenti con il comportamento atteso in molti studi psicologici.\n\nCon la prior bilanciata, le simulazioni mostrerebbero invece una dispersione centrata attorno a valori intermedi, coerente con una popolazione mista.\n\nRicalibrazione: Se le simulazioni risultano implausibili (es., &gt;30% di valori estremi non giustificati dalla teoria), si può:\n\nmodificare i parametri della prior (es., passare a Beta(1, 1) per ridurre le assunzioni a priori);\nintrodurre trasformazioni (es., logit per evitare valori al di fuori di [0,1]);\n\nadottare prior gerarchiche per catturare eterogeneità sottogruppo.\n\nProspettiva epistemologica.\nIl processo equivale a:\n\nformalizzare le ipotesi iniziali in termini probabilistici (scelta della prior);\n\nverificarne le conseguenze empiriche attraverso simulazioni;\n\nrivalutare criticamente le assunzioni alla luce delle previsioni generate.\n\nQuesto approccio previene errori comuni nell’analisi bayesiana, come l’uso involontario di prior che sovradeterminano i risultati o generano artefatti. La coerenza tra simulazioni a priori e conoscenza di dominio è un indicatore chiave della robustezza del modello.\n\n\n\n\n\n\n\n\n\nRegola pratica: Una prior adeguata non deve essere “perfetta”, ma deve produrre scenari plausibili. Se le simulazioni appaiono sistematicamente lontane dalla realtà teorica, la specificazione del modello va ripensata, non i dati osservati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Controllo predittivo a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/13_prior_pred_check.html#esempio-un-test-a-10-domande",
    "href": "chapters/bayesian_inference/13_prior_pred_check.html#esempio-un-test-a-10-domande",
    "title": "54  Controllo predittivo a priori",
    "section": "\n54.3 Esempio: un test a 10 domande",
    "text": "54.3 Esempio: un test a 10 domande\nQuesto esempio mostra bene l’idea di fondo: una prior sui parametri (competenza media e variabilità tra studenti) implica predizioni sui punteggi osservabili. Se la prior assegna troppa probabilità a esiti come 0/10 o 10/10 senza basi empiriche, significa che sta “spingendo” verso scenari estremi.\nImmaginiamo uno studente che affronta un test di 10 domande. Il numero di risposte corrette segue una binomiale:\n\\[\ny \\sim \\text{Binomiale}(n=10, p),\n\\]\ndove \\(p\\) è la probabilità di risposta corretta a una singola domanda. La prior agisce su \\(p\\), ma ciò che osserviamo sono i punteggi \\(y\\): il prior predictive check trasferisce l’incertezza su \\(p\\) alla distribuzione dei punteggi.\n\n54.3.1 Scenario 1: prior debole (alta incertezza)\nSe scegliamo una prior molto larga, lasciamo spazio anche a valori estremi di \\(p\\). Un esempio comune è la prior Beta(2,2):\n\nmedia: \\(E[p] = 0.5\\),\nvarianza relativamente ampia,\nequivalente a 4 risposte “immaginarie” (2 corrette e 2 errate).\n\nQuesta prior favorisce valori centrali, ma consente anche valori vicini a 0 e 1. La predittiva a priori \\(y \\mid p \\sim \\text{Binom}(10,p)\\) diventa una Beta–Binomiale, che simula punteggi variabili da 0 a 10.\n\nn &lt;- 10; S &lt;- 10000\np_sim &lt;- rbeta(S, 2, 2)\ny_sim &lt;- rbinom(S, size = n, prob = p_sim)\n\ntibble(y_sim) |&gt;\n  ggplot(aes(x = y_sim)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 11) +\n  labs(title = \"Predittiva a priori con Beta(2,2)\",\n       x = \"Numero di risposte corrette su 10\", y = \"Densità\")\n\n\n\n\n\n\n\nLettura. Stiamo immaginando studenti molto eterogenei: alcuni quasi sempre corretti, altri quasi sempre sbagliati, altri a metà. Il modello produce punteggi estremi (0 o 10) più spesso di quanto ci aspetteremmo nella realtà: segnale che la prior è troppo permissiva.\n\n54.3.2 Scenario 2: prior informativa (studente preparato)\nSupponiamo invece di credere che gli studenti siano mediamente preparati. Una prior plausibile è Beta(10,3):\n\nmedia circa 0.77,\nvarianza più contenuta,\nequivalente a 13 risposte “immaginarie” (10 corrette e 3 errate).\n\nQuesta prior concentra le probabilità su valori alti di \\(p\\), traducendosi in punteggi tipici tra 6 e 9 risposte corrette.\n\np_buono &lt;- rbeta(S, 10, 3)\ny_buono &lt;- rbinom(S, size = n, prob = p_buono)\n\ntibble(y_buono) |&gt;\n  ggplot(aes(x = y_buono)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 11) +\n  labs(title = \"Predittiva a priori con Beta(10,3)\",\n       x = \"Numero di risposte corrette su 10\", y = \"Densità\")\n\n\n\n\n\n\n\nLettura. I punteggi estremamente bassi (0–3) diventano improbabili, mentre le distribuzioni si concentrano su esiti più realistici per studenti preparati.\n\n54.3.3 Perché è utile?\nIl confronto tra scenari evidenzia che la prior non è solo un dettaglio tecnico: traduce in probabilità ciò che riteniamo plausibile sul comportamento degli studenti.\n\nSe i dati simulati sembrano irrealistici (molti 0/10 inattesi), la prior va corretta.\nSe i dati simulati sono coerenti con le aspettative, la prior è adeguata.\n\nIl PPC diventa così un ponte tra formule e fenomeni concreti: rende trasparente la scelta dei modelli e permette di diagnosticare eventuali incoerenze prima di analizzare i dati reali.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Controllo predittivo a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/13_prior_pred_check.html#ppc-con-brms",
    "href": "chapters/bayesian_inference/13_prior_pred_check.html#ppc-con-brms",
    "title": "54  Controllo predittivo a priori",
    "section": "\n54.4 PPC con brms\n",
    "text": "54.4 PPC con brms\n\nFinora abbiamo simulato con le funzioni di base in R. Con brms possiamo ottenere lo stesso effetto in modo più diretto, semplicemente specificando l’opzione sample_prior = \"only\". Così non usiamo alcun dato reale: generiamo punteggi solo dalla prior.\n\nn_students &lt;- 50\nn_items &lt;- 10\n\ndummy_data &lt;- tibble(\n  correct  = 0L,   # segnaposto: serve per la sintassi\n  n_trials = n_items\n) |&gt; slice(rep(1, n_students))\n\npriors &lt;- c(\n  prior(normal(0, 1.5), class = \"Intercept\") # prior su logit(p)\n)\n\nfit_prior_only &lt;- brm(\n  bf(correct | trials(n_trials) ~ 1),\n  data = dummy_data,\n  family = binomial(),\n  prior = priors,\n  sample_prior = \"only\",  # &lt;-- prior predictive\n  chains = 4, iter = 1000, cores = 4,\n  backend = \"cmdstanr\", seed = 123\n)\n\n\nyrep &lt;- posterior_predict(fit_prior_only)\nppc_bars(y = rep(0, n_students), yrep = yrep[1:200, ]) +\n  ggtitle(\"Prior predictive check (binomiale, intercetta-logit)\")\n\n\n\n\n\n\n\nInterpretazione.\n\nLa prior Normal(0,1.5) è posta sull’intercetta in scala logit.\nIn pratica significa che la probabilità di risposta corretta \\(p\\) cade di solito tra ~0.05 e ~0.95: quindi escludiamo valori estremi (0 o 1) sistematici, ma restiamo aperti a una gamma ampia.\nIl grafico mostra quali distribuzioni di punteggi (0–10 su 10) consideriamo plausibili prima di vedere i dati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Controllo predittivo a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/13_prior_pred_check.html#ppc-con-stan",
    "href": "chapters/bayesian_inference/13_prior_pred_check.html#ppc-con-stan",
    "title": "54  Controllo predittivo a priori",
    "section": "\n54.5 PPC con Stan\n",
    "text": "54.5 PPC con Stan\n\nCon Stan possiamo fare lo stesso, ma in modo ancora più esplicito: specifichiamo solo la prior, senza likelihood, e simuliamo i dati fittizi nel blocco generated quantities. Questo serve a capire cosa accade sotto il cofano.\n\nbinom_prior_ppc_stan &lt;- '\ndata {\n  int&lt;lower=1&gt; N;           // numero di studenti fittizi\n  int&lt;lower=1&gt; n_items;     // numero di item per studente\n}\nparameters {\n  real alpha;               // intercetta in logit\n}\nmodel {\n  alpha ~ normal(0, 1.5);   // prior weakly-informative\n  // Nessuna likelihood: solo prior\n}\ngenerated quantities {\n  vector[N] p;              // probabilità individuali\n  array[N] int y_rep;       // punteggi simulati\n  for (i in 1:N) {\n    p[i] = inv_logit(alpha);            // da logit a probabilità\n    y_rep[i] = binomial_rng(n_items, p[i]);\n  }\n}\n'\nwriteLines(binom_prior_ppc_stan, \"binom_prior_ppc.stan\")\n\nCompiliamo e lanciamo:\n\nmod_binom &lt;- cmdstan_model(\"binom_prior_ppc.stan\")\nfit_binom &lt;- mod_binom$sample(\n  data = list(N = 100, n_items = 10),\n  chains = 4, iter_warmup = 500, iter_sampling = 1000,\n  seed = 123, refresh = 0\n)\n\nEstraiamo i punteggi simulati e guardiamo la distribuzione della media:\n\ndraws &lt;- fit_binom$draws(variables = \"y_rep\", format = \"draws_matrix\")\ny_rep &lt;- as_draws_matrix(draws)\n\ntibble(mu = rowMeans(y_rep)) |&gt;\n  ggplot(aes(x = mu)) +\n  geom_histogram(bins = 30) +\n  labs(title = \"Predittiva a priori (Stan, binomiale, intercetta-logit)\",\n       x = \"Media risposte corrette su 10\", y = \"Frequenza\")\n\n\n\n\n\n\n\n\n54.5.1 Lettura\n\nOgni iterazione estrae un valore di \\(\\alpha\\) dalla prior Normal(0,1.5).\nLo trasformiamo in probabilità di successo con \\(p = \\text{inv\\_logit}(\\alpha)\\).\nCon quel \\(p\\) simuliamo 10 risposte per 100 studenti fittizi.\nIl grafico mostra la distribuzione della media dei punteggi simulati.\n\nCosì vediamo chiaramente quali punteggi il modello considera plausibili solo sulla base della prior. Se avessimo scelto una prior più stretta (es. Normal(2,0.5) sul logit), i punteggi si sarebbero concentrati verso l’alto (più risposte corrette attese).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Controllo predittivo a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/13_prior_pred_check.html#esempi-di-modelli-più-complessi",
    "href": "chapters/bayesian_inference/13_prior_pred_check.html#esempi-di-modelli-più-complessi",
    "title": "54  Controllo predittivo a priori",
    "section": "\n54.6 Esempi di modelli più complessi",
    "text": "54.6 Esempi di modelli più complessi\nIn precedenza ci siamo occupati di modelli semplici, una singola proporzione. Vediamo ora esempi di modelli più complessi. L’obiettivo è mostrare come diverse prior sui parametri si traducano in implicazioni sui dati. Usiamo tre casi:\n\n\nModello gaussiano (intercetta e varianza);\n\nRegressione lineare (scala dei coefficienti e della varianza);\n\nRegressione logistica (scala dei coefficienti su logit e probabilità implicite).\n\n\n54.6.1 Modello gaussiano semplice\nIpotizziamo che il meccanismo generatore dei dati sia: \\(y \\sim \\mathcal{N}(\\mu, \\sigma)\\).\nDomanda: scelte di prior su \\(\\mu\\) e \\(\\sigma\\) producono esiti \\(y\\) plausibili per la tua variabile psicologica (es. punteggi 0–100)?\n\nS &lt;- 10000\n\n# Scenario A: prior molto larga\nmu_A    &lt;- rnorm(S, 50, 50)        # media plausibile ma molto incerta\nsigma_A &lt;- rexp(S, rate = 1/20)     # sigma ~ Exp(mean=20), molto larga\nyA      &lt;- rnorm(S, mu_A, sigma_A)\n\n# Scenario B: prior più informativa\nmu_B    &lt;- rnorm(S, 50, 10)\nsigma_B &lt;- rexp(S, rate = 1/10)     # mean=10\nyB      &lt;- rnorm(S, mu_B, sigma_B)\n\nbind_rows(\n  tibble(y = yA, scenario = \"A: prior larghissima\"),\n  tibble(y = yB, scenario = \"B: prior informativa\")\n) |&gt;\n  ggplot(aes(x = y, fill = scenario)) +\n  geom_density(alpha = 0.35) +\n  labs(title = \"Predittiva a priori (gaussiana)\",\n       x = \"y (es. punteggio 0–100)\", y = \"Densità\")\n\n\n\n\n\n\n\nLettura. Se i punteggi sono noti per essere tra 0 e 100, lo Scenario A potrebbe generare troppi valori negativi o &gt;100: prior da ritarare (più informativa su \\(\\mu\\) e/o \\(\\sigma\\)).\n\n54.6.1.1 Versione Stan: prior-only, generazione in generated quantities\n\n\ngauss_prior_ppc_stan &lt;- '\ndata {\n  int&lt;lower=1&gt; N;\n}\nparameters {\n  real mu;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  mu ~ normal(50, 10);\n  sigma ~ exponential(1.0/10); // mean 10\n}\ngenerated quantities {\n  vector[N] y_rep;\n  for (i in 1:N) {\n    y_rep[i] = normal_rng(mu, sigma);\n  }\n}\n'\nwriteLines(gauss_prior_ppc_stan, \"gauss_prior_ppc.stan\")\n\n\nmod_gauss &lt;- cmdstan_model(\"gauss_prior_ppc.stan\")\n\n\nfit_gauss &lt;- mod_gauss$sample(\n  data = list(N = 200),\n  chains = 4, iter_warmup = 500, iter_sampling = 1000, seed = 123,\n  refresh = 0\n)\n\n\nyrep_g &lt;- fit_gauss$draws(\"y_rep\", format = \"draws_matrix\")\nas_tibble(yrep_g) |&gt;\n  pivot_longer(everything(), values_to = \"y\") |&gt;\n  ggplot(aes(x = y)) +\n  geom_density() +\n  labs(title = \"Stan: predittiva a priori (gaussiana)\", x = \"y\", y = \"Densità\")\n\n\n\n\n\n\n\n\n54.6.2 Regressione lineare\nConsideriamo il modello generatore:\n\\[\ny = \\alpha + \\beta x + \\varepsilon, \\qquad \\varepsilon \\sim \\mathcal{N}(0,\\sigma).\n\\]\n\n54.6.2.1 Perché è interessante\nIn regressione, il significato di \\(\\beta\\) dipende dalla scala di \\(x\\):\n\nse \\(x\\) è standardizzato (media 0, deviazione standard 1), allora \\(\\beta\\) indica la variazione media di \\(y\\) per 1 deviazione standard di \\(x\\).\nad esempio, una prior \\(\\beta \\sim \\mathcal{N}(0,1)\\) equivale a dire: “effetti moderati sono plausibili; effetti oltre 3 deviazioni standard sono rari”.\n\nI prior predictive checks ci aiutano a rispondere a due domande:\n\nLe rette simulate generano valori di \\(y\\) compatibili con la scala del fenomeno?\nLa dispersione intorno alla retta (determinata da \\(\\sigma\\)) è realistica?\n\nSe la risposta è “no”, occorre rivedere la prior su \\(\\alpha,\\beta,\\sigma\\) o trasformare \\(y\\).\n\n54.6.2.2 Scenario C: prior troppo larga\nQui imponiamo varianze enormi su \\(\\alpha\\) e \\(\\beta\\). Risultato: i valori simulati di \\(y\\) diventano irrealistici (troppo negativi o troppo alti rispetto alla scala dei dati).\n\nS &lt;- 10000\nx  &lt;- runif(S, -2, 2)  # predittore standardizzato\n\nalpha_C &lt;- rnorm(S, 0, 10)\nbeta_C  &lt;- rnorm(S, 0, 10)\nsigma_C &lt;- rexp(S, rate = 1/5)  # media ~5\nyC      &lt;- rnorm(S, alpha_C + beta_C * x, sigma_C)\n\nLettura. Una prior enorme su \\(\\sigma\\) e su \\(\\beta\\) rende molto probabili valori assurdi per \\(y\\). Non è “essere umili”: è incoerente con il dominio empirico.\n\n54.6.2.3 Scenario D: prior weakly-informative\nQui scegliamo prior centrate e con varianze moderate.\n\n\n\\(\\alpha \\sim \\mathcal{N}(0,1)\\) e \\(\\beta \\sim \\mathcal{N}(0,1)\\): effetti possibili, ma non sproporzionati.\n\n\\(\\sigma \\sim \\text{Exp}(1/2)\\): media 2, compatibile con la variabilità tipica di punteggi psicologici standardizzati.\n\n\nalpha_D &lt;- rnorm(S, 0, 1)\nbeta_D  &lt;- rnorm(S, 0, 1)\nsigma_D &lt;- rexp(S, rate = 1/2)  # media ~2\nyD      &lt;- rnorm(S, alpha_D + beta_D * x, sigma_D)\n\nbind_rows(\n  tibble(y = yC, scenario = \"C: prior molto larga\"),\n  tibble(y = yD, scenario = \"D: prior W.I.\")\n) |&gt;\n  ggplot(aes(x = y, fill = scenario)) +\n  geom_density(alpha = 0.35) +\n  labs(title = \"Predittiva a priori (regressione lineare)\",\n       x = \"Valori simulati di y\", y = \"Densità\")\n\n\n\n\n\n\n\nLettura. Con prior weakly-informative, la distribuzione di \\(y\\) resta ampia ma plausibile. Con prior larghe, invece, \\(y\\) è disperso in modo irrealistico.\n\n54.6.2.4 Versione in Stan: prior-only\nPer rendere più esplicito il concetto, scriviamo un modello Stan in cui non inseriamo dati osservati: simuliamo soltanto dalla prior.\n\nlinear_prior_ppc_stan &lt;- '\ndata {\n  int&lt;lower=1&gt; N;\n  vector[N] x;\n}\nparameters {\n  real alpha;\n  real beta;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  alpha ~ normal(0, 1);\n  beta  ~ normal(0, 1);\n  sigma ~ exponential(1.0/2); // media 2\n}\ngenerated quantities {\n  vector[N] y_rep;\n  for (i in 1:N) {\n    y_rep[i] = normal_rng(alpha + beta * x[i], sigma);\n  }\n}\n'\nwriteLines(linear_prior_ppc_stan, \"linear_prior_ppc.stan\")\n\nEseguiamo la simulazione:\n\nmod_lin &lt;- cmdstan_model(\"linear_prior_ppc.stan\")\nx_new   &lt;- runif(200, -2, 2)\n\nfit_lin &lt;- mod_lin$sample(\n  data = list(N = length(x_new), x = x_new),\n  chains = 4, iter_warmup = 500, iter_sampling = 1000, seed = 123,\n  refresh = 0\n)\n\nVisualizziamo la distribuzione di \\(y\\):\n\nyrep_l &lt;- fit_lin$draws(\"y_rep\", format = \"draws_matrix\")\nas_tibble(yrep_l) |&gt;\n  pivot_longer(everything(), values_to = \"y\") |&gt;\n  ggplot(aes(x = y)) +\n  geom_density() +\n  labs(title = \"Stan: predittiva a priori (regressione lineare)\",\n       x = \"Valori simulati di y\", y = \"Densità\")\n\n\n\n\n\n\n\n\n54.6.2.5 Cosa impariamo\n\nLa scala delle prior su \\(\\alpha,\\beta,\\sigma\\) determina la scala dei dati simulati.\nSe i valori di \\(y\\) simulati sono fuori dal dominio realistico (es. punteggi &lt; 0 o &gt; 100), i prior vanno rivisti.\nCon prior weakly-informative (centrati, varianza moderata), le simulazioni diventano coerenti col contesto psicologico.\n\n54.6.3 Regressione logistica\nNella regressione logistica, il modello per un esito binario è:\n\\[\n\\text{logit}\\, P(y=1 \\mid x) = \\alpha + \\beta x .\n\\]\nQui \\(\\alpha\\) e \\(\\beta\\) vivono sulla scala logit, non direttamente sulle probabilità. Ricorda che il logit è molto “ripido”: differenze di 2–3 unità sul logit si traducono in variazioni enormi di probabilità (da ~0.1 a ~0.9).\n\n54.6.3.1 Perché è importante\n\nCon predittori standardizzati (media 0, varianza 1), una prior \\(\\beta \\sim \\mathcal{N}(0,1)\\) implica che effetti moderati sono plausibili, mentre probabilità quasi certe (0 o 1) rimangono rare.\nUna prior \\(\\beta \\sim \\mathcal{N}(0,2.5)\\), invece, consente valori di logit fino a ±5, che corrispondono a probabilità estremamente vicine a 0 o 1: rischiamo quindi di “dare per certe” decisioni prima ancora di vedere i dati.\n\nIl PPC serve proprio a verificare se le probabilità implicite dalle prior sono coerenti con ciò che ci aspettiamo nel nostro dominio applicativo.\n\n54.6.3.2 Simulazioni in R\n\nS &lt;- 10000\nx  &lt;- rnorm(S, 0, 1)  # standardizzare è buona pratica\n\n# Scenario E: prior larga\nalpha_E &lt;- rnorm(S, 0, 2.5)\nbeta_E  &lt;- rnorm(S, 0, 2.5)\npE      &lt;- plogis(alpha_E + beta_E * x)\nyE      &lt;- rbinom(S, 1, pE)\n\n# Scenario F: prior weakly-informative\nalpha_F &lt;- rnorm(S, 0, 1)\nbeta_F  &lt;- rnorm(S, 0, 1)\npF      &lt;- plogis(alpha_F + beta_F * x)\nyF      &lt;- rbinom(S, 1, pF)\n\ntibble(p = pE, scenario = \"E: prior larga\") |&gt;\n  bind_rows(tibble(p = pF, scenario = \"F: prior W.I.\")) |&gt;\n  ggplot(aes(x = p, fill = scenario)) +\n  geom_density(alpha = 0.35) +\n  labs(title = \"Probabilità implicite dalla prior (logistica)\",\n       x = \"p(x) = P(y=1|x)\", y = \"Densità\")\n\n\n\n\n\n\n\nLettura.\n\nCon la prior larga (Scenario E), le probabilità implicite sono spesso vicine a 0 o 1: significa che il modello, prima dei dati, crede frequenti le situazioni di “certezza assoluta”.\nCon la prior più stretta (Scenario F), le probabilità restano distribuite in una gamma più plausibile (0.05–0.95), che riflette meglio l’incertezza tipica in psicologia.\n\n54.6.3.3 Regola pratica\n\nCon predittori standardizzati, usare \\(\\mathcal{N}(0,1)\\) o \\(\\mathcal{N}(0,1.5)\\) per i coefficienti logit è spesso una scelta sicura: consente abbastanza variabilità senza produrre predizioni estreme.\nPrior troppo larghe possono generare modelli “rigidi” che, prima dei dati, assumono già risposte quasi deterministiche.\n\n54.6.3.4 Versione Stan: prior-only\nPossiamo rendere tutto più esplicito con un modello Stan che non usa dati osservati e genera solo predizioni dalla prior.\n\nlogistic_prior_ppc_stan &lt;- '\ndata {\n  int&lt;lower=1&gt; N;\n  vector[N] x;\n}\nparameters {\n  real alpha;\n  real beta;\n}\nmodel {\n  alpha ~ normal(0, 1);\n  beta  ~ normal(0, 1);\n}\ngenerated quantities {\n  vector[N] p;\n  array[N] int y_rep;\n  for (i in 1:N) {\n    p[i] = inv_logit(alpha + beta * x[i]);\n    y_rep[i] = bernoulli_rng(p[i]);\n  }\n}\n'\nwriteLines(logistic_prior_ppc_stan, \"logistic_prior_ppc.stan\")\n\nEseguiamo il modello:\n\nmod_log &lt;- cmdstan_model(\"logistic_prior_ppc.stan\")\nx_new   &lt;- rnorm(300)\n\nfit_log &lt;- mod_log$sample(\n  data = list(N = length(x_new), x = x_new),\n  chains = 4, iter_warmup = 500, iter_sampling = 1000,\n  seed = 123, refresh = 0\n)\n\nVisualizziamo le probabilità implicite:\n\npost_p &lt;- fit_log$draws(\"p\", format = \"draws_matrix\")\nas_tibble(post_p) |&gt;\n  pivot_longer(everything(), values_to = \"p\") |&gt;\n  ggplot(aes(x = p)) +\n  geom_density() +\n  labs(title = \"Stan: probabilità implicite dalla prior (logistica)\",\n       x = \"p(x)\", y = \"Densità\")\n\n\n\n\n\n\n\n\n54.6.3.5 Cosa impariamo\n\nLe prior in regressione logistica hanno un impatto diretto sulle probabilità implicite.\nUna prior troppo larga equivale a dire che, prima dei dati, consideriamo probabile avere quasi sempre risposte certe (0 o 1).\nUna prior moderata mantiene invece l’incertezza, riflettendo meglio la realtà psicologica.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Controllo predittivo a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/13_prior_pred_check.html#consigli-pratici-per-specificare-le-prior",
    "href": "chapters/bayesian_inference/13_prior_pred_check.html#consigli-pratici-per-specificare-le-prior",
    "title": "54  Controllo predittivo a priori",
    "section": "\n54.7 Consigli pratici per specificare le prior",
    "text": "54.7 Consigli pratici per specificare le prior\n\n\nLavora sempre sulla scala giusta\n\nSe possibile, standardizza i predittori (media 0, deviazione standard 1).\nCosì i coefficienti hanno un significato uniforme: una Normal(0,1) indica effetti “moderati” (spostamenti di circa 1 dev. std nell’esito per 1 dev. std nel predittore).\n\n\n\nCoefficienti di regressione (\\(\\beta\\))\n\nUn buon punto di partenza sono prior Normal(0, 0.5–2).\nCon \\(\\beta \\sim \\mathcal{N}(0,1)\\): effetti piccoli/moderati sono plausibili, effetti enormi restano possibili ma meno probabili.\nAttenzione: se non standardizzi \\(x\\), la scala di \\(\\beta\\) cambia e queste regole non valgono più.\n\n\n\nIntercetta (\\(\\alpha\\))\n\nCon outcome gaussiano, centra \\(y\\) per rendere \\(\\alpha\\) interpretabile.\nCon outcome binario (link logit), una Normal(0,1–1.5) implica probabilità tipiche tra 0.05 e 0.95; una Normal(0,2.5) è molto più permissiva (quasi-certezze frequenti).\n\n\n\nVarianze o scale (\\(\\sigma\\))\n\nUsa prior sempre positive (HalfNormal, Exponential).\nScegli la media dell’Exponential nell’ordine di grandezza plausibile per il dominio: ad esempio, per punteggi 0–100 una prior Exponential(mean ≈ 5–10) è ragionevole.\nVerifica sempre con simulazioni che la dispersione generata sia coerente.\n\n\n\nLink non lineari (logit, log)\n\nNon pensare solo in termini di coefficienti logit o log: traduci sempre in probabilità implicite (per logit) o in rate attese (per log).\nChiediti: “Queste prior implicano che i soggetti abbiano davvero probabilità quasi 0 o 1 di successo?”\n\n\n\nDiagnosi e trasparenza\n\nFai sempre prior predictive checks: se i dati simulati sono “assurdi” (es. punteggi negativi o fuori scala), la prior è mal calibrata.\nDocumenta cosa hai provato, cosa hai cambiato e perché: fa parte del rigore dell’analisi bayesiana.\n\n\n\n\n\n\n\n\n\nAppendice: prior predictive con brms per i tre casi\n\n\n\n\n\nModello gaussiano.\n\nN &lt;- 100\ndf_g &lt;- tibble(y = rnorm(N, 50, 10)) # placeholder, non usato con \"only\"\n\nfit_g_prior &lt;- brm(\n  bf(y ~ 1),\n  data = df_g,\n  family = gaussian(),\n  prior = c(\n    prior(normal(50, 10), class = \"Intercept\"),\n    prior(exponential(0.1), class = \"sigma\")        \n    # prior(exponential(1.0/10), class = \"sigma\")   \n  ),\n  sample_prior = \"only\",\n  chains = 4, iter = 1000, cores = 4,\n  backend = \"cmdstanr\", seed = 123\n)\n\n\nyrep_g &lt;- posterior_predict(fit_g_prior)\nppc_dens_overlay(y = df_g$y, yrep = yrep_g[1:200, ]) +\n  ggtitle(\"brms: predittiva a priori (gaussiana)\")\n\n\n\n\n\n\n\nRegressione lineare.\n\nN &lt;- 120\ndf_l &lt;- tibble(\n  y = rnorm(N),\n  x = rnorm(N)\n)\n\n\nfit_l_prior &lt;- brm(\n  bf(y ~ 1 + x),\n  data = df_l,\n  family = gaussian(),\n  prior = c(\n    prior(normal(0, 1), class = \"Intercept\"),\n    prior(normal(0, 1), class = \"b\", coef = \"x\"),\n    prior(exponential(0.5), class = \"sigma\")      # &lt;-- 0.5 (oppure 1.0/2)\n    # prior(exponential(1.0/2), class = \"sigma\")  # &lt;-- equivalente\n  ),\n  sample_prior = \"only\",\n  chains = 4, iter = 1000, cores = 4,\n  backend = \"cmdstanr\", seed = 123\n)\n\n\nyrep_l &lt;- posterior_predict(fit_l_prior)\nppc_dens_overlay(y = df_l$y, yrep = yrep_l[1:200, ]) +\n  ggtitle(\"brms: predittiva a priori (lineare)\") +\n  xlim(-5, 5)\n\n\n\n\n\n\n\nRegressione logistica.\n\nN &lt;- 150\ndf_log &lt;- tibble(\n  y = rbinom(N, 1, 0.5),  # placeholder\n  x = rnorm(N)\n)\n\n\nfit_log_prior &lt;- brm(\n  bf(y ~ 1 + x),\n  data = df_log,\n  family = bernoulli(),\n  prior = c(\n    prior(normal(0, 1.5), class = \"Intercept\"),\n    prior(normal(0, 1), class = \"b\", coef = \"x\")\n  ),\n  sample_prior = \"only\",\n  chains = 4, iter = 1000, cores = 4,\n  backend = \"cmdstanr\", seed = 123\n)\n\n\nyrep_log &lt;- posterior_predict(fit_log_prior)\nppc_bars(y = df_log$y, yrep = yrep_log[1:200, ]) +\n  ggtitle(\"brms: prior predictive (logistica)\")",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Controllo predittivo a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/13_prior_pred_check.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/13_prior_pred_check.html#riflessioni-conclusive",
    "title": "54  Controllo predittivo a priori",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIl controllo predittivo a priori rappresenta un momento fondamentale nell’analisi bayesiana, dove la struttura matematica del modello incontra la conoscenza sostantiva del fenomeno studiato. Questo processo va ben oltre una mera verifica tecnica, configurandosi come un vero e proprio esercizio epistemologico che valuta la coerenza tra le nostre aspettative teoriche e le implicazioni quantitative del modello.\nNella pratica di ricerca, è opportuno documentare con chiarezza:\n\nla procedura di simulazione dei dati a partire dalle distribuzioni a priori,\nle eventuali incongruenze riscontrate tra i dati simulati e le aspettative teoriche,\nle modifiche apportate alle distribuzioni a priori in risposta a tali incongruenze,\ni risultati finali ottenuti dopo la ricalibrazione del modello.\n\nQuesta documentazione non costituisce un appesantimento metodologico, ma piuttosto un elemento chiave per garantire trasparenza e riproducibilità. Prendiamo ad esempio il caso di un test psicometrico con 10 domande: l’adozione di una distribuzione Beta(2,2) riflette una sostanziale incertezza a priori, producendo simulazioni con ampia variabilità di punteggi, mentre una Beta(10,2) esprime la convinzione che i rispondenti siano generalmente preparati, concentrando le previsioni su punteggi elevati.\nIn ambito psicologico, dove i costrutti teorici spesso presentano confini sfumati, questo approccio assume particolare rilevanza. A differenza delle metodologie che iniziano l’analisi solo dopo la raccolta dei dati, il framework bayesiano promuove una riflessione anticipata sulle ipotesi modellistiche e sulle loro conseguenze predittive.\nIl controllo predittivo a priori si configura dunque come un potente strumento diagnostico:\n\nsegnala discrepanze tra le assunzioni del modello e la realtà empirica,\nguida la riparametrizzazione delle distribuzioni a priori,\nrafforza la validità ecologica delle analisi successive.\n\nRendendo esplicite le implicazioni delle nostre scelte modellistiche, questa pratica favorisce lo sviluppo di analisi più consapevoli e robuste. In ultima analisi, il controllo predittivo a priori non costituisce un semplice passaggio tecnico, ma un momento essenziale per costruire modelli che riflettano autenticamente la complessità dei fenomeni psicologici che intendiamo studiare.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Controllo predittivo a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/13_prior_pred_check.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/13_prior_pred_check.html#informazioni-sullambiente-di-sviluppo",
    "title": "54  Controllo predittivo a priori",
    "section": "Informazioni sull’ambiente di sviluppo",
    "text": "Informazioni sull’ambiente di sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] cmdstanr_0.9.0        pillar_1.11.0         tinytable_0.11.0     \n#&gt;  [4] patchwork_1.3.1       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt;  [7] bayesplot_1.13.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [10] priorsense_1.1.0      posterior_1.6.1       loo_2.8.0            \n#&gt; [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [16] Rcpp_1.1.0            conflicted_1.2.0      janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.6         tidyselect_1.2.1     farver_2.1.2        \n#&gt;  [4] fastmap_1.2.0        TH.data_1.1-3        tensorA_0.36.2.1    \n#&gt;  [7] digest_0.6.37        estimability_1.5.1   timechange_0.3.0    \n#&gt; [10] lifecycle_1.0.4      processx_3.8.6       survival_3.8-3      \n#&gt; [13] magrittr_2.0.3       compiler_4.5.1       rlang_1.1.6         \n#&gt; [16] tools_4.5.1          yaml_2.3.10          data.table_1.17.8   \n#&gt; [19] knitr_1.50           labeling_0.4.3       bridgesampling_1.1-2\n#&gt; [22] htmlwidgets_1.6.4    pkgbuild_1.4.8       curl_6.4.0          \n#&gt; [25] plyr_1.8.9           RColorBrewer_1.1-3   abind_1.4-8         \n#&gt; [28] multcomp_1.4-28      withr_3.0.2          purrr_1.1.0         \n#&gt; [31] grid_4.5.1           stats4_4.5.1         xtable_1.8-4        \n#&gt; [34] colorspace_2.1-1     inline_0.3.21        emmeans_1.11.2      \n#&gt; [37] scales_1.4.0         MASS_7.3-65          cli_3.6.5           \n#&gt; [40] mvtnorm_1.3-3        rmarkdown_2.29       generics_0.1.4      \n#&gt; [43] RcppParallel_5.1.10  reshape2_1.4.4       cachem_1.1.0        \n#&gt; [46] stringr_1.5.1        splines_4.5.1        parallel_4.5.1      \n#&gt; [49] vctrs_0.6.5          V8_6.0.5             Matrix_1.7-3        \n#&gt; [52] sandwich_3.1-1       jsonlite_2.0.0       arrayhelpers_1.1-0  \n#&gt; [55] glue_1.8.0           ps_1.9.1             codetools_0.2-20    \n#&gt; [58] distributional_0.5.0 lubridate_1.9.4      stringi_1.8.7       \n#&gt; [61] gtable_0.3.6         QuickJSR_1.8.0       htmltools_0.5.8.1   \n#&gt; [64] Brobdingnag_1.2-9    R6_2.6.1             rprojroot_2.1.0     \n#&gt; [67] evaluate_1.0.4       lattice_0.22-7       backports_1.5.0     \n#&gt; [70] memoise_2.0.1        broom_1.0.9          snakecase_0.11.1    \n#&gt; [73] rstantools_2.4.0     coda_0.19-4.1        gridExtra_2.3       \n#&gt; [76] nlme_3.1-168         checkmate_2.3.2      xfun_0.52           \n#&gt; [79] zoo_1.8-14           pkgconfig_2.0.3",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Controllo predittivo a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/13_prior_pred_check.html#bibliografia",
    "href": "chapters/bayesian_inference/13_prior_pred_check.html#bibliografia",
    "title": "54  Controllo predittivo a priori",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., Vehtari, A., Simpson, D., Margossian, C. C., Carpenter, B., Yao, Y., Kennedy, L., Gabry, J., Bürkner, P.-C., & Modrák, M. (2020). Bayesian workflow. arXiv preprint arXiv:2011.01808.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Controllo predittivo a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/13_prior_pred_check.html#footnotes",
    "href": "chapters/bayesian_inference/13_prior_pred_check.html#footnotes",
    "title": "54  Controllo predittivo a priori",
    "section": "",
    "text": "Immagina di voler sapere che gusto avrà un succo se mescoli vari ingredienti. Non fai la media del gusto di singoli bicchieri, ma prendi un po’ di ogni succo (distribuzione) e li mescoli: il risultato è una nuova bevanda (la distribuzione predittiva a priori).↩︎",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Controllo predittivo a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/14_post_pred_distr.html",
    "href": "chapters/bayesian_inference/14_post_pred_distr.html",
    "title": "55  Distribuzione predittiva a posteriori",
    "section": "",
    "text": "Introduzione\nIn parole semplici, la distribuzione predittiva a posteriori ci dice quali risultati futuri sono plausibili, dati i dati osservati e il modello che utilizziamo per interpretarli.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/14_post_pred_distr.html#introduzione",
    "href": "chapters/bayesian_inference/14_post_pred_distr.html#introduzione",
    "title": "55  Distribuzione predittiva a posteriori",
    "section": "",
    "text": "Nell’inferenza bayesiana non ci interessa soltanto stimare i parametri di un modello (ad esempio, la probabilità \\(p\\) di successo in un compito con esiti binomiali). Un obiettivo altrettanto importante è prevedere dati futuri, sulla base di ciò che abbiamo già osservato. La distribuzione predittiva a posteriori serve proprio a questo: combina\n\nl’incertezza sui parametri, descritta dalla distribuzione a posteriori,\nla variabilità intrinseca del processo che genera i dati futuri.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/14_post_pred_distr.html#definizione-formale",
    "href": "chapters/bayesian_inference/14_post_pred_distr.html#definizione-formale",
    "title": "55  Distribuzione predittiva a posteriori",
    "section": "\n55.1 Definizione formale",
    "text": "55.1 Definizione formale\nSupponiamo di avere dati osservati \\(y = {y_1, y_2, \\ldots, y_n}\\), generati da un modello che dipende da un parametro ignoto \\(\\theta\\). Questo parametro può rappresentare, a seconda del caso, una probabilità, una media, o un coefficiente di regressione.\nLa conoscenza iniziale su \\(\\theta\\) è descritta da una distribuzione a priori \\(p(\\theta)\\). Dopo aver osservato i dati, aggiorniamo tale conoscenza attraverso la formula di Bayes, ottenendo la distribuzione a posteriori:\n\\[\np(\\theta \\mid y) = \\frac{p(y \\mid \\theta)\\, p(\\theta)}{p(y)} ,\n\\]\ndove:\n\n\\(p(\\theta \\mid y)\\) è la distribuzione a posteriori: rappresenta ciò che sappiamo su \\(\\theta\\) dopo i dati.\n\\(p(y \\mid \\theta)\\) è la verosimiglianza: quanto i dati osservati sono compatibili con un certo valore di \\(\\theta\\).\n\\(p(\\theta)\\) è la distribuzione a priori.\n\n\\(p(y)\\) è l’evidenza, cioè la probabilità totale dei dati, calcolata come\n\\[\np(y) = \\int p(y \\mid \\theta) p(\\theta)\\, d\\theta .\n\\]\n\n\nOra vogliamo prevedere un nuovo dato, \\(\\tilde{y}\\). In questo caso ci serve la distribuzione predittiva a posteriori \\(p(\\tilde{y} \\mid y)\\).\n\n55.1.1 Che cos’è \\(\\tilde{y}\\)?\n\nÈ un dato futuro o non ancora osservato.\nPer esempio, se \\(y\\) rappresenta il numero di successi in una serie di lanci di moneta, \\(\\tilde{y}\\) può rappresentare i successi in una nuova serie di lanci.\n\n55.1.2 Che cos’è \\(p(\\tilde{y} \\mid \\theta)\\)?\n\nÈ la probabilità di osservare \\(\\tilde{y}\\) se sapessimo che il parametro del modello è proprio \\(\\theta\\).\nNell’esempio binomiale, corrisponde alla probabilità di ottenere \\(\\tilde{y}\\) successi su \\(n_{\\text{new}}\\) prove, dato che la probabilità di successo è \\(\\theta\\).\n\n55.1.3 Come combinare \\(p(\\tilde{y} \\mid \\theta)\\) e \\(p(\\theta \\mid y)\\)\n\nPoiché non conosciamo il vero valore di \\(\\theta\\), consideriamo tutti i valori possibili, pesandoli in base alla loro plausibilità a posteriori. Questo porta alla formula fondamentale:\n\\[\np(\\tilde{y} \\mid y) = \\int p(\\tilde{y} \\mid \\theta)\\, p(\\theta \\mid y)\\, d\\theta .\n\\tag{55.1}\\]\n\n55.1.4 Interpretazione\nLa distribuzione predittiva a posteriori \\(p(\\tilde{y} \\mid y)\\) rappresenta la miglior stima possibile della probabilità di un dato futuro: tiene conto sia dell’incertezza sui parametri sia della variabilità del fenomeno stesso.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/14_post_pred_distr.html#caso-discreto",
    "href": "chapters/bayesian_inference/14_post_pred_distr.html#caso-discreto",
    "title": "55  Distribuzione predittiva a posteriori",
    "section": "\n55.2 Caso discreto",
    "text": "55.2 Caso discreto\nSe \\(\\theta\\) può assumere un numero finito di valori, l’integrale si riduce a una somma:\n\\[\np(\\tilde{y} \\mid y) = \\sum_{\\theta} p(\\tilde{y} \\mid \\theta)\\, p(\\theta \\mid y).\n\\tag{55.2}\\]\nQuesto approccio è particolarmente utile nei modelli discreti o quando lavoriamo con approssimazioni basate su campioni finiti di valori di \\(\\theta\\) (ad esempio, i campioni MCMC).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/14_post_pred_distr.html#il-caso-betabinomiale",
    "href": "chapters/bayesian_inference/14_post_pred_distr.html#il-caso-betabinomiale",
    "title": "55  Distribuzione predittiva a posteriori",
    "section": "\n55.3 Il caso Beta–Binomiale",
    "text": "55.3 Il caso Beta–Binomiale\nConsideriamo un esperimento binomiale: lanciamo una moneta \\(n\\) volte e osserviamo il numero di successi \\(y\\) (ad esempio, il numero di teste). In ottica bayesiana, l’analisi segue tre passaggi fondamentali:\n\n\nDistribuzione a priori Prima di osservare i dati, esprimiamo le nostre conoscenze (o incertezze) sulla probabilità di successo \\(p\\). Una scelta comune è la distribuzione Beta(\\(\\alpha, \\beta\\)), perché è definita sull’intervallo \\([0,1]\\) e molto flessibile:\n\n\n\\(\\alpha\\) si può interpretare come un numero “fittizio” di successi già osservati;\n\n\\(\\beta\\) come un numero “fittizio” di insuccessi.\n\nIn questo modo, la prior sintetizza eventuali conoscenze pregresse sotto forma di “dati immaginari”.\n\n\nDistribuzione a posteriori Dopo aver osservato \\(y\\) successi su \\(n\\) prove, aggiorniamo la prior con i dati tramite la regola di Bayes. Poiché la Beta è coniugata alla Binomiale, la distribuzione a posteriori ha ancora forma Beta, con parametri aggiornati:\n\\[\n\\alpha_{\\text{post}} = \\alpha_{\\text{prior}} + y, \\quad\n\\beta_{\\text{post}} = \\beta_{\\text{prior}} + (n - y).\n\\]\nQuesta distribuzione descrive ciò che sappiamo su \\(p\\) dopo aver osservato i dati.\n\n\nDistribuzione predittiva a posteriori Se vogliamo prevedere il numero di successi futuri \\(y_{\\text{new}}\\) in un nuovo esperimento con \\(n_{\\text{new}}\\) prove, dobbiamo combinare:\n\nl’incertezza residua su \\(p\\), descritta dalla distribuzione a posteriori;\nla variabilità del processo binomiale per le nuove osservazioni.\n\nIn pratica:\n\nestraiamo \\(p \\sim \\text{Beta}(\\alpha_{\\text{post}}, \\beta_{\\text{post}})\\);\ngeneriamo \\(y_{\\text{new}} \\sim \\text{Binomiale}(n_{\\text{new}}, p)\\).\n\nQuesto procedimento produce la distribuzione predittiva a posteriori, che integra entrambe le fonti di incertezza.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/14_post_pred_distr.html#un-esempio-numerico",
    "href": "chapters/bayesian_inference/14_post_pred_distr.html#un-esempio-numerico",
    "title": "55  Distribuzione predittiva a posteriori",
    "section": "\n55.4 Un esempio numerico",
    "text": "55.4 Un esempio numerico\n\n55.4.1 Parametri osservati e prior\n\nDati: \\(y = 70\\) successi su \\(n = 100\\) prove.\nPrior: Beta(2, 2), debolmente informativa, con leggera preferenza per valori di \\(p\\) vicini a 0.5.\n\n55.4.2 Distribuzione a posteriori\nAggiornando la prior:\n\\[\n\\alpha_{\\text{post}} = 2 + 70 = 72, \\quad\n\\beta_{\\text{post}} = 2 + (100 - 70) = 32.\n\\]\nLa distribuzione a posteriori è quindi \\(p \\sim \\text{Beta}(72, 32)\\), centrata attorno a \\(p \\approx 0.7\\).\n\n55.4.3 Simulazione predittiva\nSupponiamo di voler prevedere \\(y_{\\text{new}}\\) su \\(n_{\\text{new}} = 10\\) prove:\n\nset.seed(123)\n\n# Dati osservati\ny &lt;- 70\nn &lt;- 100\n\n# Prior\nalpha_prior &lt;- 2\nbeta_prior &lt;- 2\n\n# Posterior\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + (n - y)\n\n# Campioni da p|y ~ Beta(72, 32)\np_samples &lt;- rbeta(1000, alpha_post, beta_post)\n\n# Simulazione di successi futuri\ny_preds &lt;- rbinom(1000, size = 10, prob = p_samples)\n\n# Proporzioni di successi\nprop_preds &lt;- y_preds / 10\n\n\n55.4.4 Spiegazione del codice\n1. Distribuzione a posteriori di \\(p\\).\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + (n - y)\np_samples &lt;- rbeta(1000, alpha_post, beta_post)\nQui calcoliamo la distribuzione a posteriori di \\(p\\): \\(p \\mid y \\sim \\text{Beta}(72, 32)\\). Con rbeta(1000, 72, 32) estraiamo 1000 campioni da questa distribuzione: ognuno rappresenta un valore plausibile della probabilità di successo \\(p\\), pesato implicitamente dalla distribuzione a posteriori. In altre parole, stiamo implementando il concetto: non conosciamo il vero \\(p\\), ma lo trattiamo come una variabile aleatoria distribuita secondo la posterior.\n2. Distribuzione predittiva di nuovi dati.\ny_preds &lt;- rbinom(1000, size = 10, prob = p_samples)\nPer ogni valore di \\(p\\) campionato dalla posterior, simuliamo un nuovo esperimento con 10 prove (rbinom). Questa parte del codice riflette l’integrale teorico della distribuzione predittiva:\n\\[\np(\\tilde{y} \\mid y) = \\int p(\\tilde{y} \\mid p)\\, p(p \\mid y)\\, dp .\n\\]\nIn pratica, invece di calcolare l’integrale, lo approssimiamo con simulazioni:\n\nper ciascun \\(p\\) plausibile (estratto dalla posterior),\ngeneriamo un possibile esito futuro \\(\\tilde{y}\\),\nripetiamo il processo tante volte.\n\nCosì otteniamo un campione dalla distribuzione predittiva a posteriori.\n3. Proporzioni di successi.\nprop_preds &lt;- y_preds / 10\nConvertiamo i conteggi di successi in proporzioni: ogni valore rappresenta un possibile esito futuro, considerando sia l’incertezza su \\(p\\) sia la variabilità intrinseca del processo binomiale.\n4. Legame con l’idea teorica.\nL’idea era:\n\n“Poiché non conosciamo il vero valore di \\(p\\), consideriamo tutti i valori possibili, pesandoli in base alla loro plausibilità a posteriori.”\n\nIl codice fa esattamente questo:\n\ncon rbeta() campioniamo valori plausibili di \\(p\\) dalla distribuzione a posteriori (il “peso” viene dal fatto che valori più probabili vengono campionati più spesso);\ncon rbinom() generiamo i dati futuri \\(\\tilde{y}\\) per ognuno di questi valori.\n\nIl risultato (prop_preds) è un insieme di possibili esiti futuri che incorpora entrambe le fonti di incertezza:\n\nl’incertezza residua sul parametro \\(p\\) (posterior),\nla variabilità del processo binomiale (dati futuri).\n\n55.4.5 Visualizzazione\nDistribuzione a priori:\n\ncurve(dbeta(x, alpha_prior, beta_prior), from = 0, to = 1,\n      main = \"Distribuzione a Priori\", col = \"blue\", lwd = 2, ylab = \"Densità\")\n\n\n\n\n\n\n\nDistribuzione a posteriori:\n\ncurve(dbeta(x, alpha_post, beta_post), from = 0, to = 1,\n      main = \"Distribuzione a Posteriori\", col = \"red\", lwd = 2, ylab = \"Densità\")\n\n\n\n\n\n\n\nDistribuzione predittiva per \\(n_{\\text{new}} = 10\\):\n\nhist(prop_preds, breaks = 20, col = \"lightblue\", freq = FALSE,\n     main = \"Distribuzione Predittiva (n_new = 10)\",\n     xlab = \"Proporzione di successi\")\nabline(v = y/n, col = \"blue\", lwd = 2, lty = 2)\n\n\n\n\n\n\n\n\n55.4.6 Interpretazione\n\nLa distribuzione a posteriori \\(p \\sim \\text{Beta}(72, 32)\\) è stretta attorno a 0.7, riflettendo l’elevata informazione contenuta nei 100 lanci osservati.\nLa distribuzione predittiva per \\(n_{\\text{new}} = 10\\) è invece più ampia: la ridotta numerosità introduce ulteriore variabilità oltre all’incertezza residua su \\(p\\).\nL’istogramma mostra che i valori più probabili per la proporzione futura oscillano intorno a 0.7, ma con maggiore dispersione.\n\nLa distribuzione predittiva a posteriori consente di verificare se il modello è in grado di generare dati simili a quelli osservati.\nNel nostro caso, la proporzione osservata (\\(0.7\\)) cade vicino al centro della distribuzione predittiva: ciò indica che il modello riproduce bene i dati e può essere utilizzato con fiducia per fare previsioni.\n\n\n\n\n\n\nIl fatto che la distribuzione predittiva a posteriori rappresenti accuratamente la proporzione osservata può sembrare ovvio nel caso presente. Questo avviene perché stiamo lavorando con un modello semplice e ben specificato, utilizzato qui con l’intento di chiarire la logica del concetto di distribuzione predittiva a posteriori. Tuttavia, nei modelli più complessi, tipici delle indagini psicologiche, la corrispondenza tra i dati osservati e quelli predetti dal modello non può mai essere data per scontata. È essenziale verificarla attraverso la distribuzione predittiva a posteriori.\nSe i dati osservati non sono ben rappresentati dalla distribuzione predittiva a posteriori, ciò indica che il modello non è adeguato a spiegare i dati e necessita di revisione. Questo processo di verifica non solo garantisce la coerenza del modello con i dati disponibili, ma consente anche di identificare eventuali aree problematiche nella specificazione del modello, come prior inappropriati o assunzioni non realistiche. In definitiva, il confronto tra i dati osservati e quelli predetti è un passo fondamentale per la validazione di modelli complessi in contesti psicologici e scientifici.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/14_post_pred_distr.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/14_post_pred_distr.html#riflessioni-conclusive",
    "title": "55  Distribuzione predittiva a posteriori",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nLa distribuzione predittiva a posteriori è il fulcro dell’inferenza bayesiana, non solo per la sua capacità di generare previsioni robuste sui dati futuri, ma soprattutto perché integra intrinsecamente l’incertezza sui parametri del modello con la variabilità stocastica del processo. Questa sintesi di incertezze offre un quadro probabilistico completo, superando la mera stima puntuale dei parametri e fornendo una base solida per il confronto diretto tra le aspettative del modello e le evidenze empiriche.\nNel flusso di lavoro bayesiano, la distribuzione predittiva a posteriori si rivela indispensabile per la valutazione del modello. Attraverso i controlli predittivi a posteriori, permette di identificare sistematicamente le discrepanze tra i dati osservati e quelli simulati dal modello. Questi controlli non sono semplici verifiche, ma strumenti diagnostici cruciali: rivelano problemi di specificazione del modello, la non adeguatezza delle distribuzioni a priori scelte e orientano attivamente il processo iterativo di revisione e miglioramento del modello.\nIl caso beta-binomiale ha illustrato con chiarezza come un’incertezza sui parametri (rappresentata dalla distribuzione beta) si traduca in previsioni probabilistiche per eventi futuri (i successi binomiali). L’esempio ha evidenziato come le previsioni non richiedano assunzioni restrittive o non realistiche, ma emergano direttamente dalla propagazione dell’incertezza. Questo approccio non solo quantifica rigorosamente l’incertezza, ma facilita anche la comunicazione trasparente e l’interpretabilità delle previsioni.\nIn sintesi, la distribuzione predittiva a posteriori è l’elemento che salda l’inferenza parametrica all’analisi predittiva empirica nella modellazione bayesiana. Essa garantisce che il processo inferenziale sia non solo più affidabile e interpretabile, ma anche intrinsecamente più applicabile a scenari complessi del mondo reale, fornendo un ponte essenziale tra la teoria del modello e la sua utilità pratica.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/14_post_pred_distr.html#esercizi",
    "href": "chapters/bayesian_inference/14_post_pred_distr.html#esercizi",
    "title": "55  Distribuzione predittiva a posteriori",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nConsideriamo i dati della SWLS somministrata a un campione di studenti, ottenendo per ciascuno uno score complessivo. Per semplicità, vogliamo “dichiarare positivo” lo studente se il punteggio SWLS supera una determinata soglia (ad esempio, 20 su 35). In questo modo otteniamo una variabile dicotomica (0/1), che useremo come “successo” in un modello binomiale.\n\n\nDati e conteggio dei successi\n\nCarica il dataset con le risposte SWLS.\n\nCostruisci la variabile binaria (ad esempio SWLS_dich) che vale 1 se lo score ≥ 20, e 0 altrimenti.\n\nCalcola il numero di successi (numero di persone che superano la soglia) e il numero totale di osservazioni (N).\n\n\n\nModello beta-binomiale (approccio manuale via simulazione)\n\n\nSpecifica una distribuzione Beta(a, b) come prior per la probabilità di successo \\(p\\). Scegli una coppia \\((a, b)\\) relativamente poco informativa, ad esempio (2,2) o (1,1).\n\nOsservando \\(y\\) successi su \\(n\\) soggetti, aggiorna i parametri a posteriori: \\[\n  a_{\\text{post}} = a + y,\n  \\quad\n  b_{\\text{post}} = b + (n - y).\n\\]\n\nSimula un gran numero di campioni di \\(p\\) dalla distribuzione Beta\\(\\bigl(a_{\\text{post}},\\, b_{\\text{post}}\\bigr)\\).\n\nPer ciascun campione di \\(p\\), genera un valore \\(\\tilde{y}\\) da una Binomiale\\(\\bigl(n_{\\text{new}}, p\\bigr)\\), dove \\(n_{\\text{new}}\\) è la dimensione di un ipotetico nuovo campione (che puoi scegliere, ad esempio, uguale a \\(n\\) oppure un valore diverso). Otterrai così una posterior predictive distribution per \\(\\tilde{y}\\).\n\nInfine, calcola statistiche descrittive (media, varianza, intervalli) e/o disegna un istogramma di \\(\\tilde{y}\\) o della proporzione \\(\\tilde{y}/n_{\\text{new}}\\).\n\n\n\nReplicare con brms\n\n\nUsa il pacchetto brms per costruire un modello binomiale. Per esempio:\nlibrary(brms)\n\n# Crea un data frame con la variabile dicotomica\ndf_binom &lt;- data.frame(\n  successes = y,    # conteggio dei successi\n  failures  = n - y\n)\n\n# Modello binomiale con prior Beta(a,b) approssimato tramite logit\nfit_brms &lt;- brm(\n  bf(successes | trials(n) ~ 1), \n  data = df_binom,\n  family = binomial(link = \"logit\"),\n  prior = c(\n    prior(beta(2, 2), class = \"Intercept\", dpar = \"mu\") \n    # NOTA: la specifica di una \"beta(2,2)\" diretta sull'intercetta\n    # è un'approssimazione, tipicamente serve passare a una scala logit.\n    # In brms, di solito si usa prior su scale normali dell'intercetta.\n  ),\n  seed = 123\n)\n(Le specifiche del prior potrebbero richiedere una formulazione differente se vuoi rispettare esattamente la corrispondenza con Beta(a,b). In ogni caso, l’idea è mostrare come definire un prior e costruire un modello binomiale con brms.)\n\n\nVerifica la convergenza e poi estrai la posterior predictive distribution con le funzioni di brms:\npp_check(fit_brms, nsamples = 100)\nQuesto ti mostrerà come i dati predetti dal modello (in termini di binomiale) si confrontano con i dati osservati.\n\n\n\n\nConfronto e interpretazione\n\nMetti a confronto i risultati della simulazione “manuale” (Beta-Binomial) e quelli ottenuti con brms. Noterai che le distribuzioni predittive dovrebbero essere coerenti, se hai impostato un prior per brms simile a quello del modello Beta-Binomiale.\n\nDiscuti brevemente se la distribuzione predittiva a posteriori acquisita è plausibile rispetto ai dati osservati. Ad esempio, la probabilità di osservare \\(\\tilde{y}\\) simile a \\(y\\) dovrebbe essere relativamente alta se il modello è appropriato.\n\nSe vuoi, puoi cambiare \\(n_{\\text{new}}\\) (es. previsione su 200 soggetti futuri) per vedere come la variabilità della previsione si “ridimensiona” o cresce a seconda della taglia del campione.\n\n\n\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n\n\nCostruzione del dataset\n\n\nSe la SWLS varia tra 5 e 35, e la soglia è 20, puoi fare:\ndf$SWLS_dich &lt;- ifelse(df$SWLS_score &gt;= 20, 1, 0)\ny &lt;- sum(df$SWLS_dich)\nn &lt;- nrow(df)\n\n\n\n\nApproccio Beta-Binomial manuale\n\nPrior: \\((a, b) = (2, 2)\\)\nPosterior: \\((a_{\\text{post}}, b_{\\text{post}}) = (2 + y,\\, 2 + n - y)\\).\n\nGenerazione dei campioni:\nN_sim &lt;- 2000\np_post &lt;- rbeta(N_sim, a_post, b_post)\ny_pred &lt;- rbinom(N_sim, size = n_new, prob = p_post)\n\n# Se preferisci la proporzione futura:\nprop_pred &lt;- y_pred / n_new\n\n\nStatistiche:\nmean_p &lt;- mean(p_post) # media a posteriori di p\nquantile_p &lt;- quantile(p_post, c(0.025, 0.975))  \n\nmean_prop_pred &lt;- mean(prop_pred)\nquantile_prop_pred &lt;- quantile(prop_pred, c(0.025, 0.975))\n\n\nGrafici (istogramma e densità):\nhist(prop_pred, freq=FALSE, col='lightblue',\n     main='Posterior Predictive Distribution: prop. di successi')\n\n\n\n\nModello con brms\n\nUsa la sintassi di una binomiale con offset o con trials(n).\n\nSpecifica un prior che approssimi Beta(2,2) sullo scale logit, ad esempio:\n# Beta(2,2) ha media ~ 0.5, varianza relativamente ampia.\n# Approssimandola su scala logit ~ normal(0, 2.2) \n# (valore indicativo: la normal(0, 2) su logit copre un intervallo ampio).\n\nprior_approx &lt;- prior(normal(0, 2), class = \"Intercept\")\n\nEsegui pp_check(fit_brms) e interpreta.\n\n\n\nInterpretazione\n\nSe la soglia scelta per la SWLS cattura un “buon livello di soddisfazione”, potresti aspettarti una certa % di successi.\n\nSe i dati futuri simulati sono coerenti con i dati reali — ad esempio, la media di \\(\\tilde{y}\\) è vicina a \\(y\\) — allora il modello sembra descrivere bene la realtà. Altrimenti, potresti rivedere la soglia o la specifica del prior.\n\n\n\nL’elemento chiave è che la distribuzione predittiva a posteriori (posterior predictive distribution) non si limita a considerare un solo valore di \\(p\\), bensì campiona molteplici valori plausibili (dalla posterior), e per ciascuno simula un potenziale outcome. Così facendo, si riflette pienamente l’incertezza residua sul parametro e l’aleatorietà del processo binomiale.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/14_post_pred_distr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/14_post_pred_distr.html#informazioni-sullambiente-di-sviluppo",
    "title": "55  Distribuzione predittiva a posteriori",
    "section": "Informazioni sull’ambiente di sviluppo",
    "text": "Informazioni sull’ambiente di sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pillar_1.11.0         tinytable_0.11.0      patchwork_1.3.1      \n#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.13.0     \n#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.0     \n#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [16] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [19] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [22] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.6         tidyselect_1.2.1     farver_2.1.2        \n#&gt;  [4] fastmap_1.2.0        TH.data_1.1-3        tensorA_0.36.2.1    \n#&gt;  [7] digest_0.6.37        estimability_1.5.1   timechange_0.3.0    \n#&gt; [10] lifecycle_1.0.4      survival_3.8-3       magrittr_2.0.3      \n#&gt; [13] compiler_4.5.1       rlang_1.1.6          tools_4.5.1         \n#&gt; [16] knitr_1.50           bridgesampling_1.1-2 htmlwidgets_1.6.4   \n#&gt; [19] pkgbuild_1.4.8       curl_6.4.0           RColorBrewer_1.1-3  \n#&gt; [22] abind_1.4-8          multcomp_1.4-28      withr_3.0.2         \n#&gt; [25] purrr_1.1.0          grid_4.5.1           stats4_4.5.1        \n#&gt; [28] xtable_1.8-4         colorspace_2.1-1     inline_0.3.21       \n#&gt; [31] emmeans_1.11.2       scales_1.4.0         MASS_7.3-65         \n#&gt; [34] cli_3.6.5            mvtnorm_1.3-3        rmarkdown_2.29      \n#&gt; [37] generics_0.1.4       RcppParallel_5.1.10  cachem_1.1.0        \n#&gt; [40] stringr_1.5.1        splines_4.5.1        parallel_4.5.1      \n#&gt; [43] vctrs_0.6.5          V8_6.0.5             Matrix_1.7-3        \n#&gt; [46] sandwich_3.1-1       jsonlite_2.0.0       arrayhelpers_1.1-0  \n#&gt; [49] glue_1.8.0           codetools_0.2-20     distributional_0.5.0\n#&gt; [52] lubridate_1.9.4      stringi_1.8.7        gtable_0.3.6        \n#&gt; [55] QuickJSR_1.8.0       htmltools_0.5.8.1    Brobdingnag_1.2-9   \n#&gt; [58] R6_2.6.1             rprojroot_2.1.0      evaluate_1.0.4      \n#&gt; [61] lattice_0.22-7       backports_1.5.0      memoise_2.0.1       \n#&gt; [64] broom_1.0.9          snakecase_0.11.1     rstantools_2.4.0    \n#&gt; [67] coda_0.19-4.1        gridExtra_2.3        nlme_3.1-168        \n#&gt; [70] checkmate_2.3.2      xfun_0.52            zoo_1.8-14          \n#&gt; [73] pkgconfig_2.0.3",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/14_post_pred_distr.html#bibliografia",
    "href": "chapters/bayesian_inference/14_post_pred_distr.html#bibliografia",
    "title": "55  Distribuzione predittiva a posteriori",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nSchoot, R. van de, Depaoli, S., King, R., Kramer, B., Märtens, K., Tadesse, M. G., Vannucci, M., Gelman, A., Veen, D., Willemsen, J., et al. (2021). Bayesian statistics and modelling. Nature Reviews Methods Primers, 1(1), 1.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/introduction_mcmc.html",
    "href": "chapters/mcmc/introduction_mcmc.html",
    "title": "Introduzione",
    "section": "",
    "text": "In questa sezione della dispensa, ci concentreremo sulle procedure Monte Carlo a catena di Markov, con particolare attenzione all’algoritmo di Metropolis, che consente di approssimare la distribuzione a posteriori quando non è possibile ottenere una soluzione analitica. Esploreremo il concetto di predizione bayesiana, fondamentale per la costruzione della distribuzione predittiva a posteriori, e discuteremo anche la distribuzione predittiva a priori. Applicheremo l’inferenza bayesiana a diversi contesti, tra cui la stima di una proporzione, il confronto tra due proporzioni, la stima di una media da una distribuzione normale e il confronto tra due medie. Esamineremo inoltre il modello bayesiano di Poisson per l’analisi delle frequenze. Infine, introdurremo il modello gerarchico bayesiano, uno strumento potente per affrontare situazioni in cui le osservazioni sono strutturate su diversi livelli di incertezza.",
    "crumbs": [
      "MCMC",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html",
    "href": "chapters/mcmc/01_metropolis.html",
    "title": "56  L’algoritmo di Metropolis-Hastings",
    "section": "",
    "text": "Introduzione\nTuttavia, questi metodi presentano limitazioni significative non appena ci si allontana da contesti idealizzati. In particolare, diventano rapidamente inefficienti in presenza di modelli con molteplici parametri, relazioni complesse tra variabili, o distribuzioni a priori non coniugate. In tali casi, il calcolo analitico risulta spesso intrattabile, mentre l’approssimazione su griglia diventa computazionalmente proibitiva a causa della crescita esponenziale del numero di valutazioni necessarie al crescere della dimensionalità dello spazio parametrico.\nPer affrontare queste sfide, l’inferenza bayesiana moderna fa ricorso a tecniche numeriche avanzate, tra cui spicca il Metodo Monte Carlo a Catena di Markov (MCMC). Questo approccio innovativo supera i limiti dei metodi tradizionali generando campioni dalla distribuzione a posteriori attraverso un processo iterativo che combina l’efficienza del campionamento stocastico con la flessibilità degli algoritmi markoviani. Il risultato è una metodologia potente e generale, in grado di fornire stime accurate anche per modelli complessi e ad alta dimensionalità, senza richiedere soluzioni analitiche chiuse.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#lobiettivo-del-metodo-mcmc",
    "href": "chapters/mcmc/01_metropolis.html#lobiettivo-del-metodo-mcmc",
    "title": "56  L’algoritmo di Metropolis-Hastings",
    "section": "\n56.1 L’obiettivo del metodo MCMC",
    "text": "56.1 L’obiettivo del metodo MCMC\nIl metodo MCMC è un approccio computazionale che consente di approssimare distribuzioni di probabilità complesse, generando una sequenza di valori campionati che seguono la distribuzione a posteriori di interesse.\nL’idea di base è la seguente:\n\nconsideriamo la distribuzione a posteriori come una popolazione da cui desideriamo estrarre campioni;\ngenerando un numero sufficientemente grande di campioni (ad esempio, diverse migliaia), la distribuzione empirica dei campioni ottenuti si avvicina progressivamente alla distribuzione teorica a posteriori;\nin questo modo, possiamo stimare quantità di interesse, come la media, la varianza, o intervalli di credibilità, anche senza conoscere una forma analitica esplicita della distribuzione a posteriori.\n\n\n56.1.1 La natura dipendente del campionamento MCMC\nA differenza delle tecniche di campionamento indipendente precedentemente esaminate, l’approccio MCMC genera una sequenza di valori correlati attraverso un meccanismo di transizione markoviana. La caratteristica distintiva di questo processo risiede nella proprietà di Markov: ogni nuovo campione dipende esclusivamente dallo stato corrente della catena, mostrando memoria soltanto a breve termine piuttosto che dipendenza dall’intera storia precedente.\nQuesta architettura sequenziale produce inevitabilmente autocorrelazione tra osservazioni adiacenti. Quando la catena visita una regione ad alta densità della distribuzione target, tenderà a persistere in tale zona per diverse iterazioni prima di migrare verso altre regioni. Mentre tale comportamento è funzionale all’esplorazione efficiente dello spazio parametrico, introduce importanti considerazioni pratiche:\n\nl’informazione effettiva contenuta in \\(N\\) campioni correlati è inferiore a quella di \\(N\\) campioni indipendenti;\nla valutazione della convergenza richiede analisi diagnostiche specifiche;\nla dimensione efficace del campione (ESS) diventa un parametro cruciale per la qualità dell’inferenza.\n\nPer compensare questa riduzione di informazione per campione, è generalmente necessario generare sequenze più lunghe rispetto al campionamento indipendente. Tuttavia, questo svantaggio apparente è ampiamente compensato dalla capacità di MCMC di affrontare problemi complessi che risulterebbero intrattabili con metodi tradizionali.\n\n56.1.2 Perché utilizzare MCMC\nIl metodo MCMC è diventato uno strumento centrale nell’inferenza bayesiana contemporanea perché:\n\nè in grado di affrontare problemi complessi, caratterizzati da distribuzioni a posteriori di forma irregolare o definite in spazi ad alta dimensione;\nnon richiede il calcolo diretto dell’integrale di normalizzazione che compare nel teorema di Bayes;\npermette di ottenere approssimazioni accurate della distribuzione a posteriori tramite simulazione numerica.\n\nNel seguito ci concentreremo sull’algoritmo di Metropolis, uno dei metodi più semplici ed essenziali per implementare il campionamento MCMC.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#lalgoritmo-di-metropolis-introduzione-intuitiva",
    "href": "chapters/mcmc/01_metropolis.html#lalgoritmo-di-metropolis-introduzione-intuitiva",
    "title": "56  L’algoritmo di Metropolis-Hastings",
    "section": "\n56.2 L’algoritmo di Metropolis: introduzione intuitiva",
    "text": "56.2 L’algoritmo di Metropolis: introduzione intuitiva\nL’algoritmo di Metropolis è un metodo MCMC che consente di esplorare una distribuzione di probabilità complessa costruendo una sequenza di campioni dipendenti tra loro.\nLa logica dell’algoritmo può essere riassunta nei seguenti passaggi fondamentali:\n\n\nPunto di partenza: si inizia da un valore iniziale \\(\\theta_0\\) scelto arbitrariamente.\n\nProposta di un nuovo punto: si genera un nuovo valore candidato \\(\\theta^*\\) partendo da \\(\\theta_0\\), utilizzando una distribuzione di proposta (ad esempio una distribuzione normale centrata su \\(\\theta_0\\)).\n\nValutazione della proposta: si confrontano le densità a posteriori associate al valore attuale \\(\\theta_0\\) e al valore proposto \\(\\theta^*\\).\n\nDecisione di accettazione:\n\nse \\(\\theta^*\\) ha una densità a posteriori più alta di \\(\\theta_0\\), viene accettato automaticamente;\nse \\(\\theta^*\\) ha una densità a posteriori inferiore, viene accettato con una certa probabilità proporzionale al rapporto delle densità.\n\n\n\nRegistrazione: in ogni caso, si registra la posizione attuale (sia che si sia accettato un nuovo punto, sia che si sia rimasti fermi).\n\nQuesto processo viene ripetuto per un numero elevato di iterazioni, generando una catena di campioni che, dopo un opportuno periodo iniziale (detto burn-in), approssima la distribuzione a posteriori.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#perché-accettiamo-anche-mosse-peggiori",
    "href": "chapters/mcmc/01_metropolis.html#perché-accettiamo-anche-mosse-peggiori",
    "title": "56  L’algoritmo di Metropolis-Hastings",
    "section": "\n56.3 Perché accettiamo anche mosse peggiori",
    "text": "56.3 Perché accettiamo anche mosse peggiori\nUno degli aspetti peculiari dell’algoritmo di Metropolis è la possibilità di accettare anche proposte peggiori, ossia punti \\(\\theta^*\\) associati a una densità a posteriori minore rispetto allo stato attuale.\nQuesta scelta ha una motivazione fondamentale:\n\nse accettassimo solo le mosse che migliorano la densità, l’algoritmo rischierebbe di bloccarsi in un massimo locale della distribuzione, senza esplorare altre aree che, pur avendo densità più bassa localmente, potrebbero condurre a regioni più interessanti globalmente;\naccettare occasionalmente mosse peggiori consente all’algoritmo di esplorare meglio tutto lo spazio dei parametri, evitando di rimanere intrappolato in una singola area.\n\nIn questo modo, la catena può attraversare regioni di bassa probabilità e raggiungere altre modalità della distribuzione, garantendo una copertura più completa dello spazio delle soluzioni plausibili.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#la-scelta-della-larghezza-della-proposta",
    "href": "chapters/mcmc/01_metropolis.html#la-scelta-della-larghezza-della-proposta",
    "title": "56  L’algoritmo di Metropolis-Hastings",
    "section": "\n56.4 La scelta della larghezza della proposta",
    "text": "56.4 La scelta della larghezza della proposta\nNell’algoritmo di Metropolis, la proposta di un nuovo valore \\(\\theta^*\\) viene solitamente generata a partire dallo stato corrente \\(\\theta_t\\) utilizzando una distribuzione di proposta simmetrica, ad esempio una distribuzione normale \\(\\mathcal{N}(\\theta_t, \\tau^2)\\), dove \\(\\tau\\) rappresenta la deviazione standard della proposta.\nLa scelta del valore di \\(\\tau\\) (ovvero della larghezza della proposta) è cruciale per il buon funzionamento dell’algoritmo:\n\nse \\(\\tau\\) è troppo piccolo, i passi proposti saranno molto vicini al punto attuale. In questo caso, molte proposte saranno accettate, ma la catena si muoverà lentamente nello spazio dei parametri, esplorandolo inefficientemente (alta correlazione tra i campioni);\nse \\(\\tau\\) è troppo grande, i passi proposti saranno molto lontani dal punto attuale. In questo caso, la maggior parte delle proposte cadrà in regioni di bassa densità, portando a un alto tasso di rifiuto delle proposte e quindi a una scarsa efficienza del campionamento.\n\nUn valore ottimale di \\(\\tau\\) deve bilanciare:\n\n\naccettazione sufficiente di nuove proposte;\n\nesplorazione efficiente dello spazio dei parametri.\n\nIn generale, si cerca di ottenere un tasso di accettazione compreso tra il 40% e il 50% per l’algoritmo di Metropolis a singolo parametro.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#limportanza-dei-grafici-diagnostici-trace-plot-e-correlogramma",
    "href": "chapters/mcmc/01_metropolis.html#limportanza-dei-grafici-diagnostici-trace-plot-e-correlogramma",
    "title": "56  L’algoritmo di Metropolis-Hastings",
    "section": "\n56.5 L’importanza dei grafici diagnostici: Trace plot e Correlogramma",
    "text": "56.5 L’importanza dei grafici diagnostici: Trace plot e Correlogramma\nPer valutare la qualità della catena generata dall’algoritmo di Metropolis, è fondamentale analizzare alcuni grafici diagnostici.\n\n56.5.1 Trace plot\nIl trace plot rappresenta i valori campionati di \\(\\theta\\) in funzione del numero di iterazioni.\nUn trace plot di buona qualità mostra:\n\noscillazioni attorno a un valore centrale stabile (assenza di trend sistematici);\nuna copertura adeguata dello spazio plausibile per \\(\\theta\\).\n\nUn trace plot problematico può rivelare:\n\nfasi iniziali instabili (burn-in non sufficientemente lungo);\nmancata esplorazione completa della distribuzione;\nconvergenza solo apparente, con la catena bloccata in una modalità.\n\n56.5.2 Correlogramma\nIl correlogramma mostra il grado di autocorrelazione dei campioni in funzione del numero di passi di lag.\nIdealmente:\n\nl’autocorrelazione dovrebbe decrescere rapidamente all’aumentare del lag;\nuna catena ben mescolata presenta un correlogramma che si avvicina rapidamente a zero.\n\nUna forte autocorrelazione indica che i campioni successivi sono troppo simili tra loro, riducendo l’efficienza dell’inferenza statistica.\nQuesti concetti costituiscono il fondamento necessario per affrontare la comprensione operativa e pratica dell’algoritmo di Metropolis che svilupperemo nei prossimi esempi. A questo fine, il capitolo è strutturato in varie sezioni che facilitano la comprensione progressiva del tema.\n\nInizieremo discutendo di come la distribuzione a posteriori possa essere approssimata mediante tecniche di simulazione convenzionali. Questa prima parte presuppone che la distribuzione target, o “a posteriori,” sia già conosciuta o disponibile per l’analisi.\nIn seguito, passeremo a illustrare come l’algoritmo di Metropolis possa essere utilizzato per affrontare situazioni in cui la distribuzione a posteriori non è direttamente nota. In questi casi, spesso abbiamo a disposizione informazioni riguardanti la distribuzione a priori e la funzione di verosimiglianza, che possono essere utilizzate per ottenere un’approssimazione efficace della distribuzione a posteriori.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#un-esempio-concreto",
    "href": "chapters/mcmc/01_metropolis.html#un-esempio-concreto",
    "title": "56  L’algoritmo di Metropolis-Hastings",
    "section": "\n56.6 Un Esempio Concreto",
    "text": "56.6 Un Esempio Concreto\nA titolo esemplificativo, utilizzeremo il dataset moma_sample.csv, il quale costituisce un campione casuale di 100 artisti provenienti dal Museo di Arte Moderna di New York (MoMA) e contiene diverse informazioni relative a ciascun artista.\nIl nostro interesse è focalizzato sulla determinazione della probabilità che un artista presente nel MoMA appartenga alla generazione X o a una generazione successiva (nati dopo il 1965). Questa probabilità sarà indicata come \\(\\pi\\).\nImportiamo i dati.\n\nmoma_sample &lt;- rio::import(here::here(\"data\", \"moma_sample.csv\"))\n\nEsaminiamo le prime cinque righe del DataFrame.\n\nmoma_sample |&gt; \n  head()\n#&gt;                artist  country birth death alive  genx gender count\n#&gt; 1        Ad Gerritsen    dutch  1940  2015 FALSE FALSE   male     1\n#&gt; 2 Kirstine Roepstorff   danish  1972    NA  TRUE  TRUE female     3\n#&gt; 3    Lisa Baumgardner american  1958  2015 FALSE FALSE female     2\n#&gt; 4         David Bates american  1952    NA  TRUE FALSE   male     1\n#&gt; 5          Simon Levy american  1946    NA  TRUE FALSE   male     1\n#&gt; 6      Pierre Mercure canadian  1927  1966 FALSE FALSE   male     8\n#&gt;   year_acquired_min year_acquired_max\n#&gt; 1              1981              1981\n#&gt; 2              2005              2005\n#&gt; 3              2016              2016\n#&gt; 4              2001              2001\n#&gt; 5              2012              2012\n#&gt; 6              2008              2008\n\nDai dati osserviamo che solo 14 artisti su 100 appartengono alla generazione X o a una generazione successiva.\n\n# Calcoliamo la distribuzione delle generazioni\nresult &lt;- table(moma_sample$genx)\nresult\n#&gt; \n#&gt; FALSE  TRUE \n#&gt;    86    14\n\nIl valore campionato \\(y = 14\\) riflette le caratteristiche del campione che è stato osservato. Tuttavia, poiché il MOMA contiene opere di migliaia di artisti, sorge una domanda riguardante il vero valore di \\(\\theta\\) (la probabilità di appartenere alla generazione X o a una generazione successiva) all’interno di questa popolazione.\nPossiamo interpretare i dati \\(y = 14\\) come l’esito di una variabile casuale Binomiale con parametri \\(N = 100\\) e \\(\\theta\\) sconosciuto.\nSupponiamo che le nostre credenze pregresse riguardo a \\(\\theta\\) possano essere modellate attraverso una distribuzione Beta(4, 6).\n\ntibble(x = seq(0, 1, .01),\n       y = dbeta(x, 4, 6)) |&gt;\n  ggplot(aes(x=x, y=y)) + \n  geom_line()\n\n\n\n\n\n\n\nSfruttando le proprietà delle distribuzioni coniugate, possiamo calcolare esattamente la distribuzione a posteriori:\n# Y ~ Binomiale(100, π)\n# θ ~ Beta(4, 6)\n# Posteriori: θ | (Y = 14) ~ Beta(4 + 14, 6 + 100 - 14) → Beta(18, 92)\nNella figura seguente, è rappresentata la distribuzione a posteriori del parametro \\(\\theta\\), insieme alla distribuzione a priori specificata.\n\n# Sequenza per θ\nx &lt;- seq(0, 1, length.out = 1000)\n\n# Densità prior e posterior\nprior_density     &lt;- dbeta(x, 4, 6)\nposterior_density &lt;- dbeta(x, 18, 92)\n\n# Dati per il grafico\ndf &lt;- data.frame(\n  x = x,\n  prior = prior_density,\n  posterior = posterior_density\n)\n\n# Lungo\ndf_long &lt;- reshape2::melt(\n  df,\n  id.vars = \"x\",\n  measure.vars = c(\"prior\", \"posterior\"),\n  variable.name = \"distribuzione\",\n  value.name = \"densita\"\n)\n\n# Fattorizziamo con levels e labels espliciti\ndf_long &lt;- dplyr::mutate(\n  df_long,\n  distribuzione = factor(\n    distribuzione,\n    levels = c(\"prior\", \"posterior\"),\n    labels = c(\"Prior: Beta(4, 6)\", \"Posterior: Beta(18, 92)\")\n  )\n)\n\nif (!exists(\"palette_set1\")) {\n  palette_set1 &lt;- RColorBrewer::brewer.pal(3, \"Set1\")\n  names(palette_set1) &lt;- c(\"uno\",\"due\",\"tre\")\n}\n\ncols &lt;- c(\n  \"Prior: Beta(4, 6)\"       = unname(palette_set1[[1]]),\n  \"Posterior: Beta(18, 92)\" = unname(palette_set1[[2]])\n)\n\n# Grafico\nggplot(df_long, aes(x = x, y = densita)) +\n  geom_line(aes(color = distribuzione), linewidth = 1) +\n  geom_area(aes(fill = distribuzione), alpha = 0.35, position = \"identity\") +\n  scale_color_manual(values = cols, breaks = names(cols), labels = names(cols)) +\n  scale_fill_manual(values = cols,  breaks = names(cols), labels = names(cols)) +\n  labs(\n    title = \"Densità a priori e a posteriori\",\n    x = \"Valore del parametro\",\n    y = \"Densità\",\n    color = NULL, fill = NULL\n  ) +\n  theme(\n    plot.title = element_text(hjust = 0.5),\n    legend.position = \"top\"\n  )\n\n\n\n\n\n\n\nIn questo grafico, la curva blu rappresenta la distribuzione a priori \\(\\text{Beta}(4, 6)\\), mentre la curva rossa mostra la distribuzione a posteriori \\(\\text{Beta}(18, 92)\\). La sovrapposizione delle aree evidenzia come l’evidenza fornita dai dati modifichi la conoscenza iniziale sul parametro \\(\\theta\\).\nSe vogliamo conoscere il valore della media a posteriori di \\(\\theta\\), il risultato esatto è\n\\[\n\\bar{\\theta}_{post} = \\frac{\\alpha}{\\alpha + \\beta} = \\frac{18}{18 + 92} \\approx 0.1636.\n\\]\n\n56.6.1 Simulazione con distribuzione target nota\nUsiamo ora una simulazione numerica per stimare la media a posteriori di \\(\\theta\\). Conoscendo la forma della distribuzione a posteriori \\(Beta(18, 92)\\), possiamo generare un campione di osservazioni casuali da questa distribuzione. Successivamente, calcoliamo la media delle osservazioni ottenute per ottenere un’approssimazione della media a posteriori.\nSe vogliamo ottenere un risultato approssimato con un numero limitato di campioni (ad esempio, 10), possiamo utilizzare la seguente simulazione:\n\n# Generiamo 10 campioni dalla distribuzione Beta(18, 92)\nset.seed(1234)  # Per riproducibilità\ny &lt;- rbeta(10, shape1 = 18, shape2 = 92)\ny\n#&gt;  [1] 0.11831 0.17511 0.21473 0.07692 0.18174 0.18522 0.14156 0.14261 0.14194\n#&gt; [10] 0.12992\n\n\n# Calcoliamo la media dei campioni\nmean(y)\n#&gt; [1] 0.1508\n\nTuttavia, con soli 10 campioni, l’approssimazione potrebbe non essere molto accurata. Aumentando il numero di campioni, ad esempio a 10,000, possiamo ottenere una stima molto più precisa:\n\n# Generiamo 10000 campioni e calcoliamo la media\nset.seed(123)  # Per riproducibilità\nmean(rbeta(10000, shape1 = 18, shape2 = 92))\n#&gt; [1] 0.1637\n\nQuando il numero di campioni dalla distribuzione a posteriori diventa molto grande, la media campionaria converge al valore atteso della distribuzione della popolazione. Questo principio non si applica solo alla media, ma anche ad altre statistiche descrittive come la moda e la varianza.\nÈ importante sottolineare che l’applicazione della simulazione di Monte Carlo è efficace per calcolare distribuzioni a posteriori solo quando conosciamo la distribuzione stessa e possiamo utilizzare funzioni R per estrarre campioni casuali da tale distribuzione. Ciò è stato possibile nel caso della distribuzione a posteriori \\(Beta(18, 92)\\).\nTuttavia, questa situazione ideale non si verifica sempre nella pratica, poiché le distribuzioni a priori coniugate alla verosimiglianza sono spesso rare. Per esempio, nel caso di una verosimiglianza binomiale e una distribuzione a priori gaussiana, l’espressione\n\\[\np(\\theta \\mid y) = \\frac{\\mathrm{e}^{-(\\theta - 1 / 2)^2} \\theta^y (1 - \\theta)^{n - y}} {\\int_0^1 \\mathrm{e}^{-(t - 1 / 2)^2} t^y (1 - t)^{n - y} dt}\n\\]\nrende impossibile calcolare analiticamente la distribuzione a posteriori di \\(\\theta\\), precludendo quindi l’utilizzo diretto di R per generare campioni casuali.\nIn queste circostanze, però, è possibile ottenere campioni casuali dalla distribuzione a posteriori mediante l’uso di metodi Monte Carlo basati su Catena di Markov (MCMC). Gli algoritmi MCMC, come ad esempio l’algoritmo Metropolis, costituiscono una classe di metodi che consentono di estrarre campioni casuali dalla distribuzione a posteriori senza richiedere la conoscenza della sua rappresentazione analitica. Le tecniche MCMC sono ampiamente adottate per risolvere problemi di inferenza bayesiana e rappresentano il principale strumento computazionale per ottenere stime approssimate di distribuzioni a posteriori in situazioni complesse e non analiticamente trattabili.\n\n56.6.2 Algoritmo di Metropolis\nL’algoritmo di Metropolis appartiene alla famiglia dei metodi Monte Carlo basati su catene di Markov (MCMC), sfruttando le proprietà di queste catene per generare campioni da una distribuzione target. Il suo obiettivo principale è di esplorare lo spazio dei parametri in modo efficiente, producendo campioni che approssimano la distribuzione a posteriori di interesse.\n\n56.6.3 Principio di Funzionamento\nL’algoritmo inizia da un valore iniziale per i parametri e, in ogni iterazione, genera un nuovo campione tramite una distribuzione di proposta (solitamente una distribuzione normale centrata sul valore corrente). Successivamente, decide se accettare il nuovo campione in base al confronto tra le densità posteriori del nuovo campione e di quello precedente. Questa accettazione avviene in modo probabilistico, favorendo campioni con una densità più alta ma consentendo anche l’accettazione di campioni peggiori per evitare che la catena rimanga bloccata in minimi locali.\n\n56.6.4 Burn-in e Convergenza\nPoiché i primi campioni potrebbero non rappresentare bene la distribuzione target, si esclude spesso una porzione iniziale della catena (fase di burn-in). Con il progredire delle iterazioni, i campioni si distribuiscono in accordo con la distribuzione stazionaria desiderata, indipendentemente dallo stato iniziale scelto. Questo processo permette di esplorare lo spazio dei parametri in modo efficiente.\n\n56.6.5 Meccanismo di Accettazione e Rifiuto\nL’algoritmo di Metropolis bilancia due esigenze opposte:\n\n\nEsplorazione di nuove aree dello spazio dei parametri.\n\nSfruttamento delle informazioni già acquisite dai campioni precedenti.\n\nUtilizzando una regola probabilistica per accettare campioni peggiori (con minore densità a posteriori), l’algoritmo evita di restare intrappolato in minimi locali, esplorando così in modo più completo l’intera distribuzione.\n\n56.6.6 Passaggi Fondamentali dell’Algoritmo di Metropolis\n\n\nScelta di uno stato iniziale \\(\\theta_1\\) e impostazione del contatore \\(t = 1\\).\n\nQuesto è il punto di partenza della catena, dove \\(\\theta_1\\) rappresenta il primo campione.\n\n\n\nProposta di un nuovo campione \\(\\theta_p\\).\n\nUn nuovo valore \\(\\theta_p\\) viene generato da una distribuzione di proposta \\(g(\\theta_p \\mid \\theta_t)\\), solitamente una distribuzione normale centrata sul campione corrente \\(\\theta_t\\) con una deviazione standard \\(\\tau\\) che controlla l’ampiezza dei passi.\n\n\n\nVerifica dei vincoli del campione proposto.\n\nSe il nuovo campione deve rispettare dei vincoli (ad esempio, essere compreso tra 0 e 1 per probabilità), campioni non validi vengono automaticamente rifiutati.\n\n\n\nCalcolo del rapporto di accettazione \\(\\alpha\\).\n\nSi calcola \\(\\alpha = \\frac{p(\\theta_p \\mid y)}{p(\\theta_t \\mid y)}\\), che rappresenta il rapporto tra le densità a posteriori del nuovo campione \\(\\theta_p\\) e del campione corrente \\(\\theta_t\\). Questo valore guida la decisione di accettazione.\n\n\n\nDecisione di accettazione.\n\nSe \\(\\alpha \\geq 1\\), il nuovo campione \\(\\theta_p\\) viene accettato incondizionatamente.\nSe \\(\\alpha &lt; 1\\), il campione \\(\\theta_p\\) viene accettato con probabilità \\(\\alpha\\). In caso di rifiuto, si mantiene il campione corrente \\(\\theta_t\\) per la prossima iterazione.\n\n\n\nRipetizione del processo.\n\nSi ripetono i passaggi dal 2 al 5 fino a ottenere il numero desiderato di campioni.\n\n\n\n56.6.7 Dettagli Aggiuntivi\n\nDistribuzione di proposta: La distribuzione di proposta \\(g(\\theta_p \\mid \\theta_t)\\) genera nuovi campioni attorno a \\(\\theta_t\\). Tipicamente si usa una normale \\(N(\\theta_t, \\tau)\\), dove \\(\\tau\\) controlla quanto il nuovo campione si discosta da quello corrente. Scegliere un \\(\\tau\\) troppo piccolo può rendere l’esplorazione lenta, mentre un \\(\\tau\\) troppo grande può far rifiutare troppi campioni, riducendo l’efficienza.\nRapporto di accettazione \\(\\alpha\\): Se il nuovo campione ha una densità a posteriori maggiore del campione corrente, viene sempre accettato. Se ha una densità inferiore, viene accettato con probabilità \\(\\alpha\\), il che consente di esplorare anche regioni meno probabili della distribuzione.\nAccettazione probabilistica: Accettare campioni peggiori occasionalmente aiuta l’algoritmo a evitare di bloccarsi in minimi locali. Questo è uno dei punti di forza dell’algoritmo di Metropolis, che garantisce una buona esplorazione dello spazio dei parametri.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#esempio-di-implementazione",
    "href": "chapters/mcmc/01_metropolis.html#esempio-di-implementazione",
    "title": "56  L’algoritmo di Metropolis-Hastings",
    "section": "\n56.7 Esempio di Implementazione",
    "text": "56.7 Esempio di Implementazione\nSupponiamo di voler stimare la probabilità \\(\\theta\\) che un artista della Generazione X sia esposto al MoMA. Disponiamo di 14 successi (presenze) osservati su un campione di 100 artisti. Adottiamo un modello binomiale con distribuzione a priori Beta(4, 6) per \\(\\theta\\), integrando dati osservati e conoscenza a priori mediante l’algoritmo MCMC. Seguiremo l’impostazione metodologica proposta da Elizaveta Semenova, implementando l’algoritmo di Metropolis-Hastings in R. Cominciamo definendo alcune funzioni fondamentali.\n\n56.7.1 Definizione della Distribuzione a Priori\nLa funzione prior calcola la densità della distribuzione Beta(4, 6) per un dato \\(\\theta\\):\n\n# Distribuzione a priori Beta(4, 6)\nprior &lt;- function(p) {\n  dbeta(p, shape1 = 4, shape2 = 6)\n}\n\nQuesta distribuzione esprime la nostra plausibilità iniziale sui valori di \\(\\theta\\) prima di osservare i dati.\n\n56.7.2 Funzione di Verosimiglianza\nLa funzione likelihood modella la probabilità di osservare 14 successi su 100 prove:\n\n# Verosimiglianza binomiale (y = 14 successi su n = 100 prove)\nlikelihood &lt;- function(p) {\n  y &lt;- 14\n  n &lt;- 100\n  dbinom(y, size = n, prob = p)\n}\n\n\n56.7.3 Distribuzione a Posteriori Non Normalizzata\nLa posteriori si ottiene combinando priori e verosimiglianza:\n\n# Posteriori non normalizzata (prodotto tra verosimiglianza e priori)\nposterior &lt;- function(p) {\n  likelihood(p) * prior(p)\n}\n\n\n56.7.4 Distribuzione Proposta\nLa distribuzione proposta sarà una distribuzione normale centrata sullo stato corrente con una deviazione standard specificata:\n\n# Generazione proposta (normale con media sullo stato corrente)\nproposal_distribution &lt;- function(current_state, proposal_sigma) {\n  rnorm(1, mean = current_state, sd = proposal_sigma)\n}\n\n\n56.7.5 Implementazione dell’Algoritmo Metropolis-Hastings\nProcediamo ora con l’implementazione dell’algoritmo di Metropolis-Hastings, considerando i dati relativi agli artisti della Generazione X presenti al MoMA. La distribuzione a priori per \\(\\theta\\) è modellata come una Beta(4, 6).\n\n# Algoritmo Metropolis-Hastings\nmetropolis_hastings &lt;- function(n_samples, start, proposal_sigma) {\n  samples &lt;- numeric(n_samples)\n  current &lt;- start  # Stato iniziale\n\n  for (i in seq_len(n_samples)) {\n    proposal &lt;- proposal_distribution(current, proposal_sigma)\n    \n    # Verifica validità e calcolo rapporto di accettazione\n    if (proposal &gt;= 0 && proposal &lt;= 1) {\n      acceptance_ratio &lt;- min(1, posterior(proposal) / posterior(current))\n      # Accetta/rifiuta con probabilità acceptance_ratio\n      if (runif(1) &lt; acceptance_ratio) {\n        current &lt;- proposal\n      }\n    }\n    samples[i] &lt;- current  # Aggiorna la catena\n  }\n  return(samples)\n}\n\n\n\n\n\n\n\nInterpretazione intuitiva\n\n\n\n\n\nImmaginate di esplorare un paesaggio montuoso (la posteriori) avvolto dalla nebbia, dove le alture rappresentano regioni ad alta densità di probabilità. L’algoritmo replica il comportamento di un escursionista che:\n\n\nValuta la posizione corrente (current) tramite l’altezza locale (posterior(current)).\n\nPropone un passo casuale in una direzione vicina (proposal), determinata da una distribuzione normale.\n\nDecide il movimento confrontando le altezze relative:\n\nSe il nuovo punto è più alto (\\(R \\geq 1\\)), lo accetta immediatamente.\nSe è più basso (\\(R &lt; 1\\)), lo accetta con probabilità \\(R\\), simulando un’accettazione stocastica per evitare massimi locali.\n\n\n\nRegistra ogni posizione visitata, costruendo gradualmente una mappa proporzionale alla vera distribuzione.\n\n\n\n\n\n\n\n\n\n\nDettagli dell’implementazione (1)\n\n\n\n\n\nNel codice la “regola &gt; 1 → accetta” è incorporata in queste due istruzioni consecutive:\nacceptance_ratio &lt;- min(1, posterior(proposal) / posterior(current))\n...\nif (runif(1) &lt; acceptance_ratio) {\n    current &lt;- proposal\n}\n\n\nClipping a 1 con min(1, …)\n\nSe il rapporto \\(\\frac{\\text{posterior(proposal)}}{\\text{posterior(current)}}\\) è maggiore di 1 (cioè il nuovo punto ha densità a‐posteriori più alta), min() lo tronca a 1.\n\nQuindi acceptance_ratio vale esattamente 1 in tutti i casi in cui il “vero” rapporto sarebbe &gt; 1.\n\n\n\nAccettazione certa con il confronto runif(1) &lt; 1\n\n\nrunif(1) genera un numero uniforme in \\([0,1)\\); qualunque valore estratto sarà sempre &lt; 1.\n\nDi conseguenza, quando acceptance_ratio è 1 l’if è sempre vero e il punto proposto viene accettato con probabilità 1, esattamente come prescrive l’algoritmo di Metropolis (o di Metropolis-Hastings nel caso simmetrico).\n\n\n\nIn sintesi, la riga con min(1, …) traduce la regola teorica “accetta se il rapporto è &gt; 1” in una forma pratica che si integra con il test probabilistico successivo.\n\n\n\n\n\n\n\n\n\nDettagli dell’implementazione (2)\n\n\n\n\n\nProprietà della proposta simmetrica: L’algoritmo di Metropolis (quello base come questo) funziona bene se la maniera in cui proponi di “spostarti” da un punto A a un punto B è esattamente la stessa della maniera in cui proporresti di spostarti da B ad A. Pensa a una proposta “neutra” rispetto alla direzione. Questa “simmetria” nella proposta è utile perché ci permette di decidere se accettare un passo basandoci esclusivamente sul confronto della ‘probabilità’ (la densità) dei due punti (proposto e attuale) sotto la distribuzione che vogliamo esplorare. In pratica, non dobbiamo preoccuparci di ‘correggere’ il rapporto di accettazione per tenere conto di proposte che potrebbero essere più facili in una direzione che nell’altra. Questa semplicità aiuta l’algoritmo a trovare il giusto bilanciamento negli spostamenti, permettendogli di campionare correttamente dalla distribuzione desiderata nel lungo periodo.\n\n\n\n\n56.7.6 Esecuzione dell’Algoritmo\n\n# Parametri dell'algoritmo\nn_samples &lt;- 10000\nstart &lt;- 0.5\nproposal_sigma &lt;- 0.1\n\n# Esecuzione del campionamento\nset.seed(123)  # Per riproducibilità\nsamples &lt;- metropolis_hastings(n_samples, start, proposal_sigma)\n\n\n56.7.7 Analisi dei Risultati\nScartiamo i primi 5000 campioni per considerare solo quelli generati dopo il burn-in:\n\nburnin &lt;- floor(n_samples * 0.5)\npost_burnin_samples &lt;- samples[-seq_len(burnin)]\n\nCalcoliamo la media e la deviazione standard dei campioni:\n\n# Media a posteriori\nmean(post_burnin_samples)\n#&gt; [1] 0.1631\n\n# Deviazione standard a posteriori\nsd(post_burnin_samples)\n#&gt; [1] 0.03535\n\nVisualizziamo l’evoluzione della catena per i primi 200 campioni e per quelli post-burn-in:\n\ntibble(\n  Iterazione = 1:200,\n  Theta = samples[1:200]\n) |&gt; \n  ggplot(aes(x = Iterazione, y = Theta)) +\n    geom_line() + # Specifica che vuoi un grafico a linea\n    ggtitle(\"Trace Plot (Primi 200 Campioni)\") + # Aggiunge il titolo principale\n    xlab(\"Iterazioni\") + # Etichetta l'asse X\n    ylab(expression(theta)) # Etichetta l'asse Y usando l'espressione per theta\n\n\n\n\n\n\n\n\ntibble(\n  Iterazione = 1:length(post_burnin_samples), \n  Theta = post_burnin_samples\n) |&gt; \n  ggplot(aes(x = Iterazione, y = Theta)) +\n    geom_line() + # Specifica un grafico a linea\n    ggtitle(\"Trace Plot (Post Burn-in)\") + # Aggiunge il titolo\n    xlab(\"Iterazioni\") + # Indice all'interno della serie post-burn-in\n    ylab(expression(theta)) # Etichetta l'asse Y\n\n\n\n\n\n\n\nSovrapponiamo la distribuzione analitica \\(\\text{Beta}(18, 92)\\) all’istogramma dei campioni post-burn-in:\n\n# Se per qualche motivo non è stato caricato _common.R:\nif (!exists(\"palette_set1\")) {\n  palette_set1 &lt;- RColorBrewer::brewer.pal(3, \"Set1\")\n  names(palette_set1) &lt;- c(\"uno\", \"due\", \"tre\")\n}\n\n# Mappa colori coerente con la figura precedente\ncolori_grafico &lt;- c(\n  \"Istogramma MCMC\" = unname(palette_set1[[1]]),\n  \"Beta(18, 92)\"    = unname(palette_set1[[2]])\n)\n\ntibble(Theta = post_burnin_samples) |&gt; \n  ggplot(aes(x = Theta)) +\n  geom_histogram(\n    aes(y = after_stat(density), fill = \"Istogramma MCMC\"),\n    bins = 30, \n    color = \"black\", \n    alpha = 0.7\n  ) + \n  stat_function(\n    aes(color = \"Beta(18, 92)\"),\n    fun = dbeta,\n    args = list(shape1 = 18, shape2 = 92), \n    linewidth = 1.2\n  ) + \n  labs(\n    title = \"Istogramma e distribuzione a posteriori\",\n    x = expression(theta),\n    y = \"Densità\",\n    fill = \"Distribuzione\", \n    color = \"Distribuzione\"\n  ) +\n  scale_fill_manual(values = colori_grafico, breaks = names(colori_grafico)) +\n  scale_color_manual(values = colori_grafico, breaks = names(colori_grafico)) +\n  theme(\n    plot.title = element_text(hjust = 0.5),\n    legend.position = \"top\"\n  )\n\n\n\n\n\n\n\nCalcoliamo l’intervallo di credibilità al 94%:\n\nquantile(post_burnin_samples, probs = c(0.03, 0.97))\n#&gt;     3%    97% \n#&gt; 0.1020 0.2347\n\nI valori ottenuti con l’algoritmo di Metropolis (usando solo un piccolo numero di iterazioni) sono quasi identici ai valori esatti:\n\nqbeta(c(0.03, 0.97), 18, 92)\n#&gt; [1] 0.1030 0.2346\n\nQuesta implementazione in R dimostra come utilizzare l’algoritmo di Metropolis per stimare una distribuzione a posteriori e analizzare i risultati in modo dettagliato e riproducibile.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#catene-di-markov-e-convergenza",
    "href": "chapters/mcmc/01_metropolis.html#catene-di-markov-e-convergenza",
    "title": "56  L’algoritmo di Metropolis-Hastings",
    "section": "\n56.8 Catene di Markov e Convergenza",
    "text": "56.8 Catene di Markov e Convergenza\nNell’ambito delle simulazioni Monte Carlo, una catena rappresenta una sequenza di valori campionati dall’algoritmo durante le sue iterazioni. Ogni valore nella catena corrisponde a un possibile stato del sistema che stiamo modellando. In altre parole, una catena traccia il percorso che l’algoritmo segue nello spazio dei parametri, esplorando le diverse configurazioni possibili.\nPer verificare se l’algoritmo ha raggiunto la convergenza e se i campioni generati rappresentano effettivamente la distribuzione di interesse, è utile eseguire multiple catene. Ogni catena parte da un punto iniziale diverso nello spazio dei parametri.\nI vantaggi delle multiple catene:\n\n\nDiagnostica della convergenza: Confrontando le diverse catene, possiamo valutare se si stabilizzano verso la stessa distribuzione. Se le catene si mescolano bene, ovvero si intersecano frequentemente nel grafico dei valori campionati (trace plot), è un forte indicatore di convergenza.\n\nRobustezza: L’utilizzo di multiple catene rende l’analisi meno sensibile alla scelta del punto di partenza. Se una singola catena potesse rimanere “intrappolata” in una regione dello spazio dei parametri, multiple catene aumentano la probabilità di esplorare lo spazio in modo più completo.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#diagnostiche-della-soluzione-mcmc",
    "href": "chapters/mcmc/01_metropolis.html#diagnostiche-della-soluzione-mcmc",
    "title": "56  L’algoritmo di Metropolis-Hastings",
    "section": "\n56.9 Diagnostiche della soluzione MCMC",
    "text": "56.9 Diagnostiche della soluzione MCMC\n\n56.9.1 Stazionarietà e Convergenza\nUn aspetto cruciale nell’analisi delle catene di Markov MCMC è la convergenza alla distribuzione stazionaria. Intuitivamente, la catena converge quando i campioni generati rappresentano fedelmente la distribuzione di interesse, indipendentemente dal punto di partenza. Questo fenomeno è spesso indicato come “mixing”.\n\n56.9.1.1 Valutazione Visuale: Trace Plots e Grafici di Densità\n\n\nTrace Plots: Questi grafici visualizzano l’evoluzione dei parametri nel tempo. Una catena convergente mostra tracce stabili e senza trend evidenti. Tracce irregolari o con andamenti sistematici suggeriscono problemi di convergenza.\n\nGrafici di Densità: Confrontando i grafici di densità dei campioni con la distribuzione teorica, è possibile valutare visivamente se la catena sta esplorando adeguatamente lo spazio dei parametri. Una buona convergenza si manifesta con una sovrapposizione tra i due grafici.\n\nSegni di Convergenza:\n\n\nStabilità: I valori campionati oscillano attorno a un valore medio costante, senza trend marcati.\n\nOmogeneità: La variabilità dei campioni rimane relativamente uniforme nel tempo.\n\nAssenza di Periodicità: Non si osservano pattern ciclici o ripetitivi.\n\nIn sintesi, i trace plots e i grafici di densità offrono strumenti visivi rapidi per valutare la convergenza di una catena di Markov MCMC. Una convergenza soddisfacente è fondamentale per garantire la validità delle inferenze statistiche basate sui campioni generati.\n\n56.9.2 Autocorrelazione nelle catene di Markov MCMC\nA differenza dei generatori di numeri casuali indipendenti, gli algoritmi MCMC producono una sequenza di campioni correlati. Ogni valore campionato dipende da quello precedente, formando una catena di Markov. Questa interdipendenza è un aspetto fondamentale dell’MCMC.\nL’autocorrelazione quantifica il grado di dipendenza tra valori distanti di una certa quantità (detta lag) nella catena. Un’alta autocorrelazione a lag bassi indica una forte dipendenza tra campioni successivi. Al contrario, una rapida diminuzione dell’autocorrelazione al crescere del lag suggerisce che la catena “miscela” bene, ovvero esplora lo spazio dei parametri in modo efficiente.\n\n\nLag 1: Misura la correlazione tra valori consecutivi nella catena.\n\nLag 2: Misura la correlazione tra valori separati da un passo intermedio.\n\nLag k: Generalizza il concetto ai valori separati da k passi.\n\nUn correlogramma è un grafico che mostra l’autocorrelazione in funzione del lag. Un decadimento rapido dell’autocorrelazione verso zero indica una buona convergenza della catena.\nL’autocorrelazione di ordine \\(k\\) è data da \\(\\rho_k\\) e può essere stimata come:\n\\[\n\\begin{aligned}\n\\rho_k &= \\frac{Cov(\\theta_m, \\theta_{m+k})}{Var(\\theta_m)}\\notag\\\\\n&= \\frac{\\sum_{m=1}^{n-k}(\\theta_m - \\bar{\\theta})(\\theta_{m-k} - \\bar{\\theta})}{\\sum_{m=1}^{n-k}(\\theta_m - \\bar{\\theta})^2} \\qquad\\text{con }\\quad \\bar{\\theta} = \\frac{1}{n}\\sum_{m=1}^{n}\\theta_m.\n\\end{aligned}\n\\tag{56.1}\\]\n\n56.9.3 Esempio di Simulazione di Dati Autocorrelati\nPer fare un esempio pratico, creiamo un vettore di dati autocorrelati:\n\n# Creiamo un vettore di dati\nx &lt;- c(22, 24, 25, 25, 28, 29, 34, 37, 40, 44, 51, 48, 47, 50, 51)\nx\n#&gt;  [1] 22 24 25 25 28 29 34 37 40 44 51 48 47 50 51\n\n\n56.9.3.1 Calcolo dell’Autocorrelazione\nL’autocorrelazione di ordine 1 è la correlazione tra ciascun elemento e il successivo nella sequenza. In R possiamo utilizzare la funzione acf() per calcolare l’autocorrelazione.\n\n# Calcolo dell'autocorrelazione\nacf_values &lt;- acf(x, plot = FALSE)\nacf_values\n#&gt; \n#&gt; Autocorrelations of series 'x', by lag\n#&gt; \n#&gt;      0      1      2      3      4      5      6      7      8      9 \n#&gt;  1.000  0.832  0.656  0.491  0.279  0.031 -0.165 -0.304 -0.401 -0.458 \n#&gt;     10     11 \n#&gt; -0.450 -0.369\n\nNell’esempio, il vettore x rappresenta una serie temporale di 15 elementi. Il calcolo dell’autocorrelazione restituisce i seguenti valori per i primi ritardi (lag):\n\n\n0.8317: autocorrelazione di ordine 1 (lag = 1),\n\n0.6563: autocorrelazione di ordine 2 (lag = 2),\n\n0.4910: autocorrelazione di ordine 3 (lag = 3),\necc.\n\n56.9.3.2 Specifica del Numero di Ritardi (Lag)\nPossiamo limitare il numero di ritardi calcolati utilizzando l’argomento lag.max nella funzione acf():\n\n# Calcolo dell'autocorrelazione per i primi 4 lag\nacf(x, lag.max = 4, plot = FALSE)\n#&gt; \n#&gt; Autocorrelations of series 'x', by lag\n#&gt; \n#&gt;     0     1     2     3     4 \n#&gt; 1.000 0.832 0.656 0.491 0.279\n\n\n56.9.3.3 Grafico della Funzione di Autocorrelazione (Correlogramma)\nIn R possiamo creare un correlogramma con la funzione acf():\n\n# Correlogramma per la serie temporale\nacf(x, main = \"Correlogramma della Serie Temporale\", lag.max = 9)\n\n\n\n\n\n\n\n\n56.9.4 Analisi della Catena di Markov\nApplichiamo lo stesso approccio alla catena di Markov ottenuta precedentemente, considerando i campioni post burn-in:\n\n# Definizione dei campioni post burn-in\npost_burnin_samples &lt;- samples[-seq_len(burnin)]\n\n# Correlogramma per i campioni post burn-in\nacf(\n  post_burnin_samples, \n  main = \"Correlogramma della Catena Post Burn-in\", \n  lag.max = 9\n)\n\n\n\n\n\n\n\nIn situazioni ideali, l’autocorrelazione diminuisce rapidamente, diventando insignificante per piccoli lag. Questo comportamento è un’indicazione del “mixing” efficace della catena, ossia della sua convergenza alla distribuzione stazionaria.\n\n56.9.5 Sottocampionamento (Thinning)\nPer ridurre l’autocorrelazione, possiamo applicare una strategia di sottocampionamento (thinning), memorizzando solo ogni \\(m\\)-esimo campione.\n\n# Sottocampionamento con un fattore di 5\nthin &lt;- 5\nsampsthin &lt;- \n  post_burnin_samples[seq(1, length(post_burnin_samples), by = thin)]\n\n# Correlogramma per i campioni sottocampionati\nacf(\n  sampsthin, \n  main = \"Correlogramma con Sottocampionamento (Thinning)\", \n  lag.max = 9\n)\n\n\n\n\n\n\n\nIn conclusione, il correlogramma con thinning mostra che l’autocorrelazione diminuisce più rapidamente rispetto ai campioni originali, suggerendo che la strategia di sottocampionamento è efficace nel migliorare l’indipendenza tra i campioni successivi. Questo migliora la qualità delle inferenze basate sulla catena di Markov.\n\n56.9.5.1 Tasso di accettazione\nQuando si utilizza l’algoritmo Metropolis, è importante monitorare il tasso di accettazione e assicurarsi che sia nell’intervallo ottimale. Se si accetta quasi sempre il candidato proposto, probabilmente significa che, in ogni iterazione, la catena salta solo di un piccolo passo (in modo che il rapporto di accettazione sia vicino a 1 ogni volta). Di conseguenza, la catena impiegherà molte iterazioni per raggiungere altre regioni della distribuzione stazionaria e i campioni consecutivi saranno molto fortemente correlati. D’altra parte, se il tasso di accettazione è molto basso, la catena rimarrà bloccata nella stessa posizione per molte iterazioni prima di spostarsi verso uno stato diverso. Per l’algoritmo Metropolis base con un singolo parametro con una distribuzione proposta Gaussiana normale, un tasso di accettazione ottimale è compreso tra il 40% e il 50%.\n\n56.9.6 Test Statistici per la Convergenza\nOltre agli approcci grafici, esistono test statistici specifici che possono aiutare a determinare se la catena ha raggiunto uno stato stazionario.\n\n56.9.6.1 Test di Geweke\nIl test di Geweke è una procedura che confronta le medie di due segmenti della catena di campionamento, tipicamente il primo 10% e l’ultimo 50% dei campioni, dopo aver escluso un iniziale periodo di “burn-in” (una fase iniziale durante la quale la catena potrebbe non essere ancora convergente). La premessa di base è che, se la catena è in uno stato stazionario, le medie di questi due segmenti dovrebbero essere sostanzialmente uguali. Differenze importanti tra queste medie possono indicare che la catena non ha ancora raggiunto la convergenza.\n\n56.9.6.2 Geweke Z-score\nUna variante del test di Geweke è lo z-score di Geweke, che offre un modo quantitativo per valutare le differenze tra i segmenti della catena. Questo test calcola uno z-score che confronta le medie dei due segmenti tenendo conto della varianza. Un valore di z-score:\n\n\nAl di sotto di 2 (in valore assoluto) suggerisce che non ci sono differenze degne di nota tra i segmenti, indicando che la catena potrebbe essere in stato stazionario.\n\nSuperiore a 2 (in valore assoluto) indica che esiste una differenza degna di nota tra i segmenti, suggerendo che la catena non ha raggiunto la convergenza e potrebbe essere necessario un periodo di burn-in più esteso.\n\nEntrambi i metodi forniscono strumenti utili per valutare la convergenza delle catene MCMC. È importante notare che nessun test può garantire con certezza la convergenza, ma l’utilizzo congiunto di approcci grafici e test statistici può offrire una buona indicazione dello stato della catena.\n\n56.9.7 Dimensione del campione effettiva (ESS)\nLa correlazione tra campioni consecutivi in una catena MCMC riduce l’informazione effettiva contenuta in ogni iterazione. La dimensione del campione effettiva (ESS) quantifica questa perdita di informazione dovuta alla dipendenza tra i campioni, stimando il numero equivalente di campioni indipendenti. Un valore basso di ESS indica una forte correlazione tra i campioni e una convergenza più lenta della catena.\nL’ESS descrive l’efficacia del campionamento dipendente in termini di campioni indipendenti estratti dalla stessa distribuzione. Rappresenta un indicatore dell’efficienza del campionamento e dell’autocorrelazione della catena.\nLa formula per stimare la dimensione del campione effettiva (ESS) di una catena di Markov è:\n\\[\n\\text{ESS} = \\frac{N}{1 + 2 \\sum_{t=1}^{T} \\rho_t},\n\\]\ndove:\n\n\n\\(N\\) è il numero totale di campioni nella catena,\n\n\\(T\\) è il lag, ovvero il numero massimo di termini di autocorrelazione considerati,\n\n\\(\\rho_t\\) è l’autocorrelazione al lag \\(t\\), ossia la correlazione tra due campioni consecutivi separati da \\(t\\) iterazioni.\n\nIn pratica, \\(T\\) viene scelto in modo tale che \\(\\rho_T\\) sia sufficientemente piccolo, indicando che l’autocorrelazione è quasi svanita. La somma \\(\\sum_{t=1}^T \\rho_t\\) viene quindi troncata approssimativamente a \\(T\\), poiché i contributi delle autocorrelazioni successive diventano trascurabili.\n\n56.9.8 Calcolo della Statistica di Gelman-Rubin (\\(\\hat{R}\\))\nPer calcolare la statistica di Gelman-Rubin (spesso indicata come \\(\\hat{R}\\)), è necessario eseguire più catene e confrontare la variabilità all’interno di ciascuna catena con la variabilità tra le catene. Ecco i passaggi per calcolare \\(\\hat{R}\\):\n\nEsegui \\(m\\) catene di Markov di lunghezza \\(n\\), dove \\(m\\) è solitamente maggiore di 1.\nPer ciascun parametro scalare \\(\\theta\\), calcola la varianza all’interno delle catene (\\(W\\)) e la varianza tra le catene (\\(B\\)).\nCalcola la varianza combinata \\(\\hat{V}\\) come media ponderata delle varianze all’interno delle catene.\nCalcola il fattore di riduzione della scala potenziale \\(\\hat{R}\\) come la radice quadrata del rapporto tra la varianza combinata \\(\\hat{V}\\) e la varianza all’interno delle catene \\(W\\):\n\n\\[\n\\hat{R} = \\sqrt{\\frac{\\hat{V}}{W}}.\n\\]\n\nSe \\(\\hat{R}\\) è vicino a 1, ciò indica che le catene sono in convergenza.\n\nLa statistica di Gelman-Rubin \\(\\hat{R}\\) è una misura di convergenza per le catene di Markov. Essa quantifica il grado di accordo tra più catene, fornendo uno strumento diagnostico per valutare la convergenza nelle simulazioni MCMC.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#vantaggi-del-campionamento-mcmc-rispetto-alle-soluzioni-analitiche",
    "href": "chapters/mcmc/01_metropolis.html#vantaggi-del-campionamento-mcmc-rispetto-alle-soluzioni-analitiche",
    "title": "56  L’algoritmo di Metropolis-Hastings",
    "section": "\n56.10 Vantaggi del Campionamento MCMC rispetto alle Soluzioni Analitiche",
    "text": "56.10 Vantaggi del Campionamento MCMC rispetto alle Soluzioni Analitiche\nIl campionamento MCMC offre notevoli vantaggi pratici rispetto alle soluzioni analitiche nella statistica bayesiana, in particolare quando si tratta di manipolare distribuzioni a posteriori. Sebbene l’impossibilità di calcolare analiticamente la distribuzione a posteriori sia spesso la motivazione principale per l’uso di MCMC, i benefici di questo approccio si estendono ben oltre questa necessità (Bürkner, 2024).\n\n56.10.1 Facilità di Manipolazione e Flessibilità\nIl vantaggio chiave del campionamento MCMC risiede nella semplicità con cui si possono manipolare i campioni ottenuti. Mentre le densità calcolate analiticamente possono richiedere trasformazioni matematiche complesse, i campioni MCMC possono essere facilmente trasformati con operazioni dirette.\nIn conclusione, il campionamento MCMC non è solo una necessità quando le soluzioni analitiche sono introvabili, ma offre vantaggi in termini di facilità di manipolazione, flessibilità computazionale e applicabilità pratica.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#caso-normale-normale-con-soluzione-analitica",
    "href": "chapters/mcmc/01_metropolis.html#caso-normale-normale-con-soluzione-analitica",
    "title": "56  L’algoritmo di Metropolis-Hastings",
    "section": "\n56.11 Caso Normale-Normale con Soluzione Analitica",
    "text": "56.11 Caso Normale-Normale con Soluzione Analitica\nApplichiamo ora l’algoritmo di Metropolis al caso Normale-Normale di cui conosciamo la soluzione analitica. In pratica, ci poniamo il problema di capire quale valore di \\(\\mu\\) (la media vera di una popolazione) sia più plausibile, dopo aver osservato alcuni dati. Abbiamo:\n\nun’idea iniziale (prior) che dice che \\(\\mu\\) dovrebbe stare attorno a 30, con una certa incertezza (deviazione standard 5),\ne abbiamo i dati osservati (\\(y\\)) che ci danno informazioni aggiuntive su dove si trova davvero \\(\\mu\\).\n\nMa non conosciamo esattamente la distribuzione a posteriori di \\(\\mu\\).\nVogliamo costruire una “nuvola” di valori plausibili per \\(\\mu\\) basandoci su dati e prior. Il metodo che usiamo per risolvere questo problema è l’algoritmo di Metropolis.\nStep 1. Partiamo da un punto.\nx_prev &lt;- xinit\n\n\nxinit è il valore iniziale: il nostro “primo sospetto” su dove si trovi \\(\\mu\\).\nÈ come partire da un punto sulla mappa (“Penso che \\(\\mu\\) sia circa qui”).\n\nStep 2. Proponiamo un nuovo punto vicino.\nx_star &lt;- rnorm(1, mean = x_prev, sd = 0.5)\n\nImmaginiamo di essere bendati e di provare a fare un piccolo passo a caso partendo da dove siamo ora.\nQuel passo è generato con una distribuzione normale centrata su x_prev e con una deviazione standard piccola (0.5): piccoli passi casuali attorno al punto attuale.\n\nNota intuitiva:\nIl valore 0.5 decide quanto “grandi” o “piccoli” sono i nostri passi. Più è grande, più possiamo saltare lontano; più è piccolo, più restiamo vicino.\nStep 3. Calcoliamo quanto è “buono” il nuovo punto.\nposterior(x_star, data)\nposterior(x_prev, data)\n\nOgni punto sulla mappa (\\(\\mu\\)) ha un certo valore di plausibilità: quanto è probabile dati i dati osservati e il prior.\n\nposterior(x_star, data) ci dice: “quanto è buono il nuovo punto?”\n\nposterior(x_prev, data) ci dice: “quanto era buono quello vecchio?”\n\nStep 4. Decidiamo se accettare il nuovo punto.\nif (runif(1) &lt; min(1, posterior(x_star, data) / posterior(x_prev, data))) {\n  x_prev &lt;- x_star\n}\nQui applichiamo il meccanismo di base dell’algoritmo di Metropolis per decidere sull’accettazione di un nuovo punto:\n\n\nse il nuovo punto è migliore (cioè, la probabilità a posteriori è maggiore), allora lo accettiamo sicuramente (\\(\\alpha &gt; 1\\), quindi \\(\\min(1, \\alpha) = 1\\));\n\nse il nuovo punto è peggiore, possiamo comunque accettarlo con una certa probabilità:\n\nla probabilità di accettazione diminuisce all’aumentare di quanto il punto è “peggiore”;\nciò è essenziale per non rimanere bloccati nei massimi locali.\n\n\n\nIn parole semplici:\n\nse troviamo un posto migliore, ci andiamo;\nse troviamo un posto peggiore, possiamo comunque andarci… ma tirando una monetina.\n\nStep 5. Registriamo il punto attuale\nDopo aver deciso se accettare o meno il nuovo valore proposto, salviamo sempre un punto nella catena.\nMa attenzione:\n\n\nse la proposta è stata accettata, ci spostiamo al nuovo punto e lo registriamo;\n\nse la proposta è stata rifiutata, restiamo fermi e registriamo di nuovo la posizione attuale.\n\nif (runif(1) &lt; min(1, posterior(x_star, data) / posterior(x_prev, data))) {\n  x_prev &lt;- x_star  # accettiamo: ci spostiamo\n}\nsamples[i] &lt;- x_prev  # salviamo dove ci troviamo ORA\nIn entrambi i casi, samples[i] tiene traccia della posizione in cui ci troviamo dopo l’iterazione.\nIntuizione: l’escursionista bendato.\nImmaginiamo un’escursionista bendato che vuole esplorare un paesaggio fatto di colline di plausibilità (la distribuzione a posteriori):\n\na ogni passo, prova a fare un salto in una nuova direzione (x_star);\nse quel punto è più alto o non troppo peggiore, accetta di andarci e si sposta.\nse il punto è troppo brutto, rimane fermo dov’è;\nin ogni caso, segna nel diario la sua posizione attuale.\n\nEcco perché, quando guardiamo la catena, possiamo trovare valori ripetuti consecutivi: l’escursionista non si è mosso.\nQuesta caratteristica – il fatto che i campioni non siano tutti diversi – non è un errore, ma una proprietà fondamentale dell’algoritmo Metropolis: i campioni sono dipendenti e possono ripetersi.\nStep 6. Ripetiamo tante volte.\nfor (i in seq_len(nsamp)) { ... }\n\nPiù a lungo ripetiamo il processo (più iterazioni), più densa e accurata sarà la nostra approssimazione della distribuzione a posteriori di \\(\\mu\\).\nDopo un po’, i valori salvati formeranno un disegno della distribuzione plausibile di \\(\\mu\\).\n\n** Riassunto in 3 frasi:**\n\n\nPartiamo da un valore sospettato di \\(\\mu\\).\n\n\nFacciamo piccoli passi casuali e decidiamo se accettarli in base a quanto sono “buoni” rispetto ai dati + prior.\n\n\nDopo molti passi, la sequenza dei punti disegna la distribuzione a posteriori di \\(\\mu\\).\n\n\n** Dopo il sampling:**\n\npossiamo calcolare la media dei campioni = stima puntuale di \\(\\mu\\);\npossiamo costruire un intervallo di credibilità = incertezza su \\(\\mu\\);\npossiamo disegnare un istogramma dei campioni = forma della distribuzione a posteriori.\n\nAnche se l’algoritmo di Metropolis può sembrare “rozzo” (tanti piccoli passi + accettare/rifiutare), funziona benissimo ed è uno dei motivi per cui oggi possiamo applicare la statistica bayesiana a modelli anche molto complessi.\nApplichiamo dunque l’algoritmo di Metropolis all’esercizio in discussione. Iniziamo a definire le funzioni per il prior, la verosimiglianza e il posterior non normalizzato.\n\n# Prior: Normal(30, 5^2)\nprior &lt;- function(mu) {\n  dnorm(mu, mean = 30, sd = 5)\n}\n\n# Likelihood: Normal(mu, sigma^2) con sigma calcolata dai dati\nlikelihood &lt;- function(mu, data) {\n  sigma &lt;- sd(data)  # Deviazione standard dei dati\n  prod(dnorm(data, mean = mu, sd = sigma))\n}\n\n# Posterior non normalizzato\nposterior &lt;- function(mu, data) {\n  likelihood(mu, data) * prior(mu)\n}\n\nImplementiamo l’algoritmo di Metropolis per il caso normale-normale:\n\n# Algoritmo di Metropolis\nmetropolis_for_normal &lt;- function(nsamp, xinit, data) {\n  samples &lt;- numeric(nsamp)\n  x_prev &lt;- xinit\n  \n  for (i in seq_len(nsamp)) {\n    x_star &lt;- rnorm(1, mean = x_prev, sd = 0.5)  # Proposta\n    if (runif(1) &lt; min(1, posterior(x_star, data) / posterior(x_prev, data))) {\n      x_prev &lt;- x_star\n    }\n    samples[i] &lt;- x_prev\n  }\n  \n  samples\n}\n\nUtilizziamo un campione di 30 valori BDI-II forniti da Zetsche et al. (2019):\n\n# Dati osservati\ny &lt;- c(\n  26, 35, 30, 25, 44, 30, 33, 43, 22, 43, 24, 19, 39, 31, 25, \n  28, 35, 30, 26, 31, 41, 36, 26, 35, 33, 28, 27, 34, 27, 22\n)\n\nEsecuzione dell’algoritmo:\n\nsamples &lt;- metropolis_for_normal(100000, mean(y), y)\n\nNel caso normale-normale, il posterior può essere calcolato analiticamente come segue:\n\n# Parametri del prior\nmu_prior &lt;- 30\nstd_prior &lt;- 5\nvar_prior &lt;- std_prior^2\n\n# Calcolo dei parametri posterior\nn &lt;- length(y)\nsum_y &lt;- sum(y)\nvar_data &lt;- var(y)\n\nmu_post &lt;- (mu_prior / var_prior + sum_y / var_data) / (1 / var_prior + n / var_data)\nvar_post &lt;- 1 / (1 / var_prior + n / var_data)\nstd_post &lt;- sqrt(var_post)\n\nmu_post\n#&gt; [1] 30.88\nstd_post\n#&gt; [1] 1.173\n\nVisualizziamo i risultati con un istogramma dei campioni MCMC e la curva della distribuzione analitica:\n\n# Assicuriamoci che palette_set1 sia disponibile\nif (!exists(\"palette_set1\")) {\n  palette_set1 &lt;- RColorBrewer::brewer.pal(3, \"Set1\")\n  names(palette_set1) &lt;- c(\"uno\", \"due\", \"tre\")\n}\n\n# Campioni post burn-in\nburnin &lt;- floor(length(samples) * 0.5)\npost_samples &lt;- samples[-seq_len(burnin)]\n\n# Dati per la curva analitica\nx &lt;- seq(mu_post - 4 * std_post, mu_post + 4 * std_post, length.out = 1000)\nanalytical_posterior &lt;- dnorm(x, mean = mu_post, sd = std_post)\n\n# Colori coerenti con la palette\ncolore_hist &lt;- unname(palette_set1[[1]])  # es. blu Set1\ncolore_line &lt;- unname(palette_set1[[2]])  # es. rosso Set1\n\n# Creazione del grafico\nggplot() +\n  geom_histogram(\n    aes(x = post_samples, y = after_stat(density)),\n    bins = 30,\n    fill = colore_hist,\n    alpha = 0.4\n  ) +\n  geom_line(\n    aes(x = x, y = analytical_posterior),\n    color = colore_line,\n    linewidth = 1\n  ) +\n  labs(\n    title = \"Distribuzione a posteriori: MCMC vs analitico\",\n    x = expression(mu),\n    y = \"Densità\"\n  ) +\n  theme(\n    plot.title = element_text(hjust = 0.5),\n    legend.position = \"top\"\n  )\n\n\n\n\n\n\n\nTroviamo le proprietà del Posterior derivato con MCMC:\n\nmean(samples)\n#&gt; [1] 30.91\n\n\nsd(samples)\n#&gt; [1] 1.177\n\nIn conclusione, questo esempio illustra l’applicazione dell’algoritmo di Metropolis per la stima di una distribuzione a posteriori nel caso Normale-Normale e dimostra come confrontare i risultati del campionamento con la soluzione analitica, confermando così la coerenza tra le due approcci.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#riflessioni-conclusive",
    "href": "chapters/mcmc/01_metropolis.html#riflessioni-conclusive",
    "title": "56  L’algoritmo di Metropolis-Hastings",
    "section": "\n56.12 Riflessioni Conclusive",
    "text": "56.12 Riflessioni Conclusive\nIn molti casi, la distribuzione a posteriori dei parametri di un modello statistico non ha una forma analitica risolvibile. Per affrontare questa limitazione, si utilizzano metodi Monte Carlo basati su catene di Markov (MCMC). Questi algoritmi permettono di campionare efficacemente dalla distribuzione a posteriori, anche per modelli complessi, generando una sequenza di valori che approssima la distribuzione desiderata. L’algoritmo di Metropolis-Hastings (Hastings, 1970), un’estensione dell’algoritmo di Metropolis originale (Metropolis et al., 1953), è uno dei metodi MCMC più ampiamente utilizzati.\nIn sintesi, l’algoritmo segue questi passaggi principali:\n\n\nGenerazione del nuovo stato proposto: Si crea un nuovo stato vicino a quello corrente utilizzando una distribuzione di proposta.\n\nConfronto tra densità posteriori: Si confrontano le densità a posteriori del nuovo stato proposto e dello stato corrente.\n\nAccettazione probabilistica: Il nuovo stato viene sempre accettato se ha una densità posteriore maggiore, oppure accettato con una certa probabilità se ha una densità minore.\n\nBurn-in e tasso di accettazione: I primi campioni vengono scartati (fase di burn-in) per garantire che la catena abbia raggiunto la distribuzione stazionaria, e si monitora il tasso di accettazione per ottimizzare l’efficienza del campionamento.\n\nQuesto approccio consente di ottenere campioni che approssimano la distribuzione a posteriori, ma l’algoritmo di Metropolis può presentare limiti di efficienza, soprattutto per problemi ad alta dimensionalità o distribuzioni con geometrie complesse. Un aspetto cruciale è il tasso di accettazione, che rappresenta il rapporto tra il numero di proposte accettate e il numero totale di proposte. Un tasso troppo basso può indicare che la catena esplora lo spazio dei parametri in modo inefficiente, mentre un tasso troppo alto può segnalare che i passi effettuati sono troppo piccoli per consentire una buona esplorazione.\nRispetto alle varianti più moderne, l’algoritmo di Metropolis tende a essere meno efficiente. Metodi come il No-U-Turn Sampler (NUTS) e l’Hamiltonian Monte Carlo (HMC) offrono importanti miglioramenti, specialmente in spazi di parametri di grandi dimensioni. NUTS, ad esempio, viene utilizzato in strumenti avanzati come Stan e PyMC (Hoffman et al., 2014), permettendo un’esplorazione più rapida e accurata della distribuzione a posteriori.\nTra gli altri algoritmi MCMC degni di nota troviamo il campionatore di Gibbs (Geman & Geman, 1984) e l’Hamiltonian Monte Carlo (Duane et al., 1987). Questi metodi, insieme a Metropolis-Hastings, formano la base di numerose tecniche moderne per il campionamento da distribuzioni complesse. Per un approfondimento dettagliato sulle tecniche MCMC, si consiglia di consultare Hanada & Matsuura (2022).\n\n\n\n\n\n\nEsercizio 1: Autostima negli Studenti Universitari\n\n\n\n\n\nIn un campione casuale di 100 studenti, 25 hanno mostrato livelli alti di autostima.\nSupponiamo un prior Beta(2,8) sulla proporzione \\(\\theta\\) di studenti con alta autostima.\nObiettivo: stimare la distribuzione a posteriori di \\(\\theta\\) usando l’algoritmo di Metropolis.\nDefinizione delle Funzioni.\n\nset.seed(123)  # per riproducibilità\n\n# Prior: Beta(2,8)\nprior &lt;- function(p) dbeta(p, shape1 = 2, shape2 = 8)\n\n# Likelihood: binomiale 25 successi su 100\nlikelihood &lt;- function(p) dbinom(25, size = 100, prob = p)\n\n# Posterior non normalizzata\nposterior &lt;- function(p) prior(p) * likelihood(p)\n\n# Distribuzione di proposta\nproposal_distribution &lt;- function(current, proposal_sigma) {\n  rnorm(1, mean = current, sd = proposal_sigma)\n}\n\n# Algoritmo di Metropolis\nmetropolis &lt;- function(n_samples, start, proposal_sigma) {\n  samples &lt;- numeric(n_samples)\n  current &lt;- start\n  \n  for (i in seq_len(n_samples)) {\n    proposal &lt;- proposal_distribution(current, proposal_sigma)\n    if (proposal &gt;= 0 && proposal &lt;= 1) {\n      acceptance_ratio &lt;- min(1, posterior(proposal) / posterior(current))\n      if (runif(1) &lt; acceptance_ratio) {\n        current &lt;- proposal\n      }\n    }\n    samples[i] &lt;- current\n  }\n  samples\n}\n\nEsecuzione dell’Algoritmo.\n\n# Parametri\nn_samples &lt;- 10000\nstart &lt;- 0.5\nproposal_sigma &lt;- 0.1\n\n# Esecuzione\nsamples &lt;- metropolis(n_samples, start, proposal_sigma)\n\n# Burn-in\nburnin &lt;- floor(n_samples * 0.5)\npost_samples &lt;- samples[-seq_len(burnin)]\n\nAnalisi dei Risultati.\n\n# Media e deviazione standard\nmean(post_samples)\n#&gt; [1] 0.2444\nsd(post_samples)\n#&gt; [1] 0.03947\n\nCalcolo dell’Intervallo di Credibilità al 94%.\n\nquantile(post_samples, probs = c(0.03, 0.97))\n#&gt;     3%    97% \n#&gt; 0.1699 0.3190\n\nConfronto con la Soluzione Analitica.\nLa distribuzione a posteriori teorica è:\n\\[\n\\theta \\sim \\text{Beta}(27, 83)\n\\]\n\n# Media teorica\nmean_beta &lt;- 27 / (27 + 83)\nmean_beta\n#&gt; [1] 0.2455\n\n# Intervallo teorico\nqbeta(c(0.03, 0.97), 27, 83)\n#&gt; [1] 0.1727 0.3260\n\nTrace Plot.\n\n# Trace plot\npost_samples |&gt; \n  tibble(Iteration = 1:length(post_samples), Theta = post_samples) |&gt; \n  ggplot(aes(x = Iteration, y = Theta)) +\n  geom_line() +\n  labs(title = \"Trace Plot dopo Burn-in\", x = \"Iterazione\", y = expression(theta))\n\n\n\n\n\n\n\nIstogramma e Curva Teorica.\n\n# Prima generiamo il dataset della curva teorica separatamente\nx &lt;- seq(0, 1, length.out = 1000)\ndens_teorica &lt;- dbeta(x, 27, 83)\ncurva_teorica &lt;- tibble(x = x, y = dens_teorica)\n\n# Ora costruiamo il grafico correttamente\ntibble(Theta = post_samples) |&gt; \n  ggplot(aes(x = Theta)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 30, \n                 color = \"black\", fill = \"lightblue\", alpha = 0.6) +\n  geom_line(data = curva_teorica, aes(x = x, y = y), \n            color = \"red\", size = 1) +\n  labs(title = \"Posterior: Campioni MCMC vs Beta(27,83)\", \n       x = expression(theta), y = \"Densità\")\n\n\n\n\n\n\n\nRisultati Riassunti.\n\n\nMetodo\nMedia\nIntervallo 94%\n\n\n\nMCMC (Metropolis)\ncirca 0.245\ncirca [0.176, 0.320]\n\n\nTeorico Beta(27,83)\n0.245\n[0.177, 0.318]\n\n\n\nSpiegazioni Didattiche Finali.\n\n\n\n\n\n\nDistribuzione a posteriori: interpretazione\n\n\n\nLa distribuzione a posteriori ci dice quanto sono plausibili i diversi valori di \\(\\theta\\) dopo aver osservato i dati.\n\nAd esempio: “C’è una probabilità del 94% che la vera proporzione di studenti con alta autostima sia tra 17% e 32%.”\n\n\n\n\n\n\n\n\n\nAccettare mosse peggiori: motivo\n\n\n\nAccettiamo campioni con probabilità più bassa per permettere alla catena di esplorare anche aree meno probabili e non restare bloccata nei massimi locali.\n\n\n\n\n\n\n\n\nLarghezza della proposta: trade-off\n\n\n\n\n\nProposta stretta (piccoli passi): alta accettazione, ma esplorazione lenta.\n\nProposta larga (grandi passi): bassa accettazione, ma esplorazione più ampia.\n\nSi cerca un tasso di accettazione tra 40% e 50%.\n\n\n\n\n\n\n\n\nDiagnostica grafica\n\n\n\n\n\nTrace plot: deve mostrare fluttuazioni stabili senza trend.\n\nCorrelogramma: l’autocorrelazione deve decrescere rapidamente.\n\nQuesti strumenti aiutano a diagnosticare una buona esplorazione della distribuzione a posteriori.\n\n\n\n\n\n\n\n\n\n\n\nEsercizio 2 - Depressione (BDI-II)\n\n\n\n\n\nIn uno studio clinico, sono stati raccolti i punteggi BDI-II (Beck Depression Inventory) di 30 pazienti. Vogliamo stimare il valore medio della depressione nella popolazione da cui provengono questi soggetti.\nSupponiamo di avere una conoscenza a priori modellata da una distribuzione Normale(30, 5²) per la media \\(\\mu\\).\nI dati osservati sono i seguenti:\n\ny &lt;- c(26, 35, 30, 25, 44, 30, 33, 43, 22, 43,\n       24, 19, 39, 31, 25, 28, 35, 30, 26, 31,\n       41, 36, 26, 35, 33, 28, 27, 34, 27, 22)\nlength(y)  \n#&gt; [1] 30\n\nFunzioni a priori, verosimiglianza e posteriori.\n\n# Prior: Normal(30, 5^2)\nprior &lt;- function(mu) {\n  dnorm(mu, mean = 30, sd = 5)\n}\n\n# Likelihood: Normal(mu, sigma^2), sigma stimato dai dati\nlikelihood &lt;- function(mu, data) {\n  sigma &lt;- sd(data)\n  prod(dnorm(data, mean = mu, sd = sigma))\n}\n\n# Posterior non normalizzata\nposterior &lt;- function(mu, data) {\n  likelihood(mu, data) * prior(mu)\n}\n\nAlgoritmo di Metropolis.\n\nmetropolis_for_normal &lt;- function(nsamp, xinit, data) {\n  samples &lt;- numeric(nsamp)\n  x_prev &lt;- xinit\n  \n  for (i in seq_len(nsamp)) {\n    x_star &lt;- rnorm(1, mean = x_prev, sd = 0.5)  # proposta\n    if (runif(1) &lt; min(1, posterior(x_star, data) / posterior(x_prev, data))) {\n      x_prev &lt;- x_star\n    }\n    samples[i] &lt;- x_prev\n  }\n  samples\n}\n\nEsecuzione dell’algoritmo.\n\nset.seed(123)\nsamples &lt;- metropolis_for_normal(100000, mean(y), y)\n\nburnin &lt;- 50000\npost_samples &lt;- samples[-seq_len(burnin)]\n\nConfronto con la soluzione analitica.\nNel caso prior Normale e likelihood Normale con varianza nota, la posterior è ancora Normale:\n\n# Prior\nmu_prior &lt;- 30\nstd_prior &lt;- 5\nvar_prior &lt;- std_prior^2\n\n# Likelihood\nn &lt;- length(y)\nsum_y &lt;- sum(y)\nvar_data &lt;- var(y)\n\nmu_post &lt;- (mu_prior / var_prior + sum_y / var_data) / (1 / var_prior + n / var_data)\nvar_post &lt;- 1 / (1 / var_prior + n / var_data)\nstd_post &lt;- sqrt(var_post)\n\nc(mu_post, std_post)\n#&gt; [1] 30.882  1.173\n\nTrace Plot.\n\n# Trace plot\npost_samples |&gt; \n  tibble(Iteration = 1:length(post_samples), Mu = post_samples) |&gt; \n  ggplot(aes(x = Iteration, y = Mu)) +\n  geom_line() +\n  labs(title = \"Trace Plot (Post Burn-in)\", x = \"Iterazione\", y = expression(mu))\n\n\n\n\n\n\n\nIstogramma vs Posterior Analitica.\n\nx &lt;- seq(mu_post - 4 * std_post, mu_post + 4 * std_post, length.out = 1000)\ndens_teorica &lt;- dnorm(x, mean = mu_post, sd = std_post)\ncurva_teorica &lt;- tibble(x = x, y = dens_teorica)\n\npost_samples |&gt; \n  tibble(Mu = post_samples) |&gt; \n  ggplot(aes(x = Mu)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 30, fill = \"skyblue\", color = \"black\", alpha = 0.6) +\n  geom_line(data = curva_teorica, aes(x = x, y = y), color = \"red\", linewidth = 1) +\n  labs(title = \"Posterior: MCMC vs Analitica\", x = expression(mu), y = \"Densit\\u00e0\")\n\n\n\n\n\n\n\nCosa significa la distribuzione a posteriori?\nIn termini concreti, la distribuzione a posteriori rappresenta la nostra incertezza residua sul valore di \\(\\mu\\), la media dei punteggi BDI-II nella popolazione, dopo aver visto i dati. Per esempio, se calcoliamo che il 94% della distribuzione a posteriori cade tra 27.5 e 32.3, possiamo dire:\n\n“Date le nostre ipotesi iniziali e i dati osservati, c’è una probabilità del 94% che il vero valore medio della depressione nella popolazione stia tra 27.5 e 32.3”.\n\nQuesta è una affermazione probabilistica sul parametro, che è una caratteristica distintiva dell’inferenza bayesiana.\nQuesta distribuzione combina:\n\nle credenze precedenti (il prior),\ncon l’evidenza osservata (i dati).\n\nIl risultato è una distribuzione che riflette cosa sappiamo del parametro dopo aver osservato i dati, e può essere usata per ottenere medie, intervalli di credibilità, probabilità soggettive, ecc.\n\n\n\n\n\n\nPerché accettare anche campioni con densità più bassa?\n\n\n\nNell’algoritmo di Metropolis, a ogni passo si propone un nuovo valore di \\(\\theta\\). Se questo valore ha una densità a posteriori più alta, viene accettato.\nMa se ha una densità più bassa, viene comunque accettato con una certa probabilità.\nPerché farlo?\nPer evitare che la catena si “blocchi” in un massimo locale. Per esplorare anche le aree meno probabili, ma comunque possibili, della distribuzione.\nÈ un meccanismo simile a quello con cui gli esseri umani esplorano: ogni tanto vale la pena provare strade meno promettenti, per evitare di restare intrappolati. Accettare “mosse peggiori” è quindi un meccanismo di esplorazione utile a garantire che la catena possa visitare l’intero spazio dei parametri e convergere correttamente alla distribuzione desiderata.\n\n\n\n\n\n\n\n\nLarghezza della proposta: un equilibrio delicato\n\n\n\nNel Metropolis, il nuovo valore proposto viene scelto spostandosi dal valore corrente secondo una distribuzione normale:\n\\[\\theta_{new} \\sim \\mathcal{N}(\\theta_{attuale}, \\sigma).\\]\nIl parametro \\(\\sigma\\) controlla la distanza dei passi.\nSe \\(\\sigma\\) è:\n\nPiccolo → i passi sono molto corti:\n\nMolte proposte vengono accettate (alta accettazione),\nMa la catena esplora lentamente → i campioni sono fortemente autocorrelati.\n\n\nGrande → i passi sono molto lunghi:\n\nSi propongono salti drastici → molte proposte vengono rifiutate,\nLa catena si muove poco → anche in questo caso, esplorazione inefficiente.\n\n\n\n🎯 Obiettivo: trovare un compromesso ottimale.\n\nPer un parametro unidimensionale, si consiglia spesso un tasso di accettazione tra 40% e 50%.\nNegli esercizi puoi provare diversi valori di proposal_sigma e osservare il tasso di accettazione per imparare.\n\n\n\nRisultati.\n\nmean(post_samples)\n#&gt; [1] 30.87\nsd(post_samples)\n#&gt; [1] 1.152\nquantile(post_samples, probs = c(0.03, 0.97))\n#&gt;    3%   97% \n#&gt; 28.71 33.06\n\nValori teorici:\n\nmu_post  # media teorica\n#&gt; [1] 30.88\nqnorm(c(0.03, 0.97), mean = mu_post, sd = std_post)\n#&gt; [1] 28.68 33.09\n\nSpiegazione Didattica.\n\nLa media \\(\\mu\\) rappresenta il livello medio di depressione nella popolazione.\nIl prior rappresenta la nostra credenza iniziale (Normale con media 30).\nL’evidenza fornita dai dati modifica questa credenza.\nL’algoritmo di Metropolis permette di campionare da una distribuzione posterior anche senza conoscere la forma analitica.\nIl confronto tra distribuzione teorica e campioni MCMC mostra un ottimo accordo.\n\nConclusione.\nIn questo esercizio abbiamo:\n\nimplementato l’algoritmo di Metropolis per un caso con prior e likelihood Normali;\nstimato la media della distribuzione posterior;\nconfrontato i risultati con la soluzione analitica;\nverificato la coerenza dei campioni MCMC con la distribuzione teorica.\n\nQuesto mostra la potenza dell’approccio MCMC anche in situazioni dove la soluzione analitica sarebbe disponibile, e pone le basi per affrontare problemi più complessi.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/01_metropolis.html#informazioni-sullambiente-di-sviluppo",
    "title": "56  L’algoritmo di Metropolis-Hastings",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] reshape2_1.4.4        cmdstanr_0.9.0        pillar_1.11.0        \n#&gt;  [4] tinytable_0.11.0      patchwork_1.3.1       ggdist_3.3.3         \n#&gt;  [7] tidybayes_3.0.7       bayesplot_1.13.0      ggplot2_3.5.2        \n#&gt; [10] reliabilitydiag_0.2.1 priorsense_1.1.0      posterior_1.6.1      \n#&gt; [13] loo_2.8.0             rstan_2.32.7          StanHeaders_2.32.10  \n#&gt; [16] brms_2.22.0           Rcpp_1.1.0            conflicted_1.2.0     \n#&gt; [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [25] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3        inline_0.3.21        sandwich_3.1-1      \n#&gt;  [4] rlang_1.1.6          magrittr_2.0.3       multcomp_1.4-28     \n#&gt;  [7] snakecase_0.11.1     compiler_4.5.1       vctrs_0.6.5         \n#&gt; [10] stringr_1.5.1        pkgconfig_2.0.3      arrayhelpers_1.1-0  \n#&gt; [13] fastmap_1.2.0        backports_1.5.0      labeling_0.4.3      \n#&gt; [16] rmarkdown_2.29       ps_1.9.1             purrr_1.1.0         \n#&gt; [19] xfun_0.52            cachem_1.1.0         jsonlite_2.0.0      \n#&gt; [22] broom_1.0.9          parallel_4.5.1       R6_2.6.1            \n#&gt; [25] stringi_1.8.7        RColorBrewer_1.1-3   lubridate_1.9.4     \n#&gt; [28] estimability_1.5.1   knitr_1.50           zoo_1.8-14          \n#&gt; [31] pacman_0.5.1         R.utils_2.13.0       Matrix_1.7-3        \n#&gt; [34] splines_4.5.1        timechange_0.3.0     tidyselect_1.2.1    \n#&gt; [37] abind_1.4-8          yaml_2.3.10          codetools_0.2-20    \n#&gt; [40] curl_6.4.0           processx_3.8.6       pkgbuild_1.4.8      \n#&gt; [43] lattice_0.22-7       plyr_1.8.9           withr_3.0.2         \n#&gt; [46] bridgesampling_1.1-2 coda_0.19-4.1        evaluate_1.0.4      \n#&gt; [49] survival_3.8-3       RcppParallel_5.1.10  tensorA_0.36.2.1    \n#&gt; [52] checkmate_2.3.2      stats4_4.5.1         distributional_0.5.0\n#&gt; [55] generics_0.1.4       rprojroot_2.1.0      rstantools_2.4.0    \n#&gt; [58] scales_1.4.0         xtable_1.8-4         glue_1.8.0          \n#&gt; [61] emmeans_1.11.2       tools_4.5.1          data.table_1.17.8   \n#&gt; [64] mvtnorm_1.3-3        grid_4.5.1           QuickJSR_1.8.0      \n#&gt; [67] colorspace_2.1-1     nlme_3.1-168         cli_3.6.5           \n#&gt; [70] svUnit_1.0.6         Brobdingnag_1.2-9    V8_6.0.5            \n#&gt; [73] gtable_0.3.6         R.methodsS3_1.8.2    digest_0.6.37       \n#&gt; [76] TH.data_1.1-3        htmlwidgets_1.6.4    farver_2.1.2        \n#&gt; [79] memoise_2.0.1        htmltools_0.5.8.1    R.oo_1.27.1         \n#&gt; [82] lifecycle_1.0.4      MASS_7.3-65",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#bibliografia",
    "href": "chapters/mcmc/01_metropolis.html#bibliografia",
    "title": "56  L’algoritmo di Metropolis-Hastings",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBürkner, P.-C. (2024). The brms Book: Applied Bayesian Regression Modelling Using R and Stan (Early Draft). https://paulbuerkner.com/software/brms-book\n\n\nDuane, S., Kennedy, A. D., Pendleton, B. J., & Roweth, D. (1987). Hybrid monte carlo. Physics letters B, 195(2), 216–222.\n\n\nGeman, S., & Geman, D. (1984). Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images. IEEE Transactions on pattern analysis and machine intelligence, 6, 721–741.\n\n\nHanada, M., & Matsuura, S. (2022). MCMC from Scratch. Springer.\n\n\nHastings, W. K. (1970). Monte Carlo sampling methods using Markov chains and their applications. Biometrika, 57(1), 97–109.\n\n\nHoffman, M. D., Gelman, A., et al. (2014). The No-U-Turn sampler: adaptively setting path lengths in Hamiltonian Monte Carlo. Journal of Machine Learning Research, 15(1), 1593–1623.\n\n\nMetropolis, N., Rosenbluth, A. W., Rosenbluth, M. N., Teller, A. H., & Teller, E. (1953). Equation of state calculations by fast computing machines. The Journal of Chemical Physics, 21(6), 1087–1092.\n\n\nZetsche, U., Buerkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: biased or realistic? Journal of Abnormal Psychology, 128(7), 678–688.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html",
    "href": "chapters/mcmc/02_ppl.html",
    "title": "57  Linguaggi di programmazione probabilistici",
    "section": "",
    "text": "57.1 Cos’è la programmazione probabilistica\nLa programmazione probabilistica è un paradigma della programmazione informatica che consente di creare modelli e algoritmi capaci di gestire l’incertezza e la casualità. Combina i principi della teoria delle probabilità con la programmazione, permettendo di costruire sistemi in grado di ragionare su dati incerti e di prendere decisioni informate. Questo approccio consente di esprimere modelli complessi in modo naturale e intuitivo, facilitando il processo di inferenza bayesiana.\nLa programmazione probabilistica si colloca all’intersezione tra algoritmi di machine learning, statistica e linguaggi di programmazione. I suoi obiettivi principali sono semplificare il processo di inferenza e automatizzarlo.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html#perché-abbiamo-bisogno-della-programmazione-probabilistica",
    "href": "chapters/mcmc/02_ppl.html#perché-abbiamo-bisogno-della-programmazione-probabilistica",
    "title": "57  Linguaggi di programmazione probabilistici",
    "section": "57.2 Perché abbiamo bisogno della programmazione probabilistica?",
    "text": "57.2 Perché abbiamo bisogno della programmazione probabilistica?\nScrivere un proprio campionatore per l’inferenza bayesiana è un compito estremamente difficile. Richiede competenze matematiche avanzate e una profonda conoscenza degli algoritmi di campionamento (sia MCMC che approssimati). Inoltre, ci sono numerosi problemi potenziali legati alla stabilità numerica e ai costi computazionali. Questo significa che per riuscirci bisogna essere allo stesso tempo degli ottimi sviluppatori e degli esperti statistici.\nÈ però possibile delegare tutti questi compiti a un sistema che li automatizzi, permettendoci di concentrarci sulla risoluzione dei problemi scientifici.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html#linguaggi-di-programmazione-probabilistica-ppls",
    "href": "chapters/mcmc/02_ppl.html#linguaggi-di-programmazione-probabilistica-ppls",
    "title": "57  Linguaggi di programmazione probabilistici",
    "section": "57.3 Linguaggi di programmazione probabilistica (PPLs)",
    "text": "57.3 Linguaggi di programmazione probabilistica (PPLs)\nIn questa sezione esamineremo il panorama moderno dei linguaggi di programmazione probabilistica (PPLs) e, nella sezione successiva, esploreremo le funzionalità di uno di questi, Stan.\n\n57.3.1 Linguaggi di Programmazione Probabilistica (PPL)\nUn linguaggio di programmazione probabilistica (PPL) consente di formalizzare modelli bayesiani e di eseguire inferenze utilizzando algoritmi avanzati. L’utente deve semplicemente definire il modello, selezionare un campionatore e avviare il processo di inferenza.\nIn generale, le funzionalità fondamentali richieste a un PPL sono:\n\ngenerare valori casuali da distribuzioni probabilistiche;\ncondizionare variabili su dati osservati.\n\nI primi linguaggi di programmazione probabilistica, come BUGS e WinBUGS, hanno gettato le basi offrendo tre capacità essenziali:\n\nrandom: per definire variabili casuali.\nconstraint: per vincolare variabili ai dati osservati.\ninfer: per calcolare e restituire la distribuzione delle variabili di interesse.\n\nNel corso del tempo, l’elenco dei PPL disponibili si è notevolmente ampliato, comprendendo una vasta gamma di strumenti in continua evoluzione. Ecco alcuni esempi rappresentativi:\n\nBUGS, WinBUGS, JAGS\nStan\nPyMC3, PyMC4, PyMC\nNimble\nPyro, NumPyro\nEdward, TensorFlow Probability, Edward 2\nGen\nTuring\nStheno\nSOSS\nOmega\nInfer.NET",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html#come-scegliere-un-ppl",
    "href": "chapters/mcmc/02_ppl.html#come-scegliere-un-ppl",
    "title": "57  Linguaggi di programmazione probabilistici",
    "section": "57.4 Come scegliere un PPL?",
    "text": "57.4 Come scegliere un PPL?\nDal punto di vista pratico, come si può decidere quale linguaggio di programmazione probabilistica utilizzare? Ecco alcuni fattori chiave da considerare:\n\nDocumentazione: La presenza di risorse ben strutturate, come guide, tutorial e documentazione ufficiale, è essenziale per facilitare l’apprendimento e migliorare la produttività. Un PPL con documentazione chiara e completa è sempre preferibile, specialmente per chi è alle prime armi.\nPerformance: Alcuni PPL sono ottimizzati per offrire prestazioni superiori, ad esempio mediante l’elaborazione parallela o l’uso di acceleratori hardware come le GPU. Valuta le prestazioni in relazione alla complessità e alla scala dei modelli che desideri costruire.\nFunzionalità: È importante verificare se il PPL offre un’ampia gamma di distribuzioni probabilistiche e campionatori, oltre a strumenti avanzati per personalizzare i modelli e implementare inferenze specifiche.\nSupporto della comunità: Una comunità attiva può fare la differenza quando incontri difficoltà. Forum, gruppi di discussione e risorse condivise dagli utenti (come esempi pratici o risposte a domande frequenti) sono fondamentali per risolvere problemi in modo rapido e imparare dalle esperienze di altri.\nIntegrazione: Considera quanto bene il PPL si integra con gli strumenti e i framework già in uso. Per esempio, se utilizzi librerie per la manipolazione dei dati, la visualizzazione o il machine learning, come pandas, ggplot o TensorFlow, verifica che il PPL scelto supporti queste interazioni senza complicazioni.\n\n\n57.4.1 API\nI linguaggi di programmazione probabilistica (PPL) permettono agli utenti di definire con precisione le caratteristiche dei priori, della verosimiglianza e dell’intero modello bayesiano. Inoltre, offrono strumenti per effettuare le necessarie trasformazioni sui dati, garantendo la flessibilità richiesta per affrontare una vasta gamma di problemi statistici. Tuttavia, anche se i PPL cercano di semplificare queste operazioni, l’utente deve comunque scrivere codice che rispetti i vincoli sintattici e logici specifici del linguaggio. Questo richiede non solo competenze di programmazione, ma anche una buona conoscenza dei principi statistici e bayesiani.\nPer venire incontro a utenti che desiderano utilizzare l’inferenza bayesiana senza doversi addentrare nella programmazione, sono state sviluppate interfacce di alto livello. Queste interfacce permettono di specificare modelli statistici comuni in modo intuitivo, utilizzando una sintassi semplificata. Sebbene offrano meno controllo sui dettagli tecnici del modello, garantiscono comunque la possibilità di personalizzare elementi cruciali, come i priori e la verosimiglianza, rendendo l’inferenza bayesiana accessibile anche a chi non ha competenze di programmazione.\n\n\n57.4.2 Principali Interfacce di Alto Livello\nTra le interfacce più popolari troviamo:\n\nbrms: utilizza Stan come motore sottostante per eseguire l’inferenza.\nBambi: si basa su PyMC per eseguire l’inferenza bayesiana.\n\nEntrambe queste librerie adottano una sintassi semplificata, nota come sintassi di Wilkinson (Wilkinson & Rogers, 1973). Questo approccio consente di specificare modelli in modo dichiarativo, usando una struttura simile a quella adottata da pacchetti R come lm (per modelli di regressione lineare) o lme4 (per modelli multilivello con lmer).\nAd esempio, in brms è possibile specificare un modello di regressione lineare con una sintassi simile a questa:\nfit &lt;- brm(y ~ x1 + x2, data = dataset)\nIn questo esempio y ~ x1 + x2 definisce la relazione tra la variabile dipendente (y) e le variabili indipendenti (x1 e x2).\n\n\n57.4.3 Vantaggi delle Interfacce di Alto Livello\n\nAccessibilità: Riduzione della complessità sintattica, rendendo l’inferenza bayesiana più accessibile a un pubblico più ampio, inclusi studenti e ricercatori con competenze di programmazione limitate.\nFlessibilità: Sebbene più semplici, le interfacce consentono di specificare prior distribuiti in modo personalizzato e di modificare molteplici aspetti del modello.\nEfficienza: Automatizzano molti passaggi tecnici, permettendo di concentrarsi sulla definizione del modello e sull’interpretazione dei risultati.\nCompatibilità: Integrazione con strumenti statistici familiari, come il framework di modelli lineari in R.\n\nIn questo corso, utilizzeremo principalmente brms per specificare e stimare modelli di regressione lineare e multilivello, sfruttandone la sintassi intuitiva e l’integrazione con R. Negli approfondimenti, invece, esploreremo come scrivere direttamente modelli in Stan, per comprendere meglio le basi dei PPL e avere maggiore controllo sui dettagli tecnici.\nQuesta combinazione ci permetterà di bilanciare semplicità e potenza, rendendo l’inferenza bayesiana sia accessibile che personalizzabile, a seconda delle esigenze specifiche del progetto o dell’analisi.\n\n\n57.4.4 Introduzione alla sintassi di Wilkinson\nLa sintassi di Wilkinson in R fornisce un modo semplice ed efficace per specificare modelli di regressione lineare, consentendo di descrivere relazioni tra una variabile dipendente (risposta) e una o più variabili indipendenti (predittori) utilizzando una notazione simbolica. Questa sintassi si allinea direttamente al modello matematico, rendendo immediata la corrispondenza tra i termini simbolici e il codice.\n\n57.4.4.1 Modello simbolico e modello Wilkinson\nSupponiamo di voler specificare un modello di regressione lineare multipla con la seguente formula:\n\\[\ny_i = \\alpha + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\varepsilon_i ,\n\\]\ndove:\n\n\\(y_i\\) è la variabile dipendente per l’osservazione \\(i\\),\n\\(\\alpha\\) è l’intercetta,\n\\(\\beta_1\\) e \\(\\beta_2\\) sono i coefficienti di regressione per i predittori \\(x_1\\) e \\(x_2\\),\n\\(\\varepsilon_i\\) rappresenta l’errore residuo, normalmente distribuito (\\(\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma^2)\\)).\n\nIn R, questo modello può essere specificato con la sintassi Wilkinson:\ny ~ x1 + x2\n\n\n57.4.4.2 Dettaglio dei componenti\n\nIntercetta implicita:\nLa sintassi R include automaticamente l’intercetta (\\(\\alpha\\)) quando si utilizza il simbolo +. Ad esempio:\ny ~ x1 + x2\nequivale al modello: \\[\ny_i = \\alpha + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\varepsilon_i\n\\]\nEsclusione dell’intercetta:\nSe si desidera escludere l’intercetta (\\(\\alpha\\)), si utilizza - 1 nella specifica:\ny ~ x1 + x2 - 1\nQuesto produce un modello senza intercetta: \\[\ny_i = \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\varepsilon_i\n\\]\nInclusione esplicita dell’intercetta:\nAnche se è implicita, l’intercetta può essere specificata esplicitamente con 1 +:\ny ~ 1 + x1 + x2\nQuesto è equivalente al modello con intercetta implicita.\nInterazione tra predittori:\nLa sintassi Wilkinson consente anche di specificare interazioni. Ad esempio, un’interazione tra \\(x_1\\) e \\(x_2\\):\ny ~ x1 * x2\nEspande automaticamente il modello per includere: \\[\ny_i = \\alpha + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\beta_3 (x_{1i} \\cdot x_{2i}) + \\varepsilon_i\n\\]\n\n\n\n57.4.4.3 Esempio pratico\nSupponiamo di avere un dataset con una variabile dipendente y e due predittori x1 e x2. Ecco come specificare e adattare un modello di regressione lineare multipla in R:\n# Specifica del modello\nmodello &lt;- lm(y ~ x1 + x2, data = dataset)\n\n# Sommario del modello\nsummary(modello)\nQuesto codice:\n\nSpecifica un modello con intercetta e due predittori.\nAdatta il modello ai dati contenuti in dataset.\nCalcola i coefficienti (\\(\\alpha, \\beta_1, \\beta_2\\)), i valori di errore standard, i p-value (frequentisti) e altre statistiche di sintesi.\n\nIn sintesi, la sintassi di Wilkinson in R permette di esprimere modelli di regressione lineare in modo conciso e leggibile, rendendo il passaggio dal modello matematico al codice intuitivo e diretto.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html#riflessioni-conclusive",
    "href": "chapters/mcmc/02_ppl.html#riflessioni-conclusive",
    "title": "57  Linguaggi di programmazione probabilistici",
    "section": "57.5 Riflessioni Conclusive",
    "text": "57.5 Riflessioni Conclusive\nI linguaggi di programmazione probabilistica (PPL) rappresentano strumenti potenti per la specificazione completa e flessibile di modelli bayesiani, consentendo agli utenti di definire ogni aspetto del modello, dai priori alla verosimiglianza, fino agli algoritmi di inferenza. Strumenti come Stan e PyMC permettono un controllo dettagliato sui modelli, rendendoli ideali per analisi avanzate e progetti personalizzati.\nTuttavia, questo livello di controllo richiede competenze di programmazione e una comprensione approfondita della statistica bayesiana. Per superare queste barriere e rendere l’inferenza bayesiana accessibile a un pubblico più ampio, sono state sviluppate interfacce di alto livello come brms (basata su Stan) e Bambi (basata su PyMC). Questi strumenti semplificano enormemente il processo, consentendo agli utenti di specificare modelli statistici complessi senza la necessità di scrivere codice dettagliato, grazie a una sintassi intuitiva come quella di Wilkinson.\nIn sintesi:\n\nI PPL offrono flessibilità massima e un controllo completo, ma richiedono esperienza nella programmazione.\nLe interfacce di alto livello rendono possibile l’inferenza bayesiana anche a chi preferisce evitare la programmazione, garantendo un compromesso tra semplicità e capacità di personalizzazione.\n\nLa scelta tra un PPL e un’interfaccia di alto livello dipende quindi dalle esigenze specifiche: chi necessita di modelli estremamente personalizzati e complessi opterà per un PPL come Stan o PyMC, mentre chi desidera facilità d’uso senza rinunciare alla potenza dell’inferenza bayesiana troverà in brms o Bambi strumenti ideali. In ogni caso, la crescente disponibilità di strumenti e risorse rende oggi l’inferenza bayesiana più accessibile che mai, anche per chi non ha un background tecnico avanzato.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html#bibliografia",
    "href": "chapters/mcmc/02_ppl.html#bibliografia",
    "title": "57  Linguaggi di programmazione probabilistici",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nWilkinson, G., & Rogers, C. (1973). Symbolic description of factorial models for analysis of variance. Journal of the Royal Statistical Society Series C: Applied Statistics, 22(3), 392–399.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_intro.html",
    "href": "chapters/mcmc/03_stan_intro.html",
    "title": "58  Introduzione pratica a Stan",
    "section": "",
    "text": "Introduzione\nOltre alla potenza di NUTS, Stan si distingue per la sua flessibilità, essendo compatibile con diverse piattaforme tra cui R, Python e Julia. In questo corso utilizzeremo cmdstanr, l’interfaccia ufficiale per R. Alternative valide includono CmdStanPy per Python e Stan.jl per Julia, che condividono la stessa sintassi di base.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Introduzione pratica a Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_intro.html#introduzione",
    "href": "chapters/mcmc/03_stan_intro.html#introduzione",
    "title": "58  Introduzione pratica a Stan",
    "section": "",
    "text": "Stan è un linguaggio di programmazione probabilistica (Probabilistic Programming Language, PPL) progettato per l’inferenza bayesiana in modelli statistici complessi. Una delle sue caratteristiche distintive è l’implementazione del No-U-Turn Sampler (NUTS), un algoritmo avanzato che ottimizza il metodo Hamiltonian Monte Carlo (HMC). Rispetto al tradizionale algoritmo di Metropolis (Capitolo 56), NUTS offre una convergenza più rapida alla distribuzione a posteriori, riducendo drasticamente il numero di iterazioni necessarie, specialmente in modelli ad alta dimensionalità. Pur producendo risultati equivalenti dal punto di vista teorico, NUTS rappresenta un significativo passo avanti in termini di efficienza computazionale.\n\n\n\n58.0.1 Programmazione probabilistica con Stan\nLa programmazione probabilistica integra i principi della statistica bayesiana con i linguaggi di programmazione, semplificando la costruzione di modelli complessi (si veda Nicenboim et al. (2025) per una trattazione approfondita). In un PPL come Stan, il ricercatore deve solo specificare:\n\nle distribuzioni a priori dei parametri,\n\nla funzione di verosimiglianza.\n\nL’inferenza bayesiana viene poi eseguita automaticamente dal linguaggio, che genera campioni dalla distribuzione a posteriori attraverso algoritmi MCMC avanzati.\nLa struttura di un programma Stan è organizzata in blocchi logici:\n\n\ndata: contiene i dati osservati in input,\n\n\nparameters: dichiara i parametri da stimare,\n\n\nmodel: specifica le distribuzioni a priori e la verosimiglianza,\n\n\ngenerated quantities: calcola quantità derivate (es. previsioni, log-verosimiglianze).\n\nQuesta architettura modulare rende Stan intuitivo e adattabile a un’ampia gamma di applicazioni statistiche.\n\n58.0.2 Lavorare con Stan in R\nL’interfaccia cmdstanr per R segue un workflow ben definito:\n\nscrittura del modello in un file .stan,\n\ncompilazione del modello,\n\npassaggio dei dati come lista R ,\nesecuzione del campionamento con sample(),\n\nanalisi dei risultati mediante pacchetti specializzati (posterior, bayesplot).\n\nStan utilizza un sistema di tipizzazione statica: tutte le variabili devono essere dichiarate con tipi specifici (int per interi, real per valori reali, vector per vettori) e possono includere vincoli (es. lower=0 per valori positivi). Questo approccio aumenta la robustezza del codice e previene errori comuni nella specificazione dei modelli.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Introduzione pratica a Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_intro.html#dati-binari-distribuzione-di-bernoulli",
    "href": "chapters/mcmc/03_stan_intro.html#dati-binari-distribuzione-di-bernoulli",
    "title": "58  Introduzione pratica a Stan",
    "section": "\n58.1 Dati binari (distribuzione di Bernoulli)",
    "text": "58.1 Dati binari (distribuzione di Bernoulli)\nPartiamo da un esempio elementare: stimare la probabilità di successo in prove Bernoulli indipendenti. L’esperimento consiste in 1000 lanci di un dado. Registriamo:\n\n\n1 se esce un 6 (successo),\n\n0 altrimenti (fallimento).\n\nL’obiettivo è stimare la probabilità \\(\\theta = P(\\text{uscita = 6})\\). Se il dado è equo ci aspettiamo \\(\\theta = 1/6 \\approx 0.167\\), ma in un’analisi bayesiana lasciamo che siano i dati a informarci, senza assumere a priori che il dado sia perfettamente bilanciato.\nSimulazione dei dati:\n\nn &lt;- 1000\ndice_df &lt;- tibble(res = sample(1:6, size = n, replace = TRUE))\n\ny &lt;- dice_df %&gt;%\n  mutate(is_six = as.integer(res == 6)) %&gt;%\n  pull(is_six)\n\nmean(y)  # frequenza relativa di \"6\"\n#&gt; [1] 0.162\n\nIl modello è:\n\nlikelihood: \\(y_i \\sim \\text{Bernoulli}(\\theta)\\),\nprior: \\(\\theta \\sim \\text{Beta}(1,1)\\) (uniforme in \\([0,1]\\)).\n\nIn Stan:\n\nstancode &lt;- \"\ndata {\n  int&lt;lower=1&gt; N;\n  array[N] int&lt;lower=0, upper=1&gt; y;\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; theta;\n}\nmodel {\n  theta ~ beta(1, 1);     // prior\n  y ~ bernoulli(theta);   // likelihood\n}\n\"\n\nÈ necessario compilare il modello in un file temporaneo:\n\nstanmod &lt;- cmdstan_model(write_stan_file(stancode), compile = TRUE)\n\nPerché si compila? Stan traduce il codice del modello in un programma C++, lo compila e produce un eseguibile. Questo passaggio iniziale può richiedere qualche secondo, ma ha un grande vantaggio: una volta compilato, il modello può essere riutilizzato più volte in modo molto veloce, anche con dataset diversi.\nPreparazione dei dati.\n\ndata_list &lt;- list(N = length(y), y = y)\n\nIn Stan, i dati vanno passati come lista R (o dizionario in Python). I nomi e i tipi devono corrispondere a quanto dichiarato nel blocco data del modello.\nCampionamento MCMC:\n\nfit &lt;- stanmod$sample(\n  data = data_list,\n  iter_warmup = 1000,\n  iter_sampling = 10000,\n  chains = 4,\n  parallel_chains = 4,\n  seed = 4790\n)\n\n\n\niter_warmup indica le iterazioni iniziali da scartare (fase di adattamento);\n\niter_sampling è il numero di campioni da conservare;\n\nchains specifica quante catene indipendenti avviare.\n\nRisultati:\n\nprint(fit$summary())\n#&gt; # A tibble: 2 × 10\n#&gt;   variable    mean  median    sd   mad      q5     q95  rhat ess_bulk\n#&gt;   &lt;chr&gt;      &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 lp__     -445.47 -445.19  0.71  0.31 -446.91 -444.97  1.00 17447.94\n#&gt; 2 theta       0.16    0.16  0.01  0.01    0.14    0.18  1.00 14160.01\n#&gt;   ess_tail\n#&gt;      &lt;dbl&gt;\n#&gt; 1 20479.98\n#&gt; 2 16483.55\n\nStima sintetica della distribuzione a posteriori:\n\ndraws &lt;- fit$draws(format = \"draws_matrix\")\nposterior::summarise_draws(\n  draws, mean, sd, ~quantile(.x, c(0.025, 0.5, 0.975))\n)\n#&gt; # A tibble: 2 × 6\n#&gt;   variable    mean    sd  `2.5%`   `50%` `97.5%`\n#&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 lp__     -445.47  0.71 -447.51 -445.19 -444.97\n#&gt; 2 theta       0.16  0.01    0.14    0.16    0.19\n\nDiagnostiche:\n\nbayesplot::mcmc_combo(draws, pars = \"theta\")\n\n\n\n\n\n\n\nInterpretazione rapida:\n\nLa media a posteriori di \\(\\theta\\) fornisce la probabilità stimata di ottenere un 6.\nL’intervallo di credibilità (ad es. 95%) quantifica l’incertezza della stima.\nValori di \\(\\hat{R} \\approx 1\\) e un alto numero di campioni efficaci (ESS) indicano una buona convergenza delle catene.\n\n\n\n\n\n\n\nUn confronto utile\n\n\n\nLa frequenza relativa mean(y) è una stima puntuale. L’analisi bayesiana restituisce una distribuzione di plausibilità per \\(\\theta\\). Questo è cruciale quando vogliamo propagare l’incertezza in analisi successive (previsioni, decisioni, ecc.).\n\n\n\n58.1.1 Distribuzione Predittiva Posteriore\nDopo aver stimato la probabilità \\(\\theta\\) che esca un “6” in un lancio di dado, possiamo chiederci: Quante volte ci aspettiamo di osservare un “6” in \\(n\\) futuri lanci?\nCondizionatamente a \\(\\theta\\), il numero di successi (“6”) in \\(n\\) nuovi lanci segue una distribuzione binomiale:\n\\[\ny_{\\text{rep}} \\mid \\theta \\sim \\text{Binomiale}(n, \\theta) .\n\\]\nPer ottenere la distribuzione predittiva posteriore, integriamo rispetto alla distribuzione a posteriori di \\(\\theta\\):\n\\[\np(y_{\\text{rep}} \\mid y) = \\int p(y_{\\text{rep}} \\mid \\theta) \\, p(\\theta \\mid y) \\, d\\theta .\n\\]\nIn pratica, questo si ottiene campionando valori di \\(\\theta\\) dal posterior e simulando \\(y_{\\text{rep}}\\) per ciascun valore.\nEcco come generare e visualizzare la distribuzione predittiva:\n\n# Numero di futuri lanci da simulare\nn_new &lt;- 1000  \n\n# Campioni dalla distribuzione a posteriori di theta (es. estratti da Stan o MCMC)\ntheta_draws &lt;- as.numeric(draws[, \"theta\"])  \n\n# Simulazione dei conteggi predittivi\nyrep_count &lt;- rbinom(n = length(theta_draws), size = n_new, prob = theta_draws)\n\n# Visualizzazione\ntibble(count = yrep_count) %&gt;%\n  ggplot(aes(x = count)) +\n  geom_histogram(bins = 30, fill = palette_set1[\"due\"], color = \"white\", alpha = 0.8) +\n  labs(\n    title = \"Distribuzione Predittiva Posteriore\\ndel numero di '6' in 1000 lanci\",\n    x = \"Numero di '6' osservati\",\n    y = \"Frequenza\"\n  ) \n\n\n\n\n\n\n\n\n58.1.1.1 Interpretazione\n\nL’istogramma mostra la variabilità attesa del numero di “6” in 1000 lanci futuri.\nLa distribuzione è centrata intorno a \\(n \\cdot \\mathbb{E}[\\theta \\mid y]\\) (~167 per un dado equo).\nSe il dado fosse perfetto (\\(\\theta=1/6\\)), il 95% degli intervalli predittivi sarebbe tra ~150 e 185. Deviazioni marcate potrebbero indicare un bias del dado.\n\nNota:\n\nSe il dado fosse perfettamente bilanciato (\\(\\theta = 1/6\\)), il 95% degli intervalli predittivi dovrebbe includere ~150-185 successi.\n\nDeviazioni sostanziali da questo range potrebbero indicare un bias nel dado.\n\n\n\n\n\n\n\nStessa inferenza, sintassi esplicita (target +=)\n\n\n\n\n\nLa forma compatta\ntheta ~ beta(1,1);\ny ~ bernoulli(theta);\nè più leggibile e di solito preferita. Ma in realtà Stan lavora sempre nello stesso modo: somma i logaritmi delle probabilità in una variabile interna chiamata target.\n\n\ntarget rappresenta la log-verosimiglianza totale più i contributi dei prior.\nOgni istruzione target += ... aggiunge un pezzo di log-densità.\n\nUn po’ come fare un “conto cumulativo”: ad ogni riga aggiungiamo punti a favore (o contro) di certi valori dei parametri, e alla fine Stan sceglie i valori più coerenti con tutti i contributi sommati.\nQuesta è la versione esplicita:\n\nstancode_explicit &lt;- \"\ndata {\n  int&lt;lower=1&gt; N;\n  array[N] int&lt;lower=0, upper=1&gt; y;\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; theta;\n}\nmodel {\n  target += beta_lpdf(theta | 1, 1);          // prior esplicito\n  target += bernoulli_lpmf(y | theta);        // log-massa di probabilità\n}\n\"\n\n\nstanmod2 &lt;- cmdstan_model(write_stan_file(stancode_explicit), compile = TRUE)\n\n\nfit2 &lt;- stanmod2$sample(\n  data = list(N = length(y), y = y),\n  iter_warmup = 1000,\n  iter_sampling = 10000,\n  chains = 4,\n  parallel_chains = 4,\n  refresh = 1000,\n  seed = 4790\n)\n\n\nprint(fit2$summary())\n#&gt; # A tibble: 2 × 10\n#&gt;   variable    mean  median    sd   mad      q5     q95  rhat ess_bulk\n#&gt;   &lt;chr&gt;      &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 lp__     -445.47 -445.19  0.71  0.31 -446.91 -444.97  1.00 17447.94\n#&gt; 2 theta       0.16    0.16  0.01  0.01    0.14    0.18  1.00 14160.01\n#&gt;   ess_tail\n#&gt;      &lt;dbl&gt;\n#&gt; 1 20479.98\n#&gt; 2 16483.55\n\nI risultati coincidono (entro l’errore Monte Carlo) con la versione compatta, come atteso.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Introduzione pratica a Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_intro.html#dati-continui-stima-della-media-con-sigma-noto",
    "href": "chapters/mcmc/03_stan_intro.html#dati-continui-stima-della-media-con-sigma-noto",
    "title": "58  Introduzione pratica a Stan",
    "section": "\n58.2 Dati continui: stima della media con \\(\\sigma\\) noto",
    "text": "58.2 Dati continui: stima della media con \\(\\sigma\\) noto\nConsideriamo ora un caso leggermente più complesso: stimare la media \\(\\mu\\) di una distribuzione normale quando la deviazione standard \\(\\sigma\\) è nota. Questa ipotesi – conoscere \\(\\sigma\\) con certezza – è rara nella pratica, ma molto utile didatticamente: semplifica il modello e permette di concentrare l’attenzione sulla stima della media.\n\n58.2.1 Simuliamo i dati\nImmaginiamo di raccogliere i punteggi QI di 30 persone, con deviazione standard nota pari a 15 punti. I dati simulati hanno media vera 105:\n\nn &lt;- 30\nsigma &lt;- 15\ny_cont &lt;- rnorm(n, mean = 105, sd = sigma) %&gt;% round(0)\n\ntibble(y = y_cont) %&gt;%\n  ggplot(aes(x = y)) +\n  geom_histogram(bins = 15, fill = palette_set1[\"due\"], color = \"white\", alpha = 0.8) +\n  labs(title = \"Distribuzione simulata di punteggi QI\",\n       x = \"Punteggio\", y = \"Frequenza\")\n\n\n\n\n\n\n\n\n58.2.2 Specificazione del modello\nIl modello statistico è:\n\nLikelihood: \\(y_i \\sim \\mathcal{N}(\\mu, \\sigma), \\quad i=1,\\dots,N\\) con \\(\\sigma\\) noto.\nPrior su \\(\\mu\\): \\(\\mu \\sim \\mathcal{N}(\\mu_0,\\; \\tau)\\) dove \\(\\mu_0 = 100\\) e \\(\\tau = 30\\) rappresentano la nostra credenza iniziale: la media del QI tende a essere intorno a 100, ma con una larga incertezza.\n\n58.2.3 Codice Stan\nIl file Stan corrispondente è:\n\nstancode_norm &lt;- \"\ndata {\n  int&lt;lower=0&gt; N;\n  vector[N] y;                 \n  real&lt;lower=0&gt; sigma;         // sd nota\n  real mu0;                    // media del prior su mu\n  real&lt;lower=0&gt; mu_prior_sd;   // sd del prior\n}\nparameters {\n  real mu;                     // parametro di interesse\n}\nmodel {\n  mu ~ normal(mu0, mu_prior_sd);  // prior\n  y ~ normal(mu, sigma);          // likelihood\n}\n\"\n\n\n58.2.4 Lancio del modello\n\nstanmod3 &lt;- cmdstan_model(write_stan_file(stancode_norm), compile = TRUE)\n\ndata_list3 &lt;- list(\n  N = length(y_cont),\n  y = y_cont,\n  sigma = sigma,\n  mu0 = 100,\n  mu_prior_sd = 30\n)\n\nfit3 &lt;- stanmod3$sample(\n  data = data_list3,\n  iter_warmup = 1000,\n  iter_sampling = 10000,\n  chains = 4,\n  parallel_chains = 4,\n  seed = 4790,\n  refresh = 1000\n)\n\n\n58.2.5 Risultati\n\nprint(fit3$summary())\n#&gt; # A tibble: 2 × 10\n#&gt;   variable   mean median    sd   mad     q5    q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 lp__     -14.73 -14.47  0.69  0.31 -16.13 -14.24  1.00 19320.52 24333.41\n#&gt; 2 mu       106.01 106.03  2.70  2.73 101.55 110.45  1.00 14921.37 20711.16\n\n\ndraws3 &lt;- fit3$draws(format = \"draws_matrix\")\nposterior::summarise_draws(\n  draws3, mean, sd, ~quantile(.x, c(0.025, 0.5, 0.975))\n)\n#&gt; # A tibble: 2 × 6\n#&gt;   variable   mean    sd `2.5%`  `50%` `97.5%`\n#&gt;   &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 lp__     -14.73  0.69 -16.67 -14.47  -14.24\n#&gt; 2 mu       106.01  2.70 100.69 106.03  111.29\n\n\n58.2.6 Interpretazione\n\n\nLa distribuzione a posteriori di \\(\\mu\\) è ottenuta combinando:\n\nil prior \\(\\mathcal{N}(100, 30)\\),\nl’informazione dei dati osservati.\n\n\nL’intervallo di credibilità mostra l’incertezza residua: più osservazioni abbiamo, più questo intervallo si restringe.\nLa convergenza del campionamento va sempre controllata con \\(\\hat{R} \\approx 1\\) e con un numero elevato di campioni effettivi (ESS).\n\n58.2.7 Visualizzazione\nDistribuzione a posteriori di \\(\\mu\\):\n\nbayesplot::mcmc_hist(fit3$draws(\"mu\"))\n\n\n\n\n\n\n\nAndamento delle catene:\n\nbayesplot::mcmc_trace(fit3$draws(\"mu\"), n_warmup = 1000)\n\n\n\n\n\n\n\nOverlay delle densità per catena:\n\nbayesplot::mcmc_dens_overlay(fit3$draws(\"mu\"))\n\n\n\n\n\n\n\nIn sintesi: questo modello rappresenta una sorta di “test Bayesiano della media”. A differenza dell’approccio frequentista, non otteniamo solo una stima puntuale e un intervallo di confidenza, ma un’intera distribuzione di plausibilità per \\(\\mu\\), che riflette sia l’incertezza dei dati sia le nostre conoscenze a priori.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Introduzione pratica a Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_intro.html#approfondimento",
    "href": "chapters/mcmc/03_stan_intro.html#approfondimento",
    "title": "58  Introduzione pratica a Stan",
    "section": "\n58.3 Approfondimento",
    "text": "58.3 Approfondimento\nUna volta eseguito il campionamento MCMC, possiamo esplorare direttamente i campioni generati per il parametro \\(\\mu\\).\n\n58.3.1 Estrarre i campioni\n\nmu_samples &lt;- fit3$draws(variables = \"mu\", format = \"array\")\ndim(mu_samples)\n#&gt; [1] 10000     4     1\n\nL’output di dim(mu_samples) mostra la struttura dell’oggetto:\n\nla prima dimensione corrisponde al numero di iterazioni di campionamento (10.000 nel nostro caso),\nla seconda al numero di catene indipendenti (4),\nla terza al numero di parametri monitorati (qui solo 1: \\(\\mu\\)).\n\nDunque la forma dell’array è (iterazioni, catene, variabili).\nPer dare un’occhiata al contenuto:\n\nmu_samples |&gt; glimpse()\n#&gt;  'draws_array' num [1:10000, 1:4, 1] 106 108 109 107 107 ...\n#&gt;  - attr(*, \"dimnames\")=List of 3\n#&gt;   ..$ iteration: chr [1:10000] \"1\" \"2\" \"3\" \"4\" ...\n#&gt;   ..$ chain    : chr [1:4] \"1\" \"2\" \"3\" \"4\"\n#&gt;   ..$ variable : chr \"mu\"\n\nSe vogliamo lavorare con un vettore unico che contenga tutti i campioni a posteriori (senza distinguere per catena), possiamo “appiattire” l’array:\n\nmu_vector &lt;- as.vector(mu_samples)\nlength(mu_vector)   # numero totale di campioni\n#&gt; [1] 40000\nhead(mu_vector)\n#&gt; [1] 105.9 108.2 108.5 107.5 107.5 109.7\n\n\n58.3.2 Visualizzare la distribuzione a posteriori\nPossiamo rappresentare la distribuzione dei campioni in diversi modi. Un primo approccio è un istogramma:\n\nggplot(data.frame(mu = mu_vector), aes(x = mu)) +\n  geom_histogram(bins = 30, fill = palette_set1[\"due\"], color = \"white\", alpha = 0.8) +\n  labs(\n    title = \"Distribuzione a posteriori di mu\",\n    x = \"mu\",\n    y = \"Frequenza\"\n  )\n\n\n\n\n\n\n\nLo stesso risultato si ottiene in modo più diretto con bayesplot:\n\nmcmc_hist(fit3$draws(\"mu\"))\n\n\n\n\n\n\n\nIl grafico mostra:\n\nla modalità della distribuzione (valore più plausibile di \\(\\mu\\)),\nl’ampiezza della distribuzione, che riflette l’incertezza della stima,\nse l’istogramma è stretto, significa che i dati hanno fornito una stima precisa di \\(\\mu\\),\nse è ampio, l’incertezza è maggiore.\n\n58.3.3 Confronto fra catene e diagnostiche grafiche\nPer verificare che le catene abbiano esplorato bene lo spazio dei parametri, possiamo confrontare le densità stimate separatamente per ogni catena:\n\nbayesplot::mcmc_dens_overlay(fit3$draws(\"mu\"))\n\n\n\n\n\n\n\nPossiamo anche guardare il traceplot, che mostra l’andamento delle catene nel tempo:\n\nbayesplot::mcmc_trace(fit3$draws(\"mu\"), n_warmup = 1000)\n\n\n\n\n\n\n\nUn traceplot “a tappeto” (senza trend o pattern sospetti) è indice di buona mescolanza e convergenza.\nInfine, è possibile sintetizzare la distribuzione con intervalli di credibilità:\n\nbayesplot::mcmc_intervals(fit3$draws(\"mu\"), prob_outer = 0.94)\n\n\n\n\n\n\n\nIn sintesi:\nl’analisi grafica dei campioni è un passaggio cruciale nell’inferenza Bayesiana. Ci permette di:\n\nverificare la convergenza delle catene,\nvalutare l’incertezza nelle stime,\ncomunicare visivamente i risultati.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Introduzione pratica a Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_intro.html#intervallo-di-credibilità",
    "href": "chapters/mcmc/03_stan_intro.html#intervallo-di-credibilità",
    "title": "58  Introduzione pratica a Stan",
    "section": "\n58.4 Intervallo di Credibilità",
    "text": "58.4 Intervallo di Credibilità\nGli intervalli di credibilità riassumono l’incertezza sui parametri stimati in un’analisi bayesiana. A differenza degli intervalli di confidenza frequentisti, hanno un’interpretazione probabilistica diretta: dato il modello e i dati, c’è una probabilità specificata (ad esempio 94%) che il parametro cada nell’intervallo calcolato.\n\n58.4.1 Due metodi principali\n\n\nHighest Density Interval (HDI): l’intervallo più stretto che contiene la probabilità specificata, concentrandosi nelle zone di massima densità.\n\nEqual-tailed Interval (ETI): lascia la stessa probabilità nelle due code della distribuzione (es. 2,5% + 2,5% per un intervallo al 95%).\n\nSe la distribuzione a posteriori è simmetrica (es. normale), i due metodi coincidono; se è asimmetrica, l’HDI è in genere più informativo perché più compatto.\n\n58.4.1.1 Esempio in R\n\n# Genera una distribuzione normale\nposterior &lt;- distribution_normal(1000)\n\n# Calcola HDI ed ETI\nci_hdi &lt;- ci(posterior, method = \"HDI\")\nci_eti &lt;- ci(posterior, method = \"ETI\")\n\n# Visualizza la distribuzione con i limiti degli intervalli\nout &lt;- estimate_density(posterior, extend = TRUE)\nggplot(out, aes(x = x, y = y)) +\n  geom_area(fill = palette_set1[\"due\"], alpha = 0.6) +\n  # HDI in blu\n  geom_vline(xintercept = ci_hdi$CI_low, color = palette_set1[\"uno\"], linewidth = 3) +\n  geom_vline(xintercept = ci_hdi$CI_high, color = palette_set1[\"uno\"], linewidth = 3) +\n  # ETI in rosso\n  geom_vline(xintercept = ci_eti$CI_low, color = palette_set1[\"tre\"], linewidth = 1) +\n  geom_vline(xintercept = ci_eti$CI_high, color = palette_set1[\"tre\"], linewidth = 1)\n\n\n\n\n\n\n\nDistribuzione Asimmetrica\nQuando la distribuzione a posteriori è asimmetrica, come una distribuzione beta, l’HDI è generalmente più stretto rispetto all’ETI poiché privilegia le regioni di maggiore densità.\nEsempio di calcolo:\n\n# Genera una distribuzione beta\nposterior &lt;- distribution_beta(1000, 6, 2)\n\n# Calcola HDI ed ETI\nci_hdi &lt;- ci(posterior, method = \"HDI\")\nci_eti &lt;- ci(posterior, method = \"ETI\")\n\n# Visualizza la distribuzione con i limiti degli intervalli\nout &lt;- estimate_density(posterior, extend = TRUE)\nggplot(out, aes(x = x, y = y)) +\n  geom_area(fill = palette_set1[\"due\"], alpha = 0.6) +\n  # HDI in blu\n  geom_vline(xintercept = ci_hdi$CI_low, color = palette_set1[\"uno\"], linewidth = 3) +\n  geom_vline(xintercept = ci_hdi$CI_high, color = palette_set1[\"uno\"], linewidth = 3) +\n  # ETI in rosso\n  geom_vline(xintercept = ci_eti$CI_low, color = palette_set1[\"tre\"], linewidth = 1) +\n  geom_vline(xintercept = ci_eti$CI_high, color = palette_set1[\"tre\"], linewidth = 1)\n\n\n\n\n\n\n\n\n58.4.1.2 Funzioni R\n\n\nHDI:\n\n\nbayestestR::ci(fit3$draws(\"mu\"), method = \"HDI\")\n#&gt; Highest Density Interval\n#&gt; \n#&gt; Parameter |          95% HDI\n#&gt; ----------------------------\n#&gt; mu        | [100.64, 111.21]\n\n\n\nETI:\n\n\nbayestestR::ci(fit3$draws(\"mu\"), method = \"ETI\")\n#&gt; Equal-Tailed Interval\n#&gt; \n#&gt; Parameter |          95% ETI\n#&gt; ----------------------------\n#&gt; mu        | [100.69, 111.29]\n\nUtilizzando il pacchetto bayesplot possiamo rappresentare la distribuzione a posteriori con l’HDI:\n\nmcmc_areas(fit3$draws(\"mu\"), \n           prob = 0.94) +  # Specifica il livello dell'HDI\n  ggtitle(\"Distribuzione a Posteriori di Mu con HDI al 94%\") +\n  xlab(expression(mu)) +\n  ylab(\"Densità\")\n\n\n\n\n\n\n\n\n58.4.2 Scelta del Livello dell’Intervallo (89% vs 95%)\nUna discussione comune nell’inferenza bayesiana riguarda il livello predefinito degli intervalli. Sebbene il 95% sia un valore convenzionale mutuato dal frequentismo, alcune evidenze suggeriscono che livelli più bassi (ad esempio, 89%) possano essere più stabili per le distribuzioni a posteriori, specialmente con un numero limitato di campioni posteriori (Kruschke, 2014).\n\n\nVantaggi del 95%:\n\nRelazione intuitiva con la deviazione standard.\nMaggiore probabilità di includere 0, rendendo le analisi più conservative.\n\n\n\nVantaggi dell’89%:\n\nMaggiore stabilità con campioni posteriori limitati.\nEvita l’arbitrarietà del valore 95% (McElreath, 2018).\n\n\n\nIn conclusione, la scelta tra HDI e ETI, così come il livello dell’intervallo, dipende dagli obiettivi e dal contesto dell’analisi. Gli intervalli di credibilità offrono un approccio flessibile e intuitivo per sintetizzare l’incertezza, adattandosi alle esigenze di analisi sia esplorative che confermative.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Introduzione pratica a Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_intro.html#test-di-ipotesi-bayesiane",
    "href": "chapters/mcmc/03_stan_intro.html#test-di-ipotesi-bayesiane",
    "title": "58  Introduzione pratica a Stan",
    "section": "\n58.5 Test di ipotesi bayesiane",
    "text": "58.5 Test di ipotesi bayesiane\nL’inferenza bayesiana permette di rispondere in maniera diretta a domande pratiche del tipo: qual è la probabilità che un parametro superi una soglia considerata rilevante?\nRiprendiamo l’esempio del QI. Potremmo chiederci: quanto è plausibile che la media del QI* in un campione di bambini sia maggiore di 110?* La soglia di 110 viene spesso utilizzata come riferimento per indicare un livello cognitivo superiore alla media. Stimando la distribuzione a posteriori della media \\(\\mu\\), possiamo calcolare in modo immediato la probabilità:\n\\[\nP(\\mu &gt; 110 \\mid y),\n\\]\nossia la porzione di distribuzione a posteriori che si trova al di sopra di questo valore soglia. Questa probabilità si ricava direttamente dai campioni posteriori:\n\nfit3$summary(\"mu\", pr_gt_110 = ~ mean(. &gt; 110))\n#&gt; # A tibble: 1 × 2\n#&gt;   variable pr_gt_110\n#&gt;   &lt;chr&gt;        &lt;dbl&gt;\n#&gt; 1 mu            0.07\n\nCiò significa che, dati il modello e i dati osservati, c’è una probabilità dell’9% che la media del campione superi la soglia di 110.\nQuesto risultato non è un “sì” o “no” categorico, ma una misura graduale della plausibilità dell’affermazione “la media del campione è sopra la soglia di 110”. In questo caso, la probabilità relativamente bassa indica che i dati osservati non sostengono fortemente tale affermazione, pur lasciando un margine di possibilità.\nIn sintesi, il test di ipotesi bayesiano non richiede ipotesi nulle o valori critici: tutto si basa sulla distribuzione a posteriori del parametro. Questo approccio fornisce risposte intuitive e direttamente interpretabili, soprattutto in contesti applicativi come la psicologia clinica e scolastica, dove soglie pratiche (ad esempio QI &gt; 110) hanno un significato concreto.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Introduzione pratica a Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_intro.html#diagnostiche-di-campionamento",
    "href": "chapters/mcmc/03_stan_intro.html#diagnostiche-di-campionamento",
    "title": "58  Introduzione pratica a Stan",
    "section": "\n58.6 Diagnostiche di campionamento",
    "text": "58.6 Diagnostiche di campionamento\nUna volta ottenuti i campioni a posteriori, è fondamentale verificarne la qualità. Stan fornisce diversi indicatori diagnostici che permettono di capire se le catene MCMC hanno esplorato bene lo spazio dei parametri.\n\n58.6.1 Statistica \\(\\hat{R}\\)\n\nLa prima verifica riguarda la statistica di convergenza \\(\\hat{R}\\) (R-hat).\n\nrhats &lt;- rhat(fit3$draws(\"mu\"))\nprint(rhats)\n#&gt; [1] 1\nbayesplot::mcmc_rhat(rhats)\n\n\n\n\n\n\n\nUn valore di \\(\\hat{R}\\) molto vicino a 1 indica che le catene sono ben mescolate e che la convergenza è stata raggiunta. Valori superiori a 1.01–1.05 possono invece segnalare problemi.\n\n58.6.2 Dimensione del campione effettivo\nOltre alla convergenza, è importante sapere quanti campioni indipendenti equivalenti sono stati ottenuti. Questo numero è detto Effective Sample Size (\\(N_{\\text{eff}}\\)).\n\nfit3$summary()\n#&gt; # A tibble: 2 × 10\n#&gt;   variable   mean median    sd   mad     q5    q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 lp__     -14.73 -14.47  0.69  0.31 -16.13 -14.24  1.00 19320.52 24333.41\n#&gt; 2 mu       106.01 106.03  2.70  2.73 101.55 110.45  1.00 14921.37 20711.16\n\nNell’output di summary(), per ciascun parametro vengono riportati:\n\n\nmean e median: la media e la mediana della distribuzione a posteriori. Per \\(\\mu\\), media e mediana coincidono quasi perfettamente (106.39), segno che la distribuzione è simmetrica.\n\nsd: la deviazione standard, misura dell’incertezza residua (2.73 per \\(\\mu\\)).\n\nmad: la deviazione assoluta mediana, una misura di dispersione robusta. Per \\(\\mu\\) è quasi identica alla sd, confermando l’assenza di code estreme.\n\nq5 e q95: quantili al 5% e 95%, che definiscono un intervallo di credibilità al 90%. Per \\(\\mu\\), \\([101.9,; 110.9]\\).\n\nrhat: la statistica \\(\\hat{R}\\), uguale a 1, conferma la convergenza.\n\ness_bulk e ess_tail: il numero effettivo di campioni indipendenti rispettivamente per la parte centrale e per le code della distribuzione. Valori molto alti (es. &gt;10.000) indicano stime estremamente precise.\n\nIn sintesi: la distribuzione di \\(\\mu\\) è ben stimata, con campioni abbondanti ed efficienti, e senza problemi di convergenza.\n\n58.6.3 Dimensione del campione effettivo e errore Monte Carlo\nPerché serve \\(N_{\\text{eff}}\\)? Nei metodi MCMC, i campioni successivi sono correlati. \\(N_{\\text{eff}}\\) corregge per questa dipendenza e si calcola come:\n\\[\nN_{\\text{eff}} = \\frac{M}{\\text{IAT}},\n\\]\ndove \\(M\\) è il numero di iterazioni totali e \\(\\text{IAT}\\) è il tempo di autocorrelazione integrata.\nStan riporta anche l’errore standard Monte Carlo:\n\\[\n\\text{mcmc-se} = \\frac{\\text{sd}[\\theta \\mid y]}{\\sqrt{N_{\\text{eff}}}} ,\n\\]\nche misura la precisione numerica della stima dovuta al campionamento. Con \\(N_{\\text{eff}}\\) molto grande, questo errore diventa trascurabile.\n\n58.6.4 Altri indicatori di efficienza\nInfine, è utile controllare i report diagnostici più specifici:\n\nfit3$diagnostic_summary()\n#&gt; $num_divergent\n#&gt; [1] 0 0 0 0\n#&gt; \n#&gt; $num_max_treedepth\n#&gt; [1] 0 0 0 0\n#&gt; \n#&gt; $ebfmi\n#&gt; [1] 1.141 1.142 1.247 1.212\n\n\n\nnum_divergent: numero di transizioni divergenti. Se è 0, il campionamento non ha incontrato ostacoli numerici.\n\nnum_max_treedepth: numero di transizioni che hanno raggiunto la profondità massima consentita dall’algoritmo NUTS. Se è 0, l’esplorazione è stata completa.\n\nebfmi: Energy Bayesian Fraction of Missing Information. Valori &gt;0.3–0.4 sono considerati adeguati. Indicano che lo spazio dei parametri è stato esplorato in modo efficiente.\n\nNel nostro esempio, i risultati delle diagnostiche sono ottimali:\n\n\n\\(\\hat{R} = 1\\) per tutti i parametri,\n\n\\(N_{\\text{eff}}\\) molto alto,\nnessuna transizione divergente né problemi di profondità,\nEBFMI ben sopra le soglie di sicurezza.\n\nPossiamo quindi concludere che il campionamento MCMC è stato stabile, efficiente e affidabile, e che le stime a posteriori per \\(\\mu\\) riflettono bene l’informazione contenuta nei dati e nel prior.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Introduzione pratica a Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_intro.html#verifica-dei-prior-prior-predictive-check",
    "href": "chapters/mcmc/03_stan_intro.html#verifica-dei-prior-prior-predictive-check",
    "title": "58  Introduzione pratica a Stan",
    "section": "\n58.7 Verifica dei prior (Prior Predictive Check)",
    "text": "58.7 Verifica dei prior (Prior Predictive Check)\nObiettivo. Prima di guardare i dati, vogliamo chiederci: le nostre assunzioni a priori su \\(\\mu\\) sono plausibili? In altre parole, il prior scelto produce valori di \\(y\\) che hanno senso rispetto al dominio del problema (qui: punteggi QI)?\n\n58.7.1 Idea di base\nIl nostro modello è:\n\\[\ny_i \\mid \\mu \\sim \\mathcal{N}(\\mu,\\; \\sigma),\n\\qquad\n\\mu \\sim \\mathcal{N}(\\mu_0,\\; \\tau).\n\\]\nCombinando likelihood e prior, la distribuzione predittiva a priori di una singola osservazione è:\n\\[\ny_i \\sim \\mathcal{N}\\!\\Big(\\mu_0,\\; \\sqrt{\\sigma^2 + \\tau^2}\\Big).\n\\]\nQuesta distribuzione descrive quali valori ci aspettiamo prima di osservare alcun dato.\n\nSe produce valori estremi o inverosimili (ad es. QI &lt; 40 o &gt; 160), il prior è troppo largo o spostato.\nSe invece produce valori troppo concentrati in un intervallo ristretto, il prior è eccessivamente informativo, lasciando poco spazio ai dati.\n\n58.7.2 Uno switch per attivare o disattivare la likelihood\nPer implementare un prior predictive check possiamo usare lo stesso file Stan dell’inferenza, con una piccola modifica:\n\naggiungiamo una variabile booleana compute_likelihood, che ci permette di decidere se includere o meno la riga y ~ normal(mu, sigma);,\ngeneriamo repliche \\(y_{\\text{rep}}\\) in un blocco generated quantities.\n\nEcco il codice Stan:\n\nstancode_norm_ppc &lt;- \"\ndata {\n  int&lt;lower=0&gt; N;\n  vector[N] y;                 // usato solo se compute_likelihood=1\n  real&lt;lower=0&gt; sigma;         // sd nota\n  real mu0;                    // media del prior su mu\n  real&lt;lower=0&gt; mu_prior_sd;   // sd del prior\n  int&lt;lower=0, upper=1&gt; compute_likelihood; // 1 = usa y ~ normal(..), 0 = disattiva\n}\nparameters {\n  real mu;\n}\nmodel {\n  mu ~ normal(mu0, mu_prior_sd);\n  if (compute_likelihood == 1) {\n    y ~ normal(mu, sigma);\n  }\n}\ngenerated quantities {\n  vector[N] y_rep;\n  vector[N] log_lik; \n\n  for (n in 1:N) {\n    y_rep[n] = normal_rng(mu, sigma); // repliche prior/posterior predictive\n    log_lik[n] = normal_lpdf(y[n] | mu, sigma); \n  }\n}\n\"\nstanmod_ppc &lt;- cmdstan_model(write_stan_file(stancode_norm_ppc), compile = TRUE)\n\n\n58.7.3 Prior predictive check (senza dati)\nPer un controllo puro del prior disattiviamo la likelihood (compute_likelihood = 0). In questo modo, Stan genera valori \\(y_{\\text{rep}}\\) esclusivamente a partire dalle assunzioni a priori.\n\nN_ppc &lt;- length(y_cont)\n\nstan_data_prior &lt;- list(\n  N = N_ppc,\n  y = rep(0, N_ppc),   # placeholder, non usato quando compute_likelihood = 0\n  sigma = sigma,\n  mu0 = 100,\n  mu_prior_sd = 30,\n  compute_likelihood = 0\n)\n\nfit_prior &lt;- stanmod_ppc$sample(\n  data = stan_data_prior,\n  iter_warmup = 500,\n  iter_sampling = 2000,\n  chains = 4,\n  parallel_chains = 4,\n  seed = 4790,\n  refresh = 500\n)\n\n\n58.7.4 Analisi delle repliche\nDopo il campionamento, estraiamo le repliche \\(y_{\\text{rep}}\\):\n\n# Estrazione dei dati simulati\nyrep_mat_prior &lt;- posterior::as_draws_matrix(fit_prior$draws(\"y_rep\"))\n\n# Selezione solo delle colonne y_rep[1],...,y_rep[N]\nN_ppc &lt;- length(y_cont)\nyrep_mat_prior &lt;- as.matrix(yrep_mat_prior[, paste0(\"y_rep[\", 1:N_ppc, \"]\")])\n\nConfrontiamo i dati osservati con alcune repliche generate dal prior:\n\nidx &lt;- sample(seq_len(nrow(yrep_mat_prior)), 100)\n\nbayesplot::ppc_dens_overlay(\n  y = y_cont,\n  yrep = yrep_mat_prior[idx, , drop = FALSE]\n) + ggtitle(\"Prior predictive vs dati osservati (overlay densità)\")\n\n\n\n\n\n\n\n\n58.7.5 Interpretazione\n\nSe le distribuzioni simulate coprono bene la variabilità dei dati reali, il prior è plausibile.\nSe le simulazioni sono sistematicamente troppo larghe o troppo strette, il prior va ripensato (riducendo o ampliando mu_prior_sd).\n\n58.7.6 Posterior predictive check (con i dati)\nDopo aver verificato che il prior sia ragionevole, possiamo passare alla fase successiva: confrontare il modello dopo aver visto i dati.\nPer farlo, riattiviamo la verosimiglianza (compute_likelihood = 1) e stimiamo la distribuzione a posteriori di \\(\\mu\\). Nel blocco generated quantities, Stan genera anche delle repliche posterior predictive \\(y_{\\text{rep}}\\), cioè nuovi dataset simulati sotto l’ipotesi che il modello e i parametri stimati siano corretti.\nIn altre parole:\n\nil prior predictive check serve a testare le assunzioni prima dei dati,\nil posterior predictive check serve a valutare se il modello dopo i dati è in grado di riprodurre l’evidenza osservata.\n\n\nstan_data_post &lt;- list(\n  N = length(y_cont),\n  y = y_cont,\n  sigma = sigma,\n  mu0 = 100,\n  mu_prior_sd = 30,\n  compute_likelihood = 1\n)\n\nLancio del campionamento:\n\nfit_post &lt;- stanmod_ppc$sample(\n  data = stan_data_post,\n  iter_warmup = 1000,\n  iter_sampling = 10000,\n  chains = 4,\n  parallel_chains = 4,\n  seed = 4790,\n  refresh = 1000\n)\n\nEstrazione e confronto con i dati reali:\n\ny_rep &lt;- fit_post$draws(\"y_rep\", format = \"matrix\")\nppc_dens_overlay(y = stan_data_post$y, yrep = y_rep[1:100, ])\n\n\n\n\n\n\n\n\n58.7.7 Interpretazione\n\nSe la distribuzione delle repliche \\(y_{\\text{rep}}\\) copre bene la distribuzione osservata \\(y\\), significa che il modello è in grado di spiegare i dati.\nSe invece ci sono scostamenti sistematici (ad es. le repliche hanno media troppo bassa, o varianza troppo alta rispetto ai dati reali), il modello non descrive adeguatamente il fenomeno e potrebbe essere rivisto.\n\n58.7.8 Collegamento con la verifica dei prior\n\nUn prior troppo largo può portare a simulazioni estreme e poco plausibili prima dei dati.\nUn prior troppo stretto rischia di imporre eccessiva rigidità al modello, lasciando poca flessibilità ai dati.\nNel posterior predictive check, quello che conta è verificare che, dopo aver aggiornato il modello con i dati, le simulazioni riflettano in modo realistico il comportamento osservato.\n\n58.7.9 Nota didattica\nCon \\(\\sigma\\) noto e \\(\\mu \\sim \\mathcal{N}(\\mu_0, \\tau)\\), la distribuzione predittiva a priori della media campionaria \\(\\bar{y}\\) è:\n\\[\n\\bar{y} \\sim \\mathcal{N}\\!\\big(\\mu_0,\\; \\sqrt{\\tau^2 + \\tfrac{\\sigma^2}{N}}\\big).\n\\]\nQuesta formula fornisce un controllo rapido per tarare il prior rispetto alla precisione attesa del campione. Dopo l’aggiornamento con i dati, la distribuzione a posteriori restringe l’incertezza, e le repliche posterior predictive permettono di verificarne la coerenza empirica.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Introduzione pratica a Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_intro.html#riflessioni-conclusive",
    "href": "chapters/mcmc/03_stan_intro.html#riflessioni-conclusive",
    "title": "58  Introduzione pratica a Stan",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nStan, grazie all’algoritmo NUTS, rappresenta oggi uno degli strumenti più potenti e versatili per l’inferenza bayesiana. La sua forza sta nella combinazione di tre elementi:\n\nuna sintassi chiara per la definizione di modelli probabilistici anche complessi,\nun motore di campionamento efficiente e affidabile,\nuna ricca suite di strumenti diagnostici e grafici che consentono di valutare la qualità del campionamento e l’adeguatezza del modello.\n\nIn questo capitolo abbiamo visto come, partendo da esempi semplici, sia possibile costruire modelli bayesiani, verificarne le assunzioni a priori, e confrontare i dati osservati con simulazioni predittive. Strumenti come il pacchetto bayesplot rendono queste verifiche intuitive e immediate, facilitando la comprensione dei risultati anche a un livello visivo.\nUn aspetto cruciale riguarda la scelta dello stimatore:\n\nla media della distribuzione a posteriori è lo stimatore più comune, perché minimizza l’errore quadratico medio;\nla mediana è utile per la sua robustezza rispetto a code o asimmetrie;\nla moda (MAP) può essere interpretata come il valore più plausibile, anche se in pratica è meno usata in analisi bayesiana.\n\nInfine, la corretta interpretazione delle stime passa sempre attraverso il controllo delle diagnostiche MCMC: bias, errore Monte Carlo, dimensione del campione effettivo (\\(N_{\\text{eff}}\\)) e indicatori di convergenza come \\(\\hat{R}\\). Solo quando questi strumenti segnalano un campionamento affidabile possiamo trarre conclusioni valide dal nostro modello.\nIn sintesi, l’approccio bayesiano con Stan non si limita a produrre numeri, ma offre un’intera cornice concettuale e operativa per quantificare l’incertezza, confrontare modelli e integrare in modo coerente conoscenze pregresse e dati osservati.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Introduzione pratica a Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_intro.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/03_stan_intro.html#informazioni-sullambiente-di-sviluppo",
    "title": "58  Introduzione pratica a Stan",
    "section": "Informazioni sull’ambiente di sviluppo",
    "text": "Informazioni sull’ambiente di sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] insight_1.3.1         bayestestR_0.16.1     cmdstanr_0.9.0       \n#&gt;  [4] pillar_1.11.0         tinytable_0.11.0      patchwork_1.3.1      \n#&gt;  [7] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.13.0     \n#&gt; [10] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.0     \n#&gt; [13] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [16] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [19] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [22] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [25] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3        inline_0.3.21        sandwich_3.1-1      \n#&gt;  [4] rlang_1.1.6          magrittr_2.0.3       multcomp_1.4-28     \n#&gt;  [7] snakecase_0.11.1     ggridges_0.5.6       compiler_4.5.1      \n#&gt; [10] vctrs_0.6.5          reshape2_1.4.4       stringr_1.5.1       \n#&gt; [13] pkgconfig_2.0.3      arrayhelpers_1.1-0   fastmap_1.2.0       \n#&gt; [16] backports_1.5.0      labeling_0.4.3       utf8_1.2.6          \n#&gt; [19] rmarkdown_2.29       ps_1.9.1             purrr_1.1.0         \n#&gt; [22] xfun_0.52            cachem_1.1.0         jsonlite_2.0.0      \n#&gt; [25] broom_1.0.9          parallel_4.5.1       R6_2.6.1            \n#&gt; [28] stringi_1.8.7        RColorBrewer_1.1-3   lubridate_1.9.4     \n#&gt; [31] estimability_1.5.1   knitr_1.50           zoo_1.8-14          \n#&gt; [34] pacman_0.5.1         Matrix_1.7-3         splines_4.5.1       \n#&gt; [37] timechange_0.3.0     tidyselect_1.2.1     abind_1.4-8         \n#&gt; [40] yaml_2.3.10          codetools_0.2-20     curl_6.4.0          \n#&gt; [43] processx_3.8.6       pkgbuild_1.4.8       lattice_0.22-7      \n#&gt; [46] plyr_1.8.9           withr_3.0.2          bridgesampling_1.1-2\n#&gt; [49] coda_0.19-4.1        evaluate_1.0.4       survival_3.8-3      \n#&gt; [52] RcppParallel_5.1.10  tensorA_0.36.2.1     checkmate_2.3.2     \n#&gt; [55] stats4_4.5.1         distributional_0.5.0 generics_0.1.4      \n#&gt; [58] rprojroot_2.1.0      rstantools_2.4.0     scales_1.4.0        \n#&gt; [61] xtable_1.8-4         glue_1.8.0           emmeans_1.11.2      \n#&gt; [64] tools_4.5.1          data.table_1.17.8    mvtnorm_1.3-3       \n#&gt; [67] grid_4.5.1           QuickJSR_1.8.0       datawizard_1.2.0    \n#&gt; [70] colorspace_2.1-1     nlme_3.1-168         cli_3.6.5           \n#&gt; [73] svUnit_1.0.6         Brobdingnag_1.2-9    V8_6.0.5            \n#&gt; [76] gtable_0.3.6         digest_0.6.37        TH.data_1.1-3       \n#&gt; [79] htmlwidgets_1.6.4    farver_2.1.2         memoise_2.0.1       \n#&gt; [82] htmltools_0.5.8.1    lifecycle_1.0.4      MASS_7.3-65",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Introduzione pratica a Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_intro.html#bibliografia",
    "href": "chapters/mcmc/03_stan_intro.html#bibliografia",
    "title": "58  Introduzione pratica a Stan",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nNicenboim, B., Schad, D. J., & Vasishth, S. (2025). Introduction to Bayesian data analysis for cognitive science. CRC Press.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Introduzione pratica a Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html",
    "href": "chapters/mcmc/07_bayesian_workflow.html",
    "title": "60  Flusso di lavoro bayesiano",
    "section": "",
    "text": "Introduzione\nFare analisi bayesiana non significa semplicemente applicare la formula di Bayes e ottenere delle stime. Nella pratica della ricerca, serve un approccio più ampio e strutturato: il workflow bayesiano. Si tratta di un processo ciclico che aiuta i ricercatori a passare dall’idea di partenza (una domanda di ricerca) a un modello utile e convincente, capace di generare previsioni plausibili e di guidare le conclusioni.\nImmaginiamo di voler valutare l’efficacia di un nuovo intervento psicologico. Non basta raccogliere i dati e stimare i parametri: bisogna decidere quali variabili considerare, come trattare le differenze tra individui e gruppi, quali assunzioni fare sulle distribuzioni, e come controllare che il modello davvero rifletta la realtà osservata. Tutto questo richiede un percorso iterativo di costruzione, verifica e revisione.\nIn breve: il workflow bayesiano è un metodo per fare ricerca in modo più consapevole e trasparente.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#introduzione",
    "href": "chapters/mcmc/07_bayesian_workflow.html#introduzione",
    "title": "59  Flusso di lavoro bayesiano",
    "section": "",
    "text": "Costruzione iterativa del modello: Definizione e revisione di modelli probabilistici che rappresentano i processi generativi dei dati.\nVerifica e validazione: Controllo della qualità delle stime e valutazione delle capacità predittive del modello.\nRisultati e interpretazione: Confronto tra modelli alternativi per trarre conclusioni solide.\nGestione di problemi computazionali: Identificazione e soluzione di eventuali difficoltà nell’adattamento del modello.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#principi-del-workflow-bayesiano",
    "href": "chapters/mcmc/07_bayesian_workflow.html#principi-del-workflow-bayesiano",
    "title": "59  Flusso di lavoro bayesiano",
    "section": "59.2 Principi del workflow bayesiano",
    "text": "59.2 Principi del workflow bayesiano\nUn workflow è una sequenza strutturata di passi che definisce cosa costituisce una “buona pratica” in un determinato ambito. Nel contesto dell’inferenza bayesiana, il workflow si ispira a concetti come il Ciclo di Box e le più recenti estensioni proposte da studiosi come Gelman e Riha.\n\n59.2.1 Il Ciclo di Box\nGeorge Box, uno dei pionieri della statistica moderna, ha sviluppato negli anni ’60 un approccio ciclico alla modellizzazione statistica, noto come Ciclo di Box. Questo paradigma sottolinea che la modellizzazione non è un processo lineare, ma un ciclo continuo di miglioramento.\n\n\n\nFigura tratta da Blei (2014).\n\n\nIl Ciclo di Box si articola in una serie di fasi iterative:\n\nFormulazione del modello: Si costruisce un modello basato sulle conoscenze disponibili e sui dati osservati.\nInferenza: Si stimano i parametri del modello e si valutano le incertezze associate.\nValutazione del modello: Si verifica quanto il modello si adatta ai dati.\nRevisione del modello: Si corregge il modello in base alle discrepanze identificate.\n\nQuesto approccio iterativo è il cuore del workflow bayesiano. La capacità dell’inferenza bayesiana di aggiornare le credenze a priori alla luce di nuovi dati lo rende particolarmente adatto a essere integrato nel Ciclo di Box. Più recentemente, Gelman & Carpenter (2020) hanno proposto una versione estesa del Ciclo di Box, fornendo una guida dettagliata per implementare un workflow bayesiano completo.\n\n\n\nFigura tratta da Gelman & Carpenter (2020).",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#costruzione-iterativa-del-modello",
    "href": "chapters/mcmc/07_bayesian_workflow.html#costruzione-iterativa-del-modello",
    "title": "59  Flusso di lavoro bayesiano",
    "section": "59.3 Costruzione iterativa del modello",
    "text": "59.3 Costruzione iterativa del modello\nIl processo di costruzione di un modello bayesiano può essere descritto attraverso i seguenti passaggi:\n\nComprensione del fenomeno e formulazione del problema: Il punto di partenza è definire chiaramente la domanda di ricerca. L’obiettivo non è semplicemente descrivere correlazioni tra variabili, ma comprendere i meccanismi generativi dei dati.\nFormulazione matematica: Si costruisce un modello probabilistico che rappresenti il processo generativo, spesso utilizzando linguaggi probabilistici (PPL) come Stan o PyMC.\nImplementazione: Il modello viene tradotto in codice utilizzando interfacce software come R, Python o Julia, che permettono di adattare modelli complessi ai dati.\nVerifiche predittive a priori: Si simulano dati basandosi sulle distribuzioni a priori per verificare che i parametri scelti siano ragionevoli.\nAdattamento del modello: Si utilizza un algoritmo di campionamento per stimare i parametri del modello dai dati osservati (ad esempio, cmdstanr o cmdstanpy).\nDiagnostiche di convergenza: Si verifica che le catene MCMC abbiano raggiunto la convergenza, utilizzando strumenti come il valore R-hat.\nVerifiche predittive a posteriori: Si generano dati simulati a partire dalla distribuzione a posteriori per confrontarli con i dati reali e valutare la bontà del modello.\nIterazione: Sulla base dei risultati, il modello viene raffinato e migliorato.\n\nQuesto processo iterativo consente di costruire modelli che siano sia robusti sia interpretabili.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#analisi-multiverso",
    "href": "chapters/mcmc/07_bayesian_workflow.html#analisi-multiverso",
    "title": "60  Flusso di lavoro bayesiano",
    "section": "60.4 Analisi multiverso",
    "text": "60.4 Analisi multiverso\nUn’estensione recente del workflow bayesiano è l’analisi multiverso [Steegen et al. (2016); Riha et al. (2024)].\nL’idea è semplice: invece di puntare su un unico modello, esploriamo più modelli possibili, ognuno basato su scelte diverse (per esempio, variabili incluse, tipo di distribuzione, forma della relazione).\nI vantaggi sono:\n\nmaggiore trasparenza sulle scelte fatte;\nconfronto diretto tra alternative;\nconclusioni più robuste, perché sappiamo quanto dipendono dalle assunzioni iniziali.\n\nOvviamente, più modelli significano anche più complessità. Per gestirla, sono stati proposti approcci di “filtraggio iterativo”: si parte da molti modelli e, passo dopo passo, si scartano quelli che non funzionano bene, fino a concentrarsi su un insieme ristretto e più solido.\nUn esempio è l’analisi di dati clinici sulle crisi epilettiche (studio di Leppik et al., 1987). In quel caso, decine di modelli sono stati confrontati utilizzando criteri predittivi come l’ELPD (Expected Log Predictive Density). Alcuni modelli si sono rivelati poco plausibili, altri molto più predittivi e stabili. Questo dimostra come l’analisi multiverso possa rendere le conclusioni più affidabili, senza ridursi a una sola scelta arbitraria.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#riflessioni-conclusive",
    "href": "chapters/mcmc/07_bayesian_workflow.html#riflessioni-conclusive",
    "title": "60  Flusso di lavoro bayesiano",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIl workflow bayesiano è un approccio pratico e flessibile per fare ricerca. Non si tratta di una serie di regole rigide, ma di una guida che incoraggia cicli di costruzione, verifica e revisione dei modelli.\nCon strumenti come le verifiche predittive e l’analisi multiverso, i ricercatori possono:\n\nevitare modelli troppo semplici o troppo complicati;\nrendere trasparenti le proprie scelte;\ncostruire inferenze più solide e replicabili.\n\nIn altre parole, il workflow bayesiano aiuta a trasformare la teoria in pratica, accompagnando il ricercatore in tutte le fasi del processo analitico.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#bibliografia",
    "href": "chapters/mcmc/07_bayesian_workflow.html#bibliografia",
    "title": "60  Flusso di lavoro bayesiano",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBlei, D. M. (2014). Build, compute, critique, repeat: Data analysis with latent variable models. Annual Review of Statistics and Its Application, 1(1), 203–232.\n\n\nRiha, A. E., Siccha, N., Oulasvirta, A., & Vehtari, A. (2024). Supporting Bayesian modelling workflows with iterative filtering for multiverse analysis. arXiv preprint arXiv:2404.01688.\n\n\nSteegen, S., Tuerlinckx, F., Gelman, A., & Vanpaemel, W. (2016). Increasing transparency through a multiverse analysis. Perspectives on Psychological Science, 11(5), 702–712.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/introduction_linear_models.html",
    "href": "chapters/linear_models/introduction_linear_models.html",
    "title": "Introduzione",
    "section": "",
    "text": "In questa sezione affronteremo alcuni tra i casi più semplici dell’inferenza statistica, ovvero l’inferenza su una singola media, la differenza tra due medie, e l’analisi del modello di regressione lineare, sia bivariato sia multiplo, con predittori quantitativi e qualitativi.\nTradizionalmente, l’inferenza su una o due medie viene trattata mediante il t-test di Student, nell’ambito dell’approccio frequentista. Tuttavia, in una prospettiva più moderna, questi problemi possono essere ricondotti al modello lineare generale, che fornisce un quadro metodologico unificato. In questa sezione, quindi, presenteremo il modello lineare sia dal punto di vista frequentista sia secondo l’approccio bayesiano, mostrando come l’inferenza su una o due medie rappresenti un caso particolare di questo impianto generale.\nÈ utile, a questo proposito, distinguere tra due tipi di modelli: i modelli fenomenologici e i modelli meccanicistici. I modelli fenomenologici si limitano a descrivere i dati: forniscono un riassunto matematico della relazione osservata tra variabili, senza fare ipotesi esplicite sui processi che generano tali relazioni. I modelli meccanicistici, al contrario, cercano di rappresentare il processo sottostante che ha prodotto i dati, offrendo una spiegazione plausibile dei meccanismi causali in gioco.\nIl modello lineare, e in particolare il modello di regressione, appartiene alla prima categoria: è un modello fenomenologico, descrittivo. La sua enorme diffusione in psicologia è legata, almeno in parte, al successo dell’approccio frequentista, che imposta la questione inferenziale in termini dicotomici: “c’è evidenza di un’associazione tra variabili, oppure no?”, alla luce di un’ipotesi nulla che assume l’assenza di associazione nella popolazione.\nTuttavia, abbiamo già osservato come questa domanda, in sé, abbia una portata scientifica limitata. Sappiamo, in linea generale, che tutto è correlato con tutto il resto. La domanda rilevante, quindi, non è se esista un’associazione, ma quanto forte sia tale associazione. E anche quando stimiamo la forza dell’associazione, questo non ci dice ancora nulla sui meccanismi che l’hanno generata. Una descrizione accurata può essere utile, ma non è sufficiente per spiegare il fenomeno osservato.\nPurtroppo, la maggior parte dei modelli quantitativi in psicologia è di tipo fenomenologico, probabilmente a causa della predominanza dell’approccio frequentista e della sua enfasi sull’associazione statistica come obiettivo esplicativo. Questo rappresenta un limite per lo sviluppo teorico della disciplina. Esistono però anche modelli meccanicistici in psicologia – ne vedremo un esempio concreto nella sezione dedicata alla modellazione dinamica – che si propongono di simulare i processi cognitivi o affettivi sottostanti.\nIn questa sezione ci concentreremo dunque sul modello di regressione, consapevoli che si tratta di un modello descrittivo, non esplicativo. Non lo facciamo perché sia particolarmente importante dal punto di vista scientifico, ma perché è onnipresente nella pratica della ricerca psicologica. L’aspetto innovativo della trattazione che segue sarà l’adozione di una prospettiva bayesiana, che ci permette di reinterpretare l’inferenza statistica in termini di incertezza soggettiva, confronto tra modelli e plausibilità delle ipotesi, offrendo strumenti concettuali e computazionali più coerenti con un approccio scientifico maturo.",
    "crumbs": [
      "Regressione",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html",
    "href": "chapters/linear_models/01_reglin_frequentist.html",
    "title": "60  La regressione lineare bivariata",
    "section": "",
    "text": "Introduzione\nLa regressione lineare è uno degli strumenti statistici più utilizzati per modellare le relazioni tra variabili quantitative. In termini semplici, ci permette di descrivere cosa accade, in media, a una variabile (detta variabile dipendente, indicata con \\(Y\\)) quando un’altra variabile (detta variabile indipendente, indicata con \\(X\\)) cambia, assumendo che nei dati esista una certa variabilità residua.\nIn psicologia, la regressione è ampiamente impiegata per:\nTuttavia, per poterla usare in modo efficace e critico, è necessario comprenderne bene le assunzioni e i limiti.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>La regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#introduzione",
    "href": "chapters/linear_models/01_reglin_frequentist.html#introduzione",
    "title": "60  La regressione lineare bivariata",
    "section": "",
    "text": "esplorare relazioni tra costrutti psicologici,\n\nformulare previsioni di comportamenti o esiti,\n\ntestare ipotesi su meccanismi sottostanti i processi cognitivi, emotivi o sociali.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>La regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#la-relazione-tra-x-e-y",
    "href": "chapters/linear_models/01_reglin_frequentist.html#la-relazione-tra-x-e-y",
    "title": "60  La regressione lineare bivariata",
    "section": "\n60.1 La relazione tra \\(X\\) e \\(Y\\)\n",
    "text": "60.1 La relazione tra \\(X\\) e \\(Y\\)\n\nIl caso più semplice è il modello di regressione lineare bivariato, che descrive la relazione tra due variabili. L’idea di base è che, se \\(X\\) e \\(Y\\) sono associate, possiamo approssimare la loro relazione con una retta che indica come \\(Y\\) tende a variare al variare di \\(X\\).\nLa formulazione classica (frequentista) del modello è:\n\\[\ny_i = a + b x_i + e_i, \\quad i = 1, \\dots, n,\n\\]\ndove:\n\n\n\\(a\\) (intercetta): valore atteso di \\(Y\\) quando \\(X = 0\\),\n\n\\(b\\) (pendenza): variazione attesa di \\(Y\\) per ogni unità di aumento in \\(X\\),\n\n\\(e_i\\) (errore residuo): differenza tra il valore osservato \\(y_i\\) e il valore previsto dal modello.\n\nGraficamente, questa equazione corrisponde a una retta di regressione che rappresenta la miglior approssimazione lineare dei dati secondo il criterio dei minimi quadrati. Nella realtà, i punti raramente giacciono tutti sulla retta: le differenze sono catturate dagli errori residui.\nLa regressione, quindi, non predice esattamente ogni osservazione, ma descrive la tendenza media nella popolazione. Ad esempio, se \\(b = 2\\), significa che — in media — un aumento di 1 unità in \\(X\\) è associato a un aumento di 2 unità in \\(Y\\). Ciò non implica che ogni caso segua la regola in modo perfetto, ma che l’andamento complessivo sia coerente con questa relazione.\nL’obiettivo dell’analisi è stimare i parametri \\(a\\), \\(b\\) e \\(\\sigma^2\\) (varianza residua) dai dati, utilizzando il metodo dei minimi quadrati (OLS) o, più in generale, il principio di massima verosimiglianza. Nel paradigma frequentista, questi parametri sono considerati quantità fisse ma sconosciute, e l’incertezza riguarda esclusivamente gli errori di misura o variabilità non spiegata.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>La regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#a-cosa-serve-la-regressione",
    "href": "chapters/linear_models/01_reglin_frequentist.html#a-cosa-serve-la-regressione",
    "title": "60  La regressione lineare bivariata",
    "section": "\n60.2 A cosa serve la regressione?",
    "text": "60.2 A cosa serve la regressione?\nSecondo Gelman et al. (2021), la regressione lineare può essere applicata in almeno quattro contesti principali:\n\n\nPrevisione – Stimare valori futuri di una variabile di interesse o classificare casi in base a probabilità.\n\n\nEsempi: prevedere punteggi futuri a un test; monitorare il benessere psicologico in studi longitudinali; classificare individui in base alla probabilità di successo in un compito cognitivo.\n\n\n\nEsplorazione delle associazioni – Identificare e quantificare le relazioni tra predittori e risultato.\n\n\nEsempi: analizzare i tratti di personalità legati alla resilienza allo stress; studiare la relazione tra stili di attaccamento infantile e competenze relazionali adulte; valutare l’effetto di fattori socio-economici sullo sviluppo cognitivo.\n\n\n\nEstrapolazione – Estendere i risultati a contesti o popolazioni non direttamente osservati.\n\n\nEsempi: stimare l’efficacia di una terapia testata su studenti universitari nella popolazione generale; prevedere l’impatto di un intervento scolastico su un intero distretto a partire da dati di scuole pilota.\n\n\n\nInferenza causale – Stimare effetti di trattamenti o interventi, solo se supportata da un disegno di ricerca adeguato (ad es., randomizzazione).\n\n\nEsempi: valutare l’efficacia di un programma di mindfulness sull’ansia; stimare l’impatto di una psicoterapia sul disturbo post-traumatico da stress; determinare l’effetto di un intervento educativo su una popolazione diversificata.\n\n\n\nNota importante: in tutti i contesti, il modello deve includere tutte le variabili rilevanti per il fenomeno studiato. L’omissione di variabili confondenti può distorcere le stime — problema noto come errore di specificazione del modello. Ad esempio, in uno studio sull’efficacia di una psicoterapia per la depressione, fattori come età, condizioni di salute preesistenti e supporto sociale devono essere inclusi nell’analisi per evitare interpretazioni fuorvianti.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>La regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#tipologie-di-regressione",
    "href": "chapters/linear_models/01_reglin_frequentist.html#tipologie-di-regressione",
    "title": "60  La regressione lineare bivariata",
    "section": "\n60.3 Tipologie di regressione",
    "text": "60.3 Tipologie di regressione\nPossiamo distinguere tre livelli di complessità:\n\n\nRegressione bivariata – Un solo predittore e un solo esito.\n\nRegressione multipla – Un solo esito e molteplici predittori.\n\nRegressione multivariata – Più esiti simultaneamente, con uno o più predittori.\n\nIl caso bivariato, pur essendo il più semplice, è un punto di partenza fondamentale: permette di acquisire la logica di base della regressione senza complicazioni matematiche eccessive. Una volta compresi i concetti fondamentali, questi possono essere estesi a modelli più complessi, in cui l’interpretazione dei parametri richiede maggiore attenzione e i calcoli diventano più articolati.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>La regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#la-predizione-dellintelligenza",
    "href": "chapters/linear_models/01_reglin_frequentist.html#la-predizione-dellintelligenza",
    "title": "60  La regressione lineare bivariata",
    "section": "\n60.4 La predizione dell’intelligenza",
    "text": "60.4 La predizione dell’intelligenza\nPer illustrare il modello di regressione secondo l’approccio frequentista, utilizzeremo un dataset reale: i dati kidiq tratti dal National Longitudinal Survey of Youth (Gelman et al., 2021). Questi dati riguardano un campione di donne americane e i loro figli, con particolare attenzione a due variabili fondamentali per la nostra analisi: il punteggio cognitivo del bambino (kid_score) e il quoziente intellettivo della madre (mom_iq). L’obiettivo principale consiste nell’esaminare se - e in che misura - l’intelligenza materna possa essere considerata un fattore predittivo delle capacità cognitive del bambino.\n\n60.4.1 Esplorazione dei dati\nImportiamo i dati in R:\n\nkidiq &lt;- rio::import(here::here(\"data\", \"kidiq.dta\"))\n\n\nhead(kidiq)\n#&gt;   kid_score mom_hs mom_iq mom_work mom_age\n#&gt; 1        65      1 121.12        4      27\n#&gt; 2        98      1  89.36        4      25\n#&gt; 3        85      1 115.44        4      27\n#&gt; 4        83      1  99.45        3      25\n#&gt; 5       115      1  92.75        4      27\n#&gt; 6        98      0 107.90        1      18\n\nUn diagramma a dispersione per i dati di questo campione suggerisce la presenza di un’associazione positiva tra l’intelligenza del bambino (kid_score) e l’intelligenza della madre (mom_iq).\n\nggplot(kidiq, aes(x = mom_iq, y = kid_score)) +\n  geom_point(alpha = 0.6) +\n  labs(x = \"QI della madre\", y = \"QI del bambino\") +\n  ggtitle(\"Diagramma a dispersione\")\n\n\n\n\n\n\n\n\n60.4.2 Stima del modello di regressione\nCalcoliamo i coefficienti della retta di regressione utilizzando la funzione lm.\n\n# Modello di regressione lineare\nmod &lt;- lm(kid_score ~ mom_iq, data = kidiq)\n\n\n# Coefficienti stimati\ncoef(mod)\n#&gt; (Intercept)      mom_iq \n#&gt;       25.80        0.61\n\nIn generale, molte rette possono approssimare la nube di punti, ma il modello di regressione impone vincoli:\n\nla retta deve passare per il punto medio \\((\\bar{x}, \\bar{y})\\);\ndeve minimizzare la somma dei quadrati dei residui (SSE).\n\n\n# Calcola le medie per mom_iq e kid_score\nmean_x &lt;- mean(kidiq$mom_iq, na.rm = TRUE)\nmean_y &lt;- mean(kidiq$kid_score, na.rm = TRUE)\n\n# Aggiungi il punto medio al grafico\nggplot(kidiq, aes(x = mom_iq, y = kid_score)) +\n  geom_point(alpha = 0.6) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"blue\") +\n  annotate(\n    \"point\", x = mean_x, y = mean_y, color = \"red\", size = 5, \n    shape = 4, stroke = 3) +\n  labs(x = \"QI della madre\", y = \"QI del bambino\") +\n  ggtitle(\"Retta di regressione\")",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>La regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#il-modello-teorico",
    "href": "chapters/linear_models/01_reglin_frequentist.html#il-modello-teorico",
    "title": "60  La regressione lineare bivariata",
    "section": "\n60.5 Il modello teorico",
    "text": "60.5 Il modello teorico\nIl modello di regressione lineare bivariata è:\n\\[\ny_i = a + b x_i + e_i, \\quad i = 1, \\dots, n\n\\]\ndove:\n\n\n\\(a\\): intercetta (valore atteso di \\(y\\) quando \\(x = 0\\));\n\n\\(b\\): pendenza (variazione attesa di \\(y\\) per +1 in \\(x\\));\n\n\\(e_i\\): errore residuo (scarto tra osservato e predetto).\n\nNel nostro caso:\n\n\n\\(y = \\text{`kid\\_score`}\\) (QI del bambino)\n\n\\(x = \\text{`mom\\_iq`}\\) (QI della madre)\n\nLa componente deterministica \\(\\hat{y}_i = a + b x_i\\) rappresenta la parte prevedibile di \\(y\\) in funzione di \\(x\\). La componente aleatoria \\(e_i = y_i - \\hat{y}_i\\) cattura ciò che il modello non spiega.\n\n\n\n\n\n\nIllustrazione\n\n\n\n\n\nIl campione è costituito da \\(n\\) coppie di osservazioni (\\(x, y\\)).\n\\[\n\\begin{array}{cc}\n\\hline\nx_1 & y_1 \\\\\nx_2 & y_2 \\\\\nx_3 & y_3 \\\\\n\\vdots & \\vdots \\\\\nx_n & y_n \\\\\n\\hline\n\\end{array}\n\\]\nPer ciascuna coppia di valori \\(x_i, y_i\\), il modello di regressione si aspetta che il valore \\(y_i\\) sia associato al corrispondente valore \\(x_i\\) come indicato dalla seguente equazione\n\\[\n\\mathbb{E}(y_i) = a + b x_i ,\n\\tag{60.1}\\]\novvero:\n\\[\n\\begin{array}{ccc}\n\\hline\nx_i & y_i & \\mathbb{E}(y_i) = a + b x_i \\\\\n\\hline\nx_1 & y_1 & a + b x_1 \\\\\nx_2 & y_2 & a + b x_2 \\\\\nx_3 & y_3 & a + b x_3 \\\\\n\\vdots & \\vdots & \\vdots \\\\\nx_n & y_n & a + b x_n \\\\\n\\hline\n\\end{array}\n\\]\nI valori \\(y_i\\) corrispondono, nell’esempio che stiamo discutendo, alla variabile kid_score. I primi 10 valori della variabile \\(y\\) sono i seguenti:\n\nkidiq$kid_score[0:10]\n#&gt;  [1]  65  98  85  83 115  98  69 106 102  95\n\nPer fare riferimento a ciascuna osservazione usiamo l’indice \\(i\\). Quindi, ad esempio, \\(y_2\\) è uguale a\n\nkidiq$kid_score[2]\n#&gt; [1] 98\n\n\n\n\n\n60.5.1 Stima manuale dei coefficienti\nLe formule OLS sono:\n\\[\nb = \\frac{\\text{Cov}(x,y)}{\\text{Var}(x)}, \\quad a = \\bar{y} - b \\bar{x}.\n\\]\nCalcolo in R:\n\ncov_xy &lt;- cov(kidiq$kid_score, kidiq$mom_iq)\nvar_x  &lt;- var(kidiq$mom_iq)\nb &lt;- cov_xy / var_x\na &lt;- mean(kidiq$kid_score) - b * mean(kidiq$mom_iq)\na; b\n#&gt; [1] 25.8\n#&gt; [1] 0.61\n\n\n60.5.1.1 Interpretazione\n\n\nIntercetta \\(a\\): valore previsto di kid_score quando mom_iq = 0. In questo contesto ha scarso significato pratico (QI = 0 è irrealistico).\n\nPendenza \\(b\\): aumento medio in kid_score per ogni punto in più in mom_iq. Qui, \\(b \\approx 0.61\\): +1 punto di QI materno è associato, in media, a +0.61 punti nel figlio.\n\n60.5.2 Residui\nIl residuo per l’osservazione \\(i\\) è:\n\\[\n  e_i = y_i - (a + b x_i).\n\\]\novvero la differenza tra il valore osservato di \\(y\\) e il valore previsto dal modello, \\(\\hat{y}\\). La dimensione del residuo indica quanto la componente aleatoria contribuisce al valore osservato di \\(y\\).\nIn R:\n\nres &lt;- kidiq$kid_score - (a + b * kidiq$mom_iq)\nsum(res)  # ≈ 0 per costruzione OLS\n#&gt; [1] 1.444e-11\n\nQuesta proprietà (somma dei residui = 0) deriva dall’ottimizzazione OLS.\n\n60.5.3 Centrare le variabili\nCentrando \\(x\\) attorno alla sua media otteniamo un’intercetta interpretabile: il valore medio di kid_score quando mom_iq è nella media del campione.\n\nkidiq &lt;- kidiq %&gt;%\n  mutate(xd = mom_iq - mean(mom_iq))\n\nIl coefficiente \\(b\\) rimane invariato; cambia solo l’intercetta.\n\nmod1 &lt;- lm(kid_score ~ xd, data = kidiq)\ncoef(mod1)\n#&gt; (Intercept)          xd \n#&gt;       86.80        0.61\n\nHo individuato una sezione che può essere resa più chiara e compatta: quella in cui spieghi il metodo dei minimi quadrati e le formule di stima di a e b. Attualmente il testo ripete più volte le stesse definizioni (es. passaggio per il baricentro, minimizzazione SSE) e alterna spiegazioni concettuali e procedurali senza una sequenza ben definita.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>La regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#metodo-dei-minimi-quadrati-principi-e-formule",
    "href": "chapters/linear_models/01_reglin_frequentist.html#metodo-dei-minimi-quadrati-principi-e-formule",
    "title": "60  La regressione lineare bivariata",
    "section": "\n60.6 Metodo dei minimi quadrati: principi e formule",
    "text": "60.6 Metodo dei minimi quadrati: principi e formule\nNel modello di regressione bivariata, i coefficienti \\(a\\) (intercetta) e \\(b\\) (pendenza) vengono stimati scegliendo la retta che minimizza la somma dei quadrati dei residui (Sum of Squared Errors, SSE):\n\\[\ne_i = y_i - (a + b x_i), \\quad SSE = \\sum_{i=1}^n e_i^2.\n\\]\nQuesta scelta equivale, sotto l’assunzione di errori normali con media zero e varianza costante, alla stima di massima verosimiglianza.\nLa minimizzazione dell’SSE porta alle equazioni normali, la cui soluzione ha forma chiusa:\n\\[\nb = \\frac{\\mathrm{Cov}(x, y)}{\\mathrm{Var}(x)}, \\quad a = \\bar{y} - b \\,\\bar{x} ,\n\\]\ndove:\n\n\n\\(\\bar{x}\\) e \\(\\bar{y}\\) sono le medie campionarie;\n\n\\(\\mathrm{Cov}(x,y)\\) è la covarianza tra \\(x\\) e \\(y\\);\n\n\\(\\mathrm{Var}(x)\\) è la varianza di \\(x\\).\n\nQueste formule assicurano che:\n\nLa retta passa per il punto medio \\((\\bar{x}, \\bar{y})\\) della nube di punti.\nLa pendenza \\(b\\) quantifica la variazione media di \\(y\\) per un’unità di incremento di \\(x\\).\nL’intercetta \\(a\\) è il valore previsto di \\(y\\) quando \\(x=0\\) (interpretazione utile solo se \\(x=0\\) è significativo).\n\nEsempio in R:\n\ncov_xy &lt;- cov(kidiq$kid_score, kidiq$mom_iq)\nvar_x  &lt;- var(kidiq$mom_iq)\nb &lt;- cov_xy / var_x\na &lt;- mean(kidiq$kid_score) - b * mean(kidiq$mom_iq)\nc(intercetta = a, pendenza = b)\n#&gt; intercetta   pendenza \n#&gt;      25.80       0.61\n\nI risultati replicano quelli ottenuti in precedenza con lm().\n\n60.6.1 Interpretazione\nIl coefficiente \\(a\\) indica l’intercetta della retta di regressione nel diagramma a dispersione. Questo valore rappresenta il punto in cui la retta di regressione interseca l’asse \\(y\\) del sistema di assi cartesiani. Tuttavia, in questo caso specifico, il valore di \\(a\\) non è di particolare interesse poiché corrisponde al valore della retta di regressione quando l’intelligenza della madre è pari a 0, il che non ha senso nella situazione reale. Successivamente, vedremo come è possibile trasformare i dati per fornire un’interpretazione utile del coefficiente \\(a\\).\nInvece, il coefficiente \\(b\\) indica la pendenza della retta di regressione, ovvero di quanto aumenta (se \\(b\\) è positivo) o diminuisce (se \\(b\\) è negativo) la retta di regressione in corrispondenza di un aumento di 1 punto della variabile \\(x\\). Nel caso specifico del QI delle madri e dei loro figli, il coefficiente \\(b\\) ci indica che un aumento di 1 punto del QI delle madri è associato, in media, a un aumento di 0.61 punti del QI dei loro figli.\nIn pratica, il modello di regressione lineare cerca di prevedere le medie dei punteggi del QI dei figli in base al QI delle madri. Ciò significa che non è in grado di prevedere esattamente il punteggio di ciascun bambino in funzione del QI della madre, ma solo una stima della media dei punteggi dei figli quando il QI delle madri aumenta o diminuisce di un punto.\nIl coefficiente \\(b\\) ci dice di quanto aumenta (o diminuisce) in media il QI dei figli per ogni unità di aumento (o diminuzione) del QI della madre. Nel nostro caso, se il QI della madre aumenta di un punto, il QI dei figli aumenta in media di 0.61 punti.\nÈ importante comprendere che il modello statistico di regressione lineare non è in grado di prevedere il valore preciso di ogni singolo bambino, ma solo una stima della media dei punteggi del QI dei figli quando il QI delle madri aumenta o diminuisce. Questa stima è basata su una distribuzione di valori possibili che si chiama distribuzione condizionata \\(p(y \\mid x_i)\\).\nUna rappresentazione grafica del valore predetto dal modello di regressione, \\(\\hat{y}_i = a + bx_i\\) è stato fornito in precedenza. Il diagramma presenta ciascun valore \\(\\hat{y}_i = a + b x_i\\) in funzione di \\(x_i\\). I valori predetti dal modello di regressione sono i punti che stanno sulla retta di regressione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>La regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#residui-1",
    "href": "chapters/linear_models/01_reglin_frequentist.html#residui-1",
    "title": "60  La regressione lineare bivariata",
    "section": "\n60.7 Residui",
    "text": "60.7 Residui\nIn precedenza abbiamo detto che il residuo, ovvero la componente di ciascuna osservazione \\(y_i\\) che non viene predetta dal modello di regressione, corrisponde alla distanza verticale tra il valore \\(y_i\\) osservato e il valore \\(\\hat{y}_i\\) predetto dal modello di regressione:\n\\[\ne_i = y_i - (a + b x_i).\n\\]\nPer fare un esempio numerico, consideriamo il punteggio osservato del QI del primo bambino.\n\nkidiq$kid_score[1]\n#&gt; [1] 65\n\nIl QI della madre è\n\nkidiq$mom_iq[1]\n#&gt; [1] 121.1\n\nPer questo bambino, il valore predetto dal modello di regressione è\n\na + b * kidiq$mom_iq[1]\n#&gt; [1] 99.68\n\nL’errore che compiamo per predire il QI del bambino utilizzando il modello di regressione (ovvero, il residuo) è\n\nkidiq$kid_score[1] - (a + b * kidiq$mom_iq[1])\n#&gt; [1] -34.68\n\nPer tutte le osservazioni abbiamo\n\nres &lt;- kidiq$kid_score - (a + b * kidiq$mom_iq)\n\nÈ una proprietà del modello di regressione (calcolato con il metodo dei minimi quadrati) che la somma dei residui sia uguale a zero.\n\nsum(res)\n#&gt; [1] 1.444e-11\n\nQuesto significa che ogni valore osservato \\(y_i\\) viene scomposto dal modello di regressione in due componenti distinte. La componente deterministica \\(\\hat{y}_i\\), che è predicibile da \\(x_i\\), è data da \\(\\hat{y}_i = a + b x_i\\). Il residuo, invece, è dato da \\(e_i = y_i - \\hat{y}_i\\). La somma di queste due componenti, ovviamente, riproduce il valore osservato.\n\n# Creazione di un data frame con i valori calcolati\ndf &lt;- data.frame(\n  kid_score = kidiq$kid_score,\n  mom_iq = kidiq$mom_iq,\n  y_hat = a + b * kidiq$mom_iq,\n  e = kidiq$kid_score - (a + b * kidiq$mom_iq),\n  y_hat_plus_e = (a + b * kidiq$mom_iq) + (kidiq$kid_score - (a + b * kidiq$mom_iq))\n)\n\n# Visualizzazione dei primi 6 valori\nhead(df)\n#&gt;   kid_score mom_iq y_hat       e y_hat_plus_e\n#&gt; 1        65 121.12 99.68 -34.678           65\n#&gt; 2        98  89.36 80.31  17.692           98\n#&gt; 3        85 115.44 96.22 -11.217           85\n#&gt; 4        83  99.45 86.46  -3.462           83\n#&gt; 5       115  92.75 82.37  32.628          115\n#&gt; 6        98 107.90 91.62   6.383           98",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>La regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#trasformazione-dei-dati",
    "href": "chapters/linear_models/01_reglin_frequentist.html#trasformazione-dei-dati",
    "title": "60  La regressione lineare bivariata",
    "section": "\n60.8 Trasformazione dei dati",
    "text": "60.8 Trasformazione dei dati\nIn generale, per variabili a livello di scala ad intervalli, l’intercetta del modello di regressione lineare non ha un’interpretazione utile. Questo perché l’intercetta indica il valore atteso di \\(y\\) quando \\(x = 0\\), ma in caso di variabili a scala di intervalli, il valore “0” di \\(x\\) è arbitrario e non corrisponde ad un “assenza” della variabile \\(x\\). Ad esempio, un QI della madre pari a 0 non indica un’assenza di intelligenza, ma solo un valore arbitrario del test usato per misurare il QI. Quindi, sapere il valore medio del QI dei bambini quando il QI della madre è 0 non è di alcun interesse.\nPer fornire all’intercetta del modello di regressione un’interpretazione più utile, dobbiamo trasformare le osservazioni di \\(x\\). Per esempio, esprimiamo \\(x\\) come differenza dalla media. Chiamiamo questa nuova variabile \\(xd\\):\n\nkidiq$xd &lt;- kidiq$mom_iq - mean(kidiq$mom_iq)\n\nkidiq |&gt; \n  head()\n#&gt;   kid_score mom_hs mom_iq mom_work mom_age       xd\n#&gt; 1        65      1 121.12        4      27  21.1175\n#&gt; 2        98      1  89.36        4      25 -10.6381\n#&gt; 3        85      1 115.44        4      27  15.4432\n#&gt; 4        83      1  99.45        3      25  -0.5504\n#&gt; 5       115      1  92.75        4      27  -7.2543\n#&gt; 6        98      0 107.90        1      18   7.9018\n\nSe ora usiamo le coppie di osservazioni \\((xd_i, y_i)\\), il diagramma a dispersione assume la forma seguente.\n\n# Aggiungiamo una nuova variabile centrata (scarti dalla media)\nkidiq &lt;- kidiq %&gt;%\n  mutate(xd = mom_iq - mean(mom_iq))\n\n# Calcolo della retta di regressione\nb &lt;- cov(kidiq$xd, kidiq$kid_score) / var(kidiq$xd)\na &lt;- mean(kidiq$kid_score) - b * mean(kidiq$xd)\n\n# Grafico con ggplot2\nggplot(kidiq, aes(x = xd, y = kid_score)) +\n  geom_point(alpha = 0.6) +  # Punti del grafico\n  geom_abline(intercept = a, slope = b, color = \"blue\") +  # Retta di regressione\n  labs(\n    x = \"QI della madre (scarti dalla media)\", \n    y = \"QI del bambino\"\n  ) +\n  ggtitle(\"Retta di regressione sui dati centrati\")\n\n\n\n\n\n\n\nIn pratica, abbiamo spostato tutti i punti del grafico lungo l’asse delle \\(x\\), in modo tale che la media dei valori di \\(x\\) sia uguale a 0. Questo non ha cambiato la forma dei punti nel grafico, ma ha solo spostato l’origine dell’asse \\(x\\). La pendenza della linea di regressione tra \\(x\\) e \\(y\\) rimane la stessa, sia per i dati originali che per quelli trasformati. L’unica cosa che cambia è il valore dell’intercetta della linea di regressione, che ora ha un’interpretazione più significativa.\n\nfm1 &lt;- lm(kid_score ~ xd, data = kidiq)\ncoef(fm1)\n#&gt; (Intercept)          xd \n#&gt;       86.80        0.61\n\nL’intercetta rappresenta il punto in cui la retta di regressione incontra l’asse \\(y\\) nel diagramma a dispersione. Nel caso dei dati trasformati, abbiamo spostato la nube di punti lungo l’asse \\(x\\) di una quantità pari a \\(x - \\bar{x}\\), ma le relazioni spaziali tra i punti rimangono invariate. Pertanto, la pendenza della retta di regressione non cambia rispetto ai dati non trasformati. Tuttavia, il valore dell’intercetta viene influenzato dalla trasformazione. In particolare, poiché \\(xd = 0\\) corrisponde a \\(x = \\bar{x}\\) nei dati grezzi, l’intercetta del modello di regressione lineare calcolata sui dati trasformati corrisponde al valore atteso di \\(y\\) quando \\(x\\) assume il valore medio sulla scala dei dati grezzi. In altre parole, l’intercetta del modello di regressione lineare sui dati trasformati rappresenta il valore atteso del QI dei bambini corrispondente al QI medio delle madri.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>La regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#illustrazione-del-metodo-dei-minimi-quadrati",
    "href": "chapters/linear_models/01_reglin_frequentist.html#illustrazione-del-metodo-dei-minimi-quadrati",
    "title": "60  La regressione lineare bivariata",
    "section": "\n60.9 Illustrazione del metodo dei minimi quadrati",
    "text": "60.9 Illustrazione del metodo dei minimi quadrati\nPer stimare i coefficienti \\(a\\) e \\(b\\), possiamo minimizzare la somma dei quadrati dei residui tra i valori osservati \\(y_i\\) e quelli previsti \\(a + b x_i\\).\nIniziamo con il creare una griglia per i valori di \\(b\\). Supponiamo che il valore di \\(a\\) sia noto (\\(a = 25.79978\\)). Usiamo R per creare una griglia di valori possibili per \\(b\\).\n\n# Griglia di valori per b\nb_grid &lt;- seq(0, 1, length.out = 1001)\na &lt;- 25.79978  # Intercetta nota\n\nDefiniamo ora una funzione che calcola la somma dei quadrati dei residui (\\(SSE\\)) per ciascun valore di \\(b\\).\n\n# Funzione per la somma dei quadrati dei residui\nsse &lt;- function(a, b, x, y) {\n  sum((y - (a + b * x))^2)\n}\n\nApplichiamo la funzione sse alla griglia di valori \\(b\\) per calcolare la somma dei quadrati dei residui per ogni valore di \\(b\\).\n\n# Calcolo di SSE per ciascun valore di b\nsse_vals &lt;- sapply(\n  b_grid, \n  function(b) sse(a, b, kidiq$mom_iq, kidiq$kid_score)\n)\n\n\n\nsapply:\n\nÈ una funzione di R che applica una funzione ad ogni elemento di un vettore (o lista) e restituisce i risultati in un vettore.\nQui, applica la funzione sse a ciascun valore di \\(b\\) contenuto in b_grid.\n\n\n\nfunction(b):\n\nÈ una funzione anonima definita al volo per specificare come calcolare \\(SSE\\) per ciascun valore di \\(b\\).\nAll’interno, viene chiamata la funzione sse(a, b, x, y) con i seguenti parametri:\n\n\na: il valore dell’intercetta (fissato in precedenza o noto).\n\nb: il valore corrente nella griglia b_grid.\n\nx: la variabile indipendente del dataset (kidiq$mom_iq).\n\ny: la variabile dipendente del dataset (kidiq$kid_score).\n\n\n\n\nIl risultato è un vettore, sse_vals, che contiene i valori di \\(SSE\\) corrispondenti a ciascun valore di \\(b\\) in b_grid.\n\nTracciamo un grafico che mostra la somma dei quadrati dei residui (\\(SSE\\)) in funzione dei valori di \\(b\\), evidenziando il minimo.\n\n# Identificazione del valore di b che minimizza SSE\nb_min &lt;- b_grid[which.min(sse_vals)]\n\n# Creazione del dataframe per ggplot\ndat &lt;- data.frame(b_grid = b_grid, sse_vals = sse_vals)\n\n# Genera il grafico\nggplot(dat, aes(x = b_grid, y = sse_vals)) +\n  geom_line(color = \"blue\", linewidth = 1) +  \n  annotate(\n    \"point\", x = b_min, y = min(sse_vals),\n    color = \"red\", size = 3\n  ) +  # Punto minimo\n  labs(\n    x = expression(paste(\"Possibili valori di \", hat(beta))),\n    y = \"Somma dei quadrati dei residui\",\n    title = \"Minimizzazione dei residui quadratici\"\n  ) +\n  annotate(\n    \"text\", x = b_min, y = min(sse_vals), \n    label = expression(hat(beta)), color = \"red\", vjust = -1, hjust = 0.5\n  )\n\n\n\n\n\n\n\nInfine, identifichiamo il valore di \\(b\\) che minimizza la somma dei quadrati dei residui.\n\nb_min\n#&gt; [1] 0.61\n\nCon questa simulazione, abbiamo stimato il coefficiente \\(b\\) minimizzando la somma dei quadrati dei residui.\nQuesto approccio può essere esteso per stimare simultaneamente entrambi i coefficienti (\\(a\\) e \\(b\\)) utilizzando metodi di ottimizzazione più avanzati, come optim in R.\n\noptim_result &lt;- optim(\n  par = c(a = 25, b = 0.5),  # Valori iniziali\n  fn = function(params) {\n    a &lt;- params[1]\n    b &lt;- params[2]\n    sse(a, b, kidiq$mom_iq, kidiq$kid_score)\n  }\n)\n\n# Coefficienti stimati\noptim_result$par\n#&gt;       a       b \n#&gt; 25.7874  0.6101\n\nQuesta simulazione illustra come, tramite il metodo dei minimi quadrati, sia possibile stimare i parametri di un modello bivariato di regressione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>La regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#lerrore-standard-della-regressione",
    "href": "chapters/linear_models/01_reglin_frequentist.html#lerrore-standard-della-regressione",
    "title": "60  La regressione lineare bivariata",
    "section": "\n60.10 L’errore standard della regressione",
    "text": "60.10 L’errore standard della regressione\nL’errore standard della stima \\(s_e\\) misura la deviazione media dei dati dalla retta:\n\\[\n\\sqrt{\\frac{1}{n-2} \\sum_{i=1}^n \\big(y_i - (\\hat{a} + \\hat{b}x_i)\\big)^2},\n\\tag{60.2}\\]\nL’indice \\(s_e\\) possiede la stessa unità di misura di \\(y\\) ed è una stima della deviazione standard dei residui nella popolazione.\nIn R:\n\n# Calcolo dei residui\ne &lt;- kidiq$kid_score - (a + b * kidiq$mom_iq)\n\n# Mostriamo i primi 10 residui\nhead(e, 10)\n#&gt;  [1] -34.678  17.692 -11.217  -3.462  32.628   6.383 -41.521   3.865  26.414\n#&gt; [10]  11.208\n\nCalcoliamo il valore medio assoluto dei residui per avere un’indicazione della deviazione media rispetto alla retta di regressione.\n\n# Media assoluta dei residui\nmean(abs(e))\n#&gt; [1] 14.47\n\nL’errore standard della stima \\(s_e\\) si calcola come la radice quadrata della somma dei quadrati dei residui divisa per \\(n-2\\):\n\n# Calcolo di s_e\nse &lt;- sqrt(sum(e^2) / (length(e) - 2))\nse\n#&gt; [1] 18.27\n\nNotiamo che il valore medio assoluto dei residui e l’errore standard \\(s_e\\) non sono identici, ma hanno lo stesso ordine di grandezza. \\(s_e\\) è una misura più rigorosa della deviazione standard dei residui.\nQuesta analisi dimostra come \\(s_e\\) consenta di valutare quanto le previsioni del modello si discostino (in media) dai dati osservati.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>La regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#valutare-la-bontà-del-modello",
    "href": "chapters/linear_models/01_reglin_frequentist.html#valutare-la-bontà-del-modello",
    "title": "60  La regressione lineare bivariata",
    "section": "\n60.11 Valutare la bontà del modello",
    "text": "60.11 Valutare la bontà del modello\nNell’approccio frequentista, la qualità dell’adattamento si apprezza osservando l’indice di determinazione \\(R^2\\), che indica quanta parte della varianza di \\(y\\) viene spiegata dal modello, e analizzando i residui: eventuali pattern sistematici nei residui possono segnalare che la struttura scelta non coglie tutte le caratteristiche dei dati o che esistono violazioni delle ipotesi (linearità, omoscedasticità, normalità degli errori). Un esame congiunto di \\(R^2\\) e residui aiuta a diagnosticare e, se necessario, migliorare il modello.\nL’indice di determinazione viene calcolato utilizzando un’importante proprietà del modello di regressione, ovvero la scomposizione della varianza della variabile dipendente \\(y\\) in due componenti: la varianza spiegata dal modello e la varianza residua.\nPer una generica osservazione \\(x_i, y_i\\), la deviazione di \\(y_i\\) rispetto alla media \\(\\bar{y}\\) può essere espressa come la somma di due componenti: il residuo \\(e_i=y_i- \\hat{y}_i\\) e lo scarto di \\(\\hat{y}_i\\) rispetto alla media \\(\\bar{y}\\):\n\\[\ny_i - \\bar{y} = (y_i- \\hat{y}_i) + (\\hat{y}_i - \\bar{y}) = e_i + (\\hat{y}_i - \\bar{y}).\n\\]\nLa varianza totale di \\(y\\) può quindi essere scritta come:\n\\[\n\\sum_{i=1}^{n}(y_i - \\bar{y})^2 = \\sum_{i=1}^{n}(e_i + (\\hat{y}_i - \\bar{y}))^2.\n\\]\nSviluppando il quadrato e sommando, si ottiene:\n\\[\n\\sum_{i=1}^{n}(y_i - \\bar{y})^2 = \\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2 + \\sum_{i=1}^{n}(\\hat{y}_i - \\bar{y})^2.\n\\tag{60.3}\\]\nIl primo termine rappresenta la varianza residua, mentre il secondo termine rappresenta la varianza spiegata dal modello. Questa scomposizione della devianza va sotto il nome di teorema della scomposizione della devianza.\nQuesta scomposizione viene utilizzata per calcolare l’indice di determinazione \\(R^2\\), che fornisce una misura della bontà di adattamento del modello ai dati del campione. L’indice di determinazione \\(R^2\\) è definito come il rapporto tra la varianza spiegata e la varianza totale:\n\\[\nR^2 = \\frac{\\sum_{i=1}^{n}(\\hat{y}_i - \\bar{y})^2}{\\sum_{i=1}^{n}(y_i - \\bar{y})^2}.\n\\tag{60.4}\\]\nQuesto indice varia tra 0 e 1 e indica la frazione di varianza totale di \\(y\\) spiegata dal modello di regressione lineare. Un valore alto di \\(R^2\\) indica che il modello di regressione lineare si adatta bene ai dati, in quanto una grande parte della varianza di \\(y\\) è spiegata dalla variabile indipendente \\(x\\).\nPer l’esempio in discussione, possiamo calcolare la devianza totale, la devianza spiegata e l’indice di determinazione \\(R^2\\) come segue:\nLa devianza totale misura la variabilità complessiva dei punteggi osservati \\(y\\) rispetto alla loro media:\n\n# Devianza totale\ndev_t &lt;- sum((kidiq$kid_score - mean(kidiq$kid_score))^2)\ndev_t\n#&gt; [1] 180386\n\nLa devianza spiegata misura la variabilità che il modello è in grado di spiegare, considerando i valori predetti \\(a + b x\\):\n\n# Devianza spiegata\ndev_r &lt;- sum(((a + b * kidiq$mom_iq) - mean(kidiq$kid_score))^2)\ndev_r\n#&gt; [1] 36249\n\nL’indice \\(R^2\\) è il rapporto tra la devianza spiegata e la devianza totale, e indica la frazione della variabilità totale che è spiegata dal modello di regressione:\n\n# Indice di determinazione\nR2 &lt;- dev_r / dev_t\nround(R2, 3)\n#&gt; [1] 0.201\n\nPer verificare i calcoli, utilizziamo il modello di regressione lineare in R e leggiamo \\(R^2\\) direttamente dal sommario del modello:\n\n# Modello di regressione lineare\nmod &lt;- lm(kid_score ~ mom_iq, data = kidiq)\n\n# Sommario del modello per leggere R^2\nsummary(mod)$r.squared\n#&gt; [1] 0.201\n\nIl risultato mostra che circa il 20% della variabilità nei punteggi del QI dei bambini è spiegabile conoscendo il QI delle madri. Questo significa che il modello cattura una porzione rilevante della relazione, ma lascia anche spazio a fattori non inclusi nel modello che influenzano il QI dei bambini.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>La regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#inferenza-sui-coefficienti",
    "href": "chapters/linear_models/01_reglin_frequentist.html#inferenza-sui-coefficienti",
    "title": "60  La regressione lineare bivariata",
    "section": "\n60.12 Inferenza sui coefficienti",
    "text": "60.12 Inferenza sui coefficienti\nL’inferenza statistica sui coefficienti di regressione richiede la definizione della distribuzione campionaria dei coefficienti di regressione. Il modello di regressione bivariata (o lineare semplice) è:\n\\[Y_i = \\beta_0 + \\beta_1 X_i + \\varepsilon_i,\\]\ndove \\(Y_i\\) è la variabile dipendente per l’osservazione \\(i\\), \\(X_i\\) è la variabile indipendente, \\(\\beta_0\\) è l’intercetta (parametro ignoto), \\(\\beta_1\\) è il coefficiente angolare (il parametro che ci interessa stimare), e \\(\\varepsilon_i\\) è il termine di errore per l’osservazione \\(i\\).\nNell’inferenza, il nostro obiettivo è stimare i parametri ignoti \\(\\beta_0\\) e \\(\\beta_1\\) usando i dati campionari disponibili. Il metodo più comune è quello dei Minimi Quadrati Ordinari (OLS), che ci fornisce gli stimatori \\(\\hat{\\beta}_0\\) e \\(\\hat{\\beta}_1\\) (spesso indicati semplicemente con \\(b_0\\) e \\(b_1\\)). Lo stimatore per il coefficiente angolare è dato dalla formula:\n\\[\\hat{\\beta}_1 = b_1 = \\frac{\\sum_{i=1}^n (X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sum_{i=1}^n (X_i - \\bar{X})^2}.\\]\n\n60.12.1 Cos’è la Distribuzione Campionaria di \\(b_1\\)?\nLo stimatore \\(b_1\\) è una variabile casuale. Perché? Perché il suo valore dipende dal campione casuale di dati \\((X_i, Y_i)\\) che abbiamo estratto dalla popolazione.\nImmaginiamo di poter ripetere il processo di campionamento e stima del modello infinite volte:\n\nEstraiamo un campione casuale di dimensione \\(n\\).\nCalcoliamo lo stimatore \\(b_1\\) per quel campione.\nRegistriamo il valore di \\(b_1\\).\nEstraiamo un nuovo campione casuale (indipendentemente dal primo).\nCalcoliamo il “nuovo” \\(b_1\\).\nRegistriamo il valore.\n… e così via, per infinite volte.\n\nLa distribuzione campionaria di \\(b_1\\) è la distribuzione di probabilità di tutti i valori di \\(b_1\\) che otterremmo da questi infiniti campioni casuali di dimensione \\(n\\) estratti dalla stessa popolazione.\n\n60.12.2 Assunzioni di Gauss–Markov e distribuzione campionaria della pendenza\nPer il modello di regressione bivariata\n\\[\nY_i = \\beta_0 + \\beta_1 X_i + \\varepsilon_i,\n\\]\nlo stimatore OLS della pendenza è\n\\[\n\\hat{\\beta}_1 = \\frac{\\sum_{i=1}^n (X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sum_{i=1}^n (X_i - \\bar{X})^2}.\n\\]\nQuesto è una variabile casuale, perché il suo valore dipende dal campione estratto.\n\n60.12.2.1 1. Assunzioni di Gauss–Markov\nAffinché \\(\\hat{\\beta}_1\\) sia non distorto (unbiased) e BLUE (Best Linear Unbiased Estimator), devono valere:\n\nLinearità nei parametri La relazione media tra \\(Y\\) e \\(X\\) è lineare: \\(E(Y_i \\mid X_i) = \\beta_0 + \\beta_1 X_i\\).\nCampionamento casuale e indipendenza Le osservazioni \\((X_i,Y_i)\\) sono indipendenti e identicamente distribuite.\nEsogeneità Gli errori hanno media nulla condizionata a \\(X\\): \\(E(\\varepsilon_i \\mid X_i) = 0\\). Se violata, lo stimatore è distorto.\nOmoschedasticità Varianza costante degli errori: \\(\\mathrm{Var}(\\varepsilon_i \\mid X_i) = \\sigma^2\\).\nAssenza di collinearità perfetta La variabilità di \\(X\\) è positiva: \\(\\sum_{i=1}^n (X_i - \\bar{X})^2 &gt; 0\\).\n\nPer inferenza esatta in piccoli campioni si aggiunge l’assunzione di normalità: \\(\\varepsilon_i \\sim N(0,\\sigma^2)\\).\n\n60.12.2.2 2. Proprietà della distribuzione campionaria di \\(\\hat{\\beta}_1\\)\n\nSotto le assunzioni di Gauss–Markov:\n\nMedia (non distorsione) \\(E(\\hat{\\beta}_1) = \\beta_1\\) → in media, il processo di stima restituisce il vero coefficiente.\n\nVarianza\n\\[\n\\mathrm{Var}(\\hat{\\beta}_1) = \\frac{\\sigma^2}{\\sum_{i=1}^n (X_i - \\bar{X})^2}\n\\]\ndove \\(\\sigma^2\\) è la varianza degli errori. In pratica si usa la stima:\n\\[\ns^2_e = \\frac{\\sum e_i^2}{n-2}, \\quad\nSE(\\hat{\\beta}_1) = \\sqrt{\\frac{s_e^2}{\\sum (X_i - \\bar{X})^2}}\n\\]\n\n\nForma della distribuzione\n\nCon normalità degli errori → distribuzione esatta normale per ogni \\(n\\).\nSenza normalità, per grandi \\(n\\) la distribuzione è approssimativamente normale (Teorema del Limite Centrale).\n\n\n\n60.12.2.3 3. Uso della distribuzione campionaria\nConoscere la distribuzione campionaria di \\(\\hat{\\beta}_1\\) serve per:\n\nTest d’ipotesi Es.: \\(H_0: \\beta_1 = 0\\), usando la statistica \\(t = \\hat{\\beta}_1 / SE(\\hat{\\beta}_1)\\).\nIntervalli di confidenza Es.: \\(\\hat{\\beta}_1 \\pm t_{n-2,\\,0.975} \\times SE(\\hat{\\beta}_1)\\), interpretati in termini di proprietà a lungo termine della procedura di campionamento.\n\nIn sintesi, la distribuzione campionaria di \\(b_1\\) descrive la variabilità attesa dello stimatore del coefficiente angolare attraverso diversi campioni casuali. Comprendere le sue proprietà (media, varianza, forma) è essenziale per interpretare correttamente i risultati di una regressione e trarre conclusioni affidabili sulla relazione nella popolazione.1\n\n60.12.3 Simulazione in R: distribuzione campionaria di \\(\\hat{\\beta}_1\\)\n\nSimuliamo un modello lineare semplice con variabili standardizzate:\n\\[\nY_i = \\beta X_i + \\varepsilon_i, \\quad \\varepsilon_i \\sim N(0, \\sigma_\\varepsilon = 0.5),\n\\]\ncon \\(\\beta = 1.5\\) e \\(n = 30\\) osservazioni. Ripetiamo il campionamento \\(100{,}000\\) volte per approssimare la distribuzione campionaria di \\(\\hat{\\beta}_1\\).\n\n# Parametri\nbeta     &lt;- 1.5     # pendenza vera\nsigma_e  &lt;- 0.5     # deviazione standard errori\nn        &lt;- 30      # dimensione campione\nnrep     &lt;- 1e5     # numero repliche\n\n# X fissata una volta (come nelle assunzioni di Gauss-Markov)\nx &lt;- rnorm(n, mean = 0, sd = 1)\n\n# Stime memorizzate\nb_hat &lt;- numeric(nrep)\n\n# Simulazione\nfor (i in 1:nrep) {\n  e &lt;- rnorm(n, mean = 0, sd = sigma_e) # errori\n  y &lt;- beta * x + e                     # risposta\n  b_hat[i] &lt;- cov(x, y) / var(x)         # formula OLS\n}\n\nAnalisi dei risultati\n\n# Statistiche empiriche\nmean_b_hat &lt;- mean(b_hat)  # media stimata\nsd_b_hat   &lt;- sd(b_hat)    # deviazione standard stimata\n\n# Errore standard teorico\nse_theo &lt;- sqrt(sigma_e^2 / sum((x - mean(x))^2))\n\nc(media_empirica = mean_b_hat,\n  sd_empirica    = sd_b_hat,\n  SE_teorico     = se_theo)\n#&gt; media_empirica    sd_empirica     SE_teorico \n#&gt;        1.49996        0.07376        0.07398\n\nGrafico della distribuzione\n\nhist(b_hat, breaks = 50, col = \"lightblue\", freq = FALSE,\n     main = expression(\"Distribuzione campionaria di\" ~ hat(beta)[1]),\n     xlab = expression(hat(beta)[1]))\ncurve(dnorm(x, mean = mean_b_hat, sd = sd_b_hat), col = \"red\", lwd = 2, add = TRUE)\n\n\n\n\n\n\n\nInterpretazione\n\nNon distorsione La media empirica è ≈ 1.5 → conferma \\(E(\\hat{\\beta}_1) = \\beta_1\\) sotto le assunzioni di Gauss–Markov.\nPrecisione La deviazione standard empirica è molto vicina all’errore standard teorico \\(SE(\\hat{\\beta}_1) = \\sqrt{\\sigma^2 / \\sum (X_i - \\bar{X})^2}\\).\nForma della distribuzione L’istogramma è ben approssimato da una curva normale → normalità asintotica confermata anche per \\(n = 30\\).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>La regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#riflessioni-conclusive",
    "href": "chapters/linear_models/01_reglin_frequentist.html#riflessioni-conclusive",
    "title": "60  La regressione lineare bivariata",
    "section": "Riflessioni conclusive ",
    "text": "Riflessioni conclusive \nIn questo capitolo abbiamo visto come il modello di regressione lineare, nell’ottica frequentista, permetta di stimare e interpretare la relazione tra variabili, basandosi sul metodo dei minimi quadrati e verificando ipotesi precise. Abbiamo discusso il significato dei parametri, le condizioni di validità del modello e gli indici per valutarne la bontà di adattamento.\nTuttavia, questo approccio presenta alcuni limiti: non incorpora conoscenza pregressa sui parametri, si affida ai p-value per l’inferenza e richiede assunzioni rigide sulla distribuzione degli errori. Nel prossimo capitolo introdurremo l’approccio bayesiano alla regressione, che consente di integrare informazioni a priori e di esprimere le inferenze in termini di probabilità sui parametri, offrendo una prospettiva più flessibile e spesso più informativa.\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n1 – Definizione e scopi della regressione\nSecondo Gelman et al. (2021), quali sono i quattro principali utilizzi della regressione? Fornisci una breve descrizione di ciascuno.\n2 – Errore di specificazione\nCos’è l’“errore di specificazione” in un modello di regressione? Quali effetti ha sulle stime dei parametri?\n3 – Stima del modello con lm()\nUsando il data‑set kidiq (variabili kid_score e mom_iq):\n\n# carica i dati\nkidiq &lt;- rio::import(here::here(\"data\", \"kidiq.dta\"))\n\nAdatta il modello kid_score ~ mom_iq e riporta intercetta e pendenza.\n4 – Interpretazione della pendenza\nInterpreta in parole la pendenza stimata al punto 3 nel contesto dei QI di madri e figli.\n5 – Indice R²\nCalcola l’R² del modello di cui al punto 3. Cosa indica il suo valore?\n6 – Centratura del predittore\nCrea la variabile centrata mom_iq_c = mom_iq - mean(mom_iq) e ri‑adatta il modello kid_score ~ mom_iq_c. Qual è la nuova intercetta e perché adesso è più interpretabile?\n7 – Calcolo manuale di \\(b\\)\nCalcola manualmente la pendenza con la formula\\(b = \\frac{\\text{Cov}(x,y)}{\\text{Var}(x)}\\)\ne confrontala col risultato di lm().\n8 – Confronto tra σ̂ (tradizionale) e σ_CV\n* (a) Calcola l’errore standard della regressione (σ̂) usando il modello completo.\n* (b) Esegui una validazione incrociata leave‑one‑out (LOOCV) e ottieni σ_CV.\n* (c) Spiega perché, in genere, σ_CV è ≥ σ̂.\n9 – Assunzioni di Gauss‑Markov\nElenca le cinque assunzioni di Gauss‑Markov per la regressione lineare semplice e indica quale, se violata, rende distorto lo stimatore OLS della pendenza.\n10 – Simulazione della distribuzione campionaria di \\(b\\)\nSimula 100 000 campioni (n = 30) dal modello\\(Y_i = 1.5\\,X_i + \\varepsilon_i,\\; X_i \\sim \\mathcal N(0,1),\\; \\varepsilon_i \\sim \\mathcal N(0,0.5^2)\\).\nPer ogni campione calcola \\(b̂\\). Rappresenta l’istogramma dei 100 000 \\(b̂\\), riporta media e deviazione standard empiriche e confrontale con l’errore standard teorico.\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n1 – Definizione e scopi\n1. Previsione – modellare / predire nuove osservazioni.\n2. Esplorazione delle associazioni – quantificare relazioni \\(X \\rightarrow Y\\).\n3. Estrapolazione – generalizzare dal campione alla popolazione.\n4. Inferenza causale – stimare l’effetto di un intervento quando il design lo consente.\n2 – Errore di specificazione\nOmettere un predittore rilevante ⇒ i residui assorbono la sua varianza ⇒ stime di \\(b\\) distorte (bias) e varianze sottostimate → inferenze non valide.\n3 – Stima del modello\n\nlibrary(rio); library(here)\nkidiq &lt;- import(here(\"data\",\"kidiq.dta\"))\n\nmod &lt;- lm(kid_score ~ mom_iq, data = kidiq)\ncoef(mod)\n#&gt; (Intercept)      mom_iq \n#&gt;       25.80        0.61\n\nEsempio di output\n(Intercept)     mom_iq \n 25.800        0.610 \n4 – Interpretazione della pendenza\nUn punto in più di QI materno è associato, in media, a 0.61 punti di QI del figlio.\n5 – Indice R²\n\nsummary(mod)$r.squared\n#&gt; [1] 0.201\n\nOutput ≈ 0.20 ⇒ il 20 % della varianza di kid_score è spiegato da mom_iq.\n6 – Centratura\n\nkidiq$mom_iq_c &lt;- kidiq$mom_iq - mean(kidiq$mom_iq)\nmod_c &lt;- lm(kid_score ~ mom_iq_c, data = kidiq)\ncoef(mod_c)\n#&gt; (Intercept)    mom_iq_c \n#&gt;       86.80        0.61\n\nL’intercetta ora ≈ media del QI dei bambini quando il QI materno è medio.\nLa pendenza resta 0.61.\n7 – Calcolo manuale di b\n\nb_manual &lt;- cov(kidiq$mom_iq, kidiq$kid_score) / var(kidiq$mom_iq)\nall.equal(b_manual, coef(mod)[\"mom_iq\"])\n#&gt; [1] \"names for current but not for target\"\n\nTRUE → concordanza perfetta (salvo arrotondamenti).\n8 – σ̂ vs σ_CV\n\n# (a) σ̂\nsigma_hat &lt;- summary(mod)$sigma\n\n# (b) LOOCV\nn &lt;- nrow(kidiq)\nres_cv2 &lt;- numeric(n)\nfor (i in seq_len(n)){\n  fit_i &lt;- lm(kid_score ~ mom_iq, data = kidiq[-i,])\n  res_cv2[i] &lt;- (kidiq$kid_score[i] - predict(fit_i, kidiq[i,]))^2\n}\nsigma_CV &lt;- sqrt(mean(res_cv2))\n\nc(sigma_hat = sigma_hat, sigma_CV = sigma_CV)\n#&gt; sigma_hat  sigma_CV \n#&gt;     18.27     18.31\n\nσ_CV tende a superare σ̂ perché ogni predizione è fatta su dati che non hanno “visto” quell’osservazione → niente sovradimensionamento.\n9 – Assunzioni Gauss‑Markov\n1. Linearità nei parametri\n2. Campionamento casuale IID\n3. Esogeneità \\(E(\\varepsilon_i\\!\\mid X_i)=0\\) ← questa garantisce non‑distorsione\n4. Omoschedasticità\n5. Assenza di collinearità perfetta\n10 – Simulazione\n\nset.seed(123)\nbeta  &lt;- 1.5; sigma_e &lt;- 0.5; n  &lt;- 30; nrep &lt;- 1e5\nx &lt;- rnorm(n)\nb_hat &lt;- replicate(nrep, {\n  y &lt;- beta * x + rnorm(n, sd = sigma_e)\n  cov(x,y) / var(x)\n})\n\nmean_emp &lt;- mean(b_hat)\nsd_emp   &lt;- sd(b_hat)\nse_theo  &lt;- sqrt(sigma_e^2 / sum((x - mean(x))^2))\nc(media_empirica = mean_emp, sd_empirica = sd_emp, SE_teorico = se_theo)\n#&gt; media_empirica    sd_empirica     SE_teorico \n#&gt;        1.50006        0.09477        0.09464\n\nL’istogramma (codice sotto) mostra la forma quasi normale centrata su 1.5.\n\nhist(b_hat, breaks = 60, freq = FALSE, main = \"Distribuzione campionaria di b̂\",\n     xlab = \"b̂\"); curve(dnorm(x, mean_emp, sd_emp), add = TRUE, lwd = 2)\n\n\n\n\n\n\n\n- La media empirica ≈ 1.5 ⇒ unbiased.\n- La sd empirica ≈ SE teorico ⇒ formula varianza confermata.\n- Distribuzione simmetrica ≈ Normale ⇒ normalità asintotica verificata.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>La regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/01_reglin_frequentist.html#informazioni-sullambiente-di-sviluppo",
    "title": "60  La regressione lineare bivariata",
    "section": "Informazioni sull’ambiente di sviluppo",
    "text": "Informazioni sull’ambiente di sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] broom_1.0.9           pillar_1.11.0         tinytable_0.11.0     \n#&gt;  [4] patchwork_1.3.1       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt;  [7] bayesplot_1.13.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [10] priorsense_1.1.0      posterior_1.6.1       loo_2.8.0            \n#&gt; [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [16] Rcpp_1.1.0            janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [19] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [22] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.6         tidyselect_1.2.1     farver_2.1.2        \n#&gt;  [4] R.utils_2.13.0       fastmap_1.2.0        TH.data_1.1-3       \n#&gt;  [7] tensorA_0.36.2.1     pacman_0.5.1         digest_0.6.37       \n#&gt; [10] estimability_1.5.1   timechange_0.3.0     lifecycle_1.0.4     \n#&gt; [13] survival_3.8-3       magrittr_2.0.3       compiler_4.5.1      \n#&gt; [16] rlang_1.1.6          tools_4.5.1          knitr_1.50          \n#&gt; [19] labeling_0.4.3       bridgesampling_1.1-2 htmlwidgets_1.6.4   \n#&gt; [22] pkgbuild_1.4.8       curl_6.4.0           RColorBrewer_1.1-3  \n#&gt; [25] multcomp_1.4-28      abind_1.4-8          withr_3.0.2         \n#&gt; [28] purrr_1.1.0          R.oo_1.27.1          grid_4.5.1          \n#&gt; [31] stats4_4.5.1         xtable_1.8-4         colorspace_2.1-1    \n#&gt; [34] inline_0.3.21        emmeans_1.11.2       scales_1.4.0        \n#&gt; [37] MASS_7.3-65          cli_3.6.5            mvtnorm_1.3-3       \n#&gt; [40] rmarkdown_2.29       generics_0.1.4       RcppParallel_5.1.10 \n#&gt; [43] tzdb_0.5.0           stringr_1.5.1        splines_4.5.1       \n#&gt; [46] parallel_4.5.1       vctrs_0.6.5          V8_6.0.5            \n#&gt; [49] Matrix_1.7-3         sandwich_3.1-1       jsonlite_2.0.0      \n#&gt; [52] hms_1.1.3            arrayhelpers_1.1-0   glue_1.8.0          \n#&gt; [55] codetools_0.2-20     distributional_0.5.0 lubridate_1.9.4     \n#&gt; [58] stringi_1.8.7        gtable_0.3.6         QuickJSR_1.8.0      \n#&gt; [61] htmltools_0.5.8.1    Brobdingnag_1.2-9    R6_2.6.1            \n#&gt; [64] rprojroot_2.1.0      evaluate_1.0.4       lattice_0.22-7      \n#&gt; [67] readr_2.1.5          haven_2.5.5          R.methodsS3_1.8.2   \n#&gt; [70] backports_1.5.0      snakecase_0.11.1     rstantools_2.4.0    \n#&gt; [73] coda_0.19-4.1        gridExtra_2.3        nlme_3.1-168        \n#&gt; [76] checkmate_2.3.2      mgcv_1.9-3           xfun_0.52           \n#&gt; [79] forcats_1.0.0        zoo_1.8-14           pkgconfig_2.0.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>La regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#bibliografia",
    "href": "chapters/linear_models/01_reglin_frequentist.html#bibliografia",
    "title": "60  La regressione lineare bivariata",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlter, U., Too, M. A., & Cribbie, R. A. (2025). Navigating the Bayes maze: The psychologist’s guide to Bayesian statistics, a hands-on tutorial with R code. International Journal of Psychology, 60(1), e13271.\n\n\nCaudek, C., & Luccio, R. (2001). Statistica per psicologi (III rist. 2023, Vol. 11, p. 320). Laterza.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>La regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_frequentist.html#footnotes",
    "href": "chapters/linear_models/01_reglin_frequentist.html#footnotes",
    "title": "60  La regressione lineare bivariata",
    "section": "",
    "text": "Per un approfondimento sull’approccio frequentista alla regressione, si veda, per esempio, Caudek & Luccio (2001).↩︎",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>La regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_regr_toward_mean.html",
    "href": "chapters/linear_models/02_regr_toward_mean.html",
    "title": "61  La regressione verso la media",
    "section": "",
    "text": "61.1 Introduzione\nIl concetto di regressione verso la media è stato introdotto da Francis Galton, un pioniere della statistica, mentre studiava la trasmissione ereditaria di tratti fisici, in particolare l’altezza. Galton osservò che, quando si confronta l’altezza dei padri con quella dei figli, i figli tendono ad essere più vicini alla media della popolazione rispetto ai loro padri. Questo fenomeno è noto come regressione verso la media.\nImmaginiamo di avere un padre che è più alto della media della popolazione. Ci aspettiamo che suo figlio sia anch’esso più alto della media, ma non tanto quanto il padre. In altre parole, l’altezza del figlio “regredisce” parzialmente verso la media della popolazione. Lo stesso principio si applica ai padri più bassi della media: i loro figli tenderanno ad essere più bassi della media, ma non tanto quanto i padri.\nPerché succede? Quando un padre è alto 75 pollici (mentre la media magari è 69.1), essere così alto potrebbe essere dovuto a molti fattori “eccezionali” combinati (genetici, ambientali, casuali). Il figlio, tuttavia, eredita solo una parte di quei fattori, e probabilmente avrà altri fattori (positivi o negativi) in modo casuale, cosicché la sua altezza si sposta verso la media della popolazione. Questo non vuol dire che il figlio sia basso: rimane comunque al di sopra della media, ma non raggiunge l’estremo del padre.\nIl cuore statistico del fenomeno si trova nella correlazione tra due variabili (in questo caso, altezza del padre e altezza del figlio). Se la correlazione fosse 1 (perfetta), un padre alto in modo eccezionale avrebbe sempre un figlio proporzionalmente alto, senza “riavvicinarsi” alla media. Se invece la correlazione è minore di 1, come succede quasi sempre nel mondo reale, la relazione padre-figlio non è perfetta e vi è una certa variabilità.\nGalton misurò in media una correlazione di circa 0.5 tra altezza paterna e altezza del figlio maschio. Questo valore implica che, se un padre si discosta di 2-3 deviazioni standard sopra la media, il figlio di solito ne recupererà una parte, ma non interamente.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>La regressione verso la media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_regr_toward_mean.html#introduzione",
    "href": "chapters/linear_models/02_regr_toward_mean.html#introduzione",
    "title": "61  La regressione verso la media",
    "section": "",
    "text": "61.1.1 I Dati di Galton\nEsaminiamo il fenomeno della regressione verso la media usando i dati di Galton. Nel pacchetto HistData di R sono disponibili i dati originali raccolti da Galton, che includono informazioni sull’altezza di padri, madri, figli maschi e femmine. Per semplificare l’analisi, possiamo creare un dataset che include solo l’altezza del padre e l’altezza di un figlio maschio scelto casualmente da ogni famiglia:\n\nset.seed(1234)\n\ngalton_heights &lt;- GaltonFamilies |&gt;\n  filter(gender == \"male\") |&gt;\n  group_by(family) |&gt;\n  sample_n(1) |&gt;\n  ungroup() |&gt;\n  select(father, childHeight) |&gt;\n  rename(son = childHeight)\n\nQuesto dataset contiene due colonne: father (altezza del padre) e son (altezza del figlio maschio). Calcolando la media e la deviazione standard delle altezze dei padri e dei figli, otteniamo:\n\ngalton_heights |&gt; \n  summarize(\n    mean_father = mean(father), \n    sd_father   = sd(father),\n    mean_son    = mean(son), \n    sd_son      = sd(son)\n  )\n#&gt; # A tibble: 1 × 4\n#&gt;   mean_father sd_father mean_son sd_son\n#&gt;         &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1        69.1      2.55     69.1   2.62\n\nI risultati mostrano che, in media, i padri e i figli hanno altezze simili, anche se le distribuzioni non sono identiche. Un grafico di dispersione (scatterplot) evidenzia una chiara tendenza: padri più alti tendono ad avere figli più alti:\n\ngalton_heights |&gt;\n  ggplot(aes(father, son)) +\n  geom_point(alpha = 0.5)\n\n\n\n\n\n\n\n\n61.1.2 Il Coefficiente di Correlazione\nPer quantificare la relazione lineare tra l’altezza del padre e quella del figlio, utilizziamo il coefficiente di correlazione (indicato con \\(r\\) o \\(\\rho\\)). La formula del coefficiente di correlazione è:\n\\[\n\\rho = \\frac{1}{n}\\sum_{i=1}^n\n\\left(\\frac{x_i - \\mu_x}{\\sigma_x}\\right)\n\\left(\\frac{y_i - \\mu_y}{\\sigma_y}\\right).\n\\]\nIn R, possiamo calcolare la correlazione tra l’altezza del padre e quella del figlio con il seguente codice:\n\ngalton_heights |&gt; \n  summarize(r = cor(father, son)) |&gt; \n  pull(r)\n#&gt; [1] 0.4434\n\nNel nostro caso, la correlazione è circa 0.5. Questo valore positivo indica che padri più alti tendono ad avere figli più alti, ma la correlazione non è perfetta. Il coefficiente di correlazione varia tra -1 e 1, dove il valore assoluto misura la forza della relazione lineare.\n\n61.1.3 Stime Condizionate: Previsioni basate sull’Altezza del Padre\nUn modo per fare previsioni è chiedersi: “Se un padre è alto 72 pollici, quale sarà l’altezza media dei figli di tutti i padri di 72 pollici?” In termini statistici, questa è l’aspettativa condizionata \\(\\mathbb{E}(\\text{altezza figlio} \\mid \\text{altezza padre} = 72)\\).\n\nSe filtriamo i dati prendendo solo i padri di altezza 72 pollici, possiamo calcolare la media dell’altezza dei figli in quel sottogruppo.\nTuttavia, questo metodo può essere instabile se il numero di osservazioni nel sottogruppo è piccolo.\n\nAd esempio:\n\ngalton_heights |&gt; \n  filter(round(father) == 72) |&gt;\n  summarize(avg_son = mean(son))\n#&gt; # A tibble: 1 × 1\n#&gt;   avg_son\n#&gt;     &lt;dbl&gt;\n#&gt; 1    70.2\n\nQuesto ci dà la stima condizionata dell’altezza media del figlio di un padre di 72 pollici. Spesso, questa media è maggiore della media generale dei figli, ma meno di quanto il padre (72 pollici) sia sopra la media dei padri. Questo fenomeno è noto come regressione verso la media.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>La regressione verso la media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_regr_toward_mean.html#visualizzare-la-regressione-verso-la-media",
    "href": "chapters/linear_models/02_regr_toward_mean.html#visualizzare-la-regressione-verso-la-media",
    "title": "61  La regressione verso la media",
    "section": "\n61.2 Visualizzare la Regressione verso la Media",
    "text": "61.2 Visualizzare la Regressione verso la Media\nRipetiamo ora lo stesso procedimento per tutti i dati. Stratifichiamo i dati raggruppadoli in base a valori simili di altezza del padre. Calcoliamo poi in ogni gruppo la media dell’altezza del figlio:\n\ngalton_heights |&gt;\n  mutate(father_strata = factor(round(father))) |&gt;\n  group_by(father_strata) |&gt;\n  summarize(avg_son = mean(son)) |&gt;\n  ggplot(aes(x = father_strata, y = avg_son)) +\n  geom_point()\n\n\n\n\n\n\n\nNel grafico risultante, ogni punto rappresenta la media dei figli corrispondenti a un determinato “strato” di padri. Se tracciamo anche la retta di regressione, noteremo che i punti si dispongono in modo approssimativamente lineare: a padri più alti corrispondono figli più alti, ma in media meno alti di quanto ci si aspetterebbe se la correlazione fosse perfetta.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>La regressione verso la media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_regr_toward_mean.html#la-retta-di-regressione",
    "href": "chapters/linear_models/02_regr_toward_mean.html#la-retta-di-regressione",
    "title": "61  La regressione verso la media",
    "section": "\n61.3 La Retta di Regressione",
    "text": "61.3 La Retta di Regressione\nPer capire perché, dal punto di vista statistico, si verifica la regressione verso la media, consideriamo il modello di regressione lineare semplice che prevede l’altezza del figlio \\(\\hat{Y}\\) in base all’altezza del padre \\(X\\):\n\\[\n\\hat{Y} = \\beta_0 + \\beta_1 X.\n\\]\n\nQuando standardizziamo i dati (cioè trasformiamo sia \\(X\\) sia \\(Y\\) in “punti z”, sottraendo la media e dividendo per la deviazione standard), la pendenza \\(\\beta_1\\) della retta di regressione diventa esattamente la correlazione \\(\\rho\\).\n\nSe \\(\\rho = 1\\), la pendenza sarebbe 1 e non ci sarebbe alcun “riavvicinamento” alla media: i valori alti di \\(X\\) corrisponderebbero a valori altrettanto alti di \\(Y\\).\n\nSe \\(\\rho &lt; 1\\), la pendenza risulta minore di 1 e ciò significa che, partendo da un valore molto alto (o molto basso) di \\(X\\), la nostra previsione di \\(Y\\) si colloca in una posizione parzialmente più vicina alla media di \\(Y\\) rispetto alla distanza del padre dalla media di \\(X\\). È proprio questo il fenomeno della regressione verso la media.\n\n\n61.3.1 Forma non standardizzata\nNella forma originale (non standardizzata), i coefficienti si calcolano con:\n\\[\n\\beta_1\n= \\rho \\,\\frac{\\sigma_Y}{\\sigma_X},\n\\quad\n\\beta_0\n= \\mu_Y\n- \\beta_1 \\,\\mu_X,\n\\]\ndove:\n\n\n\\(\\mu_X, \\mu_Y\\) sono le medie di \\(X\\) (altezza del padre) e \\(Y\\) (altezza del figlio);\n\n\\(\\sigma_X, \\sigma_Y\\) sono le rispettive deviazioni standard;\n\n\\(\\rho\\) è la correlazione tra \\(X\\) e \\(Y\\).\n\n61.3.2 Forma standardizzata\nNella forma standardizzata, le deviazioni standard di \\(X\\) e \\(Y\\) sono pari a 1 e i coefficienti di regressione diventano:\n\\[\n\\beta_1\n= \\rho,\n\\quad\n\\beta_0\n= 0,\n\\]\ndato che le medie di \\(X\\) e \\(Y\\) sono uguali a zero.\n\n61.3.3 Regressione Verso la Media\nNe segue dunque che, se la correlazione tra le variabili è minore di 1, si verificherà necessariamente il fenomeno della regressione verso la media.\nIn R, possiamo stimare la retta di regressione tramite la stima dei minimi quadrati:\n\nfit &lt;- lm(son ~ father, data = galton_heights)\nfit$coefficients\n#&gt; (Intercept)      father \n#&gt;     37.6324      0.4559\n\nLa funzione lm calcola gli stimatori \\(\\hat{\\beta}_0\\) e \\(\\hat{\\beta}_1\\) che minimizzano la somma dei quadrati degli scarti:\n\\[\n\\text{RSS} = \\sum_{i} \\left[y_i - (\\beta_0 + \\beta_1 x_i)\\right]^2.\n\\]\nPossiamo quindi tracciare la retta sullo scatterplot dei dati:\n\ngalton_heights |&gt;\n  ggplot(aes(father, son)) +\n  geom_point(alpha = 0.5) +\n  geom_abline(\n    slope = coef(fit)[2], \n    intercept = coef(fit)[1],\n    color = \"blue\"\n  )\n\n\n\n\n\n\n\nSe standardizziamo i dati, la pendenza della retta di regressione diventa uguale alla correlazione:\n\nfit_2 &lt;- lm(scale(son) ~ scale(father), data = galton_heights)\nfit_2$coefficients\n#&gt;   (Intercept) scale(father) \n#&gt;    -7.598e-15     4.434e-01\n\n\ngalton_heights |&gt;\n  ggplot(aes(scale(father), scale(son))) +\n  geom_point(alpha = 0.5) +\n  geom_abline(\n    slope = coef(fit_2)[2], \n    intercept = coef(fit_2)[1],\n    color = \"blue\"\n  )\n\n\n\n\n\n\n\nIl punto cruciale è ricordare che la pendenza \\(\\beta_1\\) è proporzionale alla correlazione \\(\\rho\\). Se la correlazione non è perfetta (\\(\\rho &lt; 1\\)), allora qualsiasi previsione basata su \\(X\\) (ad esempio, l’altezza del padre) risulterà meno estrema di quanto sia \\(X\\) stesso rispetto alla sua media. In altre parole, un padre altissimo (molto sopra la media) avrà, in media, un figlio sopra la media ma non altrettanto estremo, “regredendo” parzialmente verso il centro della distribuzione.\nIn sintesi: la correlazione imperfetta (\\(\\rho &lt; 1\\)) è la ragione principale per cui un valore estremo di \\(X\\) (ad esempio, un padre molto alto) porta a un valore \\(\\hat{Y}\\) che è sì superiore (o inferiore) alla media, ma meno estremo del padre. Questo “ritorno verso il centro” è ciò che chiamiamo regressione verso la media.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>La regressione verso la media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_regr_toward_mean.html#riflessioni-conclusive",
    "href": "chapters/linear_models/02_regr_toward_mean.html#riflessioni-conclusive",
    "title": "61  La regressione verso la media",
    "section": "\n61.4 Riflessioni Conclusive",
    "text": "61.4 Riflessioni Conclusive\n\n\nGalton scoprì il fenomeno della regressione verso la media studiando l’altezza di padri e figli: un padre più alto della media tenderà ad avere un figlio più alto della media, ma non tanto quanto ci si aspetterebbe se la correlazione fosse perfetta.\nQuesto concetto è generale e applicabile in molti contesti. Spesso, un apparente “calo” o “miglioramento” delle prestazioni è semplicemente un effetto statistico di regressione verso la media, non un effetto causale.\nLa retta di regressione minimizza la somma dei quadrati degli errori e la sua pendenza è legata alla correlazione \\(\\rho\\) e al rapporto tra le deviazioni standard \\(\\sigma_Y\\) e \\(\\sigma_X\\).\n\nIn sintesi, la regressione verso la media è un fenomeno statistico che spiega perché, in media, i valori estremi tendono a “ritornare” verso la media della popolazione. Questo concetto è fondamentale per interpretare correttamente i dati e evitare errori di interpretazione causati da correlazioni imperfette.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>La regressione verso la media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_regr_toward_mean.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/02_regr_toward_mean.html#informazioni-sullambiente-di-sviluppo",
    "title": "61  La regressione verso la media",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] HistData_0.9-3   thematic_0.1.7   MetBrewer_0.2.0  ggokabeito_0.1.0\n#&gt;  [5] see_0.11.0       gridExtra_2.3    patchwork_1.3.0  bayesplot_1.13.0\n#&gt;  [9] psych_2.5.3      scales_1.4.0     markdown_2.0     knitr_1.50      \n#&gt; [13] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [17] purrr_1.0.4      readr_2.1.5      tidyr_1.3.1      tibble_3.3.0    \n#&gt; [21] ggplot2_3.5.2    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.4     stringi_1.8.7      lattice_0.22-7    \n#&gt;  [4] hms_1.1.3          digest_0.6.37      magrittr_2.0.3    \n#&gt;  [7] evaluate_1.0.4     grid_4.5.0         timechange_0.3.0  \n#&gt; [10] RColorBrewer_1.1-3 fastmap_1.2.0      rprojroot_2.0.4   \n#&gt; [13] jsonlite_2.0.0     mnormt_2.1.1       cli_3.6.5         \n#&gt; [16] rlang_1.1.6        withr_3.0.2        tools_4.5.0       \n#&gt; [19] parallel_4.5.0     tzdb_0.5.0         pacman_0.5.1      \n#&gt; [22] vctrs_0.6.5        R6_2.6.1           lifecycle_1.0.4   \n#&gt; [25] htmlwidgets_1.6.4  pkgconfig_2.0.3    pillar_1.10.2     \n#&gt; [28] gtable_0.3.6       glue_1.8.0         xfun_0.52         \n#&gt; [31] tidyselect_1.2.1   rstudioapi_0.17.1  farver_2.1.2      \n#&gt; [34] htmltools_0.5.8.1  nlme_3.1-168       labeling_0.4.3    \n#&gt; [37] rmarkdown_2.29     compiler_4.5.0",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>La regressione verso la media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_regr_toward_mean.html#bibliografia",
    "href": "chapters/linear_models/02_regr_toward_mean.html#bibliografia",
    "title": "61  La regressione verso la media",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>La regressione verso la media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html",
    "href": "chapters/linear_models/03_reglin_bayes.html",
    "title": "62  Modello bayesiano di regressione lineare bivariata",
    "section": "",
    "text": "62.1 Introduzione\nIn questa sezione della dispensa esploreremo il modello di regressione lineare bivariata (cioè con una sola variabile indipendente), ponendo particolare attenzione alla formulazione bayesiana. Confronteremo questo approccio con quello frequentista, così da mettere in luce i principali vantaggi dell’inferenza bayesiana, senza introdurre tecnicismi inutilmente complessi. Il nostro obiettivo comprendere come si costruisce un modello di regressione e come si interpretano i risultati nel contesto dell’incertezza.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#introduzione",
    "href": "chapters/linear_models/03_reglin_bayes.html#introduzione",
    "title": "62  Modello bayesiano di regressione lineare bivariata",
    "section": "",
    "text": "62.1.1 L’approccio bayesiano\nA differenza del metodo frequentista, la regressione bayesiana integra esplicitamente l’incertezza sui parametri attraverso distribuzioni di probabilità. L’approccio si articola in tre fasi chiave:\n\n\nSpecifica dei prior\nSi assegnano distribuzioni a priori ai parametri (a, b, σ), riflettendo conoscenze pregresse (da letteratura, teoria o ipotesi). Ad esempio:\n\n\nUn prior informativo per l’inclinazione:\n\\[b \\sim \\mathcal{N}(-0.7, 0.3)\\]\nse studi precedenti suggeriscono che l’ansia riduca la performance.\n\n\nUn prior debole (vago):\n\\[b \\sim \\mathcal{N}(0, 100)\\]\nper lasciare dominare l’evidenza empirica, avvicinandosi alle stime frequentiste.\n\n\n\n\nAggiornamento con i dati\nAttraverso il teorema di Bayes, le distribuzioni a priori vengono aggiornate alla luce dei dati osservati:\n\\[\n\\underbrace{P(a, b, \\sigma \\mid \\text{dati})}_{\\text{Posterior}} \\propto \\underbrace{P(\\text{dati} \\mid a, b, \\sigma)}_{\\text{Verosimiglianza}} \\cdot \\underbrace{P(a, b, \\sigma)}_{\\text{Prior}}.\n\\]\nIl risultato è una distribuzione di probabilità congiunta (posterior) per i parametri, che quantifica la credibilità di ogni loro valore combinando informazioni iniziali e dati.\n\n\nInterpretazione del posterior\n\nNon si ottiene una singola retta, ma un insieme plausibile di rette, ciascuna con un suo peso probabilistico.\n\nL’incertezza è riassunta da intervalli di credibilità (es. 95%): a differenza degli intervalli di confidenza frequentisti, questi ammettono un’interpretazione diretta (“la probabilità che \\(b\\) sia tra 0.8 e 1.2 è del 95%”).\n\n\n\nL’approccio bayesiano offre numerosi vantaggi sul piano sia teorico che applicativo. Innanzitutto, permette di integrare sistematicamente conoscenze esterne, un aspetto particolarmente prezioso quando sono disponibili stime pregresse derivanti da letteratura scientifica o meta-analisi. Questa caratteristica lo rende estremamente utile in contesti di ricerca cumulativa, dove nuove evidenze possono essere valutate alla luce di quanto già noto.\nUn ulteriore punto di forza risiede nella sua maggiore robustezza con campioni di piccole dimensioni. Grazie all’effetto regolarizzante dei prior, le stime risultano più stabili e meno soggette al rischio di sovradattamento ai dati osservati, problema particolarmente insidioso negli studi con limitata numerosità campionaria.\nDal punto di vista interpretativo, l’approccio bayesiano supera alcune limitazioni concettuali del framework frequentista. L’incertezza viene espressa direttamente in termini probabilistici, offrendo una lettura più immediata e intuitiva dei risultati. A differenza degli intervalli di confidenza classici - la cui interpretazione si basa su ipotesi controfattuali di ripetuti campionamenti - gli intervalli di credibilità bayesiani forniscono una valutazione diretta della plausibilità dei parametri, in linea con il modo naturale di ragionare sul concetto di probabilità.\nQueste proprietà rendono il metodo bayesiano particolarmente adatto a contesti di ricerca complessi, dove la combinazione di diverse fonti di evidenza e una rappresentazione completa dell’incertezza sono aspetti fondamentali per una corretta interpretazione dei risultati.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#il-modello-di-regressione-lineare-semplice",
    "href": "chapters/linear_models/03_reglin_bayes.html#il-modello-di-regressione-lineare-semplice",
    "title": "62  Modello bayesiano di regressione lineare bivariata",
    "section": "\n62.2 Il modello di regressione lineare semplice",
    "text": "62.2 Il modello di regressione lineare semplice\nSupponiamo di voler prevedere una variabile quantitativa \\(y\\) (per esempio, il livello di ansia) a partire da una variabile esplicativa \\(x\\) (per esempio, il numero di ore di sonno). Il modello di regressione lineare assume che la relazione tra le due variabili sia descritta da:\n\\[\ny_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i\n\\]\ndove:\n\n\n\\(\\beta_0\\) è l’intercetta (valore medio di \\(y\\) quando \\(x = 0\\)),\n\n\\(\\beta_1\\) è il coefficiente di regressione (quanto cambia \\(y\\) per ogni unità di aumento di \\(x\\)),\n\n\\(\\varepsilon_i\\) è un termine di errore casuale, che tiene conto delle deviazioni impreviste rispetto alla linea di regressione.\n\nAssumiamo che gli errori \\(\\varepsilon_i\\) siano indipendenti e distribuiti normalmente con media zero e varianza costante \\(\\sigma^2\\). Questo implica che anche i valori di \\(y_i\\), condizionati ai rispettivi \\(x_i\\), seguano una distribuzione normale:\n\\[\ny_i \\sim \\mathcal{N}(\\mu_i, \\sigma^2), \\quad \\text{con} \\quad \\mu_i = \\beta_0 + \\beta_1 x_i .\n\\]",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#cosè-la-verosimiglianza",
    "href": "chapters/linear_models/03_reglin_bayes.html#cosè-la-verosimiglianza",
    "title": "62  Modello bayesiano di regressione lineare bivariata",
    "section": "\n62.3 Cos’è la verosimiglianza?",
    "text": "62.3 Cos’è la verosimiglianza?\nLa verosimiglianza è una funzione che misura quanto bene un certo insieme di parametri del modello (cioè \\(\\beta_0\\), \\(\\beta_1\\), \\(\\sigma\\)) riesce a spiegare i dati osservati \\((x_i, y_i)\\). Si tratta di un concetto centrale sia nell’inferenza frequentista sia in quella bayesiana.\nNel nostro caso, la probabilità di osservare un dato \\(y_i\\) condizionato a \\(x_i\\) è data dalla densità di una normale. Assumendo che tutte le osservazioni siano indipendenti, la funzione di verosimiglianza congiunta si ottiene moltiplicando le densità per ciascuna osservazione:\n\\[\n\\mathcal{L}(\\beta_0, \\beta_1, \\sigma \\mid \\mathbf{y}, \\mathbf{x}) = \\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi \\sigma^2}} \\exp\\left(-\\frac{(y_i - \\beta_0 - \\beta_1 x_i)^2}{2\\sigma^2}\\right) .\n\\]\nPoiché lavorare con prodotti può essere complicato, spesso si usa la log-verosimiglianza, che trasforma i prodotti in somme:\n\\[\n\\log \\mathcal{L}(\\beta_0, \\beta_1, \\sigma \\mid \\mathbf{y}, \\mathbf{x}) = -\\frac{n}{2} \\log(2\\pi) - n \\log \\sigma - \\frac{1}{2\\sigma^2} \\sum_{i=1}^n (y_i - \\beta_0 - \\beta_1 x_i)^2 .\n\\]",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#verosimiglianza-confronto-tra-approccio-frequentista-e-bayesiano",
    "href": "chapters/linear_models/03_reglin_bayes.html#verosimiglianza-confronto-tra-approccio-frequentista-e-bayesiano",
    "title": "62  Modello bayesiano di regressione lineare bivariata",
    "section": "\n62.4 Verosimiglianza: confronto tra approccio frequentista e bayesiano",
    "text": "62.4 Verosimiglianza: confronto tra approccio frequentista e bayesiano\n\nNell’approccio frequentista, l’obiettivo è trovare i valori dei parametri che massimizzano la verosimiglianza: è il metodo della massima verosimiglianza.\nNell’approccio bayesiano, la verosimiglianza non è sufficiente: viene combinata con una distribuzione a priori sui parametri, e il risultato è una distribuzione a posteriori che riflette sia le evidenze empiriche, sia le nostre ipotesi iniziali.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#le-distribuzioni-a-priori",
    "href": "chapters/linear_models/03_reglin_bayes.html#le-distribuzioni-a-priori",
    "title": "62  Modello bayesiano di regressione lineare bivariata",
    "section": "\n62.5 Le distribuzioni a priori",
    "text": "62.5 Le distribuzioni a priori\nUno degli aspetti distintivi del metodo bayesiano è la specificazione delle distribuzioni a priori, che riflettono ciò che si crede possibile per i parametri prima di osservare i dati. Esistono diversi tipi di priori:\n\nnon informativi, che riflettono un’assenza di conoscenza iniziale. Sono distribuzioni molto larghe o piatte, progettate per influenzare il meno possibile la distribuzione a posteriori. Un esempio è una distribuzione normale con varianza molto elevata, come \\(\\mathcal{N}(0, 1000)\\);\ndebolmente informativi, che introducono un minimo di informazione strutturale per evitare stime estreme o non plausibili. Sono particolarmente utili nei modelli complessi o quando il numero di dati è limitato. Un esempio comune è \\(\\mathcal{N}(0, 2.5)\\) per i coefficienti di regressione: consente ampio margine di variazione, ma previene valori irrealistici;\ninformativi, che riflettono una conoscenza specifica accumulata prima della raccolta dei dati, per esempio da ricerche precedenti, meta-analisi, o teorie ben consolidate. Questi priori sono più ristretti e centrati su valori considerati plausibili. Possono migliorare l’efficienza dell’inferenza, ma devono essere giustificati accuratamente per evitare di introdurre distorsioni arbitrarie.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#le-distribuzioni-a-posteriori",
    "href": "chapters/linear_models/03_reglin_bayes.html#le-distribuzioni-a-posteriori",
    "title": "62  Modello bayesiano di regressione lineare bivariata",
    "section": "\n62.6 Le distribuzioni a posteriori",
    "text": "62.6 Le distribuzioni a posteriori\nUna volta specificata:\n\nla verosimiglianza (basata sul modello e sui dati), e\nle distribuzioni a priori (che esprimono le nostre credenze iniziali),\n\nè possibile applicare il teorema di Bayes per ottenere la distribuzione a posteriori di ciascun parametro. Questa distribuzione rappresenta la nostra conoscenza aggiornata dopo aver osservato i dati.\nA differenza dell’approccio frequentista, che fornisce stime puntuali, l’approccio bayesiano restituisce intere distribuzioni, permettendo di valutare l’incertezza nei risultati (ad esempio, attraverso gli intervalli di credibilità).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#implementazione-con-brms-la-formula-di-wilkinson",
    "href": "chapters/linear_models/03_reglin_bayes.html#implementazione-con-brms-la-formula-di-wilkinson",
    "title": "62  Modello bayesiano di regressione lineare bivariata",
    "section": "\n62.7 Implementazione con brms: la formula di Wilkinson",
    "text": "62.7 Implementazione con brms: la formula di Wilkinson\nNel pacchetto brms (che usa Stan come motore di calcolo), non è necessario scrivere la funzione di verosimiglianza a mano. Basta specificare il modello nella classica forma di Wilkinson:\nbrm(y ~ x, data = dati)\nQuesta notazione compatta definisce:\n\nil modello di regressione,\nla verosimiglianza implicita,\ne consente a brms di costruire automaticamente il modello bayesiano.\n\nSe non si specificano i priori, brms utilizza prior debolmente informativi di default.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#come-vengono-stimate-le-distribuzioni-a-posteriori",
    "href": "chapters/linear_models/03_reglin_bayes.html#come-vengono-stimate-le-distribuzioni-a-posteriori",
    "title": "62  Modello bayesiano di regressione lineare bivariata",
    "section": "\n62.8 Come vengono stimate le distribuzioni a posteriori?",
    "text": "62.8 Come vengono stimate le distribuzioni a posteriori?\nPoiché la distribuzione a posteriori è spesso troppo complessa per essere calcolata esattamente, brms utilizza tecniche di campionamento numerico chiamate MCMC (Markov Chain Monte Carlo).\nIn particolare, utilizza l’algoritmo NUTS (No-U-Turn Sampler), una variante evoluta dell’algoritmo di Metropolis-Hastings, che esplora lo spazio dei parametri in modo efficiente e adattivo. Grazie a questo, otteniamo campioni dalla distribuzione a posteriori, dai quali è possibile calcolare medie, intervalli di credibilità e fare previsioni.\nIn sintesi, il modello di regressione bayesiano consente di incorporare in modo trasparente incertezze, conoscenze pregresse e informazioni contenute nei dati. Rispetto all’approccio classico, non restituisce una singola stima puntuale ma un’intera distribuzione per ogni parametro. Questo permette inferenze più flessibili e più ricche di informazioni, particolarmente utili nelle scienze psicologiche, dove l’incertezza è la regola più che l’eccezione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#un-esempio-concreto",
    "href": "chapters/linear_models/03_reglin_bayes.html#un-esempio-concreto",
    "title": "62  Modello bayesiano di regressione lineare bivariata",
    "section": "\n62.9 Un Esempio Concreto",
    "text": "62.9 Un Esempio Concreto\nDefiniamo i parametri e simuliamo i dati.\n\nset.seed(123)\n\n# Definizione delle variabili\nx &lt;- 1:100\nn &lt;- length(x)\na &lt;- 1.5\nb &lt;- 0.5\nsigma &lt;- 10\n\n# Generazione di y\ny &lt;- a + b * x + rnorm(n, 0, sigma)\n\n# Creazione del dataframe\nfake &lt;- tibble(x = x, y = y)\nhead(fake)\n#&gt; # A tibble: 6 × 2\n#&gt;       x      y\n#&gt;   &lt;int&gt;  &lt;dbl&gt;\n#&gt; 1     1 -3.60 \n#&gt; 2     2  0.198\n#&gt; 3     3 18.6  \n#&gt; 4     4  4.21 \n#&gt; 5     5  5.29 \n#&gt; 6     6 21.7\n\nIniziamo adattando ai dati un modello frequentista:\n\nfm1 &lt;- lm(y ~ x, data = fake)\n\n\nsummary(fm1)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = y ~ x, data = fake)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -24.536  -5.524  -0.346   6.485  20.949 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)\n#&gt; (Intercept)   1.1360     1.8429    0.62     0.54\n#&gt; x             0.5251     0.0317   16.57   &lt;2e-16\n#&gt; \n#&gt; Residual standard error: 9.15 on 98 degrees of freedom\n#&gt; Multiple R-squared:  0.737,  Adjusted R-squared:  0.734 \n#&gt; F-statistic:  275 on 1 and 98 DF,  p-value: &lt;2e-16\n\nPer ottenere l’intervallo di confidenza (nel senso frequentista) della stima dei parametri usiamo:\n\nconfint(fm1, level = 0.95)\n#&gt;               2.5 % 97.5 %\n#&gt; (Intercept) -2.5212  4.793\n#&gt; x            0.4622  0.588\n\nAdattiamo ora ai dati un modello di regressione bayesiano utilizzando brms. Si noti che, anche in questo caso, usiamo la sintassi di Wilkinson y ~ x, come per lm(). Eseguiamo il campionamento:\n\nfm2 &lt;- brm(\n  y ~ x, \n  data = fake,\n  backend = \"cmdstanr\"\n)\n\nCome discusso nell’analisi dell’algoritmo di Metropolis, il primo passo è esaminare le tracce dei parametri per verificare la convergenza dell’algoritmo. La convergenza può essere considerata raggiunta se le catene (nel caso di brm, sono 4 per impostazione predefinita) risultano ben mescolate. Questo si manifesta in un trace plot che mostra una distribuzione uniforme e casuale dei campioni attorno a un valore centrale, senza pattern evidenti o tendenze sistematiche.\nLe tracce dei parametri si ottengono nel modo seguente:\n\nmcmc_trace(\n  fm2, \n  pars = c(\"b_Intercept\", \"b_x\", \"sigma\"),\n  facet_args = list(nrow = 3)\n)\n\n\n\n\n\n\n\nGli istogrammi delle distribuzioni a posteriori dei parametri si generano nel modo seguente:\n\nmcmc_hist(\n  fm2, \n  pars =c(\"b_Intercept\", \"b_x\", \"sigma\"),\n  facet_args = list(nrow = 3)\n)\n\n\n\n\n\n\n\nPer valutare l’autocorrelazione tra i campioni a posteriori del parametro beta, possiamo utilizzare il seguente comando:\n\nmcmc_acf(fm2, \"b_x\")\n\n\n\n\n\n\n\nL’autocorrelazione fornisce informazioni sulla dipendenza tra campioni successivi nella catena di Markov. È normale che i campioni successivi non siano completamente indipendenti, poiché le catene di Markov generano campioni correlati per costruzione. Tuttavia, se l’algoritmo ha raggiunto la convergenza, l’autocorrelazione dovrebbe diminuire rapidamente e diventare trascurabile dopo un numero relativamente piccolo di lag. Questo significa che, dopo un certo numero di passi, i campioni diventano progressivamente meno correlati tra loro, comportandosi in modo simile a campioni indipendenti estratti dalla distribuzione target.\nUn’elevata autocorrelazione su lag più lunghi potrebbe invece indicare problemi di mescolamento delle catene o una mancata convergenza, richiedendo ulteriori verifiche o aggiustamenti, come l’aumento del numero di iterazioni o una diversa parametrizzazione del modello.\nNel caso presente, notiamo una rapida diminuzione dell’autocorrelazione in funzione del numero di passi. Ciò è indicativo del fatto che la convergenza è stata raggiunta.\nUna sintesi numerica dei risultati si trova nel modo seguente:\n\nsummary(fm2)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: y ~ x \n#&gt;    Data: fake (Number of observations: 100) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept     1.17      1.79    -2.34     4.64 1.00     3981     2679\n#&gt; x             0.52      0.03     0.46     0.59 1.00     4004     2919\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     9.24      0.68     8.02    10.71 1.00     3848     2991\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nConfrontiamo le stime ottenute con i valori reali dei parametri simulati. L’intercetta è stata stimata attorno a 1.14, con un’incertezza al 95% che varia tra -2.4 e 4.8. Questo risultato rientra negli intervalli di credibilità previsti, confermando l’accuratezza del modello. Analogamente, per la pendenza \\(b\\), l’intervallo di credibilità al 95% include il valore reale simulato, dimostrando come le stime bayesiane riflettano accuratamente l’incertezza sui parametri.\nSe si utilizza la funzione conditional_effects() viene prodotto un grafico che rappresenta la relazione stimata tra il predittore \\(x\\) e la variabile di risposta \\(y\\).\n\nconditional_effects(fm2) |&gt;\n  plot(points = TRUE)\n\n\n\n\n\n\n\n\n\nLinea stimata (effetto medio):\n\nLa linea centrale del grafico rappresenta il valore medio previsto di \\(y\\) per ogni valore di \\(x\\), dato dalla relazione \\(y = \\alpha + \\beta x\\).\nQuesta linea è calcolata usando i valori medi a posteriori stimati per \\(\\alpha\\) e \\(\\beta\\).\n\n\n\nBande di incertezza (intervalli di credibilità):\n\nLe bande attorno alla linea rappresentano gli intervalli di credibilità (ad esempio, al 95%). Questi mostrano l’incertezza associata alle stime del modello per ogni valore di \\(x\\).\nPiù strette sono le bande, maggiore è la certezza del modello riguardo alla relazione stimata.\n\n\n\nDati osservati:\n\nI punti rappresentano i valori effettivi di \\(y\\) osservati nei dati. Questo consente di confrontare visivamente come i dati reali si allineano con le previsioni del modello.\n\n\n\nIl grafico consente\n\nuna verifica visiva della relazione stimata tra \\(y\\) e \\(x\\);\ndi identificazione di eventuali discrepanze tra i dati osservati e le previsioni del modello;\nuna rappresentazione dell’incertezza nelle stime.\n\nAd esempio, il grafico può mostrare se \\(x\\) ha un effetto credibile su \\(y\\) e con quale livello di incertezza. Se l’effetto di \\(x\\) è debole o nullo, la linea stimata sarà piatta (vicina a zero) e le bande di incertezza saranno ampie.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#simulazione-di-livelli-di-copertura",
    "href": "chapters/linear_models/03_reglin_bayes.html#simulazione-di-livelli-di-copertura",
    "title": "62  Modello bayesiano di regressione lineare bivariata",
    "section": "\n62.10 Simulazione di Livelli di Copertura",
    "text": "62.10 Simulazione di Livelli di Copertura\nVerifichiamo la copertura degli intervalli di credibilità al 95% attraverso simulazioni ripetute.\n\nset.seed(42)\n# Parametri veri\na_true &lt;- 0.2\nb_true &lt;- 0.3\nsigma_true &lt;- 0.5\n# Numero di simulazioni\nnum_simulations &lt;- 100\n# Conteggio delle coperture\ncoverage_a &lt;- 0\ncoverage_b &lt;- 0\nfor (i in 1:num_simulations) {\n  # Generazione dei dati\n  x &lt;- 1:20\n  y &lt;- a_true + b_true * x + sigma_true * rnorm(length(x))\n  # Adattamento del modello\n  fit &lt;- lm(y ~ x)\n  ci &lt;- confint(fit) # Intervalli di confidenza\n  # Verifica delle coperture\n  if (ci[1,1] &lt;= a_true & ci[1, 2] &gt;= a_true) {\n    coverage_a &lt;- coverage_a + 1\n  }\n  if (ci[2,1] &lt;= b_true & ci[2, 2] &gt;= b_true) {\n    coverage_b &lt;- coverage_b + 1\n  }\n}\n\n\n# Risultati\ncat(\"Coverage for a:\", coverage_a / num_simulations, \"\\n\")\n#&gt; Coverage for a: 0.93\ncat(\"Coverage for b:\", coverage_b / num_simulations, \"\\n\")\n#&gt; Coverage for b: 0.96\n\nI risultati indicano che i livelli di copertura empirici ottenuti con l’approccio frequentista corrispondono strettamente ai livelli teorici attesi.\nPer proseguire, ripeteremo la simulazione adottando un approccio bayesiano. Useremo la funzione brm() del pacchetto brms al posto di lm().\n#| message: false\n#| warning: false\n#| output: false\n#| \nset.seed(23)\nn_fake   &lt;- 100\ncover_68 &lt;- logical(n_fake)\ncover_95 &lt;- logical(n_fake)\n\n# Veri parametri\na     &lt;- 0.2    # intercetta vera\nb     &lt;- 0.3    # pendenza vera\nsigma &lt;- 0.5    # deviazione standard vera\nx     &lt;- 1:20\nn     &lt;- length(x)\n\n# Priors con set_prior \npriors &lt;- c(\n  set_prior(\"normal(0, 2.5)\", class = \"Intercept\"),\n  set_prior(\"normal(0, 2.5)\", class = \"b\", coef = \"x\"),\n  set_prior(\"cauchy(0, 2.5)\", class = \"sigma\")\n)\n\nset.seed(23)\nn_fake   &lt;- 1000\ncover_68 &lt;- logical(n_fake)\ncover_95 &lt;- logical(n_fake)\n\na     &lt;- 0.2\nb     &lt;- 0.3\nsigma &lt;- 0.5\nx     &lt;- 1:20\nn     &lt;- length(x)\n\nfor (s in seq_len(n_fake)) {\n  y    &lt;- a + b * x + rnorm(n, 0, sigma)\n  fake &lt;- data.frame(x = x, y = y)\n\n  fit &lt;- brm(\n    y ~ 1 + x,\n    data    = fake,\n    family  = gaussian(),\n    prior   = priors,\n    iter    = 2000,\n    chains  = 2,\n    refresh = 0,\n    backend = \"cmdstanr\"\n  )\n\n  post &lt;- summary(fit)$fixed\n  b_hat &lt;- post[\"x\", \"Estimate\"]\n  b_se  &lt;- post[\"x\", \"Est.Error\"]\n\n  cover_68[s] &lt;- abs(b - b_hat) &lt; b_se\n  cover_95[s] &lt;- abs(b - b_hat) &lt; 2 * b_se\n}\n\ncat(\"Coverage 68%:\", mean(cover_68), \"\\n\")\ncat(\"Coverage 95%:\", mean(cover_95), \"\\n\")\nCon solo 100 iterazioni, i risultati sono i seguenti:\n&gt; cat(\"Coverage 68%:\", mean(cover_68), \"\\n\")\nCoverage 68%: 0.73 \n&gt; cat(\"Coverage 95%:\", mean(cover_95), \"\\n\")\nCoverage 95%: 0.953 \nQuesta seconda simulazione evidenzia che anche i livelli di copertura empirici ottenuti con l’approccio bayesiano si avvicinano ai valori teorici previsti.\nI risultati ottenuti confermano l’efficacia degli intervalli di confidenza e di credibilità stimati attraverso i modelli frequentisti e bayesiani.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#confronti-non-effetti",
    "href": "chapters/linear_models/03_reglin_bayes.html#confronti-non-effetti",
    "title": "62  Modello bayesiano di regressione lineare bivariata",
    "section": "\n62.11 Confronti, non Effetti",
    "text": "62.11 Confronti, non Effetti\nGelman et al. (2021) sottolineano che i coefficienti di regressione sono spesso denominati “effetti”, ma questa terminologia può trarre in inganno. Gli “effetti”, infatti, implicano una relazione causale. Tuttavia, ciò che un modello di regressione stima non è necessariamente un effetto causale, ma piuttosto un pattern osservazionale. In particolare, ciò che osserviamo è che la media della variabile dipendente nella sottopopolazione con \\(X = x + 1\\) è spesso maggiore o minore (a seconda del segno di \\(\\beta\\)) rispetto alla media della sottopopolazione con \\(X = x\\).\nLa regressione è uno strumento matematico utilizzato principalmente per fare previsioni. I coefficienti di regressione devono quindi essere interpretati come confronti medi. Solo in circostanze specifiche, quando la regressione descrive un processo causale ben definito, è possibile interpretarli come effetti. Tuttavia, questa interpretazione causale deve essere giustificata dal disegno dello studio e non può essere dedotta unicamente dall’uso del modello statistico.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#riflessioni-conclusive",
    "href": "chapters/linear_models/03_reglin_bayes.html#riflessioni-conclusive",
    "title": "62  Modello bayesiano di regressione lineare bivariata",
    "section": "\n62.12 Riflessioni Conclusive",
    "text": "62.12 Riflessioni Conclusive\nIn questo capitolo abbiamo esplorato il modello di regressione lineare bivariata adottando una prospettiva bayesiana. Abbiamo visto che, quando si utilizzano priori debolmente informativi, le stime bayesiane tendono a coincidere con quelle dell’approccio frequentista, specialmente in presenza di un numero consistente di dati. Tuttavia, il valore distintivo dell’approccio bayesiano non si limita alla stima dei parametri: esso risiede soprattutto nella possibilità di integrare conoscenze a priori e di rappresentare l’incertezza in modo esplicito e probabilistico.\nIndipendentemente dalla scelta tra approccio bayesiano o frequentista, è importante sottolineare che i modelli statistici non offrono verità definitive. Come ricordato da Alexander (2023), i modelli non sono specchi della realtà, ma strumenti concettuali per darle significato. Agiscono come lenti interpretative, attraverso cui possiamo mettere a fuoco specifici aspetti del fenomeno studiato.\nIn particolare, i modelli statistici possono essere utilizzati per due scopi principali, entrambi fondamentali nella ricerca psicologica:\n\nPrevisione: si concentra sulla capacità del modello di anticipare nuovi dati. È un uso pragmatico ed empirico della modellizzazione, in cui l’attenzione è rivolta alla bontà predittiva del modello, spesso valutata con tecniche di validazione incrociata.\nInferenza: mira a comprendere le relazioni causali tra variabili. Per rendere credibili le inferenze causali, la regressione deve essere accompagnata da una solida progettazione dello studio (es. esperimenti, disegni longitudinali, controllo di variabili confondenti) e da ipotesi teoriche ben motivate.\n\nLa regressione lineare, in ogni caso, rappresenta una forma di media ponderata tra le osservazioni, il che implica alcune limitazioni:\n\ni risultati possono essere distorti dalla presenza di variabili confondenti non incluse nel modello;\nla qualità dei dati e la verifica delle ipotesi del modello (normalità degli errori, indipendenza, omoschedasticità) giocano un ruolo cruciale nella validità delle stime;\nl’assunzione di linearità potrebbe non essere adatta a descrivere alcune relazioni psicologiche, che spesso sono complesse o non lineari.\n\nPertanto, è essenziale non assumere il modello come un fine, ma considerarlo uno strumento di esplorazione e interpretazione, da integrare in una riflessione teorica più ampia. I risultati di una regressione non parlano da soli: vanno interpretati alla luce del disegno dello studio, della letteratura scientifica, e delle ipotesi formulate dal ricercatore.\nPer chi desidera approfondire il modello bayesiano di regressione lineare, oltre al testo di Johnson et al. (2022), si consiglia la lettura del testo Regression and Other Stories. Quest’ultimo rappresenta una guida pratica e ricca di esempi applicati, ideale per comprendere come integrare i metodi bayesiani nell’analisi di regressione e interpretarne i risultati in contesti reali.\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nVerosimiglianza\nDefinire la funzione di verosimiglianza per il modello bayesiano di regressione lineare bivariata, esplicitando i parametri e la loro interpretazione.\nScelta dei prior\nProporre un set di prior debolmente informativi differenti da quelli riportati, motivando la scelta delle distribuzioni.\nSimulazione dati\nScrivere un blocco di codice in R/Quarto per simulare un dataset con \\(n=50\\), parametri \\(lpha=2\\), \\(eta=0.5\\), \\(\\sigma=1\\) e visualizzare un grafico dispersione con la retta di regressione vera.\nStima frequentista vs bayesiana\nUtilizzando i dati simulati, adattare un modello con lm() e uno con brm() (specificando i prior). Confrontare i risultati prodotti dai due approcci, riportando i valori stimati e gli intervalli di confidenza/credibilità.\nDiagnosi MCMC\nElencare e spiegare almeno tre controlli diagnostici da effettuare sulle catene MCMC per garantire la convergenza e un buon mescolamento.\nInterpretazione dei coefficienti\nIn un contesto osservazionale, discutere perché non è appropriato interpretare i coefficienti della regressione come effetti causali. Fare riferimento ai concetti di confondimento e disegno sperimentale.\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n\n\nVerosimiglianza\n\\[\n\\mathcal{L}(\\alpha, \\beta, \\sigma \\mid y, x) = \\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(-\\frac{(y_i - (\\alpha + \\beta x_i))^2}{2\\sigma^2}\\right).\n\\]\n\n\nScelta dei prior\nAd esempio:\n\n\n\\(\\alpha \\sim \\mathcal{N}(0, 5)\\): consente maggiore variabilità iniziale;\n\n\n\\(\\beta \\sim \\text{Student-}t(3, 0, 2)\\): robuste alle code pesanti;\n\n\n\\(\\sigma \\sim \\text{Half-}Cauchy(0, 1)\\): prior leggermente più stretto sulle deviazioni.\n\n\n\nSimulazione dati\nset.seed(42)\nn &lt;- 50\nalpha &lt;- 2\nbeta  &lt;- 0.5\nsigma &lt;- 1\nx &lt;- rnorm(n, 0, 1)\ny &lt;- alpha + beta * x + rnorm(n, 0, sigma)\nplot(x, y, main = \"Dati simulati\", xlab = \"x\", ylab = \"y\")\nabline(a = alpha, b = beta, col = \"blue\", lwd = 2)\n\n\nStima frequentista vs bayesiana\n\n\nFrequentista (lm()):\nfm_f &lt;- lm(y ~ x)\nsummary(fm_f)\nconfint(fm_f, level = 0.95)\n\n\nBayesiano (brm()):\nfm_b &lt;- brm(y ~ x, data = data.frame(x, y),\n            prior = c(set_prior(\"normal(0,5)\", class=\"Intercept\"),\n                      set_prior(\"normal(0,5)\", class=\"b\"),\n                      set_prior(\"cauchy(0,1)\", class=\"sigma\")),\n            iter = 2000, chains = 2)\nsummary(fm_b)\nConfronto: i valori medi a posteriori e gli intervalli di credibilità dovrebbero includere quelli di confidenza di lm().\n\n\n\n\nDiagnosi MCMC\n\n\nTrace plots: verificare mescolamento e stazionarietà delle catene;\n\n\nR-hat: valore vicino a 1 indica convergenza;\n\n\nEffective Sample Size (ESS): numero di campioni indipendenti effettivi.\n\n\nInterpretazione dei coefficienti\nLa regressione osservazionale non controlla automaticamente i potenziali confondenti; senza randomizzazione o disegno sperimentale rigoroso, non si può inferire causalità. Bisogna considerare variabili confondenti e criteri di validità interna.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/03_reglin_bayes.html#informazioni-sullambiente-di-sviluppo",
    "title": "62  Modello bayesiano di regressione lineare bivariata",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] see_0.11.0            cmdstanr_0.9.0        pillar_1.11.0        \n#&gt;  [4] tinytable_0.11.0      patchwork_1.3.1       ggdist_3.3.3         \n#&gt;  [7] tidybayes_3.0.7       bayesplot_1.13.0      ggplot2_3.5.2        \n#&gt; [10] reliabilitydiag_0.2.1 priorsense_1.1.0      posterior_1.6.1      \n#&gt; [13] loo_2.8.0             rstan_2.32.7          StanHeaders_2.32.10  \n#&gt; [16] brms_2.22.0           Rcpp_1.1.0            janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.6         tidyselect_1.2.1     farver_2.1.2        \n#&gt;  [4] fastmap_1.2.0        TH.data_1.1-3        tensorA_0.36.2.1    \n#&gt;  [7] pacman_0.5.1         digest_0.6.37        estimability_1.5.1  \n#&gt; [10] timechange_0.3.0     lifecycle_1.0.4      processx_3.8.6      \n#&gt; [13] survival_3.8-3       magrittr_2.0.3       compiler_4.5.1      \n#&gt; [16] rlang_1.1.6          tools_4.5.1          yaml_2.3.10         \n#&gt; [19] data.table_1.17.8    knitr_1.50           labeling_0.4.3      \n#&gt; [22] bridgesampling_1.1-2 htmlwidgets_1.6.4    pkgbuild_1.4.8      \n#&gt; [25] curl_6.4.0           plyr_1.8.9           RColorBrewer_1.1-3  \n#&gt; [28] multcomp_1.4-28      abind_1.4-8          withr_3.0.2         \n#&gt; [31] purrr_1.1.0          grid_4.5.1           stats4_4.5.1        \n#&gt; [34] xtable_1.8-4         colorspace_2.1-1     inline_0.3.21       \n#&gt; [37] emmeans_1.11.2       scales_1.4.0         MASS_7.3-65         \n#&gt; [40] cli_3.6.5            mvtnorm_1.3-3        rmarkdown_2.29      \n#&gt; [43] generics_0.1.4       RcppParallel_5.1.10  reshape2_1.4.4      \n#&gt; [46] stringr_1.5.1        splines_4.5.1        parallel_4.5.1      \n#&gt; [49] vctrs_0.6.5          V8_6.0.5             Matrix_1.7-3        \n#&gt; [52] sandwich_3.1-1       jsonlite_2.0.0       arrayhelpers_1.1-0  \n#&gt; [55] glue_1.8.0           ps_1.9.1             codetools_0.2-20    \n#&gt; [58] distributional_0.5.0 lubridate_1.9.4      stringi_1.8.7       \n#&gt; [61] gtable_0.3.6         QuickJSR_1.8.0       htmltools_0.5.8.1   \n#&gt; [64] Brobdingnag_1.2-9    R6_2.6.1             rprojroot_2.1.0     \n#&gt; [67] evaluate_1.0.4       lattice_0.22-7       backports_1.5.0     \n#&gt; [70] broom_1.0.9          snakecase_0.11.1     rstantools_2.4.0    \n#&gt; [73] coda_0.19-4.1        gridExtra_2.3        nlme_3.1-168        \n#&gt; [76] checkmate_2.3.2      xfun_0.52            zoo_1.8-14          \n#&gt; [79] pkgconfig_2.0.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_reglin_bayes.html#bibliografia",
    "href": "chapters/linear_models/03_reglin_bayes.html#bibliografia",
    "title": "62  Modello bayesiano di regressione lineare bivariata",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlexander, R. (2023). Telling Stories with Data: With Applications in R. Chapman; Hall/CRC.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html",
    "href": "chapters/linear_models/04_synt_sugar.html",
    "title": "63  Zucchero sintattico",
    "section": "",
    "text": "63.1 Introduzione\nI modelli lineari sono così ampiamente utilizzati che sono stati sviluppati appositamente una sintassi, dei metodi e delle librerie per la regressione. Una di queste librerie è brms (Bayesian Regression Models using Stan), già introdotta nel Capitolo 62. brms è un pacchetto R progettato per adattare modelli gerarchici generalizzati lineari (di cui il modello lineare bivariato è un caso particolare), utilizzando una sintassi simile a quella presente nei pacchetti R, come lm, lme4, nlme, rstanarm. brms si basa su Stan, ma offre un’API di livello superiore.\nIn questo capitolo esploreremo in maniera dettagliata come condurre un’analisi di regressione utilizzando brms invece di Stan.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html#interfaccia-brms",
    "href": "chapters/linear_models/04_synt_sugar.html#interfaccia-brms",
    "title": "63  Zucchero sintattico",
    "section": "\n63.2 Interfaccia brms\n",
    "text": "63.2 Interfaccia brms\n\nPer fare un esempio, applicheremo il modello di regressione bivariato alla relazione tra altezza e peso. I dati contenuti nel file Howell_18.csv sono parte di un censimento parziale della popolazione !Kung San dell’area di Dobe, raccolti tramite interviste condotte da Nancy Howell alla fine degli anni ’60 (McElreath, 2020). I !Kung San sono una delle popolazioni di raccoglitori-cacciatori più conosciute del ventesimo secolo e sono stati oggetto di numerosi studi antropologici. In questa analisi, consideriamo un sottocampione di dati relativi alla popolazione adulta (di età superiore ai 18 anni).\nImportiamo i dati contenuti nel file Howell_18.csv.\n\ndf &lt;- rio::import(here::here(\"data\", \"Howell_18.csv\"))\n\n\ndf |&gt; \n  head()\n#&gt;   height weight age male\n#&gt; 1  151.8  47.83  63    1\n#&gt; 2  139.7  36.49  63    0\n#&gt; 3  136.5  31.86  65    0\n#&gt; 4  156.8  53.04  41    1\n#&gt; 5  145.4  41.28  51    0\n#&gt; 6  163.8  62.99  35    1\n\nGeneriamo un diagramma a dispersione tra le variabili height (altezza) e weight (peso):\n\nggplot(df, aes(x = weight, y = height)) +\n  geom_point() +  \n  labs(x = \"Weight\", y = \"Height\") \n\n\n\n\n\n\n\nbrms si concentra sui modelli di regressione, e questa specializzazione permette di adottare una sintassi più semplice, conosciuta come sintassi di Wilkinson (Wilkinson & Rogers, 1973).\nAd esempio, il modello \\(y = \\alpha + \\beta x + \\varepsilon\\) si implementa come segue:\na_model = brm(y ∼ 1 + x, data = df)\nNella sintassi di Wilkinson, il simbolo tilde (∼) separa la variabile dipendente (a sinistra) dalle variabili indipendenti (a destra). In questo caso, stiamo specificando solo la media (\\(\\mu\\)) della \\(y\\).\nbrms assume di default che la distribuzione di verosimiglianza sia gaussiana, ma è possibile modificarla tramite l’argomento family.\nLa notazione 1 si riferisce all’intercetta. L’intercetta viene inclusa di default. Per cui il modello precedente si può anche scrivere, in maniera equivalente, come\na_model = brm(y ∼ x, data = df)\nSe desideriaamo escludere l’intercetta dal modello, possiamo farlo in questo modo\nno_intercept_model = brm(y ∼ 0 + x, data = df)\noppure in questo modo\nno_intercept_model = brm(y ∼ -1 + x, data = df)\nPer includere ulteriori variabili nel modello, possiamo procedere così:\nmodel_2 = brm(\"y ∼ x + z\", data)\nbrms consente anche di includere effetti a livello di gruppo (gerarchici). Ad esempio, se desideriamo un modello ad effetti misti nel quale abbiamo un effetto diverso di \\(x\\) in ciascun gruppo g, possiamo usare la seguente sintassi:\nmodel_h = brm(y ∼ x + z + (x | g), data = df)\nLa sintassi di Wilkinson non specifica le distribuzioni a priori, ma solo come le variabili dipendenti e indipendenti sono collegate. brms definirà automaticamente delle distribuzioni a priori debolmente informative per noi, rendendo superflua la loro definizione esplicita. Tuttavia, se preferiamo avere un maggiore controllo, possiamo specificarle manualmente, come vedremo in seguito.\n\n63.2.1 Centrare le Variabili\nPer interpretare più facilmente l’intercetta, centriamo la variabile weight rispetto alla media del campione:\n\ndf$weight_c &lt;- df$weight - mean(df$weight)\n\nOra, l’intercetta (\\(\\alpha\\)) rappresenterà l’altezza media quando il peso corrisponde alla media del campione.\nAdattiamo un modello lineare con la variabile weight centrata e esaminiamo i risultati:\n\nfit_1 = brm(\n  bf(height ~ 1 + weight_c, center = FALSE), \n  data = df, \n  backend = \"cmdstanr\", \n  silent = 0\n)\n\nUtilizzando center = FALSE nel modello Bayesiano garantiamo che il centraggio venga mantenuto e non applicato nuovamente da brms.\nL’argomento backend = \"cmdstanr\" indica a brms di usare cmdstan per il campionamento, al posto di Stan che è l’impostazione predefinita. Poiché in questo insegnamento utilizzeremo cmdstan, è essenziale specificare questo backend.\nLe tracce dei parametri si ottengono nel modo seguente:\n\nmcmc_trace(\n  fit_1, \n  pars = c(\"b_Intercept\", \"b_weight_c\", \"sigma\"),\n  facet_args = list(nrow = 3)\n)\n\n\n\n\n\n\n\n\nsummary(fit_1)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: height ~ 1 + weight_c \n#&gt;    Data: df (Number of observations: 352) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept   154.59      0.27   154.06   155.11 1.00     3947     2871\n#&gt; weight_c      0.91      0.04     0.82     0.99 1.00     3945     2996\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     5.10      0.20     4.74     5.51 1.00     4902     3275\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nLa stima dell’intercetta \\(\\alpha\\) = 154.60 suggerisce che, per le persone con un peso corrispondente al valore medio del campione analizzato, l’altezza prevista è di 154.60 cm.\nPossiamo confrontare i risultati ottenuti da brm() con quelli prodotti dall’approccio frequentista:\n\nfit_2 &lt;- lm(height ~ 1 + weight_c, data = df)\n\n\nsummary(fit_2)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = height ~ 1 + weight_c, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -19.746  -2.884   0.022   3.142  14.774 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)\n#&gt; (Intercept)  154.597      0.271   570.2   &lt;2e-16\n#&gt; weight_c       0.905      0.042    21.5   &lt;2e-16\n#&gt; \n#&gt; Residual standard error: 5.09 on 350 degrees of freedom\n#&gt; Multiple R-squared:  0.57,   Adjusted R-squared:  0.568 \n#&gt; F-statistic:  463 on 1 and 350 DF,  p-value: &lt;2e-16\n\nL’uso di prior debolmente informativi fa in modo che i risultati dei due approcci siano praticamente equivalenti.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html#visualizzazione-dei-risultati",
    "href": "chapters/linear_models/04_synt_sugar.html#visualizzazione-dei-risultati",
    "title": "63  Zucchero sintattico",
    "section": "\n63.3 Visualizzazione dei Risultati",
    "text": "63.3 Visualizzazione dei Risultati\nPer comprendere visivamente la relazione stimata tra peso e altezza nel nostro modello bayesiano, utilizziamo la funzione conditional_effects:\n\nconditional_effects(fit_1, effects = \"weight_c\")\n\n\n\n\n\n\n\nIl grafico generato fornisce una rappresentazione completa della relazione stimata:\n\n\nLinea centrale (media posteriore): rappresenta la stima più probabile dell’altezza per ciascun valore del peso centrato.\n\nArea colorata (intervallo di credibilità): mostra l’intervallo di densità più alta (HDI) al 95%, indicando l’incertezza attorno alla stima centrale.\n\nÈ possibile adattare il livello di incertezza mostrato modificando l’argomento prob:\n\n# Visualizzazione con intervallo di credibilità all'89%\nconditional_effects(fit_1, effects = \"weight_c\", prob = 0.89)\n\n\n\n\n\n\n\nRidurre il valore di prob (es. a 0.80 o 0.50) produce un intervallo più stretto, mentre aumentarlo (es. a 0.99) amplia l’area di incertezza visualizzata.\n\n63.3.1 Interpretazione Pratica del Grafico\nNel grafico:\n\nil punto dove la linea attraversa weight_c = 0 corrisponde all’altezza prevista per un individuo con peso medio (poiché abbiamo centrato la variabile);\nla pendenza della linea indica quanto ci aspettiamo che l’altezza aumenti per ogni kg di peso aggiuntivo;\nla larghezza dell’intervallo di credibilità indica la nostra certezza sulle stime: più stretto l’intervallo, maggiore la certezza.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html#due-tipi-di-incertezza-nei-modelli-bayesiani",
    "href": "chapters/linear_models/04_synt_sugar.html#due-tipi-di-incertezza-nei-modelli-bayesiani",
    "title": "63  Zucchero sintattico",
    "section": "\n63.4 Due Tipi di Incertezza nei Modelli Bayesiani",
    "text": "63.4 Due Tipi di Incertezza nei Modelli Bayesiani\nImmaginiamo di voler capire come il peso (variabile X) sia collegato all’altezza (variabile Y) in un gruppo di persone. Con un modello bayesiano ottieniamo due tipi distinti di informazioni incerte:\n\n\n\n\n\n\n\nChe cosa stiamo stimando?\nCome si chiama l’incertezza?\nChe intervallo disegniamo?\n\n\n\n\nLa media “vera” dell’altezza per ogni valore di peso\n\nIncertezza del parametro (o dell’effetto medio)\n\nIntervallo di credibilità (credibility/credible interval)\n\n\n\nLa singola osservazione futura (quanto sarà alta la prossima persona di quel peso)\nIncertezza predittiva\n\nIntervallo di predizione (prediction interval)\n\n\n\n\n63.4.1 Incertezza del parametro – «Quanto stiamo sbagliando la linea media?»\n\n\nChe cosa fa il codice\n\nconditional_effects(fit_1, effects = \"weight_c\")\n\n\n\n\n\n\n\n\nDisegna la linea di regressione (in pratica: la media stimata dell’altezza per ogni peso).\n\nAggiunge intorno una fascia stretta: è l’intervallo di credibilità al 95 %.\n\n\n\n\nCome leggerla\n\nSe la fascia copre, ad esempio, da 170 cm a 172 cm per un peso di 70 kg, significa che “con il 95 % di probabilità la vera media dell’altezza per quel peso sta lì dentro”.\n\nNon dice nulla sul fatto che le persone individuali possano essere molto più basse o molto più alte.\n\n\n\n\nMetafora veloce\nPensa a tirare freccette: la freccia media cade vicino al centro, ma ogni singola freccia può andare ovunque sul bersaglio. L’intervallo di credibilità descrive la posizione del centro.\n\n\n63.4.2 Incertezza predittiva – «Quanto potrebbe variare la prossima persona?»\n\n\nChe cosa fa il codice\n\nconditional_effects(fit_1, effects = \"weight_c\", method = \"predict\")\n\n\n\n\n\n\n\n\nRipropone la stessa linea media.\n\nDisegna però una fascia molto più larga: l’intervallo di predizione.\n\n\n\n\nPerché è più largo\n\nContiene le due fonti di variabilità:\n\n\nIncertezza sulla linea media (come sopra).\n\n\nVariabilità residua: le differenze naturali tra persone di uguale peso (chi è più muscoloso, chi ha ossa più leggere ecc.).\n\n\n\n\n\n\nMetafora veloce\nOra guardi non il centro del bersaglio, ma l’intero disco dove ogni freccia potrebbe atterrare. Quell’area è molto più grande.\n\n\n63.4.3 Quando usare l’una o l’altra fascia?\n\n\n\n\n\n\n\nObiettivo della tua domanda\nFunzione da usare\nChe fascia guardare\n\n\n\nCapire l’effetto medio (es. “quanto cresce in media l’altezza al crescere di 1 kg?”)\nconditional_effects(...)\nIntervallo di credibilità\n\n\nFare previsioni su nuovi casi (es. “quanto sarà alta Maria che pesa 70 kg?”)\nconditional_effects(..., method = \"predict\")\nIntervallo di predizione\n\n\n\n63.4.4 Riepilogo\n\n\nCredibilità = incertezza sul parametro medio → fascia stretta perché stiamo stimando solo la retta di regressione.\n\n\nPredizione = incertezza su osservazioni future → fascia larga perché somma l’incertezza della retta + la variabilità individuale.\n\nScegliamo la visualizzazione che risponde alla nostra domanda: “qual è la media?” (credibilità) o “dove cadrà il prossimo dato?” (predizione).\n\nIn sintesi, la differenza principale sta nell’inclusione o meno della variabilità residua. La visualizzazione predittiva è più onesta riguardo alla nostra capacità di fare previsioni per singole osservazioni, mentre quella standard è più adatta per comprendere la relazione generale tra le variabili.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html#distribuzione-a-posteriori-dei-parametri",
    "href": "chapters/linear_models/04_synt_sugar.html#distribuzione-a-posteriori-dei-parametri",
    "title": "63  Zucchero sintattico",
    "section": "\n63.5 Distribuzione a Posteriori dei Parametri",
    "text": "63.5 Distribuzione a Posteriori dei Parametri\nPer esaminare la distribuzione a posteriori dei parametri usiamo la funzione mcmc_plot():\n\nmcmc_plot(fit_1, type = \"dens\")\n\n\n\n\n\n\n\nEsaminiamo in maggiori dettagli il sommario numerico dei parametri stimati:\n\ndraws &lt;- posterior::as_draws(fit_1, variable = \"^b_\", regex = TRUE)\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 2 × 5\n#&gt;   variable       mean     sd mcse_mean  mcse_sd\n#&gt;   &lt;chr&gt;         &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 b_Intercept 155.    0.269   0.00428  0.00391 \n#&gt; 2 b_weight_c    0.906 0.0423  0.000675 0.000681\n\nUtilizziamo la funzione as_draws() che trasforma un oggetto R in un formato compatibile con posterior. Gli argomenti variable = \"^b_\" e regex = TRUEconsentono di selezionare solo i parametri il cui nome inizia con b_: nel nostro caso saranno l’intercetta e la pendenza del modello di regressione lineare.\nSuccessivamente usiamo la funzione summarise_draws() con gli argomenti specificati per un sommario della distribuzione a posteriori dei parametri prescelti.\n\n63.5.1 Spiegazione di mcse_mean e mcse_sd\n\nI valori mcse_mean e mcse_sd sono le Monte Carlo Standard Errors (errori standard Monte Carlo) per la stima della media (mean) e della deviazione standard (sd), rispettivamente. Questi valori quantificano l’incertezza associata al processo di campionamento effettuato durante l’analisi bayesiana, in particolare quando si utilizzano algoritmi Monte Carlo come MCMC (Markov Chain Monte Carlo).\n\n63.5.1.1 mcse_mean\n\n\nRappresenta l’errore standard Monte Carlo per la stima della media.\nIndica quanto la media stimata (\\(\\text{mean}\\)) potrebbe variare a causa della finitezza dei campioni generati dall’algoritmo MCMC.\nUn valore di mcse_mean basso rispetto alla deviazione standard (\\(\\text{sd}\\)) suggerisce che il numero di campioni generati è sufficiente per ottenere una stima accurata della media.\n\n63.5.1.2 mcse_sd\n\n\nRappresenta l’errore standard Monte Carlo per la stima della deviazione standard.\nIndica quanto potrebbe variare la stima della deviazione standard (\\(\\text{sd}\\)) a causa del numero finito di campioni generati.\nAnche qui, un valore basso di mcse_sd rispetto alla sd suggerisce che l’incertezza introdotta dal campionamento è trascurabile.\n\n63.5.2 Come interpretarli?\n\n\nProporzione rispetto alla sd:\n\n\nmcse_mean e mcse_sd dovrebbero essere molto più piccoli rispetto ai rispettivi parametri (mean e sd), idealmente almeno un ordine di grandezza inferiore.\nAd esempio, per b_Intercept, mcse_mean = 0.0044 è molto più piccolo rispetto a sd = 0.2695, indicando che la stima della media è robusta.\n\n\n\nIndicazione della qualità del campionamento:\n\nValori alti di mcse_mean o mcse_sd rispetto alla sd potrebbero indicare che il numero di iterazioni MCMC non è sufficiente, che le catene non sono ben mescolate o che ci sono problemi di convergenza.\n\n\n\nIn sintesi, mcse_mean e mcse_sd sono utili per valutare l’affidabilità delle stime derivate dal campionamento Monte Carlo. Se questi valori sono bassi, possiamo essere confidenti che il numero di campioni è sufficiente per rappresentare accuratamente la distribuzione a posteriori.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html#specificare-i-priors",
    "href": "chapters/linear_models/04_synt_sugar.html#specificare-i-priors",
    "title": "63  Zucchero sintattico",
    "section": "\n63.6 Specificare i Priors",
    "text": "63.6 Specificare i Priors\nSe vogliamo personalizzare i priors, possiamo utilizzare la funzione get_prior per esplorare quelli predefiniti:\n\nget_prior(height ~ 1 + weight_c, data = df)\n#&gt;                     prior     class     coef group resp dpar nlpar lb ub\n#&gt;  student_t(3, 154.3, 8.5) Intercept                                     \n#&gt;                    (flat)         b                                     \n#&gt;                    (flat)         b weight_c                            \n#&gt;      student_t(3, 0, 8.5)     sigma                                 0   \n#&gt;        source\n#&gt;       default\n#&gt;       default\n#&gt;  (vectorized)\n#&gt;       default\n\n\n\nprior: descrive il prior predefinito assegnato a ciascun parametro del modello. Ad esempio:\n\n\nstudent_t(3, 154.3, 8.5): prior t di Student per l’intercetta con 3 gradi di libertà, una media di 154.3, e una scala di 8.5.\n\n(flat): prior piatto (non informativo) per i coefficienti delle variabili predittive, come \\(b\\) e \\(b_{weight_c}\\).\n\nstudent_t(3, 0, 8.5): prior t di Student per il parametro \\(\\sigma\\) (deviazione standard residua), centrato su 0 con una scala di 8.5.\n\n\n\nclass: identifica la classe di parametro a cui il prior si applica:\n\n\nIntercept: prior per l’intercetta (\\(\\alpha\\)).\n\nb: prior per i coefficienti delle variabili predittive (\\(\\beta\\)).\n\nsigma: prior per il parametro della deviazione standard residua (\\(\\sigma\\)).\n\n\n\ncoef: specifica a quale predittore si riferisce il prior, se applicabile. Ad esempio:\n\nVuoto per l’intercetta (poiché non dipende da un predittore specifico).\n\nweight_c per il coefficiente relativo al predittore weight_c.\n\n\n\nlb e ub: rappresentano rispettivamente i limiti inferiori (lower bound) e superiori (upper bound) per il prior, se specificati. Ad esempio:\n\nPer sigma, il limite inferiore è \\(0\\), dato che la deviazione standard non può essere negativa.\n\n\n\nsource: indica l’origine del prior. Se il prior è predefinito (default), il valore sarà default. Se un prior è specificato manualmente dall’utente, sarà indicato come tale.\n\nOra impostiamo priors espliciti e adattiamo un nuovo modello:\n\nprior_guassian &lt;-\n  brms::prior(normal(160, 10), class = \"b\", coef = \"Intercept\") +\n  brms::prior(normal(0, 5), class = \"b\", coef = \"weight_c\") +\n  brms::prior(cauchy(0, 5), class = \"sigma\")\n\nSi noti l’uso di brms::prior(). Questa notazione specifica esplicitamente che stiamo utilizzando la funzione prior() propria del pacchetto brms, evitando potenziali conflitti con funzioni omonime presenti in altre librerie caricate.\n\nfit_2 = brm(\n  bf(height ~ 1 + weight_c, center = FALSE), \n  prior = prior_guassian,\n  data = df, \n  backend = \"cmdstanr\", \n  silent = 0\n)\n\nOtteniamo un sommario numerico dei parametri stimati:\n\ndraws &lt;- posterior::as_draws(fit_2, variable = \"^b_\", regex = TRUE)\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 2 × 5\n#&gt;   variable       mean     sd mcse_mean  mcse_sd\n#&gt;   &lt;chr&gt;         &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 b_Intercept 155.    0.273   0.00425  0.00409 \n#&gt; 2 b_weight_c    0.905 0.0428  0.000703 0.000678\n\nI prior che abbiamo specificato non cambiano in maniera rilevante la soluzione a posteriori.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html#predizioni-predittive-a-posteriori",
    "href": "chapters/linear_models/04_synt_sugar.html#predizioni-predittive-a-posteriori",
    "title": "63  Zucchero sintattico",
    "section": "\n63.7 Predizioni Predittive a Posteriori",
    "text": "63.7 Predizioni Predittive a Posteriori\nUn aspetto fondamentale nella valutazione di un modello statistico, sia frequentista che bayesiano, è verificare quanto bene i dati osservati siano rappresentati dalle predizioni del modello. Tuttavia, l’approccio e l’interpretazione differiscono tra i due paradigmi.\n\n63.7.1 Confronto Frequentista\nNel caso frequentista, si confrontano i valori predetti dal modello, \\(\\hat{y} = \\hat{\\alpha} + \\hat{\\beta}x\\), con i dati osservati. Questo confronto si basa sull’analisi di:\n\nla vicinanza della retta di regressione stimata ai dati osservati;\nl’eventuale presenza di pattern nei dati che si discostano da un andamento lineare;\nla variazione della dispersione dei valori di \\(y\\) rispetto a \\(x\\) (ad esempio, per verificare l’ipotesi di omoschedasticità).\n\n63.7.2 Approccio Bayesiano\nNell’approccio bayesiano, si eseguono le stesse verifiche di base, ma l’analisi si arricchisce attraverso l’uso delle Predizioni Predittive a Posteriori (Posterior Predictive Checks, PPCs). Questo metodo consente di confrontare i dati osservati con dati simulati dal modello, utilizzando l’incertezza stimata nelle distribuzioni a posteriori dei parametri.\n\n63.7.3 Costruzione delle Predizioni Predittive a Posteriori\nNel caso di un modello bivariato, il processo per generare un grafico delle Predizioni Predittive a Posteriori è il seguente:\n\nDati osservati: Si parte dall’istogramma lisciato dei dati osservati, che rappresenta la distribuzione empirica di \\(y\\).\n\nSimulazione di dati predetti:\n\nSi estrae un campione casuale di valori \\(\\alpha'\\), \\(\\beta'\\), e \\(\\sigma'\\) dalle distribuzioni a posteriori dei parametri (\\(\\alpha\\), \\(\\beta\\), e \\(\\sigma\\)).\nUsando questi valori, si calcolano dati simulati da una distribuzione normale: \\[\ny_{\\text{sim}} \\sim \\mathcal{N}(\\alpha' + \\beta'x, \\sigma')\n\\] dove \\(x\\) sono i valori predittori osservati.\n\n\nCreazione di istogrammi: Per ogni campione simulato, si costruisce un istogramma lisciato che rappresenta la distribuzione predetta dal modello.\nRipetizione: Il processo viene ripetuto più volte, generando molti istogrammi lisciati.\nConfronto: Tutti gli istogrammi predetti vengono sovrapposti all’istogramma dei dati osservati. Questo consente di confrontare visivamente la capacità del modello di rappresentare la distribuzione dei dati.\n\n63.7.4 Interpretazione\n\n\nBuona corrispondenza: Se gli istogrammi lisciati dei dati simulati si sovrappongono bene all’istogramma dei dati osservati, significa che il modello è in grado di rappresentare adeguatamente il campione corrente.\n\nDiscrepanze: Se vi sono discrepanze sistematiche (ad esempio, picchi o code mancanti nei dati predetti rispetto agli osservati), ciò indica che il modello potrebbe non essere adeguato o che vi sono aspetti dei dati non catturati dal modello.\n\nL’approccio delle Predizioni Predittive a Posteriori è particolarmente potente perché:\n\nintegra l’incertezza nei parametri del modello;\npermette di verificare non solo la bontà di adattamento complessiva, ma anche specifici aspetti delle distribuzioni predette;\nè visivo e intuitivo, facilitando l’identificazione di discrepanze tra modello e dati.\n\nIn conclusione, le Predizioni Predittive a Posteriori forniscono un modo robusto per valutare l’adeguatezza di un modello bayesiano rispetto ai dati osservati. Se il modello riproduce bene la distribuzione dei dati osservati, si può concludere che è adatto almeno per il campione corrente. In caso contrario, potrebbe essere necessario rivedere le specifiche del modello, come i priors o la struttura delle variabili.\nVerifichiamo dunque le predizioni del modello confrontandole con i dati osservati del campione corrente:\n\npp_check(fit_2)\n\n\n\n\n\n\n\nNel caso presente, vi è una buona corrispondenza tra i dati simulati dal modello e i dati osservati.\nIl grafico seguente analizza gli errori del modello rispetto alla retta di regressione stimata.\n\npp_check(fit_1, type = \"error_scatter_avg\")\n\n\n\n\n\n\n\nQuesto comando utilizza la funzione pp_check() per produrre un grafico che mostra i residui bayesiani, ovvero le differenze tra i dati osservati e quelli predetti dal modello. Nel tipo specifico di grafico scelto (\"error_scatter_avg\"), i residui sono rappresentati rispetto ai valori predetti, consentendo di valutare visivamente se sono distribuiti in modo uniforme.\nDal grafico, si osserva che i residui bayesiani appaiono distribuiti in modo omogeneo rispetto alla retta di regressione (che non è direttamente mostrata nel grafico). Questo suggerisce che:\n\nIl modello cattura correttamente la relazione tra la variabile predittiva e la variabile di risposta.\nNon ci sono pattern sistematici nei residui, come deviazioni non lineari o variazioni della dispersione (eteroschedasticità).\n\nSe fossero presenti pattern evidenti nei residui (ad esempio, una struttura curva o una variazione sistematica della dispersione), ciò indicherebbe che il modello potrebbe non essere adeguato, richiedendo una rivalutazione della sua struttura (ad esempio, aggiungendo termini non lineari o trasformando le variabili).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html#regressione-robusta",
    "href": "chapters/linear_models/04_synt_sugar.html#regressione-robusta",
    "title": "63  Zucchero sintattico",
    "section": "\n63.8 Regressione Robusta",
    "text": "63.8 Regressione Robusta\nIn questa sezione introduciamo la regressione robusta. Lo scopo è quello di mostrare quanto sia facile modificare il modello definito da brm per specificare una diversa distribuzione degli errori. Questo non è possibile nel caso dell’approccio frequentista.\nI modelli robusti sono utili in presenza di outlier. Ad esempio, introduciamo un outlier nei dati:\n\ndf_outlier &lt;- df\ndf_outlier$height[1] &lt;- 400\ndf_outlier$weight_c[1] &lt;- -25\n\n\ndf_outlier |&gt; \n  ggplot(aes(x = weight_c, y = height)) +\n    geom_point() +  \n    labs(x = \"Weight\", y = \"Height\") \n\n\n\n\n\n\n\nNotiamo come la presenza di un solo outlier introduce una distorsione nei risultati:\n\nfit_3 = brm(\n  bf(height ~ 1 + weight_c, center = FALSE), \n  prior = prior_guassian,\n  data = df_outlier, \n  backend = \"cmdstanr\", \n  silent = 0\n)\n\n\ndraws &lt;- posterior::as_draws(fit_3, variable = \"^b_\", regex = TRUE)\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 2 × 5\n#&gt;   variable       mean    sd mcse_mean mcse_sd\n#&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 b_Intercept 155.    0.795   0.0116  0.0122 \n#&gt; 2 b_weight_c    0.466 0.123   0.00183 0.00192\n\nSenza il valore outlier, la stima di beta è circa 0.9.\nAdattiamo ora un modello robusto utilizzando una distribuzione \\(t\\) di Student:\n\nfit_4 = brm(\n  bf(height ~ 1 + weight_c, center = FALSE), \n  prior = prior_guassian,\n  family = student(),\n  data = df_outlier, \n  backend = \"cmdstanr\", \n  silent = 0\n)\n\nI risultati mostrano che il modello \\(t\\) è meno influenzato dagli outlier rispetto al modello gaussiano.\n\ndraws &lt;- posterior::as_draws(fit_4, variable = \"^b_\", regex = TRUE)\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 2 × 5\n#&gt;   variable       mean     sd mcse_mean  mcse_sd\n#&gt;   &lt;chr&gt;         &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 b_Intercept 155.    0.256   0.00413  0.00410 \n#&gt; 2 b_weight_c    0.928 0.0392  0.000654 0.000634\n\nIl parametro \\(\\nu\\) della \\(t\\) di Student viene stimato dal modello. Nel caso presente\n\ndraws &lt;- posterior::as_draws(fit_4, variable = \"nu\")\nposterior::summarise_draws(draws, \"mean\", \"sd\", \"mcse_mean\", \"mcse_sd\")\n#&gt; # A tibble: 1 × 5\n#&gt;   variable  mean    sd mcse_mean mcse_sd\n#&gt;   &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 nu        4.24 0.825    0.0147  0.0146\n\nCon un parametro \\(\\nu=4\\), la distribuzione \\(t\\) di Student presenta code molto più pesanti rispetto a una gaussiana. Questo la rende più robusta nel gestire la presenza di outliers rispetto al modello gaussiano.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html#indice-di-determinazione-bayesiano",
    "href": "chapters/linear_models/04_synt_sugar.html#indice-di-determinazione-bayesiano",
    "title": "63  Zucchero sintattico",
    "section": "\n63.9 Indice di Determinazione Bayesiano",
    "text": "63.9 Indice di Determinazione Bayesiano\nCon il pacchetto brms, possiamo calcolare il Bayes \\(R^2\\), che rappresenta l’equivalente bayesiano del classico indice di determinazione \\(R^2\\). Questo indice quantifica la proporzione di varianza spiegata dal modello, tenendo conto dell’incertezza intrinseca delle stime bayesiane.\nIl comando per calcolarlo è:\n\nbayes_R2(fit_2)\n#&gt;    Estimate Est.Error   Q2.5  Q97.5\n#&gt; R2    0.568   0.02331 0.5198 0.6085\n\nIl comando restituisce un tibble (una tabella ordinata) con le seguenti informazioni:\n\n\nEstimate: La stima media del Bayes \\(R^2\\), cioè la proporzione di varianza spiegata dal modello, basata sulle distribuzioni a posteriori dei parametri.\n\nEst.Error: L’errore standard associato alla stima del \\(R^2\\).\n\nQ2.5 e Q97.5: I limiti inferiore e superiore dell’intervallo di credibilità al 95% per il Bayes \\(R^2\\). Questi valori indicano l’incertezza sul \\(R^2\\), riflettendo la distribuzione a posteriori.\n\nNel caso presente\n\n\nStima del \\(R^2\\): Il modello spiega in media circa il 57% della varianza osservata nella variabile dipendente.\n\nErrore Standard: L’incertezza sulla stima è relativamente bassa (±0.02).\n\nIntervallo di Credibilità: C’è un 95% di probabilità che il vero valore del \\(R^2\\) si trovi tra 0.52 e 0.61.\n\n\n63.9.1 Differenze rispetto al Frequentista \\(R^2\\)\n\n\n\nIncertezza: Il Bayes \\(R^2\\) include un’intera distribuzione a posteriori, permettendo di rappresentare l’incertezza attraverso l’intervallo di credibilità. Questo non è possibile con il \\(R^2\\) frequentista, che fornisce una stima puntuale.\n\nPriors: Il Bayes \\(R^2\\) è influenzato dai priors scelti per i parametri del modello, il che consente una maggiore flessibilità e incorpora conoscenze preesistenti.\n\nIn conclusione, il Bayes \\(R^2\\) è uno strumento potente per valutare l’adattamento di un modello bayesiano, permettendo di quantificare non solo la proporzione di varianza spiegata, ma anche l’incertezza associata alla stima.\n\nr2_draws &lt;- bayes_R2(fit_2, summary = FALSE)\n\n\nr2_df &lt;- data.frame(R2 = as.numeric(r2_draws))\n\n\nggplot(r2_df, aes(x = R2)) +\n  geom_density(fill = \"skyblue\", alpha = 0.6) +\n  geom_rug(alpha = 0.2) +\n  labs(\n    title = \"Distribuzione a posteriori di R²\",\n    x = expression(R^2),\n    y = \"Densità\"\n  ) \n\n\n\n\n\n\n\n\nround(quantile(r2_df$R2, probs = c(.025, .5, .975)), 3)\n#&gt;  2.5%   50% 97.5% \n#&gt; 0.520 0.569 0.609\n\nLo stesso risultato si ottiene con la funzione mcmc_areas() di bayesplot:\n\nmcmc_areas(r2_draws, prob = 0.95) +\n  ggtitle(\"Posterior di R² (area = 95% CI)\")",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html#approfondimento-sulla-manipolazione-della-distribuzione-a-posteriori-con-brms",
    "href": "chapters/linear_models/04_synt_sugar.html#approfondimento-sulla-manipolazione-della-distribuzione-a-posteriori-con-brms",
    "title": "63  Zucchero sintattico",
    "section": "\n63.10 Approfondimento sulla manipolazione della distribuzione a posteriori con brms\n",
    "text": "63.10 Approfondimento sulla manipolazione della distribuzione a posteriori con brms\n\nDi seguito illustriamo come accedere e manipolare i campioni generati dal modello bayesiano in brms. Supponiamo di aver costruito un modello lineare semplice, dove vogliamo predire la variabile height in funzione di weight_c:\nfit_2 = brm(\n  bf(height ~ 1 + weight_c, center = FALSE), \n  prior = prior_guassian,\n  data = df, \n  backend = \"cmdstanr\", \n  silent = 0\n)\nUna volta che il modello è stato adattato e abbiamo ottenuto l’oggetto fit_2, possiamo estrarre le draws (ossia i campioni) della distribuzione a posteriori tramite la funzione as_draws():\n\nposterior_2 &lt;- as_draws(fit_2)\n\nL’oggetto posterior_2 ottenuto è di tipo draws (una struttura definita dal pacchetto posterior), che internamente può essere rappresentato come una lista o un array in cui sono memorizzati i campioni MCMC:\n\nstr(posterior_2)\n#&gt; List of 4\n#&gt;  $ 1:List of 5\n#&gt;   ..$ b_Intercept: num [1:1000] 154 154 155 154 154 ...\n#&gt;   ..$ b_weight_c : num [1:1000] 0.955 0.95 0.962 0.969 0.905 ...\n#&gt;   ..$ sigma      : num [1:1000] 5.42 5.31 5.54 5.4 5.22 ...\n#&gt;   ..$ lprior     : num [1:1000] -8.76 -8.75 -8.78 -8.76 -8.72 ...\n#&gt;   ..$ lp__       : num [1:1000] -1080 -1080 -1081 -1081 -1078 ...\n#&gt;  $ 2:List of 5\n#&gt;   ..$ b_Intercept: num [1:1000] 155 155 155 155 154 ...\n#&gt;   ..$ b_weight_c : num [1:1000] 0.922 0.804 0.933 0.933 0.925 ...\n#&gt;   ..$ sigma      : num [1:1000] 4.88 5.11 5 5 5.2 ...\n#&gt;   ..$ lprior     : num [1:1000] -8.61 -8.67 -8.67 -8.67 -8.75 ...\n#&gt;   ..$ lp__       : num [1:1000] -1082 -1081 -1078 -1078 -1082 ...\n#&gt;  $ 3:List of 5\n#&gt;   ..$ b_Intercept: num [1:1000] 154 154 154 155 155 ...\n#&gt;   ..$ b_weight_c : num [1:1000] 0.841 0.87 0.861 0.976 0.97 ...\n#&gt;   ..$ sigma      : num [1:1000] 5.2 5.08 5.06 5.17 5.31 ...\n#&gt;   ..$ lprior     : num [1:1000] -8.71 -8.7 -8.68 -8.69 -8.71 ...\n#&gt;   ..$ lp__       : num [1:1000] -1080 -1079 -1079 -1080 -1081 ...\n#&gt;  $ 4:List of 5\n#&gt;   ..$ b_Intercept: num [1:1000] 154 155 154 155 154 ...\n#&gt;   ..$ b_weight_c : num [1:1000] 0.821 0.981 0.863 0.933 0.954 ...\n#&gt;   ..$ sigma      : num [1:1000] 5.04 5.15 5.2 5.13 5 ...\n#&gt;   ..$ lprior     : num [1:1000] -8.69 -8.69 -8.72 -8.68 -8.68 ...\n#&gt;   ..$ lp__       : num [1:1000] -1081 -1080 -1079 -1079 -1079 ...\n#&gt;  - attr(*, \"class\")= chr [1:3] \"draws_list\" \"draws\" \"list\"\n\nQuesta ispezione ci permette di vedere che l’oggetto contiene le catene e i parametri campionati.\nPossiamo estrarre i nomi dei parametri del modello dall’oggetto creato da brm() nel modo seguente:\n\nvariables(fit_2)\n#&gt; [1] \"b_Intercept\" \"b_weight_c\"  \"sigma\"       \"lprior\"      \"lp__\"\n\nNel nostro esempio, siamo interessati al coefficiente di regressione associato a weight_c, che in brms è etichettato come b_weight_c. Per semplificare la manipolazione e l’analisi, possiamo servirci di tidybayes, un pacchetto che fornisce funzioni utili per trasformare i campioni in formati “tidy”.\n\nb_slope_draws &lt;- posterior_2 |&gt; \n  spread_draws(b_weight_c)\n\nLa funzione spread_draws() estrae e “srotola” le draw dei parametri in un tibble, che risulta più comodo da esplorare:\n\nhead(b_slope_draws)\n#&gt; # A tibble: 6 × 4\n#&gt;   .chain .iteration .draw b_weight_c\n#&gt;    &lt;int&gt;      &lt;int&gt; &lt;int&gt;      &lt;dbl&gt;\n#&gt; 1      1          1     1      0.955\n#&gt; 2      1          2     2      0.950\n#&gt; 3      1          3     3      0.962\n#&gt; 4      1          4     4      0.969\n#&gt; 5      1          5     5      0.905\n#&gt; 6      1          6     6      0.888\n\nIn questo modo, ogni riga corrisponde a un singolo campione della catena MCMC, per quel parametro.\nUna volta estratti i campioni del parametro di interesse (qui b_weight_c), possiamo calcolare facilmente statistiche come quantili e medie:\n\nquantile(b_slope_draws$b_weight_c, probs = c(0.03, 0.50, 0.97))\n#&gt;     3%    50%    97% \n#&gt; 0.8263 0.9037 0.9839\n\n\nmean(b_slope_draws$b_weight_c)\n#&gt; [1] 0.9047\n\n\nI quantili a 0.03, 0.50 e 0.97 forniscono, rispettivamente, un limite inferiore al 94% (0.03–0.97), la mediana a posteriori (0.50) e un limite superiore.\n\nLa funzione mean() restituisce la media a posteriori del coefficiente, un’altra statistica utile per la stima puntuale.\n\nPer comprendere meglio la forma della distribuzione a posteriori, è buona prassi tracciarne la densità. Con tidyverse e tidybayes, possiamo creare un grafico elegante in poche righe:\n\ntibble(beta = b_slope_draws$b_weight_c) %&gt;%\n  ggplot(aes(x = beta)) +\n  stat_halfeye(fill = \"skyblue\", alpha = 0.6) +\n  labs(\n    title = \"Distribuzione a posteriori di β (b_weight_c)\",\n    x = \"Valore di β\",\n    y = \"Densità a posteriori\"\n  )\n\n\n\n\n\n\n\n\n\nstat_halfeye() mostra la densità stimata dei campioni, evidenziando in modo intuitivo i valori più probabili.\n\nIl colore e l’alpha permettono di personalizzare l’aspetto del grafico.\n\nIn sintesi, utilizzando l’oggetto restituito da brm() e la funzione as_draws(), possiamo estrarre i campioni della distribuzione a posteriori e analizzare:\n\n\nstatistiche di sintesi, come media, mediana e quantili;\n\ndistribuzioni di densità, per una visualizzazione più immediata della variabilità e della forma della distribuzione a posteriori di un parametro.\n\nLa combinazione di posterior, tidybayes e tidyverse rende l’intero flusso di lavoro — dall’estrazione dei campioni fino alla creazione di grafici e statistiche — semplice e flessibile.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html#riflessioni-conclusive",
    "href": "chapters/linear_models/04_synt_sugar.html#riflessioni-conclusive",
    "title": "63  Zucchero sintattico",
    "section": "\n63.11 Riflessioni Conclusive",
    "text": "63.11 Riflessioni Conclusive\nQuesto capitolo ha mostrato come utilizzare brms per costruire e interpretare modelli lineari, evidenziando le sue capacità di gestione dei priors, diagnostica e modellizzazione robusta. Grazie alla sua semplicità e flessibilità, brms rappresenta un potente strumento per l’inferenza bayesiana.\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nModello base\nImporta il dataset Howell_18.csv, filtra gli individui di età ≥ 18 anni e adatta un modello bayesiano lineare height ∼ weight usando brm(). Visualizza il sommario.\nCentraggio del predittore\nCalcola la variabile centrata weight_c e adatta il modello height ∼ weight_c. Confronta l’intercetta (b_Intercept) con quella del modello non centrato. Spiega la differenza.\n\nSpecificazione dei prior\nUsa get_prior() per recuperare i prior di default, poi definisci manualmente prior debolmente informativi:\n\nIntercept ∼ Normal(150, 20)\nweight_c ∼ Normal(0, 10)\nsigma ∼ Cauchy(0, 5)\n\nAdatta il modello con questi prior e confronta le stime a posteriori con quelle del modello con prior di default.\n\n\nPredizioni predittive a posteriori\nPer il modello con prior personalizzati:\n\nEsegui pp_check() per la densità e per l’errore medio (type = \"error_scatter_avg\").\nDescrivi brevemente cosa mostrano i due grafici.\n\n\n\nModello robusto\nIntroduci un outlier modificando il primo record: imposta height = 400.\n\nAdatta prima un modello gaussiano e poi uno robusto con family = student().\nConfronta le stime di b_weight_c nei due modelli e discuti l’impatto dell’outlier.\n\n\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n\n\nModello base\nlibrary(brms)\ndf &lt;- rio::import(\"data/Howell_18.csv\")\ndf_adults &lt;- subset(df, age &gt;= 18)\nfit_base &lt;- brm(height ~ weight, data = df_adults, backend = \"cmdstanr\")\nsummary(fit_base)\n\n\nCentraggio del predittore\ndf_adults$weight_c &lt;- df_adults$weight - mean(df_adults$weight)\nfit_centered &lt;- brm(height ~ weight_c, data = df_adults, backend = \"cmdstanr\")\nsummary(fit_centered)\n\nIl b_Intercept nel modello non centrato è l’altezza prevista per peso = 0 (non interpretabile realisticamente).\n\nNel modello centrato, l’intercetta rappresenta l’altezza media alla media del peso del campione.\n\n\n\nSpecificazione dei prior\nget_prior(height ~ weight_c, data = df_adults)\n\npriors_custom &lt;- c(\n  prior(normal(150, 20), class = \"b\", coef = \"Intercept\"),\n  prior(normal(0, 10), class = \"b\", coef = \"weight_c\"),\n  prior(cauchy(0, 5), class = \"sigma\")\n)\nfit_priors &lt;- brm(\n  height ~ weight_c,\n  data = df_adults,\n  prior = priors_custom,\n  backend = \"cmdstanr\"\n)\nsummary(fit_priors)\n\nLe stime a posteriori rimangono simili, ma i prior personalizzati influenzano leggermente l’incertezza.\n\n\n\nPredizioni predittive a posteriori\npp_check(fit_priors)\npp_check(fit_priors, type = \"error_scatter_avg\")\n\nIl grafico di densità mostra se la distribuzione simulata riproduce quella osservata.\n\nIl grafico degli errori media evidenzia eventuali pattern sistematici nei residui.\n\n\n\nModello robusto\ndf_out &lt;- df_adults\ndf_out$height[1] &lt;- 400\nfit_gauss &lt;- brm(height ~ weight_c, data = df_out, backend = \"cmdstanr\")\nfit_student &lt;- brm(height ~ weight_c, family = student(),\n                   data = df_out, backend = \"cmdstanr\")\nsummary(fit_gauss)$fixed[\"weight_c\", ]\nsummary(fit_student)$fixed[\"weight_c\", ]\n\nIl modello gaussiano vede una variazione marcata di b_weight_c a causa dell’outlier.\n\nIl modello Student stima un coefficiente più vicino al valore senza outlier, dimostrando robustezza.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/04_synt_sugar.html#informazioni-sullambiente-di-sviluppo",
    "title": "63  Zucchero sintattico",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] tidybayes_3.0.7  cmdstanr_0.9.0   posterior_1.6.1  brms_2.22.0     \n#&gt;  [5] Rcpp_1.0.14      thematic_0.1.7   MetBrewer_0.2.0  ggokabeito_0.1.0\n#&gt;  [9] see_0.11.0       gridExtra_2.3    patchwork_1.3.0  bayesplot_1.13.0\n#&gt; [13] psych_2.5.3      scales_1.4.0     markdown_2.0     knitr_1.50      \n#&gt; [17] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [21] purrr_1.0.4      readr_2.1.5      tidyr_1.3.1      tibble_3.3.0    \n#&gt; [25] ggplot2_3.5.2    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] mnormt_2.1.1         inline_0.3.21        sandwich_3.1-1      \n#&gt;  [4] rlang_1.1.6          magrittr_2.0.3       multcomp_1.4-28     \n#&gt;  [7] ggridges_0.5.6       matrixStats_1.5.0    compiler_4.5.0      \n#&gt; [10] loo_2.8.0            reshape2_1.4.4       vctrs_0.6.5         \n#&gt; [13] pkgconfig_2.0.3      arrayhelpers_1.1-0   fastmap_1.2.0       \n#&gt; [16] backports_1.5.0      labeling_0.4.3       utf8_1.2.6          \n#&gt; [19] rmarkdown_2.29       tzdb_0.5.0           ps_1.9.1            \n#&gt; [22] xfun_0.52            jsonlite_2.0.0       parallel_4.5.0      \n#&gt; [25] R6_2.6.1             stringi_1.8.7        RColorBrewer_1.1-3  \n#&gt; [28] StanHeaders_2.32.10  estimability_1.5.1   rstan_2.32.7        \n#&gt; [31] zoo_1.8-14           pacman_0.5.1         R.utils_2.13.0      \n#&gt; [34] Matrix_1.7-3         splines_4.5.0        timechange_0.3.0    \n#&gt; [37] tidyselect_1.2.1     rstudioapi_0.17.1    abind_1.4-8         \n#&gt; [40] yaml_2.3.10          codetools_0.2-20     curl_6.3.0          \n#&gt; [43] processx_3.8.6       pkgbuild_1.4.8       plyr_1.8.9          \n#&gt; [46] lattice_0.22-7       withr_3.0.2          bridgesampling_1.1-2\n#&gt; [49] coda_0.19-4.1        evaluate_1.0.4       survival_3.8-3      \n#&gt; [52] RcppParallel_5.1.10  ggdist_3.3.3         pillar_1.10.2       \n#&gt; [55] tensorA_0.36.2.1     checkmate_2.3.2      stats4_4.5.0        \n#&gt; [58] distributional_0.5.0 generics_0.1.4       rprojroot_2.0.4     \n#&gt; [61] hms_1.1.3            rstantools_2.4.0     xtable_1.8-4        \n#&gt; [64] glue_1.8.0           emmeans_1.11.1       tools_4.5.0         \n#&gt; [67] data.table_1.17.6    mvtnorm_1.3-3        grid_4.5.0          \n#&gt; [70] QuickJSR_1.8.0       colorspace_2.1-1     nlme_3.1-168        \n#&gt; [73] cli_3.6.5            svUnit_1.0.6         Brobdingnag_1.2-9   \n#&gt; [76] V8_6.0.4             gtable_0.3.6         R.methodsS3_1.8.2   \n#&gt; [79] digest_0.6.37        TH.data_1.1-3        htmlwidgets_1.6.4   \n#&gt; [82] farver_2.1.2         htmltools_0.5.8.1    R.oo_1.27.1         \n#&gt; [85] lifecycle_1.0.4      MASS_7.3-65",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html#bibliografia",
    "href": "chapters/linear_models/04_synt_sugar.html#bibliografia",
    "title": "63  Zucchero sintattico",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlter, U., Too, M. A., & Cribbie, R. A. (2025). Navigating the Bayes maze: The psychologist’s guide to Bayesian statistics, a hands-on tutorial with R code. International Journal of Psychology, 60(1), e13271.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nWilkinson, G., & Rogers, C. (1973). Symbolic description of factorial models for analysis of variance. Journal of the Royal Statistical Society Series C: Applied Statistics, 22(3), 392–399.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04a_stan_regression.html",
    "href": "chapters/linear_models/04a_stan_regression.html",
    "title": "64  Regressione lineare in Stan",
    "section": "",
    "text": "Introduzione\nStan permette di costruire modelli di regressione che vanno dalla semplice regressione lineare ai modelli lineari generalizzati multilivello.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>Regressione lineare in Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04a_stan_regression.html#il-caso-più-semplice-regressione-lineare-con-un-predittore",
    "href": "chapters/linear_models/04a_stan_regression.html#il-caso-più-semplice-regressione-lineare-con-un-predittore",
    "title": "64  Regressione lineare in Stan",
    "section": "\n64.1 Il caso più semplice: regressione lineare con un predittore",
    "text": "64.1 Il caso più semplice: regressione lineare con un predittore\nConsideriamo il caso di una regressione lineare molto semplice, con un solo predittore, un’intercetta (\\(\\alpha\\)), un coefficiente di pendenza (\\(\\beta\\)) e un termine di errore normalmente distribuito con deviazione standard \\(\\sigma\\). Nella notazione standard della regressione, il modello è:\n\\[\ny_n = \\alpha + \\beta \\, x_n + \\varepsilon_n, \\quad \\varepsilon_n \\sim \\mathcal{N}(0, \\sigma) .\n\\]\nIn Stan, la forma più compatta di questo modello si scrive così:\ndata {\n  int&lt;lower=0&gt; N;     // numero di osservazioni\n  vector[N] x;        // predittore\n  vector[N] y;        // variabile risposta\n}\nparameters {\n  real alpha;         // intercetta\n  real beta;          // coefficiente di pendenza\n  real&lt;lower=0&gt; sigma; // deviazione standard dell’errore\n}\nmodel {\n  y ~ normal(alpha + beta * x, sigma);\n}\nIn questo modello:\n\n\nN è il numero di osservazioni;\nper ogni osservazione abbiamo un valore di x (predittore) e un valore di y (variabile risposta);\n\nalpha è l’intercetta e beta la pendenza;\n\nsigma rappresenta la deviazione standard del termine di errore, che si assume distribuito normalmente.\n\nLe variabili alpha e beta hanno un prior improprio (cioè non specificato esplicitamente), mentre sigma è vincolato ad assumere valori non negativi.\n\n64.1.1 Notazione matriciale e vettorializzazione\nLa riga:\ny ~ normal(alpha + beta * x, sigma);\nè vettorializzata, cioè calcola la probabilità di tutte le osservazioni in un’unica istruzione. È equivalente a scrivere:\nfor (n in 1:N) {\n  y[n] ~ normal(alpha + beta * x[n], sigma);\n}\nLa forma vettorializzata è più compatta e molto più veloce da eseguire. In Stan, quando un argomento di una distribuzione è un vettore, anche gli altri argomenti possono esserlo (purché abbiano la stessa dimensione) oppure possono essere scalari (in tal caso vengono “riciclati” per tutte le osservazioni).\nOra estendiamo il ragionamento al caso in cui i predittori siano più di uno, così da introdurre il concetto di effetto parziale.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>Regressione lineare in Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04a_stan_regression.html#il-modello-di-regressione-multipla-in-notazione-matriciale",
    "href": "chapters/linear_models/04a_stan_regression.html#il-modello-di-regressione-multipla-in-notazione-matriciale",
    "title": "64  Regressione lineare in Stan",
    "section": "\n64.2 Il modello di regressione multipla in notazione matriciale",
    "text": "64.2 Il modello di regressione multipla in notazione matriciale\nQuando abbiamo più predittori per ciascuna osservazione, possiamo scrivere il modello di regressione in forma vettoriale/matriciale (Caudek & Luccio, 2001).\nIn forma compatta, il modello è:\n\\[\n\\mathbf{y} = \\mathbf{X} \\, \\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon}\n\\]\ndove:\n\n\n\\(\\mathbf{y}\\) è un vettore colonna di dimensione \\(N \\times 1\\), che contiene la variabile risposta per le \\(N\\) osservazioni;\n\n\\(\\mathbf{X}\\) è una matrice \\(N \\times K\\), dove ogni riga corrisponde a un’osservazione e ogni colonna a un predittore (la prima colonna, se presente, è di 1 e serve per l’intercetta);\n\n\\(\\boldsymbol{\\beta}\\) è un vettore colonna di dimensione \\(K \\times 1\\), che contiene i coefficienti del modello (inclusa l’intercetta se la colonna di 1 è presente in \\(\\mathbf{X}\\));\n\n\\(\\boldsymbol{\\varepsilon}\\) è un vettore \\(N \\times 1\\) di errori casuali, che assumiamo distribuiti come \\(\\mathcal{N}(0, \\sigma^2)\\).\n\n\n\n\n\n\n\n\n\nNotazione matematica\nSignificato\nOggetto in Stan\nDichiarazione Stan\n\n\n\n\\(\\mathbf{y}\\)\nVettore colonna degli esiti (variabile risposta)\ny\nvector[N] y;\n\n\n\\(\\mathbf{X}\\)\nMatrice dei predittori (N osservazioni × K predittori)\nx\nmatrix[N, K] x;\n\n\n\\(\\boldsymbol{\\beta}\\)\nVettore colonna dei coefficienti di regressione\nbeta\nvector[K] beta;\n\n\n\\(\\beta_0\\)\nIntercetta\nalpha\nreal alpha;\n\n\n\\(\\sigma\\)\nDeviazione standard dell’errore\nsigma\nreal&lt;lower=0&gt; sigma;\n\n\n\\(\\hat{\\mathbf{y}} = \\mathbf{X} \\boldsymbol{\\beta} + \\beta_0\\)\nVettore delle predizioni lineari\nx * beta + alpha\nEspressione all’interno del modello Stan\n\n\n\\(\\boldsymbol{\\varepsilon}\\)\nVettore degli errori casuali\n—\nImplicito nella distribuzione normal(..., sigma)\n\n\n\n\n\n64.2.1 Sviluppo riga per riga\nScrivendo esplicitamente il contenuto della moltiplicazione \\(\\mathbf{X} \\, \\boldsymbol{\\beta}\\), otteniamo:\n\\[\n\\begin{bmatrix}\ny_{1} \\\\\ny_{2} \\\\\n\\vdots \\\\\ny_{N}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n1 & x_{11} & x_{12} & \\dots & x_{1,K-1} \\\\\n1 & x_{21} & x_{22} & \\dots & x_{2,K-1} \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n1 & x_{N1} & x_{N2} & \\dots & x_{N,K-1}\n\\end{bmatrix}\n\\begin{bmatrix}\n\\beta_{0} \\\\\n\\beta_{1} \\\\\n\\beta_{2} \\\\\n\\vdots \\\\\n\\beta_{K-1}\n\\end{bmatrix}\n+\n\\begin{bmatrix}\n\\varepsilon_{1} \\\\\n\\varepsilon_{2} \\\\\n\\vdots \\\\\n\\varepsilon_{N}\n\\end{bmatrix}\n\\]\n\n64.2.2 Interpretazione\n\n\nOgni riga della matrice \\(\\mathbf{X}\\) contiene i valori dei predittori per una singola osservazione.\n\nLa stessa colonna di \\(\\boldsymbol{\\beta}\\) (cioè lo stesso coefficiente) si applica a tutte le righe, moltiplicando il rispettivo valore del predittore.\nIl termine \\(\\beta_0\\) è l’intercetta: è costante e si applica a tutte le osservazioni.\nLa moltiplicazione \\(\\mathbf{X} \\, \\boldsymbol{\\beta}\\) produce un vettore \\(N \\times 1\\) di valori previsti (\\(\\hat{y}\\)), uno per ogni osservazione.\nGli errori \\(\\boldsymbol{\\varepsilon}\\) rappresentano la differenza tra il valore osservato \\(y_i\\) e il valore previsto \\(\\hat{y}_i\\).\n\n64.2.3 Esempio numerico\nSe \\(N=3\\) e \\(K=3\\) (intercetta + 2 predittori), abbiamo:\n\\[\n\\underbrace{\\begin{bmatrix}\ny_{1} \\\\ y_{2} \\\\ y_{3}\n\\end{bmatrix}}_{\\mathbf{y}}\n=\n\\underbrace{\\begin{bmatrix}\n1 & x_{11} & x_{12} \\\\\n1 & x_{21} & x_{22} \\\\\n1 & x_{31} & x_{32}\n\\end{bmatrix}}_{\\mathbf{X}}\n\\underbrace{\\begin{bmatrix}\n\\beta_{0} \\\\ \\beta_{1} \\\\ \\beta_{2}\n\\end{bmatrix}}_{\\boldsymbol{\\beta}}\n+\n\\underbrace{\\begin{bmatrix}\n\\varepsilon_{1} \\\\ \\varepsilon_{2} \\\\ \\varepsilon_{3}\n\\end{bmatrix}}_{\\boldsymbol{\\varepsilon}}\n\\]\nIl che equivale a:\n\\[\n\\begin{cases}\ny_{1} = \\beta_0 + \\beta_1 x_{11} + \\beta_2 x_{12} + \\varepsilon_{1} \\\\\ny_{2} = \\beta_0 + \\beta_1 x_{21} + \\beta_2 x_{22} + \\varepsilon_{2} \\\\\ny_{3} = \\beta_0 + \\beta_1 x_{31} + \\beta_2 x_{32} + \\varepsilon_{3}\n\\end{cases}\n\\]\n\n64.2.4 Interpretazione dei coefficienti parziali di regressione\nIn un modello di regressione multipla ogni coefficiente \\(\\beta_j\\) rappresenta l’effetto parziale del predittore \\(x_j\\) sulla variabile risposta \\(y\\), tenendo costanti (cioè controllando per) gli altri predittori inclusi nel modello.\n\n\nEffetto parziale: \\(\\beta_j\\) indica di quanto ci si attende che cambi \\(y\\) in media se \\(x_j\\) aumenta di una unità, mentre tutti gli altri predittori del modello restano invariati.\n\nUnità di misura: l’interpretazione è sempre nella scala originale di \\(y\\) e \\(x_j\\) (se non abbiamo standardizzato).\n\nSegno: positivo se, a parità degli altri predittori, un aumento di \\(x_j\\) è associato a un aumento di \\(y\\); negativo se associato a una diminuzione.\n\n\n64.2.4.1 Differenza con la regressione bivariata\nSe stimiamo un modello bivariato (cioè con un solo predittore per volta), il coefficiente di regressione di \\(x_j\\) rappresenta l’associazione totale tra \\(x_j\\) e \\(y\\), senza tenere conto di altri fattori. Questo può essere fuorviante quando i predittori sono correlati tra loro e/o esiste un predittore \\(x_k\\) che spiega parte della stessa varianza di \\(y\\) che spiega \\(x_j\\).\nIn questi casi:\n\n\nModello bivariato: il coefficiente di \\(x_j\\) include anche l’effetto “indiretto” dovuto alla sua correlazione con altri predittori.\n\nModello multiplo: il coefficiente di \\(x_j\\) è “depurato” dagli effetti degli altri predittori, cioè riflette l’associazione residua unica di \\(x_j\\) con \\(y\\).\n\n64.2.4.2 Esempio numerico\nImmaginiamo di voler prevedere punteggi di ansia (\\(y\\)) a partire da:\n\n\nstress percepito (\\(x_1\\), scala 0–10),\n\nore di sonno (\\(x_2\\), scala 0–10).\n\n\nset.seed(42)\nN &lt;- 2000\nrho &lt;- 0.8\n\nx1 &lt;- rnorm(N, 0, 1)\nz  &lt;- rnorm(N, 0, 1)\nx2 &lt;- rho * x1 + sqrt(1 - rho^2) * z  # cor(x1, x2) ~ 0.8\n\nbeta1_true &lt;-  1\nbeta2_true &lt;- -2\nsigma_true &lt;-  0.5\n\ny &lt;- beta1_true * x1 + beta2_true * x2 + rnorm(N, 0, sigma_true)\n\nSe \\(x_1\\) e \\(x_2\\) sono correlati (chi dorme poco tende anche a percepire più stress), allora:\n\nNel modello bivariato \\(y \\sim x_1\\), il coefficiente di \\(x_1\\) cattura sia l’effetto diretto dello stress sia quello indiretto dovuto al fatto che più stress → meno sonno → più ansia.\nNel modello di regressione multipla \\(y \\sim x_1 + x_2\\), il coefficiente di \\(x_1\\) misura solo la variazione di ansia associata a un aumento di stress a parità di ore di sonno.\n\nIn sintesi:\n\ni coefficienti bivariati misurano l’associazione totale tra predittore e risposta,\ni coefficienti parziali misurano l’associazione unica (al netto degli altri predittori),\nla differenza tra i due diventa rilevante quando i predittori sono correlati.\n\n\n\n\n\n\n\nConfronto pratico tra coefficienti bivariati e parziali\n\n\n\n\n\nUsiamo i dati simulati dell’esempio del distress (y, x1, x2) per stimare:\n\n\nModelli bivariati: un predittore per volta (y ~ x1 e y ~ x2).\n\nModello multiplo: entrambi i predittori (y ~ x1 + x2).\n\n\n# Modelli bivariati\nfit_biv_x1 &lt;- lm(y ~ x1)\nfit_biv_x2 &lt;- lm(y ~ x2)\n\n# Modello multiplo\nfit_mult &lt;- lm(y ~ x1 + x2)\n\n# Confronto dei coefficienti\ncoefs &lt;- data.frame(\n  Modello = c(\"Bivariato x1\", \"Bivariato x2\", \"Multiplo\"),\n  beta_x1 = c(coef(fit_biv_x1)[\"x1\"], NA, coef(fit_mult)[\"x1\"]),\n  beta_x2 = c(NA, coef(fit_biv_x2)[\"x2\"], coef(fit_mult)[\"x2\"])\n)\ncoefs\n#&gt;        Modello beta_x1 beta_x2\n#&gt; 1 Bivariato x1 -0.6185      NA\n#&gt; 2 Bivariato x2      NA  -1.215\n#&gt; 3     Multiplo  1.0169  -2.017\n\n\n\n\n\n\n\n\n\n\nQuando i predittori sono molto correlati: cambio di segno nel bivariato\n\n\n\n\n\nPer illustrare gli effetti della collinearità e della specificazione del modello, simuliamo un caso in cui i predittori sono fortemente correlati e gli effetti “veri” sono opposti. Vedremo che nel modello bivariato il coefficiente di x1 può addirittura cambiare segno, mentre nel modello multiplo recupera il segno corretto (effetto parziale).\nIdea della simulazione\n\nFacciamo x1 ~ N(0,1).\nCostruiamo x2 altamente correlata con x1 (es. ρ = 0.8): x2 = ρ*x1 + sqrt(1-ρ^2)*z.\nGeneriamo l’esito con effetti veri opposti: y = 1*x1 + (-2)*x2 + errore.\n\nCon questi valori, il coefficiente bivariato di x1 in y ~ x1 si approssima a:\n\\[\n\\hat\\beta^{(biv)}_{x1} \\approx \\beta_1 + \\beta_2 \\frac{\\operatorname{Cov}(x_1, x_2)}{\\operatorname{Var}(x_1)}\n= 1 + (-2)\\cdot \\rho = 1 - 2\\rho .\n\\]\nSe \\(\\rho=0.8\\), allora \\(1 - 2\\cdot 0.8 = -0.6\\): cambio di segno atteso nel bivariato.\n\n# Stime\nm_biv_x1 &lt;- lm(y ~ x1)\nm_biv_x2 &lt;- lm(y ~ x2)\nm_mult   &lt;- lm(y ~ x1 + x2)\n\nout &lt;- data.frame(\n  Modello = c(\"Bivariato x1\", \"Bivariato x2\", \"Multiplo\"),\n  beta_x1 = c(coef(m_biv_x1)[\"x1\"], NA, coef(m_mult)[\"x1\"]),\n  beta_x2 = c(NA, coef(m_biv_x2)[\"x2\"], coef(m_mult)[\"x2\"])\n)\nout\n#&gt;        Modello beta_x1 beta_x2\n#&gt; 1 Bivariato x1 -0.6185      NA\n#&gt; 2 Bivariato x2      NA  -1.215\n#&gt; 3     Multiplo  1.0169  -2.017\n\nCosa osserviamo\n\nNel modello bivariato y ~ x1 il coefficiente di x1 risulta negativo (≈ −0.6), nonostante il vero effetto di x1 sia positivo (+1).\nNel modello di regressione multipla y ~ x1 + x2 i coefficienti recuperano i valori veri (≈ +1 per x1, ≈ −2 per x2): questo è l’effetto parziale.\n\nIl cambio di segno nel bivariato è un esempio di bias da variabile omessa: stimare y ~ x1 quando x2 ha un effetto su y ed è correlata con x1 fa sì che la stima di x1 assorba (in parte o in tutto) l’effetto di x2. Matematicamente, la stima bivariata è uguale all’effetto vero più una correzione proporzionale alla correlazione tra i predittori. La formula del bias (per il modello bivariato) è:\n\\[\n\\mathbb{E}\\!\\left[\\hat\\beta^{(biv)}_{x1}\\right]\n= \\beta_1 + \\beta_2 \\frac{\\operatorname{Cov}(x_1, x_2)}{\\operatorname{Var}(x_1)} .\n\\]\nQuando \\(\\beta_2\\) e \\(\\operatorname{Cov}(x_1,x_2)\\) hanno segni opposti e grande ampiezza, la correzione può superare \\(\\beta_1\\) e invertire il segno.\nMessaggio didattico: i coefficienti bivariati misurano associazioni totali e possono essere fuorvianti in presenza di predittori correlati. I coefficienti parziali del modello multiplo sono più appropriati per l’interpretazione causale/condizionale (a parità degli altri predittori).\nIn psicologia questo scenario non è raro: per esempio, includere o escludere una variabile di controllo come il livello socioeconomico può cambiare sostanzialmente la stima dell’effetto di altre variabili come stress o supporto sociale.\n\n\n\n\n\n\n\n\n\nCome funziona la moltiplicazione tra matrici (ripasso essenziale)\n\n\n\n\n\nConformabilità. Due matrici si possono moltiplicare solo se il numero di colonne della prima coincide con il numero di righe della seconda. Se \\(A\\) è \\(m \\times k\\) e \\(B\\) è \\(k \\times n\\), allora il prodotto \\(C = A B\\) esiste ed è una matrice di dimensione \\(m \\times n\\).\nElemento \\(c_{ij}\\). L’elemento sulla riga \\(i\\) e colonna \\(j\\) di \\(C\\) si ottiene come prodotto scalare tra:\n\nla riga \\(i\\)-esima di \\(A\\) e\nla colonna \\(j\\)-esima di \\(B\\).\n\nPer prodotto scalare intendiamo: somma dei prodotti degli elementi corrispondenti.\nFormalmente,\n\\[\nc_{ij} \\;=\\; \\sum_{t=1}^{k} a_{i t}\\, b_{t j}.\n\\]\nEsempio numerico.\nSiano\n\\[\nA=\\begin{bmatrix}\n1 & 2 & 3\\\\\n4 & 5 & 6\n\\end{bmatrix}\n\\quad (2\\times 3), \\qquad\nB=\\begin{bmatrix}\n1 & 0\\\\\n-1 & 2\\\\\n2 & 1\n\\end{bmatrix}\n\\quad (3\\times 2).\n\\]\nSono conformabili (3 colonne di \\(A\\) = 3 righe di \\(B\\)). Il prodotto \\(C=AB\\) sarà \\(2\\times 2\\).\nCalcoliamo i singoli elementi:\n\n\\(c_{11} = [1,2,3]\\cdot[1,-1,2]^\\top = 1\\cdot 1 + 2\\cdot(-1) + 3\\cdot 2 = 1 - 2 + 6 = 5\\)\n\\(c_{12} = [1,2,3]\\cdot[0,2,1]^\\top = 1\\cdot 0 + 2\\cdot 2 + 3\\cdot 1 = 0 + 4 + 3 = 7\\)\n\\(c_{21} = [4,5,6]\\cdot[1,-1,2]^\\top = 4\\cdot 1 + 5\\cdot(-1) + 6\\cdot 2 = 4 - 5 + 12 = 11\\)\n\\(c_{22} = [4,5,6]\\cdot[0,2,1]^\\top = 4\\cdot 0 + 5\\cdot 2 + 6\\cdot 1 = 0 + 10 + 6 = 16\\)\n\nQuindi\n\\[\nC=AB=\\begin{bmatrix}\n5 & 7\\\\\n11 & 16\n\\end{bmatrix}.\n\\]\nVerifica in R.\n\nA &lt;- matrix(c(1,2,3, 4,5,6), nrow = 2, byrow = TRUE)\nB &lt;- matrix(c(1,0, -1,2, 2,1), nrow = 3, byrow = TRUE)\nA %*% B\n#&gt;      [,1] [,2]\n#&gt; [1,]    5    7\n#&gt; [2,]   11   16\n\n\n\n\n\n64.2.5 Regressione con più predittori in Stan\nCon più predittori, anche in Stan possiamo usare la notazione matriciale:\ndata {\n  int&lt;lower=0&gt; N;       // numero di osservazioni\n  int&lt;lower=0&gt; K;       // numero di predittori\n  matrix[N, K] x;       // matrice dei predittori\n  vector[N] y;          // variabile risposta\n}\nparameters {\n  real alpha;           // intercetta\n  vector[K] beta;       // coefficienti di regressione\n  real&lt;lower=0&gt; sigma;  // deviazione standard dell’errore\n}\nmodel {\n  y ~ normal(x * beta + alpha, sigma);\n}\nQui:\n\n\nx è una matrice N × K di predittori;\n\nbeta è un vettore con K coefficienti;\n\nx * beta produce un vettore di N valori predetti;\naggiungendo alpha otteniamo la previsione completa per ogni osservazione.\n\nAnche in questo caso la forma vettorializzata è equivalente a:\nfor (n in 1:N) {\n  y[n] ~ normal(x[n] * beta + alpha, sigma);\n}\n\n64.2.6 Intercetta come colonna della matrice dei predittori\nSe preferiamo non dichiarare un parametro separato per l’intercetta (alpha), possiamo inserire una colonna di 1 come prima colonna della matrice x. In questo caso il primo elemento di beta (beta[1]) fungerà da intercetta.\nSe però vogliamo assegnare un prior diverso all’intercetta rispetto agli altri coefficienti, è meglio dichiarare alpha come parametro separato. Questo è anche leggermente più efficiente, ma la differenza di velocità è trascurabile: la scelta va fatta per chiarezza del codice.\n\n64.2.7 Esempio numerico\nPer fare un esempio concreto, ipotizziamo che l’esito \\(y\\) sia un punteggio di distress su scala 0–100. I due predittori sono:\n\n\n\\(x_1\\): affetto negativo istantaneo su scala 0–10 (più alto = più negativo);\n\n\\(x_2\\): ore di sonno nell’ultima notte su scala 0–10.\n\nPer rendere l’esempio realistico, supponiamo che:\n\na parità di altre condizioni, aumentare l’affetto negativo di 1 punto (su 0–10) faccia crescere il distress di qualche punto (effetto positivo);\n\ndormire di più riduca il distress (effetto negativo);\nil livello medio di distress a affetto negativo medio e sonno medio sia moderato.\n\n1) Simulazione dei dati.\n\nset.seed(123)\n\nN &lt;- 200\n# Predittori su scala \"naturale\"\nx1 &lt;- pmin(pmax(rnorm(N, mean = 5, sd = 2), 0), 10)   # Affetto negativo (0-10)\nx2 &lt;- pmin(pmax(rnorm(N, mean = 7, sd = 1.5), 0), 10) # Ore di sonno (0-10)\n\n# Veri parametri (sconosciuti allo stimatore)\nalpha_true &lt;- 20        # baseline di distress a x1=5, x2=7 circa\nbeta1_true &lt;- 4         # +4 punti distress per +1 punto di affetto negativo\nbeta2_true &lt;- -3        # -3 punti distress per +1 ora di sonno\nsigma_true &lt;- 8         # rumore/residuo (DS)\n\n# Generazione dell'esito\ny &lt;- alpha_true + beta1_true * x1 + beta2_true * x2 + rnorm(N, 0, sigma_true)\n\n# Controllo rapide statistiche\nsummary(data.frame(y, x1, x2))\n#&gt;        y               x1               x2       \n#&gt;  Min.   :-11.9   Min.   : 0.382   Min.   : 3.30  \n#&gt;  1st Qu.: 10.6   1st Qu.: 3.748   1st Qu.: 6.11  \n#&gt;  Median : 20.2   Median : 4.883   Median : 7.03  \n#&gt;  Mean   : 19.0   Mean   : 4.975   Mean   : 7.05  \n#&gt;  3rd Qu.: 27.1   3rd Qu.: 6.137   3rd Qu.: 8.07  \n#&gt;  Max.   : 59.6   Max.   :10.000   Max.   :10.00\n\n2) Modello Stan.\nLavoriamo senza standardizzare le variabili. Questo ci consente di specificare prior direttamente interpretabili nelle unità psicologiche originali, evitando di dover ricondurre mentalmente i coefficienti a scale standardizzate.\n\nstancode &lt;- \"\ndata {\n  int&lt;lower=1&gt; N;\n  vector[N] x1;       // affetto negativo (0-10)\n  vector[N] x2;       // ore di sonno (0-10)\n  vector[N] y;        // distress (0-100)\n}\nparameters {\n  real alpha;              // intercetta (baseline distress)\n  vector[2] beta;          // beta[1]=effetto x1, beta[2]=effetto x2\n  real&lt;lower=0&gt; sigma;     // DS dell'errore\n}\nmodel {\n  // PRIORS informativi ma prudenti (scala grezza)\n  alpha ~ normal(20, 20);     // baseline tipica, DS ampia\n  beta[1] ~ normal(4, 2);     // NA: aumento atteso +4 distress per +1 punto\n  beta[2] ~ normal(-3, 2);    // Sonno: riduzione attesa -3 distress per +1 ora\n  sigma ~ student_t(4, 0, 10); // Rumore: DS ~5-15, tolleranza outlier\n\n  // LIKELIHOOD vettorializzato\n  y ~ normal(alpha + beta[1] * x1 + beta[2] * x2, sigma);\n}\ngenerated quantities {\n  vector[N] y_rep; // repliche per PPC\n  for (n in 1:N)\n    y_rep[n] = normal_rng(alpha + beta[1]*x1[n] + beta[2]*x2[n], sigma);\n}\n\"\n\n3) Compilazione del modello.\n\nstanmod &lt;- cmdstan_model(\n  write_stan_file(stancode),\n  compile = TRUE\n)\n\n4) Dati di input per Stan.\n\ndata_list &lt;- list(N = N, x1 = x1, x2 = x2, y = y)\n\n5) Campionamento.\n\nfit &lt;- stanmod$sample(\n  data = data_list,\n  seed = 2025,\n  chains = 4, parallel_chains = 4,\n  iter_warmup = 1000, iter_sampling = 2000\n)\n\n6) Confronto tra parametri veri e stime a posteriori.\n\npost_sum &lt;- fit$summary(variables = c(\"alpha\", \"beta[1]\", \"beta[2]\", \"sigma\"))\npost_sum\n#&gt; # A tibble: 4 × 10\n#&gt;   variable  mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 alpha    22.87  22.86  3.01  2.97 17.94 27.85  1.00  3261.06  3703.23\n#&gt; 2 beta[1]   3.85   3.85  0.29  0.29  3.37  4.33  1.00  4837.34  4324.04\n#&gt; 3 beta[2]  -3.26  -3.26  0.37  0.36 -3.88 -2.66  1.00  3952.02  4078.60\n#&gt; 4 sigma     7.78   7.76  0.40  0.39  7.15  8.47  1.00  5233.37  4444.49\n\ntrue_vals &lt;- data.frame(\n  parameter = c(\"alpha\", \"beta[1]\", \"beta[2]\", \"sigma\"),\n  true = c(20, 4, -3, 8)\n)\ntrue_vals\n#&gt;   parameter true\n#&gt; 1     alpha   20\n#&gt; 2   beta[1]    4\n#&gt; 3   beta[2]   -3\n#&gt; 4     sigma    8\n\nInterpretazione: Se i posterior mean per beta[1] e beta[2] risultano vicini a 4 e -3, e gli intervalli di credibilità li includono, il modello sta recuperando bene i valori simulati. Lavorare su scala grezza rende i coefficienti subito leggibili:\n\n\nbeta[1]: “+1 punto di NA → +4 punti di distress”,\n\nbeta[2]: “+1 ora di sonno → −3 punti di distress”.\n\n\n\n\n\n\n\nCome scegliere prior informativi in psicologia\n\n\n\n\n\nLavorare nella scala originale consente di definire prior direttamente interpretabili. La scelta dovrebbe basarsi su:\n\n\nScala di misura: specificare i prior nelle stesse unità delle variabili (es. punti su una scala 0–10 o 0–100).\n\nConoscenze pregresse: dati di studi precedenti, letteratura o esperienza clinica.\n\nPrudenza: scegliere deviazioni standard sufficientemente ampie da includere valori plausibili ma meno probabili.\n\nRobustezza: per i parametri di scala, preferire distribuzioni a code più pesanti (es. Student-t) quando si sospetta la presenza di outlier.\n\nApplicazione all’esempio del distress:\n\n\n\n\n\n\n\n\nParametro\nInterpretazione psicologica\nPrior scelto\nMotivazione\n\n\n\nalpha\nDistress medio in baseline (NA e sonno medi)\nnormal(20, 20)\nCopre un range ampio, tipico di campioni non clinici\n\n\nbeta[1]\nEffetto dell’affetto negativo (0–10)\nnormal(4, 2)\nAtteso aumento di ~4 punti distress per +1 NA, con incertezza\n\n\nbeta[2]\nEffetto delle ore di sonno (0–10)\nnormal(-3, 2)\nAttesa riduzione di ~3 punti distress per +1 ora di sonno\n\n\nsigma\nDS residua (0–100)\nstudent_t(4, 0, 10)\nCopre DS comuni 5–15, code pesanti per outlier\n\n\n\n\n\n\n7) Controllo predittivo posteriore.\n\ny_rep_mat &lt;- posterior::as_draws_matrix(fit$draws(\"y_rep\"))\nbayesplot::ppc_dens_overlay(data_list$y, y_rep_mat[1:100, ])\n\n\n\n\n\n\n\nSe le curve replicate si sovrappongono bene alla distribuzione osservata di \\(y\\), il modello ha una buona calibrazione predittiva.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>Regressione lineare in Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04a_stan_regression.html#riflessioni-conclusive",
    "href": "chapters/linear_models/04a_stan_regression.html#riflessioni-conclusive",
    "title": "64  Regressione lineare in Stan",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo visto come esprimere la regressione lineare in Stan, partendo dal caso con un solo predittore fino ad arrivare al modello multiplo in notazione matriciale. Abbiamo introdotto la distinzione tra coefficiente bivariato e coefficiente parziale, chiarendo perché in un contesto con predittori correlati il secondo fornisca un’informazione più precisa e interpretativamente solida.\nDal punto di vista pratico, abbiamo:\n\nsimulato dati psicologici plausibili su scala grezza, evitando la standardizzazione per mantenere l’interpretazione diretta dei coefficienti;\ndiscusso la scelta di prior informativi ma prudenziali derivati da conoscenze precedenti, illustrando il legame tra teoria psicologica e specificazione del modello;\neseguito il modello in Stan via CmdStanR, verificando la capacità di recuperare i parametri simulati;\neffettuato un controllo predittivo posteriore per confrontare distribuzioni osservate e replicate.\n\nQuesto approccio ha permesso di vedere l’intero flusso di lavoro: dalla formulazione teorica del modello alla sua implementazione computazionale, fino alla valutazione della bontà di adattamento.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>Regressione lineare in Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04a_stan_regression.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/04a_stan_regression.html#informazioni-sullambiente-di-sviluppo",
    "title": "64  Regressione lineare in Stan",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] cmdstanr_0.9.0        pillar_1.11.0         tinytable_0.11.0     \n#&gt;  [4] conflicted_1.2.0      patchwork_1.3.1       ggdist_3.3.3         \n#&gt;  [7] tidybayes_3.0.7       bayesplot_1.13.0      ggplot2_3.5.2        \n#&gt; [10] reliabilitydiag_0.2.1 priorsense_1.1.0      posterior_1.6.1      \n#&gt; [13] loo_2.8.0             rstan_2.32.7          StanHeaders_2.32.10  \n#&gt; [16] brms_2.22.0           Rcpp_1.1.0            janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.6         tidyselect_1.2.1     farver_2.1.2        \n#&gt;  [4] fastmap_1.2.0        TH.data_1.1-3        tensorA_0.36.2.1    \n#&gt;  [7] pacman_0.5.1         digest_0.6.37        estimability_1.5.1  \n#&gt; [10] timechange_0.3.0     lifecycle_1.0.4      processx_3.8.6      \n#&gt; [13] survival_3.8-3       magrittr_2.0.3       compiler_4.5.1      \n#&gt; [16] rlang_1.1.6          tools_4.5.1          utf8_1.2.6          \n#&gt; [19] yaml_2.3.10          data.table_1.17.8    knitr_1.50          \n#&gt; [22] labeling_0.4.3       bridgesampling_1.1-2 htmlwidgets_1.6.4   \n#&gt; [25] pkgbuild_1.4.8       curl_6.4.0           plyr_1.8.9          \n#&gt; [28] RColorBrewer_1.1-3   multcomp_1.4-28      abind_1.4-8         \n#&gt; [31] withr_3.0.2          purrr_1.1.0          grid_4.5.1          \n#&gt; [34] stats4_4.5.1         xtable_1.8-4         colorspace_2.1-1    \n#&gt; [37] inline_0.3.21        emmeans_1.11.2       scales_1.4.0        \n#&gt; [40] MASS_7.3-65          cli_3.6.5            mvtnorm_1.3-3       \n#&gt; [43] rmarkdown_2.29       generics_0.1.4       RcppParallel_5.1.10 \n#&gt; [46] reshape2_1.4.4       cachem_1.1.0         stringr_1.5.1       \n#&gt; [49] splines_4.5.1        parallel_4.5.1       vctrs_0.6.5         \n#&gt; [52] V8_6.0.5             Matrix_1.7-3         sandwich_3.1-1      \n#&gt; [55] jsonlite_2.0.0       arrayhelpers_1.1-0   glue_1.8.0          \n#&gt; [58] ps_1.9.1             codetools_0.2-20     distributional_0.5.0\n#&gt; [61] lubridate_1.9.4      stringi_1.8.7        gtable_0.3.6        \n#&gt; [64] QuickJSR_1.8.0       htmltools_0.5.8.1    Brobdingnag_1.2-9   \n#&gt; [67] R6_2.6.1             rprojroot_2.1.0      evaluate_1.0.4      \n#&gt; [70] lattice_0.22-7       backports_1.5.0      memoise_2.0.1       \n#&gt; [73] broom_1.0.9          snakecase_0.11.1     rstantools_2.4.0    \n#&gt; [76] coda_0.19-4.1        gridExtra_2.3        nlme_3.1-168        \n#&gt; [79] checkmate_2.3.2      xfun_0.52            zoo_1.8-14          \n#&gt; [82] pkgconfig_2.0.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>Regressione lineare in Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04a_stan_regression.html#bibliografia",
    "href": "chapters/linear_models/04a_stan_regression.html#bibliografia",
    "title": "64  Regressione lineare in Stan",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nCaudek, C., & Luccio, R. (2001). Statistica per psicologi (III rist. 2023, Vol. 11, p. 320). Laterza.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>Regressione lineare in Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html",
    "href": "chapters/linear_models/05_one_mean.html",
    "title": "65  Inferenza bayesiana su una media",
    "section": "",
    "text": "65.1 Preparazione del Notebook\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, posterior, bayestestR, brms, ggdist, conflicted)\n\nconflicts_prefer(stats::sd)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#introduzione",
    "href": "chapters/linear_models/05_one_mean.html#introduzione",
    "title": "65  Inferenza bayesiana su una media",
    "section": "Introduzione",
    "text": "Introduzione\nIn questo capitolo ci occuperemo di un tema classico in statistica: come inferire la media di una popolazione a partire da un campione di dati quantitativi. Si tratta di una situazione che incontriamo spesso in psicologia, ad esempio quando vogliamo stimare l’altezza media, il livello medio di ansia, o la soddisfazione media in un certo gruppo di persone. Tuttavia, anziché affrontare questo problema nel modo tradizionale, qui lo considereremo da una prospettiva più ampia e moderna, che mette al centro due concetti fondamentali per la psicologia scientifica: variabilità e incertezza.\n\n65.1.1 La variabilità come punto di partenza\nOgni volta che raccogliamo dati psicologici, ci confrontiamo inevitabilmente con la variabilità. Alcune differenze sono tra individui:\nVariabilità inter-individuale: ad esempio, quanto differiscono tra loro le altezze, i tempi di reazione o i livelli di benessere soggettivo?\nAltre differenze sono all’interno dello stesso individuo, anche se meno visibili in un singolo rilevamento:\nVariabilità intra-individuale: quanto potrebbe variare la risposta della stessa persona se la misurassimo in momenti diversi della giornata, o in giorni diversi? Anche quando non la osserviamo direttamente, la variabilità intra-individuale è sempre una componente latente del dato psicologico, e ci invita a riflettere sulle fonti di instabilità e fluttuazione nei comportamenti e negli stati mentali.\n\n65.1.2 L’incertezza come oggetto dell’inferenza\nA partire da questa variabilità, vogliamo formulare inferenze sul valore medio di un certo parametro (come l’altezza media in una popolazione). Ma ogni inferenza è anche un atto di stima incerta: nessun campione ci dà la verità, ma solo una gamma di possibilità più o meno plausibili.\nIn questo capitolo affronteremo quindi il problema dell’inferenza sulla media da due prospettive complementari:\n\n\nApproccio frequentista: basato sull’idea di ripetizione del campionamento e sul calcolo di un intervallo di confidenza;\n\nApproccio bayesiano: che assume esplicitamente l’incertezza e la rappresenta attraverso una distribuzione di probabilità (la distribuzione a posteriori).\n\n65.1.3 Perché usare brms?\nInvece di derivare la distribuzione a posteriori della media in modo analitico (come nei modelli con prior coniugati), useremo il pacchetto brms, che si basa su un potente algoritmo di campionamento chiamato NUTS (No-U-Turn Sampler). Questo ci permetterà di stimare numericamente l’intera distribuzione a posteriori della media e della variabilità, anche in casi in cui il calcolo analitico sarebbe difficile o impossibile. In questo modo, potremo:\n\nquantificare l’incertezza su ciò che ci interessa (ad esempio: qual è l’altezza media? con quanta certezza lo possiamo dire?);\nvisualizzare in modo intuitivo l’effetto dei dati e dei priori sulle nostre stime;\navvicinarci a un modo di pensare statistico più adatto alla complessità della psicologia, dove ogni dato è il risultato di molte fonti di variabilità.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#il-modello-normale-un-primo-passo-nella-descrizione-della-variabilità",
    "href": "chapters/linear_models/05_one_mean.html#il-modello-normale-un-primo-passo-nella-descrizione-della-variabilità",
    "title": "65  Inferenza bayesiana su una media",
    "section": "\n65.2 Il modello Normale: un primo passo nella descrizione della variabilità",
    "text": "65.2 Il modello Normale: un primo passo nella descrizione della variabilità\nQuando parliamo di altezza, ansia, tempo di reazione o qualsiasi altra variabile psicologica continua, un punto di partenza comune è il modello Normale. Questo modello assume che le osservazioni siano distribuite attorno a un valore medio, con una certa dispersione. In termini formali, diciamo che ogni osservazione \\(y_n\\) è generata da una distribuzione Normale con media \\(\\mu\\) e deviazione standard \\(\\sigma\\):\n\\[\ny_n \\;\\sim\\; \\mathcal N\\bigl(\\mu, \\sigma\\bigr).\n\\]\nNel linguaggio dell’inferenza, \\(\\mu\\) rappresenta il valore centrale che vogliamo stimare, mentre \\(\\sigma\\) quantifica la variabilità delle osservazioni rispetto a quel centro. Entrambi i parametri sono ignoti, e l’obiettivo dell’inferenza è proprio descrivere l’incertezza che abbiamo su di essi.\nNel capitolo precedente abbiamo visto come calcolare la distribuzione a posteriori di questi parametri in modo analitico, quando si utilizzano prior coniugati. In questo capitolo, invece, riprendiamo lo stesso problema, ma adottiamo un approccio più generale e flessibile: stimiamo il modello usando il pacchetto brms, che utilizza metodi MCMC per approssimare la distribuzione a posteriori, anche quando non esistono soluzioni chiuse.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#un-esempio-concreto-la-variabilità-dellaltezza-nei-kung-san",
    "href": "chapters/linear_models/05_one_mean.html#un-esempio-concreto-la-variabilità-dellaltezza-nei-kung-san",
    "title": "65  Inferenza bayesiana su una media",
    "section": "\n65.3 Un esempio concreto: la variabilità dell’altezza nei !Kung San",
    "text": "65.3 Un esempio concreto: la variabilità dell’altezza nei !Kung San\nPer rendere più concreto il problema, useremo un dataset storico: i dati raccolti da Nancy Howell tra la fine degli anni ’60 presso i !Kung San, una popolazione del deserto del Kalahari con uno stile di vita basato su caccia e raccolta.\nI dati che utilizzeremo riportano le altezze di individui adulti (con età superiore ai 18 anni). Questo esempio è tratto da McElreath (2020), ed è ideale per iniziare a riflettere sulla variabilità inter-individuale.\n\ndf &lt;- rio::import(here::here(\"data\", \"Howell_18.csv\"))\ndf |&gt; head()\n#&gt;   height weight age male\n#&gt; 1  151.8  47.83  63    1\n#&gt; 2  139.7  36.49  63    0\n#&gt; 3  136.5  31.86  65    0\n#&gt; 4  156.8  53.04  41    1\n#&gt; 5  145.4  41.28  51    0\n#&gt; 6  163.8  62.99  35    1\n\nIl campione è composto da 352 osservazioni:\n\nlength(df$height)\n#&gt; [1] 352\n\n\n65.3.1 Distribuzione osservata dell’altezza\nUna prima esplorazione visiva ci aiuta a capire la forma della distribuzione osservata. L’istogramma seguente mostra come si distribuiscono le altezze nel campione:\n\nggplot(df, aes(x = height)) +\n  geom_histogram(binwidth = 5, color = \"black\", fill = \"lightblue\") +\n  labs(title = \"Distribuzione dell'altezza (cm)\", x = \"Altezza\", y = \"Frequenza\") +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nLa forma appare compatibile con una distribuzione Normale. Ma quanto bene si adatta?\n\ndf |&gt;\n  ggplot(aes(sample = height)) +\n  stat_qq() +\n  stat_qq_line(colour = \"red\") +\n  labs(title = \"Normal Q-Q plot\", x = \"Quantili teorici\", y = \"Valori osservati\") +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nIl Q-Q plot mostra un leggero scostamento: la curva empirica è un po’ più piatta rispetto alla linea teorica, segno che la variabilità osservata è leggermente inferiore a quella attesa da una Normale standard (code meno pesanti). Tuttavia, la discrepanza è modesta, e possiamo comunque usare il modello gaussiano come prima approssimazione della distribuzione dei dati.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#specifica-del-modello-una-distribuzione-per-descrivere-lincertezza",
    "href": "chapters/linear_models/05_one_mean.html#specifica-del-modello-una-distribuzione-per-descrivere-lincertezza",
    "title": "65  Inferenza bayesiana su una media",
    "section": "\n65.4 Specifica del modello: una distribuzione per descrivere l’incertezza",
    "text": "65.4 Specifica del modello: una distribuzione per descrivere l’incertezza\nNel modello bayesiano, ipotizziamo che ogni osservazione \\(y_n\\) sia indipendente e identicamente distribuita (iid):\n\\[\ny_n \\sim \\mathcal N(\\mu, \\sigma),\n\\]\n\n\n\\(\\mu\\): la media vera (ignota) della popolazione.\n\n\\(\\sigma\\): la deviazione standard vera, che misura quanta variabilità c’è tra gli individui.\n\n\nL’assunzione di indipendenza implica che conoscere l’errore commesso su un individuo non ci dice nulla sull’errore commesso su un altro. L’assunzione di identica distribuzione implica che tutti gli individui provengano dalla stessa popolazione.\n\nScrivere \\(y_n \\sim \\mathcal N(\\mu, \\sigma)\\) è quindi un modo compatto per dire che ogni osservazione è un’espressione della variabilità inter-individuale, distribuita attorno a un valore centrale.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#stime-preliminari-una-fotografia-della-variabilità",
    "href": "chapters/linear_models/05_one_mean.html#stime-preliminari-una-fotografia-della-variabilità",
    "title": "65  Inferenza bayesiana su una media",
    "section": "\n65.5 Stime preliminari: una fotografia della variabilità",
    "text": "65.5 Stime preliminari: una fotografia della variabilità\nPrima di definire i priori o stimare la distribuzione a posteriori, è utile esplorare alcune statistiche descrittive:\n\nmean(df$height)   # media campionaria\n#&gt; [1] 154.6\nsd(df$height)     # deviazione standard campionaria\n#&gt; [1] 7.742\n\nQueste due quantità ci offrono una prima “fotografia” della variabilità nel campione:\n\nLa media campionaria è una stima iniziale di \\(\\mu\\), che potrà guidarci nella scelta di una prior realistica.\nLa deviazione standard campionaria è una misura iniziale di \\(\\sigma\\), e descrive quanto le osservazioni si discostano, in media, dalla media.\n\nAnche se queste statistiche non riflettono ancora in modo completo l’incertezza che abbiamo, sono molto utili per:\n\n\nGuidare la scelta dei priors in un’ottica informata;\n\nIndividuare possibili outlier o anomalie, che potrebbero influenzare sia l’inferenza frequentista sia quella bayesiana.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#il-modello-frequentista-stimare-la-media-come-punto-fisso",
    "href": "chapters/linear_models/05_one_mean.html#il-modello-frequentista-stimare-la-media-come-punto-fisso",
    "title": "65  Inferenza bayesiana su una media",
    "section": "\n65.6 Il modello frequentista: stimare la media come punto fisso",
    "text": "65.6 Il modello frequentista: stimare la media come punto fisso\nNel contesto dell’inferenza classica, uno dei modi più semplici per stimare la media di una popolazione consiste nell’adottare un modello lineare senza predittori: un modello che si limita a stimare un’unica quantità, chiamata intercetta. In pratica, questo corrisponde a stimare la media campionaria dei dati osservati.\nIn R, questo modello si specifica in modo molto compatto:\nheight ~ 1\nIl simbolo 1 indica che vogliamo stimare solo l’intercetta, senza nessuna variabile esplicativa. In termini pratici, l’intercetta rappresenta qui la media dell’altezza nel campione.\n\n65.6.1 Specifica e stima del modello\nPossiamo stimare il modello con la funzione lm():\n\nfm1 &lt;- lm(\n  formula = height ~ 1, \n  data = df\n)\n\nQuesto comando applica il metodo della minima somma dei quadrati, producendo una stima puntuale della media, assieme a una misura della sua variabilità.\n\n65.6.2 Interpretare i risultati\nL’output del modello si ottiene con:\n\nsummary(fm1)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = height ~ 1, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -18.072  -6.007  -0.292   6.058  24.473 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)\n#&gt; (Intercept)  154.597      0.413     375   &lt;2e-16\n#&gt; \n#&gt; Residual standard error: 7.74 on 351 degrees of freedom\n\nIl riassunto mostra diverse informazioni, ma le più rilevanti in questo contesto sono:\n\n\nLa stima dell’intercetta \\(\\hat{\\alpha}\\): coincide con la media campionaria delle altezze.\n\nL’errore standard: misura la variabilità attesa della stima \\(\\hat{\\alpha}\\) se ripetessimo il campionamento molte volte.\n\nIl p-value: quantifica la probabilità di osservare un valore della statistica test così estremo (o più) se la media vera fosse 0. In questo caso ha scarso interesse pratico, perché il valore di riferimento (0 cm) non è plausibile.\n\nIl R²: che in assenza di predittori non è interpretabile in modo utile.\n\n65.6.3 Intervallo di confidenza al 95%: una misura indiretta dell’incertezza\nIl modello frequentista non descrive la nostra incertezza come una distribuzione su \\(\\mu\\), ma fornisce invece un intervallo di confidenza, che ha un’interpretazione indiretta: se ripetessimo l’esperimento un numero molto elevato di volte, in circa il 95% dei casi l’intervallo conterrebbe il vero valore della media.\nPossiamo calcolarlo con:\n\nconfint(fm1, level = 0.95)\n#&gt;             2.5 % 97.5 %\n#&gt; (Intercept) 153.8  155.4\n\nQuesto intervallo si basa sulla formula classica:\n\\[\n\\hat{\\alpha} \\pm t_{\\text{df}} \\cdot \\text{SE}(\\hat{\\alpha})\n\\]\ndove:\n\n\n\\(\\hat{\\alpha}\\) è la stima puntuale della media,\n\n\\(t_{\\text{df}}\\) è il quantile della distribuzione t di Student (con \\(n - 1\\) gradi di libertà),\n\n\\(\\text{SE}(\\hat{\\alpha})\\) è l’errore standard della stima.\n\n65.6.4 Calcolo manuale (opzionale)\nSe vogliamo calcolare l’intervallo “a mano”, possiamo scrivere:\n\ncoef(fm1) + c(-1, 1) * qt(0.975, df.residual(fm1)) * 0.413\n#&gt; [1] 153.8 155.4\n\n\n\ncoef(fm1) restituisce la stima dell’intercetta,\n\nqt(0.975, df.residual(fm1)) fornisce il valore critico t,\n\n0.413 è l’errore standard (da sostituire con quello esatto, se disponibile).\n\n65.6.5 Riflessione: cos’è l’incertezza, per davvero?\nNel modello frequentista, l’incertezza sulla media è descritta in termini di variabilità potenziale tra campioni, non come incertezza su un valore specifico. Il parametro \\(\\mu\\) è trattato come fisso ma ignoto, e tutta l’incertezza risiede nella stima che otteniamo da un singolo campione.\nIn questo senso, l’approccio frequentista non fornisce una distribuzione sul parametro: non possiamo dire “la probabilità che la media sia tra 153 e 155 cm è del 95%”, ma solo che “se ripetessimo l’esperimento molte volte, l’intervallo conterrebbe la media vera nel 95% dei casi”.\nNel prossimo paragrafo vedremo come un modello bayesiano offra un’alternativa: trattare \\(\\mu\\) come una variabile aleatoria su cui esprimere direttamente l’incertezza, permettendoci di formulare affermazioni probabilistiche esplicite sui valori possibili del parametro.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#il-modello-bayesiano-descrivere-lincertezza-con-distribuzioni",
    "href": "chapters/linear_models/05_one_mean.html#il-modello-bayesiano-descrivere-lincertezza-con-distribuzioni",
    "title": "65  Inferenza bayesiana su una media",
    "section": "\n65.7 Il modello Bayesiano: descrivere l’incertezza con distribuzioni",
    "text": "65.7 Il modello Bayesiano: descrivere l’incertezza con distribuzioni\nDopo aver stimato la media dell’altezza con il modello frequentista, possiamo affrontare lo stesso problema con un approccio bayesiano, usando il pacchetto brms. Questo ci consente di rappresentare in modo più diretto l’incertezza che abbiamo sui parametri del modello.\nNel framework bayesiano, tutti i parametri sono trattati come variabili aleatorie: invece di stimare un singolo valore per la media, stimiamo una distribuzione a posteriori, che riflette l’incertezza residua dopo aver osservato i dati.\n\n65.7.1 Priori debolmente informativi: quando “non sappiamo molto”\nOgni modello bayesiano richiede la specifica di distribuzioni a priori. Tuttavia, quando non abbiamo conoscenze forti da inserire, possiamo affidarci ai priori debolmente informativi: distribuzioni ampie, generiche e poco vincolanti, che permettono ai dati di “parlare da soli”.\nSe non specifichiamo nulla, brms userà questi prior di default. È un buon punto di partenza, soprattutto per modelli semplici e dataset abbastanza ricchi.\n\n65.7.2 Specifica del modello in brms\n\nIl codice è simile a quello usato con lm():\n\nfm2 &lt;- brm(\n  formula = height ~ 1,       # stima solo l'intercetta (media dell’altezza)\n  family = gaussian(),        # assunzione di distribuzione normale\n  data = df,                  # dataset\n  chains = 4,                 # numero di catene MCMC\n  iter = 2000,                # iterazioni per catena\n  warmup = 1000,              # periodo di adattamento\n  backend = \"cmdstanr\"        # motore di calcolo efficiente\n)\n\nQui stiamo stimando due parametri:\n\n\n\\(\\mu\\) → media dell’altezza nella popolazione;\n\n\\(\\sigma\\) → deviazione standard, che rappresenta quanta variabilità inter-individuale osserviamo.\n\nIn termini formali, il modello è scritto come:\n\\[\ny_i = \\alpha + \\varepsilon_i,\\quad \\varepsilon_i \\sim \\mathcal{N}(0, \\sigma).\n\\]\n\n65.7.3 Interpretare l’output: incertezza esplicitata\nUna volta che il modello è stato stimato, possiamo esaminarne l’output:\n\nsummary(fm2)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: height ~ 1 \n#&gt;    Data: df (Number of observations: 352) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept   154.59      0.41   153.76   155.38 1.00     2728     2202\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     7.77      0.30     7.20     8.37 1.00     3096     2129\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nNel risultato troveremo:\n\n\nMedia della distribuzione a posteriori per \\(\\alpha\\), che è la stima centrale di \\(\\mu\\);\n\nErrore standard a posteriori, cioè quanto fluttua \\(\\mu\\) nei campioni simulati;\n\nIntervallo di credibilità al 95%: l’intervallo in cui cade il 95% della distribuzione a posteriori di \\(\\mu\\).\n\nA differenza dell’intervallo di confidenza frequentista, qui possiamo davvero dire:\n\nC’è il 95% di probabilità che la media dell’altezza si trovi in questo intervallo, dati il modello e i dati osservati.\n\n\n65.7.4 Riportare i risultati: due linguaggi per lo stesso fenomeno\n\n\n\n\n\n\nApproccio\nRisultato\n\n\n\nFrequentista\n“La media stimata è 154.6, con un intervallo di confidenza al 95% tra 153.8 e 155.4.”\n\n\nBayesiano\n“La media stimata a posteriori è 154.6, con un intervallo di credibilità al 95% tra 153.8 e 155.4.”\n\n\n\nNumericamente possono coincidere, ma la logica inferenziale è diversa: nel caso bayesiano, l’intervallo descrive ciò che crediamo plausibile; nel frequentista, ciò che la procedura catturerebbe nella maggior parte dei campioni ripetuti.\n\n65.7.5 Esplorare i campioni a posteriori: guardare l’incertezza in faccia\nDopo aver stimato il modello, possiamo accedere direttamente ai campioni generati dall’algoritmo NUTS:\n\nas_draws_df(fm2) %&gt;% head(3)\n#&gt; # A draws_df: 3 iterations, 1 chains, and 5 variables\n#&gt;   b_Intercept sigma Intercept lprior  lp__\n#&gt; 1         155   8.0       155   -6.1 -1224\n#&gt; 2         155   7.5       155   -6.0 -1224\n#&gt; 3         155   8.1       155   -6.1 -1225\n#&gt; # ... hidden reserved variables {'.chain', '.iteration', '.draw'}\n\nOgni riga della colonna b_Intercept rappresenta un valore plausibile per \\(\\mu\\), estratto dalla sua distribuzione a posteriori. Questi campioni sono il cuore dell’inferenza bayesiana: ci permettono di costruire grafici, intervalli e ragionamenti probabilistici.\n\n65.7.6 Calcoli riassuntivi sui campioni\nPossiamo usare i campioni per calcolare:\n\n# Media a posteriori\nmean(as_draws_df(fm2)$b_Intercept)\n#&gt; [1] 154.6\n\n# Deviazione standard a posteriori\nsd(as_draws_df(fm2)$b_Intercept)\n#&gt; [1] 0.4117\n\n# Intervallo di credibilità al 95%\nquantile(as_draws_df(fm2)$b_Intercept, probs = c(0.025, 0.975))\n#&gt;  2.5% 97.5% \n#&gt; 153.8 155.4\n\n\nQuesti valori sintetizzano l’incertezza associata alla nostra stima della media: non un singolo punto, ma una nuvola di possibilità, tutte compatibili con i dati osservati.\n\n\n65.7.7 Conclusioni intermedie\nAbbiamo visto come:\n\nL’approccio frequentista fornisca una stima puntuale e un intervallo ipotetico di copertura.\nL’approccio bayesiano fornisca una distribuzione completa a posteriori, da cui possiamo derivare medie, intervalli, probabilità e visualizzazioni.\n\nEntrambi gli approcci descrivono la variabilità tra individui, ma il metodo bayesiano offre strumenti più trasparenti per rappresentare l’incertezza sui parametri.\n\nQuesto è particolarmente utile in psicologia, dove campioni ridotti, contesti variabili e differenze individuali richiedono modelli che sappiano dire “quanto (non) sappiamo”.\n\nNel prossimo paragrafo vedremo come possiamo personalizzare i priori, incorporando informazioni pregresse (da studi precedenti, teoria, esperienza clinica…), e come questo possa influenzare l’inferenza nei casi in cui i dati da soli non siano sufficientemente informativi.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#uso-dei-prior-nel-modello-bayesiano-rendere-esplicite-le-ipotesi-sullincertezza",
    "href": "chapters/linear_models/05_one_mean.html#uso-dei-prior-nel-modello-bayesiano-rendere-esplicite-le-ipotesi-sullincertezza",
    "title": "65  Inferenza bayesiana su una media",
    "section": "\n65.8 Uso dei Prior nel Modello Bayesiano: rendere esplicite le ipotesi sull’incertezza",
    "text": "65.8 Uso dei Prior nel Modello Bayesiano: rendere esplicite le ipotesi sull’incertezza\nFinora abbiamo visto che è possibile stimare un modello bayesiano anche senza specificare esplicitamente i prior: in tal caso, brms utilizza prior debolmente informativi, lasciando che siano i dati a guidare l’inferenza.\nMa il cuore dell’approccio bayesiano sta proprio qui: nella possibilità di incorporare conoscenze precedenti, aspettative, risultati di studi precedenti — insomma, di modellare in modo esplicito e trasparente l’incertezza che abbiamo prima di vedere i dati.\n\n65.8.1 Tre domande chiave prima di stimare\nPrima di usare un modello bayesiano, è utile porsi alcune domande fondamentali:\n\nCosa sappiamo già del fenomeno?\nCome possiamo esprimere questa conoscenza sotto forma di distribuzioni?\nQuanto vogliamo che questa conoscenza influenzi l’inferenza?\n\nLa risposta a queste domande guida la scelta dei prior. Nei passaggi che seguono, vedremo come un modello informato da prior realistici possa non solo migliorare la stima, ma anche aumentare la coerenza tra teoria e dati.\n\n65.8.2 Specificare i prior: un esempio concreto\nRiprendiamo il nostro esempio sull’altezza nella popolazione dei !Kung San. Supponiamo di avere un’idea ragionevole su quanto potrebbe essere la media e la variabilità delle altezze.\nPossiamo tradurre questa conoscenza nel linguaggio delle distribuzioni:\n\nPer \\(\\mu\\) (la media), ipotizziamo: \\(\\mu \\sim \\mathcal{N}(181, 30)\\) — una media attesa intorno a 181 cm, con ampio margine di incertezza.\nPer \\(\\sigma\\) (la deviazione standard), ipotizziamo: \\(\\sigma \\sim \\mathcal{N}^+(0, 20)\\) — una normale troncata a destra, che garantisce valori positivi.\n\nQuesti prior sono informativi ma ampi: riflettono aspettative plausibili, senza imporre vincoli troppo rigidi.\n\nMcElreath scherza dicendo di usare come prior la propria altezza. L’ironia nasconde un principio importante: ogni ipotesi è valida, purché dichiarata. Un buon modello bayesiano non finge oggettività, ma esplicita l’incertezza iniziale.\n\n\n65.8.3 Forma del modello con prior espliciti\nIl modello completo si scrive così:\n\\[\n\\begin{aligned}\nY_i &\\sim \\mathcal{N}(\\mu, \\sigma) \\\\\\\\\n\\mu &\\sim \\mathcal{N}(181,\\ 30) \\\\\\\\\n\\sigma &\\sim \\mathcal{N}^+(0,\\ 20)\n\\end{aligned}\n\\]\nQui, sia la media sia la variabilità della popolazione sono trattate come quantità soggette a incertezza. La stima diventa un aggiornamento: partiamo da un’opinione iniziale e la modifichiamo alla luce dei dati.\n\n65.8.4 Implementazione in brms\n\n\nfm3 &lt;- brm(\n  formula = height ~ 1,\n  data    = df,\n  family  = gaussian(),\n  prior   = c(\n    prior(normal(181, 30), class = \"Intercept\"),\n    prior(normal(0, 20), class = \"sigma\")\n  ),\n  chains  = 4, iter = 2000,\n  seed    = 1234,\n  backend = \"cmdstanr\"\n)\n\n\n65.8.5 Analisi dell’output\nUna volta stimato il modello, possiamo esaminarlo come sempre con:\n\nsummary(fm3)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: height ~ 1 \n#&gt;    Data: df (Number of observations: 352) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept   154.60      0.41   153.80   155.41 1.00     3156     2659\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     7.77      0.29     7.20     8.38 1.00     3256     2596\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nSe i dati sono informativi (come in questo caso), l’effetto dei prior sarà contenuto: la distribuzione a posteriori sarà molto simile a quella ottenuta con prior deboli. Questo è un comportamento desiderabile: il prior non deve forzare i risultati, ma integrarsi con essi.\n\n65.8.6 Scegliere il livello dell’intervallo di credibilità\nPossiamo modificare la probabilità coperta dall’intervallo credibile, ad esempio scegliendo un intervallo all’89% anziché al 95%:\n\nsummary(fm3, prob = 0.89)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: height ~ 1 \n#&gt;    Data: df (Number of observations: 352) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-89% CI u-89% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept   154.60      0.41   153.94   155.27 1.00     3156     2659\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-89% CI u-89% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     7.77      0.29     7.32     8.25 1.00     3256     2596\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nQuesta scelta è proposta da McElreath come default per motivi pedagogici: evitare che l’intervallo venga interpretato come test di significatività.\n\n“Why 89%? Because it’s prime.” — è un invito a pensare criticamente alle convenzioni statistiche, e a riflettere su cosa stiamo cercando davvero di comunicare quando riportiamo un intervallo.\n\n\n65.8.7 Cosa otteniamo con prior espliciti?\nUsare prior informativi consente di:\n\nIncorporare conoscenze teoriche, esperienze passate, dati precedenti.\nRendere il modello più robusto quando i dati sono scarsi o rumorosi.\nEvitare stime irrealistiche in contesti con alta incertezza.\nEsplicitare le nostre ipotesi, invece di nasconderle dietro un’apparente neutralità.\n\n65.8.8 Conclusione\nIn un modello bayesiano, ogni assunzione è chiara e trattabile. I risultati non sono semplici numeri, ma distribuzioni di credibilità che raccontano ciò che è plausibile, dato ciò che sapevamo prima e ciò che abbiamo osservato ora.\n\nQuesto rende l’approccio bayesiano particolarmente adatto alla psicologia: un campo dove l’incertezza è la norma, la variabilità è parte del fenomeno da spiegare, e la trasparenza delle assunzioni è fondamentale.\n\nNel prossimo paragrafo, ci concentreremo su come visualizzare e valutare queste distribuzioni a posteriori, usando strumenti diagnostici e grafici che ci aiutano a comprendere — e comunicare — la variabilità residua stimata dal modello.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#visualizzare-lincertezza-con-bayesplot",
    "href": "chapters/linear_models/05_one_mean.html#visualizzare-lincertezza-con-bayesplot",
    "title": "65  Inferenza bayesiana su una media",
    "section": "\n65.9 Visualizzare l’incertezza con bayesplot\n",
    "text": "65.9 Visualizzare l’incertezza con bayesplot\n\nIl pacchetto bayesplot è uno strumento prezioso per ogni analisi bayesiana: permette di esplorare visivamente la variabilità delle stime a posteriori, di diagnosticare l’efficienza del campionamento MCMC e di verificare se il modello riesce a riprodurre i dati osservati.\nIn un contesto psicologico, dove spesso i dati sono rumorosi e le inferenze complesse, poter visualizzare dove e quanto il modello è incerto è fondamentale.\n\n65.9.1 Traceplot: osservare le catene in azione\nIl traceplot mostra l’evoluzione dei campioni per ogni parametro nel corso delle iterazioni MCMC. Serve a controllare:\n\nche le catene siano stazionarie (nessuna deriva sistematica),\nche si mescolino bene (assenza di autocorrelazione),\nche ci sia convergenza (tutte le catene esplorano la stessa distribuzione).\n\n\nmcmc_trace(fm3, pars = c(\"Intercept\", \"sigma\"), facet_args = list(nrow = 2))\n\n\n\n\n\n\n\nUn buon traceplot mostra bande dense, senza tendenze crescenti o oscillazioni lente: questo suggerisce che il campionamento stia catturando in modo affidabile la distribuzione a posteriori.\n\n65.9.2 Densità a posteriori: cosa crediamo dopo aver visto i dati\nPer visualizzare la distribuzione di probabilità di un parametro stimato, possiamo usare:\n\nmcmc_areas(fm3, regex_pars = \"b_Intercept\", prob = 0.89)\n\n\n\n\n\n\n\nQuesta funzione evidenzia l’intervallo credibile in cui cade, ad esempio, l’89% della densità a posteriori per la media dell’altezza.\n\nA differenza dell’intervallo di confidenza, qui possiamo davvero dire che c’è l’89% di probabilità che la media vera sia compresa in quell’intervallo.\n\n\n65.9.3 Distribuzione congiunta di due parametri: incrociare incertezze\nQuando vogliamo esplorare la relazione tra due parametri (ad esempio, media e deviazione standard), possiamo usare:\n\nmcmc_scatter(fm3, pars = c(\"Intercept\", \"sigma\"))\n\n\n\n\n\n\n\nQuesto tipo di visualizzazione è utile per valutare dipendenze tra parametri: ad esempio, se i campioni sono inclinati lungo una diagonale, significa che c’è correlazione a posteriori tra i due.\n\n65.9.4 Posterior Predictive Check: il modello spiega davvero i dati?\nUna delle forze dell’approccio bayesiano è che i modelli sono generativi: possiamo simulare nuovi dati partendo dalle distribuzioni a posteriori e confrontarli con quelli osservati.\n\npp_check(fm3)\n\n\n\n\n\n\n\nLa funzione pp_check() mostra:\n\nin nero: la distribuzione dei dati osservati,\nin colore: più repliche simulate dal modello.\n\nSe le simulazioni coprono bene i dati reali, il modello è coerente con le osservazioni. Se invece ci sono scostamenti sistematici, questo può indicare che:\n\nla distribuzione scelta non è adatta,\nci sono outlier non gestiti,\nmancano variabili esplicative nel modello.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#lapproccio-tradizionale-il-test-t-di-student",
    "href": "chapters/linear_models/05_one_mean.html#lapproccio-tradizionale-il-test-t-di-student",
    "title": "65  Inferenza bayesiana su una media",
    "section": "\n65.10 L’approccio tradizionale: il test t di Student",
    "text": "65.10 L’approccio tradizionale: il test t di Student\nPrima dell’adozione diffusa dei metodi bayesiani, l’inferenza sulla media veniva solitamente effettuata con il test t. Questo approccio assume che la variabilità osservata nel campione (stimata con la deviazione standard campionaria) sia sufficiente a rappresentare l’incertezza sul parametro d’interesse.\nIl calcolo si basa sulla statistica:\n\\[\nT = \\frac{\\bar{X} - \\mu_0}{s / \\sqrt{n}}.\n\\]\nIl test permette di costruire un intervallo di confidenza, ma non di fare affermazioni probabilistiche sui parametri. Il valore \\(\\mu\\) è considerato fisso ma sconosciuto, e l’incertezza è attribuita unicamente al campionamento.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#confronto-tra-approcci-stesso-dato-epistemologie-diverse",
    "href": "chapters/linear_models/05_one_mean.html#confronto-tra-approcci-stesso-dato-epistemologie-diverse",
    "title": "65  Inferenza bayesiana su una media",
    "section": "\n65.11 Confronto tra approcci: stesso dato, epistemologie diverse",
    "text": "65.11 Confronto tra approcci: stesso dato, epistemologie diverse\n\n\n\n\n\n\n\nElemento\nFrequentista\nBayesiano\n\n\n\nConcetto di parametro\nFisso ma ignoto\nVariabile aleatoria\n\n\nIncertezza\nTra campioni\nNei parametri\n\n\nIntervallo (95%)\nProcedura che copre nel 95% dei casi\nCredibilità del 95% sul valore vero\n\n\nEstensione a modelli complessi\nLimitata\nFlessibile\n\n\nTrasparenza delle assunzioni\nImplicita\nEsplicita",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#riflessioni-conclusive-dalla-variabilità-allincertezza",
    "href": "chapters/linear_models/05_one_mean.html#riflessioni-conclusive-dalla-variabilità-allincertezza",
    "title": "65  Inferenza bayesiana su una media",
    "section": "\n65.12 Riflessioni conclusive: dalla variabilità all’incertezza",
    "text": "65.12 Riflessioni conclusive: dalla variabilità all’incertezza\nIn questo capitolo ci siamo concentrati su un caso semplice ma essenziale: la stima della media di una variabile quantitativa. Questo esempio ci ha permesso di mettere a confronto due approcci fondamentali all’inferenza statistica — quello frequentista e quello bayesiano — evidenziandone le differenze concettuali e pratiche.\nNell’approccio frequentista, l’incertezza viene trattata come una proprietà della procedura di stima: non sappiamo quale valore ha il parametro, ma possiamo costruire intervalli che, se ripetessimo l’esperimento molte volte, conterrebbero il valore vero in una certa proporzione dei casi. In questa visione, i parametri sono fissi e ignoti, e tutta l’incertezza risiede nei dati campionari.\nL’approccio bayesiano, al contrario, considera i parametri come quantità soggette a incertezza e quindi descrivibili mediante distribuzioni di probabilità. Dopo aver osservato i dati, otteniamo una distribuzione a posteriori per ogni parametro, che ci permette di esprimere in modo diretto e intuitivo quanto riteniamo plausibili diversi valori del parametro stesso. Possiamo così calcolare non solo medie e deviazioni, ma anche la probabilità che un parametro superi una certa soglia, o che la differenza tra due condizioni sia positiva.\nUn aspetto centrale emerso nel confronto è l’importanza dei prior: nella prospettiva bayesiana, l’inferenza non è mai del tutto “neutra”, ma dipende anche da ciò che sappiamo — o assumiamo — prima di osservare i dati. Quando i dati sono informativi, i risultati bayesiani tendono a convergere con quelli frequentisti. Ma nei casi in cui i dati sono scarsi, rumorosi o ambigui, la scelta dei prior può fare la differenza, offrendo un’ancora razionale che aiuta a stabilizzare le stime e a evitare conclusioni arbitrarie.\nGli strumenti di visualizzazione offerti da bayesplot, in particolare i traceplot, le densità a posteriori e i posterior predictive check, ci aiutano a rendere tangibile questa incertezza, permettendo di controllare se le catene MCMC stanno funzionando correttamente, di esplorare le relazioni tra i parametri e di valutare la capacità del modello di generare dati simili a quelli osservati. In questo senso, il modello bayesiano non è solo un dispositivo inferenziale, ma anche un’interfaccia per riflettere sul legame tra teoria e osservazione.\nTutto ciò assume un significato particolare in psicologia, dove la variabilità tra individui, contesti e momenti è parte integrante del fenomeno da comprendere. Un approccio statistico che rappresenta esplicitamente l’incertezza, invece di nasconderla o ridurla a un test binario, si rivela quindi più adatto a riflettere la complessità reale della disciplina.\nNel prossimi capitoli ci sposteremo dal caso di una sola media al confronto tra due gruppi. Vedremo come l’approccio bayesiano ci permetta di formulare domande più ricche e informative, come: “Qual è la probabilità che il gruppo A abbia una media maggiore del gruppo B?” — domande che superano il tradizionale criterio del “significativo o no”, aprendoci a una comprensione più sfumata e utile delle differenze tra condizioni.\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nObiettivo: Utilizzare i dati dello studio di Tarrats-Pons et al. (2025) per replicare i risultati riportati nella Figura 2 , applicando sia l’approccio frequentista che il framework bayesiano. Calcolare inoltre la grandezza dell’effetto nel contesto bayesiano (Cohen’s \\(d\\)) e generare un grafico che visualizzi la distribuzione a posteriori della grandezza dell’effetto ottenuta.\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(brms)\nlibrary(posterior)\nlibrary(bayestestR)\n\ndf &lt;- read_excel(\n  here::here(\n    \"data\",\n    \"Tarrats-Pons.xlsx\"\n  ),\n  sheet = 3\n)\n\ndf |&gt;\n  group_by(Sample) |&gt;\n  summarize(\n    avg = mean(`CESS-D`),\n    n = n()\n  )\n\ndf_wide &lt;- df %&gt;%\n  select(IdentificationNumber, Sample, CESS_D = `CESS-D`) %&gt;%\n  pivot_wider(\n    names_from = Sample, # da POST/PRE\n    values_from = CESS_D, # i valori da mettere nelle colonne\n    names_prefix = \"CESSD_\" # opzionale, per nominare CESSD_POST, CESSD_PRE\n  )\n\n# Controlla il risultato\nhead(df_wide)\n\ndf_wide$diff &lt;- df_wide$CESSD_PRE - df_wide$CESSD_POST\n\nhist(df_wide$diff)\n\nt.test(df_wide$diff)\n\n# t-test sulle differenze\nres &lt;- t.test(df_wide$diff)\n\n# Numero di soggetti\nn &lt;- length(df_wide$diff)\n\n# Calcolo di Cohen's d\nd_t &lt;- as.numeric(res$statistic) / sqrt(n)\n\n# Mostro risultato\nd_t\n\nfm1 &lt;- brm(\n  formula = diff ~ 1, # Modello con sola intercetta (mu)\n  data = df_wide,\n  family = gaussian(), # Distribuzione Normale\n  prior = c(\n    brms::prior(normal(0, 10), class = \"Intercept\"), # Prior su mu\n    brms::prior(normal(0, 10), class = \"sigma\") # Prior su sigma\n  ),\n  chains = 4,\n  iter = 2000,\n  seed = 1234,\n  backend = \"cmdstanr\"\n)\nsummary(fm1)\npp_check(fm1)\n\nfm2 &lt;- brm(\n  formula = diff ~ 1, # Modello con sola intercetta (mu)\n  data = df_wide,\n  family = student(), # Distribuzione Normale\n  prior = c(\n    brms::prior(normal(0, 10), class = \"Intercept\"), # Prior su mu\n    brms::prior(normal(0, 10), class = \"sigma\") # Prior su sigma\n  ),\n  chains = 4,\n  iter = 2000,\n  seed = 1234,\n  backend = \"cmdstanr\"\n)\nsummary(fm2)\npp_check(fm2)\n\npost_samples &lt;- posterior::as_draws_df(fm1)\nhead(post_samples)\n\npost_samples$effect_size &lt;- post_samples$b_Intercept / post_samples$sigma\n\n# Calcolo diretto delle statistiche dell'effect size\nmean_effect_size &lt;- mean(post_samples$effect_size)\nsd_effect_size &lt;- sd(post_samples$effect_size)\nci_effect_size &lt;- quantile(post_samples$effect_size, probs = c(0.025, 0.975))\n\n# Stampa dei risultati\ncat(\"=== Statistiche dell'Effect Size Bayesiano ===\\n\")\ncat(\"Effect size medio:\", round(mean_effect_size, 2), \"\\n\")\ncat(\"SD dell'effect size:\", round(sd_effect_size, 2), \"\\n\")\ncat(\n  \"Intervallo di credibilità al 95%:\",\n  round(ci_effect_size[1], 2),\n  \"-\",\n  round(ci_effect_size[2], 2),\n  \"\\n\\n\"\n)\n\n# Interpretazione dell'effect size secondo le convenzioni di Cohen\nif (abs(mean_effect_size) &lt; 0.2) {\n  interpretation &lt;- \"piccolo\"\n} else if (abs(mean_effect_size) &lt; 0.5) {\n  interpretation &lt;- \"medio-piccolo\"\n} else if (abs(mean_effect_size) &lt; 0.8) {\n  interpretation &lt;- \"medio\"\n} else {\n  interpretation &lt;- \"grande\"\n}\ncat(\"Interpretazione (Cohen):\", interpretation, \"\\n\")\n\n# Calcola la probabilità che l'effect size sia maggiore di zero\nprob_positive &lt;- mean(post_samples$effect_size &gt; 0)\ncat(\n  \"Probabilità che l'effect size sia positivo:\",\n  round(prob_positive * 100, 2),\n  \"%\\n\"\n)\n\n# Se necessario, calcola probabilità per altre soglie\nprob_medium &lt;- mean(post_samples$effect_size &gt; 0.5)\ncat(\n  \"Probabilità che l'effect size sia &gt; 0.5 (medio):\",\n  round(prob_medium * 100, 2),\n  \"%\\n\"\n)\nprob_large &lt;- mean(post_samples$effect_size &gt; 0.8)\ncat(\n  \"Probabilità che l'effect size sia &gt; 0.8 (grande):\",\n  round(prob_large * 100, 2),\n  \"%\\n\"\n)\n\n# Visualizzazione della distribuzione posteriore dell'effect size\n# (Per eseguire questo blocco, devi avere ggplot2 installato e caricato)\n# library(ggplot2)\nggplot(post_samples, aes(x = effect_size)) +\n  geom_density(fill = \"skyblue\", alpha = 0.5) +\n  geom_vline(\n    xintercept = mean_effect_size,\n    color = \"red\",\n    linetype = \"dashed\"\n  ) +\n  geom_vline(\n    xintercept = ci_effect_size[1],\n    color = \"darkblue\",\n    linetype = \"dotted\"\n  ) +\n  geom_vline(\n    xintercept = ci_effect_size[2],\n    color = \"darkblue\",\n    linetype = \"dotted\"\n  ) +\n  labs(\n    title = \"Distribuzione posteriore dell'Effect Size\",\n    x = \"Effect Size (Cohen's d)\",\n    y = \"Densità\"\n  ) +\n  theme_minimal()",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/05_one_mean.html#informazioni-sullambiente-di-sviluppo",
    "title": "65  Inferenza bayesiana su una media",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] readxl_1.4.5          lubridate_1.9.4       forcats_1.0.0        \n#&gt;  [4] stringr_1.5.1         purrr_1.1.0           readr_2.1.5          \n#&gt;  [7] tidyverse_2.0.0       bayestestR_0.16.1     cmdstanr_0.9.0       \n#&gt; [10] pillar_1.11.0         tinytable_0.11.0      conflicted_1.2.0     \n#&gt; [13] patchwork_1.3.1       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt; [16] bayesplot_1.13.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [19] priorsense_1.1.0      posterior_1.6.1       loo_2.8.0            \n#&gt; [22] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [25] Rcpp_1.1.0            janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [28] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [31] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3        inline_0.3.21        sandwich_3.1-1      \n#&gt;  [4] rlang_1.1.6          magrittr_2.0.3       multcomp_1.4-28     \n#&gt;  [7] snakecase_0.11.1     ggridges_0.5.6       compiler_4.5.1      \n#&gt; [10] reshape2_1.4.4       vctrs_0.6.5          pkgconfig_2.0.3     \n#&gt; [13] arrayhelpers_1.1-0   fastmap_1.2.0        backports_1.5.0     \n#&gt; [16] labeling_0.4.3       utf8_1.2.6           rmarkdown_2.29      \n#&gt; [19] tzdb_0.5.0           ps_1.9.1             xfun_0.52           \n#&gt; [22] cachem_1.1.0         jsonlite_2.0.0       broom_1.0.9         \n#&gt; [25] parallel_4.5.1       R6_2.6.1             stringi_1.8.7       \n#&gt; [28] RColorBrewer_1.1-3   cellranger_1.1.0     estimability_1.5.1  \n#&gt; [31] knitr_1.50           zoo_1.8-14           pacman_0.5.1        \n#&gt; [34] R.utils_2.13.0       Matrix_1.7-3         splines_4.5.1       \n#&gt; [37] timechange_0.3.0     tidyselect_1.2.1     abind_1.4-8         \n#&gt; [40] yaml_2.3.10          codetools_0.2-20     curl_6.4.0          \n#&gt; [43] processx_3.8.6       pkgbuild_1.4.8       plyr_1.8.9          \n#&gt; [46] lattice_0.22-7       withr_3.0.2          bridgesampling_1.1-2\n#&gt; [49] coda_0.19-4.1        evaluate_1.0.4       survival_3.8-3      \n#&gt; [52] RcppParallel_5.1.10  tensorA_0.36.2.1     checkmate_2.3.2     \n#&gt; [55] stats4_4.5.1         insight_1.3.1        distributional_0.5.0\n#&gt; [58] generics_0.1.4       rprojroot_2.1.0      hms_1.1.3           \n#&gt; [61] rstantools_2.4.0     scales_1.4.0         xtable_1.8-4        \n#&gt; [64] glue_1.8.0           emmeans_1.11.2       tools_4.5.1         \n#&gt; [67] data.table_1.17.8    mvtnorm_1.3-3        grid_4.5.1          \n#&gt; [70] QuickJSR_1.8.0       colorspace_2.1-1     nlme_3.1-168        \n#&gt; [73] cli_3.6.5            svUnit_1.0.6         Brobdingnag_1.2-9   \n#&gt; [76] V8_6.0.5             gtable_0.3.6         R.methodsS3_1.8.2   \n#&gt; [79] digest_0.6.37        TH.data_1.1-3        htmlwidgets_1.6.4   \n#&gt; [82] farver_2.1.2         memoise_2.0.1        htmltools_0.5.8.1   \n#&gt; [85] R.oo_1.27.1          lifecycle_1.0.4      MASS_7.3-65",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_one_mean.html#bibliografia",
    "href": "chapters/linear_models/05_one_mean.html#bibliografia",
    "title": "65  Inferenza bayesiana su una media",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nTarrats-Pons, E., Mussons-Torras, M., & Jiménez-Pérez, Y. (2025). Efficacy of a Positive Psychology Intervention in Enhancing Optimism and Reducing Depression Among University Students: A Quasi-Experimental Study. Behavioral Sciences, 15(5), 571.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html",
    "href": "chapters/linear_models/07_two_means.html",
    "title": "66  Confronto tra le medie di due gruppi",
    "section": "",
    "text": "66.1 Introduzione\nUno degli obiettivi fondamentali nella ricerca psicologica è comprendere se e quanto due gruppi differiscano tra loro. Ad esempio, potremmo chiederci se un trattamento ha prodotto un cambiamento nel comportamento, se un gruppo clinico mostra livelli più elevati di ansia rispetto a un gruppo di controllo, o se due condizioni sperimentali generano risposte differenti. In tutti questi casi, l’interesse non riguarda soltanto la presenza di una differenza, ma anche la sua grandezza e l’incertezza con cui possiamo stimarla.\nL’approccio classico a tali quesiti si fonda sul test d’ipotesi frequentista, che assume come punto di partenza l’assenza di differenze tra i gruppi – la cosiddetta ipotesi nulla. Attraverso questo metodo, si valuta quanto i dati osservati siano compatibili con tale ipotesi, ottenendo come risultato il p-value, ovvero la probabilità di osservare un effetto altrettanto estremo o più estremo sotto l’ipotesi nulla.\nTuttavia, questa metodologia presenta diversi problemi. Innanzitutto, riduce l’analisi a una decisione binaria – “significativo” o “non significativo” – basata su soglie arbitrarie come il convenzionale p &lt; 0.05, senza offrire una reale comprensione della grandezza dell’effetto. Inoltre, il p-value è spesso frainteso: molti ricercatori lo interpretano erroneamente come la probabilità che l’ipotesi nulla sia vera, oppure come la probabilità che l’ipotesi alternativa sia corretta, quando in realtà esso rappresenta soltanto la probabilità dei dati osservati dato che l’ipotesi nulla sia vera (Greenland et al., 2016). Un ulteriore limite è che il p-value non fornisce una misura diretta dell’incertezza associata alla stima dell’effetto, né tiene conto in modo trasparente della variabilità intrinseca ai dati (Wasserstein & Lazar, 2016).\nProprio per queste ragioni, negli ultimi anni si è diffuso un interesse crescente verso l’inferenza bayesiana, che permette un’analisi più ricca e informativa. A differenza del metodo frequentista, che si concentra sul rifiutare o meno un’ipotesi nulla, l’approccio bayesiano sposta l’attenzione sulla stima dell’effetto e sulla quantificazione dell’incertezza. Invece di produrre un semplice verdetto binario, restituisce una distribuzione di probabilità per i parametri di interesse, mostrando in modo esplicito quanto ancora non sappiamo dopo aver osservato i dati. Questa caratteristica è particolarmente preziosa in psicologia, dove l’eterogeneità tra individui e persino all’interno dello stesso individuo nel tempo è la norma.\nMentre il metodo frequentista si limita a valutare la compatibilità dei dati con un’ipotesi fissa, l’approccio bayesiano offre strumenti più potenti. Consente, ad esempio, di calcolare direttamente la probabilità che un trattamento sia effettivamente migliore di un altro, di esplorare un’intera gamma di possibili effetti anziché focalizzarsi solo sul confronto con l’ipotesi nulla, e di integrare in modo rigoroso conoscenze precedenti per ottenere stime più robuste, soprattutto quando i dati disponibili sono pochi.\nIn questo capitolo esploreremo come modellare la differenza tra due medie utilizzando un modello di regressione con variabile indicatrice, un approccio formalmente equivalente al classico t-test ma che, nell’ambito bayesiano, permette una stima più flessibile e informativa. Vedremo come l’inferenza bayesiana fornisca strumenti più intuitivi per interpretare l’incertezza e supportare decisioni fondate nella ricerca psicologica, superando molti dei limiti dell’approccio tradizionale.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#regressione-bayesiana-per-confrontare-due-gruppi",
    "href": "chapters/linear_models/07_two_means.html#regressione-bayesiana-per-confrontare-due-gruppi",
    "title": "66  Confronto tra le medie di due gruppi",
    "section": "\n66.2 Regressione bayesiana per confrontare due gruppi",
    "text": "66.2 Regressione bayesiana per confrontare due gruppi\nPer confrontare due gruppi in un’ottica bayesiana, possiamo utilizzare un semplice modello di regressione lineare. Questo approccio, concettualmente simile al classico t-test, ci permette però di ottenere stime probabilistiche più ricche e interpretabili. Immaginiamo di voler verificare se un nuovo trattamento psicologico (gruppo sperimentale) sia più efficace di un trattamento standard (gruppo di controllo). Possiamo modellare i punteggi osservati come:\n\\[\ny_i = \\alpha + \\gamma D_i + \\varepsilon_i,\n\\]\ndove:\n\n\n\\(y_i\\) è il punteggio osservato per l’individuo \\(i\\);\n\n\\(D_i\\) è una variabile dummy: 0 per il gruppo di riferimento (es. controllo), 1 per il gruppo sperimentale;\n\n\\(\\alpha\\) rappresenta la media del gruppo di riferimento;\n\n\\(\\gamma\\) è la differenza tra le medie (l’effetto che ci interessa stimare);\n\n\\(\\varepsilon_i\\) è un errore casuale con deviazione standard \\(\\sigma\\).\n\nA differenza dell’approccio frequentista, che tratta \\(\\alpha\\), \\(\\gamma\\) e \\(\\sigma\\) come valori fissi da stimare, il metodo bayesiano li considera variabili aleatorie, a cui assegniamo distribuzioni iniziali (prior) basate su conoscenze pregresse o su assunzioni poco informative. Dopo aver osservato i dati, queste distribuzioni vengono aggiornate, producendo le distribuzioni a posteriori, che riflettono la nostra incertezza sui parametri alla luce dell’evidenza empirica.\nLa distribuzione a posteriori di \\(\\gamma\\) è particolarmente informativa, perché ci dice quanto sia plausibile ogni possibile valore della differenza tra i gruppi. Questo ci permette di:\n\ncalcolare direttamente la probabilità che l’effetto sia positivo, negativo o superiore a una soglia rilevante (ad esempio, “Qual è la probabilità che il trattamento sperimentale sia almeno 5 punti migliore del controllo?”);\nottenere intervalli di credibilità (es. 95%), che indicano un intervallo di valori in cui, con alta probabilità, cade il vero effetto;\nconfrontare i risultati con le nostre aspettative teoriche, verificando se i dati supportano, indeboliscono o ribaltano le ipotesi iniziali.\n\nA differenza del p-value, che fornisce solo una misura di “quanto estremi sono i dati sotto l’ipotesi nulla”, l’approccio bayesiano ci dà una misura diretta della plausibilità delle nostre ipotesi, in un linguaggio probabilistico più intuitivo e meno vincolato a soglie arbitrarie.\n\n66.2.1 L’approccio frequentista e bayesiano a confronto\nMentre il metodo bayesiano tratta i parametri come variabili aleatorie e quantifica l’incertezza attraverso distribuzioni di probabilità, l’approccio frequentista adotta una prospettiva radicalmente diversa. In questa visione, i dati sono considerati variabili (frutto di un campionamento casuale), mentre i parametri (come la differenza tra medie) sono fissi ma sconosciuti. L’inferenza si basa sul comportamento delle statistiche in un ipotetico universo di esperimenti ripetuti all’infinito.\nUn esempio emblematico è l’intervallo di confidenza al 95%: nella logica frequentista, esso non rappresenta la probabilità che il parametro vero cada in un certo range, ma indica che, se ripetessimo l’esperimento infinite volte, il 95% di tali intervalli conterrebbe il valore vero. Questo concetto, però, è spesso frainteso: nel singolo studio, non possiamo dire che abbiamo il 95% di fiducia nell’intervallo calcolato. Allo stesso modo, il p-value non è la probabilità che l’ipotesi nulla sia vera, ma solo la probabilità di osservare dati altrettanto estremi ammesso che l’ipotesi nulla sia corretta.\nNel confronto tra due gruppi, il frequentista calcola una statistica t e la confronta con una distribuzione teorica, chiedendosi: “Se non ci fosse alcun effetto, quanto sarebbero rari i dati che ho osservato?”. La risposta, però, non ci dice nulla sulla grandezza pratica dell’effetto né sulla sua plausibilità reale.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#un-esempio-illustrativo-il-ruolo-dellistruzione-materna",
    "href": "chapters/linear_models/07_two_means.html#un-esempio-illustrativo-il-ruolo-dellistruzione-materna",
    "title": "66  Confronto tra le medie di due gruppi",
    "section": "\n66.3 Un esempio illustrativo: il ruolo dell’istruzione materna",
    "text": "66.3 Un esempio illustrativo: il ruolo dell’istruzione materna\nDopo aver discusso le differenze tra approccio frequentista e bayesiano, vediamo ora come questi due modi di inferire si comportano su un caso reale. Utilizzeremo un dataset classico in psicologia dello sviluppo, che riporta i punteggi di quoziente intellettivo (QI) di bambini, insieme a informazioni sul livello di istruzione della madre.\nLa domanda che ci poniamo è semplice, ma rilevante: i figli di madri diplomate (che hanno completato la scuola superiore) mostrano in media un QI diverso rispetto ai figli di madri non diplomate?\n\n66.3.1 Esplorazione iniziale dei dati\nImportiamo il dataset e verifichiamo la struttura delle variabili:\n\nkidiq &lt;- rio::import(here::here(\"data\", \"kidiq.dta\"))\nglimpse(kidiq)\n#&gt; Rows: 434\n#&gt; Columns: 5\n#&gt; $ kid_score &lt;dbl&gt; 65, 98, 85, 83, 115, 98, 69, 106, 102, 95, 91, 58, 84, 7…\n#&gt; $ mom_hs    &lt;dbl&gt; 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,…\n#&gt; $ mom_iq    &lt;dbl&gt; 121.12, 89.36, 115.44, 99.45, 92.75, 107.90, 138.89, 125…\n#&gt; $ mom_work  &lt;dbl&gt; 4, 4, 4, 3, 4, 1, 4, 3, 1, 1, 1, 4, 4, 4, 2, 1, 3, 3, 4,…\n#&gt; $ mom_age   &lt;dbl&gt; 27, 25, 27, 25, 27, 18, 20, 23, 24, 19, 23, 24, 27, 26, …\n\nCalcoliamo alcune statistiche descrittive per ciascun gruppo:\n\nkidiq |&gt; \n  group_by(mom_hs) |&gt; \n  summarise(\n    n = n(),\n    media_QI = mean(kid_score),\n    sd_QI = sd(kid_score)\n  )\n#&gt; # A tibble: 2 × 4\n#&gt;   mom_hs     n media_QI sd_QI\n#&gt;    &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1      0    93     77.5  22.6\n#&gt; 2      1   341     89.3  19.0\n\nVediamo così che il campione include 93 bambini con madri non diplomate e 341 con madri diplomate, con una differenza apparente nei punteggi medi di QI. Ma questa differenza è solo un effetto casuale, o riflette una tendenza reale nella popolazione?\nPer rispondere, analizziamo il problema utilizzando entrambi gli approcci.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#due-strade-per-lo-stesso-problema",
    "href": "chapters/linear_models/07_two_means.html#due-strade-per-lo-stesso-problema",
    "title": "66  Confronto tra le medie di due gruppi",
    "section": "\n66.4 Due strade per lo stesso problema",
    "text": "66.4 Due strade per lo stesso problema\n\n66.4.1 Approccio frequentista\nPer valutare se la differenza osservata è compatibile con l’ipotesi che non ci sia alcuna differenza nella popolazione, applichiamo il t-test per campioni indipendenti:\n\nt.test(\n  kid_score ~ mom_hs, \n  data = kidiq, \n  var.equal = TRUE\n)\n#&gt; \n#&gt;  Two Sample t-test\n#&gt; \n#&gt; data:  kid_score by mom_hs\n#&gt; t = -5.1, df = 432, p-value = 6e-07\n#&gt; alternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -16.336  -7.207\n#&gt; sample estimates:\n#&gt; mean in group 0 mean in group 1 \n#&gt;           77.55           89.32\n\nQuesta funzione restituisce la stima della differenza media, l’intervallo di confidenza al 95%, e il valore del p-value. Il p-value rappresenta la probabilità di osservare una differenza almeno così grande se non ci fosse alcuna differenza reale nella popolazione (cioè sotto l’ipotesi nulla \\(\\mu_1 = \\mu_2\\)).\nÈ una misura indiretta dell’evidenza contro l’ipotesi nulla: più è piccolo il p-value, meno plausibile appare l’ipotesi di assenza di differenza. Ma, come abbiamo visto nei capitoli precedenti, questo tipo di inferenza è vincolato da assunzioni forti e da interpretazioni spesso controintuitive.\nNel prossimo paragrafo, analizzeremo lo stesso problema con l’approccio bayesiano, per ottenere una visione più continua e informativa dell’incertezza sulla differenza tra i gruppi.\n\n66.4.2 Approccio bayesiano\nA differenza dell’approccio frequentista, che parte da un’ipotesi nulla e valuta la compatibilità dei dati con essa, il paradigma bayesiano si concentra direttamente sull’effetto che vogliamo stimare. Non ci si chiede se la differenza tra gruppi “esiste”, ma quanto è plausibile e quanto è incerta.\nPer farlo, costruiamo un modello probabilistico che descriva la relazione tra il QI dei bambini e il livello di istruzione materna. Il modello è una semplice regressione con variabile dummy:\n\\[\ny_i \\sim \\mathcal{N}(\\mu_i, \\sigma), \\quad \\mu_i = \\alpha + \\gamma D_i,\n\\]\ndove:\n\n\n\\(y_i\\) è il punteggio di QI del bambino \\(i\\),\n\n\\(D_i = 0\\) se la madre non è diplomata, \\(1\\) se è diplomata,\n\n\\(\\alpha\\) rappresenta il QI medio per i figli di madri non diplomate,\n\n\\(\\gamma\\) rappresenta la differenza tra i gruppi,\n\n\\(\\sigma\\) è la deviazione standard residua.\n\n\n66.4.2.1 Stima del modello con brms\n\nStimiamo il modello utilizzando il pacchetto brms, che permette di ottenere direttamente la distribuzione a posteriori dei parametri:\n\nfit_1 &lt;- brm(\n  kid_score ~ mom_hs,\n  data = kidiq,\n  backend = \"cmdstanr\",\n  silent = 0\n)\n\nUna volta ottenuti i campioni a posteriori, possiamo rispondere in modo diretto alla domanda: qual è la probabilità che la differenza media tra i due gruppi superi una soglia di interesse, ad esempio 5 punti?\n\nposterior_samples &lt;- as_draws_df(fit_1)\nmean(posterior_samples$b_mom_hs &gt; 5)\n#&gt; [1] 0.9975\n\nQuesto valore non è un p-value, ma una vera probabilità condizionata ai dati osservati. Ad esempio, un risultato pari a 0.96 può essere interpretato come: “dato il nostro modello e i dati disponibili, c’è una probabilità del 96% che i figli di madri diplomate abbiano in media un QI superiore di almeno 5 punti”.\n\n66.4.3 Visualizzare la variabilità nei dati\nUn grafico aiuta a rappresentare non solo le medie, ma anche la distribuzione dei punteggi all’interno di ciascun gruppo:\n\nggplot(kidiq, aes(x = as.factor(mom_hs), y = kid_score)) +\n  geom_violin(trim = FALSE, fill = \"skyblue\") +\n  geom_boxplot(width = 0.1, outlier.shape = NA, fill = \"white\", color = \"black\") +\n  labs(\n    x = \"Istruzione materna\",\n    y = \"QI del bambino\",\n    title = \"Distribuzione dei punteggi QI\\nper livello di istruzione della madre\"\n  ) +\n  scale_x_discrete(labels = c(\"0\" = \"Non diplomata\", \"1\" = \"Diplomata\"))\n\n\n\n\n\n\n\nIl grafico evidenzia che, pur in presenza di una differenza tra le medie, esiste una notevole sovrapposizione tra i gruppi. Questo riflette la naturale variabilità dei dati psicologici e rende evidente perché la sola media non basta: è l’intera distribuzione che ci interessa comprendere.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#cosa-cambia-davvero-tra-i-due-approcci",
    "href": "chapters/linear_models/07_two_means.html#cosa-cambia-davvero-tra-i-due-approcci",
    "title": "66  Confronto tra le medie di due gruppi",
    "section": "\n66.5 Cosa cambia davvero tra i due approcci?",
    "text": "66.5 Cosa cambia davvero tra i due approcci?\nEntrambi gli approcci usano gli stessi dati e, in presenza di campioni ampi e modelli lineari semplici, spesso portano a conclusioni numericamente simili. Tuttavia, ciò che cambia profondamente è il significato dei risultati.\n\n\n\n\n\n\n\nAspetto\nFrequentista\nBayesiano\n\n\n\nIpotesi di partenza\nAssume \\(\\mu_1 = \\mu_2\\) (ipotesi nulla)\nNessuna ipotesi nulla\n\n\nObiettivo\nVerificare se la differenza osservata è improbabile sotto \\(H_0\\)\n\nStimare la probabilità della differenza tra i gruppi\n\n\nInterpretazione\nIl p-value è una probabilità condizionata da \\(H_0\\)\n\nLa probabilità è condizionata dai dati osservati\n\n\n\nRappresentazione\nIntervallo di confidenza\nIntervallo di credibilità\n\n\nUso dei dati precedenti\nNon previsto\nIntegrabile tramite prior\n\n\n\nIl bayesianesimo, in questo contesto, non è solo una tecnica alternativa, ma un modo diverso di porre le domande e interpretare le risposte. Invece di dire “questa differenza è significativa?”, possiamo chiedere “quanto è plausibile, alla luce dei dati, che la differenza superi una soglia rilevante?”\nNel prossimo paragrafo, estenderemo questa analisi esplorando la sensibilità del modello bayesiano rispetto alla scelta dei prior e approfondiremo strumenti diagnostici che ci aiutano a valutare quanto il modello rifletta davvero i dati.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#approfondimenti-bayesiani-dalla-flessibilità-alla-coerenza",
    "href": "chapters/linear_models/07_two_means.html#approfondimenti-bayesiani-dalla-flessibilità-alla-coerenza",
    "title": "66  Confronto tra le medie di due gruppi",
    "section": "\n66.6 Approfondimenti bayesiani: dalla flessibilità alla coerenza",
    "text": "66.6 Approfondimenti bayesiani: dalla flessibilità alla coerenza\nIl confronto tra i gruppi sul QI ci ha già mostrato i vantaggi dell’inferenza bayesiana: la possibilità di quantificare direttamente l’incertezza sulla differenza tra le medie e di stimare probabilità a posteriori interpretabili. In questa sezione vediamo come l’approccio bayesiano permetta di raffinare il modello e verificare la coerenza delle ipotesi con i dati, prima e dopo l’osservazione.\n\n66.6.1 Intervallo di credibilità e verifica predittiva\nUna volta stimato il modello, possiamo calcolare un intervallo di credibilità all’89%, una soglia suggerita in ambito didattico per sottolineare che non si tratta di una soglia “speciale”, ma di un’espressione quantitativa dell’incertezza residua:\n\nbayestestR::hdi(fit_1, parameters = \"mom_hs\", ci = 0.89)\n#&gt; Highest Density Interval\n#&gt; \n#&gt; Parameter |       89% HDI\n#&gt; -------------------------\n#&gt; mom_hs    | [8.36, 15.66]\n\nPer valutare se il modello riproduce adeguatamente i dati, possiamo utilizzare la verifica predittiva a posteriori:\n\npp_check(fit_1)\n\n\n\n\n\n\n\nNel nostro caso, il modello riproduce bene la forma generale della distribuzione osservata, ma si notano leggere discrepanze nelle code. Questo suggerisce che la distribuzione normale, pur efficace, potrebbe essere migliorata per catturare l’asimmetria presente nei dati.\n\n66.6.2 Flessibilità modellistica: usare una distribuzione skew-normal\nPer rappresentare meglio la variabilità asimmetrica, possiamo utilizzare una distribuzione skew-normal, che generalizza la normale consentendo una coda più estesa da un lato:\n\nfit_2 &lt;- brm(\n  kid_score ~ mom_hs, \n  family = skew_normal(),\n  backend = \"cmdstanr\", \n  data = kidiq\n)\n\nIl modello skew-normal migliora l’adattamento ai dati, come evidenziato da pp_check(fit_2), che mostra una maggiore sovrapposizione tra predizioni e osservazioni.\n\npp_check(fit_2)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#verifica-predittiva-a-priori-prior-predictive-check",
    "href": "chapters/linear_models/07_two_means.html#verifica-predittiva-a-priori-prior-predictive-check",
    "title": "66  Confronto tra le medie di due gruppi",
    "section": "\n66.7 Verifica predittiva a priori (Prior Predictive Check)",
    "text": "66.7 Verifica predittiva a priori (Prior Predictive Check)\nUn passaggio fondamentale nella costruzione di modelli bayesiani consiste nel chiedersi: quali dati ci aspetteremmo di vedere, se avessimo solo i prior e nessun dato reale?\nCon il prior predictive check, simuliamo dati fittizi basati unicamente sulle distribuzioni a priori, per verificare se le nostre ipotesi iniziali sono compatibili con la scala e la natura del fenomeno psicologico in esame.\nPer esempio, possiamo specificare prior debolmente informativi ma plausibili:\n\nprior_gaussian &lt;- \n  prior(normal(90, 20), class = \"Intercept\") +\n  prior(normal(0, 15), class = \"b\", coef = \"mom_hs\") +\n  prior(cauchy(0, 20), class = \"sigma\")\n\nPoi stimiamo un modello basato solo su questi prior, ignorando i dati:\n\nfit_prior &lt;- brm(\n  kid_score ~ mom_hs,\n  data = kidiq,\n  prior = prior_gaussian,\n  family = gaussian(),\n  backend = \"cmdstanr\",\n  sample_prior = \"only\"\n)\n\nVisualizzando i dati simulati:\n\npp_check(fit_prior, ndraws = 100) + xlim(10, 180)\n\n\n\n\n\n\n\npossiamo verificare se i prior generano predizioni realistiche. In questo caso, vediamo che i valori simulati si distribuiscono su un intervallo ampio ma plausibile, coerente con ciò che sappiamo sul QI. Questo indica che i prior non sono né troppo restrittivi né irrealistici.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#incorporare-conoscenza-pregressa-prior-informativi",
    "href": "chapters/linear_models/07_two_means.html#incorporare-conoscenza-pregressa-prior-informativi",
    "title": "66  Confronto tra le medie di due gruppi",
    "section": "\n66.8 Incorporare conoscenza pregressa: prior informativi",
    "text": "66.8 Incorporare conoscenza pregressa: prior informativi\nQuando disponiamo di evidenze precedenti (ad esempio, studi che indicano un effetto medio dell’istruzione materna di circa 10 punti QI), possiamo formalizzarle con un prior informativo:\n\nfit_3 &lt;- brm(\n  kid_score ~ mom_hs,\n  data = kidiq,\n  prior = c(set_prior(\"normal(10, 5)\", class = \"b\", coef = \"mom_hs\")),\n  backend = \"cmdstanr\"\n)\n\n\nsummary(fit_3)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: kid_score ~ mom_hs \n#&gt;    Data: kidiq (Number of observations: 434) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept    77.77      1.90    74.06    81.42 1.00     4533     3281\n#&gt; mom_hs       11.47      2.08     7.44    15.49 1.00     4457     3142\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma    19.90      0.68    18.63    21.30 1.00     4514     2685\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nSe i dati confermano il pattern, la distribuzione a posteriori sarà simile a quella ottenuta con prior deboli. Ma in campioni piccoli o più rumorosi, questo tipo di informazione può fare una grande differenza, aiutando a stabilizzare l’inferenza.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#test-di-ipotesi-bayesiano",
    "href": "chapters/linear_models/07_two_means.html#test-di-ipotesi-bayesiano",
    "title": "66  Confronto tra le medie di due gruppi",
    "section": "\n66.9 Test di ipotesi bayesiano",
    "text": "66.9 Test di ipotesi bayesiano\nInfine, possiamo formulare ipotesi probabilistiche direttamente interpretabili, come:\nQual è la probabilità che la differenza tra i gruppi superi i 5 punti?\n\nhypothesis(fit_1, \"mom_hs &gt; 5\")\n#&gt; Hypothesis Tests for class b:\n#&gt;         Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio\n#&gt; 1 (mom_hs)-(5) &gt; 0     6.78      2.31     3.02    10.54        399\n#&gt;   Post.Prob Star\n#&gt; 1         1    *\n#&gt; ---\n#&gt; 'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses.\n#&gt; '*': For one-sided hypotheses, the posterior probability exceeds 95%;\n#&gt; for two-sided hypotheses, the value tested against lies outside the 95%-CI.\n#&gt; Posterior probabilities of point hypotheses assume equal prior probabilities.\n\nA differenza del p-value, il risultato fornisce una risposta diretta: ad esempio, una probabilità del 98% che l’effetto sia maggiore di 5. Questo è il tipo di affermazione che possiamo portare nella discussione scientifica o clinica, senza bisogno di traduzioni arbitrarie.\n\n\n\n\n\n\nApprofondimento statistico (opzionale)\n\n\n\nConsideriamo ora le basi statistiche su cui si basa l’approccio frequentista. Nel paradigma frequentista, l’inferenza sulla differenza tra due gruppi si basa sulla distribuzione campionaria della differenza tra le medie. L’idea di fondo è che, se ripetessimo il campionamento molte volte, otterremmo valori diversi per la differenza tra le medie campionarie, e questa variabilità può essere descritta attraverso una distribuzione probabilistica.\nSupponiamo di avere due popolazioni normali e indipendenti:\n\\[\nY_1 \\sim \\mathcal{N}(\\mu_1, \\sigma_1^2) \\quad \\text{e} \\quad Y_2 \\sim \\mathcal{N}(\\mu_2, \\sigma_2^2)\n\\]\ne di osservare due campioni indipendenti, rispettivamente di dimensione \\(n_1\\) e \\(n_2\\).\nSe assumiamo inoltre che le varianze siano uguali (\\(\\sigma_1^2 = \\sigma_2^2 = \\sigma^2\\)), possiamo utilizzare una versione semplificata del modello.\n\n66.9.1 Statistica di interesse\nIl nostro obiettivo è stimare la differenza tra le medie delle due popolazioni, ovvero:\n\\[\n\\mu_1 - \\mu_2.\n\\]\nLa stima di questa quantità è data dalla differenza tra le medie campionarie:\n\\[\n\\bar{Y}_1 - \\bar{Y}_2.\n\\]\n\n66.9.2 Proprietà della statistica campionaria\n\n66.9.2.1 Valore atteso\nNel caso di due campioni indipendenti:\n\\[\nE(\\bar{Y}_1 - \\bar{Y}_2) = \\mu_1 - \\mu_2.\n\\]\n\n\n\n\n\n\nDimostrazione\n\n\n\n\n\nSi parte dalla definizione di media campionaria per ciascun gruppo e si applica la linearità dell’operatore valore atteso:\n\\[\nE(\\bar{Y}_1 - \\bar{Y}_2) = E(\\bar{Y}_1) - E(\\bar{Y}_2) = \\mu_1 - \\mu_2.\n\\]\n\n\n\n\n66.9.2.2 Varianza\nLa varianza della differenza tra le medie campionarie è:\n\\[\n\\operatorname{Var}(\\bar{Y}_1 - \\bar{Y}_2) = \\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}.\n\\]\n\n\n\n\n\n\nDimostrazione\n\n\n\n\n\nPoiché i due campioni sono indipendenti, la varianza della differenza si ottiene sommando le varianze delle due medie:\n\\[\n\\operatorname{Var}(\\bar{Y}_1) = \\frac{\\sigma_1^2}{n_1}, \\quad \\operatorname{Var}(\\bar{Y}_2) = \\frac{\\sigma_2^2}{n_2}\n\\]\nquindi:\n\\[\n\\operatorname{Var}(\\bar{Y}_1 - \\bar{Y}_2) = \\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}.\n\\]\n\n\n\nSe assumiamo varianze uguali (\\(\\sigma_1 = \\sigma_2 = \\sigma\\)), possiamo scrivere:\n\\[\n\\operatorname{Var}(\\bar{Y}_1 - \\bar{Y}_2) = \\sigma^2 \\left( \\frac{1}{n_1} + \\frac{1}{n_2} \\right).\n\\]\nPoiché \\(\\sigma^2\\) è sconosciuta, la si stima tramite la varianza pooled:\n\\[\ns_p^2 = \\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2},\n\\]\ndove \\(s_1^2\\) e \\(s_2^2\\) sono le varianze campionarie:\n\\[\ns_j^2 = \\frac{1}{n_j - 1} \\sum_{i=1}^{n_j} (y_{j,i} - \\bar{y}_j)^2, \\quad j = 1,2.\n\\]\n\n66.9.3 Distribuzione della statistica\nSotto l’ipotesi di normalità e indipendenza, e assumendo varianze uguali, la statistica \\(\\bar{Y}_1 - \\bar{Y}_2\\) segue (almeno approssimativamente) una distribuzione normale:\n\\[\n\\bar{Y}_1 - \\bar{Y}_2 \\sim \\mathcal{N} \\left( \\mu_1 - \\mu_2,\\ \\sigma \\sqrt{ \\frac{1}{n_1} + \\frac{1}{n_2} } \\right).\n\\]\nQuesta proprietà permette di costruire un intervallo di confidenza al 95% per la differenza tra le medie, oppure di effettuare un test t per due campioni indipendenti, basato sulla seguente statistica:\n\\[\nt = \\frac{(\\bar{Y}_1 - \\bar{Y}_2) - (\\mu_1 - \\mu_2)}{s_p \\sqrt{ \\frac{1}{n_1} + \\frac{1}{n_2} }}.\n\\]\nQuesta statistica segue, sotto l’ipotesi nulla \\(\\mu_1 = \\mu_2\\), una distribuzione t di Student con \\(n_1 + n_2 - 2\\) gradi di libertà.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#riflessioni-conclusive",
    "href": "chapters/linear_models/07_two_means.html#riflessioni-conclusive",
    "title": "66  Confronto tra le medie di due gruppi",
    "section": "\n66.10 Riflessioni conclusive",
    "text": "66.10 Riflessioni conclusive\nIl confronto tra medie rappresenta una procedura statistica fondamentale in psicologia, ma la sua apparente semplicità nasconde complessità interpretative spesso trascurate. Tradizionalmente, l’analisi frequentista ci ha abituati a valutare le differenze attraverso il prisma del p-value, un approccio che risulta doppiamente limitante: non solo per la sua natura binaria, ma soprattutto per la sua intrinseca incapacità di cogliere la dinamica individuale dei processi psicologici. Come evidenziato da recenti sviluppi nella scienza dell’intervento (Hayes et al., 2022), l’applicazione predittiva di risultati normativi agli individui poggia sul presupposto insostenibile dell’ergodicità - l’idea che lo stesso modello dinamico si applichi uniformemente a tutti i partecipanti (omogeneità) e che le caratteristiche dei dati rimangano stabili nel tempo (stazionarietà).\nL’analisi bayesiana, implementata attraverso strumenti come brms, ci offre una prospettiva più articolata a livello di gruppo, permettendoci di quantificare l’incertezza attraverso distribuzioni a posteriori e incorporare conoscenze pregresse. Tuttavia, anche questo approccio condivide con i metodi tradizionali un limite fondamentale: l’incapacità di modellare adeguatamente la non-stazionarietà e l’eterogeneità dinamica che caratterizzano i veri processi di cambiamento psicologico. Come osservato da Veillette & Nusbaum (2025), un effetto medio significativo può nascondere una realtà in cui solo una minoranza reagisce in modo marcato (ad esempio, il 30% con d=4 mentre il 70% resta invariato), scenario che rappresenta la norma piuttosto che l’eccezione in psicologia.\nQuesta consapevolezza ci impone una duplice rivoluzione metodologica. In primo luogo, dobbiamo abbandonare l’illusione ergodica che ha dominato la ricerca psicologica, riconoscendo che la vita mentale non assomiglia a “biglie che cadono in una tavola di Galton” - dove ogni ostacolo (trauma, pregiudizio, risorsa personale) altera in modo unico e irreplicabile i percorsi individuali. In secondo luogo, dobbiamo abbracciare approcci idionomici che partano dall’analisi idiografica ad alta densità temporale, per poi cercare - quando utile - generalizzazioni nomotetiche che migliorino effettivamente l’adattamento individuale.\nLe implicazioni sono profonde sia per la ricerca che per la pratica clinica. In ambito terapeutico, la Terapia Basata sui Processi (PBT) incarna questa svolta epistemologica, spostando l’attenzione dai protocolli standardizzati a un’analisi funzionale dei processi biopsicosociali rilevanti per il singolo cliente. Sul piano metodologico, strumenti come l’Ecological Momentary Assessment permettono di mappare le interrelazioni dinamiche intra-individuali, superando i limiti della psicometria tradizionale.\nIn definitiva, il confronto tra medie rimane uno strumento prezioso per domande a livello di popolazione, ma non può costituire il fondamento di una psicologia matura. Come disciplina, ci troviamo a un bivio: continuare a produrre stime aggregate di dubbia rilevanza individuale, o impegnarci nella sfida più complessa ma necessaria di sviluppare:\n\n\nmisure sensibili ai processi dinamici,\n\n\ndisegni longitudinali ad alta risoluzione temporale,\n\n\nmodelli analitici in grado di cogliere non-linearità e interazioni contestuali.\n\nLa statistica bayesiana rappresenta un passo avanti importante, ma il vero progresso epistemologico risiederà nella nostra capacità di conciliare rigore metodologico con pluralismo analitico - riconoscendo che nessun singolo valore (p-value, BF o effect size) potrà mai catturare la complessità del divenire psicologico individuale. Solo abbracciando strumenti all’altezza di questa complessità potremo costruire una psicologia realmente informativa, replicabile e utile - sia per comprendere la mente umana che per promuoverne il benessere.\nLa sfida che ci attende non è tanto tecnica quanto culturale: imparare a convivere con la complessità senza rinunciare al rigore, a comunicare l’incertezza senza scivolare nel relativismo, a valorizzare l’unicità senza abbandonare la generalizzazione. In questo cammino, la statistica non dovrà essere il letto di Procuste che riduce la realtà alla misurabilità, ma la bussola che ci guida nell’esplorazione innovativa della diversità psicologica umana.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/07_two_means.html#informazioni-sullambiente-di-sviluppo",
    "title": "66  Confronto tra le medie di due gruppi",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] insight_1.3.0     bayestestR_0.16.0 brms_2.22.0       Rcpp_1.0.14      \n#&gt;  [5] posterior_1.6.1   cmdstanr_0.9.0    thematic_0.1.7    MetBrewer_0.2.0  \n#&gt;  [9] ggokabeito_0.1.0  see_0.11.0        gridExtra_2.3     patchwork_1.3.0  \n#&gt; [13] bayesplot_1.13.0  psych_2.5.3       scales_1.4.0      markdown_2.0     \n#&gt; [17] knitr_1.50        lubridate_1.9.4   forcats_1.0.0     stringr_1.5.1    \n#&gt; [21] dplyr_1.1.4       purrr_1.0.4       readr_2.1.5       tidyr_1.3.1      \n#&gt; [25] tibble_3.3.0      ggplot2_3.5.2     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [29] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] mnormt_2.1.1         inline_0.3.21        sandwich_3.1-1      \n#&gt;  [4] rlang_1.1.6          magrittr_2.0.3       multcomp_1.4-28     \n#&gt;  [7] matrixStats_1.5.0    compiler_4.5.0       loo_2.8.0           \n#&gt; [10] vctrs_0.6.5          reshape2_1.4.4       pkgconfig_2.0.3     \n#&gt; [13] fastmap_1.2.0        backports_1.5.0      labeling_0.4.3      \n#&gt; [16] rmarkdown_2.29       tzdb_0.5.0           haven_2.5.5         \n#&gt; [19] ps_1.9.1             xfun_0.52            jsonlite_2.0.0      \n#&gt; [22] parallel_4.5.0       R6_2.6.1             stringi_1.8.7       \n#&gt; [25] RColorBrewer_1.1-3   StanHeaders_2.32.10  estimability_1.5.1  \n#&gt; [28] rstan_2.32.7         zoo_1.8-14           pacman_0.5.1        \n#&gt; [31] R.utils_2.13.0       Matrix_1.7-3         splines_4.5.0       \n#&gt; [34] timechange_0.3.0     tidyselect_1.2.1     rstudioapi_0.17.1   \n#&gt; [37] abind_1.4-8          yaml_2.3.10          codetools_0.2-20    \n#&gt; [40] curl_6.3.0           processx_3.8.6       pkgbuild_1.4.8      \n#&gt; [43] plyr_1.8.9           lattice_0.22-7       withr_3.0.2         \n#&gt; [46] bridgesampling_1.1-2 coda_0.19-4.1        evaluate_1.0.4      \n#&gt; [49] survival_3.8-3       RcppParallel_5.1.10  pillar_1.10.2       \n#&gt; [52] tensorA_0.36.2.1     checkmate_2.3.2      stats4_4.5.0        \n#&gt; [55] distributional_0.5.0 generics_0.1.4       rprojroot_2.0.4     \n#&gt; [58] hms_1.1.3            rstantools_2.4.0     xtable_1.8-4        \n#&gt; [61] glue_1.8.0           emmeans_1.11.1       tools_4.5.0         \n#&gt; [64] data.table_1.17.6    mvtnorm_1.3-3        grid_4.5.0          \n#&gt; [67] QuickJSR_1.8.0       datawizard_1.1.0     colorspace_2.1-1    \n#&gt; [70] nlme_3.1-168         cli_3.6.5            Brobdingnag_1.2-9   \n#&gt; [73] V8_6.0.4             gtable_0.3.6         R.methodsS3_1.8.2   \n#&gt; [76] digest_0.6.37        TH.data_1.1-3        htmlwidgets_1.6.4   \n#&gt; [79] farver_2.1.2         htmltools_0.5.8.1    R.oo_1.27.1         \n#&gt; [82] lifecycle_1.0.4      MASS_7.3-65",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_two_means.html#bibliografia",
    "href": "chapters/linear_models/07_two_means.html#bibliografia",
    "title": "66  Confronto tra le medie di due gruppi",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGreenland, S., Senn, S. J., Rothman, K. J., Carlin, J. B., Poole, C., Goodman, S. N., & Altman, D. G. (2016). Statistical tests, P values, confidence intervals, and power: a guide to misinterpretations. European Journal of Epidemiology, 31(4), 1–14.\n\n\nHayes, S. C., Ciarrochi, J., Hofmann, S. G., Chin, F., & Sahdra, B. (2022). Evolving an idionomic approach to processes of change: Towards a unified personalized science of human improvement. Behaviour Research and Therapy, 156, 104155.\n\n\nKruschke, J. K. (2013). Bayesian estimation supersedes the t test. Journal of Experimental Psychology: General, 142(2), 573–603.\n\n\nVeillette, J. P., & Nusbaum, H. C. (2025). Bayesian p-curve mixture models as a tool to dissociate effect size and effect prevalence. Communications Psychology, 3(1), 9.\n\n\nWasserstein, R. L., & Lazar, N. A. (2016). The ASA’s statement on p-values: context, process, and purpose. The American Statistician, 70(2), 129–133.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07a_effect_size.html",
    "href": "chapters/linear_models/07a_effect_size.html",
    "title": "67  La grandezza dell’effetto: valutare la rilevanza pratica",
    "section": "",
    "text": "67.1 Introduzione\nNel capitolo precedente abbiamo esaminato la differenza nei punteggi di QI tra bambini nati da madri con e senza diploma di scuola superiore. L’analisi bayesiana ci ha permesso di ottenere una distribuzione a posteriori per questa differenza, da cui derivano inferenze probabilistiche ricche e sfumate. Ma un interrogativo cruciale rimane aperto: questa differenza è importante?\nIn psicologia, come in molte scienze applicate, non è sufficiente stabilire che un effetto esiste: bisogna valutare se l’effetto ha una magnitudine sufficiente da avere rilevanza teorica, clinica o sociale. È in questa prospettiva che si introduce il concetto di grandezza dell’effetto (effect size), una misura quantitativa dell’intensità di un risultato.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>La grandezza dell’effetto: valutare la rilevanza pratica</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07a_effect_size.html#perché-stimare-la-grandezza-delleffetto",
    "href": "chapters/linear_models/07a_effect_size.html#perché-stimare-la-grandezza-delleffetto",
    "title": "67  La grandezza dell’effetto: valutare la rilevanza pratica",
    "section": "\n67.2 Perché stimare la grandezza dell’effetto",
    "text": "67.2 Perché stimare la grandezza dell’effetto\nLa grandezza dell’effetto fornisce un ponte tra analisi statistica e interpretazione sostanziale dei dati. Essa consente di rispondere a domande come:\n\nQuanto è marcata la differenza osservata?\nL’effetto ha un impatto concreto nella vita reale o nelle applicazioni cliniche?\nLa variazione osservata è sufficiente a giustificare interventi, cambiamenti o nuove ipotesi teoriche?\n\nL’American Psychological Association (APA) raccomanda di riportare sempre una misura di grandezza dell’effetto, in quanto essa fornisce un’informazione critica che va oltre la mera dicotomia “effetto presente / effetto assente”.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>La grandezza dell’effetto: valutare la rilevanza pratica</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07a_effect_size.html#standardizzare-le-differenze-il-cohens-d",
    "href": "chapters/linear_models/07a_effect_size.html#standardizzare-le-differenze-il-cohens-d",
    "title": "67  La grandezza dell’effetto: valutare la rilevanza pratica",
    "section": "\n67.3 Standardizzare le differenze: il Cohen’s d\n",
    "text": "67.3 Standardizzare le differenze: il Cohen’s d\n\nNel confronto tra due gruppi, una delle misure più comuni di grandezza dell’effetto è il Cohen’s d, che esprime la differenza tra due medie in unità di deviazione standard:\n\\[\nd = \\frac{\\mu_1 - \\mu_2}{\\sigma},\n\\]\ndove:\n\n\n\\(\\mu_1\\) e \\(\\mu_2\\) sono le medie dei due gruppi,\n\n\\(\\sigma\\) è una stima comune della deviazione standard.\n\nL’interpretazione di d è indipendente dalle unità di misura originali, il che la rende particolarmente utile per confrontare risultati provenienti da diversi studi o contesti.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>La grandezza dell’effetto: valutare la rilevanza pratica</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07a_effect_size.html#il-cohens-d-in-ottica-bayesiana",
    "href": "chapters/linear_models/07a_effect_size.html#il-cohens-d-in-ottica-bayesiana",
    "title": "67  La grandezza dell’effetto: valutare la rilevanza pratica",
    "section": "\n67.4 Il Cohen’s d in ottica bayesiana",
    "text": "67.4 Il Cohen’s d in ottica bayesiana\nNell’approccio bayesiano, non calcoliamo un unico valore di d, ma una distribuzione a posteriori di valori plausibili per d, ottenuta combinando:\n\ni campioni posteriori della differenza tra gruppi,\ni campioni posteriori della deviazione standard residua.\n\n\n67.4.1 Esempio pratico con brms\n\nA partire dal modello stimato nel capitolo precedente:\n\nkidiq &lt;- rio::import(here::here(\"data\", \"kidiq.dta\"))\n\nfit_1 &lt;- brm(\n  kid_score ~ mom_hs, \n  data = kidiq, \n  backend = \"cmdstanr\",\n  silent = 0\n)\n\nOtteniamo i campioni posteriori:\n\npost &lt;- as_draws_df(fit_1)\nd_samples &lt;- post$b_mom_hs / post$sigma\n\n\n67.4.2 Visualizzazione della distribuzione di d\n\n\nmcmc_areas(as_draws_df(tibble(d = d_samples)), pars = \"d\", prob = 0.89) +\n  labs(\n    title = \"Distribuzione a posteriori di Cohen's d\",\n    subtitle = \"Stima bayesiana della grandezza dell’effetto\"\n  )\n\n\n\n\n\n\n\nQuesta distribuzione esprime l’incertezza residua sulla grandezza dell’effetto, dopo aver osservato i dati, ed è il punto di partenza per una valutazione più completa.\n\n67.4.3 Statistiche riassuntive\n\nbayestestR::describe_posterior(d_samples, ci = 0.89)\n#&gt; Summary of Posterior Distribution\n#&gt; \n#&gt; Parameter | Median |       89% CI |   pd |          ROPE | % in ROPE\n#&gt; --------------------------------------------------------------------\n#&gt; Posterior |   0.59 | [0.41, 0.78] | 100% | [-0.10, 0.10] |        0%\n\nQuesta funzione fornisce:\n\nla stima centrale (media o mediana) di d,\nl’intervallo di credibilità,\nla probabilità che d sia maggiore o minore di soglie rilevanti.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>La grandezza dell’effetto: valutare la rilevanza pratica</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07a_effect_size.html#interpretare-la-grandezza-delleffetto-da-soglie-fisse-a-giudizi-probabilistici",
    "href": "chapters/linear_models/07a_effect_size.html#interpretare-la-grandezza-delleffetto-da-soglie-fisse-a-giudizi-probabilistici",
    "title": "67  La grandezza dell’effetto: valutare la rilevanza pratica",
    "section": "\n67.5 Interpretare la grandezza dell’effetto: da soglie fisse a giudizi probabilistici",
    "text": "67.5 Interpretare la grandezza dell’effetto: da soglie fisse a giudizi probabilistici\nIn ambito frequentista, la seguente classificazione è comunemente usata:\n\n\nValore di d\n\nInterpretazione convenzionale\n\n\n\n≈ 0.2\nEffetto piccolo\n\n\n≈ 0.5\nEffetto medio\n\n\n≥ 0.8\nEffetto grande\n\n\n\nQueste soglie hanno valore euristico, ma non vanno applicate meccanicamente. Nell’approccio bayesiano possiamo invece porre domande più informative, del tipo:\n\nQual è la probabilità che l’effetto superi 0.5 (soglia di effetto medio)?\nQual è la probabilità che sia minore di 0.2 (effetto trascurabile)?\nQual è l’intervallo entro cui cade il 89% degli effetti più credibili?\n\nQueste domande trovano risposta diretta nei dati posteriori:\n\nmean(d_samples &gt; 0.5)  # Probabilità che l'effetto sia almeno medio\n#&gt; [1] 0.7873\nmean(d_samples &gt; 0.8)  # Probabilità che l'effetto sia grande\n#&gt; [1] 0.037\nmean(d_samples &lt; 0.2)  # Probabilità che l'effetto sia trascurabile\n#&gt; [1] 0.00025",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>La grandezza dell’effetto: valutare la rilevanza pratica</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07a_effect_size.html#la-soglia-di-rilevanza-pratica",
    "href": "chapters/linear_models/07a_effect_size.html#la-soglia-di-rilevanza-pratica",
    "title": "67  La grandezza dell’effetto: valutare la rilevanza pratica",
    "section": "\n67.6 La soglia di rilevanza pratica",
    "text": "67.6 La soglia di rilevanza pratica\nIn contesti applicativi, non basta sapere che l’effetto è diverso da zero: bisogna chiedersi se supera una soglia minima di rilevanza (minimum effect of interest, o region of practical equivalence).\nAd esempio, se uno psicologo clinico ritiene che un effetto inferiore a d = 0.3 sia irrilevante dal punto di vista terapeutico, può valutare:\n\nmean(d_samples &gt; 0.3)\n#&gt; [1] 0.9938\n\nQuesta quantità risponde alla domanda: qual è la probabilità che l’effetto sia rilevante nella pratica clinica?",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>La grandezza dell’effetto: valutare la rilevanza pratica</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07a_effect_size.html#riflessioni-conclusive",
    "href": "chapters/linear_models/07a_effect_size.html#riflessioni-conclusive",
    "title": "67  La grandezza dell’effetto: valutare la rilevanza pratica",
    "section": "\n67.7 Riflessioni conclusive",
    "text": "67.7 Riflessioni conclusive\nL’American Psychological Association (APA) raccomanda vivamente di riportare le dimensioni dell’effetto (effect size) nei lavori di ricerca, in aggiunta o in alternativa alla sola verifica di ipotesi. Questo perché l’effect size fornisce un’indicazione quantitativa della magnitudine di un fenomeno, offrendo una prospettiva più informativa rispetto alla sola significatività statistica. Conoscere l’esistenza di un effetto non basta: è necessario comprenderne l’entità per valutare se esso sia teoricamente interessante o praticamente rilevante.\nNel contesto della statistica frequentista, l’effect size è spesso presentato come una stima puntuale, accompagnata da un intervallo di confidenza che rappresenta la variabilità campionaria attesa in ipotetiche ripetizioni dell’esperimento. Tuttavia, questa rappresentazione può indurre interpretazioni dicotomiche (ad esempio: significativo/non significativo), che rischiano di semplificare eccessivamente la complessità dei dati.\nL’approccio bayesiano, invece, adotta una prospettiva differente e più sfumata. L’effect size è trattato come una variabile aleatoria, di cui si stima una distribuzione a posteriori: una funzione di densità che esprime quali valori dell’effetto sono più compatibili con i dati osservati, tenendo conto anche delle conoscenze pregresse (esplicitate attraverso una distribuzione a priori). Questo consente di:\n\nformulare affermazioni probabilistiche dirette, del tipo: “c’è il 90% di probabilità che l’effetto sia almeno di media grandezza”;\n\nquantificare l’incertezza in modo trasparente e continuo, evitando l’uso di soglie arbitrarie;\n\nintegrare teoria e dati: le aspettative teoriche non sono ignorate, ma formalmente incorporate nel processo inferenziale.\n\nQuesta modalità di ragionamento è particolarmente adatta alle scienze psicologiche, dove la complessità dei fenomeni e la variabilità interindividuale sono elevati. L’obiettivo non è stabilire una verità assoluta, ma descrivere in modo credibile e informato quanto plausibile sia un certo effetto, in relazione ai dati disponibili.\nIn questo senso, la dimensione dell’effetto diventa uno strumento inferenziale a pieno titolo, non soltanto un valore da riportare a margine. Essa permette di esprimere con maggiore chiarezza comunicativa quanto i risultati ottenuti siano compatibili con ipotesi teoriche, cliniche o applicative, stimolando riflessioni più ricche e meno soggette a distorsioni interpretative.\nIn conclusione, adottare una prospettiva bayesiana sull’analisi della dimensione dell’effetto significa spostarsi da un paradigma decisionale rigido a uno probabilistico e argomentativo, in cui i risultati vengono valutati alla luce della loro plausibilità, coerenza teorica e rilevanza pratica. Questo approccio non solo migliora la qualità dell’inferenza, ma contribuisce a una scienza psicologica più trasparente, riflessiva e orientata al significato.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>La grandezza dell’effetto: valutare la rilevanza pratica</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07a_effect_size.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/07a_effect_size.html#informazioni-sullambiente-di-sviluppo",
    "title": "67  La grandezza dell’effetto: valutare la rilevanza pratica",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] insight_1.3.0     bayestestR_0.16.0 brms_2.22.0       Rcpp_1.0.14      \n#&gt;  [5] posterior_1.6.1   cmdstanr_0.9.0    thematic_0.1.7    MetBrewer_0.2.0  \n#&gt;  [9] ggokabeito_0.1.0  see_0.11.0        gridExtra_2.3     patchwork_1.3.0  \n#&gt; [13] bayesplot_1.13.0  psych_2.5.3       scales_1.4.0      markdown_2.0     \n#&gt; [17] knitr_1.50        lubridate_1.9.4   forcats_1.0.0     stringr_1.5.1    \n#&gt; [21] dplyr_1.1.4       purrr_1.0.4       readr_2.1.5       tidyr_1.3.1      \n#&gt; [25] tibble_3.3.0      ggplot2_3.5.2     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [29] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] mnormt_2.1.1         inline_0.3.21        sandwich_3.1-1      \n#&gt;  [4] rlang_1.1.6          magrittr_2.0.3       multcomp_1.4-28     \n#&gt;  [7] matrixStats_1.5.0    ggridges_0.5.6       compiler_4.5.0      \n#&gt; [10] loo_2.8.0            vctrs_0.6.5          reshape2_1.4.4      \n#&gt; [13] pkgconfig_2.0.3      fastmap_1.2.0        backports_1.5.0     \n#&gt; [16] labeling_0.4.3       rmarkdown_2.29       tzdb_0.5.0          \n#&gt; [19] haven_2.5.5          ps_1.9.1             xfun_0.52           \n#&gt; [22] jsonlite_2.0.0       parallel_4.5.0       R6_2.6.1            \n#&gt; [25] stringi_1.8.7        RColorBrewer_1.1-3   StanHeaders_2.32.10 \n#&gt; [28] estimability_1.5.1   rstan_2.32.7         zoo_1.8-14          \n#&gt; [31] pacman_0.5.1         R.utils_2.13.0       Matrix_1.7-3        \n#&gt; [34] splines_4.5.0        timechange_0.3.0     tidyselect_1.2.1    \n#&gt; [37] rstudioapi_0.17.1    abind_1.4-8          yaml_2.3.10         \n#&gt; [40] codetools_0.2-20     curl_6.3.0           processx_3.8.6      \n#&gt; [43] pkgbuild_1.4.8       lattice_0.22-7       plyr_1.8.9          \n#&gt; [46] withr_3.0.2          bridgesampling_1.1-2 coda_0.19-4.1       \n#&gt; [49] evaluate_1.0.4       survival_3.8-3       RcppParallel_5.1.10 \n#&gt; [52] pillar_1.10.2        tensorA_0.36.2.1     checkmate_2.3.2     \n#&gt; [55] stats4_4.5.0         distributional_0.5.0 generics_0.1.4      \n#&gt; [58] rprojroot_2.0.4      hms_1.1.3            rstantools_2.4.0    \n#&gt; [61] xtable_1.8-4         glue_1.8.0           emmeans_1.11.1      \n#&gt; [64] tools_4.5.0          data.table_1.17.6    mvtnorm_1.3-3       \n#&gt; [67] grid_4.5.0           QuickJSR_1.8.0       datawizard_1.1.0    \n#&gt; [70] colorspace_2.1-1     nlme_3.1-168         cli_3.6.5           \n#&gt; [73] Brobdingnag_1.2-9    V8_6.0.4             gtable_0.3.6        \n#&gt; [76] R.methodsS3_1.8.2    digest_0.6.37        TH.data_1.1-3       \n#&gt; [79] htmlwidgets_1.6.4    farver_2.1.2         htmltools_0.5.8.1   \n#&gt; [82] R.oo_1.27.1          lifecycle_1.0.4      MASS_7.3-65",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>La grandezza dell’effetto: valutare la rilevanza pratica</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07a_effect_size.html#bibliografia",
    "href": "chapters/linear_models/07a_effect_size.html#bibliografia",
    "title": "67  La grandezza dell’effetto: valutare la rilevanza pratica",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nKruschke, J. K. (2013). Bayesian estimation supersedes the t test. Journal of Experimental Psychology: General, 142(2), 573–603.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>La grandezza dell’effetto: valutare la rilevanza pratica</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_sample_size.html",
    "href": "chapters/linear_models/08_sample_size.html",
    "title": "68  Pianificazione della dimensione campionaria",
    "section": "",
    "text": "68.1 Introduzione\nNel contesto bayesiano, l’obiettivo principale non è verificare un’ipotesi nulla, ma stimare con quanta incertezza possiamo affermare che un effetto ha una certa ampiezza pratica. Questo approccio è particolarmente rilevante in psicologia, dove l’importanza di un risultato raramente si esaurisce nella sua “significatività statistica”.\nTuttavia, nella pratica scientifica è ancora diffuso l’uso della potenza frequentista. Per completezza, in questo capitolo presentiamo sia la formula classica per la potenza in un confronto tra due medie, sia una sua controparte bayesiana basata su simulazione. Il nostro scopo è mostrare come un approccio bayesiano orientato alla stima e alla simulazione possa offrire strumenti più flessibili, informativi e utili alla pianificazione degli studi.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>Pianificazione della dimensione campionaria</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_sample_size.html#lapproccio-frequentista",
    "href": "chapters/linear_models/08_sample_size.html#lapproccio-frequentista",
    "title": "68  Pianificazione della dimensione campionaria",
    "section": "\n68.2 L’approccio frequentista",
    "text": "68.2 L’approccio frequentista\nNel framework frequentista, la potenza è definita come la probabilità, calcolata prima che uno studio venga condotto, che un determinato test statistico produca un p-value inferiore a una soglia prestabilita (tipicamente 0,05), dato un effetto reale ipotizzato.\nIl calcolo della potenza richiede:\n\nuna stima della dimensione dell’effetto atteso,\nuna stima della variabilità nei dati (deviazione standard),\nuna decisione sulla soglia di significatività,\ne infine un calcolo (o simulazione) della probabilità che il p-value sia &lt; 0.05.\n\nSi sconsiglia in genere di condurre studi con potenza bassa, perché hanno una bassa probabilità di produrre risultati “significativi”. Tuttavia, questo ragionamento non considera che il concetto stesso di significatività può essere fuorviante: anche quando un test ha potenza dell’80%, ciò non garantisce che l’effetto stimato sia preciso o utile.\n\n68.2.1 La maledizione del vincitore\nUno studio con bassa potenza può produrre risultati statisticamente significativi che sono ingannevoli. In presenza di molto rumore, gli effetti significativi osservati tendono a essere:\n\n\nesagerati (errore di tipo \\(M\\), magnitude),\n\nsbagliati nel segno (errore di tipo \\(S\\), sign).\n\nIn altre parole, anche quando uno studio riesce a “scoprire” un effetto, la stima ottenuta può essere gravemente distorta. Questa è una delle ragioni principali per cui molti risultati pubblicati si rivelano non replicabili (Gelman & Carlin, 2014).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>Pianificazione della dimensione campionaria</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_sample_size.html#un-esempio-concreto",
    "href": "chapters/linear_models/08_sample_size.html#un-esempio-concreto",
    "title": "68  Pianificazione della dimensione campionaria",
    "section": "\n68.3 Un esempio concreto",
    "text": "68.3 Un esempio concreto\nPer rendere il confronto più chiaro, usiamo un esempio con gli stessi dati in entrambi gli approcci:\n\ndifferenza vera tra le medie: \\(\\Delta = 5\\);\ndeviazione standard comune: \\(\\sigma = 10\\);\ndimensione del campione: \\(n = 64\\) per gruppo;\neffetto standardizzato: Cohen’s d = 0.5",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>Pianificazione della dimensione campionaria</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_sample_size.html#analisi-frequentista-dimensione-del-campione-per-potenza-dell80",
    "href": "chapters/linear_models/08_sample_size.html#analisi-frequentista-dimensione-del-campione-per-potenza-dell80",
    "title": "68  Pianificazione della dimensione campionaria",
    "section": "\n68.4 Analisi frequentista: dimensione del campione per potenza dell’80%",
    "text": "68.4 Analisi frequentista: dimensione del campione per potenza dell’80%\nPer stimare la dimensione del campione necessaria a ottenere una potenza dell’80% in un confronto tra due gruppi indipendenti (con varianza uguale), possiamo usare la funzione power.t.test() disponibile in R.\nNel nostro esempio ipotizziamo:\n\nuna differenza attesa tra i gruppi pari a \\(\\Delta = 5\\),\nuna deviazione standard comune pari a \\(\\sigma = 10\\),\nun test bilaterale con livello di significatività \\(\\alpha = 0.05\\).\n\n\n68.4.1 Calcolo in R\n\n# Calcolo della dimensione campionaria necessaria per 80% di potenza\npower.t.test(\n  delta = 5,        # differenza attesa tra le medie\n  sd    = 10,       # deviazione standard\n  power = 0.8,      # potenza desiderata\n  sig.level = 0.05, # livello di significatività\n  type = \"two.sample\",\n  alternative = \"two.sided\"\n)\n#&gt; \n#&gt;      Two-sample t test power calculation \n#&gt; \n#&gt;               n = 63.77\n#&gt;           delta = 5\n#&gt;              sd = 10\n#&gt;       sig.level = 0.05\n#&gt;           power = 0.8\n#&gt;     alternative = two.sided\n#&gt; \n#&gt; NOTE: n is number in *each* group\n\nIl risultato indica che sono necessari circa 64 partecipanti per gruppo per ottenere l’80% di potenza con questi parametri. Tuttavia, come vedremo nella sezione successiva, questo valore non garantisce necessariamente che la stima dell’effetto sarà sufficientemente precisa o utile dal punto di vista decisionale. L’analisi bayesiana ci offrirà uno strumento più flessibile per valutare l’informatività del disegno proposto.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>Pianificazione della dimensione campionaria</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_sample_size.html#analisi-bayesiana-informatività-a-posteriori",
    "href": "chapters/linear_models/08_sample_size.html#analisi-bayesiana-informatività-a-posteriori",
    "title": "68  Pianificazione della dimensione campionaria",
    "section": "\n68.5 Analisi bayesiana: informatività a posteriori",
    "text": "68.5 Analisi bayesiana: informatività a posteriori\nNell’approccio bayesiano, non ci si chiede se l’effetto è “significativo” rispetto a una soglia arbitraria, ma quanto è informativo il risultato per prendere decisioni pratiche. In questo contesto, pianificare uno studio significa domandarsi:\n“Con quanti dati il mio modello bayesiano riuscirà a fornire una stima sufficientemente precisa e utile dell’effetto?”\nPer rispondere, possiamo stabilire dei criteri di informatività che riflettano le esigenze del nostro problema. Due criteri possibili sono:\n\nl’intervallo di credibilità all’89% per Cohen’s d ha larghezza ≤ 0.4 (criterio di precisione);\nla probabilità a posteriori che d &gt; 0.3 è ≥ 90% (criterio di utilità pratica).\n\n\n68.5.1 Simulazione generativa di uno studio\nPer verificare se un disegno sperimentale con \\(n = 64\\) per gruppo soddisfa questi criteri, possiamo simulare uno studio 100 volte, ogni volta:\n\ngenerando nuovi dati,\nstimando un modello bayesiano,\nvalutando se il risultato è sufficientemente informativo.\n\nDi seguito definiamo la funzione sim_once() che esegue una singola simulazione.\n\n# Funzione per standardizzare su scala z\nstandardise &lt;- function(x) (x - mean(x)) / sd(x)\n\n# Una singola simulazione bayesiana di uno studio\nsim_once &lt;- function(n = 64, mu0 = 100, delta = 5, sigma = 10) {\n\n  # 1. Generazione dei dati\n  y0 &lt;- rnorm(n, mu0, sigma)         # gruppo controllo\n  y1 &lt;- rnorm(n, mu0 + delta, sigma) # gruppo trattamento\n\n  # 2. Standardizzazione\n  dat &lt;- tibble(score = standardise(c(y0, y1)),\n                group = factor(rep(c(\"ctrl\", \"trt\"), each = n)))\n\n  # 3. Stima del modello bayesiano\n  fit &lt;- brm(score ~ group,\n             data = dat,\n             backend = \"cmdstanr\",\n             chains = 2, iter = 1000, warmup = 500,\n             refresh = 0, silent = 0,\n             prior = c(\n               prior(normal(0, 2), class = \"b\"),\n               prior(exponential(2), class = \"sigma\")\n             ))\n\n  # 4. Estrazione dei campioni posteriori e calcolo di Cohen's d\n  post &lt;- as_draws_df(fit)\n  d_smp &lt;- post$b_grouptrt / post$sigma\n\n  # 5. Output: due indici di informatività\n  tibble(\n    CIw89  = diff(quantile(d_smp, c(.055, .945))),  # larghezza IC 89%\n    p_gt03 = mean(d_smp &gt; 0.3)                      # P(d &gt; 0.3)\n  )\n}\n\nEcco cosa succede passo passo:\n\nSimulazione dei dati\n\n  y0 &lt;- rnorm(n, mu0, sigma)\n  y1 &lt;- rnorm(n, mu0 + delta, sigma)\n\n\nSi generano due gruppi di n = 64 osservazioni:\n\nIl gruppo di controllo ha media mu0 = 100.\nIl gruppo trattamento ha media aumentata di delta = 5.\nEntrambi i gruppi hanno la stessa variabilità (sigma = 10).\n\n\nIn pratica: simula un esperimento in cui il trattamento ha un effetto medio di 5 unità.\n\n\nStandardizzazione dei dati\n\n  score = standardise(c(y0, y1))\n\nLe osservazioni dei due gruppi vengono unite e standardizzate (portate su scala z): media = 0, deviazione standard = 1.\n\nQuesto serve a:\n\nrendere i dati comparabili tra simulazioni,\nsemplificare l’interpretazione dei risultati (si lavora su scala standardizzata).\n\n\n\n\nCreazione del dataset\n\n  dat &lt;- tibble(score = ..., group = ...)\n\n\nSi crea una tabella con le variabili:\n\nscore: i dati standardizzati\ngroup: un’etichetta che indica se il dato appartiene al gruppo controllo (ctrl) o trattamento (trt).\n\n\n\n\nStima del modello bayesiano\n\n  fit &lt;- brm(score ~ group, ...)\n\n\nSi stima un modello bayesiano con brms, dove:\n\nla variabile score è prevista dalla variabile group,\nsi usano priori debolmente informativi su effetto (b) e variabilità (sigma).\n\n\nIl coefficiente b_grouptrt stima la differenza media tra i gruppi (sulla scala standardizzata).\n\n\nEstrazione dei campioni posteriori\n\n  post &lt;- as_draws_df(fit)\n  d_smp &lt;- post$b_grouptrt / post$sigma\n\nSi estraggono i campioni dalla distribuzione a posteriori.\nSi calcola Cohen’s d a posteriori dividendo l’effetto stimato per la deviazione standard stimata: d_smp.\n\n\nOutput: due indicatori di informatività\n\n  tibble(\n    CIw89  = diff(quantile(d_smp, c(.055, .945))),\n    p_gt03 = mean(d_smp &gt; 0.3)\n  )\n\n\nCIw89: larghezza dell’intervallo di credibilità all’89% → misura di precisione.\n\np_gt03: proporzione dei campioni a posteriori in cui d &gt; 0.3 → misura di utilità pratica.\n\nIn sintesi, ogni volta che chiami sim_once():\n\nsimuli un nuovo dataset realistico;\nstimi l’effetto del trattamento con un modello bayesiano;\nmisuri quanto è preciso e informativo il risultato.\n\nQuesta funzione è il mattone fondamentale per la simulazione generativa di uno studio: ti permette di verificare, ad esempio, se con n = 64 per gruppo riesci a stimare d in modo sufficientemente utile.\n\n68.5.2 Esecuzione della simulazione\nSimuliamo 100 studi indipendenti con n = 64 per gruppo:\n\nset.seed(123)\nres &lt;- bind_rows(replicate(100, sim_once(), simplify = FALSE))\n\nEsaminiamo i risultati della simulazione:\n\nresum &lt;- summarise(res,\n  mean_CI   = mean(CIw89),\n  sd_CI     = sd(CIw89),\n  prop_good = mean(p_gt03 &gt;= 0.9)\n)\nprint(resum)\n#&gt; # A tibble: 1 × 3\n#&gt;   mean_CI  sd_CI prop_good\n#&gt;     &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1   0.569 0.0206      0.35\n\n\n68.5.3 Visualizzazione dei risultati\nIl primo grafico mostra la distribuzione delle larghezze degli intervalli di credibilità all’89%, evidenziando quante simulazioni superano la soglia di 0.4. Il secondo mostra quante simulazioni soddisfano il criterio di utilità.\n\n# Grafico 1: distribuzione della larghezza IC89\nggplot(res, aes(x = CIw89)) +\n  geom_histogram(binwidth = 0.02, fill = \"#69b3a2\", color = \"white\") +\n  geom_vline(xintercept = 0.4, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Distribuzione della larghezza\\ndell'intervallo di credibilità (89%)\",\n    x = \"Larghezza IC89\",\n    y = \"Frequenza\"\n  ) \n\n\n\n\n\n\n\n\n# Grafico 2: classificazione delle simulazioni utili/non utili\nggplot(res, aes(x = p_gt03 &gt;= 0.9)) +\n  geom_bar(fill = \"#404080\") +\n  scale_x_discrete(labels = c(\"FALSE\" = \"Non utile\", \"TRUE\" = \"Utile\")) +\n  labs(\n    title = \"Numero di simulazioni che superano\\nil criterio di utilità\",\n    x = \"Criterio: P(d &gt; 0.3) ≥ 0.9\",\n    y = \"Numero di simulazioni\"\n  ) \n\n\n\n\n\n\n\n\n68.5.4 Interpretazione dei risultati\n\n\nmean_CI rappresenta la larghezza media dell’intervallo di credibilità all’89%. Nel nostro caso è circa 0.569, quindi troppo ampio per considerare la stima precisa.\n\nprop_good è la proporzione di simulazioni in cui l’evidenza a favore di un effetto pratico d &gt; 0.3 supera il 90%. Con prop_good = 0.1, solo 1 simulazione su 10 soddisfa questo criterio.\n\nConclusione: con n = 64 per gruppo, lo studio simulato è sottodimensionato: raramente produce una stima precisa e utile. Serve un campione più grande (es. n = 80 o n = 100) per raggiungere criteri più severi di informatività.\n\n68.5.5 Confronto con la potenza frequentista\nSecondo l’approccio frequentista, n = 64 per gruppo garantisce circa 80% di potenza per d = 0.5. Ma la simulazione bayesiana mostra che:\n\nl’intervallo di credibilità risulta troppo ampio (≈ 0.57);\nl’evidenza utile (P(d &gt; 0.3) ≥ 0.9) si verifica solo nel 10% dei casi.\n\nQuesto evidenzia i limiti della potenza come unico criterio per pianificare gli studi. Anche uno studio “con potenza adeguata” potrebbe produrre risultati imprecisi o non praticabili, e contribuire agli errori di tipo M (esagerazione della stima) o S (errore nel segno dell’effetto).\nIn sintesi, pianificare uno studio non significa garantire il p &lt; .05, ma garantire che la stima sia abbastanza precisa e utile per informare decisioni.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>Pianificazione della dimensione campionaria</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_sample_size.html#riflessioni-conclusive",
    "href": "chapters/linear_models/08_sample_size.html#riflessioni-conclusive",
    "title": "68  Pianificazione della dimensione campionaria",
    "section": "\n68.6 Riflessioni Conclusive",
    "text": "68.6 Riflessioni Conclusive\n\nL’approccio bayesiano consente di valutare in modo più trasparente quanto i risultati previsti saranno precisi e utili.\nAnche se un disegno ha potenza dell’80%, potrebbe non produrre stime sufficientemente informative.\nLa simulazione bayesiana è uno strumento efficace per esplorare scenari realistici prima di raccogliere dati.\n\nBuona pratica: non fermarti al calcolo della potenza. Definisci criteri di utilità, simula gli studi e verifica se i dati attesi permetteranno davvero di rispondere alla tua domanda.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>Pianificazione della dimensione campionaria</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_sample_size.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/08_sample_size.html#informazioni-sullambiente-di-sviluppo",
    "title": "68  Pianificazione della dimensione campionaria",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] cmdstanr_0.9.0   brms_2.22.0      Rcpp_1.0.14      mice_3.18.0     \n#&gt;  [5] thematic_0.1.7   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [9] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.13.0 psych_2.5.3     \n#&gt; [13] scales_1.4.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [17] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [21] readr_2.1.5      tidyr_1.3.1      tibble_3.3.0     ggplot2_3.5.2   \n#&gt; [25] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] Rdpack_2.6.4         mnormt_2.1.1         inline_0.3.21       \n#&gt;  [4] sandwich_3.1-1       rlang_1.1.6          magrittr_2.0.3      \n#&gt;  [7] multcomp_1.4-28      matrixStats_1.5.0    compiler_4.5.0      \n#&gt; [10] loo_2.8.0            vctrs_0.6.5          pkgconfig_2.0.3     \n#&gt; [13] shape_1.4.6.1        fastmap_1.2.0        backports_1.5.0     \n#&gt; [16] labeling_0.4.3       rmarkdown_2.29       tzdb_0.5.0          \n#&gt; [19] ps_1.9.1             nloptr_2.2.1         xfun_0.52           \n#&gt; [22] glmnet_4.1-9         jomo_2.7-6           jsonlite_2.0.0      \n#&gt; [25] pan_1.9              broom_1.0.8          parallel_4.5.0      \n#&gt; [28] R6_2.6.1             StanHeaders_2.32.10  stringi_1.8.7       \n#&gt; [31] RColorBrewer_1.1-3   boot_1.3-31          rpart_4.1.24        \n#&gt; [34] estimability_1.5.1   rstan_2.32.7         iterators_1.0.14    \n#&gt; [37] zoo_1.8-14           pacman_0.5.1         Matrix_1.7-3        \n#&gt; [40] splines_4.5.0        nnet_7.3-20          timechange_0.3.0    \n#&gt; [43] tidyselect_1.2.1     rstudioapi_0.17.1    abind_1.4-8         \n#&gt; [46] yaml_2.3.10          codetools_0.2-20     curl_6.3.0          \n#&gt; [49] processx_3.8.6       pkgbuild_1.4.8       lattice_0.22-7      \n#&gt; [52] withr_3.0.2          bridgesampling_1.1-2 posterior_1.6.1     \n#&gt; [55] coda_0.19-4.1        evaluate_1.0.4       survival_3.8-3      \n#&gt; [58] RcppParallel_5.1.10  pillar_1.10.2        tensorA_0.36.2.1    \n#&gt; [61] stats4_4.5.0         checkmate_2.3.2      foreach_1.5.2       \n#&gt; [64] reformulas_0.4.1     distributional_0.5.0 generics_0.1.4      \n#&gt; [67] rprojroot_2.0.4      hms_1.1.3            rstantools_2.4.0    \n#&gt; [70] minqa_1.2.8          xtable_1.8-4         glue_1.8.0          \n#&gt; [73] emmeans_1.11.1       tools_4.5.0          data.table_1.17.6   \n#&gt; [76] lme4_1.1-37          mvtnorm_1.3-3        grid_4.5.0          \n#&gt; [79] QuickJSR_1.8.0       rbibutils_2.3        colorspace_2.1-1    \n#&gt; [82] nlme_3.1-168         cli_3.6.5            Brobdingnag_1.2-9   \n#&gt; [85] V8_6.0.4             gtable_0.3.6         digest_0.6.37       \n#&gt; [88] TH.data_1.1-3        htmlwidgets_1.6.4    farver_2.1.2        \n#&gt; [91] htmltools_0.5.8.1    lifecycle_1.0.4      mitml_0.4-5         \n#&gt; [94] MASS_7.3-65",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>Pianificazione della dimensione campionaria</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_sample_size.html#bibliografia",
    "href": "chapters/linear_models/08_sample_size.html#bibliografia",
    "title": "68  Pianificazione della dimensione campionaria",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., & Carlin, J. (2014). Beyond Power Calculations: Assessing Type S (Sign) and Type M (Magnitude) Errors. Perspectives on Psychological Science, 9(6), 641–651.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>Pianificazione della dimensione campionaria</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html",
    "href": "chapters/linear_models/09_anova_1via.html",
    "title": "69  ANOVA ad una via",
    "section": "",
    "text": "69.1 Preparazione del Notebook\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, posterior, bayestestR, brms, emmeans)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#introduzione",
    "href": "chapters/linear_models/09_anova_1via.html#introduzione",
    "title": "69  ANOVA ad una via",
    "section": "Introduzione",
    "text": "Introduzione\n\nNel Capitolo 66 ci siamo concentrati sul confronto tra due gruppi utilizzando una regressione lineare con variabili dummy. Questo approccio ci ha permesso di modellare in modo semplice l’effetto di un fattore binario e di stimare con incertezza l’ampiezza della differenza. Ora estendiamo quella logica al caso in cui il fattore abbia più di due livelli.\n\nQuesto passaggio ci introduce al cuore dell’ANOVA a una via, che non è altro che un modello lineare con un fattore categoriale a \\(k\\) livelli. In questo contesto, ci interessa capire quanta variabilità nei dati può essere attribuita alle differenze tra gruppi, e quanto invece rimane all’interno dei gruppi stessi. Come sempre in questo manuale, manterremo una lettura orientata all’incertezza e alla variabilità intra- e inter-individuale, trattando l’inferenza come uno strumento per quantificare la credibilità delle ipotesi.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#codifica-del-modello-con-variabili-dummy",
    "href": "chapters/linear_models/09_anova_1via.html#codifica-del-modello-con-variabili-dummy",
    "title": "69  ANOVA ad una via",
    "section": "\n69.2 Codifica del modello con variabili dummy",
    "text": "69.2 Codifica del modello con variabili dummy\nSupponiamo un esperimento con tre gruppi. Per rappresentare questo fattore all’interno di un modello lineare, usiamo due variabili dummy e consideriamo il terzo gruppo come riferimento implicito. Il modello assume la forma:\n\\[\nY_i = \\alpha + \\gamma_1 D_{i1} + \\gamma_2 D_{i2} + \\varepsilon_i\n\\tag{69.1}\\]\ndove:\n\n\n\\(\\alpha\\) è l’intercetta del modello,\n\n\\(\\gamma_1\\) e \\(\\gamma_2\\) sono i coefficienti associati alle variabili dummy,\n\n\\(D_{i1}\\) e \\(D_{i2}\\) indicano l’appartenenza dell’osservazione \\(i\\) ai gruppi 1 e 2, rispettivamente,\n\n\\(\\varepsilon_i\\) è l’errore aleatorio.\n\nLa codifica delle dummy è la seguente:\n\\[\n\\begin{array}{c|cc}\n\\text{Gruppo} & D_{1} & D_{2} \\\\\n\\hline\n1 & 1 & 0 \\\\\n2 & 0 & 1 \\\\\n3 & 0 & 0\n\\end{array}\n\\tag{69.2}\\]\n\n69.2.1 Interpretazione dei parametri\nCon questa codifica, possiamo esprimere le medie di ciascun gruppo come:\n\\[\n\\begin{aligned}\n\\mu_1 &= \\alpha + \\gamma_1 \\\\\n\\mu_2 &= \\alpha + \\gamma_2 \\\\\n\\mu_3 &= \\alpha\n\\end{aligned}\n\\]\nDa cui otteniamo:\n\\[\n\\alpha = \\mu_3, \\quad \\gamma_1 = \\mu_1 - \\mu_3, \\quad \\gamma_2 = \\mu_2 - \\mu_3.\n\\]\nQuindi:\n\n\n\\(\\alpha\\): media del gruppo 3 (riferimento),\n\n\\(\\gamma_1\\): quanto il gruppo 1 si discosta da \\(\\mu_3\\),\n\n\\(\\gamma_2\\): quanto il gruppo 2 si discosta da \\(\\mu_3\\).\n\nIn un’ottica bayesiana, questi coefficienti possono essere pensati come distribuzioni: esprimono quanto crediamo che ciascuna differenza sia plausibile, date le osservazioni. Passiamo ora a una simulazione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#simulazione",
    "href": "chapters/linear_models/09_anova_1via.html#simulazione",
    "title": "69  ANOVA ad una via",
    "section": "\n69.3 Simulazione",
    "text": "69.3 Simulazione\nSimuliamo un esperimento con tre condizioni: controllo, psicoterapia1 e psicoterapia2. Ogni gruppo ha una media diversa ma la stessa deviazione standard. Ci interessa modellare la variabilità tra le condizioni e interpretare le differenze in modo probabilistico.\n\nset.seed(123)\n\nn &lt;- 30  # numero di osservazioni per gruppo\n# Medie di ciascun gruppo\nmean_control &lt;- 30\nmean_psico1  &lt;- 25\nmean_psico2  &lt;- 20\n# Deviazione standard comune\nsd_value &lt;- 5\n\n# Generazione dei dati\ncontrollo     &lt;- rnorm(n, mean_control, sd_value)\npsicoterapia1 &lt;- rnorm(n, mean_psico1,  sd_value)\npsicoterapia2 &lt;- rnorm(n, mean_psico2,  sd_value)\n\n# Creazione del data frame\ndf &lt;- data.frame(\n  condizione = rep(c(\"controllo\", \"psicoterapia1\", \"psicoterapia2\"), each = n),\n  punteggio  = c(controllo, psicoterapia1, psicoterapia2)\n)\n\ndf |&gt; head()\n#&gt;   condizione punteggio\n#&gt; 1  controllo     27.20\n#&gt; 2  controllo     28.85\n#&gt; 3  controllo     37.79\n#&gt; 4  controllo     30.35\n#&gt; 5  controllo     30.65\n#&gt; 6  controllo     38.58\n\n\n69.3.1 Esplorazione iniziale\nVisualizziamo le distribuzioni dei punteggi:\n\nggplot(df, aes(x = condizione, y = punteggio, fill = condizione)) +\n  geom_violin(trim = FALSE) +\n  geom_boxplot(width = 0.2, outlier.shape = NA) +\n  labs(\n    title = \"Distribuzione dei punteggi di depressione per gruppo\",\n    x = \"Condizione sperimentale\",\n    y = \"Punteggio di depressione\"\n  ) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\nCalcoliamo media e deviazione standard per ogni gruppo:\n\ndf |&gt; \n  group_by(condizione) |&gt; \n  summarize(\n    media = mean(punteggio),\n    sd = sd(punteggio)\n  )\n#&gt; # A tibble: 3 × 3\n#&gt;   condizione    media    sd\n#&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 controllo      29.8  4.91\n#&gt; 2 psicoterapia1  25.9  4.18\n#&gt; 3 psicoterapia2  20.1  4.35",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#modello-lineare-con-variabili-dummy",
    "href": "chapters/linear_models/09_anova_1via.html#modello-lineare-con-variabili-dummy",
    "title": "69  ANOVA ad una via",
    "section": "\n69.4 Modello lineare con variabili dummy",
    "text": "69.4 Modello lineare con variabili dummy\nConvertiamo condizione in fattore e definiamo controllo come categoria di riferimento:\n\ndf$condizione &lt;- factor(df$condizione)\ndf$condizione &lt;- relevel(df$condizione, ref = \"controllo\")\ncontrasts(df$condizione)\n#&gt;               psicoterapia1 psicoterapia2\n#&gt; controllo                 0             0\n#&gt; psicoterapia1             1             0\n#&gt; psicoterapia2             0             1\n\nIl modello di regressione con le variabili dummy sarà:\n\\[\nY_i = \\beta_0 + \\beta_1 \\cdot \\text{psicoterapia1}_i + \\beta_2 \\cdot \\text{psicoterapia2}_i + \\varepsilon_i,\n\\]\ndove:\n\n\n\\(\\beta_0\\) è la media del gruppo di controllo;\n\n\\(\\beta_1\\) e \\(\\beta_2\\) sono le differenze tra le rispettive psicoterapie e il gruppo di controllo.\n\n\n69.4.1 Stima del modello\nEseguiamo una prima analisi usando il metodo di massima verosimiglianza:\n\nfm1 &lt;- lm(punteggio ~ condizione, data = df)\n\n\nsummary(fm1)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = punteggio ~ condizione, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -11.668  -2.620  -0.183   2.681  10.128 \n#&gt; \n#&gt; Coefficients:\n#&gt;                         Estimate Std. Error t value Pr(&gt;|t|)\n#&gt; (Intercept)               29.764      0.819   36.33  &lt; 2e-16\n#&gt; condizionepsicoterapia1   -3.873      1.159   -3.34   0.0012\n#&gt; condizionepsicoterapia2   -9.642      1.159   -8.32  1.1e-12\n#&gt; \n#&gt; Residual standard error: 4.49 on 87 degrees of freedom\n#&gt; Multiple R-squared:  0.446,  Adjusted R-squared:  0.434 \n#&gt; F-statistic: 35.1 on 2 and 87 DF,  p-value: 6.75e-12\n\nVerifica delle medie e differenze tra i gruppi:\n\nout &lt;- tapply(df$punteggio, df$condizione, mean)\nout[2] - out[1]  # psicoterapia1 - controllo\n#&gt; psicoterapia1 \n#&gt;        -3.873\nout[3] - out[1]  # psicoterapia2 - controllo\n#&gt; psicoterapia2 \n#&gt;        -9.642",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#contrasti-personalizzati",
    "href": "chapters/linear_models/09_anova_1via.html#contrasti-personalizzati",
    "title": "69  ANOVA ad una via",
    "section": "\n69.5 Contrasti personalizzati",
    "text": "69.5 Contrasti personalizzati\nI contrasti ci permettono di andare oltre il test globale e formulare ipotesi teoriche mirate. Ad esempio:\n\nla media del gruppo controllo è diversa dalla media delle due psicoterapie?\nle due psicoterapie differiscono tra loro?\n\nA questo fine, specifichiamo la seguente matrice dei contrasti:\n\nmy_contrasts &lt;- matrix(c(\n  0.6667,  0,     # controllo\n -0.3333,  0.5,   # psicoterapia1\n -0.3333, -0.5    # psicoterapia2\n), ncol = 2, byrow = TRUE)\n\ncolnames(my_contrasts) &lt;- c(\"Ctrl_vs_PsicoMean\", \"P1_vs_P2\")\nrownames(my_contrasts) &lt;- c(\"controllo\", \"psicoterapia1\", \"psicoterapia2\")\n\ncontrasts(df$condizione) &lt;- my_contrasts\n\nAdattiamo il modello:\n\nmod_custom &lt;- lm(punteggio ~ condizione, data = df)\n\nEsaminiamo i coefficienti:\n\nsummary(mod_custom)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = punteggio ~ condizione, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -11.668  -2.620  -0.183   2.681  10.128 \n#&gt; \n#&gt; Coefficients:\n#&gt;                             Estimate Std. Error t value Pr(&gt;|t|)\n#&gt; (Intercept)                   25.259      0.473   53.40  &lt; 2e-16\n#&gt; condizioneCtrl_vs_PsicoMean    6.758      1.003    6.73  1.7e-09\n#&gt; condizioneP1_vs_P2             5.770      1.159    4.98  3.2e-06\n#&gt; \n#&gt; Residual standard error: 4.49 on 87 degrees of freedom\n#&gt; Multiple R-squared:  0.446,  Adjusted R-squared:  0.434 \n#&gt; F-statistic: 35.1 on 2 and 87 DF,  p-value: 6.75e-12\n\nInterpretazione dei coefficienti:\n\n\nIntercetta: non rappresenta più una singola media, ma una combinazione lineare dei gruppi.\n\nCtrl_vs_PsicoMean: confronta la media di controllo con la media combinata delle due psicoterapie.\n\nP1_vs_P2: differenza tra le due psicoterapie.\n\nVerifica manuale:\n\n# Controllo - media delle psicoterapie\nout[1] - (out[2] + out[3]) / 2\n#&gt; controllo \n#&gt;     6.758\n\n\n# Psicoterapia1 - Psicoterapia2\nout[2] - out[3]\n#&gt; psicoterapia1 \n#&gt;          5.77",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#estensione-bayesiana-con-brms-e-emmeans",
    "href": "chapters/linear_models/09_anova_1via.html#estensione-bayesiana-con-brms-e-emmeans",
    "title": "69  ANOVA ad una via",
    "section": "\n69.6 Estensione bayesiana con brms e emmeans\n",
    "text": "69.6 Estensione bayesiana con brms e emmeans\n\nUsiamo ora il modello bayesiano:\n\nmod &lt;- brm(punteggio ~ condizione, data = df, backend = \"cmdstanr\")\n\n\nsummary(mod)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: punteggio ~ condizione \n#&gt;    Data: df (Number of observations: 90) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;                             Estimate Est.Error l-95% CI u-95% CI Rhat\n#&gt; Intercept                      25.26      0.48    24.33    26.15 1.00\n#&gt; condizioneCtrl_vs_PsicoMean     6.78      1.04     4.73     8.85 1.00\n#&gt; condizioneP1_vs_P2              5.76      1.16     3.49     8.08 1.00\n#&gt;                             Bulk_ESS Tail_ESS\n#&gt; Intercept                       4321     2937\n#&gt; condizioneCtrl_vs_PsicoMean     4260     2964\n#&gt; condizioneP1_vs_P2              4598     2785\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     4.54      0.34     3.93     5.26 1.00     4287     3279\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nLe medie marginali e i confronti possono essere ottenuti con il pacchetto emmeans:\n\nem &lt;- emmeans(mod, specs = \"condizione\")\nem\n#&gt;  condizione    emmean lower.HPD upper.HPD\n#&gt;  controllo       29.8      28.1      31.4\n#&gt;  psicoterapia1   25.9      24.3      27.5\n#&gt;  psicoterapia2   20.1      18.4      21.7\n#&gt; \n#&gt; Point estimate displayed: median \n#&gt; HPD interval probability: 0.95\n\nConfronti tra gruppi:\n\npairs(em)  # confronti a coppie\n#&gt;  contrast                      estimate lower.HPD upper.HPD\n#&gt;  controllo - psicoterapia1         3.90      1.70      6.21\n#&gt;  controllo - psicoterapia2         9.65      7.31     12.03\n#&gt;  psicoterapia1 - psicoterapia2     5.75      3.57      8.14\n#&gt; \n#&gt; Point estimate displayed: median \n#&gt; HPD interval probability: 0.95\n\nContrasti personalizzati:\n\nmy_list &lt;- list(\n  \"Ctrl_vs_PsicoMean\" = c(\n    \"controllo\" = 1, \"psicoterapia1\" = -0.5, \"psicoterapia2\" = -0.5\n  ),\n  \"P1_vs_P2\" = c(\n    \"controllo\" = 0, \"psicoterapia1\" = 1, \"psicoterapia2\" = -1\n  )\n)\n\n\ncontrast(em, method = my_list)\n#&gt;  contrast          estimate lower.HPD upper.HPD\n#&gt;  Ctrl_vs_PsicoMean     6.77      4.77      8.88\n#&gt;  P1_vs_P2              5.75      3.57      8.14\n#&gt; \n#&gt; Point estimate displayed: median \n#&gt; HPD interval probability: 0.95\n\n\n# Visualizzazione\nplot(em)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#riflessioni-conclusive",
    "href": "chapters/linear_models/09_anova_1via.html#riflessioni-conclusive",
    "title": "69  ANOVA ad una via",
    "section": "\n69.7 Riflessioni conclusive",
    "text": "69.7 Riflessioni conclusive\nL’ANOVA a una via è un esempio fondamentale di come un modello lineare possa rappresentare la variabilità tra gruppi. Tuttavia, il suo valore non sta nel test globale, ma nella possibilità di analizzare differenze mirate tra medie.\nAttraverso contrasti personalizzati, possiamo porre domande teoriche precise e ottenere risposte in termini di effetti stimati con incertezza. Questo approccio si integra naturalmente con la prospettiva bayesiana, che ci permette di esprimere la probabilità che una certa differenza superi una soglia di interesse pratico.\nIl pacchetto emmeans (insieme a brms) consente di navigare questa complessità in modo modulare e trasparente, producendo stime interpretabili e inference compatibili con i nostri modelli teorici. L’obiettivo non è semplicemente sapere se c’è una differenza, ma capire quanto, con quale incertezza e tra chi.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/09_anova_1via.html#informazioni-sullambiente-di-sviluppo",
    "title": "69  ANOVA ad una via",
    "section": "Informazioni sull’ambiente di sviluppo",
    "text": "Informazioni sull’ambiente di sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] emmeans_1.11.2        bayestestR_0.16.1     cmdstanr_0.9.0       \n#&gt;  [4] pillar_1.11.0         tinytable_0.11.0      patchwork_1.3.1      \n#&gt;  [7] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.13.0     \n#&gt; [10] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.0     \n#&gt; [13] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [16] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [19] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [22] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [25] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3        inline_0.3.21        sandwich_3.1-1      \n#&gt;  [4] rlang_1.1.6          magrittr_2.0.3       multcomp_1.4-28     \n#&gt;  [7] snakecase_0.11.1     compiler_4.5.1       vctrs_0.6.5         \n#&gt; [10] reshape2_1.4.4       stringr_1.5.1        pkgconfig_2.0.3     \n#&gt; [13] arrayhelpers_1.1-0   fastmap_1.2.0        backports_1.5.0     \n#&gt; [16] labeling_0.4.3       utf8_1.2.6           rmarkdown_2.29      \n#&gt; [19] ps_1.9.1             purrr_1.1.0          xfun_0.52           \n#&gt; [22] cachem_1.1.0         jsonlite_2.0.0       broom_1.0.9         \n#&gt; [25] parallel_4.5.1       R6_2.6.1             stringi_1.8.7       \n#&gt; [28] RColorBrewer_1.1-3   lubridate_1.9.4      estimability_1.5.1  \n#&gt; [31] knitr_1.50           zoo_1.8-14           pacman_0.5.1        \n#&gt; [34] Matrix_1.7-3         splines_4.5.1        timechange_0.3.0    \n#&gt; [37] tidyselect_1.2.1     abind_1.4-8          yaml_2.3.10         \n#&gt; [40] codetools_0.2-20     curl_6.4.0           processx_3.8.6      \n#&gt; [43] pkgbuild_1.4.8       plyr_1.8.9           lattice_0.22-7      \n#&gt; [46] withr_3.0.2          bridgesampling_1.1-2 coda_0.19-4.1       \n#&gt; [49] evaluate_1.0.4       survival_3.8-3       RcppParallel_5.1.10 \n#&gt; [52] tensorA_0.36.2.1     checkmate_2.3.2      stats4_4.5.1        \n#&gt; [55] insight_1.3.1        distributional_0.5.0 generics_0.1.4      \n#&gt; [58] rprojroot_2.1.0      rstantools_2.4.0     scales_1.4.0        \n#&gt; [61] xtable_1.8-4         glue_1.8.0           tools_4.5.1         \n#&gt; [64] data.table_1.17.8    mvtnorm_1.3-3        grid_4.5.1          \n#&gt; [67] QuickJSR_1.8.0       colorspace_2.1-1     nlme_3.1-168        \n#&gt; [70] cli_3.6.5            svUnit_1.0.6         Brobdingnag_1.2-9   \n#&gt; [73] V8_6.0.5             gtable_0.3.6         digest_0.6.37       \n#&gt; [76] TH.data_1.1-3        htmlwidgets_1.6.4    farver_2.1.2        \n#&gt; [79] memoise_2.0.1        htmltools_0.5.8.1    lifecycle_1.0.4     \n#&gt; [82] MASS_7.3-65",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#bibliografia",
    "href": "chapters/linear_models/09_anova_1via.html#bibliografia",
    "title": "69  ANOVA ad una via",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_2vie.html",
    "href": "chapters/linear_models/10_anova_2vie.html",
    "title": "70  ANOVA ad due vie",
    "section": "",
    "text": "Introduzione",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_2vie.html#introduzione",
    "href": "chapters/linear_models/10_anova_2vie.html#introduzione",
    "title": "70  ANOVA ad due vie",
    "section": "",
    "text": "L’ANOVA a due vie estende il modello dell’ANOVA a una via alla situazione in cui la variabile dipendente è influenzata da due fattori distinti, ciascuno con due o più livelli. Questa estensione consente di analizzare non solo gli effetti principali di ciascun fattore, ma anche l’interazione tra i due.\n\n\n70.0.1 Medie di popolazione in una classificazione a due vie\nSupponiamo di conoscere le medie di popolazione per ciascuna combinazione dei livelli dei due fattori. La struttura può essere rappresentata in una tabella come la seguente:\n\n\n\n\n\n\n\n\n\n\n\n\\(C_1\\)\n\\(C_2\\)\n\\(\\dots\\)\n\\(C_c\\)\nMedia riga\n\n\n\n\\(R_1\\)\n\\(\\mu_{11}\\)\n\\(\\mu_{12}\\)\n\\(\\dots\\)\n\\(\\mu_{1c}\\)\n\\(\\mu_{1\\cdot}\\)\n\n\n\\(R_2\\)\n\\(\\mu_{21}\\)\n\\(\\mu_{22}\\)\n\\(\\dots\\)\n\\(\\mu_{2c}\\)\n\\(\\mu_{2\\cdot}\\)\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\ddots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\\(R_r\\)\n\\(\\mu_{r1}\\)\n\\(\\mu_{r2}\\)\n\\(\\dots\\)\n\\(\\mu_{rc}\\)\n\\(\\mu_{r\\cdot}\\)\n\n\nMedia colonna\n\\(\\mu_{\\cdot 1}\\)\n\\(\\mu_{\\cdot 2}\\)\n\\(\\dots\\)\n\\(\\mu_{\\cdot c}\\)\n\\(\\mu_{\\cdot\\cdot}\\)\n\n\n\ndove:\n\n\n\\(µ_{jk}\\) è la media della cella per il livello \\(j\\) del fattore R e \\(k\\) del fattore C.\n\n\\(µ_{j:}\\) è la media marginale per la riga \\(j\\).\n\n\\(µ_{:k}\\) è la media marginale per la colonna \\(k\\).\n\n\\(µ_{::}\\) è la media complessiva.\n\n70.0.2 Effetti principali e interazione\nSe non c’è interazione tra i due fattori, la differenza tra livelli di un fattore è costante a prescindere dal livello dell’altro fattore. In altre parole, le differenze tra medie di cella si riflettono esattamente nelle differenze tra le medie marginali.\nAd esempio, se il fattore R non interagisce con il fattore C, allora:\n\\[\nµ_{j1} - µ_{j'1} = µ_{j2} - µ_{j'2} = ... = µ_{j:} - µ_{j':}\n\\]\nQuando i profili delle medie sono paralleli, l’assenza di interazione è facilmente visibile. L’interazione si manifesta quando le differenze tra livelli di un fattore variano al variare dell’altro fattore.\nL’interazione è simmetrica: se R interagisce con C, allora C interagisce con R. Se invece non vi è interazione, gli effetti principali dei fattori corrispondono alle differenze tra le rispettive medie marginali.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_2vie.html#simulazione",
    "href": "chapters/linear_models/10_anova_2vie.html#simulazione",
    "title": "70  ANOVA ad due vie",
    "section": "\n70.1 Simulazione",
    "text": "70.1 Simulazione\nSimuliamo ora un dataset che rispecchi una struttura a due vie. Consideriamo:\n\nfattore 1: condizione (controllo, psicoterapia1, psicoterapia2)\nfattore 2: gravita (molto_gravi, poco_gravi)\n\nImpostiamo le medie di cella in modo che riflettano sia effetti principali sia un’interazione.\n\nset.seed(123)\nn &lt;- 30\ncondizione &lt;- c(\"controllo\", \"psicoterapia1\", \"psicoterapia2\")\ngravita &lt;- c(\"molto_gravi\", \"poco_gravi\")\nsd_value &lt;- 5\n\nmean_table &lt;- matrix(\n  c(30, 25, 20,\n    25, 20, 15),\n  nrow = 2, byrow = TRUE\n)\n\ndf &lt;- data.frame()\n\nfor (i in seq_along(gravita)) {\n  for (j in seq_along(condizione)) {\n    media &lt;- mean_table[i, j]\n    dati &lt;- rnorm(n, mean = media, sd = sd_value)\n    df &lt;- rbind(df, data.frame(\n      gravita = gravita[i],\n      condizione = condizione[j],\n      punteggio = dati\n    ))\n  }\n}\n\nVisualizziamo i dati:\n\nggplot(df, aes(x = condizione, y = punteggio, fill = gravita)) +\n  geom_boxplot(position = position_dodge()) +\n  labs(title = \"Distribuzione dei punteggi per gravita e condizione\")",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_2vie.html#modellazione-bayesiana",
    "href": "chapters/linear_models/10_anova_2vie.html#modellazione-bayesiana",
    "title": "70  ANOVA ad due vie",
    "section": "\n70.2 Modellazione bayesiana",
    "text": "70.2 Modellazione bayesiana\nAdattiamo ai dati un modello che includa interazione:\n\nmod &lt;- brm(punteggio ~ gravita * condizione, data = df, backend = \"cmdstanr\")\n\nEsploriamo gli effetti condizionati:\n\nconditional_effects(mod, \"condizione:gravita\")",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_2vie.html#confronto-tra-modelli",
    "href": "chapters/linear_models/10_anova_2vie.html#confronto-tra-modelli",
    "title": "70  ANOVA ad due vie",
    "section": "\n70.3 Confronto tra Modelli",
    "text": "70.3 Confronto tra Modelli\nConfrontiamo due modelli:\n\n\nmod: con interazione\n\nmod1: solo con effetti principali\n\n\nmod1 &lt;- brm(punteggio ~ gravita + condizione, data = df, backend = \"cmdstanr\")\n\n\n70.3.1 LOO (Leave-One-Out Cross Validation)\n\nloo_mod  &lt;- loo(mod)\nloo_mod1 &lt;- loo(mod1)\nloo_compare(loo_mod, loo_mod1)\n#&gt;      elpd_diff se_diff\n#&gt; mod1  0.0       0.0   \n#&gt; mod  -1.0       1.5\n\nInterpretazione:\n\nse elpd_diff è piccolo rispetto a se_diff, la differenza non è sostanziale;\nil modello più semplice è preferibile se non vi è evidenza chiara a favore dell’interazione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_2vie.html#riflessioni-conclusive",
    "href": "chapters/linear_models/10_anova_2vie.html#riflessioni-conclusive",
    "title": "70  ANOVA ad due vie",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nL’ANOVA a due vie permette di esaminare sia gli effetti separati di due fattori sia la loro interazione. La modellazione bayesiana, combinata con il confronto tramite LOO, offre un approccio potente per valutare quale struttura descrive meglio i dati. Se l’interazione non migliora la predizione in modo credibile, è preferibile adottare il modello più parsimonioso.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_2vie.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/10_anova_2vie.html#informazioni-sullambiente-di-sviluppo",
    "title": "70  ANOVA ad due vie",
    "section": "Informazioni sull’ambiente di sviluppo",
    "text": "Informazioni sull’ambiente di sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] bridgesampling_1.1-2  emmeans_1.11.2        bayestestR_0.16.1    \n#&gt;  [4] cmdstanr_0.9.0        pillar_1.11.0         tinytable_0.11.0     \n#&gt;  [7] patchwork_1.3.1       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt; [10] bayesplot_1.13.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [13] priorsense_1.1.0      posterior_1.6.1       loo_2.8.0            \n#&gt; [16] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [19] Rcpp_1.1.0            conflicted_1.2.0      janitor_2.2.1        \n#&gt; [22] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [25] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [28] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.6         tidyselect_1.2.1     farver_2.1.2        \n#&gt;  [4] fastmap_1.2.0        TH.data_1.1-3        tensorA_0.36.2.1    \n#&gt;  [7] pacman_0.5.1         digest_0.6.37        estimability_1.5.1  \n#&gt; [10] timechange_0.3.0     lifecycle_1.0.4      processx_3.8.6      \n#&gt; [13] survival_3.8-3       magrittr_2.0.3       compiler_4.5.1      \n#&gt; [16] rlang_1.1.6          tools_4.5.1          yaml_2.3.10         \n#&gt; [19] data.table_1.17.8    knitr_1.50           labeling_0.4.3      \n#&gt; [22] htmlwidgets_1.6.4    pkgbuild_1.4.8       curl_6.4.0          \n#&gt; [25] RColorBrewer_1.1-3   abind_1.4-8          multcomp_1.4-28     \n#&gt; [28] withr_3.0.2          purrr_1.1.0          grid_4.5.1          \n#&gt; [31] stats4_4.5.1         xtable_1.8-4         colorspace_2.1-1    \n#&gt; [34] inline_0.3.21        scales_1.4.0         MASS_7.3-65         \n#&gt; [37] insight_1.3.1        cli_3.6.5            mvtnorm_1.3-3       \n#&gt; [40] rmarkdown_2.29       generics_0.1.4       RcppParallel_5.1.10 \n#&gt; [43] cachem_1.1.0         stringr_1.5.1        splines_4.5.1       \n#&gt; [46] parallel_4.5.1       vctrs_0.6.5          V8_6.0.5            \n#&gt; [49] Matrix_1.7-3         sandwich_3.1-1       jsonlite_2.0.0      \n#&gt; [52] arrayhelpers_1.1-0   glue_1.8.0           ps_1.9.1            \n#&gt; [55] codetools_0.2-20     distributional_0.5.0 lubridate_1.9.4     \n#&gt; [58] stringi_1.8.7        gtable_0.3.6         QuickJSR_1.8.0      \n#&gt; [61] htmltools_0.5.8.1    Brobdingnag_1.2-9    R6_2.6.1            \n#&gt; [64] rprojroot_2.1.0      evaluate_1.0.4       lattice_0.22-7      \n#&gt; [67] backports_1.5.0      memoise_2.0.1        broom_1.0.9         \n#&gt; [70] snakecase_0.11.1     rstantools_2.4.0     coda_0.19-4.1       \n#&gt; [73] gridExtra_2.3        nlme_3.1-168         checkmate_2.3.2     \n#&gt; [76] xfun_0.52            zoo_1.8-14           pkgconfig_2.0.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_2vie.html#bibliografia",
    "href": "chapters/linear_models/10_anova_2vie.html#bibliografia",
    "title": "70  ANOVA ad due vie",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_one_proportion.html",
    "href": "chapters/linear_models/11_one_proportion.html",
    "title": "71  Inferenza sulle proporzioni",
    "section": "",
    "text": "71.1 Introduzione\nSpesso ci troviamo ad affrontare la necessità di confrontare due gruppi di dati. Mentre nei capitoli precedenti abbiamo considerato il contronto tra le medie di due gruppi indipendenti, nel caso presente ci concentreremo sul confronto tra le proporzioni di due gruppi indipendenti. Per esempio, potrebbe interessarci sapere se la proporzione di un gruppo è maggiore o diversa rispetto a quella di un altro gruppo. Come in precedenza, per effettuare tale confronto, è fondamentale utilizzare un modello statistico, poiché le vere differenze tra i gruppi sono spesso accompagnate da rumore di misurazione o fluttuazioni casuali del fenomeno in esame. Questo rende difficile trarre conclusioni basandosi unicamente sulle differenze calcolate dai dati osservati.\nAnche nel caso delle proporzioni, il metodo tradizionale per confrontare statisticamente due o più gruppi consiste nell’utilizzare un test di ipotesi. Questo approccio prevede la definizione di un’ipotesi nulla, che tipicamente afferma l’assenza di differenze tra i gruppi, e l’uso di una statistica test per valutare se i dati osservati sono compatibili con tale ipotesi. Se la statistica test supera una soglia prestabilita, l’ipotesi nulla viene rifiutata, suggerendo che esiste una differenza significativa tra i gruppi.\nTuttavia, i test di ipotesi presentano diverse criticità, come vedremo in seguito. Un approccio alternativo e più informativo è quello basato sulla stima anziché sul test dell’ipotesi nulla, fondato sulla probabilità bayesiana piuttosto che su quella frequentista. In questo caso, l’obiettivo non è semplicemente verificare se esiste una differenza tra i gruppi, ma stimare quanto siano effettivamente diversi. Questo metodo è intrinsecamente più informativo, poiché fornisce una stima diretta della differenza tra i gruppi, accompagnata da una misura dell’incertezza associata. Tale incertezza riflette sia la nostra limitata conoscenza dei parametri del modello (incertezza epistemica) sia la variabilità intrinseca del sistema (incertezza aleatoria).\nIn sintesi, mentre i test di ipotesi si concentrano sul rigetto o meno di un’ipotesi nulla, l’approccio basato sulla stima offre una visione più completa e utile, permettendo di quantificare direttamente la differenza tra i gruppi e di valutare l’incertezza associata a tale stima. Questo rende l’analisi più adatta a supportare decisioni informate e basate sui dati.\nIn questo capitolo approfondiremo l’analisi bayesiana per il confronto tra due proporzioni, utilizzando il pacchetto brms in R. L’approccio bayesiano permette di ottenere una descrizione completa della distribuzione a posteriori del parametro di interesse, fornendo informazioni dettagliate sulla sua incertezza e variabilità, oltre a misure intuitive come intervalli di credibilità e probabilità dirette (es. la probabilità che la proporzione del gruppo A sia maggiore di quella del gruppo B).\nPer illustrare i vantaggi dell’approccio bayesiano, confronteremo i risultati con quelli ottenuti tramite l’analisi frequentista tradizionale. Per facilitare l’apprendimento, inizieremo con un caso più semplice: l’inferenza su una singola proporzione. Questo ci permetterà di familiarizzarci con i concetti fondamentali prima di estenderli al confronto tra due gruppi.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Inferenza sulle proporzioni</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_one_proportion.html#inferenza-su-una-proporzione",
    "href": "chapters/linear_models/11_one_proportion.html#inferenza-su-una-proporzione",
    "title": "71  Inferenza sulle proporzioni",
    "section": "\n71.2 Inferenza su Una Proporzione",
    "text": "71.2 Inferenza su Una Proporzione\n\n71.2.1 Contesto e Dati\nCome esempio per l’inferenza su una proporzione, utilizzeremo i dati dello studio di Brückner & Bearman (2005), discussi anche da Wagenmakers et al. (2010). Nell’articolo “After the promise: the STD consequences of adolescent virginity pledges”, Brückner & Bearman (2005) analizzano una serie di interviste condotte nell’ambito del National Longitudinal Study of Adolescent Health (Add Health). Lo studio si concentra sul comportamento sessuale di adolescenti, di età compresa tra 18 e 24 anni, che hanno fatto un “virginity pledge”, ovvero una promessa pubblica o scritta di rimanere vergini fino al matrimonio. Studi scientifici indicano che il comportamento sessuale di questi adolescenti non sia statisticamente diverso da quello di chi non ha fatto tale promessa, con l’unica eccezione che i “pledgers” hanno una minore probabilità di utilizzare il preservativo durante il primo rapporto sessuale.\nI dati rilevanti per la nostra analisi sono i seguenti:\n\nsu 777 adolescenti che hanno fatto il “virginity pledge”, 424 (54.6%) hanno dichiarato di aver usato il preservativo durante il primo rapporto sessuale;\nsu 9072 adolescenti che non hanno fatto la promessa, 5416 (59.7%) hanno dichiarato di aver usato il preservativo.\n\n71.2.2 Obiettivo dell’Analisi\nNella prima analisi, ci concentreremo sul campione di adolescenti che hanno fatto il “virginity pledge”. Ci chiediamo se sia credibile pensare che questi adolescenti tendano ad avere un rapporto protetto, nel loro primo rapporto sessuale, in una proporzione minore di quella che ci si potrebbe aspettare in caso di casualità (ovvero, una proporzione di 0.5).\n\n71.2.3 Analisi Frequentista\nIniziamo con un test frequentista usando la funzione prop.test() per confrontare la proporzione osservata con il valore di riferimento 0.5.\n\nprop_test_freq_vol &lt;- prop.test(\n  x = 424,\n  n = 777,\n  p = 0.5\n)\n\ntidy(prop_test_freq_vol)\n#&gt; # A tibble: 1 × 8\n#&gt;   estimate statistic p.value parameter conf.low conf.high\n#&gt;      &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1    0.546      6.31  0.0120         1    0.510     0.581\n#&gt;   method                                               alternative\n#&gt;   &lt;chr&gt;                                                &lt;chr&gt;      \n#&gt; 1 1-sample proportions test with continuity correction two.sided\n\nL’intervallo di confidenza frequentista non include il valore di riferimento 0.5, quindi, in base a questa analisi, possiamo concludere che la proporzione osservata (0.546) sia maggiore del valore atteso in caso di casualità (0.5).\n\n71.2.4 Approccio Bayesiano con brms\n\nSe utilizziamo dei prior non informativi, ci aspettiamo di giungere alla stessa conclusione anche con un approccio bayesiano. Tuttavia, l’approccio bayesiano ci permette di ottenere una distribuzione completa della probabilità a posteriori del parametro di interesse, offrendo una visione più ricca e flessibile rispetto all’approccio frequentista.\n\n71.2.4.1 Preparazione dei Dati\nIniziamo creando un data frame che sarà utilizzato con la funzione brm().\n\npledge_binomial_df &lt;- tibble(\n  n_yes = 424,\n  n_total = 777\n)\n\n# tiny data\npledge_binomial_df\n#&gt; # A tibble: 1 × 2\n#&gt;   n_yes n_total\n#&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1   424     777\n\n\n71.2.4.2 Definizione delle Opzioni del Campionatore\nImpostiamo alcune opzioni globali per il campionatore Stan.\n\n# Set some global Stan options\nCHAINS &lt;- 4\nITER &lt;- 2000\nWARMUP &lt;- 1000\nBAYES_SEED &lt;- 1234\n\n\n71.2.4.3 Modello Bayesiano\nUtilizziamo un modello di regressione con una funzione link binomiale. Questo significa che stimeremo la proporzione \\(p\\) con un modello di regressione beta-binomiale bayesiano utilizzando brms. Useremo un prior non informativo \\(\\mathcal{Beta}(1, 1)\\). Questo è un modello solo con intercetta, senza altre covariate, poiché siamo interessati solo alla proporzione sottostante, senza condizionarla su altre variabili.\nIl modello può essere rappresentato come segue:\n\\[\n\\begin{aligned}\ny_{\\text{condom\\_use}} &\\sim \\mathcal{Binomial}(n, \\pi) \\\\\n\\pi &= \\beta_0 \\\\\n\\beta_0 &\\sim \\mathcal{Beta}(1, 1)\n\\end{aligned}\n\\]\nEseguiamo l’analisi bayesiana.\n\nmodel_pledge_binomial &lt;- brm(\n  n_yes | trials(n_total) ~ 1,\n  data = pledge_binomial_df,\n  family = binomial(link = \"identity\"),\n  prior = c(prior(beta(1, 1), class = \"Intercept\", lb = 0, ub = 1)),\n  chains = CHAINS, warmup = WARMUP, iter = ITER, seed = BAYES_SEED,\n  refresh = 0,\n  backend = \"cmdstanr\"\n)\n#&gt; Running MCMC with 4 sequential chains...\n#&gt; \n#&gt; Chain 1 finished in 0.0 seconds.\n#&gt; Chain 2 finished in 0.0 seconds.\n#&gt; Chain 3 finished in 0.0 seconds.\n#&gt; Chain 4 finished in 0.0 seconds.\n#&gt; \n#&gt; All 4 chains finished successfully.\n#&gt; Mean chain execution time: 0.0 seconds.\n#&gt; Total execution time: 0.6 seconds.\n\n\n71.2.4.4 Risultati del Modello\nPoiché questo è un modello di regressione, si comporta come qualsiasi altro modello brms. Il coefficiente per l’intercetta rappresenta la proporzione stimata di adolescenti tra i 18 e i 24 anni che hanno usato il preservativo durante il primo rapporto sessuale nel campione.\n\nsummary(model_pledge_binomial)\n#&gt;  Family: binomial \n#&gt;   Links: mu = identity \n#&gt; Formula: n_yes | trials(n_total) ~ 1 \n#&gt;    Data: pledge_binomial_df (Number of observations: 1) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept     0.55      0.02     0.51     0.58 1.00     1457     1756\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nSi noti come l’intervallo di credibilità al 95% riproduce l’intervallo frequentista calcolato in precedenza.\n\n71.2.5 Confronto tra i Due Approcci\nConfrontiamo ora i risultati ottenuti dai due approcci. L’analisi frequentista ha mostrato che la proporzione osservata (0.546) è significativamente maggiore del valore di riferimento 0.5. L’approccio bayesiano conferma questa conclusione, fornendo una distribuzione completa della probabilità a posteriori per la proporzione π. Uno dei vantaggi dell’approccio bayesiano è la possibilità di incorporare informazioni a priori, se disponibili, migliorando così la robustezza delle inferenze. Inoltre, l’intervallo di credibilità bayesiano fornisce una descrizione più completa della distribuzione dei parametri, consentendo una migliore interpretazione dei risultati.\n\n71.2.6 Modello Beta-Binomiale e Soluzione Analitica\nIn questo contesto, il problema può essere modellato utilizzando una distribuzione beta-binomiale, per la quale esiste una soluzione analitica per la distribuzione a posteriori. Il modello beta-binomiale è particolarmente adatto quando si lavora con dati binomiali (ad esempio, successi e fallimenti) e si desidera incorporare una distribuzione a priori coniugata per la proporzione \\(p\\).\n\n71.2.6.1 Contestualizzazione del Modello\nPer il gruppo “pledgers”, abbiamo \\(y_1\\) successi su \\(n_1\\) prove. Se assumiamo una distribuzione a priori Beta(\\(\\alpha\\), \\(\\beta\\)), la distribuzione a posteriori per la proporzione \\(p_1\\) sarà anch’essa una distribuzione Beta, data da:\n\\[\np_1 \\mid y_1, n_1 \\sim \\mathcal{Beta}(\\alpha + y_1, \\beta + n_1 - y_1).\n\\]\nNel nostro caso specifico, scegliamo una prior non informativa \\(\\mathcal{Beta}(1, 1)\\), che equivale a una distribuzione uniforme sull’intervallo [0, 1]. Questa scelta riflette l’assenza di informazioni pregresse sulla proporzione \\(p_1\\). Pertanto, la distribuzione a posteriori per il gruppo “pledgers” diventa:\n\\[\np_1 \\mid y_1, n_1 \\sim \\mathcal{Beta}(1 + 424, 1 + 777 - 424) = \\mathcal{Beta}(425, 354).\n\\]\n\n71.2.6.2 Calcolo dell’Intervallo di Credibilità\nUtilizziamo R per calcolare l’intervallo di credibilità al 95% basato sulla distribuzione a posteriori derivata analiticamente.\n\n# Parametri della distribuzione Beta\na_post &lt;- 425  # Parametro alpha\nb_post &lt;- 354  # Parametro beta\n\n# Calcolo dell'intervallo centrale al 95%\ncredibility_interval &lt;- qbeta(c(0.025, 0.975), shape1 = a_post, shape2 = b_post)\nprint(credibility_interval)\n#&gt; [1] 0.5105 0.5804\n\nIl risultato ottenuto dall’analisi bayesiana analitica replica quello ottenuto tramite il modello brm() implementato in precedenza. Questo confronto tra approcci dimostra la coerenza tra le tecniche frequentista, bayesiana numerica e bayesiana analitica.\n\n71.2.7 Discussione e Confronto tra Approcci\nL’utilizzo della distribuzione beta-binomiale e della soluzione analitica offre diversi vantaggi:\n\n\nSemplicità: La soluzione analitica è spesso più semplice da implementare rispetto ai metodi numerici, come quelli utilizzati in brms.\n\nVelocità: I calcoli sono generalmente più veloci poiché non richiedono iterazioni o campionamenti.\n\nInterpretazione: L’uso di distribuzioni coniugate facilita l’interpretazione dei risultati, fornendo direttamente la distribuzione a posteriori senza bisogno di complessi algoritmi di inferenza.\n\nTuttavia, l’approccio bayesiano numerico tramite brms presenta anche vantaggi significativi:\n\n\nFlessibilità: Può gestire modelli più complessi e includere covariate multiple.\n\nPriori informativi: Permette di incorporare facilmente informazioni a priori, se disponibili.\n\nEstensioni: Facilita l’estensione del modello a casi più complessi, come il confronto tra proporzioni di due gruppi.\n\n\n71.2.7.1 Analisi della Distribuzione a Posteriori\nEssendo un’analisi bayesiana, possiamo lavorare con l’intera distribuzione a posteriori e calcolare direttamente l’estimando, come la differenza tra la proporzione campionaria e la proporzione di riferimento (0.5).\n\npledge_draws &lt;- model_pledge_binomial |&gt; \n  spread_draws(b_Intercept) |&gt; \n  mutate(diff = b_Intercept - 0.5)\n\nVisualizziamo la distribuzione a posteriori della proporzione.\n\np1 &lt;- ggplot(pledge_draws, aes(x = b_Intercept, y = \"Age 18–24\")) + \n  stat_halfeye(fill = \"gray\") +\n  geom_vline(xintercept = 0.5) +\n  scale_x_continuous(labels = label_percent()) +\n  coord_cartesian(ylim = c(1.5, 1.5)) +\n  labs(x = \"Proportion used a condom at first sex\", y = NULL)\np1\n\n\n\n\n\n\n\nIl valore di riferimento (0.5) non è incluso nella distribuzione a posteriori, il che significa che la differenza tra la proporzione campionaria e la proporzione di riferimento non include lo zero, con un livello di credibilità del 95%. Possiamo quindi concludere, con un livello soggettivo di credibilità del 95%, che l’uso del preservativo durante il primo rapporto sessuale sia maggiore del caso, per gli adolescenti che hanno fatto il “virginity pledge”.\n\n71.2.8 La Regione di Equivalenza Pratica (ROPE)\nL’analisi precedente confronta la proporzione osservata con un singolo valore di riferimento (0.5). Un approccio alternativo è considerare un intervallo di valori attorno a 0.5 che possano essere considerati “praticamente equivalenti” al valore di riferimento. Questo intervallo è chiamato Regione di Equivalenza Pratica (ROPE).\nSecondo Kruschke & Liddell (2018), la ROPE può essere definita come un intervallo attorno al valore nullo (baseline) che corrisponde a un decimo della deviazione standard della distribuzione a posteriori del parametro di interesse. Nel nostro caso, il parametro di interesse è la proporzione \\(p\\), e il valore nullo è 0.5. Per calcolare la ROPE, estraiamo i campioni a posteriori dal modello.\n\nposterior_samples &lt;- as_draws_df(model_pledge_binomial)\n\nCalcoliamo la deviazione standard a posteriori di \\(p\\).\n\nposterior_std_dev &lt;- sd(posterior_samples$b_Intercept)\nposterior_std_dev\n#&gt; [1] 0.01809\n\nDefiniamo la ROPE come un intervallo attorno al valore di riferimento 0.5.\n\nbaseline &lt;- 0.5  # Valore nullo (baseline)\nrope_low &lt;- baseline - 0.1 * posterior_std_dev\nrope_high &lt;- baseline + 0.1 * posterior_std_dev\n\nCalcoliamo ora la probabilità che la proporzione \\(p\\) si trovi all’interno della ROPE.\n\nrope_probability &lt;-\n  mean(\n    posterior_samples$b_Intercept &gt;= rope_low &\n      posterior_samples$b_Intercept &lt;= rope_high\n  )\nrope_probability\n#&gt; [1] 0.00325\n\nVisualizziamo la distribuzione a posteriori di \\(p\\) insieme alla ROPE.\n\nggplot(posterior_samples, aes(x = b_Intercept)) +\n  geom_density(fill = \"gray\", alpha = 0.5) +\n  annotate(\n    geom = \"rect\", \n    xmin = rope_low, \n    xmax = rope_high, \n    ymin = 0, ymax = Inf, \n    fill = \"lightgray\", alpha = 0.2\n  ) +\n  geom_vline(xintercept = baseline, color = \"lightgray\") +\n  scale_x_continuous(labels = scales::percent) +\n  labs(x = \"Proportion used a condom at first sex\", y = \"Density\")\n\n\n\n\n\n\n\nIn conclusione, dato che solo lo 0.325% (meno dell’uno per cento) della distribuzione a posteriori di \\(p\\) si trova nella ROPE, possiamo concludere che ci sono evidenze credibili che la distribuzione a posteriori del parametro \\(p\\) (la proporzione di adolescenti, di età compresa tra 18 e 24 anni, che hanno fatto il “virginity pledge” e hanno usato il preservativo durante il primo rapporto sessuale) sia diversa dal valore di riferimento 0.5. Nel caso specifico, questa proporzione è più alta, indicando che la tendenza ad avere un rapporto protetto è maggiore rispetto al caso di casualità, per questa popolazione.\n\n71.2.8.1 Discussione sulla ROPE\nL’utilizzo della ROPE offre una prospettiva aggiuntiva nell’interpretazione delle inferenze bayesiane. Invece di semplicemente determinare se un parametro è statisticamente significativo rispetto a un valore di riferimento, la ROPE permette di valutare se le differenze osservate siano praticamente rilevanti in termini di impatto reale.\n\n\nSoglia di Rilevanza: L’impostazione di una ROPE consente di stabilire una soglia di rilevanza pratica. Se la maggior parte della distribuzione a posteriori cade al di fuori della ROPE, possiamo concludere che la differenza è non solo statistica ma anche pratica.\n\nInterpretazione Clinica: Nelle applicazioni pratiche, come in ambito medico o sociale, la ROPE aiuta a distinguere tra risultati statisticamente significativi ma clinicamente insignificanti e quelli che hanno un impatto rilevante.\n\nNel contesto dello studio sui “pledgers”, l’uso della ROPE fornisce una valutazione più completa della tendenza degli adolescenti a utilizzare il preservativo durante il primo rapporto sessuale, dimostrando che questa tendenza è non solo statisticamente diversa dal caso di casualità, ma anche significativa dal punto di vista pratico.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Inferenza sulle proporzioni</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_one_proportion.html#inferenza-sulla-differenza-tra-due-proporzioni",
    "href": "chapters/linear_models/11_one_proportion.html#inferenza-sulla-differenza-tra-due-proporzioni",
    "title": "71  Inferenza sulle proporzioni",
    "section": "\n71.3 Inferenza sulla Differenza tra Due Proporzioni",
    "text": "71.3 Inferenza sulla Differenza tra Due Proporzioni\nEstendiamo ora l’analisi precedente per confrontare le proporzioni di due gruppi, un compito per il quale non esiste una soluzione analitica semplice. Nello studio in esame, ci poniamo la domanda: Fino a che punto l’analisi statistica supporta l’ipotesi che i “pledgers” abbiano una minore probabilità rispetto ai “non-pledgers” di usare il preservativo durante il primo rapporto sessuale?\nPer testare questa ipotesi utilizzando brms, estendiamo il modello bayesiano includendo due gruppi: i pledgers (che hanno fatto il voto di astinenza) e i non-pledgers (che non lo hanno fatto). L’obiettivo è stimare la differenza tra le due proporzioni e valutare se questa sia credibilmente diversa da zero.\n\n71.3.1 Creazione del Dataset\nCostruiamo un tibble con i dati relativi ai due gruppi:\n\npledge_data &lt;- tibble(\n  group = c(\"pledgers\", \"nonpledgers\"),\n  n_yes = c(424, 5416),   # Numero di partecipanti che hanno usato il preservativo\n  n_total = c(777, 9072)  # Totale dei partecipanti per ciascun gruppo\n)\nprint(pledge_data)\n#&gt; # A tibble: 2 × 3\n#&gt;   group       n_yes n_total\n#&gt;   &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 pledgers      424     777\n#&gt; 2 nonpledgers  5416    9072\n\n\n71.3.2 Specifica del Modello Bayesiano\nUtilizziamo un modello binomiale con un predittore categorico per distinguere tra i due gruppi. Il modello può essere rappresentato come:\n\\[\np_i \\sim \\text{Binomiale}(n_i, \\theta_i),\n\\]\ndove \\(\\theta_i\\) è la proporzione di utilizzo del preservativo nel gruppo \\(i\\), e modelliamo la probabilità di successo come:\n\\[\n\\theta = \\beta_0 + \\beta_1 \\cdot \\text{group},\n\\]\ndove:\n\n\n\\(\\beta_0\\) rappresenta la proporzione di non-pledgers che usano il preservativo.\n\n\\(\\beta_1\\) rappresenta la differenza tra pledgers e non-pledgers (cioè la variazione della proporzione di utilizzo del preservativo associata all’appartenenza al gruppo dei pledgers).\n\nLe caratteristiche di questo modello verranno approfondite nel capitolo successivo. Per ora, limitiamoci a stimare il modello in brms utilizzando una distribuzione binomiale e un link identità:\n\nmodel_pledge_diff &lt;- brm(\n  n_yes | trials(n_total) ~ group,\n  data = pledge_data,\n  family = binomial(link = \"identity\"),\n  prior = c(\n    prior(beta(1, 1), class = \"Intercept\", lb = 0, ub = 1),  \n    # Prior per la proporzione nei non-pledgers\n    prior(normal(0, 1), class = \"b\")  # Prior per la differenza tra gruppi\n  ),\n  chains = CHAINS, warmup = WARMUP, iter = ITER, seed = BAYES_SEED,\n  refresh = 0,\n  backend = \"cmdstanr\"\n)\n#&gt; Running MCMC with 4 sequential chains...\n#&gt; \n#&gt; Chain 1 finished in 0.1 seconds.\n#&gt; Chain 2 finished in 0.0 seconds.\n#&gt; Chain 3 finished in 0.1 seconds.\n#&gt; Chain 4 finished in 0.0 seconds.\n#&gt; \n#&gt; All 4 chains finished successfully.\n#&gt; Mean chain execution time: 0.1 seconds.\n#&gt; Total execution time: 0.8 seconds.\n\n\n71.3.3 Analisi della Distribuzione A Posteriori\nEsaminiamo il sommario del modello per valutare la stima della differenza tra le proporzioni:\n\nsummary(model_pledge_diff)\n#&gt;  Family: binomial \n#&gt;   Links: mu = identity \n#&gt; Formula: n_yes | trials(n_total) ~ group \n#&gt;    Data: pledge_data (Number of observations: 2) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept         0.60      0.01     0.59     0.61 1.00     4510     3068\n#&gt; grouppledgers    -0.05      0.02    -0.09    -0.01 1.01      889      793\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nPer interpretare meglio i risultati, estraiamo i campioni a posteriori per la differenza tra le due proporzioni:\n\npledge_diff_draws &lt;- model_pledge_diff |&gt; \n  spread_draws(b_Intercept, b_grouppledgers) |&gt; \n  mutate(\n    nonpledgers_prop = b_Intercept,  # Stima della proporzione nei non-pledgers\n    pledgers_prop = b_Intercept + b_grouppledgers,  # Stima della proporzione nei pledgers\n    diff = nonpledgers_prop - pledgers_prop  # Differenza tra le due proporzioni\n  )\n\nVisualizziamo la distribuzione a posteriori della differenza:\n\np3 &lt;- ggplot(pledge_diff_draws, aes(x = diff)) + \n  stat_halfeye(fill = \"gray\") +\n  geom_vline(xintercept = 0, linetype = \"dashed\") +\n  scale_x_continuous(labels = label_percent()) +\n  labs(x = \"Differenza nella proporzione di utilizzo del preservativo\", \n       y = \"Densità a posteriori\") \nprint(p3)\n\n\n\n\n\n\n\nCalcoliamo la probabilità che la differenza tra le proporzioni sia maggiore di zero:\n\ndiff_probability &lt;- mean(pledge_diff_draws$diff &gt; 0)\nprint(diff_probability)\n#&gt; [1] 0.997\n\n\n71.3.4 Interpretazione dei Risultati\nLa probabilità calcolata è 0.997; ciò significa che c’è una probabilità del 99.7% che la proporzione di non-pledgers che usano il preservativo sia maggiore rispetto a quella dei pledgers. Questo supporta con elevata credibilità l’ipotesi che i pledgers abbiano meno probabilità di utilizzare il preservativo durante il primo rapporto sessuale.\nPossiamo quindi concludere che la differenza tra le due proporzioni è credibilmente diversa da zero, con un’elevata probabilità a favore dell’ipotesi che i pledgers abbiano una minore propensione all’uso del preservativo rispetto ai non-pledgers. Questi risultati riproducono quelli riportati dalla letteratura precedente, come discusso da Brückner & Bearman (2005).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Inferenza sulle proporzioni</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_one_proportion.html#riflessioni-conclusive",
    "href": "chapters/linear_models/11_one_proportion.html#riflessioni-conclusive",
    "title": "71  Inferenza sulle proporzioni",
    "section": "\n71.4 Riflessioni Conclusive",
    "text": "71.4 Riflessioni Conclusive\nL’inferenza su una proporzione tramite un approccio bayesiano offre una prospettiva più ricca e flessibile rispetto agli approcci frequentisti tradizionali. Utilizzando il pacchetto brms in R, abbiamo dimostrato come sia possibile modellare la proporzione di adolescenti che hanno usato il preservativo durante il primo rapporto sessuale, ottenendo risultati coerenti con quelli frequentisti. La capacità di ottenere una distribuzione completa della probabilità a posteriori consente non solo stime puntuali ma anche una comprensione approfondita dell’incertezza associata ai parametri stimati, rendendo l’approccio bayesiano uno strumento potente per l’analisi statistica avanzata.\nL’estensione dell’analisi alla differenza tra due proporzioni ha ulteriormente evidenziato i vantaggi dell’approccio bayesiano. Attraverso brms, abbiamo confrontato le proporzioni di utilizzo del preservativo tra i “pledgers” e i “non-pledgers”, ottenendo risultati coerenti e facilmente interpretabili. L’uso di distribuzioni a posteriori complete ci ha permesso di valutare in modo più dettagliato la plausibilità delle differenze osservate, offrendo una maggiore profondità di interpretazione rispetto agli intervalli di confidenza frequentisti.\n\n71.4.1 Vantaggi dell’Approccio Bayesiano\n\nDistribuzioni A Posteriori: L’approccio bayesiano fornisce una visione completa della distribuzione dei parametri stimati, permettendo di calcolare probabilità direttamente e quantificare l’incertezza in modo più intuitivo.\nFlessibilità Modellistica: brms consente di costruire modelli complessi, inclusi modelli gerarchici e multivariati, adattandosi alle specifiche esigenze dell’analisi senza perdere di generalità.\nPrior Informativi e Non Informativi: La possibilità di incorporare prior informativi o utilizzare prior non informativi permette di integrare conoscenze pregresse o lavorare in assenza di informazioni preliminari, aumentando la robustezza delle inferenze.\nIntegrazione con Stan: Sfruttando la potenza di Stan, brms offre algoritmi di campionamento efficienti e accurati per modelli complessi, garantendo risultati affidabili anche in situazioni di alta dimensionalità.\nVisualizzazione e Interpretazione: L’integrazione con pacchetti come tidyverse e ggplot2 facilita la visualizzazione e l’interpretazione dei risultati, rendendo più semplice comunicare le analisi bayesiane a un pubblico ampio e variegato.\n\n71.4.2 Applicazioni Pratiche\nI risultati ottenuti confermano che i “pledgers” hanno una minore propensione all’uso del preservativo rispetto ai “non-pledgers”, supportando con elevata credibilità l’ipotesi formulata. Questi risultati riproducono quelli riportati dalla letteratura precedente, rafforzando la validità dell’approccio bayesiano nelle applicazioni pratiche.\n\n71.4.3 Conclusione\nIn sintesi, l’approccio bayesiano, implementato attraverso il pacchetto brms, rappresenta uno strumento estremamente potente e flessibile per l’inferenza statistica. Offre una visione più dettagliata e comprensiva rispetto agli approcci frequentisti tradizionali, permettendo di ottenere risultati coerenti e facilmente interpretabili.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Inferenza sulle proporzioni</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_one_proportion.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/11_one_proportion.html#informazioni-sullambiente-di-sviluppo",
    "title": "71  Inferenza sulle proporzioni",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] tidybayes_3.0.7   broom_1.0.8       brms_2.22.0       Rcpp_1.0.14      \n#&gt;  [5] bayestestR_0.16.0 posterior_1.6.1   cmdstanr_0.9.0    thematic_0.1.7   \n#&gt;  [9] MetBrewer_0.2.0   ggokabeito_0.1.0  see_0.11.0        gridExtra_2.3    \n#&gt; [13] patchwork_1.3.0   bayesplot_1.13.0  psych_2.5.3       scales_1.4.0     \n#&gt; [17] markdown_2.0      knitr_1.50        lubridate_1.9.4   forcats_1.0.0    \n#&gt; [21] stringr_1.5.1     dplyr_1.1.4       purrr_1.0.4       readr_2.1.5      \n#&gt; [25] tidyr_1.3.1       tibble_3.3.0      ggplot2_3.5.2     tidyverse_2.0.0  \n#&gt; [29] rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] mnormt_2.1.1         inline_0.3.21        sandwich_3.1-1      \n#&gt;  [4] rlang_1.1.6          magrittr_2.0.3       multcomp_1.4-28     \n#&gt;  [7] matrixStats_1.5.0    compiler_4.5.0       loo_2.8.0           \n#&gt; [10] vctrs_0.6.5          reshape2_1.4.4       pkgconfig_2.0.3     \n#&gt; [13] arrayhelpers_1.1-0   fastmap_1.2.0        backports_1.5.0     \n#&gt; [16] labeling_0.4.3       utf8_1.2.6           rmarkdown_2.29      \n#&gt; [19] tzdb_0.5.0           ps_1.9.1             xfun_0.52           \n#&gt; [22] jsonlite_2.0.0       parallel_4.5.0       R6_2.6.1            \n#&gt; [25] stringi_1.8.7        RColorBrewer_1.1-3   StanHeaders_2.32.10 \n#&gt; [28] estimability_1.5.1   rstan_2.32.7         zoo_1.8-14          \n#&gt; [31] pacman_0.5.1         Matrix_1.7-3         splines_4.5.0       \n#&gt; [34] timechange_0.3.0     tidyselect_1.2.1     rstudioapi_0.17.1   \n#&gt; [37] abind_1.4-8          codetools_0.2-20     curl_6.3.0          \n#&gt; [40] processx_3.8.6       pkgbuild_1.4.8       lattice_0.22-7      \n#&gt; [43] plyr_1.8.9           withr_3.0.2          bridgesampling_1.1-2\n#&gt; [46] coda_0.19-4.1        evaluate_1.0.4       survival_3.8-3      \n#&gt; [49] RcppParallel_5.1.10  ggdist_3.3.3         pillar_1.10.2       \n#&gt; [52] tensorA_0.36.2.1     checkmate_2.3.2      stats4_4.5.0        \n#&gt; [55] insight_1.3.0        distributional_0.5.0 generics_0.1.4      \n#&gt; [58] rprojroot_2.0.4      hms_1.1.3            rstantools_2.4.0    \n#&gt; [61] xtable_1.8-4         glue_1.8.0           emmeans_1.11.1      \n#&gt; [64] tools_4.5.0          data.table_1.17.6    mvtnorm_1.3-3       \n#&gt; [67] grid_4.5.0           QuickJSR_1.8.0       colorspace_2.1-1    \n#&gt; [70] nlme_3.1-168         cli_3.6.5            svUnit_1.0.6        \n#&gt; [73] Brobdingnag_1.2-9    V8_6.0.4             gtable_0.3.6        \n#&gt; [76] digest_0.6.37        TH.data_1.1-3        htmlwidgets_1.6.4   \n#&gt; [79] farver_2.1.2         htmltools_0.5.8.1    lifecycle_1.0.4     \n#&gt; [82] MASS_7.3-65",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Inferenza sulle proporzioni</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_one_proportion.html#bibliografia",
    "href": "chapters/linear_models/11_one_proportion.html#bibliografia",
    "title": "71  Inferenza sulle proporzioni",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlbert, J., & Hu, J. (2019). Probability and Bayesian Modeling. CRC Press.\n\n\nBrückner, H., & Bearman, P. (2005). After the promise: The STD consequences of adolescent virginity pledges. Journal of Adolescent Health, 36(4), 271–278.\n\n\nKruschke, J. K., & Liddell, T. M. (2018). Bayesian data analysis for newcomers. Psychonomic Bulletin & Review, 25(1), 155–177.\n\n\nWagenmakers, E.-J., Lodewyckx, T., Kuriyal, H., & Grasman, R. (2010). Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method. Cognitive Psychology, 60(3), 158–189.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Inferenza sulle proporzioni</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html",
    "href": "chapters/linear_models/12_two_proportions.html",
    "title": "72  Confronto tra due proporzioni indipendenti",
    "section": "",
    "text": "72.1 Introduzione\nSupponiamo di voler capire se due gruppi di persone hanno la stessa probabilità di “successo” in una certa attività. Per esempio, vogliamo sapere se due trattamenti diversi portano alla stessa percentuale di guarigione, oppure se studenti che seguono due metodi di studio differenti superano un esame con la stessa frequenza.\nQuando il risultato per ogni persona è un valore binario — successo o insuccesso, sì o no, guarito o non guarito — possiamo usare un modello statistico chiamato regressione logistica.\nIn particolare, se i due gruppi sono indipendenti e distinti (cioè ogni persona appartiene a uno solo dei due gruppi), possiamo usare una versione semplice della regressione logistica con una sola variabile esplicativa binaria (una “dummy”).\nAdottando un approccio bayesiano, possiamo:",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#introduzione",
    "href": "chapters/linear_models/12_two_proportions.html#introduzione",
    "title": "72  Confronto tra due proporzioni indipendenti",
    "section": "",
    "text": "rendere esplicita l’incertezza sulle nostre ipotesi iniziali tramite le distribuzioni a priori;\n\ndescrivere l’intera gamma di risultati plausibili, ottenendo una distribuzione a posteriori dei parametri invece di un singolo valore “stimato”.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#la-struttura-dei-dati",
    "href": "chapters/linear_models/12_two_proportions.html#la-struttura-dei-dati",
    "title": "72  Confronto tra due proporzioni indipendenti",
    "section": "\n72.2 La struttura dei dati",
    "text": "72.2 La struttura dei dati\nConsideriamo i dati che raccogliamo:\n\nogni partecipante è identificato da un indice \\(i = 1, 2, \\dots, N\\);\n\nper ciascuno osserviamo un esito binario:\n\\[\ny_i =\n  \\begin{cases}\n    1 & \\text{se c’è un successo},\\\\\n    0 & \\text{se c’è un insuccesso}.\n  \\end{cases}\n\\]\n\nogni partecipante appartiene a uno e un solo gruppo. Chiamiamo gruppo 0 il primo gruppo (ad esempio, il gruppo di controllo) e gruppo 1 il secondo gruppo (ad esempio, il gruppo che riceve un trattamento sperimentale).\n\nPer rappresentare questa appartenenza al gruppo, definiamo una variabile indicatrice:\n\\[\nD_i =\n  \\begin{cases}\n    0 & \\text{se il partecipante è nel gruppo 0},\\\\\n    1 & \\text{se il partecipante è nel gruppo 1}.\n  \\end{cases}\n\\]\nQuesta variabile ci permette di costruire un modello che distingue i due gruppi.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#un-modello-statistico-per-dati-binari",
    "href": "chapters/linear_models/12_two_proportions.html#un-modello-statistico-per-dati-binari",
    "title": "72  Confronto tra due proporzioni indipendenti",
    "section": "\n72.3 Un modello statistico per dati binari",
    "text": "72.3 Un modello statistico per dati binari\nPoiché il risultato \\(y\\_i\\) può essere solo 0 o 1, possiamo descriverlo con una distribuzione di Bernoulli, che rappresenta proprio questo tipo di variabili:\n\\[\ny_i \\sim \\text{Bernoulli}(p_i),\n\\]\ndove \\(p\\_i\\) è la probabilità che il partecipante \\(i\\) ottenga un successo (cioè che \\(y_i = 1\\)).\nA questo punto potremmo pensare di modellare direttamente \\(p_i\\) come una funzione di \\(D_i\\). Ma c’è un problema tecnico importante.\n\n72.3.1 Perché non modelliamo direttamente la probabilità \\(p_i\\)?\nLe probabilità devono sempre stare tra 0 e 1. Ma se usassimo un modello lineare classico (come \\(p\\_i = \\alpha + \\gamma D_i\\)), potremmo ottenere dei valori fuori da questo intervallo — ad esempio, una “probabilità” negativa o maggiore di 1, che non ha senso.\nPer evitare questo, si usa una trasformazione matematica chiamata logit, che ha due proprietà molto utili:\n\naccetta in ingresso solo valori tra 0 e 1 (cioè le probabilità),\nrestituisce un numero reale qualsiasi, da \\(-\\infty\\) a \\(+\\infty\\).\n\nLa trasformazione logit è definita così:\n\\[\n\\text{logit}(p_i) = \\log\\left(\\frac{p_i}{1 - p_i}\\right) .\n\\]\nQuesta quantità si chiama log-odds e rappresenta il logaritmo del rapporto tra la probabilità di successo e quella di insuccesso.\nEsempio:\n\nse \\(p_i = 0.5\\), allora \\(\\text{logit}(p_i) = \\log(1) = 0\\);\nse \\(p_i = 0.8\\), allora \\(\\text{logit}(p_i) = \\log(4) \\approx 1.39\\);\nse \\(p_i = 0.2\\), allora \\(\\text{logit}(p_i) = \\log(0.25) \\approx -1.39\\).\n\nGrazie a questa trasformazione, possiamo costruire un modello lineare senza rischiare di ottenere valori fuori dall’intervallo [0,1].",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#il-modello-di-regressione-logistica",
    "href": "chapters/linear_models/12_two_proportions.html#il-modello-di-regressione-logistica",
    "title": "72  Confronto tra due proporzioni indipendenti",
    "section": "\n72.4 Il modello di regressione logistica",
    "text": "72.4 Il modello di regressione logistica\nMettiamo insieme tutti i pezzi. Il nostro modello diventa:\n\\[\n\\begin{aligned}\ny_i &\\sim \\text{Bernoulli}(p_i), \\\\\n\\text{logit}(p_i) &= \\alpha + \\gamma D_i.\n\\end{aligned}\n\\]\nVediamo cosa significano i due parametri del modello:\n\n\n\\(\\alpha\\) è il log-odds di successo per il gruppo 0 (quando \\(D_i = 0\\)).\n\n\nLa probabilità di successo corrispondente si ottiene con la funzione logistica:\n\\[\np_0 = \\frac{e^{\\alpha}}{1 + e^{\\alpha}} = \\text{logistic}(\\alpha) .\n\\]\n\n\n\n\n\\(\\gamma\\) rappresenta la differenza nei log-odds tra il gruppo 1 e il gruppo 0.\n\n\nIl log-odds nel gruppo 1 è quindi $+ $, e la probabilità è:\n\\[\np_1 = \\frac{e^{\\alpha + \\gamma}}{1 + e^{\\alpha + \\gamma}} = \\text{logistic}(\\alpha + \\gamma) .\n\\]\n\n\n\n\n\n72.4.1 Interpretazione pratica\n\nSe \\(\\gamma &gt; 0\\), il gruppo 1 ha una probabilità di successo più alta rispetto al gruppo 0.\nSe \\(\\gamma &lt; 0\\), il gruppo 1 ha una probabilità più bassa.\nSe \\(\\gamma = 0\\), i due gruppi hanno la stessa probabilità di successo.\n\n72.4.2 Vantaggi dell’approccio bayesiano\nIn un’analisi bayesiana, non ci limitiamo a stimare un singolo valore per \\(\\gamma\\). Invece, otteniamo una distribuzione completa che rappresenta tutte le ipotesi plausibili sui valori di \\(\\gamma\\), tenendo conto:\n\ndella variabilità nei dati,\ndelle nostre ipotesi iniziali (le distribuzioni a priori),\ne delle informazioni che emergono dai dati osservati.\n\nQuesto ci permette di rispondere a domande come:\n\nQuanto è probabile che \\(\\gamma\\) sia maggiore di 0?\nQual è l’intervallo più credibile in cui può trovarsi \\(\\gamma\\) con il 95% di probabilità?\nQual è la probabilità che la differenza tra i gruppi sia sostanziale, non solo presente?\n\n72.4.3 Dai Logit alle Probabilità\nUna volta stimati i coefficienti del modello di regressione logistica — in particolare, l’intercetta \\(\\beta\\_0\\) e uno o più coefficienti \\(\\beta_j\\) associati ai predittori — questi si trovano sulla scala dei log-odds (cioè su scala logit). Per ottenere le probabilità previste per ciascuna combinazione di valori dei predittori, è sufficiente applicare la funzione logistica inversa, definita come:\n\\[\np = \\text{logistic}(\\eta) = \\frac{1}{1 + e^{-\\eta}},\n\\]\ndove \\(\\eta = \\beta_0 + \\beta_1 x_1 + \\dots + \\beta_k x_k\\) è il valore del predittore lineare per una certa combinazione dei predittori. Ad esempio, se si ha solo una variabile binaria \\(x\\) che vale 0 (gruppo di riferimento) o 1 (gruppo trattato), allora le probabilità nei due gruppi sono:\n\ngruppo di riferimento: \\(p_0 = \\frac{1}{1 + e^{-\\beta_0}}\\)\n\ngruppo trattamento:    \\(p_1 = \\frac{1}{1 + e^{-(\\beta\\_0 + \\beta_1)}}\\)\n\n\nIn questo modo, si può interpretare il modello non solo in termini di log-odds, ma anche come probabilità di successo, rendendo più intuitivo il significato pratico dei risultati.\n\n72.4.4 Inferenza bayesiana\n\n\nScelta delle prior\n\nUn’opzione comune è usare prior debolmente informative, ad esempio \\(\\alpha\\sim\\mathcal N(0,\\,2.5)\\) e \\(\\gamma\\sim\\mathcal N(0,\\,2.5)\\). Queste varianze larghe lasciano che i dati “parlino”, ma impediscono che le probabilità si avvicinino troppo a 0 o 1 senza evidenza.\n\n\n\nCalcolo della distribuzione a posteriori\n\nSi usa normalmente l’algoritmo MCMC (per es. No‑U‑Turn Sampler di Stan).\nOtteniamo campioni \\(\\{\\alpha^{(s)},\\gamma^{(s)}\\}_{s=1}^S\\).\n\n\n\nQuantità derivate di interesse\n\nProbabilità nei due gruppi: \\(p_0^{(s)}=\\operatorname{logistic}(\\alpha^{(s)})\\), \\(p_1^{(s)}=\\operatorname{logistic}(\\alpha^{(s)}+\\gamma^{(s)})\\).\n\nDifferenza di probabilità: \\(\\Delta^{(s)} = p_1^{(s)}-p_0^{(s)}\\). Mostra quanto, in media, il gruppo 1 supera (o non supera) il gruppo 0 in termini di proporzione.\n\nRapporto di odds: \\(\\text{OR}^{(s)} = e^{\\gamma^{(s)}}\\). Se \\(\\text{OR}=2\\) significa che gli odds di successo nel gruppo 1 sono il doppio di quelli nel gruppo 0.\n\n\n\nSintesi dei risultati\n\nMedia (o mediana) a posteriori per \\(p_0, p_1, \\Delta, \\text{OR}\\).\nIntervalli di credibilità al 95 %: tagliamo il 2.5 % di campioni in ciascuna coda.\nProbabilità che \\(\\Delta&gt;0\\) o che \\(\\text{OR}&gt;1\\): basta contare la frazione di campioni corrispondenti.\n\n\n\n72.4.5 Perché tutto questo funziona?\n\nIl logit “apre” l’intervallo (0, 1) rendendo possibile usare un modello lineare.\n\nLa regressione logistica con una dummy è l’esatto equivalente, in termini di parametri, al test bayesiano sulle due proporzioni, ma:\n\nconsente estensioni (più covariate, effetti casuali, interazioni);\npermette di riportare risultati direttamente interpretabili (differenza di probabilità, OR, predicted probabilities).\n\n\nL’approccio bayesiano produce output che si leggono come “date le nostre ipotesi preliminari e i dati, la plausibilità che la vera differenza di probabilità stia in questo intervallo è 95 %”, concetto spesso più intuitivo del valore‑p.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#inferenza-sulle-proporzioni",
    "href": "chapters/linear_models/12_two_proportions.html#inferenza-sulle-proporzioni",
    "title": "72  Confronto tra due proporzioni indipendenti",
    "section": "\n72.5 Inferenza sulle proporzioni",
    "text": "72.5 Inferenza sulle proporzioni\nIl confronto tra le proporzioni di due gruppi indipendenti può essere affrontato sia con un approccio frequentista, basato sulla distribuzione campionaria, sia con un approccio bayesiano. Vediamo i due approcci in dettaglio.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#approccio-frequentista",
    "href": "chapters/linear_models/12_two_proportions.html#approccio-frequentista",
    "title": "72  Confronto tra due proporzioni indipendenti",
    "section": "\n72.6 Approccio Frequentista",
    "text": "72.6 Approccio Frequentista\nQuando vogliamo confrontare le probabilità di successo in due gruppi distinti, possiamo analizzare la differenza tra le proporzioni di successo osservate. L’approccio frequentista affronta il problema studiando la distribuzione campionaria di questa differenza.\n\n72.6.1 Modello di riferimento\nSupponiamo di avere due gruppi indipendenti. In ciascun gruppo osserviamo esiti binari, come “successo” (1) o “insuccesso” (0), per ogni partecipante. Formalmente:\n\\[\nY_1 \\sim \\text{Bernoulli}(p_1), \\quad Y_2 \\sim \\text{Bernoulli}(p_2),\n\\]\ndove \\(p_1\\) e \\(p_2\\) sono le probabilità di successo nella popolazione del primo e del secondo gruppo, rispettivamente.\n\n72.6.2 Obiettivo dell’inferenza\nSiamo interessati a stimare e fare inferenza sulla differenza tra le due proporzioni:\n\\[\n\\Delta = p_1 - p_2.\n\\]\nPoiché non conosciamo \\(p_1\\) e \\(p_2\\), li stimiamo usando le proporzioni campionarie:\n\\[\n\\hat{p}_1 = \\frac{X_1}{n_1}, \\quad \\hat{p}_2 = \\frac{X_2}{n_2}, \\quad \\text{e dunque} \\quad \\hat{\\Delta} = \\hat{p}_1 - \\hat{p}_2.\n\\]\n\n72.6.3 Proprietà della distribuzione campionaria\nPer capire se la differenza osservata tra \\(\\hat{p}_1\\) e \\(\\hat{p}_2\\) è attribuibile al caso oppure riflette una differenza reale tra i gruppi, analizziamo la distribuzione campionaria di \\(\\hat{\\Delta}\\).\n\n72.6.3.1 Valore atteso\nIl valore atteso della differenza stimata è:\n\\[\nE(\\hat{p}_1 - \\hat{p}_2) = p_1 - p_2,\n\\]\ncioè, in media, la stima è corretta (è uno stimatore non distorto).\n\n\n\n\n\n\nDimostrazione\n\n\n\n\n\nSupponiamo di voler confrontare le proporzioni di successo in due popolazioni distinte. Sia:\n\n\n\\(X_1\\) il numero di successi osservati in un campione di dimensione \\(n_1\\) estratto dalla prima popolazione, in cui la proporzione di successo è \\(p_1\\);\n\n\\(X_2\\) il numero di successi osservati in un campione di dimensione \\(n_2\\) estratto dalla seconda popolazione, con proporzione di successo \\(p_2\\).\n\nAssumiamo che i due campioni siano indipendenti.\nLe proporzioni campionarie, che stimano rispettivamente \\(p_1\\) e \\(p_2\\), sono definite come:\n\\[\n\\hat{p}_1 = \\frac{X_1}{n_1}, \\quad \\hat{p}_2 = \\frac{X_2}{n_2}.\n\\]\nPoiché \\(X_1 \\sim \\text{Binomiale}(n_1, p_1)\\) e \\(X_2 \\sim \\text{Binomiale}(n_2, p_2)\\), possiamo determinare i valori attesi di \\(X_1\\) e \\(X_2\\) ricordando che per una variabile binomiale \\(X \\sim \\text{Bin}(n, p)\\), il valore atteso è:\n\\[\n\\mathbb{E}(X) = n p.\n\\]\nUna variabile binomiale può essere vista come la somma di \\(n\\) variabili di Bernoulli indipendenti:\n\\[\nX = X_1 + X_2 + \\dots + X_n, \\quad \\text{con } X_i \\sim \\text{Bernoulli}(p).\n\\]\nPer la linearità del valore atteso:\n\\[\n\\mathbb{E}(X) = \\sum_{i=1}^n \\mathbb{E}(X_i) = \\sum_{i=1}^n p = n p.\n\\]\nApplicando questa proprietà ai nostri due campioni:\n\\[\n\\mathbb{E}(X_1) = n_1 p_1, \\quad \\mathbb{E}(X_2) = n_2 p_2.\n\\]\nPer la prima proporzione campionaria:\n\\[\n\\mathbb{E}(\\hat{p}_1) = \\mathbb{E}\\left( \\frac{X_1}{n_1} \\right) = \\frac{1}{n_1} \\mathbb{E}(X_1) = \\frac{n_1 p_1}{n_1} = p_1.\n\\]\nAnalogamente, per la seconda:\n\\[\n\\mathbb{E}(\\hat{p}_2) = \\mathbb{E}\\left( \\frac{X_2}{n_2} \\right) = \\frac{1}{n_2} \\mathbb{E}(X_2) = \\frac{n_2 p_2}{n_2} = p_2.\n\\]\nDunque, sia \\(\\hat{p}_1\\) che \\(\\hat{p}_2\\) sono stimatori non distorti delle rispettive proporzioni della popolazione.\nInfine, calcoliamo il valore atteso della differenza tra le due proporzioni campionarie:\n\\[\n\\mathbb{E}(\\hat{p}_1 - \\hat{p}_2) = \\mathbb{E}(\\hat{p}_1) - \\mathbb{E}(\\hat{p}_2) = p_1 - p_2.\n\\]\nIn conclusione, la differenza tra le proporzioni campionarie, \\(\\hat{p}_1 - \\hat{p}_2\\), è uno stimatore non distorto della differenza tra le vere proporzioni, \\(p_1 - p_2\\).\n\n\n\n\n72.6.3.2 Varianza\nAssumendo che i campioni siano indipendenti, la varianza della differenza stimata è la somma delle varianze delle due proporzioni:\n\\[\n\\operatorname{Var}(\\hat{p}_1 - \\hat{p}_2) = \\frac{p_1(1 - p_1)}{n_1} + \\frac{p_2(1 - p_2)}{n_2}.\n\\]\nQuesta formula ci dice quanto può variare la differenza stimata da un campione all’altro.\nPoiché \\(p_1\\) e \\(p_2\\) sono ignoti, nella pratica li sostituiamo con le proporzioni osservate \\(\\hat{p}_1\\) e \\(\\hat{p}_2\\) per stimare la varianza.\n\n\n\n\n\n\nDimostrazione\n\n\n\n\n\nConsideriamo due campioni indipendenti:\n\nIl primo campione è estratto da una popolazione in cui la proporzione di successi è \\(p_1\\). Il numero di successi osservati è una variabile casuale \\(X_1 \\sim \\text{Binomiale}(n_1, p_1)\\).\nIl secondo campione proviene da una popolazione con proporzione di successi \\(p_2\\), e il numero di successi osservati è \\(X_2 \\sim \\text{Binomiale}(n_2, p_2)\\).\n\nDefiniamo le proporzioni campionarie (ovvero gli stimatori di \\(p_1\\) e \\(p_2\\)) come:\n\\[\n\\hat{p}_1 = \\frac{X_1}{n_1}, \\qquad \\hat{p}_2 = \\frac{X_2}{n_2}.\n\\]\nVogliamo calcolare la varianza della differenza tra le proporzioni campionarie:\n\\[\n\\operatorname{Var}(\\hat{p}_1 - \\hat{p}_2).\n\\]\nSe \\(Y\\) e \\(Z\\) sono variabili casuali indipendenti, allora:\n\\[\n\\operatorname{Var}(Y - Z) = \\operatorname{Var}(Y) + \\operatorname{Var}(Z).\n\\]\nNel nostro caso, \\(\\hat{p}_1\\) e \\(\\hat{p}_2\\) derivano da due campioni indipendenti, quindi possiamo applicare questa proprietà:\n\\[\n\\operatorname{Var}(\\hat{p}_1 - \\hat{p}_2) = \\operatorname{Var}(\\hat{p}_1) + \\operatorname{Var}(\\hat{p}_2).\n\\]\nPer calcolare \\(\\operatorname{Var}(\\hat{p})\\), partiamo dalla definizione di \\(\\hat{p} = X/n\\), dove \\(X \\sim \\text{Binomiale}(n, p)\\).\nÈ noto che la varianza di una binomiale (si veda Capitolo 39) è:\n\\[\n\\operatorname{Var}(X) = n p (1 - p).\n\\]\nOra applichiamo la proprietà di omogeneità della varianza: se \\(Y = cX\\), allora \\(\\operatorname{Var}(Y) = c^2 \\operatorname{Var}(X)\\). Quindi:\n\\[\n\\operatorname{Var}(\\hat{p}) = \\operatorname{Var}\\left(\\frac{X}{n}\\right) = \\frac{1}{n^2} \\cdot \\operatorname{Var}(X) = \\frac{1}{n^2} \\cdot n p (1 - p) = \\frac{p(1 - p)}{n}.\n\\]\nApplichiamo questa formula a ciascun campione:\n\\[\n\\operatorname{Var}(\\hat{p}_1) = \\frac{p_1 (1 - p_1)}{n_1}, \\qquad \\operatorname{Var}(\\hat{p}_2) = \\frac{p_2 (1 - p_2)}{n_2}.\n\\]\nSostituendo i valori ottenuti:\n\\[\n\\operatorname{Var}(\\hat{p}_1 - \\hat{p}_2) = \\frac{p_1 (1 - p_1)}{n_1} + \\frac{p_2 (1 - p_2)}{n_2}.\n\\]\nQuesta espressione rappresenta la varianza teorica della differenza tra le proporzioni campionarie, assumendo che i veri valori di \\(p_1\\) e \\(p_2\\) siano noti.\nNella realtà, i parametri \\(p_1\\) e \\(p_2\\) non sono noti, e quindi dobbiamo usare le stime campionarie al loro posto. Otteniamo così uno stimatore della varianza:\n\\[\n\\widehat{\\operatorname{Var}}(\\hat{p}_1 - \\hat{p}_2) = \\frac{\\hat{p}_1 (1 - \\hat{p}_1)}{n_1} + \\frac{\\hat{p}_2 (1 - \\hat{p}_2)}{n_2}.\n\\]\n\n\n\n\n72.6.4 Approssimazione normale\nQuando i campioni sono sufficientemente grandi, possiamo applicare il Teorema del Limite Centrale, che ci assicura che la distribuzione della differenza \\(\\hat{p}_1 - \\hat{p}_2\\) si avvicina a una distribuzione normale:\n\\[\n\\hat{p}_1 - \\hat{p}_2 \\sim \\mathcal{N}\\left(p_1 - p_2,\\ \\sqrt{\\frac{p_1(1 - p_1)}{n_1} + \\frac{p_2(1 - p_2)}{n_2}}\\right).\n\\tag{72.1}\\]\nNell’approccio frequentista, questa approssimazione è alla base della costruzione di:\n\n\nintervalli di confidenza per \\(p_1 - p_2\\),\n\ntest di ipotesi per verificare se la differenza tra le proporzioni è nulla.\n\n72.6.5 Test dell’ipotesi nulla\nLa formula Equazione 72.1 descrive la la distribuzione asintotica della differenza tra due proporzioni senza assumere che \\(p_1 = p_2\\). Si usa tipicamente per:\n\ncostruire intervalli di confidenza per \\(p_1 - p_2\\),\neffettuare test di ipotesi bilaterali, quando non si assume che le due proporzioni siano uguali sotto l’ipotesi nulla.\n\nIn alternativa, la formula\n\\[\n\\text{SE}_{\\text{pooled}} = \\sqrt{p_{\\text{pool}}(1 - p_{\\text{pool}})\\left(\\frac{1}{n_1} + \\frac{1}{n_2}\\right)}\n\\tag{72.2}\\]\nsi usa solo per testare l’ipotesi nulla \\(H_0: p_1 = p_2\\), ovvero sotto l’assunzione che \\(p_1 = p_2 = p\\), si stima questo valore comune con la proporzione combinata (pooled):\n\\[\n\\hat{p}_{\\text{pool}} = \\frac{x_1 + x_2}{n_1 + n_2}\n\\]\ne si calcola il test z usando questa stima comune.\n\n72.6.6 Quale formula usare e quando?\n\n\n\n\n\n\nScopo\nFormula da usare\n\n\n\nTest dell’ipotesi nulla \\(H_0: p_1 = p_2\\)\n\n✅ Usa la formula con pooled proportion\n\n\n\nCostruire intervallo di confidenza per \\(p_1 - p_2\\)\n\n✅ Usa la formula senza pooling, con \\(\\hat{p}_1\\) e \\(\\hat{p}_2\\)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#un-esempio-illustrativo",
    "href": "chapters/linear_models/12_two_proportions.html#un-esempio-illustrativo",
    "title": "72  Confronto tra due proporzioni indipendenti",
    "section": "\n72.7 Un esempio Illustrativo",
    "text": "72.7 Un esempio Illustrativo\nPer mettere in pratica quanto detto, consideriamo un caso reale tratto dallo studio di Banerjee et al. (2025). In questo studio vengono confrontate le abilità matematiche di:\n\n\nbambini lavoratori nei mercati di Kolkata e Delhi;\n\nbambini scolarizzati che non lavorano.\n\nL’obiettivo era valutare se le competenze sviluppate nel lavoro quotidiano (come dare il resto, sommare prezzi, ecc.) si trasferiscono al contesto scolastico e viceversa.\nI risultati principali mostrano come:\n\ni bambini lavoratori si sono dimostrati molto abili nel risolvere problemi matematici concreti, ma hanno faticato con problemi presentati in forma astratta (come quelli scolastici);\nal contrario, i bambini scolarizzati se la sono cavata meglio con problemi astratti, ma sono risultati poco efficaci nei problemi concreti del mercato.\n\nVediamo i dati raccolti per due tipi di problemi:\nProblemi astratti.\n\n\nGruppo\nSuccessi\nProve totali\nProporzione\n\n\n\nBambini lavoratori\n670\n1488\n0.45\n\n\nBambini scolarizzati\n320\n542\n0.59\n\n\n\nProblemi di mercato.\n\n\nGruppo\nSuccessi\nProve totali\nProporzione\n\n\n\nBambini lavoratori\n134\n373\n0.36\n\n\nBambini scolarizzati\n3\n271\n0.01\n\n\n\n\n72.7.1 Confronto per i problemi astratti\nUtilizzando l’approccio frequentista, vogliamo verificare se la differenza tra 0.45 (lavoratori) e 0.59 (scolarizzati) è spiegabile dal caso.\nIpotesi.\n\n\n\\(H_0\\): \\(p_1 = p_2\\) (nessuna differenza tra i gruppi);\n\n\\(H_1\\): \\(p_1 \\ne p_2\\) (esiste una differenza).\n\nCalcolo.\n\n\nProporzione combinata (pooled):\n\\[\n\\hat{p} = \\frac{670 + 320}{1488 + 542} = \\frac{990}{2030} \\approx 0.487.\n\\]\n\n\nVarianza stimata della differenza:\n\\[\n\\text{Var} = \\hat{p}(1 - \\hat{p}) \\left( \\frac{1}{1488} + \\frac{1}{542} \\right) \\approx 0.000629.\n\\]\n\nDeviazione standard: \\(\\sqrt{0.000629} \\approx 0.0251\\).\n\nStatistica z:\n\\[\nz = \\frac{0.45 - 0.59}{0.0251} \\approx -5.58.\n\\]\n\n\nIl valore z è molto lontano da 0: la probabilità di osservare una tale differenza per caso (p-value) è inferiore a 0.0001. Possiamo quindi rifiutare l’ipotesi nulla.\n\n72.7.2 Confronto per i problemi di mercato\nDati:\n\nLavoratori: 134 su 373 (\\(\\hat{p}_1 = 0.36\\))\nScolarizzati: 3 su 271 (\\(\\hat{p}_2 = 0.01\\))\n\nRipetiamo i passaggi:\n\n\\(\\hat{p} = \\frac{137}{644} \\approx 0.213\\)\n\\(\\text{Var} \\approx 0.001067\\)\nDeviazione standard: \\(\\sqrt{0.001067} \\approx 0.0327\\)\n\nStatistica z:\n\\[\nz = \\frac{0.36 - 0.01}{0.0327} \\approx 10.70\n\\]\n\n\nAnche qui, il p-value è praticamente zero: le differenze sono molto più grandi di quanto ci si aspetti per puro caso.\nIn sintesi, l’approccio frequentista ci consente di:\n\nstimare la differenza tra le proporzioni,\nquantificare l’incertezza (varianza e intervallo di confidenza),\ntestare ipotesi sul fatto che la differenza sia zero o meno.\n\nIn entrambi i confronti (problemi astratti e problemi concreti), abbiamo trovato evidenze chiare di una differenza tra i due gruppi.\n\n72.7.3 Svolgimento con R\nDi seguito mostriamo due modalità per replicare i calcoli in R: (1) passo passo usando le formule manuali, (2) usando la funzione prop.test() di R. Verranno illustrate entrambe le analisi: quella per i problemi astratti e quella per i problemi matematici di mercato.\n\n72.7.3.1 Problemi astratti\nDati\n\nBambini lavoratori (gruppo 1): 670 successi su 1488 prove.\nBambini scolarizzati (gruppo 2): 320 successi su 542 prove.\n\n\n##  Dati\nx_work   &lt;- 670   # successi (risposte corrette) tra i lavoratori\nn_work   &lt;- 1488  # totale lavoratori\n\nx_school &lt;- 320   # successi tra i non-lavoratori (scolarizzati)\nn_school &lt;- 542   # totale non-lavoratori\n\n##  Differenza di proporzioni \np_work   &lt;- x_work   / n_work\np_school &lt;- x_school / n_school\nrd       &lt;- p_school - p_work          \n\n##  Errore standard\n##  - Pooled SE per lo z-test (ipotesi H0: p1 = p2)\n##  - Unpooled SE per l’intervallo di confidenza\np_pool   &lt;- (x_work + x_school) / (n_work + n_school)\nse_test  &lt;- sqrt(p_pool * (1 - p_pool) * (1/n_work + 1/n_school))  # usato solo per lo z-test\nse_ci    &lt;- sqrt(p_work * (1 - p_work) / n_work +\n                 p_school * (1 - p_school) / n_school)  # migliore per il 95 % CI\n\n##  Inferenza\nz        &lt;- rd / se_test\np_value  &lt;- 2 * pnorm(-abs(z))\n\nalpha    &lt;- .05\nz_crit   &lt;- qnorm(1 - alpha/2)\nci_low   &lt;- rd - z_crit * se_ci\nci_high  &lt;- rd + z_crit * se_ci\n\n##  Stampa risultati\ncat(\n  sprintf(\n    \"Differenza assoluta:  %0.3f\\nErrore standard (CI): %0.3f\\nZ-test:            %0.2f\\nP-value:           %.3g\\n95%% CI:            [%0.2f, %0.2f]\\n\",\n    rd, se_ci, z, p_value, ci_low, ci_high\n  )\n)\n#&gt; Differenza assoluta:  0.140\n#&gt; Errore standard (CI): 0.025\n#&gt; Z-test:            5.59\n#&gt; P-value:           2.3e-08\n#&gt; 95% CI:            [0.09, 0.19]\n\nI valori ottenuti, 95% CI: 0.09 to 0.19, replicano quanto riportato da Banerjee et al. (2025) (la piccola differenza tra i risultati dipende dal fatto che gli autori hanno usato un metodo basato sulla regressione):\n\nOverall, 59% of non-working children correctly solved these problems compared with 45% of working children (β = –0.14, s.e.m. = 0.03, 95% CI = –0.20 to –0.08, P &lt; 0.001; Fig. 4, left).\n\n\n72.7.3.2 Analisi con funzione prop.test()\n\nPer ottenere direttamente il test di confronto di due proporzioni, possiamo usare la funzione prop.test di R. Attenzione che, di default, prop.test effettua una correzione per la continuità (Yates), che in questo contesto disattiviamo per confrontare i risultati con i calcoli manuali (impostando correct = FALSE).\n\n# Dati\nx  &lt;- c(670, 320)      # successi   (lavoratori, non-lavoratori)\nn  &lt;- c(1488, 542)     # denominatori\n\n# Test χ² / z-test per p1 = p2  ── senza correzione di continuità\nout &lt;- prop.test(x, n, correct = FALSE)\n\nout\n#&gt; \n#&gt;  2-sample test for equality of proportions without continuity\n#&gt;  correction\n#&gt; \n#&gt; data:  x out of n\n#&gt; X-squared = 31, df = 1, p-value = 2e-08\n#&gt; alternative hypothesis: two.sided\n#&gt; 95 percent confidence interval:\n#&gt;  -0.18864 -0.09163\n#&gt; sample estimates:\n#&gt; prop 1 prop 2 \n#&gt; 0.4503 0.5904\n\nInterpretazione dei risultati.\n\nIl test dell’ipotesi nulla porta al rifiuto di \\(H_0\\), suggerendo che le proporzioni di successo nei due gruppi non sono uguali.\nL’intervallo di confidenza calcolato non include lo zero, indicando che la differenza osservata è incompatibile con l’assenza di effetto.\nPossiamo quindi concludere che esiste una differenza rilevante tra le proporzioni di successo dei bambini lavoratori e di quelli scolarizzati.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#approccio-bayesiano",
    "href": "chapters/linear_models/12_two_proportions.html#approccio-bayesiano",
    "title": "72  Confronto tra due proporzioni indipendenti",
    "section": "\n72.8 Approccio Bayesiano",
    "text": "72.8 Approccio Bayesiano\nÈ possibile applicare l’approccio bayesiano al problema dell’inferenza sulla differenza tra due proporzioni indipendenti utilizzando un modello di regressione con una variabile indicatrice (dummy) per distinguere i due gruppi. Per fare un esempio, consideriamo qui i problemi astratti. Utilizziamo il pacchetto brms per stimare il modello, con distribuzioni a priori debolmente informative specificate di default.\n\n72.8.1 Dati\n\n# Successi e denominatori\nx_work   &lt;- 670 ; n_work   &lt;- 1488\nx_non    &lt;- 320 ; n_non    &lt;-  542\n\ndat_a &lt;- tibble(\n  count = c(x_work, x_non),\n  tot   = c(n_work, n_non),\n  group = factor(c(\"working\", \"non-working\"),\n                 levels = c(\"non-working\", \"working\"))  # “non-working” livello di riferimento\n)\n\ndat_a\n#&gt; # A tibble: 2 × 3\n#&gt;   count   tot group      \n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;      \n#&gt; 1   670  1488 working    \n#&gt; 2   320   542 non-working\n\n\n72.8.2 Prior debolmente informativi\n\n\nNormal (0, 2.5) sul logit corrisponde ai suggerimenti di Gelman et al. per logistic regression: – copre probabilità grossolanamente tra 0.004 e 0.996 sull’intercetta; – per il coefficiente di gruppo equivale a un odds-ratio plausibile entro ~ e±5.\n\n\npriors &lt;- c(\n  prior(normal(0, 2.5), class = \"Intercept\"),\n  prior(normal(0, 2.5), class = \"b\")\n)\n\n\n72.8.3 Stima del modello\n\nfit_a &lt;- brm(\n  count | trials(tot) ~ group,\n  data      = dat_a,\n  family    = binomial(),\n  prior     = priors,\n  backend   = \"cmdstanr\",\n  seed      = 1234,\n  iter      = 4000, chains = 4, cores = 4,\n  sample_prior = \"yes\"   # utile per i PPC sui prior\n)\n\nControlla rapidamente la convergenza:\n\nprint(fit_a, digits = 3)\n#&gt;  Family: binomial \n#&gt;   Links: mu = logit \n#&gt; Formula: count | trials(tot) ~ group \n#&gt;    Data: dat_a (Number of observations: 2) \n#&gt;   Draws: 4 chains, each with iter = 4000; warmup = 2000; thin = 1;\n#&gt;          total post-warmup draws = 8000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;              Estimate Est.Error l-95% CI u-95% CI  Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept       0.369     0.086    0.201    0.539 1.000     3230     3722\n#&gt; groupworking   -0.569     0.100   -0.766   -0.368 1.001     3929     3843\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\n\npp_check(fit_a, type = \"bars\")   \n\n\n\n\n\n\n\n\n72.8.4 Dalla scala logit alla scala delle probabilità\nIl modello stima\n\\[\n\\operatorname{logit}(p_i)=\\beta_0+\\beta_1\\; \\mathbf 1_{\\text{working},i},\n\\]\nperciò:\n\n\n\n\n\n\nParametro\nSignificato\n\n\n\nβ₀ (b_Intercept)\nlog-odds di successo per non-working\n\n\n\nβ₁ (b_groupworking)\ndifferenza di log-odds fra working e non-working\n\n\n\n\nPer ottenere proporzioni e differenza assoluta (Δ) dobbiamo trasformare ogni draw con l’inversa del logit, plogis().\n\npost &lt;- as_draws_df(fit_a, \n                    variables = c(\"b_Intercept\", \"b_groupworking\")) %&gt;% \n  mutate(\n    p_non  = plogis(b_Intercept),                       # Pr(corretto | non-working)\n    p_work = plogis(b_Intercept + b_groupworking),      # Pr(corretto | working)\n    diff   = p_non - p_work                             # risk-difference\n  )\n\nPerché non basta sottrarre β₁?\nPerché β₁ è una differenza di log-odds. La quantità di interesse qui è la differenza di probabilità. Le due scale sono non lineari e non confrontabili senza trasformazione.\n\n72.8.5 Sintesi della risk–difference\n\n\nsummary_diff &lt;- post %&gt;% \n  summarise(\n    mean     = mean(diff),\n    sd       = sd(diff),\n    `2.5%`   = quantile(diff, .025),\n    `97.5%`  = quantile(diff, .975),\n    prob_gt0 = mean(diff &gt; 0)      # P(Δ &gt; 0 | dati, prior)\n  )\n\nprint(summary_diff, digits = 3)\n#&gt; # A tibble: 1 × 5\n#&gt;    mean     sd `2.5%` `97.5%` prob_gt0\n#&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 0.141 0.0244 0.0918   0.188        1\n\n\n\nΔ (media)\nSD\n95 % CrI\nP(Δ &gt; 0)\n\n\n0.140\n0.025\n0.090 – 0.190\n1.000\n\n\nIl risultato replica quanto ottenuto con prop.test() (0.14 ± 0.025, IC 0.09–0.19).\n\n72.8.6 Confronto con l’approccio frequentista\n\nprop.test(c(x_work, x_non), c(n_work, n_non), correct = FALSE)\n#&gt; \n#&gt;  2-sample test for equality of proportions without continuity\n#&gt;  correction\n#&gt; \n#&gt; data:  c(x_work, x_non) out of c(n_work, n_non)\n#&gt; X-squared = 31, df = 1, p-value = 2e-08\n#&gt; alternative hypothesis: two.sided\n#&gt; 95 percent confidence interval:\n#&gt;  -0.18864 -0.09163\n#&gt; sample estimates:\n#&gt; prop 1 prop 2 \n#&gt; 0.4503 0.5904\n\n` Le due analisi coincidono: i bambini non-working hanno ~ 14 punti percentuali in più di probabilità di rispondere correttamente.\n\n72.8.7 Perché preferire il Bayesiano?\n\n\nNiente “ipotesi nulla” irreale – lavoriamo direttamente con la distribuzione di Δ.\n\nInterpretazione pronta – il 95 % CrI dice che, dati e prior, Δ è fra 9 e 19 punti %.\n\nFlessibilità – possiamo integrare conoscenza pregressa, fare previsioni, decision-making, ecc.\n\nCon prior debolmente informativi i risultati restano virtualmente identici all’approccio frequentista; in dataset più piccoli o modelli più complessi, la stabilizzazione offerta dai prior diventa però cruciale.\n\n72.8.8 Intervallo di credibilità a densità più alta\nPer ottenere l’intervallo di credibilità (Highest Density Interval, HDI) sulla scala delle probabilità (e non su quella logit), è necessario trasformare manualmente i draw a livello di probabilità e poi calcolare l’HDI su quei valori trasformati. In altre parole:\n\n\nestraiamo i draw posteriori di b_Intercept e b_groupworking;\n\n\ntrasformiamo i valori con la funzione logit-inversa (\\(\\operatorname{logistic}(x) = 1/(1+e^{-x})\\)) per ottenere le probabilità;\n\n\nse ci concentriamo sul solo effetto sulla scala della probabilità (e.g. differenza fra i due gruppi), calcoliamo la differenza tra la probabilità del gruppo “working” e quella del gruppo “reference” per ciascun draw;\n\n\napplichiamo hdi() su queste grandezze trasformate.\n\nDi seguito è fornito il codice R con il workflow completo.\n\nEstrazione draw posteriori.\n\n\npost &lt;- as_draws_df(fit_a)\n\n\n\nCalcolo delle probabilità per ciascun draw. La variabile ‘group’ abbia due livelli:\n\n“working” (effetto =&gt; b_groupworking)\n“non-working” (riferimento =&gt; b_Intercept)\n\n\n\n\npost &lt;- post %&gt;%\n  dplyr::mutate(\n    p_ref      = plogis(b_Intercept),                       # probabilità (referenza)\n    p_working  = plogis(b_Intercept + b_groupworking),      # prob. gruppo working\n    diff_working_ref = p_working - p_ref                    # differenza\n  )\n\n\nCalcolo dell’HDI sull’effetto (o sulle probabilità).\n\n\nHDI per la probabilità del gruppo “working”.\n\n\nhdi_working_prob &lt;- hdi(post$p_working, ci = 0.95)\nhdi_working_prob\n#&gt; 95% HDI: [0.43, 0.48]\n\n\nHDI per la probabilità del gruppo “non-working” (riferimento).\n\n\nhdi_ref_prob &lt;- hdi(post$p_ref, ci = 0.95)\nhdi_ref_prob\n#&gt; 95% HDI: [0.55, 0.63]\n\n\nHDI della differenza fra le due probabilità.\n\n\nhdi_diff &lt;- hdi(post$diff_working_ref, ci = 0.89)\nhdi_diff\n#&gt; 89% HDI: [-0.18, -0.10]\n\nInterpretazione\n\n\nhdi_working_prob fornisce l’HDI al 95% (o al livello che specificato) della probabilità di “successo” del gruppo “working”.\n\n\nhdi_ref_prob fa lo stesso per il gruppo di riferimento.\n\n\nhdi_diff restituisce l’HDI della differenza in probabilità tra “working” e “reference” (\\(p_{\\text{working}} - p_{\\text{reference}}\\)).\n\nIn questo modo ottieniamo l’intervallo di credibilità (HDI) sulla scala delle probabilità.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#riflessioni-conclusive",
    "href": "chapters/linear_models/12_two_proportions.html#riflessioni-conclusive",
    "title": "72  Confronto tra due proporzioni indipendenti",
    "section": "\n72.9 Riflessioni Conclusive",
    "text": "72.9 Riflessioni Conclusive\nIn questo capitolo abbiamo esplorato il confronto tra due proporzioni adottando sia l’approccio frequentista sia quello bayesiano. L’obiettivo principale era valutare se la proporzione di successi in un gruppo differisse da quella osservata nell’altro gruppo, e con quale grado di incertezza.\nNella procedura classica frequentista (test per due proporzioni), si calcola una statistica di test (ad esempio, un test z) e il relativo p-value, ossia la probabilità di osservare un risultato così estremo (o più) assumendo che le due proporzioni reali siano uguali (ipotesi nulla).\n\n\nIntervallo di confidenza: È possibile costruire un intervallo di confidenza (IC) per la differenza tra le due proporzioni. L’interpretazione frequentista di tale IC, però, si basa su un’ipotetica ripetizione di campionamenti ed è focalizzata sull’eventuale rifiuto o meno dell’ipotesi che la differenza sia zero.\n\n\nLimiti interpretativi: L’approccio frequentista si fonda sul concetto di ipotesi nulla “nessuna differenza” e non fornisce una probabilità diretta di quanto la differenza vera sia maggiore o minore di un certo valore, limitandosi a indicare se i dati sono inusuali qualora la differenza fosse zero.\n\nGrazie alla regola di Bayes, combiniamo informazioni a priori (sul probabile valore delle proporzioni) con i dati osservati, per ottenere una distribuzione a posteriori della differenza tra le due proporzioni. Questa distribuzione descrive i valori plausibili della differenza, insieme alle relative credibilità (probabilità).\n\n\nCredible Interval o Highest Density Interval (HDI): Al posto di un intervallo di confidenza, l’approccio bayesiano fornisce un intervallo di credibilità. Ad esempio, un 95% HDI indica i valori della differenza tra le proporzioni che cumulativamente contengono il 95% della probabilità a posteriori. È un costrutto immediatamente interpretabile: “Abbiamo una probabilità del 95% che la differenza vera cada all’interno di questo intervallo”.\n\n\nFlessibilità e interpretazione diretta: L’approccio bayesiano permette di rispondere in modo più naturale a domande come: “Qual è la probabilità che la differenza fra le due proporzioni sia maggiore di 0?” oppure “Qual è la probabilità che la proporzione di un gruppo superi quella dell’altro di almeno una certa soglia rilevante?”.\n\nConfronto tra i due approcci:\n\n\nInterpretazione dei risultati: Il p-value frequentista ci dice quanto il dato sia “improbabile” sotto l’ipotesi di uguaglianza delle proporzioni; il Bayesianesimo risponde direttamente a quanto è plausibile ogni possibile valore di differenza.\n\n\nCentralità dell’ipotesi nulla: Nel frequentismo, l’ipotesi nulla (differenza = 0) è centrale. Nel modello bayesiano, è invece possibile assegnare direttamente probabilità alla differenza e alla sua distanza da zero, evitando un focus eccessivo sull’uguaglianza perfetta delle due proporzioni.\n\n\nRuolo dei priors: L’uso di priors (non informativi o informativi) può influire sulle stime bayesiane quando i dati sono scarsi, rendendo evidente la necessità di scelte trasparenti e ben motivate. Tuttavia, con campioni ampi, l’influenza dei priors tende a ridursi e la stima a posteriori è dominata dai dati.\n\n\nCompletezza dell’inferenza: L’approccio bayesiano consente di integrare nuove informazioni e di aggiornare la distribuzione a posteriori man mano che arrivano dati aggiuntivi. Al contrario, l’approccio frequentista non fornisce un meccanismo diretto di “aggiornamento” delle stime alla luce di nuovi dati.\n\nIn sintesi,\n\n\napproccio frequentista: Si tratta di una metodologia consolidata e standard nella ricerca; fornisce risultati in termini di p-value e IC, ma l’interpretazione del p-value e dell’IC resta legata a procedure di campionamento ipotetico.\n\n\napproccio bayesiano: Offre una maniera più intuitiva di quantificare l’incertezza, assegnando probabilità dirette ai possibili valori di differenza fra le due proporzioni. Consente di formulare domande più specifiche (es. la probabilità che la differenza superi un valore definito) e di integrare in modo naturale informazioni a priori.\n\nNella pratica della ricerca, l’approccio frequentista rimane diffuso. Tuttavia, l’inferenza bayesiana fornisce un quadro interpretativo più ricco e flessibile. Utilizzare entrambi i metodi, quando appropriato, può potenziare l’analisi e la comprensione dei dati, permettendo di trarre conclusioni più robuste e trasparenti.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/12_two_proportions.html#informazioni-sullambiente-di-sviluppo",
    "title": "72  Confronto tra due proporzioni indipendenti",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] insight_1.3.0     bayestestR_0.16.0 posterior_1.6.1   cmdstanr_0.9.0   \n#&gt;  [5] brms_2.22.0       Rcpp_1.0.14       thematic_0.1.7    MetBrewer_0.2.0  \n#&gt;  [9] ggokabeito_0.1.0  see_0.11.0        gridExtra_2.3     patchwork_1.3.0  \n#&gt; [13] bayesplot_1.13.0  psych_2.5.3       scales_1.4.0      markdown_2.0     \n#&gt; [17] knitr_1.50        lubridate_1.9.4   forcats_1.0.0     stringr_1.5.1    \n#&gt; [21] dplyr_1.1.4       purrr_1.0.4       readr_2.1.5       tidyr_1.3.1      \n#&gt; [25] tibble_3.3.0      ggplot2_3.5.2     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [29] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] mnormt_2.1.1         inline_0.3.21        sandwich_3.1-1      \n#&gt;  [4] rlang_1.1.6          magrittr_2.0.3       multcomp_1.4-28     \n#&gt;  [7] matrixStats_1.5.0    compiler_4.5.0       loo_2.8.0           \n#&gt; [10] vctrs_0.6.5          reshape2_1.4.4       pkgconfig_2.0.3     \n#&gt; [13] fastmap_1.2.0        backports_1.5.0      labeling_0.4.3      \n#&gt; [16] utf8_1.2.6           rmarkdown_2.29       tzdb_0.5.0          \n#&gt; [19] ps_1.9.1             xfun_0.52            jsonlite_2.0.0      \n#&gt; [22] parallel_4.5.0       R6_2.6.1             stringi_1.8.7       \n#&gt; [25] RColorBrewer_1.1-3   StanHeaders_2.32.10  estimability_1.5.1  \n#&gt; [28] rstan_2.32.7         zoo_1.8-14           pacman_0.5.1        \n#&gt; [31] Matrix_1.7-3         splines_4.5.0        timechange_0.3.0    \n#&gt; [34] tidyselect_1.2.1     rstudioapi_0.17.1    abind_1.4-8         \n#&gt; [37] yaml_2.3.10          codetools_0.2-20     curl_6.3.0          \n#&gt; [40] processx_3.8.6       pkgbuild_1.4.8       lattice_0.22-7      \n#&gt; [43] plyr_1.8.9           withr_3.0.2          bridgesampling_1.1-2\n#&gt; [46] coda_0.19-4.1        evaluate_1.0.4       survival_3.8-3      \n#&gt; [49] RcppParallel_5.1.10  pillar_1.10.2        tensorA_0.36.2.1    \n#&gt; [52] checkmate_2.3.2      stats4_4.5.0         distributional_0.5.0\n#&gt; [55] generics_0.1.4       rprojroot_2.0.4      hms_1.1.3           \n#&gt; [58] rstantools_2.4.0     xtable_1.8-4         glue_1.8.0          \n#&gt; [61] emmeans_1.11.1       tools_4.5.0          data.table_1.17.6   \n#&gt; [64] mvtnorm_1.3-3        grid_4.5.0           QuickJSR_1.8.0      \n#&gt; [67] colorspace_2.1-1     nlme_3.1-168         cli_3.6.5           \n#&gt; [70] Brobdingnag_1.2-9    V8_6.0.4             gtable_0.3.6        \n#&gt; [73] digest_0.6.37        TH.data_1.1-3        htmlwidgets_1.6.4   \n#&gt; [76] farver_2.1.2         htmltools_0.5.8.1    lifecycle_1.0.4     \n#&gt; [79] MASS_7.3-65",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#bibliografia",
    "href": "chapters/linear_models/12_two_proportions.html#bibliografia",
    "title": "72  Confronto tra due proporzioni indipendenti",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBanerjee, A. V., Bhattacharjee, S., Chattopadhyay, R., Duflo, E., Ganimian, A. J., Rajah, K., & Spelke, E. S. (2025). Children’s arithmetic skills do not transfer between applied and academic mathematics. Nature, 1–9.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html",
    "href": "chapters/linear_models/13_poisson_model.html",
    "title": "\n73  Modello di Poisson\n",
    "section": "",
    "text": "73.1 Introduzione\nIn questo capitolo percorriamo l’intero processo che porta dall’idea di contare un evento raro – le sparatorie fatali da parte della polizia statunitense – alla stima del suo tasso medio annuo attraverso un modello di Poisson implementato con il pacchetto brms. Per contestualizzare il fenomeno si suggerisce di leggere l’articolo Racial Disparities in Police Use of Deadly Force Against Unarmed Individuals Persist After Appropriately Benchmarking Shooting Data on Violent Crime Rates (Ross et al., 2021). Non è obbligatorio per seguire il capitolo, ma fornisce lo sfondo sociale e metodologico dei dati che stiamo per analizzare.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#perché-un-modello-di-poisson",
    "href": "chapters/linear_models/13_poisson_model.html#perché-un-modello-di-poisson",
    "title": "\n73  Modello di Poisson\n",
    "section": "\n73.2 Perché un modello di Poisson?",
    "text": "73.2 Perché un modello di Poisson?\nQuando il fenomeno di interesse è un conteggio – per esempio il numero di incidenti, diagnosi o, come nel nostro caso, sparatorie in un anno – la distribuzione di Poisson è spesso una scelta naturale. Questa distribuzione è definita da un solo parametro, \\(\\lambda\\), che rappresenta la media (e varianza) del conteggio. In altre parole, se conosci \\(\\lambda\\) conosci già la forma completa della distribuzione.\nPer non appesantire la lettura ricordiamo qui solo l’essenziale: se \\(Y\\) è il numero di eventi osservati in un certo intervallo di tempo, dire che\n\\[\nY \\sim \\text{Poisson}(\\lambda)\n\\]\nsignifica che la probabilità di osservare esattamente \\(k\\) eventi è\n\\[\nP(Y = k) = \\frac{e^{-\\lambda}\\, \\lambda^{k}}{k!}, \\quad k = 0,1,2,\\dots\n\\]",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#come-brms-codifica-lambda",
    "href": "chapters/linear_models/13_poisson_model.html#come-brms-codifica-lambda",
    "title": "\n73  Modello di Poisson\n",
    "section": "\n73.3 Come brms codifica \\(\\lambda\\)\n",
    "text": "73.3 Come brms codifica \\(\\lambda\\)\n\nIl pacchetto brms, così come la maggior parte dei software di regressione, non stima \\(\\lambda\\) direttamente. Per garantire che il tasso rimanga positivo adotta un link logaritmico: all’interno del modello viene quindi stimata la quantità\n\\[\n\\eta = \\log(\\lambda).\n\\]\nNel caso più semplice, senza predittori, brms utilizza un solo coefficiente, l’intercetta b_Intercept, che è proprio l’equivalente di \\(\\eta\\). Una volta ottenuti i campioni posteriori di b_Intercept è sufficiente applicare l’esponenziale per tornare sul piano di \\(\\lambda\\):\nlambda &lt;- exp(b_Intercept)  # trasforma log-lambda in lambda\nOgni volta che in questo capitolo nomineremo “campioni di \\(\\lambda\\)” sottintenderemo che abbiamo già eseguito questa trasformazione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#la-domanda-di-ricerca",
    "href": "chapters/linear_models/13_poisson_model.html#la-domanda-di-ricerca",
    "title": "\n73  Modello di Poisson\n",
    "section": "\n73.4 La domanda di ricerca",
    "text": "73.4 La domanda di ricerca\nGrazie all’archivio pubblico del Washington Post disponiamo di tutti i casi di sparatorie fatali accadute negli Stati Uniti dal 2015 in poi. L’interesse è stimare quante se ne verificano in media in un anno e descrivere l’incertezza associata a tale stima.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#importiamo-e-prepariamo-i-dati",
    "href": "chapters/linear_models/13_poisson_model.html#importiamo-e-prepariamo-i-dati",
    "title": "\n73  Modello di Poisson\n",
    "section": "\n73.5 Importiamo e prepariamo i dati",
    "text": "73.5 Importiamo e prepariamo i dati\n\nurl &lt;- \"https://raw.githubusercontent.com/washingtonpost/data-police-shootings/master/v2/fatal-police-shootings-data.csv\"\nraw &lt;- read.csv(url, stringsAsFactors = FALSE)\nraw$date &lt;- as.Date(raw$date)\nraw$year &lt;- lubridate::year(raw$date)\n\n# Escludiamo il 2025 perché l’anno è ancora in corso e i dati sarebbero incompleti\nshootings &lt;- subset(raw, year &lt; 2025)\n\ndf &lt;- shootings %&gt;%\n  dplyr::count(year, name = \"events\")\n\n\nhead(df)\n#&gt;   year events\n#&gt; 1 2015    995\n#&gt; 2 2016    959\n#&gt; 3 2017    984\n#&gt; 4 2018    992\n#&gt; 5 2019    993\n#&gt; 6 2020   1021\n\nA questo punto abbiamo una tabella df con due colonne: year, che va dal 2015 al 2024, ed events, che contiene il numero di sparatorie registrate in ciascun anno.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#specificare-la-distribuzione-a-priori",
    "href": "chapters/linear_models/13_poisson_model.html#specificare-la-distribuzione-a-priori",
    "title": "\n73  Modello di Poisson\n",
    "section": "\n73.6 Specificare la Distribuzione a Priori",
    "text": "73.6 Specificare la Distribuzione a Priori\nPrima di osservare i dati vogliamo dichiarare che, secondo la nostra conoscenza precedente, un intervallo plausibile per \\(\\lambda\\) va grosso modo da 400 a 900 casi l’anno, con media attorno a 600. Per ottenere una distribuzione lognormale con queste caratteristiche possiamo lavorare sulla scala logaritmica e scegliere normal(6.4, 0.3). Il valore 6.4 è infatti il logaritmo naturale di 600; la deviazione 0.3 produce l’ampiezza desiderata dell’intervallo. In brms la specifica è molto compatta:\n\nprior_lambda &lt;- prior(normal(6.4, 0.3), class = \"Intercept\")",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#adattare-il-modello-in-brms",
    "href": "chapters/linear_models/13_poisson_model.html#adattare-il-modello-in-brms",
    "title": "\n73  Modello di Poisson\n",
    "section": "\n73.7 Adattare il modello in brms\n",
    "text": "73.7 Adattare il modello in brms\n\nIl cuore dell’analisi si riduce a poche righe, perché il linguaggio di brms è pensato per assomigliare alla formula syntax di lm:\n\nm0 &lt;- brm(\n  events ~ 1,                  # ~1 indica solo l’intercetta\n  family = poisson(),          # distribuzione di errore\n  data   = df,\n  prior  = prior_lambda,\n  iter   = 3000,\n  warmup = 1000,\n  chains = 4,\n  seed   = 123,\n  backend = \"cmdstanr\"\n)\n\nIl comando produce più di quattromila campioni posteriori (\\(1000\\) di warm‑up per ciascuna delle quattro catene + \\(2000\\) validi) dell’intercetta logaritmica. Le diagnosi di convergenza – \\(\\hat R\\) vicino a 1, effective sample size buona – sono riportate da summary(m0).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#dalla-scala-log-a-lambda",
    "href": "chapters/linear_models/13_poisson_model.html#dalla-scala-log-a-lambda",
    "title": "\n73  Modello di Poisson\n",
    "section": "\n73.8 Dalla scala log a \\(\\lambda\\)\n",
    "text": "73.8 Dalla scala log a \\(\\lambda\\)\n\nPer passare dalla stima di b_Intercept alla stima di \\(\\lambda\\) basta eseguire l’esponenziale sui campioni posteriori. Usando tidybayes l’operazione è quasi in linguaggio naturale:\n\nposterior_lambda &lt;- m0 |&gt;\n  spread_draws(b_Intercept) |&gt;\n  mutate(lambda = exp(b_Intercept))\n\nposterior_lambda |&gt;\n  median_qi(lambda, .width = 0.94)\n#&gt; # A tibble: 1 × 6\n#&gt;   lambda .lower .upper .width .point .interval\n#&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    \n#&gt; 1  1043.  1023.  1062.   0.94 median qi\n\nL’output ci dice che il valore più credibile di \\(\\lambda\\) è intorno a 1043 casi l’anno, con un intervallo di credibilità al 94 % che va all’incirca da 1023 a 1062.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#visualizzare-la-distribuzione-a-posteriori",
    "href": "chapters/linear_models/13_poisson_model.html#visualizzare-la-distribuzione-a-posteriori",
    "title": "\n73  Modello di Poisson\n",
    "section": "\n73.9 Visualizzare la distribuzione a posteriori",
    "text": "73.9 Visualizzare la distribuzione a posteriori\nUn grafico spesso vale più di mille numeri. Con ggplot2 e il tema che abbiamo impostato all’inizio la figura è pronta in tre righe:\n\nposterior_lambda |&gt;\n  ggplot(aes(x = lambda)) +\n  stat_halfeye(fill = \"skyblue\", alpha = 0.6) +\n  labs(\n    title = \"Distribuzione a posteriori del tasso λ\",\n    x = \"Tasso annuo di sparatorie fatali (λ)\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\nL’area più scura al centro dell’half‑eye mette in evidenza l’intervallo più denso del 50 %; l’intera “pena” laterale dell’arco rappresenta invece il 94 %.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#unestensione-confronto-tra-gruppi",
    "href": "chapters/linear_models/13_poisson_model.html#unestensione-confronto-tra-gruppi",
    "title": "\n73  Modello di Poisson\n",
    "section": "\n73.10 Un’estensione: confronto tra gruppi",
    "text": "73.10 Un’estensione: confronto tra gruppi\nFinora abbiamo trattato tutte le sparatorie fatali come se provenissero da un’unica popolazione. Una domanda molto concreta, invece, è se il tasso di vittime disarmate differisce tra persone classificate come bianche (codice W nel dataset) e tutte le altre. Per rispondere ci basta duplicare lo schema già usato: al posto di un solo tasso medio (λ) ne stimiamo due, uno per ciascun gruppo.\n\n73.10.1 Costruire il dataset\nIl primo passo è filtrare le righe che ci interessano (vittime disarmate) e poi contare, per ogni anno, quante di queste vittime appartengono a ciascun gruppo. Il codice qui sotto svolge tutto il lavoro di preparazione in un’unica catena di operazioni:\n\nurl &lt;- \"https://raw.githubusercontent.com/washingtonpost/data-police-shootings/master/v2/fatal-police-shootings-data.csv\"\n\ndf_groups &lt;- read.csv(url, stringsAsFactors = FALSE) |&gt;\n  dplyr::mutate(\n    date  = as.Date(date),\n    year  = lubridate::year(date),\n    group = dplyr::if_else(race == \"W\", \"White\", \"NonWhite\")\n  ) |&gt;\n  dplyr::filter(year &lt; 2025, armed_with == \"unarmed\") |&gt;\n  dplyr::count(year, group, name = \"events\")\n\nIn df_groups ogni riga è l’abbinamento tra un anno e un gruppo, con il relativo conteggio di vittime disarmate.\n\n73.10.2 Specificare il modello\nLa formula events ~ 0 + group dice a brms di rinunciare a un’intercetta comune e di stimarne una diversa per ogni valore di group. Poiché l’intercetta è, in scala logaritmica, il nostro parametro centrale, otteniamo due log‑tassi distinti.\nPer la prior partiamo dall’idea che, in ciascun gruppo, potremmo aspettarci circa trenta vittime disarmate l’anno ma con incertezza ampia. Lavorando nella scala log questo si traduce in una distribuzione Normale con media 3.4 e deviazione 0.3 applicata indistintamente alle due intercette:\n\nprior_race &lt;- prior(normal(3.4, 0.3), class = \"b\")\n\nIl modello completo è ora immediato:\n\nm_groups &lt;- brm(\n  events ~ 0 + group,\n  family  = poisson(),\n  data    = df_groups,\n  prior   = prior_race,\n  iter    = 3000, warmup = 1000, chains = 4,\n  backend = \"cmdstanr\", seed = 123\n)\n\n\n73.10.3 Dal log‑tasso al tasso annuale\nDopo aver controllato che tutti gli indicatori di convergenza (in particolare R‑hat) siano a posto, trasformiamo i campioni posteriori con l’esponenziale così da tornare alla scala dei tassi veri e propri:\n\npost &lt;- as_draws_df(m_groups) |&gt;\n  dplyr::transmute(\n    lambda_White    = exp(b_groupWhite),\n    lambda_NonWhite = exp(b_groupNonWhite),\n    diff_lambda     = lambda_NonWhite - lambda_White\n  )\n\nCon tidybayes riassumiamo in una riga le quantità d’interesse, usando ad esempio un intervallo di credibilità al 94 %:\n\npost |&gt;\n  median_qi(lambda_White, lambda_NonWhite, diff_lambda, .width = 0.94)\n#&gt; # A tibble: 1 × 12\n#&gt;   lambda_White lambda_White.lower lambda_White.upper lambda_NonWhite\n#&gt;          &lt;dbl&gt;              &lt;dbl&gt;              &lt;dbl&gt;           &lt;dbl&gt;\n#&gt; 1         22.5               19.9               25.4            34.1\n#&gt;   lambda_NonWhite.lower lambda_NonWhite.upper diff_lambda diff_lambda.lower\n#&gt;                   &lt;dbl&gt;                 &lt;dbl&gt;       &lt;dbl&gt;             &lt;dbl&gt;\n#&gt; 1                  30.9                  37.6        11.6              7.21\n#&gt;   diff_lambda.upper .width .point .interval\n#&gt;               &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    \n#&gt; 1              16.0   0.94 median qi\n\nNe risulta che il gruppo NonWhite registra in media circa 12 vittime disarmate in più l’anno rispetto al gruppo White; l’intero intervallo di credibilità rimane sopra lo zero, perciò l’ipotesi di un tasso maggiore fra le persone non bianche è fortemente supportata dai dati.\nCon due soli cambiamenti – la variabile group nella formula e una prior ragionevole per ciascun gruppo – abbiamo esteso il modello di Poisson a una comparazione fra categorie. Tutto il resto resta identico: link logaritmico, diagnostica delle catene, trasformazione a valle dei campioni. Una volta compreso questo meccanismo, aggiungere ulteriori gruppi o predittori diventa un esercizio di routine.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#riflessioni-conclusive",
    "href": "chapters/linear_models/13_poisson_model.html#riflessioni-conclusive",
    "title": "\n73  Modello di Poisson\n",
    "section": "\n73.11 Riflessioni Conclusive",
    "text": "73.11 Riflessioni Conclusive\nIl modello di Poisson con prior informativa e link logaritmico è un punto di partenza potente e relativamente semplice per modellare conteggi. L’implementazione in brms riduce la complessità sintattica al minimo, ma non per questo dobbiamo tralasciare di capire cosa accade dietro le quinte:\n\n\n\\(\\lambda\\) è il vero protagonista, ma viene stimato indirettamente tramite la sua trasformazione logaritmica.\nLa scelta della prior su b_Intercept va fatta nella scala log, pensando però a cosa significa nella scala originale.\nUna volta compreso il passaggio dall’intercetta logaritmica al tasso \\(\\lambda\\), è possibile arricchire il modello con più predittori, sapendo esattamente come trasformare il modello.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#esercizi",
    "href": "chapters/linear_models/13_poisson_model.html#esercizi",
    "title": "\n73  Modello di Poisson\n",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nNella finale olimpica di calcio 2024, la Spagna ha sconfitto la Francia per 5 a 3. Supponiamo di voler calcolare la probabilità di superiorità della Spagna rispetto alla Francia utilizzando un modello coniugato Gamma-Poisson (o l’approssimazione brms con prior lognormale).\n\nConsidera che il numero di gol segnati da una squadra segua una Poisson con parametro \\(\\lambda\\).\n\nSpecifica un prior su \\(\\lambda\\) per entrambe le squadre, ad esempio \\(\\alpha=1\\) e \\(\\beta=1\\) nella parametrizzazione Gamma classica (oppure una Normal(0,1.4) sull’intercetta, in modo da avere una media a posteriori analoga).\n\nAggiorna la distribuzione a posteriori conoscendo i gol segnati (5 per la Spagna e 3 per la Francia in una singola partita).\n\nCalcola la probabilità che \\(\\lambda_{\\text{Spagna}} &gt; \\lambda_{\\text{Francia}}\\).\n\n(Ispirato a “The World Cup Problem”, (Downey, 2021).)\nSuggerimento: puoi risolvere il problema in modo analitico (Gamma-Poisson con un solo conteggio) oppure puoi usare brms costruendo un dataframe:\n\ndf_soccer &lt;- data.frame(\n  team = c(\"Spain\", \"France\"),\n  goals = c(5, 3)\n)\n\n\nModello: goals ~ 0 + team, family=poisson().\nPrior su b_teamSpain e b_teamFrance.\nInfine, estrai i draws e calcola la probabilità \\(\\Pr(\\exp(b_{\\text{Spain}}) &gt; \\exp(b_{\\text{France}}))\\).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/13_poisson_model.html#informazioni-sullambiente-di-sviluppo",
    "title": "\n73  Modello di Poisson\n",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] tidybayes_3.0.7  brms_2.22.0      Rcpp_1.0.14      HDInterval_0.2.4\n#&gt;  [5] thematic_0.1.7   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [9] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.13.0 psych_2.5.3     \n#&gt; [13] scales_1.4.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [17] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [21] readr_2.1.5      tidyr_1.3.1      tibble_3.3.0     ggplot2_3.5.2   \n#&gt; [25] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] mnormt_2.1.1         inline_0.3.21        sandwich_3.1-1      \n#&gt;  [4] rlang_1.1.6          magrittr_2.0.3       multcomp_1.4-28     \n#&gt;  [7] matrixStats_1.5.0    compiler_4.5.0       loo_2.8.0           \n#&gt; [10] vctrs_0.6.5          pkgconfig_2.0.3      arrayhelpers_1.1-0  \n#&gt; [13] fastmap_1.2.0        backports_1.5.0      labeling_0.4.3      \n#&gt; [16] utf8_1.2.6           cmdstanr_0.9.0       rmarkdown_2.29      \n#&gt; [19] tzdb_0.5.0           ps_1.9.1             xfun_0.52           \n#&gt; [22] jsonlite_2.0.0       parallel_4.5.0       R6_2.6.1            \n#&gt; [25] stringi_1.8.7        RColorBrewer_1.1-3   StanHeaders_2.32.10 \n#&gt; [28] estimability_1.5.1   rstan_2.32.7         zoo_1.8-14          \n#&gt; [31] pacman_0.5.1         Matrix_1.7-3         splines_4.5.0       \n#&gt; [34] timechange_0.3.0     tidyselect_1.2.1     rstudioapi_0.17.1   \n#&gt; [37] abind_1.4-8          yaml_2.3.10          codetools_0.2-20    \n#&gt; [40] curl_6.3.0           processx_3.8.6       pkgbuild_1.4.8      \n#&gt; [43] lattice_0.22-7       withr_3.0.2          bridgesampling_1.1-2\n#&gt; [46] posterior_1.6.1      coda_0.19-4.1        evaluate_1.0.4      \n#&gt; [49] survival_3.8-3       RcppParallel_5.1.10  ggdist_3.3.3        \n#&gt; [52] pillar_1.10.2        tensorA_0.36.2.1     checkmate_2.3.2     \n#&gt; [55] stats4_4.5.0         distributional_0.5.0 generics_0.1.4      \n#&gt; [58] rprojroot_2.0.4      hms_1.1.3            rstantools_2.4.0    \n#&gt; [61] xtable_1.8-4         glue_1.8.0           emmeans_1.11.1      \n#&gt; [64] tools_4.5.0          data.table_1.17.6    mvtnorm_1.3-3       \n#&gt; [67] grid_4.5.0           QuickJSR_1.8.0       colorspace_2.1-1    \n#&gt; [70] nlme_3.1-168         cli_3.6.5            svUnit_1.0.6        \n#&gt; [73] Brobdingnag_1.2-9    V8_6.0.4             gtable_0.3.6        \n#&gt; [76] digest_0.6.37        TH.data_1.1-3        htmlwidgets_1.6.4   \n#&gt; [79] farver_2.1.2         htmltools_0.5.8.1    lifecycle_1.0.4     \n#&gt; [82] MASS_7.3-65",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#bibliografia",
    "href": "chapters/linear_models/13_poisson_model.html#bibliografia",
    "title": "\n73  Modello di Poisson\n",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nDowney, A. B. (2021). Think Bayes. \" O’Reilly Media, Inc.\".\n\n\nRoss, C. T., Winterhalder, B., & McElreath, R. (2021). Racial disparities in police use of deadly force against unarmed individuals persist after appropriately benchmarking shooting data on violent crime rates. Social Psychological and Personality Science, 12(3), 323–332.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/glm/introduction_glm.html",
    "href": "chapters/glm/introduction_glm.html",
    "title": "Introduzione",
    "section": "",
    "text": "In questa sezione esploreremo i modelli statistici che vanno oltre la regressione lineare, ossia quelli che fanno ipotesi distributive non gaussiane per la componente stocastica del modello, considerano una relazione non lineare tra il valore atteso della variabile di risposta e i predittori, e indeboliscono l’assunzione di indipendenza tra le osservazioni.",
    "crumbs": [
      "GLM",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html",
    "href": "chapters/glm/03_stan_logistic_regr.html",
    "title": "74  Regressione logistica con Stan",
    "section": "",
    "text": "Introduzione\nIn questo capitolo, approfondiremo la regressione logistica bivariata, un modello statistico che ci consente di analizzare le relazioni tra una variabile di esito binaria e una singola variabile indipendente. Esploreremo il processo di stima dei coefficienti del modello attraverso un approccio bayesiano e forniremo un’interpretazione dei risultati ottenuti. Mostreremo come i coefficienti influenzano la probabilità di successo della variabile binaria di esito, nonché come interpretare il loro segno e ampiezza.\nLa presente trattazione ricalca, in parte, quella fornita da Fox (2015), adattandola a nuovi contesti applicativi. Per una trattazione più ampia dei fondamenti teorici, si consenta la consultazione del suddetto riferimento.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#introduzione",
    "href": "chapters/glm/03_stan_logistic_regr.html#introduzione",
    "title": "74  Regressione logistica con Stan",
    "section": "",
    "text": "La regressione logistica è un modello additivo utilizzato per dati binari, ossia dati \\(y\\) che assumono valori 0 o 1. Per modellare i dati binari, dobbiamo aggiungere due caratteristiche al modello base \\(y = a + bx\\): una trasformazione non lineare che vincola l’output tra 0 e 1 (a differenza di \\(a + bx\\), che è illimitato), e un metodo per interpretare i numeri risultanti come probabilità che un evento si verifichi.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#modello-di-regressione-logistica-per-variabili-binarie",
    "href": "chapters/glm/03_stan_logistic_regr.html#modello-di-regressione-logistica-per-variabili-binarie",
    "title": "74  Regressione logistica con Stan",
    "section": "\n74.1 Modello di regressione logistica per variabili binarie",
    "text": "74.1 Modello di regressione logistica per variabili binarie\nIl modello di regressione logistica è utilizzato per analizzare la relazione tra una variabile dipendente dicotomica, che assume i valori di “successo” e “fallimento”, e una o più variabili indipendenti, che possono essere sia quantitative che qualitative. Qui ci concentreremo sul caso di una sola variabile indipendente.\nConsideriamo \\(n\\) osservazioni i.i.d., dove \\(Y_i\\) indica l’osservazione \\(i\\)-esima della variabile risposta, per \\(i=1, \\dots, n\\). Ogni osservazione è associata a un vettore di variabili esplicative \\((x_1, \\dots, x_p)\\). La relazione che vogliamo esaminare è tra la probabilità di successo \\(\\pi_i\\) e la variabile esplicativa, espressa dalla formula:\n\\[\nP(Y=1 \\mid X=x_i) = \\pi_i.\n\\]\nIn questo contesto, la variabile dipendente \\(Y\\) segue una distribuzione di Bernoulli, con i seguenti possibili valori:\n\\[\ny_i =\n\\begin{cases}\n    1 & \\text{per un successo (per l'osservazione $i$-esima)},\\\\\n    0 & \\text{per un fallimento}.\n\\end{cases}\n\\]\nLe probabilità associate a questi valori sono rispettivamente \\(\\pi\\) per il successo e \\(1-\\pi\\) per il fallimento:\n\\[\n\\begin{aligned}\n    P(Y_i = 1) &= \\pi,\\\\\n    P(Y_i = 0) &= 1-\\pi.\n\\end{aligned}\n\\]\nQuesto modello permette di studiare come le variabili esplicative influenzino la probabilità di un evento binario, come il successo o il fallimento.\nLa media condizionata \\(\\mathbb{E}(Y \\mid X=x)\\) in una popolazione può essere vista come la proporzione di valori 1 per un dato punteggio \\(x\\) sulla variabile esplicativa, ovvero la probabilità condizionata \\(\\pi_i\\) di osservare l’esito \\(Y = 1\\) in corrispondenza di un certo livello \\(X\\):\n\\[\n\\pi_i \\equiv P(Y = 1 \\mid X = x).\n\\]\nIl valore atteso diventa:\n\\[\n\\mathbb{E}(Y \\mid x) = \\pi_i.\n\\]\nSe \\(X\\) è una variabile discreta, possiamo calcolare la proporzione di \\(Y=1\\) per ogni valore di \\(X=x\\) nel campione. Queste proporzioni rappresentano una stima non parametrica della funzione di regressione di \\(Y\\) su \\(X\\), e possono essere stimate tramite tecniche di smoothing.\nPer valori bassi della variabile \\(X\\), la proporzione condizionata di valori \\(Y=1\\) sarà prossima allo 0. Per valori alti di \\(X\\), la proporzione di valori \\(Y=1\\) sarà prossima a 1. A livelli intermedi di \\(X\\), la curva di regressione non parametrica gradualmente approssima i valori 0 e 1 seguendo un andamento sigmoidale.\nPer illustrare, generiamo dei dati simulati con una variabile dicotomica \\(Y\\) e una variabile discreta \\(X\\) nei quali la probabilità che \\(Y=1\\) aumenta con il valore di \\(X\\).\n\n# --- Setup ---------------------------------------------------------------\nset.seed(42)                      # Per riproducibilità\nn &lt;- 1000                         # Numero di osservazioni\nX &lt;- sample(0:9, n, replace = TRUE)  # Predittore discreto con livelli 0..9\n\n# --- Modello logistico e generazione dati -------------------------------\nlogistic &lt;- function(x, beta0, beta1) plogis(beta0 + beta1 * x)\n\nbeta0 &lt;- -2\nbeta1 &lt;- 1                       # Maggiore pendenza\np &lt;- logistic(X, beta0, beta1)   # Probabilità di successo\n\nY &lt;- rbinom(n, size = 1, prob = p)  # Esito dicotomico\n\n# --- Media di successo e SE per ciascun livello di X --------------------\n# SE stimato come sd(Y)/sqrt(n_k); per proporzioni è vicino a sqrt(p*(1-p)/n_k)\ndf &lt;- tibble::tibble(X = X, Y = Y)\n\nsummary_by_X &lt;- df %&gt;%\n  group_by(X) %&gt;%\n  summarise(\n    mean_success_rate = mean(Y),\n    se = sd(Y) / sqrt(dplyr::n()),\n    .groups = \"drop\"\n  )\n\n# (opzionale) Limita le barre d’errore all’intervallo [0, 1]\nsummary_by_X &lt;- summary_by_X %&gt;%\n  mutate(\n    ymin = pmax(0, mean_success_rate - se),\n    ymax = pmin(1, mean_success_rate + se)\n  )\n\n# --- Grafico: punti + barre d’errore + smoother non-parametrico (LOESS) --\nggplot(summary_by_X, aes(x = X, y = mean_success_rate)) +\n  geom_point() +\n  geom_errorbar(aes(ymin = ymin, ymax = ymax), width = 0.1) +\n  geom_smooth(method = \"loess\", span = 0.3, se = FALSE, color = \"red\") +\n  labs(x = \"X\", y = \"Mean Success Rate\") +\n  theme(panel.grid.minor = element_blank())",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#modello-lineare-nelle-probabilità",
    "href": "chapters/glm/03_stan_logistic_regr.html#modello-lineare-nelle-probabilità",
    "title": "74  Regressione logistica con Stan",
    "section": "\n74.2 Modello Lineare nelle Probabilità",
    "text": "74.2 Modello Lineare nelle Probabilità\nPotremmo pensare di usare una funzione lineare per rappresentare la dipendenza di \\(Y\\) da \\(X\\). Introduciamo un modello lineare con le seguenti assunzioni standard:\n\\[\nY_i = \\alpha + \\beta X_i + \\varepsilon_i,\n\\]\ndove \\(\\varepsilon_i\\) segue una distribuzione normale con media 0 e varianza 1 (\\(\\varepsilon_i \\sim \\mathcal{N}(0, 1)\\)) e gli errori \\(\\varepsilon_i\\) e \\(\\varepsilon_j\\) sono indipendenti per ogni \\(i \\neq j\\). Il valore atteso di \\(Y_i\\) è quindi \\(\\mathbb{E}(Y_i) = \\alpha + \\beta X_i\\), portando a:\n\\[\n\\pi_i = \\alpha + \\beta X_i.\n\\]\nQuesto è noto come modello lineare nelle probabilità (linear probability model). Tuttavia, questo approccio presenta una limitazione significativa: non garantisce che i valori predetti di \\(\\pi_i\\) siano confinati nell’intervallo [0,1], come richiesto per le probabilità.\n\n74.2.1 Problemi di normalità\nConsiderando che \\(Y_i\\) può assumere solo i valori 0 o 1, i residui \\(\\varepsilon_i\\) risultano anch’essi dicotomici e quindi non possono seguire una distribuzione normale. Ad esempio, se \\(Y_i=1\\) con probabilità \\(\\pi_i\\), il residuo sarà:\n\\[\n\\varepsilon_i = 1 - \\mathbb{E}(Y_i) = 1 - (\\alpha + \\beta X_i) = 1 - \\pi_i.\n\\]\nSe, invece, \\(Y_i=0\\) con probabilità \\(1-\\pi_i\\), il residuo sarà:\n\\[\n\\varepsilon_i = 0 - \\mathbb{E}(Y_i) = 0 - (\\alpha + \\beta X_i) = - \\pi_i.\n\\]\nTuttavia, se la dimensione del campione è grande, il teorema del limite centrale può mitigare l’importanza dell’assunzione di normalità per le stime dei minimi quadrati.\n\n74.2.2 Problematiche di eteroschedasticità\nUtilizzare il metodo dei minimi quadrati può essere inappropriato in questo contesto poiché la varianza dei residui non è costante ma dipende dalla media, e quindi dalla variabile \\(X\\). Assumendo che il modello sia lineare, abbiamo che \\(\\mathbb{E}(\\varepsilon_i)=0\\). Sfruttando le relazioni discusse in precedenza, la varianza dei residui si calcola come:\n\\[\n\\mathbb{V}(\\varepsilon_i) = (1-\\pi_i)\\pi_i.\n\\]\nConsideriamo che la varianza dei residui \\(\\varepsilon_i\\) può essere espressa come:\n\\[\n\\text{Var}(\\varepsilon_i) = \\mathbb{E}(\\varepsilon_i^2) - \\mathbb{E}(\\varepsilon_i)^2,\n\\]\ndove \\(\\mathbb{E}(\\varepsilon_i^2)\\) è il valore atteso del quadrato dei residui e \\(\\mathbb{E}(\\varepsilon_i)^2\\) è il quadrato del valore atteso dei residui.\nOra calcoliamo \\(\\mathbb{E}(\\varepsilon_i^2)\\):\n\\[\n\\begin{align*}\n\\mathbb{E}(\\varepsilon_i^2) &= \\mathbb{E}[(Y_i - \\mathbb{E}(Y_i))^2] \\\\\n&= \\mathbb{E}[(Y_i - \\pi_i)^2] \\\\\n&= \\mathbb{E}[(Y_i^2 - 2Y_i\\pi_i + \\pi_i^2)] \\\\\n&= \\mathbb{E}(Y_i^2) - 2\\mathbb{E}(Y_i\\pi_i) + \\mathbb{E}(\\pi_i^2) \\\\\n&= \\mathbb{E}(Y_i) - 2\\mathbb{E}(Y_i\\pi_i) + \\pi_i^2 \\\\\n&= \\pi_i - 2\\pi_i^2 + \\pi_i^2 \\\\\n&= \\pi_i - \\pi_i^2 \\\\\n&= \\pi_i(1 - \\pi_i)\n\\end{align*}\n\\]\nOra calcoliamo \\(\\mathbb{E}(\\varepsilon_i)^2\\):\n\\[\n\\begin{align*}\n\\mathbb{E}(\\varepsilon_i)^2 &= (\\mathbb{E}(Y_i - \\mathbb{E}(Y_i)))^2 \\\\\n&= (\\mathbb{E}(Y_i - \\pi_i))^2 \\\\\n&= (0)^2 \\\\\n&= 0\n\\end{align*}\n\\]\nQuindi, sostituendo questi risultati nella formula della varianza dei residui, otteniamo:\n\\[\n\\text{Var}(\\varepsilon_i) = \\mathbb{E}(\\varepsilon_i^2) - \\mathbb{E}(\\varepsilon_i)^2 = \\pi_i(1 - \\pi_i)\n\\]\nQuindi, abbiamo dimostrato che la varianza dei residui nel modello lineare nelle probabilità può essere espressa come \\((1-\\pi_i)\\pi_i\\).\nDato che \\(\\pi_i\\) dipende da \\(x\\), ciò significa che la varianza non è costante in funzione di \\(x\\). Questa eteroschedasticità dei residui rappresenta un problema per le stime dei minimi quadrati nel modello lineare, specialmente quando le probabilità \\(\\pi_i\\) sono vicine a 0 o 1.\n\n74.2.3 Linearità\nIl maggiore inconveniente connesso all’adozione del modello lineare nelle probabilità deriva dal fatto che la stima della probabilità di successo, \\(P(\\hat{Y}_i=1)=\\hat{\\pi}_i\\), non è necessariamente compresa nell’intervallo \\((0,1)\\), ma può essere sia negativa sia maggiore di 1. Nel caso dell’esempio in discussione, ciò significa che la retta dei minimi quadrati produce valori attesi \\(\\hat{\\pi}\\) inferiori a 0 per bassi valori della variabile \\(X\\) e valori \\(\\hat{\\pi}\\) superiori a 1 per valori di \\(X\\) alti.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#modello-lineare-nelle-probabilità-vincolato",
    "href": "chapters/glm/03_stan_logistic_regr.html#modello-lineare-nelle-probabilità-vincolato",
    "title": "74  Regressione logistica con Stan",
    "section": "\n74.3 Modello lineare nelle probabilità vincolato",
    "text": "74.3 Modello lineare nelle probabilità vincolato\nUna soluzione per mantenere \\(\\pi\\) all’interno dell’intervallo (0, 1) è la seguente specificazione del modello:\n\\[\n\\pi=\n\\begin{cases}\n  0                           &\\text{se $\\alpha + \\beta X &lt; 0$},\\\\\n  \\alpha + \\beta X           &\\text{se $0 \\leq \\alpha + \\beta X \\leq 1$},\\\\\n  1 &\\text{se $\\alpha + \\beta X &gt; 1$}.\n\\end{cases}\n\\]\nQuesto modello lineare nelle probabilità vincolato mostra alcune instabilità, soprattutto a causa della sua dipendenza critica dai valori estremi di \\(\\pi\\), dove assume i valori 0 o 1. La linearità di \\(\\pi = \\alpha + \\beta X\\) si basa fortemente sui punti in cui si verificano questi estremi. In particolare, la stima di \\(\\pi = 0\\) può essere influenzata dal valore minimo di \\(X\\) associato a \\(Y=1\\), mentre la stima di \\(\\pi = 1\\) può dipendere dal valore massimo di \\(X\\) per cui \\(Y=0\\). Questi valori estremi tendono a variare significativamente tra diversi campioni e possono diventare più estremi all’aumentare della dimensione del campione.\nLa presenza di più variabili esplicative (\\(k \\geq 2\\)) complica ulteriormente la stima dei parametri del modello. Inoltre, il modello mostra un cambiamento brusco nella pendenza della curva di regressione ai punti estremi (0 e 1 di \\(\\pi\\)), risultando poco realistico in molte situazioni pratiche. Questo rende il modello meno adatto a descrivere relazioni complesse e gradualmente variabili tra \\(\\pi\\) e \\(X\\).\nUna funzione che modella una relazione più fluida e continua tra \\(\\pi\\) e \\(X\\) sarebbe più realistica e rappresentativa delle dinamiche osservate. Questo motiva la preferenza per modelli alternativi, come il modello di regressione logistica, che tende a fornire una rappresentazione più accurata e realistica delle interazioni tra variabili dicotomiche e esplicative.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#regressione-logistica",
    "href": "chapters/glm/03_stan_logistic_regr.html#regressione-logistica",
    "title": "74  Regressione logistica con Stan",
    "section": "\n74.4 Regressione logistica",
    "text": "74.4 Regressione logistica\nUn metodo efficace per gestire il problema del vincolo sulle probabilità è specificare modelli non direttamente per le probabilità stesse, ma per una loro trasformazione che elimina tale vincolo. Invece di definire un modello lineare per la probabilità condizionata \\(\\pi_i\\), si può specificare un modello lineare per il logaritmo degli odds (logit):\n\\[\n\\eta_i = \\log_e \\frac{\\pi_i}{1-\\pi_i} = \\alpha + \\beta x_i,\n\\]\nQuesto approccio non presenta problemi poiché il logit \\(\\eta_i\\) è sempre un numero reale, permettendo di modellare una trasformazione lineare di \\(\\pi_i\\). La trasformazione inversa, che ci permette di ottenere \\(\\pi_i\\) da \\(\\eta_i\\), è data dalla funzione logistica:\n\\[\n\\pi_i = \\frac{e^{\\eta_i}}{1 + e^{\\eta_i}} = \\frac{e^{\\alpha + \\beta x_i}}{1 + e^{\\alpha + \\beta x_i}}.\n\\]\n\n74.4.1 Vantaggi della regressione logistica\nLa regressione logistica presenta diversi vantaggi rispetto al modello lineare delle probabilità:\n\n\nVincolo delle Probabilità: La trasformazione logistica assicura che i valori predetti di \\(\\pi_i\\) siano sempre compresi nell’intervallo [0,1].\n\nInterpretabilità degli Odds Ratio: Il coefficiente \\(\\beta\\) può essere interpretato come il cambiamento logaritmico negli odds di successo associato a un incremento unitario di \\(X\\). In altre parole, \\(e^\\beta\\) rappresenta il fattore di aumento (o diminuzione) degli odds per un incremento unitario della variabile indipendente.\n\nGestione dell’Eteroschedasticità: La forma funzionale della varianza del modello di regressione logistica \\(\\pi_i (1 - \\pi_i)\\) è intrinsecamente considerata nel processo di stima tramite il metodo della massima verosimiglianza.\n\n74.4.2 Esempio numerico\nPer illustrare l’applicazione della regressione logistica, consideriamo nuovamente i dati simulati precedentemente. Applichiamo il modello di regressione logistica ai dati e tracciamo la curva logistica risultante:\n\n# Supponiamo che df contenga X e Y (0/1) già generati\n# Calcolo delle medie e degli errori standard\nsummary_by_X &lt;- df %&gt;%\n  group_by(X) %&gt;%\n  summarise(\n    mean_success_rate = mean(Y),\n    se = sd(Y) / sqrt(n()),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(\n    ymin = pmax(0, mean_success_rate - se),\n    ymax = pmin(1, mean_success_rate + se)\n  )\n\n# Modello di regressione logistica\nlogit_model &lt;- glm(Y ~ X, data = df, family = binomial(link = \"logit\"))\n\n# Predizioni su una griglia fine di valori di X\nx_vals &lt;- seq(min(df$X), max(df$X), length.out = 100)\npred_df &lt;- data.frame(X = x_vals)\npred_df$pred &lt;- predict(logit_model, newdata = pred_df, type = \"response\")\n\n# Grafico\nggplot(summary_by_X, aes(x = X, y = mean_success_rate)) +\n  geom_point(color = \"blue\") +\n  geom_errorbar(aes(ymin = ymin, ymax = ymax), width = 0.1, color = \"blue\") +\n  geom_line(data = pred_df, aes(x = X, y = pred), color = \"red\") +\n  labs(x = \"X\", y = \"Mean Success Rate\") +\n  theme(panel.grid.minor = element_blank())\n\n\n\n\n\n\n\nQuesto esempio dimostra come la regressione logistica possa essere utilizzata per modellare una variabile dicotomica in funzione di una variabile indipendente. La curva logistica risultante rappresenta adeguatamente la relazione tra \\(X\\) e la probabilità di successo \\(Y\\), garantendo che i valori predetti di \\(\\pi_i\\) siano sempre compresi nell’intervallo [0,1].\nNelle sezioni seguenti, descriveremo in dettaglio il modello di regressione logistica utilizzato per generare la curva logistica mostrata nella figura precedente. Inizieremo chiarendo i concetti di odds e logit e la loro relazione con le probabilità.\n\n74.4.3 Componente sistematica\nLa componente sistematica mette in relazione un vettore (\\(\\eta_1, \\eta_2, \\dots, \\eta_k\\)) con le variabili esplicative mediante un modello lineare. Sia \\(X_{ij}\\) il valore della \\(j\\)-esima variabile esplicativa (\\(j=1, 2, \\dots, p\\)) per l’\\(i\\)-esima osservazione (\\(i=1, \\dots, k\\)). Allora\n\\[\n\\eta_i = \\sum_j \\beta_j X_{ij}.\n\\]\nQuesta combinazione lineare di variabili esplicative è chiamata il predittore lineare. Un \\(X_{ij}=1, \\forall i\\) viene utilizzato per il coefficiente dell’intercetta del modello (talvolta denotata da \\(\\alpha\\)).\n\n74.4.4 Componente aleatoria\nLa componente aleatoria del modello suppone l’esistenza di \\(k\\) osservazioni indipendenti \\(y_1, y_2, \\dots, y_k\\), ciascuna delle quali viene trattata come la realizzazione di una variabile casuale \\(Y_i\\). Si assume che \\(Y_i\\) abbia una distribuzione binomiale:\n\\[\nY_i \\sim Bin(n_i, \\pi_i)\n\\]\ncon parametri \\(n_i\\) e \\(\\pi_i\\). Per dati individuali (uno per ciascun valore \\(x_i\\)), \\(n_i=1,\n    \\forall i\\).\n\n74.4.5 Funzione legame\nLa funzione legame \\(g(\\cdot)\\) mette in relazione il valore atteso della variabile risposta \\(Y_i\\) con la componente sistematica \\(\\eta_i\\) del modello. Abbiamo visto che \\(\\mathbb{E}(Y_i)=\\pi_i\\). Che relazione c’è tra \\(\\pi_i\\) e il predittore lineare \\(\\eta_i= \\alpha + \\sum_j  \\beta_j X_{ij}\\)? La risposta a questa domanda è data dalla funzione legame:\n\\[\n\\eta_i = g(\\pi_i) = \\ln{\\frac{\\pi_i}{1-\\pi_i}} .\n\\]\nSi noti che la funzione legame non trasforma la variabile risposta \\(Y_i\\) ma bensì il suo valore atteso \\(\\pi_i\\).\nLa funzione legame è invertibile: anziché trasformare il valore atteso nel predittore lineare si può trasformare il predittore lineare nel valore atteso \\(\\pi_i\\):\n\\[\n\\pi_i = \\frac{e^{\\eta_i}}{1+e^{\\eta_i}} =  \\frac{e^{\\alpha + \\sum_j  \\beta_j X_{ij}}}{1+e^{\\alpha + \\sum_j  \\beta_j X_{ij}}}.\n\\]\nSi ottiene così un modello non lineare per le probabilità \\(\\pi_i\\).\nIn conclusione, la regressione logistica estende il concetto di regressione lineare per modellare le probabilità condizionate di esiti Bernoulliani $ Y \\(, adoperando la funzione logistica come collegamento per trasformare relazioni lineari tra predittori (\\) _i = _0 + 1 X{i} $) in probabilità nell’intervallo [0,1]. Questo metodo permette di passare dalla modellazione diretta della probabilità $ p $ alla modellazione di una funzione di tale probabilità attraverso una relazione lineare, impiegando la funzione logit come funzione di collegamento.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#coefficienti-del-modello-nella-regressione-logistica-e-la-loro-interpretazione",
    "href": "chapters/glm/03_stan_logistic_regr.html#coefficienti-del-modello-nella-regressione-logistica-e-la-loro-interpretazione",
    "title": "74  Regressione logistica con Stan",
    "section": "\n74.5 Coefficienti del modello nella regressione logistica e la loro interpretazione",
    "text": "74.5 Coefficienti del modello nella regressione logistica e la loro interpretazione\nUn aspetto cruciale per comprendere la relazione tra le variabili predittive e una variabile di risposta binaria è l’interpretazione dei coefficienti del modello.\n\n74.5.1 Odds Ratio\nIl caso più semplice che consente di interpetare l’odds ratio in una regressione logistica è quando la variabile indipendente (X) è binaria (cioè può assumere solo valori 0 e 1).\nIn una regressione logistica, il modello assume la forma:\n\\[\n\\log \\left( \\frac{P(Y = 1)}{P(Y = 0)} \\right) = \\beta_0 + \\beta_1 X ,\n\\]\ndove:\n\n\n\\(\\log \\left( \\frac{P(Y = 1)}{P(Y = 0)} \\right)\\) è il logaritmo dell’odds che l’evento \\(Y = 1\\) avvenga,\n\n\\(\\beta_0\\) è l’intercetta del modello,\n\n\\(\\beta_1\\) è il coefficiente per la variabile indipendente \\(X\\).\n\n74.5.2 Passo 1: Calcolare gli odds per i due valori di \\(X\\)\n\nQuando \\(X = 0\\), l’equazione diventa:\n\\[\n\\log \\left( \\frac{P(Y = 1 \\mid X = 0)}{P(Y = 0 \\mid X = 0)} \\right) = \\beta_0 .\n\\]\nQuesto significa che l’odds di \\(Y = 1\\) dato che \\(X = 0\\) è:\n\\[\n\\frac{P(Y = 1 \\mid X = 0)}{P(Y = 0 \\mid X = 0)} = e^{\\beta_0} .\n\\]\nAllo stesso modo, quando \\(X = 1\\), l’equazione diventa:\n\\[\n\\log \\left( \\frac{P(Y = 1 \\mid X = 1)}{P(Y = 0 \\mid X = 1)} \\right) = \\beta_0 + \\beta_1 .\n\\]\nQuindi, l’odds di \\(Y = 1\\) dato che \\(X = 1\\) è:\n\\[\n\\frac{P(Y = 1 \\mid X = 1)}{P(Y = 0 \\mid X = 1)} = e^{\\beta_0 + \\beta_1} .\n\\]\n\n74.5.3 Passo 2: Calcolare l’Odds Ratio\nL’odds ratio è il rapporto tra gli odds quando \\(X = 1\\) e quando \\(X = 0\\):\n\\[\n\\text{Odds Ratio} = \\frac{\\frac{P(Y = 1 \\mid X = 1)}{P(Y = 0 \\mid X = 1)}}{\\frac{P(Y = 1 \\mid X = 0)}{P(Y = 0 \\mid X = 0)}} = \\frac{e^{\\beta_0 + \\beta_1}}{e^{\\beta_0}}.\n\\]\nSemplificando, otteniamo:\n\\[\n\\text{Odds Ratio} = e^{\\beta_1} .\n\\]\n\n74.5.4 Interpretazione dell’Odds Ratio\nL’odds ratio \\(e^{\\beta_1}\\) rappresenta il cambiamento relativo negli odds di \\(Y = 1\\) per un aumento di una unità di \\(X\\) (in questo caso, il passaggio da \\(X = 0\\) a \\(X = 1\\)).\nSe \\(\\beta_1\\) è:\n\n\nMaggiore di zero (\\(e^{\\beta_1} &gt; 1\\)): l’odds di \\(Y = 1\\) aumenta quando \\(X\\) passa da 0 a 1.\n\nMinore di zero (\\(e^{\\beta_1} &lt; 1\\)): l’odds di \\(Y = 1\\) diminuisce quando \\(X\\) passa da 0 a 1.\n\nUguale a zero (\\(e^{\\beta_1} = 1\\)): l’odds di \\(Y = 1\\) non cambia in base ai valori di \\(X\\).\n\nIn sintesi, l’odds ratio \\(e^{\\beta_1}\\) fornisce una misura dell’associazione tra la variabile binaria \\(X\\) e la probabilità dell’evento \\(Y = 1\\), rappresentando il moltiplicatore degli odds nel caso in cui \\(X\\) passi da 0 a 1.\n\n74.5.5 Interpretazione sui Logit\nNella regressione logistica, ogni coefficiente \\(\\beta_j\\) del modello può essere interpretato direttamente in termini di log-odds, che sono i logaritmi delle probabilità di ottenere un evento con esito positivo (\\(y=1\\)). Quando interpretiamo i coefficienti:\n\nCoefficienti Positivi (\\(\\beta_j &gt; 0\\)): Un coefficiente positivo indica che c’è una relazione diretta tra il predittore e l’aumento dei log-odds di osservare l’evento di interesse. Questo significa che all’aumentare del valore del predittore, la probabilità dell’evento di interesse aumenta.\nCoefficienti Negativi (\\(\\beta_j &lt; 0\\)): Al contrario, un coefficiente negativo indica una relazione inversa tra il predittore e la probabilità logistica dell’evento. Con l’aumentare del predittore, i log-odds e quindi la probabilità dell’evento diminuiscono.\n\n74.5.6 Interpretazione sugli Odds Ratio (OR)\nL’interpretazione dei coefficienti nella regressione logistica può estendersi agli odds ratio (OR), che forniscono informazioni sulla relazione tra i predittori e la probabilità dell’evento di interesse. Per esempio, consideriamo un modello con un predittore continuo \\(X\\) e un coefficiente \\(\\beta_1 = 0.50\\). Il logaritmo naturale dell’odds ratio, \\(\\log(OR) = 0.50\\), viene esponenziato per ottenere:\n\\[\nOR = e^{0.50} \\approx 1.65.\n\\]\nQuesto risultato indica che per un’unità di incremento in \\(X\\), l’odds di sperimentare l’evento di interesse è circa 1.65 volte maggiore. In altre parole, l’incremento di una unità nel predittore \\(X\\) aumenta l’odds di sperimentare l’evento di interesse di circa il 65%. Viceversa, un coefficiente negativo indicherebbe una diminuzione dell’odds per un incremento di una unità in \\(X\\).\n\n74.5.7 Interpretazione sulla Scala delle Probabilità\nLa regressione logistica consente di interpretare i coefficienti non solo in termini di log-odds, ma anche relativamente alle variazioni di probabilità. Consideriamo un modello che predice la probabilità di superare un esame basandosi sul numero di ore di studio (\\(X\\)).\nSupponiamo che il coefficiente associato alle ore di studio sia \\(\\beta_1 = 0.5\\). Questo valore indica che ogni ora aggiuntiva di studio incrementa i log-odds di successo nell’esame. Per comprendere l’impatto di un’ora in più di studio sulla probabilità di successo, possiamo utilizzare la seguente formula:\n\\[\n\\Delta p = \\frac{1}{1 + e^{-(\\beta_0 + 0.5 \\cdot (X_1 + 1))}} - \\frac{1}{1 + e^{-(\\beta_0 + 0.5 \\cdot X_1)}}.\n\\]\nQuesta formula calcola la differenza tra la probabilità di successo dopo aver aggiunto un’ora di studio e la probabilità di successo prima di tale aggiunta. In termini pratici, \\(\\Delta p\\) rappresenta l’incremento della probabilità di superare l’esame attribuibile a un’ora supplementare di studio. Questa interpretazione è cruciale per valutare quantitativamente l’effetto delle ore di studio sulla probabilità di superare l’esame.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#un-esempio-numerico",
    "href": "chapters/glm/03_stan_logistic_regr.html#un-esempio-numerico",
    "title": "74  Regressione logistica con Stan",
    "section": "\n74.6 Un esempio numerico",
    "text": "74.6 Un esempio numerico\nConsideriamo nuovamente i dati simulati in precedenza\n\nhead(df)\n#&gt; # A tibble: 6 × 2\n#&gt;       X     Y\n#&gt;   &lt;int&gt; &lt;int&gt;\n#&gt; 1     0     0\n#&gt; 2     4     1\n#&gt; 3     0     0\n#&gt; 4     8     1\n#&gt; 5     9     1\n#&gt; 6     3     0\n\nStimeremo ora i coefficienti del modello di regressione logistica usando Stan. Definiamo i dati nel formato atteso da Stan:\n\nstan_data &lt;- list(\n  N = nrow(df),\n  y = df$Y,\n  x = df$X\n)\n\nCompiliamo il modello di regressione logistica e stampiamo lo script Stan:\n\n# Costruisci il path al file Stan\nstan_file &lt;- file.path(here::here(\"stan\", \"logistic_regression.stan\"))\n# Compila il modello Stan\nmodel &lt;- cmdstan_model(stan_file)\n# Stampa il codice Stan\ncat(readLines(stan_file), sep = \"\\n\")\n#&gt; data {\n#&gt;   int&lt;lower=0&gt; N;\n#&gt;   vector[N] x;\n#&gt;   array[N] int&lt;lower=0, upper=1&gt; y;\n#&gt; }\n#&gt; parameters {\n#&gt;   real alpha;\n#&gt;   real beta;\n#&gt; }\n#&gt; model {\n#&gt;   y ~ bernoulli_logit(alpha + beta * x);\n#&gt; }\n\nEseguiamo il campionamento MCMC:\n\nfit &lt;- model$sample(\n  data = stan_data,\n  iter_warmup = 1000,\n  iter_sampling = 2000,\n  seed = 123,\n  refresh = 0          # 0 = non mostrare progress bar\n)\n\nEsaminiamo le tracce:\n\n# Estrai i draw posteriori come array\nposterior_array &lt;- fit$draws()\n\n\nmcmc_trace(posterior_array, pars = c(\"alpha\", \"beta\"))\n\n\n\n\n\n\n\nOtteniamo le stime a posteriori dei parametri:\n\nfit$summary(variables = c(\"alpha\", \"beta\"))\n#&gt; # A tibble: 2 × 10\n#&gt;   variable  mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 alpha    -1.73  -1.73  0.17  0.17 -2.02 -1.45  1.00  2394.45  2658.68\n#&gt; 2 beta      0.90   0.90  0.06  0.06  0.80  1.01  1.00  2390.48  2555.30\n\nCreiamo un nuovo DataFrame con 100 valori \\(x\\) nell’intervallo [0, 9]:\n\nnew_data &lt;- data.frame(\n  x = seq(0, 9, length.out = 100)\n)\nnew_data |&gt; head()\n#&gt;         x\n#&gt; 1 0.00000\n#&gt; 2 0.09091\n#&gt; 3 0.18182\n#&gt; 4 0.27273\n#&gt; 5 0.36364\n#&gt; 6 0.45455\n\nOtteniamo le medie a posteriori dei parametri \\(\\alpha\\) e \\(\\beta\\):\n\nalpha &lt;- mean(fit$draws(\"alpha\"))\nbeta  &lt;- mean(fit$draws(\"beta\"))\n\nprint(alpha)\n#&gt; [1] -1.732\nprint(beta)\n#&gt; [1] 0.905\n\nCalcoliamo i logit per ogni valore \\(x\\) nel dataset new_data utilizzando le stime a posteriori dei parametri \\(\\alpha\\) e \\(\\beta\\) ottenute dal modello di regressione logistica. Nel modello di regressione logistica, il logit della probabilità è una funzione lineare di \\(x\\):\n\\[\n\\log \\left( \\frac{p}{1-p} \\right) = \\alpha + \\beta x\n\\]\n\nlogit_p = alpha + new_data$x * beta\nlogit_p\n#&gt;   [1] -1.732313 -1.650044 -1.567776 -1.485508 -1.403239 -1.320971 -1.238702\n#&gt;   [8] -1.156434 -1.074166 -0.991897 -0.909629 -0.827361 -0.745092 -0.662824\n#&gt;  [15] -0.580555 -0.498287 -0.416019 -0.333750 -0.251482 -0.169213 -0.086945\n#&gt;  [22] -0.004677  0.077592  0.159860  0.242128  0.324397  0.406665  0.488934\n#&gt;  [29]  0.571202  0.653470  0.735739  0.818007  0.900275  0.982544  1.064812\n#&gt;  [36]  1.147081  1.229349  1.311617  1.393886  1.476154  1.558423  1.640691\n#&gt;  [43]  1.722959  1.805228  1.887496  1.969764  2.052033  2.134301  2.216570\n#&gt;  [50]  2.298838  2.381106  2.463375  2.545643  2.627911  2.710180  2.792448\n#&gt;  [57]  2.874717  2.956985  3.039253  3.121522  3.203790  3.286059  3.368327\n#&gt;  [64]  3.450595  3.532864  3.615132  3.697400  3.779669  3.861937  3.944206\n#&gt;  [71]  4.026474  4.108742  4.191011  4.273279  4.355548  4.437816  4.520084\n#&gt;  [78]  4.602353  4.684621  4.766889  4.849158  4.931426  5.013695  5.095963\n#&gt;  [85]  5.178231  5.260500  5.342768  5.425036  5.507305  5.589573  5.671842\n#&gt;  [92]  5.754110  5.836378  5.918647  6.000915  6.083184  6.165452  6.247720\n#&gt;  [99]  6.329989  6.412257\n\nEsaminiamo graficamente la relazione tra il logit \\(\\log \\left( \\frac{p}{1-p} \\right)\\) e \\(x\\):\n\n# Aggiungi la colonna logit_p a new_data\nnew_data$logit_p &lt;- logit_p\n\n# Grafico\nggplot(new_data, aes(x = x, y = logit_p)) +\n  geom_line(color = \"blue\") +\n  labs(\n    title = \"Logit Predetti in Funzione di X\",\n    x = \"X\",\n    y = \"Logit\"\n  )\n\n\n\n\n\n\n\nCalcoliamo i logit per ogni valore \\(x\\) nel dataset new_data utilizzando le stime a posteriori dei parametri \\(\\alpha\\) e \\(\\beta\\) ottenute dal modello di regressione logistica. Nel modello di regressione logistica, il logit della probabilità è una funzione lineare di \\(x\\). Per ottenere la probabilità \\(p\\) dalla trasformazione del logit, possiamo utilizzare la funzione logistica inversa. Svolgiamo la conversione:\n\n\nCalcoliamo il logit per ogni valore di \\(x\\):\n\\[\n\\text{logit}_p = \\alpha + \\beta x\n\\]\n\n\nApplichiamo la funzione logistica inversa (antilogit) per ottenere la probabilità \\(p\\):\n\\[\np = \\frac{e^{\\text{logit}_p}}{1 + e^{\\text{logit}_p}} = \\frac{e^{\\alpha + \\beta x}}{1 + e^{\\alpha + \\beta x}}\n\\]\n\n\nQuesta formula ci permette di trasformare il logit in una probabilità compresa tra 0 e 1 per ogni valore di \\(x\\) nel dataset new_data.\n\n# Calcola le probabilità dalla scala logit\nprob &lt;- exp(new_data$logit_p) / (1 + exp(new_data$logit_p))\n\n# Aggiungi la colonna a new_data\nnew_data$prob &lt;- prob\n\n# Grafico con ggplot2\nggplot(new_data, aes(x = x, y = prob)) +\n  geom_line(color = \"blue\") +\n  labs(\n    title = \"Probabilità Predetta in Funzione di X\",\n    x = \"X\",\n    y = \"Probabilità Predetta\"\n  )\n\n\n\n\n\n\n\n\n74.6.1 Interpretazione dei coefficienti nella regressione logistica\nAbbiamo stimato i coefficienti \\(\\alpha\\) e \\(\\beta\\) dal modello di regressione logistica con i seguenti valori:\n\n\\(\\alpha = -1.7784477\\)\n\\(\\beta = 1.003503126\\)\n\nEsamineremo ora l’interpretazione di questi coefficienti sulla scala dei logit, dell’odds ratio e delle probabilità.\n\n74.6.1.1 La regola del dividere per 4\nLa regola del dividere per 4 è un metodo utile per interpretare i coefficienti della regressione logistica. Dividendo il coefficiente \\(\\beta\\) per 4, si ottiene un’approssimazione della massima variazione nella probabilità \\(\\Pr(y = 1)\\) per un incremento unitario in \\(x\\), in corrispondenza di \\(p = 0.5\\).\nLa curva logistica è più ripida al centro, dove \\(\\alpha + \\beta x = 0\\) e quindi \\(\\text{logit}^{-1}(\\alpha + \\beta x) = 0.5\\). In questo punto, la pendenza della curva, ovvero la derivata della funzione logistica, è massima e raggiunge il valore \\(\\beta / 4\\).\nPer esempio, nel modello con \\(\\alpha = -1.778\\) e \\(\\beta = 1.003\\), dividendo \\(\\beta\\) per 4 otteniamo circa 0.25. Questo valore rappresenta l’aumento massimo, in termini di probabilità, che possiamo aspettarci per un incremento unitario in \\(x\\), in corrispondenza di \\(p = 0.5\\).\nIn sintesi, la regola del dividere per 4 semplifica l’interpretazione dei coefficienti della regressione logistica, fornendo un’indicazione intuitiva di come la variabile indipendente influisce sulla probabilità dell’evento di interesse.\n\n74.6.1.2 Scala dei Logit\nNella regressione logistica, la funzione logit rappresenta una relazione lineare tra il logit della probabilità di successo e la variabile indipendente \\(X\\):\n\\[\n\\log \\left( \\frac{p}{1-p} \\right) = \\alpha + \\beta x\n\\]\nCon i coefficienti stimati, la funzione logit diventa:\n\\[\n\\log \\left( \\frac{p}{1-p} \\right) = -1.7784477 + 1.003503126 \\cdot x\n\\]\n\n\n\\(\\alpha = -1.7784477\\): Questo è l’intercetta del modello, il valore del logit quando \\(x = 0\\). Indica che, quando \\(x\\) è 0, il logit della probabilità di successo è \\(-1.778\\).\n\n\\(\\beta = 1.003503126\\): Questo è il coefficiente di \\(x\\) e rappresenta il cambiamento nel logit per ogni incremento unitario in \\(x\\). In altre parole, per ogni incremento di 1 unità in \\(x\\), il logit della probabilità di successo aumenta di circa \\(1.0035\\).\n\n74.6.1.3 Odds Ratio\nL’odds ratio (OR) misura il cambiamento relativo nelle odds di successo per un incremento unitario in \\(x\\). È ottenuto esponenziando il coefficiente \\(\\beta\\):\n\\[\n\\text{OR} = e^{\\beta} = e^{1.0035} \\approx 2.728\n\\]\nUn odds ratio di circa \\(2.728\\) indica che, per ogni incremento unitario in \\(x\\), le odds di successo aumentano di circa \\(172.8\\%\\). In altre parole, l’odds di successo è circa \\(2.728\\) volte maggiore per ogni unità aggiuntiva di \\(x\\).\n\n74.6.1.4 Scala delle Probabilità\nPer interpretare l’effetto di \\(\\beta\\) sulla scala delle probabilità, possiamo considerare come la probabilità \\(p\\) cambia in corrispondenza di specifici valori di \\(x\\).\n\nQuando \\(x = 0\\):\n\n\\[\n\\log \\left( \\frac{p}{1-p} \\right) = -1.778\n\\]\nInvertendo il logit per ottenere \\(p\\):\n\\[\np = \\frac{e^{-1.7784477}}{1 + e^{-1.7784477}} \\approx \\frac{0.169} {1 + 0.169} \\approx 0.144\n\\]\nQuindi, la probabilità di successo quando \\(x = 0\\) è circa \\(14.4\\%\\).\n\nPer un incremento unitario in \\(x\\), diciamo \\(x = 1\\):\n\n\\[\n\\log \\left( \\frac{p}{1-p} \\right) = -1.778 + 1.0035 \\cdot 1 \\approx -0.7749\n\\]\nInvertendo il logit per ottenere \\(p\\):\n\\[\np = \\frac{e^{-0.774944574}}{1 + e^{-0.774944574}} \\approx \\frac{0.461} {1 + 0.461} \\approx 0.316\n\\]\nQuindi, la probabilità di successo quando \\(x = 1\\) è circa \\(31.6\\%\\). Tuttavia questo incremento non è costante per i diversi livelli \\(x\\) e il modo più semplice per mostrare la relazione tra probabilità di successo e la variabile \\(X\\) è quella di generare un grafico come quello che abbimo prodotto in precedenza.\n\n74.6.2 Riassunto\n\n\nScala dei Logit: Un incremento unitario in \\(x\\) aumenta il logit della probabilità di successo di \\(1.0035\\).\n\nOdds Ratio: Le odds di successo aumentano di circa \\(2.728\\) volte per ogni incremento unitario in \\(x\\).\n\nScala delle Probabilità: Quando \\(x\\) passa da 0 a 1, la probabilità di successo aumenta da circa \\(14.4\\%\\) a \\(31.6\\%\\). Per la relazione tra ciascun livello \\(x\\) e la probabilità di successo è necessario generare un grafico.\n\nQuesta analisi dimostra come i coefficienti del modello di regressione logistica possono essere interpretati su diverse scale, fornendo un quadro completo della relazione tra la variabile indipendente e la probabilità di successo.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#regressione-logistica-con-sola-intercetta",
    "href": "chapters/glm/03_stan_logistic_regr.html#regressione-logistica-con-sola-intercetta",
    "title": "74  Regressione logistica con Stan",
    "section": "\n74.7 Regressione logistica con sola intercetta",
    "text": "74.7 Regressione logistica con sola intercetta\nNella regressione lineare, un modello con sola intercetta stima semplicemente la media del campione. Analogamente, un modello lineare con un singolo predittore binario stima la differenza tra due medie. Per la regressione logistica, un modello con sola intercetta stima invece un’unica proporzione: la probabilità che la variabile risposta assuma valore 1, uguale per tutte le unità del campione.\n\n74.7.1 Esempio\nSupponiamo di avere un campione casuale di 50 persone, sottoposte a un test per una certa caratteristica psicologica (es. la tendenza a ricordare dettagli irrilevanti in un compito di memoria). Il risultato è che 10 persone (20%) presentano la caratteristica.\nPer 10 successi su 50 prove, la stima puntuale frequentista è:\n\\[\n  \\hat{p}=\\frac{10}{50}=0{.}20,\\qquad\n  SE_{\\text{Wald}}=\\sqrt{\\frac{\\hat p(1-\\hat p)}{n}}\n  =\\sqrt{\\frac{0.2\\cdot 0.8}{50}}\\approx 0{.}06.\n\\]\nGli intervalli di confidenza al 95% possono essere calcolati in modi diversi nell’approccio frequentista. Di seguito i principali:\n\n# Dati\nx &lt;- 10\nn &lt;- 50\np_hat &lt;- x / n\np_hat\n#&gt; [1] 0.2\n\n\nWald (approssimazione normale)\n\n\nSemplice ma spesso instabile con n moderati o p vicino a 0/1.\n\n\nse_wald &lt;- sqrt(p_hat * (1 - p_hat) / n)\nci_wald &lt;- p_hat + c(-1, 1) * 1.96 * se_wald\nci_wald\n#&gt; [1] 0.08913 0.31087\n\n\nWilson / score\n\n\nIn genere preferibile al Wald. In prop.test() la correzione di continuità è attiva di default.\n\n\nci_wilson_cc   &lt;- prop.test(x, n)$conf.int   # score + correzione di continuità\nci_wilson_nocc &lt;- prop.test(x, n, correct = FALSE)$conf.int # score senza correzione\nci_wilson_nocc\n#&gt; [1] 0.1124 0.3304\n#&gt; attr(,\"conf.level\")\n#&gt; [1] 0.95\n\n\nEsatto (Clopper–Pearson)\n\n\nBasato sulla binomiale; tende a essere conservativo (intervalli più ampi).\n\n\nci_exact &lt;- binom.test(x, n, conf.level = 0.95)$conf.int\nci_exact\n#&gt; [1] 0.1003 0.3372\n#&gt; attr(,\"conf.level\")\n#&gt; [1] 0.95\n\n\n74.7.1.1 Riepilogo\n\n# Tabella riassuntiva con i principali metodi\nres &lt;- data.frame(\n  metodo = c(\"Wald\", \"Wilson (no cc)\", \"Wilson (cc)\", \"Clopper–Pearson\"),\n  lower  = c(ci_wald[1], ci_wilson_nocc[1], ci_wilson_cc[1], ci_exact[1]),\n  upper  = c(ci_wald[2], ci_wilson_nocc[2], ci_wilson_cc[2], ci_exact[2])\n)\nres\n#&gt;            metodo   lower  upper\n#&gt; 1            Wald 0.08913 0.3109\n#&gt; 2  Wilson (no cc) 0.11244 0.3304\n#&gt; 3     Wilson (cc) 0.10502 0.3414\n#&gt; 4 Clopper–Pearson 0.10030 0.3372\n\nPossiamo ottenere la stessa informazione tramite una regressione logistica bayesiana con sola intercetta:\n\n# Dati\ny &lt;- c(rep(0, 40), rep(1, 10))\ndf &lt;- data.frame(y = y)\n\n# Modello bernoulli con sola intercetta\nfit &lt;- brm(\n  y ~ 1,\n  data = df,\n  family = bernoulli(),\n  seed = 123,\n  chains = 4,\n  iter = 2000,\n  backend = \"cmdstanr\"\n)\n\n\nsummary(fit, round_to = 2)\n#&gt;  Family: bernoulli \n#&gt;   Links: mu = logit \n#&gt; Formula: y ~ 1 \n#&gt;    Data: df (Number of observations: 50) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept    -1.38      0.34    -2.09    -0.74 1.00     1658     2284\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nIl coefficiente stimato b_Intercept è sulla scala logit. Per ottenere la probabilità, si usa la trasformazione inversa:\n\n# Valori stimati dal modello (esempio)\nintercept &lt;- -1.38\nerror &lt;- 0.34\n\n# Probabilità media stimata\np_hat &lt;- plogis(intercept)\n\n# Limiti di credibilità (approx ±1 SE sulla scala logit)\nlower_bound &lt;- plogis(intercept - error)\nupper_bound &lt;- plogis(intercept + error)\n\ncat(sprintf(\"p_hat: %.3f, Lower bound: %.3f, Upper bound: %.3f\",\n            p_hat, lower_bound, upper_bound), \"\\n\")\n#&gt; p_hat: 0.201, Lower bound: 0.152, Upper bound: 0.261\n\nRisultato atteso:\n\\[\n\\hat{p} \\approx 0.20,\\quad \\text{CrI 95\\%} \\approx [0.14, 0.27].\n\\]\n\n74.7.2 Confronto tra approcci\nLe stime ottenute dalla regressione logistica e quelle calcolate con la formula classica possono differire leggermente per due motivi principali:\n\n\nUso dei priori: in brm il modello è bayesiano e, anche con priori deboli, questi contribuiscono leggermente alla stima.\n\nInferenza esatta: l’errore standard classico è un’approssimazione, valida asintoticamente, mentre il modello bayesiano restituisce la distribuzione posteriore completa, che tiene conto esattamente della natura discreta dei dati.\n\nInterpretazione psicologica In un contesto di ricerca, questo tipo di modello è utile quando vogliamo stimare la prevalenza di un comportamento o di un tratto in una popolazione, con un’incertezza ben quantificata. Ad esempio, potremmo voler stimare la proporzione di studenti che provano ansia significativa durante un esame, o la percentuale di pazienti che mostrano un certo pattern cognitivo in un test clinico.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#regressione-logistica-con-un-singolo-predittore-binario",
    "href": "chapters/glm/03_stan_logistic_regr.html#regressione-logistica-con-un-singolo-predittore-binario",
    "title": "74  Regressione logistica con Stan",
    "section": "\n74.8 Regressione logistica con un singolo predittore binario",
    "text": "74.8 Regressione logistica con un singolo predittore binario\nQuando il predittore è una variabile dicotomica, la regressione logistica è concettualmente equivalente a un confronto di proporzioni. La differenza è che il modello logit ci permette di ottenere stime e intervalli di credibilità direttamente dal modello probabilistico, senza ricorrere a formule approssimate per l’errore standard, e può essere facilmente esteso ad altri predittori o a strutture gerarchiche.\nPer rendere l’esempio più vicino alla psicologia, immaginiamo uno studio sperimentale sulla memoria: 50 partecipanti svolgono un compito di richiamo libero senza alcun aiuto (condizione 0), altri 60 lo svolgono con un suggerimento iniziale (condizione 1). La variabile y indica se il partecipante ha ricordato correttamente un elemento target (1 = corretto, 0 = errato). Supponiamo che nella condizione senza suggerimento 10 su 50 partecipanti ricordino correttamente (20%), mentre nella condizione con suggerimento il numero salga a 20 su 60 (33%).\nQuesti dati possono essere organizzati così:\n\nx &lt;- c(rep(0, 50), rep(1, 60))\ny &lt;- c(rep(0, 40), rep(1, 10),   # condizione 0: 40 errori, 10 successi\n       rep(0, 40), rep(1, 20))   # condizione 1: 40 errori, 20 successi\ndf &lt;- data.frame(x = x, y = y)\ntable(df$x, df$y)\n#&gt;    \n#&gt;      0  1\n#&gt;   0 40 10\n#&gt;   1 40 20\n\n\n74.8.1 Stima del modello\nUsiamo brm per stimare un modello di regressione logistica bayesiano, specificando la famiglia bernoulli con link logit:\n\nset.seed(123)\n\nfit &lt;- brm(\n  y ~ x,  # logit(p) = b_Intercept + b_x * x\n  data   = df,\n  family = bernoulli(link = \"logit\"),\n  backend = \"cmdstanr\",\n  chains = 4, iter = 2000\n)\n\n\nsummary(fit)\n#&gt;  Family: bernoulli \n#&gt;   Links: mu = logit \n#&gt; Formula: y ~ x \n#&gt;    Data: df (Number of observations: 110) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept    -1.41      0.36    -2.15    -0.73 1.00     2639     2321\n#&gt; x             0.71      0.45    -0.18     1.61 1.00     3266     2709\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n74.8.2 Interpretazione dei coefficienti\n\n\nb_Intercept è il logit della probabilità di successo nella condizione 0 (\\(p(x=0)\\)).\n\nb_x rappresenta la differenza di logit tra condizione 1 e condizione 0.\nPer ottenere le probabilità sulla scala naturale, si applica la funzione logit-inversa: \\(p = \\mathrm{plogis}(\\text{logit}) = \\frac{1}{1+e^{-\\text{logit}}}\\).\n\n74.8.3 Probabilità posteriori e differenza\nCalcoliamo \\(p(0)\\), \\(p(1)\\) e la loro differenza \\(\\Delta\\) per ciascun campione del posteriore, e riassumiamo:\n\ndraws &lt;- as_draws_df(fit)  # dal pacchetto 'posterior'\n\np0   &lt;- plogis(draws$b_Intercept)\np1   &lt;- plogis(draws$b_Intercept + draws$b_x)\ndiff &lt;- p1 - p0\n\nsumm &lt;- tibble::tibble(\n  quantity = c(\"p(x=0)\", \"p(x=1)\", \"diff = p(1)-p(0)\"),\n  mean     = c(mean(p0), mean(p1), mean(diff)),\n  median   = c(median(p0), median(p1), median(diff)),\n  q2.5     = c(quantile(p0, .025), quantile(p1, .025), quantile(diff, .025)),\n  q97.5    = c(quantile(p0, .975), quantile(p1, .975), quantile(diff, .975)),\n  sd       = c(sd(p0), sd(p1), sd(diff))\n)\nsumm\n#&gt; # A tibble: 3 × 6\n#&gt;   quantity          mean median    q2.5 q97.5     sd\n#&gt;   &lt;chr&gt;            &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1 p(x=0)           0.202  0.199  0.105  0.325 0.0567\n#&gt; 2 p(x=1)           0.334  0.332  0.224  0.453 0.0595\n#&gt; 3 diff = p(1)-p(0) 0.131  0.133 -0.0351 0.290 0.0824\n\n\n74.8.4 Commento ai risultati\nIn questo caso, la probabilità media stimata di richiamo corretto è circa 20% nella condizione senza suggerimento e 33% con suggerimento. La differenza \\(\\Delta\\) è quindi di circa 0.13 punti percentuali, con un intervallo di credibilità al 95% che va da valori leggermente negativi (indicando che il suggerimento potrebbe non essere sempre utile) a valori positivi fino a circa 0.29.\nL’ampiezza dell’intervallo riflette l’incertezza dovuta alla dimensione campionaria relativamente ridotta. In un’ottica psicologica, questo tipo di stima ci permette di dire che, pur essendo plausibile un effetto positivo del suggerimento, non possiamo escludere del tutto la possibilità che l’effetto sia nullo o trascurabile. La regressione logistica fornisce una base formale per incorporare ulteriori predittori (ad esempio età, livello di ansia da test) o effetti gerarchici (partecipanti, item) in studi più complessi.\n\n74.8.5 Distribuzione posteriore della differenza\n\ntibble(diff = diff) |&gt;\n  ggplot(aes(x = diff)) +\n  geom_histogram(bins = 40, fill = \"skyblue\", color = \"white\") +\n  geom_vline(xintercept = mean(diff), color = \"red\", linewidth = 1) +\n  labs(\n    title = expression(paste(\"Distribuzione posteriore di \", Delta, \" = p(x=1) - p(x=0)\")),\n    x = \"Differenza di probabilità\",\n    y = \"Frequenza\"\n  )",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/glm/03_stan_logistic_regr.html#informazioni-sullambiente-di-sviluppo",
    "title": "74  Regressione logistica con Stan",
    "section": "Informazioni sull’ambiente di sviluppo",
    "text": "Informazioni sull’ambiente di sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] insight_1.3.1         bayestestR_0.16.1     cmdstanr_0.9.0       \n#&gt;  [4] pillar_1.11.0         tinytable_0.11.0      patchwork_1.3.1      \n#&gt;  [7] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.13.0     \n#&gt; [10] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.0     \n#&gt; [13] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [16] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [19] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [22] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [25] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3        inline_0.3.21        sandwich_3.1-1      \n#&gt;  [4] rlang_1.1.6          magrittr_2.0.3       multcomp_1.4-28     \n#&gt;  [7] snakecase_0.11.1     compiler_4.5.1       mgcv_1.9-3          \n#&gt; [10] vctrs_0.6.5          reshape2_1.4.4       stringr_1.5.1       \n#&gt; [13] pkgconfig_2.0.3      arrayhelpers_1.1-0   fastmap_1.2.0       \n#&gt; [16] backports_1.5.0      labeling_0.4.3       utf8_1.2.6          \n#&gt; [19] rmarkdown_2.29       ps_1.9.1             purrr_1.1.0         \n#&gt; [22] xfun_0.52            cachem_1.1.0         jsonlite_2.0.0      \n#&gt; [25] broom_1.0.9          parallel_4.5.1       R6_2.6.1            \n#&gt; [28] stringi_1.8.7        RColorBrewer_1.1-3   lubridate_1.9.4     \n#&gt; [31] estimability_1.5.1   knitr_1.50           zoo_1.8-14          \n#&gt; [34] pacman_0.5.1         Matrix_1.7-3         splines_4.5.1       \n#&gt; [37] timechange_0.3.0     tidyselect_1.2.1     abind_1.4-8         \n#&gt; [40] yaml_2.3.10          codetools_0.2-20     curl_6.4.0          \n#&gt; [43] processx_3.8.6       pkgbuild_1.4.8       plyr_1.8.9          \n#&gt; [46] lattice_0.22-7       withr_3.0.2          bridgesampling_1.1-2\n#&gt; [49] coda_0.19-4.1        evaluate_1.0.4       survival_3.8-3      \n#&gt; [52] RcppParallel_5.1.10  tensorA_0.36.2.1     checkmate_2.3.2     \n#&gt; [55] stats4_4.5.1         distributional_0.5.0 generics_0.1.4      \n#&gt; [58] rprojroot_2.1.0      rstantools_2.4.0     scales_1.4.0        \n#&gt; [61] xtable_1.8-4         glue_1.8.0           emmeans_1.11.2      \n#&gt; [64] tools_4.5.1          data.table_1.17.8    mvtnorm_1.3-3       \n#&gt; [67] grid_4.5.1           QuickJSR_1.8.0       colorspace_2.1-1    \n#&gt; [70] nlme_3.1-168         cli_3.6.5            svUnit_1.0.6        \n#&gt; [73] Brobdingnag_1.2-9    V8_6.0.5             gtable_0.3.6        \n#&gt; [76] digest_0.6.37        TH.data_1.1-3        htmlwidgets_1.6.4   \n#&gt; [79] farver_2.1.2         memoise_2.0.1        htmltools_0.5.8.1   \n#&gt; [82] lifecycle_1.0.4      MASS_7.3-65",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#bibliografia",
    "href": "chapters/glm/03_stan_logistic_regr.html#bibliografia",
    "title": "74  Regressione logistica con Stan",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nFox, J. (2015). Applied regression analysis and generalized linear models. Sage publications.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03a_stan_logistic_process.html",
    "href": "chapters/glm/03a_stan_logistic_process.html",
    "title": "75  Dal GLM a un modello processuale per dati binari",
    "section": "",
    "text": "Introduzione\nAd esempio, in un questionario online possiamo usare la regressione logistica per prevedere se uno studente risponde correttamente o erroneamente in base alla difficoltà della domanda. Ma in un compito cognitivo ripetuto, la risposta dello stesso studente al trial 10 dipende anche da come è andato il trial 9 (feedback positivo/negativo, fatica accumulata, ecc.). Il modello statico non “vede” questa dipendenza, mentre un modello processuale la incorpora.\nIn molti contesti cognitivi e comportamentali, le risposte binarie riflettono infatti:\nIl modello logistico standard assume invece:\nQueste ipotesi sono spesso poco realistiche nei dati psicologici longitudinali o sperimentali, dove:\nPer catturare meglio questi aspetti servono modelli più sofisticati, capaci di rappresentare la dipendenza temporale tra le osservazioni, l’eterogeneità intra-individuale e la natura incrementale dei processi cognitivi sottostanti. Questa transizione da una rappresentazione statica alla modellazione dinamica è cruciale in psicologia: il comportamento osservato non va visto come un evento isolato, ma come l’istantanea di un sistema complesso in continua evoluzione.\nL’obiettivo di questo capitolo è mostrare come, con Stan, sia possibile esplicitare il meccanismo generativo delle risposte, superando i limiti della regressione logistica classica e introducendo la nozione di processi dinamici autoregressivi che meglio riflettono la natura temporale dei fenomeni psicologici.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Dal GLM a un modello processuale per dati binari</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03a_stan_logistic_process.html#introduzione",
    "href": "chapters/glm/03a_stan_logistic_process.html#introduzione",
    "title": "75  Dal GLM a un modello processuale per dati binari",
    "section": "",
    "text": "La regressione logistica, introdotta nei capitoli precedenti, è uno strumento fondamentale per analizzare variabili dicotomiche \\(y \\in {0,1}\\) (ad esempio: scelta sì/no, risposta corretta/errata, accettazione/rifiuto) in funzione di predittori osservabili \\(\\mathbf{x}\\). Tuttavia, questo approccio presenta limiti importanti quando vogliamo descrivere processi psicologici dinamici, nei quali la risposta osservata è soltanto la manifestazione finale di meccanismi interni che si sviluppano nel tempo.\n\n\n\n\n\nprocessi accumulativi, come l’integrazione di evidenza nel decision making,\n\ndinamiche temporali interne, ad esempio legate all’apprendimento, all’adattamento o all’affaticamento,\n\ninterazioni stato-dipendenti, come variazioni momentanee di motivazione o attenzione.\n\n\n\nindipendenza tra le osservazioni,\neffetti costanti nel tempo,\nun unico meccanismo generativo omogeneo.\n\n\n\nle risposte sono influenzate dalla storia precedente (history dependence),\ngli stati latenti del soggetto evolvono lungo traiettorie individuali,\nla stessa soglia decisionale può cambiare nel corso del tempo.\n\n\n\n\n\n\n\n\nEsempio.\n\n\n\n\n\nImmaginiamo uno studente che affronta un test a scelta multipla. Con un modello logistico classico possiamo prevedere se risponderà correttamente in base alla difficoltà della domanda. Ma se lo stesso studente sta svolgendo una lunga serie di prove, la sua risposta alla domanda 10 dipende anche da come è andata la domanda 9: un errore può ridurre la fiducia, un successo può aumentarla. In più, col passare del tempo, possono intervenire affaticamento o distrazione. Il modello statico logit non cattura nulla di tutto ciò. Per includere questi aspetti servono modelli che riconoscano che ogni osservazione porta memoria del passato.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Dal GLM a un modello processuale per dati binari</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03a_stan_logistic_process.html#dal-modello-statico-al-modello-processuale",
    "href": "chapters/glm/03a_stan_logistic_process.html#dal-modello-statico-al-modello-processuale",
    "title": "75  Dal GLM a un modello processuale per dati binari",
    "section": "\n75.1 Dal modello statico al modello processuale",
    "text": "75.1 Dal modello statico al modello processuale\n\n75.1.1 La regressione logistica classica\nNel modello di regressione logistica (GLM logit) la probabilità di osservare una risposta positiva è:\n\\[\n\\Pr(y_i=1 \\mid \\mathbf{x}_i) = \\operatorname{logit}^{-1}\\!\\left(\\alpha + \\mathbf{x}_i^\\top \\boldsymbol\\beta\\right).\n\\]\nQui:\n\n\n\\(\\alpha\\) è l’intercetta, che rappresenta la tendenza di base a rispondere 1;\n\n\\(\\boldsymbol\\beta\\) descrive come i predittori osservati influenzano questa probabilità.\n\nUn modo intuitivo per interpretare la formula è introdurre una variabile latente continua \\(u_i\\), che possiamo pensare come la propensione interna dell’individuo a rispondere “1”:\n\\[\nu_i = \\alpha + \\mathbf{x}_i^\\top \\boldsymbol\\beta + \\varepsilon_i,\n\\qquad \\varepsilon_i \\sim \\text{Logistic}(0,1).\n\\]\nLa regola di decisione è semplice:\n\nse \\(u_i &gt; 0\\) allora osserviamo \\(y_i=1\\),\nse \\(u_i \\leq 0\\) allora osserviamo \\(y_i=0\\).\n\nIn altre parole, immaginiamo che l’individuo abbia una soglia fissa: quando la propensione supera questa soglia, la risposta osservata diventa positiva.\nPossiamo pensare a \\(u_i\\) come a un “serbatoio di propensione”: se il livello supera la soglia, si osserva una risposta positiva. Nei modelli statici il serbatoio si svuota e si riempie indipendentemente a ogni trial; nei modelli dinamici, invece, il livello attuale dipende anche da quanto era pieno al trial precedente.\nNella regressione logistica classica, questa soglia è sempre costante nel tempo e uguale per tutti i trial. Ma nei processi psicologici reali ciò non è sempre realistico: la soglia decisionale (o l’intensità della propensione) può cambiare da un momento all’altro, ad esempio per effetto di apprendimento, fatica o variazioni di motivazione.\nEd è proprio da qui che nasce la necessità di estendere il modello logit statico a un modello dinamico, in cui la variabile latente \\(u\\) (e talvolta anche la soglia) possa variare nel tempo e riflettere la natura evolutiva dei processi psicologici.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Dal GLM a un modello processuale per dati binari</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03a_stan_logistic_process.html#oltre-il-glm-dinamica-temporale",
    "href": "chapters/glm/03a_stan_logistic_process.html#oltre-il-glm-dinamica-temporale",
    "title": "75  Dal GLM a un modello processuale per dati binari",
    "section": "\n75.2 Oltre il GLM: dinamica temporale",
    "text": "75.2 Oltre il GLM: dinamica temporale\nNella regressione logistica classica abbiamo visto che ogni risposta osservata \\(y_i\\) può essere pensata come il risultato di una propensione latente \\(u_i\\), confrontata con una soglia fissa. Questa impostazione funziona bene se consideriamo le osservazioni come indipendenti e isolate.\nMa in psicologia le cose vanno spesso diversamente:\n\nnegli esperimenti con prove ripetute, le decisioni prese oggi sono influenzate da quelle appena fatte;\nnelle misurazioni longitudinali (EMA), lo stato emotivo o motivazionale di un momento dipende in parte da quello precedente;\nnei compiti di apprendimento, l’esperienza accumulata modifica gradualmente la propensione a scegliere un’opzione rispetto a un’altra.\n\nIn tutti questi casi, è naturale immaginare che la variabile latente \\(u_{i,t}\\) non nasca da zero a ogni prova, ma porti memoria del passato.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Dal GLM a un modello processuale per dati binari</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03a_stan_logistic_process.html#il-modello-ar1",
    "href": "chapters/glm/03a_stan_logistic_process.html#il-modello-ar1",
    "title": "75  Dal GLM a un modello processuale per dati binari",
    "section": "\n75.3 Il modello AR(1)",
    "text": "75.3 Il modello AR(1)\nPer rendere esplicita la dipendenza dal passato, usiamo un modello autoregressivo di ordine 1 (AR(1); Chatfield & Xing (2019)):\n\\[\n\\begin{aligned}\nu_{i,t} &= \\alpha_i\n          + \\mathbf{x}_{i,t}^\\top \\boldsymbol\\beta\n          + \\phi \\, u_{i,t-1}\n          + \\eta_{i,t},\n& \\eta_{i,t} \\sim \\mathcal{N}(0,\\sigma_u), \\\\[6pt]\ny_{i,t} \\mid u_{i,t} &\\sim \\text{Bernoulli}\\!\\left(\\operatorname{logit}^{-1}(u_{i,t})\\right).\n\\end{aligned}\n\\]\nPossiamo immaginare \\(u_{i,t}\\) come il livello di un “serbatoio di propensione”: se questo valore supera la soglia implicita dello 0 sulla scala logit, la risposta osservata è positiva \\((y_{i,t}=1)\\). La novità rispetto al modello statico è che il livello attuale \\(u_{i,t}\\) dipende anche da quello precedente \\(u_{i,t-1}\\), attraverso il termine \\(\\phi u_{i,t-1}\\).\nSignificati dei parametri del modello AR(1):\n\n\\(\\alpha_i\\) (intercetta soggetto-specifica): propensione media di un individuo (es. uno studente molto ansioso potrebbe avere più probabilità di rispondere “no”).\n\\(\\beta\\) (effetto dei predittori): effetto di variabili osservabili (es. domande più facili aumentano la probabilità di risposta corretta).\n\n\\(\\phi\\) (persistenza dinamica): quanta parte dello stato passato sopravvive:\n\nse \\(\\phi=0\\), nessuna memoria: ogni risposta è “indipendente”,\nse \\(\\phi&gt;0\\), inerzia: un successo ieri aumenta la probabilità di successo oggi,\nse \\(\\phi&lt;0\\), alternanza: un successo ieri rende più probabile un errore oggi (pattern a zig-zag).\n\n\n\\(\\sigma_u\\) (variabilità del processo): irregolarità: se grande, le traiettorie diventano rumorose (es. risposte altalenanti per distrazioni).\n\nUn piccolo schema concettuale aiuta a visualizzare:\nu(t-1)  ──▶  u(t)  ──▶  y(t)\n   │\n   └─────────── φ ───────────┘\nPer esempio:\n\n\n\\(\\alpha_i\\): uno studente particolarmente ansioso potrebbe avere un’alta probabilità di rispondere “no” a prescindere dalla domanda;\n\n\\(\\beta\\): se la domanda è facile (\\(x=1\\)), aumenta la probabilità di risposta corretta;\n\n\\(\\phi\\): se lo studente ha risposto correttamente ieri, oggi sarà più probabile che risponda ancora correttamente;\n\n\\(\\sigma_u\\): cattura la variabilità inspiegata, come distrazioni improvvise.\n\n\n75.3.1 Che cos’è \\(u_{i,t}\\)?\n\n\n\\(u_{i,t}\\) non è osservato: è uno stato latente.\nPossiamo pensarlo come il “livello di propensione” di un individuo in un certo istante \\(t\\).\nL’osservazione \\(y_{i,t}\\) (corretto/errato, sì/no, 1/0) nasce da questo stato: se \\(u_{i,t}\\) è alto, la probabilità di risposta positiva è alta; se è basso, è bassa.\nNei modelli Bayesiani o di stato latente, i valori di \\(u_{i,t}\\) non si calcolano direttamente dai dati ma vengono stimati/inferiti dal modello. In pratica, otteniamo una distribuzione a posteriori su ciascun \\(u_{i,t}\\), non un singolo valore deterministico.\n\n75.3.2 E il ruolo di \\(\\phi\\)?\nIl coefficiente \\(\\phi\\) funziona come un “peso di memoria”:\n\nSe \\(\\phi = 0\\), il passato non conta: \\(u\\_{i,t}\\) dipende solo dai predittori e dal rumore.\nSe \\(\\phi &gt; 0\\), c’è inerzia: lo stato precedente influenza positivamente quello attuale.\nSe \\(\\phi &lt; 0\\), c’è compensazione o alternanza: uno stato alto ieri spinge verso uno basso oggi.\n\nFormalmente, \\(\\phi\\) è un coefficiente di regressione come \\(\\alpha\\) e \\(\\beta\\), ma agisce sulla variabile latente del tempo precedente, quindi introduce dipendenza temporale.\n\n75.3.3 Come “si trovano” i valori di \\(u_{i,t-1}\\)?\n\nAll’inizio (al tempo \\(t=1\\)), bisogna specificare una condizione iniziale per \\(u_{i,0}\\), ad esempio assumendo \\(u_{i,0} \\sim \\mathcal{N}(0,\\sigma_0)\\).\nPer i tempi successivi, ogni \\(u_{i,t}\\) viene costruito ricorsivamente dal precedente: il modello stesso definisce la sequenza degli stati latenti.\nIn fase di stima (ad esempio con Stan), si usano i dati osservati \\(y_{i,t}\\) per inferire a posteriori quali valori plausibili di \\(u_{i,t}\\) rendono il modello coerente con le risposte osservate.\n\nRiassumendo:\n\n\n\\(u_{i,t}\\): stato latente, stimato dal modello, non osservato.\n\n\\(\\phi\\): coefficiente che regola quanto lo stato passato influenza quello presente.\n\n\\(\\alpha_i\\), \\(\\beta\\): intercetta e predittori osservati, come in una regressione logistica.\n\n\\(\\sigma_u\\): variabilità residua del processo latente.\n\n75.3.4 Perché è importante?\nCon il modello AR(1) facciamo un passo oltre la regressione logistica classica. La probabilità di risposta non è più determinata solo dai fattori esterni osservati, ma anche dagli stati interni accumulati nel tempo. In altre parole, il comportamento osservato non nasce “da zero” a ogni prova: porta con sé una traccia del passato.\nEsempi concreti aiutano a capirlo:\n\n\nCompito di apprendimento: se un partecipante ha appena ricevuto un rinforzo positivo, la sua propensione a ripetere la stessa scelta sarà più alta al trial successivo.\n\nDiario EMA: un umore negativo oggi aumenta la probabilità di trovarsi in uno stato simile anche domani, a meno che un evento esterno intervenga a interrompere la continuità.\n\nLa lezione fondamentale è questa: le scelte non sono indipendenti, ma intrecciate con la storia recente dell’individuo. Ed è proprio questa “memoria del passato” che rende i modelli dinamici strumenti più realistici e potenti per descrivere processi psicologici rispetto ai modelli statici.\n\n\n\n\n\n\nEsempio\n\n\n\n\n\nPer fare un esempio semplice, consideriamo un modello continuo con un solo predittore continuo. La dipendenza temporale la collochiamo nei residui, con una struttura AR(1). In questo modo evitiamo il problema di introdurre variabili latenti non osservabili come \\(u\\).\nPer il soggetto \\(i\\) al tempo \\(t\\):\n\\[\n\\begin{aligned}\ny_{i,t} &= \\alpha_i + \\beta\\,x_{i,t} + e_{i,t},\\\\\ne_{i,t} &= \\phi\\, e_{i,t-1} + \\eta_{i,t}, \\qquad \\eta_{i,t}\\sim\\mathcal N(0,\\sigma_\\eta^2).\n\\end{aligned}\n\\]\ndove:\n\n\n\\(y_{i,t}\\) è la risposta osservata (continua),\n\n\\(x_{i,t}\\) è il predittore osservato (continuo),\n\n\\(e_{i,t}\\) è l’errore con memoria AR(1),\n\n\\(\\phi\\) è l’autocorrelazione a lag 1 dei residui,\n\n\\(\\sigma_\\eta\\) controlla l’ampiezza del rumore “nuovo” che entra a ogni passo.\n\nIn altre parole, il valore osservato \\(y_{i,t}\\) è composto da:\n\nuna parte sistematicamente spiegata dal predittore \\(x_{i,t}\\), ponderata da \\(\\beta\\),\nuna parte casuale, \\(e_{i,t}\\), che però non è indipendente: conserva memoria del residuo precedente (\\(\\phi e_{i,t-1}\\)). Se ieri il modello ha sovrastimato, è probabile che anche oggi rimanga un residuo positivo; lo stesso vale per una sottostima.\n\n\nNota su \\(e_{i,0}\\). Per generare una serie “stazionaria”, inizializziamo il primo residuo dalla distribuzione stazionaria:\n\\[\ne_{i,0} \\sim \\mathcal N\\!\\left(0,\\; \\frac{\\sigma_\\eta^2}{1-\\phi^2}\\right).\n\\]\n\n\n# ---- Funzione di simulazione ----\nsimulate_reg_ar1 &lt;- function(alpha, beta = 0.8, phi = 0.7, sigma_eta = 1.0,\n                             T_ = 60, x_sd = 1, seed = 123) {\n  set.seed(seed)\n  n_subj &lt;- length(alpha)\n  rec &lt;- vector(\"list\", n_subj)\n\n  # Varianza stazionaria dei residui AR(1)\n  sigma_e2 &lt;- sigma_eta^2 / (1 - phi^2)\n\n  for (i in seq_len(n_subj)) {\n    e_prev &lt;- rnorm(1, mean = 0, sd = sqrt(sigma_e2))  # e_{i,0}\n    rows &lt;- vector(\"list\", T_)\n    for (t in seq_len(T_)) {\n      x_t &lt;- rnorm(1, 0, x_sd)             # predittore osservato\n      eta &lt;- rnorm(1, 0, sigma_eta)        # innovazione\n      e_t &lt;- phi * e_prev + eta            # residuo AR(1)\n      y_t &lt;- alpha[i] + beta * x_t + e_t   # risposta continua\n      rows[[t]] &lt;- data.frame(\n        subject = i, time = t,\n        x = x_t, e = e_t, y = y_t\n      )\n      e_prev &lt;- e_t\n    }\n    rec[[i]] &lt;- dplyr::bind_rows(rows)\n  }\n  dplyr::bind_rows(rec)\n}\n\n# ---- Parametri e simulazione ----\nalpha &lt;- c(-1, 0, 1)   # intercette soggetto-specifiche\nbeta  &lt;- 0.8           # effetto del predittore x\nphi   &lt;- 0.7           # autocorrelazione a lag 1 dei residui\nsigma_eta &lt;- 1.0       # deviazione standard innovazione\nT_    &lt;- 60            # lunghezza serie temporale\n\ndf &lt;- simulate_reg_ar1(alpha, beta, phi, sigma_eta, T_)\n\n# ---- Grafico didattico ----\ndf &lt;- df %&gt;%\n  group_by(subject) %&gt;%\n  mutate(x_scaled = (x - mean(x)) / sd(x) * sd(y) + mean(y)) %&gt;%\n  ungroup()\n\nggplot(df, aes(time)) +\n  geom_line(aes(y = y), linewidth = 0.9) +\n  geom_line(aes(y = x_scaled), linetype = \"dashed\") +\n  geom_hline(aes(yintercept = ave_y),\n             data = df %&gt;% group_by(subject) %&gt;% summarise(ave_y = mean(y)),\n             linewidth = 0.3, color = \"grey40\") +\n  facet_wrap(~ subject, ncol = 1,\n             labeller = as_labeller(function(s) {\n               i &lt;- as.integer(s)\n               paste0(\"Soggetto \", s, \" (alpha = \", alpha[i], \")\")\n             })) +\n  labs(title = \"Regressione con residui AR(1): y(t) e x(t) riscalato\",\n       subtitle = paste0(\"phi = \", phi, \", sigma_eta = \", sigma_eta, \", beta = \", beta),\n       y = \"y(t)  (x in tratteggio, riscalato)\", x = \"Tempo\")\n\n\n\n\n\n\n\n\n\nStruttura del modello\n\nLa parte regressiva è \\(\\alpha_i + \\beta x_{i,t}\\).\nLa memoria sta nei residui: \\(e_{i,t} = \\phi e_{i,t-1} + \\eta_{i,t}\\).\nCosì il predittore \\(x_{i,t}\\) è esogeno e \\(\\phi\\) ha un significato chiaro: è l’autocorrelazione tra residui consecutivi.\n\n\n\nGrafico a pannelli\n\nLinea piena = \\(y_{i,t}\\).\nTratteggio = \\(x_{i,t}\\), riscalato per confrontarlo visivamente con \\(y\\).\nSi vede che \\(y\\) segue \\(x\\), ma non cambia bruscamente: la presenza di \\(\\phi=0.7\\) rende la traiettoria più “liscia” grazie alla memoria nei residui.\n\n\n\n\n# ---- Verifica dell'AR(1) sui residui (soggetto 1) ----\ndf1 &lt;- df %&gt;% filter(subject == 1)\nols_fit &lt;- lm(y ~ x, data = df1)\nresid_ols &lt;- resid(ols_fit)\n\npar(mfrow = c(1, 2))\nplot(df1$time, resid_ols, type = \"l\", main = \"Residui OLS (soggetto 1)\",\n     xlab = \"Tempo\", ylab = \"Residuo\")\nacf(resid_ols, main = \"ACF residui OLS (soggetto 1)\")\n\n\n\n\n\n\npar(mfrow = c(1, 1))\n\n\nACF dei residui OLS\n\nNel modello di regressione lineare semplice \\(y \\sim x\\) si assume che i residui siano indipendenti. Nel nostro esempio, però, i residui hanno memoria AR(1): se ieri erano positivi, oggi tendono a esserlo di nuovo.\nL’ACF (autocorrelation function) dei residui ci permette di vedere questo effetto:\n\nmisura quanto i residui in tempi diversi sono correlati,\nil valore a lag 1 (tra residui consecutivi) è chiaramente positivo e vicino a \\(\\phi\\).\n\nQuindi:\n\nil modello lineare classico che assume residui indipendenti non descrive bene i dati,\noccorre un modello che includa la memoria, come l’AR(1) sui residui o un modello equivalente in stato-spazio.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Dal GLM a un modello processuale per dati binari</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03a_stan_logistic_process.html#dallar1-allark",
    "href": "chapters/glm/03a_stan_logistic_process.html#dallar1-allark",
    "title": "75  Dal GLM a un modello processuale per dati binari",
    "section": "\n75.4 Dall’AR(1) all’AR(K)",
    "text": "75.4 Dall’AR(1) all’AR(K)\nIl modello AR(1) ci ha mostrato che lo stato latente \\(u_{i,t}\\) non nasce mai da zero, ma porta con sé una traccia del passato immediato. Tuttavia, in molti processi psicologici questa “memoria a un passo” può essere troppo corta.\nPensiamo a situazioni in cui:\n\nl’effetto di un’esperienza non si esaurisce al trial successivo ma dura più a lungo,\nl’umore di oggi non dipende solo da quello di ieri, ma anche da quello di due o tre giorni fa,\nl’apprendimento si accumula su una coda di feedback estesa.\n\nIn questi casi conviene estendere il modello ad un processo autoregressivo di ordine \\(K\\) (AR(K)):\n\\[\nu_{i,t} = \\alpha_i\n        + \\mathbf{x}_{i,t}^\\top \\boldsymbol\\beta\n        + \\phi_1 u_{i,t-1}\n        + \\phi_2 u_{i,t-2}\n        + \\dots\n        + \\phi_K u_{i,t-K}\n        + \\eta_{i,t},\n\\qquad \\eta_{i,t} \\sim \\mathcal{N}(0,\\sigma_u).\n\\]\n\n75.4.1 Interpretazione psicologica\n\n\n\\(K=1\\) (AR(1)) → memoria cortissima: il presente dipende solo dallo stato immediatamente precedente (es. l’effetto diretto di un feedback appena ricevuto).\n\n\\(K=2\\) (AR(2)) → memoria breve: lo stato attuale risente degli ultimi due passi (es. l’umore influenzato dagli ultimi due giorni consecutivi).\n\n\\(K \\geq 3\\) → memoria più lunga: utile per processi cumulativi o ciclici (es. oscillazioni tra fasi di alta e bassa motivazione).\n\nIn altre parole, aumentando \\(K\\) allarghiamo la “finestra temporale” che il modello utilizza per spiegare il presente.\n\n75.4.2 Perché è utile?\nL’estensione ad AR(K) consente di modellare una gamma più ricca di dinamiche:\n\n\ninerzia semplice (AR(1)),\n\neffetti ritardati, che emergono dopo due o più step,\n\noscillazioni regolari o pattern ciclici (catturabili già con un AR(2) o AR(3)).\n\nCosì il modello diventa più flessibile e aderente alla complessità dei processi psicologici reali, nei quali la memoria del passato non ha sempre la stessa profondità, ma può essere breve, prolungata o ciclica.\n\n\n\n\n\n\nQuando usare modelli AR in psicologia?\n\nNei compiti decisionali con prove ripetute, quando sospettiamo che non solo l’ultima esperienza ma anche quelle precedenti influenzino la scelta.\nNegli studi EMA, quando l’umore o la motivazione di oggi risentono di più giorni consecutivi.\nIn generale, in tutti i casi in cui la sequenza temporale porta informazioni importanti che sarebbe un errore trattare come semplice rumore.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Dal GLM a un modello processuale per dati binari</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03a_stan_logistic_process.html#simulazione-dati",
    "href": "chapters/glm/03a_stan_logistic_process.html#simulazione-dati",
    "title": "75  Dal GLM a un modello processuale per dati binari",
    "section": "\n75.5 Simulazione dati",
    "text": "75.5 Simulazione dati\nPrima di stimare il modello su dati reali, conviene costruire un dataset simulato (AR(1) logit a livello latente). In questo modo possiamo verificare se il modello riesce a recuperare parametri noti e comprendere meglio il suo funzionamento.\nImmaginiamo \\(I=100\\) soggetti, ciascuno con \\(T=30\\) prove, e un predittore binario \\(x_{i,t}\\) (ad esempio: tipo di stimolo, 0 = neutro, 1 = emozionale). Lo stato latente \\(u_{i,t}\\) evolve come un AR(1) sulla scala logit.\n\nset.seed(123)\n\nI   &lt;- 100   # numero di soggetti\nTt  &lt;- 30    # numero di trial per soggetto\nN   &lt;- I*Tt  # osservazioni totali\n\n# Parametri \"veri\" usati per generare i dati\nalpha_mu    &lt;- 0.0   # intercetta media\nalpha_sigma &lt;- 0.7   # variabilità tra-soggetti\nbeta_true   &lt;- 0.6   # effetto del predittore\nphi_true    &lt;- 0.5   # persistenza dinamica\nsigma_u     &lt;- 0.6   # rumore di processo\n\n# Intercette soggetto-specifiche\nalpha_i &lt;- rnorm(I, alpha_mu, alpha_sigma)\n\n# Predittore binario (0/1) random\nx &lt;- rbinom(N, 1, 0.5)\n\n# Costruzione dataset\ndf &lt;- tibble::tibble(\n  id = rep(1:I, each = Tt),\n  t  = rep(1:Tt, times = I),\n  x  = x\n)\n\n# Stato latente e risposta\nu &lt;- numeric(N)\ny &lt;- integer(N)\n\nfor (i in 1:I) {\n  a  &lt;- alpha_i[i]\n  ui &lt;- numeric(Tt)\n  for (tt in 1:Tt) {\n    idx &lt;- (i-1)*Tt + tt\n    mean_ut &lt;- a + beta_true*df$x[idx] + ifelse(tt == 1, 0, phi_true*ui[tt-1])\n    ui[tt]  &lt;- rnorm(1, mean_ut, sigma_u)        # stato latente\n    p       &lt;- 1/(1 + exp(-ui[tt]))              # probabilità risposta\n    y[idx]  &lt;- rbinom(1, 1, p)                   # risposta binaria\n  }\n  u[((i-1)*Tt+1):(i*Tt)] &lt;- ui\n}\n\ndf$u_lat &lt;- u\ndf$y     &lt;- y\n\nIl modello ha bisogno di sapere quale osservazione viene prima nello stesso soggetto. Se non stiamo attenti, potremmo collegare l’ultimo trial del soggetto \\(i\\) con il primo del soggetto \\(i+1\\), il che è sbagliato. Per evitare errori, creiamo un indice prev che punta al trial precedente solo dello stesso soggetto. Se non esiste (primo trial), mettiamo 0.\n\ndf &lt;- df[order(df$id, df$t), ]\nprev &lt;- integer(nrow(df))\nfor (i in unique(df$id)) {\n  idx  &lt;- which(df$id == i)\n  prev[idx] &lt;- c(0, head(idx, -1))  # 0 = nessun precedente\n}\nstopifnot(all(df$t[prev[df$t&gt;1]] == df$t[df$t&gt;1]-1))\n\nEsempio: se il soggetto 5 ha 30 trial, per il trial 12 prev punterà al trial 11, mentre per il trial 1 avrà valore 0.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Dal GLM a un modello processuale per dati binari</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03a_stan_logistic_process.html#tabella-ponte-dallalgebra-a-stan",
    "href": "chapters/glm/03a_stan_logistic_process.html#tabella-ponte-dallalgebra-a-stan",
    "title": "75  Dal GLM a un modello processuale per dati binari",
    "section": "\n75.6 Tabella-ponte: dall’algebra a Stan",
    "text": "75.6 Tabella-ponte: dall’algebra a Stan\nPer tradurre il modello matematico in Stan, costruiamo una “mappa” dei concetti.\n\n\n\n\n\n\n\n\nConcetto\nSimbolo\nStan\nNota\n\n\n\nNumero osservazioni\n\\(N\\)\nint&lt;lower=1&gt; N;\n\n\n\nNumero soggetti\n\\(I\\)\nint&lt;lower=1&gt; I;\n\n\n\nSoggetto per trial\n—\narray[N] int&lt;lower=1,upper=I&gt; id;\n\n\n\nTrial precedente (stesso soggetto)\n—\narray[N] int&lt;lower=0,upper=N&gt; prev;\n0 se non esiste\n\n\nPredittori\n\\(\\mathbf{x}_{i,t}\\)\narray[N] int x;\nEstendibile a matrice\n\n\nRisposta\n\\(y_{i,t}\\)\narray[N] int y;\nBernoulli\n\n\nStato latente\n\\(u_{i,t}\\)\nvector[N] u;\n\n\n\nIntercetta soggetto\n\\(\\alpha_i\\)\n\nvector[I] alpha; (non centrato)\n\n\n\nPersistenza\n\\(\\phi\\)\nreal&lt;lower=-0.99,upper=0.99&gt; phi;\nvincolo stazionarietà\n\n\nRumore di processo\n\\(\\sigma_u\\)\nreal&lt;lower=0&gt; sigma_u;\ndeviazione standard",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Dal GLM a un modello processuale per dati binari</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03a_stan_logistic_process.html#modello-stan",
    "href": "chapters/glm/03a_stan_logistic_process.html#modello-stan",
    "title": "75  Dal GLM a un modello processuale per dati binari",
    "section": "\n75.7 Modello Stan",
    "text": "75.7 Modello Stan\nOra traduciamo il modello AR(1) logit in Stan. L’idea è di rappresentare esplicitamente tre parti del processo:\n\nIntercette soggetto-specifiche (\\(\\alpha_i\\)), stimate in forma non centrata per migliorare la mescolanza della catena.\n\nEvoluzione dello stato latente \\(u_{i,t}\\):\n\nal primo trial di ciascun soggetto, \\(u_{i,1}\\) dipende solo dall’intercetta, dai predittori e dal rumore;\nnei trial successivi, \\(u_{i,t}\\) dipende anche dal valore precedente \\(u_{i,t-1}\\), con peso \\(\\phi\\).\n\n\nLikelihood: la risposta osservata \\(y_{i,t}\\) segue una Bernoulli logit con parametro \\(u_{i,t}\\).\n\nInoltre, nel blocco generated quantities calcoliamo:\n\n\ny_rep = repliche simulate, utili per i posterior predictive check;\n\nlog_lik = contributi della verosimiglianza, necessari per il calcolo di LOO/WAIC.\n\nFormalmente, il modello implementato è:\n\\[\n\\begin{aligned}\nu_{i,1} &\\sim \\mathcal{N}(\\alpha_i + \\mathbf{x}_{i,1}^\\top \\beta, \\sigma_u), \\\\\nu_{i,t} &\\sim \\mathcal{N}(\\alpha_i + \\mathbf{x}_{i,t}^\\top \\beta + \\phi u_{i,t-1}, \\sigma_u) \\quad (t&gt;1), \\\\\ny_{i,t} \\mid u_{i,t} &\\sim \\text{Bernoulli}\\!\\left(\\operatorname{logit}^{-1}(u_{i,t})\\right).\n\\end{aligned}\n\\]\n\nstan_code &lt;- '\ndata{\n  int&lt;lower=1&gt; N;\n  int&lt;lower=1&gt; I;\n  array[N] int&lt;lower=1,upper=I&gt; id;\n  array[N] int&lt;lower=0,upper=1&gt; x;    // estendibile a vettore\n  array[N] int&lt;lower=0,upper=1&gt; y;\n  array[N] int&lt;lower=0,upper=N&gt; prev; // 0 se non esiste trial precedente dello stesso soggetto\n}\nparameters{\n  vector[I] alpha_raw;\n  real      alpha_mu;\n  real&lt;lower=0&gt; alpha_sigma;\n\n  real beta;\n  real&lt;lower=-0.99, upper=0.99&gt; phi;\n  real&lt;lower=0&gt; sigma_u;\n\n  vector[N] eps; // innovazioni standard N(0,1)\n}\ntransformed parameters{\n  vector[I] alpha = alpha_mu + alpha_sigma * alpha_raw;\n  vector[N] u;\n  for (n in 1:N){\n    real mean_u = alpha[id[n]] + beta * x[n];\n    if (prev[n] == 0) {\n      // opzionale: condizione stazionaria per il primo trial\n      real sd1 = sigma_u / sqrt(1 - square(phi));\n      u[n] = mean_u + sd1 * eps[n];\n    } else {\n      u[n] = mean_u + phi * u[prev[n]] + sigma_u * eps[n];\n    }\n  }\n}\nmodel{\n  // Priori più informative (vedi §2)\n  alpha_raw   ~ normal(0, 1);\n  alpha_mu    ~ normal(0, 0.5);\n  alpha_sigma ~ normal(0, 0.5);   // &lt;lower=0&gt; già impone metà-normale\n  beta        ~ normal(0, 0.5);\n  phi         ~ normal(0, 0.4);   // bounds già imposti\n  sigma_u     ~ normal(0, 0.5);   // metà-normale su sd\n\n  eps ~ normal(0,1);              // innovazioni standard\n  y ~ bernoulli_logit(u);\n}\ngenerated quantities{\n  array[N] int y_rep;\n  vector[N] log_lik;\n  for (n in 1:N){\n    y_rep[n] = bernoulli_logit_rng(u[n]);\n    log_lik[n] = bernoulli_logit_lpmf(y[n] | u[n]);\n  }\n}\n'\nstan_file &lt;- write_stan_file(stan_code)\n\nFocalizziamoci sul blocco di codice che costruisce la variabile latente dinamica \\(u_n\\) su cui poi si basa la likelihood logistica dei dati osservati \\(y_n\\).\nStruttura della likelihood. Il modello assume che la risposta osservata \\(y_n \\in \\{0,1\\}\\) derivi da una regressione logistica:\n\\[\ny_n \\sim \\text{Bernoulli}\\!\\left(\\operatorname{logit}^{-1}(u_n)\\right),\n\\]\ndove \\(u_n\\) è il predittore lineare dinamico che evolve nel tempo con memoria AR(1). In pratica, invece di avere un predittore statico \\(u_n = \\alpha_i + \\beta x_n\\), qui aggiungiamo una dipendenza dal passato: lo stato latente corrente dipende anche da quello precedente.\nCostruzione di \\(u_n\\) nel codice:\nfor (n in 1:N){\n  real mean_u = alpha[id[n]] + beta * x[n];\n  if (prev[n] == 0) {\n    // primo trial del soggetto\n    real sd1 = sigma_u / sqrt(1 - square(phi));\n    u[n] = mean_u + sd1 * eps[n];\n  } else {\n    // trial successivi\n    u[n] = mean_u + phi * u[prev[n]] + sigma_u * eps[n];\n  }\n}\n\n\nLinea 1. Calcoliamo il contributo sistematico del soggetto e del predittore:\n\\[\n\\texttt{mean\\_u} = \\alpha_{id[n]} + \\beta x_n.\n\\]\nQui \\(\\alpha_{id[n]}\\) è l’intercetta specifica del soggetto, mentre \\(\\beta x_n\\) è l’effetto del predittore osservato.\n\n\nCaso prev[n]==0. È il primo trial di quel soggetto. Non abbiamo uno stato precedente a cui agganciarci, quindi inizializziamo \\(u_n\\) assumendo la condizione stazionaria del processo AR(1):\n\\[\nu_n \\sim \\mathcal N\\!\\left(\\texttt{mean\\_u}, \\; \\frac{\\sigma_u^2}{1-\\phi^2}\\right).\n\\]\nQuesto è implementato come mean_u + sd1 * eps[n], dove eps[n] ~ Normal(0,1) e sd1 = sigma_u / sqrt{1 - phi^2}.\n\n\nCaso prev[n]!=0. È un trial successivo. In questo caso \\(u_n\\) dipende dal valore precedente \\(u_{prev[n]}\\):\n\\[\nu_n = \\texttt{mean\\_u} + \\phi \\, u_{prev[n]} + \\sigma_u \\, \\varepsilon_n,\n\\quad \\varepsilon_n \\sim \\mathcal N(0,1).\n\\]\nQui \\(\\phi\\) è il coefficiente AR(1) che controlla quanto del passato sopravvive nel presente.\n\n\nIntuizione:\n\n\n\\(\\alpha_i\\): propensione media del soggetto.\n\n\\(\\beta x_n\\): effetto del predittore osservato al trial \\(n\\).\n\n\\(\\phi u_{prev[n]}\\): memoria: se ieri \\(u\\) era alto, oggi tenderà a restare alto (se \\(\\phi&gt;0\\)).\n\n\\(\\sigma_u \\varepsilon_n\\): rumore nuovo che introduce variabilità tra un trial e l’altro.\n\nIl risultato finale è che la probabilità di risposta positiva è:\n\\[\n\\Pr(y_n=1) = \\operatorname{logit}^{-1}(u_n),\n\\]\ne l’intera likelihood del modello è:\n\\[\np(y \\mid \\alpha, \\beta, \\phi, \\sigma_u) = \\prod_{n=1}^N \\text{Bernoulli}\\!\\left(y_n \\,\\middle|\\, \\operatorname{logit}^{-1}(u_n)\\right),\n\\]\ndove ciascun \\(u_n\\) è costruito ricorsivamente come sopra.\nGenerazione dei dati di input:\n\nstan_dat &lt;- list(\n  N   = nrow(df),\n  I   = length(unique(df$id)),\n  id  = as.integer(df$id),\n  x   = as.array(as.integer(df$x)),\n  y   = as.array(as.integer(df$y)),\n  prev = as.array(prev)\n)\n\nCompilazione del modello:\n\nmod &lt;- cmdstanr::cmdstan_model(stan_file)\n\nCampionamento:\n\nfit &lt;- mod$sample(\n  data = stan_dat,\n  seed = 2024,\n  chains = 4, parallel_chains = 4,\n  iter_warmup = 1500, iter_sampling = 1500,\n  adapt_delta = 0.99,\n  max_treedepth = 15\n)\n\nRiassunto dei parametri chiave:\n\nfit$summary(c(\"alpha_mu\",\"alpha_sigma\",\"beta\",\"phi\",\"sigma_u\"))\n#&gt; # A tibble: 5 × 10\n#&gt;   variable     mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 alpha_mu     0.10   0.10  0.10  0.09 -0.05  0.27  1.00  1146.17  1890.42\n#&gt; 2 alpha_sigma  0.69   0.68  0.12  0.11  0.52  0.89  1.00   936.52  2046.04\n#&gt; 3 beta         0.61   0.61  0.09  0.09  0.46  0.77  1.00  2591.21  4164.98\n#&gt; 4 phi          0.49   0.50  0.07  0.07  0.37  0.60  1.00  1219.00  2733.87\n#&gt; 5 sigma_u      0.69   0.69  0.19  0.18  0.39  1.00  1.00   381.85   561.85\n\nLettura dei risultati.\nConfrontiamo i valori stimati con quelli usati nella simulazione:\n\n\\(\\alpha_\\mu\\) (vero = 0.0) → stimato ≈ 0.10. L’intercetta media è molto vicina al valore vero, con intervallo che comprende lo 0. La stima è quindi ben calibrata.\n\\(\\alpha_\\sigma\\) (vero = 0.7) → stimato ≈ 0.69. La variabilità tra soggetti è recuperata quasi perfettamente. Questo mostra che il modello distingue bene la propensione media dei soggetti dalle loro differenze individuali.\n\\(\\beta\\) (vero = 0.6) → stimato ≈ 0.61. L’effetto del predittore viene stimato con grande precisione, centrato sul valore vero.\n\\(\\phi\\) (vero = 0.5) → stimato ≈ 0.49. Anche il parametro di persistenza dinamica è correttamente recuperato: la memoria del passato è catturata in linea con i dati generati.\n\\(\\sigma_u\\) (vero = 0.6) → stimato ≈ 0.69. Il rumore di processo è leggermente sovrastimato, ma rimane molto vicino al valore usato nella simulazione.\n\nIn sintesi, il modello MCMC recupera in modo accurato tutti i parametri simulati. Le diagnostiche (Rhat ≈ 1, ESS elevati, nessuna divergenza) confermano che la catena ha esplorato bene lo spazio dei parametri.\n\n75.7.1 Diagnostica e Posterior Predictive Check\nUn passo fondamentale è confrontare i dati osservati con quelli simulati dal modello (y_rep). Se il modello è adeguato, le distribuzioni delle repliche devono sovrapporsi a quella dei dati reali.\n\nyrep_draws &lt;- fit$draws(\"y_rep\")\n\n# Converte in data.frame e poi in matrice\nyrep_df  &lt;- as_draws_df(yrep_draws)\nyrep_mat &lt;- as.matrix(yrep_df[, grepl(\"^y_rep\", names(yrep_df))])\n\n# proporzione osservata\nprop_obs &lt;- mean(stan_dat$y)\n\n# proporzioni replicate (una per draw)\nprop_rep &lt;- rowMeans(yrep_mat)\n\nppc_dens_overlay(y = stan_dat$y, yrep = yrep_mat[1:100, ])\n\n\n\n\n\n\n\nIl posterior predictive check mostra che la distribuzione dei dati simulati dal modello (y_rep) si sovrappone bene a quella dei dati osservati (y).\n\nLa densità osservata (linea nera) cade quasi sempre all’interno del ventaglio di densità replicate (linee colorate).\nQuesto significa che il modello riesce a generare dati che “assomigliano” a quelli reali, un segnale che la struttura autoregressiva AR(1) e i parametri stimati catturano i meccanismi principali del processo.\nSe vedessimo sistematiche discrepanze (ad esempio code troppo corte o una distribuzione spostata), sarebbe un campanello d’allarme che il modello è mal specificato o che mancano variabili importanti.\n\nIn sintesi: un buon PPC non prova che il modello sia vero, ma aumenta la fiducia che sia plausibile e che descriva i dati in modo coerente con le ipotesi teoriche.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Dal GLM a un modello processuale per dati binari</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03a_stan_logistic_process.html#confronto-con-glmm-logit-via-brm",
    "href": "chapters/glm/03a_stan_logistic_process.html#confronto-con-glmm-logit-via-brm",
    "title": "75  Dal GLM a un modello processuale per dati binari",
    "section": "\n75.8 Confronto con GLMM logit (via brm)",
    "text": "75.8 Confronto con GLMM logit (via brm)\nPer confronto abbiamo stimato lo stesso dataset con un GLM logit semplice in brm:\n\ndat &lt;- tibble(\n  y = as.numeric(stan_dat$y),\n  x = as.numeric(stan_dat$x),\n  id = as.numeric(stan_dat$id)\n)\n\n\n# ATTENZIONE: brms ignora la dipendenza seriale e l'eterogeneità nei trials!\nfit_glmer &lt;- brm(\n  y ~ x + (x | id),\n  data = dat,\n  family = bernoulli(link = \"logit\"),\n  prior = c(prior(normal(0, 1), class = \"b\")),\n  chains = 2, iter = 2000, seed = 123,\n  backend = \"cmdstanr\"\n)\n\n\nsummary(fit_glmer)\n#&gt;  Family: bernoulli \n#&gt;   Links: mu = logit \n#&gt; Formula: y ~ x + (x | id) \n#&gt;    Data: dat (Number of observations: 3000) \n#&gt;   Draws: 2 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 2000\n#&gt; \n#&gt; Multilevel Hyperparameters:\n#&gt; ~id (Number of levels: 100) \n#&gt;                  Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\n#&gt; sd(Intercept)        1.20      0.11     1.00     1.44 1.00      608\n#&gt; sd(x)                0.13      0.10     0.00     0.37 1.00      552\n#&gt; cor(Intercept,x)    -0.09      0.55    -0.95     0.92 1.00     2199\n#&gt;                  Tail_ESS\n#&gt; sd(Intercept)        1062\n#&gt; sd(x)                 821\n#&gt; cor(Intercept,x)     1438\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept     0.42      0.13     0.17     0.68 1.01      347      630\n#&gt; x             0.50      0.09     0.32     0.69 1.00     2547     1579\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n75.8.1 Interpretazione dei risultati brm\n\nIl modello multilevel logit con slope/intercetta casuali, \\(y \\sim x + (x \\mid id)\\), stima:\n\n\nIntercept = 0.42 (SE ≈ 0.13): log-odds media di risposta 1 quando \\(x=0\\), considerando la variabilità tra soggetti.\n\n\\(x = 0.50\\) (SE ≈ 0.09; 95% CI [0.32, 0.69]): effetto medio del predittore sulla log-odds, con pooling parziale tra soggetti.\n\nEterogeneità tra soggetti:\n\n\nsd(Intercept) ≈ 1.20: forte variabilità individuale nella propensione di base.\n\nsd(x) ≈ 0.13: variabilità più contenuta nell’effetto di \\(x\\).\n\ncor(Intercept, x) ≈ −0.09 con IC molto ampio: nessuna evidenza di relazione sistematica tra tendenza di base e sensibilità al predittore.\n\nIl modello, quindi, distingue l’effetto medio di \\(x\\) dalla notevole eterogeneità individuale, ma non rappresenta esplicitamente la dipendenza seriale tra prove.\n\n75.8.2 Confronto con Stan (modello processuale AR(1))\nIl modello AR(1) in Stan, stimato sugli stessi dati simulati, recupera accuratamente i valori veri:\n\n\n\\(\\beta \\approx 0.61\\) (vero = 0.60),\n\n\\(\\phi \\approx 0.49\\) (vero = 0.50),\n\n\\(\\alpha_\\sigma \\approx 0.69\\) (vero = 0.70),\n\n\\(\\sigma_u \\approx 0.69\\) (vero = 0.60).\n\nLa differenza principale riguarda l’effetto di \\(x\\):\n\nNel GLMM multilevel, \\(\\hat\\beta \\approx 0.50\\),\nNel modello processuale AR(1), \\(\\hat\\beta \\approx 0.61\\), perfettamente in linea con il valore vero.\n\nQuesto accade perché il modello brm controlla l’eterogeneità individuale ma non rappresenta la dinamica temporale: la memoria del passato (\\(\\phi\\)) resta non modellata e una parte della dipendenza seriale viene assorbita nelle stime delle varianze casuali o nell’effetto medio del predittore.\nIl modello in Stan, invece, separa esplicitamente il contributo del predittore (\\(\\beta\\)) dalla persistenza dinamica (\\(\\phi\\)) e dal rumore di processo (\\(\\sigma_u\\)), producendo stime più fedeli al meccanismo generativo.\n\n75.8.3 Messaggio chiave\n\nIl GLMM con slope/intercette casuali cattura bene l’eterogeneità tra soggetti, ma non la dipendenza temporale.\nIl modello AR(1) in Stan, introducendo la dinamica degli stati latenti, fornisce un effetto di \\(x\\) più vicino al valore vero e una rappresentazione più realistica del processo psicologico sottostante.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Dal GLM a un modello processuale per dati binari</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03a_stan_logistic_process.html#riflessioni-conclusive",
    "href": "chapters/glm/03a_stan_logistic_process.html#riflessioni-conclusive",
    "title": "75  Dal GLM a un modello processuale per dati binari",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo visto come estendere la regressione logistica a un quadro dinamico AR, capace di descrivere processi psicologici che evolvono nel tempo. Abbiamo imparato che:\n\nmodellare la dipendenza temporale è essenziale quando lavoriamo con dati sequenziali,\nStan consente di implementare questi modelli in modo flessibile,\ni modelli statici (come il GLMM logit) rischiano di dare stime distorte se la dinamica interna non è presa in considerazione.\n\nNei capitoli successivi potremo estendere questa logica ad altri processi cognitivi e decisionali, mostrando come la modellazione dinamica sia una chiave potente per passare dalla descrizione statistica alla spiegazione psicologica.\nQuesto passaggio dal GLMM al modello processuale mostra bene come i metodi bayesiani con Stan non servano solo a stimare parametri in modo diverso, ma a formulare nuove domande psicologiche, come per esempio: quanta memoria hanno i processi decisionali? Nei prossimi capitoli vedremo come ampliare questa prospettiva a modelli più complessi, in grado di catturare interazioni tra stati latenti e feedback ambientali.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Dal GLM a un modello processuale per dati binari</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03a_stan_logistic_process.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/glm/03a_stan_logistic_process.html#informazioni-sullambiente-di-sviluppo",
    "title": "75  Dal GLM a un modello processuale per dati binari",
    "section": "Informazioni sull’ambiente di sviluppo",
    "text": "Informazioni sull’ambiente di sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] insight_1.3.1         bayestestR_0.16.1     cmdstanr_0.9.0       \n#&gt;  [4] pillar_1.11.0         tinytable_0.11.0      patchwork_1.3.1      \n#&gt;  [7] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.13.0     \n#&gt; [10] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.0     \n#&gt; [13] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [16] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [19] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [22] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [25] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3        inline_0.3.21        sandwich_3.1-1      \n#&gt;  [4] rlang_1.1.6          magrittr_2.0.3       multcomp_1.4-28     \n#&gt;  [7] snakecase_0.11.1     compiler_4.5.1       vctrs_0.6.5         \n#&gt; [10] reshape2_1.4.4       stringr_1.5.1        pkgconfig_2.0.3     \n#&gt; [13] arrayhelpers_1.1-0   fastmap_1.2.0        backports_1.5.0     \n#&gt; [16] labeling_0.4.3       utf8_1.2.6           rmarkdown_2.29      \n#&gt; [19] ps_1.9.1             purrr_1.1.0          xfun_0.52           \n#&gt; [22] cachem_1.1.0         jsonlite_2.0.0       broom_1.0.9         \n#&gt; [25] parallel_4.5.1       R6_2.6.1             stringi_1.8.7       \n#&gt; [28] RColorBrewer_1.1-3   lubridate_1.9.4      estimability_1.5.1  \n#&gt; [31] knitr_1.50           zoo_1.8-14           pacman_0.5.1        \n#&gt; [34] Matrix_1.7-3         splines_4.5.1        timechange_0.3.0    \n#&gt; [37] tidyselect_1.2.1     abind_1.4-8          yaml_2.3.10         \n#&gt; [40] codetools_0.2-20     curl_6.4.0           processx_3.8.6      \n#&gt; [43] pkgbuild_1.4.8       plyr_1.8.9           lattice_0.22-7      \n#&gt; [46] withr_3.0.2          bridgesampling_1.1-2 coda_0.19-4.1       \n#&gt; [49] evaluate_1.0.4       survival_3.8-3       RcppParallel_5.1.10 \n#&gt; [52] tensorA_0.36.2.1     checkmate_2.3.2      stats4_4.5.1        \n#&gt; [55] distributional_0.5.0 generics_0.1.4       rprojroot_2.1.0     \n#&gt; [58] rstantools_2.4.0     scales_1.4.0         xtable_1.8-4        \n#&gt; [61] glue_1.8.0           emmeans_1.11.2       tools_4.5.1         \n#&gt; [64] data.table_1.17.8    mvtnorm_1.3-3        grid_4.5.1          \n#&gt; [67] QuickJSR_1.8.0       colorspace_2.1-1     nlme_3.1-168        \n#&gt; [70] cli_3.6.5            svUnit_1.0.6         Brobdingnag_1.2-9   \n#&gt; [73] V8_6.0.5             gtable_0.3.6         digest_0.6.37       \n#&gt; [76] TH.data_1.1-3        htmlwidgets_1.6.4    farver_2.1.2        \n#&gt; [79] memoise_2.0.1        htmltools_0.5.8.1    lifecycle_1.0.4     \n#&gt; [82] MASS_7.3-65",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Dal GLM a un modello processuale per dati binari</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03a_stan_logistic_process.html#bibliografia",
    "href": "chapters/glm/03a_stan_logistic_process.html#bibliografia",
    "title": "75  Dal GLM a un modello processuale per dati binari",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nChatfield, C., & Xing, H. (2019). The analysis of time series: an introduction with R. Chapman; hall/CRC.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Dal GLM a un modello processuale per dati binari</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html",
    "href": "chapters/entropy/01_entropy.html",
    "title": "76  Entropia e informazione di Shannon",
    "section": "",
    "text": "Introduzione\nL’entropia raggiunge il suo valore massimo quando la distribuzione è uniforme, cioè quando tutti gli eventi possibili hanno la stessa probabilità. In questo caso, nessun esito è più prevedibile di un altro. Quando invece le probabilità sono fortemente sbilanciate, alcuni eventi diventano molto più probabili di altri, e la nostra incertezza diminuisce.\nUn esempio aiuta a chiarire. Immaginiamo un sacchetto di palline. Se contiene soltanto palline rosse, la probabilità di estrarre il rosso è pari a 1 e quella di qualsiasi altro colore è 0: la distribuzione non è uniforme e l’entropia è zero, perché il risultato è certo. Se invece il sacchetto contiene tre colori in eguale quantità, ciascun colore ha probabilità 1/3 di essere estratto: questa è una distribuzione uniforme, nella quale l’incertezza è massima e così anche l’entropia.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>Entropia e informazione di Shannon</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#introduzione",
    "href": "chapters/entropy/01_entropy.html#introduzione",
    "title": "76  Entropia e informazione di Shannon",
    "section": "",
    "text": "In questo capitolo introdurremo il concetto di entropia, una misura centrale della teoria dell’informazione. L’entropia esprime, in termini quantitativi, l’incertezza media associata a una distribuzione di probabilità e, quindi, la quantità di informazione che ricaviamo quando un evento si verifica. Maggiore è l’imprevedibilità di un evento, maggiore è l’entropia; al contrario, quando l’esito è certo, l’entropia è minima.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>Entropia e informazione di Shannon</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#che-cosè-linformazione",
    "href": "chapters/entropy/01_entropy.html#che-cosè-linformazione",
    "title": "76  Entropia e informazione di Shannon",
    "section": "\n76.1 Che cos’è l’informazione?",
    "text": "76.1 Che cos’è l’informazione?\nUn bit è la quantità di informazione necessaria per distinguere tra due alternative ugualmente probabili. Ogni nuova decisione binaria raddoppia le possibilità. Il logaritmo in base 2 (\\(\\log_2\\)) ci dice quante decisioni binarie servono per distinguere un certo numero di alternative.\n\n\n\n\n\n\nEsempio visivo: incrocio stradale binario\n\n\n\nPer capire come l’informazione possa essere misurata in bit, consideriamo il seguente esempio. Immaginiamo di trovarci a un incrocio e di dover scegliere una strada tra due possibilità. Ogni volta che ci troviamo di fronte a un incrocio, dobbiamo prendere una decisione: andare a destra o a sinistra. Ogni decisione può essere rappresentata da un bit di informazione: 0 per la sinistra e 1 per la destra.\nConsideriamo il percorso con più incroci rappresentato nell’immagine seguente. Ogni percorso completo può essere codificato da una sequenza di bit, dove ogni bit corrisponde a una decisione (binaria) presa a un incrocio. Ad esempio, per raggiungere il punto D011, la sequenza di bit corretta è 011.\n\n\n\n\n\n\n\n\nQuanti bit sono necessari per identificare una destinazione specifica?\nOgni decisione aggiunge un bit alla sequenza che descrive il percorso.\nSe ci sono \\(m\\) destinazioni possibili, servono\n\\[\nn = \\log_2 m\n\\]\nbit per identificarne una in modo univoco.\nNel nostro esempio, abbiamo otto destinazioni finali. Pertanto, sono necessari 3 bit (3 decisioni binarie) per identificarne una in modo univoco.\nCosa rappresenta un bit in questo contesto?\nUn bit rappresenta un’unità elementare di informazione. In questo caso, ogni bit risponde alla domanda: “Devo andare a destra o a sinistra?”.\nPerché utilizziamo i logaritmi?\nIl logaritmo in base 2 ci permette di calcolare l’esponente a cui elevare 2 per ottenere un dato numero. In altre parole, ci indica quanti bit sono necessari per rappresentare un certo numero di destinazioni. Per l’esempio considerato, per arrivare a \\(D011\\) partendo da \\(A\\), sono necessarie 3 domande la cui risposta è binaria (destra/sinistra).\nPer riassumere:\n\nper raggiungere il punto D011 partendo da A, abbiamo bisogno di prendere tre decisioni binarie (sinistra o destra) in corrispondenza di tre incroci;\nogni decisione binaria può essere rappresentata da un bit (0 o 1). Quindi, per l’intero percorso, abbiamo bisogno di una sequenza di tre bit: 011;\nper rispondere alla domanda “Come si va da A a D011?”, abbiamo dunque bisogno di 3 bit di informazione.\n\nIn sintesi, esiste una relazione diretta tra il numero di bit di informazione e il numero di possibili destinazioni in un percorso decisionale binario. Ogni bit ci permette di scegliere tra due alternative, raddoppiando così il numero di possibili percorsi.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>Entropia e informazione di Shannon</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#la-sorpresa-e-linformazione-di-shannon",
    "href": "chapters/entropy/01_entropy.html#la-sorpresa-e-linformazione-di-shannon",
    "title": "76  Entropia e informazione di Shannon",
    "section": "\n76.2 La sorpresa e l’informazione di Shannon",
    "text": "76.2 La sorpresa e l’informazione di Shannon\nIntroduciamo ora un elemento fondamentale: la probabilità dell’evento. Quando due eventi hanno probabilità diverse, anche la quantità di informazione che trasmettono non è la stessa. Un evento molto probabile suscita poca sorpresa e, di conseguenza, veicola poca informazione. Al contrario, un evento raro produce una sorpresa maggiore e trasmette più informazione.\nShannon formalizzò questa intuizione definendo l’informazione – o “sorpresa” – di un evento \\(x\\) come\n\\[\nh(x) = \\log_2 \\frac{1}{p(x)} = -\\log_2 p(x) \\ \\text{bit}.\n\\tag{76.1}\\]\nQuesta espressione mostra chiaramente come l’informazione associata a un evento dipenda in modo inverso dalla sua probabilità: più l’evento è raro, maggiore sarà il valore di \\(h(x)\\).\nPer rendere l’idea, immaginiamo tre eventi con probabilità rispettivamente pari a 0.5, 0.25 e 0.10. Applicando la formula di Shannon, otteniamo che la sorpresa corrisponde rispettivamente a 1.00 bit, 2.00 bit e 3.32 bit. Si vede così che, man mano che la probabilità diminuisce, la quantità di informazione – misurata in bit – cresce. In altre parole, un’osservazione inattesa “pesa” di più, perché modifica in misura maggiore le nostre conoscenze sul sistema in esame.\n\n76.2.1 Entropia come media dell’informazione di Shannon\nFinora abbiamo considerato la sorpresa associata a un singolo evento. In molti casi, però, non ci interessa un esito isolato, ma vogliamo descrivere l’incertezza complessiva di un sistema che può produrre esiti diversi. Per farlo, occorre calcolare la sorpresa media tenendo conto di tutti i possibili risultati e delle rispettive probabilità. È proprio questo il significato dell’entropia.\nDal punto di vista matematico, l’entropia è la media pesata dell’informazione di Shannon di tutti i possibili esiti di una variabile casuale \\(X\\):\n\\[\nH(X) \\approx \\frac{1}{n} \\sum_{i=1}^{n} h(x_i).\n\\tag{76.2}\\]\nIn questa espressione, \\(h(x_i)\\) rappresenta la quantità di informazione trasmessa da un singolo esito \\(x_i\\), secondo la definizione di Shannon vista in precedenza. L’entropia non si riferisce dunque a un evento specifico, ma alla sorpresa media che ci aspettiamo di provare osservando ripetutamente la variabile.\nSe la distribuzione delle probabilità è perfettamente equilibrata – ad esempio in una distribuzione uniforme, dove tutti i risultati sono ugualmente probabili – l’entropia è massima, poiché ogni osservazione fornisce una quantità simile e relativamente alta di informazione. Se invece la distribuzione è sbilanciata – per esempio nel caso di una moneta truccata che dà quasi sempre “testa” – l’entropia è più bassa, perché la prevedibilità aumenta e la quantità media di informazione fornita da ciascuna osservazione diminuisce.\nIl grafico seguente illustra come la sorpresa di Shannon varia in funzione della probabilità di un evento: eventi rari producono un valore elevato di sorpresa, mentre eventi comuni producono un valore basso.\n\np_vals &lt;- seq(0.001, 1, by = 0.001)\nsurprise &lt;- -log2(p_vals)\n\nggplot(data.frame(p = p_vals, h = surprise), aes(x = p, y = h)) +\n  geom_line(color = \"blue\", size = 1) +\n  labs(\n    title = \"Sorpresa di Shannon in funzione della probabilità\",\n    x = \"Probabilità dell'evento p(x)\",\n    y = \"Sorpresa h(x) [bit]\"\n  ) \n\n\n\n\n\n\n\n\n76.2.2 Interpretazione dell’entropia\nDiamo ora un significato concreto al valore numerico dell’entropia. Poiché essa rappresenta la media della sorpresa attesa osservando la realizzazione di una variabile casuale, tenendo conto di tutti i possibili esiti e delle loro probabilità, può essere interpretata come il numero medio di bit necessari per descrivere un’osservazione della variabile \\(X\\).\nQuando l’entropia è espressa in bit, possiamo tradurla in un numero equivalente di alternative equiprobabili utilizzando la relazione\n\\[\nm = 2^{H(X)} .\n\\tag{76.3}\\]\nQuesto significa che un’entropia di \\(H(X)\\) bit corrisponde alla stessa incertezza che avremmo se dovessimo distinguere tra \\(m\\) esiti tutti ugualmente probabili. In questo senso, l’entropia misura la quantità di informazione contenuta in una variabile, esprimendola in termini del numero di scelte equiprobabili che la variabile potrebbe assumere.\n\n\n76.2.2.1 Esercizio — Interpretazione dell’entropia.\n1. Caso di riferimento: moneta equa.\nSe una variabile casuale può assumere due valori ugualmente probabili, come una moneta equa con \\(p(\\text{testa}) = p(\\text{croce}) = 0.5\\), la sua entropia è:\n\\[\nH(X) = 0.5 \\log_2\\frac{1}{0.5} + 0.5 \\log_2\\frac{1}{0.5}\n      = 0.5 \\times 1 + 0.5 \\times 1\n      = 1 \\ \\text{bit}.\n\\]\nQuesto è il valore massimo di entropia per una variabile con due soli esiti: 1 bit è l’informazione necessaria per distinguere tra due alternative equiprobabili.\n2. Moneta sbilanciata: singolo lancio.\nQuando la moneta è sbilanciata, l’informazione media diminuisce. Supponiamo \\(p(\\text{testa}) = 0.9\\) e \\(p(\\text{croce}) = 0.1\\).\nLa sorpresa associata a ciascun esito è:\n\\[\nh(\\text{testa}) = \\log_2\\frac{1}{0.9} \\approx 0.15 \\ \\text{bit},\n\\]\n\\[\nh(\\text{croce}) = \\log_2\\frac{1}{0.1} \\approx 3.32 \\ \\text{bit}.\n\\]\nPesando queste sorprese con le rispettive probabilità otteniamo l’entropia media:\n\\[\nH(X) = 0.9 \\times 0.15 + 0.1 \\times 3.32 \\approx 0.469 \\ \\text{bit}.\n\\]\nQuesta entropia è inferiore a 1 bit, nonostante l’esito raro (“croce”) sia molto più sorprendente di quello di una moneta equa. In generale, nessuna moneta sbilanciata può avere un’entropia media superiore a quella di una moneta equa.\n3. Più lanci: interpretazione pratica.\nSe lanciamo questa moneta 1000 volte, l’informazione totale prodotta sarà:\n\\[\n1000 \\times 0.469 \\approx 469 \\ \\text{bit}.\n\\]\nQuindi, rispetto alla moneta equa (1000 bit), otteniamo meno della metà dell’informazione.\n4. Numero equivalente di alternative equiprobabili.\nL’entropia può essere anche interpretata come il numero equivalente di alternative tutte equiprobabili:\n\\[\nm = 2^{H(X)} = 2^{0.469} \\approx 1.38.\n\\]\nQuesto non significa che esista un dado fisico con 1.38 facce: è solo un modo per dire che la quantità di incertezza media di questa moneta è la stessa di una variabile che può assumere circa 1.38 valori tutti con la stessa probabilità.\n\n# Funzione per calcolare l'entropia di una moneta\nentropy_coin &lt;- function(p) {\n  ifelse(p == 0 | p == 1, 0,\n         -p * log2(p) - (1 - p) * log2(1 - p))\n}\n\n# Sequenza di probabilità\np_values &lt;- seq(0, 1, by = 0.01)\nH_values &lt;- entropy_coin(p_values)\n\n# Dati per i punti di esempio\npoints_df &lt;- data.frame(\n  p = c(0.5, 0.9),\n  H = entropy_coin(c(0.5, 0.9)),\n  label = c(\"Moneta equa\\nH=1 bit\", \"Moneta sbilanciata\\nH=0.469 bit\")\n)\n\n# Grafico\nggplot(data.frame(p = p_values, H = H_values), aes(x = p, y = H)) +\n  geom_line(color = \"blue\", size = 1) +\n  geom_point(data = points_df, aes(x = p, y = H), color = \"red\", size = 3) +\n  geom_text(data = points_df, aes(label = label), vjust = -1, hjust = 0.5) +\n  labs(\n    title = \"Entropia di una moneta in funzione di p(testa)\",\n    x = expression(paste(\"Probabilità di testa, \", p)),\n    y = \"Entropia H(X) [bit]\"\n  )\n\n\n\n\n\n\n\n\n\n\n76.2.3 Caratteristiche dell’entropia\nL’entropia raggiunge il suo valore massimo quando tutti gli esiti possibili hanno la stessa probabilità di verificarsi. In questa condizione, l’incertezza è totale: non esiste alcun indizio che permetta di prevedere il risultato meglio del puro caso, e il grado di imprevedibilità è al massimo.\nAll’opposto, l’entropia è minima quando l’esito è completamente certo, cioè quando un evento ha probabilità pari a 1 e tutti gli altri hanno probabilità pari a 0. In tali circostanze non vi è alcuna incertezza, nessuna sorpresa e quindi nessuna informazione aggiuntiva ottenibile dall’osservazione.\nUn’ulteriore caratteristica fondamentale è l’additività per eventi indipendenti: quando due o più eventi sono indipendenti, l’entropia complessiva della loro combinazione è pari alla somma delle entropie dei singoli eventi. Questa proprietà deriva direttamente dall’additività dei logaritmi nella formula di Shannon e riflette il fatto che, nel caso di eventi indipendenti, l’incertezza complessiva si ottiene sommando le incertezze prodotte da ciascun evento considerato separatamente.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>Entropia e informazione di Shannon</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#stimare-lentropia",
    "href": "chapters/entropy/01_entropy.html#stimare-lentropia",
    "title": "76  Entropia e informazione di Shannon",
    "section": "\n76.3 Stimare l’entropia",
    "text": "76.3 Stimare l’entropia\nNelle sezioni precedenti abbiamo visto che l’entropia esprime la sorpresa media attesa quando osserviamo una variabile casuale, ed è strettamente legata all’informazione di Shannon dei singoli eventi. Passiamo ora dal concetto alla sua applicazione pratica, illustrando come calcolare l’entropia sia a partire da una distribuzione di probabilità teorica, sia da un insieme di dati osservati.\n\n76.3.1 Stimare l’entropia da una distribuzione di probabilità\nConsideriamo una variabile casuale discreta \\(X\\), che può assumere un insieme di valori distinti \\(x_1, x_2, \\dots, x_n\\), ciascuno con una probabilità associata \\(p(x) = \\Pr\\{X = x\\}\\). L’entropia \\(H(X)\\) misura l’incertezza complessiva della distribuzione di probabilità e si calcola come\n\\[\nH(X) = -\\sum_{x \\in X} p(x) \\log_2 p(x) .\n\\tag{76.4}\\]\nQuesta formula combina in un’unica media pesata la sorpresa di ciascun esito, dove la sorpresa di un evento \\(x\\) è \\(-\\log_2 p(x)\\). Il segno negativo è necessario perché i logaritmi di numeri minori di 1 sono negativi; in questo modo, l’informazione viene espressa come quantità positiva.\nOgni termine \\(-p(x) \\log_2 p(x)\\) rappresenta dunque l’informazione media fornita da un singolo esito, pesata in base alla sua probabilità. Una distribuzione uniforme, in cui tutti gli esiti sono ugualmente probabili, massimizza questa media e quindi l’entropia. Al contrario, quando alcuni esiti sono molto più probabili di altri, l’entropia si riduce, riflettendo una minore incertezza complessiva.\nIn sintesi, \\(H(X)\\) fornisce il numero medio di bit necessari per descrivere un’osservazione di \\(X\\), equivalente all’incertezza media che ci si aspetta quando si estrae un esito a caso da questa distribuzione.\n\n\n\n\n\n\nEsercizio — Entropia di un dado con otto facce.\n\n\n\n\n\nSupponiamo di avere un dado con otto facce. Ci sono \\(m = 8\\) esiti possibili:\n\\[\nA_x = \\{1,2,3,4,5,6,7,8\\}.\n\\]\nPoiché il dado è equo, tutti gli otto esiti hanno la stessa probabilità di \\(p(x) = 1/8\\), definendo così una distribuzione di probabilità uniforme:\n\\[\np(X) = \\left\\{\\frac{1}{8}, \\frac{1}{8}, \\frac{1}{8}, \\frac{1}{8}, \\frac{1}{8}, \\frac{1}{8}, \\frac{1}{8}, \\frac{1}{8}\\right\\}.\n\\]\nL’entropia di questa distribuzione può essere calcolata come:\n\\[\nH(X) = - \\sum_{i=1}^{8} \\frac{1}{8} \\log_2 \\frac{1}{8} = \\log_2 8 = 3 \\text{ bit}.\n\\]\nPoiché l’informazione associata a ciascun esito è esattamente 3 bit, anche l’entropia media è di 3 bit, che rappresenta l’incertezza complessiva della variabile \\(X\\).\nDato che \\(X\\) ha un’entropia di \\(H(X) = 3\\) bit, possiamo dire che \\(X\\) può rappresentare fino a:\n\\[\nm = 2^{H(X)} = 2^3 = 8\n\\]\nesiti equiprobabili.\n\n\n\n\n\n\n\n\n\nEsercizio — Entropia di un variabile casuale discreta.\n\n\n\n\n\nSia \\(X\\) una variabile casuale discreta che può assumere i valori \\(a, b, c,\\) e \\(d\\) con una distribuzione di probabilità di massa \\(p(a) = \\frac{1}{2}\\), \\(p(b) = \\frac{1}{4}\\), \\(p(c) = \\frac{1}{8}\\), e \\(p(d) = \\frac{1}{8}\\), rispettivamente. L’entropia di \\(X\\), che misura l’incertezza associata alla distribuzione di probabilità, è calcolata come:\n\\[\nH(X) = -\\left(\\frac{1}{2} \\log_2 \\frac{1}{2} + \\frac{1}{4} \\log_2 \\frac{1}{4} + \\frac{1}{8} \\log_2 \\frac{1}{8} + \\frac{1}{8} \\log_2 \\frac{1}{8}\\right).\n\\]\nCalcolando i singoli termini, otteniamo:\n\\[\nH(X) = -\\left(\\frac{1}{2} \\cdot (-1) + \\frac{1}{4} \\cdot (-2) + \\frac{1}{8} \\cdot (-3) + \\frac{1}{8} \\cdot (-3)\\right) = \\frac{7}{4} \\text{ bits}.\n\\]\nÈ importante notare che l’entropia \\(H(X)\\) dipende esclusivamente dalla distribuzione di probabilità dei valori di \\(X\\) e non dai valori stessi.\n\n\n\n\n76.3.2 Stimare l’entropia in un campione di osservazioni\nFinora abbiamo considerato il caso in cui la distribuzione di probabilità sia nota a priori. Nella pratica della ricerca psicologica, tuttavia, disponiamo spesso soltanto di un campione di osservazioni. In questo caso possiamo stimare l’entropia calcolando le frequenze relative di ciascun valore osservato e utilizzandole come stima empirica delle probabilità.\nIl risultato misura quanto la distribuzione dei valori nel campione sia incerta o imprevedibile. Un campione in cui le frequenze siano simili per tutti i valori possibili mostrerà un’entropia stimata elevata; al contrario, se nel campione un valore domina nettamente sugli altri, l’entropia stimata sarà bassa, indicando una distribuzione più prevedibile.\n\n\n\n\n\n\nEsercizio — Entropia di un campione di osservazioni.\n\n\n\n\n\nPer comprendere meglio questo concetto, possiamo calcolare l’entropia associata a insiemi di osservazioni. Consideriamo i due vettori seguenti:\n\\[\n\\begin{align}\nx &= \\{1, 2, 3, 3, 3, 3, 2, 1, 3, 3, 2, 1, 1, 4, 4, 3, 1, 2\\}, \\notag\\\\\ny &= \\{3, 4, 1, 1, 1, 1, 4, 3, 1, 1, 4, 3, 3, 2, 2, 1, 3, 4\\}. \\notag\n\\end{align}\n\\]\nTroviamo l’entropia associata a ciascuno di essi.\n\n# Vettori x e y\nx &lt;- c(1, 2, 3, 3, 3, 3, 2, 1, 3, 3, 2, 1, 1, 4, 4, 3, 1, 2)\ny &lt;- c(3, 4, 1, 1, 1, 1, 4, 3, 1, 1, 4, 3, 3, 2, 2, 1, 3, 4)\n\n# Conta le frequenze\nx_counts &lt;- table(x)\ny_counts &lt;- table(y)\n\n# Calcola le probabilità relative\nx_probabilities &lt;- as.numeric(x_counts) / length(x)\ny_probabilities &lt;- as.numeric(y_counts) / length(y)\n\n# Funzione per calcolare l'entropia (log in base 2)\ncalculate_entropy &lt;- function(probabilities) {\n  -sum(probabilities * log2(probabilities))\n}\n\n# Calcolo dell'entropia\nx_entropy &lt;- calculate_entropy(x_probabilities)\ny_entropy &lt;- calculate_entropy(y_probabilities)\n\n# Stampa i risultati\ncat(sprintf(\"Entropia di x: %.4f bit\\n\", x_entropy))\n#&gt; Entropia di x: 1.8776 bit\ncat(sprintf(\"Entropia di y: %.4f bit\\n\", y_entropy))\n#&gt; Entropia di y: 1.8776 bit\n\nEntrambi i vettori hanno la stessa entropia di 1.8776 bit.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>Entropia e informazione di Shannon</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#entropia-di-una-variabile-casuale-continua",
    "href": "chapters/entropy/01_entropy.html#entropia-di-una-variabile-casuale-continua",
    "title": "76  Entropia e informazione di Shannon",
    "section": "\n76.4 Entropia di una variabile casuale continua",
    "text": "76.4 Entropia di una variabile casuale continua\nPer le variabili casuali continue, il concetto di entropia si estende naturalmente a partire dal caso discreto, sostituendo la somma con un integrale. Questa generalizzazione è necessaria perché una variabile continua può assumere un numero infinito di valori all’interno di un intervallo, e le probabilità puntuali diventano nulle; ciò che conta è la densità di probabilità nei vari punti del dominio.\nPer una variabile casuale continua \\(X\\), con funzione di densità di probabilità \\(p(x)\\), l’entropia – in questo contesto detta entropia differenziale – è definita da\n\\[\nH(X) = -\\int p(x) \\log_2 p(x) \\, dx ,\n\\]\ndove \\(p(x)\\) rappresenta la densità di probabilità di \\(X\\) e l’integrale è calcolato su tutto il dominio della variabile.\nCome nel caso discreto, l’entropia differenziale fornisce una misura dell’incertezza media associata alla distribuzione di probabilità. Una densità molto concentrata – per esempio una distribuzione con picchi stretti – indica bassa entropia, perché la variabile è relativamente prevedibile. Al contrario, una densità più “sparsa” e distribuita uniformemente implica un’entropia più alta, segnalando maggiore imprevedibilità.\nIl segno negativo nella formula deriva dal fatto che, per probabilità comprese tra 0 e 1, il logaritmo è negativo: in questo modo l’entropia assume valori positivi e può essere interpretata, come nel caso discreto, come il numero medio di bit necessari per descrivere un’osservazione di \\(X\\).\n\n\n\n\n\n\nEsercizio — Un confronto numerico: normali più “strette” e più “larghe”.\n\n\n\n\n\nPer la distribuzione normale \\(X \\sim \\mathcal N(\\mu,\\sigma^2)\\) l’entropia differenziale ha una forma chiusa:\n\\[\nH(X)=\\tfrac12 \\log_2\\!\\big(2\\pi e\\,\\sigma^2\\big)\\ \\text{bit}.\n\\]\nLa dipendenza è tutta nella scala \\(\\sigma\\): raddoppiare \\(\\sigma\\) aggiunge esattamente 1 bit di entropia, perché la massa di probabilità si “spalma” su un intervallo più ampio. Numericamente, con \\(\\sigma=0{,}5\\), \\(H(X)\\approx 1{,}047\\) bit; con \\(\\sigma=1\\), \\(H(X)\\approx 2{,}047\\) bit; con \\(\\sigma=2\\), \\(H(X)\\approx 3{,}047\\) bit. L’aumento regolare di un bit per ogni raddoppio di \\(\\sigma\\) rende molto trasparente l’idea che una densità più concentrata (piccola \\(\\sigma\\)) produce minore incertezza, mentre una densità più diffusa (grande \\(\\sigma\\)) produce maggiore incertezza.\nEcco un frammento R che replica il calcolo e mostra le tre densità normalizzate sulla stessa scala, così che la relazione tra forma della densità e entropia sia visibile a colpo d’occhio.\n\n# Entropia differenziale (in bit) per N(mu, sigma^2)\nh_norm_bits &lt;- function(sigma) 0.5 * log2(2 * pi * exp(1) * sigma^2)\n\nsigmas &lt;- c(0.5, 1, 2)\nentropie &lt;- sapply(sigmas, h_norm_bits)\nround(entropie, 3)\n#&gt; [1] 1.047 2.047 3.047\n# atteso: 1.047, 2.047, 3.047\n\n# Visualizzazione delle densità\ndf &lt;- data.frame(\n  x = rep(seq(-6, 6, length.out = 1000), times = length(sigmas)),\n  sigma = factor(rep(sigmas, each = 1000))\n)\ndf$dens &lt;- mapply(function(x, s) dnorm(x, mean = 0, sd = s), df$x, as.numeric(as.character(df$sigma)))\n\nggplot(df, aes(x = x, y = dens, group = sigma)) +\n  geom_line(aes(linetype = sigma), linewidth = 1) +\n  labs(\n    title = \"Densità normali con diversa scala e relativa entropia\",\n    subtitle = paste0(\"H(σ=0.5)≈\", round(entropie[1],3), \" bit; \",\n                      \"H(σ=1)≈\",   round(entropie[2],3), \" bit; \",\n                      \"H(σ=2)≈\",   round(entropie[3],3), \" bit\"),\n    x = \"x\", y = \"densità\"\n  ) \n\n\n\n\n\n\n\nNell’analisi di dati psicologici, la stessa variabile misurata con una scala più “compressa” (varianza più piccola, punteggi concentrati) porta a una minore entropia differenziale rispetto alla stessa variabile osservata con maggiore dispersione. Questo legame diretto tra dispersione e entropia chiarisce perché, in presenza di eterogeneità individuale o situazionale, la “quantità di incertezza” da descrivere aumenti con la variabilità del fenomeno.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>Entropia e informazione di Shannon</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#la-codifica-di-huffman",
    "href": "chapters/entropy/01_entropy.html#la-codifica-di-huffman",
    "title": "76  Entropia e informazione di Shannon",
    "section": "\n76.5 La codifica di Huffman",
    "text": "76.5 La codifica di Huffman\nNelle sezioni precedenti abbiamo visto che l’entropia di una variabile casuale \\(X\\) misura la sorpresa media attesa quando osserviamo un suo esito e che può essere interpretata come la lunghezza media più breve, in bit, di un codice binario ottimale per rappresentare tali esiti. L’algoritmo di Huffman fornisce un metodo pratico per costruire un codice che si avvicina a questo limite teorico.\nIl principio è intuitivo: se dobbiamo trasmettere un messaggio composto da simboli con probabilità diverse, conviene assegnare codici più brevi ai simboli frequenti e codici più lunghi a quelli rari. In questo modo si riduce la lunghezza media complessiva del messaggio, in linea con ciò che la formula dell’entropia suggerisce.\nPer costruire una codifica di Huffman, si parte dalle frequenze (o probabilità) dei simboli. Si crea un nodo per ciascun simbolo e, in modo iterativo, si uniscono i due nodi meno probabili in un nuovo nodo la cui frequenza è la somma delle due. Il procedimento continua finché tutti i simboli confluiscono in un’unica radice. A questo punto si assegna lo 0 ai rami sinistri e l’1 ai rami destri: il codice di un simbolo è la sequenza di bit dal nodo radice alla foglia corrispondente. Il risultato è un codice prefisso (nessun codice è l’inizio di un altro), senza perdita di informazione e ottimale tra tutti i codici che usano un numero intero di bit per simbolo.\n\n76.5.1 Esempio di costruzione\nSupponiamo di avere quattro simboli con le frequenze riportate in tabella:\n\n\nSimbolo\nFrequenza\n\n\n\nA\n20\n\n\nB\n10\n\n\nC\n8\n\n\nD\n5\n\n\n\nIl procedimento di Huffman procede così:\n\n(D:5) e (C:8) → uniti in (DC:13)\n(B:10) e (DC:13) → uniti in (BDC:23)\n(A:20) e (BDC:23) → uniti in (ABDC:43)\n\nL’albero risultante è il seguente:\n       (43)\n      /    \\\n    (20)   (23)\n     A     /   \\\n         (10)  (13)\n          B    /  \\\n              D    C\nAssegnando 0 a sinistra e 1 a destra, otteniamo:\n\n\nSimbolo\nCodice Huffman\n\n\n\nA\n0\n\n\nB\n10\n\n\nD\n110\n\n\nC\n111\n\n\n\nCome previsto, il simbolo più frequente (A) ha il codice più corto, mentre i meno frequenti (C e D) hanno codici più lunghi.\n\n76.5.2 Collegamento con l’entropia\nConsideriamo ora le probabilità \\(p(A)=0.4\\), \\(p(B)=0.3\\), \\(p(C)=0.2\\), \\(p(D)=0.1\\). Con la codifica sopra, la lunghezza media del codice è:\n\\[\n(0.4 \\times 1) + (0.3 \\times 2) + (0.2 \\times 3) + (0.1 \\times 3) = 1.9 \\ \\text{bit}.\n\\]\nL’entropia teorica della variabile è:\n\\[\nH(X) = -[0.4 \\log_2 0.4 + 0.3 \\log_2 0.3 + 0.2 \\log_2 0.2 + 0.1 \\log_2 0.1] \\approx 1.8465 \\ \\text{bit}.\n\\]\nIl valore di Huffman (1.9 bit) è leggermente superiore a \\(H(X)\\) perché l’entropia può assumere valori decimali, mentre Huffman utilizza lunghezze intere di bit per simbolo. Nonostante questa piccola differenza, la codifica di Huffman è quasi ottimale e si avvicina al limite teorico imposto dall’entropia.\nIn altre parole, l’entropia rappresenta la lunghezza media minima teorica per codificare senza perdita un insieme di simboli, mentre Huffman traduce questa teoria in un algoritmo concreto che raggiunge, nei limiti imposti dall’uso di bit interi, la massima efficienza possibile.\n\n\n\n\n\n\nEsercizio — Entropia e codifica di Huffman.\n\n\n\n\n\nSupponiamo di avere una variabile casuale \\(X\\) che può assumere quattro valori: \\(A\\), \\(B\\), \\(C\\), e \\(D\\), con le seguenti probabilità:\n\n\\(p(A) = 0.4\\)\n\\(p(B) = 0.3\\)\n\\(p(C) = 0.2\\)\n\\(p(D) = 0.1\\)\n\nPer rappresentare questi esiti con un codice binario efficiente possiamo usare la codifica di Huffman, che assegna codici più brevi ai simboli più probabili, e codici più lunghi a quelli meno probabili.\nSupponiamo che Huffman produca la seguente codifica:\n\nA = 0 (1 bit)\nB = 10 (2 bit)\nC = 110 (3 bit)\nD = 111 (3 bit)\n\nLa lunghezza media del codice si ottiene moltiplicando la probabilità di ciascun simbolo per la lunghezza del suo codice binario, e poi sommando:\n\\[\n\\begin{align}\n\\text{Lunghezza media} &= (0.4 \\times 1) + (0.3 \\times 2) + (0.2 \\times 3) + (0.1 \\times 3) \\\\\n&= 0.4 + 0.6 + 0.6 + 0.3 = 1.9 \\text{ bit}.\n\\end{align}\n\\]\nQuesto significa che, in media, servono 1.9 bit per rappresentare un’osservazione della variabile \\(X\\) usando la codifica di Huffman.\nConfermiamo il risultato con il seguente codice R:\n\n# Definizione delle probabilità\nprobabilities &lt;- list(A = 0.4, B = 0.3, C = 0.2, D = 0.1)\n\n\n# Funzione per la codifica di Huffman\nhuffman_encoding &lt;- function(probabilities) {\n  nodes &lt;- lapply(names(probabilities), function(sym) {\n    list(symbol = sym, prob = probabilities[[sym]], left = NULL, right = NULL)\n  })\n\n  while (length(nodes) &gt; 1) {\n    nodes &lt;- nodes[order(sapply(nodes, function(n) n$prob))]\n    left &lt;- nodes[[1]]\n    right &lt;- nodes[[2]]\n    merged &lt;- list(symbol = NULL, prob = left$prob + right$prob, left = left, right = right)\n    nodes &lt;- c(nodes[-c(1, 2)], list(merged))\n  }\n\n  assign_codes &lt;- function(node, prefix = \"\", code_map = list()) {\n    if (!is.null(node$symbol)) {\n      code_map[[node$symbol]] &lt;- prefix\n    } else {\n      code_map &lt;- assign_codes(node$left, paste0(prefix, \"0\"), code_map)\n      code_map &lt;- assign_codes(node$right, paste0(prefix, \"1\"), code_map)\n    }\n    return(code_map)\n  }\n\n  code_map &lt;- assign_codes(nodes[[1]])\n\n  avg_length &lt;- sum(sapply(names(probabilities), function(sym) {\n    probabilities[[sym]] * nchar(code_map[[sym]])\n  }))\n\n  return(list(avg_length = avg_length, huffman_dict = code_map))\n}\n\n\n# Applicazione e stampa dei risultati\nresult &lt;- huffman_encoding(probabilities)\n\ncat(sprintf(\"Lunghezza media del codice di Huffman: %.2f bit/simbolo\\n\", result$avg_length))\n#&gt; Lunghezza media del codice di Huffman: 1.90 bit/simbolo\ncat(\"Codici di Huffman:\\n\")\n#&gt; Codici di Huffman:\nfor (sym in names(result$huffman_dict)) {\n  cat(sprintf(\"%s: %s\\n\", sym, result$huffman_dict[[sym]]))\n}\n#&gt; A: 0\n#&gt; B: 10\n#&gt; D: 110\n#&gt; C: 111\n\nOra calcoliamo l’entropia teorica della variabile \\(X\\), cioè la lunghezza media minima che qualsiasi codifica binaria può raggiungere:\n\\[\n\\begin{align}\nH(X) &= - \\sum p(x) \\log_2 p(x) \\\\\n     &= -[0.4 \\log_2 0.4 + 0.3 \\log_2 0.3 + 0.2 \\log_2 0.2 + 0.1 \\log_2 0.1] \\\\\n     &= 1.8465 \\text{ bit}.\n\\end{align}\n\\]\nIl valore dell’entropia è leggermente inferiore alla lunghezza media di Huffman (1.9 bit). Questo è normale: Huffman fornisce codici con lunghezza intera in bit, mentre l’entropia può assumere valori decimali. La codifica di Huffman è quindi quasi ottimale.\nIn sintesi:\n\n\nl’entropia \\(H(X)\\) rappresenta la lunghezza media teorica minima (in bit) per codificare una variabile casuale;\nla codifica di Huffman costruisce un codice binario che si avvicina molto a questo limite, usando più bit per i simboli rari e meno bit per quelli frequenti;\nin questo modo, l’entropia ci offre un criterio per valutare quanto efficiente è una codifica: più la lunghezza media si avvicina all’entropia, più è efficiente.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>Entropia e informazione di Shannon</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#applicazioni-psicologiche",
    "href": "chapters/entropy/01_entropy.html#applicazioni-psicologiche",
    "title": "76  Entropia e informazione di Shannon",
    "section": "\n76.6 Applicazioni psicologiche",
    "text": "76.6 Applicazioni psicologiche\nIl concetto di entropia, inteso come misura della sorpresa media associata a un evento, trova applicazioni dirette anche nello studio di fenomeni psicologici. In particolare, la sorpresa — formalizzabile in termini di informazione di Shannon — è stata associata a cambiamenti emotivi, processi di apprendimento e modulazione della motivazione.\nUn esempio classico è fornito da Spector (1956), che studiò l’effetto della probabilità a priori sulla soddisfazione dei soggetti in seguito a una promozione lavorativa. I risultati mostrarono che esiti inizialmente percepiti come poco probabili — e quindi più sorprendenti quando si verificano — producevano un impatto emotivo maggiore rispetto a esiti attesi. In altre parole, la sorpresa amplificava la risposta affettiva, confermando l’idea che l’entropia non sia solo una misura astratta, ma un indicatore della potenziale intensità della reazione emotiva.\nRicerche più recenti, in contesti sia sperimentali che ecologici, hanno confermato questo legame. Ad esempio, studi nell’ambito delle neuroscienze cognitive hanno mostrato che eventi ad alta sorpresa modulano l’attività di aree cerebrali legate all’elaborazione emotiva, come l’amigdala e la corteccia prefrontale ventromediale, influenzando sia l’umore immediato sia l’apprendimento successivo. Allo stesso modo, nell’analisi dei dati di Ecological Momentary Assessment (EMA), la probabilità soggettiva di un evento può essere messa in relazione alla variazione momentanea dell’umore, mostrando che episodi rari o inattesi tendono a generare oscillazioni emotive più marcate.\nQuesti risultati illustrano bene come il concetto di entropia possa essere utilizzato in psicologia non solo come strumento di misura della distribuzione di probabilità degli eventi, ma anche come variabile esplicativa in modelli che indagano il legame tra aspettative, sorpresa e stati emotivi. Questo stesso legame sarà centrale quando, nelle prossime sezioni, introdurremo la divergenza di Kullback–Leibler e la utilizzeremo per confrontare modelli in un’ottica bayesiana.\n\n\n\n\n\n\nEsercizio — Miniesperimento simulato: probabilità, sorpresa e umore.\n\n\n\n\n\nIn questo esempio, simuliamo 200 osservazioni in cui ogni partecipante sperimenta un evento con probabilità variabile. La sorpresa di ciascun evento viene calcolata con la formula di Shannon, e l’effetto sull’umore viene simulato assumendo che eventi più sorprendenti producano, in media, variazioni di umore più ampie (positive o negative).\n\nset.seed(123)\n\n# Numero di osservazioni\nn &lt;- 200\n\n# Probabilità percepita dell'evento (da molto probabile a molto improbabile)\np_event &lt;- runif(n, min = 0.05, max = 0.95)\n\n# Sorpresa di Shannon (in bit)\nsurprise &lt;- -log2(p_event)\n\n# Variazione di umore simulata:\n# partiamo da un effetto medio proporzionale alla sorpresa, con rumore casuale\ndelta_mood &lt;- 0.5 * surprise + rnorm(n, mean = 0, sd = 0.5)\n\n# Mettiamo tutto in un data frame\ndf &lt;- data.frame(\n  p_event = p_event,\n  surprise = surprise,\n  delta_mood = delta_mood\n)\n\n# Visualizzazione\nggplot(df, aes(x = surprise, y = delta_mood)) +\n  geom_point(alpha = 0.6) +\n  geom_smooth(method = \"lm\", se = TRUE, color = \"blue\") +\n  labs(\n    title = \"Relazione tra sorpresa dell'evento e\\nvariazione di umore\",\n    x = \"Sorpresa (bit)\",\n    y = \"Δ Umore\"\n  ) \n\n\n\n\n\n\n\nInterpretazione. Il grafico mostra che, in questa simulazione, eventi più sorprendenti (bit più alti) tendono a produrre variazioni di umore maggiori. Questo illustra visivamente l’idea, già documentata empiricamente, che la sorpresa può amplificare la risposta emotiva.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>Entropia e informazione di Shannon</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#riflessioni-conclusive",
    "href": "chapters/entropy/01_entropy.html#riflessioni-conclusive",
    "title": "76  Entropia e informazione di Shannon",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo introdotto l’entropia come misura dell’incertezza associata a una variabile casuale e, più in generale, come strumento per quantificare la sorpresa media che ci attendiamo da un sistema. Attraverso esempi concreti — dalla moneta al dado, fino alla codifica di Huffman — abbiamo visto come l’entropia non sia solo una definizione matematica, ma una quantità operativa che descrive quanta informazione ci aspettiamo di ottenere osservando un evento, e quanto “costa” trasmettere quell’informazione in termini di bit.\nIl legame tra entropia e codifica è particolarmente istruttivo: l’entropia rappresenta il limite teorico inferiore alla lunghezza media di qualsiasi codifica binaria senza perdita. L’algoritmo di Huffman, pur vincolato a lunghezze intere di bit, si avvicina molto a questo limite, dimostrando come principi puramente probabilistici possano guidare scelte pratiche di compressione ed efficienza.\nQuesti concetti, tuttavia, hanno una portata ben più ampia della sola teoria dell’informazione. Nel contesto della modellizzazione statistica — e in particolare dell’inferenzia bayesiana — l’entropia diventa la base per concetti più complessi, come la divergenza di Kullback–Leibler (KL), che misura la distanza tra due distribuzioni di probabilità. Se l’entropia ci dice quanto possiamo imparare da una distribuzione nota, la divergenza KL ci dice quanto un modello si discosta da quella distribuzione.\nQuesta connessione si estende direttamente alla valutazione predittiva dei modelli. L’Expected Log Predictive Density (ELPD), che utilizzeremo per confrontare modelli bayesiani, è infatti legato alla minimizzazione della divergenza KL rispetto al “vero” processo generatore dei dati. In altre parole:\n\nl’entropia quantifica l’incertezza intrinseca dei dati;\nla KL quantifica l’inefficienza di un modello nel rappresentare tale incertezza;\nl’ELPD ci dice quanto bene un modello, in media, riesce a prevedere nuovi dati, proprio minimizzando quella inefficienza.\n\nComprendere l’entropia, quindi, non serve solo a sapere come comprimere messaggi o calcolare la sorpresa: è un passaggio essenziale per capire cosa significhi, in termini informativi, che un modello “funziona bene” e produce previsioni affidabili.\nChiudiamo con una riflessione di natura più filosofica. Come ricorda Eckhardt (2012), l’informazione non è solo una quantità misurabile:\n\n“…our mind, and even the subconscious self, resonate. A poet can recall chains of ideas, emotions and memories with a well-turned word. In this sense, writing is magic.”\n\nQuesto ci invita a ricordare che l’informazione ha anche una dimensione qualitativa: nei modelli psicologici, soprattutto in quelli predittivi, è fondamentale considerare non solo la capacità di previsione, ma anche il significato e l’interpretabilità di ciò che il modello produce. Un buon modello non si limita a comprimere l’incertezza in bit: deve anche restituire risposte che risuonino con le domande scientifiche e psicologiche che ci poniamo.\n\n\n\n\n\n\nMappa concettuale: dall’entropia alla valutazione dei modelli\n\n\n\n\n\nEntropia \\(H(X)\\)\n→ Misura l’incertezza intrinseca di una variabile casuale.\n→ Interpretabile come la sorpresa media o la lunghezza media minima (in bit) necessaria per codificare gli esiti di \\(X\\).\nDivergenza di Kullback–Leibler \\(D_{KL}(P \\parallel Q)\\)\n→ Confronta due distribuzioni di probabilità \\(P\\) (la “vera” distribuzione) e \\(Q\\) (il modello).\n→ Misura quanto il modello \\(Q\\) si discosta da \\(P\\) in termini di inefficienza nel codificare i dati.\nExpected Log Predictive Density (ELPD)\n→ Valuta la capacità predittiva di un modello su dati nuovi.\n→ Collegata alla minimizzazione della KL tra la distribuzione dei dati e la distribuzione predittiva del modello.\n→ Più alto è l’ELPD, migliore è la capacità del modello di rappresentare e prevedere i dati.\nCollegamento logico:\nEntropia → ci dice quanta incertezza c’è nei dati.\nKL → ci dice quanto un modello spreca informazione rispetto a quella incertezza.\nELPD → ci dice quanto bene il modello prevede, riducendo quello spreco.\n\n\n\n\n\nFigura 76.1: Diagramma visivo che collega Entropia → Divergenza KL → ELPD.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>Entropia e informazione di Shannon</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/entropy/01_entropy.html#informazioni-sullambiente-di-sviluppo",
    "title": "76  Entropia e informazione di Shannon",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] tidygraph_1.3.1       ggraph_2.2.1          igraph_2.1.4         \n#&gt;  [4] pillar_1.11.0         tinytable_0.11.0      patchwork_1.3.1      \n#&gt;  [7] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.13.0     \n#&gt; [10] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.0     \n#&gt; [13] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [16] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [19] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [22] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [25] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3        inline_0.3.21        sandwich_3.1-1      \n#&gt;  [4] rlang_1.1.6          magrittr_2.0.3       multcomp_1.4-28     \n#&gt;  [7] snakecase_0.11.1     compiler_4.5.1       mgcv_1.9-3          \n#&gt; [10] vctrs_0.6.5          stringr_1.5.1        pkgconfig_2.0.3     \n#&gt; [13] arrayhelpers_1.1-0   fastmap_1.2.0        backports_1.5.0     \n#&gt; [16] labeling_0.4.3       rmarkdown_2.29       purrr_1.1.0         \n#&gt; [19] xfun_0.52            cachem_1.1.0         jsonlite_2.0.0      \n#&gt; [22] tweenr_2.0.3         broom_1.0.9          parallel_4.5.1      \n#&gt; [25] R6_2.6.1             stringi_1.8.7        RColorBrewer_1.1-3  \n#&gt; [28] lubridate_1.9.4      estimability_1.5.1   knitr_1.50          \n#&gt; [31] zoo_1.8-14           Matrix_1.7-3         splines_4.5.1       \n#&gt; [34] timechange_0.3.0     tidyselect_1.2.1     abind_1.4-8         \n#&gt; [37] yaml_2.3.10          viridis_0.6.5        codetools_0.2-20    \n#&gt; [40] curl_6.4.0           pkgbuild_1.4.8       lattice_0.22-7      \n#&gt; [43] withr_3.0.2          bridgesampling_1.1-2 coda_0.19-4.1       \n#&gt; [46] evaluate_1.0.4       survival_3.8-3       RcppParallel_5.1.10 \n#&gt; [49] polyclip_1.10-7      tensorA_0.36.2.1     checkmate_2.3.2     \n#&gt; [52] stats4_4.5.1         distributional_0.5.0 generics_0.1.4      \n#&gt; [55] rprojroot_2.1.0      rstantools_2.4.0     scales_1.4.0        \n#&gt; [58] xtable_1.8-4         glue_1.8.0           emmeans_1.11.2      \n#&gt; [61] tools_4.5.1          mvtnorm_1.3-3        graphlayouts_1.2.2  \n#&gt; [64] grid_4.5.1           QuickJSR_1.8.0       colorspace_2.1-1    \n#&gt; [67] nlme_3.1-168         ggforce_0.5.0        cli_3.6.5           \n#&gt; [70] svUnit_1.0.6         viridisLite_0.4.2    Brobdingnag_1.2-9   \n#&gt; [73] V8_6.0.5             gtable_0.3.6         digest_0.6.37       \n#&gt; [76] ggrepel_0.9.6        TH.data_1.1-3        htmlwidgets_1.6.4   \n#&gt; [79] farver_2.1.2         memoise_2.0.1        htmltools_0.5.8.1   \n#&gt; [82] lifecycle_1.0.4      MASS_7.3-65",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>Entropia e informazione di Shannon</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#bibliografia",
    "href": "chapters/entropy/01_entropy.html#bibliografia",
    "title": "76  Entropia e informazione di Shannon",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nEckhardt, W. (2012). Paradoxes in probability theory. Springer Science & Business Media.\n\n\nSpector, A. J. (1956). Expectations, fulfillment, and morale. The Journal of Abnormal and Social Psychology, 52(1), 51–56.\n\n\nStone, J. V. (2022). Information theory: a tutorial introduction, 2nd edition.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>Entropia e informazione di Shannon</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/02_kl.html",
    "href": "chapters/entropy/02_kl.html",
    "title": "77  La divergenza di Kullback-Leibler",
    "section": "",
    "text": "Introduzione\nIn questo capitolo vedremo:",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>La divergenza di Kullback-Leibler</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/02_kl.html#introduzione",
    "href": "chapters/entropy/02_kl.html#introduzione",
    "title": "77  La divergenza di Kullback-Leibler",
    "section": "",
    "text": "Nel capitolo precedente abbiamo introdotto l’entropia come misura dell’incertezza di una distribuzione di probabilità. Ora facciamo un passo avanti: invece di misurare l’incertezza di una sola distribuzione, vogliamo misurare quanto una distribuzione differisce da un’altra. Uno strumento cruciale per rispondere a questa domanda è la divergenza di Kullback-Leibler (Kullback & Leibler, 1951), spesso abbreviata come divergenza KL (\\(D_{\\text{KL}}\\)). Essa misura quanto si perde in precisione o efficienza se si utilizza un modello errato per descrivere la realtà.\n\n\n\ncos’è la divergenza KL e da dove nasce;\ncome si collega al concetto di entropia;\nperché è utile nella scelta tra modelli statistici;\ncome calcolarla e interpretarla, anche con esempi in R.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>La divergenza di Kullback-Leibler</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/02_kl.html#la-generalizzabilità-dei-modelli-e-il-metodo-scientifico",
    "href": "chapters/entropy/02_kl.html#la-generalizzabilità-dei-modelli-e-il-metodo-scientifico",
    "title": "77  La divergenza di Kullback-Leibler",
    "section": "\n77.1 La Generalizzabilità dei modelli e il metodo scientifico",
    "text": "77.1 La Generalizzabilità dei modelli e il metodo scientifico\nUno degli obiettivi fondamentali della scienza è la generalizzabilità: un buon modello non deve spiegare solo i dati che abbiamo già, ma anche prevedere correttamente nuovi dati che potremmo raccogliere in futuro. Un modello troppo semplice rischia di sotto-adattarsi ai dati (underfitting), perdendo informazioni importanti; uno troppo complesso rischia di sovra-adattarsi (overfitting), confondendo il rumore casuale con segnali reali. Il problema della generalizzabilità è quindi centrale nel metodo scientifico: vogliamo modelli abbastanza flessibili da catturare i pattern reali, ma non così flessibili da adattarsi anche a variazioni casuali.\nNell’approccio bayesiano, come osserva McElreath (2020), la scelta di un modello implica trovare un equilibrio tra due esigenze:\n\n\naccuratezza predittiva – il modello deve produrre previsioni affidabili sui dati futuri;\n\ncontrollo della complessità – il modello non deve introdurre più complessità di quanta ne richieda il fenomeno studiato.\n\nQuesto principio è vicino a quello noto come rasoio di Occam: tra due modelli che spiegano altrettanto bene i dati, preferiamo quello più semplice. La differenza è che, in ambito bayesiano, questa preferenza non è solo una regola intuitiva, ma può essere formalizzata in termini quantitativi, misurando quanta “informazione in più” dobbiamo spendere quando il nostro modello si discosta dalla realtà. Questa misura è data dalla divergenza di Kullback–Leibler, che vedremo nel seguito.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>La divergenza di Kullback-Leibler</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/02_kl.html#lentropia-relativa",
    "href": "chapters/entropy/02_kl.html#lentropia-relativa",
    "title": "77  La divergenza di Kullback-Leibler",
    "section": "\n77.2 L’Entropia relativa",
    "text": "77.2 L’Entropia relativa\nNel Capitolo 76 abbiamo visto che l’entropia \\(H(P)\\) misura la lunghezza media del codice più efficiente per descrivere una distribuzione di probabilità \\(P\\). Ora estendiamo il ragionamento al confronto tra due distribuzioni:\n\n\n\\(P\\) = distribuzione vera dei dati, cioè quella che genera realmente gli eventi;\n\n\\(Q\\) = distribuzione approssimata, cioè quella fornita dal modello.\n\nLa divergenza di Kullback–Leibler, \\(D_{\\text{KL}}(P \\parallel Q)\\), risponde alla seguente domanda:\n\nin media, quanta informazione in più dobbiamo spendere se usiamo \\(Q\\) invece di \\(P\\) per descrivere i dati?\n\nDal punto di vista della codifica, questa quantità rappresenta l’aumento medio della lunghezza del codice quando si usa un modello impreciso.\n\n77.2.1 Definizione formale\nPer una variabile casuale discreta \\(X\\):\n\\[\nD_{\\text{KL}}(P \\parallel Q) = \\sum_x p(x) \\log_2 \\frac{p(x)}{q(x)}\n\\tag{77.1}\\]\nche può essere riscritta come:\n\\[\nD_{\\text{KL}}(P \\parallel Q) = \\sum_x p(x) \\left[ \\log_2 p(x) - \\log_2 q(x) \\right].\n\\tag{77.2}\\]\nQuesta forma mette in evidenza un’interpretazione intuitiva:\n\n\n\\(\\log_2 p(x)\\) è l’informazione (in bit) associata all’esito \\(x\\) secondo la distribuzione vera \\(P\\);\n\n\\(\\log_2 q(x)\\) è l’informazione associata allo stesso esito secondo il modello \\(Q\\);\nla differenza \\(\\log_2 p(x) - \\log_2 q(x)\\) indica, per quell’esito, quanto il modello \\(Q\\) sottostima o sovrastima la sorpresa rispetto a \\(P\\);\nmoltiplicando per \\(p(x)\\) e sommando su tutti gli esiti otteniamo una media ponderata (pesata in base a quanto l’esito è probabile nella realtà).\n\nIn sintesi, \\(D_{\\text{KL}}(P \\parallel Q)\\) è la perdita media di efficienza quando descriviamo la variabile \\(X\\) con la distribuzione approssimata \\(Q\\) invece che con la distribuzione vera \\(P\\).\nSe \\(P = Q\\) la divergenza è 0, perché non vi è alcuna perdita. Quanto più \\(Q\\) si discosta da \\(P\\), tanto più grande sarà la divergenza, segnalando un “costo informativo” maggiore.\n\n\n\n\n\n\nEsempio: Divergenza KL (1)\n\n\n\n\n\nSupponiamo che la variabile casuale \\(X\\) possa assumere tre valori: A, B e C.\nLa distribuzione vera (\\(P\\)) è:\n\n\nx\n\\(p(x)\\)\n\n\n\nA\n0.5\n\n\nB\n0.3\n\n\nC\n0.2\n\n\n\nIl modello approssimante (\\(Q\\)) è:\n\n\nx\n\\(q(x)\\)\n\n\n\nA\n0.4\n\n\nB\n0.4\n\n\nC\n0.2\n\n\n\nCalcoliamo la divergenza KL:\n\\[\n\\begin{aligned}\nD_{\\text{KL}}(P \\parallel Q) &= 0.5 \\log_2\\!\\left(\\frac{0.5}{0.4}\\right)\n+ 0.3 \\log_2\\!\\left(\\frac{0.3}{0.4}\\right)\n+ 0.2 \\log_2\\!\\left(\\frac{0.2}{0.2}\\right) \\\\[4pt]\n&= 0.5 \\log_2(1.25) + 0.3 \\log_2(0.75) + 0.2 \\log_2(1) \\\\[4pt]\n&\\approx 0.160 - 0.125 + 0 \\\\[4pt]\n&= 0.035 \\ \\text{bit}.\n\\end{aligned}\n\\]\nInterpretazione\n\nPer A, il modello \\(Q\\) sottostima la probabilità vera (0.4 invece di 0.5). Questo comporta un costo informativo positivo: il codice dovrà essere leggermente più lungo rispetto all’uso di \\(P\\).\nPer B, il modello \\(Q\\) sovrastima la probabilità vera (0.4 invece di 0.3). Qui il costo informativo è negativo, ma va pesato dal fatto che nella divergenza KL la somma è pesata secondo \\(P\\), e dunque conta di più la stima errata sugli eventi più probabili.\nPer C, il modello è perfetto (\\(p(x) = q(x)\\)) e il contributo alla divergenza è nullo.\n\nIl risultato complessivo, 0.035 bit per evento, è molto piccolo: significa che, in media, usando \\(Q\\) al posto di \\(P\\) spenderemmo appena 0.035 bit di informazione in più per descrivere ogni osservazione. Le due distribuzioni sono quindi molto simili, ma la divergenza KL rileva comunque la differenza residua.\n\n\n\n\n\n\n\n\n\nEsempio: Divergenza KL (2)\n\n\n\n\n\nSupponiamo che la variabile casuale \\(X\\) possa assumere tre valori: x = 1, 2, 3.\n\n\nDistribuzione vera (\\(P\\)): \\([0.1, \\ 0.6, \\ 0.3]\\)\n\n\nDistribuzione approssimata (\\(Q\\)): \\([0.2, \\ 0.5, \\ 0.3]\\)\n\n\nCalcoliamo la divergenza KL secondo la formula ?eq-kl-def:\n\n# Definizione delle distribuzioni\nP &lt;- c(0.1, 0.6, 0.3)  # distribuzione vera\nQ &lt;- c(0.2, 0.5, 0.3)  # distribuzione approssimata\n\n\n# Calcolo dei contributi per ciascun esito\ndf_kl_terms &lt;- kl_terms(P, Q)\nprint(df_kl_terms)\n#&gt;   x   p   q    term\n#&gt; 1 1 0.1 0.2 -0.1000\n#&gt; 2 2 0.6 0.5  0.1578\n#&gt; 3 3 0.3 0.3  0.0000\n\n\n# Visualizzazione dei contributi\nggplot(df_kl_terms, aes(x = factor(x), y = term)) +\n  geom_col(fill = \"steelblue\") +\n  geom_hline(yintercept = 0, color = \"black\", linewidth = 0.3) +\n  labs(\n    x = \"Valori possibili di X\",\n    y = \"Contributo alla Divergenza KL\",\n    title = \"Contributo di ciascun esito alla Divergenza KL\"\n  )\n\n\n\n\n\n\n\nInfine, sommiamo i contributi per ottenere la divergenza totale:\n\nKL_total &lt;- sum(df_kl_terms$term)\ncat(sprintf(\"Divergenza KL da P a Q: %.4f bit\\n\", KL_total))\n#&gt; Divergenza KL da P a Q: 0.0578 bit\n\nInterpretazione\n\n\nEsito 1 (\\(p=0.1\\), \\(q=0.2\\)) – Il modello \\(Q\\) sovrastima un evento raro. Il contributo alla divergenza è negativo, ma l’impatto è ridotto perché l’evento è poco probabile nella realtà (\\(p\\) piccolo).\n\nEsito 2 (\\(p=0.6\\), \\(q=0.5\\)) – Il modello sottostima l’evento più frequente. Poiché \\(p\\) è alto, questa sottostima ha un peso maggiore nella media ponderata, generando il contributo positivo più grande.\n\nEsito 3 (\\(p=0.3\\), \\(q=0.3\\)) – Qui il modello è perfetto: \\(p(x) = q(x)\\), quindi il contributo alla divergenza è zero.\n\nIl valore complessivo di \\(D_{\\text{KL}}\\) è la somma di questi contributi: rappresenta la perdita media di efficienza (in bit per evento) quando si usa \\(Q\\) al posto di \\(P\\).\nIn questo caso, il risultato indica che usare \\(Q\\) comporta una leggera inefficienza: la codifica o le previsioni richiedono, in media, un po’ più informazione di quanto sarebbe necessario usando la distribuzione vera.\n\n\n\n\n77.2.2 Legame con l’entropia e l’entropia incrociata\nLa divergenza di Kullback–Leibler può essere riscritta come differenza tra entropia incrociata e entropia vera:\n\\[\nD_{\\text{KL}}(P \\parallel Q) = H(P, Q) - H(P),\n\\tag{77.3}\\]\ndove:\n\n\n\\(H(P)\\) è l’entropia della distribuzione vera \\(P\\) (incertezza media/lunghezza media del codice ottimale quando conosciamo la distribuzione corretta);\n\n\\(H(P, Q)\\) è l’entropia incrociata, cioè l’incertezza media se codifichiamo dati generati da \\(P\\) utilizzando un codice ottimizzato per \\(Q\\):\n\n\\[\nH(P, Q) = -\\sum_x p(x)\\log_2 q(x).\n\\tag{77.4}\\]\nIntuizione. Con questa forma, \\(D_{\\text{KL}}\\) è la sorpresa extra media (o costo informativo in bit per evento) che paghiamo quando usiamo il modello approssimato \\(Q\\) al posto della distribuzione vera \\(P\\). Poiché \\(H(P)\\) non dipende dal modello, minimizzare \\(D_{\\text{KL}}\\) equivale a minimizzare \\(H(P,Q)\\).\n\n\n\n\n\n\nPerché serve per ELPD e LOO\n\n\n\nCriteri predittivi come ELPD e LOO stimano, in media, la stessa quantità di cui vogliamo minimizzare il valore: l’entropia incrociata \\(H(P,Q)\\). Per questo, massimizzare ELPD (o ridurre la perdita di log-verosimiglianza predittiva) è un modo pratico per avvicinare \\(Q\\) a \\(P\\), ossia per ridurre indirettamente \\(D_{\\text{KL}}(P\\parallel Q)\\).\n\n\n\n\n\n\n\n\nEsempio: Entropia incrociata (1)\n\n\n\n\n\nUtilizziamo le funzioni definite sopra (entropy(), cross_entropy(), kl_divergence()) sullo stesso esempio discusso in precedenza:\n\n# Esempio: distribuzione vera P e modello Q\nP &lt;- c(0.1, 0.6, 0.3)\nQ &lt;- c(0.2, 0.5, 0.3)\n\nH_P   &lt;- entropy(P)           # H(P)\nH_PQ  &lt;- cross_entropy(P, Q)  # H(P,Q)\nDKL   &lt;- kl_divergence(P, Q)  # D_KL(P||Q)\n\ncat(sprintf(\"H(P)    = %.4f bit\\n\", H_P))\n#&gt; H(P)    = 1.2955 bit\ncat(sprintf(\"H(P,Q)  = %.4f bit\\n\", H_PQ))\n#&gt; H(P,Q)  = 1.3533 bit\ncat(sprintf(\"H(P,Q)-H(P) = %.4f bit (D_KL)\\n\", H_PQ - H_P))\n#&gt; H(P,Q)-H(P) = 0.0578 bit (D_KL)\ncat(sprintf(\"D_KL(P||Q)  = %.4f bit (controllo)\\n\", DKL))\n#&gt; D_KL(P||Q)  = 0.0578 bit (controllo)\n\nInterpretazione\n\n\n\\(H(P)\\) è il limite inferiore: la miglior compressione ottenibile conoscendo la verità (\\(P\\)).\n\n\n\\(H(P,Q)\\) è la compressione che otterremmo usando il modello (\\(Q\\)).\n\nLa loro differenza è esattamente \\(D_{\\text{KL}}(P\\parallel Q)\\): la quantità di informazione “sprecata” in media per evento usando \\(Q\\) al posto di \\(P\\).\n\n\n\n\n\n\n\n\n\n\n\nEsempio: Entropia incrociata (2)\n\n\n\n\n\nIn due esempi successivi rendiamo \\(Q\\) sempre più diverso da \\(P\\) e osserviamo come cambiano entropia incrociata e divergenza KL.\n\n# Distribuzione vera fissata\nP  &lt;- c(0.1, 0.6, 0.3)\nH_P &lt;- entropy(P)  # costante rispetto al modello\n\n# Due modelli: uno moderatamente errato (Q1), uno molto errato (Q2)\nQ1 &lt;- c(0.35, 0.30, 0.35)\nQ2 &lt;- c(0.60, 0.30, 0.10)\n\n# Calcolo di entropia incrociata e divergenza KL\nH_PQ1 &lt;- cross_entropy(P, Q1)\nH_PQ2 &lt;- cross_entropy(P, Q2)\n\nKL1 &lt;- kl_divergence(P, Q1)\nKL2 &lt;- kl_divergence(P, Q2)\n\ncat(sprintf(\"H(P)     = %.4f bit (fissa)\\n\", H_P))\n#&gt; H(P)     = 1.2955 bit (fissa)\ncat(sprintf(\"H(P,Q1)  = %.4f bit   -&gt; D_KL(P||Q1) = %.4f bit\\n\", H_PQ1, KL1))\n#&gt; H(P,Q1)  = 1.6480 bit   -&gt; D_KL(P||Q1) = 0.3525 bit\ncat(sprintf(\"H(P,Q2)  = %.4f bit   -&gt; D_KL(P||Q2) = %.4f bit\\n\", H_PQ2, KL2))\n#&gt; H(P,Q2)  = 2.1125 bit   -&gt; D_KL(P||Q2) = 0.8170 bit\n\nInterpretazione\nPoiché \\(H(P)\\) non cambia, quando \\(Q\\) si allontana da \\(P\\) cresce \\(H(P,Q)\\) e, di conseguenza, aumenta\n\\[\nD_{\\text{KL}}(P \\parallel Q) = H(P, Q) - H(P) .\n\\]\n\nQ1: il modello redistribuisce massa probabilistica, sottostimando l’esito più probabile e sovrastimando gli altri. Gli errori sugli esiti che \\(P\\) considera frequenti pesano di più nella media, aumentando \\(H(P,Q1)\\) e quindi \\(D_{\\text{KL}}\\).\nQ2: l’errore è estremo: la probabilità più alta viene assegnata all’esito meno probabile secondo \\(P\\). I contributi positivi (sottostima degli esiti comuni) dominano, facendo crescere molto \\(D_{\\text{KL}}\\).\n\nQuesto esempio mostra che minimizzare \\(H(P,Q)\\) (e quindi \\(D_{\\text{KL}}\\)) significa allineare il più possibile le probabilità del modello con quelle “vere”, soprattutto per gli esiti a cui \\(P\\) assegna più massa.\n\n\n\n\n\n\n\n\n\nDimostrazione: dalla differenza di entropie alla formula della D-KL\n\n\n\n\n\nPartiamo dalla definizione come differenza tra entropia incrociata ed entropia vera:\n\\[\nD_{\\text{KL}}(P \\parallel Q) = H(P, Q) - H(P).\n\\]\nSostituendo: \\[\nH(P,Q) = -\\sum_x p(x) \\log_2 q(x), \\quad\nH(P)   = -\\sum_x p(x) \\log_2 p(x),\n\\]\nottieni:\n\\[\nD_{\\text{KL}}(P \\parallel Q) =\n\\left[ - \\sum_x p(x) \\log_2 q(x) \\right]\n- \\left[ - \\sum_x p(x) \\log_2 p(x) \\right].\n\\]\nEliminando i segni negativi:\n\\[\nD_{\\text{KL}}(P \\parallel Q) =\n\\sum_x p(x) \\log_2 p(x) - \\sum_x p(x) \\log_2 q(x).\n\\]\nRaccogliendo in un’unica somma:\n\\[\nD_{\\text{KL}}(P \\parallel Q) =\n\\sum_x p(x) \\left[ \\log_2 p(x) - \\log_2 q(x) \\right].\n\\]\nApplicando la proprietà dei logaritmi:\n\\[\nD_{\\text{KL}}(P \\parallel Q) =\n\\sum_x p(x) \\log_2 \\frac{p(x)}{q(x)}.\n\\]\nInterpretazione: questa è la forma esplicita più usata della \\(D_{\\text{KL}}\\). Mostra chiaramente che si tratta di una media ponderata secondo \\(P\\) della differenza di informazione tra \\(P\\) e \\(Q\\) per ciascun esito \\(x\\).\n\n\n\n\n77.2.3 Interpretazione della divergenza KL\nLa divergenza \\(D_{\\text{KL}}(P \\parallel Q)\\) misura l’inefficienza media che si introduce quando si usa la distribuzione \\(Q\\) per descrivere dati che in realtà seguono \\(P\\). In termini informativi, rappresenta il costo aggiuntivo di sorpresa: quanti bit in più, in media, servono per codificare gli eventi generati da \\(P\\) se utilizziamo un codice ottimizzato per \\(Q\\) invece che per \\(P\\).\nQuesta quantità:\n\nè sempre non negativa: il modello vero (\\(P\\)) non può mai essere peggiore, in media, del modello approssimato (\\(Q\\));\nè asimmetrica: \\(D_{\\text{KL}}(P \\parallel Q) \\neq D\\_{\\text{KL}}(Q \\parallel P)\\). L’ordine è importante: invertire \\(P\\) e \\(Q\\) cambia il significato della misura, perché cambia quale distribuzione stiamo trattando come “vera”.\n\nPer questo motivo, la divergenza KL non è una “distanza” in senso geometrico, ma una misura direzionale di perdita di informazione o di inefficienza di codifica.\n\n77.2.4 Proprietà fondamentali della divergenza KL\n\nNon-negatività: \\(D_{\\text{KL}}(P \\parallel Q) \\geq 0\\) per ogni coppia di distribuzioni \\(P\\) e \\(Q\\). Il valore minimo (0) si ottiene se e solo se \\(P = Q\\).\nAsimmetria: \\(D_{\\text{KL}}(P \\parallel Q) \\neq D\\_{\\text{KL}}(Q \\parallel P)\\) in generale. Non soddisfa quindi le proprietà di una distanza simmetrica.\n\nUnità di misura: dipende dalla base del logaritmo:\n\nbase 2 → misura in bit;\nbase \\(e\\) → misura in nat (unità naturale di informazione).",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>La divergenza di Kullback-Leibler</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/02_kl.html#uso-della-divergenza-d_textkl-nella-selezione-di-modelli",
    "href": "chapters/entropy/02_kl.html#uso-della-divergenza-d_textkl-nella-selezione-di-modelli",
    "title": "77  La divergenza di Kullback-Leibler",
    "section": "\n77.3 Uso della divergenza \\(D_{\\text{KL}}\\) nella selezione di modelli",
    "text": "77.3 Uso della divergenza \\(D_{\\text{KL}}\\) nella selezione di modelli\nIn teoria, la selezione del modello consiste nello scegliere il modello \\(Q\\) che minimizza la divergenza dalla distribuzione vera \\(P\\):\n\\[\n\\text{Modello ottimale} = \\arg\\min_Q D_{\\text{KL}}(P \\parallel Q).\n\\]\nIn altre parole, il modello ideale è quello che si avvicina di più a \\(P\\) e quindi riduce al minimo la perdita media di informazione quando lo usiamo per descrivere i dati.\nProblema: nella pratica, \\(P\\) è sconosciuta — non possiamo osservare direttamente la distribuzione vera che ha generato i dati. Di conseguenza, non possiamo calcolare \\(D_{\\text{KL}}\\) in modo esatto.\n\n77.3.1 Come procedere nella pratica\nAnche se \\(P\\) è ignota, possiamo comunque confrontare modelli in termini di divergenza KL sfruttando il legame con l’entropia incrociata \\(H(P,Q)\\). Infatti, ricordiamo che:\n\\[\nD_{\\text{KL}}(P \\parallel Q) = H(P,Q) - H(P).\n\\]\nL’entropia \\(H(P)\\) non dipende dal modello \\(Q\\): è una costante rispetto al confronto tra modelli. Se prendiamo la differenza di divergenza KL tra due modelli \\(Q_1\\) e \\(Q_2\\), questa costante si annulla:\n\\[\nD_{\\text{KL}}(P \\parallel Q_1) - D_{\\text{KL}}(P \\parallel Q_2)\n= H(P,Q_1) - H(P,Q_2).\n\\tag{77.5}\\]\nQuindi, per confrontare modelli non serve conoscere \\(H(P)\\): basta confrontare le loro entropie incrociate \\(H(P,Q)\\), che dipendono solo da \\(Q\\) e che possono essere stimate dai dati.\nNel prossimo capitolo vedremo due strumenti dell’approccio bayesiano che stimano proprio \\(H(P,Q)\\) (o, più precisamente, il suo opposto \\(-H(P,Q)\\)):\n\n\nLeave-One-Out Cross-Validation (LOO-CV) – valuta quanto bene il modello predice dati non usati nella stima;\n\nExpected Log Predictive Density (ELPD) – fornisce la stima della qualità predittiva media del modello.\n\nQuesti metodi permettono di confrontare modelli in termini di differenza di divergenza KL, avvicinandoci così alla scelta del modello che, tra quelli considerati, è più vicino alla distribuzione vera \\(P\\).\n\n\n\n\n\n\nEsempio psicologico\n\n\n\n\n\nImmaginiamo di voler prevedere il punteggio di ansia settimanale di uno studente.\n\n\nModello A: utilizza come predittore solo il punteggio di coping (capacità di fronteggiare lo stress).\n\n\nModello B: utilizza coping + supporto sociale.\n\nSupponiamo che, valutando le loro prestazioni predittive, entrambi i modelli ottengano buoni risultati, ma il Modello B presenti una divergenza KL leggermente inferiore rispetto al Modello A.\nInterpretazione:\n\nla divergenza KL più bassa del Modello B indica che, in media, le sue previsioni sono leggermente più vicine alla distribuzione “vera” dei dati (minore perdita di informazione);\ntuttavia, se la differenza è piccola, potremmo preferire il Modello A per la sua maggiore semplicità e interpretabilità, applicando il principio di parsimonia (o rasoio di Occam).\n\nQuesto esempio illustra che la selezione del modello non dipende solo dalla precisione predittiva, ma anche dal bilanciamento tra accuratezza e complessità.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>La divergenza di Kullback-Leibler</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/02_kl.html#riflessioni-conclusive",
    "href": "chapters/entropy/02_kl.html#riflessioni-conclusive",
    "title": "77  La divergenza di Kullback-Leibler",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo approfondito un concetto fondamentale della teoria dell’informazione: la divergenza di Kullback–Leibler. Nata in origine per valutare l’efficienza dei codici di trasmissione, la D-KL è oggi uno strumento essenziale anche nella statistica moderna, perché misura in modo preciso quanto una distribuzione di probabilità approssimata \\(Q\\) (cioè un modello) si discosti dalla distribuzione vera \\(P\\) che genera i dati.\nAbbiamo visto che la D-KL può essere interpretata come:\n\n\nperdita media di informazione quando si usa \\(Q\\) invece di \\(P\\);\n\neccesso di sorpresa o inefficienza di codifica introdotta da un modello imperfetto;\ndifferenza tra entropia incrociata e entropia vera, il che rende possibile stimarla indirettamente.\n\nQuesto legame con l’entropia incrociata è cruciale: sebbene \\(P\\) non sia nota e la D-KL non possa essere calcolata in valore assoluto, possiamo confrontare modelli stimando le differenze di D-KL, perché la componente costante \\(H(P)\\) si annulla nel confronto.\nNel prossimo capitolo ci concentreremo proprio su come effettuare questi confronti in pratica. Vedremo come strumenti come la Leave-One-Out Cross-Validation (LOO-CV) e l’Expected Log Predictive Density (ELPD) permettano di stimare la capacità predittiva dei modelli e di identificare quello che, tra le alternative considerate, è il più vicino alla distribuzione vera dei dati.\n\n\n\n\n\n\nSintesi finale\n\n\n\n\nLa divergenza KL quantifica la perdita media di informazione usando \\(Q\\) al posto di \\(P\\).\nSi può scrivere come \\(\\sum_x p(x) \\log \\frac{p(x)}{q(x)}\\) o come \\(H(P,Q) - H(P)\\).\nÈ uno strumento chiave per valutare quanto bene un modello rappresenta la realtà.\nIn pratica, può essere confrontata tra modelli stimando \\(H(P,Q)\\) con tecniche come LOO-CV ed ELPD.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>La divergenza di Kullback-Leibler</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/02_kl.html#esercizi",
    "href": "chapters/entropy/02_kl.html#esercizi",
    "title": "77  La divergenza di Kullback-Leibler",
    "section": "Esercizi",
    "text": "Esercizi\n\nEsercizio 77.1 Cosideriamo due distribuzioni di probabilità discrete, \\(p\\) e \\(q\\):\np &lt;- c(0.2, 0.5, 0.3)\nq &lt;- c(0.1, 0.2, 0.7)\nSi calcoli l’entropia di \\(p\\), l’entropia incrociata tra \\(p\\) e \\(q\\), la divergenza di Kullback-Leibler da \\(p\\) a \\(q\\).\nSi consideri q = c(0.2, 0.55, 0.25) e si calcoli di nuovo a divergenza di Kullback-Leibler da \\(p\\) a \\(q\\). Si confronti con il risultato precedente e si interpreti.\n\n\nEsercizio 77.2 Sia \\(p\\) una distribuzione binomiale di parametri \\(\\theta = 0.2\\) e \\(n = 5\\). Sia \\(q_1\\) una approssimazione a \\(p\\): q1 = c(0.46, 0.42, 0.10, 0.01, 0.01). Sia \\(q_2\\) una distribuzione uniforme: q2 &lt;- rep(0.2, 5). Si calcoli la divergenza \\(\\mathbb{KL}\\) di \\(q_1\\) da \\(p\\) e da \\(q_2\\) da \\(p\\) e si interpretino i risultati.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>La divergenza di Kullback-Leibler</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/02_kl.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/entropy/02_kl.html#informazioni-sullambiente-di-sviluppo",
    "title": "77  La divergenza di Kullback-Leibler",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pillar_1.11.0         tinytable_0.11.0      patchwork_1.3.1      \n#&gt;  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.13.0     \n#&gt;  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.0     \n#&gt; [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#&gt; [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#&gt; [16] conflicted_1.2.0      janitor_2.2.1         matrixStats_1.5.0    \n#&gt; [19] modelr_0.1.11         tibble_3.3.0          dplyr_1.1.4          \n#&gt; [22] tidyr_1.3.1           rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.6         tidyselect_1.2.1     farver_2.1.2        \n#&gt;  [4] fastmap_1.2.0        TH.data_1.1-3        tensorA_0.36.2.1    \n#&gt;  [7] digest_0.6.37        estimability_1.5.1   timechange_0.3.0    \n#&gt; [10] lifecycle_1.0.4      survival_3.8-3       magrittr_2.0.3      \n#&gt; [13] compiler_4.5.1       rlang_1.1.6          tools_4.5.1         \n#&gt; [16] knitr_1.50           labeling_0.4.3       bridgesampling_1.1-2\n#&gt; [19] htmlwidgets_1.6.4    pkgbuild_1.4.8       curl_6.4.0          \n#&gt; [22] RColorBrewer_1.1-3   abind_1.4-8          multcomp_1.4-28     \n#&gt; [25] withr_3.0.2          purrr_1.1.0          grid_4.5.1          \n#&gt; [28] stats4_4.5.1         xtable_1.8-4         colorspace_2.1-1    \n#&gt; [31] inline_0.3.21        emmeans_1.11.2       scales_1.4.0        \n#&gt; [34] MASS_7.3-65          cli_3.6.5            mvtnorm_1.3-3       \n#&gt; [37] rmarkdown_2.29       generics_0.1.4       RcppParallel_5.1.10 \n#&gt; [40] cachem_1.1.0         stringr_1.5.1        splines_4.5.1       \n#&gt; [43] parallel_4.5.1       vctrs_0.6.5          V8_6.0.5            \n#&gt; [46] Matrix_1.7-3         sandwich_3.1-1       jsonlite_2.0.0      \n#&gt; [49] arrayhelpers_1.1-0   glue_1.8.0           codetools_0.2-20    \n#&gt; [52] distributional_0.5.0 lubridate_1.9.4      stringi_1.8.7       \n#&gt; [55] gtable_0.3.6         QuickJSR_1.8.0       htmltools_0.5.8.1   \n#&gt; [58] Brobdingnag_1.2-9    R6_2.6.1             rprojroot_2.1.0     \n#&gt; [61] evaluate_1.0.4       lattice_0.22-7       backports_1.5.0     \n#&gt; [64] memoise_2.0.1        broom_1.0.9          snakecase_0.11.1    \n#&gt; [67] rstantools_2.4.0     coda_0.19-4.1        gridExtra_2.3       \n#&gt; [70] nlme_3.1-168         checkmate_2.3.2      xfun_0.52           \n#&gt; [73] zoo_1.8-14           pkgconfig_2.0.3",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>La divergenza di Kullback-Leibler</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/02_kl.html#bibliografia",
    "href": "chapters/entropy/02_kl.html#bibliografia",
    "title": "77  La divergenza di Kullback-Leibler",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nKullback, S., & Leibler, R. A. (1951). On information and sufficiency. The Annals of Mathematical Statistics, 22(1), 79–86.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>La divergenza di Kullback-Leibler</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_model_comparison.html",
    "href": "chapters/entropy/03_model_comparison.html",
    "title": "78  Valutare i modelli bayesiani: Log-Score, LPPD, ELPD e LOO-CV",
    "section": "",
    "text": "Introduzione\nIl punto di partenza è una domanda cruciale: quanto bene il modello riesce a prevedere nuovi dati? Un buon modello non deve solo adattarsi bene ai dati già osservati, ma anche saper generalizzare a situazioni future o a campioni mai visti. Questa distinzione — adattamento vs. generalizzazione — è il cuore della valutazione predittiva.\nPer rendere concreta questa idea, immaginiamo di aver sviluppato un test psicologico per prevedere il livello di ansia degli studenti alla vigilia di un esame. Non basta sapere che il modello descrive bene i dati del campione che abbiamo usato per costruirlo: vogliamo anche essere ragionevolmente sicuri che le stesse previsioni funzionino per studenti che non hanno partecipato allo studio. In psicologia, scegliere tra due modelli non è diverso dal decidere quale test usare per prevedere un disturbo: entrambi mirano a capire quale strumento fornisce previsioni più affidabili sui dati futuri.\nIn questo capitolo esploreremo gli strumenti fondamentali per la valutazione e il confronto di modelli nell’ambito dell’inferenza bayesiana.\n1. La distribuzione predittiva posteriore\nIntrodurremo la distribuzione predittiva posteriore, che incorpora l’incertezza sui parametri per generare previsioni coerenti con lo stato di conoscenza del modello. Questo strumento rappresenta il ponte naturale tra stima e previsione, garantendo una quantificazione probabilistica completa dell’incertezza.\n2. Misure di accuratezza predittiva\nDiscuteremo il log-score, una metrica punto per punto che valuta la qualità delle previsioni, e due sue sintesi fondamentali:\n3. Validazione empirica e confronto tra modelli\nPresenteremo la tecnica Leave-One-Out Cross-Validation (LOO-CV), un approccio efficiente per stimare l’ELPD senza bisogno di nuovi dati, dimostrando come questa metodologia fornisca una valutazione robusta delle prestazioni predittive.\n4. Fondamenti teorici e interpretazione\nApprofondiremo il legame tra ELPD e divergenza di Kullback-Leibler, che consente di interpretare il confronto tra modelli come una ricerca del modello più vicino alla vera distribuzione generatrice dei dati. Questa connessione teorica fornisce una solida giustificazione informazionale per le procedure di selezione bayesiana.\nL’obiettivo del capitolo è offrire una panoramica completa e operativa, che unisca principi teorici a strumenti applicativi, guidando il lettore nella scelta razionale del modello più adatto al problema in esame.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Valutare i modelli bayesiani: Log-Score, LPPD, ELPD e LOO-CV</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_model_comparison.html#introduzione",
    "href": "chapters/entropy/03_model_comparison.html#introduzione",
    "title": "78  Valutare i modelli bayesiani: Log-Score, LPPD, ELPD e LOO-CV",
    "section": "",
    "text": "Nei capitoli precedenti abbiamo visto due concetti fondamentali: l’entropia, che misura l’incertezza insita in una distribuzione, e la divergenza di Kullback–Leibler (\\(D_{\\text{KL}}\\)), che quantifica la distanza tra due distribuzioni di probabilità. Ora possiamo fare un passo ulteriore: usare queste idee per valutare e confrontare modelli statistici nel contesto bayesiano.\n\n\n\n\n\n\n\nla LPPD (Log Pointwise Predictive Density), che misura la bontà di adattamento su dati osservati;\n\nl’ELPD (Expected Log Predictive Density), che stima l’abilità predittiva attesa su nuove osservazioni.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Valutare i modelli bayesiani: Log-Score, LPPD, ELPD e LOO-CV</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_model_comparison.html#distribuzione-predittiva-posteriore",
    "href": "chapters/entropy/03_model_comparison.html#distribuzione-predittiva-posteriore",
    "title": "78  Valutare i modelli bayesiani: Log-Score, LPPD, ELPD e LOO-CV",
    "section": "\n78.1 Distribuzione predittiva posteriore",
    "text": "78.1 Distribuzione predittiva posteriore\nNel capitolo precedente abbiamo usato la divergenza di Kullback–Leibler (KL) come misura teorica della distanza tra realtà e modello. Qui ci chiediamo: come stimiamo questa distanza quando la “vera” distribuzione generatrice è ignota? Un tassello fondamentale è la distribuzione predittiva posteriore.\nNel capitolo sul modello beta–binomiale l’abbiamo già incontrata: è lo strumento che, nell’approccio bayesiano, consente di prevedere nuovi dati incorporando sia la struttura del modello sia l’incertezza sui parametri.\nIn sintesi: dopo aver osservato i dati \\(y\\), non otteniamo un singolo “miglior” valore dei parametri, ma una distribuzione posteriore \\(p(\\theta \\mid y)\\) che quantifica i valori plausibili di \\(\\theta\\) e la nostra incertezza.\n\nEsempio. Uno psicologo che stima il livello medio di ansia in una popolazione, invece di affermare “la media è 4.7”, dirà: “il valore più plausibile è 4.7, ma è ragionevole che sia tra 4.2 e 5.1”, riflettendo la variabilità posteriore.\n\nPer prevedere un nuovo dato \\(\\tilde y\\), non fissiamo \\(\\theta\\). Mediamo invece tutte le previsioni condizionate \\(p(\\tilde y \\mid \\theta)\\) pesandole con la posteriore \\(p(\\theta\\mid y)\\):\n\\[\nq(\\tilde{y} \\mid y)\n\\;=\\;\n\\int p(\\tilde{y} \\mid \\theta)\\, p(\\theta \\mid y)\\, d\\theta .\n\\]\n\n\n\n\n\n\nIntuizione\n\n\n\n\n\nSe conoscessimo il valore vero di \\(\\theta\\), potremmo prevedere i dati futuri usando la distribuzione predittiva condizionata:\n\\[\np(\\tilde y \\mid \\theta).\n\\]\nIl problema è che \\(\\theta\\) non lo conosciamo: abbiamo soltanto la distribuzione a posteriori \\(p(\\theta\\mid y)\\). Perciò, la distribuzione predittiva posteriore si costruisce combinando le previsioni condizionate per ogni valore possibile di \\(\\theta\\), pesandole con quanto ciascun valore è plausibile a posteriori:\n\\[\np(\\tilde y\\mid y) = \\int p(\\tilde y\\mid \\theta)\\,p(\\theta\\mid y)\\,d\\theta.\n\\]\nPer fare un esempio concreto, consideriamo il caso binomiale. Supponiamo che i dati futuri siano generati da una Binomiale con \\(m\\) prove e parametro \\(\\theta\\):\n\\[\np(\\tilde y = x \\mid \\theta) = \\binom{m}{x}\\,\\theta^x(1-\\theta)^{m-x}.\n\\]\nLa distribuzione predittiva posteriore diventa:\n\\[\np(\\tilde y = x \\mid y) = \\int \\binom{m}{x}\\,\\theta^x(1-\\theta)^{m-x}\\,p(\\theta\\mid y)\\,d\\theta.\n\\]\nIn alcuni casi particolari (per esempio con prior Beta e dati binomiali) questo integrale si può risolvere analiticamente, ottenendo la Beta–Binomiale. Ma in generale non c’è una formula chiusa e serve un’approssimazione numerica.\nApprossimazione numerica con il metodo su griglia. L’idea è semplice: sostituire l’integrale con una somma pesata su una griglia di valori possibili di \\(\\theta\\). I passaggi algoritmici sono i seguenti.\n\n\nDefinire una griglia di valori di \\(\\theta\\), ad esempio 1000 punti equispaziati tra 0 e 1:\n\\[\n\\theta_1, \\theta_2, \\dots, \\theta_J.\n\\]\n\n\nCalcolare la posteriore su ciascun punto della griglia. Nel caso Beta–Binomiale:\n\\[\np(\\theta_j \\mid y) \\propto \\theta_j^{\\,k+a-1}(1-\\theta_j)^{n-k+b-1}.\n\\]\nPoi normalizzare per avere somme che valgono 1:\n\\[\nw_j = \\frac{p(\\theta_j \\mid y)}{\\sum_{\\ell=1}^J p(\\theta_\\ell \\mid y)}.\n\\]\n\n\nCombinare le predizioni condizionate. Per ogni valore futuro \\(x=0,\\dots,m\\), si calcola:\n\\[\np(\\tilde y = x \\mid y) \\approx \\sum_{j=1}^J w_j \\, \\binom{m}{x}\\theta_j^x(1-\\theta_j)^{m-x}.\n\\]\n\n\nInterpretazione: la pmf ottenuta è la nostra approssimazione numerica della distribuzione predittiva posteriore. Da essa possiamo:\n\ncalcolare probabilità,\ngenerare campioni di \\(\\tilde y\\),\nconfrontare la predizione con i dati osservati.\n\n\n\nDa ricordare:\n\nLa predittiva non si ottiene facendo la media dei valori di \\(\\tilde y\\), ma costruendo un’intera distribuzione di probabilità.\nIl metodo su griglia è il più semplice: discretizza \\(\\theta\\), pesa ogni valore con la sua plausibilità a posteriori, e combina le predizioni condizionate.\nIn problemi più complessi, la stessa logica viene implementata tramite MCMC: invece di usare una griglia fissa, si usano campioni \\(\\theta^{(s)}\\) dalla posteriore.\n\n\n\n\n\n\n\n\n\n\nEsempio numerico\n\n\n\n\n\nEsaminiamo ora uno script in R che implementa passo per passo l’approssimazione della distribuzione predittiva posteriore binomiale con il metodo su griglia.\n\n# ESEMPIO DIDATTICO: predittiva posteriore per Binomiale con metodo su griglia\n# Dati e prior\nk &lt;- 10     # successi osservati\nn &lt;- 50     # prove osservate\na &lt;- 1      # prior Beta(a, b)\nb &lt;- 1\nm &lt;- 10     # numero di prove future per la predizione (scelta didattica)\nJ &lt;- 2000   # numero di punti griglia su theta in [0,1]\n\n# -------------------------------------------------------------\n# PASSAGGIO 1: Griglia su theta\n# -------------------------------------------------------------\n\ntheta &lt;- seq(0, 1, length.out = J)\n\n# -------------------------------------------------------------\n# PASSAGGIO 2: Densità posteriore non normalizzata su ogni punto di griglia\n# -------------------------------------------------------------\n\n# Posteriore ~ Beta(a + k, b + n - k)  -&gt; densità proporzionale a theta^(a+k-1) (1-theta)^(b+n-k-1)\npost_unnorm &lt;- theta^(a + k - 1) * (1 - theta)^(b + n - k - 1)\n\n# Normalizzazione per ottenere pesi che sommano a 1\nw &lt;- post_unnorm / sum(post_unnorm)\n\n# -------------------------------------------------------------\n# PASSAGGIO 3: combinare le predittive condizionate p(tilde y | theta)\n# -------------------------------------------------------------\n# Obiettivo: costruire la pmf predittiva p(tilde y = x | y) \n# per ogni x = 0,...,m come media pesata (sulla griglia di θ) \n# delle pmf condizionate binomiali.\n\n# 1) Definiamo i valori futuri possibili di tilde y\nx_vals &lt;- 0:m\n\n# 2) Inizializziamo una matrice vuota: \n#    - J righe (una per ciascun θ_j della griglia)\n#    - (m+1) colonne (una per ogni valore possibile di x)\npx_given_theta &lt;- matrix(NA_real_, nrow = J, ncol = m + 1)\n\n# 3) Riempiamo la matrice: per ogni θ_j (riga j) e per ogni x (colonna i)\n#    calcoliamo P(tilde y = x | θ_j) = Binomiale(x | m, θ_j)\nfor (j in 1:J) {\n  for (i in 1:(m + 1)) {\n    x &lt;- x_vals[i]\n    px_given_theta[j, i] &lt;- dbinom(x, size = m, prob = theta[j])\n  }\n}\n\n# 4) Combinazione pesata:\n#    p(tilde y = x | y) ≈ somma_j w_j * P(tilde y = x | θ_j).\n#    Per ciascun valore di x (colonna i), facciamo la somma pesata.\npred_pmf &lt;- numeric(m + 1)\nfor (i in 1:(m + 1)) {\n  pred_pmf[i] &lt;- sum(w * px_given_theta[, i])\n}\n\n# Nota didattica:\n# - Ogni colonna della matrice px_given_theta contiene le probabilità condizionate \n#   P(tilde y = x_i | θ_j) per tutti i valori di griglia θ_j.\n# - Moltiplicando riga per riga queste probabilità per i pesi posteriori w_j \n#   e sommando, otteniamo la probabilità predittiva p(tilde y = x_i | y).\n# - In questo modo l’integrale viene approssimato da una somma pesata.\n\n# -------------------------------------------------------------\n# PASSAGGIO 4: Risultato: una pmf su {0,1,...,m}\n# -------------------------------------------------------------\n\npred_df &lt;- data.frame(x = x_vals, p = pred_pmf)\npred_df\n#&gt;     x         p\n#&gt; 1   0 1.139e-01\n#&gt; 2   1 2.506e-01\n#&gt; 3   2 2.762e-01\n#&gt; 4   3 1.995e-01\n#&gt; 5   4 1.040e-01\n#&gt; 6   5 4.069e-02\n#&gt; 7   6 1.206e-02\n#&gt; 8   7 2.662e-03\n#&gt; 9   8 4.178e-04\n#&gt; 10  9 4.200e-05\n#&gt; 11 10 2.049e-06\n\n\nsum(pred_df$p)  # dovrebbe essere ~1\n#&gt; [1] 1\n\n\n# (Opzionale) campionamento dalla predittiva posteriore approssimata\n# Estrae N valori da {0,...,m} con le probabilità 'p'\nset.seed(123)\nN &lt;- 5000\ntilde_y_samples &lt;- sample(pred_df$x, size = N, replace = TRUE, prob = pred_df$p)\n\n# Controllo: istogramma delle simulazioni vs pmf teorica approssimata\nggplot() +\n  geom_histogram(\n    data = data.frame(x = tilde_y_samples), aes(x = x, y = after_stat(density)),\n    binwidth = 1, breaks = seq(-0.5, m + 0.5, by = 1), fill = \"skyblue\", \n    color = \"black\") +\n  geom_point(data = pred_df, aes(x = x, y = p), pch = 19, cex = 3) + \n  geom_line(data = pred_df, aes(x = x, y = p), lwd = 1.5) + \n  ylim(0, max(pred_df$p) * 1.1) +\n  labs(\n    title = \"Posterior Predictive (grid) — m=10\",\n    x = expression(tilde(y)),\n    y = \"Density\")\n\n\n\n\n\n\n\n\nNota: il vettore pred_df$p è la pmf della predittiva posteriore approssimata; da qui si leggono probabilità, si calcolano quantità riassuntive e si può estrarre \\(\\tilde y\\).\n\nVerifica quando esiste la formula chiusa. Quando prior e likelihood sono coniugate (Beta + Binomiale), la predittiva è Beta–Binomiale. Possiamo usarla solo come verifica didattica:\n\n# Confronto con Beta-Binomiale (se applicabile)\na_post &lt;- a + k\nb_post &lt;- b + n - k\n\n# pmf beta-binomial (con funzione base: dbetabinom in VGAM, altrimenti la implementiamo)\ndbetabinom &lt;- function(x, m, a, b) {\n  # Beta-Binomiale: choose(m, x) * Beta(x+a, m-x+b) / Beta(a, b)\n  choose(m, x) * beta(x + a, m - x + b) / beta(a, b)\n}\n\nbb_pmf &lt;- sapply(0:m, function(x) dbetabinom(x, m, a_post, b_post))\ncbind(grid = pred_df$p, beta_binom = bb_pmf)[1:6, ]  # prime 6 righe a confronto\n#&gt;         grid beta_binom\n#&gt; [1,] 0.11391    0.11391\n#&gt; [2,] 0.25061    0.25061\n#&gt; [3,] 0.27618    0.27618\n#&gt; [4,] 0.19946    0.19946\n#&gt; [5,] 0.10398    0.10398\n#&gt; [6,] 0.04069    0.04069\n\n\nmax(abs(pred_df$p - bb_pmf))   # lo scarto massimo (dovrebbe essere ~0 con J grande)\n#&gt; [1] 1.679e-15\n\n\n\n\nNotazione. Useremo talvolta la forma compatta \\(q(\\cdot \\mid y)\\) per indicare la predittiva posteriore del modello. Quando ci servirà evidenziare la previsione marginale per una singola osservazione \\(y_i\\), scriveremo:\n\\[\np(y_i \\mid y)\n\\;=\\;\n\\int p(y_i \\mid \\theta)\\, p(\\theta \\mid y)\\, d\\theta,\n\\]\ncioè la verosimiglianza \\(p(y_i\\mid\\theta)\\) integrata rispetto alla posteriore \\(p(\\theta\\mid y)\\).\nIdea chiave: la predittiva posteriore propaga l’incertezza sui parametri alle previsioni. È questo passaggio a rendere le valutazioni predittive coerenti con il principio bayesiano, e quindi utilizzabili nel confronto tra modelli e nella stima di quantità legate alla “distanza” dal generatore dei dati.\n\n78.1.1 Il problema della valutazione predittiva\nIl nostro obiettivo è capire quanto la distribuzione predittiva posteriore \\(q(\\tilde{y} \\mid y)\\) si avvicini alla vera distribuzione generatrice dei dati futuri, \\(p(\\tilde{y})\\). In teoria, questa distanza si misura con la divergenza di Kullback–Leibler (KL):\n\\[\nD_{\\text{KL}}(p \\parallel q) \\;=\\; \\mathbb{E}_p\\!\\left[ \\log \\frac{p(\\tilde{y})}{q(\\tilde{y} \\mid y)} \\right].\n\\]\nQui però incontriamo subito un problema concettuale: non conosciamo \\(p(\\tilde{y})\\). Per superare questo ostacolo, possiamo ricorrere a misure surrogate che, pur non avendo accesso diretto a \\(p(\\tilde{y})\\), permettono di stimare la qualità predittiva del modello utilizzando in modo ingegnoso i dati osservati. Tra queste, vedremo il log-score, la LPPD e l’ELPD, che forniscono stime indirette della bontà predittiva.\n\n\n\n\n\n\nMappa concettuale\n\n\n\n\n\n\n\n\n\n\nQuantità\nSignificato\nUso principale\n\n\n\n\\(p(y_i \\mid \\theta)\\)\nVerosimiglianza\nCalcolo predittivo\n\n\n\\(p(\\theta \\mid y)\\)\nDistribuzione posteriore\nPonderazione\n\n\n\\(p(y_i \\mid y)\\)\nPredizione bayesiana media\nLog-score, LPPD\n\n\n\\(p(y_i \\mid y_{-i})\\)\nPredizione LOO (leave-one-out)\nELPD\n\n\n\\(q(\\tilde{y} \\mid y)\\)\nDistribuzione predittiva complessiva\nDivergenza KL, confronto modelli",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Valutare i modelli bayesiani: Log-Score, LPPD, ELPD e LOO-CV</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_model_comparison.html#sec-logscore",
    "href": "chapters/entropy/03_model_comparison.html#sec-logscore",
    "title": "78  Valutare i modelli bayesiani: Log-Score, LPPD, ELPD e LOO-CV",
    "section": "\n78.2 Il log-score: accuratezza predittiva punto per punto",
    "text": "78.2 Il log-score: accuratezza predittiva punto per punto\nAbbiamo definito la distribuzione predittiva posteriore. Ora chiediamoci: quanto bene il modello ha previsto ciascun dato osservato? Il log-score risponde proprio a questa domanda: per ogni osservazione \\(y_i\\) misura quanto il modello la considerava plausibile, cioè quanto avrebbe scommesso su quel dato.\nFormalmente,\n\\[\n\\log p(y_i \\mid y)\n\\;=\\;\n\\log \\int p(y_i \\mid \\theta)\\, p(\\theta \\mid y)\\, d\\theta .\n\\tag{78.1}\\]\nSe il modello assegna alta probabilità a \\(y_i\\), \\(\\log p(y_i \\mid y)\\) è vicino a 0 (buono). Se assegna bassa probabilità, il log-score è molto negativo (scarso).\n\n\n\n\n\n\nPerché il logaritmo?\nIl log trasforma prodotti di probabilità in somme. Così possiamo sommare contributi punto per punto dei dati invece di moltiplicarli; inoltre stabilizza i numeri molto piccoli tipici delle verosimiglianze.\n\n\n\n\n78.2.1 Dal singolo dato al punteggio totale\nPer avere una visione complessiva, sommiamo i contributi su tutte le osservazioni:\n\\[\nS\n\\;=\\;\n\\sum_{i=1}^n \\log p(y_i \\mid y) .\n\\tag{78.2}\\]\nPiù \\(S\\) è alto, più il modello “scommette” bene sui dati osservati (in-sample).\n\n78.2.2 Parametri fissati vs. parametri incerti\nCi sono due modi concettualmente distinti per valutare il log-score.\nParametri fissati (impostazione classica). Usiamo una stima puntuale dei parametri (ad es. Massima Verosimiglianza o MAP) e ignoriamo l’incertezza:\n\\[\n\\log p(y_i \\mid \\hat{\\theta}) .\n\\]\nParametri incerti (impostazione bayesiana). Non fissiamo \\(\\theta\\), ma lo trattiamo come incerto e “mescoliamo” le verosimiglianze pesandole per la plausibilità a posteriori:\n\\[\np(y_i \\mid y)\n\\;=\\;\n\\int p(y_i \\mid \\theta)\\, p(\\theta \\mid y)\\, d\\theta .\n\\tag{78.3}\\]\n\n\n\n\n\n\nDifferenza chiave.\nIl frequentista chiede: “Quanto sono plausibili i dati se i parametri valgono esattamente \\(\\hat{\\theta}\\)?”\nIl bayesiano chiede: “Quanto sono plausibili i dati in media, considerando tutti i valori di \\(\\theta\\) compatibili con i dati?”\n\n\n\n\n78.2.3 Come stimare l’integrale in pratica: campioni MCMC\nL’integrale nell’Equazione 78.3 raramente è calcolabile in forma chiusa. Con i campioni MCMC \\(\\theta^{(1)},\\dots,\\theta^{(S)} \\sim p(\\theta\\mid y)\\) possiamo approssimarlo così:\n\nPer ciascun campione \\(\\theta^{(s)}\\) calcoliamo la verosimiglianza del dato \\(y_i\\): \\[\np\\bigl(y_i \\mid \\theta^{(s)}\\bigr).\n\\] Questo produce una collezione di valori \\[\n\\bigl\\{\\, p(y_i \\mid \\theta^{(1)}),\\; p(y_i \\mid \\theta^{(2)}),\\; \\dots,\\; p(y_i \\mid \\theta^{(S)}) \\,\\bigr\\},\n\\] che rappresenta come la plausibilità di \\(y_i\\) varia al variare dei parametri plausibili.\nMedia sui campioni (mixing).\nLa probabilità predittiva puntuale di \\(y_i\\), che useremo nel log-score, è la media di quella collezione: \\[\np(y_i \\mid y)\n\\;\\approx\\;\n\\frac{1}{S}\\sum_{s=1}^S p\\bigl(y_i \\mid \\theta^{(s)}\\bigr).\n\\tag{78.4}\\] Questa media è uno scalare: condensa l’incertezza sui parametri in un’unica previsione probabilistica per \\(y_i\\).\n\n\nMini-illustrazione: se per tre campioni otteniamo \\(\\{0.40, 0.50, 0.60\\}\\), la media è \\(0.50\\). Questo numero è \\(p(y_i \\mid y)\\) da inserire nel log.\n\n\n78.2.4 La LPPD: il log-score bayesiano complessivo\nRipetiamo i passi precedenti per ogni osservazione \\(y_i\\):\n\ncalcoliamo la probabilità predittiva media \\(p(y_i\\mid y)\\) con l’Equazione 78.4;\n\nne prendiamo il logaritmo;\n\n\nsommiamo su tutte le osservazioni.\n\nIl risultato è la Log Pointwise Predictive Density (LPPD):\n\\[\n\\text{LPPD}\n\\;=\\;\n\\sum_{i=1}^n\n\\log \\left[\n\\frac{1}{S}\n\\sum_{s=1}^S\np\\bigl(y_i \\mid \\theta^{(s)}\\bigr)\n\\right].\n\\tag{78.5}\\]\nIn sintesi, il log-score classico usa un solo valore dei parametri \\((\\hat{\\theta})\\); la LPPD compie lo stesso calcolo ma tiene conto dell’incertezza, mediando su tutti i valori plausibili secondo la posterior.\n\n78.2.5 Attenzione all’overfitting\nLa LPPD è calcolata sugli stessi dati usati per stimare il modello: modelli molto flessibili possono “scommettere bene” anche sul rumore, gonfiando la LPPD in-sample. Per valutare la capacità di generalizzazione, serve una stima out-of-sample. Nelle prossime sezioni introdurremo la validazione incrociata leave-one-out (LOO-CV) e l’ELPD (Expected Log Pointwise Predictive Density), che forniscono una versione “fuori campione” della LPPD per il confronto predittivo tra modelli.\n\n\n\n\n\n\nEsempio.\n\n\n\n\n\nConsideriamo un singolo dato \\(y_i = 3\\) successi su \\(n=5\\) tentativi (Binomiale). Abbiamo tre valori plausibili per \\(\\theta\\) dalla posterior, con pesi didattici \\(w^{(s)}\\) (nella pratica MCMC i pesi sono uguali):\n\n\n\\(\\theta^{(1)}=0.3\\) con \\(w^{(1)}=0.2\\)\n\n\n\\(\\theta^{(2)}=0.5\\) con \\(w^{(2)}=0.5\\)\n\n\n\\(\\theta^{(3)}=0.7\\) con \\(w^{(3)}=0.3\\)\n\n\nPer ogni campione \\(\\theta^{(s)}\\) calcoliamo \\(p(y_i \\mid \\theta^{(s)})\\), otteniamo la collezione di likelihood \\(\\{p(y_i\\mid \\theta^{(s)})\\}_{s=1}^S\\), poi facciamo la media pesata (Equazione 78.4) per ottenere \\(p(y_i\\mid y)\\), e infine il log-score \\(\\log p(y_i\\mid y)\\) (Equazione 78.1).\n\n# Dato osservato (un solo punto)\ny_i  &lt;- 3\nn_i  &lt;- 5\n\n# \"Campioni\" posteriori (qui pochi e con pesi espliciti per chiarezza didattica)\ntheta_vals        &lt;- c(0.3, 0.5, 0.7)      # θ^(1), θ^(2), θ^(3)\nposterior_weights &lt;- c(0.2, 0.5, 0.3)      # w^(1), w^(2), w^(3); in MCMC tipicamente uguali\n\n# (1) Likelihood punto-per-punto: p(y_i | θ^(s))\nlikelihoods &lt;- dbinom(y_i, size = n_i, prob = theta_vals)\nlikelihoods  # questa è la collezione { p(y_i | θ^(s)) }_s\n#&gt; [1] 0.1323 0.3125 0.3087\n\n# (2) Media (pesata) sulle likelihood ⇒ p(y_i | y) ≈ Σ_s w^(s) p(y_i | θ^(s))\np_yi_given_y &lt;- sum(posterior_weights * likelihoods)\n\n# (3) Log-score (per un solo dato coincide con la LPPD del singolo punto)\nlog_score_i &lt;- log(p_yi_given_y)\n\n# Stampa riassuntiva con notazione coerente\ncat(\"Campioni θ^{(s)}:        \", theta_vals, \"\\n\")\n#&gt; Campioni θ^{(s)}:         0.3 0.5 0.7\ncat(\"Likelihood p(y_i|θ^{(s)}):\", round(likelihoods, 4), \"\\n\")\n#&gt; Likelihood p(y_i|θ^{(s)}): 0.1323 0.3125 0.3087\ncat(\"p(y_i|y) (media pesata):  \", round(p_yi_given_y, 4), \"\\n\")\n#&gt; p(y_i|y) (media pesata):   0.2753\ncat(\"log p(y_i|y):             \", round(log_score_i, 4), \"\\n\")\n#&gt; log p(y_i|y):              -1.29\n\nNota didattica. Nella pratica con MCMC i pesi sono uguali, \\(w^{(s)}=\\tfrac{1}{S}\\), quindi \\(p(y_i\\mid y) \\approx \\tfrac{1}{S}\\sum_{s=1}^S p(y_i\\mid \\theta^{(s)})\\) (Equazione 78.4). Con più osservazioni \\(\\{y_i\\}_{i=1}^n\\), la LPPD è la somma dei log-score punto-per-punto (Equazione 78.5).\n\n\n\n\n78.2.6 Expected Log Predictive Density (ELPD): guardare oltre i dati osservati\nSe vogliamo valutare la capacità di generalizzazione di un modello, la domanda chiave è: quanto bene predirebbe dati che non ha mai visto? L’ELPD (Expected Log Predictive Density) risponde a questa domanda con la stessa logica della LPPD, ma introduce una differenza fondamentale: la previsione di \\(y_i\\) viene calcolata escludendo \\(y_i\\) dall’adattamento del modello (Leave-One-Out, LOO):\n\\[\n\\text{ELPD} \\;=\\; \\sum_{i=1}^n \\log p(y_i \\mid y_{-i}),\n\\tag{78.6}\\]\ndove \\(y_{-i}\\) indica il dataset a cui è stata rimossa l’osservazione \\(i\\).\nEsempio Nel caso di un test sull’ansia:\n\n\nLPPD → misura quanto bene il modello predice i punteggi di ansia degli studenti già presenti nel campione osservato.\n\nELPD → misura quanto bene predirebbe il punteggio di un nuovo studente, usando solo i dati degli altri.\n\nIn sostanza, l’ELPD è una stima empirica (con segno cambiato) della divergenza di Kullback–Leibler tra la vera distribuzione dei dati futuri e la distribuzione predittiva del modello. Ci fornisce quindi un indicatore diretto di quanto le previsioni del modello si avvicinano a ciò che accadrà davvero, senza richiedere di conoscere la distribuzione reale.\n\n\n\n\n\n\nInterpretazione: l’ELPD è un log-score out-of-sample: per ogni \\(y_i\\), lo escludiamo, adattiamo il modello agli altri dati, e valutiamo la probabilità predittiva di \\(y_i\\). Più alto è l’ELPD, migliore è la capacità del modello di generalizzare a dati nuovi.\n\n\n\n\n\n\n\n\n\nEsempio.\n\n\n\n\n\nSupponiamo di avere tre osservazioni \\(y_1, y_2, y_3\\) e che il modello stimi:\n\\[\np(y_1 \\mid y_2,y_3)=0.6,\\quad p(y_2 \\mid y_1,y_3)=0.7,\\quad p(y_3 \\mid y_1,y_2)=0.5.\n\\]\nL’ELPD è:\n\\[\n\\log 0.6 + \\log 0.7 + \\log 0.5 \\; \\approx\\; -0.5108 -0.3567 -0.6931 = -1.5606.\n\\]\nUn valore meno negativo indica maggiore capacità predittiva fuori campione.\n\n\n\n\n78.2.7 LPPD vs. ELPD in sintesi\n\n\n\n\n\n\n\n\nMisura\nDati usati per predire \\(y_i\\)\n\nValuta\nLimite principale\n\n\n\nLPPD\nTutti i dati, incluso \\(y_i\\)\n\nAdattamento in-sample\nRischio di overfitting\n\n\nELPD\nTutti i dati tranne \\(y_i\\) (LOO)\nGeneralizzazione\n—\n\n\n\nMetafora In un esperimento di riconoscimento di volti, mostriamo a un partecipante 100 fotografie e lo alleniamo a riconoscerle:\n\n\nLPPD → misura quanto bene riconosce quelle stesse foto, già viste in fase di addestramento (in-sample).\n\nELPD → misura quanto bene riconosce nuove foto, mai viste prima, cioè immagini fuori dall’insieme di addestramento (out-of-sample).\n\nSe il punteggio LPPD è alto ma l’ELPD è basso, significa che il partecipante — o il modello — ha memorizzato i casi specifici, senza aver appreso regole generali utili per nuovi dati.\n\n78.2.8 Il collegamento con la divergenza KL\nLa divergenza di Kullback–Leibler \\(D_{\\text{KL}}\\) misura teoricamente la distanza tra la distribuzione vera dei dati, \\(p(\\tilde{y})\\), e la distribuzione predittiva del modello, \\(q(\\tilde{y} \\mid y)\\).\nNel confronto tra due modelli \\(A\\) e \\(B\\), la differenza nelle loro \\(D_{\\text{KL}}\\) equivale alla differenza nelle rispettive accuratezze predittive medie rispetto a \\(p(\\tilde{y})\\).\nPoiché \\(p(\\tilde{y})\\) è sconosciuta, non possiamo calcolare direttamente la KL. L’ELPD fornisce una stima empirica di questa accuratezza predittiva: un valore più alto implica un modello più “vicino” alla distribuzione vera.\n\\[\n\\text{Massimizzare ELPD} \\;\\; \\approx \\;\\; \\text{Minimizzare la divergenza KL}.\n\\]\n\n\n\n\n\n\nPerché ELPD ≈ - KL?\n\n\n\nPer definizione:\n\\[\nD_{\\text{KL}}\\big(p \\parallel q\\big)\n= \\mathbb{E}_{p} \\!\\left[ \\log \\frac{p(\\tilde{y})}{q(\\tilde{y} \\mid y)} \\right]\n= \\mathbb{E}_{p}[\\log p(\\tilde{y})] - \\mathbb{E}_{p}[\\log q(\\tilde{y} \\mid y)].\n\\]\n\nIl primo termine \\(\\mathbb{E}_{p}[\\log p(\\tilde{y})]\\) non dipende dal modello (è fisso per tutti).\nConfrontare due modelli equivale quindi a confrontare solo il secondo termine, che è \\(-\\)ELPD.\n\nEcco perché massimizzare l’ELPD equivale a minimizzare la divergenza KL: si sta massimizzando la media log-predittiva che il modello assegna ai dati futuri.\n\n\n\n\n\n\n\n\nEsempio.\n\n\n\n\n\nVogliamo confrontare due modelli predittivi per il numero di “teste” in \\(n=10\\) lanci.\n\nLa distribuzione vera è \\(p(y)=\\text{Binom}(n=10,\\;p=0.6)\\).\nIl modello candidato prevede \\(q(y)=\\text{Binom}(n=10,\\;q=0.5)\\).\n\nL’ELPD di un modello è l’aspettativa, rispetto alla distribuzione vera \\(p\\), del log-score del modello: \\(\\mathrm{ELPD}(q)=\\mathbb{E}_{p}[\\log q(Y)]\\). Nel caso discreto, l’aspettativa diventa una somma su tutti i possibili valori \\(y=0,\\dots,n\\).\n\n# Parametri del problema\nn &lt;- 10          # numero di lanci\np &lt;- 0.6         # probabilità vera di \"testa\"\nq &lt;- 0.5         # probabilità ipotizzata dal modello candidato\n\n# 1) Supporto dei possibili esiti\ny_vals &lt;- 0:n\n\n# 2) Distribuzione vera p(y) su tutto il supporto\np_y &lt;- dbinom(y_vals, size = n, prob = p)\n\n# 3) Log-predittiva del modello candidato q su tutto il supporto\nlog_q_y &lt;- log(dbinom(y_vals, size = n, prob = q))\n\n# 4) ELPD del modello candidato: somma dei log q(y) pesati da p(y)\nelpd_q &lt;- sum(p_y * log_q_y)\n\n# 5) \"Modello vero\": usa q = p. Log-predittiva del modello vero\nlog_p_y &lt;- log(dbinom(y_vals, size = n, prob = p))\n\n# 6) ELPD del modello vero: somma dei log p(y) pesati da p(y)\nelpd_p &lt;- sum(p_y * log_p_y)\n\n# 7) Divergenza KL tra p e q: somma p(y) * log [p(y)/q(y)]\nkl_pq &lt;- sum(p_y * (log_p_y - log_q_y))\n\ncat(sprintf(\"ELPD modello candidato (q=0.5): %.4f\\n\", elpd_q))\n#&gt; ELPD modello candidato (q=0.5): -2.0549\ncat(sprintf(\"ELPD modello vero      (q=0.6): %.4f\\n\", elpd_p))\n#&gt; ELPD modello vero      (q=0.6): -1.8536\ncat(sprintf(\"Differenza ELPD (vero - candidato): %.4f\\n\", elpd_p - elpd_q))\n#&gt; Differenza ELPD (vero - candidato): 0.2014\ncat(sprintf(\"KL(p || q): %.4f\\n\", kl_pq))\n#&gt; KL(p || q): 0.2014\n\nCosa stiamo verificando?\n\n\\(\\mathrm{ELPD}(q)=\\sum_y p(y)\\log q(y)\\) è più basso (più negativo) del valore ottenuto dal modello vero \\(\\mathrm{ELPD}(p)=\\sum_y p(y)\\log p(y)\\). → Il modello con \\(q=0.6\\) è più predittivo di quello con \\(q=0.5\\).\nLa differenza tra i due ELPD è uguale (vicina numericamente) alla divergenza di Kullback–Leibler:\n\n\\[\n\\mathrm{ELPD}(p)-\\mathrm{ELPD}(q)\n= \\sum_y p(y)\\big[\\log p(y)-\\log q(y)\\big]\n= D_{\\mathrm{KL}}(p\\|q)\\;&gt;\\;0.\n\\]\n→ Questo mostra algebricamente e numericamente il legame: massimizzare l’ELPD equivale a minimizzare la KL.\n\nNota sul log: nel codice usiamo il log naturale (unità in nat). Se si preferisce il log in base 2 (unità in bit), basta sostituire log() con log2(); tutte le quantità cambiano di una costante di scala, ma i confronti tra modelli restano identici.\n\nIn pratica.\nIn questo esempio abbiamo potuto calcolare l’ELPD vero perché conoscevamo l’intera distribuzione generatrice \\(p(y)\\) e potevamo integrare esattamente. Nella realtà, \\(p(y)\\) è sconosciuta: disponiamo solo di un campione osservato. In questi casi stimiamo l’ELPD empiricamente, ad esempio con la Leave-One-Out Cross-Validation (LOO-CV), che sostituisce l’aspettativa rispetto a \\(p\\) con una media sui dati raccolti, lasciando fuori una osservazione alla volta. Questa procedura ci consente di avvicinarci al calcolo ideale della KL, anche senza conoscere \\(p(y)\\).\n\n\n\n\n\n\n\n\n\nCollegamento chiave\nL’ELPD è una stima empirica (con segno cambiato) della divergenza di Kullback–Leibler.\nPiù alto è l’ELPD, migliore è la capacità predittiva del modello.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Valutare i modelli bayesiani: Log-Score, LPPD, ELPD e LOO-CV</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_model_comparison.html#leave-one-out-cross-validation-loo-cv-stimare-lelpd-nella-pratica",
    "href": "chapters/entropy/03_model_comparison.html#leave-one-out-cross-validation-loo-cv-stimare-lelpd-nella-pratica",
    "title": "78  Valutare i modelli bayesiani: Log-Score, LPPD, ELPD e LOO-CV",
    "section": "\n78.3 Leave-One-Out Cross-Validation (LOO-CV): stimare l’ELPD nella pratica",
    "text": "78.3 Leave-One-Out Cross-Validation (LOO-CV): stimare l’ELPD nella pratica\nPoiché la distribuzione vera dei dati futuri è inaccessibile, dobbiamo usare metodi indiretti per stimare quanto bene il nostro modello prevede nuove osservazioni. La validazione incrociata Leave-One-Out (LOO-CV) è uno di questi metodi e, se combinata con l’uso dell’Expected Log Predictive Density (ELPD), diventa uno strumento potente per il confronto tra modelli.\nAbbiamo visto che l’ELPD è la misura ideale della capacità predittiva di un modello su dati futuri. Il problema è che, per definizione, richiede di calcolare un’aspettativa rispetto alla vera distribuzione generatrice \\(p(\\tilde{y})\\), che non conosciamo.\nCome possiamo stimarla in pratica? Usando la LOO-CV, che simula la previsione di nuovi dati sfruttando solo le informazioni presenti nei dati osservati.\n\n78.3.1 Cos’è la LOO-CV\nLa LOO-CV è un esperimento concettuale semplice:\n\nScegli un’osservazione \\(y_i\\) dal dataset.\nEscludila dal set di addestramento.\nAdatta il modello ai dati rimanenti \\(y_{-i}\\).\nCalcola la densità predittiva del modello per l’osservazione esclusa: \\(p(y_i \\mid y_{-i})\\).\nRipeti per ogni osservazione e somma i logaritmi ottenuti.\n\nFormalmente:\n\\[\n\\text{ELPD}_{\\text{LOO}} = \\sum_{i=1}^{n} \\log p(y_i \\mid y_{-i}),\n\\tag{78.7}\\]\ndove \\(y_{-i}\\) indica il dataset senza l’osservazione \\(i\\).\nLa struttura è identica a quella dell’ELPD “ideale”, ma ogni termine è calcolato fuori campione, escludendo il dato che viene valutato.\nUn’analogia: è come escludere uno studente dall’allenamento e verificare se il modello riesce a predire il suo punteggio d’esame; ripetendo questo processo per tutti gli studenti otteniamo una misura diretta della capacità di generalizzazione.\n\n78.3.2 Perché LOO-CV funziona\nL’ELPD può essere scritto come:\n\\[\n\\mathbb{E}_p[\\log q(\\tilde{y} \\mid y)],\n\\tag{78.8}\\]\ndove \\(q(\\tilde{y} \\mid y)\\) è la distribuzione predittiva del modello.\nNon possiamo calcolare l’aspettativa rispetto a \\(p(\\tilde{y})\\), ma possiamo trattare ogni osservazione \\(y_i\\) come “nuovo dato” generato da \\(p\\) e usare la media empirica sulle osservazioni reali come stima dell’aspettativa:\n\\[\n\\text{ELPD}_{\\text{LOO}} \\approx \\mathbb{E}_p[\\log q(\\tilde{y} \\mid y)].\n\\]\nIn altre parole: LOO-CV misura quanto bene il modello predirebbe ciascun dato se non lo avesse mai visto.\n\n78.3.3 Legame con la divergenza KL\nLa divergenza di Kullback–Leibler è definita come:\n\\[\nD_{\\text{KL}}(p \\parallel q) = \\mathbb{E}_p[\\log p(\\tilde{y})] - \\mathbb{E}_p[\\log q(\\tilde{y} \\mid y)].\n\\]\nIl primo termine, l’entropia di \\(p\\), è lo stesso per tutti i modelli e scompare nel confronto.\nNe segue che, per due modelli \\(q_1\\) e \\(q_2\\):\n\\[\nD_{\\text{KL}}(p \\parallel q_1) - D_{\\text{KL}}(p \\parallel q_2) =\n\\mathbb{E}_p[\\log q\\_2(\\tilde{y} \\mid y)] - \\mathbb{E}_p[\\log q_1(\\tilde{y} \\mid y)].\n\\]\nVince il modello con ELPD più alto, perché corrisponde alla minore divergenza KL dalla distribuzione vera.\n\n78.3.4 Confrontare i modelli con LOO-CV\nPoiché \\(p(\\tilde{y})\\) è sconosciuta, sostituiamo l’aspettativa teorica con la stima empirica via LOO:\n\\[\n\\Delta\\text{ELPD} = \\text{ELPD}*{\\text{LOO}}(M_1) - \\text{ELPD}*{\\text{LOO}}(M_2) .\n\\tag{78.9}\\]\n\\(\\Delta\\text{ELPD}\\) approssima la differenza tra le divergenze KL dei modelli.\nOltre alla differenza, possiamo stimare un errore standard per capire se la superiorità di un modello è robusta o dovuta al caso.\n\n78.3.5 Punti chiave\n\n\nProblema: L’ELPD teorico richiede \\(p(\\tilde{y})\\), che è sconosciuta.\n\n\nSoluzione: LOO-CV fornisce una stima empirica out-of-sample.\n\n\nTeoria: L’ELPD è direttamente collegato alla parte “accuratezza” della KL-divergence.\n\n\nPratica: Massimizzare l’ELPD stimato equivale a scegliere il modello più vicino alla distribuzione vera.\n\nDirei che l’esempio che hai scritto è già molto chiaro e in linea con il testo precedente, ma per integrarlo meglio nel capitolo e mantenere continuità con la sezione teorica, potremmo:\n\n\nAggiungere un’introduzione contestuale per collegarlo subito alla discussione ELPD–LOO–KL.\n\nRendere più esplicito il parallelismo con la teoria (ELPD come somma delle log-predittive fuori campione).\n\nSintetizzare il codice con commenti chiave, così che lo studente possa leggerlo senza perdersi nei dettagli secondari.\n\nChiarire il senso della tabella subito dopo l’esecuzione del codice.\n\n\n\n\n\n\n\nEsempio: confronto ELPD-LOO tra due modelli\n\n\n\n\n\nQuesto mini-esempio mostra come passare dalla definizione teorica dell’ELPD alla stima pratica via Leave-One-Out, usando un caso elementare Beta–Bernoulli.\nDati. Cinque prove indipendenti: \\(y=\\{1,1,1,0,1\\}\\) (quattro “successi”, un “insuccesso”).\nModello A (Bayesiano adattato ai dati). Bernoulli\\((\\theta)\\) con prior \\(\\theta\\sim \\text{Beta}(1,1)\\) (uninformativa). Per LOO:\n\nper ogni \\(i\\), escludiamo \\(y_i\\);\ncalcoliamo la posteriore \\(\\theta \\mid y_{-i} \\sim \\text{Beta}(1+s_{-i},\\,1+n_{-i}-s_{-i})\\), dove \\(s_{-i}\\) è il numero di successi tra i \\(n-1\\) rimanenti;\ncalcoliamo la probabilità predittiva per \\(y_i\\).\n\nModello B (di confronto). Moneta equa fissa (\\(q=0.5\\)): la predittiva è sempre \\(0.5\\), indipendentemente dai dati.\n\n# Dati\ny &lt;- c(1, 1, 1, 0, 1)\nn &lt;- length(y)\n\n# Log-predittiva LOO per Modello A (Beta(1,1) + Bernoulli)\nloo_log_pred_beta &lt;- function(i, y, a0 = 1, b0 = 1) {\n  yi &lt;- y[i]\n  s_minus &lt;- sum(y) - yi\n  n_minus &lt;- n - 1\n  alpha &lt;- a0 + s_minus\n  beta  &lt;- b0 + (n_minus - s_minus)\n  p1 &lt;- alpha / (alpha + beta)\n  p  &lt;- if (yi == 1) p1 else (1 - p1)\n  log(p)\n}\n\n# Log-predittive punto-per-punto\nlp_beta  &lt;- sapply(seq_along(y), loo_log_pred_beta, y = y)\nlp_fixed &lt;- rep(log(0.5), n)\n\n# ELPD-LOO\nelpd_beta  &lt;- sum(lp_beta)\nelpd_fixed &lt;- sum(lp_fixed)\n\n# Differenza e SE\ndiff_pt &lt;- lp_beta - lp_fixed\nse_diff &lt;- sqrt(n * var(diff_pt))\n\n# Tabella riassuntiva\nres &lt;- data.frame(\n  i = 1:n, y = y,\n  lp_beta = round(lp_beta, 6),\n  lp_fixed = round(lp_fixed, 6),\n  diff = round(diff_pt, 6)\n)\nprint(res)\n#&gt;   i y lp_beta lp_fixed    diff\n#&gt; 1 1 1 -0.4055  -0.6931  0.2877\n#&gt; 2 2 1 -0.4055  -0.6931  0.2877\n#&gt; 3 3 1 -0.4055  -0.6931  0.2877\n#&gt; 4 4 0 -1.7918  -0.6931 -1.0986\n#&gt; 5 5 1 -0.4055  -0.6931  0.2877\ncat(sprintf(\"\\nELPD-LOO Modello A: %.6f\\n\", elpd_beta))\n#&gt; \n#&gt; ELPD-LOO Modello A: -3.413620\ncat(sprintf(\"ELPD-LOO Modello B: %.6f\\n\", elpd_fixed))\n#&gt; ELPD-LOO Modello B: -3.465736\ncat(sprintf(\"Differenza (A-B)  : %.6f\\n\", elpd_beta - elpd_fixed))\n#&gt; Differenza (A-B)  : 0.052116\ncat(sprintf(\"SE differenza     : %.6f\\n\", se_diff))\n#&gt; SE differenza     : 1.386294\n\nInterpretazione.\n\nOgni riga della tabella mostra la log-predittiva fuori campione per entrambi i modelli.\nIn un campione con 4 successi su 5, il Modello A assegna più di 0.5 di probabilità ai successi, e meno di 0.5 all’unico insuccesso.\nL’ELPD-LOO di A può risultare leggermente più alto di quello di B, ma l’errore standard è grande perché \\(n\\) è piccolo.\n\n\nRegola pratica: una differenza \\(|\\Delta \\text{ELPD}|\\) di almeno 2 volte l’SE fornisce un’indicazione più affidabile di superiorità del modello. In esempi così piccoli l’obiettivo è puramente didattico: capire come si calcola e cosa significa.\n\n\n\n\n\n78.3.6 ELPD-LOO e il problema dell’overfitting\nValutare un modello sugli stessi dati usati per addestrarlo tende a gonfiare le stime della sua capacità predittiva (overfitting). È come se uno studente ottenesse un punteggio perfetto ripetendo esercizi già svolti: non sappiamo se saprebbe risolverne di nuovi.\nLa Leave-One-Out Cross-Validation (LOO-CV) aggira il problema valutando ciascuna osservazione \\(y_i\\) usando solo i dati rimanenti (\\(y_{-i}\\)). Il punteggio ottenuto (ELPD-LOO) è quindi una stima out-of-sample della bontà predittiva, meno sensibile all’overfitting.\nGrazie a metodi come il Pareto-smoothed importance sampling (PSIS), oggi è possibile calcolare l’ELPD-LOO senza riadattare il modello \\(n\\) volte. In R, la funzione loo() del pacchetto loo (integrata in brms e rstanarm) rende questa procedura rapida e diretta anche per modelli complessi.\n\n\n\n\n\n\nEsempio: ELPD atteso vs ELPD-LOO stimato\n\n\n\n\n\nQuando conosci la distribuzione vera dei dati (\\(p\\)), puoi calcolare l’ELPD atteso in modo esatto. Quando invece hai solo i dati osservati, lo stimi tramite Leave-One-Out (PSIS-LOO), come mostrato di seguito.\nELPD atteso (p noto)\n\nn &lt;- 10\np &lt;- 0.6\nq &lt;- 0.5\n\ny_vals   &lt;- 0:n\np_y      &lt;- dbinom(y_vals, size = n, prob = p)\nlog_q_y  &lt;- log(dbinom(y_vals, size = n, prob = q))\nelpd     &lt;- sum(p_y * log_q_y)\n\ncat(sprintf(\"ELPD atteso (modello q = 0.5): %.4f\\n\", elpd))\n#&gt; ELPD atteso (modello q = 0.5): -2.0549\n\nELPD-LOO stimato da dati simulati\n\nset.seed(123)\ndf &lt;- data.frame(\n  k = rbinom(20, size = n, prob = p),\n  n = n\n)\n\nfit &lt;- brm(k | trials(n) ~ 1, data = df,\n           family = binomial(),\n           prior = prior(constant(0), class = \"Intercept\"),\n           iter = 2000, chains = 2)\n\nloo_res &lt;- loo(fit)\nprint(loo_res)\n\nL’oggetto loo_res fornisce l’ELPD-LOO, il suo errore standard, e le statistiche Pareto k per la diagnostica. Con loo_compare() puoi confrontare due modelli sulla base della differenza di ELPD-LOO e del relativo SE.\n\n\n\n\n\n\n\n\n\nIn pratica: stimare e confrontare l’ELPD-LOO\n\n\n\n\n\nConcetto chiave\n\nL’ELPD valuta la capacità predittiva su dati non visti.\nLa LOO-CV lo stima in modo efficiente con PSIS-LOO.\n\nStrumenti\n\nFunzione loo() del pacchetto loo, integrata in brms e rstanarm.\nDiagnostica con Pareto k, confronto con loo_compare().\n\nWorkflow tipico in R\n\nAdattare ogni modello (brm() o stan_glm()).\nEstrarre log_lik() e calcolare loo().\nConfrontare modelli con loo_compare().\n\nDecisione\n\nPreferire l’ELPD-LOO più alto.\nDifferenza ≥ 2×SE → indicazione di vantaggio sostanziale.\nValutare anche semplicità e interpretabilità.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Valutare i modelli bayesiani: Log-Score, LPPD, ELPD e LOO-CV</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_model_comparison.html#criteri-di-informazione-come-approssimazioni-della-divergenza-d_textkl",
    "href": "chapters/entropy/03_model_comparison.html#criteri-di-informazione-come-approssimazioni-della-divergenza-d_textkl",
    "title": "78  Valutare i modelli bayesiani: Log-Score, LPPD, ELPD e LOO-CV",
    "section": "\n78.4 Criteri di informazione come approssimazioni della divergenza \\(D_{\\text{KL}}\\)\n",
    "text": "78.4 Criteri di informazione come approssimazioni della divergenza \\(D_{\\text{KL}}\\)\n\nOltre alla Leave-One-Out Cross-Validation, esistono altri strumenti per stimare la qualità predittiva di un modello senza dover conoscere la distribuzione vera dei dati. Molti di questi metodi derivano, in modo più o meno diretto, dalla divergenza di Kullback–Leibler \\(D_{\\text{KL}}\\), che — come visto — misura la distanza tra la distribuzione reale e quella stimata dal modello.\nL’idea di base è sempre la stessa:\n\nvalutare quanto bene il modello spiega i dati (bontà di adattamento);\npenalizzare la complessità del modello, per ridurre il rischio di overfitting.\n\nQuesta logica si traduce in criteri di informazione che combinano due componenti:\n\n\ntermine di fit: misura di quanto bene il modello si adatta ai dati osservati (es. log-verosimiglianza, MSE);\n\ntermine di penalizzazione: aumenta con il numero di parametri o con la flessibilità del modello.\n\nTra i criteri più usati troviamo:\n\n\nMSE (Mean Squared Error) – semplice e intuitivo, basato sugli errori di previsione;\n\nAIC (Akaike Information Criterion) – approssima \\(D_{\\text{KL}}\\) tra il modello e la verità, penalizzando il numero di parametri;\n\nBIC (Bayesian Information Criterion) – simile all’AIC, ma con penalizzazione più forte per modelli complessi, proporzionale al numero di osservazioni;\n\nWAIC (Widely Applicable Information Criterion) – versione pienamente bayesiana, basata sulle previsioni del modello integrate sull’intera distribuzione a posteriori.\n\nNelle sezioni seguenti vedremo come ciascun criterio si calcola, quali assunzioni richiede e in quali situazioni è preferibile rispetto agli altri.\n\n78.4.1 Errore Quadratico Medio (MSE)\nL’Errore Quadratico Medio misura la media delle differenze al quadrato tra valori osservati e previsti:\n\\[\nMSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2.\n\\tag{78.10}\\]\n\nValori più bassi indicano previsioni più vicine ai dati osservati.\nNon tiene conto della complessità del modello, quindi può favorire modelli eccessivamente flessibili (overfitting).\n\nUtile per valutare l’accuratezza, ma da solo non è adatto a scegliere tra modelli con diversa complessità.\n\n78.4.2 Akaike Information Criterion (AIC)\nL’AIC è un’approssimazione della divergenza \\(D_{\\text{KL}}\\) e stima quanta informazione si perde usando un modello per descrivere i dati:\n\\[\nAIC = -2 \\sum_{i=1}^{n} \\log p(y_i \\mid \\hat{\\theta}_{\\text{MLE}}) + 2k,\n\\tag{78.11}\\]\ndove:\n\n\n\\(\\hat{\\theta}_{\\text{MLE}}\\): stima dei parametri ottenuta massimizzando la verosimiglianza;\n\n\\(k\\): numero di parametri del modello.\n\nInterpretazione\n\nIl primo termine valuta l’adattamento del modello ai dati.\nIl secondo penalizza la complessità per evitare overfitting.\nUn AIC più basso indica un miglior equilibrio tra accuratezza e semplicità.\n\nLimiti\n\nBasato su assunzioni asintotiche (funziona meglio con campioni grandi).\nUsa solo stime puntuali, ignorando l’incertezza dei parametri.\nNon è pienamente coerente con l’approccio bayesiano.\n\n78.4.3 Bayesian Information Criterion (BIC)\nIl BIC valuta il compromesso tra adattamento ai dati e complessità del modello, applicando una penalizzazione più severa rispetto all’AIC — soprattutto quando il numero di osservazioni \\(n\\) è grande.\n\\[\nBIC = -2 \\log p(y \\mid \\hat{\\theta}) + \\log(n) \\cdot k,\n\\tag{78.12}\\]\ndove:\n\n\n\\(p(y \\mid \\hat{\\theta})\\): massima verosimiglianza del modello (o MAP con prior piatti);\n\n\\(n\\): numero di osservazioni indipendenti;\n\n\\(k\\): numero di parametri stimati.\n\nInterpretazione\n\nIl primo termine misura l’adattamento ai dati.\nIl secondo penalizza la complessità in modo crescente con \\(n\\) e \\(k\\).\nUn BIC più basso indica un compromesso migliore tra accuratezza e parsimonia.\n\nVantaggi\n\nTende a favorire modelli più semplici quando \\(n\\) è elevato.\nHa una giustificazione teorica bayesiana: in certe condizioni, approssima il log della marginal likelihood.\n\nLimiti\n\nSi basa su assunzioni forti (indipendenza, modelli regolari, prior deboli).\nPuò sottoselezionare modelli utili con campioni piccoli o strutture complesse.\n\n78.4.4 Widely Applicable Information Criterion (WAIC)\nIl WAIC è una versione pienamente bayesiana dell’AIC:\n\nutilizza tutta la distribuzione a posteriori dei parametri;\nfornisce una stima diretta della capacità predittiva del modello.\n\n\\[\nWAIC = -2 \\left[\n\\sum_{i=1}^{n} \\log \\left( \\frac{1}{S} \\sum_{s=1}^{S} p(y_i \\mid \\theta^{(s)}) \\right) -\n\\sum_{i=1}^{n} \\mathrm{Var}_{\\theta^{(s)}} \\big( \\log p(y_i \\mid \\theta^{(s)}) \\big)\n\\right],\n\\tag{78.13}\\]\ndove:\n\n\n\\(S\\) = numero di campioni dalla distribuzione a posteriori;\n\n\\(\\theta^{(s)}\\) = \\(s\\)-esimo campione;\nil secondo termine stima il numero effettivo di parametri basato sulla variabilità della log-verosimiglianza.\n\nVantaggi\n\nAdatto anche a modelli complessi o non regolari.\nUsa direttamente i campioni MCMC.\nMigliore dell’AIC per modelli bayesiani, perché incorpora l’incertezza dei parametri.\n\nNota. Il WAIC è strettamente collegato all’ELPD: è una sua stima approssimata ottenuta dalla distribuzione a posteriori, senza bisogno di eseguire la LOO-CV.\n\n\n\n\n\n\n\nRiepilogo comparativo dei criteri di valutazione del modello\n\n\nCriterio\nTipo\nPenalizza la complessità\nUsa stime puntuali\nBasato su campioni a posteriori (es. MCMC)\n\n\n\n\nMSE\nFrequentista\nNo\nSì\nNo\n\n\nAIC\nFrequentista\nSì (modesta)\nSì\nNo\n\n\nBIC\nFrequentista/Bayesiano\nSì (forte)\nSì\nNo\n\n\nWAIC\nBayesiano\nSì (effettiva)\nNo\nSì\n\n\nLOO-CV\nBayesiano\nSì (empirica)\nNo\nSì",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Valutare i modelli bayesiani: Log-Score, LPPD, ELPD e LOO-CV</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_model_comparison.html#riflessioni-conclusive",
    "href": "chapters/entropy/03_model_comparison.html#riflessioni-conclusive",
    "title": "78  Valutare i modelli bayesiani: Log-Score, LPPD, ELPD e LOO-CV",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nLa selezione del modello, in ottica bayesiana, ruota attorno a una domanda essenziale: quanto bene il modello predice dati che non ha mai visto?\nIl riferimento teorico è l’Expected Log Predictive Density (ELPD), che misura quanto la distribuzione predittiva del modello si avvicina alla vera (e ignota) distribuzione dei dati. In termini matematici, massimizzare l’ELPD equivale a minimizzare la divergenza di Kullback–Leibler rispetto alla vera generatrice: due facce dello stesso obiettivo, rappresentare al meglio la realtà sottostante.\nPoiché \\(p_{\\text{vera}}(y)\\) è sconosciuta, l’ELPD va stimato. Le principali approssimazioni sono:\n\n\nLOO-CV (Leave-One-Out Cross-Validation): oggi lo strumento più affidabile, valuta ogni osservazione come “nuova” e stima la capacità di generalizzazione del modello.\n\nWAIC: alternativa completamente bayesiana, calcolata direttamente dai campioni della posteriori.\n\nAIC e BIC: criteri frequenstisti più rapidi ma basati su stime puntuali; utili in contesti semplici.\n\nMSE: misura l’accuratezza sulle osservazioni note, ma non penalizza la complessità e quindi non è adatto alla selezione del modello.\n\nNel confronto tra modelli, la differenza di ELPD (stimata con LOO-CV o WAIC) andrebbe interpretata insieme al relativo errore standard: una regola pratica è considerare rilevante una differenza almeno doppia rispetto all’errore standard.\nIn sintesi:\n\nla buona statistica non si limita a spiegare il passato: sa anticipare il futuro;\nla divergenza KL fornisce la misura teorica della distanza tra modello e realtà;\nl’ELPD, stimato via LOO-CV o WAIC, traduce questa misura in una valutazione pratica della capacità predittiva;\nla scelta del modello ottimale richiede un equilibrio tra accuratezza, generalizzazione e parsimonia.\n\nCon questi strumenti possiamo individuare modelli che colgono i veri pattern nei dati, evitando di farsi ingannare dal rumore e garantendo previsioni solide anche in contesti complessi.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Valutare i modelli bayesiani: Log-Score, LPPD, ELPD e LOO-CV</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_model_comparison.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/entropy/03_model_comparison.html#informazioni-sullambiente-di-sviluppo",
    "title": "78  Valutare i modelli bayesiani: Log-Score, LPPD, ELPD e LOO-CV",
    "section": "Informazioni sull’ambiente di sviluppo",
    "text": "Informazioni sull’ambiente di sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] gt_1.0.0              pillar_1.11.0         tinytable_0.11.0     \n#&gt;  [4] patchwork_1.3.1       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt;  [7] bayesplot_1.13.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [10] priorsense_1.1.0      posterior_1.6.1       loo_2.8.0            \n#&gt; [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [16] Rcpp_1.1.0            conflicted_1.2.0      janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3        inline_0.3.21        sandwich_3.1-1      \n#&gt;  [4] rlang_1.1.6          magrittr_2.0.3       multcomp_1.4-28     \n#&gt;  [7] snakecase_0.11.1     compiler_4.5.1       vctrs_0.6.5         \n#&gt; [10] stringr_1.5.1        pkgconfig_2.0.3      arrayhelpers_1.1-0  \n#&gt; [13] fastmap_1.2.0        backports_1.5.0      labeling_0.4.3      \n#&gt; [16] cmdstanr_0.9.0       rmarkdown_2.29       markdown_2.0        \n#&gt; [19] ps_1.9.1             purrr_1.1.0          xfun_0.52           \n#&gt; [22] cachem_1.1.0         litedown_0.7         jsonlite_2.0.0      \n#&gt; [25] broom_1.0.9          parallel_4.5.1       R6_2.6.1            \n#&gt; [28] stringi_1.8.7        RColorBrewer_1.1-3   lubridate_1.9.4     \n#&gt; [31] estimability_1.5.1   knitr_1.50           zoo_1.8-14          \n#&gt; [34] base64enc_0.1-3      Matrix_1.7-3         splines_4.5.1       \n#&gt; [37] timechange_0.3.0     tidyselect_1.2.1     abind_1.4-8         \n#&gt; [40] yaml_2.3.10          codetools_0.2-20     curl_6.4.0          \n#&gt; [43] processx_3.8.6       pkgbuild_1.4.8       lattice_0.22-7      \n#&gt; [46] withr_3.0.2          bridgesampling_1.1-2 coda_0.19-4.1       \n#&gt; [49] evaluate_1.0.4       survival_3.8-3       RcppParallel_5.1.10 \n#&gt; [52] xml2_1.3.8           tensorA_0.36.2.1     checkmate_2.3.2     \n#&gt; [55] stats4_4.5.1         distributional_0.5.0 generics_0.1.4      \n#&gt; [58] rprojroot_2.1.0      commonmark_2.0.0     rstantools_2.4.0    \n#&gt; [61] scales_1.4.0         xtable_1.8-4         glue_1.8.0          \n#&gt; [64] emmeans_1.11.2       tools_4.5.1          data.table_1.17.8   \n#&gt; [67] mvtnorm_1.3-3        grid_4.5.1           QuickJSR_1.8.0      \n#&gt; [70] colorspace_2.1-1     nlme_3.1-168         cli_3.6.5           \n#&gt; [73] svUnit_1.0.6         Brobdingnag_1.2-9    V8_6.0.5            \n#&gt; [76] gtable_0.3.6         sass_0.4.10          digest_0.6.37       \n#&gt; [79] TH.data_1.1-3        htmlwidgets_1.6.4    farver_2.1.2        \n#&gt; [82] memoise_2.0.1        htmltools_0.5.8.1    lifecycle_1.0.4     \n#&gt; [85] MASS_7.3-65",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Valutare i modelli bayesiani: Log-Score, LPPD, ELPD e LOO-CV</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_model_comparison.html#bibliografia",
    "href": "chapters/entropy/03_model_comparison.html#bibliografia",
    "title": "78  Valutare i modelli bayesiani: Log-Score, LPPD, ELPD e LOO-CV",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Valutare i modelli bayesiani: Log-Score, LPPD, ELPD e LOO-CV</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/introduction.html",
    "href": "chapters/formal_models/introduction.html",
    "title": "79  Teorie formali dei fenomeni psicologici",
    "section": "",
    "text": "Introduzione\nTradizionalmente, molti modelli cognitivi trattano i dati come osservazioni indipendenti e identicamente distribuite (IID). Questa assunzione semplifica l’analisi, ma trascura un aspetto cruciale: i costrutti psicologici cambiano nel tempo. Negli esperimenti, le capacità cognitive non dipendono solo dalle caratteristiche del compito, ma anche da processi mentali interni e da stati cerebrali che fluttuano su diverse scale temporali. Queste variazioni — dovute, ad esempio, a fatica, pratica, divagazione mentale o cambiamenti motivazionali — possono essere sistematiche o meno, ma raramente sono irrilevanti. Come sottolineato da Schumacher et al. (2023), i meccanismi cognitivi dovrebbero essere compresi come sistemi dinamici complessi, e i modelli dovrebbero tener conto di queste dinamiche per cogliere appieno la struttura dei dati.\nLa teoria dei sistemi dinamici (Dynamic Systems Theory, DST) offre un quadro concettuale potente per descrivere i fenomeni psicologici come processi complessi, spesso non lineari e auto-organizzanti, che emergono dall’interazione di molteplici componenti, sia all’interno dell’individuo sia tra individuo e ambiente. In questa prospettiva, il comportamento e la cognizione non sono entità statiche, ma traiettorie che si sviluppano nel tempo.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>Teorie formali dei fenomeni psicologici</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/introduction.html#introduzione",
    "href": "chapters/formal_models/introduction.html#introduzione",
    "title": "79  Teorie formali dei fenomeni psicologici",
    "section": "",
    "text": "Uno degli sviluppi più rilevanti della psicologia contemporanea è l’uso di teorie formali per indagare i meccanismi che generano i fenomeni psicologici. I modelli matematici non sono semplici strumenti di calcolo: servono a tradurre in termini quantitativi le ipotesi teoriche, a chiarire come i costrutti cognitivi — spesso latenti e non direttamente osservabili — possano essere collegati a parametri misurabili e a prevedere i comportamenti osservati.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>Teorie formali dei fenomeni psicologici</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/introduction.html#ambiti-di-applicazione",
    "href": "chapters/formal_models/introduction.html#ambiti-di-applicazione",
    "title": "79  Teorie formali dei fenomeni psicologici",
    "section": "79.1 Ambiti di applicazione",
    "text": "79.1 Ambiti di applicazione\nMolti ambiti della psicologia possono essere reinterpretati attraverso la lente dei sistemi dinamici:\n\nApprendimento per rinforzo: un processo adattativo in cui le decisioni vengono costantemente aggiornate in base a ricompense e punizioni, generando cicli di feedback che modellano il comportamento. Modelli come quello di Rescorla-Wagner descrivono matematicamente questi meccanismi e trovano applicazione dal condizionamento classico fino alla psichiatria computazionale.\nRegolazione delle emozioni: un sistema dinamico in cui processi fisiologici, cognitivi e comportamentali interagiscono nel tempo, talvolta amplificando proprio le emozioni che si cerca di controllare.\nAttaccamento e relazioni sociali: interazioni continue in cui comportamenti e stati emotivi di ciascun individuo influenzano e vengono influenzati dagli altri, creando cicli di retroazione che si consolidano nel tempo.\nSviluppo cognitivo: adattamenti e riorganizzazioni costanti delle strutture mentali in risposta a nuove esperienze, come descritto dalla teoria piagetiana reinterpretata in termini dinamici.\nControllo motorio e coordinazione: comportamenti motori che emergono dall’auto-organizzazione di sistemi neurali, muscolari e sensoriali.\nDecision making e problem solving: processi che evolvono in funzione dell’interazione tra fattori cognitivi ed emotivi e delle esperienze accumulate.\nPsicopatologia: disturbi come depressione e ansia concepiti come pattern dinamici di pensieri, emozioni e comportamenti che si autoalimentano.\nSviluppo del linguaggio: acquisizione linguistica come risultato dell’interazione continua tra fattori cognitivi, sociali e percettivi.\nDinamiche di gruppo e influenza sociale: norme e comportamenti collettivi che si trasformano attraverso cicli di influenza reciproca.\nAutoregolazione e funzioni esecutive: monitoraggio e aggiustamento costante di attenzione, emozioni e azioni per perseguire obiettivi a lungo termine.\nApprendimento e memoria: processi di codifica, consolidamento e recupero che dipendono da stati cognitivi e fisiologici mutevoli.\n\nIn questa sezione ci concentreremo su un caso specifico: il modello di revisione degli obiettivi, descritto nel tutorial di Knight et al. (2023), che offre un esempio chiaro di come un approccio dinamico possa essere formalizzato, stimato e utilizzato per interpretare dati psicologici complessi.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>Teorie formali dei fenomeni psicologici</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/introduction.html#bibliografia",
    "href": "chapters/formal_models/introduction.html#bibliografia",
    "title": "79  Teorie formali dei fenomeni psicologici",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nHayes, S. C., Hofmann, S. G., Stanton, C. E., Carpenter, J. K., Sanford, B. T., Curtiss, J. E., & Ciarrochi, J. (2019). The role of the individual in the coming era of process-based therapy. Behaviour Research and Therapy, 117, 40–53.\n\n\nKnight, E., Neal, A., Palada, H., & Ballard, T. (2023). A Tutorial on Bayesian Modeling of Change Across Time, Individuals, and Groups. Computational Brain & Behavior, 6(4), 697–718.\n\n\nSchumacher, L., Bürkner, P.-C., Voss, A., Köthe, U., & Radev, S. T. (2023). Neural superstatistics for Bayesian estimation of dynamic cognitive models. Scientific Reports, 13(1), 13778.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>Teorie formali dei fenomeni psicologici</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/01_dynamic_models.html",
    "href": "chapters/formal_models/01_dynamic_models.html",
    "title": "80  Il modello di revisione degli obiettivi",
    "section": "",
    "text": "Introduzione\nTuttavia, gli strumenti statistici più utilizzati in psicologia trascurano spesso questa dimensione temporale. Confrontiamo medie, calcoliamo correlazioni o eseguiamo regressioni, spesso trattando le osservazioni come indipendenti tra loro. Questo approccio è utile per molte domande, ma inadeguato quando l’obiettivo è comprendere l’evoluzione di un comportamento o di uno stato psicologico.\nSe vogliamo capire come le persone modificano i propri obiettivi, cambiano strategia, o si adattano nel tempo a esperienze positive e negative, abbiamo bisogno di un approccio che tenga conto della sequenza degli eventi. Serve un modello in grado di descrivere le regole del cambiamento.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Il modello di revisione degli obiettivi</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/01_dynamic_models.html#introduzione",
    "href": "chapters/formal_models/01_dynamic_models.html#introduzione",
    "title": "80  Il modello di revisione degli obiettivi",
    "section": "",
    "text": "Molti dei fenomeni studiati in psicologia non sono statici, ma si sviluppano e si trasformano nel tempo. L’apprendimento, l’adattamento agli errori, la regolazione degli obiettivi, l’emergere o la remissione di sintomi clinici sono tutti esempi di processi dinamici, in cui ciò che osserviamo in un dato momento è il risultato di una storia pregressa.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Il modello di revisione degli obiettivi</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/01_dynamic_models.html#perché-abbiamo-bisogno-di-modelli-dinamici",
    "href": "chapters/formal_models/01_dynamic_models.html#perché-abbiamo-bisogno-di-modelli-dinamici",
    "title": "80  Il modello di revisione degli obiettivi",
    "section": "80.1 Perché abbiamo bisogno di modelli dinamici?",
    "text": "80.1 Perché abbiamo bisogno di modelli dinamici?\nUn modello dinamico è una rappresentazione matematica che esplicita il modo in cui un sistema evolve nel tempo. La caratteristica distintiva di questi modelli è la presenza di dipendenze temporali: almeno una delle variabili dipende da valori passati, non solo da ciò che accade nel presente.\nQuesto è ciò che li differenzia dai modelli statici, dove ogni osservazione è trattata come indipendente dalle precedenti. Nei modelli dinamici, invece, esiste una memoria del passato, che influenza l’andamento futuro del processo. Nei modelli statici, la variabilità del comportamento è trattata come rumore o differenza individuale. Nei modelli dinamici, questa variabilità diventa informativa: è l’espressione dell’adattamento del sistema alle condizioni del contesto o alla propria storia passata.\nUna classe importante di variabili in questo contesto è costituita dalle variabili di stato (in inglese: state variables o stock variables), che rappresentano il livello accumulato di una certa quantità nel tempo: un obiettivo personale, un livello di motivazione, una credenza, o un sintomo. Queste variabili si aggiornano a ogni passo temporale secondo una regola di cambiamento, definita in termini matematici.\n\n80.1.1 Come si costruisce un modello dinamico?\nFormulare un modello dinamico significa tradurre in termini espliciti una teoria del cambiamento. I passaggi fondamentali sono:\n\nIdentificare le variabili rilevanti: quali sono gli elementi del sistema che vogliamo modellare?\nStabilire le regole di aggiornamento: come cambia ciascuna variabile nel tempo, in risposta a feedback o input esterni?\nFormalizzare il modello in equazioni: trasformare le regole in una struttura matematica coerente.\nValutare la validità del modello: confrontare le sue previsioni con i dati osservati, usando metodi statistici appropriati.\n\nQuesto approccio è particolarmente adatto alla psicologia, dove l’interesse non è solo se un comportamento cambia, ma come evolve nel tempo.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Il modello di revisione degli obiettivi</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/01_dynamic_models.html#un-esempio-concreto-il-modello-di-revisione-degli-obiettivi",
    "href": "chapters/formal_models/01_dynamic_models.html#un-esempio-concreto-il-modello-di-revisione-degli-obiettivi",
    "title": "80  Il modello di revisione degli obiettivi",
    "section": "80.2 Un esempio concreto: il modello di revisione degli obiettivi",
    "text": "80.2 Un esempio concreto: il modello di revisione degli obiettivi\nPer chiarire meglio questo concetto, partiamo da un esempio concreto: la regolazione degli obiettivi in base al feedback. Immaginiamo un esperimento in cui i partecipanti devono svolgere un compito ripetitivo, come classificare coppie di immagini. Prima di ogni prova (trial), ciascuno fissa un obiettivo personale—ad esempio, migliorare la velocità o la precisione rispetto al tentativo precedente. Al termine del trial, riceve un feedback sulla propria performance e può così decidere se mantenere o modificare l’obiettivo per la prova successiva.\nQuesto ciclo – definizione dell’obiettivo, esecuzione, feedback, aggiustamento – è dinamico e si ripete in modo iterativo. Un buon modello dinamico riesce a catturare con precisione tale meccanismo, permettendo ad esempio di stimare quanto rapidamente una persona rivede le proprie aspirazioni in risposta a successi o fallimenti.\nNel resto del capitolo, mostreremo come formalizzare matematicamente questo processo e come stimarne i parametri con un approccio bayesiano, implementato in Stan.\n\n80.2.1 Come formalizzare questo processo?\nUna delle ipotesi più semplici, ma sorprendentemente potenti, è che le persone modifichino i propri obiettivi in funzione della discrepanza tra i risultati ottenuti (performance) e le aspettative (goal). Se la performance supera l’obiettivo, le aspettative tendono ad aumentare (ambizione crescente). Se la performance è inferiore, si tende a ridurre le aspettative (aggiustamento conservativo).\nKnight et al. (2023) hanno formalizzato questa intuizione nel seguente modello dinamico lineare\n\\[\nG_t = G_{t-1} + \\alpha \\cdot (P_{t-1} - G_{t-1}) + \\beta ,\n\\tag{80.1}\\]\ndove:\n\n\\(G_t\\) è il nuovo obiettivo fissato al trial \\(t\\),\n\\(P_{t-1}\\) è la performance osservata al trial precedente,\n\\(\\alpha\\) rappresenta la sensibilità alla discrepanza (quanto il goal viene aggiornato in risposta all’errore),\n\\(\\beta\\) rappresenta un bias sistematico. \\(\\beta\\) &gt; 0: deriva ambiziosa (es. pressione sociale); \\(\\beta\\) &lt; 0: deriva cautelativa (es. affaticamento).\n\nQuesto è un modello sample-level perché assume che tutti i partecipanti condividano gli stessi parametri \\(\\alpha\\) e \\(\\beta\\), stimati sull’intero campione.\n\n\n80.2.2 Illustrazione numerica del modello\nPer comprendere meglio il comportamento del modello, esaminiamo due scenari con gli stessi parametri:\n\n\\(\\alpha = 0.5\\) (apprendimento moderato: 50% della discrepanza viene incorporata nel nuovo obiettivo);\n\\(\\beta = 2\\) (tendenza sistematica ad aumentare l’obiettivo di 2 punti a ogni trial).\n\nScenario 1: Performance superiore all’obiettivo.\n\nObiettivo precedente: \\(G_{t-1} = 50\\) punti.\nPerformance effettiva: \\(P_{t-1} = 60\\) punti.\n\nCalcolo:\n\\[\nG_t = 50 + 0.5 \\cdot (60 - 50) + 2 = 50 + 5 + 2 = \\mathbf{57}.\n\\]\nInterpretazione: Il partecipante ha superato l’obiettivo (+10 punti). Il nuovo obiettivo si adatta parzialmente alla discrepanza (+5 punti, per effetto di \\(\\alpha\\)) e riceve un’ulteriore spinta verso l’alto (+2 punti, per effetto di \\(\\beta\\)).\nRisultato: un aggiustamento ambizioso (da 50 a 57), dove \\(\\beta\\) amplifica l’effetto del successo.\nScenario 2: Performance inferiore all’obiettivo.\n\nObiettivo precedente: \\(G_{t-1} = 50\\) punti.\nPerformance effettiva: \\(P_{t-1} = 40\\) punti.\n\nCalcolo:\n\\[\nG_t = 50 + 0.5 \\cdot (40 - 50) + 2 = 50 - 5 + 2 = \\mathbf{47}.\n\\]\nInterpretazione: Nonostante la performance deludente (-10 punti), l’obiettivo si riduce a causa dell’errore (-5 punti, effetto \\(\\alpha\\)), ma la componente \\(\\beta\\) (+2 punti) attenua il calo, evitando un crollo motivazionale.\nQuesto modello può riflettere la resilienza (ovvero la tendenza a non penalizzare eccessivamente gli insuccessi) e/o la pressione esterna (per esempio, un esperimento che “spinge” a migliorare).\nConfronto con \\(\\beta\\) = 0: l’effetto della deriva sistematica.\nSe \\(\\beta\\) fosse uguale a 0, gli obiettivi si muoverebbero solo in risposta alla performance:\n\n\n\n\n\n\n\n\n\nScenario\nCon \\(\\beta\\)=2\nSenza \\(\\beta\\) (\\(\\beta\\)=0)\nDifferenza\n\n\n\n\nSuccesso\n57\n55\n+2 (\\(\\beta\\))\n\n\nFallimento\n47\n45\n+2 (\\(\\beta\\))\n\n\n\nKey insights:\n\n\\(\\alpha\\) guida l’adattamento reattivo (risposta alla discrepanza);\n\n\\(\\beta\\) introduce una tendenza proattiva:\n\n\\(\\beta\\) &gt; 0: “ambizione crescente” anche dopo fallimenti;\n\n\\(\\beta\\) &lt; 0: “cautela strutturale” (es. affaticamento).\n\n\nSintesi delle interazioni.\n\nDominio di \\(\\alpha\\): quanto rapidamente l’obiettivo “insegue” la performance;\n\nDominio di \\(\\beta\\): direzione generale (progressiva/regressiva) indipendente dal feedback;\n\nModelli completi richiedono entrambi i parametri per catturare sia le risposte locali (\\(\\alpha\\)) sia le tendenze globali (\\(\\beta\\)).\n\n\n\n80.2.3 Perché questo modello è importante?\nQuesto approccio rappresenta un ponte tra la psicologia e la modellizzazione matematica, trasformando i processi cognitivi complessi, come la regolazione degli obiettivi, in relazioni quantitative verificabili. La sua struttura dinamica offre vantaggi unici sia per la ricerca teorica che per le applicazioni pratiche, in quanto consente di tradurre le intuizioni psicologiche in parametri misurabili.\nDal punto di vista metodologico, il modello supera il limite delle descrizioni qualitative, consentendo di quantificare aspetti cruciali del comportamento umano. Il parametro \\(\\alpha\\) cattura la sensibilità individuale alle discrepanze tra le prestazioni attese e quelle reali, rivelando quanto rapidamente una persona riveda i propri obiettivi. Valori elevati di \\(\\alpha\\) indicano un adattamento rapido agli errori, mentre valori bassi suggeriscono una maggiore perseveranza. Il parametro \\(\\beta\\), invece, svela tendenze sistemiche indipendenti dalla performance, come una spinta costante all’ambizione (\\(\\beta\\) &gt; 0) o una progressiva riduzione delle aspettative (\\(\\beta\\) &lt; 0). Questa distinzione consente di formulare ipotesi precise sul ruolo relativo del feedback e dei fattori contestuali nella regolazione degli obiettivi.\nIl valore predittivo del modello lo rende particolarmente utile in ambito applicativo. Una volta stimati i parametri per un individuo o un gruppo, è possibile prevedere come reagiranno a specifici schemi di feedback. In ambito educativo, ciò consente di progettare interventi che bilancino sostegno e sfida, ottimizzando la motivazione. In ambito clinico, il modello può identificare schemi disfunzionali, come un eccessivo abbassamento degli obiettivi dopo un insuccesso (basso valore di \\(\\alpha\\) e valore negativo di \\(\\beta\\)), tipico di stati depressivi o ansiosi. Nelle organizzazioni, invece, il modello permette di adattare i sistemi di valutazione e incentivazione alle caratteristiche dei team.\nLa sua flessibilità lo rende anche una solida base per esplorare ulteriori complessità. I ricercatori possono estenderlo per studiare gli effetti non lineari, le differenze individuali o l’impatto delle variabili contestuali, mantenendo comunque una struttura interpretabile. Questa combinazione di rigore matematico e rilevanza psicologica lo rende uno strumento prezioso per avanzare la teoria e la pratica in vari campi, dalle neuroscienze cognitive alle scienze organizzative.\nIn sintesi, il modello non solo chiarisce i meccanismi cognitivi alla base della regolazione degli obiettivi, ma fornisce anche un linguaggio comune per studiarli, prevederli e influenzarli, offrendo un contributo fondamentale alla comprensione di questo processo cruciale del comportamento umano. Questa integrazione tra rigore metodologico e rilevanza applicativa segna un passo importante verso una psicologia maggiormente ancorata ai dati e interventi più aderenti alle caratteristiche individuali.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Il modello di revisione degli obiettivi</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/01_dynamic_models.html#verso-una-modellizzazione-più-ricca-estensioni-del-modello-base",
    "href": "chapters/formal_models/01_dynamic_models.html#verso-una-modellizzazione-più-ricca-estensioni-del-modello-base",
    "title": "80  Il modello di revisione degli obiettivi",
    "section": "80.3 Verso una modellizzazione più ricca: estensioni del modello base",
    "text": "80.3 Verso una modellizzazione più ricca: estensioni del modello base\nIl modello sample-level offre una rappresentazione iniziale del processo di aggiornamento degli obiettivi, ma presenta inevitabili semplificazioni. Nella realtà, infatti, le persone mostrano differenze sistematiche nel modo in cui regolano le proprie aspettative in risposta ai feedback. Per cogliere questa complessità, Knight et al. (2023) propongono diverse estensioni che arricchiscono il framework base mantenendone l’intuizione teorica fondamentale.\nUna prima direzione di sviluppo è rappresentata dal modello a livello individuale, che stima parametri distinti (\\(\\alpha_i\\) e \\(\\beta_i\\)) per ciascun partecipante. Questo approccio permette di mappare la variabilità interindividuale nella sensibilità al feedback (\\(\\alpha\\)) e nelle tendenze sistemiche (\\(\\beta\\)), offrendo una fotografia più dettagliata delle differenze psicologiche. Ad esempio, potrebbe rivelare come alcuni individui mostrino un aggiustamento rapido degli obiettivi (α elevato), mentre altri mantengano maggiore stabilità nonostante gli insuccessi (α basso).\nUn ulteriore raffinamento è offerto dai modelli gerarchici (multilevel), dove i parametri individuali sono concepiti come estratti da distribuzioni iperparametriche di gruppo. Questa architettura combina i vantaggi dell’analisi a livello individuale con la robustezza statistica derivante dalla condivisione d’informazione tra unità (shrinkage effect). Il risultato è una stima più equilibrata che evita estremi implausibili, particolarmente utile quando si lavora con campioni ridotti o dati rumorosi.\nPer indagare l’impatto di condizioni sperimentali, il modello può essere esteso nella versione a gruppi noti, dove \\(\\alpha\\) e \\(\\beta\\) vengono stimati separatamente per diverse condizioni (es. gruppi con incentivi diversi). Questa estensione permette di testare ipotesi precise sull’influenza di manipolazioni sperimentali nei processi di regolazione. Ancora più sofisticato è il mixture model, che identifica sottogruppi latenti con dinamiche distinte senza assumere a priori le categorie, rivelando ad esempio cluster naturali di “adattatori flessibili” versus “perseveranti”.\nSebbene queste estensioni non siano trattate in dettaglio nel presente capitolo, rappresentano la direzione più promettente per modellare la ricchezza del comportamento umano. Il modello base mantiene comunque il suo valore come fondamento concettuale e strumento didattico, mentre le versioni avanzate offrono strumenti sempre più precisi per catturare l’eterogeneità psicologica.\nQuesta evoluzione riflette un progresso metodologico cruciale: dal focus sulla tendenza centrale si passa a una modellizzazione distribuzionale che valorizza la variabilità individuale, trasformando le differenze da “rumore” a informazione teorica rilevante. La struttura gerarchica in particolare incarna una visione più matura dei processi psicologici, dove le dinamiche individuali sono contestualizzate all’interno di tendenze di gruppo e influenze contestuali.\nPur nella loro crescente complessità, queste estensioni preservano il cuore dinamico del modello originale - l’idea che gli obiettivi si evolvano attraverso un dialogo continuo tra aspirazioni, esperienze e tendenze personali. È proprio questa combinazione di flessibilità e coerenza teorica a rendere il framework particolarmente adatto a esplorare la complessità dei processi decisionali umani in contesti sia sperimentali che applicativi.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Il modello di revisione degli obiettivi</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/01_dynamic_models.html#stima-dei-parametri-con-stan",
    "href": "chapters/formal_models/01_dynamic_models.html#stima-dei-parametri-con-stan",
    "title": "80  Il modello di revisione degli obiettivi",
    "section": "80.4 Stima dei parametri con Stan",
    "text": "80.4 Stima dei parametri con Stan\nPassando dalla teoria alla pratica, affrontiamo ora il cuore operativo della modellizzazione: la stima dei parametri che quantificano il processo di aggiornamento degli obiettivi. Il modello dinamico precedentemente descritto trova la sua concretizzazione statistica attraverso tre parametri chiave:\n\n\\(\\alpha\\): rappresenta la sensibilità alla discrepanza tra performance e obiettivi,\n\\(\\beta\\): cattura le tendenze sistemiche nel cambiamento degli obiettivi,\n\\(\\sigma\\): misura la variabilità residua non spiegata dal modello.\n\nPer farlo, traduciamo l’equazione teorica in un modello statistico e utilizziamo un approccio bayesiano per stimare la distribuzione a posteriori dei parametri.\n\n80.4.1 Dal modello teorico al modello statistico\nIl modello dinamico di base esprime la regola di aggiornamento degli obiettivi attraverso l’equazione deterministica\n\\[\nG_t = G_{t-1} + \\alpha (P_{t-1} - G_{t-1}) + \\beta .\n\\]\nTuttavia, per trasformarla in un modello statistico adatto all’analisi empirica, dobbiamo considerare la componente stocastica del processo. Introduciamo quindi un termine di errore che catturi la variabilità naturale nel processo di fissazione degli obiettivi, l’effetto di fattori non modellati esplicitamente e eventuali errori di misurazione. La versione statistica del modello diventa:\n\\[\n\\text{Goal osservato} \\sim \\mathcal{N}(G_t, \\sigma) .\n\\tag{80.2}\\]\nIn altre parole, assumiamo che il goal osservato sia distribuito normalmente attorno al valore previsto, con una certa variabilità \\(\\sigma\\).\n\n\n80.4.2 Il vantaggio dell’approccio bayesiano per modelli dinamici\nLa natura ricorsiva del modello – dove ogni stima dipende dal valore precedente – rende complessa l’applicazione di metodi frequentisti tradizionali. L’inferenza bayesiana supera questo limite offrendo un framework naturale per gestire dipendenze temporali e incertezze parametriche.\nStan emerge come strumento particolarmente adatto, implementando algoritmi MCMC avanzati che:\n\ngestiscono efficientemente le correlazioni tra parametri,\n\npropagano coerentemente l’incertezza attraverso le catene temporali,\n\nintegrano conoscenze pregresse via distribuzioni a priori.\n\nA differenza di approcci classici, l’output non si limita a stime puntuali ma fornisce distribuzioni complete a posteriori, catturando tutte le relazioni probabilistiche tra parametri e stati latenti. Questo permette di:\n\nquantificare l’incertezza in modo rigoroso,\n\nstimare probabilità dirette per ipotesi teoriche,\n\nsviluppare previsioni robuste che incorporano tutte le fonti di variabilità.\n\n\n\n80.4.3 Esempio: implementazione del modello in Stan\nIl codice Stan presentato nel capitolo segue esattamente la struttura logica del modello teorico:\n\ni dati in input sono il numero dei trial, i goal osservati e le performance;\ni parametri da stimare sono \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\);\nla regola di aggiornamento è implementata in un ciclo for, trial per trial;\nla distribuzione normale collega il goal previsto a quello osservato;\nun blocco aggiuntivo (generated quantities) consente di generare dati simulati a partire dai parametri stimati.\n\nL’obiettivo non è solo stimare parametri, ma verificare se il modello è capace di riprodurre i dati osservati.\n\n\n80.4.4 Il codice Stan\nDi seguito, riportiamo il modello completo implementato in Stan. Analizzeremo poi ciascuna parte.\n// MODELLO PER L'AGGIORNAMENTO DEGLI OBIETTIVI BASATO SULLA PERFORMANCE PRECEDENTE\n\n// ---------------------------\n// BLOCCO DEI DATI: COSA FORNIAMO AL MODELLO\n// ---------------------------\ndata {\n  int Ntotal;                      // Numero totale di osservazioni (es. 600 trial)\n  real trial[Ntotal];              // Numero del trial (es. 1, 2, 3, ..., 600)\n  real observed_goal[Ntotal];      // Obiettivo desiderato osservato in ciascun trial\n  real performance[Ntotal];        // Prestazione osservata in ciascun trial\n}\n\n// ---------------------------\n// PARAMETRI DEL MODELLO: COSA VOGLIAMO STIMARE\n// ---------------------------\nparameters {\n  real alpha;                      // Quanto il partecipante adatta il proprio obiettivo (apprendimento)\n  real beta;                       // Tendenza generale a incrementare l’obiettivo (motivazione costante)\n  real&lt;lower=0&gt; sigma;             // Variazione casuale attorno al goal previsto (rumore)\n}\n\n// ---------------------------\n// MODELLO: COME SI SPIEGANO I DATI\n// ---------------------------\nmodel {\n  real predicted_goal;             // Variabile temporanea per salvare la previsione del goal\n\n  // --- PRIORS: aspettative iniziali sui parametri ---\n  alpha ~ normal(0, 1);            // Alpha: in media 0, con incertezza (deviazione standard = 1)\n  beta ~ normal(0, 1);             // Beta: idem\n  sigma ~ normal(0, 1);            // Sigma: deviazione standard del rumore (deve essere positiva)\n\n  // --- CICLO PER OGNI TRIAL ---\n  for (i in 1:Ntotal) {\n\n    // Caso speciale: primo trial → nessuna previsione, usiamo direttamente il dato osservato\n    if (trial[i] == 1) {\n      predicted_goal = observed_goal[i];\n    }\n\n    // Tutti i trial successivi → aggiornamento del goal basato sulla performance precedente\n    if (trial[i] &gt; 1) {\n      predicted_goal += alpha * (performance[i - 1] - predicted_goal) + beta;\n      // ↑ Questa è la \"regola di apprendimento\":\n      // - Se la performance precedente è migliore del goal → l’obiettivo aumenta\n      // - Se la performance è peggiore → l’obiettivo diminuisce\n      // - Quanto cambia? Dipende da alpha (quanto il partecipante si adatta)\n      // - A ogni passo si aggiunge anche un piccolo incremento costante (beta)\n    }\n\n    // Likelihood: assumiamo che il goal osservato sia vicino al goal previsto, con un po’ di rumore\n    observed_goal[i] ~ normal(predicted_goal, sigma);\n  }\n}\n\n// ---------------------------\n// BLOCCO PER GENERARE PREVISIONI (non necessario, ma utile per valutare il modello)\n// ---------------------------\ngenerated quantities {\n  real predicted_goal;              // Valore previsto dal modello\n  real sampled_goal[Ntotal];        // Goal \"simulati\", generati dal modello\n\n  for (i in 1:Ntotal) {\n    if (trial[i] == 1) {\n      predicted_goal = observed_goal[i];\n    }\n    if (trial[i] &gt; 1) {\n      predicted_goal += alpha * (performance[i - 1] - predicted_goal) + beta;\n    }\n\n    // Simuliamo un nuovo goal come se fosse stato osservato, aggiungendo variabilità\n    sampled_goal[i] = normal_rng(predicted_goal, sigma);\n  }\n}\n\n\n80.4.5 Il problema che vogliamo risolvere\nOra poniamoci il problema di capire la logica del modello. Immaginiamo un partecipante al nostro compito sperimentale: nel primo trial fissa un obiettivo di risposta più veloce, nel secondo modifica leggermente l’obiettivo dopo aver ricevuto un feedback negativo, e nel terzo lo regola nuovamente in seguito a un miglioramento della performance. Ci chiediamo: esiste una regola sottostante a questi aggiustamenti? Il modello mira proprio a stimare questi meccanismi, traducendo il processo di aggiornamento degli obiettivi in un insieme di equazioni che possiamo confrontare con i dati osservati.\n\n\n80.4.6 La logica del modello: tre ingredienti fondamentali\nIl nostro modello si basa su un’idea semplice: quando una persona decide il suo prossimo obiettivo, considera:\n\nAlpha (\\(\\alpha\\)): il tasso di apprendimento. “Quanto mi faccio influenzare dalla mia performance precedente?”\n\n\n\\(\\alpha\\) positivo e alto: “se ho fatto meglio del previsto, alzo molto l’obiettivo”;\n\\(\\alpha\\) positivo e basso: “anche se ho fatto bene, non cambio molto l’obiettivo”;\n\\(\\alpha\\) vicino a 0: “ignoro completamente la performance passata”.\n\n\nBeta (\\(\\beta\\)): la tendenza costante. “Indipendentemente da come è andata, tendo sempre ad alzare/abbassare l’obiettivo?”\n\n\n\\(\\beta\\) negativo: pessimismo - “ogni volta punto un po’ più in basso”;\n\\(\\beta\\) positivo: ottimismo cronico - “ogni volta punto un po’ più in alto”.\n\\(\\beta\\) vicino a zero: nessuna tendenza sistematica.\n\n\nSigma (\\(\\sigma\\)): il rumore. “Quanto sono imprevedibile nelle mie decisioni?”\n\n\n\\(\\sigma\\) basso: decisioni molto coerenti e prevedibili;\n\\(\\sigma\\) alto: decisioni più casuali e difficili da prevedere.\n\n\n\n80.4.7 La formula\nAd ogni trial (eccetto il primo), l’obiettivo viene aggiornato così:\nNuovo Obiettivo = Vecchio Obiettivo + \n                  alpha × (Performance Precedente - Vecchio Obiettivo) + \n                  beta + \n                  Un Po' di Casualità\nEsempio pratico. Supponiamo che \\(\\alpha\\) valga 0.6 e che \\(\\beta\\) valga 2. Nel trial precedente, l’obiettivo era di 50 kg e la performance ottenuta era di 55 kg.\nCalcolo del nuovo obiettivo:\nNuovo Obiettivo = 50 + 0.6 × (55 - 50) + 2\n                = 50 + 0.6 × 5 + 2  \n                = 50 + 3 + 2\n                = 55 kg\nLa persona ha superato l’obiettivo di 5 kg, quindi lo aumenta del 60% di questa differenza (3 kg) più la sua tendenza ottimistica (+2 kg).\n\n\n80.4.8 La Struttura del Codice Stan: Quattro Blocchi Logici\n\n80.4.8.1 Blocco 1: DATA - “Cosa Sappiamo”\ndata {\n  int Ntotal;                    // Quanti trial abbiamo osservato?\n  real trial[Ntotal];            // Quale numero di trial è ciascuna osservazione?\n  real observed_goal[Ntotal];    // Quali obiettivi ha dichiarato?\n  real performance[Ntotal];      // Quali performance ha ottenuto?\n}\nIn parole semplici: “Ecco i dati che abbiamo raccolto dall’esperimento.”\n\n\n80.4.8.2 Blocco 2: PARAMETERS - “Cosa Vogliamo Scoprire”\nparameters {\n  real alpha;                    // Il tasso di apprendimento\n  real beta;                     // La tendenza costante\n  real&lt;lower=0&gt; sigma;           // Quanto rumore c'è nei dati\n}\nIn parole semplici: “Questi sono i valori ignoti che vogliamo stimare dai dati.”\n\n\n80.4.8.3 Blocco 3: MODEL - “Come Funziona il Cervello”\nQuesto è il cuore del modello. Qui diciamo a Stan: “Ecco come pensiamo che funzioni il processo mentale.”\n\n80.4.8.3.1 Passo 1: Le Nostre Aspettative Iniziali (Prior).\nalpha ~ normal(0, 1);\nbeta ~ normal(0, 1);  \nsigma ~ normal(0, 1);\nTraduzione: “Prima di vedere i dati, pensiamo che \\(\\alpha\\) e \\(\\beta\\) siano attorno allo zero, ma non ne siamo sicuri.”\n\n\n80.4.8.3.2 Passo 2: Il Processo Trial-per-Trial.\nfor (i in 1:Ntotal) {\n    if (trial[i] == 1) {\n        // Primo trial: non abbiamo performance precedenti\n        predicted_goal = observed_goal[i];\n    } else {\n        // Trial successivi: applichiamo la formula\n        predicted_goal += alpha * (performance[i-1] - predicted_goal) + beta;\n    }\n    \n    // Confrontiamo la previsione con quello che abbiamo osservato\n    observed_goal[i] ~ normal(predicted_goal, sigma);\n}\nSpiegazione del ciclo FOR:\nImmaginate di avere 10 trial. Il ciclo dice: “Ora analizziamo il trial 1, poi il trial 2, poi il trial 3, e così via fino al trial 10”.\nPer ogni trial:\n\nSe si tratta del primo trial: non possiamo fare previsioni (non abbiamo performance precedenti), quindi prendiamo l’obiettivo osservato così com’è.\nSe si tratta di un trial successivo, applichiamo la nostra formula per prevedere quale dovrebbe essere l’obiettivo.\nConfronto: vediamo quanto la nostra previsione si avvicina a quanto dichiarato dalla persona.\n\n\n\n\n80.4.8.4 Blocco 4: GENERATED QUANTITIES - “Simuliamo Nuovi Dati”\ngenerated quantities {\n    // Qui generiamo dati \"finti\" usando i parametri che abbiamo stimato\n    real sampled_goal[Ntotal];\n    \n    // Stesso processo del blocco MODEL, ma generiamo nuovi dati\n    for (i in 1:Ntotal) {\n        // ... stessa logica di sopra ...\n        sampled_goal[i] = normal_rng(predicted_goal, sigma);\n    }\n}\nA cosa serve?\n\nControllo di qualità: i dati simulati assomigliano a quelli reali? Se sì, il modello è credibile.\nPrevisioni future: come si comporterebbe una nuova persona con le stesse caratteristiche?\n\n\n\n\n80.4.9 Il Processo di Stima: Come Stan Trova i Parametri\nStan non trova un singolo valore per \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\). Invece, trova una distribuzione di valori possibili per ciascun parametro.\nEsempio di risultati.\nalpha: media = 0.7, intervallo credibile = [0.5, 0.9]\nbeta: media = 1.2, intervallo credibile = [0.8, 1.6]  \nsiagma: media = 3.1, intervallo credibile = [2.7, 3.5]\nInterpretazione:\n\nquesta persona si adatta abbastanza bene alle performance passate (\\(\\alpha\\) = 0.7);\nha una leggera tendenza ottimistica (\\(\\beta\\) = 1.2);\nle sue decisioni presentano una moderata variabilità (\\(\\sigma\\) = 3.1).\n\n\n\n80.4.10 Vantaggi di questo approccio\n\nInterpretabilità: ogni parametro ha un significato psicologico chiaro;\nFlessibilità: il modello si adatta a diversi pattern di comportamento.\nIncertezza quantificata: non diciamo “\\(\\alpha\\) = 0.7”, ma “\\(\\alpha\\) è probabilmente tra 0.5 e 0.9”.\nPredizioni testabili: possiamo generare nuovi dati e verificare se sono simili a quelli reali.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Il modello di revisione degli obiettivi</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/01_dynamic_models.html#riassunto-finale",
    "href": "chapters/formal_models/01_dynamic_models.html#riassunto-finale",
    "title": "80  Il modello di revisione degli obiettivi",
    "section": "80.5 Riassunto finale",
    "text": "80.5 Riassunto finale\n\n\n\n\n\n\n\nElemento\nSignificato\n\n\n\n\n\\(\\alpha\\)\nSensibilità all’errore: quanto il partecipante modifica l’obiettivo in base alla discrepanza tra performance e aspettativa.\n\n\n\\(\\beta\\)\nSpinta costante al cambiamento: riflette una tendenza sistematica (es. ambizione crescente).\n\n\n\\(\\sigma\\)\nRumore residuo: variabilità non spiegata dal modello.\n\n\nsampled_goal\nGoal simulati dal modello, usati per verificare la bontà delle previsioni.\n\n\ngenerated quantities\nBlocchi che permettono di generare dati sintetici secondo le regole del modello.\n\n\n\nIn sintesi, questo modello ci permette di “aprire la scatola nera” del processo decisionale umano, trasformando osservazioni comportamentali in parametri psicologici interpretabili. È un esempio di come la modellazione statistica possa illuminare i meccanismi cognitivi sottostanti al comportamento umano.\n\n80.5.1 Risultati finali dell’analisi\nAl termine della modellazione in Stan, otteniamo tre componenti fondamentali per l’interpretazione.\n\nLe distribuzioni posteriori dei parametri (\\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\)) rappresentano l’insieme completo dei valori plausibili per ciascun parametro, ottenuti integrando le informazioni ricavate dai dati osservati con le nostre conoscenze a priori. Queste distribuzioni ci permettono di quantificare l’incertezza delle nostre stime.\nGli indicatori di qualità della stima, come l’R-hat (che valuta la convergenza delle catene MCMC) e l’n_eff (che misura l’efficienza del campionamento), forniscono importanti metriche diagnostiche per valutare l’affidabilità dei risultati. Un R-hat vicino a 1 e un n_eff sufficientemente alto indicano stime robuste.\nInfine, tramite il blocco “generated quantities”, otteniamo dati simulati che ci permettono di verificare la capacità predittiva del modello. Queste simulazioni, insieme ai valori di sampled_goal, sono fondamentali per verificare se il modello è in grado di riprodurre pattern simili a quelli osservati nei dati reali, fornendo una validazione aggiuntiva della sua adeguatezza.\n\n\n\n80.5.2 Interpretazione e utilità dei risultati\nLe distribuzioni a posteriori forniscono risposte concrete alle nostre domande di ricerca. Esaminando i valori stimati di \\(\\alpha\\) possiamo valutare quanto i partecipanti si adattino alle performance precedenti, mentre l’analisi di \\(\\beta\\) rivela eventuali tendenze sistematiche ad aumentare o diminuire l’ambizione. Il parametro \\(\\sigma\\), d’altra parte, ci informa sul grado di variabilità nel processo di aggiornamento degli obiettivi.\nAttraverso i dati simulati possiamo condurre posterior predictive checks, un potente strumento diagnostico che confronta i dati generati dal modello con quelli effettivamente osservati, permettendoci di valutare la bontà e la plausibilità del nostro modello.\n\n\n80.5.3 Limitazioni e sviluppi futuri\nL’attuale implementazione presenta alcune semplificazioni: assume che i parametri \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\) rimangano costanti nel tempo, non tiene conto di possibili differenze individuali e adotta una struttura puramente lineare, che potrebbe risultare troppo rigida per catturare relazioni complesse.\nPer aumentare la flessibilità del modello, sarebbe possibile introdurre una struttura gerarchica che contempli parametri specifici per ciascun individuo, consentire una variazione temporale dei parametri o incorporare termini non lineari per descrivere in modo più accurato la relazione tra performance e definizione degli obiettivi.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Il modello di revisione degli obiettivi</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/01_dynamic_models.html#riflessioni-conclusive",
    "href": "chapters/formal_models/01_dynamic_models.html#riflessioni-conclusive",
    "title": "80  Il modello di revisione degli obiettivi",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nQuesto esempio mostra come i concetti psicologici complessi, come la regolazione degli obiettivi, possano essere formalizzati tramite modelli dinamici che rappresentano l’evoluzione temporale dei processi cognitivi. L’approccio adottato integra tre elementi essenziali: la formalizzazione teorica tramite equazioni, l’implementazione computazionale in Stan e l’inferenza bayesiana per stimare e valutare il modello in relazione ai dati.\nRispetto ai modelli statici, questa prospettiva consente non solo di verificare se un comportamento cambia, ma anche come, quando e in risposta a quali condizioni. Pur nella sua semplicità, il modello presentato illustra il potenziale di una psicologia formale e meccanicistica orientata all’identificazione dei processi generativi sottostanti i dati osservati.\nCome sottolineato da Knight et al. (2023), questo paradigma si articola in tre fasi cruciali. In primo luogo, la costruzione di un modello generativo che specifichi esplicitamente i meccanismi ipotizzati. In secondo luogo, le ipotesi vengono tradotte in codice eseguibile, solitamente utilizzando linguaggi formali come Stan. Terzo, la valutazione della bontà del modello non solo mediante indicatori statistici, ma anche attraverso un confronto sistematico tra i dati osservati e quelli simulati.\nAnche un modello apparentemente semplice, come quello presentato in questo articolo, può rivelarsi utile se soddisfa tre requisiti fondamentali: (1) poggia su basi teoriche esplicite e plausibili, (2) genera previsioni empiricamente verificabili e (3) può essere esteso per indagare nuove questioni di ricerca.\nIl modello sample-level rappresenta infatti un punto di partenza che può essere arricchito in diverse direzioni: introducendo parametri individuali per catturare le differenze tra i soggetti, incorporando strutture gerarchiche per conciliare i diversi livelli di analisi o implementando modelli a gruppi latenti per identificare pattern non immediatamente evidenti nei dati.\nDal punto di vista didattico, questo esempio mostra come le teorie psicologiche possano essere tradotte in equazioni formali che possono essere simulate, testate e validate empiricamente. Questo approccio trasforma le ipotesi teoriche in affermazioni quantitative verificabili, superando l’analisi delle sole associazioni per abbracciare l’analisi dei processi.\nIn definitiva, la costruzione di modelli dinamici rappresenta un passo avanti verso una psicologia più rigorosa, che mira a spiegare i fenomeni anziché limitarsi a descriverli, contribuendo così allo sviluppo cumulativo della disciplina. Questo approccio spinge i ricercatori a considerare i meccanismi e i processi sottostanti, gettando le basi per una scienza psicologica più matura e predittiva.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Il modello di revisione degli obiettivi</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/01_dynamic_models.html#bibliografia",
    "href": "chapters/formal_models/01_dynamic_models.html#bibliografia",
    "title": "80  Il modello di revisione degli obiettivi",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nKnight, E., Neal, A., Palada, H., & Ballard, T. (2023). A Tutorial on Bayesian Modeling of Change Across Time, Individuals, and Groups. Computational Brain & Behavior, 6(4), 697–718.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Il modello di revisione degli obiettivi</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/02_dynamic_models.html",
    "href": "chapters/formal_models/02_dynamic_models.html",
    "title": "81  Estensioni",
    "section": "",
    "text": "Introduzione",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Estensioni</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/02_dynamic_models.html#introduzione",
    "href": "chapters/formal_models/02_dynamic_models.html#introduzione",
    "title": "81  Estensioni",
    "section": "",
    "text": "Seguendo la discussione di Knight et al. (2023), in questo capitolo estenderemo il modello di gruppo esaminato nel capitolo precedente in modo da esaminare il modello a livello individuale, nel quale si stima un \\(\\alpha\\) e un \\(\\beta\\) per ogni partecipante; il modello gerarchico (multilevel), nel quale i parametri individuali sono estratti da una distribuzione comune (ad esempio, una distribuzione normale); il modello per gruppi noti, in cui si confrontano i parametri tra le condizioni sperimentali (ad esempio, il gruppo “approach” vs. il gruppo “avoidance”).",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Estensioni</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/02_dynamic_models.html#person-level-model",
    "href": "chapters/formal_models/02_dynamic_models.html#person-level-model",
    "title": "81  Estensioni",
    "section": "\n81.1 Person-Level Model",
    "text": "81.1 Person-Level Model\nIl Sample-Level Model descrive il processo di aggiornamento degli obiettivi a livello di gruppo, senza tenere in considerazione le differenze individuali. Tuttavia, è possibile estendere il modello descritto nel Capitolo 80 in modo tale da stimare i parametri \\(\\alpha\\) e \\(\\beta\\) per ciascun partecipante.\n\n81.1.1 Preparazione dei dati\n\n# Caricamento del dataset\ndat &lt;- rio::import(\"data/goal_data.csv\")\n\n# Ordina i dati per soggetto e per trial\ndat &lt;- dat |&gt; \n  arrange(subject, trial)\n\n# (Opzionale) Verifica che l'ordinamento sia corretto\nstr(dat)\n#&gt; 'data.frame':    600 obs. of  5 variables:\n#&gt;  $ subject    : int  1 1 1 1 1 1 1 1 1 1 ...\n#&gt;  $ condition  : chr  \"approach\" \"approach\" \"approach\" \"approach\" ...\n#&gt;  $ goal       : int  2 2 2 4 4 2 2 4 2 4 ...\n#&gt;  $ performance: int  0 2 2 4 2 0 4 2 4 4 ...\n#&gt;  $ trial      : int  1 2 3 4 5 6 7 8 9 10 ...\n\n\ntable(dat$subject)  # restituisce il numero di trial per soggetto\n#&gt; \n#&gt;  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 \n#&gt; 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 \n#&gt; 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 \n#&gt; 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 \n#&gt; 51 52 53 54 55 56 57 58 59 60 \n#&gt; 10 10 10 10 10 10 10 10 10 10\n\n\nstan_data = list(\n  subject=dat$subject,\n  condition=as.numeric(as.factor(dat$condition)), #1 = approach, #2 = avoidance\n  observed_goal=dat$goal,\n  trial=dat$trial,\n  performance=dat$performance,\n  Nsubj=length(unique(dat$subject)),\n  Ntotal=length(dat$subject)\n)\n\n# Verifica struttura\nstr(stan_data)\n#&gt; List of 7\n#&gt;  $ subject      : int [1:600] 1 1 1 1 1 1 1 1 1 1 ...\n#&gt;  $ condition    : num [1:600] 1 1 1 1 1 1 1 1 1 1 ...\n#&gt;  $ observed_goal: int [1:600] 2 2 2 4 4 2 2 4 2 4 ...\n#&gt;  $ trial        : int [1:600] 1 2 3 4 5 6 7 8 9 10 ...\n#&gt;  $ performance  : int [1:600] 0 2 2 4 2 0 4 2 4 4 ...\n#&gt;  $ Nsubj        : int 60\n#&gt;  $ Ntotal       : int 600\n\n\n81.1.2 Definizione del modello Stan\n\nstancode &lt;- \"\ndata {\n  int&lt;lower=1&gt; Ntotal;                  // Numero totale di trial nel dataset (es. 600)\n  array[Ntotal] real trial;             // Numero del trial (es. da 1 a 30 per ogni soggetto)\n  array[Ntotal] real observed_goal;     // Valore dell'obiettivo osservato per ciascun trial\n  array[Ntotal] real performance;       // Prestazione osservata per ciascun trial\n  int&lt;lower=1&gt; Nsubj;                   // Numero di soggetti\n  array[Ntotal] int&lt;lower=1&gt; subject;   // Indice soggetto per ciascun trial\n}\n\nparameters {\n  vector[Nsubj] alpha;                  // Parametro alpha per ciascun soggetto\n  vector[Nsubj] beta;                   // Parametro beta per ciascun soggetto\n  real&lt;lower=0&gt; sigma;                  // Deviazione standard residua (comune a tutti)\n}\n\ntransformed parameters {\n  vector[Ntotal] predicted_goal;        // Obiettivo predetto per ciascun trial\n\n  for (i in 1:Ntotal) {\n    if (trial[i] == 1) {\n      // Primo trial per il soggetto → valore osservato iniziale\n      predicted_goal[i] = observed_goal[i];\n    } else {\n      // Trial successivo: aggiornamento secondo l'equazione dinamica\n      predicted_goal[i] = predicted_goal[i - 1] +\n                          alpha[subject[i]] * (performance[i - 1] - predicted_goal[i - 1]) +\n                          beta[subject[i]];\n    }\n  }\n}\n\nmodel {\n  // PRIORS DEBOLMENTE-INFORMATIVI \n  alpha ~ normal(0, 1);\n  beta ~ normal(0, 1);\n  sigma ~ normal(0, 1);\n\n  // LIKELIHOOD\n  observed_goal ~ normal(predicted_goal, sigma);\n}\n\ngenerated quantities {\n  // Replica predittiva per ciascun trial, da usare per check predittivi posteriori\n  vector[Ntotal] predicted_goal_rep;\n  vector[Ntotal] log_lik;\n\n  for (i in 1:Ntotal) {\n    predicted_goal_rep[i] = normal_rng(predicted_goal[i], sigma);\n    log_lik[i] = normal_lpdf(observed_goal[i] | predicted_goal[i], sigma);\n  }\n}\n\"\n\nQuesto modello presuppone che i dati siano ordinati per soggetto e per trial, altrimenti la dinamica i - 1 non corrisponde al trial precedente dello stesso soggetto. Esaminiamo in dettaglio cosa significano alpha[subject[i]] e beta[subject[i]]. Nel modello Stan, ogni trial i è associato a un certo soggetto. Questa informazione è contenuta nel vettore:\narray[Ntotal] int&lt;lower=1&gt; subject;\n\nstan_data$subject\n#&gt;   [1]  1  1  1  1  1  1  1  1  1  1  2  2  2  2  2  2  2  2  2  2  3  3  3\n#&gt;  [24]  3  3  3  3  3  3  3  4  4  4  4  4  4  4  4  4  4  5  5  5  5  5  5\n#&gt;  [47]  5  5  5  5  6  6  6  6  6  6  6  6  6  6  7  7  7  7  7  7  7  7  7\n#&gt;  [70]  7  8  8  8  8  8  8  8  8  8  8  9  9  9  9  9  9  9  9  9  9 10 10\n#&gt;  [93] 10 10 10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 12 12 12 12 12\n#&gt; [116] 12 12 12 12 12 13 13 13 13 13 13 13 13 13 13 14 14 14 14 14 14 14 14\n#&gt; [139] 14 14 15 15 15 15 15 15 15 15 15 15 16 16 16 16 16 16 16 16 16 16 17\n#&gt; [162] 17 17 17 17 17 17 17 17 17 18 18 18 18 18 18 18 18 18 18 19 19 19 19\n#&gt; [185] 19 19 19 19 19 19 20 20 20 20 20 20 20 20 20 20 21 21 21 21 21 21 21\n#&gt; [208] 21 21 21 22 22 22 22 22 22 22 22 22 22 23 23 23 23 23 23 23 23 23 23\n#&gt; [231] 24 24 24 24 24 24 24 24 24 24 25 25 25 25 25 25 25 25 25 25 26 26 26\n#&gt; [254] 26 26 26 26 26 26 26 27 27 27 27 27 27 27 27 27 27 28 28 28 28 28 28\n#&gt; [277] 28 28 28 28 29 29 29 29 29 29 29 29 29 29 30 30 30 30 30 30 30 30 30\n#&gt; [300] 30 31 31 31 31 31 31 31 31 31 31 32 32 32 32 32 32 32 32 32 32 33 33\n#&gt; [323] 33 33 33 33 33 33 33 33 34 34 34 34 34 34 34 34 34 34 35 35 35 35 35\n#&gt; [346] 35 35 35 35 35 36 36 36 36 36 36 36 36 36 36 37 37 37 37 37 37 37 37\n#&gt; [369] 37 37 38 38 38 38 38 38 38 38 38 38 39 39 39 39 39 39 39 39 39 39 40\n#&gt; [392] 40 40 40 40 40 40 40 40 40 41 41 41 41 41 41 41 41 41 41 42 42 42 42\n#&gt; [415] 42 42 42 42 42 42 43 43 43 43 43 43 43 43 43 43 44 44 44 44 44 44 44\n#&gt; [438] 44 44 44 45 45 45 45 45 45 45 45 45 45 46 46 46 46 46 46 46 46 46 46\n#&gt; [461] 47 47 47 47 47 47 47 47 47 47 48 48 48 48 48 48 48 48 48 48 49 49 49\n#&gt; [484] 49 49 49 49 49 49 49 50 50 50 50 50 50 50 50 50 50 51 51 51 51 51 51\n#&gt; [507] 51 51 51 51 52 52 52 52 52 52 52 52 52 52 53 53 53 53 53 53 53 53 53\n#&gt; [530] 53 54 54 54 54 54 54 54 54 54 54 55 55 55 55 55 55 55 55 55 55 56 56\n#&gt; [553] 56 56 56 56 56 56 56 56 57 57 57 57 57 57 57 57 57 57 58 58 58 58 58\n#&gt; [576] 58 58 58 58 58 59 59 59 59 59 59 59 59 59 59 60 60 60 60 60 60 60 60\n#&gt; [599] 60 60\n\nOgni elemento subject[i] ci dice a quale soggetto appartiene il trial i, usando un numero intero da 1 a Nsubj. Quindi se subject[137] == 24, significa che il 137-esimo trial è del soggetto 24.\nOra, se abbiamo un vettore di parametri specifici per ogni soggetto\nvector[Nsubj] alpha;\nvector[Nsubj] beta;\nallora\n\n\nalpha[subject[i]] significa: prendi il valore del parametro alpha associato al soggetto a cui appartiene il trial i;\nlo stesso vale per beta[subject[i]].\n\nPer esempio, supponiamo\nsubject = [1, 1, 1, 2, 2, 3, 3]\nalpha = [0.5, 0.8, 1.1]  // Tre soggetti: 1, 2, 3\nallora\n\n\nalpha[subject[4]] = alpha[2] = 0.8, perché il 4° trial è del soggetto 2.\n\nbeta[subject[6]] = beta[3] = ..., perché il 6° trial è del soggetto 3.\n\nIn sintesi, la sintassi alpha[subject[i]] (e beta[subject[i]]) indica: “Nel trial i, usa il valore del parametro alpha (o beta) del soggetto indicato da subject[i]”. È un modo compatto per associare ogni osservazione ai parametri della persona corrispondente.\n\n81.1.3 Compilazione ed esecuzione del modello\n\nstanmod &lt;- cmdstan_model(\n  write_stan_file(stancode),\n  compile = TRUE\n)\n\n\nfit1 &lt;- stanmod$sample(\n  data = stan_data,\n  iter_warmup = 1000,\n  iter_sampling = 10000,\n  chains = 4,\n  parallel_chains = 4,\n  refresh = 1000,\n  seed = 4790\n)\n\n\n81.1.4 Analisi dei risultati\nQuesto modello genera un insieme di campioni posteriori per i parametri \\(\\alpha\\) e \\(\\beta\\), uno per ciascun partecipante. I primi due grafici mostrano gli intervalli credibili al 95% per \\(\\alpha\\) e \\(\\beta\\) relativi a ogni partecipante. Come si può osservare, emerge un’eterogeneità tra i partecipanti sia per il parametro \\(\\alpha\\) che per \\(\\beta\\). Il pannello di destra mostra i parametri \\(\\alpha\\) e \\(\\beta\\) di ciascun partecipante tracciati l’uno contro l’altro (con le croci che rappresentano gli intervalli credibili per ciascun parametro).\n\n# Estrazione dei campioni\nstandraws &lt;- fit1$draws(format = \"draws_matrix\")\n\n\n# Statistiche descrittive\nstandraws |&gt; \n  subset_draws(variable = c(\"alpha\", \"beta\", \"sigma\")) |&gt; \n  summarise_draws(\n    mean,\n    ~ quantile(.x, probs = c(0.025, 0.5, 0.975))\n  ) |&gt; \n  print()\n#&gt; # A tibble: 121 × 5\n#&gt;    variable   mean `2.5%` `50%` `97.5%`\n#&gt;    &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n#&gt;  1 alpha[1]   0.61   0.06  0.63    1.01\n#&gt;  2 alpha[2]   0.19  -0.25  0.19    0.60\n#&gt;  3 alpha[3]   0.14  -0.28  0.16    0.49\n#&gt;  4 alpha[4]   0.36  -0.29  0.38    0.95\n#&gt;  5 alpha[5]   0.37   0.03  0.37    0.69\n#&gt;  6 alpha[6]   0.60   0.08  0.61    1.06\n#&gt;  7 alpha[7]   0.40   0.09  0.39    0.73\n#&gt;  8 alpha[8]   0.11  -0.09  0.11    0.34\n#&gt;  9 alpha[9]   0.46  -0.03  0.47    0.90\n#&gt; 10 alpha[10]  0.77   0.41  0.78    1.07\n#&gt; # ℹ 111 more rows\n\n\n#extract posterior samples for person-level parameters\nposteriors_person = spread_draws(fit1, alpha[subject], beta[subject])\n\n\n# Calcolo media e intervallo credibile al 95% per ciascun soggetto\nCIs_person &lt;- posteriors_person %&gt;%\n  group_by(subject) %&gt;%\n  summarise(\n    across(c(alpha, beta), list(\n      lower = ~quantile(.x, 0.025),\n      mean  = ~mean(.x),\n      upper = ~quantile(.x, 0.975)\n    ), .names = \"{.col}_{.fn}\")\n  ) %&gt;%\n  arrange(alpha_mean) %&gt;%\n  mutate(alpha_order = row_number()) %&gt;%\n  arrange(beta_mean) %&gt;%\n  mutate(beta_order = row_number())\n\n\nplot_person_alpha = ggplot(data=CIs_person) +\n  geom_point(aes(y=alpha_order,x=alpha_mean)) +\n  geom_errorbarh(aes(y=alpha_order,xmin=alpha_lower,xmax=alpha_upper),color=\"red\") +\n  labs(x= expression(alpha) ,y=\"Subject\") \n\nplot_person_beta &lt;- ggplot(data = CIs_person) +\n  geom_point(aes(y = beta_order, x = beta_mean)) +\n  geom_errorbarh(aes(y = beta_order, xmin = beta_lower, xmax = beta_upper), color = \"red\") +\n  # geom_density(data = posteriors_person, aes(x = beta), fill = \"blue\", alpha = 0.15, inherit.aes = FALSE) +\n  labs(x = expression(beta), y = \"Subject\") \n\nplot_person_alphabeta = ggplot(data=CIs_person) +\n  geom_point(aes(x=alpha_mean,y=beta_mean)) +\n  geom_errorbar(aes(x=alpha_mean,ymin=beta_lower,ymax=beta_upper),color=\"red\",alpha=0.25) +\n  geom_errorbarh(aes(y=beta_mean,xmin=alpha_lower,xmax=alpha_upper),color=\"red\",alpha=0.25) +\n  labs(x= expression(alpha) ,y=expression(beta)) \n\n\nplot_person_alpha + plot_person_beta + plot_person_alphabeta",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Estensioni</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/02_dynamic_models.html#modello-gerarchico",
    "href": "chapters/formal_models/02_dynamic_models.html#modello-gerarchico",
    "title": "81  Estensioni",
    "section": "\n81.2 Modello gerarchico",
    "text": "81.2 Modello gerarchico\nAnche se stimare i parametri per ogni partecipante separatamente può offrire vantaggi rispetto ai modelli che aggregano tutti i dati, questo approccio ha un limite importante: rende difficile trarre conclusioni sulla popolazione da cui provengono i soggetti.\nAnalizzare i dati “persona per persona” equivale infatti a eseguire tante analisi indipendenti quanti sono i partecipanti. Questo comporta una perdita di potere statistico, perché ogni stima utilizza solo i dati di un singolo individuo, ignorando tutte le informazioni presenti nel resto del campione. Inoltre, non consente di sfruttare le somiglianze tra individui, che potrebbero riflettere caratteristiche comuni della popolazione di riferimento.\nIn molti casi, però, i ricercatori sono interessati sia a comprendere le differenze individuali, sia a descrivere tendenze generali valide per l’intera popolazione. Per questo, i modelli gerarchici bayesiani (o modelli multilevel) offrono una soluzione particolarmente efficace (Turner et al., 2013; Vincent, 2016; Kruschke & Vanpaemel, 2015).\nQuesti modelli permettono di stimare simultaneamente due livelli di parametri: quelli specifici per ogni partecipante e quelli che descrivono la distribuzione dei parametri a livello di popolazione (Lewandowsky & Farrell, 2011). In pratica, le stime individuali vengono “informate” sia dai dati del singolo partecipante, sia dalla tendenza generale osservata nel gruppo. Questo processo riduce il rischio che stime instabili o influenzate da rumore abbiano troppo peso, producendo risultati più robusti e interpretabili (Boehm et al., 2018; Rouder & Lu, 2005).\n\n81.2.1 Definizione del modello Stan\n\nstancode &lt;- \"\n// Modello gerarchico bayesiano \n\n// --- BLOCCO DATI ---\ndata {\n  int&lt;lower=1&gt; Ntotal;\n  array[Ntotal] real trial;\n  array[Ntotal] real observed_goal;\n  array[Ntotal] real performance;\n  int&lt;lower=1&gt; Nsubj;\n  array[Ntotal] int&lt;lower=1&gt; subject;\n}\n\n// --- PARAMETRI ---\nparameters {\n  vector[Nsubj] alpha;\n  vector[Nsubj] beta;\n  real&lt;lower=0&gt; sigma;\n\n  real alpha_mean;\n  real&lt;lower=0&gt; alpha_sd;\n  real beta_mean;\n  real&lt;lower=0&gt; beta_sd;\n}\n\n// --- MODELLO ---\nmodel {\n  real predicted_goal;\n\n  alpha ~ normal(alpha_mean, alpha_sd);\n  beta ~ normal(beta_mean, beta_sd);\n\n  alpha_mean ~ normal(0, 1);\n  alpha_sd   ~ normal(0, 1);\n  beta_mean  ~ normal(0, 1);\n  beta_sd    ~ normal(0, 1);\n  sigma      ~ normal(0, 1);\n\n  for (i in 1:Ntotal) {\n    if (trial[i] == 1) {\n      predicted_goal = observed_goal[i];\n    } else {\n      predicted_goal += alpha[subject[i]] * (performance[i - 1] - predicted_goal) +\n                        beta[subject[i]];\n    }\n    observed_goal[i] ~ normal(predicted_goal, sigma);\n  }\n}\n\n// --- QUANTITÀ DERIVATE ---\ngenerated quantities {\n  array[Ntotal] real predicted_goal_rep;\n  array[Ntotal] real log_lik;\n  real predicted_goal;\n\n  for (i in 1:Ntotal) {\n    if (trial[i] == 1) {\n      predicted_goal = observed_goal[i];\n    } else {\n      predicted_goal += alpha[subject[i]] * (performance[i - 1] - predicted_goal) +\n                        beta[subject[i]];\n    }\n    predicted_goal_rep[i] = normal_rng(predicted_goal, sigma);\n    log_lik[i] = normal_lpdf(observed_goal[i] | predicted_goal, sigma);\n  }\n}\n\"\n\nSi noti che, a livello di codice, il modello gerarchico si distingue dal modello a livello individuale (Person-Level Model) principalmente per la seguente porzione:\n// Priori gerarchici sui parametri individuali\nalpha ~ normal(alpha_mean, alpha_sd);\nbeta  ~ normal(beta_mean, beta_sd);\nIn altre parole, nel modello gerarchico i parametri individuali alpha e beta non sono trattati come parametri indipendenti, ma come variabili casuali estratte da distribuzioni normali. Si assume cioè che:\n\nciascun valore di alpha[i] sia estratto da una distribuzione normale con media alpha_mean e deviazione standard alpha_sd;\nciascun valore di beta[i] sia estratto da una distribuzione normale con media beta_mean e deviazione standard beta_sd.\n\nQuesta struttura introduce un livello gerarchico nel modello, perché i parametri individuali sono vincolati da iper-parametri di popolazione. Il vantaggio principale è che le stime individuali vengono regolarizzate: non dipendono soltanto dai dati del singolo partecipante, ma anche dalla distribuzione complessiva nella popolazione. Questo meccanismo consente di ottenere inferenze più robuste, soprattutto in presenza di dati rumorosi o scarsi per alcuni individui.\n\n81.2.2 Compilazione ed esecuzione del modello\n\nstanmod &lt;- cmdstan_model(\n  write_stan_file(stancode),\n  compile = TRUE\n)\n\n\nfit2 &lt;- stanmod$sample(\n  data = stan_data,\n  iter_warmup = 1000,\n  iter_sampling = 10000,\n  chains = 4,\n  parallel_chains = 4,\n  refresh = 1000,\n  seed = 4790\n)\n\n\n81.2.3 Analisi dei risultati\nEseguiamo l’analisi dei risultati seguendo lo schema usato sopra.\n\n# Estrazione dei campioni posteriori come matrice (opzionale)\nstandraws &lt;- fit2$draws(format = \"draws_matrix\")\n\n\n# Statistiche descrittive aggregate\nstandraws |&gt; \n  subset_draws(variable = c(\"alpha\", \"beta\", \"sigma\", \"alpha_mean\", \"beta_mean\", \"alpha_sd\", \"beta_sd\")) |&gt; \n  summarise_draws(\n    mean,\n    ~ quantile(.x, probs = c(0.025, 0.5, 0.975))\n  )\n#&gt; # A tibble: 125 × 5\n#&gt;    variable   mean `2.5%` `50%` `97.5%`\n#&gt;    &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n#&gt;  1 alpha[1]   0.54   0.27  0.55    0.81\n#&gt;  2 alpha[2]   0.38   0.11  0.39    0.63\n#&gt;  3 alpha[3]   0.33   0.08  0.33    0.56\n#&gt;  4 alpha[4]   0.47   0.18  0.47    0.76\n#&gt;  5 alpha[5]   0.36   0.13  0.36    0.59\n#&gt;  6 alpha[6]   0.54   0.27  0.54    0.82\n#&gt;  7 alpha[7]   0.44   0.22  0.44    0.67\n#&gt;  8 alpha[8]   0.24   0.04  0.23    0.45\n#&gt;  9 alpha[9]   0.48   0.21  0.48    0.73\n#&gt; 10 alpha[10]  0.63   0.40  0.63    0.88\n#&gt; # ℹ 115 more rows\n\n\n# Estrai le draw per i parametri individuali (alpha e beta per ciascun soggetto)\nposteriors_person &lt;- spread_draws(fit2, alpha[subject], beta[subject])\n\n\n# Calcolo degli intervalli credibili per ciascun soggetto\nCIs_person &lt;- posteriors_person %&gt;%\n  group_by(subject) %&gt;%\n  summarise(\n    across(c(alpha, beta), list(\n      lower = ~quantile(.x, 0.025),\n      mean  = ~mean(.x),\n      upper = ~quantile(.x, 0.975)\n    ), .names = \"{.col}_{.fn}\")\n  ) %&gt;%\n  arrange(alpha_mean) %&gt;%\n  mutate(alpha_order = row_number()) %&gt;%\n  arrange(beta_mean) %&gt;%\n  mutate(beta_order = row_number())\n\n\n# Grafico: intervalli credibili per alpha\nplot_person_alpha &lt;- ggplot(CIs_person) +\n  geom_point(aes(y = alpha_order, x = alpha_mean)) +\n  geom_errorbarh(aes(y = alpha_order, xmin = alpha_lower, xmax = alpha_upper), color = \"red\") +\n  labs(x = expression(alpha), y = \"Soggetto\") \n\n# Grafico: intervalli credibili per beta\nplot_person_beta &lt;- ggplot(CIs_person) +\n  geom_point(aes(y = beta_order, x = beta_mean)) +\n  geom_errorbarh(aes(y = beta_order, xmin = beta_lower, xmax = beta_upper), color = \"red\") +\n  labs(x = expression(beta), y = \"Soggetto\") \n\n# Grafico: relazione tra alpha e beta per ciascun soggetto\nplot_person_alphabeta &lt;- ggplot(CIs_person) +\n  geom_point(aes(x = alpha_mean, y = beta_mean)) +\n  geom_errorbar(aes(x = alpha_mean, ymin = beta_lower, ymax = beta_upper), color = \"red\", alpha = 0.25) +\n  geom_errorbarh(aes(y = beta_mean, xmin = alpha_lower, xmax = alpha_upper), color = \"red\", alpha = 0.25) +\n  labs(x = expression(alpha), y = expression(beta)) \n\n\nplot_person_alpha + plot_person_beta + plot_person_alphabeta\n\n\n\n\n\n\n\nInfine, calcoliamo le stime a posteriori degli iper-parametri:\n\n# Riassunto per alpha_mean e beta_mean con intervallo al 95%\nstandraws |&gt;\n  subset_draws(variable = c(\"alpha_mean\", \"beta_mean\")) |&gt;\n  summarise_draws(\n    mean,\n    ~quantile(.x, probs = c(0.025, 0.975))\n  )\n#&gt; # A tibble: 2 × 4\n#&gt;   variable    mean `2.5%` `97.5%`\n#&gt;   &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 alpha_mean  0.49   0.42    0.55\n#&gt; 2 beta_mean   0.18   0.04    0.31\n\nIl modello gerarchico bayesiano fornisce inferenze su due livelli: da un lato, stima separatamente i parametri \\(\\alpha\\) e \\(\\beta\\) per ciascun partecipante; dall’altro, restituisce le distribuzioni a livello di popolazione per questi parametri, ovvero gli iper-parametri alpha_mean, alpha_sd, beta_mean, beta_sd, oltre al parametro di errore residuo sigma.\nNei pannelli di sinistra e centrale della figura precedente si osservano le distribuzioni complete delle stime individuali di \\(\\alpha\\) e \\(\\beta\\). Le linee rosse rappresentano gli intervalli credibili al 95% per ciascun partecipante, mostrando l’eterogeneità interindividuale.\nIl confronto con un modello aggregato — cioè un modello in cui si stima un solo valore di \\(\\alpha\\) e \\(\\beta\\) per l’intero campione — mostra che le medie a livello di popolazione del modello gerarchico si collocano in una regione simile dello spazio dei parametri. Tuttavia, rispetto a un modello puramente individuale (in cui ogni partecipante è trattato separatamente), il modello gerarchico presenta un’importante differenza: gli intervalli credibili dei parametri individuali risultano meno dispersi e più regolari.\nQuesto fenomeno, noto come shrinkage (restringimento), deriva dal fatto che le stime individuali sono influenzate non solo dai dati del singolo partecipante, ma anche dalla distribuzione dei parametri a livello di popolazione. In pratica, le stime estreme vengono attenuate e “attirate” verso la media del gruppo. Questo effetto è chiaramente visibile nel grafico bivariato, dove le stime dei singoli soggetti si distribuiscono attorno al centro della distribuzione collettiva.\nLo shrinkage ha un importante vantaggio: riduce l’impatto del rumore nei dati e rende le stime più robuste. Come mostrato da Boehm et al. (2018), questo approccio penalizza implicitamente i valori altamente improbabili, migliorando la stabilità delle inferenze e aumentando la capacità del modello di generalizzare a nuovi dati.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Estensioni</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/02_dynamic_models.html#differenze-tra-gruppi",
    "href": "chapters/formal_models/02_dynamic_models.html#differenze-tra-gruppi",
    "title": "81  Estensioni",
    "section": "\n81.3 Differenze tra gruppi",
    "text": "81.3 Differenze tra gruppi\n\n81.3.1 Definizione del modello Stan\n\nstancode &lt;- \"\n// Modello gerarchico con iper-parametri specifici per condizione. \n// Versione con parametrizzazione non centrata per evitare transizioni divergenti.\n\ndata {\n  int&lt;lower=1&gt; Ntotal;\n  array[Ntotal] real trial;\n  array[Ntotal] real observed_goal;\n  array[Ntotal] real performance;\n  int&lt;lower=1&gt; Nsubj;\n  array[Ntotal] int&lt;lower=1&gt; subject;\n  array[Nsubj] int&lt;lower=1, upper=2&gt; cond_by_subj;\n}\n\nparameters {\n  // Parametri non centrati\n  vector[Nsubj] alpha_raw;\n  vector[Nsubj] beta_raw;\n\n  real&lt;lower=0&gt; sigma;\n\n  array[2] real alpha_mean;\n  array[2] real&lt;lower=0&gt; alpha_sd;\n  array[2] real beta_mean;\n  array[2] real&lt;lower=0&gt; beta_sd;\n}\n\ntransformed parameters {\n  vector[Nsubj] alpha;\n  vector[Nsubj] beta;\n\n  for (s in 1:Nsubj) {\n    int k = cond_by_subj[s];\n    alpha[s] = alpha_mean[k] + alpha_sd[k] * alpha_raw[s];\n    beta[s] = beta_mean[k] + beta_sd[k] * beta_raw[s];\n  }\n}\n\nmodel {\n  real predicted_goal;\n\n  // Priori debolmente-informativi\n  for (k in 1:2) {\n    alpha_mean[k] ~ normal(0, 1);\n    alpha_sd[k] ~ normal(0, 1);\n    beta_mean[k] ~ normal(0, 1);\n    beta_sd[k] ~ normal(0, 1);\n  }\n\n  // Priori standardizzati sui raw\n  alpha_raw ~ normal(0, 1);\n  beta_raw ~ normal(0, 1);\n\n  sigma ~ normal(0, 1);\n\n  for (i in 1:Ntotal) {\n    if (trial[i] == 1) {\n      predicted_goal = observed_goal[i];\n    } else {\n      predicted_goal += alpha[subject[i]] * (performance[i - 1] - predicted_goal) +\n                         beta[subject[i]];\n    }\n    observed_goal[i] ~ normal(predicted_goal, sigma);\n  }\n}\n\ngenerated quantities {\n  array[Ntotal] real predicted_goal_rep;\n  array[Ntotal] real log_lik;\n  real predicted_goal;\n\n  for (i in 1:Ntotal) {\n    if (trial[i] == 1) {\n      predicted_goal = observed_goal[i];\n    } else {\n      predicted_goal += alpha[subject[i]] * (performance[i - 1] - predicted_goal) +\n                         beta[subject[i]];\n    }\n    predicted_goal_rep[i] = normal_rng(predicted_goal, sigma);\n    log_lik[i] = normal_lpdf(observed_goal[i] | predicted_goal, sigma);\n  }\n}\n\"\n\nNel modello Stan, la differenza tra i due gruppi (ad es. approach vs avoidance) è stata implementata a livello dei parametri gerarchici alpha (tasso di apprendimento) e beta (decision noise inversa). Vediamo come funziona, passo per passo.\n\n81.3.1.1 Dati di input\nNel blocco data ci sono due elementi chiave:\narray[Nsubj] int&lt;lower=1, upper=2&gt; cond_by_subj;\nQuesta è una variabile che assegna a ciascun soggetto il numero della condizione a cui appartiene (1 o 2). Viene derivata in R con:\ncond_by_subj &lt;- dat |&gt;\n  distinct(subject, condition_num) |&gt;\n  arrange(subject) |&gt;\n  pull(condition_num)\nOgni soggetto appartiene a una sola condizione, quindi possiamo usare cond_by_subj[s] per sapere a quale gruppo appartiene il soggetto s.\n\n81.3.1.2 Parametri di gruppo (iper-parametri)\narray[2] real alpha_mean;\narray[2] real&lt;lower=0&gt; alpha_sd;\narray[2] real beta_mean;\narray[2] real&lt;lower=0&gt; beta_sd;\nCi sono due medie e due deviazioni standard per ciascun parametro (alpha, beta), una per ogni condizione. Quindi:\n\n\nalpha_mean[1] è la media di alpha per i soggetti in condizione 1,\n\nalpha_mean[2] è la media di alpha per i soggetti in condizione 2,\nstesso discorso per beta.\n\n81.3.1.3 Costruzione dei parametri individuali in transformed parameters\n\nQuesta è la parte centrale in cui la differenza tra gruppi entra nel modello:\nvector[Nsubj] alpha;\nvector[Nsubj] beta;\n\nfor (s in 1:Nsubj) {\n  int k = cond_by_subj[s];\n  alpha[s] = alpha_mean[k] + alpha_sd[k] * alpha_raw[s];\n  beta[s]  = beta_mean[k]  + beta_sd[k]  * beta_raw[s];\n}\nCosa succede qui?\n\nPer ogni soggetto s, si identifica a quale condizione k (1 o 2) appartiene.\nIl valore del parametro alpha[s] è costruito a partire dalla media e deviazione standard della condizione k, più un termine casuale alpha_raw[s] (spiegato sotto).\nLo stesso vale per beta[s].\n\nQuesto approccio consente di stabilire una distribuzione diversa dei parametri per ciascun gruppo. In pratica, stiamo dicendo che i parametri individuali provengono da due distribuzioni differenti — una per ciascun gruppo sperimentale — e possiamo stimare separatamente le medie e le varianze di queste distribuzioni.\n\n81.3.1.4 Parametrizzazione non centrata\nUn altro aspetto specifico di questo modello è l’uso della parametrizzazione non centrata.\nQuando usiamo parametrizzazioni gerarchiche centrate, cioè:\nalpha[s] ~ normal(alpha_mean[k], alpha_sd[k])\nsi può verificare un problema noto nei modelli Bayesiani, ovvero le transizioni divergenti durante l’Hamiltonian Monte Carlo (HMC). Questo accade soprattutto quando:\n\nla deviazione standard (alpha_sd[k]) è molto piccola o incerta,\nle osservazioni per soggetto sono poche.\n\nIn questi casi, l’HMC fatica a esplorare lo spazio dei parametri, portando a campionamenti inefficienti e bias.\nIn tali circostanze si ricorre alla parametrizzazione non centrata. La parametrizzazione non centrata riformula la distribuzione gerarchica come segue. Invece di\nalpha[s] ~ normal(alpha_mean[k], alpha_sd[k])\nsi scrive:\nalpha[s] = alpha_mean[k] + alpha_sd[k] * alpha_raw[s];\nalpha_raw[s] ~ normal(0, 1);\nQuesta riscrittura:\n\nsepara il “rumore” (alpha_raw[s]) dalla scala e dal centro della distribuzione;\nrende il campionamento molto più stabile;\nmigliora l’esplorazione dello spazio dei parametri;\nè particolarmente utile nei modelli con gerarchie complesse o gruppi con pochi dati.\n\nNota: la distribuzione implicita di alpha[s] resta comunque normale con media alpha_mean[k] e deviazione alpha_sd[k]. L’unica cosa che cambia è la parametrizzazione, non il significato.\nIn conclusione, le differenze tra gruppi vengono inserite tramite iper-parametri di gruppo (alpha_mean[k], beta_mean[k]), con assegnazione a livello di soggetto (cond_by_subj[s]), per costruire alpha[s] e beta[s] specifici per ciascun soggetto e condizione.\nLa parametrizzazione non centrata viene utilizzata per definire i parametri individuali (alpha, beta) attraverso trasformazioni di variabili latenti standardizzate (alpha_raw, beta_raw). Questo migliora la convergenza e riduce il rischio di transizioni divergenti nei modelli gerarchici complessi.\n\n81.3.2 Compilazione ed esecuzione del modello\n\nstanmod &lt;- cmdstan_model(\n  write_stan_file(stancode),\n  compile = TRUE\n)\n\n\n# Crea una mappatura numerica coerente\ndat &lt;- dat |&gt;\n  mutate(condition_num = as.integer(as.factor(condition)))  # 1 = approach, 2 = avoidance\n\n# Ricava condizione per ciascun soggetto (assumendo una condizione per soggetto)\ncond_by_subj &lt;- dat |&gt;\n  distinct(subject, condition_num) |&gt;\n  arrange(subject) |&gt;\n  pull(condition_num)\n\n# Ricrea lo stan_data completo con condizione coerente\nstan_data &lt;- list(\n  Ntotal = nrow(dat),\n  Nsubj = length(unique(dat$subject)),\n  subject = dat$subject,\n  trial = dat$trial,\n  observed_goal = dat$goal,\n  performance = dat$performance,\n  condition = dat$condition_num,         # vettore per trial\n  cond_by_subj = cond_by_subj            # vettore per soggetto\n)\n\n\nfit3 &lt;- stanmod$sample(\n  data = stan_data,\n  iter_warmup = 1000,\n  iter_sampling = 10000,\n  chains = 4,\n  parallel_chains = 4,\n  refresh = 1000,\n  seed = 123, \n  adapt_delta = 0.999,  # aumenta l'adattamento per ridurre le divergenze\n  max_treedepth = 15  # aumenta la profondità dell'albero per esplorare meglio lo spazio\n)\n\n\n# Converti l'oggetto fit in draws_df (o draws_array, se preferisci)\ndraws_df &lt;- as_draws_df(fit3)\n\n# Visualizza i nomi delle variabili\nvariables &lt;- colnames(draws_df)\n\n# Stampa solo quelle che contengono \"alpha_mean\"\nprint(variables[grepl(\"alpha_mean\", variables)])\n#&gt; [1] \"alpha_mean[1]\" \"alpha_mean[2]\"\n\n# Se vuoi verificare anche altri parametri (ad es. \"alpha[\" o \"beta[\"), puoi usare\n# print(variables[grepl(\"alpha\\\\[\", variables)])\n\n\n# Estrai solo le colonne desiderate e calcola la differenza\ndraws_df |&gt; \n  select(`alpha_mean[1]`, `alpha_mean[2]`) |&gt; \n  rename(alpha_mean_1 = `alpha_mean[1]`,\n         alpha_mean_2 = `alpha_mean[2]`) |&gt; \n  mutate(delta_alpha_mean = alpha_mean_2 - alpha_mean_1) |&gt; \n  summarise(\n    delta_alpha_mean_mean = mean(delta_alpha_mean),\n    delta_alpha_mean_low95 = quantile(delta_alpha_mean, 0.025),\n    delta_alpha_mean_upp95 = quantile(delta_alpha_mean, 0.975)\n  )\n#&gt; # A tibble: 1 × 3\n#&gt;   delta_alpha_mean_mean delta_alpha_mean_low95 delta_alpha_mean_upp95\n#&gt;                   &lt;dbl&gt;                  &lt;dbl&gt;                  &lt;dbl&gt;\n#&gt; 1                -0.123                 -0.251                0.00439\n\n\n# Estrai i draw posteriori per beta_mean\ndraws_df |&gt; \n  select(`beta_mean[1]`, `beta_mean[2]`) |&gt; \n  rename(beta_mean_1 = `beta_mean[1]`,\n         beta_mean_2 = `beta_mean[2]`) |&gt; \n  mutate(delta_beta_mean = beta_mean_2 - beta_mean_1) |&gt; \n  summarise(\n    delta_beta_mean_mean = mean(delta_beta_mean),\n    delta_beta_mean_low95 = quantile(delta_beta_mean, 0.025),\n    delta_beta_mean_upp95 = quantile(delta_beta_mean, 0.975)\n  )\n#&gt; # A tibble: 1 × 3\n#&gt;   delta_beta_mean_mean delta_beta_mean_low95 delta_beta_mean_upp95\n#&gt;                  &lt;dbl&gt;                 &lt;dbl&gt;                 &lt;dbl&gt;\n#&gt; 1               -0.246                -0.511                0.0258\n\n\n# Estrai draw posteriori\nposterior_alpha &lt;- fit3 |&gt;\n  spread_draws(alpha_mean[cond]) |&gt;\n  mutate(parameter = \"alpha_mean\",\n         condition = if_else(cond == 1, \"Condition 1\", \"Condition 2\")) |&gt;\n  rename(value = alpha_mean)\n\nposterior_beta &lt;- fit3 |&gt;\n  spread_draws(beta_mean[cond]) |&gt;\n  mutate(parameter = \"beta_mean\",\n         condition = if_else(cond == 1, \"Condition 1\", \"Condition 2\")) |&gt;\n  rename(value = beta_mean)\n\n\n# Unisci per plotting\nposterior_both &lt;- bind_rows(posterior_alpha, posterior_beta)\n\n# Grafico\nggplot(posterior_both, aes(x = value, fill = condition)) +\n  geom_density(alpha = 0.6) +\n  facet_wrap(~parameter, scales = \"free\") +\n  labs(\n    x = \"Posterior Mean Value\",\n    y = \"Density\",\n    fill = \"Condition\",\n    title = \"Posterior Distributions for alpha_mean and beta_mean\"\n  ) \n\n\n\n\n\n\n\nPer entrambi i parametri (alpha_mean e beta_mean), le stime delle differenze tra le due condizioni (che possiamo definire ad esempio come “approach” e “avoidance”) mostrano valori medi negativi:\n\n\nDelta alpha_mean: -0.122. Intervallo di credibilità al 95%: [-0.248, 0.004].\n\nDelta beta_mean: -0.248. Intervallo di credibilità al 95%: [-0.514, 0.017].\n\nIn entrambi i casi, l’intervallo di credibilità include lo zero. Questo significa che, alla luce dei dati e del modello specificato, non possiamo affermare con una soglia di credibilità del 95% che vi sia una differenza sistematica tra le due condizioni per i parametri alpha e beta.\nDetto in altri termini, nonostante il valore medio delle differenze sia negativo (suggerendo che, in media, alpha_mean e beta_mean potrebbero essere più bassi nella condizione 2 rispetto alla condizione 1), l’incertezza intorno a queste stime è troppo ampia per escludere con ragionevole sicurezza che la vera differenza possa essere nulla o addirittura positiva.\n\n81.3.3 Considerazioni\n\nNon si tratta di una “mancanza di effetto”, ma piuttosto di una mancanza di evidenza per una differenza abbastanza marcata da emergere con l’attuale numero di soggetti e struttura del modello.\nPuò essere utile controllare anche la probabilità a posteriori che la differenza sia minore di 0 (ad es., mean(delta_alpha_mean &lt; 0)), per una stima più continua del supporto.\nSi potrebbe anche esplorare la dimensione dell’effetto e valutare se l’effetto stimato ha una qualche rilevanza pratica o teorica, anche se non supera la soglia convenzionale dell’intervallo credibile.\n\n\n# Calcola probabilità a posteriori per delta_alpha_mean &lt; 0 e delta_beta_mean &lt; 0\n# (supponiamo che draws_df contenga le colonne `alpha_mean[1]`, `alpha_mean[2]`, ecc.)\n\n# Calcola e stampa probabilità a posteriori\nprob_delta_alpha_neg &lt;- mean(draws_df$`alpha_mean[2]` - draws_df$`alpha_mean[1]` &lt; 0)\nprob_delta_beta_neg  &lt;- mean(draws_df$`beta_mean[2]` - draws_df$`beta_mean[1]` &lt; 0)\n\ncat(\"P(delta_alpha_mean &lt; 0):\", round(prob_delta_alpha_neg, 3), \"\\n\")\n#&gt; P(delta_alpha_mean &lt; 0): 0.97\ncat(\"P(delta_beta_mean &lt; 0):\", round(prob_delta_beta_neg, 3), \"\\n\")\n#&gt; P(delta_beta_mean &lt; 0): 0.963\n\n\n# Costruisci una tabella riassuntiva con la dimensione dell'effetto\nsummary_df &lt;- tibble(\n  parameter = c(\"alpha_mean\", \"beta_mean\"),\n  delta_mean = c(\n    mean(draws_df$`alpha_mean[2]` - draws_df$`alpha_mean[1]`),\n    mean(draws_df$`beta_mean[2]` - draws_df$`beta_mean[1]`)\n  ),\n  lower_95 = c(\n    quantile(draws_df$`alpha_mean[2]` - draws_df$`alpha_mean[1]`, 0.025),\n    quantile(draws_df$`beta_mean[2]` - draws_df$`beta_mean[1]`, 0.025)\n  ),\n  upper_95 = c(\n    quantile(draws_df$`alpha_mean[2]` - draws_df$`alpha_mean[1]`, 0.975),\n    quantile(draws_df$`beta_mean[2]` - draws_df$`beta_mean[1]`, 0.975)\n  ),\n  prob_below_0 = c(\n    prob_delta_alpha_neg,\n    prob_delta_beta_neg\n  )\n)\n\nprint(summary_df)\n#&gt; # A tibble: 2 × 5\n#&gt;   parameter  delta_mean lower_95 upper_95 prob_below_0\n#&gt;   &lt;chr&gt;           &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;\n#&gt; 1 alpha_mean     -0.123   -0.251  0.00439        0.970\n#&gt; 2 beta_mean      -0.246   -0.511  0.0258         0.963\n\n\n# Grafico a barre con intervallo credibile\n\nsummary_df |&gt; \n  ggplot(aes(x = parameter, y = delta_mean)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\", width = 0.5) +\n  geom_errorbar(aes(ymin = lower_95, ymax = upper_95), width = 0.2) +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  labs(\n    title = \"Differenze posteriori tra le condizioni\",\n    x = \"Parametro\",\n    y = \"Differenza media (cond2 - cond1)\"\n  ) \n\n\n\n\n\n\n\nSulla base dell’analisi bayesiana condotta, possiamo trarre le seguenti conclusioni in merito al confronto tra le due condizioni per i parametri alpha_mean e beta_mean, che rappresentano rispettivamente il tasso di apprendimento e la coerenza nelle scelte (inverse decision noise) Parametro alpha (tasso di apprendimento). Differenza media stimata tra condizioni: -0.122. Questo indica che, in media, la condizione 2 mostra un tasso di apprendimento più basso rispetto alla condizione 1. Intervallo di credibilità al 95%: da -0.248 a 0.004. L’intervallo include valori positivi prossimi allo zero, suggerendo che non possiamo escludere con certezza che le condizioni abbiano valori simili, ma gran parte della massa a posteriori è sotto zero. Infatti, la probabilità a posteriori che la differenza sia &lt; 0 è 0.971. Questo indica un forte supporto a favore dell’ipotesi che la condizione 2 abbia un tasso di apprendimento inferiore alla condizione 1.; Parametro beta (coerenza nelle scelte). Differenza media stimata tra condizioni: -0.248. Ciò suggerisce che la condizione 2 mostra una tendenza a scelte più rumorose (cioè meno coerenti) rispetto alla condizione 1. Intervallo di credibilità al 95%: da -0.514 a 0.017. Anche qui l’intervallo include valori vicini a zero, ma la gran parte della distribuzione è sotto lo zero. Infatti, la probabilità a posteriori che la differenza sia &lt; 0 è 0.967. Questo fornisce un forte supporto per l’ipotesi che nella condizione 2 le scelte siano meno coerenti (ovvero beta più bassa).; Conclusione. Pur non superando la soglia convenzionale dell’intervallo credibile al 95% (entrambi gli intervalli includono zero), la probabilità a posteriori che la differenza sia negativa è elevata (&gt; 0.96) per entrambi i parametri. Questi risultati indicano che:. * c’è una chiara tendenza verso un tasso di apprendimento più basso e una maggiore rumore decisionale nella condizione 2 rispetto alla condizione 1; * la forza del supporto dipende dalla soglia soggettiva che si intende adottare (es. un ricercatore potrebbe considerare 97% sufficiente, altri potrebbero richiedere &gt;99%).\nInfine, si suggerisce di considerare la rilevanza pratica o teorica dell’effetto: anche se piccolo, un delta_beta_mean = -0.25 potrebbe indicare un cambiamento sostanziale nel comportamento decisionale a seconda del contesto sperimentale.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Estensioni</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/02_dynamic_models.html#confronto-tra-modelli",
    "href": "chapters/formal_models/02_dynamic_models.html#confronto-tra-modelli",
    "title": "81  Estensioni",
    "section": "\n81.4 Confronto tra modelli",
    "text": "81.4 Confronto tra modelli\n\nlog_lik1 &lt;- fit1$draws(variables = \"log_lik\", format = \"matrix\")\nlog_lik2 &lt;- fit2$draws(variables = \"log_lik\", format = \"matrix\")\nlog_lik3 &lt;- fit3$draws(variables = \"log_lik\", format = \"matrix\")\n\n\n# Calcola LOO per ciascun modello\nloo1 &lt;- loo(log_lik1)\nloo2 &lt;- loo(log_lik2)\nloo3 &lt;- loo(log_lik3)\n\n\n# Confronto tra i modelli\nmodel_comparison &lt;- loo_compare(loo1, loo2, loo3)\nprint(model_comparison)\n#&gt;        elpd_diff se_diff\n#&gt; model3   0.0       0.0  \n#&gt; model2  -1.8       3.4  \n#&gt; model1 -78.9      43.1\n\nIl confronto tra modelli si basa sull’ELPD (Expected Log Predictive Density), una misura della bontà predittiva del modello, calcolata tramite Leave-One-Out cross-validation (LOO). Valori più alti di ELPD indicano che il modello predice meglio i dati osservati.\nQueste differenze sono calcolate rispetto al modello con il miglior ELPD, cioè il modello 3 (quello gerarchico con differenze tra gruppi). L’interpretazione è la seguente.\nIl Modello 3 (modello gerarchico con differenze tra gruppi) ha il miglior valore di ELPD e funge da riferimento per le differenze. Introduce iper-parametri differenti per ciascun gruppo (condizione), migliorando la capacità predittiva.\nIl Modello 2 (modello gerarchico senza differenze tra gruppi) ha un ELPD inferiore di 1.8 punti rispetto al modello 3, con una deviazione standard della differenza pari a 3.4. Questa differenza è piccola rispetto alla sua incertezza (±3.4), per cui non si può concludere con certezza che il modello 3 sia migliore del 2. Tuttavia, la leggera superiorità in termini predittivi del modello 3 suggerisce che potrebbe esserci un valore aggiunto nel modellare separatamente i gruppi.\nIl Modello 1 (modello senza struttura gerarchica) ha un ELPD molto più basso (-78.9), con un errore standard di 43.1. Nonostante l’incertezza ampia, la differenza è sostanziale: c’è un chiaro vantaggio predittivo nel passare a un modello gerarchico. Questo risultato è coerente con l’idea che modelli gerarchici riescono a “condividere forza” tra soggetti, migliorando le stime individuali soprattutto quando i dati per soggetto sono limitati.\nIn conclusione,\n\nil modello 1 è nettamente inferiore rispetto agli altri due;\nil modello 3 mostra una leggera superiorità rispetto al 2, ma la differenza non è statisticamente robusta (dato l’errore standard);\nin assenza di altri criteri (come semplicità o interpretabilità), si potrebbe preferire il modello 3 per la sua migliore performance predittiva, pur riconoscendo che il guadagno è modesto.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Estensioni</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/02_dynamic_models.html#riflessioni-conclusive",
    "href": "chapters/formal_models/02_dynamic_models.html#riflessioni-conclusive",
    "title": "81  Estensioni",
    "section": "\n81.5 Riflessioni Conclusive",
    "text": "81.5 Riflessioni Conclusive\nIn questo capitolo, abbiamo presentato un’evoluzione progressiva di tre approcci bayesiani per modellare l’aggiornamento degli obiettivi, dimostrando come la complessità strutturale possa migliorare l’analisi psicologica. Si è partiti da un modello individuale semplice per arrivare a un framework gerarchico che sfrutta le similarità tra i partecipanti e, infine, a un modello che incorpora le differenze tra le condizioni sperimentali.\nL’analisi comparativa ha mostrato che la struttura gerarchica offre vantaggi sostanziali in termini di capacità predittiva, come dimostrato dai valori ELPD. Questo approccio implementa efficacemente il principio dello shrinkage, stabilizzando le stime, soprattutto quando i dati per singolo soggetto sono limitati, situazione comune nella ricerca psicologica.\nParticolarmente illuminante è stato il modello con gruppi sperimentali che ha permesso di valutare le differenze sistematiche nei parametri cognitivi tra le varie condizioni. Sebbene gli effetti non raggiungano la significatività tradizionale, le probabilità a posteriori superiori al 96% forniscono un supporto quantificabile alle ipotesi direzionali, dimostrando la potenza dell’inferenza bayesiana nel cogliere sfumature spesso trascurate dai metodi convenzionali.\nDal punto di vista metodologico, questo percorso dimostra l’importanza di:\n\nstrutturare adeguatamente i modelli per riflettere le dipendenze naturali tra le osservazioni;\nincorporare sistematicamente le informazioni sperimentali nei livelli iperparametrici.\nbilanciare complessità e generalizzazione attraverso confronti model-based.\n\nIn sintesi, il modello presentato, autoregressivo non lineare a tempo discreto e formulato in un framework bayesiano multilivello, offre una cornice flessibile per rappresentare processi dinamici che variano nel tempo, tra individui e tra gruppi definiti a priori. Le tecniche presentate in questo capitolo forniscono una solida base per affrontare scenari ancora più complessi, come quelli relativi ai modelli di miscela per classificazioni non note (per un approfondimento, si veda il tutorial di Knight et al., 2023).",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Estensioni</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/02_dynamic_models.html#bibliografia",
    "href": "chapters/formal_models/02_dynamic_models.html#bibliografia",
    "title": "81  Estensioni",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nKnight, E., Neal, A., Palada, H., & Ballard, T. (2023). A Tutorial on Bayesian Modeling of Change Across Time, Individuals, and Groups. Computational Brain & Behavior, 6(4), 697–718.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Estensioni</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/03_rescorla_wagner.html",
    "href": "chapters/formal_models/03_rescorla_wagner.html",
    "title": "82  Il modello di Rescorla–Wagner",
    "section": "",
    "text": "Introduzione\nNel modello di Rescorla–Wagner, invece, l’aggiornamento è guidato dall’errore di predizione del rinforzo (reward prediction error, RPE): la differenza tra il rinforzo ottenuto e quello atteso. Questo rende il modello più psicologicamente plausibile, perché riflette il meccanismo di apprendimento osservato in molti studi di psicologia e neuroscienze, dove le nuove informazioni vengono integrate in proporzione a quanto il risultato differisce dalle aspettative.\nA questa componente di apprendimento si aggiunge un livello decisionale: le scelte non sono deterministiche, ma seguono un compromesso tra esplorazione (provare alternative meno note) e sfruttamento (scegliere l’opzione che sembra migliore sulla base dell’esperienza). Questo equilibrio è regolato dalla funzione Softmax, che traduce i valori appresi (\\(Q\\)) in probabilità di scelta.\nIn questo modo, il modello collega in maniera esplicita due livelli fondamentali:",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>Il modello di Rescorla–Wagner</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/03_rescorla_wagner.html#introduzione",
    "href": "chapters/formal_models/03_rescorla_wagner.html#introduzione",
    "title": "82  Il modello di Rescorla–Wagner",
    "section": "",
    "text": "Questo capitolo introduce il modello di Rescorla–Wagner (RW) con regola di scelta Softmax. Si tratta di un’estensione naturale del modello di revisione degli obiettivi discusso nel capitolo precedente. In quel modello, l’aggiornamento dell’obiettivo era un semplice termine additivo: ad ogni trial, la stima veniva spostata un po’ più vicino al valore osservato, con un ritmo determinato dal parametro di apprendimento.\n\n\n\n\n\n\nLivello dell’apprendimento – come i valori associati agli stimoli vengono aggiornati in base all’esperienza.\n\nLivello decisionale – come questi valori vengono trasformati in scelte effettive.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>Il modello di Rescorla–Wagner</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/03_rescorla_wagner.html#il-modello-rw-formulazione",
    "href": "chapters/formal_models/03_rescorla_wagner.html#il-modello-rw-formulazione",
    "title": "82  Il modello di Rescorla–Wagner",
    "section": "\n82.1 Il modello RW: formulazione",
    "text": "82.1 Il modello RW: formulazione\nNel paradigma a due alternative (A/B), il modello mantiene una stima di valore \\(Q_t(s)\\) per ciascuno stimolo \\(s \\in \\{A,B\\}\\). Dopo la scelta al tempo \\(t\\) e l’osservazione di un esito \\(R_t \\in \\{0,1\\}\\), il valore si aggiorna secondo\n\\[\nQ_{t+1}(s) = Q_t(s) + \\alpha \\, \\delta_t, \\qquad \\delta_t = R_t - Q_t(s),\n\\tag{82.1}\\]\ndove \\(\\alpha \\in (0,1)\\) è la learning rate. È spesso utile usare due learning rate: \\(\\alpha^+\\) per gli errori positivi (\\(\\delta_t&gt;0\\)) e \\(\\alpha^-\\) per quelli negativi (\\(\\delta_t&lt;0\\)), così da rappresentare asimmetrie nell’apprendimento da ricompense e punizioni.\nLa generazione della scelta richiede di trasformare i valori in probabilità. Con la Softmax si assume\n\\[\nP(\\text{scegli A} \\mid Q_t) = \\frac{\\exp(\\beta \\, Q_t(A))}{\\exp(\\beta \\, Q_t(A)) + \\exp(\\beta \\, Q_t(B))},\n\\tag{82.2}\\]\ndove \\(\\beta&gt;0\\) è il parametro di inverse temperature: con valori alti le scelte sono più deterministiche (sfruttamento), con valori bassi più stocastiche (esplorazione).\n\n\n\n\n\n\nApprofondimento: esplorazione vs. sfruttamento nella Softmax\n\n\n\nLa funzione Softmax trasforma le stime di valore \\(Q\\) in probabilità di scelta. Il parametro di inverse temperature \\(\\beta\\) regola quanto fortemente le differenze di valore influenzano la decisione:\n\n\n\\(\\beta\\) basso → alta esplorazione: anche opzioni con valore inferiore vengono scelte con probabilità non trascurabile.\n\n\n\\(\\beta\\) alto → alto sfruttamento: si tende quasi sempre a scegliere l’opzione con valore maggiore.\n\nNel grafico seguente, per due diversi valori di \\(\\beta\\), vediamo come cambia la relazione tra la differenza di valore \\(Q_A - Q_B\\) e la probabilità di scegliere A.\n\n# Differenze di valore\ndq &lt;- seq(-2, 2, length.out = 200)\n\n# Funzione Softmax per due opzioni\nsoftmax_prob &lt;- function(dq, beta) {\n  exp(beta * dq) / (1 + exp(beta * dq))\n}\n\ndf &lt;- data.frame(\n  dq = rep(dq, 2),\n  prob_A = c(softmax_prob(dq, beta = 0.5),\n             softmax_prob(dq, beta = 5)),\n  beta = factor(rep(c(\"β = 0.5 (alta esplorazione)\",\n                      \"β = 5 (alto sfruttamento)\"),\n                    each = length(dq)))\n)\n\nggplot(df, aes(x = dq, y = prob_A, color = beta)) +\n  geom_line(size = 1.2) +\n  scale_color_brewer(palette = \"Set1\") +\n  labs(\n    x = expression(Delta*Q[A-B]),\n    y = \"Probabilità di scegliere A\",\n    title = \"Effetto di β sul compromesso\\nesplorazione/sfruttamento\"\n  ) \n\n\n\n\n\n\n\nInterpretazione del grafico:\n\n\nSe \\(\\Delta Q = 0.5\\) (l’opzione A vale leggermente più di B):\n\ncon \\(\\beta = 0.5\\) la probabilità di scegliere A è circa 0.56, quindi il comportamento resta molto esplorativo;\ncon \\(\\beta = 5\\) la probabilità sale a circa 0.92, segnalando un comportamento quasi del tutto rivolto allo sfruttamento.\n\n\n\nSe \\(\\Delta Q = 1\\) (A è chiaramente migliore di B):\n\ncon \\(\\beta = 0.5\\) la probabilità di scegliere A è circa 0.62 — ancora lontana da una scelta deterministica;\ncon \\(\\beta = 5\\) la probabilità supera 0.99, quindi si sceglie quasi sempre A.\n\n\n\nQuesto mostra chiaramente come \\(\\beta\\) regoli il compromesso tra esplorare alternative e sfruttare la scelta più redditizia nota.\n\n\n\n82.1.1 Identificabilità e scaling\nPoiché una traslazione comune \\(Q_t(s)+c\\) non cambia le probabilità Softmax, conviene inizializzare i valori in modo simmetrico (ad es., \\(Q_0(A)=Q_0(B)=0.5\\)) e mantenere i rinforzi in \\(\\{0,1\\}\\). In alternativa, si può fissare uno dei due valori iniziali o imporre vincoli su \\(\\beta\\).",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>Il modello di Rescorla–Wagner</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/03_rescorla_wagner.html#simulazione-di-dati-prl-semplificato",
    "href": "chapters/formal_models/03_rescorla_wagner.html#simulazione-di-dati-prl-semplificato",
    "title": "82  Il modello di Rescorla–Wagner",
    "section": "\n82.2 Simulazione di dati (PRL semplificato)",
    "text": "82.2 Simulazione di dati (PRL semplificato)\nSimuliamo un compito Probabilistic Reversal Learning (PRL)1, con due stimoli: uno ricco (probabilità di ricompensa \\(p=0.7\\)) e uno povero (probabilità \\(1-p\\)), con una singola inversione a metà dei trial.\n\n# Simulatore RW + Softmax per compito 2AFC con una reversa\nsimulate_prl_rw &lt;- function(n_trials = 160,\n                            p_reward_rich = 0.7,\n                            reversal_trial = 80,\n                            alpha_pos = 0.15,\n                            alpha_neg = 0.10,\n                            beta = 4,\n                            Q0 = c(A = 0.5, B = 0.5),\n                            seed = 123) {\n  set.seed(seed)\n  Q &lt;- Q0\n  choice &lt;- integer(n_trials)\n  reward &lt;- integer(n_trials)\n  rich_is_A &lt;- rep(TRUE, n_trials)\n  if (!is.null(reversal_trial) && reversal_trial &gt; 0 && reversal_trial &lt; n_trials) {\n    rich_is_A[(reversal_trial+1):n_trials] &lt;- FALSE\n  }\n  for (t in seq_len(n_trials)) {\n    # Probabilità di scegliere A con softmax\n    pA &lt;- exp(beta * Q[\"A\"]) / (exp(beta * Q[\"A\"]) + exp(beta * Q[\"B\"]))\n    choice[t] &lt;- rbinom(1, 1, pA) # 1=A, 0=B\n    chosen &lt;- if (choice[t] == 1) \"A\" else \"B\"\n    # Probabilità di ricompensa per lo stimolo scelto\n    chosen_is_rich &lt;- (chosen == \"A\" && rich_is_A[t]) || (chosen == \"B\" && !rich_is_A[t])\n    pr &lt;- if (chosen_is_rich) p_reward_rich else (1 - p_reward_rich)\n    reward[t] &lt;- rbinom(1, 1, pr)\n    # Prediction error e aggiornamento\n    pe &lt;- reward[t] - Q[chosen]\n    if (pe &gt;= 0) {\n      Q[chosen] &lt;- Q[chosen] + alpha_pos * pe\n    } else {\n      Q[chosen] &lt;- Q[chosen] + alpha_neg * pe\n    }\n  }\n  tibble::tibble(\n    trial = seq_len(n_trials),\n    choice = factor(ifelse(choice == 1, \"A\", \"B\"), levels = c(\"A\",\"B\")),\n    reward = reward,\n    rich_is_A = rich_is_A\n  )\n}\n\nsim &lt;- simulate_prl_rw()\ndplyr::glimpse(sim)\n#&gt; Rows: 160\n#&gt; Columns: 4\n#&gt; $ trial     &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…\n#&gt; $ choice    &lt;fct&gt; B, B, A, B, B, A, B, A, A, A, B, B, A, B, B, B, A, B, A,…\n#&gt; $ reward    &lt;int&gt; 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1,…\n#&gt; $ rich_is_A &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TR…\n\nRappresentiamo l’andamento cumulativo delle scelte ricche (corrette), evidenziando la reversa.\n\nsim_plot &lt;- sim |&gt;\n  dplyr::mutate(\n    rich_choice = dplyr::case_when(\n      choice == \"A\" & rich_is_A ~ 1L,\n      choice == \"B\" & !rich_is_A ~ 1L,\n      TRUE ~ 0L\n    )\n  ) |&gt;\n  dplyr::mutate(cum_rich = cumsum(rich_choice) / dplyr::row_number())\n\nggplot(sim_plot, aes(trial, cum_rich)) +\n  geom_line(color = col1, linewidth = 1) +\n  geom_vline(xintercept = 80, linetype = 2, linewidth = 0.6, color = col2) +\n  labs(x = \"Trial\", y = \"Proporzione cumulativa scelte ricche\",\n       title = \"Andamento cumulativo e prova di reversa\") +\n  theme(plot.title = element_text(hjust = 0.5))",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>Il modello di Rescorla–Wagner</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/03_rescorla_wagner.html#stima-per-un-singolo-soggetto-mle",
    "href": "chapters/formal_models/03_rescorla_wagner.html#stima-per-un-singolo-soggetto-mle",
    "title": "82  Il modello di Rescorla–Wagner",
    "section": "\n82.3 Stima per un singolo soggetto (MLE)",
    "text": "82.3 Stima per un singolo soggetto (MLE)\nPer una prima stima accessibile, usiamo la Massima Verosimiglianza (MLE) su \\((\\alpha^+,\\alpha^-,\\beta)\\), con vincoli \\(\\alpha^\\pm \\in (0,1)\\), \\(\\beta&gt;0\\) tramite trasformazioni logistiche/esponenziali.\n\n# Log-verosimiglianza del modello RW + Softmax (un soggetto)\nll_rw_softmax &lt;- function(par, data, Q0 = c(A = 0.5, B = 0.5)) {\n  a_pos &lt;- plogis(par[1])\n  a_neg &lt;- plogis(par[2])\n  beta  &lt;- exp(par[3])\n  Q &lt;- Q0\n  ll &lt;- 0\n  for (t in seq_len(nrow(data))) {\n    pA &lt;- exp(beta * Q[\"A\"]) / (exp(beta * Q[\"A\"]) + exp(beta * Q[\"B\"]))\n    # Prob. della scelta osservata\n    p_choice &lt;- if (data$choice[t] == \"A\") pA else (1 - pA)\n    p_choice &lt;- max(p_choice, 1e-12) # stabilità numerica\n    ll &lt;- ll + log(p_choice)\n    # Aggiornamento sullo stimolo scelto\n    chosen &lt;- if (data$choice[t] == \"A\") \"A\" else \"B\"\n    pe &lt;- data$reward[t] - Q[chosen]\n    if (pe &gt;= 0) {\n      Q[chosen] &lt;- Q[chosen] + a_pos * pe\n    } else {\n      Q[chosen] &lt;- Q[chosen] + a_neg * pe\n    }\n  }\n  return(-ll) # minimizziamo\n}\n\nfit_rw_mle &lt;- function(data, init = c(qlogis(0.2), qlogis(0.2), log(3))) {\n  opt &lt;- optim(par = init, fn = ll_rw_softmax, data = data, method = \"BFGS\",\n               control = list(maxit = 500, reltol = 1e-8))\n  a_pos &lt;- plogis(opt$par[1])\n  a_neg &lt;- plogis(opt$par[2])\n  beta  &lt;- exp(opt$par[3])\n  list(par = c(alpha_pos = a_pos, alpha_neg = a_neg, beta = beta),\n       value = opt$value, convergence = opt$convergence, opt = opt)\n}\n\n# Stima MLE su dati simulati\nfit_mle &lt;- fit_rw_mle(sim)\nfit_mle$par\n#&gt; alpha_pos alpha_neg      beta \n#&gt;   0.09637   0.20590   5.14784\n\nConfrontiamo i dati osservati con una simulazione replicata dal modello parametrizzato con le stime MLE.\n\n# Simulazione \"replicata\" dal modello stimato (posterior predictive in chiave MLE)\nsim_rep &lt;- simulate_prl_rw(\n  n_trials = nrow(sim),\n  p_reward_rich = 0.7,\n  reversal_trial = 80,\n  alpha_pos = fit_mle$par[\"alpha_pos\"],\n  alpha_neg = fit_mle$par[\"alpha_neg\"],\n  beta = fit_mle$par[\"beta\"]\n)\n\ncompare_df &lt;- dplyr::bind_rows(\n  sim |&gt; dplyr::mutate(source = \"Osservato\"),\n  sim_rep |&gt; dplyr::mutate(source = \"Replicato MLE\")\n)\n\ncolori_confronto &lt;- c(\"Osservato\" = col1, \"Replicato MLE\" = col2)\n\nggplot(compare_df, aes(trial, as.numeric(choice == \"A\"), color = source)) +\n  stat_smooth(method = \"loess\", se = FALSE, linewidth = 1) +\n  geom_vline(xintercept = 80, linetype = 2, linewidth = 0.6, color = col3) +\n  scale_color_manual(values = colori_confronto, breaks = names(colori_confronto)) +\n  labs(y = \"Probabilità (stimata) di scegliere A\", color = NULL,\n       title = \"Dati osservati vs. simulazione dal modello stimato\") +\n  theme(plot.title = element_text(hjust = 0.5), legend.position = \"top\")",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>Il modello di Rescorla–Wagner</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/03_rescorla_wagner.html#stima-bayesiana-singolo-soggetto-stan",
    "href": "chapters/formal_models/03_rescorla_wagner.html#stima-bayesiana-singolo-soggetto-stan",
    "title": "82  Il modello di Rescorla–Wagner",
    "section": "\n82.4 Stima Bayesiana (singolo soggetto, Stan)",
    "text": "82.4 Stima Bayesiana (singolo soggetto, Stan)\nPer coerenza con il resto del manuale, includiamo una versione Bayesiana per singolo soggetto in Stan con prior deboli su \\(\\alpha^\\pm\\) (scala logit) e \\(\\beta\\) (scala log).\n\n# Codice Stan per RW + Softmax a due learning rate (singolo soggetto)\nstancode_rw_single &lt;- \"\ndata{\n  int&lt;lower=1&gt; T;                                  // numero di trial\n  array[T] int&lt;lower=1, upper=2&gt; choice;           // 1 = A, 2 = B\n  array[T] int&lt;lower=0, upper=1&gt; reward;           // 0/1 esito\n  vector[2] Q0;                                    // valori iniziali\n}\nparameters{\n  real a_pos_logit;\n  real a_neg_logit;\n  real log_beta;\n}\ntransformed parameters{\n  real&lt;lower=0, upper=1&gt; a_pos = inv_logit(a_pos_logit);\n  real&lt;lower=0, upper=1&gt; a_neg = inv_logit(a_neg_logit);\n  real&lt;lower=0&gt; beta = exp(log_beta);\n}\nmodel{\n  vector[2] Q = Q0;\n\n  // prior debolmente informativi\n  a_pos_logit ~ normal(0, 1.5);\n  a_neg_logit ~ normal(0, 1.5);\n  log_beta    ~ normal(1, 1.0);\n\n  for (t in 1:T){\n    // Per due alternative, la softmax si riduce a una logistica del differenziale di valore\n    // logit(pA) = beta * (Q_A - Q_B)\n    target += bernoulli_logit_lpmf( choice[t] == 1 | beta * (Q[1] - Q[2]) );\n\n    // Aggiornamento RW sullo stimolo scelto\n    int c = choice[t];                 // 1 = A, 2 = B\n    real pe = reward[t] - Q[c];        // prediction error\n    if (pe &gt;= 0) Q[c] += a_pos * pe;\n    else         Q[c] += a_neg * pe;\n  }\n}\n\"\n\n\n# Preparazione dati Stan e fit\nstan_data &lt;- list(\n  T = nrow(sim),\n  choice = ifelse(sim$choice==\"A\", 1L, 2L),\n  reward = sim$reward,\n  Q0 = c(0.5, 0.5)\n)\n\nmod_rw &lt;- cmdstanr::cmdstan_model(write_stan_file(stancode_rw_single))\nfit_rw  &lt;- mod_rw$sample(data = stan_data, chains = 4, parallel_chains = 4,\n                         iter_warmup = 1000, iter_sampling = 1000, seed = 42)\n\n\n# Estrazione dei campioni a posteriori (solo parametri di interesse)\ndraws_df &lt;- fit_rw$draws(c(\"a_pos\", \"a_neg\", \"beta\")) |&gt;\n  posterior::as_draws_df() |&gt;\n  tibble::as_tibble()\n\n\n# helper per riuso\nplot_posterior &lt;- function(draws, param, true, col_hex) {\n  ggplot(draws, aes(x = .data[[param]])) +\n    geom_histogram(aes(y = after_stat(density)), bins = 40,\n                   fill = col_hex, color = \"black\", alpha = 0.6) +\n    geom_density(color = col_hex, linewidth = 1) +\n    geom_vline(xintercept = true, color = \"black\", linetype = \"dotted\", linewidth = 1) +\n    annotate(\"text\", x = true, y = 0, label = format(true, digits = 3),\n             vjust = -1, hjust = -0.1, size = 3) +\n    labs(x = \"Valore del parametro\", y = \"Densità\",\n         title = param) +\n    theme(plot.title = element_text(hjust = 0.5))\n}\n\n# colori dalla palette_set1\ncols &lt;- c(\n  a_pos = unname(palette_set1[[\"uno\"]]),\n  a_neg = unname(palette_set1[[\"due\"]]),\n  beta  = unname(palette_set1[[\"tre\"]])\n)\n\n# valori veri (adatta se hai simulato diversamente)\ntrue_vals &lt;- c(a_pos = 0.15, a_neg = 0.10, beta = 4.0)\n\n# tre figure separate (il chunk può avere fig.height=3.5, out.width=\"70%\")\np_a_neg &lt;- plot_posterior(draws_df, \"a_neg\", true_vals[\"a_neg\"], cols[\"a_neg\"])\np_a_pos &lt;- plot_posterior(draws_df, \"a_pos\", true_vals[\"a_pos\"], cols[\"a_pos\"])\np_beta  &lt;- plot_posterior(draws_df, \"beta\",  true_vals[\"beta\"],  cols[\"beta\"])\n\n\np_a_neg\n\n\n\n\n\n\n\n\np_a_pos\n\n\n\n\n\n\n\n\np_beta\n\n\n\n\n\n\n\nL’ispezione delle distribuzioni a posteriori fornisce una misura intuitiva di quanto bene il modello è riuscito a recuperare i parametri generati nella simulazione. Nel grafico, le linee tratteggiate verticali rappresentano i valori veri usati per simulare i dati, mentre gli istogrammi mostrano la densità della distribuzione a posteriori stimata.\nSe la distribuzione a posteriori è centrata attorno al valore vero e presenta una variabilità ridotta, significa che il modello ha recuperato il parametro con buona precisione. Piccoli scostamenti possono derivare dalla variabilità stocastica del processo di simulazione o da trade-off tra parametri (ad esempio, tra a_pos e beta).\nIn un contesto applicato, questo confronto ha una doppia utilità didattica:\n\n\nVerifica del modello — Permette di capire se il modello, con la struttura e i dati disponibili, può realmente identificare i parametri di interesse.\n\nSensibilità ai dati — Evidenzia se alcuni parametri richiedono più dati o condizioni sperimentali specifiche per essere stimati in modo affidabile.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>Il modello di Rescorla–Wagner</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/03_rescorla_wagner.html#contextual-bandits-e-compiti-food-vs.-neutral",
    "href": "chapters/formal_models/03_rescorla_wagner.html#contextual-bandits-e-compiti-food-vs.-neutral",
    "title": "82  Il modello di Rescorla–Wagner",
    "section": "\n82.5 Contextual Bandits e compiti food vs. neutral",
    "text": "82.5 Contextual Bandits e compiti food vs. neutral\nLa famiglia dei banditi contestuali estende il modello RW introducendo variabili di contesto che modulano le probabilità di ricompensa (o l’interpretazione degli esiti). In pratica, si stima lo stesso impianto RW + Softmax, ma consentendo a \\(\\alpha^+,\\alpha^-\\) e \\(\\beta\\) di variare per contesto (ad es., cue alimentari vs. neutri) e, quando rilevante, per gruppo.\nNel nostro lavoro applicativo su decision-making specifico per il cibo nell’anoressia nervosa — in cui due compiti PRL identici si differenziavano unicamente per il contenuto degli stimoli (blocco neutral-only vs. food–neutral) — l’approccio RW consente di verificare se i parametri di apprendimento e scelta differiscono selettivamente nel contesto alimentare (Colpizzi et al., 2025). In particolare, i risultati indicano che deficit di apprendimento (riduzione delle learning rate) emergono solo in presenza di stimoli legati al cibo, mentre le stesse persone mostrano parametri nella norma in contesti neutrali; ciò suggerisce una specificità di contesto e supporta interpretazioni in termini di fattori di mantenimento.\n\n\n\n\n\n\nCollegamento didattico\n\n\n\nIl passaggio dal modello di revisione degli obiettivi al RW + Softmax consente di separare chiaramente apprendimento (come si aggiornano i valori) e politica di scelta (come i valori aggiornati guidano la selezione). Questa scomposizione è utile quando le differenze tra condizioni sperimentali si manifestano solo in uno dei due livelli.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>Il modello di Rescorla–Wagner</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/03_rescorla_wagner.html#riflessioni-conclusive",
    "href": "chapters/formal_models/03_rescorla_wagner.html#riflessioni-conclusive",
    "title": "82  Il modello di Rescorla–Wagner",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIl modello di Rescorla–Wagner con regola di scelta Softmax estende il modello di revisione degli obiettivi introducendo un livello decisionale che traduce i valori appresi (Q-values) in probabilità di scelta. Questo passaggio è cruciale perché separa due componenti fondamentali del comportamento:\n\n\nApprendimento dagli esiti (learning), rappresentato dai parametri di aggiornamento \\(a_{\\text{pos}}\\) e \\(a_{\\text{neg}}\\), che indicano la velocità con cui il soggetto integra feedback positivi e negativi.\n\nSelezione dell’azione (decision policy), rappresentata dal parametro \\(\\beta\\), che riflette la coerenza o la “determinazione” delle scelte sulla base dei valori appresi.\n\nQuesta distinzione è particolarmente rilevante negli studi clinici. Nel nostro lavoro sull’anoressia nervosa e il probabilistic reversal learning (PRL), abbiamo osservato che le pazienti mostrano un apprendimento ridotto solo in condizioni food-specific, mentre la prestazione in condizioni neutrali è simile a quella di controlli sani. Questo suggerisce che il deficit non è globale, ma legato al contenuto emotivamente saliente dello stimolo (Colpizzi et al., 2025).\nIl modello RW + Softmax ci ha permesso di individuare non solo quanto velocemente i valori venivano aggiornati in ciascuna condizione, ma anche come tali valori venivano tradotti in scelte. Ad esempio, una \\(\\beta\\) elevata indica scelte più coerenti con il valore appreso, mentre una \\(\\beta\\) bassa suggerisce un comportamento più esplorativo o incoerente. Nei nostri dati, le differenze in \\(a_{\\text{pos}}\\) e \\(a_{\\text{neg}}\\) tra condizioni fornivano un quadro preciso delle difficoltà di apprendimento, mentre \\(\\beta\\) rivelava se tali difficoltà si accompagnavano a un cambiamento nello stile decisionale.\nPer uno psicologo, questo approccio offre due vantaggi didattici e clinici:\n\n\nPrecisione teorica: possiamo formulare ipotesi separate su meccanismi di apprendimento e politiche decisionali, anziché inferire tutto dalla sola prestazione media.\n\nApplicabilità clinica: la scomposizione dei processi aiuta a capire se un deficit deriva da un problema nell’aggiornamento delle informazioni o da una strategia decisionale subottimale, con implicazioni per interventi mirati.\n\nIn sintesi, il modello RW + Softmax non è solo un esercizio statistico: è uno strumento che consente di tradurre il comportamento osservato in indicatori psicologicamente e clinicamente interpretabili, capaci di distinguere tra deficit specifici di contesto e strategie generali di scelta.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>Il modello di Rescorla–Wagner</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/03_rescorla_wagner.html#bibliografia",
    "href": "chapters/formal_models/03_rescorla_wagner.html#bibliografia",
    "title": "82  Il modello di Rescorla–Wagner",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nColpizzi, I., Sica, C., Marchetti, I., Guidi, L., Danti, S., Lucchesi, S., Giusti, E., Di Meglio, M., Ballardini, D., Mazzoni, C., et al. (2025). Food-specific decision-making in anorexia nervosa: a comparative study of clinical, at-risk, and healthy control groups. Eating Disorders, 1–19.",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>Il modello di Rescorla–Wagner</span>"
    ]
  },
  {
    "objectID": "chapters/formal_models/03_rescorla_wagner.html#footnotes",
    "href": "chapters/formal_models/03_rescorla_wagner.html#footnotes",
    "title": "82  Il modello di Rescorla–Wagner",
    "section": "",
    "text": "Nel compito di Probabilistic Reversal Learning, al partecipante vengono presentati due o più stimoli con probabilità diverse di ottenere un rinforzo (ad esempio una ricompensa monetaria o un feedback positivo). L’obiettivo è apprendere, attraverso il feedback, quale stimolo sia più vantaggioso. A intervalli predefiniti, ma non annunciati, le probabilità di ricompensa vengono invertite (reversal), richiedendo al partecipante di aggiornare le proprie scelte e adattarsi alla nuova contingenza. Questo compito è ampiamente utilizzato in neuropsicologia e psichiatria per valutare la flessibilità cognitiva e la sensibilità al feedback.↩︎",
    "crumbs": [
      "Modelli",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>Il modello di Rescorla–Wagner</span>"
    ]
  },
  {
    "objectID": "chapters/decision_analysis/01_study_method.html",
    "href": "chapters/decision_analysis/01_study_method.html",
    "title": "83  Analisi delle decisioni",
    "section": "",
    "text": "Introduzione\nL’analisi decisionale bayesiana è un modo per scegliere in condizioni di incertezza: si prevedono gli esiti possibili, si assegna a ciascuno un punteggio di utilità (quanto è desiderabile) o di perdita (quanto è costoso), e si sceglie l’alternativa che massimizza l’utilità attesa (equivalente a minimizzare la perdita attesa) rispetto alla distribuzione predittiva degli esiti.\nIn questo capitolo applicheremo il metodo al problema, concreto per gli studenti di psicologia, della scelta del metodo di studio. Metteremo a confronto tre opzioni, che differiscono per impegno richiesto ed efficacia prevista:\nValuteremo ogni metodo in base a due esiti: voto d’esame \\(g \\in [0,100]\\) e ore di studio \\(h \\ge 0\\). Entrambi sono incerti e variano per differenze individuali (abilità, stile, motivazione) e per la naturale variabilità del processo di apprendimento.\nIl quadro bayesiano ci consente di:",
    "crumbs": [
      "Decisioni",
      "<span class='chapter-number'>83</span>  <span class='chapter-title'>Analisi delle decisioni</span>"
    ]
  },
  {
    "objectID": "chapters/decision_analysis/01_study_method.html#introduzione",
    "href": "chapters/decision_analysis/01_study_method.html#introduzione",
    "title": "83  Analisi delle decisioni",
    "section": "",
    "text": "Metodo classico: studio su testi + esercizi; nessun supporto interattivo.\n\nMetodo di gruppo: come il classico, più discussioni in piccoli gruppi per chiarire e consolidare.\n\nMetodo con AI tutor: studio su testi integrato con spiegazioni alternative, chat interattiva e esercizi aggiuntivi generati dal tutor.\n\n\n\n\nStimare per ciascun metodo la distribuzione predittiva congiunta di \\((g, h)\\) a partire da dati (anche storici).\n\nCombinare voto e tempo in un unico numero tramite una funzione di utilità, ad es.\n\\[\nU(g,h;\\lambda) = g - \\lambda\\,h,\n\\]\ndove \\(\\lambda \\ge 0\\) esprime quanto “pesa” un’ora in termini di punti di voto (il tasso di scambio tra voto e tempo).\n\nCalcolare l’utilità attesa di ogni metodo integrando l’incertezza sui parametri e sugli esiti (via simulazione).\nSelezionare il metodo con utilità attesa più alta e quantificare quanto è probabile che sia la scelta migliore.",
    "crumbs": [
      "Decisioni",
      "<span class='chapter-number'>83</span>  <span class='chapter-title'>Analisi delle decisioni</span>"
    ]
  },
  {
    "objectID": "chapters/decision_analysis/01_study_method.html#schema-in-quattro-passi",
    "href": "chapters/decision_analysis/01_study_method.html#schema-in-quattro-passi",
    "title": "83  Analisi delle decisioni",
    "section": "\n83.1 Schema in quattro passi",
    "text": "83.1 Schema in quattro passi\nSecondo l’impostazione proposta da Gelman et al. (2013), l’analisi decisionale bayesiana può essere strutturata in quattro fasi fondamentali. Di seguito, adattiamo tale schema al contesto in esame.\n1. Definizione degli spazi delle decisioni e degli esiti.\nSiano:\n\n\n\\(D\\) l’insieme delle decisioni possibili, corrispondenti alla scelta tra tre metodi di studio:\\[  \nD = \\{1, 2, 3\\} \\equiv \\{\\text{metodo classico}, \\text{AI tutor}, \\text{studio di gruppo}\\}.  \n\\]\n\n\n\\(X\\) l’insieme degli esiti, rappresentati da una coppia \\((g, h)\\), dove:\n\n\n\\(g\\) è il voto d’esame (scalato tra 0 e 100 per convenienza);\n\n\n\\(h\\) è il numero di ore di studio impiegate (\\(h \\geq 0\\)).\nFormalmente, lo spazio degli esiti è definito come \\(X = \\mathbb{R} \\times \\mathbb{R}_+\\).\n\n\n\n2. Modellazione della distribuzione predittiva degli esiti.\nLa distribuzione degli esiti, condizionata alla decisione \\(d\\), viene modellata attraverso una specificazione congiunta delle componenti \\(H\\) (ore) e \\(G\\) (voto):\n\\[  \n\\begin{aligned}  \nH \\mid d &\\sim \\mathrm{Lognormale}\\big(\\mu^{(h)}_{d}, \\sigma^{(h)}_{d}\\big), \\\\  \nG \\mid H, d &\\sim \\mathrm{Normale}\\!\\Big(\\alpha_{d} + \\beta_{d}\\,\\log(1+H),\\ \\sigma_g\\Big).  \n\\end{aligned}  \n\\]\nGiustificazione delle scelte modellistiche:\n\nla distribuzione lognormale per \\(H\\) garantisce valori non negativi e cattura l’asimmetria tipicamente osservata nella distribuzione dei tempi di studio;\n\nla relazione tra \\(G\\) e \\(H\\) è modellata in modo da riflettere rendimenti marginali decrescenti: l’effetto delle ore di studio sul voto è positivo ma sublineare, come suggerito dal termine \\(\\log(1+H)\\);\n\ni parametri \\(\\theta = (\\mu^{(h)}_{1:3}, \\sigma^{(h)}_{1:3}, \\alpha_{1:3}, \\beta_{1:3}, \\sigma_g)\\) vengono stimati a partire da dati storici (ad esempio, registri di 300 studenti dell’anno precedente, comprendenti metodo di studio adottato, ore dedicate e voto ottenuto).\n\n3. Specificazione della funzione di utilità.\nVogliamo un numero unico che riassuma quanto è “buona” una certa combinazione di risultati: voto all’esame \\(g\\) (0–100) e ore di studio \\(h\\) (≥ 0). L’idea è premiare voti più alti e penalizzare più ore.\nUna scelta semplice è:\n\\[\nU(g,h;\\lambda) \\;=\\; g \\;-\\; \\lambda\\,h, \\qquad \\lambda \\ge 0.\n\\]\n\n\n\\(U\\) è l’utilità: più è grande, meglio è.\n\n\\(g\\) è il voto.\n\n\\(h\\) sono le ore di studio.\n\n\\(\\lambda\\) dice quanto “vale” un’ora di studio in punti di voto (cioè quanti punti sei disposto a “barattare” per risparmiare 1 ora).\n\nCome leggere \\(\\lambda\\):\n\n\n\\(\\lambda = 0\\): il tempo non pesa. Conta solo alzare il voto.\n\n\\(\\lambda = 1\\): 1 ora costa 1 punto. Risparmiare 3 ore vale come guadagnare 3 punti.\n\n\\(\\lambda = 0.5\\): 2 ore costano 1 punto. Risparmiare 2 ore “vale” come +1 punto.\n\n\\(\\lambda\\) grande (es. 2): il tempo è molto prezioso: 1 ora “vale” 2 punti.\n\n\nIn pratica, \\(\\lambda\\) fissa il tasso di scambio tra voto e ore. È una manopola che l’utente (studente/docente) sceglie per dire quanto pesa la fatica/tempo rispetto al voto.\n\nEsempi.\nCon \\(\\lambda=0.5\\) (2 ore ≈ 1 punto):\n\nPiano A: \\(g=88\\), \\(h=28\\) ⇒ \\(U=88-0.5\\cdot28=88-14=74\\)\n\nPiano B: \\(g=85\\), \\(h=20\\) ⇒ \\(U=85-0.5\\cdot20=85-10=75\\) → B è preferito (75 &gt; 74): qualche punto in meno, ma molte ore risparmiate.\n\nSe \\(\\lambda=0\\) (il tempo non conta):\n\nA: \\(U=88\\) ; B: \\(U=85\\) → A vince (conta solo il voto).\n\n4. Scelta della decisione ottimale.\nLa decisione bayesiana ottimale \\(d^*\\) è quella che massimizza l’utilità attesa predittiva:\n\\[  \nd^* = \\arg\\max_{k \\in \\{1,2,3\\}} \\mathbb{E}\\!\\left[U(G, H; \\lambda) \\mid d = k, \\text{dati}\\right].  \n\\]\nIn un contesto bayesiano, tale valore atteso viene calcolato integrando sia sull’incertezza parametrica (distribuzione a posteriori dei parametri) sia sulla variabilità predittiva degli esiti. Operativamente, questa integrazione è implementata mediante simulazioni dalla distribuzione predittiva posteriore.",
    "crumbs": [
      "Decisioni",
      "<span class='chapter-number'>83</span>  <span class='chapter-title'>Analisi delle decisioni</span>"
    ]
  },
  {
    "objectID": "chapters/decision_analysis/01_study_method.html#esempio-concreto-tre-metodi-di-studio",
    "href": "chapters/decision_analysis/01_study_method.html#esempio-concreto-tre-metodi-di-studio",
    "title": "83  Analisi delle decisioni",
    "section": "\n83.2 Esempio concreto: tre metodi di studio",
    "text": "83.2 Esempio concreto: tre metodi di studio\nImmaginiamo di avere dati dell’anno scorso (per ogni studente: metodo usato, ore totali, voto). Con Stan stimiamo \\(p(H,G\\mid d,\\text{dati})\\) come segue:\n\nModello generativo \\(H\\mid d \\sim \\text{Lognormal}(\\mu^{(h)}_{d},\\sigma^{(h)}_{d})\\) \\(G\\mid H,d \\sim \\text{Normal}(\\alpha_d + \\beta_d \\log(1+H),\\sigma_g)\\)\nUtilità \\(U(G,H;\\lambda) = G - \\lambda H\\)\n\nCalcolo dell’utilità attesa (schema Monte Carlo): per molti campioni \\(\\theta^{(s)}\\sim p(\\theta\\mid \\text{dati})\\):\n\ngeneriamo \\(H^{(s)}\\sim p(H\\mid d=k,\\theta^{(s)})\\)\n\ngeneriamo \\(G^{(s)}\\sim p(G\\mid H^{(s)}, d=k, \\theta^{(s)})\\)\n\ncalcoliamo \\(U^{(s)}_k=U(G^{(s)},H^{(s)};\\lambda)\\) L’utilità attesa per il metodo \\(k\\) è la media \\(\\frac{1}{S}\\sum_s U^{(s)}_k\\). La decisione ottimale è il metodo con media più alta.",
    "crumbs": [
      "Decisioni",
      "<span class='chapter-number'>83</span>  <span class='chapter-title'>Analisi delle decisioni</span>"
    ]
  },
  {
    "objectID": "chapters/decision_analysis/01_study_method.html#nota-pratica-su-stan",
    "href": "chapters/decision_analysis/01_study_method.html#nota-pratica-su-stan",
    "title": "83  Analisi delle decisioni",
    "section": "\n83.3 Nota pratica su Stan",
    "text": "83.3 Nota pratica su Stan\n\nnel blocco model si specificano le due componenti \\(H\\mid d\\) e \\(G\\mid H,d\\);\nnel blocco functions si definisce \\(U(g,h;\\lambda)\\);\nnel blocco generated quantities si generano, per ciascun metodo, una coppia \\((\\tilde H,\\tilde G)\\) e la corrispondente utilità util[k]. La media posteriore di util[k] approssima l’utilità attesa del metodo \\(k\\). Confrontando queste medie si ottiene la decisione.\n\nNelle sezioni successive mostreremo il codice Stan minimale e uno script R che: i) stima il modello su dati simulati/reali, ii) calcola l’utilità attesa per i tre metodi al variare di \\(\\lambda\\), iii) visualizza la distribuzione predittiva dell’utilità e la probabilità che ciascun metodo sia ottimale.\n\n83.3.1 Simulazione dei dati\n\nset.seed(123)\n\n# --- 1) Setup ---\nN &lt;- 300\nmethod_names &lt;- c(\"classico\",\"AI\",\"gruppo\")\nd &lt;- sample(1:3, N, replace = TRUE)\n\n# --- 2) Parametri \"di mondo\" più distanzianti ma plausibili ---\n# Ore (H) ~ Lognormal(mu_h, sigma_h)\n#  - classico: poche ore\n#  - AI: ore moderate\n#  - gruppo: molte ore, più variabile\nmu_h_true    &lt;- log(c(8,   12,  16))   # mediane circa: 8, 12, 16 ore\nsigma_h_true &lt;- c(0.30, 0.40, 0.50)\n\n# Voto G | H, d ~ Normal(alpha_d + beta_d * log1p(H), sigma_g)\n#  - AI: rendimento migliore (alpha e beta più alti)\n#  - gruppo: rendimento buono ma \"caro\" in ore\n#  - classico: rendimento più basso ma meno ore\nalpha_true    &lt;- c(55,  64,  61)\nbeta_true     &lt;- c(5.5, 8.0, 6.5)\nsigma_g_true  &lt;- 7\n\n# Costo orario in punti-voto: leggermente più alto per aumentare la separazione\nlambda &lt;- 0.65\n\n# --- 3) Simula ore e voti ---\nh  &lt;- rlnorm(N, meanlog = mu_h_true[d], sdlog = sigma_h_true[d])\nmu &lt;- alpha_true[d] + beta_true[d] * log1p(h)\ng  &lt;- rnorm(N, mu, sigma_g_true)\ng  &lt;- pmin(pmax(g, 0), 100)  # vincola in [0,100]\n\n\n# --- 4)  Controllo rapido: utilità \"vera\" per vedere la separazione ---\nu_true &lt;- g - lambda * h\ndf_sim &lt;- data.frame(method = factor(method_names[d], levels = method_names),\n                     g = g, h = h, u = u_true)\n\n# Densità utilità per metodo (controllo pre-Stan)\nggplot(df_sim, aes(x = u, fill = method)) +\n  geom_density(alpha = 0.35) +\n  labs(x = \"Utilità (G - λ H)\", y = \"Densità\",\n       title = \"Controllo simulazione: utilità 'vera' per metodo\") \n\n\n\n\n\n\n\n\n# --- 5) Prepara i dati per Stan ---\nstan_data &lt;- list(N = N, d = as.integer(d), h = h, g = g, lambda = lambda)\nglimpse(stan_data)\n#&gt; List of 5\n#&gt;  $ N     : num 300\n#&gt;  $ d     : int [1:300] 3 3 3 2 3 2 2 2 3 1 ...\n#&gt;  $ h     : num [1:300] 41.4 22.8 23.1 20.7 12 ...\n#&gt;  $ g     : num [1:300] 83.9 85.5 84 93.5 70.5 ...\n#&gt;  $ lambda: num 0.65\n\n\n83.3.2 Definizione del modello Stan\n\nstancode &lt;- \"\nfunctions {\n  real U(real g, real h, real lambda) {\n    return g - lambda * h;\n  }\n}\ndata {\n  int&lt;lower=0&gt; N;                     // numero osservazioni\n  array[N] int&lt;lower=1, upper=3&gt; d;   // decisione osservata: 1=classico, 2=AI, 3=gruppo\n  vector&lt;lower=0&gt;[N] h;               // ore osservate\n  vector&lt;lower=0, upper=100&gt;[N] g;    // voto osservato (clippato 0..100 a valle)\n  real&lt;lower=0&gt; lambda;               // costo orario in punti-voto\n}\nparameters {\n  // ore ~ lognormal per metodo\n  vector[3] mu_h;                     // location log(ore) per metodo\n  vector&lt;lower=0&gt;[3] sigma_h;         // scale log(ore) per metodo\n\n  // voto | (h, metodo) ~ Normal\n  vector[3] alpha;                    // intercetta per metodo\n  vector[3] beta;                     // pendenza su log1p(h) per metodo\n  real&lt;lower=0&gt; sigma_g;              // sd residua del voto\n}\nmodel {\n  // Priors debolmente informativi\n  mu_h ~ normal(log(10), 1);  // ore tipiche ~ e^N(log(10),1) ≈ 10 ore medie\n  sigma_h ~ normal(0, 0.5);  // &gt;0; log-sd moderata\n\n  alpha ~ normal(60, 20);  // voto tipico ~60 (ampio)\n  beta ~ normal(5, 5);   // più ore =&gt; voto più alto (a priori)\n  sigma_g ~ student_t(3, 0, 10);  // rumore voto\n\n  // Likelihood\n  for (n in 1:N) {\n    h[n] ~ lognormal(mu_h[d[n]], sigma_h[d[n]]);\n    g[n] ~ normal(alpha[d[n]] + beta[d[n]] * log1p(h[n]), sigma_g);\n  }\n}\ngenerated quantities {\n  // utilità predittiva una-estrazione per ciascun metodo \n  array[3] real util;\n  array[3] real g_tilde;\n  array[3] real h_tilde;\n\n  for (k in 1:3) {\n    h_tilde[k] = lognormal_rng(mu_h[k], sigma_h[k]);\n    real mu_g  = alpha[k] + beta[k] * log1p(h_tilde[k]);\n    g_tilde[k] = normal_rng(mu_g, sigma_g);\n    util[k]    = U(g_tilde[k], h_tilde[k], lambda);\n  }\n}\n\"\n\nNel blocco functions di Stan, definiamo una funzione personalizzata U che quantifica l’utilità di un esito, combinando voto (g) e ore di studio (h) in un unico indice scalare:\nreal U(real g, real h, real lambda) {\n  return g - lambda * h;\n}\nParametri:\n\n\ng: Voto d’esame (scala 0–100). Valori più alti indicano migliori risultati.\n\n\nh: Ore di studio dedicate. Valori più alti implicano un maggior “costo” temporale.\n\n\nlambda: Coefficiente che esprime il trade-off tra voto e tempo (es. λ = 0.5 ⇒ 2 ore “valgono” 1 punto di voto).\n\nInterpretazione:\nLa funzione implementa il modello lineare \\(U(g, h) = g - \\lambda h\\) dove g (voto) contribuisce positivamente all’utilità e h (ore) contribuiscono negativamente, ponderate da lambda.\nIl blocco model lega i dati osservati ai parametri del modello:\nfor (n in 1:N) {\n  h[n] ~ lognormal(mu_h[d[n]], sigma_h[d[n]]);  // Ore ~ Lognormale\n  g[n] ~ normal(alpha[d[n]] + beta[d[n]] * log1p(h[n]), sigma_g);  // Voto ~ Normale\n}\nSpiegazione:\n\nOre di studio (h):\n\nModellate come lognormali per garantire positività (h &gt; 0) e catturare asimmetria (coda lunga a destra).\n\nParametri specifici per metodo d[n]:\n\n\nmu_h[d[n]]: Media logaritmica.\n\n\nsigma_h[d[n]]: Deviazione standard logaritmica.\n\n\n\n\nVoto (g):\n\nModellato come normale con media dipendente dalle ore:\n\n\nalpha[d[n]]: Voto base (intercetta).\n\n\nbeta[d[n]]: Effetto marginale delle ore (trasformate con log1p per rendimenti decrescenti).\n\n\n\n\nsigma_g: Variabilità residua (comune a tutti i metodi).\n\n\n\nNota:\n\n\nlog1p(h[n]) equivale a \\(\\log(1 + h)\\) e garantisce un effetto positivo ma decrescente delle ore sul voto.\n\nIl blocco generated quantities genera scenari futuri e calcola l’utilità per ciascun metodo:\nfor (k in 1:3) {\n  h_tilde[k] = lognormal_rng(mu_h[k], sigma_h[k]);          // 1. Simula ore\n  real mu_g = alpha[k] + beta[k] * log1p(h_tilde[k]);      // 2. Calcola voto atteso\n  g_tilde[k] = normal_rng(mu_g, sigma_g);                  // 3. Simula voto\n  util[k] = U(g_tilde[k], h_tilde[k], lambda);             // 4. Calcola utilità\n}\nPassaggi chiave:\n\nSimulazione delle ore (h_tilde):\n\nCampionamento da una lognormale con parametri stimati per il metodo k.\n\n\n\nCalcolo del voto atteso (mu_g):\n\nUsa la relazione stimata tra ore e voto (lineare in \\(\\log(1+h)\\)).\n\n\n\nSimulazione del voto (g_tilde):\n\nCampionamento da una normale centrata su mu_g con variabilità sigma_g.\n\n\n\nCalcolo dell’utilità (util[k]):\n\nApplica la funzione U per valutare lo scenario simulato.\n\n\n\nPropagazione dell’incertezza:\n\nOgni iterazione MCMC usa parametri diversi (riflettendo l’incertezza posteriore).\n\nLa variabilità intrinseca di h_tilde e g_tilde cattura l’eterogeneità negli esiti.\n\nI campioni generati in generated quantities permettono di:\n\nStimare l’utilità attesa per metodo:\n\nMedia posteriore di util[k] (es. mean(util[1]) vs mean(util[2])).\n\n\n\nValutare la probabilità di optimalità:\n\nFrequenza con cui util[k] è il massimo tra i 3 metodi.\n\n\n\nAnalizzare distribuzioni predittive:\n\nDistribuzioni di h_tilde, g_tilde, e util per confrontare metodi.\n\n\n\n83.3.3 Compilazione ed esecuzione del modello\nCompiliamo il modello Stan:\n\nstanmod &lt;- cmdstan_model(\n  write_stan_file(stancode),\n  compile = TRUE\n)\n\nEseguiamo il campionamento MCMC:\n\nfit &lt;- stanmod$sample(\n  data = stan_data,\n  seed = 2025,\n  chains = 4, parallel_chains = 4,\n  iter_warmup = 1000, iter_sampling = 2000,\n  refresh = 200\n)\n\nRiepilogo dei parametri principali:\n\nprint(fit$summary(c(\"mu_h\",\"sigma_h\",\"alpha\",\"beta\",\"sigma_g\")))\n#&gt; # A tibble: 13 × 10\n#&gt;    variable    mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n#&gt;    &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt;  1 mu_h[1]     2.06   2.06  0.03  0.03  2.01  2.11  1.00  8799.83  6022.47\n#&gt;  2 mu_h[2]     2.42   2.42  0.05  0.05  2.35  2.50  1.00  9771.43  5748.16\n#&gt;  3 mu_h[3]     2.74   2.74  0.05  0.05  2.67  2.82  1.00  8858.07  5913.96\n#&gt;  4 sigma_h[1]  0.31   0.31  0.02  0.02  0.28  0.34  1.00  9632.06  5815.07\n#&gt;  5 sigma_h[2]  0.47   0.47  0.03  0.03  0.41  0.52  1.00  8735.26  5292.25\n#&gt;  6 sigma_h[3]  0.46   0.46  0.04  0.03  0.41  0.52  1.00 10539.11  5879.37\n#&gt;  7 alpha[1]   55.72  55.68  4.63  4.64 48.19 63.27  1.00  5453.43  5227.55\n#&gt;  8 alpha[2]   64.05  64.01  3.81  3.84 57.69 70.27  1.00  5815.79  5159.80\n#&gt;  9 alpha[3]   54.79  54.80  4.38  4.36 47.52 62.10  1.00  5614.95  5345.32\n#&gt; 10 beta[1]     5.20   5.22  2.10  2.10  1.79  8.62  1.00  5438.11  5194.19\n#&gt; 11 beta[2]     7.76   7.76  1.49  1.50  5.31 10.24  1.00  5798.74  5291.50\n#&gt; 12 beta[3]     8.58   8.56  1.54  1.52  6.05 11.14  1.00  5508.91  4994.72\n#&gt; 13 sigma_g     6.73   6.72  0.28  0.28  6.28  7.20  1.00  8493.76  5783.98\n\nEstrai utilità generate:\n\nmethod_names &lt;- c(\"classico\", \"AI\", \"gruppo\")\n\nUmat &lt;- fit$draws(variables = \"util\", format = \"draws_matrix\") |&gt; \n  as.matrix()\n# Colonne sono \"util[1]\",\"util[2]\",\"util[3]\"\ncolnames(Umat) &lt;- method_names\n\nUtilità attese e metodo migliore:\n\nU_means &lt;- colMeans(Umat)\nU_means\n#&gt; classico       AI   gruppo \n#&gt;    61.70    75.29    67.70\nbest_method &lt;- names(U_means)[which.max(U_means)]\ncat(\"\\nMetodo con utilità attesa maggiore (lambda =\", stan_data$lambda, \"):\",\n    best_method, \"\\n\")\n#&gt; \n#&gt; Metodo con utilità attesa maggiore (lambda = 0.65 ): AI\n\nProbabilità che ciascun metodo sia ottimale (per draw):\n\nbest_idx &lt;- max.col(Umat, ties.method = \"first\")\np_opt &lt;- prop.table(table(factor(best_idx, levels = 1:3, labels = method_names)))\np_opt\n#&gt; \n#&gt; classico       AI   gruppo \n#&gt;  0.04938  0.74562  0.20500\n\nRiepilogo e grafico delle distribuzioni predittive di utilità:\n\nutil_long &lt;- as.data.frame(Umat) |&gt;\n  tibble::rownames_to_column(var = \".draw\") |&gt;\n  mutate(.draw = as.integer(.draw)) |&gt;\n  pivot_longer(cols = all_of(method_names),\n               names_to = \"method\", values_to = \"util\")\n\nutil_sum &lt;- util_long |&gt;\n  group_by(method) |&gt;\n  summarize(mean = mean(util),\n            sd   = sd(util),\n            q05  = quantile(util, 0.05),\n            q50  = median(util),\n            q95  = quantile(util, 0.95),\n            .groups = \"drop\")\nutil_sum\n#&gt; # A tibble: 3 × 6\n#&gt;   method    mean    sd   q05   q50   q95\n#&gt;   &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 AI        75.3  6.88  63.8  75.4  86.6\n#&gt; 2 classico  61.7  6.78  50.5  61.7  73.0\n#&gt; 3 gruppo    67.7  7.17  55.7  67.8  79.0\n\n\nggplot(util_long, aes(x = util, fill = method)) +\n  geom_density(alpha = 0.4) +\n  labs(x = \"Utilità predittiva (per draw)\",\n       y = \"Densità\",\n       title = \"Confronto delle distribuzioni predittive di utilità\")\n\n\n\n\n\n\n\nNel grafico, l’asse x mostra l’utilità predittiva calcolata per ogni draw MCMC, cioè per ogni scenario simulato nel blocco generated quantities del modello.\nQuesti valori derivano dalla formula:\n\\[\nU = G - \\lambda H ,\n\\]\ndove:\n\n\n\\(G\\) = voto simulato (0–100)\n\n\\(H\\) = ore di studio simulate (\\(\\ge 0\\))\n\n\\(\\lambda\\) = costo di un’ora di studio espresso in punti di voto\n\nL’unità di misura dell’utilità è quindi punti di voto “netti”, già corretti per il “costo” del tempo di studio.\nInterpretazione intuitiva:\n\n\nUtilità alta → voto alto con poche ore, o tempo poco penalizzato dal valore di \\(\\lambda\\).\n\nUtilità bassa → voto basso e/o molte ore, fortemente penalizzate da \\(\\lambda\\).\n\nOgni punto della distribuzione corrisponde a:\n\nUn set di parametri campionato dalla distribuzione a posteriori \\((\\mu_h, \\sigma_h, \\alpha, \\beta, \\sigma_g)\\)\n\nUn paio di valori \\((H, G)\\) simulati da quel set di parametri\n\nIn questo modo la distribuzione riflette sia l’incertezza sui parametri sia la variabilità naturale degli esiti.\nCosa osservare nel grafico:\n\n\nAmpiezza: quanta incertezza/variabilità c’è nell’utilità per quel metodo\n\nPosizione media: utilità attesa → più a destra = metodo mediamente più vantaggioso\n\nSovrapposizione: quanta incertezza in comune → più sovrapposizione = scelta meno netta\n\nA parità di ore di studio.\nSe confrontiamo i metodi mantenendo costanti le ore di studio (\\(H\\)), le differenze nell’utilità dipendono solo dal voto atteso (\\(G\\)) di ciascun metodo:\n\nA parità di tempo, un voto più alto → utilità maggiore\nSe due metodi danno lo stesso voto medio, ma uno richiede più ore, la penalizzazione \\(-\\lambda H\\) riduce la sua utilità\n\nEsempio numerico\nSupponiamo \\(\\lambda = 0.5\\) (1 punto di voto “vale” 2 ore di studio) e \\(H = 12\\) ore per tutti i metodi:\n\n\nMetodo\nVoto atteso \\(G\\)\n\nOre \\(H\\)\n\nUtilità \\(U = G - \\lambda H\\)\n\n\n\n\nClassico\n78\n12\n\\(78 - 0.5\\cdot 12 = 72\\)\n\n\nAI\n82\n12\n\\(82 - 0.5\\cdot 12 = 76\\)\n\n\nGruppo\n79\n12\n\\(79 - 0.5\\cdot 12 = 73\\)\n\n\n\nQui l’AI ottiene utilità maggiore solo grazie al voto più alto, a parità di ore. Se invece l’AI richiedesse più ore (es. 15), con lo stesso voto 82:\n\\[\nU_{\\text{AI}} = 82 - 0.5 \\cdot 15 = 74.5\n\\]\nresterebbe superiore al “classico” (72), ma con un margine ridotto.\nGrafico a barre per ore fissate\nNel grafico seguente, fissiamo \\(H\\) a valori specifici (8, 12, 16 ore) e confrontiamo l’utilità attesa per ogni metodo. Questo evidenzia come, a ore costanti, la differenza di utilità dipenda solo dal voto atteso:\n\nmethod_names &lt;- c(\"classico\",\"AI\",\"gruppo\")\nlambda &lt;- stan_data$lambda  \n\nsum_ab &lt;- fit$summary(variables = c(\"alpha\",\"beta\")) %&gt;% select(variable, mean)\nalpha_hat &lt;- sum_ab %&gt;% filter(str_detect(variable, \"^alpha\\\\[\")) %&gt;% arrange(variable) %&gt;% pull(mean)\nbeta_hat  &lt;- sum_ab %&gt;% filter(str_detect(variable, \"^beta\\\\[\")) %&gt;% arrange(variable) %&gt;% pull(mean)\n\nfixed_H &lt;- c(8, 12, 16)\n\ndf_H &lt;- expand.grid(method = 1:3, H = fixed_H) %&gt;%\n  as_tibble() %&gt;%\n  mutate(\n    method_name = factor(method_names[method], levels = method_names),\n    G_hat = alpha_hat[method] + beta_hat[method] * log1p(H),\n    U_hat = G_hat - lambda * H\n  )\n\nggplot(df_H, aes(x = factor(H), y = U_hat, fill = method_name)) +\n  geom_col(position = position_dodge(width = 0.75)) +\n  labs(x = \"Ore fissate (H)\",\n       y = \"Utilità attesa U = Ĝ(H) - λ·H\",\n       fill = \"Metodo\",\n       title = \"A parità di ore di studio: confronto dell'utilità attesa\") \n\n\n\n\n\n\n\nA parità di voto.\nMostriamo, per alcuni target \\(G_0\\) (es. 75, 80, 85), quante ore servono a ciascun metodo e l’utilità corrispondente \\(U = G_0 - \\lambda H^\\*\\). Vince il metodo che richiede meno ore (penalità minore).\n\n\nA voto fissato, la differenza di utilità deriva solo dalle ore richieste: meno ore ⇒ penalità minore ⇒ utilità più alta.\nIl grafico rende visibile l’efficienza del metodo: per lo stesso traguardo \\(G_0\\), quale metodo “costa” meno tempo?\n\n\n# Estrai tutti i draw di alpha[ ] e beta[ ]\npars &lt;- c(paste0(\"alpha[\",1:3,\"]\"), paste0(\"beta[\",1:3,\"]\"))\ndraws &lt;- fit$draws(variables = pars, format = \"draws_matrix\") |&gt; as.matrix()\n\nG_targets &lt;- c(75, 80, 85)\nmethod_names &lt;- c(\"classico\",\"AI\",\"gruppo\")\n\n# Funzione: ore richieste H* per un draw e un metodo\nHreq_fun &lt;- function(G0, alpha, beta){\n  pmax(exp((G0 - alpha)/beta) - 1, 0)\n}\n\nout &lt;- lapply(G_targets, function(G0){\n  # per ogni draw, calcola H* dei 3 metodi\n  Hreq_mat &lt;- sapply(1:3, function(k){\n    alpha_k &lt;- draws[, paste0(\"alpha[\",k,\"]\")]\n    beta_k  &lt;- draws[, paste0(\"beta[\",k,\"]\")]\n    Hreq_fun(G0, alpha_k, beta_k)\n  })\n  colnames(Hreq_mat) &lt;- method_names\n  as_tibble(Hreq_mat) |&gt; mutate(G0 = G0, .draw = row_number())\n}) |&gt; bind_rows()\n\n# Probabilità che AI richieda meno ore degli altri (per ogni G0)\nprob_AI_best &lt;- out |&gt;\n  group_by(G0) |&gt;\n  summarize(\n    p_AI_lt_classico = mean(AI &lt; classico),\n    p_AI_lt_gruppo   = mean(AI &lt; gruppo),\n    p_AI_best        = mean(AI == pmin(AI, classico, gruppo)),\n    .groups = \"drop\"\n  )\nprob_AI_best\n#&gt; # A tibble: 3 × 4\n#&gt;      G0 p_AI_lt_classico p_AI_lt_gruppo p_AI_best\n#&gt;   &lt;dbl&gt;            &lt;dbl&gt;          &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1    75            0.993          0.999     0.992\n#&gt; 2    80            0.993          1         0.993\n#&gt; 3    85            0.993          1.000     0.993\n\n# Riassunto delle H* (mediana e IQR)\nHreq_summary &lt;- out |&gt;\n  pivot_longer(all_of(method_names), names_to = \"metodo\", values_to = \"Hreq\") |&gt;\n  group_by(G0, metodo) |&gt;\n  summarize(mediana = median(Hreq),\n            q25 = quantile(Hreq, .25),\n            q75 = quantile(Hreq, .75),\n            .groups = \"drop\")\nHreq_summary\n#&gt; # A tibble: 9 × 5\n#&gt;      G0 metodo   mediana    q25    q75\n#&gt;   &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1    75 AI          3.10   2.43   3.69\n#&gt; 2    75 classico   39.2   28.0   68.6 \n#&gt; 3    75 gruppo      9.54   8.68  10.4 \n#&gt; 4    80 AI          6.81   6.11   7.41\n#&gt; 5    80 classico  103.    60.2  253.  \n#&gt; 6    80 gruppo     17.9   16.8   19.1 \n#&gt; 7    85 AI         13.8   13.0   14.9 \n#&gt; 8    85 classico  268.   129.   923.  \n#&gt; 9    85 gruppo     32.9   29.8   36.9\n\n# Versione con mediana per draw (più stabile)\nEU_G &lt;- out |&gt;\n  pivot_longer(all_of(method_names), names_to = \"metodo\", values_to = \"Hreq\") |&gt;\n  mutate(U = G0 - stan_data$lambda * Hreq) |&gt;\n  group_by(G0, metodo) |&gt;\n  summarize(U_med = median(U), .groups = \"drop\")\n\nEU_G\n#&gt; # A tibble: 9 × 3\n#&gt;      G0 metodo   U_med\n#&gt;   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;\n#&gt; 1    75 AI        73.0\n#&gt; 2    75 classico  49.5\n#&gt; 3    75 gruppo    68.8\n#&gt; 4    80 AI        75.6\n#&gt; 5    80 classico  13.1\n#&gt; 6    80 gruppo    68.4\n#&gt; 7    85 AI        76.0\n#&gt; 8    85 classico -89.2\n#&gt; 9    85 gruppo    63.6\n\n\nmethod_names &lt;- c(\"classico\",\"AI\",\"gruppo\")\n\n# Riepilogo H* (mediana e IQR) già calcolato in 'Hreq_summary'\n# Se non esiste ancora, ricrealo da 'out':\nHreq_summary &lt;- out |&gt;\n  pivot_longer(all_of(method_names), names_to = \"metodo\", values_to = \"Hreq\") |&gt;\n  mutate(metodo = factor(metodo, levels = method_names)) |&gt;\n  group_by(G0, metodo) |&gt;\n  summarize(mediana = median(Hreq),\n            q25 = quantile(Hreq, .25),\n            q75 = quantile(Hreq, .75),\n            .groups = \"drop\")\n\n# (1) Barre: ore necessarie H* per raggiungere G0 (mediana + IQR)\nggplot(Hreq_summary, aes(x = factor(G0), y = mediana, fill = metodo)) +\n  geom_col(position = position_dodge(width = 0.8)) +\n  labs(x = \"Voto fissato (G0)\",\n       y = expression(paste(\"Ore necessarie \", H^\"*\")),\n       fill = \"Metodo\",\n       title = \"A parità di voto: ore richieste per raggiungere G0\")\n\n\n\n\n\n\n\n\nLe barre mostrano la mediana su tutti i draw MCMC (incertezza parametrica).\nA voto fissato \\(G_0\\), vince il metodo con H più bassa (meno ore) e quindi utilità residua più alta.",
    "crumbs": [
      "Decisioni",
      "<span class='chapter-number'>83</span>  <span class='chapter-title'>Analisi delle decisioni</span>"
    ]
  },
  {
    "objectID": "chapters/decision_analysis/01_study_method.html#limiti-della-funzione-di-utilità-lineare-e-modelli-avanzati",
    "href": "chapters/decision_analysis/01_study_method.html#limiti-della-funzione-di-utilità-lineare-e-modelli-avanzati",
    "title": "83  Analisi delle decisioni",
    "section": "\n83.4 Limiti della funzione di utilità lineare e modelli avanzati",
    "text": "83.4 Limiti della funzione di utilità lineare e modelli avanzati\nLa funzione di utilità lineare\n\\[\nU(g,h;\\lambda) = g - \\lambda h, \\quad \\lambda \\geq 0  \n\\]\nrappresenta un modello di riferimento per la sua semplicità e trasparenza interpretativa (“1 ora di studio equivale a λ punti di voto”). Tuttavia, questa formulazione poggia su due ipotesi restrittive:\n\n\nLinearità nel voto (g): il valore marginale di un punto è costante (es. 60→61 ≡ 90→91).\n\n\nLinearità nel tempo (h): il costo psicologico di un’ora aggiuntiva è indipendente dal carico di studio accumulato.\n\nQueste assunzioni possono risultare inadatte in contesti realistici. Esploriamo quindi alcune possibili estensioni del modello.\n\n83.4.1 Come rendere il modello più realistico\n\n\nUtilità non lineare nel voto\n\n\nRendimenti decrescenti: un aumento da 60 a 65 è più “prezioso” che da 90 a 95 → funzioni come log(g) o √g.\n\nSoglie: sotto un certo voto minimo il risultato è inaccettabile, anche se richiede poco studio.\n\n\n\nUtilità non lineare nel tempo\n\n\nFatica crescente: dopo molte ore, ogni ora extra “pesa” di più.\nModelli con potenze (h², h¹·⁵) per catturare questo effetto.\n\n\n\nRiferimenti e obiettivi personali\n\nUn voto sotto il proprio target pesa più di quanto un voto sopra dia soddisfazione (avversione alle perdite).\n\n\n\nRischio e incertezza\n\nSe i risultati sono incerti, non basta guardare la media: si può penalizzare la variabilità o ottimizzare scenari “pessimi” (es. percentile più basso atteso).\n\n\n\nPreferenze diverse tra individui\n\nStudenti con lavori part-time o carichi diversi possono avere λ personali → modelli gerarchici permettono di stimare questa variabilità.\n\n\n\nIn sintesi,\n\nun ricercatore può iniziare a verificare il modello lineare per la sua chiarezza;\npoi verifica se i dati mostrano non linearità o effetti di rischio;\naggiunge complessità solo se serve, per migliorare realismo e capacità predittiva.",
    "crumbs": [
      "Decisioni",
      "<span class='chapter-number'>83</span>  <span class='chapter-title'>Analisi delle decisioni</span>"
    ]
  },
  {
    "objectID": "chapters/decision_analysis/01_study_method.html#riflessioni-conclusive",
    "href": "chapters/decision_analysis/01_study_method.html#riflessioni-conclusive",
    "title": "83  Analisi delle decisioni",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo abbiamo visto come l’analisi decisionale bayesiana permetta di integrare in un unico quadro:\n\n\nprevisioni sugli esiti (distribuzione predittiva posteriore),\n\npreferenze esplicite (funzione di utilità),\n\ncriteri di scelta (massimizzazione dell’utilità attesa).\n\nPartendo da un modello semplice, con utilità lineare nel voto e nel tempo, abbiamo compreso come questa formulazione sia utile per introdurre i concetti fondamentali:\n\ntradurre in numeri la desiderabilità di un esito,\ncalcolare e confrontare utilità attese,\ntenere conto dell’incertezza nelle previsioni.\n\nAbbiamo poi discusso estensioni più realistiche, che possono catturare aspetti psicologici ed empirici complessi: rendimenti decrescenti, costi crescenti nel tempo, obiettivi personali, avversione al rischio e differenze individuali nei parametri.\nDal punto di vista pratico, il flusso di lavoro suggerito è:\n\n\nIniziare semplice: un modello lineare è trasparente e facile da comunicare.\n\nVerificare le assunzioni sui dati: se emergono non linearità o effetti di rischio, valutare modelli più ricchi.\n\nAggiungere complessità solo se necessaria, bilanciando realismo e interpretabilità.\n\nIl vantaggio dell’approccio bayesiano è la capacità di propagare l’incertezza — sia sui parametri sia sugli esiti — fino alla decisione finale. Ciò consente di quantificare non solo quale opzione è in media la migliore, ma anche quanto siamo sicuri di questa scelta.\nIn sintesi, l’analisi decisionale bayesiana non è solo uno strumento per “fare la scelta giusta”, ma un metodo per rendere esplicito, trasparente e verificabile il processo con cui valutiamo e confrontiamo le alternative in condizioni di incertezza.",
    "crumbs": [
      "Decisioni",
      "<span class='chapter-number'>83</span>  <span class='chapter-title'>Analisi delle decisioni</span>"
    ]
  },
  {
    "objectID": "chapters/decision_analysis/01_study_method.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/decision_analysis/01_study_method.html#informazioni-sullambiente-di-sviluppo",
    "title": "83  Analisi delle decisioni",
    "section": "Informazioni sull’ambiente di sviluppo",
    "text": "Informazioni sull’ambiente di sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] stringr_1.5.1         cmdstanr_0.9.0        pillar_1.11.0        \n#&gt;  [4] tinytable_0.11.0      patchwork_1.3.1       ggdist_3.3.3         \n#&gt;  [7] tidybayes_3.0.7       bayesplot_1.13.0      ggplot2_3.5.2        \n#&gt; [10] reliabilitydiag_0.2.1 priorsense_1.1.0      posterior_1.6.1      \n#&gt; [13] loo_2.8.0             rstan_2.32.7          StanHeaders_2.32.10  \n#&gt; [16] brms_2.22.0           Rcpp_1.1.0            conflicted_1.2.0     \n#&gt; [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [25] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.6         tidyselect_1.2.1     farver_2.1.2        \n#&gt;  [4] fastmap_1.2.0        TH.data_1.1-3        tensorA_0.36.2.1    \n#&gt;  [7] pacman_0.5.1         digest_0.6.37        estimability_1.5.1  \n#&gt; [10] timechange_0.3.0     lifecycle_1.0.4      processx_3.8.6      \n#&gt; [13] survival_3.8-3       magrittr_2.0.3       compiler_4.5.1      \n#&gt; [16] rlang_1.1.6          tools_4.5.1          utf8_1.2.6          \n#&gt; [19] yaml_2.3.10          data.table_1.17.8    knitr_1.50          \n#&gt; [22] labeling_0.4.3       bridgesampling_1.1-2 htmlwidgets_1.6.4   \n#&gt; [25] pkgbuild_1.4.8       curl_6.4.0           RColorBrewer_1.1-3  \n#&gt; [28] abind_1.4-8          multcomp_1.4-28      withr_3.0.2         \n#&gt; [31] purrr_1.1.0          grid_4.5.1           stats4_4.5.1        \n#&gt; [34] xtable_1.8-4         colorspace_2.1-1     inline_0.3.21       \n#&gt; [37] emmeans_1.11.2       scales_1.4.0         MASS_7.3-65         \n#&gt; [40] cli_3.6.5            mvtnorm_1.3-3        rmarkdown_2.29      \n#&gt; [43] generics_0.1.4       RcppParallel_5.1.10  cachem_1.1.0        \n#&gt; [46] splines_4.5.1        parallel_4.5.1       vctrs_0.6.5         \n#&gt; [49] V8_6.0.5             Matrix_1.7-3         sandwich_3.1-1      \n#&gt; [52] jsonlite_2.0.0       arrayhelpers_1.1-0   glue_1.8.0          \n#&gt; [55] ps_1.9.1             codetools_0.2-20     distributional_0.5.0\n#&gt; [58] lubridate_1.9.4      stringi_1.8.7        gtable_0.3.6        \n#&gt; [61] QuickJSR_1.8.0       htmltools_0.5.8.1    Brobdingnag_1.2-9   \n#&gt; [64] R6_2.6.1             rprojroot_2.1.0      evaluate_1.0.4      \n#&gt; [67] lattice_0.22-7       backports_1.5.0      memoise_2.0.1       \n#&gt; [70] broom_1.0.9          snakecase_0.11.1     rstantools_2.4.0    \n#&gt; [73] coda_0.19-4.1        gridExtra_2.3        nlme_3.1-168        \n#&gt; [76] checkmate_2.3.2      xfun_0.52            zoo_1.8-14          \n#&gt; [79] pkgconfig_2.0.3",
    "crumbs": [
      "Decisioni",
      "<span class='chapter-number'>83</span>  <span class='chapter-title'>Analisi delle decisioni</span>"
    ]
  },
  {
    "objectID": "chapters/decision_analysis/01_study_method.html#bibliografia",
    "href": "chapters/decision_analysis/01_study_method.html#bibliografia",
    "title": "83  Analisi delle decisioni",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., & Rubin, D. B. (2013). Bayesian Data Analysis (3rd ed.). Chapman; Hall/CRC.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "Decisioni",
      "<span class='chapter-number'>83</span>  <span class='chapter-title'>Analisi delle decisioni</span>"
    ]
  },
  {
    "objectID": "chapters/missing/01_mnar_stan.html",
    "href": "chapters/missing/01_mnar_stan.html",
    "title": "84  Dati mancanti in psicologia: identificare e modellare i casi MNAR con un approccio Bayesiano in Stan",
    "section": "",
    "text": "Introduzione\nIn questi casi, la probabilità che un dato sia osservato dipende dal valore vero non osservato. Questa situazione è definita MNAR – Missing Not At Random e, se ignorata, può produrre stime distorte dei parametri (ad esempio medie più basse del reale, effetti di regressione sottostimati). In pratica: si può concludere che un trattamento funziona quando in realtà non è così, o viceversa.\nIn questo capitolo:",
    "crumbs": [
      "Missing",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>Dati mancanti in psicologia: identificare e modellare i casi MNAR con un approccio Bayesiano in Stan</span>"
    ]
  },
  {
    "objectID": "chapters/missing/01_mnar_stan.html#introduzione",
    "href": "chapters/missing/01_mnar_stan.html#introduzione",
    "title": "84  Dati mancanti in psicologia: identificare e modellare i casi MNAR con un approccio Bayesiano in Stan",
    "section": "",
    "text": "In molte ricerche psicologiche, i dati mancanti non sono semplicemente “buchi” da riempire, ma possono essere la conseguenza diretta del fenomeno che vogliamo studiare. Questo significa che l’assenza di una risposta è essa stessa un dato psicologico. Ad esempio:\n\nnei questionari su temi sensibili (come ansia sociale, uso di sostanze, esperienze traumatiche) le persone con punteggi più elevati possono saltare più facilmente alcune domande per evitare disagio emotivo;\nnegli studi EMA (Ecological Momentary Assessment), i partecipanti possono rispondere meno quando sono di cattivo umore, sotto stress o in situazioni socialmente impegnative.\n\n\n\n\n\nrivedremo le principali tipologie di dati mancanti (MCAR, MAR, MNAR);\nvedremo come riconoscere un caso MNAR nella ricerca psicologica;\nimpareremo a costruire e stimare un modello Bayesiano in Stan per gestire dati MNAR.\n\n\n\n\n\n\n\nMCAR, MAR, MNAR: i tre meccanismi chiave\n\n\n\nQuando analizzi dati mancanti, è fondamentale capire perché mancano. Le principali categorie sono:\n\n\nMCAR (Missing Completely At Random): la probabilità che un dato manchi è indipendente sia dalle variabili osservate sia dal valore mancante.\n\n\nEsempio: in un questionario online, alcune risposte mancano a causa di un problema tecnico che interrompe la connessione.\n\n\n\nMAR (Missing At Random): la probabilità di mancanza dipende solo da variabili osservate (non dal valore mancante), una volta controllato per queste.\n\n\nEsempio: in un test di ansia, i partecipanti più anziani saltano alcune domande, ma conosciamo l’età di tutti.\n\n\n\nMNAR (Missing Not At Random): la probabilità di mancanza dipende dal valore vero mancante, anche dopo aver considerato le variabili osservate.\n\n\nEsempio: in un questionario su sintomi depressivi, chi è più depresso tende a non rispondere a domande su pensieri negativi.\n\n\n\nNota operativa: Ignorare un meccanismo MNAR può portare a stime distorte e a conclusioni errate, specialmente in studi clinici o longitudinali.",
    "crumbs": [
      "Missing",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>Dati mancanti in psicologia: identificare e modellare i casi MNAR con un approccio Bayesiano in Stan</span>"
    ]
  },
  {
    "objectID": "chapters/missing/01_mnar_stan.html#simulazione-di-dati-con-meccanismo-mnar",
    "href": "chapters/missing/01_mnar_stan.html#simulazione-di-dati-con-meccanismo-mnar",
    "title": "84  Dati mancanti in psicologia: identificare e modellare i casi MNAR con un approccio Bayesiano in Stan",
    "section": "\n84.1 Simulazione di dati con meccanismo MNAR",
    "text": "84.1 Simulazione di dati con meccanismo MNAR\nSupponiamo di voler misurare il punteggio di ansia sociale (\\(y\\)) in un campione di partecipanti. Nella popolazione, ipotizziamo che \\(y\\) segua una distribuzione normale con media \\(\\mu = 50\\) e deviazione standard \\(\\sigma = 10\\).\nPer semplificare i calcoli, standardizziamo la variabile:\n\\[\ny_z = \\frac{y - 50}{10} \\quad \\Rightarrow \\quad y_z \\sim \\mathcal{N}(0, 1)\n\\]\nOra modelliamo una situazione comune nella ricerca psicologica: le persone con ansia sociale più elevata tendono a evitare a rispondere al questionario, lasciando più risposte mancanti.\nIl comportamento di evitamento è formalizzato attraverso un modello di selezione (selection model) di tipo logistico, che specifica la probabilità condizionata di osservazione del dato nel modo seguente:\n\\[\n\\Pr(R_i = 1 \\mid y_i) = \\text{logit}^{-1}(\\alpha + \\beta\\, y_i) .\n\\tag{84.1}\\]\nDefinizione formale delle componenti del modello:\n\n\nVariabile di risposta latente:\\(R_i \\in \\{0,1\\}\\) è una variabile binaria latente che modella il processo di osservazione, dove:\n\n\n\\(R_i = 1\\) indica che l’osservazione \\(y_i\\) è osservabile (il partecipante ha fornito una risposta valida);\n\n\n\\(R_i = 0\\) denota un dato mancante (mancata risposta del partecipante).\n\n\n\nParametro \\(\\beta\\) e meccanismo di missingness:\nLa relazione tra \\(y_i\\) e \\(\\Pr(R_i = 1 \\mid y_i)\\) è governata dal parametro \\(\\beta\\):\n\nSe \\(\\beta &lt; 0\\): sussiste un meccanismo di missingness non ignorabile (MNAR) con dipendenza negativa monotona. Valori più elevati di \\(y_i\\) riducono la probabilità di osservazione, indicando un pattern di evitamento selettivo (es. partecipanti con sintomi di ansia sociale più severi tendono ad evitare di rispondere).\n\nSe \\(\\beta &gt; 0\\): il missingness è ancora MNAR, ma con dipendenza positiva monotona. Valori elevati di \\(y_i\\) aumentano la probabilità di osservazione (es. partecipanti con maggiore ansia sociale hanno maggiore propensione a rispondere).\n\nSe \\(\\beta = 0\\): la probabilità di osservazione è indipendente da \\(y_i\\), soddisfacendo l’ipotesi di Missing Completely at Random (MCAR).\n\n\n\nNota: l’esempio qui discusso riflette un tipico caso MNAR, in cui la probabilità di osservare il dato dipende direttamente dal valore vero della variabile di interesse.\nGeneriamo un dataset sintetico di \\(N\\) = 1000 unità statistiche, dove il meccanismo di missingness segue un modello di selezione logistico con parametri:\n\nintercetta (\\(\\alpha\\)) = 0,\neffetto della variabile risposta (\\(\\beta\\)) = -2.0.\n\n\nset.seed(1234)   \n\nN          &lt;- 1000\nalpha_true &lt;- 0\nbeta_true  &lt;- -2.0\n\ny_true &lt;- rnorm(N, 0, 1)\np_obs  &lt;- plogis(alpha_true + beta_true * y_true)\nR      &lt;- rbinom(N, 1, p_obs)\ny_obs  &lt;- ifelse(R == 1, y_true, NA_real_)\n\ntbl &lt;- tibble(y_true, R, y_obs, p_obs)\nmean(R)\n#&gt; [1] 0.501\nmean(is.na(y_obs))\n#&gt; [1] 0.499\n\n\n84.1.1 Analisi del bias indotto da MNAR\n\nsumm &lt;- tibble(\n  grandezza = c(\"Media\", \"Varianza\"),\n  vero      = c(mean(tbl$y_true), var(tbl$y_true)),\n  osservato = c(mean(tbl$y_obs, na.rm = TRUE), var(tbl$y_obs, na.rm = TRUE))\n)\nprint(summ)\n#&gt; # A tibble: 2 × 3\n#&gt;   grandezza    vero osservato\n#&gt;   &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 Media     -0.0266    -0.594\n#&gt; 2 Varianza   0.995      0.663\n\nI dati evidenziando una sottostima sistematica dovuta al meccanismo MNAR.\n\n84.1.2 Visualizzazione degli effetti di selezione\nVisualizziamo ora la probabilità di osservazione in funzione del valore vero e confrontiamo la distribuzione dei valori veri con quella dei valori osservati, escludendo i valori mancanti.\n\n# 1) Probabilità di osservazione in funzione del valore vero\np1 &lt;- ggplot(tbl, aes(x = y_true, y = p_obs)) +\n  geom_point(alpha = 0.20) +\n  geom_smooth(method = \"loess\", se = FALSE) +\n  labs(\n    title = \"MNAR: Pr(R=1 | y)\",\n    subtitle = \"All'aumentare di y, la probabilità di risposta diminuisce (beta_true &lt; 0)\",\n    x = \"y (vero, scala z)\", y = \"Pr(R=1 | y)\"\n  ) \n\n# 2) Distribuzione dei valori veri, con linea su media=0\np2 &lt;- ggplot(tbl, aes(x = y_true)) +\n  geom_histogram(aes(y = ..density..), bins = 30, alpha = 0.35) +\n  geom_density() +\n  geom_vline(xintercept = mean(tbl$y_true), linetype = 2) +\n  labs(\n    title = \"Distribuzione dei valori veri\",\n    subtitle = \"y_true ~ N(0, 1); linea tratteggiata = media campionaria\",\n    x = \"y (vero, scala z)\", y = \"Densità\"\n  ) \n\n# 3) Distribuzione dei valori osservati (cond. a R=1), con linea su media osservata\np3 &lt;- ggplot(filter(tbl, R == 1), aes(x = y_obs)) +\n  geom_histogram(aes(y = ..density..), bins = 30, alpha = 0.35) +\n  geom_density() +\n  geom_vline(xintercept = mean(tbl$y_obs, na.rm = TRUE), linetype = 2) +\n  labs(\n    title = \"Distribuzione dei valori osservati (R=1)\",\n    subtitle = \"Selezione MNAR: la forma/posizione può differire rispetto ai valori veri\",\n    x = \"y osservato\", y = \"Densità\"\n  ) \n\np1; p2; p3\n\n\n\n\n\n\nMNAR: probabilità di osservazione e distribuzioni ‘vero’ vs ‘osservato’.\n\n\n\n\n\n\n\n\nMNAR: probabilità di osservazione e distribuzioni ‘vero’ vs ‘osservato’.\n\n\n\n\n\n\n\n\nMNAR: probabilità di osservazione e distribuzioni ‘vero’ vs ‘osservato’.\n\n\n\nMessaggio chiave. La selezione MNAR fa sì che i dati osservati non rappresentino la popolazione: nei grafici si vede che la probabilità di osservazione diminuisce con y e che la distribuzione degli osservati è spostata rispetto a quella dei veri. Conseguenza: le analisi che ignorano il meccanismo (vedi Modello 1) tendono a stimare una media distorta e/o una varianza alterata.",
    "crumbs": [
      "Missing",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>Dati mancanti in psicologia: identificare e modellare i casi MNAR con un approccio Bayesiano in Stan</span>"
    ]
  },
  {
    "objectID": "chapters/missing/01_mnar_stan.html#modello-1-outcome-only-ignora-il-meccanismo",
    "href": "chapters/missing/01_mnar_stan.html#modello-1-outcome-only-ignora-il-meccanismo",
    "title": "84  Dati mancanti in psicologia: identificare e modellare i casi MNAR con un approccio Bayesiano in Stan",
    "section": "\n84.2 Modello 1 — Outcome-only (ignora il meccanismo)",
    "text": "84.2 Modello 1 — Outcome-only (ignora il meccanismo)\nIn questo modello assumiamo che la variabile osservata \\(y\\) (su scala z) segua:\n\\[\ny \\sim \\mathcal{N}(\\mu, \\sigma)\n\\]\ncon aspettative \\(\\mu \\approx 0\\) e \\(\\sigma \\approx 1\\).\nI valori mancanti vengono trattati come parametri latenti e stimati direttamente1, senza modellare la variabile \\(R\\) che indica la risposta. In pratica, stiamo assumendo implicitamente che i dati mancanti siano MCAR (completamente a caso) o MAR (a caso dato il modello).\n\n84.2.1 Intuizione operativa\n\nIl modello stima i valori mancanti “come se” fossero assenti in modo casuale, basandosi solo sulla distribuzione di \\(y\\).\nSe i dati sono in realtà MNAR, le stime di parametri chiave come \\(\\mu\\) possono risultare sistematicamente distorte.\nQuesto approccio è utile come baseline per confrontare l’effetto di modelli più realistici che tengono conto del meccanismo di mancanza.\n\n84.2.2 Codice Stan (outcome-only)\n\n# Modello Stan: Outcome-only (ignora R)\n# Tratta i mancanti come latenti e assume MCAR/MAR\n\nstan_ignore &lt;- '\ndata {\n  int&lt;lower=0&gt; N_obs;             // Numero di osservazioni\n  int&lt;lower=0&gt; N_mis;             // Numero di valori mancanti\n  array[N_obs] real y_obs;        // Valori osservati\n}\nparameters {\n  real mu;                        // Media della distribuzione\n  real&lt;lower=0&gt; sigma;            // Deviazione standard\n  array[N_mis] real y_mis;        // Valori mancanti (stimati)\n}\nmodel {\n  // Priors\n  mu    ~ normal(0, 1);\n  sigma ~ normal(1, 0.5);\n  \n  // Likelihood per dati osservati\n  y_obs ~ normal(mu, sigma);\n  \n  // Likelihood per dati mancanti (uguale agli osservati)\n  y_mis ~ normal(mu, sigma);\n}\ngenerated quantities {\n  real y_mean = mu;               // Stima della media\n  real y_sd   = sigma;             // Stima della deviazione standard\n}\n'\nwriteLines(stan_ignore, \"ignore_mnar.stan\")\n\n\n# Prepara i dati per Stan\ny_obs_vec &lt;- tbl$y_obs[!is.na(tbl$y_obs)]\nN_obs     &lt;- length(y_obs_vec)                 # numero osservazioni\nN_mis     &lt;- sum(is.na(tbl$y_obs))              # numero mancanti\n\ndata_ignore &lt;- list(\n  N_obs = N_obs,\n  N_mis = N_mis,\n  y_obs = y_obs_vec\n)\n\nStima:\n\nmod_ignore &lt;- cmdstan_model(\"ignore_mnar.stan\")\n\n\n# Stima Bayesiana\nfit_ignore &lt;- mod_ignore$sample(\n  data = data_ignore, seed = 11,\n  chains = 4, parallel_chains = 4,\n  iter_warmup = 1500, iter_sampling = 2000,\n  adapt_delta = 0.99, max_treedepth = 14\n)\n\nRiassunto dei parametri stimati:\n\nsumm_ignore &lt;- fit_ignore$summary(variables = c(\"mu\", \"sigma\"))",
    "crumbs": [
      "Missing",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>Dati mancanti in psicologia: identificare e modellare i casi MNAR con un approccio Bayesiano in Stan</span>"
    ]
  },
  {
    "objectID": "chapters/missing/01_mnar_stan.html#modello-2-selection-model-mnar-esplicito",
    "href": "chapters/missing/01_mnar_stan.html#modello-2-selection-model-mnar-esplicito",
    "title": "84  Dati mancanti in psicologia: identificare e modellare i casi MNAR con un approccio Bayesiano in Stan",
    "section": "\n84.3 Modello 2 — Selection model (MNAR esplicito)",
    "text": "84.3 Modello 2 — Selection model (MNAR esplicito)\nNel selection model la probabilità di osservare un dato non è costante, ma dipende dal valore stesso di \\(y\\). Questo legame è descritto dal parametro \\(\\beta\\):\n\n\n\\(\\beta\\) positivo → valori più alti di \\(y\\) hanno maggiore probabilità di essere osservati.\n\n\\(\\beta\\) negativo → valori più alti di \\(y\\) hanno minore probabilità di essere osservati (es. soggetti con punteggi elevati evitano di rispondere).\n\n\\(\\beta\\) = 0 → la probabilità di osservazione non dipende da \\(y\\) (condizionatamente alle altre variabili incluse nel modello).\n\nAd esempio, se \\(y\\) misura il livello di umore depresso, un \\(\\beta\\) negativo significherebbe che, all’aumentare del punteggio (maggiore sintomatologia), cala la probabilità di risposta — un tipico caso di missing not at random per evitamento.\nInterpretazione sulla scala logit. Ogni unità di aumento in \\(y\\) modifica il log-odds di osservazione di \\(\\beta\\) unità. Per questo motivo è utile centrare e scalare \\(y\\): una scala interpretabile rende la prior di \\(\\beta\\) più chiara e confrontabile tra studi.\nIdea chiave. Trattiamo i valori mancanti \\(y_{\\text{mis}}\\) come parametri latenti e, per ciascuna unità statistica, usiamo lo stesso valore (osservato o imputato dal modello) all’interno dell’equazione logistica per \\(R\\). In questo modo, il meccanismo di mancanza “vede” sia i dati osservati sia quelli stimati.\n\n84.3.1 Modello 2A — Prior informativa su \\(\\beta\\)\n\nIn questo modello adottiamo una prior informativa sul parametro \\(\\beta\\), che nel selection model controlla quanto e in quale direzione il valore dell’outcome \\(y\\) influenza la probabilità di essere osservato (\\(R=1\\)).\nNel nostro scenario simulato, sappiamo per costruzione che:\n\nil meccanismo è MNAR,\n\n\\(\\beta\\) è negativo (valori alti di \\(y\\) sono meno probabili da osservare).\n\nQuesta conoscenza a priori ci permette di formulare una prior centrata su un valore negativo plausibile, fondata sia sulla struttura simulata sia su ipotesi teoriche comuni in psicologia (es. soggetti con punteggi elevati su certi tratti tendono a evitare la risposta).\nPerché usare una prior informativa su \\(\\beta\\)?\n\n\nStabilizzare la stima. Se il campione è piccolo o il segnale nei dati è debole, la prior riduce l’incertezza a posteriori e aiuta a evitare stime erratiche.\n\nIntegrare conoscenza pregressa. Studi precedenti o considerazioni teoriche possono fornire un’idea credibile della direzione e dell’ordine di grandezza di \\(\\beta\\), migliorando l’identificabilità del meccanismo MNAR.\n\nIn sintesi, il modello 2A è un esempio di strategia “assistita” dalla teoria: non lasciamo che \\(\\beta\\) sia determinato solo dal dato, ma lo orientiamo con un’informazione a priori motivata e trasparente.\n\nstan_selection_inf &lt;- '\ndata {\n  int&lt;lower=0&gt; N_obs;\n  int&lt;lower=0&gt; N_mis;\n  int&lt;lower=0&gt; N_total;\n  array[N_obs] real y_obs;\n  array[N_total] int&lt;lower=0,upper=1&gt; R;\n}\nparameters {\n  real mu;\n  real&lt;lower=0&gt; sigma;\n  array[N_mis] real y_mis;\n  real alpha;\n  real beta;\n}\ntransformed parameters {\n  array[N_total] real y_all;\n  for (n in 1:N_obs)   y_all[n] = y_obs[n];\n  for (n in 1:N_mis)   y_all[N_obs + n] = y_mis[n];\n}\nmodel {\n  // Priors ancoranti su outcome (scala nota) + informativa su beta\n  mu    ~ normal(0, 0.3);\n  sigma ~ normal(1, 0.2) T[0,];\n  alpha ~ normal(0, 1);\n  beta  ~ normal(-1.5, 0.5);\n\n  // Outcome\n  y_obs ~ normal(mu, sigma);\n  y_mis ~ normal(mu, sigma);\n\n  // Selection\n  for (n in 1:N_total)\n    R[n] ~ bernoulli_logit(alpha + beta * y_all[n]);\n}\ngenerated quantities {\n  real y_mean = mu;\n  real y_sd   = sigma;\n}\n'\nwriteLines(stan_selection_inf, \"selection_mnar_informative.stan\")\n\n\nN_obs   &lt;- sum(!is.na(tbl$y_obs))\nN_mis   &lt;- sum(is.na(tbl$y_obs))\nN_total &lt;- nrow(tbl)\n\ndata_sel &lt;- list(\n  N_obs   = N_obs,\n  N_mis   = N_mis,\n  N_total = N_total,\n  y_obs   = y_obs_vec,\n  R       = as.integer(tbl$R)\n)\n\nCompila il modello Selection MNAR:\n\nmod_sel_inf &lt;- cmdstan_model(\"selection_mnar_informative.stan\")\n\n\n# Stima Bayesiana\nfit_sel_inf &lt;- mod_sel_inf$sample(\n  data = data_sel, seed = 33,\n  chains = 4, parallel_chains = 4,\n  iter_warmup = 1500, iter_sampling = 2000,\n  adapt_delta = 0.99, max_treedepth = 14\n)\n\nRiassunto dei parametri principali:\n\nsumm_sel_inf &lt;- fit_sel_inf$summary(variables = c(\"mu\",\"sigma\",\"alpha\",\"beta\"))\n\nDirei che la struttura del testo è già molto buona, ma si può renderlo più incisivo e scorrevole migliorando tre aspetti:\n\n\nRidurre la ridondanza nelle spiegazioni di cosa significhi \\(\\beta\\) (già spiegato nel modello 2A, qui basta un richiamo breve).\n\nEsplicitare il razionale pedagogico: perché in un contesto didattico è utile confrontare un modello con prior informativa e uno con prior ampia.\n\nRafforzare la metafora della “prova di forza” rendendo chiaro il legame con l’identificabilità e la robustezza dei risultati.\n\n84.3.2 Modello 2B — Prior “wide” su \\(\\beta\\) e outcome ancorato\nQuesta variante del selection model combina due scelte di prior mirate:\n\n\nOutcome fortemente ancorato sulla scala z\n\n\\(\\mu \\sim \\mathcal{N}(0, 0.2)\\)\n\n\\(\\sigma \\sim \\mathcal{N}(1, 0.1)\\) troncata a valori positivi\n\nPrima di vedere i dati, assumiamo che l’outcome sia già centrato (media vicina a 0) e scalato (deviazione standard vicina a 1). Questo ancoraggio forte riduce l’incertezza su \\(\\mu\\) e \\(\\sigma\\) e rende più stabile la stima degli altri parametri, incluso \\(\\beta\\).\n\n\nPrior ampia su \\(\\beta\\)\n\n\\(\\beta \\sim \\mathcal{N}(0, 2)\\)\n\nLasciamo quasi completa libertà al dato di determinare segno e ampiezza dell’effetto del meccanismo di mancanza. A differenza del modello 2A, qui non forniamo alcuna indicazione a priori sulla direzione attesa di \\(\\beta\\).\n\n\nRichiamo rapido su \\(\\beta\\). Il parametro \\(\\beta\\) è il coefficiente logit che collega \\(y\\) alla probabilità di essere osservato: valori negativi indicano che i punteggi alti tendono a mancare, valori positivi l’opposto, valori vicini a zero indicano assenza di relazione.\nPerché questa scelta?\nQuesto setup funziona come test di robustezza:\n\n\nAncoriamo fortemente la parte dell’outcome, per evitare che incertezza su \\(\\mu\\) e \\(\\sigma\\) si propaghi a \\(\\beta\\).\n\nAllentiamo il vincolo su \\(\\beta\\) per vedere se il segnale nei dati, senza alcun “aiuto” teorico, è sufficiente a rivelare il meccanismo MNAR.\n\nConfronto didattico: se il campione è grande e il meccanismo forte, ci aspettiamo che la stima di \\(\\beta\\) sia simile a quella del modello 2A, ma con intervalli credibili più ampi; se invece i dati non contengono abbastanza informazione, la stima sarà più incerta o ambigua.\n\nIn altre parole, il modello 2B è una “prova di forza” per il dato: tolta la stampella della prior informativa, riusciamo ancora a vedere la stessa storia?\n\nstan_sel_wide &lt;- '\ndata {\n  int&lt;lower=0&gt; N_obs;\n  int&lt;lower=0&gt; N_mis;\n  int&lt;lower=0&gt; N_total;\n  array[N_obs] real y_obs;\n  array[N_total] int&lt;lower=0,upper=1&gt; R;\n}\nparameters {\n  real mu;\n  real&lt;lower=0&gt; sigma;\n  array[N_mis] real y_mis;\n  real alpha;\n  real beta;\n}\nmodel {\n  // Priors: outcome fortemente ancorato (scala z), beta ampia\n  mu    ~ normal(0, 0.2);\n  sigma ~ normal(1, 0.1) T[0,];\n  alpha ~ normal(0, 2);\n  beta  ~ normal(0, 2);\n\n  // Outcome\n  y_obs ~ normal(mu, sigma);\n  y_mis ~ normal(mu, sigma);\n\n  // Selection con indicizzazione corretta\n  {\n    int i_obs = 1;\n    int i_mis = 1;\n    for (n in 1:N_total) {\n      real y_n = (R[n] == 1) ? y_obs[i_obs] : y_mis[i_mis];\n      R[n] ~ bernoulli_logit(alpha + beta * y_n);\n      if (R[n] == 1) i_obs += 1; else i_mis += 1;\n    }\n  }\n}\ngenerated quantities {\n  real y_mean = mu;\n  real y_sd   = sigma;\n}\n'\nwriteLines(stan_sel_wide, \"selection_mnar_wide.stan\")\n\n\nmod_sel_wide &lt;- cmdstan_model(\"selection_mnar_wide.stan\")\n\n\nfit_sel_wide &lt;- mod_sel_wide$sample(\n  data = data_sel, seed = 33,\n  chains = 4, parallel_chains = 4,\n  iter_warmup = 2500, iter_sampling = 3000,\n  adapt_delta = 0.999, max_treedepth = 20\n)\n\n\nsumm_sel_wide &lt;- fit_sel_wide$summary(variables = c(\"mu\",\"sigma\",\"alpha\",\"beta\"))",
    "crumbs": [
      "Missing",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>Dati mancanti in psicologia: identificare e modellare i casi MNAR con un approccio Bayesiano in Stan</span>"
    ]
  },
  {
    "objectID": "chapters/missing/01_mnar_stan.html#scelte-dei-prior-e-loro-razionale",
    "href": "chapters/missing/01_mnar_stan.html#scelte-dei-prior-e-loro-razionale",
    "title": "84  Dati mancanti in psicologia: identificare e modellare i casi MNAR con un approccio Bayesiano in Stan",
    "section": "\n84.4 Scelte dei prior e loro razionale",
    "text": "84.4 Scelte dei prior e loro razionale\nLe differenze tra i tre modelli non riguardano solo la parte di likelihood, ma soprattutto le scelte di prior, che riflettono ipotesi diverse sulla natura del meccanismo di mancanza e sulla scala dell’outcome. Qui riassumiamo il razionale di ciascun modello.\n\n\n\n\n\n\n\n\n\nModello\nPrior su \\(\\mu\\) e \\(\\sigma\\)\n\nPrior su \\(\\beta\\)\n\nRazionale\nAttese sulle stime\n\n\n\nOutcome-only\nLarghe (nessun ancoraggio)\nNessuna (\\(\\beta\\) assente)\nTest di riferimento: stimiamo \\(\\mu\\) e \\(\\sigma\\) ignorando il meccanismo di mancanza\nPossibile bias se i dati sono MNAR\n\n\n2A — Prior informativa su \\(\\beta\\)\nLarghe (nessun ancoraggio)\nInformativa centrata su valore negativo plausibile\nIncorporiamo conoscenza teorica/empirica sul segno e l’ordine di grandezza di \\(\\beta\\)\n\nStima di \\(\\beta\\) più stabile e intervalli credibili più stretti\n\n\n\n2B — Prior ampia su \\(\\beta\\) e outcome ancorato\nFortemente ancorate (\\(\\mu\\)≈0, \\(\\sigma\\)≈1)\nAmpia, \\(\\mathcal{N}(0, 2)\\)\n\nL’ancoraggio rende interpretabile \\(\\beta\\) in unità di deviazione standard; prior ampia per lasciare ai dati il compito di “dire la verità”\nStima di \\(\\beta\\) simile a 2A se i dati sono informativi, ma con intervalli più ampi\n\n\n\n\n\n84.4.1 Perché ancorare \\(\\mu\\) e \\(\\sigma\\) nel modello 2B?\nNon è un trucco per “facilitare” la stima, ma una scelta metodologica per fissare una scala interpretabile. Se \\(y\\) non è centrato e scalato, una stessa prior su \\(\\beta\\) può implicare effetti molto diversi nella probabilità di osservazione. Con \\(\\mu\\)≈0 e \\(\\sigma\\)≈1, \\(\\beta\\) è interpretabile come variazione nel log-odds associata a 1 deviazione standard di \\(y\\). Questo permette anche di confrontare \\(\\beta\\) tra studi diversi.\n\n84.4.2 Confronto visivo tra le prior di \\(\\beta\\)\n\nRicordiamo che \\(\\beta\\) controlla la pendenza della relazione logit tra il valore dell’outcome \\(y\\) e la probabilità di osservarlo (\\(R=1\\)):\n\n\n\\(\\beta\\) &lt; 0 → i valori più alti di \\(y\\) hanno minore probabilità di essere osservati;\n\n\\(\\beta\\) &gt; 0 → i valori più bassi di \\(y\\) hanno minore probabilità di essere osservati;\n\n\\(\\beta\\) ≈ 0 → la probabilità di osservazione non dipende da \\(y\\) (MAR condizionato).\n\nNello scenario simulato sappiamo che il meccanismo MNAR “vero” ha \\(\\beta\\) negativo: più alto è \\(y\\), più è probabile che manchi.\nLe due versioni del selection model adottano ipotesi molto diverse su \\(\\beta\\):\n\ndf_beta &lt;- bind_rows(\n  data.frame(beta = rnorm(5000, mean = -0.5, sd = 0.3), model = \"2A — Informativa\"),\n  data.frame(beta = rnorm(5000, mean = 0, sd = 2), model = \"2B — Ampia\")\n)\n\nggplot(df_beta, aes(x = beta, fill = model)) +\n  geom_density(alpha = 0.5) +\n  labs(title = \"Distribuzioni a priori di $\\beta$ nei modelli 2A e 2B\",\n       x = expression(beta), y = \"Densità\")\n\n\n\n\n\n\n\n\nLa prior informativa del modello 2A concentra la probabilità su valori negativi plausibili, fornendo una “spinta” teorica verso l’effetto atteso.\nLa prior ampia del modello 2B, invece, consente valori molto più estremi, sia positivi che negativi, lasciando al dato quasi tutta la responsabilità di informare \\(\\beta\\).\n\nMessaggio didattico: confrontare i risultati di 2A e 2B ci permette di capire quanto le nostre assunzioni a priori influenzano la stima e se, in presenza di un segnale forte nei dati, il modello riesce a recuperare comunque il meccanismo MNAR.\n\n84.4.3 Confronto delle stime e interpretazione\nConfrontiamo i parametri chiave (media e deviazione standard) dei tre modelli con i valori veri della simulazione.\nCosa ci aspettiamo di vedere:\n\n\nOutcome-only: bias negativo su \\(\\mu\\) e sottostima di \\(\\sigma\\), perché i valori alti di \\(y\\) sono sottorappresentati.\n\n2A: recupero di \\(\\mu\\) e \\(\\sigma\\) vicino ai valori veri, con \\(\\beta\\) stimato negativo e intervalli più stretti grazie alla prior informativa.\n\n2B: recupero simile a 2A, ma con intervalli più ampi su \\(\\beta\\) e, in parte, su \\(\\mu\\), perché il modello non riceve “spinta” a priori.\n\n\nsumm_ignore\n#&gt; # A tibble: 2 × 10\n#&gt;   variable  mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 mu       -0.59  -0.59  0.04  0.04 -0.65 -0.53  1.00  6441.29  6124.54\n#&gt; 2 sigma     0.82   0.82  0.03  0.03  0.78  0.86  1.00  3383.99  4952.44\n\n\nsumm_sel_inf\n#&gt; # A tibble: 4 × 10\n#&gt;   variable  mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 mu       -0.58  -0.58  0.04  0.04 -0.64 -0.52  1.00  6056.09  6409.33\n#&gt; 2 sigma     0.82   0.82  0.03  0.03  0.78  0.86  1.00  4187.94  5424.54\n#&gt; 3 alpha    -0.02  -0.02  0.09  0.09 -0.17  0.13  1.00  6587.79  5973.37\n#&gt; 4 beta     -0.04  -0.04  0.11  0.11 -0.22  0.14  1.00  4943.59  5281.03\n\n\nsumm_sel_wide\n#&gt; # A tibble: 4 × 10\n#&gt;   variable  mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 mu        0.05   0.05  0.09  0.09 -0.11  0.19  1.01   706.33  1072.86\n#&gt; 2 sigma     1.04   1.04  0.06  0.06  0.94  1.13  1.01   776.09  1299.45\n#&gt; 3 alpha     0.14   0.12  0.21  0.21 -0.17  0.51  1.01   780.47  1495.66\n#&gt; 4 beta     -2.10  -2.09  0.36  0.35 -2.68 -1.51  1.00   833.02  1098.85\n\nNel grafico seguente visualizziamo gli intervalli (90%) per \\(\\mu\\) e \\(\\sigma\\), con le linee tratteggiate ai valori veri per il Modello 1 e il Modello 2B.\n\nsumm_mu_sigma &lt;- function(fit, model_label) {\n  posterior::summarise_draws(\n    posterior::as_draws_df(fit$draws(variables = c(\"mu\", \"sigma\"))),\n    mean = ~mean(.x),\n    q5   = ~posterior::quantile2(.x, 0.05),\n    q95  = ~posterior::quantile2(.x, 0.95)\n  ) |&gt;\n    dplyr::transmute(model = model_label, variable, mean, q5, q95)\n}\n\ns_ignore &lt;- summ_mu_sigma(fit_ignore,   \"Outcome-only\")\ns_wide   &lt;- summ_mu_sigma(fit_sel_wide, \"Selection (beta ampia, outcome ancorato)\")\n\nplot_tbl &lt;- bind_rows(s_ignore, s_wide) |&gt;\n  mutate(model = factor(model,\n    levels = c(\"Outcome-only\",\n               \"Selection (beta ampia, outcome ancorato)\")))\n\nplot_param &lt;- function(tbl, param_name, label_y) {\n  df &lt;- filter(tbl, variable == param_name)\n  truth_val   &lt;- if (param_name == \"mu\") 0 else 1\n  param_label &lt;- if (param_name == \"mu\") \"Media (mu, z)\" else \"Dev. Std (sigma, z)\"\n\n  ggplot(df, aes(x = model, y = mean)) +\n    geom_pointrange(aes(ymin = q5, ymax = q95)) +\n    geom_hline(yintercept = truth_val, linetype = 2) +\n    labs(title = paste(\"Stime posteriori di\", param_label), x = NULL, y = label_y) +\n    coord_flip()\n}\n\ng_mu    &lt;- plot_param(plot_tbl, \"mu\",    \"Media posteriore (90% CI)\")\ng_sigma &lt;- plot_param(plot_tbl, \"sigma\", \"Deviazione standard posteriore (90% CI)\")\n\n\ng_mu\n\n\n\n\n\n\n\n\ng_sigma\n\n\n\n\n\n\n\n\n84.4.4 Lettura dei risultati\n\nOutcome-only Il modello che ignora il meccanismo di selezione fornisce una stima di \\(\\mu\\) fortemente distorta verso il basso (–0.65 contro il valore vero vicino a 0). Questo accade perché i dati osservati provengono in prevalenza da valori bassi della variabile, e l’assenza di correzione porta a una sottostima sistematica. Anche \\(\\sigma\\) è sottostimata (0.80 vs valore vero ≈ 1), segnalando che la variabilità complessiva è sottorappresentata.\nSelection MNAR con prior informativa su \\(\\beta\\) L’inclusione esplicita del meccanismo di selezione riduce fortemente il bias su \\(\\mu\\) (–0.11) e riporta \\(\\sigma\\) vicino al valore vero (0.99). Come atteso, \\(\\beta\\) viene stimato negativo (–1.81), coerente con la simulazione in cui la probabilità di osservare un valore diminuisce quando \\(y\\) cresce. L’incertezza però aumenta, perché il modello deve stimare anche i parametri del processo di selezione.\nSelection MNAR con prior ampia su \\(\\beta\\) e outcome ancorato Anche con prior meno informativa su \\(\\beta\\) la stima di \\(\\mu\\) resta vicina a 0 (–0.038) e \\(\\sigma\\) è in linea con il valore vero (1.015). \\(\\beta\\) è di nuovo negativo (–2.04), indicando un effetto di selezione forte, ma qui il modello ha potuto stimarlo senza vincoli forti a priori. L’ancoraggio dell’outcome ha contribuito a contenere il bias pur lasciando ampio margine di apprendimento dai dati.\n\nIn sintesi: ignorare il meccanismo MNAR produce bias sostanziale su media e varianza. Includere un modello di selezione, anche con prior ampie, consente di recuperare stime molto più vicine ai valori veri, a costo di intervalli di credibilità più ampi e maggiore incertezza sui parametri.",
    "crumbs": [
      "Missing",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>Dati mancanti in psicologia: identificare e modellare i casi MNAR con un approccio Bayesiano in Stan</span>"
    ]
  },
  {
    "objectID": "chapters/missing/01_mnar_stan.html#identificabilità-scaling-e-scelte-di-prior",
    "href": "chapters/missing/01_mnar_stan.html#identificabilità-scaling-e-scelte-di-prior",
    "title": "84  Dati mancanti in psicologia: identificare e modellare i casi MNAR con un approccio Bayesiano in Stan",
    "section": "\n84.5 Identificabilità, scaling e scelte di prior",
    "text": "84.5 Identificabilità, scaling e scelte di prior\nI modelli MNAR, in particolare i selection models, non sono “gratuiti” in termini di informazione: stimare il meccanismo di mancanza richiede struttura e segnali nei dati.\n\n\nIdentificabilità: con campioni piccoli o con un meccanismo di mancanza debole, \\(\\beta\\) può essere stimato con grande incertezza.\n\nScaling: centrare e scalare \\(y\\) facilita l’assegnazione di prior interpretabili a \\(\\beta\\) (ad esempio normal(0,1)), rendendo la scala dei parametri coerente con l’interpretazione.\n\nScelte di prior: priors debolmente informative su \\(\\mu\\) e \\(\\sigma\\), coerenti con la scala dei dati; su \\(\\alpha\\) e \\(\\beta\\), priors compatibili con la plausibilità teorica del fenomeno.\n\nVariabili ausiliarie: se disponibili, includere misure correlate o precedenti che riducano la dipendenza tra \\(y\\) e il meccanismo di mancanza. Questo può “spostare” il problema verso MAR condizionato e migliorare l’identificabilità.\n\n\n\n\n\n\n\nSuggerimento pratico: confronta più specificazioni (prior diverse, con/senza variabili ausiliarie) e documenta l’impatto sulle stime di interesse. La trasparenza sulle assunzioni è parte integrante dell’inferenza.",
    "crumbs": [
      "Missing",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>Dati mancanti in psicologia: identificare e modellare i casi MNAR con un approccio Bayesiano in Stan</span>"
    ]
  },
  {
    "objectID": "chapters/missing/01_mnar_stan.html#interpretazione-dei-risultati-alla-luce-della-teoria-mnar",
    "href": "chapters/missing/01_mnar_stan.html#interpretazione-dei-risultati-alla-luce-della-teoria-mnar",
    "title": "84  Dati mancanti in psicologia: identificare e modellare i casi MNAR con un approccio Bayesiano in Stan",
    "section": "\n84.6 Interpretazione dei risultati alla luce della teoria MNAR",
    "text": "84.6 Interpretazione dei risultati alla luce della teoria MNAR\nNella simulazione, il vero valore dell’outcome standardizzato è:\n\n\n\\(\\mu\\) = 0 (media)\n\n\\(\\sigma\\) = 1 (deviazione standard)\n\ne il meccanismo di mancanza è MNAR con \\(\\beta\\) &lt; 0: i valori alti di \\(y\\) hanno minore probabilità di essere osservati.\n\n84.6.1 Comportamento dei modelli\n\n\n\n\n\n\n\n\nModello\nStima \\(\\mu\\)\n\nStima \\(\\sigma\\)\n\nRelazione con il vero valore\n\n\n\nOutcome-only\nDistorto verso il basso\nDistorto verso l’alto\nIgnorando il meccanismo MNAR, \\(\\mu\\) sottostima la media reale (perché i valori alti mancano più spesso), e \\(\\sigma\\) è sovrastimata (perché la variabilità residua è gonfiata)\n\n\n2A — Prior informativa\nVicino al valore vero\nVicino al valore vero\nLa prior su \\(\\beta\\) aiuta a correggere il bias e a recuperare le stime corrette di \\(\\mu\\) e \\(\\sigma\\)\n\n\n\n2B — Prior ampia + outcome ancorato\n\nVicino al valore vero (ma con CI più ampia)\n\nVicino al valore vero (ma con CI più ampia)\nL’ancoraggio di \\(\\mu\\) e \\(\\sigma\\) rende interpretabile \\(\\beta\\); senza prior informativa, l’incertezza è maggiore ma il segnale dei dati basta a recuperare il meccanismo\n\n\n\n84.6.2 Perché ha senso teoricamente?\n\nOutcome-only: il meccanismo MNAR non è modellato → stimatore biased. In teoria MNAR, ignorare la dipendenza di \\(R\\) da \\(y\\) porta a stime distorte di parametri descrittivi dell’outcome.\n2A: la prior informativa su \\(\\beta\\) fornisce una “stampella” teorica → correzione del bias anche con pochi dati o segnale debole.\n2B: la prior ampia su \\(\\beta\\), combinata con \\(\\mu\\) e \\(\\sigma\\) ancorati, permette ai dati di “parlare da soli”. Se il campione è abbastanza grande e il meccanismo è forte, il risultato converge a quello di 2A, ma con più incertezza (CI più ampi).\n\n84.6.3 Messaggio didattico\n\n\nIgnorare il meccanismo MNAR tende a produrre bias (qui: \\(\\mu\\) fortemente sottostimata).\nUn selection model che include \\(\\Pr(R=1\\mid y)\\) può ridurre o annullare il bias su \\(\\mu\\) e recuperare la stima di \\(\\sigma\\), identificando al contempo un \\(\\beta&lt;0\\) coerente con il meccanismo simulato.\nCon prior ampia su \\(\\beta\\) (\\(\\mathcal{N}(0,2)\\)) e segnale forte nei dati, il parametro viene comunque spinto nella direzione corretta (negativa), ma con maggiore incertezza rispetto a una prior leggermente più informativa (es. \\(\\mathcal{N}(-1.5,1)\\)).\n\nBuone pratiche: monitorare \\(\\hat{R}\\) ed ESS, aumentare le iterazioni se l’identificabilità è debole, e valutare prior motivate teoricamente; includere variabili ausiliarie quando possibile.\n\nIn sintesi, nel modello con prior ampia su \\(\\beta\\) il recupero di \\(\\mu \\approx 0\\) e \\(\\sigma \\approx 1\\) è sostanziale, e l’effetto del meccanismo di mancanza (\\(\\beta \\approx -1.88\\), IC \\(90\\%\\) [-2.65, -0.60]) è coerente con lo scenario MNAR simulato (\\(\\beta*{\\text{true}}=-2\\)). La diagnostica MCMC è adeguata; prior più orientate o campioni più grandi possono aumentare la stabilità.",
    "crumbs": [
      "Missing",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>Dati mancanti in psicologia: identificare e modellare i casi MNAR con un approccio Bayesiano in Stan</span>"
    ]
  },
  {
    "objectID": "chapters/missing/01_mnar_stan.html#varianti-utili-oltre-al-selection-model",
    "href": "chapters/missing/01_mnar_stan.html#varianti-utili-oltre-al-selection-model",
    "title": "84  Dati mancanti in psicologia: identificare e modellare i casi MNAR con un approccio Bayesiano in Stan",
    "section": "\n84.7 Varianti utili oltre al selection model",
    "text": "84.7 Varianti utili oltre al selection model\n\n\nPattern-mixture models: si specifica \\(p(y \\mid R)\\) separatamente per osservati e mancanti, ricomponendo poi la distribuzione complessiva. Richiedono vincoli o anchoring per l’identificazione.\n\nShared-parameter models: outcome e meccanismo di osservazione condividono variabili latenti (es. un tratto di evitamento che influenza sia \\(y\\) sia \\(R\\)).\n\nMultilevel/longitudinali: in EMA e studi ripetuti è naturale usare modelli gerarchici con effetti casuali a più livelli; l’MNAR può agire in modo diverso a livello di momento, giorno o soggetto.",
    "crumbs": [
      "Missing",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>Dati mancanti in psicologia: identificare e modellare i casi MNAR con un approccio Bayesiano in Stan</span>"
    ]
  },
  {
    "objectID": "chapters/missing/01_mnar_stan.html#linee-guida-sintetiche",
    "href": "chapters/missing/01_mnar_stan.html#linee-guida-sintetiche",
    "title": "84  Dati mancanti in psicologia: identificare e modellare i casi MNAR con un approccio Bayesiano in Stan",
    "section": "\n84.8 Linee guida sintetiche",
    "text": "84.8 Linee guida sintetiche\n\n\nDiagnosi iniziale: esplora pattern di mancanza e relazioni temporali/contestuali (“chi non risponde e quando?”).\n\nParti semplice: usa un outcome-only come baseline (MAR plausibile?) e aggiungi MNAR se giustificato.\n\nVariabili ausiliarie: sfruttale per ridurre l’informatività del meccanismo.\n\nScala e priori: centra/scala dove utile; usa priors debolmente informative ma plausibili.\n\nAnalisi di sensibilità: verifica la stabilità delle conclusioni al variare di prior e struttura del meccanismo.\n\nDocumentazione: esplicita assunzioni e giustifica il modello con la teoria psicologica o il contesto.",
    "crumbs": [
      "Missing",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>Dati mancanti in psicologia: identificare e modellare i casi MNAR con un approccio Bayesiano in Stan</span>"
    ]
  },
  {
    "objectID": "chapters/missing/01_mnar_stan.html#riflessioni-conclusive",
    "href": "chapters/missing/01_mnar_stan.html#riflessioni-conclusive",
    "title": "84  Dati mancanti in psicologia: identificare e modellare i casi MNAR con un approccio Bayesiano in Stan",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\n\nIn presenza di dati MNAR, ignorare il meccanismo può portare a inferenze fuorvianti.\nL’approccio Bayesiano con Stan consente di modellare esplicitamente la mancanza (selection model), riducendo il bias a costo di ipotesi più forti e maggiore incertezza.\nIn psicologia, dove il non rispondere può far parte del processo stesso (evitamento, umore), è metodologicamente opportuno modellare il meccanismo, integrare analisi di sensibilità e riportare in modo trasparente le assunzioni.",
    "crumbs": [
      "Missing",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>Dati mancanti in psicologia: identificare e modellare i casi MNAR con un approccio Bayesiano in Stan</span>"
    ]
  },
  {
    "objectID": "chapters/missing/01_mnar_stan.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/missing/01_mnar_stan.html#informazioni-sullambiente-di-sviluppo",
    "title": "84  Dati mancanti in psicologia: identificare e modellare i casi MNAR con un approccio Bayesiano in Stan",
    "section": "Informazioni sull’ambiente di sviluppo",
    "text": "Informazioni sull’ambiente di sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] stringr_1.5.1         cmdstanr_0.9.0        pillar_1.11.0        \n#&gt;  [4] tinytable_0.11.0      patchwork_1.3.1       ggdist_3.3.3         \n#&gt;  [7] tidybayes_3.0.7       bayesplot_1.13.0      ggplot2_3.5.2        \n#&gt; [10] reliabilitydiag_0.2.1 priorsense_1.1.0      posterior_1.6.1      \n#&gt; [13] loo_2.8.0             rstan_2.32.7          StanHeaders_2.32.10  \n#&gt; [16] brms_2.22.0           Rcpp_1.1.0            conflicted_1.2.0     \n#&gt; [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        \n#&gt; [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          \n#&gt; [25] rio_1.2.3             here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.6         tidyselect_1.2.1     farver_2.1.2        \n#&gt;  [4] fastmap_1.2.0        TH.data_1.1-3        tensorA_0.36.2.1    \n#&gt;  [7] pacman_0.5.1         digest_0.6.37        estimability_1.5.1  \n#&gt; [10] timechange_0.3.0     lifecycle_1.0.4      processx_3.8.6      \n#&gt; [13] survival_3.8-3       magrittr_2.0.3       compiler_4.5.1      \n#&gt; [16] rlang_1.1.6          tools_4.5.1          utf8_1.2.6          \n#&gt; [19] yaml_2.3.10          data.table_1.17.8    knitr_1.50          \n#&gt; [22] labeling_0.4.3       bridgesampling_1.1-2 htmlwidgets_1.6.4   \n#&gt; [25] pkgbuild_1.4.8       curl_6.4.0           RColorBrewer_1.1-3  \n#&gt; [28] abind_1.4-8          multcomp_1.4-28      withr_3.0.2         \n#&gt; [31] purrr_1.1.0          grid_4.5.1           stats4_4.5.1        \n#&gt; [34] xtable_1.8-4         colorspace_2.1-1     inline_0.3.21       \n#&gt; [37] emmeans_1.11.2       scales_1.4.0         MASS_7.3-65         \n#&gt; [40] cli_3.6.5            mvtnorm_1.3-3        rmarkdown_2.29      \n#&gt; [43] generics_0.1.4       RcppParallel_5.1.10  cachem_1.1.0        \n#&gt; [46] splines_4.5.1        parallel_4.5.1       vctrs_0.6.5         \n#&gt; [49] V8_6.0.5             Matrix_1.7-3         sandwich_3.1-1      \n#&gt; [52] jsonlite_2.0.0       arrayhelpers_1.1-0   glue_1.8.0          \n#&gt; [55] ps_1.9.1             codetools_0.2-20     distributional_0.5.0\n#&gt; [58] lubridate_1.9.4      stringi_1.8.7        gtable_0.3.6        \n#&gt; [61] QuickJSR_1.8.0       htmltools_0.5.8.1    Brobdingnag_1.2-9   \n#&gt; [64] R6_2.6.1             rprojroot_2.1.0      evaluate_1.0.4      \n#&gt; [67] lattice_0.22-7       backports_1.5.0      memoise_2.0.1       \n#&gt; [70] broom_1.0.9          snakecase_0.11.1     rstantools_2.4.0    \n#&gt; [73] coda_0.19-4.1        gridExtra_2.3        nlme_3.1-168        \n#&gt; [76] checkmate_2.3.2      mgcv_1.9-3           xfun_0.52           \n#&gt; [79] zoo_1.8-14           pkgconfig_2.0.3",
    "crumbs": [
      "Missing",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>Dati mancanti in psicologia: identificare e modellare i casi MNAR con un approccio Bayesiano in Stan</span>"
    ]
  },
  {
    "objectID": "chapters/missing/01_mnar_stan.html#bibliografia",
    "href": "chapters/missing/01_mnar_stan.html#bibliografia",
    "title": "84  Dati mancanti in psicologia: identificare e modellare i casi MNAR con un approccio Bayesiano in Stan",
    "section": "Bibliografia",
    "text": "Bibliografia",
    "crumbs": [
      "Missing",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>Dati mancanti in psicologia: identificare e modellare i casi MNAR con un approccio Bayesiano in Stan</span>"
    ]
  },
  {
    "objectID": "chapters/missing/01_mnar_stan.html#footnotes",
    "href": "chapters/missing/01_mnar_stan.html#footnotes",
    "title": "84  Dati mancanti in psicologia: identificare e modellare i casi MNAR con un approccio Bayesiano in Stan",
    "section": "",
    "text": "Cosa significa “i valori mancanti sono parametri latenti?” Indichiamo con \\(y_i\\) il valore “vero” per l’unità \\(i\\). Per alcune unità \\(y_i\\) non è osservato (manca). Nel modello bayesiano includiamo comunque un oggetto \\(y_i\\) per ogni unità, anche quando è mancante: lo trattiamo come una quantità sconosciuta da inferire insieme a \\(\\mu\\) e \\(\\sigma\\). Tecnicamente: aggiungiamo un nodo \\(y_i^{\\text{mis}}\\) con la stessa distribuzione dell’outcome, ad es. \\(y_i^{\\text{mis}} \\sim \\mathcal{N}(\\mu,\\sigma).\\) Durante il campionamento, il modello genera valori plausibili per ciascun \\(y_i^{\\text{mis}}\\) coerenti con \\(\\mu\\) e \\(\\sigma\\). Importante: questi \\(y_i^{\\text{mis}}\\) non “informano” \\(\\mu\\) e \\(\\sigma\\) oltre ai dati osservati: sono imputazioni coerenti col modello (servono, per esempio, a produrre dataset completi), ma non correggono eventuali distorsioni dovute al meccanismo di mancanza. In breve: l’imputazione discende solo dalla distribuzione scelta per \\(y.\\)↩︎",
    "crumbs": [
      "Missing",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>Dati mancanti in psicologia: identificare e modellare i casi MNAR con un approccio Bayesiano in Stan</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/introduction_frequentist_inference.html",
    "href": "chapters/frequentist_inference/introduction_frequentist_inference.html",
    "title": "Introduzione",
    "section": "",
    "text": "Differenze fondamentali tra i due approcci\nCome discusso nel capitolo dedicato all’interpretazione delle probabilità (25  Interpretazione della probabilità), esistono due principali approcci nell’inferenza statistica: la statistica frequentista e la statistica bayesiana. Entrambi i metodi consentono di trarre conclusioni sulla popolazione di interesse attraverso l’analisi dei dati e vengono utilizzati per stimare quantità sconosciute, formulare previsioni e testare ipotesi. Tuttavia, differiscono nell’interpretazione della probabilità e nel modo in cui integrano le conoscenze pregresse e le evidenze disponibili.",
    "crumbs": [
      "Frequentismo",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/introduction_frequentist_inference.html#differenze-fondamentali-tra-i-due-approcci",
    "href": "chapters/frequentist_inference/introduction_frequentist_inference.html#differenze-fondamentali-tra-i-due-approcci",
    "title": "Introduzione",
    "section": "",
    "text": "Statistica frequentista\nNella statistica frequentista, la probabilità è interpretata come la frequenza relativa di un evento in un numero infinito di prove. Questo approccio assume che il valore vero di un parametro della popolazione sia fisso ma sconosciuto e che debba essere stimato esclusivamente dai dati osservati. Le inferenze statistiche vengono effettuate attraverso metodi quali:\n\nStima puntuale: fornisce un singolo valore come miglior stima del parametro.\nIntervalli di confidenza: definiscono un intervallo in cui il parametro si trova con una data probabilità, sotto ripetute campionature.\nTest di ipotesi: valutano la compatibilità dei dati con un’ipotesi nulla, attraverso il calcolo di p-value e statistiche test.\n\nQuesto approccio si basa su assunzioni riguardanti il processo che genera i dati e sull’idea che la verità statistica emerga dal comportamento asintotico di esperimenti ripetuti.\n\n\nStatistica bayesiana\nNella statistica bayesiana, la probabilità rappresenta un grado di credenza in un evento, soggetto ad aggiornamento alla luce di nuove evidenze (Jaynes, 2003). Questo approccio si fonda sull’applicazione del teorema di Bayes, che consente di aggiornare la conoscenza su un parametro in base ai dati osservati.\n\nIl valore del parametro è trattato come una variabile casuale con una distribuzione di probabilità.\nL’analisi parte da una distribuzione a priori, che rappresenta la conoscenza precedente.\nI nuovi dati vengono combinati con la distribuzione a priori tramite la verosimiglianza (likelihood).\nIl risultato è la distribuzione a posteriori, che sintetizza l’incertezza aggiornata sul parametro.\n\nQuesto approccio permette di incorporare informazioni pregresse ed è particolarmente utile in contesti con dati limitati o conoscenze precedenti rilevanti.",
    "crumbs": [
      "Frequentismo",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/introduction_frequentist_inference.html#il-problema-dellinduzione-di-hume",
    "href": "chapters/frequentist_inference/introduction_frequentist_inference.html#il-problema-dellinduzione-di-hume",
    "title": "Introduzione",
    "section": "Il problema dell’induzione di Hume",
    "text": "Il problema dell’induzione di Hume\nUna prospettiva utile per comprendere la differenza tra questi due approcci è il problema dell’induzione, formulato da David Hume nel 1739 nel suo A Treatise of Human Nature (Hacking, 2006). Hume solleva un dubbio fondamentale: come possiamo giustificare le inferenze dal passato al futuro? Nessuna quantità di osservazioni passate garantisce che il futuro seguirà lo stesso schema.\n\nL’approccio frequentista presuppone implicitamente che il mondo segua regolarità statistiche costanti. Tuttavia, questo assunto è vulnerabile alle critiche di Hume, poiché non offre una giustificazione epistemica all’estrapolazione del passato.\nL’approccio bayesiano integra l’incertezza nell’inferenza: la probabilità di un evento futuro è un riflesso delle nostre credenze attuali e viene aggiornata alla luce di nuove osservazioni. Questo approccio si adatta meglio a situazioni in cui il mondo potrebbe non seguire regolarità fisse.",
    "crumbs": [
      "Frequentismo",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/introduction_frequentist_inference.html#un-esempio-pratico-il-lancio-di-una-moneta",
    "href": "chapters/frequentist_inference/introduction_frequentist_inference.html#un-esempio-pratico-il-lancio-di-una-moneta",
    "title": "Introduzione",
    "section": "Un esempio pratico: il lancio di una moneta",
    "text": "Un esempio pratico: il lancio di una moneta\nConsideriamo il classico esempio del lancio di una moneta per illustrare le differenze tra i due approcci:\n\nFrequentista: definisce la probabilità di ottenere testa come la proporzione di teste osservate in un numero infinito di lanci. La probabilità è una proprietà intrinseca della moneta, indipendente dalle credenze dell’osservatore.\nBayesiano: parte da una distribuzione a priori sulla probabilità della moneta di cadere su testa. Dopo ogni lancio, aggiorna la credenza utilizzando la verosimiglianza, ottenendo una nuova distribuzione a posteriori. Questo metodo riflette un aggiornamento razionale delle credenze alla luce di nuove osservazioni.\n\nL’approccio bayesiano è quindi più flessibile e coerente con la prospettiva di Hume: accetta l’incertezza del futuro e la gestisce attraverso un meccanismo di aggiornamento continuo.",
    "crumbs": [
      "Frequentismo",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/introduction_frequentist_inference.html#obiettivo-di-questa-sezione",
    "href": "chapters/frequentist_inference/introduction_frequentist_inference.html#obiettivo-di-questa-sezione",
    "title": "Introduzione",
    "section": "Obiettivo di questa sezione",
    "text": "Obiettivo di questa sezione\nIn questa sezione della dispensa, esamineremo in dettaglio i metodi della statistica frequentista, tra cui la stima puntuale, gli intervalli di confidenza e il test di ipotesi. Questi strumenti costituiscono il nucleo dell’inferenza statistica tradizionale e offrono un quadro solido per analizzare i dati in assenza di informazioni pregresse. Tuttavia, come evidenziato dal problema di Hume, ogni approccio ha i suoi limiti e presupposti. La scelta tra frequentismo e bayesianesimo dipende dal contesto e dagli obiettivi dell’analisi.",
    "crumbs": [
      "Frequentismo",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/introduction_frequentist_inference.html#bibliografia",
    "href": "chapters/frequentist_inference/introduction_frequentist_inference.html#bibliografia",
    "title": "Introduzione",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nHacking, I. (2006). The emergence of probability: A philosophical study of early ideas about probability, induction and statistical inference. Cambridge University Press.\n\n\nJaynes, E. T. (2003). Probability theory: The logic of science. Cambridge University Press.",
    "crumbs": [
      "Frequentismo",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html",
    "title": "85  Inferenza frequentista",
    "section": "",
    "text": "85.1 Introduzione\nIn questo capitolo esamineremo le radici storiche della statistica frequentista e le sue connessioni con il movimento eugenetico. Vedremo come alcune idee sviluppate nel contesto di questa corrente abbiano influenzato l’elaborazione dei metodi statistici che molti di noi utilizzano ancora oggi.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>85</span>  <span class='chapter-title'>Inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#i-frequentisti-sono-razzisti",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#i-frequentisti-sono-razzisti",
    "title": "85  Inferenza frequentista",
    "section": "\n85.2 I Frequentisti sono Razzisti?",
    "text": "85.2 I Frequentisti sono Razzisti?\nNel Capitolo 30, abbiamo esplorato le origini storiche e il contesto culturale che hanno portato all’interpretazione del teorema di Bayes proposta da Richard Price. Quelle origini, legate alla rivoluzione americana, rappresentano il “lato luminoso” del liberalismo moderno.\nLe origini dell’approccio frequentista, invece, si collocano agli antipodi: sono strettamente intrecciate con ciò che potremmo definire la “parte oscura” della modernità. L’avversione per la soggettività, tipica del frequentismo, riflette una visione più rigida e deterministica, distante dall’apertura e dalla flessibilità del pensiero bayesiano.\n\n85.2.1 Francis Galton e l’Eugenetica\nFrancis Galton (1822-1911), cugino di Charles Darwin, fu un esploratore, un medico e un pioniere della meteorologia. Ma il suo contributo più importante, e anche più controverso, riguardò la statistica e lo studio dell’ereditarietà del talento.\n\n\nDistribuzione Normale e Regressione\nGalton formalizzò la distribuzione normale e introdusse il concetto di “regressione verso la media”, chiamata inizialmente “regressione verso la mediocrità”.\n\n\nHereditary Genius\nNel suo libro Hereditary Genius, Galton sosteneva che il talento fosse trasmesso all’interno di specifiche famiglie. Fu lui a coniare la famosa espressione “nature and nurture” per indicare il ruolo combinato di eredità e ambiente nello sviluppo umano.\n\n\nEugenetica\nGalton mirava a “migliorare la specie umana” promuovendo la riproduzione tra famiglie ritenute “di successo” e scoraggiandola tra quelle considerate “inferiori”. Le sue idee, fortemente razziste, includevano l’idea che gli africani fossero “inferiori” e “pigri”, gli arabi “semplici consumatori della produzione altrui” e che gli anglosassoni fossero la “razza superiore”.\n\n85.2.2 L’Impatto di Galton su Pearson e Fisher\nLe teorie di Galton influenzarono Karl Pearson (1857-1936) e Ronald Fisher (1890-1962), due figure chiave della statistica moderna. Entrambi condividevano idee razziste e appoggiavano l’eugenetica:\n\n\nKarl Pearson\nProfessore all’University College di Londra, sviluppò strumenti come il test del chi quadrato e la deviazione standard. Ereditò la cattedra di eugenetica fondata da Galton.\n\n\nRonald Fisher\nConsiderato uno dei padri della statistica moderna, sviluppò l’analisi della varianza (ANOVA), il concetto di significatività statistica e il metodo della massima verosimiglianza (MLE).\n\nQuesti autori cercarono di allontanare la statistica dalla prospettiva di Laplace e Bayes, rifiutando l’idea di introdurre componenti soggettive nella loro “scienza”. Volevano che la statistica apparisse del tutto “oggettiva” per sostenere teorie eugenetiche e gerarchie razziali come se fossero dimostrate scientificamente.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>85</span>  <span class='chapter-title'>Inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#implicazioni-per-le-pratiche-correnti",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#implicazioni-per-le-pratiche-correnti",
    "title": "85  Inferenza frequentista",
    "section": "\n85.3 Implicazioni per le Pratiche Correnti",
    "text": "85.3 Implicazioni per le Pratiche Correnti\nIn che misura dovremmo considerare le implicazioni storiche ed etiche del frequentismo quando lo utilizziamo oggi? Secondo (Chivers, 2024), sebbene sia evidente che l’ideologia razziale nazista possa essere collegata alle idee di Galton, la questione centrale in statistica rimane: “Quale approccio è metodologicamente corretto?” o, più pragmaticamente, “Quale approccio è più utile?”.\nTuttavia, limitarsi a un dibattito puramente metodologico rischia di trascurare il fatto che la scienza non si svolge in una “torre d’avorio” astratta, ma ha conseguenze concrete. Se una teoria A, pur essendo efficace in uno scenario ideale, ha effetti profondamente negativi nella realtà, dovremmo davvero adottarla acriticamente? La risposta, per molti, è no.\nNel caso del frequentismo, non solo emergono questioni etiche, ma – come vedremo in seguito – si evidenziano anche limiti metodologici. La sua pretesa di “oggettività” si rivela un’illusione quando si analizza in profondità il funzionamento reale delle procedure inferenziali. In psicologia, dove la variabilità individuale e le questioni etiche sono centrali, questi difetti possono avere conseguenze particolarmente dannose.\n\n\n\n\n\n\nNota didattica: L’approccio frequentista viene presentato qui soprattutto per mostrare perché il suo uso esclusivo sia problematico. In questo capitolo descriveremo i fondamenti statistici del frequentismo e la logica delle sue procedure inferenziali. Nel capitoli successivi discuteremo invece come le sue applicazioni pratiche possano ostacolare il progresso della psicologia.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>85</span>  <span class='chapter-title'>Inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#il-paradigma-frequentista",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#il-paradigma-frequentista",
    "title": "85  Inferenza frequentista",
    "section": "\n85.4 Il Paradigma Frequentista",
    "text": "85.4 Il Paradigma Frequentista\nL’obiettivo della statistica frequentista è trarre conclusioni su un’intera popolazione partendo da un campione di dati. In questo contesto:\n\nI dati osservati vengono considerati come un’estrazione casuale (un “campione”) da una popolazione più ampia.\n\nIl modello statistico assume che esista un processo generatore dei dati, descritto da una distribuzione di probabilità.\n\nQuando raccogliamo un campione di dati, dobbiamo tenere presente che avremmo potuto ottenere molti altri campioni diversi (il principio di ripetizione del campionamento).\n\n\n85.4.1 Probabilità e Ripetizione del Campionamento\nIl frequentismo adotta un’interpretazione della probabilità basata sulle frequenze: se ripetessimo un esperimento moltissime volte, la probabilità di un evento sarebbe il rapporto tra il numero di volte in cui l’evento si verifica e il numero totale di prove.\n\n85.4.2 Stima di un Parametro\nSupponiamo di voler stimare un parametro (ad esempio, la media di una popolazione). Il frequentismo cerca un stimatore – una funzione del campione – che abbia determinate proprietà, tra cui l’assenza di distorsione (l’unbiasedness) e la consistenza (la vicinanza alla realtà con l’aumentare del numero di dati).\nUn esempio comune è la stima della media della popolazione tramite la media del campione. Sotto certe condizioni, si può dimostrare che, ripetendo l’esperimento moltissime volte, la media del campione in media coinciderà con la vera media della popolazione.\n\n85.4.3 Intervalli di Confidenza\nNell’approccio frequentista, invece di fornire un singolo valore come stima di un parametro, si costruisce un intervallo di confidenza. L’idea fondamentale è che, se ripetessimo molte volte la stessa procedura di campionamento e di calcolo dell’intervallo, una certa percentuale di questi (ad esempio il 95%) conterrà effettivamente il valore vero del parametro.\nPrima di raccogliere i dati, gli estremi di questo intervallo (i “limiti di confidenza”) sono variabili casuali, perché dipendono dal campione che otterremo. Di conseguenza, la probabilità (per esempio, il 95%) si riferisce alla procedura di costruzione dell’intervallo, non all’intervallo in sé dopo l’osservazione dei dati. Una volta infatti che il campione è stato raccolto e l’intervallo è stato calcolato, quest’ultimo è un oggetto “fisso”: o contiene il valore vero del parametro, o non lo contiene; non è più possibile attribuirgli una probabilità di contenere il parametro. L’affermazione “intervallo di confidenza al 95%” significa dunque che, sul lungo periodo, usando sempre la stessa procedura, il 95% degli intervalli costruiti conterrà il parametro vero.\n\n85.4.4 Test delle Ipotesi: Approccio Frequentista e Limitazioni\nNel contesto del test di un’ipotesi (ad esempio, \\(H_0\\): “la media di una popolazione è uguale a 0”), l’approccio frequentista definisce una regione di rifiuto in base a un livello di significatività prefissato (ad esempio, \\(\\alpha = 0.05\\)). Se il risultato dell’analisi (come il p-value) cade all’interno di questa regione, si procede a rifiutare \\(H_0\\); altrimenti, si manca di rifiutare \\(H_0\\) (ovvero, non si rifiuta l’ipotesi nulla).\n\n\nErrore di tipo I (falso positivo): si verifica quando si rifiuta \\(H_0\\) nonostante essa sia vera.\n\n\nErrore di tipo II (falso negativo): si verifica quando non si rifiuta \\(H_0\\) nonostante essa sia falsa.\n\nNel paradigma frequentista, il ricercatore controlla la probabilità di questi errori, in particolare l’errore di tipo I, attraverso la scelta di \\(\\alpha\\) e il calcolo di indicatori come il p-value. Tuttavia, questo approccio presenta alcune criticità:\n\nDecisione dicotomica\nIl test conduce a una scelta binaria (rifiutare o non rifiutare \\(H_0\\)), che può risultare eccessivamente rigida. I fenomeni reali spesso non si prestano a una categorizzazione netta basata su una soglia arbitraria, rendendo la distinzione “significativo/non significativo” potenzialmente fuorviante. Una visione più sfumata, che consideri l’entità dell’effetto e l’incertezza, potrebbe essere più informativa.\nSoglia arbitraria\nIl valore di \\(\\alpha\\) (comunemente fissato a 0.05) è in gran parte una convenzione. Ad esempio, un valore-p di 0.049 porta al rifiuto di \\(H_0\\), mentre un valore-p di 0.051 non lo fa, nonostante la differenza tra i due casi sia minima. Questa arbitrarietà può influenzare in modo significativo l’interpretazione dei risultati, creando una discontinuità artificiale.\nNessuna prova diretta di verità/falsità\nUn valore-p basso non implica che \\(H_0\\) sia “falsa” o che un’ipotesi alternativa sia “vera”. Indica semplicemente che, assumendo \\(H_0\\) vera, dati simili (o più estremi) sarebbero rari sotto ripetuti campionamenti. Il test frequentista non fornisce una risposta alla domanda “Qual è la probabilità che \\(H_0\\) sia vera?”, limitando la sua capacità di supportare inferenze dirette sulla veridicità delle ipotesi.\n\nQueste criticità evidenziano come la rigidità del test (basato su una decisione binaria) e l’uso di soglie fisse possano risultare problematici, specialmente in discipline come la psicologia, dove le misurazioni sono spesso affette da rumore e le differenze tra condizioni possono essere sottili. Un approccio più flessibile, che integri la stima degli effetti, gli intervalli di confidenza e una valutazione contestuale, potrebbe offrire una comprensione più robusta e sfumata dei dati.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>85</span>  <span class='chapter-title'>Inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#riflessioni-conclusive",
    "title": "85  Inferenza frequentista",
    "section": "\n85.5 Riflessioni Conclusive",
    "text": "85.5 Riflessioni Conclusive\nIn questo capitolo abbiamo mostrato come la statistica frequentista, pur essendo stata un pilastro dell’inferenza moderna, affondi le proprie radici in idee profondamente problematiche, come l’eugenetica e il razzismo sostenuti da Galton, Pearson e Fisher. Sebbene oggi queste teorie sembrino superate e distanti dalle nostre pratiche di laboratorio, conoscerne la genesi aiuta a comprendere come l’idea di un’oggettività assoluta sia stata impiegata per legittimare visioni ideologiche discutibili.\nParallelamente, la riflessione storica solleva interrogativi sul metodo e sulle sue implicazioni pratiche. La metafora della “torre d’avorio” mostra quanto sia pericoloso trattare la scienza come un sistema chiuso, ignorando le conseguenze etiche e sociali. Nel campo della psicologia, in particolare, la crisi di replicabilità (McElreath, 2020) rivela come l’uso acritico di procedure frequentiste possa influire sulla validità dei risultati.\nIn definitiva, il frequentismo non va considerato solo come un insieme di tecniche, ma come un paradigma con implicazioni culturali, etiche e metodologiche. Nel prossimo capitolo mostreremo come le applicazioni pratiche dell’approccio frequentista possano risultare limitanti e, talvolta, dannose per il progresso della psicologia (Gelman et al., 2013). Conoscere le basi e le implicazioni di tale paradigma è il primo passo per un uso più consapevole e responsabile degli strumenti statistici.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>85</span>  <span class='chapter-title'>Inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#informazioni-sullambiente-di-sviluppo",
    "title": "85  Inferenza frequentista",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.7   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.13.0 psych_2.5.3     \n#&gt;  [9] scales_1.4.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.3.0     ggplot2_3.5.2   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.4     stringi_1.8.7      lattice_0.22-7    \n#&gt;  [4] hms_1.1.3          digest_0.6.37      magrittr_2.0.3    \n#&gt;  [7] evaluate_1.0.4     grid_4.5.0         timechange_0.3.0  \n#&gt; [10] RColorBrewer_1.1-3 fastmap_1.2.0      rprojroot_2.0.4   \n#&gt; [13] jsonlite_2.0.0     mnormt_2.1.1       cli_3.6.5         \n#&gt; [16] rlang_1.1.6        withr_3.0.2        tools_4.5.0       \n#&gt; [19] parallel_4.5.0     tzdb_0.5.0         pacman_0.5.1      \n#&gt; [22] vctrs_0.6.5        R6_2.6.1           lifecycle_1.0.4   \n#&gt; [25] htmlwidgets_1.6.4  pkgconfig_2.0.3    pillar_1.10.2     \n#&gt; [28] gtable_0.3.6       glue_1.8.0         xfun_0.52         \n#&gt; [31] tidyselect_1.2.1   rstudioapi_0.17.1  farver_2.1.2      \n#&gt; [34] htmltools_0.5.8.1  nlme_3.1-168       rmarkdown_2.29    \n#&gt; [37] compiler_4.5.0",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>85</span>  <span class='chapter-title'>Inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#bibliografia",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#bibliografia",
    "title": "85  Inferenza frequentista",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nChivers, T. (2024). Everything is Predictable: How Bayesian Statistics Explain Our World. Simon; Schuster.\n\n\nGelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., & Rubin, D. B. (2013). Bayesian Data Analysis (3rd ed.). Chapman; Hall/CRC.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>85</span>  <span class='chapter-title'>Inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01a_stime_parametri.html",
    "href": "chapters/frequentist_inference/01a_stime_parametri.html",
    "title": "86  Stime, stimatori e parametri",
    "section": "",
    "text": "86.1 Introduzione\nIn questo capitolo, ci concentreremo sul concetto di distribuzione campionaria, uno dei pilastri dell’inferenza statistica frequentista. La distribuzione campionaria descrive come le stime dei parametri della popolazione, come la media o la varianza, variano da campione a campione. Essa permette di stabilire proprietà probabilistiche delle stime campionarie, come la loro media e varianza, che sono fondamentali per costruire intervalli di confidenza e condurre test di ipotesi, strumenti essenziali dell’inferenza statistica frequentista.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01a_stime_parametri.html#introduzione",
    "href": "chapters/frequentist_inference/01a_stime_parametri.html#introduzione",
    "title": "86  Stime, stimatori e parametri",
    "section": "",
    "text": "Domande introduttive\n\n\n\nPrima di iniziare a esplorare il concetto di distribuzione campionaria e il suo ruolo nell’inferenza statistica, considera le seguenti domande. Prova a formulare una risposta intuitiva basata sulle tue conoscenze attuali prima di procedere con la lettura del capitolo. Le simulazioni che seguiranno ti aiuteranno a confermare o rivedere le tue risposte.\n\nSe estraiamo ripetutamente campioni casuali dalla stessa popolazione e calcoliamo la loro media, come saranno distribuite queste medie campionarie rispetto alla media della popolazione?\nSupponiamo di estrarre campioni di dimensione \\(n=2\\) da una popolazione. L’insieme delle medie campionarie sarà più concentrato intorno alla media della popolazione rispetto ai valori individuali della popolazione stessa?\nQuale relazione esiste tra la dimensione del campione \\(n\\) e la variabilità delle medie campionarie? In altre parole, se aumentiamo la dimensione del campione, cosa succede alla dispersione della distribuzione campionaria?\nLa distribuzione campionaria della media campionaria sarà sempre normale? Quali fattori influenzano la sua forma?\nLa media della distribuzione campionaria coincide sempre con la media della popolazione? E la sua varianza è maggiore o minore rispetto alla varianza della popolazione?\nSupponiamo di estrarre piccoli campioni da una popolazione che ha una distribuzione fortemente asimmetrica. Quale forma avrà la distribuzione delle medie campionarie per piccoli campioni? E per campioni più grandi?",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01a_stime_parametri.html#stime-stimatori-e-parametri",
    "href": "chapters/frequentist_inference/01a_stime_parametri.html#stime-stimatori-e-parametri",
    "title": "86  Stime, stimatori e parametri",
    "section": "\n86.2 Stime, stimatori e parametri",
    "text": "86.2 Stime, stimatori e parametri\nDopo aver esplorato il contesto culturale del frequentismo nel capitolo precedente, ci spostiamo ora su un piano strettamente statistico per introdurre il concetto di stima statistica.\nQuando si analizzano i dati, l’obiettivo è spesso quello di ottenere informazioni su una caratteristica della popolazione. Tuttavia, nella maggior parte dei casi, si ha accesso solo a un campione di osservazioni. La quantità sconosciuta che vogliamo stimare viene chiamata parametro, mentre il valore che calcoliamo dal campione per approssimare questo parametro è la stima. La formula o il procedimento matematico che utilizziamo per ottenere la stima è detto stimatore. Formalmente, uno stimatore è una funzione dei dati osservati utilizzata per produrre una stima di un parametro.\nIn altre parole, quando analizziamo un campione, cerchiamo di inferire proprietà della popolazione da cui il campione è tratto. Il parametro rappresenta una misura di queste proprietà, ma raramente può essere calcolato direttamente sulla popolazione intera. Pertanto, utilizziamo le osservazioni campionarie per ottenere una stima del parametro. La stima è quindi un’approssimazione del valore del parametro basata sui dati raccolti, mentre lo stimatore è la regola matematica o statistica che la produce.\nÈ importante sottolineare che le stime non coincidono necessariamente con il vero valore del parametro, poiché sono soggette a incertezza dovuta alla variabilità del campionamento. In questo capitolo esamineremo come l’approccio frequentista quantifica questa incertezza e come possiamo utilizzare tale quantificazione per trarre conclusioni affidabili sui parametri di interesse.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01a_stime_parametri.html#distribuzione-campionaria",
    "href": "chapters/frequentist_inference/01a_stime_parametri.html#distribuzione-campionaria",
    "title": "86  Stime, stimatori e parametri",
    "section": "\n86.3 Distribuzione campionaria",
    "text": "86.3 Distribuzione campionaria\nNell’inferenza frequentista applicata alla psicologia, il parametro di maggiore interesse è spesso la media della popolazione—si veda anche la discussione nella Sezione 19.9.1. In questo capitolo esploreremo come la media di un campione casuale possa essere utilizzata per stimare la media \\(\\mu\\) di una popolazione. Per valutare l’incertezza associata a questa stima, introdurremo il concetto di distribuzione campionaria, un principio fondamentale dell’approccio frequentista.\nPer chiarire questa idea, inizieremo con un esempio basato su una popolazione finita di piccole dimensioni, pur consapevoli che le proprietà illustrate si estendono anche a popolazioni di dimensioni maggiori.\n\n86.3.1 Esempio introduttivo\nConsideriamo la seguente popolazione:\n\nx &lt;- c(2, 4.5, 5, 5.5)\nx\n#&gt; [1] 2.0 4.5 5.0 5.5\n\nQuesti valori potrebbero rappresentare il tempo di reazione (in secondi) di quattro partecipanti a un esperimento di decisione rapida, in cui devono identificare il colore di uno stimolo visivo. In questo caso, l’intera popolazione è costituita da tutti i partecipanti disponibili per lo studio, ad esempio se l’esperimento è stato condotto in un piccolo gruppo di persone selezionate per caratteristiche specifiche, come quattro gemelli monozigoti in uno studio sulle differenze cognitive intra-familiari.\nL’istogramma sottostante rappresenta la distribuzione di frequenza della popolazione:\n\n# Creazione del dataframe\ndf &lt;- data.frame(Valori = c(2, 4.5, 5, 5.5))\n\n# Istogramma con ggplot2\nggplot(df, aes(x = Valori)) +\n  geom_histogram(bins = 5, aes(y = after_stat(density)), fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Distribuzione della popolazione\", x = \"Valori\", y = \"Densità\") \n\n\n\n\n\n\n\nCalcoliamo la media e la varianza della popolazione:\n\nmean(x)  # Media\n#&gt; [1] 4.25\nvar(x)   # Varianza\n#&gt; [1] 2.417\n\n\n86.3.2 Campionamento\nConsideriamo ora tutti i possibili campioni di dimensione \\(n = 2\\) che possiamo estrarre dalla popolazione. Poiché ogni valore può essere selezionato indipendentemente in entrambe le posizioni del campione, il numero totale di combinazioni possibili si ottiene con il calcolo combinatorio:\n\\[\n\\text{Numero totale di campioni} = k^n ,\n\\]\ndove \\(k\\) è la dimensione della popolazione e \\(n\\) è la dimensione del campione. Nel nostro caso, con \\(k = 4\\) e \\(n = 2\\), otteniamo:\n\\[\n4^2 = 16 .\n\\]\nPossiamo generare esplicitamente queste combinazioni con il seguente codice:\n\nsamples &lt;- expand.grid(x, x)\nsamples\n#&gt;    Var1 Var2\n#&gt; 1   2.0  2.0\n#&gt; 2   4.5  2.0\n#&gt; 3   5.0  2.0\n#&gt; 4   5.5  2.0\n#&gt; 5   2.0  4.5\n#&gt; 6   4.5  4.5\n#&gt; 7   5.0  4.5\n#&gt; 8   5.5  4.5\n#&gt; 9   2.0  5.0\n#&gt; 10  4.5  5.0\n#&gt; 11  5.0  5.0\n#&gt; 12  5.5  5.0\n#&gt; 13  2.0  5.5\n#&gt; 14  4.5  5.5\n#&gt; 15  5.0  5.5\n#&gt; 16  5.5  5.5\n\nOgni riga rappresenta un campione possibile. Confermiamo il numero totale di campioni con:\n\nnrow(samples)\n#&gt; [1] 16\n\nOra calcoliamo la media di ciascun campione, ottenendo la distribuzione campionaria delle medie per \\(n = 2\\):\n\nsample_means &lt;- rowMeans(samples)\nsample_means\n#&gt;  [1] 2.00 3.25 3.50 3.75 3.25 4.50 4.75 5.00 3.50 4.75 5.00 5.25 3.75 5.00\n#&gt; [15] 5.25 5.50\n\nQuesta distribuzione campionaria mostra tutte le possibili medie che possiamo ottenere estraendo campioni casuali di dimensione 2 dalla popolazione. Si tratta di un concetto fondamentale in inferenza statistica frequentista, poiché la distribuzione delle medie campionarie diventa progressivamente più simmetrica e concentrata attorno alla media della popolazione man mano che \\(n\\) aumenta, come previsto dal teorema del limite centrale.\n\n86.3.3 Visualizzazione della distribuzione campionaria\nPossiamo visualizzare la distribuzione campionaria delle medie con un istogramma:\n\n# Creazione del dataframe\ndf &lt;- data.frame(Valori = sample_means)\n\n# Istogramma con ggplot2\nggplot(df, aes(x = Valori)) +\n  geom_histogram(bins = 5, aes(y = after_stat(density)), fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Distribuzione campionaria delle medie (n = 2)\", x = \"Media campionaria\", y = \"Densità\") \n\n\n\n\n\n\n\nL’istogramma mostra come le medie campionarie non siano distribuite uniformemente, ma seguano una struttura precisa determinata dalla distribuzione dei valori originali della popolazione. Con un numero maggiore di osservazioni per campione (\\(n\\) più grande), la distribuzione campionaria delle medie tende a diventare più stretta e simmetrica attorno alla media della popolazione, illustrando così il principio alla base dell’inferenza statistica frequentista.\n\n86.3.4 Verifiche teoriche\n\n86.3.4.1 Media della distribuzione campionaria\nSecondo la teoria statistica, la media della distribuzione campionaria deve coincidere con la media della popolazione. Questo implica che, se prendiamo la media di tutti i campioni possibili di una certa dimensione, il valore risultante sarà uguale alla media della popolazione stessa. Possiamo verificarlo con il seguente calcolo:\n\nmean(x)  # Media della popolazione\n#&gt; [1] 4.25\nmean(sample_means)  # Media della distribuzione campionaria\n#&gt; [1] 4.25\n\n\n86.3.4.2 Varianza della distribuzione campionaria\nUn altro risultato importante è che la varianza della distribuzione campionaria delle medie è inferiore alla varianza della popolazione. In particolare, la teoria prevede che sia pari alla varianza della popolazione divisa per la dimensione del campione \\(n\\):\n\\[\n\\mathbb{V}(\\bar{X}) = \\frac{\\sigma^2}{n}\n\\]\nPoiché in questo caso \\(n = 2\\), confrontiamo la varianza teorica con quella empirica:\n\n# Funzione per calcolare la varianza senza la correzione di Bessel\nvariance &lt;- function(x) {\n  mean((x - mean(x))^2)\n}\n\n\nvariance(x) / 2  # Varianza teorica\n#&gt; [1] 0.9062\nvariance(sample_means)  # Varianza empirica\n#&gt; [1] 0.9062\n\nOsserviamo che la varianza delle medie campionarie è inferiore alla varianza della popolazione, confermando che le medie campionarie mostrano meno variabilità rispetto alle singole osservazioni.\n\n86.3.5 Esempio di campione osservato\nPer comprendere meglio questi concetti, consideriamo un singolo campione, ad esempio:\n\nobserved_sample &lt;- c(5, 5.5)\nobserved_sample\n#&gt; [1] 5.0 5.5\n\nCalcoliamo la sua media e deviazione standard:\n\nmean(observed_sample)  # Media del campione\n#&gt; [1] 5.25\nsqrt(variance(observed_sample))  # Deviazione standard del campione\n#&gt; [1] 0.25\n\nOra confrontiamo questi valori con quelli della popolazione:\n\nmean(x)  # Media della popolazione\n#&gt; [1] 4.25\nsqrt(variance(x))  # Deviazione standard della popolazione\n#&gt; [1] 1.346\n\nOsserviamo che la media del campione si avvicina a quella della popolazione, ma non coincide necessariamente con essa. Questo è del tutto normale: ogni campione rappresenta solo una porzione della popolazione e la sua media può variare leggermente a seconda delle osservazioni selezionate.\nPer quanto riguarda la deviazione standard, in questo caso specifico risulta inferiore a quella della popolazione. Tuttavia, in generale, la dispersione di un singolo campione può essere maggiore o minore rispetto a quella della popolazione, poiché dipende dalla variabilità casuale delle osservazioni estratte. Proprio per questo motivo, per trarre inferenze affidabili sulla popolazione, è più utile considerare la distribuzione campionaria delle medie piuttosto che un singolo campione isolato.\nQuesto esempio illustra bene il principio della stima campionaria: mentre un singolo campione fornisce un’informazione parziale, l’analisi di molteplici campioni consente di ottenere una stima più precisa e stabile della media della popolazione, riducendo l’incertezza e migliorando l’affidabilità dell’inferenza statistica.\n\n86.3.6 La Simulazione Illustra Due Principi\nDalla simulazione emergono due principi fondamentali dell’inferenza statistica:\n\n\nLa media della distribuzione campionaria coincide con la media della popolazione. Questo implica che se estraiamo molteplici campioni di dimensione \\(n\\) e calcoliamo la loro media, il valore atteso della media campionaria sarà uguale alla media della popolazione \\(\\mu\\). Formalmente:\n\\[\n\\mathbb{E}(\\bar{X}_n) = \\mu .\n\\]\nQuesto risultato conferma che la media campionaria è uno stimatore non distorto della media della popolazione.\n\n\nLa varianza della distribuzione campionaria è minore della varianza della popolazione. Questo riflette il fatto che le medie campionarie tendono a essere più stabili rispetto alle singole osservazioni. La relazione teorica che descrive questa proprietà è:\n\\[\n\\mathbb{V}(\\bar{X}) = \\frac{\\sigma^2}{n} .\n\\]\nCiò significa che, aumentando la dimensione del campione \\(n\\), la variabilità delle medie campionarie si riduce, rendendo la stima della media della popolazione più precisa. Questo concetto è alla base della teoria del teorema centrale del limite, che diventa sempre più evidente con campioni di dimensioni maggiori.\n\n\n\n\n\n\n\n\nDimostrazione che \\(\\bar{X}\\) è uno stimatore corretto della media della popolazione\n\n\n\n\n\nDato un campione casuale di \\(n\\) osservazioni \\(X_1, X_2, \\dots, X_n\\) estratte da una popolazione con media \\(\\mu\\) e varianza \\(\\sigma^2\\), la media campionaria è definita come:\n\\[\n\\bar{X}_n = \\frac{1}{n} \\sum_{i=1}^{n} X_i .\n\\]\nUtilizziamo la linearità dell’operatore di aspettativa:\n\\[\n\\mathbb{E}(\\bar{X}_n) = \\mathbb{E} \\left( \\frac{1}{n} \\sum_{i=1}^{n} X_i \\right) .\n\\]\nPer la proprietà della linearità dell’aspettativa, possiamo portare fuori il fattore costante \\(\\frac{1}{n}\\):\n\\[\n\\mathbb{E}(\\bar{X}_n) = \\frac{1}{n} \\sum_{i=1}^{n} \\mathbb{E}(X_i) .\n\\]\nPoiché ogni \\(X_i\\) proviene dalla stessa popolazione, ha la stessa aspettativa \\(\\mathbb{E}(X_i) = \\mu\\), quindi:\n\\[\n\\mathbb{E}(\\bar{X}_n) = \\frac{1}{n} \\sum_{i=1}^{n} \\mu .\n\\]\nSommando \\(n\\) volte \\(\\mu\\), otteniamo:\n\\[\n\\mathbb{E}(\\bar{X}_n) = \\frac{1}{n} (n \\mu) = \\mu .\n\\]\nIn conclusione, abbiamo dimostrato che:\n\\[\n\\mathbb{E}(\\bar{X}_n) = \\mu .\n\\]\nQuesto significa che la media campionaria \\(\\bar{X}_n\\) è uno stimatore corretto (non distorto) della media della popolazione \\(\\mu\\), poiché il suo valore atteso coincide esattamente con la quantità che vogliamo stimare.\n\n\n\n\n\n\n\n\n\nDimostrazione della riduzione della varianza nelle medie campionarie\n\n\n\n\n\nSia \\(X_1, X_2, \\dots, X_n\\) un campione casuale di \\(n\\) osservazioni indipendenti estratte da una popolazione con media \\(\\mu\\) e varianza \\(\\sigma^2\\). La media campionaria è definita come:\n\\[\n\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i.\n\\]\nPer definizione, la varianza di \\(\\bar{X}\\) è:\n\\[\n\\mathbb{V}(\\bar{X}) = \\mathbb{V}\\left(\\frac{1}{n} \\sum_{i=1}^n X_i\\right).\n\\]\nPoiché una costante moltiplicata da una variabile aleatoria può essere “estratta” dalla varianza, otteniamo:\n\\[\n\\mathbb{V}(\\bar{X}) = \\frac{1}{n^2} \\mathbb{V}\\left(\\sum_{i=1}^n X_i\\right).\n\\]\nOra dobbiamo calcolare \\(\\mathbb{V}\\left(\\sum_{i=1}^n X_i\\right)\\). Le variabili \\(X_1, X_2, \\dots, X_n\\) sono indipendenti, quindi la varianza della somma è la somma delle varianze:\n\\[\n\\mathbb{V}\\left(\\sum_{i=1}^n X_i\\right) = \\sum_{i=1}^n \\mathbb{V}(X_i).\n\\]\nPoiché tutte le variabili \\(X_i\\) hanno la stessa varianza \\(\\sigma^2\\):\n\\[\n\\mathbb{V}\\left(\\sum_{i=1}^n X_i\\right) = n \\sigma^2.\n\\]\nSostituendo nella formula precedente, otteniamo:\n\\[\n\\mathbb{V}(\\bar{X}) = \\frac{1}{n^2} \\cdot n \\sigma^2 = \\frac{\\sigma^2}{n}.\n\\]\nIn generale, dunque, per un campione di ampiezza \\(n\\), vale la relazione \\(\\mathbb{V}(\\bar{X}) = \\frac{\\sigma^2}{n}\\).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01a_stime_parametri.html#proprietà-della-distribuzione-campionaria",
    "href": "chapters/frequentist_inference/01a_stime_parametri.html#proprietà-della-distribuzione-campionaria",
    "title": "86  Stime, stimatori e parametri",
    "section": "\n86.4 Proprietà della distribuzione campionaria",
    "text": "86.4 Proprietà della distribuzione campionaria\nUna caratteristica fondamentale della distribuzione campionaria riguarda la sua forma e il modo in cui dipende dalla distribuzione della popolazione da cui vengono estratti i campioni. Possiamo distinguere due casi principali:\n\nSe la popolazione segue una distribuzione normale, allora anche la distribuzione delle medie campionarie sarà normalmente distribuita, indipendentemente dalla dimensione del campione \\(n\\). Questo significa che, anche con campioni molto piccoli, la media campionaria manterrà la stessa forma della distribuzione originale.\nSe la popolazione non segue una distribuzione normale, entra in gioco il teorema centrale del limite. Questo teorema afferma che, man mano che la dimensione del campione \\(n\\) aumenta, la distribuzione delle medie campionarie tenderà comunque a una distribuzione normale, indipendentemente dalla forma della distribuzione di partenza. In pratica, per campioni sufficientemente grandi, possiamo approssimare la distribuzione delle medie campionarie con una normale, anche se la popolazione da cui provengono i dati è asimmetrica o non gaussiana.\n\nQueste proprietà sono fondamentali nell’inferenza statistica frequentista: permettono di stimare e testare parametri della popolazione utilizzando campioni, facilitando l’applicazione di strumenti basati sulla distribuzione normale, come gli intervalli di confidenza e i test di ipotesi.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01a_stime_parametri.html#teorema-del-limite-centrale",
    "href": "chapters/frequentist_inference/01a_stime_parametri.html#teorema-del-limite-centrale",
    "title": "86  Stime, stimatori e parametri",
    "section": "\n86.5 Teorema del Limite Centrale",
    "text": "86.5 Teorema del Limite Centrale\nEsaminiamo ora più in dettaglio il Teorema del Limite Centrale (TLC). Nel 1812, Pierre-Simon Laplace dimostrò il TLC, che afferma che la somma (o la media) di una sequenza di variabili casuali indipendenti e identicamente distribuite (i.i.d.) tende a distribuirsi secondo una distribuzione Normale (o Gaussiana), al crescere della dimensione del campione. Inoltre, il TLC specifica i parametri della distribuzione Normale risultante in base ai valori attesi e alle varianze delle variabili casuali sommate.\n\nTeorema 86.1 Si consideri una sequenza di variabili aleatorie indipendenti e identicamente distribuite (i.i.d.) \\(Y_1, Y_2, \\dots, Y_n\\), con valore atteso \\(\\mathbb{E}(Y_i) = \\mu\\) e deviazione standard \\(\\text{SD}(Y_i) = \\sigma.\\) Si definisca una nuova variabile casuale come la media campionaria:\n\\[\nZ = \\frac{1}{n} \\sum_{i=1}^n Y_i.\n\\]\nAl tendere di \\(n\\) all’infinito (\\(n \\rightarrow \\infty\\)), la distribuzione di \\(Z\\) converge a una distribuzione Normale con valore atteso \\(\\mu\\) e deviazione standard \\(\\frac{\\sigma}{\\sqrt{n}}\\):\n\\[\nZ \\sim \\mathcal{N}\\left(\\mu, \\, \\frac{\\sigma}{\\sqrt{n}} \\right).\n\\]\nIn altre parole, la densità di probabilità di \\(Z\\) tende a:\n\\[\np_Z(z) \\rightarrow \\mathcal{N}\\left(z \\ \\Bigg| \\ \\mu, \\, \\frac{\\sigma}{\\sqrt{n}} \\right).\n\\]\n\nIl TLC può essere generalizzato anche a variabili casuali che non sono identicamente distribuite, purché siano indipendenti e abbiano valori attesi e varianze finite. Questo teorema spiega perché molti fenomeni naturali, come l’altezza degli adulti o il peso di una popolazione, tendono a seguire una distribuzione Normale. Infatti, tali fenomeni sono spesso il risultato di una combinazione di numerosi effetti additivi e indipendenti, ciascuno dei quali contribuisce in modo relativamente piccolo. Indipendentemente dalla distribuzione individuale di ciascun effetto, la loro somma (o media) tende a distribuirsi in modo Normale. Questa è la ragione per cui la distribuzione Normale fornisce una buona approssimazione per la distribuzione di molti fenomeni osservati in natura.\n\n86.5.1 Illustrazione del Teorema del Limite Centrale (TLC)\nPer comprendere il Teorema del Limite Centrale (TLC), consideriamo una popolazione iniziale che segue una distribuzione fortemente asimmetrica: la distribuzione Beta(2,1), caratterizzata da una forte asimmetria positiva.\n\n# Parametri della distribuzione Beta\na &lt;- 2\nb &lt;- 1\n\n# Genera valori per la distribuzione Beta\nx &lt;- seq(0, 1, length.out = 1000)  # Valori tra 0 e 1\ny &lt;- dbeta(x, shape1 = a, shape2 = b)  # Densità della distribuzione Beta\n\n# Crea un dataframe per qplot\ndata &lt;- data.frame(x = x, y = y)\n\n# Grafico con qplot\nqplot(x, y, data = data, geom = \"line\", \n      main = \"Distribuzione Beta(2, 1)\", \n      xlab = \"x\", \n      ylab = \"Densità\")\n\n\n\n\n\n\n\nEstrarremo più volte campioni casuali di ampiezza \\(n\\) da questa popolazione e calcoleremo le medie campionarie. Il TLC prevede che, all’aumentare della dimensione del campione, la distribuzione delle medie campionarie tenda a una distribuzione normale, indipendentemente dalla forma della popolazione di partenza.\nPer verificare questa proprietà, definiamo una funzione che genera campioni, calcola le medie e visualizza la loro distribuzione campionaria per diversi valori di \\(n\\):\n\n# Parametri della distribuzione Beta\nalpha &lt;- 2\nbeta &lt;- 1\n\n# Funzione per simulare e visualizzare la distribuzione campionaria\nplot_samples &lt;- function(n) {\n  # Media e deviazione standard della distribuzione Beta\n  mu &lt;- alpha / (alpha + beta)\n  sigma &lt;- sqrt(alpha * beta / ((alpha + beta)^2 * (alpha + beta + 1)))\n  \n  # Generazione di 50.000 campioni casuali di dimensione n\n  sample_means &lt;- replicate(50000, mean(rbeta(n, alpha, beta)))\n  \n  # Creazione del dataframe\n  df &lt;- data.frame(MediaCampionaria = sample_means)\n  \n  # Creazione del grafico con ggplot2\n  ggplot(df, aes(x = MediaCampionaria)) +\n    geom_histogram(aes(y = after_stat(density)), bins = 50, fill = \"lightblue\", color = \"black\") +\n    stat_function(fun = dnorm, args = list(mean = mu, sd = sigma / sqrt(n)), color = \"black\", lwd = 1.2) +\n    labs(title = paste(\"Distribuzione campionaria per n =\", n),\n         x = \"Media campionaria\",\n         y = \"Densità\") +\n    theme_minimal()\n}\n\n\n86.5.1.1 Visualizzazione della convergenza alla normalità\nAnalizziamo l’effetto della dimensione del campione sulle medie campionarie:\n\n\nCampioni di ampiezza \\(n = 1\\)\nSe \\(n = 1\\), la distribuzione campionaria coincide esattamente con la distribuzione della popolazione di partenza, che in questo caso è fortemente asimmetrica:\n\nplot_samples(1)\n\n\n\n\n\n\n\n\n\nCampioni di ampiezza \\(n = 2\\)\nCon \\(n = 2\\), la distribuzione delle medie campionarie inizia a perdere parte della sua asimmetria:\n\nplot_samples(2)\n\n\n\n\n\n\n\n\n\nCampioni di ampiezza \\(n = 4\\)\nPer \\(n = 4\\), la distribuzione delle medie campionarie diventa più simmetrica e tende già a una forma più vicina a quella normale:\n\nplot_samples(4)\n\n\n\n\n\n\n\n\n\nCampioni di ampiezza \\(n = 30\\)\nQuando \\(n\\) diventa sufficientemente grande (ad esempio \\(n = 30\\)), la distribuzione campionaria delle medie è praticamente indistinguibile da una normale:\n\nplot_samples(30)\n\n\n\n\n\n\n\n\n\n86.5.1.2 Conclusione\nIl Teorema del Limite Centrale (TLC) afferma che, indipendentemente dalla forma della distribuzione della popolazione:\n\nSe la dimensione del campione è sufficientemente grande, la distribuzione delle medie campionarie \\(\\bar{X}\\) sarà approssimativamente normale, anche se la popolazione di partenza non lo è.\n\nLa distribuzione delle medie campionarie avrà media uguale a quella della popolazione \\(\\mu\\) e deviazione standard pari a:\n\\[\n\\bar{X} \\sim \\mathcal{N}(\\mu, \\sigma / \\sqrt{n})\n\\]\ndove \\(\\sigma\\) è la deviazione standard della popolazione e \\(n\\) è la dimensione del campione.\n\n\n86.5.2 Implicazioni\n\nNormalità emergente\nIl TLC giustifica l’uso della distribuzione normale in molte applicazioni statistiche, anche quando i dati originali non seguono una distribuzione normale.\nErrore standard e precisione delle stime\nIl TLC fornisce una formula esplicita per calcolare l’errore standard \\(\\sigma / \\sqrt{n}\\), che quantifica l’incertezza associata alla media campionaria. All’aumentare di \\(n\\), l’errore standard diminuisce, migliorando la precisione della stima della media della popolazione.\n\nQuesta proprietà è alla base di molte tecniche statistiche, come gli intervalli di confidenza e i test di ipotesi, che assumono la normalità della distribuzione campionaria delle medie anche quando la popolazione di partenza non è normale.\n\n86.5.3 Applicazioni in psicologia\nMolti fenomeni psicologici che misuriamo (ad esempio, il QI come media di molte abilità cognitive) derivano dalla media di più variabili, e quindi seguono la distribuzione normale grazie al TLC. Questo spiega perché la distribuzione normale appare così frequentemente nei dati sperimentali di psicologia e in molte altre discipline scientifiche.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01a_stime_parametri.html#distribuzioni-campionarie-di-altre-statistiche",
    "href": "chapters/frequentist_inference/01a_stime_parametri.html#distribuzioni-campionarie-di-altre-statistiche",
    "title": "86  Stime, stimatori e parametri",
    "section": "\n86.6 Distribuzioni campionarie di altre statistiche",
    "text": "86.6 Distribuzioni campionarie di altre statistiche\nAbbiamo già analizzato la distribuzione campionaria della media dei campioni. Tuttavia, è possibile costruire distribuzioni campionarie per altre statistiche campionarie. Ad esempio, consideriamo la distribuzione campionaria del valore massimo e della varianza.\n\n86.6.1 Distribuzione campionaria del valore massimo\nSupponiamo di avere una popolazione normalmente distribuita con media \\(\\mu = 100\\) e deviazione standard \\(\\sigma = 15\\). Generiamo 10.000 campioni casuali di ampiezza \\(n = 5\\) e calcoliamo il valore massimo per ogni campione.\n\n86.6.1.1 Simulazione e visualizzazione\n\nset.seed(123)  # Per risultati riproducibili\n\n# Parametri della distribuzione\nmu &lt;- 100\nsigma &lt;- 15\n\n# Simulazione: calcolo del valore massimo per ciascun campione\nn_samples &lt;- 10000\nsample_maxes &lt;- replicate(\n  n_samples, \n  max(rnorm(5, mean = mu, sd = sigma))\n)\n\n# Creazione del dataframe\ndf &lt;- data.frame(ValoreMassimo = sample_maxes)\n\n# Istogramma con ggplot2\nggplot(df, aes(x = ValoreMassimo)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 50, fill = \"lightblue\", color = \"black\") +\n  stat_function(fun = dnorm, args = list(mean = mu, sd = sigma), color = \"black\", lwd = 1.2) +\n  labs(title = \"Distribuzione campionaria del valore massimo\",\n       x = \"Valore massimo\",\n       y = \"Densità\")\n\n\n\n\n\n\n\nOsserviamo che il valore atteso della distribuzione campionaria del massimo è maggiore della media della popolazione \\(\\mu\\).\n\n86.6.2 Distribuzione campionaria della varianza\nUn’altra statistica interessante è la varianza campionaria. La formula della varianza campionaria, basata sulla statistica descrittiva, è:\n\\[\nS^2 = \\frac{\\sum_{i=1}^n (Y_i - \\bar{Y})^2}{n}.\n\\]\nCalcoliamo la distribuzione campionaria della varianza per campioni di ampiezza \\(n = 5\\).\n\n86.6.2.1 Simulazione e visualizzazione\n\nset.seed(123)\n\n# Parametri della distribuzione\nmu &lt;- 100\nsigma &lt;- 15\nn_samples &lt;- 10000\n\n# Funzione per calcolare la varianza senza la correzione di Bessel\nvariance &lt;- function(x) {\n  mean((x - mean(x))^2)  # Divisione per n invece di (n-1)\n}\n\n# Simulazione: calcolo della varianza per ciascun campione\nsample_vars &lt;- replicate(\n  n_samples, \n  variance(rnorm(5, mean = mu, sd = sigma))\n)\n\n# Creazione del dataframe\ndf &lt;- data.frame(Varianza = sample_vars)\n\n# Istogramma con ggplot2\nggplot(df, aes(x = Varianza)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 50, fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Distribuzione campionaria della varianza\",\n       x = \"Varianza\",\n       y = \"Densità\")\n\n\n\n\n\n\n\n\n# Media empirica della varianza campionaria\nmean(sample_vars)\n#&gt; [1] 180.7\n\nSappiamo che la varianza della popolazione è \\(\\sigma^2 = 15^2 = 225\\). Tuttavia, il valore medio empirico delle varianze campionarie calcolate con \\(S^2\\) risulta minore di 225. Questo avviene perché lo stimatore \\(S^2\\) è distorto.\n\n86.6.3 Correzione della distorsione\nPer eliminare la distorsione, utilizziamo il seguente stimatore della varianza della popolazione:\n\\[\ns^2 = \\frac{\\sum_{i=1}^n (Y_i - \\bar{Y})^2}{n-1}.\n\\]\n\n86.6.3.1 Verifica con simulazione\n\nset.seed(123)\n\n# Simulazione: calcolo della varianza con la correzione\nsample_vars_unbiased &lt;- replicate(\n  n_samples, \n  var(rnorm(5, mean = mu, sd = sigma))\n)\n\n# Creazione del dataframe\ndf &lt;- data.frame(Varianza = sample_vars_unbiased)\n\n# Istogramma con ggplot2\nggplot(df, aes(x = Varianza)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 50, fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Distribuzione campionaria della varianza (corretta)\",\n       x = \"Varianza\",\n       y = \"Densità\")\n\n\n\n\n\n\n\n\n# Media empirica della varianza corretta\nmean(sample_vars_unbiased)\n#&gt; [1] 225.8\n\nCon questo stimatore, la media della distribuzione campionaria coincide con la varianza reale della popolazione \\(\\sigma^2 = 225\\).\nIn conclusione:\n\nLa distribuzione campionaria del massimo mostra che il valore massimo dei campioni è, in media, maggiore della media della popolazione.\nLa varianza campionaria non corretta (\\(S^2\\)) è uno stimatore distorto, poiché il suo valore atteso non coincide con la varianza della popolazione.\nLo stimatore corretto \\(s^2\\), che utilizza il divisore \\(n - 1\\), elimina la distorsione e fornisce una stima non distorta della varianza della popolazione.\n\nIn generale, uno stimatore è considerato non distorto quando il valore atteso delle sue stime coincide con il valore reale del parametro. Nel caso della media campionaria e della varianza corretta, entrambi gli stimatori sono non distorti.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01a_stime_parametri.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/01a_stime_parametri.html#riflessioni-conclusive",
    "title": "86  Stime, stimatori e parametri",
    "section": "\n86.7 Riflessioni Conclusive",
    "text": "86.7 Riflessioni Conclusive\nIn generale, i parametri della popolazione sono sconosciuti, ma possiamo stimarli utilizzando le informazioni del campione. Di seguito viene presentata una tabella che riassume i simboli comuni utilizzati per indicare le quantità note e sconosciute nel contesto dell’inferenza statistica. Questo ci aiuterà a tenere traccia di ciò che sappiamo e ciò che non sappiamo.\n\n\n\n\n\n\n\nSimbolo\nNome\nÈ qualcosa che conosciamo?\n\n\n\n\\(s\\)\nDeviazione standard del campione\nSì, la calcoliamo dai dati grezzi\n\n\n\\(\\sigma\\)\nDeviazione standard della popolazione\nNo, tranne in casi particolari o nelle simulazioni\n\n\n\\(\\hat{\\sigma}\\)\nStima della deviazione standard della popolazione\nSì, ma non è uguale a \\(\\sigma\\)\n\n\n\n\\(s^2\\)\nVarianza del campione\nSì, la calcoliamo dai dati grezzi\n\n\n\\(\\sigma^2\\)\nVarianza della popolazione\nNo, tranne in casi particolari o nelle simulazioni\n\n\n\\(\\hat{\\sigma}^2\\)\nStima della varianza della popolazione\nSì, ma non è uguale a \\(\\sigma^2\\)\n\n\n\n\n\nUtilizzando le informazioni di un campione casuale di ampiezza \\(n\\):\n\nLa stima migliore che possiamo ottenere per la media \\(\\mu\\) della popolazione è la media del campione \\(\\bar{Y}\\).\nLa stima migliore che possiamo ottenere per la varianza \\(\\sigma^2\\) della popolazione è:\n\n\\[\n\\hat{\\sigma}^2 = \\frac{1}{n-1} \\sum_{i=1}^n (Y_i - \\bar{Y})^2.\n\\]\n\n\n\n\n\n\nRisposte alle domande iniziali\n\n\n\n\n\nDopo aver esplorato il concetto di distribuzione campionaria attraverso simulazioni ed esempi pratici, possiamo ora confrontare le nostre risposte intuitive con quanto appreso:\n\nLe medie campionarie tendono a distribuirsi intorno alla media della popolazione, con una variabilità che dipende dalla dimensione del campione.\nSì, le medie campionarie sono meno disperse rispetto ai singoli valori della popolazione, il che significa che forniscono una stima più stabile della media della popolazione.\nAll’aumentare di \\(n\\), la distribuzione campionaria delle medie diventa più stretta, ossia la variabilità delle medie campionarie si riduce. La varianza della distribuzione campionaria è pari a \\(\\sigma^2 / n\\), dove \\(\\sigma^2\\) è la varianza della popolazione.\nNo, la distribuzione campionaria della media è normale solo se la popolazione di partenza è normale o se la dimensione del campione è sufficientemente grande (Teorema del Limite Centrale).\nSì, la media della distribuzione campionaria coincide con la media della popolazione. Tuttavia, la varianza della distribuzione campionaria è inferiore alla varianza della popolazione, poiché viene divisa per la dimensione del campione (\\(n\\)).\nPer campioni piccoli, la distribuzione delle medie campionarie somiglierà alla distribuzione della popolazione originale. Se la popolazione è fortemente asimmetrica, anche la distribuzione campionaria per piccoli campioni sarà asimmetrica. Tuttavia, aumentando \\(n\\), la distribuzione delle medie campionarie tenderà a una normale, indipendentemente dalla forma della popolazione di partenza.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01a_stime_parametri.html#esercizi",
    "href": "chapters/frequentist_inference/01a_stime_parametri.html#esercizi",
    "title": "86  Stime, stimatori e parametri",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nParte 1: Popolazione di Piccole Dimensioni Si consideri una popolazione con i seguenti valori:\n\\[\nx = \\{2, 4.5, 5, 5.5\\}\n\\]\n\nCalcolare la media e la varianza della popolazione.\nEstrarre tutti i possibili campioni di ampiezza \\(n = 2\\) con ripetizione e calcolare la media di ciascun campione.\nRappresentare graficamente la distribuzione campionaria delle medie.\nCalcolare la probabilità che la media campionaria sia inferiore a 3:\n\nEsattamente, utilizzando la distribuzione campionaria.\nApprossimativamente, assumendo una distribuzione normale se il campione fosse sufficientemente grande.\n\n\n\nParte 2: Popolazione di Grandi Dimensioni\nSi consideri ora una popolazione più grande, generata da una distribuzione normale con media \\(\\mu = 10\\) e deviazione standard \\(\\sigma = 3\\).\n\nGenerare una popolazione di 1000 osservazioni.\nCalcolare la media e la varianza della popolazione.\nEstrarre 10.000 campioni casuali di ampiezza \\(n = 15\\) e calcolare la media campionaria per ciascun campione.\nRappresentare graficamente la distribuzione campionaria delle medie.\nCalcolare la probabilità che la media campionaria sia inferiore a 9:\n\nEsattamente, utilizzando la distribuzione campionaria.\nApprossimativamente, utilizzando la distribuzione normale.\n\n\n\nObiettivo: Verificare sperimentalmente le proprietà della distribuzione campionaria della media e confrontare i risultati con le previsioni teoriche fornite dal Teorema del Limite Centrale.\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\nProprietà della Distribuzione Campionaria della Media\n\nMedia: La media della distribuzione campionaria coincide con la media della popolazione:\nVarianza: La varianza della distribuzione campionaria è pari alla varianza della popolazione divisa per la dimensione del campione:\nForma:\n\n\nSe la popolazione segue una distribuzione normale, anche la distribuzione campionaria della media sarà normale.\nSe la popolazione non è normale, il Teorema del Limite Centrale garantisce che la distribuzione campionaria della media sarà approssimativamente normale per campioni di dimensioni sufficientemente grandi (\\(n \\geq 30\\)).\n\nDefiniamo una popolazione e calcoliamo i parametri:\n\n# Popolazione\nx &lt;- c(2, 4.5, 5, 5.5)\nmean(x)  # Media della popolazione\n#&gt; [1] 4.25\nvar(x)   # Varianza della popolazione\n#&gt; [1] 2.417\n\nEstrarre tutti i possibili campioni di ampiezza \\(n = 2\\) e calcolare la media di ciascun campione:\n\n# Tutti i campioni di ampiezza 2\nsamples &lt;- expand.grid(x, x)\nsample_means &lt;- rowMeans(samples)\n\n# Visualizzare la distribuzione campionaria\ndf &lt;- data.frame(sample_means = sample_means)\n\nggplot(df, aes(x = sample_means)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 5, fill = \"blue\", alpha = 0.6) +\n  geom_density(color = \"red\", size = 1) +\n  labs(\n    title = \"Distribuzione campionaria delle medie\",\n    x = \"Media campionaria\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\nCalcoliamo la probabilità che, all’interno della distribuzione campionaria, la media del campione sia minore di 3. Troviamo il valore esatto nella simulazione. Approssimiamo il valore esatto con il valore atteso se il campione fosse sufficientemente grande da poter assumere una distribuzione campionaria normale:\n\n# Probabilità esatta dalla distribuzione campionaria\nexact_probability &lt;- mean(sample_means &lt; 3)\nexact_probability\n#&gt; [1] 0.0625\n\n# Approssimazione tramite distribuzione normale\nmu &lt;- mean(x)  # Media della popolazione\nsigma &lt;- sqrt(var(x) / 2)  # Deviazione standard della distribuzione campionaria\napprox_probability &lt;- pnorm(3, mean = mu, sd = sigma)\napprox_probability\n#&gt; [1] 0.1277\n\nRipetiamo ora l’esempio, mantenendo la stessa struttura della simulazione, ma considerando una popolazione più grande tale per cui si possa estrarre un campione di ampiezza 15:\n\n# Nuova popolazione\nset.seed(123)\nx_large &lt;- rnorm(1000, mean = 10, sd = 3)  # Popolazione più grande\nmean(x_large)  # Media della popolazione\n#&gt; [1] 10.05\nvar(x_large)   # Varianza della popolazione\n#&gt; [1] 8.851\n\n# Estrazione di campioni di ampiezza 15\nsamples_large &lt;- replicate(10000, mean(sample(x_large, size = 15)))\n\n# Creazione del data frame per ggplot2\ndf_large &lt;- data.frame(sample_means = samples_large)\n\n# Visualizzazione con ggplot2\nggplot(df_large, aes(x = sample_means)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 50, fill = \"blue\", alpha = 0.6) +\n  geom_density(color = \"red\", size = 1) +\n  labs(\n    title = \"Distribuzione campionaria delle medie (n = 15)\",\n    x = \"Media campionaria\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\n\n# Probabilità esatta dalla simulazione\nexact_probability_large &lt;- mean(samples_large &lt; 9)\nexact_probability_large\n#&gt; [1] 0.0834\n\n\n# Approssimazione tramite distribuzione normale\nmu_large &lt;- mean(x_large)\nsigma_large &lt;- sqrt(var(x_large) / 15)\napprox_probability_large &lt;- pnorm(9, mean = mu_large, sd = sigma_large)\napprox_probability_large\n#&gt; [1] 0.08616\n\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nDistribuzione Campionaria della Differenza tra Medie\nL’obiettivo di questo esercizio è esplorare le proprietà della distribuzione campionaria della differenza tra medie campionarie, analizzando sia il caso di popolazioni finite di piccole dimensioni sia il caso di popolazioni più grandi, con distribuzioni normali.\nEsercizio 1: Simulazione con Popolazioni di Piccole Dimensioni\nConsideriamo due popolazioni finite composte da un numero limitato di elementi:\n\n\nPopolazione 1: \\(x_1 = \\{2, 4.5, 5, 6\\}\\)\n\n\nPopolazione 2: \\(x_2 = \\{3, 3.5, 4, 7\\}\\)\n\n\n\n86.7.0.1 Compiti:\n\n\n\nCalcolo dei parametri delle popolazioni:\n\nDeterminare la media e la varianza di entrambe le popolazioni.\n\n\n\nEstrazione di campioni:\n\nEstrarre tutti i possibili campioni di ampiezza \\(n = 2\\) con ripetizione da entrambe le popolazioni.\nCalcolare la media campionaria di ciascun campione.\n\n\n\nDistribuzione campionaria della differenza tra le medie:\n\nCalcolare la differenza tra le medie di tutti i possibili campioni ottenuti dalle due popolazioni.\nRappresentare graficamente la distribuzione della differenza tra le medie.\n\n\n\nProbabilità della differenza tra le medie:\n\nCalcolare la probabilità che la differenza tra le medie campionarie sia maggiore di 1.\n\n\n\nEsercizio 2: Simulazione con Popolazioni di Grande Dimensione\nConsideriamo ora due popolazioni più grandi, distribuite normalmente:\n\n\nPopolazione 1: \\(X_1 \\sim N(10, 4^2)\\) (media = 10, deviazione standard = 4)\n\nPopolazione 2: \\(X_2 \\sim N(8, 3^2)\\) (media = 8, deviazione standard = 3)\n\nCompiti:\n\n\nGenerazione delle popolazioni:\n\nCreare due popolazioni casuali di 10.000 osservazioni ciascuna, distribuite normalmente.\n\n\n\nEstrazione di campioni:\n\nEstrarre 10.000 campioni casuali di ampiezza \\(n_1 = 15\\) dalla prima popolazione e \\(n_2 = 20\\) dalla seconda popolazione.\nCalcolare la media di ciascun campione.\n\n\n\nDistribuzione campionaria della differenza tra le medie:\n\nCalcolare la differenza tra le medie campionarie ottenute dalle due popolazioni.\nRappresentare graficamente la distribuzione della differenza tra le medie.\n\n\n\nProbabilità della differenza tra le medie:\n\nCalcolare la probabilità che la differenza tra le medie campionarie sia maggiore di 2 in due modi:\n\n\nMetodo empirico: utilizzando la distribuzione ottenuta nella simulazione.\n\nMetodo teorico: approssimando la distribuzione con una normale e calcolando la probabilità con la formula teorica della varianza della differenza tra le medie.\n\n\n\n\n\nDomande di Discussione\n\nCome cambia la forma della distribuzione campionaria al variare delle dimensioni dei campioni \\(n_1\\) e \\(n_2\\)?\nLa probabilità stimata tramite simulazione coincide con quella calcolata utilizzando l’approssimazione normale? Perché?\nCosa accadrebbe alla distribuzione campionaria se le popolazioni originali non fossero normali? Quale sarebbe il ruolo del Teorema del Limite Centrale?\n\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\nEsercizio 1: Simulazione con Popolazioni di Piccola Dimensione\nSupponiamo di avere due popolazioni finite definite come segue:\n\nPopolazione 1: \\(x_1 = \\{2, 4.5, 5, 6\\}\\)\n\nPopolazione 2: \\(x_2 = \\{3, 3.5, 4, 7\\}\\)\n\n\n\nCalcola le medie e le varianze delle due popolazioni:\n\n\n# Popolazione 1\nx1 &lt;- c(2, 4.5, 5, 6)\nmean(x1)  # Media di x1\n#&gt; [1] 4.375\nvar(x1)   # Varianza di x1\n#&gt; [1] 2.896\n\n\n# Popolazione 2\nx2 &lt;- c(3, 3.5, 4, 7)\nmean(x2)  # Media di x2\n#&gt; [1] 4.375\nvar(x2)   # Varianza di x2\n#&gt; [1] 3.229\n\n\nEstrai tutti i possibili campioni di ampiezza \\(n = 2\\) da entrambe le popolazioni:\n\n\n# Tutti i campioni di ampiezza 2\nsamples1 &lt;- expand.grid(x1, x1)\nsamples2 &lt;- expand.grid(x2, x2)\n\n# Medie campionarie\nsample_means1 &lt;- rowMeans(samples1)\nsample_means2 &lt;- rowMeans(samples2)\n\n\nCalcola la differenza tra le medie campionarie di ciascuna combinazione di campioni:\n\n\n# Differenze tra le medie campionarie\nsample_diff &lt;- as.vector(outer(sample_means1, sample_means2, \"-\"))\n\n\nVisualizza la distribuzione campionaria della differenza tra le medie:\n\n\n# Istogramma della differenza tra medie campionarie\n\n# Creazione del data frame per ggplot2\ndf_diff &lt;- data.frame(sample_diff = sample_diff)\n\n# Visualizzazione con ggplot2\nggplot(df_diff, aes(x = sample_diff)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 10, fill = \"blue\", alpha = 0.6) +\n  geom_density(color = \"red\", size = 1) +\n  labs(\n    title = \"Distribuzione campionaria della differenza tra medie\",\n    x = \"Differenza campionaria\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\n\nCalcola la probabilità che la differenza campionaria sia maggiore di 1:\n\n\n# Probabilità esatta dalla distribuzione campionaria\nexact_probability &lt;- mean(sample_diff &gt; 1)\nexact_probability\n#&gt; [1] 0.2656\n\nEsercizio 2: Simulazione con Popolazioni di Grande Dimensione\nOra considera due popolazioni più grandi con distribuzioni normali:\n\nPopolazione 1: \\(X_1 \\sim N(10, 4^2)\\)\n\nPopolazione 2: \\(X_2 \\sim N(8, 3^2)\\)\n\n\n\nGenera due popolazioni casuali:\n\n\nset.seed(123)\npop1 &lt;- rnorm(10000, mean = 10, sd = 4)\npop2 &lt;- rnorm(10000, mean = 8, sd = 3)\n\n\nEstrai 10.000 campioni casuali di ampiezza \\(n_1 = 15\\) e \\(n_2 = 20\\) rispettivamente:\n\n\n# Estrazione di campioni e calcolo delle medie\nsample_means1 &lt;- replicate(10000, mean(sample(pop1, size = 15)))\nsample_means2 &lt;- replicate(10000, mean(sample(pop2, size = 20)))\n\n\nCalcola la differenza tra le medie campionarie:\n\n\n# Differenze tra medie campionarie\nsample_diff_large &lt;- sample_means1 - sample_means2\n\n\nVisualizza la distribuzione campionaria della differenza tra le medie:\n\n\n# Istogramma della distribuzione campionaria\n\n# Creazione del data frame per ggplot2\ndf_diff_large &lt;- data.frame(sample_diff = sample_diff_large)\n\n# Visualizzazione con ggplot2\nggplot(df_diff_large, aes(x = sample_diff)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 50, fill = \"blue\", alpha = 0.6) +\n  geom_density(color = \"red\", size = 1) +\n  labs(\n    title = \"Distribuzione campionaria della differenza tra medie (n1 = 15, n2 = 20)\",\n    x = \"Differenza campionaria\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\n\n\nCalcola la probabilità che la differenza campionaria sia maggiore di 2 utilizzando:\n\nla simulazione;\nl’approssimazione normale.\n\n\n\n\n# Probabilità esatta\nexact_probability_large &lt;- mean(sample_diff_large &gt; 2)\nexact_probability_large\n#&gt; [1] 0.505\n\n\n# Approssimazione normale\nmu_diff &lt;- 10 - 8  # Differenza tra le medie delle popolazioni\nsigma_diff &lt;- sqrt(4^2 / 15 + 3^2 / 20)  # Deviazione standard della differenza\napprox_probability_large &lt;- 1 - pnorm(2, mean = mu_diff, sd = sigma_diff)\napprox_probability_large\n#&gt; [1] 0.5\n\nDomande di Discussione.\n\nCome cambia la forma della distribuzione campionaria al variare delle dimensioni campionarie \\(n_1\\) e \\(n_2\\)?\nLa probabilità calcolata tramite simulazione coincide con quella calcolata tramite approssimazione normale? Perché?\nCosa accadrebbe alla distribuzione campionaria se le popolazioni originali non fossero normali?\n\n\n\n\n\n\n\n\n\n\nProblemi 3\n\n\n\n\n\nProblema: Distribuzione Campionaria di una Proporzione\nL’obiettivo di questo esercizio è esplorare la distribuzione campionaria di una proporzione campionaria \\(\\hat{p}\\) e verificare l’applicabilità dell’approssimazione normale per grandi dimensioni campionarie, come previsto dal Teorema del Limite Centrale.\nSituazione\nSupponiamo di avere una popolazione infinita in cui ciascun individuo può appartenere a una di due categorie: “successo” (codificato come 1) o “insuccesso” (codificato come 0). La probabilità di successo nella popolazione è data da \\(p = 0.6\\).\nCompiti\n\n\nDefinizione della popolazione e dei parametri:\n\nLa popolazione ha una proporzione di successi pari a \\(p = 0.6\\).\nLa deviazione standard teorica della distribuzione campionaria della proporzione è calcolata come:\\[\n\\text{SD}(\\hat{p}) = \\sqrt{\\frac{p(1 - p)}{n}}\n\\]\n\nSi fissi una dimensione campionaria pari a \\(n = 100\\).\n\n\n\nSimulazione di campioni:\n\nGenerare 10.000 campioni casuali di ampiezza \\(n = 100\\).\nPer ogni campione, calcolare la proporzione campionaria \\(\\hat{p}\\), cioè la frazione di successi nel campione.\n\n\n\nDistribuzione campionaria delle proporzioni:\n\nRappresentare graficamente la distribuzione delle proporzioni campionarie con un istogramma.\nSovrapporre la distribuzione normale teorica \\(N(p, \\text{SD}(\\hat{p}))\\) per confrontare l’andamento empirico con quello teorico.\n\n\n\nAnalisi della distribuzione:\n\nValutare se la distribuzione campionaria ottenuta rispetta l’approssimazione normale.\nRiflettere su come la dimensione del campione e il valore di \\(p\\) influenzano questa approssimazione.\n\n\n\nDomande di Discussione\n\nLa distribuzione campionaria delle proporzioni \\(\\hat{p}\\) sembra approssimarsi a una distribuzione normale? Perché?\nCosa accadrebbe se la dimensione del campione fosse più piccola, ad esempio \\(n = 30\\)?\nSe la probabilità di successo \\(p\\) fosse molto vicina a 0 o 1, l’approssimazione normale sarebbe ancora valida? Perché?\n\n\n\n\n\n\n\n\n\n\nSoluzioni 3\n\n\n\n\n\nLa distribuzione campionaria di una proporzione descrive come la proporzione campionaria (\\(\\hat{p}\\)) varia tra campioni di una popolazione. Per campioni grandi, il Teorema del Limite Centrale garantisce che la distribuzione campionaria di \\(\\hat{p}\\) può essere approssimata con una distribuzione normale.\n\n\nSupponiamo una popolazione infinita in cui la probabilità di successo (\\(p\\)) è \\(p = 0.6\\). Scegli una dimensione campionaria \\(n = 100\\).\nSimula 10.000 campioni casuali di ampiezza \\(n\\) e calcola le proporzioni campionarie (\\(\\hat{p}\\)).\nConfronta l’istogramma delle proporzioni campionarie con la distribuzione normale teorica approssimativa.\n\n\n# Parametri della popolazione\np &lt;- 0.6  # Probabilità di successo nella popolazione\nn &lt;- 100  # Dimensione del campione\n\n# Simulazione di 10.000 campioni\nset.seed(123)\nsample_props &lt;- replicate(10000, mean(rbinom(n, size = 1, prob = p)))\n\n# Creazione di un data frame per ggplot2\ndf_props &lt;- data.frame(sample_props = sample_props)\n\n# Parametri della distribuzione normale teorica\nmean_theoretical &lt;- p\nsd_theoretical &lt;- sqrt(p * (1 - p) / n)\n\n# Visualizzazione con ggplot2\nggplot(df_props, aes(x = sample_props)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 40, fill = \"blue\", alpha = 0.6) +\n  stat_function(\n    fun = dnorm,\n    args = list(mean = mean_theoretical, sd = sd_theoretical),\n    color = \"red\",\n    size = 1\n  ) +\n  labs(\n    title = \"Distribuzione campionaria di una proporzione (n = 100)\",\n    x = \"Proporzione campionaria (\\u0302p)\",\n    y = \"Densità\"\n  ) \n\n\n\n\n\n\n\n\n\nPopolazione e parametri:\n\nLa popolazione è definita da \\(p = 0.6\\).\nLa deviazione standard teorica della distribuzione campionaria è calcolata come \\(\\text{SD}(\\hat{p}) = \\sqrt{\\frac{p(1-p)}{n}}\\).\n\n\n\nSimulazione:\n\nPer ogni campione, i successi (\\(0\\) o \\(1\\)) sono generati con rbinom, e la proporzione campionaria \\(\\hat{p}\\) è calcolata come media.\n\n\n\nGrafico:\n\nL’istogramma delle proporzioni campionarie è sovrapposto alla curva normale teorica (\\(N(p, \\text{SD}(\\hat{p}))\\)).\n\n\n\nDomande di Discussione.\n\nLa distribuzione campionaria di \\(\\hat{p}\\) sembra approssimarsi a una distribuzione normale? Perché?\nCosa accadrebbe se \\(n\\) fosse più piccolo (es. \\(n = 30\\))?\nSe \\(p\\) fosse più vicino a \\(0\\) o \\(1\\), l’approssimazione normale sarebbe ancora valida? Spiega.\n\n\n\n\n\n\n\n\n\n\nProblemi 4\n\n\n\n\n\nProblema: Distribuzione Campionaria della Differenza tra Due Proporzioni\nL’obiettivo di questo esercizio è esplorare la distribuzione campionaria della differenza tra due proporzioni campionarie, \\(\\hat{p}_1 - \\hat{p}_2\\), ottenute da due campioni indipendenti estratti da popolazioni diverse. Per campioni sufficientemente grandi, il Teorema del Limite Centrale garantisce che la distribuzione di \\(\\hat{p}_1 - \\hat{p}_2\\) può essere approssimata con una distribuzione normale.\nSituazione\nAbbiamo due popolazioni con proporzioni di successo diverse:\n\n\nPopolazione 1 ha una proporzione di successo \\(p_1 = 0.6\\).\n\nPopolazione 2 ha una proporzione di successo \\(p_2 = 0.4\\).\n\nVogliamo studiare il comportamento della distribuzione campionaria della differenza tra le proporzioni campionarie quando preleviamo campioni indipendenti da ciascuna popolazione.\nCompiti\n\n\nDefinizione delle popolazioni e dei parametri:\n\nLa proporzione di successi nelle due popolazioni è \\(p_1 = 0.6\\) e \\(p_2 = 0.4\\).\nEntrambi i campioni hanno dimensione \\(n_1 = n_2 = 150\\).\nLa deviazione standard teorica della distribuzione campionaria della differenza tra proporzioni è calcolata come: \\[\n\\text{SD}(\\hat{p}_1 - \\hat{p}_2) = \\sqrt{\\frac{p_1 (1-p_1)}{n_1} + \\frac{p_2 (1-p_2)}{n_2}}\n\\]\n\n\n\n\nSimulazione di campioni:\n\nGenerare 10.000 campioni indipendenti di ampiezza \\(n_1 = 150\\) dalla prima popolazione e \\(n_2 = 150\\) dalla seconda popolazione.\nCalcolare la proporzione campionaria \\(\\hat{p}_1\\) e \\(\\hat{p}_2\\) per ciascun campione.\nCalcolare la differenza tra le proporzioni campionarie.\n\n\n\nDistribuzione campionaria della differenza tra le proporzioni:\n\nRappresentare graficamente la distribuzione di \\(\\hat{p}_1 - \\hat{p}_2\\) con un istogramma.\nSovrapporre la distribuzione normale teorica \\(N(p_1 - p_2, \\text{SD}(\\hat{p}_1 - \\hat{p}_2))\\) per confrontare l’andamento empirico con quello teorico.\n\n\n\nCalcolo della probabilità che la differenza tra proporzioni sia maggiore di un valore specifico:\n\n\nMetodo empirico: calcolare la proporzione di campioni in cui \\(\\hat{p}_1 - \\hat{p}_2 &gt; 0.1\\).\n\nMetodo teorico: utilizzare la distribuzione normale approssimata per stimare la probabilità che \\(\\hat{p}_1 - \\hat{p}_2 &gt; 0.1\\).\n\n\n\nDomande di Discussione\n\nL’approssimazione normale è valida in questo caso? Perché?\nCome cambierebbe la distribuzione campionaria se la dimensione del campione \\(n_1\\) o \\(n_2\\) fosse più piccola?\nSe i valori di \\(p_1\\) o \\(p_2\\) fossero più vicini a 0 o 1, come cambierebbe la probabilità calcolata e l’accuratezza dell’approssimazione normale?\n\n\n\n\n\n\n\n\n\n\nSoluzioni 4\n\n\n\n\n\nLa distribuzione campionaria della differenza tra due proporzioni (\\(\\hat{p}_1 - \\hat{p}_2\\)) descrive come la differenza tra le proporzioni campionarie varia tra due campioni indipendenti estratti da due popolazioni.\nPer campioni grandi, il Teorema del Limite Centrale garantisce che \\(\\hat{p}_1 - \\hat{p}_2\\) segue approssimativamente una distribuzione normale con media e varianza calcolate dalle proporzioni della popolazione.\nObiettivo:\n\nSimulare due popolazioni con proporzioni \\(p_1\\) e \\(p_2\\).\nEstrarre campioni indipendenti da ciascuna popolazione.\nCalcolare la distribuzione campionaria di \\(\\hat{p}_1 - \\hat{p}_2\\).\nCalcolare la probabilità che la differenza campionaria sia maggiore di un valore specifico (es. \\(0.1\\)).\n\nParametri del Problema:\n\nPopolazione 1: \\(p_1 = 0.6\\)\n\nPopolazione 2: \\(p_2 = 0.4\\)\n\nDimensione campionaria: \\(n_1 = n_2 = 150\\)\n\nValore specifico: \\(0.1\\)\n\n\n\n# Parametri delle due popolazioni\np1 &lt;- 0.6  # Proporzione di successi nella Popolazione 1\np2 &lt;- 0.4  # Proporzione di successi nella Popolazione 2\nn1 &lt;- 150  # Dimensione campionaria per la Popolazione 1\nn2 &lt;- 150  # Dimensione campionaria per la Popolazione 2\n\n# Simulazione di 10.000 campioni indipendenti\nset.seed(123)\nsample_p1 &lt;- replicate(10000, mean(rbinom(n1, size = 1, prob = p1)))\nsample_p2 &lt;- replicate(10000, mean(rbinom(n2, size = 1, prob = p2)))\n\n# Calcolo della differenza tra proporzioni campionarie\nsample_diff &lt;- sample_p1 - sample_p2\n\n# Parametri teorici della distribuzione normale approssimata\nmean_diff &lt;- p1 - p2\nsd_diff &lt;- sqrt((p1 * (1 - p1) / n1) + (p2 * (1 - p2) / n2))\n\n# Creazione del data frame per ggplot2\ndf_diff &lt;- data.frame(sample_diff = sample_diff)\n\n# Visualizzazione con ggplot2\nggplot(df_diff, aes(x = sample_diff)) +\n  geom_histogram(\n    aes(y = after_stat(density)), bins = 40, fill = \"blue\", alpha = 0.6\n  ) +\n  stat_function(\n    fun = dnorm,\n    args = list(mean = mean_diff, sd = sd_diff),\n    color = \"red\",\n    size = 1\n  ) +\n  labs(\n    title = \"Distribuzione campionaria della differenza tra proporzioni\",\n    x = \"Differenza campionaria (p1 - p2)\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\n\n# Calcolo della probabilità che la differenza sia maggiore di 0.1\nexact_probability &lt;- mean(sample_diff &gt; 0.1)\nexact_probability\n#&gt; [1] 0.9599\n\n\n# Approssimazione tramite distribuzione normale\napprox_probability &lt;- 1 - pnorm(0.1, mean = mean_diff, sd = sd_diff)\napprox_probability\n#&gt; [1] 0.9615\n\n\n\nParametri delle popolazioni:\n\nDue popolazioni con proporzioni \\(p_1 = 0.6\\) e \\(p_2 = 0.4\\).\nDimensioni campionarie \\(n_1 = n_2 = 150\\).\n\n\n\nSimulazione:\n\nPer ogni campione, i successi (\\(0\\) o \\(1\\)) sono generati con rbinom.\nCalcoliamo le proporzioni campionarie e la differenza tra di esse.\n\n\n\nDistribuzione teorica:\n\nMedia teorica: \\(p_1 - p_2\\).\nDeviazione standard teorica: \\(\\sqrt{\\frac{p_1 (1-p_1)}{n_1} + \\frac{p_2 (1-p_2)}{n_2}}\\).\n\n\n\nVisualizzazione:\n\nUn istogramma di \\(\\hat{p}_1 - \\hat{p}_2\\) sovrapposto alla curva della distribuzione normale teorica.\n\n\n\nCalcolo della probabilità:\n\nProbabilità esatta dalla simulazione: proporzione di \\(\\hat{p}_1 - \\hat{p}_2 &gt; 0.1\\).\nProbabilità approssimata dalla distribuzione normale.\n\n\n\nDomande di Discussione.\n\nL’approssimazione normale è valida in questo caso? Perché?\nCome cambierebbe la distribuzione campionaria se \\(n_1\\) o \\(n_2\\) fossero più piccoli?\nCome influenzerebbe la probabilità calcolata un valore \\(p_1\\) o \\(p_2\\) più vicino a \\(0\\) o \\(1\\)?",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01a_stime_parametri.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/01a_stime_parametri.html#informazioni-sullambiente-di-sviluppo",
    "title": "86  Stime, stimatori e parametri",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.7   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.13.0 psych_2.5.3     \n#&gt;  [9] scales_1.4.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.3.0     ggplot2_3.5.2   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.4     stringi_1.8.7      lattice_0.22-7    \n#&gt;  [4] hms_1.1.3          digest_0.6.37      magrittr_2.0.3    \n#&gt;  [7] evaluate_1.0.4     grid_4.5.0         timechange_0.3.0  \n#&gt; [10] RColorBrewer_1.1-3 fastmap_1.2.0      rprojroot_2.0.4   \n#&gt; [13] jsonlite_2.0.0     mnormt_2.1.1       cli_3.6.5         \n#&gt; [16] rlang_1.1.6        withr_3.0.2        tools_4.5.0       \n#&gt; [19] parallel_4.5.0     tzdb_0.5.0         pacman_0.5.1      \n#&gt; [22] vctrs_0.6.5        R6_2.6.1           lifecycle_1.0.4   \n#&gt; [25] htmlwidgets_1.6.4  pkgconfig_2.0.3    pillar_1.10.2     \n#&gt; [28] gtable_0.3.6       glue_1.8.0         xfun_0.52         \n#&gt; [31] tidyselect_1.2.1   rstudioapi_0.17.1  farver_2.1.2      \n#&gt; [34] htmltools_0.5.8.1  nlme_3.1-168       labeling_0.4.3    \n#&gt; [37] rmarkdown_2.29     compiler_4.5.0",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html",
    "href": "chapters/frequentist_inference/02_conf_interv.html",
    "title": "87  Intervalli di fiducia",
    "section": "",
    "text": "87.1 Introduzione\nGli intervalli di confidenza sono uno strumento fondamentale nell’inferenza statistica frequentista. Essi consentono di stimare un parametro sconosciuto di una popolazione, come la media \\(\\mu\\), tenendo conto dell’incertezza derivante dal fatto che la stima si basa su un campione. Questo materiale didattico si propone di spiegare in modo dettagliato e chiaro la costruzione di un intervallo di confidenza per la media di una popolazione, sia nel caso di varianza nota sia in quello di varianza incognita.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#inferenza-statistica-frequentista-e-media-campionaria",
    "href": "chapters/frequentist_inference/02_conf_interv.html#inferenza-statistica-frequentista-e-media-campionaria",
    "title": "87  Intervalli di fiducia",
    "section": "\n87.2 Inferenza Statistica Frequentista e Media Campionaria",
    "text": "87.2 Inferenza Statistica Frequentista e Media Campionaria\nQuando estraiamo un campione casuale semplice \\(X_1, X_2, \\dots, X_n\\) da una popolazione con media \\(\\mu\\) e varianza \\(\\sigma^2\\), la media campionaria \\(\\bar{X}\\) è definita come:\n\\[\n\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i.\n\\]\nLa media campionaria \\(\\bar{X}\\) è una variabile casuale perché dipende dai valori osservati nel campione, che sono essi stessi casuali. Le proprietà della media campionaria sono le seguenti:\n\n\nMedia della distribuzione campionaria: \\(E[\\bar{X}] = \\mu\\). La media campionaria è uno stimatore non distorto della media della popolazione.\n\nVarianza della distribuzione campionaria: \\(\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n}\\). Questo significa che la precisione di \\(\\bar{X}\\) come stima di \\(\\mu\\) aumenta con il numero di osservazioni \\(n\\).\n\nQueste proprietà sono fondamentali per calcolare un intervallo di confidenza, poiché ci permettono di descrivere la distribuzione di \\(\\bar{X}\\).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#intervallo-di-confidenza-per-la-media-caso-di-varianza-nota",
    "href": "chapters/frequentist_inference/02_conf_interv.html#intervallo-di-confidenza-per-la-media-caso-di-varianza-nota",
    "title": "87  Intervalli di fiducia",
    "section": "\n87.3 Intervallo di Confidenza per la Media: Caso di Varianza Nota",
    "text": "87.3 Intervallo di Confidenza per la Media: Caso di Varianza Nota\nSupponiamo che la popolazione sia distribuita normalmente con media \\(\\mu\\) e varianza \\(\\sigma^2\\), e che \\(\\sigma^2\\) sia nota. La distribuzione della media campionaria \\(\\bar{X}\\) è anch’essa normale:\n\\[\n\\bar{X} \\sim \\mathcal{N}\\left(\\mu, \\frac{\\sigma^2}{n}\\right).\n\\]\nPasso 1: Standardizzazione della Media Campionaria.\nPer lavorare con una distribuzione normale standard (media 0 e varianza 1), standardizziamo \\(\\bar{X}\\) utilizzando la formula:\n\\[\nZ = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}}.\n\\]\nQui, \\(\\sigma / \\sqrt{n}\\) è la deviazione standard della distribuzione campionaria di \\(\\bar{X}\\).\nDopo questa trasformazione, la variabile \\(Z\\) segue una distribuzione normale standard:\n\\[\nZ \\sim \\mathcal{N}(0, 1).\n\\]\nPasso 2: Determinazione del Livello di Confidenza.\nScegliamo un livello di confidenza \\(\\gamma\\), ad esempio \\(\\gamma = 0.95\\). Per una distribuzione normale standard, troviamo il valore critico \\(z\\) tale che la probabilità tra \\(-z\\) e \\(+z\\) sia pari al livello di confidenza:\n\\[\nP(-z \\leq Z \\leq z) = \\gamma.\n\\]\nPer un livello di confidenza del 95%, \\(z \\approx 1.96\\).\nPasso 3: Formulazione dell’Intervallo di Confidenza.\nPartiamo dalla probabilità per \\(Z\\):\n\\[\nP(-z \\leq Z \\leq z) = \\gamma.\n\\]\nSostituiamo la definizione di \\(Z\\):\n\\[\nP\\left(-z \\leq \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}} \\leq z\\right) = \\gamma.\n\\]\nMoltiplichiamo tutti i membri per \\(\\sigma / \\sqrt{n}\\) per rimuovere il denominatore:\n\\[\nP\\left(-z \\cdot \\frac{\\sigma}{\\sqrt{n}} \\leq \\bar{X} - \\mu \\leq z \\cdot \\frac{\\sigma}{\\sqrt{n}}\\right) = \\gamma.\n\\]\nAggiungiamo \\(\\mu\\) a tutti i membri per isolare \\(\\mu\\):\n\\[\nP\\left(\\bar{X} - z \\cdot \\frac{\\sigma}{\\sqrt{n}} \\leq \\mu \\leq \\bar{X} + z \\cdot \\frac{\\sigma}{\\sqrt{n}}\\right) = \\gamma.\n\\]\nPasso 4: Limiti dell’Intervallo di Confidenza.\nDefiniamo i limiti inferiore e superiore dell’intervallo di confidenza:\n\\[\n\\hat{a} = \\bar{X} - z \\cdot \\frac{\\sigma}{\\sqrt{n}}, \\quad \\hat{b} = \\bar{X} + z \\cdot \\frac{\\sigma}{\\sqrt{n}}.\n\\]\nL’intervallo di confidenza per \\(\\mu\\) è quindi:\n\\[\n(\\hat{a}, \\hat{b}) = \\left(\\bar{X} - z \\cdot \\frac{\\sigma}{\\sqrt{n}}, \\bar{X} + z \\cdot \\frac{\\sigma}{\\sqrt{n}}\\right).\n\\]",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#intervallo-di-confidenza-per-la-media-caso-di-varianza-incognita",
    "href": "chapters/frequentist_inference/02_conf_interv.html#intervallo-di-confidenza-per-la-media-caso-di-varianza-incognita",
    "title": "87  Intervalli di fiducia",
    "section": "\n87.4 Intervallo di Confidenza per la Media: Caso di Varianza Incognita",
    "text": "87.4 Intervallo di Confidenza per la Media: Caso di Varianza Incognita\nNella maggior parte dei casi pratici, la varianza \\(\\sigma^2\\) non è nota. In questi casi, stimiamo \\(\\sigma\\) con la deviazione standard campionaria \\(s\\) e utilizziamo la distribuzione t di Student, che tiene conto dell’incertezza aggiuntiva.\nPasso 1: Distribuzione t di Student.\nLa statistica che seguiamo è:\n\\[\nT = \\frac{\\bar{X} - \\mu}{s / \\sqrt{n}},\n\\]\ndove \\(T\\) segue una distribuzione t con \\(n-1\\) gradi di libertà.\nPasso 2: Costruzione dell’Intervallo di Confidenza.\nAnalogamente al caso precedente, costruiamo l’intervallo partendo da:\n\\[\nP(-t^\\ast \\leq T \\leq t^\\ast) = \\gamma,\n\\]\ndove \\(t^\\ast\\) è il valore critico della distribuzione t per il livello di confidenza \\(\\gamma\\) e \\(n-1\\) gradi di libertà.\nSostituendo \\(T\\):\n\\[\nP\\left(-t^\\ast \\leq \\frac{\\bar{X} - \\mu}{s / \\sqrt{n}} \\leq t^\\ast\\right) = \\gamma.\n\\]\nMoltiplichiamo per \\(s / \\sqrt{n}\\):\n\\[\nP\\left(-t^\\ast \\cdot \\frac{s}{\\sqrt{n}} \\leq \\bar{X} - \\mu \\leq t^\\ast \\cdot \\frac{s}{\\sqrt{n}}\\right) = \\gamma.\n\\]\nAggiungiamo \\(\\mu\\):\n\\[\nP\\left(\\bar{X} - t^\\ast \\cdot \\frac{s}{\\sqrt{n}} \\leq \\mu \\leq \\bar{X} + t^\\ast \\cdot \\frac{s}{\\sqrt{n}}\\right) = \\gamma.\n\\]\nPasso 3: Limiti dell’Intervallo.\nI limiti dell’intervallo sono:\n\\[\n\\hat{a} = \\bar{X} - t^\\ast \\cdot \\frac{s}{\\sqrt{n}}, \\quad \\hat{b} = \\bar{X} + t^\\ast \\cdot \\frac{s}{\\sqrt{n}}.\n\\]\nIn conclusione, gli intervalli di confidenza forniscono un modo per quantificare l’incertezza nelle stime di parametri sconosciuti. La loro costruzione dipende dalla distribuzione campionaria dello stimatore e dall’informazione disponibile sulla varianza.\n\n87.4.1 Applicabilità e Limitazioni\n\nIl metodo presuppone che la popolazione segua una distribuzione normale e è valido anche per campioni di piccole dimensioni (ad esempio, \\(n &lt; 30\\)) prelevati da tale popolazione.\nSe la popolazione non è normalmente distribuita e la dimensione del campione è ridotta, questo metodo potrebbe non essere idoneo.\nTuttavia, per campioni di grandi dimensioni (\\(n \\geq 30\\)), questo approccio rimane valido per la stima dell’intervallo di confidenza grazie al teorema del limite centrale, che si applica anche a popolazioni con distribuzioni non normali.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#livello-di-copertura",
    "href": "chapters/frequentist_inference/02_conf_interv.html#livello-di-copertura",
    "title": "87  Intervalli di fiducia",
    "section": "\n87.5 Livello di Copertura",
    "text": "87.5 Livello di Copertura\nPer interpretare correttamente gli intervalli di fiducia è fondamentale considerare il concetto di “livello di copertura”. Questo livello indica la frequenza con cui l’intervallo di fiducia include il valore reale del parametro della popolazione, in una serie di esperimenti ripetuti.\nEsempio di Livello di Copertura:\n\nSe il livello di copertura è del 95%, significa che, nel lungo periodo, il 95% degli intervalli di fiducia costruiti conterrà il valore vero del parametro.\nImportante: Questo non implica che ci sia una probabilità del 95% che il valore vero del parametro cada in un particolare intervallo di fiducia. Infatti, il parametro della popolazione è un valore fisso e non soggetto a probabilità; piuttosto, l’incertezza risiede nell’intervallo di fiducia stesso.\n\nCome Funziona la Copertura:\n\nNel contesto frequentista, la “probabilità” si riferisce alla frequenza a lungo termine di un certo evento in un gran numero di ripetizioni dell’esperimento.\nNel caso degli intervalli di fiducia, l’“esperimento” è l’estrazione di un campione dalla popolazione, e l’“evento” è la generazione di un intervallo di fiducia che contiene il valore vero del parametro.\nIl livello di copertura, generalmente indicato come \\(1-\\alpha\\), rappresenta la probabilità a lungo termine che intervalli di fiducia costruiti con questa metodologia includano il vero valore del parametro.\n\n\n87.5.1 Simulazione\n\nPer illustrare questo concetto, eseguiamo una simulazione con la popolazione degli adulti maschi italiani, assunta come normalmente distribuita con media 175 cm e varianza 49 cm².\nEseguiamo 1000 ripetizioni di un esperimento, estraendo ogni volta un campione di 30 individui.\nPer ciascun campione, calcoliamo l’intervallo di fiducia al 95% usando la formula:\n\n\\[\n\\bar{X} \\pm t \\frac{s}{\\sqrt{n}},\n\\]\ndove \\(\\bar{X}\\) è la media campionaria, \\(s\\) è la deviazione standard campionaria e \\(t\\) è il valore critico della distribuzione t-Student per \\(n-1\\) gradi di libertà al livello di significatività \\(\\alpha/2 = 0.025\\). - Registriamo i limiti di ciascun intervallo e controlliamo quanti di essi includono effettivamente il vero valore medio della popolazione.\nAttraverso questa simulazione, possiamo visualizzare concretamente il concetto di livello di copertura e la sua importanza nella statistica frequentista.\nIn questa simulazione, genereremo 1000 campioni casuali di dimensione \\(n = 30\\) da una distribuzione normale con media \\(\\mu = 175\\) e deviazione standard \\(\\sigma = 7\\). Successivamente, calcoleremo gli intervalli di confidenza al 95% per ciascun campione e valuteremo il livello di copertura.\n\nset.seed(123)  # Per riproducibilità\n\n# Parametri della distribuzione\nmu &lt;- 175\nsigma &lt;- 7\nn &lt;- 30\nn_samples &lt;- 1000\n\n# Generazione dei campioni\nsamples &lt;- replicate(n_samples, rnorm(n, mean = mu, sd = sigma))\ndim(samples)  # Verifica dimensioni: 30 righe per 1000 colonne\n#&gt; [1]   30 1000\n\nIl primo campione di ampiezza \\(n = 30\\) che abbiamo ottenuto è il seguente:\n\nsamples[, 1]  # Primo campione\n#&gt;  [1] 171.1 173.4 185.9 175.5 175.9 187.0 178.2 166.1 170.2 171.9 183.6 177.5\n#&gt; [13] 177.8 175.8 171.1 187.5 178.5 161.2 179.9 171.7 167.5 173.5 167.8 169.9\n#&gt; [25] 170.6 163.2 180.9 176.1 167.0 183.8\n\nStampiamo le medie dei primi dieci campioni:\n\nsample_means &lt;- colMeans(samples)  # Medie di tutti i campioni\nsample_means[1:10]  # Prime dieci medie\n#&gt;  [1] 174.7 176.2 175.2 174.3 173.7 176.1 175.1 174.4 175.4 177.4\n\nTroviamo il valore critico della distribuzione \\(t\\) di Student con \\(n - 1\\) gradi di libertà e livello di confidenza del 95% (\\(\\alpha = 0.05\\)):\n\nalpha &lt;- 0.05\nt_critical &lt;- qt(1 - alpha / 2, df = n - 1)  # Valore critico\nt_critical\n#&gt; [1] 2.045\n\nUtilizzando il valore critico \\(t\\), calcoliamo 1000 intervalli di confidenza per la media della popolazione:\n\n# Calcolo della deviazione standard campionaria\nsample_sds &lt;- apply(samples, 2, sd)\n\n# Ampiezza degli intervalli\ninterval_width &lt;- t_critical * sample_sds / sqrt(n)\n\n# Limiti degli intervalli di confidenza\nCI_low &lt;- sample_means - interval_width\nCI_high &lt;- sample_means + interval_width\n\nTroviamo il livello di copertura, ovvero la proporzione di intervalli di confidenza che contengono il vero valore della media della popolazione \\(\\mu\\):\n\ncoverage &lt;- mean(CI_low &lt; mu & mu &lt; CI_high)  # Proporzione di copertura\ncoverage\n#&gt; [1] 0.956\n\nIn conclusione, ripetendo la simulazione per 1000 campioni, abbiamo ottenuto un livello di copertura molto vicino al valore nominale di \\(1 - \\alpha = 0.95\\). Questo risultato dimostra che, con un campione di dimensione \\(n = 30\\), gli intervalli di confidenza al 95% calcolati utilizzando la distribuzione \\(t\\) di Student forniscono stime accurate della media della popolazione.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#il-concetto-di-livello-di-confidenza",
    "href": "chapters/frequentist_inference/02_conf_interv.html#il-concetto-di-livello-di-confidenza",
    "title": "87  Intervalli di fiducia",
    "section": "\n87.6 Il Concetto di Livello di Confidenza",
    "text": "87.6 Il Concetto di Livello di Confidenza\nGli intervalli di confidenza sono range di valori che, con una certa sicurezza statistica, si ritiene includano il parametro di interesse.\nSecondo l’approccio frequentista, l’intervallo di confidenza si deve considerare come una metodologia:\n\nSe ripetiamo l’esperimento (estrarre un campione e calcolare l’intervallo di confidenza) molte volte, il metodo produce un intervallo che coprirà il valore vero del parametro nel 95% dei casi, assumendo un livello di confidenza del 95%.\n\n\n87.6.1 Un Malinteso Comune nell’Interpretazione degli Intervalli di Confidenza\nÈ inesatto affermare che un determinato intervallo di confidenza contenga il valore vero di un parametro con una probabilità del 95%. Questo è un errore diffuso, persino tra i ricercatori, che spesso interpretano l’intervallo di confidenza come indicativo della probabilità che il parametro (ad esempio, la media della popolazione \\(\\mu\\)) si trovi effettivamente all’interno di un dato intervallo (es. \\([\\hat{a}, \\hat{b}]\\)).\nLa descrizione corretta è la seguente:\n\n“La metodologia impiegata per calcolare l’intervallo \\([\\hat{a}, \\hat{b}]\\) ha il 95% di probabilità di generare un intervallo che include il vero valore del parametro”.\nCiò significa che l’intervallo di confidenza non esprime una probabilità circa la posizione precisa del parametro, ma riflette la probabilità che la procedura adottata per determinarlo generi un intervallo che lo includa.\n\nIn conclusione, l’intervallo di confidenza ci fornisce una garanzia statistica riguardo alla affidabilità del metodo usato per la sua stima, piuttosto che sulla esatta ubicazione del parametro in questione.\n\n87.6.2 Fraintendimenti Comuni sugli Intervalli di Confidenza\nNel loro lavoro, Hoekstra et al. (2014) evidenziano come, nonostante l’ampio riconoscimento dei limiti dei test di ipotesi nulle, gli intervalli di confidenza siano spesso consigliati per l’inferenza statistica. Anche l’American Psychological Association (APA) suggerisce che gli intervalli di confidenza siano “in generale, la migliore strategia di reportistica”. Tuttavia, Hoekstra et al. (2014) sottolineano che queste raccomandazioni non considerano la difficoltà nel fornire una corretta interpretazione degli intervalli di confidenza.\nPer indagare l’interpretazione degli intervalli di confidenza, Hoekstra et al. (2014) hanno condotto uno studio con due domande principali:\n\nQuanto frequentemente intervalli di confidenza sono mal interpretati da studenti e ricercatori?\nL’esperienza nella ricerca riduce le interpretazioni errate degli intervalli di confidenza?\n\nPrima di presentare lo studio, Hoekstra et al. (2014) ricordano qual è l’interpretazione corretta degli intervalli di confidenza.\n\nA CI is a numerical interval constructed around the estimate of a parameter. Such an interval does not, however, directly indicate a property of the parameter; instead, it indicates a property of the procedure, as is typical for a frequentist technique. Specifically, we may find that a particular procedure, when used repeatedly across a series of hypothetical data sets (i.e., the sample space), yields intervals that contain the true parameter value in 95% of the cases. When such a procedure is applied to a particular data set, the resulting interval is said to be a 95% CI. The key point is that the CIs do not provide for a statement about the parameter as it relates to the particular sample at hand; instead, they provide for a statement about the performance of the procedure of drawing such intervals in repeated use. Hence, it is incorrect to interpret a CI as the probability that the true value is within the interval (e.g., Berger & Wolpert, 1988). As is the case with \\(p\\)-values, CIs do not allow one to make probability statements about parameters or hypotheses.\n\nNel loro studio, Hoekstra et al. (2014) hanno presentato un questionario a 596 partecipanti, tra cui studenti universitari e ricercatori, con le seguenti affermazioni riguardanti l’interpretazione degli intervalli di confidenza.\n\nProfessor Bumbledorf conducts an experiment, analyzes the data, and reports: “The 95% confidence interval for the mean ranges from 0.1 to 0.4.” Please mark each of the statements below as ‘true’ or ‘false’.\n\n\n\nThe probability that the true mean is greater than 0 is at least 95%.\nThe probability that the true mean equals 0 is smaller than 5%.\nThe “null hypothesis” that the true mean equals 0 is likely to be incorrect.\nThere is a 95% probability that the true mean lies between 0.1 and 0.4.\nWe can be 95% confident that the true mean lies between 0.1 and 0.4.\nIf we were to repeat the experiment over and over, then 95% of the time the true mean falls between 0.1 and 0.4.\n\n\nSorprendentemente, anche se tutte le sei affermazioni nel questionario sono errate, molti partecipanti hanno concordato con esse. I risultati mostrano che, in media, i partecipanti hanno concordato con circa 3.5 affermazioni errate su 6. Non è stata rilevata una differenza di rilievo nell’interpretazione degli intervalli di confidenza tra studenti e ricercatori, suggerendo che l’esperienza nella ricerca non migliora la comprensione di questo concetto.\nI risultati indicano che molte persone interpretano erroneamente gli intervalli di confidenza, e che anche l’esperienza nella ricerca non garantisce una migliore comprensione. Questo solleva dubbi sull’efficacia degli intervalli di confidenza frequentisti e suggerisce che gli “intervalli di credibilità” bayesiani possano rappresentare un’alternativa più vantaggiosa. Quest’ultimi tendono ad essere più intuitivi e di più facile interpretazione corretta.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#confronto-tra-intervalli-frequentisti-e-bayesiani",
    "href": "chapters/frequentist_inference/02_conf_interv.html#confronto-tra-intervalli-frequentisti-e-bayesiani",
    "title": "87  Intervalli di fiducia",
    "section": "\n87.7 Confronto tra Intervalli Frequentisti e Bayesiani",
    "text": "87.7 Confronto tra Intervalli Frequentisti e Bayesiani\nConcludiamo questo capitolo esaminando le differenze tra l’intervallo di confidenza frequentista e l’intervallo di credibilità bayesiano, utilizzando lo stesso set di dati per entrambi i calcoli.\n\n87.7.1 Intervallo di confidenza frequentista\nImmaginiamo di avere un gruppo di 20 osservazioni relative alla performance in un test cognitivo. Il nostro obiettivo è stimare la media della popolazione da cui queste osservazioni sono tratte. Supponiamo che i dati provengano da una distribuzione normale con media \\(\\mu = 50\\) e deviazione standard \\(\\sigma = 10\\).\n\nset.seed(123)  # Per risultati riproducibili\n\n# Parametri della popolazione\nsample_size &lt;- 20\nmu &lt;- 50\nsigma &lt;- 10\n\n# Simulazione del campione\nsample_data &lt;- rnorm(sample_size, mean = mu, sd = sigma)\nprint(sample_data)\n#&gt;  [1] 44.40 47.70 65.59 50.71 51.29 67.15 54.61 37.35 43.13 45.54 62.24 53.60\n#&gt; [13] 54.01 51.11 44.44 67.87 54.98 30.33 57.01 45.27\n\nVisualizziamo la distribuzione dei dati:\n\ntibble(Valori = sample_data) |&gt;\n  ggplot(aes(x = Valori)) +\n  geom_histogram(aes(y = after_stat(density)),\n    bins = 30, # Puoi regolare il numero di bin\n    fill = \"skyblue\",\n    color = \"black\",\n    alpha = 0.7\n  ) +\n  labs(\n    title = \"Distribuzione dei dati campionari\",\n    x = \"Valori\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\nLa media campionaria (\\(\\hat{\\mu}\\)) viene calcolata come:\n\\[\n\\hat{\\mu} = \\frac{1}{n} \\sum_{i=1}^n X_i\n\\]\nIn R:\n\nsample_mean &lt;- mean(sample_data)\nsample_mean\n#&gt; [1] 51.42\n\nLa deviazione standard campionaria (\\(s\\)) si calcola come:\n\\[\ns = \\sqrt{\\frac{\\sum_{i=1}^n (X_i - \\bar{X})^2}{n-1}}\n\\]\nIn R:\n\nvariance &lt;- function(x) {\n  sum((x - mean(x))^2) / length(x)\n}\n\nsample_sd &lt;- sqrt(variance(sample_data))  # Deviazione standard campionaria\nsample_sd\n#&gt; [1] 9.48\n\nL’errore standard della media (\\(SE\\)) è:\n\\[\nSE = \\frac{s}{\\sqrt{n}}\n\\]\nIn R:\n\nstandard_error &lt;- sample_sd / sqrt(sample_size)\nstandard_error\n#&gt; [1] 2.12\n\nUn intervallo di confidenza è definito come:\n\\[\n\\bar{X} \\pm t_{\\text{critico}} \\cdot SE\n\\]\ndove \\(t_{\\text{critico}}\\) è il valore critico della distribuzione \\(t\\) di Student per un livello di confidenza del 95% (\\(\\alpha = 0.05\\)) e \\(n-1\\) gradi di libertà. In R:\n\nalpha &lt;- 0.05\ndf &lt;- sample_size - 1\nt_critical &lt;- qt(1 - alpha / 2, df)\nt_critical\n#&gt; [1] 2.093\n\nCalcoliamo il margine di errore:\n\nmargin_of_error &lt;- t_critical * standard_error\nmargin_of_error\n#&gt; [1] 4.437\n\nCalcoliamo i limiti inferiore e superiore dell’intervallo di confidenza:\n\nconfidence_interval &lt;- \n  c(sample_mean - margin_of_error, sample_mean + margin_of_error)\nconfidence_interval\n#&gt; [1] 46.98 55.85\n\nPossiamo interpretare questo risultato dicendo che la procedura utilizzata per calcolare l’intervallo include il valore vero della media della popolazione nel 95% dei casi.\nCreiamo un grafico per mostrare la distribuzione dei dati, la media campionaria e l’intervallo di confidenza:\n\ntibble(Valori = sample_data) |&gt;\n  ggplot(aes(x = Valori)) +\n  geom_histogram(aes(y = ..density..),\n    bins = 30, # Puoi regolare il numero di bin\n    fill = \"skyblue\",\n    color = \"black\",\n    alpha = 0.7\n  ) +\n\n  # Linea per la media campionaria\n  geom_vline(aes(xintercept = sample_mean),\n    color = \"blue\",\n    linetype = \"dashed\",\n    linewidth = 1.2\n  ) +\n\n  # Linee per l'intervallo di confidenza\n  geom_vline(aes(xintercept = confidence_interval[1]),\n    color = \"darkgreen\",\n    linewidth = 1.2\n  ) +\n  geom_vline(aes(xintercept = confidence_interval[2]),\n    color = \"darkgreen\",\n    linewidth = 1.2\n  ) +\n\n  # Titoli e assi\n  labs(\n    title = \"Intervallo di Confidenza per la Media\",\n    x = \"Valori\",\n    y = \"Densità\"\n  ) +\n\n  # Legenda personalizzata\n  annotate(\"text\",\n    x = sample_mean, y = 0.02, label = \"Media campionaria\",\n    color = \"blue\", angle = 90, vjust = -0.5\n  ) +\n  annotate(\"text\",\n    x = confidence_interval[1], y = 0.02, label = \"IC Inferiore\",\n    color = \"darkgreen\", angle = 90, vjust = -0.5\n  ) +\n  annotate(\"text\",\n    x = confidence_interval[2], y = 0.02, label = \"IC Superiore\",\n    color = \"darkgreen\", angle = 90, vjust = -0.5\n  )\n\n\n\n\n\n\n\n\n87.7.1.1 Confronto tra gli Approcci Frequentista e Bayesiano\nIntervallo di Credibilità Bayesiano:\n\nRappresenta il grado di credenza (posteriori) che il parametro \\(\\mu\\) si trovi all’interno dell’intervallo calcolato.\nDipende sia dai dati osservati sia dalle distribuzioni a priori utilizzate nel modello, che possono influenzare il risultato in base alla loro specificità o vaghezza.\n\nIntervallo di Confidenza Frequentista:\n\nNon esprime la probabilità che il parametro \\(\\mu\\) appartenga a un determinato intervallo.\nSi riferisce invece alla procedura di costruzione dell’intervallo: se il campionamento fosse ripetuto infinite volte, il 95% degli intervalli costruiti conterrebbe il vero valore di \\(\\mu\\).\n\nIn sintesi:\n\nL’intervallo di credibilità bayesiano fornisce una stima probabilistica diretta e interpretabile della posizione di \\(\\mu\\), basata su dati osservati e informazioni a priori.\nL’intervallo di confidenza frequentista, invece, valuta la affidabilità della procedura nel lungo termine, senza fare affermazioni dirette sulla probabilità che il parametro rientri nell’intervallo specifico.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/02_conf_interv.html#riflessioni-conclusive",
    "title": "87  Intervalli di fiducia",
    "section": "\n87.8 Riflessioni Conclusive",
    "text": "87.8 Riflessioni Conclusive\nCome sottolineato da Hoekstra et al. (2014), è comune riscontrare fraintendimenti riguardo agli intervalli di fiducia. Il “livello di confidenza del 95%” è da interpretarsi come la probabilità a lungo termine che, in una serie di intervalli di fiducia calcolati, il 95% di essi includa il vero valore del parametro sconosciuto. Tuttavia, per un singolo intervallo di fiducia, non è possibile dichiarare con sicurezza che questo contenga effettivamente il parametro di interesse. In altre parole, la certezza sulla presenza del parametro sconosciuto all’interno di un dato intervallo di fiducia non è garantita per ogni singolo caso analizzato.\nÈ inoltre inesatto presumere che esista un legame diretto tra la varianza e la media di un campione, ipotizzando che un intervallo di fiducia più ristretto implichi maggiore precisione. Nella prospettiva frequentista, la “precisione” è strettamente legata al livello di copertura a lungo termine assicurato dal metodo usato per creare gli intervalli di fiducia. Questo concetto non si applica al singolo intervallo di fiducia osservato. Dunque, un intervallo di fiducia che si presenta estremamente ristretto potrebbe in realtà essere significativamente lontano dal valore vero del parametro non noto.\nÈ importante sottolineare che l’approccio frequentista offre un metodo per calcolare gli intervalli di confidenza per una vasta gamma di statistiche. Questo include, ad esempio, la stima dell’intervallo di confidenza per la differenza tra due medie, per una proporzione o per la differenza tra due proporzioni. Ecco le formule per calcolare gli intervalli di confidenza per i casi menzionati:\nIntervallo di confidenza per la differenza tra due medie.\nSe abbiamo due campioni indipendenti di dimensione \\(n_1\\) e \\(n_2\\), con medie \\(\\bar{x}_1\\) e \\(\\bar{x}_2\\) e deviazioni standard \\(s_1\\) e \\(s_2\\), l’intervallo di confidenza per la differenza tra le medie è calcolato come:\n\\[\n(\\bar{x}_1 - \\bar{x}_2) \\pm t_{\\alpha/2} \\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}},\n\\]\ndove \\(t_{\\alpha/2}\\) è il valore critico della distribuzione t di Student con \\(\\alpha/2\\) di probabilità di coda e gradi di libertà \\(df = n_1 + n_2 - 2\\).\nIntervallo di confidenza per una proporzione.\nPer stimare l’intervallo di confidenza per una proporzione \\(p\\) in un campione binomiale di dimensione \\(n\\), la formula è:\n\\[\n\\hat{p} \\pm z_{\\alpha/2} \\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}},\n\\]\ndove \\(\\hat{p}\\) è la proporzione campionaria e \\(z_{\\alpha/2}\\) è il valore critico della distribuzione normale standard con \\(\\alpha/2\\) di probabilità di coda.\nIntervallo di confidenza per la differenza tra due proporzioni.\nPer stimare l’intervallo di confidenza per la differenza tra due proporzioni \\(p_1\\) e \\(p_2\\) in due campioni binomiali di dimensioni \\(n_1\\) e \\(n_2\\), la formula è:\n\\[\n(\\hat{p}_1 - \\hat{p}_2) \\pm z_{\\alpha/2} \\sqrt{\\frac{\\hat{p}_1(1 - \\hat{p}_1)}{n_1} + \\frac{\\hat{p}_2(1 - \\hat{p}_2)}{n_2}},\n\\]\ndove \\(\\hat{p}_1\\) e \\(\\hat{p}_2\\) sono le proporzioni campionarie e \\(z_{\\alpha/2}\\) è il valore critico della distribuzione normale standard con \\(\\alpha/2\\) di probabilità di coda.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#esercizi",
    "href": "chapters/frequentist_inference/02_conf_interv.html#esercizi",
    "title": "87  Intervalli di fiducia",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\n\nChe cos’è un intervallo di confidenza dal punto di vista frequentista?\nChe cosa significa la copertura al 95% di un intervallo di confidenza?\nPerché non è corretto dire che “c’è il 95% di probabilità che il valore vero di \\(\\mu\\) cada in questo intervallo di confidenza”?\nIn cosa consiste la differenza tra un intervallo di confidenza costruito con la distribuzione normale standard \\(Z\\) e uno costruito con la distribuzione \\(t\\) di Student?\nPerché, nel caso di varianza incognita, si usa la deviazione standard campionaria \\(s\\) al posto di \\(\\sigma\\)?\nCome influenza la dimensione del campione \\(n\\) l’ampiezza dell’intervallo di confidenza?\nPerché gli intervalli di confidenza frequentisti si basano su un concetto di “ripetizione dell’esperimento” nel lungo periodo?\nQuali sono due fraintendimenti comuni sugli intervalli di confidenza?\nCome si interpreta correttamente un intervallo di confidenza al 95%?\nQual è la differenza essenziale tra un intervallo di confidenza frequentista e un intervallo di credibilità bayesiano?\n\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\n\nChe cos’è un intervallo di confidenza dal punto di vista frequentista?\n\nRisposta\nUn intervallo di confidenza (IC) è un range di valori costruito attorno a una stima campionaria (ad esempio, la media campionaria) che, secondo il metodo frequentista adottato, conterrà il valore vero del parametro in una certa proporzione di casi (ad esempio il 95%) se si ripetesse l’esperimento (ossia il campionamento) un numero molto grande di volte. Non esprime dunque la “probabilità” che il parametro sia dentro l’intervallo in un singolo caso, ma una frequenza di successo nel lungo periodo.\n\nChe cosa significa la copertura al 95% di un intervallo di confidenza?\n\nRisposta\nIl livello di copertura (ad esempio, 95%) indica che, in una serie ipotetica di infiniti campioni indipendenti e nel calcolo ripetuto di infiniti intervalli di confidenza secondo la stessa procedura, il 95% di tali intervalli conterrà il valore vero del parametro. È una proprietà della procedura di costruzione degli intervalli, non di un singolo intervallo già calcolato.\n\nPerché non è corretto dire che “c’è il 95% di probabilità che il valore vero di \\(\\mu\\) cada in questo intervallo di confidenza”?\n\nRisposta\nNella prospettiva frequentista, il parametro \\(\\mu\\) è considerato un valore fisso (non una variabile casuale). L’incertezza risiede nel campione e nella procedura di costruzione dell’intervallo, non nel parametro. Di conseguenza, non si può associare una probabilità alla posizione di \\(\\mu\\) all’interno di un singolo intervallo: l’intervallo o contiene \\(\\mu\\) oppure no, senza mezze misure probabilistiche.\n\nIn cosa consiste la differenza tra un intervallo di confidenza costruito con la distribuzione normale standard \\(Z\\) e uno costruito con la distribuzione \\(t\\) di Student?\n\nRisposta\n- Distribuzione \\(Z\\): si utilizza quando la varianza della popolazione \\(\\sigma^2\\) è nota (o si approssima molto bene) e la popolazione è normalmente distribuita, o quando il campione è molto grande (per applicare il teorema del limite centrale).\n- Distribuzione \\(t\\): si impiega quando la varianza \\(\\sigma^2\\) non è nota e bisogna stimarla con la deviazione standard campionaria \\(s\\). La distribuzione \\(t\\) “corregge” per l’incertezza aggiuntiva dovuta alla stima di \\(\\sigma\\) e diventa progressivamente simile alla normale standard quando il numero di gradi di libertà (cioè la dimensione del campione meno uno) è elevato.\n\nPerché, nel caso di varianza incognita, si usa la deviazione standard campionaria \\(s\\) al posto di \\(\\sigma\\)?\n\nRisposta\nQuando \\(\\sigma\\) non è nota, la si sostituisce con la stima campionaria \\(s\\). Poiché \\(s\\) è anch’essa una variabile casuale (cioè dipende dai dati osservati), introduce un’ulteriore fonte di incertezza. Questo giustifica l’uso della distribuzione \\(t\\) di Student anziché della normale standard, poiché \\(t\\) ingloba tale incertezza aggiuntiva.\n\nCome influenza la dimensione del campione \\(n\\) l’ampiezza dell’intervallo di confidenza?\n\nRisposta\nAumentando \\(n\\), l’errore standard della media (cioè \\(\\frac{\\sigma}{\\sqrt{n}}\\) oppure \\(\\frac{s}{\\sqrt{n}}\\)) diminuisce. Di conseguenza, l’intervallo di confidenza si restringe (a parità di livello di confidenza). In altre parole, con più dati a disposizione la stima della media è più “precisa” nel senso frequentista, e ciò si riflette in un IC più stretto.\n\nPerché gli intervalli di confidenza frequentisti si basano su un concetto di “ripetizione dell’esperimento” nel lungo periodo?\n\nRisposta\nLa filosofia frequentista definisce la probabilità come una frequenza relativa di un evento dopo molteplici repliche dell’esperimento. Per gli intervalli di confidenza, ciò implica che la probabilità di copertura (ad esempio 95%) è intesa come la frequenza con cui, ripetendo infinite volte il campionamento e la costruzione di IC allo stesso modo, l’intervallo calcolato conterrà il vero parametro. Non riguarda invece la probabilità del parametro di trovarsi in un intervallo specifico.\n\nQuali sono due fraintendimenti comuni sugli intervalli di confidenza?\n\nRisposta\n1. Credere che l’IC fornisca una probabilità diretta di contenere il parametro (es. “c’è il 95% di probabilità che \\(\\mu\\) sia qui dentro”) – in realtà, nel frequentismo \\(\\mu\\) è fisso e l’IC varia.\n2. Pensare che l’intervallo di confidenza sia significativo per la singola stima più che per la procedura – in realtà, il 95% di copertura si riferisce alla ripetizione dell’esperimento, non a un singolo intervallo.\n\nCome si interpreta correttamente un intervallo di confidenza al 95%?\n\nRisposta\n“Se ripetiamo più volte l’esperimento, ossia estraiamo molti campioni indipendenti dalla popolazione e costruiamo ogni volta un intervallo di confidenza con la stessa procedura, allora il 95% di quegli intervalli conterrà il valore vero della media \\(\\mu\\).” È dunque una garanzia circa l’efficacia della metodologia nel lungo periodo.\n\nQual è la differenza essenziale tra un intervallo di confidenza frequentista e un intervallo di credibilità bayesiano?\n\nRisposta\n- Intervallo di confidenza frequentista: descrive la performance a lungo termine di una procedura; non permette di affermare “la probabilità che \\(\\mu\\) sia nell’intervallo è il 95%”.\n- Intervallo di credibilità bayesiano: esprime direttamente una credenza probabilistica a posteriori sul parametro (ad esempio, “c’è il 95% di probabilità che \\(\\mu\\) sia in questo intervallo”), perché il parametro è trattato come variabile casuale, con una distribuzione a priori che si aggiorna con i dati osservati.\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nDi seguito trovi 10 esercizi incentrati sulla costruzione di intervalli di confidenza. I primi 5 richiedono di svolgere i calcoli “a mano” (carta e penna o calcolatrice), gli ultimi 5 prevedono l’utilizzo di R.\nEsercizi da Risolvere “a Mano”\n\nIntervallo di Confidenza per la Media (Varianza Nota)\n\nUna ricercatrice vuole stimare la media di un punteggio di reattività emotiva (scala 0–100) in giovani adulti. Dai dati precedenti, si sa che la varianza vera (della popolazione) è \\(\\sigma^2 = 16\\). Si raccoglie un campione di \\(n=25\\) partecipanti e la media campionaria risulta \\(\\bar{X} = 45\\).\n1. Calcola l’intervallo di confidenza al 95% per la media della popolazione (\\(\\mu\\)).\n2. Fornisci un’interpretazione corretta (frequentista) del risultato.\n\nIntervallo di Confidenza per la Media (Varianza Incognita, 99%)\n\nIn un’indagine sulla soddisfazione lavorativa (scala da 1 a 7), vengono coinvolti \\(n=10\\) psicologi clinici. I dati raccolti forniscono:\n- Media campionaria \\(\\bar{X} = 5{,}6\\)\n- Deviazione standard campionaria \\(s=0{,}8\\)\nLa popolazione è considerata approssimativamente normale ma la varianza è ignota. Calcola l’IC al 99% per la vera media di soddisfazione \\(\\mu\\).\n\nIntervallo di Confidenza per la Differenza tra Due Medie (Varianze Incognite Uguali)\n\nUn team di psicologi del lavoro vuole confrontare i livelli di stress (scala 0–50) tra due gruppi di dipendenti di un’azienda (Campione 1: reparto A, Campione 2: reparto B). I dati sono:\n\nReparto A (\\(n_1=12\\)):\\(\\bar{X}_1 = 22\\), \\(s_1 = 4\\)\nReparto B (\\(n_2=10\\)):\\(\\bar{X}_2 = 19\\), \\(s_2 = 3{,}5\\)\n\nAssumi che le due popolazioni siano normali con varianze ignote ma uguali e calcola l’intervallo di confidenza al 95% per \\(\\mu_A - \\mu_B\\). (Usa quindi la formula con la varianza pooled.)\n\nIntervallo di Confidenza per una Proporzione\n\nUno studio pilota su un programma di training per la gestione dell’ansia vede 120 persone iscriversi. Alla fine del programma, 48 di loro riportano di aver diminuito la frequenza di attacchi di panico in modo “significativo”.\n1. Stima la proporzione campionaria \\(\\hat{p}\\).\n2. Calcola l’IC al 95% per la vera proporzione \\(p\\) di persone che trarrebbe beneficio “significativo” dal programma.\n\nIntervallo di Confidenza per la Differenza tra Due Proporzioni\n\nIn un esperimento, due gruppi di partecipanti ricevono diversi percorsi di psicoterapia per ridurre l’insonnia:\n\n\nGruppo 1 (\\(n_1=50\\)): 35 persone riportano un netto miglioramento del sonno.\n\n\nGruppo 2 (\\(n_2=40\\)): 20 persone riportano un netto miglioramento del sonno.\n\nSi vuole stimare la differenza \\((p_1 - p_2)\\) nelle proporzioni di successo dei due trattamenti. Calcola l’IC al 95%.\nEsercizi da Risolvere con R\nNei prossimi esercizi, utilizza R per effettuare i calcoli. I dati sono già contestualizzati in ambito psicologico.\n\nIntervallo di Confidenza per la Media (Varianza Incognita)\n\nHai misurato i tempi di reazione (in millisecondi) a uno stimolo di pericolo in un gruppo di 15 partecipanti. I dati (approssimati) sono:\nreaction_times &lt;- c(220, 250, 210, 240, 260, 270, 225, 255, 235, 245, 210, 270, 265, 220, 230)\n\nUtilizza R per calcolare la media e la deviazione standard campionaria.\n\nCostruisci (tramite t.test(reaction_times)) l’intervallo di confidenza al 95% per il tempo di reazione medio della popolazione.\n\n\nIntervallo di Confidenza per la Differenza tra Due Medie (Varianze Incognite)\n\nDue gruppi di studenti hanno svolto un test di memoria verbale dopo aver seguito differenti strategie di studio:\ngroupA &lt;- c(15, 12, 18, 10, 14, 16, 19, 11)\ngroupB &lt;- c(10, 9, 14, 11, 8, 12, 13, 15)\n\nCalcola in R le medie campionarie dei due gruppi.\n\nUtilizza t.test(groupA, groupB, var.equal = FALSE) per ottenere l’IC al 95% della differenza \\(\\mu_A - \\mu_B\\).\n\nRiporta i risultati numerici.\n\n\nIntervallo di Confidenza per una Proporzione (Studio su Fobia Specifica)\n\nIn un piccolo studio, hai i dati (binari: 1 = “attacco d’ansia”, 0 = “nessun attacco”) raccolti da 20 persone esposte a uno stimolo fobico:\nattacks &lt;- c(1,0,0,1,1,1,1,0,0,1,0,1,1,1,1,0,0,1,0,1)\n\nCalcola in R la proporzione campionaria di attacchi d’ansia.\n\nUtilizza prop.test() per costruire l’IC al 95% per la proporzione vera di attacchi d’ansia in questa specifica situazione.\n\n\nIntervallo di Confidenza per la Differenza tra Due Proporzioni (Test A/B di un Training Psicologico)\n\nDue versioni di un training psicologico anti-stress (A e B) sono state testate su studenti universitari, registrando (binario: 1/0) se al termine del corso mostrano ridotti livelli di stress:\nversionA &lt;- c(1,1,0,1,1,0,1,0,1,1,0,1)\nversionB &lt;- c(0,0,1,1,1,0,1,0,0,1,0,0)\n\nCalcola in R \\(\\hat{p}_A\\) e \\(\\hat{p}_B\\).\n\nUsa prop.test(x = ..., n = ...) per l’IC al 95% di \\((p_A - p_B)\\).\n\nRiporta i risultati.\n\n\nSimulazione di Copertura per l’IC sulla Media (Contesto Psicologico)\n\nScrivi (o completa) uno script in R che simuli 1000 campioni di punteggi di ansia (scala 0–80) estratti da una distribuzione approssimata come Normale, con media vera \\(\\mu=40\\) e \\(\\sigma=10\\). Per ogni campione di ampiezza \\(n=25\\):\n\nCalcola la media campionaria e la deviazione standard.\n\nCostruisci l’IC al 95% (usando la distribuzione t).\n\nVerifica quante volte l’intervallo contiene il vero valore \\(\\mu = 40\\).\n\nStima la proporzione di copertura e commenta se è prossima a 0,95.\n\nEsempio di traccia:\nset.seed(123)\nn_sims &lt;- 1000\nn &lt;- 25\nmu &lt;- 40\nsigma &lt;- 10\n\ncount_included &lt;- 0\n\nfor(i in 1:n_sims){\n  sample_data &lt;- rnorm(n, mean = mu, sd = sigma)\n  # calcola media, sd, IC, verifica se 40 è dentro l’IC\n}\n\ncoverage &lt;- count_included / n_sims\ncoverage\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\nSoluzioni Esercizi “a Mano”\nSoluzione 1\n\nDati: \\(\\sigma^2=16 \\implies \\sigma=4\\); \\(n=25\\); \\(\\bar{X}=45\\); livello di confidenza 95% (\\(\\alpha=0{,}05\\)).\n\nErrore standard:\\[\n\\text{SE} = \\frac{\\sigma}{\\sqrt{n}} = \\frac{4}{5} = 0{,}8.\n\\]\n\nValore critico \\(z_{\\alpha/2}\\approx 1{,}96\\).\n\nMargine di errore:\\[\nE = z_{\\alpha/2} \\times \\text{SE} \\approx 1{,}96 \\times 0{,}8 = 1{,}57.\n\\]\n\nIC 95%:\\[\n45 \\pm 1{,}57 \\quad \\Rightarrow \\quad (43{,}43;\\, 46{,}57).\n\\]\n\n\nSoluzione 2\n\nDati: \\(n=10\\), \\(\\bar{X}=5{,}6\\), \\(s=0{,}8\\), confidenza 99% (\\(\\alpha=0{,}01\\)).\n\nGradi di libertà \\(df = 9\\). Il valore di \\(t_{\\alpha/2, df=9}\\) (per \\(\\alpha/2=0{,}005\\)) è approssimativamente 3,25 (dipende dalla tabella).\n\nErrore standard:\\[\n\\text{SE} = \\frac{s}{\\sqrt{n}} = \\frac{0{,}8}{\\sqrt{10}} \\approx \\frac{0{,}8}{3{,}162} \\approx 0{,}253.\n\\]\n\nMargine di errore:\\[\nE = 3{,}25 \\times 0{,}253 \\approx 0{,}82.\n\\]\n\nIC al 99%:\\[\n5{,}6 \\pm 0{,}82 \\quad \\Rightarrow \\quad (4{,}78;\\, 6{,}42).\n\\]\n\n\nSoluzione 3\n\nDati:\n\nCampione 1 (A): \\(n_1=12\\), \\(\\bar{X}_1=22\\), \\(s_1=4\\).\n\nCampione 2 (B): \\(n_2=10\\), \\(\\bar{X}_2=19\\), \\(s_2=3{,}5\\).\n\nIC 95% \\(\\Rightarrow \\alpha=0{,}05\\).\n\nSi assume varianza uguale (\\(\\sigma_A^2 = \\sigma_B^2\\)) \\(\\Rightarrow\\) varianza pooled.\n\n\n\n\nVarianza campionaria: \\(s_1^2=16\\), \\(s_2^2=12{,}25\\).\n\nVarianza pooled:\\[\ns_p^2\n= \\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}\n= \\frac{(11 \\times 16) + (9 \\times 12{,}25)}{12 + 10 - 2}.\n\\] \\[\n= \\frac{176 + 110{,}25}{20}\n= \\frac{286{,}25}{20}\n= 14{,}3125.\n\\] \\[\ns_p = \\sqrt{14{,}3125} \\approx 3{,}785.\n\\]\n\nErrore standard della differenza:\\[\n\\text{SE}(\\bar{X}_1 - \\bar{X}_2)\n= \\sqrt{\\,s_p^2\\!\\left(\\tfrac{1}{n_1} + \\tfrac{1}{n_2}\\right)}\n= \\sqrt{\\,14{,}3125 \\times \\left(\\tfrac{1}{12} + \\tfrac{1}{10}\\right)}.\n\\] \\[\n\\tfrac{1}{12} + \\tfrac{1}{10} = 0{,}0833 + 0{,}1 = 0{,}1833.\n\\] \\[\n14{,}3125 \\times 0{,}1833 \\approx 2{,}624\n\\quad \\Rightarrow \\quad \\sqrt{2{,}624} \\approx 1{,}62.\n\\]\n\nDifferenza campionaria: \\(\\bar{X}_1 - \\bar{X}_2 = 3\\).\n\nValore critico \\(t_{\\alpha/2}\\) con \\(df = n_1 + n_2 - 2 = 20\\): circa 2,086.\n\nMargine di errore: \\(E \\approx 2{,}086 \\times 1{,}62 \\approx 3{,}38\\).\n\nIC 95%:\\[\n3 \\pm 3{,}38 \\quad \\Rightarrow \\quad (-0{,}38;\\, 6{,}38).\n\\] (Approssimando: i valori variano un po’ in base agli arrotondamenti.)\n\n\nSoluzione 4\n\nDati: \\(n=120\\), successo \\(x=48\\).\n\n\n\\(\\hat{p} = \\frac{48}{120}=0{,}4\\).\n\nErrore standard (approssimazione normale):\\[\n\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} = \\sqrt{\\frac{0{,}4 \\times 0{,}6}{120}} = \\sqrt{\\frac{0{,}24}{120}} = \\sqrt{0{,}002} \\approx 0{,}0447.\n\\]\n\nCon \\(\\alpha=0{,}05\\), \\(z_{\\alpha/2} \\approx 1{,}96\\).\n\nMargine di errore:\\[\nE = 1{,}96 \\times 0{,}0447 \\approx 0{,}0876.\n\\]\n\nIC 95%:\\[\n0{,}4 \\pm 0{,}0876 \\quad \\Rightarrow \\quad (0{,}3124;\\, 0{,}4876).\n\\]\n\n\nSoluzione 5\n\nDati:\n\nGruppo 1 (\\(n_1=50\\)): 35 successi \\(\\Rightarrow \\hat{p}_1=35/50=0{,}70\\).\n\nGruppo 2 (\\(n_2=40\\)): 20 successi \\(\\Rightarrow \\hat{p}_2=20/40=0{,}50\\).\n\n\n\nDifferenza: \\(\\hat{p}_1 - \\hat{p}_2=0{,}20\\).\n\nErrore standard:\\[\n\\sqrt{\\frac{0{,}70 \\cdot 0{,}30}{50} + \\frac{0{,}50 \\cdot 0{,}50}{40}}\n= \\sqrt{\\frac{0{,}21}{50} + \\frac{0{,}25}{40}}\n= \\sqrt{0{,}0042 + 0{,}00625}\n= \\sqrt{0{,}01045} \\approx 0{,}1022.\n\\]\n\nMargine di errore (al 95%, \\(z_{\\alpha/2}=1{,}96\\)):\\[\n1{,}96 \\times 0{,}1022 \\approx 0{,}200.\n\\]\n\nIC 95%:\\[\n0{,}20 \\pm 0{,}20 \\quad \\Rightarrow \\quad (0{,}00;\\, 0{,}40).\n\\] *(Può capitare un limite inferiore esattamente 0, se si arrotonda.)\n\nSoluzioni Esercizi con R\n(I risultati possono variare leggermente a seconda della versione di R e di eventuali correzioni di continuità nelle funzioni di test.)\nSoluzione 6\nreaction_times &lt;- c(220, 250, 210, 240, 260, 270, 225, 255, 235, 245, 210, 270, 265, 220, 230)\n\nmean(reaction_times)         # media\nsd(reaction_times)           # deviazione standard\nt.test(reaction_times)       # t.test con conf.level = 0.95 di default\n\nEsempio di risultato:\n\nMedia campionaria \\(\\bar{X}\\approx 240\\) (dipende dai dati esatti)\n\n\nt.test() riporta un IC 95% (ad es.): \\((230, 250)\\) [numeri a titolo di esempio].\n\n\n\nSoluzione 7\ngroupA &lt;- c(15, 12, 18, 10, 14, 16, 19, 11)\ngroupB &lt;- c(10, 9, 14, 11, 8, 12, 13, 15)\n\nmean(groupA)  # ~ 14.375\nmean(groupB)  # ~ 11.50\nt.test(groupA, groupB, var.equal = FALSE)\n\n\nEsempio di output (fittizio):\nWelch Two Sample t-test\ndata:  groupA and groupB\nt = 2.35, df = 13.7, p-value = 0.033\n95 percent confidence interval:\n  0.47  5.77\nsample estimates:\n  mean of x  mean of y \n      14.375     11.500\nQuindi l’IC 95% per \\(\\mu_A - \\mu_B\\) potrebbe essere circa \\((0{,}47;\\, 5{,}77)\\).\n\n\nSoluzione 8\nattacks &lt;- c(1,0,0,1,1,1,1,0,0,1,0,1,1,1,1,0,0,1,0,1)\n\nsum(attacks)        # conta quanti \"1\"\nlength(attacks)     # 20\n\nprop.test(sum(attacks), length(attacks), conf.level = 0.95)\n\nSe, ad esempio, vi fossero 12 “1” su 20, \\(\\hat{p}=0{,}60\\).\n\nL’intervallo di confidenza al 95% (a seconda della continuity correction) potrebbe essere indicativamente \\((0{,}36;\\, 0{,}80)\\).\n\nSoluzione 9\nversionA &lt;- c(1,1,0,1,1,0,1,0,1,1,0,1)\nversionB &lt;- c(0,0,1,1,1,0,1,0,0,1,0,0)\n\nsumA &lt;- sum(versionA)\nsumB &lt;- sum(versionB)\nnA   &lt;- length(versionA)\nnB   &lt;- length(versionB)\n\nprop.test(c(sumA,sumB), c(nA,nB), conf.level = 0.95)\n\nEsempio:\n\n\nsum(versionA) = 8 successi su 12 (\\(\\hat{p}_A=0{,}666...\\))\n\n\nsum(versionB) = 5 successi su 12 (\\(\\hat{p}_B=0{,}416...\\))\n\nL’IC per \\(\\hat{p}_A - \\hat{p}_B\\) potrebbe essere, ad esempio, \\((-0{,}05;\\, 0{,}61)\\).\n\n\n\n(I numeri esatti variano a seconda dell’eventuale correzione di continuità.)\nSoluzione 10\nUn possibile script:\nset.seed(123)\nn_sims &lt;- 1000\nn &lt;- 25\nmu &lt;- 40\nsigma &lt;- 10\n\ncount_included &lt;- 0\n\nfor(i in 1:n_sims){\n  sample_data &lt;- rnorm(n, mean = mu, sd = sigma)\n  xbar &lt;- mean(sample_data)\n  s &lt;- sd(sample_data)\n  \n  # t critico\n  t_crit &lt;- qt(0.975, df = n - 1)\n  \n  # IC\n  se &lt;- s / sqrt(n)\n  E &lt;- t_crit * se\n  lower &lt;- xbar - E\n  upper &lt;- xbar + E\n  \n  if(mu &gt;= lower & mu &lt;= upper){\n    count_included &lt;- count_included + 1\n  }\n}\n\ncoverage &lt;- count_included / n_sims\ncoverage\n\n\nEsempio di risultato:\n&gt; coverage\n[1] 0.948\nOvvero ~94,8% degli IC contengono il vero valore \\(\\mu=40\\), in linea con il 95% atteso (piccole differenze dovute al caso).\n\n\nCommento Conclusivo\nIn ogni caso, ricorda sempre che l’interpretazione frequentista di un intervallo di confidenza si basa sulla “copertura a lungo termine” del metodo di costruzione dell’IC, non sulla probabilità che il vero parametro cada nell’intervallo specifico appena calcolato.\n\n\n\n\n\n\n\n\n\nProblemi 3\n\n\n\n\n\nEsercizio 1 – Calcolo e interpretazione dell’IC frequentista per la media\n\n\nCalcola la media campionaria \\(\\bar{X}\\) e la deviazione standard campionaria \\(s\\).\n\nAssumendo che il punteggio SWLS nella popolazione di riferimento (ad esempio, “giovani adulti universitari”) sia approssimativamente normale ma con varianza sconosciuta, costruisci l’intervallo di confidenza al 95% per la media \\(\\mu\\) utilizzando la distribuzione \\(t\\) di Student con \\(n - 1\\) gradi di libertà (dove \\(n=10\\)).\n\n\nInterpreta questo intervallo di confidenza in ottica frequentista. Metti in evidenza la distinzione fra l’“interpretazione corretta” (copertura sul lungo periodo) e l’“interpretazione scorretta” (credere che ci sia il 95% di probabilità che \\(\\mu\\) stia nell’intervallo calcolato).\n\nSpunti di riflessione sui limiti:\n- Con un campione molto piccolo, l’intervallo di confidenza potrebbe essere molto ampio.\n- Se la popolazione non fosse davvero normale, la validità dell’IC con distribuzione \\(t\\) potrebbe essere compromessa.\n- In ottica frequentista, il singolo intervallo o contiene il vero valore di \\(\\mu\\) o non lo contiene: la “probabilità 95%” si riferisce alla procedura di costruzione, non a questo singolo intervallo specifico.\nEsercizio 2 – Sensibilità dell’IC a diversi livelli di confidenza\n\nUtilizzando gli stessi 10 dati, calcola:\n\nl’intervallo di confidenza all’80%\n\nl’intervallo di confidenza al 99%\n\n\n\nConfronta l’ampiezza dei tre intervalli (80%, 95%, 99%).\n\nCommenta dal punto di vista dell’interpretazione frequentista: perché l’IC al 99% è più ampio di quello al 95%, e quest’ultimo è più ampio di quello all’80%?\n\nSpunti di riflessione sui limiti:\n- Aumentare il livello di confidenza fa sì che l’IC si allarghi, spesso di molto se \\(n\\) è piccolo.\n- Un IC più ampio rassicura sulla “copertura” nel lungo periodo, ma è meno informativo per il singolo studio.\nEsercizio 3 – Utilizzo di software per il calcolo (ad esempio, R o altro)\n\n\nInserisci i dati in un software (come R). Puoi farlo in R con:\nswls_data &lt;- c(28, 22, 26, 18, 30, 24, 27, 17, 21, 25)\n\n\nCalcola la media e la deviazione standard in R, poi utilizza la funzione t.test():\nt.test(swls_data, conf.level = 0.95)\n\nRiporta l’intervallo di confidenza ottenuto e confrontalo con quello calcolato a mano.\nCommenta eventuali differenze (minime) dovute agli arrotondamenti o a correzioni interne di R.\nRibadisci la corretta interpretazione frequentista: se si ripetesse lo stesso studio molte volte (stessa dimensione campionaria, stesso contesto di popolazione, stessa procedura di calcolo), il 95% di questi IC conterrebbe il valore vero di \\(\\mu\\).\n\nEsercizio 4 – Confronto pratico e riflessioni critiche\n\nImmagina di avere un’ipotesi: “La media SWLS nella popolazione dei giovani adulti universitari è pari a 24” (un’ipotesi plausibile se la scala totale va da 5 a 35).\n\nOsserva l’IC al 95% che hai calcolato: contiene il valore 24?\n\nSe l’IC contiene 24, puoi dire che il valore “24” è “molto probabile”? (No, attenzione! Vedi interpretazione corretta vs. errata.)\n\nSe l’IC non contiene 24, puoi concludere che la media reale è “sicuramente” diversa da 24? (No, perché hai solo un campione piccolo e il concetto di significatività vs. copertura può essere fuorviante.)\n\nSpunti di riflessione sui limiti:\n- Il “livello di fiducia” dell’IC non è una “probabilità” che \\(\\mu\\) sia all’interno di un singolo intervallo: è una proprietà della procedura sul lungo periodo.\n- Con pochi dati, le assunzioni (come la normalità) e la variabilità casuale giocano un ruolo enorme: l’intervallo può risultare poco stabile e molto sensibile a pochi valori estremi.\n- L’IC non dice “quanto è plausibile 24” (questo sarebbe più vicino a un approccio bayesiano, che definisce un intervallo di credibilità). L’IC frequentista dice soltanto che, ripetendo molte volte la stessa procedura, nel 95% dei casi il vero \\(\\mu\\) cadrà entro l’intervallo calcolato in ciascuna ripetizione.\n\n\n\n\n\n\n\n\n\nSoluzioni 3\n\n\n\n\n\nSupponiamo siano stati raccolti i dati seguenti (sostituisci con i dati effettivi):\n28, 22, 26, 18, 30, 24, 27, 17, 21, 25\nEsercizio 1\n\nCalcolo di media e deviazione standard campionaria\n\nIndichiamo i punteggi come \\(X_1, X_2, \\dots, X_{10}\\). La media campionaria è:\n\\[\n\\bar{X} = \\frac{1}{n}\\sum_{i=1}^n X_i.\n\\]\nFacendo la somma \\(28 + 22 + 26 + 18 + 30 + 24 + 27 + 17 + 21 + 25 = 238\\).\nQuindi, con \\(n=10\\), otteniamo:\n\\[\n\\bar{X} = \\frac{238}{10} = 23.8.\n\\]\nPer la deviazione standard campionaria \\(s\\), si utilizza:\n\\[\ns = \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^n \\bigl(X_i - \\bar{X}\\bigr)^2}.\n\\]\nCalcolando (o usando un foglio di calcolo / software), si ricava approssimativamente:\n\\[\ns \\approx 4.26.\n\\]\n\nCostruzione dell’Intervallo di Confidenza al 95%\n\nPoiché la varianza è sconosciuta e il campione è piccolo, usiamo la distribuzione \\(t\\) di Student con \\(n-1 = 9\\) gradi di libertà.\n- Livello di confidenza: \\(95\\%\\).\n- \\(\\alpha = 0,05\\), quindi \\(\\alpha/2 = 0,025\\).\n- Il valore critico \\(t_{\\alpha/2,df=9}\\) è circa 2,262 (da tavole o software).\n\nErrore standard\n\n\\[\n\\text{SE} = \\frac{s}{\\sqrt{n}} = \\frac{4.26}{\\sqrt{10}} \\approx 4.26 / 3.162 \\approx 1.35.\n\\]\n\nMargine di errore\n\n\\[\nE = t_{\\alpha/2} \\times \\text{SE} \\approx 2.262 \\times 1.35 \\approx 3.05.\n\\]\n\nIntervallo di confidenza\n\n\\[\n\\bar{X} \\pm E \\quad \\Rightarrow \\quad 23.8 \\pm 3.05\n\\quad \\Rightarrow \\quad (20.75;\\, 26.85).\n\\]\n\nInterpretazione frequentista corretta\n\n\n\nInterpretazione corretta: se ripetessimo lo stesso tipo di studio molte volte (stessa procedura di campionamento, stesse dimensioni, stesso metodo di calcolo dell’IC), il 95% di questi intervalli conterrà il vero valore della media della popolazione (\\(\\mu\\)).\n\n\nInterpretazione scorretta (da evitare): “C’è il 95% di probabilità che la vera media sia qui dentro”. Nel frequentismo, \\(\\mu\\) è considerato un valore fisso e non aleatorio. L’incertezza riguarda l’intervallo, non il parametro.\n\nLimite: con poche osservazioni (n=10), l’intervallo può risultare piuttosto ampio. Inoltre, l’assunzione di normalità della popolazione di partenza potrebbe non essere pienamente soddisfatta.\nEsercizio 2\n\nCalcolo di due nuovi IC: 80% e 99%\n\nUtilizziamo gli stessi \\(\\bar{X} = 23.8\\), \\(s = 4.26\\), \\(n=10\\). Cambia solo il valore critico \\(t\\).\n\n\nIC all’80% (\\(\\alpha=0,20\\), \\(\\alpha/2 = 0,10\\)):\n\n\n\\(t_{0,10,df=9} \\approx 1.383\\)\n\n\n\\(\\text{SE} \\approx 1.35\\) (come prima)\n\nMargine di errore \\(E = 1.383 \\times 1.35 \\approx 1.87\\)\n\nIC 80%: \\((23.8 \\pm 1.87)\\) \\(\\Rightarrow\\) \\((21.93;\\, 25.67)\\).\n\n\n\nIC al 99% (\\(\\alpha=0,01\\), \\(\\alpha/2 = 0,005\\)):\n\n\n\\(t_{0,005,df=9} \\approx 3.25\\)\n\n\n\\(\\text{SE} \\approx 1.35\\)\n\nMargine di errore \\(E = 3.25 \\times 1.35 \\approx 4.39\\)\n\nIC 99%: \\((23.8 \\pm 4.39)\\) \\(\\Rightarrow\\) \\((19.41;\\, 28.19)\\).\n\n\n\n\nConfronto delle ampiezze\n\n\n\n80%: \\((21.93;\\, 25.67)\\) (più stretto)\n\n\n95%: \\((20.75;\\, 26.85)\\) (intermedio)\n\n\n99%: \\((19.41;\\, 28.19)\\) (più largo)\n\nAumentando il livello di confidenza, l’intervallo si espande. Per “coprire” il valore vero nel 99% delle volte, occorre un intervallo più ampio.\nEsercizio 3\n\nCalcolo in R\n\nSe in R inseriamo i dati:\nswls_data &lt;- c(28, 22, 26, 18, 30, 24, 27, 17, 21, 25)\n\nmean(swls_data)  # ~ 23.8\nsd(swls_data)    # ~ 4.26\nt.test(swls_data, conf.level = 0.95)\n\nConfronto con il calcolo “a mano”\n\nLa funzione t.test() (di default) eseguirà un One Sample t-test con confidenza 95%. Restituisce:\n\nUn IC molto simile a \\((20.75;\\, 26.85)\\), con possibili piccole differenze di arrotondamento.\n\n\nRibadire l’interpretazione\n\n\nIl risultato di t.test() potrebbe riportare:95 percent confidence interval: (20.72, 26.88)\n(o valori simili).\n\nAnche qui vale la regola: non è una probabilità che \\(\\mu\\) sia dentro, bensì una proprietà della procedura (lungo periodo).\n\nEsercizio 4\n\n\nIpotesi: “La media SWLS reale nella popolazione è 24”.\n\n\nVerifica se 24 è dentro l’IC al 95%. Dall’IC \\((20.75;\\, 26.85)\\), notiamo che 24 rientra in questo intervallo.\n\nSignifica che è “probabile” 24?\n\nAttenzione: l’IC frequentista non fornisce una probabilità su questo specifico valore. Dire che “24 è dentro l’intervallo” non equivale a dire “la probabilità che \\(\\mu\\) = 24 è 95%”.\n\n\n\nSe 24 fosse stato fuori dall’intervallo, non potremmo comunque affermare con certezza che \\(\\mu\\neq 24\\). Ricordiamo sempre che, con un campione così piccolo, l’incertezza è alta e l’IC si basa su assunzioni (normalità e stima corretta).\n\nLimiti dell’interpretazione\n\nCon campioni ridotti, basta poco (un outlier o una leggera deviazione dalla normalità) per alterare significativamente l’intervallo.\n\nIl livello di confidenza (ad es. 95%) è una proprietà della procedura: in una serie di infiniti studi simili, il 95% di quegli intervalli conterrebbe \\(\\mu\\). Non significa che, dato questo singolo intervallo, ci sia una “probabilità 95%” di includere il parametro.\n\nRiepilogo Finale\n\n\nValori Numerici:\n\nMedia \\(\\bar{X} = 23.8\\); dev. standard \\(s \\approx 4.26\\).\n\nIC 95% (a mano) \\(\\approx (20.75;\\, 26.85)\\).\n\nIC 80% \\(\\approx (21.93;\\, 25.67)\\); IC 99% \\(\\approx (19.41;\\, 28.19)\\).\n\n\n\n\nInterpretazione Frequentista:\n&gt; Nel lungo periodo, il 95% (o 99%, 80%, ecc.) degli intervalli calcolati con la stessa procedura conterrà il vero valore di \\(\\mu\\).\n\n\nLimiti (campioni piccoli, ipotesi di normalità, differenza tra “copertura ripetuta” e “probabilità che \\(\\mu\\) sia in un singolo IC”).\n\nIn questo modo, gli studenti vedono sia la parte di calcolo (formule, tabelle/valori critici, software) sia gli aspetti interpretativi (come evitare i fraintendimenti più comuni sul significato dell’IC frequentista).\nConclusioni generali\n\nCon un campione così piccolo (n=10), l’intervallo di confidenza può essere largo e sensibile a qualsiasi deviazione dall’assunzione di normalità.\n\nL’interpretazione frequentista si focalizza sulla “procedura” e sul “lungo periodo” (ripetizione dell’esperimento), non sulla probabilità che \\(\\mu\\) sia dentro questo intervallo specifico.\n\nÈ facile incorrere in fraintendimenti (“c’è il 95% di probabilità che la vera media sia qui dentro?”), occorre ribadire che la probabilità secondo il frequentismo riguarda il campionamento e la costruzione dell’intervallo, non la posizione fissa del parametro.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/02_conf_interv.html#informazioni-sullambiente-di-sviluppo",
    "title": "87  Intervalli di fiducia",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] bayestestR_0.16.0 posterior_1.6.1   cmdstanr_0.9.0    thematic_0.1.7   \n#&gt;  [5] MetBrewer_0.2.0   ggokabeito_0.1.0  see_0.11.0        gridExtra_2.3    \n#&gt;  [9] patchwork_1.3.0   bayesplot_1.13.0  psych_2.5.3       scales_1.4.0     \n#&gt; [13] markdown_2.0      knitr_1.50        lubridate_1.9.4   forcats_1.0.0    \n#&gt; [17] stringr_1.5.1     dplyr_1.1.4       purrr_1.0.4       readr_2.1.5      \n#&gt; [21] tidyr_1.3.1       tibble_3.3.0      ggplot2_3.5.2     tidyverse_2.0.0  \n#&gt; [25] rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6         tensorA_0.36.2.1     xfun_0.52           \n#&gt;  [4] htmlwidgets_1.6.4    insight_1.3.0        processx_3.8.6      \n#&gt;  [7] lattice_0.22-7       tzdb_0.5.0           vctrs_0.6.5         \n#&gt; [10] tools_4.5.0          ps_1.9.1             generics_0.1.4      \n#&gt; [13] parallel_4.5.0       pacman_0.5.1         pkgconfig_2.0.3     \n#&gt; [16] checkmate_2.3.2      RColorBrewer_1.1-3   distributional_0.5.0\n#&gt; [19] lifecycle_1.0.4      compiler_4.5.0       farver_2.1.2        \n#&gt; [22] mnormt_2.1.1         htmltools_0.5.8.1    pillar_1.10.2       \n#&gt; [25] abind_1.4-8          nlme_3.1-168         tidyselect_1.2.1    \n#&gt; [28] digest_0.6.37        stringi_1.8.7        labeling_0.4.3      \n#&gt; [31] rprojroot_2.0.4      fastmap_1.2.0        grid_4.5.0          \n#&gt; [34] cli_3.6.5            magrittr_2.0.3       withr_3.0.2         \n#&gt; [37] backports_1.5.0      timechange_0.3.0     rmarkdown_2.29      \n#&gt; [40] hms_1.1.3            evaluate_1.0.4       rlang_1.1.6         \n#&gt; [43] glue_1.8.0           rstudioapi_0.17.1    jsonlite_2.0.0      \n#&gt; [46] R6_2.6.1",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#bibliografia",
    "href": "chapters/frequentist_inference/02_conf_interv.html#bibliografia",
    "title": "87  Intervalli di fiducia",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nHoekstra, R., Morey, R. D., Rouder, J. N., & Wagenmakers, E.-J. (2014). Robust misinterpretation of confidence intervals. Psychonomic Bulletin & Review, 21(5), 1157–1164.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html",
    "href": "chapters/frequentist_inference/03_sample_size.html",
    "title": "88  La grandezza del campione",
    "section": "",
    "text": "88.1 Introduzione\nLa scelta della dimensione del campione è fondamentale per garantire che i risultati di uno studio siano affidabili, bilanciando precisione e costi. In questo capitolo, esamineremo come calcolare la dimensione minima del campione necessaria per stimare la media di una popolazione con un margine di errore prefissato e un determinato livello di confidenza. Utilizzeremo un esempio tratto dalla psicologia per illustrare il processo e fornire implementazioni pratiche in R.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>88</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#la-logica-dietro-la-scelta-della-dimensione-campionaria",
    "href": "chapters/frequentist_inference/03_sample_size.html#la-logica-dietro-la-scelta-della-dimensione-campionaria",
    "title": "88  La grandezza del campione",
    "section": "\n88.2 La Logica Dietro la Scelta della Dimensione Campionaria",
    "text": "88.2 La Logica Dietro la Scelta della Dimensione Campionaria\nIn psicologia, è comune stimare la media di una variabile (ad esempio, il punteggio medio di una scala psicometrica). I vantaggi di utilizzare campioni più grandi includono:\n\n\nStime più precise: Con un campione più grande, la varianza dell’estimatore diminuisce, rendendo le stime più accurate.\n\nMaggiore fiducia nei risultati: Un campione più grande riduce il margine di errore, aumentando la certezza dei risultati.\n\nTuttavia, i campioni più grandi richiedono risorse maggiori in termini di tempo e denaro. Pertanto, il problema si riduce spesso a trovare il campione più piccolo che garantisca la precisione desiderata.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>88</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#calcolo-della-dimensione-campionaria",
    "href": "chapters/frequentist_inference/03_sample_size.html#calcolo-della-dimensione-campionaria",
    "title": "88  La grandezza del campione",
    "section": "\n88.3 Calcolo della Dimensione Campionaria",
    "text": "88.3 Calcolo della Dimensione Campionaria\nPer campioni sufficientemente grandi, la media campionaria \\(\\bar{X}\\) segue una distribuzione normale:\n\\[\n\\bar{X} \\sim \\mathcal{N}\\left(\\mu, \\frac{\\sigma^2}{n}\\right),\n\\]\ndove:\n\n\n\\(n\\) è la dimensione del campione,\n\n\\(\\mu\\) è la vera media della popolazione,\n\n\\(\\sigma^2\\) è la varianza della popolazione.\n\nIl nostro obiettivo è trovare la dimensione campionaria \\(n\\) tale che:\n\\[\nP\\left(|\\bar{X} - \\mu| &lt; E\\right) \\geq 0.95,\n\\]\ndove:\n\n\n\\(\\bar{X}\\) è la media campionaria,\n\n\\(\\mu\\) è la media della popolazione,\n\n\\(E\\) è il margine di errore massimo accettabile.\n\nSappiamo che, per il teorema centrale del limite, la media campionaria \\(\\bar{X}\\) può essere standardizzata come segue:\n\\[\nZ = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}}.\n\\]\nQuesta quantità \\(Z\\) segue una distribuzione normale standard \\(\\mathcal{N}(0, 1)\\).\nQuindi, possiamo riscrivere la probabilità richiesta come:\n\\[\nP\\left(|\\bar{X} - \\mu| &lt; E\\right) = P\\left(|Z| &lt; z_{0.025}\\right),\n\\]\ndove \\(z_{0.025} = 1.96\\) è il quantile superiore della distribuzione normale standard corrispondente a un livello di confidenza del \\(95\\%\\).\nDalla definizione della variabile standardizzata \\(Z\\), possiamo ricavare la relazione per il margine di errore:\n\\[\n|\\bar{X} - \\mu| &lt; E \\implies Z = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}} \\implies \\left|\\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}}\\right| &lt; \\frac{E}{\\sigma / \\sqrt{n}}.\n\\]\nSostituendo la condizione \\(|Z| &lt; z_{0.025}\\), otteniamo:\n\\[\n\\frac{E}{\\sigma / \\sqrt{n}} = z_{0.025}.\n\\]\nRisolvendo per \\(\\sqrt{n}\\), moltiplichiamo entrambi i membri per \\(\\sigma / \\sqrt{n}\\):\n\\[\nE = z_{0.025} \\cdot \\frac{\\sigma}{\\sqrt{n}}.\n\\]\nIsoliamo \\(\\sqrt{n}\\) dividendo entrambi i membri per \\(z_{0.025} \\cdot \\sigma\\):\n\\[\n\\sqrt{n} = \\frac{z_{0.025} \\cdot \\sigma}{E}.\n\\]\nInfine, eleviamo entrambi i membri al quadrato per ottenere \\(n\\):\n\\[\nn = \\left(\\frac{z_{0.025} \\cdot \\sigma}{E}\\right)^2.\n\\]\nIn conclusione, la dimensione campionaria minima \\(n\\) necessaria per soddisfare il margine di errore \\(E\\) e il livello di confidenza richiesto è:\n\\[\nn = \\left(\\frac{z_{0.025} \\cdot \\sigma}{E}\\right)^2.\n\\]",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>88</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#stima-della-media-del-punteggio-di-autostima",
    "href": "chapters/frequentist_inference/03_sample_size.html#stima-della-media-del-punteggio-di-autostima",
    "title": "88  La grandezza del campione",
    "section": "\n88.4 Stima della Media del Punteggio di Autostima",
    "text": "88.4 Stima della Media del Punteggio di Autostima\nConsideriamo un esempio pratico: vogliamo stimare la media del punteggio di autostima in una popolazione di giovani adulti, utilizzando la Rosenberg Self-Esteem Scale (RSES), che assegna un punteggio compreso tra 0 e 30.\nDettagli del Problema:\n\nDeviazione standard del punteggio: \\(\\sigma = 6\\) (stimata da studi precedenti).\nMargine di errore massimo accettabile: \\(E = 2\\).\nLivello di confidenza: \\(95\\%\\).\n\nImplementiamo in R la formula derivata in precedenza.\n\n# Parametri del problema\nsigma &lt;- 6     # Deviazione standard del punteggio RSES\nE &lt;- 2         # Margine di errore desiderato\nz_alpha &lt;- qnorm(0.975)  # Quantile superiore della distribuzione normale (95% confidenza)\n\n# Calcolo della dimensione campionaria\nn &lt;- (z_alpha * sigma / E)^2\nn &lt;- ceiling(n)  # Arrotondamento all'intero successivo\nn\n#&gt; [1] 35\n\nIn conclusione, la dimensione campionaria minima necessaria per stimare la media del punteggio di autostima con un margine di errore massimo di 2 punti e un livello di confidenza del 95% è \\(n = 35\\).\n\n88.4.1 Approfondimenti\n\n\nPrecisione e Livello di Confidenza Aumentando \\(n\\), la varianza di \\(\\bar{X}\\) diminuisce:\n\\[\n\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n}.\n\\]\nQuesto restringe l’intervallo di confidenza e migliora la precisione.\n\nCosto e Praticità Un campione più grande comporta costi più elevati. È importante trovare il giusto compromesso tra precisione e fattibilità.\nAdattamento ad Altri Livelli di Confidenza Per altri livelli di confidenza, basta modificare il quantile \\(z_{\\alpha/2}\\). Ad esempio, per un livello di confidenza del 99%, \\(z_{0.005} \\approx\\) 2.576.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>88</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/03_sample_size.html#riflessioni-conclusive",
    "title": "88  La grandezza del campione",
    "section": "\n88.5 Riflessioni Conclusive",
    "text": "88.5 Riflessioni Conclusive\nDefinire la dimensione del campione rappresenta un passaggio cruciale nella progettazione di qualsiasi studio psicologico. Un approccio matematico rigoroso, fondato su analisi di potenza statistica e stime di effetti attesi, consente di ottimizzare il bilanciamento tra precisione dei risultati e limitazioni pratiche, come tempi, costi e disponibilità dei partecipanti. Questo equilibrio è fondamentale per garantire che i dati raccolti siano sufficientemente robusti da supportare conclusioni valide, senza tuttavia sprecare risorse in campioni eccessivamente ampi. Una corretta determinazione del campione contribuisce inoltre a ridurre il rischio di errori di tipo I e II, rafforzando l’integrità scientifica della ricerca.\nNel confronto tra paradigmi statistici, l’approccio frequentista si distingue per la sua enfasi sul controllo degli errori e sulla replicabilità attraverso il calcolo del valore p e della potenza statistica. Questo metodo richiede una rigorosa pianificazione preliminare, con la determinazione a priori della dimensione del campione basata su stime dell’effetto atteso e soglie prefissate di significatività e potenza. Tale rigidità metodologica, sebbene garantisca standardizzazione e controllo degli errori di Tipo I, può presentare notevoli limitazioni. In particolare, non permette modifiche alla dimensione del campione durante lo studio senza compromettere la validità statistica e può portare al problema dello “optional stopping”, dove il controllo ripetuto dei risultati aumenta il rischio di falsi positivi.\nL’approccio bayesiano, d’altra parte, offre una prospettiva complementare, ponendo l’accento sulla stima e sull’aggiornamento delle credenze in base ai dati osservati. Nel contesto bayesiano, la dimensione del campione non è solo uno strumento per garantire la significatività statistica, ma diventa un mezzo per affinare la precisione delle stime a posteriori. Questo approccio si caratterizza per una maggiore flessibilità, permettendo il monitoraggio continuo dell’evidenza attraverso i fattori di Bayes e l’aggiornamento sequenziale delle stime di probabilità. L’uso di distribuzioni a priori consente di incorporare conoscenze pregresse, portando a distribuzioni a posteriori che quantificano l’incertezza in modo più intuitivo e direttamente interpretabile.\nLa scelta di quando interrompere la raccolta dati rappresenta un esempio emblematico delle differenze tra i due approcci. Mentre il metodo frequentista richiede una dimensione campionaria fissa determinata a priori, l’approccio bayesiano permette una maggiore flessibilità, consentendo di interrompere la raccolta quando si raggiunge un livello desiderato di precisione nelle stime posteriori. Tuttavia, questa flessibilità comporta anche sfide specifiche, come la necessità di specificare distribuzioni a priori appropriate e una maggiore complessità computazionale.\nUna soluzione pragmatica potrebbe essere l’integrazione dei punti di forza di entrambi gli approcci. Si potrebbe utilizzare l’analisi della potenza frequentista per stabilire una dimensione minima del campione, implementando poi un monitoraggio bayesiano per valutare quando l’evidenza raccolta è sufficiente. Questo approccio integrato dovrebbe essere guidato da regole decisionali stabilite a priori e supportato da analisi di sensitività per valutare la robustezza delle conclusioni.\nIn sintesi, la scelta della dimensione del campione e la decisione su quando concludere la raccolta dati non dovrebbero essere viste solo come problemi tecnici, ma come opportunità per riflettere sulle priorità della ricerca, sul contesto teorico e sulle metodologie più adatte. La combinazione dei punti di forza degli approcci frequentista e bayesiano può portare a una ricerca più robusta, flessibile e informativa, contribuendo a un progresso scientifico più solido e sfaccettato. Tale scelta metodologica deve considerare gli obiettivi specifici dello studio, le risorse disponibili, i requisiti delle riviste scientifiche e la natura delle ipotesi da testare, bilanciando le esigenze di precisione con quelle di praticabilità. Pertanto, investire tempo nella pianificazione di questo aspetto non è solo una scelta metodologica, ma un imperativo etico per chiunque si impegni nella produzione di conoscenza psicologica.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>88</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#esercizi",
    "href": "chapters/frequentist_inference/03_sample_size.html#esercizi",
    "title": "88  La grandezza del campione",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nEsercizio 1: Dimensione del campione per un margine di errore prefissato\n\nEsaminando i dati raccolti, hai ottenuto una deviazione standard campionaria (stimata) \\(s \\approx 4{,}3\\) sui punteggi SWLS.\nHai stabilito di voler stimare la media SWLS con un margine di errore massimo \\(E = 2\\) punti e un livello di confidenza del 95%.\n\nUtilizzando il valore critico \\(z_{0.025} \\approx 1{,}96\\) (per il 95%), ipotizza che la deviazione standard di popolazione \\(\\sigma\\) possa essere approssimata da \\(s\\). Calcola quindi la dimensione del campione \\(n\\) necessaria:\n\\[\nn = \\left(\\frac{z_{\\alpha/2} \\times \\sigma}{E}\\right)^2.\n\\]\n\nInterpreta il risultato: è un campione grande o piccolo? Quali fattori potrebbero influenzarne la validità (ad es. la stima di \\(\\sigma\\) da soli 10 soggetti)?\n\nEsercizio 2: Aumento del livello di confidenza e influenza su \\(n\\)\n\nCon gli stessi dati dell’Esercizio 1 (stesso \\(\\sigma\\approx4{,}3\\), stesso \\(E=2\\)), calcola la dimensione \\(n\\) se volessi un livello di confidenza del 99%.\n\nConfronta tale dimensione con quella trovata al 95%.\n\nCommenta: perché un livello di confidenza più elevato richiede un campione più grande? E in che modo ciò può impattare sull’organizzazione pratica della ricerca (tempi, costi, disponibilità di partecipanti)?\n\nEsercizio 3: Potere statistico per rilevare una differenza dalla media di riferimento\n\nIpotizza che la media SWLS di riferimento (ad es. in letteratura) sia 24.\n\nVuoi un test a una coda (one-sample t-test o z-test) con \\(\\alpha = 0{,}05\\), e desideri un potere (\\(1-\\beta\\)) dell’80% di rivelare una differenza di 3 punti (cioè vuoi essere in grado di concludere che la vera media è almeno 3 punti più alta o più bassa di 24).\n\nUsa come stima della deviazione standard la stessa \\(s \\approx 4{,}3\\). Sulla base delle formule di potenza statistica per un test a una coda, calcola un numero approssimativo di soggetti \\(n\\) necessari. (Suggerimento: puoi usare formule di power analysis o fare riferimento a software R, es. power.t.test() o pwr.t.test().)\n\n\nInterpreta la dimensione campionaria trovata: è realistica per un esperimento in cui potresti raccogliere partecipanti simili a quelli del pilot? Oppure rappresenta un valore troppo elevato?\n\nEsercizio 4: Confronto tra due gruppi e potere statistico\n\nIpotizza di voler confrontare due gruppi indipendenti (ognuno con punteggi SWLS) e di voler rilevare una differenza media di 5 punti tra i due gruppi (Gruppo A vs Gruppo B).\n\nAssumi che ciascun gruppo abbia la stessa deviazione standard \\(\\sigma = 4{,}3\\).\n\nVuoi un test a due code, \\(\\alpha=0{,}05\\), e un potere dell’80%. Utilizza (se vuoi) la formula approssimata per due campioni indipendenti, oppure uno strumento in R (ad es. power.t.test con type=\"two.sample\").\n\nCalcola (o stima) la dimensione \\(n\\) per ciascun gruppo.\n\n\nCommenta: confronta il risultato con la disponibilità realistica dei partecipanti. Che implicazioni metodologiche o pratiche emergono?\n\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\nSoluzione Esercizio 1\nDati principali:\n- \\(\\sigma \\approx 4{,}3\\) (stimata dal pilot)\n- \\(E = 2\\) (margine di errore)\n- Livello di confidenza 95% \\(\\Rightarrow z_{\\alpha/2} \\approx 1{,}96\\)\nLa formula per la dimensione campionaria:\n\\[\nn = \\left(\\frac{z_{\\alpha/2} \\times \\sigma}{E}\\right)^2\n\\]\nCalcolo:\n\\[\nn\n= \\left(\\frac{1{,}96 \\times 4{,}3}{2}\\right)^2\n= \\left(\\frac{8{,}428}{2}\\right)^2\n= (4{,}214)^2\n\\approx 17{,}76.\n\\]\nArrotondando all’intero superiore:\n\\[\nn \\approx 18.\n\\]\nInterpretazione\n\nServirebbero circa 18 partecipanti (anziché 10) per ottenere un IC al 95% con margine d’errore 2, ipotizzando \\(\\sigma \\approx 4{,}3\\).\n\n\nLimiti: la \\(\\sigma\\) deriva da un campione di sole 10 persone e potrebbe non rappresentare bene la deviazione standard reale dell’intera popolazione. Se in realtà \\(\\sigma\\) fosse più grande, \\(n\\) andrebbe rivisto al rialzo; se fosse minore, 18 potrebbe essere anche sovrastimato.\n\n18 non è troppo elevato; potrebbe essere gestibile in uno studio con costi contenuti. Tuttavia, la validità dipende dalla solidità della stima di \\(\\sigma\\).\n\nSoluzione Esercizio 2\nCambio di livello di confidenza: da 95% a 99%. Ora \\(\\alpha=0{,}01\\) e \\(\\alpha/2=0{,}005\\).\nIl valore critico \\(z_{0.005}\\) è circa 2,576.\n\\[\nn = \\left(\\frac{2,576 \\times 4{,}3}{2}\\right)^2\n= \\left(\\frac{11{,}0768}{2}\\right)^2\n= (5{,}5384)^2\n\\approx 30{,}7.\n\\]\nArrotondato in eccesso:\n\\[\nn \\approx 31.\n\\]\nConfronto con i 18 trovati prima\n- Aumentando la confidenza dal 95% al 99%, la dimensione campionaria passa da ~18 a ~31, cioè un incremento notevole.\n- Motivo: per assicurare un intervallo che, nel lungo periodo, includa il vero valore nel 99% dei casi, occorre un margine di errore più “tollerante” (oppure un campione più grande per mantenere lo stesso \\(E\\)).\n- Impatto pratico: reclutare 31 soggetti (invece di 18) può pesare in termini di costi e disponibilità, ma riduce l’incertezza dell’IC dal punto di vista frequentista.\nSoluzione Esercizio 3\nPotere statistico (80%) per rilevare \\(\\Delta = 3\\) in un test a una coda contro il valore di riferimento 24.\n- \\(\\alpha=0{,}05\\) (quindi una coda, il valore critico si situa intorno a z=1.645 per la potenza, ma i calcoli precisi si fanno di solito con formule di power analysis).\n- \\(\\sigma \\approx 4{,}3\\).\n- \\(\\Delta = 3\\).\nIn R, con pwr.t.test() o power.t.test(), l’approssimazione verrebbe impostata come:\nlibrary(pwr)  # se usi pwr\npwr.t.test(d = 3/4.3, sig.level = 0.05, power = 0.80,\n           type = \"one.sample\", alternative=\"greater\")\noppure:\npower.t.test(delta = 3, sd = 4.3, sig.level = 0.05, \n             power = 0.80, type = \"one.sample\", \n             alternative = \"one.sided\")\nEsempio di risultato (numeri indicativi): potresti ottenere \\(n \\approx 20\\). (Il valore preciso cambia a seconda delle approssimazioni e del software.)\nInterpretazione\n- Con 20 soggetti, se \\(\\Delta\\) fosse veramente di 3 punti rispetto a 24, il test a una coda dovrebbe avere l’80% di chance di rigettare l’ipotesi nulla (cioè di rilevare la differenza) a \\(\\alpha=0{,}05\\).\n- Se cercassi di replicare il pilot (dove avevi 10 soggetti), probabilmente la potenza sarebbe inferiore.\n- Potresti chiederti se 20 partecipanti siano facili da reclutare o se, dal punto di vista pratico, 20 restino pochi per altre ragioni (ad es. robustezza dei modelli, normalità, outlier).\nSoluzione Esercizio 4\n\nDue campioni indipendenti, differenza attesa = 5 punti, potere = 80%, test a due code\n\nCon formula approssimata (oppure software R), i parametri tipici:\n\n\nDifferenza minima rilevabile: \\(\\Delta = 5\\)\n\n\n\\(\\sigma = 4{,}3\\) in ciascun gruppo\n\n\n\\(\\alpha = 0{,}05\\) (due code), potere = 80%\n\nTipo di test: “two-sample t test” (Gruppo A vs Gruppo B, varianze uguali)\n\nIn R con power.t.test():\npower.t.test(delta = 5, sd = 4.3, sig.level = 0.05,\n             power = 0.80, type = \"two.sample\",\n             alternative = \"two.sided\")\nEsempio di risultato: potresti ottenere \\(n \\approx 14\\) per gruppo (quindi 28 totali). (Il numero può variare leggermente a seconda delle approssimazioni.)\n\nCommento\n\n\n\n18 o 20 partecipanti totali potrebbero bastare per un one-sample test (Esercizi 1–3), ma qui servono 28 (14 per gruppo) per avere lo stesso potere su una differenza di 5 punti.\n\nIn pratica:\n\nSe hai risorse per arruolare solo 15–20 persone totali, potrebbe non esserci potere sufficiente (grande rischio di errore di tipo II).\n\nPotrebbe convenire ridurre la differenza minima desiderata (ma questo cambierebbe le conclusioni) o cercare un campione più grande.\n\n\n\nLe considerazioni metodologiche includono: “Posso davvero aspettarmi 5 punti di differenza?” Se la differenza reale fosse più piccola, servirebbe un campione ancora più grande per rilevarla con sufficiente potenza.\n\nConclusioni Finali\n\nLa dimensione del campione dipende da molti fattori:\n\nVarianza (o deviazione standard) stimata.\n\nMargine di errore desiderato (o differenza minima rilevabile).\n\nLivello di confidenza o \\(\\alpha\\).\n\nPotere statistico \\((1-\\beta)\\).\n\n\n\nI dati SWLS di un pilot di 10 persone forniscono un’indicazione iniziale (stima di \\(\\sigma\\)), ma la precisione di quella stima è limitata.\n\nPer studi sperimentali o correlazionali, i calcoli di dimensione campionaria andrebbero fatti a priori (idealmente ancor prima di raccogliere i dati) e basati su stime realistiche o su letteratura pre-esistente.\n\nSe la stima di \\(\\sigma\\) o della dimensione dell’effetto \\(\\Delta\\) è incerta, è utile svolgere analisi di sensitività, variando gli input per vedere come cambiano i risultati.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>88</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/03_sample_size.html#informazioni-sullambiente-di-sviluppo",
    "title": "88  La grandezza del campione",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.7   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.13.0 psych_2.5.3     \n#&gt;  [9] scales_1.4.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.3.0     ggplot2_3.5.2   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.4     stringi_1.8.7      lattice_0.22-7    \n#&gt;  [4] hms_1.1.3          digest_0.6.37      magrittr_2.0.3    \n#&gt;  [7] evaluate_1.0.4     grid_4.5.0         timechange_0.3.0  \n#&gt; [10] RColorBrewer_1.1-3 fastmap_1.2.0      rprojroot_2.0.4   \n#&gt; [13] jsonlite_2.0.0     mnormt_2.1.1       cli_3.6.5         \n#&gt; [16] rlang_1.1.6        withr_3.0.2        tools_4.5.0       \n#&gt; [19] parallel_4.5.0     tzdb_0.5.0         pacman_0.5.1      \n#&gt; [22] vctrs_0.6.5        R6_2.6.1           lifecycle_1.0.4   \n#&gt; [25] htmlwidgets_1.6.4  pkgconfig_2.0.3    pillar_1.10.2     \n#&gt; [28] gtable_0.3.6       glue_1.8.0         xfun_0.52         \n#&gt; [31] tidyselect_1.2.1   rstudioapi_0.17.1  farver_2.1.2      \n#&gt; [34] htmltools_0.5.8.1  nlme_3.1-168       rmarkdown_2.29    \n#&gt; [37] compiler_4.5.0",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>88</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#bibliografia",
    "href": "chapters/frequentist_inference/03_sample_size.html#bibliografia",
    "title": "88  La grandezza del campione",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGiner-Sorolla, R., Montoya, A. K., Reifman, A., Carpenter, T., Lewis Jr, N. A., Aberson, C. L., Bostyn, D. H., Conrique, B. G., Ng, B. W., Schoemann, A. M., et al. (2024). Power to detect what? Considerations for planning and evaluating sample size. Personality and Social Psychology Review, 28(3), 276–301.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>88</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html",
    "title": "\n89  Significatività statistica\n",
    "section": "",
    "text": "89.1 Introduzione\nIl test di ipotesi è un metodo fondamentale della ricerca scientifica, utilizzato per fare inferenze sui parametri della popolazione a partire dai dati campionari. Nel contesto della psicologia, questo approccio viene frequentemente impiegato per valutare l’efficacia di interventi psicologici, confrontare teorie o approcci, analizzare l’influenza di variabili psicologiche su comportamenti e processi cognitivi, e approfondire i meccanismi alla base di fenomeni complessi come apprendimento, memoria ed emozioni.\nIn questo capitolo ci focalizzeremo sul test di ipotesi frequentista, un metodo largamente utilizzato ma non privo di limiti. È importante sottolineare che la comunità statistica sconsiglia di affidarsi esclusivamente a questo approccio come criterio decisionale per valutare la validità di un risultato sperimentale.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#test-del-chi-quadrato",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#test-del-chi-quadrato",
    "title": "\n89  Significatività statistica\n",
    "section": "\n89.2 Test del Chi-Quadrato",
    "text": "89.2 Test del Chi-Quadrato\nPer introdurre il concetto di test di ipotesi nel contesto frequentista, iniziamo presentando uno dei test più semplici e utilizzati: il test del Chi-Quadrato. Questo test è particolarmente utile per valutare l’ipotesi di indipendenza tra due variabili categoriali organizzate in una tabella di contingenza (per ulteriori dettagli sulla struttura delle tabelle di contingenza, si veda il Capitolo 16).\nUna tabella di contingenza è una rappresentazione tabellare che mostra la distribuzione congiunta di due variabili categoriali. Ogni cella della tabella contiene la frequenza osservata delle combinazioni delle categorie delle due variabili. Inoltre, la tabella include i totali marginali, che rappresentano le somme delle frequenze per ciascuna riga e ciascuna colonna.\nIl test del Chi-Quadrato si pone una domanda fondamentale: “Come apparirebbe la tabella di contingenza se le due variabili fossero indipendenti?”. In altre parole, il test verifica se esiste una relazione significativa tra le due variabili o se, al contrario, le variabili sono indipendenti l’una dall’altra.\nCome già visto in precedenza analizzando la distribuzione di probabilità congiunta, si ha indipendenza quando le probabilità congiunte sono uguali al prodotto delle probabilità marginali. Partendo dalle proporzioni marginali, possiamo quindi calcolare i valori teorici attesi in ciascuna cella della tabella di contingenza, assumendo che le due variabili siano indipendenti.\nVa sottolineato che l’indipendenza è una proprietà della popolazione, non del campione. Pertanto, nei dati campionari, ci aspettiamo che i valori osservati nelle celle della tabella differiscano leggermente dai valori teorici attesi, anche se nella popolazione le variabili sono realmente indipendenti. La discrepanza complessiva tra i valori osservati e quelli attesi, calcolati sotto l’ipotesi di indipendenza, può essere misurata utilizzando una statistica chiamata Chi-Quadrato (\\(\\chi^2\\)).\nLa formula della statistica Chi-Quadrato è:\n\\[\n\\chi^2 = \\sum \\frac{(O_i - E_i)^2}{E_i} ,\n\\]\ndove:\n\n\n\\(O_i\\) rappresenta i valori osservati nelle celle della tabella,\n\n\n\\(E_i\\) rappresenta i valori attesi nelle celle, calcolati sotto l’ipotesi di indipendenza,\n\nLa somma (\\(\\sum\\)) viene effettuata su tutte le celle della tabella.\n\n\n89.2.1 Interpretazione della Statistica Chi-Quadrato\nLa statistica Chi-Quadrato misura la discrepanza complessiva tra i valori osservati e quelli attesi. Se non ci fosse differenza tra i valori congiunti osservati e quelli teorici, la statistica Chi-Quadrato sarebbe pari a zero. All’aumentare della discrepanza tra valori osservati e attesi, il valore della statistica Chi-Quadrato aumenta.\nPer valutare l’importanza della discrepanza osservata, utilizziamo la distribuzione campionaria della statistica Chi-Quadrato. Questa distribuzione descrive la probabilità di ottenere valori della statistica Chi-Quadrato sotto l’ipotesi nulla (indipendenza tra le variabili). La forma della distribuzione dipende dai gradi di libertà (\\(\\nu\\)), che si calcolano come:\n\\[\n\\nu = (n_{\\text{righe}} - 1)(n_{\\text{colonne}} - 1) ,\n\\]\ndove \\(n_{\\text{righe}}\\) e \\(n_{\\text{colonne}}\\) rappresentano rispettivamente il numero di righe e colonne della tabella di contingenza.\n\n89.2.2 Valutazione dell’Ipotesi di Indipendenza\nLa probabilità associata a una data discrepanza (\\(\\chi^2\\)) tra valori osservati e attesi, assumendo che l’ipotesi nulla sia vera, corrisponde all’area sotto la coda destra della distribuzione Chi-Quadrato, nell’intervallo [\\(C\\), \\(+\\infty\\)]. Questa probabilità è indicata come \\(p\\)-value.\nSe il \\(p\\)-value è molto piccolo (tipicamente inferiore a una soglia predefinita, come 0.05), possiamo rifiutare l’ipotesi nulla e concludere che è improbabile che le due variabili siano indipendenti nella popolazione.\n\n89.2.3 Riepilogo dei Passaggi del Test Chi-Quadrato\n\n\nCalcolo dei Valori Attesi: Per ogni cella, calcola \\(E_i\\) utilizzando la formula:\n\\[\nE_i = \\frac{\\text{Totale della Riga} \\times \\text{Totale della Colonna}}{\\text{Totale Complessivo}}\n\\]\n\n\nCalcolo della Statistica Chi-Quadrato: Usa la formula:\n\\[\n\\chi^2 = \\sum \\frac{(O_i - E_i)^2}{E_i}\n\\]\n\nDeterminazione dei Gradi di Libertà: Calcola \\(\\nu\\) come \\((n_{\\text{righe}} - 1)(n_{\\text{colonne}} - 1)\\).\nConfronto con la Distribuzione Chi-Quadrato: Determina il \\(p\\)-value associato al valore di \\(\\chi^2\\) calcolato e valuta l’ipotesi nulla.\n\nIn conclusione, il Test Chi-Quadrato rappresenta uno strumento per verificare l’indipendenza tra due variabili categoriali. Grazie alla sua semplicità di applicazione e interpretazione, costituisce un metodo di analisi largamente utilizzato in ambito psicologico, sociale e statistico. Tuttavia, è importante prestare attenzione ai presupposti del test, come la sufficienza dei dati in ogni cella, per garantire risultati affidabili e interpretabili.\n\n# Creare la tabella di contingenza\nobserved &lt;- matrix(c(44, 0, 119, \n                              55, 68, 0, \n                              47, 0, 0),\n                            nrow = 3, byrow = TRUE)\n\n# Aggiungere i nomi di righe e colonne\nrownames(observed) &lt;- c(\"Biscoe\", \"Dream\", \"Torgersen\")\ncolnames(observed) &lt;- c(\"Adelie\", \"Chinstrap\", \"Gentoo\")\n\n# Visualizzare la tabella\nprint(observed)\n#&gt;           Adelie Chinstrap Gentoo\n#&gt; Biscoe        44         0    119\n#&gt; Dream         55        68      0\n#&gt; Torgersen     47         0      0\n\n\nchi_square_result &lt;- chisq.test(observed)\nchi_square_result\n#&gt; \n#&gt;  Pearson's Chi-squared test\n#&gt; \n#&gt; data:  observed\n#&gt; X-squared = 285, df = 4, p-value &lt;2e-16\n\nSvolgiamo i calcoli “a mano” usando R. Per calcolare la statistica del test del Chi-Quadrato “a mano” in R, segui questi passaggi:\nCalcoliamo i totali per righe e colonne e il totale complessivo.\n\n# Totali marginali\nrow_totals &lt;- rowSums(observed)\ncol_totals &lt;- colSums(observed)\ngrand_total &lt;- sum(observed)\n\n# Visualizzare i totali\nprint(\"Totali marginali per righe:\")\n#&gt; [1] \"Totali marginali per righe:\"\nprint(row_totals)\n#&gt;    Biscoe     Dream Torgersen \n#&gt;       163       123        47\nprint(\"Totali marginali per colonne:\")\n#&gt; [1] \"Totali marginali per colonne:\"\nprint(col_totals)\n#&gt;    Adelie Chinstrap    Gentoo \n#&gt;       146        68       119\nprint(paste(\"Totale complessivo:\", grand_total))\n#&gt; [1] \"Totale complessivo: 333\"\n\nI valori attesi si calcolano come:\n\\[\nE_{ij} = \\frac{\\text{Totale riga} \\times \\text{Totale colonna}}{\\text{Totale complessivo}} .\n\\]\n\n# Calcolo dei valori attesi\nexpected &lt;- outer(row_totals, col_totals) / grand_total\n\n# Visualizzare i valori attesi\nprint(\"Valori attesi:\")\n#&gt; [1] \"Valori attesi:\"\nprint(expected)\n#&gt;           Adelie Chinstrap Gentoo\n#&gt; Biscoe     71.47    33.285  58.25\n#&gt; Dream      53.93    25.117  43.95\n#&gt; Torgersen  20.61     9.598  16.80\n\nLa statistica Chi-Quadrato si calcola con:\n\\[\n\\chi^2 = \\sum \\frac{(O_{ij} - E_{ij})^2}{E_{ij}} .\n\\]\n\n# Calcolo della statistica Chi-Quadrato\nchi_square_stat &lt;- sum((observed - expected)^2 / expected)\n\n# Visualizzare il risultato\nprint(paste(\"Statistica Chi-Quadrato:\", chi_square_stat))\n#&gt; [1] \"Statistica Chi-Quadrato: 284.590012688092\"\n\nI gradi di libertà si calcolano come:\n\\[\ndof = (\\text{n. righe} - 1) \\times (\\text{n. colonne} - 1) .\n\\]\n\n# Calcolo dei gradi di libertà\ndof &lt;- (nrow(observed) - 1) * (ncol(observed) - 1)\n\n# Visualizzare i gradi di libertà\nprint(paste(\"Gradi di libertà:\", dof))\n#&gt; [1] \"Gradi di libertà: 4\"\n\nConfrontiamo la statistica Chi-Quadrato con la distribuzione teorica per ottenere il p-value.\n\n# Calcolo del p-value\np_value &lt;- pchisq(chi_square_stat, df = dof, lower.tail = FALSE)\n\n# Visualizzare il p-value\nprint(paste(\"p-value:\", p_value))\n#&gt; [1] \"p-value: 2.28189154098739e-60\"\n\nInterpretazione:\nIl valore-\\(p\\) risulta molto piccolo, indicando che, se le variabili Isola e Specie fossero realmente indipendenti, sarebbe estremamente improbabile osservare una distribuzione delle specie di pinguini sulle tre isole così diversa da quella teoricamente attesa. In altre parole, il valore-\\(p\\) rappresenta la probabilità di ottenere, per puro caso, una discrepanza tra i valori osservati e quelli attesi pari o superiore a quella riscontrata nei dati.\nPoiché il valore-\\(p\\) è estremamente basso, possiamo concludere che l’ipotesi di indipendenza tra le variabili Isola e Specie non è plausibile. Questo indica che la distribuzione delle specie di pinguini varia in relazione all’isola, ovvero che conoscendo l’isola è possibile prevedere la distribuzione delle specie. In altre parole, le variabili Isola e Specie sono associate.\n\n89.2.4 Significatività Statistica: Un Concetto da Riconsiderare\nCome discusso nell’esempio precedente, un risultato è considerato “statisticamente significativo” se la probabilità che sia dovuto al caso è bassa, il che suggerisce che il risultato sia stabile o reale. Al contrario, risultati “non significativi” vengono spesso etichettati come privi di valore e ignorati. Questa semplificazione, però, può portare a gravi fraintendimenti. Ad esempio:\n\n\nDipendenza dal campione: La significatività statistica è fortemente influenzata dalla dimensione del campione; risultati apparentemente “significativi” possono emergere anche da effetti molto piccoli in campioni ampi.\n\nRisultati non significativi: Un risultato non significativo non implica che l’effetto sia nullo o irrilevante.\n\nScelte soggettive: Livelli di confidenza e test statistici differenti possono influenzare l’esito dell’analisi, portando a interpretazioni arbitrarie.\n\n89.2.5 Limiti e Applicazioni del Metodo Frequentista\nIl problema più grave dell’approccio frequentista è che esso non sempre mantiene la “promessa” di fornire una base oggettiva per la decisione statistica. Infatti, il ricorso esclusivo alla significatività statistica conduce a risultati opposti a quelli desiderati, aumentando il rischio di pubblicare risultati non replicabili o di trascurare evidenze importanti si veda il 94.\nIn alternativa, è più utile considerare il risultato osservato nel contesto scientifico più ampio, integrandolo con altre analisi. Questo approccio critico e completo consente di superare i limiti della significatività statistica e di interpretare i risultati con maggiore rigore.\n\n89.2.6 Un Caso Specifico: La Media del Campione\nTorniamo ora a esaminare il test di ipotesi all’interno del quadro frequentista, focalizzandoci sul caso di una variabile continua, diversamente dal contesto qualitativo trattato nel test del Chi-Quadrato. Per approfondire la comprensione della significatività statistica, analizzeremo in dettaglio l’utilizzo della media campionaria come stimatore della media della popolazione. Questa riflessione ci consentirà di esplorare sia i limiti che le applicazioni pratiche di tale strumento all’interno della statistica inferenziale frequentista. Attraverso questo esempio, potremo mettere in luce aspetti teorici e operativi dei test di ipotesi, nonché fornire indicazioni su come migliorare l’interpretazione dei risultati, con particolare riferimento al campo della ricerca psicologica.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#il-test-di-ipotesi",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#il-test-di-ipotesi",
    "title": "\n89  Significatività statistica\n",
    "section": "\n89.3 Il Test di Ipotesi",
    "text": "89.3 Il Test di Ipotesi\nIl test di ipotesi è un metodo statistico utilizzato per valutare se i dati sono coerenti con l’ipotesi nulla (\\(H_0\\)). L’ipotesi nulla solitamente afferma che non vi è alcun effetto o differenza significativa, mentre l’ipotesi alternativa (\\(H_1\\)) rappresenta l’affermazione che si desidera testare. I dati del campione vengono analizzati per determinare se forniscono prove sufficienti per rifiutare l’ipotesi nulla. Un passaggio cruciale consiste nel calcolare il value-p.\n\n89.3.1 La procedura di Test di Ipotesi\nEsaminiamo in dettaglio le varie fasi della procedura del test di ipotesi di stampo frequentista.\nPasso 1: Formulare l’ipotesi nulla (\\(H_0\\)) e l’ipotesi alternativa (\\(H_1\\)) basandosi sulla domanda di ricerca.\nPasso 2: Stabilire un livello di significatività, α (solitamente 0.05).\nPasso 3: Selezionare il Test Statistico appropriato, verificare eventuali assunzioni e calcolare il test statistico.\nPasso 4: Decidere se il risultato è “statisticamente significativo” secondo (a) la regione di rifiuto o (b) il valore-p.\n\nL’approccio della regione di rifiuto. Basandosi sulla distribuzione campionaria nota del test statistico, la regione di rifiuto è un insieme di valori per il test statistico per i quali l’ipotesi nulla viene rifiutata. Se il valore osservato del test statistico rientra nella regione di rifiuto, allora si rifiuta l’ipotesi nulla.\nL’approccio del valore-p. Il valore-p è la probabilità di ottenere i risultati osservati, o risultati ancora più estremi, se l’ipotesi nulla è vera.\n\nConfrontiamo il valore-p calcolato con il livello di significatività α:\n\nSe il valore-p &lt; α, si rifiuta l’ipotesi nulla (\\(H_0\\)).\nSe il valore-p ≥ α, non si rifiuta l’ipotesi nulla (\\(H_0\\)).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#il-test-di-ipotesi-nel-contesto-frequentista",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#il-test-di-ipotesi-nel-contesto-frequentista",
    "title": "\n89  Significatività statistica\n",
    "section": "\n89.4 Il Test di Ipotesi nel Contesto Frequentista",
    "text": "89.4 Il Test di Ipotesi nel Contesto Frequentista\nSi noti che i metodi bayesiani e frequentisti non sono semplicemente due approcci diversi per rispondere alla stessa domanda, ma formulano domande fondamentalmente diverse. Pertanto, per comprendere il test di ipotesi frequentista, è essenziale chiarire cosa si intende per valore-p.\nL’American Statistical Association (ASA) definisce il valore-p come:\n\nthe probability under a specified statistical model that a statistical summary of the data (e.g., the sample mean difference between two compared groups) would be equal to or more extreme than its observed value (Wasserstein e Lazar 2016).\n\nQuesta definizione può risultare difficile da comprendere perché contiene concetti complessi come “probabilità” e “modello statistico specificato”. Per capire meglio cosa rappresenta un valore-p, è necessario esaminare attentamente entrambi questi concetti. Questo ci porterà anche a una comprensione più profonda di altri concetti fondamentali per l’inferenza frequentista e ci aiuterà a distinguere tra inferenza frequentista e inferenza bayesiana.\nUna distinzione fondamentale tra l’approccio frequentista e quello bayesiano riguarda l’interpretazione della probabilità: il primo si basa sulla frequenza relativa degli eventi nel lungo periodo, mentre il secondo si basa sulla “certezza soggettiva” o sul grado di fiducia che un individuo attribuisce a un evento specifico.\nChiarito che la probabilità assume significati diversi nei contesti frequentista e bayesiano, possiamo chiederci quale nozione di probabilità sia implicita nella definizione del valore-p fornita dall’ASA. La visione comune suggerisce che si riferisca alle frequenze relative. Ma frequenze relative di cosa e ripetizioni di cosa?\nPossiamo riformulare la definizione dell’ASA in questo modo:\n\nIl valore-p si riferisce alla frequenza relativa di ottenere un riassunto statistico dei dati grande quanto o più grande del valore osservato in ripetizioni ipotetiche di un esperimento descritto da un modello statistico specificato.\n\nQuindi, l’approccio frequentista può essere descritto come un metodo per stimare il valore di un parametro attraverso esperimenti ipotetici, confrontando i nostri dati con i risultati di tali esperimenti per giudicare se i nostri dati sono sorprendenti o meno.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#applicazione-alla-media-campionaria",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#applicazione-alla-media-campionaria",
    "title": "\n89  Significatività statistica\n",
    "section": "\n89.5 Applicazione alla Media Campionaria",
    "text": "89.5 Applicazione alla Media Campionaria\nIn questo capitolo ci concentreremo sull’applicazione del processo di test di ipotesi frequentista alla media campionaria. Vedremo come la media di un campione possa essere impiegata per trarre inferenze sulla media di una popolazione, analizzandone limiti e possibili utilizzi nell’ambito dell’inferenza statistica frequentista.\nI test su uno o due campioni (one-sample e two-sample tests) hanno rappresentato le prime fondamenta dell’analisi statistica dei dati. Al giorno d’oggi, tuttavia, i nostri disegni sperimentali tendono a essere più complessi di quanto questi semplici test possano gestire. Nonostante ciò, tali test – in particolare il celebre t-test di Student – costituiscono ancora un’ottima porta d’ingresso alla modellazione statistica, poiché i principi su cui si basano sono relativamente intuitivi e consentono di familiarizzare con il processo di verifica dell’ipotesi.\nPer comprendere meglio i valori-p e la verifica del test di ipotesi, può essere molto utile ricorrere a simulazioni. Attraverso queste ultime è possibile ricreare condizioni sperimentali ipotetiche e osservare la variabilità dei risultati, fornendo così una prospettiva più chiara sulle implicazioni della statistica frequentista.\n\n89.5.1 La Distribuzione della Media Campionaria\nQuando consideriamo la media campionaria come stima della media di una popolazione, assumiamo che questa popolazione segua una distribuzione normale. Vogliamo quindi esplorare la distribuzione della media campionaria (\\(\\bar{X}\\)), che descrive la variazione di \\(\\bar{X}\\) attraverso infiniti campioni di dimensione \\(n\\). Abbiamo già dimostrato che, se la popolazione è normalmente distribuita, anche la distribuzione campionaria di \\(\\bar{X}\\) seguirà una distribuzione normale, con media \\(\\mu\\) (la media della popolazione) e deviazione standard \\(\\frac{\\sigma}{\\sqrt{n}}\\) (dove \\(\\sigma\\) è la deviazione standard della popolazione e \\(n\\) è la dimensione del campione).\n\n89.5.2 Test di Ipotesi sulla Media Campionaria\nSupponendo di conoscere \\(\\sigma\\) ma non \\(\\mu\\), utilizziamo i test di ipotesi per indagare quanto la media campionaria osservata si discosti da un valore ipotetico \\(\\mu_0\\), specificato dall’ipotesi nulla. Questo processo ci permette di valutare la plausibilità di \\(\\mu_0\\) come vera media della popolazione.\n\n89.5.3 Calcolo della Statistica del Test\nPer valutare quanto la media campionaria osservata si discosti dall’ipotesi nulla che propone \\(\\mu = \\mu_0\\), standardizziamo \\(\\bar{X}\\) usando la formula:\n\\[\nZ = \\frac{\\bar{X} - \\mu_0}{\\sigma/\\sqrt{n}}\n\\]\nQuesta trasformazione produce una variabile \\(Z\\) che segue una distribuzione normale standard \\(\\mathcal{N}(0, 1)\\). Valori estremi di \\(Z\\) (sia molto grandi che molto piccoli) suggeriscono che la media campionaria osservata è incompatibile con \\(\\mu_0\\), portando al rigetto dell’ipotesi nulla.\n\n89.5.3.1 Simulazione\nPer illustrare quanto espresso sopra attraverso una simulazione, consideriamo un esempio numerico. Supponiamo che \\(\\mu_0 = 100\\), \\(\\sigma = 15\\) e \\(n = 30\\). Vogliamo calcolare il valore-p per l’evento \\(\\bar{X} &gt; 105\\).\nLa simulazione può essere eseguita come segue:\n\n# To make the simulation reproducible\nset.seed(123)\n\nmu_0 &lt;- 100\nsigma &lt;- 15\nn &lt;- 30\nn_sim &lt;- 10000  # Number of simulations\n\n# Generate n_sim sample means from a N(mu_0, sigma/sqrt(n))\nsample_means &lt;- rnorm(n_sim, mean = mu_0, sd = sigma / sqrt(n))\n\n# Calculate the p-value as the proportion of sample means &gt; 105\np_value &lt;- mean(sample_means &gt; 105)\n\n# Print the p-value\nprint(p_value)\n#&gt; [1] 0.0339\n\nQuesto script simula la distribuzione campionaria di \\(\\bar{X}\\) sotto l’ipotesi nulla che \\(\\mu = \\mu_0\\) e calcola il valore-p per l’evento \\(\\bar{X} &gt; 105\\). Il valore-p indica la probabilità di osservare un valore di \\(\\bar{X}\\) così estremo (o più estremo) se l’ipotesi nulla fosse vera.\nIl risultato della simulazione può essere confrontato con il calcolo teorico del valore-p usando la distribuzione normale standard. Il valore \\(Z\\) per \\(\\bar{X} = 120\\) è calcolato come:\n\\[\nZ = \\frac{105 - 100}{15/\\sqrt{30}}\n\\]\nPossiamo usare la funzione stats.norm.sf() per trovare l’area sotto la curva normale standard a destra di questo valore \\(Z\\), che corrisponde al valore-p teorico.\n\n# Calculate the Z-score\nZ &lt;- (105 - 100) / (15 / sqrt(30))\nprint(Z)\n#&gt; [1] 1.826\n\n\n# Calculate the upper tail probability\nupper_tail_prob &lt;- pnorm(Z, lower.tail = FALSE)\n\nprint(upper_tail_prob)\n#&gt; [1] 0.03394\n\nOppure, in maniera equivalente\n\n# Calculate the upper tail probability\nupper_tail_prob &lt;- 1 - pnorm(105, mean = 100, sd = 15 / sqrt(30))\nprint(upper_tail_prob)\n#&gt; [1] 0.03394\n\nIl calcolo teorico mostra che il valore \\(Z\\) per una media campionaria di 105 è 1.82. Questo valore indica una deviazione sostanziale dalla media ipotizzata sotto l’ipotesi nulla (\\(\\mu_0 = 100\\)). Tale deviazione può essere quantificata dalla “sorpresa” indicata dal valore-p, dove valori-p piccoli rappresentano una maggiore sorpresa. Il valore-p ottenuto, pari a 0.0339, indica un elevato grado di sorpresa: come mostrato dalla simulazione, un valore di 105 o superiore si verifica solo nel 3.4% dei casi se l’esperimento viene ripetuto numerose volte sotto l’ipotesi nulla. Questo suggerisce che un risultato del genere è altamente improbabile se l’ipotesi nulla fosse vera.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#applicazioni-pratiche",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#applicazioni-pratiche",
    "title": "\n89  Significatività statistica\n",
    "section": "\n89.6 Applicazioni pratiche",
    "text": "89.6 Applicazioni pratiche\nNella precedente discussione, abbiamo supposto \\(\\sigma\\) nota. Tuttavia, poiché di solito non conosciamo il valore di \\(\\sigma\\) nella pratica, dobbiamo stimarlo utilizzando la deviazione standard campionaria \\(s\\). Pertanto, al posto di \\(\\sigma\\), possiamo utilizzare \\(s\\), ottenendo così la statistica:\n\\[\nT = \\frac{\\bar{X} - \\mu_0}{\\frac{s}{\\sqrt{n}}}.\n\\]\nSi può dimostrare che la statistica \\(T\\) segue una distribuzione \\(t\\) di Student con \\(n-1\\) gradi di libertà se il campione casuale è stato estratto da una popolazione normale.\nA questo punto, possiamo applicare la stessa logica descritta in precedenza e possiamom basarci sulla statistica \\(T\\) per testare un’ipotesi sulla media della popolazione. Utilizzando il valore critico appropriato dalla distribuzione \\(t\\) di Student con \\(n-1\\) gradi di libertà e un livello di significatività predefinito, possiamo determinare se i dati osservati supportano o respingono l’ipotesi nulla sulla media della popolazione.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#ipotesi-statistiche",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#ipotesi-statistiche",
    "title": "\n89  Significatività statistica\n",
    "section": "\n89.7 Ipotesi statistiche",
    "text": "89.7 Ipotesi statistiche\nEsaminiamo in maggior dettaglio la procedura di test di ipotesi statistiche nel contesto frequentista. Definiamo innanzitutto l’ipotesi statistica come una dichiarazione riguardante la distribuzione di probabilità di una variabile casuale. Tale ipotesi può riguardare la forma funzionale della distribuzione o i parametri che la caratterizzano.\nIn particolare, l’ipotesi che riguarda i parametri di una o più popolazioni viene denominata ipotesi nulla e viene rappresentata come \\(H_0\\). Per un parametro sconosciuto \\(\\theta\\), l’ipotesi nulla viene formulata come:\n\\[\nH_0: \\theta \\in \\Theta_0 \\subset \\Theta,\n\\]\ndove \\(\\Theta_0\\) è un sottoinsieme del dominio \\(\\Theta\\), che rappresenta tutti i possibili valori del parametro \\(\\theta\\) coerenti con il modello statistico adottato. L’ipotesi nulla può essere semplice se \\(\\Theta_0\\) contiene un unico elemento, oppure composta se contiene più di un elemento.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#i-passi-di-un-test-di-ipotesi",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#i-passi-di-un-test-di-ipotesi",
    "title": "\n89  Significatività statistica\n",
    "section": "\n89.8 I passi di un test di ipotesi",
    "text": "89.8 I passi di un test di ipotesi\nPer prendere una decisione tra accettare o respingere l’ipotesi nulla, i frequentisti utilizzano un test statistico. Un test statistico frequentista ci permette di valutare se i dati osservati forniscono prove sufficienti per respingere o accettare un’ipotesi riguardante una proprietà di una popolazione di interesse e si può descrivere nel modo seguente.\nIniziamo formulando l’ipotesi nulla \\(H_0\\), che rappresenta un’affermazione specifica sulla popolazione. L’ipotesi alternativa \\(H_1\\) viene formulata come l’evento complementare rispetto all’evento specificato dall’ipotesi nulla. Successivamente, definiamo una statistica campionaria \\(\\mathcal{G}_n(X_1, \\dots, X_n)\\) che viene calcolata a partire dai dati campionari e che ha una distribuzione nota quando l’ipotesi nulla è vera.\nSuccessivamente, suddividiamo l’insieme di tutte le possibili realizzazioni della statistica \\(\\mathcal{G}_n\\) in due insiemi disgiunti: la “regione di accettazione” \\(\\mathcal{A}\\) e la sua regione complementare, la “regione di rifiuto” \\(\\mathcal{R}\\). La regione di accettazione rappresenta l’insieme dei valori che la statistica può assumere sotto l’ipotesi nulla, mentre la regione di rifiuto rappresenta l’insieme dei valori che la statistica può assumere se l’ipotesi nulla è falsa.\nInfine, selezioniamo un livello di significatività \\(\\alpha\\), che rappresenta la massima probabilità di respingere erroneamente l’ipotesi nulla quando questa è vera. Se l’osservazione della statistica \\(\\mathcal{G}_n\\) rientra nella regione di accettazione, allora l’ipotesi nulla non viene respinta; altrimenti, viene respinta a favore dell’ipotesi alternativa.\nIn sintesi, il test statistico ci consente di stabilire se i dati osservati forniscono sufficienti evidenze per rifiutare l’ipotesi nulla a favore dell’ipotesi alternativa.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#ipotesi-alternativa",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#ipotesi-alternativa",
    "title": "\n89  Significatività statistica\n",
    "section": "\n89.9 Ipotesi alternativa",
    "text": "89.9 Ipotesi alternativa\nDurante un test di ipotesi, dopo aver definito l’ipotesi nulla \\(H_0\\), possono essere considerate diverse ipotesi alternative \\(H_1\\). Le ipotesi alternative più comuni si suddividono in tre tipi:\n\n\n\\(H_1: \\theta \\neq \\theta_0\\),\n\n\\(H_1: \\theta &gt; \\theta_0\\),\n\n\\(H_1: \\theta &lt; \\theta_0\\).\n\nQueste corrispondono rispettivamente a un test bidirezionale, un test unilaterale superiore (o destro) e un test unilaterale inferiore (o sinistro).\nLa scelta dell’ipotesi alternativa determina la definizione della regione di rifiuto \\(\\mathcal{R}\\) dell’ipotesi nulla \\(H_0\\). La regione di rifiuto rappresenta i valori estremi della distribuzione, nella direzione dell’ipotesi alternativa \\(H_1\\). Nel caso di un test unilaterale inferiore, \\(\\mathcal{R}\\) si trova nella coda sinistra della distribuzione, nell’intervallo [\\(-\\infty\\), \\(\\theta_0\\)]. Nel caso di un test unilaterale superiore, \\(\\mathcal{R}\\) si trova nella coda destra della distribuzione, nell’intervallo [\\(\\theta_0\\), \\(\\infty\\)].\nI valori critici sono i valori che delimitano la regione di rifiuto \\(\\mathcal{R}\\) in un test unilaterale e i valori che delimitano le regioni di rifiuto \\(\\mathcal{R}\\) in un test bidirezionale. Il risultato di un test viene considerato statisticamente significativo se il valore della statistica del test si trova nella regione di rifiuto \\(\\mathcal{R}\\).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#valore-p",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#valore-p",
    "title": "\n89  Significatività statistica\n",
    "section": "\n89.10 Valore-p",
    "text": "89.10 Valore-p\nIl valore-p è definito come la probabilità che la statistica del test assuma un valore uguale o più estremo di quello osservato, considerando la distribuzione campionaria costruita assumendo come vera l’ipotesi nulla. La significatività statistica viene convenzionalmente definita come un valore-p inferiore a 0.05, indicando che l’evidenza osservata è improbabile da ottenere se l’ipotesi nulla è vera. Se il risultato osservato non raggiunge la significatività statistica, significa che la stima non è statisticamente significativa e che il valore osservato può essere spiegato da una semplice variazione casuale.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#un-esempio-motivante",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#un-esempio-motivante",
    "title": "\n89  Significatività statistica\n",
    "section": "\n89.11 Un esempio motivante",
    "text": "89.11 Un esempio motivante\nPer esplorare il concetto di significatività statistica, possiamo prendere in considerazione uno studio svolto da Mehr et al. (2016) sul ruolo della musica nella trasmissione di messaggi sociali ai bambini. La musica è una forma d’arte presente in molte attività quotidiane e può trasmettere informazioni relative alla cultura e all’appartenenza sociale. Gli autori dello studio hanno voluto indagare se i bambini di soli 5 mesi avessero una preferenza per individui sconosciuti che cantavano loro una canzone familiare rispetto ad altri individui sconosciuti che cantavano una canzone simile, ma con una diversa melodia.\nDalle analisi condotte da Mehr et al. (2016) è emerso che la preferenza dei bambini si manifestava solo quando la canzone veniva cantata dai loro genitori durante la fase di familiarizzazione, ma non quando la stessa canzone veniva cantata da un estraneo. Secondo gli autori, questo dimostra che il significato sociale è un elemento chiave nella preferenza dei bambini, oltre alla familiarità con la canzone.\n\n89.11.1 Domanda della ricerca e ipotesi statistiche\nLa ricerca condotta da Mehr et al. (2016) si è concentrata sullo studio dell’influenza della musica sui messaggi sociali trasmessi ai bambini molto piccoli. Tuttavia, come molte altre ipotesi psicologiche, l’ipotesi principale non può essere valutata direttamente in termini quantitativi. Pertanto, i ricercatori devono formulare ipotesi statistiche, che, sebbene non coincidano con l’ipotesi della ricerca, possono essere esaminate in termini probabilistici.\nPer chiarire questo punto, consideriamo l’esperimento condotto sui bambini da Mehr et al. (2016). Dopo la fase di familiarizzazione con la canzone di prova, i bambini partecipanti sono stati sottoposti a un test in laboratorio, durante il quale sono stati mostrati due video. Nel primo video, un estraneo cantava la canzone di prova, mentre nel secondo video, un altro individuo cantava una canzone simile ma non familiare ai bambini. I ricercatori hanno misurato il tempo in cui i bambini fissavano ciascun video. Nel primo esperimento, la variabile dipendente era la media delle proporzioni di tempo che i bambini fissavano il video “familiare” rispetto al tempo di fissazione totale. Poiché l’ipotesi principale non può essere valutata direttamente, i ricercatori hanno formulato ipotesi statistiche che possono essere esaminate in termini probabilistici.\nPoiché nei tipici esperimenti psicologici, come nel caso della ricerca di Mehr et al. (2016), l’ipotesi della ricerca non può essere valutata direttamente, è necessario stabilire una connessione tra l’ipotesi della ricerca e l’ipotesi statistica. Nel caso specifico, ci sono tre possibili scenari da considerare:\n\nNel caso in cui i bambini non mostrino alcuna preferenza tra i due tipi di video-registrazione, la media delle proporzioni di tempo di fissazione per la popolazione sarà uguale a \\(\\mu = 0.5\\), in quanto i tempi di fissazione saranno uguali in media per le due video-registrazioni.\nSe invece gli autori della ricerca hanno ragione, i bambini mostreranno una preferenza per il video con la canzone familiare rispetto a quello con la canzone non familiare. In questo caso, l’ipotesi statistica sarà \\(\\mu &gt; 0.5\\), dove \\(\\mu = 0.5\\) rappresenta il livello di probabilità casuale.\nInfine, una terza possibilità è che i bambini siano maggiormente attratti da una melodia non familiare, contrariamente a quanto suggerito dagli autori della ricerca. In tal caso, l’ipotesi statistica diventa \\(\\mu &lt; 0.5\\).\n\nLe tre ipotesi precedenti sono esempi di ipotesi statistiche, che sono delle affermazioni riguardanti i valori di un parametro di un modello statistico. Nel caso dell’esperimento di Mehr et al. (2016), il modello statistico riguarda la distribuzione delle proporzioni dei tempi di fissazione di una popolazione virtuale di infiniti bambini di sei mesi di età. Ogni bambino avrà una proporzione di tempi di fissazione diversa dagli altri bambini. Il modello statistico descritto dai ricercatori rappresenta la distribuzione dei possibili valori della proporzione del tempo di fissazione nei confronti del video “familiare”. I dati raccolti dagli sperimentatori corrispondono alla media della proporzione del tempo di fissazione del video “familiare” e possono essere messi in relazione con il modello statistico.\n\n89.11.2 Domanda della ricerca e ipotesi statistiche\nLa distinzione tra l’ipotesi della ricerca e l’ipotesi statistica è cruciale durante il test delle ipotesi. L’ipotesi della ricerca riguarda l’affermazione che si intende testare sulla natura dei fenomeni psicologici, mentre l’ipotesi statistica riguarda il modello generativo dei dati, ovvero le proprietà della popolazione. Nel caso dell’esperimento condotto da Mehr e colleghi, l’ipotesi della ricerca afferma che la preferenza sociale dei bambini è influenzata dalla musica e, in particolare, dalla familiarità con i materiali musicali. L’ipotesi statistica, invece, sostiene che la media della proporzione del tempo di fissazione dei bambini sul video “familiare” sia maggiore di 0.5.\nI test di ipotesi vengono applicati alle ipotesi statistiche, non alle ipotesi della ricerca. Ciò significa che se l’esperimento non viene condotto nella maniera appropriata, il collegamento tra l’ipotesi statistica e la domanda della ricerca può essere spezzato. Ad esempio, se l’attore che canta la melodia familiare assomiglia ad uno dei genitori del bambino, mentre l’altro attore ha un aspetto molto diverso, allora potrebbe essere facile trovare evidenze a supporto dell’ipotesi statistica secondo cui la proporzione media del tempo di fissazione dei bambini nei confronti del video “familiare” è maggiore di 0.5, ma ciò non avrebbe nulla a che fare con la domanda della ricerca.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#ipotesi-nulla-e-ipotesi-alternativa",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#ipotesi-nulla-e-ipotesi-alternativa",
    "title": "\n89  Significatività statistica\n",
    "section": "\n89.12 Ipotesi nulla e ipotesi alternativa",
    "text": "89.12 Ipotesi nulla e ipotesi alternativa\nFino a qui il ragionamento è stato semplice: il ricercatore ha un’ipotesi a proposito dei fenomeni psicologici e a tale ipotesi di ricerca corrisponde un’ipotesi statistica che riguarda il meccanismo generativo dei dati. Se il fenomeno psicologico possiede le proprietà suggerite dall’ipotesi della ricerca, allora il ricercatore può aspettarsi che i dati osservati abbiano alcune specifiche caratteristiche. A questo punto, però, il ragionamento diventa contro-intuitivo perché non è possibile verificare direttamente l’ipotesi statistica che corrisponde alla domanda della ricerca.\n\n89.12.1 Apagogia\nIn linea di principio, non è mai possibile dimostrare direttamente la verità di una proposizione. Tuttavia, possiamo dimostrare la sua verità in modo indiretto, ovvero provando la falsità della sua proposizione complementare.\nL’esempio classico è il seguente. Consideriamo la seguente proposizione: “Tutti i cigni sono bianchi” (questo è l’esempio ornitologico preferito da Popper). L’osservazione di un numero qualsiasi di cigni bianchi non è sufficiente a dimostrare la verità di questa proposizione – infatti, ci potrebbe essere da qualche parte un cigno non bianco che non abbiamo osservato (e infatti c’è). D’altra parte, invece, l’osservazione di un solo cigno che non sia bianco (ovvero, per esempio, l’osservazione di un cigno nero proveniente dall’Australia) può falsificare la proposizione considerata. Questa è la logica del falsificazionismo di Popper.\nQuesto modo di pensare è stato trasferito nella procedura di test di ipotesi di stampo frequentista. Dato che non possiamo dimostrare vera l’ipotesi statistica associata alla domanda della ricerca, seguiamo il percorso opposto. Ovvero, ci poniamo l’obiettivo di dimostrare falso l’evento complementare a quello specificato dall’ipotesi statistica associata alla domanda della ricerca. L’ipotesi statistica che vorremmo falsificare si chiama “ipotesi nulla” e viene denotata con \\(H_0\\). Nel caso dell’esempio che stiamo discutendo, l’ipotesi nulla è: \\(\\mu \\leq 0.5\\). Si noti che l’ipotesi nulla include tutte le possibili ipotesi statistiche che si possono formulare (ovvero, \\(\\mu = 0.5\\) e \\(\\mu &lt; 0.5\\)), ad eccezione di quella che è associata all’ipotesi della ricerca (ovvero, \\(\\mu &gt; 0.5\\)). Questo definisce, nel caso presente, un test unilaterale.\nIn pratica, ciò che stiamo facendo è dividere tutti i possibili valori di \\(\\mu\\) in due gruppi: quei valori che sono coerenti con l’ipotesi della ricerca (ovvero, i valori che specificano l’ipotesi alternativa, denotata con \\(H_1\\)) e quei valori che non sono coerenti con l’ipotesi della ricerca (ovvero, i valori che specificano l’ipotesi nulla).\nAvendo detto questo, la cosa importante da riconoscere è che l’obiettivo di un test di ipotesi frequentista non è quello di dimostrare che l’ipotesi alternativa è (probabilmente) vera; l’obiettivo è mostrare che l’ipotesi nulla è (probabilmente) falsa. La maggior parte delle persone ritiene che questo modo di ragionare sia piuttosto strano.\n\n89.12.2 La similitudine del processo penale\nUn test di ipotesi è spesso comparato ad un processo penale, dove l’ipotesi nulla rappresenta l’imputato, il ricercatore il pubblico ministero, e il test statistico il giudice. Così come in un processo penale, anche in un test di ipotesi c’è una presunzione di innocenza, dove l’ipotesi nulla viene considerata vera a meno che il ricercatore non dimostri, con evidenza al di là di ogni ragionevole dubbio, che è falsa. Il ricercatore progetta l’esperimento in modo da massimizzare la possibilità che i dati producano una condanna dell’ipotesi nulla. Il test statistico, rappresentato dal giudice in questa metafora, stabilisce le regole che devono essere seguite per giungere al verdetto e tali regole sono pensate per proteggere l’ipotesi nulla. In particolare, sono studiate per garantire che la probabilità di una condanna sia bassa se l’ipotesi nulla è effettivamente vera. È importante sottolineare che l’ipotesi nulla deve essere protetta, poiché il ricercatore sta cercando di dimostrare che essa è falsa.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#due-tipi-di-errori",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#due-tipi-di-errori",
    "title": "\n89  Significatività statistica\n",
    "section": "\n89.13 Due tipi di errori",
    "text": "89.13 Due tipi di errori\nPrima di entrare nei dettagli su come viene costruito un test statistico è utile capire la logica su cui esso è basato. In precedenza abbiamo paragonato il test di ipotesi nulla ad un processo penale, ma ora dobbiamo essere più espliciti. Idealmente, vorremmo costruire il nostro test in modo da non commettere errori. Sfortunatamente, però, questo non è possibile: a volte il ricercatore è sfortunato e finisce per prendere la decisione sbagliata, anche se adotta un processo decisionale razionale. Ad esempio, può succedere che una moneta venga lanciata 10 volte di fila e produca testa tutte le 10 volte. Ciò sembra fornire una prova molto forte del fatto che la moneta è sbilanciata, ma c’è una possibilità su 1024 che ciò accada anche se la moneta è equilibrata. In altre parole, nella vita reale dobbiamo sempre accettare la possibilità che le nostre scelte siano sbagliate, anche quando sembrano ragionevoli. Di conseguenza, l’obiettivo dei test delle ipotesi statistiche non è quello di eliminare completamente gli errori (questo è impossibile), ma di ridurre gli errori al minimo.\nA questo punto, dobbiamo precisare meglio cosa intendiamo per “errori”. Iniziamo con il rendere esplicito quello che è ovvio: l’ipotesi nulla può essere vera o falsa, e il nostro test ci può condurre a rifiutare l’ipotesi nulla o a non rifiutarla. La decisione di rigettare o non rigettare l’ipotesi nulla ci espone dunque al rischio di commettere uno di due tipi di errore, come indicato nella figura seguente. L’errore di I tipo, denotato con \\(\\alpha\\), è quello che commettiamo se rigettiamo l’ipotesi nulla quando essa è vera; l’errore di II tipo, denotato con \\(\\beta\\), è quello che commettiamo se accettiamo l’ipotesi nulla mentre invece è vera l’ipotesi alternativa.\n\n\n89.13.1 Errore di I tipo: la protezione dei diritti dell’imputato\nIn precedenza abbiamo paragonato il test statistico ad un processo penale. Infatti, un processo penale richiede che si stabilisca la colpevolezza dell’imputato “oltre ogni ragionevole dubbio”. Le regole del processo penale sono state progettate per garantire che non ci sia (quasi) nessuna possibilità di condannare ingiustamente un imputato innocente: il processo penale è progettato (almeno in teoria) per proteggere i diritti dell’imputato. Detto in altri termini, il processo penale non mette sullo stesso piano i due tipi di errore che si possono commettere: punire un innocente o assolvere un colpevole. L’errore che consiste nel punire un innocente viene considerato assai più grave di quello che porta ad assolvere un colpevole.\nUn test statistico fa praticamente la stessa cosa: i test di ipotesi statistiche sono costruiti in modo tale da controllare la probabilità di un errore di I tipo, con l’obiettivo di mantenerla al di sotto di una certa soglia prefissata. Questa probabilità, denotata con \\(\\alpha\\), viene chiamata “livello di significatività del test”. Usando parole diverse, possiamo dire che un test di ipotesi ha un livello di significatività \\(\\alpha\\) se il tasso di errore di I tipo non è più grande di \\(\\alpha\\). Per convenzione, i ricercatori fanno uso di tre diversi livelli \\(\\alpha\\): 0.05, 0.01 e 0.001.\n\n89.13.2 Errore di II tipo: l’asimmetria del giudizio\nChe dire del tasso di errore di II tipo? In realtà, vorremmo tenere anche quello sotto controllo e denotiamo la probabilità di un errore di II tipo con \\(\\beta\\). Il livello d’errore \\(\\beta\\) viene raramente discusso ed è molto più comune fare riferimento alla potenza del test, che è la probabilità dell’evento complementare, ovvero la probabilità con cui rifiutiamo l’ipotesi nulla quando è realmente falsa, ovvero \\(1-\\beta\\). Un test viene detto “potente” quando è caratterizzato da un piccolo valore \\(\\beta\\) pur mantenendo il livello \\(\\alpha\\) sotto una piccola soglia di probabilità prefissata.\nSi noti l’asimmetria qui rivelata: i test di ipotesi sono progettati per garantire che il livello \\(\\alpha\\) sia mantenuto sotto la soglia prefissata, ma non esiste alcuna corrispondente garanzia a proposito di \\(\\beta\\). Sicuramente è preferibile che il tasso di errore di II tipo sia piccolo, e in generale i ricercatori cercano di progettare i loro esperimenti in maniera tale da avere una ragionevole potenza del test (\\(1 - \\beta\\)) – questo si ottiene utilizzando un campione sufficientemente grande – ma nella logica della costruzione del test di ipotesi questo aspetto è secondario rispetto alla necessità di controllare il tasso di errore di I tipo.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#come-si-costruisce-un-test-di-ipotesi",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#come-si-costruisce-un-test-di-ipotesi",
    "title": "\n89  Significatività statistica\n",
    "section": "\n89.14 Come si costruisce un test di ipotesi?",
    "text": "89.14 Come si costruisce un test di ipotesi?\nRitorniamo all’esempio relativo allo studio di Mehr et al. (2016). In questo caso, sulla base all’ipotesi della ricerca, l’ipotesi nulla può essere formulata come \\(H_0: \\mu \\leq 0.5\\). Esaminando un campione di 32 bambini di età media pari a 5.6 mesi, Mehr et al. (2016) hanno scoperto che, in media, i bambini dirigevano lo sguardo verso il video “familiare” nel 56% del tempo totale di fissazione. Dunque, la media campionaria è \\(\\bar{X} = 0.56\\) Questo è il valore campionario rilevante per il test dell’ipotesi nulla.\nIngenuamente, potremmo pensare che, per decidere se \\(H_0\\) sia falsa o meno, sia sufficiente confrontare la proporzione calcolata nel campione con il valore \\(\\pi\\) specificato dall’ipotesi nulla. Nel caso presente, l’ipotesi nulla non specifica un unico valore \\(\\mu\\) ma bensì un intervallo di valori: \\([0, 0.5]\\). I dati campionari specificano un valore \\(\\bar{X} = 0.56\\), ovvero un valore che non è incluso nell’intervallo specificato da \\(H_0\\). Questo è incoraggiante. Se invece avessimo osservato \\(\\bar{X} = 0.41\\), per esempio, allora non ci sarebbe stato nient’altro da dire: se i dati osservati sono compatibili con \\(H_0\\) non c’è bisogno di eseguire alcun test statistico – abbiamo già trovato la risposta alla domanda della ricerca.\n\n89.14.1 La variabilità campionaria\nNel caso dell’esperimento di Mehr et al. (2016) che stiamo discutendo, \\(\\bar{X}\\) non cade nell’intervallo specificato da \\(H_0\\). Sulla base del valore osservato \\(\\bar{X} = 0.56\\) possiamo dunque concludere che \\(H_0\\) è falsa? Non così presto. Non è sufficiente trovare una differenza \\(\\bar{X} - \\mu\\) nella direzione giusta (cioè positiva, nel nostro caso). È anche necessario tenere in considerazione il fenomeno della variabilità campionaria.\nInfatti, la media \\(\\bar{X}\\) osservata in ogni singolo campione di ampiezza \\(n=32\\) è una variabile aleatoria: in ciascun possibile campione di ampiezza 32 i bambini si comportano in maniera diversa e, di conseguenza, \\(\\bar{X}\\) assumerà un valore diverso da campione a campione. Le statistiche campionarie – nel nostro caso la media \\(\\bar{X}\\) – sono di necessità diverse dai parametri. Ciò a cui noi siamo interessati è la media della popolazione, ovvero \\(\\mu\\), ma sfortunatamente conosciamo solo una sua realizzazione campionaria, ovvero \\(\\bar{X}\\).\nRisulta dunque chiaro che la nostra decisione rispetto ad \\(H_0\\) non può essere unicamente basata sulla differenza tra \\(\\bar{X} - \\mu\\). Infatti, è ragionevole pensare che, indipendentemente dal fatto che l’ipotesi nulla sia vera o meno, in alcuni campioni la differenza \\(\\bar{X} - \\mu\\) sarà positive mentre in altri campioni sarà negativa. Dobbiamo dunque trovare una procedura che riduca la possibilità di rifiutare \\(H_0\\) per effetto del caso soltanto. Possiamo (e dobbiamo) fare di meglio che considerare unicamente la differenza \\(\\bar{X} - \\mu\\).\n\n89.14.2 Le distribuzioni delle statistiche test\nIl metodo seguito dall’approccio frequentista per affrontare questo problema è quello di costruire la distribuzione della statistica test \\(\\mathcal{G}_n\\), rilevante per il test di \\(H_0\\), assumendo come vera l’ipotesi nulla. Questo è il concetto più contro-intuitivo di tutta la procedura di test di ipotesi dell’approccio frequentista. Esaminiamolo più in dettaglio.\nLo scopo della procedura di test statistici dell’approccio frequentista non è quello di verificare l’ipotesi alternativa: questo non è logicamente possibile. Invece, come suggerito dalla similitudine del processo penale all’ipotesi nulla, l’approccio frequentista si pone l’obiettivo di determinare se ci siano indizi sufficienti per “condannare” l’ipotesi nulla, ovvero, per rigettarla. In questa reductio ad absurdum, la “presunzione di innocenza” di \\(H_0\\) corrisponde all’idea che dobbiamo assumere come vera l’ipotesi nulla fino a prova contraria.\nNell’esempio che stiamo discutendo, assumere come vera l’ipotesi nulla significa assumere che il parametro \\(\\mu\\) (la media della popolazione) sia uguale a 0.5. Sulla base di questa assunzione, per i dati dell’esempio presente, è possibile costruire la distribuzione delle medie dei campioni di ampiezza 32. Standardizzando poi la media del campione, è possibile stabilire quanto sia “distante” dal valore atteso della distribuzione campionaria costruita assumento come vera \\(H_0\\).\nLa standardizzazione di \\(\\bar{X}\\) si effettua mediante il rapporto\n\\[\nT = \\frac{\\bar{X} - \\mu}{\\frac{s}{\\sqrt{n}}},\n\\]\ndove \\(\\bar{X}\\) è la media del campione (nel nostro caso, 0.56), \\(s\\) è la deviazione standard del campione (gli autori riportano \\(s\\) = 0.179) e \\(n\\) è l’ampiezza del campione (ovvero, \\(n\\) = 32). Per il caso presente otteniamo:\n\nT &lt;- (0.56 - 0.50) / (0.179 / sqrt(32))\nprint(T)\n#&gt; [1] 1.896\n\n\n89.14.3 Regioni di rifiuto e regioni di non rifiuto\nConoscendo la distribuzione dei valori della statistica test (distribuzione determinata assumendo come vera \\(H_0\\)) diventa poi possibile dividere l’insieme dei valori possibili di \\(\\mathcal{G}_n\\) (il nome che abbiamo assegnato ad una generica statistica test) in due regioni: i valori che ci portano a rigettare \\(H_0\\) (regione di rifiuto) e quelli che non ci consentono di rigettare \\(H_0\\) (regione di non rifiuto).\nPer decidere quanto deve essere grande la regione di rifiuto di \\(H_0\\) è sufficiente collocare nella regione di rifiuto i valori estremi della statistica test \\(\\mathcal{G}_n\\), ovvero quelli che sarebbe molto improbabile osservare se \\(H_0\\) fosse vera.\n\n89.14.4 Quando rifiutare l’ipotesi nulla\nSupponiamo che la figura seguente rappresenti la distribuzione campionaria della statistica test \\(\\mathcal{G}_n\\).\n\nSe i dati producono la statistica test \\(\\mathcal{G}_n^1\\), non possiamo rifiutare l’ipotesi nulla \\(H_0\\). Se invece i dati producono \\(\\mathcal{G}_n^2\\) allora possiamo rifiutare l’ipotesi nulla in favore dell’ipotesi alternativa. Ci sono varie cose da notare.\n\nLa regione di rifiuto è costituita da valori lontani dal centro della distribuzione campionaria della statistica test, la quale è stata costruita assumendo come vera \\(H_0\\).\nLa regione di rifiuto è situata nelle code della distribuzione. Vedremo in seguito anche degli esempi di regioni di rifiuto unilaterali.\nIn questa discussione, l’ipotesi alternativa non è menzionata. Rifiutiamo o non rifiutiamo \\(H_0\\) basandoci unicamente sulla distribuzione campionaria \\(f(\\mathcal{G}_n \\mid H_0)\\), cioè sulla probabilità della statistica test condizionata all’ipotesi nulla \\(H_0\\). L’ipotesi alternativa \\(H_1\\) viene presa in considerazione quando si sceglie dove posizionare la regione di rifiuto di \\(H_0\\), ma formalmente non gioca alcun ruolo nel rigettare o meno \\(H_0\\).\n\n89.14.5 Specificazione delle regioni di rifiuto\nL’ipotesi alternativa \\(H_1\\) può assumere forme diverse e ciò conduce a specificazioni diverse della regione di rifiuto \\(\\mathcal{R}\\) di \\(H_0\\). La regione di rifiuto \\(\\mathcal{R}\\) dell’ipotesi nulla corrisponde ai valori collocati agli estremi della distribuzione secondo la direzione dell’ipotesi alternativa \\(H_1\\).\n\nSe l’ipotesi alternativa è \\(H_1: \\theta \\neq \\theta_0\\) (dove \\(\\theta\\) è un generico parametro e \\(\\theta_0\\) è uno specifico valore del parametro), allora le evidenze coerenti con l’ipotesi alternativa (e che portano al rigetto di \\(H_0\\)) sono contenute negli intervalli \\([-\\infty, \\theta_0]\\) e \\([\\theta_0, +\\infty]\\).\nSe l’ipotesi alternativa è \\(H_1: \\theta &lt; \\theta_0\\), allora le evidenze coerenti con l’ipotesi alternativa (e che portano al rigetto di \\(H_0\\)) sono contenute nell’intervallo \\([-\\infty, \\theta_0]\\) e l’intera regione di rifiuto \\(\\mathcal{R}\\) è collocata nella coda di sinistra della distribuzione.\nSe l’ipotesi alternativa è \\(H_1: \\theta &gt; \\theta_0\\), allora le evidenze coerenti con l’ipotesi alternativa (e che portano al rigetto di \\(H_0\\)) sono contenute nell’intervallo \\([\\theta_0, \\infty]\\) e l’intera regione di rifiuto \\(\\mathcal{R}\\) è collocata nella coda di destra della distribuzione.\n\nSi chiamano valori critici i valori che delimitano la regione di rifiuto \\(\\mathcal{R}\\) in un test unilaterale e i valori che delimitano le regioni di rifiuto \\(\\mathcal{R}\\) in un test bilaterale. In un test bidirezionale, i valori critici lasciano in ciascuna delle due code della distribuzione della statistica test una probabilità pari a \\(\\alpha/2\\); in un test unidirezionale lasciano una probabilità pari ad \\(\\alpha\\) in una sola coda. Il risultato di un test si dice statisticamente significativo quando il valore della statistica test ricade nella regione di rifiuto \\(\\mathcal{R}\\).\n\n89.14.6 La decisione statistica\nIl processo di decisione statistica viene descritto da von Mises (1964) nel modo seguente:\n\nControllare (checking) o saggiare (testing) ha la forma seguente: se il “risultato osservato” ha una ‘piccola’ probabilità subordinatamente all’ipotesi assunta, respingiamo l’ipotesi. (p. 441)\n\nOvviamente l’ipotesi a cui von Mises fa riferimento è l’ipotesi nulla.\nIn pratica, possiamo decidere se rigettare o meno l’ipotesi nulla in due modi: determinando se la statistica test \\(\\mathcal{G}_n\\) cade o meno nella regione di rifiuto (come abbiamo descritto sopra) o confrontando il valore-\\(p\\) con \\(\\alpha\\) – i due metodi sono equivalenti.\nIl valore-p rappresenta la probabilità di osservare un valore della statistica test \\(\\mathcal{G}_n\\) pari a quello effettivamente osservato, o maggiore, quanto l’ipotesi nulla è vera. Se il valore-\\(p\\) è minore del livello di significatività \\(\\alpha\\), allora la statistica test cade nella regione di rifiuto di \\(H_0\\) e ciò conduce al rifiuto dell’ipotesi nulla. Tali concetti sono riassunti nella tabella seguente.\n\nPer l’esempio in discussione, la statistica \\(T\\) calcolata sopra si distribuisce come \\(t\\) di Student con \\(\\nu = 31\\) gradi di libertà. Il valore-p corrisponde dunque all’area sottesa ad una \\(t_{31}\\) nell’intervallo \\([1.896, +\\infty]\\) (test unidirezionale destro), ovvero\n\n# Calculate the upper tail probability for the t-distribution\np &lt;- 1 - pt(T, df = 31)\nprint(p)\n#&gt; [1] 0.03365\n\nDato che il valore-p è minore di \\(\\alpha = 0.05\\), Mehr et al. (2016) rifiutano \\(H_0\\) (cioè che la proporzione media del tempo di fissazione dei bambini nei confronti del video “familiare” sia 0.5, o minore) e concludono che i bambini mostrano una preferenza per il video familiare.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#potenza-del-test",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#potenza-del-test",
    "title": "\n89  Significatività statistica\n",
    "section": "\n89.15 Potenza del test",
    "text": "89.15 Potenza del test\nRitorniamo ora al concetto di potenza del test. Il livello di significatività e la potenza del test vengono usati per quantificare la qualità dell’inferenza statistica. Idealmente, la procedura di test di ipotesi non dovrebbe giungere alla conclusione sbagliata. Ovvero, non dovrebbe respingere \\(H_0\\) quando essa è vera e dovrebbe respingere \\(H_0\\) in favore dell’alternativa quando \\(H_1\\) è vera. Ma questi sono solo due dei quattro esiti che, in principio, sono possibili, e corrispondono alle probabilità indicate di seguito.\n\nPossiamo pensare a \\(H_0\\) come all’ipotesi che descrive l’evento “nulla di interessante sta succedendo” – ad esempio, “la moneta è bilanciata”, “il trattamento non è migliore del placebo”, ecc. – e pensare ad \\(H_1\\) come al caso contrario, ovvero: “sta accadendo qualcosa di interessante”. Quindi la potenza del test, ovvero la probabilità \\(1 - \\beta\\) di rigettare \\(H_0\\) quando essa è falsa, corrisponde alla probabilità di rilevare qualcosa di interessante, quando qualcosa di interessante è effettivamente successo, mentre il livello di significatività corrisponde alla probabilità di affermare che qualcosa di interessante si è verificato, quando in realtà non è successo nulla di interessante.\nIl calcolo della potenza di un test è spesso difficile, perché richiede la conoscenza della distribuzione campionaria di \\(\\mathcal{G}_n\\) quando è vera l’ipotesi alternativa \\(H_1\\). Tipicamente possiamo aumentare la potenza di un test aumentando la numerosità del campione in maniera tale da diminuire la varianza delle distribuzioni della statistica test condizionate a \\(H_0\\) e ad \\(H_1\\). In un disegno sperimentale è importante determinare in anticipo il numero di prove o dei soggetti necessari per raggiungere la potenza desiderata.\n\n89.15.1 Neyman e Fisher\nLa procedura di test di ipotesi statistiche descritta sopra combina due approcci teorici diversi, proposti da Sir Ronald Fisher e Jerzy Neyman. La storia di questi due approcci non è lineare, poiché Fisher e Neyman hanno modificato le loro opinioni nel tempo, senza mai fornire una “verità definitiva” su come interpretare il loro lavoro.\nIn sintesi, Fisher considerava che il ricercatore avesse un’unica ipotesi (quella nulla) e che lo scopo fosse verificare se i dati fossero coerenti o meno con essa. In questo senso, il valore-\\(p\\) rappresenta la probabilità di osservare, sotto l’ipotesi nulla, il risultato ottenuto o uno ancora più estremo. Se il valore-\\(p\\) è piccolo, Fisher rifiutava l’ipotesi nulla. Tuttavia, poiché non venivano formulate altre ipotesi, non c’era modo di “accettare l’alternativa”.\nAl contrario, Neyman adottava un approccio più formale rispetto a Fisher e pensava che lo scopo della verifica delle ipotesi fosse quello di prendere decisioni. Secondo Neyman, il problema era decidere se accettare l’ipotesi nulla o l’alternativa e il test serviva a stabilire quale supporto venisse fornito alle due alternative. Per questo motivo, era fondamentale specificare in modo preciso l’ipotesi alternativa. Nel suo approccio, il valore-\\(p\\) non misurava la probabilità del risultato del test o di uno più estremo sotto l’ipotesi nulla, ma forniva una descrizione astratta dei “possibili test” che portavano all’accettazione dell’ipotesi nulla o dell’alternativa.\nAttualmente ci troviamo in una situazione strana e ambigua, dove sono presenti elementi di entrambi gli approcci. La procedura di verifica di ipotesi statistiche distingue tra un’ipotesi nulla e un’ipotesi alternativa, seguendo la visione di Neyman, ma definisce il valore-\\(p\\) in termini di dati estremi, come avrebbe fatto Fisher, in confronto con un livello \\(\\alpha\\) stabilito da Neyman. Alcuni test statistici specificano in modo chiaro l’ipotesi alternativa, mentre altri sono più vaghi in merito, adottando l’approccio di Fisher. Inoltre, c’è disaccordo tra i ricercatori riguardo alla possibilità di “accettare l’alternativa”, a seconda che si segua Neyman o Fisher. Questa confusione costituisce il “peccato originale” della procedura di verifica di ipotesi statistiche. Tuttavia, ci sono motivi più specifici per cui questo approccio, noto come significatività statistica, viene criticato da molti ricercatori come una delle cause principali della crisi della replicabilità dei risultati della ricerca in psicologia e in altri campi. Nel capitolo ?sec-errors-s-m esploreremo queste ragioni in dettaglio.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#la-storia-del-test-dellipotesi-nulla-di-fisher-e-le-sue-contraddizioni",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#la-storia-del-test-dellipotesi-nulla-di-fisher-e-le-sue-contraddizioni",
    "title": "\n89  Significatività statistica\n",
    "section": "\n89.16 La Storia del Test dell’Ipotesi Nulla di Fisher e le Sue Contraddizioni",
    "text": "89.16 La Storia del Test dell’Ipotesi Nulla di Fisher e le Sue Contraddizioni\nConcludiamo l’analisi della procedura dei test di ipotesi statistici esaminando l’evento che ha ispirato Ronald A. Fisher a sviluppare la sua teoria dell’inferenza statistica, focalizzata sul test dell’ipotesi nulla. Questo episodio è descritto dettagliatamente da Etz et al. (2018). L’aneddoto riguarda un tè che Fisher aveva offerto alla sua collega, la Dott.ssa Muriel Bristol. Durante la preparazione della bevanda, la Dr.ssa Bristol contestò il metodo adottato da Fisher, asserendo che il tè avrebbe avuto un gusto migliore se il latte fosse stato versato prima dell’acqua bollente. Per verificare l’affermazione della Dr.ssa Bristol, Fisher ideò un esperimento di discriminazione sensoriale. Nei test condotti, la Dr.ssa Bristol fu in grado di individuare correttamente il processo di preparazione del tè in cinque occasioni su sei.\nQuesto risultato pose Fisher di fronte a un interrogativo: la sua collega stava semplicemente facendo una supposizione fortunata, oppure era effettivamente in grado di discernere tra le due diverse modalità di preparazione? Per risolvere questa questione, Fisher elaborò la sua metodologia per il test dell’ipotesi nulla. Utilizzò un valore-\\(p\\) calcolato sulla base della probabilità dell’evento osservato, nonché di qualsiasi altro evento più estremo che potrebbe verificarsi sotto l’ipotesi nulla.\nTuttavia, è stato fatto notare che l’approccio di Fisher al test dell’ipotesi nulla può essere insufficiente e portare a conclusioni errate (Etz et al., 2018). Una delle questioni fondamentali riguarda la definizione di un evento “più estremo” rispetto a quello osservato.\nSupponiamo che lo scopo dell’esperimento casuale sia di determinare l’accuratezza delle riposte della Dr.ssa Bristol in esattamente sei tentativi (e non di più). In tale caso, con 5 risposte corrette, il valore-\\(p\\) è pari a 0.109, che non è statisticamente significativo. In questo scenario, secondo la logica di Fisher, non si dovrebbe respingere l’ipotesi nulla che la Dr. Bristol stesse semplicemente indovinando.\nSupponiamo ora che lo scopo dell’esperimento casuale sia di continuare a servire tè fino a quando la Dr.ssa Bristol non abbia raggiunto cinque risposte corrette (un risultato che, per coincidenza, si è verificato dopo sei tentativi). Se analizziamo i dati in questo secondo scenario, il valore-\\(p\\) diventa pari a 0.031, che è statisticamente significativo. In quest’ultimo caso, l’ipotesi nulla verrebbe respinta.\nQuello che emerge è che, nonostante i dati osservati nei due scenari siano identici, giungiamo a conclusioni opposte come conseguenza delle diverse modalità di campionamento impiegate. Questa variabilità è problematica poiché il valore-\\(p\\), e quindi la nostra valutazione delle capacità discriminative della Dr.ssa Bristol, dipendono non solo dai dati effettivamente raccolti, ma anche dal disegno sperimentale adottato. Questa constatazione mette in discussione la robustezza del test dell’ipotesi nulla come strumento fondamentale per l’inferenza scientifica.\nPer illustrare il problema, svolgiamo i calcoli utilizzando le distribuzioni statistiche richieste per i due tipi di campionamento: la distribuzione binomiale e la distribuzione geometrica negativa.\n\n89.16.1 Distribuzione Binomiale\nLa distribuzione binomiale è la distribuzione da utilizzare quando il numero di tentativi è prefissato e conosciuto a priori. Nel contesto dell’esempio del tè, assumiamo che siano state servite esattamente sei tazze. La formula per determinare la probabilità di registrare esattamente \\(k\\) successi in \\(n\\) tentativi è la seguente:\n\\[\nP(X = k) = \\binom{n}{k} \\times p^k \\times (1-p)^{(n-k)}\n\\]\nQui, \\(\\binom{n}{k}\\) rappresenta il coefficiente binomiale, \\(p\\) è la probabilità di un singolo successo (ossia di indovinare correttamente la preparazione del tè), e \\((1-p)\\) è la probabilità di un singolo fallimento.\nPer calcolare il valore-\\(p\\) in questo specifico contesto, dobbiamo sommare le probabilità di ottenere un risultato di 5 o più estremo su un totale di 6 tentativi.\n\n# Parameters\nn_binomial &lt;- 6  # Number of fixed trials for the binomial distribution\nn_success &lt;- 5  # Desired number of successes\np &lt;- 0.5  # Probability of success\n\n# Calculate the p-value for the binomial distribution\np_value_binomial &lt;- 1 - pbinom(n_success - 1, size = n_binomial, prob = p)\n\np_value_binomial\n#&gt; [1] 0.1094\n\n\n89.16.2 Distribuzione Geometrica Negativa\nNel contesto dell’esperimento del tè, quando il test continua fino al raggiungimento di un numero prefissato di successi (nel nostro caso, cinque identificazioni corrette), la distribuzione di riferimento appropriata è la distribuzione geometrica negativa.\nLa distribuzione geometrica negativa modella il numero di fallimenti \\(k\\) che si verificano prima di ottenere un numero prefissato \\(r\\) di successi in una sequenza di prove indipendenti di Bernoulli, dove ogni prova ha probabilità di successo \\(p\\).\nLa probabilità di osservare esattamente \\(k\\) fallimenti prima di ottenere \\(r\\) successi è data da:\n\\[\nP(X = k) = \\binom{k+r-1}{k} p^r (1-p)^k,\n\\]\ndove:\n\n\n\\(k\\) è il numero di fallimenti,\n\n\\(r\\) è il numero di successi desiderato,\n\n\\(p\\) è la probabilità di successo in ogni prova,\n\n\\(\\binom{k+r-1}{k}\\) è il coefficiente binomiale che rappresenta il numero di modi possibili in cui \\(k\\) fallimenti e \\(r\\) successi possono essere ordinati.\n\nNel nostro caso specifico:\n\n\n\\(r = 5\\) (successi desiderati),\n\n\\(p = 0.5\\) (probabilità di indovinare correttamente sotto l’ipotesi nulla),\n\n\\(k\\) varia da 0 a 1 (possibili fallimenti prima del quinto successo).\n\nIl valore-p si calcola sommando le probabilità per tutti i casi “più estremi” di quello osservato:\n\\[\n\\text{valore-p} = \\sum_{k=0}^{1} \\binom{k+5-1}{k} (0.5)^5 (0.5)^k.\n\\]\nImplementazione:\n\n# Parameters\nn_binomial &lt;- 6  # Number of fixed trials for the binomial distribution\nn_success &lt;- 5  # Desired number of successes\np &lt;- 0.5  # Probability of success (guessing the tea cup)\n\n# Calculate the p-value for the negative binomial distribution\np_value_geom_corrected &lt;- 0\nfor (k in 0:(n_binomial - n_success - 1)) {  # Number of failures before the 5th success\n  p_value_geom_corrected &lt;- p_value_geom_corrected + \n    choose(k + n_success - 1, k) * ((1 - p)^k) * (p^n_success)\n}\n\np_value_geom_corrected\n#&gt; [1] 0.03125\n\nIn conclusione,\n\nper la distribuzione binomiale, il p-value è \\(0.109\\), che non è statisticamente significativo (dato che è maggiore di 0.05); quindi, secondo Fisher, in questo caso non dovremmo rigettare l’ipotesi nulla che Dr. Bristol stia indovinando.\nper la distribuzione geometrica negativa, il p-value è \\(0.031\\), che è statisticamente significativo (dato che è minore di 0.05); in questo caso, dovremmo rigettare l’ipotesi nulla, suggerendo che Dr. Bristol non sta semplicemente indovinando.\n\nLa presente discussione mostra che, in base alla procedura del test dell’ipotesi nulla, la stessa sequenza di eventi (5 successi su 6 tentativi) può portare a conclusioni opposte a seconda delle ipotesi sul processo di campionamento. Questo paradosso è uno dei motivi (per ulteriori critiche, si veda Wasserstein & Lazar (2016); Benjamin et al. (2018)) per cui l’inferenza bayesiana è diventata più popolare negli ultimi anni come quadro alternativo per il test delle ipotesi e la stima dei parametri.\n\n89.16.3 Approccio Bayesiano\nNel loro lavoro, Etz et al. (2018) propongono un’alternativa bayesiana per risolvere il problema esaminato da Fisher. Questa soluzione bayesiana evita le contraddizioni che emergono quando si cercano di definire “risultati più estremi” che non sono stati osservati. L’approccio bayesiano si focalizza esclusivamente sui dati effettivamente raccolti e utilizza queste osservazioni per aggiornare le probabilità iniziali (o “a priori”) associate a diverse ipotesi. Il processo si basa sulla regola di Bayes e si sviluppa in tre fasi principali:\n\nStabilire Probabilità a Priori: Iniziamo assegnando una distribuzione di probabilità a priori a tutti i possibili tassi di successo che la Dr. Bristol potrebbe avere. Questo include una probabilità specifica per l’ipotesi nulla, che suggerisce che la Dr. Bristol stia semplicemente indovinando (con un tasso di successo del 50%).\nAggiornare le Probabilità con Dati Osservati: Utilizziamo i dati raccolti nell’esperimento per aggiornare le nostre probabilità a priori. Questo aggiornamento è fatto utilizzando la regola di Bayes.\nCalcolare il Fattore di Bayes: Questa metrica ci dice quanto i dati osservati influenzano le probabilità delle diverse ipotesi. Un Fattore di Bayes molto maggiore di 1 indicherebbe un forte supporto per l’ipotesi alternativa rispetto all’ipotesi nulla.\n\nNel caso specifico, il Fattore di Bayes calcolato è risultato essere circa 147.33, un valore notevolmente alto. Questo suggerisce che i dati osservati sono molto più compatibili con l’ipotesi che la Dr.ssa Bristol possa effettivamente distinguere tra le diverse preparazioni del tè, piuttosto che con l’ipotesi che stia indovinando.\nEtz et al. (2018) concludono che l’approccio bayesiano offre un quadro più robusto e coerente per il test delle ipotesi. A differenza del metodo frequentista, esso non dipende dalla definizione di “risultati più estremi” non osservati e si concentra invece esclusivamente sui dati effettivamente raccolti. Questa focalizzazione, in generale, rende l’approccio bayesiano una soluzione più solida per valutare le ipotesi scientifiche. Per una rivisitazione bayesiana dell’esperimento “The Lady Tasting Tea”, si veda anche la discussione di Doorn et al. (2020).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#malintesi-sul-valore-p",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#malintesi-sul-valore-p",
    "title": "\n89  Significatività statistica\n",
    "section": "\n89.17 Malintesi sul valore-p",
    "text": "89.17 Malintesi sul valore-p\nSono diffusi molti malintesi sul valore-p. Ne esaminiamo qui quelli più comuni.\nMalinteso 1: Un valore p non significativo significa che l’ipotesi nulla è vera.\nIl malinteso che un valore p non significativo (p &gt; 0.05) implichi l’assenza di effetto o la verità dell’ipotesi nulla è diffuso e porta a conclusioni errate. La chiave per evitare questo errore sta nel comprendere che i valori p riflettono la probabilità dei dati osservati sotto l’ipotesi nulla, e non la probabilità dell’ipotesi stessa. Un valore p elevato non dimostra che l’ipotesi nulla sia vera, ma indica semplicemente che i dati osservati non sono sufficientemente insoliti da rifiutare l’ipotesi nulla con un livello di confidenza predefinito.\nRisultati non significativi possono verificarsi anche quando esiste un effetto reale, ma i dati non sono abbastanza estremi da superare la soglia di significatività statistica.\nInvece di concludere affrettatamente l’assenza di effetto da un valore p non significativo, dovremmo riconoscere l’ambiguità e considerare altre possibilità. Dichiarazioni come “non c’era differenza” dovrebbero essere riformulate in termini di assenza di differenza statisticamente significativa, lasciando aperta la questione dell’esistenza di un effetto reale.\nL’approccio bayesiano offre una prospettiva diversa che può essere particolarmente utile per interpretare risultati non significativi. A differenza dei valori p, che si limitano a valutare la probabilità dei dati sotto l’ipotesi nulla, l’inferenza bayesiana permette di calcolare direttamente la probabilità delle ipotesi date i dati.\nL’approccio bayesiano, quindi, non si limita a rifiutare o non rifiutare l’ipotesi nulla, ma quantifica la forza dell’evidenza a favore di un’ipotesi rispetto all’altra, fornendo una conclusione più informativa rispetto al semplice “non posso rifiutare l’ipotesi nulla”.\nMalintesto 2: Un valore p significativo significa che l’ipotesi nulla è falsa.\nCome spiegato in precedenza, il valore-p quantifica la “sorpresa” suscitata dai dati, alla luce dell’ipotesi nulla. Non ci dice niente sull’ipotesi che abbiamo assunto per quantificare la “sorpresa”.\nMalinteso 3: Un valore p significativo significa che è stato scoperto un effetto importante.\nLa distinzione tra “significatività statistica” e “rilevanza pratica” è fondamentale: mentre la prima indica semplicemente che un risultato è improbabile sotto l’ipotesi nulla, la seconda valuta l’effetto nel contesto di applicazioni reali e le sue implicazioni.\nUn effetto statisticamente significativo non garantisce che l’effetto abbia un impatto pratico notevole o utile.\nInoltre, al di là della significatività pratica, l’abitudine di molti psicologi di escludere i predittori che non risultano “statisticamente significativi” è un grossolano errore: la significatività statistica non può essere usata come un metodo per la selezione di variabili in un modello statistico.\nUn p &lt; 0.05 indica che, se l’ipotesi nulla è vera, abbiamo osservato dati che dovrebbero essere considerati sorprendenti. Tuttavia, solo perché i dati sono sorprendenti, non significa che dobbiamo preoccuparcene. È principalmente l’etichetta verbale “significativo” che causa confusione qui: in un contesto frequentista, un effetto “significativo” è un effetto “sorprendente” alla luce di \\(H_0\\), non è necessariamente un effetto “importante”.\nMalinteso 4: Se avete osservato un risultato significativo, la probabilità che abbiate commesso un errore di Tipo 1 (un falso positivo) è del 5%.\nIl malinteso che la presenza di un risultato significativo (per esempio, p &lt; 0.05) indichi una probabilità del 5% di aver commesso un errore di Tipo 1 (falso positivo) riflette una comprensione errata della statistica frequentista. La probabilità del 5% si riferisce al tasso di errore di Tipo 1, che è la proporzione di volte che potremmo aspettarci di rifiutare erroneamente l’ipotesi nulla se questa fosse vera, su molteplici ripetizioni dell’esperimento sotto le stesse condizioni. In altre parole, se potessimo ripetere lo stesso studio infinite volte, osserveremmo risultati falsamente positivi nel 5% di questi studi, assumendo che l’ipotesi nulla sia effettivamente vera in ogni caso.\nTuttavia, una volta che abbiamo raccolto i dati e ottenuto un risultato significativo in un unico studio, non possiamo dire che “la probabilità che questo particolare risultato sia un errore di Tipo 1 è del 5%”. In realtà, in quel momento specifico, l’evento (commettere un errore di Tipo 1) è già accaduto o non è accaduto; la probabilità associata a quel singolo risultato non è più applicabile nel modo in cui potremmo aspettarci intuitivamente. Il risultato è, per così dire, una realtà fissa: o abbiamo rilevato un effetto che in realtà non esiste (errore di Tipo 1), oppure abbiamo correttamente identificato un effetto reale. Senza ulteriori esperimenti o dati, non possiamo determinare con certezza in quale di queste categorie cade il nostro risultato.\nIn breve, il tasso del 5% di errore di Tipo 1 non si applica retroattivamente a un singolo risultato ottenuto, ma piuttosto descrive il comportamento a lungo termine di un test statistico sotto ripetute campionature. Questa distinzione è cruciale per una corretta interpretazione dei risultati degli esperimenti e sottolinea l’importanza di non sovrastimare la certezza di un singolo risultato statistico significativo.\nMalinteso 5: Uno meno il valore p è la probabilità che l’effetto si replichi quando ripetuto.\nIl concetto che 1 meno il valore p rappresenti la probabilità di replicazione di un effetto è un malinteso diffuso. In realtà, la probabilità di replicazione di un effetto non può essere direttamente calcolata dal valore p di un singolo studio a causa della complessità dei fattori coinvolti, tra cui la vera differenza media tra i gruppi. La potenza statistica di un test, che dipende dalla dimensione dell’effetto, dalla dimensione del campione e dal livello di significatività α, fornisce una stima della probabilità di rilevare un effetto significativo se questo effetto esiste davvero. Tuttavia, osservare un effetto significativo in un unico studio (ad esempio, p = 0.03) non significa che vi sia una probabilità del 97% che tale effetto si replichi in studi futuri. La possibilità di replicare un risultato dipende dalla presenza di un vero effetto e dalla potenza statistica del test originale.\nIn sintesi, la replicabilità di un effetto è influenzata da molti fattori e non può essere inferita semplicemente dal valore p di un singolo risultato. La comprensione e l’interpretazione corrette della replicabilità richiedono un’analisi dettagliata della potenza statistica e della dimensione dell’effetto, oltre che della consistenza dei risultati attraverso studi multipli.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#riflessioni-conclusive",
    "title": "\n89  Significatività statistica\n",
    "section": "\n89.18 Riflessioni Conclusive",
    "text": "89.18 Riflessioni Conclusive\nIl presente capitolo ha messo in evidenza le numerose limitazioni e i potenziali pericoli dell’approccio frequentista al test dell’ipotesi nulla, portando alla luce una serie di paradossi e malintesi che minano la sua validità come strumento primario per l’inferenza scientifica. In particolare, abbiamo visto come il valore-p, spesso utilizzato come metro di giudizio assoluto per decidere se un risultato è significativo o meno, possa condurre a conclusioni fuorvianti, dipendendo non solo dai dati osservati ma anche dal contesto sperimentale e dalle scelte soggettive del ricercatore. Questo approccio, che si basa su una logica binaria di “accettare” o “rifiutare” l’ipotesi nulla, sembra incapace di cogliere la complessità delle relazioni causali e degli effetti reali presenti nei fenomeni psicologici e sociali. Più profondamente, emerge con chiarezza che il metodo frequentista, lungi dall’essere un sistema oggettivo per la decisione statistica, è invece intriso di convenzioni arbitrarie (come il livello di significatività α = 0.05) e di una visione riduzionistica della probabilità, concepita come frequenza relativa di eventi ripetibili nel tempo piuttosto che come misura della nostra incertezza riguardo a un evento specifico.\nTuttavia, al di là delle critiche tecniche, il problema più grave risiede nella tendenza a considerare il test dell’ipotesi nulla come uno strumento definitivo per valutare la veridicità di ipotesi scientifiche, anziché come un semplice punto di partenza per ulteriori indagini. La cultura prevalente nella comunità scientifica, che premia i risultati “statisticamente significativi”, ha contribuito a creare un ambiente in cui gli studi replicabili sono rari e dove molti risultati pubblicati sono fragili e difficilmente generalizzabili. È qui che l’approccio bayesiano entra in gioco, offrendo una soluzione coerente e robusta che supera molte delle carenze del frequentismo. Al contrario del metodo frequentista, che si concentra su ipotesi nulle arbitrariamente definite e sulle distribuzioni campionarie di statistiche teoriche, il bayesianesimo ci permette di incorporare informazioni pregresse (prior) e di aggiornare queste conoscenze in base ai dati osservati, fornendo una stima diretta della probabilità delle ipotesi di interesse. Questo approccio, che mette al centro la nozione di evidenza, permette di quantificare la forza delle prove a favore di diverse ipotesi, evitando così le dicotomie rigide tra “significativo” e “non significativo” e promuovendo una visione più sfumata e matematicamente fondata dell’inferenza statistica.\nIn conclusione, il test dell’ipotesi nulla frequentista, pur essendo ampiamente utilizzato, rappresenta uno degli aspetti più controversi e problematici dell’approccio tradizionale. La sua rigidità metodologica e la dipendenza da concetti come il valore p e la significatività statistica lo rendono non solo impreciso, ma anche inadeguato a cogliere la complessità dei fenomeni che la ricerca psicologica si propone di esplorare. Abbandonare questo paradigma non è solo una questione di precisione tecnica, ma di superare una mentalità riduzionista che limita la nostra capacità di interpretare i dati in modo sfumato e contestuale.\nL’adozione di metodologie bayesiane, al contrario, offre un quadro più dinamico e flessibile, in cui le ipotesi non sono semplicemente accettate o rifiutate, ma valutate in termini probabilistici. Questo approccio incoraggia un confronto diretto tra modelli e ipotesi contrapposte, permettendo di aggiornare le nostre credenze alla luce dei nuovi dati. Non si tratta solo di un miglioramento tecnico nelle inferenze scientifiche, ma di un invito a ripensare il modo in cui concepiamo la conoscenza e il processo di scoperta. La prospettiva bayesiana, infatti, enfatizza l’incertezza come parte intrinseca della ricerca, trasformandola in uno strumento per affinare le nostre comprensioni piuttosto che un ostacolo da superare.\nIn un contesto psicologico intrinsecamente complesso e caratterizzato da incertezza, l’approccio bayesiano rappresenta un’opportunità per adottare un’epistemologia più flessibile e razionale. La sua forza risiede nella capacità di adattarsi alla natura multifattoriale dei fenomeni psicologici, integrando in modo coerente e trasparente sia le conoscenze pregresse sia le nuove evidenze. In questo senso, l’adozione del paradigma bayesiano non è soltanto un avanzamento metodologico, ma anche un passo verso una scienza più consapevole, critica e adatta alle sfide della psicologia contemporanea.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#esercizi",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#esercizi",
    "title": "\n89  Significatività statistica\n",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\n\nL’Idea di Base del Test di Ipotesi\n\nSpiega il principio generale del test di ipotesi nulla in ambito frequentista. In che modo la logica dell’“assumere come vera l’ipotesi nulla fino a prova contraria” è paragonabile al concetto di “presunzione di innocenza” in un processo penale? Quali vantaggi e svantaggi comporta questa impostazione?\n\nIpotesi di Ricerca vs. Ipotesi Statistica\n\nSpiega in che modo l’ipotesi di ricerca (ad esempio, “esiste un effetto della musica sul comportamento dei bambini”) differisce dall’ipotesi statistica che si testa formalmente (ad esempio, “la media di un indice di preferenza è maggiore di 0.5”). Perché spesso la ricerca psicologica non può testare direttamente l’ipotesi di ricerca?\n\nSignificatività Statistica e Rilevanza Pratica\n\nChe differenza c’è tra “risultato statisticamente significativo” e “risultato rilevante (o importante) dal punto di vista pratico o teorico”? Porta un esempio in cui un test frequenzista possa dare un valore-\\(p\\) molto basso senza che l’effetto sia considerato rilevante nel contesto.\n\nMalinteso: Un Risultato non Significativo Implica Che \\(H_0\\) Sia Vera?\n\nPerché è errato concludere che l’ipotesi nulla sia vera quando il test non risulta significativo (cioè quando \\(p \\ge 0.05\\))? Quali altre spiegazioni potrebbero esserci se un esperimento produce un valore-\\(p\\) alto?\n\nIl Ruolo della Variabilità Campionaria\n\nIn che modo la variabilità campionaria (cioè il fatto che stime come la media campionaria varino da campione a campione) influisce sulla necessità di un test di ipotesi? Perché non è sufficiente confrontare la media osservata con il valore ipotizzato per concludere se \\(H_0\\) è falsa?\n\nErrori di I e II Tipo e Potenza del Test\n\nDescrivi i concetti di errore di I tipo (falso positivo) e errore di II tipo (falso negativo). Perché i test sono progettati primariamente per controllare l’errore di I tipo? Che cos’è la potenza (\\(1-\\beta\\)) di un test?\n\nIl Valore-\\(p\\): Che Cosa (non) Indica?\n\nSpiega la definizione di valore-\\(p\\) secondo l’approccio frequentista. Quali sono due malintesi comuni su ciò che il valore-\\(p\\) non rappresenta?\n\nCritica: Dipendenza dai “Risultati più Estremi Non Osservati”\n\nNell’esempio dell’episodio “The Lady Tasting Tea”, come mai il test di ipotesi frequentista può portare a conclusioni diverse pur avendo gli stessi dati osservati, a seconda di come è definito il “processo di campionamento”? Perché questa è una limitazione?\n\nControllo dell’Errore di I Tipo, ma Non dell’Errore di II Tipo\n\nPerché nel test di ipotesi frequentista esiste un’asimmetria per cui si controlla rigorosamente l’errore di I tipo (fissando \\(\\alpha\\)), ma non esiste un analogo vincolo obbligatorio sull’errore di II tipo (\\(\\beta\\))? Quali conseguenze pratiche ne derivano per la pianificazione di uno studio?\n\nLimiti dell’Approccio Frequentista e Alternative\n\nRiassumi in che senso il test di ipotesi nulla frequentista è ritenuto da alcuni ricercatori insufficiente o fuorviante (es. “dichotomania” del significato, p-value dipendente dal disegno, ecc.). Quali alternative o integrazioni sono state proposte in letteratura per superare questi limiti?\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\n\nL’Idea di Base del Test di Ipotesi\n\n\nL’ipotesi nulla (\\(H_0\\)) è considerata “innocente” fino a che l’evidenza non la “condanna”.\n\nIl test statistico stabilisce la probabilità di osservare dati così (o più) estremi assumendo che \\(H_0\\) sia vera.\n\nVantaggio: stabilire un controllo sul rischio di un falso positivo (errore di I tipo).\n\nSvantaggio: non si dimostra direttamente l’ipotesi di ricerca (\\(H_1\\)), ma si prova a “falsificare” \\(H_0\\).\n\n\nIpotesi di Ricerca vs. Ipotesi Statistica\n\n\nL’ipotesi statistica è una versione quantificabile (e falsificabile) dell’ipotesi di ricerca.\n\nLe ipotesi di ricerca in psicologia sono spesso complesse (costrutti non sempre direttamente misurabili).\n\nI ricercatori formulano un modello statistico semplificato per rendere l’ipotesi testabile.\n\n\nSignificatività Statistica e Rilevanza Pratica\n\n\n“Significativo” in senso frequentista significa “dati improbabili se \\(H_0\\) è vera”.\n\nNon implica necessariamente un effetto ampio o di importanza pratica.\n\nCon campioni molto grandi, si possono rilevare anche differenze piccolissime, magari prive di valore applicativo.\n\n\nMalinteso: Un Risultato non Significativo Implica Che \\(H_0\\) Sia Vera?\n\n\nUn valore-\\(p\\) “alto” segnala che i dati non forniscono sufficiente evidenza per rifiutare \\(H_0\\), non che \\(H_0\\) è vera.\n\nPossibile mancanza di potenza statistica (campione troppo piccolo) o presenza di effetti molto ridotti.\n\nL’approccio frequentista non quantifica la probabilità che \\(H_0\\) sia vera, ma la probabilità di osservare certi dati assumendo che \\(H_0\\) lo sia.\n\n\nIl Ruolo della Variabilità Campionaria\n\n\nAnche se la media campionaria si discosta da \\(H_0\\), potremmo aver ottenuto quella differenza per puro caso.\n\nOccorre stabilire quanto discostamento sia “raro” secondo la distribuzione campionaria ipotizzata da \\(H_0\\).\n\nIl test calcola quante volte, nel lungo periodo, si osservano dati così estremi casualmente.\n\n\nErrori di I e II Tipo e Potenza del Test\n\n\nErrore di I tipo: rigettare \\(H_0\\) quando è vera.\n\nErrore di II tipo: non rigettare \\(H_0\\) quando è falsa.\n\nIl test frequenzista fissa una soglia \\(\\alpha\\) (livello di significatività) per controllare l’errore di I tipo.\n\nLa potenza quantifica la probabilità di individuare realmente un effetto quando esso esiste.\n\n\nIl Valore-\\(p\\): Che Cosa (non) Indica?\n\n\nIl valore-\\(p\\) è la probabilità di ottenere un risultato almeno così estremo se \\(H_0\\) è vera.\n\nMalinteso 1: pensare che indichi la probabilità che \\(H_0\\) sia vera o falsa.\n\nMalinteso 2: confondere “\\(p &lt; 0.05\\) =&gt; probabilità 95% che l’effetto sia vero” (non è così!).\n\n\nCritica: Dipendenza dai “Risultati più Estremi Non Osservati”\n\n\nIl valore-\\(p\\) frequenzista include la probabilità di osservare anche “risultati più estremi” non avvenuti nell’esperimento.\n\nSe l’esperimento era “fissare a priori 6 tazze” vs. “continuare finché non ottiene 5 successi”, può cambiare la distribuzione usata (binomiale vs. geometrica negativa).\n\nQuesto mostra che il valore-\\(p\\) dipende dal contesto sperimentale, non solo dai dati effettivi.\n\n\nControllo dell’Errore di I Tipo, ma Non dell’Errore di II Tipo\n\n\nSi vuole evitare di “condannare” un’ipotesi nulla “innocente”.\n\nL’errore di II tipo spesso viene trascurato e può essere molto alto se il campione è piccolo.\n\nConseguenze: molti studi hanno potenza insufficiente; i “falsi negativi” rimangono frequenti.\n\n\nLimiti dell’Approccio Frequentista e Alternative\n\n\nCritiche: inflazione di falsi positivi, dipendenza arbitraria da \\(\\alpha=0.05\\), scarsa attenzione alla dimensione dell’effetto, interpretazioni errate del p-value.\n\nAlternative:\n\n\nApproccio bayesiano (fattori di Bayes, posteriori, credibilità).\n\n\nConfidence intervals ampliati da riflessioni su potenza e dimensione dell’effetto.\n\n\nMisure dell’effetto e analisi approfondite invece di un giudizio binario su “p&lt;0.05”.\n\n\n\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nEsercizi “A Mano”\nQuesti esercizi si possono affrontare con le formule del test di ipotesi (z-test o t-test per la media, test di proporzioni, ecc.), senza ricorrere a software.\nEsercizio 1: One-sample t-test sulla SWLS\n\n\nHai un piccolo campione di \\(n=9\\) studenti, con punteggi SWLS (ipotetici) riportati di seguito:\n\\[\n21, \\ 18, \\ 26, \\ 20, \\ 23, \\ 16, \\ 22, \\ 19, \\ 25\n\\]\n\nSupponi che, in letteratura, la media teorica su popolazioni simili sia di circa \\(\\mu_0 = 20\\).\nIpotesi nulla \\((H_0)\\): la media del campione non differisce da 20 (cioè \\(\\mu = 20\\)).Ipotesi alternativa \\((H_1)\\): la media del campione differisce da 20 (two-sided test).\n\nRichiesta:\n\nCalcola la media campionaria \\(\\bar{X}\\) e la deviazione standard campionaria \\(s\\).\n\nEsegui un t-test a mano (con formula \\(t = \\frac{\\bar{X} - \\mu_0}{s/\\sqrt{n}}\\)).\n\nStabilisci se, con \\(\\alpha=0.05\\) (test a due code), si rifiuta o meno \\(H_0\\).\n\n\nSuggerimento: Usa la tabella della distribuzione t (o ricorri a tavole semplificate) per trovare il valore critico a \\(df = n-1 = 8\\). Solo per questo step, usa R.\n\nEsercizio 22: One-sample t-test sulla LSNS-6\n\n\nHai un campione di \\(n=8\\) persone anziane, con punteggi LSNS-6 (Scala della Rete Sociale di Lubben) ipotetici (in realtà userai i dati raccolti):\n\\[\n10,\\ 14,\\ 8,\\ 13,\\ 12,\\ 7,\\ 15,\\ 9\n\\]\n\nIn letteratura si suppone che un punteggio medio su popolazioni simili sia \\(\\mu_0 = 12\\).\nIpotesi nulla: \\(\\mu = 12\\).Ipotesi alternativa: \\(\\mu \\neq 12\\).\n\nRichiesta:\n\nCalcola media e deviazione standard.\n\nCalcola la statistica \\(t\\) e confrontala con il valore critico per \\(\\alpha=0.05\\), two-sided, con \\(df = 7\\).\n\nConcludi se rifiuti l’ipotesi nulla o meno.\n\n\n\nEsercizio 3: Due campioni indipendenti (SWLS)\n\n\nConsidera i dati raccolti dal tuo gruppo e quelli di un altro gruppo TPV (es., Gruppo A = 6 persone, Gruppo B = 5 persone) che hanno compilato la SWLS. Riporta per ipotesi i seguenti punteggi medi e DS (usa i dati reali):\n\nGruppo A: \\(\\bar{X}_A = 24,\\ s_A=4,\\ n_A=6\\)\n\nGruppo B: \\(\\bar{X}_B = 19,\\ s_B=3,\\ n_B=5\\)\n\n\n\nVuoi testare se le due medie differiscono in modo significativo (\\(\\alpha=0.05\\), due code).\nIpotesi nulla: \\(\\mu_A = \\mu_B\\).Ipotesi alternativa: \\(\\mu_A \\neq \\mu_B\\).\n\nRichiesta:\n\nCalcola la statistica \\(t\\) di un two-sample t-test (varianze incognite, assunte uguali).\n\nUsa la formula con la “varianza pooled”.\n\nCalcola i \\(df\\) approssimati come \\(n_A + n_B - 2\\).\n\nConcludi se rifiuti \\(H_0\\).\n\n\n\nEsercizio 4: Test su una proporzione (SWLS recodificata)\n\nA volte si trasforma la SWLS in una variabile binaria es. “\\(\\mathrm{SWLS} \\ge 24\\) = soddisfatto, \\(\\mathrm{SWLS}&lt;24\\) = non soddisfatto”.\nConsidera i dati raccolti e i corrispondenti risultati binari (Sì/No) siano 4 “soddisfatti” e 6 “non soddisfatti”.\nIpotesi nulla: la proporzione di “soddisfatti” è \\(p_0 = 0.50\\) (ipotizzi che metà dei partecipanti sia soddisfatta).Ipotesi alternativa: la proporzione \\(\\neq 0.50\\).\nCalcola la statistica \\(Z\\) per una proporzione (usando la formula della normal approx. se \\(\\hat{p}=4/10\\)).\nConfronta \\(|Z|\\) con il valore critico a \\(\\alpha=0.05\\) (due code), \\(z_{0.025}\\approx 1.96\\). Concludi.\n\nEsercizio 5: Confronto fra due proporzioni (LSNS-6 recodificata)\n\nConsiderai dati di due gruppi TPV (Gruppo A, Gruppo B).\n\nSupponi che, per Gruppo A (\\(n_A=8\\)), 3 persone abbiano un punteggio \\(\\ge 12\\) (considerato “buon supporto”). Per Gruppo B (\\(n_B=10\\)), 7 persone siano \\(\\ge 12\\) – usa i dati reali.\n\nIpotesi nulla: \\(\\,p_A = p_B\\).Ipotesi alternativa: \\(\\,p_A \\neq p_B\\).\n\nCalcola \\(\\hat{p}_A = 3/8\\) e \\(\\hat{p}_B = 7/10\\).\n\nFai il test per il confronto di due proporzioni (con la formula per la “pooled proportion”). Decidi se c’è differenza significativa al 5%.\n\nEsercizi “Con R”\nOra proponiamo 5 esercizi da svolgere con il software R. Naturalmente, dovrete caricare il vostro dataset reale (ad esempio in formato CSV o XLS) e adattare i comandi di R.\nEsercizio 1: Calcolo e t-test di una sola media per la SWLS\n\n\nCaricate in R i vostri dati SWLS in un vettore, es.:\nswls_data &lt;- c(...)  # I vostri punteggi\n\n\nStampate la media e la deviazione standard:\nmean(swls_data)\nsd(swls_data)\n\nTest se la media differisce da 24, usando t.test(swls_data, mu = 24).\nOsservate il p-value e concludete se rifiutate \\(H_0\\): \\(\\mu=24\\) vs \\(H_1\\): \\(\\mu \\neq 24\\).\n\nEsercizio 2: Calcolo e t-test di una sola media per la LSNS-6\n\n\nFate lo stesso per la LSNS:\nlsns_data &lt;- c(...)  # I vostri punteggi\n\nCalcolate mean(lsns_data), sd(lsns_data).\nEseguite un test con t.test(lsns_data, mu = X) dove \\(X\\) è un valore teorico (ad es. 12 o 10, a seconda delle informazioni di letteratura).\nInterpretate l’output, guardando estimate, conf.int, p-value.\n\nEsercizio 3: Confronto di due medie (SWLS) con due gruppi\n\n\nConsiderate i dati di due gruppi TPV. Avete due vettori in R:\ngroupA &lt;- c(...)  # SWLS di chi appartiene al gruppo A\ngroupB &lt;- c(...)  # SWLS di chi appartiene al gruppo B\n\nCalcolate mean(groupA), mean(groupB).\n\nEseguite:\nt.test(groupA, groupB, var.equal = FALSE)  # Welch Two Sample t-test\n\nConfrontate la differenza delle medie riportata con l’intervallo di confidenza. Il p-value indica se la differenza è significativa (ipotesi nulla: medie uguali).\n\nEsercizio 4: Test su una proporzione (ricodifica SWLS)\n\n\nRicodificate i vostri punteggi SWLS in “1 = soddisfatto” / “0 = non soddisfatto”. Ad esempio:\nsatisfied &lt;- ifelse(swls_data &gt;= 24, 1, 0)\n\n\nContate la proporzione di “1”:\nmean(satisfied)\n\nEffettuate il test con prop.test(sum(satisfied), length(satisfied), p = 0.5) (se ipotizzate \\(p_0=0.5\\)).\nGuardate l’output e interpretate: l’intervallo di confidenza e il p-value.\n\nEsercizio 5: Confronto di due proporzioni (ricodifica LSNS)\n\n\nFate una ricodifica binaria sul vostro vettore LSNS, ad esempio “1 se \\(\\ge12\\), 0 se &lt;12”:\ngood_support &lt;- ifelse(lsns_data &gt;= 12, 1, 0)\n\n\nSeparate i partecipanti in due gruppi (ad esempio, un gruppo “A” e un gruppo “B”):\ngroupA_inds &lt;- (some condition)  # righe che corrispondono a Gruppo A\ngroupB_inds &lt;- (some other condition)\n\nCalcolate sum(good_support[groupA_inds]), length(groupA_inds) e idem per groupB.\nUsate prop.test(x = c(...), n = c(...)) per confrontare le due proporzioni.\nConcludete: se p-value &lt; 0.05, potete rifiutare \\(H_0\\) (le due proporzioni sono uguali).\n\n\n\n\n\n\n\n\n\n\nProblemi 3\n\n\n\n\n\nEsercizio 1 – P-value e Interpretazione Probabilistica\nSpiega perché il valore-\\(p\\) del test di ipotesi nulla (frequentista) non può essere interpretato come “probabilità che l’ipotesi nulla sia vera” e in che modo l’approccio bayesiano fornisce invece una “probabilità a posteriori” sull’ipotesi. Descrivi due possibili conseguenze pratiche di questa differenza di interpretazione.\nEsercizio 2 – Ruolo dei “Risultati più Estremi Non Osservati”\nNel test frequentista, il valore-\\(p\\) si basa anche sulla probabilità di risultati più estremi di quelli effettivamente osservati, ma che non si sono verificati. Perché questo è considerato un limite (o un paradosso) e in che modo un’analisi bayesiana eviterebbe (o ridurrebbe) questo problema?\nEsercizio 3 – Dipendenza dal Disegno Sperimentale e Optional Stopping\nNel test di ipotesi frequenzista, il valore-\\(p\\) può cambiare se il ricercatore modifica il piano di raccolta dati (ad es. fermare la raccolta quando si ottiene un certo risultato). Perché si parla di “problema dell’optional stopping”? Come gestisce invece l’approccio bayesiano la decisione di proseguire o fermare un esperimento sulla base dei dati via via raccolti?\nEsercizio 4 – Significatività Statistica vs. Dimensione dell’Effetto\nUno dei limiti dell’approccio frequentista è la confusione tra “significatività statistica” (p&lt;0.05) e “importanza/ampiezza dell’effetto”. Spiega in che modo l’approccio bayesiano può incorporare in modo più diretto la dimensione dell’effetto e l’incertezza a riguardo (tramite le “distribuzioni a posteriori” o “intervalli di credibilità”).\nEsercizio 5 – Problemi di Replicabilità: Come Confrontare Modelli?\nSi osserva spesso che i risultati frequentisti (p&lt;0.05) non si replicano bene in studi successivi. Descrivi come un’analisi bayesiana (con i “fattori di Bayes” o i “posterior odds”) possa dare un quadro più flessibile per confrontare ipotesi alternative, riducendo il rischio di eccessive conclusioni basate su un singolo p-value.\n\n\n\n\n\n\n\n\n\nSoluzioni 3\n\n\n\n\n\nSoluzione 1 – P-value e Probabilità dell’Ipotesi\n\n\nPunto chiave: Il valore-\\(p\\) è la probabilità di ottenere dati “uguali o più estremi” dando per vera l’ipotesi nulla. Invece, “probabilità che \\(H_0\\) sia vera” sarebbe un concetto diverso: è la probabilità dell’ipotesi data i dati osservati (interpretazione inversa).\n\n\nConseguenze pratiche:\n\nUn p-value “basso” non dice “quanto è probabile che \\(H_0\\) sia falsa”, ma solo che quei dati sarebbero rari sotto \\(H_0\\).\n\nI ricercatori spesso sovrastimano la “conferma” contro \\(H_0\\) o interpretano male un p&gt;0.05 come “ipotesi nulla vera”.\n\n\n\n\nApproccio bayesiano: Consente di calcolare una posterior probability di \\(H_0\\) (o di \\(H_1\\)) grazie alla regola di Bayes, purché si disponga di una prior e di un modello.\n\nSoluzione 2 – Risultati più Estremi Non Osservati\n\n\nProblema: Nel frequentismo, il valore-\\(p\\) integra la probabilità di dati che non si sono verificati (“what if scenario”). Ciò porta a dipendere da un insieme di risultati ipotetici e a potenziali paradossi (e.g. “Lady Tasting Tea”).\n\n\nLimite: Può capitare che stessi dati osservati, ma piani di raccolta diversi, generino p-value diversi.\n\n\nBayesian: Calcola la verosimiglianza solo sui dati effettivi e aggiorna la prior → “focus su ciò che è effettivamente avvenuto”. Non serve considerare a posteriori “risultati più estremi” che non si sono verificati, se non in misura minima (attraverso l’integrazione sulle possibili distribuzioni posteriori, ma con un meccanismo diverso dal p-value).\n\nSoluzione 3 – Optional Stopping e Disegno Sperimentale\n\n\nOptional Stopping: In un test frequentista, se continuiamo ad analizzare i dati e fermiamo la raccolta non appena otteniamo p&lt;0.05, si gonfia il rischio di errore di I tipo.\n\n\nLimite: Il p-value frequentista dipende dall’idea di un “protocollo fisso” a priori. Se si viola questo piano (aggiungendo dati finché non si ottiene “significatività”), il test non è più valido.\n\n\nBayesiano: L’approccio consente un monitoraggio sequenziale (monitoring) dei dati: si aggiorna la distribuzione a posteriori man mano che arrivano nuove osservazioni, e fermarsi quando la posterior probability (o il fattore di Bayes) supera (o non supera) una certa soglia. Questo non invalida formalmente l’inferenza perché si sta accumulando evidenza in modo coerente con Bayes.\n\nSoluzione 4 – Ampiezza dell’Effetto e Intervalli di Credibilità\n\n\nFrequenza: Un p-value significativo non dice quanto è grande l’effetto, solo che non si spiega “facilmente” con \\(H_0=0\\).\n\n\nLimite: Spesso si confonde “p&lt;0.05” con “effetto grande/impact significativo”: in realtà, la dimensione potrebbe essere piccola.\n\n\nBayesiano: Offre una distribuzione a posteriori sull’effetto (\\(\\theta\\)), da cui si può ricavare un intervallo di credibilità (dove, ad esempio, c’è il 95% di probabilità che \\(\\theta\\) si trovi in quell’intervallo). Consente di valutare se l’effetto è davvero grande o molto stretto attorno allo 0.\n\nSoluzione 5 – Replicabilità e Confronto di Ipotesi\n\n\nProblema di replicabilità: Molti studi con p&lt;0.05 non vengono replicati (forse per effetti piccoli, scarsa potenza, pubblicazione selettiva, etc.).\n\n\nLimite: Un singolo p-value non dà informazioni su “quanto credere a \\(H_1\\) rispetto a \\(H_0\\)” e non aiuta a cumulare evidenze in analisi meta-analitiche in modo flessibile.\n\n\nBayesiano: Utilizza fattori di Bayes (Bayes Factor) o “posterior odds”, confrontando due modelli (es. \\(H_0\\) vs \\(H_1\\)). Se i dati futuri confermano una delle ipotesi, la posterior si rafforza. È un sistema più graduale e cumulativo di aggiornamento della credenza, riducendo la tendenza a “collezionare p&lt;0.05”.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#informazioni-sullambiente-di-sviluppo",
    "title": "\n89  Significatività statistica\n",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.18.0      thematic_0.1.7   MetBrewer_0.2.0  ggokabeito_0.1.0\n#&gt;  [5] see_0.11.0       gridExtra_2.3    patchwork_1.3.0  bayesplot_1.13.0\n#&gt;  [9] psych_2.5.3      scales_1.4.0     markdown_2.0     knitr_1.50      \n#&gt; [13] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [17] purrr_1.0.4      readr_2.1.5      tidyr_1.3.1      tibble_3.3.0    \n#&gt; [21] ggplot2_3.5.2    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6       shape_1.4.6.1      xfun_0.52         \n#&gt;  [4] htmlwidgets_1.6.4  lattice_0.22-7     tzdb_0.5.0        \n#&gt;  [7] Rdpack_2.6.4       vctrs_0.6.5        tools_4.5.0       \n#&gt; [10] generics_0.1.4     parallel_4.5.0     pan_1.9           \n#&gt; [13] pacman_0.5.1       jomo_2.7-6         pkgconfig_2.0.3   \n#&gt; [16] Matrix_1.7-3       RColorBrewer_1.1-3 lifecycle_1.0.4   \n#&gt; [19] compiler_4.5.0     farver_2.1.2       mnormt_2.1.1      \n#&gt; [22] codetools_0.2-20   htmltools_0.5.8.1  glmnet_4.1-9      \n#&gt; [25] nloptr_2.2.1       pillar_1.10.2      MASS_7.3-65       \n#&gt; [28] reformulas_0.4.1   iterators_1.0.14   rpart_4.1.24      \n#&gt; [31] boot_1.3-31        mitml_0.4-5        foreach_1.5.2     \n#&gt; [34] nlme_3.1-168       tidyselect_1.2.1   digest_0.6.37     \n#&gt; [37] stringi_1.8.7      splines_4.5.0      rprojroot_2.0.4   \n#&gt; [40] fastmap_1.2.0      grid_4.5.0         cli_3.6.5         \n#&gt; [43] magrittr_2.0.3     survival_3.8-3     broom_1.0.8       \n#&gt; [46] withr_3.0.2        backports_1.5.0    timechange_0.3.0  \n#&gt; [49] rmarkdown_2.29     nnet_7.3-20        lme4_1.1-37       \n#&gt; [52] hms_1.1.3          evaluate_1.0.4     rbibutils_2.3     \n#&gt; [55] rlang_1.1.6        Rcpp_1.0.14        glue_1.8.0        \n#&gt; [58] minqa_1.2.8        rstudioapi_0.17.1  jsonlite_2.0.0    \n#&gt; [61] R6_2.6.1",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#bibliografia",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#bibliografia",
    "title": "\n89  Significatività statistica\n",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBenjamin, D. J., Berger, J. O., Johannesson, M., Nosek, B. A., Wagenmakers, E.-J., Berk, R., Bollen, K. A., Brembs, B., Brown, L., Camerer, C., et al. (2018). Redefine statistical significance. Nature Human Behaviour, 2(1), 6–10.\n\n\nDoorn, J. van, Matzke, D., & Wagenmakers, E.-J. (2020). An in-class demonstration of Bayesian inference. Psychology Learning & Teaching, 19(1), 36–45.\n\n\nEtz, A., Gronau, Q. F., Dablander, F., Edelsbrunner, P. A., & Baribault, B. (2018). How to become a Bayesian in eight easy steps: An annotated reading list. Psychonomic bulletin & review, 25(1), 219–234.\n\n\nMehr, S. A., Song, L. A., & Spelke, E. S. (2016). For 5-month-old infants, melodies are social. Psychological Science, 27(4), 486–501.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:\n\n\nWasserstein, R. L., & Lazar, N. A. (2016). The ASA’s statement on p-values: context, process, and purpose. The American Statistician, 70(2), 129–133.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html",
    "title": "\n90  Test t di Student per campioni indipendenti\n",
    "section": "",
    "text": "90.1 Introduzione\nQuesto capitolo è dedicato al test t di Student per campioni indipendenti, uno dei test statistici più utilizzati nella pratica frequentista. Il test t di Student è un metodo che permette di confrontare le medie di due gruppi diversi (o “campioni”) e determinare se la differenza osservata tra le medie sia statisticamente significativa o se possa essere attribuita a semplice casualità.\nIl test è particolarmente utile quando si ha accesso solo a piccoli campioni provenienti da popolazioni sconosciute, ma è importante comprendere bene i suoi principi fondamentali e limiti prima di applicarlo.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#applicazioni-del-test-t-di-student",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#applicazioni-del-test-t-di-student",
    "title": "\n90  Test t di Student per campioni indipendenti\n",
    "section": "\n90.2 Applicazioni del Test t di Student",
    "text": "90.2 Applicazioni del Test t di Student\nIl test t di Student per campioni indipendenti serve per rispondere alla domanda: “Le medie di due gruppi sono significativamente diverse?” Per esempio, potremmo voler sapere se ci sono differenze significative nel peso medio tra uomini e donne.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#assunzioni-principali",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#assunzioni-principali",
    "title": "\n90  Test t di Student per campioni indipendenti\n",
    "section": "\n90.3 Assunzioni Principali",
    "text": "90.3 Assunzioni Principali\nPrima di procedere con il test, è essenziale assicurarsi che siano valide le seguenti ipotesi:\n\n\nIndipendenza: Le osservazioni nei due campioni devono essere indipendenti.\n\nNormalità: I dati nei due campioni provengono da popolazioni distribuite normalmente.\n\nUguaglianza delle Varianze (Omoschedasticità): Le varianze delle due popolazioni da cui provengono i campioni sono uguali.\n\nSe queste condizioni non sono soddisfatte, potrebbe essere necessario considerare alternative come il test di Welch, che non richiede l’uguaglianza delle varianze.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#passaggi-del-test-t-di-student",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#passaggi-del-test-t-di-student",
    "title": "\n90  Test t di Student per campioni indipendenti\n",
    "section": "\n90.4 Passaggi del Test t di Student",
    "text": "90.4 Passaggi del Test t di Student\nEcco una panoramica dei passaggi chiave:\n\n\nCalcolare la Differenza tra le Medie: Si calcola la differenza tra le medie dei due campioni.\n\\[\n\\bar{x}_1 - \\bar{x}_2\n\\]\ndove \\(\\bar{x}_1\\) e \\(\\bar{x}_2\\) sono le medie dei due campioni.\n\n\nStimare la Deviazione Standard Combinata: Se assumiamo che le varianze siano uguali (omoschedasticità), possiamo usare una stima combinata della deviazione standard, chiamata deviazione standard pooled \\(s_p\\):\n\\[\ns_p = \\sqrt{\\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}}\n\\]\ndove \\(n_1\\) e \\(n_2\\) sono le dimensioni dei campioni, e \\(s_1^2\\) e \\(s_2^2\\) sono le varianze campionarie.\n\n\nCalcolare la Statistica t: La statistica t viene calcolata usando la formula seguente:\n\\[\nt = \\frac{(\\bar{x}_1 - \\bar{x}_2)}{s_p \\sqrt{\\left(\\frac{1}{n_1} + \\frac{1}{n_2}\\right)}}\n\\]\n\n\nDeterminare i Gradi di Libertà: I gradi di libertà (\\(df\\)) sono calcolati come:\n\\[\ndf = n_1 + n_2 - 2\n\\]\n\nCalcolare il Valore-p: Infine, si confronta la statistica t con la distribuzione t di Student per ottenere il valore-p. Questo valore indica la probabilità di osservare una differenza così estrema tra le medie dei campioni, dato che l’ipotesi nulla è vera.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#dimostrazione",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#dimostrazione",
    "title": "\n90  Test t di Student per campioni indipendenti\n",
    "section": "\n90.5 Dimostrazione",
    "text": "90.5 Dimostrazione\nPer dimostrare come calcolare la varianza della differenza tra due medie campionarie, consideriamo due campioni casuali indipendenti \\(X_1, X_2, \\dots, X_n\\) e \\(Y_1, Y_2, \\dots, Y_m\\), estratti dalla stessa popolazione con media \\(\\mu\\) e varianza \\(\\sigma^2\\). Definiamo \\(\\bar{X}\\) e \\(\\bar{Y}\\) come le medie campionarie di questi due campioni, rispettivamente.\nLe medie campionarie \\(\\bar{X}\\) e \\(\\bar{Y}\\) sono date da:\n\\[\n\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i ,\n\\] \\[\n\\bar{Y} = \\frac{1}{m} \\sum_{j=1}^m Y_j .\n\\]\nEntrambe le medie campionarie \\(\\bar{X}\\) e \\(\\bar{Y}\\) sono stimatori non distorti della media della popolazione \\(\\mu\\). Le loro varianze sono:\n\\[\n\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n} ,\n\\] \\[\n\\text{Var}(\\bar{Y}) = \\frac{\\sigma^2}{m} .\n\\]\nSiamo interessati a calcolare la varianza della differenza \\(\\bar{X} - \\bar{Y}\\). Utilizzando le proprietà della varianza per combinazioni lineari di variabili aleatorie indipendenti, otteniamo:\n\\[\n\\text{Var}(\\bar{X} - \\bar{Y}) = \\text{Var}(\\bar{X}) + \\text{Var}(\\bar{Y}) ,\n\\]\ndato che i termini incrociati si annullano per l’indipendenza di \\(\\bar{X}\\) e \\(\\bar{Y}\\). Sostituendo le varianze di \\(\\bar{X}\\) e \\(\\bar{Y}\\), abbiamo:\n\\[\n\\text{Var}(\\bar{X} - \\bar{Y}) = \\frac{\\sigma^2}{n} + \\frac{\\sigma^2}{m} ,\n\\] \\[\n\\text{Var}(\\bar{X} - \\bar{Y}) = \\sigma^2 \\left(\\frac{1}{n} + \\frac{1}{m}\\right) .\n\\]\nQuindi, la varianza della differenza tra le due medie campionarie è una combinazione delle varianze delle singole medie, ponderate in base alle dimensioni dei campioni corrispondenti.\nPer giungere alla formula del test \\(t\\) di Student per due campioni indipendenti, dobbiamo considerare l’incertezza aggiuntiva derivante dal fatto che non conosciamo \\(\\sigma\\). Il modo migliore per stimare \\(\\sigma\\) è utilizzare le due deviazioni standard dei campioni, ponderate per i rispettivi gradi di libertà, come indicato nella formula della deviazione standard pooled:\n\\[\ns_p = \\sqrt{\\frac{(n - 1)s^2_x + (m - 1)s^2_y}{n + m - 2}},\n\\]\ndove \\(s_x\\) e \\(s_y\\) sono le deviazioni standard dei due campioni, e \\(n\\) e \\(m\\) sono le numerosità dei due campioni.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#esempio-pratico",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#esempio-pratico",
    "title": "\n90  Test t di Student per campioni indipendenti\n",
    "section": "\n90.6 Esempio Pratico",
    "text": "90.6 Esempio Pratico\nSupponiamo di avere due campioni:\n\n\nDonne: Pesi = [38.9, 61.2, 73.3, 21.8, 63.4, 64.6, 48.4, 48.8, 48.5]\n\nUomini: Pesi = [67.8, 60, 63.4, 76, 89.4, 73.3, 67.3, 61.3, 62.4]\n\nCreiamo un DataFrame in R e calcoliamo la statistica t:\n\nwomen_weight &lt;- c(38.9, 61.2, 73.3, 21.8, 63.4, 64.6, 48.4, 48.8, 48.5)\nmen_weight &lt;- c(67.8, 60, 63.4, 76, 89.4, 73.3, 67.3, 61.3, 62.4)\n\nweight &lt;- c(women_weight, men_weight)\nis_female &lt;- rep(c(1, 0), each = 9)  # 1 = Femmina, 0 = Maschio\n\ndf &lt;- data.frame(is_female = is_female, weight = weight)\n\nPer calcolare manualmente la statistica t:\n\n# Estraiamo i pesi per ogni gruppo\nweight_f &lt;- df$weight[df$is_female == 1]\nweight_m &lt;- df$weight[df$is_female == 0]\n\n# Calcolo della deviazione standard pooled\ns_pool_num &lt;- ((length(weight_f) - 1) * var(weight_f)) + ((length(weight_m) - 1) * var(weight_m))\ns_pool_denom &lt;- length(weight_f) + length(weight_m) - 2\ns_pool &lt;- sqrt(s_pool_num / s_pool_denom)\n\n# Calcolo della statistica t\nt_num &lt;- mean(weight_f) - mean(weight_m)\nt_denom &lt;- s_pool * sqrt(1 / length(weight_f) + 1 / length(weight_m))\nT &lt;- t_num / t_denom\nT\n#&gt; [1] -2.784\n\n\n# Gradi di libertà\ndf_degrees &lt;- length(weight_f) + length(weight_m) - 2\ndf_degrees\n#&gt; [1] 16\n\n\n# Calcolo del valore-p\np_value &lt;- 2 * pt(abs(T), df = df_degrees, lower.tail = FALSE)\nprint(p_value)\n#&gt; [1] 0.01327\n\nIn alternativa, possiamo usare la funzione t.test di R:\n\nres &lt;- t.test(weight_f, weight_m, var.equal = TRUE)\nprint(res, digits = 7)\n#&gt; \n#&gt;  Two Sample t-test\n#&gt; \n#&gt; data:  weight_f and weight_m\n#&gt; t = -2.7842, df = 16, p-value = 0.01327\n#&gt; alternative hypothesis: true difference in means is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -29.748019  -4.029759\n#&gt; sample estimates:\n#&gt; mean of x mean of y \n#&gt;  52.10000  68.98889\n\n\n90.6.1 Interpretazione dei Risultati\nIl test t di Student ha generato un valore-p inferiore a 0.05, indicando che la differenza osservata tra i pesi medi delle donne e degli uomini è statisticamente significativa. Questo significa che, con un livello di confidenza del 95%, possiamo rifiutare l’ipotesi nulla secondo cui le medie dei due gruppi sono uguali.\nÈ importante ricordare che un basso valore-p suggerisce che la differenza osservata non è dovuta al caso. Tuttavia, ciò non prova automaticamente una relazione causale; piuttosto, apre la strada ad ulteriori indagini sulle cause della differenza.\n\n90.6.2 Riportare i Risultati\nQuando si riportano i risultati di un test t, è fondamentale adottare pratiche che favoriscano una comprensione approfondita e accurata dei dati. Di seguito viene presentato un confronto tra due versioni dei risultati: una da evitare, che si basa su un’interpretazione tradizionale della significatività statistica, e una versione migliorata che enfatizza l’intervallo di confidenza e l’ampiezza dell’effetto.\n\n90.6.2.1 Versione da Evitare\nLa seguente formulazione segue un approccio tradizionale incentrato sulla “significatività statistica,” che è oggi ritenuto inadeguato per una comunicazione efficace dei risultati:\n\nAbbiamo condotto un test t di Student per confrontare le medie dei due gruppi. I risultati mostrano una differenza significativa tra i pesi medi delle donne e degli uomini (t(16) = -2.78, p-value = 0.01). L’intervallo di confidenza al 95% per la differenza delle medie è [-29.75, -4.03]. L’ampiezza dell’effetto, misurata con Cohen’s d, è 1.31, indicando un effetto grande. La potenza statistica del test è stata stimata al 74.4%.\n\nIn questa versione, il focus è eccessivamente concentrato sul valore-p, che può portare a interpretazioni riduttive e distorte dei risultati.\n\n90.6.2.2 Versione Migliorata\nEcco invece una versione migliore che mantiene un approccio frequentista, ma sposta l’enfasi sull’intervallo di confidenza e sull’ampiezza dell’effetto, offrendo una descrizione più completa e informativa:\n\nÈ stato condotto un test t di Student per confrontare le medie dei due gruppi. La differenza tra i pesi medi delle donne e degli uomini è stata stimata in -16.89 kg (intervallo di confidenza al 95%: [-29.75, -4.03]), suggerendo che il peso medio degli uomini sia maggiore rispetto a quello delle donne nel campione analizzato. Questo intervallo indica che, con una fiducia del 95%, la differenza reale tra i pesi medi potrebbe variare tra circa -29.75 kg e -4.03 kg.\nL’ampiezza dell’effetto, misurata con Cohen’s d = 1.31, indica una differenza considerevole, equivalente a oltre una deviazione standard. Questo valore suggerisce che la differenza osservata non solo è statisticamente rilevante, ma anche sostanziale dal punto di vista pratico.\nInoltre, la potenza del test, considerando la dimensione dell’effetto osservata, è pari al 74.4%, suggerendo che il test ha una buona capacità di rilevare differenze di questa entità nel campione analizzato. Ciò significa che, se una differenza di tale magnitudine fosse presente nella popolazione, esisterebbe una probabilità superiore al 70% di rilevarla correttamente.\n\nQuesta modalità di reporting fornisce una descrizione più dettagliata ed esplicativa dei risultati, evitando interpretazioni basate esclusivamente sul valore-p e concentrandosi invece sulla grandezza e sull’incertezza della stima. Tale approccio consente una valutazione più equilibrata e informata dei dati, promuovendo una comprensione più approfondita delle implicazioni pratiche e scientifiche dei risultati ottenuti.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#riflessioni-conclusive",
    "title": "\n90  Test t di Student per campioni indipendenti\n",
    "section": "\n90.7 Riflessioni Conclusive",
    "text": "90.7 Riflessioni Conclusive\nIl test t di Student è uno strumento statistico ampiamente utilizzato per l’inferenza su una media o per confrontare le medie di due gruppi. È talmente importante che alcuni lo hanno definito il metodo statistico più importante nella scienza. Tuttavia, come osserva Andrew Gelman, questa affermazione non va accettata acriticamente. Benché il test t sia semplice ed efficace in molti contesti, presenta notevoli limitazioni che ne riducono l’affidabilità e l’applicabilità quando si affrontano problemi complessi o si desidera una comprensione più approfondita dei dati (Kruschke, 2013).\n\n90.7.1 Limiti del Test t di Student\nUno dei principali limiti del test t risiede nell’assunzione che i dati seguano una distribuzione normale (gaussiana). Questa assunzione è spesso violata in pratica, specialmente con campioni piccoli o quando i dati presentano asimmetrie o code pesanti. Inoltre, nel caso di campioni indipendenti, il test richiede l’omogeneità delle varianze, un’altra assunzione frequentemente infondata. Quando queste condizioni non sono soddisfatte, il test può fornire risultati distorti, necessitando di correzioni come quella di Welch per gestire differenze di varianza.\nUn ulteriore limite del test t è legato alla sua dipendenza dalla soglia di significatività \\(\\alpha\\), solitamente fissata a 0.05. Questa scelta è arbitraria e può influenzare criticamente le conclusioni. Il test valuta esclusivamente la compatibilità dei dati con l’ipotesi nulla (\\(H_0\\)) e fornisce solo un p-value, senza offrire informazioni dirette sulla plausibilità dell’ipotesi alternativa (\\(H_1\\)). Ciò significa che un p-value basso non garantisce che \\(H_1\\) sia vera o che i dati supportino tale ipotesi.\n\n90.7.2 L’Approccio Bayesiano: Una Soluzione Più Potente\nIn contrasto con il paradigma frequentista, l’approccio bayesiano offre un quadro statistico più flessibile e informativo. Attraverso il teorema di Bayes, è possibile calcolare direttamente la probabilità di un’ipotesi dato l’insieme dei dati osservati. Questo permette di quantificare la forza dell’evidenza a favore di un’ipotesi rispetto alle altre, superando le limitazioni intrinseche del test t.\n\n90.7.2.1 Vantaggi dell’Approccio Bayesiano\n\nNon richiede assunzioni rigide: A differenza del test t, che si basa su ipotesi restrittive come la normalità e l’omoschedasticità, l’inferenza bayesiana è in grado di gestire modelli più generali e robusti, adattandosi ai dati reali senza doverli forzare in strutture artificiali.\nIncorporazione delle informazioni pregresse: L’approccio bayesiano permette di integrare conoscenze pregresse attraverso distribuzioni a priori, migliorando la qualità delle stime e consentendo analisi più realistiche. Questo è particolarmente utile in situazioni dove i dati disponibili sono scarsi o rumorosi.\nInferenze più informative: Al posto di semplici decisioni binarie (“rifiuto” o “non rifiuto” di \\(H_0\\)), il bayesianismo fornisce distribuzioni a posteriori complete, che descrivono l’incertezza sui parametri di interesse. Questo consente inferenze più dettagliate e interpretabili.\nGestione della complessità: L’approccio bayesiano gestisce in modo naturale modelli complessi e gerarchici, rendendolo ideale per analisi avanzate. Ad esempio, Kruschke (2013) dimostra come tecniche bayesiane possano superare le limitazioni del test t anche in presenza di violazioni delle assunzioni classiche, producendo risultati più stabili e affidabili.\n\n90.7.2.2 Implementazione Pratica\nSebbene l’approccio bayesiano richieda una maggiore attenzione nella scelta delle distribuzioni a priori e nella specificazione del modello, l’avvento di software moderni come Stan, PyMC3 e JAGS ha reso l’implementazione di modelli bayesiani sempre più accessibile. Oggi, anche ricercatori con competenze statistiche moderate possono applicare metodi bayesiani per affrontare problemi complessi con maggiore precisione e coerenza.\n\n90.7.3 Conclusioni\nIl test t di Student rimane un valido strumento per analisi rapide e semplici, ma le sue limitazioni diventano evidenti quando si lavora con dati complessi o si cerca una comprensione più profonda delle relazioni sottostanti. L’approccio bayesiano rappresenta un’evoluzione concettuale e metodologica rispetto all’inferenza frequentista tradizionale, offrendo numerosi vantaggi: inferenze più ricche, integrazione di informazioni pregresse, gestione delle violazioni delle assunzioni e produzione di stime più robuste. Per questi motivi, il paradigma bayesiano è sempre più considerato come la scelta preferibile per chi desidera un’analisi statistica solida, flessibile e informativa.\nIn ultima analisi, mentre il test t resta un punto di partenza utile, l’adozione dell’approccio bayesiano permette di avanzare verso una comprensione più completa e accurata dei dati.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#informazioni-sullambiente-di-sviluppo",
    "title": "\n90  Test t di Student per campioni indipendenti\n",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.18.0      thematic_0.1.7   MetBrewer_0.2.0  ggokabeito_0.1.0\n#&gt;  [5] see_0.11.0       gridExtra_2.3    patchwork_1.3.0  bayesplot_1.13.0\n#&gt;  [9] psych_2.5.3      scales_1.4.0     markdown_2.0     knitr_1.50      \n#&gt; [13] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [17] purrr_1.0.4      readr_2.1.5      tidyr_1.3.1      tibble_3.3.0    \n#&gt; [21] ggplot2_3.5.2    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6       shape_1.4.6.1      xfun_0.52         \n#&gt;  [4] htmlwidgets_1.6.4  lattice_0.22-7     tzdb_0.5.0        \n#&gt;  [7] Rdpack_2.6.4       vctrs_0.6.5        tools_4.5.0       \n#&gt; [10] generics_0.1.4     parallel_4.5.0     pan_1.9           \n#&gt; [13] pacman_0.5.1       jomo_2.7-6         pkgconfig_2.0.3   \n#&gt; [16] Matrix_1.7-3       RColorBrewer_1.1-3 lifecycle_1.0.4   \n#&gt; [19] compiler_4.5.0     farver_2.1.2       mnormt_2.1.1      \n#&gt; [22] codetools_0.2-20   htmltools_0.5.8.1  glmnet_4.1-9      \n#&gt; [25] nloptr_2.2.1       pillar_1.10.2      MASS_7.3-65       \n#&gt; [28] reformulas_0.4.1   iterators_1.0.14   rpart_4.1.24      \n#&gt; [31] boot_1.3-31        mitml_0.4-5        foreach_1.5.2     \n#&gt; [34] nlme_3.1-168       tidyselect_1.2.1   digest_0.6.37     \n#&gt; [37] stringi_1.8.7      splines_4.5.0      rprojroot_2.0.4   \n#&gt; [40] fastmap_1.2.0      grid_4.5.0         cli_3.6.5         \n#&gt; [43] magrittr_2.0.3     survival_3.8-3     broom_1.0.8       \n#&gt; [46] withr_3.0.2        backports_1.5.0    timechange_0.3.0  \n#&gt; [49] rmarkdown_2.29     nnet_7.3-20        lme4_1.1-37       \n#&gt; [52] hms_1.1.3          evaluate_1.0.4     rbibutils_2.3     \n#&gt; [55] rlang_1.1.6        Rcpp_1.0.14        glue_1.8.0        \n#&gt; [58] minqa_1.2.8        rstudioapi_0.17.1  jsonlite_2.0.0    \n#&gt; [61] R6_2.6.1",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#bibliografia",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#bibliografia",
    "title": "\n90  Test t di Student per campioni indipendenti\n",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nKruschke, J. K. (2013). Bayesian estimation supersedes the t test. Journal of Experimental Psychology: General, 142(2), 573–603.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/introduction_replication_crisis.html",
    "href": "chapters/replication_crisis/introduction_replication_crisis.html",
    "title": "Introduzione",
    "section": "",
    "text": "Bibliografia\nLa psicologia, insieme ad altre discipline scientifiche, sta attraversando una Riforma Metodologica scaturita da una crisi profonda: l’incapacità di replicare risultati di ricerche precedentemente pubblicati. Questa crisi di replicazione, che mina la credibilità della scienza, ha portato a un ripensamento radicale delle pratiche di ricerca, degli standard metodologici e degli incentivi accademici (Korbmacher et al., 2023). Siti come Retraction Watch, che monitorano le ritrattazioni di studi scientifici, testimoniano l’entità del problema, evidenziando casi di frodi, manipolazioni statistiche e pratiche di ricerca opache.\nLe Cause della Crisi.\nTra le cause principali vi sono incentivi distorti (come la pressione a pubblicare rapidamente), l’utilizzo acritico di tecniche inferenziali frequentiste – che facilitano la proliferazione di falsi positivi – e la scarsa attenzione alla dimensione campionaria. Come dimostrato da Altmejd et al. (2019), alcuni elementi superficiali permettono di prevedere la replicabilità di uno studio:\nSorprendentemente, prevedere se uno studio sarà replicabile non richiede competenze avanzate. Camerer et al. (2018) ha mostrato che scienziati coinvolti in un “mercato delle scommesse” predicevano con precisione quali studi di scienze sociali si sarebbero replicati. Ancora più significativo è il lavoro di Hoogeveen et al. (2020): partecipanti senza formazione specifica, esposti a semplici descrizioni di studi psicologici, hanno identificato con successo ricerche a rischio di fallimento replicativo. Ciò suggerisce che molti studi presentano difetti metodologici evidenti, riconoscibili persino a un pubblico non esperto.\nLa Diffusione degli Errori nella Letteratura Scientifica.\nLa pubblicazione peer-reviewed non garantisce l’affidabilità di una ricerca. Yang et al. (2020) ha rilevato che studi non replicabili vengono citati con la stessa frequenza di quelli validi, alimentando un ciclo di errori. Questo paradosso – scienziati capaci di riconoscere studi fragili ma inclini a citarli – riflette una cultura accademica disfunzionale (Smaldino & McElreath, 2016), dove la quantità di pubblicazioni prevale sulla qualità e gli incentivi premiano scorciatoie metodologiche.\nEsempi Emblematici e la Crisi di Validità.\nLa crisi non riguarda solo la replicazione, ma anche la validità delle misure e delle teorie. Ricerche influenti, come quelle sul pre-cognition di Ritchie et al. (2012) o sugli effetti del priming inconscio di John Bargh, si sono rivelate basate su evidenze fragili (Schimmack, 2012). Anche concetti consolidati, come l’esaurimento dell’autocontrollo (ego depletion) legato ai livelli di glucosio, sono stati criticati per mancanza di supporto empirico (Vadillo et al., 2016). Persino opere di autori celebri, come Thinking: Fast and Slow di Daniel Kahneman, contengono affermazioni basate su risultati non replicabili (Schimmack, 2020).\nVerso una Soluzione: Oltre l’Inferenza Frequentista.\nQuesta sezione della dispensa si concentra su uno dei nodi metodologici alla base della crisi: i limiti dell’inferenza frequentista (Baker, 2016). Concetti come gli errori di tipo S (conclusioni errate sulla direzione di un effetto) e di tipo M (sovrastima dell’entità di un effetto), introdotti da Gelman & Carlin (2014), illuminano le insidie delle tecniche statistiche tradizionali. Per affrontare la crisi, è necessario adottare approcci alternativi: preregistrazione degli studi, utilizzo di metodi bayesiani, e una valutazione critica della credibilità cumulativa della letteratura (Schimmack, 2020).\nConclusioni.\nLa crisi della replicabilità non è solo un problema tecnico, ma il sintomo di un sistema scientifico da ripensare. Riviste accademiche, istituzioni e ricercatori devono promuovere integrità, trasparenza e una cultura che valorizzi la robustezza rispetto alla novità. Solo così la psicologia potrà riconquistare il ruolo di scienza empirica rigorosa, capace di produrre conoscenza affidabile.",
    "crumbs": [
      "Crisi",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/introduction_replication_crisis.html#bibliografia",
    "href": "chapters/replication_crisis/introduction_replication_crisis.html#bibliografia",
    "title": "Introduzione",
    "section": "",
    "text": "Altmejd, A., Dreber, A., Forsell, E., Huber, J., Imai, T., Johannesson, M., Kirchler, M., Nave, G., & Camerer, C. (2019). Predicting the replicability of social science lab experiments. PloS one, 14(12), e0225826.\n\n\nBaker, M. (2016). Reproducibility Crisis. Nature, 533(7604), 452–454.\n\n\nCamerer, C. F., Dreber, A., Holzmeister, F., Ho, T.-H., Huber, J., Johannesson, M., Kirchler, M., Nave, G., Nosek, B. A., Pfeiffer, T., et al. (2018). Evaluating the replicability of social science experiments in Nature and Science between 2010 and 2015. Nature human behaviour, 2(9), 637–644.\n\n\nGelman, A., & Carlin, J. (2014). Beyond Power Calculations: Assessing Type S (Sign) and Type M (Magnitude) Errors. Perspectives on Psychological Science, 9(6), 641–651.\n\n\nHoogeveen, S., Sarafoglou, A., & Wagenmakers, E.-J. (2020). Laypeople can predict which social-science studies will be replicated successfully. Advances in Methods and Practices in Psychological Science, 3(3), 267–285.\n\n\nKorbmacher, M., Azevedo, F., Pennington, C. R., Hartmann, H., Pownall, M., Schmidt, K., Elsherif, M., Breznau, N., Robertson, O., Kalandadze, T., et al. (2023). The replication crisis has led to positive structural, procedural, and community changes. Communications Psychology, 1(1), 3.\n\n\nRitchie, S. J., Wiseman, R., & French, C. C. (2012). Failing the future: Three unsuccessful attempts to replicate Bem’s ‘Retroactive Facilitation of Recall’Effect. PloS one, 7(3), e33423.\n\n\nSchimmack, U. (2012). The ironic effect of significant results on the credibility of multiple-study articles. Psychological methods, 17(4), 551–566.\n\n\nSchimmack, U. (2020). A meta-psychological perspective on the decade of replication failures in social psychology. Canadian Psychology/Psychologie Canadienne, 61(4), 364–376.\n\n\nSmaldino, P. E., & McElreath, R. (2016). The natural selection of bad science. Royal Society Open Science, 3(9), 160384.\n\n\nVadillo, M. A., Gold, N., & Osman, M. (2016). The bitter truth about sugar and willpower: The limited evidential value of the glucose model of ego depletion. Psychological Science, 27(9), 1207–1214.\n\n\nYang, Y., Youyou, W., & Uzzi, B. (2020). Estimating the deep replicability of scientific findings using human and artificial intelligence. Proceedings of the National Academy of Sciences, 117(20), 10762–10768.",
    "crumbs": [
      "Crisi",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html",
    "href": "chapters/replication_crisis/01_crisis.html",
    "title": "91  La crisi della replicazione",
    "section": "",
    "text": "91.1 Introduzione\nIl presente capitolo introduce la crisi di replicazione che affligge la ricerca psicologica, analizzandone le cause precipue e ponendo in rilievo il ruolo che l’approccio statistico frequentista ha avuto nel concorrere a tale problematica. Il contenuto di questo capitolo costituisce una sintesi rielaborata del testo A student’s guide to open science: Using the replication crisis to reform psychology (Pennington, 2023).",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#i-pilastri-della-scienza-psicologica-ideale",
    "href": "chapters/replication_crisis/01_crisis.html#i-pilastri-della-scienza-psicologica-ideale",
    "title": "91  La crisi della replicazione",
    "section": "\n91.2 I Pilastri della Scienza Psicologica Ideale",
    "text": "91.2 I Pilastri della Scienza Psicologica Ideale\nAffinché la psicologia sia riconosciuta come scienza rigorosa, deve aderire a principi fondamentali:\n\n91.2.1 A. Replicabilità e Riproducibilità\n\n\n\nDefinizione: Un effetto empirico è considerato valido solo se replicabile da ricercatori indipendenti, con metodologie analoghe e campioni adeguati.\n\n\nEsempio: Lo studio classico di Asch sul conformismo (1951) è stato replicato in contesti cross-culturali, rafforzandone la validità.\n\n91.2.2 B. Attributi Essenziali della Ricerca\n\nLa scienza ideale dovrebbe essere:\n\n\n\n\n\n\n\nPrincipio\nDescrizione\nImplicazioni per la Psicologia\n\n\n\nCredibile\nSottoposizione delle ipotesi a verifica rigorosa e peer review trasparente.\nEvitare p-hacking e HARKing (Hypothesizing After Results are Known).\n\n\nAffidabile\nRisultati accurati e privi di distorsioni (bias).\nUtilizzo di preregistrazione e open data.\n\n\nTrasparente\nDescrizione dettagliata di metodi, analisi e risultati.\nAdozione di registered reports e condivisione di materiali supplementari.\n\n\nAccessibile\nDemocratizzazione della conoscenza (es. open access).\nPiattaforme come PsyArXiv per preprint o OSF per la condivisione di protocolli.\n\n\nInclusiva\nPartecipazione equa di gruppi sottorappresentati (etnici, di genere, ecc.).\nStudi con campioni diversificati (es. non solo WEIRD: Western, Educated, Industrialized, Rich, Democratic).\n\n\nCollaborativa\nSuperamento della competizione accademica a favore di reti di ricerca.\nProgetti multi-lab (es. Many Labs in psicologia sociale).\n\n\nAutocorrettiva\nRevisione continua degli errori e ritrattazione di risultati non validi.\nDatabase come Retraction Watch e correzioni pubbliche negli articoli.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#la-disconnessione-tra-ideale-e-realtà",
    "href": "chapters/replication_crisis/01_crisis.html#la-disconnessione-tra-ideale-e-realtà",
    "title": "91  La crisi della replicazione",
    "section": "\n91.3 La Disconnessione tra Ideale e Realtà",
    "text": "91.3 La Disconnessione tra Ideale e Realtà\nPennington (2023) utilizza un esercizio retorico per criticare la prassi scientifica tradizionale:\n\nVisualizzate lo stereotipo dello scienziato: un uomo bianco, in un laboratorio con cartelli ‘DIVIETO DI ACCESSO’, che tratta i dati come proprietà privata. Questa immagine riflette una scienza chiusa, competitiva e non allineata ai valori di trasparenza e collaborazione.\n\n\n91.3.1 Problemi Emersi\n\n\nSegretezza: Ricercatori che occultano dati per paura di critiche o “furti” di idee.\n\n\nCrisi di replicazione: Il 50-70% degli studi psicologici non è replicabile (Collaboration, 2015).\n\n\nPressioni accademiche: Focus su pubblicazioni “rivoluzionarie” a scapito di solidità metodologica.\n\n91.3.2 Verso una Psicologia più Rigorosa\nPer affrontare le criticità emerse nella ricerca psicologica, sono state avanzate diverse proposte concrete. Una delle direzioni più promettenti è l’adozione diffusa delle pratiche di Open Science, che includono la preregistrazione degli studi (per evitare il p-hacking), la condivisione aperta dei dati (open data) e l’utilizzo di strumenti gratuiti e trasparenti, come il software JASP per le analisi statistiche. Questi approcci non solo aumentano l’affidabilità dei risultati, ma favoriscono anche una cultura di collaborazione anziché di segretezza.\nUn altro passo fondamentale riguarda la formazione dei ricercatori. Introdurre corsi obbligatori su etica della ricerca e metodi quantitativi avanzati potrebbe ridurre errori metodologici e comportamenti opportunistici, preparando una nuova generazione di psicologi a standard più rigorosi.\nInfine, è essenziale ripensare il sistema di valutazione accademica. Invece di premiare la mera quantità di pubblicazioni – che spesso spinge verso risultati “sensazionali” ma poco replicabili – sarebbe più produttivo incentivare la qualità, la trasparenza e l’impatto a lungo termine del lavoro scientifico.\nUn esempio concreto di questo cambiamento è il progetto ManyBabies, un’iniziativa internazionale che coinvolge decine di laboratori nello studio dello sviluppo infantile. Grazie alla collaborazione su larga scala e alla condivisione di protocolli standardizzati, ManyBabies ha dimostrato come sia possibile produrre risultati più solidi e generalizzabili, superando i limiti dei piccoli studi isolati. Questo caso illustra perfettamente i benefici di una psicologia più aperta, cooperativa e metodologicamente rigorosa.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#la-crisi-della-replicazione-in-psicologia",
    "href": "chapters/replication_crisis/01_crisis.html#la-crisi-della-replicazione-in-psicologia",
    "title": "91  La crisi della replicazione",
    "section": "\n91.4 La Crisi della Replicazione in Psicologia",
    "text": "91.4 La Crisi della Replicazione in Psicologia\nNegli ultimi decenni, la psicologia si è trovata al centro di una crisi che ha messo in discussione molte delle sue basi epistemologiche e metodologiche: la crisi della replicazione. Questo fenomeno indica l’incapacità di replicare con successo un’ampia parte degli studi pubblicati, con implicazioni rilevanti per la cultura accademica e il modo di concepire la ricerca scientifica (Parsons et al., 2022).\nPer fallimento della replicazione si intende il caso in cui uno studio, ripetuto da altri ricercatori seguendo le stesse procedure e utilizzando campioni simili, non riesce a ottenere risultati comparabili a quelli originali. Questo ha portato alla luce problemi sistemici legati alla metodologia di ricerca, all’interpretazione dei dati e alle dinamiche del sistema accademico. La crisi della replicazione ha dunque evidenziato la necessità di un cambiamento strutturale nella pratica scientifica, sottolineando l’urgenza di un approccio più trasparente, rigoroso e collaborativo.\nNelle sezioni seguenti vengono presentati gli eventi chiave di quella che possiamo chiamare la storia della crisi della replicazione.\n\n91.4.1 2005: “Perché la maggior parte dei risultati pubblicati è falsa” (Ioannidis)\nUn primo momento cruciale è stato l’articolo di “Why Most Published Research Findings Are False” (Ioannidis, 2005) che ha evidenziato come molti risultati scientifici fossero in realtà falsi positivi. Ioannidis attribuì questo fenomeno a campioni di piccole dimensioni, un’eccessiva enfasi sui valori-p per indicare significatività, flessibilità nei metodi di analisi e la competizione per produrre risultati “innovativi”. Questo articolo ha messo in luce problemi che trascendono la psicologia, ma che in seguito sarebbero emersi come centrali anche per questa disciplina.\n\n91.4.2 2011: Lo Studio di Daryl Bem, “Feeling the Future”\nUno degli eventi più controversi è stato lo studio di Daryl Bem “Feeling the Future” (Bem, 2011), che suggeriva l’esistenza della precognizione, ovvero la capacità di “sentire” eventi futuri. Attraverso nove esperimenti, Bem pubblicò risultati statisticamente significativi che sembravano sfidare le leggi della causalità.\nLo studio di Bem si inseriva nella tradizione degli esperimenti di “priming”, una tecnica ampiamente utilizzata in psicologia sociale dagli anni ’70. Gli esperimenti di priming tipicamente coinvolgevano studenti universitari, remunerati con modeste somme o crediti accademici. I partecipanti venivano esposti a determinati concetti per poi osservare come questi influenzassero il loro comportamento successivo. Un celebre esempio è lo studio di John Bargh del 1996, che dimostrò come l’esposizione a parole associate all’età avanzata inducesse i soggetti a camminare più lentamente (Bargh et al., 1996). Un altro studio del 2006 rivelò che il priming con concetti legati al denaro rendeva le persone meno propense ad aiutare gli altri. Questi studi sembravano dimostrare una straordinaria malleabilità della mente umana, suggerendo che il nostro comportamento potesse essere inconsciamente manipolato da sottili segnali ambientali (Leys, 2024). Tuttavia, lo studio di Bem introdusse un elemento nuovo in questo paradigma sperimentale.\nTra i vari esperimenti condotti da Bem, uno in particolare si distingueva. I soggetti venivano esposti a una parola con connotazione positiva o negativa e successivamente dovevano valutare rapidamente la piacevolezza di alcune immagini. Fin qui, nulla di insolito. La svolta radicale consisteva nel fatto che in metà delle prove, il priming avveniva dopo che i soggetti avevano già visto e valutato l’immagine (Bem, 2011).\nSorprendentemente, i risultati mostravano che il priming funzionava anche in queste condizioni: i partecipanti erano più veloci a giudicare piacevoli le immagini quando successivamente venivano esposti a una parola positiva. Questo effetto risultava statisticamente significativo, con un p-value di 0.01, sufficiente secondo gli standard correnti per rifiutare l’ipotesi nulla.\nBem interpretò questi risultati come prova della chiaroveggenza, una conclusione che suscitò notevoli controversie e ridicolizzò la psicologia. Gli altri otto esperimenti dello studio, tutti basati su classici paradigmi della psicologia sociale con l’ordine temporale invertito, mostrarono risultati altrettanto statisticamente significativi.\nQuesti risultati ponevano la comunità scientifica di fronte a un dilemma: accettare l’esistenza di fenomeni paranormali o mettere in discussione le pratiche statistiche e metodologiche consolidate nella disciplina. Bem stesso continua a sostenere la validità dei suoi risultati come prova dell’esistenza di capacità precognitive.\nSebbene pubblicato su una rivista prestigiosa, lo studio sollevò enormi dubbi metodologici. Le repliche successive non riuscirono a confermare i risultati di Bem, mostrando come pratiche discutibili, quali il p-hacking (modifiche al metodo di analisi per ottenere risultati significativi), potessero produrre falsi positivi apparentemente robusti.\n\n91.4.3 2011: Il Caso di Frode di Diederik Stapel\nNello stesso anno, Diederik Stapel, una figura di spicco della psicologia sociale, fu accusato di aver falsificato dati in decine di studi pubblicati. Tra i suoi esperimenti più famosi vi era quello secondo cui ambienti disordinati aumenterebbero il razzismo. Un altro studio suggeriva che mangiare carne rendeva le persone più antisociali. Tuttavia, si scoprì che per quegli studi, e molti altri, non aveva mai condotto gli esperimenti né raccolto i dati. Li aveva semplicemente inventati. A volte le frodi accadono. Stapel fu scoperto (alla fine), licenziato e decine dei suoi articoli furono ritirati. Questo scandalo scosse profondamente la comunità accademica e divenne un simbolo della crisi.\n\n91.4.4 2011: La Meta-ricerca e le Pratiche di Ricerca Discutibili (QRPs)\nLa meta-ricerca è un campo di studio che si concentra sul modo in cui viene condotta la ricerca scientifica. Comprende temi come i metodi, la trasparenza nella comunicazione, la riproducibilità, la valutazione e i sistemi di incentivi che regolano la scienza (Ioannidis et al., 2015). Questo ambito è emerso con urgenza dopo una serie di casi controversi e di frodi conclamate, come gli studi di Daryl Bem e Diederik Stapel, che hanno evidenziato falle nei processi di ricerca. I ricercatori hanno così iniziato ad analizzare pratiche note come Questionable Research Practices (QRPs, Pratiche di Ricerca Discutibili), che sfruttano aree grigie nelle norme scientifiche per raccogliere e analizzare i dati.\nSimmons et al. (2011) hanno dimostrato come la flessibilità nella raccolta, analisi e comunicazione dei dati permetta ai ricercatori di far apparire “significativo” praticamente qualsiasi risultato. Tra le pratiche discusse, spiccano:\n\n\nOptional stopping: Interrompere la raccolta dei dati non appena si raggiunge la significatività statistica, invece di seguire un piano prestabilito.\n\n\nP-hacking: Condurre molteplici test non pianificati, selezionando variabili o analisi solo quando producono un valore p inferiore a 0.05.\n\n\nHARKing (Hypothesizing After Results are Known): Modificare le ipotesi a posteriori per adattarle ai risultati ottenuti, presentandole come ipotesi iniziali.\n\nQueste pratiche non solo compromettono l’integrità scientifica, ma rendono estremamente facile produrre falsi positivi. Per dimostrarlo, Simmons e colleghi hanno condotto simulazioni al computer e due esperimenti, rivelando quanto fosse “troppo facile” raccogliere prove a sostegno di ipotesi false.\nLa portata di queste pratiche è sorprendente. Simmons et al. hanno scoperto che:\n\nUsare una sola QRP può quasi raddoppiare il tasso di falsi positivi, portandolo dal 5% al 10%.\n\nCombinare più QRPs può far salire questa percentuale oltre il 60%.\n\nPer sottolineare il problema, i ricercatori hanno dimostrato, in modo volutamente ironico, che ascoltare la canzone dei Beatles “When I’m Sixty-Four” potrebbe far apparire le persone più giovani di quanto fossero prima di ascoltarla. Questa dimostrazione satirica evidenziava che inseguire la significatività statistica senza un rigore metodologico può produrre risultati assurdi.\nJohn et al. (2012) hanno condotto un’indagine su larga scala, intervistando 2000 ricercatori per comprendere la diffusione delle QRPs. Con un approccio innovativo, hanno chiesto ai partecipanti non solo di riferire le proprie pratiche, ma anche quelle dei colleghi. I risultati sono stati sconvolgenti:\n\nOltre il 60% degli intervistati ha ammesso di non aver riportato tutte le variabili dipendenti misurate.\n\nPiù del 50% ha interrotto la raccolta dati non appena ottenuti risultati significativi (optional stopping).\n\nPiù del 40% ha selezionato e riportato solo esperimenti “riusciti”.\n\nSorprendentemente, i ricercatori tendevano a dichiarare che i colleghi adottavano queste pratiche più frequentemente di loro stessi. Molti giustificavano queste pratiche come “norme accademiche” del tempo.\nLa meta-ricerca ha giocato un ruolo cruciale nell’aprire gli occhi della comunità scientifica sui pericoli di queste decisioni apparentemente “banali”. In un contesto in cui le QRPs erano ampiamente accettate, la meta-ricerca ha evidenziato come queste pratiche possano seriamente danneggiare il progresso scientifico. Grazie al movimento dell’Open Science, si stanno introducendo norme che migliorano la credibilità della ricerca, spostando l’enfasi dalla produzione di risultati “significativi” alla conduzione di studi rigorosi e trasparenti.\n\n91.4.5 2012: La Crisi di Fiducia della Psicologia\nSiamo nel 2012, un anno segnato da una serie di eventi che spingono Harold Pashler ed Eric-Jan Wagenmakers a dichiarare che la psicologia sta affrontando una “crisi di fiducia”. In un numero speciale della rivista Perspectives on Psychological Science (PoPs), i due autori raccolgono una molteplicità di prospettive sulla nascente crisi della replicazione, cercando di individuarne le cause e le implicazioni.\nLe reazioni alla crisi sono variegate e, in alcuni casi, contrastanti. Alcuni studiosi sostengono che le affermazioni di una crisi siano premature (Stroebe e Strack, 2014) e che i problemi di replicazione non siano un fenomeno nuovo (Spellman, 2015). Altri, invece, sottolineano come incentivare e valorizzare gli studi di replicazione rappresenti un metodo efficace e diretto per migliorare la qualità della scienza psicologica (Koole e Lakens, 2012).\nIl numero speciale evidenzia anche iniziative in corso per affrontare il problema. Tra queste, l’Open Science Collaboration (OSC), un progetto di larga scala avviato nel 2012, si propone di verificare empiricamente se la psicologia sia effettivamente alle prese con una crisi della replicazione. L’obiettivo del progetto è ambizioso: replicare numerosi studi pubblicati per valutare la robustezza dei risultati originari. Sebbene i risultati di questa iniziativa non fossero ancora disponibili al momento della pubblicazione del numero speciale, il progetto rappresentava già una pietra miliare per la disciplina.\nNonostante le preoccupazioni, il numero speciale si chiude con una nota positiva, destinata a risuonare nella comunità scientifica. I casi di frode, le pratiche di ricerca discutibili (QRPs) e i fallimenti nei tentativi di replicazione, sebbene dannosi, hanno aperto la strada a una riflessione critica. Questo processo ha permesso alla psicologia di affrontare i propri limiti, correggere errori, superare i bias e costruire una letteratura più affidabile e trasparente.\nQuesto periodo storico segna un punto di svolta: la crisi di fiducia ha messo in discussione le fondamenta della disciplina, ma ha anche creato l’opportunità per un rinnovamento scientifico, stimolando pratiche più rigorose e una maggiore attenzione alla replicabilità e alla trasparenza.\n\n91.4.6 2014: Il Progetto “Many Labs”\nNel 2014 fu pubblicato il primo tentativo su larga scala di replicare risultati psicologici: il progetto “Many Labs”. Questo imponente sforzo collaborativo, guidato da Klein et al. (2014), testò la replicabilità di 13 risultati classici della psicologia, coinvolgendo 6344 partecipanti in 12 paesi. Gli studi selezionati rispettavano tre criteri principali: erano relativamente brevi, avevano un design semplice e potevano essere facilmente condotti online.\nTra i fenomeni esaminati figurava la fallacia del costo irrecuperabile (sunk cost fallacy), secondo cui le persone tendono a proseguire un’attività quando vi hanno già investito tempo, sforzi o denaro. Un esempio classico: se hai acquistato un biglietto per vedere la tua squadra di calcio preferita e, il giorno della partita, inizia a piovere a dirotto, sarai più propenso a partecipare perché hai già speso i soldi per il biglietto (Oppenheimer e Monin, 2009).\nAltri studi replicati includevano:\n\nL’influenza del framing dei guadagni e delle perdite sul rischio (Tversky e Kahneman, 1981).\n\nLe differenze di genere negli atteggiamenti impliciti verso la matematica e le arti (Nosek et al., 2002).\n\nI risultati sembravano promettenti: il 77% degli studi replicò con successo i risultati originali (10 su 13). Tuttavia, non tutti gli studi fornirono lo stesso livello di evidenza. Ad esempio:\n\nUno studio sull’efficacia del contatto sociale immaginato nel ridurre i pregiudizi (Husnu e Crisp, 2010) mostrò supporto limitato, con solo 4 campioni su 36 che evidenziarono un effetto significativo.\n\nDue studi di priming non furono replicati. Nel primo, i ricercatori non trovarono che l’esposizione alla bandiera americana aumentasse il conservatorismo (Carter et al., 2011). Nel secondo, il priming con concetti legati al denaro non portò a un incremento delle credenze o dei comportamenti capitalistici (Caruso et al., 2013).\n\nSebbene i risultati fossero accolti come una vittoria per la replicabilità, alcuni ricercatori sottolinearono limiti nel progetto Many Labs 1. Gli stessi autori riconobbero che molti degli studi selezionati erano già noti per essere altamente replicabili. Secondo alcuni critici, il principale contributo di questo progetto era dimostrare che almeno dieci effetti psicologici erano replicabili, ma non forniva una panoramica più ampia sulla replicabilità complessiva nella psicologia (Yarkoni, 2013).\nQuesto progetto rappresentò comunque un passo fondamentale per affrontare la crisi della replicazione, sottolineando l’importanza della collaborazione scientifica e del rigore metodologico.\n\n91.4.7 2015: Il Progetto di Riproducibilità della Open Science Collaboration\nNel 2015, la Open Science Collaboration (OSC) pubblicò i risultati del Reproducibility Project: Psychology, dimostrando che la buona scienza richiede tempo e rigore. Superando i limiti del progetto Many Labs 1, un team composto da oltre 270 ricercatori internazionali si impegnò a replicare 100 studi scelti casualmente da riviste di punta nel campo della psicologia.\nPer garantire risultati solidi e inattaccabili, il team adottò una metodologia rigorosa:\n- Consultazione con gli autori originali: gli autori degli studi originali furono coinvolti per confermare il design sperimentale e ridurre al minimo eventuali discrepanze.\n- Aumento delle dimensioni campionarie: i campioni furono ampliati per garantire una potenza statistica sufficiente.\n- Registrazione preventiva dei metodi: i piani di analisi e raccolta dati furono registrati in anticipo per prevenire bias da parte dei ricercatori.\nGli studi selezionati per la replicazione includevano domande di ricerca come:\n\nLa convinzione che il comportamento umano sia predeterminato incoraggia il tradimento?\n\nI bambini seguono automaticamente lo sguardo per trovare oggetti nascosti?\n\nÈ possibile osservare un “effetto after-motion” da fotografie fisse che rappresentano movimento?\n\nI risultati del progetto fecero scalpore e conquistarono i titoli dei giornali a livello globale. Solo il 36% degli studi replicò con successo, ottenendo un valore-p inferiore a 0.05. La psicologia sociale si rivelò particolarmente problematica, con un tasso di replicazione del 25%, rispetto al 50% degli studi di psicologia cognitiva.\nPer contestualizzare questi numeri, se gli effetti originali fossero stati realmente validi, il tasso minimo di replicazione atteso sarebbe stato dell’89% (Field et al., 2019). Anche tra gli studi replicati, le dimensioni degli effetti risultarono dimezzate rispetto a quelle riportate negli studi originali.\nQuesti risultati provocarono una forte reazione nella comunità scientifica. Ci si chiedeva: era la fine della psicologia? La disciplina avrebbe mai recuperato credibilità? Sebbene i dati fossero allarmanti, aprirono un dibattito più ampio. Come sottolineato da Kuhn (1962) e Redish et al. (2018), fallimenti nella replicazione possono segnare l’inizio di una rivoluzione scientifica, stimolando un ripensamento dei metodi, delle ipotesi e delle pratiche di ricerca.\nIl Reproducibility Project: Psychology non solo mise in luce le fragilità della disciplina, ma divenne un punto di partenza per migliorare la trasparenza, la collaborazione e la robustezza nella ricerca psicologica.\n\n91.4.7.1 Studi Successivi\nQuesti risultati sono stati ulteriormente corroborati da numerosi studi successivi, tra cui una ricerca più recente basata su tecniche di machine learning, che ha esaminato studi di psicologia pubblicati in sei importanti riviste nell’arco di vent’anni. Questa ricerca suggerisce che poco più della metà di questi articoli di psicologia non supererebbe i test di replicazione (Youyou et al., 2023). Discipline come la psicologia sociale sono state oggetto di particolare preoccupazione, con un tasso di replicazione del solo 25% riportato dal Progetto di Riproducibilità (Collaboration, 2015). Questo dato è in linea con il lavoro di Youyou et al. (2023), che ha mostrato come la replicabilità degli articoli di psicologia vari considerevolmente per sottocampo, con la psicologia sociale che mostra un tasso di replicazione stimato del 37%, un risultato leggermente più incoraggiante rispetto a quanto riportato in precedenza, ma ancora tra i più bassi dei sottocampi esaminati. Altri settori come la psicologia dello sviluppo, cognitiva e clinica hanno mostrato tassi di replicazione stimati rispettivamente del 36%, 42% e 44%, mentre aree come la psicologia delle organizzazioni e della personalità hanno mostrato tassi leggermente più incoraggianti (50% e 55%, rispettivamente). Complessivamente, le evidenze suggeriscono che le preoccupazioni diffuse sulla robustezza e replicabilità dei risultati della ricerca psicologica siano fondate. Sebbene il problema non sia limitato esclusivamente alla psicologia, le questioni rilevate in questo campo hanno ricevuto notevole attenzione a causa dell’apparente portata del fenomeno.\nQuesti risultati confermavano in modo drammatico le previsioni formulate anni prima da John Ioannidis e Dennis Lindley. Le loro avvertenze riguardo alla possibilità che una larga parte, se non la maggioranza, dei risultati scientifici pubblicati potesse essere falsa, si rivelavano ora profetiche.\nIl Progetto di Riproducibilità di Nosek ha segnato un punto di svolta nel dibattito sulla crisi della replicazione in psicologia e, più in generale, nelle scienze sociali e biomediche. Ha evidenziato non solo la fragilità di molti risultati ritenuti consolidati, ma anche la necessità di un riesame critico delle pratiche di ricerca e pubblicazione scientifica. Questo ripensamento delle metodologie scientifiche è ancora in atto.\n\n91.4.8 2015: 1500 Scienziati Sollevano il Velo sulla Riproducibilità\nI risultati del progetto Collaboration (2015) colpirono il mondo della psicologia come un fulmine a ciel sereno. Molti risultati psicologici, considerati affidabili, crollarono improvvisamente, generando un’ondata di discussioni nei dipartimenti universitari: quale sarebbe stato il prossimo “effetto” a fallire? Tuttavia, nonostante la psicologia fosse diventata l’emblema delle repliche fallite, presto si comprese che non era un problema esclusivo della disciplina.\nNel 2016, Baker condusse un’indagine su 1500 scienziati provenienti da diverse discipline, tra cui chimica, medicina, fisica e ingegneria, per esplorare le preoccupazioni riguardo alla replicazione e alla riproducibilità (Baker, 2016). I risultati furono sorprendenti: circa il 90% dei partecipanti concordò sull’esistenza di una crisi di riproducibilità, definita come significativa dal 52% e lieve dal 38%.\nUn dato particolarmente allarmante emerse dall’indagine:\n\nIn media, il 40% degli scienziati aveva riscontrato difficoltà nel riprodurre i propri esperimenti.\n\nQuesta percentuale saliva a oltre il 60% quando si tentava di riprodurre gli esperimenti di altri ricercatori.\n\nTra le discipline, la chimica risultò la più problematica, con oltre l’85% dei ricercatori che riportavano fallimenti nel riprodurre i risultati altrui.\nL’articolo di Baker riportava anche esperienze personali che riflettevano il senso di smarrimento generato da questa crisi. Il professor Marcus Munafò, per esempio, descrisse così il suo percorso:\n\nHo cercato di replicare ciò che dalla letteratura sembrava semplice, ma non ci sono riuscito. Ho avuto una crisi di fiducia, e poi ho scoperto che questa esperienza non era affatto rara. (Baker, 2016)\n\nL’indagine di Baker non si limitò a evidenziare il problema, ma esplorò anche le possibili cause della crisi, come pratiche metodologiche inadeguate e pressioni accademiche, offrendo al contempo suggerimenti per interventi correttivi.\nL’indagine segnò un momento cruciale: la crisi della riproducibilità, inizialmente confinata a discussioni accademiche, raggiunse una visibilità globale. Non era più solo un problema della psicologia, ma un fenomeno che colpiva l’intero mondo scientifico, portando con sé la necessità di una trasformazione radicale delle pratiche di ricerca.\nQuesto evento contribuì a consolidare il riconoscimento della crisi della riproducibilità come una sfida centrale per tutta la scienza, spingendo verso un cambiamento culturale che mettesse al centro trasparenza, rigore e collaborazione.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#la-cultura-della-frode-nel-sistema-accademico",
    "href": "chapters/replication_crisis/01_crisis.html#la-cultura-della-frode-nel-sistema-accademico",
    "title": "91  La crisi della replicazione",
    "section": "\n91.5 La Cultura della Frode nel Sistema Accademico",
    "text": "91.5 La Cultura della Frode nel Sistema Accademico\nIn alcuni casi, la crisi della replicazione si intreccia con episodi di frode scientifica, rivelando un lato oscuro della ricerca accademica. Uno degli aspetti più preoccupanti è che il sistema accademico, con i suoi meccanismi di incentivo basati su pubblicazioni frequenti e finanziamenti competitivi, può indirettamente favorire comportamenti disonesti. Questo sistema, orientato al publish or perish (pubblica o scompari), crea pressioni che talvolta spingono i ricercatori a compromettere l’integrità scientifica per raggiungere i propri obiettivi di carriera.\n\n91.5.1 Il Caso Brian Wansink\nUn caso emblematico è quello di Brian Wansink, ex ricercatore di spicco alla Cornell University, che ricevette cospicui finanziamenti federali durante l’amministrazione Obama. I suoi studi sul comportamento alimentare, come quello sugli uomini che mangiano di più in presenza di donne o sull’effetto dei nomi “attraenti” dati alle verdure sul consumo da parte dei bambini, attirarono grande attenzione mediatica ma si rivelarono in seguito non replicabili. Le conseguenze per Wansink furono severe: diciotto suoi articoli furono ritirati, sette ricevettero “espressioni di preoccupazione”, e quindici furono corretti. Nel 2019, Wansink si dimise dalla Cornell University dopo essere stato giudicato colpevole di cattiva condotta scientifica.\n\n91.5.2 Il Caso Sylvain Lesné\nUn altro esempio rilevante riguarda Sylvain Lesné e i suoi coautori che, nel 2006, pubblicarono su Nature un importante articolo sul morbo di Alzheimer. Questo lavoro era fondamentale per lo sviluppo dell’ipotesi amiloide, un meccanismo proposto per spiegare come la malattia affligge le sue vittime. La ricerca sulla malattia di Alzheimer, che colpisce oltre 50 milioni di persone nel mondo, ha ricevuto oltre un miliardo di dollari in finanziamenti governativi fino al 2022, incoraggiata da studi come quello di Lesné.\nNel 2022, il neuroscienziato Matthew Schrag scoprì immagini manipolate in questo e in molti altri articoli di Lesné, inclusi quelli che sostenevano l’ipotesi amiloide. Le immagini erano state manualmente modificate e accorpate per mostrare falsamente supporto alle ipotesi degli articoli. Queste frodi passarono inosservate attraverso i processi di peer review formali di Nature e di altre sei riviste accademiche, venendo infine scoperte solo tramite canali non ufficiali.\nLe conseguenze di queste scoperte furono lente e frammentarie. Gli altri coautori dell’articolo del 2006 alla fine accettarono di ritirarlo, ma non Lesné stesso. La lentezza della risposta a queste evidenze di frode, e il fatto che Lesné continui a essere finanziato dal National Institutes of Health e impiegato presso l’Università del Minnesota, dimostra un fallimento sistemico nell’affrontare la cattiva condotta scientifica.\n\n91.5.3 Altri Casi di Rilievo\nNel mondo accademico, diversi altri recenti scandali hanno messo in luce il problema della frode scientifica e le sue conseguenze spesso limitate per i responsabili. Ecco alcuni casi emblematici:\n\nMarc Tessier-Lavigne, ex presidente della Stanford University: Nel 2023, fu costretto a dimettersi dopo la rivelazione di dati falsificati in sue ricerche precedenti presso Genentech. Nonostante lo scandalo, Tessier-Lavigne ha subito conseguenze minime, diventando successivamente CEO di una nuova azienda di ricerca farmacologica. Lo scandalo fu portato alla luce grazie all’indagine condotta da Theo Baker, uno studente diciassettenne di Stanford.\n\nDan Ariely e Francesca Gino: Questi due rinomati psicologi, noti per le loro ricerche sulla disonestà e il comportamento non etico, sono stati coinvolti in uno scandalo di frode scientifica.\n\nDan Ariely, nel 2021, fu implicato nella fabbricazione di dati in un articolo del 2012 sulla disonestà.\nFrancesca Gino, docente presso la Harvard Business School, è stata accusata di aver presentato lavori contenenti risultati falsificati. Il sito del Dipartimento ora riporta che è in “administrative leave”.\n\n\n\nL’inefficacia delle istituzioni accademiche nel gestire la frode scientifica sembra riflettere un problema culturale di carattere sistemico. Gli incentivi attuali favoriscono la pubblicazione di risultati positivi e innovativi, spesso a scapito dell’integrità scientifica. Gli studiosi che resistono a queste pressioni rischiano di essere emarginati, mentre chi adotta pratiche discutibili per ottenere risultati desiderati viene premiato con finanziamenti, promozioni e prestigio accademico.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#cosa-significa-fallimento-della-replicazione",
    "href": "chapters/replication_crisis/01_crisis.html#cosa-significa-fallimento-della-replicazione",
    "title": "91  La crisi della replicazione",
    "section": "\n91.6 Cosa Significa “Fallimento della Replicazione”?",
    "text": "91.6 Cosa Significa “Fallimento della Replicazione”?\nIl fallimento della replicazione non coincide necessariamente con l’idea che il fenomeno studiato sia inesistente. Al contrario, le cause di un esito negativo in un tentativo di replicazione possono essere molteplici e spesso difficili da individuare con precisione. Comprendere queste ragioni è fondamentale per identificare le criticità metodologiche, migliorare il rigore scientifico e favorire il progresso della conoscenza. Al di là dei casi evidenti di frode, i fallimenti della replicazione rappresentano un’opportunità per riflettere sulla qualità delle pratiche di ricerca.\n\n91.6.1 Possibili Cause di Fallimento nella Replicazione\n\nFalsi positivi nello studio originale\nUn fallimento può indicare che lo studio originale abbia rilevato un effetto inesistente per puro caso. Questo rischio è particolarmente elevato in studi con campioni di piccole dimensioni e bassa potenza statistica, dove gli effetti riportati risultano spesso sovrastimati o instabili.\n\nFalsi negativi nella replica\nIl fallimento può derivare da un falso negativo, ovvero la mancata rilevazione di un effetto realmente esistente. Le cause principali includono:\n\nDifferenze metodologiche o di popolazione tra studio originale e replica.\n\nConfondenti metodologici o una potenza statistica insufficiente.\n\nPresenza di variabili moderatrici che influenzano l’intensità dell’effetto in determinati contesti.\n\n\n\n91.6.2 La Scienza tra Incertezza e Riproducibilità\nLa scienza raramente offre certezze assolute. Come evidenziato dall’Open Science Collaboration, un singolo studio, sia esso originale o di replica, non è sufficiente a fornire una risposta definitiva. Solo replicazioni multiple e sistematiche possono distinguere effetti reali da errori casuali, offrendo una visione più affidabile di un fenomeno. Questo approccio richiede tempo e risorse, ma rappresenta il cuore del metodo scientifico.\n\n91.6.3 Psicologia e Altri Campi\nSebbene la crisi della replicazione sia stata ampiamente discussa in psicologia, problemi simili affliggono molte altre discipline scientifiche. Studi di replicazione hanno evidenziato risultati preoccupanti: in oncologia, meno della metà degli studi replicati ha prodotto risultati coerenti, con tassi di riproducibilità estremamente bassi in alcuni casi; nelle neuroscienze, i tentativi di replicare correlazioni cervello-comportamento hanno mostrato un altissimo tasso di insuccesso. Anche in discipline come l’economia e la filosofia sperimentale, pur registrando tassi di replicazione relativamente più elevati, permangono dubbi sulla selezione degli studi replicati e sulla rappresentatività dei risultati (Pennington, 2023).\nQuesti dati dimostrano che la problematica della replicazione non è esclusiva della psicologia, ma comune a diverse aree del sapere. Tuttavia, sollevano anche un interrogativo critico: è corretto parlare di “crisi” o si tratta piuttosto di una fase di trasformazione necessaria per migliorare il rigore e la trasparenza nella ricerca scientifica?",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#dibattito-sulla-natura-della-crisi",
    "href": "chapters/replication_crisis/01_crisis.html#dibattito-sulla-natura-della-crisi",
    "title": "91  La crisi della replicazione",
    "section": "\n91.7 Dibattito sulla Natura della Crisi",
    "text": "91.7 Dibattito sulla Natura della Crisi\nIl tema della crisi della replicazione ha suscitato un dibattito acceso e opinioni contrastanti all’interno della comunità scientifica:\n\nApproccio alle repliche: Alcuni ricercatori ritengono che le repliche esatte siano poco significative, preferendo le repliche concettuali che possano approfondire la comprensione di un fenomeno. Altri, invece, sostengono che solo repliche rigorose ed esatte siano in grado di verificare la robustezza di un effetto, garantendo maggiore affidabilità.\nInterpretazione dei dati dell’Open Science Collaboration (OSC): Il tasso di successo delle repliche riportato dall’OSC, pari al 36%, ha alimentato ulteriori discussioni. Alcuni attribuiscono questo risultato a differenze metodologiche tra studi originali e tentativi di replica, come campioni diversi o contesti modificati. Tuttavia, ricerche successive hanno smentito queste ipotesi, indicando che tali variazioni non spiegano interamente i bassi tassi di replicazione.\n\nInvece di considerare i fallimenti di replicazione come una crisi, molti studiosi li interpretano come un’opportunità per rafforzare la scienza. La replicazione, infatti, rappresenta un elemento fondamentale del metodo scientifico: permette di identificare i limiti di un fenomeno e di migliorare la comprensione delle condizioni in cui si manifesta. Ogni fallimento diventa, così, uno stimolo per il progresso.\nQuesta visione ha dato origine a un movimento noto come “rivoluzione della credibilità”, che punta a migliorare la qualità della ricerca attraverso trasparenza, autocorrezione e valorizzazione delle repliche. Progetti come il Loss of Confidence dimostrano che riconoscere i limiti e le incertezze degli studi precedenti non rappresenta una debolezza, ma un segno di integrità scientifica.\nIl passaggio dalla percezione di crisi a una rivoluzione della credibilità rappresenta un profondo cambiamento culturale nella comunità accademica. La scienza non è un processo statico, ma un percorso dinamico che evolve grazie al confronto critico e alla riflessione. In questa prospettiva, ogni fallimento nella replicazione non è un punto d’arrivo, ma un trampolino di lancio verso una conoscenza più affidabile e trasparente.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#cause-della-crisi",
    "href": "chapters/replication_crisis/01_crisis.html#cause-della-crisi",
    "title": "91  La crisi della replicazione",
    "section": "\n91.8 Cause della Crisi",
    "text": "91.8 Cause della Crisi\n\n91.8.1 Incentivi Accademici e la Dominanza della Quantità sulla Qualità\nPer comprendere a fondo le problematiche che affliggono il mondo della ricerca, è essenziale considerare il contesto lavorativo in cui operano i ricercatori. Sebbene spesso vengano idealizzati come figure obiettive e razionali, è fondamentale ricordare che sono anche esseri umani, soggetti a pressioni professionali, responsabilità economiche e ambizioni di carriera. Il loro lavoro è costantemente sottoposto a valutazione: oltre a gestire attività didattiche e amministrative, devono pubblicare articoli su riviste di prestigio e assicurarsi finanziamenti per sostenere i loro gruppi di ricerca. Questo sistema premia la quantità a discapito della qualità, favorendo una mentalità di “pubblica o perisci”.\nLa pressione a pubblicare incessantemente è una delle principali cause dei problemi che alimentano la crisi di replicazione nella scienza. La cultura del “publish or perish” spinge i ricercatori a produrre rapidamente risultati rilevanti, spesso a scapito della rigorosità metodologica e della riproducibilità (Gopalakrishna et al., 2022; Grimes et al., 2018).\nQuesta situazione genera un paradosso: ciò che favorisce la carriera individuale di uno scienziato non sempre coincide con gli interessi del progresso scientifico. Le motivazioni intrinseche di contribuire alla conoscenza vengono spesso offuscate da motivazioni estrinseche legate a indicatori di produttività accademica. Non sorprende, quindi, che oltre il 60% dei ricercatori individui questa pressione come una delle principali cause dei problemi legati alla replicazione e alla riproducibilità.\n\n91.8.2 Bias Cognitivi e Distorsioni nella Ricerca\nI bias cognitivi rappresentano un ulteriore ostacolo alla qualità della ricerca. Tra i principali si trovano:\n\n\nBias di conferma: la tendenza a cercare o interpretare informazioni che confermano le proprie ipotesi iniziali, trascurando dati contrari.\n\nApofenia: il riconoscimento di schemi in dati casuali, spesso combinato con una preferenza per risultati positivi.\n\nBias retrospettivo: la convinzione che un evento fosse prevedibile solo dopo che si è verificato, portando i ricercatori a presentare risultati in modo fuorviante.\n\nQuesti bias favoriscono la ricerca di risultati positivi a scapito di quelli nulli o contrari, contribuendo a creare un problema più grande: il bias di pubblicazione.\n\n91.8.3 Bias di Pubblicazione e il Problema dei “File Drawer”\nIl sistema di pubblicazione accademica incentiva risultati innovativi e positivi, spesso trascurando studi con risultati nulli o repliche. Questo bias, noto come file drawer problem, descrive la tendenza a relegare nei “cassetti” studi non statisticamente significativi, rendendoli inaccessibili e distorcendo la letteratura scientifica.\nIn psicologia, l’impatto di questo fenomeno è particolarmente grave. Studi hanno rilevato che oltre il 90% degli articoli in psicologia riporta risultati positivi, una percentuale notevolmente più alta rispetto ad altre discipline. Questo non solo crea una rappresentazione distorta della realtà, ma amplifica il rischio di undead theories, teorie prive di solide basi empiriche che continuano a dominare il dibattito scientifico.\n\n91.8.4 Pratiche di Ricerca Dubbiamente Etiche\nLa pressione a pubblicare ha portato all’emergere di comportamenti noti come Questionable Research Practices (QRPs). Tra questi:\n\n\nP-hacking: manipolazione dei dati o analisi fino a ottenere un p-value significativo (&lt; 0.05).\n\nHARKing (Hypothesizing After Results are Known): modificare l’ipotesi iniziale per adattarla ai risultati ottenuti.\n\nStopping opzionale: interrompere la raccolta dei dati quando si raggiunge un p-value desiderato.\n\nQueste pratiche, pur non essendo sempre considerate frodi, distorcono i risultati e compromettono la replicabilità degli studi, creando teorie difficili da falsificare.\n\n91.8.5 La Centralità dei Valori-p e la Crisi della Significatività Statistica\nIl valore-p, elemento centrale della metodologia scientifica basata sull’ipotesi nulla (Null Hypothesis Significance Testing), è diventato una “valuta” per la pubblicazione. Tuttavia, affidarsi esclusivamente ai valori-p presenta gravi limiti:\n\n\nParadosso di Lindley: con campioni di grandi dimensioni, valori-p vicini a 0.05 possono supportare l’ipotesi nulla invece di confutarla.\n\nDistorsioni da QRPs: l’utilizzo di pratiche discutibili può produrre falsi positivi statisticamente significativi.\n\nBenché alcuni studiosi abbiano proposto l’abbassamento della soglia di significatività statistica a 0.005 o l’integrazione dei valori-p con stime degli effetti e intervalli di confidenza, il punto centrale continua ad essere il fatto che l’enfasi dovrebbe spostarsi dai risultati statistici alla qualità metodologica degli studi.\nPer affrontare questi problemi, è necessario un cambiamento culturale e strutturale. La trasparenza, l’autocorrezione e l’adozione di pratiche come la preregistrazione degli studi possono aiutare a ridurre l’impatto dei bias e delle QRPs. Inoltre, incentivare repliche rigorose e promuovere un sistema di pubblicazione che premi la qualità rispetto alla quantità sono passi fondamentali per migliorare la credibilità della scienza.\n\n91.8.6 Campioni Troppo Piccoli\nUno dei fattori chiave che contribuiscono alla crisi della replicazione in psicologia è l’uso di campioni di dimensioni ridotte. Questo approccio ha permesso ai ricercatori di massimizzare la quantità di pubblicazioni a scapito della qualità e dell’affidabilità degli effetti rilevati. Higginson e Munafò (2016) sottolineano come questo fenomeno rappresenti una “selezione naturale della cattiva scienza”, dove incentivi strutturali premiano metodologie di ricerca poco rigorose.\nContrariamente a quanto si potrebbe pensare, ottenere un effetto significativo con un campione piccolo non garantisce che lo stesso effetto rimanga significativo con un campione più grande. Questo problema è strettamente legato alla potenza statistica, che rappresenta la probabilità, nel lungo periodo, di rifiutare correttamente l’ipotesi nulla quando l’ipotesi alternativa è vera. Una potenza statistica bassa comporta un’elevata probabilità di errori di Tipo II (falsi negativi) e, allo stesso tempo, riduce la probabilità che un risultato significativo rifletta un effetto reale.\nIn psicologia, la potenza statistica viene solitamente fissata a un minimo dell’80%, il che significa che, nel lungo termine, uno studio dovrebbe avere l’80% di possibilità di rilevare un effetto reale. Tuttavia, molti studi più datati raramente menzionano la potenza statistica, nonostante il concetto sia noto dagli anni ’30. Questo ha contribuito a generare una letteratura scientifica con effetti sovrastimati o poco affidabili.\nIn un approccio frequentista, per calcolare la potenza di uno studio, è necessario conoscere almeno due dei seguenti tre parametri: dimensione dell’effetto atteso, criterio di significatività e dimensione del campione pianificata. Per esempio, un ricercatore che si aspetta di trovare un effetto “medio” (Cohen’s d = 0.50) con un criterio di significatività di p &lt; .05 può determinare la dimensione del campione necessaria per garantire una potenza sufficiente. Tuttavia, molti studi psicologici hanno ignorato questo tipo di pianificazione, basandosi su campioni troppo piccoli per rilevare effetti affidabili.\nL’uso di campioni piccoli, combinato con pratiche discutibili di ricerca (Questionable Research Practices, QRPs) e bias di pubblicazione, ha portato a una letteratura scientifica piena di effetti inflazionati. Ad esempio, meta-analisi iniziali sul concetto di esaurimento dell’ego (ego depletion) stimavano un effetto medio (d = 0.62). Tuttavia, repliche successive hanno trovato effetti molto più piccoli, spesso inferiori a d = 0.10. Allo stesso modo, il progetto dell’Open Science Collaboration (2015) ha evidenziato che le dimensioni degli effetti nelle repliche erano, in media, dimezzate rispetto agli studi originali.\nCampioni di piccole dimensioni non solo riducono la probabilità di rilevare effetti reali, ma compromettono anche la credibilità dei risultati significativi. Una bassa potenza statistica mina l’obiettivo fondamentale della ricerca scientifica, limitando la capacità di trarre conclusioni solide e contribuendo alla crisi della replicazione. Per migliorare la qualità della scienza, è essenziale adottare pratiche di ricerca più rigorose, pianificando adeguatamente la dimensione del campione e garantendo una potenza statistica sufficiente.\n\n91.8.7 La Misurazione: Un Problema Sottovalutato\nOltre alle dimensioni campionarie inadeguate, la psicologia potrebbe soffrire di problemi legati alla misurazione. Per rispondere a domande scientifiche, i ricercatori devono definire e misurare con precisione il costrutto oggetto di indagine. Ad esempio, per investigare se una mentalità di crescita possa migliorare l’intelligenza, un ricercatore deve prima definire e poi misurare sia la mentalità che l’intelligenza. Tuttavia, la misurazione è un processo complesso e impegnativo.\nL’intelligenza è un costrutto latente, il che significa che, a differenza dell’altezza di una persona, non può essere osservata o misurata direttamente. Gli psicologi inferiscono l’intelligenza stimando il quoziente intellettivo (QI) di un individuo, basandosi sulle risposte a numerose domande di un test di intelligenza, adattate all’età del partecipante. Ma come possiamo sapere se il QI rappresenta un buon indicatore dell’intelligenza? È necessario valutare la validità di costrutto, definita come la capacità di una misura di comportarsi in modo coerente con le ipotesi teoriche (Cronbach e Meehl, 1955; Fink, 2010). Alcuni ricercatori hanno sostenuto che una spiegazione spesso trascurata della crisi della replicazione risieda nella scarsa validità di costrutto delle nostre misure (Lilienfeld e Strother, 2020; Loken e Gelman, 2017).\nPer evidenziare il problema della misurazione in psicologia, Flake e colleghi hanno condotto una revisione di articoli pubblicati in una rivista prestigiosa. La loro analisi ha mostrato che molte scale di misurazione utilizzate non avevano una chiara fonte dichiarata, mentre altre erano state sviluppate senza una documentazione adeguata. Inoltre, una parte significativa delle scale citate era stata modificata rispetto alla versione originale, rendendo sconosciute le loro proprietà psicometriche.\nGli autori hanno anche rilevato l’uso di Pratiche di Misurazione Discutibili (Questionable Measurement Practices, QMPs), che includono la mancata divulgazione di informazioni sulla validità delle misure quando questa non risulta soddisfacente. Questi problemi suggeriscono che molti costrutti psicologici non siano adeguatamente validati, un fattore che potrebbe contribuire alle difficoltà di replicazione degli studi.\nAltri ricercatori hanno argomentato che problemi di validità interna ed esterna possano contribuire alla crisi della replicazione (Fabrigar et al., 2020). La validità interna si riferisce a come uno studio stabilisce una relazione di causa-effetto tra le variabili indipendenti e dipendenti (Cook e Campbell, 1979). Fabrigar et al. suggeriscono che un tentativo di replicazione possa fallire se:\n\nLo studio originale ha sofferto di minacce alla validità che hanno causato un effetto spurio (alta validità interna nella replica).\nI ricercatori introducono elementi assenti nello studio originale (bassa validità interna nella replica).\n\nLa validità esterna riguarda la possibilità di generalizzare i risultati di uno studio ad altri contesti o popolazioni. Questo può influenzare le repliche se, ad esempio, la replica viene condotta su una popolazione diversa o se i materiali dello studio sono tradotti da un’altra lingua, causando incomprensioni nei partecipanti.\nPer sintetizzare questi problemi, Flake e Fried (2020) li definiscono “measurement schmeasurement”, espressione che descrive la mancanza di attenzione verso la validità delle misure nella scienza psicologica. Se le misure utilizzate in uno studio non sono valide, ne consegue che anche i risultati e le conclusioni tratte non possono essere considerati affidabili. Quando tali studi vengono replicati, potrebbero essere destinati al fallimento ancor prima di iniziare.\n\n91.8.8 La Novità a Scapito della Replicazione: Una Distorsione nella Ricerca\nL’enfasi eccessiva sui risultati innovativi e il valore attribuito alle scoperte significative stanno incentivando pratiche di ricerca distorte, favorendo la sovrarappresentazione di risultati positivi e una mancanza di rigore metodologico (Ferguson & Heene, 2012; Ware & Munafò, 2015).\nLa psicologia sperimentale, nata nel 1879 con il primo laboratorio fondato da Wilhelm Wundt, si trova oggi a fronteggiare una crisi di replicazione nonostante oltre un secolo di progresso scientifico. Una delle principali cause è la scarsa attenzione dedicata agli studi di replicazione, storicamente poco valorizzati e raramente premiati nelle scienze sociali.\nLa cultura accademica attuale privilegia la novità e i risultati positivi, relegando i risultati nulli e gli studi di replicazione a un ruolo marginale. Questo fenomeno riflette ciò che Antonakis (2017) definisce significosis – un’ossessione per i risultati significativi – e neofilia – un’eccessiva enfasi sulla novità. Già Sterling (1959) aveva messo in guardia contro il rischio che i ricercatori testassero ripetutamente un’ipotesi fino a ottenere, per puro caso, un risultato significativo, senza verificarlo attraverso replicazioni. In assenza di queste verifiche, interi ambiti di studio possono essere costruiti su un numero allarmante di affermazioni non supportate da dati solidi.\nQuesto squilibrio si riflette non solo nella letteratura scientifica, ma anche nei progetti di ricerca condotti dagli studenti. Le tesi di laurea in psicologia, spesso realizzate in autonomia, senza finanziamenti e con tempistiche ridotte, soffrono degli stessi problemi della ricerca accademica: campioni di piccole dimensioni, studi sottopotenziati e un’elevata probabilità di falsi positivi. Se pubblicati selettivamente, questi progetti rischiano di premiare la fortuna più della qualità scientifica.\nIniziative come il Collaborative Replications and Education Project (CREP) rappresentano un passo verso un cambiamento culturale. CREP incoraggia gli studenti a condurre studi di replicazione come parte del loro percorso formativo, promuovendo una scienza più collaborativa, rigorosa e orientata alla verifica dei risultati, contrastando così la prevalenza della novità fine a se stessa.\n\n91.8.9 La scienza non si autocorregge come dovrebbe\nUn principio cardine della scienza è l’autocorrezione, ma nella pratica accademica moderna, questo processo sembra spesso ostacolato da incentivi e preoccupazioni reputazionali. I ricercatori, pressati dalle scadenze per nuovi progetti o richieste di finanziamento, raramente dedicano il tempo necessario a rivedere e correggere i propri lavori passati. Questo mancato impegno rappresenta una delle spiegazioni della crisi di replicazione.\nUn esempio significativo è il Registered Replication Report dello studio di Srull e Wyer (1979), replicato da McCarthy et al. (2018). Lo studio originale aveva mostrato che il priming con stimoli aggressivi portava i partecipanti a interpretare un comportamento ambiguo come più ostile. Tuttavia, il tentativo di replicazione ha rilevato un effetto trascurabile. Una possibile spiegazione è che alcune statistiche dello studio originale fossero riportate in modo errato, un errore che, nonostante tutto, non è mai stato corretto. Similmente, altri casi documentano gravi discrepanze nei dati riportati in letteratura, come dimostrato da van der Zee et al. (2017) nel loro riesame di articoli del Cornell Food Lab, che ha rivelato oltre 150 incongruenze.\nLa microbiologa Elizabeth Bik ha inoltre evidenziato che la manipolazione di immagini scientifiche è diventata una forma emergente di cattiva condotta, volta a rendere i risultati più impressionanti o a mascherare dati problematici. Sebbene alcuni casi di manipolazione portino a ritrazioni o correzioni, il lavoro di revisione è spesso svolto da altri ricercatori come attività volontaria, suggerendo che la scienza sia più “eterocorrettiva” che autocorrettiva.\nNonostante le difficoltà, il processo di autocorrezione è fondamentale per il progresso scientifico. Vazire (2020) sostiene che il disagio provocato dalla revisione critica sia salutare e necessiti di una maggiore umiltà intellettuale da parte dei ricercatori. Questo include il riconoscimento pubblico delle limitazioni dei propri studi e, quando necessario, la pubblicazione di correzioni o dichiarazioni di perdita di fiducia nei risultati originali.\n\n91.8.10 La Scienza Chiusa come Ostacolo alla Replicazione\nUno degli ostacoli principali alla replicazione è la mancanza di trasparenza e dettaglio negli studi precedenti. In un sistema di “scienza chiusa,” in cui dati e metodi sono trattati come segreti industriali, ricreare esperimenti e verificare analisi diventa un’impresa ardua, se non impossibile. Questa opacità interessa molti aspetti della ricerca, dai materiali utilizzati ai dati raccolti, fino alle scelte analitiche effettuate durante lo studio.\nPratiche come la reportistica selettiva e la flessibilità non dichiarata nei metodi e nei dati compromettono l’integrità della scienza. La riluttanza a condividere dati e materiali, insieme al bias di pubblicazione che favorisce i risultati significativi rispetto a quelli nulli, amplifica ulteriormente il problema (Bruton et al., 2020; Nosek et al., 2012).\nUn esempio concreto riguarda le decisioni prese durante l’analisi dei dati, come la gestione dei valori anomali o le correzioni per analisi multiple. Queste scelte possono avere un impatto notevole sui risultati, ma se non vengono documentate in modo trasparente, altri ricercatori non saranno in grado di replicare gli stessi risultati. Questo problema è noto come il giardino dei sentieri che si biforcano (garden of forking paths), dove una serie di decisioni non esplicitate porta a risultati divergenti e difficili da verificare (Gelman & Loken, 2013).\n\n\n\n\n\n\nLo psicologo Paul Meehl condusse uno studio su un campione di cinquantasettamila studenti delle scuole superiori del Minnesota, indagando su variabili quali religione, abitudini nel tempo libero, ordine di nascita, numero di fratelli, piani post-diploma e numerosi altri aspetti (Meehl, 2012). Complessivamente, le diverse risposte dei partecipanti potevano essere combinate in 990 modi distinti, permettendo analisi del tipo: “Gli studenti appassionati di cucina hanno una maggiore probabilità di essere figli unici?” o “Gli studenti provenienti da famiglie battiste sono più inclini a partecipare a club politici scolastici?”. Meehl evidenziò che, analizzando i dati, il 92% di queste possibili combinazioni risultava in correlazioni statisticamente significative. Queste differenze, sebbene reali, presumibilmente derivano da cause multifattoriali e complesse.\nAndrew Gelman ha denominato questo fenomeno Il Giardino dei Sentieri che si Biforcano [Garden of Forking Paths; Gelman & Loken (2013)], riferendosi ai molteplici gradi di libertà a disposizione del ricercatore nell’analisi dei dati. Come nell’esempio di Meehl, è possibile esaminare le differenze intergruppo (se questo è l’oggetto di interesse) da molteplici prospettive. Con un campione sufficientemente ampio, alcune di queste differenze risulteranno “statisticamente significative”. Ciò indica che, in quello specifico campione, quel particolare aspetto dei dati è rilevante. Tuttavia, questa differenza “statisticamente significativa” non sarà necessariamente generalizzabile ad un altro campione, il quale presenterà le proprie idiosincrasie.\nIn altri termini, come sottolineato da Gelman & Loken (2013), l’approccio basato sul test dell’ipotesi nulla si limita a “descrivere il rumore”. Da un punto di vista teorico, simili esercizi statistici risultano privi di valore euristico e non contribuiscono in nessun modo all’avanzamento delle conoscenze sul fenomeno oggetto di studio.\nIn un’ottica di inferenza statistica, questo problema è riconducibile al concetto di “p-hacking” o “data dredging”, dove l’esplorazione esaustiva di molteplici ipotesi statistiche su un singolo set di dati può portare a falsi positivi e a una sovrastima della significatività statistica.\n\n\n\nLa soluzione è chiara: promuovere una cultura di apertura, rendendo dati e metodi accessibili. Nonostante i progressi tecnologici che facilitano la condivisione, questa pratica rimane poco diffusa. Sebbene esistano ragioni valide per non condividere i dati, come la tutela dell’anonimato dei partecipanti, tali motivazioni dovrebbero essere dichiarate in modo esplicito e rigoroso.\nQuesti ostacoli sottolineano l’urgenza di una trasformazione culturale all’interno della comunità scientifica, che favorisca trasparenza e collaborazione. Affrontare queste limitazioni strutturali è essenziale per superare la crisi di replicazione, permettendo alla scienza di avanzare in modo più affidabile e autoregolarsi nel tempo.\n\n91.8.11 La Probabilità Inversa\nOltre a questi fattori, alcuni studiosi sostengono che la radice della crisi della replicazione sia ancora più profonda e risieda nell’approccio statistico stesso, ampiamente adottato dalla comunità scientifica (Chivers, 2024; Gelman & Loken, 2014; Loken & Gelman, 2017). Questo punto di vista suggerisce che le difficoltà nella replicazione dei risultati non siano solo il prodotto di comportamenti individuali discutibili, ma derivino in larga parte da un’interpretazione e un’applicazione problematica dei metodi statistici.\nPer comprendere meglio questa questione, dobbiamo tornare alle basi della statistica inferenziale. L’approccio frequentista, dominante nella ricerca scientifica, si basa sulle probabilità di campionamento. Questo metodo, che risale a Jakob Bernoulli nel XVIII secolo, calcola la probabilità di osservare certi dati assumendo che una determinata ipotesi sia vera. Il famoso “p-value” è un esempio di questa logica: esso indica la probabilità di ottenere risultati estremi quanto o più estremi di quelli osservati, supponendo che l’ipotesi nulla sia vera.\nTuttavia, questo approccio ha un limite fondamentale: non ci dice direttamente quanto è probabile che la nostra ipotesi sia vera alla luce dei dati raccolti. In altre parole, non fornisce una “probabilità inferenziale”, cioè la probabilità che l’ipotesi sia corretta in base ai risultati ottenuti. Qui entra in gioco l’approccio bayesiano. Il teorema di Bayes offre un metodo per calcolare proprio questa probabilità inferenziale. L’approccio bayesiano tiene conto non solo dei dati osservati, ma anche delle conoscenze pregresse (le “prior”) relative all’ipotesi in esame.\nLa differenza tra questi due approcci è cruciale. Mentre il p-value ci dice quanto sono improbabili i nostri dati se l’ipotesi nulla è vera, l’approccio bayesiano ci fornisce la probabilità che la nostra ipotesi sia vera alla luce dei dati raccolti e delle conoscenze precedenti.\n\n91.8.12 Implicazioni per la Pratica Scientifica\nQuesta distinzione ha implicazioni profonde per la pratica scientifica. L’uso esclusivo dell’approccio frequentista può portare a sovrastimare la forza delle evidenze a favore di un’ipotesi, specialmente quando si lavora con campioni piccoli o si conducono molti test statistici, come spesso accade in psicologia.\nAlcune soluzioni proposte per affrontare la crisi della replicazione includono:\n\nAbbassare la soglia di significatività statistica, rendendo più difficile dichiarare un risultato “significativo”.\nRichiedere la preregistrazione delle ipotesi per prevenire l’HARKing (Hypothesizing After Results are Known).\nFar sì che le riviste accettino gli articoli basandosi sui metodi piuttosto che sui risultati, per evitare il bias verso la pubblicazione di risultati solo “positivi” o “nuovi”.\n\nTuttavia, queste soluzioni, pur utili, non affrontano il problema fondamentale dell’interpretazione delle evidenze statistiche. L’adozione di un approccio bayesiano offre una soluzione più radicale, fornendo un quadro più completo e realistico della forza delle evidenze a favore o contro un’ipotesi scientifica.\n\n91.8.12.1 Guardare i Dati\nConsideriamo una simulazione, ispirata da Lakens (2015), che illustra come una pratica apparentemente innocua – osservare i risultati man mano che vengono raccolti nell’approccio frequentista – possa avere conseguenze significative sulle conclusioni di uno studio. In particolare, questa pratica può influire sulla probabilità di ottenere un risultato statisticamente significativo.\nNella simulazione seguente, due campioni casuali vengono estratti dalla stessa popolazione normale di partenza. Di conseguenza, l’“ipotesi nulla” è vera: non c’è differenza tra le medie delle popolazioni. Tuttavia, a causa della variabilità campionaria, il p-valore risulta fortemente influenzato da ogni singola osservazione aggiunta al campione.\n\nsimulate_t_tests &lt;- function(seed, max_sample_size, mu = 0, sigma = 1) {\n  set.seed(seed)\n\n  # Intervallo di grandezza campionaria\n  sample_sizes &lt;- seq(2, max_sample_size, by = 2)\n  p_values &lt;- numeric(length(sample_sizes))\n\n  # Genera due campioni grandi iniziali da una distribuzione normale\n  full_sample1 &lt;- rnorm(max_sample_size, mean = mu, sd = sigma)\n  full_sample2 &lt;- rnorm(max_sample_size, mean = mu, sd = sigma)\n\n  # Simulazione\n  for (i in seq_along(sample_sizes)) {\n    n &lt;- sample_sizes[i]\n\n    # Estrai sottoinsiemi incrementali dai campioni completi\n    sample1 &lt;- full_sample1[1:n]\n    sample2 &lt;- full_sample2[1:n]\n\n    # Esegui il t-test per il confronto delle medie di due gruppi indipendenti\n    t_test &lt;- t.test(sample1, sample2, var.equal = TRUE)\n    p_values[i] &lt;- t_test$p.value\n  }\n\n  # Crea il grafico del p-valore in funzione della grandezza campionaria\n  plot(\n    sample_sizes, p_values, type = \"l\", col = \"#b97c7c\",\n    xlab = \"Grandezza Campionaria\", ylab = \"P-valore\",\n    main = \"P-valore in funzione della grandezza campionaria\"\n  )\n  abline(h = 0.05, col = \"#8f2727\", lty = 2, lwd = 1.5)\n  legend(\"topright\", legend = \"Significatività a 0.05\", col = \"#8f2727\", lty = 2, cex = 0.8)\n}\n\nNelle due simulazioni seguenti, osserviamo come il p-valore cambi progressivamente aumentando la dimensione dei campioni casuali da \\(n = 2\\) a \\(n = 300\\). È evidente come il p-valore vari drasticamente con l’aggiunta di nuove osservazioni ai campioni. Inoltre, in alcune configurazioni, il p-valore può scendere al di sotto della soglia critica di 0.05 per puro caso. Se un ricercatore interrompesse la raccolta dei dati in quel momento, otterrebbe un risultato “statisticamente significativo”, pur avendo campioni estratti dalla stessa popolazione.\n\nsimulate_t_tests(seed = 1234, max_sample_size = 300, mu = 0, sigma = 2)\nsimulate_t_tests(seed = 2, max_sample_size = 300, mu = 0, sigma = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuesta simulazione mette in evidenza una limitazione fondamentale dell’approccio frequentista: ogni test statistico considera esclusivamente i dati del campione corrente, ignorando le conoscenze accumulate in precedenza. Questo rende il processo decisionale estremamente volatile, poiché, teoricamente, ad ogni nuovo studio si “dimentica” tutta l’informazione derivante dagli studi precedenti.\n\n91.8.12.2 Analisi Bayesiana\nL’approccio bayesiano offre una soluzione elegante a questo problema. Nel framework bayesiano, la distribuzione a posteriori (cioè, la nostra convinzione aggiornata dopo aver osservato i dati) bilancia sempre l’informazione a priori (ciò che sapevamo prima dell’esperimento) con la verosimiglianza (ciò che i dati ci dicono). Questo equilibrio è particolarmente prezioso quando i dati sono deboli o contengono molto rumore, come nel caso dei dati della simulazione che stiamo discutendo. In tali situazioni, l’informazione a priori assume un ruolo più rilevante, impedendo conclusioni affrettate basate su dati poco informativi.\nPer illustrare questa differenza, consideriamo l’analisi bayesiana dei dati simulati in precedenza. Se questi dati vengono analizzati con l’approccio frequentista, forniscono un risultato “statisticamente significativo”, suggerendo una differenza tra i due gruppi.\nTuttavia, analizzando gli stessi dati con un approccio bayesiano, otteniamo un intervallo di credibilità al 95% compreso tra -0.52 e 1.12. Poiché questo intervallo include lo zero, possiamo affermare, con un livello di certezza soggettiva del 95%, che non c’è una differenza sostanziale tra le medie delle due popolazioni da cui sono stati estratti i campioni.\nQuesta discrepanza nei risultati evidenzia un punto cruciale: l’approccio bayesiano è più resistente ai falsi positivi in presenza di dati rumorosi o campioni piccoli. Invece di forzare una decisione binaria (significativo/non significativo) basata su una soglia arbitraria, l’analisi bayesiana fornisce una rappresentazione più sfumata e realistica dell’incertezza associata alle nostre conclusioni.\nInoltre, l’approccio bayesiano offre il vantaggio di essere cumulativo: ogni nuovo studio non parte da zero, ma incorpora naturalmente le conoscenze precedenti attraverso la distribuzione a priori.\n\n# Imposta il seme per la riproducibilità\nset.seed(12)\n\n# Parametri della distribuzione normale\nmu &lt;- 0\nsigma &lt;- 2\nmax_sample_size &lt;- 50\n\n# Genera due campioni indipendenti\nfull_sample1 &lt;- rnorm(max_sample_size, mean = mu, sd = sigma)\nfull_sample2 &lt;- rnorm(max_sample_size, mean = mu, sd = sigma)\n\n\n# Prepara i dati per Stan\nstan_data &lt;- list(\n  N1 = length(full_sample1),\n  N2 = length(full_sample2),\n  y1 = full_sample1,\n  y2 = full_sample2\n)\n\n# Visualizza i dati preparati\nprint(stan_data)\n#&gt; $N1\n#&gt; [1] 50\n#&gt; \n#&gt; $N2\n#&gt; [1] 50\n#&gt; \n#&gt; $y1\n#&gt;  [1] -2.9611  3.1543 -1.9135 -1.8400 -3.9953 -0.5446 -0.6307 -1.2565 -0.2129\n#&gt; [10]  0.8560 -1.5554 -2.5878 -1.5591  0.0239 -0.3048 -1.4069  2.3778  0.6810\n#&gt; [19]  1.0139 -0.5866  0.4473  4.0144  2.0240 -0.6049 -2.0505 -0.5348 -0.3982\n#&gt; [28]  0.2622  0.2916  0.7241  1.3480  4.1441 -1.0821 -2.1410 -0.7449 -0.9703\n#&gt; [37]  0.5496 -0.9590  1.5962 -2.0089  0.2100 -2.3120  1.1563 -3.1913 -0.6170\n#&gt; [46]  0.8989 -1.9541  0.3800  1.4629 -0.9852\n#&gt; \n#&gt; $y2\n#&gt;  [1] -0.085370 -0.225341  0.913654  4.040670 -2.101780  1.469304  1.078499\n#&gt;  [8] -2.628546 -0.500077  0.628409  0.813093  1.988841  1.711537  0.394258\n#&gt; [15]  1.668650  1.693580  3.908211 -4.298520  1.942241  2.290123 -1.050801\n#&gt; [22]  0.500640 -0.858813 -0.365039 -0.206621 -1.267676 -2.542108 -0.767901\n#&gt; [29]  1.033512 -0.355937  0.008516 -2.548119 -0.404221  2.328932 -0.046759\n#&gt; [36]  1.794313 -0.353449  2.227418 -1.083778 -1.926797  0.752897 -1.969348\n#&gt; [43]  1.795119  0.258525  2.067406 -0.684579  0.904563 -1.389476 -0.478027\n#&gt; [50] -2.014598\n\n\n# Path to the Stan file\nstan_file &lt;- here::here(\"stan\", \"two_means_diff.stan\")\n\n# Create a CmdStanModel object\nmod &lt;- cmdstan_model(stan_file)\nmod$code() # Stampa il codice del modello\n#&gt;  [1] \"data {\"                                                                \n#&gt;  [2] \"  int&lt;lower=0&gt; N1; // Numero di osservazioni nel gruppo 1\"             \n#&gt;  [3] \"  int&lt;lower=0&gt; N2; // Numero di osservazioni nel gruppo 2\"             \n#&gt;  [4] \"  vector[N1] y1; // Dati del gruppo 1\"                                 \n#&gt;  [5] \"  vector[N2] y2; // Dati del gruppo 2\"                                 \n#&gt;  [6] \"}\"                                                                     \n#&gt;  [7] \"parameters {\"                                                          \n#&gt;  [8] \"  real mu1; // Media del gruppo 1\"                                     \n#&gt;  [9] \"  real delta; // Differenza tra le medie\"                              \n#&gt; [10] \"  real&lt;lower=0&gt; sigma; // Deviazione standard comune\"                  \n#&gt; [11] \"  real&lt;lower=0&gt; nu; // Gradi di libertà per la distribuzione t\"        \n#&gt; [12] \"}\"                                                                     \n#&gt; [13] \"transformed parameters {\"                                              \n#&gt; [14] \"  real mu2; // Media del gruppo 2\"                                     \n#&gt; [15] \"  mu2 = mu1 + delta;\"                                                  \n#&gt; [16] \"}\"                                                                     \n#&gt; [17] \"model {\"                                                               \n#&gt; [18] \"  // Priori\"                                                           \n#&gt; [19] \"  mu1 ~ normal(0, 5);\"                                                 \n#&gt; [20] \"  delta ~ normal(0, 2); // Priore su delta\"                            \n#&gt; [21] \"  sigma ~ cauchy(0, 5);\"                                               \n#&gt; [22] \"  nu ~ gamma(2, 0.1); // Priore sulla t-student\"                       \n#&gt; [23] \"  \"                                                                    \n#&gt; [24] \"  // Verosimiglianza\"                                                  \n#&gt; [25] \"  y1 ~ student_t(nu, mu1, sigma);\"                                     \n#&gt; [26] \"  y2 ~ student_t(nu, mu2, sigma);\"                                     \n#&gt; [27] \"}\"                                                                     \n#&gt; [28] \"generated quantities {\"                                                \n#&gt; [29] \"  real diff; // Differenza tra le medie (alias di delta per chiarezza)\"\n#&gt; [30] \"  diff = delta;\"                                                       \n#&gt; [31] \"}\"\n\nEsegui il campionamento:\n\nfit &lt;- mod$sample(\n  data = stan_data,\n  seed = 123,\n  chains = 4,\n  iter_sampling = 2000,\n  iter_warmup = 1000,\n  show_messages = FALSE\n)\n\nRiassumi i risultati per mu1, mu2 e delta:\n\nfit_summary &lt;- fit$summary(variables = c(\"mu1\", \"mu2\", \"delta\"))\nprint(fit_summary)\n#&gt; # A tibble: 3 × 10\n#&gt;   variable   mean median    sd   mad      q5    q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 mu1      -0.313 -0.312 0.241 0.238 -0.707  0.0818  1.00    5378.    5491.\n#&gt; 2 mu2       0.164  0.166 0.246 0.248 -0.235  0.568   1.00    9428.    6234.\n#&gt; 3 delta     0.477  0.474 0.341 0.344 -0.0887 1.04    1.00    5155.    5260.\n\nEstrai i campioni di delta:\n\ndelta_samples &lt;- fit$draws(variables = \"delta\", format = \"matrix\")[, 1]\n\nDisegna la distribuzione a posteriori di delta:\n\ndelta_df &lt;- data.frame(delta = delta_samples)\n\nggplot(delta_df, aes(x = delta)) +\n  geom_histogram(aes(y = ..density..), bins = 30, fill = \"#b97c7c\", alpha = 0.75) +\n  geom_vline(\n    xintercept = mean(delta_samples),\n    linetype = \"dashed\",\n    linewidth = 1.2,\n    label = paste(\"Mean:\", round(mean(delta_samples), 2))\n  ) +\n  labs(\n    x = \"delta\",\n    y = \"Density\",\n    title = \"Posterior distribution of delta\"\n  ) \n\n\n\n\n\n\n\nPuoi calcolare l’intervallo di credibilità usando per un intervallo al 95%:\n\nquantile(delta_samples, probs = c(0.025, 0.975))\n#&gt;    2.5%   97.5% \n#&gt; -0.1872  1.1553\n\n\n91.8.12.3 Garbage In, Garbage Out\nLa natura della statistica frequentista impone di prendere una decisione dicotomica: o si rifiuta l’ipotesi nulla o non la si rifiuta. Ciò implica che o esiste un effetto reale, oppure non esiste. Con un campione abbastanza grande, è inevitabile trovare qualche effetto, anche se di minima entità.\nUn approccio bayesiano, invece, permette di stimare la dimensione dell’effetto e di fornire una distribuzione di probabilità. Una distribuzione di probabilità è una rappresentazione grafica delle diverse possibilità che potrebbero verificarsi. In questo contesto, si tratta della “probabilità inversa”, ovvero della plausibilità dell’ipotesi alla luce dei dati osservati e delle conoscenze pregresse. Qui, il parametro \\(\\delta\\) rappresenta la differenza tra le due medie ed è il parametro di interesse. Le credenze precedenti su \\(\\delta\\) sono espresse tramite una distribuzione a priori: in questo caso, una distribuzione Normale centrata su 0 con una deviazione standard di 2. La distribuzione a posteriori rappresenta la nostra conoscenza aggiornata su \\(\\delta\\) dopo l’aggiornamento bayesiano. Il parametro \\(\\delta\\) è la nostra ipotesi sulla differenza tra le due medie, e l’inferenza bayesiana riguarda il cambiamento della nostra credenza dopo aver osservato i dati.\nL’approccio frequentista, al contrario, produce una decisione dicotomica che non modifica la nostra concezione dell’ipotesi dopo aver osservato i dati. Assume una determinata ipotesi come vera e verifica se i dati sono coerenti con essa. Tramite il concetto binario di “significatività statistica”, non si modificano le ipotesi di interesse, ma si accettano o si rifiutano le ipotesi nulle.\nSebbene l’approccio frequentista sia spesso considerato “ingenuo” da molti ricercatori, adottare l’approccio bayesiano non rappresenta una soluzione miracolosa ai problemi della scienza contemporanea. Risolve alcuni problemi, ma non altri. In particolare, non affronta la questione degli incentivi accademici che favoriscono la pubblicazione di un elevato numero di articoli, indipendentemente dalla loro qualità. Un principio fondamentale della ricerca è “Garbage in, garbage out”. Se i dati derivano da un disegno di ricerca fallace o poco creativo, se la ricerca non ha un solido fondamento teorico capace di avanzare le nostre conoscenze, o se la qualità delle misurazioni è insufficiente, i dati raccolti sono puro rumore. Nessun metodo statistico, nemmeno quello bayesiano, può trasformare la spazzatura in oro.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#esercizi",
    "href": "chapters/replication_crisis/01_crisis.html#esercizi",
    "title": "91  La crisi della replicazione",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nEsistono numerosi esempi di ricerche che non riescono a essere replicate (posso citare anche uno studio di replicazione che ho condotto io stesso: Caudek et al. (2017)). Un recente caso emblematico è rappresentato dallo studio di Karataş & Cutright (2023) e dal successivo tentativo di replicazione condotto da Moore et al. (2024). Analizzando le quattro principali argomentazioni sollevate da Gelman & Brown (2024) per criticare lo studio di Aungle & Langer (2023), si offra un’interpretazione del perché lo studio di Karataş & Cutright (2023) non sia stato replicato con successo.\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\n1) Sulla “Crisi della Replicazione” in Psicologia\nChe cosa si intende quando si parla di “crisi della replicazione” in psicologia?\n\n\nA. La difficoltà di molti laboratori nel reperire fondi per la ricerca.\n\n\nB. L’incapacità o la grave difficoltà di replicare, con risultati simili, una parte consistente degli studi pubblicati.\n\n\nC. La tendenza di alcuni scienziati a pubblicare risultati simili ad altri per sfruttare la loro notorietà.\n\n\nD. Lo scarso interesse degli editori di riviste nel pubblicare studi teorici.\n\n\nE. La mancanza di strumenti statistici adeguati per l’analisi dei dati qualitativi.\n\n2) Cosa significa “fallimento della replicazione”?\nQuale delle seguenti opzioni descrive correttamente il “fallimento della replicazione”?\n\n\nA. Non riuscire a pubblicare uno studio su una rivista ad alto impatto.\n\n\nB. Non riuscire a confermare la robustezza metodologica dello studio originale in sede di peer-review.\n\n\nC. Riportare risultati che confermano un’ipotesi già discussa in letteratura.\n\n\nD. Non ottenere, con procedure simili e campioni simili, risultati paragonabili a quelli dello studio originale.\n\n\nE. Non riuscire a reclutare un numero sufficiente di partecipanti in una nuova ricerca.\n\n3) Quale studio scatenò polemiche sulla precognizione?\nNel 2011, un autore pubblicò uno studio che sembrava dimostrare capacità “paranormali” nei partecipanti, scatenando polemiche e dubbi. Chi fu?\n\n\nA. Diederik Stapel, che usò dati inventati.\n\n\nB. John Ioannidis, autore di “Why Most Published Research Findings Are False”.\n\n\nC. Daryl Bem, con l’articolo “Feeling the Future” sulle facoltà precognitive.\n\n\nD. Brian Wansink, con studi su etichette “attraenti” delle verdure.\n\n\nE. Daniel Kahneman, con esperimenti sui bias cognitivi e di giudizio.\n\n4) Cosa si intende per “p-hacking”?\nLa pratica denominata p-hacking (nell’ambito della crisi di replicazione) consiste nel:\n\n\nA. Interrompere la raccolta dati nel momento in cui si ottiene un risultato in linea con l’ipotesi.\n\n\nB. Manipolare, in maniera fraudolenta, immagini o grafici.\n\n\nC. Tradurre erroneamente i questionari in più lingue, alterando i risultati.\n\n\nD. Utilizzare molteplici analisi e combinazioni di variabili fino a ottenere un valore-(p) inferiore a 0.05.\n\n\nE. Avere più autori su uno stesso manoscritto per dividerne la responsabilità.\n\n5) Qual è il tasso di replicazione emerso dal “Reproducibility Project: Psychology” (2015)?\nSecondo i dati dell’Open Science Collaboration (2015), approssimativamente quanti studi di psicologia replicarono con successo (ottenendo risultati “significativi” simili agli originali)?\n\n\nA. Circa il 36%.\n\n\nB. Circa il 65%.\n\n\nC. Quasi il 90%.\n\n\nD. Nessuno studio è stato replicato con successo.\n\n\nE. Circa il 10%.\n\n6) Cosa sono le Questionable Research Practices (QRPs)?\nQuale definizione descrive meglio le “QRPs” (Questionable Research Practices)?\n\n\nA. Pratiche statistiche avanzate che aumentano la robustezza dei risultati.\n\n\nB. Metodologie di campionamento probabilistico trasparenti e preregistrate.\n\n\nC. Pratiche di ricerca discutibili, come “optional stopping” e selezione post-hoc di ipotesi, che influiscono negativamente sull’integrità scientifica.\n\n\nD. Strumenti di meta-analisi per combinare risultati di studi diversi.\n\n\nE. Procedure di controllo etico per proteggere i diritti dei partecipanti.\n\n7) Perché i campioni troppo piccoli sono considerati problematici?\nNella letteratura sulla crisi di replicazione, perché avere campioni di dimensione ridotta costituisce una criticità?\n\n\nA. Perché rendono più facile l’analisi statistica, riducendo la possibilità di trovare p &lt; .05.\n\n\nB. Perché riducono la potenza statistica, aumentando il rischio di sovrastimare effetti e di ottenere risultati non replicabili.\n\n\nC. Perché il costo di reclutamento è troppo basso, compromettendo l’interesse dei revisori.\n\n\nD. Perché obbligano a utilizzare necessariamente test non-parametrici.\n\n\nE. Perché la psicologia preferisce dataset qualitativi, non quantitativi.\n\n8) Che cosa significa “bias di pubblicazione”?\nCon l’espressione “bias di pubblicazione” (o publication bias), ci si riferisce a:\n\n\nA. La tendenza dei revisori a selezionare articoli soltanto se ben scritti.\n\n\nB. L’inclinazione delle riviste di settore a pubblicare preferibilmente i lavori dei ricercatori senior.\n\n\nC. La propensione alla pubblicazione di studi con risultati innovativi e statisticamente positivi, trascurando invece studi con risultati nulli.\n\n\nD. L’obbligo di pubblicare i protocolli di studio in forma open.\n\n\nE. Una norma deontologica che impone di nascondere i metodi inediti per evitare furti di idee.\n\n9) Quale scopo principale ha il movimento dell’Open Science?\nNel contesto della crisi di replicazione, qual è l’obiettivo cardine promosso dal movimento per la Scienza Aperta (Open Science)?\n\n\nA. Aumentare il controllo sugli studi, rendendo segreti i metodi di analisi.\n\n\nB. Pubblicare soltanto studi che abbiano ottenuto finanziamenti pubblici.\n\n\nC. Rendere i dati, i materiali e le procedure il più possibile trasparenti e accessibili, favorendo le repliche e la verifica indipendente.\n\n\nD. Abolire completamente l’uso di test statistici e valori-p.\n\n\nE. Prediligere esclusivamente studi qualitativi in ambito psicologico.\n\n10) Perché la scienza non si autocorregge come si afferma?\nSecondo quanto discusso, come mai la scienza non risulta sempre “autocorrettiva” nella pratica reale?\n\n\nA. Perché gli editori impongono di inserire errori per testare la capacità dei revisori di individuarli.\n\n\nB. Perché è molto costoso usare software di statistica adeguati.\n\n\nC. Perché la pressione a pubblicare risultati nuovi prevale sull’attenzione a errori e correzioni; i ricercatori non hanno incentivi sufficienti a pubblicare smentite, ritrazioni o correzioni.\n\n\nD. Perché l’uso della statistica bayesiana ha complicato la procedura di revisione.\n\n\nE. Perché tutti gli studi di psicologia sono in realtà corretti al 99%.\n\n\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\n\n\nB\n\n\nD\n\n\nC\n\n\nD\n\n\nA\n\n\nC\n\n\nB\n\n\nC\n\n\nC\n\nC\n\nLa crisi della replicazione in psicologia è il risultato di una combinazione di fattori sistemici e metodologici:\n\n\nIncentivi distorti (“publish or perish”), che spingono a privilegiare la novità rispetto alla qualità e alla rigorosità delle ricerche.\n\n\nPratiche di ricerca discutibili (QRPs), tra cui p-hacking e optional stopping, che producono un numero elevato di falsi positivi.\n\n\nBias di pubblicazione, che favorisce i risultati statistici significativi a scapito di studi con esiti non significativi o repliche.\n\n\nBassa potenza statistica e campioni di piccole dimensioni, che gonfiano o sovrastimano l’effetto di fenomeni psicologici.\n\n\nScarsa trasparenza e accessibilità (scienza “chiusa”), che rende difficile verificare e replicare i risultati originari.\n\nNonostante i numeri allarmanti riportati da studi di vasta portata (come il Reproducibility Project), questa situazione può essere vista come un’opportunità di “rivoluzione della credibilità”:\n\nSi stanno diffondendo pratiche di Open Science, con la condivisione di dati, protocolli, codici e materiali, favorendo così la replica e la validazione indipendente.\n\nLa cultura della replicazione viene valorizzata, incentivando studi più rigorosi e focalizzati sulla robustezza degli effetti.\n\nL’approccio statistico tradizionale (frequentista) è posto in discussione, evidenziando la possibilità di integrare o sostituire i test di ipotesi nulla con metodologie più robuste, tra cui quelle bayesiane, le analisi preregistrate e la valorizzazione di stime degli effetti con intervalli di credibilità.\n\nLa crisi di replicazione, quindi, non deve essere intesa come un fallimento totale, bensì come un momento critico che ha avviato un rinnovamento, mirato a rendere la scienza psicologica (e altre discipline) più rigorosa, trasparente e affidabile.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/replication_crisis/01_crisis.html#informazioni-sullambiente-di-sviluppo",
    "title": "91  La crisi della replicazione",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] posterior_1.6.1  cmdstanr_0.9.0   thematic_0.1.7   MetBrewer_0.2.0 \n#&gt;  [5] ggokabeito_0.1.0 see_0.11.0       gridExtra_2.3    patchwork_1.3.0 \n#&gt;  [9] bayesplot_1.13.0 psych_2.5.3      scales_1.4.0     markdown_2.0    \n#&gt; [13] knitr_1.50       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   \n#&gt; [17] dplyr_1.1.4      purrr_1.0.4      readr_2.1.5      tidyr_1.3.1     \n#&gt; [21] tibble_3.3.0     ggplot2_3.5.2    tidyverse_2.0.0  rio_1.2.3       \n#&gt; [25] here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6         tensorA_0.36.2.1     xfun_0.52           \n#&gt;  [4] htmlwidgets_1.6.4    processx_3.8.6       lattice_0.22-7      \n#&gt;  [7] tzdb_0.5.0           vctrs_0.6.5          tools_4.5.0         \n#&gt; [10] ps_1.9.1             generics_0.1.4       parallel_4.5.0      \n#&gt; [13] pacman_0.5.1         pkgconfig_2.0.3      data.table_1.17.6   \n#&gt; [16] checkmate_2.3.2      RColorBrewer_1.1-3   distributional_0.5.0\n#&gt; [19] lifecycle_1.0.4      compiler_4.5.0       farver_2.1.2        \n#&gt; [22] mnormt_2.1.1         htmltools_0.5.8.1    yaml_2.3.10         \n#&gt; [25] pillar_1.10.2        abind_1.4-8          nlme_3.1-168        \n#&gt; [28] tidyselect_1.2.1     digest_0.6.37        stringi_1.8.7       \n#&gt; [31] labeling_0.4.3       rprojroot_2.0.4      fastmap_1.2.0       \n#&gt; [34] grid_4.5.0           cli_3.6.5            magrittr_2.0.3      \n#&gt; [37] utf8_1.2.6           withr_3.0.2          backports_1.5.0     \n#&gt; [40] timechange_0.3.0     rmarkdown_2.29       matrixStats_1.5.0   \n#&gt; [43] hms_1.1.3            evaluate_1.0.4       rlang_1.1.6         \n#&gt; [46] glue_1.8.0           rstudioapi_0.17.1    jsonlite_2.0.0      \n#&gt; [49] R6_2.6.1",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#bibliografia",
    "href": "chapters/replication_crisis/01_crisis.html#bibliografia",
    "title": "91  La crisi della replicazione",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAungle, P., & Langer, E. (2023). Physical healing as a function of perceived time. Scientific Reports, 13(1), 22432.\n\n\nBaker, M. (2016). 1,500 scientists lift the lid on reproducibility. Nature, 533(7604).\n\n\nBargh, J. A., Chen, M., & Burrows, L. (1996). Automaticity of social behavior: Direct effects of trait construct and stereotype activation on action. Journal of Personality and Social Psychology, 71(2), 230–244.\n\n\nBem, D. J. (2011). Feeling the future: experimental evidence for anomalous retroactive influences on cognition and affect. Journal of Personality and Social Psychology, 100(3), 407–425.\n\n\nBruton, S. V., Medlin, M., Brown, M., & Sacco, D. F. (2020). Personal motivations and systemic incentives: Scientists on questionable research practices. Science and Engineering Ethics, 26(3), 1531–1547.\n\n\nCaudek, C., Lorenzino, M., & Liperoti, R. (2017). Delta plots do not reveal response inhibition in lying. Consciousness and Cognition, 55, 232–244.\n\n\nChivers, T. (2024). Everything is Predictable: How Bayesian Statistics Explain Our World. Simon; Schuster.\n\n\nCollaboration, O. S. (2015). Estimating the reproducibility of psychological science. Science, 349(6251), aac4716.\n\n\nFerguson, C. J., & Heene, M. (2012). A vast graveyard of undead theories: Publication bias and psychological science’s aversion to the null. Perspectives on Psychological Science, 7(6), 555–561.\n\n\nGelman, A., & Brown, N. J. (2024). How statistical challenges and misreadings of the literature combine to produce unreplicable science: An example from psychology.\n\n\nGelman, A., & Loken, E. (2013). The garden of forking paths: Why multiple comparisons can be a problem, even when there is no «fishing expedition» or «p-hacking» and the research hypothesis was posited ahead of time. Department of Statistics, Columbia University, 348(1-17), 3.\n\n\nGelman, A., & Loken, E. (2014). The statistical crisis in science. American scientist, 102(6), 460–465.\n\n\nGopalakrishna, G., Ter Riet, G., Vink, G., Stoop, I., Wicherts, J. M., & Bouter, L. M. (2022). Prevalence of questionable research practices, research misconduct and their potential explanatory factors: A survey among academic researchers in The Netherlands. PloS one, 17(2), e0263023.\n\n\nGrimes, D. R., Bauch, C. T., & Ioannidis, J. P. (2018). Modelling science trustworthiness under publish or perish pressure. Royal Society open science, 5(1), 171511.\n\n\nIoannidis, J. P. (2005). Why most published research findings are false. PLoS medicine, 2(8), e124.\n\n\nKarataş, M., & Cutright, K. M. (2023). Thinking about God increases acceptance of artificial intelligence in decision-making. Proceedings of the National Academy of Sciences, 120(33), e2218961120.\n\n\nLakens, D. (2015). On the challenges of drawing conclusions from p-values just below 0.05. PeerJ, 3, e1142.\n\n\nLeys, R. (2024). Anatomy of a Train Wreck: The Rise and Fall of Priming Research. University of Chicago Press.\n\n\nLoken, E., & Gelman, A. (2017). Measurement Error and the Replication Crisis. Science, 355(6325), 584–585.\n\n\nMeehl, P. E. (2012). Why summaries of research on psychological theories are often uninterpretable. In Improving inquiry in social science (pp. 13–59). Routledge.\n\n\nMoore, D. A., Schroeder, J., Bailey, E. R., Gershon, R., Moore, J. E., & Simmons, J. P. (2024). Does thinking about God increase acceptance of artificial intelligence in decision-making? Proceedings of the National Academy of Sciences, 121(31), e2402315121.\n\n\nNosek, B. A., Spies, J. R., & Motyl, M. (2012). Scientific utopia: II. Restructuring incentives and practices to promote truth over publishability. Perspectives on Psychological Science, 7(6), 615–631.\n\n\nPennington, C. (2023). A student’s guide to open science: Using the replication crisis to reform psychology. McGraw-Hill Education (UK).\n\n\nWare, J. J., & Munafò, M. R. (2015). Significance chasing in research practice: causes, consequences and possible solutions. Addiction, 110(1), 4–8.\n\n\nYouyou, W., Yang, Y., & Uzzi, B. (2023). A discipline-wide investigation of the replicability of Psychology papers over the past two decades. Proceedings of the National Academy of Sciences, 120(6), e2208863120.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html",
    "title": "92  Limiti dell’inferenza frequentista",
    "section": "",
    "text": "Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nIn questa sezione della dispensa, abbiamo approfondito il metodo “tradizionale” per il test di significatività dell’ipotesi nulla (NHST). Comprendere la logica sottostante all’approccio NHST è fondamentale, poiché esso ha rappresentato il principale strumento della statistica inferenziale sin dalla sua introduzione all’inizio del XX secolo, e la maggior parte dei ricercatori continua a basarsi su questa procedura per l’analisi dei dati. Tuttavia, negli ultimi anni, l’NHST è stato oggetto di crescenti critiche, con molti studiosi che sostengono che questo approccio possa generare più problemi di quanti ne risolva. Per questo motivo, è cruciale esaminare le critiche avanzate dalla comunità scientifica nei confronti della procedura inferenziale NHST. In questa sezione, analizzeremo alcuni dei principali dubbi e limiti emersi riguardo a tale metodologia.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>92</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#luso-del-valore-p-nel-mondo-della-ricerca",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#luso-del-valore-p-nel-mondo-della-ricerca",
    "title": "92  Limiti dell’inferenza frequentista",
    "section": "92.1 L’uso del valore-\\(p\\) nel mondo della ricerca",
    "text": "92.1 L’uso del valore-\\(p\\) nel mondo della ricerca\nNel suo articolo “Statistical Errors” (2014), Nuzzo mette in luce i limiti dell’approccio NHST nella pratica scientifica Nuzzo (2014). Sebbene il valore-\\(p\\) sia stato introdotto da Ronald Fisher negli anni ’20, egli non lo concepì mai come un test formale. Fisher lo considerava piuttosto uno strumento informale per valutare se l’evidenza empirica fosse “significativa” in senso colloquiale, ovvero meritevole di ulteriore attenzione. Nella pratica, Fisher suggeriva di assumere un’ipotesi nulla e di calcolare la probabilità di osservare un risultato altrettanto estremo o più estremo di quello ottenuto, presupponendo che il risultato fosse interamente dovuto alla variabilità campionaria. Tuttavia, per Fisher, il valore-\\(p\\) non era una conclusione definitiva, ma uno strumento da integrare in un processo decisionale più ampio, che tenesse conto sia delle evidenze empiriche sia delle conoscenze pregresse del ricercatore. In altre parole, il valore-\\(p\\) era parte di un ragionamento scientifico, non il punto finale di tale ragionamento.\nVerso la fine degli anni ’20, Jerzy Neyman e Egon Pearson, rivali di Fisher, formalizzarono le procedure di decisione statistica con l’obiettivo di renderle più rigorose e oggettive. Introdussero concetti come il potere statistico e il tasso di falsi positivi, ma si distanziarono dall’uso del valore-\\(p\\) proposto da Fisher. Le divergenze tra Fisher, Neyman e Pearson diedero vita a un acceso dibattito: Neyman definì il lavoro di Fisher “matematicamente peggiore dell’inutilità”, mentre Fisher bollò l’approccio di Neyman come “infantile” e “dannoso per la libertà intellettuale dell’Occidente”.\nNel frattempo, altri autori iniziarono a scrivere manuali di statistica per guidare i ricercatori. Tuttavia, molti di questi autori non erano statistici e avevano una comprensione superficiale delle differenze tra i vari approcci. Il risultato fu un sistema ibrido che combinava il valore-\\(p\\) di Fisher con il framework rigoroso di Neyman e Pearson. Fu in questo contesto che la soglia di un valore-\\(p\\) pari a 0.05 venne arbitrariamente definita come “statisticamente significativa”.\nStoricamente, tuttavia, il valore-\\(p\\) proposto da Fisher aveva un significato molto diverso rispetto a quello che gli viene attribuito oggi. Come abbiamo visto, per Fisher era uno strumento informale, da utilizzare all’interno di un processo decisionale più ampio e non come un criterio meccanico per stabilire la verità scientifica. L’uso del valore-\\(p\\) nel sistema ibrido adottato dai manuali di statistica è quindi privo di una solida giustificazione teorica.\nNel 2016, l’American Statistical Association (ASA) ha espresso forti preoccupazioni riguardo all’uso inappropriato del valore-\\(p\\) nella pratica scientifica contemporanea Wasserstein & Lazar (2016):\n\n\\(P\\)-values do not measure the probability that the studied hypothesis is true, or the probability that the data were produced by random chance alone. Researchers often wish to turn a \\(p\\)-value into a statement about the truth of a null hypothesis, or about the probability that random chance produced the observed data. The \\(p\\)-value is neither. It is a statement about data in relation to a specified hypothetical explanation, and is not a statement about the explanation itself.\n\nL’articolo prosegue sottolineando che:\n\nScientific conclusions and business or policy decisions should not be based only on whether a \\(p\\)-value passes a specific threshold. Practices that reduce data analysis or scientific inference to mechanical “bright-line” rules (such as “\\(p &lt; 0.05\\)”) for justifying scientific claims or conclusions can lead to erroneous beliefs and poor decision making. A conclusion does not immediately become ‘true’ on one side of the divide and ‘false’ on the other. Researchers should bring many contextual factors into play to derive scientific inferences, including the design of a study, the quality of the measurements, the external evidence for the phenomenon under study, and the validity of assumptions that underlie the data analysis. Pragmatic considerations often require binary, ‘yes-no’ decisions, but this does not mean that \\(p\\)-values alone can ensure that a decision is correct or incorrect. The widespread use of “statistical significance” (generally interpreted as \\(p \\leq 0.05\\)) as a license for making a claim of a scientific finding (or implied truth) leads to considerable distortion of the scientific process.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>92</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#p-hacking",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#p-hacking",
    "title": "92  Limiti dell’inferenza frequentista",
    "section": "92.2 \\(P\\)-hacking",
    "text": "92.2 \\(P\\)-hacking\nLa pratica del \\(P\\)-hacking rappresenta una delle principali criticità associate all’uso del valore-\\(p\\) ed è conosciuta anche con termini come data-dredging, snooping, fishing, significance-chasing o double-dipping. Secondo Uri Simonsohn, professore all’Università della Pennsylvania, il \\(P\\)-hacking consiste nel manipolare i dati o le analisi fino a ottenere un risultato statisticamente significativo, tipicamente con un valore-\\(p\\) inferiore a 0.05. Ad esempio, si potrebbe dire: “Quel risultato sembra frutto di \\(P\\)-hacking; gli autori hanno escluso una condizione per far diminuire il valore-\\(p\\) sotto la soglia di 0.05” oppure “Lei è un \\(P\\)-hacker, controlla continuamente i dati durante la raccolta per trovare un risultato significativo”.\nQuesta pratica trasforma uno studio esplorativo, che dovrebbe essere interpretato con estrema cautela, in uno studio confermativo (apparentemente robusto), i cui risultati, tuttavia, hanno una probabilità molto bassa di essere replicati in ricerche successive. Secondo le simulazioni condotte da Simonsohn, piccole modifiche nelle scelte analitiche possono aumentare il tasso di falsi positivi fino al 60% in un singolo studio.\nIl \\(P\\)-hacking è particolarmente diffuso negli studi che cercano di dimostrare effetti di piccola entità utilizzando dati molto rumorosi. Un’analisi della letteratura psicologica ha rivelato che i valori-\\(p\\) riportati tendono a concentrarsi appena al di sotto della soglia di 0.05, un fenomeno che può essere interpretato come un segnale di \\(P\\)-hacking: i ricercatori eseguono molteplici test statistici fino a trovarne uno che raggiunge la “significatività statistica” e poi riportano solo quello. Come evidenziato in figura, questa pratica non è limitata alla psicologia, ma è ampiamente diffusa in tutti i campi della ricerca scientifica, contribuendo a minare l’affidabilità dei risultati pubblicati.\n\n\n\nDistribuzione dei valori-\\(p\\) nelle pubblicazioni scientifiche di economia, psicologia e biologia.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>92</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#critiche-al-valore-p",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#critiche-al-valore-p",
    "title": "92  Limiti dell’inferenza frequentista",
    "section": "92.3 Critiche al valore-\\(p\\)",
    "text": "92.3 Critiche al valore-\\(p\\)\nIl valore-\\(p\\) è stato spesso paragonato a creature fastidiose e persistenti come le zanzare, oppure ai “vestiti nuovi dell’imperatore”, metafora che rappresenta la tendenza a ignorare problemi evidenti preferendo fingere che tutto vada bene. È stato anche definito un intellectual rake sterile, un termine che sottolinea la sua incapacità di produrre risultati utili. Non manca nemmeno l’ironia sul fatto che la procedura di statistical hypothesis inference testing venga chiamata così principalmente per l’acronimo che genera.\nIl valore-\\(p\\) promuove un modo di pensare distorto, spostando l’attenzione dal cuore della ricerca, ovvero la forza della manipolazione sperimentale, verso la dimostrazione di un’ipotesi nulla che si sa già essere falsa. Ad esempio, uno studio condotto su oltre 19,000 individui ha mostrato che le coppie che si incontrano online hanno una probabilità inferiore di divorziare (\\(p &lt; 0.002\\)) e riportano una maggiore soddisfazione nella vita matrimoniale (\\(p &lt; 0.001\\)) rispetto a quelle che si sono conosciute offline. Sebbene questi risultati possano sembrare interessanti, senza considerare la dimensione dell’effetto – come la riduzione del tasso di divorzio dal 7.67% al 5.96% o l’aumento dell’indice di soddisfazione matrimoniale da 5.48 a 5.64 su una scala a sette punti – il loro impatto pratico rischia di essere sopravvalutato. In generale, la domanda chiave non dovrebbe essere “c’è un effetto?”, ma piuttosto “quanto è grande l’effetto?”. Questo approccio permette di valutare meglio l’effettiva rilevanza dei risultati, andando oltre la semplice significatività statistica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>92</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#leffetto-sperimentale-è-esattamente-nullo",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#leffetto-sperimentale-è-esattamente-nullo",
    "title": "92  Limiti dell’inferenza frequentista",
    "section": "92.4 L’effetto sperimentale è esattamente nullo?",
    "text": "92.4 L’effetto sperimentale è esattamente nullo?\nUna delle critiche più ricorrenti alla logica del test di verifica delle ipotesi statistiche riguarda l’assunzione irrealistica che l’effetto della manipolazione sperimentale sia esattamente nullo. Ad esempio, la fisica ci dimostra che persino lo spostamento di un grammo di massa in una stella distante anni luce dalla Terra può influenzare, seppur minimamente, il movimento delle molecole di un gas sul nostro pianeta (Borel, 1914). Questo esempio suggerisce che ogni manipolazione sperimentale, per quanto piccola, produca in qualche modo un effetto. Pertanto, come sottolinea Andrew Gelman, il problema non è tanto dimostrare che l’ipotesi nulla sia falsa – ovvero che la manipolazione sperimentale non abbia alcun effetto – quanto piuttosto valutare se la dimensione dell’effetto sia sufficientemente grande da avere un impatto pratico e se tale effetto sia riproducibile.\nIn questo contesto, la logica del test dell’ipotesi nulla risulta particolarmente problematica, specialmente quando si lavora con campioni piccoli ed effetti di modesta entità, come accade spesso negli studi psicologici. Questo approccio può portare a una sovrastima della dimensione dell’effetto e a una visione binaria dei risultati (vero/falso), distogliendo l’attenzione dalla stima accurata e non distorta della dimensione effettiva dell’effetto. In altre parole, la ricerca dovrebbe concentrarsi meno sul rifiutare un’ipotesi nulla spesso irrealistica e più sulla comprensione e quantificazione dell’impatto reale delle variabili studiate.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>92</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#attenti-al-valore-p",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#attenti-al-valore-p",
    "title": "92  Limiti dell’inferenza frequentista",
    "section": "92.5 Attenti al valore-\\(p\\)!",
    "text": "92.5 Attenti al valore-\\(p\\)!\nConsideriamo il seguente problema. Supponiamo di eseguire un \\(t\\)-test per due campioni indipendenti per verificare l’ipotesi nulla che le medie delle due popolazioni siano uguali. Fissiamo un livello di significatività \\(\\alpha = 0.05\\) e otteniamo un valore-\\(p\\) pari a \\(0.04\\). La domanda è: qual è la probabilità che i due campioni provengano da distribuzioni con la stessa media?\nLe opzioni sono:\n(a) \\(19/20\\); (b) \\(1/19\\); (c) \\(1/20\\); (d) \\(95/100\\); (e) sconosciuta.\nLa risposta corretta è: (e) sconosciuta. Questo perché la statistica frequentista calcola le probabilità dei dati condizionatamente alle ipotesi (assunte come vere), ma non permette di determinare la probabilità di un’ipotesi. In altre parole, il valore-\\(p\\) non fornisce informazioni sulla probabilità che l’ipotesi nulla sia vera o falsa; indica solo la probabilità di osservare i dati (o risultati più estremi) assumendo che l’ipotesi nulla sia vera.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>92</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#la-crisi-della-riprodicibilità-dei-risultati-della-ricerca",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#la-crisi-della-riprodicibilità-dei-risultati-della-ricerca",
    "title": "92  Limiti dell’inferenza frequentista",
    "section": "92.6 La crisi della riprodicibilità dei risultati della ricerca",
    "text": "92.6 La crisi della riprodicibilità dei risultati della ricerca\nNegli ultimi anni, la mancanza di replicabilità dei risultati della ricerca – inclusa quella psicologica – è emersa come un tema di grande rilevanza nel dibattito scientifico. In questo contesto, è stato evidenziato che alcuni aspetti del metodo scientifico, in particolare l’uso del valore-\\(p\\) e la pratica del test di significatività dell’ipotesi nulla (NHST, Null Hypothesis Significance Testing), potrebbero contribuire a quella che è stata definita una “crisi della ricerca scientifica”. Un’analisi approfondita di questo problema è stata proposta da Gelman (2016), il quale sostiene che la NHST sia intrinsecamente problematica. Questo approccio, infatti, spinge i ricercatori a cercare di rigettare un’ipotesi “fantoccio” (straw-man), spesso già falsa a priori o di scarso interesse scientifico, a favore di un’ipotesi alternativa che il ricercatore preferisce. In generale, è più ragionevole affermare che la differenza tra due condizioni sia molto piccola piuttosto che esattamente uguale a zero, ma la NHST non è progettata per cogliere questa sfumatura.\nNei libri di statistica, la NHST viene spesso presentata come una sorta di “alchimia” che trasforma la casualità in una falsa certezza, utilizzando termini come “confidenza” e “significatività” (Gelman, 2016). Il processo di raccolta dei dati, analisi e inferenza statistica viene sintetizzato in una conclusione espressa in termini di valore-\\(p\\) e intervalli di confidenza che escludono lo zero. Tuttavia, questo può creare l’impressione errata che il ricercatore abbia una comprensione completa del fenomeno studiato. Il problema principale della NHST è che spesso produce risultati “statisticamente significativi” in contesti in cui le caratteristiche del fenomeno non giustificano le conclusioni tratte. Questo può portare a una bassa replicabilità dei risultati, contribuendo alla crisi di fiducia nella ricerca.\nLa comunità statistica ha sottolineato come la non replicabilità sia particolarmente evidente quando i ricercatori, utilizzando la NHST, traggono conclusioni errate basate su piccoli campioni ed effetti di dimensioni ridotte. Queste condizioni, insieme ad altre, rendono l’applicazione della NHST estremamente problematica. Purtroppo, queste situazioni descrivono molte delle ricerche recenti in psicologia, un campo in cui gli effetti sono spesso modesti e i campioni limitati.\nLa statistica è stata definita come un metodo per prendere decisioni razionali in condizioni di incertezza. Gli statistici raccomandano ai ricercatori non solo di padroneggiare le tecniche statistiche, ma anche di imparare a convivere con l’incertezza, nonostante la crescente sofisticazione degli strumenti disponibili. Conviverci significa evitare di pensare che ottenere un valore-\\(p\\) “statisticamente significativo” equivalga a risolvere un problema scientifico. Ma allora, come possiamo avere fiducia in ciò che apprendiamo dai dati? Una possibile strategia è la replicazione e la convalida esterna dei risultati, sebbene nella ricerca psicologica e nelle scienze sociali questo sia spesso difficile da realizzare a causa degli elevati costi e delle complessità pratiche. Il problema di quali strumenti metodologici e metodi statistici siano più adatti per indagare i fenomeni psicologici, senza cadere in errori di interpretazione, rimane quindi una questione aperta e di cruciale importanza.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>92</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#commenti-e-considerazioni-finali",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#commenti-e-considerazioni-finali",
    "title": "92  Limiti dell’inferenza frequentista",
    "section": "92.7 Commenti e considerazioni finali",
    "text": "92.7 Commenti e considerazioni finali\nNon possiamo concludere senza affrontare la controversia che circonda il concetto di valore-\\(p\\). Nonostante sia ancora ampiamente utilizzato e spesso interpretato in modo errato, il valore-\\(p\\) conferisce solo una parvenza di legittimità a risultati dubbi, incoraggia cattive pratiche di ricerca e favorisce la produzione di falsi positivi. Inoltre, il suo significato è spesso frainteso, persino dagli esperti: quando chiamati a definire il valore-\\(p\\), molti forniscono risposte imprecise o sbagliate. Ciò che i ricercatori desiderano sapere è se i risultati di uno studio siano corretti o meno, ma il valore-\\(p\\) non fornisce questa informazione. Non dice nulla sulla dimensione dell’effetto, sulla forza dell’evidenza o sulla probabilità che il risultato sia frutto del caso. Allora, qual è il suo vero significato? Stuart Buck lo spiega in modo efficace:\n\nImmaginate di avere una moneta che sospettate sia truccata a favore della testa (l’ipotesi nulla è che la moneta sia equa). La lanciate 100 volte e ottenete più teste che croci. Il valore-\\(p\\) non vi dirà se la moneta è equa, ma vi indicherà la probabilità di ottenere almeno lo stesso numero di teste osservato se la moneta fosse equa. Questo è tutto – niente di più.\n\nIn sintesi, il valore-\\(p\\) risponde a una domanda molto specifica che, tuttavia, non ha alcuna rilevanza diretta per la validità scientifica dei risultati di una ricerca. In un’epoca in cui la crisi della riproducibilità dei risultati è sempre più evidente (Baker, 2016), il test dell’ipotesi nulla e gli intervalli di confidenza frequentisti sono stati identificati come una delle principali cause del problema. Questo ha spinto molti ricercatori a cercare alternative metodologiche più robuste e informative, in grado di superare i limiti intrinseci del valore-\\(p\\) e di promuovere una scienza più affidabile e trasparente.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>92</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#bibliografia",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#bibliografia",
    "title": "92  Limiti dell’inferenza frequentista",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBaker, M. (2016). Reproducibility Crisis. Nature, 533(7604), 452–454.\n\n\nBorel, E. (1914). Introduction Géométrique. G. Villars, New York.\n\n\nGelman, A. (2016). Commentary on «Crisis in Science? Or Crisis in Statistics! Mixed Messages in Statistics with Impact on Science». Journal of Statistical Research, 48-50(1), 11–12.\n\n\nGoligher, E. C., Heath, A., & Harhay, M. O. (2024). Bayesian statistics for clinical research. The Lancet, 404(10457), 1067–1076. https://doi.org/10.1016/S0140-6736(24)00055-9\n\n\nNuzzo, R. (2014). Statistical Errors. Nature, 506(7487), 150–152.\n\n\nWasserstein, R. L., & Lazar, N. A. (2016). The ASA’s statement on p-values: context, process, and purpose. The American Statistician, 70(2), 129–133.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>92</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html",
    "href": "chapters/replication_crisis/03_effect_size.html",
    "title": "93  La grandezza dell’effetto",
    "section": "",
    "text": "93.1 Introduzione\nLa dimensione dell’effetto (effect size) è un concetto chiave nella metodologia della ricerca, utilizzato per quantificare la forza della relazione statistica tra due variabili. Questa misura standardizzata descrive l’entità di un effetto, come quello di un intervento o di un trattamento, fornendo una valutazione quantitativa dell’importanza di un fenomeno osservato.\nÈ essenziale distinguere tra dimensione dell’effetto e significatività statistica. Un risultato può essere “statisticamente significativo” anche se l’effetto è di piccole dimensioni, e viceversa. La conoscenza di uno di questi aspetti non fornisce automaticamente informazioni sull’altro, evidenziando la necessità di considerare entrambi nell’analisi dei dati.\nL’importanza della dimensione dell’effetto è ampiamente riconosciuta nel mondo della ricerca scientifica. Il manuale dell’American Psychological Association (APA) del 2010 ne sottolinea la rilevanza, raccomandando di includere questa misura negli studi pubblicati. Di conseguenza, la maggior parte degli articoli nelle riviste associate all’APA riporta la dimensione dell’effetto, solitamente indicata tra parentesi accanto al valore-\\(p\\).\nNonostante la sua importanza e la prassi di riportarla, la psicologia scientifica spesso mostra una carenza nella corretta valutazione e interpretazione delle dimensioni dell’effetto. Molti ricercatori si limitano a comunicare questi valori senza analizzarli in profondità, portando a conclusioni che possono risultare superficiali, poco informative, fuorvianti o addirittura errate. Questa tendenza riflette una sottovalutazione sistematica e una diffusa incomprensione del concetto di dimensione dell’effetto, persino tra i professionisti della ricerca.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>93</span>  <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#misurazione-delleffetto-approcci-e-applicazioni",
    "href": "chapters/replication_crisis/03_effect_size.html#misurazione-delleffetto-approcci-e-applicazioni",
    "title": "93  La grandezza dell’effetto",
    "section": "93.2 Misurazione dell’Effetto: Approcci e Applicazioni",
    "text": "93.2 Misurazione dell’Effetto: Approcci e Applicazioni\nTra le metriche più utilizzate per quantificare l’effetto di un trattamento o di una differenza tra gruppi troviamo il \\(d\\) di Cohen e l’\\(r\\) di Pearson. Il \\(d\\) di Cohen è particolarmente utile per descrivere le differenze tra le medie di due gruppi sperimentali, esprimendo tale differenza in termini di deviazione standard aggregata.\nLa differenza standardizzata tra le medie di due gruppi può essere calcolata con la seguente formula (equazione 5.1, Glass et al., 1981):\n\\[\nd_p = \\frac{M_1 - M_2}{S_p},\n\\]\ndove:\n\n\\(M_1\\) e \\(M_2\\) sono le medie dei due gruppi,\n\\(S_p\\) è la deviazione standard combinata.\n\nUn valore positivo di \\(d_p\\) indica che la media del gruppo 1 è maggiore di quella del gruppo 2. La deviazione standard combinata \\(S_p\\) è calcolata come la radice quadrata della varianza media ponderata per i gradi di libertà (\\(df = n-1\\)) dei due gruppi (pp. 108, Glass et al., 1981):\n\\[\nS_p = \\sqrt{\\frac{(n_1 - 1) S_1^2 + (n_2 - 1) S_2^2}{n_1 + n_2 - 2}},\n\\]\ndove:\n\n\\(n_1\\) e \\(n_2\\) sono le dimensioni dei due gruppi,\n\\(S_1^2\\) e \\(S_2^2\\) sono le varianze (quadrato della deviazione standard) dei due gruppi.\n\nIl \\(d_p\\) di Cohen è strettamente correlato alla statistica \\(t\\) di un test \\(t\\) per campioni indipendenti. Infatti, è possibile calcolare \\(d_p\\) a partire dalla statistica \\(t\\) utilizzando la seguente formula (equazione 5.3, Glass et al., 1981):\n\\[\nd = t \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}.\n\\]\nL’errore standard di \\(d_p\\) è dato da:\n\\[\nSE_{d_p} = \\sqrt{\\frac{n_1 + n_2}{n_1 n_2} + \\frac{d_p^2}{2(n_1 + n_2)}}.\n\\]\nD’altra parte, la statistica \\(r\\) di Pearson misura il grado di correlazione lineare tra due variabili, indicando quanto una variabile possa predire l’altra. È interessante notare che queste due misure, \\(d\\) e \\(r\\), possono essere convertite l’una nell’altra attraverso la relazione:\n\\[\nd = \\frac{2r}{\\sqrt{1-r^2}}.\n\\]\nQuesta conversione permette di passare da una misura di differenza tra medie a una misura di correlazione, offrendo una maggiore flessibilità nell’interpretazione dei risultati.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>93</span>  <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#interpretazione-della-dimensione-delleffetto",
    "href": "chapters/replication_crisis/03_effect_size.html#interpretazione-della-dimensione-delleffetto",
    "title": "93  La grandezza dell’effetto",
    "section": "93.3 Interpretazione della Dimensione dell’Effetto",
    "text": "93.3 Interpretazione della Dimensione dell’Effetto\nL’interpretazione della dimensione dell’effetto è un aspetto cruciale nell’analisi statistica, ma spesso viene affrontata in modi che possono risultare privi di significato o addirittura fuorvianti. Di seguito, esploriamo due approcci comuni e le loro criticità.\n\n93.3.1 Gli Standard di Cohen\nUno dei metodi più diffusi per interpretare la dimensione dell’effetto si basa sugli standard proposti da Jacob Cohen (1977, 1988). Cohen ha suggerito delle soglie arbitrarie per classificare l’effetto:\n\nr = 0.10 → effetto piccolo,\nr = 0.30 → effetto medio,\nr = 0.50 → effetto grande.\n\nTuttavia, come sottolineato da Funder (2019), queste soglie sono spesso utilizzate in modo acritico, senza considerare il contesto specifico. Lo stesso Cohen ha espresso rammarico per aver introdotto queste categorie, precisando che dovrebbero essere adottate solo in assenza di criteri più solidi.\nLe etichette “piccolo”, “medio” e “grande” sono prive di significato se non vengono contestualizzate. Per un’interpretazione corretta, è essenziale porsi due domande fondamentali:\n\nRispetto a cosa? Cosa rappresenta un effetto piccolo, medio o grande nel contesto specifico dello studio?\nA quale scopo? Qual è l’impatto pratico o teorico dell’effetto osservato?\n\nSenza rispondere a queste domande, l’uso degli standard di Cohen rischia di essere poco informativo o addirittura ingannevole.\n\n\n93.3.2 Elevare al Quadrato la Correlazione\nUn altro approccio comune, ma altrettanto problematico, consiste nell’elevare al quadrato il coefficiente di correlazione \\(r\\) per ottenere \\(r^2\\), interpretato come la “proporzione di varianza spiegata”. Ad esempio, una correlazione \\(r = 0.30\\) corrisponde a \\(r^2 = 0.09\\), spesso descritto come “solo il 9% della varianza spiegata”.\nTuttavia, come evidenziato da Funder & Ozer (2019), questa pratica è criticabile per due motivi principali:\n\nMancanza di interpretabilità: Mentre \\(r\\) rappresenta la pendenza di una regressione standardizzata, \\(r^2\\) è molto meno intuitivo, poiché riflette solo la proporzione di varianza condivisa tra due variabili.\nPotenziale fuorviante: Elevare al quadrato \\(r\\) può distorcere la percezione dell’effetto. Ad esempio, una correlazione \\(r = 0.30\\) (effetto medio secondo Cohen) diventa \\(r^2 = 0.09\\), che sembra trascurabile, ma in realtà potrebbe avere un impatto significativo nel contesto applicativo.\n\nUn esempio chiaro è fornito da Darlington (1990). Consideriamo un gioco in cui si lanciano due monete: un nickel (5¢) e un dime (10¢). Se esce testa, si vincono rispettivamente 5¢ o 10¢. Le correlazioni tra il valore delle monete e il pagamento sono:\n\nNickel: \\(r = 0.4472\\) (\\(r^2 = 0.20\\)),\nDime: \\(r = 0.8944\\) (\\(r^2 = 0.80\\)).\n\nSe interpretassimo \\(r^2\\) in modo letterale, potremmo erroneamente concludere che il dime “conta quattro volte più” del nickel. Tuttavia, le correlazioni originali mostrano che \\(0.8944\\) è esattamente il doppio di \\(0.4472\\), offrendo un confronto più accurato e informativo.\nIn sintesi, l’interpretazione della dimensione dell’effetto richiede cautela e contestualizzazione. Gli standard di Cohen, sebbene ampiamente utilizzati, sono arbitrari e possono essere fuorvianti se applicati in modo acritico. Allo stesso modo, elevare al quadrato la correlazione \\(r\\) per ottenere \\(r^2\\) rischia di distorcere la percezione dell’effetto, rendendolo meno interpretabile e potenzialmente fuorviante. Per un’analisi robusta, è essenziale considerare il contesto e l’impatto pratico dell’effetto osservato, evitando di affidarsi esclusivamente a metriche standardizzate o trasformazioni matematiche poco informative.\n\n\n93.3.3 Alternative migliori\nÈ cruciale interpretare le dimensioni degli effetti in modo che ne arricchisca il significato. Funder & Ozer (2019) propongono due strategie principali: l’adozione di benchmark (criteri di riferimento) e la valutazione delle implicazioni pratiche dei risultati.\n\nUtilizzare criteri di riferimento significa confrontare l’entità di un risultato con quella di risultati ben noti e ampiamente compresi. Simile al modo in cui giudichiamo l’altezza di una persona basandoci su confronti con altri, i ricercatori possono ottenere una percezione accurata dell’importanza di un risultato confrontandolo con la dimensione di effetti noti, sia quelli tipici del campo di studio sia quelli emersi da ricerche passate.\nUn approccio al benchmarking può includere l’analisi di risultati considerati “classici” nel campo di interesse o la considerazione di dimensioni dell’effetto per risultati che hanno ottenuto un solido consenso nella comunità psicologica.\nIn un’ottica più ampia, alcuni ricercatori hanno proposto benchmark per la dimensione dell’effetto calcolando medie su vasti corpi di letteratura. Ad esempio, uno studio di psicologia sociale ha esaminato 708 correlazioni ottenute meta-analiticamente, rivelando che la dimensione media dell’effetto \\(r\\) era di .19.\nLa conoscenza comune o i risultati di ricerche non psicologiche possono offrire benchmark per valutare la forza di una relazione tra variabili. Un esempio è l’efficacia degli antistaminici contro il comune raffreddore, che corrisponde a un \\(r\\) di .11, mentre l’effetto degli anti-infiammatori non steroidei (come l’ibuprofene) sul dolore è di \\(r = .14\\).\n\nTali confronti illustrano come l’interpretazione delle dimensioni dell’effetto possa essere notevolmente approfondita e resa più significativa attraverso il riferimento a benchmark consolidati o intuitivamente comprensibili, sia dentro che fuori il campo della psicologia. Questo metodo consente di inserire i risultati di nuove ricerche in un contesto più vasto, favorendo una valutazione più consapevole della loro rilevanza relativa.\n\n\n93.3.4 Alternative Migliori per Interpretare la Dimensione dell’Effetto\nPer arricchire il significato delle dimensioni dell’effetto, è essenziale adottare approcci che vadano oltre le metriche standardizzate e si basino su criteri di riferimento concreti e contestualizzati. Funder & Ozer (2019) propone due strategie principali: l’uso di benchmark (criteri di riferimento) e la valutazione delle implicazioni pratiche dei risultati.\n\n93.3.4.1 1. Utilizzare Criteri di Riferimento (Benchmark)\nUn modo efficace per interpretare la dimensione dell’effetto è confrontarla con risultati ben noti e ampiamente compresi, sia all’interno del campo di studio che in contesti più generali. Questo approccio è simile a come giudichiamo l’altezza di una persona confrontandola con quella di altre persone.\n\nConfronto con Risultati Classici: I ricercatori possono ottenere una percezione più accurata dell’importanza di un risultato confrontandolo con dimensioni dell’effetto di studi considerati “classici” nel proprio campo. Ad esempio, in psicologia, è possibile fare riferimento a risultati che hanno ottenuto un solido consenso nella comunità scientifica.\nMedie da Meta-Analisi: Alcuni ricercatori hanno proposto benchmark calcolando medie su vasti corpi di letteratura. Ad esempio, uno studio di psicologia sociale ha analizzato 708 correlazioni ottenute meta-analiticamente, rilevando che la dimensione media dell’effetto \\(r\\) era di 0.19. Questo valore può servire come punto di riferimento per valutare l’entità di nuovi risultati.\nEsempi Trasversali: Anche conoscenze comuni o risultati di ricerche non psicologiche possono offrire benchmark utili. Ad esempio:\n\nL’efficacia degli antistaminici contro il comune raffreddore corrisponde a un \\(r = 0.11\\).\nL’effetto degli anti-infiammatori non steroidei (come l’ibuprofene) sul dolore è pari a \\(r = 0.14\\).\n\n\nQuesti confronti mostrano come l’interpretazione della dimensione dell’effetto possa essere notevolmente approfondita e resa più significativa attraverso il riferimento a benchmark consolidati o intuitivamente comprensibili.\n\n\n93.3.4.2 2. Valutare le Implicazioni Pratiche\nOltre ai benchmark, è fondamentale considerare le implicazioni pratiche dei risultati. Un effetto statisticamente piccolo può avere un impatto significativo se applicato a un contesto reale. Ad esempio:\n\nUn \\(r = 0.10\\) potrebbe sembrare trascurabile, ma se tradotto in un intervento su larga scala (ad esempio, un programma educativo o una politica sanitaria), potrebbe portare a benefici tangibili per un gran numero di persone.\n\nIn conclusione, l’interpretazione della dimensione dell’effetto può essere notevolmente migliorata attraverso l’uso di benchmark e la valutazione delle implicazioni pratiche. Confrontare i risultati con studi classici, medie di meta-analisi o esempi tratti da altri campi consente di inserire i nuovi risultati in un contesto più ampio e significativo. Questo approccio non solo arricchisce l’interpretazione, ma favorisce anche una valutazione più consapevole della rilevanza e dell’impatto delle scoperte scientifiche.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>93</span>  <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#riflessioni-conclusive",
    "href": "chapters/replication_crisis/03_effect_size.html#riflessioni-conclusive",
    "title": "93  La grandezza dell’effetto",
    "section": "93.4 Riflessioni Conclusive",
    "text": "93.4 Riflessioni Conclusive\nLa sovrastima della grandezza degli effetti in psicologia rappresenta un problema diffuso e significativo. Un principio spesso enfatizzato nella psicologia sociale e nell’economia comportamentale, specialmente nei media e nei corsi di business, è che piccoli interventi, o “nudge” (spinte gentili), possano produrre effetti sorprendentemente ampi sul comportamento. Questa idea ha portato a numerose affermazioni sensazionalistiche, come l’ipotesi che le elezioni possano essere influenzate dall’esito di partite di football o che stimoli subliminali, come una faccina sorridente, possano generare cambiamenti drastici negli atteggiamenti verso temi complessi come l’immigrazione.\nAlla base di queste affermazioni c’è un modello di mondo che non si limita al concetto di “effetto farfalla” (dove piccoli cambiamenti possono avere conseguenze imprevedibili e amplificate), ma suggerisce che piccoli interventi possano produrre effetti grandi e prevedibili. Questo approccio, talvolta definito “modello a pulsante” delle scienze sociali, presuppone che, facendo X, si possa aspettarsi di osservare Y in modo sistematico. Tuttavia, questa visione presenta diverse criticità:\n\n93.4.1 Problemi del Modello “a Pulsante”\n\nSovrastima degli effetti: Molti studi riportano effetti esagerati per interventi minimi, che spesso non vengono replicati in ricerche successive. Questo solleva dubbi sulla validità e sull’affidabilità di tali risultati.\nMancanza di considerazione delle interazioni: Se esistessero davvero molti effetti grandi e prevedibili, questi interferirebbero tra loro, rendendo difficile osservare risultati coerenti nei dati reali. La complessità del comportamento umano raramente si presta a relazioni lineari e isolate.\nInstabilità del sistema: Un sistema sociale caratterizzato da molti effetti grandi e prevedibili sarebbe intrinsecamente instabile e difficile da studiare, contraddicendo l’osservazione che le società tendono a mostrare una certa stabilità nel tempo.\nGeneralizzazione eccessiva: Spesso i risultati ottenuti in contesti di laboratorio altamente controllati vengono estesi a situazioni reali molto più complesse, senza considerare le differenze contestuali.\nBias di pubblicazione: Gli studi che riportano effetti grandi e statisticamente significativi hanno maggiori probabilità di essere pubblicati, creando una rappresentazione distorta della realtà e alimentando un ciclo di sovrastima.\n\n\n\n93.4.2 Verso un Approccio più Cauto e Sfumato\nNonostante queste criticità, è importante riconoscere che la psicologia ha identificato molti fenomeni robusti, specialmente in aree come la psicologia clinica e la psicologia della percezione. Tuttavia, è fondamentale adottare un approccio più cauto e riflessivo nell’interpretazione e nella comunicazione dei risultati della ricerca.\nLa consapevolezza di questi problemi ha portato a una serie di miglioramenti metodologici, tra cui:\n\nEnfasi sulla replicabilità: Maggiore attenzione alla riproducibilità degli studi per garantire che i risultati siano affidabili.\nUso di campioni più ampi: Studi condotti su campioni più grandi e diversificati per aumentare la validità esterna.\nMetodi statistici più robusti: Adozione di tecniche statistiche avanzate per ridurre il rischio di falsi positivi.\nApproccio critico e riflessivo: La comunità scientifica sta diventando sempre più consapevole della necessità di evitare semplificazioni eccessive e di riconoscere la complessità dei fenomeni psicologici.\n\nIn sintesi, mentre la psicologia offre intuizioni preziose sul comportamento umano, è essenziale mantenere un sano scetticismo verso affermazioni di effetti grandi e facilmente ottenibili. La realtà è spesso più complessa e sfumata di quanto suggerito da titoli sensazionalistici o da singoli studi. Un approccio equilibrato, che combina rigore metodologico, contestualizzazione e umiltà scientifica, è fondamentale per avanzare nella comprensione dei fenomeni psicologici e per evitare di cadere in trappole interpretative che possono distorcere la nostra visione del comportamento umano.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>93</span>  <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#bibliografia",
    "href": "chapters/replication_crisis/03_effect_size.html#bibliografia",
    "title": "93  La grandezza dell’effetto",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nFunder, D. C., & Ozer, D. J. (2019). Evaluating effect size in psychological research: Sense and nonsense. Advances in Methods and Practices in Psychological Science, 2(2), 156–168.\n\n\nGlass, G. V., McGaw, B., & Smith, M. L. (1981). Meta-analysis in Social Research. Sage Publications.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>93</span>  <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html",
    "href": "chapters/replication_crisis/04_s_m_errors.html",
    "title": "94  Errori di segno e errori di grandezza",
    "section": "",
    "text": "94.1 Introduzione\nIn questo capitolo analizzeremo la relazione tra la crisi della replicabilità e le procedure decisionali statistiche proprie dell’approccio frequentista. In particolare, approfondiremo gli errori di tipo M (magnitude) e di tipo S (sign), discussi da Loken & Gelman (2017), e il loro impatto sulla validità dei risultati scientifici.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>94</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#introduzione",
    "href": "chapters/replication_crisis/04_s_m_errors.html#introduzione",
    "title": "94  Errori di segno e errori di grandezza",
    "section": "",
    "text": "Domande Iniziali\n\n\n\nPrima di esplorare le simulazioni e i risultati discussi in questo capitolo, prova a riflettere sulle seguenti domande. Ti invitiamo a formulare delle ipotesi sui risultati delle simulazioni prima di leggere le spiegazioni:\n\nSe si effettuano molteplici studi su un effetto molto piccolo utilizzando campioni di dimensioni ridotte, cosa pensi che accadrà ai risultati pubblicati che ottengono significatività statistica? Saranno accurati rispetto alla vera grandezza dell’effetto?\nIn uno scenario in cui non esiste alcuna differenza tra due gruppi, quanto spesso credi che un test t fornisca un risultato statisticamente significativo che verrà pubblicato? Quali fattori potrebbero influenzare questa probabilità?\nSupponiamo che in una serie di esperimenti alcuni studi trovino effetti significativi e altri no. Quale pensi sia la tendenza degli studi pubblicati rispetto a quelli non pubblicati? Quale impatto può avere questa tendenza sulla percezione della realtà scientifica?\nSe dovessi valutare la replicabilità di uno studio basato sulla significatività statistica, quali problemi potresti incontrare se l’effetto sottostante è molto piccolo?\n\nTieni a mente le tue risposte mentre esplori le simulazioni presentate in questo capitolo. Alla fine del capitolo, confronteremo le previsioni con i risultati effettivi.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>94</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#il-filtro-della-significatività-statistica",
    "href": "chapters/replication_crisis/04_s_m_errors.html#il-filtro-della-significatività-statistica",
    "title": "94  Errori di segno e errori di grandezza",
    "section": "\n94.2 Il Filtro della Significatività Statistica",
    "text": "94.2 Il Filtro della Significatività Statistica\nNel ?sec-crisis abbiamo esplorato come la pratica scientifica contemporanea sia spesso compromessa da casi di frode, principalmente a causa delle significative implicazioni economiche legate alla pubblicazione su riviste scientifiche di alto prestigio. Questo fenomeno è spesso sottovalutato, poiché le riviste tendono a essere riluttanti nel riconoscere la necessità di correzioni o ritrattazioni degli articoli già pubblicati.\nLa frode scientifica rappresenta una minaccia evidente alla riproducibilità dei risultati, un pilastro fondamentale del metodo scientifico. Tuttavia, le difficoltà nel replicare i risultati pubblicati non sono attribuibili esclusivamente a frodi o a “pratiche di ricerca disoneste” (Nelson et al., 2018). Un problema intrinseco risiede nel metodo statistico ampiamente adottato dai ricercatori: l’approccio del test di ipotesi nulla e della significatività statistica di stampo fisheriano. Secondo questo metodo, i risultati che non raggiungono la soglia di “significatività statistica” vengono scartati, mentre quelli che la superano sono considerati credibili, basandosi esclusivamente su questo criterio (Wagenmakers et al., 2008).\nTuttavia, l’idea che la significatività statistica sia un filtro affidabile per distinguere i risultati di ricerca “validi” da quelli “non validi” è fondamentalmente errata. Numerose evidenze dimostrano i limiti di questo approccio. Per approfondire questa problematica, esamineremo lo studio di Loken & Gelman (2017), che mette in luce la relazione tra la crisi della replicabilità e le procedure decisionali statistiche dell’approccio frequentista.\nUno dei principali problemi evidenziati da Loken & Gelman (2017) è che, in contesti di ricerca complessi, la significatività statistica fornisce prove molto deboli riguardo al segno (sign) o all’entità (magnitude) degli effetti sottostanti. In altre parole, il raggiungimento della significatività statistica non garantisce né la rilevanza né la consistenza dei risultati ottenuti. Questo solleva seri dubbi sull’affidabilità di tale criterio come unico strumento per valutare la validità delle scoperte scientifiche.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>94</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#errori-di-tipo-m-e-s",
    "href": "chapters/replication_crisis/04_s_m_errors.html#errori-di-tipo-m-e-s",
    "title": "94  Errori di segno e errori di grandezza",
    "section": "\n94.3 Errori di tipo M e S\n",
    "text": "94.3 Errori di tipo M e S\n\nPer illustrare le implicazioni del processo decisionale basato sulla significatività statistica, Loken & Gelman (2017) hanno condotto una simulazione. In questa simulazione, hanno considerato uno scenario di ricerca ipotetico in cui era presente un effetto reale, sebbene molto debole, difficilmente rilevabile senza un ampio volume di dati. Utilizzando l’approccio frequentista, hanno cercato di identificare questo effetto valutando la significatività statistica.\nI risultati della simulazione hanno mostrato che, anche in presenza di un effetto reale (seppur debole), l’approccio frequentista riusciva a rilevare un effetto statisticamente significativo solo in una piccola percentuale dei casi. Inoltre, quando un effetto significativo veniva individuato, la stima della sua grandezza risultava altamente imprecisa e instabile.\nIn sintesi, la significatività statistica fornisce un’indicazione generica sulla presenza o assenza di un effetto, ma non offre informazioni affidabili sulla sua entità o replicabilità. Questo problema è particolarmente rilevante in campi come la psicologia e le scienze sociali, dove gli studi spesso si basano su campioni di dimensioni ridotte e gli effetti osservati tendono a essere modesti. In tali contesti, l’approccio frequentista rischia di produrre prove deboli e instabili, compromettendo la replicabilità e l’affidabilità dei risultati.\n\n94.3.1 Simulazione semplificata\nRiproduciamo qui, in forma semplificata, la simulazione condotta da Loken & Gelman (2017). Iniziamo importando le librerie necessarie.\nConsideriamo due campioni casuali indipendenti di dimensioni \\(n_1 = 20\\) e \\(n_2 = 25\\), estratti rispettivamente dalle distribuzioni normali \\(\\mathcal{N}(102, 10)\\) e \\(\\mathcal{N}(100, 10)\\). La dimensione effettiva dell’effetto (\\(d\\)) per la differenza tra le medie dei due campioni è calcolata utilizzando la formula:\n\\[\nd = \\frac{\\bar{y}_1 - \\bar{y}_2}{s_p},\n\\]\ndove \\(\\bar{y}_1\\) e \\(\\bar{y}_2\\) rappresentano le medie campionarie dei due gruppi, e \\(s_p\\) è la deviazione standard combinata, definita come:\n\\[\ns_p = \\sqrt{\\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1 + n_2 - 2}}.\n\\]\nIn questo caso specifico, la dimensione effettiva dell’effetto risulta molto piccola, indicando che la differenza osservata tra le medie dei due gruppi non ha una rilevanza pratica significativa. Ciò suggerisce che la distinzione tra i due gruppi, seppur statisticamente rilevabile, non ha un impatto sostanziale in contesti reali.\n\n# Parametri\nmu_1 &lt;- 102  # Media del primo gruppo\nmu_2 &lt;- 100  # Media del secondo gruppo\nsigma &lt;- 10  # Deviazione standard comune\nn1 &lt;- 20     # Numero di osservazioni nel primo gruppo\nn2 &lt;- 25     # Numero di osservazioni nel secondo gruppo\n\n# Calcolo della differenza media\nmean_difference &lt;- abs(mu_1 - mu_2)\n\n# Calcolo della deviazione standard pooled\npooled_sd &lt;- sqrt(((n1 - 1) * sigma^2 + (n2 - 1) * sigma^2) / (n1 + n2 - 2))\n\n# Calcolo di Cohen's d\ncohen_d &lt;- mean_difference / pooled_sd\n\n# Output del risultato\ncat(\"Dimensione dell'effetto (Cohen's d):\", cohen_d, \"\\n\")\n#&gt; Dimensione dell'effetto (Cohen's d): 0.2\n\nEsaminiamo ora le conclusioni che emergerebbero applicando l’approccio frequentista e la sua procedura di decisione statistica in questo contesto. Supponiamo di condurre una simulazione in cui vengono estratti due campioni: il primo composto da 20 osservazioni provenienti dalla prima popolazione e il secondo da 25 osservazioni provenienti dalla seconda popolazione. Successivamente, applichiamo il test \\(t\\) di Student per confrontare le medie dei due gruppi.\nNell’ambito dell’approccio frequentista, il valore-\\(p\\) ottenuto dal test determina la decisione statistica. Se il valore-\\(p\\) è superiore a 0.05, i risultati vengono considerati non significativi e, di conseguenza, scartati. Al contrario, se il valore-\\(p\\) è inferiore a 0.05, il risultato è ritenuto “pubblicabile” e si conclude che esiste una differenza statisticamente significativa tra i due gruppi.\nPer valutare in modo approfondito le conclusioni derivate da questa procedura, è necessario ripetere l’intero processo per un numero elevato di iterazioni, ad esempio 50.000 volte. Ciò significa che, in ciascuna iterazione, vengono estratti nuovi campioni, viene calcolato il test \\(t\\) di Student e viene determinato il corrispondente valore-\\(p\\). Ripetendo questo processo su larga scala, è possibile ottenere una distribuzione completa dei risultati, che consente di analizzare la frequenza con cui si ottengono risultati significativi e la stabilità delle stime prodotte dall’approccio frequentista in questo contesto.\n\n# Parametri\nn_samples &lt;- 50000\nmu_1 &lt;- 102\nmu_2 &lt;- 100\nsigma &lt;- 10\nn1 &lt;- 20\nn2 &lt;- 25\n\n# Inizializzazione del risultato\nres &lt;- c()\n\n# Simulazioni\nset.seed(123)  # Per la riproducibilità\nfor (i in 1:n_samples) {\n  # Generazione dei campioni casuali\n  y1 &lt;- rnorm(n1, mean = mu_1, sd = sigma)\n  y2 &lt;- rnorm(n2, mean = mu_2, sd = sigma)\n  \n  # Calcolo della dimensione dell'effetto\n  y1bar &lt;- mean(y1)\n  y2bar &lt;- mean(y2)\n  v1 &lt;- var(y1)\n  v2 &lt;- var(y2)\n  s &lt;- sqrt(((n1 - 1) * v1 + (n2 - 1) * v2) / (n1 + n2 - 2))\n  efsize &lt;- (y1bar - y2bar) / s\n  \n  # Calcolo del valore p\n  t_test &lt;- t.test(y1, y2, var.equal = TRUE)\n  \n  # Salvataggio della dimensione dell'effetto solo per risultati \"statisticamente significativi\"\n  if (t_test$p.value &lt; 0.05) {\n    res &lt;- c(res, efsize)\n  }\n}\n\n\nres_df &lt;- data.frame(effect_size = res)\n\nggplot(res_df, aes(x = effect_size)) +\n  geom_histogram(bins = 20, fill = \"blue\", color = \"black\", alpha = 0.7) +\n  geom_vline(\n    xintercept = 0.2, color = \"red\", linetype = \"dashed\", \n    size = 1.2, label = \"True Effect Size\") +\n  labs(\n    x = \"Effect Size\",\n    y = \"Frequency\",\n    title = \"Histogram of Effect Sizes for\\n'Statistically Significant' Results\"\n  ) \n\n\n\n\n\n\n\nCome evidenziato da Loken & Gelman (2017), l’applicazione dell’approccio frequentista nella procedura di decisione statistica può condurre a due tipi di errori rilevanti. Il primo, noto come errore di magnitude (grandezza), si manifesta quando i risultati pubblicati tendono a sovrastimare la reale entità dell’effetto. Nella simulazione condotta, nonostante la vera grandezza dell’effetto fosse modesta (0.2), la media della grandezza dell’effetto per i risultati classificati come “statisticamente significativi” era circa 0.8, suggerendo un effetto di entità “ampia”. Questo indica una distorsione sistematica verso stime esagerate.\nIl secondo errore, chiamato errore di segno, si verifica quando, a causa della variabilità campionaria, la direzione dell’effetto viene stimata in modo errato. In tali casi, il ricercatore potrebbe erroneamente concludere che \\(\\mu_2 &gt; \\mu_1\\), quando in realtà non è così. È importante sottolineare che, anche in queste situazioni, la grandezza assoluta dell’effetto risulta sovrastimata.\nUn aspetto degno di nota è che queste conclusioni rimarrebbero valide anche se si considerasse l’intervallo di confidenza per la differenza tra le medie. In sintesi, l’approccio frequentista introduce un errore sistematico nella stima della grandezza dell’effetto, che rappresenta la quantità più rilevante per il ricercatore. In alcuni casi, può persino portare a errori nella determinazione della direzione dell’effetto, compromettendo ulteriormente l’affidabilità delle conclusioni scientifiche.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>94</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#riflessioni-conclusive",
    "href": "chapters/replication_crisis/04_s_m_errors.html#riflessioni-conclusive",
    "title": "94  Errori di segno e errori di grandezza",
    "section": "\n94.4 Riflessioni Conclusive",
    "text": "94.4 Riflessioni Conclusive\nIn conclusione, l’approccio frequentista non rappresenta un metodo affidabile per valutare i risultati della ricerca e determinarne l’attendibilità o la necessità di scartarli (Gelman & Carlin, 2014; Loken & Gelman, 2017). Questa mancanza di affidabilità è dovuta all’introduzione di errori sistematici nella stima della grandezza degli effetti, che in alcuni casi possono persino portare a errori nella direzione dell’effetto stesso. Alla luce di queste criticità, non sembrano esserci motivi validi per continuare a fare affidamento su questo approccio.\nAl contrario, l’adozione dell’approccio bayesiano sembra offrire una soluzione più precisa e affidabile per l’analisi dei dati di ricerca. Questo metodo valuta la probabilità delle ipotesi alla luce dei dati osservati, evitando gli errori intrinseci dell’approccio frequentista e fornendo una base più solida per prendere decisioni informate sulla validità dei risultati. In questo modo, l’approccio bayesiano si presenta come un’alternativa più robusta e scientificamente rigorosa.\n\n\n\n\n\n\nRisposte alle domande iniziali\n\n\n\n\n\nOra confrontiamo le previsioni con i risultati ottenuti dalle simulazioni:\n\nSovrastima della grandezza dell’effetto: I risultati pubblicati tendono a essere selezionati sulla base della significatività statistica, il che porta a una sovrastima sistematica della grandezza dell’effetto rispetto alla realtà. Questo fenomeno, noto come errore di tipo M (magnitude), si verifica perché solo gli effetti con valori estremi (per caso) superano la soglia di significatività statistica e vengono pubblicati.\nFalsi positivi e loro frequenza: In uno scenario in cui non esiste alcuna differenza tra i due gruppi (cioè la vera differenza è zero), il test t ha fornito risultati statisticamente significativi nel 5% dei casi, come previsto dalla soglia di α = 0.05. Tuttavia, la selezione dei risultati pubblicati amplifica questo problema, rendendo più probabile che i lettori incontrino falsi positivi nella letteratura scientifica.\nBias nella pubblicazione: Gli studi che riportano risultati significativi hanno maggiore probabilità di essere pubblicati rispetto a quelli che non trovano un effetto significativo. Questo porta a un effetto distorsivo nella letteratura scientifica, in cui i risultati pubblicati tendono a sovrastimare l’effetto reale. Il “filtro della significatività statistica” crea una percezione distorta della realtà scientifica, poiché gli effetti nulli o piccoli tendono a essere sottorappresentati nella letteratura.\nReplicabilità e significatività statistica: Gli studi con effetti piccoli e campioni ridotti sono particolarmente vulnerabili al fallimento della replicazione. Anche quando un effetto reale esiste, la probabilità di ottenerne una stima precisa è bassa, e la replicazione potrebbe risultare in un valore non significativo, generando confusione nella comunità scientifica.\n\nConsiderazioni Finali\nLe simulazioni evidenziano come la significatività statistica, utilizzata come criterio per la pubblicazione, contribuisca a un bias nella selezione dei risultati, distorcendo la percezione della realtà scientifica. Questo fenomeno, noto come “filtro della significatività statistica”, è una delle cause principali della crisi della replicabilità, poiché induce i ricercatori e i lettori a sovrastimare la grandezza e la presenza di effetti studiati.\nPer affrontare queste problematiche, approcci alternativi, come quelli bayesiani, possono offrire soluzioni più robuste, permettendo una valutazione più affidabile delle ipotesi alla luce dei dati osservati.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>94</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#esercizi",
    "href": "chapters/replication_crisis/04_s_m_errors.html#esercizi",
    "title": "94  Errori di segno e errori di grandezza",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\n\nPerché la significatività statistica non è un criterio affidabile per valutare la validità dei risultati scientifici?\nSpiega il concetto di “filtro della significatività statistica” e il suo impatto sulla pubblicazione dei risultati.\nQual è la differenza tra errore di tipo M e errore di tipo S? Come influenzano l’interpretazione dei risultati?\nPerché i risultati pubblicati tendono a sovrastimare la grandezza dell’effetto rispetto alla realtà?\nQuali sono le conseguenze della pubblicazione selettiva dei risultati per la replicabilità degli studi?\nPerché gli studi con campioni di piccole dimensioni sono più vulnerabili a errori nella stima della grandezza dell’effetto?\nIn che modo la selezione dei risultati pubblicati altera la percezione della forza degli effetti studiati?\nPerché un test frequentista può portare a una falsa conclusione sulla direzione di un effetto?\nQuali sono le principali differenze tra l’approccio frequentista e quello bayesiano nella valutazione della significatività di un effetto?\nIn che modo l’approccio bayesiano può ridurre il rischio di errori dovuti alla selezione dei risultati basata sulla significatività statistica?\n\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\n\nLa significatività statistica non garantisce la validità di un risultato perché dipende dalla dimensione del campione e da soglie arbitrarie (come p &lt; 0.05). Inoltre, non misura la rilevanza pratica di un effetto, ma solo la probabilità che i dati osservati siano ottenuti sotto l’ipotesi nulla.\nIl “filtro della significatività statistica” si riferisce alla tendenza a pubblicare solo risultati con p &lt; 0.05, tralasciando studi con risultati non significativi. Questo porta a una distorsione nella letteratura scientifica e a una sovrastima della forza degli effetti riportati.\nErrore di tipo M (Magnitude) indica la sovrastima della grandezza dell’effetto nei risultati pubblicati, mentre errore di tipo S (Sign) si riferisce all’errata determinazione della direzione dell’effetto. Questi errori si verificano perché solo gli effetti più estremi tendono a superare il filtro della significatività statistica.\nI risultati pubblicati tendono a sovrastimare la grandezza dell’effetto perché solo gli effetti più grandi (anche per pura casualità) superano la soglia di significatività statistica e vengono pubblicati, mentre quelli più piccoli restano inediti.\nLa pubblicazione selettiva riduce la replicabilità perché introduce una distorsione sistematica nei risultati disponibili. Le repliche spesso non trovano effetti altrettanto grandi o significativi, creando instabilità nella conoscenza scientifica.\nI campioni piccoli aumentano la variabilità delle stime dell’effetto, rendendo più probabile che un risultato significativo sia solo un’oscillazione casuale dei dati piuttosto che un vero effetto replicabile.\nLa selezione dei risultati pubblicati altera la percezione della forza degli effetti perché induce i lettori a credere che gli effetti siano più forti e consistenti di quanto non siano realmente.\nUn test frequentista può portare a una falsa conclusione sulla direzione dell’effetto perché, in campioni piccoli, le stime dell’effetto possono essere fortemente influenzate dal rumore, portando a interpretazioni errate.\nL’approccio frequentista si basa sul valore-p e sulla soglia di significatività, mentre l’approccio bayesiano utilizza la probabilità a posteriori per aggiornare la credibilità delle ipotesi alla luce dei dati osservati. Il metodo bayesiano permette inferenze più flessibili e robuste.\nL’approccio bayesiano riduce il rischio di errori dovuti alla selezione dei risultati perché non si basa su una soglia arbitraria di significatività, ma fornisce un quadro probabilistico della forza dell’effetto, evitando distorsioni dovute alla pubblicazione selettiva.\n\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nIn questo esercizio simuleremo più esperimenti, ognuno con 15 osservazioni, per comprendere come il filtro della significatività statistica possa distorcere le nostre conclusioni sugli effetti osservati.\nObiettivo\n\nComprendere come l’approccio frequentista possa portare a stime errate dell’effetto reale.\nEsplorare gli errori di tipo M (magnitude) e S (sign), derivanti dal filtro della significatività statistica.\n\nStruttura dell’esercizio\n\nSimuliamo esperimenti in cui il vero effetto tra due gruppi è piccolo (Cohen’s d = 0.2). Consideriamo i dati SWLS e due popolazioni che differiscono nel modo indicato. Ipotizziamo che le due popolazioni SWLS siano normali.\nEstraiamo 15 osservazioni per gruppo.\nUsiamo un test t per verificare se la differenza tra i gruppi è significativa.\nRegistriamo solo i risultati con p &lt; 0.05, calcolando la distribuzione degli effetti significativi.\nValutiamo se la stima dell’effetto nei risultati pubblicabili è gonfiata rispetto al vero effetto.\nContiamo i casi in cui il segno dell’effetto è invertito.\n\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\n# Librerie necessarie\nlibrary(ggplot2)\n\n# Impostazioni della simulazione\nset.seed(42)         # Per la riproducibilità\nn_sims &lt;- 50000      # Numero di simulazioni\nn_per_group &lt;- 15    # Numero di osservazioni per gruppo\ntrue_d &lt;- 0.2        # Vero effetto (Cohen's d)\nswls_mean &lt;- 25      # Media ipotizzata per il primo gruppo\nswls_sd &lt;- 5         # Deviazione standard ipotizzata per la SWLS\n\n# Calcolo della media del secondo gruppo sulla base di Cohen's d\nswls_mean_2 &lt;- swls_mean + true_d * swls_sd\n\n# Inizializziamo i vettori per registrare i risultati\neffect_sizes &lt;- c()\nfalse_sign_count &lt;- 0\n\n# Simulazioni\nfor (i in 1:n_sims) {\n  # Generazione dei due gruppi da distribuzioni normali\n  group1 &lt;- rnorm(n_per_group, mean = swls_mean, sd = swls_sd)\n  group2 &lt;- rnorm(n_per_group, mean = swls_mean_2, sd = swls_sd)\n  \n  # Calcolo della dimensione dell'effetto (Cohen's d)\n  mean_diff &lt;- mean(group2) - mean(group1)\n  pooled_sd &lt;- sqrt(((n_per_group - 1) * var(group1) + (n_per_group - 1) * var(group2)) / (2 * n_per_group - 2))\n  d_estimated &lt;- mean_diff / pooled_sd\n  \n  # Test t per confrontare le medie\n  t_test &lt;- t.test(group1, group2, var.equal = TRUE)\n  \n  # Consideriamo solo i risultati statisticamente significativi\n  if (t_test$p.value &lt; 0.05) {\n    effect_sizes &lt;- c(effect_sizes, d_estimated)\n    \n    # Conta i casi in cui il segno è invertito\n    if (d_estimated &lt; 0) {\n      false_sign_count &lt;- false_sign_count + 1\n    }\n  }\n}\n\n# Creazione di un dataframe per la visualizzazione\nres_df &lt;- data.frame(effect_size = effect_sizes)\n\n# Istogramma della dimensione dell'effetto tra i risultati \"significativi\"\nggplot(res_df, aes(x = effect_size)) +\n  geom_histogram(bins = 30, fill = \"blue\", color = \"black\", alpha = 0.7) +\n  geom_vline(xintercept = true_d, color = \"red\", linetype = \"dashed\", size = 1.2) +\n  labs(\n    x = \"Dimensione dell'effetto stimata\",\n    y = \"Frequenza\",\n    title = \"Distribuzione degli effetti significativi (SWLS)\"\n  ) +\n  theme_minimal()\n\n# Output di sintesi\ncat(\"Numero di risultati statisticamente significativi:\", length(effect_sizes), \"\\n\")\ncat(\"Media della dimensione dell'effetto tra i risultati pubblicati:\", mean(effect_sizes), \"\\n\")\ncat(\"Numero di risultati con segno invertito:\", false_sign_count, \"\\n\")\ncat(\"Proporzione di risultati con segno invertito:\", false_sign_count / length(effect_sizes), \"\\n\")\nInterpretazione dei Risultati\n\n\nErrore di tipo M (Magnitude): La media degli effetti stimati nei risultati pubblicati sarà molto più grande di 0.2 (il vero effetto), dimostrando come il filtro della significatività tenda a sovrastimare gli effetti reali.\n\nErrore di tipo S (Sign): Una percentuale dei risultati pubblicabili mostrerà effetti nella direzione sbagliata (d &lt; 0), dimostrando che il processo decisionale basato su p &lt; 0.05 può portare a conclusioni errate.\n\nVisualizzazione: L’istogramma mostrerà che la distribuzione degli effetti significativi è spostata rispetto al vero effetto (linea rossa tratteggiata).\n\nDomande di discussione:\n\nPerché la stima dell’effetto è gonfiata nei risultati pubblicabili?\nCome cambia la situazione aumentando il numero di osservazioni per gruppo?\nQuali strategie alternative potrebbero ridurre questi errori?\n\nApprofondimento:\n\nRipetere l’esperimento con n_per_group = 50 e osservare se l’errore di tipo M diminuisce.\nConfrontare questo approccio con un’analisi Bayesiana per evidenziare il ruolo dell’inferenza basata su probabilità posteriori.\n\nConclusione\nQuesto esercizio mostra chiaramente i problemi dell’approccio frequentista basato su p &lt; 0.05, evidenziando i limiti dell’uso della significatività statistica come filtro decisionale.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>94</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/replication_crisis/04_s_m_errors.html#informazioni-sullambiente-di-sviluppo",
    "title": "94  Errori di segno e errori di grandezza",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.7   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.13.0 psych_2.5.3     \n#&gt;  [9] scales_1.4.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.3.0     ggplot2_3.5.2   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.4     stringi_1.8.7      lattice_0.22-7    \n#&gt;  [4] hms_1.1.3          digest_0.6.37      magrittr_2.0.3    \n#&gt;  [7] evaluate_1.0.4     grid_4.5.0         timechange_0.3.0  \n#&gt; [10] RColorBrewer_1.1-3 fastmap_1.2.0      rprojroot_2.0.4   \n#&gt; [13] jsonlite_2.0.0     mnormt_2.1.1       cli_3.6.5         \n#&gt; [16] rlang_1.1.6        withr_3.0.2        yaml_2.3.10       \n#&gt; [19] tools_4.5.0        parallel_4.5.0     tzdb_0.5.0        \n#&gt; [22] pacman_0.5.1       vctrs_0.6.5        R6_2.6.1          \n#&gt; [25] lifecycle_1.0.4    htmlwidgets_1.6.4  pkgconfig_2.0.3   \n#&gt; [28] pillar_1.10.2      gtable_0.3.6       glue_1.8.0        \n#&gt; [31] xfun_0.52          tidyselect_1.2.1   rstudioapi_0.17.1 \n#&gt; [34] farver_2.1.2       htmltools_0.5.8.1  nlme_3.1-168      \n#&gt; [37] labeling_0.4.3     rmarkdown_2.29     compiler_4.5.0",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>94</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#bibliografia",
    "href": "chapters/replication_crisis/04_s_m_errors.html#bibliografia",
    "title": "94  Errori di segno e errori di grandezza",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., & Carlin, J. (2014). Beyond Power Calculations: Assessing Type S (Sign) and Type M (Magnitude) Errors. Perspectives on Psychological Science, 9(6), 641–651.\n\n\nLoken, E., & Gelman, A. (2017). Measurement Error and the Replication Crisis. Science, 355(6325), 584–585.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nNelson, L. D., Simmons, J., & Simonsohn, U. (2018). Psychology’s renaissance. Annual review of psychology, 69(1), 511–534.\n\n\nWagenmakers, E.-J., Lee, M., Lodewyckx, T., & Iverson, G. J. (2008). Bayesian versus frequentist inference. Bayesian evaluation of informative hypotheses, 181–207.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>94</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_p_values.html",
    "href": "chapters/replication_crisis/05_p_values.html",
    "title": "\n95  La fragilità del p-valore\n",
    "section": "",
    "text": "95.1 Introduzione\nQuesto capitolo analizza la fragilità dei valori-\\(p\\) e la loro variabilità in diversi campioni. Attraverso una simulazione, dimostreremo come l’uso dei valori-\\(p\\) come criterio per valutare la rilevanza sostanziale di un risultato costituisca un errore metodologico. L’analisi si basa su un approccio critico ispirato da una discussione proposta da Andrew Gelman nel suo blog.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>95</span>  <span class='chapter-title'>La fragilità del *p*-valore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_p_values.html#simulazione",
    "href": "chapters/replication_crisis/05_p_values.html#simulazione",
    "title": "\n95  La fragilità del p-valore\n",
    "section": "\n95.2 Simulazione",
    "text": "95.2 Simulazione\nQuesta simulazione mira a dimostrare quanto i valori-\\(p\\) possano essere instabili e variare notevolmente da campione a campione, anche quando i dati provengono dalla stessa distribuzione. Ciò evidenzia come il valore-\\(p\\), comunemente utilizzato per valutare la significatività statistica di un effetto, possa essere fortemente influenzato dalla variabilità campionaria, specialmente in campioni di piccole dimensioni o con effetti deboli. Gelman & Stern (2006) esprimono questo concetto affermando che:\n\nLa differenza tra “significativo” e “non significativo” non è di per sé statisticamente significativa.\n\n\n95.2.1 Logica della Simulazione\n\n\nObiettivo:\n\nDimostrare la variabilità dei valori-\\(p\\) calcolati su diversi campioni estratti da una popolazione con una media molto vicina a zero.\nMostrare come, nonostante l’effetto reale sia piccolo, i valori-\\(p\\) possano variare notevolmente a seconda della variabilità della popolazione e delle dimensioni del campione.\n\n\n\nSetup della Simulazione:\n\nGeneriamo \\(J = 10\\) campioni indipendenti, ciascuno con un numero ridotto di osservazioni (\\(n = 10\\)), per massimizzare la variabilità dei risultati.\nOgni campione è generato da una distribuzione normale con una media vera di \\(\\mu = 0.05\\) e una deviazione standard di \\(\\sigma = 0.1\\). Questi parametri sono scelti per rendere la media dei campioni vicina a zero, mantenendo una certa variabilità.\n\n\n\nCalcolo della media campionaria:\n\nPer ciascun campione, calcoliamo la media (\\(\\hat{\\mu}\\)) e la deviazione standard (\\(\\hat{\\sigma}\\)).\nLa media del campione (\\(\\hat{\\mu}\\)) è utilizzata come stima del parametro.\n\n\n\nCalcolo del valore-\\(p\\):\n\nApplichiamo un \\(t\\)-test per ciascun campione per verificare l’ipotesi nulla (\\(H_0\\)) che la media del campione sia zero.\n\nIl valore-\\(p\\) viene calcolato utilizzando la formula classica del \\(t\\)-test:\n\\[\nt = \\frac{\\hat{\\mu}}{\\frac{\\hat{\\sigma}}{\\sqrt{n}}}\n\\]\ndove:\n\n\n\\(\\hat{\\mu}\\) è la media del campione,\n\n\\(\\hat{\\sigma}\\) è la deviazione standard del campione,\n\n\\(n\\) è il numero di osservazioni per campione.\n\n\n\nSuccessivamente, il valore-\\(p\\) è calcolato come:\n\\[\n\\text{p-value} = 2 \\times (1 - \\text{CDF}(|t|))\n\\]\ndove \\(\\text{CDF}\\) è la funzione cumulativa della distribuzione \\(t\\) con \\(n-1\\) gradi di libertà.\n\n\n\n\n95.2.2 Descrizione della Sintassi\nIl codice R è strutturato come segue:\n\n\nGenerazione dei campioni:\n\nCreiamo una lista di campioni (10 campioni in totale), ciascuno con 10 osservazioni, utilizzando la distribuzione normale con media 0.05 e deviazione standard 0.1.\n\n\n\nCalcolo delle medie e dei valori-\\(p\\):\n\nIteriamo su ciascun campione per calcolare la media (\\(\\hat{\\mu}\\)) e la deviazione standard (\\(\\hat{\\sigma}\\)).\nCalcoliamo il valore statistico \\(t\\) e il corrispondente valore-\\(p\\) utilizzando la distribuzione \\(t\\).\n\n\n\nStampa dei risultati:\n\nI valori-\\(p\\) vengono arrotondati e stampati per osservare la loro variabilità.\n\n\n\n\n# Imposta il seme per riproducibilità\nset.seed(1234)\n\n# Parametri della simulazione\nJ &lt;- 10              # Numero di campioni indipendenti\nn &lt;- 10              # Numero di osservazioni per campione\ntrue_mean &lt;- 0.05    # Media vera della popolazione\ntrue_sd &lt;- 0.1       # Deviazione standard della popolazione\n\n# Genera i campioni casuali\nsamples &lt;- replicate(J, rnorm(n, mean = true_mean, sd = true_sd), simplify = FALSE)\n\n# Calcola statistiche campionarie e p-valori\nresults &lt;- lapply(samples, function(sample) {\n  sample_mean &lt;- mean(sample)                         # Media campionaria\n  sample_sd &lt;- sd(sample)                             # Deviazione standard campionaria\n  t_statistic &lt;- sample_mean / (sample_sd / sqrt(n))  # Statistica t\n  p_value &lt;- 2 * (1 - pt(abs(t_statistic), df = n - 1))  # valore-$p$ bilaterale\n  list(mean = sample_mean, sd = sample_sd, t = t_statistic, p_value = p_value)\n})\n\n# Converti i risultati in un data frame per facilitarne la visualizzazione\nresults_df &lt;- do.call(rbind, lapply(results, as.data.frame))\nrownames(results_df) &lt;- paste(\"C\", 1:J)\n\n# Visualizza i risultati\nprint(results_df)\n#&gt;          mean      sd       t  p_value\n#&gt; C 1   0.01168 0.09958  0.3711 0.719183\n#&gt; C 2   0.03818 0.10673  1.1313 0.287183\n#&gt; C 3   0.01121 0.06660  0.5320 0.607576\n#&gt; C 4  -0.02662 0.08942 -0.9413 0.371116\n#&gt; C 5  -0.01098 0.07872 -0.4411 0.669552\n#&gt; C 6   0.02211 0.11860  0.5896 0.569941\n#&gt; C 7   0.11166 0.11442  3.0860 0.013013\n#&gt; C 8   0.04577 0.09237  1.5670 0.151566\n#&gt; C 9   0.03415 0.07349  1.4695 0.175755\n#&gt; C 10  0.10607 0.09840  3.4089 0.007763\n\n\nggplot(results_df, aes(x = rownames(results_df), y = p_value)) +\n  geom_point(size = 3, color = \"blue\") +\n  geom_hline(yintercept = 0.05, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Variabilità dei p-valori nei campioni\",\n    x = \"Campioni\",\n    y = \"valore-$p$\"\n  ) \n\n\n\n\n\n\n\n\n95.2.3 Interpretazione dei Risultati\nIn un tipico esperimento, i risultati potrebbero variare notevolmente tra i diversi campioni analizzati. Alcuni campioni potrebbero essere pienamente compatibili con il rumore statistico, mentre altri potrebbero suggerire lievi evidenze contro l’ipotesi nulla. Altri ancora potrebbero addirittura apparire altamente significativi dal punto di vista statistico.\nTuttavia, la differenza tra ‘statisticamente significativo’ e ‘non significativo’ non sempre corrisponde a una distinzione scientificamente rilevante nel fenomeno studiato. Ad esempio, un valore-\\(p\\) di 0.003 potrebbe sembrare drasticamente diverso da uno di 0.336, ma questa discrepanza, di per sé, non implica un’effettiva differenza sostanziale.\nQuesta situazione estrema emerge quando non esiste alcuna vera variazione sottostante tra i campioni. In tali casi, un modello multilivello rivelerebbe che le apparenti differenze osservate non rappresentano un’effettiva variabilità degna di interesse, ma fluttuazioni casuali intorno a un effetto nullo.\n\n95.2.4 Punti Chiave\n\nIl valore-\\(p\\) descrive solo l’ipotesi nulla: È una misura relativa all’assenza di effetto, ma non ha necessariamente un significato diretto rispetto a un effetto reale, anche se piccolo.\nIl valore-\\(p\\) è altamente variabile: Essendo una trasformazione non lineare dello z-score, il valore-\\(p\\) può comportarsi in modi non intuitivi, soprattutto con campioni piccoli.\nLe simulazioni sono istruttive: Anche esperimenti semplici come questo possono essere estremamente utili per comprendere le limitazioni e l’interpretazione dei risultati.\n\n95.2.5 Un Avvertimento Importante\nAnche le inferenze bayesiane sono soggette a variabilità. Qualsiasi sintesi dei dati porta con sé un certo grado di incertezza. Il problema non risiede nei valori-\\(p\\) in sé, ma nel loro utilizzo scorretto. Interpretare un valore-\\(p\\) come una dichiarazione forte sulla realtà, invece di considerarlo un riassunto rumoroso di un esperimento specifico, è un errore comune.\nAllo stesso modo, fraintendimenti e sovrainterpretazioni possono verificarsi anche con approcci bayesiani. Ad esempio, l’adattamento di un modello con prior non informativi e l’interpretazione della probabilità posteriore di un parametro (ad esempio, maggiore di zero) sulla base di una soglia arbitraria può portare a conclusioni altrettanto problematiche. Questi risultati ci ricordano l’importanza di una sana cautela nell’interpretazione statistica, indipendentemente dal metodo utilizzato.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>95</span>  <span class='chapter-title'>La fragilità del *p*-valore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_p_values.html#riflessioni-conclusive",
    "href": "chapters/replication_crisis/05_p_values.html#riflessioni-conclusive",
    "title": "\n95  La fragilità del p-valore\n",
    "section": "\n95.3 Riflessioni Conclusive",
    "text": "95.3 Riflessioni Conclusive\nLa simulazione mostra che, nonostante le medie dei campioni siano generate con una distribuzione simile, i valori-\\(p\\) possono variare drasticamente. Questo effetto è amplificato dalla scelta di campioni piccoli e di una media vera molto vicina all’ipotesi nulla (zero). Ciò dimostra quanto il valore-\\(p\\) possa essere influenzato da piccole variazioni nei dati e perché non sia sempre un indicatore affidabile per valutare l’efficacia o la presenza di un effetto.\nIn generale, la domanda importante dal punto di vista scientifico non è se in un particolare campione è stato ottenuto un risultato statisticamente significativo, ma se l’effetto osservato in quel campione sia generalizzabile ad altri campioni e a dati futuri. Solo in questo secondo caso possiamo concludere, con un certo grado di certezza, di aver compreso qualcosa di rilevante sul fenomeno studiato.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>95</span>  <span class='chapter-title'>La fragilità del *p*-valore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_p_values.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/replication_crisis/05_p_values.html#informazioni-sullambiente-di-sviluppo",
    "title": "\n95  La fragilità del p-valore\n",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.7   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.1  bayesplot_1.13.0 psych_2.5.6     \n#&gt;  [9] scales_1.4.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.1.0     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.3.0     ggplot2_3.5.2   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.4     stringi_1.8.7      lattice_0.22-7    \n#&gt;  [4] hms_1.1.3          digest_0.6.37      magrittr_2.0.3    \n#&gt;  [7] evaluate_1.0.4     grid_4.5.1         timechange_0.3.0  \n#&gt; [10] RColorBrewer_1.1-3 fastmap_1.2.0      rprojroot_2.1.0   \n#&gt; [13] jsonlite_2.0.0     mnormt_2.1.1       cli_3.6.5         \n#&gt; [16] rlang_1.1.6        withr_3.0.2        tools_4.5.1       \n#&gt; [19] parallel_4.5.1     tzdb_0.5.0         pacman_0.5.1      \n#&gt; [22] vctrs_0.6.5        R6_2.6.1           lifecycle_1.0.4   \n#&gt; [25] htmlwidgets_1.6.4  pkgconfig_2.0.3    pillar_1.11.0     \n#&gt; [28] gtable_0.3.6       glue_1.8.0         xfun_0.52         \n#&gt; [31] tidyselect_1.2.1   rstudioapi_0.17.1  farver_2.1.2      \n#&gt; [34] htmltools_0.5.8.1  nlme_3.1-168       labeling_0.4.3    \n#&gt; [37] rmarkdown_2.29     compiler_4.5.1",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>95</span>  <span class='chapter-title'>La fragilità del *p*-valore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_p_values.html#bibliografia",
    "href": "chapters/replication_crisis/05_p_values.html#bibliografia",
    "title": "\n95  La fragilità del p-valore\n",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., & Stern, H. (2006). The difference between «significant» and «not significant» is not itself statistically significant. The American Statistician, 60(4), 328–331.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>95</span>  <span class='chapter-title'>La fragilità del *p*-valore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html",
    "href": "chapters/replication_crisis/06_changes.html",
    "title": "96  Riforma",
    "section": "",
    "text": "96.1 Introduzione\nLa crisi della riproducibilità ha stimolato un profondo dibattito sullo stato della ricerca nelle scienze comportamentali, cognitive e sociali. La scoperta che molti studi pubblicati non sono replicabili ha minato la fiducia nella ricerca scientifica, evidenziando carenze metodologiche e strutturali nel sistema accademico. In risposta a questa crisi, sono state avanzate diverse proposte di riforma per migliorare la qualità e l’affidabilità della ricerca scientifica.\nSecondo Korbmacher et al. (2023), sono necessarie riforme strutturali, cambiamenti procedurali e trasformazioni nella comunità scientifica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>96</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#riforme-strutturali",
    "href": "chapters/replication_crisis/06_changes.html#riforme-strutturali",
    "title": "96  Riforma",
    "section": "96.2 Riforme Strutturali",
    "text": "96.2 Riforme Strutturali\n\n96.2.1 Integrazione della Riproducibilità nei Curriculum Educativi\nUna proposta chiave per affrontare la crisi della riproducibilità è l’integrazione delle pratiche di riproducibilità nei curriculum delle scienze psicologiche e affini. Attualmente, molti programmi di formazione non enfatizzano sufficientemente l’importanza della replicabilità e della trasparenza nella ricerca. Includere questi temi nei corsi di metodologia della ricerca può sensibilizzare le nuove generazioni di ricercatori sull’adozione di pratiche più rigorose e trasparenti. Alcuni programmi universitari hanno già iniziato a incorporare repliche di studi famosi nel percorso formativo, offrendo agli studenti l’opportunità di comprendere meglio i limiti e le potenzialità del processo scientifico.\n\n\n96.2.2 Incentivi per la Scienza Aperta\nUn altro aspetto cruciale è la riforma dei sistemi di incentivazione accademica. Tradizionalmente, il sistema accademico ha privilegiato la quantità di pubblicazioni e la novità dei risultati, piuttosto che la loro qualità e replicabilità. Per promuovere pratiche di scienza aperta, come la preregistrazione degli studi e la condivisione aperta dei dati, si propone l’introduzione di riconoscimenti ufficiali, come badge di “open science” o crediti accademici per la pubblicazione di rapporti registrati. Questi cambiamenti potrebbero favorire una maggiore adozione di pratiche che promuovono la trasparenza e rafforzano la fiducia nella ricerca scientifica.\nA tal proposito, uno studio di Scheel et al. (2021) ha confrontato i risultati di rapporti registrati pubblicati (N = 71) con un campione casuale di studi ipotetico-deduttivi della letteratura standard (N = 152) in psicologia. Analizzando la prima ipotesi di ciascun articolo, è emerso che il 96% dei risultati nei rapporti standard erano positivi, contro solo il 44% nei rapporti registrati.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>96</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#cambiamenti-procedurali",
    "href": "chapters/replication_crisis/06_changes.html#cambiamenti-procedurali",
    "title": "96  Riforma",
    "section": "96.3 Cambiamenti Procedurali",
    "text": "96.3 Cambiamenti Procedurali\n\n96.3.1 Mercati di Previsione per la Credibilità della Ricerca\nI mercati di previsione sono stati proposti come strumento innovativo per valutare la credibilità della ricerca. In questi mercati, esperti e non esperti scommettono sulla probabilità che i risultati di determinati studi siano replicabili. Questo approccio ha dimostrato un’elevata accuratezza nella classificazione della replicabilità degli studi, offrendo un metodo alternativo e complementare alla replicazione diretta. I mercati di previsione potrebbero essere particolarmente utili in contesti in cui la raccolta dati è costosa o difficile, fornendo una prima indicazione sulla solidità dei risultati di ricerca.\n\n\n96.3.2 Strumenti di Valutazione Statistica\nUn’altra proposta riguarda l’adozione di nuovi strumenti di valutazione statistica per identificare e correggere il bias di pubblicazione e migliorare la potenza degli studi. Strumenti come la curva-p e la curva-z sono stati sviluppati per analizzare la distribuzione dei valori p e identificare eventuali distorsioni nei risultati pubblicati. Inoltre, alcuni studiosi hanno suggerito di abbassare il livello di significatività statistica standard da 0,05 a 0,005 per ridurre il tasso di falsi positivi e aumentare la robustezza dei risultati. Queste proposte rappresentano passi importanti verso una maggiore precisione nelle analisi statistiche.\n\n\n96.3.3 Analisi Multiverso\nL’analisi multiverso è un’altra proposta innovativa che mira a gestire la molteplicità di scelte analitiche possibili in un singolo studio. Questa tecnica prevede l’esecuzione di molteplici analisi su uno stesso dataset, variando i parametri e le scelte metodologiche, per testare la stabilità dei risultati. L’adozione di questo approccio permette di evidenziare quanto i risultati siano sensibili alle scelte analitiche, contribuendo a una maggiore trasparenza e affidabilità nelle conclusioni tratte dagli studi.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>96</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#cambiamenti-nella-comunità",
    "href": "chapters/replication_crisis/06_changes.html#cambiamenti-nella-comunità",
    "title": "96  Riforma",
    "section": "96.4 Cambiamenti nella Comunità",
    "text": "96.4 Cambiamenti nella Comunità\n\n96.4.1 Big Team Science\nIl concetto di “Big Team Science” rappresenta un cambiamento significativo nella modalità di condurre ricerca. Questo approccio prevede la collaborazione su larga scala tra scienziati di diversi paesi e discipline, con l’obiettivo di replicare studi, raccogliere grandi campioni e condividere risorse. Questo modello di lavoro collettivo non solo aumenta l’efficienza della ricerca, ma promuove anche una maggiore diversità nei campioni e nei team di ricerca. Tuttavia, esistono anche criticità, come la possibilità di perpetuare disuguaglianze tra ricercatori di paesi sviluppati e in via di sviluppo, e la difficoltà nel riconoscere adeguatamente i contributi individuali all’interno di grandi consorzi.\n\n\n96.4.2 Collaborazioni Avversariali\nLe collaborazioni avversariali rappresentano un altro approccio interessante per migliorare la qualità della ricerca. In queste collaborazioni, ricercatori con visioni teoriche contrastanti lavorano insieme per progettare e condurre studi che testino le loro ipotesi in modo rigoroso. Questo tipo di collaborazione può ridurre i bias personali e promuovere un confronto costruttivo, portando a conclusioni più solide e condivise all’interno della comunità scientifica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>96</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#crisi-della-generalizzabilità",
    "href": "chapters/replication_crisis/06_changes.html#crisi-della-generalizzabilità",
    "title": "96  Riforma",
    "section": "96.5 Crisi della Generalizzabilità",
    "text": "96.5 Crisi della Generalizzabilità\nYarkoni (2022) affronta la questione critica della scarsa validità delle inferenze quantitative presenti nella letteratura psicologica pubblicata, proponendo tre strategie principali per migliorare la qualità della ricerca in psicologia.\n\n96.5.1 Do Something Else\nIl primo suggerimento è di considerare l’abbandono della ricerca psicologica quantitativa quando risulta troppo difficile estrarre conclusioni significative e generalizzabili da effetti complessi e variabili. L’autore critica la tendenza a concludere ogni contributo di ricerca con una nota positiva, indipendentemente dalle evidenze raccolte. In alcuni casi, potrebbe essere più saggio riconoscere i limiti della ricerca e scegliere percorsi di carriera alternativi, specialmente per i ricercatori alle prime armi.\n\n\n96.5.2 Abbracciare l’Analisi Qualitativa\nLa seconda opzione proposta è continuare a fare ricerca psicologica, ma abbandonando in gran parte i metodi statistici inferenziali a favore di metodi qualitativi. L’autore sostiene che gran parte della scienza quantitativa in psicologia sia in realtà un’analisi qualitativa mascherata. In molti casi, l’analisi qualitativa potrebbe fornire risposte più profonde e significative rispetto a un approccio quantitativo superficiale.\n\n\n96.5.3 Adottare Standard Migliori\nLa terza strategia consiste nel migliorare gli standard della ricerca quantitativa in psicologia per renderla più rigorosa e affidabile. L’autore propone diverse pratiche, tra cui:\n\nInferenze più conservative: Evitare generalizzazioni ampie basate su dati limitati.\nRicerca descrittiva: Prendere più seriamente la ricerca descrittiva, che si concentra sulla caratterizzazione delle relazioni tra variabili.\nModelli statistici più espansivi: Utilizzare modelli che considerino una più ampia gamma di variabili e fattori.\nProgettare con la variazione in mente: Abbracciare la variabilità naturale delle condizioni sperimentali.\nStime della varianza: Porre maggiore enfasi sull’analisi delle componenti della varianza.\nPredizioni più rischiose: Formulare predizioni teoriche che comportino un alto grado di rischio.\nUtilità predittiva pratica: Concentrarsi sull’utilità pratica delle predizioni piuttosto che su considerazioni puramente teoriche.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>96</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#sviluppare-teorie-formali",
    "href": "chapters/replication_crisis/06_changes.html#sviluppare-teorie-formali",
    "title": "96  Riforma",
    "section": "96.6 Sviluppare Teorie Formali",
    "text": "96.6 Sviluppare Teorie Formali\nOltre alle carenze metodologiche o statistiche, è stato spesso sottolineato che la crisi di replicabilità trova le sue radici nella mancanza di un quadro teorico cumulativo. Senza un quadro teorico generale che generi ipotesi in diversi ambiti, i programmi empirici si sviluppano a partire da intuizioni personali e teorie popolari influenzate culturalmente. Fornendo strumenti per formulare previsioni chiare, anche attraverso l’uso di modelli formali, i quadri teorici stabiliscono aspettative che permettono di determinare se un nuovo risultato conferma le ricerche esistenti, integrandosi con esse, oppure se è inaspettato e, pertanto, richiede ulteriori verifiche e approfondimenti (Muthukrishna & Henrich, 2019).",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>96</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#riflessioni-conclusive",
    "href": "chapters/replication_crisis/06_changes.html#riflessioni-conclusive",
    "title": "96  Riforma",
    "section": "96.7 Riflessioni Conclusive",
    "text": "96.7 Riflessioni Conclusive\nL’ampio utilizzo dei test statistici frequentisti in psicologia risulta spesso fuorviante, poiché attribuisce un’apparenza di rigore scientifico a inferenze che, in realtà, sono principalmente qualitative. Si rende quindi necessaria una profonda riforma delle pratiche di ricerca, volta a promuovere una maggiore trasparenza e precisione, oltre a incoraggiare la disponibilità a mettere in discussione e abbandonare approcci metodologici che non superano una rigorosa analisi critica (Yarkoni, 2022).\nLa crisi di replicabilità ha spinto verso una serie di riforme con il potenziale di trasformare positivamente la ricerca psicologica. Tra queste iniziative vi sono la promozione della scienza aperta, l’adozione di standard metodologici più rigorosi e una maggiore attenzione a pratiche di ricerca che privilegiano la qualità e la replicabilità dei risultati rispetto alla loro quantità e novità. Sebbene questi cambiamenti possano sembrare meno spettacolari rispetto ai metodi attualmente utilizzati, essi rappresentano un percorso fondamentale per garantire la credibilità e la sostenibilità a lungo termine della disciplina.\nAffinché queste riforme abbiano un impatto duraturo, è essenziale un cambiamento strutturale a tutti i livelli della comunità scientifica:\n\nI ricercatori devono impegnarsi ad adottare pratiche più rigorose e trasparenti, privilegiando la solidità metodologica e la replicabilità dei loro studi.\nGli enti finanziatori devono incentivare la qualità e la replicabilità degli studi, piuttosto che premiare esclusivamente la produzione di risultati innovativi o appariscenti.\nLe istituzioni accademiche devono rivedere i criteri di valutazione del merito scientifico, dando maggior peso all’impatto a lungo termine delle ricerche e alla loro solidità metodologica.\nLe riviste scientifiche devono assicurarsi che i risultati pubblicati siano realmente robusti e generalizzabili, anziché limitarsi a privilegiare i risultati nuovi o sorprendenti.\n\nQuesti cambiamenti, sebbene complessi e talvolta impopolari, sono fondamentali per ristabilire la fiducia nel processo scientifico e per garantire che la ricerca psicologica continui a offrire contributi utili e affidabili nella comprensione della mente umana e del comportamento.\nIn conclusione, la sfida posta dalla crisi di replicabilità offre un’opportunità unica per ridefinire e rafforzare le fondamenta metodologiche della ricerca psicologica. Abbracciando questi cambiamenti, la psicologia può emergere come una disciplina più robusta, trasparente e affidabile, capace di fornire intuizioni utili e durature sul funzionamento della mente e del comportamento umano.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>96</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#bibliografia",
    "href": "chapters/replication_crisis/06_changes.html#bibliografia",
    "title": "96  Riforma",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nKorbmacher, M., Azevedo, F., Pennington, C. R., Hartmann, H., Pownall, M., Schmidt, K., Elsherif, M., Breznau, N., Robertson, O., Kalandadze, T., et al. (2023). The replication crisis has led to positive structural, procedural, and community changes. Communications Psychology, 1(1), 3.\n\n\nMuthukrishna, M., & Henrich, J. (2019). A problem in theory. Nature Human Behaviour, 3(3), 221–229.\n\n\nScheel, A. M., Schijen, M. R., & Lakens, D. (2021). An excess of positive results: Comparing the standard psychology literature with registered reports. Advances in Methods and Practices in Psychological Science, 4(2), 25152459211007467.\n\n\nYarkoni, T. (2022). The generalizability crisis. Behavioral and Brain Sciences, 45, e1.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>96</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_piranha.html",
    "href": "chapters/replication_crisis/07_piranha.html",
    "title": "97  Il Problema del priming: sfide e paradossi nella psicologia sociale",
    "section": "",
    "text": "97.1 Introduzione\nUn recente articolo di Tosh et al. (2025) affronta una questione centrale per la psicologia e la crisi della replicabilità: il cosiddetto “problema del piranha”. Questo argomento riguarda la convinzione, diffusa in molti studi psicologici, che piccoli interventi (o “nudges”), apparentemente insignificanti, possano generare effetti notevoli sul comportamento. L’articolo dimostra formalmente, con il supporto del teorema di Van der Corput (Tao, 2014), che se tali effetti fossero davvero così grandi e consistenti, allora sarebbe possibile manipolare il comportamento umano in modi empiricamente irrealistici.\nIn altre parole, la letteratura psicologica spesso riporta effetti di dimensioni tali che richiederebbero assunzioni incompatibili con le evidenze empiriche. Questi risultati suggeriscono che le affermazioni di grandi effetti indipendenti sono più probabilmente attribuibili a problemi metodologici, come bassa potenza statistica o “gradi di libertà del ricercatore” (Simmons et al., 2011).",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>97</span>  <span class='chapter-title'>Il Problema del priming: sfide e paradossi nella psicologia sociale</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_piranha.html#il-problema-del-piranha",
    "href": "chapters/replication_crisis/07_piranha.html#il-problema-del-piranha",
    "title": "97  Il Problema del priming: sfide e paradossi nella psicologia sociale",
    "section": "97.2 Il problema del piranha",
    "text": "97.2 Il problema del piranha\nTosh et al. (2025) evidenziano che, in un sistema complesso, se molte variabili esplicative hanno un forte impatto su una singola variabile di esito, queste devono inevitabilmente mostrare interazioni o correlazioni rilevanti tra loro.\n\n97.2.1 Punti chiave del problema\n\nEffetti ampi e interazioni: Il “problema del piranha” sottolinea che è improbabile che molte variabili esplicative abbiano effetti ampi e indipendenti su una singola variabile di esito all’interno di un sistema stabile. Questo principio si basa sulla disuguaglianza di Van der Corput, che dimostra come l’aumento del numero di variabili con grandi effetti richieda una considerazione delle loro interazioni. Tali interazioni generano una rete complessa di influenze, rendendo difficile isolare l’impatto di un singolo fattore. Gli effetti osservati in un dato studio potrebbero non essere generalizzabili, poiché dipendono dai livelli di altre variabili presenti nello stesso contesto.\nAnalogia con i piranha: L’analogia del piranha descrive un sistema sovraffollato di variabili esplicative con grandi effetti, che interagiscono tra loro fino a ridurre la stabilità complessiva. Proprio come i piranha in un acquario competono tra loro fino a ridurre il loro numero, un sistema con molte variabili di forte impatto tende a generare interazioni che limitano la prevedibilità e la stabilità del sistema. In altre parole, gli effetti individuali vengono alterati, ridotti o cancellati attraverso la competizione tra variabili.\n\n\n\n97.2.2 Rilevanza per la crisi di replicabilità\nIl problema del piranha offre una prospettiva cruciale per comprendere le cause della crisi di replicabilità nella psicologia e nelle scienze sociali. Secondo Tosh et al. (2025), questa crisi non è attribuibile soltanto a problemi metodologici come la bassa potenza statistica, ma riflette un limite intrinseco dell’idea stessa che numerosi grandi effetti indipendenti possano coesistere in un sistema complesso.\nI teoremi discussi nell’articolo dimostrano che un sistema stabile non può contenere numerosi effetti forti e indipendenti senza generare predizioni empiricamente insostenibili. Ciò implica che la ricerca di molteplici “grandi effetti” rischia di essere basata su assunzioni irrealistiche riguardo alla natura delle interazioni tra variabili.\nIl problema del piranha è particolarmente rilevante per la psicologia, dove spesso si cercano numerose cause indipendenti per spiegare fenomeni complessi. Tosh et al. (2025) mettono in discussione non tanto i singoli effetti riportati, quanto l’assunzione di base secondo cui il comportamento umano e le interazioni sociali sarebbero influenzati da un gran numero di effetti indipendenti.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>97</span>  <span class='chapter-title'>Il Problema del priming: sfide e paradossi nella psicologia sociale</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_piranha.html#il-priming-nella-psicologia-sociale",
    "href": "chapters/replication_crisis/07_piranha.html#il-priming-nella-psicologia-sociale",
    "title": "97  Il Problema del priming: sfide e paradossi nella psicologia sociale",
    "section": "97.3 Il priming nella psicologia sociale",
    "text": "97.3 Il priming nella psicologia sociale\nUno degli esempi analizzati da Tosh et al. (2025) riguarda la ricerca sul priming sociale, una linea di indagine ampiamente discussa e criticata nella psicologia sociale (si veda anche Leys, 2024). Gli autori utilizzano uno studio classico per illustrare le loro argomentazioni: un esperimento del 1996 condotto da Bargh et al. (1996), in cui i partecipanti riorganizzavano frasi contenenti parole associate alla vecchiaia (ad esempio, “Florida” o “solo”). I risultati riportavano che questi partecipanti camminavano più lentamente rispetto a un gruppo di controllo, con una riduzione del 13% nella velocità di camminata (Bargh et al., 1996).\nL’idea che una manipolazione così semplice possa produrre un effetto tanto marcato è stata successivamente oggetto di numerose critiche. I tentativi di replicare lo studio non hanno avuto successo, e il lavoro di Bargh et al. (1996) è ora considerato un esempio emblematico di risultati impossibili da replicare. Questo studio rappresenta solo uno dei molti casi in cui sono stati riportati effetti sorprendentemente grandi per manipolazioni apparentemente insignificanti.\nTosh et al. (2025) sostengono che, se davvero piccoli interventi (nudges) producono effetti così rilevanti, emergerebbe inevitabilmente il problema delle interazioni con numerosi altri fattori già noti per influire sul comportamento umano. La letteratura psicologica include infatti studi che attribuiscono grandi effetti a fattori come ormoni, immagini subliminali, notizie di partite di calcio o attacchi di squali, incontri casuali con sconosciuti, stato socioeconomico dei genitori, condizioni meteorologiche, l’ultima cifra dell’età, il genere del nome di un uragano, e molti altri. Secondo gli autori, se tutti questi fattori influenzassero realmente un singolo esito, le loro interazioni diventerebbero incredibilmente complesse e imprevedibili, rendendo impossibile individuare effetti stabili e replicabili.\nPer illustrare l’assurdità di alcuni di questi risultati, Tosh et al. (2025) propongono un esempio ipotetico. Supponiamo che 100 nudges producano ciascuno un effetto del 13% sulla velocità di camminata, come riportato da Bargh et al. (1996). Se questi effetti fossero indipendenti, l’effetto combinato sarebbe enorme: la velocità di camminata potrebbe facilmente raddoppiare, dimezzarsi o variare ancora di più. Tuttavia, tali variazioni sono empiricamente irrealistiche. In altre parole, le assunzioni su cui si basano molte di queste ricerche porterebbero a predizioni che non trovano riscontro nei dati osservabili.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>97</span>  <span class='chapter-title'>Il Problema del priming: sfide e paradossi nella psicologia sociale</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_piranha.html#riflessioni-conclusive",
    "href": "chapters/replication_crisis/07_piranha.html#riflessioni-conclusive",
    "title": "97  Il Problema del priming: sfide e paradossi nella psicologia sociale",
    "section": "97.4 Riflessioni Conclusive",
    "text": "97.4 Riflessioni Conclusive\nIl “problema del piranha” evidenzia i limiti intrinseci nell’assumere che numerosi effetti indipendenti e di grande entità possano coesistere all’interno di un sistema complesso. In realtà, tali effetti devono necessariamente interagire tra loro o essere correlati, rendendo improbabile la loro indipendenza. Questa dinamica crea instabilità nel sistema e porta a variazioni degli effetti nel tempo o tra popolazioni, compromettendo la possibilità di generalizzarne i risultati.\nTosh et al. (2025) suggeriscono che molti risultati pubblicati, che riportano effetti improbabilmente grandi, siano attribuibili non tanto a reali fenomeni psicologici, quanto a problemi metodologici, come bassa potenza statistica e i “gradi di libertà del ricercatore” (Simmons et al., 2011). La proliferazione di questi risultati contribuisce alla crisi di replicabilità, poiché i presunti effetti si rivelano spesso instabili o non replicabili.\nLa consapevolezza dei limiti imposti dal problema del piranha invita la ricerca psicologica a focalizzarsi maggiormente sulla robustezza metodologica, sull’identificazione di effetti plausibili e sulla considerazione delle interazioni tra variabili. Piuttosto che cercare di identificare molteplici grandi effetti, è essenziale riconoscere che un sistema complesso, per essere stabile e prevedibile, richiede un approccio che consideri l’interdipendenza delle variabili e la struttura complessiva del sistema. Questo approccio può contribuire a migliorare la validità e la replicabilità della ricerca nelle scienze sociali.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>97</span>  <span class='chapter-title'>Il Problema del priming: sfide e paradossi nella psicologia sociale</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_piranha.html#bibliografia",
    "href": "chapters/replication_crisis/07_piranha.html#bibliografia",
    "title": "97  Il Problema del priming: sfide e paradossi nella psicologia sociale",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBargh, J. A., Chen, M., & Burrows, L. (1996). Automaticity of social behavior: Direct effects of trait construct and stereotype activation on action. Journal of Personality and Social Psychology, 71(2), 230–244.\n\n\nLeys, R. (2024). Anatomy of a Train Wreck: The Rise and Fall of Priming Research. University of Chicago Press.\n\n\nSimmons, J. P., Nelson, L. D., & Simonsohn, U. (2011). False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant. Psychological science, 22(11), 1359–1366.\n\n\nTosh, C., Greengard, P., Goodrich, B., Gelman, A., Vehtari, A., & Hsu, D. (2025). The Piranha Problem: Large Effects Swimming in a Small Pond. Notices of the American Mathematical Society.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>97</span>  <span class='chapter-title'>Il Problema del priming: sfide e paradossi nella psicologia sociale</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_degrees_of_freedom.html",
    "href": "chapters/replication_crisis/08_degrees_of_freedom.html",
    "title": "98  I gradi di libertà del ricercatore",
    "section": "",
    "text": "98.1 Introduzione\nLo studio di Gould et al. (2025), ripreso dalla rivista Science (O’Grady, 2025), mostra come le scelte analitiche dei ricercatori possano generare una variabilità significativa nei risultati, persino quando si utilizzano gli stessi dati e si affronta la medesima domanda di ricerca in ecologia e biologia evolutiva. Questa discrepanza supera di gran lunga l’errore statistico atteso, rivelando un problema sistemico che trascende i confini disciplinari.\nI risultati concordano con quelli di precedenti progetti “many analysts” – tra cui il pionieristico lavoro in psicologia di Silberzahn et al. (2018) – e sottolineano, come evidenziato dallo psicologo Eric Uhlmann, “il ruolo cruciale delle decisioni soggettive nella pratica scientifica”. Ciò conferma che la fragilità metodologica non è un’esclusiva della psicologia, ma riguarda settori come le neuroscienze, le scienze sociali e, appunto, l’ecologia.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>98</span>  <span class='chapter-title'>I gradi di libertà del ricercatore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_degrees_of_freedom.html#metodologia",
    "href": "chapters/replication_crisis/08_degrees_of_freedom.html#metodologia",
    "title": "98  I gradi di libertà del ricercatore",
    "section": "98.2 Metodologia",
    "text": "98.2 Metodologia\nGould et al. (2025) hanno coinvolto 174 team di ricerca (246 analisti) nell’analisi indipendente di due dataset inediti:\n\nEcologia evolutiva: relazione tra numero di fratelli e crescita dei pulcini di cinciallegra (Cyanistes caeruleus).\nEcologia della conservazione: impatto della copertura erbosa sul reclutamento di piantine di Eucalyptus.\n\nOgni team ha risposto a una domanda specifica:\n\nDataset cinciallegra: “Quanto la competizione tra fratelli influenza la crescita dei pulcini?”\nDataset eucalipto: “In che modo la copertura erbosa condiziona il reclutamento di piantine?”\n\nI ricercatori hanno fornito risultati, giustificazioni metodologiche, codice analitico e hanno sottoposto le procedure a peer review incrociata, creando un sistema di controllo reciproco.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>98</span>  <span class='chapter-title'>I gradi di libertà del ricercatore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_degrees_of_freedom.html#risultati",
    "href": "chapters/replication_crisis/08_degrees_of_freedom.html#risultati",
    "title": "98  I gradi di libertà del ricercatore",
    "section": "98.3 Risultati",
    "text": "98.3 Risultati\nLo studio ha evidenziato eterogeneità estrema nelle conclusioni, nonostante l’uniformità dei dati di partenza:\n\nCinciallegra: L’effetto medio negativo (più fratelli = minore crescita) nascondeva un’ampia dispersione, con stime da -0.8 a +0.2 (Figura 1a).\nEucalipto: La relazione media era debolmente negativa e non significativa, ma con outlier che invertivano la tendenza (Figura 1b).\n\n\n\n\n\n\n\nFigura 98.1: Distribuzione degli effetti standardizzati nei due dataset: crescita dei pulcini (sinistra) e reclutamento di piantine (destra) (adattata da Gould et al., 2025).\n\n\n\nSorprendentemente, né la selezione di variabili, né l’uso di effetti casuali, né il giudizio dei revisori correlavano con la distanza dalla media meta-analitica. In altre parole, risultati divergenti non erano associati a scelte metodologicamente “peggiori”, ma a combinazioni altrettanto valide di decisioni analitiche.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>98</span>  <span class='chapter-title'>I gradi di libertà del ricercatore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_degrees_of_freedom.html#il-problema-dei-gradi-di-libertà-del-ricercatore",
    "href": "chapters/replication_crisis/08_degrees_of_freedom.html#il-problema-dei-gradi-di-libertà-del-ricercatore",
    "title": "98  I gradi di libertà del ricercatore",
    "section": "98.4 Il Problema dei Gradi di Libertà del Ricercatore",
    "text": "98.4 Il Problema dei Gradi di Libertà del Ricercatore\nIl lavoro illustra chiaramente come i “gradi di libertà analitici” – le molteplici opzioni durante l’analisi dati – possano generare conclusioni divergenti. Tra le decisioni critiche:\n\nGestione di outlier e dati mancanti.\nDefinizione operativa delle variabili.\nScelta di modelli statistici e controlli.\n\nQueste scelte, spesso soggettive ma teoricamente giustificabili, definiscono un “spazio analitico” con migliaia di percorsi possibili. Ogni studio pubblicato rappresenta dunque una singola traiettoria in questo labirinto metodologico, rischiando di offrire una visione parziale e potenzialmente distorta.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>98</span>  <span class='chapter-title'>I gradi di libertà del ricercatore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_degrees_of_freedom.html#implicazioni-e-strategie-di-mitigazione",
    "href": "chapters/replication_crisis/08_degrees_of_freedom.html#implicazioni-e-strategie-di-mitigazione",
    "title": "98  I gradi di libertà del ricercatore",
    "section": "98.5 Implicazioni e Strategie di Mitigazione",
    "text": "98.5 Implicazioni e Strategie di Mitigazione\nLa variabilità sistematica impone una revisione delle pratiche di ricerca:\n\nAnalisi di sensibilità avanzate:\n\nAnalisi multiverso: testare tutte le combinazioni plausibili di scelte metodologiche.\nCurve di specificazione: mappare come i risultati variano al mutare delle assunzioni.\n\nModelli aggregati: Combinare stime da approcci diversi (es., Bayesian Model Averaging) per ridurre la dipendenza da singole specifiche.\n\nTrasparenza procedurale:\n\nPreregistrazione: fissare ipotesi e metodi prima di accedere ai dati.\nPubblicazione di codice e dati grezzi.\n\nFormazione metodologica: Rafforzare le competenze statistiche, con enfasi sulla gestione della complessità analitica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>98</span>  <span class='chapter-title'>I gradi di libertà del ricercatore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_degrees_of_freedom.html#riflessioni-conclusive",
    "href": "chapters/replication_crisis/08_degrees_of_freedom.html#riflessioni-conclusive",
    "title": "98  I gradi di libertà del ricercatore",
    "section": "98.6 Riflessioni Conclusive",
    "text": "98.6 Riflessioni Conclusive\nQuesto studio dimostra empiricamente che l’affidabilità della scienza dipende non solo dai dati, ma da come li analizziamo. La variabilità indotta dai gradi di libertà del ricercatore mina la riproducibilità, soprattutto in contesti con elevata discrezionalità analitica. La soluzione non è l’uniformità metodologica, ma una cultura della trasparenza e della pluralità analitica, dove ogni risultato sia esplicitamente contestualizzato nel suo spazio di scelte possibili. Solo così ecologia, psicologia e discipline affini potranno produrre conoscenze solide e autocritiche.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>98</span>  <span class='chapter-title'>I gradi di libertà del ricercatore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_degrees_of_freedom.html#bibliografia",
    "href": "chapters/replication_crisis/08_degrees_of_freedom.html#bibliografia",
    "title": "98  I gradi di libertà del ricercatore",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGould, E., Fraser, H. S., Parker, T. H., Nakagawa, S., Griffith, S. C., Vesk, P. A., Fidler, F., Hamilton, D. G., Abbey-Lee, R. N., Abbott, J. K., et al. (2025). Same data, different analysts: variation in effect sizes due to analytical decisions in ecology and evolutionary biology. BMC biology, 23(1), 35.\n\n\nO’Grady, C. (2025). Given the same data, ecologists arrive at different conclusions. Science, 387(6738), 1026.\n\n\nSilberzahn, R., Uhlmann, E. L., Martin, D. P., Anselmi, P., Aust, F., Awtrey, E., Bahnı́k, Š., Bai, F., Bannard, C., Bonnier, E., et al. (2018). Many analysts, one data set: Making transparent how variations in analytic choices affect results. Advances in Methods and Practices in Psychological Science, 1(3), 337–356.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>98</span>  <span class='chapter-title'>I gradi di libertà del ricercatore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/09_integrity.html",
    "href": "chapters/replication_crisis/09_integrity.html",
    "title": "99  Integrità della ricerca",
    "section": "",
    "text": "99.1 Introduzione\nL’integrità della ricerca si fonda su principi e standard professionali volti a garantire l’affidabilità e la qualità degli studi scientifici. Essa si distingue dall’etica della ricerca, che invece si concentra sui principi morali. Elementi chiave per l’integrità includono la condivisione dei dati, il consenso informato e la trasparenza nelle pratiche di ricerca. I codici di condotta svolgono un ruolo cruciale nel guidare i comportamenti etici sia dei ricercatori che delle istituzioni. Tra le principali sfide da affrontare vi sono le pratiche di ricerca discutibili, la fabbricazione e falsificazione dei dati, il plagio e la gestione dei conflitti di interesse. Promuovere una cultura della ricerca basata su onestà, trasparenza e rispetto dei principi etici è essenziale per preservare l’integrità scientifica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>99</span>  <span class='chapter-title'>Integrità della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/09_integrity.html#standard-professionali-nei-codici-di-condotta-per-lintegrità-della-ricerca",
    "href": "chapters/replication_crisis/09_integrity.html#standard-professionali-nei-codici-di-condotta-per-lintegrità-della-ricerca",
    "title": "99  Integrità della ricerca",
    "section": "99.2 Standard Professionali nei Codici di Condotta per l’Integrità della Ricerca",
    "text": "99.2 Standard Professionali nei Codici di Condotta per l’Integrità della Ricerca\nNel contesto della ricerca, aderire a principi di condotta responsabile è fondamentale. Questi principi, spesso definiti come buone pratiche di ricerca, stabiliscono standard professionali che mirano a ottimizzare la qualità e l’affidabilità degli studi. Sebbene i concetti di base su cosa costituisca una buona pratica di ricerca rimangano stabili nel tempo, la loro applicazione pratica si evolve in risposta a cambiamenti sociali, politici e tecnologici. Un esempio significativo di questa evoluzione è l’enfasi crescente sulla condivisione dei dati di ricerca, resa possibile dall’uso di repository online gratuiti. Ciò ha portato a un’aspettativa diffusa di trasparenza e accessibilità dei dati. Allo stesso modo, la condivisione del codice utilizzato per analizzare i dati è diventata una pratica sempre più incoraggiata.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>99</span>  <span class='chapter-title'>Integrità della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/09_integrity.html#differenziazione-tra-integrità-ed-etica-della-ricerca",
    "href": "chapters/replication_crisis/09_integrity.html#differenziazione-tra-integrità-ed-etica-della-ricerca",
    "title": "99  Integrità della ricerca",
    "section": "99.3 Differenziazione tra Integrità ed Etica della Ricerca",
    "text": "99.3 Differenziazione tra Integrità ed Etica della Ricerca\nL’integrità della ricerca si basa su standard professionali, mentre l’etica della ricerca si fonda su principi morali come l’autonomia, la beneficenza, la non-maleficenza e la giustizia. Questi principi etici si traducono in pratiche specifiche, quali il consenso informato e la garanzia di verità e riservatezza nei confronti dei partecipanti. I ricercatori hanno l’obbligo di evitare studi che possano causare danni o risultare eccessivamente onerosi per i soggetti coinvolti.\nI codici di condotta per l’integrità della ricerca presentano alcune variazioni tra le diverse fonti. Ad esempio, il Codice di condotta europeo per l’integrità della ricerca sottolinea l’importanza di principi come onestà, trasparenza, accuratezza, responsabilità, affidabilità, rispetto e indipendenza. Questi principi si traducono in comportamenti specifici attesi sia dai ricercatori che dalle istituzioni, come la condivisione dei dati nel rispetto delle normative sulla protezione dei dati, tra cui il GDPR europeo.\nUn esempio pratico di come gli standard si siano evoluti è rappresentato dalla condivisione dei dati di ricerca. In passato, questa pratica era limitata dalla mancanza di infrastrutture adeguate. Oggi, grazie ai repository online e alla pressione esercitata da riviste scientifiche e finanziatori, la condivisione dei dati è diventata una pratica standard, riflettendo un cambiamento verso una maggiore apertura e trasparenza.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>99</span>  <span class='chapter-title'>Integrità della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/09_integrity.html#pressioni-e-sfide-nelladesione-ai-codici-di-condotta",
    "href": "chapters/replication_crisis/09_integrity.html#pressioni-e-sfide-nelladesione-ai-codici-di-condotta",
    "title": "99  Integrità della ricerca",
    "section": "99.4 Pressioni e Sfide nell’Adesione ai Codici di Condotta",
    "text": "99.4 Pressioni e Sfide nell’Adesione ai Codici di Condotta\nNonostante l’esistenza di codici di condotta, i ricercatori, specialmente quelli all’inizio della carriera, possono subire pressioni da parte dei supervisori per adottare comportamenti che deviano dagli standard stabiliti. Questo è spesso dovuto alla competitività nel campo scientifico e al sistema di valutazione basato sul numero di pubblicazioni. Tali dinamiche possono portare a pratiche di ricerca discutibili (PRD), come la pubblicazione selettiva dei risultati o l’uso di analisi dei dati flessibili per ottenere risultati statisticamente significativi.\nPer preservare l’integrità della ricerca, è essenziale creare un ambiente di lavoro che promuova apertura, inclusività e discussione franca delle pressioni e delle sfide etiche. Ciò richiede non solo l’adesione ai codici di condotta esistenti, ma anche un impegno attivo delle istituzioni nel promuovere la formazione etica e l’integrità tra i ricercatori. Solo attraverso un approccio di questo tipo la comunità scientifica può aspirare a una ricerca di alta qualità, sia eticamente responsabile che metodologicamente solida.\nUn esempio emblematico delle tensioni nel mondo accademico è il gioco da tavolo Publish or Perish, recentemente promosso dalla prestigiosa rivista Nature. La descrizione del gioco è provocatoria:\n\n“Falsificare dati, screditare altri scienziati, pubblicare una montagna di articoli che ricevono una torre di citazioni: i cinici potrebbero descrivere questi come passi necessari per raggiungere il successo accademico.”\n\nQuesta iniziativa solleva interrogativi sullo stato attuale della ricerca scientifica. Il mondo accademico sembra offrire incentivi distorti, mentre il sistema economico delle riviste scientifiche presenta una componente di monetizzazione che spesso entra in conflitto con gli obiettivi fondamentali della ricerca. Questo contesto favorisce l’accettazione di pratiche disoneste, funzionali al mantenimento dello status quo.\nIn questo scenario complesso, emergono voci di dissenso che auspicano una riforma del sistema scientifico (McElreath, 2020; Smaldino & McElreath, 2016). È necessaria una riflessione profonda su come bilanciare la produttività accademica con l’etica e la qualità della ricerca, nonché sul ruolo delle riviste scientifiche nel plasmare il panorama della ricerca contemporanea.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>99</span>  <span class='chapter-title'>Integrità della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/09_integrity.html#bibliografia",
    "href": "chapters/replication_crisis/09_integrity.html#bibliografia",
    "title": "99  Integrità della ricerca",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nSmaldino, P. E., & McElreath, R. (2016). The natural selection of bad science. Royal Society Open Science, 3(9), 160384.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>99</span>  <span class='chapter-title'>Integrità della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html",
    "href": "chapters/epiloque/epiloque.html",
    "title": "Considerazioni Conclusive",
    "section": "",
    "text": "Limiti dell’Inferenza Frequentista\nL’inferenza bayesiana rappresenta un approccio rigoroso e trasparente per integrare conoscenze pregresse e dati empirici nell’analisi psicologica. A differenza dei metodi frequentisti, l’approccio bayesiano consente di quantificare l’incertezza e di costruire modelli che riflettono le nostre aspettative iniziali. Questa flessibilità è particolarmente preziosa in psicologia, dove teorie e ipotesi svolgono un ruolo centrale nel guidare la ricerca. L’inferenza bayesiana rende esplicite le nostre assunzioni a priori e ci permette di valutare come i dati influenzano la nostra comprensione dei fenomeni psicologici.\nIn questo corso, abbiamo esaminato i limiti dell’inferenza frequentista, specialmente quando utilizzata come “filtro” per distinguere risultati scientifici rilevanti da quelli trascurabili. L’eccessiva dipendenza dai valori-p è stata ampiamente criticata per la sua associazione con inferenze inadeguate. Gli effetti possono essere sovrastimati, talvolta anche nella direzione sbagliata, quando la stima è vincolata alla significatività statistica in presenza di dati altamente variabili (Loken & Gelman, 2017).\nNonostante le critiche di lunga data e i dibattiti sul loro uso improprio (Gardner e Altman, 1986; Cohen, 1994; Anderson et al., 2000; Fidler et al., 2004; Finch et al., 2004), i valori-p persistono come indicatore di significatività. Questa tenacia riflette forse la necessità dei ricercatori di avere strumenti intuitivi, sebbene semplificati, per interpretare i dati. Tuttavia, l’uso rigido di soglie arbitrarie (ad esempio, 0.05, 0.01, 0.001) ha trasformato il raggiungimento della significatività in un obiettivo fine a se stesso, piuttosto che in uno strumento per comprendere i fenomeni sottostanti (Cohen, 1994; Kirk, 1996). Inoltre, i valori-p possono solo rifiutare l’ipotesi nulla, ma non confermarla, poiché un risultato non significativo non implica l’assenza di effetti o differenze (Wagenmakers, 2007; Amrhein et al., 2019).\nL’uso improprio dei valori-p, noto come “p-hacking” (Simmons et al., 2011), ha favorito pratiche scientifiche discutibili, contribuendo alla crisi di riproducibilità nella psicologia (Chambers et al., 2014; Szucs e Ioannidis, 2016).",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html#la-crisi-della-replicabilità",
    "href": "chapters/epiloque/epiloque.html#la-crisi-della-replicabilità",
    "title": "Considerazioni Conclusive",
    "section": "La Crisi della Replicabilità",
    "text": "La Crisi della Replicabilità\nLa crisi della replicabilità rappresenta una delle principali sfide che affliggono la ricerca scientifica contemporanea, con effetti particolarmente rilevanti nel campo della psicologia. Quando i risultati di uno studio non possono essere riprodotti in condizioni simili, si mette in discussione non solo la validità delle teorie su cui si basano interventi clinici e politiche pubbliche, ma anche la fiducia generale nella scienza. Questo problema va oltre l’ambito accademico, influenzando direttamente l’efficacia delle applicazioni pratiche delle ricerche.\n\nLe Cause Sottostanti\nUno dei fattori principali della crisi è legato all’uso di metodologie di ricerca e analisi dei dati insufficientemente rigorose, che spesso portano a falsi positivi. Sebbene siano stati fatti appelli per migliorare le pratiche scientifiche, tali problemi persistono, indicando che il fenomeno non è semplicemente frutto di errori o mancanza di comprensione. Secondo Smaldino e McElreath (2016), la causa radicale risiede nei sistemi di incentivi distorti che favoriscono la quantità piuttosto che la qualità della ricerca. In questo contesto, la pressione a pubblicare risultati significativi diventa prioritaria rispetto alla rigorosità metodologica, alimentando un circolo vizioso in cui la “scienza scadente” si perpetua.\nPratiche comuni, come il p-hacking (manipolazione statistica per ottenere risultati significativi) o la selezione selettiva dei dati, vengono adottate inconsciamente o intenzionalmente per massimizzare le probabilità di pubblicazione. Questo meccanismo, descritto come una forma di “selezione naturale della scienza scadente”, premia approcci che facilitano la produzione di risultati spettacolari, ma non necessariamente veritieri.\n\n\nVerso una Soluzione: Cambiare la Cultura Scientifica\nPer superare questa crisi, è fondamentale operare un cambiamento culturale all’interno della comunità scientifica. Non basta correggere gli errori metodologici; occorre modificare radicalmente gli incentivi per premiare la qualità, la trasparenza e la replicabilità della ricerca. Alcune strategie chiave includono:\n\nPromozione di Pratiche Rigorose:\n\nAdottare protocolli trasparenti, preregistrare gli studi prima del loro avvio e condividere apertamente dati e materiali.\nImplementare procedure di peer review più severe e incoraggiare la revisione post-pubblicazione.\n\nValorizzazione della Replicazione:\n\nDare maggiore riconoscimento agli studi che replicano risultati precedenti, anziché privilegiare esclusivamente nuove scoperte.\nCreare riviste specializzate che si concentriano sulla verifica e sulla riproducibilità degli studi.\n\nRiforma dei Criteri di Valutazione:\n\nSpostare l’attenzione dalla quantità delle pubblicazioni alla loro qualità e impatto scientifico.\nIncorporare metriche alternative, come l’impatto sociale e la contribuzione alla conoscenza consolidata.\n\n\n\n\nNuovi Approcci Metodologici\nAlcune proposte innovative mirano a migliorare la qualità delle analisi statistiche e ridurre la propensione a falsi positivi. Un esempio è l’adozione dell’inferenza bayesiana, che offre vantaggi significativi rispetto ai metodi tradizionali:\n\nMaggiore flessibilità nell’analisi di dati rumorosi o campioni piccoli.\nMinore propensione agli errori di tipo I.\nPossibilità di incorporare conoscenze pregresse nel processo decisionale.\n\nTuttavia, l’inferenza bayesiana da sola non può risolvere completamente il problema. È necessario affrontare anche le cause strutturali, come il sistema accademico che premia la produttività quantitativa piuttosto che la qualità.\nUn’altra prospettiva promettente è quella avanzata da Richard McElreath, che suggerisce di passare da un approccio descrittivo a uno che descrive formalmente i meccanismi generativi dei dati. Questo significa formulare ipotesi esplicite sui processi sottostanti e testarle attraverso confronti quantitativi tra modelli. Tecniche come la validazione incrociata bayesiana Leave-One-Out (LOO) permettono di valutare la robustezza dei modelli e la loro capacità di generalizzare a nuovi contesti.\nInoltre, la “rivoluzione causale” cerca di identificare relazioni causali in contesti naturali, superando i limiti degli esperimenti controllati tradizionali. Questo approccio richiede ai ricercatori di formulare ipotesi causali esplicite e confrontare modelli alternativi, migliorando così la comprensione dei fenomeni studiati.\n\n\nImplicazioni Sociali e Educative\nLa crisi della replicabilità ha implicazioni concrete al di là del mondo accademico. Interventi clinici, politiche pubbliche e decisioni basate su ricerche non replicabili rischiano di essere inefficaci o dannose. Pertanto, garantire la replicabilità e l’affidabilità delle scoperte scientifiche è essenziale non solo per preservare l’integrità accademica, ma anche per assumersi responsabilità sociali.\nUna revisione dei metodi didattici e dei programmi accademici è altrettanto cruciale. Gli studenti devono essere formati per comprendere e applicare inferenze basate su dati empirici. Studiosi come Mine Dogucu hanno sottolineato l’importanza di integrare approcci bayesiani e causalità nei corsi di formazione, e la presente dispensa si inserisce in questo sforzo (Dogucu & Çetinkaya-Rundel, 2021; Dogucu & Hu, 2022; Johnson et al., 2022; Rosenberg et al., 2022).",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html#conclusioni",
    "href": "chapters/epiloque/epiloque.html#conclusioni",
    "title": "Considerazioni Conclusive",
    "section": "Conclusioni",
    "text": "Conclusioni\nAffrontare e superare la crisi della replicabilità rappresenta una sfida fondamentale per la comunità scientifica, richiedendo un impegno collettivo per riformare profondamente la cultura della ricerca. Modificare gli incentivi che favoriscono quantità piuttosto che qualità, promuovere pratiche metodologiche rigorose e valorizzare la replicazione sono passi essenziali per costruire una scienza più affidabile. Solo attraverso un approccio multidimensionale sarà possibile ripristinare la fiducia nella psicologia scientifica e garantire che le sue applicazioni pratiche siano fondate su basi solide e verificabili.\nIn questo contesto, l’inferenza bayesiana emerge come uno strumento di grande valore per l’analisi dei dati psicologici. Offrendo metodi avanzati per gestire l’incertezza, integrare conoscenze pregresse e adattarsi a modelli complessi, essa si dimostra particolarmente utile per esplorare i fenomeni legati alla mente umana e al comportamento. La sua capacità di fornire previsioni robuste e di aggiornare le ipotesi in base a nuovi dati la rende un approccio ideale per affrontare le sfide poste dalla natura intrinsecamente dinamica del campo psicologico.\nTuttavia, è importante sottolineare che l’adozione di metodi bayesiani non costituisce da sola una soluzione completa alla crisi della replicabilità. Per migliorare realmente la qualità della ricerca, è necessario integrare queste tecniche con pratiche metodologiche rigorose. Tra queste, spiccano la formalizzazione di modelli generativi, che consentono di descrivere esplicitamente i processi sottostanti ai dati osservati, e il confronto tra modelli alternativi, fondamentale per valutare l’adeguatezza delle teorie proposte. Inoltre, l’adozione di una prospettiva causale esplicita è cruciale per identificare correttamente le relazioni di causa-effetto, superando i limiti degli studi correlazionali o degli esperimenti tradizionali.\nIn conclusione, solo un approccio integrato, che combini l’inferenza bayesiana con pratiche metodologiche avanzate e una riflessione critica sui sistemi di incentivi accademici, permetterà di progredire verso una scienza psicologica più affidabile e riproducibile. Questo sforzo collettivo non solo migliorerà la qualità delle ricerche, ma contribuirà anche a fornire una comprensione più profonda e accurata del comportamento umano, consolidando così la posizione della psicologia come disciplina scientifica solida e credibile.",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html#bibliografia",
    "href": "chapters/epiloque/epiloque.html#bibliografia",
    "title": "Considerazioni Conclusive",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nDogucu, M., & Çetinkaya-Rundel, M. (2021). Web scraping in the statistics and data science curriculum: Challenges and opportunities. Journal of Statistics and Data Science Education, 29(sup1), S112–S122.\n\n\nDogucu, M., & Hu, J. (2022). The current state of undergraduate Bayesian education and recommendations for the future. The American Statistician, 76(4), 405–413.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nLoken, E., & Gelman, A. (2017). Measurement Error and the Replication Crisis. Science, 355(6325), 584–585.\n\n\nRosenberg, J. M., Kubsch, M., Wagenmakers, E.-J., & Dogucu, M. (2022). Making sense of uncertainty in the science classroom: A Bayesian approach. Science & Education, 31(5), 1239–1262.",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/appendix/a01_shell.html",
    "href": "chapters/appendix/a01_shell.html",
    "title": "Appendice A — La Shell",
    "section": "",
    "text": "A.1 Che cos’è una Shell?\nUna shell è un programma che riceve comandi dall’utente tramite tastiera (o da file) e li passa al sistema operativo per l’esecuzione. Può essere accessibile tramite un terminale (o un emulatore di terminale).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>La Shell</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01_shell.html#che-cosè-una-shell",
    "href": "chapters/appendix/a01_shell.html#che-cosè-una-shell",
    "title": "Appendice A — La Shell",
    "section": "",
    "text": "A.1.1 Breve Storia della Shell\n\n1971: Ken Thompson di Bell Labs sviluppa la shell per UNIX.\n1977: Stephen Bourne introduce la Bourne shell (sh).\nDopo il 1977: Viene sviluppata la C shell (csh) e tcsh.\nBash: Sviluppata da Brian Fox come sostituto migliorato della Bourne shell.\n1990: Paul Falsted sviluppa Zsh, che diventa la shell predefinita per macOS dal 2019.\n\n\n\nA.1.2 Windows vs macOS/Linux\n\nWindows 10: È possibile utilizzare Bash attivando il Windows Subsystem for Linux. Tuttavia, l’ambiente preferito è solitamente PowerShell.\nmacOS/Linux: Zsh è la shell predefinita in entrambi i sistemi. È consigliabile sfruttare l’applicazione warp per un’esperienza utente moderna e ottimizzata.\n\n\n\nA.1.3 Comandi di Base Unix\n\npwd: Mostra il percorso della directory corrente.\nls: Elenca file e cartelle nella directory corrente.\ncd: Cambia directory. Senza argomenti, ti porta alla directory home.\nmkdir: Crea una nuova directory.\nrmdir: Rimuove una directory vuota.\nImportante: Evitare spazi nei nomi di file e cartelle.\n\n\nA.1.3.1 Gestione File\n\nmv: Rinomina o sposta file (usa \\ o '' per i nomi di file con spazi).\ncp: Copia file o cartelle (usa -r per le cartelle).\nrm: Rimuove file o cartelle (usa -i per confermare prima di eliminare).\n\n\n\nA.1.3.2 Visualizzazione e Manipolazione Contenuti dei File\n\nless / more: Visualizza il contenuto dei file con possibilità di navigazione.\ncat: Mostra l’intero contenuto di un file.\nhead: Mostra le prime righe di un file.\ntail: Mostra le ultime righe di un file.\n\n\n\n\nA.1.4 Comandi di Base PowerShell\nPer adattare i comandi Unix per l’utilizzo in PowerShell di Windows, molti dei comandi rimangono simili grazie alla natura cross-platform di PowerShell e alla sua flessibilità nel gestire sia gli stili di comando Unix che quelli tradizionali di Windows. Ecco come si traducono i comandi:\n\nGet-Location o semplicemente pwd: Mostra il percorso della directory corrente, simile a pwd in Unix.\nGet-ChildItem o semplicemente ls: Elenca file e cartelle nella directory corrente, equivalente a ls in Unix.\nSet-Location o semplicemente cd: Cambia directory. cd senza argomenti ti porta alla directory home in PowerShell con cd ~.\nNew-Item -ItemType Directory -Name 'nomeDirectory': Crea una nuova directory, simile a mkdir in Unix.\nRemove-Item -Path 'nomeDirectory' -Force: Rimuove una directory, anche se non vuota. Equivalente a rmdir in Unix, ma più potente perché può rimuovere anche directory con contenuti utilizzando il parametro -Force.\n\n\nA.1.4.1 Gestione File\n\nMove-Item -Path 'origine' -Destination 'destinazione': Rinomina o sposta file, equivalente a mv in Unix.\nCopy-Item -Path 'origine' -Destination 'destinazione': Copia file o cartelle, simile a cp in Unix. Usa -Recurse per copiare cartelle.\nRemove-Item -Path 'file' -Force: Rimuove file o cartelle, simile a rm in Unix. Usa -Force per rimuovere senza conferme e -Recurse per rimuovere cartelle con contenuti.\n\n\n\nA.1.4.2 Visualizzazione e Manipolazione Contenuti dei File\n\nGet-Content 'file' | More: Visualizza il contenuto dei file con possibilità di navigazione, simile a less/more in Unix.\nGet-Content 'file': Mostra l’intero contenuto di un file, equivalente a cat in Unix.\nGet-Content 'file' -Head &lt;numero&gt;: Mostra le prime righe di un file, simile a head in Unix.\nGet-Content 'file' -Tail &lt;numero&gt;: Mostra le ultime righe di un file, equivalente a tail in Unix.\n\n\n\n\n\n\n\nÈ cruciale familiarizzarsi con l’utilizzo dei percorsi relativi per semplificare gli spostamenti tra le diverse directory. L’impiego dei percorsi relativi rende il processo di navigazione più intuitivo e meno incline agli errori.\n\nNomi Chiari e Concisi: Evitate di includere spazi nei nomi dei file e delle cartelle. Preferite l’utilizzo di trattini bassi (_) per separare le parole e mantenere una struttura leggibile e facilmente comprensibile.\nEvitare Caratteri Speciali: È importante evitare l’inserimento di caratteri speciali come asterischi (*), dollari ($), slash (/, \\), punti (.), virgole (,), punti e virgole (;), parentesi (()), parentesi quadre ([]), parentesi graffe ({}), ampersand (&), barre verticali (|), punti esclamativi (!), punti interrogativi (?) nei nomi dei file e delle cartelle. Talvolta, anche l’uso del trattino (-) può causare problemi; quindi è consigliabile evitarlo. Questi caratteri possono generare problemi di compatibilità con alcuni sistemi operativi o applicazioni, rendendo più complessa la gestione dei file.\nDifferenziazione tra Maiuscole e Minuscole: Unix distingue tra maiuscole e minuscole (tratta le lettere come oggetti distinti), mentre Windows non lo fa. Per evitare confusioni, è consigliabile adottare una politica conservativa: considerate i nomi che differiscono solo per la case delle lettere come distinti.\n\nSeguendo questi consigli, è possibile ottimizzare notevolmente l’organizzazione e la gestione dei propri file, migliorando l’efficienza del lavoro e riducendo il rischio di errori.\n\n\n\nCon la pratica, la riga di comando diventa uno strumento molto efficiente. Questa breve guida fornisce le basi per iniziare a esplorare e gestire i file dal terminale, offrendo una base di partenza per ulteriori apprendimenti (es., Robbins, 2016). La familiarità con la shell è fondamentale nella data science.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>La Shell</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01_shell.html#bibliografia",
    "href": "chapters/appendix/a01_shell.html#bibliografia",
    "title": "Appendice A — La Shell",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nRobbins, A. (2016). Bash Pocket Reference: Help for Power Users and Sys Admins. O’Reilly Media, Inc.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>La Shell</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01a_files.html",
    "href": "chapters/appendix/a01a_files.html",
    "title": "Appendice B — Cartelle e documenti",
    "section": "",
    "text": "B.1 Introduzione\nI file su un computer sono organizzati tramite una struttura gerarchica chiamata struttura ad albero, costituita da cartelle (o directory) e file. Questa organizzazione permette una gestione ordinata e intuitiva delle informazioni.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Cartelle e documenti</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01a_files.html#introduzione",
    "href": "chapters/appendix/a01a_files.html#introduzione",
    "title": "Appendice B — Cartelle e documenti",
    "section": "",
    "text": "Radice (Root): È il punto più alto dell’albero da cui partono tutte le ramificazioni.\nCartelle/Directory: Contenitori che possono includere file o altre cartelle.\nFile: Gli elementi finali che contengono dati.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Cartelle e documenti</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01a_files.html#unixlinuxmacos",
    "href": "chapters/appendix/a01a_files.html#unixlinuxmacos",
    "title": "Appendice B — Cartelle e documenti",
    "section": "B.2 Unix/Linux/macOS",
    "text": "B.2 Unix/Linux/macOS\nNei sistemi Unix, l’albero ha una struttura chiara che inizia sempre dalla radice indicata con lo slash /.\nEsempio semplificato:\n/\n├── bin             # programmi di sistema essenziali\n├── etc             # file di configurazione\n├── home            # cartelle personali degli utenti\n│   └── utente\n│       ├── Documenti\n│       ├── Immagini\n│       └── Scaricati\n├── usr             # applicazioni e librerie utente\n├── var             # dati variabili come log e cache\n└── tmp             # file temporanei\nNei sistemi Unix i percorsi dei file si scrivono utilizzando lo slash (/), ad esempio:\n/home/utente/Documenti/tesi.docx",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Cartelle e documenti</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01a_files.html#windows",
    "href": "chapters/appendix/a01a_files.html#windows",
    "title": "Appendice B — Cartelle e documenti",
    "section": "B.3 Windows",
    "text": "B.3 Windows\nWindows organizza i file in maniera simile ma partendo da una o più unità (dischi), tipicamente indicate da lettere come C:, D:, ecc. La radice di ogni albero corrisponde quindi all’unità disco.\nEsempio semplificato:\nC:\\\n├── Program Files   # applicazioni installate\n├── Windows         # sistema operativo e file di sistema\n├── Utenti          # dati degli utenti\n│   └── utente\n│       ├── Documenti\n│       ├── Immagini\n│       └── Download\n└── Temp            # file temporanei\nNei sistemi Windows i percorsi dei file si scrivono utilizzando il backslash (\\), ad esempio:\nC:\\Utenti\\utente\\Documenti\\tesi.docx",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Cartelle e documenti</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01a_files.html#principali-comandi",
    "href": "chapters/appendix/a01a_files.html#principali-comandi",
    "title": "Appendice B — Cartelle e documenti",
    "section": "B.4 Principali Comandi",
    "text": "B.4 Principali Comandi\nQui sotto viene presentata una panoramica sintetica dei principali comandi per gestire la struttura ad albero di file e cartelle nei sistemi Unix (Linux e macOS) e Windows.\n\nB.4.1 Unix/Linux/macOS (Terminale Bash o zsh)\n\n\n\n\n\n\n\n\nComando\nFunzione\nEsempio\n\n\n\n\npwd\nMostra la cartella corrente (Print Working Directory)\npwd → /home/utente/Documenti\n\n\ncd\nCambia la cartella corrente (Change Directory)\ncd /home/utente/Scaricati\n\n\nls\nElenca il contenuto di una cartella (List)\nls o ls -l\n\n\nmkdir\nCrea una nuova cartella (Make Directory)\nmkdir nuova_cartella\n\n\nmv\nSposta o rinomina file/cartelle (Move)\nmv file.txt Documenti/ oppure mv vecchio.txt nuovo.txt\n\n\ncp\nCopia file/cartelle (Copy)\ncp file.txt copia_file.txt\n\n\nrm\nRimuove file (Remove)\nrm file.txt\n\n\nrmdir\nRimuove una cartella vuota (Remove Directory)\nrmdir cartella_vuota\n\n\nwhoami\nMostra l’utente corrente\nwhoami → utente\n\n\n\nEsempio di uso dei comandi:\npwd\ncd /home/utente\nmkdir nuovo\ncd nuovo\ntouch prova.txt\nls\nmv prova.txt ../Documenti\ncd ../Documenti\ncp prova.txt copia_prova.txt\nrm prova.txt\nwhoami\n\n\nB.4.2 Windows (Prompt dei comandi, CMD)\n\n\n\n\n\n\n\n\nComando\nFunzione\nEsempio\n\n\n\n\ncd\nCambia la cartella corrente (Change Directory)\ncd C:\\Utenti\\utente\\Documenti\n\n\ncd\nMostra la cartella corrente\ncd → C:\\Utenti\\utente\\Documenti\n\n\ndir\nElenca il contenuto della cartella\ndir\n\n\nmkdir\nCrea una nuova cartella\nmkdir nuova_cartella\n\n\nmove\nSposta o rinomina file/cartelle\nmove file.txt Documenti\\ o move vecchio.txt nuovo.txt\n\n\ncopy\nCopia file\ncopy file.txt copia_file.txt\n\n\ndel\nRimuove file\ndel file.txt\n\n\nrmdir\nRimuove cartella vuota\nrmdir cartella_vuota\n\n\nwhoami\nMostra l’utente corrente\nwhoami → utente\n\n\n\nEsempio di uso dei comandi:\ncd C:\\Utenti\\utente\nmkdir nuovo\ncd nuovo\necho prova &gt; prova.txt\ndir\nmove prova.txt ..\\Documenti\ncd ..\\Documenti\ncopy prova.txt copia_prova.txt\ndel prova.txt\nwhoami\nNota finale.\nEntrambi i sistemi operativi consentono operazioni simili, ma hanno sintassi e convenzioni leggermente diverse. Questi comandi di base permettono una gestione essenziale e rapida della struttura ad albero.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Cartelle e documenti</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01a_files.html#conclusioni",
    "href": "chapters/appendix/a01a_files.html#conclusioni",
    "title": "Appendice B — Cartelle e documenti",
    "section": "Conclusioni",
    "text": "Conclusioni\nIn sintesi, entrambi i sistemi operativi utilizzano una struttura ad albero per facilitare la gestione, la navigazione e l’organizzazione dei file e delle cartelle. Cambiano principalmente la notazione (/ o \\) e la gestione della radice (una singola radice / in Unix, più radici contrassegnate da lettere come C: in Windows).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Cartelle e documenti</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a02_math_symbols.html",
    "href": "chapters/appendix/a02_math_symbols.html",
    "title": "Appendice C — Simbologia di base",
    "section": "",
    "text": "Per una scrittura più sintetica possono essere utilizzati alcuni simboli matematici.\n\n\\(\\log(x)\\): il logaritmo naturale di \\(x\\).\nL’operatore logico booleano \\(\\land\\) significa “e” (congiunzione forte) mentre il connettivo di disgiunzione \\(\\lor\\) significa “o” (oppure) (congiunzione debole).\nIl quantificatore esistenziale \\(\\exists\\) vuol dire “esiste almeno un” e indica l’esistenza di almeno una istanza del concetto/oggetto indicato. Il quantificatore esistenziale di unicità \\(\\exists!\\) (“esiste soltanto un”) indica l’esistenza di esattamente una istanza del concetto/oggetto indicato. Il quantificatore esistenziale \\(\\nexists\\) nega l’esistenza del concetto/oggetto indicato.\nIl quantificatore universale \\(\\forall\\) vuol dire “per ogni.”\n\\(\\mathcal{A, S}\\): insiemi.\n\\(x \\in A\\): \\(x\\) è un elemento dell’insieme \\(A\\).\nL’implicazione logica “\\(\\Rightarrow\\)” significa “implica” (se …allora). \\(P \\Rightarrow Q\\) vuol dire che \\(P\\) è condizione sufficiente per la verità di \\(Q\\) e che \\(Q\\) è condizione necessaria per la verità di \\(P\\).\nL’equivalenza matematica “\\(\\iff\\)” significa “se e solo se” e indica una condizione necessaria e sufficiente, o corrispondenza biunivoca.\nIl simbolo \\(\\vert\\) si legge “tale che.”\nIl simbolo \\(\\triangleq\\) (o \\(:=\\)) si legge “uguale per definizione.”\nIl simbolo \\(\\Delta\\) indica la differenza fra due valori della variabile scritta a destra del simbolo.\nIl simbolo \\(\\propto\\) si legge “proporzionale a.”\nIl simbolo \\(\\approx\\) si legge “circa.”\nIl simbolo \\(\\in\\) della teoria degli insiemi vuol dire “appartiene” e indica l’appartenenza di un elemento ad un insieme. Il simbolo \\(\\notin\\) vuol dire “non appartiene.”\nIl simbolo \\(\\subseteq\\) si legge “è un sottoinsieme di” (può coincidere con l’insieme stesso). Il simbolo \\(\\subset\\) si legge “è un sottoinsieme proprio di.”\nIl simbolo \\(\\#\\) indica la cardinalità di un insieme.\nIl simbolo \\(\\cap\\) indica l’intersezione di due insiemi. Il simbolo \\(\\cup\\) indica l’unione di due insiemi.\nIl simbolo \\(\\emptyset\\) indica l’insieme vuoto o evento impossibile.\nIn matematica, \\(\\mbox{argmax}\\) identifica l’insieme dei punti per i quali una data funzione raggiunge il suo massimo. In altre parole, \\(\\mbox{argmax}_x f(x)\\) è l’insieme dei valori di \\(x\\) per i quali \\(f(x)\\) raggiunge il valore più alto.\n\\(a, c, \\alpha, \\gamma\\): scalari.\n\\(\\boldsymbol{x}, \\boldsymbol{y}\\): vettori.\n\\(\\boldsymbol{X}, \\boldsymbol{Y}\\): matrici.\n\\(X \\sim p\\): la variabile casuale \\(X\\) si distribuisce come \\(p\\).\n\\(p(\\cdot)\\): distribuzione di massa o di densità di probabilità.\n\\(p(y \\mid \\boldsymbol{x})\\): la probabilità o densità di \\(y\\) dato \\(\\boldsymbol{x}\\), ovvero \\(p(y = \\boldsymbol{Y} \\mid x = \\boldsymbol{X})\\).\n\\(f(x)\\): una funzione arbitraria di \\(x\\).\n\\(f(\\boldsymbol{X}; \\theta, \\gamma)\\): \\(f\\) è una funzione di \\(\\boldsymbol{X}\\) con parametri \\(\\theta, \\gamma\\). Questa notazione indica che \\(\\boldsymbol{X}\\) sono i dati che vengono passati ad un modello di parametri \\(\\theta, \\gamma\\).\n\\(\\mathcal{N}(\\mu, \\sigma^2)\\): distribuzione gaussiana di media \\(\\mu\\) e varianza \\(sigma^2\\).\n\\(\\mbox{Beta}(\\alpha, \\beta)\\): distribuzione Beta di parametri \\(\\alpha\\) e \\(\\beta\\).\n\\(\\mathcal{U}(a, b)\\): distribuzione uniforme con limite inferiore \\(a\\) e limite superiore \\(b\\).\n\\(\\mbox{Cauchy}(\\alpha, \\beta)\\): distribuzione di Cauchy di parametri \\(\\alpha\\) (posizione: media) e \\(\\beta\\) (scala: radice quadrata della varianza).\n\\(\\mathcal{B}(p)\\): distribuzione di Bernoulli di parametro \\(p\\) (probabilità di successo).\n\\(\\mbox{Bin}(n, p)\\): distribuzione binomiale di parametri \\(n\\) (numero di prove) e \\(p\\) (probabilità di successo).\n\\(\\mathbb{KL} (p \\mid\\mid q)\\): la divergenza di Kullback-Leibler da \\(p\\) a \\(q\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Simbologia di base</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a03_latex.html",
    "href": "chapters/appendix/a03_latex.html",
    "title": "Appendice D — Equazioni Matematiche in LaTeX",
    "section": "",
    "text": "D.1 LaTeX\nLaTeX è un potente strumento di composizione tipografica, ampiamente utilizzato per la produzione di documenti scientifici e tecnici. Una delle sue caratteristiche più apprezzate è la capacità di gestire equazioni matematiche in modo elegante e preciso. In questo articolo, esploreremo come scrivere equazioni matematiche in LaTeX, coprendo i modi matematici, le operazioni di base, l’allineamento delle equazioni e molto altro.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Equazioni Matematiche in LaTeX</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a03_latex.html#modelli-matematici-in-latex",
    "href": "chapters/appendix/a03_latex.html#modelli-matematici-in-latex",
    "title": "Appendice D — Equazioni Matematiche in LaTeX",
    "section": "D.2 Modelli Matematici in LaTeX",
    "text": "D.2 Modelli Matematici in LaTeX\nPer scrivere equazioni matematiche in LaTeX, esistono due modalità principali: la modalità inline e la modalità display.\n\nModalità Inline: Utilizzata per inserire equazioni all’interno del testo. Le espressioni matematiche sono racchiuse tra simboli di dollaro ($), ad esempio $E=mc^2$ produce \\(E=mc^2\\).\nModalità Display: Utilizzata per equazioni che devono essere evidenziate e centrate su una nuova linea. Le espressioni possono essere racchiuse tra $$ e $$, o all’interno di ambienti come \\begin{equation} e \\end{equation}.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Equazioni Matematiche in LaTeX</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a03_latex.html#scrivere-costrutti-matematici-di-base",
    "href": "chapters/appendix/a03_latex.html#scrivere-costrutti-matematici-di-base",
    "title": "Appendice D — Equazioni Matematiche in LaTeX",
    "section": "D.3 Scrivere Costrutti Matematici di Base",
    "text": "D.3 Scrivere Costrutti Matematici di Base\n\nD.3.1 Operazioni Aritmetiche\nLe operazioni aritmetiche possono essere scritte direttamente all’interno del testo utilizzando il simbolo del dollaro. Ad esempio:\n\nAddizione: $a + b$ produce \\(a + b\\).\nMoltiplicazione: $a \\cdot b$ o $a \\times b$ produce \\(a \\cdot b\\) o \\(a \\times b\\).\nDivisione: $a / b$ o $a \\div b$ produce \\(a / b\\) o \\(a \\div b\\).\n\n\n\nD.3.2 Frazioni e Coefficienti Binomiali\nLe frazioni si scrivono utilizzando il comando \\frac{num}{den}. Ad esempio, $\\frac{a}{b}$ produce \\(\\frac{a}{b}\\).\nPer i coefficienti binomiali, si utilizza il comando \\binom{n}{k}. Ad esempio, $\\binom{n}{k}$ produce \\(\\binom{n}{k}\\).\n\n\nD.3.3 Pedici e Apici\nI pedici si ottengono con _, mentre gli apici con ^. Ad esempio:\n\n$a_{1}$ produce \\(a_{1}\\).\n$a^{2}$ produce \\(a^{2}\\).\n\n\n\nD.3.4 Integrali e Radici\nPer gli integrali, i limiti di integrazione si scrivono come pedici e apici. Ad esempio:\n\n$\\int_{a}^{b} f(x) \\, dx$ produce \\(\\int_{a}^{b} f(x) \\, dx\\).\n\nLe radici si ottengono con il comando \\sqrt{}. Ad esempio, $\\sqrt{a + b}$ produce \\(\\sqrt{a + b}\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Equazioni Matematiche in LaTeX</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a03_latex.html#allineamento-delle-equazioni",
    "href": "chapters/appendix/a03_latex.html#allineamento-delle-equazioni",
    "title": "Appendice D — Equazioni Matematiche in LaTeX",
    "section": "D.4 Allineamento delle Equazioni",
    "text": "D.4 Allineamento delle Equazioni\nPer allineare più equazioni, si utilizza l’ambiente align. Ad esempio:\n\\begin{align*}\na + b &= c \\\\\nd + e &= f\n\\end{align*}\nQuesto allinea le equazioni al segno di uguale.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Equazioni Matematiche in LaTeX</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a03_latex.html#parentesi-e-operatori",
    "href": "chapters/appendix/a03_latex.html#parentesi-e-operatori",
    "title": "Appendice D — Equazioni Matematiche in LaTeX",
    "section": "D.5 Parentesi e Operatori",
    "text": "D.5 Parentesi e Operatori\nLe parentesi possono essere ridimensionate utilizzando i comandi \\left( e \\right). Ad esempio:\n$$ \n\\left( \\frac{a}{b} \\right) \n$$\nGli operatori come seno, coseno e logaritmi si scrivono con comandi specifici come \\sin, \\cos, e \\log.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Equazioni Matematiche in LaTeX</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a03_latex.html#conclusione",
    "href": "chapters/appendix/a03_latex.html#conclusione",
    "title": "Appendice D — Equazioni Matematiche in LaTeX",
    "section": "D.6 Conclusione",
    "text": "D.6 Conclusione\nLaTeX offre una vasta gamma di strumenti per la scrittura di equazioni matematiche, rendendolo uno strumento indispensabile per chiunque lavori con documenti scientifici. Con un po’ di pratica, è possibile padroneggiare queste tecniche e produrre documenti di alta qualità con facilità.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Equazioni Matematiche in LaTeX</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html",
    "href": "chapters/appendix/a11_numbers.html",
    "title": "Appendice E — Numeri e intervalli",
    "section": "",
    "text": "E.1 Numeri binari\nI numeri binari rappresentano il sistema numerico più elementare utilizzato in informatica, poiché sono composti unicamente da due simboli: 0 e 1. Questa caratteristica li rende particolarmente adatti alla rappresentazione di situazioni dicotomiche (vero/falso, presente/assente) e consente ai computer di operare rapidamente ed efficacemente sui dati.\nUn esempio semplice d’impiego dei valori logici binari si ottiene quando raccogliamo risposte a una domanda chiusa. Immaginiamo, ad esempio, di porre la domanda “Ti piacciono i mirtilli?” a 10 studenti. Se le risposte vengono memorizzate in R come valori logici (TRUE per “Sì” e FALSE per “No”), potremmo avere:\nopinion &lt;- c(TRUE, FALSE, TRUE, TRUE, TRUE, FALSE, TRUE, TRUE, TRUE, FALSE)\nopinion\n\n [1]  TRUE FALSE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE FALSE\nIn questo caso, TRUE e FALSE corrispondono a 1 e 0 rispettivamente quando utilizzati in operazioni numeriche. Lo stesso avviene in Python, dove True è interpretato come 1 e False come 0. Questa rappresentazione binaria permette di ottenere facilmente statistiche sintetiche. Per esempio, per calcolare la proporzione di risposte positive rispetto al totale, è sufficiente sommare i valori (contando così il numero di TRUE) e dividere per la lunghezza del vettore:\nsum(opinion) / length(opinion)\n\n[1] 0.7\nQuesto fornisce immediatamente la percentuale di studenti che hanno risposto “Sì” alla domanda.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-interi",
    "href": "chapters/appendix/a11_numbers.html#numeri-interi",
    "title": "Appendice E — Numeri e intervalli",
    "section": "\nE.2 Numeri interi",
    "text": "E.2 Numeri interi\nI numeri interi sono caratterizzati dall’assenza di componenti decimali. Essi includono sia i numeri naturali (1, 2, 3, …), tradizionalmente utilizzati per il conteggio, sia i loro opposti negativi. L’insieme dei numeri naturali è indicato con \\(\\mathbb{N}\\), mentre l’insieme dei numeri interi (che include i numeri naturali, i loro negativi e lo zero) si denota con \\(\\mathbb{Z}\\):\n\\[\n\\mathbb{Z} = \\{0, \\pm 1, \\pm 2, \\pm 3, \\dots\\}\n\\]",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-razionali",
    "href": "chapters/appendix/a11_numbers.html#numeri-razionali",
    "title": "Appendice E — Numeri e intervalli",
    "section": "\nE.3 Numeri razionali",
    "text": "E.3 Numeri razionali\nI numeri razionali sono quei numeri che possono essere espressi come il rapporto tra due numeri interi, con il denominatore diverso da zero. Essi formano l’insieme:\n\\[\n\\mathbb{Q} = \\left\\{\\frac{m}{n} \\mid m,n \\in \\mathbb{Z}, n \\neq 0\\right\\}.\n\\]\nPoiché ogni numero naturale è anche un intero, e ogni intero può essere rappresentato come razionale (ad esempio \\(5 = \\frac{5}{1}\\)), si ha una catena d’inclusioni tra i diversi insiemi di numeri:\n\\[\n\\mathbb{N} \\subseteq \\mathbb{Z} \\subseteq \\mathbb{Q}.\n\\]\nSe si desidera considerare solo i numeri razionali non negativi, si utilizza la notazione:\n\\[\n\\mathbb{Q}^+ = \\{q \\in \\mathbb{Q} \\mid q \\geq 0\\}.\n\\]",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-irrazionali",
    "href": "chapters/appendix/a11_numbers.html#numeri-irrazionali",
    "title": "Appendice E — Numeri e intervalli",
    "section": "\nE.4 Numeri irrazionali",
    "text": "E.4 Numeri irrazionali\nNon tutti i numeri possono essere espressi come rapporto di due interi. I numeri che non hanno questa proprietà sono detti irrazionali. Essi non possono essere scritti in forma frazionaria e la loro espansione decimale è infinita e non periodica. Esempi tipici di numeri irrazionali sono:\n\n\\(\\sqrt{2}\\)\n\\(\\sqrt{3}\\)\n\\(\\pi = 3.141592...\\)",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-reali",
    "href": "chapters/appendix/a11_numbers.html#numeri-reali",
    "title": "Appendice E — Numeri e intervalli",
    "section": "\nE.5 Numeri reali",
    "text": "E.5 Numeri reali\nI numeri razionali non coprono tutti i possibili punti sulla retta reale. Per rappresentare ogni possibile misura, grandezza o punto su una linea continua, si considerano i numeri reali, denotati con \\(\\mathbb{R}\\). L’insieme dei numeri reali comprende sia i razionali sia gli irrazionali:\n\\[\n\\mathbb{N} \\subseteq \\mathbb{Z} \\subseteq \\mathbb{Q} \\subseteq \\mathbb{R}.\n\\]\nIn statistica, la precisione con cui si esprime una misura è spesso legata al numero di cifre decimali utilizzate, sfruttando così appieno la “continuità” offerta dai numeri reali.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#intervalli-numerici",
    "href": "chapters/appendix/a11_numbers.html#intervalli-numerici",
    "title": "Appendice E — Numeri e intervalli",
    "section": "\nE.6 Intervalli Numerici",
    "text": "E.6 Intervalli Numerici\nDefinizione: Un intervallo numerico è un sottoinsieme connesso della retta reale. Intuitivamente, rappresenta tutti i numeri reali compresi tra due estremi, che possono o meno essere inclusi nell’intervallo stesso.\nClassificazione degli intervalli: Gli intervalli vengono classificati in base all’inclusione o meno degli estremi:\n\n\nIntervallo chiuso: Include entrambi gli estremi. Si indica con \\([a, b]\\) e rappresenta l’insieme dei numeri reali \\(x\\) tali che \\(a \\leq x \\leq b\\).\n\nIntervallo aperto: Non include alcun estremo. Si indica con \\((a, b)\\) e rappresenta l’insieme dei numeri reali \\(x\\) tali che \\(a &lt; x &lt; b\\).\n\nIntervalli semiaperti:\n\n\nChiuso a sinistra e aperto a destra: Include l’estremo sinistro ma non quello destro. Si indica con \\([a, b)\\) e rappresenta l’insieme dei numeri reali \\(x\\) tali che \\(a \\leq x &lt; b\\).\n\nAperto a sinistra e chiuso a destra: Include l’estremo destro ma non quello sinistro. Si indica con \\((a, b]\\) e rappresenta l’insieme dei numeri reali \\(x\\) tali che \\(a &lt; x \\leq b\\).\n\n\n\nTabella riassuntiva:\n\n\nIntervallo\nNotazione\nCondizione\n\n\n\nChiuso\n\\([a, b]\\)\n\\(a \\leq x \\leq b\\)\n\n\nAperto\n\\((a, b)\\)\n\\(a &lt; x &lt; b\\)\n\n\nChiuso a sinistra, aperto a destra\n\\([a, b)\\)\n\\(a \\leq x &lt; b\\)\n\n\nAperto a sinistra, chiuso a destra\n\\((a, b]\\)\n\\(a &lt; x \\leq b\\)\n\n\n\nOsservazioni: * La scelta della notazione con parentesi quadre o tonde indica rispettivamente l’inclusione o l’esclusione degli estremi.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html",
    "href": "chapters/appendix/a12_sum_notation.html",
    "title": "Appendice F — Sommatorie",
    "section": "",
    "text": "F.1 Manipolazione di somme\nLe somme sono uno strumento fondamentale in molti contesti matematici e statistici, e per gestirle in modo efficace è essenziale disporre di una notazione chiara e precisa. Consideriamo, ad esempio, la somma dei primi \\(n\\) numeri interi, che può essere espressa come \\(1 + 2 + \\dots + (n-1) + n\\), dove i puntini di sospensione (\\(\\dots\\)) indicano che la sequenza deve essere completata seguendo il pattern definito dai termini precedenti e successivi. Tuttavia, una notazione come \\(1 + 7 + \\dots + 73.6\\) risulterebbe ambigua senza ulteriori specifiche. In generale, ci troveremo di fronte a somme della forma\n\\[\nx_1 + x_2 + \\dots + x_n,\n\\]\ndove \\(x_n\\) rappresenta un numero definito altrove. Sebbene questa notazione con i puntini di sospensione sia utile in alcuni contesti, può risultare poco chiara in altri. Per questo motivo, si preferisce utilizzare la notazione di sommatoria:\n\\[\n\\sum_{i=1}^n x_i,\n\\]\nche si legge “sommatoria per \\(i\\) che va da \\(1\\) a \\(n\\) di \\(x_i\\)”. Il simbolo \\(\\sum\\) (la lettera sigma maiuscola dell’alfabeto greco) rappresenta l’operazione di somma, \\(x_i\\) è il generico addendo, mentre \\(1\\) e \\(n\\) sono gli estremi della sommatoria, che definiscono l’intervallo di variazione dell’indice \\(i\\). Solitamente, l’estremo inferiore è \\(1\\), ma potrebbe essere qualsiasi altro numero \\(m &lt; n\\). Pertanto, possiamo scrivere:\n\\[\n\\sum_{i=1}^n x_i = x_1 + x_2 + \\dots + x_n.\n\\]\nAd esempio, se i valori di \\(x\\) sono \\(\\{3, 11, 4, 7\\}\\), avremo:\n\\[\n\\sum_{i=1}^4 x_i = 3 + 11 + 4 + 7 = 25,\n\\]\ndove \\(x_1 = 3\\), \\(x_2 = 11\\), e così via. La quantità \\(x_i\\) è detta argomento della sommatoria, mentre la variabile \\(i\\), che assume valori interi successivi, è chiamata indice della sommatoria.\nLa notazione di sommatoria può anche essere espressa nella forma:\n\\[\n\\sum_{P(i)} x_i,\n\\]\ndove \\(P(i)\\) è una proposizione logica riguardante \\(i\\) che può essere vera o falsa. Quando è evidente che si vogliono sommare tutte le \\(n\\) osservazioni, la notazione può essere semplificata in \\(\\sum_{i} x_i\\) o addirittura \\(\\sum x_i\\). L’indice \\(i\\) può essere sostituito da altre lettere, come \\(k, j, l, \\dots\\), a seconda del contesto.\nPer semplificare i calcoli che coinvolgono le sommatorie, è utile conoscere alcune proprietà fondamentali.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html#manipolazione-di-somme",
    "href": "chapters/appendix/a12_sum_notation.html#manipolazione-di-somme",
    "title": "Appendice F — Sommatorie",
    "section": "",
    "text": "F.1.1 Proprietà 1 (Somma di una costante)\nLa sommatoria di \\(n\\) valori tutti uguali a una costante \\(a\\) è pari a \\(n\\) volte la costante stessa:\n\\[\n\\sum_{i=1}^{n} a = \\underbrace{a + a + \\dots + a}_{n \\text{ volte}} = n a.\n\\]\n\n\nF.1.2 Proprietà 2 (Proprietà distributiva)\nSe l’argomento della sommatoria contiene una costante, è possibile fattorizzarla. Ad esempio:\n\\[\n\\sum_{i=1}^{n} a x_i = a x_1 + a x_2 + \\dots + a x_n = a (x_1 + x_2 + \\dots + x_n) = a \\sum_{i=1}^{n} x_i.\n\\]\n\n\nF.1.3 Proprietà 3 (Proprietà associativa)\nSe l’argomento della sommatoria è una somma, possiamo separare i termini:\n\\[\n\\sum_{i=1}^{n} (a + x_i) = (a + x_1) + (a + x_2) + \\dots + (a + x_n) = n a + \\sum_{i=1}^{n} x_i.\n\\]\nIn generale, possiamo scrivere:\n\\[\n\\sum_{i=1}^{n} (x_i + y_i) = \\sum_{i=1}^{n} x_i + \\sum_{i=1}^{n} y_i.\n\\]\n\n\nF.1.4 Proprietà 4 (Operazioni algebriche)\nSe è necessario eseguire un’operazione algebrica (come l’elevamento a potenza o il logaritmo) sull’argomento della sommatoria, questa operazione deve essere eseguita prima della somma. Ad esempio:\n\\[\n\\sum_{i=1}^{n} x_i^2 = x_1^2 + x_2^2 + \\dots + x_n^2 \\neq \\left( \\sum_{i=1}^{n} x_i \\right)^2.\n\\]\n\n\nF.1.5 Proprietà 5 (Prodotto di termini)\nNel caso di un prodotto tra termini, il prodotto deve essere eseguito prima della somma:\n\\[\n\\sum_{i=1}^{n} x_i y_i = x_1 y_1 + x_2 y_2 + \\dots + x_n y_n.\n\\]\nInfatti, \\(a_1 b_1 + a_2 b_2 \\neq (a_1 + a_2)(b_1 + b_2)\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html#doppia-sommatoria",
    "href": "chapters/appendix/a12_sum_notation.html#doppia-sommatoria",
    "title": "Appendice F — Sommatorie",
    "section": "F.2 Doppia sommatoria",
    "text": "F.2 Doppia sommatoria\nIn alcuni contesti, si incontrano espressioni con una doppia sommatoria e un doppio indice:\n\\[\n\\sum_{i=1}^{n} \\sum_{j=1}^{m} x_{ij}.\n\\]\nQuesta notazione implica che, per ogni valore dell’indice esterno \\(i\\) (da \\(1\\) a \\(n\\)), si deve sviluppare la sommatoria interna per \\(j\\) (da \\(1\\) a \\(m\\)). Ad esempio:\n\\[\n\\sum_{i=1}^{3} \\sum_{j=4}^{6} x_{ij} = (x_{1,4} + x_{1,5} + x_{1,6}) + (x_{2,4} + x_{2,5} + x_{2,6}) + (x_{3,4} + x_{3,5} + x_{3,6}).\n\\]\nUn caso particolare interessante è la doppia sommatoria del prodotto di due variabili:\n\\[\n\\sum_{i=1}^{n} \\sum_{j=1}^{n} x_i y_j.\n\\]\nIn questo caso, poiché \\(x_i\\) non dipende dall’indice \\(j\\), possiamo estrarre \\(x_i\\) dalla sommatoria interna:\n\\[\n\\sum_{i=1}^{n} \\left( x_i \\sum_{j=1}^{n} y_j \\right).\n\\]\nAllo stesso modo, la sommatoria interna \\(\\sum_{j=1}^{n} y_j\\) non dipende da \\(i\\), quindi può essere estratta dalla sommatoria esterna:\n\\[\n\\sum_{i=1}^{n} \\sum_{j=1}^{n} x_i y_j = \\left( \\sum_{i=1}^{n} x_i \\right) \\left( \\sum_{j=1}^{n} y_j \\right).\n\\]\n\nF.2.1 Esempio pratico\nConsideriamo i vettori \\(x = \\{2, 3, 1\\}\\) e \\(y = \\{1, 4, 9\\}\\). Calcoliamo la doppia sommatoria:\n\\[\n\\begin{aligned}\n\\sum_{i=1}^3 \\sum_{j=1}^3 x_i y_j &= x_1 y_1 + x_1 y_2 + x_1 y_3 + x_2 y_1 + x_2 y_2 + x_2 y_3 + x_3 y_1 + x_3 y_2 + x_3 y_3 \\\\\n&= 2 \\times (1 + 4 + 9) + 3 \\times (1 + 4 + 9) + 1 \\times (1 + 4 + 9) \\\\\n&= 2 \\times 14 + 3 \\times 14 + 1 \\times 14 = 84.\n\\end{aligned}\n\\]\nD’altra parte, il prodotto delle due sommatorie è:\n\\[\n\\left( \\sum_{i=1}^3 x_i \\right) \\left( \\sum_{j=1}^3 y_j \\right) = (2 + 3 + 1) \\times (1 + 4 + 9) = 6 \\times 14 = 84.\n\\]\nI due risultati coincidono, confermando la validità della proprietà.\nPer ulteriori approfondimenti, si consiglia la consultazione del testo Concrete Mathematics: A Foundation for Computer Science (Graham et al., 1994).\nEsercizi pratici sono disponibili sulla seguente pagina web.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html#bibliografia",
    "href": "chapters/appendix/a12_sum_notation.html#bibliografia",
    "title": "Appendice F — Sommatorie",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGraham, R. L., Knuth, D. E., & Patashnik, O. (1994). Concrete Mathematics: A Foundation for Computer Science (2nd ed.). Addison-Wesley.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html",
    "href": "chapters/appendix/a13_sets.html",
    "title": "Appendice G — Insiemi",
    "section": "",
    "text": "G.1 Diagrammi di Eulero-Venn\nUn insieme (o collezione, classe, gruppo, …) è stato definito da Georg Cantor nel modo seguente:\nMentre non è rilevante la natura degli oggetti che costituiscono l’insieme, ciò che importa è distinguere se un dato oggetto appartenga o meno ad un insieme. Deve essere vera una delle due possibilità: il dato oggetto è un elemento dell’insieme considerato oppure non è elemento dell’insieme considerato. Due insiemi \\(A\\) e \\(B\\) si dicono uguali se sono formati dagli stessi elementi, anche se disposti in ordine diverso: \\(A=B\\). Due insiemi \\(A\\) e \\(B\\) si dicono diversi se non contengono gli stessi elementi: \\(A \\neq B\\). Ad esempio, i seguenti insiemi sono uguali:\n\\[\n\\{1, 2, 3\\} = \\{3, 1, 2\\} = \\{1, 3, 2\\}= \\{1, 1, 1, 2, 3, 3, 3\\}.\n\\]\nGli insiemi sono denotati da una lettera maiuscola, mentre le lettere minuscole, di solito, designano gli elementi di un insieme. Per esempio, un generico insieme \\(A\\) si indica con\n\\[\nA = \\{a_1, a_2, \\dots, a_n\\}, \\quad \\text{con } n &gt; 0.\n\\]\nLa scrittura \\(a \\in A\\) dice che \\(a\\) è un elemento di \\(A\\). Per dire che \\(b\\) non è un elemento di \\(A\\) si scrive \\(b \\notin A.\\)\nPer quegli insiemi i cui elementi soddisfano una certa proprietà che li caratterizza, tale proprietà può essere usata per descrivere più sinteticamente l’insieme:\n\\[\nA = \\{x ~\\vert~ \\text{proprietà posseduta da } x\\},\n\\]\nche si legge come “\\(A\\) è l’insieme degli elementi \\(x\\) per cui è vera la proprietà indicata.” Per esempio, per indicare l’insieme \\(A\\) delle coppie di numeri reali \\((x,y)\\) che appartengono alla parabola \\(y = x^2 + 1\\) si può scrivere:\n\\[\nA = \\{(x,y) ~\\vert~ y = x^2 + 1\\}.\n\\]\nDati due insiemi \\(A\\) e \\(B\\), diremo che \\(A\\) è un sottoinsieme di \\(B\\) se e solo se tutti gli elementi di \\(A\\) sono anche elementi di \\(B\\):\n\\[\nA \\subseteq B \\iff (\\forall x \\in A \\Rightarrow x \\in B).\n\\]\nSe esiste almeno un elemento di \\(B\\) che non appartiene ad \\(A\\) allora diremo che \\(A\\) è un sottoinsieme proprio di \\(B\\):\n\\[\nA \\subset B \\iff (A \\subseteq B, \\exists~ x \\in B ~\\vert~ x \\notin A).\n\\]\nUn altro insieme, detto insieme delle parti, o insieme potenza, che si associa all’insieme \\(A\\) è l’insieme di tutti i sottoinsiemi di \\(A\\), inclusi l’insieme vuoto e \\(A\\) stesso. Per esempio, per l’insieme \\(A = \\{a, b, c\\}\\), l’insieme delle parti è:\n\\[\n\\mathcal{P}(A) = \\{\n\\emptyset, \\{a\\}, \\{b\\}, \\{c\\},\n\\{a, b\\}, \\{a, c\\}, \\{c, b\\},\n\\{a, b, c\\}\n\\}.\n\\]\nI diagrammi di Venn sono uno strumento grafico molto utile per rappresentare gli insiemi e per verificare le proprietà delle operazioni tra di essi. Questi diagrammi prendono il nome dal matematico inglese del 19° secolo John Venn, anche se rappresentazioni simili erano già state utilizzate in precedenza da Leibniz e Eulero.\nI diagrammi di Venn rappresentano gli insiemi come regioni del piano delimitate da una curva chiusa. Nel caso di insiemi finiti, è possibile evidenziare alcuni elementi di un insieme tramite punti, e in alcuni casi possono essere evidenziati tutti gli elementi degli insiemi considerati.\nIn sostanza, questi diagrammi sono un modo visuale per rappresentare le proprietà degli insiemi e delle operazioni tra di essi. Sono uno strumento molto utile per visualizzare la relazione tra gli insiemi e per capire meglio come si combinano gli elementi all’interno di essi.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#appartenenza-ad-un-insieme",
    "href": "chapters/appendix/a13_sets.html#appartenenza-ad-un-insieme",
    "title": "Appendice G — Insiemi",
    "section": "\nG.2 Appartenenza ad un insieme",
    "text": "G.2 Appartenenza ad un insieme\nUsiamo ora R\n\nSet1 &lt;- c(1, 2)\nprint(Set1)\n\n[1] 1 2\n\nprint(class(Set1))\n\n[1] \"numeric\"\n\n\n\nmy_list &lt;- c(1, 2, 3, 4)\nmy_set_from_list &lt;- unique(my_list)\nprint(my_set_from_list)\n\n[1] 1 2 3 4\n\n\nL’appartenenza ad un insieme si verifica con %in%.\n\nmy_set &lt;- c(1, 3, 5)\nprint(\"Ecco il mio insieme:\")\n\n[1] \"Ecco il mio insieme:\"\n\nprint(my_set)\n\n[1] 1 3 5\n\nprint(\"1 appartiene all'insieme:\")\n\n[1] \"1 appartiene all'insieme:\"\n\nprint(1 %in% my_set)\n\n[1] TRUE\n\nprint(\"2 non appartiene all'insieme:\")\n\n[1] \"2 non appartiene all'insieme:\"\n\nprint(2 %in% my_set)\n\n[1] FALSE\n\nprint(\"4 NON appartiene all'insieme:\")\n\n[1] \"4 NON appartiene all'insieme:\"\n\nprint(!(4 %in% my_set))\n\n[1] TRUE",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#relazioni-tra-insiemi",
    "href": "chapters/appendix/a13_sets.html#relazioni-tra-insiemi",
    "title": "Appendice G — Insiemi",
    "section": "\nG.3 Relazioni tra insiemi",
    "text": "G.3 Relazioni tra insiemi\nEsaminiamo le funzioni Python per descrivere le relazioni tra insiemi. In particolare, dopo avere definito l’insieme universo e l’insieme vuoto, considereremo la relazione di inclusione che conduce al concetto di sottoinsieme. Analogamente si definisce il concetto di sovrainsieme. Mostreremo anche come valutare se due insiemi sono disgiunti (si dicono disgiunti gli insiemi con intersezione vuota).\n\nUniv &lt;- 0:10\nSuper &lt;- Univ[Univ %% 2 == 0]\nDisj &lt;- Univ[Univ %% 2 == 1]\nSub &lt;- c(4, 6)\nNull &lt;- Univ[Univ &gt; 10]\n\n\nprint(\"Insieme Universo (tutti gli interi positivi fino a 10):\")\n\n[1] \"Insieme Universo (tutti gli interi positivi fino a 10):\"\n\nprint(Univ)\n\n [1]  0  1  2  3  4  5  6  7  8  9 10\n\nprint(\"Tutti gli interi positivi pari fino a 10:\")\n\n[1] \"Tutti gli interi positivi pari fino a 10:\"\n\nprint(Super)\n\n[1]  0  2  4  6  8 10\n\nprint(\"Tutti gli interi positivi dispari fino a 10:\")\n\n[1] \"Tutti gli interi positivi dispari fino a 10:\"\n\nprint(Disj)\n\n[1] 1 3 5 7 9\n\nprint(\"Insieme di due elementi, 4 e 6:\")\n\n[1] \"Insieme di due elementi, 4 e 6:\"\n\nprint(Sub)\n\n[1] 4 6\n\nprint(\"Un insieme vuoto:\")\n\n[1] \"Un insieme vuoto:\"\n\nprint(Null)\n\ninteger(0)\n\n\n\nprint('È \"Super\" un sovrainsieme di \"Sub\"?')\n\n[1] \"È \\\"Super\\\" un sovrainsieme di \\\"Sub\\\"?\"\n\nprint(all(Sub %in% Super))\n\n[1] TRUE\n\nprint('È \"Super\" un sottoinsieme di \"Univ\"?')\n\n[1] \"È \\\"Super\\\" un sottoinsieme di \\\"Univ\\\"?\"\n\nprint(all(Super %in% Univ))\n\n[1] TRUE\n\nprint('È \"Sub\" un sovrainsieme di \"Super\"?')\n\n[1] \"È \\\"Sub\\\" un sovrainsieme di \\\"Super\\\"?\"\n\nprint(all(Super %in% Sub))\n\n[1] FALSE\n\nprint('Sono \"Super\" e \"Disj\" insiemi disgiunti?')\n\n[1] \"Sono \\\"Super\\\" e \\\"Disj\\\" insiemi disgiunti?\"\n\nprint(length(intersect(Super, Disj)) == 0)\n\n[1] TRUE",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#operazioni-tra-insiemi",
    "href": "chapters/appendix/a13_sets.html#operazioni-tra-insiemi",
    "title": "Appendice G — Insiemi",
    "section": "\nG.4 Operazioni tra insiemi",
    "text": "G.4 Operazioni tra insiemi\nSi definisce intersezione di \\(A\\) e \\(B\\) l’insieme \\(A \\cap B\\) di tutti gli elementi \\(x\\) che appartengono ad \\(A\\) e contemporaneamente a \\(B\\):\n\\[\nA \\cap B = \\{x ~\\vert~ x \\in A \\land x \\in B\\}.\n\\]\nSi definisce unione di \\(A\\) e \\(B\\) l’insieme \\(A \\cup B\\) di tutti gli elementi \\(x\\) che appartengono ad \\(A\\) o a \\(B\\), cioè\n\\[\nA \\cup B = \\{x ~\\vert~ x \\in A \\lor x \\in B\\}.\n\\]\nDifferenza. Si indica con \\(A \\setminus B\\) l’insieme degli elementi di \\(A\\) che non appartengono a \\(B\\):\n\\[\nA \\setminus B = \\{x ~\\vert~ x \\in A \\land x \\notin B\\}.\n\\]\nInsieme complementare. Nel caso che sia \\(B \\subseteq A\\), l’insieme differenza \\(A \\setminus B\\) è detto insieme complementare di \\(B\\) in \\(A\\) e si indica con \\(B^C\\).\nDato un insieme \\(S\\), una partizione di \\(S\\) è una collezione di sottoinsiemi di \\(S\\), \\(S_1, \\dots, S_k\\), tali che\n\\[\nS = S_1 \\cup S_2 \\cup \\dots S_k\n\\]\ne\n\\[\nS_i \\cap S_j, \\quad \\text{con } i \\neq j.\n\\]\nLa relazione tra unione, intersezione e insieme complementare è data dalle leggi di DeMorgan:\n\\[\n(A \\cup B)^c = A^c \\cap B^c,\n\\]\n\\[\n(A \\cap B)^c = A^c \\cup B^c.\n\\]\nIn tutte le seguenti figure, \\(S\\) è la regione delimitata dal rettangolo, \\(L\\) è la regione all’interno del cerchio di sinistra e \\(R\\) è la regione all’interno del cerchio di destra. La regione evidenziata mostra l’insieme indicato sotto ciascuna figura.\n\n\nDiagrammi di Venn\n\nI diagrammi di Eulero-Venn che illustrano le leggi di DeMorgan sono forniti nella figura seguente.\n\n\nLeggi di DeMorgan\n\nVediamo ora come si eseguono le operazioni tra insiemi con R.\nIntersezione.\n\nS1 &lt;- seq(1, 10, by = 3)\nS2 &lt;- 1:6\nS_intersection &lt;- intersect(S1, S2)\nprint(\"Intersezione di S1 e S2:\")\n\n[1] \"Intersezione di S1 e S2:\"\n\nprint(S_intersection)\n\n[1] 1 4\n\n\nUnione. Si noti che il connettivo logico | corrisponde all’unione.\n\nS_union &lt;- union(S1, S2)\nprint(\"Unione di S1 e S2:\")\n\n[1] \"Unione di S1 e S2:\"\n\nprint(S_union)\n\n[1]  1  4  7 10  2  3  5  6\n\n\nInsieme complementare.\n\nS &lt;- seq(0, 20, by = 2)\nS_complement &lt;- setdiff(0:20, S)\nprint(\"S è l'insieme dei numeri interi pari tra 0 e 20:\")\n\n[1] \"S è l'insieme dei numeri interi pari tra 0 e 20:\"\n\nprint(S)\n\n [1]  0  2  4  6  8 10 12 14 16 18 20\n\nprint(\"S_complement è l'insieme dei numeri interi dispari tra 0 e 20:\")\n\n[1] \"S_complement è l'insieme dei numeri interi dispari tra 0 e 20:\"\n\nprint(S_complement)\n\n [1]  1  3  5  7  9 11 13 15 17 19\n\n\n\nprint(\"È l'unione di S e S_complement uguale a tutti i numeri interi tra 0 e 20?\")\n\n[1] \"È l'unione di S e S_complement uguale a tutti i numeri interi tra 0 e 20?\"\n\nprint(setequal(union(S, S_complement), 0:20))\n\n[1] TRUE\n\n\nDifferenza tra insiemi.\n\nS1 &lt;- seq(0, 30, by = 3)\nS2 &lt;- seq(0, 30, by = 5)\nprint(\"Differenza tra S2 e S1:\")\n\n[1] \"Differenza tra S2 e S1:\"\n\nprint(setdiff(S2, S1))\n\n[1]  5 10 20 25\n\nprint(\"Differenza tra S1 e S2:\")\n\n[1] \"Differenza tra S1 e S2:\"\n\nprint(setdiff(S1, S2))\n\n[1]  3  6  9 12 18 21 24 27\n\n\nDifferenza simmetrica. La differenza simmetrica, indicata con il simbolo Δ, è un’operazione insiemistica definita come unione tra la differenza tra il primo e il secondo insieme e la differenza tra il secondo e il primo insieme. In modo equivalente, la differenza simmetrica equivale all’unione tra i due insiemi meno la loro intersezione.\n\nsym_diff &lt;- union(setdiff(S1, S2), setdiff(S2, S1))\nprint(\"Differenza simmetrica:\")\n\n[1] \"Differenza simmetrica:\"\n\nprint(sym_diff)\n\n [1]  3  6  9 12 18 21 24 27  5 10 20 25",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#coppie-ordinate-e-prodotto-cartesiano",
    "href": "chapters/appendix/a13_sets.html#coppie-ordinate-e-prodotto-cartesiano",
    "title": "Appendice G — Insiemi",
    "section": "\nG.5 Coppie ordinate e prodotto cartesiano",
    "text": "G.5 Coppie ordinate e prodotto cartesiano\nUna coppia ordinata \\((x,y)\\) è l’insieme i cui elementi sono \\(x \\in A\\) e \\(y \\in B\\) e nella quale \\(x\\) è la prima componente (o prima coordinata) e \\(y\\) la seconda. L’insieme di tutte le coppie ordinate costruite a partire dagli insiemi \\(A\\) e \\(B\\) viene detto prodotto cartesiano:\n\\[\nA \\times B = \\{(x, y) ~\\vert~ x \\in A \\land y \\in B\\}.\n\\]\nAd esempio, sia \\(A = \\{1, 2, 3\\}\\) e \\(B = \\{a, b\\}\\). Allora,\n\\[\n\\{1, 2\\} \\times \\{a, b, c\\} = \\{(1, a), (1, b), (1, c), (2, a), (2, b), (2, c)\\}.\n\\]\nPiù in generale, un prodotto cartesiano di \\(n\\) insiemi può essere rappresentato da un array di \\(n\\) dimensioni, dove ogni elemento è una ennupla o tupla ordinata (ovvero, una collezione o un elenco ordinato di \\(n\\) oggetti). Una n-pla ordinata si distingue da un insieme di \\(n\\) elementi in quanto fra gli elementi di un insieme non è dato alcun ordine. Inoltre gli elementi di una ennupla possono anche essere ripetuti. Essendo la n-pla un elenco ordinato, in generale di ogni suo elemento è possibile dire se sia il primo, il secondo, il terzo, eccetera, fino all’n-esimo. Il prodotto cartesiano prende il nome da René Descartes la cui formulazione della geometria analitica ha dato origine al concetto.\n\nA &lt;- c(\"a\", \"b\", \"c\")\nS &lt;- 1:3\ncartesian_product &lt;- expand.grid(A, S)\nprint(\"Prodotto cartesiano di A e S:\")\n\n[1] \"Prodotto cartesiano di A e S:\"\n\nprint(cartesian_product)\n\n  Var1 Var2\n1    a    1\n2    b    1\n3    c    1\n4    a    2\n5    b    2\n6    c    2\n7    a    3\n8    b    3\n9    c    3\n\n\nSi definisce cardinalità (o potenza) di un insieme finito il numero degli elementi dell’insieme. Viene indicata con \\(\\vert A\\vert, \\#(A)\\) o \\(\\text{c}(A)\\).\n\nprint(\"La cardinalità dell'insieme prodotto cartesiano è:\")\n\n[1] \"La cardinalità dell'insieme prodotto cartesiano è:\"\n\nprint(nrow(cartesian_product))\n\n[1] 9\n\n\nPotenza del prodotto cartesiano\n\nA &lt;- c(\"Head\", \"Tail\")\np2 &lt;- expand.grid(A, A)\nprint(\"Il quadrato dell'insieme A è un insieme che contiene:\")\n\n[1] \"Il quadrato dell'insieme A è un insieme che contiene:\"\n\nprint(nrow(p2))\n\n[1] 4\n\nprint(p2)\n\n  Var1 Var2\n1 Head Head\n2 Tail Head\n3 Head Tail\n4 Tail Tail\n\n\n\np3 &lt;- expand.grid(A, A, A)\nprint(\"L'insieme A elevato alla terza potenza è costituito da:\")\n\n[1] \"L'insieme A elevato alla terza potenza è costituito da:\"\n\nprint(nrow(p3))\n\n[1] 8\n\nprint(p3)\n\n  Var1 Var2 Var3\n1 Head Head Head\n2 Tail Head Head\n3 Head Tail Head\n4 Tail Tail Head\n5 Head Head Tail\n6 Tail Head Tail\n7 Head Tail Tail\n8 Tail Tail Tail",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html",
    "href": "chapters/appendix/a14_combinatorics.html",
    "title": "Appendice H — Calcolo combinatorio",
    "section": "",
    "text": "H.1 Principio della somma\nIl calcolo combinatorio studia il numero di modi in cui è possibile combinare, ordinare o disporre elementi appartenenti a uno o più insiemi, seguendo regole ben definite. Molti problemi di probabilità richiedono strumenti combinatori per determinare la probabilità di eventi complessi. In questo capitolo, esploreremo i concetti fondamentali del calcolo combinatorio, illustrandoli attraverso il modello del campionamento dall’urna. Tratteremo i principi della somma e del prodotto, fondamentali per affrontare problemi più avanzati, come permutazioni, disposizioni e combinazioni.\nIl principio della somma si applica quando un insieme di elementi può essere suddiviso in sottoinsiemi disgiunti (ossia senza sovrapposizioni). In questo caso, il numero totale di elementi è dato dalla somma delle cardinalità dei sottoinsiemi:\n\\[\nn_{\\text{tot}} = n_1 + n_2 + \\dots + n_k .\n\\]\nEsempio\nUn distributore contiene tre scomparti di caramelle, ciascuno con un diverso tipo di dolci:\nQuante caramelle ci sono in totale nel distributore?\nSecondo il principio della somma, il numero totale di caramelle è:\n\\[\nn_{\\text{tot}} = n_A + n_B + n_C = 10 + 8 + 12 = 30.\n\\]\nCalcolo in R:\nA &lt;- 10\nB &lt;- 8\nC &lt;- 12\n\ntotale_caramelle &lt;- A + B + C\ntotale_caramelle\n#&gt; [1] 30\nRisultato: Nel distributore ci sono 30 caramelle in totale.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#principio-della-somma",
    "href": "chapters/appendix/a14_combinatorics.html#principio-della-somma",
    "title": "Appendice H — Calcolo combinatorio",
    "section": "",
    "text": "Scomparto A: 10 caramelle alla menta,\n\n\nScomparto B: 8 caramelle alla frutta,\n\n\nScomparto C: 12 caramelle al cioccolato.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#principio-del-prodotto",
    "href": "chapters/appendix/a14_combinatorics.html#principio-del-prodotto",
    "title": "Appendice H — Calcolo combinatorio",
    "section": "\nH.2 Principio del prodotto",
    "text": "H.2 Principio del prodotto\nIl principio del prodotto si applica quando un’operazione può essere suddivisa in più fasi indipendenti, ciascuna con un numero specifico di possibilità. In tal caso, il numero totale di combinazioni è dato dal prodotto delle possibilità offerte da ciascuna fase:\n\\[\nn_{\\text{tot}} = n_1 \\cdot n_2 \\cdot \\dots \\cdot n_k .\n\\]\nEsempio\nSupponiamo di avere quattro urne contenenti palline di diverso colore:\n\n\nUrna A: 5 palline,\n\n\nUrna B: 6 palline,\n\n\nUrna C: 3 palline,\n\n\nUrna D: 2 palline.\n\nVogliamo formare insiemi di due palline, ciascuna estratta da urne differenti.\nSecondo il principio del prodotto, per ogni coppia di urne, il numero di combinazioni è dato dal prodotto del numero di palline contenute nelle due urne. Utilizziamo poi il principio della somma per ottenere il totale complessivo:\n\\[\nn_{\\text{tot}} = AB + AC + AD + BC + BD + CD.\n\\]\nCalcolo in R:\n\nAB &lt;- 5 * 6\nAC &lt;- 5 * 3\nAD &lt;- 5 * 2\nBC &lt;- 6 * 3\nBD &lt;- 6 * 2\nCD &lt;- 3 * 2\n\ntotale_insiemi &lt;- AB + AC + AD + BC + BD + CD\ntotale_insiemi\n#&gt; [1] 91\n\nRisultato: È possibile formare 91 insiemi di due palline, ciascuna estratta da urne differenti.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#il-modello-dellurna-e-i-metodi-di-campionamento",
    "href": "chapters/appendix/a14_combinatorics.html#il-modello-dellurna-e-i-metodi-di-campionamento",
    "title": "Appendice H — Calcolo combinatorio",
    "section": "\nH.3 Il modello dell’urna e i metodi di campionamento",
    "text": "H.3 Il modello dell’urna e i metodi di campionamento\nMolti problemi di calcolo combinatorio possono essere interpretati come estrazioni di palline da un’urna. Esistono quattro modi fondamentali di effettuare un campionamento, a seconda che:\n\nle estrazioni siano con o senza ripetizione,\nl’ordine degli elementi conti o meno.\n\nQueste quattro combinazioni danno origine a quattro principali metodi di campionamento:\n\n\nCon ripetizione e con ordine: Dopo ogni estrazione, la pallina viene rimessa nell’urna. (Es. formazione di codici numerici con ripetizioni)\n\nSenza ripetizione e con ordine: Ogni estrazione rimuove definitivamente la pallina dall’urna. (Es. assegnare premi in una gara)\n\nCon ripetizione e senza ordine: Si considerano i gruppi di elementi senza preoccuparsi dell’ordine. (Es. selezionare un certo numero di ingredienti da una dispensa)\n\nSenza ripetizione e senza ordine: Si scelgono elementi distinti senza considerare l’ordine. (Es. formare squadre da un gruppo di persone)\n\n\nEsempio H.1  \n\nurna &lt;- c(\"a\", \"b\", \"c\")\n\n# Con ripetizione e ordine\ncampionamento1 &lt;- expand.grid(urna, urna) |&gt;\n    rename(Elemento1 = Var1, Elemento2 = Var2)\n\n# Senza ripetizione e con ordine\ncampionamento2 &lt;- permutations(n = length(urna), r = 2, v = urna) |&gt;\n    as.data.frame() |&gt;\n    rename(Elemento1 = V1, Elemento2 = V2)\n\n# Con ripetizione e senza ordine\ncampionamento3 &lt;- combinations(\n    n = length(urna), r = 2, v = urna, repeats.allowed = TRUE\n) |&gt;\n    as.data.frame() |&gt;\n    rename(Elemento1 = V1, Elemento2 = V2)\n\n# Senza ripetizione e senza ordine\ncampionamento4 &lt;- combinations(n = length(urna), r = 2, v = urna) |&gt;\n    as.data.frame() |&gt;\n    rename(Elemento1 = V1, Elemento2 = V2)\n\n# Risultati\nlist(\n    `Con ripetizione e ordine` = campionamento1,\n    `Senza ripetizione e con ordine` = campionamento2,\n    `Con ripetizione e senza ordine` = campionamento3,\n    `Senza ripetizione e senza ordine` = campionamento4\n)\n#&gt; $`Con ripetizione e ordine`\n#&gt;   Elemento1 Elemento2\n#&gt; 1         a         a\n#&gt; 2         b         a\n#&gt; 3         c         a\n#&gt; 4         a         b\n#&gt; 5         b         b\n#&gt; 6         c         b\n#&gt; 7         a         c\n#&gt; 8         b         c\n#&gt; 9         c         c\n#&gt; \n#&gt; $`Senza ripetizione e con ordine`\n#&gt;   Elemento1 Elemento2\n#&gt; 1         a         b\n#&gt; 2         a         c\n#&gt; 3         b         a\n#&gt; 4         b         c\n#&gt; 5         c         a\n#&gt; 6         c         b\n#&gt; \n#&gt; $`Con ripetizione e senza ordine`\n#&gt;   Elemento1 Elemento2\n#&gt; 1         a         a\n#&gt; 2         a         b\n#&gt; 3         a         c\n#&gt; 4         b         b\n#&gt; 5         b         c\n#&gt; 6         c         c\n#&gt; \n#&gt; $`Senza ripetizione e senza ordine`\n#&gt;   Elemento1 Elemento2\n#&gt; 1         a         b\n#&gt; 2         a         c\n#&gt; 3         b         c",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#permutazioni-disporre-tutti-gli-elementi-con-ordine",
    "href": "chapters/appendix/a14_combinatorics.html#permutazioni-disporre-tutti-gli-elementi-con-ordine",
    "title": "Appendice H — Calcolo combinatorio",
    "section": "\nH.4 Permutazioni: Disporre tutti gli elementi con ordine",
    "text": "H.4 Permutazioni: Disporre tutti gli elementi con ordine\nLe permutazioni rappresentano tutti i modi in cui è possibile ordinare \\(n\\) elementi distinti. Il numero di permutazioni è dato da:\n\\[\nP_n = n!\n\\]\ndove \\(n!\\) (n fattoriale) è il prodotto di tutti i numeri da 1 a \\(n\\):\n\\[\nn! = n \\cdot (n-1) \\cdot (n-2) \\cdot \\dots \\cdot 1.\n\\]\n\nH.4.1 Intuizione della formula\nImmaginiamo di avere \\(n\\) elementi distinti e di doverli disporre in una sequenza. Il primo elemento può essere scelto in \\(n\\) modi. Una volta scelto il primo, rimangono \\(n-1\\) possibilità per il secondo, poi \\(n-2\\) per il terzo e così via, fino all’ultimo elemento, che avrà 1 sola possibilità. Applicando il principio del prodotto, otteniamo:\n\\[\nP_n = n \\times (n-1) \\times (n-2) \\times \\dots \\times 1 = n!\n\\]\n\nH.4.2 Metodo di campionamento corrispondente\n\n\nCampionamento senza ripetizione e con ordine: si estrae una pallina, la si esclude dall’urna e si continua fino a esaurire gli elementi.\n\n\nEsempio pratico: Ordinare i partecipanti di una gara su un podio (primo, secondo e terzo classificato).\n\nH.4.3 Esempio in R: Permutazioni di tre elementi\nSe abbiamo tre lettere {a, b, c}, le possibili permutazioni sono:\n\\[\nP_3 = 3! = 3 \\times 2 \\times 1 = 6.\n\\]\n\nA &lt;- c(\"a\", \"b\", \"c\")\nperm &lt;- permutations(n = length(A), r = length(A), v = A)\nprint(perm)\n#&gt;      [,1] [,2] [,3]\n#&gt; [1,] \"a\"  \"b\"  \"c\" \n#&gt; [2,] \"a\"  \"c\"  \"b\" \n#&gt; [3,] \"b\"  \"a\"  \"c\" \n#&gt; [4,] \"b\"  \"c\"  \"a\" \n#&gt; [5,] \"c\"  \"a\"  \"b\" \n#&gt; [6,] \"c\"  \"b\"  \"a\"\nnrow(perm)  # Verifica del numero di permutazioni\n#&gt; [1] 6\n\nRisultato:\n\\[\n\\{a, b, c\\}, \\{a, c, b\\}, \\{b, a, c\\}, \\{b, c, a\\}, \\{c, a, b\\}, \\{c, b, a\\}.\n\\]",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#disposizioni-selezionare-alcuni-elementi-con-ordine",
    "href": "chapters/appendix/a14_combinatorics.html#disposizioni-selezionare-alcuni-elementi-con-ordine",
    "title": "Appendice H — Calcolo combinatorio",
    "section": "\nH.5 Disposizioni: Selezionare alcuni elementi con ordine",
    "text": "H.5 Disposizioni: Selezionare alcuni elementi con ordine\nLe disposizioni si usano quando si scelgono \\(k\\) elementi da un insieme di \\(n\\), rispettando l’ordine. Il numero totale di disposizioni è:\n\\[\nD_{n,k} = \\frac{n!}{(n-k)!} .\n\\]\n\nH.5.1 Intuizione della formula\nSupponiamo di avere \\(n\\) elementi e di voler scegliere solo \\(k\\) elementi, mantenendo l’ordine.\n\nil primo elemento può essere scelto in \\(n\\) modi;\nil secondo elemento può essere scelto tra gli \\(n-1\\) elementi rimanenti;\n\nil terzo tra gli \\(n-2\\) rimanenti.\n\nSi prosegue fino a quando si hanno scelto \\(k\\) elementi, fermandosi prima di esaurire tutti gli elementi.\n\\[\nD_{n,k} = n \\times (n-1) \\times (n-2) \\times \\dots \\times (n-k+1) .\n\\]\nQuesta espressione corrisponde alla divisione del fattoriale di \\(n\\) per il fattoriale degli elementi che non vengono selezionati:\n\\[\nD_{n,k} = \\frac{n!}{(n-k)!} .\n\\]\n\nH.5.2 Metodo di campionamento corrispondente\n\n\nCampionamento senza ripetizione e con ordine: si estrae una pallina, la si esclude dall’urna e si continua fino a raggiungere il numero desiderato di elementi, fermandosi prima di esaurire tutti gli elementi.\n\n\nEsempio pratico: Estrarre casualmente 2 studenti da una classe di 10 e assegnare loro i ruoli di rappresentante e vice-rappresentante (l’ordine conta).\n\nH.5.3 Esempio in R: Disposizioni di 2 elementi da {a, b, c}\nSe scegliamo 2 lettere su 3, il numero di disposizioni è:\n\\[\nD_{3,2} = \\frac{3!}{(3-2)!} = \\frac{3 \\times 2 \\times 1}{1} = 6.\n\\]\n\ndisp &lt;- permutations(n = length(A), r = 2, v = A)\nprint(disp)\n#&gt;      [,1] [,2]\n#&gt; [1,] \"a\"  \"b\" \n#&gt; [2,] \"a\"  \"c\" \n#&gt; [3,] \"b\"  \"a\" \n#&gt; [4,] \"b\"  \"c\" \n#&gt; [5,] \"c\"  \"a\" \n#&gt; [6,] \"c\"  \"b\"\nnrow(disp)  # Verifica del numero di disposizioni\n#&gt; [1] 6\n\nRisultato:\n\\[\n\\{a, b\\}, \\{a, c\\}, \\{b, a\\}, \\{b, c\\}, \\{c, a\\}, \\{c, b\\}.\n\\]\nLe disposizioni considerano l’ordine, quindi \\(\\{a, b\\}\\) è diverso da \\(\\{b, a\\}\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#combinazioni-selezionare-alcuni-elementi-senza-ordine",
    "href": "chapters/appendix/a14_combinatorics.html#combinazioni-selezionare-alcuni-elementi-senza-ordine",
    "title": "Appendice H — Calcolo combinatorio",
    "section": "\nH.6 Combinazioni: Selezionare alcuni elementi senza ordine",
    "text": "H.6 Combinazioni: Selezionare alcuni elementi senza ordine\nLe combinazioni rappresentano il numero di modi per scegliere \\(k\\) elementi da \\(n\\) senza considerare l’ordine. Il numero di combinazioni è dato da:\n\\[\nC_{n,k} = \\binom{n}{k} = \\frac{n!}{k!(n-k)!} .\n\\]\n\nH.6.1 Intuizione della formula\nSupponiamo di avere \\(n\\) elementi e di voler selezionare \\(k\\) elementi senza considerare l’ordine.\nCome nel caso delle disposizioni, il primo elemento può essere scelto in \\(n\\) modi, il secondo in \\(n-1\\), e così via fino a selezionare \\(k\\) elementi.\n\\[\nD_{n,k} = n \\times (n-1) \\times \\dots \\times (n-k+1) .\n\\]\nTuttavia, in questo caso, l’ordine non conta, quindi ogni selezione viene duplicata per il numero di modi in cui i \\(k\\) elementi possono essere ordinati, ossia \\(k!\\) permutazioni interne. Per correggere questa duplicazione, dobbiamo dividere per \\(k!\\):\n\\[\nC_{n,k} = \\frac{D_{n,k}}{k!} = \\frac{n!}{k!(n-k)!} .\n\\]\n\nH.6.2 Metodo di campionamento corrispondente\n\n\nCampionamento senza ripetizione e senza ordine: si estrae una pallina e la si esclude dall’urna, ma non importa l’ordine in cui le palline vengono estratte.\n\n\nEsempio pratico: Formare una squadra di 2 studenti da un gruppo di 10 senza assegnare ruoli specifici (quindi \\(\\{a, b\\}\\) è uguale a \\(\\{b, a\\}\\)).\n\nH.6.3 Esempio in R: Combinazioni di 2 elementi da {a, b, c}\nSe scegliamo 2 lettere su 3 senza considerare l’ordine, otteniamo:\n\\[\nC_{3,2} = \\binom{3}{2} = \\frac{3!}{2!(3-2)!} = \\frac{3 \\times 2 \\times 1}{2 \\times 1 \\times 1} = 3.\n\\]\n\ncomb &lt;- combinations(n = length(A), r = 2, v = A)\nprint(comb)\n#&gt;      [,1] [,2]\n#&gt; [1,] \"a\"  \"b\" \n#&gt; [2,] \"a\"  \"c\" \n#&gt; [3,] \"b\"  \"c\"\nnrow(comb)  # Verifica del numero di combinazioni\n#&gt; [1] 3\n\nRisultato:\n\\[\n\\{a, b\\}, \\{a, c\\}, \\{b, c\\}.\n\\]\nLe combinazioni non considerano l’ordine, quindi \\(\\{a, b\\}\\) è uguale a \\(\\{b, a\\}\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#sintesi-quando-usare-ciascun-metodo",
    "href": "chapters/appendix/a14_combinatorics.html#sintesi-quando-usare-ciascun-metodo",
    "title": "Appendice H — Calcolo combinatorio",
    "section": "\nH.7 Sintesi: Quando usare ciascun metodo?",
    "text": "H.7 Sintesi: Quando usare ciascun metodo?\n\n\n\n\n\n\n\n\n\nMetodo\nRipetizione?\nOrdine?\nFormula\nMetodo di campionamento\n\n\n\nPermutazioni\n❌ No\n✅ Sì\n\\(n!\\)\nSenza ripetizione e con ordine\n\n\nDisposizioni\n❌ No\n✅ Sì\n\\(\\frac{n!}{(n-k)!}\\)\nSenza ripetizione e con ordine\n\n\nCombinazioni\n❌ No\n❌ No\n\\(\\binom{n}{k} = \\frac{n!}{k!(n-k)!}\\)\nSenza ripetizione e senza ordine\n\n\n\nIn conclusione, abbiamo visto come il modello dell’urna aiuti a comprendere i problemi combinatori. Le differenze tra permutazioni, disposizioni e combinazioni dipendono da due fattori fondamentali: ripetizione e ordine.\nQuesta classificazione è essenziale per risolvere problemi di probabilità e statistica in modo rigoroso. Gli esempi e il codice R forniscono strumenti concreti per applicare questi concetti nella pratica.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a15_calculus.html",
    "href": "chapters/appendix/a15_calculus.html",
    "title": "Appendice I — Per liberarvi dai terrori preliminari",
    "section": "",
    "text": "I.1 Integrali\nIn questo capitolo, traduciamo e adattiamo il capitolo Per liberarvi dai terrori preliminari tratto da Calculus made easy.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>I</span>  <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a15_calculus.html#integrali",
    "href": "chapters/appendix/a15_calculus.html#integrali",
    "title": "Appendice I — Per liberarvi dai terrori preliminari",
    "section": "",
    "text": "Il terrore preliminare, che spesso impedisce agli studenti di avvicinarsi all’analisi matematica, può essere superato comprendendo il significato intuitivo dei due simboli principali utilizzati in questo campo.\nQuesti simboli, che possono sembrare intimidatori, sono in realtà molto semplici:\n\n\\(d\\): Questo simbolo significa semplicemente “un po’ di”. Ad esempio, \\(\\operatorname{d}\\!x\\) indica un piccolo incremento di \\(x\\), mentre \\(\\operatorname{d}\\!u\\) rappresenta un piccolo incremento di \\(u\\). I matematici preferiscono dire “un elemento di” invece di “un po’ di”, ma il concetto è lo stesso. Questi piccoli incrementi possono essere considerati infinitamente piccoli.\n\\(\\int\\): Questo simbolo è una S allungata e rappresenta “la somma di”. Quindi, \\(\\int \\operatorname{d}\\!x\\) significa la somma di tutti i piccoli incrementi di \\(x\\), mentre \\(\\int \\operatorname{d}\\!t\\) indica la somma di tutti i piccoli incrementi di \\(t\\). I matematici chiamano questo simbolo “integrale”. Se consideri \\(x\\) come composto da tanti piccoli pezzi \\(\\operatorname{d}\\!x\\), sommandoli tutti otterrai l’intero valore di \\(x\\). La parola “integrale” significa semplicemente “il tutto”. Ad esempio, se pensi a un’ora come composta da 3600 secondi, la somma di tutti questi secondi ti darà un’ora. Quando vedi un’espressione che inizia con \\(\\int\\), significa che devi sommare tutti i piccoli pezzi indicati dai simboli che seguono.\n\nEcco, il terrore è svanito!\n\n\n\n\nI.1.1 Verifica con Simulazioni in R\nPer calcolare e visualizzare l’integrale di una funzione di densità, possiamo utilizzare il linguaggio di programmazione R. Consideriamo come esempio la funzione di densità gaussiana, definita dalla seguente formula:\n\\[\nf(x; \\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{-\\frac{(x - \\mu)^2}{2 \\sigma^2}}.\n\\]\nIn R, possiamo definire questa funzione come segue:\n\ngaussian &lt;- function(x, mu, sigma) {\n  1 / (sigma * sqrt(2 * pi)) * exp(-((x - mu)^2) / (2 * sigma^2))\n}\n\nDefiniamo i parametri e generiamo i valori per il calcolo della funzione di densità su un intervallo:\n\nmu &lt;- 0      # Media\nsigma &lt;- 1   # Deviazione standard\na &lt;- -10     # Limite inferiore\nb &lt;- 10      # Limite superiore\nn &lt;- 10000   # Numero di punti\n\nx_range &lt;- seq(a, b, length.out = n)  # Valori x\nfx &lt;- gaussian(x_range, mu, sigma)   # Ordinata della funzione\n\nVisualizziamo la funzione utilizzando il pacchetto ggplot2:\n\nlibrary(ggplot2)\nlibrary(scales)\n\nggplot(data.frame(x = x_range, fx = fx), aes(x, fx)) +\n  geom_line(color = \"blue\") +\n  labs(\n    title = \"Funzione di densità gaussiana\", \n    x = \"x\", \n    y = \"f(x)\"\n  )\n\n\n\n\n\n\n\nCreiamo una funzione per approssimare l’integrale sommando i prodotti \\(\\Delta x \\cdot f(x)\\):\n\nintegral_approximation &lt;- function(f, a, b, n) {\n  delta &lt;- (b - a) / n\n  sum(delta * f)\n}\n\n# Calcolo dell'integrale approssimato\napprox &lt;- integral_approximation(fx, a, b, n)\napprox\n\n[1] 0.9999\n\n\nConfrontiamo il risultato con il calcolo fornito dalla funzione integrate di R:\n\nintegrate(\n  function(x) gaussian(x, mu, sigma),\n  lower = a,\n  upper = b\n)\n\n1 with absolute error &lt; 7.4e-05\n\n\nCalcoliamo l’area sotto la curva in intervalli di interesse. Ad esempio, per \\([-1.96, 1.96]\\), che corrisponde al 95% dell’area nella distribuzione normale standard:\n\na &lt;- -1.96\nb &lt;- 1.96\nx_range &lt;- seq(a, b, length.out = n)\nfx &lt;- gaussian(x_range, mu, sigma)\n\napprox &lt;- integral_approximation(fx, a, b, n)\napprox\n\n[1] 0.9499321\n\n\nConfrontiamo con il risultato fornito da integrate():\n\nintegrate(\n  function(x) gaussian(x, mu, sigma),\n  lower = a,\n  upper = b\n)\n\n0.9500042 with absolute error &lt; 1e-11\n\n\nVerifichiamo l’area sotto la curva per \\([-1, 1]\\), che rappresenta circa il 68% dell’area totale:\n\na &lt;- -1.0\nb &lt;- 1.0\nx_range &lt;- seq(a, b, length.out = n)\nfx &lt;- gaussian(x_range, mu, sigma)\n\napprox &lt;- integral_approximation(fx, a, b, n)\napprox\n\n[1] 0.6826696\n\n\nConfronto:\n\nintegrate(\n  function(x) gaussian(x, mu, sigma),\n  lower = a,\n  upper = b\n)\n\n0.6826895 with absolute error &lt; 7.6e-15\n\n\nIn sintesi, questo approccio dimostra come calcolare l’integrale di una funzione di densità in un intervallo utilizzando sia un metodo approssimativo basato sulla somma dei rettangoli sia il metodo numerico integrato. In entrambi i casi, l’obiettivo è calcolare l’area sotto la curva, che corrisponde all’integrale della funzione di densità.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>I</span>  <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a15_calculus.html#potenze",
    "href": "chapters/appendix/a15_calculus.html#potenze",
    "title": "Appendice I — Per liberarvi dai terrori preliminari",
    "section": "\nI.2 Potenze",
    "text": "I.2 Potenze\nLe potenze sono un’operazione matematica che rappresenta un prodotto ripetuto. Si indicano generalmente come:\n\\[\na^n,\n\\]\ndove:\n\n\n\\(a\\) è la base,\n\n\\(n\\) è l’esponente.\n\nLa potenza rappresenta il prodotto della base \\(a\\) ripetuto \\(n\\) volte.\n\nI.2.1 Definizione di potenza\n\\[\na^n = \\underbrace{a \\cdot a \\cdot \\dots \\cdot a}_{n \\text{ fattori}} \\quad \\text{con } n \\in \\mathbb{N}.\n\\]\nAd esempio:\n\n\n\\(2^3 = 2 \\cdot 2 \\cdot 2 = 8\\),\n\n\\(3^4 = 3 \\cdot 3 \\cdot 3 \\cdot 3 = 81\\).\n\n\nI.2.2 Proprietà delle potenze\n\n\nMoltiplicazione di potenze con la stessa base:\n\\[\na^m \\cdot a^n = a^{m+n}\n\\]\nEsempio: \\(2^3 \\cdot 2^2 = 2^{3+2} = 2^5 = 32\\).\n\n\nDivisione di potenze con la stessa base:\n\\[\n\\frac{a^m}{a^n} = a^{m-n}, \\quad \\text{con } m \\geq n.\n\\]\nEsempio: \\(\\frac{5^4}{5^2} = 5^{4-2} = 5^2 = 25\\).\n\n\nPotenze di potenze:\n\\[\n(a^m)^n = a^{m \\cdot n}.\n\\]\nEsempio: \\((3^2)^3 = 3^{2 \\cdot 3} = 3^6 = 729\\).\n\n\nProdotto di potenze con basi diverse ma lo stesso esponente:\n\\[\na^n \\cdot b^n = (a \\cdot b)^n.\n\\]\nEsempio: \\(2^3 \\cdot 3^3 = (2 \\cdot 3)^3 = 6^3 = 216\\).\n\n\nDivisione di potenze con basi diverse ma lo stesso esponente:\n\\[\n\\frac{a^n}{b^n} = \\left(\\frac{a}{b}\\right)^n.\n\\]\nEsempio: \\(\\frac{4^2}{2^2} = \\left(\\frac{4}{2}\\right)^2 = 2^2 = 4\\).\n\n\nEsponente zero:\n\\[\na^0 = 1, \\quad \\text{con } a \\neq 0.\n\\]\nEsempio: \\(5^0 = 1\\).\n\n\nEsponente negativo:\n\\[\na^{-n} = \\frac{1}{a^n}.\n\\]\nEsempio: \\(2^{-3} = \\frac{1}{2^3} = \\frac{1}{8}\\).\n\n\nRadice come potenza frazionaria:\n\\[\na^{\\frac{1}{n}} = \\sqrt[n]{a}, \\quad a^{\\frac{m}{n}} = \\sqrt[n]{a^m}.\n\\]\nEsempio: \\(8^{\\frac{1}{3}} = \\sqrt[3]{8} = 2\\).\n\n\n\nI.2.3 Esempi pratici\n\n\nCalcolo semplice:\n\\[\n4^3 = 4 \\cdot 4 \\cdot 4 = 64.\n\\]\n\n\nUtilizzo delle proprietà:\n\\[\n3^5 \\cdot 3^2 = 3^{5+2} = 3^7 = 2187.\n\\]\n\n\nDivisione:\n\\[\n\\frac{6^4}{6^2} = 6^{4-2} = 6^2 = 36.\n\\]\n\n\nEsponente negativo:\n\\[\n10^{-2} = \\frac{1}{10^2} = \\frac{1}{100} = 0.01.\n\\]\n\n\nRadice come potenza:\n\\[\n16^{\\frac{1}{2}} = \\sqrt{16} = 4.\n\\]\n\n\n\nI.2.4 Nota sui numeri razionali e reali\n\nLe potenze con esponenti interi sono definite per ogni base.\nLe potenze con esponenti frazionari o reali richiedono che la base sia positiva per evitare ambiguità.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>I</span>  <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a15_calculus.html#logaritmi",
    "href": "chapters/appendix/a15_calculus.html#logaritmi",
    "title": "Appendice I — Per liberarvi dai terrori preliminari",
    "section": "\nI.3 Logaritmi",
    "text": "I.3 Logaritmi\nIl logaritmo è una funzione matematica che risponde alla domanda: “quante volte devo moltiplicare un certo numero (chiamato”base”) per ottenere un altro numero?” Matematicamente, questo è espresso come:\n\\[\n\\log_b(a) = x \\iff b^x = a\n\\]\nAd esempio, \\(\\log_2(8) = 3\\) perché \\(2^3 = 8\\).\nNel contesto dei logaritmi, i valori molto piccoli (compresi tra 0 e 1) diventano più grandi (in termini assoluti) e negativi quando applichiamo una funzione logaritmica. Questo è utile per stabilizzare i calcoli, specialmente quando lavoriamo con prodotti di numeri molto piccoli che potrebbero portare a problemi di underflow.\nPer esempio:\n\n\\(\\log(1) = 0\\)\n\\(\\log(0.1) = -1\\)\n\\(\\log(0.01) = -2\\)\n\\(\\log(0.001) = -3\\)\n\nCome si può vedere, i valori assoluti dei logaritmi crescono man mano che il numero originale si avvicina a zero.\nUna delle proprietà più utili dei logaritmi è che consentono di trasformare un prodotto in una somma:\n\\[\n\\log_b(a \\times c) = \\log_b(a) + \\log_b(c)\n\\]\nQuesta proprietà è estremamente utile in calcoli complessi, come nella statistica bayesiana, dove il prodotto di molte probabilità potrebbe diventare un numero molto piccolo e causare problemi numerici.\nUn’altra proprietà utile dei logaritmi è che un rapporto tra due numeri diventa la differenza dei loro logaritmi:\n\\[\n\\log_b\\left(\\frac{a}{c}\\right) = \\log_b(a) - \\log_b(c)\n\\]\nAnche questa proprietà è molto utilizzata in matematica, specialmente in situazioni in cui è necessario normalizzare i dati.\nIn sintesi, i logaritmi sono strumenti potenti per semplificare e stabilizzare i calcoli matematici. Essi consentono di lavorare più agevolmente con numeri molto grandi o molto piccoli e di trasformare operazioni complesse come prodotti e divisioni in somme e differenze, rendendo i calcoli più gestibili e meno inclini a errori numerici.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>I</span>  <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a47_first_order_markov.html",
    "href": "chapters/appendix/a47_first_order_markov.html",
    "title": "Appendice J — Catene di Markov",
    "section": "",
    "text": "J.1 Classificazione degli Stati\nIl processo di Markov di primo ordine è un concetto fondamentale in molti campi, tra cui l’intelligenza artificiale, la statistica e la teoria delle probabilità. Questo modello probabilistico rappresenta un equilibrio tra la semplicità delle variabili casuali indipendenti e la complessità delle interazioni tra variabili. Per chiarire il concetto, consideriamo una sequenza temporale di eventi rappresentata da variabili casuali \\(X_0, X_1, ..., X_n, ...\\). In molti fenomeni reali, queste variabili non sono né completamente indipendenti né totalmente interdipendenti. Una catena di Markov rappresenta un compromesso tra questi due estremi.\nIn questo contesto, ci concentreremo su catene di Markov con stati discreti e tempo discreto. Ciò significa che le variabili \\(X_n\\) possono assumere valori in un insieme finito, tipicamente indicato come \\(\\{1, 2, ..., M\\}\\), e che gli eventi si verificano in momenti distinti e numerabili. La proprietà fondamentale di una catena di Markov può essere espressa matematicamente con la seguente equazione:\n\\[\nP(X_{n+1} = j | X_n = i, X_{n-1} = i_{n-1}, ..., X_0 = i_0) = P(X_{n+1} = j | X_n = i).\n\\]\nQuesta equazione indica che il futuro (rappresentato da \\(X_{n+1}\\)) dipende solo dal presente (\\(X_n\\)) e non dal passato (\\(X_{n-1}, ..., X_0\\)). La proprietà di Markov può essere vista come un primo allentamento dell’assunzione di indipendenza: le variabili casuali sono dipendenti in un modo specifico che risulta matematicamente conveniente.\nQuantità importanti associate a una catena di Markov sono le probabilità condizionate, chiamate probabilità di transizione:\n\\[\nP(X_{n+1} = j \\mid X_n = i).\n\\]\nLa probabilità \\(P(X_{n+1} = j \\mid X_n = i)\\), nota come probabilità di transizione, rappresenta la probabilità di passare dallo stato \\(i\\) allo stato \\(j\\) in un singolo passo.\nPer descrivere completamente una catena di Markov, si utilizza una matrice \\(Q\\), chiamata matrice di transizione. Questa è una matrice \\(M \\times M\\) in cui ogni elemento \\(q_{ij}\\) rappresenta la probabilità di transizione dallo stato \\(i\\) allo stato \\(j\\). Un’importante caratteristica della matrice di transizione è che la somma degli elementi di ogni riga deve essere pari a 1, poiché partendo da uno stato qualsiasi, il sistema deve necessariamente transitare in uno degli stati possibili.\nPer chiarire ulteriormente il concetto, consideriamo un modello di previsione del tempo a Firenze con tre possibili condizioni meteorologiche: soleggiato, piovoso e nebbioso. Di seguito è riportata una matrice di transizione che rappresenta le probabilità di passaggio da un tipo di tempo all’altro:\nVediamo come calcolare alcune probabilità:\nIl modello di Markov di base assume che le probabilità di transizione rimangano costanti nel tempo, una proprietà nota come omogeneità temporale. Questo significa che, per esempio, la probabilità di passare dallo stato “soleggiato” allo stato “piovoso” è la stessa in qualsiasi periodo dell’anno.\nIn sintesi, l’utilità del modello di Markov risiede nella sua capacità di semplificare notevolmente i calcoli probabilistici. Invece di considerare l’intera storia passata del sistema, è sufficiente conoscere solo lo stato attuale per fare previsioni sul futuro. Questa caratteristica, nota come “assenza di memoria”, rende il modello estremamente utile in molte applicazioni pratiche, dalla modellazione di fenomeni naturali alla progettazione di algoritmi di apprendimento automatico. Il processo di Markov di primo ordine offre uno strumento potente per analizzare e prevedere il comportamento di sistemi complessi nel tempo, bilanciando la necessità di catturare le dipendenze temporali con la semplicità computazionale. La sua versatilità e applicabilità in diversi campi lo rendono un concetto chiave per comprendere e modellare molti fenomeni del mondo reale.\nConsideriamo ora la terminologia usata per descrivere le varie caratteristiche di una catena di Markov.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>J</span>  <span class='chapter-title'>Catene di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a47_first_order_markov.html#classificazione-degli-stati",
    "href": "chapters/appendix/a47_first_order_markov.html#classificazione-degli-stati",
    "title": "Appendice J — Catene di Markov",
    "section": "",
    "text": "J.1.1 Catene di Markov Irriducibili\nUna catena di Markov è detta irriducibile se, per qualsiasi coppia di stati \\(i\\) e \\(j\\), esiste una probabilità positiva di passare dallo stato \\(i\\) allo stato \\(j\\) in un numero finito di passi. In altre parole, una catena irriducibile non ha stati isolati: ogni stato è raggiungibile da qualsiasi altro stato.\n\n\nJ.1.2 Stati Ricorrenti\nUno stato \\(i\\) di una catena di Markov si dice ricorrente se, partendo da \\(i\\), la probabilità di ritornarvi è uguale a 1. Questo implica che una volta raggiunto lo stato \\(i\\), è garantito che la catena tornerà in \\(i\\) prima o poi. Gli stati ricorrenti possono essere ulteriormente classificati come:\n\nPositivamente ricorrenti: uno stato è positivamente ricorrente se il tempo medio atteso per ritornare in quello stato, partendo da esso, è finito.\nNullamente ricorrenti: uno stato è nullamente ricorrente se il tempo medio atteso per ritornare in quello stato è infinito.\nRicorrenti di Harris: sono stati ricorrenti che vengono visitati infinite volte quando il tempo tende all’infinito, garantendo una certa frequenza di visita.\n\n\n\nJ.1.3 Aperiodicità\nUno stato \\(i\\) si dice aperiodico se il massimo comun divisore dei tempi di ritorno in \\(i\\) è 1. In altre parole, uno stato è aperiodico se non esiste un ciclo deterministico che vincola i tempi in cui la catena può ritornare in quello stato. Una catena di Markov è aperiodica se tutti i suoi stati sono aperiodici. L’aperiodicità evita che la catena rimanga bloccata in una sequenza ciclica fissa, permettendo un comportamento più variegato nel tempo.\n\n\nJ.1.4 Stazionarietà\nNella teoria delle catene di Markov, una distribuzione stazionaria \\(\\pi\\) è una distribuzione di probabilità sugli stati tale che, se la catena parte con questa distribuzione iniziale, la distribuzione delle probabilità rimane invariata nel tempo. Matematicamente, se \\(\\pi\\) è la distribuzione stazionaria, allora \\(\\pi P = \\pi\\), dove \\(P\\) è la matrice di transizione della catena di Markov. La stazionarietà è fondamentale per analizzare il comportamento a lungo termine della catena, poiché una volta raggiunta, la distribuzione di probabilità sugli stati rimane costante.\n\n\nJ.1.5 Ergodicità\nUna catena di Markov si dice ergodica se è irriducibile e aperiodica, e tutti i suoi stati sono positivamente ricorrenti. Questo implica che la catena, nel lungo termine, visita tutti gli stati secondo una distribuzione di probabilità che diventa stabile (stazionaria) e non dipende dallo stato iniziale. La proprietà di ergodicità è cruciale in quanto garantisce che le medie temporali di una funzione sugli stati della catena convergono alle medie rispetto alla distribuzione stazionaria.\n\n\nJ.1.6 Convergenza\nLa convergenza di una catena di Markov si riferisce al processo mediante il quale la distribuzione di probabilità degli stati si avvicina alla distribuzione stazionaria \\(\\pi\\) man mano che il numero di passi \\(n\\) tende all’infinito. In altre parole, indipendentemente dalla distribuzione iniziale degli stati, la distribuzione della catena dopo un lungo periodo di tempo sarà vicina a \\(\\pi\\). Questo concetto è strettamente legato alla stazionarietà, poiché la convergenza descrive il percorso verso l’equilibrio, mentre la stazionarietà rappresenta lo stato di equilibrio raggiunto.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>J</span>  <span class='chapter-title'>Catene di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a47_first_order_markov.html#sommario",
    "href": "chapters/appendix/a47_first_order_markov.html#sommario",
    "title": "Appendice J — Catene di Markov",
    "section": "J.2 Sommario",
    "text": "J.2 Sommario\nUna catena di Markov è una sequenza di variabili aleatorie \\(X_0, X_1, X_2, \\ldots\\) che soddisfa la cosiddetta proprietà di Markov. Questa proprietà stabilisce che, dato lo stato attuale della catena, il futuro è indipendente dal passato. Formalmente, questa proprietà si esprime come:\n\\[\nP(X_{n+1} = j \\mid X_n = i, X_{n-1} = i_{n-1}, \\ldots, X_0 = i_0) = P(X_{n+1} = j \\mid X_n = i) = q_{ij},\n\\]\ndove \\(q_{ij}\\) rappresenta la probabilità di passare dallo stato \\(i\\) allo stato \\(j\\) in un singolo passo. Queste probabilità di transizione sono organizzate in una matrice di transizione \\(Q = (q_{ij})\\), in cui ogni riga corrisponde a una distribuzione di probabilità condizionata sui possibili stati futuri dato l’attuale stato della catena.\nLa distribuzione di probabilità degli stati della catena dopo \\(n\\) passi può essere calcolata moltiplicando la matrice di transizione \\(Q\\) elevata alla potenza \\(n\\) per il vettore di probabilità iniziale \\(s\\), che descrive la distribuzione di probabilità degli stati al tempo \\(0\\). In simboli, questo è rappresentato da \\(sQ^n\\), che fornisce la distribuzione di probabilità marginale degli stati dopo \\(n\\) passi.\nGli stati di una catena di Markov possono essere classificati come ricorrenti o transitori. Uno stato è ricorrente se la catena torna a questo stato ripetutamente nel tempo; è transitorio se la catena potrebbe lasciare questo stato per non ritornarvi mai più. Gli stati possono anche avere un periodo associato, definito come il massimo comun divisore dei numeri di passi necessari per ritornare allo stato stesso. Una catena di Markov è detta irriducibile se è possibile raggiungere qualsiasi stato da qualsiasi altro stato in un numero finito di passi, ed è aperiodica se ogni stato ha periodo 1.\nUna distribuzione stazionaria di una catena di Markov è una distribuzione di probabilità che rimane invariata nel tempo. Se la catena inizia con questa distribuzione, continuerà a mantenerla in ogni passo successivo. Questa condizione si esprime matematicamente come \\(sQ = s\\), dove \\(s\\) è il vettore di probabilità stazionaria e \\(Q\\) è la matrice di transizione. Per una catena di Markov finita che è irriducibile e aperiodica, esiste una distribuzione stazionaria unica verso la quale la catena converge indipendentemente dalla distribuzione iniziale.\nUn concetto importante nelle catene di Markov è quello di reversibilità. Una catena di Markov è detta reversibile se esiste una distribuzione di probabilità \\(s\\) tale che, per ogni coppia di stati \\(i\\) e \\(j\\), la condizione di reversibilità \\(s_i q_{ij} = s_j q_{ji}\\) sia soddisfatta. Questa condizione garantisce che \\(s\\) sia una distribuzione stazionaria per la catena. Le catene di Markov reversibili sono particolarmente utili in applicazioni pratiche come gli algoritmi di simulazione Monte Carlo, ad esempio l’algoritmo di Metropolis-Hastings, poiché permettono di progettare catene che convergono rapidamente alla distribuzione di probabilità desiderata.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>J</span>  <span class='chapter-title'>Catene di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a47_first_order_markov.html#letteratura",
    "href": "chapters/appendix/a47_first_order_markov.html#letteratura",
    "title": "Appendice J — Catene di Markov",
    "section": "J.3 Letteratura",
    "text": "J.3 Letteratura\nI metodi markoviani sono stati ampiamente utilizzati in vari ambiti della psicologia e dell’educazione. Una delle applicazioni più comuni di questi metodi è il clustering dei dati sequenziali (Törmänen et al. (2022); Törmänen et al. (2023); Fincham et al. (2018)). Ad esempio, i modelli nascosti di Markov (HMM) sono stati utilizzati per raggruppare le sequenze di dati tracciati da sistemi di gestione dell’apprendimento (LMS) degli studenti, al fine di identificare i loro schemi di attività, ovvero le tattiche e strategie di apprendimento (Fincham et al. (2018)). Un uso molto diffuso dei modelli di Markov di primo ordine è quello di mappare le transizioni degli studenti tra diverse attività di apprendimento. Per esempio, Matcha et al. (2020) ha utilizzato modelli di Markov di primo ordine per studiare i processi di transizione degli studenti tra diverse strategie di apprendimento. Altri usi includono lo studio delle transizioni tra diverse strategie di scrittura accademica (Peeters et al. (2020)), tra eventi di apprendimento autoregolato (Lim et al. (2023)), o all’interno di contesti di apprendimento collaborativo (Saqr & López-Pernas (2023)). Esempi più specifici nell’ambito psicologico comprendono lo studio delle influenze reciproche tra stati affettivi (Cipresso et al. (2023)) e l’analisi degli effetti psicologici che dipendono dal tempo nelle sequenze di decision-making (Gunawan et al. (2022)).\n\n\n\n\nCipresso, P., Borghesi, F., & Chirico, A. (2023). Affects affect affects: A Markov chain. Frontiers in Psychology, 14, 1162655.\n\n\nFincham, E., Gašević, D., Jovanović, J., & Pardo, A. (2018). From study tactics to learning strategies: An analytical method for extracting interpretable representations. IEEE Transactions on Learning Technologies, 12(1), 59–72.\n\n\nGunawan, D., Hawkins, G. E., Kohn, R., Tran, M.-N., & Brown, S. D. (2022). Time-evolving psychological processes over repeated decisions. Psychological Review, 129(3), 438–456.\n\n\nLim, L., Bannert, M., Graaf, J. van der, Singh, S., Fan, Y., Surendrannair, S., Rakovic, M., Molenaar, I., Moore, J., & Gašević, D. (2023). Effects of real-time analytics-based personalized scaffolds on students’ self-regulated learning. Computers in Human Behavior, 139, 107547.\n\n\nMatcha, W., Gasevic, D., Jovanovic, J., Pardo, A., Lim, L., Maldonado-Mahauad, J., Gentili, S., Pérez-Sanagustı́n, M., Tsai, Y.-S., et al. (2020). Analytics of Learning Strategies: Role of Course Design and Delivery Modality Authors. Journal of Learning Analytics, 7(2), 45–71.\n\n\nPeeters, W., Saqr, M., & Viberg, O. (2020). Applying learning analytics to map students’ self-regulated learning tactics in an academic writing course. Proceedings of the 28th International Conference on Computers in Education, 1, 245–254.\n\n\nSaqr, M., & López-Pernas, S. (2023). The temporal dynamics of online problem-based learning: Why and when sequence matters. International Journal of Computer-Supported Collaborative Learning, 18(1), 11–37.\n\n\nTörmänen, T., Järvenoja, H., Saqr, M., Malmberg, J., & Järvelä, S. (2022). A person-centered approach to study students’ socio-emotional interaction profiles and regulation of collaborative learning. Frontiers in Education, 7, 866612.\n\n\nTörmänen, T., Järvenoja, H., Saqr, M., Malmberg, J., & Järvelä, S. (2023). Affective states and regulation of learning during socio-emotional interactions in secondary school collaborative groups. British Journal of Educational Psychology, 93, 48–70.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>J</span>  <span class='chapter-title'>Catene di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a50_lin_fun.html",
    "href": "chapters/appendix/a50_lin_fun.html",
    "title": "Appendice K — La funzione lineare",
    "section": "",
    "text": "K.1 Concetto di Funzione\nNello studio dei fenomeni naturali e nella risoluzione di problemi tecnici e matematici, è spesso necessario considerare la variazione di una grandezza come dipendente dalla variazione di un’altra. Ad esempio, nello studio del moto, il percorso compiuto da un oggetto può essere visto come una grandezza variabile in funzione del tempo: il cammino percorso è, dunque, una funzione del tempo.\nQuesta considerazione ci conduce alla seguente definizione:\nSe a ogni valore della variabile \\(x\\) (all’interno di un certo intervallo) corrisponde un valore ben definito di un’altra variabile \\(y\\), allora si dice che \\(y\\) è una funzione di \\(x\\). In notazione funzionale si scrive:\n\\[\ny = f(x) \\quad \\text{o anche} \\quad y = \\varphi(x).\n\\]\nLa variabile \\(x\\) è detta variabile indipendente o argomento della funzione. La relazione che lega \\(x\\) a \\(y\\) si chiama relazione funzionale. La lettera \\(f\\) nella notazione \\(y = f(x)\\) indica che per ottenere il valore di \\(y\\) a partire da \\(x\\) è necessario applicare una certa “regola” o “operazione”. In modo analogo, si possono utilizzare anche altre notazioni come \\(u = \\varphi(x)\\).\nLa notazione \\(y = C\\), dove \\(C\\) è una costante, indica una funzione il cui valore rimane invariato per qualunque valore di \\(x\\).\nL’insieme dei valori di \\(x\\) per cui la funzione \\(y = f(x)\\) è definita si chiama dominio di definizione della funzione.\nSe per valori crescenti della variabile indipendente \\(x\\) anche il valore della funzione \\(y = f(x)\\) aumenta, allora la funzione si dice crescente. Analogamente, se a valori crescenti di \\(x\\) corrispondono valori decrescenti della funzione \\(y = f(x)\\), la funzione si dice decrescente.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>K</span>  <span class='chapter-title'>La funzione lineare</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a50_lin_fun.html#la-retta",
    "href": "chapters/appendix/a50_lin_fun.html#la-retta",
    "title": "Appendice K — La funzione lineare",
    "section": "K.2 La Retta",
    "text": "K.2 La Retta\nLa funzione lineare è definita come:\n\\[\nf(x) = a + b x,\n\\]\ndove \\(a\\) e \\(b\\) sono costanti. Il grafico di tale funzione è una retta. Qui, \\(b\\) è detto coefficiente angolare, mentre \\(a\\) è l’intercetta con l’asse delle \\(y\\). In altri termini, la retta interseca l’asse \\(y\\) nel punto \\((0, a)\\).\nPer comprendere il ruolo di \\(a\\) e \\(b\\), consideriamo prima il caso particolare:\n\\[\ny = b x.\n\\]\nQuesta espressione rappresenta una proporzionalità diretta tra \\(x\\) e \\(y\\): al crescere di \\(x\\), \\(y\\) varia in proporzione. Nel caso generale:\n\\[\ny = a + b x,\n\\]\nil termine \\(a\\) “trasla” verticalmente il grafico, aggiungendo una costante a ogni valore \\(b x\\).\nIl segno del coefficiente \\(b\\) determina il comportamento della funzione lineare:\n\nSe \\(b &gt; 0\\), il valore di \\(y\\) aumenta all’aumentare di \\(x\\).\n\nSe \\(b &lt; 0\\), il valore di \\(y\\) diminuisce all’aumentare di \\(x\\).\n\nSe \\(b = 0\\), il grafico è una retta orizzontale e \\(y\\) rimane costante.\n\nPossiamo dare un’interpretazione geometrica ancora più intuitiva se consideriamo variazioni (incrementi) di \\(x\\). Preso un punto \\(x_0\\) e aggiungendo un piccolo incremento \\(\\varepsilon\\), definiamo:\n\\[\n\\Delta x = (x_0 + \\varepsilon) - x_0 = \\varepsilon,\n\\] \\[\n\\Delta y = f(x_0 + \\varepsilon) - f(x_0).\n\\]\nIl coefficiente angolare \\(b\\) può essere interpretato come il rapporto tra la variazione di \\(y\\) e la variazione di \\(x\\):\n\\[\nb = \\frac{\\Delta y}{\\Delta x} = \\frac{f(x_0 + \\varepsilon) - f(x_0)}{(x_0 + \\varepsilon) - x_0}.\n\\]\nQuesto rapporto è costante e non dipende dalla scelta di \\(x_0\\) o di \\(\\varepsilon\\). In particolare, se scegliamo \\(\\Delta x = 1\\), il coefficiente angolare \\(b\\) rappresenta semplicemente di quanto varia \\(y\\) quando \\(x\\) aumenta di un’unità.\n\n\n\n\n\n\n\nFigura K.1: La funzione lineare \\(y = a + bx\\).\n\n\n\nCome mostrato in figura, il coefficiente \\(b\\) indica la pendenza della retta, ossia quanto “ripida” è la sua inclinazione rispetto all’asse orizzontale.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>K</span>  <span class='chapter-title'>La funzione lineare</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a71_install_cmdstan.html",
    "href": "chapters/appendix/a71_install_cmdstan.html",
    "title": "Appendice L — Come installare CmdStan",
    "section": "",
    "text": "L.1 Windows\nSu macOS e Linux, questa configurazione dovrebbe essere già pronta di default.\nSu Windows è necessario installare RTools e configurare PATH:\nProblemi comuni:",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>L</span>  <span class='chapter-title'>Come installare CmdStan</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a71_install_cmdstan.html#windows",
    "href": "chapters/appendix/a71_install_cmdstan.html#windows",
    "title": "Appendice L — Come installare CmdStan",
    "section": "",
    "text": "Installazione di RTools:\n\nVai su https://cran.r-project.org/bin/windows/Rtools/\nScarica la versione di RTools compatibile con la tua versione di R (Generalmente, RTools 4.3 per R 4.3.x, RTools 4.2 per R 4.2.x, etc.)\nEsegui l’installer scaricato\nIMPORTANTE: Durante l’installazione, seleziona la casella “Add rtools to system PATH”\n\nVerifica dell’installazione e configurazione del PATH:\n\nApri PowerShell o Command Prompt\nVerifica se RTools è nel PATH digitando:\n\ngcc --version\nSe vedi la versione di gcc, RTools è nel PATH.\nSe RTools non è nel PATH, devi aggiungerlo manualmente:\n\nCerca “Impostazioni di Sistema” in Windows\nClicca su “Impostazioni di sistema avanzate”\nClicca su “Variabili d’ambiente”\nNella sezione “Variabili di sistema”, trova “Path”\nClicca “Modifica”\nClicca “Nuovo” e aggiungi questi percorsi (sostituisci X.X con la tua versione di RTools):\nC:\\rtools4X\\mingw64\\bin\nC:\\rtools4X\\usr\\bin\n\nVerifica finale:\n\nChiudi e riapri il terminale\nProva questi comandi:\n\ngcc --version\nmake --version\nSe entrambi i comandi mostrano le versioni, l’installazione è completa.\nTest in R:\n\nApri R o RStudio\nEsegui:\n\nSys.which(\"make\")\nDovrebbe mostrare il percorso di make.\n\n\n\nSe i comandi non vengono riconosciuti dopo aver aggiunto il PATH, prova a riavviare il computer.\nSe usi RStudio, potrebbe essere necessario riavviarlo dopo aver modificato il PATH.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>L</span>  <span class='chapter-title'>Come installare CmdStan</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#grafici-a-barre",
    "href": "chapters/eda/04_exploring_qualitative_data.html#grafici-a-barre",
    "title": "16  Esplorare i dati qualitativi",
    "section": "\n16.5 Grafici a barre",
    "text": "16.5 Grafici a barre\nI grafici a barre sono uno degli strumenti più utilizzati per rappresentare visivamente i dati categoriali. Essi consentono di confrontare le frequenze delle categorie in modo immediato, mostrando chiaramente quali valori sono più comuni o più rari nel campione.\n\n16.5.1 Grafico a barre con una variabile\nNel caso più semplice, un grafico a barre rappresenta una sola variabile categoriale. Le categorie sono riportate lungo un asse (di solito l’asse orizzontale) e la lunghezza o altezza delle barre è proporzionale al numero di osservazioni per ciascuna categoria.\nAd esempio, per i dati sui pinguini possiamo visualizzare il numero totale di esemplari osservati in ciascuna isola:\n\nggplot(df, aes(x = island)) +\n  geom_bar() +\n  ggtitle(\"Numero totale di pinguini per isola\") +\n  xlab(\"Isola\") +\n  ylab(\"Numero di pinguini\") \n\n\n\n\n\n\n\nAllo stesso modo, possiamo costruire un grafico a barre che mostra la distribuzione delle specie:\n\nggplot(df, aes(x = species)) +\n  geom_bar() +\n  ggtitle(\"Numero totale di pinguini per specie\") +\n  xlab(\"Specie\") +\n  ylab(\"Numero di pinguini\")\n\n\n\n\n\n\n\nQuesti grafici permettono di confrontare rapidamente le frequenze delle categorie, mettendo in evidenza quali specie o quali isole sono più rappresentate.\n\n16.5.2 Grafico a barre con due variabili\nUn grafico a barre può essere esteso per visualizzare simultaneamente due variabili categoriali. In questo caso, una variabile viene posta sull’asse delle ascisse, mentre la seconda è distinta tramite colori diversi o barre impilate.\nAd esempio, possiamo osservare come le diverse specie di pinguini si distribuiscono sulle isole:\n\nggplot(df, aes(x = island, fill = species)) +\n  geom_bar(position = \"stack\") +\n  ggtitle(\"Numero di pinguini per specie e isola\") +\n  xlab(\"Isola\") +\n  ylab(\"Numero di pinguini\") +\n  labs(fill = \"Specie\") \n\n\n\n\n\n\n\nOppure, invertendo i ruoli delle due variabili, possiamo rappresentare le specie sull’asse delle ascisse e distinguere le isole tramite colori:\n\nggplot(df, aes(x = species, fill = island)) +\n  geom_bar(position = \"stack\") +\n  ggtitle(\"Numero di pinguini per isola e specie\") +\n  xlab(\"Specie\") +\n  ylab(\"Numero di pinguini\") +\n  labs(fill = \"Isola\")\n\n\n\n\n\n\n\nQuesti grafici permettono di esplorare visivamente l’associazione tra due variabili qualitative.\n\n16.5.3 Frequenze relative\nOltre alle frequenze assolute, è spesso utile rappresentare le frequenze relative (cioè le proporzioni). Questo approccio elimina l’effetto del numero totale di osservazioni, rendendo più facile confrontare le distribuzioni tra gruppi di dimensioni diverse.\nAd esempio, il grafico seguente mostra la composizione relativa delle specie per ogni isola:\n\nggplot(df, aes(x = island, fill = species)) +\n  geom_bar(position = \"fill\") +\n  ggtitle(\"Proporzione di pinguini per specie e isola\") +\n  xlab(\"Isola\") +\n  ylab(\"Proporzione\") +\n  labs(fill = \"Specie\")\n\n\n\n\n\n\n\nQui ogni barra è normalizzata a 1: l’altezza di ciascun segmento rappresenta la proporzione di una specie all’interno dell’isola. In questo modo è più facile capire quale specie prevale in ciascun contesto, indipendentemente dal numero complessivo di pinguini osservati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#proporzioni-di-riga-e-di-colonna",
    "href": "chapters/eda/04_exploring_qualitative_data.html#proporzioni-di-riga-e-di-colonna",
    "title": "16  Esplorare i dati qualitativi",
    "section": "\n16.4 Proporzioni di riga e di colonna",
    "text": "16.4 Proporzioni di riga e di colonna\nFinora ci siamo concentrati sui conteggi assoluti. Tuttavia, in molti casi è più informativo osservare le proporzioni relative.\n\nLe proporzioni di riga descrivono come si distribuiscono le categorie di una variabile all’interno di ciascun gruppo dell’altra.\nLe proporzioni di colonna, al contrario, mostrano la distribuzione di una variabile rispetto alle categorie dell’altra.\n\nQuesti calcoli si ottengono facilmente a partire dalla tabella di contingenza.\n\n16.4.1 Proporzioni di riga (specie per isola)\n\ndf %&gt;%\n  tabyl(island, species) %&gt;%   # Tabella di contingenza\n  adorn_percentages(\"row\") %&gt;% # Proporzioni rispetto a ciascuna isola\n  adorn_totals(\"col\") %&gt;%      # Totali di riga\n  adorn_pct_formatting(digits = 2)\n#&gt;     island  Adelie Chinstrap Gentoo   Total\n#&gt;     Biscoe  26.99%     0.00% 73.01% 100.00%\n#&gt;      Dream  44.72%    55.28%  0.00% 100.00%\n#&gt;  Torgersen 100.00%     0.00%  0.00% 100.00%\n\nQuesto output mostra, per ogni isola, la percentuale di pinguini appartenenti a ciascuna specie.\n\n16.4.2 Proporzioni di colonna (isole per specie)\n\ndf |&gt; \n  tabyl(island, species) |&gt; \n  adorn_percentages(\"col\") |&gt;  # Proporzioni rispetto a ciascuna specie\n  adorn_totals(\"row\") |&gt; \n  adorn_pct_formatting(digits = 2)\n#&gt;     island  Adelie Chinstrap  Gentoo\n#&gt;     Biscoe  30.14%     0.00% 100.00%\n#&gt;      Dream  37.67%   100.00%   0.00%\n#&gt;  Torgersen  32.19%     0.00%   0.00%\n#&gt;      Total 100.00%   100.00% 100.00%\n\nQui vediamo, per ciascuna specie, su quali isole si distribuiscono i pinguini e con quale proporzione.\nIn sintesi, le proporzioni di riga e colonna forniscono un dettaglio numerico che aiuta a interpretare meglio le relazioni tra le variabili categoriali.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#mosaic-plot",
    "href": "chapters/eda/04_exploring_qualitative_data.html#mosaic-plot",
    "title": "16  Esplorare i dati qualitativi",
    "section": "\n16.6 Mosaic plot",
    "text": "16.6 Mosaic plot\nIl Mosaic plot è una tecnica di visualizzazione particolarmente adatta per rappresentare le tabelle di contingenza. A differenza di un semplice grafico a barre impilate, questo tipo di grafico mostra contemporaneamente:\n\nla distribuzione interna delle categorie di una variabile,\nla dimensione relativa complessiva dei gruppi della variabile principale.\n\nIn pratica, non ci dice solo come le categorie si suddividono all’interno dei gruppi, ma anche quanto grandi sono i gruppi stessi.\n\nmosaic(\n  ~ species + island, \n  data = df, \n  main = \"Mosaic Plot of Species and Island\",\n  shade = TRUE\n)\n\n\n\n\n\n\n\n\n16.6.1 Come leggere un mosaic plot\n\n\nDimensioni dei rettangoli\n\nLa larghezza rappresenta la dimensione relativa dei gruppi della variabile principale (island).\nL’altezza indica la proporzione delle categorie della variabile secondaria (species) all’interno di ciascun gruppo.\n\n\n\nColori (opzione shade = TRUE)\n\nI colori evidenziano deviazioni dalle frequenze attese in caso di indipendenza statistica.\nUn colore scuro segnala che in quel gruppo la frequenza osservata è molto diversa da quella attesa sotto indipendenza.\n\n\n\nInterpretazione pratica\n\nUn rettangolo largo e alto segnala una categoria numerosa in un gruppo consistente.\nUn rettangolo stretto o sottile indica una categoria rara o assente in quel gruppo.\n\n\n\nIn questo esempio, vediamo chiaramente che:\n\ngli Adelie sono presenti in tutte le isole,\ni Chinstrap compaiono solo a Dream,\ni Gentoo solo a Biscoe.\n\nIl Mosaic plot è quindi utile per cogliere schemi di associazione tra variabili categoriali e valutare rapidamente quali combinazioni sono predominanti o assenti.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#introduzione",
    "href": "chapters/eda/06_data_visualization.html#introduzione",
    "title": "18  Principi della visualizzazione dei dati",
    "section": "",
    "text": "In questo capitolo vengono introdotti i principi fondamentali della visualizzazione dei dati, accompagnati da esempi concreti e da una discussione sui principali errori da evitare. La visualizzazione non è soltanto un supporto estetico: è uno strumento essenziale per interpretare, comunicare e validare i risultati delle analisi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#introduzione",
    "href": "chapters/eda/04_exploring_qualitative_data.html#introduzione",
    "title": "16  Esplorare i dati qualitativi",
    "section": "",
    "text": "In questo capitolo ci concentreremo sull’analisi esplorativa dei dati (EDA) applicata ai dati qualitativi e categoriali. In psicologia la raccolta di dati qualitativi e categoriali è estremamente frequente: si pensi alle variabili sociodemografiche (genere, stato civile, livello di istruzione), alle risposte a item a scelta multipla nei questionari, alle diagnosi cliniche, o alle categorie di comportamento osservato in laboratorio. Prima di procedere a modelli complessi, è fondamentale esplorare questi dati per comprenderne la struttura, individuare pattern ricorrenti e riconoscere eventuali anomalie.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#introduzione",
    "href": "chapters/eda/05_exploring_numeric_data.html#introduzione",
    "title": "17  Esplorare i dati numerici",
    "section": "",
    "text": "In questo capitolo ci concentreremo sull’analisi dei dati numerici. In particolare, esamineremo le distribuzioni di frequenza e i quantili, insieme alle tecniche di visualizzazione più comuni, come l’istogramma, l’istogramma smussato e il box-plot. Tratteremo sia gli aspetti computazionali che quelli interpretativi di queste misure, fornendo strumenti utili non solo per una comprensione personale, ma anche per la comunicazione efficace dei risultati, in particolare con chi utilizza questi dati per prendere decisioni pratiche nel mondo reale.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#il-ciclo-di-box",
    "href": "chapters/mcmc/07_bayesian_workflow.html#il-ciclo-di-box",
    "title": "60  Flusso di lavoro bayesiano",
    "section": "60.1 Il ciclo di Box",
    "text": "60.1 Il ciclo di Box\nNegli anni ’60, lo statistico George Box descrisse la modellizzazione come un ciclo continuo di costruzione, valutazione e revisione. Questo approccio, noto come Ciclo di Box, è diventato un punto di riferimento anche per il workflow bayesiano.\nL’idea chiave è semplice: i modelli non sono mai perfetti, ma strumenti che possono essere continuamente migliorati.\n\n\n\nFigura tratta da Blei (2014).\n\n\nIl ciclo comprende quattro fasi:\n\nFormulare un modello sulla base delle conoscenze disponibili;\nFare inferenza, cioè stimare parametri e incertezze;\nValutare il modello, controllando quanto descrive bene i dati;\nRivedere il modello, correggendo le discrepanze.\n\nIl flusso di lavoro bayesiano si integra bene con questo ciclo perché le nostre convinzioni possono essere aggiornate man mano che arrivano nuovi dati.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#le-fasi-del-workflow-bayesiano",
    "href": "chapters/mcmc/07_bayesian_workflow.html#le-fasi-del-workflow-bayesiano",
    "title": "60  Flusso di lavoro bayesiano",
    "section": "60.2 Le fasi del workflow bayesiano",
    "text": "60.2 Le fasi del workflow bayesiano\nNella pratica, il workflow bayesiano segue alcune tappe principali:\n\nDefinizione della domanda di ricerca: partire da un problema chiaro e da un’ipotesi sul processo che genera i dati.\nCostruzione del modello: tradurre l’ipotesi in un modello probabilistico.\nSimulazioni a priori: generare dati fittizi dai soli priori per capire se le ipotesi iniziali sono ragionevoli.\nAdattamento ai dati: stimare i parametri del modello sui dati osservati.\nVerifiche a posteriori: confrontare i dati osservati con quelli simulati a partire dal modello stimato.\nDiagnostiche: controllare che il procedimento di stima sia andato a buon fine (per esempio, che le catene MCMC abbiano esplorato bene lo spazio dei parametri).\nIterazione: tornare indietro e migliorare il modello quando necessario.\n\nQuesta sequenza non è lineare: spesso bisogna ripetere più volte alcuni passaggi, fino a raggiungere un equilibrio tra semplicità e capacità esplicativa.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#verifiche-predittive",
    "href": "chapters/mcmc/07_bayesian_workflow.html#verifiche-predittive",
    "title": "60  Flusso di lavoro bayesiano",
    "section": "60.3 Verifiche predittive",
    "text": "60.3 Verifiche predittive\nUno strumento centrale sono le verifiche predittive.\n\nLe verifiche a priori controllano che i priori scelti non producano scenari irrealistici.\nLe verifiche a posteriori servono per confrontare i dati osservati con i dati che il modello, una volta stimato, sarebbe capace di generare.\n\nSe il modello produce dati molto diversi da quelli reali, vuol dire che qualcosa va rivisto.\nQueste verifiche non sono test statistici “passa/non passa”, ma occasioni di apprendimento: ci dicono dove il modello funziona e dove deve essere migliorato.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio_stan.html",
    "href": "chapters/mcmc/08_stan_odds_ratio_stan.html",
    "title": "59  Analisi bayesiana dell’odds ratio",
    "section": "",
    "text": "Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nPreparazione del Notebook\nL’odds ratio (OR) rappresenta una misura statistica fondamentale per quantificare l’associazione tra una variabile espositiva (o condizione di interesse) e un outcome binario. Nello specifico, l’OR compara la probabilità relativa del verificarsi dell’evento nei gruppi a confronto, fornendo quindi una misura di effetto particolarmente utile in ambito epidemiologico.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Analisi bayesiana dell'odds ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio_stan.html#odds",
    "href": "chapters/mcmc/08_stan_odds_ratio_stan.html#odds",
    "title": "59  Analisi bayesiana dell’odds ratio (Stan)",
    "section": "\n59.1 Odds",
    "text": "59.1 Odds\nIl termine “odds” rappresenta il rapporto tra la probabilità che un evento si verifichi e la probabilità che l’evento opposto si verifichi. Matematicamente, l’odds può essere calcolato come:\n\\[\n\\text{odds} = \\frac{\\pi}{1-\\pi},\n\\]\ndove \\(\\pi\\) rappresenta la probabilità dell’evento di interesse.\nMentre una probabilità \\(\\pi\\) è sempre compresa tra 0 e 1, gli odds possono variare da 0 a infinito. Per comprendere meglio gli odds lungo questo spettro, consideriamo tre diversi scenari in cui \\(\\pi\\) rappresenta la probabilità di un evento.\nSe la probabilità di un evento è \\(\\pi = \\frac{2}{3}\\), allora la probabilità che l’evento non si verifichi è \\(1 - \\pi = \\frac{1}{3}\\) e gli odds del verificarsi dell’evento sono:\n\\[\n\\text{odds} = \\frac{2/3}{1-2/3} = 2.\n\\]\nQuesto significa che la probabilità che l’evento si verifichi è il doppio della probabilità che non si verifichi.\nSe, invece, la probabilità dell’evento è \\(\\pi = \\frac{1}{3}\\), allora gli odds che l’evento si verifichi sono la metà rispetto agli odds che non si verifichi:\n\\[\n\\text{odds} = \\frac{1/3}{1-1/3} = \\frac{1}{2}.\n\\]\nInfine, se la probabilità dell’evento è \\(\\pi = \\frac{1}{2}\\), allora gli odds dell’evento sono pari a 1:\n\\[\n\\text{odds} = \\frac{1/2}{1-1/2} = 1.\n\\]\n\n59.1.1 Interpretazione\nGli odds possono essere interpretati nel modo seguente. Consideriamo un evento di interesse con probabilità \\(\\pi \\in [0, 1]\\) e gli odds corrispondenti \\(\\frac{\\pi}{1-\\pi} \\in [0, \\infty)\\). Confrontando gli odds con il valore 1, possiamo ottenere una prospettiva sull’incertezza dell’evento:\n\nGli odds di un evento sono inferiori a 1 se e solo se le probabilità dell’evento sono inferiori al 50-50, cioè \\(\\pi &lt; 0.5\\).\nGli odds di un evento sono uguali a 1 se e solo se le probabilità dell’evento sono del 50-50, cioè \\(\\pi = 0.5\\).\nGli odds di un evento sono superiori a 1 se e solo se le probabilità dell’evento sono superiori al 50-50, cioè \\(\\pi &gt; 0.5\\).\n\nUno dei motivi per preferire l’uso dell’odds rispetto alla probabilità, nonostante quest’ultima sia un concetto più intuitivo, risiede nel fatto che quando le probabilità si avvicinano ai valori estremi (cioè 0 o 1), è più facile rilevare e apprezzare le differenze tra gli odds piuttosto che le differenze tra le probabilità.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Analisi bayesiana dell'odds ratio (Stan)</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio_stan.html#odds-ratio",
    "href": "chapters/mcmc/08_stan_odds_ratio_stan.html#odds-ratio",
    "title": "59  Analisi bayesiana dell’odds ratio (Stan)",
    "section": "\n59.2 Odds Ratio",
    "text": "59.2 Odds Ratio\nQuando abbiamo una variabile di interesse espressa come proporzione, possiamo confrontare i gruppi utilizzando l’odds ratio. L’odds ratio rappresenta il rapporto tra gli odds di un evento in un gruppo e gli odds dello stesso evento in un secondo gruppo:\n\\[\nOR = \\frac{odds_1}{odds_2} = \\frac{p_1/(1-p_1)}{p_2/(1-p_2)}.\n\\]\nInterpretazione:\n\nOR = 1: l’appartenenza al gruppo non influenza il risultato;\nOR &gt; 1: l’appartenenza al gruppo specificato al numeratore dell’OR aumenta la probabilità dell’evento rispetto al gruppo specificato al denominatore;\nOR &lt; 1: l’appartenenza al gruppo specificato al numeratore dell’OR riduce la probabilità dell’evento rispetto al gruppo specificato al denominatore.\n\nL’odds ratio è particolarmente utile quando vogliamo confrontare due gruppi e vedere come l’appartenenza a uno di essi influenza la probabilità di un certo evento. Ad esempio, consideriamo uno studio psicologico in cui stiamo valutando l’efficacia di una terapia comportamentale per ridurre l’ansia. Possiamo suddividere i partecipanti allo studio in due gruppi: quelli che sono stati sottoposti al trattamento (gruppo di trattamento) e quelli che non sono stati sottoposti al trattamento (gruppo di controllo).\nCalcolando l’odds ratio tra il gruppo di trattamento e il gruppo di controllo, possiamo capire se la terapia ha aumentato o ridotto la probabilità di riduzione dell’ansia. Se l’odds ratio è maggiore di 1, significa che la terapia ha aumentato le probabilità di riduzione dell’ansia; se è inferiore a 1, significa che il trattamento ha ridotto le probabilità di riduzione dell’ansia. L’odds ratio ci fornisce quindi una misura dell’effetto della terapia rispetto al controllo.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Analisi bayesiana dell'odds ratio (Stan)</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio_stan.html#logaritmo-dellodds-ratio",
    "href": "chapters/mcmc/08_stan_odds_ratio_stan.html#logaritmo-dellodds-ratio",
    "title": "59  Analisi bayesiana dell’odds ratio (Stan)",
    "section": "\n59.3 Logaritmo dell’Odds Ratio",
    "text": "59.3 Logaritmo dell’Odds Ratio\nIl logaritmo dell’odds ratio è una trasformazione matematica molto utilizzata nell’analisi statistica, specialmente nella regressione logistica. Essa permette di rendere l’odds ratio interpretabile su una scala lineare, semplificando l’analisi e l’interpretazione dei risultati.\nLa formula per calcolare il logaritmo dell’odds ratio è la seguente:\n\\[\n\\text{logit}(OR) = \\log(OR) = \\log\\left(\\frac{odds_1}{odds_2}\\right).\n\\]\nIn altre parole, il logaritmo dell’odds ratio è il logaritmo naturale del rapporto tra gli odds di un evento nel primo gruppo e gli odds dello stesso evento nel secondo gruppo.\n\n59.3.1 Interpretazione\nL’interpretazione del logaritmo dell’odds ratio è più intuitiva rispetto all’odds ratio stesso. Una variazione di una unità nel logaritmo dell’odds ratio corrisponde a un cambiamento costante nell’odds ratio stesso.\nSe il logaritmo dell’odds ratio è positivo, significa che l’odds dell’evento nel primo gruppo è maggiore rispetto al secondo gruppo. Più il valore del logaritmo dell’odds ratio si avvicina a zero, più l’odds dell’evento nei due gruppi si avvicina a essere simile.\nSe, invece, il logaritmo dell’odds ratio è negativo, l’odds dell’evento nel primo gruppo è inferiore rispetto al secondo gruppo. Un valore di logaritmo dell’odds ratio vicino a zero indica che l’odds dell’evento è simile nei due gruppi.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Analisi bayesiana dell'odds ratio (Stan)</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio_stan.html#analisi-bayesiana-delle-proporzioni",
    "href": "chapters/mcmc/08_stan_odds_ratio_stan.html#analisi-bayesiana-delle-proporzioni",
    "title": "59  Analisi bayesiana dell’odds ratio",
    "section": "\n59.4 Analisi bayesiana delle proporzioni",
    "text": "59.4 Analisi bayesiana delle proporzioni\nDopo aver introdotto i concetti di odds, odds ratio e logit, possiamo affrontare l’analisi bayesiana delle proporzioni. Questo approccio consente di confrontare le probabilità di due gruppi stimando direttamente la distribuzione a posteriori delle quantità di interesse, come l’odds ratio, e di rappresentare in modo esplicito l’incertezza delle stime attraverso intervalli di credibilità.\nIl cuore dell’approccio bayesiano è il teorema di Bayes, che permette di aggiornare le conoscenze iniziali, espresse sotto forma di distribuzione a priori, con l’evidenza fornita dai dati osservati. In questo modo si ottiene una distribuzione a posteriori che integra sia l’informazione empirica sia le assunzioni iniziali.\nPer illustrare la procedura useremo un set di dati fittizio ispirato a un classico esperimento di etologia descritto da Von Frisch (1914) e ripreso da Hoffmann et al. (2022). L’obiettivo dell’esperimento era verificare se le api fossero in grado di distinguere i colori. Nella fase di addestramento, le api del gruppo sperimentale venivano esposte a un disco blu e a un disco verde: soltanto il disco blu era ricoperto da una soluzione zuccherina, altamente appetibile. Il gruppo di controllo non riceveva alcun addestramento.\nNella fase di test la soluzione zuccherina veniva rimossa e si osservava il comportamento delle api. Qualora le api avessero effettivamente appreso l’associazione colore-ricompensa, ci si sarebbe attesi una preferenza persistente per il disco blu. I dati raccolti mostrano che nel gruppo sperimentale 130 api su 200 si sono avvicinate al disco blu, mentre nel gruppo di controllo la stessa scelta si è verificata in 100 casi su 200.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Analisi bayesiana dell'odds ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio_stan.html#analisi-bayesiana-dellodds-ratio",
    "href": "chapters/mcmc/08_stan_odds_ratio_stan.html#analisi-bayesiana-dellodds-ratio",
    "title": "59  Analisi bayesiana dell’odds ratio",
    "section": "\n59.6 Analisi bayesiana dell’odds ratio",
    "text": "59.6 Analisi bayesiana dell’odds ratio\nFinora abbiamo ottenuto una stima puntuale dell’OR, ma l’analisi bayesiana ci consente di andare oltre, valutando l’intera distribuzione a posteriori dell’odds ratio e quindi la nostra incertezza. Il modello bayesiano che utilizziamo è basato su due distribuzioni binomiali, una per ciascun gruppo:\n\\[\ny_1 \\sim \\text{Binomiale}(N_1, \\theta_1), \\qquad\ny_2 \\sim \\text{Binomiale}(N_2, \\theta_2),\n\\]\ndove \\(\\theta_1\\) e \\(\\theta_2\\) rappresentano le probabilità di scelta del disco blu nei due gruppi. Per entrambi i parametri adottiamo priori debolmente informative, ad esempio\n\\[\n\\theta_1 \\sim \\text{Beta}(2,2), \\qquad\n\\theta_2 \\sim \\text{Beta}(2,2).\n\\]\nUna volta osservati i dati, il teorema di Bayes aggiorna queste distribuzioni, producendo le posteriori di \\(\\theta_1\\) e \\(\\theta_2\\). Nel blocco generated quantities del modello Stan possiamo calcolare sia la differenza dei logit sia l’odds ratio corrispondente:\n\\[\n\\log(\\text{OR}) = \\operatorname{logit}(\\theta_1) - \\operatorname{logit}(\\theta_2), \\qquad\n\\text{OR} = \\exp\\{\\log(\\text{OR})\\}.\n\\]\nL’inferenza si basa quindi sulla distribuzione posteriore di OR. Da essa possiamo derivare, ad esempio, l’intervallo di credibilità al 90%. Se questo intervallo non comprende il valore 1, concludiamo che vi è un’evidenza consistente di una differenza tra i gruppi; in caso contrario, i dati non forniscono supporto sufficiente per affermare che l’effetto sia reale a livello di popolazione.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Analisi bayesiana dell'odds ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio_stan.html#il-codice-stan-auto-contenuto",
    "href": "chapters/mcmc/08_stan_odds_ratio_stan.html#il-codice-stan-auto-contenuto",
    "title": "59  Analisi bayesiana dell’odds ratio",
    "section": "\n59.6 3) Il codice Stan (auto-contenuto)",
    "text": "59.6 3) Il codice Stan (auto-contenuto)\n\nstancode &lt;- \"\ndata {\n  int&lt;lower=0&gt; N1;  int&lt;lower=0&gt; y1;\n  int&lt;lower=0&gt; N2;  int&lt;lower=0&gt; y2;\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; theta1;\n  real&lt;lower=0, upper=1&gt; theta2;\n}\nmodel {\n  // Priors (debolmente informativi)\n  theta1 ~ beta(2, 2);\n  theta2 ~ beta(2, 2);\n\n  // Likelihood\n  y1 ~ binomial(N1, theta1);\n  y2 ~ binomial(N2, theta2);\n}\ngenerated quantities {\n  real log_or  = logit(theta1) - logit(theta2);\n  real oddsratio = exp(log_or);\n}\n\"\nstan_file &lt;- cmdstanr::write_stan_file(stancode, dir = here::here(\"stan\"), basename = \"odds-ratio.stan\")\nmod &lt;- cmdstan_model(stan_file)\nmod$print()\n#&gt; \n#&gt; data {\n#&gt;   int&lt;lower=0&gt; N1;  int&lt;lower=0&gt; y1;\n#&gt;   int&lt;lower=0&gt; N2;  int&lt;lower=0&gt; y2;\n#&gt; }\n#&gt; parameters {\n#&gt;   real&lt;lower=0, upper=1&gt; theta1;\n#&gt;   real&lt;lower=0, upper=1&gt; theta2;\n#&gt; }\n#&gt; model {\n#&gt;   // Priors (debolmente informativi)\n#&gt;   theta1 ~ beta(2, 2);\n#&gt;   theta2 ~ beta(2, 2);\n#&gt; \n#&gt;   // Likelihood\n#&gt;   y1 ~ binomial(N1, theta1);\n#&gt;   y2 ~ binomial(N2, theta2);\n#&gt; }\n#&gt; generated quantities {\n#&gt;   real log_or  = logit(theta1) - logit(theta2);\n#&gt;   real oddsratio = exp(log_or);\n#&gt; }\n\nNel blocco generated quantities, calcoliamo l’odds ratio:\n\\[\n\\text{oddsratio} = \\frac{\\theta_1 / (1 - \\theta_1)}{\\theta_2 / (1 - \\theta_2)}.\n\\]\nQuesto rapporto delle odds ci dà una misura della forza dell’associazione tra l’evento e i gruppi.\nIn sintesi, il modello bayesiano utilizza i dati osservati per aggiornare le nostre convinzioni iniziali sui parametri \\(\\theta_1\\) e \\(\\theta_2\\), fornendo una distribuzione a posteriori che riflette sia le informazioni a priori sia le evidenze empiriche.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Analisi bayesiana dell'odds ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio_stan.html#dati-campionamento-e-oggetti-utili",
    "href": "chapters/mcmc/08_stan_odds_ratio_stan.html#dati-campionamento-e-oggetti-utili",
    "title": "59  Analisi bayesiana dell’odds ratio",
    "section": "\n59.7 4) Dati, campionamento e oggetti utili",
    "text": "59.7 4) Dati, campionamento e oggetti utili\n\nn1 &lt;- 200; y1 &lt;- 130\nn2 &lt;- 200; y2 &lt;- 100\nstan_data &lt;- list(N1 = n1, y1 = y1, N2 = n2, y2 = y2)\n\nfit &lt;- mod$sample(\n  data = stan_data,\n  seed = 123,\n  chains = 4, parallel_chains = 4,\n  iter_warmup = 2000, iter_sampling = 5000,\n  adapt_delta = 0.99,\n  show_messages = FALSE\n)",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Analisi bayesiana dell'odds ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio_stan.html#riassunto-posteriore-e-interpretazione",
    "href": "chapters/mcmc/08_stan_odds_ratio_stan.html#riassunto-posteriore-e-interpretazione",
    "title": "59  Analisi bayesiana dell’odds ratio",
    "section": "\n59.8 5) Riassunto posteriore e interpretazione",
    "text": "59.8 5) Riassunto posteriore e interpretazione\n\n\nIntercept = \\(\\beta_0\\) corrisponde al logit(\\(\\theta\\)) per il gruppo di riferimento (di solito group = g1).\n\n\nb_groupg2 = \\(\\beta_1\\) è la differenza in logit tra il gruppo “g2” e il gruppo “g1”.\n\nIn altre parole, \\(\\theta_{\\text{g2}} = \\mathrm{logit}^{-1}(\\beta_0 + \\beta_1)\\).\n\n\n\n\n59.8.1 5.1 Riassunti numerici\n\n# estrai i draw per parametri chiave\ndraws_or  &lt;- as_draws_df(fit$draws(\"oddsratio\"))\ndraws_log &lt;- as_draws_df(fit$draws(\"log_or\"))\ndraws_th  &lt;- as_draws_df(fit$draws(c(\"theta1\",\"theta2\")))\n\n# riassunti standard (mediana + CrI 90%)\npost_summ &lt;- tibble(\n  quantity = c(\"theta1\", \"theta2\", \"log_or\", \"oddsratio\"),\n  median   = c(median(draws_th$theta1), median(draws_th$theta2),\n               median(draws_log$log_or), median(draws_or$oddsratio)),\n  cri90_l  = c(quantile(draws_th$theta1, .05), quantile(draws_th$theta2, .05),\n               quantile(draws_log$log_or, .05), quantile(draws_or$oddsratio, .05)),\n  cri90_u  = c(quantile(draws_th$theta1, .95), quantile(draws_th$theta2, .95),\n               quantile(draws_log$log_or, .95), quantile(draws_or$oddsratio, .95))\n)\npost_summ\n#&gt; # A tibble: 4 × 4\n#&gt;   quantity  median cri90_l cri90_u\n#&gt;   &lt;chr&gt;      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 theta1     0.648   0.592   0.701\n#&gt; 2 theta2     0.500   0.443   0.556\n#&gt; 3 log_or     0.612   0.281   0.944\n#&gt; 4 oddsratio  1.84    1.32    2.57\n\nProbabilità di effetto in direzione positiva (qui: OR &gt; 1):\n\npr_or_gt1 &lt;- mean(draws_or$oddsratio &gt; 1)\npr_or_gt1\n#&gt; [1] 0.999\n\nLettura didattica.\n\n\n\\(\\theta_1\\) e \\(\\theta_2\\) sono le probabilità (sperimentale vs controllo).\n\n\\(\\text{log-OR}\\) centra l’effetto su scala simmetrica: 0 = nessuna differenza.\n\n\\(\\text{OR}&gt;1\\) indica odds maggiori nel gruppo sperimentale.\nL’intervallo di credibilità al 90% (CrI 90%) per OR quantifica l’incertezza.\n\n\\(\\Pr(\\text{OR}&gt;1)\\) esprime quanto è plausibile, a posteriori, un effetto in quella direzione.\n\n\nInterpretazione-tipo: la mediana di OR è circa 1.8–1.9; il CrI 90% non include 1; \\(\\Pr(\\text{OR}&gt;1)\\) ≈ 1. Questo sostiene l’ipotesi che, nel campione e dato il modello, le api addestrate scelgano il disco blu con odds maggiori.\n\n\n59.8.2 5.2 Una figura semplice\n\nbayesplot::mcmc_areas(fit$draws(\"oddsratio\"), prob = 0.9) +\n  ggtitle(\"Distribuzione a posteriori di OR (CrI 90%)\") +\n  xlab(\"OR\")\n\n\n\n\n\n\n\nLa distribuzione posteriore del rapporto degli odds è il modo più semplice e accurato per descrivere la differenza tra i due gruppi. Nel caso presente, notiamo che vi è un’elevata probabilità che la differenza tra i due gruppi sia affidabile e relativamente grande.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Analisi bayesiana dell'odds ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio_stan.html#opzionale-sensibilità-ai-priori-in-1-riga",
    "href": "chapters/mcmc/08_stan_odds_ratio_stan.html#opzionale-sensibilità-ai-priori-in-1-riga",
    "title": "59  Analisi bayesiana dell’odds ratio",
    "section": "\n59.9 6) (Opzionale) Sensibilità ai priori in 1 riga",
    "text": "59.9 6) (Opzionale) Sensibilità ai priori in 1 riga\nPer valutare la robustezza delle conclusioni, si possono provare priors alternative (es. Beta(1,1) non informativa; Beta(0.5,0.5) più dispersiva; Beta(5,5) più concentrata). Basta cambiare le iper–per prior nel blocco model e ricampionare. Le stime di OR dovrebbero cambiare poco con dati relativamente informativi come questi.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Analisi bayesiana dell'odds ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio_stan.html#diagnostica",
    "href": "chapters/mcmc/08_stan_odds_ratio_stan.html#diagnostica",
    "title": "59  Analisi bayesiana dell’odds ratio",
    "section": "\n59.10 7) Diagnostica",
    "text": "59.10 7) Diagnostica\nQuesti controlli sono spiegati altrove; qui ci limitiamo a una checklist minima:\n\n# Numeriche essenziali su parametri chiave\nposterior::summarize_draws(\n  fit$draws(c(\"theta1\",\"theta2\",\"log_or\",\"oddsratio\")),\n  \"rhat\", \"ess_bulk\", \"ess_tail\"\n)\n#&gt; # A tibble: 4 × 4\n#&gt;   variable   rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 theta1     1.00 10382.00  9966.36\n#&gt; 2 theta2     1.00 10900.80  9428.63\n#&gt; 3 log_or     1.00 10384.61  9646.95\n#&gt; 4 oddsratio  1.00 10384.61  9646.95\n\nUna rapida ispezione visiva può completare il quadro:\n\nbayesplot::mcmc_trace(fit$draws(\"oddsratio\")) + ggtitle(\"Trace di OR\")\n\n\n\n\n\n\n\n\nSe compaiono problemi (Rhat &gt; 1.01, ESS basso, divergenze), aumentare adapt_delta, controllare i priori (troppo stretti) o riparametrizzare.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Analisi bayesiana dell'odds ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio_stan.html#riflessioni-conclusive",
    "href": "chapters/mcmc/08_stan_odds_ratio_stan.html#riflessioni-conclusive",
    "title": "59  Analisi bayesiana dell’odds ratio",
    "section": "Riflessioni conclusive",
    "text": "Riflessioni conclusive\nIn questo capitolo, abbiamo esplorato come applicare un approccio bayesiano per analizzare e interpretare l’odds ratio tra due proporzioni. Attraverso l’uso del modello statistico, siamo stati in grado di stimare la distribuzione a posteriori dell’odds ratio e di calcolare l’intervallo di credibilità.\nI risultati ottenuti, supportati da un controllo diagnostico delle catene Markoviane, indicano che la differenza osservata tra i due gruppi è credibile e supportata dai dati. L’odds ratio stimato e il relativo intervallo di credibilità escludono il valore 1, suggerendo una differenza coerente tra i gruppi analizzati. L’approccio bayesiano si è dimostrato efficace, non solo per stimare i parametri di interesse, ma anche per quantificare l’incertezza associata a tali stime.\nIn sintesi, l’analisi bayesiana dell’odds ratio ha permesso di rispondere alla domanda di ricerca, confermando che le api mostrano comportamenti coerenti con una capacità di distinzione cromatica. L’approccio presentato in questo capitolo può essere esteso ad altre applicazioni, offrendo una struttura versatile per il confronto tra proporzioni in diversi contesti sperimentali.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Analisi bayesiana dell'odds ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio_stan.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/08_stan_odds_ratio_stan.html#informazioni-sullambiente-di-sviluppo",
    "title": "59  Analisi bayesiana dell’odds ratio",
    "section": "Informazioni sull’ambiente di sviluppo",
    "text": "Informazioni sull’ambiente di sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] cmdstanr_0.9.0        pillar_1.11.0         tinytable_0.11.0     \n#&gt;  [4] patchwork_1.3.1       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt;  [7] bayesplot_1.13.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [10] priorsense_1.1.0      posterior_1.6.1       loo_2.8.0            \n#&gt; [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [16] Rcpp_1.1.0            conflicted_1.2.0      janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gridExtra_2.3        inline_0.3.21        sandwich_3.1-1      \n#&gt;  [4] rlang_1.1.6          magrittr_2.0.3       multcomp_1.4-28     \n#&gt;  [7] snakecase_0.11.1     ggridges_0.5.6       compiler_4.5.1      \n#&gt; [10] vctrs_0.6.5          reshape2_1.4.4       stringr_1.5.1       \n#&gt; [13] pkgconfig_2.0.3      arrayhelpers_1.1-0   fastmap_1.2.0       \n#&gt; [16] backports_1.5.0      labeling_0.4.3       utf8_1.2.6          \n#&gt; [19] rmarkdown_2.29       ps_1.9.1             purrr_1.1.0         \n#&gt; [22] xfun_0.52            cachem_1.1.0         jsonlite_2.0.0      \n#&gt; [25] broom_1.0.9          parallel_4.5.1       R6_2.6.1            \n#&gt; [28] stringi_1.8.7        RColorBrewer_1.1-3   lubridate_1.9.4     \n#&gt; [31] estimability_1.5.1   knitr_1.50           zoo_1.8-14          \n#&gt; [34] pacman_0.5.1         Matrix_1.7-3         splines_4.5.1       \n#&gt; [37] timechange_0.3.0     tidyselect_1.2.1     abind_1.4-8         \n#&gt; [40] yaml_2.3.10          codetools_0.2-20     curl_6.4.0          \n#&gt; [43] processx_3.8.6       pkgbuild_1.4.8       lattice_0.22-7      \n#&gt; [46] plyr_1.8.9           withr_3.0.2          bridgesampling_1.1-2\n#&gt; [49] coda_0.19-4.1        evaluate_1.0.4       survival_3.8-3      \n#&gt; [52] RcppParallel_5.1.10  tensorA_0.36.2.1     checkmate_2.3.2     \n#&gt; [55] stats4_4.5.1         distributional_0.5.0 generics_0.1.4      \n#&gt; [58] rprojroot_2.1.0      rstantools_2.4.0     scales_1.4.0        \n#&gt; [61] xtable_1.8-4         glue_1.8.0           emmeans_1.11.2      \n#&gt; [64] tools_4.5.1          data.table_1.17.8    mvtnorm_1.3-3       \n#&gt; [67] grid_4.5.1           QuickJSR_1.8.0       colorspace_2.1-1    \n#&gt; [70] nlme_3.1-168         cli_3.6.5            svUnit_1.0.6        \n#&gt; [73] Brobdingnag_1.2-9    V8_6.0.5             gtable_0.3.6        \n#&gt; [76] digest_0.6.37        TH.data_1.1-3        htmlwidgets_1.6.4   \n#&gt; [79] farver_2.1.2         memoise_2.0.1        htmltools_0.5.8.1   \n#&gt; [82] lifecycle_1.0.4      MASS_7.3-65",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Analisi bayesiana dell'odds ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio_stan.html#bibliografia",
    "href": "chapters/mcmc/08_stan_odds_ratio_stan.html#bibliografia",
    "title": "59  Analisi bayesiana dell’odds ratio",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nHoffmann, T., Hofman, A., & Wagenmakers, E.-J. (2022). Bayesian tests of two proportions: A tutorial with R and JASP. Methodology, 18(4), 239–277.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Analisi bayesiana dell'odds ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio_stan.html#introduzione",
    "href": "chapters/mcmc/08_stan_odds_ratio_stan.html#introduzione",
    "title": "59  Analisi bayesiana dell’odds ratio",
    "section": "",
    "text": "In questo capitolo applicheremo gli strumenti statistici presentati precedentemente all’analisi bayesiana del confronto tra due proporzioni. La trattazione si articolerà in tre fasi fondamentali:\n\nIntroduzione dei concetti teorici di odds, odds ratio e trasformazione logit\nPresentazione del framework bayesiano per il confronto tra proporzioni\nApplicazione pratica degli strumenti analitici",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Analisi bayesiana dell'odds ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio_stan.html#odds-definizione-e-interpretazione",
    "href": "chapters/mcmc/08_stan_odds_ratio_stan.html#odds-definizione-e-interpretazione",
    "title": "59  Analisi bayesiana dell’odds ratio",
    "section": "\n59.1 Odds: definizione e interpretazione",
    "text": "59.1 Odds: definizione e interpretazione\n\n59.1.1 Concetto fondamentale\nNell’analisi statistica, gli odds rappresentano un modo alternativo rispetto alla probabilità per quantificare la verosimiglianza di un evento. La loro definizione formale è data dal rapporto tra la probabilità che l’evento si verifichi (\\(\\pi\\)) e la probabilità che non si verifichi (\\(1-\\pi\\)):\n\\[\n\\text{odds} = \\frac{\\pi}{1-\\pi}.\n\\]\nMentre la probabilità è sempre compresa tra 0 e 1, gli odds possono variare da 0 a infinito. Questa proprietà conferisce agli odds una maggiore ampiezza di scala, rendendoli particolarmente utili per descrivere situazioni in cui un evento è molto raro o quasi certo.\n\n59.1.2 Esempi illustrativi\nIl legame tra odds e probabilità può essere chiarito attraverso alcuni esempi. Se la probabilità di successo è pari a due terzi, gli odds risultano uguali a 2: ciò significa che l’evento è due volte più probabile che si verifichi rispetto a non verificarsi. Se invece la probabilità è pari a un terzo, gli odds valgono 0.5, e dunque l’evento ha metà della probabilità di verificarsi rispetto al non verificarsi. Infine, nel caso in cui la probabilità sia esattamente pari a un mezzo, gli odds risultano uguali a 1: l’evento è cioè ugualmente probabile che accada o meno.\n\n59.1.3 Proprietà e utilità degli odds\nGli odds hanno una scala intrinsecamente asimmetrica: valori inferiori a 1 corrispondono a probabilità inferiori al 50%, un valore pari a 1 rappresenta la situazione di equiprobabilità, mentre valori superiori a 1 indicano probabilità maggiori della metà. Questa caratteristica rende gli odds molto sensibili quando ci si avvicina agli estremi della distribuzione, cioè a probabilità molto basse o molto alte. In tali contesti, anche piccole variazioni di probabilità producono grandi differenze negli odds, offrendo quindi una maggiore capacità discriminativa.\nUn’altra proprietà cruciale è la loro trasformabilità. La funzione logit, definita come\n\\[\n\\log \\left( \\frac{\\pi}{1-\\pi} \\right),\n\\]\npermette di trasformare gli odds in una scala simmetrica che copre l’intero asse reale. Questa trasformazione è alla base della regressione logistica e di molte altre applicazioni statistiche, poiché consente di trattare quantità limitate tra 0 e 1 (le probabilità) attraverso un modello lineare illimitato.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Analisi bayesiana dell'odds ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio_stan.html#odds-ratio-concetto-e-applicazioni",
    "href": "chapters/mcmc/08_stan_odds_ratio_stan.html#odds-ratio-concetto-e-applicazioni",
    "title": "59  Analisi bayesiana dell’odds ratio",
    "section": "\n59.2 Odds Ratio: concetto e applicazioni",
    "text": "59.2 Odds Ratio: concetto e applicazioni\n\n59.2.1 Definizione\nL’odds ratio (OR) è una misura statistica che consente di confrontare la probabilità relativa di un evento tra due gruppi. È definito come il rapporto tra gli odds del gruppo 1 e quelli del gruppo 2:\n\\[\nOR = \\frac{\\text{odds}_1}{\\text{odds}_2} = \\frac{p_1/(1-p_1)}{p_2/(1-p_2)},\n\\]\ndove \\(p_1\\) e \\(p_2\\) rappresentano le probabilità dell’evento nei due gruppi considerati.\n\n59.2.2 Interpretazione\nUn valore di OR pari a 1 indica assenza di associazione, cioè l’evento è ugualmente probabile in entrambi i gruppi. Se l’OR è maggiore di 1, l’evento risulta più probabile nel gruppo 1 rispetto al gruppo 2. Viceversa, se l’OR è inferiore a 1, l’evento è meno probabile nel gruppo 1. Maggiore è la distanza dall’unità, più forte è l’associazione: valori estremi, come 10 o 0.1, segnalano legami molto marcati, mentre valori vicini a 1 corrispondono ad associazioni deboli.\n\n59.2.3 Esempio applicativo\nImmaginiamo uno studio clinico volto a verificare l’efficacia di una terapia comportamentale nel trattamento dell’ansia. Nel gruppo trattato, costituito da 100 pazienti, 60 mostrano miglioramenti (\\(p_1 = 0.6\\)). Nel gruppo di controllo, anch’esso di 100 pazienti, i miglioramenti riguardano 40 persone (\\(p_2 = 0.4\\)). Gli odds del gruppo trattato sono pari a \\(0.6/0.4 = 1.5\\), mentre quelli del gruppo di controllo sono \\(0.4/0.6 \\approx 0.67\\). L’odds ratio risulta quindi \\(1.5/0.67 \\approx 2.24\\). L’interpretazione è immediata: i pazienti trattati hanno circa 2.24 volte più probabilità di migliorare rispetto ai controlli.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Analisi bayesiana dell'odds ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio_stan.html#log-odds-ratio-trasformazione-e-vantaggi",
    "href": "chapters/mcmc/08_stan_odds_ratio_stan.html#log-odds-ratio-trasformazione-e-vantaggi",
    "title": "59  Analisi bayesiana dell’odds ratio",
    "section": "\n59.3 Log-Odds Ratio: trasformazione e vantaggi",
    "text": "59.3 Log-Odds Ratio: trasformazione e vantaggi\n\n59.3.1 Motivazione e formula\nSebbene l’odds ratio sia una misura intuitiva, esso ha una natura moltiplicativa che può complicare le analisi statistiche. Per questo motivo, è comune applicare la trasformazione logaritmica, ottenendo il log-odds ratio:\n\\[\n\\log(OR) = \\log\\left(\\frac{\\text{odds}_1}{\\text{odds}_2}\\right).\n\\]\nQuesta trasformazione rende simmetrical la scala, estendendola da meno infinito a più infinito e normalizza le distribuzioni in molti contesti empirici.\n\n59.3.2 Interpretazione\nUn valore di log-odds ratio pari a zero indica assenza di differenza tra i gruppi (equivalente a un OR pari a 1). Valori positivi indicano che l’evento è più probabile nel gruppo 1, mentre valori negativi segnalano il contrario. Riprendendo l’esempio precedente, il log-odds ratio corrisponde a \\(\\log(2.24) \\approx 0.81\\). Questo valore può essere interpretato come un incremento di circa 0.81 unità nei log-odds del risultato associato alla condizione sperimentale.\n\n59.3.3 Confronto con l’OR\nL’odds ratio vive su una scala positiva e va interpretato in termini moltiplicativi (“due volte più probabile”). Il log-odds ratio, invece, vive su una scala simmetrica e permette un’interpretazione additiva (“+0.81 unità nei log-odds”). Questo passaggio dalla moltiplicazione all’addizione è un vantaggio cruciale nei modelli multivariati, dove gli effetti dei predittori vengono combinati in modo lineare.\nIn sintesi, gli odds offrono una misura alternativa alla probabilità, particolarmente utile per descrivere eventi rari o molto frequenti. L’odds ratio rappresenta lo strumento principale per confrontare due gruppi, fornendo una misura relativa dell’associazione. La trasformazione logaritmica del rapporto, ossia il log-odds ratio, consente di superare i limiti della scala moltiplicativa e di integrare facilmente queste quantità nei modelli statistici, come la regressione logistica. In questo modo, concetti apparentemente semplici come odds e odds ratio si rivelano fondamentali non solo per l’interpretazione dei dati, ma anche per la costruzione di modelli predittivi complessi in psicologia, medicina e scienze sociali.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Analisi bayesiana dell'odds ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#introduzione",
    "href": "chapters/mcmc/01_metropolis.html#introduzione",
    "title": "56  L’algoritmo di Metropolis-Hastings",
    "section": "",
    "text": "Nei capitoli precedenti abbiamo esaminato diversi esempi di inferenza bayesiana, concentrandoci su modelli parametrici semplici come il caso unidimensionale del modello bernoulliano. In questi scenari elementari, abbiamo utilizzato due approcci principali: l’approssimazione discreta su griglia, che valuta la distribuzione a posteriori su un insieme finito di valori parametrali, e l’uso di distribuzioni a priori coniugate, che, grazie alla loro forma analiticamente trattabile, permettono di derivare la posterior in modo esatto.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio_stan.html#calcoli-preliminari-proporzioni-e-odds",
    "href": "chapters/mcmc/08_stan_odds_ratio_stan.html#calcoli-preliminari-proporzioni-e-odds",
    "title": "59  Analisi bayesiana dell’odds ratio",
    "section": "\n59.5 Calcoli preliminari: proporzioni e odds",
    "text": "59.5 Calcoli preliminari: proporzioni e odds\nNel gruppo sperimentale la proporzione di api che hanno scelto il disco blu è\n\\[\np_e = \\frac{130}{200} = 0.65,\n\\]\ncorrispondente a odds pari a\n\\[\n\\text{odds}_e = \\frac{0.65}{1-0.65} \\approx 1.86.\n\\]\nQuesto valore indica che, per ogni scelta del disco verde, nel gruppo sperimentale si osservano circa 1.86 scelte del disco blu.\nNel gruppo di controllo la proporzione è invece\n\\[\np_c = \\frac{100}{200} = 0.50,\n\\]\nche corrisponde a odds pari a\n\\[\n\\text{odds}_c = \\frac{0.50}{1-0.50} = 1.00.\n\\]\nIn questo caso, le scelte si distribuiscono equamente tra i due colori.\nIl confronto tra i due gruppi fornisce l’odds ratio:\n\\[\n\\text{OR} = \\frac{\\text{odds}_e}{\\text{odds}_c} = \\frac{1.86}{1.00} = 1.86.\n\\]\nL’interpretazione è chiara: le api addestrate hanno odds di scelta del disco blu circa 1.86 volte maggiori rispetto a quelle non addestrate.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Analisi bayesiana dell'odds ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio_stan.html#modello-e-scelte-di-prior",
    "href": "chapters/mcmc/08_stan_odds_ratio_stan.html#modello-e-scelte-di-prior",
    "title": "59  Analisi bayesiana dell’odds ratio",
    "section": "\n59.7 Modello e scelte di prior",
    "text": "59.7 Modello e scelte di prior\nFormalmente, modelliamo i conteggi di “successi” (scelta del blu) con due binomiali indipendenti:\n\\[\ny_1 \\sim \\text{Binomiale}(N_1,\\theta_1), \\qquad\ny_2 \\sim \\text{Binomiale}(N_2,\\theta_2),\n\\]\ndove \\(\\theta_1\\) e \\(\\theta_2\\) sono le probabilità di successo nei due gruppi. Usiamo prior debolmente informativi \\(\\theta_1,\\theta_2 \\sim \\text{Beta}(2,2)\\), che esprimono una moderata preferenza per valori centrali pur rimanendo sufficientemente diffusi. L’OR si ottiene via\n\\[\n\\log(\\text{OR})=\\operatorname{logit}(\\theta_1)-\\operatorname{logit}(\\theta_2),\n\\qquad \\text{OR}=\\exp\\{\\log(\\text{OR})\\}.\n\\]\nL’inferenza si conduce sulla distribuzione a posteriori di OR: l’ampiezza e la posizione dell’intervallo di credibilità riflettono la forza dell’evidenza nei dati.\n\n59.7.1 Codice Stan\n\n# Codice Stan come stringa: due binomiali con prior Beta(2,2).\nstancode &lt;- \"\ndata {\n  int&lt;lower=0&gt; N1;  int&lt;lower=0&gt; y1;\n  int&lt;lower=0&gt; N2;  int&lt;lower=0&gt; y2;\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; theta1;\n  real&lt;lower=0, upper=1&gt; theta2;\n}\nmodel {\n  // Priors debolmente informativi\n  theta1 ~ beta(2, 2);\n  theta2 ~ beta(2, 2);\n\n  // Likelihood\n  y1 ~ binomial(N1, theta1);\n  y2 ~ binomial(N2, theta2);\n}\ngenerated quantities {\n  // Log-odds ratio e odds ratio derivati dai parametri\n  real log_or     = logit(theta1) - logit(theta2);\n  real oddsratio  = exp(log_or);\n}\n\"\n\n\n59.7.2 Setup in R e compilazione\n\n# Scrive il file .stan su disco (opzionale: cambia percorso/cartella a piacere)\nstan_file &lt;- cmdstanr::write_stan_file(stancode)\n\n# Compila il modello Stan\nmod &lt;- cmdstan_model(stan_file)\nmod$print()  # controllo veloce della compilazione\n#&gt; \n#&gt; data {\n#&gt;   int&lt;lower=0&gt; N1;  int&lt;lower=0&gt; y1;\n#&gt;   int&lt;lower=0&gt; N2;  int&lt;lower=0&gt; y2;\n#&gt; }\n#&gt; parameters {\n#&gt;   real&lt;lower=0, upper=1&gt; theta1;\n#&gt;   real&lt;lower=0, upper=1&gt; theta2;\n#&gt; }\n#&gt; model {\n#&gt;   // Priors debolmente informativi\n#&gt;   theta1 ~ beta(2, 2);\n#&gt;   theta2 ~ beta(2, 2);\n#&gt; \n#&gt;   // Likelihood\n#&gt;   y1 ~ binomial(N1, theta1);\n#&gt;   y2 ~ binomial(N2, theta2);\n#&gt; }\n#&gt; generated quantities {\n#&gt;   // Log-odds ratio e odds ratio derivati dai parametri\n#&gt;   real log_or     = logit(theta1) - logit(theta2);\n#&gt;   real oddsratio  = exp(log_or);\n#&gt; }\n\n\n59.7.3 Dati ed esecuzione del campionamento\n\n# Dati: conteggi per sperimentale (gruppo 1) e controllo (gruppo 2)\nN1 &lt;- 200; y1 &lt;- 130\nN2 &lt;- 200; y2 &lt;- 100\n\nstan_data &lt;- list(N1 = N1, y1 = y1, N2 = N2, y2 = y2)\n\n# Campionamento MCMC: impostazioni robuste e riproducibili\nfit &lt;- mod$sample(\n  data = stan_data,\n  seed = 123,\n  chains = 4, parallel_chains = 4,\n  iter_warmup = 1500, iter_sampling = 4000,\n  adapt_delta = 0.99,\n  show_messages = FALSE\n)\n\nCommento. Le iterazioni sono generose per garantire stime stabili; adapt_delta elevato riduce il rischio di divergenze. Su dataset di questa semplicità, convergenza e mescolamento sono in genere eccellenti.\n\n59.7.4 Riassunti a posteriori e quantità didattiche chiave\n\n# Estrazione dei draw in formato comodo\ndraws_or   &lt;- as_draws_df(fit$draws(\"oddsratio\"))\ndraws_log  &lt;- as_draws_df(fit$draws(\"log_or\"))\ndraws_th   &lt;- as_draws_df(fit$draws(c(\"theta1\",\"theta2\")))\n\n# Riassunti sintetici (mediana e CrI 90%)\npost_summ &lt;- tibble(\n  quantity = c(\"theta1\", \"theta2\", \"log_or\", \"oddsratio\"),\n  median   = c(median(draws_th$theta1),\n               median(draws_th$theta2),\n               median(draws_log$log_or),\n               median(draws_or$oddsratio)),\n  cri90_l  = c(quantile(draws_th$theta1, .05),\n               quantile(draws_th$theta2, .05),\n               quantile(draws_log$log_or, .05),\n               quantile(draws_or$oddsratio, .05)),\n  cri90_u  = c(quantile(draws_th$theta1, .95),\n               quantile(draws_th$theta2, .95),\n               quantile(draws_log$log_or, .95),\n               quantile(draws_or$oddsratio, .95))\n)\npost_summ\n#&gt; # A tibble: 4 × 4\n#&gt;   quantity  median cri90_l cri90_u\n#&gt;   &lt;chr&gt;      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 theta1     0.648   0.591   0.701\n#&gt; 2 theta2     0.500   0.442   0.558\n#&gt; 3 log_or     0.612   0.274   0.950\n#&gt; 4 oddsratio  1.84    1.32    2.59\n\n\n# Probabilità a posteriori che l'effetto sia nella direzione ipotizzata (OR &gt; 1)\npr_or_gt1 &lt;- mean(draws_or$oddsratio &gt; 1)\npr_or_gt1\n#&gt; [1] 0.9987\n\nLettura didattica. \\(\\theta_1\\) e \\(\\theta_2\\) sono le probabilità nei due gruppi; \\(\\log(\\text{OR})\\) è centrato su scala simmetrica (0 equivale a nessuna differenza); \\(\\text{OR}&gt;1\\) indica odds maggiori nel gruppo sperimentale. Il CrI 90% per OR quantifica l’incertezza e \\(\\Pr(\\text{OR}&gt;1)\\) esprime quanto è plausibile, a posteriori, un effetto nella direzione attesa.\n\n59.7.5 Visualizzazione della distribuzione di OR\n\n# Densità posteriore di OR con intervallo di credibilità al 90%\nbayesplot::mcmc_areas(fit$draws(\"oddsratio\"), prob = 0.90) +\n  ggtitle(\"Distribuzione a posteriori di OR (CrI 90%)\") +\n  xlab(\"Odds Ratio (OR)\")\n\n\n\n\n\n\n\nInterpretazione. La massa della distribuzione concentrata sopra 1, con un CrI 90% che non include 1, indica evidenza consistente che l’addestramento aumenti le odds di scelta del disco blu. In termini sostantivi, le api addestrate mostrano una preferenza più marcata per il blu rispetto al controllo.\n\n59.7.6 Diagnostica essenziale\n\n# Indicatori numerici chiave: Rhat ~ 1, ESS adeguati\nposterior::summarize_draws(\n  fit$draws(c(\"theta1\",\"theta2\",\"log_or\",\"oddsratio\")),\n  \"rhat\", \"ess_bulk\", \"ess_tail\"\n)\n#&gt; # A tibble: 4 × 4\n#&gt;   variable   rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 theta1     1.00  8330.80  7214.40\n#&gt; 2 theta2     1.00  8633.91  8242.30\n#&gt; 3 log_or     1.00  8450.80  7778.62\n#&gt; 4 oddsratio  1.00  8450.80  7778.62\n\n\n# Traceplot di controllo su OR\nbayesplot::mcmc_trace(fit$draws(\"oddsratio\")) +\n  ggtitle(\"Traceplot di OR\")\n\n\n\n\n\n\n\nSe emergono problemi (Rhat &gt; 1.01, ESS basso, divergenze riportate in output), conviene aumentare iter_warmup/iter_sampling, alzare adapt_delta o, in ultima istanza, riconsiderare i prior se sono eccessivamente stretti.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Analisi bayesiana dell'odds ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/11_stan_poisson_model_1.html",
    "href": "chapters/mcmc/11_stan_poisson_model_1.html",
    "title": "60  Modello di Poisson (1)",
    "section": "",
    "text": "Introduzione\nPreparazione del Notebook",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Modello di Poisson (1)</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/11_stan_poisson_model_1.html#dal-modello-teorico-al-modello-computazionale",
    "href": "chapters/mcmc/11_stan_poisson_model_1.html#dal-modello-teorico-al-modello-computazionale",
    "title": "60  Modello di Poisson (1)",
    "section": "\n60.1 Dal modello teorico al modello computazionale",
    "text": "60.1 Dal modello teorico al modello computazionale\nSupponiamo di avere osservazioni che rappresentano il numero di volte in cui si verifica un certo evento in un intervallo di tempo: ad esempio, il numero di compulsioni registrate da un paziente in otto momenti diversi della giornata, oppure il numero di telefonate ricevute da un centralino in altrettanti turni orari. I dati a nostra disposizione sono i seguenti:\n\ny &lt;- c(2, 1, 3, 2, 2, 1, 1, 1)\n\nAbbiamo quindi \\(N = 8\\) osservazioni. Vogliamo stimare \\(\\lambda\\), cioè il tasso medio di occorrenza degli eventi. L’ipotesi di partenza è che i dati seguano una distribuzione di Poisson, che è la distribuzione di riferimento per fenomeni di conteggio. La formula della Poisson è:\n\\[\nP(y_i \\mid \\lambda) = \\frac{\\lambda^{y_i} e^{-\\lambda}}{y_i!}, \\quad y_i \\in \\mathbb{N},\\ \\lambda &gt; 0.\n\\]\nQuesta formula ci dice che la probabilità di osservare un certo numero di eventi dipende da un unico parametro, \\(\\lambda\\), che rappresenta proprio il tasso medio.\nPer condurre un’analisi bayesiana abbiamo bisogno anche di specificare una distribuzione a priori su \\(\\lambda\\). In questo caso scegliamo una Gamma, che si combina molto bene con la Poisson perché le due distribuzioni sono coniugate. La densità della Gamma è la seguente:\n\\[\np(\\lambda) = \\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)} \\lambda^{\\alpha - 1} e^{-\\beta \\lambda}, \\quad \\lambda &gt; 0.\n\\]\nI due parametri \\(\\alpha\\) e \\(\\beta\\) regolano rispettivamente la forma e la concentrazione della distribuzione. Nel nostro esempio poniamo \\(\\alpha = 9\\) e \\(\\beta = 2\\). In questo modo, il valore medio della priori è \\(\\alpha / \\beta = 4.5\\), cioè la nostra convinzione iniziale è che il numero medio di eventi sia attorno a 4 o 5, pur lasciando spazio all’incertezza.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Modello di Poisson (1)</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/11_stan_poisson_model_1.html#scrivere-il-modello-in-stan",
    "href": "chapters/mcmc/11_stan_poisson_model_1.html#scrivere-il-modello-in-stan",
    "title": "60  Modello di Poisson (1)",
    "section": "\n60.2 Scrivere il modello in Stan",
    "text": "60.2 Scrivere il modello in Stan\nOra traduciamo queste idee in Stan. Un modello in Stan è diviso in blocchi. Nel blocco data indichiamo i dati osservati e i parametri noti, nel blocco parameters i parametri che vogliamo stimare, e nel blocco model specifichiamo la struttura probabilistica del modello, cioè la priori e la verosimiglianza.\nIl modello Stan è quindi:\ndata {\n  int&lt;lower=0&gt; N;                // numero di osservazioni\n  array[N] int&lt;lower=0&gt; y;       // dati osservati\n  real&lt;lower=0&gt; alpha_prior;     // parametro alpha della Gamma\n  real&lt;lower=0&gt; beta_prior;      // parametro beta della Gamma\n}\nparameters {\n  real&lt;lower=0&gt; lambda;          // parametro di interesse\n}\nmodel {\n  lambda ~ gamma(alpha_prior, beta_prior);   // priori\n  y ~ poisson(lambda);                       // verosimiglianza\n}\ngenerated quantities {\n  real alpha_post = alpha_prior + sum(y);    // parametri posteriori teorici\n  real beta_post  = beta_prior + N;\n}\nIn questo esempio aggiungiamo anche una sezione “generated quantities”, dove calcoliamo i parametri della distribuzione a posteriori teorica. Non è strettamente necessario, ma ci serve per fare il confronto con quanto otterremo dal campionamento MCMC.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Modello di Poisson (1)</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/11_stan_poisson_model_1.html#preparare-i-dati-ed-eseguire-il-modello-in-r",
    "href": "chapters/mcmc/11_stan_poisson_model_1.html#preparare-i-dati-ed-eseguire-il-modello-in-r",
    "title": "60  Modello di Poisson (1)",
    "section": "\n60.3 Preparare i dati ed eseguire il modello in R",
    "text": "60.3 Preparare i dati ed eseguire il modello in R\nDopo aver scritto il file Stan e salvato con estensione .stan, lo possiamo compilare ed eseguire in R con il pacchetto cmdstanr.\n\nstan_file &lt;- here::here(\"stan\", \"gamma_poisson_mcmc.stan\")\nmod &lt;- cmdstan_model(stan_file)\n\nN &lt;- length(y)\nalpha_prior &lt;- 9\nbeta_prior &lt;- 2\n\nstan_data &lt;- list(N = N, y = y, alpha_prior = alpha_prior, beta_prior = beta_prior)\n\nUna volta preparati i dati, lanciamo il campionamento:\n\nfit &lt;- mod$sample(\n  data = stan_data,\n  seed = 123,\n  chains = 4,\n  parallel_chains = 4,\n  iter_sampling = 3000,\n  iter_warmup = 2000,\n  show_messages = FALSE\n)\n\nA questo punto Stan ci restituisce una grande quantità di campioni dalla distribuzione a posteriori del parametro \\(\\lambda\\). Con questi campioni possiamo fare analisi numeriche e grafiche.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Modello di Poisson (1)</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/11_stan_poisson_model_1.html#analizzare-i-risultati",
    "href": "chapters/mcmc/11_stan_poisson_model_1.html#analizzare-i-risultati",
    "title": "60  Modello di Poisson (1)",
    "section": "\n60.4 Analizzare i risultati",
    "text": "60.4 Analizzare i risultati\nPer prima cosa estraiamo i campioni di \\(\\lambda\\):\n\nlambda_samples &lt;- as.vector(fit$draws(\"lambda\"))\n\nIn parallelo, possiamo calcolare i parametri della distribuzione Gamma che rappresenta la soluzione analitica a posteriori. Sono:\n\nalpha_post &lt;- alpha_prior + sum(y)\nbeta_post  &lt;- beta_prior + N\n\nPer visualizzare i risultati, tracciamo un istogramma dei campioni MCMC e vi sovrapponiamo la curva della distribuzione Gamma a posteriori teorica:\n\nlambda_samples_df &lt;- data.frame(lambda_samples = lambda_samples)\n\nggplot(lambda_samples_df, aes(x = lambda_samples)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 50, fill = \"skyblue\", alpha = 0.7) +\n  stat_function(\n    fun = function(x) dgamma(x, shape = alpha_post, rate = beta_post),\n    color = \"red\", linewidth = 1.2\n  ) +\n  labs(\n    title = \"Distribuzione a posteriori di λ\",\n    x = \"λ\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\nIl grafico mostra che i campioni prodotti da Stan si distribuiscono esattamente come la curva teorica della distribuzione Gamma, confermando che il nostro modello è stato specificato correttamente.\nPossiamo anche calcolare un intervallo di credibilità per \\(\\lambda\\). Ad esempio, prendiamo il 94% centrale della distribuzione:\n\nquantile(lambda_samples, probs = c(0.03, 0.97))\n#&gt;    3%   97% \n#&gt; 1.422 3.177\n\nIl risultato è che il valore medio stimato di \\(\\lambda\\) è circa 2.2, e che con un grado di certezza soggettivo del 94% possiamo dire che si trova tra 1.4 e 3.1.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Modello di Poisson (1)</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/11_stan_poisson_model_1.html#riflessioni-conclusive",
    "href": "chapters/mcmc/11_stan_poisson_model_1.html#riflessioni-conclusive",
    "title": "60  Modello di Poisson (1)",
    "section": "\n60.5 Riflessioni conclusive",
    "text": "60.5 Riflessioni conclusive\nIn questo capitolo abbiamo fatto un passo importante: abbiamo visto come tradurre un modello probabilistico relativamente semplice in Stan, come eseguire il campionamento MCMC, e come confrontare i risultati con la soluzione analitica. Questo esempio ci ha permesso di verificare che Stan funziona correttamente, perché in questo caso conoscevamo già la distribuzione a posteriori esatta.\nL’aspetto davvero interessante, però, è che la stessa procedura può essere usata anche quando la soluzione analitica non esiste. Nei capitoli successivi incontreremo modelli più complessi, in cui la coniugatezza non ci aiuta più e non abbiamo formule chiuse per la distribuzione a posteriori. In quei casi, il campionamento MCMC sarà lo strumento indispensabile per fare inferenza bayesiana.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Modello di Poisson (1)</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/11_stan_poisson_model_1.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/11_stan_poisson_model_1.html#informazioni-sullambiente-di-sviluppo",
    "title": "60  Modello di Poisson (1)",
    "section": "Informazioni sull’ambiente di sviluppo",
    "text": "Informazioni sull’ambiente di sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.1 (2025-06-13)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.6\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] cmdstanr_0.9.0        pillar_1.11.0         tinytable_0.11.0     \n#&gt;  [4] patchwork_1.3.1       ggdist_3.3.3          tidybayes_3.0.7      \n#&gt;  [7] bayesplot_1.13.0      ggplot2_3.5.2         reliabilitydiag_0.2.1\n#&gt; [10] priorsense_1.1.0      posterior_1.6.1       loo_2.8.0            \n#&gt; [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          \n#&gt; [16] Rcpp_1.1.0            conflicted_1.2.0      janitor_2.2.1        \n#&gt; [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#&gt; [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#&gt; [25] here_1.0.1           \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] svUnit_1.0.6         tidyselect_1.2.1     farver_2.1.2        \n#&gt;  [4] fastmap_1.2.0        TH.data_1.1-3        tensorA_0.36.2.1    \n#&gt;  [7] pacman_0.5.1         digest_0.6.37        estimability_1.5.1  \n#&gt; [10] timechange_0.3.0     lifecycle_1.0.4      processx_3.8.6      \n#&gt; [13] survival_3.8-3       magrittr_2.0.3       compiler_4.5.1      \n#&gt; [16] rlang_1.1.6          tools_4.5.1          yaml_2.3.10         \n#&gt; [19] data.table_1.17.8    knitr_1.50           labeling_0.4.3      \n#&gt; [22] bridgesampling_1.1-2 htmlwidgets_1.6.4    pkgbuild_1.4.8      \n#&gt; [25] curl_6.4.0           RColorBrewer_1.1-3   abind_1.4-8         \n#&gt; [28] multcomp_1.4-28      withr_3.0.2          purrr_1.1.0         \n#&gt; [31] grid_4.5.1           stats4_4.5.1         xtable_1.8-4        \n#&gt; [34] colorspace_2.1-1     inline_0.3.21        emmeans_1.11.2      \n#&gt; [37] scales_1.4.0         MASS_7.3-65          cli_3.6.5           \n#&gt; [40] mvtnorm_1.3-3        rmarkdown_2.29       generics_0.1.4      \n#&gt; [43] RcppParallel_5.1.10  cachem_1.1.0         stringr_1.5.1       \n#&gt; [46] splines_4.5.1        parallel_4.5.1       vctrs_0.6.5         \n#&gt; [49] V8_6.0.5             Matrix_1.7-3         sandwich_3.1-1      \n#&gt; [52] jsonlite_2.0.0       arrayhelpers_1.1-0   glue_1.8.0          \n#&gt; [55] ps_1.9.1             codetools_0.2-20     distributional_0.5.0\n#&gt; [58] lubridate_1.9.4      stringi_1.8.7        gtable_0.3.6        \n#&gt; [61] QuickJSR_1.8.0       htmltools_0.5.8.1    Brobdingnag_1.2-9   \n#&gt; [64] R6_2.6.1             rprojroot_2.1.0      evaluate_1.0.4      \n#&gt; [67] lattice_0.22-7       backports_1.5.0      memoise_2.0.1       \n#&gt; [70] broom_1.0.9          snakecase_0.11.1     rstantools_2.4.0    \n#&gt; [73] coda_0.19-4.1        gridExtra_2.3        nlme_3.1-168        \n#&gt; [76] checkmate_2.3.2      xfun_0.52            zoo_1.8-14          \n#&gt; [79] pkgconfig_2.0.3",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Modello di Poisson (1)</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/11_stan_poisson_model_1.html#bibliografia",
    "href": "chapters/mcmc/11_stan_poisson_model_1.html#bibliografia",
    "title": "60  Modello di Poisson (1)",
    "section": "Bibliografia",
    "text": "Bibliografia",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Modello di Poisson (1)</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/11_stan_poisson_model_1.html#introduzione",
    "href": "chapters/mcmc/11_stan_poisson_model_1.html#introduzione",
    "title": "60  Modello di Poisson (1)",
    "section": "",
    "text": "In questo capitolo affrontiamo un primo esempio di modellazione con Stan, il linguaggio di programmazione che useremo per costruire modelli statistici e fare inferenza bayesiana. L’idea di base è di riprendere un problema che abbiamo già studiato con metodi analitici e con il metodo su griglia – il modello Gamma–Poisson – e di risolverlo ora attraverso il campionamento MCMC. In questo modo potremo confrontare i risultati e, allo stesso tempo, iniziare a familiarizzare con Stan.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Modello di Poisson (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_gamma_poisson_model.html#introduzione",
    "href": "chapters/bayesian_inference/11_gamma_poisson_model.html#introduzione",
    "title": "52  Modello coniugato Gamma-Poisson",
    "section": "",
    "text": "In psicologia capita spesso di lavorare con variabili di conteggio, cioè variabili che registrano quante volte un certo evento si verifica. Pensiamo, ad esempio, al numero di sintomi riportati da un paziente in una settimana, oppure al numero di parole pronunciate da un bambino durante un’interazione osservata in laboratorio. In altri casi, le variabili di conteggio vengono usate in psicolinguistica per misurare la frequenza con cui certi vocaboli compaiono in un testo.\n\n\n\n\n\nmostrare come stimare il parametro \\(\\lambda\\) in un contesto bayesiano, utilizzando una distribuzione a priori di tipo Gamma, che si combina bene con la Poisson;\nconfrontare due approcci diversi per ottenere la distribuzione a posteriori: da un lato la derivazione analitica, che sfrutta la coniugatezza tra le due distribuzioni, dall’altro una procedura di simulazione Monte Carlo, che ci permette di approssimare la distribuzione anche quando non disponiamo di formule esatte.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_gamma_poisson_model.html#la-coppia-coniugata-gammapoisson",
    "href": "chapters/bayesian_inference/11_gamma_poisson_model.html#la-coppia-coniugata-gammapoisson",
    "title": "52  Modello coniugato Gamma-Poisson",
    "section": "\n52.3 La coppia coniugata Gamma–Poisson",
    "text": "52.3 La coppia coniugata Gamma–Poisson\nAbbiamo visto separatamente due elementi: la distribuzione di Poisson, che descrive il numero di eventi osservati, e la distribuzione Gamma, che scegliamo come distribuzione a priori per il parametro di tasso \\(\\lambda\\). Ora possiamo metterli insieme per costruire un modello bayesiano completo.\nIl cuore del ragionamento è questo:\n\ni dati osservati (\\(y_1, y_2, \\dots, y_N\\)) sono modellati come Poisson con parametro \\(\\lambda\\);\nla nostra conoscenza a priori su \\(\\lambda\\) è rappresentata da una distribuzione Gamma con parametri \\(\\alpha_{\\text{prior}}\\) e \\(\\beta_{\\text{prior}}\\).\n\nQuesta combinazione è molto conveniente perché la Gamma è coniugata alla Poisson. Ma che cosa significa, concretamente, “coniugata”? Significa che, dopo aver osservato i dati, la distribuzione a posteriori di \\(\\lambda\\) rimane della stessa famiglia della priori, cioè una distribuzione Gamma. In altre parole, se parto con una Gamma e la aggiorno con dati di tipo Poisson, ottengo ancora una Gamma: cambia soltanto il valore dei parametri, che incorporano l’informazione proveniente dai dati.\n\n52.3.1 La distribuzione a posteriori\nLa regola di Bayes ci dice che:\n\\[\np(\\lambda \\mid y) \\propto p(\\lambda) \\cdot p(y \\mid \\lambda).\n\\]\nSostituendo le due distribuzioni (Gamma per la priori e Poisson per la verosimiglianza), si vede facilmente che la forma risultante è ancora quella di una Gamma. I parametri aggiornati sono:\n\\[\n\\alpha_{\\text{post}} = \\alpha_{\\text{prior}} + \\sum_{i=1}^N y_i\n\\]\n\\[\n\\beta_{\\text{post}} = \\beta_{\\text{prior}} + N\n\\]\nDunque, la nostra credenza su \\(\\lambda\\) dopo aver osservato i dati è rappresentata da una distribuzione:\n\\[\n\\lambda \\mid y \\sim \\text{Gamma}(\\alpha_{\\text{post}}, \\beta_{\\text{post}})\n\\]\n\n52.3.2 Intuizione\nChe cosa sta succedendo qui? L’aggiornamento dei parametri ha un’interpretazione molto intuitiva:\n\n\n\\(\\alpha\\) aumenta con la somma degli eventi osservati: più eventi contiamo, più la distribuzione a posteriori si sposta verso valori alti di \\(\\lambda\\).\n\n\\(\\beta\\) aumenta con il numero di osservazioni \\(N\\): più intervalli di tempo osserviamo, più aumenta la precisione con cui stimiamo il tasso medio.\n\nIn altre parole, i parametri della posteriori rappresentano una sintesi tra la nostra conoscenza a priori e i dati raccolti.\n\n52.3.3 Un esempio numerico\nRiprendiamo l’esempio visto prima, con i dati:\n\ny &lt;- c(2, 1, 3, 2, 2, 1, 1, 1)\n\nAbbiamo \\(N = 8\\) osservazioni, e come priori scegliamo \\(\\alpha_{\\text{prior}} = 9\\) e \\(\\beta_{\\text{prior}} = 2\\).\nCalcoliamo i nuovi parametri:\n\nalpha_post &lt;- 9 + sum(y)\nbeta_post  &lt;- 2 + length(y)\n\nalpha_post; beta_post\n#&gt; [1] 22\n#&gt; [1] 10\n\nIl risultato è \\(\\alpha_{\\text{post}} = 22\\) e \\(\\beta_{\\text{post}} = 10\\). La nostra distribuzione a posteriori è quindi una Gamma(22, 10), che rappresenta la nuova convinzione su \\(\\lambda\\) dopo aver visto i dati.\n\n52.3.4 Visualizzare la posteriori\nPossiamo visualizzare il cambiamento confrontando la priori e la posteriori:\n\nx &lt;- seq(0, 6, length.out = 500)\n\nprior_density &lt;- dgamma(x, shape = 9, rate = 2)\npost_density  &lt;- dgamma(x, shape = alpha_post, rate = beta_post)\n\ndf &lt;- data.frame(\n  x = rep(x, 2),\n  densita = c(prior_density, post_density),\n  Distribuzione = rep(c(\"Prior\", \"Posterior\"), each = length(x))\n)\n\nggplot(df, aes(x = x, y = densita, color = Distribuzione)) +\n  geom_line(size = 1) +\n  labs(\n    title = \"Aggiornamento da Prior a Posterior (Gamma–Poisson)\",\n    x = expression(lambda),\n    y = \"Densità\"\n  ) +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nIl grafico mostra chiaramente che la posteriori è più concentrata: osservare gli otto dati ci ha reso più sicuri sul valore di \\(\\lambda\\). Inoltre, il centro della distribuzione si è spostato verso il valore suggerito dai dati, integrando così le informazioni empiriche con le credenze iniziali.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_balance_prior_post.html#trasformazioni-e-scala-dei-parametri",
    "href": "chapters/bayesian_inference/10_balance_prior_post.html#trasformazioni-e-scala-dei-parametri",
    "title": "51  L’influenza della distribuzione a priori",
    "section": "\n51.4 Trasformazioni e scala dei parametri",
    "text": "51.4 Trasformazioni e scala dei parametri\nUn punto spesso trascurato riguarda il fatto che le prior non sono “neutre” rispetto al cambiamento di scala. Ad esempio, se in uno studio sulla soddisfazione lavorativa esprimiamo un punteggio medio in una scala da 1 a 10, una prior uniforme su quella scala appare “piatta” e non informativa. Ma se trasformiamo la scala in percentuale (0–100), la stessa prior non rimane più uniforme. Questo mostra che una prior non può essere “piatta” per tutte le possibili rappresentazioni del parametro: occorre sempre riflettere su quale scala sia più significativa per il problema psicologico studiato.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_balance_prior_post.html#priori-coniugate-e-metodi-moderni",
    "href": "chapters/bayesian_inference/10_balance_prior_post.html#priori-coniugate-e-metodi-moderni",
    "title": "51  L’influenza della distribuzione a priori",
    "section": "\n51.5 Priori coniugate e metodi moderni",
    "text": "51.5 Priori coniugate e metodi moderni\nStoricamente, i ricercatori preferivano usare priori coniugate, che semplificano i calcoli perché producono posteriori della stessa famiglia di distribuzioni. Ad esempio, la distribuzione Beta è coniugata alla Binomiale: se osserviamo il numero di successi in un test di memoria, una prior Beta consente di calcolare facilmente la posteriori. Oggi, grazie ai metodi di campionamento (ad esempio MCMC), non è più necessario limitarsi alle priors coniugate. Possiamo scegliere priors più flessibili, anche non coniugate, che meglio riflettono le conoscenze psicologiche disponibili.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_balance_prior_post.html#il-caso-coniugato-beta-binomiale",
    "href": "chapters/bayesian_inference/10_balance_prior_post.html#il-caso-coniugato-beta-binomiale",
    "title": "51  L’influenza della distribuzione a priori",
    "section": "\n51.7 Il caso coniugato: Beta-Binomiale",
    "text": "51.7 Il caso coniugato: Beta-Binomiale\nUn esempio classico in cui i calcoli diventano semplici è il modello Beta-Binomiale. La distribuzione Beta è coniugata alla Binomiale: ciò significa che la forma della posteriori rimane una Beta.\n\nplot_beta_binomial &lt;- function(alpha, beta, y, n) {\n  theta &lt;- seq(0, 1, length.out = 100)\n  prior_density &lt;- dbeta(theta, alpha, beta)\n  likelihood &lt;- dbinom(y, n, theta)\n  scaled_likelihood &lt;- likelihood / max(likelihood)\n  posterior_density &lt;- dbeta(theta, alpha + y, beta + n - y)\n  \n  data &lt;- tibble(\n    theta = theta,\n    Prior = prior_density,\n    Likelihood = scaled_likelihood,\n    Posterior = posterior_density\n  ) |&gt; \n    pivot_longer(cols = c(Prior, Likelihood, Posterior), \n                 names_to = \"distribution\", \n                 values_to = \"density\")\n  \n  ggplot(data, aes(x = theta, y = density, color = distribution)) +\n    geom_line(size = 1.2) +\n    labs(title = \"Modello Beta-Binomiale\",\n         x = expression(theta), y = \"Densità\") +\n    theme(plot.title = element_text(hjust = 0.5))\n}\n\n# Priore uniforme\nplot_beta_binomial(alpha = 1, beta = 1, y = 6, n = 9)\n\n\n\n\n\n\n\n# Priore informativo\nplot_beta_binomial(alpha = 2, beta = 2, y = 6, n = 9)\n\n\n\n\n\n\n\n# Priore fortemente informativo\nplot_beta_binomial(alpha = 2, beta = 5, y = 6, n = 9)\n\n\n\n\n\n\n\nCon un priore uniforme, i dati (6 su 9) guidano quasi interamente la stima. Con un priore più informativo, la posteriori si sposta nella direzione suggerita dalle credenze pregresse.\nIn sintesi, le simulazioni mostrano due punti chiave:\n\n\nIl peso della prior dipende dalla quantità di dati. Con pochi dati (come i 9 tentativi del nostro studente), la prior può influenzare molto la stima. Con tanti dati, la verosimiglianza tende a prevalere.\n\nLe scelte di prior hanno senso solo se motivate. In psicologia, una prior può derivare da ricerche precedenti (es. meta-analisi), da conoscenze teoriche (es. aspettarci che un trattamento riduca e non aumenti i sintomi) o da ipotesi ragionevoli.\n\nL’approccio bayesiano ci permette quindi di integrare flessibilmente dati e conoscenze pregresse, arrivando a inferenze che sono al tempo stesso empiricamente fondate e teoricamente sensate.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_uncertainty.html#introduzione",
    "href": "chapters/bayesian_inference/01_uncertainty.html#introduzione",
    "title": "43  Abbracciare l’incertezza",
    "section": "",
    "text": "L’espressione “abbracciare l’incertezza” è una delle più rappresentative nel contesto della statistica bayesiana. In questo capitolo, esploreremo il significato di questa affermazione, basandoci sulla trattazione introduttiva proposta nel primo capitolo di Understanding Uncertainty di Lindley (Lindley, 2013).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_intro_bayes.html#interpretazioni-della-probabilità",
    "href": "chapters/bayesian_inference/02_intro_bayes.html#interpretazioni-della-probabilità",
    "title": "44  La quantificazione dell’incertezza",
    "section": "\n44.1 Interpretazioni della probabilità",
    "text": "44.1 Interpretazioni della probabilità\nCome discusso nei capitoli introduttivi, la probabilità può essere intesa in modi diversi. Nell’approccio frequentista essa descrive l’incertezza come una proprietà del mondo, legata alla variabilità aleatoria dei fenomeni (incertezza aleatoria). Nell’approccio bayesiano, invece, la probabilità quantifica il nostro grado di conoscenza e di fiducia in un’ipotesi (incertezza epistemica).\n\n44.1.1 Interpretazione frequentista\nNel frequentismo, la probabilità è definita come frequenza relativa di un evento in un numero indefinito di prove ripetute nelle stesse condizioni:\n\\[\n\\Pr(E) = \\lim_{N \\to \\infty} \\frac{\\text{numero di volte in cui } E \\text{ si verifica}}{N}.\n\\]\nQuesta concezione presenta due difficoltà principali:\n\n\nRipetizioni infinite: un requisito teorico impossibile da realizzare in molti contesti, specialmente in psicologia.\n\nClasse di riferimento: non è sempre chiaro quale popolazione considerare per definire l’evento.\n\nPer esempio, come stabilire la popolazione di riferimento per parlare della probabilità che un individuo specifico superi una soglia clinica di ansia?\n\n44.1.2 Interpretazione bayesiana\nPer il bayesianesimo, la probabilità misura un grado di credenza razionale. Essa rappresenta quanto riteniamo plausibile un’ipotesi o un parametro, combinando:\n\n\nconoscenze pregresse (la distribuzione a priori),\n\nnuove osservazioni (i dati).\n\nIl teorema di Bayes formalizza questo processo di aggiornamento:\n\\[\np(\\theta \\mid D) = \\frac{p(D \\mid \\theta)\\, p(\\theta)}{p(D)},\n\\]\ndove:\n\n\n\\(p(\\theta \\mid D)\\) è la probabilità a posteriori del parametro \\(\\theta\\), aggiornata con i dati \\(D\\),\n\n\\(p(\\theta)\\) è la probabilità a priori assegnata a \\(\\theta\\),\n\n\\(p(D \\mid \\theta)\\) è la verosimiglianza, cioè la probabilità dei dati dato \\(\\theta\\),\n\n\\(p(D)\\) è la probabilità totale dei dati, necessaria per normalizzare la distribuzione.\n\nL’approccio bayesiano esprime l’incertezza con distribuzioni di probabilità: non una singola stima puntuale, ma un ventaglio di valori plausibili e il grado di fiducia associato a ciascuno.\nIn sintesi, il frequentismo interpreta la probabilità come una proprietà oggettiva dei fenomeni ripetibili, mentre il bayesianesimo la intende come misura della nostra conoscenza. Questa seconda prospettiva è particolarmente adatta alle scienze psicologiche, dove i dati sono spesso limitati e i processi sottostanti complessi e latenti. Integrando dati empirici con informazioni pregresse, l’inferenza bayesiana non solo migliora la capacità predittiva, ma fornisce anche un quadro concettuale chiaro e rigoroso per affrontare l’incertezza.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_intro_bayes.html#laggiornamento-bayesiano-esempio-intuitivo",
    "href": "chapters/bayesian_inference/02_intro_bayes.html#laggiornamento-bayesiano-esempio-intuitivo",
    "title": "44  La quantificazione dell’incertezza",
    "section": "\n44.3 L’aggiornamento bayesiano: esempio intuitivo",
    "text": "44.3 L’aggiornamento bayesiano: esempio intuitivo\nIl punto di forza della modellazione bayesiana risiede nella sua capacità di aggiornare continuamente le credenze sui parametri del modello man mano che si raccolgono nuovi dati. Questo processo iterativo, basato sul teorema di Bayes, consente di integrare sia le credenze iniziali (a priori) sia le evidenze empiriche (verosimiglianza) per ottenere stime sempre più precise.\nUn esempio intuitivo per spiegare l’aggiornamento bayesiano è quello proposto da McElreath (2020). Supponiamo di voler stimare la proporzione della superficie terrestre coperta d’acqua. L’esperimento consiste nel lanciare un globo terrestre in aria, afferrarlo e osservare se la superficie sotto il dito è acqua o terra. Dopo ogni osservazione, possiamo aggiornare le nostre credenze sulla proporzione d’acqua (p).\nIniziamo con una distribuzione a priori che assegna la stessa probabilità a tutti i valori possibili di \\(p\\) (proporzione d’acqua). Dopo il primo lancio, in cui osserviamo acqua (“W”), la probabilità che \\(p\\) sia zero diminuisce, mentre quella che \\(p\\) sia maggiore aumenta. Man mano che raccogliamo più dati, la distribuzione si aggiorna, riducendo l’incertezza e convergendo verso una stima più precisa di \\(p\\).\nCon l’aumento dei dati osservati, la distribuzione a posteriori si concentra sempre di più attorno ai valori di \\(p\\) che meglio spiegano i dati. Questo processo rappresenta il continuo affinamento delle stime bayesiane, che diventano più accurate man mano che le evidenze si accumulano.\nIn sintesi, l’aggiornamento bayesiano fornisce un quadro flessibile e sistematico per trattare l’incertezza e integrare nuove informazioni. È particolarmente utile nelle scienze psicologiche e sociali, dove la complessità e la variabilità dei fenomeni rendono difficile ottenere stime precise. Questo approccio consente di migliorare costantemente la comprensione dei fenomeni, adattando le credenze man mano che emergono nuovi dati.\n\n\n\n\n\n\n\n\nIl grafico precedente illustra un processo di aggiornamento bayesiano, in cui vengono progressivamente aggiornate le credenze sulla proporzione di superficie coperta d’acqua (\\(p\\)) del globo terrestre, man mano che vengono raccolti nuovi dati. Dopo ogni lancio, le probabilità sui possibili valori di \\(p\\) vengono aggiornate sulla base delle osservazioni, utilizzando il teorema di Bayes. Il processo è visualizzato attraverso una serie di grafici, organizzati in una griglia 3x3, con ogni pannello che rappresenta un’osservazione aggiuntiva.\nNota sui grafici.\n\n\nLinea Blu: La distribuzione a posteriori calcolata per il pannello corrente.\n\nLinea Grigia: La distribuzione a priori utilizzata, che è il posterior del pannello precedente.\n\nAggiornamento Bayesiano: Ogni volta che vengono osservati nuovi dati, la distribuzione a posteriori diventa il a priori per il passo successivo, consentendo di incorporare progressivamente l’informazione osservata.\n\n\n\n\n\n\n\nApprofondimento\n\n\n\n\n\nA una prima lettura, è sufficiente focalizzarsi sul significato dell’aggiornamento bayesiano e sulle conseguenze che questo produce rispetto alle nostre credenze su \\(p\\), man mano che vengono osservati nuovi dati. Per il momento, il meccanismo dettagliato attraverso cui l’aggiornamento bayesiano viene realizzato non è ancora stato esplicitato, e quindi gli studenti possono inizialmente tralasciare la spiegazione approfondita contenuta in questo riquadro.\nDopo aver letto il contenuto di Capitolo 48, sarà possibile tornare sull’esempio discusso qui e comprenderne appieno l’aggiornamento bayesiano, interpretandolo alla luce delle proprietà delle famiglie coniugate. Questo consentirà di cogliere non solo il significato generale dell’aggiornamento, ma anche i dettagli tecnici che lo rendono particolarmente efficiente in contesti come quello descritto.\nPrimo Pannello.\n\n\nOsservazione iniziale: Abbiamo il primo dato, un successo (“W”).\n\nA priori: La distribuzione a priori iniziale è una distribuzione Beta(1, 1). Questa rappresenta una conoscenza iniziale non informativa, ovvero l’ipotesi che qualsiasi proporzione di successi (\\(p\\)) sia ugualmente probabile.\n\nA posteriori: Con un successo su una prova: \\[\n\\text{Posterior} \\sim \\mathcal{Beta}(1 + 1, 1 + 0) = \\mathcal{Beta}(2, 1).\n\\] La distribuzione risultante è concentrata verso i valori più alti di \\(p\\), riflettendo il successo osservato.\n\nSecondo Pannello.\n\n\nOsservazioni: Ora abbiamo due dati, “W” e “L”, quindi un successo su due prove.\n\nA priori: La distribuzione a priori per questo passo è il posterior del pannello precedente, ovvero \\(\\mathcal{Beta}(2, 1)\\).\n\nA posteriori: Con un successo (\\(W = 1\\)) e un insuccesso (\\(L = 1\\)): \\[\n\\text{Posterior} \\sim \\mathcal{Beta}(2 + 1, 1 + 1) = \\mathcal{Beta}(3, 2).\n\\] La nuova distribuzione riflette un aggiornamento che tiene conto sia del successo che dell’insuccesso.\n\nTerzo Pannello.\n\n\nOsservazioni: Ora abbiamo tre dati, “W”, “L”, “W”, quindi due successi su tre prove.\n\nA priori: La distribuzione a priori è il posterior del pannello precedente, \\(\\mathcal{Beta}(3, 2)\\).\n\nA posteriori: Con due successi (\\(W = 2\\)) e un insuccesso (\\(L = 1\\)): \\[\n\\text{Posterior} \\sim \\mathcal{Beta}(3 + 1, 2 + 0) = \\mathcal{Beta}(4, 2).\n\\]\n\n\nQuarto Pannello.\n\n\nOsservazioni: Ora abbiamo quattro dati, “W”, “L”, “W”, “W”, quindi tre successi su quattro prove.\n\nA priori: La distribuzione a priori è il posterior del pannello precedente, \\(\\mathcal{Beta}(4, 2)\\).\n\nA posteriori: Con tre successi (\\(W = 3\\)) e un insuccesso (\\(L = 1\\)): \\[\n\\text{Posterior} \\sim \\mathcal{Beta}(4 + 1, 2 + 0) = \\mathcal{Beta}(5, 2).\n\\]\n\n\nQuinto Pannello.\n\n\nOsservazioni: Ora abbiamo cinque dati, “W”, “L”, “W”, “W”, “L”, quindi tre successi su cinque prove.\n\nA priori: La distribuzione a priori è il posterior del pannello precedente, \\(\\mathcal{Beta}(5, 2)\\).\n\nA posteriori: Con tre successi (\\(W = 3\\)) e due insuccessi (\\(L = 2\\)): \\[\n\\text{Posterior} \\sim \\mathcal{Beta}(5 + 0, 2 + 1) = \\mathcal{Beta}(5, 3).\n\\]\n\n\nSesto Pannello.\n\n\nOsservazioni: Ora abbiamo sei dati, “W”, “L”, “W”, “W”, “L”, “W”, quindi quattro successi su sei prove.\n\nA priori: La distribuzione a priori è il posterior del pannello precedente, \\(\\mathcal{Beta}(5, 3)\\).\n\nA posteriori: Con quattro successi (\\(W = 4\\)) e due insuccessi (\\(L = 2\\)): \\[\n\\text{Posterior} \\sim \\mathcal{Beta}(5 + 1, 3 + 0) = \\mathcal{Beta}(6, 3).\n\\]\n\n\nSettimo Pannello.\n\n\nOsservazioni: Ora abbiamo sette dati, “W”, “L”, “W”, “W”, “L”, “W”, “L”, quindi quattro successi su sette prove.\n\nA priori: La distribuzione a priori è il posterior del pannello precedente, \\(\\mathcal{Beta}(6, 3)\\).\n\nA posteriori: Con quattro successi (\\(W = 4\\)) e tre insuccessi (\\(L = 3\\)): \\[\n\\text{Posterior} \\sim \\mathcal{Beta}(6 + 0, 3 + 1) = \\mathcal{Beta}(6, 4).\n\\]\n\n\nOttavo Pannello.\n\n\nOsservazioni: Ora abbiamo otto dati, “W”, “L”, “W”, “W”, “L”, “W”, “L”, “W”, quindi cinque successi su otto prove.\n\nA priori: La distribuzione a priori è il posterior del pannello precedente, \\(\\mathcal{Beta}(6, 4)\\).\n\nA posteriori: Con cinque successi (\\(W = 5\\)) e tre insuccessi (\\(L = 3\\)): \\[\n\\text{Posterior} \\sim \\mathcal{Beta}(6 + 1, 4 + 0) = \\mathcal{Beta}(7, 4).\n\\]\n\n\nNono Pannello.\n\n\nOsservazioni: Ora abbiamo nove dati, “W”, “L”, “W”, “W”, “L”, “W”, “L”, “W”, “W”, quindi sei successi su nove prove.\n\nA priori: La distribuzione a priori è il posterior del pannello precedente, \\(\\mathcal{Beta}(7, 4)\\).\n\nA posteriori: Con sei successi (\\(W = 6\\)) e tre insuccessi (\\(L = 3\\)): \\[\n\\text{Posterior} \\sim \\mathcal{Beta}(7 + 1, 4 + 0) = \\mathcal{Beta}(8, 4).\n\\]\n\n\n\n\n\nQuesto processo mostra come il modello bayesiano aggiorna continuamente le credenze man mano che i dati vengono osservati. Ogni nuovo pannello segue lo stesso schema: la distribuzione a priori (linea tratteggiata) viene aggiornata con la nuova osservazione (linea continua). Se viene osservata acqua (W), il picco della distribuzione si sposta a destra; se viene osservata terra (L), il picco si sposta a sinistra. In ogni caso, la curva diventa progressivamente più “appuntita”, indicando che l’incertezza sulla vera proporzione di acqua diminuisce con l’aumentare del numero di osservazioni.\nL’aspetto fondamentale dell’approccio bayesiano è che ogni distribuzione a posteriori aggiornata (linea continua) diventa la nuova distribuzione a priori per la successiva osservazione. Questo processo iterativo permette di apprendere progressivamente dai dati, integrando ogni nuova informazione per affinare la stima di \\(p\\). Alla fine, la distribuzione diventa sempre più concentrata intorno al valore più probabile di \\(p\\), man mano che raccogliamo più dati.\nIn conclusione, l’esempio illustra come l’aggiornamento bayesiano modifichi le nostre credenze sulla proporzione d’acqua (\\(p\\)) sulla superficie del globo, basandosi sulle osservazioni raccolte. Ogni curva rappresenta la sintesi delle conoscenze attuali, combinando le osservazioni precedenti con l’ultima evidenza raccolta. Il grafico dimostra visivamente come l’approccio bayesiano consenta di trattare l’incertezza e aggiornare le stime in modo coerente e progressivo.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_intro_bayes.html#lincertezza-come-distribuzione-di-probabilità",
    "href": "chapters/bayesian_inference/02_intro_bayes.html#lincertezza-come-distribuzione-di-probabilità",
    "title": "44  La quantificazione dell’incertezza",
    "section": "\n44.1 L’incertezza come distribuzione di probabilità",
    "text": "44.1 L’incertezza come distribuzione di probabilità\nPrima di addentrarci nei meccanismi dell’aggiornamento bayesiano, è fondamentale comprendere come l’approccio bayesiano concettualizza l’incertezza. A differenza del pensiero quotidiano, che spesso tratta l’incertezza come una semplice mancanza di informazione, la statistica bayesiana la rappresenta attraverso distribuzioni di probabilità che catturano non solo cosa non sappiamo, ma anche quanto siamo incerti riguardo a ciò che non sappiamo.\n\n44.1.1 L’esempio di Sherlock Holmes\nPer illustrare questo concetto, consideriamo un esempio ispirato ai racconti di Arthur Conan Doyle (Kruschke, 2014). Immaginiamo che Sherlock Holmes stia indagando su un caso di furto in una villa londinese. Il detective sa che il colpevole è una delle quattro persone presenti quella sera: il maggiordomo, la cuoca, il giardiniere e un ospite. Inizialmente, senza alcuna evidenza particolare, Holmes potrebbe assegnare la stessa probabilità a ciascun sospetto: 25% per ognuno.\nQuesta distribuzione uniforme dell’incertezza rappresenta uno stato di “ignoranza simmetrica” - non abbiamo ragioni per sospettare una persona più delle altre. Tuttavia, man mano che Holmes raccoglie indizi, la sua incertezza si trasforma e si concentra. Supponiamo che scopra impronte di terra fresca nel corridoio che porta alla cassaforte. Questa evidenza aumenta la probabilità che il colpevole sia il giardiniere (che lavora con la terra) e diminuisce quella degli altri sospetti. La distribuzione della probabilità potrebbe ora diventare: giardiniere 60%, maggiordomo 20%, cuoca 15%, ospite 5%. Successivamente, Holmes potrebbe scoprire che il giardiniere ha un alibi solido per l’ora del furto. Questa nuova informazione ridistribuisce completamente la probabilità: giardiniere 5%, maggiordomo 50%, cuoca 35%, ospite 10%.\n\n44.1.2 La natura dinamica dell’incertezza bayesiana\nL’esempio relativo a Sherlock Holmes illustra tre aspetti cruciali dell’approccio bayesiano all’incertezza. Primo, l’incertezza non è semplicemente “non sapere qualcosa”, ma una distribuzione strutturata di plausibilità tra diverse possibilità. Secondo, questa distribuzione cambia sistematicamente man mano che nuove evidenze diventano disponibili. Terzo, in ogni momento possiamo quantificare precisamente il nostro grado di certezza o incertezza riguardo a ciascuna ipotesi.\nNel contesto della ricerca psicologica, possiamo applicare lo stesso principio ai parametri dei nostri modelli statistici. Invece di cercare un singolo valore “vero” per un parametro come la media di un gruppo o la forza di una correlazione, trattiamo questi parametri come variabili la cui incertezza può essere rappresentata attraverso distribuzioni di probabilità. Una distribuzione stretta e appuntita indica alta certezza riguardo al valore del parametro, mentre una distribuzione ampia e piatta riflette maggiore incertezza.1",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_intro_bayes.html#dalla-certezza-puntuale-alla-distribuzione-dellincertezza",
    "href": "chapters/bayesian_inference/02_intro_bayes.html#dalla-certezza-puntuale-alla-distribuzione-dellincertezza",
    "title": "44  La quantificazione dell’incertezza",
    "section": "\n44.2 Dalla certezza puntuale alla distribuzione dell’incertezza",
    "text": "44.2 Dalla certezza puntuale alla distribuzione dell’incertezza\nLa differenza tra l’approccio tradizionale e quello bayesiano può essere illustrata pensando a come risponderemmo alla domanda “Qual è l’intelligenza media degli studenti di psicologia?” L’approccio tradizionale tenterebbe di fornire una singola risposta numerica, come “Il QI medio è 110”. L’approccio bayesiano, invece, riconoscerebbe l’incertezza inerente in questa stima e fornirebbe una distribuzione: “Siamo piuttosto sicuri che il QI medio sia tra 105 e 115, con 110 come valore più plausibile, ma valori tra 100 e 120 sono ancora ragionevolmente possibili”.\nQuesta rappresentazione probabilistica dell’incertezza non è semplicemente più onesta intellettualmente - è anche più utile praticamente. Ci permette di prendere decisioni informate che tengono conto dell’incertezza, di pianificare studi futuri che riducano l’incertezza dove è più necessario, e di comunicare i risultati della ricerca in modo che rifletta accuratamente il nostro grado di conoscenza.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_intro_bayes.html#le-fondamenta-concettuali-dellinferenza-bayesiana",
    "href": "chapters/bayesian_inference/02_intro_bayes.html#le-fondamenta-concettuali-dellinferenza-bayesiana",
    "title": "44  La quantificazione dell’incertezza",
    "section": "\n44.3 Le fondamenta concettuali dell’inferenza bayesiana",
    "text": "44.3 Le fondamenta concettuali dell’inferenza bayesiana\nCome è stato discusso nei capitoli introduttivi, l’approccio bayesiano alla statistica si fonda su una visione particolare della probabilità che differisce sostanzialmente dall’interpretazione frequentista tradizionale. Mentre il frequentismo interpreta la probabilità come una proprietà oggettiva del mondo legata alla frequenza di eventi ripetibili, il bayesianesimo la intende come una misura del nostro grado di credenza o certezza riguardo a proposizioni incerte.\n\n44.3.1 Interpretazione bayesiana della probabilità\nNel frequentismo, dire che una moneta ha probabilità 0.5 di dare testa significa che, in un numero infinito di lanci, la frequenza relativa di teste convergerà a 0.5. Questa definizione, pur elegante matematicamente, presenta difficoltà pratiche evidenti: raramente possiamo ripetere un esperimento infinite volte, e molti eventi di interesse sono intrinsecamente irripetibili. Il bayesianesimo offre un’alternativa concettualmente diversa: la probabilità 0.5 rappresenta il nostro grado di credenza che il prossimo lancio darà testa, basato sulle informazioni attualmente disponibili. Questa interpretazione soggettiva della probabilità non la rende arbitraria o non scientifica, purché seguiamo le regole della teoria della probabilità per garantire coerenza logica nelle nostre inferenze.\n\n44.3.2 Il teorema di Bayes come strumento di aggiornamento\nIl cuore dell’inferenza bayesiana è il teorema di Bayes, che fornisce una formula matematica per aggiornare le nostre credenze alla luce di nuove evidenze:\n\\[\np(\\theta \\mid D) = \\frac{p(D \\mid \\theta)\\, p(\\theta)}{p(D)},\n\\]\nQuesta equazione apparentemente semplice cattura un processo cognitivo fondamentale: come integrare nuove informazioni con conoscenze preesistenti. Il termine \\(p(θ)\\) rappresenta le nostre credenze iniziali sul parametro \\(\\theta\\) (distribuzione a priori), \\((D \\mid \\theta)\\) descrive quanto sono compatibili i dati osservati \\(D\\) con diversi valori di \\(\\theta\\) (verosimiglianza), e \\(p(\\theta \\mid D)\\) è il risultato dell’aggiornamento: le nostre credenze aggiornate dopo aver osservato i dati (distribuzione a posteriori).\nIl denominatore \\(p(D)\\) è spesso chiamato “evidenza” o “probabilità marginale” dei dati, e serve come costante di normalizzazione per garantire che la distribuzione a posteriori integri a 1.\n\n\n\n\n\n\nLa verosimiglianza come funzione di θ\n\n\n\nLa stessa formula che usiamo per descrivere la probabilità dei dati dati i parametri può essere “letta al contrario”. Se fissiamo i dati osservati \\(y\\), la funzione\n\\[\nL(\\theta \\mid y) \\propto p(y \\mid \\theta)\n\\]\nsi chiama funzione di verosimiglianza. Non è una probabilità vera e propria (non si somma a 1 su \\(\\theta\\)), ma ci dice quali valori di \\(\\theta\\) rendono i dati più plausibili.\nQuesta distinzione è cruciale:\n\n\nProbabilità → dati variabili, parametri fissi.\n\n\nVerosimiglianza → dati fissi, parametri variabili.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_intro_bayes.html#il-processo-generatore-dei-dati-dal-parametro-allosservazione",
    "href": "chapters/bayesian_inference/02_intro_bayes.html#il-processo-generatore-dei-dati-dal-parametro-allosservazione",
    "title": "44  La quantificazione dell’incertezza",
    "section": "\n44.4 Il processo generatore dei dati: dal parametro all’osservazione",
    "text": "44.4 Il processo generatore dei dati: dal parametro all’osservazione\nUn concetto centrale nell’inferenza statistica, che spesso rimane implicito nei corsi introduttivi, è quello del processo generatore dei dati. Questo concetto rappresenta il meccanismo teorico attraverso cui i parametri sconosciuti di interesse producono i dati che osserviamo nel nostro campione.\n\n44.4.1 Comprendere il legame parametro-dati\nQuando conduciamo una ricerca psicologica, osserviamo dati specifici: punteggi a test, tempi di reazione, risposte a questionari. Tuttavia, quello che veramente ci interessa sono i parametri sottostanti che hanno generato questi dati: la vera media della popolazione, la vera forza di una correlazione, la vera differenza tra gruppi sperimentali. Il processo generatore dei dati è il modello teorico che specifica come questi parametri latenti si traducono nelle osservazioni concrete.\nConsideriamo un esempio concreto. Supponiamo di essere interessati al livello medio di ansia in una popolazione di studenti universitari. Il parametro di interesse è \\(\\mu\\), la vera media della popolazione. Tuttavia, quando raccogliamo dati, otteniamo solo un campione di osservazioni: \\(x_1,x_2, \\dots,x_n\\). Il processo generatore dei dati specifica che ogni osservazione \\(x_i\\) è estratta da una distribuzione normale con media \\(\\mu\\) e deviazione standard \\(\\sigma\\): \\(x_i \\sim \\mathcal{N}(\\mu, \\sigma)\\).\n\n44.4.2 La verosimiglianza come ponte concettuale\nLa verosimiglianza \\(p(D \\mid \\theta)\\) formalizza matematicamente il processo generatore dei dati (si veda il Capitolo 42). Essa esprime la probabilità di osservare esattamente i dati che abbiamo raccolto, dato un particolare valore del parametro \\(\\theta\\). In altre parole, per ogni possibile valore di \\(\\theta\\), la verosimiglianza ci dice quanto sono “probabili” o “compatibili” i nostri dati osservati.\nQuesto concetto può essere controintuitivo inizialmente, perché stiamo calcolando la probabilità dei dati (che abbiamo già osservato e quindi sappiamo essere “veri”) condizionata su parametri (che sono sconosciuti). Tuttavia, la verosimiglianza ci fornisce uno strumento potente per confrontare diversi valori possibili del parametro: valori di \\(\\theta\\) che rendono i nostri dati più probabili sono più plausibili di valori che li rendono meno probabili.\n\n44.4.3 L’importanza delle assunzioni sul processo generatore\nLa scelta del processo generatore dei dati è cruciale e riflette le nostre assunzioni teoriche sul fenomeno studiato. Assumere che i dati seguano una distribuzione normale implica che la variabilità osservata è simmetrica attorno alla media e che valori estremi sono rari ma possibili. Assumere una distribuzione di Poisson suggerirebbe che stiamo modellando conteggi di eventi rari. Assumere una distribuzione Beta indicherebbe che stiamo lavorando con proporzioni o probabilità.\nQueste scelte non sono neutre: influenzano profondamente le inferenze che traiamo dai dati. Un vantaggio dell’approccio bayesiano è che rende esplicite queste assunzioni, permettendoci di valutarne la plausibilità e di esplorare la robustezza delle nostre conclusioni a assunzioni alternative.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_intro_bayes.html#laggiornamento-bayesiano-in-azione-lesempio-del-globo",
    "href": "chapters/bayesian_inference/02_intro_bayes.html#laggiornamento-bayesiano-in-azione-lesempio-del-globo",
    "title": "44  La quantificazione dell’incertezza",
    "section": "\n44.5 L’aggiornamento bayesiano in azione: l’esempio del globo",
    "text": "44.5 L’aggiornamento bayesiano in azione: l’esempio del globo\nPer illustrare concretamente come funziona l’aggiornamento bayesiano, consideriamo l’esempio classico proposto da McElreath nel suo testo “Statistical Rethinking” (McElreath, 2020). Immaginiamo di voler stimare la proporzione della superficie terrestre coperta d’acqua utilizzando un metodo sperimentale semplice: lanciare un globo terrestre in aria, afferrarlo casualmente, e osservare se il punto sotto il nostro dito indice è acqua o terra.\n\n44.5.1 Il setup sperimentale\nChiamiamo \\(p\\) la vera proporzione di superficie coperta d’acqua. Questo è il nostro parametro di interesse - quello che vogliamo stimare. Ogni lancio del globo ci dà un’osservazione: “W” se tocchiamo acqua, “L” se tocchiamo terra. Il nostro processo generatore dei dati assume che ogni lancio sia indipendente e che la probabilità di osservare acqua in ogni singolo lancio sia esattamente \\(p\\).\nInizialmente, non abbiamo conoscenze specifiche sulla proporzione d’acqua sulla Terra. Potremmo quindi iniziare con una distribuzione a priori uniforme: ogni valore di \\(p\\) tra 0 e 1 è ugualmente plausibile. Questa scelta riflette uno stato di “ignoranza informativa” - non abbiamo ragioni per favorire alcuni valori di \\(p\\) rispetto ad altri.\n\n44.5.2 La dinamica dell’apprendimento\nSupponiamo che il primo lancio risulti in “W” (acqua). Come dovrebbe cambiare la nostra credenza su \\(p\\)? Intuitivamente, osservare acqua dovrebbe aumentare la plausibilità di valori di pp p più alti e diminuire quella di valori più bassi. Il teorema di Bayes formalizza esattamente questa intuizione.\nPrima dell’osservazione, tutti i valori di \\(p\\) avevano la stessa probabilità. Dopo aver osservato “W”, valori di \\(p\\) vicini a 0 diventano molto implausibili (se \\(p\\) fosse davvero vicino a 0, sarebbe stato molto improbabile osservare acqua al primo lancio), mentre valori più alti di \\(p\\) diventano più credibili. La distribuzione a posteriori rifletterà questo cambiamento, concentrando più probabilità sui valori più alti di \\(p\\).\nIl secondo lancio risulta in “L” (terra). Questa nuova osservazione fornisce evidenza nella direzione opposta: ora valori molto alti di \\(p\\) diventano meno plausibili. La distribuzione a posteriori si aggiusterà di nuovo, bilanciando l’evidenza di entrambe le osservazioni. Il pattern risultante sarà una distribuzione che favorisce valori intermedi di \\(p\\), coerenti con l’aver osservato sia acqua che terra.\n\n44.5.3 L’accumulo progressivo dell’evidenza\nMan mano che continuiamo a raccogliere dati - diciamo che osserviamo la sequenza “W”, “L”, “W”, “W”, “L”, “W”, “L”, “W”, “W” - la distribuzione a posteriori evolve continuamente. Ogni nuova osservazione aggiorna le nostre credenze, integrando la nuova evidenza con tutta l’informazione precedentemente raccolta.\nUn aspetto cruciale di questo processo è che la distribuzione a posteriori dopo \\(n\\) osservazioni diventa automaticamente la distribuzione a priori per la (n+1)-esima osservazione. Questo riflette un principio fondamentale dell’apprendimento bayesiano: ogni pezzo di informazione è integrato cumulativamente, e non c’è perdita di informazione nel processo di aggiornamento.\n\n44.5.4 L’evoluzione dell’incertezza\nOltre a tracciare come cambia la nostra stima “migliore” di \\(p\\) (ad esempio, la moda della distribuzione), è altrettanto importante osservare come evolve la nostra incertezza. Nelle prime fasi dell’esperimento, quando abbiamo pochi dati, la distribuzione a posteriori sarà relativamente ampia, riflettendo la nostra incertezza sostanziale sul valore di \\(p\\).\nMan mano che raccogliamo più osservazioni, la distribuzione diventa progressivamente più stretta e concentrata. Questo restringimento rappresenta la riduzione dell’incertezza: con più dati, diventiamo più sicuri del valore di \\(p\\). Tuttavia, la forma precisa di questa evoluzione dipende dai dati specifici osservati. Se i dati sono molto consistenti (ad esempio, molti successi consecutivi), l’incertezza si ridurrà rapidamente. Se i dati sono più variabili, la riduzione dell’incertezza sarà più graduale.\n\n\n\n\n\n\n\n\nIl grafico illustra visivamente questo processo di aggiornamento bayesiano. In ogni pannello, la linea grigia rappresenta la distribuzione a priori (le nostre credenze prima della nuova osservazione), mentre la linea blu mostra la distribuzione a posteriori (le credenze aggiornate dopo l’osservazione). Si può notare come ogni distribuzione a posteriori diventi la nuova distribuzione a priori per il passo successivo, creando una catena continua di aggiornamento dell’incertezza.\n\n\n\n\n\n\nPosteriori diverse a confronto\n\n\n\nLo stesso insieme di dati può dare origine a posteriori molto diverse a seconda del prior.\nQuesto non è un “difetto” del Bayes, ma un aspetto centrale: rende esplicita l’influenza delle ipotesi di partenza.\nIl vantaggio è che possiamo discutere apertamente quanto le conclusioni dipendano dal prior e, se necessario, confrontare più specificazioni (analisi di sensibilità).\n\n\n\n44.5.5 Lezioni dall’esempio del globo\nQuesto esempio illustra diversi principi fondamentali dell’inferenza bayesiana. Primo, l’aggiornamento delle credenze è sistematico e quantificabile: non ci basiamo su intuizioni vaghe, ma su calcoli matematici precisi. Secondo, l’informazione si accumula in modo ottimale: ogni osservazione contribuisce alla nostra conoscenza complessiva senza perdita di informazione precedente. Terzo, il processo esplicita chiaramente la distinzione tra ciò che sappiamo (la distribuzione a posteriori corrente) e ciò che non sappiamo (l’ampiezza di questa distribuzione). Quarto, il metodo fornisce previsioni calibrate: possiamo usare la distribuzione a posteriori non solo per stimare \\(p\\), ma anche per predire l’esito di futuri lanci del globo.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_intro_bayes.html#implicazioni-per-la-ricerca-psicologica",
    "href": "chapters/bayesian_inference/02_intro_bayes.html#implicazioni-per-la-ricerca-psicologica",
    "title": "44  La quantificazione dell’incertezza",
    "section": "\n44.6 Implicazioni per la ricerca psicologica",
    "text": "44.6 Implicazioni per la ricerca psicologica\nL’approccio bayesiano all’inferenza ha profonde implicazioni per come conduciamo e interpretiamo la ricerca psicologica. A differenza dei metodi frequentisti tradizionali, che forniscono risposte dicotomiche (significativo/non significativo) basate su criteri arbitrari (come \\(p\\) &lt; 0.05), l’inferenza bayesiana offre un quadro più ricco e sfumato per comprendere e comunicare i risultati della ricerca.\n\n44.6.1 Dai test di ipotesi all’aggiornamento delle credenze\nIl paradigma tradizionale dei test di ipotesi null’ipotesi (NHST) struttura la ricerca come un processo di decisione binaria: rifiutiamo o non rifiutiamo l’ipotesi nulla. Questo approccio, pur avendo servito la psicologia per decenni, presenta limitazioni ben documentate. Non ci dice quanto è plausibile l’ipotesi alternativa, non quantifica l’incertezza nelle nostre stime, e non fornisce un meccanismo naturale per integrare risultati di studi multipli.\nL’approccio bayesiano ricontestualizza la ricerca come un processo continuo di aggiornamento delle credenze. Invece di chiedere “Possiamo rifiutare l’ipotesi nulla?”, chiediamo “Come cambiano le nostre credenze riguardo al fenomeno di interesse alla luce di questi nuovi dati?”. Questa formulazione è più naturale e informativamente ricca: invece di una decisione binaria, otteniamo una quantificazione completa dell’incertezza e un aggiornamento calibrato delle nostre conoscenze. L’integrazione di conoscenze preesistenti\nUno dei vantaggi più significativi dell’approccio bayesiano è la sua capacità di integrare formalmente conoscenze preesistenti nell’analisi dei dati. Nella ricerca psicologica, raramente partiamo da zero: abbiamo teorie esistenti, risultati di studi precedenti, e conoscenze accumulate nel campo. L’inferenza frequentista tradizionale tratta ogni studio come se fosse condotto in un vuoto informativo, ignorando sistematicamente queste conoscenze pregresse.\nL’inferenza bayesiana, attraverso la distribuzione a priori, permette di incorporare esplicitamente queste informazioni preesistenti. Questo non significa che i risultati sono “soggettivi” o “non scientifici” - significa semplicemente che riconosciamo che la scienza è un’attività cumulativa dove ogni nuovo studio si costruisce sulle fondamenta degli studi precedenti.\n\n44.6.2 La comunicazione dell’incertezza\nI risultati bayesiani si prestano naturalmente a una comunicazione più onesta e informativa dell’incertezza. Invece di riportare che “la differenza tra gruppi è significativa (\\(p\\) &lt; 0.05)”, possiamo dire che “siamo al 95% sicuri che la vera differenza tra gruppi sia tra 0.3 e 0.8 punti, con 0.55 come valore più plausibile”. Questa formulazione comunica non solo la direzione e la magnitudine dell’effetto, ma anche il grado di certezza che possiamo avere in questa stima.\nInoltre, l’approccio bayesiano fornisce strumenti naturali per rispondere a domande praticamente rilevanti. Invece di limitarci a stabilire se un effetto è “significativo”, possiamo calcolare la probabilità che l’effetto sia abbastanza grande da essere praticamente importante, o la probabilità che un intervento terapeutico sia superiore a trattamenti esistenti.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_intro_bayes.html#considerazioni-pratiche-e-limitazioni",
    "href": "chapters/bayesian_inference/02_intro_bayes.html#considerazioni-pratiche-e-limitazioni",
    "title": "44  La quantificazione dell’incertezza",
    "section": "\n44.7 Considerazioni pratiche e limitazioni",
    "text": "44.7 Considerazioni pratiche e limitazioni\nPur offrendo vantaggi concettuali significativi, l’approccio bayesiano presenta anche sfide pratiche che devono essere riconosciute e affrontate. La scelta delle distribuzioni a priori, in particolare, può essere controversa e richiede giustificazione teorica. Distribuzioni a priori troppo informative possono dominare i dati, mentre distribuzioni troppo vaghe possono portare a problemi computazionali.\nLa complessità computazionale rappresenta un’altra sfida. Mentre esempi semplici come quello del globo ammettono soluzioni analitiche, la maggior parte dei modelli bayesiani realistici richiede metodi computazionali intensivi come il campionamento Monte Carlo via catene di Markov (MCMC). Questo può rendere l’analisi bayesiana meno accessibile per ricercatori senza formazione computazionale specializzata.\nTuttavia, lo sviluppo di software user-friendly come Stan, PyMC, e interfacce R come rstanarm e brms stanno rendendo l’analisi bayesiana sempre più accessibile. Inoltre, la crescente disponibilità di potenza computazionale e il miglioramento degli algoritmi stanno riducendo progressivamente questi ostacoli pratici.\n\n\n\n\n\n\nLa predittiva posteriore\n\n\n\nOltre a stimare i parametri, possiamo chiederci: quali dati futuri ci aspettiamo? Questa distribuzione si chiama predittiva posteriore (si veda il Capitolo 55):\n\\[\np(\\tilde{y} \\mid y) = \\int p(\\tilde{y} \\mid \\theta)\\, p(\\theta \\mid y)\\, d\\theta.\n\\]\nIn pratica:\n\nestraiamo valori di \\(\\theta\\) dalla posterior;\n\nper ciascun valore simuliamo nuovi dati;\n\notteniamo così la distribuzione delle possibili osservazioni future.\n\nEsempio: dopo aver osservato 8 successi su 10, la probabilità che il prossimo lancio sia testa non è fissata, ma distribuita: circa il 73% in media, con incertezza esplicitata dalla posterior.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_intro_bayes.html#footnotes",
    "href": "chapters/bayesian_inference/02_intro_bayes.html#footnotes",
    "title": "44  La quantificazione dell’incertezza",
    "section": "",
    "text": "Un esempio semplice è il modello binomiale, che descrive il numero di successi \\(y\\) in \\(n\\) prove indipendenti con probabilità di successo \\(\\theta\\). Scriviamo \\(y \\sim \\text{Binomiale}(n, \\theta)\\). In questo caso \\(\\theta\\) è il parametro che rappresenta la probabilità di successo in ciascuna prova. Nella pratica, non conosciamo il valore “vero” di \\(\\theta\\) (per esempio, la probabilità che una persona risponda correttamente a un item di un test), ma possiamo rappresentare la nostra incertezza con una distribuzione di probabilità su \\(\\theta\\) e aggiornarla man mano che raccogliamo dati.↩︎",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_statistical_models.html#modelli-fenomenologici-descrivere-le-associazioni",
    "href": "chapters/bayesian_inference/03_statistical_models.html#modelli-fenomenologici-descrivere-le-associazioni",
    "title": "45  Modelli statistici",
    "section": "\n45.2 Modelli fenomenologici: descrivere le associazioni",
    "text": "45.2 Modelli fenomenologici: descrivere le associazioni\nUn modello fenomenologico cerca di sintetizzare i dati osservati attraverso relazioni statistiche.\nUn esempio tipico è la regressione lineare:\n\\[\ny_i = \\alpha + \\beta x_i + \\varepsilon_i .\n\\]\nQuesta formula descrive come varia la media di \\(y\\) in funzione di \\(x\\). È utile per riassumere e predire, ma non dice nulla sul meccanismo psicologico che produce la relazione.\n\n45.2.1 Il problema dell’errore di specificazione\nI modelli fenomenologici sono esposti a gravi rischi:\n\npossono adattarsi bene ai dati osservati ma essere falsi nel rappresentare la realtà;\n\ntrascurano variabili latenti o meccanismi che non vengono osservati direttamente;\n\npossono generare correlazioni spurie e interpretazioni fuorvianti.\n\nEsempio: una regressione che mostra un legame tra “tempo sui social” e “ansia” non ci dice nulla sul ruolo di mediazione di variabili cognitive o sociali.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_statistical_models.html#modelli-meccanicistici-spiegare-i-processi",
    "href": "chapters/bayesian_inference/03_statistical_models.html#modelli-meccanicistici-spiegare-i-processi",
    "title": "45  Modelli statistici",
    "section": "\n45.3 Modelli meccanicistici: spiegare i processi",
    "text": "45.3 Modelli meccanicistici: spiegare i processi\nI modelli meccanicistici non si limitano a descrivere relazioni, ma cercano di rappresentare il processo generativo.\n\n45.3.1 Esempi in psicologia\n\n\nRescorla-Wagner: formalizza come le aspettative di un soggetto vengono aggiornate in base agli errori di previsione durante l’apprendimento associativo.\n\n\nDrift Diffusion Model (DDM): descrive scelte binarie e tempi di reazione come risultato di un processo di accumulo di evidenza.\n\nQuesti modelli sono più vicini a una teoria psicologica esplicita, e possono essere testati confrontando le loro previsioni con i dati osservati.\n\n\n\n\n\n\nDifferenza intuitiva\n\n\n\nUn modello fenomenologico può dire: “più ore di studio → voti più alti”.\nUn modello meccanicistico può dire: “ogni sessione di studio incrementa la memoria con un tasso di apprendimento definito, che a sua volta determina la probabilità di rispondere correttamente”.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Modelli statistici</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_statistical_models.html#valutazione-e-confronto-dei-modelli",
    "href": "chapters/bayesian_inference/03_statistical_models.html#valutazione-e-confronto-dei-modelli",
    "title": "45  Modelli statistici",
    "section": "\n45.4 Valutazione e confronto dei modelli",
    "text": "45.4 Valutazione e confronto dei modelli\nIn un approccio bayesiano, il confronto tra modelli è parte integrante della pratica scientifica. Non si tratta solo di “adattare” un modello ai dati, ma di chiedersi:\n\nQuanto bene il modello descrive i dati osservati?\n\nQuanto bene si generalizza a nuovi dati?\n\nQuanto è coerente con la teoria psicologica di riferimento?\n\nQueste domande permettono di superare la visione ingenua secondo cui “un modello buono è quello che si adatta bene ai dati”.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Modelli statistici</span>"
    ]
  }
]