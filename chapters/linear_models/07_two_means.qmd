# Confronto tra le medie di due gruppi {#sec-linear-models-two-groups}

::: callout-note
## In questo capitolo imparerai a

- condurre un confronto bayesiano tra le medie di due gruppi utilizzando la  funzione `brm()` del pacchetto **brms**.
:::

::: callout-tip
## Prerequisiti

- Consultare l'articolo "Bayesian estimation supersedes the t test" [@kruschke2013bayesian]. 
:::

::: callout-important
## Preparazione del Notebook

```{r}
here::here("code", "_common.R") |> 
  source()

# Load packages
if (!requireNamespace("pacman")) install.packages("pacman")
pacman::p_load(cmdstanr, posterior, brms, bayestestR, insight)
```
:::

## Introduzione

Uno degli obiettivi fondamentali nella ricerca psicologica è comprendere se e quanto due gruppi differiscano tra loro. Ad esempio, ci chiediamo se un trattamento ha prodotto un cambiamento nel comportamento, se un gruppo clinico mostra livelli più elevati di ansia rispetto a un gruppo di controllo, o se due condizioni sperimentali generano risposte differenti. In tutti questi casi, l’interesse non riguarda soltanto la presenza di una differenza, ma anche la sua grandezza e l’incertezza con cui possiamo stimarla.

L’approccio tradizionale si basa sul test d’ipotesi: si parte dall’assunzione che non vi sia alcuna differenza tra i gruppi (ipotesi nulla) e si valuta quanto i dati osservati siano compatibili con questa ipotesi. Il risultato, il p-value, indica la probabilità di ottenere dati così estremi (o più) se l’ipotesi nulla fosse vera. Ma questo tipo di inferenza, per quanto diffuso, si riduce a una decisione binaria fondata su soglie arbitrarie e spesso non aiuta a comprendere davvero la natura del fenomeno psicologico osservato.

Un’alternativa più ricca è offerta dall’approccio bayesiano, che sposta il focus dal "verificare se c’è una differenza" al "quanto è grande e quanto siamo incerti nel stimarla". Invece di produrre una risposta secca, il modello bayesiano restituisce una distribuzione di probabilità per ogni parametro, riflettendo in modo esplicito l’incertezza residua dopo aver osservato i dati. Questo è particolarmente utile in psicologia, dove l’eterogeneità inter- e intra-individuale è la norma.

Nel confronto tra due gruppi, il modello bayesiano distingue due fonti fondamentali di incertezza: l’**incertezza aleatoria**, legata alla variabilità naturale del comportamento umano, e l’**incertezza epistemica**, che riguarda la nostra conoscenza limitata e che possiamo ridurre attraverso l’accumulo di dati o l’integrazione di conoscenze pregresse tramite i prior.

Nel corso di questo capitolo vedremo come modellare la differenza tra due medie utilizzando una regressione con variabile indicatrice. Questo approccio, formalmente equivalente al classico confronto tra due gruppi, permette di stimare la differenza in termini probabilistici, fornendo strumenti chiari per ragionare sull’incertezza.

## Regressione bayesiana per confrontare due gruppi

Il confronto tra due medie può essere espresso in modo semplice con un modello di regressione lineare:

$$
y_i = \alpha + \gamma D_i + \varepsilon_i,
$$

dove:

* $y_i$ è il punteggio osservato per l’individuo $i$;
* $D_i$ è una variabile dummy: 0 per il gruppo di riferimento (es. controllo), 1 per il gruppo sperimentale;
* $\alpha$ rappresenta la media del gruppo di riferimento;
* $\gamma$ è la differenza tra le medie;
* $\varepsilon_i$ è un errore casuale con deviazione standard $\sigma$.

Nel contesto bayesiano, trattiamo $\alpha$, $\gamma$ e $\sigma$ come variabili aleatorie, a cui associamo delle distribuzioni a priori. Una volta osservati i dati, aggiorniamo queste credenze ottenendo le distribuzioni a posteriori. La distribuzione a posteriori di \$\gamma\$ ci dice quanto è plausibile ciascun valore della differenza tra gruppi, data l’evidenza empirica e le nostre ipotesi iniziali.

Questo ci permette di:

* calcolare direttamente la probabilità che la differenza sia positiva, negativa o maggiore di una soglia rilevante;
* ottenere un intervallo di credibilità (es. al 95%) che racchiude i valori più plausibili;
* confrontare il risultato con aspettative teoriche pregresse.

L’approccio bayesiano offre così un linguaggio continuo e graduale per descrivere l’evidenza, evitando interpretazioni forzate e soglie arbitrarie.

## L’approccio frequentista: un confronto concettuale

Il frequentismo affronta lo stesso problema partendo da un’altra prospettiva: i dati sono considerati aleatori, mentre i parametri sono fissi ma sconosciuti. L’inferenza si basa sul comportamento della statistica campionaria in esperimenti ipotetici ripetuti all’infinito. L’intervallo di confidenza al 95%, ad esempio, è costruito per contenere il valore vero nel 95% dei campioni, ma non possiamo interpretarlo come un’affermazione probabilistica sul singolo caso.

Nel confronto tra due gruppi, la differenza tra le medie campionarie è utilizzata per calcolare una statistica $t$, confrontata con una distribuzione teorica per valutare la compatibilità dei dati con l’ipotesi nulla ($\mu_1 = \mu_2$). Il p-value misura quanto sarebbe raro osservare una differenza pari a quella trovata (o maggiore), se l’ipotesi nulla fosse vera. Ma non ci dice nulla sulla probabilità che la differenza sia vera, né sulla sua grandezza.

## Due modi diversi di trattare l’incertezza

Sia il frequentismo che il bayesianesimo usano la stessa struttura del modello, ma differiscono per come concepiscono l’incertezza:

| Aspetto                        | Frequentista                            | Bayesiano                               |
| ------------------------------ | --------------------------------------- | --------------------------------------- |
| Parametri                      | Fissi ma ignoti                         | Variabili aleatorie                     |
| Incertezza                     | Deriva dalla procedura                  | Espressa come probabilità sui parametri |
| Intervallo                     | Di confidenza                           | Di credibilità                          |
| Risposta alla domanda          | “I dati sono compatibili con $H_0$?” | “Quanto è plausibile questo valore?”    |
| Uso della conoscenza pregressa | Non previsto                            | Possibile tramite prior                 |

In psicologia, dove le risposte raramente sono nette e dove la variabilità è fisiologica, la capacità dell’approccio bayesiano di rappresentare l’incertezza in modo diretto rende l’inferenza non solo più trasparente, ma anche più utile per la comprensione dei dati.

## Un esempio illustrativo: il ruolo dell’istruzione materna

Dopo aver discusso le differenze tra approccio frequentista e bayesiano, vediamo ora come questi due modi di inferire si comportano su un caso reale. Utilizzeremo un dataset classico in psicologia dello sviluppo, che riporta i punteggi di **quoziente intellettivo (QI)** di bambini, insieme a informazioni sul **livello di istruzione della madre**.

La domanda che ci poniamo è semplice, ma rilevante: *i figli di madri diplomate (che hanno completato la scuola superiore) mostrano in media un QI diverso rispetto ai figli di madri non diplomate?*

### Esplorazione iniziale dei dati

Importiamo il dataset e verifichiamo la struttura delle variabili:

```{r}
kidiq <- rio::import(here::here("data", "kidiq.dta"))
glimpse(kidiq)
```

Calcoliamo alcune statistiche descrittive per ciascun gruppo:

```{r}
kidiq |> 
  group_by(mom_hs) |> 
  summarise(
    n = n(),
    media_QI = mean(kid_score),
    sd_QI = sd(kid_score)
  )
```

Vediamo così che il campione include **93 bambini** con madri non diplomate e **341 con madri diplomate**, con una differenza apparente nei punteggi medi di QI. Ma questa differenza è solo un effetto casuale, o riflette una tendenza reale nella popolazione?

Per rispondere, analizziamo il problema utilizzando entrambi gli approcci.

## Due strade per lo stesso problema

### Approccio frequentista

Per valutare se la differenza osservata è compatibile con l’ipotesi che non ci sia alcuna differenza nella popolazione, applichiamo il **t-test per campioni indipendenti**:

```{r}
t.test(
  kid_score ~ mom_hs, 
  data = kidiq, 
  var.equal = TRUE
)
```

Questa funzione restituisce la stima della differenza media, l'intervallo di confidenza al 95%, e il valore del **p-value**. Il p-value rappresenta la probabilità di osservare una differenza almeno così grande *se* non ci fosse alcuna differenza reale nella popolazione (cioè sotto l’ipotesi nulla $\mu_1 = \mu_2$).

È una misura indiretta dell’evidenza contro l’ipotesi nulla: più è piccolo il p-value, meno plausibile appare l’ipotesi di assenza di differenza. Ma, come abbiamo visto nei capitoli precedenti, questo tipo di inferenza è vincolato da assunzioni forti e da interpretazioni spesso controintuitive.

Nel prossimo paragrafo, analizzeremo lo stesso problema con l’approccio bayesiano, per ottenere una visione più continua e informativa dell’incertezza sulla differenza tra i gruppi.


### Approccio bayesiano

A differenza dell’approccio frequentista, che parte da un’ipotesi nulla e valuta la compatibilità dei dati con essa, il paradigma bayesiano si concentra direttamente sull’effetto che vogliamo stimare. Non ci si chiede se la differenza tra gruppi "esiste", ma quanto è plausibile e quanto è incerta.

Per farlo, costruiamo un modello probabilistico che descriva la relazione tra il QI dei bambini e il livello di istruzione materna. Il modello è una semplice regressione con variabile dummy:

$$
y_i \sim \mathcal{N}(\mu_i, \sigma), \quad \mu_i = \alpha + \gamma D_i,
$$

dove:

* $y_i$ è il punteggio di QI del bambino $i$,
* $D_i = 0$ se la madre non è diplomata, $1$ se è diplomata,
* $\alpha$ rappresenta il QI medio per i figli di madri non diplomate,
* $\gamma$ rappresenta la differenza tra i gruppi,
* $\sigma$ è la deviazione standard residua.

#### Stima del modello con `brms`

Stimiamo il modello utilizzando il pacchetto `brms`, che permette di ottenere direttamente la distribuzione a posteriori dei parametri:

```{r}
#| output: false
fit_1 <- brm(
  kid_score ~ mom_hs,
  data = kidiq,
  backend = "cmdstanr",
  silent = 0
)
```

Una volta ottenuti i campioni a posteriori, possiamo rispondere in modo diretto alla domanda: *qual è la probabilità che la differenza media tra i due gruppi superi una soglia di interesse, ad esempio 5 punti?*

```{r}
posterior_samples <- as_draws_df(fit_1)
mean(posterior_samples$b_mom_hs > 5)
```

Questo valore non è un p-value, ma una vera probabilità condizionata ai dati osservati. Ad esempio, un risultato pari a 0.96 può essere interpretato come: *"dato il nostro modello e i dati disponibili, c’è una probabilità del 96% che i figli di madri diplomate abbiano in media un QI superiore di almeno 5 punti"*.

### Visualizzare la variabilità nei dati

Un grafico aiuta a rappresentare non solo le medie, ma anche la distribuzione dei punteggi all’interno di ciascun gruppo:

```{r}
ggplot(kidiq, aes(x = as.factor(mom_hs), y = kid_score)) +
  geom_violin(trim = FALSE, fill = "skyblue") +
  geom_boxplot(width = 0.1, outlier.shape = NA, fill = "white", color = "black") +
  labs(
    x = "Istruzione materna",
    y = "QI del bambino",
    title = "Distribuzione dei punteggi QI\nper livello di istruzione della madre"
  ) +
  scale_x_discrete(labels = c("0" = "Non diplomata", "1" = "Diplomata"))
```

Il grafico evidenzia che, pur in presenza di una differenza tra le medie, esiste una notevole sovrapposizione tra i gruppi. Questo riflette la naturale variabilità dei dati psicologici e rende evidente perché la sola media non basta: è l’intera distribuzione che ci interessa comprendere.

## Cosa cambia davvero tra i due approcci?

Entrambi gli approcci usano gli stessi dati e, in presenza di campioni ampi e modelli lineari semplici, spesso portano a conclusioni numericamente simili. Tuttavia, ciò che cambia profondamente è il significato dei risultati.

| Aspetto                 | Frequentista                                                       | Bayesiano                                            |
| ----------------------- | ------------------------------------------------------------------ | ---------------------------------------------------- |
| Ipotesi di partenza     | Assume $\mu_1 = \mu_2$ (ipotesi nulla)                         | Nessuna ipotesi nulla                                |
| Obiettivo               | Verificare se la differenza osservata è improbabile sotto $H_0$ | Stimare la probabilità della differenza tra i gruppi |
| Interpretazione         | Il p-value è una probabilità *condizionata da $H_0$*            | La probabilità è *condizionata dai dati osservati*   |
| Rappresentazione        | Intervallo di confidenza                                           | Intervallo di credibilità                            |
| Uso dei dati precedenti | Non previsto                                                       | Integrabile tramite prior                            |

Il bayesianesimo, in questo contesto, non è solo una tecnica alternativa, ma un modo diverso di porre le domande e interpretare le risposte. Invece di dire *"questa differenza è significativa?"*, possiamo chiedere *"quanto è plausibile, alla luce dei dati, che la differenza superi una soglia rilevante?"*

Nel prossimo paragrafo, estenderemo questa analisi esplorando la sensibilità del modello bayesiano rispetto alla scelta dei prior e approfondiremo strumenti diagnostici che ci aiutano a valutare quanto il modello rifletta davvero i dati.


## Approfondimenti bayesiani: dalla flessibilità alla coerenza

Il confronto tra i gruppi sul QI ci ha già mostrato i vantaggi dell’inferenza bayesiana: la possibilità di quantificare direttamente l’incertezza sulla differenza tra le medie e di stimare probabilità a posteriori interpretabili. In questa sezione vediamo come l’approccio bayesiano permetta di **raffinare il modello** e **verificare la coerenza delle ipotesi** con i dati, prima e dopo l’osservazione.

### Intervallo di credibilità e verifica predittiva

Una volta stimato il modello, possiamo calcolare un **intervallo di credibilità all’89%**, una soglia suggerita in ambito didattico per sottolineare che non si tratta di una soglia “speciale”, ma di un’espressione quantitativa dell’incertezza residua:

```{r}
bayestestR::hdi(fit_1, parameters = "mom_hs", ci = 0.89)
```

Per valutare se il modello riproduce adeguatamente i dati, possiamo utilizzare la **verifica predittiva a posteriori**:

```{r}
pp_check(fit_1)
```

Nel nostro caso, il modello riproduce bene la forma generale della distribuzione osservata, ma si notano leggere discrepanze nelle code. Questo suggerisce che la distribuzione normale, pur efficace, potrebbe essere migliorata per catturare l’asimmetria presente nei dati.


### Flessibilità modellistica: usare una distribuzione skew-normal

Per rappresentare meglio la **variabilità asimmetrica**, possiamo utilizzare una **distribuzione skew-normal**, che generalizza la normale consentendo una coda più estesa da un lato:

```{r}
#| output: false
fit_2 <- brm(
  kid_score ~ mom_hs, 
  family = skew_normal(),
  backend = "cmdstanr", 
  data = kidiq
)
```

Il modello skew-normal migliora l’adattamento ai dati, come evidenziato da `pp_check(fit_2)`, che mostra una maggiore sovrapposizione tra predizioni e osservazioni.

```{r}
pp_check(fit_2)
```

## Verifica predittiva a priori (Prior Predictive Check)

Un passaggio fondamentale nella costruzione di modelli bayesiani consiste nel chiedersi: **quali dati ci aspetteremmo di vedere, se avessimo solo i prior e nessun dato reale?**

Con il **prior predictive check**, simuliamo dati fittizi basati unicamente sulle distribuzioni a priori, per verificare se le nostre ipotesi iniziali sono **compatibili con la scala e la natura del fenomeno psicologico in esame**.

Per esempio, possiamo specificare prior debolmente informativi ma plausibili:

```{r}
prior_gaussian <- 
  prior(normal(90, 20), class = "Intercept") +
  prior(normal(0, 15), class = "b", coef = "mom_hs") +
  prior(cauchy(0, 20), class = "sigma")
```

Poi stimiamo un modello basato **solo su questi prior**, ignorando i dati:

```{r}
#| output: false
fit_prior <- brm(
  kid_score ~ mom_hs,
  data = kidiq,
  prior = prior_gaussian,
  family = gaussian(),
  backend = "cmdstanr",
  sample_prior = "only"
)
```

Visualizzando i dati simulati:

```{r}
pp_check(fit_prior, ndraws = 100) + xlim(10, 180)
```

possiamo verificare se i prior generano predizioni realistiche. In questo caso, vediamo che i valori simulati si distribuiscono su un intervallo ampio ma plausibile, coerente con ciò che sappiamo sul QI. Questo indica che i prior non sono né troppo restrittivi né irrealistici.

## Incorporare conoscenza pregressa: prior informativi

Quando disponiamo di evidenze precedenti (ad esempio, studi che indicano un effetto medio dell’istruzione materna di circa 10 punti QI), possiamo formalizzarle con un prior informativo:

```{r}
#| output: false
fit_3 <- brm(
  kid_score ~ mom_hs,
  data = kidiq,
  prior = c(set_prior("normal(10, 5)", class = "b", coef = "mom_hs")),
  backend = "cmdstanr"
)
```

```{r}
summary(fit_3)
```

Se i dati confermano il pattern, la distribuzione a posteriori sarà **simile a quella ottenuta con prior deboli**. Ma in campioni piccoli o più rumorosi, questo tipo di informazione può fare una grande differenza, aiutando a stabilizzare l’inferenza.

## Test di ipotesi bayesiano

Infine, possiamo formulare **ipotesi probabilistiche direttamente interpretabili**, come:

*Qual è la probabilità che la differenza tra i gruppi superi i 5 punti?*

```{r}
hypothesis(fit_1, "mom_hs > 5")
```

A differenza del *p*-value, il risultato fornisce una risposta diretta: ad esempio, una probabilità del 98% che l’effetto sia maggiore di 5. Questo è il tipo di affermazione che possiamo portare **nella discussione scientifica o clinica**, senza bisogno di traduzioni arbitrarie.


::: {.callout-tip}
## Approfondimento statistico (opzionale)

Consideriamo ora le basi statistiche su cui si basa l'approccio frequentista. Nel paradigma frequentista, l’inferenza sulla differenza tra due gruppi si basa sulla **distribuzione campionaria** della differenza tra le medie. L’idea di fondo è che, se ripetessimo il campionamento molte volte, otterremmo valori diversi per la differenza tra le medie campionarie, e questa variabilità può essere descritta attraverso una distribuzione probabilistica.

Supponiamo di avere due popolazioni normali e indipendenti:

$$
Y_1 \sim \mathcal{N}(\mu_1, \sigma_1^2) \quad \text{e} \quad Y_2 \sim \mathcal{N}(\mu_2, \sigma_2^2)
$$

e di osservare due campioni indipendenti, rispettivamente di dimensione $n_1$ e $n_2$.

Se assumiamo inoltre che le varianze siano uguali ($\sigma_1^2 = \sigma_2^2 = \sigma^2$), possiamo utilizzare una versione semplificata del modello.

### Statistica di interesse

Il nostro obiettivo è stimare la **differenza tra le medie** delle due popolazioni, ovvero:

$$
\mu_1 - \mu_2.
$$

La stima di questa quantità è data dalla **differenza tra le medie campionarie**:

$$
\bar{Y}_1 - \bar{Y}_2.
$$

### Proprietà della statistica campionaria

#### Valore atteso

Nel caso di due campioni indipendenti:

$$
E(\bar{Y}_1 - \bar{Y}_2) = \mu_1 - \mu_2.
$$

::: {.callout-important title="Dimostrazione" collapse="true"}

Si parte dalla definizione di media campionaria per ciascun gruppo e si applica la linearità dell’operatore valore atteso:

$$
E(\bar{Y}_1 - \bar{Y}_2) = E(\bar{Y}_1) - E(\bar{Y}_2) = \mu_1 - \mu_2.
$$

:::

#### Varianza

La varianza della differenza tra le medie campionarie è:

$$
\operatorname{Var}(\bar{Y}_1 - \bar{Y}_2) = \frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}.
$$

::: {.callout-important title="Dimostrazione" collapse="true"}

Poiché i due campioni sono indipendenti, la varianza della differenza si ottiene sommando le varianze delle due medie:

$$
\operatorname{Var}(\bar{Y}_1) = \frac{\sigma_1^2}{n_1}, \quad \operatorname{Var}(\bar{Y}_2) = \frac{\sigma_2^2}{n_2}
$$

quindi:

$$
\operatorname{Var}(\bar{Y}_1 - \bar{Y}_2) = \frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}.
$$

:::

Se assumiamo varianze uguali ($\sigma_1 = \sigma_2 = \sigma$), possiamo scrivere:

$$
\operatorname{Var}(\bar{Y}_1 - \bar{Y}_2) = \sigma^2 \left( \frac{1}{n_1} + \frac{1}{n_2} \right).
$$

Poiché $\sigma^2$ è sconosciuta, la si stima tramite la **varianza pooled**:

$$
s_p^2 = \frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2},
$$

dove $s_1^2$ e $s_2^2$ sono le varianze campionarie:

$$
s_j^2 = \frac{1}{n_j - 1} \sum_{i=1}^{n_j} (y_{j,i} - \bar{y}_j)^2, \quad j = 1,2.
$$

### Distribuzione della statistica

Sotto l’ipotesi di normalità e indipendenza, e assumendo varianze uguali, la statistica $\bar{Y}_1 - \bar{Y}_2$ segue (almeno approssimativamente) una distribuzione normale:

$$
\bar{Y}_1 - \bar{Y}_2 \sim \mathcal{N} \left( \mu_1 - \mu_2,\ \sigma \sqrt{ \frac{1}{n_1} + \frac{1}{n_2} } \right).
$$

Questa proprietà permette di costruire un **intervallo di confidenza al 95%** per la differenza tra le medie, oppure di effettuare un **test t per due campioni indipendenti**, basato sulla seguente statistica:

$$
t = \frac{(\bar{Y}_1 - \bar{Y}_2) - (\mu_1 - \mu_2)}{s_p \sqrt{ \frac{1}{n_1} + \frac{1}{n_2} }}.
$$

Questa statistica segue, sotto l’ipotesi nulla $\mu_1 = \mu_2$, una distribuzione t di Student con $n_1 + n_2 - 2$ gradi di libertà.
:::

## Riflessioni conclusive: ragionare con l’incertezza

Il confronto tra due medie è un problema classico dell’analisi statistica. Ma il modo in cui lo affrontiamo riflette due visioni profondamente diverse dell’inferenza. L’approccio frequentista interpreta i dati alla luce di una procedura ipotetica: si domanda quanto una differenza osservata sarebbe rara se, in realtà, non ci fosse alcuna differenza nella popolazione. Il risultato, spesso riassunto in un p-value, è una misura indiretta e condizionata da un’ipotesi che, nella pratica psicologica, è raramente realistica.

L’approccio bayesiano, invece, sposta il focus: non interroga la compatibilità dei dati con un mondo ipotetico, ma costruisce una rappresentazione probabilistica della nostra incertezza rispetto ai parametri del modello. Il punto centrale non è più la validità dell’ipotesi nulla, ma la plausibilità, l’ampiezza e la rilevanza della differenza osservata, data l’evidenza disponibile e — se dichiarate — le conoscenze pregresse.

Utilizzando `brms`, abbiamo visto come questa prospettiva si traduca operativamente in modelli che restituiscono intere distribuzioni a posteriori, anziché singole stime. Abbiamo potuto:

* quantificare la probabilità che una differenza superi una soglia rilevante;
* ottenere intervalli di credibilità che esprimono in modo diretto l’incertezza residua;
* diagnosticare il comportamento del modello con controlli predittivi, sia posteriori che a priori;
* integrare conoscenze precedenti in modo esplicito, tramite la definizione di prior informativi.

In contesti come la psicologia — dove i dati sono rumorosi, la variabilità tra individui è elevata, e le ipotesi raramente sono nette — questo tipo di inferenza offre un vantaggio cruciale: non riduce la complessità empirica a una dicotomia (significativo / non significativo), ma la rappresenta in termini di gradiente, compatibilità, e margine d’incertezza.

L’inferenza bayesiana, dunque, non è semplicemente un’alternativa metodologica: è una cornice epistemologica che incoraggia un uso più riflessivo dei dati. Invece di trattare l’analisi statistica come un rituale decisionale, invita a formulare domande più articolate: *quale differenza è compatibile con i dati? quanto siamo incerti? quale informazione pregressa siamo disposti a includere?*

In definitiva, questo capitolo ha mostrato che ragionare in termini bayesiani significa non solo ottenere risultati più interpretabili, ma anche *modellare in modo esplicito il nostro stato di conoscenza*, rendendo visibile — e quindi discutibile e migliorabile — il grado di fiducia che attribuiamo alle nostre conclusioni. In psicologia, dove i fenomeni sono complessi e l’incertezza è inevitabile, questo rappresenta non un lusso, ma una necessità.



## Informazioni sull'Ambiente di Sviluppo {.unnumbered} 

```{r}
sessionInfo()
```

## Bibliografia {.unnumbered}

