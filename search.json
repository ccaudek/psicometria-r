[
  {
    "objectID": "chapters/linear_models/08_sample_size.html",
    "href": "chapters/linear_models/08_sample_size.html",
    "title": "67  Pianificazione della dimensione campionaria",
    "section": "",
    "text": "67.1 Introduzione\nNel contesto bayesiano, l’obiettivo principale non è verificare un’ipotesi nulla, ma stimare con quanta incertezza possiamo affermare che un effetto ha una certa ampiezza pratica. Questo approccio è particolarmente rilevante in psicologia, dove l’importanza di un risultato raramente si esaurisce nella sua “significatività statistica”.\nTuttavia, nella pratica scientifica è ancora diffuso l’uso della potenza frequentista. Per completezza, in questo capitolo presentiamo sia la formula classica per la potenza in un confronto tra due medie, sia una sua controparte bayesiana basata su simulazione. Il nostro scopo è mostrare come un approccio bayesiano orientato alla stima e alla simulazione possa offrire strumenti più flessibili, informativi e utili alla pianificazione degli studi.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Pianificazione della dimensione campionaria</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_sample_size.html#lapproccio-frequentista",
    "href": "chapters/linear_models/08_sample_size.html#lapproccio-frequentista",
    "title": "67  Pianificazione della dimensione campionaria",
    "section": "\n67.2 L’approccio frequentista",
    "text": "67.2 L’approccio frequentista\nNel framework frequentista, la potenza è definita come la probabilità, calcolata prima che uno studio venga condotto, che un determinato test statistico produca un p-value inferiore a una soglia prestabilita (tipicamente 0,05), dato un effetto reale ipotizzato.\nIl calcolo della potenza richiede:\n\nuna stima della dimensione dell’effetto atteso,\nuna stima della variabilità nei dati (deviazione standard),\nuna decisione sulla soglia di significatività,\ne infine un calcolo (o simulazione) della probabilità che il p-value sia &lt; 0.05.\n\nSi sconsiglia in genere di condurre studi con potenza bassa, perché hanno una bassa probabilità di produrre risultati “significativi”. Tuttavia, questo ragionamento non considera che il concetto stesso di significatività può essere fuorviante: anche quando un test ha potenza dell’80%, ciò non garantisce che l’effetto stimato sia preciso o utile.\n\n67.2.1 La maledizione del vincitore\nUno studio con bassa potenza può produrre risultati statisticamente significativi che sono ingannevoli. In presenza di molto rumore, gli effetti significativi osservati tendono a essere:\n\n\nesagerati (errore di tipo \\(M\\), magnitude),\n\nsbagliati nel segno (errore di tipo \\(S\\), sign).\n\nIn altre parole, anche quando uno studio riesce a “scoprire” un effetto, la stima ottenuta può essere gravemente distorta. Questa è una delle ragioni principali per cui molti risultati pubblicati si rivelano non replicabili (Gelman & Carlin, 2014).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Pianificazione della dimensione campionaria</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_sample_size.html#un-esempio-concreto",
    "href": "chapters/linear_models/08_sample_size.html#un-esempio-concreto",
    "title": "67  Pianificazione della dimensione campionaria",
    "section": "\n67.3 Un esempio concreto",
    "text": "67.3 Un esempio concreto\nPer rendere il confronto più chiaro, usiamo un esempio con gli stessi dati in entrambi gli approcci:\n\ndifferenza vera tra le medie: \\(\\Delta = 5\\);\ndeviazione standard comune: \\(\\sigma = 10\\);\ndimensione del campione: \\(n = 64\\) per gruppo;\neffetto standardizzato: Cohen’s d = 0.5",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Pianificazione della dimensione campionaria</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_sample_size.html#analisi-frequentista-dimensione-del-campione-per-potenza-dell80",
    "href": "chapters/linear_models/08_sample_size.html#analisi-frequentista-dimensione-del-campione-per-potenza-dell80",
    "title": "67  Pianificazione della dimensione campionaria",
    "section": "\n67.4 Analisi frequentista: dimensione del campione per potenza dell’80%",
    "text": "67.4 Analisi frequentista: dimensione del campione per potenza dell’80%\nPer stimare la dimensione del campione necessaria a ottenere una potenza dell’80% in un confronto tra due gruppi indipendenti (con varianza uguale), possiamo usare la funzione power.t.test() disponibile in R.\nNel nostro esempio ipotizziamo:\n\nuna differenza attesa tra i gruppi pari a \\(\\Delta = 5\\),\nuna deviazione standard comune pari a \\(\\sigma = 10\\),\nun test bilaterale con livello di significatività \\(\\alpha = 0.05\\).\n\n\n67.4.1 Calcolo in R\n\n# Calcolo della dimensione campionaria necessaria per 80% di potenza\npower.t.test(\n  delta = 5,        # differenza attesa tra le medie\n  sd    = 10,       # deviazione standard\n  power = 0.8,      # potenza desiderata\n  sig.level = 0.05, # livello di significatività\n  type = \"two.sample\",\n  alternative = \"two.sided\"\n)\n#&gt; \n#&gt;      Two-sample t test power calculation \n#&gt; \n#&gt;               n = 63.77\n#&gt;           delta = 5\n#&gt;              sd = 10\n#&gt;       sig.level = 0.05\n#&gt;           power = 0.8\n#&gt;     alternative = two.sided\n#&gt; \n#&gt; NOTE: n is number in *each* group\n\nIl risultato indica che sono necessari circa 64 partecipanti per gruppo per ottenere l’80% di potenza con questi parametri. Tuttavia, come vedremo nella sezione successiva, questo valore non garantisce necessariamente che la stima dell’effetto sarà sufficientemente precisa o utile dal punto di vista decisionale. L’analisi bayesiana ci offrirà uno strumento più flessibile per valutare l’informatività del disegno proposto.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Pianificazione della dimensione campionaria</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_sample_size.html#analisi-bayesiana-informatività-a-posteriori",
    "href": "chapters/linear_models/08_sample_size.html#analisi-bayesiana-informatività-a-posteriori",
    "title": "67  Pianificazione della dimensione campionaria",
    "section": "\n67.5 Analisi bayesiana: informatività a posteriori",
    "text": "67.5 Analisi bayesiana: informatività a posteriori\nNell’approccio bayesiano, non ci si chiede se l’effetto è “significativo” rispetto a una soglia arbitraria, ma quanto è informativo il risultato per prendere decisioni pratiche. In questo contesto, pianificare uno studio significa domandarsi:\n“Con quanti dati il mio modello bayesiano riuscirà a fornire una stima sufficientemente precisa e utile dell’effetto?”\nPer rispondere, possiamo stabilire dei criteri di informatività che riflettano le esigenze del nostro problema. Due criteri possibili sono:\n\nl’intervallo di credibilità all’89% per Cohen’s d ha larghezza ≤ 0.4 (criterio di precisione);\nla probabilità a posteriori che d &gt; 0.3 è ≥ 90% (criterio di utilità pratica).\n\n\n67.5.1 Simulazione generativa di uno studio\nPer verificare se un disegno sperimentale con \\(n = 64\\) per gruppo soddisfa questi criteri, possiamo simulare uno studio 100 volte, ogni volta:\n\ngenerando nuovi dati,\nstimando un modello bayesiano,\nvalutando se il risultato è sufficientemente informativo.\n\nDi seguito definiamo la funzione sim_once() che esegue una singola simulazione.\n\n# Funzione per standardizzare su scala z\nstandardise &lt;- function(x) (x - mean(x)) / sd(x)\n\n# Una singola simulazione bayesiana di uno studio\nsim_once &lt;- function(n = 64, mu0 = 100, delta = 5, sigma = 10) {\n\n  # 1. Generazione dei dati\n  y0 &lt;- rnorm(n, mu0, sigma)         # gruppo controllo\n  y1 &lt;- rnorm(n, mu0 + delta, sigma) # gruppo trattamento\n\n  # 2. Standardizzazione\n  dat &lt;- tibble(score = standardise(c(y0, y1)),\n                group = factor(rep(c(\"ctrl\", \"trt\"), each = n)))\n\n  # 3. Stima del modello bayesiano\n  fit &lt;- brm(score ~ group,\n             data = dat,\n             backend = \"cmdstanr\",\n             chains = 2, iter = 1000, warmup = 500,\n             refresh = 0, silent = 0,\n             prior = c(\n               prior(normal(0, 2), class = \"b\"),\n               prior(exponential(2), class = \"sigma\")\n             ))\n\n  # 4. Estrazione dei campioni posteriori e calcolo di Cohen's d\n  post &lt;- as_draws_df(fit)\n  d_smp &lt;- post$b_grouptrt / post$sigma\n\n  # 5. Output: due indici di informatività\n  tibble(\n    CIw89  = diff(quantile(d_smp, c(.055, .945))),  # larghezza IC 89%\n    p_gt03 = mean(d_smp &gt; 0.3)                      # P(d &gt; 0.3)\n  )\n}\n\nEcco cosa succede passo passo:\n\nSimulazione dei dati\n\n  y0 &lt;- rnorm(n, mu0, sigma)\n  y1 &lt;- rnorm(n, mu0 + delta, sigma)\n\n\nSi generano due gruppi di n = 64 osservazioni:\n\nIl gruppo di controllo ha media mu0 = 100.\nIl gruppo trattamento ha media aumentata di delta = 5.\nEntrambi i gruppi hanno la stessa variabilità (sigma = 10).\n\n\nIn pratica: simula un esperimento in cui il trattamento ha un effetto medio di 5 unità.\n\n\nStandardizzazione dei dati\n\n  score = standardise(c(y0, y1))\n\nLe osservazioni dei due gruppi vengono unite e standardizzate (portate su scala z): media = 0, deviazione standard = 1.\n\nQuesto serve a:\n\nrendere i dati comparabili tra simulazioni,\nsemplificare l’interpretazione dei risultati (si lavora su scala standardizzata).\n\n\n\n\nCreazione del dataset\n\n  dat &lt;- tibble(score = ..., group = ...)\n\n\nSi crea una tabella con le variabili:\n\nscore: i dati standardizzati\ngroup: un’etichetta che indica se il dato appartiene al gruppo controllo (ctrl) o trattamento (trt).\n\n\n\n\nStima del modello bayesiano\n\n  fit &lt;- brm(score ~ group, ...)\n\n\nSi stima un modello bayesiano con brms, dove:\n\nla variabile score è prevista dalla variabile group,\nsi usano priori debolmente informativi su effetto (b) e variabilità (sigma).\n\n\nIl coefficiente b_grouptrt stima la differenza media tra i gruppi (sulla scala standardizzata).\n\n\nEstrazione dei campioni posteriori\n\n  post &lt;- as_draws_df(fit)\n  d_smp &lt;- post$b_grouptrt / post$sigma\n\nSi estraggono i campioni dalla distribuzione a posteriori.\nSi calcola Cohen’s d a posteriori dividendo l’effetto stimato per la deviazione standard stimata: d_smp.\n\n\nOutput: due indicatori di informatività\n\n  tibble(\n    CIw89  = diff(quantile(d_smp, c(.055, .945))),\n    p_gt03 = mean(d_smp &gt; 0.3)\n  )\n\n\nCIw89: larghezza dell’intervallo di credibilità all’89% → misura di precisione.\n\np_gt03: proporzione dei campioni a posteriori in cui d &gt; 0.3 → misura di utilità pratica.\n\nIn sintesi, ogni volta che chiami sim_once():\n\nsimuli un nuovo dataset realistico;\nstimi l’effetto del trattamento con un modello bayesiano;\nmisuri quanto è preciso e informativo il risultato.\n\nQuesta funzione è il mattone fondamentale per la simulazione generativa di uno studio: ti permette di verificare, ad esempio, se con n = 64 per gruppo riesci a stimare d in modo sufficientemente utile.\n\n67.5.2 Esecuzione della simulazione\nSimuliamo 100 studi indipendenti con n = 64 per gruppo:\n\nset.seed(123)\nres &lt;- bind_rows(replicate(100, sim_once(), simplify = FALSE))\n\nEsaminiamo i risultati della simulazione:\n\nresum &lt;- summarise(res,\n  mean_CI   = mean(CIw89),\n  sd_CI     = sd(CIw89),\n  prop_good = mean(p_gt03 &gt;= 0.9)\n)\nprint(resum)\n#&gt; # A tibble: 1 × 3\n#&gt;   mean_CI  sd_CI prop_good\n#&gt;     &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1   0.569 0.0206      0.35\n\n\n67.5.3 Visualizzazione dei risultati\nIl primo grafico mostra la distribuzione delle larghezze degli intervalli di credibilità all’89%, evidenziando quante simulazioni superano la soglia di 0.4. Il secondo mostra quante simulazioni soddisfano il criterio di utilità.\n\n# Grafico 1: distribuzione della larghezza IC89\nggplot(res, aes(x = CIw89)) +\n  geom_histogram(binwidth = 0.02, fill = \"#69b3a2\", color = \"white\") +\n  geom_vline(xintercept = 0.4, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Distribuzione della larghezza\\ndell'intervallo di credibilità (89%)\",\n    x = \"Larghezza IC89\",\n    y = \"Frequenza\"\n  ) \n\n\n\n\n\n\n\n\n# Grafico 2: classificazione delle simulazioni utili/non utili\nggplot(res, aes(x = p_gt03 &gt;= 0.9)) +\n  geom_bar(fill = \"#404080\") +\n  scale_x_discrete(labels = c(\"FALSE\" = \"Non utile\", \"TRUE\" = \"Utile\")) +\n  labs(\n    title = \"Numero di simulazioni che superano\\nil criterio di utilità\",\n    x = \"Criterio: P(d &gt; 0.3) ≥ 0.9\",\n    y = \"Numero di simulazioni\"\n  ) \n\n\n\n\n\n\n\n\n67.5.4 Interpretazione dei risultati\n\n\nmean_CI rappresenta la larghezza media dell’intervallo di credibilità all’89%. Nel nostro caso è circa 0.569, quindi troppo ampio per considerare la stima precisa.\n\nprop_good è la proporzione di simulazioni in cui l’evidenza a favore di un effetto pratico d &gt; 0.3 supera il 90%. Con prop_good = 0.1, solo 1 simulazione su 10 soddisfa questo criterio.\n\nConclusione: con n = 64 per gruppo, lo studio simulato è sottodimensionato: raramente produce una stima precisa e utile. Serve un campione più grande (es. n = 80 o n = 100) per raggiungere criteri più severi di informatività.\n\n67.5.5 Confronto con la potenza frequentista\nSecondo l’approccio frequentista, n = 64 per gruppo garantisce circa 80% di potenza per d = 0.5. Ma la simulazione bayesiana mostra che:\n\nl’intervallo di credibilità risulta troppo ampio (≈ 0.57);\nl’evidenza utile (P(d &gt; 0.3) ≥ 0.9) si verifica solo nel 10% dei casi.\n\nQuesto evidenzia i limiti della potenza come unico criterio per pianificare gli studi. Anche uno studio “con potenza adeguata” potrebbe produrre risultati imprecisi o non praticabili, e contribuire agli errori di tipo M (esagerazione della stima) o S (errore nel segno dell’effetto).\nIn sintesi, pianificare uno studio non significa garantire il p &lt; .05, ma garantire che la stima sia abbastanza precisa e utile per informare decisioni.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Pianificazione della dimensione campionaria</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_sample_size.html#confronto-diretto",
    "href": "chapters/linear_models/08_sample_size.html#confronto-diretto",
    "title": "67  Pianificazione della dimensione campionaria",
    "section": "\n67.6 Confronto diretto",
    "text": "67.6 Confronto diretto\n\n\n\n\n\n\n\n\nn per gruppo\nPotenza (frequentista)\nCriterio 1 (IC89 \\(\\leq 0.4\\))\nCriterio 2 (P(d &gt; 0.3) \\(\\geq 0.9\\))\n\n\n\n64\n0.80\nNo\n0.33\n\n\n100\n0.93\nSì\n0.77",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Pianificazione della dimensione campionaria</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_sample_size.html#riflessioni-conclusive",
    "href": "chapters/linear_models/08_sample_size.html#riflessioni-conclusive",
    "title": "67  Pianificazione della dimensione campionaria",
    "section": "\n67.6 Riflessioni Conclusive",
    "text": "67.6 Riflessioni Conclusive\n\nL’approccio bayesiano consente di valutare in modo più trasparente quanto i risultati previsti saranno precisi e utili.\nAnche se un disegno ha potenza dell’80%, potrebbe non produrre stime sufficientemente informative.\nLa simulazione bayesiana è uno strumento efficace per esplorare scenari realistici prima di raccogliere dati.\n\nBuona pratica: non fermarti al calcolo della potenza. Definisci criteri di utilità, simula gli studi e verifica se i dati attesi permetteranno davvero di rispondere alla tua domanda.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Pianificazione della dimensione campionaria</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_sample_size.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/08_sample_size.html#informazioni-sullambiente-di-sviluppo",
    "title": "67  Pianificazione della dimensione campionaria",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] cmdstanr_0.9.0   brms_2.22.0      Rcpp_1.0.14      mice_3.17.0     \n#&gt;  [5] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [9] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.12.0 psych_2.5.3     \n#&gt; [13] scales_1.4.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [17] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [21] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.2   \n#&gt; [25] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] Rdpack_2.6.4         mnormt_2.1.1         inline_0.3.21       \n#&gt;  [4] rlang_1.1.6          magrittr_2.0.3       matrixStats_1.5.0   \n#&gt;  [7] compiler_4.5.0       loo_2.8.0            vctrs_0.6.5         \n#&gt; [10] pkgconfig_2.0.3      shape_1.4.6.1        fastmap_1.2.0       \n#&gt; [13] backports_1.5.0      labeling_0.4.3       rmarkdown_2.29      \n#&gt; [16] tzdb_0.5.0           ps_1.9.1             nloptr_2.2.1        \n#&gt; [19] xfun_0.52            glmnet_4.1-8         jomo_2.7-6          \n#&gt; [22] jsonlite_2.0.0       pan_1.9              broom_1.0.8         \n#&gt; [25] parallel_4.5.0       R6_2.6.1             StanHeaders_2.32.10 \n#&gt; [28] stringi_1.8.7        RColorBrewer_1.1-3   boot_1.3-31         \n#&gt; [31] rpart_4.1.24         estimability_1.5.1   rstan_2.32.7        \n#&gt; [34] iterators_1.0.14     pacman_0.5.1         Matrix_1.7-3        \n#&gt; [37] splines_4.5.0        nnet_7.3-20          timechange_0.3.0    \n#&gt; [40] tidyselect_1.2.1     rstudioapi_0.17.1    abind_1.4-8         \n#&gt; [43] yaml_2.3.10          codetools_0.2-20     curl_6.2.2          \n#&gt; [46] processx_3.8.6       pkgbuild_1.4.7       lattice_0.22-7      \n#&gt; [49] withr_3.0.2          bridgesampling_1.1-2 posterior_1.6.1     \n#&gt; [52] coda_0.19-4.1        evaluate_1.0.3       survival_3.8-3      \n#&gt; [55] RcppParallel_5.1.10  pillar_1.10.2        tensorA_0.36.2.1    \n#&gt; [58] stats4_4.5.0         checkmate_2.3.2      foreach_1.5.2       \n#&gt; [61] reformulas_0.4.1     distributional_0.5.0 generics_0.1.4      \n#&gt; [64] rprojroot_2.0.4      hms_1.1.3            rstantools_2.4.0    \n#&gt; [67] minqa_1.2.8          xtable_1.8-4         glue_1.8.0          \n#&gt; [70] emmeans_1.11.1       tools_4.5.0          data.table_1.17.2   \n#&gt; [73] lme4_1.1-37          mvtnorm_1.3-3        grid_4.5.0          \n#&gt; [76] QuickJSR_1.7.0       rbibutils_2.3        colorspace_2.1-1    \n#&gt; [79] nlme_3.1-168         cli_3.6.5            Brobdingnag_1.2-9   \n#&gt; [82] V8_6.0.3             gtable_0.3.6         digest_0.6.37       \n#&gt; [85] htmlwidgets_1.6.4    farver_2.1.2         htmltools_0.5.8.1   \n#&gt; [88] lifecycle_1.0.4      mitml_0.4-5          MASS_7.3-65",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Pianificazione della dimensione campionaria</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_sample_size.html#bibliografia",
    "href": "chapters/linear_models/08_sample_size.html#bibliografia",
    "title": "67  Pianificazione della dimensione campionaria",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., & Carlin, J. (2014). Beyond Power Calculations: Assessing Type S (Sign) and Type M (Magnitude) Errors. Perspectives on Psychological Science, 9(6), 641–651.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Pianificazione della dimensione campionaria</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html",
    "href": "chapters/linear_models/09_anova_1via.html",
    "title": "68  ANOVA ad una via",
    "section": "",
    "text": "68.1 Preparazione del Notebook\nhere::here(\"code\", \"_common.R\") |&gt; \n  source()\n\n# Load packages\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(cmdstanr, posterior, bayestestR, brms, emmeans)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#introduzione",
    "href": "chapters/linear_models/09_anova_1via.html#introduzione",
    "title": "68  ANOVA ad una via",
    "section": "\n68.2 Introduzione",
    "text": "68.2 Introduzione\nNel Capitolo 65 ci siamo concentrati sul confronto tra due gruppi utilizzando una regressione lineare con variabili dummy. Questo approccio ci ha permesso di modellare in modo semplice l’effetto di un fattore binario e di stimare con incertezza l’ampiezza della differenza. Ora estendiamo quella logica al caso in cui il fattore abbia più di due livelli.\nQuesto passaggio ci introduce al cuore dell’ANOVA a una via, che non è altro che un modello lineare con un fattore categoriale a \\(k\\) livelli. In questo contesto, ci interessa capire quanta variabilità nei dati può essere attribuita alle differenze tra gruppi, e quanto invece rimane all’interno dei gruppi stessi. Come sempre in questo manuale, manterremo una lettura orientata all’incertezza e alla variabilità intra- e inter-individuale, trattando l’inferenza come uno strumento per quantificare la credibilità delle ipotesi.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#simulazione",
    "href": "chapters/linear_models/09_anova_1via.html#simulazione",
    "title": "68  ANOVA ad una via",
    "section": "\n68.4 Simulazione",
    "text": "68.4 Simulazione\nSimuliamo un esperimento con tre condizioni: controllo, psicoterapia1 e psicoterapia2. Ogni gruppo ha una media diversa ma la stessa deviazione standard. Ci interessa modellare la variabilità tra le condizioni e interpretare le differenze in modo probabilistico.\n\nset.seed(123)\n\nn &lt;- 30  # numero di osservazioni per gruppo\n# Medie di ciascun gruppo\nmean_control &lt;- 30\nmean_psico1  &lt;- 25\nmean_psico2  &lt;- 20\n# Deviazione standard comune\nsd_value &lt;- 5\n\n# Generazione dei dati\ncontrollo     &lt;- rnorm(n, mean_control, sd_value)\npsicoterapia1 &lt;- rnorm(n, mean_psico1,  sd_value)\npsicoterapia2 &lt;- rnorm(n, mean_psico2,  sd_value)\n\n# Creazione del data frame\ndf &lt;- data.frame(\n  condizione = rep(c(\"controllo\", \"psicoterapia1\", \"psicoterapia2\"), each = n),\n  punteggio  = c(controllo, psicoterapia1, psicoterapia2)\n)\n\ndf |&gt; head()\n#&gt;   condizione punteggio\n#&gt; 1  controllo     27.20\n#&gt; 2  controllo     28.85\n#&gt; 3  controllo     37.79\n#&gt; 4  controllo     30.35\n#&gt; 5  controllo     30.65\n#&gt; 6  controllo     38.58\n\n\n68.4.1 Esplorazione iniziale\nVisualizziamo le distribuzioni dei punteggi:\n\nggplot(df, aes(x = condizione, y = punteggio, fill = condizione)) +\n  geom_violin(trim = FALSE) +\n  geom_boxplot(width = 0.2, outlier.shape = NA) +\n  labs(\n    title = \"Distribuzione dei punteggi di depressione per gruppo\",\n    x = \"Condizione sperimentale\",\n    y = \"Punteggio di depressione\"\n  ) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\nCalcoliamo media e deviazione standard per ogni gruppo:\n\ndf |&gt; \n  group_by(condizione) |&gt; \n  summarize(\n    media = mean(punteggio),\n    sd = sd(punteggio)\n  )\n#&gt; # A tibble: 3 × 3\n#&gt;   condizione    media    sd\n#&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 controllo      29.8  4.91\n#&gt; 2 psicoterapia1  25.9  4.18\n#&gt; 3 psicoterapia2  20.1  4.35",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#codifica-con-variabili-dummy",
    "href": "chapters/linear_models/09_anova_1via.html#codifica-con-variabili-dummy",
    "title": "68  ANOVA ad una via",
    "section": "\n68.4 Codifica con variabili dummy",
    "text": "68.4 Codifica con variabili dummy\nConvertiamo condizione in fattore e definiamo controllo come categoria di riferimento:\n\ndf$condizione &lt;- factor(df$condizione)\ndf$condizione &lt;- relevel(df$condizione, ref = \"controllo\")\ncontrasts(df$condizione)\n#&gt;               psicoterapia1 psicoterapia2\n#&gt; controllo                 0             0\n#&gt; psicoterapia1             1             0\n#&gt; psicoterapia2             0             1\n\nIl modello di regressione con dummy sarà:\n\\[\nY_i = \\beta_0 + \\beta_1 \\cdot \\text{psicoterapia1}_i + \\beta_2 \\cdot \\text{psicoterapia2}_i + \\varepsilon_i,\n\\]\ndove:\n\n\n\\(\\beta_0\\) è la media del gruppo di controllo;\n\n\\(\\beta_1\\) e \\(\\beta_2\\) sono le differenze tra le rispettive psicoterapie e il gruppo di controllo.\n\n\n68.4.1 Stima del modello\nEseguiamo una prima analisi usando il metodo di massima verosimiglianza:\n\nfm1 &lt;- lm(punteggio ~ condizione, data = df)\n\n\nsummary(fm1)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = punteggio ~ condizione, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -11.668  -2.620  -0.183   2.681  10.128 \n#&gt; \n#&gt; Coefficients:\n#&gt;                         Estimate Std. Error t value Pr(&gt;|t|)\n#&gt; (Intercept)               29.764      0.819   36.33  &lt; 2e-16\n#&gt; condizionepsicoterapia1   -3.873      1.159   -3.34   0.0012\n#&gt; condizionepsicoterapia2   -9.642      1.159   -8.32  1.1e-12\n#&gt; \n#&gt; Residual standard error: 4.49 on 87 degrees of freedom\n#&gt; Multiple R-squared:  0.446,  Adjusted R-squared:  0.434 \n#&gt; F-statistic: 35.1 on 2 and 87 DF,  p-value: 6.75e-12\n\nVerifica delle medie e differenze tra gruppi:\n\nout &lt;- tapply(df$punteggio, df$condizione, mean)\nout[2] - out[1]  # psicoterapia1 - controllo\n#&gt; psicoterapia1 \n#&gt;        -3.873\nout[3] - out[1]  # psicoterapia2 - controllo\n#&gt; psicoterapia2 \n#&gt;        -9.642",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#contrasti-personalizzati",
    "href": "chapters/linear_models/09_anova_1via.html#contrasti-personalizzati",
    "title": "68  ANOVA ad una via",
    "section": "\n68.6 Contrasti personalizzati",
    "text": "68.6 Contrasti personalizzati\nI contrasti ci permettono di andare oltre il test globale e formulare ipotesi teoriche mirate. Ad esempio:\n\nla media del gruppo controllo è diversa dalla media delle due psicoterapie?\nle due psicoterapie differiscono tra loro?\n\nA questo fine, specifichiamo la seguente matrice dei contrasti:\n\nmy_contrasts &lt;- matrix(c(\n  0.6667,  0,     # controllo\n -0.3333,  0.5,   # psicoterapia1\n -0.3333, -0.5    # psicoterapia2\n), ncol = 2, byrow = TRUE)\n\ncolnames(my_contrasts) &lt;- c(\"Ctrl_vs_PsicoMean\", \"P1_vs_P2\")\nrownames(my_contrasts) &lt;- c(\"controllo\", \"psicoterapia1\", \"psicoterapia2\")\n\ncontrasts(df$condizione) &lt;- my_contrasts\n\nAdattiamo il modello:\n\nmod_custom &lt;- lm(punteggio ~ condizione, data = df)\n\nEsaminiamo i coefficienti:\n\nsummary(mod_custom)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = punteggio ~ condizione, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -11.668  -2.620  -0.183   2.681  10.128 \n#&gt; \n#&gt; Coefficients:\n#&gt;                             Estimate Std. Error t value Pr(&gt;|t|)\n#&gt; (Intercept)                   25.259      0.473   53.40  &lt; 2e-16\n#&gt; condizioneCtrl_vs_PsicoMean    6.758      1.003    6.73  1.7e-09\n#&gt; condizioneP1_vs_P2             5.770      1.159    4.98  3.2e-06\n#&gt; \n#&gt; Residual standard error: 4.49 on 87 degrees of freedom\n#&gt; Multiple R-squared:  0.446,  Adjusted R-squared:  0.434 \n#&gt; F-statistic: 35.1 on 2 and 87 DF,  p-value: 6.75e-12\n\nInterpretazione dei coefficienti:\n\n\nIntercetta: non rappresenta più una singola media, ma una combinazione lineare dei gruppi.\n\nCtrl_vs_PsicoMean: confronta la media di controllo con la media combinata delle due psicoterapie.\n\nP1_vs_P2: differenza tra le due psicoterapie.\n\nVerifica manuale:\n\n# Controllo - media delle psicoterapie\nout[1] - (out[2] + out[3]) / 2\n#&gt; controllo \n#&gt;     6.758\n\n\n# Psicoterapia1 - Psicoterapia2\nout[2] - out[3]\n#&gt; psicoterapia1 \n#&gt;          5.77",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#interpretazione-dei-coefficienti",
    "href": "chapters/linear_models/09_anova_1via.html#interpretazione-dei-coefficienti",
    "title": "68  ANOVA ad una via",
    "section": "\n68.6 Interpretazione dei coefficienti",
    "text": "68.6 Interpretazione dei coefficienti\n\n\nIntercetta: non rappresenta più una singola media, ma una combinazione lineare dei gruppi.\n\nCtrl_vs_PsicoMean: confronta la media di controllo con la media combinata delle due psicoterapie.\n\nP1_vs_P2: differenza tra le due psicoterapie.\n\nVerifica manuale:\n\n# Controllo - media delle psicoterapie\nout[1] - (out[2] + out[3]) / 2\n#&gt; controllo \n#&gt;     6.758\n\n\n# Psicoterapia1 - Psicoterapia2\nout[2] - out[3]\n#&gt; psicoterapia1 \n#&gt;          5.77",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#uso-del-pacchetto-emmeans",
    "href": "chapters/linear_models/09_anova_1via.html#uso-del-pacchetto-emmeans",
    "title": "68  ANOVA ad una via",
    "section": "\n68.7 Uso del pacchetto emmeans\n",
    "text": "68.7 Uso del pacchetto emmeans\n\nIl pacchetto emmeans consente di ottenere gli stessi risultati in modo più diretto e modulare.\n\n68.7.1 Stima con brms\n\nUsiamo ora emmeans con brms:\n\nmod &lt;- brm(punteggio ~ condizione, data = df, backend = \"cmdstanr\")\n\n\nsummary(mod)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: punteggio ~ condizione \n#&gt;    Data: df (Number of observations: 90) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;                             Estimate Est.Error l-95% CI u-95% CI Rhat\n#&gt; Intercept                      25.26      0.48    24.33    26.15 1.00\n#&gt; condizioneCtrl_vs_PsicoMean     6.78      1.04     4.73     8.85 1.00\n#&gt; condizioneP1_vs_P2              5.76      1.16     3.49     8.08 1.00\n#&gt;                             Bulk_ESS Tail_ESS\n#&gt; Intercept                       4321     2937\n#&gt; condizioneCtrl_vs_PsicoMean     4260     2964\n#&gt; condizioneP1_vs_P2              4598     2785\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     4.54      0.34     3.93     5.26 1.00     4287     3279\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n68.7.2 Calcolo delle medie marginali\n\nem &lt;- emmeans(mod, specs = \"condizione\")\nem\n#&gt;  condizione    emmean lower.HPD upper.HPD\n#&gt;  controllo       29.8      28.1      31.4\n#&gt;  psicoterapia1   25.9      24.3      27.5\n#&gt;  psicoterapia2   20.1      18.4      21.7\n#&gt; \n#&gt; Point estimate displayed: median \n#&gt; HPD interval probability: 0.95\n\n\n68.7.3 Confronti tra gruppi\n\npairs(em)  # confronti a coppie\n#&gt;  contrast                      estimate lower.HPD upper.HPD\n#&gt;  controllo - psicoterapia1         3.90      1.70      6.21\n#&gt;  controllo - psicoterapia2         9.65      7.31     12.03\n#&gt;  psicoterapia1 - psicoterapia2     5.75      3.57      8.14\n#&gt; \n#&gt; Point estimate displayed: median \n#&gt; HPD interval probability: 0.95\n\n\n68.7.4 Contrasti personalizzati con emmeans\n\n\nmy_list &lt;- list(\n  \"Ctrl_vs_PsicoMean\" = c(\n    \"controllo\" = 1, \"psicoterapia1\" = -0.5, \"psicoterapia2\" = -0.5\n  ),\n  \"P1_vs_P2\" = c(\n    \"controllo\" = 0, \"psicoterapia1\" = 1, \"psicoterapia2\" = -1\n  )\n)\n\n\ncontrast(em, method = my_list)\n#&gt;  contrast          estimate lower.HPD upper.HPD\n#&gt;  Ctrl_vs_PsicoMean     6.77      4.77      8.88\n#&gt;  P1_vs_P2              5.75      3.57      8.14\n#&gt; \n#&gt; Point estimate displayed: median \n#&gt; HPD interval probability: 0.95\n\n\n# Visualizzazione\nplot(em)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#riflessioni-conclusive",
    "href": "chapters/linear_models/09_anova_1via.html#riflessioni-conclusive",
    "title": "68  ANOVA ad una via",
    "section": "\n68.8 Riflessioni Conclusive",
    "text": "68.8 Riflessioni Conclusive\nL’ANOVA a una via è un esempio fondamentale di come un modello lineare possa rappresentare la variabilità tra gruppi. Tuttavia, il suo valore non sta nel test globale, ma nella possibilità di analizzare differenze mirate tra medie.\nAttraverso contrasti personalizzati, possiamo porre domande teoriche precise e ottenere risposte in termini di effetti stimati con incertezza. Questo approccio si integra naturalmente con la prospettiva bayesiana, che ci permette di esprimere la probabilità che una certa differenza superi una soglia di interesse pratico.\nIl pacchetto emmeans (insieme a brms) consente di navigare questa complessità in modo modulare e trasparente, producendo stime interpretabili e inference compatibili con i nostri modelli teorici. L’obiettivo non è semplicemente sapere se c’è una differenza, ma capire quanto, con quale incertezza e tra chi.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/09_anova_1via.html#informazioni-sullambiente-di-sviluppo",
    "title": "68  ANOVA ad una via",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] emmeans_1.11.1    brms_2.22.0       Rcpp_1.0.14       bayestestR_0.16.0\n#&gt;  [5] posterior_1.6.1   cmdstanr_0.9.0    thematic_0.1.6    MetBrewer_0.2.0  \n#&gt;  [9] ggokabeito_0.1.0  see_0.11.0        gridExtra_2.3     patchwork_1.3.0  \n#&gt; [13] bayesplot_1.12.0  psych_2.5.3       scales_1.4.0      markdown_2.0     \n#&gt; [17] knitr_1.50        lubridate_1.9.4   forcats_1.0.0     stringr_1.5.1    \n#&gt; [21] dplyr_1.1.4       purrr_1.0.4       readr_2.1.5       tidyr_1.3.1      \n#&gt; [25] tibble_3.2.1      ggplot2_3.5.2     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [29] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1     farver_2.1.2         loo_2.8.0           \n#&gt;  [4] fastmap_1.2.0        tensorA_0.36.2.1     pacman_0.5.1        \n#&gt;  [7] digest_0.6.37        timechange_0.3.0     estimability_1.5.1  \n#&gt; [10] lifecycle_1.0.4      StanHeaders_2.32.10  processx_3.8.6      \n#&gt; [13] magrittr_2.0.3       compiler_4.5.0       rlang_1.1.6         \n#&gt; [16] tools_4.5.0          utf8_1.2.5           yaml_2.3.10         \n#&gt; [19] data.table_1.17.2    labeling_0.4.3       bridgesampling_1.1-2\n#&gt; [22] htmlwidgets_1.6.4    curl_6.2.2           pkgbuild_1.4.7      \n#&gt; [25] mnormt_2.1.1         plyr_1.8.9           RColorBrewer_1.1-3  \n#&gt; [28] abind_1.4-8          withr_3.0.2          grid_4.5.0          \n#&gt; [31] stats4_4.5.0         colorspace_2.1-1     xtable_1.8-4        \n#&gt; [34] inline_0.3.21        insight_1.3.0        cli_3.6.5           \n#&gt; [37] mvtnorm_1.3-3        rmarkdown_2.29       generics_0.1.4      \n#&gt; [40] RcppParallel_5.1.10  rstudioapi_0.17.1    reshape2_1.4.4      \n#&gt; [43] tzdb_0.5.0           rstan_2.32.7         parallel_4.5.0      \n#&gt; [46] matrixStats_1.5.0    vctrs_0.6.5          V8_6.0.3            \n#&gt; [49] Matrix_1.7-3         jsonlite_2.0.0       hms_1.1.3           \n#&gt; [52] glue_1.8.0           codetools_0.2-20     ps_1.9.1            \n#&gt; [55] distributional_0.5.0 stringi_1.8.7        gtable_0.3.6        \n#&gt; [58] QuickJSR_1.7.0       pillar_1.10.2        htmltools_0.5.8.1   \n#&gt; [61] Brobdingnag_1.2-9    R6_2.6.1             rprojroot_2.0.4     \n#&gt; [64] evaluate_1.0.3       lattice_0.22-7       backports_1.5.0     \n#&gt; [67] rstantools_2.4.0     coda_0.19-4.1        nlme_3.1-168        \n#&gt; [70] checkmate_2.3.2      xfun_0.52            pkgconfig_2.0.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#bibliografia",
    "href": "chapters/linear_models/09_anova_1via.html#bibliografia",
    "title": "68  ANOVA ad una via",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_2vie.html",
    "href": "chapters/linear_models/10_anova_2vie.html",
    "title": "69  ANOVA ad due vie",
    "section": "",
    "text": "69.1 Introduzione\nL’ANOVA a due vie estende il modello dell’ANOVA a una via alla situazione in cui la variabile dipendente è influenzata da due fattori distinti, ciascuno con due o più livelli. Questa estensione consente di analizzare non solo gli effetti principali di ciascun fattore, ma anche l’interazione tra i due.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_2vie.html#introduzione",
    "href": "chapters/linear_models/10_anova_2vie.html#introduzione",
    "title": "69  ANOVA ad due vie",
    "section": "",
    "text": "69.1.1 Medie di popolazione in una classificazione a due vie\nSupponiamo di conoscere le medie di popolazione per ciascuna combinazione dei livelli dei due fattori. La struttura può essere rappresentata in una tabella come la seguente:\n\n\n\n\n\n\n\n\n\n\n\n\\(C_1\\)\n\\(C_2\\)\n\\(\\dots\\)\n\\(C_c\\)\nMedia riga\n\n\n\n\\(R_1\\)\n\\(\\mu_{11}\\)\n\\(\\mu_{12}\\)\n\\(\\dots\\)\n\\(\\mu_{1c}\\)\n\\(\\mu_{1\\cdot}\\)\n\n\n\\(R_2\\)\n\\(\\mu_{21}\\)\n\\(\\mu_{22}\\)\n\\(\\dots\\)\n\\(\\mu_{2c}\\)\n\\(\\mu_{2\\cdot}\\)\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\ddots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\\(R_r\\)\n\\(\\mu_{r1}\\)\n\\(\\mu_{r2}\\)\n\\(\\dots\\)\n\\(\\mu_{rc}\\)\n\\(\\mu_{r\\cdot}\\)\n\n\nMedia colonna\n\\(\\mu_{\\cdot 1}\\)\n\\(\\mu_{\\cdot 2}\\)\n\\(\\dots\\)\n\\(\\mu_{\\cdot c}\\)\n\\(\\mu_{\\cdot\\cdot}\\)\n\n\n\ndove:\n\n\n\\(µ_{jk}\\) è la media della cella per il livello \\(j\\) del fattore R e \\(k\\) del fattore C.\n\n\\(µ_{j:}\\) è la media marginale per la riga \\(j\\).\n\n\\(µ_{:k}\\) è la media marginale per la colonna \\(k\\).\n\n\\(µ_{::}\\) è la media complessiva.\n\n69.1.2 Effetti principali e interazione\nSe non c’è interazione tra i due fattori, la differenza tra livelli di un fattore è costante a prescindere dal livello dell’altro fattore. In altre parole, le differenze tra medie di cella si riflettono esattamente nelle differenze tra le medie marginali.\nAd esempio, se il fattore R non interagisce con il fattore C, allora:\n\\[\nµ_{j1} - µ_{j'1} = µ_{j2} - µ_{j'2} = ... = µ_{j:} - µ_{j':}\n\\]\nQuando i profili delle medie sono paralleli, l’assenza di interazione è facilmente visibile. L’interazione si manifesta quando le differenze tra livelli di un fattore variano al variare dell’altro fattore.\nL’interazione è simmetrica: se R interagisce con C, allora C interagisce con R. Se invece non vi è interazione, gli effetti principali dei fattori corrispondono alle differenze tra le rispettive medie marginali.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_2vie.html#simulazione",
    "href": "chapters/linear_models/10_anova_2vie.html#simulazione",
    "title": "69  ANOVA ad due vie",
    "section": "\n69.2 Simulazione",
    "text": "69.2 Simulazione\nSimuliamo ora un dataset che rispecchi una struttura a due vie. Consideriamo:\n\nfattore 1: condizione (controllo, psicoterapia1, psicoterapia2)\nfattore 2: gravita (molto_gravi, poco_gravi)\n\nImpostiamo le medie di cella in modo che riflettano sia effetti principali sia un’interazione.\n\nset.seed(123)\nn &lt;- 30\ncondizione &lt;- c(\"controllo\", \"psicoterapia1\", \"psicoterapia2\")\ngravita &lt;- c(\"molto_gravi\", \"poco_gravi\")\nsd_value &lt;- 5\n\nmean_table &lt;- matrix(\n  c(30, 25, 20,\n    25, 20, 15),\n  nrow = 2, byrow = TRUE\n)\n\ndf &lt;- data.frame()\n\nfor (i in seq_along(gravita)) {\n  for (j in seq_along(condizione)) {\n    media &lt;- mean_table[i, j]\n    dati &lt;- rnorm(n, mean = media, sd = sd_value)\n    df &lt;- rbind(df, data.frame(\n      gravita = gravita[i],\n      condizione = condizione[j],\n      punteggio = dati\n    ))\n  }\n}\n\nVisualizziamo i dati:\n\nggplot(df, aes(x = condizione, y = punteggio, fill = gravita)) +\n  geom_boxplot(position = position_dodge()) +\n  labs(title = \"Distribuzione dei punteggi per gravita e condizione\")",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_2vie.html#modellazione-bayesiana",
    "href": "chapters/linear_models/10_anova_2vie.html#modellazione-bayesiana",
    "title": "69  ANOVA ad due vie",
    "section": "\n69.3 Modellazione Bayesiana",
    "text": "69.3 Modellazione Bayesiana\nAdattiamo ai dati un modello che includa interazione:\n\nmod &lt;- brm(punteggio ~ gravita * condizione, data = df, backend = \"cmdstanr\")\n\nEsploriamo gli effetti condizionati:\n\nconditional_effects(mod, \"condizione:gravita\")",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_2vie.html#confronto-tra-modelli",
    "href": "chapters/linear_models/10_anova_2vie.html#confronto-tra-modelli",
    "title": "69  ANOVA ad due vie",
    "section": "\n69.4 Confronto tra Modelli",
    "text": "69.4 Confronto tra Modelli\nConfrontiamo due modelli:\n\n\nmod: con interazione\n\nmod1: solo con effetti principali\n\n\nmod1 &lt;- brm(punteggio ~ gravita + condizione, data = df, backend = \"cmdstanr\")\n\n\n69.4.1 LOO (Leave-One-Out Cross Validation)\n\nloo_mod  &lt;- loo(mod)\nloo_mod1 &lt;- loo(mod1)\nloo_compare(loo_mod, loo_mod1)\n#&gt;      elpd_diff se_diff\n#&gt; mod1  0.0       0.0   \n#&gt; mod  -0.7       1.5\n\nInterpretazione:\n\nse elpd_diff è piccolo rispetto a se_diff, la differenza non è sostanziale;\nil modello più semplice è preferibile se non vi è evidenza chiara a favore dell’interazione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_2vie.html#conclusione",
    "href": "chapters/linear_models/10_anova_2vie.html#conclusione",
    "title": "69  ANOVA ad due vie",
    "section": "\n69.5 Conclusione",
    "text": "69.5 Conclusione\nL’ANOVA a due vie permette di esaminare sia gli effetti separati di due fattori sia la loro interazione. La modellazione bayesiana, combinata con il confronto tramite LOO, offre un approccio potente per valutare quale struttura descrive meglio i dati. Se l’interazione non migliora la predizione in modo credibile, è preferibile adottare il modello più parsimonioso.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_2vie.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/10_anova_2vie.html#informazioni-sullambiente-di-sviluppo",
    "title": "69  ANOVA ad due vie",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] bridgesampling_1.1-2 loo_2.8.0            emmeans_1.11.1      \n#&gt;  [4] brms_2.22.0          Rcpp_1.0.14          bayestestR_0.15.3   \n#&gt;  [7] posterior_1.6.1      cmdstanr_0.9.0       thematic_0.1.6      \n#&gt; [10] MetBrewer_0.2.0      ggokabeito_0.1.0     see_0.11.0          \n#&gt; [13] gridExtra_2.3        patchwork_1.3.0      bayesplot_1.12.0    \n#&gt; [16] psych_2.5.3          scales_1.4.0         markdown_2.0        \n#&gt; [19] knitr_1.50           lubridate_1.9.4      forcats_1.0.0       \n#&gt; [22] stringr_1.5.1        dplyr_1.1.4          purrr_1.0.4         \n#&gt; [25] readr_2.1.5          tidyr_1.3.1          tibble_3.2.1        \n#&gt; [28] ggplot2_3.5.2        tidyverse_2.0.0      rio_1.2.3           \n#&gt; [31] here_1.0.1          \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1     farver_2.1.2         fastmap_1.2.0       \n#&gt;  [4] tensorA_0.36.2.1     pacman_0.5.1         digest_0.6.37       \n#&gt;  [7] timechange_0.3.0     estimability_1.5.1   lifecycle_1.0.4     \n#&gt; [10] StanHeaders_2.32.10  processx_3.8.6       magrittr_2.0.3      \n#&gt; [13] compiler_4.5.0       rlang_1.1.6          tools_4.5.0         \n#&gt; [16] yaml_2.3.10          data.table_1.17.2    labeling_0.4.3      \n#&gt; [19] htmlwidgets_1.6.4    curl_6.2.2           pkgbuild_1.4.7      \n#&gt; [22] mnormt_2.1.1         RColorBrewer_1.1-3   abind_1.4-8         \n#&gt; [25] withr_3.0.2          grid_4.5.0           stats4_4.5.0        \n#&gt; [28] colorspace_2.1-1     xtable_1.8-4         inline_0.3.21       \n#&gt; [31] insight_1.2.0        cli_3.6.5            mvtnorm_1.3-3       \n#&gt; [34] rmarkdown_2.29       generics_0.1.4       RcppParallel_5.1.10 \n#&gt; [37] rstudioapi_0.17.1    tzdb_0.5.0           rstan_2.32.7        \n#&gt; [40] parallel_4.5.0       matrixStats_1.5.0    vctrs_0.6.5         \n#&gt; [43] V8_6.0.3             Matrix_1.7-3         jsonlite_2.0.0      \n#&gt; [46] hms_1.1.3            glue_1.8.0           codetools_0.2-20    \n#&gt; [49] ps_1.9.1             distributional_0.5.0 stringi_1.8.7       \n#&gt; [52] gtable_0.3.6         QuickJSR_1.7.0       pillar_1.10.2       \n#&gt; [55] htmltools_0.5.8.1    Brobdingnag_1.2-9    R6_2.6.1            \n#&gt; [58] rprojroot_2.0.4      evaluate_1.0.3       lattice_0.22-7      \n#&gt; [61] backports_1.5.0      rstantools_2.4.0     coda_0.19-4.1       \n#&gt; [64] nlme_3.1-168         checkmate_2.3.2      xfun_0.52           \n#&gt; [67] pkgconfig_2.0.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_anova_2vie.html#bibliografia",
    "href": "chapters/linear_models/10_anova_2vie.html#bibliografia",
    "title": "69  ANOVA ad due vie",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>ANOVA ad due vie</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_one_proportion.html",
    "href": "chapters/linear_models/11_one_proportion.html",
    "title": "70  Inferenza sulle proporzioni",
    "section": "",
    "text": "70.1 Introduzione\nSpesso ci troviamo ad affrontare la necessità di confrontare due gruppi di dati. Mentre nei capitoli precedenti abbiamo considerato il contronto tra le medie di due gruppi indipendenti, nel caso presente ci concentreremo sul confronto tra le proporzioni di due gruppi indipendenti. Per esempio, potrebbe interessarci sapere se la proporzione di un gruppo è maggiore o diversa rispetto a quella di un altro gruppo. Come in precedenza, per effettuare tale confronto, è fondamentale utilizzare un modello statistico, poiché le vere differenze tra i gruppi sono spesso accompagnate da rumore di misurazione o fluttuazioni casuali del fenomeno in esame. Questo rende difficile trarre conclusioni basandosi unicamente sulle differenze calcolate dai dati osservati.\nAnche nel caso delle proporzioni, il metodo tradizionale per confrontare statisticamente due o più gruppi consiste nell’utilizzare un test di ipotesi. Questo approccio prevede la definizione di un’ipotesi nulla, che tipicamente afferma l’assenza di differenze tra i gruppi, e l’uso di una statistica test per valutare se i dati osservati sono compatibili con tale ipotesi. Se la statistica test supera una soglia prestabilita, l’ipotesi nulla viene rifiutata, suggerendo che esiste una differenza significativa tra i gruppi.\nTuttavia, i test di ipotesi presentano diverse criticità, come vedremo in seguito. Un approccio alternativo e più informativo è quello basato sulla stima anziché sul test dell’ipotesi nulla, fondato sulla probabilità bayesiana piuttosto che su quella frequentista. In questo caso, l’obiettivo non è semplicemente verificare se esiste una differenza tra i gruppi, ma stimare quanto siano effettivamente diversi. Questo metodo è intrinsecamente più informativo, poiché fornisce una stima diretta della differenza tra i gruppi, accompagnata da una misura dell’incertezza associata. Tale incertezza riflette sia la nostra limitata conoscenza dei parametri del modello (incertezza epistemica) sia la variabilità intrinseca del sistema (incertezza aleatoria).\nIn sintesi, mentre i test di ipotesi si concentrano sul rigetto o meno di un’ipotesi nulla, l’approccio basato sulla stima offre una visione più completa e utile, permettendo di quantificare direttamente la differenza tra i gruppi e di valutare l’incertezza associata a tale stima. Questo rende l’analisi più adatta a supportare decisioni informate e basate sui dati.\nIn questo capitolo approfondiremo l’analisi bayesiana per il confronto tra due proporzioni, utilizzando il pacchetto brms in R. L’approccio bayesiano permette di ottenere una descrizione completa della distribuzione a posteriori del parametro di interesse, fornendo informazioni dettagliate sulla sua incertezza e variabilità, oltre a misure intuitive come intervalli di credibilità e probabilità dirette (es. la probabilità che la proporzione del gruppo A sia maggiore di quella del gruppo B).\nPer illustrare i vantaggi dell’approccio bayesiano, confronteremo i risultati con quelli ottenuti tramite l’analisi frequentista tradizionale. Per facilitare l’apprendimento, inizieremo con un caso più semplice: l’inferenza su una singola proporzione. Questo ci permetterà di familiarizzarci con i concetti fondamentali prima di estenderli al confronto tra due gruppi.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Inferenza sulle proporzioni</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_one_proportion.html#inferenza-su-una-proporzione",
    "href": "chapters/linear_models/11_one_proportion.html#inferenza-su-una-proporzione",
    "title": "70  Inferenza sulle proporzioni",
    "section": "\n70.2 Inferenza su Una Proporzione",
    "text": "70.2 Inferenza su Una Proporzione\n\n70.2.1 Contesto e Dati\nCome esempio per l’inferenza su una proporzione, utilizzeremo i dati dello studio di Brückner & Bearman (2005), discussi anche da Wagenmakers et al. (2010). Nell’articolo “After the promise: the STD consequences of adolescent virginity pledges”, Brückner & Bearman (2005) analizzano una serie di interviste condotte nell’ambito del National Longitudinal Study of Adolescent Health (Add Health). Lo studio si concentra sul comportamento sessuale di adolescenti, di età compresa tra 18 e 24 anni, che hanno fatto un “virginity pledge”, ovvero una promessa pubblica o scritta di rimanere vergini fino al matrimonio. Studi scientifici indicano che il comportamento sessuale di questi adolescenti non sia statisticamente diverso da quello di chi non ha fatto tale promessa, con l’unica eccezione che i “pledgers” hanno una minore probabilità di utilizzare il preservativo durante il primo rapporto sessuale.\nI dati rilevanti per la nostra analisi sono i seguenti:\n\nsu 777 adolescenti che hanno fatto il “virginity pledge”, 424 (54.6%) hanno dichiarato di aver usato il preservativo durante il primo rapporto sessuale;\nsu 9072 adolescenti che non hanno fatto la promessa, 5416 (59.7%) hanno dichiarato di aver usato il preservativo.\n\n70.2.2 Obiettivo dell’Analisi\nNella prima analisi, ci concentreremo sul campione di adolescenti che hanno fatto il “virginity pledge”. Ci chiediamo se sia credibile pensare che questi adolescenti tendano ad avere un rapporto protetto, nel loro primo rapporto sessuale, in una proporzione minore di quella che ci si potrebbe aspettare in caso di casualità (ovvero, una proporzione di 0.5).\n\n70.2.3 Analisi Frequentista\nIniziamo con un test frequentista usando la funzione prop.test() per confrontare la proporzione osservata con il valore di riferimento 0.5.\n\nprop_test_freq_vol &lt;- prop.test(\n  x = 424,\n  n = 777,\n  p = 0.5\n)\n\ntidy(prop_test_freq_vol)\n#&gt; # A tibble: 1 × 8\n#&gt;   estimate statistic p.value parameter conf.low conf.high\n#&gt;      &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1    0.546      6.31  0.0120         1    0.510     0.581\n#&gt;   method                                               alternative\n#&gt;   &lt;chr&gt;                                                &lt;chr&gt;      \n#&gt; 1 1-sample proportions test with continuity correction two.sided\n\nL’intervallo di confidenza frequentista non include il valore di riferimento 0.5, quindi, in base a questa analisi, possiamo concludere che la proporzione osservata (0.546) sia maggiore del valore atteso in caso di casualità (0.5).\n\n70.2.4 Approccio Bayesiano con brms\n\nSe utilizziamo dei prior non informativi, ci aspettiamo di giungere alla stessa conclusione anche con un approccio bayesiano. Tuttavia, l’approccio bayesiano ci permette di ottenere una distribuzione completa della probabilità a posteriori del parametro di interesse, offrendo una visione più ricca e flessibile rispetto all’approccio frequentista.\n\n70.2.4.1 Preparazione dei Dati\nIniziamo creando un data frame che sarà utilizzato con la funzione brm().\n\npledge_binomial_df &lt;- tibble(\n  n_yes = 424,\n  n_total = 777\n)\n\n# tiny data\npledge_binomial_df\n#&gt; # A tibble: 1 × 2\n#&gt;   n_yes n_total\n#&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1   424     777\n\n\n70.2.4.2 Definizione delle Opzioni del Campionatore\nImpostiamo alcune opzioni globali per il campionatore Stan.\n\n# Set some global Stan options\nCHAINS &lt;- 4\nITER &lt;- 2000\nWARMUP &lt;- 1000\nBAYES_SEED &lt;- 1234\n\n\n70.2.4.3 Modello Bayesiano\nUtilizziamo un modello di regressione con una funzione link binomiale. Questo significa che stimeremo la proporzione \\(p\\) con un modello di regressione beta-binomiale bayesiano utilizzando brms. Useremo un prior non informativo \\(\\mathcal{Beta}(1, 1)\\). Questo è un modello solo con intercetta, senza altre covariate, poiché siamo interessati solo alla proporzione sottostante, senza condizionarla su altre variabili.\nIl modello può essere rappresentato come segue:\n\\[\n\\begin{aligned}\ny_{\\text{condom\\_use}} &\\sim \\mathcal{Binomial}(n, \\pi) \\\\\n\\pi &= \\beta_0 \\\\\n\\beta_0 &\\sim \\mathcal{Beta}(1, 1)\n\\end{aligned}\n\\]\nEseguiamo l’analisi bayesiana.\n\nmodel_pledge_binomial &lt;- brm(\n  n_yes | trials(n_total) ~ 1,\n  data = pledge_binomial_df,\n  family = binomial(link = \"identity\"),\n  prior = c(prior(beta(1, 1), class = \"Intercept\", lb = 0, ub = 1)),\n  chains = CHAINS, warmup = WARMUP, iter = ITER, seed = BAYES_SEED,\n  refresh = 0,\n  backend = \"cmdstanr\"\n)\n#&gt; Running MCMC with 4 sequential chains...\n#&gt; \n#&gt; Chain 1 finished in 0.0 seconds.\n#&gt; Chain 2 finished in 0.0 seconds.\n#&gt; Chain 3 finished in 0.0 seconds.\n#&gt; Chain 4 finished in 0.0 seconds.\n#&gt; \n#&gt; All 4 chains finished successfully.\n#&gt; Mean chain execution time: 0.0 seconds.\n#&gt; Total execution time: 0.5 seconds.\n\n\n70.2.4.4 Risultati del Modello\nPoiché questo è un modello di regressione, si comporta come qualsiasi altro modello brms. Il coefficiente per l’intercetta rappresenta la proporzione stimata di adolescenti tra i 18 e i 24 anni che hanno usato il preservativo durante il primo rapporto sessuale nel campione.\n\nsummary(model_pledge_binomial)\n#&gt;  Family: binomial \n#&gt;   Links: mu = identity \n#&gt; Formula: n_yes | trials(n_total) ~ 1 \n#&gt;    Data: pledge_binomial_df (Number of observations: 1) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept     0.55      0.02     0.51     0.58 1.00     1457     1756\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nSi noti come l’intervallo di credibilità al 95% riproduce l’intervallo frequentista calcolato in precedenza.\n\n70.2.5 Confronto tra i Due Approcci\nConfrontiamo ora i risultati ottenuti dai due approcci. L’analisi frequentista ha mostrato che la proporzione osservata (0.546) è significativamente maggiore del valore di riferimento 0.5. L’approccio bayesiano conferma questa conclusione, fornendo una distribuzione completa della probabilità a posteriori per la proporzione π. Uno dei vantaggi dell’approccio bayesiano è la possibilità di incorporare informazioni a priori, se disponibili, migliorando così la robustezza delle inferenze. Inoltre, l’intervallo di credibilità bayesiano fornisce una descrizione più completa della distribuzione dei parametri, consentendo una migliore interpretazione dei risultati.\n\n70.2.6 Modello Beta-Binomiale e Soluzione Analitica\nIn questo contesto, il problema può essere modellato utilizzando una distribuzione beta-binomiale, per la quale esiste una soluzione analitica per la distribuzione a posteriori. Il modello beta-binomiale è particolarmente adatto quando si lavora con dati binomiali (ad esempio, successi e fallimenti) e si desidera incorporare una distribuzione a priori coniugata per la proporzione \\(p\\).\n\n70.2.6.1 Contestualizzazione del Modello\nPer il gruppo “pledgers”, abbiamo \\(y_1\\) successi su \\(n_1\\) prove. Se assumiamo una distribuzione a priori Beta(\\(\\alpha\\), \\(\\beta\\)), la distribuzione a posteriori per la proporzione \\(p_1\\) sarà anch’essa una distribuzione Beta, data da:\n\\[\np_1 \\mid y_1, n_1 \\sim \\mathcal{Beta}(\\alpha + y_1, \\beta + n_1 - y_1).\n\\]\nNel nostro caso specifico, scegliamo una prior non informativa \\(\\mathcal{Beta}(1, 1)\\), che equivale a una distribuzione uniforme sull’intervallo [0, 1]. Questa scelta riflette l’assenza di informazioni pregresse sulla proporzione \\(p_1\\). Pertanto, la distribuzione a posteriori per il gruppo “pledgers” diventa:\n\\[\np_1 \\mid y_1, n_1 \\sim \\mathcal{Beta}(1 + 424, 1 + 777 - 424) = \\mathcal{Beta}(425, 354).\n\\]\n\n70.2.6.2 Calcolo dell’Intervallo di Credibilità\nUtilizziamo R per calcolare l’intervallo di credibilità al 95% basato sulla distribuzione a posteriori derivata analiticamente.\n\n# Parametri della distribuzione Beta\na_post &lt;- 425  # Parametro alpha\nb_post &lt;- 354  # Parametro beta\n\n# Calcolo dell'intervallo centrale al 95%\ncredibility_interval &lt;- qbeta(c(0.025, 0.975), shape1 = a_post, shape2 = b_post)\nprint(credibility_interval)\n#&gt; [1] 0.5105 0.5804\n\nIl risultato ottenuto dall’analisi bayesiana analitica replica quello ottenuto tramite il modello brm() implementato in precedenza. Questo confronto tra approcci dimostra la coerenza tra le tecniche frequentista, bayesiana numerica e bayesiana analitica.\n\n70.2.7 Discussione e Confronto tra Approcci\nL’utilizzo della distribuzione beta-binomiale e della soluzione analitica offre diversi vantaggi:\n\n\nSemplicità: La soluzione analitica è spesso più semplice da implementare rispetto ai metodi numerici, come quelli utilizzati in brms.\n\nVelocità: I calcoli sono generalmente più veloci poiché non richiedono iterazioni o campionamenti.\n\nInterpretazione: L’uso di distribuzioni coniugate facilita l’interpretazione dei risultati, fornendo direttamente la distribuzione a posteriori senza bisogno di complessi algoritmi di inferenza.\n\nTuttavia, l’approccio bayesiano numerico tramite brms presenta anche vantaggi significativi:\n\n\nFlessibilità: Può gestire modelli più complessi e includere covariate multiple.\n\nPriori informativi: Permette di incorporare facilmente informazioni a priori, se disponibili.\n\nEstensioni: Facilita l’estensione del modello a casi più complessi, come il confronto tra proporzioni di due gruppi.\n\n\n70.2.7.1 Analisi della Distribuzione a Posteriori\nEssendo un’analisi bayesiana, possiamo lavorare con l’intera distribuzione a posteriori e calcolare direttamente l’estimando, come la differenza tra la proporzione campionaria e la proporzione di riferimento (0.5).\n\npledge_draws &lt;- model_pledge_binomial |&gt; \n  spread_draws(b_Intercept) |&gt; \n  mutate(diff = b_Intercept - 0.5)\n\nVisualizziamo la distribuzione a posteriori della proporzione.\n\np1 &lt;- ggplot(pledge_draws, aes(x = b_Intercept, y = \"Age 18–24\")) + \n  stat_halfeye(fill = \"gray\") +\n  geom_vline(xintercept = 0.5) +\n  scale_x_continuous(labels = label_percent()) +\n  coord_cartesian(ylim = c(1.5, 1.5)) +\n  labs(x = \"Proportion used a condom at first sex\", y = NULL)\np1\n\n\n\n\n\n\n\nIl valore di riferimento (0.5) non è incluso nella distribuzione a posteriori, il che significa che la differenza tra la proporzione campionaria e la proporzione di riferimento non include lo zero, con un livello di credibilità del 95%. Possiamo quindi concludere, con un livello soggettivo di credibilità del 95%, che l’uso del preservativo durante il primo rapporto sessuale sia maggiore del caso, per gli adolescenti che hanno fatto il “virginity pledge”.\n\n70.2.8 La Regione di Equivalenza Pratica (ROPE)\nL’analisi precedente confronta la proporzione osservata con un singolo valore di riferimento (0.5). Un approccio alternativo è considerare un intervallo di valori attorno a 0.5 che possano essere considerati “praticamente equivalenti” al valore di riferimento. Questo intervallo è chiamato Regione di Equivalenza Pratica (ROPE).\nSecondo Kruschke & Liddell (2018), la ROPE può essere definita come un intervallo attorno al valore nullo (baseline) che corrisponde a un decimo della deviazione standard della distribuzione a posteriori del parametro di interesse. Nel nostro caso, il parametro di interesse è la proporzione \\(p\\), e il valore nullo è 0.5. Per calcolare la ROPE, estraiamo i campioni a posteriori dal modello.\n\nposterior_samples &lt;- as_draws_df(model_pledge_binomial)\n\nCalcoliamo la deviazione standard a posteriori di \\(p\\).\n\nposterior_std_dev &lt;- sd(posterior_samples$b_Intercept)\nposterior_std_dev\n#&gt; [1] 0.01809\n\nDefiniamo la ROPE come un intervallo attorno al valore di riferimento 0.5.\n\nbaseline &lt;- 0.5  # Valore nullo (baseline)\nrope_low &lt;- baseline - 0.1 * posterior_std_dev\nrope_high &lt;- baseline + 0.1 * posterior_std_dev\n\nCalcoliamo ora la probabilità che la proporzione \\(p\\) si trovi all’interno della ROPE.\n\nrope_probability &lt;-\n  mean(\n    posterior_samples$b_Intercept &gt;= rope_low &\n      posterior_samples$b_Intercept &lt;= rope_high\n  )\nrope_probability\n#&gt; [1] 0.00325\n\nVisualizziamo la distribuzione a posteriori di \\(p\\) insieme alla ROPE.\n\nggplot(posterior_samples, aes(x = b_Intercept)) +\n  geom_density(fill = \"gray\", alpha = 0.5) +\n  annotate(\n    geom = \"rect\", \n    xmin = rope_low, \n    xmax = rope_high, \n    ymin = 0, ymax = Inf, \n    fill = \"lightgray\", alpha = 0.2\n  ) +\n  geom_vline(xintercept = baseline, color = \"lightgray\") +\n  scale_x_continuous(labels = scales::percent) +\n  labs(x = \"Proportion used a condom at first sex\", y = \"Density\")\n\n\n\n\n\n\n\nIn conclusione, dato che solo lo 0.325% (meno dell’uno per cento) della distribuzione a posteriori di \\(p\\) si trova nella ROPE, possiamo concludere che ci sono evidenze credibili che la distribuzione a posteriori del parametro \\(p\\) (la proporzione di adolescenti, di età compresa tra 18 e 24 anni, che hanno fatto il “virginity pledge” e hanno usato il preservativo durante il primo rapporto sessuale) sia diversa dal valore di riferimento 0.5. Nel caso specifico, questa proporzione è più alta, indicando che la tendenza ad avere un rapporto protetto è maggiore rispetto al caso di casualità, per questa popolazione.\n\n70.2.8.1 Discussione sulla ROPE\nL’utilizzo della ROPE offre una prospettiva aggiuntiva nell’interpretazione delle inferenze bayesiane. Invece di semplicemente determinare se un parametro è statisticamente significativo rispetto a un valore di riferimento, la ROPE permette di valutare se le differenze osservate siano praticamente rilevanti in termini di impatto reale.\n\n\nSoglia di Rilevanza: L’impostazione di una ROPE consente di stabilire una soglia di rilevanza pratica. Se la maggior parte della distribuzione a posteriori cade al di fuori della ROPE, possiamo concludere che la differenza è non solo statistica ma anche pratica.\n\nInterpretazione Clinica: Nelle applicazioni pratiche, come in ambito medico o sociale, la ROPE aiuta a distinguere tra risultati statisticamente significativi ma clinicamente insignificanti e quelli che hanno un impatto rilevante.\n\nNel contesto dello studio sui “pledgers”, l’uso della ROPE fornisce una valutazione più completa della tendenza degli adolescenti a utilizzare il preservativo durante il primo rapporto sessuale, dimostrando che questa tendenza è non solo statisticamente diversa dal caso di casualità, ma anche significativa dal punto di vista pratico.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Inferenza sulle proporzioni</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_one_proportion.html#inferenza-sulla-differenza-tra-due-proporzioni",
    "href": "chapters/linear_models/11_one_proportion.html#inferenza-sulla-differenza-tra-due-proporzioni",
    "title": "70  Inferenza sulle proporzioni",
    "section": "\n70.3 Inferenza sulla Differenza tra Due Proporzioni",
    "text": "70.3 Inferenza sulla Differenza tra Due Proporzioni\nEstendiamo ora l’analisi precedente per confrontare le proporzioni di due gruppi, un compito per il quale non esiste una soluzione analitica semplice. Nello studio in esame, ci poniamo la domanda: Fino a che punto l’analisi statistica supporta l’ipotesi che i “pledgers” abbiano una minore probabilità rispetto ai “non-pledgers” di usare il preservativo durante il primo rapporto sessuale?\nPer testare questa ipotesi utilizzando brms, estendiamo il modello bayesiano includendo due gruppi: i pledgers (che hanno fatto il voto di astinenza) e i non-pledgers (che non lo hanno fatto). L’obiettivo è stimare la differenza tra le due proporzioni e valutare se questa sia credibilmente diversa da zero.\n\n70.3.1 Creazione del Dataset\nCostruiamo un tibble con i dati relativi ai due gruppi:\n\npledge_data &lt;- tibble(\n  group = c(\"pledgers\", \"nonpledgers\"),\n  n_yes = c(424, 5416),   # Numero di partecipanti che hanno usato il preservativo\n  n_total = c(777, 9072)  # Totale dei partecipanti per ciascun gruppo\n)\nprint(pledge_data)\n#&gt; # A tibble: 2 × 3\n#&gt;   group       n_yes n_total\n#&gt;   &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 pledgers      424     777\n#&gt; 2 nonpledgers  5416    9072\n\n\n70.3.2 Specifica del Modello Bayesiano\nUtilizziamo un modello binomiale con un predittore categorico per distinguere tra i due gruppi. Il modello può essere rappresentato come:\n\\[\np_i \\sim \\text{Binomiale}(n_i, \\theta_i),\n\\]\ndove \\(\\theta_i\\) è la proporzione di utilizzo del preservativo nel gruppo \\(i\\), e modelliamo la probabilità di successo come:\n\\[\n\\theta = \\beta_0 + \\beta_1 \\cdot \\text{group},\n\\]\ndove:\n\n\n\\(\\beta_0\\) rappresenta la proporzione di non-pledgers che usano il preservativo.\n\n\\(\\beta_1\\) rappresenta la differenza tra pledgers e non-pledgers (cioè la variazione della proporzione di utilizzo del preservativo associata all’appartenenza al gruppo dei pledgers).\n\nLe caratteristiche di questo modello verranno approfondite nel capitolo successivo. Per ora, limitiamoci a stimare il modello in brms utilizzando una distribuzione binomiale e un link identità:\n\nmodel_pledge_diff &lt;- brm(\n  n_yes | trials(n_total) ~ group,\n  data = pledge_data,\n  family = binomial(link = \"identity\"),\n  prior = c(\n    prior(beta(1, 1), class = \"Intercept\", lb = 0, ub = 1),  \n    # Prior per la proporzione nei non-pledgers\n    prior(normal(0, 1), class = \"b\")  # Prior per la differenza tra gruppi\n  ),\n  chains = CHAINS, warmup = WARMUP, iter = ITER, seed = BAYES_SEED,\n  refresh = 0,\n  backend = \"cmdstanr\"\n)\n#&gt; Running MCMC with 4 sequential chains...\n#&gt; \n#&gt; Chain 1 finished in 0.1 seconds.\n#&gt; Chain 2 finished in 0.0 seconds.\n#&gt; Chain 3 finished in 0.1 seconds.\n#&gt; Chain 4 finished in 0.0 seconds.\n#&gt; \n#&gt; All 4 chains finished successfully.\n#&gt; Mean chain execution time: 0.1 seconds.\n#&gt; Total execution time: 0.8 seconds.\n\n\n70.3.3 Analisi della Distribuzione A Posteriori\nEsaminiamo il sommario del modello per valutare la stima della differenza tra le proporzioni:\n\nsummary(model_pledge_diff)\n#&gt;  Family: binomial \n#&gt;   Links: mu = identity \n#&gt; Formula: n_yes | trials(n_total) ~ group \n#&gt;    Data: pledge_data (Number of observations: 2) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept         0.60      0.01     0.59     0.61 1.00     4511     3068\n#&gt; grouppledgers    -0.05      0.02    -0.09    -0.01 1.01      889      793\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nPer interpretare meglio i risultati, estraiamo i campioni a posteriori per la differenza tra le due proporzioni:\n\npledge_diff_draws &lt;- model_pledge_diff |&gt; \n  spread_draws(b_Intercept, b_grouppledgers) |&gt; \n  mutate(\n    nonpledgers_prop = b_Intercept,  # Stima della proporzione nei non-pledgers\n    pledgers_prop = b_Intercept + b_grouppledgers,  # Stima della proporzione nei pledgers\n    diff = nonpledgers_prop - pledgers_prop  # Differenza tra le due proporzioni\n  )\n\nVisualizziamo la distribuzione a posteriori della differenza:\n\np3 &lt;- ggplot(pledge_diff_draws, aes(x = diff)) + \n  stat_halfeye(fill = \"gray\") +\n  geom_vline(xintercept = 0, linetype = \"dashed\") +\n  scale_x_continuous(labels = label_percent()) +\n  labs(x = \"Differenza nella proporzione di utilizzo del preservativo\", \n       y = \"Densità a posteriori\") \nprint(p3)\n\n\n\n\n\n\n\nCalcoliamo la probabilità che la differenza tra le proporzioni sia maggiore di zero:\n\ndiff_probability &lt;- mean(pledge_diff_draws$diff &gt; 0)\nprint(diff_probability)\n#&gt; [1] 0.997\n\n\n70.3.4 Interpretazione dei Risultati\nLa probabilità calcolata è 0.997; ciò significa che c’è una probabilità del 99.7% che la proporzione di non-pledgers che usano il preservativo sia maggiore rispetto a quella dei pledgers. Questo supporta con elevata credibilità l’ipotesi che i pledgers abbiano meno probabilità di utilizzare il preservativo durante il primo rapporto sessuale.\nPossiamo quindi concludere che la differenza tra le due proporzioni è credibilmente diversa da zero, con un’elevata probabilità a favore dell’ipotesi che i pledgers abbiano una minore propensione all’uso del preservativo rispetto ai non-pledgers. Questi risultati riproducono quelli riportati dalla letteratura precedente, come discusso da Brückner & Bearman (2005).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Inferenza sulle proporzioni</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_one_proportion.html#riflessioni-conclusive",
    "href": "chapters/linear_models/11_one_proportion.html#riflessioni-conclusive",
    "title": "70  Inferenza sulle proporzioni",
    "section": "\n70.4 Riflessioni Conclusive",
    "text": "70.4 Riflessioni Conclusive\nL’inferenza su una proporzione tramite un approccio bayesiano offre una prospettiva più ricca e flessibile rispetto agli approcci frequentisti tradizionali. Utilizzando il pacchetto brms in R, abbiamo dimostrato come sia possibile modellare la proporzione di adolescenti che hanno usato il preservativo durante il primo rapporto sessuale, ottenendo risultati coerenti con quelli frequentisti. La capacità di ottenere una distribuzione completa della probabilità a posteriori consente non solo stime puntuali ma anche una comprensione approfondita dell’incertezza associata ai parametri stimati, rendendo l’approccio bayesiano uno strumento potente per l’analisi statistica avanzata.\nL’estensione dell’analisi alla differenza tra due proporzioni ha ulteriormente evidenziato i vantaggi dell’approccio bayesiano. Attraverso brms, abbiamo confrontato le proporzioni di utilizzo del preservativo tra i “pledgers” e i “non-pledgers”, ottenendo risultati coerenti e facilmente interpretabili. L’uso di distribuzioni a posteriori complete ci ha permesso di valutare in modo più dettagliato la plausibilità delle differenze osservate, offrendo una maggiore profondità di interpretazione rispetto agli intervalli di confidenza frequentisti.\n\n70.4.1 Vantaggi dell’Approccio Bayesiano\n\nDistribuzioni A Posteriori: L’approccio bayesiano fornisce una visione completa della distribuzione dei parametri stimati, permettendo di calcolare probabilità direttamente e quantificare l’incertezza in modo più intuitivo.\nFlessibilità Modellistica: brms consente di costruire modelli complessi, inclusi modelli gerarchici e multivariati, adattandosi alle specifiche esigenze dell’analisi senza perdere di generalità.\nPrior Informativi e Non Informativi: La possibilità di incorporare prior informativi o utilizzare prior non informativi permette di integrare conoscenze pregresse o lavorare in assenza di informazioni preliminari, aumentando la robustezza delle inferenze.\nIntegrazione con Stan: Sfruttando la potenza di Stan, brms offre algoritmi di campionamento efficienti e accurati per modelli complessi, garantendo risultati affidabili anche in situazioni di alta dimensionalità.\nVisualizzazione e Interpretazione: L’integrazione con pacchetti come tidyverse e ggplot2 facilita la visualizzazione e l’interpretazione dei risultati, rendendo più semplice comunicare le analisi bayesiane a un pubblico ampio e variegato.\n\n70.4.2 Applicazioni Pratiche\nI risultati ottenuti confermano che i “pledgers” hanno una minore propensione all’uso del preservativo rispetto ai “non-pledgers”, supportando con elevata credibilità l’ipotesi formulata. Questi risultati riproducono quelli riportati dalla letteratura precedente, rafforzando la validità dell’approccio bayesiano nelle applicazioni pratiche.\n\n70.4.3 Conclusione\nIn sintesi, l’approccio bayesiano, implementato attraverso il pacchetto brms, rappresenta uno strumento estremamente potente e flessibile per l’inferenza statistica. Offre una visione più dettagliata e comprensiva rispetto agli approcci frequentisti tradizionali, permettendo di ottenere risultati coerenti e facilmente interpretabili.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Inferenza sulle proporzioni</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_one_proportion.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/11_one_proportion.html#informazioni-sullambiente-di-sviluppo",
    "title": "70  Inferenza sulle proporzioni",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] tidybayes_3.0.7   broom_1.0.8       brms_2.22.0       Rcpp_1.0.14      \n#&gt;  [5] bayestestR_0.15.3 posterior_1.6.1   cmdstanr_0.9.0    thematic_0.1.6   \n#&gt;  [9] MetBrewer_0.2.0   ggokabeito_0.1.0  see_0.11.0        gridExtra_2.3    \n#&gt; [13] patchwork_1.3.0   bayesplot_1.12.0  psych_2.5.3       scales_1.4.0     \n#&gt; [17] markdown_2.0      knitr_1.50        lubridate_1.9.4   forcats_1.0.0    \n#&gt; [21] stringr_1.5.1     dplyr_1.1.4       purrr_1.0.4       readr_2.1.5      \n#&gt; [25] tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.2     tidyverse_2.0.0  \n#&gt; [29] rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1     svUnit_1.0.6         farver_2.1.2        \n#&gt;  [4] loo_2.8.0            fastmap_1.2.0        tensorA_0.36.2.1    \n#&gt;  [7] pacman_0.5.1         digest_0.6.37        timechange_0.3.0    \n#&gt; [10] estimability_1.5.1   lifecycle_1.0.4      StanHeaders_2.32.10 \n#&gt; [13] processx_3.8.6       magrittr_2.0.3       compiler_4.5.0      \n#&gt; [16] rlang_1.1.6          tools_4.5.0          utf8_1.2.5          \n#&gt; [19] data.table_1.17.2    labeling_0.4.3       bridgesampling_1.1-2\n#&gt; [22] htmlwidgets_1.6.4    curl_6.2.2           pkgbuild_1.4.7      \n#&gt; [25] mnormt_2.1.1         plyr_1.8.9           RColorBrewer_1.1-3  \n#&gt; [28] abind_1.4-8          withr_3.0.2          stats4_4.5.0        \n#&gt; [31] grid_4.5.0           colorspace_2.1-1     inline_0.3.21       \n#&gt; [34] xtable_1.8-4         emmeans_1.11.1       insight_1.2.0       \n#&gt; [37] cli_3.6.5            mvtnorm_1.3-3        rmarkdown_2.29      \n#&gt; [40] generics_0.1.4       RcppParallel_5.1.10  rstudioapi_0.17.1   \n#&gt; [43] reshape2_1.4.4       tzdb_0.5.0           rstan_2.32.7        \n#&gt; [46] parallel_4.5.0       matrixStats_1.5.0    vctrs_0.6.5         \n#&gt; [49] V8_6.0.3             Matrix_1.7-3         jsonlite_2.0.0      \n#&gt; [52] hms_1.1.3            arrayhelpers_1.1-0   ggdist_3.3.3        \n#&gt; [55] glue_1.8.0           codetools_0.2-20     ps_1.9.1            \n#&gt; [58] distributional_0.5.0 stringi_1.8.7        gtable_0.3.6        \n#&gt; [61] QuickJSR_1.7.0       pillar_1.10.2        htmltools_0.5.8.1   \n#&gt; [64] Brobdingnag_1.2-9    R6_2.6.1             rprojroot_2.0.4     \n#&gt; [67] evaluate_1.0.3       lattice_0.22-7       backports_1.5.0     \n#&gt; [70] rstantools_2.4.0     coda_0.19-4.1        nlme_3.1-168        \n#&gt; [73] checkmate_2.3.2      xfun_0.52            pkgconfig_2.0.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Inferenza sulle proporzioni</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_one_proportion.html#bibliografia",
    "href": "chapters/linear_models/11_one_proportion.html#bibliografia",
    "title": "70  Inferenza sulle proporzioni",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlbert, J., & Hu, J. (2019). Probability and Bayesian Modeling. CRC Press.\n\n\nBrückner, H., & Bearman, P. (2005). After the promise: The STD consequences of adolescent virginity pledges. Journal of Adolescent Health, 36(4), 271–278.\n\n\nKruschke, J. K., & Liddell, T. M. (2018). Bayesian data analysis for newcomers. Psychonomic Bulletin & Review, 25(1), 155–177.\n\n\nWagenmakers, E.-J., Lodewyckx, T., Kuriyal, H., & Grasman, R. (2010). Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method. Cognitive Psychology, 60(3), 158–189.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Inferenza sulle proporzioni</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html",
    "href": "chapters/linear_models/12_two_proportions.html",
    "title": "71  Confronto tra due proporzioni indipendenti",
    "section": "",
    "text": "71.1 Introduzione\nSupponiamo di voler capire se due gruppi di persone hanno la stessa probabilità di “successo” in una certa attività. Per esempio, vogliamo sapere se due trattamenti diversi portano alla stessa percentuale di guarigione, oppure se studenti che seguono due metodi di studio differenti superano un esame con la stessa frequenza.\nQuando il risultato per ogni persona è un valore binario — successo o insuccesso, sì o no, guarito o non guarito — possiamo usare un modello statistico chiamato regressione logistica.\nIn particolare, se i due gruppi sono indipendenti e distinti (cioè ogni persona appartiene a uno solo dei due gruppi), possiamo usare una versione semplice della regressione logistica con una sola variabile esplicativa binaria (una “dummy”).\nAdottando un approccio bayesiano, possiamo:",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#introduzione",
    "href": "chapters/linear_models/12_two_proportions.html#introduzione",
    "title": "71  Confronto tra due proporzioni indipendenti",
    "section": "",
    "text": "rendere esplicita l’incertezza sulle nostre ipotesi iniziali tramite le distribuzioni a priori;\n\ndescrivere l’intera gamma di risultati plausibili, ottenendo una distribuzione a posteriori dei parametri invece di un singolo valore “stimato”.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#la-struttura-dei-dati",
    "href": "chapters/linear_models/12_two_proportions.html#la-struttura-dei-dati",
    "title": "71  Confronto tra due proporzioni indipendenti",
    "section": "\n71.2 La struttura dei dati",
    "text": "71.2 La struttura dei dati\nConsideriamo i dati che raccogliamo:\n\nogni partecipante è identificato da un indice \\(i = 1, 2, \\dots, N\\);\n\nper ciascuno osserviamo un esito binario:\n\\[\ny_i =\n  \\begin{cases}\n    1 & \\text{se c’è un successo},\\\\\n    0 & \\text{se c’è un insuccesso}.\n  \\end{cases}\n\\]\n\nogni partecipante appartiene a uno e un solo gruppo. Chiamiamo gruppo 0 il primo gruppo (ad esempio, il gruppo di controllo) e gruppo 1 il secondo gruppo (ad esempio, il gruppo che riceve un trattamento sperimentale).\n\nPer rappresentare questa appartenenza al gruppo, definiamo una variabile indicatrice:\n\\[\nD_i =\n  \\begin{cases}\n    0 & \\text{se il partecipante è nel gruppo 0},\\\\\n    1 & \\text{se il partecipante è nel gruppo 1}.\n  \\end{cases}\n\\]\nQuesta variabile ci permette di costruire un modello che distingue i due gruppi.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#un-modello-statistico-per-dati-binari",
    "href": "chapters/linear_models/12_two_proportions.html#un-modello-statistico-per-dati-binari",
    "title": "71  Confronto tra due proporzioni indipendenti",
    "section": "\n71.3 Un modello statistico per dati binari",
    "text": "71.3 Un modello statistico per dati binari\nPoiché il risultato \\(y\\_i\\) può essere solo 0 o 1, possiamo descriverlo con una distribuzione di Bernoulli, che rappresenta proprio questo tipo di variabili:\n\\[\ny_i \\sim \\text{Bernoulli}(p_i),\n\\]\ndove \\(p\\_i\\) è la probabilità che il partecipante \\(i\\) ottenga un successo (cioè che \\(y_i = 1\\)).\nA questo punto potremmo pensare di modellare direttamente \\(p_i\\) come una funzione di \\(D_i\\). Ma c’è un problema tecnico importante.\n\n71.3.1 Perché non modelliamo direttamente la probabilità \\(p_i\\)?\nLe probabilità devono sempre stare tra 0 e 1. Ma se usassimo un modello lineare classico (come \\(p\\_i = \\alpha + \\gamma D_i\\)), potremmo ottenere dei valori fuori da questo intervallo — ad esempio, una “probabilità” negativa o maggiore di 1, che non ha senso.\nPer evitare questo, si usa una trasformazione matematica chiamata logit, che ha due proprietà molto utili:\n\naccetta in ingresso solo valori tra 0 e 1 (cioè le probabilità),\nrestituisce un numero reale qualsiasi, da \\(-\\infty\\) a \\(+\\infty\\).\n\nLa trasformazione logit è definita così:\n\\[\n\\text{logit}(p_i) = \\log\\left(\\frac{p_i}{1 - p_i}\\right) .\n\\]\nQuesta quantità si chiama log-odds e rappresenta il logaritmo del rapporto tra la probabilità di successo e quella di insuccesso.\nEsempio:\n\nse \\(p_i = 0.5\\), allora \\(\\text{logit}(p_i) = \\log(1) = 0\\);\nse \\(p_i = 0.8\\), allora \\(\\text{logit}(p_i) = \\log(4) \\approx 1.39\\);\nse \\(p_i = 0.2\\), allora \\(\\text{logit}(p_i) = \\log(0.25) \\approx -1.39\\).\n\nGrazie a questa trasformazione, possiamo costruire un modello lineare senza rischiare di ottenere valori fuori dall’intervallo [0,1].",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#il-modello-di-regressione-logistica",
    "href": "chapters/linear_models/12_two_proportions.html#il-modello-di-regressione-logistica",
    "title": "71  Confronto tra due proporzioni indipendenti",
    "section": "\n71.4 Il modello di regressione logistica",
    "text": "71.4 Il modello di regressione logistica\nMettiamo insieme tutti i pezzi. Il nostro modello diventa:\n\\[\n\\begin{aligned}\ny_i &\\sim \\text{Bernoulli}(p_i), \\\\\n\\text{logit}(p_i) &= \\alpha + \\gamma D_i.\n\\end{aligned}\n\\]\nVediamo cosa significano i due parametri del modello:\n\n\n\\(\\alpha\\) è il log-odds di successo per il gruppo 0 (quando \\(D_i = 0\\)).\n\n\nLa probabilità di successo corrispondente si ottiene con la funzione logistica:\n\\[\np_0 = \\frac{e^{\\alpha}}{1 + e^{\\alpha}} = \\text{logistic}(\\alpha) .\n\\]\n\n\n\n\n\\(\\gamma\\) rappresenta la differenza nei log-odds tra il gruppo 1 e il gruppo 0.\n\n\nIl log-odds nel gruppo 1 è quindi $+ $, e la probabilità è:\n\\[\np_1 = \\frac{e^{\\alpha + \\gamma}}{1 + e^{\\alpha + \\gamma}} = \\text{logistic}(\\alpha + \\gamma) .\n\\]\n\n\n\n\n\n71.4.1 Interpretazione pratica\n\nSe \\(\\gamma &gt; 0\\), il gruppo 1 ha una probabilità di successo più alta rispetto al gruppo 0.\nSe \\(\\gamma &lt; 0\\), il gruppo 1 ha una probabilità più bassa.\nSe \\(\\gamma = 0\\), i due gruppi hanno la stessa probabilità di successo.\n\n71.4.2 Vantaggi dell’approccio bayesiano\nIn un’analisi bayesiana, non ci limitiamo a stimare un singolo valore per \\(\\gamma\\). Invece, otteniamo una distribuzione completa che rappresenta tutte le ipotesi plausibili sui valori di \\(\\gamma\\), tenendo conto:\n\ndella variabilità nei dati,\ndelle nostre ipotesi iniziali (le distribuzioni a priori),\ne delle informazioni che emergono dai dati osservati.\n\nQuesto ci permette di rispondere a domande come:\n\nQuanto è probabile che \\(\\gamma\\) sia maggiore di 0?\nQual è l’intervallo più credibile in cui può trovarsi \\(\\gamma\\) con il 95% di probabilità?\nQual è la probabilità che la differenza tra i gruppi sia sostanziale, non solo presente?\n\n71.4.3 Dai Logit alle Probabilità\nUna volta stimati i coefficienti del modello di regressione logistica — in particolare, l’intercetta \\(\\beta\\_0\\) e uno o più coefficienti \\(\\beta_j\\) associati ai predittori — questi si trovano sulla scala dei log-odds (cioè su scala logit). Per ottenere le probabilità previste per ciascuna combinazione di valori dei predittori, è sufficiente applicare la funzione logistica inversa, definita come:\n\\[\np = \\text{logistic}(\\eta) = \\frac{1}{1 + e^{-\\eta}},\n\\]\ndove \\(\\eta = \\beta_0 + \\beta_1 x_1 + \\dots + \\beta_k x_k\\) è il valore del predittore lineare per una certa combinazione dei predittori. Ad esempio, se si ha solo una variabile binaria \\(x\\) che vale 0 (gruppo di riferimento) o 1 (gruppo trattato), allora le probabilità nei due gruppi sono:\n\ngruppo di riferimento: \\(p_0 = \\frac{1}{1 + e^{-\\beta_0}}\\)\n\ngruppo trattamento:    \\(p_1 = \\frac{1}{1 + e^{-(\\beta\\_0 + \\beta_1)}}\\)\n\n\nIn questo modo, si può interpretare il modello non solo in termini di log-odds, ma anche come probabilità di successo, rendendo più intuitivo il significato pratico dei risultati.\n\n71.4.4 Inferenza bayesiana\n\n\nScelta delle prior\n\nUn’opzione comune è usare prior debolmente informative, ad esempio \\(\\alpha\\sim\\mathcal N(0,\\,2.5)\\) e \\(\\gamma\\sim\\mathcal N(0,\\,2.5)\\). Queste varianze larghe lasciano che i dati “parlino”, ma impediscono che le probabilità si avvicinino troppo a 0 o 1 senza evidenza.\n\n\n\nCalcolo della distribuzione a posteriori\n\nSi usa normalmente l’algoritmo MCMC (per es. No‑U‑Turn Sampler di Stan).\nOtteniamo campioni \\(\\{\\alpha^{(s)},\\gamma^{(s)}\\}_{s=1}^S\\).\n\n\n\nQuantità derivate di interesse\n\nProbabilità nei due gruppi: \\(p_0^{(s)}=\\operatorname{logistic}(\\alpha^{(s)})\\), \\(p_1^{(s)}=\\operatorname{logistic}(\\alpha^{(s)}+\\gamma^{(s)})\\).\n\nDifferenza di probabilità: \\(\\Delta^{(s)} = p_1^{(s)}-p_0^{(s)}\\). Mostra quanto, in media, il gruppo 1 supera (o non supera) il gruppo 0 in termini di proporzione.\n\nRapporto di odds: \\(\\text{OR}^{(s)} = e^{\\gamma^{(s)}}\\). Se \\(\\text{OR}=2\\) significa che gli odds di successo nel gruppo 1 sono il doppio di quelli nel gruppo 0.\n\n\n\nSintesi dei risultati\n\nMedia (o mediana) a posteriori per \\(p_0, p_1, \\Delta, \\text{OR}\\).\nIntervalli di credibilità al 95 %: tagliamo il 2.5 % di campioni in ciascuna coda.\nProbabilità che \\(\\Delta&gt;0\\) o che \\(\\text{OR}&gt;1\\): basta contare la frazione di campioni corrispondenti.\n\n\n\n71.4.5 Perché tutto questo funziona?\n\nIl logit “apre” l’intervallo (0, 1) rendendo possibile usare un modello lineare.\n\nLa regressione logistica con una dummy è l’esatto equivalente, in termini di parametri, al test bayesiano sulle due proporzioni, ma:\n\nconsente estensioni (più covariate, effetti casuali, interazioni);\npermette di riportare risultati direttamente interpretabili (differenza di probabilità, OR, predicted probabilities).\n\n\nL’approccio bayesiano produce output che si leggono come “date le nostre ipotesi preliminari e i dati, la plausibilità che la vera differenza di probabilità stia in questo intervallo è 95 %”, concetto spesso più intuitivo del valore‑p.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#inferenza-sulle-proporzioni",
    "href": "chapters/linear_models/12_two_proportions.html#inferenza-sulle-proporzioni",
    "title": "71  Confronto tra due proporzioni indipendenti",
    "section": "\n71.5 Inferenza sulle proporzioni",
    "text": "71.5 Inferenza sulle proporzioni\nIl confronto tra le proporzioni di due gruppi indipendenti può essere affrontato sia con un approccio frequentista, basato sulla distribuzione campionaria, sia con un approccio bayesiano. Vediamo i due approcci in dettaglio.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#approccio-frequentista",
    "href": "chapters/linear_models/12_two_proportions.html#approccio-frequentista",
    "title": "71  Confronto tra due proporzioni indipendenti",
    "section": "\n71.6 Approccio Frequentista",
    "text": "71.6 Approccio Frequentista\nQuando vogliamo confrontare le probabilità di successo in due gruppi distinti, possiamo analizzare la differenza tra le proporzioni di successo osservate. L’approccio frequentista affronta il problema studiando la distribuzione campionaria di questa differenza.\n\n71.6.1 Modello di riferimento\nSupponiamo di avere due gruppi indipendenti. In ciascun gruppo osserviamo esiti binari, come “successo” (1) o “insuccesso” (0), per ogni partecipante. Formalmente:\n\\[\nY_1 \\sim \\text{Bernoulli}(p_1), \\quad Y_2 \\sim \\text{Bernoulli}(p_2),\n\\]\ndove \\(p_1\\) e \\(p_2\\) sono le probabilità di successo nella popolazione del primo e del secondo gruppo, rispettivamente.\n\n71.6.2 Obiettivo dell’inferenza\nSiamo interessati a stimare e fare inferenza sulla differenza tra le due proporzioni:\n\\[\n\\Delta = p_1 - p_2.\n\\]\nPoiché non conosciamo \\(p_1\\) e \\(p_2\\), li stimiamo usando le proporzioni campionarie:\n\\[\n\\hat{p}_1 = \\frac{X_1}{n_1}, \\quad \\hat{p}_2 = \\frac{X_2}{n_2}, \\quad \\text{e dunque} \\quad \\hat{\\Delta} = \\hat{p}_1 - \\hat{p}_2.\n\\]\n\n71.6.3 Proprietà della distribuzione campionaria\nPer capire se la differenza osservata tra \\(\\hat{p}_1\\) e \\(\\hat{p}_2\\) è attribuibile al caso oppure riflette una differenza reale tra i gruppi, analizziamo la distribuzione campionaria di \\(\\hat{\\Delta}\\).\n\n71.6.3.1 Valore atteso\nIl valore atteso della differenza stimata è:\n\\[\nE(\\hat{p}_1 - \\hat{p}_2) = p_1 - p_2,\n\\]\ncioè, in media, la stima è corretta (è uno stimatore non distorto).\n\n\n\n\n\n\nDimostrazione\n\n\n\n\n\nSupponiamo di voler confrontare le proporzioni di successo in due popolazioni distinte. Sia:\n\n\n\\(X_1\\) il numero di successi osservati in un campione di dimensione \\(n_1\\) estratto dalla prima popolazione, in cui la proporzione di successo è \\(p_1\\);\n\n\\(X_2\\) il numero di successi osservati in un campione di dimensione \\(n_2\\) estratto dalla seconda popolazione, con proporzione di successo \\(p_2\\).\n\nAssumiamo che i due campioni siano indipendenti.\nLe proporzioni campionarie, che stimano rispettivamente \\(p_1\\) e \\(p_2\\), sono definite come:\n\\[\n\\hat{p}_1 = \\frac{X_1}{n_1}, \\quad \\hat{p}_2 = \\frac{X_2}{n_2}.\n\\]\nPoiché \\(X_1 \\sim \\text{Binomiale}(n_1, p_1)\\) e \\(X_2 \\sim \\text{Binomiale}(n_2, p_2)\\), possiamo determinare i valori attesi di \\(X_1\\) e \\(X_2\\) ricordando che per una variabile binomiale \\(X \\sim \\text{Bin}(n, p)\\), il valore atteso è:\n\\[\n\\mathbb{E}(X) = n p.\n\\]\nUna variabile binomiale può essere vista come la somma di \\(n\\) variabili di Bernoulli indipendenti:\n\\[\nX = X_1 + X_2 + \\dots + X_n, \\quad \\text{con } X_i \\sim \\text{Bernoulli}(p).\n\\]\nPer la linearità del valore atteso:\n\\[\n\\mathbb{E}(X) = \\sum_{i=1}^n \\mathbb{E}(X_i) = \\sum_{i=1}^n p = n p.\n\\]\nApplicando questa proprietà ai nostri due campioni:\n\\[\n\\mathbb{E}(X_1) = n_1 p_1, \\quad \\mathbb{E}(X_2) = n_2 p_2.\n\\]\nPer la prima proporzione campionaria:\n\\[\n\\mathbb{E}(\\hat{p}_1) = \\mathbb{E}\\left( \\frac{X_1}{n_1} \\right) = \\frac{1}{n_1} \\mathbb{E}(X_1) = \\frac{n_1 p_1}{n_1} = p_1.\n\\]\nAnalogamente, per la seconda:\n\\[\n\\mathbb{E}(\\hat{p}_2) = \\mathbb{E}\\left( \\frac{X_2}{n_2} \\right) = \\frac{1}{n_2} \\mathbb{E}(X_2) = \\frac{n_2 p_2}{n_2} = p_2.\n\\]\nDunque, sia \\(\\hat{p}_1\\) che \\(\\hat{p}_2\\) sono stimatori non distorti delle rispettive proporzioni della popolazione.\nInfine, calcoliamo il valore atteso della differenza tra le due proporzioni campionarie:\n\\[\n\\mathbb{E}(\\hat{p}_1 - \\hat{p}_2) = \\mathbb{E}(\\hat{p}_1) - \\mathbb{E}(\\hat{p}_2) = p_1 - p_2.\n\\]\nIn conclusione, la differenza tra le proporzioni campionarie, \\(\\hat{p}_1 - \\hat{p}_2\\), è uno stimatore non distorto della differenza tra le vere proporzioni, \\(p_1 - p_2\\).\n\n\n\n\n71.6.3.2 Varianza\nAssumendo che i campioni siano indipendenti, la varianza della differenza stimata è la somma delle varianze delle due proporzioni:\n\\[\n\\operatorname{Var}(\\hat{p}_1 - \\hat{p}_2) = \\frac{p_1(1 - p_1)}{n_1} + \\frac{p_2(1 - p_2)}{n_2}.\n\\]\nQuesta formula ci dice quanto può variare la differenza stimata da un campione all’altro.\nPoiché \\(p_1\\) e \\(p_2\\) sono ignoti, nella pratica li sostituiamo con le proporzioni osservate \\(\\hat{p}_1\\) e \\(\\hat{p}_2\\) per stimare la varianza.\n\n\n\n\n\n\nDimostrazione\n\n\n\n\n\nConsideriamo due campioni indipendenti:\n\nIl primo campione è estratto da una popolazione in cui la proporzione di successi è \\(p_1\\). Il numero di successi osservati è una variabile casuale \\(X_1 \\sim \\text{Binomiale}(n_1, p_1)\\).\nIl secondo campione proviene da una popolazione con proporzione di successi \\(p_2\\), e il numero di successi osservati è \\(X_2 \\sim \\text{Binomiale}(n_2, p_2)\\).\n\nDefiniamo le proporzioni campionarie (ovvero gli stimatori di \\(p_1\\) e \\(p_2\\)) come:\n\\[\n\\hat{p}_1 = \\frac{X_1}{n_1}, \\qquad \\hat{p}_2 = \\frac{X_2}{n_2}.\n\\]\nVogliamo calcolare la varianza della differenza tra le proporzioni campionarie:\n\\[\n\\operatorname{Var}(\\hat{p}_1 - \\hat{p}_2).\n\\]\nSe \\(Y\\) e \\(Z\\) sono variabili casuali indipendenti, allora:\n\\[\n\\operatorname{Var}(Y - Z) = \\operatorname{Var}(Y) + \\operatorname{Var}(Z).\n\\]\nNel nostro caso, \\(\\hat{p}_1\\) e \\(\\hat{p}_2\\) derivano da due campioni indipendenti, quindi possiamo applicare questa proprietà:\n\\[\n\\operatorname{Var}(\\hat{p}_1 - \\hat{p}_2) = \\operatorname{Var}(\\hat{p}_1) + \\operatorname{Var}(\\hat{p}_2).\n\\]\nPer calcolare \\(\\operatorname{Var}(\\hat{p})\\), partiamo dalla definizione di \\(\\hat{p} = X/n\\), dove \\(X \\sim \\text{Binomiale}(n, p)\\).\nÈ noto che la varianza di una binomiale (si veda Capitolo 39) è:\n\\[\n\\operatorname{Var}(X) = n p (1 - p).\n\\]\nOra applichiamo la proprietà di omogeneità della varianza: se \\(Y = cX\\), allora \\(\\operatorname{Var}(Y) = c^2 \\operatorname{Var}(X)\\). Quindi:\n\\[\n\\operatorname{Var}(\\hat{p}) = \\operatorname{Var}\\left(\\frac{X}{n}\\right) = \\frac{1}{n^2} \\cdot \\operatorname{Var}(X) = \\frac{1}{n^2} \\cdot n p (1 - p) = \\frac{p(1 - p)}{n}.\n\\]\nApplichiamo questa formula a ciascun campione:\n\\[\n\\operatorname{Var}(\\hat{p}_1) = \\frac{p_1 (1 - p_1)}{n_1}, \\qquad \\operatorname{Var}(\\hat{p}_2) = \\frac{p_2 (1 - p_2)}{n_2}.\n\\]\nSostituendo i valori ottenuti:\n\\[\n\\operatorname{Var}(\\hat{p}_1 - \\hat{p}_2) = \\frac{p_1 (1 - p_1)}{n_1} + \\frac{p_2 (1 - p_2)}{n_2}.\n\\]\nQuesta espressione rappresenta la varianza teorica della differenza tra le proporzioni campionarie, assumendo che i veri valori di \\(p_1\\) e \\(p_2\\) siano noti.\nNella realtà, i parametri \\(p_1\\) e \\(p_2\\) non sono noti, e quindi dobbiamo usare le stime campionarie al loro posto. Otteniamo così uno stimatore della varianza:\n\\[\n\\widehat{\\operatorname{Var}}(\\hat{p}_1 - \\hat{p}_2) = \\frac{\\hat{p}_1 (1 - \\hat{p}_1)}{n_1} + \\frac{\\hat{p}_2 (1 - \\hat{p}_2)}{n_2}.\n\\]\n\n\n\n\n71.6.4 Approssimazione normale\nQuando i campioni sono sufficientemente grandi, possiamo applicare il Teorema del Limite Centrale, che ci assicura che la distribuzione della differenza \\(\\hat{p}_1 - \\hat{p}_2\\) si avvicina a una distribuzione normale:\n\\[\n\\hat{p}_1 - \\hat{p}_2 \\sim \\mathcal{N}\\left(p_1 - p_2,\\ \\sqrt{\\frac{p_1(1 - p_1)}{n_1} + \\frac{p_2(1 - p_2)}{n_2}}\\right).\n\\tag{71.1}\\]\nNell’approccio frequentista, questa approssimazione è alla base della costruzione di:\n\n\nintervalli di confidenza per \\(p_1 - p_2\\),\n\ntest di ipotesi per verificare se la differenza tra le proporzioni è nulla.\n\n71.6.5 Test dell’ipotesi nulla\nLa formula Equazione 71.1 descrive la la distribuzione asintotica della differenza tra due proporzioni senza assumere che \\(p_1 = p_2\\). Si usa tipicamente per:\n\ncostruire intervalli di confidenza per \\(p_1 - p_2\\),\neffettuare test di ipotesi bilaterali, quando non si assume che le due proporzioni siano uguali sotto l’ipotesi nulla.\n\nIn alternativa, la formula\n\\[\n\\text{SE}_{\\text{pooled}} = \\sqrt{p_{\\text{pool}}(1 - p_{\\text{pool}})\\left(\\frac{1}{n_1} + \\frac{1}{n_2}\\right)}\n\\tag{71.2}\\]\nsi usa solo per testare l’ipotesi nulla \\(H_0: p_1 = p_2\\), ovvero sotto l’assunzione che \\(p_1 = p_2 = p\\), si stima questo valore comune con la proporzione combinata (pooled):\n\\[\n\\hat{p}_{\\text{pool}} = \\frac{x_1 + x_2}{n_1 + n_2}\n\\]\ne si calcola il test z usando questa stima comune.\n\n71.6.6 Quale formula usare e quando?\n\n\n\n\n\n\nScopo\nFormula da usare\n\n\n\nTest dell’ipotesi nulla \\(H_0: p_1 = p_2\\)\n\n✅ Usa la formula con pooled proportion\n\n\n\nCostruire intervallo di confidenza per \\(p_1 - p_2\\)\n\n✅ Usa la formula senza pooling, con \\(\\hat{p}_1\\) e \\(\\hat{p}_2\\)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#un-esempio-illustrativo",
    "href": "chapters/linear_models/12_two_proportions.html#un-esempio-illustrativo",
    "title": "71  Confronto tra due proporzioni indipendenti",
    "section": "\n71.7 Un esempio Illustrativo",
    "text": "71.7 Un esempio Illustrativo\nPer mettere in pratica quanto detto, consideriamo un caso reale tratto dallo studio di Banerjee et al. (2025). In questo studio vengono confrontate le abilità matematiche di:\n\n\nbambini lavoratori nei mercati di Kolkata e Delhi;\n\nbambini scolarizzati che non lavorano.\n\nL’obiettivo era valutare se le competenze sviluppate nel lavoro quotidiano (come dare il resto, sommare prezzi, ecc.) si trasferiscono al contesto scolastico e viceversa.\nI risultati principali mostrano come:\n\ni bambini lavoratori si sono dimostrati molto abili nel risolvere problemi matematici concreti, ma hanno faticato con problemi presentati in forma astratta (come quelli scolastici);\nal contrario, i bambini scolarizzati se la sono cavata meglio con problemi astratti, ma sono risultati poco efficaci nei problemi concreti del mercato.\n\nVediamo i dati raccolti per due tipi di problemi:\nProblemi astratti.\n\n\nGruppo\nSuccessi\nProve totali\nProporzione\n\n\n\nBambini lavoratori\n670\n1488\n0.45\n\n\nBambini scolarizzati\n320\n542\n0.59\n\n\n\nProblemi di mercato.\n\n\nGruppo\nSuccessi\nProve totali\nProporzione\n\n\n\nBambini lavoratori\n134\n373\n0.36\n\n\nBambini scolarizzati\n3\n271\n0.01\n\n\n\n\n71.7.1 Confronto per i problemi astratti\nUtilizzando l’approccio frequentista, vogliamo verificare se la differenza tra 0.45 (lavoratori) e 0.59 (scolarizzati) è spiegabile dal caso.\nIpotesi.\n\n\n\\(H_0\\): \\(p_1 = p_2\\) (nessuna differenza tra i gruppi);\n\n\\(H_1\\): \\(p_1 \\ne p_2\\) (esiste una differenza).\n\nCalcolo.\n\n\nProporzione combinata (pooled):\n\\[\n\\hat{p} = \\frac{670 + 320}{1488 + 542} = \\frac{990}{2030} \\approx 0.487.\n\\]\n\n\nVarianza stimata della differenza:\n\\[\n\\text{Var} = \\hat{p}(1 - \\hat{p}) \\left( \\frac{1}{1488} + \\frac{1}{542} \\right) \\approx 0.000629.\n\\]\n\nDeviazione standard: \\(\\sqrt{0.000629} \\approx 0.0251\\).\n\nStatistica z:\n\\[\nz = \\frac{0.45 - 0.59}{0.0251} \\approx -5.58.\n\\]\n\n\nIl valore z è molto lontano da 0: la probabilità di osservare una tale differenza per caso (p-value) è inferiore a 0.0001. Possiamo quindi rifiutare l’ipotesi nulla.\n\n71.7.2 Confronto per i problemi di mercato\nDati:\n\nLavoratori: 134 su 373 (\\(\\hat{p}_1 = 0.36\\))\nScolarizzati: 3 su 271 (\\(\\hat{p}_2 = 0.01\\))\n\nRipetiamo i passaggi:\n\n\\(\\hat{p} = \\frac{137}{644} \\approx 0.213\\)\n\\(\\text{Var} \\approx 0.001067\\)\nDeviazione standard: \\(\\sqrt{0.001067} \\approx 0.0327\\)\n\nStatistica z:\n\\[\nz = \\frac{0.36 - 0.01}{0.0327} \\approx 10.70\n\\]\n\n\nAnche qui, il p-value è praticamente zero: le differenze sono molto più grandi di quanto ci si aspetti per puro caso.\nIn sintesi, l’approccio frequentista ci consente di:\n\nstimare la differenza tra le proporzioni,\nquantificare l’incertezza (varianza e intervallo di confidenza),\ntestare ipotesi sul fatto che la differenza sia zero o meno.\n\nIn entrambi i confronti (problemi astratti e problemi concreti), abbiamo trovato evidenze chiare di una differenza tra i due gruppi.\n\n71.7.3 Svolgimento con R\nDi seguito mostriamo due modalità per replicare i calcoli in R: (1) passo passo usando le formule manuali, (2) usando la funzione prop.test() di R. Verranno illustrate entrambe le analisi: quella per i problemi astratti e quella per i problemi matematici di mercato.\n\n71.7.3.1 Problemi astratti\nDati\n\nBambini lavoratori (gruppo 1): 670 successi su 1488 prove.\nBambini scolarizzati (gruppo 2): 320 successi su 542 prove.\n\n\n##  Dati\nx_work   &lt;- 670   # successi (risposte corrette) tra i lavoratori\nn_work   &lt;- 1488  # totale lavoratori\n\nx_school &lt;- 320   # successi tra i non-lavoratori (scolarizzati)\nn_school &lt;- 542   # totale non-lavoratori\n\n##  Differenza di proporzioni \np_work   &lt;- x_work   / n_work\np_school &lt;- x_school / n_school\nrd       &lt;- p_school - p_work          \n\n##  Errore standard\n##  - Pooled SE per lo z-test (ipotesi H0: p1 = p2)\n##  - Unpooled SE per l’intervallo di confidenza\np_pool   &lt;- (x_work + x_school) / (n_work + n_school)\nse_test  &lt;- sqrt(p_pool * (1 - p_pool) * (1/n_work + 1/n_school))  # usato solo per lo z-test\nse_ci    &lt;- sqrt(p_work * (1 - p_work) / n_work +\n                 p_school * (1 - p_school) / n_school)  # migliore per il 95 % CI\n\n##  Inferenza\nz        &lt;- rd / se_test\np_value  &lt;- 2 * pnorm(-abs(z))\n\nalpha    &lt;- .05\nz_crit   &lt;- qnorm(1 - alpha/2)\nci_low   &lt;- rd - z_crit * se_ci\nci_high  &lt;- rd + z_crit * se_ci\n\n##  Stampa risultati\ncat(\n  sprintf(\n    \"Differenza assoluta:  %0.3f\\nErrore standard (CI): %0.3f\\nZ-test:            %0.2f\\nP-value:           %.3g\\n95%% CI:            [%0.2f, %0.2f]\\n\",\n    rd, se_ci, z, p_value, ci_low, ci_high\n  )\n)\n#&gt; Differenza assoluta:  0.140\n#&gt; Errore standard (CI): 0.025\n#&gt; Z-test:            5.59\n#&gt; P-value:           2.3e-08\n#&gt; 95% CI:            [0.09, 0.19]\n\nI valori ottenuti, 95% CI: 0.09 to 0.19, replicano quanto riportato da Banerjee et al. (2025) (la piccola differenza tra i risultati dipende dal fatto che gli autori hanno usato un metodo basato sulla regressione):\n\nOverall, 59% of non-working children correctly solved these problems compared with 45% of working children (β = –0.14, s.e.m. = 0.03, 95% CI = –0.20 to –0.08, P &lt; 0.001; Fig. 4, left).\n\n\n71.7.3.2 Analisi con funzione prop.test()\n\nPer ottenere direttamente il test di confronto di due proporzioni, possiamo usare la funzione prop.test di R. Attenzione che, di default, prop.test effettua una correzione per la continuità (Yates), che in questo contesto disattiviamo per confrontare i risultati con i calcoli manuali (impostando correct = FALSE).\n\n# Dati\nx  &lt;- c(670, 320)      # successi   (lavoratori, non-lavoratori)\nn  &lt;- c(1488, 542)     # denominatori\n\n# Test χ² / z-test per p1 = p2  ── senza correzione di continuità\nout &lt;- prop.test(x, n, correct = FALSE)\n\nout\n#&gt; \n#&gt;  2-sample test for equality of proportions without continuity\n#&gt;  correction\n#&gt; \n#&gt; data:  x out of n\n#&gt; X-squared = 31, df = 1, p-value = 2e-08\n#&gt; alternative hypothesis: two.sided\n#&gt; 95 percent confidence interval:\n#&gt;  -0.18864 -0.09163\n#&gt; sample estimates:\n#&gt; prop 1 prop 2 \n#&gt; 0.4503 0.5904\n\nInterpretazione dei risultati.\n\nIl test dell’ipotesi nulla porta al rifiuto di \\(H_0\\), suggerendo che le proporzioni di successo nei due gruppi non sono uguali.\nL’intervallo di confidenza calcolato non include lo zero, indicando che la differenza osservata è incompatibile con l’assenza di effetto.\nPossiamo quindi concludere che esiste una differenza rilevante tra le proporzioni di successo dei bambini lavoratori e di quelli scolarizzati.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#approccio-bayesiano",
    "href": "chapters/linear_models/12_two_proportions.html#approccio-bayesiano",
    "title": "71  Confronto tra due proporzioni indipendenti",
    "section": "\n71.8 Approccio Bayesiano",
    "text": "71.8 Approccio Bayesiano\nÈ possibile applicare l’approccio bayesiano al problema dell’inferenza sulla differenza tra due proporzioni indipendenti utilizzando un modello di regressione con una variabile indicatrice (dummy) per distinguere i due gruppi. Per fare un esempio, consideriamo qui i problemi astratti. Utilizziamo il pacchetto brms per stimare il modello, con distribuzioni a priori debolmente informative specificate di default.\n\n71.8.1 Dati\n\n# Successi e denominatori\nx_work   &lt;- 670 ; n_work   &lt;- 1488\nx_non    &lt;- 320 ; n_non    &lt;-  542\n\ndat_a &lt;- tibble(\n  count = c(x_work, x_non),\n  tot   = c(n_work, n_non),\n  group = factor(c(\"working\", \"non-working\"),\n                 levels = c(\"non-working\", \"working\"))  # “non-working” livello di riferimento\n)\n\ndat_a\n#&gt; # A tibble: 2 × 3\n#&gt;   count   tot group      \n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;      \n#&gt; 1   670  1488 working    \n#&gt; 2   320   542 non-working\n\n\n71.8.2 Prior debolmente informativi\n\n\nNormal (0, 2.5) sul logit corrisponde ai suggerimenti di Gelman et al. per logistic regression: – copre probabilità grossolanamente tra 0.004 e 0.996 sull’intercetta; – per il coefficiente di gruppo equivale a un odds-ratio plausibile entro ~ e±5.\n\n\npriors &lt;- c(\n  prior(normal(0, 2.5), class = \"Intercept\"),\n  prior(normal(0, 2.5), class = \"b\")\n)\n\n\n71.8.3 Stima del modello\n\nfit_a &lt;- brm(\n  count | trials(tot) ~ group,\n  data      = dat_a,\n  family    = binomial(),\n  prior     = priors,\n  backend   = \"cmdstanr\",\n  seed      = 1234,\n  iter      = 4000, chains = 4, cores = 4,\n  sample_prior = \"yes\"   # utile per i PPC sui prior\n)\n\nControlla rapidamente la convergenza:\n\nprint(fit_a, digits = 3)\n#&gt;  Family: binomial \n#&gt;   Links: mu = logit \n#&gt; Formula: count | trials(tot) ~ group \n#&gt;    Data: dat_a (Number of observations: 2) \n#&gt;   Draws: 4 chains, each with iter = 4000; warmup = 2000; thin = 1;\n#&gt;          total post-warmup draws = 8000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;              Estimate Est.Error l-95% CI u-95% CI  Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept       0.369     0.086    0.201    0.539 1.000     3230     3722\n#&gt; groupworking   -0.569     0.100   -0.766   -0.368 1.001     3929     3843\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\n\npp_check(fit_a, type = \"bars\")   \n\n\n\n\n\n\n\n\n71.8.4 Dalla scala logit alla scala delle probabilità\nIl modello stima\n\\[\n\\operatorname{logit}(p_i)=\\beta_0+\\beta_1\\; \\mathbf 1_{\\text{working},i},\n\\]\nperciò:\n\n\n\n\n\n\nParametro\nSignificato\n\n\n\nβ₀ (b_Intercept)\nlog-odds di successo per non-working\n\n\n\nβ₁ (b_groupworking)\ndifferenza di log-odds fra working e non-working\n\n\n\n\nPer ottenere proporzioni e differenza assoluta (Δ) dobbiamo trasformare ogni draw con l’inversa del logit, plogis().\n\npost &lt;- as_draws_df(fit_a, \n                    variables = c(\"b_Intercept\", \"b_groupworking\")) %&gt;% \n  mutate(\n    p_non  = plogis(b_Intercept),                       # Pr(corretto | non-working)\n    p_work = plogis(b_Intercept + b_groupworking),      # Pr(corretto | working)\n    diff   = p_non - p_work                             # risk-difference\n  )\n\nPerché non basta sottrarre β₁?\nPerché β₁ è una differenza di log-odds. La quantità di interesse qui è la differenza di probabilità. Le due scale sono non lineari e non confrontabili senza trasformazione.\n\n71.8.5 Sintesi della risk–difference\n\n\nsummary_diff &lt;- post %&gt;% \n  summarise(\n    mean     = mean(diff),\n    sd       = sd(diff),\n    `2.5%`   = quantile(diff, .025),\n    `97.5%`  = quantile(diff, .975),\n    prob_gt0 = mean(diff &gt; 0)      # P(Δ &gt; 0 | dati, prior)\n  )\n\nprint(summary_diff, digits = 3)\n#&gt; # A tibble: 1 × 5\n#&gt;    mean     sd `2.5%` `97.5%` prob_gt0\n#&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 0.141 0.0244 0.0918   0.188        1\n\n\n\nΔ (media)\nSD\n95 % CrI\nP(Δ &gt; 0)\n\n\n0.140\n0.025\n0.090 – 0.190\n1.000\n\n\nIl risultato replica quanto ottenuto con prop.test() (0.14 ± 0.025, IC 0.09–0.19).\n\n71.8.6 Confronto con l’approccio frequentista\n\nprop.test(c(x_work, x_non), c(n_work, n_non), correct = FALSE)\n#&gt; \n#&gt;  2-sample test for equality of proportions without continuity\n#&gt;  correction\n#&gt; \n#&gt; data:  c(x_work, x_non) out of c(n_work, n_non)\n#&gt; X-squared = 31, df = 1, p-value = 2e-08\n#&gt; alternative hypothesis: two.sided\n#&gt; 95 percent confidence interval:\n#&gt;  -0.18864 -0.09163\n#&gt; sample estimates:\n#&gt; prop 1 prop 2 \n#&gt; 0.4503 0.5904\n\n` Le due analisi coincidono: i bambini non-working hanno ~ 14 punti percentuali in più di probabilità di rispondere correttamente.\n\n71.8.7 Perché preferire il Bayesiano?\n\n\nNiente “ipotesi nulla” irreale – lavoriamo direttamente con la distribuzione di Δ.\n\nInterpretazione pronta – il 95 % CrI dice che, dati e prior, Δ è fra 9 e 19 punti %.\n\nFlessibilità – possiamo integrare conoscenza pregressa, fare previsioni, decision-making, ecc.\n\nCon prior debolmente informativi i risultati restano virtualmente identici all’approccio frequentista; in dataset più piccoli o modelli più complessi, la stabilizzazione offerta dai prior diventa però cruciale.\n\n71.8.8 Intervallo di credibilità a densità più alta\nPer ottenere l’intervallo di credibilità (Highest Density Interval, HDI) sulla scala delle probabilità (e non su quella logit), è necessario trasformare manualmente i draw a livello di probabilità e poi calcolare l’HDI su quei valori trasformati. In altre parole:\n\n\nestraiamo i draw posteriori di b_Intercept e b_groupworking;\n\n\ntrasformiamo i valori con la funzione logit-inversa (\\(\\operatorname{logistic}(x) = 1/(1+e^{-x})\\)) per ottenere le probabilità;\n\n\nse ci concentriamo sul solo effetto sulla scala della probabilità (e.g. differenza fra i due gruppi), calcoliamo la differenza tra la probabilità del gruppo “working” e quella del gruppo “reference” per ciascun draw;\n\n\napplichiamo hdi() su queste grandezze trasformate.\n\nDi seguito è fornito il codice R con il workflow completo.\n\nEstrazione draw posteriori.\n\n\npost &lt;- as_draws_df(fit_a)\n\n\n\nCalcolo delle probabilità per ciascun draw. La variabile ‘group’ abbia due livelli:\n\n“working” (effetto =&gt; b_groupworking)\n“non-working” (riferimento =&gt; b_Intercept)\n\n\n\n\npost &lt;- post %&gt;%\n  dplyr::mutate(\n    p_ref      = plogis(b_Intercept),                       # probabilità (referenza)\n    p_working  = plogis(b_Intercept + b_groupworking),      # prob. gruppo working\n    diff_working_ref = p_working - p_ref                    # differenza\n  )\n\n\nCalcolo dell’HDI sull’effetto (o sulle probabilità).\n\n\nHDI per la probabilità del gruppo “working”.\n\n\nhdi_working_prob &lt;- hdi(post$p_working, ci = 0.95)\nhdi_working_prob\n#&gt; 95% HDI: [0.43, 0.48]\n\n\nHDI per la probabilità del gruppo “non-working” (riferimento).\n\n\nhdi_ref_prob &lt;- hdi(post$p_ref, ci = 0.95)\nhdi_ref_prob\n#&gt; 95% HDI: [0.55, 0.63]\n\n\nHDI della differenza fra le due probabilità.\n\n\nhdi_diff &lt;- hdi(post$diff_working_ref, ci = 0.89)\nhdi_diff\n#&gt; 89% HDI: [-0.18, -0.10]\n\nInterpretazione\n\n\nhdi_working_prob fornisce l’HDI al 95% (o al livello che specificato) della probabilità di “successo” del gruppo “working”.\n\n\nhdi_ref_prob fa lo stesso per il gruppo di riferimento.\n\n\nhdi_diff restituisce l’HDI della differenza in probabilità tra “working” e “reference” (\\(p_{\\text{working}} - p_{\\text{reference}}\\)).\n\nIn questo modo ottieniamo l’intervallo di credibilità (HDI) sulla scala delle probabilità.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#riflessioni-conclusive",
    "href": "chapters/linear_models/12_two_proportions.html#riflessioni-conclusive",
    "title": "71  Confronto tra due proporzioni indipendenti",
    "section": "\n71.9 Riflessioni Conclusive",
    "text": "71.9 Riflessioni Conclusive\nIn questo capitolo abbiamo esplorato il confronto tra due proporzioni adottando sia l’approccio frequentista sia quello bayesiano. L’obiettivo principale era valutare se la proporzione di successi in un gruppo differisse da quella osservata nell’altro gruppo, e con quale grado di incertezza.\nNella procedura classica frequentista (test per due proporzioni), si calcola una statistica di test (ad esempio, un test z) e il relativo p-value, ossia la probabilità di osservare un risultato così estremo (o più) assumendo che le due proporzioni reali siano uguali (ipotesi nulla).\n\n\nIntervallo di confidenza: È possibile costruire un intervallo di confidenza (IC) per la differenza tra le due proporzioni. L’interpretazione frequentista di tale IC, però, si basa su un’ipotetica ripetizione di campionamenti ed è focalizzata sull’eventuale rifiuto o meno dell’ipotesi che la differenza sia zero.\n\n\nLimiti interpretativi: L’approccio frequentista si fonda sul concetto di ipotesi nulla “nessuna differenza” e non fornisce una probabilità diretta di quanto la differenza vera sia maggiore o minore di un certo valore, limitandosi a indicare se i dati sono inusuali qualora la differenza fosse zero.\n\nGrazie alla regola di Bayes, combiniamo informazioni a priori (sul probabile valore delle proporzioni) con i dati osservati, per ottenere una distribuzione a posteriori della differenza tra le due proporzioni. Questa distribuzione descrive i valori plausibili della differenza, insieme alle relative credibilità (probabilità).\n\n\nCredible Interval o Highest Density Interval (HDI): Al posto di un intervallo di confidenza, l’approccio bayesiano fornisce un intervallo di credibilità. Ad esempio, un 95% HDI indica i valori della differenza tra le proporzioni che cumulativamente contengono il 95% della probabilità a posteriori. È un costrutto immediatamente interpretabile: “Abbiamo una probabilità del 95% che la differenza vera cada all’interno di questo intervallo”.\n\n\nFlessibilità e interpretazione diretta: L’approccio bayesiano permette di rispondere in modo più naturale a domande come: “Qual è la probabilità che la differenza fra le due proporzioni sia maggiore di 0?” oppure “Qual è la probabilità che la proporzione di un gruppo superi quella dell’altro di almeno una certa soglia rilevante?”.\n\nConfronto tra i due approcci:\n\n\nInterpretazione dei risultati: Il p-value frequentista ci dice quanto il dato sia “improbabile” sotto l’ipotesi di uguaglianza delle proporzioni; il Bayesianesimo risponde direttamente a quanto è plausibile ogni possibile valore di differenza.\n\n\nCentralità dell’ipotesi nulla: Nel frequentismo, l’ipotesi nulla (differenza = 0) è centrale. Nel modello bayesiano, è invece possibile assegnare direttamente probabilità alla differenza e alla sua distanza da zero, evitando un focus eccessivo sull’uguaglianza perfetta delle due proporzioni.\n\n\nRuolo dei priors: L’uso di priors (non informativi o informativi) può influire sulle stime bayesiane quando i dati sono scarsi, rendendo evidente la necessità di scelte trasparenti e ben motivate. Tuttavia, con campioni ampi, l’influenza dei priors tende a ridursi e la stima a posteriori è dominata dai dati.\n\n\nCompletezza dell’inferenza: L’approccio bayesiano consente di integrare nuove informazioni e di aggiornare la distribuzione a posteriori man mano che arrivano dati aggiuntivi. Al contrario, l’approccio frequentista non fornisce un meccanismo diretto di “aggiornamento” delle stime alla luce di nuovi dati.\n\nIn sintesi,\n\n\napproccio frequentista: Si tratta di una metodologia consolidata e standard nella ricerca; fornisce risultati in termini di p-value e IC, ma l’interpretazione del p-value e dell’IC resta legata a procedure di campionamento ipotetico.\n\n\napproccio bayesiano: Offre una maniera più intuitiva di quantificare l’incertezza, assegnando probabilità dirette ai possibili valori di differenza fra le due proporzioni. Consente di formulare domande più specifiche (es. la probabilità che la differenza superi un valore definito) e di integrare in modo naturale informazioni a priori.\n\nNella pratica della ricerca, l’approccio frequentista rimane diffuso. Tuttavia, l’inferenza bayesiana fornisce un quadro interpretativo più ricco e flessibile. Utilizzare entrambi i metodi, quando appropriato, può potenziare l’analisi e la comprensione dei dati, permettendo di trarre conclusioni più robuste e trasparenti.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/12_two_proportions.html#informazioni-sullambiente-di-sviluppo",
    "title": "71  Confronto tra due proporzioni indipendenti",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] insight_1.2.0     bayestestR_0.15.3 posterior_1.6.1   cmdstanr_0.9.0   \n#&gt;  [5] brms_2.22.0       Rcpp_1.0.14       thematic_0.1.6    MetBrewer_0.2.0  \n#&gt;  [9] ggokabeito_0.1.0  see_0.11.0        gridExtra_2.3     patchwork_1.3.0  \n#&gt; [13] bayesplot_1.12.0  psych_2.5.3       scales_1.4.0      markdown_2.0     \n#&gt; [17] knitr_1.50        lubridate_1.9.4   forcats_1.0.0     stringr_1.5.1    \n#&gt; [21] dplyr_1.1.4       purrr_1.0.4       readr_2.1.5       tidyr_1.3.1      \n#&gt; [25] tibble_3.2.1      ggplot2_3.5.2     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [29] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1     farver_2.1.2         loo_2.8.0           \n#&gt;  [4] fastmap_1.2.0        tensorA_0.36.2.1     pacman_0.5.1        \n#&gt;  [7] digest_0.6.37        timechange_0.3.0     estimability_1.5.1  \n#&gt; [10] lifecycle_1.0.4      StanHeaders_2.32.10  processx_3.8.6      \n#&gt; [13] magrittr_2.0.3       compiler_4.5.0       rlang_1.1.6         \n#&gt; [16] tools_4.5.0          utf8_1.2.5           yaml_2.3.10         \n#&gt; [19] data.table_1.17.2    labeling_0.4.3       bridgesampling_1.1-2\n#&gt; [22] htmlwidgets_1.6.4    curl_6.2.2           pkgbuild_1.4.7      \n#&gt; [25] mnormt_2.1.1         plyr_1.8.9           RColorBrewer_1.1-3  \n#&gt; [28] abind_1.4-8          withr_3.0.2          stats4_4.5.0        \n#&gt; [31] grid_4.5.0           colorspace_2.1-1     inline_0.3.21       \n#&gt; [34] xtable_1.8-4         emmeans_1.11.1       cli_3.6.5           \n#&gt; [37] mvtnorm_1.3-3        rmarkdown_2.29       generics_0.1.4      \n#&gt; [40] RcppParallel_5.1.10  rstudioapi_0.17.1    reshape2_1.4.4      \n#&gt; [43] tzdb_0.5.0           rstan_2.32.7         parallel_4.5.0      \n#&gt; [46] matrixStats_1.5.0    vctrs_0.6.5          V8_6.0.3            \n#&gt; [49] Matrix_1.7-3         jsonlite_2.0.0       hms_1.1.3           \n#&gt; [52] glue_1.8.0           codetools_0.2-20     ps_1.9.1            \n#&gt; [55] distributional_0.5.0 stringi_1.8.7        gtable_0.3.6        \n#&gt; [58] QuickJSR_1.7.0       pillar_1.10.2        htmltools_0.5.8.1   \n#&gt; [61] Brobdingnag_1.2-9    R6_2.6.1             rprojroot_2.0.4     \n#&gt; [64] evaluate_1.0.3       lattice_0.22-7       backports_1.5.0     \n#&gt; [67] rstantools_2.4.0     coda_0.19-4.1        nlme_3.1-168        \n#&gt; [70] checkmate_2.3.2      xfun_0.52            pkgconfig_2.0.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_two_proportions.html#bibliografia",
    "href": "chapters/linear_models/12_two_proportions.html#bibliografia",
    "title": "71  Confronto tra due proporzioni indipendenti",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBanerjee, A. V., Bhattacharjee, S., Chattopadhyay, R., Duflo, E., Ganimian, A. J., Rajah, K., & Spelke, E. S. (2025). Children’s arithmetic skills do not transfer between applied and academic mathematics. Nature, 1–9.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Confronto tra due proporzioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html",
    "href": "chapters/linear_models/13_poisson_model.html",
    "title": "\n72  Modello di Poisson\n",
    "section": "",
    "text": "72.1 Introduzione\nIn questo capitolo percorriamo l’intero processo che porta dall’idea di contare un evento raro – le sparatorie fatali da parte della polizia statunitense – alla stima del suo tasso medio annuo attraverso un modello di Poisson implementato con il pacchetto brms. Per contestualizzare il fenomeno si suggerisce di leggere l’articolo Racial Disparities in Police Use of Deadly Force Against Unarmed Individuals Persist After Appropriately Benchmarking Shooting Data on Violent Crime Rates (Ross et al., 2021). Non è obbligatorio per seguire il capitolo, ma fornisce lo sfondo sociale e metodologico dei dati che stiamo per analizzare.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#perché-un-modello-di-poisson",
    "href": "chapters/linear_models/13_poisson_model.html#perché-un-modello-di-poisson",
    "title": "\n72  Modello di Poisson\n",
    "section": "\n72.2 Perché un modello di Poisson?",
    "text": "72.2 Perché un modello di Poisson?\nQuando il fenomeno di interesse è un conteggio – per esempio il numero di incidenti, diagnosi o, come nel nostro caso, sparatorie in un anno – la distribuzione di Poisson è spesso una scelta naturale. Questa distribuzione è definita da un solo parametro, \\(\\lambda\\), che rappresenta la media (e varianza) del conteggio. In altre parole, se conosci \\(\\lambda\\) conosci già la forma completa della distribuzione.\nPer non appesantire la lettura ricordiamo qui solo l’essenziale: se \\(Y\\) è il numero di eventi osservati in un certo intervallo di tempo, dire che\n\\[\nY \\sim \\text{Poisson}(\\lambda)\n\\]\nsignifica che la probabilità di osservare esattamente \\(k\\) eventi è\n\\[\nP(Y = k) = \\frac{e^{-\\lambda}\\, \\lambda^{k}}{k!}, \\quad k = 0,1,2,\\dots\n\\]",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#come-brms-codifica-lambda",
    "href": "chapters/linear_models/13_poisson_model.html#come-brms-codifica-lambda",
    "title": "\n72  Modello di Poisson\n",
    "section": "\n72.3 Come brms codifica \\(\\lambda\\)\n",
    "text": "72.3 Come brms codifica \\(\\lambda\\)\n\nIl pacchetto brms, così come la maggior parte dei software di regressione, non stima \\(\\lambda\\) direttamente. Per garantire che il tasso rimanga positivo adotta un link logaritmico: all’interno del modello viene quindi stimata la quantità\n\\[\n\\eta = \\log(\\lambda).\n\\]\nNel caso più semplice, senza predittori, brms utilizza un solo coefficiente, l’intercetta b_Intercept, che è proprio l’equivalente di \\(\\eta\\). Una volta ottenuti i campioni posteriori di b_Intercept è sufficiente applicare l’esponenziale per tornare sul piano di \\(\\lambda\\):\nlambda &lt;- exp(b_Intercept)  # trasforma log-lambda in lambda\nOgni volta che in questo capitolo nomineremo “campioni di \\(\\lambda\\)” sottintenderemo che abbiamo già eseguito questa trasformazione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#la-domanda-di-ricerca",
    "href": "chapters/linear_models/13_poisson_model.html#la-domanda-di-ricerca",
    "title": "\n72  Modello di Poisson\n",
    "section": "\n72.4 La domanda di ricerca",
    "text": "72.4 La domanda di ricerca\nGrazie all’archivio pubblico del Washington Post disponiamo di tutti i casi di sparatorie fatali accadute negli Stati Uniti dal 2015 in poi. L’interesse è stimare quante se ne verificano in media in un anno e descrivere l’incertezza associata a tale stima.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#importiamo-e-prepariamo-i-dati",
    "href": "chapters/linear_models/13_poisson_model.html#importiamo-e-prepariamo-i-dati",
    "title": "\n72  Modello di Poisson\n",
    "section": "\n72.5 Importiamo e prepariamo i dati",
    "text": "72.5 Importiamo e prepariamo i dati\n\nurl &lt;- \"https://raw.githubusercontent.com/washingtonpost/data-police-shootings/master/v2/fatal-police-shootings-data.csv\"\nraw &lt;- read.csv(url, stringsAsFactors = FALSE)\nraw$date &lt;- as.Date(raw$date)\nraw$year &lt;- lubridate::year(raw$date)\n\n# Escludiamo il 2025 perché l’anno è ancora in corso e i dati sarebbero incompleti\nshootings &lt;- subset(raw, year &lt; 2025)\n\ndf &lt;- shootings %&gt;%\n  dplyr::count(year, name = \"events\")\n\n\nhead(df)\n#&gt;   year events\n#&gt; 1 2015    995\n#&gt; 2 2016    959\n#&gt; 3 2017    984\n#&gt; 4 2018    992\n#&gt; 5 2019    993\n#&gt; 6 2020   1021\n\nA questo punto abbiamo una tabella df con due colonne: year, che va dal 2015 al 2024, ed events, che contiene il numero di sparatorie registrate in ciascun anno.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#specificare-la-distribuzione-a-priori",
    "href": "chapters/linear_models/13_poisson_model.html#specificare-la-distribuzione-a-priori",
    "title": "\n72  Modello di Poisson\n",
    "section": "\n72.6 Specificare la Distribuzione a Priori",
    "text": "72.6 Specificare la Distribuzione a Priori\nPrima di osservare i dati vogliamo dichiarare che, secondo la nostra conoscenza precedente, un intervallo plausibile per \\(\\lambda\\) va grosso modo da 400 a 900 casi l’anno, con media attorno a 600. Per ottenere una distribuzione lognormale con queste caratteristiche possiamo lavorare sulla scala logaritmica e scegliere normal(6.4, 0.3). Il valore 6.4 è infatti il logaritmo naturale di 600; la deviazione 0.3 produce l’ampiezza desiderata dell’intervallo. In brms la specifica è molto compatta:\n\nprior_lambda &lt;- prior(normal(6.4, 0.3), class = \"Intercept\")",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#adattare-il-modello-in-brms",
    "href": "chapters/linear_models/13_poisson_model.html#adattare-il-modello-in-brms",
    "title": "\n72  Modello di Poisson\n",
    "section": "\n72.7 Adattare il modello in brms\n",
    "text": "72.7 Adattare il modello in brms\n\nIl cuore dell’analisi si riduce a poche righe, perché il linguaggio di brms è pensato per assomigliare alla formula syntax di lm:\n\nm0 &lt;- brm(\n  events ~ 1,                  # ~1 indica solo l’intercetta\n  family = poisson(),          # distribuzione di errore\n  data   = df,\n  prior  = prior_lambda,\n  iter   = 3000,\n  warmup = 1000,\n  chains = 4,\n  seed   = 123,\n  backend = \"cmdstanr\"\n)\n\nIl comando produce più di quattromila campioni posteriori (\\(1000\\) di warm‑up per ciascuna delle quattro catene + \\(2000\\) validi) dell’intercetta logaritmica. Le diagnosi di convergenza – \\(\\hat R\\) vicino a 1, effective sample size buona – sono riportate da summary(m0).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#dalla-scala-log-a-lambda",
    "href": "chapters/linear_models/13_poisson_model.html#dalla-scala-log-a-lambda",
    "title": "\n72  Modello di Poisson\n",
    "section": "\n72.8 Dalla scala log a \\(\\lambda\\)\n",
    "text": "72.8 Dalla scala log a \\(\\lambda\\)\n\nPer passare dalla stima di b_Intercept alla stima di \\(\\lambda\\) basta eseguire l’esponenziale sui campioni posteriori. Usando tidybayes l’operazione è quasi in linguaggio naturale:\n\nposterior_lambda &lt;- m0 |&gt;\n  spread_draws(b_Intercept) |&gt;\n  mutate(lambda = exp(b_Intercept))\n\nposterior_lambda |&gt;\n  median_qi(lambda, .width = 0.94)\n#&gt; # A tibble: 1 × 6\n#&gt;   lambda .lower .upper .width .point .interval\n#&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    \n#&gt; 1  1043.  1023.  1062.   0.94 median qi\n\nL’output ci dice che il valore più credibile di \\(\\lambda\\) è intorno a 1043 casi l’anno, con un intervallo di credibilità al 94 % che va all’incirca da 1023 a 1062.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#visualizzare-la-distribuzione-a-posteriori",
    "href": "chapters/linear_models/13_poisson_model.html#visualizzare-la-distribuzione-a-posteriori",
    "title": "\n72  Modello di Poisson\n",
    "section": "\n72.9 Visualizzare la distribuzione a posteriori",
    "text": "72.9 Visualizzare la distribuzione a posteriori\nUn grafico spesso vale più di mille numeri. Con ggplot2 e il tema che abbiamo impostato all’inizio la figura è pronta in tre righe:\n\nposterior_lambda |&gt;\n  ggplot(aes(x = lambda)) +\n  stat_halfeye(fill = \"skyblue\", alpha = 0.6) +\n  labs(\n    title = \"Distribuzione a posteriori del tasso λ\",\n    x = \"Tasso annuo di sparatorie fatali (λ)\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\nL’area più scura al centro dell’half‑eye mette in evidenza l’intervallo più denso del 50 %; l’intera “pena” laterale dell’arco rappresenta invece il 94 %.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#unestensione-confronto-tra-gruppi",
    "href": "chapters/linear_models/13_poisson_model.html#unestensione-confronto-tra-gruppi",
    "title": "\n72  Modello di Poisson\n",
    "section": "\n72.10 Un’estensione: confronto tra gruppi",
    "text": "72.10 Un’estensione: confronto tra gruppi\nFinora abbiamo trattato tutte le sparatorie fatali come se provenissero da un’unica popolazione. Una domanda molto concreta, invece, è se il tasso di vittime disarmate differisce tra persone classificate come bianche (codice W nel dataset) e tutte le altre. Per rispondere ci basta duplicare lo schema già usato: al posto di un solo tasso medio (λ) ne stimiamo due, uno per ciascun gruppo.\n\n72.10.1 Costruire il dataset\nIl primo passo è filtrare le righe che ci interessano (vittime disarmate) e poi contare, per ogni anno, quante di queste vittime appartengono a ciascun gruppo. Il codice qui sotto svolge tutto il lavoro di preparazione in un’unica catena di operazioni:\n\nurl &lt;- \"https://raw.githubusercontent.com/washingtonpost/data-police-shootings/master/v2/fatal-police-shootings-data.csv\"\n\ndf_groups &lt;- read.csv(url, stringsAsFactors = FALSE) |&gt;\n  dplyr::mutate(\n    date  = as.Date(date),\n    year  = lubridate::year(date),\n    group = dplyr::if_else(race == \"W\", \"White\", \"NonWhite\")\n  ) |&gt;\n  dplyr::filter(year &lt; 2025, armed_with == \"unarmed\") |&gt;\n  dplyr::count(year, group, name = \"events\")\n\nIn df_groups ogni riga è l’abbinamento tra un anno e un gruppo, con il relativo conteggio di vittime disarmate.\n\n72.10.2 Specificare il modello\nLa formula events ~ 0 + group dice a brms di rinunciare a un’intercetta comune e di stimarne una diversa per ogni valore di group. Poiché l’intercetta è, in scala logaritmica, il nostro parametro centrale, otteniamo due log‑tassi distinti.\nPer la prior partiamo dall’idea che, in ciascun gruppo, potremmo aspettarci circa trenta vittime disarmate l’anno ma con incertezza ampia. Lavorando nella scala log questo si traduce in una distribuzione Normale con media 3.4 e deviazione 0.3 applicata indistintamente alle due intercette:\n\nprior_race &lt;- prior(normal(3.4, 0.3), class = \"b\")\n\nIl modello completo è ora immediato:\n\nm_groups &lt;- brm(\n  events ~ 0 + group,\n  family  = poisson(),\n  data    = df_groups,\n  prior   = prior_race,\n  iter    = 3000, warmup = 1000, chains = 4,\n  backend = \"cmdstanr\", seed = 123\n)\n\n\n72.10.3 Dal log‑tasso al tasso annuale\nDopo aver controllato che tutti gli indicatori di convergenza (in particolare R‑hat) siano a posto, trasformiamo i campioni posteriori con l’esponenziale così da tornare alla scala dei tassi veri e propri:\n\npost &lt;- as_draws_df(m_groups) |&gt;\n  dplyr::transmute(\n    lambda_White    = exp(b_groupWhite),\n    lambda_NonWhite = exp(b_groupNonWhite),\n    diff_lambda     = lambda_NonWhite - lambda_White\n  )\n\nCon tidybayes riassumiamo in una riga le quantità d’interesse, usando ad esempio un intervallo di credibilità al 94 %:\n\npost |&gt;\n  median_qi(lambda_White, lambda_NonWhite, diff_lambda, .width = 0.94)\n#&gt; # A tibble: 1 × 12\n#&gt;   lambda_White lambda_White.lower lambda_White.upper lambda_NonWhite\n#&gt;          &lt;dbl&gt;              &lt;dbl&gt;              &lt;dbl&gt;           &lt;dbl&gt;\n#&gt; 1         22.5               19.9               25.4            34.1\n#&gt;   lambda_NonWhite.lower lambda_NonWhite.upper diff_lambda diff_lambda.lower\n#&gt;                   &lt;dbl&gt;                 &lt;dbl&gt;       &lt;dbl&gt;             &lt;dbl&gt;\n#&gt; 1                  30.9                  37.6        11.6              7.21\n#&gt;   diff_lambda.upper .width .point .interval\n#&gt;               &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    \n#&gt; 1              16.0   0.94 median qi\n\nNe risulta che il gruppo NonWhite registra in media circa 12 vittime disarmate in più l’anno rispetto al gruppo White; l’intero intervallo di credibilità rimane sopra lo zero, perciò l’ipotesi di un tasso maggiore fra le persone non bianche è fortemente supportata dai dati.\nCon due soli cambiamenti – la variabile group nella formula e una prior ragionevole per ciascun gruppo – abbiamo esteso il modello di Poisson a una comparazione fra categorie. Tutto il resto resta identico: link logaritmico, diagnostica delle catene, trasformazione a valle dei campioni. Una volta compreso questo meccanismo, aggiungere ulteriori gruppi o predittori diventa un esercizio di routine.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#riflessioni-conclusive",
    "href": "chapters/linear_models/13_poisson_model.html#riflessioni-conclusive",
    "title": "\n72  Modello di Poisson\n",
    "section": "\n72.11 Riflessioni Conclusive",
    "text": "72.11 Riflessioni Conclusive\nIl modello di Poisson con prior informativa e link logaritmico è un punto di partenza potente e relativamente semplice per modellare conteggi. L’implementazione in brms riduce la complessità sintattica al minimo, ma non per questo dobbiamo tralasciare di capire cosa accade dietro le quinte:\n\n\n\\(\\lambda\\) è il vero protagonista, ma viene stimato indirettamente tramite la sua trasformazione logaritmica.\nLa scelta della prior su b_Intercept va fatta nella scala log, pensando però a cosa significa nella scala originale.\nUna volta compreso il passaggio dall’intercetta logaritmica al tasso \\(\\lambda\\), è possibile arricchire il modello con più predittori, sapendo esattamente come trasformare il modello.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#esercizi",
    "href": "chapters/linear_models/13_poisson_model.html#esercizi",
    "title": "\n72  Modello di Poisson\n",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nNella finale olimpica di calcio 2024, la Spagna ha sconfitto la Francia per 5 a 3. Supponiamo di voler calcolare la probabilità di superiorità della Spagna rispetto alla Francia utilizzando un modello coniugato Gamma-Poisson (o l’approssimazione brms con prior lognormale).\n\nConsidera che il numero di gol segnati da una squadra segua una Poisson con parametro \\(\\lambda\\).\n\nSpecifica un prior su \\(\\lambda\\) per entrambe le squadre, ad esempio \\(\\alpha=1\\) e \\(\\beta=1\\) nella parametrizzazione Gamma classica (oppure una Normal(0,1.4) sull’intercetta, in modo da avere una media a posteriori analoga).\n\nAggiorna la distribuzione a posteriori conoscendo i gol segnati (5 per la Spagna e 3 per la Francia in una singola partita).\n\nCalcola la probabilità che \\(\\lambda_{\\text{Spagna}} &gt; \\lambda_{\\text{Francia}}\\).\n\n(Ispirato a “The World Cup Problem”, (Downey, 2021).)\nSuggerimento: puoi risolvere il problema in modo analitico (Gamma-Poisson con un solo conteggio) oppure puoi usare brms costruendo un dataframe:\n\ndf_soccer &lt;- data.frame(\n  team = c(\"Spain\", \"France\"),\n  goals = c(5, 3)\n)\n\n\nModello: goals ~ 0 + team, family=poisson().\nPrior su b_teamSpain e b_teamFrance.\nInfine, estrai i draws e calcola la probabilità \\(\\Pr(\\exp(b_{\\text{Spain}}) &gt; \\exp(b_{\\text{France}}))\\).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/13_poisson_model.html#informazioni-sullambiente-di-sviluppo",
    "title": "\n72  Modello di Poisson\n",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] tidybayes_3.0.7  brms_2.22.0      Rcpp_1.0.14      HDInterval_0.2.4\n#&gt;  [5] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [9] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.12.0 psych_2.5.3     \n#&gt; [13] scales_1.4.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [17] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [21] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.2   \n#&gt; [25] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1     svUnit_1.0.6         farver_2.1.2        \n#&gt;  [4] loo_2.8.0            fastmap_1.2.0        tensorA_0.36.2.1    \n#&gt;  [7] pacman_0.5.1         digest_0.6.37        timechange_0.3.0    \n#&gt; [10] estimability_1.5.1   lifecycle_1.0.4      StanHeaders_2.32.10 \n#&gt; [13] processx_3.8.6       magrittr_2.0.3       posterior_1.6.1     \n#&gt; [16] compiler_4.5.0       rlang_1.1.6          tools_4.5.0         \n#&gt; [19] utf8_1.2.5           yaml_2.3.10          data.table_1.17.2   \n#&gt; [22] labeling_0.4.3       bridgesampling_1.1-2 htmlwidgets_1.6.4   \n#&gt; [25] curl_6.2.2           pkgbuild_1.4.7       mnormt_2.1.1        \n#&gt; [28] RColorBrewer_1.1-3   cmdstanr_0.9.0       abind_1.4-8         \n#&gt; [31] withr_3.0.2          stats4_4.5.0         grid_4.5.0          \n#&gt; [34] colorspace_2.1-1     inline_0.3.21        xtable_1.8-4        \n#&gt; [37] emmeans_1.11.1       cli_3.6.5            mvtnorm_1.3-3       \n#&gt; [40] rmarkdown_2.29       generics_0.1.4       RcppParallel_5.1.10 \n#&gt; [43] rstudioapi_0.17.1    tzdb_0.5.0           rstan_2.32.7        \n#&gt; [46] parallel_4.5.0       matrixStats_1.5.0    vctrs_0.6.5         \n#&gt; [49] V8_6.0.3             Matrix_1.7-3         jsonlite_2.0.0      \n#&gt; [52] hms_1.1.3            arrayhelpers_1.1-0   ggdist_3.3.3        \n#&gt; [55] glue_1.8.0           codetools_0.2-20     ps_1.9.1            \n#&gt; [58] distributional_0.5.0 stringi_1.8.7        gtable_0.3.6        \n#&gt; [61] QuickJSR_1.7.0       pillar_1.10.2        htmltools_0.5.8.1   \n#&gt; [64] Brobdingnag_1.2-9    R6_2.6.1             rprojroot_2.0.4     \n#&gt; [67] evaluate_1.0.3       lattice_0.22-7       backports_1.5.0     \n#&gt; [70] rstantools_2.4.0     coda_0.19-4.1        nlme_3.1-168        \n#&gt; [73] checkmate_2.3.2      xfun_0.52            pkgconfig_2.0.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_poisson_model.html#bibliografia",
    "href": "chapters/linear_models/13_poisson_model.html#bibliografia",
    "title": "\n72  Modello di Poisson\n",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nDowney, A. B. (2021). Think Bayes. \" O’Reilly Media, Inc.\".\n\n\nRoss, C. T., Winterhalder, B., & McElreath, R. (2021). Racial disparities in police use of deadly force against unarmed individuals persist after appropriately benchmarking shooting data on violent crime rates. Social Psychological and Personality Science, 12(3), 323–332.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/introduction_frequentist_inference.html",
    "href": "chapters/frequentist_inference/introduction_frequentist_inference.html",
    "title": "Introduzione",
    "section": "",
    "text": "Differenze fondamentali tra i due approcci\nCome discusso nel capitolo dedicato all’interpretazione delle probabilità (25  Interpretazione della probabilità), esistono due principali approcci nell’inferenza statistica: la statistica frequentista e la statistica bayesiana. Entrambi i metodi consentono di trarre conclusioni sulla popolazione di interesse attraverso l’analisi dei dati e vengono utilizzati per stimare quantità sconosciute, formulare previsioni e testare ipotesi. Tuttavia, differiscono nell’interpretazione della probabilità e nel modo in cui integrano le conoscenze pregresse e le evidenze disponibili.",
    "crumbs": [
      "Frequentismo",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/introduction_frequentist_inference.html#differenze-fondamentali-tra-i-due-approcci",
    "href": "chapters/frequentist_inference/introduction_frequentist_inference.html#differenze-fondamentali-tra-i-due-approcci",
    "title": "Introduzione",
    "section": "",
    "text": "Statistica frequentista\nNella statistica frequentista, la probabilità è interpretata come la frequenza relativa di un evento in un numero infinito di prove. Questo approccio assume che il valore vero di un parametro della popolazione sia fisso ma sconosciuto e che debba essere stimato esclusivamente dai dati osservati. Le inferenze statistiche vengono effettuate attraverso metodi quali:\n\nStima puntuale: fornisce un singolo valore come miglior stima del parametro.\nIntervalli di confidenza: definiscono un intervallo in cui il parametro si trova con una data probabilità, sotto ripetute campionature.\nTest di ipotesi: valutano la compatibilità dei dati con un’ipotesi nulla, attraverso il calcolo di p-value e statistiche test.\n\nQuesto approccio si basa su assunzioni riguardanti il processo che genera i dati e sull’idea che la verità statistica emerga dal comportamento asintotico di esperimenti ripetuti.\n\n\nStatistica bayesiana\nNella statistica bayesiana, la probabilità rappresenta un grado di credenza in un evento, soggetto ad aggiornamento alla luce di nuove evidenze (Jaynes, 2003). Questo approccio si fonda sull’applicazione del teorema di Bayes, che consente di aggiornare la conoscenza su un parametro in base ai dati osservati.\n\nIl valore del parametro è trattato come una variabile casuale con una distribuzione di probabilità.\nL’analisi parte da una distribuzione a priori, che rappresenta la conoscenza precedente.\nI nuovi dati vengono combinati con la distribuzione a priori tramite la verosimiglianza (likelihood).\nIl risultato è la distribuzione a posteriori, che sintetizza l’incertezza aggiornata sul parametro.\n\nQuesto approccio permette di incorporare informazioni pregresse ed è particolarmente utile in contesti con dati limitati o conoscenze precedenti rilevanti.",
    "crumbs": [
      "Frequentismo",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/introduction_frequentist_inference.html#il-problema-dellinduzione-di-hume",
    "href": "chapters/frequentist_inference/introduction_frequentist_inference.html#il-problema-dellinduzione-di-hume",
    "title": "Introduzione",
    "section": "Il problema dell’induzione di Hume",
    "text": "Il problema dell’induzione di Hume\nUna prospettiva utile per comprendere la differenza tra questi due approcci è il problema dell’induzione, formulato da David Hume nel 1739 nel suo A Treatise of Human Nature (Hacking, 2006). Hume solleva un dubbio fondamentale: come possiamo giustificare le inferenze dal passato al futuro? Nessuna quantità di osservazioni passate garantisce che il futuro seguirà lo stesso schema.\n\nL’approccio frequentista presuppone implicitamente che il mondo segua regolarità statistiche costanti. Tuttavia, questo assunto è vulnerabile alle critiche di Hume, poiché non offre una giustificazione epistemica all’estrapolazione del passato.\nL’approccio bayesiano integra l’incertezza nell’inferenza: la probabilità di un evento futuro è un riflesso delle nostre credenze attuali e viene aggiornata alla luce di nuove osservazioni. Questo approccio si adatta meglio a situazioni in cui il mondo potrebbe non seguire regolarità fisse.",
    "crumbs": [
      "Frequentismo",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/introduction_frequentist_inference.html#un-esempio-pratico-il-lancio-di-una-moneta",
    "href": "chapters/frequentist_inference/introduction_frequentist_inference.html#un-esempio-pratico-il-lancio-di-una-moneta",
    "title": "Introduzione",
    "section": "Un esempio pratico: il lancio di una moneta",
    "text": "Un esempio pratico: il lancio di una moneta\nConsideriamo il classico esempio del lancio di una moneta per illustrare le differenze tra i due approcci:\n\nFrequentista: definisce la probabilità di ottenere testa come la proporzione di teste osservate in un numero infinito di lanci. La probabilità è una proprietà intrinseca della moneta, indipendente dalle credenze dell’osservatore.\nBayesiano: parte da una distribuzione a priori sulla probabilità della moneta di cadere su testa. Dopo ogni lancio, aggiorna la credenza utilizzando la verosimiglianza, ottenendo una nuova distribuzione a posteriori. Questo metodo riflette un aggiornamento razionale delle credenze alla luce di nuove osservazioni.\n\nL’approccio bayesiano è quindi più flessibile e coerente con la prospettiva di Hume: accetta l’incertezza del futuro e la gestisce attraverso un meccanismo di aggiornamento continuo.",
    "crumbs": [
      "Frequentismo",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/introduction_frequentist_inference.html#obiettivo-di-questa-sezione",
    "href": "chapters/frequentist_inference/introduction_frequentist_inference.html#obiettivo-di-questa-sezione",
    "title": "Introduzione",
    "section": "Obiettivo di questa sezione",
    "text": "Obiettivo di questa sezione\nIn questa sezione della dispensa, esamineremo in dettaglio i metodi della statistica frequentista, tra cui la stima puntuale, gli intervalli di confidenza e il test di ipotesi. Questi strumenti costituiscono il nucleo dell’inferenza statistica tradizionale e offrono un quadro solido per analizzare i dati in assenza di informazioni pregresse. Tuttavia, come evidenziato dal problema di Hume, ogni approccio ha i suoi limiti e presupposti. La scelta tra frequentismo e bayesianesimo dipende dal contesto e dagli obiettivi dell’analisi.",
    "crumbs": [
      "Frequentismo",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/introduction_frequentist_inference.html#bibliografia",
    "href": "chapters/frequentist_inference/introduction_frequentist_inference.html#bibliografia",
    "title": "Introduzione",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nHacking, I. (2006). The emergence of probability: A philosophical study of early ideas about probability, induction and statistical inference. Cambridge University Press.\n\n\nJaynes, E. T. (2003). Probability theory: The logic of science. Cambridge University Press.",
    "crumbs": [
      "Frequentismo",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html",
    "title": "73  Inferenza frequentista",
    "section": "",
    "text": "73.1 Introduzione\nIn questo capitolo esamineremo le radici storiche della statistica frequentista e le sue connessioni con il movimento eugenetico. Vedremo come alcune idee sviluppate nel contesto di questa corrente abbiano influenzato l’elaborazione dei metodi statistici che molti di noi utilizzano ancora oggi.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>Inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#i-frequentisti-sono-razzisti",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#i-frequentisti-sono-razzisti",
    "title": "73  Inferenza frequentista",
    "section": "\n73.2 I Frequentisti sono Razzisti?",
    "text": "73.2 I Frequentisti sono Razzisti?\nNel Capitolo 30, abbiamo esplorato le origini storiche e il contesto culturale che hanno portato all’interpretazione del teorema di Bayes proposta da Richard Price. Quelle origini, legate alla rivoluzione americana, rappresentano il “lato luminoso” del liberalismo moderno.\nLe origini dell’approccio frequentista, invece, si collocano agli antipodi: sono strettamente intrecciate con ciò che potremmo definire la “parte oscura” della modernità. L’avversione per la soggettività, tipica del frequentismo, riflette una visione più rigida e deterministica, distante dall’apertura e dalla flessibilità del pensiero bayesiano.\n\n73.2.1 Francis Galton e l’Eugenetica\nFrancis Galton (1822-1911), cugino di Charles Darwin, fu un esploratore, un medico e un pioniere della meteorologia. Ma il suo contributo più importante, e anche più controverso, riguardò la statistica e lo studio dell’ereditarietà del talento.\n\n\nDistribuzione Normale e Regressione\nGalton formalizzò la distribuzione normale e introdusse il concetto di “regressione verso la media”, chiamata inizialmente “regressione verso la mediocrità”.\n\n\nHereditary Genius\nNel suo libro Hereditary Genius, Galton sosteneva che il talento fosse trasmesso all’interno di specifiche famiglie. Fu lui a coniare la famosa espressione “nature and nurture” per indicare il ruolo combinato di eredità e ambiente nello sviluppo umano.\n\n\nEugenetica\nGalton mirava a “migliorare la specie umana” promuovendo la riproduzione tra famiglie ritenute “di successo” e scoraggiandola tra quelle considerate “inferiori”. Le sue idee, fortemente razziste, includevano l’idea che gli africani fossero “inferiori” e “pigri”, gli arabi “semplici consumatori della produzione altrui” e che gli anglosassoni fossero la “razza superiore”.\n\n73.2.2 L’Impatto di Galton su Pearson e Fisher\nLe teorie di Galton influenzarono Karl Pearson (1857-1936) e Ronald Fisher (1890-1962), due figure chiave della statistica moderna. Entrambi condividevano idee razziste e appoggiavano l’eugenetica:\n\n\nKarl Pearson\nProfessore all’University College di Londra, sviluppò strumenti come il test del chi quadrato e la deviazione standard. Ereditò la cattedra di eugenetica fondata da Galton.\n\n\nRonald Fisher\nConsiderato uno dei padri della statistica moderna, sviluppò l’analisi della varianza (ANOVA), il concetto di significatività statistica e il metodo della massima verosimiglianza (MLE).\n\nQuesti autori cercarono di allontanare la statistica dalla prospettiva di Laplace e Bayes, rifiutando l’idea di introdurre componenti soggettive nella loro “scienza”. Volevano che la statistica apparisse del tutto “oggettiva” per sostenere teorie eugenetiche e gerarchie razziali come se fossero dimostrate scientificamente.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>Inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#implicazioni-per-le-pratiche-correnti",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#implicazioni-per-le-pratiche-correnti",
    "title": "73  Inferenza frequentista",
    "section": "\n73.3 Implicazioni per le Pratiche Correnti",
    "text": "73.3 Implicazioni per le Pratiche Correnti\nIn che misura dovremmo considerare le implicazioni storiche ed etiche del frequentismo quando lo utilizziamo oggi? Secondo (Chivers, 2024), sebbene sia evidente che l’ideologia razziale nazista possa essere collegata alle idee di Galton, la questione centrale in statistica rimane: “Quale approccio è metodologicamente corretto?” o, più pragmaticamente, “Quale approccio è più utile?”.\nTuttavia, limitarsi a un dibattito puramente metodologico rischia di trascurare il fatto che la scienza non si svolge in una “torre d’avorio” astratta, ma ha conseguenze concrete. Se una teoria A, pur essendo efficace in uno scenario ideale, ha effetti profondamente negativi nella realtà, dovremmo davvero adottarla acriticamente? La risposta, per molti, è no.\nNel caso del frequentismo, non solo emergono questioni etiche, ma – come vedremo in seguito – si evidenziano anche limiti metodologici. La sua pretesa di “oggettività” si rivela un’illusione quando si analizza in profondità il funzionamento reale delle procedure inferenziali. In psicologia, dove la variabilità individuale e le questioni etiche sono centrali, questi difetti possono avere conseguenze particolarmente dannose.\n\n\n\n\n\n\nNota didattica: L’approccio frequentista viene presentato qui soprattutto per mostrare perché il suo uso esclusivo sia problematico. In questo capitolo descriveremo i fondamenti statistici del frequentismo e la logica delle sue procedure inferenziali. Nel capitoli successivi discuteremo invece come le sue applicazioni pratiche possano ostacolare il progresso della psicologia.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>Inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#il-paradigma-frequentista",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#il-paradigma-frequentista",
    "title": "73  Inferenza frequentista",
    "section": "\n73.4 Il Paradigma Frequentista",
    "text": "73.4 Il Paradigma Frequentista\nL’obiettivo della statistica frequentista è trarre conclusioni su un’intera popolazione partendo da un campione di dati. In questo contesto:\n\nI dati osservati vengono considerati come un’estrazione casuale (un “campione”) da una popolazione più ampia.\n\nIl modello statistico assume che esista un processo generatore dei dati, descritto da una distribuzione di probabilità.\n\nQuando raccogliamo un campione di dati, dobbiamo tenere presente che avremmo potuto ottenere molti altri campioni diversi (il principio di ripetizione del campionamento).\n\n\n73.4.1 Probabilità e Ripetizione del Campionamento\nIl frequentismo adotta un’interpretazione della probabilità basata sulle frequenze: se ripetessimo un esperimento moltissime volte, la probabilità di un evento sarebbe il rapporto tra il numero di volte in cui l’evento si verifica e il numero totale di prove.\n\n73.4.2 Stima di un Parametro\nSupponiamo di voler stimare un parametro (ad esempio, la media di una popolazione). Il frequentismo cerca un stimatore – una funzione del campione – che abbia determinate proprietà, tra cui l’assenza di distorsione (l’unbiasedness) e la consistenza (la vicinanza alla realtà con l’aumentare del numero di dati).\nUn esempio comune è la stima della media della popolazione tramite la media del campione. Sotto certe condizioni, si può dimostrare che, ripetendo l’esperimento moltissime volte, la media del campione in media coinciderà con la vera media della popolazione.\n\n73.4.3 Intervalli di Confidenza\nNell’approccio frequentista, invece di fornire un singolo valore come stima di un parametro, si costruisce un intervallo di confidenza. L’idea fondamentale è che, se ripetessimo molte volte la stessa procedura di campionamento e di calcolo dell’intervallo, una certa percentuale di questi (ad esempio il 95%) conterrà effettivamente il valore vero del parametro.\nPrima di raccogliere i dati, gli estremi di questo intervallo (i “limiti di confidenza”) sono variabili casuali, perché dipendono dal campione che otterremo. Di conseguenza, la probabilità (per esempio, il 95%) si riferisce alla procedura di costruzione dell’intervallo, non all’intervallo in sé dopo l’osservazione dei dati. Una volta infatti che il campione è stato raccolto e l’intervallo è stato calcolato, quest’ultimo è un oggetto “fisso”: o contiene il valore vero del parametro, o non lo contiene; non è più possibile attribuirgli una probabilità di contenere il parametro. L’affermazione “intervallo di confidenza al 95%” significa dunque che, sul lungo periodo, usando sempre la stessa procedura, il 95% degli intervalli costruiti conterrà il parametro vero.\n\n73.4.4 Test delle Ipotesi: Approccio Frequentista e Limitazioni\nNel contesto del test di un’ipotesi (ad esempio, \\(H_0\\): “la media di una popolazione è uguale a 0”), l’approccio frequentista definisce una regione di rifiuto in base a un livello di significatività prefissato (ad esempio, \\(\\alpha = 0.05\\)). Se il risultato dell’analisi (come il p-value) cade all’interno di questa regione, si procede a rifiutare \\(H_0\\); altrimenti, si manca di rifiutare \\(H_0\\) (ovvero, non si rifiuta l’ipotesi nulla).\n\n\nErrore di tipo I (falso positivo): si verifica quando si rifiuta \\(H_0\\) nonostante essa sia vera.\n\n\nErrore di tipo II (falso negativo): si verifica quando non si rifiuta \\(H_0\\) nonostante essa sia falsa.\n\nNel paradigma frequentista, il ricercatore controlla la probabilità di questi errori, in particolare l’errore di tipo I, attraverso la scelta di \\(\\alpha\\) e il calcolo di indicatori come il p-value. Tuttavia, questo approccio presenta alcune criticità:\n\nDecisione dicotomica\nIl test conduce a una scelta binaria (rifiutare o non rifiutare \\(H_0\\)), che può risultare eccessivamente rigida. I fenomeni reali spesso non si prestano a una categorizzazione netta basata su una soglia arbitraria, rendendo la distinzione “significativo/non significativo” potenzialmente fuorviante. Una visione più sfumata, che consideri l’entità dell’effetto e l’incertezza, potrebbe essere più informativa.\nSoglia arbitraria\nIl valore di \\(\\alpha\\) (comunemente fissato a 0.05) è in gran parte una convenzione. Ad esempio, un valore-p di 0.049 porta al rifiuto di \\(H_0\\), mentre un valore-p di 0.051 non lo fa, nonostante la differenza tra i due casi sia minima. Questa arbitrarietà può influenzare in modo significativo l’interpretazione dei risultati, creando una discontinuità artificiale.\nNessuna prova diretta di verità/falsità\nUn valore-p basso non implica che \\(H_0\\) sia “falsa” o che un’ipotesi alternativa sia “vera”. Indica semplicemente che, assumendo \\(H_0\\) vera, dati simili (o più estremi) sarebbero rari sotto ripetuti campionamenti. Il test frequentista non fornisce una risposta alla domanda “Qual è la probabilità che \\(H_0\\) sia vera?”, limitando la sua capacità di supportare inferenze dirette sulla veridicità delle ipotesi.\n\nQueste criticità evidenziano come la rigidità del test (basato su una decisione binaria) e l’uso di soglie fisse possano risultare problematici, specialmente in discipline come la psicologia, dove le misurazioni sono spesso affette da rumore e le differenze tra condizioni possono essere sottili. Un approccio più flessibile, che integri la stima degli effetti, gli intervalli di confidenza e una valutazione contestuale, potrebbe offrire una comprensione più robusta e sfumata dei dati.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>Inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#riflessioni-conclusive",
    "title": "73  Inferenza frequentista",
    "section": "\n73.5 Riflessioni Conclusive",
    "text": "73.5 Riflessioni Conclusive\nIn questo capitolo abbiamo mostrato come la statistica frequentista, pur essendo stata un pilastro dell’inferenza moderna, affondi le proprie radici in idee profondamente problematiche, come l’eugenetica e il razzismo sostenuti da Galton, Pearson e Fisher. Sebbene oggi queste teorie sembrino superate e distanti dalle nostre pratiche di laboratorio, conoscerne la genesi aiuta a comprendere come l’idea di un’oggettività assoluta sia stata impiegata per legittimare visioni ideologiche discutibili.\nParallelamente, la riflessione storica solleva interrogativi sul metodo e sulle sue implicazioni pratiche. La metafora della “torre d’avorio” mostra quanto sia pericoloso trattare la scienza come un sistema chiuso, ignorando le conseguenze etiche e sociali. Nel campo della psicologia, in particolare, la crisi di replicabilità (McElreath, 2020) rivela come l’uso acritico di procedure frequentiste possa influire sulla validità dei risultati.\nIn definitiva, il frequentismo non va considerato solo come un insieme di tecniche, ma come un paradigma con implicazioni culturali, etiche e metodologiche. Nel prossimo capitolo mostreremo come le applicazioni pratiche dell’approccio frequentista possano risultare limitanti e, talvolta, dannose per il progresso della psicologia (Gelman et al., 1995). Conoscere le basi e le implicazioni di tale paradigma è il primo passo per un uso più consapevole e responsabile degli strumenti statistici.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>Inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#informazioni-sullambiente-di-sviluppo",
    "title": "73  Inferenza frequentista",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.12.0 psych_2.5.3     \n#&gt;  [9] scales_1.4.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.2   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.4     stringi_1.8.7      lattice_0.22-7    \n#&gt;  [4] hms_1.1.3          digest_0.6.37      magrittr_2.0.3    \n#&gt;  [7] evaluate_1.0.3     grid_4.5.0         timechange_0.3.0  \n#&gt; [10] RColorBrewer_1.1-3 fastmap_1.2.0      rprojroot_2.0.4   \n#&gt; [13] jsonlite_2.0.0     mnormt_2.1.1       cli_3.6.5         \n#&gt; [16] rlang_1.1.6        withr_3.0.2        tools_4.5.0       \n#&gt; [19] parallel_4.5.0     tzdb_0.5.0         pacman_0.5.1      \n#&gt; [22] vctrs_0.6.5        R6_2.6.1           lifecycle_1.0.4   \n#&gt; [25] htmlwidgets_1.6.4  pkgconfig_2.0.3    pillar_1.10.2     \n#&gt; [28] gtable_0.3.6       glue_1.8.0         xfun_0.52         \n#&gt; [31] tidyselect_1.2.1   rstudioapi_0.17.1  farver_2.1.2      \n#&gt; [34] htmltools_0.5.8.1  nlme_3.1-168       rmarkdown_2.29    \n#&gt; [37] compiler_4.5.0",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>Inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#bibliografia",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#bibliografia",
    "title": "73  Inferenza frequentista",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nChivers, T. (2024). Everything is Predictable: How Bayesian Statistics Explain Our World. Simon; Schuster.\n\n\nGelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (1995). Bayesian data analysis. Chapman; Hall/CRC.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>Inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01a_stime_parametri.html",
    "href": "chapters/frequentist_inference/01a_stime_parametri.html",
    "title": "74  Stime, stimatori e parametri",
    "section": "",
    "text": "74.1 Introduzione\nIn questo capitolo, ci concentreremo sul concetto di distribuzione campionaria, uno dei pilastri dell’inferenza statistica frequentista. La distribuzione campionaria descrive come le stime dei parametri della popolazione, come la media o la varianza, variano da campione a campione. Essa permette di stabilire proprietà probabilistiche delle stime campionarie, come la loro media e varianza, che sono fondamentali per costruire intervalli di confidenza e condurre test di ipotesi, strumenti essenziali dell’inferenza statistica frequentista.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01a_stime_parametri.html#introduzione",
    "href": "chapters/frequentist_inference/01a_stime_parametri.html#introduzione",
    "title": "74  Stime, stimatori e parametri",
    "section": "",
    "text": "Domande introduttive\n\n\n\nPrima di iniziare a esplorare il concetto di distribuzione campionaria e il suo ruolo nell’inferenza statistica, considera le seguenti domande. Prova a formulare una risposta intuitiva basata sulle tue conoscenze attuali prima di procedere con la lettura del capitolo. Le simulazioni che seguiranno ti aiuteranno a confermare o rivedere le tue risposte.\n\nSe estraiamo ripetutamente campioni casuali dalla stessa popolazione e calcoliamo la loro media, come saranno distribuite queste medie campionarie rispetto alla media della popolazione?\nSupponiamo di estrarre campioni di dimensione \\(n=2\\) da una popolazione. L’insieme delle medie campionarie sarà più concentrato intorno alla media della popolazione rispetto ai valori individuali della popolazione stessa?\nQuale relazione esiste tra la dimensione del campione \\(n\\) e la variabilità delle medie campionarie? In altre parole, se aumentiamo la dimensione del campione, cosa succede alla dispersione della distribuzione campionaria?\nLa distribuzione campionaria della media campionaria sarà sempre normale? Quali fattori influenzano la sua forma?\nLa media della distribuzione campionaria coincide sempre con la media della popolazione? E la sua varianza è maggiore o minore rispetto alla varianza della popolazione?\nSupponiamo di estrarre piccoli campioni da una popolazione che ha una distribuzione fortemente asimmetrica. Quale forma avrà la distribuzione delle medie campionarie per piccoli campioni? E per campioni più grandi?",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01a_stime_parametri.html#stime-stimatori-e-parametri",
    "href": "chapters/frequentist_inference/01a_stime_parametri.html#stime-stimatori-e-parametri",
    "title": "74  Stime, stimatori e parametri",
    "section": "\n74.2 Stime, stimatori e parametri",
    "text": "74.2 Stime, stimatori e parametri\nDopo aver esplorato il contesto culturale del frequentismo nel capitolo precedente, ci spostiamo ora su un piano strettamente statistico per introdurre il concetto di stima statistica.\nQuando si analizzano i dati, l’obiettivo è spesso quello di ottenere informazioni su una caratteristica della popolazione. Tuttavia, nella maggior parte dei casi, si ha accesso solo a un campione di osservazioni. La quantità sconosciuta che vogliamo stimare viene chiamata parametro, mentre il valore che calcoliamo dal campione per approssimare questo parametro è la stima. La formula o il procedimento matematico che utilizziamo per ottenere la stima è detto stimatore. Formalmente, uno stimatore è una funzione dei dati osservati utilizzata per produrre una stima di un parametro.\nIn altre parole, quando analizziamo un campione, cerchiamo di inferire proprietà della popolazione da cui il campione è tratto. Il parametro rappresenta una misura di queste proprietà, ma raramente può essere calcolato direttamente sulla popolazione intera. Pertanto, utilizziamo le osservazioni campionarie per ottenere una stima del parametro. La stima è quindi un’approssimazione del valore del parametro basata sui dati raccolti, mentre lo stimatore è la regola matematica o statistica che la produce.\nÈ importante sottolineare che le stime non coincidono necessariamente con il vero valore del parametro, poiché sono soggette a incertezza dovuta alla variabilità del campionamento. In questo capitolo esamineremo come l’approccio frequentista quantifica questa incertezza e come possiamo utilizzare tale quantificazione per trarre conclusioni affidabili sui parametri di interesse.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01a_stime_parametri.html#distribuzione-campionaria",
    "href": "chapters/frequentist_inference/01a_stime_parametri.html#distribuzione-campionaria",
    "title": "74  Stime, stimatori e parametri",
    "section": "\n74.3 Distribuzione campionaria",
    "text": "74.3 Distribuzione campionaria\nNell’inferenza frequentista applicata alla psicologia, il parametro di maggiore interesse è spesso la media della popolazione—si veda anche la discussione nella Sezione 19.9.1. In questo capitolo esploreremo come la media di un campione casuale possa essere utilizzata per stimare la media \\(\\mu\\) di una popolazione. Per valutare l’incertezza associata a questa stima, introdurremo il concetto di distribuzione campionaria, un principio fondamentale dell’approccio frequentista.\nPer chiarire questa idea, inizieremo con un esempio basato su una popolazione finita di piccole dimensioni, pur consapevoli che le proprietà illustrate si estendono anche a popolazioni di dimensioni maggiori.\n\n74.3.1 Esempio introduttivo\nConsideriamo la seguente popolazione:\n\nx &lt;- c(2, 4.5, 5, 5.5)\nx\n#&gt; [1] 2.0 4.5 5.0 5.5\n\nQuesti valori potrebbero rappresentare il tempo di reazione (in secondi) di quattro partecipanti a un esperimento di decisione rapida, in cui devono identificare il colore di uno stimolo visivo. In questo caso, l’intera popolazione è costituita da tutti i partecipanti disponibili per lo studio, ad esempio se l’esperimento è stato condotto in un piccolo gruppo di persone selezionate per caratteristiche specifiche, come quattro gemelli monozigoti in uno studio sulle differenze cognitive intra-familiari.\nL’istogramma sottostante rappresenta la distribuzione di frequenza della popolazione:\n\n# Creazione del dataframe\ndf &lt;- data.frame(Valori = c(2, 4.5, 5, 5.5))\n\n# Istogramma con ggplot2\nggplot(df, aes(x = Valori)) +\n  geom_histogram(bins = 5, aes(y = after_stat(density)), fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Distribuzione della popolazione\", x = \"Valori\", y = \"Densità\") \n\n\n\n\n\n\n\nCalcoliamo la media e la varianza della popolazione:\n\nmean(x)  # Media\n#&gt; [1] 4.25\nvar(x)   # Varianza\n#&gt; [1] 2.417\n\n\n74.3.2 Campionamento\nConsideriamo ora tutti i possibili campioni di dimensione \\(n = 2\\) che possiamo estrarre dalla popolazione. Poiché ogni valore può essere selezionato indipendentemente in entrambe le posizioni del campione, il numero totale di combinazioni possibili si ottiene con il calcolo combinatorio:\n\\[\n\\text{Numero totale di campioni} = k^n ,\n\\]\ndove \\(k\\) è la dimensione della popolazione e \\(n\\) è la dimensione del campione. Nel nostro caso, con \\(k = 4\\) e \\(n = 2\\), otteniamo:\n\\[\n4^2 = 16 .\n\\]\nPossiamo generare esplicitamente queste combinazioni con il seguente codice:\n\nsamples &lt;- expand.grid(x, x)\nsamples\n#&gt;    Var1 Var2\n#&gt; 1   2.0  2.0\n#&gt; 2   4.5  2.0\n#&gt; 3   5.0  2.0\n#&gt; 4   5.5  2.0\n#&gt; 5   2.0  4.5\n#&gt; 6   4.5  4.5\n#&gt; 7   5.0  4.5\n#&gt; 8   5.5  4.5\n#&gt; 9   2.0  5.0\n#&gt; 10  4.5  5.0\n#&gt; 11  5.0  5.0\n#&gt; 12  5.5  5.0\n#&gt; 13  2.0  5.5\n#&gt; 14  4.5  5.5\n#&gt; 15  5.0  5.5\n#&gt; 16  5.5  5.5\n\nOgni riga rappresenta un campione possibile. Confermiamo il numero totale di campioni con:\n\nnrow(samples)\n#&gt; [1] 16\n\nOra calcoliamo la media di ciascun campione, ottenendo la distribuzione campionaria delle medie per \\(n = 2\\):\n\nsample_means &lt;- rowMeans(samples)\nsample_means\n#&gt;  [1] 2.00 3.25 3.50 3.75 3.25 4.50 4.75 5.00 3.50 4.75 5.00 5.25 3.75 5.00\n#&gt; [15] 5.25 5.50\n\nQuesta distribuzione campionaria mostra tutte le possibili medie che possiamo ottenere estraendo campioni casuali di dimensione 2 dalla popolazione. Si tratta di un concetto fondamentale in inferenza statistica frequentista, poiché la distribuzione delle medie campionarie diventa progressivamente più simmetrica e concentrata attorno alla media della popolazione man mano che \\(n\\) aumenta, come previsto dal teorema del limite centrale.\n\n74.3.3 Visualizzazione della distribuzione campionaria\nPossiamo visualizzare la distribuzione campionaria delle medie con un istogramma:\n\n# Creazione del dataframe\ndf &lt;- data.frame(Valori = sample_means)\n\n# Istogramma con ggplot2\nggplot(df, aes(x = Valori)) +\n  geom_histogram(bins = 5, aes(y = after_stat(density)), fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Distribuzione campionaria delle medie (n = 2)\", x = \"Media campionaria\", y = \"Densità\") \n\n\n\n\n\n\n\nL’istogramma mostra come le medie campionarie non siano distribuite uniformemente, ma seguano una struttura precisa determinata dalla distribuzione dei valori originali della popolazione. Con un numero maggiore di osservazioni per campione (\\(n\\) più grande), la distribuzione campionaria delle medie tende a diventare più stretta e simmetrica attorno alla media della popolazione, illustrando così il principio alla base dell’inferenza statistica frequentista.\n\n74.3.4 Verifiche teoriche\n\n74.3.4.1 Media della distribuzione campionaria\nSecondo la teoria statistica, la media della distribuzione campionaria deve coincidere con la media della popolazione. Questo implica che, se prendiamo la media di tutti i campioni possibili di una certa dimensione, il valore risultante sarà uguale alla media della popolazione stessa. Possiamo verificarlo con il seguente calcolo:\n\nmean(x)  # Media della popolazione\n#&gt; [1] 4.25\nmean(sample_means)  # Media della distribuzione campionaria\n#&gt; [1] 4.25\n\n\n74.3.4.2 Varianza della distribuzione campionaria\nUn altro risultato importante è che la varianza della distribuzione campionaria delle medie è inferiore alla varianza della popolazione. In particolare, la teoria prevede che sia pari alla varianza della popolazione divisa per la dimensione del campione \\(n\\):\n\\[\n\\mathbb{V}(\\bar{X}) = \\frac{\\sigma^2}{n}\n\\]\nPoiché in questo caso \\(n = 2\\), confrontiamo la varianza teorica con quella empirica:\n\n# Funzione per calcolare la varianza senza la correzione di Bessel\nvariance &lt;- function(x) {\n  mean((x - mean(x))^2)\n}\n\n\nvariance(x) / 2  # Varianza teorica\n#&gt; [1] 0.9062\nvariance(sample_means)  # Varianza empirica\n#&gt; [1] 0.9062\n\nOsserviamo che la varianza delle medie campionarie è inferiore alla varianza della popolazione, confermando che le medie campionarie mostrano meno variabilità rispetto alle singole osservazioni.\n\n74.3.5 Esempio di campione osservato\nPer comprendere meglio questi concetti, consideriamo un singolo campione, ad esempio:\n\nobserved_sample &lt;- c(5, 5.5)\nobserved_sample\n#&gt; [1] 5.0 5.5\n\nCalcoliamo la sua media e deviazione standard:\n\nmean(observed_sample)  # Media del campione\n#&gt; [1] 5.25\nsqrt(variance(observed_sample))  # Deviazione standard del campione\n#&gt; [1] 0.25\n\nOra confrontiamo questi valori con quelli della popolazione:\n\nmean(x)  # Media della popolazione\n#&gt; [1] 4.25\nsqrt(variance(x))  # Deviazione standard della popolazione\n#&gt; [1] 1.346\n\nOsserviamo che la media del campione si avvicina a quella della popolazione, ma non coincide necessariamente con essa. Questo è del tutto normale: ogni campione rappresenta solo una porzione della popolazione e la sua media può variare leggermente a seconda delle osservazioni selezionate.\nPer quanto riguarda la deviazione standard, in questo caso specifico risulta inferiore a quella della popolazione. Tuttavia, in generale, la dispersione di un singolo campione può essere maggiore o minore rispetto a quella della popolazione, poiché dipende dalla variabilità casuale delle osservazioni estratte. Proprio per questo motivo, per trarre inferenze affidabili sulla popolazione, è più utile considerare la distribuzione campionaria delle medie piuttosto che un singolo campione isolato.\nQuesto esempio illustra bene il principio della stima campionaria: mentre un singolo campione fornisce un’informazione parziale, l’analisi di molteplici campioni consente di ottenere una stima più precisa e stabile della media della popolazione, riducendo l’incertezza e migliorando l’affidabilità dell’inferenza statistica.\n\n74.3.6 La Simulazione Illustra Due Principi\nDalla simulazione emergono due principi fondamentali dell’inferenza statistica:\n\n\nLa media della distribuzione campionaria coincide con la media della popolazione. Questo implica che se estraiamo molteplici campioni di dimensione \\(n\\) e calcoliamo la loro media, il valore atteso della media campionaria sarà uguale alla media della popolazione \\(\\mu\\). Formalmente:\n\\[\n\\mathbb{E}(\\bar{X}_n) = \\mu .\n\\]\nQuesto risultato conferma che la media campionaria è uno stimatore non distorto della media della popolazione.\n\n\nLa varianza della distribuzione campionaria è minore della varianza della popolazione. Questo riflette il fatto che le medie campionarie tendono a essere più stabili rispetto alle singole osservazioni. La relazione teorica che descrive questa proprietà è:\n\\[\n\\mathbb{V}(\\bar{X}) = \\frac{\\sigma^2}{n} .\n\\]\nCiò significa che, aumentando la dimensione del campione \\(n\\), la variabilità delle medie campionarie si riduce, rendendo la stima della media della popolazione più precisa. Questo concetto è alla base della teoria del teorema centrale del limite, che diventa sempre più evidente con campioni di dimensioni maggiori.\n\n\n\n\n\n\n\n\nDimostrazione che \\(\\bar{X}\\) è uno stimatore corretto della media della popolazione\n\n\n\n\n\nDato un campione casuale di \\(n\\) osservazioni \\(X_1, X_2, \\dots, X_n\\) estratte da una popolazione con media \\(\\mu\\) e varianza \\(\\sigma^2\\), la media campionaria è definita come:\n\\[\n\\bar{X}_n = \\frac{1}{n} \\sum_{i=1}^{n} X_i .\n\\]\nUtilizziamo la linearità dell’operatore di aspettativa:\n\\[\n\\mathbb{E}(\\bar{X}_n) = \\mathbb{E} \\left( \\frac{1}{n} \\sum_{i=1}^{n} X_i \\right) .\n\\]\nPer la proprietà della linearità dell’aspettativa, possiamo portare fuori il fattore costante \\(\\frac{1}{n}\\):\n\\[\n\\mathbb{E}(\\bar{X}_n) = \\frac{1}{n} \\sum_{i=1}^{n} \\mathbb{E}(X_i) .\n\\]\nPoiché ogni \\(X_i\\) proviene dalla stessa popolazione, ha la stessa aspettativa \\(\\mathbb{E}(X_i) = \\mu\\), quindi:\n\\[\n\\mathbb{E}(\\bar{X}_n) = \\frac{1}{n} \\sum_{i=1}^{n} \\mu .\n\\]\nSommando \\(n\\) volte \\(\\mu\\), otteniamo:\n\\[\n\\mathbb{E}(\\bar{X}_n) = \\frac{1}{n} (n \\mu) = \\mu .\n\\]\nIn conclusione, abbiamo dimostrato che:\n\\[\n\\mathbb{E}(\\bar{X}_n) = \\mu .\n\\]\nQuesto significa che la media campionaria \\(\\bar{X}_n\\) è uno stimatore corretto (non distorto) della media della popolazione \\(\\mu\\), poiché il suo valore atteso coincide esattamente con la quantità che vogliamo stimare.\n\n\n\n\n\n\n\n\n\nDimostrazione della riduzione della varianza nelle medie campionarie\n\n\n\n\n\nSia \\(X_1, X_2, \\dots, X_n\\) un campione casuale di \\(n\\) osservazioni indipendenti estratte da una popolazione con media \\(\\mu\\) e varianza \\(\\sigma^2\\). La media campionaria è definita come:\n\\[\n\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i.\n\\]\nPer definizione, la varianza di \\(\\bar{X}\\) è:\n\\[\n\\mathbb{V}(\\bar{X}) = \\mathbb{V}\\left(\\frac{1}{n} \\sum_{i=1}^n X_i\\right).\n\\]\nPoiché una costante moltiplicata da una variabile aleatoria può essere “estratta” dalla varianza, otteniamo:\n\\[\n\\mathbb{V}(\\bar{X}) = \\frac{1}{n^2} \\mathbb{V}\\left(\\sum_{i=1}^n X_i\\right).\n\\]\nOra dobbiamo calcolare \\(\\mathbb{V}\\left(\\sum_{i=1}^n X_i\\right)\\). Le variabili \\(X_1, X_2, \\dots, X_n\\) sono indipendenti, quindi la varianza della somma è la somma delle varianze:\n\\[\n\\mathbb{V}\\left(\\sum_{i=1}^n X_i\\right) = \\sum_{i=1}^n \\mathbb{V}(X_i).\n\\]\nPoiché tutte le variabili \\(X_i\\) hanno la stessa varianza \\(\\sigma^2\\):\n\\[\n\\mathbb{V}\\left(\\sum_{i=1}^n X_i\\right) = n \\sigma^2.\n\\]\nSostituendo nella formula precedente, otteniamo:\n\\[\n\\mathbb{V}(\\bar{X}) = \\frac{1}{n^2} \\cdot n \\sigma^2 = \\frac{\\sigma^2}{n}.\n\\]\nIn generale, dunque, per un campione di ampiezza \\(n\\), vale la relazione \\(\\mathbb{V}(\\bar{X}) = \\frac{\\sigma^2}{n}\\).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01a_stime_parametri.html#proprietà-della-distribuzione-campionaria",
    "href": "chapters/frequentist_inference/01a_stime_parametri.html#proprietà-della-distribuzione-campionaria",
    "title": "74  Stime, stimatori e parametri",
    "section": "\n74.4 Proprietà della distribuzione campionaria",
    "text": "74.4 Proprietà della distribuzione campionaria\nUna caratteristica fondamentale della distribuzione campionaria riguarda la sua forma e il modo in cui dipende dalla distribuzione della popolazione da cui vengono estratti i campioni. Possiamo distinguere due casi principali:\n\nSe la popolazione segue una distribuzione normale, allora anche la distribuzione delle medie campionarie sarà normalmente distribuita, indipendentemente dalla dimensione del campione \\(n\\). Questo significa che, anche con campioni molto piccoli, la media campionaria manterrà la stessa forma della distribuzione originale.\nSe la popolazione non segue una distribuzione normale, entra in gioco il teorema centrale del limite. Questo teorema afferma che, man mano che la dimensione del campione \\(n\\) aumenta, la distribuzione delle medie campionarie tenderà comunque a una distribuzione normale, indipendentemente dalla forma della distribuzione di partenza. In pratica, per campioni sufficientemente grandi, possiamo approssimare la distribuzione delle medie campionarie con una normale, anche se la popolazione da cui provengono i dati è asimmetrica o non gaussiana.\n\nQueste proprietà sono fondamentali nell’inferenza statistica frequentista: permettono di stimare e testare parametri della popolazione utilizzando campioni, facilitando l’applicazione di strumenti basati sulla distribuzione normale, come gli intervalli di confidenza e i test di ipotesi.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01a_stime_parametri.html#teorema-del-limite-centrale",
    "href": "chapters/frequentist_inference/01a_stime_parametri.html#teorema-del-limite-centrale",
    "title": "74  Stime, stimatori e parametri",
    "section": "\n74.5 Teorema del Limite Centrale",
    "text": "74.5 Teorema del Limite Centrale\nEsaminiamo ora più in dettaglio il Teorema del Limite Centrale (TLC). Nel 1812, Pierre-Simon Laplace dimostrò il TLC, che afferma che la somma (o la media) di una sequenza di variabili casuali indipendenti e identicamente distribuite (i.i.d.) tende a distribuirsi secondo una distribuzione Normale (o Gaussiana), al crescere della dimensione del campione. Inoltre, il TLC specifica i parametri della distribuzione Normale risultante in base ai valori attesi e alle varianze delle variabili casuali sommate.\n\nTeorema 74.1 Si consideri una sequenza di variabili aleatorie indipendenti e identicamente distribuite (i.i.d.) \\(Y_1, Y_2, \\dots, Y_n\\), con valore atteso \\(\\mathbb{E}(Y_i) = \\mu\\) e deviazione standard \\(\\text{SD}(Y_i) = \\sigma.\\) Si definisca una nuova variabile casuale come la media campionaria:\n\\[\nZ = \\frac{1}{n} \\sum_{i=1}^n Y_i.\n\\]\nAl tendere di \\(n\\) all’infinito (\\(n \\rightarrow \\infty\\)), la distribuzione di \\(Z\\) converge a una distribuzione Normale con valore atteso \\(\\mu\\) e deviazione standard \\(\\frac{\\sigma}{\\sqrt{n}}\\):\n\\[\nZ \\sim \\mathcal{N}\\left(\\mu, \\, \\frac{\\sigma}{\\sqrt{n}} \\right).\n\\]\nIn altre parole, la densità di probabilità di \\(Z\\) tende a:\n\\[\np_Z(z) \\rightarrow \\mathcal{N}\\left(z \\ \\Bigg| \\ \\mu, \\, \\frac{\\sigma}{\\sqrt{n}} \\right).\n\\]\n\nIl TLC può essere generalizzato anche a variabili casuali che non sono identicamente distribuite, purché siano indipendenti e abbiano valori attesi e varianze finite. Questo teorema spiega perché molti fenomeni naturali, come l’altezza degli adulti o il peso di una popolazione, tendono a seguire una distribuzione Normale. Infatti, tali fenomeni sono spesso il risultato di una combinazione di numerosi effetti additivi e indipendenti, ciascuno dei quali contribuisce in modo relativamente piccolo. Indipendentemente dalla distribuzione individuale di ciascun effetto, la loro somma (o media) tende a distribuirsi in modo Normale. Questa è la ragione per cui la distribuzione Normale fornisce una buona approssimazione per la distribuzione di molti fenomeni osservati in natura.\n\n74.5.1 Illustrazione del Teorema del Limite Centrale (TLC)\nPer comprendere il Teorema del Limite Centrale (TLC), consideriamo una popolazione iniziale che segue una distribuzione fortemente asimmetrica: la distribuzione Beta(2,1), caratterizzata da una forte asimmetria positiva.\n\n# Parametri della distribuzione Beta\na &lt;- 2\nb &lt;- 1\n\n# Genera valori per la distribuzione Beta\nx &lt;- seq(0, 1, length.out = 1000)  # Valori tra 0 e 1\ny &lt;- dbeta(x, shape1 = a, shape2 = b)  # Densità della distribuzione Beta\n\n# Crea un dataframe per qplot\ndata &lt;- data.frame(x = x, y = y)\n\n# Grafico con qplot\nqplot(x, y, data = data, geom = \"line\", \n      main = \"Distribuzione Beta(2, 1)\", \n      xlab = \"x\", \n      ylab = \"Densità\")\n\n\n\n\n\n\n\nEstrarremo più volte campioni casuali di ampiezza \\(n\\) da questa popolazione e calcoleremo le medie campionarie. Il TLC prevede che, all’aumentare della dimensione del campione, la distribuzione delle medie campionarie tenda a una distribuzione normale, indipendentemente dalla forma della popolazione di partenza.\nPer verificare questa proprietà, definiamo una funzione che genera campioni, calcola le medie e visualizza la loro distribuzione campionaria per diversi valori di \\(n\\):\n\n# Parametri della distribuzione Beta\nalpha &lt;- 2\nbeta &lt;- 1\n\n# Funzione per simulare e visualizzare la distribuzione campionaria\nplot_samples &lt;- function(n) {\n  # Media e deviazione standard della distribuzione Beta\n  mu &lt;- alpha / (alpha + beta)\n  sigma &lt;- sqrt(alpha * beta / ((alpha + beta)^2 * (alpha + beta + 1)))\n  \n  # Generazione di 50.000 campioni casuali di dimensione n\n  sample_means &lt;- replicate(50000, mean(rbeta(n, alpha, beta)))\n  \n  # Creazione del dataframe\n  df &lt;- data.frame(MediaCampionaria = sample_means)\n  \n  # Creazione del grafico con ggplot2\n  ggplot(df, aes(x = MediaCampionaria)) +\n    geom_histogram(aes(y = after_stat(density)), bins = 50, fill = \"lightblue\", color = \"black\") +\n    stat_function(fun = dnorm, args = list(mean = mu, sd = sigma / sqrt(n)), color = \"black\", lwd = 1.2) +\n    labs(title = paste(\"Distribuzione campionaria per n =\", n),\n         x = \"Media campionaria\",\n         y = \"Densità\") +\n    theme_minimal()\n}\n\n\n74.5.1.1 Visualizzazione della convergenza alla normalità\nAnalizziamo l’effetto della dimensione del campione sulle medie campionarie:\n\n\nCampioni di ampiezza \\(n = 1\\)\nSe \\(n = 1\\), la distribuzione campionaria coincide esattamente con la distribuzione della popolazione di partenza, che in questo caso è fortemente asimmetrica:\n\nplot_samples(1)\n\n\n\n\n\n\n\n\n\nCampioni di ampiezza \\(n = 2\\)\nCon \\(n = 2\\), la distribuzione delle medie campionarie inizia a perdere parte della sua asimmetria:\n\nplot_samples(2)\n\n\n\n\n\n\n\n\n\nCampioni di ampiezza \\(n = 4\\)\nPer \\(n = 4\\), la distribuzione delle medie campionarie diventa più simmetrica e tende già a una forma più vicina a quella normale:\n\nplot_samples(4)\n\n\n\n\n\n\n\n\n\nCampioni di ampiezza \\(n = 30\\)\nQuando \\(n\\) diventa sufficientemente grande (ad esempio \\(n = 30\\)), la distribuzione campionaria delle medie è praticamente indistinguibile da una normale:\n\nplot_samples(30)\n\n\n\n\n\n\n\n\n\n74.5.1.2 Conclusione\nIl Teorema del Limite Centrale (TLC) afferma che, indipendentemente dalla forma della distribuzione della popolazione:\n\nSe la dimensione del campione è sufficientemente grande, la distribuzione delle medie campionarie \\(\\bar{X}\\) sarà approssimativamente normale, anche se la popolazione di partenza non lo è.\n\nLa distribuzione delle medie campionarie avrà media uguale a quella della popolazione \\(\\mu\\) e deviazione standard pari a:\n\\[\n\\bar{X} \\sim \\mathcal{N}(\\mu, \\sigma / \\sqrt{n})\n\\]\ndove \\(\\sigma\\) è la deviazione standard della popolazione e \\(n\\) è la dimensione del campione.\n\n\n74.5.2 Implicazioni\n\nNormalità emergente\nIl TLC giustifica l’uso della distribuzione normale in molte applicazioni statistiche, anche quando i dati originali non seguono una distribuzione normale.\nErrore standard e precisione delle stime\nIl TLC fornisce una formula esplicita per calcolare l’errore standard \\(\\sigma / \\sqrt{n}\\), che quantifica l’incertezza associata alla media campionaria. All’aumentare di \\(n\\), l’errore standard diminuisce, migliorando la precisione della stima della media della popolazione.\n\nQuesta proprietà è alla base di molte tecniche statistiche, come gli intervalli di confidenza e i test di ipotesi, che assumono la normalità della distribuzione campionaria delle medie anche quando la popolazione di partenza non è normale.\n\n74.5.3 Applicazioni in psicologia\nMolti fenomeni psicologici che misuriamo (ad esempio, il QI come media di molte abilità cognitive) derivano dalla media di più variabili, e quindi seguono la distribuzione normale grazie al TLC. Questo spiega perché la distribuzione normale appare così frequentemente nei dati sperimentali di psicologia e in molte altre discipline scientifiche.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01a_stime_parametri.html#distribuzioni-campionarie-di-altre-statistiche",
    "href": "chapters/frequentist_inference/01a_stime_parametri.html#distribuzioni-campionarie-di-altre-statistiche",
    "title": "74  Stime, stimatori e parametri",
    "section": "\n74.6 Distribuzioni campionarie di altre statistiche",
    "text": "74.6 Distribuzioni campionarie di altre statistiche\nAbbiamo già analizzato la distribuzione campionaria della media dei campioni. Tuttavia, è possibile costruire distribuzioni campionarie per altre statistiche campionarie. Ad esempio, consideriamo la distribuzione campionaria del valore massimo e della varianza.\n\n74.6.1 Distribuzione campionaria del valore massimo\nSupponiamo di avere una popolazione normalmente distribuita con media \\(\\mu = 100\\) e deviazione standard \\(\\sigma = 15\\). Generiamo 10.000 campioni casuali di ampiezza \\(n = 5\\) e calcoliamo il valore massimo per ogni campione.\n\n74.6.1.1 Simulazione e visualizzazione\n\nset.seed(123)  # Per risultati riproducibili\n\n# Parametri della distribuzione\nmu &lt;- 100\nsigma &lt;- 15\n\n# Simulazione: calcolo del valore massimo per ciascun campione\nn_samples &lt;- 10000\nsample_maxes &lt;- replicate(\n  n_samples, \n  max(rnorm(5, mean = mu, sd = sigma))\n)\n\n# Creazione del dataframe\ndf &lt;- data.frame(ValoreMassimo = sample_maxes)\n\n# Istogramma con ggplot2\nggplot(df, aes(x = ValoreMassimo)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 50, fill = \"lightblue\", color = \"black\") +\n  stat_function(fun = dnorm, args = list(mean = mu, sd = sigma), color = \"black\", lwd = 1.2) +\n  labs(title = \"Distribuzione campionaria del valore massimo\",\n       x = \"Valore massimo\",\n       y = \"Densità\")\n\n\n\n\n\n\n\nOsserviamo che il valore atteso della distribuzione campionaria del massimo è maggiore della media della popolazione \\(\\mu\\).\n\n74.6.2 Distribuzione campionaria della varianza\nUn’altra statistica interessante è la varianza campionaria. La formula della varianza campionaria, basata sulla statistica descrittiva, è:\n\\[\nS^2 = \\frac{\\sum_{i=1}^n (Y_i - \\bar{Y})^2}{n}.\n\\]\nCalcoliamo la distribuzione campionaria della varianza per campioni di ampiezza \\(n = 5\\).\n\n74.6.2.1 Simulazione e visualizzazione\n\nset.seed(123)\n\n# Parametri della distribuzione\nmu &lt;- 100\nsigma &lt;- 15\nn_samples &lt;- 10000\n\n# Funzione per calcolare la varianza senza la correzione di Bessel\nvariance &lt;- function(x) {\n  mean((x - mean(x))^2)  # Divisione per n invece di (n-1)\n}\n\n# Simulazione: calcolo della varianza per ciascun campione\nsample_vars &lt;- replicate(\n  n_samples, \n  variance(rnorm(5, mean = mu, sd = sigma))\n)\n\n# Creazione del dataframe\ndf &lt;- data.frame(Varianza = sample_vars)\n\n# Istogramma con ggplot2\nggplot(df, aes(x = Varianza)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 50, fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Distribuzione campionaria della varianza\",\n       x = \"Varianza\",\n       y = \"Densità\")\n\n\n\n\n\n\n\n\n# Media empirica della varianza campionaria\nmean(sample_vars)\n#&gt; [1] 180.7\n\nSappiamo che la varianza della popolazione è \\(\\sigma^2 = 15^2 = 225\\). Tuttavia, il valore medio empirico delle varianze campionarie calcolate con \\(S^2\\) risulta minore di 225. Questo avviene perché lo stimatore \\(S^2\\) è distorto.\n\n74.6.3 Correzione della distorsione\nPer eliminare la distorsione, utilizziamo il seguente stimatore della varianza della popolazione:\n\\[\ns^2 = \\frac{\\sum_{i=1}^n (Y_i - \\bar{Y})^2}{n-1}.\n\\]\n\n74.6.3.1 Verifica con simulazione\n\nset.seed(123)\n\n# Simulazione: calcolo della varianza con la correzione\nsample_vars_unbiased &lt;- replicate(\n  n_samples, \n  var(rnorm(5, mean = mu, sd = sigma))\n)\n\n# Creazione del dataframe\ndf &lt;- data.frame(Varianza = sample_vars_unbiased)\n\n# Istogramma con ggplot2\nggplot(df, aes(x = Varianza)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 50, fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Distribuzione campionaria della varianza (corretta)\",\n       x = \"Varianza\",\n       y = \"Densità\")\n\n\n\n\n\n\n\n\n# Media empirica della varianza corretta\nmean(sample_vars_unbiased)\n#&gt; [1] 225.8\n\nCon questo stimatore, la media della distribuzione campionaria coincide con la varianza reale della popolazione \\(\\sigma^2 = 225\\).\nIn conclusione:\n\nLa distribuzione campionaria del massimo mostra che il valore massimo dei campioni è, in media, maggiore della media della popolazione.\nLa varianza campionaria non corretta (\\(S^2\\)) è uno stimatore distorto, poiché il suo valore atteso non coincide con la varianza della popolazione.\nLo stimatore corretto \\(s^2\\), che utilizza il divisore \\(n - 1\\), elimina la distorsione e fornisce una stima non distorta della varianza della popolazione.\n\nIn generale, uno stimatore è considerato non distorto quando il valore atteso delle sue stime coincide con il valore reale del parametro. Nel caso della media campionaria e della varianza corretta, entrambi gli stimatori sono non distorti.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01a_stime_parametri.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/01a_stime_parametri.html#riflessioni-conclusive",
    "title": "74  Stime, stimatori e parametri",
    "section": "\n74.7 Riflessioni Conclusive",
    "text": "74.7 Riflessioni Conclusive\nIn generale, i parametri della popolazione sono sconosciuti, ma possiamo stimarli utilizzando le informazioni del campione. Di seguito viene presentata una tabella che riassume i simboli comuni utilizzati per indicare le quantità note e sconosciute nel contesto dell’inferenza statistica. Questo ci aiuterà a tenere traccia di ciò che sappiamo e ciò che non sappiamo.\n\n\n\n\n\n\n\nSimbolo\nNome\nÈ qualcosa che conosciamo?\n\n\n\n\\(s\\)\nDeviazione standard del campione\nSì, la calcoliamo dai dati grezzi\n\n\n\\(\\sigma\\)\nDeviazione standard della popolazione\nNo, tranne in casi particolari o nelle simulazioni\n\n\n\\(\\hat{\\sigma}\\)\nStima della deviazione standard della popolazione\nSì, ma non è uguale a \\(\\sigma\\)\n\n\n\n\\(s^2\\)\nVarianza del campione\nSì, la calcoliamo dai dati grezzi\n\n\n\\(\\sigma^2\\)\nVarianza della popolazione\nNo, tranne in casi particolari o nelle simulazioni\n\n\n\\(\\hat{\\sigma}^2\\)\nStima della varianza della popolazione\nSì, ma non è uguale a \\(\\sigma^2\\)\n\n\n\n\n\nUtilizzando le informazioni di un campione casuale di ampiezza \\(n\\):\n\nLa stima migliore che possiamo ottenere per la media \\(\\mu\\) della popolazione è la media del campione \\(\\bar{Y}\\).\nLa stima migliore che possiamo ottenere per la varianza \\(\\sigma^2\\) della popolazione è:\n\n\\[\n\\hat{\\sigma}^2 = \\frac{1}{n-1} \\sum_{i=1}^n (Y_i - \\bar{Y})^2.\n\\]\n\n\n\n\n\n\nRisposte alle domande iniziali\n\n\n\n\n\nDopo aver esplorato il concetto di distribuzione campionaria attraverso simulazioni ed esempi pratici, possiamo ora confrontare le nostre risposte intuitive con quanto appreso:\n\nLe medie campionarie tendono a distribuirsi intorno alla media della popolazione, con una variabilità che dipende dalla dimensione del campione.\nSì, le medie campionarie sono meno disperse rispetto ai singoli valori della popolazione, il che significa che forniscono una stima più stabile della media della popolazione.\nAll’aumentare di \\(n\\), la distribuzione campionaria delle medie diventa più stretta, ossia la variabilità delle medie campionarie si riduce. La varianza della distribuzione campionaria è pari a \\(\\sigma^2 / n\\), dove \\(\\sigma^2\\) è la varianza della popolazione.\nNo, la distribuzione campionaria della media è normale solo se la popolazione di partenza è normale o se la dimensione del campione è sufficientemente grande (Teorema del Limite Centrale).\nSì, la media della distribuzione campionaria coincide con la media della popolazione. Tuttavia, la varianza della distribuzione campionaria è inferiore alla varianza della popolazione, poiché viene divisa per la dimensione del campione (\\(n\\)).\nPer campioni piccoli, la distribuzione delle medie campionarie somiglierà alla distribuzione della popolazione originale. Se la popolazione è fortemente asimmetrica, anche la distribuzione campionaria per piccoli campioni sarà asimmetrica. Tuttavia, aumentando \\(n\\), la distribuzione delle medie campionarie tenderà a una normale, indipendentemente dalla forma della popolazione di partenza.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01a_stime_parametri.html#esercizi",
    "href": "chapters/frequentist_inference/01a_stime_parametri.html#esercizi",
    "title": "74  Stime, stimatori e parametri",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nParte 1: Popolazione di Piccole Dimensioni Si consideri una popolazione con i seguenti valori:\n\\[\nx = \\{2, 4.5, 5, 5.5\\}\n\\]\n\nCalcolare la media e la varianza della popolazione.\nEstrarre tutti i possibili campioni di ampiezza \\(n = 2\\) con ripetizione e calcolare la media di ciascun campione.\nRappresentare graficamente la distribuzione campionaria delle medie.\nCalcolare la probabilità che la media campionaria sia inferiore a 3:\n\nEsattamente, utilizzando la distribuzione campionaria.\nApprossimativamente, assumendo una distribuzione normale se il campione fosse sufficientemente grande.\n\n\n\nParte 2: Popolazione di Grandi Dimensioni\nSi consideri ora una popolazione più grande, generata da una distribuzione normale con media \\(\\mu = 10\\) e deviazione standard \\(\\sigma = 3\\).\n\nGenerare una popolazione di 1000 osservazioni.\nCalcolare la media e la varianza della popolazione.\nEstrarre 10.000 campioni casuali di ampiezza \\(n = 15\\) e calcolare la media campionaria per ciascun campione.\nRappresentare graficamente la distribuzione campionaria delle medie.\nCalcolare la probabilità che la media campionaria sia inferiore a 9:\n\nEsattamente, utilizzando la distribuzione campionaria.\nApprossimativamente, utilizzando la distribuzione normale.\n\n\n\nObiettivo: Verificare sperimentalmente le proprietà della distribuzione campionaria della media e confrontare i risultati con le previsioni teoriche fornite dal Teorema del Limite Centrale.\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\nProprietà della Distribuzione Campionaria della Media\n\nMedia: La media della distribuzione campionaria coincide con la media della popolazione:\nVarianza: La varianza della distribuzione campionaria è pari alla varianza della popolazione divisa per la dimensione del campione:\nForma:\n\n\nSe la popolazione segue una distribuzione normale, anche la distribuzione campionaria della media sarà normale.\nSe la popolazione non è normale, il Teorema del Limite Centrale garantisce che la distribuzione campionaria della media sarà approssimativamente normale per campioni di dimensioni sufficientemente grandi (\\(n \\geq 30\\)).\n\nDefiniamo una popolazione e calcoliamo i parametri:\n\n# Popolazione\nx &lt;- c(2, 4.5, 5, 5.5)\nmean(x)  # Media della popolazione\n#&gt; [1] 4.25\nvar(x)   # Varianza della popolazione\n#&gt; [1] 2.417\n\nEstrarre tutti i possibili campioni di ampiezza \\(n = 2\\) e calcolare la media di ciascun campione:\n\n# Tutti i campioni di ampiezza 2\nsamples &lt;- expand.grid(x, x)\nsample_means &lt;- rowMeans(samples)\n\n# Visualizzare la distribuzione campionaria\ndf &lt;- data.frame(sample_means = sample_means)\n\nggplot(df, aes(x = sample_means)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 5, fill = \"blue\", alpha = 0.6) +\n  geom_density(color = \"red\", size = 1) +\n  labs(\n    title = \"Distribuzione campionaria delle medie\",\n    x = \"Media campionaria\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\nCalcoliamo la probabilità che, all’interno della distribuzione campionaria, la media del campione sia minore di 3. Troviamo il valore esatto nella simulazione. Approssimiamo il valore esatto con il valore atteso se il campione fosse sufficientemente grande da poter assumere una distribuzione campionaria normale:\n\n# Probabilità esatta dalla distribuzione campionaria\nexact_probability &lt;- mean(sample_means &lt; 3)\nexact_probability\n#&gt; [1] 0.0625\n\n# Approssimazione tramite distribuzione normale\nmu &lt;- mean(x)  # Media della popolazione\nsigma &lt;- sqrt(var(x) / 2)  # Deviazione standard della distribuzione campionaria\napprox_probability &lt;- pnorm(3, mean = mu, sd = sigma)\napprox_probability\n#&gt; [1] 0.1277\n\nRipetiamo ora l’esempio, mantenendo la stessa struttura della simulazione, ma considerando una popolazione più grande tale per cui si possa estrarre un campione di ampiezza 15:\n\n# Nuova popolazione\nset.seed(123)\nx_large &lt;- rnorm(1000, mean = 10, sd = 3)  # Popolazione più grande\nmean(x_large)  # Media della popolazione\n#&gt; [1] 10.05\nvar(x_large)   # Varianza della popolazione\n#&gt; [1] 8.851\n\n# Estrazione di campioni di ampiezza 15\nsamples_large &lt;- replicate(10000, mean(sample(x_large, size = 15)))\n\n# Creazione del data frame per ggplot2\ndf_large &lt;- data.frame(sample_means = samples_large)\n\n# Visualizzazione con ggplot2\nggplot(df_large, aes(x = sample_means)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 50, fill = \"blue\", alpha = 0.6) +\n  geom_density(color = \"red\", size = 1) +\n  labs(\n    title = \"Distribuzione campionaria delle medie (n = 15)\",\n    x = \"Media campionaria\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\n\n# Probabilità esatta dalla simulazione\nexact_probability_large &lt;- mean(samples_large &lt; 9)\nexact_probability_large\n#&gt; [1] 0.0834\n\n\n# Approssimazione tramite distribuzione normale\nmu_large &lt;- mean(x_large)\nsigma_large &lt;- sqrt(var(x_large) / 15)\napprox_probability_large &lt;- pnorm(9, mean = mu_large, sd = sigma_large)\napprox_probability_large\n#&gt; [1] 0.08616\n\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nDistribuzione Campionaria della Differenza tra Medie\nL’obiettivo di questo esercizio è esplorare le proprietà della distribuzione campionaria della differenza tra medie campionarie, analizzando sia il caso di popolazioni finite di piccole dimensioni sia il caso di popolazioni più grandi, con distribuzioni normali.\nEsercizio 1: Simulazione con Popolazioni di Piccole Dimensioni\nConsideriamo due popolazioni finite composte da un numero limitato di elementi:\n\n\nPopolazione 1: \\(x_1 = \\{2, 4.5, 5, 6\\}\\)\n\n\nPopolazione 2: \\(x_2 = \\{3, 3.5, 4, 7\\}\\)\n\n\n\n74.7.0.1 Compiti:\n\n\n\nCalcolo dei parametri delle popolazioni:\n\nDeterminare la media e la varianza di entrambe le popolazioni.\n\n\n\nEstrazione di campioni:\n\nEstrarre tutti i possibili campioni di ampiezza \\(n = 2\\) con ripetizione da entrambe le popolazioni.\nCalcolare la media campionaria di ciascun campione.\n\n\n\nDistribuzione campionaria della differenza tra le medie:\n\nCalcolare la differenza tra le medie di tutti i possibili campioni ottenuti dalle due popolazioni.\nRappresentare graficamente la distribuzione della differenza tra le medie.\n\n\n\nProbabilità della differenza tra le medie:\n\nCalcolare la probabilità che la differenza tra le medie campionarie sia maggiore di 1.\n\n\n\nEsercizio 2: Simulazione con Popolazioni di Grande Dimensione\nConsideriamo ora due popolazioni più grandi, distribuite normalmente:\n\n\nPopolazione 1: \\(X_1 \\sim N(10, 4^2)\\) (media = 10, deviazione standard = 4)\n\nPopolazione 2: \\(X_2 \\sim N(8, 3^2)\\) (media = 8, deviazione standard = 3)\n\nCompiti:\n\n\nGenerazione delle popolazioni:\n\nCreare due popolazioni casuali di 10.000 osservazioni ciascuna, distribuite normalmente.\n\n\n\nEstrazione di campioni:\n\nEstrarre 10.000 campioni casuali di ampiezza \\(n_1 = 15\\) dalla prima popolazione e \\(n_2 = 20\\) dalla seconda popolazione.\nCalcolare la media di ciascun campione.\n\n\n\nDistribuzione campionaria della differenza tra le medie:\n\nCalcolare la differenza tra le medie campionarie ottenute dalle due popolazioni.\nRappresentare graficamente la distribuzione della differenza tra le medie.\n\n\n\nProbabilità della differenza tra le medie:\n\nCalcolare la probabilità che la differenza tra le medie campionarie sia maggiore di 2 in due modi:\n\n\nMetodo empirico: utilizzando la distribuzione ottenuta nella simulazione.\n\nMetodo teorico: approssimando la distribuzione con una normale e calcolando la probabilità con la formula teorica della varianza della differenza tra le medie.\n\n\n\n\n\nDomande di Discussione\n\nCome cambia la forma della distribuzione campionaria al variare delle dimensioni dei campioni \\(n_1\\) e \\(n_2\\)?\nLa probabilità stimata tramite simulazione coincide con quella calcolata utilizzando l’approssimazione normale? Perché?\nCosa accadrebbe alla distribuzione campionaria se le popolazioni originali non fossero normali? Quale sarebbe il ruolo del Teorema del Limite Centrale?\n\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\nEsercizio 1: Simulazione con Popolazioni di Piccola Dimensione\nSupponiamo di avere due popolazioni finite definite come segue:\n\nPopolazione 1: \\(x_1 = \\{2, 4.5, 5, 6\\}\\)\n\nPopolazione 2: \\(x_2 = \\{3, 3.5, 4, 7\\}\\)\n\n\n\nCalcola le medie e le varianze delle due popolazioni:\n\n\n# Popolazione 1\nx1 &lt;- c(2, 4.5, 5, 6)\nmean(x1)  # Media di x1\n#&gt; [1] 4.375\nvar(x1)   # Varianza di x1\n#&gt; [1] 2.896\n\n\n# Popolazione 2\nx2 &lt;- c(3, 3.5, 4, 7)\nmean(x2)  # Media di x2\n#&gt; [1] 4.375\nvar(x2)   # Varianza di x2\n#&gt; [1] 3.229\n\n\nEstrai tutti i possibili campioni di ampiezza \\(n = 2\\) da entrambe le popolazioni:\n\n\n# Tutti i campioni di ampiezza 2\nsamples1 &lt;- expand.grid(x1, x1)\nsamples2 &lt;- expand.grid(x2, x2)\n\n# Medie campionarie\nsample_means1 &lt;- rowMeans(samples1)\nsample_means2 &lt;- rowMeans(samples2)\n\n\nCalcola la differenza tra le medie campionarie di ciascuna combinazione di campioni:\n\n\n# Differenze tra le medie campionarie\nsample_diff &lt;- as.vector(outer(sample_means1, sample_means2, \"-\"))\n\n\nVisualizza la distribuzione campionaria della differenza tra le medie:\n\n\n# Istogramma della differenza tra medie campionarie\n\n# Creazione del data frame per ggplot2\ndf_diff &lt;- data.frame(sample_diff = sample_diff)\n\n# Visualizzazione con ggplot2\nggplot(df_diff, aes(x = sample_diff)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 10, fill = \"blue\", alpha = 0.6) +\n  geom_density(color = \"red\", size = 1) +\n  labs(\n    title = \"Distribuzione campionaria della differenza tra medie\",\n    x = \"Differenza campionaria\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\n\nCalcola la probabilità che la differenza campionaria sia maggiore di 1:\n\n\n# Probabilità esatta dalla distribuzione campionaria\nexact_probability &lt;- mean(sample_diff &gt; 1)\nexact_probability\n#&gt; [1] 0.2656\n\nEsercizio 2: Simulazione con Popolazioni di Grande Dimensione\nOra considera due popolazioni più grandi con distribuzioni normali:\n\nPopolazione 1: \\(X_1 \\sim N(10, 4^2)\\)\n\nPopolazione 2: \\(X_2 \\sim N(8, 3^2)\\)\n\n\n\nGenera due popolazioni casuali:\n\n\nset.seed(123)\npop1 &lt;- rnorm(10000, mean = 10, sd = 4)\npop2 &lt;- rnorm(10000, mean = 8, sd = 3)\n\n\nEstrai 10.000 campioni casuali di ampiezza \\(n_1 = 15\\) e \\(n_2 = 20\\) rispettivamente:\n\n\n# Estrazione di campioni e calcolo delle medie\nsample_means1 &lt;- replicate(10000, mean(sample(pop1, size = 15)))\nsample_means2 &lt;- replicate(10000, mean(sample(pop2, size = 20)))\n\n\nCalcola la differenza tra le medie campionarie:\n\n\n# Differenze tra medie campionarie\nsample_diff_large &lt;- sample_means1 - sample_means2\n\n\nVisualizza la distribuzione campionaria della differenza tra le medie:\n\n\n# Istogramma della distribuzione campionaria\n\n# Creazione del data frame per ggplot2\ndf_diff_large &lt;- data.frame(sample_diff = sample_diff_large)\n\n# Visualizzazione con ggplot2\nggplot(df_diff_large, aes(x = sample_diff)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 50, fill = \"blue\", alpha = 0.6) +\n  geom_density(color = \"red\", size = 1) +\n  labs(\n    title = \"Distribuzione campionaria della differenza tra medie (n1 = 15, n2 = 20)\",\n    x = \"Differenza campionaria\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\n\n\nCalcola la probabilità che la differenza campionaria sia maggiore di 2 utilizzando:\n\nla simulazione;\nl’approssimazione normale.\n\n\n\n\n# Probabilità esatta\nexact_probability_large &lt;- mean(sample_diff_large &gt; 2)\nexact_probability_large\n#&gt; [1] 0.505\n\n\n# Approssimazione normale\nmu_diff &lt;- 10 - 8  # Differenza tra le medie delle popolazioni\nsigma_diff &lt;- sqrt(4^2 / 15 + 3^2 / 20)  # Deviazione standard della differenza\napprox_probability_large &lt;- 1 - pnorm(2, mean = mu_diff, sd = sigma_diff)\napprox_probability_large\n#&gt; [1] 0.5\n\nDomande di Discussione.\n\nCome cambia la forma della distribuzione campionaria al variare delle dimensioni campionarie \\(n_1\\) e \\(n_2\\)?\nLa probabilità calcolata tramite simulazione coincide con quella calcolata tramite approssimazione normale? Perché?\nCosa accadrebbe alla distribuzione campionaria se le popolazioni originali non fossero normali?\n\n\n\n\n\n\n\n\n\n\nProblemi 3\n\n\n\n\n\nProblema: Distribuzione Campionaria di una Proporzione\nL’obiettivo di questo esercizio è esplorare la distribuzione campionaria di una proporzione campionaria \\(\\hat{p}\\) e verificare l’applicabilità dell’approssimazione normale per grandi dimensioni campionarie, come previsto dal Teorema del Limite Centrale.\nSituazione\nSupponiamo di avere una popolazione infinita in cui ciascun individuo può appartenere a una di due categorie: “successo” (codificato come 1) o “insuccesso” (codificato come 0). La probabilità di successo nella popolazione è data da \\(p = 0.6\\).\nCompiti\n\n\nDefinizione della popolazione e dei parametri:\n\nLa popolazione ha una proporzione di successi pari a \\(p = 0.6\\).\nLa deviazione standard teorica della distribuzione campionaria della proporzione è calcolata come:\\[\n\\text{SD}(\\hat{p}) = \\sqrt{\\frac{p(1 - p)}{n}}\n\\]\n\nSi fissi una dimensione campionaria pari a \\(n = 100\\).\n\n\n\nSimulazione di campioni:\n\nGenerare 10.000 campioni casuali di ampiezza \\(n = 100\\).\nPer ogni campione, calcolare la proporzione campionaria \\(\\hat{p}\\), cioè la frazione di successi nel campione.\n\n\n\nDistribuzione campionaria delle proporzioni:\n\nRappresentare graficamente la distribuzione delle proporzioni campionarie con un istogramma.\nSovrapporre la distribuzione normale teorica \\(N(p, \\text{SD}(\\hat{p}))\\) per confrontare l’andamento empirico con quello teorico.\n\n\n\nAnalisi della distribuzione:\n\nValutare se la distribuzione campionaria ottenuta rispetta l’approssimazione normale.\nRiflettere su come la dimensione del campione e il valore di \\(p\\) influenzano questa approssimazione.\n\n\n\nDomande di Discussione\n\nLa distribuzione campionaria delle proporzioni \\(\\hat{p}\\) sembra approssimarsi a una distribuzione normale? Perché?\nCosa accadrebbe se la dimensione del campione fosse più piccola, ad esempio \\(n = 30\\)?\nSe la probabilità di successo \\(p\\) fosse molto vicina a 0 o 1, l’approssimazione normale sarebbe ancora valida? Perché?\n\n\n\n\n\n\n\n\n\n\nSoluzioni 3\n\n\n\n\n\nLa distribuzione campionaria di una proporzione descrive come la proporzione campionaria (\\(\\hat{p}\\)) varia tra campioni di una popolazione. Per campioni grandi, il Teorema del Limite Centrale garantisce che la distribuzione campionaria di \\(\\hat{p}\\) può essere approssimata con una distribuzione normale.\n\n\nSupponiamo una popolazione infinita in cui la probabilità di successo (\\(p\\)) è \\(p = 0.6\\). Scegli una dimensione campionaria \\(n = 100\\).\nSimula 10.000 campioni casuali di ampiezza \\(n\\) e calcola le proporzioni campionarie (\\(\\hat{p}\\)).\nConfronta l’istogramma delle proporzioni campionarie con la distribuzione normale teorica approssimativa.\n\n\n# Parametri della popolazione\np &lt;- 0.6  # Probabilità di successo nella popolazione\nn &lt;- 100  # Dimensione del campione\n\n# Simulazione di 10.000 campioni\nset.seed(123)\nsample_props &lt;- replicate(10000, mean(rbinom(n, size = 1, prob = p)))\n\n# Creazione di un data frame per ggplot2\ndf_props &lt;- data.frame(sample_props = sample_props)\n\n# Parametri della distribuzione normale teorica\nmean_theoretical &lt;- p\nsd_theoretical &lt;- sqrt(p * (1 - p) / n)\n\n# Visualizzazione con ggplot2\nggplot(df_props, aes(x = sample_props)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 40, fill = \"blue\", alpha = 0.6) +\n  stat_function(\n    fun = dnorm,\n    args = list(mean = mean_theoretical, sd = sd_theoretical),\n    color = \"red\",\n    size = 1\n  ) +\n  labs(\n    title = \"Distribuzione campionaria di una proporzione (n = 100)\",\n    x = \"Proporzione campionaria (\\u0302p)\",\n    y = \"Densità\"\n  ) \n\n\n\n\n\n\n\n\n\nPopolazione e parametri:\n\nLa popolazione è definita da \\(p = 0.6\\).\nLa deviazione standard teorica della distribuzione campionaria è calcolata come \\(\\text{SD}(\\hat{p}) = \\sqrt{\\frac{p(1-p)}{n}}\\).\n\n\n\nSimulazione:\n\nPer ogni campione, i successi (\\(0\\) o \\(1\\)) sono generati con rbinom, e la proporzione campionaria \\(\\hat{p}\\) è calcolata come media.\n\n\n\nGrafico:\n\nL’istogramma delle proporzioni campionarie è sovrapposto alla curva normale teorica (\\(N(p, \\text{SD}(\\hat{p}))\\)).\n\n\n\nDomande di Discussione.\n\nLa distribuzione campionaria di \\(\\hat{p}\\) sembra approssimarsi a una distribuzione normale? Perché?\nCosa accadrebbe se \\(n\\) fosse più piccolo (es. \\(n = 30\\))?\nSe \\(p\\) fosse più vicino a \\(0\\) o \\(1\\), l’approssimazione normale sarebbe ancora valida? Spiega.\n\n\n\n\n\n\n\n\n\n\nProblemi 4\n\n\n\n\n\nProblema: Distribuzione Campionaria della Differenza tra Due Proporzioni\nL’obiettivo di questo esercizio è esplorare la distribuzione campionaria della differenza tra due proporzioni campionarie, \\(\\hat{p}_1 - \\hat{p}_2\\), ottenute da due campioni indipendenti estratti da popolazioni diverse. Per campioni sufficientemente grandi, il Teorema del Limite Centrale garantisce che la distribuzione di \\(\\hat{p}_1 - \\hat{p}_2\\) può essere approssimata con una distribuzione normale.\nSituazione\nAbbiamo due popolazioni con proporzioni di successo diverse:\n\n\nPopolazione 1 ha una proporzione di successo \\(p_1 = 0.6\\).\n\nPopolazione 2 ha una proporzione di successo \\(p_2 = 0.4\\).\n\nVogliamo studiare il comportamento della distribuzione campionaria della differenza tra le proporzioni campionarie quando preleviamo campioni indipendenti da ciascuna popolazione.\nCompiti\n\n\nDefinizione delle popolazioni e dei parametri:\n\nLa proporzione di successi nelle due popolazioni è \\(p_1 = 0.6\\) e \\(p_2 = 0.4\\).\nEntrambi i campioni hanno dimensione \\(n_1 = n_2 = 150\\).\nLa deviazione standard teorica della distribuzione campionaria della differenza tra proporzioni è calcolata come: \\[\n\\text{SD}(\\hat{p}_1 - \\hat{p}_2) = \\sqrt{\\frac{p_1 (1-p_1)}{n_1} + \\frac{p_2 (1-p_2)}{n_2}}\n\\]\n\n\n\n\nSimulazione di campioni:\n\nGenerare 10.000 campioni indipendenti di ampiezza \\(n_1 = 150\\) dalla prima popolazione e \\(n_2 = 150\\) dalla seconda popolazione.\nCalcolare la proporzione campionaria \\(\\hat{p}_1\\) e \\(\\hat{p}_2\\) per ciascun campione.\nCalcolare la differenza tra le proporzioni campionarie.\n\n\n\nDistribuzione campionaria della differenza tra le proporzioni:\n\nRappresentare graficamente la distribuzione di \\(\\hat{p}_1 - \\hat{p}_2\\) con un istogramma.\nSovrapporre la distribuzione normale teorica \\(N(p_1 - p_2, \\text{SD}(\\hat{p}_1 - \\hat{p}_2))\\) per confrontare l’andamento empirico con quello teorico.\n\n\n\nCalcolo della probabilità che la differenza tra proporzioni sia maggiore di un valore specifico:\n\n\nMetodo empirico: calcolare la proporzione di campioni in cui \\(\\hat{p}_1 - \\hat{p}_2 &gt; 0.1\\).\n\nMetodo teorico: utilizzare la distribuzione normale approssimata per stimare la probabilità che \\(\\hat{p}_1 - \\hat{p}_2 &gt; 0.1\\).\n\n\n\nDomande di Discussione\n\nL’approssimazione normale è valida in questo caso? Perché?\nCome cambierebbe la distribuzione campionaria se la dimensione del campione \\(n_1\\) o \\(n_2\\) fosse più piccola?\nSe i valori di \\(p_1\\) o \\(p_2\\) fossero più vicini a 0 o 1, come cambierebbe la probabilità calcolata e l’accuratezza dell’approssimazione normale?\n\n\n\n\n\n\n\n\n\n\nSoluzioni 4\n\n\n\n\n\nLa distribuzione campionaria della differenza tra due proporzioni (\\(\\hat{p}_1 - \\hat{p}_2\\)) descrive come la differenza tra le proporzioni campionarie varia tra due campioni indipendenti estratti da due popolazioni.\nPer campioni grandi, il Teorema del Limite Centrale garantisce che \\(\\hat{p}_1 - \\hat{p}_2\\) segue approssimativamente una distribuzione normale con media e varianza calcolate dalle proporzioni della popolazione.\nObiettivo:\n\nSimulare due popolazioni con proporzioni \\(p_1\\) e \\(p_2\\).\nEstrarre campioni indipendenti da ciascuna popolazione.\nCalcolare la distribuzione campionaria di \\(\\hat{p}_1 - \\hat{p}_2\\).\nCalcolare la probabilità che la differenza campionaria sia maggiore di un valore specifico (es. \\(0.1\\)).\n\nParametri del Problema:\n\nPopolazione 1: \\(p_1 = 0.6\\)\n\nPopolazione 2: \\(p_2 = 0.4\\)\n\nDimensione campionaria: \\(n_1 = n_2 = 150\\)\n\nValore specifico: \\(0.1\\)\n\n\n\n# Parametri delle due popolazioni\np1 &lt;- 0.6  # Proporzione di successi nella Popolazione 1\np2 &lt;- 0.4  # Proporzione di successi nella Popolazione 2\nn1 &lt;- 150  # Dimensione campionaria per la Popolazione 1\nn2 &lt;- 150  # Dimensione campionaria per la Popolazione 2\n\n# Simulazione di 10.000 campioni indipendenti\nset.seed(123)\nsample_p1 &lt;- replicate(10000, mean(rbinom(n1, size = 1, prob = p1)))\nsample_p2 &lt;- replicate(10000, mean(rbinom(n2, size = 1, prob = p2)))\n\n# Calcolo della differenza tra proporzioni campionarie\nsample_diff &lt;- sample_p1 - sample_p2\n\n# Parametri teorici della distribuzione normale approssimata\nmean_diff &lt;- p1 - p2\nsd_diff &lt;- sqrt((p1 * (1 - p1) / n1) + (p2 * (1 - p2) / n2))\n\n# Creazione del data frame per ggplot2\ndf_diff &lt;- data.frame(sample_diff = sample_diff)\n\n# Visualizzazione con ggplot2\nggplot(df_diff, aes(x = sample_diff)) +\n  geom_histogram(\n    aes(y = after_stat(density)), bins = 40, fill = \"blue\", alpha = 0.6\n  ) +\n  stat_function(\n    fun = dnorm,\n    args = list(mean = mean_diff, sd = sd_diff),\n    color = \"red\",\n    size = 1\n  ) +\n  labs(\n    title = \"Distribuzione campionaria della differenza tra proporzioni\",\n    x = \"Differenza campionaria (p1 - p2)\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\n\n# Calcolo della probabilità che la differenza sia maggiore di 0.1\nexact_probability &lt;- mean(sample_diff &gt; 0.1)\nexact_probability\n#&gt; [1] 0.9599\n\n\n# Approssimazione tramite distribuzione normale\napprox_probability &lt;- 1 - pnorm(0.1, mean = mean_diff, sd = sd_diff)\napprox_probability\n#&gt; [1] 0.9615\n\n\n\nParametri delle popolazioni:\n\nDue popolazioni con proporzioni \\(p_1 = 0.6\\) e \\(p_2 = 0.4\\).\nDimensioni campionarie \\(n_1 = n_2 = 150\\).\n\n\n\nSimulazione:\n\nPer ogni campione, i successi (\\(0\\) o \\(1\\)) sono generati con rbinom.\nCalcoliamo le proporzioni campionarie e la differenza tra di esse.\n\n\n\nDistribuzione teorica:\n\nMedia teorica: \\(p_1 - p_2\\).\nDeviazione standard teorica: \\(\\sqrt{\\frac{p_1 (1-p_1)}{n_1} + \\frac{p_2 (1-p_2)}{n_2}}\\).\n\n\n\nVisualizzazione:\n\nUn istogramma di \\(\\hat{p}_1 - \\hat{p}_2\\) sovrapposto alla curva della distribuzione normale teorica.\n\n\n\nCalcolo della probabilità:\n\nProbabilità esatta dalla simulazione: proporzione di \\(\\hat{p}_1 - \\hat{p}_2 &gt; 0.1\\).\nProbabilità approssimata dalla distribuzione normale.\n\n\n\nDomande di Discussione.\n\nL’approssimazione normale è valida in questo caso? Perché?\nCome cambierebbe la distribuzione campionaria se \\(n_1\\) o \\(n_2\\) fossero più piccoli?\nCome influenzerebbe la probabilità calcolata un valore \\(p_1\\) o \\(p_2\\) più vicino a \\(0\\) o \\(1\\)?",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01a_stime_parametri.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/01a_stime_parametri.html#informazioni-sullambiente-di-sviluppo",
    "title": "74  Stime, stimatori e parametri",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.12.0 psych_2.5.3     \n#&gt;  [9] scales_1.4.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.2   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.4     stringi_1.8.7      lattice_0.22-7    \n#&gt;  [4] hms_1.1.3          digest_0.6.37      magrittr_2.0.3    \n#&gt;  [7] evaluate_1.0.3     grid_4.5.0         timechange_0.3.0  \n#&gt; [10] RColorBrewer_1.1-3 fastmap_1.2.0      rprojroot_2.0.4   \n#&gt; [13] jsonlite_2.0.0     mnormt_2.1.1       cli_3.6.5         \n#&gt; [16] rlang_1.1.6        withr_3.0.2        tools_4.5.0       \n#&gt; [19] parallel_4.5.0     tzdb_0.5.0         pacman_0.5.1      \n#&gt; [22] vctrs_0.6.5        R6_2.6.1           lifecycle_1.0.4   \n#&gt; [25] htmlwidgets_1.6.4  pkgconfig_2.0.3    pillar_1.10.2     \n#&gt; [28] gtable_0.3.6       glue_1.8.0         xfun_0.52         \n#&gt; [31] tidyselect_1.2.1   rstudioapi_0.17.1  farver_2.1.2      \n#&gt; [34] htmltools_0.5.8.1  nlme_3.1-168       labeling_0.4.3    \n#&gt; [37] rmarkdown_2.29     compiler_4.5.0",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html",
    "href": "chapters/frequentist_inference/02_conf_interv.html",
    "title": "75  Intervalli di fiducia",
    "section": "",
    "text": "75.1 Introduzione\nGli intervalli di confidenza sono uno strumento fondamentale nell’inferenza statistica frequentista. Essi consentono di stimare un parametro sconosciuto di una popolazione, come la media \\(\\mu\\), tenendo conto dell’incertezza derivante dal fatto che la stima si basa su un campione. Questo materiale didattico si propone di spiegare in modo dettagliato e chiaro la costruzione di un intervallo di confidenza per la media di una popolazione, sia nel caso di varianza nota sia in quello di varianza incognita.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#inferenza-statistica-frequentista-e-media-campionaria",
    "href": "chapters/frequentist_inference/02_conf_interv.html#inferenza-statistica-frequentista-e-media-campionaria",
    "title": "75  Intervalli di fiducia",
    "section": "\n75.2 Inferenza Statistica Frequentista e Media Campionaria",
    "text": "75.2 Inferenza Statistica Frequentista e Media Campionaria\nQuando estraiamo un campione casuale semplice \\(X_1, X_2, \\dots, X_n\\) da una popolazione con media \\(\\mu\\) e varianza \\(\\sigma^2\\), la media campionaria \\(\\bar{X}\\) è definita come:\n\\[\n\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i.\n\\]\nLa media campionaria \\(\\bar{X}\\) è una variabile casuale perché dipende dai valori osservati nel campione, che sono essi stessi casuali. Le proprietà della media campionaria sono le seguenti:\n\n\nMedia della distribuzione campionaria: \\(E[\\bar{X}] = \\mu\\). La media campionaria è uno stimatore non distorto della media della popolazione.\n\nVarianza della distribuzione campionaria: \\(\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n}\\). Questo significa che la precisione di \\(\\bar{X}\\) come stima di \\(\\mu\\) aumenta con il numero di osservazioni \\(n\\).\n\nQueste proprietà sono fondamentali per calcolare un intervallo di confidenza, poiché ci permettono di descrivere la distribuzione di \\(\\bar{X}\\).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#intervallo-di-confidenza-per-la-media-caso-di-varianza-nota",
    "href": "chapters/frequentist_inference/02_conf_interv.html#intervallo-di-confidenza-per-la-media-caso-di-varianza-nota",
    "title": "75  Intervalli di fiducia",
    "section": "\n75.3 Intervallo di Confidenza per la Media: Caso di Varianza Nota",
    "text": "75.3 Intervallo di Confidenza per la Media: Caso di Varianza Nota\nSupponiamo che la popolazione sia distribuita normalmente con media \\(\\mu\\) e varianza \\(\\sigma^2\\), e che \\(\\sigma^2\\) sia nota. La distribuzione della media campionaria \\(\\bar{X}\\) è anch’essa normale:\n\\[\n\\bar{X} \\sim \\mathcal{N}\\left(\\mu, \\frac{\\sigma^2}{n}\\right).\n\\]\nPasso 1: Standardizzazione della Media Campionaria.\nPer lavorare con una distribuzione normale standard (media 0 e varianza 1), standardizziamo \\(\\bar{X}\\) utilizzando la formula:\n\\[\nZ = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}}.\n\\]\nQui, \\(\\sigma / \\sqrt{n}\\) è la deviazione standard della distribuzione campionaria di \\(\\bar{X}\\).\nDopo questa trasformazione, la variabile \\(Z\\) segue una distribuzione normale standard:\n\\[\nZ \\sim \\mathcal{N}(0, 1).\n\\]\nPasso 2: Determinazione del Livello di Confidenza.\nScegliamo un livello di confidenza \\(\\gamma\\), ad esempio \\(\\gamma = 0.95\\). Per una distribuzione normale standard, troviamo il valore critico \\(z\\) tale che la probabilità tra \\(-z\\) e \\(+z\\) sia pari al livello di confidenza:\n\\[\nP(-z \\leq Z \\leq z) = \\gamma.\n\\]\nPer un livello di confidenza del 95%, \\(z \\approx 1.96\\).\nPasso 3: Formulazione dell’Intervallo di Confidenza.\nPartiamo dalla probabilità per \\(Z\\):\n\\[\nP(-z \\leq Z \\leq z) = \\gamma.\n\\]\nSostituiamo la definizione di \\(Z\\):\n\\[\nP\\left(-z \\leq \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}} \\leq z\\right) = \\gamma.\n\\]\nMoltiplichiamo tutti i membri per \\(\\sigma / \\sqrt{n}\\) per rimuovere il denominatore:\n\\[\nP\\left(-z \\cdot \\frac{\\sigma}{\\sqrt{n}} \\leq \\bar{X} - \\mu \\leq z \\cdot \\frac{\\sigma}{\\sqrt{n}}\\right) = \\gamma.\n\\]\nAggiungiamo \\(\\mu\\) a tutti i membri per isolare \\(\\mu\\):\n\\[\nP\\left(\\bar{X} - z \\cdot \\frac{\\sigma}{\\sqrt{n}} \\leq \\mu \\leq \\bar{X} + z \\cdot \\frac{\\sigma}{\\sqrt{n}}\\right) = \\gamma.\n\\]\nPasso 4: Limiti dell’Intervallo di Confidenza.\nDefiniamo i limiti inferiore e superiore dell’intervallo di confidenza:\n\\[\n\\hat{a} = \\bar{X} - z \\cdot \\frac{\\sigma}{\\sqrt{n}}, \\quad \\hat{b} = \\bar{X} + z \\cdot \\frac{\\sigma}{\\sqrt{n}}.\n\\]\nL’intervallo di confidenza per \\(\\mu\\) è quindi:\n\\[\n(\\hat{a}, \\hat{b}) = \\left(\\bar{X} - z \\cdot \\frac{\\sigma}{\\sqrt{n}}, \\bar{X} + z \\cdot \\frac{\\sigma}{\\sqrt{n}}\\right).\n\\]",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#intervallo-di-confidenza-per-la-media-caso-di-varianza-incognita",
    "href": "chapters/frequentist_inference/02_conf_interv.html#intervallo-di-confidenza-per-la-media-caso-di-varianza-incognita",
    "title": "75  Intervalli di fiducia",
    "section": "\n75.4 Intervallo di Confidenza per la Media: Caso di Varianza Incognita",
    "text": "75.4 Intervallo di Confidenza per la Media: Caso di Varianza Incognita\nNella maggior parte dei casi pratici, la varianza \\(\\sigma^2\\) non è nota. In questi casi, stimiamo \\(\\sigma\\) con la deviazione standard campionaria \\(s\\) e utilizziamo la distribuzione t di Student, che tiene conto dell’incertezza aggiuntiva.\nPasso 1: Distribuzione t di Student.\nLa statistica che seguiamo è:\n\\[\nT = \\frac{\\bar{X} - \\mu}{s / \\sqrt{n}},\n\\]\ndove \\(T\\) segue una distribuzione t con \\(n-1\\) gradi di libertà.\nPasso 2: Costruzione dell’Intervallo di Confidenza.\nAnalogamente al caso precedente, costruiamo l’intervallo partendo da:\n\\[\nP(-t^\\ast \\leq T \\leq t^\\ast) = \\gamma,\n\\]\ndove \\(t^\\ast\\) è il valore critico della distribuzione t per il livello di confidenza \\(\\gamma\\) e \\(n-1\\) gradi di libertà.\nSostituendo \\(T\\):\n\\[\nP\\left(-t^\\ast \\leq \\frac{\\bar{X} - \\mu}{s / \\sqrt{n}} \\leq t^\\ast\\right) = \\gamma.\n\\]\nMoltiplichiamo per \\(s / \\sqrt{n}\\):\n\\[\nP\\left(-t^\\ast \\cdot \\frac{s}{\\sqrt{n}} \\leq \\bar{X} - \\mu \\leq t^\\ast \\cdot \\frac{s}{\\sqrt{n}}\\right) = \\gamma.\n\\]\nAggiungiamo \\(\\mu\\):\n\\[\nP\\left(\\bar{X} - t^\\ast \\cdot \\frac{s}{\\sqrt{n}} \\leq \\mu \\leq \\bar{X} + t^\\ast \\cdot \\frac{s}{\\sqrt{n}}\\right) = \\gamma.\n\\]\nPasso 3: Limiti dell’Intervallo.\nI limiti dell’intervallo sono:\n\\[\n\\hat{a} = \\bar{X} - t^\\ast \\cdot \\frac{s}{\\sqrt{n}}, \\quad \\hat{b} = \\bar{X} + t^\\ast \\cdot \\frac{s}{\\sqrt{n}}.\n\\]\nIn conclusione, gli intervalli di confidenza forniscono un modo per quantificare l’incertezza nelle stime di parametri sconosciuti. La loro costruzione dipende dalla distribuzione campionaria dello stimatore e dall’informazione disponibile sulla varianza.\n\n75.4.1 Applicabilità e Limitazioni\n\nIl metodo presuppone che la popolazione segua una distribuzione normale e è valido anche per campioni di piccole dimensioni (ad esempio, \\(n &lt; 30\\)) prelevati da tale popolazione.\nSe la popolazione non è normalmente distribuita e la dimensione del campione è ridotta, questo metodo potrebbe non essere idoneo.\nTuttavia, per campioni di grandi dimensioni (\\(n \\geq 30\\)), questo approccio rimane valido per la stima dell’intervallo di confidenza grazie al teorema del limite centrale, che si applica anche a popolazioni con distribuzioni non normali.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#livello-di-copertura",
    "href": "chapters/frequentist_inference/02_conf_interv.html#livello-di-copertura",
    "title": "75  Intervalli di fiducia",
    "section": "\n75.5 Livello di Copertura",
    "text": "75.5 Livello di Copertura\nPer interpretare correttamente gli intervalli di fiducia è fondamentale considerare il concetto di “livello di copertura”. Questo livello indica la frequenza con cui l’intervallo di fiducia include il valore reale del parametro della popolazione, in una serie di esperimenti ripetuti.\nEsempio di Livello di Copertura:\n\nSe il livello di copertura è del 95%, significa che, nel lungo periodo, il 95% degli intervalli di fiducia costruiti conterrà il valore vero del parametro.\nImportante: Questo non implica che ci sia una probabilità del 95% che il valore vero del parametro cada in un particolare intervallo di fiducia. Infatti, il parametro della popolazione è un valore fisso e non soggetto a probabilità; piuttosto, l’incertezza risiede nell’intervallo di fiducia stesso.\n\nCome Funziona la Copertura:\n\nNel contesto frequentista, la “probabilità” si riferisce alla frequenza a lungo termine di un certo evento in un gran numero di ripetizioni dell’esperimento.\nNel caso degli intervalli di fiducia, l’“esperimento” è l’estrazione di un campione dalla popolazione, e l’“evento” è la generazione di un intervallo di fiducia che contiene il valore vero del parametro.\nIl livello di copertura, generalmente indicato come \\(1-\\alpha\\), rappresenta la probabilità a lungo termine che intervalli di fiducia costruiti con questa metodologia includano il vero valore del parametro.\n\n\n75.5.1 Simulazione\n\nPer illustrare questo concetto, eseguiamo una simulazione con la popolazione degli adulti maschi italiani, assunta come normalmente distribuita con media 175 cm e varianza 49 cm².\nEseguiamo 1000 ripetizioni di un esperimento, estraendo ogni volta un campione di 30 individui.\nPer ciascun campione, calcoliamo l’intervallo di fiducia al 95% usando la formula:\n\n\\[\n\\bar{X} \\pm t \\frac{s}{\\sqrt{n}},\n\\]\ndove \\(\\bar{X}\\) è la media campionaria, \\(s\\) è la deviazione standard campionaria e \\(t\\) è il valore critico della distribuzione t-Student per \\(n-1\\) gradi di libertà al livello di significatività \\(\\alpha/2 = 0.025\\). - Registriamo i limiti di ciascun intervallo e controlliamo quanti di essi includono effettivamente il vero valore medio della popolazione.\nAttraverso questa simulazione, possiamo visualizzare concretamente il concetto di livello di copertura e la sua importanza nella statistica frequentista.\nIn questa simulazione, genereremo 1000 campioni casuali di dimensione \\(n = 30\\) da una distribuzione normale con media \\(\\mu = 175\\) e deviazione standard \\(\\sigma = 7\\). Successivamente, calcoleremo gli intervalli di confidenza al 95% per ciascun campione e valuteremo il livello di copertura.\n\nset.seed(123)  # Per riproducibilità\n\n# Parametri della distribuzione\nmu &lt;- 175\nsigma &lt;- 7\nn &lt;- 30\nn_samples &lt;- 1000\n\n# Generazione dei campioni\nsamples &lt;- replicate(n_samples, rnorm(n, mean = mu, sd = sigma))\ndim(samples)  # Verifica dimensioni: 30 righe per 1000 colonne\n#&gt; [1]   30 1000\n\nIl primo campione di ampiezza \\(n = 30\\) che abbiamo ottenuto è il seguente:\n\nsamples[, 1]  # Primo campione\n#&gt;  [1] 171.1 173.4 185.9 175.5 175.9 187.0 178.2 166.1 170.2 171.9 183.6 177.5\n#&gt; [13] 177.8 175.8 171.1 187.5 178.5 161.2 179.9 171.7 167.5 173.5 167.8 169.9\n#&gt; [25] 170.6 163.2 180.9 176.1 167.0 183.8\n\nStampiamo le medie dei primi dieci campioni:\n\nsample_means &lt;- colMeans(samples)  # Medie di tutti i campioni\nsample_means[1:10]  # Prime dieci medie\n#&gt;  [1] 174.7 176.2 175.2 174.3 173.7 176.1 175.1 174.4 175.4 177.4\n\nTroviamo il valore critico della distribuzione \\(t\\) di Student con \\(n - 1\\) gradi di libertà e livello di confidenza del 95% (\\(\\alpha = 0.05\\)):\n\nalpha &lt;- 0.05\nt_critical &lt;- qt(1 - alpha / 2, df = n - 1)  # Valore critico\nt_critical\n#&gt; [1] 2.045\n\nUtilizzando il valore critico \\(t\\), calcoliamo 1000 intervalli di confidenza per la media della popolazione:\n\n# Calcolo della deviazione standard campionaria\nsample_sds &lt;- apply(samples, 2, sd)\n\n# Ampiezza degli intervalli\ninterval_width &lt;- t_critical * sample_sds / sqrt(n)\n\n# Limiti degli intervalli di confidenza\nCI_low &lt;- sample_means - interval_width\nCI_high &lt;- sample_means + interval_width\n\nTroviamo il livello di copertura, ovvero la proporzione di intervalli di confidenza che contengono il vero valore della media della popolazione \\(\\mu\\):\n\ncoverage &lt;- mean(CI_low &lt; mu & mu &lt; CI_high)  # Proporzione di copertura\ncoverage\n#&gt; [1] 0.956\n\nIn conclusione, ripetendo la simulazione per 1000 campioni, abbiamo ottenuto un livello di copertura molto vicino al valore nominale di \\(1 - \\alpha = 0.95\\). Questo risultato dimostra che, con un campione di dimensione \\(n = 30\\), gli intervalli di confidenza al 95% calcolati utilizzando la distribuzione \\(t\\) di Student forniscono stime accurate della media della popolazione.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#il-concetto-di-livello-di-confidenza",
    "href": "chapters/frequentist_inference/02_conf_interv.html#il-concetto-di-livello-di-confidenza",
    "title": "75  Intervalli di fiducia",
    "section": "\n75.6 Il Concetto di Livello di Confidenza",
    "text": "75.6 Il Concetto di Livello di Confidenza\nGli intervalli di confidenza sono range di valori che, con una certa sicurezza statistica, si ritiene includano il parametro di interesse.\nSecondo l’approccio frequentista, l’intervallo di confidenza si deve considerare come una metodologia:\n\nSe ripetiamo l’esperimento (estrarre un campione e calcolare l’intervallo di confidenza) molte volte, il metodo produce un intervallo che coprirà il valore vero del parametro nel 95% dei casi, assumendo un livello di confidenza del 95%.\n\n\n75.6.1 Un Malinteso Comune nell’Interpretazione degli Intervalli di Confidenza\nÈ inesatto affermare che un determinato intervallo di confidenza contenga il valore vero di un parametro con una probabilità del 95%. Questo è un errore diffuso, persino tra i ricercatori, che spesso interpretano l’intervallo di confidenza come indicativo della probabilità che il parametro (ad esempio, la media della popolazione \\(\\mu\\)) si trovi effettivamente all’interno di un dato intervallo (es. \\([\\hat{a}, \\hat{b}]\\)).\nLa descrizione corretta è la seguente:\n\n“La metodologia impiegata per calcolare l’intervallo \\([\\hat{a}, \\hat{b}]\\) ha il 95% di probabilità di generare un intervallo che include il vero valore del parametro”.\nCiò significa che l’intervallo di confidenza non esprime una probabilità circa la posizione precisa del parametro, ma riflette la probabilità che la procedura adottata per determinarlo generi un intervallo che lo includa.\n\nIn conclusione, l’intervallo di confidenza ci fornisce una garanzia statistica riguardo alla affidabilità del metodo usato per la sua stima, piuttosto che sulla esatta ubicazione del parametro in questione.\n\n75.6.2 Fraintendimenti Comuni sugli Intervalli di Confidenza\nNel loro lavoro, Hoekstra et al. (2014) evidenziano come, nonostante l’ampio riconoscimento dei limiti dei test di ipotesi nulle, gli intervalli di confidenza siano spesso consigliati per l’inferenza statistica. Anche l’American Psychological Association (APA) suggerisce che gli intervalli di confidenza siano “in generale, la migliore strategia di reportistica”. Tuttavia, Hoekstra et al. (2014) sottolineano che queste raccomandazioni non considerano la difficoltà nel fornire una corretta interpretazione degli intervalli di confidenza.\nPer indagare l’interpretazione degli intervalli di confidenza, Hoekstra et al. (2014) hanno condotto uno studio con due domande principali:\n\nQuanto frequentemente intervalli di confidenza sono mal interpretati da studenti e ricercatori?\nL’esperienza nella ricerca riduce le interpretazioni errate degli intervalli di confidenza?\n\nPrima di presentare lo studio, Hoekstra et al. (2014) ricordano qual è l’interpretazione corretta degli intervalli di confidenza.\n\nA CI is a numerical interval constructed around the estimate of a parameter. Such an interval does not, however, directly indicate a property of the parameter; instead, it indicates a property of the procedure, as is typical for a frequentist technique. Specifically, we may find that a particular procedure, when used repeatedly across a series of hypothetical data sets (i.e., the sample space), yields intervals that contain the true parameter value in 95% of the cases. When such a procedure is applied to a particular data set, the resulting interval is said to be a 95% CI. The key point is that the CIs do not provide for a statement about the parameter as it relates to the particular sample at hand; instead, they provide for a statement about the performance of the procedure of drawing such intervals in repeated use. Hence, it is incorrect to interpret a CI as the probability that the true value is within the interval (e.g., Berger & Wolpert, 1988). As is the case with \\(p\\)-values, CIs do not allow one to make probability statements about parameters or hypotheses.\n\nNel loro studio, Hoekstra et al. (2014) hanno presentato un questionario a 596 partecipanti, tra cui studenti universitari e ricercatori, con le seguenti affermazioni riguardanti l’interpretazione degli intervalli di confidenza.\n\nProfessor Bumbledorf conducts an experiment, analyzes the data, and reports: “The 95% confidence interval for the mean ranges from 0.1 to 0.4.” Please mark each of the statements below as ‘true’ or ‘false’.\n\n\n\nThe probability that the true mean is greater than 0 is at least 95%.\nThe probability that the true mean equals 0 is smaller than 5%.\nThe “null hypothesis” that the true mean equals 0 is likely to be incorrect.\nThere is a 95% probability that the true mean lies between 0.1 and 0.4.\nWe can be 95% confident that the true mean lies between 0.1 and 0.4.\nIf we were to repeat the experiment over and over, then 95% of the time the true mean falls between 0.1 and 0.4.\n\n\nSorprendentemente, anche se tutte le sei affermazioni nel questionario sono errate, molti partecipanti hanno concordato con esse. I risultati mostrano che, in media, i partecipanti hanno concordato con circa 3.5 affermazioni errate su 6. Non è stata rilevata una differenza di rilievo nell’interpretazione degli intervalli di confidenza tra studenti e ricercatori, suggerendo che l’esperienza nella ricerca non migliora la comprensione di questo concetto.\nI risultati indicano che molte persone interpretano erroneamente gli intervalli di confidenza, e che anche l’esperienza nella ricerca non garantisce una migliore comprensione. Questo solleva dubbi sull’efficacia degli intervalli di confidenza frequentisti e suggerisce che gli “intervalli di credibilità” bayesiani possano rappresentare un’alternativa più vantaggiosa. Quest’ultimi tendono ad essere più intuitivi e di più facile interpretazione corretta.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#confronto-tra-intervalli-frequentisti-e-bayesiani",
    "href": "chapters/frequentist_inference/02_conf_interv.html#confronto-tra-intervalli-frequentisti-e-bayesiani",
    "title": "75  Intervalli di fiducia",
    "section": "\n75.7 Confronto tra Intervalli Frequentisti e Bayesiani",
    "text": "75.7 Confronto tra Intervalli Frequentisti e Bayesiani\nConcludiamo questo capitolo esaminando le differenze tra l’intervallo di confidenza frequentista e l’intervallo di credibilità bayesiano, utilizzando lo stesso set di dati per entrambi i calcoli.\n\n75.7.1 Intervallo di confidenza frequentista\nImmaginiamo di avere un gruppo di 20 osservazioni relative alla performance in un test cognitivo. Il nostro obiettivo è stimare la media della popolazione da cui queste osservazioni sono tratte. Supponiamo che i dati provengano da una distribuzione normale con media \\(\\mu = 50\\) e deviazione standard \\(\\sigma = 10\\).\n\nset.seed(123)  # Per risultati riproducibili\n\n# Parametri della popolazione\nsample_size &lt;- 20\nmu &lt;- 50\nsigma &lt;- 10\n\n# Simulazione del campione\nsample_data &lt;- rnorm(sample_size, mean = mu, sd = sigma)\nprint(sample_data)\n#&gt;  [1] 44.40 47.70 65.59 50.71 51.29 67.15 54.61 37.35 43.13 45.54 62.24 53.60\n#&gt; [13] 54.01 51.11 44.44 67.87 54.98 30.33 57.01 45.27\n\nVisualizziamo la distribuzione dei dati:\n\ntibble(Valori = sample_data) |&gt;\n  ggplot(aes(x = Valori)) +\n  geom_histogram(aes(y = after_stat(density)),\n    bins = 30, # Puoi regolare il numero di bin\n    fill = \"skyblue\",\n    color = \"black\",\n    alpha = 0.7\n  ) +\n  labs(\n    title = \"Distribuzione dei dati campionari\",\n    x = \"Valori\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\nLa media campionaria (\\(\\hat{\\mu}\\)) viene calcolata come:\n\\[\n\\hat{\\mu} = \\frac{1}{n} \\sum_{i=1}^n X_i\n\\]\nIn R:\n\nsample_mean &lt;- mean(sample_data)\nsample_mean\n#&gt; [1] 51.42\n\nLa deviazione standard campionaria (\\(s\\)) si calcola come:\n\\[\ns = \\sqrt{\\frac{\\sum_{i=1}^n (X_i - \\bar{X})^2}{n-1}}\n\\]\nIn R:\n\nvariance &lt;- function(x) {\n  sum((x - mean(x))^2) / length(x)\n}\n\nsample_sd &lt;- sqrt(variance(sample_data))  # Deviazione standard campionaria\nsample_sd\n#&gt; [1] 9.48\n\nL’errore standard della media (\\(SE\\)) è:\n\\[\nSE = \\frac{s}{\\sqrt{n}}\n\\]\nIn R:\n\nstandard_error &lt;- sample_sd / sqrt(sample_size)\nstandard_error\n#&gt; [1] 2.12\n\nUn intervallo di confidenza è definito come:\n\\[\n\\bar{X} \\pm t_{\\text{critico}} \\cdot SE\n\\]\ndove \\(t_{\\text{critico}}\\) è il valore critico della distribuzione \\(t\\) di Student per un livello di confidenza del 95% (\\(\\alpha = 0.05\\)) e \\(n-1\\) gradi di libertà. In R:\n\nalpha &lt;- 0.05\ndf &lt;- sample_size - 1\nt_critical &lt;- qt(1 - alpha / 2, df)\nt_critical\n#&gt; [1] 2.093\n\nCalcoliamo il margine di errore:\n\nmargin_of_error &lt;- t_critical * standard_error\nmargin_of_error\n#&gt; [1] 4.437\n\nCalcoliamo i limiti inferiore e superiore dell’intervallo di confidenza:\n\nconfidence_interval &lt;- \n  c(sample_mean - margin_of_error, sample_mean + margin_of_error)\nconfidence_interval\n#&gt; [1] 46.98 55.85\n\nPossiamo interpretare questo risultato dicendo che la procedura utilizzata per calcolare l’intervallo include il valore vero della media della popolazione nel 95% dei casi.\nCreiamo un grafico per mostrare la distribuzione dei dati, la media campionaria e l’intervallo di confidenza:\n\ntibble(Valori = sample_data) |&gt;\n  ggplot(aes(x = Valori)) +\n  geom_histogram(aes(y = ..density..),\n    bins = 30, # Puoi regolare il numero di bin\n    fill = \"skyblue\",\n    color = \"black\",\n    alpha = 0.7\n  ) +\n\n  # Linea per la media campionaria\n  geom_vline(aes(xintercept = sample_mean),\n    color = \"blue\",\n    linetype = \"dashed\",\n    linewidth = 1.2\n  ) +\n\n  # Linee per l'intervallo di confidenza\n  geom_vline(aes(xintercept = confidence_interval[1]),\n    color = \"darkgreen\",\n    linewidth = 1.2\n  ) +\n  geom_vline(aes(xintercept = confidence_interval[2]),\n    color = \"darkgreen\",\n    linewidth = 1.2\n  ) +\n\n  # Titoli e assi\n  labs(\n    title = \"Intervallo di Confidenza per la Media\",\n    x = \"Valori\",\n    y = \"Densità\"\n  ) +\n\n  # Legenda personalizzata\n  annotate(\"text\",\n    x = sample_mean, y = 0.02, label = \"Media campionaria\",\n    color = \"blue\", angle = 90, vjust = -0.5\n  ) +\n  annotate(\"text\",\n    x = confidence_interval[1], y = 0.02, label = \"IC Inferiore\",\n    color = \"darkgreen\", angle = 90, vjust = -0.5\n  ) +\n  annotate(\"text\",\n    x = confidence_interval[2], y = 0.02, label = \"IC Superiore\",\n    color = \"darkgreen\", angle = 90, vjust = -0.5\n  )\n\n\n\n\n\n\n\n\n75.7.1.1 Confronto tra gli Approcci Frequentista e Bayesiano\nIntervallo di Credibilità Bayesiano:\n\nRappresenta il grado di credenza (posteriori) che il parametro \\(\\mu\\) si trovi all’interno dell’intervallo calcolato.\nDipende sia dai dati osservati sia dalle distribuzioni a priori utilizzate nel modello, che possono influenzare il risultato in base alla loro specificità o vaghezza.\n\nIntervallo di Confidenza Frequentista:\n\nNon esprime la probabilità che il parametro \\(\\mu\\) appartenga a un determinato intervallo.\nSi riferisce invece alla procedura di costruzione dell’intervallo: se il campionamento fosse ripetuto infinite volte, il 95% degli intervalli costruiti conterrebbe il vero valore di \\(\\mu\\).\n\nIn sintesi:\n\nL’intervallo di credibilità bayesiano fornisce una stima probabilistica diretta e interpretabile della posizione di \\(\\mu\\), basata su dati osservati e informazioni a priori.\nL’intervallo di confidenza frequentista, invece, valuta la affidabilità della procedura nel lungo termine, senza fare affermazioni dirette sulla probabilità che il parametro rientri nell’intervallo specifico.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/02_conf_interv.html#riflessioni-conclusive",
    "title": "75  Intervalli di fiducia",
    "section": "\n75.8 Riflessioni Conclusive",
    "text": "75.8 Riflessioni Conclusive\nCome sottolineato da Hoekstra et al. (2014), è comune riscontrare fraintendimenti riguardo agli intervalli di fiducia. Il “livello di confidenza del 95%” è da interpretarsi come la probabilità a lungo termine che, in una serie di intervalli di fiducia calcolati, il 95% di essi includa il vero valore del parametro sconosciuto. Tuttavia, per un singolo intervallo di fiducia, non è possibile dichiarare con sicurezza che questo contenga effettivamente il parametro di interesse. In altre parole, la certezza sulla presenza del parametro sconosciuto all’interno di un dato intervallo di fiducia non è garantita per ogni singolo caso analizzato.\nÈ inoltre inesatto presumere che esista un legame diretto tra la varianza e la media di un campione, ipotizzando che un intervallo di fiducia più ristretto implichi maggiore precisione. Nella prospettiva frequentista, la “precisione” è strettamente legata al livello di copertura a lungo termine assicurato dal metodo usato per creare gli intervalli di fiducia. Questo concetto non si applica al singolo intervallo di fiducia osservato. Dunque, un intervallo di fiducia che si presenta estremamente ristretto potrebbe in realtà essere significativamente lontano dal valore vero del parametro non noto.\nÈ importante sottolineare che l’approccio frequentista offre un metodo per calcolare gli intervalli di confidenza per una vasta gamma di statistiche. Questo include, ad esempio, la stima dell’intervallo di confidenza per la differenza tra due medie, per una proporzione o per la differenza tra due proporzioni. Ecco le formule per calcolare gli intervalli di confidenza per i casi menzionati:\nIntervallo di confidenza per la differenza tra due medie.\nSe abbiamo due campioni indipendenti di dimensione \\(n_1\\) e \\(n_2\\), con medie \\(\\bar{x}_1\\) e \\(\\bar{x}_2\\) e deviazioni standard \\(s_1\\) e \\(s_2\\), l’intervallo di confidenza per la differenza tra le medie è calcolato come:\n\\[\n(\\bar{x}_1 - \\bar{x}_2) \\pm t_{\\alpha/2} \\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}},\n\\]\ndove \\(t_{\\alpha/2}\\) è il valore critico della distribuzione t di Student con \\(\\alpha/2\\) di probabilità di coda e gradi di libertà \\(df = n_1 + n_2 - 2\\).\nIntervallo di confidenza per una proporzione.\nPer stimare l’intervallo di confidenza per una proporzione \\(p\\) in un campione binomiale di dimensione \\(n\\), la formula è:\n\\[\n\\hat{p} \\pm z_{\\alpha/2} \\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}},\n\\]\ndove \\(\\hat{p}\\) è la proporzione campionaria e \\(z_{\\alpha/2}\\) è il valore critico della distribuzione normale standard con \\(\\alpha/2\\) di probabilità di coda.\nIntervallo di confidenza per la differenza tra due proporzioni.\nPer stimare l’intervallo di confidenza per la differenza tra due proporzioni \\(p_1\\) e \\(p_2\\) in due campioni binomiali di dimensioni \\(n_1\\) e \\(n_2\\), la formula è:\n\\[\n(\\hat{p}_1 - \\hat{p}_2) \\pm z_{\\alpha/2} \\sqrt{\\frac{\\hat{p}_1(1 - \\hat{p}_1)}{n_1} + \\frac{\\hat{p}_2(1 - \\hat{p}_2)}{n_2}},\n\\]\ndove \\(\\hat{p}_1\\) e \\(\\hat{p}_2\\) sono le proporzioni campionarie e \\(z_{\\alpha/2}\\) è il valore critico della distribuzione normale standard con \\(\\alpha/2\\) di probabilità di coda.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#esercizi",
    "href": "chapters/frequentist_inference/02_conf_interv.html#esercizi",
    "title": "75  Intervalli di fiducia",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\n\nChe cos’è un intervallo di confidenza dal punto di vista frequentista?\nChe cosa significa la copertura al 95% di un intervallo di confidenza?\nPerché non è corretto dire che “c’è il 95% di probabilità che il valore vero di \\(\\mu\\) cada in questo intervallo di confidenza”?\nIn cosa consiste la differenza tra un intervallo di confidenza costruito con la distribuzione normale standard \\(Z\\) e uno costruito con la distribuzione \\(t\\) di Student?\nPerché, nel caso di varianza incognita, si usa la deviazione standard campionaria \\(s\\) al posto di \\(\\sigma\\)?\nCome influenza la dimensione del campione \\(n\\) l’ampiezza dell’intervallo di confidenza?\nPerché gli intervalli di confidenza frequentisti si basano su un concetto di “ripetizione dell’esperimento” nel lungo periodo?\nQuali sono due fraintendimenti comuni sugli intervalli di confidenza?\nCome si interpreta correttamente un intervallo di confidenza al 95%?\nQual è la differenza essenziale tra un intervallo di confidenza frequentista e un intervallo di credibilità bayesiano?\n\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\n\nChe cos’è un intervallo di confidenza dal punto di vista frequentista?\n\nRisposta\nUn intervallo di confidenza (IC) è un range di valori costruito attorno a una stima campionaria (ad esempio, la media campionaria) che, secondo il metodo frequentista adottato, conterrà il valore vero del parametro in una certa proporzione di casi (ad esempio il 95%) se si ripetesse l’esperimento (ossia il campionamento) un numero molto grande di volte. Non esprime dunque la “probabilità” che il parametro sia dentro l’intervallo in un singolo caso, ma una frequenza di successo nel lungo periodo.\n\nChe cosa significa la copertura al 95% di un intervallo di confidenza?\n\nRisposta\nIl livello di copertura (ad esempio, 95%) indica che, in una serie ipotetica di infiniti campioni indipendenti e nel calcolo ripetuto di infiniti intervalli di confidenza secondo la stessa procedura, il 95% di tali intervalli conterrà il valore vero del parametro. È una proprietà della procedura di costruzione degli intervalli, non di un singolo intervallo già calcolato.\n\nPerché non è corretto dire che “c’è il 95% di probabilità che il valore vero di \\(\\mu\\) cada in questo intervallo di confidenza”?\n\nRisposta\nNella prospettiva frequentista, il parametro \\(\\mu\\) è considerato un valore fisso (non una variabile casuale). L’incertezza risiede nel campione e nella procedura di costruzione dell’intervallo, non nel parametro. Di conseguenza, non si può associare una probabilità alla posizione di \\(\\mu\\) all’interno di un singolo intervallo: l’intervallo o contiene \\(\\mu\\) oppure no, senza mezze misure probabilistiche.\n\nIn cosa consiste la differenza tra un intervallo di confidenza costruito con la distribuzione normale standard \\(Z\\) e uno costruito con la distribuzione \\(t\\) di Student?\n\nRisposta\n- Distribuzione \\(Z\\): si utilizza quando la varianza della popolazione \\(\\sigma^2\\) è nota (o si approssima molto bene) e la popolazione è normalmente distribuita, o quando il campione è molto grande (per applicare il teorema del limite centrale).\n- Distribuzione \\(t\\): si impiega quando la varianza \\(\\sigma^2\\) non è nota e bisogna stimarla con la deviazione standard campionaria \\(s\\). La distribuzione \\(t\\) “corregge” per l’incertezza aggiuntiva dovuta alla stima di \\(\\sigma\\) e diventa progressivamente simile alla normale standard quando il numero di gradi di libertà (cioè la dimensione del campione meno uno) è elevato.\n\nPerché, nel caso di varianza incognita, si usa la deviazione standard campionaria \\(s\\) al posto di \\(\\sigma\\)?\n\nRisposta\nQuando \\(\\sigma\\) non è nota, la si sostituisce con la stima campionaria \\(s\\). Poiché \\(s\\) è anch’essa una variabile casuale (cioè dipende dai dati osservati), introduce un’ulteriore fonte di incertezza. Questo giustifica l’uso della distribuzione \\(t\\) di Student anziché della normale standard, poiché \\(t\\) ingloba tale incertezza aggiuntiva.\n\nCome influenza la dimensione del campione \\(n\\) l’ampiezza dell’intervallo di confidenza?\n\nRisposta\nAumentando \\(n\\), l’errore standard della media (cioè \\(\\frac{\\sigma}{\\sqrt{n}}\\) oppure \\(\\frac{s}{\\sqrt{n}}\\)) diminuisce. Di conseguenza, l’intervallo di confidenza si restringe (a parità di livello di confidenza). In altre parole, con più dati a disposizione la stima della media è più “precisa” nel senso frequentista, e ciò si riflette in un IC più stretto.\n\nPerché gli intervalli di confidenza frequentisti si basano su un concetto di “ripetizione dell’esperimento” nel lungo periodo?\n\nRisposta\nLa filosofia frequentista definisce la probabilità come una frequenza relativa di un evento dopo molteplici repliche dell’esperimento. Per gli intervalli di confidenza, ciò implica che la probabilità di copertura (ad esempio 95%) è intesa come la frequenza con cui, ripetendo infinite volte il campionamento e la costruzione di IC allo stesso modo, l’intervallo calcolato conterrà il vero parametro. Non riguarda invece la probabilità del parametro di trovarsi in un intervallo specifico.\n\nQuali sono due fraintendimenti comuni sugli intervalli di confidenza?\n\nRisposta\n1. Credere che l’IC fornisca una probabilità diretta di contenere il parametro (es. “c’è il 95% di probabilità che \\(\\mu\\) sia qui dentro”) – in realtà, nel frequentismo \\(\\mu\\) è fisso e l’IC varia.\n2. Pensare che l’intervallo di confidenza sia significativo per la singola stima più che per la procedura – in realtà, il 95% di copertura si riferisce alla ripetizione dell’esperimento, non a un singolo intervallo.\n\nCome si interpreta correttamente un intervallo di confidenza al 95%?\n\nRisposta\n“Se ripetiamo più volte l’esperimento, ossia estraiamo molti campioni indipendenti dalla popolazione e costruiamo ogni volta un intervallo di confidenza con la stessa procedura, allora il 95% di quegli intervalli conterrà il valore vero della media \\(\\mu\\).” È dunque una garanzia circa l’efficacia della metodologia nel lungo periodo.\n\nQual è la differenza essenziale tra un intervallo di confidenza frequentista e un intervallo di credibilità bayesiano?\n\nRisposta\n- Intervallo di confidenza frequentista: descrive la performance a lungo termine di una procedura; non permette di affermare “la probabilità che \\(\\mu\\) sia nell’intervallo è il 95%”.\n- Intervallo di credibilità bayesiano: esprime direttamente una credenza probabilistica a posteriori sul parametro (ad esempio, “c’è il 95% di probabilità che \\(\\mu\\) sia in questo intervallo”), perché il parametro è trattato come variabile casuale, con una distribuzione a priori che si aggiorna con i dati osservati.\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nDi seguito trovi 10 esercizi incentrati sulla costruzione di intervalli di confidenza. I primi 5 richiedono di svolgere i calcoli “a mano” (carta e penna o calcolatrice), gli ultimi 5 prevedono l’utilizzo di R.\nEsercizi da Risolvere “a Mano”\n\nIntervallo di Confidenza per la Media (Varianza Nota)\n\nUna ricercatrice vuole stimare la media di un punteggio di reattività emotiva (scala 0–100) in giovani adulti. Dai dati precedenti, si sa che la varianza vera (della popolazione) è \\(\\sigma^2 = 16\\). Si raccoglie un campione di \\(n=25\\) partecipanti e la media campionaria risulta \\(\\bar{X} = 45\\).\n1. Calcola l’intervallo di confidenza al 95% per la media della popolazione (\\(\\mu\\)).\n2. Fornisci un’interpretazione corretta (frequentista) del risultato.\n\nIntervallo di Confidenza per la Media (Varianza Incognita, 99%)\n\nIn un’indagine sulla soddisfazione lavorativa (scala da 1 a 7), vengono coinvolti \\(n=10\\) psicologi clinici. I dati raccolti forniscono:\n- Media campionaria \\(\\bar{X} = 5{,}6\\)\n- Deviazione standard campionaria \\(s=0{,}8\\)\nLa popolazione è considerata approssimativamente normale ma la varianza è ignota. Calcola l’IC al 99% per la vera media di soddisfazione \\(\\mu\\).\n\nIntervallo di Confidenza per la Differenza tra Due Medie (Varianze Incognite Uguali)\n\nUn team di psicologi del lavoro vuole confrontare i livelli di stress (scala 0–50) tra due gruppi di dipendenti di un’azienda (Campione 1: reparto A, Campione 2: reparto B). I dati sono:\n\nReparto A (\\(n_1=12\\)):\\(\\bar{X}_1 = 22\\), \\(s_1 = 4\\)\nReparto B (\\(n_2=10\\)):\\(\\bar{X}_2 = 19\\), \\(s_2 = 3{,}5\\)\n\nAssumi che le due popolazioni siano normali con varianze ignote ma uguali e calcola l’intervallo di confidenza al 95% per \\(\\mu_A - \\mu_B\\). (Usa quindi la formula con la varianza pooled.)\n\nIntervallo di Confidenza per una Proporzione\n\nUno studio pilota su un programma di training per la gestione dell’ansia vede 120 persone iscriversi. Alla fine del programma, 48 di loro riportano di aver diminuito la frequenza di attacchi di panico in modo “significativo”.\n1. Stima la proporzione campionaria \\(\\hat{p}\\).\n2. Calcola l’IC al 95% per la vera proporzione \\(p\\) di persone che trarrebbe beneficio “significativo” dal programma.\n\nIntervallo di Confidenza per la Differenza tra Due Proporzioni\n\nIn un esperimento, due gruppi di partecipanti ricevono diversi percorsi di psicoterapia per ridurre l’insonnia:\n\n\nGruppo 1 (\\(n_1=50\\)): 35 persone riportano un netto miglioramento del sonno.\n\n\nGruppo 2 (\\(n_2=40\\)): 20 persone riportano un netto miglioramento del sonno.\n\nSi vuole stimare la differenza \\((p_1 - p_2)\\) nelle proporzioni di successo dei due trattamenti. Calcola l’IC al 95%.\nEsercizi da Risolvere con R\nNei prossimi esercizi, utilizza R per effettuare i calcoli. I dati sono già contestualizzati in ambito psicologico.\n\nIntervallo di Confidenza per la Media (Varianza Incognita)\n\nHai misurato i tempi di reazione (in millisecondi) a uno stimolo di pericolo in un gruppo di 15 partecipanti. I dati (approssimati) sono:\nreaction_times &lt;- c(220, 250, 210, 240, 260, 270, 225, 255, 235, 245, 210, 270, 265, 220, 230)\n\nUtilizza R per calcolare la media e la deviazione standard campionaria.\n\nCostruisci (tramite t.test(reaction_times)) l’intervallo di confidenza al 95% per il tempo di reazione medio della popolazione.\n\n\nIntervallo di Confidenza per la Differenza tra Due Medie (Varianze Incognite)\n\nDue gruppi di studenti hanno svolto un test di memoria verbale dopo aver seguito differenti strategie di studio:\ngroupA &lt;- c(15, 12, 18, 10, 14, 16, 19, 11)\ngroupB &lt;- c(10, 9, 14, 11, 8, 12, 13, 15)\n\nCalcola in R le medie campionarie dei due gruppi.\n\nUtilizza t.test(groupA, groupB, var.equal = FALSE) per ottenere l’IC al 95% della differenza \\(\\mu_A - \\mu_B\\).\n\nRiporta i risultati numerici.\n\n\nIntervallo di Confidenza per una Proporzione (Studio su Fobia Specifica)\n\nIn un piccolo studio, hai i dati (binari: 1 = “attacco d’ansia”, 0 = “nessun attacco”) raccolti da 20 persone esposte a uno stimolo fobico:\nattacks &lt;- c(1,0,0,1,1,1,1,0,0,1,0,1,1,1,1,0,0,1,0,1)\n\nCalcola in R la proporzione campionaria di attacchi d’ansia.\n\nUtilizza prop.test() per costruire l’IC al 95% per la proporzione vera di attacchi d’ansia in questa specifica situazione.\n\n\nIntervallo di Confidenza per la Differenza tra Due Proporzioni (Test A/B di un Training Psicologico)\n\nDue versioni di un training psicologico anti-stress (A e B) sono state testate su studenti universitari, registrando (binario: 1/0) se al termine del corso mostrano ridotti livelli di stress:\nversionA &lt;- c(1,1,0,1,1,0,1,0,1,1,0,1)\nversionB &lt;- c(0,0,1,1,1,0,1,0,0,1,0,0)\n\nCalcola in R \\(\\hat{p}_A\\) e \\(\\hat{p}_B\\).\n\nUsa prop.test(x = ..., n = ...) per l’IC al 95% di \\((p_A - p_B)\\).\n\nRiporta i risultati.\n\n\nSimulazione di Copertura per l’IC sulla Media (Contesto Psicologico)\n\nScrivi (o completa) uno script in R che simuli 1000 campioni di punteggi di ansia (scala 0–80) estratti da una distribuzione approssimata come Normale, con media vera \\(\\mu=40\\) e \\(\\sigma=10\\). Per ogni campione di ampiezza \\(n=25\\):\n\nCalcola la media campionaria e la deviazione standard.\n\nCostruisci l’IC al 95% (usando la distribuzione t).\n\nVerifica quante volte l’intervallo contiene il vero valore \\(\\mu = 40\\).\n\nStima la proporzione di copertura e commenta se è prossima a 0,95.\n\nEsempio di traccia:\nset.seed(123)\nn_sims &lt;- 1000\nn &lt;- 25\nmu &lt;- 40\nsigma &lt;- 10\n\ncount_included &lt;- 0\n\nfor(i in 1:n_sims){\n  sample_data &lt;- rnorm(n, mean = mu, sd = sigma)\n  # calcola media, sd, IC, verifica se 40 è dentro l’IC\n}\n\ncoverage &lt;- count_included / n_sims\ncoverage\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\nSoluzioni Esercizi “a Mano”\nSoluzione 1\n\nDati: \\(\\sigma^2=16 \\implies \\sigma=4\\); \\(n=25\\); \\(\\bar{X}=45\\); livello di confidenza 95% (\\(\\alpha=0{,}05\\)).\n\nErrore standard:\\[\n\\text{SE} = \\frac{\\sigma}{\\sqrt{n}} = \\frac{4}{5} = 0{,}8.\n\\]\n\nValore critico \\(z_{\\alpha/2}\\approx 1{,}96\\).\n\nMargine di errore:\\[\nE = z_{\\alpha/2} \\times \\text{SE} \\approx 1{,}96 \\times 0{,}8 = 1{,}57.\n\\]\n\nIC 95%:\\[\n45 \\pm 1{,}57 \\quad \\Rightarrow \\quad (43{,}43;\\, 46{,}57).\n\\]\n\n\nSoluzione 2\n\nDati: \\(n=10\\), \\(\\bar{X}=5{,}6\\), \\(s=0{,}8\\), confidenza 99% (\\(\\alpha=0{,}01\\)).\n\nGradi di libertà \\(df = 9\\). Il valore di \\(t_{\\alpha/2, df=9}\\) (per \\(\\alpha/2=0{,}005\\)) è approssimativamente 3,25 (dipende dalla tabella).\n\nErrore standard:\\[\n\\text{SE} = \\frac{s}{\\sqrt{n}} = \\frac{0{,}8}{\\sqrt{10}} \\approx \\frac{0{,}8}{3{,}162} \\approx 0{,}253.\n\\]\n\nMargine di errore:\\[\nE = 3{,}25 \\times 0{,}253 \\approx 0{,}82.\n\\]\n\nIC al 99%:\\[\n5{,}6 \\pm 0{,}82 \\quad \\Rightarrow \\quad (4{,}78;\\, 6{,}42).\n\\]\n\n\nSoluzione 3\n\nDati:\n\nCampione 1 (A): \\(n_1=12\\), \\(\\bar{X}_1=22\\), \\(s_1=4\\).\n\nCampione 2 (B): \\(n_2=10\\), \\(\\bar{X}_2=19\\), \\(s_2=3{,}5\\).\n\nIC 95% \\(\\Rightarrow \\alpha=0{,}05\\).\n\nSi assume varianza uguale (\\(\\sigma_A^2 = \\sigma_B^2\\)) \\(\\Rightarrow\\) varianza pooled.\n\n\n\n\nVarianza campionaria: \\(s_1^2=16\\), \\(s_2^2=12{,}25\\).\n\nVarianza pooled:\\[\ns_p^2\n= \\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}\n= \\frac{(11 \\times 16) + (9 \\times 12{,}25)}{12 + 10 - 2}.\n\\] \\[\n= \\frac{176 + 110{,}25}{20}\n= \\frac{286{,}25}{20}\n= 14{,}3125.\n\\] \\[\ns_p = \\sqrt{14{,}3125} \\approx 3{,}785.\n\\]\n\nErrore standard della differenza:\\[\n\\text{SE}(\\bar{X}_1 - \\bar{X}_2)\n= \\sqrt{\\,s_p^2\\!\\left(\\tfrac{1}{n_1} + \\tfrac{1}{n_2}\\right)}\n= \\sqrt{\\,14{,}3125 \\times \\left(\\tfrac{1}{12} + \\tfrac{1}{10}\\right)}.\n\\] \\[\n\\tfrac{1}{12} + \\tfrac{1}{10} = 0{,}0833 + 0{,}1 = 0{,}1833.\n\\] \\[\n14{,}3125 \\times 0{,}1833 \\approx 2{,}624\n\\quad \\Rightarrow \\quad \\sqrt{2{,}624} \\approx 1{,}62.\n\\]\n\nDifferenza campionaria: \\(\\bar{X}_1 - \\bar{X}_2 = 3\\).\n\nValore critico \\(t_{\\alpha/2}\\) con \\(df = n_1 + n_2 - 2 = 20\\): circa 2,086.\n\nMargine di errore: \\(E \\approx 2{,}086 \\times 1{,}62 \\approx 3{,}38\\).\n\nIC 95%:\\[\n3 \\pm 3{,}38 \\quad \\Rightarrow \\quad (-0{,}38;\\, 6{,}38).\n\\] (Approssimando: i valori variano un po’ in base agli arrotondamenti.)\n\n\nSoluzione 4\n\nDati: \\(n=120\\), successo \\(x=48\\).\n\n\n\\(\\hat{p} = \\frac{48}{120}=0{,}4\\).\n\nErrore standard (approssimazione normale):\\[\n\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} = \\sqrt{\\frac{0{,}4 \\times 0{,}6}{120}} = \\sqrt{\\frac{0{,}24}{120}} = \\sqrt{0{,}002} \\approx 0{,}0447.\n\\]\n\nCon \\(\\alpha=0{,}05\\), \\(z_{\\alpha/2} \\approx 1{,}96\\).\n\nMargine di errore:\\[\nE = 1{,}96 \\times 0{,}0447 \\approx 0{,}0876.\n\\]\n\nIC 95%:\\[\n0{,}4 \\pm 0{,}0876 \\quad \\Rightarrow \\quad (0{,}3124;\\, 0{,}4876).\n\\]\n\n\nSoluzione 5\n\nDati:\n\nGruppo 1 (\\(n_1=50\\)): 35 successi \\(\\Rightarrow \\hat{p}_1=35/50=0{,}70\\).\n\nGruppo 2 (\\(n_2=40\\)): 20 successi \\(\\Rightarrow \\hat{p}_2=20/40=0{,}50\\).\n\n\n\nDifferenza: \\(\\hat{p}_1 - \\hat{p}_2=0{,}20\\).\n\nErrore standard:\\[\n\\sqrt{\\frac{0{,}70 \\cdot 0{,}30}{50} + \\frac{0{,}50 \\cdot 0{,}50}{40}}\n= \\sqrt{\\frac{0{,}21}{50} + \\frac{0{,}25}{40}}\n= \\sqrt{0{,}0042 + 0{,}00625}\n= \\sqrt{0{,}01045} \\approx 0{,}1022.\n\\]\n\nMargine di errore (al 95%, \\(z_{\\alpha/2}=1{,}96\\)):\\[\n1{,}96 \\times 0{,}1022 \\approx 0{,}200.\n\\]\n\nIC 95%:\\[\n0{,}20 \\pm 0{,}20 \\quad \\Rightarrow \\quad (0{,}00;\\, 0{,}40).\n\\] *(Può capitare un limite inferiore esattamente 0, se si arrotonda.)\n\nSoluzioni Esercizi con R\n(I risultati possono variare leggermente a seconda della versione di R e di eventuali correzioni di continuità nelle funzioni di test.)\nSoluzione 6\nreaction_times &lt;- c(220, 250, 210, 240, 260, 270, 225, 255, 235, 245, 210, 270, 265, 220, 230)\n\nmean(reaction_times)         # media\nsd(reaction_times)           # deviazione standard\nt.test(reaction_times)       # t.test con conf.level = 0.95 di default\n\nEsempio di risultato:\n\nMedia campionaria \\(\\bar{X}\\approx 240\\) (dipende dai dati esatti)\n\n\nt.test() riporta un IC 95% (ad es.): \\((230, 250)\\) [numeri a titolo di esempio].\n\n\n\nSoluzione 7\ngroupA &lt;- c(15, 12, 18, 10, 14, 16, 19, 11)\ngroupB &lt;- c(10, 9, 14, 11, 8, 12, 13, 15)\n\nmean(groupA)  # ~ 14.375\nmean(groupB)  # ~ 11.50\nt.test(groupA, groupB, var.equal = FALSE)\n\n\nEsempio di output (fittizio):\nWelch Two Sample t-test\ndata:  groupA and groupB\nt = 2.35, df = 13.7, p-value = 0.033\n95 percent confidence interval:\n  0.47  5.77\nsample estimates:\n  mean of x  mean of y \n      14.375     11.500\nQuindi l’IC 95% per \\(\\mu_A - \\mu_B\\) potrebbe essere circa \\((0{,}47;\\, 5{,}77)\\).\n\n\nSoluzione 8\nattacks &lt;- c(1,0,0,1,1,1,1,0,0,1,0,1,1,1,1,0,0,1,0,1)\n\nsum(attacks)        # conta quanti \"1\"\nlength(attacks)     # 20\n\nprop.test(sum(attacks), length(attacks), conf.level = 0.95)\n\nSe, ad esempio, vi fossero 12 “1” su 20, \\(\\hat{p}=0{,}60\\).\n\nL’intervallo di confidenza al 95% (a seconda della continuity correction) potrebbe essere indicativamente \\((0{,}36;\\, 0{,}80)\\).\n\nSoluzione 9\nversionA &lt;- c(1,1,0,1,1,0,1,0,1,1,0,1)\nversionB &lt;- c(0,0,1,1,1,0,1,0,0,1,0,0)\n\nsumA &lt;- sum(versionA)\nsumB &lt;- sum(versionB)\nnA   &lt;- length(versionA)\nnB   &lt;- length(versionB)\n\nprop.test(c(sumA,sumB), c(nA,nB), conf.level = 0.95)\n\nEsempio:\n\n\nsum(versionA) = 8 successi su 12 (\\(\\hat{p}_A=0{,}666...\\))\n\n\nsum(versionB) = 5 successi su 12 (\\(\\hat{p}_B=0{,}416...\\))\n\nL’IC per \\(\\hat{p}_A - \\hat{p}_B\\) potrebbe essere, ad esempio, \\((-0{,}05;\\, 0{,}61)\\).\n\n\n\n(I numeri esatti variano a seconda dell’eventuale correzione di continuità.)\nSoluzione 10\nUn possibile script:\nset.seed(123)\nn_sims &lt;- 1000\nn &lt;- 25\nmu &lt;- 40\nsigma &lt;- 10\n\ncount_included &lt;- 0\n\nfor(i in 1:n_sims){\n  sample_data &lt;- rnorm(n, mean = mu, sd = sigma)\n  xbar &lt;- mean(sample_data)\n  s &lt;- sd(sample_data)\n  \n  # t critico\n  t_crit &lt;- qt(0.975, df = n - 1)\n  \n  # IC\n  se &lt;- s / sqrt(n)\n  E &lt;- t_crit * se\n  lower &lt;- xbar - E\n  upper &lt;- xbar + E\n  \n  if(mu &gt;= lower & mu &lt;= upper){\n    count_included &lt;- count_included + 1\n  }\n}\n\ncoverage &lt;- count_included / n_sims\ncoverage\n\n\nEsempio di risultato:\n&gt; coverage\n[1] 0.948\nOvvero ~94,8% degli IC contengono il vero valore \\(\\mu=40\\), in linea con il 95% atteso (piccole differenze dovute al caso).\n\n\nCommento Conclusivo\nIn ogni caso, ricorda sempre che l’interpretazione frequentista di un intervallo di confidenza si basa sulla “copertura a lungo termine” del metodo di costruzione dell’IC, non sulla probabilità che il vero parametro cada nell’intervallo specifico appena calcolato.\n\n\n\n\n\n\n\n\n\nProblemi 3\n\n\n\n\n\nEsercizio 1 – Calcolo e interpretazione dell’IC frequentista per la media\n\n\nCalcola la media campionaria \\(\\bar{X}\\) e la deviazione standard campionaria \\(s\\).\n\nAssumendo che il punteggio SWLS nella popolazione di riferimento (ad esempio, “giovani adulti universitari”) sia approssimativamente normale ma con varianza sconosciuta, costruisci l’intervallo di confidenza al 95% per la media \\(\\mu\\) utilizzando la distribuzione \\(t\\) di Student con \\(n - 1\\) gradi di libertà (dove \\(n=10\\)).\n\n\nInterpreta questo intervallo di confidenza in ottica frequentista. Metti in evidenza la distinzione fra l’“interpretazione corretta” (copertura sul lungo periodo) e l’“interpretazione scorretta” (credere che ci sia il 95% di probabilità che \\(\\mu\\) stia nell’intervallo calcolato).\n\nSpunti di riflessione sui limiti:\n- Con un campione molto piccolo, l’intervallo di confidenza potrebbe essere molto ampio.\n- Se la popolazione non fosse davvero normale, la validità dell’IC con distribuzione \\(t\\) potrebbe essere compromessa.\n- In ottica frequentista, il singolo intervallo o contiene il vero valore di \\(\\mu\\) o non lo contiene: la “probabilità 95%” si riferisce alla procedura di costruzione, non a questo singolo intervallo specifico.\nEsercizio 2 – Sensibilità dell’IC a diversi livelli di confidenza\n\nUtilizzando gli stessi 10 dati, calcola:\n\nl’intervallo di confidenza all’80%\n\nl’intervallo di confidenza al 99%\n\n\n\nConfronta l’ampiezza dei tre intervalli (80%, 95%, 99%).\n\nCommenta dal punto di vista dell’interpretazione frequentista: perché l’IC al 99% è più ampio di quello al 95%, e quest’ultimo è più ampio di quello all’80%?\n\nSpunti di riflessione sui limiti:\n- Aumentare il livello di confidenza fa sì che l’IC si allarghi, spesso di molto se \\(n\\) è piccolo.\n- Un IC più ampio rassicura sulla “copertura” nel lungo periodo, ma è meno informativo per il singolo studio.\nEsercizio 3 – Utilizzo di software per il calcolo (ad esempio, R o altro)\n\n\nInserisci i dati in un software (come R). Puoi farlo in R con:\nswls_data &lt;- c(28, 22, 26, 18, 30, 24, 27, 17, 21, 25)\n\n\nCalcola la media e la deviazione standard in R, poi utilizza la funzione t.test():\nt.test(swls_data, conf.level = 0.95)\n\nRiporta l’intervallo di confidenza ottenuto e confrontalo con quello calcolato a mano.\nCommenta eventuali differenze (minime) dovute agli arrotondamenti o a correzioni interne di R.\nRibadisci la corretta interpretazione frequentista: se si ripetesse lo stesso studio molte volte (stessa dimensione campionaria, stesso contesto di popolazione, stessa procedura di calcolo), il 95% di questi IC conterrebbe il valore vero di \\(\\mu\\).\n\nEsercizio 4 – Confronto pratico e riflessioni critiche\n\nImmagina di avere un’ipotesi: “La media SWLS nella popolazione dei giovani adulti universitari è pari a 24” (un’ipotesi plausibile se la scala totale va da 5 a 35).\n\nOsserva l’IC al 95% che hai calcolato: contiene il valore 24?\n\nSe l’IC contiene 24, puoi dire che il valore “24” è “molto probabile”? (No, attenzione! Vedi interpretazione corretta vs. errata.)\n\nSe l’IC non contiene 24, puoi concludere che la media reale è “sicuramente” diversa da 24? (No, perché hai solo un campione piccolo e il concetto di significatività vs. copertura può essere fuorviante.)\n\nSpunti di riflessione sui limiti:\n- Il “livello di fiducia” dell’IC non è una “probabilità” che \\(\\mu\\) sia all’interno di un singolo intervallo: è una proprietà della procedura sul lungo periodo.\n- Con pochi dati, le assunzioni (come la normalità) e la variabilità casuale giocano un ruolo enorme: l’intervallo può risultare poco stabile e molto sensibile a pochi valori estremi.\n- L’IC non dice “quanto è plausibile 24” (questo sarebbe più vicino a un approccio bayesiano, che definisce un intervallo di credibilità). L’IC frequentista dice soltanto che, ripetendo molte volte la stessa procedura, nel 95% dei casi il vero \\(\\mu\\) cadrà entro l’intervallo calcolato in ciascuna ripetizione.\n\n\n\n\n\n\n\n\n\nSoluzioni 3\n\n\n\n\n\nSupponiamo siano stati raccolti i dati seguenti (sostituisci con i dati effettivi):\n28, 22, 26, 18, 30, 24, 27, 17, 21, 25\nEsercizio 1\n\nCalcolo di media e deviazione standard campionaria\n\nIndichiamo i punteggi come \\(X_1, X_2, \\dots, X_{10}\\). La media campionaria è:\n\\[\n\\bar{X} = \\frac{1}{n}\\sum_{i=1}^n X_i.\n\\]\nFacendo la somma \\(28 + 22 + 26 + 18 + 30 + 24 + 27 + 17 + 21 + 25 = 238\\).\nQuindi, con \\(n=10\\), otteniamo:\n\\[\n\\bar{X} = \\frac{238}{10} = 23.8.\n\\]\nPer la deviazione standard campionaria \\(s\\), si utilizza:\n\\[\ns = \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^n \\bigl(X_i - \\bar{X}\\bigr)^2}.\n\\]\nCalcolando (o usando un foglio di calcolo / software), si ricava approssimativamente:\n\\[\ns \\approx 4.26.\n\\]\n\nCostruzione dell’Intervallo di Confidenza al 95%\n\nPoiché la varianza è sconosciuta e il campione è piccolo, usiamo la distribuzione \\(t\\) di Student con \\(n-1 = 9\\) gradi di libertà.\n- Livello di confidenza: \\(95\\%\\).\n- \\(\\alpha = 0,05\\), quindi \\(\\alpha/2 = 0,025\\).\n- Il valore critico \\(t_{\\alpha/2,df=9}\\) è circa 2,262 (da tavole o software).\n\nErrore standard\n\n\\[\n\\text{SE} = \\frac{s}{\\sqrt{n}} = \\frac{4.26}{\\sqrt{10}} \\approx 4.26 / 3.162 \\approx 1.35.\n\\]\n\nMargine di errore\n\n\\[\nE = t_{\\alpha/2} \\times \\text{SE} \\approx 2.262 \\times 1.35 \\approx 3.05.\n\\]\n\nIntervallo di confidenza\n\n\\[\n\\bar{X} \\pm E \\quad \\Rightarrow \\quad 23.8 \\pm 3.05\n\\quad \\Rightarrow \\quad (20.75;\\, 26.85).\n\\]\n\nInterpretazione frequentista corretta\n\n\n\nInterpretazione corretta: se ripetessimo lo stesso tipo di studio molte volte (stessa procedura di campionamento, stesse dimensioni, stesso metodo di calcolo dell’IC), il 95% di questi intervalli conterrà il vero valore della media della popolazione (\\(\\mu\\)).\n\n\nInterpretazione scorretta (da evitare): “C’è il 95% di probabilità che la vera media sia qui dentro”. Nel frequentismo, \\(\\mu\\) è considerato un valore fisso e non aleatorio. L’incertezza riguarda l’intervallo, non il parametro.\n\nLimite: con poche osservazioni (n=10), l’intervallo può risultare piuttosto ampio. Inoltre, l’assunzione di normalità della popolazione di partenza potrebbe non essere pienamente soddisfatta.\nEsercizio 2\n\nCalcolo di due nuovi IC: 80% e 99%\n\nUtilizziamo gli stessi \\(\\bar{X} = 23.8\\), \\(s = 4.26\\), \\(n=10\\). Cambia solo il valore critico \\(t\\).\n\n\nIC all’80% (\\(\\alpha=0,20\\), \\(\\alpha/2 = 0,10\\)):\n\n\n\\(t_{0,10,df=9} \\approx 1.383\\)\n\n\n\\(\\text{SE} \\approx 1.35\\) (come prima)\n\nMargine di errore \\(E = 1.383 \\times 1.35 \\approx 1.87\\)\n\nIC 80%: \\((23.8 \\pm 1.87)\\) \\(\\Rightarrow\\) \\((21.93;\\, 25.67)\\).\n\n\n\nIC al 99% (\\(\\alpha=0,01\\), \\(\\alpha/2 = 0,005\\)):\n\n\n\\(t_{0,005,df=9} \\approx 3.25\\)\n\n\n\\(\\text{SE} \\approx 1.35\\)\n\nMargine di errore \\(E = 3.25 \\times 1.35 \\approx 4.39\\)\n\nIC 99%: \\((23.8 \\pm 4.39)\\) \\(\\Rightarrow\\) \\((19.41;\\, 28.19)\\).\n\n\n\n\nConfronto delle ampiezze\n\n\n\n80%: \\((21.93;\\, 25.67)\\) (più stretto)\n\n\n95%: \\((20.75;\\, 26.85)\\) (intermedio)\n\n\n99%: \\((19.41;\\, 28.19)\\) (più largo)\n\nAumentando il livello di confidenza, l’intervallo si espande. Per “coprire” il valore vero nel 99% delle volte, occorre un intervallo più ampio.\nEsercizio 3\n\nCalcolo in R\n\nSe in R inseriamo i dati:\nswls_data &lt;- c(28, 22, 26, 18, 30, 24, 27, 17, 21, 25)\n\nmean(swls_data)  # ~ 23.8\nsd(swls_data)    # ~ 4.26\nt.test(swls_data, conf.level = 0.95)\n\nConfronto con il calcolo “a mano”\n\nLa funzione t.test() (di default) eseguirà un One Sample t-test con confidenza 95%. Restituisce:\n\nUn IC molto simile a \\((20.75;\\, 26.85)\\), con possibili piccole differenze di arrotondamento.\n\n\nRibadire l’interpretazione\n\n\nIl risultato di t.test() potrebbe riportare:95 percent confidence interval: (20.72, 26.88)\n(o valori simili).\n\nAnche qui vale la regola: non è una probabilità che \\(\\mu\\) sia dentro, bensì una proprietà della procedura (lungo periodo).\n\nEsercizio 4\n\n\nIpotesi: “La media SWLS reale nella popolazione è 24”.\n\n\nVerifica se 24 è dentro l’IC al 95%. Dall’IC \\((20.75;\\, 26.85)\\), notiamo che 24 rientra in questo intervallo.\n\nSignifica che è “probabile” 24?\n\nAttenzione: l’IC frequentista non fornisce una probabilità su questo specifico valore. Dire che “24 è dentro l’intervallo” non equivale a dire “la probabilità che \\(\\mu\\) = 24 è 95%”.\n\n\n\nSe 24 fosse stato fuori dall’intervallo, non potremmo comunque affermare con certezza che \\(\\mu\\neq 24\\). Ricordiamo sempre che, con un campione così piccolo, l’incertezza è alta e l’IC si basa su assunzioni (normalità e stima corretta).\n\nLimiti dell’interpretazione\n\nCon campioni ridotti, basta poco (un outlier o una leggera deviazione dalla normalità) per alterare significativamente l’intervallo.\n\nIl livello di confidenza (ad es. 95%) è una proprietà della procedura: in una serie di infiniti studi simili, il 95% di quegli intervalli conterrebbe \\(\\mu\\). Non significa che, dato questo singolo intervallo, ci sia una “probabilità 95%” di includere il parametro.\n\nRiepilogo Finale\n\n\nValori Numerici:\n\nMedia \\(\\bar{X} = 23.8\\); dev. standard \\(s \\approx 4.26\\).\n\nIC 95% (a mano) \\(\\approx (20.75;\\, 26.85)\\).\n\nIC 80% \\(\\approx (21.93;\\, 25.67)\\); IC 99% \\(\\approx (19.41;\\, 28.19)\\).\n\n\n\n\nInterpretazione Frequentista:\n&gt; Nel lungo periodo, il 95% (o 99%, 80%, ecc.) degli intervalli calcolati con la stessa procedura conterrà il vero valore di \\(\\mu\\).\n\n\nLimiti (campioni piccoli, ipotesi di normalità, differenza tra “copertura ripetuta” e “probabilità che \\(\\mu\\) sia in un singolo IC”).\n\nIn questo modo, gli studenti vedono sia la parte di calcolo (formule, tabelle/valori critici, software) sia gli aspetti interpretativi (come evitare i fraintendimenti più comuni sul significato dell’IC frequentista).\nConclusioni generali\n\nCon un campione così piccolo (n=10), l’intervallo di confidenza può essere largo e sensibile a qualsiasi deviazione dall’assunzione di normalità.\n\nL’interpretazione frequentista si focalizza sulla “procedura” e sul “lungo periodo” (ripetizione dell’esperimento), non sulla probabilità che \\(\\mu\\) sia dentro questo intervallo specifico.\n\nÈ facile incorrere in fraintendimenti (“c’è il 95% di probabilità che la vera media sia qui dentro?”), occorre ribadire che la probabilità secondo il frequentismo riguarda il campionamento e la costruzione dell’intervallo, non la posizione fissa del parametro.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/02_conf_interv.html#informazioni-sullambiente-di-sviluppo",
    "title": "75  Intervalli di fiducia",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] bayestestR_0.15.3 posterior_1.6.1   cmdstanr_0.9.0    thematic_0.1.6   \n#&gt;  [5] MetBrewer_0.2.0   ggokabeito_0.1.0  see_0.11.0        gridExtra_2.3    \n#&gt;  [9] patchwork_1.3.0   bayesplot_1.12.0  psych_2.5.3       scales_1.4.0     \n#&gt; [13] markdown_2.0      knitr_1.50        lubridate_1.9.4   forcats_1.0.0    \n#&gt; [17] stringr_1.5.1     dplyr_1.1.4       purrr_1.0.4       readr_2.1.5      \n#&gt; [21] tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.2     tidyverse_2.0.0  \n#&gt; [25] rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6         tensorA_0.36.2.1     xfun_0.52           \n#&gt;  [4] htmlwidgets_1.6.4    insight_1.2.0        processx_3.8.6      \n#&gt;  [7] lattice_0.22-7       tzdb_0.5.0           vctrs_0.6.5         \n#&gt; [10] tools_4.5.0          ps_1.9.1             generics_0.1.4      \n#&gt; [13] parallel_4.5.0       pacman_0.5.1         pkgconfig_2.0.3     \n#&gt; [16] checkmate_2.3.2      RColorBrewer_1.1-3   distributional_0.5.0\n#&gt; [19] lifecycle_1.0.4      compiler_4.5.0       farver_2.1.2        \n#&gt; [22] mnormt_2.1.1         htmltools_0.5.8.1    pillar_1.10.2       \n#&gt; [25] abind_1.4-8          nlme_3.1-168         tidyselect_1.2.1    \n#&gt; [28] digest_0.6.37        stringi_1.8.7        labeling_0.4.3      \n#&gt; [31] rprojroot_2.0.4      fastmap_1.2.0        grid_4.5.0          \n#&gt; [34] cli_3.6.5            magrittr_2.0.3       withr_3.0.2         \n#&gt; [37] backports_1.5.0      timechange_0.3.0     rmarkdown_2.29      \n#&gt; [40] hms_1.1.3            evaluate_1.0.3       rlang_1.1.6         \n#&gt; [43] glue_1.8.0           rstudioapi_0.17.1    jsonlite_2.0.0      \n#&gt; [46] R6_2.6.1",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#bibliografia",
    "href": "chapters/frequentist_inference/02_conf_interv.html#bibliografia",
    "title": "75  Intervalli di fiducia",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nHoekstra, R., Morey, R. D., Rouder, J. N., & Wagenmakers, E.-J. (2014). Robust misinterpretation of confidence intervals. Psychonomic Bulletin & Review, 21(5), 1157–1164.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Intervalli di fiducia</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html",
    "href": "chapters/frequentist_inference/03_sample_size.html",
    "title": "76  La grandezza del campione",
    "section": "",
    "text": "76.1 Introduzione\nLa scelta della dimensione del campione è fondamentale per garantire che i risultati di uno studio siano affidabili, bilanciando precisione e costi. In questo capitolo, esamineremo come calcolare la dimensione minima del campione necessaria per stimare la media di una popolazione con un margine di errore prefissato e un determinato livello di confidenza. Utilizzeremo un esempio tratto dalla psicologia per illustrare il processo e fornire implementazioni pratiche in R.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#la-logica-dietro-la-scelta-della-dimensione-campionaria",
    "href": "chapters/frequentist_inference/03_sample_size.html#la-logica-dietro-la-scelta-della-dimensione-campionaria",
    "title": "76  La grandezza del campione",
    "section": "\n76.2 La Logica Dietro la Scelta della Dimensione Campionaria",
    "text": "76.2 La Logica Dietro la Scelta della Dimensione Campionaria\nIn psicologia, è comune stimare la media di una variabile (ad esempio, il punteggio medio di una scala psicometrica). I vantaggi di utilizzare campioni più grandi includono:\n\n\nStime più precise: Con un campione più grande, la varianza dell’estimatore diminuisce, rendendo le stime più accurate.\n\nMaggiore fiducia nei risultati: Un campione più grande riduce il margine di errore, aumentando la certezza dei risultati.\n\nTuttavia, i campioni più grandi richiedono risorse maggiori in termini di tempo e denaro. Pertanto, il problema si riduce spesso a trovare il campione più piccolo che garantisca la precisione desiderata.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#calcolo-della-dimensione-campionaria",
    "href": "chapters/frequentist_inference/03_sample_size.html#calcolo-della-dimensione-campionaria",
    "title": "76  La grandezza del campione",
    "section": "\n76.3 Calcolo della Dimensione Campionaria",
    "text": "76.3 Calcolo della Dimensione Campionaria\nPer campioni sufficientemente grandi, la media campionaria \\(\\bar{X}\\) segue una distribuzione normale:\n\\[\n\\bar{X} \\sim \\mathcal{N}\\left(\\mu, \\frac{\\sigma^2}{n}\\right),\n\\]\ndove:\n\n\n\\(n\\) è la dimensione del campione,\n\n\\(\\mu\\) è la vera media della popolazione,\n\n\\(\\sigma^2\\) è la varianza della popolazione.\n\nIl nostro obiettivo è trovare la dimensione campionaria \\(n\\) tale che:\n\\[\nP\\left(|\\bar{X} - \\mu| &lt; E\\right) \\geq 0.95,\n\\]\ndove:\n\n\n\\(\\bar{X}\\) è la media campionaria,\n\n\\(\\mu\\) è la media della popolazione,\n\n\\(E\\) è il margine di errore massimo accettabile.\n\nSappiamo che, per il teorema centrale del limite, la media campionaria \\(\\bar{X}\\) può essere standardizzata come segue:\n\\[\nZ = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}}.\n\\]\nQuesta quantità \\(Z\\) segue una distribuzione normale standard \\(\\mathcal{N}(0, 1)\\).\nQuindi, possiamo riscrivere la probabilità richiesta come:\n\\[\nP\\left(|\\bar{X} - \\mu| &lt; E\\right) = P\\left(|Z| &lt; z_{0.025}\\right),\n\\]\ndove \\(z_{0.025} = 1.96\\) è il quantile superiore della distribuzione normale standard corrispondente a un livello di confidenza del \\(95\\%\\).\nDalla definizione della variabile standardizzata \\(Z\\), possiamo ricavare la relazione per il margine di errore:\n\\[\n|\\bar{X} - \\mu| &lt; E \\implies Z = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}} \\implies \\left|\\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}}\\right| &lt; \\frac{E}{\\sigma / \\sqrt{n}}.\n\\]\nSostituendo la condizione \\(|Z| &lt; z_{0.025}\\), otteniamo:\n\\[\n\\frac{E}{\\sigma / \\sqrt{n}} = z_{0.025}.\n\\]\nRisolvendo per \\(\\sqrt{n}\\), moltiplichiamo entrambi i membri per \\(\\sigma / \\sqrt{n}\\):\n\\[\nE = z_{0.025} \\cdot \\frac{\\sigma}{\\sqrt{n}}.\n\\]\nIsoliamo \\(\\sqrt{n}\\) dividendo entrambi i membri per \\(z_{0.025} \\cdot \\sigma\\):\n\\[\n\\sqrt{n} = \\frac{z_{0.025} \\cdot \\sigma}{E}.\n\\]\nInfine, eleviamo entrambi i membri al quadrato per ottenere \\(n\\):\n\\[\nn = \\left(\\frac{z_{0.025} \\cdot \\sigma}{E}\\right)^2.\n\\]\nIn conclusione, la dimensione campionaria minima \\(n\\) necessaria per soddisfare il margine di errore \\(E\\) e il livello di confidenza richiesto è:\n\\[\nn = \\left(\\frac{z_{0.025} \\cdot \\sigma}{E}\\right)^2.\n\\]",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#stima-della-media-del-punteggio-di-autostima",
    "href": "chapters/frequentist_inference/03_sample_size.html#stima-della-media-del-punteggio-di-autostima",
    "title": "76  La grandezza del campione",
    "section": "\n76.4 Stima della Media del Punteggio di Autostima",
    "text": "76.4 Stima della Media del Punteggio di Autostima\nConsideriamo un esempio pratico: vogliamo stimare la media del punteggio di autostima in una popolazione di giovani adulti, utilizzando la Rosenberg Self-Esteem Scale (RSES), che assegna un punteggio compreso tra 0 e 30.\nDettagli del Problema:\n\nDeviazione standard del punteggio: \\(\\sigma = 6\\) (stimata da studi precedenti).\nMargine di errore massimo accettabile: \\(E = 2\\).\nLivello di confidenza: \\(95\\%\\).\n\nImplementiamo in R la formula derivata in precedenza.\n\n# Parametri del problema\nsigma &lt;- 6     # Deviazione standard del punteggio RSES\nE &lt;- 2         # Margine di errore desiderato\nz_alpha &lt;- qnorm(0.975)  # Quantile superiore della distribuzione normale (95% confidenza)\n\n# Calcolo della dimensione campionaria\nn &lt;- (z_alpha * sigma / E)^2\nn &lt;- ceiling(n)  # Arrotondamento all'intero successivo\nn\n#&gt; [1] 35\n\nIn conclusione, la dimensione campionaria minima necessaria per stimare la media del punteggio di autostima con un margine di errore massimo di 2 punti e un livello di confidenza del 95% è \\(n = 35\\).\n\n76.4.1 Approfondimenti\n\n\nPrecisione e Livello di Confidenza Aumentando \\(n\\), la varianza di \\(\\bar{X}\\) diminuisce:\n\\[\n\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n}.\n\\]\nQuesto restringe l’intervallo di confidenza e migliora la precisione.\n\nCosto e Praticità Un campione più grande comporta costi più elevati. È importante trovare il giusto compromesso tra precisione e fattibilità.\nAdattamento ad Altri Livelli di Confidenza Per altri livelli di confidenza, basta modificare il quantile \\(z_{\\alpha/2}\\). Ad esempio, per un livello di confidenza del 99%, \\(z_{0.005} \\approx\\) 2.576.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/03_sample_size.html#riflessioni-conclusive",
    "title": "76  La grandezza del campione",
    "section": "\n76.5 Riflessioni Conclusive",
    "text": "76.5 Riflessioni Conclusive\nDefinire la dimensione del campione rappresenta un passaggio cruciale nella progettazione di qualsiasi studio psicologico. Un approccio matematico rigoroso, fondato su analisi di potenza statistica e stime di effetti attesi, consente di ottimizzare il bilanciamento tra precisione dei risultati e limitazioni pratiche, come tempi, costi e disponibilità dei partecipanti. Questo equilibrio è fondamentale per garantire che i dati raccolti siano sufficientemente robusti da supportare conclusioni valide, senza tuttavia sprecare risorse in campioni eccessivamente ampi. Una corretta determinazione del campione contribuisce inoltre a ridurre il rischio di errori di tipo I e II, rafforzando l’integrità scientifica della ricerca.\nNel confronto tra paradigmi statistici, l’approccio frequentista si distingue per la sua enfasi sul controllo degli errori e sulla replicabilità attraverso il calcolo del valore p e della potenza statistica. Questo metodo richiede una rigorosa pianificazione preliminare, con la determinazione a priori della dimensione del campione basata su stime dell’effetto atteso e soglie prefissate di significatività e potenza. Tale rigidità metodologica, sebbene garantisca standardizzazione e controllo degli errori di Tipo I, può presentare notevoli limitazioni. In particolare, non permette modifiche alla dimensione del campione durante lo studio senza compromettere la validità statistica e può portare al problema dello “optional stopping”, dove il controllo ripetuto dei risultati aumenta il rischio di falsi positivi.\nL’approccio bayesiano, d’altra parte, offre una prospettiva complementare, ponendo l’accento sulla stima e sull’aggiornamento delle credenze in base ai dati osservati. Nel contesto bayesiano, la dimensione del campione non è solo uno strumento per garantire la significatività statistica, ma diventa un mezzo per affinare la precisione delle stime a posteriori. Questo approccio si caratterizza per una maggiore flessibilità, permettendo il monitoraggio continuo dell’evidenza attraverso i fattori di Bayes e l’aggiornamento sequenziale delle stime di probabilità. L’uso di distribuzioni a priori consente di incorporare conoscenze pregresse, portando a distribuzioni a posteriori che quantificano l’incertezza in modo più intuitivo e direttamente interpretabile.\nLa scelta di quando interrompere la raccolta dati rappresenta un esempio emblematico delle differenze tra i due approcci. Mentre il metodo frequentista richiede una dimensione campionaria fissa determinata a priori, l’approccio bayesiano permette una maggiore flessibilità, consentendo di interrompere la raccolta quando si raggiunge un livello desiderato di precisione nelle stime posteriori. Tuttavia, questa flessibilità comporta anche sfide specifiche, come la necessità di specificare distribuzioni a priori appropriate e una maggiore complessità computazionale.\nUna soluzione pragmatica potrebbe essere l’integrazione dei punti di forza di entrambi gli approcci. Si potrebbe utilizzare l’analisi della potenza frequentista per stabilire una dimensione minima del campione, implementando poi un monitoraggio bayesiano per valutare quando l’evidenza raccolta è sufficiente. Questo approccio integrato dovrebbe essere guidato da regole decisionali stabilite a priori e supportato da analisi di sensitività per valutare la robustezza delle conclusioni.\nIn sintesi, la scelta della dimensione del campione e la decisione su quando concludere la raccolta dati non dovrebbero essere viste solo come problemi tecnici, ma come opportunità per riflettere sulle priorità della ricerca, sul contesto teorico e sulle metodologie più adatte. La combinazione dei punti di forza degli approcci frequentista e bayesiano può portare a una ricerca più robusta, flessibile e informativa, contribuendo a un progresso scientifico più solido e sfaccettato. Tale scelta metodologica deve considerare gli obiettivi specifici dello studio, le risorse disponibili, i requisiti delle riviste scientifiche e la natura delle ipotesi da testare, bilanciando le esigenze di precisione con quelle di praticabilità. Pertanto, investire tempo nella pianificazione di questo aspetto non è solo una scelta metodologica, ma un imperativo etico per chiunque si impegni nella produzione di conoscenza psicologica.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#esercizi",
    "href": "chapters/frequentist_inference/03_sample_size.html#esercizi",
    "title": "76  La grandezza del campione",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nEsercizio 1: Dimensione del campione per un margine di errore prefissato\n\nEsaminando i dati raccolti, hai ottenuto una deviazione standard campionaria (stimata) \\(s \\approx 4{,}3\\) sui punteggi SWLS.\nHai stabilito di voler stimare la media SWLS con un margine di errore massimo \\(E = 2\\) punti e un livello di confidenza del 95%.\n\nUtilizzando il valore critico \\(z_{0.025} \\approx 1{,}96\\) (per il 95%), ipotizza che la deviazione standard di popolazione \\(\\sigma\\) possa essere approssimata da \\(s\\). Calcola quindi la dimensione del campione \\(n\\) necessaria:\n\\[\nn = \\left(\\frac{z_{\\alpha/2} \\times \\sigma}{E}\\right)^2.\n\\]\n\nInterpreta il risultato: è un campione grande o piccolo? Quali fattori potrebbero influenzarne la validità (ad es. la stima di \\(\\sigma\\) da soli 10 soggetti)?\n\nEsercizio 2: Aumento del livello di confidenza e influenza su \\(n\\)\n\nCon gli stessi dati dell’Esercizio 1 (stesso \\(\\sigma\\approx4{,}3\\), stesso \\(E=2\\)), calcola la dimensione \\(n\\) se volessi un livello di confidenza del 99%.\n\nConfronta tale dimensione con quella trovata al 95%.\n\nCommenta: perché un livello di confidenza più elevato richiede un campione più grande? E in che modo ciò può impattare sull’organizzazione pratica della ricerca (tempi, costi, disponibilità di partecipanti)?\n\nEsercizio 3: Potere statistico per rilevare una differenza dalla media di riferimento\n\nIpotizza che la media SWLS di riferimento (ad es. in letteratura) sia 24.\n\nVuoi un test a una coda (one-sample t-test o z-test) con \\(\\alpha = 0{,}05\\), e desideri un potere (\\(1-\\beta\\)) dell’80% di rivelare una differenza di 3 punti (cioè vuoi essere in grado di concludere che la vera media è almeno 3 punti più alta o più bassa di 24).\n\nUsa come stima della deviazione standard la stessa \\(s \\approx 4{,}3\\). Sulla base delle formule di potenza statistica per un test a una coda, calcola un numero approssimativo di soggetti \\(n\\) necessari. (Suggerimento: puoi usare formule di power analysis o fare riferimento a software R, es. power.t.test() o pwr.t.test().)\n\n\nInterpreta la dimensione campionaria trovata: è realistica per un esperimento in cui potresti raccogliere partecipanti simili a quelli del pilot? Oppure rappresenta un valore troppo elevato?\n\nEsercizio 4: Confronto tra due gruppi e potere statistico\n\nIpotizza di voler confrontare due gruppi indipendenti (ognuno con punteggi SWLS) e di voler rilevare una differenza media di 5 punti tra i due gruppi (Gruppo A vs Gruppo B).\n\nAssumi che ciascun gruppo abbia la stessa deviazione standard \\(\\sigma = 4{,}3\\).\n\nVuoi un test a due code, \\(\\alpha=0{,}05\\), e un potere dell’80%. Utilizza (se vuoi) la formula approssimata per due campioni indipendenti, oppure uno strumento in R (ad es. power.t.test con type=\"two.sample\").\n\nCalcola (o stima) la dimensione \\(n\\) per ciascun gruppo.\n\n\nCommenta: confronta il risultato con la disponibilità realistica dei partecipanti. Che implicazioni metodologiche o pratiche emergono?\n\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\nSoluzione Esercizio 1\nDati principali:\n- \\(\\sigma \\approx 4{,}3\\) (stimata dal pilot)\n- \\(E = 2\\) (margine di errore)\n- Livello di confidenza 95% \\(\\Rightarrow z_{\\alpha/2} \\approx 1{,}96\\)\nLa formula per la dimensione campionaria:\n\\[\nn = \\left(\\frac{z_{\\alpha/2} \\times \\sigma}{E}\\right)^2\n\\]\nCalcolo:\n\\[\nn\n= \\left(\\frac{1{,}96 \\times 4{,}3}{2}\\right)^2\n= \\left(\\frac{8{,}428}{2}\\right)^2\n= (4{,}214)^2\n\\approx 17{,}76.\n\\]\nArrotondando all’intero superiore:\n\\[\nn \\approx 18.\n\\]\nInterpretazione\n\nServirebbero circa 18 partecipanti (anziché 10) per ottenere un IC al 95% con margine d’errore 2, ipotizzando \\(\\sigma \\approx 4{,}3\\).\n\n\nLimiti: la \\(\\sigma\\) deriva da un campione di sole 10 persone e potrebbe non rappresentare bene la deviazione standard reale dell’intera popolazione. Se in realtà \\(\\sigma\\) fosse più grande, \\(n\\) andrebbe rivisto al rialzo; se fosse minore, 18 potrebbe essere anche sovrastimato.\n\n18 non è troppo elevato; potrebbe essere gestibile in uno studio con costi contenuti. Tuttavia, la validità dipende dalla solidità della stima di \\(\\sigma\\).\n\nSoluzione Esercizio 2\nCambio di livello di confidenza: da 95% a 99%. Ora \\(\\alpha=0{,}01\\) e \\(\\alpha/2=0{,}005\\).\nIl valore critico \\(z_{0.005}\\) è circa 2,576.\n\\[\nn = \\left(\\frac{2,576 \\times 4{,}3}{2}\\right)^2\n= \\left(\\frac{11{,}0768}{2}\\right)^2\n= (5{,}5384)^2\n\\approx 30{,}7.\n\\]\nArrotondato in eccesso:\n\\[\nn \\approx 31.\n\\]\nConfronto con i 18 trovati prima\n- Aumentando la confidenza dal 95% al 99%, la dimensione campionaria passa da ~18 a ~31, cioè un incremento notevole.\n- Motivo: per assicurare un intervallo che, nel lungo periodo, includa il vero valore nel 99% dei casi, occorre un margine di errore più “tollerante” (oppure un campione più grande per mantenere lo stesso \\(E\\)).\n- Impatto pratico: reclutare 31 soggetti (invece di 18) può pesare in termini di costi e disponibilità, ma riduce l’incertezza dell’IC dal punto di vista frequentista.\nSoluzione Esercizio 3\nPotere statistico (80%) per rilevare \\(\\Delta = 3\\) in un test a una coda contro il valore di riferimento 24.\n- \\(\\alpha=0{,}05\\) (quindi una coda, il valore critico si situa intorno a z=1.645 per la potenza, ma i calcoli precisi si fanno di solito con formule di power analysis).\n- \\(\\sigma \\approx 4{,}3\\).\n- \\(\\Delta = 3\\).\nIn R, con pwr.t.test() o power.t.test(), l’approssimazione verrebbe impostata come:\nlibrary(pwr)  # se usi pwr\npwr.t.test(d = 3/4.3, sig.level = 0.05, power = 0.80,\n           type = \"one.sample\", alternative=\"greater\")\noppure:\npower.t.test(delta = 3, sd = 4.3, sig.level = 0.05, \n             power = 0.80, type = \"one.sample\", \n             alternative = \"one.sided\")\nEsempio di risultato (numeri indicativi): potresti ottenere \\(n \\approx 20\\). (Il valore preciso cambia a seconda delle approssimazioni e del software.)\nInterpretazione\n- Con 20 soggetti, se \\(\\Delta\\) fosse veramente di 3 punti rispetto a 24, il test a una coda dovrebbe avere l’80% di chance di rigettare l’ipotesi nulla (cioè di rilevare la differenza) a \\(\\alpha=0{,}05\\).\n- Se cercassi di replicare il pilot (dove avevi 10 soggetti), probabilmente la potenza sarebbe inferiore.\n- Potresti chiederti se 20 partecipanti siano facili da reclutare o se, dal punto di vista pratico, 20 restino pochi per altre ragioni (ad es. robustezza dei modelli, normalità, outlier).\nSoluzione Esercizio 4\n\nDue campioni indipendenti, differenza attesa = 5 punti, potere = 80%, test a due code\n\nCon formula approssimata (oppure software R), i parametri tipici:\n\n\nDifferenza minima rilevabile: \\(\\Delta = 5\\)\n\n\n\\(\\sigma = 4{,}3\\) in ciascun gruppo\n\n\n\\(\\alpha = 0{,}05\\) (due code), potere = 80%\n\nTipo di test: “two-sample t test” (Gruppo A vs Gruppo B, varianze uguali)\n\nIn R con power.t.test():\npower.t.test(delta = 5, sd = 4.3, sig.level = 0.05,\n             power = 0.80, type = \"two.sample\",\n             alternative = \"two.sided\")\nEsempio di risultato: potresti ottenere \\(n \\approx 14\\) per gruppo (quindi 28 totali). (Il numero può variare leggermente a seconda delle approssimazioni.)\n\nCommento\n\n\n\n18 o 20 partecipanti totali potrebbero bastare per un one-sample test (Esercizi 1–3), ma qui servono 28 (14 per gruppo) per avere lo stesso potere su una differenza di 5 punti.\n\nIn pratica:\n\nSe hai risorse per arruolare solo 15–20 persone totali, potrebbe non esserci potere sufficiente (grande rischio di errore di tipo II).\n\nPotrebbe convenire ridurre la differenza minima desiderata (ma questo cambierebbe le conclusioni) o cercare un campione più grande.\n\n\n\nLe considerazioni metodologiche includono: “Posso davvero aspettarmi 5 punti di differenza?” Se la differenza reale fosse più piccola, servirebbe un campione ancora più grande per rilevarla con sufficiente potenza.\n\nConclusioni Finali\n\nLa dimensione del campione dipende da molti fattori:\n\nVarianza (o deviazione standard) stimata.\n\nMargine di errore desiderato (o differenza minima rilevabile).\n\nLivello di confidenza o \\(\\alpha\\).\n\nPotere statistico \\((1-\\beta)\\).\n\n\n\nI dati SWLS di un pilot di 10 persone forniscono un’indicazione iniziale (stima di \\(\\sigma\\)), ma la precisione di quella stima è limitata.\n\nPer studi sperimentali o correlazionali, i calcoli di dimensione campionaria andrebbero fatti a priori (idealmente ancor prima di raccogliere i dati) e basati su stime realistiche o su letteratura pre-esistente.\n\nSe la stima di \\(\\sigma\\) o della dimensione dell’effetto \\(\\Delta\\) è incerta, è utile svolgere analisi di sensitività, variando gli input per vedere come cambiano i risultati.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/03_sample_size.html#informazioni-sullambiente-di-sviluppo",
    "title": "76  La grandezza del campione",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.12.0 psych_2.5.3     \n#&gt;  [9] scales_1.4.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.2   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.4     stringi_1.8.7      lattice_0.22-7    \n#&gt;  [4] hms_1.1.3          digest_0.6.37      magrittr_2.0.3    \n#&gt;  [7] evaluate_1.0.3     grid_4.5.0         timechange_0.3.0  \n#&gt; [10] RColorBrewer_1.1-3 fastmap_1.2.0      rprojroot_2.0.4   \n#&gt; [13] jsonlite_2.0.0     mnormt_2.1.1       cli_3.6.5         \n#&gt; [16] rlang_1.1.6        withr_3.0.2        tools_4.5.0       \n#&gt; [19] parallel_4.5.0     tzdb_0.5.0         pacman_0.5.1      \n#&gt; [22] vctrs_0.6.5        R6_2.6.1           lifecycle_1.0.4   \n#&gt; [25] htmlwidgets_1.6.4  pkgconfig_2.0.3    pillar_1.10.2     \n#&gt; [28] gtable_0.3.6       glue_1.8.0         xfun_0.52         \n#&gt; [31] tidyselect_1.2.1   rstudioapi_0.17.1  farver_2.1.2      \n#&gt; [34] htmltools_0.5.8.1  nlme_3.1-168       rmarkdown_2.29    \n#&gt; [37] compiler_4.5.0",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#bibliografia",
    "href": "chapters/frequentist_inference/03_sample_size.html#bibliografia",
    "title": "76  La grandezza del campione",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGiner-Sorolla, R., Montoya, A. K., Reifman, A., Carpenter, T., Lewis Jr, N. A., Aberson, C. L., Bostyn, D. H., Conrique, B. G., Ng, B. W., Schoemann, A. M., et al. (2024). Power to detect what? Considerations for planning and evaluating sample size. Personality and Social Psychology Review, 28(3), 276–301.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html",
    "title": "\n77  Significatività statistica\n",
    "section": "",
    "text": "77.1 Introduzione\nIl test di ipotesi è un metodo fondamentale della ricerca scientifica, utilizzato per fare inferenze sui parametri della popolazione a partire dai dati campionari. Nel contesto della psicologia, questo approccio viene frequentemente impiegato per valutare l’efficacia di interventi psicologici, confrontare teorie o approcci, analizzare l’influenza di variabili psicologiche su comportamenti e processi cognitivi, e approfondire i meccanismi alla base di fenomeni complessi come apprendimento, memoria ed emozioni.\nIn questo capitolo ci focalizzeremo sul test di ipotesi frequentista, un metodo largamente utilizzato ma non privo di limiti. È importante sottolineare che la comunità statistica sconsiglia di affidarsi esclusivamente a questo approccio come criterio decisionale per valutare la validità di un risultato sperimentale.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#test-del-chi-quadrato",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#test-del-chi-quadrato",
    "title": "\n77  Significatività statistica\n",
    "section": "\n77.2 Test del Chi-Quadrato",
    "text": "77.2 Test del Chi-Quadrato\nPer introdurre il concetto di test di ipotesi nel contesto frequentista, iniziamo presentando uno dei test più semplici e utilizzati: il test del Chi-Quadrato. Questo test è particolarmente utile per valutare l’ipotesi di indipendenza tra due variabili categoriali organizzate in una tabella di contingenza (per ulteriori dettagli sulla struttura delle tabelle di contingenza, si veda il Capitolo 16).\nUna tabella di contingenza è una rappresentazione tabellare che mostra la distribuzione congiunta di due variabili categoriali. Ogni cella della tabella contiene la frequenza osservata delle combinazioni delle categorie delle due variabili. Inoltre, la tabella include i totali marginali, che rappresentano le somme delle frequenze per ciascuna riga e ciascuna colonna.\nIl test del Chi-Quadrato si pone una domanda fondamentale: “Come apparirebbe la tabella di contingenza se le due variabili fossero indipendenti?”. In altre parole, il test verifica se esiste una relazione significativa tra le due variabili o se, al contrario, le variabili sono indipendenti l’una dall’altra.\nCome già visto in precedenza analizzando la distribuzione di probabilità congiunta, si ha indipendenza quando le probabilità congiunte sono uguali al prodotto delle probabilità marginali. Partendo dalle proporzioni marginali, possiamo quindi calcolare i valori teorici attesi in ciascuna cella della tabella di contingenza, assumendo che le due variabili siano indipendenti.\nVa sottolineato che l’indipendenza è una proprietà della popolazione, non del campione. Pertanto, nei dati campionari, ci aspettiamo che i valori osservati nelle celle della tabella differiscano leggermente dai valori teorici attesi, anche se nella popolazione le variabili sono realmente indipendenti. La discrepanza complessiva tra i valori osservati e quelli attesi, calcolati sotto l’ipotesi di indipendenza, può essere misurata utilizzando una statistica chiamata Chi-Quadrato (\\(\\chi^2\\)).\nLa formula della statistica Chi-Quadrato è:\n\\[\n\\chi^2 = \\sum \\frac{(O_i - E_i)^2}{E_i} ,\n\\]\ndove:\n\n\n\\(O_i\\) rappresenta i valori osservati nelle celle della tabella,\n\n\n\\(E_i\\) rappresenta i valori attesi nelle celle, calcolati sotto l’ipotesi di indipendenza,\n\nLa somma (\\(\\sum\\)) viene effettuata su tutte le celle della tabella.\n\n\n77.2.1 Interpretazione della Statistica Chi-Quadrato\nLa statistica Chi-Quadrato misura la discrepanza complessiva tra i valori osservati e quelli attesi. Se non ci fosse differenza tra i valori congiunti osservati e quelli teorici, la statistica Chi-Quadrato sarebbe pari a zero. All’aumentare della discrepanza tra valori osservati e attesi, il valore della statistica Chi-Quadrato aumenta.\nPer valutare l’importanza della discrepanza osservata, utilizziamo la distribuzione campionaria della statistica Chi-Quadrato. Questa distribuzione descrive la probabilità di ottenere valori della statistica Chi-Quadrato sotto l’ipotesi nulla (indipendenza tra le variabili). La forma della distribuzione dipende dai gradi di libertà (\\(\\nu\\)), che si calcolano come:\n\\[\n\\nu = (n_{\\text{righe}} - 1)(n_{\\text{colonne}} - 1) ,\n\\]\ndove \\(n_{\\text{righe}}\\) e \\(n_{\\text{colonne}}\\) rappresentano rispettivamente il numero di righe e colonne della tabella di contingenza.\n\n77.2.2 Valutazione dell’Ipotesi di Indipendenza\nLa probabilità associata a una data discrepanza (\\(\\chi^2\\)) tra valori osservati e attesi, assumendo che l’ipotesi nulla sia vera, corrisponde all’area sotto la coda destra della distribuzione Chi-Quadrato, nell’intervallo [\\(C\\), \\(+\\infty\\)]. Questa probabilità è indicata come \\(p\\)-value.\nSe il \\(p\\)-value è molto piccolo (tipicamente inferiore a una soglia predefinita, come 0.05), possiamo rifiutare l’ipotesi nulla e concludere che è improbabile che le due variabili siano indipendenti nella popolazione.\n\n77.2.3 Riepilogo dei Passaggi del Test Chi-Quadrato\n\n\nCalcolo dei Valori Attesi: Per ogni cella, calcola \\(E_i\\) utilizzando la formula:\n\\[\nE_i = \\frac{\\text{Totale della Riga} \\times \\text{Totale della Colonna}}{\\text{Totale Complessivo}}\n\\]\n\n\nCalcolo della Statistica Chi-Quadrato: Usa la formula:\n\\[\n\\chi^2 = \\sum \\frac{(O_i - E_i)^2}{E_i}\n\\]\n\nDeterminazione dei Gradi di Libertà: Calcola \\(\\nu\\) come \\((n_{\\text{righe}} - 1)(n_{\\text{colonne}} - 1)\\).\nConfronto con la Distribuzione Chi-Quadrato: Determina il \\(p\\)-value associato al valore di \\(\\chi^2\\) calcolato e valuta l’ipotesi nulla.\n\nIn conclusione, il Test Chi-Quadrato rappresenta uno strumento per verificare l’indipendenza tra due variabili categoriali. Grazie alla sua semplicità di applicazione e interpretazione, costituisce un metodo di analisi largamente utilizzato in ambito psicologico, sociale e statistico. Tuttavia, è importante prestare attenzione ai presupposti del test, come la sufficienza dei dati in ogni cella, per garantire risultati affidabili e interpretabili.\n\n# Creare la tabella di contingenza\nobserved &lt;- matrix(c(44, 0, 119, \n                              55, 68, 0, \n                              47, 0, 0),\n                            nrow = 3, byrow = TRUE)\n\n# Aggiungere i nomi di righe e colonne\nrownames(observed) &lt;- c(\"Biscoe\", \"Dream\", \"Torgersen\")\ncolnames(observed) &lt;- c(\"Adelie\", \"Chinstrap\", \"Gentoo\")\n\n# Visualizzare la tabella\nprint(observed)\n#&gt;           Adelie Chinstrap Gentoo\n#&gt; Biscoe        44         0    119\n#&gt; Dream         55        68      0\n#&gt; Torgersen     47         0      0\n\n\nchi_square_result &lt;- chisq.test(observed)\nchi_square_result\n#&gt; \n#&gt;  Pearson's Chi-squared test\n#&gt; \n#&gt; data:  observed\n#&gt; X-squared = 285, df = 4, p-value &lt;2e-16\n\nSvolgiamo i calcoli “a mano” usando R. Per calcolare la statistica del test del Chi-Quadrato “a mano” in R, segui questi passaggi:\nCalcoliamo i totali per righe e colonne e il totale complessivo.\n\n# Totali marginali\nrow_totals &lt;- rowSums(observed)\ncol_totals &lt;- colSums(observed)\ngrand_total &lt;- sum(observed)\n\n# Visualizzare i totali\nprint(\"Totali marginali per righe:\")\n#&gt; [1] \"Totali marginali per righe:\"\nprint(row_totals)\n#&gt;    Biscoe     Dream Torgersen \n#&gt;       163       123        47\nprint(\"Totali marginali per colonne:\")\n#&gt; [1] \"Totali marginali per colonne:\"\nprint(col_totals)\n#&gt;    Adelie Chinstrap    Gentoo \n#&gt;       146        68       119\nprint(paste(\"Totale complessivo:\", grand_total))\n#&gt; [1] \"Totale complessivo: 333\"\n\nI valori attesi si calcolano come:\n\\[\nE_{ij} = \\frac{\\text{Totale riga} \\times \\text{Totale colonna}}{\\text{Totale complessivo}} .\n\\]\n\n# Calcolo dei valori attesi\nexpected &lt;- outer(row_totals, col_totals) / grand_total\n\n# Visualizzare i valori attesi\nprint(\"Valori attesi:\")\n#&gt; [1] \"Valori attesi:\"\nprint(expected)\n#&gt;           Adelie Chinstrap Gentoo\n#&gt; Biscoe     71.47    33.285  58.25\n#&gt; Dream      53.93    25.117  43.95\n#&gt; Torgersen  20.61     9.598  16.80\n\nLa statistica Chi-Quadrato si calcola con:\n\\[\n\\chi^2 = \\sum \\frac{(O_{ij} - E_{ij})^2}{E_{ij}} .\n\\]\n\n# Calcolo della statistica Chi-Quadrato\nchi_square_stat &lt;- sum((observed - expected)^2 / expected)\n\n# Visualizzare il risultato\nprint(paste(\"Statistica Chi-Quadrato:\", chi_square_stat))\n#&gt; [1] \"Statistica Chi-Quadrato: 284.590012688092\"\n\nI gradi di libertà si calcolano come:\n\\[\ndof = (\\text{n. righe} - 1) \\times (\\text{n. colonne} - 1) .\n\\]\n\n# Calcolo dei gradi di libertà\ndof &lt;- (nrow(observed) - 1) * (ncol(observed) - 1)\n\n# Visualizzare i gradi di libertà\nprint(paste(\"Gradi di libertà:\", dof))\n#&gt; [1] \"Gradi di libertà: 4\"\n\nConfrontiamo la statistica Chi-Quadrato con la distribuzione teorica per ottenere il p-value.\n\n# Calcolo del p-value\np_value &lt;- pchisq(chi_square_stat, df = dof, lower.tail = FALSE)\n\n# Visualizzare il p-value\nprint(paste(\"p-value:\", p_value))\n#&gt; [1] \"p-value: 2.28189154098739e-60\"\n\nInterpretazione:\nIl valore-\\(p\\) risulta molto piccolo, indicando che, se le variabili Isola e Specie fossero realmente indipendenti, sarebbe estremamente improbabile osservare una distribuzione delle specie di pinguini sulle tre isole così diversa da quella teoricamente attesa. In altre parole, il valore-\\(p\\) rappresenta la probabilità di ottenere, per puro caso, una discrepanza tra i valori osservati e quelli attesi pari o superiore a quella riscontrata nei dati.\nPoiché il valore-\\(p\\) è estremamente basso, possiamo concludere che l’ipotesi di indipendenza tra le variabili Isola e Specie non è plausibile. Questo indica che la distribuzione delle specie di pinguini varia in relazione all’isola, ovvero che conoscendo l’isola è possibile prevedere la distribuzione delle specie. In altre parole, le variabili Isola e Specie sono associate.\n\n77.2.4 Significatività Statistica: Un Concetto da Riconsiderare\nCome discusso nell’esempio precedente, un risultato è considerato “statisticamente significativo” se la probabilità che sia dovuto al caso è bassa, il che suggerisce che il risultato sia stabile o reale. Al contrario, risultati “non significativi” vengono spesso etichettati come privi di valore e ignorati. Questa semplificazione, però, può portare a gravi fraintendimenti. Ad esempio:\n\n\nDipendenza dal campione: La significatività statistica è fortemente influenzata dalla dimensione del campione; risultati apparentemente “significativi” possono emergere anche da effetti molto piccoli in campioni ampi.\n\nRisultati non significativi: Un risultato non significativo non implica che l’effetto sia nullo o irrilevante.\n\nScelte soggettive: Livelli di confidenza e test statistici differenti possono influenzare l’esito dell’analisi, portando a interpretazioni arbitrarie.\n\n77.2.5 Limiti e Applicazioni del Metodo Frequentista\nIl problema più grave dell’approccio frequentista è che esso non sempre mantiene la “promessa” di fornire una base oggettiva per la decisione statistica. Infatti, il ricorso esclusivo alla significatività statistica conduce a risultati opposti a quelli desiderati, aumentando il rischio di pubblicare risultati non replicabili o di trascurare evidenze importanti si veda il 82.\nIn alternativa, è più utile considerare il risultato osservato nel contesto scientifico più ampio, integrandolo con altre analisi. Questo approccio critico e completo consente di superare i limiti della significatività statistica e di interpretare i risultati con maggiore rigore.\n\n77.2.6 Un Caso Specifico: La Media del Campione\nTorniamo ora a esaminare il test di ipotesi all’interno del quadro frequentista, focalizzandoci sul caso di una variabile continua, diversamente dal contesto qualitativo trattato nel test del Chi-Quadrato. Per approfondire la comprensione della significatività statistica, analizzeremo in dettaglio l’utilizzo della media campionaria come stimatore della media della popolazione. Questa riflessione ci consentirà di esplorare sia i limiti che le applicazioni pratiche di tale strumento all’interno della statistica inferenziale frequentista. Attraverso questo esempio, potremo mettere in luce aspetti teorici e operativi dei test di ipotesi, nonché fornire indicazioni su come migliorare l’interpretazione dei risultati, con particolare riferimento al campo della ricerca psicologica.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#il-test-di-ipotesi",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#il-test-di-ipotesi",
    "title": "\n77  Significatività statistica\n",
    "section": "\n77.3 Il Test di Ipotesi",
    "text": "77.3 Il Test di Ipotesi\nIl test di ipotesi è un metodo statistico utilizzato per valutare se i dati sono coerenti con l’ipotesi nulla (\\(H_0\\)). L’ipotesi nulla solitamente afferma che non vi è alcun effetto o differenza significativa, mentre l’ipotesi alternativa (\\(H_1\\)) rappresenta l’affermazione che si desidera testare. I dati del campione vengono analizzati per determinare se forniscono prove sufficienti per rifiutare l’ipotesi nulla. Un passaggio cruciale consiste nel calcolare il value-p.\n\n77.3.1 La procedura di Test di Ipotesi\nEsaminiamo in dettaglio le varie fasi della procedura del test di ipotesi di stampo frequentista.\nPasso 1: Formulare l’ipotesi nulla (\\(H_0\\)) e l’ipotesi alternativa (\\(H_1\\)) basandosi sulla domanda di ricerca.\nPasso 2: Stabilire un livello di significatività, α (solitamente 0.05).\nPasso 3: Selezionare il Test Statistico appropriato, verificare eventuali assunzioni e calcolare il test statistico.\nPasso 4: Decidere se il risultato è “statisticamente significativo” secondo (a) la regione di rifiuto o (b) il valore-p.\n\nL’approccio della regione di rifiuto. Basandosi sulla distribuzione campionaria nota del test statistico, la regione di rifiuto è un insieme di valori per il test statistico per i quali l’ipotesi nulla viene rifiutata. Se il valore osservato del test statistico rientra nella regione di rifiuto, allora si rifiuta l’ipotesi nulla.\nL’approccio del valore-p. Il valore-p è la probabilità di ottenere i risultati osservati, o risultati ancora più estremi, se l’ipotesi nulla è vera.\n\nConfrontiamo il valore-p calcolato con il livello di significatività α:\n\nSe il valore-p &lt; α, si rifiuta l’ipotesi nulla (\\(H_0\\)).\nSe il valore-p ≥ α, non si rifiuta l’ipotesi nulla (\\(H_0\\)).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#il-test-di-ipotesi-nel-contesto-frequentista",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#il-test-di-ipotesi-nel-contesto-frequentista",
    "title": "\n77  Significatività statistica\n",
    "section": "\n77.4 Il Test di Ipotesi nel Contesto Frequentista",
    "text": "77.4 Il Test di Ipotesi nel Contesto Frequentista\nSi noti che i metodi bayesiani e frequentisti non sono semplicemente due approcci diversi per rispondere alla stessa domanda, ma formulano domande fondamentalmente diverse. Pertanto, per comprendere il test di ipotesi frequentista, è essenziale chiarire cosa si intende per valore-p.\nL’American Statistical Association (ASA) definisce il valore-p come:\n\nthe probability under a specified statistical model that a statistical summary of the data (e.g., the sample mean difference between two compared groups) would be equal to or more extreme than its observed value (Wasserstein e Lazar 2016).\n\nQuesta definizione può risultare difficile da comprendere perché contiene concetti complessi come “probabilità” e “modello statistico specificato”. Per capire meglio cosa rappresenta un valore-p, è necessario esaminare attentamente entrambi questi concetti. Questo ci porterà anche a una comprensione più profonda di altri concetti fondamentali per l’inferenza frequentista e ci aiuterà a distinguere tra inferenza frequentista e inferenza bayesiana.\nUna distinzione fondamentale tra l’approccio frequentista e quello bayesiano riguarda l’interpretazione della probabilità: il primo si basa sulla frequenza relativa degli eventi nel lungo periodo, mentre il secondo si basa sulla “certezza soggettiva” o sul grado di fiducia che un individuo attribuisce a un evento specifico.\nChiarito che la probabilità assume significati diversi nei contesti frequentista e bayesiano, possiamo chiederci quale nozione di probabilità sia implicita nella definizione del valore-p fornita dall’ASA. La visione comune suggerisce che si riferisca alle frequenze relative. Ma frequenze relative di cosa e ripetizioni di cosa?\nPossiamo riformulare la definizione dell’ASA in questo modo:\n\nIl valore-p si riferisce alla frequenza relativa di ottenere un riassunto statistico dei dati grande quanto o più grande del valore osservato in ripetizioni ipotetiche di un esperimento descritto da un modello statistico specificato.\n\nQuindi, l’approccio frequentista può essere descritto come un metodo per stimare il valore di un parametro attraverso esperimenti ipotetici, confrontando i nostri dati con i risultati di tali esperimenti per giudicare se i nostri dati sono sorprendenti o meno.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#applicazione-alla-media-campionaria",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#applicazione-alla-media-campionaria",
    "title": "\n77  Significatività statistica\n",
    "section": "\n77.5 Applicazione alla Media Campionaria",
    "text": "77.5 Applicazione alla Media Campionaria\nIn questo capitolo ci concentreremo sull’applicazione del processo di test di ipotesi frequentista alla media campionaria. Vedremo come la media di un campione possa essere impiegata per trarre inferenze sulla media di una popolazione, analizzandone limiti e possibili utilizzi nell’ambito dell’inferenza statistica frequentista.\nI test su uno o due campioni (one-sample e two-sample tests) hanno rappresentato le prime fondamenta dell’analisi statistica dei dati. Al giorno d’oggi, tuttavia, i nostri disegni sperimentali tendono a essere più complessi di quanto questi semplici test possano gestire. Nonostante ciò, tali test – in particolare il celebre t-test di Student – costituiscono ancora un’ottima porta d’ingresso alla modellazione statistica, poiché i principi su cui si basano sono relativamente intuitivi e consentono di familiarizzare con il processo di verifica dell’ipotesi.\nPer comprendere meglio i valori-p e la verifica del test di ipotesi, può essere molto utile ricorrere a simulazioni. Attraverso queste ultime è possibile ricreare condizioni sperimentali ipotetiche e osservare la variabilità dei risultati, fornendo così una prospettiva più chiara sulle implicazioni della statistica frequentista.\n\n77.5.1 La Distribuzione della Media Campionaria\nQuando consideriamo la media campionaria come stima della media di una popolazione, assumiamo che questa popolazione segua una distribuzione normale. Vogliamo quindi esplorare la distribuzione della media campionaria (\\(\\bar{X}\\)), che descrive la variazione di \\(\\bar{X}\\) attraverso infiniti campioni di dimensione \\(n\\). Abbiamo già dimostrato che, se la popolazione è normalmente distribuita, anche la distribuzione campionaria di \\(\\bar{X}\\) seguirà una distribuzione normale, con media \\(\\mu\\) (la media della popolazione) e deviazione standard \\(\\frac{\\sigma}{\\sqrt{n}}\\) (dove \\(\\sigma\\) è la deviazione standard della popolazione e \\(n\\) è la dimensione del campione).\n\n77.5.2 Test di Ipotesi sulla Media Campionaria\nSupponendo di conoscere \\(\\sigma\\) ma non \\(\\mu\\), utilizziamo i test di ipotesi per indagare quanto la media campionaria osservata si discosti da un valore ipotetico \\(\\mu_0\\), specificato dall’ipotesi nulla. Questo processo ci permette di valutare la plausibilità di \\(\\mu_0\\) come vera media della popolazione.\n\n77.5.3 Calcolo della Statistica del Test\nPer valutare quanto la media campionaria osservata si discosti dall’ipotesi nulla che propone \\(\\mu = \\mu_0\\), standardizziamo \\(\\bar{X}\\) usando la formula:\n\\[\nZ = \\frac{\\bar{X} - \\mu_0}{\\sigma/\\sqrt{n}}\n\\]\nQuesta trasformazione produce una variabile \\(Z\\) che segue una distribuzione normale standard \\(\\mathcal{N}(0, 1)\\). Valori estremi di \\(Z\\) (sia molto grandi che molto piccoli) suggeriscono che la media campionaria osservata è incompatibile con \\(\\mu_0\\), portando al rigetto dell’ipotesi nulla.\n\n77.5.3.1 Simulazione\nPer illustrare quanto espresso sopra attraverso una simulazione, consideriamo un esempio numerico. Supponiamo che \\(\\mu_0 = 100\\), \\(\\sigma = 15\\) e \\(n = 30\\). Vogliamo calcolare il valore-p per l’evento \\(\\bar{X} &gt; 105\\).\nLa simulazione può essere eseguita come segue:\n\n# To make the simulation reproducible\nset.seed(123)\n\nmu_0 &lt;- 100\nsigma &lt;- 15\nn &lt;- 30\nn_sim &lt;- 10000  # Number of simulations\n\n# Generate n_sim sample means from a N(mu_0, sigma/sqrt(n))\nsample_means &lt;- rnorm(n_sim, mean = mu_0, sd = sigma / sqrt(n))\n\n# Calculate the p-value as the proportion of sample means &gt; 105\np_value &lt;- mean(sample_means &gt; 105)\n\n# Print the p-value\nprint(p_value)\n#&gt; [1] 0.0339\n\nQuesto script simula la distribuzione campionaria di \\(\\bar{X}\\) sotto l’ipotesi nulla che \\(\\mu = \\mu_0\\) e calcola il valore-p per l’evento \\(\\bar{X} &gt; 105\\). Il valore-p indica la probabilità di osservare un valore di \\(\\bar{X}\\) così estremo (o più estremo) se l’ipotesi nulla fosse vera.\nIl risultato della simulazione può essere confrontato con il calcolo teorico del valore-p usando la distribuzione normale standard. Il valore \\(Z\\) per \\(\\bar{X} = 120\\) è calcolato come:\n\\[\nZ = \\frac{105 - 100}{15/\\sqrt{30}}\n\\]\nPossiamo usare la funzione stats.norm.sf() per trovare l’area sotto la curva normale standard a destra di questo valore \\(Z\\), che corrisponde al valore-p teorico.\n\n# Calculate the Z-score\nZ &lt;- (105 - 100) / (15 / sqrt(30))\nprint(Z)\n#&gt; [1] 1.826\n\n\n# Calculate the upper tail probability\nupper_tail_prob &lt;- pnorm(Z, lower.tail = FALSE)\n\nprint(upper_tail_prob)\n#&gt; [1] 0.03394\n\nOppure, in maniera equivalente\n\n# Calculate the upper tail probability\nupper_tail_prob &lt;- 1 - pnorm(105, mean = 100, sd = 15 / sqrt(30))\nprint(upper_tail_prob)\n#&gt; [1] 0.03394\n\nIl calcolo teorico mostra che il valore \\(Z\\) per una media campionaria di 105 è 1.82. Questo valore indica una deviazione sostanziale dalla media ipotizzata sotto l’ipotesi nulla (\\(\\mu_0 = 100\\)). Tale deviazione può essere quantificata dalla “sorpresa” indicata dal valore-p, dove valori-p piccoli rappresentano una maggiore sorpresa. Il valore-p ottenuto, pari a 0.0339, indica un elevato grado di sorpresa: come mostrato dalla simulazione, un valore di 105 o superiore si verifica solo nel 3.4% dei casi se l’esperimento viene ripetuto numerose volte sotto l’ipotesi nulla. Questo suggerisce che un risultato del genere è altamente improbabile se l’ipotesi nulla fosse vera.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#applicazioni-pratiche",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#applicazioni-pratiche",
    "title": "\n77  Significatività statistica\n",
    "section": "\n77.6 Applicazioni pratiche",
    "text": "77.6 Applicazioni pratiche\nNella precedente discussione, abbiamo supposto \\(\\sigma\\) nota. Tuttavia, poiché di solito non conosciamo il valore di \\(\\sigma\\) nella pratica, dobbiamo stimarlo utilizzando la deviazione standard campionaria \\(s\\). Pertanto, al posto di \\(\\sigma\\), possiamo utilizzare \\(s\\), ottenendo così la statistica:\n\\[\nT = \\frac{\\bar{X} - \\mu_0}{\\frac{s}{\\sqrt{n}}}.\n\\]\nSi può dimostrare che la statistica \\(T\\) segue una distribuzione \\(t\\) di Student con \\(n-1\\) gradi di libertà se il campione casuale è stato estratto da una popolazione normale.\nA questo punto, possiamo applicare la stessa logica descritta in precedenza e possiamom basarci sulla statistica \\(T\\) per testare un’ipotesi sulla media della popolazione. Utilizzando il valore critico appropriato dalla distribuzione \\(t\\) di Student con \\(n-1\\) gradi di libertà e un livello di significatività predefinito, possiamo determinare se i dati osservati supportano o respingono l’ipotesi nulla sulla media della popolazione.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#ipotesi-statistiche",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#ipotesi-statistiche",
    "title": "\n77  Significatività statistica\n",
    "section": "\n77.7 Ipotesi statistiche",
    "text": "77.7 Ipotesi statistiche\nEsaminiamo in maggior dettaglio la procedura di test di ipotesi statistiche nel contesto frequentista. Definiamo innanzitutto l’ipotesi statistica come una dichiarazione riguardante la distribuzione di probabilità di una variabile casuale. Tale ipotesi può riguardare la forma funzionale della distribuzione o i parametri che la caratterizzano.\nIn particolare, l’ipotesi che riguarda i parametri di una o più popolazioni viene denominata ipotesi nulla e viene rappresentata come \\(H_0\\). Per un parametro sconosciuto \\(\\theta\\), l’ipotesi nulla viene formulata come:\n\\[\nH_0: \\theta \\in \\Theta_0 \\subset \\Theta,\n\\]\ndove \\(\\Theta_0\\) è un sottoinsieme del dominio \\(\\Theta\\), che rappresenta tutti i possibili valori del parametro \\(\\theta\\) coerenti con il modello statistico adottato. L’ipotesi nulla può essere semplice se \\(\\Theta_0\\) contiene un unico elemento, oppure composta se contiene più di un elemento.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#i-passi-di-un-test-di-ipotesi",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#i-passi-di-un-test-di-ipotesi",
    "title": "\n77  Significatività statistica\n",
    "section": "\n77.8 I passi di un test di ipotesi",
    "text": "77.8 I passi di un test di ipotesi\nPer prendere una decisione tra accettare o respingere l’ipotesi nulla, i frequentisti utilizzano un test statistico. Un test statistico frequentista ci permette di valutare se i dati osservati forniscono prove sufficienti per respingere o accettare un’ipotesi riguardante una proprietà di una popolazione di interesse e si può descrivere nel modo seguente.\nIniziamo formulando l’ipotesi nulla \\(H_0\\), che rappresenta un’affermazione specifica sulla popolazione. L’ipotesi alternativa \\(H_1\\) viene formulata come l’evento complementare rispetto all’evento specificato dall’ipotesi nulla. Successivamente, definiamo una statistica campionaria \\(\\mathcal{G}_n(X_1, \\dots, X_n)\\) che viene calcolata a partire dai dati campionari e che ha una distribuzione nota quando l’ipotesi nulla è vera.\nSuccessivamente, suddividiamo l’insieme di tutte le possibili realizzazioni della statistica \\(\\mathcal{G}_n\\) in due insiemi disgiunti: la “regione di accettazione” \\(\\mathcal{A}\\) e la sua regione complementare, la “regione di rifiuto” \\(\\mathcal{R}\\). La regione di accettazione rappresenta l’insieme dei valori che la statistica può assumere sotto l’ipotesi nulla, mentre la regione di rifiuto rappresenta l’insieme dei valori che la statistica può assumere se l’ipotesi nulla è falsa.\nInfine, selezioniamo un livello di significatività \\(\\alpha\\), che rappresenta la massima probabilità di respingere erroneamente l’ipotesi nulla quando questa è vera. Se l’osservazione della statistica \\(\\mathcal{G}_n\\) rientra nella regione di accettazione, allora l’ipotesi nulla non viene respinta; altrimenti, viene respinta a favore dell’ipotesi alternativa.\nIn sintesi, il test statistico ci consente di stabilire se i dati osservati forniscono sufficienti evidenze per rifiutare l’ipotesi nulla a favore dell’ipotesi alternativa.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#ipotesi-alternativa",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#ipotesi-alternativa",
    "title": "\n77  Significatività statistica\n",
    "section": "\n77.9 Ipotesi alternativa",
    "text": "77.9 Ipotesi alternativa\nDurante un test di ipotesi, dopo aver definito l’ipotesi nulla \\(H_0\\), possono essere considerate diverse ipotesi alternative \\(H_1\\). Le ipotesi alternative più comuni si suddividono in tre tipi:\n\n\n\\(H_1: \\theta \\neq \\theta_0\\),\n\n\\(H_1: \\theta &gt; \\theta_0\\),\n\n\\(H_1: \\theta &lt; \\theta_0\\).\n\nQueste corrispondono rispettivamente a un test bidirezionale, un test unilaterale superiore (o destro) e un test unilaterale inferiore (o sinistro).\nLa scelta dell’ipotesi alternativa determina la definizione della regione di rifiuto \\(\\mathcal{R}\\) dell’ipotesi nulla \\(H_0\\). La regione di rifiuto rappresenta i valori estremi della distribuzione, nella direzione dell’ipotesi alternativa \\(H_1\\). Nel caso di un test unilaterale inferiore, \\(\\mathcal{R}\\) si trova nella coda sinistra della distribuzione, nell’intervallo [\\(-\\infty\\), \\(\\theta_0\\)]. Nel caso di un test unilaterale superiore, \\(\\mathcal{R}\\) si trova nella coda destra della distribuzione, nell’intervallo [\\(\\theta_0\\), \\(\\infty\\)].\nI valori critici sono i valori che delimitano la regione di rifiuto \\(\\mathcal{R}\\) in un test unilaterale e i valori che delimitano le regioni di rifiuto \\(\\mathcal{R}\\) in un test bidirezionale. Il risultato di un test viene considerato statisticamente significativo se il valore della statistica del test si trova nella regione di rifiuto \\(\\mathcal{R}\\).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#valore-p",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#valore-p",
    "title": "\n77  Significatività statistica\n",
    "section": "\n77.10 Valore-p",
    "text": "77.10 Valore-p\nIl valore-p è definito come la probabilità che la statistica del test assuma un valore uguale o più estremo di quello osservato, considerando la distribuzione campionaria costruita assumendo come vera l’ipotesi nulla. La significatività statistica viene convenzionalmente definita come un valore-p inferiore a 0.05, indicando che l’evidenza osservata è improbabile da ottenere se l’ipotesi nulla è vera. Se il risultato osservato non raggiunge la significatività statistica, significa che la stima non è statisticamente significativa e che il valore osservato può essere spiegato da una semplice variazione casuale.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#un-esempio-motivante",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#un-esempio-motivante",
    "title": "\n77  Significatività statistica\n",
    "section": "\n77.11 Un esempio motivante",
    "text": "77.11 Un esempio motivante\nPer esplorare il concetto di significatività statistica, possiamo prendere in considerazione uno studio svolto da Mehr et al. (2016) sul ruolo della musica nella trasmissione di messaggi sociali ai bambini. La musica è una forma d’arte presente in molte attività quotidiane e può trasmettere informazioni relative alla cultura e all’appartenenza sociale. Gli autori dello studio hanno voluto indagare se i bambini di soli 5 mesi avessero una preferenza per individui sconosciuti che cantavano loro una canzone familiare rispetto ad altri individui sconosciuti che cantavano una canzone simile, ma con una diversa melodia.\nDalle analisi condotte da Mehr et al. (2016) è emerso che la preferenza dei bambini si manifestava solo quando la canzone veniva cantata dai loro genitori durante la fase di familiarizzazione, ma non quando la stessa canzone veniva cantata da un estraneo. Secondo gli autori, questo dimostra che il significato sociale è un elemento chiave nella preferenza dei bambini, oltre alla familiarità con la canzone.\n\n77.11.1 Domanda della ricerca e ipotesi statistiche\nLa ricerca condotta da Mehr et al. (2016) si è concentrata sullo studio dell’influenza della musica sui messaggi sociali trasmessi ai bambini molto piccoli. Tuttavia, come molte altre ipotesi psicologiche, l’ipotesi principale non può essere valutata direttamente in termini quantitativi. Pertanto, i ricercatori devono formulare ipotesi statistiche, che, sebbene non coincidano con l’ipotesi della ricerca, possono essere esaminate in termini probabilistici.\nPer chiarire questo punto, consideriamo l’esperimento condotto sui bambini da Mehr et al. (2016). Dopo la fase di familiarizzazione con la canzone di prova, i bambini partecipanti sono stati sottoposti a un test in laboratorio, durante il quale sono stati mostrati due video. Nel primo video, un estraneo cantava la canzone di prova, mentre nel secondo video, un altro individuo cantava una canzone simile ma non familiare ai bambini. I ricercatori hanno misurato il tempo in cui i bambini fissavano ciascun video. Nel primo esperimento, la variabile dipendente era la media delle proporzioni di tempo che i bambini fissavano il video “familiare” rispetto al tempo di fissazione totale. Poiché l’ipotesi principale non può essere valutata direttamente, i ricercatori hanno formulato ipotesi statistiche che possono essere esaminate in termini probabilistici.\nPoiché nei tipici esperimenti psicologici, come nel caso della ricerca di Mehr et al. (2016), l’ipotesi della ricerca non può essere valutata direttamente, è necessario stabilire una connessione tra l’ipotesi della ricerca e l’ipotesi statistica. Nel caso specifico, ci sono tre possibili scenari da considerare:\n\nNel caso in cui i bambini non mostrino alcuna preferenza tra i due tipi di video-registrazione, la media delle proporzioni di tempo di fissazione per la popolazione sarà uguale a \\(\\mu = 0.5\\), in quanto i tempi di fissazione saranno uguali in media per le due video-registrazioni.\nSe invece gli autori della ricerca hanno ragione, i bambini mostreranno una preferenza per il video con la canzone familiare rispetto a quello con la canzone non familiare. In questo caso, l’ipotesi statistica sarà \\(\\mu &gt; 0.5\\), dove \\(\\mu = 0.5\\) rappresenta il livello di probabilità casuale.\nInfine, una terza possibilità è che i bambini siano maggiormente attratti da una melodia non familiare, contrariamente a quanto suggerito dagli autori della ricerca. In tal caso, l’ipotesi statistica diventa \\(\\mu &lt; 0.5\\).\n\nLe tre ipotesi precedenti sono esempi di ipotesi statistiche, che sono delle affermazioni riguardanti i valori di un parametro di un modello statistico. Nel caso dell’esperimento di Mehr et al. (2016), il modello statistico riguarda la distribuzione delle proporzioni dei tempi di fissazione di una popolazione virtuale di infiniti bambini di sei mesi di età. Ogni bambino avrà una proporzione di tempi di fissazione diversa dagli altri bambini. Il modello statistico descritto dai ricercatori rappresenta la distribuzione dei possibili valori della proporzione del tempo di fissazione nei confronti del video “familiare”. I dati raccolti dagli sperimentatori corrispondono alla media della proporzione del tempo di fissazione del video “familiare” e possono essere messi in relazione con il modello statistico.\n\n77.11.2 Domanda della ricerca e ipotesi statistiche\nLa distinzione tra l’ipotesi della ricerca e l’ipotesi statistica è cruciale durante il test delle ipotesi. L’ipotesi della ricerca riguarda l’affermazione che si intende testare sulla natura dei fenomeni psicologici, mentre l’ipotesi statistica riguarda il modello generativo dei dati, ovvero le proprietà della popolazione. Nel caso dell’esperimento condotto da Mehr e colleghi, l’ipotesi della ricerca afferma che la preferenza sociale dei bambini è influenzata dalla musica e, in particolare, dalla familiarità con i materiali musicali. L’ipotesi statistica, invece, sostiene che la media della proporzione del tempo di fissazione dei bambini sul video “familiare” sia maggiore di 0.5.\nI test di ipotesi vengono applicati alle ipotesi statistiche, non alle ipotesi della ricerca. Ciò significa che se l’esperimento non viene condotto nella maniera appropriata, il collegamento tra l’ipotesi statistica e la domanda della ricerca può essere spezzato. Ad esempio, se l’attore che canta la melodia familiare assomiglia ad uno dei genitori del bambino, mentre l’altro attore ha un aspetto molto diverso, allora potrebbe essere facile trovare evidenze a supporto dell’ipotesi statistica secondo cui la proporzione media del tempo di fissazione dei bambini nei confronti del video “familiare” è maggiore di 0.5, ma ciò non avrebbe nulla a che fare con la domanda della ricerca.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#ipotesi-nulla-e-ipotesi-alternativa",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#ipotesi-nulla-e-ipotesi-alternativa",
    "title": "\n77  Significatività statistica\n",
    "section": "\n77.12 Ipotesi nulla e ipotesi alternativa",
    "text": "77.12 Ipotesi nulla e ipotesi alternativa\nFino a qui il ragionamento è stato semplice: il ricercatore ha un’ipotesi a proposito dei fenomeni psicologici e a tale ipotesi di ricerca corrisponde un’ipotesi statistica che riguarda il meccanismo generativo dei dati. Se il fenomeno psicologico possiede le proprietà suggerite dall’ipotesi della ricerca, allora il ricercatore può aspettarsi che i dati osservati abbiano alcune specifiche caratteristiche. A questo punto, però, il ragionamento diventa contro-intuitivo perché non è possibile verificare direttamente l’ipotesi statistica che corrisponde alla domanda della ricerca.\n\n77.12.1 Apagogia\nIn linea di principio, non è mai possibile dimostrare direttamente la verità di una proposizione. Tuttavia, possiamo dimostrare la sua verità in modo indiretto, ovvero provando la falsità della sua proposizione complementare.\nL’esempio classico è il seguente. Consideriamo la seguente proposizione: “Tutti i cigni sono bianchi” (questo è l’esempio ornitologico preferito da Popper). L’osservazione di un numero qualsiasi di cigni bianchi non è sufficiente a dimostrare la verità di questa proposizione – infatti, ci potrebbe essere da qualche parte un cigno non bianco che non abbiamo osservato (e infatti c’è). D’altra parte, invece, l’osservazione di un solo cigno che non sia bianco (ovvero, per esempio, l’osservazione di un cigno nero proveniente dall’Australia) può falsificare la proposizione considerata. Questa è la logica del falsificazionismo di Popper.\nQuesto modo di pensare è stato trasferito nella procedura di test di ipotesi di stampo frequentista. Dato che non possiamo dimostrare vera l’ipotesi statistica associata alla domanda della ricerca, seguiamo il percorso opposto. Ovvero, ci poniamo l’obiettivo di dimostrare falso l’evento complementare a quello specificato dall’ipotesi statistica associata alla domanda della ricerca. L’ipotesi statistica che vorremmo falsificare si chiama “ipotesi nulla” e viene denotata con \\(H_0\\). Nel caso dell’esempio che stiamo discutendo, l’ipotesi nulla è: \\(\\mu \\leq 0.5\\). Si noti che l’ipotesi nulla include tutte le possibili ipotesi statistiche che si possono formulare (ovvero, \\(\\mu = 0.5\\) e \\(\\mu &lt; 0.5\\)), ad eccezione di quella che è associata all’ipotesi della ricerca (ovvero, \\(\\mu &gt; 0.5\\)). Questo definisce, nel caso presente, un test unilaterale.\nIn pratica, ciò che stiamo facendo è dividere tutti i possibili valori di \\(\\mu\\) in due gruppi: quei valori che sono coerenti con l’ipotesi della ricerca (ovvero, i valori che specificano l’ipotesi alternativa, denotata con \\(H_1\\)) e quei valori che non sono coerenti con l’ipotesi della ricerca (ovvero, i valori che specificano l’ipotesi nulla).\nAvendo detto questo, la cosa importante da riconoscere è che l’obiettivo di un test di ipotesi frequentista non è quello di dimostrare che l’ipotesi alternativa è (probabilmente) vera; l’obiettivo è mostrare che l’ipotesi nulla è (probabilmente) falsa. La maggior parte delle persone ritiene che questo modo di ragionare sia piuttosto strano.\n\n77.12.2 La similitudine del processo penale\nUn test di ipotesi è spesso comparato ad un processo penale, dove l’ipotesi nulla rappresenta l’imputato, il ricercatore il pubblico ministero, e il test statistico il giudice. Così come in un processo penale, anche in un test di ipotesi c’è una presunzione di innocenza, dove l’ipotesi nulla viene considerata vera a meno che il ricercatore non dimostri, con evidenza al di là di ogni ragionevole dubbio, che è falsa. Il ricercatore progetta l’esperimento in modo da massimizzare la possibilità che i dati producano una condanna dell’ipotesi nulla. Il test statistico, rappresentato dal giudice in questa metafora, stabilisce le regole che devono essere seguite per giungere al verdetto e tali regole sono pensate per proteggere l’ipotesi nulla. In particolare, sono studiate per garantire che la probabilità di una condanna sia bassa se l’ipotesi nulla è effettivamente vera. È importante sottolineare che l’ipotesi nulla deve essere protetta, poiché il ricercatore sta cercando di dimostrare che essa è falsa.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#due-tipi-di-errori",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#due-tipi-di-errori",
    "title": "\n77  Significatività statistica\n",
    "section": "\n77.13 Due tipi di errori",
    "text": "77.13 Due tipi di errori\nPrima di entrare nei dettagli su come viene costruito un test statistico è utile capire la logica su cui esso è basato. In precedenza abbiamo paragonato il test di ipotesi nulla ad un processo penale, ma ora dobbiamo essere più espliciti. Idealmente, vorremmo costruire il nostro test in modo da non commettere errori. Sfortunatamente, però, questo non è possibile: a volte il ricercatore è sfortunato e finisce per prendere la decisione sbagliata, anche se adotta un processo decisionale razionale. Ad esempio, può succedere che una moneta venga lanciata 10 volte di fila e produca testa tutte le 10 volte. Ciò sembra fornire una prova molto forte del fatto che la moneta è sbilanciata, ma c’è una possibilità su 1024 che ciò accada anche se la moneta è equilibrata. In altre parole, nella vita reale dobbiamo sempre accettare la possibilità che le nostre scelte siano sbagliate, anche quando sembrano ragionevoli. Di conseguenza, l’obiettivo dei test delle ipotesi statistiche non è quello di eliminare completamente gli errori (questo è impossibile), ma di ridurre gli errori al minimo.\nA questo punto, dobbiamo precisare meglio cosa intendiamo per “errori”. Iniziamo con il rendere esplicito quello che è ovvio: l’ipotesi nulla può essere vera o falsa, e il nostro test ci può condurre a rifiutare l’ipotesi nulla o a non rifiutarla. La decisione di rigettare o non rigettare l’ipotesi nulla ci espone dunque al rischio di commettere uno di due tipi di errore, come indicato nella figura seguente. L’errore di I tipo, denotato con \\(\\alpha\\), è quello che commettiamo se rigettiamo l’ipotesi nulla quando essa è vera; l’errore di II tipo, denotato con \\(\\beta\\), è quello che commettiamo se accettiamo l’ipotesi nulla mentre invece è vera l’ipotesi alternativa.\n\n\n77.13.1 Errore di I tipo: la protezione dei diritti dell’imputato\nIn precedenza abbiamo paragonato il test statistico ad un processo penale. Infatti, un processo penale richiede che si stabilisca la colpevolezza dell’imputato “oltre ogni ragionevole dubbio”. Le regole del processo penale sono state progettate per garantire che non ci sia (quasi) nessuna possibilità di condannare ingiustamente un imputato innocente: il processo penale è progettato (almeno in teoria) per proteggere i diritti dell’imputato. Detto in altri termini, il processo penale non mette sullo stesso piano i due tipi di errore che si possono commettere: punire un innocente o assolvere un colpevole. L’errore che consiste nel punire un innocente viene considerato assai più grave di quello che porta ad assolvere un colpevole.\nUn test statistico fa praticamente la stessa cosa: i test di ipotesi statistiche sono costruiti in modo tale da controllare la probabilità di un errore di I tipo, con l’obiettivo di mantenerla al di sotto di una certa soglia prefissata. Questa probabilità, denotata con \\(\\alpha\\), viene chiamata “livello di significatività del test”. Usando parole diverse, possiamo dire che un test di ipotesi ha un livello di significatività \\(\\alpha\\) se il tasso di errore di I tipo non è più grande di \\(\\alpha\\). Per convenzione, i ricercatori fanno uso di tre diversi livelli \\(\\alpha\\): 0.05, 0.01 e 0.001.\n\n77.13.2 Errore di II tipo: l’asimmetria del giudizio\nChe dire del tasso di errore di II tipo? In realtà, vorremmo tenere anche quello sotto controllo e denotiamo la probabilità di un errore di II tipo con \\(\\beta\\). Il livello d’errore \\(\\beta\\) viene raramente discusso ed è molto più comune fare riferimento alla potenza del test, che è la probabilità dell’evento complementare, ovvero la probabilità con cui rifiutiamo l’ipotesi nulla quando è realmente falsa, ovvero \\(1-\\beta\\). Un test viene detto “potente” quando è caratterizzato da un piccolo valore \\(\\beta\\) pur mantenendo il livello \\(\\alpha\\) sotto una piccola soglia di probabilità prefissata.\nSi noti l’asimmetria qui rivelata: i test di ipotesi sono progettati per garantire che il livello \\(\\alpha\\) sia mantenuto sotto la soglia prefissata, ma non esiste alcuna corrispondente garanzia a proposito di \\(\\beta\\). Sicuramente è preferibile che il tasso di errore di II tipo sia piccolo, e in generale i ricercatori cercano di progettare i loro esperimenti in maniera tale da avere una ragionevole potenza del test (\\(1 - \\beta\\)) – questo si ottiene utilizzando un campione sufficientemente grande – ma nella logica della costruzione del test di ipotesi questo aspetto è secondario rispetto alla necessità di controllare il tasso di errore di I tipo.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#come-si-costruisce-un-test-di-ipotesi",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#come-si-costruisce-un-test-di-ipotesi",
    "title": "\n77  Significatività statistica\n",
    "section": "\n77.14 Come si costruisce un test di ipotesi?",
    "text": "77.14 Come si costruisce un test di ipotesi?\nRitorniamo all’esempio relativo allo studio di Mehr et al. (2016). In questo caso, sulla base all’ipotesi della ricerca, l’ipotesi nulla può essere formulata come \\(H_0: \\mu \\leq 0.5\\). Esaminando un campione di 32 bambini di età media pari a 5.6 mesi, Mehr et al. (2016) hanno scoperto che, in media, i bambini dirigevano lo sguardo verso il video “familiare” nel 56% del tempo totale di fissazione. Dunque, la media campionaria è \\(\\bar{X} = 0.56\\) Questo è il valore campionario rilevante per il test dell’ipotesi nulla.\nIngenuamente, potremmo pensare che, per decidere se \\(H_0\\) sia falsa o meno, sia sufficiente confrontare la proporzione calcolata nel campione con il valore \\(\\pi\\) specificato dall’ipotesi nulla. Nel caso presente, l’ipotesi nulla non specifica un unico valore \\(\\mu\\) ma bensì un intervallo di valori: \\([0, 0.5]\\). I dati campionari specificano un valore \\(\\bar{X} = 0.56\\), ovvero un valore che non è incluso nell’intervallo specificato da \\(H_0\\). Questo è incoraggiante. Se invece avessimo osservato \\(\\bar{X} = 0.41\\), per esempio, allora non ci sarebbe stato nient’altro da dire: se i dati osservati sono compatibili con \\(H_0\\) non c’è bisogno di eseguire alcun test statistico – abbiamo già trovato la risposta alla domanda della ricerca.\n\n77.14.1 La variabilità campionaria\nNel caso dell’esperimento di Mehr et al. (2016) che stiamo discutendo, \\(\\bar{X}\\) non cade nell’intervallo specificato da \\(H_0\\). Sulla base del valore osservato \\(\\bar{X} = 0.56\\) possiamo dunque concludere che \\(H_0\\) è falsa? Non così presto. Non è sufficiente trovare una differenza \\(\\bar{X} - \\mu\\) nella direzione giusta (cioè positiva, nel nostro caso). È anche necessario tenere in considerazione il fenomeno della variabilità campionaria.\nInfatti, la media \\(\\bar{X}\\) osservata in ogni singolo campione di ampiezza \\(n=32\\) è una variabile aleatoria: in ciascun possibile campione di ampiezza 32 i bambini si comportano in maniera diversa e, di conseguenza, \\(\\bar{X}\\) assumerà un valore diverso da campione a campione. Le statistiche campionarie – nel nostro caso la media \\(\\bar{X}\\) – sono di necessità diverse dai parametri. Ciò a cui noi siamo interessati è la media della popolazione, ovvero \\(\\mu\\), ma sfortunatamente conosciamo solo una sua realizzazione campionaria, ovvero \\(\\bar{X}\\).\nRisulta dunque chiaro che la nostra decisione rispetto ad \\(H_0\\) non può essere unicamente basata sulla differenza tra \\(\\bar{X} - \\mu\\). Infatti, è ragionevole pensare che, indipendentemente dal fatto che l’ipotesi nulla sia vera o meno, in alcuni campioni la differenza \\(\\bar{X} - \\mu\\) sarà positive mentre in altri campioni sarà negativa. Dobbiamo dunque trovare una procedura che riduca la possibilità di rifiutare \\(H_0\\) per effetto del caso soltanto. Possiamo (e dobbiamo) fare di meglio che considerare unicamente la differenza \\(\\bar{X} - \\mu\\).\n\n77.14.2 Le distribuzioni delle statistiche test\nIl metodo seguito dall’approccio frequentista per affrontare questo problema è quello di costruire la distribuzione della statistica test \\(\\mathcal{G}_n\\), rilevante per il test di \\(H_0\\), assumendo come vera l’ipotesi nulla. Questo è il concetto più contro-intuitivo di tutta la procedura di test di ipotesi dell’approccio frequentista. Esaminiamolo più in dettaglio.\nLo scopo della procedura di test statistici dell’approccio frequentista non è quello di verificare l’ipotesi alternativa: questo non è logicamente possibile. Invece, come suggerito dalla similitudine del processo penale all’ipotesi nulla, l’approccio frequentista si pone l’obiettivo di determinare se ci siano indizi sufficienti per “condannare” l’ipotesi nulla, ovvero, per rigettarla. In questa reductio ad absurdum, la “presunzione di innocenza” di \\(H_0\\) corrisponde all’idea che dobbiamo assumere come vera l’ipotesi nulla fino a prova contraria.\nNell’esempio che stiamo discutendo, assumere come vera l’ipotesi nulla significa assumere che il parametro \\(\\mu\\) (la media della popolazione) sia uguale a 0.5. Sulla base di questa assunzione, per i dati dell’esempio presente, è possibile costruire la distribuzione delle medie dei campioni di ampiezza 32. Standardizzando poi la media del campione, è possibile stabilire quanto sia “distante” dal valore atteso della distribuzione campionaria costruita assumento come vera \\(H_0\\).\nLa standardizzazione di \\(\\bar{X}\\) si effettua mediante il rapporto\n\\[\nT = \\frac{\\bar{X} - \\mu}{\\frac{s}{\\sqrt{n}}},\n\\]\ndove \\(\\bar{X}\\) è la media del campione (nel nostro caso, 0.56), \\(s\\) è la deviazione standard del campione (gli autori riportano \\(s\\) = 0.179) e \\(n\\) è l’ampiezza del campione (ovvero, \\(n\\) = 32). Per il caso presente otteniamo:\n\nT &lt;- (0.56 - 0.50) / (0.179 / sqrt(32))\nprint(T)\n#&gt; [1] 1.896\n\n\n77.14.3 Regioni di rifiuto e regioni di non rifiuto\nConoscendo la distribuzione dei valori della statistica test (distribuzione determinata assumendo come vera \\(H_0\\)) diventa poi possibile dividere l’insieme dei valori possibili di \\(\\mathcal{G}_n\\) (il nome che abbiamo assegnato ad una generica statistica test) in due regioni: i valori che ci portano a rigettare \\(H_0\\) (regione di rifiuto) e quelli che non ci consentono di rigettare \\(H_0\\) (regione di non rifiuto).\nPer decidere quanto deve essere grande la regione di rifiuto di \\(H_0\\) è sufficiente collocare nella regione di rifiuto i valori estremi della statistica test \\(\\mathcal{G}_n\\), ovvero quelli che sarebbe molto improbabile osservare se \\(H_0\\) fosse vera.\n\n77.14.4 Quando rifiutare l’ipotesi nulla\nSupponiamo che la figura seguente rappresenti la distribuzione campionaria della statistica test \\(\\mathcal{G}_n\\).\n\nSe i dati producono la statistica test \\(\\mathcal{G}_n^1\\), non possiamo rifiutare l’ipotesi nulla \\(H_0\\). Se invece i dati producono \\(\\mathcal{G}_n^2\\) allora possiamo rifiutare l’ipotesi nulla in favore dell’ipotesi alternativa. Ci sono varie cose da notare.\n\nLa regione di rifiuto è costituita da valori lontani dal centro della distribuzione campionaria della statistica test, la quale è stata costruita assumendo come vera \\(H_0\\).\nLa regione di rifiuto è situata nelle code della distribuzione. Vedremo in seguito anche degli esempi di regioni di rifiuto unilaterali.\nIn questa discussione, l’ipotesi alternativa non è menzionata. Rifiutiamo o non rifiutiamo \\(H_0\\) basandoci unicamente sulla distribuzione campionaria \\(f(\\mathcal{G}_n \\mid H_0)\\), cioè sulla probabilità della statistica test condizionata all’ipotesi nulla \\(H_0\\). L’ipotesi alternativa \\(H_1\\) viene presa in considerazione quando si sceglie dove posizionare la regione di rifiuto di \\(H_0\\), ma formalmente non gioca alcun ruolo nel rigettare o meno \\(H_0\\).\n\n77.14.5 Specificazione delle regioni di rifiuto\nL’ipotesi alternativa \\(H_1\\) può assumere forme diverse e ciò conduce a specificazioni diverse della regione di rifiuto \\(\\mathcal{R}\\) di \\(H_0\\). La regione di rifiuto \\(\\mathcal{R}\\) dell’ipotesi nulla corrisponde ai valori collocati agli estremi della distribuzione secondo la direzione dell’ipotesi alternativa \\(H_1\\).\n\nSe l’ipotesi alternativa è \\(H_1: \\theta \\neq \\theta_0\\) (dove \\(\\theta\\) è un generico parametro e \\(\\theta_0\\) è uno specifico valore del parametro), allora le evidenze coerenti con l’ipotesi alternativa (e che portano al rigetto di \\(H_0\\)) sono contenute negli intervalli \\([-\\infty, \\theta_0]\\) e \\([\\theta_0, +\\infty]\\).\nSe l’ipotesi alternativa è \\(H_1: \\theta &lt; \\theta_0\\), allora le evidenze coerenti con l’ipotesi alternativa (e che portano al rigetto di \\(H_0\\)) sono contenute nell’intervallo \\([-\\infty, \\theta_0]\\) e l’intera regione di rifiuto \\(\\mathcal{R}\\) è collocata nella coda di sinistra della distribuzione.\nSe l’ipotesi alternativa è \\(H_1: \\theta &gt; \\theta_0\\), allora le evidenze coerenti con l’ipotesi alternativa (e che portano al rigetto di \\(H_0\\)) sono contenute nell’intervallo \\([\\theta_0, \\infty]\\) e l’intera regione di rifiuto \\(\\mathcal{R}\\) è collocata nella coda di destra della distribuzione.\n\nSi chiamano valori critici i valori che delimitano la regione di rifiuto \\(\\mathcal{R}\\) in un test unilaterale e i valori che delimitano le regioni di rifiuto \\(\\mathcal{R}\\) in un test bilaterale. In un test bidirezionale, i valori critici lasciano in ciascuna delle due code della distribuzione della statistica test una probabilità pari a \\(\\alpha/2\\); in un test unidirezionale lasciano una probabilità pari ad \\(\\alpha\\) in una sola coda. Il risultato di un test si dice statisticamente significativo quando il valore della statistica test ricade nella regione di rifiuto \\(\\mathcal{R}\\).\n\n77.14.6 La decisione statistica\nIl processo di decisione statistica viene descritto da von Mises (1964) nel modo seguente:\n\nControllare (checking) o saggiare (testing) ha la forma seguente: se il “risultato osservato” ha una ‘piccola’ probabilità subordinatamente all’ipotesi assunta, respingiamo l’ipotesi. (p. 441)\n\nOvviamente l’ipotesi a cui von Mises fa riferimento è l’ipotesi nulla.\nIn pratica, possiamo decidere se rigettare o meno l’ipotesi nulla in due modi: determinando se la statistica test \\(\\mathcal{G}_n\\) cade o meno nella regione di rifiuto (come abbiamo descritto sopra) o confrontando il valore-\\(p\\) con \\(\\alpha\\) – i due metodi sono equivalenti.\nIl valore-p rappresenta la probabilità di osservare un valore della statistica test \\(\\mathcal{G}_n\\) pari a quello effettivamente osservato, o maggiore, quanto l’ipotesi nulla è vera. Se il valore-\\(p\\) è minore del livello di significatività \\(\\alpha\\), allora la statistica test cade nella regione di rifiuto di \\(H_0\\) e ciò conduce al rifiuto dell’ipotesi nulla. Tali concetti sono riassunti nella tabella seguente.\n\nPer l’esempio in discussione, la statistica \\(T\\) calcolata sopra si distribuisce come \\(t\\) di Student con \\(\\nu = 31\\) gradi di libertà. Il valore-p corrisponde dunque all’area sottesa ad una \\(t_{31}\\) nell’intervallo \\([1.896, +\\infty]\\) (test unidirezionale destro), ovvero\n\n# Calculate the upper tail probability for the t-distribution\np &lt;- 1 - pt(T, df = 31)\nprint(p)\n#&gt; [1] 0.03365\n\nDato che il valore-p è minore di \\(\\alpha = 0.05\\), Mehr et al. (2016) rifiutano \\(H_0\\) (cioè che la proporzione media del tempo di fissazione dei bambini nei confronti del video “familiare” sia 0.5, o minore) e concludono che i bambini mostrano una preferenza per il video familiare.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#potenza-del-test",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#potenza-del-test",
    "title": "\n77  Significatività statistica\n",
    "section": "\n77.15 Potenza del test",
    "text": "77.15 Potenza del test\nRitorniamo ora al concetto di potenza del test. Il livello di significatività e la potenza del test vengono usati per quantificare la qualità dell’inferenza statistica. Idealmente, la procedura di test di ipotesi non dovrebbe giungere alla conclusione sbagliata. Ovvero, non dovrebbe respingere \\(H_0\\) quando essa è vera e dovrebbe respingere \\(H_0\\) in favore dell’alternativa quando \\(H_1\\) è vera. Ma questi sono solo due dei quattro esiti che, in principio, sono possibili, e corrispondono alle probabilità indicate di seguito.\n\nPossiamo pensare a \\(H_0\\) come all’ipotesi che descrive l’evento “nulla di interessante sta succedendo” – ad esempio, “la moneta è bilanciata”, “il trattamento non è migliore del placebo”, ecc. – e pensare ad \\(H_1\\) come al caso contrario, ovvero: “sta accadendo qualcosa di interessante”. Quindi la potenza del test, ovvero la probabilità \\(1 - \\beta\\) di rigettare \\(H_0\\) quando essa è falsa, corrisponde alla probabilità di rilevare qualcosa di interessante, quando qualcosa di interessante è effettivamente successo, mentre il livello di significatività corrisponde alla probabilità di affermare che qualcosa di interessante si è verificato, quando in realtà non è successo nulla di interessante.\nIl calcolo della potenza di un test è spesso difficile, perché richiede la conoscenza della distribuzione campionaria di \\(\\mathcal{G}_n\\) quando è vera l’ipotesi alternativa \\(H_1\\). Tipicamente possiamo aumentare la potenza di un test aumentando la numerosità del campione in maniera tale da diminuire la varianza delle distribuzioni della statistica test condizionate a \\(H_0\\) e ad \\(H_1\\). In un disegno sperimentale è importante determinare in anticipo il numero di prove o dei soggetti necessari per raggiungere la potenza desiderata.\n\n77.15.1 Neyman e Fisher\nLa procedura di test di ipotesi statistiche descritta sopra combina due approcci teorici diversi, proposti da Sir Ronald Fisher e Jerzy Neyman. La storia di questi due approcci non è lineare, poiché Fisher e Neyman hanno modificato le loro opinioni nel tempo, senza mai fornire una “verità definitiva” su come interpretare il loro lavoro.\nIn sintesi, Fisher considerava che il ricercatore avesse un’unica ipotesi (quella nulla) e che lo scopo fosse verificare se i dati fossero coerenti o meno con essa. In questo senso, il valore-\\(p\\) rappresenta la probabilità di osservare, sotto l’ipotesi nulla, il risultato ottenuto o uno ancora più estremo. Se il valore-\\(p\\) è piccolo, Fisher rifiutava l’ipotesi nulla. Tuttavia, poiché non venivano formulate altre ipotesi, non c’era modo di “accettare l’alternativa”.\nAl contrario, Neyman adottava un approccio più formale rispetto a Fisher e pensava che lo scopo della verifica delle ipotesi fosse quello di prendere decisioni. Secondo Neyman, il problema era decidere se accettare l’ipotesi nulla o l’alternativa e il test serviva a stabilire quale supporto venisse fornito alle due alternative. Per questo motivo, era fondamentale specificare in modo preciso l’ipotesi alternativa. Nel suo approccio, il valore-\\(p\\) non misurava la probabilità del risultato del test o di uno più estremo sotto l’ipotesi nulla, ma forniva una descrizione astratta dei “possibili test” che portavano all’accettazione dell’ipotesi nulla o dell’alternativa.\nAttualmente ci troviamo in una situazione strana e ambigua, dove sono presenti elementi di entrambi gli approcci. La procedura di verifica di ipotesi statistiche distingue tra un’ipotesi nulla e un’ipotesi alternativa, seguendo la visione di Neyman, ma definisce il valore-\\(p\\) in termini di dati estremi, come avrebbe fatto Fisher, in confronto con un livello \\(\\alpha\\) stabilito da Neyman. Alcuni test statistici specificano in modo chiaro l’ipotesi alternativa, mentre altri sono più vaghi in merito, adottando l’approccio di Fisher. Inoltre, c’è disaccordo tra i ricercatori riguardo alla possibilità di “accettare l’alternativa”, a seconda che si segua Neyman o Fisher. Questa confusione costituisce il “peccato originale” della procedura di verifica di ipotesi statistiche. Tuttavia, ci sono motivi più specifici per cui questo approccio, noto come significatività statistica, viene criticato da molti ricercatori come una delle cause principali della crisi della replicabilità dei risultati della ricerca in psicologia e in altri campi. Nel capitolo ?sec-errors-s-m esploreremo queste ragioni in dettaglio.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#la-storia-del-test-dellipotesi-nulla-di-fisher-e-le-sue-contraddizioni",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#la-storia-del-test-dellipotesi-nulla-di-fisher-e-le-sue-contraddizioni",
    "title": "\n77  Significatività statistica\n",
    "section": "\n77.16 La Storia del Test dell’Ipotesi Nulla di Fisher e le Sue Contraddizioni",
    "text": "77.16 La Storia del Test dell’Ipotesi Nulla di Fisher e le Sue Contraddizioni\nConcludiamo l’analisi della procedura dei test di ipotesi statistici esaminando l’evento che ha ispirato Ronald A. Fisher a sviluppare la sua teoria dell’inferenza statistica, focalizzata sul test dell’ipotesi nulla. Questo episodio è descritto dettagliatamente da Etz et al. (2018). L’aneddoto riguarda un tè che Fisher aveva offerto alla sua collega, la Dott.ssa Muriel Bristol. Durante la preparazione della bevanda, la Dr.ssa Bristol contestò il metodo adottato da Fisher, asserendo che il tè avrebbe avuto un gusto migliore se il latte fosse stato versato prima dell’acqua bollente. Per verificare l’affermazione della Dr.ssa Bristol, Fisher ideò un esperimento di discriminazione sensoriale. Nei test condotti, la Dr.ssa Bristol fu in grado di individuare correttamente il processo di preparazione del tè in cinque occasioni su sei.\nQuesto risultato pose Fisher di fronte a un interrogativo: la sua collega stava semplicemente facendo una supposizione fortunata, oppure era effettivamente in grado di discernere tra le due diverse modalità di preparazione? Per risolvere questa questione, Fisher elaborò la sua metodologia per il test dell’ipotesi nulla. Utilizzò un valore-\\(p\\) calcolato sulla base della probabilità dell’evento osservato, nonché di qualsiasi altro evento più estremo che potrebbe verificarsi sotto l’ipotesi nulla.\nTuttavia, è stato fatto notare che l’approccio di Fisher al test dell’ipotesi nulla può essere insufficiente e portare a conclusioni errate (Etz et al., 2018). Una delle questioni fondamentali riguarda la definizione di un evento “più estremo” rispetto a quello osservato.\nSupponiamo che lo scopo dell’esperimento casuale sia di determinare l’accuratezza delle riposte della Dr.ssa Bristol in esattamente sei tentativi (e non di più). In tale caso, con 5 risposte corrette, il valore-\\(p\\) è pari a 0.109, che non è statisticamente significativo. In questo scenario, secondo la logica di Fisher, non si dovrebbe respingere l’ipotesi nulla che la Dr. Bristol stesse semplicemente indovinando.\nSupponiamo ora che lo scopo dell’esperimento casuale sia di continuare a servire tè fino a quando la Dr.ssa Bristol non abbia raggiunto cinque risposte corrette (un risultato che, per coincidenza, si è verificato dopo sei tentativi). Se analizziamo i dati in questo secondo scenario, il valore-\\(p\\) diventa pari a 0.031, che è statisticamente significativo. In quest’ultimo caso, l’ipotesi nulla verrebbe respinta.\nQuello che emerge è che, nonostante i dati osservati nei due scenari siano identici, giungiamo a conclusioni opposte come conseguenza delle diverse modalità di campionamento impiegate. Questa variabilità è problematica poiché il valore-\\(p\\), e quindi la nostra valutazione delle capacità discriminative della Dr.ssa Bristol, dipendono non solo dai dati effettivamente raccolti, ma anche dal disegno sperimentale adottato. Questa constatazione mette in discussione la robustezza del test dell’ipotesi nulla come strumento fondamentale per l’inferenza scientifica.\nPer illustrare il problema, svolgiamo i calcoli utilizzando le distribuzioni statistiche richieste per i due tipi di campionamento: la distribuzione binomiale e la distribuzione geometrica negativa.\n\n77.16.1 Distribuzione Binomiale\nLa distribuzione binomiale è la distribuzione da utilizzare quando il numero di tentativi è prefissato e conosciuto a priori. Nel contesto dell’esempio del tè, assumiamo che siano state servite esattamente sei tazze. La formula per determinare la probabilità di registrare esattamente \\(k\\) successi in \\(n\\) tentativi è la seguente:\n\\[\nP(X = k) = \\binom{n}{k} \\times p^k \\times (1-p)^{(n-k)}\n\\]\nQui, \\(\\binom{n}{k}\\) rappresenta il coefficiente binomiale, \\(p\\) è la probabilità di un singolo successo (ossia di indovinare correttamente la preparazione del tè), e \\((1-p)\\) è la probabilità di un singolo fallimento.\nPer calcolare il valore-\\(p\\) in questo specifico contesto, dobbiamo sommare le probabilità di ottenere un risultato di 5 o più estremo su un totale di 6 tentativi.\n\n# Parameters\nn_binomial &lt;- 6  # Number of fixed trials for the binomial distribution\nn_success &lt;- 5  # Desired number of successes\np &lt;- 0.5  # Probability of success\n\n# Calculate the p-value for the binomial distribution\np_value_binomial &lt;- 1 - pbinom(n_success - 1, size = n_binomial, prob = p)\n\np_value_binomial\n#&gt; [1] 0.1094\n\n\n77.16.2 Distribuzione Geometrica Negativa\nNel contesto dell’esperimento del tè, quando il test continua fino al raggiungimento di un numero prefissato di successi (nel nostro caso, cinque identificazioni corrette), la distribuzione di riferimento appropriata è la distribuzione geometrica negativa.\nLa distribuzione geometrica negativa modella il numero di fallimenti \\(k\\) che si verificano prima di ottenere un numero prefissato \\(r\\) di successi in una sequenza di prove indipendenti di Bernoulli, dove ogni prova ha probabilità di successo \\(p\\).\nLa probabilità di osservare esattamente \\(k\\) fallimenti prima di ottenere \\(r\\) successi è data da:\n\\[\nP(X = k) = \\binom{k+r-1}{k} p^r (1-p)^k,\n\\]\ndove:\n\n\n\\(k\\) è il numero di fallimenti,\n\n\\(r\\) è il numero di successi desiderato,\n\n\\(p\\) è la probabilità di successo in ogni prova,\n\n\\(\\binom{k+r-1}{k}\\) è il coefficiente binomiale che rappresenta il numero di modi possibili in cui \\(k\\) fallimenti e \\(r\\) successi possono essere ordinati.\n\nNel nostro caso specifico:\n\n\n\\(r = 5\\) (successi desiderati),\n\n\\(p = 0.5\\) (probabilità di indovinare correttamente sotto l’ipotesi nulla),\n\n\\(k\\) varia da 0 a 1 (possibili fallimenti prima del quinto successo).\n\nIl valore-p si calcola sommando le probabilità per tutti i casi “più estremi” di quello osservato:\n\\[\n\\text{valore-p} = \\sum_{k=0}^{1} \\binom{k+5-1}{k} (0.5)^5 (0.5)^k.\n\\]\nImplementazione:\n\n# Parameters\nn_binomial &lt;- 6  # Number of fixed trials for the binomial distribution\nn_success &lt;- 5  # Desired number of successes\np &lt;- 0.5  # Probability of success (guessing the tea cup)\n\n# Calculate the p-value for the negative binomial distribution\np_value_geom_corrected &lt;- 0\nfor (k in 0:(n_binomial - n_success - 1)) {  # Number of failures before the 5th success\n  p_value_geom_corrected &lt;- p_value_geom_corrected + \n    choose(k + n_success - 1, k) * ((1 - p)^k) * (p^n_success)\n}\n\np_value_geom_corrected\n#&gt; [1] 0.03125\n\nIn conclusione,\n\nper la distribuzione binomiale, il p-value è \\(0.109\\), che non è statisticamente significativo (dato che è maggiore di 0.05); quindi, secondo Fisher, in questo caso non dovremmo rigettare l’ipotesi nulla che Dr. Bristol stia indovinando.\nper la distribuzione geometrica negativa, il p-value è \\(0.031\\), che è statisticamente significativo (dato che è minore di 0.05); in questo caso, dovremmo rigettare l’ipotesi nulla, suggerendo che Dr. Bristol non sta semplicemente indovinando.\n\nLa presente discussione mostra che, in base alla procedura del test dell’ipotesi nulla, la stessa sequenza di eventi (5 successi su 6 tentativi) può portare a conclusioni opposte a seconda delle ipotesi sul processo di campionamento. Questo paradosso è uno dei motivi (per ulteriori critiche, si veda Wasserstein & Lazar (2016); Benjamin et al. (2018)) per cui l’inferenza bayesiana è diventata più popolare negli ultimi anni come quadro alternativo per il test delle ipotesi e la stima dei parametri.\n\n77.16.3 Approccio Bayesiano\nNel loro lavoro, Etz et al. (2018) propongono un’alternativa bayesiana per risolvere il problema esaminato da Fisher. Questa soluzione bayesiana evita le contraddizioni che emergono quando si cercano di definire “risultati più estremi” che non sono stati osservati. L’approccio bayesiano si focalizza esclusivamente sui dati effettivamente raccolti e utilizza queste osservazioni per aggiornare le probabilità iniziali (o “a priori”) associate a diverse ipotesi. Il processo si basa sulla regola di Bayes e si sviluppa in tre fasi principali:\n\nStabilire Probabilità a Priori: Iniziamo assegnando una distribuzione di probabilità a priori a tutti i possibili tassi di successo che la Dr. Bristol potrebbe avere. Questo include una probabilità specifica per l’ipotesi nulla, che suggerisce che la Dr. Bristol stia semplicemente indovinando (con un tasso di successo del 50%).\nAggiornare le Probabilità con Dati Osservati: Utilizziamo i dati raccolti nell’esperimento per aggiornare le nostre probabilità a priori. Questo aggiornamento è fatto utilizzando la regola di Bayes.\nCalcolare il Fattore di Bayes: Questa metrica ci dice quanto i dati osservati influenzano le probabilità delle diverse ipotesi. Un Fattore di Bayes molto maggiore di 1 indicherebbe un forte supporto per l’ipotesi alternativa rispetto all’ipotesi nulla.\n\nNel caso specifico, il Fattore di Bayes calcolato è risultato essere circa 147.33, un valore notevolmente alto. Questo suggerisce che i dati osservati sono molto più compatibili con l’ipotesi che la Dr.ssa Bristol possa effettivamente distinguere tra le diverse preparazioni del tè, piuttosto che con l’ipotesi che stia indovinando.\nEtz et al. (2018) concludono che l’approccio bayesiano offre un quadro più robusto e coerente per il test delle ipotesi. A differenza del metodo frequentista, esso non dipende dalla definizione di “risultati più estremi” non osservati e si concentra invece esclusivamente sui dati effettivamente raccolti. Questa focalizzazione, in generale, rende l’approccio bayesiano una soluzione più solida per valutare le ipotesi scientifiche. Per una rivisitazione bayesiana dell’esperimento “The Lady Tasting Tea”, si veda anche la discussione di Doorn et al. (2020).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#malintesi-sul-valore-p",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#malintesi-sul-valore-p",
    "title": "\n77  Significatività statistica\n",
    "section": "\n77.17 Malintesi sul valore-p",
    "text": "77.17 Malintesi sul valore-p\nSono diffusi molti malintesi sul valore-p. Ne esaminiamo qui quelli più comuni.\nMalinteso 1: Un valore p non significativo significa che l’ipotesi nulla è vera.\nIl malinteso che un valore p non significativo (p &gt; 0.05) implichi l’assenza di effetto o la verità dell’ipotesi nulla è diffuso e porta a conclusioni errate. La chiave per evitare questo errore sta nel comprendere che i valori p riflettono la probabilità dei dati osservati sotto l’ipotesi nulla, e non la probabilità dell’ipotesi stessa. Un valore p elevato non dimostra che l’ipotesi nulla sia vera, ma indica semplicemente che i dati osservati non sono sufficientemente insoliti da rifiutare l’ipotesi nulla con un livello di confidenza predefinito.\nRisultati non significativi possono verificarsi anche quando esiste un effetto reale, ma i dati non sono abbastanza estremi da superare la soglia di significatività statistica.\nInvece di concludere affrettatamente l’assenza di effetto da un valore p non significativo, dovremmo riconoscere l’ambiguità e considerare altre possibilità. Dichiarazioni come “non c’era differenza” dovrebbero essere riformulate in termini di assenza di differenza statisticamente significativa, lasciando aperta la questione dell’esistenza di un effetto reale.\nL’approccio bayesiano offre una prospettiva diversa che può essere particolarmente utile per interpretare risultati non significativi. A differenza dei valori p, che si limitano a valutare la probabilità dei dati sotto l’ipotesi nulla, l’inferenza bayesiana permette di calcolare direttamente la probabilità delle ipotesi date i dati.\nL’approccio bayesiano, quindi, non si limita a rifiutare o non rifiutare l’ipotesi nulla, ma quantifica la forza dell’evidenza a favore di un’ipotesi rispetto all’altra, fornendo una conclusione più informativa rispetto al semplice “non posso rifiutare l’ipotesi nulla”.\nMalintesto 2: Un valore p significativo significa che l’ipotesi nulla è falsa.\nCome spiegato in precedenza, il valore-p quantifica la “sorpresa” suscitata dai dati, alla luce dell’ipotesi nulla. Non ci dice niente sull’ipotesi che abbiamo assunto per quantificare la “sorpresa”.\nMalinteso 3: Un valore p significativo significa che è stato scoperto un effetto importante.\nLa distinzione tra “significatività statistica” e “rilevanza pratica” è fondamentale: mentre la prima indica semplicemente che un risultato è improbabile sotto l’ipotesi nulla, la seconda valuta l’effetto nel contesto di applicazioni reali e le sue implicazioni.\nUn effetto statisticamente significativo non garantisce che l’effetto abbia un impatto pratico notevole o utile.\nInoltre, al di là della significatività pratica, l’abitudine di molti psicologi di escludere i predittori che non risultano “statisticamente significativi” è un grossolano errore: la significatività statistica non può essere usata come un metodo per la selezione di variabili in un modello statistico.\nUn p &lt; 0.05 indica che, se l’ipotesi nulla è vera, abbiamo osservato dati che dovrebbero essere considerati sorprendenti. Tuttavia, solo perché i dati sono sorprendenti, non significa che dobbiamo preoccuparcene. È principalmente l’etichetta verbale “significativo” che causa confusione qui: in un contesto frequentista, un effetto “significativo” è un effetto “sorprendente” alla luce di \\(H_0\\), non è necessariamente un effetto “importante”.\nMalinteso 4: Se avete osservato un risultato significativo, la probabilità che abbiate commesso un errore di Tipo 1 (un falso positivo) è del 5%.\nIl malinteso che la presenza di un risultato significativo (per esempio, p &lt; 0.05) indichi una probabilità del 5% di aver commesso un errore di Tipo 1 (falso positivo) riflette una comprensione errata della statistica frequentista. La probabilità del 5% si riferisce al tasso di errore di Tipo 1, che è la proporzione di volte che potremmo aspettarci di rifiutare erroneamente l’ipotesi nulla se questa fosse vera, su molteplici ripetizioni dell’esperimento sotto le stesse condizioni. In altre parole, se potessimo ripetere lo stesso studio infinite volte, osserveremmo risultati falsamente positivi nel 5% di questi studi, assumendo che l’ipotesi nulla sia effettivamente vera in ogni caso.\nTuttavia, una volta che abbiamo raccolto i dati e ottenuto un risultato significativo in un unico studio, non possiamo dire che “la probabilità che questo particolare risultato sia un errore di Tipo 1 è del 5%”. In realtà, in quel momento specifico, l’evento (commettere un errore di Tipo 1) è già accaduto o non è accaduto; la probabilità associata a quel singolo risultato non è più applicabile nel modo in cui potremmo aspettarci intuitivamente. Il risultato è, per così dire, una realtà fissa: o abbiamo rilevato un effetto che in realtà non esiste (errore di Tipo 1), oppure abbiamo correttamente identificato un effetto reale. Senza ulteriori esperimenti o dati, non possiamo determinare con certezza in quale di queste categorie cade il nostro risultato.\nIn breve, il tasso del 5% di errore di Tipo 1 non si applica retroattivamente a un singolo risultato ottenuto, ma piuttosto descrive il comportamento a lungo termine di un test statistico sotto ripetute campionature. Questa distinzione è cruciale per una corretta interpretazione dei risultati degli esperimenti e sottolinea l’importanza di non sovrastimare la certezza di un singolo risultato statistico significativo.\nMalinteso 5: Uno meno il valore p è la probabilità che l’effetto si replichi quando ripetuto.\nIl concetto che 1 meno il valore p rappresenti la probabilità di replicazione di un effetto è un malinteso diffuso. In realtà, la probabilità di replicazione di un effetto non può essere direttamente calcolata dal valore p di un singolo studio a causa della complessità dei fattori coinvolti, tra cui la vera differenza media tra i gruppi. La potenza statistica di un test, che dipende dalla dimensione dell’effetto, dalla dimensione del campione e dal livello di significatività α, fornisce una stima della probabilità di rilevare un effetto significativo se questo effetto esiste davvero. Tuttavia, osservare un effetto significativo in un unico studio (ad esempio, p = 0.03) non significa che vi sia una probabilità del 97% che tale effetto si replichi in studi futuri. La possibilità di replicare un risultato dipende dalla presenza di un vero effetto e dalla potenza statistica del test originale.\nIn sintesi, la replicabilità di un effetto è influenzata da molti fattori e non può essere inferita semplicemente dal valore p di un singolo risultato. La comprensione e l’interpretazione corrette della replicabilità richiedono un’analisi dettagliata della potenza statistica e della dimensione dell’effetto, oltre che della consistenza dei risultati attraverso studi multipli.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#riflessioni-conclusive",
    "title": "\n77  Significatività statistica\n",
    "section": "\n77.18 Riflessioni Conclusive",
    "text": "77.18 Riflessioni Conclusive\nIl presente capitolo ha messo in evidenza le numerose limitazioni e i potenziali pericoli dell’approccio frequentista al test dell’ipotesi nulla, portando alla luce una serie di paradossi e malintesi che minano la sua validità come strumento primario per l’inferenza scientifica. In particolare, abbiamo visto come il valore-p, spesso utilizzato come metro di giudizio assoluto per decidere se un risultato è significativo o meno, possa condurre a conclusioni fuorvianti, dipendendo non solo dai dati osservati ma anche dal contesto sperimentale e dalle scelte soggettive del ricercatore. Questo approccio, che si basa su una logica binaria di “accettare” o “rifiutare” l’ipotesi nulla, sembra incapace di cogliere la complessità delle relazioni causali e degli effetti reali presenti nei fenomeni psicologici e sociali. Più profondamente, emerge con chiarezza che il metodo frequentista, lungi dall’essere un sistema oggettivo per la decisione statistica, è invece intriso di convenzioni arbitrarie (come il livello di significatività α = 0.05) e di una visione riduzionistica della probabilità, concepita come frequenza relativa di eventi ripetibili nel tempo piuttosto che come misura della nostra incertezza riguardo a un evento specifico.\nTuttavia, al di là delle critiche tecniche, il problema più grave risiede nella tendenza a considerare il test dell’ipotesi nulla come uno strumento definitivo per valutare la veridicità di ipotesi scientifiche, anziché come un semplice punto di partenza per ulteriori indagini. La cultura prevalente nella comunità scientifica, che premia i risultati “statisticamente significativi”, ha contribuito a creare un ambiente in cui gli studi replicabili sono rari e dove molti risultati pubblicati sono fragili e difficilmente generalizzabili. È qui che l’approccio bayesiano entra in gioco, offrendo una soluzione coerente e robusta che supera molte delle carenze del frequentismo. Al contrario del metodo frequentista, che si concentra su ipotesi nulle arbitrariamente definite e sulle distribuzioni campionarie di statistiche teoriche, il bayesianesimo ci permette di incorporare informazioni pregresse (prior) e di aggiornare queste conoscenze in base ai dati osservati, fornendo una stima diretta della probabilità delle ipotesi di interesse. Questo approccio, che mette al centro la nozione di evidenza, permette di quantificare la forza delle prove a favore di diverse ipotesi, evitando così le dicotomie rigide tra “significativo” e “non significativo” e promuovendo una visione più sfumata e matematicamente fondata dell’inferenza statistica.\nIn conclusione, il test dell’ipotesi nulla frequentista, pur essendo ampiamente utilizzato, rappresenta uno degli aspetti più controversi e problematici dell’approccio tradizionale. La sua rigidità metodologica e la dipendenza da concetti come il valore p e la significatività statistica lo rendono non solo impreciso, ma anche inadeguato a cogliere la complessità dei fenomeni che la ricerca psicologica si propone di esplorare. Abbandonare questo paradigma non è solo una questione di precisione tecnica, ma di superare una mentalità riduzionista che limita la nostra capacità di interpretare i dati in modo sfumato e contestuale.\nL’adozione di metodologie bayesiane, al contrario, offre un quadro più dinamico e flessibile, in cui le ipotesi non sono semplicemente accettate o rifiutate, ma valutate in termini probabilistici. Questo approccio incoraggia un confronto diretto tra modelli e ipotesi contrapposte, permettendo di aggiornare le nostre credenze alla luce dei nuovi dati. Non si tratta solo di un miglioramento tecnico nelle inferenze scientifiche, ma di un invito a ripensare il modo in cui concepiamo la conoscenza e il processo di scoperta. La prospettiva bayesiana, infatti, enfatizza l’incertezza come parte intrinseca della ricerca, trasformandola in uno strumento per affinare le nostre comprensioni piuttosto che un ostacolo da superare.\nIn un contesto psicologico intrinsecamente complesso e caratterizzato da incertezza, l’approccio bayesiano rappresenta un’opportunità per adottare un’epistemologia più flessibile e razionale. La sua forza risiede nella capacità di adattarsi alla natura multifattoriale dei fenomeni psicologici, integrando in modo coerente e trasparente sia le conoscenze pregresse sia le nuove evidenze. In questo senso, l’adozione del paradigma bayesiano non è soltanto un avanzamento metodologico, ma anche un passo verso una scienza più consapevole, critica e adatta alle sfide della psicologia contemporanea.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#esercizi",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#esercizi",
    "title": "\n77  Significatività statistica\n",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\n\nL’Idea di Base del Test di Ipotesi\n\nSpiega il principio generale del test di ipotesi nulla in ambito frequentista. In che modo la logica dell’“assumere come vera l’ipotesi nulla fino a prova contraria” è paragonabile al concetto di “presunzione di innocenza” in un processo penale? Quali vantaggi e svantaggi comporta questa impostazione?\n\nIpotesi di Ricerca vs. Ipotesi Statistica\n\nSpiega in che modo l’ipotesi di ricerca (ad esempio, “esiste un effetto della musica sul comportamento dei bambini”) differisce dall’ipotesi statistica che si testa formalmente (ad esempio, “la media di un indice di preferenza è maggiore di 0.5”). Perché spesso la ricerca psicologica non può testare direttamente l’ipotesi di ricerca?\n\nSignificatività Statistica e Rilevanza Pratica\n\nChe differenza c’è tra “risultato statisticamente significativo” e “risultato rilevante (o importante) dal punto di vista pratico o teorico”? Porta un esempio in cui un test frequenzista possa dare un valore-\\(p\\) molto basso senza che l’effetto sia considerato rilevante nel contesto.\n\nMalinteso: Un Risultato non Significativo Implica Che \\(H_0\\) Sia Vera?\n\nPerché è errato concludere che l’ipotesi nulla sia vera quando il test non risulta significativo (cioè quando \\(p \\ge 0.05\\))? Quali altre spiegazioni potrebbero esserci se un esperimento produce un valore-\\(p\\) alto?\n\nIl Ruolo della Variabilità Campionaria\n\nIn che modo la variabilità campionaria (cioè il fatto che stime come la media campionaria varino da campione a campione) influisce sulla necessità di un test di ipotesi? Perché non è sufficiente confrontare la media osservata con il valore ipotizzato per concludere se \\(H_0\\) è falsa?\n\nErrori di I e II Tipo e Potenza del Test\n\nDescrivi i concetti di errore di I tipo (falso positivo) e errore di II tipo (falso negativo). Perché i test sono progettati primariamente per controllare l’errore di I tipo? Che cos’è la potenza (\\(1-\\beta\\)) di un test?\n\nIl Valore-\\(p\\): Che Cosa (non) Indica?\n\nSpiega la definizione di valore-\\(p\\) secondo l’approccio frequentista. Quali sono due malintesi comuni su ciò che il valore-\\(p\\) non rappresenta?\n\nCritica: Dipendenza dai “Risultati più Estremi Non Osservati”\n\nNell’esempio dell’episodio “The Lady Tasting Tea”, come mai il test di ipotesi frequentista può portare a conclusioni diverse pur avendo gli stessi dati osservati, a seconda di come è definito il “processo di campionamento”? Perché questa è una limitazione?\n\nControllo dell’Errore di I Tipo, ma Non dell’Errore di II Tipo\n\nPerché nel test di ipotesi frequentista esiste un’asimmetria per cui si controlla rigorosamente l’errore di I tipo (fissando \\(\\alpha\\)), ma non esiste un analogo vincolo obbligatorio sull’errore di II tipo (\\(\\beta\\))? Quali conseguenze pratiche ne derivano per la pianificazione di uno studio?\n\nLimiti dell’Approccio Frequentista e Alternative\n\nRiassumi in che senso il test di ipotesi nulla frequentista è ritenuto da alcuni ricercatori insufficiente o fuorviante (es. “dichotomania” del significato, p-value dipendente dal disegno, ecc.). Quali alternative o integrazioni sono state proposte in letteratura per superare questi limiti?\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\n\nL’Idea di Base del Test di Ipotesi\n\n\nL’ipotesi nulla (\\(H_0\\)) è considerata “innocente” fino a che l’evidenza non la “condanna”.\n\nIl test statistico stabilisce la probabilità di osservare dati così (o più) estremi assumendo che \\(H_0\\) sia vera.\n\nVantaggio: stabilire un controllo sul rischio di un falso positivo (errore di I tipo).\n\nSvantaggio: non si dimostra direttamente l’ipotesi di ricerca (\\(H_1\\)), ma si prova a “falsificare” \\(H_0\\).\n\n\nIpotesi di Ricerca vs. Ipotesi Statistica\n\n\nL’ipotesi statistica è una versione quantificabile (e falsificabile) dell’ipotesi di ricerca.\n\nLe ipotesi di ricerca in psicologia sono spesso complesse (costrutti non sempre direttamente misurabili).\n\nI ricercatori formulano un modello statistico semplificato per rendere l’ipotesi testabile.\n\n\nSignificatività Statistica e Rilevanza Pratica\n\n\n“Significativo” in senso frequentista significa “dati improbabili se \\(H_0\\) è vera”.\n\nNon implica necessariamente un effetto ampio o di importanza pratica.\n\nCon campioni molto grandi, si possono rilevare anche differenze piccolissime, magari prive di valore applicativo.\n\n\nMalinteso: Un Risultato non Significativo Implica Che \\(H_0\\) Sia Vera?\n\n\nUn valore-\\(p\\) “alto” segnala che i dati non forniscono sufficiente evidenza per rifiutare \\(H_0\\), non che \\(H_0\\) è vera.\n\nPossibile mancanza di potenza statistica (campione troppo piccolo) o presenza di effetti molto ridotti.\n\nL’approccio frequentista non quantifica la probabilità che \\(H_0\\) sia vera, ma la probabilità di osservare certi dati assumendo che \\(H_0\\) lo sia.\n\n\nIl Ruolo della Variabilità Campionaria\n\n\nAnche se la media campionaria si discosta da \\(H_0\\), potremmo aver ottenuto quella differenza per puro caso.\n\nOccorre stabilire quanto discostamento sia “raro” secondo la distribuzione campionaria ipotizzata da \\(H_0\\).\n\nIl test calcola quante volte, nel lungo periodo, si osservano dati così estremi casualmente.\n\n\nErrori di I e II Tipo e Potenza del Test\n\n\nErrore di I tipo: rigettare \\(H_0\\) quando è vera.\n\nErrore di II tipo: non rigettare \\(H_0\\) quando è falsa.\n\nIl test frequenzista fissa una soglia \\(\\alpha\\) (livello di significatività) per controllare l’errore di I tipo.\n\nLa potenza quantifica la probabilità di individuare realmente un effetto quando esso esiste.\n\n\nIl Valore-\\(p\\): Che Cosa (non) Indica?\n\n\nIl valore-\\(p\\) è la probabilità di ottenere un risultato almeno così estremo se \\(H_0\\) è vera.\n\nMalinteso 1: pensare che indichi la probabilità che \\(H_0\\) sia vera o falsa.\n\nMalinteso 2: confondere “\\(p &lt; 0.05\\) =&gt; probabilità 95% che l’effetto sia vero” (non è così!).\n\n\nCritica: Dipendenza dai “Risultati più Estremi Non Osservati”\n\n\nIl valore-\\(p\\) frequenzista include la probabilità di osservare anche “risultati più estremi” non avvenuti nell’esperimento.\n\nSe l’esperimento era “fissare a priori 6 tazze” vs. “continuare finché non ottiene 5 successi”, può cambiare la distribuzione usata (binomiale vs. geometrica negativa).\n\nQuesto mostra che il valore-\\(p\\) dipende dal contesto sperimentale, non solo dai dati effettivi.\n\n\nControllo dell’Errore di I Tipo, ma Non dell’Errore di II Tipo\n\n\nSi vuole evitare di “condannare” un’ipotesi nulla “innocente”.\n\nL’errore di II tipo spesso viene trascurato e può essere molto alto se il campione è piccolo.\n\nConseguenze: molti studi hanno potenza insufficiente; i “falsi negativi” rimangono frequenti.\n\n\nLimiti dell’Approccio Frequentista e Alternative\n\n\nCritiche: inflazione di falsi positivi, dipendenza arbitraria da \\(\\alpha=0.05\\), scarsa attenzione alla dimensione dell’effetto, interpretazioni errate del p-value.\n\nAlternative:\n\n\nApproccio bayesiano (fattori di Bayes, posteriori, credibilità).\n\n\nConfidence intervals ampliati da riflessioni su potenza e dimensione dell’effetto.\n\n\nMisure dell’effetto e analisi approfondite invece di un giudizio binario su “p&lt;0.05”.\n\n\n\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nEsercizi “A Mano”\nQuesti esercizi si possono affrontare con le formule del test di ipotesi (z-test o t-test per la media, test di proporzioni, ecc.), senza ricorrere a software.\nEsercizio 1: One-sample t-test sulla SWLS\n\n\nHai un piccolo campione di \\(n=9\\) studenti, con punteggi SWLS (ipotetici) riportati di seguito:\n\\[\n21, \\ 18, \\ 26, \\ 20, \\ 23, \\ 16, \\ 22, \\ 19, \\ 25\n\\]\n\nSupponi che, in letteratura, la media teorica su popolazioni simili sia di circa \\(\\mu_0 = 20\\).\nIpotesi nulla \\((H_0)\\): la media del campione non differisce da 20 (cioè \\(\\mu = 20\\)).Ipotesi alternativa \\((H_1)\\): la media del campione differisce da 20 (two-sided test).\n\nRichiesta:\n\nCalcola la media campionaria \\(\\bar{X}\\) e la deviazione standard campionaria \\(s\\).\n\nEsegui un t-test a mano (con formula \\(t = \\frac{\\bar{X} - \\mu_0}{s/\\sqrt{n}}\\)).\n\nStabilisci se, con \\(\\alpha=0.05\\) (test a due code), si rifiuta o meno \\(H_0\\).\n\n\nSuggerimento: Usa la tabella della distribuzione t (o ricorri a tavole semplificate) per trovare il valore critico a \\(df = n-1 = 8\\). Solo per questo step, usa R.\n\nEsercizio 22: One-sample t-test sulla LSNS-6\n\n\nHai un campione di \\(n=8\\) persone anziane, con punteggi LSNS-6 (Scala della Rete Sociale di Lubben) ipotetici (in realtà userai i dati raccolti):\n\\[\n10,\\ 14,\\ 8,\\ 13,\\ 12,\\ 7,\\ 15,\\ 9\n\\]\n\nIn letteratura si suppone che un punteggio medio su popolazioni simili sia \\(\\mu_0 = 12\\).\nIpotesi nulla: \\(\\mu = 12\\).Ipotesi alternativa: \\(\\mu \\neq 12\\).\n\nRichiesta:\n\nCalcola media e deviazione standard.\n\nCalcola la statistica \\(t\\) e confrontala con il valore critico per \\(\\alpha=0.05\\), two-sided, con \\(df = 7\\).\n\nConcludi se rifiuti l’ipotesi nulla o meno.\n\n\n\nEsercizio 3: Due campioni indipendenti (SWLS)\n\n\nConsidera i dati raccolti dal tuo gruppo e quelli di un altro gruppo TPV (es., Gruppo A = 6 persone, Gruppo B = 5 persone) che hanno compilato la SWLS. Riporta per ipotesi i seguenti punteggi medi e DS (usa i dati reali):\n\nGruppo A: \\(\\bar{X}_A = 24,\\ s_A=4,\\ n_A=6\\)\n\nGruppo B: \\(\\bar{X}_B = 19,\\ s_B=3,\\ n_B=5\\)\n\n\n\nVuoi testare se le due medie differiscono in modo significativo (\\(\\alpha=0.05\\), due code).\nIpotesi nulla: \\(\\mu_A = \\mu_B\\).Ipotesi alternativa: \\(\\mu_A \\neq \\mu_B\\).\n\nRichiesta:\n\nCalcola la statistica \\(t\\) di un two-sample t-test (varianze incognite, assunte uguali).\n\nUsa la formula con la “varianza pooled”.\n\nCalcola i \\(df\\) approssimati come \\(n_A + n_B - 2\\).\n\nConcludi se rifiuti \\(H_0\\).\n\n\n\nEsercizio 4: Test su una proporzione (SWLS recodificata)\n\nA volte si trasforma la SWLS in una variabile binaria es. “\\(\\mathrm{SWLS} \\ge 24\\) = soddisfatto, \\(\\mathrm{SWLS}&lt;24\\) = non soddisfatto”.\nConsidera i dati raccolti e i corrispondenti risultati binari (Sì/No) siano 4 “soddisfatti” e 6 “non soddisfatti”.\nIpotesi nulla: la proporzione di “soddisfatti” è \\(p_0 = 0.50\\) (ipotizzi che metà dei partecipanti sia soddisfatta).Ipotesi alternativa: la proporzione \\(\\neq 0.50\\).\nCalcola la statistica \\(Z\\) per una proporzione (usando la formula della normal approx. se \\(\\hat{p}=4/10\\)).\nConfronta \\(|Z|\\) con il valore critico a \\(\\alpha=0.05\\) (due code), \\(z_{0.025}\\approx 1.96\\). Concludi.\n\nEsercizio 5: Confronto fra due proporzioni (LSNS-6 recodificata)\n\nConsiderai dati di due gruppi TPV (Gruppo A, Gruppo B).\n\nSupponi che, per Gruppo A (\\(n_A=8\\)), 3 persone abbiano un punteggio \\(\\ge 12\\) (considerato “buon supporto”). Per Gruppo B (\\(n_B=10\\)), 7 persone siano \\(\\ge 12\\) – usa i dati reali.\n\nIpotesi nulla: \\(\\,p_A = p_B\\).Ipotesi alternativa: \\(\\,p_A \\neq p_B\\).\n\nCalcola \\(\\hat{p}_A = 3/8\\) e \\(\\hat{p}_B = 7/10\\).\n\nFai il test per il confronto di due proporzioni (con la formula per la “pooled proportion”). Decidi se c’è differenza significativa al 5%.\n\nEsercizi “Con R”\nOra proponiamo 5 esercizi da svolgere con il software R. Naturalmente, dovrete caricare il vostro dataset reale (ad esempio in formato CSV o XLS) e adattare i comandi di R.\nEsercizio 1: Calcolo e t-test di una sola media per la SWLS\n\n\nCaricate in R i vostri dati SWLS in un vettore, es.:\nswls_data &lt;- c(...)  # I vostri punteggi\n\n\nStampate la media e la deviazione standard:\nmean(swls_data)\nsd(swls_data)\n\nTest se la media differisce da 24, usando t.test(swls_data, mu = 24).\nOsservate il p-value e concludete se rifiutate \\(H_0\\): \\(\\mu=24\\) vs \\(H_1\\): \\(\\mu \\neq 24\\).\n\nEsercizio 2: Calcolo e t-test di una sola media per la LSNS-6\n\n\nFate lo stesso per la LSNS:\nlsns_data &lt;- c(...)  # I vostri punteggi\n\nCalcolate mean(lsns_data), sd(lsns_data).\nEseguite un test con t.test(lsns_data, mu = X) dove \\(X\\) è un valore teorico (ad es. 12 o 10, a seconda delle informazioni di letteratura).\nInterpretate l’output, guardando estimate, conf.int, p-value.\n\nEsercizio 3: Confronto di due medie (SWLS) con due gruppi\n\n\nConsiderate i dati di due gruppi TPV. Avete due vettori in R:\ngroupA &lt;- c(...)  # SWLS di chi appartiene al gruppo A\ngroupB &lt;- c(...)  # SWLS di chi appartiene al gruppo B\n\nCalcolate mean(groupA), mean(groupB).\n\nEseguite:\nt.test(groupA, groupB, var.equal = FALSE)  # Welch Two Sample t-test\n\nConfrontate la differenza delle medie riportata con l’intervallo di confidenza. Il p-value indica se la differenza è significativa (ipotesi nulla: medie uguali).\n\nEsercizio 4: Test su una proporzione (ricodifica SWLS)\n\n\nRicodificate i vostri punteggi SWLS in “1 = soddisfatto” / “0 = non soddisfatto”. Ad esempio:\nsatisfied &lt;- ifelse(swls_data &gt;= 24, 1, 0)\n\n\nContate la proporzione di “1”:\nmean(satisfied)\n\nEffettuate il test con prop.test(sum(satisfied), length(satisfied), p = 0.5) (se ipotizzate \\(p_0=0.5\\)).\nGuardate l’output e interpretate: l’intervallo di confidenza e il p-value.\n\nEsercizio 5: Confronto di due proporzioni (ricodifica LSNS)\n\n\nFate una ricodifica binaria sul vostro vettore LSNS, ad esempio “1 se \\(\\ge12\\), 0 se &lt;12”:\ngood_support &lt;- ifelse(lsns_data &gt;= 12, 1, 0)\n\n\nSeparate i partecipanti in due gruppi (ad esempio, un gruppo “A” e un gruppo “B”):\ngroupA_inds &lt;- (some condition)  # righe che corrispondono a Gruppo A\ngroupB_inds &lt;- (some other condition)\n\nCalcolate sum(good_support[groupA_inds]), length(groupA_inds) e idem per groupB.\nUsate prop.test(x = c(...), n = c(...)) per confrontare le due proporzioni.\nConcludete: se p-value &lt; 0.05, potete rifiutare \\(H_0\\) (le due proporzioni sono uguali).\n\n\n\n\n\n\n\n\n\n\nProblemi 3\n\n\n\n\n\nEsercizio 1 – P-value e Interpretazione Probabilistica\nSpiega perché il valore-\\(p\\) del test di ipotesi nulla (frequentista) non può essere interpretato come “probabilità che l’ipotesi nulla sia vera” e in che modo l’approccio bayesiano fornisce invece una “probabilità a posteriori” sull’ipotesi. Descrivi due possibili conseguenze pratiche di questa differenza di interpretazione.\nEsercizio 2 – Ruolo dei “Risultati più Estremi Non Osservati”\nNel test frequentista, il valore-\\(p\\) si basa anche sulla probabilità di risultati più estremi di quelli effettivamente osservati, ma che non si sono verificati. Perché questo è considerato un limite (o un paradosso) e in che modo un’analisi bayesiana eviterebbe (o ridurrebbe) questo problema?\nEsercizio 3 – Dipendenza dal Disegno Sperimentale e Optional Stopping\nNel test di ipotesi frequenzista, il valore-\\(p\\) può cambiare se il ricercatore modifica il piano di raccolta dati (ad es. fermare la raccolta quando si ottiene un certo risultato). Perché si parla di “problema dell’optional stopping”? Come gestisce invece l’approccio bayesiano la decisione di proseguire o fermare un esperimento sulla base dei dati via via raccolti?\nEsercizio 4 – Significatività Statistica vs. Dimensione dell’Effetto\nUno dei limiti dell’approccio frequentista è la confusione tra “significatività statistica” (p&lt;0.05) e “importanza/ampiezza dell’effetto”. Spiega in che modo l’approccio bayesiano può incorporare in modo più diretto la dimensione dell’effetto e l’incertezza a riguardo (tramite le “distribuzioni a posteriori” o “intervalli di credibilità”).\nEsercizio 5 – Problemi di Replicabilità: Come Confrontare Modelli?\nSi osserva spesso che i risultati frequentisti (p&lt;0.05) non si replicano bene in studi successivi. Descrivi come un’analisi bayesiana (con i “fattori di Bayes” o i “posterior odds”) possa dare un quadro più flessibile per confrontare ipotesi alternative, riducendo il rischio di eccessive conclusioni basate su un singolo p-value.\n\n\n\n\n\n\n\n\n\nSoluzioni 3\n\n\n\n\n\nSoluzione 1 – P-value e Probabilità dell’Ipotesi\n\n\nPunto chiave: Il valore-\\(p\\) è la probabilità di ottenere dati “uguali o più estremi” dando per vera l’ipotesi nulla. Invece, “probabilità che \\(H_0\\) sia vera” sarebbe un concetto diverso: è la probabilità dell’ipotesi data i dati osservati (interpretazione inversa).\n\n\nConseguenze pratiche:\n\nUn p-value “basso” non dice “quanto è probabile che \\(H_0\\) sia falsa”, ma solo che quei dati sarebbero rari sotto \\(H_0\\).\n\nI ricercatori spesso sovrastimano la “conferma” contro \\(H_0\\) o interpretano male un p&gt;0.05 come “ipotesi nulla vera”.\n\n\n\n\nApproccio bayesiano: Consente di calcolare una posterior probability di \\(H_0\\) (o di \\(H_1\\)) grazie alla regola di Bayes, purché si disponga di una prior e di un modello.\n\nSoluzione 2 – Risultati più Estremi Non Osservati\n\n\nProblema: Nel frequentismo, il valore-\\(p\\) integra la probabilità di dati che non si sono verificati (“what if scenario”). Ciò porta a dipendere da un insieme di risultati ipotetici e a potenziali paradossi (e.g. “Lady Tasting Tea”).\n\n\nLimite: Può capitare che stessi dati osservati, ma piani di raccolta diversi, generino p-value diversi.\n\n\nBayesian: Calcola la verosimiglianza solo sui dati effettivi e aggiorna la prior → “focus su ciò che è effettivamente avvenuto”. Non serve considerare a posteriori “risultati più estremi” che non si sono verificati, se non in misura minima (attraverso l’integrazione sulle possibili distribuzioni posteriori, ma con un meccanismo diverso dal p-value).\n\nSoluzione 3 – Optional Stopping e Disegno Sperimentale\n\n\nOptional Stopping: In un test frequentista, se continuiamo ad analizzare i dati e fermiamo la raccolta non appena otteniamo p&lt;0.05, si gonfia il rischio di errore di I tipo.\n\n\nLimite: Il p-value frequentista dipende dall’idea di un “protocollo fisso” a priori. Se si viola questo piano (aggiungendo dati finché non si ottiene “significatività”), il test non è più valido.\n\n\nBayesiano: L’approccio consente un monitoraggio sequenziale (monitoring) dei dati: si aggiorna la distribuzione a posteriori man mano che arrivano nuove osservazioni, e fermarsi quando la posterior probability (o il fattore di Bayes) supera (o non supera) una certa soglia. Questo non invalida formalmente l’inferenza perché si sta accumulando evidenza in modo coerente con Bayes.\n\nSoluzione 4 – Ampiezza dell’Effetto e Intervalli di Credibilità\n\n\nFrequenza: Un p-value significativo non dice quanto è grande l’effetto, solo che non si spiega “facilmente” con \\(H_0=0\\).\n\n\nLimite: Spesso si confonde “p&lt;0.05” con “effetto grande/impact significativo”: in realtà, la dimensione potrebbe essere piccola.\n\n\nBayesiano: Offre una distribuzione a posteriori sull’effetto (\\(\\theta\\)), da cui si può ricavare un intervallo di credibilità (dove, ad esempio, c’è il 95% di probabilità che \\(\\theta\\) si trovi in quell’intervallo). Consente di valutare se l’effetto è davvero grande o molto stretto attorno allo 0.\n\nSoluzione 5 – Replicabilità e Confronto di Ipotesi\n\n\nProblema di replicabilità: Molti studi con p&lt;0.05 non vengono replicati (forse per effetti piccoli, scarsa potenza, pubblicazione selettiva, etc.).\n\n\nLimite: Un singolo p-value non dà informazioni su “quanto credere a \\(H_1\\) rispetto a \\(H_0\\)” e non aiuta a cumulare evidenze in analisi meta-analitiche in modo flessibile.\n\n\nBayesiano: Utilizza fattori di Bayes (Bayes Factor) o “posterior odds”, confrontando due modelli (es. \\(H_0\\) vs \\(H_1\\)). Se i dati futuri confermano una delle ipotesi, la posterior si rafforza. È un sistema più graduale e cumulativo di aggiornamento della credenza, riducendo la tendenza a “collezionare p&lt;0.05”.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#informazioni-sullambiente-di-sviluppo",
    "title": "\n77  Significatività statistica\n",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.17.0      thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0\n#&gt;  [5] see_0.11.0       gridExtra_2.3    patchwork_1.3.0  bayesplot_1.12.0\n#&gt;  [9] psych_2.5.3      scales_1.4.0     markdown_2.0     knitr_1.50      \n#&gt; [13] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [17] purrr_1.0.4      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [21] ggplot2_3.5.2    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6       shape_1.4.6.1      xfun_0.52         \n#&gt;  [4] htmlwidgets_1.6.4  lattice_0.22-7     tzdb_0.5.0        \n#&gt;  [7] Rdpack_2.6.4       vctrs_0.6.5        tools_4.5.0       \n#&gt; [10] generics_0.1.4     parallel_4.5.0     pan_1.9           \n#&gt; [13] pacman_0.5.1       jomo_2.7-6         pkgconfig_2.0.3   \n#&gt; [16] Matrix_1.7-3       RColorBrewer_1.1-3 lifecycle_1.0.4   \n#&gt; [19] compiler_4.5.0     farver_2.1.2       mnormt_2.1.1      \n#&gt; [22] codetools_0.2-20   htmltools_0.5.8.1  glmnet_4.1-8      \n#&gt; [25] nloptr_2.2.1       pillar_1.10.2      MASS_7.3-65       \n#&gt; [28] reformulas_0.4.1   iterators_1.0.14   rpart_4.1.24      \n#&gt; [31] boot_1.3-31        mitml_0.4-5        foreach_1.5.2     \n#&gt; [34] nlme_3.1-168       tidyselect_1.2.1   digest_0.6.37     \n#&gt; [37] stringi_1.8.7      splines_4.5.0      rprojroot_2.0.4   \n#&gt; [40] fastmap_1.2.0      grid_4.5.0         cli_3.6.5         \n#&gt; [43] magrittr_2.0.3     survival_3.8-3     broom_1.0.8       \n#&gt; [46] withr_3.0.2        backports_1.5.0    timechange_0.3.0  \n#&gt; [49] rmarkdown_2.29     nnet_7.3-20        lme4_1.1-37       \n#&gt; [52] hms_1.1.3          evaluate_1.0.3     rbibutils_2.3     \n#&gt; [55] rlang_1.1.6        Rcpp_1.0.14        glue_1.8.0        \n#&gt; [58] minqa_1.2.8        rstudioapi_0.17.1  jsonlite_2.0.0    \n#&gt; [61] R6_2.6.1",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_test_ipotesi.html#bibliografia",
    "href": "chapters/frequentist_inference/04_test_ipotesi.html#bibliografia",
    "title": "\n77  Significatività statistica\n",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBenjamin, D. J., Berger, J. O., Johannesson, M., Nosek, B. A., Wagenmakers, E.-J., Berk, R., Bollen, K. A., Brembs, B., Brown, L., Camerer, C., et al. (2018). Redefine statistical significance. Nature Human Behaviour, 2(1), 6–10.\n\n\nDoorn, J. van, Matzke, D., & Wagenmakers, E.-J. (2020). An in-class demonstration of Bayesian inference. Psychology Learning & Teaching, 19(1), 36–45.\n\n\nEtz, A., Gronau, Q. F., Dablander, F., Edelsbrunner, P. A., & Baribault, B. (2018). How to become a Bayesian in eight easy steps: An annotated reading list. Psychonomic bulletin & review, 25(1), 219–234.\n\n\nMehr, S. A., Song, L. A., & Spelke, E. S. (2016). For 5-month-old infants, melodies are social. Psychological Science, 27(4), 486–501.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:\n\n\nWasserstein, R. L., & Lazar, N. A. (2016). The ASA’s statement on p-values: context, process, and purpose. The American Statistician, 70(2), 129–133.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html",
    "title": "\n78  Test t di Student per campioni indipendenti\n",
    "section": "",
    "text": "78.1 Introduzione\nQuesto capitolo è dedicato al test t di Student per campioni indipendenti, uno dei test statistici più utilizzati nella pratica frequentista. Il test t di Student è un metodo che permette di confrontare le medie di due gruppi diversi (o “campioni”) e determinare se la differenza osservata tra le medie sia statisticamente significativa o se possa essere attribuita a semplice casualità.\nIl test è particolarmente utile quando si ha accesso solo a piccoli campioni provenienti da popolazioni sconosciute, ma è importante comprendere bene i suoi principi fondamentali e limiti prima di applicarlo.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#applicazioni-del-test-t-di-student",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#applicazioni-del-test-t-di-student",
    "title": "\n78  Test t di Student per campioni indipendenti\n",
    "section": "\n78.2 Applicazioni del Test t di Student",
    "text": "78.2 Applicazioni del Test t di Student\nIl test t di Student per campioni indipendenti serve per rispondere alla domanda: “Le medie di due gruppi sono significativamente diverse?” Per esempio, potremmo voler sapere se ci sono differenze significative nel peso medio tra uomini e donne.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#assunzioni-principali",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#assunzioni-principali",
    "title": "\n78  Test t di Student per campioni indipendenti\n",
    "section": "\n78.3 Assunzioni Principali",
    "text": "78.3 Assunzioni Principali\nPrima di procedere con il test, è essenziale assicurarsi che siano valide le seguenti ipotesi:\n\n\nIndipendenza: Le osservazioni nei due campioni devono essere indipendenti.\n\nNormalità: I dati nei due campioni provengono da popolazioni distribuite normalmente.\n\nUguaglianza delle Varianze (Omoschedasticità): Le varianze delle due popolazioni da cui provengono i campioni sono uguali.\n\nSe queste condizioni non sono soddisfatte, potrebbe essere necessario considerare alternative come il test di Welch, che non richiede l’uguaglianza delle varianze.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#passaggi-del-test-t-di-student",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#passaggi-del-test-t-di-student",
    "title": "\n78  Test t di Student per campioni indipendenti\n",
    "section": "\n78.4 Passaggi del Test t di Student",
    "text": "78.4 Passaggi del Test t di Student\nEcco una panoramica dei passaggi chiave:\n\n\nCalcolare la Differenza tra le Medie: Si calcola la differenza tra le medie dei due campioni.\n\\[\n\\bar{x}_1 - \\bar{x}_2\n\\]\ndove \\(\\bar{x}_1\\) e \\(\\bar{x}_2\\) sono le medie dei due campioni.\n\n\nStimare la Deviazione Standard Combinata: Se assumiamo che le varianze siano uguali (omoschedasticità), possiamo usare una stima combinata della deviazione standard, chiamata deviazione standard pooled \\(s_p\\):\n\\[\ns_p = \\sqrt{\\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}}\n\\]\ndove \\(n_1\\) e \\(n_2\\) sono le dimensioni dei campioni, e \\(s_1^2\\) e \\(s_2^2\\) sono le varianze campionarie.\n\n\nCalcolare la Statistica t: La statistica t viene calcolata usando la formula seguente:\n\\[\nt = \\frac{(\\bar{x}_1 - \\bar{x}_2)}{s_p \\sqrt{\\left(\\frac{1}{n_1} + \\frac{1}{n_2}\\right)}}\n\\]\n\n\nDeterminare i Gradi di Libertà: I gradi di libertà (\\(df\\)) sono calcolati come:\n\\[\ndf = n_1 + n_2 - 2\n\\]\n\nCalcolare il Valore-p: Infine, si confronta la statistica t con la distribuzione t di Student per ottenere il valore-p. Questo valore indica la probabilità di osservare una differenza così estrema tra le medie dei campioni, dato che l’ipotesi nulla è vera.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#dimostrazione",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#dimostrazione",
    "title": "\n78  Test t di Student per campioni indipendenti\n",
    "section": "\n78.5 Dimostrazione",
    "text": "78.5 Dimostrazione\nPer dimostrare come calcolare la varianza della differenza tra due medie campionarie, consideriamo due campioni casuali indipendenti \\(X_1, X_2, \\dots, X_n\\) e \\(Y_1, Y_2, \\dots, Y_m\\), estratti dalla stessa popolazione con media \\(\\mu\\) e varianza \\(\\sigma^2\\). Definiamo \\(\\bar{X}\\) e \\(\\bar{Y}\\) come le medie campionarie di questi due campioni, rispettivamente.\nLe medie campionarie \\(\\bar{X}\\) e \\(\\bar{Y}\\) sono date da:\n\\[\n\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i ,\n\\] \\[\n\\bar{Y} = \\frac{1}{m} \\sum_{j=1}^m Y_j .\n\\]\nEntrambe le medie campionarie \\(\\bar{X}\\) e \\(\\bar{Y}\\) sono stimatori non distorti della media della popolazione \\(\\mu\\). Le loro varianze sono:\n\\[\n\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n} ,\n\\] \\[\n\\text{Var}(\\bar{Y}) = \\frac{\\sigma^2}{m} .\n\\]\nSiamo interessati a calcolare la varianza della differenza \\(\\bar{X} - \\bar{Y}\\). Utilizzando le proprietà della varianza per combinazioni lineari di variabili aleatorie indipendenti, otteniamo:\n\\[\n\\text{Var}(\\bar{X} - \\bar{Y}) = \\text{Var}(\\bar{X}) + \\text{Var}(\\bar{Y}) ,\n\\]\ndato che i termini incrociati si annullano per l’indipendenza di \\(\\bar{X}\\) e \\(\\bar{Y}\\). Sostituendo le varianze di \\(\\bar{X}\\) e \\(\\bar{Y}\\), abbiamo:\n\\[\n\\text{Var}(\\bar{X} - \\bar{Y}) = \\frac{\\sigma^2}{n} + \\frac{\\sigma^2}{m} ,\n\\] \\[\n\\text{Var}(\\bar{X} - \\bar{Y}) = \\sigma^2 \\left(\\frac{1}{n} + \\frac{1}{m}\\right) .\n\\]\nQuindi, la varianza della differenza tra le due medie campionarie è una combinazione delle varianze delle singole medie, ponderate in base alle dimensioni dei campioni corrispondenti.\nPer giungere alla formula del test \\(t\\) di Student per due campioni indipendenti, dobbiamo considerare l’incertezza aggiuntiva derivante dal fatto che non conosciamo \\(\\sigma\\). Il modo migliore per stimare \\(\\sigma\\) è utilizzare le due deviazioni standard dei campioni, ponderate per i rispettivi gradi di libertà, come indicato nella formula della deviazione standard pooled:\n\\[\ns_p = \\sqrt{\\frac{(n - 1)s^2_x + (m - 1)s^2_y}{n + m - 2}},\n\\]\ndove \\(s_x\\) e \\(s_y\\) sono le deviazioni standard dei due campioni, e \\(n\\) e \\(m\\) sono le numerosità dei due campioni.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#esempio-pratico",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#esempio-pratico",
    "title": "\n78  Test t di Student per campioni indipendenti\n",
    "section": "\n78.6 Esempio Pratico",
    "text": "78.6 Esempio Pratico\nSupponiamo di avere due campioni:\n\n\nDonne: Pesi = [38.9, 61.2, 73.3, 21.8, 63.4, 64.6, 48.4, 48.8, 48.5]\n\nUomini: Pesi = [67.8, 60, 63.4, 76, 89.4, 73.3, 67.3, 61.3, 62.4]\n\nCreiamo un DataFrame in R e calcoliamo la statistica t:\n\nwomen_weight &lt;- c(38.9, 61.2, 73.3, 21.8, 63.4, 64.6, 48.4, 48.8, 48.5)\nmen_weight &lt;- c(67.8, 60, 63.4, 76, 89.4, 73.3, 67.3, 61.3, 62.4)\n\nweight &lt;- c(women_weight, men_weight)\nis_female &lt;- rep(c(1, 0), each = 9)  # 1 = Femmina, 0 = Maschio\n\ndf &lt;- data.frame(is_female = is_female, weight = weight)\n\nPer calcolare manualmente la statistica t:\n\n# Estraiamo i pesi per ogni gruppo\nweight_f &lt;- df$weight[df$is_female == 1]\nweight_m &lt;- df$weight[df$is_female == 0]\n\n# Calcolo della deviazione standard pooled\ns_pool_num &lt;- ((length(weight_f) - 1) * var(weight_f)) + ((length(weight_m) - 1) * var(weight_m))\ns_pool_denom &lt;- length(weight_f) + length(weight_m) - 2\ns_pool &lt;- sqrt(s_pool_num / s_pool_denom)\n\n# Calcolo della statistica t\nt_num &lt;- mean(weight_f) - mean(weight_m)\nt_denom &lt;- s_pool * sqrt(1 / length(weight_f) + 1 / length(weight_m))\nT &lt;- t_num / t_denom\nT\n#&gt; [1] -2.784\n\n\n# Gradi di libertà\ndf_degrees &lt;- length(weight_f) + length(weight_m) - 2\ndf_degrees\n#&gt; [1] 16\n\n\n# Calcolo del valore-p\np_value &lt;- 2 * pt(abs(T), df = df_degrees, lower.tail = FALSE)\nprint(p_value)\n#&gt; [1] 0.01327\n\nIn alternativa, possiamo usare la funzione t.test di R:\n\nres &lt;- t.test(weight_f, weight_m, var.equal = TRUE)\nprint(res, digits = 7)\n#&gt; \n#&gt;  Two Sample t-test\n#&gt; \n#&gt; data:  weight_f and weight_m\n#&gt; t = -2.7842, df = 16, p-value = 0.01327\n#&gt; alternative hypothesis: true difference in means is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -29.748019  -4.029759\n#&gt; sample estimates:\n#&gt; mean of x mean of y \n#&gt;  52.10000  68.98889\n\n\n78.6.1 Interpretazione dei Risultati\nIl test t di Student ha generato un valore-p inferiore a 0.05, indicando che la differenza osservata tra i pesi medi delle donne e degli uomini è statisticamente significativa. Questo significa che, con un livello di confidenza del 95%, possiamo rifiutare l’ipotesi nulla secondo cui le medie dei due gruppi sono uguali.\nÈ importante ricordare che un basso valore-p suggerisce che la differenza osservata non è dovuta al caso. Tuttavia, ciò non prova automaticamente una relazione causale; piuttosto, apre la strada ad ulteriori indagini sulle cause della differenza.\n\n78.6.2 Riportare i Risultati\nQuando si riportano i risultati di un test t, è fondamentale adottare pratiche che favoriscano una comprensione approfondita e accurata dei dati. Di seguito viene presentato un confronto tra due versioni dei risultati: una da evitare, che si basa su un’interpretazione tradizionale della significatività statistica, e una versione migliorata che enfatizza l’intervallo di confidenza e l’ampiezza dell’effetto.\n\n78.6.2.1 Versione da Evitare\nLa seguente formulazione segue un approccio tradizionale incentrato sulla “significatività statistica,” che è oggi ritenuto inadeguato per una comunicazione efficace dei risultati:\n\nAbbiamo condotto un test t di Student per confrontare le medie dei due gruppi. I risultati mostrano una differenza significativa tra i pesi medi delle donne e degli uomini (t(16) = -2.78, p-value = 0.01). L’intervallo di confidenza al 95% per la differenza delle medie è [-29.75, -4.03]. L’ampiezza dell’effetto, misurata con Cohen’s d, è 1.31, indicando un effetto grande. La potenza statistica del test è stata stimata al 74.4%.\n\nIn questa versione, il focus è eccessivamente concentrato sul valore-p, che può portare a interpretazioni riduttive e distorte dei risultati.\n\n78.6.2.2 Versione Migliorata\nEcco invece una versione migliore che mantiene un approccio frequentista, ma sposta l’enfasi sull’intervallo di confidenza e sull’ampiezza dell’effetto, offrendo una descrizione più completa e informativa:\n\nÈ stato condotto un test t di Student per confrontare le medie dei due gruppi. La differenza tra i pesi medi delle donne e degli uomini è stata stimata in -16.89 kg (intervallo di confidenza al 95%: [-29.75, -4.03]), suggerendo che il peso medio degli uomini sia maggiore rispetto a quello delle donne nel campione analizzato. Questo intervallo indica che, con una fiducia del 95%, la differenza reale tra i pesi medi potrebbe variare tra circa -29.75 kg e -4.03 kg.\nL’ampiezza dell’effetto, misurata con Cohen’s d = 1.31, indica una differenza considerevole, equivalente a oltre una deviazione standard. Questo valore suggerisce che la differenza osservata non solo è statisticamente rilevante, ma anche sostanziale dal punto di vista pratico.\nInoltre, la potenza del test, considerando la dimensione dell’effetto osservata, è pari al 74.4%, suggerendo che il test ha una buona capacità di rilevare differenze di questa entità nel campione analizzato. Ciò significa che, se una differenza di tale magnitudine fosse presente nella popolazione, esisterebbe una probabilità superiore al 70% di rilevarla correttamente.\n\nQuesta modalità di reporting fornisce una descrizione più dettagliata ed esplicativa dei risultati, evitando interpretazioni basate esclusivamente sul valore-p e concentrandosi invece sulla grandezza e sull’incertezza della stima. Tale approccio consente una valutazione più equilibrata e informata dei dati, promuovendo una comprensione più approfondita delle implicazioni pratiche e scientifiche dei risultati ottenuti.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#riflessioni-conclusive",
    "title": "\n78  Test t di Student per campioni indipendenti\n",
    "section": "\n78.7 Riflessioni Conclusive",
    "text": "78.7 Riflessioni Conclusive\nIl test t di Student è uno strumento statistico ampiamente utilizzato per l’inferenza su una media o per confrontare le medie di due gruppi. È talmente importante che alcuni lo hanno definito il metodo statistico più importante nella scienza. Tuttavia, come osserva Andrew Gelman, questa affermazione non va accettata acriticamente. Benché il test t sia semplice ed efficace in molti contesti, presenta notevoli limitazioni che ne riducono l’affidabilità e l’applicabilità quando si affrontano problemi complessi o si desidera una comprensione più approfondita dei dati (Kruschke, 2013).\n\n78.7.1 Limiti del Test t di Student\nUno dei principali limiti del test t risiede nell’assunzione che i dati seguano una distribuzione normale (gaussiana). Questa assunzione è spesso violata in pratica, specialmente con campioni piccoli o quando i dati presentano asimmetrie o code pesanti. Inoltre, nel caso di campioni indipendenti, il test richiede l’omogeneità delle varianze, un’altra assunzione frequentemente infondata. Quando queste condizioni non sono soddisfatte, il test può fornire risultati distorti, necessitando di correzioni come quella di Welch per gestire differenze di varianza.\nUn ulteriore limite del test t è legato alla sua dipendenza dalla soglia di significatività \\(\\alpha\\), solitamente fissata a 0.05. Questa scelta è arbitraria e può influenzare criticamente le conclusioni. Il test valuta esclusivamente la compatibilità dei dati con l’ipotesi nulla (\\(H_0\\)) e fornisce solo un p-value, senza offrire informazioni dirette sulla plausibilità dell’ipotesi alternativa (\\(H_1\\)). Ciò significa che un p-value basso non garantisce che \\(H_1\\) sia vera o che i dati supportino tale ipotesi.\n\n78.7.2 L’Approccio Bayesiano: Una Soluzione Più Potente\nIn contrasto con il paradigma frequentista, l’approccio bayesiano offre un quadro statistico più flessibile e informativo. Attraverso il teorema di Bayes, è possibile calcolare direttamente la probabilità di un’ipotesi dato l’insieme dei dati osservati. Questo permette di quantificare la forza dell’evidenza a favore di un’ipotesi rispetto alle altre, superando le limitazioni intrinseche del test t.\n\n78.7.2.1 Vantaggi dell’Approccio Bayesiano\n\nNon richiede assunzioni rigide: A differenza del test t, che si basa su ipotesi restrittive come la normalità e l’omoschedasticità, l’inferenza bayesiana è in grado di gestire modelli più generali e robusti, adattandosi ai dati reali senza doverli forzare in strutture artificiali.\nIncorporazione delle informazioni pregresse: L’approccio bayesiano permette di integrare conoscenze pregresse attraverso distribuzioni a priori, migliorando la qualità delle stime e consentendo analisi più realistiche. Questo è particolarmente utile in situazioni dove i dati disponibili sono scarsi o rumorosi.\nInferenze più informative: Al posto di semplici decisioni binarie (“rifiuto” o “non rifiuto” di \\(H_0\\)), il bayesianismo fornisce distribuzioni a posteriori complete, che descrivono l’incertezza sui parametri di interesse. Questo consente inferenze più dettagliate e interpretabili.\nGestione della complessità: L’approccio bayesiano gestisce in modo naturale modelli complessi e gerarchici, rendendolo ideale per analisi avanzate. Ad esempio, Kruschke (2013) dimostra come tecniche bayesiane possano superare le limitazioni del test t anche in presenza di violazioni delle assunzioni classiche, producendo risultati più stabili e affidabili.\n\n78.7.2.2 Implementazione Pratica\nSebbene l’approccio bayesiano richieda una maggiore attenzione nella scelta delle distribuzioni a priori e nella specificazione del modello, l’avvento di software moderni come Stan, PyMC3 e JAGS ha reso l’implementazione di modelli bayesiani sempre più accessibile. Oggi, anche ricercatori con competenze statistiche moderate possono applicare metodi bayesiani per affrontare problemi complessi con maggiore precisione e coerenza.\n\n78.7.3 Conclusioni\nIl test t di Student rimane un valido strumento per analisi rapide e semplici, ma le sue limitazioni diventano evidenti quando si lavora con dati complessi o si cerca una comprensione più profonda delle relazioni sottostanti. L’approccio bayesiano rappresenta un’evoluzione concettuale e metodologica rispetto all’inferenza frequentista tradizionale, offrendo numerosi vantaggi: inferenze più ricche, integrazione di informazioni pregresse, gestione delle violazioni delle assunzioni e produzione di stime più robuste. Per questi motivi, il paradigma bayesiano è sempre più considerato come la scelta preferibile per chi desidera un’analisi statistica solida, flessibile e informativa.\nIn ultima analisi, mentre il test t resta un punto di partenza utile, l’adozione dell’approccio bayesiano permette di avanzare verso una comprensione più completa e accurata dei dati.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#informazioni-sullambiente-di-sviluppo",
    "title": "\n78  Test t di Student per campioni indipendenti\n",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.17.0      thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0\n#&gt;  [5] see_0.11.0       gridExtra_2.3    patchwork_1.3.0  bayesplot_1.12.0\n#&gt;  [9] psych_2.5.3      scales_1.4.0     markdown_2.0     knitr_1.50      \n#&gt; [13] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [17] purrr_1.0.4      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [21] ggplot2_3.5.2    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6       shape_1.4.6.1      xfun_0.52         \n#&gt;  [4] htmlwidgets_1.6.4  lattice_0.22-7     tzdb_0.5.0        \n#&gt;  [7] Rdpack_2.6.4       vctrs_0.6.5        tools_4.5.0       \n#&gt; [10] generics_0.1.4     parallel_4.5.0     pan_1.9           \n#&gt; [13] pacman_0.5.1       jomo_2.7-6         pkgconfig_2.0.3   \n#&gt; [16] Matrix_1.7-3       RColorBrewer_1.1-3 lifecycle_1.0.4   \n#&gt; [19] compiler_4.5.0     farver_2.1.2       mnormt_2.1.1      \n#&gt; [22] codetools_0.2-20   htmltools_0.5.8.1  glmnet_4.1-8      \n#&gt; [25] nloptr_2.2.1       pillar_1.10.2      MASS_7.3-65       \n#&gt; [28] reformulas_0.4.1   iterators_1.0.14   rpart_4.1.24      \n#&gt; [31] boot_1.3-31        mitml_0.4-5        foreach_1.5.2     \n#&gt; [34] nlme_3.1-168       tidyselect_1.2.1   digest_0.6.37     \n#&gt; [37] stringi_1.8.7      splines_4.5.0      rprojroot_2.0.4   \n#&gt; [40] fastmap_1.2.0      grid_4.5.0         cli_3.6.5         \n#&gt; [43] magrittr_2.0.3     survival_3.8-3     broom_1.0.8       \n#&gt; [46] withr_3.0.2        backports_1.5.0    timechange_0.3.0  \n#&gt; [49] rmarkdown_2.29     nnet_7.3-20        lme4_1.1-37       \n#&gt; [52] hms_1.1.3          evaluate_1.0.3     rbibutils_2.3     \n#&gt; [55] rlang_1.1.6        Rcpp_1.0.14        glue_1.8.0        \n#&gt; [58] minqa_1.2.8        rstudioapi_0.17.1  jsonlite_2.0.0    \n#&gt; [61] R6_2.6.1",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/05_two_ind_samples.html#bibliografia",
    "href": "chapters/frequentist_inference/05_two_ind_samples.html#bibliografia",
    "title": "\n78  Test t di Student per campioni indipendenti\n",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nKruschke, J. K. (2013). Bayesian estimation supersedes the t test. Journal of Experimental Psychology: General, 142(2), 573–603.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/introduction_replication_crisis.html",
    "href": "chapters/replication_crisis/introduction_replication_crisis.html",
    "title": "Introduzione",
    "section": "",
    "text": "Bibliografia\nLa psicologia, insieme ad altre discipline scientifiche, sta attraversando una Riforma Metodologica scaturita da una crisi profonda: l’incapacità di replicare risultati di ricerche precedentemente pubblicati. Questa crisi di replicazione, che mina la credibilità della scienza, ha portato a un ripensamento radicale delle pratiche di ricerca, degli standard metodologici e degli incentivi accademici (Korbmacher et al., 2023). Siti come Retraction Watch, che monitorano le ritrattazioni di studi scientifici, testimoniano l’entità del problema, evidenziando casi di frodi, manipolazioni statistiche e pratiche di ricerca opache.\nLe Cause della Crisi.\nTra le cause principali vi sono incentivi distorti (come la pressione a pubblicare rapidamente), l’utilizzo acritico di tecniche inferenziali frequentiste – che facilitano la proliferazione di falsi positivi – e la scarsa attenzione alla dimensione campionaria. Come dimostrato da Altmejd et al. (2019), alcuni elementi superficiali permettono di prevedere la replicabilità di uno studio:\nSorprendentemente, prevedere se uno studio sarà replicabile non richiede competenze avanzate. Camerer et al. (2018) ha mostrato che scienziati coinvolti in un “mercato delle scommesse” predicevano con precisione quali studi di scienze sociali si sarebbero replicati. Ancora più significativo è il lavoro di Hoogeveen et al. (2020): partecipanti senza formazione specifica, esposti a semplici descrizioni di studi psicologici, hanno identificato con successo ricerche a rischio di fallimento replicativo. Ciò suggerisce che molti studi presentano difetti metodologici evidenti, riconoscibili persino a un pubblico non esperto.\nLa Diffusione degli Errori nella Letteratura Scientifica.\nLa pubblicazione peer-reviewed non garantisce l’affidabilità di una ricerca. Yang et al. (2020) ha rilevato che studi non replicabili vengono citati con la stessa frequenza di quelli validi, alimentando un ciclo di errori. Questo paradosso – scienziati capaci di riconoscere studi fragili ma inclini a citarli – riflette una cultura accademica disfunzionale (Smaldino & McElreath, 2016), dove la quantità di pubblicazioni prevale sulla qualità e gli incentivi premiano scorciatoie metodologiche.\nEsempi Emblematici e la Crisi di Validità.\nLa crisi non riguarda solo la replicazione, ma anche la validità delle misure e delle teorie. Ricerche influenti, come quelle sul pre-cognition di Ritchie et al. (2012) o sugli effetti del priming inconscio di John Bargh, si sono rivelate basate su evidenze fragili (Schimmack, 2012). Anche concetti consolidati, come l’esaurimento dell’autocontrollo (ego depletion) legato ai livelli di glucosio, sono stati criticati per mancanza di supporto empirico (Vadillo et al., 2016). Persino opere di autori celebri, come Thinking: Fast and Slow di Daniel Kahneman, contengono affermazioni basate su risultati non replicabili (Schimmack, 2020).\nVerso una Soluzione: Oltre l’Inferenza Frequentista.\nQuesta sezione della dispensa si concentra su uno dei nodi metodologici alla base della crisi: i limiti dell’inferenza frequentista (Baker, 2016). Concetti come gli errori di tipo S (conclusioni errate sulla direzione di un effetto) e di tipo M (sovrastima dell’entità di un effetto), introdotti da Gelman & Carlin (2014), illuminano le insidie delle tecniche statistiche tradizionali. Per affrontare la crisi, è necessario adottare approcci alternativi: preregistrazione degli studi, utilizzo di metodi bayesiani, e una valutazione critica della credibilità cumulativa della letteratura (Schimmack, 2020).\nConclusioni.\nLa crisi della replicabilità non è solo un problema tecnico, ma il sintomo di un sistema scientifico da ripensare. Riviste accademiche, istituzioni e ricercatori devono promuovere integrità, trasparenza e una cultura che valorizzi la robustezza rispetto alla novità. Solo così la psicologia potrà riconquistare il ruolo di scienza empirica rigorosa, capace di produrre conoscenza affidabile.",
    "crumbs": [
      "Crisi",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/introduction_replication_crisis.html#bibliografia",
    "href": "chapters/replication_crisis/introduction_replication_crisis.html#bibliografia",
    "title": "Introduzione",
    "section": "",
    "text": "Altmejd, A., Dreber, A., Forsell, E., Huber, J., Imai, T., Johannesson, M., Kirchler, M., Nave, G., & Camerer, C. (2019). Predicting the replicability of social science lab experiments. PloS one, 14(12), e0225826.\n\n\nBaker, M. (2016). Reproducibility Crisis. Nature, 533(7604), 452–454.\n\n\nCamerer, C. F., Dreber, A., Holzmeister, F., Ho, T.-H., Huber, J., Johannesson, M., Kirchler, M., Nave, G., Nosek, B. A., Pfeiffer, T., et al. (2018). Evaluating the replicability of social science experiments in Nature and Science between 2010 and 2015. Nature human behaviour, 2(9), 637–644.\n\n\nGelman, A., & Carlin, J. (2014). Beyond Power Calculations: Assessing Type S (Sign) and Type M (Magnitude) Errors. Perspectives on Psychological Science, 9(6), 641–651.\n\n\nHoogeveen, S., Sarafoglou, A., & Wagenmakers, E.-J. (2020). Laypeople can predict which social-science studies will be replicated successfully. Advances in Methods and Practices in Psychological Science, 3(3), 267–285.\n\n\nKorbmacher, M., Azevedo, F., Pennington, C. R., Hartmann, H., Pownall, M., Schmidt, K., Elsherif, M., Breznau, N., Robertson, O., Kalandadze, T., et al. (2023). The replication crisis has led to positive structural, procedural, and community changes. Communications Psychology, 1(1), 3.\n\n\nRitchie, S. J., Wiseman, R., & French, C. C. (2012). Failing the future: Three unsuccessful attempts to replicate Bem’s ‘Retroactive Facilitation of Recall’Effect. PloS one, 7(3), e33423.\n\n\nSchimmack, U. (2012). The ironic effect of significant results on the credibility of multiple-study articles. Psychological methods, 17(4), 551–566.\n\n\nSchimmack, U. (2020). A meta-psychological perspective on the decade of replication failures in social psychology. Canadian Psychology/Psychologie Canadienne, 61(4), 364–376.\n\n\nSmaldino, P. E., & McElreath, R. (2016). The natural selection of bad science. Royal Society Open Science, 3(9), 160384.\n\n\nVadillo, M. A., Gold, N., & Osman, M. (2016). The bitter truth about sugar and willpower: The limited evidential value of the glucose model of ego depletion. Psychological Science, 27(9), 1207–1214.\n\n\nYang, Y., Youyou, W., & Uzzi, B. (2020). Estimating the deep replicability of scientific findings using human and artificial intelligence. Proceedings of the National Academy of Sciences, 117(20), 10762–10768.",
    "crumbs": [
      "Crisi",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html",
    "href": "chapters/replication_crisis/01_crisis.html",
    "title": "79  La crisi della replicazione",
    "section": "",
    "text": "79.1 Introduzione\nIl presente capitolo introduce la crisi di replicazione che affligge la ricerca psicologica, analizzandone le cause precipue e ponendo in rilievo il ruolo che l’approccio statistico frequentista ha avuto nel concorrere a tale problematica. Il contenuto di questo capitolo costituisce una sintesi rielaborata del testo A student’s guide to open science: Using the replication crisis to reform psychology (Pennington, 2023).",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#i-pilastri-della-scienza-psicologica-ideale",
    "href": "chapters/replication_crisis/01_crisis.html#i-pilastri-della-scienza-psicologica-ideale",
    "title": "79  La crisi della replicazione",
    "section": "\n79.2 I Pilastri della Scienza Psicologica Ideale",
    "text": "79.2 I Pilastri della Scienza Psicologica Ideale\nAffinché la psicologia sia riconosciuta come scienza rigorosa, deve aderire a principi fondamentali:\n\n79.2.1 A. Replicabilità e Riproducibilità\n\n\n\nDefinizione: Un effetto empirico è considerato valido solo se replicabile da ricercatori indipendenti, con metodologie analoghe e campioni adeguati.\n\n\nEsempio: Lo studio classico di Asch sul conformismo (1951) è stato replicato in contesti cross-culturali, rafforzandone la validità.\n\n79.2.2 B. Attributi Essenziali della Ricerca\n\nLa scienza ideale dovrebbe essere:\n\n\n\n\n\n\n\nPrincipio\nDescrizione\nImplicazioni per la Psicologia\n\n\n\nCredibile\nSottoposizione delle ipotesi a verifica rigorosa e peer review trasparente.\nEvitare p-hacking e HARKing (Hypothesizing After Results are Known).\n\n\nAffidabile\nRisultati accurati e privi di distorsioni (bias).\nUtilizzo di preregistrazione e open data.\n\n\nTrasparente\nDescrizione dettagliata di metodi, analisi e risultati.\nAdozione di registered reports e condivisione di materiali supplementari.\n\n\nAccessibile\nDemocratizzazione della conoscenza (es. open access).\nPiattaforme come PsyArXiv per preprint o OSF per la condivisione di protocolli.\n\n\nInclusiva\nPartecipazione equa di gruppi sottorappresentati (etnici, di genere, ecc.).\nStudi con campioni diversificati (es. non solo WEIRD: Western, Educated, Industrialized, Rich, Democratic).\n\n\nCollaborativa\nSuperamento della competizione accademica a favore di reti di ricerca.\nProgetti multi-lab (es. Many Labs in psicologia sociale).\n\n\nAutocorrettiva\nRevisione continua degli errori e ritrattazione di risultati non validi.\nDatabase come Retraction Watch e correzioni pubbliche negli articoli.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#la-disconnessione-tra-ideale-e-realtà",
    "href": "chapters/replication_crisis/01_crisis.html#la-disconnessione-tra-ideale-e-realtà",
    "title": "79  La crisi della replicazione",
    "section": "\n79.3 La Disconnessione tra Ideale e Realtà",
    "text": "79.3 La Disconnessione tra Ideale e Realtà\nPennington (2023) utilizza un esercizio retorico per criticare la prassi scientifica tradizionale:\n\nVisualizzate lo stereotipo dello scienziato: un uomo bianco, in un laboratorio con cartelli ‘DIVIETO DI ACCESSO’, che tratta i dati come proprietà privata. Questa immagine riflette una scienza chiusa, competitiva e non allineata ai valori di trasparenza e collaborazione.\n\n\n79.3.1 Problemi Emersi\n\n\nSegretezza: Ricercatori che occultano dati per paura di critiche o “furti” di idee.\n\n\nCrisi di replicazione: Il 50-70% degli studi psicologici non è replicabile (Collaboration, 2015).\n\n\nPressioni accademiche: Focus su pubblicazioni “rivoluzionarie” a scapito di solidità metodologica.\n\n79.3.2 Verso una Psicologia più Rigorosa\nPer affrontare le criticità emerse nella ricerca psicologica, sono state avanzate diverse proposte concrete. Una delle direzioni più promettenti è l’adozione diffusa delle pratiche di Open Science, che includono la preregistrazione degli studi (per evitare il p-hacking), la condivisione aperta dei dati (open data) e l’utilizzo di strumenti gratuiti e trasparenti, come il software JASP per le analisi statistiche. Questi approcci non solo aumentano l’affidabilità dei risultati, ma favoriscono anche una cultura di collaborazione anziché di segretezza.\nUn altro passo fondamentale riguarda la formazione dei ricercatori. Introdurre corsi obbligatori su etica della ricerca e metodi quantitativi avanzati potrebbe ridurre errori metodologici e comportamenti opportunistici, preparando una nuova generazione di psicologi a standard più rigorosi.\nInfine, è essenziale ripensare il sistema di valutazione accademica. Invece di premiare la mera quantità di pubblicazioni – che spesso spinge verso risultati “sensazionali” ma poco replicabili – sarebbe più produttivo incentivare la qualità, la trasparenza e l’impatto a lungo termine del lavoro scientifico.\nUn esempio concreto di questo cambiamento è il progetto ManyBabies, un’iniziativa internazionale che coinvolge decine di laboratori nello studio dello sviluppo infantile. Grazie alla collaborazione su larga scala e alla condivisione di protocolli standardizzati, ManyBabies ha dimostrato come sia possibile produrre risultati più solidi e generalizzabili, superando i limiti dei piccoli studi isolati. Questo caso illustra perfettamente i benefici di una psicologia più aperta, cooperativa e metodologicamente rigorosa.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#la-crisi-della-replicazione-in-psicologia",
    "href": "chapters/replication_crisis/01_crisis.html#la-crisi-della-replicazione-in-psicologia",
    "title": "79  La crisi della replicazione",
    "section": "\n79.4 La Crisi della Replicazione in Psicologia",
    "text": "79.4 La Crisi della Replicazione in Psicologia\nNegli ultimi decenni, la psicologia si è trovata al centro di una crisi che ha messo in discussione molte delle sue basi epistemologiche e metodologiche: la crisi della replicazione. Questo fenomeno indica l’incapacità di replicare con successo un’ampia parte degli studi pubblicati, con implicazioni rilevanti per la cultura accademica e il modo di concepire la ricerca scientifica (Parsons et al., 2022).\nPer fallimento della replicazione si intende il caso in cui uno studio, ripetuto da altri ricercatori seguendo le stesse procedure e utilizzando campioni simili, non riesce a ottenere risultati comparabili a quelli originali. Questo ha portato alla luce problemi sistemici legati alla metodologia di ricerca, all’interpretazione dei dati e alle dinamiche del sistema accademico. La crisi della replicazione ha dunque evidenziato la necessità di un cambiamento strutturale nella pratica scientifica, sottolineando l’urgenza di un approccio più trasparente, rigoroso e collaborativo.\nNelle sezioni seguenti vengono presentati gli eventi chiave di quella che possiamo chiamare la storia della crisi della replicazione.\n\n79.4.1 2005: “Perché la maggior parte dei risultati pubblicati è falsa” (Ioannidis)\nUn primo momento cruciale è stato l’articolo di “Why Most Published Research Findings Are False” (Ioannidis, 2005) che ha evidenziato come molti risultati scientifici fossero in realtà falsi positivi. Ioannidis attribuì questo fenomeno a campioni di piccole dimensioni, un’eccessiva enfasi sui valori-p per indicare significatività, flessibilità nei metodi di analisi e la competizione per produrre risultati “innovativi”. Questo articolo ha messo in luce problemi che trascendono la psicologia, ma che in seguito sarebbero emersi come centrali anche per questa disciplina.\n\n79.4.2 2011: Lo Studio di Daryl Bem, “Feeling the Future”\nUno degli eventi più controversi è stato lo studio di Daryl Bem “Feeling the Future” (Bem, 2011), che suggeriva l’esistenza della precognizione, ovvero la capacità di “sentire” eventi futuri. Attraverso nove esperimenti, Bem pubblicò risultati statisticamente significativi che sembravano sfidare le leggi della causalità.\nLo studio di Bem si inseriva nella tradizione degli esperimenti di “priming”, una tecnica ampiamente utilizzata in psicologia sociale dagli anni ’70. Gli esperimenti di priming tipicamente coinvolgevano studenti universitari, remunerati con modeste somme o crediti accademici. I partecipanti venivano esposti a determinati concetti per poi osservare come questi influenzassero il loro comportamento successivo. Un celebre esempio è lo studio di John Bargh del 1996, che dimostrò come l’esposizione a parole associate all’età avanzata inducesse i soggetti a camminare più lentamente (Bargh et al., 1996). Un altro studio del 2006 rivelò che il priming con concetti legati al denaro rendeva le persone meno propense ad aiutare gli altri. Questi studi sembravano dimostrare una straordinaria malleabilità della mente umana, suggerendo che il nostro comportamento potesse essere inconsciamente manipolato da sottili segnali ambientali (Leys, 2024). Tuttavia, lo studio di Bem introdusse un elemento nuovo in questo paradigma sperimentale.\nTra i vari esperimenti condotti da Bem, uno in particolare si distingueva. I soggetti venivano esposti a una parola con connotazione positiva o negativa e successivamente dovevano valutare rapidamente la piacevolezza di alcune immagini. Fin qui, nulla di insolito. La svolta radicale consisteva nel fatto che in metà delle prove, il priming avveniva dopo che i soggetti avevano già visto e valutato l’immagine (Bem, 2011).\nSorprendentemente, i risultati mostravano che il priming funzionava anche in queste condizioni: i partecipanti erano più veloci a giudicare piacevoli le immagini quando successivamente venivano esposti a una parola positiva. Questo effetto risultava statisticamente significativo, con un p-value di 0.01, sufficiente secondo gli standard correnti per rifiutare l’ipotesi nulla.\nBem interpretò questi risultati come prova della chiaroveggenza, una conclusione che suscitò notevoli controversie e ridicolizzò la psicologia. Gli altri otto esperimenti dello studio, tutti basati su classici paradigmi della psicologia sociale con l’ordine temporale invertito, mostrarono risultati altrettanto statisticamente significativi.\nQuesti risultati ponevano la comunità scientifica di fronte a un dilemma: accettare l’esistenza di fenomeni paranormali o mettere in discussione le pratiche statistiche e metodologiche consolidate nella disciplina. Bem stesso continua a sostenere la validità dei suoi risultati come prova dell’esistenza di capacità precognitive.\nSebbene pubblicato su una rivista prestigiosa, lo studio sollevò enormi dubbi metodologici. Le repliche successive non riuscirono a confermare i risultati di Bem, mostrando come pratiche discutibili, quali il p-hacking (modifiche al metodo di analisi per ottenere risultati significativi), potessero produrre falsi positivi apparentemente robusti.\n\n79.4.3 2011: Il Caso di Frode di Diederik Stapel\nNello stesso anno, Diederik Stapel, una figura di spicco della psicologia sociale, fu accusato di aver falsificato dati in decine di studi pubblicati. Tra i suoi esperimenti più famosi vi era quello secondo cui ambienti disordinati aumenterebbero il razzismo. Un altro studio suggeriva che mangiare carne rendeva le persone più antisociali. Tuttavia, si scoprì che per quegli studi, e molti altri, non aveva mai condotto gli esperimenti né raccolto i dati. Li aveva semplicemente inventati. A volte le frodi accadono. Stapel fu scoperto (alla fine), licenziato e decine dei suoi articoli furono ritirati. Questo scandalo scosse profondamente la comunità accademica e divenne un simbolo della crisi.\n\n79.4.4 2011: La Meta-ricerca e le Pratiche di Ricerca Discutibili (QRPs)\nLa meta-ricerca è un campo di studio che si concentra sul modo in cui viene condotta la ricerca scientifica. Comprende temi come i metodi, la trasparenza nella comunicazione, la riproducibilità, la valutazione e i sistemi di incentivi che regolano la scienza (Ioannidis et al., 2015). Questo ambito è emerso con urgenza dopo una serie di casi controversi e di frodi conclamate, come gli studi di Daryl Bem e Diederik Stapel, che hanno evidenziato falle nei processi di ricerca. I ricercatori hanno così iniziato ad analizzare pratiche note come Questionable Research Practices (QRPs, Pratiche di Ricerca Discutibili), che sfruttano aree grigie nelle norme scientifiche per raccogliere e analizzare i dati.\nSimmons et al. (2011) hanno dimostrato come la flessibilità nella raccolta, analisi e comunicazione dei dati permetta ai ricercatori di far apparire “significativo” praticamente qualsiasi risultato. Tra le pratiche discusse, spiccano:\n\n\nOptional stopping: Interrompere la raccolta dei dati non appena si raggiunge la significatività statistica, invece di seguire un piano prestabilito.\n\n\nP-hacking: Condurre molteplici test non pianificati, selezionando variabili o analisi solo quando producono un valore p inferiore a 0.05.\n\n\nHARKing (Hypothesizing After Results are Known): Modificare le ipotesi a posteriori per adattarle ai risultati ottenuti, presentandole come ipotesi iniziali.\n\nQueste pratiche non solo compromettono l’integrità scientifica, ma rendono estremamente facile produrre falsi positivi. Per dimostrarlo, Simmons e colleghi hanno condotto simulazioni al computer e due esperimenti, rivelando quanto fosse “troppo facile” raccogliere prove a sostegno di ipotesi false.\nLa portata di queste pratiche è sorprendente. Simmons et al. hanno scoperto che:\n\nUsare una sola QRP può quasi raddoppiare il tasso di falsi positivi, portandolo dal 5% al 10%.\n\nCombinare più QRPs può far salire questa percentuale oltre il 60%.\n\nPer sottolineare il problema, i ricercatori hanno dimostrato, in modo volutamente ironico, che ascoltare la canzone dei Beatles “When I’m Sixty-Four” potrebbe far apparire le persone più giovani di quanto fossero prima di ascoltarla. Questa dimostrazione satirica evidenziava che inseguire la significatività statistica senza un rigore metodologico può produrre risultati assurdi.\nJohn et al. (2012) hanno condotto un’indagine su larga scala, intervistando 2000 ricercatori per comprendere la diffusione delle QRPs. Con un approccio innovativo, hanno chiesto ai partecipanti non solo di riferire le proprie pratiche, ma anche quelle dei colleghi. I risultati sono stati sconvolgenti:\n\nOltre il 60% degli intervistati ha ammesso di non aver riportato tutte le variabili dipendenti misurate.\n\nPiù del 50% ha interrotto la raccolta dati non appena ottenuti risultati significativi (optional stopping).\n\nPiù del 40% ha selezionato e riportato solo esperimenti “riusciti”.\n\nSorprendentemente, i ricercatori tendevano a dichiarare che i colleghi adottavano queste pratiche più frequentemente di loro stessi. Molti giustificavano queste pratiche come “norme accademiche” del tempo.\nLa meta-ricerca ha giocato un ruolo cruciale nell’aprire gli occhi della comunità scientifica sui pericoli di queste decisioni apparentemente “banali”. In un contesto in cui le QRPs erano ampiamente accettate, la meta-ricerca ha evidenziato come queste pratiche possano seriamente danneggiare il progresso scientifico. Grazie al movimento dell’Open Science, si stanno introducendo norme che migliorano la credibilità della ricerca, spostando l’enfasi dalla produzione di risultati “significativi” alla conduzione di studi rigorosi e trasparenti.\n\n79.4.5 2012: La Crisi di Fiducia della Psicologia\nSiamo nel 2012, un anno segnato da una serie di eventi che spingono Harold Pashler ed Eric-Jan Wagenmakers a dichiarare che la psicologia sta affrontando una “crisi di fiducia”. In un numero speciale della rivista Perspectives on Psychological Science (PoPs), i due autori raccolgono una molteplicità di prospettive sulla nascente crisi della replicazione, cercando di individuarne le cause e le implicazioni.\nLe reazioni alla crisi sono variegate e, in alcuni casi, contrastanti. Alcuni studiosi sostengono che le affermazioni di una crisi siano premature (Stroebe e Strack, 2014) e che i problemi di replicazione non siano un fenomeno nuovo (Spellman, 2015). Altri, invece, sottolineano come incentivare e valorizzare gli studi di replicazione rappresenti un metodo efficace e diretto per migliorare la qualità della scienza psicologica (Koole e Lakens, 2012).\nIl numero speciale evidenzia anche iniziative in corso per affrontare il problema. Tra queste, l’Open Science Collaboration (OSC), un progetto di larga scala avviato nel 2012, si propone di verificare empiricamente se la psicologia sia effettivamente alle prese con una crisi della replicazione. L’obiettivo del progetto è ambizioso: replicare numerosi studi pubblicati per valutare la robustezza dei risultati originari. Sebbene i risultati di questa iniziativa non fossero ancora disponibili al momento della pubblicazione del numero speciale, il progetto rappresentava già una pietra miliare per la disciplina.\nNonostante le preoccupazioni, il numero speciale si chiude con una nota positiva, destinata a risuonare nella comunità scientifica. I casi di frode, le pratiche di ricerca discutibili (QRPs) e i fallimenti nei tentativi di replicazione, sebbene dannosi, hanno aperto la strada a una riflessione critica. Questo processo ha permesso alla psicologia di affrontare i propri limiti, correggere errori, superare i bias e costruire una letteratura più affidabile e trasparente.\nQuesto periodo storico segna un punto di svolta: la crisi di fiducia ha messo in discussione le fondamenta della disciplina, ma ha anche creato l’opportunità per un rinnovamento scientifico, stimolando pratiche più rigorose e una maggiore attenzione alla replicabilità e alla trasparenza.\n\n79.4.6 2014: Il Progetto “Many Labs”\nNel 2014 fu pubblicato il primo tentativo su larga scala di replicare risultati psicologici: il progetto “Many Labs”. Questo imponente sforzo collaborativo, guidato da Klein et al. (2014), testò la replicabilità di 13 risultati classici della psicologia, coinvolgendo 6344 partecipanti in 12 paesi. Gli studi selezionati rispettavano tre criteri principali: erano relativamente brevi, avevano un design semplice e potevano essere facilmente condotti online.\nTra i fenomeni esaminati figurava la fallacia del costo irrecuperabile (sunk cost fallacy), secondo cui le persone tendono a proseguire un’attività quando vi hanno già investito tempo, sforzi o denaro. Un esempio classico: se hai acquistato un biglietto per vedere la tua squadra di calcio preferita e, il giorno della partita, inizia a piovere a dirotto, sarai più propenso a partecipare perché hai già speso i soldi per il biglietto (Oppenheimer e Monin, 2009).\nAltri studi replicati includevano:\n\nL’influenza del framing dei guadagni e delle perdite sul rischio (Tversky e Kahneman, 1981).\n\nLe differenze di genere negli atteggiamenti impliciti verso la matematica e le arti (Nosek et al., 2002).\n\nI risultati sembravano promettenti: il 77% degli studi replicò con successo i risultati originali (10 su 13). Tuttavia, non tutti gli studi fornirono lo stesso livello di evidenza. Ad esempio:\n\nUno studio sull’efficacia del contatto sociale immaginato nel ridurre i pregiudizi (Husnu e Crisp, 2010) mostrò supporto limitato, con solo 4 campioni su 36 che evidenziarono un effetto significativo.\n\nDue studi di priming non furono replicati. Nel primo, i ricercatori non trovarono che l’esposizione alla bandiera americana aumentasse il conservatorismo (Carter et al., 2011). Nel secondo, il priming con concetti legati al denaro non portò a un incremento delle credenze o dei comportamenti capitalistici (Caruso et al., 2013).\n\nSebbene i risultati fossero accolti come una vittoria per la replicabilità, alcuni ricercatori sottolinearono limiti nel progetto Many Labs 1. Gli stessi autori riconobbero che molti degli studi selezionati erano già noti per essere altamente replicabili. Secondo alcuni critici, il principale contributo di questo progetto era dimostrare che almeno dieci effetti psicologici erano replicabili, ma non forniva una panoramica più ampia sulla replicabilità complessiva nella psicologia (Yarkoni, 2013).\nQuesto progetto rappresentò comunque un passo fondamentale per affrontare la crisi della replicazione, sottolineando l’importanza della collaborazione scientifica e del rigore metodologico.\n\n79.4.7 2015: Il Progetto di Riproducibilità della Open Science Collaboration\nNel 2015, la Open Science Collaboration (OSC) pubblicò i risultati del Reproducibility Project: Psychology, dimostrando che la buona scienza richiede tempo e rigore. Superando i limiti del progetto Many Labs 1, un team composto da oltre 270 ricercatori internazionali si impegnò a replicare 100 studi scelti casualmente da riviste di punta nel campo della psicologia.\nPer garantire risultati solidi e inattaccabili, il team adottò una metodologia rigorosa:\n- Consultazione con gli autori originali: gli autori degli studi originali furono coinvolti per confermare il design sperimentale e ridurre al minimo eventuali discrepanze.\n- Aumento delle dimensioni campionarie: i campioni furono ampliati per garantire una potenza statistica sufficiente.\n- Registrazione preventiva dei metodi: i piani di analisi e raccolta dati furono registrati in anticipo per prevenire bias da parte dei ricercatori.\nGli studi selezionati per la replicazione includevano domande di ricerca come:\n\nLa convinzione che il comportamento umano sia predeterminato incoraggia il tradimento?\n\nI bambini seguono automaticamente lo sguardo per trovare oggetti nascosti?\n\nÈ possibile osservare un “effetto after-motion” da fotografie fisse che rappresentano movimento?\n\nI risultati del progetto fecero scalpore e conquistarono i titoli dei giornali a livello globale. Solo il 36% degli studi replicò con successo, ottenendo un valore-p inferiore a 0.05. La psicologia sociale si rivelò particolarmente problematica, con un tasso di replicazione del 25%, rispetto al 50% degli studi di psicologia cognitiva.\nPer contestualizzare questi numeri, se gli effetti originali fossero stati realmente validi, il tasso minimo di replicazione atteso sarebbe stato dell’89% (Field et al., 2019). Anche tra gli studi replicati, le dimensioni degli effetti risultarono dimezzate rispetto a quelle riportate negli studi originali.\nQuesti risultati provocarono una forte reazione nella comunità scientifica. Ci si chiedeva: era la fine della psicologia? La disciplina avrebbe mai recuperato credibilità? Sebbene i dati fossero allarmanti, aprirono un dibattito più ampio. Come sottolineato da Kuhn (1962) e Redish et al. (2018), fallimenti nella replicazione possono segnare l’inizio di una rivoluzione scientifica, stimolando un ripensamento dei metodi, delle ipotesi e delle pratiche di ricerca.\nIl Reproducibility Project: Psychology non solo mise in luce le fragilità della disciplina, ma divenne un punto di partenza per migliorare la trasparenza, la collaborazione e la robustezza nella ricerca psicologica.\n\n79.4.7.1 Studi Successivi\nQuesti risultati sono stati ulteriormente corroborati da numerosi studi successivi, tra cui una ricerca più recente basata su tecniche di machine learning, che ha esaminato studi di psicologia pubblicati in sei importanti riviste nell’arco di vent’anni. Questa ricerca suggerisce che poco più della metà di questi articoli di psicologia non supererebbe i test di replicazione (Youyou et al., 2023). Discipline come la psicologia sociale sono state oggetto di particolare preoccupazione, con un tasso di replicazione del solo 25% riportato dal Progetto di Riproducibilità (Collaboration, 2015). Questo dato è in linea con il lavoro di Youyou et al. (2023), che ha mostrato come la replicabilità degli articoli di psicologia vari considerevolmente per sottocampo, con la psicologia sociale che mostra un tasso di replicazione stimato del 37%, un risultato leggermente più incoraggiante rispetto a quanto riportato in precedenza, ma ancora tra i più bassi dei sottocampi esaminati. Altri settori come la psicologia dello sviluppo, cognitiva e clinica hanno mostrato tassi di replicazione stimati rispettivamente del 36%, 42% e 44%, mentre aree come la psicologia delle organizzazioni e della personalità hanno mostrato tassi leggermente più incoraggianti (50% e 55%, rispettivamente). Complessivamente, le evidenze suggeriscono che le preoccupazioni diffuse sulla robustezza e replicabilità dei risultati della ricerca psicologica siano fondate. Sebbene il problema non sia limitato esclusivamente alla psicologia, le questioni rilevate in questo campo hanno ricevuto notevole attenzione a causa dell’apparente portata del fenomeno.\nQuesti risultati confermavano in modo drammatico le previsioni formulate anni prima da John Ioannidis e Dennis Lindley. Le loro avvertenze riguardo alla possibilità che una larga parte, se non la maggioranza, dei risultati scientifici pubblicati potesse essere falsa, si rivelavano ora profetiche.\nIl Progetto di Riproducibilità di Nosek ha segnato un punto di svolta nel dibattito sulla crisi della replicazione in psicologia e, più in generale, nelle scienze sociali e biomediche. Ha evidenziato non solo la fragilità di molti risultati ritenuti consolidati, ma anche la necessità di un riesame critico delle pratiche di ricerca e pubblicazione scientifica. Questo ripensamento delle metodologie scientifiche è ancora in atto.\n\n79.4.8 2015: 1500 Scienziati Sollevano il Velo sulla Riproducibilità\nI risultati del progetto Collaboration (2015) colpirono il mondo della psicologia come un fulmine a ciel sereno. Molti risultati psicologici, considerati affidabili, crollarono improvvisamente, generando un’ondata di discussioni nei dipartimenti universitari: quale sarebbe stato il prossimo “effetto” a fallire? Tuttavia, nonostante la psicologia fosse diventata l’emblema delle repliche fallite, presto si comprese che non era un problema esclusivo della disciplina.\nNel 2016, Baker condusse un’indagine su 1500 scienziati provenienti da diverse discipline, tra cui chimica, medicina, fisica e ingegneria, per esplorare le preoccupazioni riguardo alla replicazione e alla riproducibilità (Baker, 2016). I risultati furono sorprendenti: circa il 90% dei partecipanti concordò sull’esistenza di una crisi di riproducibilità, definita come significativa dal 52% e lieve dal 38%.\nUn dato particolarmente allarmante emerse dall’indagine:\n\nIn media, il 40% degli scienziati aveva riscontrato difficoltà nel riprodurre i propri esperimenti.\n\nQuesta percentuale saliva a oltre il 60% quando si tentava di riprodurre gli esperimenti di altri ricercatori.\n\nTra le discipline, la chimica risultò la più problematica, con oltre l’85% dei ricercatori che riportavano fallimenti nel riprodurre i risultati altrui.\nL’articolo di Baker riportava anche esperienze personali che riflettevano il senso di smarrimento generato da questa crisi. Il professor Marcus Munafò, per esempio, descrisse così il suo percorso:\n\nHo cercato di replicare ciò che dalla letteratura sembrava semplice, ma non ci sono riuscito. Ho avuto una crisi di fiducia, e poi ho scoperto che questa esperienza non era affatto rara. (Baker, 2016)\n\nL’indagine di Baker non si limitò a evidenziare il problema, ma esplorò anche le possibili cause della crisi, come pratiche metodologiche inadeguate e pressioni accademiche, offrendo al contempo suggerimenti per interventi correttivi.\nL’indagine segnò un momento cruciale: la crisi della riproducibilità, inizialmente confinata a discussioni accademiche, raggiunse una visibilità globale. Non era più solo un problema della psicologia, ma un fenomeno che colpiva l’intero mondo scientifico, portando con sé la necessità di una trasformazione radicale delle pratiche di ricerca.\nQuesto evento contribuì a consolidare il riconoscimento della crisi della riproducibilità come una sfida centrale per tutta la scienza, spingendo verso un cambiamento culturale che mettesse al centro trasparenza, rigore e collaborazione.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#la-cultura-della-frode-nel-sistema-accademico",
    "href": "chapters/replication_crisis/01_crisis.html#la-cultura-della-frode-nel-sistema-accademico",
    "title": "79  La crisi della replicazione",
    "section": "\n79.5 La Cultura della Frode nel Sistema Accademico",
    "text": "79.5 La Cultura della Frode nel Sistema Accademico\nIn alcuni casi, la crisi della replicazione si intreccia con episodi di frode scientifica, rivelando un lato oscuro della ricerca accademica. Uno degli aspetti più preoccupanti è che il sistema accademico, con i suoi meccanismi di incentivo basati su pubblicazioni frequenti e finanziamenti competitivi, può indirettamente favorire comportamenti disonesti. Questo sistema, orientato al publish or perish (pubblica o scompari), crea pressioni che talvolta spingono i ricercatori a compromettere l’integrità scientifica per raggiungere i propri obiettivi di carriera.\n\n79.5.1 Il Caso Brian Wansink\nUn caso emblematico è quello di Brian Wansink, ex ricercatore di spicco alla Cornell University, che ricevette cospicui finanziamenti federali durante l’amministrazione Obama. I suoi studi sul comportamento alimentare, come quello sugli uomini che mangiano di più in presenza di donne o sull’effetto dei nomi “attraenti” dati alle verdure sul consumo da parte dei bambini, attirarono grande attenzione mediatica ma si rivelarono in seguito non replicabili. Le conseguenze per Wansink furono severe: diciotto suoi articoli furono ritirati, sette ricevettero “espressioni di preoccupazione”, e quindici furono corretti. Nel 2019, Wansink si dimise dalla Cornell University dopo essere stato giudicato colpevole di cattiva condotta scientifica.\n\n79.5.2 Il Caso Sylvain Lesné\nUn altro esempio rilevante riguarda Sylvain Lesné e i suoi coautori che, nel 2006, pubblicarono su Nature un importante articolo sul morbo di Alzheimer. Questo lavoro era fondamentale per lo sviluppo dell’ipotesi amiloide, un meccanismo proposto per spiegare come la malattia affligge le sue vittime. La ricerca sulla malattia di Alzheimer, che colpisce oltre 50 milioni di persone nel mondo, ha ricevuto oltre un miliardo di dollari in finanziamenti governativi fino al 2022, incoraggiata da studi come quello di Lesné.\nNel 2022, il neuroscienziato Matthew Schrag scoprì immagini manipolate in questo e in molti altri articoli di Lesné, inclusi quelli che sostenevano l’ipotesi amiloide. Le immagini erano state manualmente modificate e accorpate per mostrare falsamente supporto alle ipotesi degli articoli. Queste frodi passarono inosservate attraverso i processi di peer review formali di Nature e di altre sei riviste accademiche, venendo infine scoperte solo tramite canali non ufficiali.\nLe conseguenze di queste scoperte furono lente e frammentarie. Gli altri coautori dell’articolo del 2006 alla fine accettarono di ritirarlo, ma non Lesné stesso. La lentezza della risposta a queste evidenze di frode, e il fatto che Lesné continui a essere finanziato dal National Institutes of Health e impiegato presso l’Università del Minnesota, dimostra un fallimento sistemico nell’affrontare la cattiva condotta scientifica.\n\n79.5.3 Altri Casi di Rilievo\nNel mondo accademico, diversi altri recenti scandali hanno messo in luce il problema della frode scientifica e le sue conseguenze spesso limitate per i responsabili. Ecco alcuni casi emblematici:\n\nMarc Tessier-Lavigne, ex presidente della Stanford University: Nel 2023, fu costretto a dimettersi dopo la rivelazione di dati falsificati in sue ricerche precedenti presso Genentech. Nonostante lo scandalo, Tessier-Lavigne ha subito conseguenze minime, diventando successivamente CEO di una nuova azienda di ricerca farmacologica. Lo scandalo fu portato alla luce grazie all’indagine condotta da Theo Baker, uno studente diciassettenne di Stanford.\n\nDan Ariely e Francesca Gino: Questi due rinomati psicologi, noti per le loro ricerche sulla disonestà e il comportamento non etico, sono stati coinvolti in uno scandalo di frode scientifica.\n\nDan Ariely, nel 2021, fu implicato nella fabbricazione di dati in un articolo del 2012 sulla disonestà.\nFrancesca Gino, docente presso la Harvard Business School, è stata accusata di aver presentato lavori contenenti risultati falsificati. Il sito del Dipartimento ora riporta che è in “administrative leave”.\n\n\n\nL’inefficacia delle istituzioni accademiche nel gestire la frode scientifica sembra riflettere un problema culturale di carattere sistemico. Gli incentivi attuali favoriscono la pubblicazione di risultati positivi e innovativi, spesso a scapito dell’integrità scientifica. Gli studiosi che resistono a queste pressioni rischiano di essere emarginati, mentre chi adotta pratiche discutibili per ottenere risultati desiderati viene premiato con finanziamenti, promozioni e prestigio accademico.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#cosa-significa-fallimento-della-replicazione",
    "href": "chapters/replication_crisis/01_crisis.html#cosa-significa-fallimento-della-replicazione",
    "title": "79  La crisi della replicazione",
    "section": "\n79.6 Cosa Significa “Fallimento della Replicazione”?",
    "text": "79.6 Cosa Significa “Fallimento della Replicazione”?\nIl fallimento della replicazione non coincide necessariamente con l’idea che il fenomeno studiato sia inesistente. Al contrario, le cause di un esito negativo in un tentativo di replicazione possono essere molteplici e spesso difficili da individuare con precisione. Comprendere queste ragioni è fondamentale per identificare le criticità metodologiche, migliorare il rigore scientifico e favorire il progresso della conoscenza. Al di là dei casi evidenti di frode, i fallimenti della replicazione rappresentano un’opportunità per riflettere sulla qualità delle pratiche di ricerca.\n\n79.6.1 Possibili Cause di Fallimento nella Replicazione\n\nFalsi positivi nello studio originale\nUn fallimento può indicare che lo studio originale abbia rilevato un effetto inesistente per puro caso. Questo rischio è particolarmente elevato in studi con campioni di piccole dimensioni e bassa potenza statistica, dove gli effetti riportati risultano spesso sovrastimati o instabili.\n\nFalsi negativi nella replica\nIl fallimento può derivare da un falso negativo, ovvero la mancata rilevazione di un effetto realmente esistente. Le cause principali includono:\n\nDifferenze metodologiche o di popolazione tra studio originale e replica.\n\nConfondenti metodologici o una potenza statistica insufficiente.\n\nPresenza di variabili moderatrici che influenzano l’intensità dell’effetto in determinati contesti.\n\n\n\n79.6.2 La Scienza tra Incertezza e Riproducibilità\nLa scienza raramente offre certezze assolute. Come evidenziato dall’Open Science Collaboration, un singolo studio, sia esso originale o di replica, non è sufficiente a fornire una risposta definitiva. Solo replicazioni multiple e sistematiche possono distinguere effetti reali da errori casuali, offrendo una visione più affidabile di un fenomeno. Questo approccio richiede tempo e risorse, ma rappresenta il cuore del metodo scientifico.\n\n79.6.3 Psicologia e Altri Campi\nSebbene la crisi della replicazione sia stata ampiamente discussa in psicologia, problemi simili affliggono molte altre discipline scientifiche. Studi di replicazione hanno evidenziato risultati preoccupanti: in oncologia, meno della metà degli studi replicati ha prodotto risultati coerenti, con tassi di riproducibilità estremamente bassi in alcuni casi; nelle neuroscienze, i tentativi di replicare correlazioni cervello-comportamento hanno mostrato un altissimo tasso di insuccesso. Anche in discipline come l’economia e la filosofia sperimentale, pur registrando tassi di replicazione relativamente più elevati, permangono dubbi sulla selezione degli studi replicati e sulla rappresentatività dei risultati (Pennington, 2023).\nQuesti dati dimostrano che la problematica della replicazione non è esclusiva della psicologia, ma comune a diverse aree del sapere. Tuttavia, sollevano anche un interrogativo critico: è corretto parlare di “crisi” o si tratta piuttosto di una fase di trasformazione necessaria per migliorare il rigore e la trasparenza nella ricerca scientifica?",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#dibattito-sulla-natura-della-crisi",
    "href": "chapters/replication_crisis/01_crisis.html#dibattito-sulla-natura-della-crisi",
    "title": "79  La crisi della replicazione",
    "section": "\n79.7 Dibattito sulla Natura della Crisi",
    "text": "79.7 Dibattito sulla Natura della Crisi\nIl tema della crisi della replicazione ha suscitato un dibattito acceso e opinioni contrastanti all’interno della comunità scientifica:\n\nApproccio alle repliche: Alcuni ricercatori ritengono che le repliche esatte siano poco significative, preferendo le repliche concettuali che possano approfondire la comprensione di un fenomeno. Altri, invece, sostengono che solo repliche rigorose ed esatte siano in grado di verificare la robustezza di un effetto, garantendo maggiore affidabilità.\nInterpretazione dei dati dell’Open Science Collaboration (OSC): Il tasso di successo delle repliche riportato dall’OSC, pari al 36%, ha alimentato ulteriori discussioni. Alcuni attribuiscono questo risultato a differenze metodologiche tra studi originali e tentativi di replica, come campioni diversi o contesti modificati. Tuttavia, ricerche successive hanno smentito queste ipotesi, indicando che tali variazioni non spiegano interamente i bassi tassi di replicazione.\n\nInvece di considerare i fallimenti di replicazione come una crisi, molti studiosi li interpretano come un’opportunità per rafforzare la scienza. La replicazione, infatti, rappresenta un elemento fondamentale del metodo scientifico: permette di identificare i limiti di un fenomeno e di migliorare la comprensione delle condizioni in cui si manifesta. Ogni fallimento diventa, così, uno stimolo per il progresso.\nQuesta visione ha dato origine a un movimento noto come “rivoluzione della credibilità”, che punta a migliorare la qualità della ricerca attraverso trasparenza, autocorrezione e valorizzazione delle repliche. Progetti come il Loss of Confidence dimostrano che riconoscere i limiti e le incertezze degli studi precedenti non rappresenta una debolezza, ma un segno di integrità scientifica.\nIl passaggio dalla percezione di crisi a una rivoluzione della credibilità rappresenta un profondo cambiamento culturale nella comunità accademica. La scienza non è un processo statico, ma un percorso dinamico che evolve grazie al confronto critico e alla riflessione. In questa prospettiva, ogni fallimento nella replicazione non è un punto d’arrivo, ma un trampolino di lancio verso una conoscenza più affidabile e trasparente.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#cause-della-crisi",
    "href": "chapters/replication_crisis/01_crisis.html#cause-della-crisi",
    "title": "79  La crisi della replicazione",
    "section": "\n79.8 Cause della Crisi",
    "text": "79.8 Cause della Crisi\n\n79.8.1 Incentivi Accademici e la Dominanza della Quantità sulla Qualità\nPer comprendere a fondo le problematiche che affliggono il mondo della ricerca, è essenziale considerare il contesto lavorativo in cui operano i ricercatori. Sebbene spesso vengano idealizzati come figure obiettive e razionali, è fondamentale ricordare che sono anche esseri umani, soggetti a pressioni professionali, responsabilità economiche e ambizioni di carriera. Il loro lavoro è costantemente sottoposto a valutazione: oltre a gestire attività didattiche e amministrative, devono pubblicare articoli su riviste di prestigio e assicurarsi finanziamenti per sostenere i loro gruppi di ricerca. Questo sistema premia la quantità a discapito della qualità, favorendo una mentalità di “pubblica o perisci”.\nLa pressione a pubblicare incessantemente è una delle principali cause dei problemi che alimentano la crisi di replicazione nella scienza. La cultura del “publish or perish” spinge i ricercatori a produrre rapidamente risultati rilevanti, spesso a scapito della rigorosità metodologica e della riproducibilità (Gopalakrishna et al., 2022; Grimes et al., 2018).\nQuesta situazione genera un paradosso: ciò che favorisce la carriera individuale di uno scienziato non sempre coincide con gli interessi del progresso scientifico. Le motivazioni intrinseche di contribuire alla conoscenza vengono spesso offuscate da motivazioni estrinseche legate a indicatori di produttività accademica. Non sorprende, quindi, che oltre il 60% dei ricercatori individui questa pressione come una delle principali cause dei problemi legati alla replicazione e alla riproducibilità.\n\n79.8.2 Bias Cognitivi e Distorsioni nella Ricerca\nI bias cognitivi rappresentano un ulteriore ostacolo alla qualità della ricerca. Tra i principali si trovano:\n\n\nBias di conferma: la tendenza a cercare o interpretare informazioni che confermano le proprie ipotesi iniziali, trascurando dati contrari.\n\nApofenia: il riconoscimento di schemi in dati casuali, spesso combinato con una preferenza per risultati positivi.\n\nBias retrospettivo: la convinzione che un evento fosse prevedibile solo dopo che si è verificato, portando i ricercatori a presentare risultati in modo fuorviante.\n\nQuesti bias favoriscono la ricerca di risultati positivi a scapito di quelli nulli o contrari, contribuendo a creare un problema più grande: il bias di pubblicazione.\n\n79.8.3 Bias di Pubblicazione e il Problema dei “File Drawer”\nIl sistema di pubblicazione accademica incentiva risultati innovativi e positivi, spesso trascurando studi con risultati nulli o repliche. Questo bias, noto come file drawer problem, descrive la tendenza a relegare nei “cassetti” studi non statisticamente significativi, rendendoli inaccessibili e distorcendo la letteratura scientifica.\nIn psicologia, l’impatto di questo fenomeno è particolarmente grave. Studi hanno rilevato che oltre il 90% degli articoli in psicologia riporta risultati positivi, una percentuale notevolmente più alta rispetto ad altre discipline. Questo non solo crea una rappresentazione distorta della realtà, ma amplifica il rischio di undead theories, teorie prive di solide basi empiriche che continuano a dominare il dibattito scientifico.\n\n79.8.4 Pratiche di Ricerca Dubbiamente Etiche\nLa pressione a pubblicare ha portato all’emergere di comportamenti noti come Questionable Research Practices (QRPs). Tra questi:\n\n\nP-hacking: manipolazione dei dati o analisi fino a ottenere un p-value significativo (&lt; 0.05).\n\nHARKing (Hypothesizing After Results are Known): modificare l’ipotesi iniziale per adattarla ai risultati ottenuti.\n\nStopping opzionale: interrompere la raccolta dei dati quando si raggiunge un p-value desiderato.\n\nQueste pratiche, pur non essendo sempre considerate frodi, distorcono i risultati e compromettono la replicabilità degli studi, creando teorie difficili da falsificare.\n\n79.8.5 La Centralità dei Valori-p e la Crisi della Significatività Statistica\nIl valore-p, elemento centrale della metodologia scientifica basata sull’ipotesi nulla (Null Hypothesis Significance Testing), è diventato una “valuta” per la pubblicazione. Tuttavia, affidarsi esclusivamente ai valori-p presenta gravi limiti:\n\n\nParadosso di Lindley: con campioni di grandi dimensioni, valori-p vicini a 0.05 possono supportare l’ipotesi nulla invece di confutarla.\n\nDistorsioni da QRPs: l’utilizzo di pratiche discutibili può produrre falsi positivi statisticamente significativi.\n\nBenché alcuni studiosi abbiano proposto l’abbassamento della soglia di significatività statistica a 0.005 o l’integrazione dei valori-p con stime degli effetti e intervalli di confidenza, il punto centrale continua ad essere il fatto che l’enfasi dovrebbe spostarsi dai risultati statistici alla qualità metodologica degli studi.\nPer affrontare questi problemi, è necessario un cambiamento culturale e strutturale. La trasparenza, l’autocorrezione e l’adozione di pratiche come la preregistrazione degli studi possono aiutare a ridurre l’impatto dei bias e delle QRPs. Inoltre, incentivare repliche rigorose e promuovere un sistema di pubblicazione che premi la qualità rispetto alla quantità sono passi fondamentali per migliorare la credibilità della scienza.\n\n79.8.6 Campioni Troppo Piccoli\nUno dei fattori chiave che contribuiscono alla crisi della replicazione in psicologia è l’uso di campioni di dimensioni ridotte. Questo approccio ha permesso ai ricercatori di massimizzare la quantità di pubblicazioni a scapito della qualità e dell’affidabilità degli effetti rilevati. Higginson e Munafò (2016) sottolineano come questo fenomeno rappresenti una “selezione naturale della cattiva scienza”, dove incentivi strutturali premiano metodologie di ricerca poco rigorose.\nContrariamente a quanto si potrebbe pensare, ottenere un effetto significativo con un campione piccolo non garantisce che lo stesso effetto rimanga significativo con un campione più grande. Questo problema è strettamente legato alla potenza statistica, che rappresenta la probabilità, nel lungo periodo, di rifiutare correttamente l’ipotesi nulla quando l’ipotesi alternativa è vera. Una potenza statistica bassa comporta un’elevata probabilità di errori di Tipo II (falsi negativi) e, allo stesso tempo, riduce la probabilità che un risultato significativo rifletta un effetto reale.\nIn psicologia, la potenza statistica viene solitamente fissata a un minimo dell’80%, il che significa che, nel lungo termine, uno studio dovrebbe avere l’80% di possibilità di rilevare un effetto reale. Tuttavia, molti studi più datati raramente menzionano la potenza statistica, nonostante il concetto sia noto dagli anni ’30. Questo ha contribuito a generare una letteratura scientifica con effetti sovrastimati o poco affidabili.\nIn un approccio frequentista, per calcolare la potenza di uno studio, è necessario conoscere almeno due dei seguenti tre parametri: dimensione dell’effetto atteso, criterio di significatività e dimensione del campione pianificata. Per esempio, un ricercatore che si aspetta di trovare un effetto “medio” (Cohen’s d = 0.50) con un criterio di significatività di p &lt; .05 può determinare la dimensione del campione necessaria per garantire una potenza sufficiente. Tuttavia, molti studi psicologici hanno ignorato questo tipo di pianificazione, basandosi su campioni troppo piccoli per rilevare effetti affidabili.\nL’uso di campioni piccoli, combinato con pratiche discutibili di ricerca (Questionable Research Practices, QRPs) e bias di pubblicazione, ha portato a una letteratura scientifica piena di effetti inflazionati. Ad esempio, meta-analisi iniziali sul concetto di esaurimento dell’ego (ego depletion) stimavano un effetto medio (d = 0.62). Tuttavia, repliche successive hanno trovato effetti molto più piccoli, spesso inferiori a d = 0.10. Allo stesso modo, il progetto dell’Open Science Collaboration (2015) ha evidenziato che le dimensioni degli effetti nelle repliche erano, in media, dimezzate rispetto agli studi originali.\nCampioni di piccole dimensioni non solo riducono la probabilità di rilevare effetti reali, ma compromettono anche la credibilità dei risultati significativi. Una bassa potenza statistica mina l’obiettivo fondamentale della ricerca scientifica, limitando la capacità di trarre conclusioni solide e contribuendo alla crisi della replicazione. Per migliorare la qualità della scienza, è essenziale adottare pratiche di ricerca più rigorose, pianificando adeguatamente la dimensione del campione e garantendo una potenza statistica sufficiente.\n\n79.8.7 La Misurazione: Un Problema Sottovalutato\nOltre alle dimensioni campionarie inadeguate, la psicologia potrebbe soffrire di problemi legati alla misurazione. Per rispondere a domande scientifiche, i ricercatori devono definire e misurare con precisione il costrutto oggetto di indagine. Ad esempio, per investigare se una mentalità di crescita possa migliorare l’intelligenza, un ricercatore deve prima definire e poi misurare sia la mentalità che l’intelligenza. Tuttavia, la misurazione è un processo complesso e impegnativo.\nL’intelligenza è un costrutto latente, il che significa che, a differenza dell’altezza di una persona, non può essere osservata o misurata direttamente. Gli psicologi inferiscono l’intelligenza stimando il quoziente intellettivo (QI) di un individuo, basandosi sulle risposte a numerose domande di un test di intelligenza, adattate all’età del partecipante. Ma come possiamo sapere se il QI rappresenta un buon indicatore dell’intelligenza? È necessario valutare la validità di costrutto, definita come la capacità di una misura di comportarsi in modo coerente con le ipotesi teoriche (Cronbach e Meehl, 1955; Fink, 2010). Alcuni ricercatori hanno sostenuto che una spiegazione spesso trascurata della crisi della replicazione risieda nella scarsa validità di costrutto delle nostre misure (Lilienfeld e Strother, 2020; Loken e Gelman, 2017).\nPer evidenziare il problema della misurazione in psicologia, Flake e colleghi hanno condotto una revisione di articoli pubblicati in una rivista prestigiosa. La loro analisi ha mostrato che molte scale di misurazione utilizzate non avevano una chiara fonte dichiarata, mentre altre erano state sviluppate senza una documentazione adeguata. Inoltre, una parte significativa delle scale citate era stata modificata rispetto alla versione originale, rendendo sconosciute le loro proprietà psicometriche.\nGli autori hanno anche rilevato l’uso di Pratiche di Misurazione Discutibili (Questionable Measurement Practices, QMPs), che includono la mancata divulgazione di informazioni sulla validità delle misure quando questa non risulta soddisfacente. Questi problemi suggeriscono che molti costrutti psicologici non siano adeguatamente validati, un fattore che potrebbe contribuire alle difficoltà di replicazione degli studi.\nAltri ricercatori hanno argomentato che problemi di validità interna ed esterna possano contribuire alla crisi della replicazione (Fabrigar et al., 2020). La validità interna si riferisce a come uno studio stabilisce una relazione di causa-effetto tra le variabili indipendenti e dipendenti (Cook e Campbell, 1979). Fabrigar et al. suggeriscono che un tentativo di replicazione possa fallire se:\n\nLo studio originale ha sofferto di minacce alla validità che hanno causato un effetto spurio (alta validità interna nella replica).\nI ricercatori introducono elementi assenti nello studio originale (bassa validità interna nella replica).\n\nLa validità esterna riguarda la possibilità di generalizzare i risultati di uno studio ad altri contesti o popolazioni. Questo può influenzare le repliche se, ad esempio, la replica viene condotta su una popolazione diversa o se i materiali dello studio sono tradotti da un’altra lingua, causando incomprensioni nei partecipanti.\nPer sintetizzare questi problemi, Flake e Fried (2020) li definiscono “measurement schmeasurement”, espressione che descrive la mancanza di attenzione verso la validità delle misure nella scienza psicologica. Se le misure utilizzate in uno studio non sono valide, ne consegue che anche i risultati e le conclusioni tratte non possono essere considerati affidabili. Quando tali studi vengono replicati, potrebbero essere destinati al fallimento ancor prima di iniziare.\n\n79.8.8 La Novità a Scapito della Replicazione: Una Distorsione nella Ricerca\nL’enfasi eccessiva sui risultati innovativi e il valore attribuito alle scoperte significative stanno incentivando pratiche di ricerca distorte, favorendo la sovrarappresentazione di risultati positivi e una mancanza di rigore metodologico (Ferguson & Heene, 2012; Ware & Munafò, 2015).\nLa psicologia sperimentale, nata nel 1879 con il primo laboratorio fondato da Wilhelm Wundt, si trova oggi a fronteggiare una crisi di replicazione nonostante oltre un secolo di progresso scientifico. Una delle principali cause è la scarsa attenzione dedicata agli studi di replicazione, storicamente poco valorizzati e raramente premiati nelle scienze sociali.\nLa cultura accademica attuale privilegia la novità e i risultati positivi, relegando i risultati nulli e gli studi di replicazione a un ruolo marginale. Questo fenomeno riflette ciò che Antonakis (2017) definisce significosis – un’ossessione per i risultati significativi – e neofilia – un’eccessiva enfasi sulla novità. Già Sterling (1959) aveva messo in guardia contro il rischio che i ricercatori testassero ripetutamente un’ipotesi fino a ottenere, per puro caso, un risultato significativo, senza verificarlo attraverso replicazioni. In assenza di queste verifiche, interi ambiti di studio possono essere costruiti su un numero allarmante di affermazioni non supportate da dati solidi.\nQuesto squilibrio si riflette non solo nella letteratura scientifica, ma anche nei progetti di ricerca condotti dagli studenti. Le tesi di laurea in psicologia, spesso realizzate in autonomia, senza finanziamenti e con tempistiche ridotte, soffrono degli stessi problemi della ricerca accademica: campioni di piccole dimensioni, studi sottopotenziati e un’elevata probabilità di falsi positivi. Se pubblicati selettivamente, questi progetti rischiano di premiare la fortuna più della qualità scientifica.\nIniziative come il Collaborative Replications and Education Project (CREP) rappresentano un passo verso un cambiamento culturale. CREP incoraggia gli studenti a condurre studi di replicazione come parte del loro percorso formativo, promuovendo una scienza più collaborativa, rigorosa e orientata alla verifica dei risultati, contrastando così la prevalenza della novità fine a se stessa.\n\n79.8.9 La scienza non si autocorregge come dovrebbe\nUn principio cardine della scienza è l’autocorrezione, ma nella pratica accademica moderna, questo processo sembra spesso ostacolato da incentivi e preoccupazioni reputazionali. I ricercatori, pressati dalle scadenze per nuovi progetti o richieste di finanziamento, raramente dedicano il tempo necessario a rivedere e correggere i propri lavori passati. Questo mancato impegno rappresenta una delle spiegazioni della crisi di replicazione.\nUn esempio significativo è il Registered Replication Report dello studio di Srull e Wyer (1979), replicato da McCarthy et al. (2018). Lo studio originale aveva mostrato che il priming con stimoli aggressivi portava i partecipanti a interpretare un comportamento ambiguo come più ostile. Tuttavia, il tentativo di replicazione ha rilevato un effetto trascurabile. Una possibile spiegazione è che alcune statistiche dello studio originale fossero riportate in modo errato, un errore che, nonostante tutto, non è mai stato corretto. Similmente, altri casi documentano gravi discrepanze nei dati riportati in letteratura, come dimostrato da van der Zee et al. (2017) nel loro riesame di articoli del Cornell Food Lab, che ha rivelato oltre 150 incongruenze.\nLa microbiologa Elizabeth Bik ha inoltre evidenziato che la manipolazione di immagini scientifiche è diventata una forma emergente di cattiva condotta, volta a rendere i risultati più impressionanti o a mascherare dati problematici. Sebbene alcuni casi di manipolazione portino a ritrazioni o correzioni, il lavoro di revisione è spesso svolto da altri ricercatori come attività volontaria, suggerendo che la scienza sia più “eterocorrettiva” che autocorrettiva.\nNonostante le difficoltà, il processo di autocorrezione è fondamentale per il progresso scientifico. Vazire (2020) sostiene che il disagio provocato dalla revisione critica sia salutare e necessiti di una maggiore umiltà intellettuale da parte dei ricercatori. Questo include il riconoscimento pubblico delle limitazioni dei propri studi e, quando necessario, la pubblicazione di correzioni o dichiarazioni di perdita di fiducia nei risultati originali.\n\n79.8.10 La Scienza Chiusa come Ostacolo alla Replicazione\nUno degli ostacoli principali alla replicazione è la mancanza di trasparenza e dettaglio negli studi precedenti. In un sistema di “scienza chiusa,” in cui dati e metodi sono trattati come segreti industriali, ricreare esperimenti e verificare analisi diventa un’impresa ardua, se non impossibile. Questa opacità interessa molti aspetti della ricerca, dai materiali utilizzati ai dati raccolti, fino alle scelte analitiche effettuate durante lo studio.\nPratiche come la reportistica selettiva e la flessibilità non dichiarata nei metodi e nei dati compromettono l’integrità della scienza. La riluttanza a condividere dati e materiali, insieme al bias di pubblicazione che favorisce i risultati significativi rispetto a quelli nulli, amplifica ulteriormente il problema (Bruton et al., 2020; Nosek et al., 2012).\nUn esempio concreto riguarda le decisioni prese durante l’analisi dei dati, come la gestione dei valori anomali o le correzioni per analisi multiple. Queste scelte possono avere un impatto notevole sui risultati, ma se non vengono documentate in modo trasparente, altri ricercatori non saranno in grado di replicare gli stessi risultati. Questo problema è noto come il giardino dei sentieri che si biforcano (garden of forking paths), dove una serie di decisioni non esplicitate porta a risultati divergenti e difficili da verificare (Gelman & Loken, 2013).\n\n\n\n\n\n\nLo psicologo Paul Meehl condusse uno studio su un campione di cinquantasettamila studenti delle scuole superiori del Minnesota, indagando su variabili quali religione, abitudini nel tempo libero, ordine di nascita, numero di fratelli, piani post-diploma e numerosi altri aspetti (Meehl, 2012). Complessivamente, le diverse risposte dei partecipanti potevano essere combinate in 990 modi distinti, permettendo analisi del tipo: “Gli studenti appassionati di cucina hanno una maggiore probabilità di essere figli unici?” o “Gli studenti provenienti da famiglie battiste sono più inclini a partecipare a club politici scolastici?”. Meehl evidenziò che, analizzando i dati, il 92% di queste possibili combinazioni risultava in correlazioni statisticamente significative. Queste differenze, sebbene reali, presumibilmente derivano da cause multifattoriali e complesse.\nAndrew Gelman ha denominato questo fenomeno Il Giardino dei Sentieri che si Biforcano [Garden of Forking Paths; Gelman & Loken (2013)], riferendosi ai molteplici gradi di libertà a disposizione del ricercatore nell’analisi dei dati. Come nell’esempio di Meehl, è possibile esaminare le differenze intergruppo (se questo è l’oggetto di interesse) da molteplici prospettive. Con un campione sufficientemente ampio, alcune di queste differenze risulteranno “statisticamente significative”. Ciò indica che, in quello specifico campione, quel particolare aspetto dei dati è rilevante. Tuttavia, questa differenza “statisticamente significativa” non sarà necessariamente generalizzabile ad un altro campione, il quale presenterà le proprie idiosincrasie.\nIn altri termini, come sottolineato da Gelman & Loken (2013), l’approccio basato sul test dell’ipotesi nulla si limita a “descrivere il rumore”. Da un punto di vista teorico, simili esercizi statistici risultano privi di valore euristico e non contribuiscono in nessun modo all’avanzamento delle conoscenze sul fenomeno oggetto di studio.\nIn un’ottica di inferenza statistica, questo problema è riconducibile al concetto di “p-hacking” o “data dredging”, dove l’esplorazione esaustiva di molteplici ipotesi statistiche su un singolo set di dati può portare a falsi positivi e a una sovrastima della significatività statistica.\n\n\n\nLa soluzione è chiara: promuovere una cultura di apertura, rendendo dati e metodi accessibili. Nonostante i progressi tecnologici che facilitano la condivisione, questa pratica rimane poco diffusa. Sebbene esistano ragioni valide per non condividere i dati, come la tutela dell’anonimato dei partecipanti, tali motivazioni dovrebbero essere dichiarate in modo esplicito e rigoroso.\nQuesti ostacoli sottolineano l’urgenza di una trasformazione culturale all’interno della comunità scientifica, che favorisca trasparenza e collaborazione. Affrontare queste limitazioni strutturali è essenziale per superare la crisi di replicazione, permettendo alla scienza di avanzare in modo più affidabile e autoregolarsi nel tempo.\n\n79.8.11 La Probabilità Inversa\nOltre a questi fattori, alcuni studiosi sostengono che la radice della crisi della replicazione sia ancora più profonda e risieda nell’approccio statistico stesso, ampiamente adottato dalla comunità scientifica (Chivers, 2024; Gelman & Loken, 2014; Loken & Gelman, 2017). Questo punto di vista suggerisce che le difficoltà nella replicazione dei risultati non siano solo il prodotto di comportamenti individuali discutibili, ma derivino in larga parte da un’interpretazione e un’applicazione problematica dei metodi statistici.\nPer comprendere meglio questa questione, dobbiamo tornare alle basi della statistica inferenziale. L’approccio frequentista, dominante nella ricerca scientifica, si basa sulle probabilità di campionamento. Questo metodo, che risale a Jakob Bernoulli nel XVIII secolo, calcola la probabilità di osservare certi dati assumendo che una determinata ipotesi sia vera. Il famoso “p-value” è un esempio di questa logica: esso indica la probabilità di ottenere risultati estremi quanto o più estremi di quelli osservati, supponendo che l’ipotesi nulla sia vera.\nTuttavia, questo approccio ha un limite fondamentale: non ci dice direttamente quanto è probabile che la nostra ipotesi sia vera alla luce dei dati raccolti. In altre parole, non fornisce una “probabilità inferenziale”, cioè la probabilità che l’ipotesi sia corretta in base ai risultati ottenuti. Qui entra in gioco l’approccio bayesiano. Il teorema di Bayes offre un metodo per calcolare proprio questa probabilità inferenziale. L’approccio bayesiano tiene conto non solo dei dati osservati, ma anche delle conoscenze pregresse (le “prior”) relative all’ipotesi in esame.\nLa differenza tra questi due approcci è cruciale. Mentre il p-value ci dice quanto sono improbabili i nostri dati se l’ipotesi nulla è vera, l’approccio bayesiano ci fornisce la probabilità che la nostra ipotesi sia vera alla luce dei dati raccolti e delle conoscenze precedenti.\n\n79.8.12 Implicazioni per la Pratica Scientifica\nQuesta distinzione ha implicazioni profonde per la pratica scientifica. L’uso esclusivo dell’approccio frequentista può portare a sovrastimare la forza delle evidenze a favore di un’ipotesi, specialmente quando si lavora con campioni piccoli o si conducono molti test statistici, come spesso accade in psicologia.\nAlcune soluzioni proposte per affrontare la crisi della replicazione includono:\n\nAbbassare la soglia di significatività statistica, rendendo più difficile dichiarare un risultato “significativo”.\nRichiedere la preregistrazione delle ipotesi per prevenire l’HARKing (Hypothesizing After Results are Known).\nFar sì che le riviste accettino gli articoli basandosi sui metodi piuttosto che sui risultati, per evitare il bias verso la pubblicazione di risultati solo “positivi” o “nuovi”.\n\nTuttavia, queste soluzioni, pur utili, non affrontano il problema fondamentale dell’interpretazione delle evidenze statistiche. L’adozione di un approccio bayesiano offre una soluzione più radicale, fornendo un quadro più completo e realistico della forza delle evidenze a favore o contro un’ipotesi scientifica.\n\n79.8.12.1 Guardare i Dati\nConsideriamo una simulazione, ispirata da Lakens (2015), che illustra come una pratica apparentemente innocua – osservare i risultati man mano che vengono raccolti nell’approccio frequentista – possa avere conseguenze significative sulle conclusioni di uno studio. In particolare, questa pratica può influire sulla probabilità di ottenere un risultato statisticamente significativo.\nNella simulazione seguente, due campioni casuali vengono estratti dalla stessa popolazione normale di partenza. Di conseguenza, l’“ipotesi nulla” è vera: non c’è differenza tra le medie delle popolazioni. Tuttavia, a causa della variabilità campionaria, il p-valore risulta fortemente influenzato da ogni singola osservazione aggiunta al campione.\n\nsimulate_t_tests &lt;- function(seed, max_sample_size, mu = 0, sigma = 1) {\n  set.seed(seed)\n\n  # Intervallo di grandezza campionaria\n  sample_sizes &lt;- seq(2, max_sample_size, by = 2)\n  p_values &lt;- numeric(length(sample_sizes))\n\n  # Genera due campioni grandi iniziali da una distribuzione normale\n  full_sample1 &lt;- rnorm(max_sample_size, mean = mu, sd = sigma)\n  full_sample2 &lt;- rnorm(max_sample_size, mean = mu, sd = sigma)\n\n  # Simulazione\n  for (i in seq_along(sample_sizes)) {\n    n &lt;- sample_sizes[i]\n\n    # Estrai sottoinsiemi incrementali dai campioni completi\n    sample1 &lt;- full_sample1[1:n]\n    sample2 &lt;- full_sample2[1:n]\n\n    # Esegui il t-test per il confronto delle medie di due gruppi indipendenti\n    t_test &lt;- t.test(sample1, sample2, var.equal = TRUE)\n    p_values[i] &lt;- t_test$p.value\n  }\n\n  # Crea il grafico del p-valore in funzione della grandezza campionaria\n  plot(\n    sample_sizes, p_values, type = \"l\", col = \"#b97c7c\",\n    xlab = \"Grandezza Campionaria\", ylab = \"P-valore\",\n    main = \"P-valore in funzione della grandezza campionaria\"\n  )\n  abline(h = 0.05, col = \"#8f2727\", lty = 2, lwd = 1.5)\n  legend(\"topright\", legend = \"Significatività a 0.05\", col = \"#8f2727\", lty = 2, cex = 0.8)\n}\n\nNelle due simulazioni seguenti, osserviamo come il p-valore cambi progressivamente aumentando la dimensione dei campioni casuali da \\(n = 2\\) a \\(n = 300\\). È evidente come il p-valore vari drasticamente con l’aggiunta di nuove osservazioni ai campioni. Inoltre, in alcune configurazioni, il p-valore può scendere al di sotto della soglia critica di 0.05 per puro caso. Se un ricercatore interrompesse la raccolta dei dati in quel momento, otterrebbe un risultato “statisticamente significativo”, pur avendo campioni estratti dalla stessa popolazione.\n\nsimulate_t_tests(seed = 1234, max_sample_size = 300, mu = 0, sigma = 2)\nsimulate_t_tests(seed = 2, max_sample_size = 300, mu = 0, sigma = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuesta simulazione mette in evidenza una limitazione fondamentale dell’approccio frequentista: ogni test statistico considera esclusivamente i dati del campione corrente, ignorando le conoscenze accumulate in precedenza. Questo rende il processo decisionale estremamente volatile, poiché, teoricamente, ad ogni nuovo studio si “dimentica” tutta l’informazione derivante dagli studi precedenti.\n\n79.8.12.2 Analisi Bayesiana\nL’approccio bayesiano offre una soluzione elegante a questo problema. Nel framework bayesiano, la distribuzione a posteriori (cioè, la nostra convinzione aggiornata dopo aver osservato i dati) bilancia sempre l’informazione a priori (ciò che sapevamo prima dell’esperimento) con la verosimiglianza (ciò che i dati ci dicono). Questo equilibrio è particolarmente prezioso quando i dati sono deboli o contengono molto rumore, come nel caso dei dati della simulazione che stiamo discutendo. In tali situazioni, l’informazione a priori assume un ruolo più rilevante, impedendo conclusioni affrettate basate su dati poco informativi.\nPer illustrare questa differenza, consideriamo l’analisi bayesiana dei dati simulati in precedenza. Se questi dati vengono analizzati con l’approccio frequentista, forniscono un risultato “statisticamente significativo”, suggerendo una differenza tra i due gruppi.\nTuttavia, analizzando gli stessi dati con un approccio bayesiano, otteniamo un intervallo di credibilità al 95% compreso tra -0.52 e 1.12. Poiché questo intervallo include lo zero, possiamo affermare, con un livello di certezza soggettiva del 95%, che non c’è una differenza sostanziale tra le medie delle due popolazioni da cui sono stati estratti i campioni.\nQuesta discrepanza nei risultati evidenzia un punto cruciale: l’approccio bayesiano è più resistente ai falsi positivi in presenza di dati rumorosi o campioni piccoli. Invece di forzare una decisione binaria (significativo/non significativo) basata su una soglia arbitraria, l’analisi bayesiana fornisce una rappresentazione più sfumata e realistica dell’incertezza associata alle nostre conclusioni.\nInoltre, l’approccio bayesiano offre il vantaggio di essere cumulativo: ogni nuovo studio non parte da zero, ma incorpora naturalmente le conoscenze precedenti attraverso la distribuzione a priori.\n\n# Imposta il seme per la riproducibilità\nset.seed(12)\n\n# Parametri della distribuzione normale\nmu &lt;- 0\nsigma &lt;- 2\nmax_sample_size &lt;- 50\n\n# Genera due campioni indipendenti\nfull_sample1 &lt;- rnorm(max_sample_size, mean = mu, sd = sigma)\nfull_sample2 &lt;- rnorm(max_sample_size, mean = mu, sd = sigma)\n\n\n# Prepara i dati per Stan\nstan_data &lt;- list(\n  N1 = length(full_sample1),\n  N2 = length(full_sample2),\n  y1 = full_sample1,\n  y2 = full_sample2\n)\n\n# Visualizza i dati preparati\nprint(stan_data)\n#&gt; $N1\n#&gt; [1] 50\n#&gt; \n#&gt; $N2\n#&gt; [1] 50\n#&gt; \n#&gt; $y1\n#&gt;  [1] -2.9611  3.1543 -1.9135 -1.8400 -3.9953 -0.5446 -0.6307 -1.2565 -0.2129\n#&gt; [10]  0.8560 -1.5554 -2.5878 -1.5591  0.0239 -0.3048 -1.4069  2.3778  0.6810\n#&gt; [19]  1.0139 -0.5866  0.4473  4.0144  2.0240 -0.6049 -2.0505 -0.5348 -0.3982\n#&gt; [28]  0.2622  0.2916  0.7241  1.3480  4.1441 -1.0821 -2.1410 -0.7449 -0.9703\n#&gt; [37]  0.5496 -0.9590  1.5962 -2.0089  0.2100 -2.3120  1.1563 -3.1913 -0.6170\n#&gt; [46]  0.8989 -1.9541  0.3800  1.4629 -0.9852\n#&gt; \n#&gt; $y2\n#&gt;  [1] -0.085370 -0.225341  0.913654  4.040670 -2.101780  1.469304  1.078499\n#&gt;  [8] -2.628546 -0.500077  0.628409  0.813093  1.988841  1.711537  0.394258\n#&gt; [15]  1.668650  1.693580  3.908211 -4.298520  1.942241  2.290123 -1.050801\n#&gt; [22]  0.500640 -0.858813 -0.365039 -0.206621 -1.267676 -2.542108 -0.767901\n#&gt; [29]  1.033512 -0.355937  0.008516 -2.548119 -0.404221  2.328932 -0.046759\n#&gt; [36]  1.794313 -0.353449  2.227418 -1.083778 -1.926797  0.752897 -1.969348\n#&gt; [43]  1.795119  0.258525  2.067406 -0.684579  0.904563 -1.389476 -0.478027\n#&gt; [50] -2.014598\n\n\n# Path to the Stan file\nstan_file &lt;- here::here(\"stan\", \"two_means_diff.stan\")\n\n# Create a CmdStanModel object\nmod &lt;- cmdstan_model(stan_file)\nmod$code() # Stampa il codice del modello\n#&gt;  [1] \"data {\"                                                                \n#&gt;  [2] \"  int&lt;lower=0&gt; N1; // Numero di osservazioni nel gruppo 1\"             \n#&gt;  [3] \"  int&lt;lower=0&gt; N2; // Numero di osservazioni nel gruppo 2\"             \n#&gt;  [4] \"  vector[N1] y1; // Dati del gruppo 1\"                                 \n#&gt;  [5] \"  vector[N2] y2; // Dati del gruppo 2\"                                 \n#&gt;  [6] \"}\"                                                                     \n#&gt;  [7] \"parameters {\"                                                          \n#&gt;  [8] \"  real mu1; // Media del gruppo 1\"                                     \n#&gt;  [9] \"  real delta; // Differenza tra le medie\"                              \n#&gt; [10] \"  real&lt;lower=0&gt; sigma; // Deviazione standard comune\"                  \n#&gt; [11] \"  real&lt;lower=0&gt; nu; // Gradi di libertà per la distribuzione t\"        \n#&gt; [12] \"}\"                                                                     \n#&gt; [13] \"transformed parameters {\"                                              \n#&gt; [14] \"  real mu2; // Media del gruppo 2\"                                     \n#&gt; [15] \"  mu2 = mu1 + delta;\"                                                  \n#&gt; [16] \"}\"                                                                     \n#&gt; [17] \"model {\"                                                               \n#&gt; [18] \"  // Priori\"                                                           \n#&gt; [19] \"  mu1 ~ normal(0, 5);\"                                                 \n#&gt; [20] \"  delta ~ normal(0, 2); // Priore su delta\"                            \n#&gt; [21] \"  sigma ~ cauchy(0, 5);\"                                               \n#&gt; [22] \"  nu ~ gamma(2, 0.1); // Priore sulla t-student\"                       \n#&gt; [23] \"  \"                                                                    \n#&gt; [24] \"  // Verosimiglianza\"                                                  \n#&gt; [25] \"  y1 ~ student_t(nu, mu1, sigma);\"                                     \n#&gt; [26] \"  y2 ~ student_t(nu, mu2, sigma);\"                                     \n#&gt; [27] \"}\"                                                                     \n#&gt; [28] \"generated quantities {\"                                                \n#&gt; [29] \"  real diff; // Differenza tra le medie (alias di delta per chiarezza)\"\n#&gt; [30] \"  diff = delta;\"                                                       \n#&gt; [31] \"}\"\n\nEsegui il campionamento:\n\nfit &lt;- mod$sample(\n  data = stan_data,\n  seed = 123,\n  chains = 4,\n  iter_sampling = 2000,\n  iter_warmup = 1000,\n  show_messages = FALSE\n)\n\nRiassumi i risultati per mu1, mu2 e delta:\n\nfit_summary &lt;- fit$summary(variables = c(\"mu1\", \"mu2\", \"delta\"))\nprint(fit_summary)\n#&gt; # A tibble: 3 × 10\n#&gt;   variable   mean median    sd   mad      q5    q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 mu1      -0.313 -0.312 0.241 0.238 -0.707  0.0818  1.00    5378.    5491.\n#&gt; 2 mu2       0.164  0.166 0.246 0.248 -0.235  0.568   1.00    9428.    6234.\n#&gt; 3 delta     0.477  0.474 0.341 0.344 -0.0887 1.04    1.00    5155.    5260.\n\nEstrai i campioni di delta:\n\ndelta_samples &lt;- fit$draws(variables = \"delta\", format = \"matrix\")[, 1]\n\nDisegna la distribuzione a posteriori di delta:\n\ndelta_df &lt;- data.frame(delta = delta_samples)\n\nggplot(delta_df, aes(x = delta)) +\n  geom_histogram(aes(y = ..density..), bins = 30, fill = \"#b97c7c\", alpha = 0.75) +\n  geom_vline(\n    xintercept = mean(delta_samples),\n    linetype = \"dashed\",\n    linewidth = 1.2,\n    label = paste(\"Mean:\", round(mean(delta_samples), 2))\n  ) +\n  labs(\n    x = \"delta\",\n    y = \"Density\",\n    title = \"Posterior distribution of delta\"\n  ) \n\n\n\n\n\n\n\nPuoi calcolare l’intervallo di credibilità usando per un intervallo al 95%:\n\nquantile(delta_samples, probs = c(0.025, 0.975))\n#&gt;    2.5%   97.5% \n#&gt; -0.1872  1.1553\n\n\n79.8.12.3 Garbage In, Garbage Out\nLa natura della statistica frequentista impone di prendere una decisione dicotomica: o si rifiuta l’ipotesi nulla o non la si rifiuta. Ciò implica che o esiste un effetto reale, oppure non esiste. Con un campione abbastanza grande, è inevitabile trovare qualche effetto, anche se di minima entità.\nUn approccio bayesiano, invece, permette di stimare la dimensione dell’effetto e di fornire una distribuzione di probabilità. Una distribuzione di probabilità è una rappresentazione grafica delle diverse possibilità che potrebbero verificarsi. In questo contesto, si tratta della “probabilità inversa”, ovvero della plausibilità dell’ipotesi alla luce dei dati osservati e delle conoscenze pregresse. Qui, il parametro \\(\\delta\\) rappresenta la differenza tra le due medie ed è il parametro di interesse. Le credenze precedenti su \\(\\delta\\) sono espresse tramite una distribuzione a priori: in questo caso, una distribuzione Normale centrata su 0 con una deviazione standard di 2. La distribuzione a posteriori rappresenta la nostra conoscenza aggiornata su \\(\\delta\\) dopo l’aggiornamento bayesiano. Il parametro \\(\\delta\\) è la nostra ipotesi sulla differenza tra le due medie, e l’inferenza bayesiana riguarda il cambiamento della nostra credenza dopo aver osservato i dati.\nL’approccio frequentista, al contrario, produce una decisione dicotomica che non modifica la nostra concezione dell’ipotesi dopo aver osservato i dati. Assume una determinata ipotesi come vera e verifica se i dati sono coerenti con essa. Tramite il concetto binario di “significatività statistica”, non si modificano le ipotesi di interesse, ma si accettano o si rifiutano le ipotesi nulle.\nSebbene l’approccio frequentista sia spesso considerato “ingenuo” da molti ricercatori, adottare l’approccio bayesiano non rappresenta una soluzione miracolosa ai problemi della scienza contemporanea. Risolve alcuni problemi, ma non altri. In particolare, non affronta la questione degli incentivi accademici che favoriscono la pubblicazione di un elevato numero di articoli, indipendentemente dalla loro qualità. Un principio fondamentale della ricerca è “Garbage in, garbage out”. Se i dati derivano da un disegno di ricerca fallace o poco creativo, se la ricerca non ha un solido fondamento teorico capace di avanzare le nostre conoscenze, o se la qualità delle misurazioni è insufficiente, i dati raccolti sono puro rumore. Nessun metodo statistico, nemmeno quello bayesiano, può trasformare la spazzatura in oro.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#esercizi",
    "href": "chapters/replication_crisis/01_crisis.html#esercizi",
    "title": "79  La crisi della replicazione",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nEsistono numerosi esempi di ricerche che non riescono a essere replicate (posso citare anche uno studio di replicazione che ho condotto io stesso: Caudek et al. (2017)). Un recente caso emblematico è rappresentato dallo studio di Karataş & Cutright (2023) e dal successivo tentativo di replicazione condotto da Moore et al. (2024). Analizzando le quattro principali argomentazioni sollevate da Gelman & Brown (2024) per criticare lo studio di Aungle & Langer (2023), si offra un’interpretazione del perché lo studio di Karataş & Cutright (2023) non sia stato replicato con successo.\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\n1) Sulla “Crisi della Replicazione” in Psicologia\nChe cosa si intende quando si parla di “crisi della replicazione” in psicologia?\n\n\nA. La difficoltà di molti laboratori nel reperire fondi per la ricerca.\n\n\nB. L’incapacità o la grave difficoltà di replicare, con risultati simili, una parte consistente degli studi pubblicati.\n\n\nC. La tendenza di alcuni scienziati a pubblicare risultati simili ad altri per sfruttare la loro notorietà.\n\n\nD. Lo scarso interesse degli editori di riviste nel pubblicare studi teorici.\n\n\nE. La mancanza di strumenti statistici adeguati per l’analisi dei dati qualitativi.\n\n2) Cosa significa “fallimento della replicazione”?\nQuale delle seguenti opzioni descrive correttamente il “fallimento della replicazione”?\n\n\nA. Non riuscire a pubblicare uno studio su una rivista ad alto impatto.\n\n\nB. Non riuscire a confermare la robustezza metodologica dello studio originale in sede di peer-review.\n\n\nC. Riportare risultati che confermano un’ipotesi già discussa in letteratura.\n\n\nD. Non ottenere, con procedure simili e campioni simili, risultati paragonabili a quelli dello studio originale.\n\n\nE. Non riuscire a reclutare un numero sufficiente di partecipanti in una nuova ricerca.\n\n3) Quale studio scatenò polemiche sulla precognizione?\nNel 2011, un autore pubblicò uno studio che sembrava dimostrare capacità “paranormali” nei partecipanti, scatenando polemiche e dubbi. Chi fu?\n\n\nA. Diederik Stapel, che usò dati inventati.\n\n\nB. John Ioannidis, autore di “Why Most Published Research Findings Are False”.\n\n\nC. Daryl Bem, con l’articolo “Feeling the Future” sulle facoltà precognitive.\n\n\nD. Brian Wansink, con studi su etichette “attraenti” delle verdure.\n\n\nE. Daniel Kahneman, con esperimenti sui bias cognitivi e di giudizio.\n\n4) Cosa si intende per “p-hacking”?\nLa pratica denominata p-hacking (nell’ambito della crisi di replicazione) consiste nel:\n\n\nA. Interrompere la raccolta dati nel momento in cui si ottiene un risultato in linea con l’ipotesi.\n\n\nB. Manipolare, in maniera fraudolenta, immagini o grafici.\n\n\nC. Tradurre erroneamente i questionari in più lingue, alterando i risultati.\n\n\nD. Utilizzare molteplici analisi e combinazioni di variabili fino a ottenere un valore-(p) inferiore a 0.05.\n\n\nE. Avere più autori su uno stesso manoscritto per dividerne la responsabilità.\n\n5) Qual è il tasso di replicazione emerso dal “Reproducibility Project: Psychology” (2015)?\nSecondo i dati dell’Open Science Collaboration (2015), approssimativamente quanti studi di psicologia replicarono con successo (ottenendo risultati “significativi” simili agli originali)?\n\n\nA. Circa il 36%.\n\n\nB. Circa il 65%.\n\n\nC. Quasi il 90%.\n\n\nD. Nessuno studio è stato replicato con successo.\n\n\nE. Circa il 10%.\n\n6) Cosa sono le Questionable Research Practices (QRPs)?\nQuale definizione descrive meglio le “QRPs” (Questionable Research Practices)?\n\n\nA. Pratiche statistiche avanzate che aumentano la robustezza dei risultati.\n\n\nB. Metodologie di campionamento probabilistico trasparenti e preregistrate.\n\n\nC. Pratiche di ricerca discutibili, come “optional stopping” e selezione post-hoc di ipotesi, che influiscono negativamente sull’integrità scientifica.\n\n\nD. Strumenti di meta-analisi per combinare risultati di studi diversi.\n\n\nE. Procedure di controllo etico per proteggere i diritti dei partecipanti.\n\n7) Perché i campioni troppo piccoli sono considerati problematici?\nNella letteratura sulla crisi di replicazione, perché avere campioni di dimensione ridotta costituisce una criticità?\n\n\nA. Perché rendono più facile l’analisi statistica, riducendo la possibilità di trovare p &lt; .05.\n\n\nB. Perché riducono la potenza statistica, aumentando il rischio di sovrastimare effetti e di ottenere risultati non replicabili.\n\n\nC. Perché il costo di reclutamento è troppo basso, compromettendo l’interesse dei revisori.\n\n\nD. Perché obbligano a utilizzare necessariamente test non-parametrici.\n\n\nE. Perché la psicologia preferisce dataset qualitativi, non quantitativi.\n\n8) Che cosa significa “bias di pubblicazione”?\nCon l’espressione “bias di pubblicazione” (o publication bias), ci si riferisce a:\n\n\nA. La tendenza dei revisori a selezionare articoli soltanto se ben scritti.\n\n\nB. L’inclinazione delle riviste di settore a pubblicare preferibilmente i lavori dei ricercatori senior.\n\n\nC. La propensione alla pubblicazione di studi con risultati innovativi e statisticamente positivi, trascurando invece studi con risultati nulli.\n\n\nD. L’obbligo di pubblicare i protocolli di studio in forma open.\n\n\nE. Una norma deontologica che impone di nascondere i metodi inediti per evitare furti di idee.\n\n9) Quale scopo principale ha il movimento dell’Open Science?\nNel contesto della crisi di replicazione, qual è l’obiettivo cardine promosso dal movimento per la Scienza Aperta (Open Science)?\n\n\nA. Aumentare il controllo sugli studi, rendendo segreti i metodi di analisi.\n\n\nB. Pubblicare soltanto studi che abbiano ottenuto finanziamenti pubblici.\n\n\nC. Rendere i dati, i materiali e le procedure il più possibile trasparenti e accessibili, favorendo le repliche e la verifica indipendente.\n\n\nD. Abolire completamente l’uso di test statistici e valori-p.\n\n\nE. Prediligere esclusivamente studi qualitativi in ambito psicologico.\n\n10) Perché la scienza non si autocorregge come si afferma?\nSecondo quanto discusso, come mai la scienza non risulta sempre “autocorrettiva” nella pratica reale?\n\n\nA. Perché gli editori impongono di inserire errori per testare la capacità dei revisori di individuarli.\n\n\nB. Perché è molto costoso usare software di statistica adeguati.\n\n\nC. Perché la pressione a pubblicare risultati nuovi prevale sull’attenzione a errori e correzioni; i ricercatori non hanno incentivi sufficienti a pubblicare smentite, ritrazioni o correzioni.\n\n\nD. Perché l’uso della statistica bayesiana ha complicato la procedura di revisione.\n\n\nE. Perché tutti gli studi di psicologia sono in realtà corretti al 99%.\n\n\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\n\n\nB\n\n\nD\n\n\nC\n\n\nD\n\n\nA\n\n\nC\n\n\nB\n\n\nC\n\n\nC\n\nC\n\nLa crisi della replicazione in psicologia è il risultato di una combinazione di fattori sistemici e metodologici:\n\n\nIncentivi distorti (“publish or perish”), che spingono a privilegiare la novità rispetto alla qualità e alla rigorosità delle ricerche.\n\n\nPratiche di ricerca discutibili (QRPs), tra cui p-hacking e optional stopping, che producono un numero elevato di falsi positivi.\n\n\nBias di pubblicazione, che favorisce i risultati statistici significativi a scapito di studi con esiti non significativi o repliche.\n\n\nBassa potenza statistica e campioni di piccole dimensioni, che gonfiano o sovrastimano l’effetto di fenomeni psicologici.\n\n\nScarsa trasparenza e accessibilità (scienza “chiusa”), che rende difficile verificare e replicare i risultati originari.\n\nNonostante i numeri allarmanti riportati da studi di vasta portata (come il Reproducibility Project), questa situazione può essere vista come un’opportunità di “rivoluzione della credibilità”:\n\nSi stanno diffondendo pratiche di Open Science, con la condivisione di dati, protocolli, codici e materiali, favorendo così la replica e la validazione indipendente.\n\nLa cultura della replicazione viene valorizzata, incentivando studi più rigorosi e focalizzati sulla robustezza degli effetti.\n\nL’approccio statistico tradizionale (frequentista) è posto in discussione, evidenziando la possibilità di integrare o sostituire i test di ipotesi nulla con metodologie più robuste, tra cui quelle bayesiane, le analisi preregistrate e la valorizzazione di stime degli effetti con intervalli di credibilità.\n\nLa crisi di replicazione, quindi, non deve essere intesa come un fallimento totale, bensì come un momento critico che ha avviato un rinnovamento, mirato a rendere la scienza psicologica (e altre discipline) più rigorosa, trasparente e affidabile.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/replication_crisis/01_crisis.html#informazioni-sullambiente-di-sviluppo",
    "title": "79  La crisi della replicazione",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] posterior_1.6.1  cmdstanr_0.9.0   thematic_0.1.6   MetBrewer_0.2.0 \n#&gt;  [5] ggokabeito_0.1.0 see_0.11.0       gridExtra_2.3    patchwork_1.3.0 \n#&gt;  [9] bayesplot_1.12.0 psych_2.5.3      scales_1.4.0     markdown_2.0    \n#&gt; [13] knitr_1.50       lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1   \n#&gt; [17] dplyr_1.1.4      purrr_1.0.4      readr_2.1.5      tidyr_1.3.1     \n#&gt; [21] tibble_3.2.1     ggplot2_3.5.2    tidyverse_2.0.0  rio_1.2.3       \n#&gt; [25] here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6         tensorA_0.36.2.1     xfun_0.52           \n#&gt;  [4] htmlwidgets_1.6.4    processx_3.8.6       lattice_0.22-7      \n#&gt;  [7] tzdb_0.5.0           vctrs_0.6.5          tools_4.5.0         \n#&gt; [10] ps_1.9.1             generics_0.1.4       parallel_4.5.0      \n#&gt; [13] pacman_0.5.1         pkgconfig_2.0.3      data.table_1.17.2   \n#&gt; [16] checkmate_2.3.2      RColorBrewer_1.1-3   distributional_0.5.0\n#&gt; [19] lifecycle_1.0.4      compiler_4.5.0       farver_2.1.2        \n#&gt; [22] mnormt_2.1.1         htmltools_0.5.8.1    yaml_2.3.10         \n#&gt; [25] pillar_1.10.2        abind_1.4-8          nlme_3.1-168        \n#&gt; [28] tidyselect_1.2.1     digest_0.6.37        stringi_1.8.7       \n#&gt; [31] labeling_0.4.3       rprojroot_2.0.4      fastmap_1.2.0       \n#&gt; [34] grid_4.5.0           cli_3.6.5            magrittr_2.0.3      \n#&gt; [37] utf8_1.2.5           withr_3.0.2          backports_1.5.0     \n#&gt; [40] timechange_0.3.0     rmarkdown_2.29       matrixStats_1.5.0   \n#&gt; [43] hms_1.1.3            evaluate_1.0.3       rlang_1.1.6         \n#&gt; [46] glue_1.8.0           rstudioapi_0.17.1    jsonlite_2.0.0      \n#&gt; [49] R6_2.6.1",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#bibliografia",
    "href": "chapters/replication_crisis/01_crisis.html#bibliografia",
    "title": "79  La crisi della replicazione",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAungle, P., & Langer, E. (2023). Physical healing as a function of perceived time. Scientific Reports, 13(1), 22432.\n\n\nBaker, M. (2016). 1,500 scientists lift the lid on reproducibility. Nature, 533(7604).\n\n\nBargh, J. A., Chen, M., & Burrows, L. (1996). Automaticity of social behavior: Direct effects of trait construct and stereotype activation on action. Journal of Personality and Social Psychology, 71(2), 230–244.\n\n\nBem, D. J. (2011). Feeling the future: experimental evidence for anomalous retroactive influences on cognition and affect. Journal of Personality and Social Psychology, 100(3), 407–425.\n\n\nBruton, S. V., Medlin, M., Brown, M., & Sacco, D. F. (2020). Personal motivations and systemic incentives: Scientists on questionable research practices. Science and Engineering Ethics, 26(3), 1531–1547.\n\n\nCaudek, C., Lorenzino, M., & Liperoti, R. (2017). Delta plots do not reveal response inhibition in lying. Consciousness and Cognition, 55, 232–244.\n\n\nChivers, T. (2024). Everything is Predictable: How Bayesian Statistics Explain Our World. Simon; Schuster.\n\n\nCollaboration, O. S. (2015). Estimating the reproducibility of psychological science. Science, 349(6251), aac4716.\n\n\nFerguson, C. J., & Heene, M. (2012). A vast graveyard of undead theories: Publication bias and psychological science’s aversion to the null. Perspectives on Psychological Science, 7(6), 555–561.\n\n\nGelman, A., & Brown, N. J. (2024). How statistical challenges and misreadings of the literature combine to produce unreplicable science: An example from psychology.\n\n\nGelman, A., & Loken, E. (2013). The garden of forking paths: Why multiple comparisons can be a problem, even when there is no «fishing expedition» or «p-hacking» and the research hypothesis was posited ahead of time. Department of Statistics, Columbia University, 348(1-17), 3.\n\n\nGelman, A., & Loken, E. (2014). The statistical crisis in science. American scientist, 102(6), 460–465.\n\n\nGopalakrishna, G., Ter Riet, G., Vink, G., Stoop, I., Wicherts, J. M., & Bouter, L. M. (2022). Prevalence of questionable research practices, research misconduct and their potential explanatory factors: A survey among academic researchers in The Netherlands. PloS one, 17(2), e0263023.\n\n\nGrimes, D. R., Bauch, C. T., & Ioannidis, J. P. (2018). Modelling science trustworthiness under publish or perish pressure. Royal Society open science, 5(1), 171511.\n\n\nIoannidis, J. P. (2005). Why most published research findings are false. PLoS medicine, 2(8), e124.\n\n\nKarataş, M., & Cutright, K. M. (2023). Thinking about God increases acceptance of artificial intelligence in decision-making. Proceedings of the National Academy of Sciences, 120(33), e2218961120.\n\n\nLakens, D. (2015). On the challenges of drawing conclusions from p-values just below 0.05. PeerJ, 3, e1142.\n\n\nLeys, R. (2024). Anatomy of a Train Wreck: The Rise and Fall of Priming Research. University of Chicago Press.\n\n\nLoken, E., & Gelman, A. (2017). Measurement Error and the Replication Crisis. Science, 355(6325), 584–585.\n\n\nMeehl, P. E. (2012). Why summaries of research on psychological theories are often uninterpretable. In Improving inquiry in social science (pp. 13–59). Routledge.\n\n\nMoore, D. A., Schroeder, J., Bailey, E. R., Gershon, R., Moore, J. E., & Simmons, J. P. (2024). Does thinking about God increase acceptance of artificial intelligence in decision-making? Proceedings of the National Academy of Sciences, 121(31), e2402315121.\n\n\nNosek, B. A., Spies, J. R., & Motyl, M. (2012). Scientific utopia: II. Restructuring incentives and practices to promote truth over publishability. Perspectives on Psychological Science, 7(6), 615–631.\n\n\nPennington, C. (2023). A student’s guide to open science: Using the replication crisis to reform psychology. McGraw-Hill Education (UK).\n\n\nWare, J. J., & Munafò, M. R. (2015). Significance chasing in research practice: causes, consequences and possible solutions. Addiction, 110(1), 4–8.\n\n\nYouyou, W., Yang, Y., & Uzzi, B. (2023). A discipline-wide investigation of the replicability of Psychology papers over the past two decades. Proceedings of the National Academy of Sciences, 120(6), e2208863120.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html",
    "title": "80  Limiti dell’inferenza frequentista",
    "section": "",
    "text": "Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nIn questa sezione della dispensa, abbiamo approfondito il metodo “tradizionale” per il test di significatività dell’ipotesi nulla (NHST). Comprendere la logica sottostante all’approccio NHST è fondamentale, poiché esso ha rappresentato il principale strumento della statistica inferenziale sin dalla sua introduzione all’inizio del XX secolo, e la maggior parte dei ricercatori continua a basarsi su questa procedura per l’analisi dei dati. Tuttavia, negli ultimi anni, l’NHST è stato oggetto di crescenti critiche, con molti studiosi che sostengono che questo approccio possa generare più problemi di quanti ne risolva. Per questo motivo, è cruciale esaminare le critiche avanzate dalla comunità scientifica nei confronti della procedura inferenziale NHST. In questa sezione, analizzeremo alcuni dei principali dubbi e limiti emersi riguardo a tale metodologia.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#luso-del-valore-p-nel-mondo-della-ricerca",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#luso-del-valore-p-nel-mondo-della-ricerca",
    "title": "80  Limiti dell’inferenza frequentista",
    "section": "80.1 L’uso del valore-\\(p\\) nel mondo della ricerca",
    "text": "80.1 L’uso del valore-\\(p\\) nel mondo della ricerca\nNel suo articolo “Statistical Errors” (2014), Nuzzo mette in luce i limiti dell’approccio NHST nella pratica scientifica Nuzzo (2014). Sebbene il valore-\\(p\\) sia stato introdotto da Ronald Fisher negli anni ’20, egli non lo concepì mai come un test formale. Fisher lo considerava piuttosto uno strumento informale per valutare se l’evidenza empirica fosse “significativa” in senso colloquiale, ovvero meritevole di ulteriore attenzione. Nella pratica, Fisher suggeriva di assumere un’ipotesi nulla e di calcolare la probabilità di osservare un risultato altrettanto estremo o più estremo di quello ottenuto, presupponendo che il risultato fosse interamente dovuto alla variabilità campionaria. Tuttavia, per Fisher, il valore-\\(p\\) non era una conclusione definitiva, ma uno strumento da integrare in un processo decisionale più ampio, che tenesse conto sia delle evidenze empiriche sia delle conoscenze pregresse del ricercatore. In altre parole, il valore-\\(p\\) era parte di un ragionamento scientifico, non il punto finale di tale ragionamento.\nVerso la fine degli anni ’20, Jerzy Neyman e Egon Pearson, rivali di Fisher, formalizzarono le procedure di decisione statistica con l’obiettivo di renderle più rigorose e oggettive. Introdussero concetti come il potere statistico e il tasso di falsi positivi, ma si distanziarono dall’uso del valore-\\(p\\) proposto da Fisher. Le divergenze tra Fisher, Neyman e Pearson diedero vita a un acceso dibattito: Neyman definì il lavoro di Fisher “matematicamente peggiore dell’inutilità”, mentre Fisher bollò l’approccio di Neyman come “infantile” e “dannoso per la libertà intellettuale dell’Occidente”.\nNel frattempo, altri autori iniziarono a scrivere manuali di statistica per guidare i ricercatori. Tuttavia, molti di questi autori non erano statistici e avevano una comprensione superficiale delle differenze tra i vari approcci. Il risultato fu un sistema ibrido che combinava il valore-\\(p\\) di Fisher con il framework rigoroso di Neyman e Pearson. Fu in questo contesto che la soglia di un valore-\\(p\\) pari a 0.05 venne arbitrariamente definita come “statisticamente significativa”.\nStoricamente, tuttavia, il valore-\\(p\\) proposto da Fisher aveva un significato molto diverso rispetto a quello che gli viene attribuito oggi. Come abbiamo visto, per Fisher era uno strumento informale, da utilizzare all’interno di un processo decisionale più ampio e non come un criterio meccanico per stabilire la verità scientifica. L’uso del valore-\\(p\\) nel sistema ibrido adottato dai manuali di statistica è quindi privo di una solida giustificazione teorica.\nNel 2016, l’American Statistical Association (ASA) ha espresso forti preoccupazioni riguardo all’uso inappropriato del valore-\\(p\\) nella pratica scientifica contemporanea Wasserstein & Lazar (2016):\n\n\\(P\\)-values do not measure the probability that the studied hypothesis is true, or the probability that the data were produced by random chance alone. Researchers often wish to turn a \\(p\\)-value into a statement about the truth of a null hypothesis, or about the probability that random chance produced the observed data. The \\(p\\)-value is neither. It is a statement about data in relation to a specified hypothetical explanation, and is not a statement about the explanation itself.\n\nL’articolo prosegue sottolineando che:\n\nScientific conclusions and business or policy decisions should not be based only on whether a \\(p\\)-value passes a specific threshold. Practices that reduce data analysis or scientific inference to mechanical “bright-line” rules (such as “\\(p &lt; 0.05\\)”) for justifying scientific claims or conclusions can lead to erroneous beliefs and poor decision making. A conclusion does not immediately become ‘true’ on one side of the divide and ‘false’ on the other. Researchers should bring many contextual factors into play to derive scientific inferences, including the design of a study, the quality of the measurements, the external evidence for the phenomenon under study, and the validity of assumptions that underlie the data analysis. Pragmatic considerations often require binary, ‘yes-no’ decisions, but this does not mean that \\(p\\)-values alone can ensure that a decision is correct or incorrect. The widespread use of “statistical significance” (generally interpreted as \\(p \\leq 0.05\\)) as a license for making a claim of a scientific finding (or implied truth) leads to considerable distortion of the scientific process.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#p-hacking",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#p-hacking",
    "title": "80  Limiti dell’inferenza frequentista",
    "section": "80.2 \\(P\\)-hacking",
    "text": "80.2 \\(P\\)-hacking\nLa pratica del \\(P\\)-hacking rappresenta una delle principali criticità associate all’uso del valore-\\(p\\) ed è conosciuta anche con termini come data-dredging, snooping, fishing, significance-chasing o double-dipping. Secondo Uri Simonsohn, professore all’Università della Pennsylvania, il \\(P\\)-hacking consiste nel manipolare i dati o le analisi fino a ottenere un risultato statisticamente significativo, tipicamente con un valore-\\(p\\) inferiore a 0.05. Ad esempio, si potrebbe dire: “Quel risultato sembra frutto di \\(P\\)-hacking; gli autori hanno escluso una condizione per far diminuire il valore-\\(p\\) sotto la soglia di 0.05” oppure “Lei è un \\(P\\)-hacker, controlla continuamente i dati durante la raccolta per trovare un risultato significativo”.\nQuesta pratica trasforma uno studio esplorativo, che dovrebbe essere interpretato con estrema cautela, in uno studio confermativo (apparentemente robusto), i cui risultati, tuttavia, hanno una probabilità molto bassa di essere replicati in ricerche successive. Secondo le simulazioni condotte da Simonsohn, piccole modifiche nelle scelte analitiche possono aumentare il tasso di falsi positivi fino al 60% in un singolo studio.\nIl \\(P\\)-hacking è particolarmente diffuso negli studi che cercano di dimostrare effetti di piccola entità utilizzando dati molto rumorosi. Un’analisi della letteratura psicologica ha rivelato che i valori-\\(p\\) riportati tendono a concentrarsi appena al di sotto della soglia di 0.05, un fenomeno che può essere interpretato come un segnale di \\(P\\)-hacking: i ricercatori eseguono molteplici test statistici fino a trovarne uno che raggiunge la “significatività statistica” e poi riportano solo quello. Come evidenziato in figura, questa pratica non è limitata alla psicologia, ma è ampiamente diffusa in tutti i campi della ricerca scientifica, contribuendo a minare l’affidabilità dei risultati pubblicati.\n\n\n\nDistribuzione dei valori-\\(p\\) nelle pubblicazioni scientifiche di economia, psicologia e biologia.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#critiche-al-valore-p",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#critiche-al-valore-p",
    "title": "80  Limiti dell’inferenza frequentista",
    "section": "80.3 Critiche al valore-\\(p\\)",
    "text": "80.3 Critiche al valore-\\(p\\)\nIl valore-\\(p\\) è stato spesso paragonato a creature fastidiose e persistenti come le zanzare, oppure ai “vestiti nuovi dell’imperatore”, metafora che rappresenta la tendenza a ignorare problemi evidenti preferendo fingere che tutto vada bene. È stato anche definito un intellectual rake sterile, un termine che sottolinea la sua incapacità di produrre risultati utili. Non manca nemmeno l’ironia sul fatto che la procedura di statistical hypothesis inference testing venga chiamata così principalmente per l’acronimo che genera.\nIl valore-\\(p\\) promuove un modo di pensare distorto, spostando l’attenzione dal cuore della ricerca, ovvero la forza della manipolazione sperimentale, verso la dimostrazione di un’ipotesi nulla che si sa già essere falsa. Ad esempio, uno studio condotto su oltre 19,000 individui ha mostrato che le coppie che si incontrano online hanno una probabilità inferiore di divorziare (\\(p &lt; 0.002\\)) e riportano una maggiore soddisfazione nella vita matrimoniale (\\(p &lt; 0.001\\)) rispetto a quelle che si sono conosciute offline. Sebbene questi risultati possano sembrare interessanti, senza considerare la dimensione dell’effetto – come la riduzione del tasso di divorzio dal 7.67% al 5.96% o l’aumento dell’indice di soddisfazione matrimoniale da 5.48 a 5.64 su una scala a sette punti – il loro impatto pratico rischia di essere sopravvalutato. In generale, la domanda chiave non dovrebbe essere “c’è un effetto?”, ma piuttosto “quanto è grande l’effetto?”. Questo approccio permette di valutare meglio l’effettiva rilevanza dei risultati, andando oltre la semplice significatività statistica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#leffetto-sperimentale-è-esattamente-nullo",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#leffetto-sperimentale-è-esattamente-nullo",
    "title": "80  Limiti dell’inferenza frequentista",
    "section": "80.4 L’effetto sperimentale è esattamente nullo?",
    "text": "80.4 L’effetto sperimentale è esattamente nullo?\nUna delle critiche più ricorrenti alla logica del test di verifica delle ipotesi statistiche riguarda l’assunzione irrealistica che l’effetto della manipolazione sperimentale sia esattamente nullo. Ad esempio, la fisica ci dimostra che persino lo spostamento di un grammo di massa in una stella distante anni luce dalla Terra può influenzare, seppur minimamente, il movimento delle molecole di un gas sul nostro pianeta (Borel, 1914). Questo esempio suggerisce che ogni manipolazione sperimentale, per quanto piccola, produca in qualche modo un effetto. Pertanto, come sottolinea Andrew Gelman, il problema non è tanto dimostrare che l’ipotesi nulla sia falsa – ovvero che la manipolazione sperimentale non abbia alcun effetto – quanto piuttosto valutare se la dimensione dell’effetto sia sufficientemente grande da avere un impatto pratico e se tale effetto sia riproducibile.\nIn questo contesto, la logica del test dell’ipotesi nulla risulta particolarmente problematica, specialmente quando si lavora con campioni piccoli ed effetti di modesta entità, come accade spesso negli studi psicologici. Questo approccio può portare a una sovrastima della dimensione dell’effetto e a una visione binaria dei risultati (vero/falso), distogliendo l’attenzione dalla stima accurata e non distorta della dimensione effettiva dell’effetto. In altre parole, la ricerca dovrebbe concentrarsi meno sul rifiutare un’ipotesi nulla spesso irrealistica e più sulla comprensione e quantificazione dell’impatto reale delle variabili studiate.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#attenti-al-valore-p",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#attenti-al-valore-p",
    "title": "80  Limiti dell’inferenza frequentista",
    "section": "80.5 Attenti al valore-\\(p\\)!",
    "text": "80.5 Attenti al valore-\\(p\\)!\nConsideriamo il seguente problema. Supponiamo di eseguire un \\(t\\)-test per due campioni indipendenti per verificare l’ipotesi nulla che le medie delle due popolazioni siano uguali. Fissiamo un livello di significatività \\(\\alpha = 0.05\\) e otteniamo un valore-\\(p\\) pari a \\(0.04\\). La domanda è: qual è la probabilità che i due campioni provengano da distribuzioni con la stessa media?\nLe opzioni sono:\n(a) \\(19/20\\); (b) \\(1/19\\); (c) \\(1/20\\); (d) \\(95/100\\); (e) sconosciuta.\nLa risposta corretta è: (e) sconosciuta. Questo perché la statistica frequentista calcola le probabilità dei dati condizionatamente alle ipotesi (assunte come vere), ma non permette di determinare la probabilità di un’ipotesi. In altre parole, il valore-\\(p\\) non fornisce informazioni sulla probabilità che l’ipotesi nulla sia vera o falsa; indica solo la probabilità di osservare i dati (o risultati più estremi) assumendo che l’ipotesi nulla sia vera.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#la-crisi-della-riprodicibilità-dei-risultati-della-ricerca",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#la-crisi-della-riprodicibilità-dei-risultati-della-ricerca",
    "title": "80  Limiti dell’inferenza frequentista",
    "section": "80.6 La crisi della riprodicibilità dei risultati della ricerca",
    "text": "80.6 La crisi della riprodicibilità dei risultati della ricerca\nNegli ultimi anni, la mancanza di replicabilità dei risultati della ricerca – inclusa quella psicologica – è emersa come un tema di grande rilevanza nel dibattito scientifico. In questo contesto, è stato evidenziato che alcuni aspetti del metodo scientifico, in particolare l’uso del valore-\\(p\\) e la pratica del test di significatività dell’ipotesi nulla (NHST, Null Hypothesis Significance Testing), potrebbero contribuire a quella che è stata definita una “crisi della ricerca scientifica”. Un’analisi approfondita di questo problema è stata proposta da Gelman (2016), il quale sostiene che la NHST sia intrinsecamente problematica. Questo approccio, infatti, spinge i ricercatori a cercare di rigettare un’ipotesi “fantoccio” (straw-man), spesso già falsa a priori o di scarso interesse scientifico, a favore di un’ipotesi alternativa che il ricercatore preferisce. In generale, è più ragionevole affermare che la differenza tra due condizioni sia molto piccola piuttosto che esattamente uguale a zero, ma la NHST non è progettata per cogliere questa sfumatura.\nNei libri di statistica, la NHST viene spesso presentata come una sorta di “alchimia” che trasforma la casualità in una falsa certezza, utilizzando termini come “confidenza” e “significatività” (Gelman, 2016). Il processo di raccolta dei dati, analisi e inferenza statistica viene sintetizzato in una conclusione espressa in termini di valore-\\(p\\) e intervalli di confidenza che escludono lo zero. Tuttavia, questo può creare l’impressione errata che il ricercatore abbia una comprensione completa del fenomeno studiato. Il problema principale della NHST è che spesso produce risultati “statisticamente significativi” in contesti in cui le caratteristiche del fenomeno non giustificano le conclusioni tratte. Questo può portare a una bassa replicabilità dei risultati, contribuendo alla crisi di fiducia nella ricerca.\nLa comunità statistica ha sottolineato come la non replicabilità sia particolarmente evidente quando i ricercatori, utilizzando la NHST, traggono conclusioni errate basate su piccoli campioni ed effetti di dimensioni ridotte. Queste condizioni, insieme ad altre, rendono l’applicazione della NHST estremamente problematica. Purtroppo, queste situazioni descrivono molte delle ricerche recenti in psicologia, un campo in cui gli effetti sono spesso modesti e i campioni limitati.\nLa statistica è stata definita come un metodo per prendere decisioni razionali in condizioni di incertezza. Gli statistici raccomandano ai ricercatori non solo di padroneggiare le tecniche statistiche, ma anche di imparare a convivere con l’incertezza, nonostante la crescente sofisticazione degli strumenti disponibili. Conviverci significa evitare di pensare che ottenere un valore-\\(p\\) “statisticamente significativo” equivalga a risolvere un problema scientifico. Ma allora, come possiamo avere fiducia in ciò che apprendiamo dai dati? Una possibile strategia è la replicazione e la convalida esterna dei risultati, sebbene nella ricerca psicologica e nelle scienze sociali questo sia spesso difficile da realizzare a causa degli elevati costi e delle complessità pratiche. Il problema di quali strumenti metodologici e metodi statistici siano più adatti per indagare i fenomeni psicologici, senza cadere in errori di interpretazione, rimane quindi una questione aperta e di cruciale importanza.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#commenti-e-considerazioni-finali",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#commenti-e-considerazioni-finali",
    "title": "80  Limiti dell’inferenza frequentista",
    "section": "80.7 Commenti e considerazioni finali",
    "text": "80.7 Commenti e considerazioni finali\nNon possiamo concludere senza affrontare la controversia che circonda il concetto di valore-\\(p\\). Nonostante sia ancora ampiamente utilizzato e spesso interpretato in modo errato, il valore-\\(p\\) conferisce solo una parvenza di legittimità a risultati dubbi, incoraggia cattive pratiche di ricerca e favorisce la produzione di falsi positivi. Inoltre, il suo significato è spesso frainteso, persino dagli esperti: quando chiamati a definire il valore-\\(p\\), molti forniscono risposte imprecise o sbagliate. Ciò che i ricercatori desiderano sapere è se i risultati di uno studio siano corretti o meno, ma il valore-\\(p\\) non fornisce questa informazione. Non dice nulla sulla dimensione dell’effetto, sulla forza dell’evidenza o sulla probabilità che il risultato sia frutto del caso. Allora, qual è il suo vero significato? Stuart Buck lo spiega in modo efficace:\n\nImmaginate di avere una moneta che sospettate sia truccata a favore della testa (l’ipotesi nulla è che la moneta sia equa). La lanciate 100 volte e ottenete più teste che croci. Il valore-\\(p\\) non vi dirà se la moneta è equa, ma vi indicherà la probabilità di ottenere almeno lo stesso numero di teste osservato se la moneta fosse equa. Questo è tutto – niente di più.\n\nIn sintesi, il valore-\\(p\\) risponde a una domanda molto specifica che, tuttavia, non ha alcuna rilevanza diretta per la validità scientifica dei risultati di una ricerca. In un’epoca in cui la crisi della riproducibilità dei risultati è sempre più evidente (Baker, 2016), il test dell’ipotesi nulla e gli intervalli di confidenza frequentisti sono stati identificati come una delle principali cause del problema. Questo ha spinto molti ricercatori a cercare alternative metodologiche più robuste e informative, in grado di superare i limiti intrinseci del valore-\\(p\\) e di promuovere una scienza più affidabile e trasparente.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#bibliografia",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#bibliografia",
    "title": "80  Limiti dell’inferenza frequentista",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBaker, M. (2016). Reproducibility Crisis. Nature, 533(7604), 452–454.\n\n\nBorel, E. (1914). Introduction Géométrique. G. Villars, New York.\n\n\nGelman, A. (2016). Commentary on «Crisis in Science? Or Crisis in Statistics! Mixed Messages in Statistics with Impact on Science». Journal of Statistical Research, 48-50(1), 11–12.\n\n\nGoligher, E. C., Heath, A., & Harhay, M. O. (2024). Bayesian statistics for clinical research. The Lancet, 404(10457), 1067–1076. https://doi.org/10.1016/S0140-6736(24)00055-9\n\n\nNuzzo, R. (2014). Statistical Errors. Nature, 506(7487), 150–152.\n\n\nWasserstein, R. L., & Lazar, N. A. (2016). The ASA’s statement on p-values: context, process, and purpose. The American Statistician, 70(2), 129–133.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html",
    "href": "chapters/replication_crisis/03_effect_size.html",
    "title": "81  La grandezza dell’effetto",
    "section": "",
    "text": "81.1 Introduzione\nLa dimensione dell’effetto (effect size) è un concetto chiave nella metodologia della ricerca, utilizzato per quantificare la forza della relazione statistica tra due variabili. Questa misura standardizzata descrive l’entità di un effetto, come quello di un intervento o di un trattamento, fornendo una valutazione quantitativa dell’importanza di un fenomeno osservato.\nÈ essenziale distinguere tra dimensione dell’effetto e significatività statistica. Un risultato può essere “statisticamente significativo” anche se l’effetto è di piccole dimensioni, e viceversa. La conoscenza di uno di questi aspetti non fornisce automaticamente informazioni sull’altro, evidenziando la necessità di considerare entrambi nell’analisi dei dati.\nL’importanza della dimensione dell’effetto è ampiamente riconosciuta nel mondo della ricerca scientifica. Il manuale dell’American Psychological Association (APA) del 2010 ne sottolinea la rilevanza, raccomandando di includere questa misura negli studi pubblicati. Di conseguenza, la maggior parte degli articoli nelle riviste associate all’APA riporta la dimensione dell’effetto, solitamente indicata tra parentesi accanto al valore-\\(p\\).\nNonostante la sua importanza e la prassi di riportarla, la psicologia scientifica spesso mostra una carenza nella corretta valutazione e interpretazione delle dimensioni dell’effetto. Molti ricercatori si limitano a comunicare questi valori senza analizzarli in profondità, portando a conclusioni che possono risultare superficiali, poco informative, fuorvianti o addirittura errate. Questa tendenza riflette una sottovalutazione sistematica e una diffusa incomprensione del concetto di dimensione dell’effetto, persino tra i professionisti della ricerca.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#misurazione-delleffetto-approcci-e-applicazioni",
    "href": "chapters/replication_crisis/03_effect_size.html#misurazione-delleffetto-approcci-e-applicazioni",
    "title": "81  La grandezza dell’effetto",
    "section": "81.2 Misurazione dell’Effetto: Approcci e Applicazioni",
    "text": "81.2 Misurazione dell’Effetto: Approcci e Applicazioni\nTra le metriche più utilizzate per quantificare l’effetto di un trattamento o di una differenza tra gruppi troviamo il \\(d\\) di Cohen e l’\\(r\\) di Pearson. Il \\(d\\) di Cohen è particolarmente utile per descrivere le differenze tra le medie di due gruppi sperimentali, esprimendo tale differenza in termini di deviazione standard aggregata.\nLa differenza standardizzata tra le medie di due gruppi può essere calcolata con la seguente formula (equazione 5.1, Glass et al., 1981):\n\\[\nd_p = \\frac{M_1 - M_2}{S_p},\n\\]\ndove:\n\n\\(M_1\\) e \\(M_2\\) sono le medie dei due gruppi,\n\\(S_p\\) è la deviazione standard combinata.\n\nUn valore positivo di \\(d_p\\) indica che la media del gruppo 1 è maggiore di quella del gruppo 2. La deviazione standard combinata \\(S_p\\) è calcolata come la radice quadrata della varianza media ponderata per i gradi di libertà (\\(df = n-1\\)) dei due gruppi (pp. 108, Glass et al., 1981):\n\\[\nS_p = \\sqrt{\\frac{(n_1 - 1) S_1^2 + (n_2 - 1) S_2^2}{n_1 + n_2 - 2}},\n\\]\ndove:\n\n\\(n_1\\) e \\(n_2\\) sono le dimensioni dei due gruppi,\n\\(S_1^2\\) e \\(S_2^2\\) sono le varianze (quadrato della deviazione standard) dei due gruppi.\n\nIl \\(d_p\\) di Cohen è strettamente correlato alla statistica \\(t\\) di un test \\(t\\) per campioni indipendenti. Infatti, è possibile calcolare \\(d_p\\) a partire dalla statistica \\(t\\) utilizzando la seguente formula (equazione 5.3, Glass et al., 1981):\n\\[\nd = t \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}.\n\\]\nL’errore standard di \\(d_p\\) è dato da:\n\\[\nSE_{d_p} = \\sqrt{\\frac{n_1 + n_2}{n_1 n_2} + \\frac{d_p^2}{2(n_1 + n_2)}}.\n\\]\nD’altra parte, la statistica \\(r\\) di Pearson misura il grado di correlazione lineare tra due variabili, indicando quanto una variabile possa predire l’altra. È interessante notare che queste due misure, \\(d\\) e \\(r\\), possono essere convertite l’una nell’altra attraverso la relazione:\n\\[\nd = \\frac{2r}{\\sqrt{1-r^2}}.\n\\]\nQuesta conversione permette di passare da una misura di differenza tra medie a una misura di correlazione, offrendo una maggiore flessibilità nell’interpretazione dei risultati.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#interpretazione-della-dimensione-delleffetto",
    "href": "chapters/replication_crisis/03_effect_size.html#interpretazione-della-dimensione-delleffetto",
    "title": "81  La grandezza dell’effetto",
    "section": "81.3 Interpretazione della Dimensione dell’Effetto",
    "text": "81.3 Interpretazione della Dimensione dell’Effetto\nL’interpretazione della dimensione dell’effetto è un aspetto cruciale nell’analisi statistica, ma spesso viene affrontata in modi che possono risultare privi di significato o addirittura fuorvianti. Di seguito, esploriamo due approcci comuni e le loro criticità.\n\n81.3.1 Gli Standard di Cohen\nUno dei metodi più diffusi per interpretare la dimensione dell’effetto si basa sugli standard proposti da Jacob Cohen (1977, 1988). Cohen ha suggerito delle soglie arbitrarie per classificare l’effetto:\n\nr = 0.10 → effetto piccolo,\nr = 0.30 → effetto medio,\nr = 0.50 → effetto grande.\n\nTuttavia, come sottolineato da Funder (2019), queste soglie sono spesso utilizzate in modo acritico, senza considerare il contesto specifico. Lo stesso Cohen ha espresso rammarico per aver introdotto queste categorie, precisando che dovrebbero essere adottate solo in assenza di criteri più solidi.\nLe etichette “piccolo”, “medio” e “grande” sono prive di significato se non vengono contestualizzate. Per un’interpretazione corretta, è essenziale porsi due domande fondamentali:\n\nRispetto a cosa? Cosa rappresenta un effetto piccolo, medio o grande nel contesto specifico dello studio?\nA quale scopo? Qual è l’impatto pratico o teorico dell’effetto osservato?\n\nSenza rispondere a queste domande, l’uso degli standard di Cohen rischia di essere poco informativo o addirittura ingannevole.\n\n\n81.3.2 Elevare al Quadrato la Correlazione\nUn altro approccio comune, ma altrettanto problematico, consiste nell’elevare al quadrato il coefficiente di correlazione \\(r\\) per ottenere \\(r^2\\), interpretato come la “proporzione di varianza spiegata”. Ad esempio, una correlazione \\(r = 0.30\\) corrisponde a \\(r^2 = 0.09\\), spesso descritto come “solo il 9% della varianza spiegata”.\nTuttavia, come evidenziato da Funder & Ozer (2019), questa pratica è criticabile per due motivi principali:\n\nMancanza di interpretabilità: Mentre \\(r\\) rappresenta la pendenza di una regressione standardizzata, \\(r^2\\) è molto meno intuitivo, poiché riflette solo la proporzione di varianza condivisa tra due variabili.\nPotenziale fuorviante: Elevare al quadrato \\(r\\) può distorcere la percezione dell’effetto. Ad esempio, una correlazione \\(r = 0.30\\) (effetto medio secondo Cohen) diventa \\(r^2 = 0.09\\), che sembra trascurabile, ma in realtà potrebbe avere un impatto significativo nel contesto applicativo.\n\nUn esempio chiaro è fornito da Darlington (1990). Consideriamo un gioco in cui si lanciano due monete: un nickel (5¢) e un dime (10¢). Se esce testa, si vincono rispettivamente 5¢ o 10¢. Le correlazioni tra il valore delle monete e il pagamento sono:\n\nNickel: \\(r = 0.4472\\) (\\(r^2 = 0.20\\)),\nDime: \\(r = 0.8944\\) (\\(r^2 = 0.80\\)).\n\nSe interpretassimo \\(r^2\\) in modo letterale, potremmo erroneamente concludere che il dime “conta quattro volte più” del nickel. Tuttavia, le correlazioni originali mostrano che \\(0.8944\\) è esattamente il doppio di \\(0.4472\\), offrendo un confronto più accurato e informativo.\nIn sintesi, l’interpretazione della dimensione dell’effetto richiede cautela e contestualizzazione. Gli standard di Cohen, sebbene ampiamente utilizzati, sono arbitrari e possono essere fuorvianti se applicati in modo acritico. Allo stesso modo, elevare al quadrato la correlazione \\(r\\) per ottenere \\(r^2\\) rischia di distorcere la percezione dell’effetto, rendendolo meno interpretabile e potenzialmente fuorviante. Per un’analisi robusta, è essenziale considerare il contesto e l’impatto pratico dell’effetto osservato, evitando di affidarsi esclusivamente a metriche standardizzate o trasformazioni matematiche poco informative.\n\n\n81.3.3 Alternative migliori\nÈ cruciale interpretare le dimensioni degli effetti in modo che ne arricchisca il significato. Funder & Ozer (2019) propongono due strategie principali: l’adozione di benchmark (criteri di riferimento) e la valutazione delle implicazioni pratiche dei risultati.\n\nUtilizzare criteri di riferimento significa confrontare l’entità di un risultato con quella di risultati ben noti e ampiamente compresi. Simile al modo in cui giudichiamo l’altezza di una persona basandoci su confronti con altri, i ricercatori possono ottenere una percezione accurata dell’importanza di un risultato confrontandolo con la dimensione di effetti noti, sia quelli tipici del campo di studio sia quelli emersi da ricerche passate.\nUn approccio al benchmarking può includere l’analisi di risultati considerati “classici” nel campo di interesse o la considerazione di dimensioni dell’effetto per risultati che hanno ottenuto un solido consenso nella comunità psicologica.\nIn un’ottica più ampia, alcuni ricercatori hanno proposto benchmark per la dimensione dell’effetto calcolando medie su vasti corpi di letteratura. Ad esempio, uno studio di psicologia sociale ha esaminato 708 correlazioni ottenute meta-analiticamente, rivelando che la dimensione media dell’effetto \\(r\\) era di .19.\nLa conoscenza comune o i risultati di ricerche non psicologiche possono offrire benchmark per valutare la forza di una relazione tra variabili. Un esempio è l’efficacia degli antistaminici contro il comune raffreddore, che corrisponde a un \\(r\\) di .11, mentre l’effetto degli anti-infiammatori non steroidei (come l’ibuprofene) sul dolore è di \\(r = .14\\).\n\nTali confronti illustrano come l’interpretazione delle dimensioni dell’effetto possa essere notevolmente approfondita e resa più significativa attraverso il riferimento a benchmark consolidati o intuitivamente comprensibili, sia dentro che fuori il campo della psicologia. Questo metodo consente di inserire i risultati di nuove ricerche in un contesto più vasto, favorendo una valutazione più consapevole della loro rilevanza relativa.\n\n\n81.3.4 Alternative Migliori per Interpretare la Dimensione dell’Effetto\nPer arricchire il significato delle dimensioni dell’effetto, è essenziale adottare approcci che vadano oltre le metriche standardizzate e si basino su criteri di riferimento concreti e contestualizzati. Funder & Ozer (2019) propone due strategie principali: l’uso di benchmark (criteri di riferimento) e la valutazione delle implicazioni pratiche dei risultati.\n\n81.3.4.1 1. Utilizzare Criteri di Riferimento (Benchmark)\nUn modo efficace per interpretare la dimensione dell’effetto è confrontarla con risultati ben noti e ampiamente compresi, sia all’interno del campo di studio che in contesti più generali. Questo approccio è simile a come giudichiamo l’altezza di una persona confrontandola con quella di altre persone.\n\nConfronto con Risultati Classici: I ricercatori possono ottenere una percezione più accurata dell’importanza di un risultato confrontandolo con dimensioni dell’effetto di studi considerati “classici” nel proprio campo. Ad esempio, in psicologia, è possibile fare riferimento a risultati che hanno ottenuto un solido consenso nella comunità scientifica.\nMedie da Meta-Analisi: Alcuni ricercatori hanno proposto benchmark calcolando medie su vasti corpi di letteratura. Ad esempio, uno studio di psicologia sociale ha analizzato 708 correlazioni ottenute meta-analiticamente, rilevando che la dimensione media dell’effetto \\(r\\) era di 0.19. Questo valore può servire come punto di riferimento per valutare l’entità di nuovi risultati.\nEsempi Trasversali: Anche conoscenze comuni o risultati di ricerche non psicologiche possono offrire benchmark utili. Ad esempio:\n\nL’efficacia degli antistaminici contro il comune raffreddore corrisponde a un \\(r = 0.11\\).\nL’effetto degli anti-infiammatori non steroidei (come l’ibuprofene) sul dolore è pari a \\(r = 0.14\\).\n\n\nQuesti confronti mostrano come l’interpretazione della dimensione dell’effetto possa essere notevolmente approfondita e resa più significativa attraverso il riferimento a benchmark consolidati o intuitivamente comprensibili.\n\n\n81.3.4.2 2. Valutare le Implicazioni Pratiche\nOltre ai benchmark, è fondamentale considerare le implicazioni pratiche dei risultati. Un effetto statisticamente piccolo può avere un impatto significativo se applicato a un contesto reale. Ad esempio:\n\nUn \\(r = 0.10\\) potrebbe sembrare trascurabile, ma se tradotto in un intervento su larga scala (ad esempio, un programma educativo o una politica sanitaria), potrebbe portare a benefici tangibili per un gran numero di persone.\n\nIn conclusione, l’interpretazione della dimensione dell’effetto può essere notevolmente migliorata attraverso l’uso di benchmark e la valutazione delle implicazioni pratiche. Confrontare i risultati con studi classici, medie di meta-analisi o esempi tratti da altri campi consente di inserire i nuovi risultati in un contesto più ampio e significativo. Questo approccio non solo arricchisce l’interpretazione, ma favorisce anche una valutazione più consapevole della rilevanza e dell’impatto delle scoperte scientifiche.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#riflessioni-conclusive",
    "href": "chapters/replication_crisis/03_effect_size.html#riflessioni-conclusive",
    "title": "81  La grandezza dell’effetto",
    "section": "81.4 Riflessioni Conclusive",
    "text": "81.4 Riflessioni Conclusive\nLa sovrastima della grandezza degli effetti in psicologia rappresenta un problema diffuso e significativo. Un principio spesso enfatizzato nella psicologia sociale e nell’economia comportamentale, specialmente nei media e nei corsi di business, è che piccoli interventi, o “nudge” (spinte gentili), possano produrre effetti sorprendentemente ampi sul comportamento. Questa idea ha portato a numerose affermazioni sensazionalistiche, come l’ipotesi che le elezioni possano essere influenzate dall’esito di partite di football o che stimoli subliminali, come una faccina sorridente, possano generare cambiamenti drastici negli atteggiamenti verso temi complessi come l’immigrazione.\nAlla base di queste affermazioni c’è un modello di mondo che non si limita al concetto di “effetto farfalla” (dove piccoli cambiamenti possono avere conseguenze imprevedibili e amplificate), ma suggerisce che piccoli interventi possano produrre effetti grandi e prevedibili. Questo approccio, talvolta definito “modello a pulsante” delle scienze sociali, presuppone che, facendo X, si possa aspettarsi di osservare Y in modo sistematico. Tuttavia, questa visione presenta diverse criticità:\n\n81.4.1 Problemi del Modello “a Pulsante”\n\nSovrastima degli effetti: Molti studi riportano effetti esagerati per interventi minimi, che spesso non vengono replicati in ricerche successive. Questo solleva dubbi sulla validità e sull’affidabilità di tali risultati.\nMancanza di considerazione delle interazioni: Se esistessero davvero molti effetti grandi e prevedibili, questi interferirebbero tra loro, rendendo difficile osservare risultati coerenti nei dati reali. La complessità del comportamento umano raramente si presta a relazioni lineari e isolate.\nInstabilità del sistema: Un sistema sociale caratterizzato da molti effetti grandi e prevedibili sarebbe intrinsecamente instabile e difficile da studiare, contraddicendo l’osservazione che le società tendono a mostrare una certa stabilità nel tempo.\nGeneralizzazione eccessiva: Spesso i risultati ottenuti in contesti di laboratorio altamente controllati vengono estesi a situazioni reali molto più complesse, senza considerare le differenze contestuali.\nBias di pubblicazione: Gli studi che riportano effetti grandi e statisticamente significativi hanno maggiori probabilità di essere pubblicati, creando una rappresentazione distorta della realtà e alimentando un ciclo di sovrastima.\n\n\n\n81.4.2 Verso un Approccio più Cauto e Sfumato\nNonostante queste criticità, è importante riconoscere che la psicologia ha identificato molti fenomeni robusti, specialmente in aree come la psicologia clinica e la psicologia della percezione. Tuttavia, è fondamentale adottare un approccio più cauto e riflessivo nell’interpretazione e nella comunicazione dei risultati della ricerca.\nLa consapevolezza di questi problemi ha portato a una serie di miglioramenti metodologici, tra cui:\n\nEnfasi sulla replicabilità: Maggiore attenzione alla riproducibilità degli studi per garantire che i risultati siano affidabili.\nUso di campioni più ampi: Studi condotti su campioni più grandi e diversificati per aumentare la validità esterna.\nMetodi statistici più robusti: Adozione di tecniche statistiche avanzate per ridurre il rischio di falsi positivi.\nApproccio critico e riflessivo: La comunità scientifica sta diventando sempre più consapevole della necessità di evitare semplificazioni eccessive e di riconoscere la complessità dei fenomeni psicologici.\n\nIn sintesi, mentre la psicologia offre intuizioni preziose sul comportamento umano, è essenziale mantenere un sano scetticismo verso affermazioni di effetti grandi e facilmente ottenibili. La realtà è spesso più complessa e sfumata di quanto suggerito da titoli sensazionalistici o da singoli studi. Un approccio equilibrato, che combina rigore metodologico, contestualizzazione e umiltà scientifica, è fondamentale per avanzare nella comprensione dei fenomeni psicologici e per evitare di cadere in trappole interpretative che possono distorcere la nostra visione del comportamento umano.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#bibliografia",
    "href": "chapters/replication_crisis/03_effect_size.html#bibliografia",
    "title": "81  La grandezza dell’effetto",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nFunder, D. C., & Ozer, D. J. (2019). Evaluating effect size in psychological research: Sense and nonsense. Advances in Methods and Practices in Psychological Science, 2(2), 156–168.\n\n\nGlass, G. V., McGaw, B., & Smith, M. L. (1981). Meta-analysis in Social Research. Sage Publications.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html",
    "href": "chapters/replication_crisis/04_s_m_errors.html",
    "title": "82  Errori di segno e errori di grandezza",
    "section": "",
    "text": "82.1 Introduzione\nIn questo capitolo analizzeremo la relazione tra la crisi della replicabilità e le procedure decisionali statistiche proprie dell’approccio frequentista. In particolare, approfondiremo gli errori di tipo M (magnitude) e di tipo S (sign), discussi da Loken & Gelman (2017), e il loro impatto sulla validità dei risultati scientifici.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#introduzione",
    "href": "chapters/replication_crisis/04_s_m_errors.html#introduzione",
    "title": "82  Errori di segno e errori di grandezza",
    "section": "",
    "text": "Domande Iniziali\n\n\n\nPrima di esplorare le simulazioni e i risultati discussi in questo capitolo, prova a riflettere sulle seguenti domande. Ti invitiamo a formulare delle ipotesi sui risultati delle simulazioni prima di leggere le spiegazioni:\n\nSe si effettuano molteplici studi su un effetto molto piccolo utilizzando campioni di dimensioni ridotte, cosa pensi che accadrà ai risultati pubblicati che ottengono significatività statistica? Saranno accurati rispetto alla vera grandezza dell’effetto?\nIn uno scenario in cui non esiste alcuna differenza tra due gruppi, quanto spesso credi che un test t fornisca un risultato statisticamente significativo che verrà pubblicato? Quali fattori potrebbero influenzare questa probabilità?\nSupponiamo che in una serie di esperimenti alcuni studi trovino effetti significativi e altri no. Quale pensi sia la tendenza degli studi pubblicati rispetto a quelli non pubblicati? Quale impatto può avere questa tendenza sulla percezione della realtà scientifica?\nSe dovessi valutare la replicabilità di uno studio basato sulla significatività statistica, quali problemi potresti incontrare se l’effetto sottostante è molto piccolo?\n\nTieni a mente le tue risposte mentre esplori le simulazioni presentate in questo capitolo. Alla fine del capitolo, confronteremo le previsioni con i risultati effettivi.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#il-filtro-della-significatività-statistica",
    "href": "chapters/replication_crisis/04_s_m_errors.html#il-filtro-della-significatività-statistica",
    "title": "82  Errori di segno e errori di grandezza",
    "section": "\n82.2 Il Filtro della Significatività Statistica",
    "text": "82.2 Il Filtro della Significatività Statistica\nNel ?sec-crisis abbiamo esplorato come la pratica scientifica contemporanea sia spesso compromessa da casi di frode, principalmente a causa delle significative implicazioni economiche legate alla pubblicazione su riviste scientifiche di alto prestigio. Questo fenomeno è spesso sottovalutato, poiché le riviste tendono a essere riluttanti nel riconoscere la necessità di correzioni o ritrattazioni degli articoli già pubblicati.\nLa frode scientifica rappresenta una minaccia evidente alla riproducibilità dei risultati, un pilastro fondamentale del metodo scientifico. Tuttavia, le difficoltà nel replicare i risultati pubblicati non sono attribuibili esclusivamente a frodi o a “pratiche di ricerca disoneste” (Nelson et al., 2018). Un problema intrinseco risiede nel metodo statistico ampiamente adottato dai ricercatori: l’approccio del test di ipotesi nulla e della significatività statistica di stampo fisheriano. Secondo questo metodo, i risultati che non raggiungono la soglia di “significatività statistica” vengono scartati, mentre quelli che la superano sono considerati credibili, basandosi esclusivamente su questo criterio (Wagenmakers et al., 2008).\nTuttavia, l’idea che la significatività statistica sia un filtro affidabile per distinguere i risultati di ricerca “validi” da quelli “non validi” è fondamentalmente errata. Numerose evidenze dimostrano i limiti di questo approccio. Per approfondire questa problematica, esamineremo lo studio di Loken & Gelman (2017), che mette in luce la relazione tra la crisi della replicabilità e le procedure decisionali statistiche dell’approccio frequentista.\nUno dei principali problemi evidenziati da Loken & Gelman (2017) è che, in contesti di ricerca complessi, la significatività statistica fornisce prove molto deboli riguardo al segno (sign) o all’entità (magnitude) degli effetti sottostanti. In altre parole, il raggiungimento della significatività statistica non garantisce né la rilevanza né la consistenza dei risultati ottenuti. Questo solleva seri dubbi sull’affidabilità di tale criterio come unico strumento per valutare la validità delle scoperte scientifiche.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#errori-di-tipo-m-e-s",
    "href": "chapters/replication_crisis/04_s_m_errors.html#errori-di-tipo-m-e-s",
    "title": "82  Errori di segno e errori di grandezza",
    "section": "\n82.3 Errori di tipo M e S\n",
    "text": "82.3 Errori di tipo M e S\n\nPer illustrare le implicazioni del processo decisionale basato sulla significatività statistica, Loken & Gelman (2017) hanno condotto una simulazione. In questa simulazione, hanno considerato uno scenario di ricerca ipotetico in cui era presente un effetto reale, sebbene molto debole, difficilmente rilevabile senza un ampio volume di dati. Utilizzando l’approccio frequentista, hanno cercato di identificare questo effetto valutando la significatività statistica.\nI risultati della simulazione hanno mostrato che, anche in presenza di un effetto reale (seppur debole), l’approccio frequentista riusciva a rilevare un effetto statisticamente significativo solo in una piccola percentuale dei casi. Inoltre, quando un effetto significativo veniva individuato, la stima della sua grandezza risultava altamente imprecisa e instabile.\nIn sintesi, la significatività statistica fornisce un’indicazione generica sulla presenza o assenza di un effetto, ma non offre informazioni affidabili sulla sua entità o replicabilità. Questo problema è particolarmente rilevante in campi come la psicologia e le scienze sociali, dove gli studi spesso si basano su campioni di dimensioni ridotte e gli effetti osservati tendono a essere modesti. In tali contesti, l’approccio frequentista rischia di produrre prove deboli e instabili, compromettendo la replicabilità e l’affidabilità dei risultati.\n\n82.3.1 Simulazione semplificata\nRiproduciamo qui, in forma semplificata, la simulazione condotta da Loken & Gelman (2017). Iniziamo importando le librerie necessarie.\nConsideriamo due campioni casuali indipendenti di dimensioni \\(n_1 = 20\\) e \\(n_2 = 25\\), estratti rispettivamente dalle distribuzioni normali \\(\\mathcal{N}(102, 10)\\) e \\(\\mathcal{N}(100, 10)\\). La dimensione effettiva dell’effetto (\\(d\\)) per la differenza tra le medie dei due campioni è calcolata utilizzando la formula:\n\\[\nd = \\frac{\\bar{y}_1 - \\bar{y}_2}{s_p},\n\\]\ndove \\(\\bar{y}_1\\) e \\(\\bar{y}_2\\) rappresentano le medie campionarie dei due gruppi, e \\(s_p\\) è la deviazione standard combinata, definita come:\n\\[\ns_p = \\sqrt{\\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1 + n_2 - 2}}.\n\\]\nIn questo caso specifico, la dimensione effettiva dell’effetto risulta molto piccola, indicando che la differenza osservata tra le medie dei due gruppi non ha una rilevanza pratica significativa. Ciò suggerisce che la distinzione tra i due gruppi, seppur statisticamente rilevabile, non ha un impatto sostanziale in contesti reali.\n\n# Parametri\nmu_1 &lt;- 102  # Media del primo gruppo\nmu_2 &lt;- 100  # Media del secondo gruppo\nsigma &lt;- 10  # Deviazione standard comune\nn1 &lt;- 20     # Numero di osservazioni nel primo gruppo\nn2 &lt;- 25     # Numero di osservazioni nel secondo gruppo\n\n# Calcolo della differenza media\nmean_difference &lt;- abs(mu_1 - mu_2)\n\n# Calcolo della deviazione standard pooled\npooled_sd &lt;- sqrt(((n1 - 1) * sigma^2 + (n2 - 1) * sigma^2) / (n1 + n2 - 2))\n\n# Calcolo di Cohen's d\ncohen_d &lt;- mean_difference / pooled_sd\n\n# Output del risultato\ncat(\"Dimensione dell'effetto (Cohen's d):\", cohen_d, \"\\n\")\n#&gt; Dimensione dell'effetto (Cohen's d): 0.2\n\nEsaminiamo ora le conclusioni che emergerebbero applicando l’approccio frequentista e la sua procedura di decisione statistica in questo contesto. Supponiamo di condurre una simulazione in cui vengono estratti due campioni: il primo composto da 20 osservazioni provenienti dalla prima popolazione e il secondo da 25 osservazioni provenienti dalla seconda popolazione. Successivamente, applichiamo il test \\(t\\) di Student per confrontare le medie dei due gruppi.\nNell’ambito dell’approccio frequentista, il valore-\\(p\\) ottenuto dal test determina la decisione statistica. Se il valore-\\(p\\) è superiore a 0.05, i risultati vengono considerati non significativi e, di conseguenza, scartati. Al contrario, se il valore-\\(p\\) è inferiore a 0.05, il risultato è ritenuto “pubblicabile” e si conclude che esiste una differenza statisticamente significativa tra i due gruppi.\nPer valutare in modo approfondito le conclusioni derivate da questa procedura, è necessario ripetere l’intero processo per un numero elevato di iterazioni, ad esempio 50.000 volte. Ciò significa che, in ciascuna iterazione, vengono estratti nuovi campioni, viene calcolato il test \\(t\\) di Student e viene determinato il corrispondente valore-\\(p\\). Ripetendo questo processo su larga scala, è possibile ottenere una distribuzione completa dei risultati, che consente di analizzare la frequenza con cui si ottengono risultati significativi e la stabilità delle stime prodotte dall’approccio frequentista in questo contesto.\n\n# Parametri\nn_samples &lt;- 50000\nmu_1 &lt;- 102\nmu_2 &lt;- 100\nsigma &lt;- 10\nn1 &lt;- 20\nn2 &lt;- 25\n\n# Inizializzazione del risultato\nres &lt;- c()\n\n# Simulazioni\nset.seed(123)  # Per la riproducibilità\nfor (i in 1:n_samples) {\n  # Generazione dei campioni casuali\n  y1 &lt;- rnorm(n1, mean = mu_1, sd = sigma)\n  y2 &lt;- rnorm(n2, mean = mu_2, sd = sigma)\n  \n  # Calcolo della dimensione dell'effetto\n  y1bar &lt;- mean(y1)\n  y2bar &lt;- mean(y2)\n  v1 &lt;- var(y1)\n  v2 &lt;- var(y2)\n  s &lt;- sqrt(((n1 - 1) * v1 + (n2 - 1) * v2) / (n1 + n2 - 2))\n  efsize &lt;- (y1bar - y2bar) / s\n  \n  # Calcolo del valore p\n  t_test &lt;- t.test(y1, y2, var.equal = TRUE)\n  \n  # Salvataggio della dimensione dell'effetto solo per risultati \"statisticamente significativi\"\n  if (t_test$p.value &lt; 0.05) {\n    res &lt;- c(res, efsize)\n  }\n}\n\n\nres_df &lt;- data.frame(effect_size = res)\n\nggplot(res_df, aes(x = effect_size)) +\n  geom_histogram(bins = 20, fill = \"blue\", color = \"black\", alpha = 0.7) +\n  geom_vline(\n    xintercept = 0.2, color = \"red\", linetype = \"dashed\", \n    size = 1.2, label = \"True Effect Size\") +\n  labs(\n    x = \"Effect Size\",\n    y = \"Frequency\",\n    title = \"Histogram of Effect Sizes for\\n'Statistically Significant' Results\"\n  ) \n\n\n\n\n\n\n\nCome evidenziato da Loken & Gelman (2017), l’applicazione dell’approccio frequentista nella procedura di decisione statistica può condurre a due tipi di errori rilevanti. Il primo, noto come errore di magnitude (grandezza), si manifesta quando i risultati pubblicati tendono a sovrastimare la reale entità dell’effetto. Nella simulazione condotta, nonostante la vera grandezza dell’effetto fosse modesta (0.2), la media della grandezza dell’effetto per i risultati classificati come “statisticamente significativi” era circa 0.8, suggerendo un effetto di entità “ampia”. Questo indica una distorsione sistematica verso stime esagerate.\nIl secondo errore, chiamato errore di segno, si verifica quando, a causa della variabilità campionaria, la direzione dell’effetto viene stimata in modo errato. In tali casi, il ricercatore potrebbe erroneamente concludere che \\(\\mu_2 &gt; \\mu_1\\), quando in realtà non è così. È importante sottolineare che, anche in queste situazioni, la grandezza assoluta dell’effetto risulta sovrastimata.\nUn aspetto degno di nota è che queste conclusioni rimarrebbero valide anche se si considerasse l’intervallo di confidenza per la differenza tra le medie. In sintesi, l’approccio frequentista introduce un errore sistematico nella stima della grandezza dell’effetto, che rappresenta la quantità più rilevante per il ricercatore. In alcuni casi, può persino portare a errori nella determinazione della direzione dell’effetto, compromettendo ulteriormente l’affidabilità delle conclusioni scientifiche.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#riflessioni-conclusive",
    "href": "chapters/replication_crisis/04_s_m_errors.html#riflessioni-conclusive",
    "title": "82  Errori di segno e errori di grandezza",
    "section": "\n82.4 Riflessioni Conclusive",
    "text": "82.4 Riflessioni Conclusive\nIn conclusione, l’approccio frequentista non rappresenta un metodo affidabile per valutare i risultati della ricerca e determinarne l’attendibilità o la necessità di scartarli (Gelman & Carlin, 2014; Loken & Gelman, 2017). Questa mancanza di affidabilità è dovuta all’introduzione di errori sistematici nella stima della grandezza degli effetti, che in alcuni casi possono persino portare a errori nella direzione dell’effetto stesso. Alla luce di queste criticità, non sembrano esserci motivi validi per continuare a fare affidamento su questo approccio.\nAl contrario, l’adozione dell’approccio bayesiano sembra offrire una soluzione più precisa e affidabile per l’analisi dei dati di ricerca. Questo metodo valuta la probabilità delle ipotesi alla luce dei dati osservati, evitando gli errori intrinseci dell’approccio frequentista e fornendo una base più solida per prendere decisioni informate sulla validità dei risultati. In questo modo, l’approccio bayesiano si presenta come un’alternativa più robusta e scientificamente rigorosa.\n\n\n\n\n\n\nRisposte alle domande iniziali\n\n\n\n\n\nOra confrontiamo le previsioni con i risultati ottenuti dalle simulazioni:\n\nSovrastima della grandezza dell’effetto: I risultati pubblicati tendono a essere selezionati sulla base della significatività statistica, il che porta a una sovrastima sistematica della grandezza dell’effetto rispetto alla realtà. Questo fenomeno, noto come errore di tipo M (magnitude), si verifica perché solo gli effetti con valori estremi (per caso) superano la soglia di significatività statistica e vengono pubblicati.\nFalsi positivi e loro frequenza: In uno scenario in cui non esiste alcuna differenza tra i due gruppi (cioè la vera differenza è zero), il test t ha fornito risultati statisticamente significativi nel 5% dei casi, come previsto dalla soglia di α = 0.05. Tuttavia, la selezione dei risultati pubblicati amplifica questo problema, rendendo più probabile che i lettori incontrino falsi positivi nella letteratura scientifica.\nBias nella pubblicazione: Gli studi che riportano risultati significativi hanno maggiore probabilità di essere pubblicati rispetto a quelli che non trovano un effetto significativo. Questo porta a un effetto distorsivo nella letteratura scientifica, in cui i risultati pubblicati tendono a sovrastimare l’effetto reale. Il “filtro della significatività statistica” crea una percezione distorta della realtà scientifica, poiché gli effetti nulli o piccoli tendono a essere sottorappresentati nella letteratura.\nReplicabilità e significatività statistica: Gli studi con effetti piccoli e campioni ridotti sono particolarmente vulnerabili al fallimento della replicazione. Anche quando un effetto reale esiste, la probabilità di ottenerne una stima precisa è bassa, e la replicazione potrebbe risultare in un valore non significativo, generando confusione nella comunità scientifica.\n\nConsiderazioni Finali\nLe simulazioni evidenziano come la significatività statistica, utilizzata come criterio per la pubblicazione, contribuisca a un bias nella selezione dei risultati, distorcendo la percezione della realtà scientifica. Questo fenomeno, noto come “filtro della significatività statistica”, è una delle cause principali della crisi della replicabilità, poiché induce i ricercatori e i lettori a sovrastimare la grandezza e la presenza di effetti studiati.\nPer affrontare queste problematiche, approcci alternativi, come quelli bayesiani, possono offrire soluzioni più robuste, permettendo una valutazione più affidabile delle ipotesi alla luce dei dati osservati.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#esercizi",
    "href": "chapters/replication_crisis/04_s_m_errors.html#esercizi",
    "title": "82  Errori di segno e errori di grandezza",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\n\nPerché la significatività statistica non è un criterio affidabile per valutare la validità dei risultati scientifici?\nSpiega il concetto di “filtro della significatività statistica” e il suo impatto sulla pubblicazione dei risultati.\nQual è la differenza tra errore di tipo M e errore di tipo S? Come influenzano l’interpretazione dei risultati?\nPerché i risultati pubblicati tendono a sovrastimare la grandezza dell’effetto rispetto alla realtà?\nQuali sono le conseguenze della pubblicazione selettiva dei risultati per la replicabilità degli studi?\nPerché gli studi con campioni di piccole dimensioni sono più vulnerabili a errori nella stima della grandezza dell’effetto?\nIn che modo la selezione dei risultati pubblicati altera la percezione della forza degli effetti studiati?\nPerché un test frequentista può portare a una falsa conclusione sulla direzione di un effetto?\nQuali sono le principali differenze tra l’approccio frequentista e quello bayesiano nella valutazione della significatività di un effetto?\nIn che modo l’approccio bayesiano può ridurre il rischio di errori dovuti alla selezione dei risultati basata sulla significatività statistica?\n\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\n\nLa significatività statistica non garantisce la validità di un risultato perché dipende dalla dimensione del campione e da soglie arbitrarie (come p &lt; 0.05). Inoltre, non misura la rilevanza pratica di un effetto, ma solo la probabilità che i dati osservati siano ottenuti sotto l’ipotesi nulla.\nIl “filtro della significatività statistica” si riferisce alla tendenza a pubblicare solo risultati con p &lt; 0.05, tralasciando studi con risultati non significativi. Questo porta a una distorsione nella letteratura scientifica e a una sovrastima della forza degli effetti riportati.\nErrore di tipo M (Magnitude) indica la sovrastima della grandezza dell’effetto nei risultati pubblicati, mentre errore di tipo S (Sign) si riferisce all’errata determinazione della direzione dell’effetto. Questi errori si verificano perché solo gli effetti più estremi tendono a superare il filtro della significatività statistica.\nI risultati pubblicati tendono a sovrastimare la grandezza dell’effetto perché solo gli effetti più grandi (anche per pura casualità) superano la soglia di significatività statistica e vengono pubblicati, mentre quelli più piccoli restano inediti.\nLa pubblicazione selettiva riduce la replicabilità perché introduce una distorsione sistematica nei risultati disponibili. Le repliche spesso non trovano effetti altrettanto grandi o significativi, creando instabilità nella conoscenza scientifica.\nI campioni piccoli aumentano la variabilità delle stime dell’effetto, rendendo più probabile che un risultato significativo sia solo un’oscillazione casuale dei dati piuttosto che un vero effetto replicabile.\nLa selezione dei risultati pubblicati altera la percezione della forza degli effetti perché induce i lettori a credere che gli effetti siano più forti e consistenti di quanto non siano realmente.\nUn test frequentista può portare a una falsa conclusione sulla direzione dell’effetto perché, in campioni piccoli, le stime dell’effetto possono essere fortemente influenzate dal rumore, portando a interpretazioni errate.\nL’approccio frequentista si basa sul valore-p e sulla soglia di significatività, mentre l’approccio bayesiano utilizza la probabilità a posteriori per aggiornare la credibilità delle ipotesi alla luce dei dati osservati. Il metodo bayesiano permette inferenze più flessibili e robuste.\nL’approccio bayesiano riduce il rischio di errori dovuti alla selezione dei risultati perché non si basa su una soglia arbitraria di significatività, ma fornisce un quadro probabilistico della forza dell’effetto, evitando distorsioni dovute alla pubblicazione selettiva.\n\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nIn questo esercizio simuleremo più esperimenti, ognuno con 15 osservazioni, per comprendere come il filtro della significatività statistica possa distorcere le nostre conclusioni sugli effetti osservati.\nObiettivo\n\nComprendere come l’approccio frequentista possa portare a stime errate dell’effetto reale.\nEsplorare gli errori di tipo M (magnitude) e S (sign), derivanti dal filtro della significatività statistica.\n\nStruttura dell’esercizio\n\nSimuliamo esperimenti in cui il vero effetto tra due gruppi è piccolo (Cohen’s d = 0.2). Consideriamo i dati SWLS e due popolazioni che differiscono nel modo indicato. Ipotizziamo che le due popolazioni SWLS siano normali.\nEstraiamo 15 osservazioni per gruppo.\nUsiamo un test t per verificare se la differenza tra i gruppi è significativa.\nRegistriamo solo i risultati con p &lt; 0.05, calcolando la distribuzione degli effetti significativi.\nValutiamo se la stima dell’effetto nei risultati pubblicabili è gonfiata rispetto al vero effetto.\nContiamo i casi in cui il segno dell’effetto è invertito.\n\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\n# Librerie necessarie\nlibrary(ggplot2)\n\n# Impostazioni della simulazione\nset.seed(42)         # Per la riproducibilità\nn_sims &lt;- 50000      # Numero di simulazioni\nn_per_group &lt;- 15    # Numero di osservazioni per gruppo\ntrue_d &lt;- 0.2        # Vero effetto (Cohen's d)\nswls_mean &lt;- 25      # Media ipotizzata per il primo gruppo\nswls_sd &lt;- 5         # Deviazione standard ipotizzata per la SWLS\n\n# Calcolo della media del secondo gruppo sulla base di Cohen's d\nswls_mean_2 &lt;- swls_mean + true_d * swls_sd\n\n# Inizializziamo i vettori per registrare i risultati\neffect_sizes &lt;- c()\nfalse_sign_count &lt;- 0\n\n# Simulazioni\nfor (i in 1:n_sims) {\n  # Generazione dei due gruppi da distribuzioni normali\n  group1 &lt;- rnorm(n_per_group, mean = swls_mean, sd = swls_sd)\n  group2 &lt;- rnorm(n_per_group, mean = swls_mean_2, sd = swls_sd)\n  \n  # Calcolo della dimensione dell'effetto (Cohen's d)\n  mean_diff &lt;- mean(group2) - mean(group1)\n  pooled_sd &lt;- sqrt(((n_per_group - 1) * var(group1) + (n_per_group - 1) * var(group2)) / (2 * n_per_group - 2))\n  d_estimated &lt;- mean_diff / pooled_sd\n  \n  # Test t per confrontare le medie\n  t_test &lt;- t.test(group1, group2, var.equal = TRUE)\n  \n  # Consideriamo solo i risultati statisticamente significativi\n  if (t_test$p.value &lt; 0.05) {\n    effect_sizes &lt;- c(effect_sizes, d_estimated)\n    \n    # Conta i casi in cui il segno è invertito\n    if (d_estimated &lt; 0) {\n      false_sign_count &lt;- false_sign_count + 1\n    }\n  }\n}\n\n# Creazione di un dataframe per la visualizzazione\nres_df &lt;- data.frame(effect_size = effect_sizes)\n\n# Istogramma della dimensione dell'effetto tra i risultati \"significativi\"\nggplot(res_df, aes(x = effect_size)) +\n  geom_histogram(bins = 30, fill = \"blue\", color = \"black\", alpha = 0.7) +\n  geom_vline(xintercept = true_d, color = \"red\", linetype = \"dashed\", size = 1.2) +\n  labs(\n    x = \"Dimensione dell'effetto stimata\",\n    y = \"Frequenza\",\n    title = \"Distribuzione degli effetti significativi (SWLS)\"\n  ) +\n  theme_minimal()\n\n# Output di sintesi\ncat(\"Numero di risultati statisticamente significativi:\", length(effect_sizes), \"\\n\")\ncat(\"Media della dimensione dell'effetto tra i risultati pubblicati:\", mean(effect_sizes), \"\\n\")\ncat(\"Numero di risultati con segno invertito:\", false_sign_count, \"\\n\")\ncat(\"Proporzione di risultati con segno invertito:\", false_sign_count / length(effect_sizes), \"\\n\")\nInterpretazione dei Risultati\n\n\nErrore di tipo M (Magnitude): La media degli effetti stimati nei risultati pubblicati sarà molto più grande di 0.2 (il vero effetto), dimostrando come il filtro della significatività tenda a sovrastimare gli effetti reali.\n\nErrore di tipo S (Sign): Una percentuale dei risultati pubblicabili mostrerà effetti nella direzione sbagliata (d &lt; 0), dimostrando che il processo decisionale basato su p &lt; 0.05 può portare a conclusioni errate.\n\nVisualizzazione: L’istogramma mostrerà che la distribuzione degli effetti significativi è spostata rispetto al vero effetto (linea rossa tratteggiata).\n\nDomande di discussione:\n\nPerché la stima dell’effetto è gonfiata nei risultati pubblicabili?\nCome cambia la situazione aumentando il numero di osservazioni per gruppo?\nQuali strategie alternative potrebbero ridurre questi errori?\n\nApprofondimento:\n\nRipetere l’esperimento con n_per_group = 50 e osservare se l’errore di tipo M diminuisce.\nConfrontare questo approccio con un’analisi Bayesiana per evidenziare il ruolo dell’inferenza basata su probabilità posteriori.\n\nConclusione\nQuesto esercizio mostra chiaramente i problemi dell’approccio frequentista basato su p &lt; 0.05, evidenziando i limiti dell’uso della significatività statistica come filtro decisionale.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/replication_crisis/04_s_m_errors.html#informazioni-sullambiente-di-sviluppo",
    "title": "82  Errori di segno e errori di grandezza",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.12.0 psych_2.5.3     \n#&gt;  [9] scales_1.4.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.2   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.4     stringi_1.8.7      lattice_0.22-7    \n#&gt;  [4] hms_1.1.3          digest_0.6.37      magrittr_2.0.3    \n#&gt;  [7] evaluate_1.0.3     grid_4.5.0         timechange_0.3.0  \n#&gt; [10] RColorBrewer_1.1-3 fastmap_1.2.0      rprojroot_2.0.4   \n#&gt; [13] jsonlite_2.0.0     mnormt_2.1.1       cli_3.6.5         \n#&gt; [16] rlang_1.1.6        withr_3.0.2        yaml_2.3.10       \n#&gt; [19] tools_4.5.0        parallel_4.5.0     tzdb_0.5.0        \n#&gt; [22] pacman_0.5.1       vctrs_0.6.5        R6_2.6.1          \n#&gt; [25] lifecycle_1.0.4    htmlwidgets_1.6.4  pkgconfig_2.0.3   \n#&gt; [28] pillar_1.10.2      gtable_0.3.6       glue_1.8.0        \n#&gt; [31] xfun_0.52          tidyselect_1.2.1   rstudioapi_0.17.1 \n#&gt; [34] farver_2.1.2       htmltools_0.5.8.1  nlme_3.1-168      \n#&gt; [37] labeling_0.4.3     rmarkdown_2.29     compiler_4.5.0",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#bibliografia",
    "href": "chapters/replication_crisis/04_s_m_errors.html#bibliografia",
    "title": "82  Errori di segno e errori di grandezza",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., & Carlin, J. (2014). Beyond Power Calculations: Assessing Type S (Sign) and Type M (Magnitude) Errors. Perspectives on Psychological Science, 9(6), 641–651.\n\n\nLoken, E., & Gelman, A. (2017). Measurement Error and the Replication Crisis. Science, 355(6325), 584–585.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nNelson, L. D., Simmons, J., & Simonsohn, U. (2018). Psychology’s renaissance. Annual review of psychology, 69(1), 511–534.\n\n\nWagenmakers, E.-J., Lee, M., Lodewyckx, T., & Iverson, G. J. (2008). Bayesian versus frequentist inference. Bayesian evaluation of informative hypotheses, 181–207.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_p_values.html",
    "href": "chapters/replication_crisis/05_p_values.html",
    "title": "\n83  La fragilità del p-valore\n",
    "section": "",
    "text": "83.1 Introduzione\nIl codice presentato è ispirato da un post sul blog di Andrew Gelman. L’obiettivo è esplorare la fragilità dei p-valori e la loro variabilità in diverse condizioni sperimentali.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>83</span>  <span class='chapter-title'>La fragilità del *p*-valore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_p_values.html#simulazione",
    "href": "chapters/replication_crisis/05_p_values.html#simulazione",
    "title": "\n83  La fragilità del p-valore\n",
    "section": "\n83.2 Simulazione",
    "text": "83.2 Simulazione\nQuesta simulazione mira a dimostrare quanto i p-valori possano essere instabili e variare significativamente da campione a campione, anche quando i dati provengono da una distribuzione con parametri molto simili. Questo evidenzia come il p-valore, comunemente utilizzato per valutare la significatività statistica di un effetto, possa essere fortemente influenzato dalla variabilità campionaria, specialmente in campioni di piccole dimensioni o con effetti deboli. Gelman & Stern (2006) esprimono questo concetto affermando che:\n\nla differenza tra “significativo” e “non significativo” non è di per sé statisticamente significativa.\n\n\n83.2.1 Logica della Simulazione\n\n\nObiettivo:\n\nDimostrare la variabilità dei p-valori calcolati su diversi campioni estratti da una popolazione con una media molto vicina a zero.\nMostrare come, nonostante l’effetto reale sia piccolo, i p-valori possano variare notevolmente a seconda della variabilità e delle dimensioni del campione.\n\n\n\nSetup della Simulazione:\n\nGeneriamo \\(J = 10\\) campioni indipendenti, ciascuno con un numero ridotto di osservazioni (\\(n = 10\\)), per massimizzare la variabilità dei risultati.\nOgni campione è generato da una distribuzione normale con una media vera di \\(\\mu = 0.05\\) e una deviazione standard di \\(\\sigma = 0.1\\). Questi parametri sono scelti per rendere la media dei campioni vicina a zero, mantenendo una certa variabilità.\n\n\n\nCalcolo della media campionaria:\n\nPer ciascun campione, calcoliamo la media (\\(\\hat{\\mu}\\)) e la deviazione standard (\\(\\hat{\\sigma}\\)).\nLa media del campione (\\(\\hat{\\mu}\\)) è utilizzata come stima del parametro.\n\n\n\nCalcolo del p-valore:\n\nApplichiamo un t-test per ciascun campione per verificare l’ipotesi nulla (\\(H_0\\)) che la media del campione sia zero.\n\nIl p-valore viene calcolato utilizzando la formula classica del t-test:\n\\[\nt = \\frac{\\hat{\\mu}}{\\frac{\\hat{\\sigma}}{\\sqrt{n}}}\n\\]\ndove:\n\n\n\\(\\hat{\\mu}\\) è la media del campione,\n\n\\(\\hat{\\sigma}\\) è la deviazione standard del campione,\n\n\\(n\\) è il numero di osservazioni per campione.\n\n\n\nSuccessivamente, il p-valore è calcolato come:\n\\[\n\\text{p-value} = 2 \\times (1 - \\text{CDF}(|t|))\n\\]\ndove \\(\\text{CDF}\\) è la funzione cumulativa della distribuzione t con \\(n-1\\) gradi di libertà.\n\n\n\n\n83.2.2 Descrizione della Sintassi\nIl codice R è strutturato come segue:\n\n\nGenerazione dei campioni:\n\nCreiamo una lista di campioni (10 campioni in totale), ciascuno con 10 osservazioni, utilizzando la distribuzione normale con media 0.05 e deviazione standard 0.1.\n\n\n\nCalcolo delle medie e dei p-valori:\n\nIteriamo su ciascun campione per calcolare la media (\\(\\hat{\\mu}\\)) e la deviazione standard (\\(\\hat{\\sigma}\\)).\nCalcoliamo il valore statistico \\(t\\) e il corrispondente p-valore utilizzando la distribuzione t.\n\n\n\nStampa dei risultati:\n\nI p-valori vengono arrotondati e stampati per osservare la loro variabilità.\n\n\n\n\n# Imposta il seme per riproducibilità\nset.seed(1234)\n\n# Parametri della simulazione\nJ &lt;- 10              # Numero di campioni indipendenti\nn &lt;- 10              # Numero di osservazioni per campione\ntrue_mean &lt;- 0.05    # Media vera della popolazione\ntrue_sd &lt;- 0.1       # Deviazione standard della popolazione\n\n# Genera i campioni casuali\nsamples &lt;- replicate(J, rnorm(n, mean = true_mean, sd = true_sd), simplify = FALSE)\n\n# Calcola statistiche campionarie e p-valori\nresults &lt;- lapply(samples, function(sample) {\n  sample_mean &lt;- mean(sample)                         # Media campionaria\n  sample_sd &lt;- sd(sample)                             # Deviazione standard campionaria\n  t_statistic &lt;- sample_mean / (sample_sd / sqrt(n))  # Statistica t\n  p_value &lt;- 2 * (1 - pt(abs(t_statistic), df = n - 1))  # p-valore bilaterale\n  list(mean = sample_mean, sd = sample_sd, t = t_statistic, p_value = p_value)\n})\n\n# Converti i risultati in un data frame per facilitarne la visualizzazione\nresults_df &lt;- do.call(rbind, lapply(results, as.data.frame))\nrownames(results_df) &lt;- paste(\"C\", 1:J)\n\n# Visualizza i risultati\nprint(results_df)\n#&gt;          mean      sd       t  p_value\n#&gt; C 1   0.01168 0.09958  0.3711 0.719183\n#&gt; C 2   0.03818 0.10673  1.1313 0.287183\n#&gt; C 3   0.01121 0.06660  0.5320 0.607576\n#&gt; C 4  -0.02662 0.08942 -0.9413 0.371116\n#&gt; C 5  -0.01098 0.07872 -0.4411 0.669552\n#&gt; C 6   0.02211 0.11860  0.5896 0.569941\n#&gt; C 7   0.11166 0.11442  3.0860 0.013013\n#&gt; C 8   0.04577 0.09237  1.5670 0.151566\n#&gt; C 9   0.03415 0.07349  1.4695 0.175755\n#&gt; C 10  0.10607 0.09840  3.4089 0.007763\n\n\nggplot(results_df, aes(x = rownames(results_df), y = p_value)) +\n  geom_point(size = 3, color = \"blue\") +\n  geom_hline(yintercept = 0.05, linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Variabilità dei p-valori nei campioni\",\n    x = \"Campioni\",\n    y = \"p-valore\"\n  ) \n\n\n\n\n\n\n\n\n83.2.3 Interpretazione dei Risultati\nImmaginiamo che questo sia un esperimento reale. Alcuni campioni potrebbero mostrare risultati compatibili con il puro rumore, altri fornire deboli indicazioni contro l’ipotesi nulla, mentre altri ancora potrebbero sembrare altamente significativi dal punto di vista statistico. Tuttavia, la differenza tra “significativo” e “non significativo” non è di per sé statisticamente significativa. Ad esempio, una differenza tra un p-valore di 0.336 e uno di 0.003 potrebbe sembrare rilevante, ma non lo è.\nQuesto scenario estremo riflette una situazione in cui non c’è una reale variazione sottostante. Se si utilizzasse un modello multilivello, probabilmente emergerebbe l’assenza di una variazione effettiva significativa.\n\n83.2.4 Punti Chiave\n\nIl p-valore descrive solo l’ipotesi nulla: È una misura relativa all’assenza di effetto, ma non ha necessariamente un significato diretto rispetto a un effetto reale, anche se piccolo.\nIl p-valore è altamente variabile: Essendo una trasformazione non lineare dello z-score, il p-valore può comportarsi in modi non intuitivi, soprattutto con campioni piccoli.\nLe simulazioni sono istruttive: Anche esperimenti semplici come questo possono essere estremamente utili per comprendere le limitazioni e l’interpretazione dei risultati.\n\n83.2.5 Un Avvertimento Importante\nAnche le inferenze bayesiane sono soggette a variabilità. Qualsiasi sintesi dei dati porta con sé un certo grado di incertezza. Il problema non risiede nei p-valori in sé, ma nel loro utilizzo scorretto. Interpretare un p-valore come una dichiarazione forte sulla realtà, invece di considerarlo un riassunto rumoroso di un esperimento specifico, è un errore comune.\nAllo stesso modo, fraintendimenti e sovrainterpretazioni possono verificarsi anche con approcci bayesiani. Ad esempio, l’adattamento di un modello con prior non informativi e l’interpretazione della probabilità posteriore di un parametro (ad esempio, maggiore di zero) sulla base di una soglia arbitraria può portare a conclusioni altrettanto problematiche. Questi risultati ci ricordano l’importanza di una sana cautela nell’interpretazione statistica, indipendentemente dal metodo utilizzato.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>83</span>  <span class='chapter-title'>La fragilità del *p*-valore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_p_values.html#riflessioni-conclusive",
    "href": "chapters/replication_crisis/05_p_values.html#riflessioni-conclusive",
    "title": "\n83  La fragilità del p-valore\n",
    "section": "\n83.3 Riflessioni Conclusive",
    "text": "83.3 Riflessioni Conclusive\nLa simulazione mostra che, nonostante le medie dei campioni siano generate con una distribuzione simile, i p-valori possono variare drasticamente. Questo effetto è amplificato dalla scelta di campioni piccoli e di una media vera molto vicina all’ipotesi nulla (zero). Dimostra quanto il p-valore possa essere influenzato da piccole variazioni nei dati e perché non sia sempre un indicatore affidabile per valutare l’efficacia o la presenza di un effetto.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>83</span>  <span class='chapter-title'>La fragilità del *p*-valore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_p_values.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/replication_crisis/05_p_values.html#informazioni-sullambiente-di-sviluppo",
    "title": "\n83  La fragilità del p-valore\n",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.12.0 psych_2.5.3     \n#&gt;  [9] scales_1.4.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.2   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.4     stringi_1.8.7      lattice_0.22-7    \n#&gt;  [4] hms_1.1.3          digest_0.6.37      magrittr_2.0.3    \n#&gt;  [7] evaluate_1.0.3     grid_4.5.0         timechange_0.3.0  \n#&gt; [10] RColorBrewer_1.1-3 fastmap_1.2.0      rprojroot_2.0.4   \n#&gt; [13] jsonlite_2.0.0     mnormt_2.1.1       cli_3.6.5         \n#&gt; [16] rlang_1.1.6        withr_3.0.2        tools_4.5.0       \n#&gt; [19] parallel_4.5.0     tzdb_0.5.0         pacman_0.5.1      \n#&gt; [22] vctrs_0.6.5        R6_2.6.1           lifecycle_1.0.4   \n#&gt; [25] htmlwidgets_1.6.4  pkgconfig_2.0.3    pillar_1.10.2     \n#&gt; [28] gtable_0.3.6       glue_1.8.0         xfun_0.52         \n#&gt; [31] tidyselect_1.2.1   rstudioapi_0.17.1  farver_2.1.2      \n#&gt; [34] htmltools_0.5.8.1  nlme_3.1-168       labeling_0.4.3    \n#&gt; [37] rmarkdown_2.29     compiler_4.5.0",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>83</span>  <span class='chapter-title'>La fragilità del *p*-valore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_p_values.html#bibliografia",
    "href": "chapters/replication_crisis/05_p_values.html#bibliografia",
    "title": "\n83  La fragilità del p-valore\n",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., & Stern, H. (2006). The difference between «significant» and «not significant» is not itself statistically significant. The American Statistician, 60(4), 328–331.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>83</span>  <span class='chapter-title'>La fragilità del *p*-valore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html",
    "href": "chapters/replication_crisis/06_changes.html",
    "title": "84  Riforma",
    "section": "",
    "text": "84.1 Introduzione\nLa crisi della riproducibilità ha stimolato un profondo dibattito sullo stato della ricerca nelle scienze comportamentali, cognitive e sociali. La scoperta che molti studi pubblicati non sono replicabili ha minato la fiducia nella ricerca scientifica, evidenziando carenze metodologiche e strutturali nel sistema accademico. In risposta a questa crisi, sono state avanzate diverse proposte di riforma per migliorare la qualità e l’affidabilità della ricerca scientifica.\nSecondo Korbmacher et al. (2023), sono necessarie riforme strutturali, cambiamenti procedurali e trasformazioni nella comunità scientifica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#riforme-strutturali",
    "href": "chapters/replication_crisis/06_changes.html#riforme-strutturali",
    "title": "84  Riforma",
    "section": "84.2 Riforme Strutturali",
    "text": "84.2 Riforme Strutturali\n\n84.2.1 Integrazione della Riproducibilità nei Curriculum Educativi\nUna proposta chiave per affrontare la crisi della riproducibilità è l’integrazione delle pratiche di riproducibilità nei curriculum delle scienze psicologiche e affini. Attualmente, molti programmi di formazione non enfatizzano sufficientemente l’importanza della replicabilità e della trasparenza nella ricerca. Includere questi temi nei corsi di metodologia della ricerca può sensibilizzare le nuove generazioni di ricercatori sull’adozione di pratiche più rigorose e trasparenti. Alcuni programmi universitari hanno già iniziato a incorporare repliche di studi famosi nel percorso formativo, offrendo agli studenti l’opportunità di comprendere meglio i limiti e le potenzialità del processo scientifico.\n\n\n84.2.2 Incentivi per la Scienza Aperta\nUn altro aspetto cruciale è la riforma dei sistemi di incentivazione accademica. Tradizionalmente, il sistema accademico ha privilegiato la quantità di pubblicazioni e la novità dei risultati, piuttosto che la loro qualità e replicabilità. Per promuovere pratiche di scienza aperta, come la preregistrazione degli studi e la condivisione aperta dei dati, si propone l’introduzione di riconoscimenti ufficiali, come badge di “open science” o crediti accademici per la pubblicazione di rapporti registrati. Questi cambiamenti potrebbero favorire una maggiore adozione di pratiche che promuovono la trasparenza e rafforzano la fiducia nella ricerca scientifica.\nA tal proposito, uno studio di Scheel et al. (2021) ha confrontato i risultati di rapporti registrati pubblicati (N = 71) con un campione casuale di studi ipotetico-deduttivi della letteratura standard (N = 152) in psicologia. Analizzando la prima ipotesi di ciascun articolo, è emerso che il 96% dei risultati nei rapporti standard erano positivi, contro solo il 44% nei rapporti registrati.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#cambiamenti-procedurali",
    "href": "chapters/replication_crisis/06_changes.html#cambiamenti-procedurali",
    "title": "84  Riforma",
    "section": "84.3 Cambiamenti Procedurali",
    "text": "84.3 Cambiamenti Procedurali\n\n84.3.1 Mercati di Previsione per la Credibilità della Ricerca\nI mercati di previsione sono stati proposti come strumento innovativo per valutare la credibilità della ricerca. In questi mercati, esperti e non esperti scommettono sulla probabilità che i risultati di determinati studi siano replicabili. Questo approccio ha dimostrato un’elevata accuratezza nella classificazione della replicabilità degli studi, offrendo un metodo alternativo e complementare alla replicazione diretta. I mercati di previsione potrebbero essere particolarmente utili in contesti in cui la raccolta dati è costosa o difficile, fornendo una prima indicazione sulla solidità dei risultati di ricerca.\n\n\n84.3.2 Strumenti di Valutazione Statistica\nUn’altra proposta riguarda l’adozione di nuovi strumenti di valutazione statistica per identificare e correggere il bias di pubblicazione e migliorare la potenza degli studi. Strumenti come la curva-p e la curva-z sono stati sviluppati per analizzare la distribuzione dei valori p e identificare eventuali distorsioni nei risultati pubblicati. Inoltre, alcuni studiosi hanno suggerito di abbassare il livello di significatività statistica standard da 0,05 a 0,005 per ridurre il tasso di falsi positivi e aumentare la robustezza dei risultati. Queste proposte rappresentano passi importanti verso una maggiore precisione nelle analisi statistiche.\n\n\n84.3.3 Analisi Multiverso\nL’analisi multiverso è un’altra proposta innovativa che mira a gestire la molteplicità di scelte analitiche possibili in un singolo studio. Questa tecnica prevede l’esecuzione di molteplici analisi su uno stesso dataset, variando i parametri e le scelte metodologiche, per testare la stabilità dei risultati. L’adozione di questo approccio permette di evidenziare quanto i risultati siano sensibili alle scelte analitiche, contribuendo a una maggiore trasparenza e affidabilità nelle conclusioni tratte dagli studi.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#cambiamenti-nella-comunità",
    "href": "chapters/replication_crisis/06_changes.html#cambiamenti-nella-comunità",
    "title": "84  Riforma",
    "section": "84.4 Cambiamenti nella Comunità",
    "text": "84.4 Cambiamenti nella Comunità\n\n84.4.1 Big Team Science\nIl concetto di “Big Team Science” rappresenta un cambiamento significativo nella modalità di condurre ricerca. Questo approccio prevede la collaborazione su larga scala tra scienziati di diversi paesi e discipline, con l’obiettivo di replicare studi, raccogliere grandi campioni e condividere risorse. Questo modello di lavoro collettivo non solo aumenta l’efficienza della ricerca, ma promuove anche una maggiore diversità nei campioni e nei team di ricerca. Tuttavia, esistono anche criticità, come la possibilità di perpetuare disuguaglianze tra ricercatori di paesi sviluppati e in via di sviluppo, e la difficoltà nel riconoscere adeguatamente i contributi individuali all’interno di grandi consorzi.\n\n\n84.4.2 Collaborazioni Avversariali\nLe collaborazioni avversariali rappresentano un altro approccio interessante per migliorare la qualità della ricerca. In queste collaborazioni, ricercatori con visioni teoriche contrastanti lavorano insieme per progettare e condurre studi che testino le loro ipotesi in modo rigoroso. Questo tipo di collaborazione può ridurre i bias personali e promuovere un confronto costruttivo, portando a conclusioni più solide e condivise all’interno della comunità scientifica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#crisi-della-generalizzabilità",
    "href": "chapters/replication_crisis/06_changes.html#crisi-della-generalizzabilità",
    "title": "84  Riforma",
    "section": "84.5 Crisi della Generalizzabilità",
    "text": "84.5 Crisi della Generalizzabilità\nYarkoni (2022) affronta la questione critica della scarsa validità delle inferenze quantitative presenti nella letteratura psicologica pubblicata, proponendo tre strategie principali per migliorare la qualità della ricerca in psicologia.\n\n84.5.1 Do Something Else\nIl primo suggerimento è di considerare l’abbandono della ricerca psicologica quantitativa quando risulta troppo difficile estrarre conclusioni significative e generalizzabili da effetti complessi e variabili. L’autore critica la tendenza a concludere ogni contributo di ricerca con una nota positiva, indipendentemente dalle evidenze raccolte. In alcuni casi, potrebbe essere più saggio riconoscere i limiti della ricerca e scegliere percorsi di carriera alternativi, specialmente per i ricercatori alle prime armi.\n\n\n84.5.2 Abbracciare l’Analisi Qualitativa\nLa seconda opzione proposta è continuare a fare ricerca psicologica, ma abbandonando in gran parte i metodi statistici inferenziali a favore di metodi qualitativi. L’autore sostiene che gran parte della scienza quantitativa in psicologia sia in realtà un’analisi qualitativa mascherata. In molti casi, l’analisi qualitativa potrebbe fornire risposte più profonde e significative rispetto a un approccio quantitativo superficiale.\n\n\n84.5.3 Adottare Standard Migliori\nLa terza strategia consiste nel migliorare gli standard della ricerca quantitativa in psicologia per renderla più rigorosa e affidabile. L’autore propone diverse pratiche, tra cui:\n\nInferenze più conservative: Evitare generalizzazioni ampie basate su dati limitati.\nRicerca descrittiva: Prendere più seriamente la ricerca descrittiva, che si concentra sulla caratterizzazione delle relazioni tra variabili.\nModelli statistici più espansivi: Utilizzare modelli che considerino una più ampia gamma di variabili e fattori.\nProgettare con la variazione in mente: Abbracciare la variabilità naturale delle condizioni sperimentali.\nStime della varianza: Porre maggiore enfasi sull’analisi delle componenti della varianza.\nPredizioni più rischiose: Formulare predizioni teoriche che comportino un alto grado di rischio.\nUtilità predittiva pratica: Concentrarsi sull’utilità pratica delle predizioni piuttosto che su considerazioni puramente teoriche.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#sviluppare-teorie-formali",
    "href": "chapters/replication_crisis/06_changes.html#sviluppare-teorie-formali",
    "title": "84  Riforma",
    "section": "84.6 Sviluppare Teorie Formali",
    "text": "84.6 Sviluppare Teorie Formali\nOltre alle carenze metodologiche o statistiche, è stato spesso sottolineato che la crisi di replicabilità trova le sue radici nella mancanza di un quadro teorico cumulativo. Senza un quadro teorico generale che generi ipotesi in diversi ambiti, i programmi empirici si sviluppano a partire da intuizioni personali e teorie popolari influenzate culturalmente. Fornendo strumenti per formulare previsioni chiare, anche attraverso l’uso di modelli formali, i quadri teorici stabiliscono aspettative che permettono di determinare se un nuovo risultato conferma le ricerche esistenti, integrandosi con esse, oppure se è inaspettato e, pertanto, richiede ulteriori verifiche e approfondimenti (Muthukrishna & Henrich, 2019).",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#riflessioni-conclusive",
    "href": "chapters/replication_crisis/06_changes.html#riflessioni-conclusive",
    "title": "84  Riforma",
    "section": "84.7 Riflessioni Conclusive",
    "text": "84.7 Riflessioni Conclusive\nL’ampio utilizzo dei test statistici frequentisti in psicologia risulta spesso fuorviante, poiché attribuisce un’apparenza di rigore scientifico a inferenze che, in realtà, sono principalmente qualitative. Si rende quindi necessaria una profonda riforma delle pratiche di ricerca, volta a promuovere una maggiore trasparenza e precisione, oltre a incoraggiare la disponibilità a mettere in discussione e abbandonare approcci metodologici che non superano una rigorosa analisi critica (Yarkoni, 2022).\nLa crisi di replicabilità ha spinto verso una serie di riforme con il potenziale di trasformare positivamente la ricerca psicologica. Tra queste iniziative vi sono la promozione della scienza aperta, l’adozione di standard metodologici più rigorosi e una maggiore attenzione a pratiche di ricerca che privilegiano la qualità e la replicabilità dei risultati rispetto alla loro quantità e novità. Sebbene questi cambiamenti possano sembrare meno spettacolari rispetto ai metodi attualmente utilizzati, essi rappresentano un percorso fondamentale per garantire la credibilità e la sostenibilità a lungo termine della disciplina.\nAffinché queste riforme abbiano un impatto duraturo, è essenziale un cambiamento strutturale a tutti i livelli della comunità scientifica:\n\nI ricercatori devono impegnarsi ad adottare pratiche più rigorose e trasparenti, privilegiando la solidità metodologica e la replicabilità dei loro studi.\nGli enti finanziatori devono incentivare la qualità e la replicabilità degli studi, piuttosto che premiare esclusivamente la produzione di risultati innovativi o appariscenti.\nLe istituzioni accademiche devono rivedere i criteri di valutazione del merito scientifico, dando maggior peso all’impatto a lungo termine delle ricerche e alla loro solidità metodologica.\nLe riviste scientifiche devono assicurarsi che i risultati pubblicati siano realmente robusti e generalizzabili, anziché limitarsi a privilegiare i risultati nuovi o sorprendenti.\n\nQuesti cambiamenti, sebbene complessi e talvolta impopolari, sono fondamentali per ristabilire la fiducia nel processo scientifico e per garantire che la ricerca psicologica continui a offrire contributi utili e affidabili nella comprensione della mente umana e del comportamento.\nIn conclusione, la sfida posta dalla crisi di replicabilità offre un’opportunità unica per ridefinire e rafforzare le fondamenta metodologiche della ricerca psicologica. Abbracciando questi cambiamenti, la psicologia può emergere come una disciplina più robusta, trasparente e affidabile, capace di fornire intuizioni utili e durature sul funzionamento della mente e del comportamento umano.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#bibliografia",
    "href": "chapters/replication_crisis/06_changes.html#bibliografia",
    "title": "84  Riforma",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nKorbmacher, M., Azevedo, F., Pennington, C. R., Hartmann, H., Pownall, M., Schmidt, K., Elsherif, M., Breznau, N., Robertson, O., Kalandadze, T., et al. (2023). The replication crisis has led to positive structural, procedural, and community changes. Communications Psychology, 1(1), 3.\n\n\nMuthukrishna, M., & Henrich, J. (2019). A problem in theory. Nature Human Behaviour, 3(3), 221–229.\n\n\nScheel, A. M., Schijen, M. R., & Lakens, D. (2021). An excess of positive results: Comparing the standard psychology literature with registered reports. Advances in Methods and Practices in Psychological Science, 4(2), 25152459211007467.\n\n\nYarkoni, T. (2022). The generalizability crisis. Behavioral and Brain Sciences, 45, e1.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_piranha.html",
    "href": "chapters/replication_crisis/07_piranha.html",
    "title": "85  Il Problema del priming: sfide e paradossi nella psicologia sociale",
    "section": "",
    "text": "85.1 Introduzione\nUn recente articolo di Tosh et al. (2025) affronta una questione centrale per la psicologia e la crisi della replicabilità: il cosiddetto “problema del piranha”. Questo argomento riguarda la convinzione, diffusa in molti studi psicologici, che piccoli interventi (o “nudges”), apparentemente insignificanti, possano generare effetti notevoli sul comportamento. L’articolo dimostra formalmente, con il supporto del teorema di Van der Corput (Tao, 2014), che se tali effetti fossero davvero così grandi e consistenti, allora sarebbe possibile manipolare il comportamento umano in modi empiricamente irrealistici.\nIn altre parole, la letteratura psicologica spesso riporta effetti di dimensioni tali che richiederebbero assunzioni incompatibili con le evidenze empiriche. Questi risultati suggeriscono che le affermazioni di grandi effetti indipendenti sono più probabilmente attribuibili a problemi metodologici, come bassa potenza statistica o “gradi di libertà del ricercatore” (Simmons et al., 2011).",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>85</span>  <span class='chapter-title'>Il Problema del priming: sfide e paradossi nella psicologia sociale</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_piranha.html#il-problema-del-piranha",
    "href": "chapters/replication_crisis/07_piranha.html#il-problema-del-piranha",
    "title": "85  Il Problema del priming: sfide e paradossi nella psicologia sociale",
    "section": "85.2 Il problema del piranha",
    "text": "85.2 Il problema del piranha\nTosh et al. (2025) evidenziano che, in un sistema complesso, se molte variabili esplicative hanno un forte impatto su una singola variabile di esito, queste devono inevitabilmente mostrare interazioni o correlazioni rilevanti tra loro.\n\n85.2.1 Punti chiave del problema\n\nEffetti ampi e interazioni: Il “problema del piranha” sottolinea che è improbabile che molte variabili esplicative abbiano effetti ampi e indipendenti su una singola variabile di esito all’interno di un sistema stabile. Questo principio si basa sulla disuguaglianza di Van der Corput, che dimostra come l’aumento del numero di variabili con grandi effetti richieda una considerazione delle loro interazioni. Tali interazioni generano una rete complessa di influenze, rendendo difficile isolare l’impatto di un singolo fattore. Gli effetti osservati in un dato studio potrebbero non essere generalizzabili, poiché dipendono dai livelli di altre variabili presenti nello stesso contesto.\nAnalogia con i piranha: L’analogia del piranha descrive un sistema sovraffollato di variabili esplicative con grandi effetti, che interagiscono tra loro fino a ridurre la stabilità complessiva. Proprio come i piranha in un acquario competono tra loro fino a ridurre il loro numero, un sistema con molte variabili di forte impatto tende a generare interazioni che limitano la prevedibilità e la stabilità del sistema. In altre parole, gli effetti individuali vengono alterati, ridotti o cancellati attraverso la competizione tra variabili.\n\n\n\n85.2.2 Rilevanza per la crisi di replicabilità\nIl problema del piranha offre una prospettiva cruciale per comprendere le cause della crisi di replicabilità nella psicologia e nelle scienze sociali. Secondo Tosh et al. (2025), questa crisi non è attribuibile soltanto a problemi metodologici come la bassa potenza statistica, ma riflette un limite intrinseco dell’idea stessa che numerosi grandi effetti indipendenti possano coesistere in un sistema complesso.\nI teoremi discussi nell’articolo dimostrano che un sistema stabile non può contenere numerosi effetti forti e indipendenti senza generare predizioni empiricamente insostenibili. Ciò implica che la ricerca di molteplici “grandi effetti” rischia di essere basata su assunzioni irrealistiche riguardo alla natura delle interazioni tra variabili.\nIl problema del piranha è particolarmente rilevante per la psicologia, dove spesso si cercano numerose cause indipendenti per spiegare fenomeni complessi. Tosh et al. (2025) mettono in discussione non tanto i singoli effetti riportati, quanto l’assunzione di base secondo cui il comportamento umano e le interazioni sociali sarebbero influenzati da un gran numero di effetti indipendenti.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>85</span>  <span class='chapter-title'>Il Problema del priming: sfide e paradossi nella psicologia sociale</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_piranha.html#il-priming-nella-psicologia-sociale",
    "href": "chapters/replication_crisis/07_piranha.html#il-priming-nella-psicologia-sociale",
    "title": "85  Il Problema del priming: sfide e paradossi nella psicologia sociale",
    "section": "85.3 Il priming nella psicologia sociale",
    "text": "85.3 Il priming nella psicologia sociale\nUno degli esempi analizzati da Tosh et al. (2025) riguarda la ricerca sul priming sociale, una linea di indagine ampiamente discussa e criticata nella psicologia sociale (si veda anche Leys, 2024). Gli autori utilizzano uno studio classico per illustrare le loro argomentazioni: un esperimento del 1996 condotto da Bargh et al. (1996), in cui i partecipanti riorganizzavano frasi contenenti parole associate alla vecchiaia (ad esempio, “Florida” o “solo”). I risultati riportavano che questi partecipanti camminavano più lentamente rispetto a un gruppo di controllo, con una riduzione del 13% nella velocità di camminata (Bargh et al., 1996).\nL’idea che una manipolazione così semplice possa produrre un effetto tanto marcato è stata successivamente oggetto di numerose critiche. I tentativi di replicare lo studio non hanno avuto successo, e il lavoro di Bargh et al. (1996) è ora considerato un esempio emblematico di risultati impossibili da replicare. Questo studio rappresenta solo uno dei molti casi in cui sono stati riportati effetti sorprendentemente grandi per manipolazioni apparentemente insignificanti.\nTosh et al. (2025) sostengono che, se davvero piccoli interventi (nudges) producono effetti così rilevanti, emergerebbe inevitabilmente il problema delle interazioni con numerosi altri fattori già noti per influire sul comportamento umano. La letteratura psicologica include infatti studi che attribuiscono grandi effetti a fattori come ormoni, immagini subliminali, notizie di partite di calcio o attacchi di squali, incontri casuali con sconosciuti, stato socioeconomico dei genitori, condizioni meteorologiche, l’ultima cifra dell’età, il genere del nome di un uragano, e molti altri. Secondo gli autori, se tutti questi fattori influenzassero realmente un singolo esito, le loro interazioni diventerebbero incredibilmente complesse e imprevedibili, rendendo impossibile individuare effetti stabili e replicabili.\nPer illustrare l’assurdità di alcuni di questi risultati, Tosh et al. (2025) propongono un esempio ipotetico. Supponiamo che 100 nudges producano ciascuno un effetto del 13% sulla velocità di camminata, come riportato da Bargh et al. (1996). Se questi effetti fossero indipendenti, l’effetto combinato sarebbe enorme: la velocità di camminata potrebbe facilmente raddoppiare, dimezzarsi o variare ancora di più. Tuttavia, tali variazioni sono empiricamente irrealistiche. In altre parole, le assunzioni su cui si basano molte di queste ricerche porterebbero a predizioni che non trovano riscontro nei dati osservabili.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>85</span>  <span class='chapter-title'>Il Problema del priming: sfide e paradossi nella psicologia sociale</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_piranha.html#riflessioni-conclusive",
    "href": "chapters/replication_crisis/07_piranha.html#riflessioni-conclusive",
    "title": "85  Il Problema del priming: sfide e paradossi nella psicologia sociale",
    "section": "85.4 Riflessioni Conclusive",
    "text": "85.4 Riflessioni Conclusive\nIl “problema del piranha” evidenzia i limiti intrinseci nell’assumere che numerosi effetti indipendenti e di grande entità possano coesistere all’interno di un sistema complesso. In realtà, tali effetti devono necessariamente interagire tra loro o essere correlati, rendendo improbabile la loro indipendenza. Questa dinamica crea instabilità nel sistema e porta a variazioni degli effetti nel tempo o tra popolazioni, compromettendo la possibilità di generalizzarne i risultati.\nTosh et al. (2025) suggeriscono che molti risultati pubblicati, che riportano effetti improbabilmente grandi, siano attribuibili non tanto a reali fenomeni psicologici, quanto a problemi metodologici, come bassa potenza statistica e i “gradi di libertà del ricercatore” (Simmons et al., 2011). La proliferazione di questi risultati contribuisce alla crisi di replicabilità, poiché i presunti effetti si rivelano spesso instabili o non replicabili.\nLa consapevolezza dei limiti imposti dal problema del piranha invita la ricerca psicologica a focalizzarsi maggiormente sulla robustezza metodologica, sull’identificazione di effetti plausibili e sulla considerazione delle interazioni tra variabili. Piuttosto che cercare di identificare molteplici grandi effetti, è essenziale riconoscere che un sistema complesso, per essere stabile e prevedibile, richiede un approccio che consideri l’interdipendenza delle variabili e la struttura complessiva del sistema. Questo approccio può contribuire a migliorare la validità e la replicabilità della ricerca nelle scienze sociali.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>85</span>  <span class='chapter-title'>Il Problema del priming: sfide e paradossi nella psicologia sociale</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_piranha.html#bibliografia",
    "href": "chapters/replication_crisis/07_piranha.html#bibliografia",
    "title": "85  Il Problema del priming: sfide e paradossi nella psicologia sociale",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBargh, J. A., Chen, M., & Burrows, L. (1996). Automaticity of social behavior: Direct effects of trait construct and stereotype activation on action. Journal of Personality and Social Psychology, 71(2), 230–244.\n\n\nLeys, R. (2024). Anatomy of a Train Wreck: The Rise and Fall of Priming Research. University of Chicago Press.\n\n\nSimmons, J. P., Nelson, L. D., & Simonsohn, U. (2011). False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant. Psychological science, 22(11), 1359–1366.\n\n\nTosh, C., Greengard, P., Goodrich, B., Gelman, A., Vehtari, A., & Hsu, D. (2025). The Piranha Problem: Large Effects Swimming in a Small Pond. Notices of the American Mathematical Society.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>85</span>  <span class='chapter-title'>Il Problema del priming: sfide e paradossi nella psicologia sociale</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_degrees_of_freedom.html",
    "href": "chapters/replication_crisis/08_degrees_of_freedom.html",
    "title": "86  I gradi di libertà del ricercatore",
    "section": "",
    "text": "86.1 Introduzione\nLo studio di Gould et al. (2025), ripreso dalla rivista Science (O’Grady, 2025), mostra come le scelte analitiche dei ricercatori possano generare una variabilità significativa nei risultati, persino quando si utilizzano gli stessi dati e si affronta la medesima domanda di ricerca in ecologia e biologia evolutiva. Questa discrepanza supera di gran lunga l’errore statistico atteso, rivelando un problema sistemico che trascende i confini disciplinari.\nI risultati concordano con quelli di precedenti progetti “many analysts” – tra cui il pionieristico lavoro in psicologia di Silberzahn et al. (2018) – e sottolineano, come evidenziato dallo psicologo Eric Uhlmann, “il ruolo cruciale delle decisioni soggettive nella pratica scientifica”. Ciò conferma che la fragilità metodologica non è un’esclusiva della psicologia, ma riguarda settori come le neuroscienze, le scienze sociali e, appunto, l’ecologia.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>I gradi di libertà del ricercatore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_degrees_of_freedom.html#metodologia",
    "href": "chapters/replication_crisis/08_degrees_of_freedom.html#metodologia",
    "title": "86  I gradi di libertà del ricercatore",
    "section": "86.2 Metodologia",
    "text": "86.2 Metodologia\nGould et al. (2025) hanno coinvolto 174 team di ricerca (246 analisti) nell’analisi indipendente di due dataset inediti:\n\nEcologia evolutiva: relazione tra numero di fratelli e crescita dei pulcini di cinciallegra (Cyanistes caeruleus).\nEcologia della conservazione: impatto della copertura erbosa sul reclutamento di piantine di Eucalyptus.\n\nOgni team ha risposto a una domanda specifica:\n\nDataset cinciallegra: “Quanto la competizione tra fratelli influenza la crescita dei pulcini?”\nDataset eucalipto: “In che modo la copertura erbosa condiziona il reclutamento di piantine?”\n\nI ricercatori hanno fornito risultati, giustificazioni metodologiche, codice analitico e hanno sottoposto le procedure a peer review incrociata, creando un sistema di controllo reciproco.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>I gradi di libertà del ricercatore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_degrees_of_freedom.html#risultati",
    "href": "chapters/replication_crisis/08_degrees_of_freedom.html#risultati",
    "title": "86  I gradi di libertà del ricercatore",
    "section": "86.3 Risultati",
    "text": "86.3 Risultati\nLo studio ha evidenziato eterogeneità estrema nelle conclusioni, nonostante l’uniformità dei dati di partenza:\n\nCinciallegra: L’effetto medio negativo (più fratelli = minore crescita) nascondeva un’ampia dispersione, con stime da -0.8 a +0.2 (Figura 1a).\nEucalipto: La relazione media era debolmente negativa e non significativa, ma con outlier che invertivano la tendenza (Figura 1b).\n\n\n\n\n\n\n\nFigura 86.1: Distribuzione degli effetti standardizzati nei due dataset: crescita dei pulcini (sinistra) e reclutamento di piantine (destra) (adattata da Gould et al., 2025).\n\n\n\nSorprendentemente, né la selezione di variabili, né l’uso di effetti casuali, né il giudizio dei revisori correlavano con la distanza dalla media meta-analitica. In altre parole, risultati divergenti non erano associati a scelte metodologicamente “peggiori”, ma a combinazioni altrettanto valide di decisioni analitiche.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>I gradi di libertà del ricercatore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_degrees_of_freedom.html#il-problema-dei-gradi-di-libertà-del-ricercatore",
    "href": "chapters/replication_crisis/08_degrees_of_freedom.html#il-problema-dei-gradi-di-libertà-del-ricercatore",
    "title": "86  I gradi di libertà del ricercatore",
    "section": "86.4 Il Problema dei Gradi di Libertà del Ricercatore",
    "text": "86.4 Il Problema dei Gradi di Libertà del Ricercatore\nIl lavoro illustra chiaramente come i “gradi di libertà analitici” – le molteplici opzioni durante l’analisi dati – possano generare conclusioni divergenti. Tra le decisioni critiche:\n\nGestione di outlier e dati mancanti.\nDefinizione operativa delle variabili.\nScelta di modelli statistici e controlli.\n\nQueste scelte, spesso soggettive ma teoricamente giustificabili, definiscono un “spazio analitico” con migliaia di percorsi possibili. Ogni studio pubblicato rappresenta dunque una singola traiettoria in questo labirinto metodologico, rischiando di offrire una visione parziale e potenzialmente distorta.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>I gradi di libertà del ricercatore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_degrees_of_freedom.html#implicazioni-e-strategie-di-mitigazione",
    "href": "chapters/replication_crisis/08_degrees_of_freedom.html#implicazioni-e-strategie-di-mitigazione",
    "title": "86  I gradi di libertà del ricercatore",
    "section": "86.5 Implicazioni e Strategie di Mitigazione",
    "text": "86.5 Implicazioni e Strategie di Mitigazione\nLa variabilità sistematica impone una revisione delle pratiche di ricerca:\n\nAnalisi di sensibilità avanzate:\n\nAnalisi multiverso: testare tutte le combinazioni plausibili di scelte metodologiche.\nCurve di specificazione: mappare come i risultati variano al mutare delle assunzioni.\n\nModelli aggregati: Combinare stime da approcci diversi (es., Bayesian Model Averaging) per ridurre la dipendenza da singole specifiche.\n\nTrasparenza procedurale:\n\nPreregistrazione: fissare ipotesi e metodi prima di accedere ai dati.\nPubblicazione di codice e dati grezzi.\n\nFormazione metodologica: Rafforzare le competenze statistiche, con enfasi sulla gestione della complessità analitica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>I gradi di libertà del ricercatore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_degrees_of_freedom.html#riflessioni-conclusive",
    "href": "chapters/replication_crisis/08_degrees_of_freedom.html#riflessioni-conclusive",
    "title": "86  I gradi di libertà del ricercatore",
    "section": "86.6 Riflessioni Conclusive",
    "text": "86.6 Riflessioni Conclusive\nQuesto studio dimostra empiricamente che l’affidabilità della scienza dipende non solo dai dati, ma da come li analizziamo. La variabilità indotta dai gradi di libertà del ricercatore mina la riproducibilità, soprattutto in contesti con elevata discrezionalità analitica. La soluzione non è l’uniformità metodologica, ma una cultura della trasparenza e della pluralità analitica, dove ogni risultato sia esplicitamente contestualizzato nel suo spazio di scelte possibili. Solo così ecologia, psicologia e discipline affini potranno produrre conoscenze solide e autocritiche.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>I gradi di libertà del ricercatore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/08_degrees_of_freedom.html#bibliografia",
    "href": "chapters/replication_crisis/08_degrees_of_freedom.html#bibliografia",
    "title": "86  I gradi di libertà del ricercatore",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGould, E., Fraser, H. S., Parker, T. H., Nakagawa, S., Griffith, S. C., Vesk, P. A., Fidler, F., Hamilton, D. G., Abbey-Lee, R. N., Abbott, J. K., et al. (2025). Same data, different analysts: variation in effect sizes due to analytical decisions in ecology and evolutionary biology. BMC biology, 23(1), 35.\n\n\nO’Grady, C. (2025). Given the same data, ecologists arrive at different conclusions. Science, 387(6738), 1026.\n\n\nSilberzahn, R., Uhlmann, E. L., Martin, D. P., Anselmi, P., Aust, F., Awtrey, E., Bahnı́k, Š., Bai, F., Bannard, C., Bonnier, E., et al. (2018). Many analysts, one data set: Making transparent how variations in analytic choices affect results. Advances in Methods and Practices in Psychological Science, 1(3), 337–356.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>I gradi di libertà del ricercatore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/09_integrity.html",
    "href": "chapters/replication_crisis/09_integrity.html",
    "title": "87  Integrità della ricerca",
    "section": "",
    "text": "87.1 Introduzione\nL’integrità della ricerca si fonda su principi e standard professionali volti a garantire l’affidabilità e la qualità degli studi scientifici. Essa si distingue dall’etica della ricerca, che invece si concentra sui principi morali. Elementi chiave per l’integrità includono la condivisione dei dati, il consenso informato e la trasparenza nelle pratiche di ricerca. I codici di condotta svolgono un ruolo cruciale nel guidare i comportamenti etici sia dei ricercatori che delle istituzioni. Tra le principali sfide da affrontare vi sono le pratiche di ricerca discutibili, la fabbricazione e falsificazione dei dati, il plagio e la gestione dei conflitti di interesse. Promuovere una cultura della ricerca basata su onestà, trasparenza e rispetto dei principi etici è essenziale per preservare l’integrità scientifica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Integrità della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/09_integrity.html#standard-professionali-nei-codici-di-condotta-per-lintegrità-della-ricerca",
    "href": "chapters/replication_crisis/09_integrity.html#standard-professionali-nei-codici-di-condotta-per-lintegrità-della-ricerca",
    "title": "87  Integrità della ricerca",
    "section": "87.2 Standard Professionali nei Codici di Condotta per l’Integrità della Ricerca",
    "text": "87.2 Standard Professionali nei Codici di Condotta per l’Integrità della Ricerca\nNel contesto della ricerca, aderire a principi di condotta responsabile è fondamentale. Questi principi, spesso definiti come buone pratiche di ricerca, stabiliscono standard professionali che mirano a ottimizzare la qualità e l’affidabilità degli studi. Sebbene i concetti di base su cosa costituisca una buona pratica di ricerca rimangano stabili nel tempo, la loro applicazione pratica si evolve in risposta a cambiamenti sociali, politici e tecnologici. Un esempio significativo di questa evoluzione è l’enfasi crescente sulla condivisione dei dati di ricerca, resa possibile dall’uso di repository online gratuiti. Ciò ha portato a un’aspettativa diffusa di trasparenza e accessibilità dei dati. Allo stesso modo, la condivisione del codice utilizzato per analizzare i dati è diventata una pratica sempre più incoraggiata.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Integrità della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/09_integrity.html#differenziazione-tra-integrità-ed-etica-della-ricerca",
    "href": "chapters/replication_crisis/09_integrity.html#differenziazione-tra-integrità-ed-etica-della-ricerca",
    "title": "87  Integrità della ricerca",
    "section": "87.3 Differenziazione tra Integrità ed Etica della Ricerca",
    "text": "87.3 Differenziazione tra Integrità ed Etica della Ricerca\nL’integrità della ricerca si basa su standard professionali, mentre l’etica della ricerca si fonda su principi morali come l’autonomia, la beneficenza, la non-maleficenza e la giustizia. Questi principi etici si traducono in pratiche specifiche, quali il consenso informato e la garanzia di verità e riservatezza nei confronti dei partecipanti. I ricercatori hanno l’obbligo di evitare studi che possano causare danni o risultare eccessivamente onerosi per i soggetti coinvolti.\nI codici di condotta per l’integrità della ricerca presentano alcune variazioni tra le diverse fonti. Ad esempio, il Codice di condotta europeo per l’integrità della ricerca sottolinea l’importanza di principi come onestà, trasparenza, accuratezza, responsabilità, affidabilità, rispetto e indipendenza. Questi principi si traducono in comportamenti specifici attesi sia dai ricercatori che dalle istituzioni, come la condivisione dei dati nel rispetto delle normative sulla protezione dei dati, tra cui il GDPR europeo.\nUn esempio pratico di come gli standard si siano evoluti è rappresentato dalla condivisione dei dati di ricerca. In passato, questa pratica era limitata dalla mancanza di infrastrutture adeguate. Oggi, grazie ai repository online e alla pressione esercitata da riviste scientifiche e finanziatori, la condivisione dei dati è diventata una pratica standard, riflettendo un cambiamento verso una maggiore apertura e trasparenza.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Integrità della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/09_integrity.html#pressioni-e-sfide-nelladesione-ai-codici-di-condotta",
    "href": "chapters/replication_crisis/09_integrity.html#pressioni-e-sfide-nelladesione-ai-codici-di-condotta",
    "title": "87  Integrità della ricerca",
    "section": "87.4 Pressioni e Sfide nell’Adesione ai Codici di Condotta",
    "text": "87.4 Pressioni e Sfide nell’Adesione ai Codici di Condotta\nNonostante l’esistenza di codici di condotta, i ricercatori, specialmente quelli all’inizio della carriera, possono subire pressioni da parte dei supervisori per adottare comportamenti che deviano dagli standard stabiliti. Questo è spesso dovuto alla competitività nel campo scientifico e al sistema di valutazione basato sul numero di pubblicazioni. Tali dinamiche possono portare a pratiche di ricerca discutibili (PRD), come la pubblicazione selettiva dei risultati o l’uso di analisi dei dati flessibili per ottenere risultati statisticamente significativi.\nPer preservare l’integrità della ricerca, è essenziale creare un ambiente di lavoro che promuova apertura, inclusività e discussione franca delle pressioni e delle sfide etiche. Ciò richiede non solo l’adesione ai codici di condotta esistenti, ma anche un impegno attivo delle istituzioni nel promuovere la formazione etica e l’integrità tra i ricercatori. Solo attraverso un approccio di questo tipo la comunità scientifica può aspirare a una ricerca di alta qualità, sia eticamente responsabile che metodologicamente solida.\nUn esempio emblematico delle tensioni nel mondo accademico è il gioco da tavolo Publish or Perish, recentemente promosso dalla prestigiosa rivista Nature. La descrizione del gioco è provocatoria:\n\n“Falsificare dati, screditare altri scienziati, pubblicare una montagna di articoli che ricevono una torre di citazioni: i cinici potrebbero descrivere questi come passi necessari per raggiungere il successo accademico.”\n\nQuesta iniziativa solleva interrogativi sullo stato attuale della ricerca scientifica. Il mondo accademico sembra offrire incentivi distorti, mentre il sistema economico delle riviste scientifiche presenta una componente di monetizzazione che spesso entra in conflitto con gli obiettivi fondamentali della ricerca. Questo contesto favorisce l’accettazione di pratiche disoneste, funzionali al mantenimento dello status quo.\nIn questo scenario complesso, emergono voci di dissenso che auspicano una riforma del sistema scientifico (McElreath, 2020; Smaldino & McElreath, 2016). È necessaria una riflessione profonda su come bilanciare la produttività accademica con l’etica e la qualità della ricerca, nonché sul ruolo delle riviste scientifiche nel plasmare il panorama della ricerca contemporanea.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Integrità della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/09_integrity.html#bibliografia",
    "href": "chapters/replication_crisis/09_integrity.html#bibliografia",
    "title": "87  Integrità della ricerca",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nSmaldino, P. E., & McElreath, R. (2016). The natural selection of bad science. Royal Society Open Science, 3(9), 160384.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Integrità della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html",
    "href": "chapters/epiloque/epiloque.html",
    "title": "Considerazioni Conclusive",
    "section": "",
    "text": "Limiti dell’Inferenza Frequentista\nL’inferenza bayesiana rappresenta un approccio rigoroso e trasparente per integrare conoscenze pregresse e dati empirici nell’analisi psicologica. A differenza dei metodi frequentisti, l’approccio bayesiano consente di quantificare l’incertezza e di costruire modelli che riflettono le nostre aspettative iniziali. Questa flessibilità è particolarmente preziosa in psicologia, dove teorie e ipotesi svolgono un ruolo centrale nel guidare la ricerca. L’inferenza bayesiana rende esplicite le nostre assunzioni a priori e ci permette di valutare come i dati influenzano la nostra comprensione dei fenomeni psicologici.\nIn questo corso, abbiamo esaminato i limiti dell’inferenza frequentista, specialmente quando utilizzata come “filtro” per distinguere risultati scientifici rilevanti da quelli trascurabili. L’eccessiva dipendenza dai valori-p è stata ampiamente criticata per la sua associazione con inferenze inadeguate. Gli effetti possono essere sovrastimati, talvolta anche nella direzione sbagliata, quando la stima è vincolata alla significatività statistica in presenza di dati altamente variabili (Loken & Gelman, 2017).\nNonostante le critiche di lunga data e i dibattiti sul loro uso improprio (Gardner e Altman, 1986; Cohen, 1994; Anderson et al., 2000; Fidler et al., 2004; Finch et al., 2004), i valori-p persistono come indicatore di significatività. Questa tenacia riflette forse la necessità dei ricercatori di avere strumenti intuitivi, sebbene semplificati, per interpretare i dati. Tuttavia, l’uso rigido di soglie arbitrarie (ad esempio, 0.05, 0.01, 0.001) ha trasformato il raggiungimento della significatività in un obiettivo fine a se stesso, piuttosto che in uno strumento per comprendere i fenomeni sottostanti (Cohen, 1994; Kirk, 1996). Inoltre, i valori-p possono solo rifiutare l’ipotesi nulla, ma non confermarla, poiché un risultato non significativo non implica l’assenza di effetti o differenze (Wagenmakers, 2007; Amrhein et al., 2019).\nL’uso improprio dei valori-p, noto come “p-hacking” (Simmons et al., 2011), ha favorito pratiche scientifiche discutibili, contribuendo alla crisi di riproducibilità nella psicologia (Chambers et al., 2014; Szucs e Ioannidis, 2016).",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html#la-crisi-della-replicabilità",
    "href": "chapters/epiloque/epiloque.html#la-crisi-della-replicabilità",
    "title": "Considerazioni Conclusive",
    "section": "La Crisi della Replicabilità",
    "text": "La Crisi della Replicabilità\nLa crisi della replicabilità rappresenta una delle principali sfide che affliggono la ricerca scientifica contemporanea, con effetti particolarmente rilevanti nel campo della psicologia. Quando i risultati di uno studio non possono essere riprodotti in condizioni simili, si mette in discussione non solo la validità delle teorie su cui si basano interventi clinici e politiche pubbliche, ma anche la fiducia generale nella scienza. Questo problema va oltre l’ambito accademico, influenzando direttamente l’efficacia delle applicazioni pratiche delle ricerche.\n\nLe Cause Sottostanti\nUno dei fattori principali della crisi è legato all’uso di metodologie di ricerca e analisi dei dati insufficientemente rigorose, che spesso portano a falsi positivi. Sebbene siano stati fatti appelli per migliorare le pratiche scientifiche, tali problemi persistono, indicando che il fenomeno non è semplicemente frutto di errori o mancanza di comprensione. Secondo Smaldino e McElreath (2016), la causa radicale risiede nei sistemi di incentivi distorti che favoriscono la quantità piuttosto che la qualità della ricerca. In questo contesto, la pressione a pubblicare risultati significativi diventa prioritaria rispetto alla rigorosità metodologica, alimentando un circolo vizioso in cui la “scienza scadente” si perpetua.\nPratiche comuni, come il p-hacking (manipolazione statistica per ottenere risultati significativi) o la selezione selettiva dei dati, vengono adottate inconsciamente o intenzionalmente per massimizzare le probabilità di pubblicazione. Questo meccanismo, descritto come una forma di “selezione naturale della scienza scadente”, premia approcci che facilitano la produzione di risultati spettacolari, ma non necessariamente veritieri.\n\n\nVerso una Soluzione: Cambiare la Cultura Scientifica\nPer superare questa crisi, è fondamentale operare un cambiamento culturale all’interno della comunità scientifica. Non basta correggere gli errori metodologici; occorre modificare radicalmente gli incentivi per premiare la qualità, la trasparenza e la replicabilità della ricerca. Alcune strategie chiave includono:\n\nPromozione di Pratiche Rigorose:\n\nAdottare protocolli trasparenti, preregistrare gli studi prima del loro avvio e condividere apertamente dati e materiali.\nImplementare procedure di peer review più severe e incoraggiare la revisione post-pubblicazione.\n\nValorizzazione della Replicazione:\n\nDare maggiore riconoscimento agli studi che replicano risultati precedenti, anziché privilegiare esclusivamente nuove scoperte.\nCreare riviste specializzate che si concentriano sulla verifica e sulla riproducibilità degli studi.\n\nRiforma dei Criteri di Valutazione:\n\nSpostare l’attenzione dalla quantità delle pubblicazioni alla loro qualità e impatto scientifico.\nIncorporare metriche alternative, come l’impatto sociale e la contribuzione alla conoscenza consolidata.\n\n\n\n\nNuovi Approcci Metodologici\nAlcune proposte innovative mirano a migliorare la qualità delle analisi statistiche e ridurre la propensione a falsi positivi. Un esempio è l’adozione dell’inferenza bayesiana, che offre vantaggi significativi rispetto ai metodi tradizionali:\n\nMaggiore flessibilità nell’analisi di dati rumorosi o campioni piccoli.\nMinore propensione agli errori di tipo I.\nPossibilità di incorporare conoscenze pregresse nel processo decisionale.\n\nTuttavia, l’inferenza bayesiana da sola non può risolvere completamente il problema. È necessario affrontare anche le cause strutturali, come il sistema accademico che premia la produttività quantitativa piuttosto che la qualità.\nUn’altra prospettiva promettente è quella avanzata da Richard McElreath, che suggerisce di passare da un approccio descrittivo a uno che descrive formalmente i meccanismi generativi dei dati. Questo significa formulare ipotesi esplicite sui processi sottostanti e testarle attraverso confronti quantitativi tra modelli. Tecniche come la validazione incrociata bayesiana Leave-One-Out (LOO) permettono di valutare la robustezza dei modelli e la loro capacità di generalizzare a nuovi contesti.\nInoltre, la “rivoluzione causale” cerca di identificare relazioni causali in contesti naturali, superando i limiti degli esperimenti controllati tradizionali. Questo approccio richiede ai ricercatori di formulare ipotesi causali esplicite e confrontare modelli alternativi, migliorando così la comprensione dei fenomeni studiati.\n\n\nImplicazioni Sociali e Educative\nLa crisi della replicabilità ha implicazioni concrete al di là del mondo accademico. Interventi clinici, politiche pubbliche e decisioni basate su ricerche non replicabili rischiano di essere inefficaci o dannose. Pertanto, garantire la replicabilità e l’affidabilità delle scoperte scientifiche è essenziale non solo per preservare l’integrità accademica, ma anche per assumersi responsabilità sociali.\nUna revisione dei metodi didattici e dei programmi accademici è altrettanto cruciale. Gli studenti devono essere formati per comprendere e applicare inferenze basate su dati empirici. Studiosi come Mine Dogucu hanno sottolineato l’importanza di integrare approcci bayesiani e causalità nei corsi di formazione, e la presente dispensa si inserisce in questo sforzo (Dogucu & Çetinkaya-Rundel, 2021; Dogucu & Hu, 2022; Johnson et al., 2022; Rosenberg et al., 2022).",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html#conclusioni",
    "href": "chapters/epiloque/epiloque.html#conclusioni",
    "title": "Considerazioni Conclusive",
    "section": "Conclusioni",
    "text": "Conclusioni\nAffrontare e superare la crisi della replicabilità rappresenta una sfida fondamentale per la comunità scientifica, richiedendo un impegno collettivo per riformare profondamente la cultura della ricerca. Modificare gli incentivi che favoriscono quantità piuttosto che qualità, promuovere pratiche metodologiche rigorose e valorizzare la replicazione sono passi essenziali per costruire una scienza più affidabile. Solo attraverso un approccio multidimensionale sarà possibile ripristinare la fiducia nella psicologia scientifica e garantire che le sue applicazioni pratiche siano fondate su basi solide e verificabili.\nIn questo contesto, l’inferenza bayesiana emerge come uno strumento di grande valore per l’analisi dei dati psicologici. Offrendo metodi avanzati per gestire l’incertezza, integrare conoscenze pregresse e adattarsi a modelli complessi, essa si dimostra particolarmente utile per esplorare i fenomeni legati alla mente umana e al comportamento. La sua capacità di fornire previsioni robuste e di aggiornare le ipotesi in base a nuovi dati la rende un approccio ideale per affrontare le sfide poste dalla natura intrinsecamente dinamica del campo psicologico.\nTuttavia, è importante sottolineare che l’adozione di metodi bayesiani non costituisce da sola una soluzione completa alla crisi della replicabilità. Per migliorare realmente la qualità della ricerca, è necessario integrare queste tecniche con pratiche metodologiche rigorose. Tra queste, spiccano la formalizzazione di modelli generativi, che consentono di descrivere esplicitamente i processi sottostanti ai dati osservati, e il confronto tra modelli alternativi, fondamentale per valutare l’adeguatezza delle teorie proposte. Inoltre, l’adozione di una prospettiva causale esplicita è cruciale per identificare correttamente le relazioni di causa-effetto, superando i limiti degli studi correlazionali o degli esperimenti tradizionali.\nIn conclusione, solo un approccio integrato, che combini l’inferenza bayesiana con pratiche metodologiche avanzate e una riflessione critica sui sistemi di incentivi accademici, permetterà di progredire verso una scienza psicologica più affidabile e riproducibile. Questo sforzo collettivo non solo migliorerà la qualità delle ricerche, ma contribuirà anche a fornire una comprensione più profonda e accurata del comportamento umano, consolidando così la posizione della psicologia come disciplina scientifica solida e credibile.",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html#bibliografia",
    "href": "chapters/epiloque/epiloque.html#bibliografia",
    "title": "Considerazioni Conclusive",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nDogucu, M., & Çetinkaya-Rundel, M. (2021). Web scraping in the statistics and data science curriculum: Challenges and opportunities. Journal of Statistics and Data Science Education, 29(sup1), S112–S122.\n\n\nDogucu, M., & Hu, J. (2022). The current state of undergraduate Bayesian education and recommendations for the future. The American Statistician, 76(4), 405–413.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nLoken, E., & Gelman, A. (2017). Measurement Error and the Replication Crisis. Science, 355(6325), 584–585.\n\n\nRosenberg, J. M., Kubsch, M., Wagenmakers, E.-J., & Dogucu, M. (2022). Making sense of uncertainty in the science classroom: A Bayesian approach. Science & Education, 31(5), 1239–1262.",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/appendix/a01_shell.html",
    "href": "chapters/appendix/a01_shell.html",
    "title": "Appendice A — La Shell",
    "section": "",
    "text": "A.1 Che cos’è una Shell?\nUna shell è un programma che riceve comandi dall’utente tramite tastiera (o da file) e li passa al sistema operativo per l’esecuzione. Può essere accessibile tramite un terminale (o un emulatore di terminale).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>La Shell</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01_shell.html#che-cosè-una-shell",
    "href": "chapters/appendix/a01_shell.html#che-cosè-una-shell",
    "title": "Appendice A — La Shell",
    "section": "",
    "text": "A.1.1 Breve Storia della Shell\n\n1971: Ken Thompson di Bell Labs sviluppa la shell per UNIX.\n1977: Stephen Bourne introduce la Bourne shell (sh).\nDopo il 1977: Viene sviluppata la C shell (csh) e tcsh.\nBash: Sviluppata da Brian Fox come sostituto migliorato della Bourne shell.\n1990: Paul Falsted sviluppa Zsh, che diventa la shell predefinita per macOS dal 2019.\n\n\n\nA.1.2 Windows vs macOS/Linux\n\nWindows 10: È possibile utilizzare Bash attivando il Windows Subsystem for Linux. Tuttavia, l’ambiente preferito è solitamente PowerShell.\nmacOS/Linux: Zsh è la shell predefinita in entrambi i sistemi. È consigliabile sfruttare l’applicazione warp per un’esperienza utente moderna e ottimizzata.\n\n\n\nA.1.3 Comandi di Base Unix\n\npwd: Mostra il percorso della directory corrente.\nls: Elenca file e cartelle nella directory corrente.\ncd: Cambia directory. Senza argomenti, ti porta alla directory home.\nmkdir: Crea una nuova directory.\nrmdir: Rimuove una directory vuota.\nImportante: Evitare spazi nei nomi di file e cartelle.\n\n\nA.1.3.1 Gestione File\n\nmv: Rinomina o sposta file (usa \\ o '' per i nomi di file con spazi).\ncp: Copia file o cartelle (usa -r per le cartelle).\nrm: Rimuove file o cartelle (usa -i per confermare prima di eliminare).\n\n\n\nA.1.3.2 Visualizzazione e Manipolazione Contenuti dei File\n\nless / more: Visualizza il contenuto dei file con possibilità di navigazione.\ncat: Mostra l’intero contenuto di un file.\nhead: Mostra le prime righe di un file.\ntail: Mostra le ultime righe di un file.\n\n\n\n\nA.1.4 Comandi di Base PowerShell\nPer adattare i comandi Unix per l’utilizzo in PowerShell di Windows, molti dei comandi rimangono simili grazie alla natura cross-platform di PowerShell e alla sua flessibilità nel gestire sia gli stili di comando Unix che quelli tradizionali di Windows. Ecco come si traducono i comandi:\n\nGet-Location o semplicemente pwd: Mostra il percorso della directory corrente, simile a pwd in Unix.\nGet-ChildItem o semplicemente ls: Elenca file e cartelle nella directory corrente, equivalente a ls in Unix.\nSet-Location o semplicemente cd: Cambia directory. cd senza argomenti ti porta alla directory home in PowerShell con cd ~.\nNew-Item -ItemType Directory -Name 'nomeDirectory': Crea una nuova directory, simile a mkdir in Unix.\nRemove-Item -Path 'nomeDirectory' -Force: Rimuove una directory, anche se non vuota. Equivalente a rmdir in Unix, ma più potente perché può rimuovere anche directory con contenuti utilizzando il parametro -Force.\n\n\nA.1.4.1 Gestione File\n\nMove-Item -Path 'origine' -Destination 'destinazione': Rinomina o sposta file, equivalente a mv in Unix.\nCopy-Item -Path 'origine' -Destination 'destinazione': Copia file o cartelle, simile a cp in Unix. Usa -Recurse per copiare cartelle.\nRemove-Item -Path 'file' -Force: Rimuove file o cartelle, simile a rm in Unix. Usa -Force per rimuovere senza conferme e -Recurse per rimuovere cartelle con contenuti.\n\n\n\nA.1.4.2 Visualizzazione e Manipolazione Contenuti dei File\n\nGet-Content 'file' | More: Visualizza il contenuto dei file con possibilità di navigazione, simile a less/more in Unix.\nGet-Content 'file': Mostra l’intero contenuto di un file, equivalente a cat in Unix.\nGet-Content 'file' -Head &lt;numero&gt;: Mostra le prime righe di un file, simile a head in Unix.\nGet-Content 'file' -Tail &lt;numero&gt;: Mostra le ultime righe di un file, equivalente a tail in Unix.\n\n\n\n\n\n\n\nÈ cruciale familiarizzarsi con l’utilizzo dei percorsi relativi per semplificare gli spostamenti tra le diverse directory. L’impiego dei percorsi relativi rende il processo di navigazione più intuitivo e meno incline agli errori.\n\nNomi Chiari e Concisi: Evitate di includere spazi nei nomi dei file e delle cartelle. Preferite l’utilizzo di trattini bassi (_) per separare le parole e mantenere una struttura leggibile e facilmente comprensibile.\nEvitare Caratteri Speciali: È importante evitare l’inserimento di caratteri speciali come asterischi (*), dollari ($), slash (/, \\), punti (.), virgole (,), punti e virgole (;), parentesi (()), parentesi quadre ([]), parentesi graffe ({}), ampersand (&), barre verticali (|), punti esclamativi (!), punti interrogativi (?) nei nomi dei file e delle cartelle. Talvolta, anche l’uso del trattino (-) può causare problemi; quindi è consigliabile evitarlo. Questi caratteri possono generare problemi di compatibilità con alcuni sistemi operativi o applicazioni, rendendo più complessa la gestione dei file.\nDifferenziazione tra Maiuscole e Minuscole: Unix distingue tra maiuscole e minuscole (tratta le lettere come oggetti distinti), mentre Windows non lo fa. Per evitare confusioni, è consigliabile adottare una politica conservativa: considerate i nomi che differiscono solo per la case delle lettere come distinti.\n\nSeguendo questi consigli, è possibile ottimizzare notevolmente l’organizzazione e la gestione dei propri file, migliorando l’efficienza del lavoro e riducendo il rischio di errori.\n\n\n\nCon la pratica, la riga di comando diventa uno strumento molto efficiente. Questa breve guida fornisce le basi per iniziare a esplorare e gestire i file dal terminale, offrendo una base di partenza per ulteriori apprendimenti (es., Robbins, 2016). La familiarità con la shell è fondamentale nella data science.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>La Shell</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01_shell.html#bibliografia",
    "href": "chapters/appendix/a01_shell.html#bibliografia",
    "title": "Appendice A — La Shell",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nRobbins, A. (2016). Bash Pocket Reference: Help for Power Users and Sys Admins. O’Reilly Media, Inc.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>La Shell</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01a_files.html",
    "href": "chapters/appendix/a01a_files.html",
    "title": "Appendice B — Cartelle e documenti",
    "section": "",
    "text": "B.1 Introduzione\nI file su un computer sono organizzati tramite una struttura gerarchica chiamata struttura ad albero, costituita da cartelle (o directory) e file. Questa organizzazione permette una gestione ordinata e intuitiva delle informazioni.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Cartelle e documenti</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01a_files.html#introduzione",
    "href": "chapters/appendix/a01a_files.html#introduzione",
    "title": "Appendice B — Cartelle e documenti",
    "section": "",
    "text": "Radice (Root): È il punto più alto dell’albero da cui partono tutte le ramificazioni.\nCartelle/Directory: Contenitori che possono includere file o altre cartelle.\nFile: Gli elementi finali che contengono dati.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Cartelle e documenti</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01a_files.html#unixlinuxmacos",
    "href": "chapters/appendix/a01a_files.html#unixlinuxmacos",
    "title": "Appendice B — Cartelle e documenti",
    "section": "B.2 Unix/Linux/macOS",
    "text": "B.2 Unix/Linux/macOS\nNei sistemi Unix, l’albero ha una struttura chiara che inizia sempre dalla radice indicata con lo slash /.\nEsempio semplificato:\n/\n├── bin             # programmi di sistema essenziali\n├── etc             # file di configurazione\n├── home            # cartelle personali degli utenti\n│   └── utente\n│       ├── Documenti\n│       ├── Immagini\n│       └── Scaricati\n├── usr             # applicazioni e librerie utente\n├── var             # dati variabili come log e cache\n└── tmp             # file temporanei\nNei sistemi Unix i percorsi dei file si scrivono utilizzando lo slash (/), ad esempio:\n/home/utente/Documenti/tesi.docx",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Cartelle e documenti</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01a_files.html#windows",
    "href": "chapters/appendix/a01a_files.html#windows",
    "title": "Appendice B — Cartelle e documenti",
    "section": "B.3 Windows",
    "text": "B.3 Windows\nWindows organizza i file in maniera simile ma partendo da una o più unità (dischi), tipicamente indicate da lettere come C:, D:, ecc. La radice di ogni albero corrisponde quindi all’unità disco.\nEsempio semplificato:\nC:\\\n├── Program Files   # applicazioni installate\n├── Windows         # sistema operativo e file di sistema\n├── Utenti          # dati degli utenti\n│   └── utente\n│       ├── Documenti\n│       ├── Immagini\n│       └── Download\n└── Temp            # file temporanei\nNei sistemi Windows i percorsi dei file si scrivono utilizzando il backslash (\\), ad esempio:\nC:\\Utenti\\utente\\Documenti\\tesi.docx",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Cartelle e documenti</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01a_files.html#principali-comandi",
    "href": "chapters/appendix/a01a_files.html#principali-comandi",
    "title": "Appendice B — Cartelle e documenti",
    "section": "B.4 Principali Comandi",
    "text": "B.4 Principali Comandi\nQui sotto viene presentata una panoramica sintetica dei principali comandi per gestire la struttura ad albero di file e cartelle nei sistemi Unix (Linux e macOS) e Windows.\n\nB.4.1 Unix/Linux/macOS (Terminale Bash o zsh)\n\n\n\n\n\n\n\n\nComando\nFunzione\nEsempio\n\n\n\n\npwd\nMostra la cartella corrente (Print Working Directory)\npwd → /home/utente/Documenti\n\n\ncd\nCambia la cartella corrente (Change Directory)\ncd /home/utente/Scaricati\n\n\nls\nElenca il contenuto di una cartella (List)\nls o ls -l\n\n\nmkdir\nCrea una nuova cartella (Make Directory)\nmkdir nuova_cartella\n\n\nmv\nSposta o rinomina file/cartelle (Move)\nmv file.txt Documenti/ oppure mv vecchio.txt nuovo.txt\n\n\ncp\nCopia file/cartelle (Copy)\ncp file.txt copia_file.txt\n\n\nrm\nRimuove file (Remove)\nrm file.txt\n\n\nrmdir\nRimuove una cartella vuota (Remove Directory)\nrmdir cartella_vuota\n\n\nwhoami\nMostra l’utente corrente\nwhoami → utente\n\n\n\nEsempio di uso dei comandi:\npwd\ncd /home/utente\nmkdir nuovo\ncd nuovo\ntouch prova.txt\nls\nmv prova.txt ../Documenti\ncd ../Documenti\ncp prova.txt copia_prova.txt\nrm prova.txt\nwhoami\n\n\nB.4.2 Windows (Prompt dei comandi, CMD)\n\n\n\n\n\n\n\n\nComando\nFunzione\nEsempio\n\n\n\n\ncd\nCambia la cartella corrente (Change Directory)\ncd C:\\Utenti\\utente\\Documenti\n\n\ncd\nMostra la cartella corrente\ncd → C:\\Utenti\\utente\\Documenti\n\n\ndir\nElenca il contenuto della cartella\ndir\n\n\nmkdir\nCrea una nuova cartella\nmkdir nuova_cartella\n\n\nmove\nSposta o rinomina file/cartelle\nmove file.txt Documenti\\ o move vecchio.txt nuovo.txt\n\n\ncopy\nCopia file\ncopy file.txt copia_file.txt\n\n\ndel\nRimuove file\ndel file.txt\n\n\nrmdir\nRimuove cartella vuota\nrmdir cartella_vuota\n\n\nwhoami\nMostra l’utente corrente\nwhoami → utente\n\n\n\nEsempio di uso dei comandi:\ncd C:\\Utenti\\utente\nmkdir nuovo\ncd nuovo\necho prova &gt; prova.txt\ndir\nmove prova.txt ..\\Documenti\ncd ..\\Documenti\ncopy prova.txt copia_prova.txt\ndel prova.txt\nwhoami\nNota finale.\nEntrambi i sistemi operativi consentono operazioni simili, ma hanno sintassi e convenzioni leggermente diverse. Questi comandi di base permettono una gestione essenziale e rapida della struttura ad albero.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Cartelle e documenti</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01a_files.html#conclusioni",
    "href": "chapters/appendix/a01a_files.html#conclusioni",
    "title": "Appendice B — Cartelle e documenti",
    "section": "Conclusioni",
    "text": "Conclusioni\nIn sintesi, entrambi i sistemi operativi utilizzano una struttura ad albero per facilitare la gestione, la navigazione e l’organizzazione dei file e delle cartelle. Cambiano principalmente la notazione (/ o \\) e la gestione della radice (una singola radice / in Unix, più radici contrassegnate da lettere come C: in Windows).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Cartelle e documenti</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a02_math_symbols.html",
    "href": "chapters/appendix/a02_math_symbols.html",
    "title": "Appendice C — Simbologia di base",
    "section": "",
    "text": "Per una scrittura più sintetica possono essere utilizzati alcuni simboli matematici.\n\n\\(\\log(x)\\): il logaritmo naturale di \\(x\\).\nL’operatore logico booleano \\(\\land\\) significa “e” (congiunzione forte) mentre il connettivo di disgiunzione \\(\\lor\\) significa “o” (oppure) (congiunzione debole).\nIl quantificatore esistenziale \\(\\exists\\) vuol dire “esiste almeno un” e indica l’esistenza di almeno una istanza del concetto/oggetto indicato. Il quantificatore esistenziale di unicità \\(\\exists!\\) (“esiste soltanto un”) indica l’esistenza di esattamente una istanza del concetto/oggetto indicato. Il quantificatore esistenziale \\(\\nexists\\) nega l’esistenza del concetto/oggetto indicato.\nIl quantificatore universale \\(\\forall\\) vuol dire “per ogni.”\n\\(\\mathcal{A, S}\\): insiemi.\n\\(x \\in A\\): \\(x\\) è un elemento dell’insieme \\(A\\).\nL’implicazione logica “\\(\\Rightarrow\\)” significa “implica” (se …allora). \\(P \\Rightarrow Q\\) vuol dire che \\(P\\) è condizione sufficiente per la verità di \\(Q\\) e che \\(Q\\) è condizione necessaria per la verità di \\(P\\).\nL’equivalenza matematica “\\(\\iff\\)” significa “se e solo se” e indica una condizione necessaria e sufficiente, o corrispondenza biunivoca.\nIl simbolo \\(\\vert\\) si legge “tale che.”\nIl simbolo \\(\\triangleq\\) (o \\(:=\\)) si legge “uguale per definizione.”\nIl simbolo \\(\\Delta\\) indica la differenza fra due valori della variabile scritta a destra del simbolo.\nIl simbolo \\(\\propto\\) si legge “proporzionale a.”\nIl simbolo \\(\\approx\\) si legge “circa.”\nIl simbolo \\(\\in\\) della teoria degli insiemi vuol dire “appartiene” e indica l’appartenenza di un elemento ad un insieme. Il simbolo \\(\\notin\\) vuol dire “non appartiene.”\nIl simbolo \\(\\subseteq\\) si legge “è un sottoinsieme di” (può coincidere con l’insieme stesso). Il simbolo \\(\\subset\\) si legge “è un sottoinsieme proprio di.”\nIl simbolo \\(\\#\\) indica la cardinalità di un insieme.\nIl simbolo \\(\\cap\\) indica l’intersezione di due insiemi. Il simbolo \\(\\cup\\) indica l’unione di due insiemi.\nIl simbolo \\(\\emptyset\\) indica l’insieme vuoto o evento impossibile.\nIn matematica, \\(\\mbox{argmax}\\) identifica l’insieme dei punti per i quali una data funzione raggiunge il suo massimo. In altre parole, \\(\\mbox{argmax}_x f(x)\\) è l’insieme dei valori di \\(x\\) per i quali \\(f(x)\\) raggiunge il valore più alto.\n\\(a, c, \\alpha, \\gamma\\): scalari.\n\\(\\boldsymbol{x}, \\boldsymbol{y}\\): vettori.\n\\(\\boldsymbol{X}, \\boldsymbol{Y}\\): matrici.\n\\(X \\sim p\\): la variabile casuale \\(X\\) si distribuisce come \\(p\\).\n\\(p(\\cdot)\\): distribuzione di massa o di densità di probabilità.\n\\(p(y \\mid \\boldsymbol{x})\\): la probabilità o densità di \\(y\\) dato \\(\\boldsymbol{x}\\), ovvero \\(p(y = \\boldsymbol{Y} \\mid x = \\boldsymbol{X})\\).\n\\(f(x)\\): una funzione arbitraria di \\(x\\).\n\\(f(\\boldsymbol{X}; \\theta, \\gamma)\\): \\(f\\) è una funzione di \\(\\boldsymbol{X}\\) con parametri \\(\\theta, \\gamma\\). Questa notazione indica che \\(\\boldsymbol{X}\\) sono i dati che vengono passati ad un modello di parametri \\(\\theta, \\gamma\\).\n\\(\\mathcal{N}(\\mu, \\sigma^2)\\): distribuzione gaussiana di media \\(\\mu\\) e varianza \\(sigma^2\\).\n\\(\\mbox{Beta}(\\alpha, \\beta)\\): distribuzione Beta di parametri \\(\\alpha\\) e \\(\\beta\\).\n\\(\\mathcal{U}(a, b)\\): distribuzione uniforme con limite inferiore \\(a\\) e limite superiore \\(b\\).\n\\(\\mbox{Cauchy}(\\alpha, \\beta)\\): distribuzione di Cauchy di parametri \\(\\alpha\\) (posizione: media) e \\(\\beta\\) (scala: radice quadrata della varianza).\n\\(\\mathcal{B}(p)\\): distribuzione di Bernoulli di parametro \\(p\\) (probabilità di successo).\n\\(\\mbox{Bin}(n, p)\\): distribuzione binomiale di parametri \\(n\\) (numero di prove) e \\(p\\) (probabilità di successo).\n\\(\\mathbb{KL} (p \\mid\\mid q)\\): la divergenza di Kullback-Leibler da \\(p\\) a \\(q\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Simbologia di base</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a03_latex.html",
    "href": "chapters/appendix/a03_latex.html",
    "title": "Appendice D — Equazioni Matematiche in LaTeX",
    "section": "",
    "text": "D.1 LaTeX\nLaTeX è un potente strumento di composizione tipografica, ampiamente utilizzato per la produzione di documenti scientifici e tecnici. Una delle sue caratteristiche più apprezzate è la capacità di gestire equazioni matematiche in modo elegante e preciso. In questo articolo, esploreremo come scrivere equazioni matematiche in LaTeX, coprendo i modi matematici, le operazioni di base, l’allineamento delle equazioni e molto altro.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Equazioni Matematiche in LaTeX</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a03_latex.html#modelli-matematici-in-latex",
    "href": "chapters/appendix/a03_latex.html#modelli-matematici-in-latex",
    "title": "Appendice D — Equazioni Matematiche in LaTeX",
    "section": "D.2 Modelli Matematici in LaTeX",
    "text": "D.2 Modelli Matematici in LaTeX\nPer scrivere equazioni matematiche in LaTeX, esistono due modalità principali: la modalità inline e la modalità display.\n\nModalità Inline: Utilizzata per inserire equazioni all’interno del testo. Le espressioni matematiche sono racchiuse tra simboli di dollaro ($), ad esempio $E=mc^2$ produce \\(E=mc^2\\).\nModalità Display: Utilizzata per equazioni che devono essere evidenziate e centrate su una nuova linea. Le espressioni possono essere racchiuse tra $$ e $$, o all’interno di ambienti come \\begin{equation} e \\end{equation}.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Equazioni Matematiche in LaTeX</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a03_latex.html#scrivere-costrutti-matematici-di-base",
    "href": "chapters/appendix/a03_latex.html#scrivere-costrutti-matematici-di-base",
    "title": "Appendice D — Equazioni Matematiche in LaTeX",
    "section": "D.3 Scrivere Costrutti Matematici di Base",
    "text": "D.3 Scrivere Costrutti Matematici di Base\n\nD.3.1 Operazioni Aritmetiche\nLe operazioni aritmetiche possono essere scritte direttamente all’interno del testo utilizzando il simbolo del dollaro. Ad esempio:\n\nAddizione: $a + b$ produce \\(a + b\\).\nMoltiplicazione: $a \\cdot b$ o $a \\times b$ produce \\(a \\cdot b\\) o \\(a \\times b\\).\nDivisione: $a / b$ o $a \\div b$ produce \\(a / b\\) o \\(a \\div b\\).\n\n\n\nD.3.2 Frazioni e Coefficienti Binomiali\nLe frazioni si scrivono utilizzando il comando \\frac{num}{den}. Ad esempio, $\\frac{a}{b}$ produce \\(\\frac{a}{b}\\).\nPer i coefficienti binomiali, si utilizza il comando \\binom{n}{k}. Ad esempio, $\\binom{n}{k}$ produce \\(\\binom{n}{k}\\).\n\n\nD.3.3 Pedici e Apici\nI pedici si ottengono con _, mentre gli apici con ^. Ad esempio:\n\n$a_{1}$ produce \\(a_{1}\\).\n$a^{2}$ produce \\(a^{2}\\).\n\n\n\nD.3.4 Integrali e Radici\nPer gli integrali, i limiti di integrazione si scrivono come pedici e apici. Ad esempio:\n\n$\\int_{a}^{b} f(x) \\, dx$ produce \\(\\int_{a}^{b} f(x) \\, dx\\).\n\nLe radici si ottengono con il comando \\sqrt{}. Ad esempio, $\\sqrt{a + b}$ produce \\(\\sqrt{a + b}\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Equazioni Matematiche in LaTeX</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a03_latex.html#allineamento-delle-equazioni",
    "href": "chapters/appendix/a03_latex.html#allineamento-delle-equazioni",
    "title": "Appendice D — Equazioni Matematiche in LaTeX",
    "section": "D.4 Allineamento delle Equazioni",
    "text": "D.4 Allineamento delle Equazioni\nPer allineare più equazioni, si utilizza l’ambiente align. Ad esempio:\n\\begin{align*}\na + b &= c \\\\\nd + e &= f\n\\end{align*}\nQuesto allinea le equazioni al segno di uguale.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Equazioni Matematiche in LaTeX</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a03_latex.html#parentesi-e-operatori",
    "href": "chapters/appendix/a03_latex.html#parentesi-e-operatori",
    "title": "Appendice D — Equazioni Matematiche in LaTeX",
    "section": "D.5 Parentesi e Operatori",
    "text": "D.5 Parentesi e Operatori\nLe parentesi possono essere ridimensionate utilizzando i comandi \\left( e \\right). Ad esempio:\n$$ \n\\left( \\frac{a}{b} \\right) \n$$\nGli operatori come seno, coseno e logaritmi si scrivono con comandi specifici come \\sin, \\cos, e \\log.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Equazioni Matematiche in LaTeX</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a03_latex.html#conclusione",
    "href": "chapters/appendix/a03_latex.html#conclusione",
    "title": "Appendice D — Equazioni Matematiche in LaTeX",
    "section": "D.6 Conclusione",
    "text": "D.6 Conclusione\nLaTeX offre una vasta gamma di strumenti per la scrittura di equazioni matematiche, rendendolo uno strumento indispensabile per chiunque lavori con documenti scientifici. Con un po’ di pratica, è possibile padroneggiare queste tecniche e produrre documenti di alta qualità con facilità.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Equazioni Matematiche in LaTeX</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html",
    "href": "chapters/appendix/a11_numbers.html",
    "title": "Appendice E — Numeri e intervalli",
    "section": "",
    "text": "E.1 Numeri binari\nI numeri binari rappresentano il sistema numerico più elementare utilizzato in informatica, poiché sono composti unicamente da due simboli: 0 e 1. Questa caratteristica li rende particolarmente adatti alla rappresentazione di situazioni dicotomiche (vero/falso, presente/assente) e consente ai computer di operare rapidamente ed efficacemente sui dati.\nUn esempio semplice d’impiego dei valori logici binari si ottiene quando raccogliamo risposte a una domanda chiusa. Immaginiamo, ad esempio, di porre la domanda “Ti piacciono i mirtilli?” a 10 studenti. Se le risposte vengono memorizzate in R come valori logici (TRUE per “Sì” e FALSE per “No”), potremmo avere:\nopinion &lt;- c(TRUE, FALSE, TRUE, TRUE, TRUE, FALSE, TRUE, TRUE, TRUE, FALSE)\nopinion\n\n [1]  TRUE FALSE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE FALSE\nIn questo caso, TRUE e FALSE corrispondono a 1 e 0 rispettivamente quando utilizzati in operazioni numeriche. Lo stesso avviene in Python, dove True è interpretato come 1 e False come 0. Questa rappresentazione binaria permette di ottenere facilmente statistiche sintetiche. Per esempio, per calcolare la proporzione di risposte positive rispetto al totale, è sufficiente sommare i valori (contando così il numero di TRUE) e dividere per la lunghezza del vettore:\nsum(opinion) / length(opinion)\n\n[1] 0.7\nQuesto fornisce immediatamente la percentuale di studenti che hanno risposto “Sì” alla domanda.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-interi",
    "href": "chapters/appendix/a11_numbers.html#numeri-interi",
    "title": "Appendice E — Numeri e intervalli",
    "section": "\nE.2 Numeri interi",
    "text": "E.2 Numeri interi\nI numeri interi sono caratterizzati dall’assenza di componenti decimali. Essi includono sia i numeri naturali (1, 2, 3, …), tradizionalmente utilizzati per il conteggio, sia i loro opposti negativi. L’insieme dei numeri naturali è indicato con \\(\\mathbb{N}\\), mentre l’insieme dei numeri interi (che include i numeri naturali, i loro negativi e lo zero) si denota con \\(\\mathbb{Z}\\):\n\\[\n\\mathbb{Z} = \\{0, \\pm 1, \\pm 2, \\pm 3, \\dots\\}\n\\]",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-razionali",
    "href": "chapters/appendix/a11_numbers.html#numeri-razionali",
    "title": "Appendice E — Numeri e intervalli",
    "section": "\nE.3 Numeri razionali",
    "text": "E.3 Numeri razionali\nI numeri razionali sono quei numeri che possono essere espressi come il rapporto tra due numeri interi, con il denominatore diverso da zero. Essi formano l’insieme:\n\\[\n\\mathbb{Q} = \\left\\{\\frac{m}{n} \\mid m,n \\in \\mathbb{Z}, n \\neq 0\\right\\}.\n\\]\nPoiché ogni numero naturale è anche un intero, e ogni intero può essere rappresentato come razionale (ad esempio \\(5 = \\frac{5}{1}\\)), si ha una catena d’inclusioni tra i diversi insiemi di numeri:\n\\[\n\\mathbb{N} \\subseteq \\mathbb{Z} \\subseteq \\mathbb{Q}.\n\\]\nSe si desidera considerare solo i numeri razionali non negativi, si utilizza la notazione:\n\\[\n\\mathbb{Q}^+ = \\{q \\in \\mathbb{Q} \\mid q \\geq 0\\}.\n\\]",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-irrazionali",
    "href": "chapters/appendix/a11_numbers.html#numeri-irrazionali",
    "title": "Appendice E — Numeri e intervalli",
    "section": "\nE.4 Numeri irrazionali",
    "text": "E.4 Numeri irrazionali\nNon tutti i numeri possono essere espressi come rapporto di due interi. I numeri che non hanno questa proprietà sono detti irrazionali. Essi non possono essere scritti in forma frazionaria e la loro espansione decimale è infinita e non periodica. Esempi tipici di numeri irrazionali sono:\n\n\\(\\sqrt{2}\\)\n\\(\\sqrt{3}\\)\n\\(\\pi = 3.141592...\\)",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-reali",
    "href": "chapters/appendix/a11_numbers.html#numeri-reali",
    "title": "Appendice E — Numeri e intervalli",
    "section": "\nE.5 Numeri reali",
    "text": "E.5 Numeri reali\nI numeri razionali non coprono tutti i possibili punti sulla retta reale. Per rappresentare ogni possibile misura, grandezza o punto su una linea continua, si considerano i numeri reali, denotati con \\(\\mathbb{R}\\). L’insieme dei numeri reali comprende sia i razionali sia gli irrazionali:\n\\[\n\\mathbb{N} \\subseteq \\mathbb{Z} \\subseteq \\mathbb{Q} \\subseteq \\mathbb{R}.\n\\]\nIn statistica, la precisione con cui si esprime una misura è spesso legata al numero di cifre decimali utilizzate, sfruttando così appieno la “continuità” offerta dai numeri reali.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#intervalli-numerici",
    "href": "chapters/appendix/a11_numbers.html#intervalli-numerici",
    "title": "Appendice E — Numeri e intervalli",
    "section": "\nE.6 Intervalli Numerici",
    "text": "E.6 Intervalli Numerici\nDefinizione: Un intervallo numerico è un sottoinsieme connesso della retta reale. Intuitivamente, rappresenta tutti i numeri reali compresi tra due estremi, che possono o meno essere inclusi nell’intervallo stesso.\nClassificazione degli intervalli: Gli intervalli vengono classificati in base all’inclusione o meno degli estremi:\n\n\nIntervallo chiuso: Include entrambi gli estremi. Si indica con \\([a, b]\\) e rappresenta l’insieme dei numeri reali \\(x\\) tali che \\(a \\leq x \\leq b\\).\n\nIntervallo aperto: Non include alcun estremo. Si indica con \\((a, b)\\) e rappresenta l’insieme dei numeri reali \\(x\\) tali che \\(a &lt; x &lt; b\\).\n\nIntervalli semiaperti:\n\n\nChiuso a sinistra e aperto a destra: Include l’estremo sinistro ma non quello destro. Si indica con \\([a, b)\\) e rappresenta l’insieme dei numeri reali \\(x\\) tali che \\(a \\leq x &lt; b\\).\n\nAperto a sinistra e chiuso a destra: Include l’estremo destro ma non quello sinistro. Si indica con \\((a, b]\\) e rappresenta l’insieme dei numeri reali \\(x\\) tali che \\(a &lt; x \\leq b\\).\n\n\n\nTabella riassuntiva:\n\n\nIntervallo\nNotazione\nCondizione\n\n\n\nChiuso\n\\([a, b]\\)\n\\(a \\leq x \\leq b\\)\n\n\nAperto\n\\((a, b)\\)\n\\(a &lt; x &lt; b\\)\n\n\nChiuso a sinistra, aperto a destra\n\\([a, b)\\)\n\\(a \\leq x &lt; b\\)\n\n\nAperto a sinistra, chiuso a destra\n\\((a, b]\\)\n\\(a &lt; x \\leq b\\)\n\n\n\nOsservazioni: * La scelta della notazione con parentesi quadre o tonde indica rispettivamente l’inclusione o l’esclusione degli estremi.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html",
    "href": "chapters/appendix/a12_sum_notation.html",
    "title": "Appendice F — Sommatorie",
    "section": "",
    "text": "F.1 Manipolazione di somme\nLe somme sono uno strumento fondamentale in molti contesti matematici e statistici, e per gestirle in modo efficace è essenziale disporre di una notazione chiara e precisa. Consideriamo, ad esempio, la somma dei primi \\(n\\) numeri interi, che può essere espressa come \\(1 + 2 + \\dots + (n-1) + n\\), dove i puntini di sospensione (\\(\\dots\\)) indicano che la sequenza deve essere completata seguendo il pattern definito dai termini precedenti e successivi. Tuttavia, una notazione come \\(1 + 7 + \\dots + 73.6\\) risulterebbe ambigua senza ulteriori specifiche. In generale, ci troveremo di fronte a somme della forma\n\\[\nx_1 + x_2 + \\dots + x_n,\n\\]\ndove \\(x_n\\) rappresenta un numero definito altrove. Sebbene questa notazione con i puntini di sospensione sia utile in alcuni contesti, può risultare poco chiara in altri. Per questo motivo, si preferisce utilizzare la notazione di sommatoria:\n\\[\n\\sum_{i=1}^n x_i,\n\\]\nche si legge “sommatoria per \\(i\\) che va da \\(1\\) a \\(n\\) di \\(x_i\\)”. Il simbolo \\(\\sum\\) (la lettera sigma maiuscola dell’alfabeto greco) rappresenta l’operazione di somma, \\(x_i\\) è il generico addendo, mentre \\(1\\) e \\(n\\) sono gli estremi della sommatoria, che definiscono l’intervallo di variazione dell’indice \\(i\\). Solitamente, l’estremo inferiore è \\(1\\), ma potrebbe essere qualsiasi altro numero \\(m &lt; n\\). Pertanto, possiamo scrivere:\n\\[\n\\sum_{i=1}^n x_i = x_1 + x_2 + \\dots + x_n.\n\\]\nAd esempio, se i valori di \\(x\\) sono \\(\\{3, 11, 4, 7\\}\\), avremo:\n\\[\n\\sum_{i=1}^4 x_i = 3 + 11 + 4 + 7 = 25,\n\\]\ndove \\(x_1 = 3\\), \\(x_2 = 11\\), e così via. La quantità \\(x_i\\) è detta argomento della sommatoria, mentre la variabile \\(i\\), che assume valori interi successivi, è chiamata indice della sommatoria.\nLa notazione di sommatoria può anche essere espressa nella forma:\n\\[\n\\sum_{P(i)} x_i,\n\\]\ndove \\(P(i)\\) è una proposizione logica riguardante \\(i\\) che può essere vera o falsa. Quando è evidente che si vogliono sommare tutte le \\(n\\) osservazioni, la notazione può essere semplificata in \\(\\sum_{i} x_i\\) o addirittura \\(\\sum x_i\\). L’indice \\(i\\) può essere sostituito da altre lettere, come \\(k, j, l, \\dots\\), a seconda del contesto.\nPer semplificare i calcoli che coinvolgono le sommatorie, è utile conoscere alcune proprietà fondamentali.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html#manipolazione-di-somme",
    "href": "chapters/appendix/a12_sum_notation.html#manipolazione-di-somme",
    "title": "Appendice F — Sommatorie",
    "section": "",
    "text": "F.1.1 Proprietà 1 (Somma di una costante)\nLa sommatoria di \\(n\\) valori tutti uguali a una costante \\(a\\) è pari a \\(n\\) volte la costante stessa:\n\\[\n\\sum_{i=1}^{n} a = \\underbrace{a + a + \\dots + a}_{n \\text{ volte}} = n a.\n\\]\n\n\nF.1.2 Proprietà 2 (Proprietà distributiva)\nSe l’argomento della sommatoria contiene una costante, è possibile fattorizzarla. Ad esempio:\n\\[\n\\sum_{i=1}^{n} a x_i = a x_1 + a x_2 + \\dots + a x_n = a (x_1 + x_2 + \\dots + x_n) = a \\sum_{i=1}^{n} x_i.\n\\]\n\n\nF.1.3 Proprietà 3 (Proprietà associativa)\nSe l’argomento della sommatoria è una somma, possiamo separare i termini:\n\\[\n\\sum_{i=1}^{n} (a + x_i) = (a + x_1) + (a + x_2) + \\dots + (a + x_n) = n a + \\sum_{i=1}^{n} x_i.\n\\]\nIn generale, possiamo scrivere:\n\\[\n\\sum_{i=1}^{n} (x_i + y_i) = \\sum_{i=1}^{n} x_i + \\sum_{i=1}^{n} y_i.\n\\]\n\n\nF.1.4 Proprietà 4 (Operazioni algebriche)\nSe è necessario eseguire un’operazione algebrica (come l’elevamento a potenza o il logaritmo) sull’argomento della sommatoria, questa operazione deve essere eseguita prima della somma. Ad esempio:\n\\[\n\\sum_{i=1}^{n} x_i^2 = x_1^2 + x_2^2 + \\dots + x_n^2 \\neq \\left( \\sum_{i=1}^{n} x_i \\right)^2.\n\\]\n\n\nF.1.5 Proprietà 5 (Prodotto di termini)\nNel caso di un prodotto tra termini, il prodotto deve essere eseguito prima della somma:\n\\[\n\\sum_{i=1}^{n} x_i y_i = x_1 y_1 + x_2 y_2 + \\dots + x_n y_n.\n\\]\nInfatti, \\(a_1 b_1 + a_2 b_2 \\neq (a_1 + a_2)(b_1 + b_2)\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html#doppia-sommatoria",
    "href": "chapters/appendix/a12_sum_notation.html#doppia-sommatoria",
    "title": "Appendice F — Sommatorie",
    "section": "F.2 Doppia sommatoria",
    "text": "F.2 Doppia sommatoria\nIn alcuni contesti, si incontrano espressioni con una doppia sommatoria e un doppio indice:\n\\[\n\\sum_{i=1}^{n} \\sum_{j=1}^{m} x_{ij}.\n\\]\nQuesta notazione implica che, per ogni valore dell’indice esterno \\(i\\) (da \\(1\\) a \\(n\\)), si deve sviluppare la sommatoria interna per \\(j\\) (da \\(1\\) a \\(m\\)). Ad esempio:\n\\[\n\\sum_{i=1}^{3} \\sum_{j=4}^{6} x_{ij} = (x_{1,4} + x_{1,5} + x_{1,6}) + (x_{2,4} + x_{2,5} + x_{2,6}) + (x_{3,4} + x_{3,5} + x_{3,6}).\n\\]\nUn caso particolare interessante è la doppia sommatoria del prodotto di due variabili:\n\\[\n\\sum_{i=1}^{n} \\sum_{j=1}^{n} x_i y_j.\n\\]\nIn questo caso, poiché \\(x_i\\) non dipende dall’indice \\(j\\), possiamo estrarre \\(x_i\\) dalla sommatoria interna:\n\\[\n\\sum_{i=1}^{n} \\left( x_i \\sum_{j=1}^{n} y_j \\right).\n\\]\nAllo stesso modo, la sommatoria interna \\(\\sum_{j=1}^{n} y_j\\) non dipende da \\(i\\), quindi può essere estratta dalla sommatoria esterna:\n\\[\n\\sum_{i=1}^{n} \\sum_{j=1}^{n} x_i y_j = \\left( \\sum_{i=1}^{n} x_i \\right) \\left( \\sum_{j=1}^{n} y_j \\right).\n\\]\n\nF.2.1 Esempio pratico\nConsideriamo i vettori \\(x = \\{2, 3, 1\\}\\) e \\(y = \\{1, 4, 9\\}\\). Calcoliamo la doppia sommatoria:\n\\[\n\\begin{aligned}\n\\sum_{i=1}^3 \\sum_{j=1}^3 x_i y_j &= x_1 y_1 + x_1 y_2 + x_1 y_3 + x_2 y_1 + x_2 y_2 + x_2 y_3 + x_3 y_1 + x_3 y_2 + x_3 y_3 \\\\\n&= 2 \\times (1 + 4 + 9) + 3 \\times (1 + 4 + 9) + 1 \\times (1 + 4 + 9) \\\\\n&= 2 \\times 14 + 3 \\times 14 + 1 \\times 14 = 84.\n\\end{aligned}\n\\]\nD’altra parte, il prodotto delle due sommatorie è:\n\\[\n\\left( \\sum_{i=1}^3 x_i \\right) \\left( \\sum_{j=1}^3 y_j \\right) = (2 + 3 + 1) \\times (1 + 4 + 9) = 6 \\times 14 = 84.\n\\]\nI due risultati coincidono, confermando la validità della proprietà.\nPer ulteriori approfondimenti, si consiglia la consultazione del testo Concrete Mathematics: A Foundation for Computer Science (Graham et al., 1994).\nEsercizi pratici sono disponibili sulla seguente pagina web.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html#bibliografia",
    "href": "chapters/appendix/a12_sum_notation.html#bibliografia",
    "title": "Appendice F — Sommatorie",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGraham, R. L., Knuth, D. E., & Patashnik, O. (1994). Concrete Mathematics: A Foundation for Computer Science (2nd ed.). Addison-Wesley.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html",
    "href": "chapters/appendix/a13_sets.html",
    "title": "Appendice G — Insiemi",
    "section": "",
    "text": "G.1 Diagrammi di Eulero-Venn\nUn insieme (o collezione, classe, gruppo, …) è stato definito da Georg Cantor nel modo seguente:\nMentre non è rilevante la natura degli oggetti che costituiscono l’insieme, ciò che importa è distinguere se un dato oggetto appartenga o meno ad un insieme. Deve essere vera una delle due possibilità: il dato oggetto è un elemento dell’insieme considerato oppure non è elemento dell’insieme considerato. Due insiemi \\(A\\) e \\(B\\) si dicono uguali se sono formati dagli stessi elementi, anche se disposti in ordine diverso: \\(A=B\\). Due insiemi \\(A\\) e \\(B\\) si dicono diversi se non contengono gli stessi elementi: \\(A \\neq B\\). Ad esempio, i seguenti insiemi sono uguali:\n\\[\n\\{1, 2, 3\\} = \\{3, 1, 2\\} = \\{1, 3, 2\\}= \\{1, 1, 1, 2, 3, 3, 3\\}.\n\\]\nGli insiemi sono denotati da una lettera maiuscola, mentre le lettere minuscole, di solito, designano gli elementi di un insieme. Per esempio, un generico insieme \\(A\\) si indica con\n\\[\nA = \\{a_1, a_2, \\dots, a_n\\}, \\quad \\text{con } n &gt; 0.\n\\]\nLa scrittura \\(a \\in A\\) dice che \\(a\\) è un elemento di \\(A\\). Per dire che \\(b\\) non è un elemento di \\(A\\) si scrive \\(b \\notin A.\\)\nPer quegli insiemi i cui elementi soddisfano una certa proprietà che li caratterizza, tale proprietà può essere usata per descrivere più sinteticamente l’insieme:\n\\[\nA = \\{x ~\\vert~ \\text{proprietà posseduta da } x\\},\n\\]\nche si legge come “\\(A\\) è l’insieme degli elementi \\(x\\) per cui è vera la proprietà indicata.” Per esempio, per indicare l’insieme \\(A\\) delle coppie di numeri reali \\((x,y)\\) che appartengono alla parabola \\(y = x^2 + 1\\) si può scrivere:\n\\[\nA = \\{(x,y) ~\\vert~ y = x^2 + 1\\}.\n\\]\nDati due insiemi \\(A\\) e \\(B\\), diremo che \\(A\\) è un sottoinsieme di \\(B\\) se e solo se tutti gli elementi di \\(A\\) sono anche elementi di \\(B\\):\n\\[\nA \\subseteq B \\iff (\\forall x \\in A \\Rightarrow x \\in B).\n\\]\nSe esiste almeno un elemento di \\(B\\) che non appartiene ad \\(A\\) allora diremo che \\(A\\) è un sottoinsieme proprio di \\(B\\):\n\\[\nA \\subset B \\iff (A \\subseteq B, \\exists~ x \\in B ~\\vert~ x \\notin A).\n\\]\nUn altro insieme, detto insieme delle parti, o insieme potenza, che si associa all’insieme \\(A\\) è l’insieme di tutti i sottoinsiemi di \\(A\\), inclusi l’insieme vuoto e \\(A\\) stesso. Per esempio, per l’insieme \\(A = \\{a, b, c\\}\\), l’insieme delle parti è:\n\\[\n\\mathcal{P}(A) = \\{\n\\emptyset, \\{a\\}, \\{b\\}, \\{c\\},\n\\{a, b\\}, \\{a, c\\}, \\{c, b\\},\n\\{a, b, c\\}\n\\}.\n\\]\nI diagrammi di Venn sono uno strumento grafico molto utile per rappresentare gli insiemi e per verificare le proprietà delle operazioni tra di essi. Questi diagrammi prendono il nome dal matematico inglese del 19° secolo John Venn, anche se rappresentazioni simili erano già state utilizzate in precedenza da Leibniz e Eulero.\nI diagrammi di Venn rappresentano gli insiemi come regioni del piano delimitate da una curva chiusa. Nel caso di insiemi finiti, è possibile evidenziare alcuni elementi di un insieme tramite punti, e in alcuni casi possono essere evidenziati tutti gli elementi degli insiemi considerati.\nIn sostanza, questi diagrammi sono un modo visuale per rappresentare le proprietà degli insiemi e delle operazioni tra di essi. Sono uno strumento molto utile per visualizzare la relazione tra gli insiemi e per capire meglio come si combinano gli elementi all’interno di essi.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#appartenenza-ad-un-insieme",
    "href": "chapters/appendix/a13_sets.html#appartenenza-ad-un-insieme",
    "title": "Appendice G — Insiemi",
    "section": "\nG.2 Appartenenza ad un insieme",
    "text": "G.2 Appartenenza ad un insieme\nUsiamo ora R\n\nSet1 &lt;- c(1, 2)\nprint(Set1)\n\n[1] 1 2\n\nprint(class(Set1))\n\n[1] \"numeric\"\n\n\n\nmy_list &lt;- c(1, 2, 3, 4)\nmy_set_from_list &lt;- unique(my_list)\nprint(my_set_from_list)\n\n[1] 1 2 3 4\n\n\nL’appartenenza ad un insieme si verifica con %in%.\n\nmy_set &lt;- c(1, 3, 5)\nprint(\"Ecco il mio insieme:\")\n\n[1] \"Ecco il mio insieme:\"\n\nprint(my_set)\n\n[1] 1 3 5\n\nprint(\"1 appartiene all'insieme:\")\n\n[1] \"1 appartiene all'insieme:\"\n\nprint(1 %in% my_set)\n\n[1] TRUE\n\nprint(\"2 non appartiene all'insieme:\")\n\n[1] \"2 non appartiene all'insieme:\"\n\nprint(2 %in% my_set)\n\n[1] FALSE\n\nprint(\"4 NON appartiene all'insieme:\")\n\n[1] \"4 NON appartiene all'insieme:\"\n\nprint(!(4 %in% my_set))\n\n[1] TRUE",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#relazioni-tra-insiemi",
    "href": "chapters/appendix/a13_sets.html#relazioni-tra-insiemi",
    "title": "Appendice G — Insiemi",
    "section": "\nG.3 Relazioni tra insiemi",
    "text": "G.3 Relazioni tra insiemi\nEsaminiamo le funzioni Python per descrivere le relazioni tra insiemi. In particolare, dopo avere definito l’insieme universo e l’insieme vuoto, considereremo la relazione di inclusione che conduce al concetto di sottoinsieme. Analogamente si definisce il concetto di sovrainsieme. Mostreremo anche come valutare se due insiemi sono disgiunti (si dicono disgiunti gli insiemi con intersezione vuota).\n\nUniv &lt;- 0:10\nSuper &lt;- Univ[Univ %% 2 == 0]\nDisj &lt;- Univ[Univ %% 2 == 1]\nSub &lt;- c(4, 6)\nNull &lt;- Univ[Univ &gt; 10]\n\n\nprint(\"Insieme Universo (tutti gli interi positivi fino a 10):\")\n\n[1] \"Insieme Universo (tutti gli interi positivi fino a 10):\"\n\nprint(Univ)\n\n [1]  0  1  2  3  4  5  6  7  8  9 10\n\nprint(\"Tutti gli interi positivi pari fino a 10:\")\n\n[1] \"Tutti gli interi positivi pari fino a 10:\"\n\nprint(Super)\n\n[1]  0  2  4  6  8 10\n\nprint(\"Tutti gli interi positivi dispari fino a 10:\")\n\n[1] \"Tutti gli interi positivi dispari fino a 10:\"\n\nprint(Disj)\n\n[1] 1 3 5 7 9\n\nprint(\"Insieme di due elementi, 4 e 6:\")\n\n[1] \"Insieme di due elementi, 4 e 6:\"\n\nprint(Sub)\n\n[1] 4 6\n\nprint(\"Un insieme vuoto:\")\n\n[1] \"Un insieme vuoto:\"\n\nprint(Null)\n\ninteger(0)\n\n\n\nprint('È \"Super\" un sovrainsieme di \"Sub\"?')\n\n[1] \"È \\\"Super\\\" un sovrainsieme di \\\"Sub\\\"?\"\n\nprint(all(Sub %in% Super))\n\n[1] TRUE\n\nprint('È \"Super\" un sottoinsieme di \"Univ\"?')\n\n[1] \"È \\\"Super\\\" un sottoinsieme di \\\"Univ\\\"?\"\n\nprint(all(Super %in% Univ))\n\n[1] TRUE\n\nprint('È \"Sub\" un sovrainsieme di \"Super\"?')\n\n[1] \"È \\\"Sub\\\" un sovrainsieme di \\\"Super\\\"?\"\n\nprint(all(Super %in% Sub))\n\n[1] FALSE\n\nprint('Sono \"Super\" e \"Disj\" insiemi disgiunti?')\n\n[1] \"Sono \\\"Super\\\" e \\\"Disj\\\" insiemi disgiunti?\"\n\nprint(length(intersect(Super, Disj)) == 0)\n\n[1] TRUE",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#operazioni-tra-insiemi",
    "href": "chapters/appendix/a13_sets.html#operazioni-tra-insiemi",
    "title": "Appendice G — Insiemi",
    "section": "\nG.4 Operazioni tra insiemi",
    "text": "G.4 Operazioni tra insiemi\nSi definisce intersezione di \\(A\\) e \\(B\\) l’insieme \\(A \\cap B\\) di tutti gli elementi \\(x\\) che appartengono ad \\(A\\) e contemporaneamente a \\(B\\):\n\\[\nA \\cap B = \\{x ~\\vert~ x \\in A \\land x \\in B\\}.\n\\]\nSi definisce unione di \\(A\\) e \\(B\\) l’insieme \\(A \\cup B\\) di tutti gli elementi \\(x\\) che appartengono ad \\(A\\) o a \\(B\\), cioè\n\\[\nA \\cup B = \\{x ~\\vert~ x \\in A \\lor x \\in B\\}.\n\\]\nDifferenza. Si indica con \\(A \\setminus B\\) l’insieme degli elementi di \\(A\\) che non appartengono a \\(B\\):\n\\[\nA \\setminus B = \\{x ~\\vert~ x \\in A \\land x \\notin B\\}.\n\\]\nInsieme complementare. Nel caso che sia \\(B \\subseteq A\\), l’insieme differenza \\(A \\setminus B\\) è detto insieme complementare di \\(B\\) in \\(A\\) e si indica con \\(B^C\\).\nDato un insieme \\(S\\), una partizione di \\(S\\) è una collezione di sottoinsiemi di \\(S\\), \\(S_1, \\dots, S_k\\), tali che\n\\[\nS = S_1 \\cup S_2 \\cup \\dots S_k\n\\]\ne\n\\[\nS_i \\cap S_j, \\quad \\text{con } i \\neq j.\n\\]\nLa relazione tra unione, intersezione e insieme complementare è data dalle leggi di DeMorgan:\n\\[\n(A \\cup B)^c = A^c \\cap B^c,\n\\]\n\\[\n(A \\cap B)^c = A^c \\cup B^c.\n\\]\nIn tutte le seguenti figure, \\(S\\) è la regione delimitata dal rettangolo, \\(L\\) è la regione all’interno del cerchio di sinistra e \\(R\\) è la regione all’interno del cerchio di destra. La regione evidenziata mostra l’insieme indicato sotto ciascuna figura.\n\n\nDiagrammi di Venn\n\nI diagrammi di Eulero-Venn che illustrano le leggi di DeMorgan sono forniti nella figura seguente.\n\n\nLeggi di DeMorgan\n\nVediamo ora come si eseguono le operazioni tra insiemi con R.\nIntersezione.\n\nS1 &lt;- seq(1, 10, by = 3)\nS2 &lt;- 1:6\nS_intersection &lt;- intersect(S1, S2)\nprint(\"Intersezione di S1 e S2:\")\n\n[1] \"Intersezione di S1 e S2:\"\n\nprint(S_intersection)\n\n[1] 1 4\n\n\nUnione. Si noti che il connettivo logico | corrisponde all’unione.\n\nS_union &lt;- union(S1, S2)\nprint(\"Unione di S1 e S2:\")\n\n[1] \"Unione di S1 e S2:\"\n\nprint(S_union)\n\n[1]  1  4  7 10  2  3  5  6\n\n\nInsieme complementare.\n\nS &lt;- seq(0, 20, by = 2)\nS_complement &lt;- setdiff(0:20, S)\nprint(\"S è l'insieme dei numeri interi pari tra 0 e 20:\")\n\n[1] \"S è l'insieme dei numeri interi pari tra 0 e 20:\"\n\nprint(S)\n\n [1]  0  2  4  6  8 10 12 14 16 18 20\n\nprint(\"S_complement è l'insieme dei numeri interi dispari tra 0 e 20:\")\n\n[1] \"S_complement è l'insieme dei numeri interi dispari tra 0 e 20:\"\n\nprint(S_complement)\n\n [1]  1  3  5  7  9 11 13 15 17 19\n\n\n\nprint(\"È l'unione di S e S_complement uguale a tutti i numeri interi tra 0 e 20?\")\n\n[1] \"È l'unione di S e S_complement uguale a tutti i numeri interi tra 0 e 20?\"\n\nprint(setequal(union(S, S_complement), 0:20))\n\n[1] TRUE\n\n\nDifferenza tra insiemi.\n\nS1 &lt;- seq(0, 30, by = 3)\nS2 &lt;- seq(0, 30, by = 5)\nprint(\"Differenza tra S2 e S1:\")\n\n[1] \"Differenza tra S2 e S1:\"\n\nprint(setdiff(S2, S1))\n\n[1]  5 10 20 25\n\nprint(\"Differenza tra S1 e S2:\")\n\n[1] \"Differenza tra S1 e S2:\"\n\nprint(setdiff(S1, S2))\n\n[1]  3  6  9 12 18 21 24 27\n\n\nDifferenza simmetrica. La differenza simmetrica, indicata con il simbolo Δ, è un’operazione insiemistica definita come unione tra la differenza tra il primo e il secondo insieme e la differenza tra il secondo e il primo insieme. In modo equivalente, la differenza simmetrica equivale all’unione tra i due insiemi meno la loro intersezione.\n\nsym_diff &lt;- union(setdiff(S1, S2), setdiff(S2, S1))\nprint(\"Differenza simmetrica:\")\n\n[1] \"Differenza simmetrica:\"\n\nprint(sym_diff)\n\n [1]  3  6  9 12 18 21 24 27  5 10 20 25",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#coppie-ordinate-e-prodotto-cartesiano",
    "href": "chapters/appendix/a13_sets.html#coppie-ordinate-e-prodotto-cartesiano",
    "title": "Appendice G — Insiemi",
    "section": "\nG.5 Coppie ordinate e prodotto cartesiano",
    "text": "G.5 Coppie ordinate e prodotto cartesiano\nUna coppia ordinata \\((x,y)\\) è l’insieme i cui elementi sono \\(x \\in A\\) e \\(y \\in B\\) e nella quale \\(x\\) è la prima componente (o prima coordinata) e \\(y\\) la seconda. L’insieme di tutte le coppie ordinate costruite a partire dagli insiemi \\(A\\) e \\(B\\) viene detto prodotto cartesiano:\n\\[\nA \\times B = \\{(x, y) ~\\vert~ x \\in A \\land y \\in B\\}.\n\\]\nAd esempio, sia \\(A = \\{1, 2, 3\\}\\) e \\(B = \\{a, b\\}\\). Allora,\n\\[\n\\{1, 2\\} \\times \\{a, b, c\\} = \\{(1, a), (1, b), (1, c), (2, a), (2, b), (2, c)\\}.\n\\]\nPiù in generale, un prodotto cartesiano di \\(n\\) insiemi può essere rappresentato da un array di \\(n\\) dimensioni, dove ogni elemento è una ennupla o tupla ordinata (ovvero, una collezione o un elenco ordinato di \\(n\\) oggetti). Una n-pla ordinata si distingue da un insieme di \\(n\\) elementi in quanto fra gli elementi di un insieme non è dato alcun ordine. Inoltre gli elementi di una ennupla possono anche essere ripetuti. Essendo la n-pla un elenco ordinato, in generale di ogni suo elemento è possibile dire se sia il primo, il secondo, il terzo, eccetera, fino all’n-esimo. Il prodotto cartesiano prende il nome da René Descartes la cui formulazione della geometria analitica ha dato origine al concetto.\n\nA &lt;- c(\"a\", \"b\", \"c\")\nS &lt;- 1:3\ncartesian_product &lt;- expand.grid(A, S)\nprint(\"Prodotto cartesiano di A e S:\")\n\n[1] \"Prodotto cartesiano di A e S:\"\n\nprint(cartesian_product)\n\n  Var1 Var2\n1    a    1\n2    b    1\n3    c    1\n4    a    2\n5    b    2\n6    c    2\n7    a    3\n8    b    3\n9    c    3\n\n\nSi definisce cardinalità (o potenza) di un insieme finito il numero degli elementi dell’insieme. Viene indicata con \\(\\vert A\\vert, \\#(A)\\) o \\(\\text{c}(A)\\).\n\nprint(\"La cardinalità dell'insieme prodotto cartesiano è:\")\n\n[1] \"La cardinalità dell'insieme prodotto cartesiano è:\"\n\nprint(nrow(cartesian_product))\n\n[1] 9\n\n\nPotenza del prodotto cartesiano\n\nA &lt;- c(\"Head\", \"Tail\")\np2 &lt;- expand.grid(A, A)\nprint(\"Il quadrato dell'insieme A è un insieme che contiene:\")\n\n[1] \"Il quadrato dell'insieme A è un insieme che contiene:\"\n\nprint(nrow(p2))\n\n[1] 4\n\nprint(p2)\n\n  Var1 Var2\n1 Head Head\n2 Tail Head\n3 Head Tail\n4 Tail Tail\n\n\n\np3 &lt;- expand.grid(A, A, A)\nprint(\"L'insieme A elevato alla terza potenza è costituito da:\")\n\n[1] \"L'insieme A elevato alla terza potenza è costituito da:\"\n\nprint(nrow(p3))\n\n[1] 8\n\nprint(p3)\n\n  Var1 Var2 Var3\n1 Head Head Head\n2 Tail Head Head\n3 Head Tail Head\n4 Tail Tail Head\n5 Head Head Tail\n6 Tail Head Tail\n7 Head Tail Tail\n8 Tail Tail Tail",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html",
    "href": "chapters/appendix/a14_combinatorics.html",
    "title": "Appendice H — Calcolo combinatorio",
    "section": "",
    "text": "H.1 Principio della somma\nIl calcolo combinatorio studia il numero di modi in cui è possibile combinare, ordinare o disporre elementi appartenenti a uno o più insiemi, seguendo regole ben definite. Molti problemi di probabilità richiedono strumenti combinatori per determinare la probabilità di eventi complessi. In questo capitolo, esploreremo i concetti fondamentali del calcolo combinatorio, illustrandoli attraverso il modello del campionamento dall’urna. Tratteremo i principi della somma e del prodotto, fondamentali per affrontare problemi più avanzati, come permutazioni, disposizioni e combinazioni.\nIl principio della somma si applica quando un insieme di elementi può essere suddiviso in sottoinsiemi disgiunti (ossia senza sovrapposizioni). In questo caso, il numero totale di elementi è dato dalla somma delle cardinalità dei sottoinsiemi:\n\\[\nn_{\\text{tot}} = n_1 + n_2 + \\dots + n_k .\n\\]\nEsempio\nUn distributore contiene tre scomparti di caramelle, ciascuno con un diverso tipo di dolci:\nQuante caramelle ci sono in totale nel distributore?\nSecondo il principio della somma, il numero totale di caramelle è:\n\\[\nn_{\\text{tot}} = n_A + n_B + n_C = 10 + 8 + 12 = 30.\n\\]\nCalcolo in R:\nA &lt;- 10\nB &lt;- 8\nC &lt;- 12\n\ntotale_caramelle &lt;- A + B + C\ntotale_caramelle\n#&gt; [1] 30\nRisultato: Nel distributore ci sono 30 caramelle in totale.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#principio-della-somma",
    "href": "chapters/appendix/a14_combinatorics.html#principio-della-somma",
    "title": "Appendice H — Calcolo combinatorio",
    "section": "",
    "text": "Scomparto A: 10 caramelle alla menta,\n\n\nScomparto B: 8 caramelle alla frutta,\n\n\nScomparto C: 12 caramelle al cioccolato.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#principio-del-prodotto",
    "href": "chapters/appendix/a14_combinatorics.html#principio-del-prodotto",
    "title": "Appendice H — Calcolo combinatorio",
    "section": "\nH.2 Principio del prodotto",
    "text": "H.2 Principio del prodotto\nIl principio del prodotto si applica quando un’operazione può essere suddivisa in più fasi indipendenti, ciascuna con un numero specifico di possibilità. In tal caso, il numero totale di combinazioni è dato dal prodotto delle possibilità offerte da ciascuna fase:\n\\[\nn_{\\text{tot}} = n_1 \\cdot n_2 \\cdot \\dots \\cdot n_k .\n\\]\nEsempio\nSupponiamo di avere quattro urne contenenti palline di diverso colore:\n\n\nUrna A: 5 palline,\n\n\nUrna B: 6 palline,\n\n\nUrna C: 3 palline,\n\n\nUrna D: 2 palline.\n\nVogliamo formare insiemi di due palline, ciascuna estratta da urne differenti.\nSecondo il principio del prodotto, per ogni coppia di urne, il numero di combinazioni è dato dal prodotto del numero di palline contenute nelle due urne. Utilizziamo poi il principio della somma per ottenere il totale complessivo:\n\\[\nn_{\\text{tot}} = AB + AC + AD + BC + BD + CD.\n\\]\nCalcolo in R:\n\nAB &lt;- 5 * 6\nAC &lt;- 5 * 3\nAD &lt;- 5 * 2\nBC &lt;- 6 * 3\nBD &lt;- 6 * 2\nCD &lt;- 3 * 2\n\ntotale_insiemi &lt;- AB + AC + AD + BC + BD + CD\ntotale_insiemi\n#&gt; [1] 91\n\nRisultato: È possibile formare 91 insiemi di due palline, ciascuna estratta da urne differenti.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#il-modello-dellurna-e-i-metodi-di-campionamento",
    "href": "chapters/appendix/a14_combinatorics.html#il-modello-dellurna-e-i-metodi-di-campionamento",
    "title": "Appendice H — Calcolo combinatorio",
    "section": "\nH.3 Il modello dell’urna e i metodi di campionamento",
    "text": "H.3 Il modello dell’urna e i metodi di campionamento\nMolti problemi di calcolo combinatorio possono essere interpretati come estrazioni di palline da un’urna. Esistono quattro modi fondamentali di effettuare un campionamento, a seconda che:\n\nle estrazioni siano con o senza ripetizione,\nl’ordine degli elementi conti o meno.\n\nQueste quattro combinazioni danno origine a quattro principali metodi di campionamento:\n\n\nCon ripetizione e con ordine: Dopo ogni estrazione, la pallina viene rimessa nell’urna. (Es. formazione di codici numerici con ripetizioni)\n\nSenza ripetizione e con ordine: Ogni estrazione rimuove definitivamente la pallina dall’urna. (Es. assegnare premi in una gara)\n\nCon ripetizione e senza ordine: Si considerano i gruppi di elementi senza preoccuparsi dell’ordine. (Es. selezionare un certo numero di ingredienti da una dispensa)\n\nSenza ripetizione e senza ordine: Si scelgono elementi distinti senza considerare l’ordine. (Es. formare squadre da un gruppo di persone)\n\n\nEsempio H.1  \n\nurna &lt;- c(\"a\", \"b\", \"c\")\n\n# Con ripetizione e ordine\ncampionamento1 &lt;- expand.grid(urna, urna) |&gt;\n    rename(Elemento1 = Var1, Elemento2 = Var2)\n\n# Senza ripetizione e con ordine\ncampionamento2 &lt;- permutations(n = length(urna), r = 2, v = urna) |&gt;\n    as.data.frame() |&gt;\n    rename(Elemento1 = V1, Elemento2 = V2)\n\n# Con ripetizione e senza ordine\ncampionamento3 &lt;- combinations(\n    n = length(urna), r = 2, v = urna, repeats.allowed = TRUE\n) |&gt;\n    as.data.frame() |&gt;\n    rename(Elemento1 = V1, Elemento2 = V2)\n\n# Senza ripetizione e senza ordine\ncampionamento4 &lt;- combinations(n = length(urna), r = 2, v = urna) |&gt;\n    as.data.frame() |&gt;\n    rename(Elemento1 = V1, Elemento2 = V2)\n\n# Risultati\nlist(\n    `Con ripetizione e ordine` = campionamento1,\n    `Senza ripetizione e con ordine` = campionamento2,\n    `Con ripetizione e senza ordine` = campionamento3,\n    `Senza ripetizione e senza ordine` = campionamento4\n)\n#&gt; $`Con ripetizione e ordine`\n#&gt;   Elemento1 Elemento2\n#&gt; 1         a         a\n#&gt; 2         b         a\n#&gt; 3         c         a\n#&gt; 4         a         b\n#&gt; 5         b         b\n#&gt; 6         c         b\n#&gt; 7         a         c\n#&gt; 8         b         c\n#&gt; 9         c         c\n#&gt; \n#&gt; $`Senza ripetizione e con ordine`\n#&gt;   Elemento1 Elemento2\n#&gt; 1         a         b\n#&gt; 2         a         c\n#&gt; 3         b         a\n#&gt; 4         b         c\n#&gt; 5         c         a\n#&gt; 6         c         b\n#&gt; \n#&gt; $`Con ripetizione e senza ordine`\n#&gt;   Elemento1 Elemento2\n#&gt; 1         a         a\n#&gt; 2         a         b\n#&gt; 3         a         c\n#&gt; 4         b         b\n#&gt; 5         b         c\n#&gt; 6         c         c\n#&gt; \n#&gt; $`Senza ripetizione e senza ordine`\n#&gt;   Elemento1 Elemento2\n#&gt; 1         a         b\n#&gt; 2         a         c\n#&gt; 3         b         c",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#permutazioni-disporre-tutti-gli-elementi-con-ordine",
    "href": "chapters/appendix/a14_combinatorics.html#permutazioni-disporre-tutti-gli-elementi-con-ordine",
    "title": "Appendice H — Calcolo combinatorio",
    "section": "\nH.4 Permutazioni: Disporre tutti gli elementi con ordine",
    "text": "H.4 Permutazioni: Disporre tutti gli elementi con ordine\nLe permutazioni rappresentano tutti i modi in cui è possibile ordinare \\(n\\) elementi distinti. Il numero di permutazioni è dato da:\n\\[\nP_n = n!\n\\]\ndove \\(n!\\) (n fattoriale) è il prodotto di tutti i numeri da 1 a \\(n\\):\n\\[\nn! = n \\cdot (n-1) \\cdot (n-2) \\cdot \\dots \\cdot 1.\n\\]\n\nH.4.1 Intuizione della formula\nImmaginiamo di avere \\(n\\) elementi distinti e di doverli disporre in una sequenza. Il primo elemento può essere scelto in \\(n\\) modi. Una volta scelto il primo, rimangono \\(n-1\\) possibilità per il secondo, poi \\(n-2\\) per il terzo e così via, fino all’ultimo elemento, che avrà 1 sola possibilità. Applicando il principio del prodotto, otteniamo:\n\\[\nP_n = n \\times (n-1) \\times (n-2) \\times \\dots \\times 1 = n!\n\\]\n\nH.4.2 Metodo di campionamento corrispondente\n\n\nCampionamento senza ripetizione e con ordine: si estrae una pallina, la si esclude dall’urna e si continua fino a esaurire gli elementi.\n\n\nEsempio pratico: Ordinare i partecipanti di una gara su un podio (primo, secondo e terzo classificato).\n\nH.4.3 Esempio in R: Permutazioni di tre elementi\nSe abbiamo tre lettere {a, b, c}, le possibili permutazioni sono:\n\\[\nP_3 = 3! = 3 \\times 2 \\times 1 = 6.\n\\]\n\nA &lt;- c(\"a\", \"b\", \"c\")\nperm &lt;- permutations(n = length(A), r = length(A), v = A)\nprint(perm)\n#&gt;      [,1] [,2] [,3]\n#&gt; [1,] \"a\"  \"b\"  \"c\" \n#&gt; [2,] \"a\"  \"c\"  \"b\" \n#&gt; [3,] \"b\"  \"a\"  \"c\" \n#&gt; [4,] \"b\"  \"c\"  \"a\" \n#&gt; [5,] \"c\"  \"a\"  \"b\" \n#&gt; [6,] \"c\"  \"b\"  \"a\"\nnrow(perm)  # Verifica del numero di permutazioni\n#&gt; [1] 6\n\nRisultato:\n\\[\n\\{a, b, c\\}, \\{a, c, b\\}, \\{b, a, c\\}, \\{b, c, a\\}, \\{c, a, b\\}, \\{c, b, a\\}.\n\\]",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#disposizioni-selezionare-alcuni-elementi-con-ordine",
    "href": "chapters/appendix/a14_combinatorics.html#disposizioni-selezionare-alcuni-elementi-con-ordine",
    "title": "Appendice H — Calcolo combinatorio",
    "section": "\nH.5 Disposizioni: Selezionare alcuni elementi con ordine",
    "text": "H.5 Disposizioni: Selezionare alcuni elementi con ordine\nLe disposizioni si usano quando si scelgono \\(k\\) elementi da un insieme di \\(n\\), rispettando l’ordine. Il numero totale di disposizioni è:\n\\[\nD_{n,k} = \\frac{n!}{(n-k)!} .\n\\]\n\nH.5.1 Intuizione della formula\nSupponiamo di avere \\(n\\) elementi e di voler scegliere solo \\(k\\) elementi, mantenendo l’ordine.\n\nil primo elemento può essere scelto in \\(n\\) modi;\nil secondo elemento può essere scelto tra gli \\(n-1\\) elementi rimanenti;\n\nil terzo tra gli \\(n-2\\) rimanenti.\n\nSi prosegue fino a quando si hanno scelto \\(k\\) elementi, fermandosi prima di esaurire tutti gli elementi.\n\\[\nD_{n,k} = n \\times (n-1) \\times (n-2) \\times \\dots \\times (n-k+1) .\n\\]\nQuesta espressione corrisponde alla divisione del fattoriale di \\(n\\) per il fattoriale degli elementi che non vengono selezionati:\n\\[\nD_{n,k} = \\frac{n!}{(n-k)!} .\n\\]\n\nH.5.2 Metodo di campionamento corrispondente\n\n\nCampionamento senza ripetizione e con ordine: si estrae una pallina, la si esclude dall’urna e si continua fino a raggiungere il numero desiderato di elementi, fermandosi prima di esaurire tutti gli elementi.\n\n\nEsempio pratico: Estrarre casualmente 2 studenti da una classe di 10 e assegnare loro i ruoli di rappresentante e vice-rappresentante (l’ordine conta).\n\nH.5.3 Esempio in R: Disposizioni di 2 elementi da {a, b, c}\nSe scegliamo 2 lettere su 3, il numero di disposizioni è:\n\\[\nD_{3,2} = \\frac{3!}{(3-2)!} = \\frac{3 \\times 2 \\times 1}{1} = 6.\n\\]\n\ndisp &lt;- permutations(n = length(A), r = 2, v = A)\nprint(disp)\n#&gt;      [,1] [,2]\n#&gt; [1,] \"a\"  \"b\" \n#&gt; [2,] \"a\"  \"c\" \n#&gt; [3,] \"b\"  \"a\" \n#&gt; [4,] \"b\"  \"c\" \n#&gt; [5,] \"c\"  \"a\" \n#&gt; [6,] \"c\"  \"b\"\nnrow(disp)  # Verifica del numero di disposizioni\n#&gt; [1] 6\n\nRisultato:\n\\[\n\\{a, b\\}, \\{a, c\\}, \\{b, a\\}, \\{b, c\\}, \\{c, a\\}, \\{c, b\\}.\n\\]\nLe disposizioni considerano l’ordine, quindi \\(\\{a, b\\}\\) è diverso da \\(\\{b, a\\}\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#combinazioni-selezionare-alcuni-elementi-senza-ordine",
    "href": "chapters/appendix/a14_combinatorics.html#combinazioni-selezionare-alcuni-elementi-senza-ordine",
    "title": "Appendice H — Calcolo combinatorio",
    "section": "\nH.6 Combinazioni: Selezionare alcuni elementi senza ordine",
    "text": "H.6 Combinazioni: Selezionare alcuni elementi senza ordine\nLe combinazioni rappresentano il numero di modi per scegliere \\(k\\) elementi da \\(n\\) senza considerare l’ordine. Il numero di combinazioni è dato da:\n\\[\nC_{n,k} = \\binom{n}{k} = \\frac{n!}{k!(n-k)!} .\n\\]\n\nH.6.1 Intuizione della formula\nSupponiamo di avere \\(n\\) elementi e di voler selezionare \\(k\\) elementi senza considerare l’ordine.\nCome nel caso delle disposizioni, il primo elemento può essere scelto in \\(n\\) modi, il secondo in \\(n-1\\), e così via fino a selezionare \\(k\\) elementi.\n\\[\nD_{n,k} = n \\times (n-1) \\times \\dots \\times (n-k+1) .\n\\]\nTuttavia, in questo caso, l’ordine non conta, quindi ogni selezione viene duplicata per il numero di modi in cui i \\(k\\) elementi possono essere ordinati, ossia \\(k!\\) permutazioni interne. Per correggere questa duplicazione, dobbiamo dividere per \\(k!\\):\n\\[\nC_{n,k} = \\frac{D_{n,k}}{k!} = \\frac{n!}{k!(n-k)!} .\n\\]\n\nH.6.2 Metodo di campionamento corrispondente\n\n\nCampionamento senza ripetizione e senza ordine: si estrae una pallina e la si esclude dall’urna, ma non importa l’ordine in cui le palline vengono estratte.\n\n\nEsempio pratico: Formare una squadra di 2 studenti da un gruppo di 10 senza assegnare ruoli specifici (quindi \\(\\{a, b\\}\\) è uguale a \\(\\{b, a\\}\\)).\n\nH.6.3 Esempio in R: Combinazioni di 2 elementi da {a, b, c}\nSe scegliamo 2 lettere su 3 senza considerare l’ordine, otteniamo:\n\\[\nC_{3,2} = \\binom{3}{2} = \\frac{3!}{2!(3-2)!} = \\frac{3 \\times 2 \\times 1}{2 \\times 1 \\times 1} = 3.\n\\]\n\ncomb &lt;- combinations(n = length(A), r = 2, v = A)\nprint(comb)\n#&gt;      [,1] [,2]\n#&gt; [1,] \"a\"  \"b\" \n#&gt; [2,] \"a\"  \"c\" \n#&gt; [3,] \"b\"  \"c\"\nnrow(comb)  # Verifica del numero di combinazioni\n#&gt; [1] 3\n\nRisultato:\n\\[\n\\{a, b\\}, \\{a, c\\}, \\{b, c\\}.\n\\]\nLe combinazioni non considerano l’ordine, quindi \\(\\{a, b\\}\\) è uguale a \\(\\{b, a\\}\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#sintesi-quando-usare-ciascun-metodo",
    "href": "chapters/appendix/a14_combinatorics.html#sintesi-quando-usare-ciascun-metodo",
    "title": "Appendice H — Calcolo combinatorio",
    "section": "\nH.7 Sintesi: Quando usare ciascun metodo?",
    "text": "H.7 Sintesi: Quando usare ciascun metodo?\n\n\n\n\n\n\n\n\n\nMetodo\nRipetizione?\nOrdine?\nFormula\nMetodo di campionamento\n\n\n\nPermutazioni\n❌ No\n✅ Sì\n\\(n!\\)\nSenza ripetizione e con ordine\n\n\nDisposizioni\n❌ No\n✅ Sì\n\\(\\frac{n!}{(n-k)!}\\)\nSenza ripetizione e con ordine\n\n\nCombinazioni\n❌ No\n❌ No\n\\(\\binom{n}{k} = \\frac{n!}{k!(n-k)!}\\)\nSenza ripetizione e senza ordine\n\n\n\nIn conclusione, abbiamo visto come il modello dell’urna aiuti a comprendere i problemi combinatori. Le differenze tra permutazioni, disposizioni e combinazioni dipendono da due fattori fondamentali: ripetizione e ordine.\nQuesta classificazione è essenziale per risolvere problemi di probabilità e statistica in modo rigoroso. Gli esempi e il codice R forniscono strumenti concreti per applicare questi concetti nella pratica.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a15_calculus.html",
    "href": "chapters/appendix/a15_calculus.html",
    "title": "Appendice I — Per liberarvi dai terrori preliminari",
    "section": "",
    "text": "I.1 Integrali\nIn questo capitolo, traduciamo e adattiamo il capitolo Per liberarvi dai terrori preliminari tratto da Calculus made easy.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>I</span>  <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a15_calculus.html#integrali",
    "href": "chapters/appendix/a15_calculus.html#integrali",
    "title": "Appendice I — Per liberarvi dai terrori preliminari",
    "section": "",
    "text": "Il terrore preliminare, che spesso impedisce agli studenti di avvicinarsi all’analisi matematica, può essere superato comprendendo il significato intuitivo dei due simboli principali utilizzati in questo campo.\nQuesti simboli, che possono sembrare intimidatori, sono in realtà molto semplici:\n\n\\(d\\): Questo simbolo significa semplicemente “un po’ di”. Ad esempio, \\(\\operatorname{d}\\!x\\) indica un piccolo incremento di \\(x\\), mentre \\(\\operatorname{d}\\!u\\) rappresenta un piccolo incremento di \\(u\\). I matematici preferiscono dire “un elemento di” invece di “un po’ di”, ma il concetto è lo stesso. Questi piccoli incrementi possono essere considerati infinitamente piccoli.\n\\(\\int\\): Questo simbolo è una S allungata e rappresenta “la somma di”. Quindi, \\(\\int \\operatorname{d}\\!x\\) significa la somma di tutti i piccoli incrementi di \\(x\\), mentre \\(\\int \\operatorname{d}\\!t\\) indica la somma di tutti i piccoli incrementi di \\(t\\). I matematici chiamano questo simbolo “integrale”. Se consideri \\(x\\) come composto da tanti piccoli pezzi \\(\\operatorname{d}\\!x\\), sommandoli tutti otterrai l’intero valore di \\(x\\). La parola “integrale” significa semplicemente “il tutto”. Ad esempio, se pensi a un’ora come composta da 3600 secondi, la somma di tutti questi secondi ti darà un’ora. Quando vedi un’espressione che inizia con \\(\\int\\), significa che devi sommare tutti i piccoli pezzi indicati dai simboli che seguono.\n\nEcco, il terrore è svanito!\n\n\n\n\nI.1.1 Verifica con Simulazioni in R\nPer calcolare e visualizzare l’integrale di una funzione di densità, possiamo utilizzare il linguaggio di programmazione R. Consideriamo come esempio la funzione di densità gaussiana, definita dalla seguente formula:\n\\[\nf(x; \\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{-\\frac{(x - \\mu)^2}{2 \\sigma^2}}.\n\\]\nIn R, possiamo definire questa funzione come segue:\n\ngaussian &lt;- function(x, mu, sigma) {\n  1 / (sigma * sqrt(2 * pi)) * exp(-((x - mu)^2) / (2 * sigma^2))\n}\n\nDefiniamo i parametri e generiamo i valori per il calcolo della funzione di densità su un intervallo:\n\nmu &lt;- 0      # Media\nsigma &lt;- 1   # Deviazione standard\na &lt;- -10     # Limite inferiore\nb &lt;- 10      # Limite superiore\nn &lt;- 10000   # Numero di punti\n\nx_range &lt;- seq(a, b, length.out = n)  # Valori x\nfx &lt;- gaussian(x_range, mu, sigma)   # Ordinata della funzione\n\nVisualizziamo la funzione utilizzando il pacchetto ggplot2:\n\nlibrary(ggplot2)\nlibrary(scales)\n\nggplot(data.frame(x = x_range, fx = fx), aes(x, fx)) +\n  geom_line(color = \"blue\") +\n  labs(\n    title = \"Funzione di densità gaussiana\", \n    x = \"x\", \n    y = \"f(x)\"\n  )\n\n\n\n\n\n\n\nCreiamo una funzione per approssimare l’integrale sommando i prodotti \\(\\Delta x \\cdot f(x)\\):\n\nintegral_approximation &lt;- function(f, a, b, n) {\n  delta &lt;- (b - a) / n\n  sum(delta * f)\n}\n\n# Calcolo dell'integrale approssimato\napprox &lt;- integral_approximation(fx, a, b, n)\napprox\n\n[1] 0.9999\n\n\nConfrontiamo il risultato con il calcolo fornito dalla funzione integrate di R:\n\nintegrate(\n  function(x) gaussian(x, mu, sigma),\n  lower = a,\n  upper = b\n)\n\n1 with absolute error &lt; 7.4e-05\n\n\nCalcoliamo l’area sotto la curva in intervalli di interesse. Ad esempio, per \\([-1.96, 1.96]\\), che corrisponde al 95% dell’area nella distribuzione normale standard:\n\na &lt;- -1.96\nb &lt;- 1.96\nx_range &lt;- seq(a, b, length.out = n)\nfx &lt;- gaussian(x_range, mu, sigma)\n\napprox &lt;- integral_approximation(fx, a, b, n)\napprox\n\n[1] 0.9499321\n\n\nConfrontiamo con il risultato fornito da integrate():\n\nintegrate(\n  function(x) gaussian(x, mu, sigma),\n  lower = a,\n  upper = b\n)\n\n0.9500042 with absolute error &lt; 1e-11\n\n\nVerifichiamo l’area sotto la curva per \\([-1, 1]\\), che rappresenta circa il 68% dell’area totale:\n\na &lt;- -1.0\nb &lt;- 1.0\nx_range &lt;- seq(a, b, length.out = n)\nfx &lt;- gaussian(x_range, mu, sigma)\n\napprox &lt;- integral_approximation(fx, a, b, n)\napprox\n\n[1] 0.6826696\n\n\nConfronto:\n\nintegrate(\n  function(x) gaussian(x, mu, sigma),\n  lower = a,\n  upper = b\n)\n\n0.6826895 with absolute error &lt; 7.6e-15\n\n\nIn sintesi, questo approccio dimostra come calcolare l’integrale di una funzione di densità in un intervallo utilizzando sia un metodo approssimativo basato sulla somma dei rettangoli sia il metodo numerico integrato. In entrambi i casi, l’obiettivo è calcolare l’area sotto la curva, che corrisponde all’integrale della funzione di densità.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>I</span>  <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a15_calculus.html#potenze",
    "href": "chapters/appendix/a15_calculus.html#potenze",
    "title": "Appendice I — Per liberarvi dai terrori preliminari",
    "section": "\nI.2 Potenze",
    "text": "I.2 Potenze\nLe potenze sono un’operazione matematica che rappresenta un prodotto ripetuto. Si indicano generalmente come:\n\\[\na^n,\n\\]\ndove:\n\n\n\\(a\\) è la base,\n\n\\(n\\) è l’esponente.\n\nLa potenza rappresenta il prodotto della base \\(a\\) ripetuto \\(n\\) volte.\n\nI.2.1 Definizione di potenza\n\\[\na^n = \\underbrace{a \\cdot a \\cdot \\dots \\cdot a}_{n \\text{ fattori}} \\quad \\text{con } n \\in \\mathbb{N}.\n\\]\nAd esempio:\n\n\n\\(2^3 = 2 \\cdot 2 \\cdot 2 = 8\\),\n\n\\(3^4 = 3 \\cdot 3 \\cdot 3 \\cdot 3 = 81\\).\n\n\nI.2.2 Proprietà delle potenze\n\n\nMoltiplicazione di potenze con la stessa base:\n\\[\na^m \\cdot a^n = a^{m+n}\n\\]\nEsempio: \\(2^3 \\cdot 2^2 = 2^{3+2} = 2^5 = 32\\).\n\n\nDivisione di potenze con la stessa base:\n\\[\n\\frac{a^m}{a^n} = a^{m-n}, \\quad \\text{con } m \\geq n.\n\\]\nEsempio: \\(\\frac{5^4}{5^2} = 5^{4-2} = 5^2 = 25\\).\n\n\nPotenze di potenze:\n\\[\n(a^m)^n = a^{m \\cdot n}.\n\\]\nEsempio: \\((3^2)^3 = 3^{2 \\cdot 3} = 3^6 = 729\\).\n\n\nProdotto di potenze con basi diverse ma lo stesso esponente:\n\\[\na^n \\cdot b^n = (a \\cdot b)^n.\n\\]\nEsempio: \\(2^3 \\cdot 3^3 = (2 \\cdot 3)^3 = 6^3 = 216\\).\n\n\nDivisione di potenze con basi diverse ma lo stesso esponente:\n\\[\n\\frac{a^n}{b^n} = \\left(\\frac{a}{b}\\right)^n.\n\\]\nEsempio: \\(\\frac{4^2}{2^2} = \\left(\\frac{4}{2}\\right)^2 = 2^2 = 4\\).\n\n\nEsponente zero:\n\\[\na^0 = 1, \\quad \\text{con } a \\neq 0.\n\\]\nEsempio: \\(5^0 = 1\\).\n\n\nEsponente negativo:\n\\[\na^{-n} = \\frac{1}{a^n}.\n\\]\nEsempio: \\(2^{-3} = \\frac{1}{2^3} = \\frac{1}{8}\\).\n\n\nRadice come potenza frazionaria:\n\\[\na^{\\frac{1}{n}} = \\sqrt[n]{a}, \\quad a^{\\frac{m}{n}} = \\sqrt[n]{a^m}.\n\\]\nEsempio: \\(8^{\\frac{1}{3}} = \\sqrt[3]{8} = 2\\).\n\n\n\nI.2.3 Esempi pratici\n\n\nCalcolo semplice:\n\\[\n4^3 = 4 \\cdot 4 \\cdot 4 = 64.\n\\]\n\n\nUtilizzo delle proprietà:\n\\[\n3^5 \\cdot 3^2 = 3^{5+2} = 3^7 = 2187.\n\\]\n\n\nDivisione:\n\\[\n\\frac{6^4}{6^2} = 6^{4-2} = 6^2 = 36.\n\\]\n\n\nEsponente negativo:\n\\[\n10^{-2} = \\frac{1}{10^2} = \\frac{1}{100} = 0.01.\n\\]\n\n\nRadice come potenza:\n\\[\n16^{\\frac{1}{2}} = \\sqrt{16} = 4.\n\\]\n\n\n\nI.2.4 Nota sui numeri razionali e reali\n\nLe potenze con esponenti interi sono definite per ogni base.\nLe potenze con esponenti frazionari o reali richiedono che la base sia positiva per evitare ambiguità.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>I</span>  <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a15_calculus.html#logaritmi",
    "href": "chapters/appendix/a15_calculus.html#logaritmi",
    "title": "Appendice I — Per liberarvi dai terrori preliminari",
    "section": "\nI.3 Logaritmi",
    "text": "I.3 Logaritmi\nIl logaritmo è una funzione matematica che risponde alla domanda: “quante volte devo moltiplicare un certo numero (chiamato”base”) per ottenere un altro numero?” Matematicamente, questo è espresso come:\n\\[\n\\log_b(a) = x \\iff b^x = a\n\\]\nAd esempio, \\(\\log_2(8) = 3\\) perché \\(2^3 = 8\\).\nNel contesto dei logaritmi, i valori molto piccoli (compresi tra 0 e 1) diventano più grandi (in termini assoluti) e negativi quando applichiamo una funzione logaritmica. Questo è utile per stabilizzare i calcoli, specialmente quando lavoriamo con prodotti di numeri molto piccoli che potrebbero portare a problemi di underflow.\nPer esempio:\n\n\\(\\log(1) = 0\\)\n\\(\\log(0.1) = -1\\)\n\\(\\log(0.01) = -2\\)\n\\(\\log(0.001) = -3\\)\n\nCome si può vedere, i valori assoluti dei logaritmi crescono man mano che il numero originale si avvicina a zero.\nUna delle proprietà più utili dei logaritmi è che consentono di trasformare un prodotto in una somma:\n\\[\n\\log_b(a \\times c) = \\log_b(a) + \\log_b(c)\n\\]\nQuesta proprietà è estremamente utile in calcoli complessi, come nella statistica bayesiana, dove il prodotto di molte probabilità potrebbe diventare un numero molto piccolo e causare problemi numerici.\nUn’altra proprietà utile dei logaritmi è che un rapporto tra due numeri diventa la differenza dei loro logaritmi:\n\\[\n\\log_b\\left(\\frac{a}{c}\\right) = \\log_b(a) - \\log_b(c)\n\\]\nAnche questa proprietà è molto utilizzata in matematica, specialmente in situazioni in cui è necessario normalizzare i dati.\nIn sintesi, i logaritmi sono strumenti potenti per semplificare e stabilizzare i calcoli matematici. Essi consentono di lavorare più agevolmente con numeri molto grandi o molto piccoli e di trasformare operazioni complesse come prodotti e divisioni in somme e differenze, rendendo i calcoli più gestibili e meno inclini a errori numerici.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>I</span>  <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a47_first_order_markov.html",
    "href": "chapters/appendix/a47_first_order_markov.html",
    "title": "Appendice J — Catene di Markov",
    "section": "",
    "text": "J.1 Classificazione degli Stati\nIl processo di Markov di primo ordine è un concetto fondamentale in molti campi, tra cui l’intelligenza artificiale, la statistica e la teoria delle probabilità. Questo modello probabilistico rappresenta un equilibrio tra la semplicità delle variabili casuali indipendenti e la complessità delle interazioni tra variabili. Per chiarire il concetto, consideriamo una sequenza temporale di eventi rappresentata da variabili casuali \\(X_0, X_1, ..., X_n, ...\\). In molti fenomeni reali, queste variabili non sono né completamente indipendenti né totalmente interdipendenti. Una catena di Markov rappresenta un compromesso tra questi due estremi.\nIn questo contesto, ci concentreremo su catene di Markov con stati discreti e tempo discreto. Ciò significa che le variabili \\(X_n\\) possono assumere valori in un insieme finito, tipicamente indicato come \\(\\{1, 2, ..., M\\}\\), e che gli eventi si verificano in momenti distinti e numerabili. La proprietà fondamentale di una catena di Markov può essere espressa matematicamente con la seguente equazione:\n\\[\nP(X_{n+1} = j | X_n = i, X_{n-1} = i_{n-1}, ..., X_0 = i_0) = P(X_{n+1} = j | X_n = i).\n\\]\nQuesta equazione indica che il futuro (rappresentato da \\(X_{n+1}\\)) dipende solo dal presente (\\(X_n\\)) e non dal passato (\\(X_{n-1}, ..., X_0\\)). La proprietà di Markov può essere vista come un primo allentamento dell’assunzione di indipendenza: le variabili casuali sono dipendenti in un modo specifico che risulta matematicamente conveniente.\nQuantità importanti associate a una catena di Markov sono le probabilità condizionate, chiamate probabilità di transizione:\n\\[\nP(X_{n+1} = j \\mid X_n = i).\n\\]\nLa probabilità \\(P(X_{n+1} = j \\mid X_n = i)\\), nota come probabilità di transizione, rappresenta la probabilità di passare dallo stato \\(i\\) allo stato \\(j\\) in un singolo passo.\nPer descrivere completamente una catena di Markov, si utilizza una matrice \\(Q\\), chiamata matrice di transizione. Questa è una matrice \\(M \\times M\\) in cui ogni elemento \\(q_{ij}\\) rappresenta la probabilità di transizione dallo stato \\(i\\) allo stato \\(j\\). Un’importante caratteristica della matrice di transizione è che la somma degli elementi di ogni riga deve essere pari a 1, poiché partendo da uno stato qualsiasi, il sistema deve necessariamente transitare in uno degli stati possibili.\nPer chiarire ulteriormente il concetto, consideriamo un modello di previsione del tempo a Firenze con tre possibili condizioni meteorologiche: soleggiato, piovoso e nebbioso. Di seguito è riportata una matrice di transizione che rappresenta le probabilità di passaggio da un tipo di tempo all’altro:\nVediamo come calcolare alcune probabilità:\nIl modello di Markov di base assume che le probabilità di transizione rimangano costanti nel tempo, una proprietà nota come omogeneità temporale. Questo significa che, per esempio, la probabilità di passare dallo stato “soleggiato” allo stato “piovoso” è la stessa in qualsiasi periodo dell’anno.\nIn sintesi, l’utilità del modello di Markov risiede nella sua capacità di semplificare notevolmente i calcoli probabilistici. Invece di considerare l’intera storia passata del sistema, è sufficiente conoscere solo lo stato attuale per fare previsioni sul futuro. Questa caratteristica, nota come “assenza di memoria”, rende il modello estremamente utile in molte applicazioni pratiche, dalla modellazione di fenomeni naturali alla progettazione di algoritmi di apprendimento automatico. Il processo di Markov di primo ordine offre uno strumento potente per analizzare e prevedere il comportamento di sistemi complessi nel tempo, bilanciando la necessità di catturare le dipendenze temporali con la semplicità computazionale. La sua versatilità e applicabilità in diversi campi lo rendono un concetto chiave per comprendere e modellare molti fenomeni del mondo reale.\nConsideriamo ora la terminologia usata per descrivere le varie caratteristiche di una catena di Markov.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>J</span>  <span class='chapter-title'>Catene di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a47_first_order_markov.html#classificazione-degli-stati",
    "href": "chapters/appendix/a47_first_order_markov.html#classificazione-degli-stati",
    "title": "Appendice J — Catene di Markov",
    "section": "",
    "text": "J.1.1 Catene di Markov Irriducibili\nUna catena di Markov è detta irriducibile se, per qualsiasi coppia di stati \\(i\\) e \\(j\\), esiste una probabilità positiva di passare dallo stato \\(i\\) allo stato \\(j\\) in un numero finito di passi. In altre parole, una catena irriducibile non ha stati isolati: ogni stato è raggiungibile da qualsiasi altro stato.\n\n\nJ.1.2 Stati Ricorrenti\nUno stato \\(i\\) di una catena di Markov si dice ricorrente se, partendo da \\(i\\), la probabilità di ritornarvi è uguale a 1. Questo implica che una volta raggiunto lo stato \\(i\\), è garantito che la catena tornerà in \\(i\\) prima o poi. Gli stati ricorrenti possono essere ulteriormente classificati come:\n\nPositivamente ricorrenti: uno stato è positivamente ricorrente se il tempo medio atteso per ritornare in quello stato, partendo da esso, è finito.\nNullamente ricorrenti: uno stato è nullamente ricorrente se il tempo medio atteso per ritornare in quello stato è infinito.\nRicorrenti di Harris: sono stati ricorrenti che vengono visitati infinite volte quando il tempo tende all’infinito, garantendo una certa frequenza di visita.\n\n\n\nJ.1.3 Aperiodicità\nUno stato \\(i\\) si dice aperiodico se il massimo comun divisore dei tempi di ritorno in \\(i\\) è 1. In altre parole, uno stato è aperiodico se non esiste un ciclo deterministico che vincola i tempi in cui la catena può ritornare in quello stato. Una catena di Markov è aperiodica se tutti i suoi stati sono aperiodici. L’aperiodicità evita che la catena rimanga bloccata in una sequenza ciclica fissa, permettendo un comportamento più variegato nel tempo.\n\n\nJ.1.4 Stazionarietà\nNella teoria delle catene di Markov, una distribuzione stazionaria \\(\\pi\\) è una distribuzione di probabilità sugli stati tale che, se la catena parte con questa distribuzione iniziale, la distribuzione delle probabilità rimane invariata nel tempo. Matematicamente, se \\(\\pi\\) è la distribuzione stazionaria, allora \\(\\pi P = \\pi\\), dove \\(P\\) è la matrice di transizione della catena di Markov. La stazionarietà è fondamentale per analizzare il comportamento a lungo termine della catena, poiché una volta raggiunta, la distribuzione di probabilità sugli stati rimane costante.\n\n\nJ.1.5 Ergodicità\nUna catena di Markov si dice ergodica se è irriducibile e aperiodica, e tutti i suoi stati sono positivamente ricorrenti. Questo implica che la catena, nel lungo termine, visita tutti gli stati secondo una distribuzione di probabilità che diventa stabile (stazionaria) e non dipende dallo stato iniziale. La proprietà di ergodicità è cruciale in quanto garantisce che le medie temporali di una funzione sugli stati della catena convergono alle medie rispetto alla distribuzione stazionaria.\n\n\nJ.1.6 Convergenza\nLa convergenza di una catena di Markov si riferisce al processo mediante il quale la distribuzione di probabilità degli stati si avvicina alla distribuzione stazionaria \\(\\pi\\) man mano che il numero di passi \\(n\\) tende all’infinito. In altre parole, indipendentemente dalla distribuzione iniziale degli stati, la distribuzione della catena dopo un lungo periodo di tempo sarà vicina a \\(\\pi\\). Questo concetto è strettamente legato alla stazionarietà, poiché la convergenza descrive il percorso verso l’equilibrio, mentre la stazionarietà rappresenta lo stato di equilibrio raggiunto.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>J</span>  <span class='chapter-title'>Catene di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a47_first_order_markov.html#sommario",
    "href": "chapters/appendix/a47_first_order_markov.html#sommario",
    "title": "Appendice J — Catene di Markov",
    "section": "J.2 Sommario",
    "text": "J.2 Sommario\nUna catena di Markov è una sequenza di variabili aleatorie \\(X_0, X_1, X_2, \\ldots\\) che soddisfa la cosiddetta proprietà di Markov. Questa proprietà stabilisce che, dato lo stato attuale della catena, il futuro è indipendente dal passato. Formalmente, questa proprietà si esprime come:\n\\[\nP(X_{n+1} = j \\mid X_n = i, X_{n-1} = i_{n-1}, \\ldots, X_0 = i_0) = P(X_{n+1} = j \\mid X_n = i) = q_{ij},\n\\]\ndove \\(q_{ij}\\) rappresenta la probabilità di passare dallo stato \\(i\\) allo stato \\(j\\) in un singolo passo. Queste probabilità di transizione sono organizzate in una matrice di transizione \\(Q = (q_{ij})\\), in cui ogni riga corrisponde a una distribuzione di probabilità condizionata sui possibili stati futuri dato l’attuale stato della catena.\nLa distribuzione di probabilità degli stati della catena dopo \\(n\\) passi può essere calcolata moltiplicando la matrice di transizione \\(Q\\) elevata alla potenza \\(n\\) per il vettore di probabilità iniziale \\(s\\), che descrive la distribuzione di probabilità degli stati al tempo \\(0\\). In simboli, questo è rappresentato da \\(sQ^n\\), che fornisce la distribuzione di probabilità marginale degli stati dopo \\(n\\) passi.\nGli stati di una catena di Markov possono essere classificati come ricorrenti o transitori. Uno stato è ricorrente se la catena torna a questo stato ripetutamente nel tempo; è transitorio se la catena potrebbe lasciare questo stato per non ritornarvi mai più. Gli stati possono anche avere un periodo associato, definito come il massimo comun divisore dei numeri di passi necessari per ritornare allo stato stesso. Una catena di Markov è detta irriducibile se è possibile raggiungere qualsiasi stato da qualsiasi altro stato in un numero finito di passi, ed è aperiodica se ogni stato ha periodo 1.\nUna distribuzione stazionaria di una catena di Markov è una distribuzione di probabilità che rimane invariata nel tempo. Se la catena inizia con questa distribuzione, continuerà a mantenerla in ogni passo successivo. Questa condizione si esprime matematicamente come \\(sQ = s\\), dove \\(s\\) è il vettore di probabilità stazionaria e \\(Q\\) è la matrice di transizione. Per una catena di Markov finita che è irriducibile e aperiodica, esiste una distribuzione stazionaria unica verso la quale la catena converge indipendentemente dalla distribuzione iniziale.\nUn concetto importante nelle catene di Markov è quello di reversibilità. Una catena di Markov è detta reversibile se esiste una distribuzione di probabilità \\(s\\) tale che, per ogni coppia di stati \\(i\\) e \\(j\\), la condizione di reversibilità \\(s_i q_{ij} = s_j q_{ji}\\) sia soddisfatta. Questa condizione garantisce che \\(s\\) sia una distribuzione stazionaria per la catena. Le catene di Markov reversibili sono particolarmente utili in applicazioni pratiche come gli algoritmi di simulazione Monte Carlo, ad esempio l’algoritmo di Metropolis-Hastings, poiché permettono di progettare catene che convergono rapidamente alla distribuzione di probabilità desiderata.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>J</span>  <span class='chapter-title'>Catene di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a47_first_order_markov.html#letteratura",
    "href": "chapters/appendix/a47_first_order_markov.html#letteratura",
    "title": "Appendice J — Catene di Markov",
    "section": "J.3 Letteratura",
    "text": "J.3 Letteratura\nI metodi markoviani sono stati ampiamente utilizzati in vari ambiti della psicologia e dell’educazione. Una delle applicazioni più comuni di questi metodi è il clustering dei dati sequenziali (Törmänen et al. (2022); Törmänen et al. (2023); Fincham et al. (2018)). Ad esempio, i modelli nascosti di Markov (HMM) sono stati utilizzati per raggruppare le sequenze di dati tracciati da sistemi di gestione dell’apprendimento (LMS) degli studenti, al fine di identificare i loro schemi di attività, ovvero le tattiche e strategie di apprendimento (Fincham et al. (2018)). Un uso molto diffuso dei modelli di Markov di primo ordine è quello di mappare le transizioni degli studenti tra diverse attività di apprendimento. Per esempio, Matcha et al. (2020) ha utilizzato modelli di Markov di primo ordine per studiare i processi di transizione degli studenti tra diverse strategie di apprendimento. Altri usi includono lo studio delle transizioni tra diverse strategie di scrittura accademica (Peeters et al. (2020)), tra eventi di apprendimento autoregolato (Lim et al. (2023)), o all’interno di contesti di apprendimento collaborativo (Saqr & López-Pernas (2023)). Esempi più specifici nell’ambito psicologico comprendono lo studio delle influenze reciproche tra stati affettivi (Cipresso et al. (2023)) e l’analisi degli effetti psicologici che dipendono dal tempo nelle sequenze di decision-making (Gunawan et al. (2022)).\n\n\n\n\nCipresso, P., Borghesi, F., & Chirico, A. (2023). Affects affect affects: A Markov chain. Frontiers in Psychology, 14, 1162655.\n\n\nFincham, E., Gašević, D., Jovanović, J., & Pardo, A. (2018). From study tactics to learning strategies: An analytical method for extracting interpretable representations. IEEE Transactions on Learning Technologies, 12(1), 59–72.\n\n\nGunawan, D., Hawkins, G. E., Kohn, R., Tran, M.-N., & Brown, S. D. (2022). Time-evolving psychological processes over repeated decisions. Psychological Review, 129(3), 438–456.\n\n\nLim, L., Bannert, M., Graaf, J. van der, Singh, S., Fan, Y., Surendrannair, S., Rakovic, M., Molenaar, I., Moore, J., & Gašević, D. (2023). Effects of real-time analytics-based personalized scaffolds on students’ self-regulated learning. Computers in Human Behavior, 139, 107547.\n\n\nMatcha, W., Gasevic, D., Jovanovic, J., Pardo, A., Lim, L., Maldonado-Mahauad, J., Gentili, S., Pérez-Sanagustı́n, M., Tsai, Y.-S., et al. (2020). Analytics of Learning Strategies: Role of Course Design and Delivery Modality Authors. Journal of Learning Analytics, 7(2), 45–71.\n\n\nPeeters, W., Saqr, M., & Viberg, O. (2020). Applying learning analytics to map students’ self-regulated learning tactics in an academic writing course. Proceedings of the 28th International Conference on Computers in Education, 1, 245–254.\n\n\nSaqr, M., & López-Pernas, S. (2023). The temporal dynamics of online problem-based learning: Why and when sequence matters. International Journal of Computer-Supported Collaborative Learning, 18(1), 11–37.\n\n\nTörmänen, T., Järvenoja, H., Saqr, M., Malmberg, J., & Järvelä, S. (2022). A person-centered approach to study students’ socio-emotional interaction profiles and regulation of collaborative learning. Frontiers in Education, 7, 866612.\n\n\nTörmänen, T., Järvenoja, H., Saqr, M., Malmberg, J., & Järvelä, S. (2023). Affective states and regulation of learning during socio-emotional interactions in secondary school collaborative groups. British Journal of Educational Psychology, 93, 48–70.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>J</span>  <span class='chapter-title'>Catene di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a50_lin_fun.html",
    "href": "chapters/appendix/a50_lin_fun.html",
    "title": "Appendice K — La funzione lineare",
    "section": "",
    "text": "K.1 Concetto di Funzione\nNello studio dei fenomeni naturali e nella risoluzione di problemi tecnici e matematici, è spesso necessario considerare la variazione di una grandezza come dipendente dalla variazione di un’altra. Ad esempio, nello studio del moto, il percorso compiuto da un oggetto può essere visto come una grandezza variabile in funzione del tempo: il cammino percorso è, dunque, una funzione del tempo.\nQuesta considerazione ci conduce alla seguente definizione:\nSe a ogni valore della variabile \\(x\\) (all’interno di un certo intervallo) corrisponde un valore ben definito di un’altra variabile \\(y\\), allora si dice che \\(y\\) è una funzione di \\(x\\). In notazione funzionale si scrive:\n\\[\ny = f(x) \\quad \\text{o anche} \\quad y = \\varphi(x).\n\\]\nLa variabile \\(x\\) è detta variabile indipendente o argomento della funzione. La relazione che lega \\(x\\) a \\(y\\) si chiama relazione funzionale. La lettera \\(f\\) nella notazione \\(y = f(x)\\) indica che per ottenere il valore di \\(y\\) a partire da \\(x\\) è necessario applicare una certa “regola” o “operazione”. In modo analogo, si possono utilizzare anche altre notazioni come \\(u = \\varphi(x)\\).\nLa notazione \\(y = C\\), dove \\(C\\) è una costante, indica una funzione il cui valore rimane invariato per qualunque valore di \\(x\\).\nL’insieme dei valori di \\(x\\) per cui la funzione \\(y = f(x)\\) è definita si chiama dominio di definizione della funzione.\nSe per valori crescenti della variabile indipendente \\(x\\) anche il valore della funzione \\(y = f(x)\\) aumenta, allora la funzione si dice crescente. Analogamente, se a valori crescenti di \\(x\\) corrispondono valori decrescenti della funzione \\(y = f(x)\\), la funzione si dice decrescente.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>K</span>  <span class='chapter-title'>La funzione lineare</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a50_lin_fun.html#la-retta",
    "href": "chapters/appendix/a50_lin_fun.html#la-retta",
    "title": "Appendice K — La funzione lineare",
    "section": "K.2 La Retta",
    "text": "K.2 La Retta\nLa funzione lineare è definita come:\n\\[\nf(x) = a + b x,\n\\]\ndove \\(a\\) e \\(b\\) sono costanti. Il grafico di tale funzione è una retta. Qui, \\(b\\) è detto coefficiente angolare, mentre \\(a\\) è l’intercetta con l’asse delle \\(y\\). In altri termini, la retta interseca l’asse \\(y\\) nel punto \\((0, a)\\).\nPer comprendere il ruolo di \\(a\\) e \\(b\\), consideriamo prima il caso particolare:\n\\[\ny = b x.\n\\]\nQuesta espressione rappresenta una proporzionalità diretta tra \\(x\\) e \\(y\\): al crescere di \\(x\\), \\(y\\) varia in proporzione. Nel caso generale:\n\\[\ny = a + b x,\n\\]\nil termine \\(a\\) “trasla” verticalmente il grafico, aggiungendo una costante a ogni valore \\(b x\\).\nIl segno del coefficiente \\(b\\) determina il comportamento della funzione lineare:\n\nSe \\(b &gt; 0\\), il valore di \\(y\\) aumenta all’aumentare di \\(x\\).\n\nSe \\(b &lt; 0\\), il valore di \\(y\\) diminuisce all’aumentare di \\(x\\).\n\nSe \\(b = 0\\), il grafico è una retta orizzontale e \\(y\\) rimane costante.\n\nPossiamo dare un’interpretazione geometrica ancora più intuitiva se consideriamo variazioni (incrementi) di \\(x\\). Preso un punto \\(x_0\\) e aggiungendo un piccolo incremento \\(\\varepsilon\\), definiamo:\n\\[\n\\Delta x = (x_0 + \\varepsilon) - x_0 = \\varepsilon,\n\\] \\[\n\\Delta y = f(x_0 + \\varepsilon) - f(x_0).\n\\]\nIl coefficiente angolare \\(b\\) può essere interpretato come il rapporto tra la variazione di \\(y\\) e la variazione di \\(x\\):\n\\[\nb = \\frac{\\Delta y}{\\Delta x} = \\frac{f(x_0 + \\varepsilon) - f(x_0)}{(x_0 + \\varepsilon) - x_0}.\n\\]\nQuesto rapporto è costante e non dipende dalla scelta di \\(x_0\\) o di \\(\\varepsilon\\). In particolare, se scegliamo \\(\\Delta x = 1\\), il coefficiente angolare \\(b\\) rappresenta semplicemente di quanto varia \\(y\\) quando \\(x\\) aumenta di un’unità.\n\n\n\n\n\n\n\nFigura K.1: La funzione lineare \\(y = a + bx\\).\n\n\n\nCome mostrato in figura, il coefficiente \\(b\\) indica la pendenza della retta, ossia quanto “ripida” è la sua inclinazione rispetto all’asse orizzontale.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>K</span>  <span class='chapter-title'>La funzione lineare</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a71_install_cmdstan.html",
    "href": "chapters/appendix/a71_install_cmdstan.html",
    "title": "Appendice L — Come installare CmdStan",
    "section": "",
    "text": "L.1 Windows\nSu macOS e Linux, questa configurazione dovrebbe essere già pronta di default.\nSu Windows è necessario installare RTools e configurare PATH:\nProblemi comuni:",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>L</span>  <span class='chapter-title'>Come installare CmdStan</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a71_install_cmdstan.html#windows",
    "href": "chapters/appendix/a71_install_cmdstan.html#windows",
    "title": "Appendice L — Come installare CmdStan",
    "section": "",
    "text": "Installazione di RTools:\n\nVai su https://cran.r-project.org/bin/windows/Rtools/\nScarica la versione di RTools compatibile con la tua versione di R (Generalmente, RTools 4.3 per R 4.3.x, RTools 4.2 per R 4.2.x, etc.)\nEsegui l’installer scaricato\nIMPORTANTE: Durante l’installazione, seleziona la casella “Add rtools to system PATH”\n\nVerifica dell’installazione e configurazione del PATH:\n\nApri PowerShell o Command Prompt\nVerifica se RTools è nel PATH digitando:\n\ngcc --version\nSe vedi la versione di gcc, RTools è nel PATH.\nSe RTools non è nel PATH, devi aggiungerlo manualmente:\n\nCerca “Impostazioni di Sistema” in Windows\nClicca su “Impostazioni di sistema avanzate”\nClicca su “Variabili d’ambiente”\nNella sezione “Variabili di sistema”, trova “Path”\nClicca “Modifica”\nClicca “Nuovo” e aggiungi questi percorsi (sostituisci X.X con la tua versione di RTools):\nC:\\rtools4X\\mingw64\\bin\nC:\\rtools4X\\usr\\bin\n\nVerifica finale:\n\nChiudi e riapri il terminale\nProva questi comandi:\n\ngcc --version\nmake --version\nSe entrambi i comandi mostrano le versioni, l’installazione è completa.\nTest in R:\n\nApri R o RStudio\nEsegui:\n\nSys.which(\"make\")\nDovrebbe mostrare il percorso di make.\n\n\n\nSe i comandi non vengono riconosciuti dopo aver aggiunto il PATH, prova a riavviare il computer.\nSe usi RStudio, potrebbe essere necessario riavviarlo dopo aver modificato il PATH.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>L</span>  <span class='chapter-title'>Come installare CmdStan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#codifica-del-modello-con-variabili-dummy",
    "href": "chapters/linear_models/09_anova_1via.html#codifica-del-modello-con-variabili-dummy",
    "title": "68  ANOVA ad una via",
    "section": "\n68.3 Codifica del modello con variabili dummy",
    "text": "68.3 Codifica del modello con variabili dummy\nSupponiamo un esperimento con tre gruppi. Per rappresentare questo fattore all’interno di un modello lineare, usiamo due variabili dummy e consideriamo il terzo gruppo come riferimento implicito. Il modello assume la forma:\n\\[\nY_i = \\alpha + \\gamma_1 D_{i1} + \\gamma_2 D_{i2} + \\varepsilon_i\n\\tag{68.1}\\]\ndove:\n\n\n\\(\\alpha\\) è l’intercetta del modello,\n\n\\(\\gamma_1\\) e \\(\\gamma_2\\) sono i coefficienti associati alle variabili dummy,\n\n\\(D_{i1}\\) e \\(D_{i2}\\) indicano l’appartenenza dell’osservazione \\(i\\) ai gruppi 1 e 2, rispettivamente,\n\n\\(\\varepsilon_i\\) è l’errore aleatorio.\n\nLa codifica delle dummy è la seguente:\n\\[\n\\begin{array}{c|cc}\n\\text{Gruppo} & D_{1} & D_{2} \\\\\n\\hline\n1 & 1 & 0 \\\\\n2 & 0 & 1 \\\\\n3 & 0 & 0\n\\end{array}\n\\tag{68.2}\\]\n\n68.3.1 Interpretazione dei parametri\nCon questa codifica, possiamo esprimere le medie di ciascun gruppo come:\n\\[\n\\begin{aligned}\n\\mu_1 &= \\alpha + \\gamma_1 \\\\\n\\mu_2 &= \\alpha + \\gamma_2 \\\\\n\\mu_3 &= \\alpha\n\\end{aligned}\n\\]\nDa cui otteniamo:\n\\[\n\\alpha = \\mu_3, \\quad \\gamma_1 = \\mu_1 - \\mu_3, \\quad \\gamma_2 = \\mu_2 - \\mu_3.\n\\]\nQuindi:\n\n\n\\(\\alpha\\): media del gruppo 3 (riferimento),\n\n\\(\\gamma_1\\): quanto il gruppo 1 si discosta da \\(\\mu_3\\),\n\n\\(\\gamma_2\\): quanto il gruppo 2 si discosta da \\(\\mu_3\\).\n\nIn un’ottica bayesiana, questi coefficienti possono essere pensati come distribuzioni: esprimono quanto crediamo che ciascuna differenza sia plausibile, date le osservazioni. Passiamo ora a una simulazione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#modello-lineare-con-variabili-dummy",
    "href": "chapters/linear_models/09_anova_1via.html#modello-lineare-con-variabili-dummy",
    "title": "68  ANOVA ad una via",
    "section": "\n68.5 Modello lineare con variabili dummy",
    "text": "68.5 Modello lineare con variabili dummy\nConvertiamo condizione in fattore e definiamo controllo come categoria di riferimento:\n\ndf$condizione &lt;- factor(df$condizione)\ndf$condizione &lt;- relevel(df$condizione, ref = \"controllo\")\ncontrasts(df$condizione)\n#&gt;               psicoterapia1 psicoterapia2\n#&gt; controllo                 0             0\n#&gt; psicoterapia1             1             0\n#&gt; psicoterapia2             0             1\n\nIl modello di regressione con le variabili dummy sarà:\n\\[\nY_i = \\beta_0 + \\beta_1 \\cdot \\text{psicoterapia1}_i + \\beta_2 \\cdot \\text{psicoterapia2}_i + \\varepsilon_i,\n\\]\ndove:\n\n\n\\(\\beta_0\\) è la media del gruppo di controllo;\n\n\\(\\beta_1\\) e \\(\\beta_2\\) sono le differenze tra le rispettive psicoterapie e il gruppo di controllo.\n\n\n68.5.1 Stima del modello\nEseguiamo una prima analisi usando il metodo di massima verosimiglianza:\n\nfm1 &lt;- lm(punteggio ~ condizione, data = df)\n\n\nsummary(fm1)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = punteggio ~ condizione, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -11.668  -2.620  -0.183   2.681  10.128 \n#&gt; \n#&gt; Coefficients:\n#&gt;                         Estimate Std. Error t value Pr(&gt;|t|)\n#&gt; (Intercept)               29.764      0.819   36.33  &lt; 2e-16\n#&gt; condizionepsicoterapia1   -3.873      1.159   -3.34   0.0012\n#&gt; condizionepsicoterapia2   -9.642      1.159   -8.32  1.1e-12\n#&gt; \n#&gt; Residual standard error: 4.49 on 87 degrees of freedom\n#&gt; Multiple R-squared:  0.446,  Adjusted R-squared:  0.434 \n#&gt; F-statistic: 35.1 on 2 and 87 DF,  p-value: 6.75e-12\n\nVerifica delle medie e differenze tra i gruppi:\n\nout &lt;- tapply(df$punteggio, df$condizione, mean)\nout[2] - out[1]  # psicoterapia1 - controllo\n#&gt; psicoterapia1 \n#&gt;        -3.873\nout[3] - out[1]  # psicoterapia2 - controllo\n#&gt; psicoterapia2 \n#&gt;        -9.642",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_anova_1via.html#estensione-bayesiana-con-brms-e-emmeans",
    "href": "chapters/linear_models/09_anova_1via.html#estensione-bayesiana-con-brms-e-emmeans",
    "title": "68  ANOVA ad una via",
    "section": "\n68.7 Estensione bayesiana con brms e emmeans\n",
    "text": "68.7 Estensione bayesiana con brms e emmeans\n\nUsiamo ora il modello bayesiano:\n\nmod &lt;- brm(punteggio ~ condizione, data = df, backend = \"cmdstanr\")\n\n\nsummary(mod)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: punteggio ~ condizione \n#&gt;    Data: df (Number of observations: 90) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;                             Estimate Est.Error l-95% CI u-95% CI Rhat\n#&gt; Intercept                      25.26      0.48    24.33    26.15 1.00\n#&gt; condizioneCtrl_vs_PsicoMean     6.78      1.04     4.73     8.85 1.00\n#&gt; condizioneP1_vs_P2              5.76      1.16     3.49     8.08 1.00\n#&gt;                             Bulk_ESS Tail_ESS\n#&gt; Intercept                       4321     2937\n#&gt; condizioneCtrl_vs_PsicoMean     4260     2964\n#&gt; condizioneP1_vs_P2              4598     2785\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     4.54      0.34     3.93     5.26 1.00     4287     3279\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nLe medie marginali e i confronti possono essere ottenuti con il pacchetto emmeans:\n\nem &lt;- emmeans(mod, specs = \"condizione\")\nem\n#&gt;  condizione    emmean lower.HPD upper.HPD\n#&gt;  controllo       29.8      28.1      31.4\n#&gt;  psicoterapia1   25.9      24.3      27.5\n#&gt;  psicoterapia2   20.1      18.4      21.7\n#&gt; \n#&gt; Point estimate displayed: median \n#&gt; HPD interval probability: 0.95\n\nConfronti tra gruppi:\n\npairs(em)  # confronti a coppie\n#&gt;  contrast                      estimate lower.HPD upper.HPD\n#&gt;  controllo - psicoterapia1         3.90      1.70      6.21\n#&gt;  controllo - psicoterapia2         9.65      7.31     12.03\n#&gt;  psicoterapia1 - psicoterapia2     5.75      3.57      8.14\n#&gt; \n#&gt; Point estimate displayed: median \n#&gt; HPD interval probability: 0.95\n\nContrasti personalizzati:\n\nmy_list &lt;- list(\n  \"Ctrl_vs_PsicoMean\" = c(\n    \"controllo\" = 1, \"psicoterapia1\" = -0.5, \"psicoterapia2\" = -0.5\n  ),\n  \"P1_vs_P2\" = c(\n    \"controllo\" = 0, \"psicoterapia1\" = 1, \"psicoterapia2\" = -1\n  )\n)\n\n\ncontrast(em, method = my_list)\n#&gt;  contrast          estimate lower.HPD upper.HPD\n#&gt;  Ctrl_vs_PsicoMean     6.77      4.77      8.88\n#&gt;  P1_vs_P2              5.75      3.57      8.14\n#&gt; \n#&gt; Point estimate displayed: median \n#&gt; HPD interval probability: 0.95\n\n\n# Visualizzazione\nplot(em)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>ANOVA ad una via</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Psicometria",
    "section": "",
    "text": "Informazioni Generali",
    "crumbs": [
      "Informazioni Generali"
    ]
  },
  {
    "objectID": "index.html#informazioni-generali",
    "href": "index.html#informazioni-generali",
    "title": "Psicometria",
    "section": "",
    "text": "Anno Accademico: 2024-2025\nCodice Insegnamento: B000286 (coorte L-Z)\nOrario:\n\nLunedì e Martedì (8:30-10:30)\n\nGiovedì (11:30-13:30)\n\nPlesso Didattico La Torretta",
    "crumbs": [
      "Informazioni Generali"
    ]
  },
  {
    "objectID": "index.html#panoramica-del-corso",
    "href": "index.html#panoramica-del-corso",
    "title": "Psicometria",
    "section": "Panoramica del Corso",
    "text": "Panoramica del Corso\nIl corso offre una formazione teorico-pratica nell’analisi dei dati psicologici, con particolare attenzione alle applicazioni in R. Vengono affrontati temi come analisi descrittiva, esplorazione dei dati, flusso di lavoro, organizzazione di progetti e modelli statistici di base, sia bayesiani che frequentisti. Grande enfasi è posta sulle buone pratiche di Open Science, promuovendo trasparenza e riproducibilità nelle analisi.\nIl corso integra questi argomenti in un percorso didattico che combina lezioni teoriche, esercitazioni pratiche e momenti di riflessione critica. Gli studenti saranno così preparati ad applicare l’analisi dei dati sia in contesti accademici che pratici.\n\nSyllabus dettagliato\nCalendario delle lezioni",
    "crumbs": [
      "Informazioni Generali"
    ]
  },
  {
    "objectID": "index.html#licenza-duso",
    "href": "index.html#licenza-duso",
    "title": "Psicometria",
    "section": "Licenza d’Uso",
    "text": "Licenza d’Uso\nI materiali sono rilasciati con licenza CC BY 4.0. È consentito qualsiasi utilizzo previa attribuzione. Per usi commerciali o derivati, consultare le linee guida complete.",
    "crumbs": [
      "Informazioni Generali"
    ]
  },
  {
    "objectID": "chapters/key_notions/introduction_key_notions.html",
    "href": "chapters/key_notions/introduction_key_notions.html",
    "title": "Fondamenti",
    "section": "",
    "text": "La data science è un campo che si sviluppa all’intersezione tra la statistica e l’informatica. La statistica fornisce una serie di metodologie per analizzare i dati e ottenere informazioni significative, mentre l’informatica si occupa dello sviluppo di software e strumenti per implementare tali metodologie. In questa sezione della dispensa, approfondiremo alcuni concetti fondamentali della statistica e della misurazione psicologica. Considereremo anche in termini generali quali sono gli obiettivi e i limiti dell’analisi dei dati psicologici.",
    "crumbs": [
      "Fondamenti"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html",
    "href": "chapters/key_notions/01_key_notions.html",
    "title": "1  Concetti chiave",
    "section": "",
    "text": "1.1 Introduzione\nNella ricerca scientifica, la formulazione di risposte a specifiche domande di indagine avviene attraverso l’applicazione di metodologie rigorose e l’esecuzione di osservazioni accurate e controllate. Le informazioni raccolte mediante diverse tecniche di indagine—come ricerche sul campo, indagini campionarie e protocolli sperimentali—vengono definite con il termine tecnico di dati. Questo capitolo introduce i principi fondamentali dell’analisi dei dati, concentrandosi sia sulle caratteristiche dei dati stessi sia sui metodi di raccolta.\nL’analisi dei dati permette di sintetizzare grandi quantità di informazioni e di verificare le previsioni avanzate dalle teorie. Tuttavia, senza una teoria che dia significato ai dati, le osservazioni rimangono mere descrizioni prive di un contesto esplicativo. È attraverso l’integrazione tra dati e teoria che si raggiunge una comprensione profonda dei fenomeni e si favorisce l’avanzamento scientifico [es., Wertheimer (1880–1943), scoperta del movimento-\\(\\phi\\) e nascita del movimento della Gestalt; Steinman et al. (2000)].",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#introduzione",
    "href": "chapters/key_notions/01_key_notions.html#introduzione",
    "title": "1  Concetti chiave",
    "section": "",
    "text": "Statistica\n\n\n\nIl termine “statistica” può assumere diversi significati a seconda del contesto:\n\nPrimo significato: La statistica è una scienza che si occupa dello studio e dell’applicazione di metodi per la raccolta, organizzazione, analisi, interpretazione e presentazione dei dati.\nSecondo significato: Il termine si riferisce a una misura o valore numerico calcolato a partire da un campione di dati, come la media campionaria, la deviazione standard campionaria o il coefficiente di correlazione campionario.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#la-spiegazione-scientifica",
    "href": "chapters/key_notions/01_key_notions.html#la-spiegazione-scientifica",
    "title": "1  Concetti chiave",
    "section": "1.2 La Spiegazione Scientifica",
    "text": "1.2 La Spiegazione Scientifica\nLa scienza non si limita a descrivere o prevedere i fenomeni: il suo obiettivo principale è spiegare il perché degli eventi, offrendo una comprensione approfondita delle cause e dei meccanismi che li regolano. La spiegazione scientifica è cruciale per costruire teorie capaci non solo di descrivere e prevedere, ma anche di chiarire le dinamiche causali e le connessioni tra i fenomeni, contribuendo a un controllo più consapevole e informato su di essi.\nConsideriamo, ad esempio, il rapporto tra il background familiare e il rendimento scolastico. Numerose ricerche evidenziano una forte correlazione tra il livello di istruzione dei genitori e il successo accademico dei figli. Una prospettiva puramente descrittiva potrebbe limitarsi a constatare che: “Gli studenti provenienti da famiglie con basso livello di istruzione hanno minori probabilità di conseguire un titolo universitario”. Tuttavia, la vera sfida scientifica consiste nell’andare oltre questa previsione, ponendosi domande più profonde:\n\nquali meccanismi causali determinano questa disparità?\n\nquali interventi possono efficacemente ridurre tali disuguaglianze?\n\nPer superare il livello di semplice previsione, la ricerca deve identificare i fattori causali alla base del fenomeno, in modo da comprendere come l’azione su questi fattori possa modificare gli esiti. Nel caso dell’esempio sul rapporto tra background familiare e rendimento scolastico, ciò implica comprendere, ad esempio:\n\nse e in che modo il sostegno finanziario possa favorire il percorso degli studenti svantaggiati;\nquali politiche educative possano produrre effetti positivi sul lungo termine;\ncome i meccanismi sociali e individuali influenzino il processo educativo.\n\nAcquisire una conoscenza approfondita dei meccanismi causali permette di andare oltre la semplice previsione, rendendo possibile la progettazione di interventi mirati e strategici che possano realmente incidere sui fenomeni in modo efficace e duraturo.\n\n1.2.1 Elementi Fondamentali della Spiegazione Scientifica\nLa filosofia della scienza identifica tre componenti fondamentali di una spiegazione scientifica:\n\nExplanandum\nÈ il fenomeno che desideriamo comprendere, ovvero ciò di cui cerchiamo le cause o i meccanismi. Un esempio: “Gli studenti con alti livelli di ansia da prestazione ottengono punteggi più bassi nei test scolastici rispetto ai loro pari.”\nExplanans\nÈ l’insieme dei fattori che spiegano il fenomeno. Nel caso dell’ansia da prestazione, un possibile explanans potrebbe essere: “L’ansia danneggia la concentrazione e la memoria di lavoro, influendo negativamente sulla performance nei test.”\nLegame esplicativo\nComprende i principi o i meccanismi che dimostrano come l’explanans produca l’explanandum. Seguendo l’esempio precedente: “Livelli elevati di ansia innescano il sistema nervoso simpatico, aumentando lo stress fisiologico e riducendo l’efficienza dei processi cognitivi necessari per compiti complessi.”\n\nQuesti tre elementi si combinano all’interno di modelli scientifici, che costituiscono le strutture teoriche e metodologiche impiegate per formulare e verificare spiegazioni. In psicologia, tali modelli includono:\n\nIl fenomeno da spiegare (ad es. le prestazioni scolastiche).\n\nI fattori che lo influenzano (ad es. ansia, regolazione emotiva).\n\nI meccanismi sottostanti che collegano cause ed effetti (ad es. attivazione fisiologica, memoria di lavoro compromessa).\n\nUn modello psicologico sull’ansia da prestazione, ad esempio, potrebbe considerare la relazione tra livello di ansia percepita, capacità di regolazione emotiva e memoria di lavoro. A differenza di modelli esclusivamente descrittivi o predittivi, i modelli esplicativi rispondono a domande causali: non si limitano ad attestare che ansia e prestazioni sono correlate, ma mostrano come e perché l’ansia riduca il rendimento. Inoltre, tali modelli suggeriscono strategie d’intervento per attenuare l’effetto dell’ansia, come il potenziamento della regolazione emotiva o l’uso di tecniche di gestione dello stress.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#modelli-psicologici",
    "href": "chapters/key_notions/01_key_notions.html#modelli-psicologici",
    "title": "1  Concetti chiave",
    "section": "1.3 Modelli Psicologici",
    "text": "1.3 Modelli Psicologici\n\n\n\n\n\n\nUn modello è una rappresentazione concettuale – spesso supportata da formalismi matematici – di un fenomeno reale, basata su un insieme di equazioni e ipotesi che descrivono le relazioni tra variabili e la struttura probabilistica sottostante. L’obiettivo è coglierne gli aspetti essenziali senza includere ogni dettaglio superfluo, formulando predizioni quantitative che possano essere verificate empiricamente. Poiché spesso esistono molteplici modelli in grado di spiegare lo stesso fenomeno, il compito della ricerca consiste nel selezionare quello che meglio descrive i dati e soddisfa criteri di validità, accuratezza e parsimonia.\n\n\n\nI modelli psicologici, in particolare, sono strumenti teorici finalizzati a descrivere, spiegare e prevedere il comportamento umano e i processi mentali. Un modello ben costruito dovrebbe possedere le seguenti caratteristiche:\n\nCoerenza descrittiva\nIl modello deve fornire una rappresentazione logica e coerente del fenomeno, includendo tutti gli elementi chiave del processo psicologico e organizzando le osservazioni in una struttura interpretativa chiara.\nCapacità predittiva\nDeve essere in grado di formulare previsioni verificabili e di produrre ipotesi testabili sulla base dei dati raccolti, permettendo così di valutare la validità del modello.\nSupporto empirico\nLe previsioni e le ipotesi del modello vanno confrontate con l’evidenza empirica, ottenuta attraverso ricerche sistematiche e rigorose. I dati devono corroborare le relazioni proposte dal modello.\nFalsificabilità\nIl modello deve poter essere sottoposto a verifica empirica e, all’occorrenza, smentito. Se emergono osservazioni in conflitto con le sue previsioni, il modello deve essere revisionato o sostituito.\nParsimonia\nLa spiegazione deve risultare semplice e lineare, includendo solo gli elementi indispensabili per rendere conto del fenomeno. Assunzioni superflue o ridondanti ne riducono la robustezza.\nGeneralizzabilità\nIl modello dovrebbe poter essere esteso a contesti e situazioni diverse, superando i limiti di specifiche condizioni sperimentali o campioni ristretti.\nUtilità pratica\nDovrebbe offrire linee guida concrete per l’applicazione nel mondo reale, ad esempio negli interventi clinici, nei programmi di prevenzione o nelle terapie, così da avere un impatto positivo sugli individui e sulla società.\n\nUno degli ostacoli maggiori nella costruzione di modelli in psicologia è la natura soggettiva, dinamica e variabile dell’esperienza umana. È quindi necessario bilanciare la precisione teorica (spesso supportata da formalizzazioni matematiche o computazionali) con la flessibilità necessaria a catturare l’eterogeneità dei fenomeni psicologici. A questo si aggiungono i vincoli etici della ricerca sull’essere umano e le potenziali ricadute sociali dei risultati.\nL’analisi quantitativa dei dati gioca un ruolo centrale nella validazione dei modelli psicologici: mediante metodologie statistiche e computazionali avanzate, i ricercatori possono verificare se le predizioni di un modello trovano riscontro nei dati empirici e se tali predizioni si mantengono valide in contesti diversi. Questo processo non solo consolida la comprensione del fenomeno, ma consente anche di anticipare e, in alcune circostanze, influenzare il comportamento e i processi mentali. Un modello rigorosamente formulato e testabile diviene quindi un potente strumento per lo sviluppo di interventi efficaci e il progresso teorico.\n\n1.3.1 Rappresentare i Fenomeni per Ragionare e Comunicare\nLa spiegazione scientifica non si limita a far luce sui meccanismi causali, ma fornisce anche un linguaggio formale per analizzare e condividere conoscenze sui fenomeni. In psicologia, i modelli scientifici costituiscono strumenti fondamentali per descrivere i processi attraverso variabili, funzioni e parametri, offrendo una struttura che facilita l’individuazione di relazioni e proprietà essenziali. Un modello efficace semplifica la complessità del fenomeno, agevolando sia la comunicazione tra studiosi sia la comprensione intuitiva.\nInoltre, i modelli non si limitano a organizzare le informazioni esistenti: stimolano anche l’emergere di nuove ipotesi di ricerca, promuovono collegamenti tra concetti apparentemente lontani e consentono di trasferire conoscenze tra discipline, ampliando così l’orizzonte dell’indagine scientifica.\n\n\n1.3.2 Il Ruolo dell’Analisi dei Dati\nL’analisi dei dati è parte integrante del metodo scientifico e, in psicologia, assolve due funzioni primarie:\n\nSemplificare e sintetizzare informazioni complesse\nAttraverso statistiche descrittive, rappresentazioni grafiche e altre tecniche di sintesi, l’analisi dei dati aiuta a individuare schemi, tendenze e anomalie. Questo passaggio è essenziale per comprendere le differenze tra individui o gruppi e per formulare ipotesi di ricerca più mirate.\nValutare le predizioni dei modelli\nConfrontando i dati raccolti con le previsioni teoriche, si misura la validità di un modello. Tale confronto è indispensabile per confermare, raffinare o rivedere le ipotesi di partenza, orientando così il progresso della conoscenza scientifica.\n\nTuttavia, limitarsi alla ricerca di correlazioni o di pattern nei dati, senza un solido quadro teorico, non basta a comprendere pienamente il fenomeno. Risultati empirici privi di spiegazioni causali rimangono frammentari. Per questo motivo, integrare i dati in un modello teorico esplicativo è cruciale: si possono così proporre meccanismi causali, identificare relazioni e avanzare nuove ipotesi di ricerca.\n\n\n1.3.3 Carattere Multidisciplinare dell’Analisi dei Dati\nPer rispondere alle complesse domande poste in psicologia, l’analisi dei dati si fonda sull’integrazione di più discipline: statistica, teoria della probabilità e informatica. Ciascuna offre contributi indispensabili per affrontare la complessità dei processi psicologici:\n\nStatistica\nFornisce tecniche per la raccolta, l’organizzazione e l’interpretazione dei dati, consentendo di riassumere le informazioni, individuare pattern significativi e valutare empiricamente le ipotesi dei modelli psicologici.\nTeoria della probabilità\nCostituisce la base matematica della statistica e della modellazione scientifica, offrendo strumenti per quantificare l’incertezza, descrivere la variabilità delle osservazioni e costruire modelli predittivi rigorosi.\nInformatica\nContribuisce con strumenti per la gestione, l’analisi e la visualizzazione di grandi quantità di dati, nonché per l’implementazione di modelli computazionali sofisticati. Questi modelli si rivelano fondamentali nel simulare e testare dinamiche dei processi psicologici.\n\nLa natura multidisciplinare dell’analisi dei dati rispecchia l’esigenza di competenze diverse per comprendere e modellizzare i fenomeni psicologici in modo rigoroso. L’approccio quantitativo e computazionale ai modelli non si limita a descrivere e interpretare i dati, ma consente di formulare predizioni precise e sottoponibili a verifica, contribuendo così all’avanzamento della psicologia come scienza.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#concetti-chiave-nellanalisi-dei-dati",
    "href": "chapters/key_notions/01_key_notions.html#concetti-chiave-nellanalisi-dei-dati",
    "title": "1  Concetti chiave",
    "section": "1.4 Concetti Chiave nell’Analisi dei Dati",
    "text": "1.4 Concetti Chiave nell’Analisi dei Dati\nPer condurre un’analisi dei dati efficace, è fondamentale comprendere alcuni concetti chiave che guidano il processo di indagine, dall’identificazione del fenomeno alla formulazione di inferenze.\n\n1.4.1 Popolazioni e Campioni\nL’analisi dei dati inizia con l’identificazione della popolazione di interesse, che rappresenta l’insieme completo degli individui o delle entità coinvolte nel fenomeno studiato. Poiché studiare un’intera popolazione è spesso impraticabile, si ricorre ai campioni, sottoinsiemi rappresentativi della popolazione. La qualità e la rappresentatività del campione sono cruciali: un campione non rappresentativo può portare a conclusioni errate, limitando la generalizzabilità dei risultati.\n\n\n\n\n\n\nParametri e Statistiche\n\n\n\nUn parametro è una caratteristica numerica della popolazione (es. media \\(\\mu\\), deviazione standard \\(\\sigma\\)). Una statistica è una caratteristica numerica calcolata sul campione (es. media campionaria \\(\\bar{x}\\), deviazione standard campionaria \\(s\\)). L’inferenza statistica si occupa di stimare i parametri della popolazione a partire dalle statistiche campionarie.\n\n\n\n\n1.4.2 Bias nella Raccolta Dati\nI bias nella raccolta e interpretazione dei dati possono compromettere l’accuratezza dei risultati. Comprendere chi ha raccolto i dati, come e con quali scopi è essenziale per una corretta interpretazione (Johnson et al., 2022). I dati non sono mai completamente neutri; i metodi e gli obiettivi di raccolta influenzano i risultati. Ad esempio, selezionare partecipanti da una popolazione di studenti universitari potrebbe introdurre un bias sistematico, limitando la generalizzabilità ad altri contesti (Murray & Carr, 2024; Nobles, 2000).\n\n\n1.4.3 Variabili e Costanti\nNell’analisi statistica, le variabili rappresentano le caratteristiche osservate che possono assumere diversi valori (numerici o categorici). Le costanti, al contrario, rimangono fisse in un determinato contesto. Le variabili si distinguono in:\n\nvariabili indipendenti (o predittive): influenzano altri fenomeni;\n\nvariabili dipendenti: rappresentano gli esiti di interesse influenzati dalle variabili indipendenti.\n\nAd esempio, in uno studio sugli effetti della terapia cognitivo-comportamentale, la variabile indipendente potrebbe essere la partecipazione alla terapia, mentre la variabile dipendente sarebbe la riduzione dei sintomi di ansia.\n\n\n1.4.4 Studi Osservazionali ed Esperimenti\nEsistono due principali metodi di raccolta dati.\n\nEsperimenti: I ricercatori manipolano una o più variabili per valutare il loro effetto su altre variabili, controllando per i fattori confondenti. Ad esempio, per valutare l’efficacia di un trattamento, i partecipanti possono essere assegnati casualmente a un gruppo di controllo (placebo) e a un gruppo sperimentale (trattamento attivo). La randomizzazione riduce il rischio di bias sistematici.\nStudi osservazionali: I dati vengono raccolti senza interferire con il fenomeno osservato. Ad esempio, un’indagine su come lo stress influenza la produttività lavorativa potrebbe basarsi su questionari senza manipolare lo stress dei partecipanti. Questi studi forniscono correlazioni tra variabili, ma non dimostrano relazioni causali.\n\n\n\n1.4.5 Effetti\nIn statistica, un effetto rappresenta il cambiamento osservato nella variabile dipendente in relazione a una variabile indipendente. Questo cambiamento può indicare un’associazione tra le due variabili, ma la sua interpretazione come relazione causale dipende strettamente dal disegno sperimentale con cui i dati sono stati raccolti.\nAd esempio, se si osserva una riduzione dei sintomi tra la fase pre-trattamento e quella post-trattamento in un gruppo di pazienti sottoposti a una terapia, è possibile identificare un effetto della terapia. Tuttavia, senza un disegno sperimentale adeguato – come un esperimento controllato randomizzato (RCT) – non è possibile stabilire con certezza che la riduzione dei sintomi sia causata dalla terapia e non da altri fattori, come il decorso naturale della malattia o l’effetto placebo (Huntington-Klein, 2021).\nI modelli statistici, da soli, non possono determinare relazioni causali: possono quantificare l’entità di un effetto e valutare la forza dell’associazione tra variabili, ma la causalità può essere inferita solo se i dati provengono da un disegno sperimentale che isola il meccanismo di interesse, controllando per possibili fattori di confondimento. Pertanto, per trarre conclusioni causali robuste, è essenziale integrare l’analisi statistica con un approccio metodologico rigoroso basato su strategie di manipolazione sperimentale, assegnazione casuale o tecniche avanzate per il controllo dei bias nei dati osservazionali.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#stima-e-inferenza-statistica-dal-campione-alla-popolazione",
    "href": "chapters/key_notions/01_key_notions.html#stima-e-inferenza-statistica-dal-campione-alla-popolazione",
    "title": "1  Concetti chiave",
    "section": "1.5 Stima e Inferenza Statistica: Dal Campione alla Popolazione",
    "text": "1.5 Stima e Inferenza Statistica: Dal Campione alla Popolazione\nLa stima e l’inferenza statistica costituiscono i pilastri della metodologia quantitativa, poiché permettono di estendere le conclusioni tratte da un campione – una porzione limitata di individui osservati – all’intera popolazione di interesse. L’uso dei campioni risulta indispensabile a causa dei vincoli di tempo, costi e risorse, che spesso rendono impossibile lo studio dell’intera popolazione.\nTuttavia, il ricorso al campione introduce inevitabilmente un’incertezza intrinseca: le statistiche campionarie (come media o varianza del campione) sono stime dei parametri della popolazione e di norma non coincidono esattamente con i valori “veri” della popolazione. Tale discrepanza è nota come errore di campionamento, la cui entità dipende, tra l’altro, dalla dimensione del campione e dalla strategia di campionamento adottata.\nLa teoria degli stimatori e gli strumenti di inferenza statistica (ad esempio, intervalli di confidenza in un approccio frequentista o intervalli di credibilità in un approccio bayesiano) consentono di quantificare e gestire quest’incertezza, fornendo un quadro che permette di trarre conclusioni credibili sulla popolazione partendo dai dati raccolti.\n\n1.5.1 Stima: Inferire le Caratteristiche della Popolazione\nLa stima è il processo con cui, a partire dai dati di un campione, si inferiscono proprietà della popolazione, come la media o la varianza. Poiché ogni campione rappresenta solo una frazione della popolazione, può fornire stime diverse; questo fenomeno è noto come variabilità campionaria. Proprio tale variabilità costituisce la principale fonte di incertezza nelle inferenze: se un singolo campione non è sufficientemente ampio o rappresentativo, la stima potrebbe discostarsi in misura rilevante dai valori effettivi presenti nella popolazione.\n\n1.5.1.1 Fattori che Influenzano l’Accuratezza\nTre fattori fondamentali influiscono sull’accuratezza di una stima:\n\nDimensione del campione\nUn campione più grande tende a ridurre la variabilità campionaria, aumentando la precisione delle stime.\nRappresentatività\nUn campione ben progettato e rappresentativo rispecchia le caratteristiche essenziali della popolazione. Al contrario, un campione distorto (ad esempio, selezionato per convenienza) può condurre a stime fuorvianti.\nVariabilità della popolazione\nSe la popolazione è estremamente eterogenea, sono necessari campioni più ampi per produrre stime affidabili.\n\n\n\n1.5.1.2 Gli Stimatori: Proprietà Fondamentali\nGli stimatori sono formule matematiche o procedure statistiche usate per calcolare le stime. La loro qualità si valuta principalmente in base a:\n\nConsistenza\nUno stimatore è consistente se, all’aumentare della dimensione del campione, la stima tende a convergere verso il valore reale del parametro.\nNon distorsione (unbiasedness)\nUno stimatore è non distorto se il suo valore atteso corrisponde al parametro della popolazione. In altri termini, in media, lo stimatore coincide con il valore reale.\nEfficienza\nTra stimatori non distorti, è più efficiente quello con varianza minore, poiché fornisce stime più stabili.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#inferenza-statistica",
    "href": "chapters/key_notions/01_key_notions.html#inferenza-statistica",
    "title": "1  Concetti chiave",
    "section": "1.6 Inferenza Statistica",
    "text": "1.6 Inferenza Statistica\nL’inferenza statistica si basa sulle stime campionarie per trarre conclusioni sull’intera popolazione. In particolare, risponde a tre grandi interrogativi:\n\nStima dei parametri della popolazione\nOttenere valori plausibili per parametri quali media, varianza e proporzioni, quantificando contestualmente l’incertezza (ad esempio, costruendo intervalli di confidenza o di credibilità).\nValutazione di ipotesi\nConfrontare ipotesi rivali, come l’esistenza di differenze tra gruppi o di relazioni tra variabili. Attraverso il confronto tra ipotesi e dati, si determina quale ipotesi è meglio supportata.\nPrevisione\nUtilizzare i dati esistenti per anticipare risultati futuri, tenendo conto delle fonti di incertezza legate sia alla variabilità intrinseca dei dati sia ai parametri non perfettamente noti.\n\nSia l’approccio frequentista sia quello bayesiano affrontano questi problemi in modo rigoroso, ma differiscono nel modo di concettualizzare l’incertezza e di incorporare l’informazione nei modelli.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#le-sfide-dellinferenza-statistica-in-psicologia",
    "href": "chapters/key_notions/01_key_notions.html#le-sfide-dellinferenza-statistica-in-psicologia",
    "title": "1  Concetti chiave",
    "section": "1.7 Le Sfide dell’Inferenza Statistica in Psicologia",
    "text": "1.7 Le Sfide dell’Inferenza Statistica in Psicologia\nIn psicologia e, più in generale, nelle scienze sociali, l’inferenza statistica incontra specifiche problematiche spesso connesse alla complessità dei fenomeni oggetto di studio (Gelman et al., 2021). Tra le sfide principali figurano:\n\nLimiti nella generalizzazione dei risultati\nIn molti studi psicologici, le condizioni sperimentali create in laboratorio o in ambienti altamente controllati non sempre rispecchiano le dinamiche reali in cui i fenomeni si manifestano. L’uso di procedure standardizzate e compiti artificiali può semplificare notevolmente le variabili in gioco, a scapito della validità esterna: i risultati ottenuti potrebbero non essere direttamente trasferibili a contesti naturali o situazioni di vita quotidiana. Inoltre, se i partecipanti vengono selezionati per ragioni pratiche (ad esempio, studenti universitari reclutati su base volontaria), ciò limita ulteriormente la rappresentatività del campione, rendendo più difficile estendere le conclusioni a gruppi più eterogenei o a popolazioni diverse.\nRischio di semplificare eccessivamente i meccanismi causali ipotizzati\nL’inferenza causale – implicita o esplicita nella maggior parte delle ricerche in psicologia – mira a comprendere se e come un fattore influisca su un altro. Tuttavia, in contesti così complessi, i modelli causali proposti possono risultare eccessivamente semplificati, trascurando interazioni tra variabili, fattori contestuali o processi multilivello. Quando tali aspetti non vengono adeguatamente considerati, le conclusioni possono rivelarsi poco utili o non sufficientemente applicabili ai contesti reali.\nDistorsioni legate alla misurazione\nMolti costrutti di interesse psicologico (es. ansia, autostima, intelligenza) non sono direttamente osservabili, bensì misurati attraverso questionari, test o altre metodologie indirette. Tale approccio introduce possibili errori di misurazione e distorsioni legate allo strumento di valutazione. L’inferenza statistica deve quindi tenere conto di questa complessità, collegando in modo rigoroso le osservazioni empiriche ai costrutti teorici sottostanti.\n\nIn sintesi, la stima e l’inferenza statistica rappresentano strumenti fondamentali per trasformare i dati campionari in conoscenza generalizzabile, soprattutto in un contesto come quello psicologico, caratterizzato da un’elevata variabilità nei comportamenti e nei processi mentali. Da un lato, la metodologia quantitativa offre un quadro consolidato per gestire l’incertezza e testare ipotesi; dall’altro, è cruciale prestare attenzione alla qualità del campione, alla validità degli strumenti di misura e all’intrinseca complessità dei costrutti indagati.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#la-quantificazione-dellincertezza",
    "href": "chapters/key_notions/01_key_notions.html#la-quantificazione-dellincertezza",
    "title": "1  Concetti chiave",
    "section": "1.8 La Quantificazione dell’Incertezza",
    "text": "1.8 La Quantificazione dell’Incertezza\nLe considerazioni introduttive di questo capitolo mettono in evidenza come la gestione e la quantificazione dell’incertezza rappresentino un aspetto cruciale della stima e dell’inferenza statistica. Qualunque stima ottenuta da un campione è inevitabilmente soggetta a errore, poiché il campione costituisce soltanto una frazione della popolazione di riferimento. L’inferenza statistica offre gli strumenti necessari per quantificare tale incertezza, ad esempio tramite gli intervalli di confidenza (nell’approccio frequentista) o le distribuzioni a posteriori (nell’approccio bayesiano), consentendo di esprimere in modo rigoroso il grado di fiducia nelle conclusioni raggiunte.\nIn conclusione, la stima e l’inferenza statistica rappresentano strumenti essenziali per trasformare i dati empirici in conoscenza solida e applicabile. È tuttavia indispensabile avvalersene in maniera critica, tenendo sempre presenti le possibili distorsioni insite nel processo di raccolta e analisi dei dati. Ciò significa prestare particolare attenzione alla rappresentatività del campione, alla validità delle misurazioni e all’interpretazione corretta dei risultati, così da evitare generalizzazioni indebite o conclusioni fuorvianti.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#riflessioni-conclusive",
    "href": "chapters/key_notions/01_key_notions.html#riflessioni-conclusive",
    "title": "1  Concetti chiave",
    "section": "1.9 Riflessioni Conclusive",
    "text": "1.9 Riflessioni Conclusive\nL’analisi dei dati acquisisce valore solo quando è integrata con una solida teoria scientifica, che fornisce il contesto e il quadro interpretativo necessario per attribuire senso ai risultati. Ad esempio, osservare che un trattamento psicologico riduce i sintomi è un’osservazione empirica che, senza una teoria che chiarisca i meccanismi sottostanti, rimane priva di potere esplicativo. È la teoria che orienta il processo analitico, formulando ipotesi verificabili e offrendo interpretazioni che si inseriscono in un modello più ampio.\nIn definitiva, la relazione tra teoria e analisi dei dati è intrinsecamente circolare e dinamica: le teorie guidano la raccolta, l’analisi e l’interpretazione dei dati, mentre i dati, a loro volta, stimolano il perfezionamento e l’evoluzione delle teorie. Questo dialogo continuo è ciò che permette un progresso costante nella comprensione dei fenomeni psicologici.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#esercizi",
    "href": "chapters/key_notions/01_key_notions.html#esercizi",
    "title": "1  Concetti chiave",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nChe cos’è una spiegazione scientifica e in che modo si differenzia da una mera descrizione o previsione di un fenomeno?\nPerché, quando si parla di popolazione e campione, è fondamentale assicurarsi che il campione sia rappresentativo, e quali conseguenze possono derivare da un campione non rappresentativo?\nChe differenza c’è tra un parametro e una statistica, e perché in inferenza statistica si cerca di stimare il parametro sconosciuto a partire dalla statistica campionaria?\nCosa si intende per bias nella raccolta e interpretazione dei dati, e in che modo la consapevolezza dei possibili bias può migliorare la qualità della ricerca?\nPerché in psicologia e nelle scienze sociali risulta essenziale integrare l’analisi dei dati con un quadro teorico solido e coerente?\nQual è la differenza principale tra uno studio osservazionale e un esperimento, e perché la distinzione è importante per comprendere la causalità?\nChe ruolo svolgono i modelli scientifici in psicologia, e quali caratteristiche fondamentali dovrebbero possedere per essere considerati validi e utili?\nIn che modo l’analisi dei dati aiuta a passare dalle semplici correlazioni o tendenze osservate all’elaborazione di ipotesi e spiegazioni più profonde?\nChe differenza c’è tra variabili indipendenti e variabili dipendenti, e perché questa distinzione è cruciale per disegnare uno studio e interpretarne i risultati?\nPerché parlare di incertezza è inevitabile quando si utilizzano i dati di un campione, e come la statistica (frequentista o bayesiana) ci aiuta a gestirla?\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n1. Che cos’è una spiegazione scientifica e in che modo si differenzia da una mera descrizione o previsione di un fenomeno?\nUna spiegazione scientifica mira a individuare le cause e i meccanismi che generano o influenzano un fenomeno. Non si limita quindi a descrivere cosa accade o a prevedere ciò che potrebbe accadere (come una semplice correlazione o un modello predittivo), ma cerca di chiarire perché il fenomeno si verifica. Ad esempio, dire “i bambini con genitori laureati hanno migliori prestazioni scolastiche” è una descrizione (o previsione) utile; spiegare che ciò avviene a causa di un maggior sostegno nel percorso di studi, di un ambiente più ricco di stimoli culturali, o di un contesto socioeconomico facilitante, fornisce invece una spiegazione che va oltre la pura correlazione statistica.\n2. Perché, quando si parla di popolazione e campione, è fondamentale assicurarsi che il campione sia rappresentativo, e quali conseguenze possono derivare da un campione non rappresentativo?\nIl campione è il sottoinsieme di individui selezionati da una popolazione più ampia. Affinché i risultati di uno studio siano validi e generalizzabili, il campione deve rispecchiare le principali caratteristiche della popolazione (ad esempio in termini di età, genere, livello socioeconomico, ecc.). Se il campione non è rappresentativo (per esempio, se si reclutano solo studenti universitari per uno studio su tutta la popolazione italiana), possono emergere bias di selezione che rendono impossibile estendere correttamente i risultati a gruppi sociali diversi. Conseguenze tipiche di un campione non rappresentativo includono stime distorte dei parametri d’interesse, conclusioni fuorvianti e ridotta validità esterna della ricerca.\n3. Che differenza c’è tra un parametro e una statistica, e perché in inferenza statistica si cerca di stimare il parametro sconosciuto a partire dalla statistica campionaria?\n\nUn parametro è una caratteristica numerica della popolazione (ad esempio la media reale di un determinato tratto o la proporzione di individui con una certa caratteristica).\n\nUna statistica è una misura analoga, ma calcolata sul campione (ad esempio la media o la proporzione campionaria).\n\nPoiché in genere è impossibile o molto costoso misurare l’intera popolazione, si raccoglie un campione più piccolo e gestibile. La statistica del campione (ad es. la media campionaria) è quindi usata per stimare il parametro (ad es. la media della popolazione). L’obiettivo dell’inferenza statistica è fornire, insieme a questa stima, una misura dell’incertezza associata (per esempio un intervallo di confidenza), così da comprendere quanto la statistica campionaria potrebbe “avvicinarsi” al vero valore del parametro.\n4. Cosa si intende per bias nella raccolta e interpretazione dei dati, e in che modo la consapevolezza dei possibili bias può migliorare la qualità della ricerca?\nIl bias è un errore sistematico che altera i risultati di uno studio in una direzione specifica, dovuto a scelte o condizioni nel disegno della ricerca, nella selezione del campione, nella misurazione o nell’interpretazione dei dati. Ad esempio, se reclutiamo solo volontari particolarmente motivati a partecipare a una ricerca, potremmo ottenere risultati che sovrastimano un certo fenomeno e non rispecchiano la popolazione generale.\nEssere consapevoli di come i bias possano nascere aiuta i ricercatori a mitigarli (ad esempio, bilanciando il reclutamento dei partecipanti o rendendo anonima la compilazione di un questionario) e a tenere conto dei loro effetti quando si interpretano i risultati. Così, la ricerca risulta più affidabile e validamente interpretata.\n5. Perché in psicologia e nelle scienze sociali risulta essenziale integrare l’analisi dei dati con un quadro teorico solido e coerente?\nNelle scienze sociali e in psicologia, i fenomeni studiati sono spesso complessi e influenzati da molte variabili. I dati da soli, senza una teoria, forniscono soltanto una descrizione o una misurazione di ciò che accade in un dato momento. La teoria invece permette di:\n\nIdentificare le variabili rilevanti e formulare ipotesi specifiche;\n\nInterpretare i risultati, attribuendo un senso e un contesto alle relazioni osservate;\n\nComprendere i meccanismi causali e sviluppare spiegazioni che vadano oltre la pura descrizione.\n\nSenza un quadro teorico di riferimento, sarebbe difficile capire perché si osservano determinate relazioni e come possano cambiare in contesti diversi o in situazioni sperimentali alternative.\n6. Qual è la differenza principale tra uno studio osservazionale e un esperimento, e perché la distinzione è importante per comprendere la causalità?\n\nStudio osservazionale: Il ricercatore raccoglie i dati senza intervenire né manipolare alcuna variabile. Ad esempio, si misura il livello di stress delle persone e la loro produttività sul lavoro, senza modificare artificialmente il livello di stress. Questi studi mostrano correlazioni, ma è difficile stabilire con certezza relazioni di causa-effetto.\n\nEsperimento: Il ricercatore manipola una o più variabili (variabili indipendenti) e controlla le condizioni, ad esempio assegnando in modo casuale i partecipanti a un gruppo di trattamento e a uno di controllo. Ciò facilita la comprensione di eventuali nessi causali, perché la randomizzazione e il controllo degli altri fattori riducono il rischio che variabili esterne influenzino i risultati.\n\nLa distinzione è cruciale perché, nei fenomeni complessi della psicologia, gli studi osservazionali possono suggerire ipotesi di relazione, ma di solito occorre un disegno sperimentale (quando possibile) per trarre conclusioni più solide sulla causalità.\n7. Che ruolo svolgono i modelli scientifici in psicologia, e quali caratteristiche fondamentali dovrebbero possedere per essere considerati validi e utili?\nI modelli scientifici in psicologia forniscono una struttura concettuale e spesso formale (matematica o simulativa) per rappresentare e spiegare processi mentali e comportamentali. Servono a:\n\nOrganizzare osservazioni ed evidenze in un sistema coerente;\n\nFare previsioni verificabili empiricamente;\n\nGuidare l’interpretazione di nuovi dati e la progettazione di futuri studi.\n\nCaratteristiche di un buon modello sono:\n\nCoerenza descrittiva (rappresenta fedelmente il fenomeno);\n\nCapacità predittiva (prevede correttamente i risultati di situazioni nuove);\n\nSupporto empirico (confermato dai dati raccolti rigorosamente);\n\nFalsificabilità (dev’essere possibile smentirlo con evidenze contrarie);\n\nParsimonia (non dev’essere inutilmente complicato);\n\nGeneralizzabilità (applicabile a diversi contesti e situazioni);\n\nUtilità pratica (fornisce indicazioni utili per interventi o comprensione teorica).\n\n8. In che modo l’analisi dei dati aiuta a passare dalle semplici correlazioni o tendenze osservate all’elaborazione di ipotesi e spiegazioni più profonde?\nL’analisi dei dati non si limita a segnalare che “due variabili sono associate” (correlazioni), ma offre:\n\nStrumenti per isolare l’effetto di una variabile sulle altre (regressioni multiple, modelli a effetti misti, ecc.);\n\nMetodologie per la verifica di ipotesi specifiche sulla direzione e sulla natura delle relazioni (ad es. test statistici o modelli di mediazione-moderazione in psicologia);\n\nIndicatori dell’incertezza e della robustezza dei risultati (intervalli di confidenza, analisi della potenza, analisi bayesiane).\n\nCon questi strumenti, i ricercatori possono integrare i risultati quantitativi con le teorie esistenti, sviluppare nuove ipotesi su meccanismi causali e proporre spiegazioni più articolate su come e perché le variabili si influenzino reciprocamente.\n9. Che differenza c’è tra variabili indipendenti e variabili dipendenti, e perché questa distinzione è cruciale per disegnare uno studio e interpretarne i risultati?\n\nVariabile indipendente (VI): è quella che si sospetta abbia un effetto su un’altra variabile, o che si desidera manipolare in un disegno sperimentale (per esempio, l’introduzione di un nuovo metodo di studio).\n\nVariabile dipendente (VD): è la variabile che si misura per valutare l’eventuale effetto della variabile indipendente (ad esempio, i risultati di un test di apprendimento).\nLa distinzione è basilare perché chiarisce la direzione del rapporto di interesse e permette di formulare ipotesi come “VI → VD” (es. “il nuovo metodo di studio migliora i risultati del test”). Sbagliare a identificare quali sono le variabili indipendenti e dipendenti può portare a disegni di ricerca confusi e interpretazioni errate.\n\n10. Perché parlare di incertezza è inevitabile quando si utilizzano i dati di un campione, e come la statistica (frequentista o bayesiana) ci aiuta a gestirla?\nQuando raccogliamo dati da un campione (necessariamente limitato), non possiamo osservare l’intera popolazione. Questo introduce un margine di incertezza su quanto la misura campionaria (statistica) rispecchi il parametro reale della popolazione. Inoltre, possono sempre esserci fattori non controllati o errori di misurazione.\n\nNell’approccio frequentista, l’incertezza è gestita tramite concetti come gli intervalli di confidenza e i valori p, che quantificano la probabilità di osservare determinati risultati assumendo determinate ipotesi (per es. l’ipotesi nulla).\n\nNell’approccio bayesiano, l’incertezza è modellata tramite distribuzioni di probabilità (posteriori) che incorporano sia i dati osservati sia le informazioni pregresse (priors).\n\nEntrambi gli approcci forniscono metodologie per valutare quanto ci si possa fidare di una data conclusione, riconoscendo il carattere aleatorio e parziale dei dati e rendendo esplicito il grado di incertezza.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#bibliografia",
    "href": "chapters/key_notions/01_key_notions.html#bibliografia",
    "title": "1  Concetti chiave",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.\n\n\nHuntington-Klein, N. (2021). The effect: An introduction to research design and causality. Chapman; Hall/CRC.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nMurray, E. J., & Carr, K. C. (2024). Measuring Racial Sentiment Using Social Media Is Harder Than It Seems. Epidemiology, 35(1), 60–63.\n\n\nNobles, M. (2000). Shades of citizenship: Race and the census in modern politics. Stanford University Press.\n\n\nSteinman, R. M., Pizlo, Z., & Pizlo, F. J. (2000). Phi is not beta, and why Wertheimer’s discovery launched the Gestalt revolution. Vision research, 40(17), 2257–2264.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_design.html",
    "href": "chapters/key_notions/02_design.html",
    "title": "2  Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "",
    "text": "2.1 Introduzione\nQuesto capitolo si propone di approfondire i concetti introdotti in precedenza, concentrandosi in particolare sul processo di campionamento e sull’importanza delle diverse metodologie di ricerca in psicologia. Dopo aver compreso il ruolo fondamentale dei dati nella verifica delle teorie, emerge una questione cruciale: come vengono raccolti questi dati?\nLa raccolta dei dati non è un’attività neutra o priva di conseguenze metodologiche. I dati, infatti, non hanno lo stesso valore scientifico a seconda di come vengono ottenuti. Alcune modalità di raccolta generano informazioni preziose e utili per testare le teorie, mentre altre possono produrre risultati fuorvianti, distorti o addirittura dannosi per la validità della ricerca.\nIl metodo scientifico fornisce un quadro di riferimento che delinea le caratteristiche ideali di un processo di raccolta dati in grado di produrre informazioni valide e affidabili. Tuttavia, le prescrizioni del metodo scientifico sono per loro natura generali e astratte. Tradurre questi principi in procedure concrete e applicarli efficacemente in un contesto di ricerca specifico rappresenta una sfida significativa.\nQuesto passaggio, che collega la teoria alla pratica, dipende dalle risorse disponibili, dalla competenza metodologica e dalla creatività del ricercatore. La capacità di ideare e attuare strategie di raccolta dati adeguate al contesto specifico della ricerca è fondamentale per garantire la qualità e la validità dei risultati ottenuti. In questo capitolo, approfondiremo i principi del campionamento e introdurremo i concetti chiave relativi ai disegni di ricerca.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_design.html#popolazioni-e-campioni",
    "href": "chapters/key_notions/02_design.html#popolazioni-e-campioni",
    "title": "2  Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "2.2 Popolazioni e Campioni",
    "text": "2.2 Popolazioni e Campioni\nNella ricerca scientifica, è essenziale distinguere tra popolazione e campione.\n\nPopolazione: rappresenta l’insieme completo di unità che condividono una o più caratteristiche specifiche oggetto di studio. La dimensione della popolazione è indicata con N.\nCampione: è un sottoinsieme della popolazione, di dimensione n. L’obiettivo del campionamento è ottenere un campione rappresentativo, ovvero un sottoinsieme che rifletta accuratamente le caratteristiche della popolazione di riferimento.\n\n\n2.2.1 Metodi di Campionamento\nEsistono diverse strategie per selezionare un campione rappresentativo da una popolazione. Queste strategie si dividono principalmente in due categorie: campionamento probabilistico e campionamento non probabilistico.\n\n2.2.1.1 Campionamento Probabilistico\nNel campionamento probabilistico, ogni unità della popolazione ha una probabilità nota e non nulla di essere inclusa nel campione. Questo approccio minimizza il rischio di distorsioni sistematiche (bias) e consente di stimare l’errore di campionamento.\n\nCampionamento Casuale Semplice (CCS):\nOgni unità della popolazione ha la stessa probabilità di essere inclusa nel campione. Questo metodo richiede una lista completa di tutte le unità della popolazione, nota come frame di campionamento. La selezione può avvenire con o senza reinserimento. Il CCS senza reinserimento è il più comune nella pratica, ma nelle ricerche psicologiche è raramente utilizzabile a causa della difficoltà di ottenere un frame completo della popolazione.\nCampionamento Stratificato:\nLa popolazione viene divisa in strati (H), ovvero sottogruppi omogenei in base a una o più variabili rilevanti (es. età, genere, regione geografica). Da ogni strato h viene estratto un campione casuale semplice di dimensione nh. Questo metodo può essere:\n\nProporzionale: la dimensione del campione in ogni strato è proporzionale alla dimensione dello strato nella popolazione.\nNon proporzionale: utilizzato per sovra-campionare gruppi minoritari, consentendo analisi dettagliate di sottogruppi altrimenti poco rappresentati.\nNelle ricerche psicologiche, il campionamento stratificato è utile per garantire che variabili come il genere o l’età siano adeguatamente rappresentate, ma può essere complesso da implementare.\n\nCampionamento a Grappolo (Cluster Sampling):\nLa popolazione viene suddivisa in grappoli (cluster), che rappresentano gruppi eterogenei (es. scuole, ospedali, quartieri). Vengono selezionati casualmente alcuni grappoli, includendo tutte le unità al loro interno. Questo metodo è economico e pratico, specialmente in contesti dove accedere all’intera popolazione è difficile. Tuttavia, la precisione può essere ridotta se i grappoli differiscono notevolmente tra loro.\nCampionamento Multistadio:\nCombinazione di campionamento a grappolo e CCS. Vengono selezionati casualmente alcuni grappoli e, successivamente, all’interno di ciascun grappolo, si estrae un campione casuale di unità. Questo metodo bilancia costi e precisione, risultando particolarmente adatto a studi su larga scala, ad esempio a livello nazionale.\n\n\n\n2.2.1.2 Campionamento Non Probabilistico\nNel campionamento non probabilistico, la probabilità di inclusione di ogni unità nel campione non è nota. Questo approccio è spesso adottato per ragioni di praticità o quando non è disponibile un frame di campionamento. Tuttavia, aumenta il rischio di distorsioni e limita la generalizzabilità dei risultati alla popolazione.\n\nCampionamento di Convenienza:\nÈ il metodo più diffuso nella ricerca psicologica. I partecipanti vengono selezionati in base alla loro facile accessibilità (es., studenti universitari, volontari). Questo metodo è rapido ed economico, ma introduce significativi bias di selezione, poiché il campione non è rappresentativo della popolazione generale.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_design.html#il-campionamento-nella-ricerca-psicologica",
    "href": "chapters/key_notions/02_design.html#il-campionamento-nella-ricerca-psicologica",
    "title": "2  Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "2.3 Il Campionamento nella Ricerca Psicologica",
    "text": "2.3 Il Campionamento nella Ricerca Psicologica\nIl tema del campionamento nella ricerca psicologica è cruciale perché influisce in modo diretto sulla validità esterna e sulla generalizzabilità dei risultati. Nella pratica, però, l’ideale metodologico del campionamento probabilistico è spesso difficile da perseguire, a causa di vincoli di tempo, di risorse economiche e di accessibilità ai partecipanti (Henrich et al., 2010a). Per queste ragioni, molti studi in psicologia fanno ricorso al campionamento di convenienza, che prevede la selezione dei partecipanti sulla base della loro facile reperibilità, come studenti universitari o volontari reclutati online.\n\n2.3.1 Perché il Campionamento di Convenienza è così Diffuso?\n\nVincoli di Risorse\nLa ricerca psicologica, specie in ambito accademico, spesso non dispone di finanziamenti sufficienti per condurre campionamenti su larga scala. Reclutare partecipanti rappresentativi di un’intera popolazione richiederebbe budget, logistica e tempo ben superiori a quelli generalmente disponibili (Peterson & Merunka, 2014). Il campionamento di convenienza diventa quindi un compromesso “necessario” per poter portare avanti gli studi.\nAccessibilità ai Partecipanti\nNel contesto universitario, gli studenti rappresentano il bacino più facilmente accessibile e motivato a partecipare a studi psicologici, talvolta in cambio di crediti formativi o rimborsi simbolici (Sears, 1986). In altri contesti, si ricorre a piattaforme online che forniscono volontari in tempi brevi, consentendo di raccogliere dati in modo rapido e a costi contenuti.\nRapidità di Raccolta Dati\nIl vantaggio principale del campionamento di convenienza è la possibilità di raccogliere dati in tempi molto più ridotti rispetto a strategie di campionamento probabilistico. Tale rapidità può risultare essenziale per studi pilota o ricerche che richiedono analisi preliminari di fenomeni ancora poco esplorati.\n\n\n\n2.3.2 Limiti e Implicazioni\nIl ricorso al campionamento di convenienza comporta inevitabilmente dei limiti in termini di rappresentatività del campione. Gli individui che si prestano a partecipare a uno studio potrebbero avere caratteristiche socio-demografiche, cognitive o motivazionali peculiari (ad esempio, essere più giovani, con livelli di istruzione più alti, culturalmente più omogenei), portando ad un fenomeno noto come “campioni WEIRD” [Western, Educated, Industrialized, Rich, Democratic; Henrich et al. (2010b)]. Ciò significa che i risultati ottenuti potrebbero non riflettere adeguatamente l’intera variabilità della popolazione umana.\n\nGeneralizzabilità Ridotta: Uno studio condotto su studenti di psicologia in un’università europea può non essere applicabile a individui di diverse fasce di età, provenienti da altre aree geografiche o con retroterra socio-culturali differenti.\nBias di Selezione: I partecipanti volontari, specialmente online, possono essere attratti dallo studio per ragioni specifiche (ad esempio, curiosità verso la psicologia, tempo libero a disposizione, motivazione a ottenere un compenso), introducendo distorsioni non presenti nella popolazione più ampia.\nLimitazioni nei Risultati: Se i processi psicologici oggetto di indagine sono influenzati da cultura, età o altre variabili, lo studio potrebbe non catturare in modo esaustivo la complessità del fenomeno.\n\n\n\n2.3.3 Perché in Psicologia è (in Parte) Accettabile\nSebbene il campionamento di convenienza costituisca un limite, è bene ricordare che molti fenomeni psicologici presentano elementi di base che sono relativamente generali o universali nell’essere umano [ad esempio, i processi di percezione, l’apprendimento di base, alcune dinamiche emotive e motivazionali; cfr. Tooby & Cosmides (2005)]. Ciò significa che, entro certi confini, studiare un campione di convenienza può comunque fornire indicazioni utili e trasferibili ad altre popolazioni. Inoltre, buona parte delle ricerche in psicologia mira ad approfondire meccanismi e processi interna corporis – cioè aspetti di natura cognitiva, emotiva o sociale che, pur potendo variare in intensità o manifestazione, hanno basi comuni tra gli individui.\nIn altre parole, esiste un trade-off tra la necessità di disporre di campioni rappresentativi per garantire la massima generalizzabilità e la specificità dei fenomeni psicologici, che talvolta risiedono in processi considerati “universali”. Se lo scopo di uno studio è quello di testare meccanismi cognitivi di base (per esempio, l’elaborazione di stimoli visivi o di memoria), un campione di studenti potrebbe comunque fornire dati sufficientemente robusti, purché si riconoscano i limiti del contesto di raccolta.\n\n2.3.3.1 Considerazioni Etiche e Pratiche\nTalvolta, per ragioni etiche, non è semplice reperire partecipanti da particolari fasce di popolazione (ad esempio minori, pazienti clinici, soggetti in contesti istituzionali). In alcune ricerche, poi, l’uso di questionari lunghi o procedure sperimentali intense rende difficile attrarre volontari al di fuori dell’ambiente universitario. Da questo punto di vista, avere un bacino di partecipanti noti (ad es. studenti di psicologia) agevola la raccolta dei dati.\n\nRicompense: Spesso i dipartimenti offrono crediti formativi o piccoli compensi ai partecipanti, innescando un circolo virtuoso di interesse per la ricerca.\nLibertà di rifiuto: Le università dispongono di comitati etici che tutelano i diritti dei partecipanti, garantendo che anche i reclutamenti “di comodo” rispettino i principi etici fondamentali (consenso informato, anonimato, diritto al recesso, ecc.).\n\n\n\n\n2.3.4 Come Mitigare i Limiti del Campionamento di Convenienza\n\nReplicazione Incrociata (Cross-Replication)\nUn metodo efficace per aumentare la validità dei risultati è replicare lo stesso studio su campioni differenti, di età diversa o provenienti da contesti socio-culturali eterogenei. Ripetere la ricerca in più contesti e ottenere risultati simili fornisce evidenza della generalizzabilità del fenomeno.\nCampionamento Diversificato\nAnche se si ricorre a un campionamento di convenienza, si può tentare di diversificare la provenienza dei partecipanti (ad esempio, includendo studenti di diverse facoltà o atenei, oppure reclutando volontari su piattaforme online internazionali). Un campione che rifletta almeno in parte una maggiore varietà di background socio-culturali è comunque preferibile alla selezione di un solo gruppo omogeneo.\nCaratterizzazione Dettagliata del Campione\nÈ fondamentale fornire informazioni precise su età, genere, livello di istruzione, estrazione socio-culturale e altre variabili rilevanti. Questo permette ai lettori di valutare in che misura i risultati dello studio possano essere trasferiti ad altre popolazioni.\nIntegrazione di Metodi di Campionamento Misti\nAlcuni ricercatori scelgono di integrare campionamenti non probabilistici con piccole porzioni di campionamento più stratificato o di selezionare sotto-campioni rappresentativi per determinati sottogruppi. Non si tratta di un vero e proprio campionamento probabilistico, ma può comunque migliorare la robustezza dei risultati rispetto al puro campionamento di convenienza.\n\n\n\n2.3.5 Considerazioni Economiche e Future Prospettive\nAlla luce di questi punti, appare chiaro che il ricorso a metodi di campionamento probabilistici più rigorosi (campionamento casuale semplice, stratificato o a grappolo) richiederebbe aumenti significativi nei finanziamenti e un impegno logistico maggiore. Ciò non è sempre fattibile in contesti di ricerca accademica o quando i progetti sono condotti con budget limitati.\nD’altro canto, i finanziamenti aggiuntivi permetterebbero di:\n\nReclutare campioni più ampi e diversificati, ad esempio attraverso agenzie di rilevazione professionali o sondaggi a livello nazionale.\n\nImplementare studi longitudinali su popolazioni geograficamente distribuite, riducendo il rischio di raccogliere dati esclusivamente da aree limitrofe ai centri di ricerca.\nSostenere progetti multicentrici a livello internazionale, che consentono di testare l’universalità o la specificità culturale dei fenomeni psicologici.\n\nFino a quando queste risorse non saranno disponibili su larga scala, il campionamento di convenienza rimarrà la soluzione più diffusa e “realistica” nella ricerca psicologica. Tuttavia, non bisogna considerarlo esclusivamente un limite: la specificità dei fenomeni psicologici, legati a processi condivisi tra gli individui, talvolta permette di estrarre conclusioni valide anche da campioni meno rappresentativi, purché si utilizzino adeguate cautele nell’interpretazione e si persegua la replicazione come prassi consolidata.\nIn sintesi, il campionamento di convenienza è una strategia inevitabile nell’attuale panorama della ricerca psicologica, caratterizzato da forti limitazioni di risorse, ma in molti casi risulta comunque sufficiente per investigare dinamiche e processi psicologici di base. L’auspicio per il futuro è di poter disporre di finanziamenti e collaborazioni che permettano di ampliare il raggio d’azione e la diversità dei partecipanti, rafforzando la validità e la generalizzabilità della produzione scientifica in psicologia.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_design.html#metodologia-sperimentale",
    "href": "chapters/key_notions/02_design.html#metodologia-sperimentale",
    "title": "2  Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "2.4 Metodologia Sperimentale",
    "text": "2.4 Metodologia Sperimentale\n\n2.4.1 Principi Fondamentali del Disegno Sperimentale\n\nControllo\nL’obiettivo è ridurre l’influenza di variabili confondenti (Z) sulla relazione tra la variabile indipendente (X) e quella dipendente (Y). Utilizzare un gruppo di controllo consente di stabilire un riferimento per valutare l’effetto del trattamento.\nRandomizzazione\nL’assegnazione casuale dei partecipanti ai gruppi sperimentali distribuisce le variabili confondenti in modo equilibrato tra i gruppi, aumentando la credibilità dell’inferenza causale tra X e Y. Questo approccio garantisce che eventuali differenze osservate siano attribuibili al trattamento e non a fattori esterni.\n\n\n\n2.4.2 Strategie di Mitigazione dei Bias\n\nCecità (Blinding)\nStrumento chiave per minimizzare l’influenza di aspettative e pregiudizi, sia nei partecipanti che nei ricercatori. Le principali modalità includono:\n\nCecità singola: I partecipanti non sono consapevoli del trattamento assegnato.\nCecità doppia: Sia i partecipanti che i ricercatori che interagiscono direttamente con loro non conoscono l’assegnazione dei trattamenti.\nCecità tripla: Né i partecipanti, né i ricercatori, né gli analisti dei dati sono a conoscenza dei trattamenti durante la raccolta e l’analisi dei dati.\n\nGruppo di Controllo\nL’introduzione di un gruppo che riceve un trattamento inerte (controllo) consente di isolare gli effetti psicologici legati alle aspettative dei partecipanti, distinguendoli dagli effetti specifici del trattamento.\nStandardizzazione delle Procedure\nGarantire che tutte le condizioni sperimentali, eccetto la variabile manipolata, siano mantenute costanti tra i gruppi. Questo riduce la variabilità non controllata, migliorando la comparabilità dei risultati.\n\n\n\n2.4.3 Nota sulla Replicazione\nLa replicazione degli esperimenti non è una caratteristica intrinseca del metodo sperimentale, ma rappresenta una pratica fondamentale nella scienza per verificare l’affidabilità e la generalizzabilità dei risultati. Si distingue in:\n\nReplicazione diretta: Ripetere lo stesso studio con le stesse condizioni.\nReplicazione concettuale: Ripetere lo studio modificando aspetti specifici per testare la robustezza del risultato.\n\n\n\n2.4.4 Tipologie di Disegni Sperimentali\n\nDisegno a Gruppi Indipendenti (Between-Subjects):\nI partecipanti vengono assegnati a un unico gruppo e sono esposti a una sola condizione sperimentale. Questo disegno è utile quando l’esposizione multipla potrebbe introdurre confondenti, ma richiede un campione più ampio per raggiungere lo stesso livello di precisione.\nDisegno a Misure Ripetute (Within-Subjects):\nGli stessi partecipanti vengono esposti a tutte le condizioni sperimentali. Questo approccio riduce la variabilità tra soggetti, migliorando la precisione delle stime. Tuttavia, richiede attenzione nel controllare gli effetti di ordine, come affaticamento o apprendimento, spesso attraverso il bilanciamento dell’ordine di presentazione dei trattamenti.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_design.html#studi-osservazionali",
    "href": "chapters/key_notions/02_design.html#studi-osservazionali",
    "title": "2  Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "2.5 Studi Osservazionali",
    "text": "2.5 Studi Osservazionali\nGli studi osservazionali possono essere classificati in:\n\nStudi Trasversali (Cross-Sectional)\nI dati vengono raccolti in un singolo momento. Utili per stimare la prevalenza di una condizione, ma non permettono di stabilire relazioni causali.\nStudi di Coorte (Cohort Studies)\nUn gruppo di individui (coorte) viene seguito nel tempo per osservare l’incidenza di un evento. Permettono di studiare la relazione tra esposizione e outcome, ma possono essere costosi e richiedere molto tempo.\nStudi Caso-Controllo (Case-Control Studies)\nVengono confrontati individui con una determinata condizione (casi) con individui senza la condizione (controlli) per identificare possibili fattori di rischio. Utili per studiare malattie rare, ma soggetti a bias di selezione e di ricordo.\n\nLe principali limitazioni degli studi osservazionali sono la presenza di variabili confondenti e la difficoltà di stabilire relazioni causali.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_design.html#riflessioni-conclusive",
    "href": "chapters/key_notions/02_design.html#riflessioni-conclusive",
    "title": "2  Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "2.6 Riflessioni Conclusive",
    "text": "2.6 Riflessioni Conclusive\nNel corso di questo capitolo, abbiamo esplorato l’importanza del campionamento e delle diverse strategie di ricerca in psicologia, mettendo in luce i vincoli metodologici e le implicazioni derivanti da scelte spesso guidate dalle risorse a disposizione. Se da un lato i metodi di campionamento probabilistico garantiscono maggiore controllo sulla rappresentatività del campione, dall’altro, la realtà accademica e il contesto operativo di molti studi psicologici spingono verso soluzioni di comodo, inevitabilmente limitanti ma non per questo prive di valore scientifico.\nLe complessità intrinseche nello studio di fenomeni psicologici – spesso universali e al tempo stesso influenzati da variabili culturali e individuali – ci ricordano quanto sia importante mantenere un equilibrato senso critico. Da un punto di vista metodologico, l’esigenza di replicare gli studi in più contesti rimane la prassi fondamentale per rafforzare la credibilità dei risultati. Altrettanto cruciale è la volontà di caratterizzare in modo trasparente i propri campioni, rendendo chiaro in che misura siano (o non siano) rappresentativi della popolazione d’interesse. In tal modo, la comunità scientifica può valutare con maggiore consapevolezza la trasferibilità delle conclusioni a contesti diversi.\nUn ulteriore spunto di riflessione riguarda la tensione tra la desiderabilità di disegni di ricerca ideali (con campioni estesi e probabilistici) e le inevitabili restrizioni di tempo e budget. Se l’implementazione di studi su larga scala o a livello multicentrico consentirebbe di cogliere le sfumature culturali e socio-demografiche dei fenomeni, è altrettanto vero che, nel panorama attuale, molte ricerche non potrebbero essere realizzate senza ricorrere a partecipanti di più facile accesso, come gli studenti universitari o i volontari online. Tale flessibilità operativa può comunque produrre conoscenza significativa, a condizione che il ricercatore rimanga vigile rispetto ai possibili bias introdotti.\nIn definitiva, l’invito a chiunque conduca ricerche psicologiche è quello di coltivare una mentalità aperta, volta a bilanciare i limiti contingenti (economici, logistici, etici) con la necessità di mantenere standard metodologici solidi. Ciò implica sfruttare le potenzialità dell’integrazione tra disegni sperimentali e osservazionali, prestare attenzione alle forme di bias e, soprattutto, adottare la replicazione come pratica sistematica. Solo attraverso questa sinergia fra rigore scientifico e consapevolezza delle risorse disponibili è possibile far progredire la disciplina su basi empiriche sempre più solide e generalizzabili.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_design.html#esercizi",
    "href": "chapters/key_notions/02_design.html#esercizi",
    "title": "2  Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nPerché la fase di raccolta dei dati è considerata “non neutrale” e quali conseguenze può avere sull’affidabilità dei risultati di una ricerca psicologica?\nIn che modo i diversi metodi di campionamento (probabilistico vs. non probabilistico) influiscono sulla generalizzabilità delle conclusioni di uno studio e quali situazioni giustificano l’uso dell’uno o dell’altro?\nQuali sono i principali rischi nell’adottare un campionamento di convenienza in ricerche psicologiche, e quali strategie si possono utilizzare per mitigare questi rischi?\nIn che modo la randomizzazione e l’uso di gruppi di controllo supportano l’inferenza causale in un disegno sperimentale, e perché queste caratteristiche sono spesso più difficili da mantenere negli studi osservazionali?\nQuali sono i principali criteri da considerare quando si valuta la validità di uno studio in termini di campionamento, disegno di ricerca e replicabilità?\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n1. Perché la fase di raccolta dei dati è considerata “non neutrale” e quali conseguenze può avere sull’affidabilità dei risultati di una ricerca psicologica?\nLa raccolta dei dati non è mai un processo completamente neutrale perché comporta scelte metodologiche e pratiche che possono influenzare la qualità e la natura delle informazioni ottenute. Ad esempio:\n\nSelezione del campione: Scegliere chi includere o escludere nella ricerca incide sulla rappresentatività del campione. Un campione non rappresentativo può produrre risultati distorti e difficilmente generalizzabili.\n\nModalità di somministrazione degli strumenti: La maniera in cui vengono somministrati questionari, test o interviste può influire sulle risposte dei partecipanti (per esempio, differenze tra somministrazione online vs. cartacea, questionari anonimi vs. non anonimi, ecc.).\n\nContesto e tempistiche: Il contesto ambientale (es., rumori, distrazioni) o il momento in cui i dati vengono raccolti (es., in prossimità di esami universitari) possono influenzare lo stato emotivo o motivazionale dei partecipanti.\n\nCome conseguenza, tutte queste variabili possono introdurre bias – ossia distorsioni sistematiche – che compromettono l’affidabilità e la validità dei risultati, rendendo l’interpretazione dei dati più complessa e potenzialmente fuorviante. In altre parole, se la fase di raccolta dati non è accuratamente progettata e condotta, la ricerca potrebbe fornire conclusioni scorrette o di limitata utilità scientifica.\n2. In che modo i diversi metodi di campionamento (probabilistico vs. non probabilistico) influiscono sulla generalizzabilità delle conclusioni di uno studio e quali situazioni giustificano l’uso dell’uno o dell’altro?\n\nCampionamento probabilistico:\n\nOgni unità della popolazione ha una probabilità nota e non nulla di essere selezionata.\n\nMetodi come il campionamento casuale semplice, stratificato o a grappolo forniscono un quadro più solido per stimare l’errore di campionamento e minimizzare i bias.\n\nI risultati ottenuti sono, in linea di massima, più facilmente generalizzabili all’intera popolazione di riferimento.\n\nÈ preferibile in studi di larga scala, in cui esiste un buon frame di campionamento (lista esaustiva della popolazione) e le risorse (tempo, fondi) consentono di implementare un disegno rigoroso.\n\nCampionamento non probabilistico:\n\nLa probabilità di inclusione di un’unità non è nota, per cui non si possono calcolare in modo rigoroso le stime di errore.\n\nIl metodo più comune è il campionamento di convenienza, in cui vengono reclutate persone facilmente accessibili (es., studenti universitari, volontari, piattaforme online).\n\nLa generalizzabilità dei risultati è ridotta, poiché il campione potrebbe non rispecchiare le caratteristiche della popolazione di interesse.\n\nÈ spesso utilizzato per studi esplorativi, ricerche a budget limitato o quando non si dispone di un elenco completo della popolazione.\n\n\nIn sintesi, il campionamento probabilistico è preferibile quando si mira a ottenere risultati solidi e generalizzabili a una popolazione più ampia e le condizioni logistiche lo consentono. Il campionamento non probabilistico, invece, è giustificato in studi preliminari, in situazioni in cui la popolazione non è ben definita o difficilmente accessibile, o quando si hanno vincoli di risorse che rendono impraticabile un campionamento probabilistico.\n3. Quali sono i principali rischi nell’adottare un campionamento di convenienza in ricerche psicologiche, e quali strategie si possono utilizzare per mitigare questi rischi?\n\nPrincipali rischi:\n\nBias di selezione: I partecipanti reclutati con metodi di convenienza (ad es. studenti di psicologia) potrebbero non rispecchiare l’eterogeneità della popolazione generale, limitando la generalizzabilità dei risultati.\n\nOmogeneità del campione: Se il campione è molto omogeneo (per età, livello di istruzione, contesto culturale), diventa difficile estendere le conclusioni a gruppi con caratteristiche diverse.\n\nAutoselezione: I volontari che si offrono di partecipare potrebbero differire sistematicamente da coloro che non partecipano (ad esempio, maggiore interesse per il tema della ricerca o per la ricompensa economica offerta).\n\nStrategie di mitigazione:\n\nSovra-campionamento: Includere deliberatamente più partecipanti appartenenti a gruppi minoritari o sottorappresentati, per disporre di sottocampioni più completi.\n\nReplicazione: Ripetere l’esperimento con campioni diversi (per età, contesto geografico, cultura) per verificare se i risultati si mantengono coerenti.\n\nDescrizione dettagliata del campione: Fornire informazioni precise sulle caratteristiche sociodemografiche (età, genere, livello di istruzione, ecc.) in modo che altri ricercatori o lettori possano valutare la trasferibilità dei risultati.\n\nCautela nell’interpretazione: Esplicitare nelle conclusioni i limiti relativi alla natura del campionamento e invitare a considerare possibili fattori confondenti legati alla non rappresentatività del campione.\n\n\n4. In che modo la randomizzazione e l’uso di gruppi di controllo supportano l’inferenza causale in un disegno sperimentale, e perché queste caratteristiche sono spesso più difficili da mantenere negli studi osservazionali?\n\nRandomizzazione:\n\nAssegna i partecipanti ai gruppi sperimentali (condizione sperimentale vs. condizione di controllo) in maniera casuale.\n\nGarantisce che variabili potenzialmente confondenti vengano distribuite equamente tra i gruppi, aumentando la probabilità che eventuali differenze nelle misure di esito (variabile dipendente) siano dovute esclusivamente alla manipolazione sperimentale (variabile indipendente).\n\nQuesto processo riduce l’influenza di fattori esterni non misurati o non conosciuti, favorendo un’inferenza causale più solida.\n\nGruppi di controllo:\n\nConsentono di confrontare i risultati di chi riceve il trattamento/intervento con chi non lo riceve (o riceve un trattamento placebo).\n\nAiutano a isolare l’effetto “vero” del trattamento dalle variazioni dovute a effetti psicologici (ad es. effetto placebo), al passare del tempo o a eventi esterni.\n\nDifficoltà negli studi osservazionali:\n\nNon prevedono la manipolazione diretta di una variabile indipendente né l’assegnazione casuale dei partecipanti: le persone “si assegnano da sole” alle condizioni.\n\nManca il controllo sperimentale: non è sempre possibile includere un gruppo di controllo o applicare procedure di randomizzazione.\n\nLe variabili confondenti possono agire in modo non controllabile e compromettere l’interpretazione causale: anche con analisi statistiche sofisticate, è difficile escludere del tutto la presenza di fattori esterni che influenzano la relazione tra esposizione e outcome.\n\n\nPer questi motivi, gli studi sperimentali (con randomizzazione e controllo) rimangono il metodo privilegiato per stabilire nessi di causalità, mentre gli studi osservazionali servono principalmente a generare ipotesi, descrivere fenomeni, o analizzare relazioni di associazione più che di causalità.\n5. Quali sono i principali criteri da considerare quando si valuta la validità di uno studio in termini di campionamento, disegno di ricerca e replicabilità?\n\nRappresentatività del campione:\n\nIl campione rispecchia realmente le caratteristiche della popolazione di interesse?\n\nÈ stato usato un metodo di campionamento appropriato (probabilistico vs. non probabilistico)?\n\nControllo e randomizzazione (validità interna):\n\nLo studio ha previsto un disegno sperimentale con assegnazione casuale e gruppo di controllo?\n\nQuanto è efficace il controllo delle variabili confondenti (bias di selezione, aspettative, effetto placebo, ecc.)?\n\nGeneralizzabilità o validità esterna:\n\nI risultati dello studio sono applicabili oltre il contesto specifico in cui è stato condotto?\n\nVi sono limitazioni dovute all’uso di un campione di convenienza o di un contesto culturale molto particolare?\n\nStandardizzazione delle procedure:\n\nLe istruzioni, i tempi di raccolta dati, i materiali utilizzati sono stati gestiti in modo uniforme per tutti i partecipanti?\n\nReplicabilità:\n\nÈ possibile ripetere lo studio (replicazione diretta o concettuale) e ottenere risultati simili?\n\nGli autori forniscono informazioni sufficienti (materiali, protocolli, analisi) per consentire la replicazione?\n\nChiarezza nell’esposizione dei limiti:\n\nGli autori discutono apertamente le limitazioni del metodo di campionamento o del disegno di ricerca e suggeriscono possibili miglioramenti per studi futuri?\n\n\nNel complesso, una valutazione critica di uno studio deve integrare tutti questi aspetti (campionamento, disegno, replicabilità) per stabilire in che misura i risultati siano solidi, attendibili e utilmente generalizzabili.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_design.html#bibliografia",
    "href": "chapters/key_notions/02_design.html#bibliografia",
    "title": "2  Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nHenrich, J., Heine, S. J., & Norenzayan, A. (2010a). Most people are not WEIRD. Nature, 466(7302), 29–29.\n\n\nHenrich, J., Heine, S. J., & Norenzayan, A. (2010b). The weirdest people in the world? Behavioral and Brain Sciences, 33(2-3), 61–83.\n\n\nPeterson, R. A., & Merunka, D. R. (2014). Convenience samples of college students and research reproducibility. Journal of Business Research, 67(5), 1035–1041.\n\n\nTooby, J., & Cosmides, L. (2005). Evolutionary psychology: Conceptual foundations. In D. M. Buss (A c. Di), The Handbook of Evolutionary Psychology (pp. 5–67). Wiley.\n\n\nYouyou, W., Yang, Y., & Uzzi, B. (2023). A discipline-wide investigation of the replicability of Psychology papers over the past two decades. Proceedings of the National Academy of Sciences, 120(6), e2208863120.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_measurement.html",
    "href": "chapters/key_notions/03_measurement.html",
    "title": "3  La misurazione in psicologia",
    "section": "",
    "text": "3.1 Introduzione\nLa scienza si avvale di modelli per interpretare i dati, ma opera sempre con teorie incomplete e misurazioni soggette a errori. Di conseguenza, è fondamentale riconoscere le incertezze quando si cerca di estrarre informazioni dalle misurazioni utilizzando i nostri modelli. Nessuna misurazione, spiegazione o previsione è perfettamente accurata e precisa, e non possiamo mai conoscere con esattezza l’entità dei loro errori. Questo riconoscimento è alla base della teoria della misurazione, che cerca di quantificare e gestire queste incertezze per migliorare la qualità delle nostre conclusioni scientifiche.\nQuesta incertezza viene catturata in tre equazioni fondamentali. La prima è l’Equazione di Misurazione, che riconosce l’errore osservativo:\n\\[\ny = z + \\varepsilon_y,\n\\]\ndove \\(y\\) rappresenta il valore misurato, \\(z\\) il valore reale e \\(\\varepsilon_y\\) l’errore di misurazione. La seconda è l’Equazione di Modellazione, che esprime la presenza di un diverso tipo di errore:\n\\[\nz = f(x, \\theta) + \\varepsilon_\\text{model},\n\\]\ndove \\(f\\) è il modello, \\(x\\) sono le condizioni ambientali per cui eseguiamo il modello, \\(\\theta\\) sono i valori dei parametri del modello e \\(\\varepsilon_\\text{model}\\) rappresenta l’errore del modello, che sorge perché \\(f\\), \\(x\\) e \\(\\theta\\) saranno tutti in qualche misura imprecisi.\nCombinando queste due equazioni, otteniamo l’Equazione della Scienza:\n\\[\ny = f(x, \\theta) + \\varepsilon_\\text{model} + \\varepsilon_y.\n\\]\nLa scienza è il tentativo di spiegare le osservazioni \\(y\\) utilizzando un modello \\(f\\), cercando di minimizzare l’errore di misurazione \\(\\varepsilon_y\\) e l’errore del modello \\(\\varepsilon_\\text{model}\\), in modo che il modello possa essere utilizzato per fare previsioni sul mondo reale (\\(z\\)). L’approccio bayesiano alla scienza riconosce e quantifica le incertezze su tutti e sei gli elementi dell’Equazione della Scienza: \\(y\\), \\(f\\), \\(x\\), \\(\\theta\\), \\(\\varepsilon_\\text{model}\\) e \\(\\varepsilon_y\\).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_measurement.html#la-teoria-della-misurazione",
    "href": "chapters/key_notions/03_measurement.html#la-teoria-della-misurazione",
    "title": "3  La misurazione in psicologia",
    "section": "3.2 La teoria della Misurazione",
    "text": "3.2 La teoria della Misurazione\nLa teoria della misurazione, oggetto di questo capitolo, si concentra sull’errore di misurazione e sull’equazione fondamentale \\(y = z + \\varepsilon_y\\). Questa equazione può essere esaminata da tre prospettive distinte. La prima concerne l’affidabilità della misura, rappresentata dal termine \\(\\varepsilon_y\\). La psicometria, branca dedicata alla teoria della misurazione psicologica, si occupa di quantificare l’affidabilità delle misure psicologiche attraverso metodi come la Teoria Classica dei Test e la Teoria di Risposta all’Item.\nLa seconda prospettiva riguarda la validità delle misure psicologiche, ovvero quanto adeguatamente la misura \\(y\\) rappresenti il costrutto \\(z\\). Questo aspetto, più complesso dell’affidabilità, non può essere risolto meramente con metodi statistici, ma richiede una profonda comprensione delle teorie psicologiche e della loro capacità di descrivere e prevedere i fenomeni psicologici.\nLa terza prospettiva si concentra sulle procedure di assegnazione dei valori a \\(y\\), esplorando quali metodi (questionari, interviste, esperimenti) siano più appropriati e come valutarne l’adeguatezza.\n\n3.2.1 Costrutti Psicologici\nLa teoria della misurazione sottolinea l’importanza di distinguere tra la procedura di misurazione e il costrutto che si intende misurare. Ad esempio, mentre la temperatura è un costrutto, il termometro è lo strumento di misurazione. Analogamente, l’abilità matematica è un costrutto, mentre un test di matematica è la procedura per misurarla.\nNelle scienze psicologiche e sociali, la misurazione presenta sfide uniche rispetto alle scienze fisiche, poiché i costrutti in esame sono spesso astratti e non direttamente osservabili. Ciò richiede una particolare attenzione alla validità e all’affidabilità degli strumenti di misurazione, nonché una costante riflessione sulle limitazioni e le potenziali fonti di errore.\nIl capitolo introduce concetti fondamentali relativi alla misurazione quantitativa delle caratteristiche psicologiche, con un focus sulla teoria delle scale di misura di Stevens (1946). Questa teoria fornisce un quadro concettuale per comprendere i diversi tipi di scale di misurazione e le operazioni matematiche appropriate per ciascuna. Inoltre, vengono esplorate alcune procedure di scaling psicologico, ovvero l’assegnazione di numeri all’intensità di fenomeni psicologici.\n\n\n3.2.2 Scaling Psicologico\nLo scaling psicologico si occupa della trasformazione dei dati empirici raccolti durante uno studio psicologico in misure o punteggi che rappresentino accuratamente le caratteristiche psicologiche oggetto di indagine.\nScaling di Guttman. Uno dei metodi di scaling più noti è lo «Scaling di Guttman», che viene utilizzato per rappresentare relazioni ordinate tra gli elementi di una scala. Ad esempio, in un questionario sui sintomi dell’ansia, le domande possono essere disposte in ordine di intensità crescente dei sintomi. Secondo il modello di Guttman, se un partecipante risponde “sì” a una domanda che riflette un sintomo più intenso, ci si aspetta che abbia risposto “sì” anche a tutte le domande precedenti, che rappresentano sintomi di intensità minore. Questo approccio consente di costruire una scala che riflette in modo sistematico e coerente la gravità dei sintomi.\nScaling Thurstoniano. Lo «Scaling Thurstoniano» è un metodo utilizzato per misurare preferenze o giudizi soggettivi. Ad esempio, per valutare la preferenza tra diversi tipi di cibi, i partecipanti confrontano due cibi alla volta ed esprimono una preferenza. Le risposte vengono poi utilizzate per assegnare punteggi che riflettono la preferenza media per ciascun cibo.\nScaling Fechneriano. Lo scaling fechneriano si basa sulla legge di Fechner, secondo cui la percezione di uno stimolo aumenta in modo logaritmico rispetto alla sua intensità fisica. La misura fondamentale è la JND (Just Noticeable Difference), ovvero la minima differenza percepibile tra due stimoli. Secondo Fechner, sommando le JND si ottiene una scala psicologica dell’intensità percepita, utile per studiare grandezze sensoriali come luminosità, peso e suono (per es., Domini & Caudek, 2009).\nQuestionari Likert. I questionari Likert richiedono ai partecipanti di esprimere il loro grado di accordo con una serie di affermazioni su una scala a più livelli, che va da «fortemente in disaccordo» a «fortemente d’accordo». I punteggi ottenuti vengono sommati per rappresentare la posizione complessiva dell’individuo rispetto all’oggetto di studio.\n\n\n3.2.3 Metodi di Valutazione delle Scale Psicologiche\nPer valutare le proprietà delle scale psicologiche, vengono utilizzati vari metodi. Ad esempio, l’affidabilità delle misure può essere analizzata utilizzando il coefficiente alpha di Cronbach o il coefficiente Omega di McDonald, entrambi utilizzati per misurare la coerenza interna delle risposte ai diversi item di un questionario. Inoltre, la validità delle scale può essere esaminata confrontando i risultati ottenuti con misure simili o attraverso analisi statistiche che verificano se la scala cattura accuratamente il costrutto psicologico che si intende misurare. La validità di costrutto è particolarmente cruciale, poiché riguarda la capacità della scala di misurare effettivamente il concetto psicologico che si intende esplorare.\n\n\n3.2.4 Prospettive Moderne\nNegli ultimi anni, il dibattito sulla misurazione psicologica si è arricchito di nuove prospettive, grazie all’avvento di tecnologie avanzate e all’integrazione di approcci interdisciplinari. Ecco alcune delle tendenze più rilevanti.\nTeoria della Risposta agli Item. La Teoria della Risposta agli Item (IRT) ha guadagnato popolarità per la sua capacità di fornire stime più precise delle abilità latenti rispetto ai modelli classici. La IRT considera la probabilità che un individuo risponda correttamente a un item in funzione della sua abilità e delle caratteristiche dell’item stesso, offrendo una visione più dettagliata delle proprietà psicometriche degli strumenti di misurazione.\nApprocci Bayesiani. Gli approcci bayesiani stanno rivoluzionando il campo della psicometria, permettendo di incorporare informazioni a priori nelle stime e di aggiornare le credenze sulla base di nuovi dati. Questi metodi sono particolarmente utili per affrontare la complessità e l’incertezza inerenti alla misurazione psicologica.\nAnalisi di Rete. L’analisi di rete è un’altra metodologia emergente che vede i costrutti psicologici non come variabili latenti indipendenti, ma come reti di sintomi interconnessi. Questo approccio può offrire nuove intuizioni sulla struttura delle psicopatologie e sulla dinamica dei sintomi.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_measurement.html#le-scale-di-misurazione",
    "href": "chapters/key_notions/03_measurement.html#le-scale-di-misurazione",
    "title": "3  La misurazione in psicologia",
    "section": "3.3 Le scale di misurazione",
    "text": "3.3 Le scale di misurazione\nLe scale di misurazione sono strumenti fondamentali per assegnare numeri ai dati osservati, rappresentando le proprietà psicologiche. La teoria delle scale di Stevens (1946) identifica quattro tipi di scale di misurazione: nominali, ordinali, a intervalli e di rapporti. Ognuna di queste scale consente di effettuare operazioni aritmetiche diverse, poiché ciascuna di esse è in grado di “catturare” solo alcune delle proprietà dei fenomeni psicologici che si intende misurare.\n\n\n\nScale di misurazione.\n\n\n\n3.3.1 Scala nominale\nLa scala nominale è il livello di misurazione più semplice e corrisponde ad una tassonomia o classificazione delle categorie che utilizziamo per descrivere i fenomeni psicologici. I simboli o numeri che costituiscono questa scala rappresentano i nomi delle categorie e non hanno alcun valore numerico intrinseco. Con la scala nominale possiamo solo distinguere se una caratteristica psicologica è uguale o diversa da un’altra.\nI dati raccolti con la scala nominale sono suddivisi in categorie qualitative e mutuamente esclusive, in cui ogni dato appartiene ad una sola categoria. In questa scala, esiste solo la relazione di equivalenza tra le misure delle unità di studio: gli elementi del campione appartenenti a classi diverse sono differenti, mentre tutti quelli della stessa classe sono tra loro equivalenti.\nL’unica operazione algebrica consentita dalla scala nominale è quella di contare le unità di studio che appartengono ad ogni categoria e il numero totale di categorie. Di conseguenza, la descrizione dei dati avviene tramite le frequenze assolute e le frequenze relative.\nDalla scala nominale è possibile costruire altre scale nominali equivalenti alla prima, trasformando i valori della scala di partenza in modo tale da cambiare i nomi delle categorie, ma lasciando inalterata la suddivisione delle unità di studio nelle medesime classi di equivalenza. In altre parole, cambiando i nomi delle categorie di una variabile misurata su scala nominale, si ottiene una nuova variabile esattamente equivalente alla prima.\n\n\n3.3.2 Scala ordinale\nLa scala ordinale mantiene la caratteristica della scala nominale di classificare ogni unità di misura all’interno di una singola categoria, ma introduce la relazione di ordinamento tra le categorie. In quanto basata su una relazione di ordine, una scala ordinale descrive solo il rango di ordine tra le categorie e non fornisce informazioni sulla distanza tra di esse. Non ci dice, ad esempio, se la distanza tra le categorie \\(a\\) e \\(b\\) è uguale, maggiore o minore della distanza tra le categorie \\(b\\) e \\(c\\).\nUn esempio classico di scala ordinale è quello della scala Mohs per la determinazione della durezza dei minerali. Per stabilire la durezza dei minerali si usa il criterio empirico della scalfittura. Vengono stabiliti livelli di durezza crescente da 1 a 10 con riferimento a dieci minerali: talco, gesso, calcite, fluorite, apatite, ortoclasio, quarzo, topazio, corindone e diamante. Un minerale appartenente ad uno di questi livelli se scalfisce quello di livello inferiore ed è scalfito da quello di livello superiore.\n\n\n\nLa scala di durezza dei minerali di Mohs. Un oggetto è considerato più duro di X se graffia X. Sono incluse anche misure di durezza relativa utilizzando uno sclerometro, da cui emerge la non linearità della scala di Mohs (Burchard, 2004).\n\n\n\n\n3.3.3 Scala ad intervalli\nLa scala ad intervalli di misurazione include le proprietà della scala nominale e della scala ordinale e permette di misurare le distanze tra le coppie di unità statistiche in termini di un intervallo costante, chiamato “unità di misura”, a cui viene attribuito il valore “1”. L’origine della scala, ovvero il punto zero, è scelta arbitrariamente e non indica l’assenza della proprietà che si sta misurando. Ciò significa che la scala ad intervalli consente anche valori negativi e lo zero non viene attribuito all’unità statistica in cui la proprietà risulta assente.\nLa scala ad intervalli equivalenti consente l’esecuzione di operazioni algebriche basate sulla differenza tra i numeri associati ai diversi punti della scala, operazioni algebriche non possibili con le scale di misura nominale o ordinale. Tuttavia, il limite della scala ad intervalli è che non consente di calcolare il rapporto tra coppie di misure. È possibile affermare la differenza tra \\(a\\) e \\(b\\) come la metà della differenza tra \\(c\\) e \\(d\\) o che le due differenze sono uguali, ma non è possibile affermare che \\(a\\) abbia una proprietà misurata in quantità doppia rispetto a \\(b\\). In altre parole, non è possibile stabilire rapporti diretti tra le misure ottenute. Solo le differenze tra le modalità permettono tutte le operazioni aritmetiche, come la somma, l’elevazione a potenza o la divisione, che sono alla base della statistica inferenziale.\nNelle scale ad intervalli equivalenti, l’unità di misura è arbitraria e può essere cambiata attraverso una dilatazione, ovvero la moltiplicazione di tutti i valori della scala per una costante positiva. Inoltre, la traslazione, ovvero l’aggiunta di una costante a tutti i valori della scala, è ammessa poiché non altera le differenze tra i valori della scala. La scala rimane invariata rispetto a traslazioni e dilatazioni e dunque le uniche trasformazioni ammissibili sono le trasformazioni lineari:\n\\[\ny' = a + by, \\quad b &gt; 0.\n\\]\nInfatti, l’uguaglianza dei rapporti fra gli intervalli rimane invariata a seguito di una trasformazione lineare.\nEsempio di scala ad intervalli è la temperatura misurata in gradi Celsius o Fahrenheit, ma non Kelvin. Come per la scala nominale, è possibile stabilire se due modalità sono uguali o diverse: \\(30^\\circ C \\neq 20^\\circ C\\). Come per la scala ordinale è possibile mettere due modalità in una relazione d’ordine: \\(30^\\circ C &gt; 20^\\circ C\\). In aggiunta ai casi precedenti, però, è possibile definire una unità di misura per cui è possibile dire che tra \\(30^\\circ C\\) e \\(20^\\circ C\\) c’è una differenza di \\(30^\\circ - 20^\\circ = 10^\\circ C\\). I valori di temperatura, oltre a poter essere ordinati secondo l’intensità del fenomeno, godono della proprietà che le differenze tra loro sono direttamente confrontabili e quantificabili.\nIl limite della scala ad intervalli è quello di non consentire il calcolo del rapporto tra coppie di misure. Ad esempio, una temperatura di \\(80^\\circ C\\) non è il doppio di una di \\(40^\\circ C\\). Se infatti esprimiamo le stesse temperature nei termini della scala Fahrenheit, allora i due valori non saranno in rapporto di 1 a 2 tra loro. Infatti, \\(20^\\circ C = 68^\\circ F\\) e \\(40^\\circ C = 104^\\circ F\\). Questo significa che la relazione “il doppio di” che avevamo individuato in precedenza si applicava ai numeri della scala centigrada, ma non alla proprietà misurata (cioè la temperatura). La decisione di che scala usare (Centigrada vs. Fahrenheit) è arbitraria. Ma questa arbitrarietà non deve influenzare le inferenze che traiamo dai dati. Queste inferenze, infatti, devono dirci qualcosa a proposito della realtà empirica e non possono in nessun modo essere condizionate dalle nostre scelte arbitrarie che ci portano a scegliere la scala Centigrada piuttosto che quella Fahrenheit.\nConsideriamo ora l’aspetto invariante di una trasformazione lineare, ovvero l’uguaglianza dei rapporti fra intervalli. Prendiamo in esame, ad esempio, tre temperature: \\(20^\\circ C = 68^\\circ F\\), \\(15^\\circ C = 59^\\circ F\\), \\(10^\\circ C = 50 ^\\circ F\\).\nÈ facile rendersi conto del fatto che i rapporti fra intervalli restano costanti indipendentemente dall’unità di misura che è stata scelta:\n\\[\n  \\frac{20^\\circ C - 10^\\circ C}{20^\\circ C - 15^\\circ C} =\n  \\frac{68^\\circ F - 50^\\circ F}{68^\\circ F-59^\\circ F} = 2.\n\\]\n\n\n3.3.4 Scala di rapporti\nNella scala a rapporti equivalenti, lo zero non è arbitrario e rappresenta l’elemento che ha intensità nulla rispetto alla proprietà misurata. Per costruire questa scala, si associa il numero 0 all’elemento con intensità nulla e si sceglie un’unità di misura \\(u\\). Ad ogni elemento si assegna un numero \\(a\\) definito come \\(a = d / u\\), dove \\(d\\) rappresenta la distanza dall’origine. In questo modo, i numeri assegnati riflettono le differenze e i rapporti tra le intensità della proprietà misurata.\nIn questa scala, è possibile effettuare operazioni aritmetiche non solo sulle differenze tra i valori della scala, ma anche sui valori stessi della scala. L’unica scelta arbitraria è l’unità di misura, ma lo zero deve sempre rappresentare l’intensità nulla della proprietà considerata.\nLe trasformazioni ammissibili in questa scala sono chiamate trasformazioni di similarità e sono del tipo \\(y' = by\\), dove \\(b &gt; 0\\). In questa scala, i rapporti tra i valori rimangono invariati dopo le trasformazioni. In altre parole, se rapportiamo due valori originali e due valori trasformati, il rapporto rimane lo stesso: \\(\\frac{y_i}{y_j} = \\frac{y'_i}{y'_j}\\).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_measurement.html#gerarchia-dei-livelli-delle-scale-di-misurazione",
    "href": "chapters/key_notions/03_measurement.html#gerarchia-dei-livelli-delle-scale-di-misurazione",
    "title": "3  La misurazione in psicologia",
    "section": "3.4 Gerarchia dei livelli delle scale di misurazione",
    "text": "3.4 Gerarchia dei livelli delle scale di misurazione\nSecondo Stevens (1946), esiste una gerarchia dei livelli delle scale di misurazione, denominati “livelli di scala”. Questi livelli sono organizzati in modo gerarchico, in cui la scala nominale rappresenta il livello più basso della misurazione, mentre la scala a rapporti equivalenti rappresenta il livello più alto.\n\nScala nominale: Classifica le categorie senza un ordine specifico.\nScala ordinale: Classifica le categorie in un ordine specifico, ma senza una misura precisa delle distanze.\nScala a intervalli: Misura le distanze tra le categorie con un intervallo costante, ma senza un punto zero assoluto.\nScala di rapporti: Misura le distanze con un intervallo costante e un punto zero assoluto.\n\n\n\n\nRelazioni tra i livelli di misurazione.\n\n\nPassando da un livello di misurazione ad uno più alto aumenta il numero di operazioni aritmetiche che possono essere compiute sui valori della scala.\n\n3.4.1 Variabili Discrete e Continue\nLe variabili possono essere classificate come variabili a livello di intervalli o di rapporti e possono essere sia discrete che continue.\n\nVariabili discrete: Assumono valori specifici ma non possono assumere valori intermedi.\nVariabili continue: Possono assumere qualsiasi valore all’interno di un intervallo specificato.\n\n\n\n\nVariabili discrete e continue.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_measurement.html#interazione-tra-teoria-sostanziale-e-misurazione-nella-ricerca-scientifica",
    "href": "chapters/key_notions/03_measurement.html#interazione-tra-teoria-sostanziale-e-misurazione-nella-ricerca-scientifica",
    "title": "3  La misurazione in psicologia",
    "section": "3.5 Interazione tra Teoria Sostanziale e Misurazione nella Ricerca Scientifica",
    "text": "3.5 Interazione tra Teoria Sostanziale e Misurazione nella Ricerca Scientifica\n\n3.5.1 Un caso studio sul mind-body healing\nUn esempio di lettura critica della letteratura scientifica è offerto dall’analisi di uno studio sul mind-body healing pubblicato su Nature Aungle & Langer (2023). La ricerca riporta miglioramenti nella salute fisica associati a pratiche mente-corpo, ma è stata oggetto di severe critiche metodologiche da parte del statistico Andrew Gelman sul blog Statistical Modeling. Questo caso rivela due aspetti fondamentali spesso trascurati: il ruolo della teoria sostanziale e i criteri di misurazione rigorosa.\n\n\n3.5.2 La Teoria Sostanziale come Fondamento\nGelman evidenzia un deficit epistemologico centrale: l’assenza di un framework teorico convincente che spieghi i meccanismi causali ipotizzati. Senza una teoria che:\n\nDefinisca in modo univoco i costrutti (es.: “guarigione mente-corpo”)\n\nIdentifichi pathways biologici o psicologici plausibili\n\nSi integri con conoscenze consolidate (es.: neuroscienze, immunologia),\n\ni risultati empirici perdono significato scientifico, rischiando di degenerare in quella che Gelman definisce “junk science”. Una teoria solida non è solo un optional descrittivo, ma una precondizione per:\n\nFormulare ipotesi verificabili\n\nInterpretare correlazioni in termini causali\n\nEvitare inferenze speculative o tautologiche.\n\n\n\n3.5.3 Criticità nella Misurazione\nLo studio presenta inoltre problemi operazionali rilevanti:\n\n3.5.3.1 A. Validità degli strumenti\n\nLa misurazione delle pratiche mente-corpo non controlla adeguatamente:\n\nFattori confondenti (aspettative dei partecipanti, effetto placebo)\n\nBias di autovalutazione\n\n\nGli outcome clinici utilizzano scale non validate, compromettendo la comparabilità dei risultati.\n\n\n\n3.5.3.2 Questioni di validità\n\nInterna: L’assenza di blinding e randomizzazione rigorosa mina l’attribuzione causale.\n\nEsterna: Campioni non rappresentativi limitano la generalizzabilità (per approfondimenti, si veda Capitolo 34).\n\nCome discusso nella letteratura metodologica (Accuracy and Precision), la qualità delle misurazioni determina direttamente l’affidabilità delle conclusioni. Misure distorte o imprecise generano un “rumore” statistico che oscura eventuali segnali reali.\n\n\n\n3.5.4 Verso una Valutazione Integrata\nLa lettura critica di questo articolo mostra come la critica scientifica deve simultaneamente considerare due piani:\n\n\n\n\n\n\n\nDimensione\nRischi di Negligenza\n\n\n\n\nTeorica\nInterpretazioni ad hoc, ipotesi non falsificabili\n\n\nOperativa\nArtefatti metodologici, misurazioni inadeguate, conclusioni spurie\n\n\n\nUna ricerca rigorosa richiede un circolo ermeneutico tra teoria e dati: le misurazioni devono testare ipotesi derivate da framework teorici, mentre i risultati empirici devono raffinare le teorie stesse. Senza questo dialogo, si cade nel dualismo sterile tra:\n\nEmpirismo naïve (raccolta dati acritica)\n\nTeorizzazione dogmatica (slegata dall’evidenza).\n\nIn sintesi, la lettura critica di articoli scientifici esige:\n\ncompetenza transdisciplinare (statistica, epistemologia, conoscenze del dominio),\nconsapevolezza sui limiti della misurazione di costrutti.\n\nCome illustrato nell’analisi di Gelman, solo integrando valutazioni teoriche e metodologiche è possibile distinguere scienza robusta da pseudoscienza. Questo approccio non è meramente “difensivo”, ma costituisce il motore stesso del progresso scientifico, come approfondito nelle riflessioni su validità interna/esterna.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_measurement.html#riflessioni-conclusive",
    "href": "chapters/key_notions/03_measurement.html#riflessioni-conclusive",
    "title": "3  La misurazione in psicologia",
    "section": "3.6 Riflessioni Conclusive",
    "text": "3.6 Riflessioni Conclusive\nLa misurazione in psicologia non è un semplice atto di raccolta di dati, ma un processo fondamentale per garantire che le osservazioni empiriche siano interpretabili alla luce di modelli teorici solidi. Una buona misurazione non si limita a ridurre l’errore, ma consente di attribuire un significato coerente ai punteggi ottenuti, facilitando così il progresso della conoscenza scientifica. Senza strumenti adeguati per la misurazione, il rischio è quello di costruire teorie su basi incerte, compromettendo la validità delle conclusioni tratte.\nDue pilastri sostengono dunque una ricerca psicologica rigorosa: la teoria e la misurazione. La teoria fornisce il quadro concettuale entro cui si interpretano i dati, definendo le ipotesi e orientando le analisi. La misurazione, invece, è il ponte tra i costrutti astratti e le osservazioni empiriche, traducendo concetti complessi in variabili operative affidabili. Nessuna delle due componenti può reggersi senza l’altra: una teoria senza misurazione adeguata rischia di rimanere speculativa, mentre una misurazione priva di un solido fondamento teorico può portare a dati privi di significato.\nNella valutazione di un qualsiasi studio psicologico, un approccio critico richiede quindi di esaminare sia la solidità del quadro teorico sia la qualità degli strumenti di misurazione adottati. Il progresso della ricerca dipende dalla capacità di integrare questi due elementi, attraverso metodologie che riducano l’incertezza e migliorino la precisione delle inferenze. Le moderne tecniche di analisi dei dati, i modelli psicometrici avanzati e le tecnologie digitali stanno ampliando le possibilità di misurazione, offrendo strumenti più sensibili e adattabili alla complessità dei fenomeni psicologici. Tuttavia, la sfida principale rimane la stessa: garantire che la misurazione sia non solo accurata, ma anche teoricamente fondata, affinché le conoscenze acquisite possano davvero contribuire alla comprensione della mente e del comportamento umano.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_measurement.html#esercizi",
    "href": "chapters/key_notions/03_measurement.html#esercizi",
    "title": "3  La misurazione in psicologia",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nEsercizio 1: Identificazione del Livello di Misurazione\nObiettivo: Comprendere i diversi livelli di misurazione applicati alla psicologia.\n\nIdentifica il livello di misurazione (nominale, ordinale, intervalli, rapporti) per ciascuna delle seguenti variabili psicologiche:\n\n\nTipo di terapia psicologica (Cognitivo-comportamentale, Psicodinamica, Umanistica)\n\n\nLivello di ansia auto-riferito su una scala da 1 a 10\n\n\nNumero di episodi depressivi in un anno\n\n\nTempo di reazione in millisecondi in un test cognitivo\n\n\n\nEsercizio 2: Confronto tra Scale\nObiettivo: Comprendere le differenze tra le scale di misurazione.\n\nSpiega la differenza tra una scala ordinale e una scala a intervalli utilizzando l’esempio della soddisfazione lavorativa.\nPerché il punteggio QI è misurato su una scala a intervalli e non su una scala a rapporti?\nIn che modo il punteggio di una scala di autostima su una scala Likert differisce da una misurazione su una scala di rapporti?\n\nEsercizio 3: Operazioni Aritmetiche Consentite\nObiettivo: Comprendere le operazioni matematiche consentite per ciascun livello di misurazione.\n\nQuali operazioni aritmetiche sono ammissibili per una scala nominale?\nPuò avere senso calcolare la media di punteggi su una scala ordinale? Perché?\nSe hai misurato il tempo di reazione in secondi, quali operazioni aritmetiche puoi eseguire?\n\nEsercizio 4: Trasformazioni Ammissibili\nObiettivo: Comprendere le trasformazioni possibili per ogni scala di misurazione.\n\nSe una variabile è misurata su una scala nominale, quale tipo di trasformazione è consentita?\nPer una scala a intervalli, quali trasformazioni matematiche sono permesse senza alterare le proprietà della scala?\nQuale tipo di trasformazione è consentita su una scala di rapporti?\n\nEsercizio 5: Applicazione delle Scale a Dati Psicologici\nObiettivo: Applicare i concetti a contesti psicologici reali.\n\nUna scala di ansia clinica fornisce punteggi compresi tra 0 e 100. Quale livello di misurazione è più appropriato e perché?\nUn esperimento misura la memoria dichiarativa chiedendo ai partecipanti di ricordare un elenco di parole. Come dovrebbe essere misurata la variabile “numero di parole ricordate”?\nIn uno studio sulla personalità, i tratti vengono classificati come “estroverso” e “introverso”. Qual è il livello di misurazione?\n\nEsercizio 6: Valutazione della Scala di Misurazione\nObiettivo: Identificare la corretta scala di misurazione per vari fenomeni psicologici.\n\nIl livello di aggressività misurato su una scala da 1 a 5 è nominale, ordinale, intervalli o rapporti? Giustifica la tua risposta.\nIl numero di attacchi di panico in una settimana può essere considerato su scala ordinale? Perché sì o perché no?\nUn test di intelligenza misura il QI con una media di 100 e una deviazione standard di 15. Qual è il livello di misurazione e quali sono le implicazioni per l’analisi statistica?\n\nEsercizio 7: Costruzione di una Scala Psicologica\nObiettivo: Creare una scala di misurazione per una variabile psicologica.\n\nSe dovessi costruire una scala per misurare la resilienza, quale livello di misurazione sceglieresti e perché?\nCome potresti trasformare una scala nominale di preferenza musicale in una scala ordinale?\nUn questionario sulla qualità della vita chiede ai partecipanti di valutare la loro felicità su una scala da 1 a 10. È una scala a intervalli o ordinale? Giustifica.\n\nEsercizio 8: Interpretazione Statistica dei Dati\nObiettivo: Collegare il livello di misurazione alle tecniche statistiche appropriate.\n\nPerché una mediana è più appropriata della media per dati ordinali?\nQuale test statistico sarebbe più adatto per confrontare due gruppi su una variabile nominale?\nQuali analisi possono essere condotte su dati raccolti su una scala a rapporti?\n\nEsercizio 9: Misurazione e Inferenze Psicologiche\nObiettivo: Riflettere su come il livello di misurazione influisce sulle conclusioni di una ricerca.\n\nSe un test di personalità usa una scala Likert da 1 a 7, quali precauzioni devono essere prese nell’interpretare le differenze tra punteggi?\nUn questionario di benessere assegna punteggi tra 0 e 100, ma non ha uno zero assoluto. Quale scala è questa e quali sono le limitazioni?\nIn uno studio sulla depressione, i sintomi vengono codificati come “assenti”, “moderati” o “gravi”. Che tipo di scala è questa e quali statistiche possono essere usate per analizzarla?\n\nEsercizio 10: Esperimenti Psicologici e Misurazione\nObiettivo: Applicare la teoria della misurazione nella progettazione di esperimenti psicologici.\n\nSe un esperimento misura la memoria a breve termine con un compito di richiamo di parole, quale scala di misurazione utilizzeresti?\nCome la scelta della scala di misurazione può influenzare le inferenze che si possono trarre da un esperimento?\nQuali tipi di analisi statistica sono appropriati per dati misurati su scala ordinale rispetto a scala di rapporti?\n\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\nEsercizio 1: Identificazione del Livello di Misurazione\nObiettivo: Comprendere i diversi livelli di misurazione applicati alla psicologia.\n\nIdentifica il livello di misurazione (nominale, ordinale, intervalli, rapporti) per ciascuna delle seguenti variabili psicologiche:\n\n\nNominale (Tipo di terapia psicologica è una classificazione senza ordine)\n\n\nOrdinale (Scala da 1 a 10, con ordine ma senza distanze uguali)\n\n\nRapporti (Numero di episodi depressivi ha uno zero assoluto e si possono fare rapporti tra valori)\n\n\nRapporti (Tempo di reazione ha uno zero assoluto e permette operazioni di rapporto)\n\n\n\nEsercizio 2: Confronto tra Scale\nObiettivo: Comprendere le differenze tra le scale di misurazione.\n\nLa scala ordinale fornisce un ordine ma non permette di calcolare differenze precise, mentre la scala a intervalli ha differenze costanti tra i valori. Ad esempio, “soddisfazione lavorativa” su una scala da 1 a 5 è ordinale, mentre il punteggio di un test psicologico è a intervalli.\nIl punteggio QI è a intervalli perché la differenza tra punteggi è significativa, ma non ha uno zero assoluto che rappresenta l’assenza di intelligenza.\nUna scala Likert misura il livello di accordo con una dichiarazione, quindi è generalmente considerata ordinale, nonostante sia trattata spesso come una scala a intervalli.\n\nEsercizio 3: Operazioni Aritmetiche Consentite\nObiettivo: Comprendere le operazioni matematiche consentite per ciascun livello di misurazione.\n\nNella scala nominale si può solo contare la frequenza delle categorie (ad es., il numero di partecipanti che usano un tipo di terapia).\nNo, la media su dati ordinali può essere fuorviante perché le distanze tra le categorie non sono necessariamente uguali. Meglio usare la mediana.\nSul tempo di reazione si possono eseguire tutte le operazioni aritmetiche, inclusa la media, la moltiplicazione e i rapporti tra valori.\n\nEsercizio 4: Trasformazioni Ammissibili\nObiettivo: Comprendere le trasformazioni possibili per ogni scala di misurazione.\n\nSulla scala nominale, solo le trasformazioni di ricodifica (ad esempio, cambiare i nomi delle categorie) sono permesse.\nPer una scala a intervalli, si possono effettuare trasformazioni lineari della forma y’ = a + by con b &gt; 0.\nPer una scala di rapporti, sono consentite trasformazioni di similarità della forma y’ = by, dove b &gt; 0.\n\nEsercizio 5: Applicazione delle Scale a Dati Psicologici\nObiettivo: Applicare i concetti a contesti psicologici reali.\n\nScala a intervalli, perché ha differenze costanti tra i punteggi ma nessuno zero assoluto.\nScala di rapporti, perché il numero di parole ricordate ha uno zero assoluto e consente operazioni di rapporto.\nNominale, perché non vi è un ordine gerarchico tra le categorie “estroverso” e “introverso”.\n\nEsercizio 6: Valutazione della Scala di Misurazione\nObiettivo: Identificare la corretta scala di misurazione per vari fenomeni psicologici.\n\nOrdinale, perché il livello di aggressività segue un ordine, ma le differenze tra i livelli non sono necessariamente uguali.\nNo, perché il numero di attacchi di panico è una variabile discreta e misurabile su scala di rapporti.\nIntervalli, perché il punteggio QI ha distanze costanti tra i valori, ma non ha uno zero assoluto.\n\nEsercizio 7: Costruzione di una Scala Psicologica\nObiettivo: Creare una scala di misurazione per una variabile psicologica.\n\nOrdinale o a intervalli, a seconda della precisione della misurazione della resilienza.\nSi potrebbe assegnare un valore numerico crescente alle categorie di preferenza musicale per ottenere una scala ordinale.\nÈ una scala ordinale, perché la differenza tra livelli non è necessariamente costante.\n\nEsercizio 8: Interpretazione Statistica dei Dati\nObiettivo: Collegare il livello di misurazione alle tecniche statistiche appropriate.\n\nPerché la mediana è meno sensibile ai valori estremi rispetto alla media.\nUn test chi-quadrato è adatto per confrontare frequenze di dati nominali tra gruppi.\nSi possono calcolare media, deviazione standard e utilizzare test parametrici come t-test o ANOVA.\n\nEsercizio 9: Misurazione e Inferenze Psicologiche\nObiettivo: Riflettere su come il livello di misurazione influisce sulle conclusioni di una ricerca.\n\nI punteggi Likert sono ordinali, quindi confronti tra differenze di punteggio devono essere interpretati con cautela.\nIntervalli, perché non ha uno zero assoluto, il che limita l’uso di operazioni moltiplicative.\nOrdinale, e si possono usare test non parametrici come il test di Kruskal-Wallis o il test di Mann-Whitney.\n\nEsercizio 10: Esperimenti Psicologici e Misurazione\nObiettivo: Applicare la teoria della misurazione nella progettazione di esperimenti psicologici.\n\nRapporti, perché il numero di parole ricordate è una variabile discreta con uno zero assoluto.\nSe si usa una scala ordinale, bisogna essere cauti nell’uso della media e della deviazione standard.\nScala ordinale → test non parametrici (Mann-Whitney); scala di rapporti → test parametrici (t-test, ANOVA).\n\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nEsercizio 1 – Teoria Sostanziale e “Junk Science”\nObiettivo: Riconoscere il ruolo di una teoria sostanziale solida e comprendere come la sua assenza possa compromettere uno studio.\n\nLeggi la sezione in cui Gelman critica l’assenza di una teoria solida nello studio sulle pratiche mente-corpo.\n\nSpiega, in massimo 10 righe, perché secondo Gelman la mancanza di una teoria coerente rende i risultati del suddetto studio “poco significativi” o addirittura “junk science”.\n\nProponi un esempio ipotetico (non correlato al mind-body healing) di uno studio psicologico che, pur presentando dati numerosi e analizzati con metodi statistici sofisticati, risulti privo di una teoria solida. Descrivi sinteticamente perché questo potrebbe rientrare nel concetto di “junk science”.\n\nEsercizio 2 – Problemi di Misurazione\nObiettivo: Identificare le criticità più comuni nella misurazione dei fenomeni psicologici.\n\nElenca almeno tre possibili fattori confondenti che potrebbero influenzare la misurazione dell’efficacia di un intervento psicologico (ad esempio, l’effetto placebo, le aspettative dei partecipanti, ecc.).\n\nSpiega come questi fattori confondenti potrebbero compromettere la validità interna dello studio.\n\nIndica almeno due caratteristiche fondamentali che una buona scala di misurazione (per una variabile psicologica) dovrebbe possedere per essere ritenuta affidabile e valida.\n\nEsercizio 3 – Precisione e Bias\nObiettivo: Chiarire la distinzione tra precisione e distorsione (bias) e come questi aspetti si riflettano nella validità delle conclusioni.\n\nDefinisci, con parole tue, i concetti di precisione e bias in ambito psicometrico.\nFornisci un esempio concreto di uno strumento di misura preciso ma distorto (bias elevato) e di uno strumento poco preciso ma non distorto (bias basso).\n\nSpiega come la combinazione di scarsa precisione e alto bias possa influire sulla possibilità di trarre conclusioni affidabili in uno studio psicologico.\n\nEsercizio 4 – Validità Interna ed Esterna\nObiettivo: Approfondire come le scelte di misurazione influiscano sulla validità interna ed esterna di uno studio.\n\nIn riferimento allo studio sul mind-body healing discusso nel capitolo, identifica due fattori che potrebbero compromettere la validità interna e due fattori che potrebbero limitarne la validità esterna.\n\nDescrivi in 5-8 righe le differenze principali tra validità interna e validità esterna, utilizzando esempi presi sia dal contesto della guarigione mente-corpo sia da altri contesti psicologici (ad esempio, studi sull’apprendimento o sulla motivazione).\n\nProponi una modifica al disegno di ricerca (ipotetico) che potrebbe migliorare la validità interna dello studio originale. Spiega brevemente come questa modifica ne influenzerebbe anche la validità esterna.\n\nEsercizio 5 – Integrare Teoria e Misurazione: Breve Progetto di Ricerca\nObiettivo: Mettere in pratica i concetti di teoria e misurazione attraverso la progettazione di uno studio.\n\nImmagina di voler condurre uno studio su un intervento di “training di rilassamento mentale” finalizzato a ridurre l’ansia negli studenti universitari.\n\nSviluppa una breve traccia di progetto (massimo 15 righe) rispondendo ai seguenti punti:\n\nTeoria di base: Qual è la teoria sostanziale dietro l’efficacia del training di rilassamento? Quali meccanismi psicologici verrebbero attivati?\n\nIpotesi: Quale effetto prevedi sull’ansia degli studenti?\n\nMisurazione: Che tipo di strumento useresti per valutare il livello di ansia e perché (ad esempio, questionari self-report validati, misure fisiologiche come battito cardiaco, ecc.)?\n\nControllo dei confondenti: Quali variabili secondarie possono influire sui risultati e come intendi gestirle?\n\nValidità: Come assicureresti una buona validità interna? Che strategie adotteresti per aumentare la validità esterna?\n\nSpiega brevemente in che modo la combinazione di un solido quadro teorico e di una misurazione accurata permette di evitare che lo studio venga etichettato come “junk science”.\n\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\nEsercizio 1 – Teoria Sostanziale e “Junk Science”\n\nPerché la mancanza di una teoria solida rende i risultati poco significativi?\n\n\nGelman critica lo studio sul mind-body healing perché non vi è un modello teorico convincente che spieghi il meccanismo causale tra pratiche mente-corpo e miglioramenti di salute.\n\nSenza un quadro teorico robusto, i risultati sono interpretati in modo esplorativo e rischiano di essere attribuiti a variabili non controllate (effetto placebo, regressione alla media, ecc.).\n\nUna teoria ben formulata aiuta a delimitare le ipotesi, guidare il disegno di ricerca e interpretare correttamente i dati. In assenza di ciò, i numeri raccolti potrebbero essere viziati da fattori confondenti o da semplici correlazioni spurious.\n\n\n“Junk science” in massimo 10 righe\n\n\nEsempio di testo in 10 righe (circa)\n**Lo studio sul mind-body healing viene talvolta definito “junk science” da Gelman perché, in mancanza di una teoria sostanziale solida, i dati raccolti non forniscono indicazioni chiare sui processi psicologici o fisiologici coinvolti. Una ricerca classificata come “junk science” è priva di rigore metodologico o teorico, e può presentare gravi problemi di replicabilità o di interpretazione dei risultati. In particolare, se non vi è un modello plausibile che colleghi in modo coerente la pratica mente-corpo ai cambiamenti in variabili biologiche e comportamentali, i risultati empirici rischiano di essere semplici coincidenze. L’assenza di un costrutto ben definito e di ipotesi derivanti da una teoria coerente rende difficile capire se i cambiamenti osservati siano reali, casuali o dovuti ad altre cause non considerate (per esempio, l’effetto placebo). Infine, senza un’adeguata cornice teorica, gli studiosi non sanno come interpretare o generalizzare i dati, e la scienza non progredisce realmente.*\n\n\nEsempio di uno studio privo di teoria solida (ipotesi di “junk science”)\n\n\nSituazione ipotetica: Uno studio che raccoglie decine di variabili sulla personalità e sul benessere, poi usa tecniche statistiche sofisticate (analisi di big data, reti neurali, ecc.) per trovare correlazioni fra i tratti di personalità e centinaia di indicatori fisici.\nPerché “junk science”: Se lo studio non definisce a priori quali ipotesi testare e non ha una teoria chiara che spieghi perché certe caratteristiche di personalità dovrebbero correlarsi con determinati parametri fisici, i risultati trovati potrebbero essere frutto di coincidenze casuali. Inoltre, in assenza di un modello teorico solido, anche risultati statisticamente significativi possono essere privi di significato dal punto di vista psicologico.\n\nEsercizio 2 – Problemi di Misurazione\n\nTre possibili fattori confondenti nell’efficacia di un intervento psicologico\n\n\nEffetto placebo: I partecipanti migliorano perché si aspettano di migliorare, non per l’effettiva efficacia dell’intervento.\n\nAspettative dei partecipanti: Se sanno di partecipare a uno studio, potrebbero modificare il proprio comportamento (effetto Hawthorne).\n\nDesiderabilità sociale: I partecipanti forniscono risposte che ritengono socialmente desiderabili, falsando i risultati (ad esempio, sottostimando i livelli di ansia o stress).\n\n\nCome questi fattori confondenti compromettono la validità interna\n\n\nLa validità interna riguarda il grado in cui è possibile concludere che sia effettivamente la variabile indipendente (l’intervento) a causare le modifiche osservate nella variabile dipendente (es. livelli di ansia).\n\nSe subentrano l’effetto placebo, aspettative non controllate o tendenze alla desiderabilità sociale, diventa difficile stabilire un nesso causale chiaro. Esiste sempre il dubbio che altri processi cognitivi o sociali (non l’intervento in sé) abbiano prodotto il risultato.\n\n\nDue caratteristiche fondamentali di una buona scala di misurazione\n\n\nAffidabilità: Capacità dello strumento di fornire misure stabili e coerenti nel tempo (ad esempio, coerenza interna, stabilità test-retest).\n\nValidità: Capacità dello strumento di misurare effettivamente ciò che si propone di misurare (validità di contenuto, di costrutto, di criterio).\n\nEsercizio 3 – Precisione e Bias\n\nDefinizioni di precisione e bias\n\n\nPrecisione: Indica il grado di dispersione (o variabilità) delle misurazioni. Uno strumento preciso produce misure molto simili fra loro se ripetute nelle stesse condizioni (bassa varianza).\n\nBias (distorsione): Indica l’errore sistematico, ossia la tendenza a sovra- o sottostimare sistematicamente il fenomeno in esame. Uno strumento può essere molto coerente nelle misure, ma se è “tarato” male, darà sempre un risultato distorto.\n\n\nEsempio concreto di misura “precisa ma distorta” e “poco precisa ma non distorta”\n\n\nPrecisa ma distorta: Un cronometro che, a causa di un difetto di fabbricazione, parte sempre con 2 secondi di ritardo ma poi misura i tempi con estrema coerenza. Risultato: tutte le misure saranno molto simili (alta precisione), ma sempre sfasate di 2 secondi (alto bias).\n\nPoco precisa ma non distorta: Un termometro vecchio che a volte segna 36,2°C, altre 36,7°C, altre 37,1°C, senza un pattern sistematico. In media potrebbe risultare vicino ai 36,5°C, quindi senza un bias chiaro, ma con un’alta variabilità tra una misurazione e l’altra (bassa precisione).\n\n\nConseguenze di scarsa precisione e alto bias\n\n\nSe uno strumento è poco preciso (alta variabilità) e altamente distorto (bias elevato), i risultati ottenuti non solo oscillano in modo imprevedibile, ma sono costantemente lontani dal valore “vero”.\n\nIn queste condizioni, le conclusioni diventano inaffidabili, poiché è quasi impossibile distinguere l’effetto reale (casuale o causale) dalle deformazioni introdotte dallo strumento e dall’errore di misura.\n\nEsercizio 4 – Validità Interna ed Esterna\n\nDue fattori che compromettono la validità interna e due fattori che compromettono la validità esterna (nell’esempio del mind-body healing)\n\n\nValidità interna:\n\nAssegnazione non casuale ai gruppi: se i partecipanti scelgono autonomamente di aderire alle pratiche mente-corpo, potrebbero essere più motivati o avere caratteristiche iniziali diverse.\n\nMancata o inadeguata gestione dell’effetto placebo: non sapere se l’intervento “mente-corpo” sia stato percepito come particolarmente “speciale” dai partecipanti può introdurre differenze di aspettativa.\n\nValidità esterna:\n\nCampione non rappresentativo: se lo studio è condotto solo su persone che frequentano un determinato tipo di centro di benessere, i risultati potrebbero non essere generalizzabili all’intera popolazione.\n\nContesto specifico: pratiche mente-corpo svolte in un ambiente estremamente controllato (es. un laboratorio o un ritiro speciale) potrebbero non replicarsi nella vita quotidiana di chiunque.\n\n\n\nDifferenze tra validità interna ed esterna (5-8 righe di esempio)\n\n\nLa validità interna si riferisce alla correttezza del disegno di ricerca nel dimostrare un effetto causale. Un alto livello di validità interna implica che i ricercatori siano ragionevolmente sicuri che l’intervento (ad esempio, una tecnica mente-corpo) abbia causato i risultati osservati (miglioramento della salute). La validità esterna, invece, riguarda la possibilità di generalizzare i risultati a contesti, persone e tempi differenti. Se un intervento è stato testato in condizioni molto specifiche, potrebbe funzionare bene solo in quel contesto e con quel particolare campione. Per esempio, un intervento sul mind-body healing con individui altamente motivati potrebbe non dare gli stessi risultati in una popolazione generalizzata. Allo stesso modo, uno studio sull’apprendimento condotto in un laboratorio altamente controllato potrebbe non riflettere le reali dinamiche di un’aula scolastica.\n\n\nModifica al disegno di ricerca per migliorare la validità interna e conseguenze sulla validità esterna\n\n\nProposta: Introdurre un gruppo di controllo con un intervento placebo o un’attività simile ma priva di contenuto “mente-corpo” (ad es. sessioni di lettura rilassante). In questo modo, si può confrontare l’effetto “specífico” dell’intervento.\nCome influenza la validità interna: Con un gruppo di controllo placebo, diventa più semplice escludere che il miglioramento sia dovuto solo alle aspettative dei partecipanti. Questo riduce il rischio di confondenti e aumenta la validità interna.\nCome influenza la validità esterna: Potrebbe rendere il contesto dello studio più artificiale (un gruppo fa “meditazione”, l’altro legge in silenzio), il che potrebbe ridurre la naturalezza della situazione e potenzialmente limitare la generalizzabilità ad ambienti reali (validità esterna).\n\nEsercizio 5 – Integrare Teoria e Misurazione: Breve Progetto di Ricerca\n\nBreve traccia di progetto: “Training di rilassamento mentale per ridurre l’ansia negli studenti universitari”\n\n\nTeoria di base\nIl training di rilassamento mentale si fonda sul presupposto teorico che le tecniche di riduzione dello stress (es. respirazione consapevole, rilassamento muscolare progressivo) possano agire sui livelli di attivazione fisiologica e sui pensieri intrusivi. Riducendo l’iperattivazione del sistema nervoso simpatico e favorendo uno stato di calma, diminuisce l’ansia percepita.\nIpotesi\nGli studenti che seguono il training di rilassamento per 4 settimane mostreranno una riduzione significativa nei punteggi di ansia, rispetto a un gruppo di controllo che non partecipa al training.\nMisurazione\nUtilizzo di una scala validata come lo STAI (State-Trait Anxiety Inventory) per misurare il livello di ansia pre e post intervento. Possibile integrazione con misure fisiologiche (battito cardiaco a riposo) per avere dati oggettivi.\nControllo dei confondenti\n\nRegistrare la storia clinica dei partecipanti (per escludere coloro che assumono farmaci ansiolitici).\n\nRichiedere che i partecipanti non modifichino drasticamente le proprie abitudini di studio o di vita durante l’intervento.\n\nAssicurarsi che i valutatori non sappiano chi fa parte del gruppo di training o del gruppo di controllo (blinding parziale).\n\nValidità\n\nValidità interna: Uso di un gruppo di controllo e assegnazione casuale (randomizzazione) per assicurare che i due gruppi siano comparabili.\n\nValidità esterna: Inclusione di studenti provenienti da diverse facoltà, così da riflettere una maggiore eterogeneità di popolazione.\n\n\n\nCome teoria solida e misurazione accurata evitano la “junk science”\n\n\nUna solida cornice teorica spiega i meccanismi psicologici e fisiologici che legano l’intervento (training di rilassamento) all’esito (riduzione dell’ansia).\n\nUna misurazione accurata e validata (STAI, misure fisiologiche) riduce errori e distorsioni. Se le misure sono ripetute nel tempo (pre e post), si possono confrontare i cambiamenti effettivi.\n\nIntegrando teoria e misurazione, i risultati assumono un significato scientifico più robusto. Non basta osservare un miglioramento: occorre dimostrare come e perché tale miglioramento avvenga, evitando di cadere in semplici correlazioni prive di spiegazione (e quindi potenzialmente “junk science”).\n\n\n\n\n\n\n\n\n\n\nProblemi 3\n\n\n\n\n\nEsercizio 1 – Trasformazioni in Scala Nominale\nSituazione\nUn ricercatore vuole indagare la percezione di appartenenza sociale tra studenti universitari di Psicologia. A ciascuno studente viene chiesto di rispondere alla domanda: “Qual è il gruppo studentesco a cui ritieni di appartenere maggiormente?”, scegliendo una tra le seguenti categorie:\n\n\nGruppo A (focalizzato su ricerca e studio)\n\n\n\nGruppo B (focalizzato su attività ricreative)\n\n\n\nGruppo C (focalizzato su volontariato e progetti sociali)\n\n\nIstruzioni\n\nIdentifica la scala di misurazione utilizzata per classificare gli studenti (nominale, ordinale, a intervalli o di rapporti).\n\nIndica quali trasformazioni sono ammissibili su questa scala e spiega perché non è possibile applicare operazioni di tipo aritmetico (somme, differenze, etc.).\n\nProponi un esempio di nuova scala nominale equivalente, ossia una nuova denominazione delle categorie che rispetti la suddivisione originale. (Esempio: rinominarle in Gruppo X, Gruppo Y, Gruppo Z, oppure usare colori, animali-simbolo, ecc.). Spiega perché questa trasformazione non altera i risultati dell’indagine.\n\nEsercizio 2 – Trasformazioni in Scala Ordinale\nSituazione\nIn un questionario sul benessere psicologico, agli studenti viene chiesto di classificare il loro stato di motivazione allo studio su una scala da 1 (bassa motivazione) a 5 (alta motivazione). Si ottiene così un dato ordinalmente misurato.\nIstruzioni\n\nSpiega perché tale variabile (“livello di motivazione”) rappresenta una scala ordinale. Quali proprietà la rendono diversa da una semplice scala nominale?\n\nDescrivi in che modo è possibile ridenominare i valori della scala (ad esempio, da [1,2,3,4,5] a [“Molto bassa”, “Bassa”, “Media”, “Alta”, “Molto alta”]) senza alterare il rapporto d’ordine tra le categorie.\n\nProponi un esempio di trasformazione non ammissibile: qual è un’operazione aritmetica che non avrebbe senso applicare su una scala ordinale e perché (ad esempio, calcolare “il doppio di motivazione”)?\n\nEsercizio 3 – Trasformazioni in Scala ad Intervalli\nSituazione\nUn gruppo di ricercatori in Psicometria vuole confrontare i punteggi di un test d’intelligenza (misurati secondo la scala tradizionale del QI, con media 100 e deviazione standard 15) con un nuovo test sperimentale. Come ben noto, la scala del QI è considerata, nelle sue approssimazioni psicometriche, una scala ad intervalli.\nIstruzioni\n\nSpiega in cosa consiste la trasformazione lineare ammessa (del tipo \\(y' = a + b y\\), con \\(b &gt; 0\\)) e perché tale trasformazione preserva le differenze tra i punteggi.\n\nFai un esempio concreto di trasformazione lineare: supponi di voler “riscalare” i punteggi del QI in modo che la nuova media sia 50. Definisci i valori di \\(a\\) e \\(b\\) (indicando un’ipotesi di calcolo) e mostra come viene modificato il punteggio di un individuo con QI = 115.\n\nDiscuta perché, nonostante la somiglianza con le scale ordinale e nominale (puoi comunque distinguere punteggi e ordinarli), una scala ad intervalli consente operazioni matematiche più complesse (ad esempio, differenze) che non sarebbero valide negli altri due livelli.\n\nEsercizio 4 – Trasformazioni in Scala di Rapporti\nSituazione\nUn laboratorio di psicofisiologia misura i tempi di reazione (in millisecondi) a uno stimolo luminoso. Poiché il tempo di reazione pari a 0 ms significa realmente assenza di risposta (ovvero, impossibile da misurare in pratica, ma concettualmente corrisponde a intensità nulla del fenomeno “tempo di reazione”), ci troviamo in una scala di rapporti.\nIstruzioni\n\nSpiega perché il tempo di reazione soddisfa i requisiti di una scala di rapporti, inclusa la presenza di uno zero assoluto e la possibilità di confrontare i punteggi con rapporti (ad esempio, “il tempo di reazione del partecipante A è il doppio di quello del partecipante B”).\n\nQuali sono le trasformazioni ammissibili su una scala di rapporti? Fornisci un esempio numerico (per esempio, se moltiplichi tutti i tempi di reazione per 2, che cosa accade al rapporto tra i punteggi di due partecipanti?).\n\nDescrivi il motivo per cui è possibile dire che A ha una latenza doppia di B usando i millisecondi, ma non è sempre possibile fare asserzioni analoghe usando scale ad intervalli. Fai un parallelo, ad esempio, con le temperature in Celsius.\n\nEsercizio 5 – Riconoscere e Applicare le Trasformazioni nei Quattro Livelli di Scala\nSituazione\nUn docente di Psicologia sperimentale ha raccolto quattro serie di dati su vari aspetti:\n\nOrientamento politico (liberale, conservatore, centrista, ecc.).\n\nClassifica di soddisfazione sul tirocinio (1° posto, 2° posto, 3° posto, etc.).\n\nPunteggi di un test di personalità su un fattore (con media = 100, deviazione standard = 10) trattato come scala ad intervalli.\n\nFrequenza cardiaca a riposo misurata in battiti al minuto (bpm).\n\nIstruzioni\n\nIdentifica per ciascuno dei quattro insiemi di dati il livello di scala (nominale, ordinale, intervalli, rapporti).\n\nPer ognuno dei quattro livelli di scala elenca almeno una trasformazione ammessa (ad es. ridenominazione delle categorie per la nominale, traslazione e dilatazione per l’intervalli, ecc.) e una non ammessa (esempio: non puoi sommare categorie nominali, non puoi calcolare la radice quadrata di un rango ordinale dandogli significato, ecc.).\n\nRifletti in breve (2-3 righe) su come queste differenze nelle trasformazioni ammissibili incidano sull’interpretazione dei dati e sulle analisi statistiche che il docente potrà validamente utilizzare (ad esempio, test non parametrici per variabili ordinarie, test parametrici per scale ad intervalli/rapporti).\n\n\n\n\n\n\n\n\n\n\nSoluzioni 3\n\n\n\n\n\nEsercizio 1 – Trasformazioni in Scala Nominale\n\nIdentificazione della scala La classificazione degli studenti in “Gruppo A/B/C” è scala nominale. Non esiste alcun ordine intrinseco tra le categorie; si tratta semplicemente di etichette qualitative.\nTrasformazioni ammissibili\n\n\nTrasformazioni ammissibili: ridenominare o rinominare le categorie senza modificare la partizione del campione (esempio: A → “Studio”, B → “Ricreazione”, C → “Volontariato”).\n\nL’unica operazione aritmetica consentita è il conteggio delle frequenze nelle varie categorie.\n\n\nOperazioni non consentite: non è possibile sommare o sottrarre etichette, né confrontare categorie in termini di “più/meno grande” o “rapporto”.\n\n\nEsempio di nuova scala nominale equivalente\n\n\nPotresti chiamare i gruppi: “Alpha, Beta, Gamma” (oppure con colori: “Rosso, Blu, Verde”).\n\nQuesta trasformazione non altera la classificazione in sé: tutti gli studenti del Gruppo A rimangono nel “nuovo” gruppo Alpha, e così via.\n\nNon cambia la struttura dei dati e di conseguenza non altera i risultati della ricerca (restano invariate le frequenze e la suddivisione nelle categorie).\n\nEsercizio 2 – Trasformazioni in Scala Ordinale\n\nPerché è una scala ordinale? La variabile “livello di motivazione” da 1 (bassa) a 5 (alta) indica:\n\n\nClassificazione in categorie (come in una scala nominale).\n\nRelazione d’ordine chiara (1 &lt; 2 &lt; 3 &lt; 4 &lt; 5).\n\nNon fornisce alcuna informazione sulle distanze reali tra i punti (non è detto che la differenza tra 1 e 2 sia uguale a quella tra 3 e 4).\nÈ quindi una scala ordinale e non semplicemente nominale.\n\n\nRidenominazione dei valori mantenendo l’ordine\n\n\nPuoi sostituire i numeri con etichette testuali rispettando lo stesso ordine:\n1 → “Molto bassa”\n2 → “Bassa”\n3 → “Media”\n4 → “Alta”\n5 → “Molto alta”\n\nL’ordine rimane lo stesso: “Molto bassa” &lt; “Bassa” &lt; … &lt; “Molto alta”.\n\n\nEsempio di trasformazione non ammissibile\n\n\nCalcolare “il doppio di motivazione”: dire che la categoria 4 è “il doppio” della categoria 2 non ha senso, perché non c’è un’unità di misura fissa che quantifichi la differenza tra i livelli. Le categorie ordinali servono solo a ordinare, non a quantificare in modo assoluto.\n\nEsercizio 3 – Trasformazioni in Scala ad Intervalli\n\nTrasformazione lineare ammessa\n\n\nForma generale: \\(y' = a + b y\\), con \\(b &gt; 0\\).\n\nPreserva le differenze tra i valori (ad esempio, \\((y_2 - y_1) = (y'_2 - y'_1) / b\\)), perché la traslazione aggiunge una costante a tutti i punteggi e la dilatazione (moltiplicazione per \\(b\\)) mantiene le proporzioni fra gli intervalli.\n\n\nEsempio concreto\n\n\nScala QI: media = 100, deviazione standard = 15.\n\nVuoi che la nuova media sia 50.\n\nPer semplificare, supponiamo di voler “spostare” ogni valore verso una nuova scala centrata a 50, mantenendo una deviazione standard proporzionale.\n\nUna possibile trasformazione lineare:\n\\[\n  y' = (y - 100) + 50 = y - 50.\n\\]\nIn questo caso, \\(a = -50\\), \\(b = 1\\).\n\nSe un individuo ha QI = 115, allora \\(y' = 115 - 50 = 65\\).\n\n\nSe invece volessi anche cambiare la deviazione standard, potresti usare un fattore \\(b \\neq 1\\). Ad esempio, se desideri una deviazione standard = 10, potresti usare \\(b = \\frac{10}{15} \\approx 0.67\\).\n\n\nDifferenze rispetto alle scale nominali/ordinali\n\n\nCon una scala ad intervalli puoi:\n\nOrdinare i punteggi.\n\nStabilire differenze (es. un individuo A ha 15 punti in più di B).\n\n\nNon puoi invece stabilire rapporti (es. “A ha il doppio di X rispetto a B” non è lecito), perché lo zero è arbitrario e la distanza “0” non rappresenta l’assenza del fenomeno (come invece avviene nella scala di rapporti).\n\nEsercizio 4 – Trasformazioni in Scala di Rapporti\n\nPerché il tempo di reazione è in una scala di rapporti?\n\n\nZero assoluto: un tempo di reazione (teoricamente) pari a 0 ms significherebbe nessun tempo trascorso → totale assenza del fenomeno misurato (impossibile nella pratica, ma concettualmente definisce uno zero non arbitrario).\n\nPuoi confrontare i punteggi con rapporti: “il tempo di reazione di A è il doppio di quello di B” (200 ms vs. 100 ms).\n\n\nTrasformazioni ammissibili\n\n\nTrasformazione di similarità: \\(y' = b y\\) con \\(b &gt; 0\\).\n\nSe hai due tempi di reazione \\(y_1\\) e \\(y_2\\), il rapporto \\(\\frac{y_1}{y_2}\\) rimane invariato anche dopo la trasformazione:\n\\[\n  \\frac{y'_1}{y'_2} = \\frac{b y_1}{b y_2} = \\frac{y_1}{y_2}.\n\\]\nEsempio numerico: se i tempi di reazione di due partecipanti sono 100 ms e 200 ms, il rapporto è 2. Se moltiplichi entrambi per 2, ottieni 200 ms e 400 ms, e il rapporto rimane 2.\n\n\nConfronto con scala ad intervalli (esempio delle temperature)\n\n\nIn una scala di rapporti puoi dire “A ha una latenza doppia di B” perché lo zero non è arbitrario.\n\nCon la temperatura (scala ad intervalli) lo zero (es. 0°C) non rappresenta l’assenza di calore, quindi non ha senso dire che 80°C è “il doppio” di 40°C. Cambiando la scala (ad es. Fahrenheit) il rapporto cambia.\n\nEsercizio 5 – Riconoscere e Applicare le Trasformazioni nei Quattro Livelli di Scala\n\nIdentificazione del livello di scala\n\n\nOrientamento politico: scala nominale (categorie qualitative prive di ordine).\n\nClassifica di soddisfazione (1°, 2°, 3°, …): scala ordinale (c’è un ordine, ma non si conosce la “distanza” fra i posti).\n\nPunteggi di un test di personalità (con media=100, dev.st=10), considerati approssimazione di una scala ad intervalli (si assumono le differenze significative, lo zero è arbitrario).\n\nFrequenza cardiaca a riposo (bpm): scala di rapporti (zero assoluto e rapporti confrontabili).\n\n\nTrasformazioni ammesse e non ammesse\n\n\nNominale:\n\nAmmessa: cambiare etichette (A → “Liberale”, B → “Conservatore” ecc.).\n\nNon ammessa: sommare categorie, ordinare, calcolare media delle categorie.\n\n\nOrdinale:\n\nAmmessa: rietichettare i ranghi (1° → “Migliore”, 2° → “Secondo posto”…).\n\nNon ammessa: calcolare rapporti (il 2° posto non è “il doppio” del 1°), sommare posizioni in modo significativo.\n\n\nA intervalli:\n\nAmmessa: trasformazione lineare (traslazione + dilatazione).\n\nNon ammessa: dire che un punteggio è “tre volte” un altro; lo zero è arbitrario.\n\n\nA rapporti:\n\nAmmessa: trasformazione di similarità (\\(y' = b y\\)), in cui i rapporti rimangono invariati.\n\nNon ammessa: aggiunta di una costante a tutti i valori (questa sposterebbe lo zero, rendendolo arbitrario e trasformando la scala in una scala ad intervalli).\n\n\n\nImplicazioni per l’interpretazione e le analisi\n\n\nUna variabile nominale consente solo frequenze e test non parametrici basati su conteggi (es. Chi-quadrato).\n\nUna variabile ordinale permette test di ordinamento (es. test di rank, come il Wilcoxon), ma non calcoli di media con significato forte.\n\nUna scala ad intervalli permette di usare statistiche parametriche (calcolo di media, varianza, test come t-test, ANOVA), assumendo che l’interpretazione delle differenze sia coerente.\n\nUna scala di rapporti permette, in più, il confronto di rapporti (ad esempio, si possono applicare modelli parametrici che includano il concetto di proporzioni o slope logico su dati che abbiano senso a zero assoluto).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_measurement.html#bibliografia",
    "href": "chapters/key_notions/03_measurement.html#bibliografia",
    "title": "3  La misurazione in psicologia",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAungle, P., & Langer, E. (2023). Physical healing as a function of perceived time. Scientific Reports, 13(1), 22432.\n\n\nDomini, F., & Caudek, C. (2009). The intrinsic constraint model and Fechnerian sensory scaling. Journal of Vision, 9(2), 25–25.\n\n\nLilienfeld, S. O., & Strother, A. N. (2020). Psychological measurement and the replication crisis: Four sacred cows. Canadian Psychology/Psychologie Canadienne, 61(4), 281–288.\n\n\nMaul, A., Irribarra, D. T., & Wilson, M. (2016). On the philosophical foundations of psychological measurement. Measurement, 79, 311–320.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_data_analysis.html",
    "href": "chapters/key_notions/04_data_analysis.html",
    "title": "4  La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana",
    "section": "",
    "text": "Introduzione\nNegli ultimi vent’anni, le scienze sociali e la psicologia hanno vissuto una profonda trasformazione metodologica ed epistemologica. Questo cambiamento, spesso definito come “Credibility Revolution” (Angrist & Pischke, 2010), “Causal Revolution” (Pearl & Mackenzie, 2018) e “Replication Crisis” (Collaboration, 2015; Nosek et al., 2022), ha portato a un ripensamento delle pratiche di ricerca, specialmente in psicologia (Korbmacher et al., 2023). Questa transizione verso quella che Munger (2023) chiama “Science versione 2” è stata motivata dalla consapevolezza di lacune metodologiche passate e ha spinto verso l’adozione di approcci più rigorosi e replicabili.\nLe origini di questa riforma risiedono nel riconoscimento di problemi metodologici diffusi, come la proliferazione di falsi positivi (Simmons et al., 2011), l’abuso dei “gradi di libertà dei ricercatori” (Gelman & Loken, 2013), e l’inadeguatezza delle pratiche statistiche tradizionali (Gelman & Loken, 2014). Fenomeni come il p-hacking, l’uso di campioni di piccole dimensioni (Button et al., 2013), e la mancanza di trasparenza nei metodi di ricerca hanno contribuito a minare la credibilità delle scoperte psicologiche (Ioannidis, 2005; Meehl, 1967), portando alla cosiddetta “Replication Crisis” (Baker, 2016; Bishop, 2019) — si veda il Capitolo 79.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_data_analysis.html#lapproccio-bayesiano",
    "href": "chapters/key_notions/04_data_analysis.html#lapproccio-bayesiano",
    "title": "4  La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana",
    "section": "4.1 L’Approccio Bayesiano",
    "text": "4.1 L’Approccio Bayesiano\nIn risposta a queste sfide, l’approccio bayesiano è emerso come un paradigma statistico chiave nella “Credibility Revolution”. A differenza dell’inferenza frequentista, che si basa sul Test dell’Ipotesi Nulla, la statistica bayesiana offre un framework più flessibile e intuitivo per l’analisi dei dati e l’inferenza causale. Il principio fondamentale dell’approccio bayesiano è l’aggiornamento delle distribuzioni di probabilità a priori (priors) alla luce di nuove evidenze, un processo che si allinea con l’obiettivo di una scienza cumulativa e auto-correttiva.\nL’adozione di metodi bayesiani in psicologia presenta numerosi vantaggi:\n\nQuantificazione dell’incertezza: L’inferenza bayesiana fornisce distribuzioni di probabilità posteriori complete per i parametri di interesse, offrendo una rappresentazione più ricca e sfumata dell’incertezza rispetto agli intervalli di confidenza frequentisti.\nIncorporazione di conoscenze pregresse: Le priors bayesiane permettono di integrare formalmente conoscenze precedenti nel processo inferenziale, promuovendo un approccio cumulativo alla ricerca.\nRobustezza alle pratiche di ricerca discutibili: I metodi bayesiani sono meno suscettibili a pratiche come il p-hacking, poiché l’inferenza si basa sull’intera distribuzione posteriore piuttosto che su soglie arbitrarie di significatività.\n\n\n4.1.1 Vantaggi e Applicazioni\nL’utilizzo delle statistiche bayesiane nella ricerca psicologica presenta notevoli vantaggi rispetto ai metodi statistici tradizionali, come i test di significatività basati sull’ipotesi nulla. Uno dei principali punti di forza risiede nella sua indipendenza dalla teoria dei grandi campioni, rendendolo particolarmente adatto a studi con dimensioni campionarie ridotte, una condizione frequente in psicologia (Larson et al., 2023).\n\n4.1.1.1 Sfide dei Campioni Piccoli in Psicologia\nLa ricerca psicologica spesso si confronta con campioni limitati a causa di:\n\nBassa prevalenza di condizioni specifiche (es. disturbi rari);\n\nDifficoltà nel reclutamento (es. popolazioni difficili da raggiungere);\n\nComplessità procedurali (es. valutazioni longitudinali o multimodali).\n\nQuesti campioni, oltre a essere numericamente ridotti, sono spesso caratterizzati da elevata eterogeneità, che si manifesta in:\n\nVariabilità fenotipica: Differenze comportamentali tra individui con la stessa condizione psicologica;\n\nDiscrepanza tra studi: Stime degli effetti divergenti in ricerche simili.\nTali fattori possono generare distorsioni nelle stime e risultati scarsamente riproducibili.\n\n\n\n4.1.1.2 Vantaggi dell’Approccio Bayesiano\n\nValutazione dell’Adeguatezza del Campione\n\nAttraverso l’analisi di sensibilità delle distribuzioni a priori, è possibile valutare quanto i risultati dipendano dalle assunzioni iniziali, identificando campioni troppo piccoli o ipotesi troppo influenti.\n\nPrecisione con Dati Limitati\n\nL’integrazione di conoscenze a priori ben definite (es. dati di studi precedenti) permette di ottenere stime robuste anche con piccoli campioni, compensando la carenza di dati attraverso informazioni esterne.\n\nInclusione Equa di Popolazioni Sottorappresentate\n\nL’approccio bayesiano riduce la necessità di campioni molto numerosi, evitando la pressione sul reclutamento di gruppi minoritari (es. minoranze etniche). Questo favorisce una ricerca più equa e rappresentativa, senza sacrificare la validità statistica.\n\n\n\n\n4.1.1.3 Impatto sulla Riproducibilità e Politiche di Ricerca\nIn sintesi, la capacità di gestire l’eterogeneità e di ottimizzare l’uso dei dati rende il metodo bayesiano uno strumento chiave per affrontare la crisi di riproducibilità in psicologia. Inoltre, promuove politiche inclusive, riducendo barriere etiche e pratiche legate al sovra-reclutamento di gruppi vulnerabili.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_data_analysis.html#modellazione-formale-e-data-science",
    "href": "chapters/key_notions/04_data_analysis.html#modellazione-formale-e-data-science",
    "title": "4  La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana",
    "section": "4.2 Modellazione Formale e Data Science",
    "text": "4.2 Modellazione Formale e Data Science\nLa “Credibility Revolution” ha favorito l’integrazione della Data Science nelle pratiche di ricerca psicologica. L’adozione di pipeline di analisi dei dati riproducibili, l’uso di controllo di versione e la condivisione di dati e codice sono diventati standard de facto nella comunità scientifica. Questi strumenti non solo migliorano la trasparenza e la replicabilità della ricerca, ma facilitano anche la collaborazione e l’accumulo di conoscenze nel campo.\nParallelamente, si è osservato un rinnovato interesse per la modellazione formale in psicologia, che consente non solo la verifica ma anche lo sviluppo di modelli dei meccanismi sottostanti ai fenomeni psicologici (Oberauer & Lewandowsky, 2019; Van Dongen et al., 2024). Questo approccio supera la mera descrizione delle associazioni tra variabili, tipica della pratica dominante dell’ANOVA nel contesto pre-riforma.\nLa modellazione bayesiana si presta particolarmente bene a questo approccio, offrendo un framework unificato per la specificazione di modelli formali, l’incorporazione di incertezza parametrica e la valutazione dell’evidenza empirica. Attraverso tecniche come il confronto tra modelli bayesiano e l’analisi di sensibilità, i ricercatori possono valutare rigorosamente la plausibilità relativa di diverse teorie psicologiche.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_data_analysis.html#riflessioni-epistemologiche",
    "href": "chapters/key_notions/04_data_analysis.html#riflessioni-epistemologiche",
    "title": "4  La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana",
    "section": "4.3 Riflessioni Epistemologiche",
    "text": "4.3 Riflessioni Epistemologiche\nL’adozione di metodi bayesiani e della Data Science in psicologia deve essere accompagnata da una profonda riflessione epistemologica. Come sottolineato da George Box:\n\nTutti i modelli sono sbagliati, ma alcuni sono utili.\n\nQuesta massima risuona particolarmente nel contesto della ricerca psicologica, dove i fenomeni di interesse sono spesso complessi e multifattoriali.\nL’approccio bayesiano, con la sua enfasi sull’aggiornamento iterativo delle credenze alla luce di nuove evidenze, si allinea naturalmente con una visione della scienza come processo di apprendimento continuo piuttosto che come ricerca di verità assolute. Questa prospettiva riconosce i limiti intrinseci dei nostri modelli e delle nostre teorie, pur valorizzandone l’utilità euristica e predittiva.\nIn particolare, McElreath (2020) sottolinea l’importanza di riconoscere la dualità tra il “mondo del modello” e il mondo reale più ampio che cerchiamo di comprendere. Questa consapevolezza è cruciale per evitare la reificazione dei nostri modelli statistici e per mantenere una prospettiva critica sulle nostre inferenze.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_data_analysis.html#riflessioni-conclusive",
    "href": "chapters/key_notions/04_data_analysis.html#riflessioni-conclusive",
    "title": "4  La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana",
    "section": "4.4 Riflessioni Conclusive",
    "text": "4.4 Riflessioni Conclusive\nL’integrazione dell’approccio bayesiano e della Data Science nella ricerca psicologica rappresenta una risposta promettente alle sfide poste dalla “Replication Crisis”. Offrendo un framework coerente per la modellazione formale, l’inferenza statistica e l’incorporazione di conoscenze pregresse, questi approcci promettono di elevare il rigore e la credibilità della ricerca psicologica. Tuttavia, è fondamentale che l’adozione di questi metodi sia accompagnata da una adeguata consapevolezza metodologica ed epistemologica.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_data_analysis.html#esercizi",
    "href": "chapters/key_notions/04_data_analysis.html#esercizi",
    "title": "4  La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nQuali sono i principali fattori che hanno portato alla “Credibility Revolution” in psicologia e in che modo le nuove metodologie — in particolare l’approccio bayesiano e le buone pratiche di Data Science — mirano a superare i limiti che hanno contribuito alla “Replication Crisis”?\nIn che modo il paradigma bayesiano differisce dall’approccio frequentista nella gestione dell’incertezza e nell’aggiornamento della conoscenza, e quali vantaggi pratici offre quando si lavora con campioni di piccole dimensioni e popolazioni eterogenee?\nQual è il ruolo delle distribuzioni a priori nelle analisi bayesiane e come ci si assicura che l’uso di priors non introduca bias indesiderati, specialmente in un contesto come quello psicologico dove le teorie e i dati pregressi possono essere incompleti o controversi?\nPerché la modellazione formale e le buone pratiche di Data Science (ad es. condivisione di codice, controllo di versione, pipeline riproducibili) risultano fondamentali per una scienza cumulativa e per mitigare gli errori sistematici nella ricerca psicologica?\nDal punto di vista epistemologico, in che modo il principio “tutti i modelli sono sbagliati, ma alcuni sono utili” influenza la costruzione, la valutazione e l’interpretazione dei modelli in psicologia, e come si integra con la prospettiva bayesiana di scienza come processo iterativo di apprendimento?\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n1. Quali sono i principali fattori che hanno portato alla “Credibility Revolution” in psicologia e in che modo le nuove metodologie — in particolare l’approccio bayesiano e le buone pratiche di Data Science — mirano a superare i limiti che hanno contribuito alla “Replication Crisis”?\nNegli ultimi decenni, la psicologia ha attraversato una “Replication Crisis” a causa di diverse pratiche di ricerca problematiche, tra cui l’utilizzo di campioni di piccole dimensioni, l’uso eccessivo di test di significatività frequentisti con p &lt; .05 come soglia rigida, il fenomeno del p-hacking (cioè l’adattamento delle analisi per ottenere risultati “significativi”), e la carenza di trasparenza e condivisione dei dati. Questi fattori hanno portato alla pubblicazione di molti falsi positivi e a un’erosione della fiducia nelle conclusioni psicologiche.\nLa “Credibility Revolution” nasce dalla presa di coscienza di questi problemi e dall’introduzione di nuove metodologie che offrono maggior rigore e trasparenza. L’approccio bayesiano, in particolare, consente di superare alcuni limiti della statistica frequentista, poiché fornisce distribuzioni posteriori di plausibilità per i parametri e non si affida a soglie arbitrarie di significatività. Inoltre, la Data Science ha promosso la diffusione di pipeline analitiche riproducibili (tramite il controllo di versione, la condivisione del codice e dei dati), contribuendo a ridurre errori, bias e a favorire la replicabilità. Insieme, queste innovazioni mirano a creare una scienza più aperta, solida e cumulativa.\n2. In che modo il paradigma bayesiano differisce dall’approccio frequentista nella gestione dell’incertezza e nell’aggiornamento della conoscenza, e quali vantaggi pratici offre quando si lavora con campioni di piccole dimensioni e popolazioni eterogenee?\nIl paradigma frequentista si basa sull’idea di ripetizione ipotetica degli esperimenti e sull’applicazione di test di significatività, focalizzandosi su p-value e intervalli di confidenza che rispondono a domande “se si ripetesse infinite volte l’esperimento, in media cosa accadrebbe?”. L’inferenza bayesiana, al contrario, concepisce la probabilità come uno stato di conoscenza (o di credenza) e integra le informazioni precedenti (priors) con i dati osservati per produrre una distribuzione posteriore. Ciò consente un aggiornamento continuo e iterativo delle ipotesi alla luce delle nuove evidenze.\nQuesta impostazione risulta particolarmente utile quando i campioni sono ridotti e le popolazioni indagate sono eterogenee. In tali condizioni, il paradigma frequentista rischia di generare stime instabili o intervalli di confidenza molto ampi. L’approccio bayesiano, invece, permette di incorporare informazioni pregresse e di ottenere stime più precise, a patto che le priors siano giustificate e non eccessivamente informative. L’attenzione alla distribuzione posteriore rende inoltre più chiaro il grado di incertezza associato ai parametri di interesse e favorisce la formulazione di inferenze più calibrate.\n3. Qual è il ruolo delle distribuzioni a priori nelle analisi bayesiane e come ci si assicura che l’uso di priors non introduca bias indesiderati, specialmente in un contesto come quello psicologico dove le teorie e i dati pregressi possono essere incompleti o controversi?\nNell’approccio bayesiano, le distribuzioni a priori (priors) rappresentano la conoscenza o le ipotesi iniziali di cui si dispone sui parametri in esame prima di raccogliere i dati. Se ben specificate, contribuiscono a rendere l’analisi più informativa, soprattutto quando il campione è di piccole dimensioni. Tuttavia, un uso improprio delle priors può introdurre bias, poiché priors troppo “forti” (ossia eccessivamente vincolanti) possono spingere i risultati verso determinate conclusioni.\nPer evitare questi rischi, i ricercatori devono adottare priors ben motivate e trasparenti. In psicologia, dove le teorie possono essere ancora in fase di sviluppo e i dati pregressi non sempre affidabili, è spesso utile iniziare con priors non informative o debolmente informative, per ridurre il rischio di forzare troppo il modello. È anche fondamentale effettuare analisi di sensibilità: testare differenti specificazioni di priors per verificare se i risultati sono robusti oppure fortemente dipendenti da particolari assunzioni iniziali. La documentazione delle scelte fatte (e le relative ragioni) è parte integrante di una buona pratica di ricerca trasparente.\n4. Perché la modellazione formale e le buone pratiche di Data Science (ad es. condivisione di codice, controllo di versione, pipeline riproducibili) risultano fondamentali per una scienza cumulativa e per mitigare gli errori sistematici nella ricerca psicologica?\nLa modellazione formale consente di superare la mera descrizione delle relazioni tra variabili (tipica dell’ANOVA o dei modelli lineari tradizionali) e di entrare nel merito dei meccanismi sottostanti i fenomeni psicologici, costruendo teorie più articolate e fondate. Questa prospettiva rende più esplicite le assunzioni e le ipotesi su cui si basa la ricerca, permettendo un confronto chiaro tra diverse spiegazioni concorrenti.\nParallelamente, l’adozione di strumenti e pratiche di Data Science come la condivisione di codice (in repository pubblici), l’uso del controllo di versione (es. Git) e pipeline analitiche riproducibili riducono gli errori e favoriscono la verifica indipendente dei risultati. Ciò aumenta la trasparenza, poiché altri ricercatori possono ispezionare i passaggi compiuti, e consente la replicazione degli studi. In una scienza cumulativa, infatti, la possibilità di riprodurre, criticare e migliorare i risultati di lavori precedenti è essenziale per costruire un corpus di conoscenze solido e affidabile.\n5. Dal punto di vista epistemologico, in che modo il principio “tutti i modelli sono sbagliati, ma alcuni sono utili” influenza la costruzione, la valutazione e l’interpretazione dei modelli in psicologia, e come si integra con la prospettiva bayesiana di scienza come processo iterativo di apprendimento?\nLa celebre frase di George Box (“tutti i modelli sono sbagliati, ma alcuni sono utili”) evidenzia come i modelli statistici e teorici non possano mai rappresentare perfettamente la realtà, specialmente in un campo complesso come la psicologia, in cui le variabili spesso interagiscono in modo non lineare e multi-dimensionale. Ciò non significa che i modelli siano inutili; anzi, se ben costruiti, possono offrire uno strumento potente per interpretare e prevedere i fenomeni.\nNell’ottica bayesiana, la costruzione dei modelli è un processo iterativo in cui le ipotesi iniziali (priors) vengono continuamente aggiornate alla luce di nuove evidenze (la distribuzione posteriore). Questo ciclo di apprendimento riflette un’idea di scienza non come ricerca della “verità assoluta”, ma come progressivo affinamento delle teorie. Il principio di Box ricorda ai ricercatori che qualsiasi modello deve essere costantemente messo alla prova, confrontato con altri modelli, e aggiornato o abbandonato se i dati non lo supportano più. In questo senso, la prospettiva bayesiana favorisce una mentalità flessibile e aperta, pronta a rivedere i propri presupposti e a migliorare progressivamente la comprensione dei fenomeni psicologici.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_data_analysis.html#bibliografia",
    "href": "chapters/key_notions/04_data_analysis.html#bibliografia",
    "title": "4  La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAngrist, J. D., & Pischke, J.-S. (2010). The credibility revolution in empirical economics: How better research design is taking the con out of econometrics. Journal of economic perspectives, 24(2), 3–30.\n\n\nBaker, M. (2016). 1,500 scientists lift the lid on reproducibility. Nature, 533(7604).\n\n\nBishop, D. (2019). The psychology of experimental psychologists: Overcoming cognitive constraints to improve research.\n\n\nButton, K. S., Ioannidis, J. P., Mokrysz, C., Nosek, B. A., Flint, J., Robinson, E. S., & Munafò, M. R. (2013). Power failure: why small sample size undermines the reliability of neuroscience. Nature Reviews Neuroscience, 14(5), 365–376.\n\n\nCollaboration, O. S. (2015). Estimating the reproducibility of psychological science. Science, 349(6251), aac4716.\n\n\nGelman, A., & Loken, E. (2013). The garden of forking paths: Why multiple comparisons can be a problem, even when there is no «fishing expedition» or «p-hacking» and the research hypothesis was posited ahead of time. Department of Statistics, Columbia University, 348(1-17), 3.\n\n\nGelman, A., & Loken, E. (2014). The statistical crisis in science. American scientist, 102(6), 460–465.\n\n\nIoannidis, J. P. (2005). Why most published research findings are false. PLoS medicine, 2(8), e124.\n\n\nKorbmacher, M., Azevedo, F., Pennington, C. R., Hartmann, H., Pownall, M., Schmidt, K., Elsherif, M., Breznau, N., Robertson, O., Kalandadze, T., et al. (2023). The replication crisis has led to positive structural, procedural, and community changes. Communications Psychology, 1(1), 3.\n\n\nLabatut, B. (2021). Quando abbiamo smesso di capire il mondo. Adelphi Edizioni spa.\n\n\nLarson, C., Kaplan, D., Girolamo, T., Kover, S. T., & Eigsti, I.-M. (2023). A Bayesian statistics tutorial for clinical research: Prior distributions and meaningful results for small clinical samples. Journal of Clinical Psychology, 79(11), 2602–2624.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nMeehl, P. E. (1967). Theory-testing in psychology and physics: A methodological paradox. Philosophy of science, 34(2), 103–115.\n\n\nMunger, K. (2023). Temporal validity as meta-science. Research & Politics, 10(3), 20531680231187271.\n\n\nNosek, B. A., Hardwicke, T. E., Moshontz, H., Allard, A., Corker, K. S., Dreber, A., Fidler, F., Hilgard, J., Kline Struhl, M., Nuijten, M. B., et al. (2022). Replicability, robustness, and reproducibility in psychological science. Annual Review of Psychology, 73(1), 719–748.\n\n\nOberauer, K., & Lewandowsky, S. (2019). Addressing the theory crisis in psychology. Psychonomic Bulletin & Review, 26, 1596–1618.\n\n\nPearl, J., & Mackenzie, D. (2018). The book of why: the new science of cause and effect. Basic books.\n\n\nSimmons, J. P., Nelson, L. D., & Simonsohn, U. (2011). False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant. Psychological science, 22(11), 1359–1366.\n\n\nVan Dongen, N., Bork, R. van, Finnemann, A., Haslbeck, J., Maas, H. L. van der, Robinaugh, D. J., Ron, J. de, Sprenger, J., & Borsboom, D. (2024). Productive explanation: A framework for evaluating explanations in psychological science. Psychological Review.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_data_analysis.html",
    "href": "chapters/key_notions/01_data_analysis.html",
    "title": "1  La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana",
    "section": "",
    "text": "Introduzione\nNegli ultimi vent’anni, le scienze sociali e la psicologia hanno vissuto una profonda trasformazione metodologica ed epistemologica. Questo cambiamento, spesso definito come “Credibility Revolution” (Angrist & Pischke, 2010), “Causal Revolution” (Pearl & Mackenzie, 2018) e “Replication Crisis” (Collaboration, 2015; Nosek et al., 2022), ha portato a un ripensamento delle pratiche di ricerca, specialmente in psicologia (Korbmacher et al., 2023). Questa transizione verso quella che Munger (2023) chiama “Science versione 2” è stata motivata dalla consapevolezza di lacune metodologiche passate e ha spinto verso l’adozione di approcci più rigorosi e replicabili.\nLe origini di questa riforma risiedono nel riconoscimento di problemi metodologici diffusi, come la proliferazione di falsi positivi (Simmons et al., 2011), l’abuso dei “gradi di libertà dei ricercatori” (Gelman & Loken, 2013), e l’inadeguatezza delle pratiche statistiche tradizionali (Gelman & Loken, 2014). Fenomeni come il p-hacking, l’uso di campioni di piccole dimensioni (Button et al., 2013), e la mancanza di trasparenza nei metodi di ricerca hanno contribuito a minare la credibilità delle scoperte psicologiche (Ioannidis, 2005; Meehl, 1967), portando alla cosiddetta “Replication Crisis” (Baker, 2016; Bishop, 2019) — si veda il Capitolo 79.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_data_analysis.html#lapproccio-bayesiano",
    "href": "chapters/key_notions/01_data_analysis.html#lapproccio-bayesiano",
    "title": "1  La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana",
    "section": "1.1 L’Approccio Bayesiano",
    "text": "1.1 L’Approccio Bayesiano\nIn risposta a queste sfide, l’approccio bayesiano è emerso come un paradigma statistico chiave nella “Credibility Revolution”. A differenza dell’inferenza frequentista, che si basa sul Test dell’Ipotesi Nulla, la statistica bayesiana offre un framework più flessibile e intuitivo per l’analisi dei dati e l’inferenza causale. Il principio fondamentale dell’approccio bayesiano è l’aggiornamento delle distribuzioni di probabilità a priori (priors) alla luce di nuove evidenze, un processo che si allinea con l’obiettivo di una scienza cumulativa e auto-correttiva.\nL’adozione di metodi bayesiani in psicologia presenta numerosi vantaggi:\n\nQuantificazione dell’incertezza: L’inferenza bayesiana fornisce distribuzioni di probabilità posteriori complete per i parametri di interesse, offrendo una rappresentazione più ricca e sfumata dell’incertezza rispetto agli intervalli di confidenza frequentisti.\nIncorporazione di conoscenze pregresse: Le priors bayesiane permettono di integrare formalmente conoscenze precedenti nel processo inferenziale, promuovendo un approccio cumulativo alla ricerca.\nRobustezza alle pratiche di ricerca discutibili: I metodi bayesiani sono meno suscettibili a pratiche come il p-hacking, poiché l’inferenza si basa sull’intera distribuzione posteriore piuttosto che su soglie arbitrarie di significatività.\n\n\n1.1.1 Vantaggi e Applicazioni\nL’utilizzo delle statistiche bayesiane nella ricerca psicologica presenta notevoli vantaggi rispetto ai metodi statistici tradizionali, come i test di significatività basati sull’ipotesi nulla. Uno dei principali punti di forza risiede nella sua indipendenza dalla teoria dei grandi campioni, rendendolo particolarmente adatto a studi con dimensioni campionarie ridotte, una condizione frequente in psicologia (Larson et al., 2023).\n\n1.1.1.1 Sfide dei Campioni Piccoli in Psicologia\nLa ricerca psicologica spesso si confronta con campioni limitati a causa di:\n\nBassa prevalenza di condizioni specifiche (es. disturbi rari);\n\nDifficoltà nel reclutamento (es. popolazioni difficili da raggiungere);\n\nComplessità procedurali (es. valutazioni longitudinali o multimodali).\n\nQuesti campioni, oltre a essere numericamente ridotti, sono spesso caratterizzati da elevata eterogeneità, che si manifesta in:\n\nVariabilità fenotipica: Differenze comportamentali tra individui con la stessa condizione psicologica;\n\nDiscrepanza tra studi: Stime degli effetti divergenti in ricerche simili.\nTali fattori possono generare distorsioni nelle stime e risultati scarsamente riproducibili.\n\n\n\n1.1.1.2 Vantaggi dell’Approccio Bayesiano\n\nValutazione dell’Adeguatezza del Campione\n\nAttraverso l’analisi di sensibilità delle distribuzioni a priori, è possibile valutare quanto i risultati dipendano dalle assunzioni iniziali, identificando campioni troppo piccoli o ipotesi troppo influenti.\n\nPrecisione con Dati Limitati\n\nL’integrazione di conoscenze a priori ben definite (es. dati di studi precedenti) permette di ottenere stime robuste anche con piccoli campioni, compensando la carenza di dati attraverso informazioni esterne.\n\nInclusione Equa di Popolazioni Sottorappresentate\n\nL’approccio bayesiano riduce la necessità di campioni molto numerosi, evitando la pressione sul reclutamento di gruppi minoritari (es. minoranze etniche). Questo favorisce una ricerca più equa e rappresentativa, senza sacrificare la validità statistica.\n\n\n\n\n1.1.1.3 Impatto sulla Riproducibilità e Politiche di Ricerca\nIn sintesi, la capacità di gestire l’eterogeneità e di ottimizzare l’uso dei dati rende il metodo bayesiano uno strumento chiave per affrontare la crisi di riproducibilità in psicologia. Inoltre, promuove politiche inclusive, riducendo barriere etiche e pratiche legate al sovra-reclutamento di gruppi vulnerabili.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_data_analysis.html#modellazione-formale-e-data-science",
    "href": "chapters/key_notions/01_data_analysis.html#modellazione-formale-e-data-science",
    "title": "1  La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana",
    "section": "1.2 Modellazione Formale e Data Science",
    "text": "1.2 Modellazione Formale e Data Science\nLa “Credibility Revolution” ha favorito l’integrazione della Data Science nelle pratiche di ricerca psicologica. L’adozione di pipeline di analisi dei dati riproducibili, l’uso di controllo di versione e la condivisione di dati e codice sono diventati standard de facto nella comunità scientifica. Questi strumenti non solo migliorano la trasparenza e la replicabilità della ricerca, ma facilitano anche la collaborazione e l’accumulo di conoscenze nel campo.\nParallelamente, si è osservato un rinnovato interesse per la modellazione formale in psicologia, che consente non solo la verifica ma anche lo sviluppo di modelli dei meccanismi sottostanti ai fenomeni psicologici (Oberauer & Lewandowsky, 2019; Van Dongen et al., 2024). Questo approccio supera la mera descrizione delle associazioni tra variabili, tipica della pratica dominante dell’ANOVA nel contesto pre-riforma.\nLa modellazione bayesiana si presta particolarmente bene a questo approccio, offrendo un framework unificato per la specificazione di modelli formali, l’incorporazione di incertezza parametrica e la valutazione dell’evidenza empirica. Attraverso tecniche come il confronto tra modelli bayesiano e l’analisi di sensibilità, i ricercatori possono valutare rigorosamente la plausibilità relativa di diverse teorie psicologiche.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_data_analysis.html#riflessioni-epistemologiche",
    "href": "chapters/key_notions/01_data_analysis.html#riflessioni-epistemologiche",
    "title": "1  La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana",
    "section": "1.3 Riflessioni Epistemologiche",
    "text": "1.3 Riflessioni Epistemologiche\nL’adozione di metodi bayesiani e della Data Science in psicologia deve essere accompagnata da una profonda riflessione epistemologica. Come sottolineato da George Box:\n\nTutti i modelli sono sbagliati, ma alcuni sono utili.\n\nQuesta massima risuona particolarmente nel contesto della ricerca psicologica, dove i fenomeni di interesse sono spesso complessi e multifattoriali.\nL’approccio bayesiano, con la sua enfasi sull’aggiornamento iterativo delle credenze alla luce di nuove evidenze, si allinea naturalmente con una visione della scienza come processo di apprendimento continuo piuttosto che come ricerca di verità assolute. Questa prospettiva riconosce i limiti intrinseci dei nostri modelli e delle nostre teorie, pur valorizzandone l’utilità euristica e predittiva.\nIn particolare, McElreath (2020) sottolinea l’importanza di riconoscere la dualità tra il “mondo del modello” e il mondo reale più ampio che cerchiamo di comprendere. Questa consapevolezza è cruciale per evitare la reificazione dei nostri modelli statistici e per mantenere una prospettiva critica sulle nostre inferenze.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_data_analysis.html#riflessioni-conclusive",
    "href": "chapters/key_notions/01_data_analysis.html#riflessioni-conclusive",
    "title": "1  La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana",
    "section": "1.4 Riflessioni Conclusive",
    "text": "1.4 Riflessioni Conclusive\nL’integrazione dell’approccio bayesiano e della Data Science nella ricerca psicologica rappresenta una risposta promettente alle sfide poste dalla “Replication Crisis”. Offrendo un framework coerente per la modellazione formale, l’inferenza statistica e l’incorporazione di conoscenze pregresse, questi approcci promettono di elevare il rigore e la credibilità della ricerca psicologica. Tuttavia, è fondamentale che l’adozione di questi metodi sia accompagnata da una adeguata consapevolezza metodologica ed epistemologica.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_data_analysis.html#esercizi",
    "href": "chapters/key_notions/01_data_analysis.html#esercizi",
    "title": "1  La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nQuali sono i principali fattori che hanno portato alla “Credibility Revolution” in psicologia e in che modo le nuove metodologie — in particolare l’approccio bayesiano e le buone pratiche di Data Science — mirano a superare i limiti che hanno contribuito alla “Replication Crisis”?\nIn che modo il paradigma bayesiano differisce dall’approccio frequentista nella gestione dell’incertezza e nell’aggiornamento della conoscenza, e quali vantaggi pratici offre quando si lavora con campioni di piccole dimensioni e popolazioni eterogenee?\nQual è il ruolo delle distribuzioni a priori nelle analisi bayesiane e come ci si assicura che l’uso di priors non introduca bias indesiderati, specialmente in un contesto come quello psicologico dove le teorie e i dati pregressi possono essere incompleti o controversi?\nPerché la modellazione formale e le buone pratiche di Data Science (ad es. condivisione di codice, controllo di versione, pipeline riproducibili) risultano fondamentali per una scienza cumulativa e per mitigare gli errori sistematici nella ricerca psicologica?\nDal punto di vista epistemologico, in che modo il principio “tutti i modelli sono sbagliati, ma alcuni sono utili” influenza la costruzione, la valutazione e l’interpretazione dei modelli in psicologia, e come si integra con la prospettiva bayesiana di scienza come processo iterativo di apprendimento?\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n1. Quali sono i principali fattori che hanno portato alla “Credibility Revolution” in psicologia e in che modo le nuove metodologie — in particolare l’approccio bayesiano e le buone pratiche di Data Science — mirano a superare i limiti che hanno contribuito alla “Replication Crisis”?\nNegli ultimi decenni, la psicologia ha attraversato una “Replication Crisis” a causa di diverse pratiche di ricerca problematiche, tra cui l’utilizzo di campioni di piccole dimensioni, l’uso eccessivo di test di significatività frequentisti con p &lt; .05 come soglia rigida, il fenomeno del p-hacking (cioè l’adattamento delle analisi per ottenere risultati “significativi”), e la carenza di trasparenza e condivisione dei dati. Questi fattori hanno portato alla pubblicazione di molti falsi positivi e a un’erosione della fiducia nelle conclusioni psicologiche.\nLa “Credibility Revolution” nasce dalla presa di coscienza di questi problemi e dall’introduzione di nuove metodologie che offrono maggior rigore e trasparenza. L’approccio bayesiano, in particolare, consente di superare alcuni limiti della statistica frequentista, poiché fornisce distribuzioni posteriori di plausibilità per i parametri e non si affida a soglie arbitrarie di significatività. Inoltre, la Data Science ha promosso la diffusione di pipeline analitiche riproducibili (tramite il controllo di versione, la condivisione del codice e dei dati), contribuendo a ridurre errori, bias e a favorire la replicabilità. Insieme, queste innovazioni mirano a creare una scienza più aperta, solida e cumulativa.\n2. In che modo il paradigma bayesiano differisce dall’approccio frequentista nella gestione dell’incertezza e nell’aggiornamento della conoscenza, e quali vantaggi pratici offre quando si lavora con campioni di piccole dimensioni e popolazioni eterogenee?\nIl paradigma frequentista si basa sull’idea di ripetizione ipotetica degli esperimenti e sull’applicazione di test di significatività, focalizzandosi su p-value e intervalli di confidenza che rispondono a domande “se si ripetesse infinite volte l’esperimento, in media cosa accadrebbe?”. L’inferenza bayesiana, al contrario, concepisce la probabilità come uno stato di conoscenza (o di credenza) e integra le informazioni precedenti (priors) con i dati osservati per produrre una distribuzione posteriore. Ciò consente un aggiornamento continuo e iterativo delle ipotesi alla luce delle nuove evidenze.\nQuesta impostazione risulta particolarmente utile quando i campioni sono ridotti e le popolazioni indagate sono eterogenee. In tali condizioni, il paradigma frequentista rischia di generare stime instabili o intervalli di confidenza molto ampi. L’approccio bayesiano, invece, permette di incorporare informazioni pregresse e di ottenere stime più precise, a patto che le priors siano giustificate e non eccessivamente informative. L’attenzione alla distribuzione posteriore rende inoltre più chiaro il grado di incertezza associato ai parametri di interesse e favorisce la formulazione di inferenze più calibrate.\n3. Qual è il ruolo delle distribuzioni a priori nelle analisi bayesiane e come ci si assicura che l’uso di priors non introduca bias indesiderati, specialmente in un contesto come quello psicologico dove le teorie e i dati pregressi possono essere incompleti o controversi?\nNell’approccio bayesiano, le distribuzioni a priori (priors) rappresentano la conoscenza o le ipotesi iniziali di cui si dispone sui parametri in esame prima di raccogliere i dati. Se ben specificate, contribuiscono a rendere l’analisi più informativa, soprattutto quando il campione è di piccole dimensioni. Tuttavia, un uso improprio delle priors può introdurre bias, poiché priors troppo “forti” (ossia eccessivamente vincolanti) possono spingere i risultati verso determinate conclusioni.\nPer evitare questi rischi, i ricercatori devono adottare priors ben motivate e trasparenti. In psicologia, dove le teorie possono essere ancora in fase di sviluppo e i dati pregressi non sempre affidabili, è spesso utile iniziare con priors non informative o debolmente informative, per ridurre il rischio di forzare troppo il modello. È anche fondamentale effettuare analisi di sensibilità: testare differenti specificazioni di priors per verificare se i risultati sono robusti oppure fortemente dipendenti da particolari assunzioni iniziali. La documentazione delle scelte fatte (e le relative ragioni) è parte integrante di una buona pratica di ricerca trasparente.\n4. Perché la modellazione formale e le buone pratiche di Data Science (ad es. condivisione di codice, controllo di versione, pipeline riproducibili) risultano fondamentali per una scienza cumulativa e per mitigare gli errori sistematici nella ricerca psicologica?\nLa modellazione formale consente di superare la mera descrizione delle relazioni tra variabili (tipica dell’ANOVA o dei modelli lineari tradizionali) e di entrare nel merito dei meccanismi sottostanti i fenomeni psicologici, costruendo teorie più articolate e fondate. Questa prospettiva rende più esplicite le assunzioni e le ipotesi su cui si basa la ricerca, permettendo un confronto chiaro tra diverse spiegazioni concorrenti.\nParallelamente, l’adozione di strumenti e pratiche di Data Science come la condivisione di codice (in repository pubblici), l’uso del controllo di versione (es. Git) e pipeline analitiche riproducibili riducono gli errori e favoriscono la verifica indipendente dei risultati. Ciò aumenta la trasparenza, poiché altri ricercatori possono ispezionare i passaggi compiuti, e consente la replicazione degli studi. In una scienza cumulativa, infatti, la possibilità di riprodurre, criticare e migliorare i risultati di lavori precedenti è essenziale per costruire un corpus di conoscenze solido e affidabile.\n5. Dal punto di vista epistemologico, in che modo il principio “tutti i modelli sono sbagliati, ma alcuni sono utili” influenza la costruzione, la valutazione e l’interpretazione dei modelli in psicologia, e come si integra con la prospettiva bayesiana di scienza come processo iterativo di apprendimento?\nLa celebre frase di George Box (“tutti i modelli sono sbagliati, ma alcuni sono utili”) evidenzia come i modelli statistici e teorici non possano mai rappresentare perfettamente la realtà, specialmente in un campo complesso come la psicologia, in cui le variabili spesso interagiscono in modo non lineare e multi-dimensionale. Ciò non significa che i modelli siano inutili; anzi, se ben costruiti, possono offrire uno strumento potente per interpretare e prevedere i fenomeni.\nNell’ottica bayesiana, la costruzione dei modelli è un processo iterativo in cui le ipotesi iniziali (priors) vengono continuamente aggiornate alla luce di nuove evidenze (la distribuzione posteriore). Questo ciclo di apprendimento riflette un’idea di scienza non come ricerca della “verità assoluta”, ma come progressivo affinamento delle teorie. Il principio di Box ricorda ai ricercatori che qualsiasi modello deve essere costantemente messo alla prova, confrontato con altri modelli, e aggiornato o abbandonato se i dati non lo supportano più. In questo senso, la prospettiva bayesiana favorisce una mentalità flessibile e aperta, pronta a rivedere i propri presupposti e a migliorare progressivamente la comprensione dei fenomeni psicologici.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_data_analysis.html#bibliografia",
    "href": "chapters/key_notions/01_data_analysis.html#bibliografia",
    "title": "1  La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAngrist, J. D., & Pischke, J.-S. (2010). The credibility revolution in empirical economics: How better research design is taking the con out of econometrics. Journal of economic perspectives, 24(2), 3–30.\n\n\nBaker, M. (2016). 1,500 scientists lift the lid on reproducibility. Nature, 533(7604).\n\n\nBishop, D. (2019). The psychology of experimental psychologists: Overcoming cognitive constraints to improve research.\n\n\nButton, K. S., Ioannidis, J. P., Mokrysz, C., Nosek, B. A., Flint, J., Robinson, E. S., & Munafò, M. R. (2013). Power failure: why small sample size undermines the reliability of neuroscience. Nature Reviews Neuroscience, 14(5), 365–376.\n\n\nCollaboration, O. S. (2015). Estimating the reproducibility of psychological science. Science, 349(6251), aac4716.\n\n\nGelman, A., & Loken, E. (2013). The garden of forking paths: Why multiple comparisons can be a problem, even when there is no «fishing expedition» or «p-hacking» and the research hypothesis was posited ahead of time. Department of Statistics, Columbia University, 348(1-17), 3.\n\n\nGelman, A., & Loken, E. (2014). The statistical crisis in science. American scientist, 102(6), 460–465.\n\n\nIoannidis, J. P. (2005). Why most published research findings are false. PLoS medicine, 2(8), e124.\n\n\nKorbmacher, M., Azevedo, F., Pennington, C. R., Hartmann, H., Pownall, M., Schmidt, K., Elsherif, M., Breznau, N., Robertson, O., Kalandadze, T., et al. (2023). The replication crisis has led to positive structural, procedural, and community changes. Communications Psychology, 1(1), 3.\n\n\nLabatut, B. (2021). Quando abbiamo smesso di capire il mondo. Adelphi Edizioni spa.\n\n\nLarson, C., Kaplan, D., Girolamo, T., Kover, S. T., & Eigsti, I.-M. (2023). A Bayesian statistics tutorial for clinical research: Prior distributions and meaningful results for small clinical samples. Journal of Clinical Psychology, 79(11), 2602–2624.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nMeehl, P. E. (1967). Theory-testing in psychology and physics: A methodological paradox. Philosophy of science, 34(2), 103–115.\n\n\nMunger, K. (2023). Temporal validity as meta-science. Research & Politics, 10(3), 20531680231187271.\n\n\nNosek, B. A., Hardwicke, T. E., Moshontz, H., Allard, A., Corker, K. S., Dreber, A., Fidler, F., Hilgard, J., Kline Struhl, M., Nuijten, M. B., et al. (2022). Replicability, robustness, and reproducibility in psychological science. Annual Review of Psychology, 73(1), 719–748.\n\n\nOberauer, K., & Lewandowsky, S. (2019). Addressing the theory crisis in psychology. Psychonomic Bulletin & Review, 26, 1596–1618.\n\n\nPearl, J., & Mackenzie, D. (2018). The book of why: the new science of cause and effect. Basic books.\n\n\nSimmons, J. P., Nelson, L. D., & Simonsohn, U. (2011). False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant. Psychological science, 22(11), 1359–1366.\n\n\nVan Dongen, N., Bork, R. van, Finnemann, A., Haslbeck, J., Maas, H. L. van der, Robinaugh, D. J., Ron, J. de, Sprenger, J., & Borsboom, D. (2024). Productive explanation: A framework for evaluating explanations in psychological science. Psychological Review.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>La riforma metodologica in psicologia: dalla crisi alla rivoluzione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html",
    "href": "chapters/key_notions/02_key_notions.html",
    "title": "2  Concetti chiave",
    "section": "",
    "text": "2.1 Introduzione\nNella ricerca scientifica, la formulazione di risposte a specifiche domande di indagine avviene attraverso l’applicazione di metodologie rigorose e l’esecuzione di osservazioni accurate e controllate. Le informazioni raccolte mediante diverse tecniche di indagine—come ricerche sul campo, indagini campionarie e protocolli sperimentali—vengono definite con il termine tecnico di dati. Questo capitolo introduce i principi fondamentali dell’analisi dei dati, concentrandosi sia sulle caratteristiche dei dati stessi sia sui metodi di raccolta.\nL’analisi dei dati permette di sintetizzare grandi quantità di informazioni e di verificare le previsioni avanzate dalle teorie. Tuttavia, senza una teoria che dia significato ai dati, le osservazioni rimangono mere descrizioni prive di un contesto esplicativo. È attraverso l’integrazione tra dati e teoria che si raggiunge una comprensione profonda dei fenomeni e si favorisce l’avanzamento scientifico [es., Wertheimer (1880–1943), scoperta del movimento-\\(\\phi\\) e nascita del movimento della Gestalt; Steinman et al. (2000)].",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#introduzione",
    "href": "chapters/key_notions/02_key_notions.html#introduzione",
    "title": "2  Concetti chiave",
    "section": "",
    "text": "Statistica\n\n\n\nIl termine “statistica” può assumere diversi significati a seconda del contesto:\n\nPrimo significato: La statistica è una scienza che si occupa dello studio e dell’applicazione di metodi per la raccolta, organizzazione, analisi, interpretazione e presentazione dei dati.\nSecondo significato: Il termine si riferisce a una misura o valore numerico calcolato a partire da un campione di dati, come la media campionaria, la deviazione standard campionaria o il coefficiente di correlazione campionario.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#la-spiegazione-scientifica",
    "href": "chapters/key_notions/02_key_notions.html#la-spiegazione-scientifica",
    "title": "2  Concetti chiave",
    "section": "2.2 La Spiegazione Scientifica",
    "text": "2.2 La Spiegazione Scientifica\nLa scienza non si limita a descrivere o prevedere i fenomeni: il suo obiettivo principale è spiegare il perché degli eventi, offrendo una comprensione approfondita delle cause e dei meccanismi che li regolano. La spiegazione scientifica è cruciale per costruire teorie capaci non solo di descrivere e prevedere, ma anche di chiarire le dinamiche causali e le connessioni tra i fenomeni, contribuendo a un controllo più consapevole e informato su di essi.\nConsideriamo, ad esempio, il rapporto tra il background familiare e il rendimento scolastico. Numerose ricerche evidenziano una forte correlazione tra il livello di istruzione dei genitori e il successo accademico dei figli. Una prospettiva puramente descrittiva potrebbe limitarsi a constatare che: “Gli studenti provenienti da famiglie con basso livello di istruzione hanno minori probabilità di conseguire un titolo universitario”. Tuttavia, la vera sfida scientifica consiste nell’andare oltre questa previsione, ponendosi domande più profonde:\n\nquali meccanismi causali determinano questa disparità?\n\nquali interventi possono efficacemente ridurre tali disuguaglianze?\n\nPer superare il livello di semplice previsione, la ricerca deve identificare i fattori causali alla base del fenomeno, in modo da comprendere come l’azione su questi fattori possa modificare gli esiti. Nel caso dell’esempio sul rapporto tra background familiare e rendimento scolastico, ciò implica comprendere, ad esempio:\n\nse e in che modo il sostegno finanziario possa favorire il percorso degli studenti svantaggiati;\nquali politiche educative possano produrre effetti positivi sul lungo termine;\ncome i meccanismi sociali e individuali influenzino il processo educativo.\n\nAcquisire una conoscenza approfondita dei meccanismi causali permette di andare oltre la semplice previsione, rendendo possibile la progettazione di interventi mirati e strategici che possano realmente incidere sui fenomeni in modo efficace e duraturo.\n\n2.2.1 Elementi Fondamentali della Spiegazione Scientifica\nLa filosofia della scienza identifica tre componenti fondamentali di una spiegazione scientifica:\n\nExplanandum\nÈ il fenomeno che desideriamo comprendere, ovvero ciò di cui cerchiamo le cause o i meccanismi. Un esempio: “Gli studenti con alti livelli di ansia da prestazione ottengono punteggi più bassi nei test scolastici rispetto ai loro pari.”\nExplanans\nÈ l’insieme dei fattori che spiegano il fenomeno. Nel caso dell’ansia da prestazione, un possibile explanans potrebbe essere: “L’ansia danneggia la concentrazione e la memoria di lavoro, influendo negativamente sulla performance nei test.”\nLegame esplicativo\nComprende i principi o i meccanismi che dimostrano come l’explanans produca l’explanandum. Seguendo l’esempio precedente: “Livelli elevati di ansia innescano il sistema nervoso simpatico, aumentando lo stress fisiologico e riducendo l’efficienza dei processi cognitivi necessari per compiti complessi.”\n\nQuesti tre elementi si combinano all’interno di modelli scientifici, che costituiscono le strutture teoriche e metodologiche impiegate per formulare e verificare spiegazioni. In psicologia, tali modelli includono:\n\nIl fenomeno da spiegare (ad es. le prestazioni scolastiche).\n\nI fattori che lo influenzano (ad es. ansia, regolazione emotiva).\n\nI meccanismi sottostanti che collegano cause ed effetti (ad es. attivazione fisiologica, memoria di lavoro compromessa).\n\nUn modello psicologico sull’ansia da prestazione, ad esempio, potrebbe considerare la relazione tra livello di ansia percepita, capacità di regolazione emotiva e memoria di lavoro. A differenza di modelli esclusivamente descrittivi o predittivi, i modelli esplicativi rispondono a domande causali: non si limitano ad attestare che ansia e prestazioni sono correlate, ma mostrano come e perché l’ansia riduca il rendimento. Inoltre, tali modelli suggeriscono strategie d’intervento per attenuare l’effetto dell’ansia, come il potenziamento della regolazione emotiva o l’uso di tecniche di gestione dello stress.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#modelli-psicologici",
    "href": "chapters/key_notions/02_key_notions.html#modelli-psicologici",
    "title": "2  Concetti chiave",
    "section": "2.3 Modelli Psicologici",
    "text": "2.3 Modelli Psicologici\n\n\n\n\n\n\nUn modello è una rappresentazione concettuale – spesso supportata da formalismi matematici – di un fenomeno reale, basata su un insieme di equazioni e ipotesi che descrivono le relazioni tra variabili e la struttura probabilistica sottostante. L’obiettivo è coglierne gli aspetti essenziali senza includere ogni dettaglio superfluo, formulando predizioni quantitative che possano essere verificate empiricamente. Poiché spesso esistono molteplici modelli in grado di spiegare lo stesso fenomeno, il compito della ricerca consiste nel selezionare quello che meglio descrive i dati e soddisfa criteri di validità, accuratezza e parsimonia.\n\n\n\nI modelli psicologici, in particolare, sono strumenti teorici finalizzati a descrivere, spiegare e prevedere il comportamento umano e i processi mentali. Un modello ben costruito dovrebbe possedere le seguenti caratteristiche:\n\nCoerenza descrittiva\nIl modello deve fornire una rappresentazione logica e coerente del fenomeno, includendo tutti gli elementi chiave del processo psicologico e organizzando le osservazioni in una struttura interpretativa chiara.\nCapacità predittiva\nDeve essere in grado di formulare previsioni verificabili e di produrre ipotesi testabili sulla base dei dati raccolti, permettendo così di valutare la validità del modello.\nSupporto empirico\nLe previsioni e le ipotesi del modello vanno confrontate con l’evidenza empirica, ottenuta attraverso ricerche sistematiche e rigorose. I dati devono corroborare le relazioni proposte dal modello.\nFalsificabilità\nIl modello deve poter essere sottoposto a verifica empirica e, all’occorrenza, smentito. Se emergono osservazioni in conflitto con le sue previsioni, il modello deve essere revisionato o sostituito.\nParsimonia\nLa spiegazione deve risultare semplice e lineare, includendo solo gli elementi indispensabili per rendere conto del fenomeno. Assunzioni superflue o ridondanti ne riducono la robustezza.\nGeneralizzabilità\nIl modello dovrebbe poter essere esteso a contesti e situazioni diverse, superando i limiti di specifiche condizioni sperimentali o campioni ristretti.\nUtilità pratica\nDovrebbe offrire linee guida concrete per l’applicazione nel mondo reale, ad esempio negli interventi clinici, nei programmi di prevenzione o nelle terapie, così da avere un impatto positivo sugli individui e sulla società.\n\nUno degli ostacoli maggiori nella costruzione di modelli in psicologia è la natura soggettiva, dinamica e variabile dell’esperienza umana. È quindi necessario bilanciare la precisione teorica (spesso supportata da formalizzazioni matematiche o computazionali) con la flessibilità necessaria a catturare l’eterogeneità dei fenomeni psicologici. A questo si aggiungono i vincoli etici della ricerca sull’essere umano e le potenziali ricadute sociali dei risultati.\nL’analisi quantitativa dei dati gioca un ruolo centrale nella validazione dei modelli psicologici: mediante metodologie statistiche e computazionali avanzate, i ricercatori possono verificare se le predizioni di un modello trovano riscontro nei dati empirici e se tali predizioni si mantengono valide in contesti diversi. Questo processo non solo consolida la comprensione del fenomeno, ma consente anche di anticipare e, in alcune circostanze, influenzare il comportamento e i processi mentali. Un modello rigorosamente formulato e testabile diviene quindi un potente strumento per lo sviluppo di interventi efficaci e il progresso teorico.\n\n2.3.1 Rappresentare i Fenomeni per Ragionare e Comunicare\nLa spiegazione scientifica non si limita a far luce sui meccanismi causali, ma fornisce anche un linguaggio formale per analizzare e condividere conoscenze sui fenomeni. In psicologia, i modelli scientifici costituiscono strumenti fondamentali per descrivere i processi attraverso variabili, funzioni e parametri, offrendo una struttura che facilita l’individuazione di relazioni e proprietà essenziali. Un modello efficace semplifica la complessità del fenomeno, agevolando sia la comunicazione tra studiosi sia la comprensione intuitiva.\nInoltre, i modelli non si limitano a organizzare le informazioni esistenti: stimolano anche l’emergere di nuove ipotesi di ricerca, promuovono collegamenti tra concetti apparentemente lontani e consentono di trasferire conoscenze tra discipline, ampliando così l’orizzonte dell’indagine scientifica.\n\n\n2.3.2 Il Ruolo dell’Analisi dei Dati\nL’analisi dei dati è parte integrante del metodo scientifico e, in psicologia, assolve due funzioni primarie:\n\nSemplificare e sintetizzare informazioni complesse\nAttraverso statistiche descrittive, rappresentazioni grafiche e altre tecniche di sintesi, l’analisi dei dati aiuta a individuare schemi, tendenze e anomalie. Questo passaggio è essenziale per comprendere le differenze tra individui o gruppi e per formulare ipotesi di ricerca più mirate.\nValutare le predizioni dei modelli\nConfrontando i dati raccolti con le previsioni teoriche, si misura la validità di un modello. Tale confronto è indispensabile per confermare, raffinare o rivedere le ipotesi di partenza, orientando così il progresso della conoscenza scientifica.\n\nTuttavia, limitarsi alla ricerca di correlazioni o di pattern nei dati, senza un solido quadro teorico, non basta a comprendere pienamente il fenomeno. Risultati empirici privi di spiegazioni causali rimangono frammentari. Per questo motivo, integrare i dati in un modello teorico esplicativo è cruciale: si possono così proporre meccanismi causali, identificare relazioni e avanzare nuove ipotesi di ricerca.\n\n\n2.3.3 Carattere Multidisciplinare dell’Analisi dei Dati\nPer rispondere alle complesse domande poste in psicologia, l’analisi dei dati si fonda sull’integrazione di più discipline: statistica, teoria della probabilità e informatica. Ciascuna offre contributi indispensabili per affrontare la complessità dei processi psicologici:\n\nStatistica\nFornisce tecniche per la raccolta, l’organizzazione e l’interpretazione dei dati, consentendo di riassumere le informazioni, individuare pattern significativi e valutare empiricamente le ipotesi dei modelli psicologici.\nTeoria della probabilità\nCostituisce la base matematica della statistica e della modellazione scientifica, offrendo strumenti per quantificare l’incertezza, descrivere la variabilità delle osservazioni e costruire modelli predittivi rigorosi.\nInformatica\nContribuisce con strumenti per la gestione, l’analisi e la visualizzazione di grandi quantità di dati, nonché per l’implementazione di modelli computazionali sofisticati. Questi modelli si rivelano fondamentali nel simulare e testare dinamiche dei processi psicologici.\n\nLa natura multidisciplinare dell’analisi dei dati rispecchia l’esigenza di competenze diverse per comprendere e modellizzare i fenomeni psicologici in modo rigoroso. L’approccio quantitativo e computazionale ai modelli non si limita a descrivere e interpretare i dati, ma consente di formulare predizioni precise e sottoponibili a verifica, contribuendo così all’avanzamento della psicologia come scienza.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#concetti-chiave-nellanalisi-dei-dati",
    "href": "chapters/key_notions/02_key_notions.html#concetti-chiave-nellanalisi-dei-dati",
    "title": "2  Concetti chiave",
    "section": "2.4 Concetti Chiave nell’Analisi dei Dati",
    "text": "2.4 Concetti Chiave nell’Analisi dei Dati\nPer condurre un’analisi dei dati efficace, è fondamentale comprendere alcuni concetti chiave che guidano il processo di indagine, dall’identificazione del fenomeno alla formulazione di inferenze.\n\n2.4.1 Popolazioni e Campioni\nL’analisi dei dati inizia con l’identificazione della popolazione di interesse, che rappresenta l’insieme completo degli individui o delle entità coinvolte nel fenomeno studiato. Poiché studiare un’intera popolazione è spesso impraticabile, si ricorre ai campioni, sottoinsiemi rappresentativi della popolazione. La qualità e la rappresentatività del campione sono cruciali: un campione non rappresentativo può portare a conclusioni errate, limitando la generalizzabilità dei risultati.\n\n\n\n\n\n\nParametri e Statistiche\n\n\n\nUn parametro è una caratteristica numerica della popolazione (es. media \\(\\mu\\), deviazione standard \\(\\sigma\\)). Una statistica è una caratteristica numerica calcolata sul campione (es. media campionaria \\(\\bar{x}\\), deviazione standard campionaria \\(s\\)). L’inferenza statistica si occupa di stimare i parametri della popolazione a partire dalle statistiche campionarie.\n\n\n\n\n2.4.2 Bias nella Raccolta Dati\nI bias nella raccolta e interpretazione dei dati possono compromettere l’accuratezza dei risultati. Comprendere chi ha raccolto i dati, come e con quali scopi è essenziale per una corretta interpretazione (Johnson et al., 2022). I dati non sono mai completamente neutri; i metodi e gli obiettivi di raccolta influenzano i risultati. Ad esempio, selezionare partecipanti da una popolazione di studenti universitari potrebbe introdurre un bias sistematico, limitando la generalizzabilità ad altri contesti (Murray & Carr, 2024; Nobles, 2000).\n\n\n2.4.3 Variabili e Costanti\nNell’analisi statistica, le variabili rappresentano le caratteristiche osservate che possono assumere diversi valori (numerici o categorici). Le costanti, al contrario, rimangono fisse in un determinato contesto. Le variabili si distinguono in:\n\nvariabili indipendenti (o predittive): influenzano altri fenomeni;\n\nvariabili dipendenti: rappresentano gli esiti di interesse influenzati dalle variabili indipendenti.\n\nAd esempio, in uno studio sugli effetti della terapia cognitivo-comportamentale, la variabile indipendente potrebbe essere la partecipazione alla terapia, mentre la variabile dipendente sarebbe la riduzione dei sintomi di ansia.\n\n\n2.4.4 Studi Osservazionali ed Esperimenti\nEsistono due principali metodi di raccolta dati.\n\nEsperimenti: I ricercatori manipolano una o più variabili per valutare il loro effetto su altre variabili, controllando per i fattori confondenti. Ad esempio, per valutare l’efficacia di un trattamento, i partecipanti possono essere assegnati casualmente a un gruppo di controllo (placebo) e a un gruppo sperimentale (trattamento attivo). La randomizzazione riduce il rischio di bias sistematici.\nStudi osservazionali: I dati vengono raccolti senza interferire con il fenomeno osservato. Ad esempio, un’indagine su come lo stress influenza la produttività lavorativa potrebbe basarsi su questionari senza manipolare lo stress dei partecipanti. Questi studi forniscono correlazioni tra variabili, ma non dimostrano relazioni causali.\n\n\n\n2.4.5 Effetti\nIn statistica, un effetto rappresenta il cambiamento osservato nella variabile dipendente in relazione a una variabile indipendente. Questo cambiamento può indicare un’associazione tra le due variabili, ma la sua interpretazione come relazione causale dipende strettamente dal disegno sperimentale con cui i dati sono stati raccolti.\nAd esempio, se si osserva una riduzione dei sintomi tra la fase pre-trattamento e quella post-trattamento in un gruppo di pazienti sottoposti a una terapia, è possibile identificare un effetto della terapia. Tuttavia, senza un disegno sperimentale adeguato – come un esperimento controllato randomizzato (RCT) – non è possibile stabilire con certezza che la riduzione dei sintomi sia causata dalla terapia e non da altri fattori, come il decorso naturale della malattia o l’effetto placebo (Huntington-Klein, 2021).\nI modelli statistici, da soli, non possono determinare relazioni causali: possono quantificare l’entità di un effetto e valutare la forza dell’associazione tra variabili, ma la causalità può essere inferita solo se i dati provengono da un disegno sperimentale che isola il meccanismo di interesse, controllando per possibili fattori di confondimento. Pertanto, per trarre conclusioni causali robuste, è essenziale integrare l’analisi statistica con un approccio metodologico rigoroso basato su strategie di manipolazione sperimentale, assegnazione casuale o tecniche avanzate per il controllo dei bias nei dati osservazionali.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#stima-e-inferenza-statistica-dal-campione-alla-popolazione",
    "href": "chapters/key_notions/02_key_notions.html#stima-e-inferenza-statistica-dal-campione-alla-popolazione",
    "title": "2  Concetti chiave",
    "section": "2.5 Stima e Inferenza Statistica: Dal Campione alla Popolazione",
    "text": "2.5 Stima e Inferenza Statistica: Dal Campione alla Popolazione\nLa stima e l’inferenza statistica costituiscono i pilastri della metodologia quantitativa, poiché permettono di estendere le conclusioni tratte da un campione – una porzione limitata di individui osservati – all’intera popolazione di interesse. L’uso dei campioni risulta indispensabile a causa dei vincoli di tempo, costi e risorse, che spesso rendono impossibile lo studio dell’intera popolazione.\nTuttavia, il ricorso al campione introduce inevitabilmente un’incertezza intrinseca: le statistiche campionarie (come media o varianza del campione) sono stime dei parametri della popolazione e di norma non coincidono esattamente con i valori “veri” della popolazione. Tale discrepanza è nota come errore di campionamento, la cui entità dipende, tra l’altro, dalla dimensione del campione e dalla strategia di campionamento adottata.\nLa teoria degli stimatori e gli strumenti di inferenza statistica (ad esempio, intervalli di confidenza in un approccio frequentista o intervalli di credibilità in un approccio bayesiano) consentono di quantificare e gestire quest’incertezza, fornendo un quadro che permette di trarre conclusioni credibili sulla popolazione partendo dai dati raccolti.\n\n2.5.1 Stima: Inferire le Caratteristiche della Popolazione\nLa stima è il processo con cui, a partire dai dati di un campione, si inferiscono proprietà della popolazione, come la media o la varianza. Poiché ogni campione rappresenta solo una frazione della popolazione, può fornire stime diverse; questo fenomeno è noto come variabilità campionaria. Proprio tale variabilità costituisce la principale fonte di incertezza nelle inferenze: se un singolo campione non è sufficientemente ampio o rappresentativo, la stima potrebbe discostarsi in misura rilevante dai valori effettivi presenti nella popolazione.\n\n2.5.1.1 Fattori che Influenzano l’Accuratezza\nTre fattori fondamentali influiscono sull’accuratezza di una stima:\n\nDimensione del campione\nUn campione più grande tende a ridurre la variabilità campionaria, aumentando la precisione delle stime.\nRappresentatività\nUn campione ben progettato e rappresentativo rispecchia le caratteristiche essenziali della popolazione. Al contrario, un campione distorto (ad esempio, selezionato per convenienza) può condurre a stime fuorvianti.\nVariabilità della popolazione\nSe la popolazione è estremamente eterogenea, sono necessari campioni più ampi per produrre stime affidabili.\n\n\n\n2.5.1.2 Gli Stimatori: Proprietà Fondamentali\nGli stimatori sono formule matematiche o procedure statistiche usate per calcolare le stime. La loro qualità si valuta principalmente in base a:\n\nConsistenza\nUno stimatore è consistente se, all’aumentare della dimensione del campione, la stima tende a convergere verso il valore reale del parametro.\nNon distorsione (unbiasedness)\nUno stimatore è non distorto se il suo valore atteso corrisponde al parametro della popolazione. In altri termini, in media, lo stimatore coincide con il valore reale.\nEfficienza\nTra stimatori non distorti, è più efficiente quello con varianza minore, poiché fornisce stime più stabili.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#inferenza-statistica",
    "href": "chapters/key_notions/02_key_notions.html#inferenza-statistica",
    "title": "2  Concetti chiave",
    "section": "2.6 Inferenza Statistica",
    "text": "2.6 Inferenza Statistica\nL’inferenza statistica si basa sulle stime campionarie per trarre conclusioni sull’intera popolazione. In particolare, risponde a tre grandi interrogativi:\n\nStima dei parametri della popolazione\nOttenere valori plausibili per parametri quali media, varianza e proporzioni, quantificando contestualmente l’incertezza (ad esempio, costruendo intervalli di confidenza o di credibilità).\nValutazione di ipotesi\nConfrontare ipotesi rivali, come l’esistenza di differenze tra gruppi o di relazioni tra variabili. Attraverso il confronto tra ipotesi e dati, si determina quale ipotesi è meglio supportata.\nPrevisione\nUtilizzare i dati esistenti per anticipare risultati futuri, tenendo conto delle fonti di incertezza legate sia alla variabilità intrinseca dei dati sia ai parametri non perfettamente noti.\n\nSia l’approccio frequentista sia quello bayesiano affrontano questi problemi in modo rigoroso, ma differiscono nel modo di concettualizzare l’incertezza e di incorporare l’informazione nei modelli.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#le-sfide-dellinferenza-statistica-in-psicologia",
    "href": "chapters/key_notions/02_key_notions.html#le-sfide-dellinferenza-statistica-in-psicologia",
    "title": "2  Concetti chiave",
    "section": "2.7 Le Sfide dell’Inferenza Statistica in Psicologia",
    "text": "2.7 Le Sfide dell’Inferenza Statistica in Psicologia\nIn psicologia e, più in generale, nelle scienze sociali, l’inferenza statistica incontra specifiche problematiche spesso connesse alla complessità dei fenomeni oggetto di studio (Gelman et al., 2021). Tra le sfide principali figurano:\n\nLimiti nella generalizzazione dei risultati\nIn molti studi psicologici, le condizioni sperimentali create in laboratorio o in ambienti altamente controllati non sempre rispecchiano le dinamiche reali in cui i fenomeni si manifestano. L’uso di procedure standardizzate e compiti artificiali può semplificare notevolmente le variabili in gioco, a scapito della validità esterna: i risultati ottenuti potrebbero non essere direttamente trasferibili a contesti naturali o situazioni di vita quotidiana. Inoltre, se i partecipanti vengono selezionati per ragioni pratiche (ad esempio, studenti universitari reclutati su base volontaria), ciò limita ulteriormente la rappresentatività del campione, rendendo più difficile estendere le conclusioni a gruppi più eterogenei o a popolazioni diverse.\nRischio di semplificare eccessivamente i meccanismi causali ipotizzati\nL’inferenza causale – implicita o esplicita nella maggior parte delle ricerche in psicologia – mira a comprendere se e come un fattore influisca su un altro. Tuttavia, in contesti così complessi, i modelli causali proposti possono risultare eccessivamente semplificati, trascurando interazioni tra variabili, fattori contestuali o processi multilivello. Quando tali aspetti non vengono adeguatamente considerati, le conclusioni possono rivelarsi poco utili o non sufficientemente applicabili ai contesti reali.\nDistorsioni legate alla misurazione\nMolti costrutti di interesse psicologico (es. ansia, autostima, intelligenza) non sono direttamente osservabili, bensì misurati attraverso questionari, test o altre metodologie indirette. Tale approccio introduce possibili errori di misurazione e distorsioni legate allo strumento di valutazione. L’inferenza statistica deve quindi tenere conto di questa complessità, collegando in modo rigoroso le osservazioni empiriche ai costrutti teorici sottostanti.\n\nIn sintesi, la stima e l’inferenza statistica rappresentano strumenti fondamentali per trasformare i dati campionari in conoscenza generalizzabile, soprattutto in un contesto come quello psicologico, caratterizzato da un’elevata variabilità nei comportamenti e nei processi mentali. Da un lato, la metodologia quantitativa offre un quadro consolidato per gestire l’incertezza e testare ipotesi; dall’altro, è cruciale prestare attenzione alla qualità del campione, alla validità degli strumenti di misura e all’intrinseca complessità dei costrutti indagati.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#la-quantificazione-dellincertezza",
    "href": "chapters/key_notions/02_key_notions.html#la-quantificazione-dellincertezza",
    "title": "2  Concetti chiave",
    "section": "2.8 La Quantificazione dell’Incertezza",
    "text": "2.8 La Quantificazione dell’Incertezza\nLe considerazioni introduttive di questo capitolo mettono in evidenza come la gestione e la quantificazione dell’incertezza rappresentino un aspetto cruciale della stima e dell’inferenza statistica. Qualunque stima ottenuta da un campione è inevitabilmente soggetta a errore, poiché il campione costituisce soltanto una frazione della popolazione di riferimento. L’inferenza statistica offre gli strumenti necessari per quantificare tale incertezza, ad esempio tramite gli intervalli di confidenza (nell’approccio frequentista) o le distribuzioni a posteriori (nell’approccio bayesiano), consentendo di esprimere in modo rigoroso il grado di fiducia nelle conclusioni raggiunte.\nIn conclusione, la stima e l’inferenza statistica rappresentano strumenti essenziali per trasformare i dati empirici in conoscenza solida e applicabile. È tuttavia indispensabile avvalersene in maniera critica, tenendo sempre presenti le possibili distorsioni insite nel processo di raccolta e analisi dei dati. Ciò significa prestare particolare attenzione alla rappresentatività del campione, alla validità delle misurazioni e all’interpretazione corretta dei risultati, così da evitare generalizzazioni indebite o conclusioni fuorvianti.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#riflessioni-conclusive",
    "href": "chapters/key_notions/02_key_notions.html#riflessioni-conclusive",
    "title": "2  Concetti chiave",
    "section": "2.9 Riflessioni Conclusive",
    "text": "2.9 Riflessioni Conclusive\nL’analisi dei dati acquisisce valore solo quando è integrata con una solida teoria scientifica, che fornisce il contesto e il quadro interpretativo necessario per attribuire senso ai risultati. Ad esempio, osservare che un trattamento psicologico riduce i sintomi è un’osservazione empirica che, senza una teoria che chiarisca i meccanismi sottostanti, rimane priva di potere esplicativo. È la teoria che orienta il processo analitico, formulando ipotesi verificabili e offrendo interpretazioni che si inseriscono in un modello più ampio.\nIn definitiva, la relazione tra teoria e analisi dei dati è intrinsecamente circolare e dinamica: le teorie guidano la raccolta, l’analisi e l’interpretazione dei dati, mentre i dati, a loro volta, stimolano il perfezionamento e l’evoluzione delle teorie. Questo dialogo continuo è ciò che permette un progresso costante nella comprensione dei fenomeni psicologici.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#esercizi",
    "href": "chapters/key_notions/02_key_notions.html#esercizi",
    "title": "2  Concetti chiave",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nChe cos’è una spiegazione scientifica e in che modo si differenzia da una mera descrizione o previsione di un fenomeno?\nPerché, quando si parla di popolazione e campione, è fondamentale assicurarsi che il campione sia rappresentativo, e quali conseguenze possono derivare da un campione non rappresentativo?\nChe differenza c’è tra un parametro e una statistica, e perché in inferenza statistica si cerca di stimare il parametro sconosciuto a partire dalla statistica campionaria?\nCosa si intende per bias nella raccolta e interpretazione dei dati, e in che modo la consapevolezza dei possibili bias può migliorare la qualità della ricerca?\nPerché in psicologia e nelle scienze sociali risulta essenziale integrare l’analisi dei dati con un quadro teorico solido e coerente?\nQual è la differenza principale tra uno studio osservazionale e un esperimento, e perché la distinzione è importante per comprendere la causalità?\nChe ruolo svolgono i modelli scientifici in psicologia, e quali caratteristiche fondamentali dovrebbero possedere per essere considerati validi e utili?\nIn che modo l’analisi dei dati aiuta a passare dalle semplici correlazioni o tendenze osservate all’elaborazione di ipotesi e spiegazioni più profonde?\nChe differenza c’è tra variabili indipendenti e variabili dipendenti, e perché questa distinzione è cruciale per disegnare uno studio e interpretarne i risultati?\nPerché parlare di incertezza è inevitabile quando si utilizzano i dati di un campione, e come la statistica (frequentista o bayesiana) ci aiuta a gestirla?\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n1. Che cos’è una spiegazione scientifica e in che modo si differenzia da una mera descrizione o previsione di un fenomeno?\nUna spiegazione scientifica mira a individuare le cause e i meccanismi che generano o influenzano un fenomeno. Non si limita quindi a descrivere cosa accade o a prevedere ciò che potrebbe accadere (come una semplice correlazione o un modello predittivo), ma cerca di chiarire perché il fenomeno si verifica. Ad esempio, dire “i bambini con genitori laureati hanno migliori prestazioni scolastiche” è una descrizione (o previsione) utile; spiegare che ciò avviene a causa di un maggior sostegno nel percorso di studi, di un ambiente più ricco di stimoli culturali, o di un contesto socioeconomico facilitante, fornisce invece una spiegazione che va oltre la pura correlazione statistica.\n2. Perché, quando si parla di popolazione e campione, è fondamentale assicurarsi che il campione sia rappresentativo, e quali conseguenze possono derivare da un campione non rappresentativo?\nIl campione è il sottoinsieme di individui selezionati da una popolazione più ampia. Affinché i risultati di uno studio siano validi e generalizzabili, il campione deve rispecchiare le principali caratteristiche della popolazione (ad esempio in termini di età, genere, livello socioeconomico, ecc.). Se il campione non è rappresentativo (per esempio, se si reclutano solo studenti universitari per uno studio su tutta la popolazione italiana), possono emergere bias di selezione che rendono impossibile estendere correttamente i risultati a gruppi sociali diversi. Conseguenze tipiche di un campione non rappresentativo includono stime distorte dei parametri d’interesse, conclusioni fuorvianti e ridotta validità esterna della ricerca.\n3. Che differenza c’è tra un parametro e una statistica, e perché in inferenza statistica si cerca di stimare il parametro sconosciuto a partire dalla statistica campionaria?\n\nUn parametro è una caratteristica numerica della popolazione (ad esempio la media reale di un determinato tratto o la proporzione di individui con una certa caratteristica).\n\nUna statistica è una misura analoga, ma calcolata sul campione (ad esempio la media o la proporzione campionaria).\n\nPoiché in genere è impossibile o molto costoso misurare l’intera popolazione, si raccoglie un campione più piccolo e gestibile. La statistica del campione (ad es. la media campionaria) è quindi usata per stimare il parametro (ad es. la media della popolazione). L’obiettivo dell’inferenza statistica è fornire, insieme a questa stima, una misura dell’incertezza associata (per esempio un intervallo di confidenza), così da comprendere quanto la statistica campionaria potrebbe “avvicinarsi” al vero valore del parametro.\n4. Cosa si intende per bias nella raccolta e interpretazione dei dati, e in che modo la consapevolezza dei possibili bias può migliorare la qualità della ricerca?\nIl bias è un errore sistematico che altera i risultati di uno studio in una direzione specifica, dovuto a scelte o condizioni nel disegno della ricerca, nella selezione del campione, nella misurazione o nell’interpretazione dei dati. Ad esempio, se reclutiamo solo volontari particolarmente motivati a partecipare a una ricerca, potremmo ottenere risultati che sovrastimano un certo fenomeno e non rispecchiano la popolazione generale.\nEssere consapevoli di come i bias possano nascere aiuta i ricercatori a mitigarli (ad esempio, bilanciando il reclutamento dei partecipanti o rendendo anonima la compilazione di un questionario) e a tenere conto dei loro effetti quando si interpretano i risultati. Così, la ricerca risulta più affidabile e validamente interpretata.\n5. Perché in psicologia e nelle scienze sociali risulta essenziale integrare l’analisi dei dati con un quadro teorico solido e coerente?\nNelle scienze sociali e in psicologia, i fenomeni studiati sono spesso complessi e influenzati da molte variabili. I dati da soli, senza una teoria, forniscono soltanto una descrizione o una misurazione di ciò che accade in un dato momento. La teoria invece permette di:\n\nIdentificare le variabili rilevanti e formulare ipotesi specifiche;\n\nInterpretare i risultati, attribuendo un senso e un contesto alle relazioni osservate;\n\nComprendere i meccanismi causali e sviluppare spiegazioni che vadano oltre la pura descrizione.\n\nSenza un quadro teorico di riferimento, sarebbe difficile capire perché si osservano determinate relazioni e come possano cambiare in contesti diversi o in situazioni sperimentali alternative.\n6. Qual è la differenza principale tra uno studio osservazionale e un esperimento, e perché la distinzione è importante per comprendere la causalità?\n\nStudio osservazionale: Il ricercatore raccoglie i dati senza intervenire né manipolare alcuna variabile. Ad esempio, si misura il livello di stress delle persone e la loro produttività sul lavoro, senza modificare artificialmente il livello di stress. Questi studi mostrano correlazioni, ma è difficile stabilire con certezza relazioni di causa-effetto.\n\nEsperimento: Il ricercatore manipola una o più variabili (variabili indipendenti) e controlla le condizioni, ad esempio assegnando in modo casuale i partecipanti a un gruppo di trattamento e a uno di controllo. Ciò facilita la comprensione di eventuali nessi causali, perché la randomizzazione e il controllo degli altri fattori riducono il rischio che variabili esterne influenzino i risultati.\n\nLa distinzione è cruciale perché, nei fenomeni complessi della psicologia, gli studi osservazionali possono suggerire ipotesi di relazione, ma di solito occorre un disegno sperimentale (quando possibile) per trarre conclusioni più solide sulla causalità.\n7. Che ruolo svolgono i modelli scientifici in psicologia, e quali caratteristiche fondamentali dovrebbero possedere per essere considerati validi e utili?\nI modelli scientifici in psicologia forniscono una struttura concettuale e spesso formale (matematica o simulativa) per rappresentare e spiegare processi mentali e comportamentali. Servono a:\n\nOrganizzare osservazioni ed evidenze in un sistema coerente;\n\nFare previsioni verificabili empiricamente;\n\nGuidare l’interpretazione di nuovi dati e la progettazione di futuri studi.\n\nCaratteristiche di un buon modello sono:\n\nCoerenza descrittiva (rappresenta fedelmente il fenomeno);\n\nCapacità predittiva (prevede correttamente i risultati di situazioni nuove);\n\nSupporto empirico (confermato dai dati raccolti rigorosamente);\n\nFalsificabilità (dev’essere possibile smentirlo con evidenze contrarie);\n\nParsimonia (non dev’essere inutilmente complicato);\n\nGeneralizzabilità (applicabile a diversi contesti e situazioni);\n\nUtilità pratica (fornisce indicazioni utili per interventi o comprensione teorica).\n\n8. In che modo l’analisi dei dati aiuta a passare dalle semplici correlazioni o tendenze osservate all’elaborazione di ipotesi e spiegazioni più profonde?\nL’analisi dei dati non si limita a segnalare che “due variabili sono associate” (correlazioni), ma offre:\n\nStrumenti per isolare l’effetto di una variabile sulle altre (regressioni multiple, modelli a effetti misti, ecc.);\n\nMetodologie per la verifica di ipotesi specifiche sulla direzione e sulla natura delle relazioni (ad es. test statistici o modelli di mediazione-moderazione in psicologia);\n\nIndicatori dell’incertezza e della robustezza dei risultati (intervalli di confidenza, analisi della potenza, analisi bayesiane).\n\nCon questi strumenti, i ricercatori possono integrare i risultati quantitativi con le teorie esistenti, sviluppare nuove ipotesi su meccanismi causali e proporre spiegazioni più articolate su come e perché le variabili si influenzino reciprocamente.\n9. Che differenza c’è tra variabili indipendenti e variabili dipendenti, e perché questa distinzione è cruciale per disegnare uno studio e interpretarne i risultati?\n\nVariabile indipendente (VI): è quella che si sospetta abbia un effetto su un’altra variabile, o che si desidera manipolare in un disegno sperimentale (per esempio, l’introduzione di un nuovo metodo di studio).\n\nVariabile dipendente (VD): è la variabile che si misura per valutare l’eventuale effetto della variabile indipendente (ad esempio, i risultati di un test di apprendimento).\nLa distinzione è basilare perché chiarisce la direzione del rapporto di interesse e permette di formulare ipotesi come “VI → VD” (es. “il nuovo metodo di studio migliora i risultati del test”). Sbagliare a identificare quali sono le variabili indipendenti e dipendenti può portare a disegni di ricerca confusi e interpretazioni errate.\n\n10. Perché parlare di incertezza è inevitabile quando si utilizzano i dati di un campione, e come la statistica (frequentista o bayesiana) ci aiuta a gestirla?\nQuando raccogliamo dati da un campione (necessariamente limitato), non possiamo osservare l’intera popolazione. Questo introduce un margine di incertezza su quanto la misura campionaria (statistica) rispecchi il parametro reale della popolazione. Inoltre, possono sempre esserci fattori non controllati o errori di misurazione.\n\nNell’approccio frequentista, l’incertezza è gestita tramite concetti come gli intervalli di confidenza e i valori p, che quantificano la probabilità di osservare determinati risultati assumendo determinate ipotesi (per es. l’ipotesi nulla).\n\nNell’approccio bayesiano, l’incertezza è modellata tramite distribuzioni di probabilità (posteriori) che incorporano sia i dati osservati sia le informazioni pregresse (priors).\n\nEntrambi gli approcci forniscono metodologie per valutare quanto ci si possa fidare di una data conclusione, riconoscendo il carattere aleatorio e parziale dei dati e rendendo esplicito il grado di incertezza.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_key_notions.html#bibliografia",
    "href": "chapters/key_notions/02_key_notions.html#bibliografia",
    "title": "2  Concetti chiave",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.\n\n\nHuntington-Klein, N. (2021). The effect: An introduction to research design and causality. Chapman; Hall/CRC.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nMurray, E. J., & Carr, K. C. (2024). Measuring Racial Sentiment Using Social Media Is Harder Than It Seems. Epidemiology, 35(1), 60–63.\n\n\nNobles, M. (2000). Shades of citizenship: Race and the census in modern politics. Stanford University Press.\n\n\nSteinman, R. M., Pizlo, Z., & Pizlo, F. J. (2000). Phi is not beta, and why Wertheimer’s discovery launched the Gestalt revolution. Vision research, 40(17), 2257–2264.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_design.html",
    "href": "chapters/key_notions/03_design.html",
    "title": "3  Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "",
    "text": "3.1 Introduzione\nQuesto capitolo si propone di approfondire i concetti introdotti in precedenza, concentrandosi in particolare sul processo di campionamento e sull’importanza delle diverse metodologie di ricerca in psicologia. Dopo aver compreso il ruolo fondamentale dei dati nella verifica delle teorie, emerge una questione cruciale: come vengono raccolti questi dati?\nLa raccolta dei dati non è un’attività neutra o priva di conseguenze metodologiche. I dati, infatti, non hanno lo stesso valore scientifico a seconda di come vengono ottenuti. Alcune modalità di raccolta generano informazioni preziose e utili per testare le teorie, mentre altre possono produrre risultati fuorvianti, distorti o addirittura dannosi per la validità della ricerca.\nIl metodo scientifico fornisce un quadro di riferimento che delinea le caratteristiche ideali di un processo di raccolta dati in grado di produrre informazioni valide e affidabili. Tuttavia, le prescrizioni del metodo scientifico sono per loro natura generali e astratte. Tradurre questi principi in procedure concrete e applicarli efficacemente in un contesto di ricerca specifico rappresenta una sfida significativa.\nQuesto passaggio, che collega la teoria alla pratica, dipende dalle risorse disponibili, dalla competenza metodologica e dalla creatività del ricercatore. La capacità di ideare e attuare strategie di raccolta dati adeguate al contesto specifico della ricerca è fondamentale per garantire la qualità e la validità dei risultati ottenuti. In questo capitolo, approfondiremo i principi del campionamento e introdurremo i concetti chiave relativi ai disegni di ricerca.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_design.html#popolazioni-e-campioni",
    "href": "chapters/key_notions/03_design.html#popolazioni-e-campioni",
    "title": "3  Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "3.2 Popolazioni e Campioni",
    "text": "3.2 Popolazioni e Campioni\nNella ricerca scientifica, è essenziale distinguere tra popolazione e campione.\n\nPopolazione: rappresenta l’insieme completo di unità che condividono una o più caratteristiche specifiche oggetto di studio. La dimensione della popolazione è indicata con N.\nCampione: è un sottoinsieme della popolazione, di dimensione n. L’obiettivo del campionamento è ottenere un campione rappresentativo, ovvero un sottoinsieme che rifletta accuratamente le caratteristiche della popolazione di riferimento.\n\n\n3.2.1 Metodi di Campionamento\nEsistono diverse strategie per selezionare un campione rappresentativo da una popolazione. Queste strategie si dividono principalmente in due categorie: campionamento probabilistico e campionamento non probabilistico.\n\n3.2.1.1 Campionamento Probabilistico\nNel campionamento probabilistico, ogni unità della popolazione ha una probabilità nota e non nulla di essere inclusa nel campione. Questo approccio minimizza il rischio di distorsioni sistematiche (bias) e consente di stimare l’errore di campionamento.\n\nCampionamento Casuale Semplice (CCS):\nOgni unità della popolazione ha la stessa probabilità di essere inclusa nel campione. Questo metodo richiede una lista completa di tutte le unità della popolazione, nota come frame di campionamento. La selezione può avvenire con o senza reinserimento. Il CCS senza reinserimento è il più comune nella pratica, ma nelle ricerche psicologiche è raramente utilizzabile a causa della difficoltà di ottenere un frame completo della popolazione.\nCampionamento Stratificato:\nLa popolazione viene divisa in strati (H), ovvero sottogruppi omogenei in base a una o più variabili rilevanti (es. età, genere, regione geografica). Da ogni strato h viene estratto un campione casuale semplice di dimensione nh. Questo metodo può essere:\n\nProporzionale: la dimensione del campione in ogni strato è proporzionale alla dimensione dello strato nella popolazione.\nNon proporzionale: utilizzato per sovra-campionare gruppi minoritari, consentendo analisi dettagliate di sottogruppi altrimenti poco rappresentati.\nNelle ricerche psicologiche, il campionamento stratificato è utile per garantire che variabili come il genere o l’età siano adeguatamente rappresentate, ma può essere complesso da implementare.\n\nCampionamento a Grappolo (Cluster Sampling):\nLa popolazione viene suddivisa in grappoli (cluster), che rappresentano gruppi eterogenei (es. scuole, ospedali, quartieri). Vengono selezionati casualmente alcuni grappoli, includendo tutte le unità al loro interno. Questo metodo è economico e pratico, specialmente in contesti dove accedere all’intera popolazione è difficile. Tuttavia, la precisione può essere ridotta se i grappoli differiscono notevolmente tra loro.\nCampionamento Multistadio:\nCombinazione di campionamento a grappolo e CCS. Vengono selezionati casualmente alcuni grappoli e, successivamente, all’interno di ciascun grappolo, si estrae un campione casuale di unità. Questo metodo bilancia costi e precisione, risultando particolarmente adatto a studi su larga scala, ad esempio a livello nazionale.\n\n\n\n3.2.1.2 Campionamento Non Probabilistico\nNel campionamento non probabilistico, la probabilità di inclusione di ogni unità nel campione non è nota. Questo approccio è spesso adottato per ragioni di praticità o quando non è disponibile un frame di campionamento. Tuttavia, aumenta il rischio di distorsioni e limita la generalizzabilità dei risultati alla popolazione.\n\nCampionamento di Convenienza:\nÈ il metodo più diffuso nella ricerca psicologica. I partecipanti vengono selezionati in base alla loro facile accessibilità (es., studenti universitari, volontari). Questo metodo è rapido ed economico, ma introduce significativi bias di selezione, poiché il campione non è rappresentativo della popolazione generale.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_design.html#il-campionamento-nella-ricerca-psicologica",
    "href": "chapters/key_notions/03_design.html#il-campionamento-nella-ricerca-psicologica",
    "title": "3  Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "3.3 Il Campionamento nella Ricerca Psicologica",
    "text": "3.3 Il Campionamento nella Ricerca Psicologica\nIl tema del campionamento nella ricerca psicologica è cruciale perché influisce in modo diretto sulla validità esterna e sulla generalizzabilità dei risultati. Nella pratica, però, l’ideale metodologico del campionamento probabilistico è spesso difficile da perseguire, a causa di vincoli di tempo, di risorse economiche e di accessibilità ai partecipanti (Henrich et al., 2010a). Per queste ragioni, molti studi in psicologia fanno ricorso al campionamento di convenienza, che prevede la selezione dei partecipanti sulla base della loro facile reperibilità, come studenti universitari o volontari reclutati online.\n\n3.3.1 Perché il Campionamento di Convenienza è così Diffuso?\n\nVincoli di Risorse\nLa ricerca psicologica, specie in ambito accademico, spesso non dispone di finanziamenti sufficienti per condurre campionamenti su larga scala. Reclutare partecipanti rappresentativi di un’intera popolazione richiederebbe budget, logistica e tempo ben superiori a quelli generalmente disponibili (Peterson & Merunka, 2014). Il campionamento di convenienza diventa quindi un compromesso “necessario” per poter portare avanti gli studi.\nAccessibilità ai Partecipanti\nNel contesto universitario, gli studenti rappresentano il bacino più facilmente accessibile e motivato a partecipare a studi psicologici, talvolta in cambio di crediti formativi o rimborsi simbolici (Sears, 1986). In altri contesti, si ricorre a piattaforme online che forniscono volontari in tempi brevi, consentendo di raccogliere dati in modo rapido e a costi contenuti.\nRapidità di Raccolta Dati\nIl vantaggio principale del campionamento di convenienza è la possibilità di raccogliere dati in tempi molto più ridotti rispetto a strategie di campionamento probabilistico. Tale rapidità può risultare essenziale per studi pilota o ricerche che richiedono analisi preliminari di fenomeni ancora poco esplorati.\n\n\n\n3.3.2 Limiti e Implicazioni\nIl ricorso al campionamento di convenienza comporta inevitabilmente dei limiti in termini di rappresentatività del campione. Gli individui che si prestano a partecipare a uno studio potrebbero avere caratteristiche socio-demografiche, cognitive o motivazionali peculiari (ad esempio, essere più giovani, con livelli di istruzione più alti, culturalmente più omogenei), portando ad un fenomeno noto come “campioni WEIRD” [Western, Educated, Industrialized, Rich, Democratic; Henrich et al. (2010b)]. Ciò significa che i risultati ottenuti potrebbero non riflettere adeguatamente l’intera variabilità della popolazione umana.\n\nGeneralizzabilità Ridotta: Uno studio condotto su studenti di psicologia in un’università europea può non essere applicabile a individui di diverse fasce di età, provenienti da altre aree geografiche o con retroterra socio-culturali differenti.\nBias di Selezione: I partecipanti volontari, specialmente online, possono essere attratti dallo studio per ragioni specifiche (ad esempio, curiosità verso la psicologia, tempo libero a disposizione, motivazione a ottenere un compenso), introducendo distorsioni non presenti nella popolazione più ampia.\nLimitazioni nei Risultati: Se i processi psicologici oggetto di indagine sono influenzati da cultura, età o altre variabili, lo studio potrebbe non catturare in modo esaustivo la complessità del fenomeno.\n\n\n\n3.3.3 Perché in Psicologia è (in Parte) Accettabile\nSebbene il campionamento di convenienza costituisca un limite, è bene ricordare che molti fenomeni psicologici presentano elementi di base che sono relativamente generali o universali nell’essere umano [ad esempio, i processi di percezione, l’apprendimento di base, alcune dinamiche emotive e motivazionali; cfr. Tooby & Cosmides (2005)]. Ciò significa che, entro certi confini, studiare un campione di convenienza può comunque fornire indicazioni utili e trasferibili ad altre popolazioni. Inoltre, buona parte delle ricerche in psicologia mira ad approfondire meccanismi e processi interna corporis – cioè aspetti di natura cognitiva, emotiva o sociale che, pur potendo variare in intensità o manifestazione, hanno basi comuni tra gli individui.\nIn altre parole, esiste un trade-off tra la necessità di disporre di campioni rappresentativi per garantire la massima generalizzabilità e la specificità dei fenomeni psicologici, che talvolta risiedono in processi considerati “universali”. Se lo scopo di uno studio è quello di testare meccanismi cognitivi di base (per esempio, l’elaborazione di stimoli visivi o di memoria), un campione di studenti potrebbe comunque fornire dati sufficientemente robusti, purché si riconoscano i limiti del contesto di raccolta.\n\n3.3.3.1 Considerazioni Etiche e Pratiche\nTalvolta, per ragioni etiche, non è semplice reperire partecipanti da particolari fasce di popolazione (ad esempio minori, pazienti clinici, soggetti in contesti istituzionali). In alcune ricerche, poi, l’uso di questionari lunghi o procedure sperimentali intense rende difficile attrarre volontari al di fuori dell’ambiente universitario. Da questo punto di vista, avere un bacino di partecipanti noti (ad es. studenti di psicologia) agevola la raccolta dei dati.\n\nRicompense: Spesso i dipartimenti offrono crediti formativi o piccoli compensi ai partecipanti, innescando un circolo virtuoso di interesse per la ricerca.\nLibertà di rifiuto: Le università dispongono di comitati etici che tutelano i diritti dei partecipanti, garantendo che anche i reclutamenti “di comodo” rispettino i principi etici fondamentali (consenso informato, anonimato, diritto al recesso, ecc.).\n\n\n\n\n3.3.4 Come Mitigare i Limiti del Campionamento di Convenienza\n\nReplicazione Incrociata (Cross-Replication)\nUn metodo efficace per aumentare la validità dei risultati è replicare lo stesso studio su campioni differenti, di età diversa o provenienti da contesti socio-culturali eterogenei. Ripetere la ricerca in più contesti e ottenere risultati simili fornisce evidenza della generalizzabilità del fenomeno.\nCampionamento Diversificato\nAnche se si ricorre a un campionamento di convenienza, si può tentare di diversificare la provenienza dei partecipanti (ad esempio, includendo studenti di diverse facoltà o atenei, oppure reclutando volontari su piattaforme online internazionali). Un campione che rifletta almeno in parte una maggiore varietà di background socio-culturali è comunque preferibile alla selezione di un solo gruppo omogeneo.\nCaratterizzazione Dettagliata del Campione\nÈ fondamentale fornire informazioni precise su età, genere, livello di istruzione, estrazione socio-culturale e altre variabili rilevanti. Questo permette ai lettori di valutare in che misura i risultati dello studio possano essere trasferiti ad altre popolazioni.\nIntegrazione di Metodi di Campionamento Misti\nAlcuni ricercatori scelgono di integrare campionamenti non probabilistici con piccole porzioni di campionamento più stratificato o di selezionare sotto-campioni rappresentativi per determinati sottogruppi. Non si tratta di un vero e proprio campionamento probabilistico, ma può comunque migliorare la robustezza dei risultati rispetto al puro campionamento di convenienza.\n\n\n\n3.3.5 Considerazioni Economiche e Future Prospettive\nAlla luce di questi punti, appare chiaro che il ricorso a metodi di campionamento probabilistici più rigorosi (campionamento casuale semplice, stratificato o a grappolo) richiederebbe aumenti significativi nei finanziamenti e un impegno logistico maggiore. Ciò non è sempre fattibile in contesti di ricerca accademica o quando i progetti sono condotti con budget limitati.\nD’altro canto, i finanziamenti aggiuntivi permetterebbero di:\n\nReclutare campioni più ampi e diversificati, ad esempio attraverso agenzie di rilevazione professionali o sondaggi a livello nazionale.\n\nImplementare studi longitudinali su popolazioni geograficamente distribuite, riducendo il rischio di raccogliere dati esclusivamente da aree limitrofe ai centri di ricerca.\nSostenere progetti multicentrici a livello internazionale, che consentono di testare l’universalità o la specificità culturale dei fenomeni psicologici.\n\nFino a quando queste risorse non saranno disponibili su larga scala, il campionamento di convenienza rimarrà la soluzione più diffusa e “realistica” nella ricerca psicologica. Tuttavia, non bisogna considerarlo esclusivamente un limite: la specificità dei fenomeni psicologici, legati a processi condivisi tra gli individui, talvolta permette di estrarre conclusioni valide anche da campioni meno rappresentativi, purché si utilizzino adeguate cautele nell’interpretazione e si persegua la replicazione come prassi consolidata.\nIn sintesi, il campionamento di convenienza è una strategia inevitabile nell’attuale panorama della ricerca psicologica, caratterizzato da forti limitazioni di risorse, ma in molti casi risulta comunque sufficiente per investigare dinamiche e processi psicologici di base. L’auspicio per il futuro è di poter disporre di finanziamenti e collaborazioni che permettano di ampliare il raggio d’azione e la diversità dei partecipanti, rafforzando la validità e la generalizzabilità della produzione scientifica in psicologia.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_design.html#metodologia-sperimentale",
    "href": "chapters/key_notions/03_design.html#metodologia-sperimentale",
    "title": "3  Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "3.4 Metodologia Sperimentale",
    "text": "3.4 Metodologia Sperimentale\n\n3.4.1 Principi Fondamentali del Disegno Sperimentale\n\nControllo\nL’obiettivo è ridurre l’influenza di variabili confondenti (Z) sulla relazione tra la variabile indipendente (X) e quella dipendente (Y). Utilizzare un gruppo di controllo consente di stabilire un riferimento per valutare l’effetto del trattamento.\nRandomizzazione\nL’assegnazione casuale dei partecipanti ai gruppi sperimentali distribuisce le variabili confondenti in modo equilibrato tra i gruppi, aumentando la credibilità dell’inferenza causale tra X e Y. Questo approccio garantisce che eventuali differenze osservate siano attribuibili al trattamento e non a fattori esterni.\n\n\n\n3.4.2 Strategie di Mitigazione dei Bias\n\nCecità (Blinding)\nStrumento chiave per minimizzare l’influenza di aspettative e pregiudizi, sia nei partecipanti che nei ricercatori. Le principali modalità includono:\n\nCecità singola: I partecipanti non sono consapevoli del trattamento assegnato.\nCecità doppia: Sia i partecipanti che i ricercatori che interagiscono direttamente con loro non conoscono l’assegnazione dei trattamenti.\nCecità tripla: Né i partecipanti, né i ricercatori, né gli analisti dei dati sono a conoscenza dei trattamenti durante la raccolta e l’analisi dei dati.\n\nGruppo di Controllo\nL’introduzione di un gruppo che riceve un trattamento inerte (controllo) consente di isolare gli effetti psicologici legati alle aspettative dei partecipanti, distinguendoli dagli effetti specifici del trattamento.\nStandardizzazione delle Procedure\nGarantire che tutte le condizioni sperimentali, eccetto la variabile manipolata, siano mantenute costanti tra i gruppi. Questo riduce la variabilità non controllata, migliorando la comparabilità dei risultati.\n\n\n\n3.4.3 Nota sulla Replicazione\nLa replicazione degli esperimenti non è una caratteristica intrinseca del metodo sperimentale, ma rappresenta una pratica fondamentale nella scienza per verificare l’affidabilità e la generalizzabilità dei risultati. Si distingue in:\n\nReplicazione diretta: Ripetere lo stesso studio con le stesse condizioni.\nReplicazione concettuale: Ripetere lo studio modificando aspetti specifici per testare la robustezza del risultato.\n\n\n\n3.4.4 Tipologie di Disegni Sperimentali\n\nDisegno a Gruppi Indipendenti (Between-Subjects):\nI partecipanti vengono assegnati a un unico gruppo e sono esposti a una sola condizione sperimentale. Questo disegno è utile quando l’esposizione multipla potrebbe introdurre confondenti, ma richiede un campione più ampio per raggiungere lo stesso livello di precisione.\nDisegno a Misure Ripetute (Within-Subjects):\nGli stessi partecipanti vengono esposti a tutte le condizioni sperimentali. Questo approccio riduce la variabilità tra soggetti, migliorando la precisione delle stime. Tuttavia, richiede attenzione nel controllare gli effetti di ordine, come affaticamento o apprendimento, spesso attraverso il bilanciamento dell’ordine di presentazione dei trattamenti.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_design.html#studi-osservazionali",
    "href": "chapters/key_notions/03_design.html#studi-osservazionali",
    "title": "3  Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "3.5 Studi Osservazionali",
    "text": "3.5 Studi Osservazionali\nGli studi osservazionali possono essere classificati in:\n\nStudi Trasversali (Cross-Sectional)\nI dati vengono raccolti in un singolo momento. Utili per stimare la prevalenza di una condizione, ma non permettono di stabilire relazioni causali.\nStudi di Coorte (Cohort Studies)\nUn gruppo di individui (coorte) viene seguito nel tempo per osservare l’incidenza di un evento. Permettono di studiare la relazione tra esposizione e outcome, ma possono essere costosi e richiedere molto tempo.\nStudi Caso-Controllo (Case-Control Studies)\nVengono confrontati individui con una determinata condizione (casi) con individui senza la condizione (controlli) per identificare possibili fattori di rischio. Utili per studiare malattie rare, ma soggetti a bias di selezione e di ricordo.\n\nLe principali limitazioni degli studi osservazionali sono la presenza di variabili confondenti e la difficoltà di stabilire relazioni causali.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_design.html#riflessioni-conclusive",
    "href": "chapters/key_notions/03_design.html#riflessioni-conclusive",
    "title": "3  Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "3.6 Riflessioni Conclusive",
    "text": "3.6 Riflessioni Conclusive\nNel corso di questo capitolo, abbiamo esplorato l’importanza del campionamento e delle diverse strategie di ricerca in psicologia, mettendo in luce i vincoli metodologici e le implicazioni derivanti da scelte spesso guidate dalle risorse a disposizione. Se da un lato i metodi di campionamento probabilistico garantiscono maggiore controllo sulla rappresentatività del campione, dall’altro, la realtà accademica e il contesto operativo di molti studi psicologici spingono verso soluzioni di comodo, inevitabilmente limitanti ma non per questo prive di valore scientifico.\nLe complessità intrinseche nello studio di fenomeni psicologici – spesso universali e al tempo stesso influenzati da variabili culturali e individuali – ci ricordano quanto sia importante mantenere un equilibrato senso critico. Da un punto di vista metodologico, l’esigenza di replicare gli studi in più contesti rimane la prassi fondamentale per rafforzare la credibilità dei risultati. Altrettanto cruciale è la volontà di caratterizzare in modo trasparente i propri campioni, rendendo chiaro in che misura siano (o non siano) rappresentativi della popolazione d’interesse. In tal modo, la comunità scientifica può valutare con maggiore consapevolezza la trasferibilità delle conclusioni a contesti diversi.\nUn ulteriore spunto di riflessione riguarda la tensione tra la desiderabilità di disegni di ricerca ideali (con campioni estesi e probabilistici) e le inevitabili restrizioni di tempo e budget. Se l’implementazione di studi su larga scala o a livello multicentrico consentirebbe di cogliere le sfumature culturali e socio-demografiche dei fenomeni, è altrettanto vero che, nel panorama attuale, molte ricerche non potrebbero essere realizzate senza ricorrere a partecipanti di più facile accesso, come gli studenti universitari o i volontari online. Tale flessibilità operativa può comunque produrre conoscenza significativa, a condizione che il ricercatore rimanga vigile rispetto ai possibili bias introdotti.\nIn definitiva, l’invito a chiunque conduca ricerche psicologiche è quello di coltivare una mentalità aperta, volta a bilanciare i limiti contingenti (economici, logistici, etici) con la necessità di mantenere standard metodologici solidi. Ciò implica sfruttare le potenzialità dell’integrazione tra disegni sperimentali e osservazionali, prestare attenzione alle forme di bias e, soprattutto, adottare la replicazione come pratica sistematica. Solo attraverso questa sinergia fra rigore scientifico e consapevolezza delle risorse disponibili è possibile far progredire la disciplina su basi empiriche sempre più solide e generalizzabili.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_design.html#esercizi",
    "href": "chapters/key_notions/03_design.html#esercizi",
    "title": "3  Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nPerché la fase di raccolta dei dati è considerata “non neutrale” e quali conseguenze può avere sull’affidabilità dei risultati di una ricerca psicologica?\nIn che modo i diversi metodi di campionamento (probabilistico vs. non probabilistico) influiscono sulla generalizzabilità delle conclusioni di uno studio e quali situazioni giustificano l’uso dell’uno o dell’altro?\nQuali sono i principali rischi nell’adottare un campionamento di convenienza in ricerche psicologiche, e quali strategie si possono utilizzare per mitigare questi rischi?\nIn che modo la randomizzazione e l’uso di gruppi di controllo supportano l’inferenza causale in un disegno sperimentale, e perché queste caratteristiche sono spesso più difficili da mantenere negli studi osservazionali?\nQuali sono i principali criteri da considerare quando si valuta la validità di uno studio in termini di campionamento, disegno di ricerca e replicabilità?\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n1. Perché la fase di raccolta dei dati è considerata “non neutrale” e quali conseguenze può avere sull’affidabilità dei risultati di una ricerca psicologica?\nLa raccolta dei dati non è mai un processo completamente neutrale perché comporta scelte metodologiche e pratiche che possono influenzare la qualità e la natura delle informazioni ottenute. Ad esempio:\n\nSelezione del campione: Scegliere chi includere o escludere nella ricerca incide sulla rappresentatività del campione. Un campione non rappresentativo può produrre risultati distorti e difficilmente generalizzabili.\n\nModalità di somministrazione degli strumenti: La maniera in cui vengono somministrati questionari, test o interviste può influire sulle risposte dei partecipanti (per esempio, differenze tra somministrazione online vs. cartacea, questionari anonimi vs. non anonimi, ecc.).\n\nContesto e tempistiche: Il contesto ambientale (es., rumori, distrazioni) o il momento in cui i dati vengono raccolti (es., in prossimità di esami universitari) possono influenzare lo stato emotivo o motivazionale dei partecipanti.\n\nCome conseguenza, tutte queste variabili possono introdurre bias – ossia distorsioni sistematiche – che compromettono l’affidabilità e la validità dei risultati, rendendo l’interpretazione dei dati più complessa e potenzialmente fuorviante. In altre parole, se la fase di raccolta dati non è accuratamente progettata e condotta, la ricerca potrebbe fornire conclusioni scorrette o di limitata utilità scientifica.\n2. In che modo i diversi metodi di campionamento (probabilistico vs. non probabilistico) influiscono sulla generalizzabilità delle conclusioni di uno studio e quali situazioni giustificano l’uso dell’uno o dell’altro?\n\nCampionamento probabilistico:\n\nOgni unità della popolazione ha una probabilità nota e non nulla di essere selezionata.\n\nMetodi come il campionamento casuale semplice, stratificato o a grappolo forniscono un quadro più solido per stimare l’errore di campionamento e minimizzare i bias.\n\nI risultati ottenuti sono, in linea di massima, più facilmente generalizzabili all’intera popolazione di riferimento.\n\nÈ preferibile in studi di larga scala, in cui esiste un buon frame di campionamento (lista esaustiva della popolazione) e le risorse (tempo, fondi) consentono di implementare un disegno rigoroso.\n\nCampionamento non probabilistico:\n\nLa probabilità di inclusione di un’unità non è nota, per cui non si possono calcolare in modo rigoroso le stime di errore.\n\nIl metodo più comune è il campionamento di convenienza, in cui vengono reclutate persone facilmente accessibili (es., studenti universitari, volontari, piattaforme online).\n\nLa generalizzabilità dei risultati è ridotta, poiché il campione potrebbe non rispecchiare le caratteristiche della popolazione di interesse.\n\nÈ spesso utilizzato per studi esplorativi, ricerche a budget limitato o quando non si dispone di un elenco completo della popolazione.\n\n\nIn sintesi, il campionamento probabilistico è preferibile quando si mira a ottenere risultati solidi e generalizzabili a una popolazione più ampia e le condizioni logistiche lo consentono. Il campionamento non probabilistico, invece, è giustificato in studi preliminari, in situazioni in cui la popolazione non è ben definita o difficilmente accessibile, o quando si hanno vincoli di risorse che rendono impraticabile un campionamento probabilistico.\n3. Quali sono i principali rischi nell’adottare un campionamento di convenienza in ricerche psicologiche, e quali strategie si possono utilizzare per mitigare questi rischi?\n\nPrincipali rischi:\n\nBias di selezione: I partecipanti reclutati con metodi di convenienza (ad es. studenti di psicologia) potrebbero non rispecchiare l’eterogeneità della popolazione generale, limitando la generalizzabilità dei risultati.\n\nOmogeneità del campione: Se il campione è molto omogeneo (per età, livello di istruzione, contesto culturale), diventa difficile estendere le conclusioni a gruppi con caratteristiche diverse.\n\nAutoselezione: I volontari che si offrono di partecipare potrebbero differire sistematicamente da coloro che non partecipano (ad esempio, maggiore interesse per il tema della ricerca o per la ricompensa economica offerta).\n\nStrategie di mitigazione:\n\nSovra-campionamento: Includere deliberatamente più partecipanti appartenenti a gruppi minoritari o sottorappresentati, per disporre di sottocampioni più completi.\n\nReplicazione: Ripetere l’esperimento con campioni diversi (per età, contesto geografico, cultura) per verificare se i risultati si mantengono coerenti.\n\nDescrizione dettagliata del campione: Fornire informazioni precise sulle caratteristiche sociodemografiche (età, genere, livello di istruzione, ecc.) in modo che altri ricercatori o lettori possano valutare la trasferibilità dei risultati.\n\nCautela nell’interpretazione: Esplicitare nelle conclusioni i limiti relativi alla natura del campionamento e invitare a considerare possibili fattori confondenti legati alla non rappresentatività del campione.\n\n\n4. In che modo la randomizzazione e l’uso di gruppi di controllo supportano l’inferenza causale in un disegno sperimentale, e perché queste caratteristiche sono spesso più difficili da mantenere negli studi osservazionali?\n\nRandomizzazione:\n\nAssegna i partecipanti ai gruppi sperimentali (condizione sperimentale vs. condizione di controllo) in maniera casuale.\n\nGarantisce che variabili potenzialmente confondenti vengano distribuite equamente tra i gruppi, aumentando la probabilità che eventuali differenze nelle misure di esito (variabile dipendente) siano dovute esclusivamente alla manipolazione sperimentale (variabile indipendente).\n\nQuesto processo riduce l’influenza di fattori esterni non misurati o non conosciuti, favorendo un’inferenza causale più solida.\n\nGruppi di controllo:\n\nConsentono di confrontare i risultati di chi riceve il trattamento/intervento con chi non lo riceve (o riceve un trattamento placebo).\n\nAiutano a isolare l’effetto “vero” del trattamento dalle variazioni dovute a effetti psicologici (ad es. effetto placebo), al passare del tempo o a eventi esterni.\n\nDifficoltà negli studi osservazionali:\n\nNon prevedono la manipolazione diretta di una variabile indipendente né l’assegnazione casuale dei partecipanti: le persone “si assegnano da sole” alle condizioni.\n\nManca il controllo sperimentale: non è sempre possibile includere un gruppo di controllo o applicare procedure di randomizzazione.\n\nLe variabili confondenti possono agire in modo non controllabile e compromettere l’interpretazione causale: anche con analisi statistiche sofisticate, è difficile escludere del tutto la presenza di fattori esterni che influenzano la relazione tra esposizione e outcome.\n\n\nPer questi motivi, gli studi sperimentali (con randomizzazione e controllo) rimangono il metodo privilegiato per stabilire nessi di causalità, mentre gli studi osservazionali servono principalmente a generare ipotesi, descrivere fenomeni, o analizzare relazioni di associazione più che di causalità.\n5. Quali sono i principali criteri da considerare quando si valuta la validità di uno studio in termini di campionamento, disegno di ricerca e replicabilità?\n\nRappresentatività del campione:\n\nIl campione rispecchia realmente le caratteristiche della popolazione di interesse?\n\nÈ stato usato un metodo di campionamento appropriato (probabilistico vs. non probabilistico)?\n\nControllo e randomizzazione (validità interna):\n\nLo studio ha previsto un disegno sperimentale con assegnazione casuale e gruppo di controllo?\n\nQuanto è efficace il controllo delle variabili confondenti (bias di selezione, aspettative, effetto placebo, ecc.)?\n\nGeneralizzabilità o validità esterna:\n\nI risultati dello studio sono applicabili oltre il contesto specifico in cui è stato condotto?\n\nVi sono limitazioni dovute all’uso di un campione di convenienza o di un contesto culturale molto particolare?\n\nStandardizzazione delle procedure:\n\nLe istruzioni, i tempi di raccolta dati, i materiali utilizzati sono stati gestiti in modo uniforme per tutti i partecipanti?\n\nReplicabilità:\n\nÈ possibile ripetere lo studio (replicazione diretta o concettuale) e ottenere risultati simili?\n\nGli autori forniscono informazioni sufficienti (materiali, protocolli, analisi) per consentire la replicazione?\n\nChiarezza nell’esposizione dei limiti:\n\nGli autori discutono apertamente le limitazioni del metodo di campionamento o del disegno di ricerca e suggeriscono possibili miglioramenti per studi futuri?\n\n\nNel complesso, una valutazione critica di uno studio deve integrare tutti questi aspetti (campionamento, disegno, replicabilità) per stabilire in che misura i risultati siano solidi, attendibili e utilmente generalizzabili.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_design.html#bibliografia",
    "href": "chapters/key_notions/03_design.html#bibliografia",
    "title": "3  Campionamento, metodologia sperimentale e studi osservazionali",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nHenrich, J., Heine, S. J., & Norenzayan, A. (2010a). Most people are not WEIRD. Nature, 466(7302), 29–29.\n\n\nHenrich, J., Heine, S. J., & Norenzayan, A. (2010b). The weirdest people in the world? Behavioral and Brain Sciences, 33(2-3), 61–83.\n\n\nPeterson, R. A., & Merunka, D. R. (2014). Convenience samples of college students and research reproducibility. Journal of Business Research, 67(5), 1035–1041.\n\n\nTooby, J., & Cosmides, L. (2005). Evolutionary psychology: Conceptual foundations. In D. M. Buss (A c. Di), The Handbook of Evolutionary Psychology (pp. 5–67). Wiley.\n\n\nYouyou, W., Yang, Y., & Uzzi, B. (2023). A discipline-wide investigation of the replicability of Psychology papers over the past two decades. Proceedings of the National Academy of Sciences, 120(6), e2208863120.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Campionamento, metodologia sperimentale e studi osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_measurement.html",
    "href": "chapters/key_notions/04_measurement.html",
    "title": "4  La misurazione in psicologia",
    "section": "",
    "text": "4.1 Introduzione\nLa scienza si avvale di modelli per interpretare i dati, ma opera sempre con teorie incomplete e misurazioni soggette a errori. Di conseguenza, è fondamentale riconoscere le incertezze quando si cerca di estrarre informazioni dalle misurazioni utilizzando i nostri modelli. Nessuna misurazione, spiegazione o previsione è perfettamente accurata e precisa, e non possiamo mai conoscere con esattezza l’entità dei loro errori. Questo riconoscimento è alla base della teoria della misurazione, che cerca di quantificare e gestire queste incertezze per migliorare la qualità delle nostre conclusioni scientifiche.\nQuesta incertezza viene catturata in tre equazioni fondamentali. La prima è l’Equazione di Misurazione, che riconosce l’errore osservativo:\n\\[\ny = z + \\varepsilon_y,\n\\]\ndove \\(y\\) rappresenta il valore misurato, \\(z\\) il valore reale e \\(\\varepsilon_y\\) l’errore di misurazione. La seconda è l’Equazione di Modellazione, che esprime la presenza di un diverso tipo di errore:\n\\[\nz = f(x, \\theta) + \\varepsilon_\\text{model},\n\\]\ndove \\(f\\) è il modello, \\(x\\) sono le condizioni ambientali per cui eseguiamo il modello, \\(\\theta\\) sono i valori dei parametri del modello e \\(\\varepsilon_\\text{model}\\) rappresenta l’errore del modello, che sorge perché \\(f\\), \\(x\\) e \\(\\theta\\) saranno tutti in qualche misura imprecisi.\nCombinando queste due equazioni, otteniamo l’Equazione della Scienza:\n\\[\ny = f(x, \\theta) + \\varepsilon_\\text{model} + \\varepsilon_y.\n\\]\nLa scienza è il tentativo di spiegare le osservazioni \\(y\\) utilizzando un modello \\(f\\), cercando di minimizzare l’errore di misurazione \\(\\varepsilon_y\\) e l’errore del modello \\(\\varepsilon_\\text{model}\\), in modo che il modello possa essere utilizzato per fare previsioni sul mondo reale (\\(z\\)). L’approccio bayesiano alla scienza riconosce e quantifica le incertezze su tutti e sei gli elementi dell’Equazione della Scienza: \\(y\\), \\(f\\), \\(x\\), \\(\\theta\\), \\(\\varepsilon_\\text{model}\\) e \\(\\varepsilon_y\\).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_measurement.html#la-teoria-della-misurazione",
    "href": "chapters/key_notions/04_measurement.html#la-teoria-della-misurazione",
    "title": "4  La misurazione in psicologia",
    "section": "4.2 La teoria della Misurazione",
    "text": "4.2 La teoria della Misurazione\nLa teoria della misurazione, oggetto di questo capitolo, si concentra sull’errore di misurazione e sull’equazione fondamentale \\(y = z + \\varepsilon_y\\). Questa equazione può essere esaminata da tre prospettive distinte. La prima concerne l’affidabilità della misura, rappresentata dal termine \\(\\varepsilon_y\\). La psicometria, branca dedicata alla teoria della misurazione psicologica, si occupa di quantificare l’affidabilità delle misure psicologiche attraverso metodi come la Teoria Classica dei Test e la Teoria di Risposta all’Item.\nLa seconda prospettiva riguarda la validità delle misure psicologiche, ovvero quanto adeguatamente la misura \\(y\\) rappresenti il costrutto \\(z\\). Questo aspetto, più complesso dell’affidabilità, non può essere risolto meramente con metodi statistici, ma richiede una profonda comprensione delle teorie psicologiche e della loro capacità di descrivere e prevedere i fenomeni psicologici.\nLa terza prospettiva si concentra sulle procedure di assegnazione dei valori a \\(y\\), esplorando quali metodi (questionari, interviste, esperimenti) siano più appropriati e come valutarne l’adeguatezza.\n\n4.2.1 Costrutti Psicologici\nLa teoria della misurazione sottolinea l’importanza di distinguere tra la procedura di misurazione e il costrutto che si intende misurare. Ad esempio, mentre la temperatura è un costrutto, il termometro è lo strumento di misurazione. Analogamente, l’abilità matematica è un costrutto, mentre un test di matematica è la procedura per misurarla.\nNelle scienze psicologiche e sociali, la misurazione presenta sfide uniche rispetto alle scienze fisiche, poiché i costrutti in esame sono spesso astratti e non direttamente osservabili. Ciò richiede una particolare attenzione alla validità e all’affidabilità degli strumenti di misurazione, nonché una costante riflessione sulle limitazioni e le potenziali fonti di errore.\nIl capitolo introduce concetti fondamentali relativi alla misurazione quantitativa delle caratteristiche psicologiche, con un focus sulla teoria delle scale di misura di Stevens (1946). Questa teoria fornisce un quadro concettuale per comprendere i diversi tipi di scale di misurazione e le operazioni matematiche appropriate per ciascuna. Inoltre, vengono esplorate alcune procedure di scaling psicologico, ovvero l’assegnazione di numeri all’intensità di fenomeni psicologici.\n\n\n4.2.2 Scaling Psicologico\nLo scaling psicologico si occupa della trasformazione dei dati empirici raccolti durante uno studio psicologico in misure o punteggi che rappresentino accuratamente le caratteristiche psicologiche oggetto di indagine.\nScaling di Guttman. Uno dei metodi di scaling più noti è lo «Scaling di Guttman», che viene utilizzato per rappresentare relazioni ordinate tra gli elementi di una scala. Ad esempio, in un questionario sui sintomi dell’ansia, le domande possono essere disposte in ordine di intensità crescente dei sintomi. Secondo il modello di Guttman, se un partecipante risponde “sì” a una domanda che riflette un sintomo più intenso, ci si aspetta che abbia risposto “sì” anche a tutte le domande precedenti, che rappresentano sintomi di intensità minore. Questo approccio consente di costruire una scala che riflette in modo sistematico e coerente la gravità dei sintomi.\nScaling Thurstoniano. Lo «Scaling Thurstoniano» è un metodo utilizzato per misurare preferenze o giudizi soggettivi. Ad esempio, per valutare la preferenza tra diversi tipi di cibi, i partecipanti confrontano due cibi alla volta ed esprimono una preferenza. Le risposte vengono poi utilizzate per assegnare punteggi che riflettono la preferenza media per ciascun cibo.\nScaling Fechneriano. Lo scaling fechneriano si basa sulla legge di Fechner, secondo cui la percezione di uno stimolo aumenta in modo logaritmico rispetto alla sua intensità fisica. La misura fondamentale è la JND (Just Noticeable Difference), ovvero la minima differenza percepibile tra due stimoli. Secondo Fechner, sommando le JND si ottiene una scala psicologica dell’intensità percepita, utile per studiare grandezze sensoriali come luminosità, peso e suono (per es., Domini & Caudek, 2009).\nQuestionari Likert. I questionari Likert richiedono ai partecipanti di esprimere il loro grado di accordo con una serie di affermazioni su una scala a più livelli, che va da «fortemente in disaccordo» a «fortemente d’accordo». I punteggi ottenuti vengono sommati per rappresentare la posizione complessiva dell’individuo rispetto all’oggetto di studio.\n\n\n4.2.3 Metodi di Valutazione delle Scale Psicologiche\nPer valutare le proprietà delle scale psicologiche, vengono utilizzati vari metodi. Ad esempio, l’affidabilità delle misure può essere analizzata utilizzando il coefficiente alpha di Cronbach o il coefficiente Omega di McDonald, entrambi utilizzati per misurare la coerenza interna delle risposte ai diversi item di un questionario. Inoltre, la validità delle scale può essere esaminata confrontando i risultati ottenuti con misure simili o attraverso analisi statistiche che verificano se la scala cattura accuratamente il costrutto psicologico che si intende misurare. La validità di costrutto è particolarmente cruciale, poiché riguarda la capacità della scala di misurare effettivamente il concetto psicologico che si intende esplorare.\n\n\n4.2.4 Prospettive Moderne\nNegli ultimi anni, il dibattito sulla misurazione psicologica si è arricchito di nuove prospettive, grazie all’avvento di tecnologie avanzate e all’integrazione di approcci interdisciplinari. Ecco alcune delle tendenze più rilevanti.\nTeoria della Risposta agli Item. La Teoria della Risposta agli Item (IRT) ha guadagnato popolarità per la sua capacità di fornire stime più precise delle abilità latenti rispetto ai modelli classici. La IRT considera la probabilità che un individuo risponda correttamente a un item in funzione della sua abilità e delle caratteristiche dell’item stesso, offrendo una visione più dettagliata delle proprietà psicometriche degli strumenti di misurazione.\nApprocci Bayesiani. Gli approcci bayesiani stanno rivoluzionando il campo della psicometria, permettendo di incorporare informazioni a priori nelle stime e di aggiornare le credenze sulla base di nuovi dati. Questi metodi sono particolarmente utili per affrontare la complessità e l’incertezza inerenti alla misurazione psicologica.\nAnalisi di Rete. L’analisi di rete è un’altra metodologia emergente che vede i costrutti psicologici non come variabili latenti indipendenti, ma come reti di sintomi interconnessi. Questo approccio può offrire nuove intuizioni sulla struttura delle psicopatologie e sulla dinamica dei sintomi.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_measurement.html#le-scale-di-misurazione",
    "href": "chapters/key_notions/04_measurement.html#le-scale-di-misurazione",
    "title": "4  La misurazione in psicologia",
    "section": "4.3 Le scale di misurazione",
    "text": "4.3 Le scale di misurazione\nLe scale di misurazione sono strumenti fondamentali per assegnare numeri ai dati osservati, rappresentando le proprietà psicologiche. La teoria delle scale di Stevens (1946) identifica quattro tipi di scale di misurazione: nominali, ordinali, a intervalli e di rapporti. Ognuna di queste scale consente di effettuare operazioni aritmetiche diverse, poiché ciascuna di esse è in grado di “catturare” solo alcune delle proprietà dei fenomeni psicologici che si intende misurare.\n\n\n\nScale di misurazione.\n\n\n\n4.3.1 Scala nominale\nLa scala nominale è il livello di misurazione più semplice e corrisponde ad una tassonomia o classificazione delle categorie che utilizziamo per descrivere i fenomeni psicologici. I simboli o numeri che costituiscono questa scala rappresentano i nomi delle categorie e non hanno alcun valore numerico intrinseco. Con la scala nominale possiamo solo distinguere se una caratteristica psicologica è uguale o diversa da un’altra.\nI dati raccolti con la scala nominale sono suddivisi in categorie qualitative e mutuamente esclusive, in cui ogni dato appartiene ad una sola categoria. In questa scala, esiste solo la relazione di equivalenza tra le misure delle unità di studio: gli elementi del campione appartenenti a classi diverse sono differenti, mentre tutti quelli della stessa classe sono tra loro equivalenti.\nL’unica operazione algebrica consentita dalla scala nominale è quella di contare le unità di studio che appartengono ad ogni categoria e il numero totale di categorie. Di conseguenza, la descrizione dei dati avviene tramite le frequenze assolute e le frequenze relative.\nDalla scala nominale è possibile costruire altre scale nominali equivalenti alla prima, trasformando i valori della scala di partenza in modo tale da cambiare i nomi delle categorie, ma lasciando inalterata la suddivisione delle unità di studio nelle medesime classi di equivalenza. In altre parole, cambiando i nomi delle categorie di una variabile misurata su scala nominale, si ottiene una nuova variabile esattamente equivalente alla prima.\n\n\n4.3.2 Scala ordinale\nLa scala ordinale mantiene la caratteristica della scala nominale di classificare ogni unità di misura all’interno di una singola categoria, ma introduce la relazione di ordinamento tra le categorie. In quanto basata su una relazione di ordine, una scala ordinale descrive solo il rango di ordine tra le categorie e non fornisce informazioni sulla distanza tra di esse. Non ci dice, ad esempio, se la distanza tra le categorie \\(a\\) e \\(b\\) è uguale, maggiore o minore della distanza tra le categorie \\(b\\) e \\(c\\).\nUn esempio classico di scala ordinale è quello della scala Mohs per la determinazione della durezza dei minerali. Per stabilire la durezza dei minerali si usa il criterio empirico della scalfittura. Vengono stabiliti livelli di durezza crescente da 1 a 10 con riferimento a dieci minerali: talco, gesso, calcite, fluorite, apatite, ortoclasio, quarzo, topazio, corindone e diamante. Un minerale appartenente ad uno di questi livelli se scalfisce quello di livello inferiore ed è scalfito da quello di livello superiore.\n\n\n\nLa scala di durezza dei minerali di Mohs. Un oggetto è considerato più duro di X se graffia X. Sono incluse anche misure di durezza relativa utilizzando uno sclerometro, da cui emerge la non linearità della scala di Mohs (Burchard, 2004).\n\n\n\n\n4.3.3 Scala ad intervalli\nLa scala ad intervalli di misurazione include le proprietà della scala nominale e della scala ordinale e permette di misurare le distanze tra le coppie di unità statistiche in termini di un intervallo costante, chiamato “unità di misura”, a cui viene attribuito il valore “1”. L’origine della scala, ovvero il punto zero, è scelta arbitrariamente e non indica l’assenza della proprietà che si sta misurando. Ciò significa che la scala ad intervalli consente anche valori negativi e lo zero non viene attribuito all’unità statistica in cui la proprietà risulta assente.\nLa scala ad intervalli equivalenti consente l’esecuzione di operazioni algebriche basate sulla differenza tra i numeri associati ai diversi punti della scala, operazioni algebriche non possibili con le scale di misura nominale o ordinale. Tuttavia, il limite della scala ad intervalli è che non consente di calcolare il rapporto tra coppie di misure. È possibile affermare la differenza tra \\(a\\) e \\(b\\) come la metà della differenza tra \\(c\\) e \\(d\\) o che le due differenze sono uguali, ma non è possibile affermare che \\(a\\) abbia una proprietà misurata in quantità doppia rispetto a \\(b\\). In altre parole, non è possibile stabilire rapporti diretti tra le misure ottenute. Solo le differenze tra le modalità permettono tutte le operazioni aritmetiche, come la somma, l’elevazione a potenza o la divisione, che sono alla base della statistica inferenziale.\nNelle scale ad intervalli equivalenti, l’unità di misura è arbitraria e può essere cambiata attraverso una dilatazione, ovvero la moltiplicazione di tutti i valori della scala per una costante positiva. Inoltre, la traslazione, ovvero l’aggiunta di una costante a tutti i valori della scala, è ammessa poiché non altera le differenze tra i valori della scala. La scala rimane invariata rispetto a traslazioni e dilatazioni e dunque le uniche trasformazioni ammissibili sono le trasformazioni lineari:\n\\[\ny' = a + by, \\quad b &gt; 0.\n\\]\nInfatti, l’uguaglianza dei rapporti fra gli intervalli rimane invariata a seguito di una trasformazione lineare.\nEsempio di scala ad intervalli è la temperatura misurata in gradi Celsius o Fahrenheit, ma non Kelvin. Come per la scala nominale, è possibile stabilire se due modalità sono uguali o diverse: \\(30^\\circ C \\neq 20^\\circ C\\). Come per la scala ordinale è possibile mettere due modalità in una relazione d’ordine: \\(30^\\circ C &gt; 20^\\circ C\\). In aggiunta ai casi precedenti, però, è possibile definire una unità di misura per cui è possibile dire che tra \\(30^\\circ C\\) e \\(20^\\circ C\\) c’è una differenza di \\(30^\\circ - 20^\\circ = 10^\\circ C\\). I valori di temperatura, oltre a poter essere ordinati secondo l’intensità del fenomeno, godono della proprietà che le differenze tra loro sono direttamente confrontabili e quantificabili.\nIl limite della scala ad intervalli è quello di non consentire il calcolo del rapporto tra coppie di misure. Ad esempio, una temperatura di \\(80^\\circ C\\) non è il doppio di una di \\(40^\\circ C\\). Se infatti esprimiamo le stesse temperature nei termini della scala Fahrenheit, allora i due valori non saranno in rapporto di 1 a 2 tra loro. Infatti, \\(20^\\circ C = 68^\\circ F\\) e \\(40^\\circ C = 104^\\circ F\\). Questo significa che la relazione “il doppio di” che avevamo individuato in precedenza si applicava ai numeri della scala centigrada, ma non alla proprietà misurata (cioè la temperatura). La decisione di che scala usare (Centigrada vs. Fahrenheit) è arbitraria. Ma questa arbitrarietà non deve influenzare le inferenze che traiamo dai dati. Queste inferenze, infatti, devono dirci qualcosa a proposito della realtà empirica e non possono in nessun modo essere condizionate dalle nostre scelte arbitrarie che ci portano a scegliere la scala Centigrada piuttosto che quella Fahrenheit.\nConsideriamo ora l’aspetto invariante di una trasformazione lineare, ovvero l’uguaglianza dei rapporti fra intervalli. Prendiamo in esame, ad esempio, tre temperature: \\(20^\\circ C = 68^\\circ F\\), \\(15^\\circ C = 59^\\circ F\\), \\(10^\\circ C = 50 ^\\circ F\\).\nÈ facile rendersi conto del fatto che i rapporti fra intervalli restano costanti indipendentemente dall’unità di misura che è stata scelta:\n\\[\n  \\frac{20^\\circ C - 10^\\circ C}{20^\\circ C - 15^\\circ C} =\n  \\frac{68^\\circ F - 50^\\circ F}{68^\\circ F-59^\\circ F} = 2.\n\\]\n\n\n4.3.4 Scala di rapporti\nNella scala a rapporti equivalenti, lo zero non è arbitrario e rappresenta l’elemento che ha intensità nulla rispetto alla proprietà misurata. Per costruire questa scala, si associa il numero 0 all’elemento con intensità nulla e si sceglie un’unità di misura \\(u\\). Ad ogni elemento si assegna un numero \\(a\\) definito come \\(a = d / u\\), dove \\(d\\) rappresenta la distanza dall’origine. In questo modo, i numeri assegnati riflettono le differenze e i rapporti tra le intensità della proprietà misurata.\nIn questa scala, è possibile effettuare operazioni aritmetiche non solo sulle differenze tra i valori della scala, ma anche sui valori stessi della scala. L’unica scelta arbitraria è l’unità di misura, ma lo zero deve sempre rappresentare l’intensità nulla della proprietà considerata.\nLe trasformazioni ammissibili in questa scala sono chiamate trasformazioni di similarità e sono del tipo \\(y' = by\\), dove \\(b &gt; 0\\). In questa scala, i rapporti tra i valori rimangono invariati dopo le trasformazioni. In altre parole, se rapportiamo due valori originali e due valori trasformati, il rapporto rimane lo stesso: \\(\\frac{y_i}{y_j} = \\frac{y'_i}{y'_j}\\).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_measurement.html#gerarchia-dei-livelli-delle-scale-di-misurazione",
    "href": "chapters/key_notions/04_measurement.html#gerarchia-dei-livelli-delle-scale-di-misurazione",
    "title": "4  La misurazione in psicologia",
    "section": "4.4 Gerarchia dei livelli delle scale di misurazione",
    "text": "4.4 Gerarchia dei livelli delle scale di misurazione\nSecondo Stevens (1946), esiste una gerarchia dei livelli delle scale di misurazione, denominati “livelli di scala”. Questi livelli sono organizzati in modo gerarchico, in cui la scala nominale rappresenta il livello più basso della misurazione, mentre la scala a rapporti equivalenti rappresenta il livello più alto.\n\nScala nominale: Classifica le categorie senza un ordine specifico.\nScala ordinale: Classifica le categorie in un ordine specifico, ma senza una misura precisa delle distanze.\nScala a intervalli: Misura le distanze tra le categorie con un intervallo costante, ma senza un punto zero assoluto.\nScala di rapporti: Misura le distanze con un intervallo costante e un punto zero assoluto.\n\n\n\n\nRelazioni tra i livelli di misurazione.\n\n\nPassando da un livello di misurazione ad uno più alto aumenta il numero di operazioni aritmetiche che possono essere compiute sui valori della scala.\n\n4.4.1 Variabili Discrete e Continue\nLe variabili possono essere classificate come variabili a livello di intervalli o di rapporti e possono essere sia discrete che continue.\n\nVariabili discrete: Assumono valori specifici ma non possono assumere valori intermedi.\nVariabili continue: Possono assumere qualsiasi valore all’interno di un intervallo specificato.\n\n\n\n\nVariabili discrete e continue.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_measurement.html#interazione-tra-teoria-sostanziale-e-misurazione-nella-ricerca-scientifica",
    "href": "chapters/key_notions/04_measurement.html#interazione-tra-teoria-sostanziale-e-misurazione-nella-ricerca-scientifica",
    "title": "4  La misurazione in psicologia",
    "section": "4.5 Interazione tra Teoria Sostanziale e Misurazione nella Ricerca Scientifica",
    "text": "4.5 Interazione tra Teoria Sostanziale e Misurazione nella Ricerca Scientifica\n\n4.5.1 Un caso studio sul mind-body healing\nUn esempio di lettura critica della letteratura scientifica è offerto dall’analisi di uno studio sul mind-body healing pubblicato su Nature Aungle & Langer (2023). La ricerca riporta miglioramenti nella salute fisica associati a pratiche mente-corpo, ma è stata oggetto di severe critiche metodologiche da parte del statistico Andrew Gelman sul blog Statistical Modeling. Questo caso rivela due aspetti fondamentali spesso trascurati: il ruolo della teoria sostanziale e i criteri di misurazione rigorosa.\n\n\n4.5.2 La Teoria Sostanziale come Fondamento\nGelman evidenzia un deficit epistemologico centrale: l’assenza di un framework teorico convincente che spieghi i meccanismi causali ipotizzati. Senza una teoria che:\n\nDefinisca in modo univoco i costrutti (es.: “guarigione mente-corpo”)\n\nIdentifichi pathways biologici o psicologici plausibili\n\nSi integri con conoscenze consolidate (es.: neuroscienze, immunologia),\n\ni risultati empirici perdono significato scientifico, rischiando di degenerare in quella che Gelman definisce “junk science”. Una teoria solida non è solo un optional descrittivo, ma una precondizione per:\n\nFormulare ipotesi verificabili\n\nInterpretare correlazioni in termini causali\n\nEvitare inferenze speculative o tautologiche.\n\n\n\n4.5.3 Criticità nella Misurazione\nLo studio presenta inoltre problemi operazionali rilevanti:\n\n4.5.3.1 A. Validità degli strumenti\n\nLa misurazione delle pratiche mente-corpo non controlla adeguatamente:\n\nFattori confondenti (aspettative dei partecipanti, effetto placebo)\n\nBias di autovalutazione\n\n\nGli outcome clinici utilizzano scale non validate, compromettendo la comparabilità dei risultati.\n\n\n\n4.5.3.2 Questioni di validità\n\nInterna: L’assenza di blinding e randomizzazione rigorosa mina l’attribuzione causale.\n\nEsterna: Campioni non rappresentativi limitano la generalizzabilità (per approfondimenti, si veda Capitolo 34).\n\nCome discusso nella letteratura metodologica (Accuracy and Precision), la qualità delle misurazioni determina direttamente l’affidabilità delle conclusioni. Misure distorte o imprecise generano un “rumore” statistico che oscura eventuali segnali reali.\n\n\n\n4.5.4 Verso una Valutazione Integrata\nLa lettura critica di questo articolo mostra come la critica scientifica deve simultaneamente considerare due piani:\n\n\n\n\n\n\n\nDimensione\nRischi di Negligenza\n\n\n\n\nTeorica\nInterpretazioni ad hoc, ipotesi non falsificabili\n\n\nOperativa\nArtefatti metodologici, misurazioni inadeguate, conclusioni spurie\n\n\n\nUna ricerca rigorosa richiede un circolo ermeneutico tra teoria e dati: le misurazioni devono testare ipotesi derivate da framework teorici, mentre i risultati empirici devono raffinare le teorie stesse. Senza questo dialogo, si cade nel dualismo sterile tra:\n\nEmpirismo naïve (raccolta dati acritica)\n\nTeorizzazione dogmatica (slegata dall’evidenza).\n\nIn sintesi, la lettura critica di articoli scientifici esige:\n\ncompetenza transdisciplinare (statistica, epistemologia, conoscenze del dominio),\nconsapevolezza sui limiti della misurazione di costrutti.\n\nCome illustrato nell’analisi di Gelman, solo integrando valutazioni teoriche e metodologiche è possibile distinguere scienza robusta da pseudoscienza. Questo approccio non è meramente “difensivo”, ma costituisce il motore stesso del progresso scientifico, come approfondito nelle riflessioni su validità interna/esterna.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_measurement.html#riflessioni-conclusive",
    "href": "chapters/key_notions/04_measurement.html#riflessioni-conclusive",
    "title": "4  La misurazione in psicologia",
    "section": "4.6 Riflessioni Conclusive",
    "text": "4.6 Riflessioni Conclusive\nLa misurazione in psicologia non è un semplice atto di raccolta di dati, ma un processo fondamentale per garantire che le osservazioni empiriche siano interpretabili alla luce di modelli teorici solidi. Una buona misurazione non si limita a ridurre l’errore, ma consente di attribuire un significato coerente ai punteggi ottenuti, facilitando così il progresso della conoscenza scientifica. Senza strumenti adeguati per la misurazione, il rischio è quello di costruire teorie su basi incerte, compromettendo la validità delle conclusioni tratte.\nDue pilastri sostengono dunque una ricerca psicologica rigorosa: la teoria e la misurazione. La teoria fornisce il quadro concettuale entro cui si interpretano i dati, definendo le ipotesi e orientando le analisi. La misurazione, invece, è il ponte tra i costrutti astratti e le osservazioni empiriche, traducendo concetti complessi in variabili operative affidabili. Nessuna delle due componenti può reggersi senza l’altra: una teoria senza misurazione adeguata rischia di rimanere speculativa, mentre una misurazione priva di un solido fondamento teorico può portare a dati privi di significato.\nNella valutazione di un qualsiasi studio psicologico, un approccio critico richiede quindi di esaminare sia la solidità del quadro teorico sia la qualità degli strumenti di misurazione adottati. Il progresso della ricerca dipende dalla capacità di integrare questi due elementi, attraverso metodologie che riducano l’incertezza e migliorino la precisione delle inferenze. Le moderne tecniche di analisi dei dati, i modelli psicometrici avanzati e le tecnologie digitali stanno ampliando le possibilità di misurazione, offrendo strumenti più sensibili e adattabili alla complessità dei fenomeni psicologici. Tuttavia, la sfida principale rimane la stessa: garantire che la misurazione sia non solo accurata, ma anche teoricamente fondata, affinché le conoscenze acquisite possano davvero contribuire alla comprensione della mente e del comportamento umano.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_measurement.html#esercizi",
    "href": "chapters/key_notions/04_measurement.html#esercizi",
    "title": "4  La misurazione in psicologia",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi 1\n\n\n\n\n\nEsercizio 1: Identificazione del Livello di Misurazione\nObiettivo: Comprendere i diversi livelli di misurazione applicati alla psicologia.\n\nIdentifica il livello di misurazione (nominale, ordinale, intervalli, rapporti) per ciascuna delle seguenti variabili psicologiche:\n\n\nTipo di terapia psicologica (Cognitivo-comportamentale, Psicodinamica, Umanistica)\n\n\nLivello di ansia auto-riferito su una scala da 1 a 10\n\n\nNumero di episodi depressivi in un anno\n\n\nTempo di reazione in millisecondi in un test cognitivo\n\n\n\nEsercizio 2: Confronto tra Scale\nObiettivo: Comprendere le differenze tra le scale di misurazione.\n\nSpiega la differenza tra una scala ordinale e una scala a intervalli utilizzando l’esempio della soddisfazione lavorativa.\nPerché il punteggio QI è misurato su una scala a intervalli e non su una scala a rapporti?\nIn che modo il punteggio di una scala di autostima su una scala Likert differisce da una misurazione su una scala di rapporti?\n\nEsercizio 3: Operazioni Aritmetiche Consentite\nObiettivo: Comprendere le operazioni matematiche consentite per ciascun livello di misurazione.\n\nQuali operazioni aritmetiche sono ammissibili per una scala nominale?\nPuò avere senso calcolare la media di punteggi su una scala ordinale? Perché?\nSe hai misurato il tempo di reazione in secondi, quali operazioni aritmetiche puoi eseguire?\n\nEsercizio 4: Trasformazioni Ammissibili\nObiettivo: Comprendere le trasformazioni possibili per ogni scala di misurazione.\n\nSe una variabile è misurata su una scala nominale, quale tipo di trasformazione è consentita?\nPer una scala a intervalli, quali trasformazioni matematiche sono permesse senza alterare le proprietà della scala?\nQuale tipo di trasformazione è consentita su una scala di rapporti?\n\nEsercizio 5: Applicazione delle Scale a Dati Psicologici\nObiettivo: Applicare i concetti a contesti psicologici reali.\n\nUna scala di ansia clinica fornisce punteggi compresi tra 0 e 100. Quale livello di misurazione è più appropriato e perché?\nUn esperimento misura la memoria dichiarativa chiedendo ai partecipanti di ricordare un elenco di parole. Come dovrebbe essere misurata la variabile “numero di parole ricordate”?\nIn uno studio sulla personalità, i tratti vengono classificati come “estroverso” e “introverso”. Qual è il livello di misurazione?\n\nEsercizio 6: Valutazione della Scala di Misurazione\nObiettivo: Identificare la corretta scala di misurazione per vari fenomeni psicologici.\n\nIl livello di aggressività misurato su una scala da 1 a 5 è nominale, ordinale, intervalli o rapporti? Giustifica la tua risposta.\nIl numero di attacchi di panico in una settimana può essere considerato su scala ordinale? Perché sì o perché no?\nUn test di intelligenza misura il QI con una media di 100 e una deviazione standard di 15. Qual è il livello di misurazione e quali sono le implicazioni per l’analisi statistica?\n\nEsercizio 7: Costruzione di una Scala Psicologica\nObiettivo: Creare una scala di misurazione per una variabile psicologica.\n\nSe dovessi costruire una scala per misurare la resilienza, quale livello di misurazione sceglieresti e perché?\nCome potresti trasformare una scala nominale di preferenza musicale in una scala ordinale?\nUn questionario sulla qualità della vita chiede ai partecipanti di valutare la loro felicità su una scala da 1 a 10. È una scala a intervalli o ordinale? Giustifica.\n\nEsercizio 8: Interpretazione Statistica dei Dati\nObiettivo: Collegare il livello di misurazione alle tecniche statistiche appropriate.\n\nPerché una mediana è più appropriata della media per dati ordinali?\nQuale test statistico sarebbe più adatto per confrontare due gruppi su una variabile nominale?\nQuali analisi possono essere condotte su dati raccolti su una scala a rapporti?\n\nEsercizio 9: Misurazione e Inferenze Psicologiche\nObiettivo: Riflettere su come il livello di misurazione influisce sulle conclusioni di una ricerca.\n\nSe un test di personalità usa una scala Likert da 1 a 7, quali precauzioni devono essere prese nell’interpretare le differenze tra punteggi?\nUn questionario di benessere assegna punteggi tra 0 e 100, ma non ha uno zero assoluto. Quale scala è questa e quali sono le limitazioni?\nIn uno studio sulla depressione, i sintomi vengono codificati come “assenti”, “moderati” o “gravi”. Che tipo di scala è questa e quali statistiche possono essere usate per analizzarla?\n\nEsercizio 10: Esperimenti Psicologici e Misurazione\nObiettivo: Applicare la teoria della misurazione nella progettazione di esperimenti psicologici.\n\nSe un esperimento misura la memoria a breve termine con un compito di richiamo di parole, quale scala di misurazione utilizzeresti?\nCome la scelta della scala di misurazione può influenzare le inferenze che si possono trarre da un esperimento?\nQuali tipi di analisi statistica sono appropriati per dati misurati su scala ordinale rispetto a scala di rapporti?\n\n\n\n\n\n\n\n\n\n\nSoluzioni 1\n\n\n\n\n\nEsercizio 1: Identificazione del Livello di Misurazione\nObiettivo: Comprendere i diversi livelli di misurazione applicati alla psicologia.\n\nIdentifica il livello di misurazione (nominale, ordinale, intervalli, rapporti) per ciascuna delle seguenti variabili psicologiche:\n\n\nNominale (Tipo di terapia psicologica è una classificazione senza ordine)\n\n\nOrdinale (Scala da 1 a 10, con ordine ma senza distanze uguali)\n\n\nRapporti (Numero di episodi depressivi ha uno zero assoluto e si possono fare rapporti tra valori)\n\n\nRapporti (Tempo di reazione ha uno zero assoluto e permette operazioni di rapporto)\n\n\n\nEsercizio 2: Confronto tra Scale\nObiettivo: Comprendere le differenze tra le scale di misurazione.\n\nLa scala ordinale fornisce un ordine ma non permette di calcolare differenze precise, mentre la scala a intervalli ha differenze costanti tra i valori. Ad esempio, “soddisfazione lavorativa” su una scala da 1 a 5 è ordinale, mentre il punteggio di un test psicologico è a intervalli.\nIl punteggio QI è a intervalli perché la differenza tra punteggi è significativa, ma non ha uno zero assoluto che rappresenta l’assenza di intelligenza.\nUna scala Likert misura il livello di accordo con una dichiarazione, quindi è generalmente considerata ordinale, nonostante sia trattata spesso come una scala a intervalli.\n\nEsercizio 3: Operazioni Aritmetiche Consentite\nObiettivo: Comprendere le operazioni matematiche consentite per ciascun livello di misurazione.\n\nNella scala nominale si può solo contare la frequenza delle categorie (ad es., il numero di partecipanti che usano un tipo di terapia).\nNo, la media su dati ordinali può essere fuorviante perché le distanze tra le categorie non sono necessariamente uguali. Meglio usare la mediana.\nSul tempo di reazione si possono eseguire tutte le operazioni aritmetiche, inclusa la media, la moltiplicazione e i rapporti tra valori.\n\nEsercizio 4: Trasformazioni Ammissibili\nObiettivo: Comprendere le trasformazioni possibili per ogni scala di misurazione.\n\nSulla scala nominale, solo le trasformazioni di ricodifica (ad esempio, cambiare i nomi delle categorie) sono permesse.\nPer una scala a intervalli, si possono effettuare trasformazioni lineari della forma y’ = a + by con b &gt; 0.\nPer una scala di rapporti, sono consentite trasformazioni di similarità della forma y’ = by, dove b &gt; 0.\n\nEsercizio 5: Applicazione delle Scale a Dati Psicologici\nObiettivo: Applicare i concetti a contesti psicologici reali.\n\nScala a intervalli, perché ha differenze costanti tra i punteggi ma nessuno zero assoluto.\nScala di rapporti, perché il numero di parole ricordate ha uno zero assoluto e consente operazioni di rapporto.\nNominale, perché non vi è un ordine gerarchico tra le categorie “estroverso” e “introverso”.\n\nEsercizio 6: Valutazione della Scala di Misurazione\nObiettivo: Identificare la corretta scala di misurazione per vari fenomeni psicologici.\n\nOrdinale, perché il livello di aggressività segue un ordine, ma le differenze tra i livelli non sono necessariamente uguali.\nNo, perché il numero di attacchi di panico è una variabile discreta e misurabile su scala di rapporti.\nIntervalli, perché il punteggio QI ha distanze costanti tra i valori, ma non ha uno zero assoluto.\n\nEsercizio 7: Costruzione di una Scala Psicologica\nObiettivo: Creare una scala di misurazione per una variabile psicologica.\n\nOrdinale o a intervalli, a seconda della precisione della misurazione della resilienza.\nSi potrebbe assegnare un valore numerico crescente alle categorie di preferenza musicale per ottenere una scala ordinale.\nÈ una scala ordinale, perché la differenza tra livelli non è necessariamente costante.\n\nEsercizio 8: Interpretazione Statistica dei Dati\nObiettivo: Collegare il livello di misurazione alle tecniche statistiche appropriate.\n\nPerché la mediana è meno sensibile ai valori estremi rispetto alla media.\nUn test chi-quadrato è adatto per confrontare frequenze di dati nominali tra gruppi.\nSi possono calcolare media, deviazione standard e utilizzare test parametrici come t-test o ANOVA.\n\nEsercizio 9: Misurazione e Inferenze Psicologiche\nObiettivo: Riflettere su come il livello di misurazione influisce sulle conclusioni di una ricerca.\n\nI punteggi Likert sono ordinali, quindi confronti tra differenze di punteggio devono essere interpretati con cautela.\nIntervalli, perché non ha uno zero assoluto, il che limita l’uso di operazioni moltiplicative.\nOrdinale, e si possono usare test non parametrici come il test di Kruskal-Wallis o il test di Mann-Whitney.\n\nEsercizio 10: Esperimenti Psicologici e Misurazione\nObiettivo: Applicare la teoria della misurazione nella progettazione di esperimenti psicologici.\n\nRapporti, perché il numero di parole ricordate è una variabile discreta con uno zero assoluto.\nSe si usa una scala ordinale, bisogna essere cauti nell’uso della media e della deviazione standard.\nScala ordinale → test non parametrici (Mann-Whitney); scala di rapporti → test parametrici (t-test, ANOVA).\n\n\n\n\n\n\n\n\n\n\nProblemi 2\n\n\n\n\n\nEsercizio 1 – Teoria Sostanziale e “Junk Science”\nObiettivo: Riconoscere il ruolo di una teoria sostanziale solida e comprendere come la sua assenza possa compromettere uno studio.\n\nLeggi la sezione in cui Gelman critica l’assenza di una teoria solida nello studio sulle pratiche mente-corpo.\n\nSpiega, in massimo 10 righe, perché secondo Gelman la mancanza di una teoria coerente rende i risultati del suddetto studio “poco significativi” o addirittura “junk science”.\n\nProponi un esempio ipotetico (non correlato al mind-body healing) di uno studio psicologico che, pur presentando dati numerosi e analizzati con metodi statistici sofisticati, risulti privo di una teoria solida. Descrivi sinteticamente perché questo potrebbe rientrare nel concetto di “junk science”.\n\nEsercizio 2 – Problemi di Misurazione\nObiettivo: Identificare le criticità più comuni nella misurazione dei fenomeni psicologici.\n\nElenca almeno tre possibili fattori confondenti che potrebbero influenzare la misurazione dell’efficacia di un intervento psicologico (ad esempio, l’effetto placebo, le aspettative dei partecipanti, ecc.).\n\nSpiega come questi fattori confondenti potrebbero compromettere la validità interna dello studio.\n\nIndica almeno due caratteristiche fondamentali che una buona scala di misurazione (per una variabile psicologica) dovrebbe possedere per essere ritenuta affidabile e valida.\n\nEsercizio 3 – Precisione e Bias\nObiettivo: Chiarire la distinzione tra precisione e distorsione (bias) e come questi aspetti si riflettano nella validità delle conclusioni.\n\nDefinisci, con parole tue, i concetti di precisione e bias in ambito psicometrico.\nFornisci un esempio concreto di uno strumento di misura preciso ma distorto (bias elevato) e di uno strumento poco preciso ma non distorto (bias basso).\n\nSpiega come la combinazione di scarsa precisione e alto bias possa influire sulla possibilità di trarre conclusioni affidabili in uno studio psicologico.\n\nEsercizio 4 – Validità Interna ed Esterna\nObiettivo: Approfondire come le scelte di misurazione influiscano sulla validità interna ed esterna di uno studio.\n\nIn riferimento allo studio sul mind-body healing discusso nel capitolo, identifica due fattori che potrebbero compromettere la validità interna e due fattori che potrebbero limitarne la validità esterna.\n\nDescrivi in 5-8 righe le differenze principali tra validità interna e validità esterna, utilizzando esempi presi sia dal contesto della guarigione mente-corpo sia da altri contesti psicologici (ad esempio, studi sull’apprendimento o sulla motivazione).\n\nProponi una modifica al disegno di ricerca (ipotetico) che potrebbe migliorare la validità interna dello studio originale. Spiega brevemente come questa modifica ne influenzerebbe anche la validità esterna.\n\nEsercizio 5 – Integrare Teoria e Misurazione: Breve Progetto di Ricerca\nObiettivo: Mettere in pratica i concetti di teoria e misurazione attraverso la progettazione di uno studio.\n\nImmagina di voler condurre uno studio su un intervento di “training di rilassamento mentale” finalizzato a ridurre l’ansia negli studenti universitari.\n\nSviluppa una breve traccia di progetto (massimo 15 righe) rispondendo ai seguenti punti:\n\nTeoria di base: Qual è la teoria sostanziale dietro l’efficacia del training di rilassamento? Quali meccanismi psicologici verrebbero attivati?\n\nIpotesi: Quale effetto prevedi sull’ansia degli studenti?\n\nMisurazione: Che tipo di strumento useresti per valutare il livello di ansia e perché (ad esempio, questionari self-report validati, misure fisiologiche come battito cardiaco, ecc.)?\n\nControllo dei confondenti: Quali variabili secondarie possono influire sui risultati e come intendi gestirle?\n\nValidità: Come assicureresti una buona validità interna? Che strategie adotteresti per aumentare la validità esterna?\n\nSpiega brevemente in che modo la combinazione di un solido quadro teorico e di una misurazione accurata permette di evitare che lo studio venga etichettato come “junk science”.\n\n\n\n\n\n\n\n\n\n\nSoluzioni 2\n\n\n\n\n\nEsercizio 1 – Teoria Sostanziale e “Junk Science”\n\nPerché la mancanza di una teoria solida rende i risultati poco significativi?\n\n\nGelman critica lo studio sul mind-body healing perché non vi è un modello teorico convincente che spieghi il meccanismo causale tra pratiche mente-corpo e miglioramenti di salute.\n\nSenza un quadro teorico robusto, i risultati sono interpretati in modo esplorativo e rischiano di essere attribuiti a variabili non controllate (effetto placebo, regressione alla media, ecc.).\n\nUna teoria ben formulata aiuta a delimitare le ipotesi, guidare il disegno di ricerca e interpretare correttamente i dati. In assenza di ciò, i numeri raccolti potrebbero essere viziati da fattori confondenti o da semplici correlazioni spurious.\n\n\n“Junk science” in massimo 10 righe\n\n\nEsempio di testo in 10 righe (circa)\n**Lo studio sul mind-body healing viene talvolta definito “junk science” da Gelman perché, in mancanza di una teoria sostanziale solida, i dati raccolti non forniscono indicazioni chiare sui processi psicologici o fisiologici coinvolti. Una ricerca classificata come “junk science” è priva di rigore metodologico o teorico, e può presentare gravi problemi di replicabilità o di interpretazione dei risultati. In particolare, se non vi è un modello plausibile che colleghi in modo coerente la pratica mente-corpo ai cambiamenti in variabili biologiche e comportamentali, i risultati empirici rischiano di essere semplici coincidenze. L’assenza di un costrutto ben definito e di ipotesi derivanti da una teoria coerente rende difficile capire se i cambiamenti osservati siano reali, casuali o dovuti ad altre cause non considerate (per esempio, l’effetto placebo). Infine, senza un’adeguata cornice teorica, gli studiosi non sanno come interpretare o generalizzare i dati, e la scienza non progredisce realmente.*\n\n\nEsempio di uno studio privo di teoria solida (ipotesi di “junk science”)\n\n\nSituazione ipotetica: Uno studio che raccoglie decine di variabili sulla personalità e sul benessere, poi usa tecniche statistiche sofisticate (analisi di big data, reti neurali, ecc.) per trovare correlazioni fra i tratti di personalità e centinaia di indicatori fisici.\nPerché “junk science”: Se lo studio non definisce a priori quali ipotesi testare e non ha una teoria chiara che spieghi perché certe caratteristiche di personalità dovrebbero correlarsi con determinati parametri fisici, i risultati trovati potrebbero essere frutto di coincidenze casuali. Inoltre, in assenza di un modello teorico solido, anche risultati statisticamente significativi possono essere privi di significato dal punto di vista psicologico.\n\nEsercizio 2 – Problemi di Misurazione\n\nTre possibili fattori confondenti nell’efficacia di un intervento psicologico\n\n\nEffetto placebo: I partecipanti migliorano perché si aspettano di migliorare, non per l’effettiva efficacia dell’intervento.\n\nAspettative dei partecipanti: Se sanno di partecipare a uno studio, potrebbero modificare il proprio comportamento (effetto Hawthorne).\n\nDesiderabilità sociale: I partecipanti forniscono risposte che ritengono socialmente desiderabili, falsando i risultati (ad esempio, sottostimando i livelli di ansia o stress).\n\n\nCome questi fattori confondenti compromettono la validità interna\n\n\nLa validità interna riguarda il grado in cui è possibile concludere che sia effettivamente la variabile indipendente (l’intervento) a causare le modifiche osservate nella variabile dipendente (es. livelli di ansia).\n\nSe subentrano l’effetto placebo, aspettative non controllate o tendenze alla desiderabilità sociale, diventa difficile stabilire un nesso causale chiaro. Esiste sempre il dubbio che altri processi cognitivi o sociali (non l’intervento in sé) abbiano prodotto il risultato.\n\n\nDue caratteristiche fondamentali di una buona scala di misurazione\n\n\nAffidabilità: Capacità dello strumento di fornire misure stabili e coerenti nel tempo (ad esempio, coerenza interna, stabilità test-retest).\n\nValidità: Capacità dello strumento di misurare effettivamente ciò che si propone di misurare (validità di contenuto, di costrutto, di criterio).\n\nEsercizio 3 – Precisione e Bias\n\nDefinizioni di precisione e bias\n\n\nPrecisione: Indica il grado di dispersione (o variabilità) delle misurazioni. Uno strumento preciso produce misure molto simili fra loro se ripetute nelle stesse condizioni (bassa varianza).\n\nBias (distorsione): Indica l’errore sistematico, ossia la tendenza a sovra- o sottostimare sistematicamente il fenomeno in esame. Uno strumento può essere molto coerente nelle misure, ma se è “tarato” male, darà sempre un risultato distorto.\n\n\nEsempio concreto di misura “precisa ma distorta” e “poco precisa ma non distorta”\n\n\nPrecisa ma distorta: Un cronometro che, a causa di un difetto di fabbricazione, parte sempre con 2 secondi di ritardo ma poi misura i tempi con estrema coerenza. Risultato: tutte le misure saranno molto simili (alta precisione), ma sempre sfasate di 2 secondi (alto bias).\n\nPoco precisa ma non distorta: Un termometro vecchio che a volte segna 36,2°C, altre 36,7°C, altre 37,1°C, senza un pattern sistematico. In media potrebbe risultare vicino ai 36,5°C, quindi senza un bias chiaro, ma con un’alta variabilità tra una misurazione e l’altra (bassa precisione).\n\n\nConseguenze di scarsa precisione e alto bias\n\n\nSe uno strumento è poco preciso (alta variabilità) e altamente distorto (bias elevato), i risultati ottenuti non solo oscillano in modo imprevedibile, ma sono costantemente lontani dal valore “vero”.\n\nIn queste condizioni, le conclusioni diventano inaffidabili, poiché è quasi impossibile distinguere l’effetto reale (casuale o causale) dalle deformazioni introdotte dallo strumento e dall’errore di misura.\n\nEsercizio 4 – Validità Interna ed Esterna\n\nDue fattori che compromettono la validità interna e due fattori che compromettono la validità esterna (nell’esempio del mind-body healing)\n\n\nValidità interna:\n\nAssegnazione non casuale ai gruppi: se i partecipanti scelgono autonomamente di aderire alle pratiche mente-corpo, potrebbero essere più motivati o avere caratteristiche iniziali diverse.\n\nMancata o inadeguata gestione dell’effetto placebo: non sapere se l’intervento “mente-corpo” sia stato percepito come particolarmente “speciale” dai partecipanti può introdurre differenze di aspettativa.\n\nValidità esterna:\n\nCampione non rappresentativo: se lo studio è condotto solo su persone che frequentano un determinato tipo di centro di benessere, i risultati potrebbero non essere generalizzabili all’intera popolazione.\n\nContesto specifico: pratiche mente-corpo svolte in un ambiente estremamente controllato (es. un laboratorio o un ritiro speciale) potrebbero non replicarsi nella vita quotidiana di chiunque.\n\n\n\nDifferenze tra validità interna ed esterna (5-8 righe di esempio)\n\n\nLa validità interna si riferisce alla correttezza del disegno di ricerca nel dimostrare un effetto causale. Un alto livello di validità interna implica che i ricercatori siano ragionevolmente sicuri che l’intervento (ad esempio, una tecnica mente-corpo) abbia causato i risultati osservati (miglioramento della salute). La validità esterna, invece, riguarda la possibilità di generalizzare i risultati a contesti, persone e tempi differenti. Se un intervento è stato testato in condizioni molto specifiche, potrebbe funzionare bene solo in quel contesto e con quel particolare campione. Per esempio, un intervento sul mind-body healing con individui altamente motivati potrebbe non dare gli stessi risultati in una popolazione generalizzata. Allo stesso modo, uno studio sull’apprendimento condotto in un laboratorio altamente controllato potrebbe non riflettere le reali dinamiche di un’aula scolastica.\n\n\nModifica al disegno di ricerca per migliorare la validità interna e conseguenze sulla validità esterna\n\n\nProposta: Introdurre un gruppo di controllo con un intervento placebo o un’attività simile ma priva di contenuto “mente-corpo” (ad es. sessioni di lettura rilassante). In questo modo, si può confrontare l’effetto “specífico” dell’intervento.\nCome influenza la validità interna: Con un gruppo di controllo placebo, diventa più semplice escludere che il miglioramento sia dovuto solo alle aspettative dei partecipanti. Questo riduce il rischio di confondenti e aumenta la validità interna.\nCome influenza la validità esterna: Potrebbe rendere il contesto dello studio più artificiale (un gruppo fa “meditazione”, l’altro legge in silenzio), il che potrebbe ridurre la naturalezza della situazione e potenzialmente limitare la generalizzabilità ad ambienti reali (validità esterna).\n\nEsercizio 5 – Integrare Teoria e Misurazione: Breve Progetto di Ricerca\n\nBreve traccia di progetto: “Training di rilassamento mentale per ridurre l’ansia negli studenti universitari”\n\n\nTeoria di base\nIl training di rilassamento mentale si fonda sul presupposto teorico che le tecniche di riduzione dello stress (es. respirazione consapevole, rilassamento muscolare progressivo) possano agire sui livelli di attivazione fisiologica e sui pensieri intrusivi. Riducendo l’iperattivazione del sistema nervoso simpatico e favorendo uno stato di calma, diminuisce l’ansia percepita.\nIpotesi\nGli studenti che seguono il training di rilassamento per 4 settimane mostreranno una riduzione significativa nei punteggi di ansia, rispetto a un gruppo di controllo che non partecipa al training.\nMisurazione\nUtilizzo di una scala validata come lo STAI (State-Trait Anxiety Inventory) per misurare il livello di ansia pre e post intervento. Possibile integrazione con misure fisiologiche (battito cardiaco a riposo) per avere dati oggettivi.\nControllo dei confondenti\n\nRegistrare la storia clinica dei partecipanti (per escludere coloro che assumono farmaci ansiolitici).\n\nRichiedere che i partecipanti non modifichino drasticamente le proprie abitudini di studio o di vita durante l’intervento.\n\nAssicurarsi che i valutatori non sappiano chi fa parte del gruppo di training o del gruppo di controllo (blinding parziale).\n\nValidità\n\nValidità interna: Uso di un gruppo di controllo e assegnazione casuale (randomizzazione) per assicurare che i due gruppi siano comparabili.\n\nValidità esterna: Inclusione di studenti provenienti da diverse facoltà, così da riflettere una maggiore eterogeneità di popolazione.\n\n\n\nCome teoria solida e misurazione accurata evitano la “junk science”\n\n\nUna solida cornice teorica spiega i meccanismi psicologici e fisiologici che legano l’intervento (training di rilassamento) all’esito (riduzione dell’ansia).\n\nUna misurazione accurata e validata (STAI, misure fisiologiche) riduce errori e distorsioni. Se le misure sono ripetute nel tempo (pre e post), si possono confrontare i cambiamenti effettivi.\n\nIntegrando teoria e misurazione, i risultati assumono un significato scientifico più robusto. Non basta osservare un miglioramento: occorre dimostrare come e perché tale miglioramento avvenga, evitando di cadere in semplici correlazioni prive di spiegazione (e quindi potenzialmente “junk science”).\n\n\n\n\n\n\n\n\n\n\nProblemi 3\n\n\n\n\n\nEsercizio 1 – Trasformazioni in Scala Nominale\nSituazione\nUn ricercatore vuole indagare la percezione di appartenenza sociale tra studenti universitari di Psicologia. A ciascuno studente viene chiesto di rispondere alla domanda: “Qual è il gruppo studentesco a cui ritieni di appartenere maggiormente?”, scegliendo una tra le seguenti categorie:\n\n\nGruppo A (focalizzato su ricerca e studio)\n\n\n\nGruppo B (focalizzato su attività ricreative)\n\n\n\nGruppo C (focalizzato su volontariato e progetti sociali)\n\n\nIstruzioni\n\nIdentifica la scala di misurazione utilizzata per classificare gli studenti (nominale, ordinale, a intervalli o di rapporti).\n\nIndica quali trasformazioni sono ammissibili su questa scala e spiega perché non è possibile applicare operazioni di tipo aritmetico (somme, differenze, etc.).\n\nProponi un esempio di nuova scala nominale equivalente, ossia una nuova denominazione delle categorie che rispetti la suddivisione originale. (Esempio: rinominarle in Gruppo X, Gruppo Y, Gruppo Z, oppure usare colori, animali-simbolo, ecc.). Spiega perché questa trasformazione non altera i risultati dell’indagine.\n\nEsercizio 2 – Trasformazioni in Scala Ordinale\nSituazione\nIn un questionario sul benessere psicologico, agli studenti viene chiesto di classificare il loro stato di motivazione allo studio su una scala da 1 (bassa motivazione) a 5 (alta motivazione). Si ottiene così un dato ordinalmente misurato.\nIstruzioni\n\nSpiega perché tale variabile (“livello di motivazione”) rappresenta una scala ordinale. Quali proprietà la rendono diversa da una semplice scala nominale?\n\nDescrivi in che modo è possibile ridenominare i valori della scala (ad esempio, da [1,2,3,4,5] a [“Molto bassa”, “Bassa”, “Media”, “Alta”, “Molto alta”]) senza alterare il rapporto d’ordine tra le categorie.\n\nProponi un esempio di trasformazione non ammissibile: qual è un’operazione aritmetica che non avrebbe senso applicare su una scala ordinale e perché (ad esempio, calcolare “il doppio di motivazione”)?\n\nEsercizio 3 – Trasformazioni in Scala ad Intervalli\nSituazione\nUn gruppo di ricercatori in Psicometria vuole confrontare i punteggi di un test d’intelligenza (misurati secondo la scala tradizionale del QI, con media 100 e deviazione standard 15) con un nuovo test sperimentale. Come ben noto, la scala del QI è considerata, nelle sue approssimazioni psicometriche, una scala ad intervalli.\nIstruzioni\n\nSpiega in cosa consiste la trasformazione lineare ammessa (del tipo \\(y' = a + b y\\), con \\(b &gt; 0\\)) e perché tale trasformazione preserva le differenze tra i punteggi.\n\nFai un esempio concreto di trasformazione lineare: supponi di voler “riscalare” i punteggi del QI in modo che la nuova media sia 50. Definisci i valori di \\(a\\) e \\(b\\) (indicando un’ipotesi di calcolo) e mostra come viene modificato il punteggio di un individuo con QI = 115.\n\nDiscuta perché, nonostante la somiglianza con le scale ordinale e nominale (puoi comunque distinguere punteggi e ordinarli), una scala ad intervalli consente operazioni matematiche più complesse (ad esempio, differenze) che non sarebbero valide negli altri due livelli.\n\nEsercizio 4 – Trasformazioni in Scala di Rapporti\nSituazione\nUn laboratorio di psicofisiologia misura i tempi di reazione (in millisecondi) a uno stimolo luminoso. Poiché il tempo di reazione pari a 0 ms significa realmente assenza di risposta (ovvero, impossibile da misurare in pratica, ma concettualmente corrisponde a intensità nulla del fenomeno “tempo di reazione”), ci troviamo in una scala di rapporti.\nIstruzioni\n\nSpiega perché il tempo di reazione soddisfa i requisiti di una scala di rapporti, inclusa la presenza di uno zero assoluto e la possibilità di confrontare i punteggi con rapporti (ad esempio, “il tempo di reazione del partecipante A è il doppio di quello del partecipante B”).\n\nQuali sono le trasformazioni ammissibili su una scala di rapporti? Fornisci un esempio numerico (per esempio, se moltiplichi tutti i tempi di reazione per 2, che cosa accade al rapporto tra i punteggi di due partecipanti?).\n\nDescrivi il motivo per cui è possibile dire che A ha una latenza doppia di B usando i millisecondi, ma non è sempre possibile fare asserzioni analoghe usando scale ad intervalli. Fai un parallelo, ad esempio, con le temperature in Celsius.\n\nEsercizio 5 – Riconoscere e Applicare le Trasformazioni nei Quattro Livelli di Scala\nSituazione\nUn docente di Psicologia sperimentale ha raccolto quattro serie di dati su vari aspetti:\n\nOrientamento politico (liberale, conservatore, centrista, ecc.).\n\nClassifica di soddisfazione sul tirocinio (1° posto, 2° posto, 3° posto, etc.).\n\nPunteggi di un test di personalità su un fattore (con media = 100, deviazione standard = 10) trattato come scala ad intervalli.\n\nFrequenza cardiaca a riposo misurata in battiti al minuto (bpm).\n\nIstruzioni\n\nIdentifica per ciascuno dei quattro insiemi di dati il livello di scala (nominale, ordinale, intervalli, rapporti).\n\nPer ognuno dei quattro livelli di scala elenca almeno una trasformazione ammessa (ad es. ridenominazione delle categorie per la nominale, traslazione e dilatazione per l’intervalli, ecc.) e una non ammessa (esempio: non puoi sommare categorie nominali, non puoi calcolare la radice quadrata di un rango ordinale dandogli significato, ecc.).\n\nRifletti in breve (2-3 righe) su come queste differenze nelle trasformazioni ammissibili incidano sull’interpretazione dei dati e sulle analisi statistiche che il docente potrà validamente utilizzare (ad esempio, test non parametrici per variabili ordinarie, test parametrici per scale ad intervalli/rapporti).\n\n\n\n\n\n\n\n\n\n\nSoluzioni 3\n\n\n\n\n\nEsercizio 1 – Trasformazioni in Scala Nominale\n\nIdentificazione della scala La classificazione degli studenti in “Gruppo A/B/C” è scala nominale. Non esiste alcun ordine intrinseco tra le categorie; si tratta semplicemente di etichette qualitative.\nTrasformazioni ammissibili\n\n\nTrasformazioni ammissibili: ridenominare o rinominare le categorie senza modificare la partizione del campione (esempio: A → “Studio”, B → “Ricreazione”, C → “Volontariato”).\n\nL’unica operazione aritmetica consentita è il conteggio delle frequenze nelle varie categorie.\n\n\nOperazioni non consentite: non è possibile sommare o sottrarre etichette, né confrontare categorie in termini di “più/meno grande” o “rapporto”.\n\n\nEsempio di nuova scala nominale equivalente\n\n\nPotresti chiamare i gruppi: “Alpha, Beta, Gamma” (oppure con colori: “Rosso, Blu, Verde”).\n\nQuesta trasformazione non altera la classificazione in sé: tutti gli studenti del Gruppo A rimangono nel “nuovo” gruppo Alpha, e così via.\n\nNon cambia la struttura dei dati e di conseguenza non altera i risultati della ricerca (restano invariate le frequenze e la suddivisione nelle categorie).\n\nEsercizio 2 – Trasformazioni in Scala Ordinale\n\nPerché è una scala ordinale? La variabile “livello di motivazione” da 1 (bassa) a 5 (alta) indica:\n\n\nClassificazione in categorie (come in una scala nominale).\n\nRelazione d’ordine chiara (1 &lt; 2 &lt; 3 &lt; 4 &lt; 5).\n\nNon fornisce alcuna informazione sulle distanze reali tra i punti (non è detto che la differenza tra 1 e 2 sia uguale a quella tra 3 e 4).\nÈ quindi una scala ordinale e non semplicemente nominale.\n\n\nRidenominazione dei valori mantenendo l’ordine\n\n\nPuoi sostituire i numeri con etichette testuali rispettando lo stesso ordine:\n1 → “Molto bassa”\n2 → “Bassa”\n3 → “Media”\n4 → “Alta”\n5 → “Molto alta”\n\nL’ordine rimane lo stesso: “Molto bassa” &lt; “Bassa” &lt; … &lt; “Molto alta”.\n\n\nEsempio di trasformazione non ammissibile\n\n\nCalcolare “il doppio di motivazione”: dire che la categoria 4 è “il doppio” della categoria 2 non ha senso, perché non c’è un’unità di misura fissa che quantifichi la differenza tra i livelli. Le categorie ordinali servono solo a ordinare, non a quantificare in modo assoluto.\n\nEsercizio 3 – Trasformazioni in Scala ad Intervalli\n\nTrasformazione lineare ammessa\n\n\nForma generale: \\(y' = a + b y\\), con \\(b &gt; 0\\).\n\nPreserva le differenze tra i valori (ad esempio, \\((y_2 - y_1) = (y'_2 - y'_1) / b\\)), perché la traslazione aggiunge una costante a tutti i punteggi e la dilatazione (moltiplicazione per \\(b\\)) mantiene le proporzioni fra gli intervalli.\n\n\nEsempio concreto\n\n\nScala QI: media = 100, deviazione standard = 15.\n\nVuoi che la nuova media sia 50.\n\nPer semplificare, supponiamo di voler “spostare” ogni valore verso una nuova scala centrata a 50, mantenendo una deviazione standard proporzionale.\n\nUna possibile trasformazione lineare:\n\\[\n  y' = (y - 100) + 50 = y - 50.\n\\]\nIn questo caso, \\(a = -50\\), \\(b = 1\\).\n\nSe un individuo ha QI = 115, allora \\(y' = 115 - 50 = 65\\).\n\n\nSe invece volessi anche cambiare la deviazione standard, potresti usare un fattore \\(b \\neq 1\\). Ad esempio, se desideri una deviazione standard = 10, potresti usare \\(b = \\frac{10}{15} \\approx 0.67\\).\n\n\nDifferenze rispetto alle scale nominali/ordinali\n\n\nCon una scala ad intervalli puoi:\n\nOrdinare i punteggi.\n\nStabilire differenze (es. un individuo A ha 15 punti in più di B).\n\n\nNon puoi invece stabilire rapporti (es. “A ha il doppio di X rispetto a B” non è lecito), perché lo zero è arbitrario e la distanza “0” non rappresenta l’assenza del fenomeno (come invece avviene nella scala di rapporti).\n\nEsercizio 4 – Trasformazioni in Scala di Rapporti\n\nPerché il tempo di reazione è in una scala di rapporti?\n\n\nZero assoluto: un tempo di reazione (teoricamente) pari a 0 ms significherebbe nessun tempo trascorso → totale assenza del fenomeno misurato (impossibile nella pratica, ma concettualmente definisce uno zero non arbitrario).\n\nPuoi confrontare i punteggi con rapporti: “il tempo di reazione di A è il doppio di quello di B” (200 ms vs. 100 ms).\n\n\nTrasformazioni ammissibili\n\n\nTrasformazione di similarità: \\(y' = b y\\) con \\(b &gt; 0\\).\n\nSe hai due tempi di reazione \\(y_1\\) e \\(y_2\\), il rapporto \\(\\frac{y_1}{y_2}\\) rimane invariato anche dopo la trasformazione:\n\\[\n  \\frac{y'_1}{y'_2} = \\frac{b y_1}{b y_2} = \\frac{y_1}{y_2}.\n\\]\nEsempio numerico: se i tempi di reazione di due partecipanti sono 100 ms e 200 ms, il rapporto è 2. Se moltiplichi entrambi per 2, ottieni 200 ms e 400 ms, e il rapporto rimane 2.\n\n\nConfronto con scala ad intervalli (esempio delle temperature)\n\n\nIn una scala di rapporti puoi dire “A ha una latenza doppia di B” perché lo zero non è arbitrario.\n\nCon la temperatura (scala ad intervalli) lo zero (es. 0°C) non rappresenta l’assenza di calore, quindi non ha senso dire che 80°C è “il doppio” di 40°C. Cambiando la scala (ad es. Fahrenheit) il rapporto cambia.\n\nEsercizio 5 – Riconoscere e Applicare le Trasformazioni nei Quattro Livelli di Scala\n\nIdentificazione del livello di scala\n\n\nOrientamento politico: scala nominale (categorie qualitative prive di ordine).\n\nClassifica di soddisfazione (1°, 2°, 3°, …): scala ordinale (c’è un ordine, ma non si conosce la “distanza” fra i posti).\n\nPunteggi di un test di personalità (con media=100, dev.st=10), considerati approssimazione di una scala ad intervalli (si assumono le differenze significative, lo zero è arbitrario).\n\nFrequenza cardiaca a riposo (bpm): scala di rapporti (zero assoluto e rapporti confrontabili).\n\n\nTrasformazioni ammesse e non ammesse\n\n\nNominale:\n\nAmmessa: cambiare etichette (A → “Liberale”, B → “Conservatore” ecc.).\n\nNon ammessa: sommare categorie, ordinare, calcolare media delle categorie.\n\n\nOrdinale:\n\nAmmessa: rietichettare i ranghi (1° → “Migliore”, 2° → “Secondo posto”…).\n\nNon ammessa: calcolare rapporti (il 2° posto non è “il doppio” del 1°), sommare posizioni in modo significativo.\n\n\nA intervalli:\n\nAmmessa: trasformazione lineare (traslazione + dilatazione).\n\nNon ammessa: dire che un punteggio è “tre volte” un altro; lo zero è arbitrario.\n\n\nA rapporti:\n\nAmmessa: trasformazione di similarità (\\(y' = b y\\)), in cui i rapporti rimangono invariati.\n\nNon ammessa: aggiunta di una costante a tutti i valori (questa sposterebbe lo zero, rendendolo arbitrario e trasformando la scala in una scala ad intervalli).\n\n\n\nImplicazioni per l’interpretazione e le analisi\n\n\nUna variabile nominale consente solo frequenze e test non parametrici basati su conteggi (es. Chi-quadrato).\n\nUna variabile ordinale permette test di ordinamento (es. test di rank, come il Wilcoxon), ma non calcoli di media con significato forte.\n\nUna scala ad intervalli permette di usare statistiche parametriche (calcolo di media, varianza, test come t-test, ANOVA), assumendo che l’interpretazione delle differenze sia coerente.\n\nUna scala di rapporti permette, in più, il confronto di rapporti (ad esempio, si possono applicare modelli parametrici che includano il concetto di proporzioni o slope logico su dati che abbiano senso a zero assoluto).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/04_measurement.html#bibliografia",
    "href": "chapters/key_notions/04_measurement.html#bibliografia",
    "title": "4  La misurazione in psicologia",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAungle, P., & Langer, E. (2023). Physical healing as a function of perceived time. Scientific Reports, 13(1), 22432.\n\n\nDomini, F., & Caudek, C. (2009). The intrinsic constraint model and Fechnerian sensory scaling. Journal of Vision, 9(2), 25–25.\n\n\nLilienfeld, S. O., & Strother, A. N. (2020). Psychological measurement and the replication crisis: Four sacred cows. Canadian Psychology/Psychologie Canadienne, 61(4), 281–288.\n\n\nMaul, A., Irribarra, D. T., & Wilson, M. (2016). On the philosophical foundations of psychological measurement. Measurement, 79, 311–320.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/05_cognitive_models.html",
    "href": "chapters/key_notions/05_cognitive_models.html",
    "title": "5  Modelli cognitivi",
    "section": "",
    "text": "5.1 Introduzione\nIn questo corso esploreremo perché un’analisi puramente associativa tra variabili non sia sufficiente per comprendere i meccanismi causali nei fenomeni psicologici. Una strategia più efficace consiste nel formalizzare quantitativamente i modelli dei processi psicologici di interesse e testarli empiricamente.\nPer rendere concreto il concetto di processo generatore dei dati in psicologia, introdurremo due modelli psicologici fondamentali: il modello di apprendimento associativo di Rescorla-Wagner e il Drift-Diffusion Model.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelli cognitivi</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/05_cognitive_models.html#modello-di-apprendimento-associativo-di-rescorla-wagner",
    "href": "chapters/key_notions/05_cognitive_models.html#modello-di-apprendimento-associativo-di-rescorla-wagner",
    "title": "5  Modelli cognitivi",
    "section": "\n5.2 Modello di Apprendimento Associativo di Rescorla-Wagner",
    "text": "5.2 Modello di Apprendimento Associativo di Rescorla-Wagner\nUno dei modelli più influenti nello studio dell’apprendimento è il modello di Rescorla-Wagner. Questo modello descrive come gli individui apprendano le associazioni tra stimoli e risposte sulla base dell’errore di previsione. L’apprendimento avviene aggiornando le aspettative di ricompensa in base alle esperienze passate, utilizzando due parametri fondamentali:\n\n\nα (tasso di apprendimento): determina quanto l’errore di previsione influisce sull’aggiornamento dell’aspettativa.\n\nβ (temperatura della scelta): regola la probabilità di selezionare l’opzione con il valore atteso più alto rispetto a esplorare alternative.\n\n\n5.2.1 L’Apprendimento Associativo\nL’apprendimento per rinforzo studia come le persone imparano a massimizzare le ricompense in ambienti in cui la scelta ottimale è inizialmente sconosciuta. Immaginiamo un partecipante che deve scegliere ripetutamente tra due slot machine, ricevendo ricompense con probabilità diverse per ogni macchina. L’obiettivo è massimizzare le vincite nel tempo.\nPer illustrare il modello, si usa spesso la metafora delle slot machine. Nel caso più semplice, si immagina un agente che svolge il compito con \\(n\\) tentativi, due slot machine e probabilità di ricompensa fisse \\(\\mu = [0.2, 0.8]\\).\n\n5.2.2 Regola di Apprendimento per Rinforzo (\\(\\delta\\)-rule)\nIl modello di Rescorla-Wagner descrive l’apprendimento come un processo basato sull’errore di previsione. L’aggiornamento del valore di uno stimolo avviene secondo la seguente equazione:\n\\[\nV_{s,t} = V_{s,t-1} + \\alpha (r_{t-1} - V_{s,t-1})\n\\]\nDove:\n\n\n\\(V_{s,t}\\) è il valore atteso dello stimolo \\(s\\) al tempo \\(t\\).\n\n\\(r_{t-1}\\) è la ricompensa ottenuta alla prova precedente.\n\n\\(\\alpha\\) (tra 0 e 1) è il tasso di apprendimento, che determina la velocità con cui l’agente aggiorna le proprie aspettative.\n\nSe il valore di \\(\\alpha\\) è alto, l’apprendimento sarà rapido, mentre se è basso, l’agente si baserà maggiormente sulle esperienze passate.\n\n5.2.3 Modello di Scelta: Softmax\nDopo aver aggiornato i valori attesi delle opzioni, il partecipante deve scegliere tra esse.\nDue strategie possibili sono:\n\n\nSfruttamento: selezionare sempre l’opzione con il valore più alto.\n\nEsplorazione: scegliere occasionalmente un’opzione con un valore più basso per verificare se potrebbe essere migliore.\n\nPer modellare questo comportamento si usa la funzione Softmax:\n\\[\np(s) = \\frac{\\exp(\\beta \\cdot V_{s})}{\\sum_i \\exp(\\beta \\cdot V_{i})}\n\\]\nDove \\(\\beta\\) è un parametro che determina il grado di esplorazione:\n\n\n\\(\\beta = 0\\): scelta completamente casuale.\n\n\\(\\beta \\to \\infty\\): scelta deterministica dell’opzione con il valore più alto.\n\nUn individuo con \\(\\beta\\) alto sceglierà quasi sempre l’opzione con il valore atteso più elevato, mentre con un \\(\\beta\\) basso esplorerà più frequentemente.\n\n5.2.4 Simulazione dell’Apprendimento con il Modello di Rescorla-Wagner\nPossiamo implementare la regola di aggiornamento in R con la seguente funzione:\n\nupdate_rw &lt;- function(value, alpha=0.15, lambda=1) {\n  value + alpha * (lambda - value)\n}\n\nSimuliamo ora l’apprendimento per 40 prove, assumendo che il partecipante riceva sempre una ricompensa:\n\nn_trials &lt;- 40\nstrength &lt;- numeric(n_trials)\nfor(trial in 2:n_trials) {\n  strength[trial] &lt;- update_rw(strength[trial-1])\n}\nplot(1:n_trials, strength, type = 'l', ylim = c(0,1), xlab = \"Prove\", ylab = \"Aspettativa di ricompensa\")\n\n\n\n\n\n\n\nL’aspettativa di ricompensa aumenta progressivamente fino a stabilizzarsi.\n\n5.2.5 Estinzione dell’Associazione\nSe dopo 25 prove la ricompensa non viene più fornita, il valore associato allo stimolo diminuisce gradualmente:\n\nn_trials &lt;- 50                \nstrength &lt;- numeric(n_trials)\nlambda &lt;- 1\n\nfor(trial in 2:n_trials) {\n  if(trial &gt; 25) {\n    lambda &lt;- 0\n  }\n  strength[trial] &lt;- update_rw(value = strength[trial-1], lambda = lambda)\n}\n\nplot(1:n_trials, strength, type = 'l', ylim = c(0,1), xlab = \"Prove\", ylab = \"Aspettativa di ricompensa\")\n\n\n\n\n\n\n\nL’associazione si estingue gradualmente quando il rinforzo viene rimosso.\n\n5.2.6 Implementazione della Regola Softmax\nPer simulare le scelte di un partecipante utilizziamo la funzione Softmax:\n\nsoftmax &lt;- function(beta, x) {\n  1 / (1 + exp(-beta * x))\n}\n\nbeta &lt;- 5\nx &lt;- seq(-1, 1, length.out = 100)\ny &lt;- softmax(beta, x)\nplot(x, y, type = 'l', xlab = \"Valore (A) - valore (B)\", ylab = \"p(scelta = A)\")\n\n\n\n\n\n\n\nLa funzione mostra che:\n\nLa probabilità di scegliere un’opzione aumenta con il suo valore atteso.\nCon \\(\\beta\\) elevato, il partecipante sceglie quasi sempre l’opzione migliore.\nCon \\(\\beta\\) basso, le scelte sono più casuali.\n\n5.2.7 Verifica e Applicazioni del Modello\nQuello descritto è il meccanismo generatore dei dati ipotizzato dal modello di Rescorla-Wagner. Per testare il modello, è necessario stimare i parametri \\(\\alpha\\) e \\(\\beta\\), e confrontare le previsioni del modello con i dati osservati. Tuttavia, in questo corso non affronteremo il problema della stima dei parametri del modello di Rescorla-Wagner. L’obiettivo principale è comprendere cosa significhi formalizzare quantitativamente un modello psicologico e in che modo questo approccio si differenzi da una semplice analisi delle associazioni tra variabili.\nIn sintesi, il modello di Rescorla-Wagner rappresenta uno strumento essenziale per lo studio dell’apprendimento associativo. Attraverso la simulazione dell’aggiornamento delle aspettative e delle strategie decisionali, possiamo descrivere il comportamento di individui che apprendono in contesti di rinforzo. Questo modello ha trovato applicazione in numerosi ambiti della psicologia cognitiva e delle neuroscienze, contribuendo alla comprensione dei processi di apprendimento e decisione.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelli cognitivi</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/05_cognitive_models.html#drift-diffusion-model",
    "href": "chapters/key_notions/05_cognitive_models.html#drift-diffusion-model",
    "title": "5  Modelli cognitivi",
    "section": "\n5.3 Drift Diffusion Model",
    "text": "5.3 Drift Diffusion Model\nIl processo decisionale è uno dei temi centrali della psicologia cognitiva e delle neuroscienze. Ogni giorno prendiamo decisioni, dalle più semplici alle più complesse, influenzate da fattori come la percezione, la memoria, l’attenzione e il contesto in cui ci troviamo. Una domanda fondamentale è: Come prendiamo decisioni in condizioni di incertezza?\nUno dei modelli più utilizzati per rispondere a questa domanda è il Drift Diffusion Model (DDM), un modello matematico che descrive il processo di accumulo delle informazioni fino alla presa di una decisione. Questo modello consente di quantificare e comprendere i meccanismi alla base delle scelte umane.\n\n5.3.1 Cos’è il Drift Diffusion Model?\nIl DDM descrive come le persone raccolgono informazioni nel tempo per prendere una decisione tra due alternative. Immagina di dover stabilire se un punto si sta muovendo verso destra o verso sinistra. Non hai una risposta immediata, ma accumuli informazioni (o “evidenza”) nel tempo fino a quando non sei abbastanza sicuro per scegliere.\nQuesto processo è influenzato da vari fattori, come la chiarezza delle prove disponibili e l’incertezza associata alla decisione.\n\n5.3.2 Come Funziona il Processo di Accumulo dell’Evidenza?\nIl processo decisionale può essere paragonato a un accumulo graduale di informazioni a favore di una delle due opzioni disponibili. Ecco come funziona:\n\nRaccolta delle informazioni\nOgni nuova informazione che ricevi si accumula a favore di una delle due alternative. Ad esempio, se stai cercando di determinare la direzione del movimento di un punto, ogni piccolo dettaglio visivo ti aiuta ad avvicinarti a una decisione.\nVelocità di accumulo (Drift rate)\nLa velocità con cui raccogli le informazioni dipende dalla qualità del segnale. Se le prove sono chiare e forti, l’accumulo sarà veloce. Se invece sono ambigue, il processo sarà più lento.\nRumore e incertezza\nDurante l’accumulo, c’è sempre una componente casuale o “rumore”, che può causare fluttuazioni nel processo. Questo significa che l’informazione non si accumula in modo perfettamente lineare, ma può oscillare a causa di fattori casuali.\nSoglie decisionali\nPrima di iniziare il compito, ci sono due “soglie” che rappresentano i punti di decisione. Quando l’evidenza accumulata raggiunge una di queste soglie, si prende la decisione corrispondente.\nTempo di reazione\nIl tempo impiegato per raggiungere una delle soglie è il tempo di reazione. Se le informazioni sono chiare, la decisione sarà rapida; se sono ambigue, il tempo sarà più lungo.\n\nUn’utile metafora per comprendere questo processo è quella di riempire un secchio con informazioni: ogni evidenza raccolta equivale a una goccia d’acqua che viene aggiunta al secchio. Quando il livello d’acqua raggiunge una delle due soglie, viene presa la decisione.\n\n5.3.3 I Parametri del DDM\nIl DDM è caratterizzato da quattro parametri principali che descrivono diversi aspetti del processo decisionale:\n\nTasso di drift (\\(v\\))\nRappresenta la velocità con cui l’evidenza si accumula a favore di una decisione. Valori più alti indicano un processo decisionale più efficiente, mentre valori più bassi suggeriscono un’accumulazione lenta e incerta.\nSeparazione delle soglie (\\(a\\))\nIndica la distanza tra le due soglie decisionali. Valori più alti corrispondono a decisioni più caute (tempi di reazione più lunghi ma minore probabilità di errore), mentre valori più bassi indicano decisioni più rapide ma potenzialmente meno accurate.\nTempo di non-decisione (\\(t_0\\))\nCorrisponde al tempo necessario per processi che precedono e seguono l’accumulo di evidenza, come la percezione dello stimolo e l’esecuzione della risposta. Questo tempo è indipendente dall’accumulo delle informazioni.\nBias iniziale (\\(z\\))\nDefinisce il punto di partenza del processo di accumulo. Se è equidistante tra le due soglie, la decisione è imparziale. Se invece è spostato verso una delle due soglie, significa che la persona ha una predisposizione a scegliere una delle due alternative.\n\n5.3.4 Il Compromesso tra Velocità e Accuratezza\nUno degli aspetti più interessanti del DDM è il compromesso tra velocità e accuratezza.\n\nSe una persona desidera rispondere rapidamente, può abbassare le soglie decisionali, ma questo aumenta la probabilità di errore.\n\nSe invece punta a una maggiore accuratezza, può aumentare la distanza tra le soglie, rendendo il processo più lento ma più affidabile.\n\nQuesto compromesso è evidente in compiti sperimentali come:\n\nIl compito di Stroop, dove bisogna ignorare un’informazione interferente (es. leggere il colore di una parola e non il significato della parola stessa).\n\nIl compito di decisione lessicale, in cui si deve determinare se una stringa di lettere è una parola esistente o meno.\n\nIl DDM permette di capire se le differenze nei tempi di reazione tra gruppi dipendono da una strategia più cauta (maggiore \\(a\\)) o da una difficoltà nell’accumulare evidenza (minore \\(v\\)).\n\n5.3.5 Perché è Importante il DDM?\nIl DDM è uno strumento potente perché permette di quantificare aspetti del processo decisionale che altrimenti sarebbero difficili da misurare, come la velocità di accumulo dell’evidenza o l’effetto del rumore sulla decisione.\nÈ stato applicato in numerosi ambiti, tra cui:\n\n\nCompiti percettivi e decisionali: studi sulla discriminazione di stimoli visivi e uditivi.\n\nProcessi di controllo cognitivo: analisi delle differenze individuali nella regolazione dell’impulsività.\n\nPsicopatologia: esplorazione delle alterazioni nel processo decisionale in condizioni come depressione, ansia e schizofrenia.\n\nIl Drift Diffusion Model offre dunque una rappresentazione chiara e quantitativa del processo decisionale in condizioni di incertezza. Descrivendo l’accumulo graduale delle informazioni e il raggiungimento delle soglie decisionali, il modello ci aiuta a comprendere il compromesso tra velocità e accuratezza e i fattori che influenzano le scelte.\nL’applicazione del DDM in psicologia cognitiva e neuroscienze permette di studiare non solo il comportamento umano, ma anche i meccanismi neurali che regolano il processo decisionale.\n\n5.3.6 Simulazione del DDM\nUna delle potenzialità del DDM è la possibilità di simulare dati sintetici per confrontare le predizioni del modello con dati empirici. In R, possiamo generare una simulazione semplificata del modello utilizzando pacchetti dedicati come rtdists o brms.\nUn esempio di codice per simulare dati con parametri definiti:\n\n# Nuova configurazione dei parametri\na &lt;- 1.2   # Separazione delle soglie (aumentato)\nv &lt;- 0.3   # Tasso di drift\nt0 &lt;- 0.2  # Tempo di non-decisione\nz &lt;- 0.5   # Bias iniziale (deve essere tra 0 e 1)\n\n# Generazione dei dati\nsim_data &lt;- rdiffusion(n = 1000, a = a, v = v, t0 = t0, z = z)\n\n# Visualizzazione dei tempi di reazione\nhist(\n  sim_data$rt, \n  breaks = 30, \n  main = \"Distribuzione dei tempi di reazione\", \n  xlab = \"RT (s)\"\n)\n\n\n\n\n\n\n\nQuesto codice genera una distribuzione di tempi di reazione e scelte coerenti con le ipotesi del DDM, permettendo di esplorare l’effetto delle variazioni dei parametri sul comportamento del modello.\nIn sintesi, il Drift Diffusion Model fornisce un quadro teorico potente per l’analisi del processo decisionale in psicologia cognitiva. Modellando il tempo di reazione e la probabilità di risposta in termini di parametri interpretabili, il DDM permette di distinguere tra strategie decisionali e difficoltà cognitive, superando i limiti di un’analisi puramente descrittiva. Grazie alla sua capacità di catturare la dinamica dei processi decisionali, il DDM è oggi uno degli strumenti più utilizzati per studiare il comportamento umano in contesti sperimentali e applicativi.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelli cognitivi</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/05_cognitive_models.html#riflessioni-conclusive",
    "href": "chapters/key_notions/05_cognitive_models.html#riflessioni-conclusive",
    "title": "5  Modelli cognitivi",
    "section": "\n5.4 Riflessioni Conclusive",
    "text": "5.4 Riflessioni Conclusive\nUn modo per approfondire la comprensione dei processi di apprendimento e decisione è attraverso l’utilizzo di modelli computazionali. Questi modelli consentono di inferire i meccanismi cognitivi sottostanti partendo dai comportamenti osservabili, offrendo una formalizzazione quantitativa dei processi psicologici. In questo capitolo, abbiamo esaminato due modelli fondamentali: il modello di Rescorla-Wagner e il Drift Diffusion Model (DDM).\nIl modello di Rescorla-Wagner descrive l’apprendimento associativo come un aggiornamento incrementale delle aspettative basato sull’errore di previsione. Questo modello ha dimostrato una notevole capacità di spiegare come gli individui apprendano a stimare la probabilità di una ricompensa sulla base delle esperienze passate. Il parametro chiave in questo processo è il tasso di apprendimento \\(\\alpha\\), che determina la velocità con cui le aspettative vengono aggiornate in base alle nuove informazioni. L’utilizzo della funzione softmax, inoltre, permette di modellare il bilanciamento tra esplorazione ed sfruttamento nelle scelte.\nD’altra parte, il Drift Diffusion Model (DDM) fornisce una descrizione dettagliata del processo decisionale in compiti a due alternative, modellando l’accumulo graduale di evidenza fino al raggiungimento di una soglia decisionale. I parametri del DDM, tra cui il drift rate (\\(v\\)), la threshold separation (\\(a\\)), il non-decision time (\\(t_0\\)) e il starting point (\\(z\\)), permettono di distinguere tra velocità di elaborazione dell’informazione, strategie di risposta più o meno caute e tempi di esecuzione della risposta indipendenti dal processo decisionale.\nEntrambi i modelli evidenziano il valore della formalizzazione matematica nello studio dei processi cognitivi. Il modello di Rescorla-Wagner è particolarmente utile per comprendere come gli individui apprendano e aggiornino le proprie credenze sulla base dell’esperienza, mentre il DDM fornisce una rappresentazione più dettagliata delle dinamiche della presa di decisione e del compromesso tra velocità e accuratezza.\nIn conclusione, l’approccio computazionale alla psicologia cognitiva permette di superare i limiti di un’analisi puramente descrittiva, fornendo strumenti matematici per testare ipotesi sui processi cognitivi. L’uso combinato di modelli di apprendimento e di modelli decisionali consente di ottenere una visione più completa dei meccanismi che guidano il comportamento umano, con implicazioni per la ricerca di base e le applicazioni cliniche.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelli cognitivi</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/05_cognitive_models.html#esercizi",
    "href": "chapters/key_notions/05_cognitive_models.html#esercizi",
    "title": "5  Modelli cognitivi",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\n\nChe cosa descrive il modello di Rescorla-Wagner?\nQual è il ruolo del parametro α nel modello di Rescorla-Wagner?\nQuale funzione matematica viene utilizzata per modellare il bilanciamento tra esplorazione ed esploitazione nel modello di Rescorla-Wagner?\nQuali sono i principali parametri del Drift Diffusion Model (DDM)?\nIn che modo il DDM spiega il compromesso tra velocità e accuratezza nelle decisioni?\n\n\n\n\n\n\n\n\n\n\nSoluzioni\n\n\n\n\n\n\nIl modello di Rescorla-Wagner descrive come gli individui apprendano le associazioni tra stimoli e risposte in base all’errore di previsione. L’aspettativa di ricompensa viene aggiornata attraverso l’esperienza, con un processo regolato dal tasso di apprendimento (α).\nIl parametro α (tasso di apprendimento) determina quanto velocemente un individuo aggiorna le proprie aspettative in base all’errore di previsione. Se α è alto, l’apprendimento è rapido; se è basso, l’individuo si basa maggiormente sulle esperienze passate.\nLa funzione Softmax viene utilizzata per modellare il bilanciamento tra esplorazione ed esploitazione. Essa regola la probabilità di scegliere un’opzione in base al valore atteso e alla temperatura della scelta (β).\n\nI principali parametri del DDM sono:\n\n\nTasso di drift (v): velocità con cui viene accumulata l’evidenza.\n\n\nSeparazione delle soglie (a): distanza tra le soglie decisionali.\n\n\nTempo di non-decisione (t₀): tempo impiegato per processi indipendenti dall’accumulo dell’evidenza.\n\n\nBias iniziale (z): punto di partenza dell’accumulo dell’evidenza.\n\n\nIl DDM spiega il compromesso tra velocità e accuratezza attraverso la separazione delle soglie decisionali (a). Se le soglie sono più vicine, le decisioni sono più rapide ma meno accurate; se sono più distanti, le decisioni sono più lente ma più precise.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelli cognitivi</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/05_cognitive_models.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/key_notions/05_cognitive_models.html#informazioni-sullambiente-di-sviluppo",
    "title": "5  Modelli cognitivi",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] rtdists_0.11-5   thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0\n#&gt;  [5] see_0.11.0       gridExtra_2.3    patchwork_1.3.0  bayesplot_1.12.0\n#&gt;  [9] psych_2.5.3      scales_1.4.0     markdown_2.0     knitr_1.50      \n#&gt; [13] lubridate_1.9.4  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n#&gt; [17] purrr_1.0.4      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n#&gt; [21] ggplot2_3.5.2    tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.4     stringi_1.8.7      lattice_0.22-7    \n#&gt;  [4] hms_1.1.3          digest_0.6.37      magrittr_2.0.3    \n#&gt;  [7] evaluate_1.0.3     grid_4.5.0         timechange_0.3.0  \n#&gt; [10] RColorBrewer_1.1-3 mvtnorm_1.3-3      fastmap_1.2.0     \n#&gt; [13] Matrix_1.7-3       rprojroot_2.0.4    jsonlite_2.0.0    \n#&gt; [16] survival_3.8-3     mnormt_2.1.1       cli_3.6.5         \n#&gt; [19] expm_1.0-0         rlang_1.1.6        splines_4.5.0     \n#&gt; [22] gsl_2.1-8          withr_3.0.2        tools_4.5.0       \n#&gt; [25] parallel_4.5.0     tzdb_0.5.0         pacman_0.5.1      \n#&gt; [28] vctrs_0.6.5        R6_2.6.1           lifecycle_1.0.4   \n#&gt; [31] htmlwidgets_1.6.4  pkgconfig_2.0.3    pillar_1.10.2     \n#&gt; [34] gtable_0.3.6       Rcpp_1.0.14        glue_1.8.0        \n#&gt; [37] xfun_0.52          tidyselect_1.2.1   msm_1.8.2         \n#&gt; [40] rstudioapi_0.17.1  farver_2.1.2       htmltools_0.5.8.1 \n#&gt; [43] nlme_3.1-168       rmarkdown_2.29     compiler_4.5.0    \n#&gt; [46] evd_2.3-7.1",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelli cognitivi</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/05_cognitive_models.html#bibliografia",
    "href": "chapters/key_notions/05_cognitive_models.html#bibliografia",
    "title": "5  Modelli cognitivi",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nSoto, F. A., Vogel, E. H., Uribe-Bahamonde, Y. E., & Perez, O. D. (2023). Why is the Rescorla-Wagner model so influential? Neurobiology of Learning and Memory, 204, 107794.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelli cognitivi</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html",
    "href": "chapters/probability/15_likelihood.html",
    "title": "42  La verosimiglianza",
    "section": "",
    "text": "Introduzione\nI ricercatori utilizzano diversi modelli matematici per descrivere e prevedere il comportamento dei dati osservati. Questi modelli si distinguono tra loro per la struttura funzionale, ovvero il modo in cui collegano le variabili osservate con parametri teorici. La scelta del modello migliore avviene confrontando le previsioni teoriche generate dal modello con i dati effettivamente osservati. Il modello che produce previsioni più vicine ai dati reali viene considerato il più adeguato per descrivere il fenomeno studiato.\nIn questo processo di confronto, la funzione di verosimiglianza gioca un ruolo fondamentale. Essa quantifica la probabilità che i dati osservati siano stati generati da un particolare modello con determinati valori dei suoi parametri. In altre parole, la verosimiglianza misura quanto i dati siano compatibili con il modello ipotizzato.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#il-principio-della-verosimiglianza",
    "href": "chapters/probability/15_likelihood.html#il-principio-della-verosimiglianza",
    "title": "42  La verosimiglianza",
    "section": "\n42.1 Il Principio della Verosimiglianza",
    "text": "42.1 Il Principio della Verosimiglianza\nLa verosimiglianza misura quanto sia plausibile ciascun valore dei parametri alla luce dei dati osservati. In altre parole, indica quanto ogni possibile valore dei parametri sia compatibile con i dati raccolti.\n\nDefinizione 42.1 Consideriamo un vettore aleatorio \\(Y\\), la cui distribuzione è descritta da una funzione di densità (nel caso continuo) oppure da una funzione di massa di probabilità (nel caso discreto), indicata con \\(f(y \\mid \\theta)\\), dove \\(\\theta\\) è un vettore di parametri appartenente allo spazio parametrico \\(\\Theta\\).\nUna volta osservato un valore specifico \\(y\\) del vettore \\(Y\\), definiamo la funzione di verosimiglianza come una funzione che associa a ciascun valore possibile dei parametri \\(\\theta\\) la plausibilità di aver osservato proprio quei dati:\n\\[\nL(\\theta; y) = f(y \\mid \\theta).\n\\]\nIn questa espressione, i dati osservati \\(y\\) sono considerati fissi, mentre la variabile di interesse è \\(\\theta\\). La funzione di verosimiglianza esprime quindi quanto ogni possibile valore di \\(\\theta\\) sia compatibile con i dati osservati.\n\n\n42.1.1 Relazione tra Verosimiglianza e Funzione di Probabilità\nSia la funzione di probabilità (o densità) sia la funzione di verosimiglianza sono costruite sulla stessa espressione matematica: \\(f(y \\mid \\theta)\\). Tuttavia, il significato che attribuiamo a questa espressione cambia radicalmente a seconda del contesto inferenziale in cui ci troviamo.\nLa differenza tra funzione di probabilità e funzione di verosimiglianza riguarda il ruolo epistemologico assegnato ai dati e ai parametri:\n\nFunzione di densità (o massa) di probabilità:\nIn questo caso, assumiamo che i parametri \\(\\theta\\) siano noti e consideriamo i dati \\(y\\) come variabili aleatorie. La funzione \\(f(y \\mid \\theta)\\) rappresenta quindi il meccanismo generativo dei dati: ci dice quanto è probabile (o densa) l’osservazione di \\(y\\), se \\(\\theta\\) è fissato.\nFunzione di verosimiglianza:\nQui la prospettiva si inverte: i dati \\(y\\) sono fissi perché già osservati, mentre i parametri \\(\\theta\\) sono incogniti e rappresentano l’oggetto dell’inferenza. La funzione \\(L(\\theta; y) = f(y \\mid \\theta)\\) misura quanto ciascun valore possibile di \\(\\theta\\) sia compatibile con i dati osservati.\n\nFormalmente, la relazione è:\n\\[\nL(\\theta; y) = f(y \\mid \\theta)\n\\]\nma l’interpretazione è diversa:\n\n\n\\(f(y \\mid \\theta)\\) → probabilità di osservare \\(y\\), dato \\(\\theta\\) (parametri fissi, dati variabili);\n\n\\(L(\\theta; y)\\) → plausibilità di \\(\\theta\\), dati gli \\(y\\) osservati (dati fissi, parametri variabili).\n\nIn sintesi:\n\nLa funzione di probabilità risponde alla domanda:“Se i parametri fossero questi, quanto è probabile osservare questi dati?”\n\nLa funzione di verosimiglianza risponde alla domanda:“Dati questi dati, quali valori dei parametri sono più plausibili?”\n\n\nQuesta distinzione è fondamentale per l’inferenza statistica: mentre la funzione di probabilità descrive il processo generativo dei dati, la verosimiglianza gioca un ruolo centrale nell’aggiornamento delle credenze sui parametri.\nIn particolare, nella prospettiva bayesiana, la verosimiglianza fornisce l’informazione derivante dai dati osservati, che viene combinata con le credenze precedenti (prior) per ottenere la distribuzione a posteriori dei parametri.\nIn sintesi, la verosimiglianza ci dice quanto i dati supportano i diversi valori dei parametri. Nella visione bayesiana, essa è lo strumento attraverso cui i dati modificano le nostre credenze.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#la-log-verosimiglianza",
    "href": "chapters/probability/15_likelihood.html#la-log-verosimiglianza",
    "title": "42  La verosimiglianza",
    "section": "\n42.2 La Log-Verosimiglianza",
    "text": "42.2 La Log-Verosimiglianza\nPer ragioni sia analitiche che computazionali, si lavora spesso con la log-verosimiglianza, ovvero il logaritmo della funzione di verosimiglianza:\n\\[\n\\ell(\\theta; y) = \\log L(\\theta; y) = \\log f(y \\mid \\theta).\n\\]\nLa log-verosimiglianza presenta numerosi vantaggi:\n\n\nNumerici: i prodotti di probabilità molto piccole possono causare problemi di underflow numerico. Il logaritmo trasforma questi prodotti in somme, che sono numericamente più stabili.\n\nAnalitici: derivare la log-verosimiglianza rispetto ai parametri è spesso più semplice, facilitando la stima mediante metodi come il massimo della verosimiglianza (MLE).\n\nAdditività: se i dati sono indipendenti, la log-verosimiglianza totale è la somma delle log-verosimiglianze individuali:\n\n\\[\n\\ell(\\theta; y_1, \\dots, y_n) = \\sum_{i=1}^{n} \\log f(y_i \\mid \\theta).\n\\]\nQuesta proprietà è fondamentale nei modelli statistici in cui si assumono osservazioni indipendenti e identicamente distribuite (i.i.d.).\nInfine, è importante ricordare che massimizzare la log-verosimiglianza è equivalente a massimizzare la verosimiglianza, poiché il logaritmo è una funzione monotona crescente. Per questo motivo, molte tecniche di stima e modellazione in statistica e machine learning sono formulate in termini di log-verosimiglianza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#sequenza-di-lanci-di-una-moneta",
    "href": "chapters/probability/15_likelihood.html#sequenza-di-lanci-di-una-moneta",
    "title": "42  La verosimiglianza",
    "section": "\n42.3 Sequenza di Lanci di una Moneta",
    "text": "42.3 Sequenza di Lanci di una Moneta\nPer comprendere il concetto di verosimiglianza, iniziamo con un esempio semplice e intuitivo. Immagina di voler stimare la probabilità che una moneta cada su testa, e chiamiamo questa probabilità \\(p_H\\).\nIl nostro obiettivo è capire quali valori di \\(p_H\\) rendono più plausibile ciò che abbiamo osservato. Per farlo, vedremo come calcolare la probabilità di osservare determinate sequenze di lanci, assumendo che ogni lancio sia indipendente dagli altri.\n\n42.3.1 Perché moltiplichiamo le probabilità?\nSe lanciamo una moneta più volte, ogni risultato è indipendente dai precedenti: il fatto che esca “testa” o “croce” in un lancio non influenza il risultato del lancio successivo. Questo significa che la probabilità di osservare una specifica sequenza si ottiene moltiplicando le probabilità di ciascun singolo lancio.\nAd esempio, supponiamo che la probabilità di testa sia \\(p_H\\), e quindi la probabilità di croce sarà \\(1 - p_H\\). Se osserviamo la sequenza HTHT, allora la probabilità di ottenere questa sequenza è:\n\\[\nP(\\text{HTHT} \\mid p_H) = p_H \\cdot (1 - p_H) \\cdot p_H \\cdot (1 - p_H) = p_H^2 (1 - p_H)^2.\n\\]\nSe invece osserviamo una sequenza come THTH o HHTT, la probabilità è la stessa: \\(p_H^2 (1 - p_H)^2.\\) Questo perché non ci interessa l’ordine dei lanci, ma solo quante teste e quante croci abbiamo ottenuto.\n\n42.3.2 Generalizzazione\nIn generale, se lanciamo una moneta \\(n\\) volte e osserviamo \\(y\\) teste (successi) e \\(n - y\\) croci (insuccessi), la probabilità di ottenere una qualsiasi sequenza con questa configurazione è:\n\\[\nP(Y = y \\mid p_H) = p_H^y (1 - p_H)^{n - y}.\n\\tag{42.1}\\]\nQuesta espressione è la funzione di verosimiglianza, perché ci dice quanto un certo valore di \\(p_H\\) è compatibile con i dati osservati.\n\n42.3.3 Connessione con la Distribuzione Binomiale\nL’Equazione 42.1 è anche il nucleo della distribuzione binomiale. La formula completa per la probabilità binomiale è:\n\\[\nP(Y = y \\mid p_H) = \\binom{n}{y} p_H^y (1 - p_H)^{n - y}.\n\\]\nL’unica differenza è il coefficiente binomiale \\(\\binom{n}{y}\\), che conta quante sequenze diverse portano allo stesso numero di successi e insuccessi.\nQuando calcoliamo la verosimiglianza, possiamo ignorare questo coefficiente: non dipende da \\(p_H\\), quindi non influisce sul valore che massimizza la funzione. Per questo motivo, usiamo solo il “nucleo” della funzione binomiale:\n\\[\nL(p_H \\mid y) = p_H^y (1 - p_H)^{n - y}.\n\\tag{42.2}\\]\n\n42.3.4 Esempio 1: Due lanci\nImmaginiamo di lanciare una moneta due volte e di osservare una testa e una croce. Il nostro obiettivo è stimare \\(p_H\\), cioè la probabilità che la moneta cada su testa. Per iniziare, valutiamo quanto sono plausibili due diversi valori di \\(p_H\\) alla luce dei dati osservati, calcolando la funzione di verosimiglianza.\n\n\nSe \\(p_H = 0.5\\) (una moneta equa), allora:\n\\[\nL(0.5) = 0.5^1 \\cdot (1 - 0.5)^1 = 0.25 .\n\\]\n\n\nSe \\(p_H = 0.4\\), allora:\n\\[\nL(0.4) = 0.4^1 \\cdot 0.6^1 = 0.24 .\n\\]\n\n\nIn entrambi i casi, la funzione di verosimiglianza ci dice quanto sia plausibile quel valore di \\(p_H\\), dati i risultati che abbiamo osservato (una testa e una croce). Come possiamo notare, il valore \\(p_H = 0.5\\) è più compatibile con i dati osservati rispetto a \\(p_H = 0.4\\).\n\n42.3.5 Calcolo della verosimiglianza su una griglia di valori\nOra ripetiamo questo calcolo per molti valori diversi di \\(p_H\\), compresi tra 0 e 1. Questo ci permette di visualizzare la funzione di verosimiglianza e di vedere per quali valori di \\(p_H\\) essa è più alta.\n\n# Parametri osservati\nn &lt;- 2             # Numero totale di lanci\ny &lt;- 1             # Numero di teste osservate\n\n# Griglia di valori per p_H da 0 a 1\np_H &lt;- seq(0, 1, length.out = 100)\n\n# Calcolo della funzione di verosimiglianza\nlikelihood &lt;- p_H^y * (1 - p_H)^(n - y)\n\n\n42.3.6 Rappresentazione grafica\nIl grafico seguente mostra la funzione di verosimiglianza per i 100 valori di \\(p_H\\). Ogni punto della curva indica quanto è compatibile quel valore di \\(p_H\\) con i dati che abbiamo osservato.\n\nggplot(data.frame(p_H, likelihood), aes(x = p_H, y = likelihood)) +\n  geom_line(color = okabe_ito_palette[2], linewidth = 1.2) +\n  labs(\n    title = \"Funzione di Verosimiglianza per 2 Lanci\\n(1 Testa, 1 Croce)\",\n    x = expression(p[H]),\n    y = \"Verosimiglianza\"\n  )\n\n\n\n\n\n\n\n\n42.3.7 Cosa ci dice il grafico?\n\nLa funzione di verosimiglianza raggiunge il suo massimo per \\(p_H = 0.5\\), che corrisponde alla proporzione osservata (1 testa su 2 lanci).\nQuesto valore di \\(p_H\\) è quindi il più plausibile secondo i dati: rappresenta la stima di massima verosimiglianza.\nI valori estremi (vicini a 0 o a 1) hanno verosimiglianza molto bassa: non spiegano bene il fatto che abbiamo ottenuto una testa e una croce.\n\nEcco una versione migliorata e più didattica del tuo Esempio 2: Tre lanci, pensata per studenti che stanno imparando il concetto di verosimiglianza passo dopo passo. Mantiene l’approccio del primo esempio e rafforza la continuità logica, l’intuizione e l’interpretazione dei risultati, con un linguaggio semplice ma preciso.\n\n42.3.8 Esempio 2: Tre lanci\nProseguiamo con un secondo esperimento: lanciamo una moneta tre volte, e otteniamo una testa e due croci. Anche in questo caso, vogliamo stimare \\(p_H\\), la probabilità che la moneta cada su testa, e valutare quali valori di \\(p_H\\) sono più compatibili con i dati osservati.\nIniziamo calcolando la verosimiglianza per due valori specifici:\n\nSe \\(p_H = 0.5\\) (moneta equa): \\[\nL(0.5) = 0.5^1 \\cdot (1 - 0.5)^2 = 0.5 \\cdot 0.25 = 0.125\n\\]\nSe \\(p_H = 0.4\\): \\[\nL(0.4) = 0.4^1 \\cdot 0.6^2 = 0.4 \\cdot 0.36 = 0.144\n\\]\n\nCome vediamo, in questo caso \\(p_H = 0.4\\) ha una verosimiglianza maggiore rispetto a \\(p_H = 0.5\\): questo suggerisce che il valore 0.4 spiega meglio i dati (1 testa su 3 lanci) rispetto alla moneta equa.\n\n42.3.9 Calcolo su una griglia di valori\nCalcoliamo ora la verosimiglianza per 100 valori compresi tra 0 e 1 per visualizzare la funzione su tutto l’intervallo di probabilità.\n\n# Parametri osservati\nn &lt;- 3             # Numero totale di lanci\ny &lt;- 1             # Numero di teste osservate\n\n# Sequenza di valori possibili per p_H\np_H &lt;- seq(0, 1, length.out = 100)\n\n# Calcolo della funzione di verosimiglianza\nlikelihood &lt;- p_H^y * (1 - p_H)^(n - y)\n\n\n42.3.10 Rappresentazione grafica\nIl grafico seguente mostra la funzione di verosimiglianza: ci dice quanto ogni valore di \\(p_H\\) è compatibile con l’osservazione di 1 testa e 2 croci.\n\n# Mostra la curva della verosimiglianza\nggplot(data.frame(p_H, likelihood), aes(x = p_H, y = likelihood)) +\n  geom_line(color = okabe_ito_palette[2], linewidth = 1.2) +\n  labs(\n    title = \"Funzione di Verosimiglianza per 3 Lanci\\n(1 Testa, 2 Croci)\",\n    x = expression(p[H]),\n    y = \"Verosimiglianza\"\n  )\n\n\n\n\n\n\n\n\n42.3.11 Cosa osserviamo?\n\nIl massimo della funzione di verosimiglianza non è più in \\(p_H = 0.5\\), ma più vicino a 0.33, cioè alla proporzione osservata (1 testa su 3 lanci).\nQuesto riflette il fatto che il valore di \\(p_H\\) che meglio spiega i dati è quello che riproduce la frequenza osservata.\nLa curva è più stretta rispetto al caso con 2 lanci: abbiamo più informazioni, quindi possiamo stimare \\(p_H\\) con maggiore precisione.\nAnche qui, i valori estremi di \\(p_H\\) (vicino a 0 o 1) hanno verosimiglianze basse, perché non giustificano bene l’osservazione di una testa e due croci.\n\n42.3.12 Interpretazione dei Risultati\n\nLa funzione di verosimiglianza raggiunge il massimo per valori di \\(p_H\\) vicini alla proporzione di teste osservata.\nQuando il numero di lanci aumenta, la curva diventa più “stretta”: i dati ci permettono di stimare \\(p_H\\) in modo più preciso.\nValori estremi di \\(p_H\\) (vicini a 0 o 1) hanno verosimiglianze basse: non spiegano bene i dati osservati.\n\nIn sintesi, abbiamo visto come costruire la funzione di verosimiglianza a partire dai dati osservati, senza usare direttamente la distribuzione binomiale completa.\nLa tua sezione è già molto chiara, ma possiamo migliorarla ulteriormente per renderla ancora più didattica e accessibile a studenti principianti, mantenendo un linguaggio preciso e coerente con le sezioni precedenti.\nL’obiettivo è aiutare gli studenti a vedere come la distribuzione binomiale si collega alla verosimiglianza e alla stima del parametro.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#verosimiglianza-binomiale",
    "href": "chapters/probability/15_likelihood.html#verosimiglianza-binomiale",
    "title": "42  La verosimiglianza",
    "section": "\n42.4 Verosimiglianza binomiale",
    "text": "42.4 Verosimiglianza binomiale\nTorniamo al nostro esperimento con la moneta, ma questa volta lo rendiamo un po’ più realistico: lanciamo la moneta \\(n = 30\\) volte e otteniamo \\(y = 23\\) teste.\nPer modellare il numero totale di teste osservate, utilizziamo la distribuzione binomiale, che ci dice qual è la probabilità di ottenere esattamente \\(y\\) successi su \\(n\\) prove, quando la probabilità di successo in ogni singolo lancio è \\(\\theta\\):\n\\[\nP(Y = y \\mid \\theta) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n - y}.\n\\]\nIn questo contesto:\n\n\n\\(Y\\) è una variabile casuale che rappresenta il numero di teste ottenute,\n\n\\(y = 23\\) è il valore osservato,\n\n\\(\\theta\\) (o \\(p_H\\)) è la probabilità incognita di ottenere testa in un singolo lancio.\n\n\n42.4.1 Dalla distribuzione alla verosimiglianza\nUna volta osservati i dati (\\(y = 23\\)), possiamo considerarli fissati e analizzare quanto ciascun valore possibile del parametro \\(\\theta\\) (la probabilità di ottenere testa) sia compatibile con questi dati. Per farlo, possiamo riutilizzare direttamente la formula della distribuzione binomiale, trattandola come funzione di \\(\\theta\\) anziché come funzione di \\(y\\):\n\\[\nL(\\theta \\mid y = 23) = \\binom{30}{23} \\theta^{23} (1 - \\theta)^7.\n\\]\nQuesta è la funzione di verosimiglianza, che ci dice quanto ogni valore di \\(\\theta\\) sia plausibile alla luce dei dati osservati. A differenza degli esempi precedenti (in cui abbiamo ignorato le costanti moltiplicative), qui non abbiamo bisogno di semplificare la formula: la funzione dbinom() in R calcola automaticamente l’intera espressione, costante inclusa.\n\n42.4.2 Visualizzazione della funzione di verosimiglianza\nIl codice seguente costruisce il grafico della funzione di verosimiglianza, calcolando per ogni valore di \\(\\theta\\) la probabilità di osservare 23 successi su 30 prove:\n\n# Parametri osservati\nn &lt;- 30       # Numero totale di lanci\ny &lt;- 23       # Numero di teste osservate\n\n# Griglia di valori possibili per p_H\np_H &lt;- seq(0, 1, length.out = 1000)\n\n# Calcolo della funzione di verosimiglianza (usando la binomiale completa)\nlikelihood &lt;- dbinom(y, size = n, prob = p_H)\n\n# Creazione del data frame\ndata &lt;- data.frame(p_H, likelihood)\n\n# Grafico della funzione di verosimiglianza\nggplot(data, aes(x = p_H, y = likelihood)) +\n  geom_line(color = okabe_ito_palette[2], linewidth = 1.2) +\n  labs(\n    title = \"Funzione di Verosimiglianza per 30 Lanci di Moneta (23 Teste)\",\n    x = expression(p[H]),\n    y = \"Verosimiglianza\"\n  )\n\n\n\n\n\n\n\n\n42.4.3 Interpretazione del risultato\nOsservando il grafico, vediamo che:\n\nla funzione di verosimiglianza raggiunge il suo massimo in corrispondenza di \\(p_H \\approx 0.77\\);\nquesto significa che il valore di \\(\\theta\\) (cioè \\(p_H\\)) che rende più plausibile l’osservazione di 23 teste su 30 è circa 0.77;\nin altre parole, la stima di massima verosimiglianza (MLE) per la probabilità di ottenere testa è: \\[\n\\hat{p}_H = \\frac{23}{30} \\approx 0.767.\n\\]\n\n\nQuesto risultato è del tutto intuitivo: la stima migliore è la proporzione osservata di teste.\nLa verosimiglianza ci mostra quali altri valori di \\(\\theta\\) sono meno compatibili con i dati.\nIn sintesi, abbiamo visto come utilizzare direttamente la distribuzione binomiale per costruire la funzione di verosimiglianza. Questa funzione è uno strumento fondamentale per confrontare diversi valori possibili del parametro \\(\\theta\\) (cioè la probabilità di successo) alla luce dei dati osservati.\nNel caso della moneta lanciata 30 volte con 23 teste, abbiamo trattato il numero di successi osservati (\\(y = 23\\)) come un dato fisso, e abbiamo valutato per quali valori di \\(\\theta\\) questa osservazione sarebbe più plausibile.\nIn R, per calcolare la funzione di verosimiglianza non serve riscrivere manualmente la formula della binomiale. Possiamo usare la funzione dbinom(), che calcola le probabilità (o masse) della distribuzione binomiale per un dato numero di successi \\(y\\), un numero totale di prove \\(n\\), e una certa probabilità di successo \\(\\theta\\).\nAd esempio, nel codice:\nlikelihood &lt;- dbinom(y, size = n, prob = p_H)\n\n\ny è il numero di successi osservati (23),\n\nn è il numero totale di prove (30),\n\np_H è un vettore di valori di \\(\\theta\\) tra 0 e 1.\n\nIl risultato likelihood è un vettore che contiene, per ciascun valore di \\(\\theta\\), la verosimiglianza associata a quel valore: cioè, quanto quel valore di \\(\\theta\\) è compatibile con i dati che abbiamo osservato.\nRiassumendo:\n\n\ndbinom() fornisce la funzione di probabilità della binomiale,\nfissando \\(y\\) e variando \\(\\theta\\), usiamo dbinom() per costruire la funzione di verosimiglianza,\npossiamo poi tracciare un grafico di questa funzione per visualizzare quali valori di \\(\\theta\\) sono più plausibili.\n\nQuesta strategia mostra come la verosimiglianza possa essere costruita direttamente a partire da una distribuzione conosciuta (in questo caso, la binomiale) e implementata facilmente in R con strumenti standard.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#la-stima-di-massima-verosimiglianza",
    "href": "chapters/probability/15_likelihood.html#la-stima-di-massima-verosimiglianza",
    "title": "42  La verosimiglianza",
    "section": "\n42.5 La Stima di Massima Verosimiglianza",
    "text": "42.5 La Stima di Massima Verosimiglianza\nNel momento in cui osserviamo dei dati e vogliamo stimare un parametro incognito (ad esempio, la probabilità \\(\\theta\\) che una moneta dia “testa”), un metodo classico è la stima di massima verosimiglianza (Maximum Likelihood Estimation, o MLE).\nAnche se nella prospettiva bayesiana ci interessa la distribuzione completa dei valori plausibili del parametro (e non un singolo valore stimato), è utile conoscere il concetto di MLE, che rappresenta il valore di \\(\\theta\\) che rende i dati osservati più compatibili con il modello. Più avanti vedremo come la MLE corrisponde, nel caso di una prior uniforme, al valore massimo della distribuzione a posteriori.\n\n42.5.1 L’idea di Fondo\nLa logica è semplice. Una volta osservati i dati, ci chiediamo: quali valori del parametro sono più compatibili con ciò che abbiamo visto? Il valore che risulta più plausibile è la stima di massima verosimiglianza.\nImmagina di “provare” tanti valori di \\(\\theta\\), e per ciascuno chiederti: “se fosse questo il vero valore di \\(\\theta\\), quanto sarebbe plausibile osservare questi dati?” Il valore che meglio spiega i dati è quello scelto come stima.\n\n42.5.2 Un Esempio Concreto\nHai lanciato una moneta 30 volte e hai osservato 23 teste. La tua domanda è: quanto è sbilanciata la moneta?\nUtilizziamo la funzione di verosimiglianza, che ci dice quanto ogni valore possibile di \\(\\theta\\) è compatibile con i dati osservati. Più alta è la verosimiglianza, più plausibile è il valore di \\(\\theta\\).\n\n42.5.3 Una metafora visiva\nImmagina di osservare una curva che rappresenta la verosimiglianza al variare del parametro \\(\\theta\\).\nLa curva si alza, raggiunge un punto massimo, e poi scende: proprio come una collina.\nQuel punto più alto della curva rappresenta il valore di \\(\\theta\\) che è più compatibile con i dati osservati: è il valore per cui i dati risultano più verosimili, secondo il modello.\nQuel valore è chiamato stima di massima verosimiglianza (maximum likelihood estimate): è il punto in cima alla collina della verosimiglianza.\n\n42.5.4 Come si Trova il Massimo?\nDal punto di vista matematico, il massimo di una funzione si trova dove la sua pendenza (la derivata) è zero: cioè, dove smette di salire e inizia a scendere.\nPer la verosimiglianza binomiale (trasformata in log-verosimiglianza), questo calcolo si può fare in modo esatto. Se hai osservato \\(y\\) successi su \\(n\\) prove, la log-verosimiglianza è:\n\\[\n\\ell(\\theta) = y \\log \\theta + (n - y) \\log(1 - \\theta),\n\\]\ne la derivata si annulla quando:\n\\[\n\\hat{\\theta} = \\frac{y}{n}.\n\\]\nIn altre parole, la MLE è semplicemente la proporzione osservata di successi.\n\n42.5.5 Un punto Importante per l’Approccio Bayesiano\nNel contesto bayesiano, non ci limitiamo a cercare il valore più plausibile del parametro, ma costruiamo una distribuzione completa che rappresenta l’incertezza su \\(\\theta\\). Tuttavia, il punto in cui la distribuzione a posteriori raggiunge il suo massimo viene chiamato MAP (Maximum A Posteriori), e se assumiamo una distribuzione a priori uniforme, MLE e MAP coincidono. Quindi, la MLE può essere vista come un caso speciale del ragionamento bayesiano, utile per introdurre il concetto di compatibilità tra parametri e dati.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#calcolare-la-mle-in-r",
    "href": "chapters/probability/15_likelihood.html#calcolare-la-mle-in-r",
    "title": "42  La verosimiglianza",
    "section": "\n42.6 Calcolare la MLE in R",
    "text": "42.6 Calcolare la MLE in R\n\n42.6.1 Metodo 1: Valutazione su Griglia\n\n# Parametri\nn &lt;- 30\ny &lt;- 23\ntheta &lt;- seq(0, 1, length.out = 10000)\n\n# Calcolo della verosimiglianza binomiale\nlikelihood &lt;- dbinom(y, size = n, prob = theta)\n\n# Trova il massimo\nmax_index &lt;- which.max(likelihood)\noptimal_theta &lt;- theta[max_index]\n\n# Risultato\noptimal_theta\n#&gt; [1] 0.7667\n\nSpiegazione:\n\n\ndbinom() calcola la verosimiglianza per ogni valore di \\(\\theta\\);\n\nwhich.max() individua il massimo;\n\ntheta[max_index] restituisce la stima MLE.\n\n42.6.2 Metodo 2: Ottimizzazione Numerica\nIn alternativa, possiamo trovare la MLE senza usare griglie, con un approccio più efficiente.\n\n# Funzione log-verosimiglianza negativa\nneg_log_likelihood &lt;- function(theta) {\n  - (y * log(theta) + (n - y) * log(1 - theta))\n}\n\n# Ottimizzazione numerica\nresult &lt;- optim(\n  par = 0.5,\n  fn = neg_log_likelihood,\n  method = \"Brent\",\n  lower = 1e-6,\n  upper = 1 - 1e-6\n)\n\noptimal_theta_numerical &lt;- result$par\noptimal_theta_numerical\n#&gt; [1] 0.7667\n\nNota: abbiamo calcolato la log-verosimiglianza negativa, perché optim() cerca minimi per default.\n\n42.6.3 Confronto tra le Soluzioni\n\nc(\n  \"Griglia\" = optimal_theta, \n  \"Ottimizzazione\" = optimal_theta_numerical, \n  \"Analitica\" = y / n\n)\n#&gt;        Griglia Ottimizzazione      Analitica \n#&gt;         0.7667         0.7667         0.7667\n\nTutti i metodi restituiscono lo stesso risultato:\\[\n\\hat{\\theta} = \\frac{23}{30} \\approx 0.767.\n\\]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#verosimiglianza-congiunta",
    "href": "chapters/probability/15_likelihood.html#verosimiglianza-congiunta",
    "title": "42  La verosimiglianza",
    "section": "\n42.7 Verosimiglianza Congiunta",
    "text": "42.7 Verosimiglianza Congiunta\nAbbiamo visto che, nel caso di una sequenza di \\(n\\) lanci di una moneta, la funzione di verosimiglianza si basa sulla distribuzione binomiale. In questo caso, trattiamo un esperimento Bernoulliano ripetuto \\(n\\) volte, e la nostra osservazione è il numero totale di successi (teste). Il numero complessivo di successi segue una distribuzione binomiale, e la funzione di verosimiglianza assume la forma:\n\\[\n\\mathcal{L}(\\theta) = P(Y = y \\mid \\theta) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n - y}.\n\\]\nQui la verosimiglianza è espressa direttamente in termini del numero totale di successi e insuccessi, senza dover scrivere il contributo di ogni singolo lancio.\nTuttavia, possiamo affrontare la questione da una prospettiva diversa: invece di considerare il numero totale di successi, possiamo pensare alla verosimiglianza come il prodotto delle probabilità di ogni singolo lancio. Questo ci porta a una generalizzazione importante: la verosimiglianza congiunta di più osservazioni indipendenti.\n\n42.7.1 Dal Caso Binomiale alla Verosimiglianza Congiunta\nNel caso dei lanci della moneta, le singole osservazioni sono prove Bernoulliane indipendenti, ovvero ogni singolo lancio è un’osservazione indipendente che segue una distribuzione Bernoulli con parametro \\(\\theta\\):\n\\[\nP(Y_i = 1 \\mid \\theta) = \\theta, \\quad P(Y_i = 0 \\mid \\theta) = 1 - \\theta.\n\\]\nSe trattiamo ogni prova individualmente, la funzione di verosimiglianza per una singola osservazione è:\n\\[\n\\mathcal{L}(\\theta \\mid y_i) = \\theta^{y_i} (1 - \\theta)^{1 - y_i}.\n\\]\nOra, per un campione di \\(n\\) osservazioni indipendenti, la verosimiglianza congiunta è il prodotto delle verosimiglianze delle singole osservazioni:\n\\[\n\\mathcal{L}(\\theta \\mid y_1, y_2, \\dots, y_n) = \\prod_{i=1}^{n} \\theta^{y_i} (1 - \\theta)^{1 - y_i}.\n\\]\nRiconosciamo che questa espressione è identica alla funzione di verosimiglianza della distribuzione binomiale, perché il numero totale di successi è:\n\\[\ny = \\sum_{i=1}^{n} y_i.\n\\]\nQuindi, riscrivendo la verosimiglianza congiunta, otteniamo:\n\\[\n\\mathcal{L}(\\theta) = \\theta^{\\sum y_i} (1 - \\theta)^{n - \\sum y_i} = \\theta^y (1 - \\theta)^{n - y}.\n\\]\nQuesta è proprio la verosimiglianza della distribuzione binomiale! Questo mostra che il caso binomiale può essere visto come una forma compatta di verosimiglianza congiunta per prove Bernoulliane indipendenti.\n\n42.7.2 Perché è Importante la Verosimiglianza Congiunta?\nL’idea della verosimiglianza congiunta è fondamentale perché ci permette di estendere i concetti di verosimiglianza dal caso di una singola osservazione al caso di molte osservazioni indipendenti. Questo è utile in molti contesti statistici:\n\n\nstimare parametri basandosi su un intero campione invece che su una singola osservazione;\n\ndefinire modelli statistici più complessi, in cui le osservazioni sono indipendenti ma possono avere diverse distribuzioni.\n\nIn sintesi, l’esempio binomiale mostra che la verosimiglianza congiunta di prove Bernoulliane indipendenti si riconduce alla verosimiglianza binomiale. Tuttavia, la vera potenza della verosimiglianza congiunta si manifesta in distribuzioni continue come la normale, dove la produttoria delle densità di probabilità per singole osservazioni è chiaramente distinta dalla funzione di verosimiglianza per il campione intero.\nLa chiave per comprendere il concetto è rendersi conto che la verosimiglianza di un’intera sequenza di prove indipendenti è il prodotto delle singole verosimiglianze.\n\n42.7.3 Esempio: Osservazioni Raggruppate\nPer illustrare il concetto di verosimiglianza congiunta nel caso della distribuzione binomiale, consideriamo quattro gruppi distinti di osservazioni binomiali indipendenti:\n\n\ngruppo 1: 23 successi su 30 prove,\n\ngruppo 2: 20 successi su 28 prove,\n\ngruppo 3: 29 successi su 40 prove,\n\ngruppo 4: 29 successi su 36 prove.\n\nPoiché ogni gruppo segue una distribuzione binomiale indipendente con lo stesso parametro \\(\\theta\\), la log-verosimiglianza congiunta si ottiene sommando le log-verosimiglianze di ciascun gruppo:\n\\[\n\\log \\mathcal{L}(\\theta) = \\sum_{i=1}^{4} \\left[ y_i \\log(\\theta) + (n_i - y_i) \\log(1 - \\theta) \\right],\n\\]\ndove:\n\n\n\\(n_i\\) è il numero totale di prove nel gruppo \\(i\\),\n\n\\(y_i\\) è il numero di successi nel gruppo \\(i\\).\n\nSostituendo i valori specifici:\n\\[\n\\begin{aligned}\n\\log \\mathcal{L}(\\theta) &= [23\\log(\\theta) + (30-23)\\log(1 - \\theta)] \\\\\n&\\quad + [20\\log(\\theta) + (28-20)\\log(1 - \\theta)] \\\\\n&\\quad + [29\\log(\\theta) + (40-29)\\log(1 - \\theta)] \\\\\n&\\quad + [29\\log(\\theta) + (36-29)\\log(1 - \\theta)].\n\\end{aligned}\n\\]\nQuesta formula ci permette di calcolare quanto è plausibile il valore del parametro \\(\\theta\\), tenendo conto simultaneamente di tutte le osservazioni nei quattro gruppi.\n\n42.7.4 Implementazione in R\nSupponiamo di avere i dati di quattro gruppi indipendenti, e vogliamo trovare la stima del parametro \\(\\theta\\) che massimizza la log-verosimiglianza congiunta. Procederemo passo dopo passo.\n1. Definire una funzione per la log-verosimiglianza congiunta.\nQuesta funzione riceve un valore di \\(\\theta\\) e una lista di gruppi. Ogni gruppo contiene il numero totale di prove e il numero di successi. La funzione calcola la somma delle log-verosimiglianze per ciascun gruppo.\n\n# Funzione che calcola la log-verosimiglianza congiunta\nlog_verosimiglianza_congiunta &lt;- function(theta, dati) {\n  # Limitiamo theta per evitare log(0)\n  if (theta &lt;= 0) theta &lt;- 1e-10\n  if (theta &gt;= 1) theta &lt;- 1 - 1e-10\n\n  # Inizializziamo il totale\n  somma_loglik &lt;- 0\n\n  # Per ogni gruppo, calcoliamo il contributo alla log-verosimiglianza\n  for (i in 1:length(dati)) {\n    gruppo &lt;- dati[[i]]   # Estrae il gruppo i-esimo\n    n &lt;- gruppo[1]        # Numero totale di prove\n    y &lt;- gruppo[2]        # Numero di successi\n\n    # Aggiunge il contributo del gruppo alla somma totale\n    somma_loglik &lt;- somma_loglik + y * log(theta) + (n - y) * log(1 - theta)\n  }\n\n  # Restituiamo il valore negativo (perché optim() cerca minimi)\n  return(-somma_loglik)\n}\n\n2. Inserire i dati.\nQui definiamo i dati per ciascun gruppo come coppie (numero di prove, numero di successi):\n\n# Dati osservati per ciascun gruppo\ndati_gruppi &lt;- list(\n  c(30, 23),\n  c(28, 20),\n  c(40, 29),\n  c(36, 29)\n)\n\n3. Trovare la stima di θ che massimizza la verosimiglianza.\nUsiamo optim() per trovare numericamente il valore di \\(\\theta\\) che minimizza il valore negativo della log-verosimiglianza, ovvero che massimizza la log-verosimiglianza.\n\n# Ricerca del valore ottimale di theta\nresult &lt;- optim(\n  par = 0.5,                            # Valore iniziale\n  fn = log_verosimiglianza_congiunta,  # Funzione da minimizzare\n  dati = dati_gruppi,                  # Passiamo i dati\n  method = \"L-BFGS-B\",                 # Metodo con vincoli\n  lower = 0, upper = 1                 # Vincoli: theta tra 0 e 1\n)\n\n# Stima ottimale trovata\nresult$par\n#&gt; [1] 0.7537\n\n4. Visualizzare la log-verosimiglianza.\nCostruiamo ora un grafico che mostri come varia la log-verosimiglianza al variare di \\(\\theta\\).\n\n# Valori di theta da esplorare\ntheta_values &lt;- seq(0.01, 0.99, length.out = 100)\n\n# Vettore per salvare i valori di log-verosimiglianza\nlog_likelihood_values &lt;- numeric(length(theta_values))\n\n# Calcoliamo il valore della funzione per ogni valore di theta\nfor (i in 1:length(theta_values)) {\n  t &lt;- theta_values[i]\n  log_likelihood_values[i] &lt;- log_verosimiglianza_congiunta(t, dati_gruppi)\n}\n\nOra costruiamo il grafico:\n\nggplot(\n  data.frame(theta = theta_values, log_likelihood = log_likelihood_values),\n  aes(x = theta, y = log_likelihood)\n) +\n  geom_line(color = \"blue\", linewidth = 1.2) +\n  labs(\n    title = \"Funzione di Log-Verosimiglianza Congiunta\",\n    x = expression(theta),\n    y = \"Log-verosimiglianza negativa\"\n  )\n\n\n\n\n\n\n\nCon questo esempio abbiamo visto che:\n\nla log-verosimiglianza congiunta si ottiene sommando le log-verosimiglianze dei singoli gruppi;\nè possibile trovare la stima ottimale di \\(\\theta\\) numericamente, senza formule complicate;\nil grafico della log-verosimiglianza ci aiuta a visualizzare il punto in cui il modello è più compatibile con i dati.\n\nQuesto approccio — basato sull’uso della verosimiglianza e della sua somma tra gruppi indipendenti — sarà anche la base per il passaggio all’inferenza bayesiana, dove aggiungeremo una distribuzione a priori per ottenere una distribuzione a posteriori di \\(\\theta\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#perché-è-importante-la-verosimiglianza-congiunta",
    "href": "chapters/probability/15_likelihood.html#perché-è-importante-la-verosimiglianza-congiunta",
    "title": "42  La verosimiglianza",
    "section": "\n42.8 Perché è Importante la Verosimiglianza Congiunta?",
    "text": "42.8 Perché è Importante la Verosimiglianza Congiunta?\nL’idea della verosimiglianza congiunta è fondamentale perché ci permette di estendere i concetti di verosimiglianza dal caso di una singola osservazione al caso di molte osservazioni indipendenti. Questo è utile in molti contesti statistici:\n\n\nstimare parametri basandosi su un intero campione invece che su una singola osservazione;\n\ndefinire modelli statistici più complessi, in cui le osservazioni sono indipendenti ma possono avere diverse distribuzioni.\n\nIn sintesi, l’esempio binomiale mostra che la verosimiglianza congiunta di prove Bernoulliane indipendenti si riconduce alla verosimiglianza binomiale. Tuttavia, la vera potenza della verosimiglianza congiunta si manifesta in distribuzioni continue come la normale, dove la produttoria delle densità di probabilità per singole osservazioni è chiaramente distinta dalla funzione di verosimiglianza per il campione intero.\nLa chiave per comprendere il concetto è rendersi conto che la verosimiglianza di un’intera sequenza di prove indipendenti è il prodotto delle singole verosimiglianze.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#esempio-osservazioni-raggruppate",
    "href": "chapters/probability/15_likelihood.html#esempio-osservazioni-raggruppate",
    "title": "42  La verosimiglianza",
    "section": "\n42.9 Esempio: Osservazioni Raggruppate",
    "text": "42.9 Esempio: Osservazioni Raggruppate\nPer illustrare il concetto di verosimiglianza congiunta nel caso della distribuzione binomiale, consideriamo quattro gruppi distinti di osservazioni binomiali indipendenti:\n\n\ngruppo 1: 23 successi su 30 prove,\n\ngruppo 2: 20 successi su 28 prove,\n\ngruppo 3: 29 successi su 40 prove,\n\ngruppo 4: 29 successi su 36 prove.\n\nPoiché ogni gruppo segue una distribuzione binomiale indipendente con lo stesso parametro \\(\\theta\\), la log-verosimiglianza congiunta si ottiene sommando le log-verosimiglianze di ciascun gruppo:\n\\[\n\\log \\mathcal{L}(\\theta) = \\sum_{i=1}^{4} \\left[ y_i \\log(\\theta) + (n_i - y_i) \\log(1 - \\theta) \\right],\n\\]\ndove:\n\n\n\\(n_i\\) è il numero totale di prove nel gruppo \\(i\\),\n\n\\(y_i\\) è il numero di successi nel gruppo \\(i\\).\n\nSostituendo i valori specifici:\n\\[\n\\begin{aligned}\n\\log \\mathcal{L}(\\theta) &= [23\\log(\\theta) + (30-23)\\log(1 - \\theta)] \\\\\n&\\quad + [20\\log(\\theta) + (28-20)\\log(1 - \\theta)] \\\\\n&\\quad + [29\\log(\\theta) + (40-29)\\log(1 - \\theta)] \\\\\n&\\quad + [29\\log(\\theta) + (36-29)\\log(1 - \\theta)].\n\\end{aligned}\n\\]\nQuesta formula ci permette di calcolare quanto è plausibile il valore del parametro \\(\\theta\\), tenendo conto simultaneamente di tutte le osservazioni nei quattro gruppi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#implementazione-in-r",
    "href": "chapters/probability/15_likelihood.html#implementazione-in-r",
    "title": "42  La verosimiglianza",
    "section": "\n42.10 Implementazione in R",
    "text": "42.10 Implementazione in R\nSupponiamo di avere i dati di quattro gruppi indipendenti, e vogliamo trovare la stima del parametro \\(\\theta\\) che massimizza la log-verosimiglianza congiunta. Procederemo passo dopo passo.\n1. Definire una funzione per la log-verosimiglianza congiunta.\nQuesta funzione riceve un valore di \\(\\theta\\) e una lista di gruppi. Ogni gruppo contiene il numero totale di prove e il numero di successi. La funzione calcola la somma delle log-verosimiglianze per ciascun gruppo.\n\n# Funzione che calcola la log-verosimiglianza congiunta\nlog_verosimiglianza_congiunta &lt;- function(theta, dati) {\n  # Limitiamo theta per evitare log(0)\n  if (theta &lt;= 0) theta &lt;- 1e-10\n  if (theta &gt;= 1) theta &lt;- 1 - 1e-10\n\n  # Inizializziamo il totale\n  somma_loglik &lt;- 0\n\n  # Per ogni gruppo, calcoliamo il contributo alla log-verosimiglianza\n  for (i in 1:length(dati)) {\n    gruppo &lt;- dati[[i]]   # Estrae il gruppo i-esimo\n    n &lt;- gruppo[1]        # Numero totale di prove\n    y &lt;- gruppo[2]        # Numero di successi\n\n    # Aggiunge il contributo del gruppo alla somma totale\n    somma_loglik &lt;- somma_loglik + y * log(theta) + (n - y) * log(1 - theta)\n  }\n\n  # Restituiamo il valore negativo (perché optim() cerca minimi)\n  return(-somma_loglik)\n}\n\n2. Inserire i dati.\nQui definiamo i dati per ciascun gruppo come coppie (numero di prove, numero di successi):\n\n# Dati osservati per ciascun gruppo\ndati_gruppi &lt;- list(\n  c(30, 23),\n  c(28, 20),\n  c(40, 29),\n  c(36, 29)\n)\n\n3. Trovare la stima di θ che massimizza la verosimiglianza.\nUsiamo optim() per trovare numericamente il valore di \\(\\theta\\) che minimizza il valore negativo della log-verosimiglianza, ovvero che massimizza la log-verosimiglianza.\n\n# Ricerca del valore ottimale di theta\nresult &lt;- optim(\n  par = 0.5,                            # Valore iniziale\n  fn = log_verosimiglianza_congiunta,  # Funzione da minimizzare\n  dati = dati_gruppi,                  # Passiamo i dati\n  method = \"L-BFGS-B\",                 # Metodo con vincoli\n  lower = 0, upper = 1                 # Vincoli: theta tra 0 e 1\n)\n\n# Stima ottimale trovata\nresult$par\n#&gt; [1] 0.7537\n\n4. Visualizzare la log-verosimiglianza.\nCostruiamo ora un grafico che mostri come varia la log-verosimiglianza al variare di \\(\\theta\\).\n\n# Valori di theta da esplorare\ntheta_values &lt;- seq(0.01, 0.99, length.out = 100)\n\n# Vettore per salvare i valori di log-verosimiglianza\nlog_likelihood_values &lt;- numeric(length(theta_values))\n\n# Calcoliamo il valore della funzione per ogni valore di theta\nfor (i in 1:length(theta_values)) {\n  t &lt;- theta_values[i]\n  log_likelihood_values[i] &lt;- log_verosimiglianza_congiunta(t, dati_gruppi)\n}\n\nOra costruiamo il grafico:\n\nggplot(\n  data.frame(theta = theta_values, log_likelihood = log_likelihood_values),\n  aes(x = theta, y = log_likelihood)\n) +\n  geom_line(color = \"blue\", linewidth = 1.2) +\n  labs(\n    title = \"Funzione di Log-Verosimiglianza Congiunta\",\n    x = expression(theta),\n    y = \"Log-verosimiglianza negativa\"\n  )\n\n\n\n\n\n\n\nCon questo esempio abbiamo visto che:\n\nla log-verosimiglianza congiunta si ottiene sommando le log-verosimiglianze dei singoli gruppi;\nè possibile trovare la stima ottimale di \\(\\theta\\) numericamente, senza formule complicate;\nil grafico della log-verosimiglianza ci aiuta a visualizzare il punto in cui il modello è più compatibile con i dati.\n\nQuesto approccio — basato sull’uso della verosimiglianza e della sua somma tra gruppi indipendenti — sarà anche la base per il passaggio all’inferenza bayesiana, dove aggiungeremo una distribuzione a priori per ottenere una distribuzione a posteriori di \\(\\theta\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#la-verosimiglianza-marginale",
    "href": "chapters/probability/15_likelihood.html#la-verosimiglianza-marginale",
    "title": "42  La verosimiglianza",
    "section": "\n42.8 La Verosimiglianza Marginale",
    "text": "42.8 La Verosimiglianza Marginale\nLa verosimiglianza marginale è un concetto fondamentale nell’inferenza bayesiana, utilizzato per valutare quanto un modello sia compatibile con i dati osservati, tenendo conto dell’incertezza sui parametri.\nA differenza della verosimiglianza standard, che misura la plausibilità dei dati per un valore fisso del parametro, la verosimiglianza marginale considera tutti i possibili valori del parametro, pesandoli in base alla loro probabilità a priori. Questo approccio permette di integrare l’incertezza nella valutazione del modello.\n\n42.8.1 Caso con Parametri Discreti\nPer comprendere meglio il concetto, consideriamo un esperimento in cui eseguiamo 10 tentativi e otteniamo 7 successi. Supponiamo che la probabilità di successo \\(\\theta\\) possa assumere solo tre valori discreti:\n\\[\n\\theta \\in \\{0.1, 0.5, 0.9\\}.\n\\]\nPer calcolare la verosimiglianza marginale, dobbiamo:\n\n\nAssegnare una probabilità a priori a ciascun valore di \\(\\theta\\), ad esempio:\n\nDistribuzione uniforme: \\[\np(\\theta = 0.1) = p(\\theta = 0.5) = p(\\theta = 0.9) = \\frac{1}{3}.\n\\]\n\nDistribuzione non uniforme (ad esempio, dando più peso a \\(\\theta = 0.5\\)): \\[\np(\\theta = 0.1) = \\frac{1}{4}, \\quad p(\\theta = 0.5) = \\frac{1}{2}, \\quad p(\\theta = 0.9) = \\frac{1}{4}.\n\\]\n\n\n\n\nCalcolare la probabilità di osservare 7 successi su 10 prove per ogni valore di \\(\\theta\\):\n\\[\np(k=7 \\mid \\theta) = \\binom{10}{7} \\theta^7 (1 - \\theta)^3.\n\\]\n\n\nMoltiplicare ciascuna di queste probabilità per la corrispondente probabilità a priori e sommare i risultati:\n\\[\np(k=7 \\mid n=10) = \\sum_{i} p(k=7 \\mid \\theta_i) p(\\theta_i).\n\\]\n\n\nSostituendo i valori per la distribuzione uniforme:\n\\[\np(k=7 \\mid n=10) = \\binom{10}{7} 0.1^7 (0.9)^3 \\cdot \\frac{1}{3} +\n\\binom{10}{7} 0.5^7 (0.5)^3 \\cdot \\frac{1}{3} +\n\\binom{10}{7} 0.9^7 (0.1)^3 \\cdot \\frac{1}{3}.\n\\]\nQuesta somma rappresenta la verosimiglianza marginale, ossia la probabilità di ottenere 7 successi su 10, considerando tutte le possibili incertezze su \\(\\theta\\).\n\n42.8.2 Caso con Parametri Continui\nNella maggior parte delle situazioni, il parametro \\(\\theta\\) non assume solo pochi valori discreti, ma può variare continuamente in un intervallo (ad esempio, tra 0 e 1). In questo caso, invece di sommare, dobbiamo integrare:\n\\[\np(k=7 \\mid n=10) = \\int_{0}^{1} \\binom{10}{7} \\theta^7 (1 - \\theta)^3 p(\\theta) \\, d\\theta.\n\\]\nQui:\n\n\n\\(p(\\theta)\\) è la distribuzione a priori di \\(\\theta\\).\nL’integrale rappresenta una media ponderata della probabilità di ottenere i dati, considerando tutti i valori di \\(\\theta\\).\n\nAd esempio, se \\(\\theta \\sim \\text{Beta}(2,2)\\), la verosimiglianza marginale diventa:\n\\[\np(k=7 \\mid n=10) = \\int_{0}^{1} \\binom{10}{7} \\theta^7 (1 - \\theta)^3 \\frac{\\theta (1-\\theta)}{B(2,2)} \\, d\\theta.\n\\]\nQuesto tipo di calcolo viene spesso risolto numericamente.\n\n42.8.3 Calcolo Numerico della Verosimiglianza Marginale in R\nSe vogliamo calcolare la verosimiglianza marginale numericamente, possiamo usare l’integrazione numerica in R.\nCaso con Parametri Discreti.\n\n# Definiamo i valori possibili di theta e le probabilità a priori\ntheta_vals &lt;- c(0.1, 0.5, 0.9)\nprior_probs &lt;- c(1/3, 1/3, 1/3)  # Distribuzione uniforme\n\n# Calcoliamo la verosimiglianza per ciascun valore di theta\nlikelihoods &lt;- dbinom(7, size = 10, prob = theta_vals)\n\n# Calcoliamo la verosimiglianza marginale sommando i contributi ponderati\nmarginal_likelihood &lt;- sum(likelihoods * prior_probs)\nprint(marginal_likelihood)\n#&gt; [1] 0.0582\n\nCaso con Parametri Continui.\n\n# Definiamo la funzione di verosimiglianza pesata dalla prior\nintegrand &lt;- function(theta) {\n  dbinom(7, size = 10, prob = theta) * dbeta(theta, shape1 = 2, shape2 = 2)\n}\n\n# Eseguiamo l'integrazione numerica\nmarginal_likelihood &lt;- integrate(integrand, lower = 0, upper = 1)$value\nprint(marginal_likelihood)\n#&gt; [1] 0.1119\n\n\n42.8.4 Interpretazione della Verosimiglianza Marginale\nLa verosimiglianza marginale rappresenta la probabilità complessiva dei dati, tenendo conto di tutte le possibili incertezze sul parametro \\(\\theta\\).\n\nSe la verosimiglianza marginale è alta, significa che il modello nel suo insieme è compatibile con i dati osservati.\nSe la verosimiglianza marginale è bassa, significa che, indipendentemente dal valore di \\(\\theta\\), il modello non spiega bene i dati.\n\nA differenza della verosimiglianza classica, che valuta quanto siano probabili i dati per un singolo valore di \\(\\theta\\), la verosimiglianza marginale considera tutte le possibili ipotesi sul parametro.\n\n42.8.5 Ruolo nella Statistica Bayesiana\nLa verosimiglianza marginale svolge un ruolo cruciale nell’inferenza bayesiana perché appare nella formula di Bayes:\n\\[\np(\\theta \\mid D) = \\frac{p(D \\mid \\theta) p(\\theta)}{p(D)},\n\\]\ndove \\(p(D)\\) è la verosimiglianza marginale. Questa quantità:\n\nserve da fattore di normalizzazione per la distribuzione a posteriori \\(p(\\theta \\mid D)\\);\n\npermette di confrontare modelli diversi, attraverso il fattore di Bayes:\n\\[\nBF = \\frac{p(D \\mid M_1)}{p(D \\mid M_2)},\n\\]\ndove \\(M_1\\) e \\(M_2\\) sono due modelli diversi.\n\n\nIn conclusione, la verosimiglianza marginale è un concetto chiave nell’inferenza bayesiana, che ci permette di valutare quanto un modello sia coerente con i dati, tenendo conto di tutte le possibili incertezze sui parametri:\n\nper parametri discreti, si calcola come una somma ponderata;\nper parametri continui, si calcola con un integrale;\nè essenziale per il calcolo della distribuzione a posteriori e per il confronto tra modelli.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#verosimiglianza-gaussiana",
    "href": "chapters/probability/15_likelihood.html#verosimiglianza-gaussiana",
    "title": "42  La verosimiglianza",
    "section": "\n42.9 Verosimiglianza Gaussiana",
    "text": "42.9 Verosimiglianza Gaussiana\nLa distribuzione gaussiana (o distribuzione normale) è una delle distribuzioni più utilizzate in statistica perché descrive molti fenomeni naturali e psicologici. In questo capitolo esploreremo come si calcola la verosimiglianza, ovvero la plausibilità dei parametri, nel caso della distribuzione normale.\n\n42.9.1 Caso di una Singola Osservazione\nImmaginiamo di misurare il Quoziente Intellettivo (QI) di una persona e ottenere un valore specifico, ad esempio 114. Assumiamo che il QI segua una distribuzione normale con media \\(\\mu\\) sconosciuta e deviazione standard \\(\\sigma\\) nota (ad esempio \\(\\sigma = 15\\)).\nLa funzione di densità di probabilità per una distribuzione normale è:\n\\[\nf(y \\mid \\mu, \\sigma) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(-\\frac{(y-\\mu)^2}{2\\sigma^2}\\right) ,\n\\]\ndove:\n\n\n\\(y\\) è il valore osservato,\n\n\\(\\mu\\) è la media (il parametro che vogliamo stimare),\n\n\\(\\sigma\\) è la deviazione standard (conosciuta).\n\nLa verosimiglianza misura quanto diversi valori di \\(\\mu\\) sono plausibili, dato il valore osservato (114).\nEsempio pratico in R:\n\n# Dati iniziali\ny_obs &lt;- 114\nsigma &lt;- 15\nmu_values &lt;- seq(70, 160, length.out = 1000)\n\n# Calcolo della verosimiglianza\nlikelihood &lt;- dnorm(y_obs, mean = mu_values, sd = sigma)\n\n# Grafico della verosimiglianza\nggplot(data.frame(mu = mu_values, likelihood = likelihood), aes(x = mu, y = likelihood)) +\n  geom_line(color = okabe_ito_palette[2], linewidth = 1.2) +\n  labs(\n    title = \"Verosimiglianza per un singolo valore di QI (114)\",\n    x = \"Media (μ)\",\n    y = \"Verosimiglianza\"\n  )\n\n\n\n\n\n\n\nQual è il valore migliore per \\(\\mu\\)?\nIl valore migliore di \\(\\mu\\) sarà quello che rende massima la verosimiglianza. In questo semplice caso, è esattamente il valore osservato (114):\n\nmu_ottimale &lt;- mu_values[which.max(likelihood)]\ncat(\"Il valore ottimale di μ è:\", mu_ottimale)\n#&gt; Il valore ottimale di μ è: 114\n\n\n42.9.2 Log-Verosimiglianza\nSpesso, per semplicità di calcolo, si usa la log-verosimiglianza, che trasforma i prodotti in somme, rendendo i calcoli più semplici e stabili:\n\\[\n\\log L(\\mu \\mid y, \\sigma) = -\\frac{1}{2}\\log(2\\pi) - \\log(\\sigma) - \\frac{(y-\\mu)^2}{2\\sigma^2}.\n\\]\nCalcolo pratico con R:\n\n# Funzione di log-verosimiglianza negativa usando dnorm()\nnegative_log_likelihood &lt;- function(mu, y, sigma) {\n  # Ritorniamo il valore negativo della log-verosimiglianza\n  -dnorm(y, mean = mu, sd = sigma, log = TRUE)\n}\n\nresult &lt;- optim(\n  par = 100, # Valore iniziale\n  fn = negative_log_likelihood,\n  y = y_obs,\n  sigma = sigma,\n  method = \"L-BFGS-B\",\n  lower = 70,\n  upper = 160\n)\n\nmu_max_loglik &lt;- result$par\ncat(\"Il valore ottimale di μ dalla log-verosimiglianza è:\", mu_max_loglik)\n#&gt; Il valore ottimale di μ dalla log-verosimiglianza è: 114\n\nIn questo caso, otteniamo nuovamente \\(\\mu = 114\\).\n\n42.9.3 Campione di Osservazioni Indipendenti\nSupponiamo di aver raccolto i punteggi alla scala BDI-II per 30 persone. Ciascun punteggio è un’osservazione indipendente da una distribuzione normale con media incognita \\(\\mu\\) e deviazione standard nota \\(\\sigma = 6.5\\).\n\n# Dati osservati (punteggi BDI-II)\ny &lt;- c(\n  26, 35, 30, 25, 44, 30, 33, 43, 22, 43, 24, 19, 39, 31, 25, \n  28, 35, 30, 26, 31, 41, 36, 26, 35, 33, 28, 27, 34, 27, 22\n)\n\nsigma &lt;- 6.5\n\n\n42.9.4 Calcolo della Log-Verosimiglianza\nDefiniamo una funzione che calcola la log-verosimiglianza totale:\n\nlog_likelihood &lt;- function(mu, y, sigma) {\n  sum(dnorm(y, mean = mu, sd = sigma, log = TRUE))\n}\n\nEsploriamo ora un intervallo di valori plausibili per \\(\\mu\\) e calcoliamo la log-verosimiglianza per ciascun valore:\n\n# Intervallo di valori possibili per μ\nmu_range &lt;- seq(mean(y) - 2 * sigma, mean(y) + 2 * sigma, length.out = 1000)\n\n# Inizializza vettore dei risultati\nlog_lik_values &lt;- numeric(length(mu_range))\n\n# Ciclo esplicito per chiarezza didattica\nfor (i in seq_along(mu_range)) {\n  mu_val &lt;- mu_range[i]\n  log_lik_values[i] &lt;- log_likelihood(mu_val, y, sigma)\n}\n\n\n42.9.5 Visualizzazione della Log-Verosimiglianza\n\nggplot(\n  data.frame(mu = mu_range, log_likelihood = log_lik_values),\n  aes(x = mu, y = log_likelihood)\n) +\n  geom_line(color = okabe_ito_palette[2], linewidth = 1.2) +\n  geom_vline(xintercept = mean(y), linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Log-verosimiglianza per punteggi BDI-II\",\n    x = expression(mu),\n    y = \"Log-verosimiglianza\"\n  )\n\n\n\n\n\n\n\nLa linea tratteggiata rossa indica la media campionaria, che — come ci aspettiamo — è anche il valore che massimizza la log-verosimiglianza.\n\n42.9.6 Ottimizzazione Numerica\nSe volessimo calcolare il valore ottimale di \\(\\mu\\) in modo automatico:\n\n# Funzione negativa da minimizzare\nnegative_log_likelihood &lt;- function(mu, y, sigma) {\n  -sum(dnorm(y, mean = mu, sd = sigma, log = TRUE))\n}\n\n# Ottimizzazione con limiti\nresult &lt;- optim(\n  par = mean(y),                   # Valore iniziale\n  fn = negative_log_likelihood,   # Funzione da minimizzare\n  y = y,\n  sigma = sigma,\n  method = \"L-BFGS-B\",\n  lower = min(mu_range),\n  upper = max(mu_range)\n)\n\nmu_optimal &lt;- result$par\ncat(\"Il valore ottimale di μ è:\", mu_optimal)\n#&gt; Il valore ottimale di μ è: 30.93\n\n\nAbbiamo utilizzato dnorm(..., log = TRUE) per calcolare in modo semplice e numericamente stabile la log-verosimiglianza.\nIl valore di \\(\\mu\\) che massimizza la log-verosimiglianza corrisponde alla media campionaria.\nQuesto è un caso in cui la stima di massima verosimiglianza ha una forma chiusa, ma l’approccio numerico resta utile e generalizzabile.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#campione-di-osservazioni-indipendenti",
    "href": "chapters/probability/15_likelihood.html#campione-di-osservazioni-indipendenti",
    "title": "42  La verosimiglianza",
    "section": "\n42.13 Campione di Osservazioni Indipendenti",
    "text": "42.13 Campione di Osservazioni Indipendenti\nSupponiamo di aver raccolto i punteggi alla scala BDI-II per 30 persone. Ciascun punteggio è un’osservazione indipendente da una distribuzione normale con media incognita \\(\\mu\\) e deviazione standard nota \\(\\sigma = 6.5\\).\n\n# Dati osservati (punteggi BDI-II)\ny &lt;- c(\n  26, 35, 30, 25, 44, 30, 33, 43, 22, 43, 24, 19, 39, 31, 25, \n  28, 35, 30, 26, 31, 41, 36, 26, 35, 33, 28, 27, 34, 27, 22\n)\n\nsigma &lt;- 6.5\n\n\n42.13.1 Calcolo della Log-Verosimiglianza\nDefiniamo una funzione che calcola la log-verosimiglianza totale:\n\nlog_likelihood &lt;- function(mu, y, sigma) {\n  sum(dnorm(y, mean = mu, sd = sigma, log = TRUE))\n}\n\nEsploriamo ora un intervallo di valori plausibili per \\(\\mu\\) e calcoliamo la log-verosimiglianza per ciascun valore:\n\n# Intervallo di valori possibili per μ\nmu_range &lt;- seq(mean(y) - 2 * sigma, mean(y) + 2 * sigma, length.out = 1000)\n\n# Inizializza vettore dei risultati\nlog_lik_values &lt;- numeric(length(mu_range))\n\n# Ciclo esplicito per chiarezza didattica\nfor (i in seq_along(mu_range)) {\n  mu_val &lt;- mu_range[i]\n  log_lik_values[i] &lt;- log_likelihood(mu_val, y, sigma)\n}\n\n\n42.13.2 Visualizzazione della Log-Verosimiglianza\n\nggplot(\n  data.frame(mu = mu_range, log_likelihood = log_lik_values),\n  aes(x = mu, y = log_likelihood)\n) +\n  geom_line(color = okabe_ito_palette[2], linewidth = 1.2) +\n  geom_vline(xintercept = mean(y), linetype = \"dashed\", color = \"red\") +\n  labs(\n    title = \"Log-verosimiglianza per punteggi BDI-II\",\n    x = expression(mu),\n    y = \"Log-verosimiglianza\"\n  )\n\n\n\n\n\n\n\nLa linea tratteggiata rossa indica la media campionaria, che — come ci aspettiamo — è anche il valore che massimizza la log-verosimiglianza.\n\n42.13.3 Ottimizzazione Numerica\nSe volessimo calcolare il valore ottimale di \\(\\mu\\) in modo automatico:\n\n# Funzione negativa da minimizzare\nnegative_log_likelihood &lt;- function(mu, y, sigma) {\n  -sum(dnorm(y, mean = mu, sd = sigma, log = TRUE))\n}\n\n# Ottimizzazione con limiti\nresult &lt;- optim(\n  par = mean(y),                   # Valore iniziale\n  fn = negative_log_likelihood,   # Funzione da minimizzare\n  y = y,\n  sigma = sigma,\n  method = \"L-BFGS-B\",\n  lower = min(mu_range),\n  upper = max(mu_range)\n)\n\nmu_optimal &lt;- result$par\ncat(\"Il valore ottimale di μ è:\", mu_optimal)\n#&gt; Il valore ottimale di μ è: 30.93\n\n\nAbbiamo utilizzato dnorm(..., log = TRUE) per calcolare in modo semplice e numericamente stabile la log-verosimiglianza.\nIl valore di \\(\\mu\\) che massimizza la log-verosimiglianza corrisponde alla media campionaria.\nQuesto è un caso in cui la stima di massima verosimiglianza ha una forma chiusa, ma l’approccio numerico resta utile e generalizzabile.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#il-rapporto-di-verosimiglianze",
    "href": "chapters/probability/15_likelihood.html#il-rapporto-di-verosimiglianze",
    "title": "42  La verosimiglianza",
    "section": "\n42.10 Il rapporto di verosimiglianze",
    "text": "42.10 Il rapporto di verosimiglianze\nQuando conduciamo un’analisi statistica, spesso ci troviamo di fronte alla necessità di confrontare due modelli che cercano di spiegare gli stessi dati. Immaginiamo, ad esempio, di voler capire qual è la media di una certa variabile (come il punteggio a un test, il tempo di reazione, ecc.). Potremmo avere due ipotesi alternative sull’effettivo valore della media:\n\nsecondo un primo modello, la media è \\(\\mu_1\\) (ad esempio, l’ipotesi “nulla”, che rappresenta uno stato di riferimento o di assenza di effetto),\nsecondo un secondo modello, la media è \\(\\mu_2\\) (ad esempio, l’ipotesi “alternativa”, che rappresenta un cambiamento o un effetto).\n\nPer decidere quale modello è più compatibile con i dati osservati, possiamo usare la verosimiglianza (likelihood). La verosimiglianza misura quanto bene un certo valore del parametro spiega i dati osservati. Più la verosimiglianza è alta, più i dati sono “coerenti” con quel valore.\n\n42.10.1 Il confronto\nPer confrontare i due modelli, calcoliamo la verosimiglianza dei dati in ciascun caso, e ne facciamo il rapporto:\n\\[\n\\lambda = \\frac{L(\\mu_2 \\mid \\text{dati})}{L(\\mu_1 \\mid \\text{dati})}\n\\tag{42.3}\\]\ndove:\n\n\n\\(L(\\mu_2 \\mid \\text{dati})\\) è la verosimiglianza del modello alternativo (cioè, quanto sono compatibili i dati con \\(\\mu_2\\)),\n\n\\(L(\\mu_1 \\mid \\text{dati})\\) è la verosimiglianza del modello nullo (cioè, quanto sono compatibili i dati con \\(\\mu_1\\)).\n\nQuesta quantità si chiama rapporto di verosimiglianze (likelihood ratio, LR), e rappresenta uno strumento per quantificare quanto i dati favoriscono un modello rispetto all’altro.\n\n42.10.2 Come si interpreta \\(\\lambda\\)?\n\nSe \\(\\lambda &gt; 1\\), significa che i dati supportano più il modello alternativo: i dati sono più probabili sotto \\(\\mu_2\\) che sotto \\(\\mu_1\\).\nSe \\(\\lambda &lt; 1\\), significa che i dati supportano più il modello nullo: i dati sono più probabili sotto \\(\\mu_1\\) che sotto \\(\\mu_2\\).\nSe \\(\\lambda \\approx 1\\), allora i dati non permettono di distinguere chiaramente tra i due modelli.\n\nIl rapporto di verosimiglianze ci dice quale modello rende i dati osservati più “plausibili”.\n\n42.10.3 Un Esempio\nImmagina di aver lanciato una moneta 10 volte e di aver ottenuto 7 teste. Ti chiedi ora quale tra questi due modelli spiega meglio i dati:\n\n\nModello 1 (nullo): la moneta è equa, quindi la probabilità di testa è \\(\\mu_1 = 0.5\\);\n\nModello 2 (alternativo): la moneta è truccata a favore delle teste, e la probabilità di testa è \\(\\mu_2 = 0.7\\).\n\n42.10.4 Calcolo delle verosimiglianze\nUseremo la distribuzione binomiale, che descrive il numero di successi (in questo caso, teste) in un numero fisso di prove (10 lanci), dato un certo valore di probabilità.\nLa verosimiglianza è semplicemente la probabilità di ottenere 7 teste su 10 lanci, sotto ciascun modello:\n\n\nsotto il modello nullo (\\(\\mu_1 = 0.5\\)):\n\\[\nL(0.5 \\mid \\text{7 teste}) = \\binom{10}{7} (0.5)^7 (1 - 0.5)^3 = 120 \\cdot (0.5)^{10} \\approx 0.117\n\\]\n\n\nsotto il modello alternativo (\\(\\mu_2 = 0.7\\)):\n\\[\nL(0.7 \\mid \\text{7 teste}) = \\binom{10}{7} (0.7)^7 (0.3)^3 \\approx 120 \\cdot 0.0824 \\cdot 0.027 = 0.267\n\\]\n\n\n42.10.5 Calcolo del rapporto di verosimiglianze\nOra possiamo calcolare il rapporto:\n\\[\n\\lambda = \\frac{L(0.7 \\mid \\text{7 teste})}{L(0.5 \\mid \\text{7 teste})} \\approx \\frac{0.267}{0.117} \\approx 2.28\n\\]\nQuesto significa che i dati sono circa 2.3 volte più compatibili con l’ipotesi che la moneta sia truccata (con \\(\\mu = 0.7\\)) rispetto a quella che sia equa (\\(\\mu = 0.5\\)).\n\n42.10.6 Visualizzare le funzioni di verosimiglianza\nPossiamo visualizzare graficamente come cambia la verosimiglianza al variare della probabilità di testa (\\(\\theta\\)), mantenendo fisso il numero di lanci e il numero di teste osservate.\n\n42.10.6.1 Codice R\n\n# Parametri osservati\nn &lt;- 10        # numero totale di lanci\nx &lt;- 7         # numero di teste osservate\n\n# Sequenza di probabilità (theta)\ntheta &lt;- seq(0, 1, length.out = 100)\n\n# Verosimiglianza per ogni theta\nlikelihood &lt;- dbinom(x, size = n, prob = theta)\n\n# Crea dataframe per ggplot\ndf &lt;- data.frame(theta = theta, likelihood = likelihood)\n\n# Verosimiglianza nei due modelli\nL_0.5 &lt;- dbinom(x, size = n, prob = 0.5)\nL_0.7 &lt;- dbinom(x, size = n, prob = 0.7)\nLR &lt;- L_0.7 / L_0.5\n\n# Crea grafico\nggplot(df, aes(x = theta, y = likelihood)) +\n  geom_line(color = okabe_ito_palette[2], linewidth = 1.2) +\n  geom_vline(xintercept = 0.5, linetype = \"dashed\", color = \"red\") +\n  geom_vline(xintercept = 0.7, linetype = \"dashed\", color = \"darkgreen\") +\n  geom_point(aes(x = 0.5, y = L_0.5), color = \"red\", size = 3) +\n  geom_point(aes(x = 0.7, y = L_0.7), color = \"darkgreen\", size = 3) +\n  labs(\n    title = \"Funzione di verosimiglianza per 7 teste su 10 lanci\",\n    x = expression(theta),\n    y = \"Verosimiglianza\"\n  ) +\n  annotate(\n    \"text\", x = 0.5, y = L_0.5 + 0.01, \n    label = \"mu == 0.5\", \n    parse = TRUE, hjust = -0.2, color = \"red\"\n  ) +\n  annotate(\n    \"text\", x = 0.7, y = L_0.7 + 0.01, \n    label = \"mu == 0.7\", parse = TRUE, hjust = -0.2, color = \"darkgreen\")\n\n\n\n\n\n\n\n\n# Stampa dei risultati numerici\ncat(\"L(mu = 0.5) =\", round(L_0.5, 3), \"\\n\")\n#&gt; L(mu = 0.5) = 0.117\ncat(\"L(mu = 0.7) =\", round(L_0.7, 3), \"\\n\")\n#&gt; L(mu = 0.7) = 0.267\ncat(\"Likelihood Ratio =\", round(LR, 2), \"\\n\")\n#&gt; Likelihood Ratio = 2.28\n\nIl grafico mostra come cambia la verosimiglianza al variare di \\(\\theta\\), e indica visivamente i valori assunti nei due modelli specifici. Si vede chiaramente che \\(\\theta = 0.7\\) è più compatibile con l’osservazione di 7 teste.\nIn sintesi, il rapporto di verosimiglianze è uno strumento per confrontare due ipotesi. Non richiede che una delle due sia vera, ma solo di confrontare quanto bene ciascuna spiega i dati osservati. In questo esempio, i dati favoriscono l’ipotesi che la moneta sia truccata, ma non in modo schiacciante. Il valore di \\(\\lambda = 2.28\\) indica un’evidenza moderata a favore del modello alternativo.\n\n42.10.7 Rapporti di Verosimiglianza Aggiustati e Criterio di Akaike\nSpesso il rapporto di verosimiglianza “grezzo” (\\(\\lambda\\)) deve essere aggiustato per tenere conto della differenza nel numero di parametri tra i modelli confrontati. Infatti, quando confrontiamo due modelli, quello con più parametri tende quasi sempre a descrivere meglio i dati osservati, ma ciò può essere dovuto semplicemente alla sua maggiore complessità. Questo fenomeno è noto come sovradattamento (overfitting).\nPer correggere questa tendenza, si usa un rapporto di verosimiglianza aggiustato (Adjusted Likelihood Ratio, indicato con \\(\\lambda_{\\text{adj}}\\). Questo tipo di aggiustamento penalizza i modelli più complessi, rendendo il confronto tra modelli più equo e affidabile.\n\n42.10.8 Relazione con il Criterio di Akaike (AIC)\nUna modalità comune per effettuare questa correzione è tramite il Criterio di Akaike (AIC). L’AIC è definito come:\n\\[\n\\text{AIC} = 2k - 2\\log(\\lambda),\n\\tag{42.4}\\]\nin cui:\n\n\n\\(k\\) è il numero dei parametri del modello.\n\n\\(\\lambda\\) è il rapporto di verosimiglianza grezzo.\n\nDa questa equazione possiamo ricavare una formula per calcolare il rapporto di verosimiglianza aggiustato utilizzando l’AIC:\n\\[\n\\lambda_{\\text{adj}} = \\lambda \\times e^{(k_1 - k_2)},\n\\]\ndove:\n\n\n\\(k_1\\) è il numero di parametri del modello più semplice,\n\n\\(k_2\\) è il numero di parametri del modello più complesso,\n\n\\(e^{(k_1 - k_2)}\\) è il fattore correttivo che penalizza il modello più complesso.\n\nIn breve, più parametri ha un modello, maggiore sarà la penalizzazione applicata.\n\n42.10.9 Rapporto tra Likelihood Ratio e AIC\nIl rapporto di verosimiglianza aggiustato tramite l’AIC consente di confrontare in modo equo modelli con un numero differente di parametri. Senza questa correzione, rischieremmo di scegliere sempre modelli più complessi, indipendentemente dalla loro reale capacità esplicativa, con il rischio di sovrastimare la qualità della loro spiegazione.\nUtilizzare il rapporto di verosimiglianza aggiustato, quindi, permette di scegliere il modello migliore considerando sia la capacità di adattarsi ai dati, sia la semplicità del modello stesso.\n\n42.10.10 Illustrazione\nImmaginiamo un semplice esperimento psicologico sulla memoria visiva. Vogliamo capire se mostrare immagini emotivamente intense aiuta le persone a ricordare meglio, rispetto a immagini neutre.\nAbbiamo due gruppi di partecipanti:\n\nil gruppo neutro vede 30 immagini neutre e ne ricorda correttamente 14;\nil gruppo emozionale vede 30 immagini emotivamente intense e ne ricorda 22.\n\n42.10.11 Obiettivo\nVogliamo confrontare due modelli alternativi:\n\n\nmodello nullo (H₀): la probabilità di ricordare un’immagine è uguale nei due gruppi;\n\nmodello alternativo (H₁): la probabilità di ricordare è diversa nei due gruppi.\n\n42.10.12 Dati osservati\n\nsuccessi_neutro &lt;- 14\nsuccessi_emozione &lt;- 22\nprove &lt;- 30\n\n\n42.10.13 1. Calcolo della Verosimiglianza\nIpotesi nulla: probabilità comune.\nSe la probabilità è la stessa in entrambi i gruppi, possiamo stimarla combinando i successi totali:\n\np_null &lt;- (successi_neutro + successi_emozione) / (2 * prove)\n\nLog-verosimiglianza sotto H₀.\nSotto l’ipotesi nulla, i dati di entrambi i gruppi devono essere spiegati da una sola probabilità:\n\nll_null &lt;- dbinom(successi_neutro, prove, p_null, log = TRUE) + \n           dbinom(successi_emozione, prove, p_null, log = TRUE)\n\nIpotesi alternativa: probabilità diversa per ogni gruppo.\nStimiamo separatamente la probabilità di ricordare in ciascun gruppo:\n\np_neutro &lt;- successi_neutro / prove\np_emozione &lt;- successi_emozione / prove\n\nLog-verosimiglianza sotto H₁.\nOgni gruppo ha la propria verosimiglianza:\n\nll_alt &lt;- dbinom(successi_neutro, prove, p_neutro, log = TRUE) + \n          dbinom(successi_emozione, prove, p_emozione, log = TRUE)\n\n\n42.10.14 2. Confronto tra Modelli\nRapporto di verosimiglianza (non penalizzato).\nCalcoliamo il rapporto tra le due verosimiglianze:\n\nlr &lt;- exp(ll_alt - ll_null)\n\nQuesto ci dice quanto meglio il modello alternativo spiega i dati rispetto al modello nullo.\n\n42.10.15 3. Penalizzazione per la Complessità\nI modelli più complessi tendono a spiegare meglio i dati, ma rischiano di adattarsi troppo. Per questo, usiamo un criterio che penalizza la complessità: l’AIC (Akaike Information Criterion).\nNumero di parametri:\n\nk_null &lt;- 1  # un'unica probabilità per entrambi i gruppi\nk_alt &lt;- 2   # probabilità distinte per ciascun gruppo\n\nCalcolo dell’AIC per ciascun modello:\n\nAIC_null &lt;- 2 * k_null - 2 * ll_null\nAIC_alt &lt;- 2 * k_alt - 2 * ll_alt\n\nRapporto di verosimiglianza aggiustato.\nUsiamo l’AIC per calcolare una versione penalizzata del rapporto di verosimiglianze:\n\nlr_adj &lt;- exp((AIC_null - AIC_alt) / 2)\n\nRisultati:\n\ncat(\"Rapporto di verosimiglianza grezzo:\", round(lr, 2), \"\\n\")\n#&gt; Rapporto di verosimiglianza grezzo: 9.54\ncat(\"Rapporto di verosimiglianza aggiustato (λ_adj):\", round(lr_adj, 2), \"\\n\")\n#&gt; Rapporto di verosimiglianza aggiustato (λ_adj): 3.51\n\nInterpretazione:\n\nse λ_adj &gt; 1, i dati sono più compatibili con il modello alternativo (due probabilità distinte);\nse λ_adj ≈ 1, non c’è abbastanza evidenza per preferire un modello all’altro.\n\n42.10.16 4. Test del Rapporto di Verosimiglianza\nPossiamo testare formalmente se la differenza tra i modelli è rilevante o potrebbe essere dovuta al caso.\nLa statistica test è:\n\\[\n-2 \\cdot (\\log L_{H_0} - \\log L_{H_1})\n\\]\nQuesta statistica segue (approssimativamente) una distribuzione chi-quadrato con un numero di gradi di libertà pari alla differenza nel numero di parametri tra i modelli:\n\nLR_test &lt;- -2 * (ll_null - ll_alt)\ndf &lt;- k_alt - k_null\np_value &lt;- 1 - pchisq(LR_test, df)\n\ncat(\"Statistica test (-2 log LR):\", round(LR_test, 2), \"\\n\")\n#&gt; Statistica test (-2 log LR): 4.51\ncat(\"Gradi di libertà:\", df, \"\\n\")\n#&gt; Gradi di libertà: 1\ncat(\"Valore p del test:\", round(p_value, 4), \"\\n\")\n#&gt; Valore p del test: 0.0337\n\nIn sintesi,\n\nse p &lt; 0.05, possiamo concludere che il modello alternativo è da preferire: i dati sono difficilmente compatibili con l’ipotesi di probabilità uguali nei due gruppi;\nse p &gt; 0.05, non abbiamo evidenza sufficiente per preferire il modello alternativo.\n\nNel nostro esempio:\n\nla statistica test è ≈ 4.48;\nil valore-p è ≈ 0.0337.\n\n👉 Poiché il valore-p è inferiore a 0.05, possiamo concludere che il gruppo emozionale ha una probabilità di ricordare credibilmente diversa da quella del gruppo neutro.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#un-esempio-semplice",
    "href": "chapters/probability/15_likelihood.html#un-esempio-semplice",
    "title": "42  La verosimiglianza",
    "section": "\n42.15 Un Esempio Semplice",
    "text": "42.15 Un Esempio Semplice\nImmagina di aver lanciato una moneta 10 volte e di aver ottenuto 7 teste. Ti chiedi ora quale tra questi due modelli spiega meglio i dati:\n\n\nModello 1 (nullo): la moneta è equa, quindi la probabilità di testa è \\(\\mu_1 = 0.5\\);\n\nModello 2 (alternativo): la moneta è truccata a favore delle teste, e la probabilità di testa è \\(\\mu_2 = 0.7\\).\n\n\n42.15.1 Calcolo delle verosimiglianze\nUseremo la distribuzione binomiale, che descrive il numero di successi (in questo caso, teste) in un numero fisso di prove (10 lanci), dato un certo valore di probabilità.\nLa verosimiglianza è semplicemente la probabilità di ottenere 7 teste su 10 lanci, sotto ciascun modello:\n\n\nsotto il modello nullo (\\(\\mu_1 = 0.5\\)):\n\\[\nL(0.5 \\mid \\text{7 teste}) = \\binom{10}{7} (0.5)^7 (1 - 0.5)^3 = 120 \\cdot (0.5)^{10} \\approx 0.117\n\\]\n\n\nsotto il modello alternativo (\\(\\mu_2 = 0.7\\)):\n\\[\nL(0.7 \\mid \\text{7 teste}) = \\binom{10}{7} (0.7)^7 (0.3)^3 \\approx 120 \\cdot 0.0824 \\cdot 0.027 = 0.267\n\\]\n\n\n42.15.2 Calcolo del rapporto di verosimiglianze\nOra possiamo calcolare il rapporto:\n\\[\n\\lambda = \\frac{L(0.7 \\mid \\text{7 teste})}{L(0.5 \\mid \\text{7 teste})} \\approx \\frac{0.267}{0.117} \\approx 2.28\n\\]\n👉 Questo significa che i dati sono circa 2.3 volte più compatibili con l’ipotesi che la moneta sia truccata (con \\(\\mu = 0.7\\)) rispetto a quella che sia equa (\\(\\mu = 0.5\\)).\n\n42.15.3 Visualizzare le funzioni di verosimiglianza\nPossiamo visualizzare graficamente come cambia la verosimiglianza al variare della probabilità di testa (\\(\\theta\\)), mantenendo fisso il numero di lanci e il numero di teste osservate.\n\n42.15.3.1 Codice R\n\n# Parametri osservati\nn &lt;- 10        # numero totale di lanci\nx &lt;- 7         # numero di teste osservate\n\n# Sequenza di probabilità (theta)\ntheta &lt;- seq(0, 1, length.out = 100)\n\n# Verosimiglianza per ogni theta\nlikelihood &lt;- dbinom(x, size = n, prob = theta)\n\n# Crea dataframe per ggplot\ndf &lt;- data.frame(theta = theta, likelihood = likelihood)\n\n# Verosimiglianza nei due modelli\nL_0.5 &lt;- dbinom(x, size = n, prob = 0.5)\nL_0.7 &lt;- dbinom(x, size = n, prob = 0.7)\nLR &lt;- L_0.7 / L_0.5\n\n# Crea grafico\nggplot(df, aes(x = theta, y = likelihood)) +\n  geom_line(color = okabe_ito_palette[2], linewidth = 1.2) +\n  geom_vline(xintercept = 0.5, linetype = \"dashed\", color = \"red\") +\n  geom_vline(xintercept = 0.7, linetype = \"dashed\", color = \"darkgreen\") +\n  geom_point(aes(x = 0.5, y = L_0.5), color = \"red\", size = 3) +\n  geom_point(aes(x = 0.7, y = L_0.7), color = \"darkgreen\", size = 3) +\n  labs(\n    title = \"Funzione di verosimiglianza per 7 teste su 10 lanci\",\n    x = expression(theta),\n    y = \"Verosimiglianza\"\n  ) +\n  annotate(\n    \"text\", x = 0.5, y = L_0.5 + 0.01, \n    label = \"mu == 0.5\", \n    parse = TRUE, hjust = -0.2, color = \"red\"\n  ) +\n  annotate(\n    \"text\", x = 0.7, y = L_0.7 + 0.01, \n    label = \"mu == 0.7\", parse = TRUE, hjust = -0.2, color = \"darkgreen\")\n\n\n\n\n\n\n\n\n# Stampa dei risultati numerici\ncat(\"L(mu = 0.5) =\", round(L_0.5, 3), \"\\n\")\n#&gt; L(mu = 0.5) = 0.117\ncat(\"L(mu = 0.7) =\", round(L_0.7, 3), \"\\n\")\n#&gt; L(mu = 0.7) = 0.267\ncat(\"Likelihood Ratio =\", round(LR, 2), \"\\n\")\n#&gt; Likelihood Ratio = 2.28\n\nIl grafico mostra come cambia la verosimiglianza al variare di \\(\\theta\\), e indica visivamente i valori assunti nei due modelli specifici. Si vede chiaramente che \\(\\theta = 0.7\\) è più compatibile con l’osservazione di 7 teste.\nIn sintesi, il rapporto di verosimiglianze è uno strumento per confrontare due ipotesi. Non richiede che una delle due sia vera, ma solo di confrontare quanto bene ciascuna spiega i dati osservati. In questo esempio, i dati favoriscono l’ipotesi che la moneta sia truccata, ma non in modo schiacciante. Il valore di \\(\\lambda = 2.28\\) indica un’evidenza moderata a favore del modello alternativo.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#rapporti-di-verosimiglianza-aggiustati-e-criterio-di-akaike",
    "href": "chapters/probability/15_likelihood.html#rapporti-di-verosimiglianza-aggiustati-e-criterio-di-akaike",
    "title": "42  La verosimiglianza",
    "section": "\n42.16 Rapporti di Verosimiglianza Aggiustati e Criterio di Akaike",
    "text": "42.16 Rapporti di Verosimiglianza Aggiustati e Criterio di Akaike\nSpesso il rapporto di verosimiglianza “grezzo” (\\(\\lambda\\)) deve essere aggiustato per tenere conto della differenza nel numero di parametri tra i modelli confrontati. Infatti, quando confrontiamo due modelli, quello con più parametri tende quasi sempre a descrivere meglio i dati osservati, ma ciò può essere dovuto semplicemente alla sua maggiore complessità. Questo fenomeno è noto come sovradattamento (overfitting).\nPer correggere questa tendenza, si usa un rapporto di verosimiglianza aggiustato (Adjusted Likelihood Ratio, indicato con \\(\\lambda_{\\text{adj}}\\). Questo tipo di aggiustamento penalizza i modelli più complessi, rendendo il confronto tra modelli più equo e affidabile.\n\n42.16.1 Relazione con il Criterio di Akaike (AIC)\nUna modalità comune per effettuare questa correzione è tramite il Criterio di Akaike (AIC). L’AIC è definito come:\n\\[\n\\text{AIC} = 2k - 2\\log(\\lambda),\n\\tag{42.4}\\]\nin cui:\n\n\n\\(k\\) è il numero dei parametri del modello.\n\n\\(\\lambda\\) è il rapporto di verosimiglianza grezzo.\n\nDa questa equazione possiamo ricavare una formula per calcolare il rapporto di verosimiglianza aggiustato utilizzando l’AIC:\n\\[\n\\lambda_{\\text{adj}} = \\lambda \\times e^{(k_1 - k_2)},\n\\]\ndove:\n\n\n\\(k_1\\) è il numero di parametri del modello più semplice,\n\n\\(k_2\\) è il numero di parametri del modello più complesso,\n\n\\(e^{(k_1 - k_2)}\\) è il fattore correttivo che penalizza il modello più complesso.\n\nIn breve, più parametri ha un modello, maggiore sarà la penalizzazione applicata.\n\n42.16.2 Rapporto tra Likelihood Ratio e AIC\nIl rapporto di verosimiglianza aggiustato tramite l’AIC consente di confrontare in modo equo modelli con un numero differente di parametri. Senza questa correzione, rischieremmo di scegliere sempre modelli più complessi, indipendentemente dalla loro reale capacità esplicativa, con il rischio di sovrastimare la qualità della loro spiegazione.\nUtilizzare il rapporto di verosimiglianza aggiustato, quindi, permette di scegliere il modello migliore considerando sia la capacità di adattarsi ai dati, sia la semplicità del modello stesso.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#illustrazione",
    "href": "chapters/probability/15_likelihood.html#illustrazione",
    "title": "42  La verosimiglianza",
    "section": "\n42.17 Illustrazione",
    "text": "42.17 Illustrazione\nImmaginiamo un semplice esperimento psicologico sulla memoria visiva. Vogliamo capire se mostrare immagini emotivamente intense aiuta le persone a ricordare meglio, rispetto a immagini neutre.\nAbbiamo due gruppi di partecipanti:\n\nil gruppo neutro vede 30 immagini neutre e ne ricorda correttamente 14;\nil gruppo emozionale vede 30 immagini emotivamente intense e ne ricorda 22.\n\n\n42.17.1 Obiettivo\nVogliamo confrontare due modelli alternativi:\n\n\nmodello nullo (H₀): la probabilità di ricordare un’immagine è uguale nei due gruppi;\n\nmodello alternativo (H₁): la probabilità di ricordare è diversa nei due gruppi.\n\n42.17.2 Dati osservati\n\nsuccessi_neutro &lt;- 14\nsuccessi_emozione &lt;- 22\nprove &lt;- 30\n\n\n42.17.3 1. Calcolo della Verosimiglianza\nIpotesi nulla: probabilità comune.\nSe la probabilità è la stessa in entrambi i gruppi, possiamo stimarla combinando i successi totali:\n\np_null &lt;- (successi_neutro + successi_emozione) / (2 * prove)\n\nLog-verosimiglianza sotto H₀.\nSotto l’ipotesi nulla, i dati di entrambi i gruppi devono essere spiegati da una sola probabilità:\n\nll_null &lt;- dbinom(successi_neutro, prove, p_null, log = TRUE) + \n           dbinom(successi_emozione, prove, p_null, log = TRUE)\n\nIpotesi alternativa: probabilità diversa per ogni gruppo.\nStimiamo separatamente la probabilità di ricordare in ciascun gruppo:\n\np_neutro &lt;- successi_neutro / prove\np_emozione &lt;- successi_emozione / prove\n\nLog-verosimiglianza sotto H₁.\nOgni gruppo ha la propria verosimiglianza:\n\nll_alt &lt;- dbinom(successi_neutro, prove, p_neutro, log = TRUE) + \n          dbinom(successi_emozione, prove, p_emozione, log = TRUE)\n\n\n42.17.4 2. Confronto tra Modelli\nRapporto di verosimiglianza (non penalizzato).\nCalcoliamo il rapporto tra le due verosimiglianze:\n\nlr &lt;- exp(ll_alt - ll_null)\n\nQuesto ci dice quanto meglio il modello alternativo spiega i dati rispetto al modello nullo.\n\n42.17.5 3. Penalizzazione per la Complessità\nI modelli più complessi tendono a spiegare meglio i dati, ma rischiano di adattarsi troppo. Per questo, usiamo un criterio che penalizza la complessità: l’AIC (Akaike Information Criterion).\nNumero di parametri:\n\nk_null &lt;- 1  # un'unica probabilità per entrambi i gruppi\nk_alt &lt;- 2   # probabilità distinte per ciascun gruppo\n\nCalcolo dell’AIC per ciascun modello:\n\nAIC_null &lt;- 2 * k_null - 2 * ll_null\nAIC_alt &lt;- 2 * k_alt - 2 * ll_alt\n\nRapporto di verosimiglianza aggiustato.\nUsiamo l’AIC per calcolare una versione penalizzata del rapporto di verosimiglianze:\n\nlr_adj &lt;- exp((AIC_null - AIC_alt) / 2)\n\nRisultati:\n\ncat(\"Rapporto di verosimiglianza grezzo:\", round(lr, 2), \"\\n\")\n#&gt; Rapporto di verosimiglianza grezzo: 9.54\ncat(\"Rapporto di verosimiglianza aggiustato (λ_adj):\", round(lr_adj, 2), \"\\n\")\n#&gt; Rapporto di verosimiglianza aggiustato (λ_adj): 3.51\n\nInterpretazione:\n\nse λ_adj &gt; 1, i dati sono più compatibili con il modello alternativo (due probabilità distinte);\nse λ_adj ≈ 1, non c’è abbastanza evidenza per preferire un modello all’altro.\n\n42.17.6 4. Test del Rapporto di Verosimiglianza\nPossiamo testare formalmente se la differenza tra i modelli è rilevante o potrebbe essere dovuta al caso.\nLa statistica test è:\n\\[\n-2 \\cdot (\\log L_{H_0} - \\log L_{H_1})\n\\]\nQuesta statistica segue (approssimativamente) una distribuzione chi-quadrato con un numero di gradi di libertà pari alla differenza nel numero di parametri tra i modelli:\n\nLR_test &lt;- -2 * (ll_null - ll_alt)\ndf &lt;- k_alt - k_null\np_value &lt;- 1 - pchisq(LR_test, df)\n\ncat(\"Statistica test (-2 log LR):\", round(LR_test, 2), \"\\n\")\n#&gt; Statistica test (-2 log LR): 4.51\ncat(\"Gradi di libertà:\", df, \"\\n\")\n#&gt; Gradi di libertà: 1\ncat(\"Valore p del test:\", round(p_value, 4), \"\\n\")\n#&gt; Valore p del test: 0.0337\n\nIn sintesi,\n\nse p &lt; 0.05, possiamo concludere che il modello alternativo è da preferire: i dati sono difficilmente compatibili con l’ipotesi di probabilità uguali nei due gruppi;\nse p &gt; 0.05, non abbiamo evidenza sufficiente per preferire il modello alternativo.\n\nNel nostro esempio:\n\nla statistica test è ≈ 4.48;\nil valore-p è ≈ 0.0337.\n\n👉 Poiché il valore-p è inferiore a 0.05, possiamo concludere che il gruppo emozionale ha una probabilità di ricordare credibilmente diversa da quella del gruppo neutro.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#riflessioni-conclusive",
    "href": "chapters/probability/15_likelihood.html#riflessioni-conclusive",
    "title": "42  La verosimiglianza",
    "section": "\n42.11 Riflessioni Conclusive",
    "text": "42.11 Riflessioni Conclusive\nLa funzione di verosimiglianza costituisce il fulcro dell’inferenza statistica, permettendo di quantificare la plausibilità dei parametri di un modello alla luce dei dati osservati. La sua costruzione poggia su tre elementi fondamentali: la scelta del modello generatore dei dati, lo spazio dei parametri e le evidenze empiriche.\nNel caso di modelli binomiali e gaussiani, la verosimiglianza assume forme analiticamente maneggevoli, facilitando sia la stima puntuale che la valutazione di ipotesi. In particolare:\n- Per la distribuzione normale, la stima di massima verosimiglianza di () coincide con la media campionaria, mentre la sua rappresentazione grafica offre una chiara indicazione della precisione della stima.\n- L’uso della log-verosimiglianza non solo semplifica i calcoli, ma migliora anche la stabilità numerica, specialmente in contesti con campioni di grandi dimensioni.\n- Il rapporto di verosimiglianza emerge come strumento versatile, capace di coniugare bontà di adattamento e parsimonia, come dimostrato da criteri quali l’AIC.\nQuesti strumenti non sono meri artifici tecnici, ma rappresentano un linguaggio comune per confrontare modelli e interpretare risultati in modo rigoroso. La loro corretta applicazione richiede tuttavia una comprensione approfondita delle assunzioni sottostanti, affinché le conclusioni tratte riflettano fedelmente la realtà dei dati.\nIn definitiva, la verosimiglianza – nelle sue diverse forme – rimane una guida indispensabile per navigare il complesso rapporto tra teoria e osservazione, offrendo un equilibrio tra flessibilità metodologica e robustezza inferenziale.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#esercizi",
    "href": "chapters/probability/15_likelihood.html#esercizi",
    "title": "42  La verosimiglianza",
    "section": "Esercizi",
    "text": "Esercizi\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nSpiega ciascuno dei concetti seguenti con una frase:\n\nprobabilità.\nfunzione di massa di probabilità.\nfunzione di densità di probabilità.\ndistribuzione di probabilità.\ndistribuzione di probabilità discreta.\ndistribuzione di probabilità continua.\nfunzione di distribuzione cumulativa (cdf).\nverosimiglianza\n\n\n\n\n\n\n\n\n\n\nProblemi\n\n\n\n\n\nSupponi di aver misurato il livello di ansia (ad esempio usando una scala standardizzata) in un campione di 15 persone con i seguenti punteggi:\nansia &lt;- c(23, 27, 30, 29, 25, 28, 26, 24, 31, 29, 27, 26, 28, 30, 25)\nAssumendo che la deviazione standard sia nota e pari a 3.5, svolgi le seguenti attività in R:\n\nCalcola la funzione di verosimiglianza gaussiana per diversi valori di \\(\\mu\\) nell’intervallo da 20 a 35.\nTrova numericamente il valore di \\(\\mu\\) che rende massima la verosimiglianza (stima di massima verosimiglianza, MLE).\nDisegna un grafico della funzione di verosimiglianza per visualizzare il risultato.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/15_likelihood.html#informazioni-sullambiente-di-sviluppo",
    "title": "42  La verosimiglianza",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.5\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] thematic_0.1.6   MetBrewer_0.2.0  ggokabeito_0.1.0 see_0.11.0      \n#&gt;  [5] gridExtra_2.3    patchwork_1.3.0  bayesplot_1.12.0 psych_2.5.3     \n#&gt;  [9] scales_1.4.0     markdown_2.0     knitr_1.50       lubridate_1.9.4 \n#&gt; [13] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4     \n#&gt; [17] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.2   \n#&gt; [21] tidyverse_2.0.0  rio_1.2.3        here_1.0.1      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.4     stringi_1.8.7      lattice_0.22-7    \n#&gt;  [4] hms_1.1.3          digest_0.6.37      magrittr_2.0.3    \n#&gt;  [7] evaluate_1.0.3     grid_4.5.0         timechange_0.3.0  \n#&gt; [10] RColorBrewer_1.1-3 fastmap_1.2.0      rprojroot_2.0.4   \n#&gt; [13] jsonlite_2.0.0     mnormt_2.1.1       cli_3.6.5         \n#&gt; [16] rlang_1.1.6        withr_3.0.2        tools_4.5.0       \n#&gt; [19] parallel_4.5.0     tzdb_0.5.0         pacman_0.5.1      \n#&gt; [22] vctrs_0.6.5        R6_2.6.1           lifecycle_1.0.4   \n#&gt; [25] htmlwidgets_1.6.4  pkgconfig_2.0.3    pillar_1.10.2     \n#&gt; [28] gtable_0.3.6       glue_1.8.0         xfun_0.52         \n#&gt; [31] tidyselect_1.2.1   rstudioapi_0.17.1  farver_2.1.2      \n#&gt; [34] htmltools_0.5.8.1  nlme_3.1-168       labeling_0.4.3    \n#&gt; [37] rmarkdown_2.29     compiler_4.5.0",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_likelihood.html#bibliografia",
    "href": "chapters/probability/15_likelihood.html#bibliografia",
    "title": "42  La verosimiglianza",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nSchervish, M. J., & DeGroot, M. H. (2014). Probability and statistics (Vol. 563). Pearson Education London, UK:",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/introduction_probability.html",
    "href": "chapters/probability/introduction_probability.html",
    "title": "Probabilità",
    "section": "",
    "text": "Questa sezione della dispensa introduce la teoria della probabilità, una componente essenziale per la ricerca scientifica. Nell’ambito della scienza, l’inferenza induttiva è di fondamentale importanza, e la probabilità svolge un ruolo cruciale in questo processo. Poiché la scienza non può garantire verità assolute, ma solo approssimazioni corroborate da evidenze, la probabilità diventa lo strumento chiave per quantificare il grado di incertezza associato a un’ipotesi, a una previsione o a un modello. Due scuole di pensiero dominano questo scenario: l’approccio bayesiano, che interpreta la probabilità come misura soggettiva del grado di fiducia in una proposizione, e l’approccio frequentista, che la definisce come frequenza relativa di un evento osservabile in condizioni ripetute. Sebbene queste prospettive differiscano radicalmente nell’interpretazione filosofica, entrambe poggiano sullo stesso formalismo matematico. Padroneggiare i concetti fondamentali della probabilità è dunque essenziale per comprendere sia gli strumenti dell’inferenza bayesiana, sia quelli classici dell’analisi statistica.\nQuesta sezione fornisce le basi teoriche necessarie per navigare entrambi i paradigmi. Partiremo dalle definizioni di probabilità e dalle sue regole fondamentali, per poi introdurre concetti come la probabilità condizionale e il teorema di Bayes, che stanno alla base dell’aggiornamento delle credenze alla luce di nuovi dati. Esploreremo inoltre le proprietà delle variabili casuali, distinguendo tra distribuzioni discrete (a massa di probabilità) e continue (a densità di probabilità). Infine, discuteremo la funzione di verosimiglianza, comune alle due scuole: mentre i bayesiani la integrano con informazioni a priori per costruire distribuzioni posteriori, i frequentisti ne sfruttano il principio della massima verosimiglianza per stimare parametri in modo puramente empirico, senza assumere conoscenze preliminari.",
    "crumbs": [
      "Probabilità"
    ]
  }
]