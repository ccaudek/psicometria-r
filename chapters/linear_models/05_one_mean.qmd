# Inferenza bayesiana su una media {#sec-mcmc-one-mean}

::: callout-important
## In questo capitolo imparerai a

- fare inferenza sulla media di un campione;
- trovare le distribuzioni a posteriori usando `brms`;
- verificare il modello usando i pp-check plots.
:::

::: callout-tip
## Prerequisiti

- Leggere il capitolo *Geocentric models* di Statistical rethinking [@McElreath_rethinking].
:::

::: .callout-caution
## Preparazione del Notebook

```{r}
here::here("code", "_common.R") |> 
  source()

# Load packages
if (!requireNamespace("pacman")) install.packages("pacman")
pacman::p_load(cmdstanr, posterior, bayestestR, brms, ggdist)
```
:::

## Introduzione 

L'obiettivo principale di questo capitolo è esaminare un contesto che abbiamo già preso in considerazione in precedenza: ci troviamo di fronte a un campione di dati misurati su una scala a intervalli o rapporti e desideriamo effettuare inferenze sulla media della popolazione da cui il campione è stato estratto. Tuttavia, anziché procedere con una derivazione analitica della distribuzione a posteriori della media della popolazione, in questo caso utilizzeremo `brms`.

## Il modello Normale

I priori coniugati Normali di una Normale non richiedono l'approssimazione numerica ottenuta mediante metodi MCMC. In questo capitolo, tuttavia, ripetiamo l'esercizio descritto nel @sec-bayesian-inference-conjugate-2 usando `brms`.

## Un esempio concreto

Per applicare il modello Normale, utilizzeremo i dati del censimento parziale dell'area di Dobe dei !Kung San, raccolti attraverso interviste condotte da Nancy Howell alla fine degli anni '60. I !Kung San sono una suddivisione della popolazione San, che vive nel deserto del Kalahari, tra Namibia, Botswana e Angola, e mantengono un'economia basata su caccia e raccolta. Riprodurremo l'analisi descritta da @McElreath_rethinking, esaminando unicamente i valori dell'altezza di individui di età superiore ai 18 anni.

```{r}
df <- rio::import(here::here("data", "Howell_18.csv"))
df |> 
  head()
```

Il campione include 352 osservazioni:

```{r}
length(df$height)
```

```{r}
ggplot(df, aes(x = height)) +
  geom_histogram(binwidth = 5, color = "black", fill = "lightblue") +
  labs(title = "Istogramma dell'Altezza", x = "Altezza (cm)", y = "Frequenza") +
  theme(
    plot.title = element_text(hjust = 0.5)
  )
```

Come indicato dall'istogramma, i dati sono approssimativamente distribuiti in maniera gaussiana:

```{r}
df |>
  ggplot(aes(sample = height)) +
  stat_qq() +
  stat_qq_line(colour = "red") +
  labs(
    title = "Normal Q-Q plot",
    x = "Teorici (Z-score)",
    y = "Valori osservati"
  ) +
  theme(
    plot.title = element_text(hjust = 0.5)
  )
```

In realtà, dal Q-Q plot si nota un piccolo scostamento sistematico. Quando la retta che approssima i punti empirici risulta più **piatta** rispetto alla diagonale teorica (che avrebbe pendenza 1 se i dati fossero perfettamente normali), la distribuzione empirica risulta **meno dispersa** di una Gaussiana di riferimento: i quantili empirici aumentano più lentamente di quelli teorici, indicando una varianza leggermente inferiore (o code meno ampie). Nel caso presente, tuttavia, questo scostamento è di modesta entità e si può comunque procedere all’adattamento di un modello gaussiano.

## Modello Bayesiano per una singola media

Immaginiamo di voler modellare l’altezza (in cm) di un gruppo di persone.
Per ogni osservazione $y_n$ (con $n=1,\dots,N$) assumiamo:

$$
y_n \;\sim\; \mathcal N\!\bigl(\mu,\;\sigma\bigr) ,
$$

dove

* **$\mu$** è la *media vera* (ignota) dell’altezza nella popolazione;
* **$\sigma$** è la *deviazione standard vera* (anch’essa ignota), che misura quanto le altezze oscillano attorno a $\mu$.


### Cosa significa l’assunzione “iid”

* **Identicamente distribuiti** – tutti i $t_n$ provengono dalla stessa distribuzione normale $\mathcal N(\mu,\sigma)$.
* **Indipendenti** – conoscere l’errore commesso su un individuo non dà alcuna informazione sull’errore commesso su un altro:

  $$
    \operatorname{cov}(y_i-\mu,\; y_j-\mu)=0 \quad\text{per } i\neq j.
  $$

Scrivere “$y_n \sim \mathcal N(\mu,\sigma)$” è quindi un modo compatto per dire che i dati osservati sono *iid* dalla distribuzione normale parametrizzata da $\mu$ e $\sigma$.


### Esplorare i dati

Prima di inserire priors ed eseguire l’inferenza Bayesiana può essere utile vedere che cosa raccontano i dati grezzi.

```{r}
# media campionaria
mean(df$height)

# deviazione standard campionaria
sd(df$height)
```

* **Media campionaria**: una stima preliminare di $\mu$.
* **Deviazione standard campionaria**: una stima preliminare di $\sigma$.

Questi riassunti *non* sostituiscono l’inferenza Bayesiana, ma aiutano a:

1. **scegliere priors ragionevoli** (per esempio centrare la prior di $\mu$ vicino alla media campionaria).
2. **controllare outlier o errori di misura** che, essendo la Normal sensibile agli estremi, potrebbero distorcere l’analisi.

## Il modello frequentista 

Nel contesto frequentista, se vogliamo stimare la **media dell’altezza** nella popolazione, possiamo usare un modello lineare molto semplice: un modello **senza predittori**, che stima solo l’intercetta.

In R, questo si traduce nella formula:

```r
height ~ 1
```

Il simbolo `1` indica che vogliamo stimare **solo l’intercetta**, cioè la media dell’altezza nel campione. Il modello si può specificare così:

```{r}
fm1 <- lm(
  formula = height ~ 1, 
  data = df
)
```

### Interpretazione del modello

L’output del comando:

```{r}
summary(fm1)
```

mostra:

* la **stima puntuale dell’intercetta** ($\hat{\alpha}$), che in questo caso coincide con la **media campionaria di `height`**;
* l’**errore standard** della stima;
* il **p-value** (relativo all’ipotesi nulla che la media sia zero, anche se raramente è di interesse reale);
* l’**R-squared**, che però **non è informativo** in un modello senza predittori.

### Intervallo di confidenza al 95% per la media

Per ottenere l’intervallo di confidenza frequentista al 95% per $\alpha$ (cioè per la media campionaria), possiamo usare la funzione `confint()`:

```{r}
confint(fm1, level = 0.95)
```

Quest’intervallo si basa sulla formula classica:

$$
\hat{\alpha} \pm t_{\text{df}} \cdot \text{SE}(\hat{\alpha})
$$

dove:

* $\hat{\alpha}$ è la stima puntuale della media;
* $t_{\text{df}}$ è il quantile della distribuzione t di Student, con un numero di gradi di libertà pari a $n - 1$;
* $\text{SE}(\hat{\alpha})$ è l’errore standard della stima.


### Calcolo manuale dell’intervallo

Se vogliamo calcolare l’intervallo “a mano”, possiamo scrivere:

```{r}
coef(fm1) + c(-1, 1) * qt(0.975, df.residual(fm1)) * 0.413
```

* `coef(fm1)` restituisce la stima della media;
* `qt(0.975, df.residual(fm1))` restituisce il valore critico della distribuzione $t$ per un intervallo al 95%;
* `0.413` è l’errore standard della stima (può essere sostituito con il valore esatto fornito da `summary(fm1)`).

In sintesi, questo è l’approccio frequentista classico per stimare la media e costruire un intervallo di confidenza. Si basa su:

* la **distribuzione campionaria** della media,
* l’assunzione di **normalità** e **indipendenza** degli errori.


## Modello Bayesiano senza specificare prior (prior debolmente informativi)

Dopo aver stimato la media dell’altezza con il modello frequentista, ora vogliamo **replicare lo stesso modello** usando un approccio **bayesiano** con il pacchetto `brms`.

Nel modello bayesiano, è sempre necessario specificare delle **distribuzioni a priori** per i parametri. Tuttavia, se **non le specifichiamo esplicitamente**, `brms` utilizzerà dei **prior debolmente informativi**: distribuzioni ampie e generiche, che influenzano poco l’inferenza quando i dati sono informativi. In pratica, è come dire “non abbiamo forti idee a priori, lasciamo che siano i dati a parlare”.


### Specifica del modello

Il codice per stimare il modello è simile a quello usato con `lm()`:

```{r}
#| message: false
#| warning: false
#| output: false
#| 
fm2 <- brm(
  formula = height ~ 1,        # come prima, stimiamo solo l'intercetta
  family = gaussian(),         # specifica la distribuzione dei dati (Normal)
  data = df,                   # dataset
  chains = 4,                  # numero di catene indipendenti
  iter = 2000,                 # numero totale di iterazioni per catena
  warmup = 1000,               # iterazioni iniziali usate per "scaldare" l'algoritmo
  backend = "cmdstanr"         # motore di calcolo usato (più veloce e trasparente)
)
```

Vediamo nel dettaglio alcune opzioni:

1. **`formula = height ~ 1`**
   Indica che stiamo stimando solo l’intercetta, cioè la media dell’altezza.

2. **`family = gaussian()`**
   Rende esplicito che i dati seguono una distribuzione normale. (Con `lm()` era implicito.)

3. **`prior = ...`**
   In questo caso non lo abbiamo specificato, quindi `brms` userà i **prior di default** (debolmente informativi).

4. **`chains`, `iter`, `warmup`**
   Sono parametri che controllano come viene effettuato il campionamento Bayesiano, cioè la stima della distribuzione a posteriori dei parametri:

   * `chains`: quante catene indipendenti vengono eseguite (default = 4).
   * `iter`: numero totale di iterazioni per catena.
   * `warmup`: prime iterazioni da scartare (servono ad “adattare” il campionatore).

L’algoritmo usato da `brms` per il campionamento si chiama **NUTS** (No-U-Turn Sampler), un’evoluzione del metodo Hamiltonian Monte Carlo. È molto efficiente nel campionare distribuzioni complesse.


### Struttura del modello

Anche in questo caso, il modello può essere scritto così:

$$
y_i = \alpha + \varepsilon_i, \quad \varepsilon_i \sim \mathcal{N}(0, \sigma)
$$

La differenza è che qui **stiamo stimando la distribuzione a posteriori** di $\alpha$ e $\sigma$, e non solo un valore puntuale.

### Analisi dell’output

Una volta stimato il modello, possiamo esaminare i risultati con:

```{r}
summary(fm2)
```

L’output mostrerà:

* la **media (o mediana)** della distribuzione a posteriori per $\alpha$ (cioè la nostra stima della media dell’altezza),
* l’**errore standard a posteriori**,
* l’**intervallo di credibilità al 95%**, che rappresenta la zona in cui, dato il modello e i dati, si trova con alta probabilità il valore vero di $\alpha$.

Questo **intervallo di credibilità** è diverso dall’intervallo di confidenza frequentista: in ottica bayesiana possiamo davvero dire che "c'è il 95% di probabilità che $\alpha$ sia dentro l’intervallo", dato che stiamo ragionando in termini di probabilità sui parametri.

Se il modello converge correttamente (nessun avviso di problemi), il comando `summary()` fornisce un riassunto completo della stima Bayesiana, rendendo il passaggio dal mondo frequentista a quello bayesiano molto intuitivo.


## Riportare i Risultati

Nel caso frequentista, il risultato può essere riportato nel modo seguente: 

> l’analisi ha fornito una stima puntuale di α pari a 154.6, con un intervallo di confidenza al 95% compreso tra [153.8; 155.4].

Nel caso bayesiano diciamo:

> l’analisi bayesiana, condotta con una prior non informativa, ha restituito una stima a posteriori di α pari a 154.6, con un intervallo di credibilità al 95% [153.8; 155.4].


### Analisi dei Campioni a Posteriori

Dopo aver stimato il modello con `brm()`, possiamo accedere ai **campioni a posteriori** dei parametri. Ogni campione rappresenta una possibile combinazione di valori plausibili di $\alpha$ (la media) e $\sigma$ (la deviazione standard), estratta dalla distribuzione a posteriori.

Per esplorare questi campioni, usiamo:

```{r}
as_draws_df(fm2) %>% 
  head(3)
```

Nella tabella risultante, la colonna **`b_Intercept`** rappresenta i campioni per $\mu$, cioè la media dell’altezza stimata a posteriori.

Possiamo ignorare le ultime tre colonne:

* `Intercept`: un’intercetta “ausiliaria” usata se ci fossero predittori centrati (coincide con `b_Intercept` in questo caso).
* `lprior`: la log-verosimiglianza del prior, utile per strumenti diagnostici (es. con il pacchetto [`priorsense`](https://github.com/n-kall/priorsense)).
* `lp__`: la log-verosimiglianza a posteriori non normalizzata, utile per il campionamento ma non per l'inferenza diretta.


### Calcoli riassuntivi sui campioni a posteriori

Possiamo calcolare direttamente **media**, **deviazione standard** e **intervallo di credibilità al 95%** per $\mu$, usando i campioni della colonna `b_Intercept`:

```{r}
# Media a posteriori (stima puntuale)
as_draws_df(fm2)$b_Intercept %>% mean()
```

```{r}
# Deviazione standard a posteriori (errore standard)
as_draws_df(fm2)$b_Intercept %>% sd()
```

```{r}
# Intervallo di credibilità al 95%
as_draws_df(fm2)$b_Intercept %>% quantile(c(0.025, 0.975))
```

### Conclusioni Intermedie

* Con `lm()` (modello **frequentista**), otteniamo una stima puntuale di $\alpha$ tramite il **metodo della massima verosimiglianza**, e un **intervallo di confidenza al 95%**, che esprime quanto sarebbe variabile la nostra stima in campioni ripetuti.

* Con `brm()` (modello **bayesiano**), otteniamo una **distribuzione a posteriori** per $\alpha$, che riflette l’incertezza residua dopo aver visto i dati. Anche usando un **prior debolmente informativo**, i risultati numerici sono molto simili a quelli frequentisti—ma la **prospettiva interpretativa è diversa**:
  un intervallo come $[153.78,\ 155.41]$ significa che c’è **il 95% di probabilità** che il vero valore di $\alpha$ sia compreso in quell’intervallo.

* Se decidessimo di includere **informazioni a priori specifiche** (ad esempio, provenienti da studi precedenti), potremmo definire un **prior informativo** per $\alpha$ all’interno di `brm()`. In questo caso, i risultati potrebbero **divergere sensibilmente** da quelli frequentisti, **soprattutto quando i dati sono scarsi** o poco informativi.

Questo esempio mostra come il modello bayesiano generalizzi il caso frequentista, offrendo maggiore flessibilità e un’interpretazione probabilistica più diretta.


## Uso dei Prior nel Modello Bayesiano

Abbiamo visto che è possibile stimare il nostro modello anche senza specificare esplicitamente le distribuzioni a priori, ottenendo comunque le distribuzioni a posteriori dei parametri. Tuttavia, prima di interpretare i risultati, è importante porsi alcune domande fondamentali:

* **Quali informazioni stiamo introducendo attraverso i prior?**
* **I prior riflettono credenze plausibili e coerenti con il contesto del problema?**
* **La funzione di verosimiglianza scelta è adatta ai dati osservati?**

Per rispondere a queste domande, nei prossimi passaggi esamineremo sia la **distribuzione predittiva a priori** sia quella **a posteriori**, e condurremo analisi di **sensibilità ai prior**. Questi strumenti permettono di valutare quanto le assunzioni iniziali influenzino i risultati finali.

### Specificare i priori: un esempio concreto

Nel paradigma bayesiano, possiamo incorporare **conoscenze pregresse** sotto forma di distribuzioni a priori. In questo esempio, ipotizziamo di avere qualche aspettativa informata sull’altezza media e sulla sua variabilità. Assegniamo:

* una prior $\mathcal{N}(181,\ 30)$ per $\mu$, la media dell’altezza,
* una prior $\mathcal{N}(0,\ 20)$, **troncata inferiormente a zero**, per $\sigma$, la deviazione standard.

La scelta del valore centrale di 181 cm per $\mu$ segue l’esempio di @McElreath_rethinking, che ironicamente propone la propria altezza come ipotesi iniziale informata. È un modo per mostrare che anche una conoscenza soggettiva può entrare nel modello, purché dichiarata apertamente.

### Descrizione formale del modello

Il modello bayesiano assume la seguente forma:

$$
\begin{aligned}
Y_i &\sim \mathcal{N}(\mu, \sigma) \\
\mu &\sim \mathcal{N}(181,\ 30) \\
\sigma &\sim \mathcal{N}^+(0,\ 20)
\end{aligned}
$$

dove:

* $Y_i$ rappresenta l’altezza osservata per l’individuo $i$,
* $\mu$ è la media da stimare,
* $\sigma$ è la deviazione standard,
* $\mathcal{N}^+$ indica una **normale troncata** per garantire che $\sigma > 0$.

In ambito bayesiano, $\mu$ e $\sigma$ sono trattati come **variabili casuali**: non esistono come valori fissi da scoprire, ma come quantità soggette a incertezza, aggiornabili in base ai dati.


### Implementazione in `brms`

Il codice per stimare questo modello in `brms` è il seguente:

```{r}
#| message: false
#| warning: false
#| output: false
#| 
fm3 <- brm(
  formula = height ~ 1,             # Modello con sola intercetta (μ)
  data    = df,
  family  = gaussian(),             # Modello normale
  prior   = c(
    prior(normal(181, 30), class = "Intercept"),  # Prior informativo su μ
    prior(normal(0, 20), class = "sigma")         # Prior (troncato) su σ
  ),
  chains  = 4,
  iter    = 2000,
  seed    = 1234,
  backend = "cmdstanr"
)
```

Una volta stimato il modello, possiamo ottenere un riepilogo dei risultati con:

```{r}
summary(fm3)
```

### Risultati e interpretazione

Anche con questi **prior informativi ma ampi**, i risultati per $\mu$ saranno simili a quelli del modello frequentista se i dati sono sufficientemente informativi. In questo caso, i dati “prevalgono” sul prior: è un comportamento desiderabile quando i prior non sono troppo restrittivi.

### Cambiare il livello dell’intervallo di credibilità

Possiamo chiedere a `brms` di calcolare un **intervallo di credibilità all’89%** (anziché al consueto 95%):

```{r}
summary(fm3, prob = 0.89)
```

@McElreath_rethinking suggerisce l’intervallo all’89% come default nel suo approccio didattico, per evitare che i lettori lo interpretino come un test di significatività mascherato. Aggiunge anche con ironia:

> Why 89%? It’s just the default. It displays a quite wide interval, so it shows a high-probability range of parameter values. If you want another interval, such as the conventional and mindless 95%, you can use `precis(m4.1, prob = 0.95)`. But I don’t recommend 95% intervals, because readers will have a hard time not viewing them as significance tests. 89 is also a prime number, so if someone asks you to justify it, you can stare at them meaningfully and incant, ‘Because it is prime.’ That’s no worse justification than the conventional justification for 95%.

Oltre all’ironia, il messaggio è chiaro: la scelta dell’intervallo di credibilità deve riflettere **una rappresentazione onesta dell’incertezza**, piuttosto che un’adesione meccanica a convenzioni statistiche.

In sintesi, l’uso dei prior consente di:

* incorporare conoscenze pregresse nel modello,
* rendere l’inferenza più robusta quando i dati sono scarsi,
* esplicitare le proprie ipotesi, invece di nasconderle dietro un’apparente “oggettività”.

Nel modello bayesiano, ogni assunzione è esplicita, e i risultati sono interpretati come **distribuzioni di probabilità sui parametri**, non come stime puntuali affette da errore. Questo rende l’approccio particolarmente adatto in contesti in cui la **trasparenza dell’incertezza** è essenziale.

## Funzioni *bayesplot*

Il pacchetto **`bayesplot`** mette a disposizione un insieme di funzioni molto utili per **visualizzare** la distribuzione a posteriori di uno o più parametri e per **verificare** la bontà di adattamento del modello ai dati.

### Traceplot

Un **traceplot** consente di verificare la convergenza delle catene MCMC e di controllare l’autocorrelazione dei campioni a posteriori. Nel seguente esempio, si mostrano le tracce (i valori campionati lungo le iterazioni) per i parametri “Intercept” e “sigma”:

```{r}
mcmc_trace(
  fm3, 
  pars = c("Intercept", "sigma"),
  facet_args = list(nrow = 2)
)
```

- L’asse orizzontale indica il numero di iterazione MCMC,  
- L’asse verticale mostra il valore assunto dal parametro in quella iterazione,  
- Avere catene che si mescolano bene e appaiono “stazionarie” (senza trend crescenti o calanti) è un buon segnale di convergenza.

### Distribuzione a posteriori di un singolo parametro

Se vogliamo visualizzare la **distribuzione a posteriori** di un singolo parametro (ad esempio l’intercetta, qui chiamata “b_Intercept” nel modello `brms`), possiamo usare:

```{r}
mcmc_areas(fm3, regex_pars = "b_Intercept", prob = 0.89)
```

- Viene mostrata la **densità a posteriori**, con un’area evidenziata corrispondente all’**89% di credibilità** (specificabile con `prob = 0.89` o un altro valore).  
- Se desideriamo un intervallo di credibilità al 95%, useremo `prob = 0.95`.

### Rappresentazione congiunta di due parametri

Per studiare la relazione tra due parametri (ad esempio “Intercept” e “sigma”):

```{r}
mcmc_scatter(fm3, pars = c("Intercept", "sigma"))
```

- Si ottiene un **diagramma di dispersione** dei campioni a posteriori sui due assi, uno per ciascun parametro, con eventuali isodensità che mostrano le aree più probabili nella distribuzione congiunta.

### Posterior Predictive Check

La funzione `pp_check()` è utilizzata per valutare se il modello è in grado di riprodurre i dati osservati:

```{r}
pp_check(fm3)
```

- Questa funzione genera un **confronto** tra la distribuzione dei dati reali (rappresentati, ad esempio, con una linea nera su un istogramma) e la distribuzione di diversi *dataset simulati* dal modello, sfruttando la **distribuzione a posteriori** dei parametri ($\alpha$, $\sigma$, ecc.).  
- Poiché il modello bayesiano è **generativo**, possiamo campionare nuovi dati “fittizi” a partire da ogni draw della posterior: in questo modo otteniamo molteplici dataset simulati, ognuno generato con un diverso valore di $\alpha$ e $\sigma$ estratto dalle distribuzioni posteriori.

Nel grafico prodotto da `pp_check()`, i dati osservati compaiono spesso come **linea continua nera**, mentre i dati simulati dal modello (ad esempio, 8 repliche di default) sono mostrati in **colori più chiari** o linee semitrasparenti. Se la distribuzione empirica si sovrappone bene a quelle generate, significa che il modello **spiega adeguatamente** i dati.

- Nel nostro caso, notiamo che le distribuzioni simulate risultano **molto simili** a quella osservata, indicando che la stima di $\alpha$ e $\sigma$ cattura in modo soddisfacente la variabilità dei dati.  
- Se invece avessimo osservato **discrepanze sistematiche** (ad esempio, dati reali con code più pesanti, oppure un picco in posizioni diverse rispetto alle distribuzioni simulate), ci saremmo insospettiti riguardo all’adeguatezza del modello. In situazioni del genere, conviene rivedere le assunzioni (e.g. normalità, varianza costante, eventuali covariate assenti, ecc.) prima di trarre conclusioni dai risultati a posteriori.

In sintesi, il pacchetto **`bayesplot`** fornisce strumenti fondamentali per:

1. **Valutare la convergenza** delle catene MCMC (*traceplot, autocorrelation plots*),  
2. **Esplorare** la distribuzione a posteriori dei parametri (*mcmc_areas, mcmc_density, mcmc_scatter, …*),  
3. **Verificare** la bontà del modello rispetto ai dati osservati mediante *posterior predictive checks* (*pp_check*).

Queste analisi grafiche forniscono informazioni cruciali sia sulla qualità del campionamento (e dunque sulla stabilità delle stime) sia sull’adeguatezza delle ipotesi modellistiche adottate.

## L’approccio Tradizionale

Prima dell’avvento dei metodi bayesiani e di altri approcci moderni, l’inferenza sulla **media** di una popolazione veniva spesso affrontata ricorrendo al **test t di Student**. 

### La statistica T di Student

Il test si basa sulla seguente statistica:

$$
T = \frac{\bar{X} - \mu_0}{s / \sqrt{n}},
$$

dove:

- $\bar{X}$ è la **media campionaria** di $n$ osservazioni,  
- $\mu_0$ è il **valore ipotizzato** dalla cosiddetta “ipotesi nulla” (solitamente $\mu_0 = 0$, ma può essere qualsiasi valore di riferimento),  
- $s$ è la **deviazione standard campionaria corretta** (ovvero stimatore di $\sigma$),  
- $n$ è la **dimensione del campione**.

Quando $\sigma$ (deviazione standard vera) è sconosciuta e sostituita da $s$, la statistica $\,T$ segue (in teoria) una distribuzione t di Student con $n - 1$ gradi di libertà:

$$
T \sim t_{(n-1)}.
$$

### Collegamento con la distribuzione Z

Se $\sigma$ fosse nota, useremmo la statistica:

$$
Z = \frac{\bar{X} - \mu}{\sigma / \sqrt{n}},
$$

la quale segue una **distribuzione Normale Standard** ($Z \sim \mathcal{N}(0,1)$). Quando invece $\sigma$ è sostituita da $s$, la distribuzione di questa statistica diventa una **t di Student** (che, per $n$ grande, si avvicina molto alla $\mathcal{N}(0,1)$).

### Intervallo di confidenza

Con il test t di Student, si ottiene anche il **tradizionale intervallo di confidenza** al 95% per $\mu$:

$$
\bar{X} \pm t_{0.975,\,n-1} \cdot \frac{s}{\sqrt{n}},
$$

dove $t_{0.975,\,n-1}$ è il quantile al 97.5% della distribuzione t con $n-1$ gradi di libertà (circa 2.0 se $n$ è sufficientemente grande, mentre 1.96 è il valore per la distribuzione normale standard).

#### Esempio in R

Nell’esempio riportato, se vogliamo costruire l’intervallo di confidenza al 95% manualmente, possiamo scrivere:

```{r}
mean(df$height) + 
  c(-1, 1) * qt(0.975, length(df$height) - 1) * (sd(df$height) / sqrt(length(df$height)))
```

oppure usare direttamente la funzione:

```{r}
t.test(df$height, mu = 0)
```

che restituisce sia il **valore della statistica T**, sia l’**intervallo di confidenza** e il **p-value** del test t (ipotizzando, in questo esempio, $\mu_0 = 0$ come ipotesi nulla). 

### Confronto con il modello di regressione a sola intercetta

Si noti che i risultati (media stimata e intervallo di confidenza) coincidono con quanto si otterrebbe usando una **regressione lineare** con sola intercetta (come `lm(height ~ 1, data=df)`) e richiedendo l’intervallo di confidenza con `confint()`. Sia il test $t$ di Student sia la regressione lineare semplice (senza covariate) condividono infatti le stesse assunzioni di base e forniscono risultati equivalenti per quanto riguarda l’inferenza sulla media.

## Riflessioni Conlusive

In questo capitolo abbiamo esaminato l'inferenza sulla media di una popolazione partendo da un semplice modello con sola intercetta, sia nell'ottica frequentista che in quella bayesiana. Utilizzando `lm()`, abbiamo ricavato la stima puntuale della media campionaria e il corrispondente intervallo di confidenza al 95%, interpretato come proprietà della procedura di stima. Con `brm()`, abbiamo ottenuto risultati numericamente simili, ma con una diversa interpretazione epistemologica: l'intervallo di credibilità rappresenta **il grado di incertezza a posteriori sulla media**, dato il modello e i dati osservati. Infine, abbiamo mostrato come introdurre informazioni a priori nel modello bayesiano, evidenziando come i risultati possano discostarsi da quelli frequentisti soprattutto in presenza di campioni piccoli o dati poco informativi. In sintesi, la modellazione bayesiana offre un quadro più flessibile e trasparente, sia nell’incorporare conoscenze pregresse sia nel rappresentare incertezza, rendendola particolarmente adatta a contesti psicologici dove le fonti di variabilità sono spesso molteplici e complesse.


::: {.callout-important title="Problemi" collapse="true"}

**Obiettivo:** Utilizzare i dati dello studio di @tarrats2025efficacy per replicare i risultati riportati nella Figura 2 , applicando sia l’approccio frequentista che il framework bayesiano. Calcolare inoltre la grandezza dell’effetto nel contesto bayesiano (Cohen’s $d$) e generare un grafico che visualizzi la distribuzione a posteriori della grandezza dell’effetto ottenuta. 

:::

::: {.callout-tip title="Soluzioni" collapse="true"}

```{r}
#| message: false
#| warning: false
#| output: false
#| 
library(tidyverse)
library(readxl)
library(brms)
library(posterior)
library(bayestestR)

df <- read_excel(
  here::here(
    "data",
    "Tarrats-Pons.xlsx"
  ),
  sheet = 3
)

df |>
  group_by(Sample) |>
  summarize(
    avg = mean(`CESS-D`),
    n = n()
  )

df_wide <- df %>%
  select(IdentificationNumber, Sample, CESS_D = `CESS-D`) %>%
  pivot_wider(
    names_from = Sample, # da POST/PRE
    values_from = CESS_D, # i valori da mettere nelle colonne
    names_prefix = "CESSD_" # opzionale, per nominare CESSD_POST, CESSD_PRE
  )

# Controlla il risultato
head(df_wide)

df_wide$diff <- df_wide$CESSD_PRE - df_wide$CESSD_POST

hist(df_wide$diff)

t.test(df_wide$diff)

# t-test sulle differenze
res <- t.test(df_wide$diff)

# Numero di soggetti
n <- length(df_wide$diff)

# Calcolo di Cohen's d
d_t <- as.numeric(res$statistic) / sqrt(n)

# Mostro risultato
d_t

fm1 <- brm(
  formula = diff ~ 1, # Modello con sola intercetta (mu)
  data = df_wide,
  family = gaussian(), # Distribuzione Normale
  prior = c(
    brms::prior(normal(0, 10), class = "Intercept"), # Prior su mu
    brms::prior(normal(0, 10), class = "sigma") # Prior su sigma
  ),
  chains = 4,
  iter = 2000,
  seed = 1234,
  backend = "cmdstanr"
)
summary(fm1)
pp_check(fm1)

fm2 <- brm(
  formula = diff ~ 1, # Modello con sola intercetta (mu)
  data = df_wide,
  family = student(), # Distribuzione Normale
  prior = c(
    brms::prior(normal(0, 10), class = "Intercept"), # Prior su mu
    brms::prior(normal(0, 10), class = "sigma") # Prior su sigma
  ),
  chains = 4,
  iter = 2000,
  seed = 1234,
  backend = "cmdstanr"
)
summary(fm2)
pp_check(fm2)

post_samples <- posterior::as_draws_df(fm1)
head(post_samples)

post_samples$effect_size <- post_samples$b_Intercept / post_samples$sigma

# Calcolo diretto delle statistiche dell'effect size
mean_effect_size <- mean(post_samples$effect_size)
sd_effect_size <- sd(post_samples$effect_size)
ci_effect_size <- quantile(post_samples$effect_size, probs = c(0.025, 0.975))

# Stampa dei risultati
cat("=== Statistiche dell'Effect Size Bayesiano ===\n")
cat("Effect size medio:", round(mean_effect_size, 2), "\n")
cat("SD dell'effect size:", round(sd_effect_size, 2), "\n")
cat(
  "Intervallo di credibilità al 95%:",
  round(ci_effect_size[1], 2),
  "-",
  round(ci_effect_size[2], 2),
  "\n\n"
)

# Interpretazione dell'effect size secondo le convenzioni di Cohen
if (abs(mean_effect_size) < 0.2) {
  interpretation <- "piccolo"
} else if (abs(mean_effect_size) < 0.5) {
  interpretation <- "medio-piccolo"
} else if (abs(mean_effect_size) < 0.8) {
  interpretation <- "medio"
} else {
  interpretation <- "grande"
}
cat("Interpretazione (Cohen):", interpretation, "\n")

# Calcola la probabilità che l'effect size sia maggiore di zero
prob_positive <- mean(post_samples$effect_size > 0)
cat(
  "Probabilità che l'effect size sia positivo:",
  round(prob_positive * 100, 2),
  "%\n"
)

# Se necessario, calcola probabilità per altre soglie
prob_medium <- mean(post_samples$effect_size > 0.5)
cat(
  "Probabilità che l'effect size sia > 0.5 (medio):",
  round(prob_medium * 100, 2),
  "%\n"
)
prob_large <- mean(post_samples$effect_size > 0.8)
cat(
  "Probabilità che l'effect size sia > 0.8 (grande):",
  round(prob_large * 100, 2),
  "%\n"
)

# Visualizzazione della distribuzione posteriore dell'effect size
# (Per eseguire questo blocco, devi avere ggplot2 installato e caricato)
# library(ggplot2)
ggplot(post_samples, aes(x = effect_size)) +
  geom_density(fill = "skyblue", alpha = 0.5) +
  geom_vline(
    xintercept = mean_effect_size,
    color = "red",
    linetype = "dashed"
  ) +
  geom_vline(
    xintercept = ci_effect_size[1],
    color = "darkblue",
    linetype = "dotted"
  ) +
  geom_vline(
    xintercept = ci_effect_size[2],
    color = "darkblue",
    linetype = "dotted"
  ) +
  labs(
    title = "Distribuzione posteriore dell'Effect Size",
    x = "Effect Size (Cohen's d)",
    y = "Densità"
  ) +
  theme_minimal()
```
:::

## Informazioni sull'Ambiente di Sviluppo {.unnumbered} 

```{r}
sessionInfo()
```

## Bibliografia {.unnumbered}
