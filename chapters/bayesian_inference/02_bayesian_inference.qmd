---
execute:
  freeze: auto
---

# Inferenza bayesiana {#sec-bayes-inference}


::: callout-important
## In questo capitolo approfondirai i seguenti concetti fondamentali:  

- distribuzione marginale;
- approccio analitico e numerico per determinare la distribuzione a posteriori;
- linguaggi di programmazione probabilistici;
- inferenza predittiva.
::: 

::: callout-tip
## Prerequisiti

- Leggere il capitolo *Bayes' Rule* del testo di @Johnson2022bayesrules.
:::

::: callout-caution
## Preparazione del Notebook

```{r}
here::here("code", "_common.R") |> 
  source()
```
:::


## Introduzione

Questo capitolo approfondisce i concetti introdotti nel precedente, presentando l'aggiornamento bayesiano in modo formale e dettagliato.

### Il Paradigma dell'Inferenza Bayesiana

Al centro dell'inferenza bayesiana vi è l'idea che la probabilità misuri il grado di certezza soggettiva riguardo a un'ipotesi o alla plausibilità di un valore per un parametro sconosciuto. L'inferenza bayesiana si basa sul concetto di aggiornamento continuo: partendo da credenze iniziali (**priori**), queste vengono riviste alla luce di nuove informazioni fornite dai dati, producendo credenze aggiornate (**posteriori**).

Per esempio, consideriamo il caso di una moneta. Dopo averla lanciata 10 volte osserviamo 8 testa ($y = 8$) e ci chiediamo se la moneta sia equilibrata ($p = 0.5$). Per rispondere, definiamo un **modello generativo dei dati**, il più semplice dei quali è il modello binomiale, caratterizzato dal parametro $p$, la probabilità di ottenere testa. Questo parametro è l'oggetto della nostra inferenza.

### Approccio Classico: Massima Verosimiglianza

Un metodo classico è la **massima verosimiglianza**, che stima $p$ come rapporto tra successi e tentativi: $\hat{p} = y/N = 0.8$. Tuttavia, questa stima puntuale non fornisce informazioni sull'incertezza associata a $p$ o sulla plausibilità di altri valori vicini.

### Approccio Bayesiano: Prior e Posteriori

L'approccio bayesiano supera questa limitazione introducendo una **distribuzione a priori** per $p$, che riflette le credenze iniziali. Una distribuzione uniforme su $[0, 1]$ considera tutti i valori di $p$ ugualmente plausibili, mentre una distribuzione centrata su $0.5$ indica una convinzione iniziale che la moneta sia equilibrata.

Dopo aver osservato i dati ($y = 8$, $N = 10$), combiniamo il prior con la **funzione di verosimiglianza** (che esprime la probabilità dei dati per ciascun valore ipotizzato di $p$) tramite il **teorema di Bayes**:

$$
p(\theta \mid y) \propto p(y \mid \theta)p(\theta),
$$
  
dove:
  
- $p(\theta)$ è la distribuzione **a priori**.
- $p(y \mid \theta)$ è la **verosimiglianza**.
- $p(\theta \mid y)$ è la distribuzione **a posteriori**.

Il teorema di Bayes produce una **distribuzione a posteriori**, che integra le informazioni iniziali con quelle dei dati osservati, fornendo:

1. Una stima plausibile di $p$ (ad esempio, mediana o moda della distribuzione a posteriori).
2. Una misura dell'incertezza associata a $p$ (ad esempio, varianza o intervalli di credibilità).

### Vantaggi dell'Inferenza Bayesiana

L'inferenza bayesiana non si limita a stime puntuali ma descrive lo stato attuale di conoscenza attraverso una distribuzione completa. Questo approccio è particolarmente utile in contesti con dati scarsi o elevata incertezza, frequenti in psicologia.

## Implementazione e Calcolo 

Per calcolare la distribuzione a posteriori in un contesto di inferenza bayesiana, si possono adottare due approcci principali.

### Approccio Analitico (o Coniugato)

Questo metodo è applicabile quando la distribuzione a priori appartiene alla stessa famiglia di distribuzioni della funzione di verosimiglianza, definendo una *relazione coniugata*. In questi casi:  

- La distribuzione a posteriori può essere calcolata esattamente attraverso formule matematiche, senza necessità di approssimazioni.  
- L'approccio è computazionalmente efficiente, poiché evita algoritmi iterativi complessi.  

**Limitazioni:**  

- La coniugazione è possibile solo per modelli semplici e specifici, limitando l'uso di questo approccio ai casi in cui le assunzioni sono realistiche.  
- Nei dati reali, la necessità di flessibilità spesso rende queste assunzioni troppo restrittive.


### Approccio Numerico  

Quando il calcolo analitico non è possibile, ad esempio per modelli complessi o distribuzioni non coniugate, si ricorre a metodi numerici per stimare la distribuzione a posteriori in modo approssimato ma accurato.

#### Metodi Basati su Catene di Markov Monte Carlo

Gli algoritmi MCMC campionano iterativamente dalla distribuzione a posteriori, garantendo la convergenza a quest'ultima con un numero sufficiente di iterazioni. Tra i metodi più diffusi: 

- **Metropolis-Hastings:** Un algoritmo generale adatto a una vasta gamma di distribuzioni.  
- **Gibbs Sampling:** Una variante particolarmente efficiente quando le distribuzioni condizionali sono note, anche se la distribuzione congiunta è difficile da campionare direttamente.

#### Altri Metodi Numerici  

Oltre alle MCMC, si utilizzano anche approcci alternativi:  

- **Variational Bayes:**  
   - Cerca una distribuzione $q(z)$ che approssima $p(z \mid x)$ minimizzando una misura di divergenza, come la divergenza di Kullback-Leibler.  
   - Questo metodo trasforma il problema di inferenza in un problema di ottimizzazione, risultando spesso più veloce delle MCMC, ma talvolta meno accurato.  
- **Approssimazione di Laplace:**  
   - Approssima la distribuzione a posteriori con una normale centrata sul valore MAP (massimo a posteriori) e con una matrice di covarianza basata sull’inverso dell’Hessiano negativo al MAP.  
   - È efficiente, ma l’accuratezza è limitata nelle regioni lontane dal MAP o per distribuzioni non gaussiane.

### Vantaggi e Svantaggi degli Approcci Numerici

**Vantaggi:**  

- **Versatilità:** Applicabili a una vasta gamma di modelli e distribuzioni, anche molto complessi.  
- **Flessibilità:** Consentono di incorporare informazioni a priori articolate.  

**Svantaggi:**

- **Costo Computazionale:** Modelli complessi o grandi dataset richiedono risorse computazionali elevate.  
- **Tuning degli Algoritmi:** Parametri come la proposta iniziale nelle MCMC devono essere scelti attentamente per garantire efficienza e convergenza.  

In sintesi

- l’approccio analitico è ideale per semplicità ed efficienza ma limitato a casi specifici; 
- l’approccio numerico, pur richiedendo maggiore attenzione e risorse, offre una soluzione generale e flessibile per affrontare modelli realistici.  

La scelta dell’approccio dipende dalla complessità del modello e dalla natura dei dati.


## Programmazione Probabilistica

I linguaggi di programmazione probabilistica (PPL) facilitando l'uso di tecniche di approssimazione numerica per stimare le distribuzioni posteriori. Grazie ai PPL, la modellizzazione probabilistica diventa più accessibile, riducendo le barriere tecniche e computazionali. Questi strumenti consentono di definire modelli in modo dichiarativo, descrivendo le relazioni tra le variabili in termini probabilistici senza doversi occupare dei dettagli algoritmici sottostanti. In altre parole, i PPL permettono ai ricercatori di concentrarsi sull'espressione del modello, lasciando ai linguaggi il compito di gestire l'implementazione computazionale.

Tra i PPL più utilizzati troviamo:

- **Stan**: Uno dei linguaggi più popolari, noto per la sua efficienza e flessibilità.
- **PyMC**: Molto utilizzato nell'ecosistema Python, offre un'interfaccia user-friendly per la modellazione bayesiana.
- **TensorFlow**: Un framework che combina un approccio probabilistico con le reti neurali.

### Come Funzionano i PPL?

I linguaggi di programmazione probabilistica richiedono semplicemente la descrizione del modello probabilistico. Successivamente, utilizzano algoritmi di inferenza, come le catene di Markov Monte Carlo (MCMC) o l'inferenza variazionale, per stimare la distribuzione posteriore delle variabili di interesse. Ciò consente ai ricercatori di ottenere stime delle variabili sconosciute e di valutare l'incertezza associata.

In conclusione, i linguaggi di programmazione probabilistica hanno trasformato il modo in cui affrontiamo l'inferenza bayesiana, rendendola più accessibile e potente. Grazie alla loro semplicità d'uso e alla potenza computazionale, i PPL hanno reso l'inferenza bayesiana uno strumento sempre più diffuso in molte discipline, inclusa la psicologia. Questo approccio facilita la modellazione di fenomeni complessi e l'analisi rigorosa di dati, offrendo un metodo efficace per rispondere a domande di ricerca psicologica in modo trasparente e accurato.


## Notazione

In seguito, utilizzeremo $y$ per rappresentare i dati osservati e $\theta$ per indicare i parametri sconosciuti di un modello statistico. Entrambi, $y$ e $\theta$, saranno trattati come variabili casuali. Utilizzeremo $x$ per denotare le quantità note, come i predittori di un modello lineare.

È comune scrivere modelli statistici utilizzando la seguente notazione:

$$
\begin{aligned}
y & \sim \mathrm{normal}(\mu, \sigma) \\
\mu & \sim \mathrm{normal}(0, 10) \\
\sigma & \sim \mathrm{normal}^+(\sigma \mid  0, 1),
\end{aligned}
$$

dove il simbolo $\sim$ è chiamato *tilde* (`\sim` in LaTeX). 

In generale, possiamo leggere $\sim$ come *"è distribuito come"*, e questa notazione è usata come una scorciatoia per definire distribuzioni. L'esempio sopra può essere scritto anche come:

$$
\begin{aligned}
   p(y \mid \mu, \sigma) & = \mathrm{normal}(y \mid  \mu, \sigma)\\
   p(\mu) & = \mathrm{normal}(\mu \mid 0, 10)\\
   p(\sigma) & = \mathrm{normal}^+(\sigma \mid  0, 1).
\end{aligned}
$$

## Riflessioni Conclusive

Al cuore della ricerca scientifica c'è una domanda del tipo: "dimmi qualcosa sulla variabile $\theta$ dato che ho osservato i dati $D$ e ho una certa conoscenza del meccanismo sottostante che genera i dati". La regola di Bayes fornisce la seguente risposta:

$$
p(\theta \mid D) = \frac{p(D \mid\theta) p(\theta)}{p(D)} = \frac{p(D \mid \theta) p(\theta)}{\int_\theta p(D \mid\theta) p(\theta) d\theta}.
$$

Questa equazione mostra come, partendo da un modello generativo $p(D \mid\theta)$ dei dati osservati e abbinato a una credenza a priori $p(\theta)$ su quali valori della variabile $\theta$ siano plausibili, possiamo inferire la distribuzione a posteriori $p(\theta \mid D)$ della variabile alla luce dei dati osservati.

La stima MAP (Massimo A Posteriori), che corrisponde al valore di $\theta$ che massimizza la distribuzione a posteriori, rappresenta una stima puntuale del parametro:

$$
\theta^* = \arg \max_\theta p(\theta \mid D).
$$

Nel caso di un prior non informativo (piatto), la stima MAP coincide con la stima di massima verosimiglianza, ovvero il valore di $\theta$ che massimizza la probabilità che il modello generi i dati osservati.


## Informazioni sull'Ambiente di Sviluppo {.unnumbered} 

```{r}
sessionInfo()
```

## Bibliografia {.unnumbered}

