# Pensare ad una proporzione in termini soggettivi {#sec-bayesian-inference-proportion}

::: callout-note
## In questo capitolo imparerai a

- applicare l'aggiornamento bayesiano per affinare credenze;
- rappresentare distribuzioni a priori (discrete e continue);
- calcolare la verosimiglianza e aggiornare la distribuzione a priori;
- derivare e interpretare la distribuzione a posteriori;
- usare il metodo a griglia per approssimare la distribuzione a posteriori;
- applicare il modello binomiale per stimare probabilità e incertezze;
- calcolare medie, mode e intervalli di credibilità;
- utilizzare la distribuzione Beta come prior continuo.
:::

::: callout-tip
## Prerequisiti

- Leggere il settimo capitolo del testo di @albert_2019prob.
:::

::: callout-important
## Preparazione del Notebook

```{r}
here::here("code", "_common.R") |> 
  source()

# Load packages
if (!requireNamespace("pacman")) install.packages("pacman")
pacman::p_load(HDInterval)
```
:::

## Introduzione 

L’inferenza bayesiana offre un quadro formale per aggiornare le nostre convinzioni riguardo a un parametro incognito, come la probabilità $\theta$ di un evento, alla luce di nuove osservazioni. Questo approccio è basato sul teorema di Bayes, che combina in modo coerente le conoscenze iniziali—espresse attraverso una distribuzione a priori—con l’evidenza fornita dai dati, sintetizzata dalla funzione di verosimiglianza. Il risultato è una distribuzione a posteriori, che rappresenta le nostre credenze rivedute dopo aver considerato sia l’ipotesi iniziale sia i dati osservati.  

L’inferenza bayesiana si distingue per la sua flessibilità nel trattare l’incertezza: invece di fornire stime puntuali, lavora con distribuzioni di probabilità, permettendo di quantificare in modo esplicito la fiducia associata a ciascun valore possibile del parametro. Tale caratteristica la rende particolarmente utile in contesti in cui le informazioni sono incomplete o soggette a revisione, come spesso accade nella ricerca psicologica.  

In questo capitolo esploreremo l'inferenza bayesiana attraverso il modello binomiale, particolarmente adatto per analizzare dati dicotomici. Inizieremo considerando un semplice caso con distribuzione a priori discreta, dove il parametro $\theta$ (probabilità di successo) può assumere solo valori predefiniti. Questo approccio ci permetterà di osservare come le nostre credenze su $\theta$ si modifichino gradualmente con l'arrivo di nuovi dati. Successivamente, estenderemo il discorso al caso più generale delle distribuzioni a priori continue, che meglio si adattano alla modellizzazione di problemi reali. L’obiettivo è fornire una comprensione intuitiva ma rigorosa del processo dell'aggiornamento bayesiano, evidenziandone sia la logica sottostante sia le potenzialità applicative. 

## Verosimiglianza Binomiale 

La distribuzione binomiale descrive il numero di successi $y$ in $n$ prove indipendenti, ciascuna con probabilità di successo $\theta$. La sua funzione di verosimiglianza è:

$$ 
p(y \mid \theta) = \text{Bin}(y \mid n, \theta) = \binom{n}{y} \theta^y (1 - \theta)^{n-y}, 
$$

dove $\theta$ rappresenta la probabilità di successo per singola prova, $y$ è il numero osservato di successi e $n$ è il numero totale di prove (fissato a priori).

## Esempio: Go/No-Go Task

Nel classico Go/No-Go task [@shiffrin1977controlled], i partecipanti rispondono a stimoli ("Go") ma devono inibire la risposta per uno specifico stimolo bersaglio ("No-Go"). Ogni prova è un evento bernoulliano: successo (risposta corretta) o fallimento (errore). L'obiettivo è studiare la capacità di inibizione, analizzando la proporzione di risposte corrette nelle prove No-Go.

Prendiamo come esempio i risultati di un partecipante in un compito di inibizione della risposta. In 9 prove No-Go consecutive, il partecipante ha mostrato il seguente pattern di risposte: 1, 0, 1, 1, 1, 0, 1, 0, 1, dove 1 indica una corretta inibizione della risposta e 0 rappresenta un errore di inibizione. Complessivamente, si osservano 6 risposte corrette su 9 prove.

In questo contesto sperimentale, possiamo modellare la prestazione del partecipante utilizzando una distribuzione binomiale. Ogni prova costituisce un'osservazione indipendente che segue una distribuzione di Bernoulli con parametro $\theta$, dove $\theta$ rappresenta la probabilità sottostante di inibizione corretta. La variabile $\theta$ cattura quindi l'abilità inibitoria del partecipante nel compito No-Go.

Il modello binomiale ci permette di stimare $\theta$ a partire dai dati osservati e di quantificare l'incertezza associata a questa stima. In particolare, la verosimiglianza dei dati osservati (6 successi su 9 prove) può essere espressa attraverso la funzione di massa di probabilità binomiale, che assegna una probabilità a ogni possibile valore di $\theta$ compreso tra 0 e 1.

L'analisi bayesiana di questo problema prevede la combinazione di queste informazioni con una distribuzione a priori che rappresenta le nostre credenze iniziali sull'abilità inibitoria del partecipante. Questo approccio ci consentirà di ottenere una distribuzione a posteriori per $\theta$ che sintetizza sia le informazioni a priori sia l'evidenza fornita dai dati osservati.

## Metodo Basato su Griglia per l'Aggiornamento Bayesiano

Il metodo basato su griglia rappresenta un approccio computazionalmente semplice per ottenere la distribuzione a posteriori quando non è disponibile una soluzione analitica diretta. Questo metodo risulta particolarmente utile per illustrare concretamente il processo di aggiornamento bayesiano.

Il procedimento inizia definendo un intervallo plausibile per il parametro $\theta$, tipicamente compreso tra 0 e 1 nel caso di probabilità. All'interno di questo intervallo, viene costruita una griglia costituita da un insieme finito di valori equidistanti (ad esempio, $\theta$ = 0, 0.01, 0.02, ..., 1). Per ciascun valore $\theta$ nella griglia, si calcola il prodotto della verosimiglianza dei dati osservati (data $\theta$) e della densità a priori corrispondente.

I valori così ottenuti vengono poi normalizzati dividendo ciascuno di essi per la somma totale dei prodotti calcolati su tutta la griglia. Questa operazione garantisce che l'area sotto la curva risultante sia pari a 1, trasformando così i valori in una vera distribuzione di probabilità. La distribuzione risultante rappresenta un'approssimazione discreta della vera distribuzione a posteriori continua. 

Sebbene approssimato, questo metodo offre diversi vantaggi didattici: mantiene trasparente ogni fase del calcolo, permette di visualizzare direttamente l'effetto dell'aggiornamento bayesiano e non richiede conoscenze avanzate di metodi computazionali. La precisione dell'approssimazione può essere migliorata aumentando la densità dei punti nella griglia, a scapito però di un maggior costo computazionale.

Nel caso del nostro esempio con 6 successi su 9 prove, applicheremo questo metodo utilizzando come a priori una distribuzione uniforme, dimostrando come l'osservazione dei dati modifichi la nostra comprensione della probabilità $\theta$ di corretta inibizione nel compito No-Go.

## Aggiornamento Bayesiano con Priori Discreta  

### Costruzione della Priori  

Nel caso del compito Go/No-Go, il parametro θ rappresenta la probabilità che un partecipante inibisca correttamente una risposta. In assenza di informazioni preliminari specifiche, potremmo inizialmente considerare tutti i valori di $\theta$ ugualmente plausibili.  Per implementare concretamente questo approccio:  

- definiamo un insieme discreto di valori possibili per $\theta$: {0, 0.1, 0.2, ..., 1};
- assegniamo a ciascun valore la stessa probabilità a priori: $p(\theta) = 1/11 \approx 0.09$.  

Questa scelta rappresenta uno stato di massima incertezza iniziale, dove nessun valore di $\theta$ risulta a priori più plausibile di altri.  

### Aggiornamento con i Dati  

Supponiamo di osservare 6 inibizioni corrette su 9 prove ($y$=6, $n$=9). Per ogni valore $\theta$ nella griglia:  

1. calcoliamo la verosimiglianza binomiale:  
   $p(y \mid \theta) = \theta^6(1-\theta)^3$;

2. moltiplichiamo per la probabilità a priori (0.09 in questo caso);  

3. normalizziamo dividendo per la somma totale di tutti i prodotti ottenuti. 

Il risultato è una distribuzione a posteriori discreta che mostra come l'osservazione di 6 successi su 9 prove modifica le nostre credenze iniziali su $\theta$. I valori più vicini a 6/9 $\approx$ 0.67 riceveranno maggiore probabilità a posteriori.  

### Interpretazione  

Questo processo dimostra come l'osservazione dei dati modifichi le nostre credenze iniziali. La distribuzione a posteriori si sposta gradualmente dalla configurazione iniziale uniforme verso una forma più informata, concentrandosi attorno ai valori di $\theta$ più compatibili con i dati osservati.  

In particolare, dopo aver osservato 6 successi su 9 prove, valori come $\theta$ = 0.6 o 0.7 diventano significativamente più plausibili rispetto a valori estremi come θ = 0.2 o 0.9. Questo riflette il modo in cui l'evidenza empirica aggiorna le nostre aspettative iniziali.  

L'uso di una griglia discreta fornisce un'approssimazione della vera distribuzione continua, dove la precisione dell'approssimazione migliora quanto più fitta è la griglia di punti considerata. Questo approccio permette di visualizzare in modo concreto il meccanismo di aggiornamento bayesiano, mostrando come a ogni nuova osservazione corrisponda una revisione della nostra conoscenza del parametro $\theta$.

### Implementazione in R

#### Definizione dei parametri

Iniziamo creando una griglia discreta per il parametro θ, che rappresenta la probabilità di successo nel nostro compito Go/No-Go:

```{r}
theta <- seq(0, 1, by = 0.1)  # Griglia di valori da 0 a 1 con passo 0.1
```

#### Distribuzione a priori uniforme

Quando non abbiamo informazioni preliminari, usiamo una distribuzione uniforme:

```{r}
priori_unif <- rep(1 / length(theta), length(theta))  # Probabilità uniformi
```

Visualizziamo questa distribuzione:

```{r}
ggplot(data.frame(theta, prob = priori_unif), aes(x = theta, y = prob)) +
  geom_col(width = 0.08) +
  labs(title = "Distribuzione a Priori Uniforme",
       x = expression(theta),
       y = "Densità di probabilità")
```

#### Distribuzione a priori informativa

Se invece riteniamo più probabili valori centrali di $\theta$:

```{r}
priori_inf <- c(
  0, 0.05, 0.05, 0.05, 0.175, 0.175, 0.175, 0.175, 0.05, 0.05, 0.05
)
```

Visualizzazione:

```{r}
ggplot(data.frame(theta, prob = priori_inf), aes(x = theta, y = prob)) +
  geom_col(width = 0.08) +
  labs(title = "Distribuzione a Priori Informativa",
       x = expression(theta),
       y = "Densità di probabilità")
```

#### Calcolo della verosimiglianza

Per i nostri dati (6 successi su 9 prove):

```{r}
verosimiglianza <- dbinom(6, size = 9, prob = theta)
```

Visualizzazione:

```{r}
ggplot(data.frame(theta, prob = verosimiglianza), aes(x = theta, y = prob)) +
  geom_col(width = 0.08) +
  labs(title = "Funzione di Verosimiglianza",
       x = expression(theta),
       y = "L(θ|dati)")
```

#### Calcolo della distribuzione a posteriori

Combiniamo priori e verosimiglianza:

```{r}
posteriori_non_norm <- priori_inf * verosimiglianza
posteriori <- posteriori_non_norm / sum(posteriori_non_norm)  # Normalizzazione
```

Visualizzazione:

```{r}
ggplot(data.frame(theta, prob = posteriori), aes(x = theta, y = prob)) +
  geom_col(width = 0.08) +
  labs(title = "Distribuzione a Posteriori",
       x = expression(theta),
       y = "P(θ|dati)")
```

#### Statistiche descrittive

Calcoliamo alcune quantità riassuntive:

```{r}
media_post <- sum(theta * posteriori)
var_post <- sum(theta^2 * posteriori) - media_post^2
moda_post <- theta[which.max(posteriori)]

cat("Media a posteriori:", round(media_post, 3),
    "\nVarianza a posteriori:", round(var_post, 3),
    "\nModa a posteriori:", moda_post)
```

L'implementazione illustra tre caratteristiche essenziali dell'inferenza bayesiana. La funzione di verosimiglianza attribuisce maggiore densità di probabilità a valori di $\theta$ compresi tra 0.6 e 0.7, in accordo con l'evidenza empirica dei 6 successi osservati su 9 prove. La distribuzione a priori contribuisce in modo determinante alla configurazione della distribuzione a posteriori risultante. Il processo di aggiornamento bayesiano integra in modo rigoroso queste due fonti informative mediante l'applicazione  del teorema di Bayes.

La metodologia si distingue per la sua flessibilità applicativa, permettendo di adeguarsi a diverse esigenze analitiche. È possibile modificare facilmente i parametri osservati, come il numero di successi e prove registrate, per adattare l'analisi a diversi set di dati. La distribuzione a priori può essere calibrata in base alle specifiche ipotesi teoriche del ricercatore, offrendo la possibilità di incorporare conoscenze pregresse di varia natura. Un ulteriore vantaggio operativo consiste nella possibilità di aumentare la precisione delle stime semplicemente aggiungendo punti alla griglia di valori considerati per $\theta$, ottenendo così un'approssimazione più fedele della distribuzione continua. Questa combinazione di adattabilità e precisione rende l'approccio particolarmente efficace sia nelle fasi iniziali di analisi esplorativa, dove è necessario testare rapidamente diverse configurazioni, sia in contesti sperimentali controllati che richiedono modelli più sofisticati. 

## Aggiornamento Bayesiano con una Distribuzione a Priori Continua

Passiamo ora all'aggiornamento bayesiano utilizzando una distribuzione a priori continua, in particolare la distribuzione Beta. Questo approccio è particolarmente utile poiché consente di rappresentare $\theta$ come una variabile continua definita nell'intervallo [0, 1].

### Definizione della Distribuzione Beta

Iniziamo con una distribuzione Beta simmetrica, Beta(2, 2), e calcoliamo la sua densità di probabilità su un intervallo continuo di valori $\theta$.

```{r}
# Parametri della distribuzione Beta
alpha <- 2
beta <- 2

# Valori di theta
theta <- seq(0, 1, length.out = 1000)

# Densità di probabilità della distribuzione Beta
pdf <- dbeta(theta, alpha, beta)

# Grafico della distribuzione Beta
data.frame(theta, pdf) |>
  ggplot(
    aes(x = theta, y = pdf)
  ) +
  geom_line(linewidth = 1.2) +
  labs(
    title = "Funzione di Densità di Probabilità Beta(2, 2)",
    x = expression(theta),
    y = "Densità"
  )
```

### Distribuzione a Priori Non Simmetrica

Consideriamo una distribuzione a priori non simmetrica, Beta(2, 5), per rappresentare credenze che privilegiano valori bassi di $\theta$.

```{r}
# Parametri della distribuzione Beta non simmetrica
alpha <- 2
beta <- 5

# Valori di theta e densità di probabilità
theta <- seq(0, 1, length.out = 100) # Valori di theta
pdf <- dbeta(theta, alpha, beta) # Densità di probabilità Beta(2, 5)

# Creazione del grafico
data.frame(theta, pdf) |>
  ggplot(aes(x = theta, y = pdf)) +
  geom_line(linewidth = 1.2) +
  labs(
    title = "Funzione di Densità di Probabilità Beta(2, 5)",
    x = expression(theta),
    y = "Densità"
  )
```

### Verosimiglianza

Consideriamo un esperimento con 9 prove e 6 successi, modellato con una distribuzione binomiale. Calcoliamo la funzione di verosimiglianza normalizzata.

```{r}
# Parametri dell'esperimento
n <- 9
k <- 6

# Calcolo della verosimiglianza
likelihood <- dbinom(k, size = n, prob = theta)
likelihood <- likelihood / sum(likelihood) # Normalizzazione

# Grafico della verosimiglianza
data.frame(theta, likelihood) |>
  ggplot(
    aes(x = theta, y = likelihood)
  ) +
  geom_line(linewidth = 1.2) +
  labs(
    title = "Funzione di Verosimiglianza",
    x = expression(theta),
    y = "Densità"
  )
```

### Distribuzione a Posteriori

La distribuzione a posteriori si ottiene moltiplicando la distribuzione a priori per la verosimiglianza e normalizzando il risultato.

```{r}
# Calcolo della distribuzione a priori Beta(2, 5)
prior <- dbeta(theta, shape1 = 2, shape2 = 5)
prior <- prior / sum(prior)

# Calcolo della distribuzione a posteriori
posterior <- (prior * likelihood) / sum(prior * likelihood)
```

```{r}
# Uniamo tutti i dati in un dataframe per ggplot2
dat <- tibble(
  theta,
  prior,
  likelihood,
  posterior
)

# Preparazione dei dati per il plot
long_data <- dat |>
  pivot_longer(
    cols = c(prior, likelihood, posterior),
    names_to = "distribution",
    values_to = "density"
  )

# Grafico
long_data |>
  ggplot(aes(x = theta, y = density, color = distribution)) +
  geom_line(size = 1.2) +
  labs(
    title = "Distribuzioni Bayesiane",
    x = expression(theta),
    y = "Densità"
  ) +
  theme(legend.position = "bottom")
```

### Quantità a Posteriori

Calcoliamo alcune quantità riassuntive dalla distribuzione a posteriori.

- **Media a Posteriori**

```{r}
posterior_mean <- sum(theta * posterior)
posterior_mean
```

- **Deviazione Standard a Posteriori**

```{r}
posterior_sd <- sqrt(sum((theta^2) * posterior) - posterior_mean^2)
posterior_sd
```

- **Moda a Posteriori**

```{r}
posterior_mode <- theta[which.max(posterior)]
posterior_mode
```

### Campionamento dalla Distribuzione a Posteriori

Possiamo generare campioni casuali dalla distribuzione a posteriori per effettuare inferenze.

```{r}
# Campionamento casuale basato sul posterior
set.seed(123)
samples <- sample(theta, size = 10000, prob = posterior, replace = TRUE)

# Creazione dell'istogramma e della curva di densità
data_frame_samples <- data.frame(samples)

# Grafico con ggplot
data_frame_samples |>
  ggplot(aes(x = samples)) +
  geom_histogram(
    aes(y = after_stat(density)),
    bins = 20,
    fill = "gray", color = "black"
  ) +
  geom_density(color = "black", size = 1.2) +
  labs(
    title = "Distribuzione dei Campioni dalla Posteriori",
    x = expression(theta),
    y = "Densità"
  )
```

#### Intervalli di Credibilità

Calcoliamo l'intervallo di credibilità al 94%.

```{r}
credible_interval <- quantile(samples, probs = c(0.03, 0.97))
credible_interval
```

Se desideriamo calcolare l'intervallo di densità più alta (HPDI), possiamo utilizzare pacchetti aggiuntivi come `HDInterval`.

```{r}
# Calcolo HPDI (richiede il pacchetto HDInterval)
hdi(samples, credMass = 0.94)
```

In sintesi, questo approccio dimostra l'applicazione del metodo bayesiano con distribuzioni a priori continue, utilizzando sia formule analitiche che campionamento. I risultati mostrano come possiamo ottenere credenze aggiornate su $\theta$ e riassumerle con quantità come media, moda e intervalli di credibilità.

## Metodo basato su griglia

Il metodo utilizzato in questo capitolo per generare la distribuzione a posteriori è noto come metodo basato su griglia. Questo metodo numerico esatto si basa sul calcolo della distribuzione a posteriori mediante una griglia di punti uniformemente spaziati. Nonostante la maggior parte dei parametri sia continua, l'approssimazione della distribuzione a posteriori può essere ottenuta considerando soltanto una griglia finita di valori dei parametri. Il metodo segue quattro fasi:

1. Fissare una griglia discreta di possibili valori dei parametri.
2. Valutare la distribuzione a priori e la funzione di verosimiglianza per ciascun valore della griglia.
3. Calcolare l'approssimazione della densità a posteriori, ottenuta moltiplicando la distribuzione a priori per la funzione di verosimiglianza per ciascun valore della griglia e normalizzando i prodotti in modo che la loro somma sia uguale a 1.
4. Selezionare $n$ valori casuali dalla griglia per ottenere un campione casuale della densità a posteriori normalizzata.

Questo metodo può essere potenziato aumentando il numero di punti nella griglia, ma il limite principale risiede nel fatto che all'aumentare della dimensionalità dello spazio dei parametri, il numero di punti necessari per una stima accurata cresce in modo esponenziale, rendendo il metodo impraticabile per problemi complessi.

In sintesi, l'approccio basato sulla griglia è intuitivo e non richiede competenze di programmazione avanzate per l'implementazione. Inoltre, fornisce un risultato che può essere considerato, per tutti gli scopi pratici, come un campione casuale estratto dalla distribuzione di probabilità a posteriori condizionata ai dati. Tuttavia, questo metodo è limitato a causa della *maledizione della dimensionalità*[^036_posterior_sim-1], il che significa che può essere applicato soltanto a modelli statistici semplici con non più di due parametri. Di conseguenza, in pratica, è spesso sostituito da altre tecniche più efficienti, poiché i modelli impiegati in psicologia richiedono frequentemente la stima di centinaia o anche migliaia di parametri.

[^036_posterior_sim-1]: Per comprendere la maledizione della dimensionalità, possiamo considerare l'esempio di una griglia di 100 punti equispaziati. Nel caso di un solo parametro, sarebbe necessario calcolare solo 100 valori. Tuttavia, se abbiamo due parametri, il numero di valori da calcolare diventa $100^2$. Se invece abbiamo 10 parametri, il numero di valori da calcolare sarebbe di $10^{10}$. È evidente che la quantità di calcoli richiesta diventa troppo grande persino per un computer molto potente. Pertanto, per modelli che richiedono la stima di un numero significativo di parametri, è necessario utilizzare un approccio diverso.

::: {.callout-important title="Esercizio" collapse="true"}

In uno studio sulla percezione delle emozioni, un partecipante osserva 10 fotografie di volti arrabbiati. Deve indicare se il volto esprime **rabbia** o no. Ogni risposta può essere **corretta (1)** o **errata (0)**.

I dati osservati del partecipante sono:

```
1, 0, 1, 1, 1, 0, 0, 1, 1, 1
```

→ Totale: **7 successi** su **10 prove** → $y = 7$, $n = 10$.

**Obiettivo:** stimare la probabilità $\theta$ che il partecipante riconosca correttamente un volto arrabbiato, tenendo conto sia dei **dati osservati** sia di **conoscenze pregresse**.

**Prior Informativo.**

Supponiamo di voler adottare un approccio cautamente *pessimistico* sulle capacità iniziali del partecipante, basandoci su studi precedenti che indicano un riconoscimento della rabbia **non sempre accurato**, ad esempio mediamente intorno al **40%** con moderata incertezza.

Per rappresentare questa convinzione, scegliamo come **distribuzione a priori** una **Beta(4, 6)**:

- **Media**: $\mu = \frac{4}{4+6} = 0.4$
- **Varianza**: $\frac{4 \cdot 6}{(10)^2 \cdot 11} = 0.0218$

Questa prior concentra la massa di probabilità su valori inferiori a 0.5, ma lascia spazio anche a livelli di competenza superiori.


**Calcolo della Distribuzione a Posteriori con il Metodo Basato su Griglia.**

**1. Griglia di valori per $\theta$.**

```{r}
theta <- seq(0, 1, length.out = 1000)
head(theta)
tail(theta)
```

**2. Calcolo della distribuzione a priori Beta(4, 6).**

```{r}
prior <- dbeta(theta, shape1 = 4, shape2 = 6)
prior <- prior / sum(prior)  # normalizzazione
```

Visualizzazione:

```{r}
ggplot(data.frame(theta, prior), aes(x = theta, y = prior)) +
  geom_line(linewidth = 1.2, color = okabe_ito_palette[2]) +
  labs(
    title = "Distribuzione a Priori Informativa: Beta(4, 6)",
    x = expression(theta),
    y = "Densità (normalizzata)"
  ) +
  theme_minimal(base_size = 14)
```

**3. Calcolo della verosimiglianza per 7 successi su 10.**

```{r}
likelihood <- dbinom(7, size = 10, prob = theta)
likelihood <- likelihood / sum(likelihood)  # normalizzazione
```

Visualizzazione:

```{r}
ggplot(data.frame(theta, likelihood), aes(x = theta, y = likelihood)) +
  geom_line(linewidth = 1.2, color = okabe_ito_palette[1]) +
  labs(
    title = "Funzione di Verosimiglianza: 7 successi su 10",
    x = expression(theta),
    y = "Densità (normalizzata)"
  ) +
  theme_minimal(base_size = 14)
```

**4. Calcolo della distribuzione a posteriori.**

```{r}
unnormalized_posterior <- prior * likelihood
posterior <- unnormalized_posterior / sum(unnormalized_posterior)
```

**5. Visualizzazione congiunta: prior, likelihood e posteriori.**

```{r}
data <- data.frame(theta, prior, likelihood, posterior)

# Imposta i livelli desiderati con nomi leggibili
long_data <- pivot_longer(
  data,
  cols = c("prior", "likelihood", "posterior"),
  names_to = "distribution",
  values_to = "density"
) |>
  mutate(distribution = factor(
    distribution,
    levels = c("prior", "likelihood", "posterior"),
    labels = c("A Priori", "Verosimiglianza", "A Posteriori")
    )
  )

ggplot(
  long_data, 
  aes(x = theta, y = density, color = distribution)
  ) +
  geom_line(linewidth = 1.2) +
  labs(
    title = "Distribuzioni Bayesiane: A Priori, Verosimiglianza e A Posteriori",
    x = expression(theta),
    y = "Densità (normalizzata)",
    color = NULL
  ) +
  scale_color_manual(
    values = c(
      "A Priori" = okabe_ito_palette[2],       # blu
      "Verosimiglianza" = okabe_ito_palette[1],# arancione
      "A Posteriori" = okabe_ito_palette[3]    # verde
    )
  ) +
  theme(legend.position = "bottom")
```

**Riepilogo:**

- la **prior** (Beta(4,6)) riflette una convinzione iniziale più scettica;
- la **verosimiglianza** è centrata su $\theta = 0.7$, corrispondente a 7 successi su 10;
- la **posteriori** media tra prior e dati, ma si sposta chiaramente verso destra, evidenziando l’**effetto aggiornamento bayesiano**.

Questo esempio mostra come l’approccio bayesiano:

- **integra in modo trasparente** dati individuali e credenze pregresse;
- **produce una stima personalizzata** della capacità del partecipante;
- permette di **quantificare l’incertezza** in modo completo, tramite la distribuzione a posteriori.

**Quantità a Posteriori.**

Media:

```{r}
posterior_mean <- sum(theta * posterior)
posterior_mean
```

Deviazione standard:

```{r}
posterior_sd <- sqrt(sum((theta^2) * posterior) - posterior_mean^2)
posterior_sd
```

Moda:

```{r}
posterior_mode <- theta[which.max(posterior)]
posterior_mode
```

Intervallo di credibilità al 94%:

```{r}
samples <- sample(theta, size = 10000, replace = TRUE, prob = posterior)
quantile(samples, probs = c(0.03, 0.97))
```

Questo esercizio mostra come:

- l’informazione pregressa può essere incorporata in modo trasparente in un modello bayesiano;
- la posteriori riflette **una combinazione tra dati osservati e conoscenze precedenti**.

:::

## Riflessioni Conclusive

In questo capitolo, abbiamo esplorato l'aggiornamento bayesiano utilizzando una distribuzione a priori discreta, accennando brevemente al caso delle distribuzioni a priori continue. Quando si affrontano scenari con distribuzioni a priori continue, l'elaborazione della distribuzione a posteriori generalmente richiede la risoluzione di un integrale che, nella maggior parte dei casi, non ammette una soluzione analitica. Tuttavia, ci sono eccezioni notevoli, come nell'inferenza relativa alle proporzioni, dove la distribuzione a priori è modellata come una distribuzione Beta e la funzione di verosimiglianza segue una distribuzione binomiale. In queste circostanze particolari, è possibile derivare analiticamente la distribuzione a posteriori. L'analisi dettagliata di questo caso sarà trattata nel capitolo successivo.

## Esercizi {.unnumbered}

::: {.callout-important title="Problemi 1" collapse="true"}
In uno studio sull'analisi delle pratiche di trasparenza e riproducibilità nella ricerca in psicologia, @hardwicke2022estimating hanno riportato che la condivisione dei materiali di ricerca è stata rilevata nel 14% dei casi (26 su 183 studi), con un intervallo di confidenza al 95% pari a [10%, 19%]. Questo suggerisce che la condivisione di materiali è rara.

Ispirandoti ai risultati di questo studio, costruisci una distribuzione a priori per la probabilità $\theta$ che uno studio condivida i materiali di ricerca. Per semplicità, discretizza $\theta$ in 10 livelli equispaziati: $0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95$.

Attribuisci le seguenti probabilità a priori ai 10 livelli, basandoti sull'informazione che la condivisione dei materiali è un evento raro ma non trascurabile: $0.05, 0.20, 0.30, 0.15, 0.10, 0.08, 0.05, 0.03, 0.02, 0.02$.

Supponiamo che siano stati osservati 20 studi su 100 che hanno condiviso i materiali di ricerca. Calcola la distribuzione a posteriori utilizzando il metodo basato su griglia. Calcola la media della distribuzione a posteriori e l'intervallo di credibilità al 89%.
:::

::: {.callout-tip title="Soluzioni 1" collapse="true"}
```r
# Definizione dei possibili valori di theta (probabilità discreta)
theta <- seq(0.05, 0.95, by = 0.10)

# Definizione della distribuzione a priori
prior <- c(0.05, 0.20, 0.30, 0.15, 0.10, 0.08, 0.05, 0.03, 0.02, 0.02)

# Normalizzazione della prior (se necessario, ma in questo caso già normalizzata)
prior <- prior / sum(prior)

# Dati osservati
successi <- 20  # studi che hanno condiviso materiali
n <- 100        # studi totali

# Calcolo della verosimiglianza usando la distribuzione binomiale
likelihood <- dbinom(successi, size = n, prob = theta)

# Calcolo della distribuzione a posteriori (applicazione del teorema di Bayes)
posterior <- likelihood * prior
posterior <- posterior / sum(posterior)  # Normalizzazione

# Calcolo della media della distribuzione a posteriori
posterior_mean <- sum(theta * posterior)

# Calcolo dell'intervallo di credibilità al 89%
cdf <- cumsum(posterior)  # Distribuzione cumulativa
lower_bound <- theta[which.min(abs(cdf - 0.055))]  # 5.5% quantile
upper_bound <- theta[which.min(abs(cdf - 0.945))]  # 94.5% quantile

# Output dei risultati
list(
  posterior_mean = posterior_mean,
  credibility_interval_89 = c(lower_bound, upper_bound)
)
```
:::

::: {.callout-important title="Problemi 2" collapse="true"}

L'obiettivo di questo esercizio è applicare il metodo basato su griglia per stimare la distribuzione a posteriori di una proporzione, utilizzando dati dalla Scala della Rete Sociale di Lubben (LSNS-6). Si assume che un punteggio LSNS-6 superiore a una soglia prefissata indichi isolamento sociale. Il compito è:

1. Scegliere una soglia per classificare i partecipanti in due gruppi (isolati vs. non isolati), garantendo che la proporzione osservata non sia inferiore a 0.1 o superiore a 0.9.
2. Calcolare la distribuzione a posteriori della proporzione usando un'approssimazione discreta su una griglia di valori.
3. Determinare l'intervallo di credibilità all'89%.
4. Interpretare i risultati.

**Consegna:**
caricare su Moodle il file .qmd compilato in pdf.
:::

::: {.callout-tip title="Soluzioni 2" collapse="true"}
**Dati e Modellizzazione**

Si assume che i dati siano rappresentati da una variabile binaria $y$, con $y = 1$ per individui classificati come isolati e $y = 0$ altrimenti. Supponiamo che su un campione di $n$ individui, $s$ siano isolati.

Definiamo il modello statistico:

$$ y_i \sim \text{Bernoulli}(\theta) $$

con:

- $y_i \in \{0,1\}$ per $i=1,\dots,n$,
- $\theta$ proporzione di individui isolati nella popolazione.

La distribuzione a priori su $\theta$ è scelta come $\text{Beta}(2,2)$, che rappresenta una conoscenza iniziale moderata e non estrema.

**Metodo basato su griglia**

Il metodo a griglia approssima la distribuzione a posteriori calcolando la probabilità per una serie di valori discreti di $\theta$.

1. **Definire una griglia di valori per $\theta$**:

    ```r
    theta <- seq(0, 1, length.out = 100)
    ```
2. **Calcolare la distribuzione a priori**:

    ```r
    prior <- dbeta(theta, 2, 2)
    prior <- prior / sum(prior)  # Normalizzazione
    ```
3. **Calcolare la verosimiglianza**:

    ```r
    likelihood <- dbinom(s, size = n, prob = theta)
    likelihood <- likelihood / sum(likelihood)  # Normalizzazione
    ```
4. **Calcolare la distribuzione a posteriori**:

    ```r
    posterior <- prior * likelihood
    posterior <- posterior / sum(posterior)  # Normalizzazione
    ```

** Calcolo dell'intervallo di credibilità all'89%**

L'intervallo di credibilità è calcolato come l'intervallo che contiene il 89% della probabilità a posteriori.

```r
ci_89 <- quantile(sample(theta, size = 10000, prob = posterior, replace = TRUE), probs = c(0.055, 0.945))
ci_89
```

**Interpretazione dei risultati**

1. **Valore atteso e moda a posteriori**:

    ```r
    mean_theta <- sum(theta * posterior)
    mode_theta <- theta[which.max(posterior)]
    ```
    
    - Il valore atteso fornisce una stima puntuale di $\theta$.
    - La moda indica il valore più probabile della proporzione di isolamento sociale.

2. **Intervallo di credibilità**:

    - L'89% della probabilità a posteriori cade tra i valori dell'intervallo di credibilità.
    - Se l'intervallo è stretto, c'è maggiore certezza sulla proporzione stimata.
    - Se l'intervallo è ampio, vi è maggiore incertezza sulla proporzione.
:::

## Informazioni sull'Ambiente di Sviluppo {.unnumbered}

```{r}
sessionInfo()
```

## Bibliografia {.unnumbered}
