---
execute:
  freeze: auto
---

# Distribuzione predittiva a posteriori {#sec-bayesian-inference-post-pred-distr}

**Prerequisiti**

- Leggere il capitolo [Posterior Inference & Prediction](https://www.bayesrulesbook.com/chapter-8#ch8-post-pred) di [Bayes Rules!](https://www.bayesrulesbook.com).

**Concetti e competenze chiave**

- Imparare a combinare le probabilità a posteriori con le probabilità condizionali di un nuovo evento (come ottenere "croce" in un ulteriore lancio) per fare previsioni future. La distribuzione predittiva a posteriori ci permette di calcolare la probabilità di nuovi dati, tenendo conto delle evidenze osservate.
- Capire come la modellazione probabilistica aiuti a formalizzare l'incertezza e a fare previsioni basate su evidenze aggiornate, un concetto chiave nel ragionamento statistico e inferenziale.

## Introduzione 

In questo capitolo esploreremo il concetto di *distribuzione predittiva a posteriori*, concentrandoci sul caso discreto. Per rendere il tema accessibile e intuitivo, utilizzeremo come esempio esplicativo il classico problema del *sacchetto di monete* (*bag of coins*), che permette di visualizzare chiaramente il processo di inferenza bayesiana.


## Previsioni su Eventi Futuri

La *distribuzione predittiva a posteriori* è un elemento centrale nell'inferenza bayesiana. Essa rappresenta la probabilità di eventi futuri calcolata sulla base delle osservazioni raccolte e delle nostre convinzioni aggiornate (*a posteriori*). In altre parole, consente di fare previsioni tenendo conto sia dei dati osservati che dell'incertezza residua nei parametri del modello.

### Definizione Formale

Supponiamo di avere un insieme di dati osservati $y = \{y_1, y_2, \ldots, y_n\}$, generati da un modello che dipende da un parametro sconosciuto $\theta$. Inizialmente, le nostre conoscenze su $\theta$ sono rappresentate dalla distribuzione a priori $p(\theta)$. Dopo aver osservato i dati, possiamo aggiornare la nostra conoscenza su $\theta$ mediante la distribuzione a posteriori $p(\theta | y)$, calcolata con la formula di Bayes:

$$
p(\theta | y) = \frac{p(y | \theta) p(\theta)}{p(y)},
$$

dove:

- $p(\theta | y)$ è la distribuzione a posteriori del parametro $\theta$;
- $p(y | \theta)$ è la *verosimiglianza*, cioè la probabilità di osservare i dati dati i parametri;
- $p(\theta)$ è la distribuzione a priori di $\theta$;
- $p(y)$ è l'evidenza, ovvero la probabilità totale dei dati osservati.

Per fare previsioni su un nuovo dato $\tilde{y}$, usiamo la *distribuzione predittiva a posteriori*, che combina tutte le possibili ipotesi sui parametri $\theta$, pesate per le loro probabilità a posteriori:

$$
p(\tilde{y} | y) = \int p(\tilde{y} | \theta) p(\theta | y) \, d\theta.
$$

Nel caso discreto, l'integrale diventa una somma:

$$
p(\tilde{y} | y) = \sum_{\theta} p(\tilde{y} | \theta) p(\theta | y).
$$

Questa espressione incorpora la nostra incertezza sui parametri, permettendoci di fare previsioni più robuste e coerenti.

---

## Il Sacchetto di Monete

Il problema del *sacchetto di monete* fornisce un esempio pratico per comprendere la distribuzione predittiva a posteriori. Immaginiamo di avere un sacchetto contenente tre tipi di monete:

1. **Moneta di Tipo 0**: Dà sempre "croce" (probabilità di "testa" = 0).
2. **Moneta di Tipo 1**: È una moneta equa (probabilità di "testa" = 0.5 e di "croce" = 0.5).
3. **Moneta di Tipo 2**: Dà sempre "testa" (probabilità di "testa" = 1).

Supponiamo di scegliere una moneta a caso dal sacchetto e di lanciarla quattro volte, ottenendo sempre "croce". Vogliamo calcolare la probabilità di ottenere "croce" al quinto lancio, utilizzando la distribuzione predittiva a posteriori.

---

### Passo 1: Probabilità Iniziali (*A Priori*)

Prima di osservare i risultati dei lanci, non abbiamo informazioni su quale tipo di moneta sia stato estratto. Attribuiamo quindi una probabilità uniforme (*a priori*) a ciascun tipo di moneta:

- $P(\text{Tipo 0}) = \frac{1}{3}$;
- $P(\text{Tipo 1}) = \frac{1}{3}$;
- $P(\text{Tipo 2}) = \frac{1}{3}$.

---

### Passo 2: Osservare i Risultati e Aggiornare le Probabilità

Dopo aver osservato quattro lanci consecutivi che hanno dato "croce", possiamo aggiornare le probabilità sui tipi di moneta utilizzando la formula di Bayes.

- **Moneta di Tipo 0**: La probabilità di osservare quattro "croce" è 1, dato che questa moneta dà sempre "croce".
- **Moneta di Tipo 1**: La probabilità di osservare quattro "croce" consecutivi è $(0.5)^4 = 0.0625$.
- **Moneta di Tipo 2**: La probabilità di osservare quattro "croce" è 0, dato che questa moneta dà sempre "testa".

Usiamo la formula di Bayes per calcolare le probabilità posteriori. Supponiamo che $D$ rappresenti il dato osservato ("croce, croce, croce, croce"). La probabilità totale $P(D)$ è:

$$
P(D) = P(D | \text{Tipo 0}) P(\text{Tipo 0}) + P(D | \text{Tipo 1}) P(\text{Tipo 1}) + P(D | \text{Tipo 2}) P(\text{Tipo 2}),
$$

cioè:

$$
P(D) = 1 \cdot \frac{1}{3} + 0.0625 \cdot \frac{1}{3} + 0 \cdot \frac{1}{3} = \frac{1.0625}{3}.
$$

Le probabilità posteriori diventano quindi:

- $P(\text{Tipo 0} | D) = \frac{1 \cdot \frac{1}{3}}{\frac{1.0625}{3}} = \frac{1}{1.0625} \approx 0.941$;
- $P(\text{Tipo 1} | D) = \frac{0.0625 \cdot \frac{1}{3}}{\frac{1.0625}{3}} = \frac{0.0625}{1.0625} \approx 0.059$;
- $P(\text{Tipo 2} | D) = 0$.

---

### Passo 3: Predire il Risultato del Quinto Lancio

La probabilità di ottenere "croce" al quinto lancio è calcolata combinando le probabilità posteriori con la probabilità di "croce" per ciascun tipo di moneta:

$$
P(\text{croce al quinto lancio} | D) = P(\text{Tipo 0} | D) \cdot 1 + P(\text{Tipo 1} | D) \cdot 0.5 + P(\text{Tipo 2} | D) \cdot 0.
$$

Inserendo i valori calcolati:

$$
P(\text{croce al quinto lancio} | D) = 0.941 \cdot 1 + 0.059 \cdot 0.5 + 0 \cdot 0 = 0.9705.
$$

---

## Interpretazione

La distribuzione predittiva a posteriori combina la nostra incertezza sui parametri con le osservazioni passate, fornendo una stima robusta per eventi futuri. In questo esempio, la probabilità di ottenere "croce" al quinto lancio è alta ($0.9705$), poiché le osservazioni precedenti indicano una forte probabilità che la moneta scelta sia di Tipo 0.

## Riflessioni Conclusive

Il problema del *sacchetto di monete* illustra come la distribuzione predittiva a posteriori permetta di fare previsioni integrate e coerenti, aggiornando sistematicamente le credenze iniziali con le evidenze osservate. Questo approccio evidenzia la potenza dell'inferenza bayesiana nel gestire l'incertezza e nel fornire previsioni informate.


## Esercizi

::: {#exr-bag-of-coins-1}

Utilizzando un set di dati diverso, ovvero tre "testa" seguite da una "croce", calcola la distribuzione predittiva a posteriori per il prossimo lancio.

:::
   
::: {#exr-bag-of-coins-2}

Consideriamo un modello in cui ci sono tre tipi di monete, ognuna con una probabilità diversa di dare "testa" o "croce":

1. Moneta di Tipo 0: Questa moneta dà sempre "croce". La probabilità di ottenere "testa" è 0.
2. Moneta di Tipo 1: Questa moneta ha una probabilità di 0.7 di ottenere "testa" e 0.3 di ottenere "croce".
3. Moneta di Tipo 2: Questa moneta dà sempre "testa". La probabilità di ottenere "testa" è 1.

Nel sacchetto ci sono: 2 monete di tipo 0, 1 moneta di tipo 1 e 1 moneta di tipo 2. Supponiamo di osservare la sequenza *croce, testa, croce*. Vogliamo calcolare la probabilità di ottenere "croce" al quarto lancio.

:::

