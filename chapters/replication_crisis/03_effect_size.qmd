# La grandezza dell'effetto

::: callout-important
## In questo capitolo imparerai a

- La dimensione dell’effetto quantifica la forza della relazione tra due variabili, standardizzando l’entità di un intervento o trattamento.
- È fondamentale distinguere tra dimensione dell’effetto e significatività statistica.
- La corretta valutazione e interpretazione di questa misura è spesso carente nella letteratura psicologica, portando a conclusioni superficiali e fuorvianti.
- Le interpretazioni più appropriate degli indici della grandezza dell'effetto includono l’uso di benchmark e la valutazione delle implicazioni pratiche.
:::

::: callout-tip
## Prerequisiti

- Leggere [The piranha problem: Large effects swimming in a small pond](https://statmodeling.stat.columbia.edu/2024/07/22/the-piranha-problem-large-effects-swimming-in-a-small-pond/).
:::

::: callout-caution
## Preparazione del Notebook

```{r}
here::here("code", "_common.R") |> 
  source()

# Load packages
if (!requireNamespace("pacman")) install.packages("pacman")
pacman::p_load(mice, labelled, haven, pointblank)
```
:::


## Introduzione

La [dimensione dell'effetto](https://en.wikipedia.org/wiki/Effect_size) (*effect size*) è un concetto fondamentale nella metodologia della ricerca, utilizzato per quantificare la forza della relazione statistica tra due variabili. Questa misura rappresenta l'entità dell'effetto di un intervento o di un trattamento in modo standardizzato, descrivendo in termini quantitativi l'importanza di un fenomeno osservato.

È cruciale distinguere tra la dimensione dell'effetto e la significatività statistica. Un risultato può essere "statisticamente significativo" pur avendo un effetto di piccole dimensioni, e viceversa. La conoscenza di uno di questi concetti non fornisce automaticamente informazioni sull'altro, evidenziando la necessità di considerare entrambi gli aspetti nell'analisi dei dati.

L'importanza della dimensione dell'effetto è ampiamente riconosciuta nel campo della ricerca scientifica. Il manuale dell'American Psychological Association (APA) del 2010 ne sottolinea la rilevanza, raccomandando di riportare questa misura negli studi pubblicati. Di conseguenza, la maggior parte degli articoli nelle riviste associate all'APA include la dimensione dell'effetto, generalmente indicata tra parentesi accanto al valore di p.

Nonostante la sua importanza e la prassi di riportarla, la psicologia scientifica spesso mostra una carenza nella corretta valutazione e interpretazione delle dimensioni dell'effetto. Molti ricercatori si limitano a comunicare questi valori senza esaminarli approfonditamente, portando a conclusioni che possono risultare superficiali, poco informative, fuorvianti o addirittura errate. Questa tendenza rivela una sottovalutazione sistematica e una diffusa incomprensione delle dimensioni dell'effetto, anche tra i professionisti della ricerca.

## Misurazione dell'Effetto: Approcci e Applicazioni

Tra le metriche più adottate per quantificare la dimensione dell'effetto si annoverano il $d$ di Cohen e l'$r$ di Pearson. Il $d$ di Cohen è prevalentemente impiegato per descrivere le differenze tra le medie di gruppi sperimentali, quantificando questa differenza in termini di una deviazione standard aggregata. 

La differenza standardizzata delle medie tra due gruppi può essere calcolata con la seguente formula [equazione 5.1, @glass1981a],

$$
d_p = \frac{M_1 - M_2}{S_p}.
$$

Un valore positivo di $d_p$ indica che la media del gruppo 1 è maggiore della media del gruppo 2. Dividere la differenza delle medie per la deviazione standard combinata, $S_p$, è la formulazione classica del $d$ di Cohen. La deviazione standard combinata, $S_p$, può essere calcolata come la radice quadrata della varianza media (ponderata per i gradi di libertà, $df = n-1$) del gruppo 1 e del gruppo 2 [pp. 108, @glass1981a]:

$$
S_p = \sqrt{\frac{(n_1 - 1) S_1^2 + (n_2 - 1) S_2^2}{n_1 + n_2 - 2}}.
$$

Si noti che il termine *varianza* si riferisce al quadrato della deviazione standard ($S^2$). Il $d_p$ di Cohen è correlato alla statistica t di un test t per campioni indipendenti. Infatti, possiamo calcolare il valore di $d_p$ a partire dalla statistica $t$ con la seguente formula [equazione 5.3, @glass1981a]:

$$
d = t \sqrt{\frac{1}{n_1} + \frac{1}{n_2}}.
$$

L'errore standard corrispondente di $d_p$ è,

$$
SE_{d_p} = \sqrt{\frac{n_1 + n_2}{n_1 n_2} + \frac{d_p^2}{2(n_1 + n_2)}}.
$$

La statistica $r$ di Pearson, d'altro canto, viene utilizzato per esprimere il grado di previsione di una variabile attraverso un'altra, fornendo una misura della correlazione. È interessante notare come queste due misure possano essere convertite l'una nell'altra attraverso la relazione:

$$
d = \frac{2r}{\sqrt{1-r^2}}.
$$

## Interpretare la Dimensione dell'Effetto

L'interpretazione delle dimensioni dell'effetto solitamente avviene in due modi comuni: uno è privo di significato e l'altro è seriamente fuorviante.

- **Gli Standard di Cohen.** Funder (2019) affermano che l'interpretazione più ampiamente utilizzata ma priva di senso delle dimensioni dell'effetto richiama gli standard stabiliti da Jacob Cohen (1977, 1988). Cohen ha fissato i valori di r di .10, .30 e .50 come soglie per effetti piccoli, medi e grandi, rispettivamente. Tuttavia, Cohen stesso ha dichiarato che queste soglie dovrebbero essere utilizzate solo in assenza di una base migliore e in seguito ha espresso rammarico per averle proposte. 

    I termini "piccolo", "medio" e "grande" sono privi di significato senza un contesto di riferimento. È necessario rispondere a due domande fondamentali: (a) piccolo, medio o grande rispetto a cosa? e (b) piccolo, medio o grande a quale scopo?

- **Elevare al Quadrato la Correlazione.** Secondo @funder2019evaluating, un altro metodo comune per valutare la dimensione dell'effetto è ancora più problematico: elevare al quadrato il valore di r. Ad esempio, un r di .30 elevato al quadrato produce .09, interpretato come "proporzione di varianza spiegata". Questa conversione spesso viene riportata con la parola "solo", come in "la correlazione di .30 ha spiegato solo il 9% della varianza".

    Non esiste una giustificazione valida per considerare r² come una misura appropriata della dimensione dell'effetto. La statistica r corrisponde alla pendenza di regressione quando entrambe le variabili sono standardizzate, mentre r² è molto meno interpretabile perché riflette la proporzione di varianza in una variabile spiegata da un'altra.

    Un esempio illustrativo è fornito da Darlington (1990). Immaginiamo un gioco in cui si lanciano prima un nickel (5¢) e poi un dime (10¢), ricevendo un pagamento di 5¢ o 10¢ rispettivamente se la moneta mostra testa. Le correlazioni tra il valore del nickel e il pagamento (r = .4472) e tra il valore del dime e il pagamento (r = .8944) sono calcolate. Elevando al quadrato queste correlazioni, si ottiene che i nickel spiegano il 20% della varianza nel pagamento, mentre i dime spiegano l'80%. Tuttavia, interpretare questi valori come indicazione che i dime contano quattro volte tanto quanto i nickel è fuorviante. Le correlazioni originali (.8944 è esattamente il doppio di .4472) offrono un confronto più informativo. In conclusione, elevare al quadrato r per valutare la dimensione dell'effetto non solo è poco informativo, ma può anche essere fuorviante.

### Alternative migliori 

È cruciale interpretare le dimensioni degli effetti in modo che ne arricchisca il significato. @funder2019evaluating propongono due strategie principali: l'adozione di benchmark (criteri di riferimento) e la valutazione delle implicazioni pratiche dei risultati.

- Utilizzare criteri di riferimento significa confrontare l'entità di un risultato con quella di risultati ben noti e ampiamente compresi. Simile al modo in cui giudichiamo l'altezza di una persona basandoci su confronti con altri, i ricercatori possono ottenere una percezione accurata dell'importanza di un risultato confrontandolo con la dimensione di effetti noti, sia quelli tipici del campo di studio sia quelli emersi da ricerche passate.

- Un approccio al benchmarking può includere l'analisi di risultati considerati "classici" nel campo di interesse o la considerazione di dimensioni dell'effetto per risultati che hanno ottenuto un solido consenso nella comunità psicologica.

- In un'ottica più ampia, alcuni ricercatori hanno proposto benchmark per la dimensione dell'effetto calcolando medie su vasti corpi di letteratura. Ad esempio, uno studio di psicologia sociale ha esaminato 708 correlazioni ottenute meta-analiticamente, rivelando che la dimensione media dell'effetto $r$ era di .19.

- La conoscenza comune o i risultati di ricerche non psicologiche possono offrire benchmark per valutare la forza di una relazione tra variabili. Un esempio è l'efficacia degli antistaminici contro il comune raffreddore, che corrisponde a un $r$ di .11, mentre l'effetto degli anti-infiammatori non steroidei (come l'ibuprofene) sul dolore è di $r = .14$.

Tali confronti illustrano come l'interpretazione delle dimensioni dell'effetto possa essere notevolmente approfondita e resa più significativa attraverso il riferimento a benchmark consolidati o intuitivamente comprensibili, sia dentro che fuori il campo della psicologia. Questo metodo consente di inserire i risultati di nuove ricerche in un contesto più vasto, favorendo una valutazione più consapevole della loro rilevanza relativa.

## Raccomandazioni per la Pratica di Ricerca

@funder2019evaluating concludono il loro articolo con una serie di raccomandazioni per migliorare la pratica di riportare le dimensioni degli effetti negli studi scientifici.

**Riportare sempre e in modo evidente le dimensioni degli effetti.** Ogni studio dovrebbe evidenziare chiaramente le dimensioni degli effetti. Una conseguenza di questa raccomandazione è che la dimensione del campione di uno studio deve essere adeguata affinché la stima della dimensione dell'effetto sia affidabile.

**Condurre studi con campioni ampi.** Studi con campioni ampi sono ideali. Sebbene questo non sia sempre fattibile con certi tipi di ricerca o popolazioni specifiche, dovrebbe essere una priorità aumentare il più possibile la dimensione del campione.

**Riportare le dimensioni degli effetti in termini utili nel contesto.** Il coefficiente di correlazione $r$ di Pearson, essendo una misura standardizzata della dimensione dell'effetto, non fornisce informazioni sulle unità di misura dello studio. Pertanto, è necessario utilizzare misure delle dimensioni degli effetti che siano utili nel contesto specifico dello studio, come differenze medie o coefficienti di regressione grezzi, accanto a misure standardizzate, quando possibile.

**Evitare terminologia vuota.** Si dovrebbe smettere di elevare al quadrato i valori di $r$ per minimizzare l'apparente piccola percentuale di varianza spiegata e di utilizzare senza riflettere le linee guida di J. Cohen (1977, 1988), che lo stesso Cohen ha successivamente disconosciuto. Idealmente, termini come "piccolo" e "grande" dovrebbero essere eliminati dal vocabolario delle dimensioni degli effetti, poiché sono etichette soggettive e spesso arbitrarie che non aggiungono informazioni utili ai risultati quantitativi.

## Commenti e considerazioni finali 

La sovrastima della grandezza dell'effetto in psicologia costituisce un problema diffuso. Un principio fondamentale della psicologia sociale e dell'economia comportamentale, almeno come viene presentato nei media e insegnato in molte scuole di business, è che piccoli "nudge" o spinte gentili, spesso cose che potremmo pensare non ci influenzino affatto, possono avere grandi effetti sul comportamento. Questo ha portato a numerose affermazioni sensazionalistiche, come l'idea che le elezioni siano decise da partite di football, o che la presentazione subliminale di una faccina sorridente possa causare enormi cambiamenti negli atteggiamenti verso l'immigrazione.

Il modello di mondo alla base di queste affermazioni non è solo "l'effetto farfalla", ovvero che piccoli cambiamenti possono avere grandi effetti, ma piuttosto che piccoli cambiamenti possono avere effetti grandi e prevedibili. È quello che a volte viene chiamato il modello "a pulsante" delle scienze sociali: l'idea che se fai X, puoi aspettarti di vedere Y.

Tuttavia, questa visione presenta diversi problemi:

1. Sovrastima degli effetti: Molti studi riportano effetti sorprendentemente grandi per interventi minimi, che spesso non vengono replicati in studi successivi.
2. Mancanza di considerazione delle interazioni: Se esistessero molti effetti grandi e prevedibili sul comportamento, questi interferirebbero tra loro, rendendo difficile osservare effetti coerenti nei dati osservazionali.
3. Instabilità: Un sistema sociale con molti effetti grandi e prevedibili sarebbe instabile e difficile da studiare.
4. Generalizzazione eccessiva: Spesso si tende a generalizzare risultati ottenuti in condizioni di laboratorio molto specifiche a contesti più ampi e complessi della vita reale.
5. Bias di pubblicazione: Gli studi che riportano effetti grandi e statisticamente significativi hanno maggiori probabilità di essere pubblicati, creando una rappresentazione distorta della realtà.

È importante sottolineare che la psicologia descrive molti fenomeni robusti, per esempio nella psicologia clinica e nella psicologia della percezione. Tuttavia, è fondamentale adottare un approccio più cauto e sfumato nell'interpretazione e nella comunicazione dei risultati della ricerca psicologica. La consapevolezza di questo problema ha portato a una maggiore enfasi sulla replicabilità degli studi, sull'uso di campioni più ampi e su metodi statistici più robusti. Inoltre, sta emergendo un approccio più critico e riflessivo nella comunità scientifica, che riconosce la complessità dei fenomeni psicologici e la necessità di evitare semplificazioni eccessive.

In conclusione, mentre la psicologia offre preziose intuizioni sul comportamento umano, è essenziale mantenere un sano scetticismo verso affermazioni di effetti grandi e facilmente ottenibili. La realtà è spesso più complessa e sfumata di quanto suggerito da titoli sensazionalistici o da singoli studi. 

## Informazioni sull'Ambiente di Sviluppo {.unnumbered} 

```{r}
sessionInfo()
```

## Bibliografia {.unnumbered}
