[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Psicometria",
    "section": "",
    "text": "Benvenuti\nBenvenuti nel sito web dell’insegnamento di Psicometria, parte del Corso di Laurea in Scienze e Tecniche Psicologiche dell’Università degli Studi di Firenze.",
    "crumbs": [
      "Benvenuti"
    ]
  },
  {
    "objectID": "index.html#descrizione",
    "href": "index.html#descrizione",
    "title": "Psicometria",
    "section": "Descrizione",
    "text": "Descrizione\nL’insegnamento offre una formazione teorico-pratica nell’ambito dell’inferenza statistica, con un focus particolare sulle applicazioni in campo psicologico. Attraverso esercitazioni pratiche in Python e R, gli studenti acquisiranno competenze nell’analisi di dati e nell’uso di modelli statistici avanzati.\n\nAnno Accademico: 2024-2025\nCodice Insegnamento: B000286\nOrario e Luogo: Lunedì e Martedì (8:30-10:30), Giovedì (11:30-13:30), Plesso didattico La Torretta.\n\n\n\n\n\n\n\nNota\n\n\n\nQuesto sito web è la fonte ufficiale per il programma dell’insegnamento B000286 - Psicometria e le modalità d’esame.",
    "crumbs": [
      "Benvenuti"
    ]
  },
  {
    "objectID": "index.html#struttura-dellinsegnamento",
    "href": "index.html#struttura-dellinsegnamento",
    "title": "Psicometria",
    "section": "Struttura dell’Insegnamento",
    "text": "Struttura dell’Insegnamento\nL’insegnamento è articolato in diverse sezioni, ognuna delle quali si concentra su un argomento chiave per fornire una comprensione approfondita delle metodologie e degli strumenti necessari per l’analisi statistica e la gestione dei dati.\n\nFondamenti di Statistica: Introduzione ai concetti statistici di base, con un focus su misure descrittive, distribuzioni e visualizzazione dei dati.\nTeoria della Probabilità: Principi fondamentali della probabilità, inclusi eventi, distribuzioni di probabilità e applicazioni pratiche.\nInferenza Frequentista: Approfondimento sull’inferenza statistica basata sulla frequenza, con applicazioni per test di ipotesi e stime puntuali e intervallari.\nInferenza Bayesiana: Introduzione e applicazioni avanzate dell’inferenza bayesiana, con un confronto con l’approccio frequentista.\nProgrammazione in R: Esercitazioni pratiche sull’utilizzo di R per l’analisi dei dati, con particolare attenzione a script replicabili e workflow efficienti.\nGestione di un Progetto di Data Analysis: Approccio strutturato per interpretare, documentare e comunicare i risultati di un’analisi, con attenzione alla riproducibilità.\nComunicazione dei Risultati: Tecniche per rappresentare in modo efficace i risultati statistici, inclusa la creazione di report, visualizzazioni e presentazioni.\n\nQuesta struttura mira a combinare teoria e pratica, offrendo agli studenti gli strumenti necessari per affrontare le sfide dell’analisi statistica in contesti reali.\nConsulta il syllabus completo per ulteriori dettagli.",
    "crumbs": [
      "Benvenuti"
    ]
  },
  {
    "objectID": "index.html#materiale-didattico",
    "href": "index.html#materiale-didattico",
    "title": "Psicometria",
    "section": "Materiale Didattico",
    "text": "Materiale Didattico\nIl presente sito web ospita la dispensa ufficiale del corso, contenente tutte le note e i materiali relativi alle lezioni. Per quanto riguarda le esercitazioni pratiche e gli esempi applicativi, è possibile accedere al sito dedicato, disponibile al seguente indirizzo: Psicometria Esercizi. Entrambi i materiali sono forniti gratuitamente agli studenti, senza necessità di ulteriori acquisti.",
    "crumbs": [
      "Benvenuti"
    ]
  },
  {
    "objectID": "prefazione.html",
    "href": "prefazione.html",
    "title": "Prefazione",
    "section": "",
    "text": "Bibliografia\nCome possiamo migliorare l’analisi dei dati psicologici per renderla più affidabile e robusta? È possibile affrontare questa sfida semplicemente applicando una serie di algoritmi o procedure standard? L’analisi dei dati in psicologia può davvero essere ridotta a un insieme di “ricette” preconfezionate (McElreath, 2020)?\nQueste domande ci portano a riflettere sulla natura stessa dell’analisi dei dati psicologici. A differenza di ciò che suggerisce l’approccio frequentista del test dell’ipotesi nulla, l’analisi dei dati non è una disciplina che si esaurisce con l’applicazione meccanica di metodi predefiniti. Anzi, considerare l’analisi dei dati come un insieme di procedure automatiche contribuisce a uno dei problemi più gravi della psicologia contemporanea: la crisi della replicabilità dei risultati (Korbmacher et al., 2023).\nMa perché la replicabilità è così cruciale? Se i risultati delle ricerche psicologiche non sono replicabili, significa che la nostra comprensione dei fenomeni psicologici è superficiale e inaffidabile. Questo non è solo un problema teorico o accademico; ha implicazioni dirette sulle applicazioni pratiche della psicologia. Se le basi scientifiche sono incerte, anche le strategie di intervento psicologico rischiano di essere inefficaci o addirittura dannose (Funder et al., 2014; Ioannidis, 2019; Shrout & Rodgers, 2018; Tackett et al., 2019).\nPerché le pratiche di analisi dei dati derivanti dal frequentismo potrebbero contribuire a questa crisi? In che modo gli incentivi accademici influenzano la qualità della ricerca psicologica? E, soprattutto, quali alternative abbiamo per migliorare l’affidabilità e la validità delle nostre conclusioni?\nL’analisi bayesiana emerge come una delle proposte per superare i limiti dell’approccio frequentista (Gelman et al., 1995). Tuttavia, è sufficiente abbandonare l’inferenza frequentista per risolvere i problemi della psicologia? Come possiamo integrare metodi robusti e flessibili, come quelli bayesiani, con una comprensione più approfondita e trasparente dei fenomeni psicologici?\nIn questo corso, esploreremo queste domande, cercando di identificare le “buone pratiche” dell’analisi dei dati psicologici. Discuteremo i limiti delle metodologie attuali, esamineremo le cause sottostanti della crisi della replicabilità e valuteremo come l’adozione di metodi avanzati, come l’inferenza bayesiana e la modellazione causale, possa offrire soluzioni efficaci (Oberauer & Lewandowsky, 2019; Wagenmakers et al., 2018; Yarkoni, 2022). Il nostro obiettivo è fornire una visione critica e costruttiva, che non solo identifichi le sfide della ricerca psicologica, ma proponga anche percorsi concreti per migliorare la qualità e l’affidabilità della scienza psicologica.",
    "crumbs": [
      "Prefazione"
    ]
  },
  {
    "objectID": "prefazione.html#bibliografia",
    "href": "prefazione.html#bibliografia",
    "title": "Prefazione",
    "section": "",
    "text": "Funder, D. C., Levine, J. M., Mackie, D. M., Morf, C. C., Sansone, C., Vazire, S., & West, S. G. (2014). Improving the dependability of research in personality and social psychology: Recommendations for research and educational practice. Personality and Social Psychology Review, 18(1), 3–12.\n\n\nGelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (1995). Bayesian data analysis. Chapman; Hall/CRC.\n\n\nIoannidis, J. P. (2019). What have we (not) learnt from millions of scientific papers with P values? The American Statistician, 73(sup1), 20–25.\n\n\nKorbmacher, M., Azevedo, F., Pennington, C. R., Hartmann, H., Pownall, M., Schmidt, K., Elsherif, M., Breznau, N., Robertson, O., Kalandadze, T., et al. (2023). The replication crisis has led to positive structural, procedural, and community changes. Communications Psychology, 1(1), 3.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nOberauer, K., & Lewandowsky, S. (2019). Addressing the theory crisis in psychology. Psychonomic Bulletin & Review, 26, 1596–1618.\n\n\nShrout, P. E., & Rodgers, J. L. (2018). Psychology, science, and knowledge construction: Broadening perspectives from the replication crisis. Annual Review of Psychology, 69(1), 487–510.\n\n\nTackett, J. L., Brandes, C. M., King, K. M., & Markon, K. E. (2019). Psychology’s replication crisis and clinical psychological science. Annual Review of Clinical Psychology, 15(1), 579–604.\n\n\nWagenmakers, E.-J., Marsman, M., Jamil, T., Ly, A., Verhagen, J., Love, J., Selker, R., Gronau, Q. F., Šmı́ra, M., Epskamp, S., et al. (2018). Bayesian inference for psychology. Part I: Theoretical advantages and practical ramifications. Psychonomic Bulletin & Review, 25, 35–57.\n\n\nYarkoni, T. (2022). The generalizability crisis. Behavioral and Brain Sciences, 45, e1.",
    "crumbs": [
      "Prefazione"
    ]
  },
  {
    "objectID": "programmazione2024.html",
    "href": "programmazione2024.html",
    "title": "1  Incontri",
    "section": "",
    "text": "1.1 Calendario delle lezioni\nIl calendario didattico prevede 32 incontri, con un esame parziale a metà corso e gli ultimi tre incontri riservati a un secondo esame parziale e alle presentazioni degli studenti.\nPausa di Pasqua",
    "crumbs": [
      "Calendario",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Incontri</span>"
    ]
  },
  {
    "objectID": "programmazione2024.html#calendario-delle-lezioni",
    "href": "programmazione2024.html#calendario-delle-lezioni",
    "title": "1  Incontri",
    "section": "",
    "text": "Incontro\nData\nArgomento\nOrario\n\n\n\n\n1\n3 marzo\nPresentazione del corso, struttura e obiettivi\n8:30-10:30\n\n\n2\n4 marzo\nIntroduzione a Python e R per l’analisi dei dati\n8:30-10:30\n\n\n3\n6 marzo\nExploratory Data Analysis\n11:30-13:30\n\n\n4\n10 marzo\nFondamenti di probabilità\n8:30-10:30\n\n\n5\n11 marzo\nSpazi di probabilità e variabili casuali\n8:30-10:30\n\n\n6\n13 marzo\nDistribuzioni di probabilità discreta\n11:30-13:30\n\n\n7\n17 marzo\nDistribuzioni di probabilità continua\n8:30-10:30\n\n\n8\n18 marzo\nTeorema di Bayes e inferenza Bayesiana\n8:30-10:30\n\n\n9\n20 marzo\nPriori coniugati e metodo basato su griglia\n11:30-13:30\n\n\n10\n24 marzo\nMetodi Monte Carlo e algoritmi MCMC\n8:30-10:30\n\n\n11\n25 marzo\nIntroduzione a Stan e programmazione probabilistica\n8:30-10:30\n\n\n12\n27 marzo\nPredizione bayesiana\n11:30-13:30\n\n\n13\n31 marzo\nSintesi e diagnostica della distribuzione a posteriori\n8:30-10:30\n\n\n14\n1 aprile\nModello gaussiano, poisson, esponenziale, a mistura\n8:30-10:30\n\n\n15\n3 aprile\nModello categoriale e gerarchico\n11:30-13:30\n\n\n16\n7 aprile\nModello lineare bivariato, OLS\n8:30-10:30\n\n\n17\n8 aprile\nElementi di algebra lineare e regressione multipla\n8:30-10:30\n\n\n18\n10 aprile\nAnalisi della covarianza, interazioni statistiche\n11:30-13:30\n\n\n\n\n\n\n\n\n\n\n\n\n\nIncontro\nData\nArgomento\nOrario\n\n\n\n\n19\n15 aprile\nEsame parziale\n8:30-10:30\n\n\n20\n17 aprile\nModello lineare gerarchico e modelli lineari misti\n11:30-13:30\n\n\n21\n22 aprile\nInferenza causale: concetti di base\n8:30-10:30\n\n\n22\n24 aprile\nGLM, regressione logistica e binomiale\n11:30-13:30\n\n\n23\n28 aprile\nEntropia e teoria dell’informazione\n8:30-10:30\n\n\n24\n29 aprile\nComparazione di modelli con entropia\n8:30-10:30\n\n\n25\n6 maggio\nAnalisi dei dati longitudinali e modelli dinamici\n8:30-10:30\n\n\n26\n8 maggio\nModelli cognitivi\n11:30-13:30\n\n\n27\n12 maggio\nTest di ipotesi frequentista\n8:30-10:30\n\n\n28\n13 maggio\nIntervalli di confidenza frequentisti\n8:30-10:30\n\n\n29\n15 maggio\nCrisi della replicazione\n11:30-13:30",
    "crumbs": [
      "Calendario",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Incontri</span>"
    ]
  },
  {
    "objectID": "programmazione2024.html#calendario-delle-relazioni-in-itinere",
    "href": "programmazione2024.html#calendario-delle-relazioni-in-itinere",
    "title": "1  Incontri",
    "section": "1.2 Calendario delle relazioni in itinere",
    "text": "1.2 Calendario delle relazioni in itinere\nLe relazioni di avanzamento del progetto di gruppo dovranno essere consegnate entro le scadenze stabilite. Ogni gruppo dovrà presentare un unico elaborato.\n\n\n\n\n\n\n\nData di Scadenza\nContenuto della Relazione\n\n\n\n\n18 marzo\nRelazione 1: Importazione dei dati, data wrangling, data tidying, dizionario dei dati, statistiche descrittive\n\n\n25 marzo\nRelazione 2: Priori coniugati e metodo basato su griglia\n\n\n31 marzo\nRelazione 3: Metodi Monte Carlo e algoritmi MCMC\n\n\n7 aprile\nRelazione 4: Regressione lineare\n\n\n8 maggio\nRelazione 5: Confronto di modelli\n\n\n18 maggio\nRelazione 6: Analisi frequentista; limiti dell’approccio frequentista\n\n\n\n\nOgni relazione rappresenta una tappa del progetto di gruppo, che culminerà nella presentazione finale durante gli ultimi incontri del corso.",
    "crumbs": [
      "Calendario",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Incontri</span>"
    ]
  },
  {
    "objectID": "programmazione2024.html#esame-parziale-e-presentazioni-finali",
    "href": "programmazione2024.html#esame-parziale-e-presentazioni-finali",
    "title": "1  Incontri",
    "section": "1.3 Esame parziale e presentazioni finali",
    "text": "1.3 Esame parziale e presentazioni finali\n\n\n\n\n\n\n\n\n\nIncontro\nData\nArgomento\nOrario\n\n\n\n\n30\n19 maggio\nEsame parziale finale\n8:30-10:30\n\n\n31\n20 maggio\nPresentazioni dei progetti\n8:30-10:30\n\n\n32\n22 maggio\nPresentazioni dei progetti\n11:30-13:30",
    "crumbs": [
      "Calendario",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Incontri</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/introduction_key_notions.html",
    "href": "chapters/key_notions/introduction_key_notions.html",
    "title": "Introduzione",
    "section": "",
    "text": "La data science è un campo che si sviluppa all’intersezione tra la statistica e l’informatica. La statistica fornisce una serie di metodologie per analizzare i dati e ottenere informazioni significative, mentre l’informatica si occupa dello sviluppo di software e strumenti per implementare tali metodologie. In questa sezione della dispensa, approfondiremo alcuni concetti fondamentali della statistica e della misurazione psicologica. Considereremo anche in termini generali quali sono gli obiettivi e i limiti dell’analisi dei dati psicologici.",
    "crumbs": [
      "Fondamenti",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/key_notions/00_uncertainty.html",
    "href": "chapters/key_notions/00_uncertainty.html",
    "title": "2  Abbracciare l’incertezza",
    "section": "",
    "text": "2.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nL’espressione “abbracciare l’incertezza” è tra le più emblematiche nel panorama della statistica bayesiana. In questo capitolo, approfondiremo il significato di questa affermazione, seguendo la trattazione introduttiva proposta nel primo capitolo di Understanding Uncertainty di Lindley (Lindley, 2013).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/00_uncertainty.html#lincertezza-nella-ricerca-psicologica",
    "href": "chapters/key_notions/00_uncertainty.html#lincertezza-nella-ricerca-psicologica",
    "title": "2  Abbracciare l’incertezza",
    "section": "2.2 L’incertezza nella ricerca psicologica",
    "text": "2.2 L’incertezza nella ricerca psicologica\nL’incertezza rappresenta un elemento cruciale non solo nella statistica, ma in tutte le discipline scientifiche, con particolare rilievo per la psicologia, che affronta fenomeni complessi e difficili da misurare. Nell’indagare processi cognitivi, emozioni e comportamenti, i ricercatori si confrontano con dati complessi, spesso ambigui e suscettibili di interpretazioni molteplici. Sebbene alcune affermazioni possano essere sostenute con elevata confidenza o confutate con certezza, la maggior parte delle ipotesi scientifiche si colloca in una zona grigia dominata dall’incertezza.\nL’obiettivo di questo insegnamento è guidare gli studenti nella comprensione e nella gestione dell’incertezza nella ricerca psicologica, adottando l’approccio bayesiano all’analisi dei dati. Questo metodo, basato sulla quantificazione e sull’aggiornamento delle credenze alla luce di nuove evidenze, fornirà agli studenti gli strumenti per affrontare l’incertezza in modo rigoroso e sistematico, sia nella carriera accademica sia nella pratica clinica.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/00_uncertainty.html#la-natura-soggettiva-dellincertezza",
    "href": "chapters/key_notions/00_uncertainty.html#la-natura-soggettiva-dellincertezza",
    "title": "2  Abbracciare l’incertezza",
    "section": "2.3 La natura soggettiva dell’incertezza",
    "text": "2.3 La natura soggettiva dell’incertezza\nUn elemento cruciale dell’incertezza, spesso trascurato, è la sua dimensione soggettiva. De Finetti (Finetti, 1970) ha evidenziato come l’incertezza sia, almeno in parte, una questione personale: ciò che è incerto per uno psicologo può non esserlo per un altro, in funzione delle loro esperienze, conoscenze pregresse e interpretazioni dei dati disponibili. Anche di fronte a una stessa questione, due ricercatori possono condividere un’incertezza comune, ma con gradi di intensità diversi.\nQuesta componente soggettiva è particolarmente significativa in psicologia, dove le differenze individuali e culturali influenzano la percezione e l’interpretazione dei fenomeni. L’approccio bayesiano offre un potente strumento per affrontare questa soggettività, consentendo di quantificare le differenze tra credenze individuali e di aggiornarle in modo coerente sulla base di nuove evidenze oggettive.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/00_uncertainty.html#lonnipresenza-dellincertezza",
    "href": "chapters/key_notions/00_uncertainty.html#lonnipresenza-dellincertezza",
    "title": "2  Abbracciare l’incertezza",
    "section": "2.4 L’onnipresenza dell’incertezza",
    "text": "2.4 L’onnipresenza dell’incertezza\nL’incertezza pervade ogni aspetto della ricerca psicologica. Ogni esperimento, misurazione o interpretazione dei dati comporta un margine di incertezza. Questa condizione è particolarmente evidente nello studio di fenomeni complessi come il comportamento umano o i processi mentali, dove innumerevoli variabili interagiscono, molte delle quali difficili da misurare o controllare con precisione.\nTuttavia, l’incertezza non deve essere vista come un ostacolo insormontabile. Al contrario, riconoscerla e quantificarla può favorire una comprensione più profonda e realistica dei fenomeni psicologici. Attraverso l’approccio bayesiano, diventa possibile integrare l’incertezza nel processo di indagine scientifica, trattandola non come un limite, ma come una risorsa.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/00_uncertainty.html#superare-la-soppressione-dellincertezza",
    "href": "chapters/key_notions/00_uncertainty.html#superare-la-soppressione-dellincertezza",
    "title": "2  Abbracciare l’incertezza",
    "section": "2.5 Superare la soppressione dell’incertezza",
    "text": "2.5 Superare la soppressione dell’incertezza\nNonostante la sua onnipresenza, l’incertezza è spesso ignorata o minimizzata nella comunicazione scientifica. Questo può avvenire attraverso interpretazioni eccessivamente ottimistiche dei risultati, la presentazione di conclusioni come fatti certi, o una riluttanza a riconoscere i limiti degli studi condotti. Tale atteggiamento, sebbene comprensibile, può condurre a conclusioni errate e a una visione distorta della realtà.\nL’approccio bayesiano permette di affrontare l’incertezza in modo esplicito e costruttivo. Fornendo un quadro rigoroso per quantificarla, analizzarla e comunicarla chiaramente, migliora la trasparenza della ricerca e promuove conclusioni più oneste e accurate.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/00_uncertainty.html#i-benefici-dellincertezza",
    "href": "chapters/key_notions/00_uncertainty.html#i-benefici-dellincertezza",
    "title": "2  Abbracciare l’incertezza",
    "section": "2.6 I benefici dell’incertezza",
    "text": "2.6 I benefici dell’incertezza\nContrariamente a quanto si possa pensare, l’incertezza offre numerosi vantaggi per la ricerca psicologica:\n\nStimola l’esplorazione scientifica: La consapevolezza dell’incertezza incoraggia i ricercatori a formulare nuove ipotesi e a migliorare i metodi di studio.\nPromuove l’onestà intellettuale: Accettare l’incertezza rende i ricercatori più cauti e aperti a prospettive alternative.\nMigliora la qualità delle analisi: Integrare l’incertezza porta a disegni sperimentali più robusti e interpretazioni più accurate.\nFacilita la collaborazione interdisciplinare: Riconoscere i limiti delle proprie conoscenze stimola la ricerca di input da altri esperti.\nRiflette la complessità dei fenomeni psicologici: L’incertezza è intrinseca ai processi mentali e riconoscerla consente di rappresentarli in modo più realistico.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/00_uncertainty.html#tipi-di-incertezza",
    "href": "chapters/key_notions/00_uncertainty.html#tipi-di-incertezza",
    "title": "2  Abbracciare l’incertezza",
    "section": "2.7 Tipi di incertezza",
    "text": "2.7 Tipi di incertezza\nL’incertezza nella ricerca può essere classificata in tre categorie principali, in base alla sua origine: aleatoria, epistemica e ontologica (Gansch & Adee, 2020).\n\n2.7.1 Incertezza Aleatoria\nL’incertezza aleatoria è intrinseca alla natura casuale di un processo e non può essere eliminata per un dato modello probabilistico. Essa è considerata irreducibile e viene quantificata tramite distribuzioni probabilistiche. Ad esempio, nella misurazione della risposta di un individuo a uno stimolo, la variabilità intrinseca nel comportamento umano, dovuta a fattori imprevedibili, rappresenta un caso di incertezza aleatoria. Questo tipo di incertezza è una caratteristica fondamentale di molti fenomeni psicologici e biologici.\n\n\n2.7.2 Incertezza Epistemica\nL’incertezza epistemica deriva dalla conoscenza limitata o incompleta di un fenomeno. Essa rappresenta il “noto-ignoto”, cioè ciò che sappiamo di non sapere, ed è legata alle semplificazioni insite in ogni modello scientifico. Ad esempio, un modello psicologico che non consideri le influenze culturali o ambientali potrebbe risultare incompleto, introducendo incertezza epistemica. Diversamente dall’incertezza aleatoria, l’incertezza epistemica può essere ridotta attraverso il miglioramento dei modelli, l’inclusione di variabili rilevanti o la raccolta di ulteriori dati.\n\n\n2.7.3 Incertezza Ontologica\nL’incertezza ontologica riguarda l’“ignoto-ignoto”, ovvero aspetti di un sistema che non sono ancora stati identificati. In psicologia, questo potrebbe riferirsi a variabili o processi non ancora scoperti che influenzano un comportamento. Ad esempio, studiando i disturbi mentali, potrebbero emergere nuovi fattori di rischio precedentemente sconosciuti.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/00_uncertainty.html#il-calcolo-dellincertezza-nellapproccio-bayesiano",
    "href": "chapters/key_notions/00_uncertainty.html#il-calcolo-dellincertezza-nellapproccio-bayesiano",
    "title": "2  Abbracciare l’incertezza",
    "section": "2.8 Il calcolo dell’incertezza nell’approccio bayesiano",
    "text": "2.8 Il calcolo dell’incertezza nell’approccio bayesiano\nL’insegnamento si propone di fornire agli studenti strumenti per affrontare e quantificare l’incertezza attraverso l’approccio bayesiano (Gelman et al., 1995). Fondato sul teorema di Bayes, questo metodo rappresenta un quadro teorico rigoroso e sistematico per aggiornare le credenze alla luce di nuove evidenze, configurandosi come una componente centrale della metodologia scientifica.\nIl processo si basa su quattro passaggi essenziali. In primo luogo, si parte dalla quantificazione delle credenze iniziali, note come prior, che rappresentano le conoscenze pregresse o le ipotesi relative a un determinato fenomeno psicologico. Successivamente, si analizza la forza delle evidenze empiriche fornite dai dati raccolti, formalizzata nella likelihood. Queste due informazioni vengono combinate per generare le credenze aggiornate, chiamate posterior, che sintetizzano la conoscenza disponibile integrando i dati empirici e le ipotesi iniziali. Infine, le credenze aggiornate possono essere utilizzate per prendere decisioni più informate, pianificare ricerche future e orientare interventi.\n\n2.8.1 Il ruolo delle credenze e delle decisioni nella ricerca psicologica\nLe credenze rivestono un ruolo fondamentale nella ricerca psicologica, influenzando tutte le fasi del processo scientifico, dalla progettazione degli esperimenti all’interpretazione dei risultati, fino alla scelta di interventi clinici. L’approccio bayesiano si distingue per la sua capacità di esplicitare e formalizzare queste credenze, consentendo di aggiornare il loro contenuto in modo coerente e trasparente man mano che emergono nuove evidenze.\nQuesto metodo permette non solo di ottimizzare le decisioni basandosi su informazioni aggiornate, ma anche di comunicare chiaramente l’incertezza associata alle conclusioni, evidenziandone i limiti e garantendo maggiore trasparenza scientifica. Affrontare l’incertezza come una componente intrinseca della ricerca non solo migliora la qualità dell’analisi, ma consente anche di promuovere un approccio più realistico e rigoroso nello studio dei fenomeni psicologici.\nIn sintesi, l’approccio bayesiano offre un modello operativo per integrare l’incertezza nel processo decisionale, trattandola non come un ostacolo, ma come un elemento essenziale per una comprensione più sfumata e accurata della realtà.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/00_uncertainty.html#riflessioni-conclusive",
    "href": "chapters/key_notions/00_uncertainty.html#riflessioni-conclusive",
    "title": "2  Abbracciare l’incertezza",
    "section": "2.9 Riflessioni Conclusive",
    "text": "2.9 Riflessioni Conclusive\nQuesto insegnamento fornisce gli strumenti per applicare l’analisi bayesiana nell’ambito dei dati psicologici, insegnando a considerare l’incertezza come una parte integrante e preziosa del processo scientifico. Attraverso questo approccio, gli studenti potranno acquisire una comprensione più raffinata e strutturata dei fenomeni psicologici, integrando l’incertezza come elemento fondamentale per interpretare i dati e formulare inferenze rigorose.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/00_uncertainty.html#bibliografia",
    "href": "chapters/key_notions/00_uncertainty.html#bibliografia",
    "title": "2  Abbracciare l’incertezza",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nFinetti, B. de. (1970). Teoria delle probabilità: sintesi introduttiva con appendice critica. Einaudi.\n\n\nGansch, R., & Adee, A. (2020). System theoretic view on uncertainties. 2020 Design, Automation & Test in Europe Conference & Exhibition (DATE), 1345–1350.\n\n\nGelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (1995). Bayesian data analysis. Chapman; Hall/CRC.\n\n\nLindley, D. V. (2013). Understanding uncertainty. John Wiley & Sons.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html",
    "href": "chapters/key_notions/01_key_notions.html",
    "title": "3  Concetti chiave",
    "section": "",
    "text": "Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nQuesto capitolo introduce il contesto e i principi base dell’analisi dei dati, con un focus su come le tecniche statistiche, combinate con una solida teoria dei fenomeni, siano strumentali all’avanzamento delle conoscenze scientifiche.\nL’analisi dei dati consente di sintetizzare grandi quantità di informazioni e di verificare le previsioni avanzate dalle teorie. Tuttavia, senza una teoria che dia significato ai dati, le osservazioni rimangono mere descrizioni prive di un contesto esplicativo. È attraverso l’integrazione tra dati e teoria che si raggiunge una comprensione profonda dei fenomeni e si favorisce l’avanzamento scientifico.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#introduzione",
    "href": "chapters/key_notions/01_key_notions.html#introduzione",
    "title": "3  Concetti chiave",
    "section": "",
    "text": "Most of the fundamental ideas of science are essentially simple, and may, as a rule, be expressed in a language comprehensible to everyone.\n(Einstein A and Infeld L, 1938)\n\n\n\n\n\n\n\n\nStatistica\n\n\n\nIl termine “statistica” può assumere diversi significati, a seconda del contesto in cui viene utilizzato.\n\nNel primo senso, la statistica è una scienza e una disciplina che si occupa dello studio e dell’applicazione di metodi e tecniche per la raccolta, l’organizzazione, l’analisi, l’interpretazione e la presentazione di dati.\nNel secondo senso, il termine “statistica” si riferisce a una singola misura o un valore numerico che è stato calcolato a partire da un campione di dati. Questo tipo di statistica rappresenta una caratteristica specifica del campione. Esempi comuni di statistiche in questo senso includono la media campionaria, la deviazione standard campionaria o il coefficiente di correlazione campionario.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#la-spiegazione-scientifica",
    "href": "chapters/key_notions/01_key_notions.html#la-spiegazione-scientifica",
    "title": "3  Concetti chiave",
    "section": "3.1 La Spiegazione Scientifica",
    "text": "3.1 La Spiegazione Scientifica\nLa scienza non si limita a descrivere o prevedere i fenomeni; essa mira a spiegare il perché degli eventi, fornendo una comprensione delle cause e dei meccanismi che governano il mondo. La spiegazione scientifica è quindi uno strumento essenziale per costruire teorie che non solo descrivono e prevedono, ma anche chiariscono le dinamiche causali e le connessioni tra fenomeni, aiutando così a sviluppare un controllo informato sugli stessi.\nSe prendiamo l’esempio del successo accademico in psicologia dell’educazione, possiamo osservare che i dati rivelano una forte associazione tra il livello di istruzione dei genitori e il successo scolastico dei figli. Tuttavia, una semplice previsione basata su questa associazione – “provenendo da una famiglia con basso livello d’istruzione, è improbabile che tu ottenga un titolo universitario” – non risponde alle domande fondamentali per migliorare il sistema educativo: perché esiste questa disparità? Quali interventi potrebbero ridurre questa disuguaglianza?\nPer andare oltre la previsione, la scienza deve individuare i fattori causali che contribuiscono al fenomeno, esplorare il modo in cui agire su questi fattori potrebbe alterare l’outcome, e stimare le incertezze e le dinamiche temporali di questi effetti. Ad esempio, per ridurre la disuguaglianza educativa, è necessario comprendere se e come aumentare il sostegno finanziario agli studenti possa realmente facilitare il percorso scolastico di chi proviene da contesti meno favoriti, e prevedere gli effetti di lungo termine di tali politiche. Questo approccio permette non solo di prevedere ma anche di controllare e migliorare i fenomeni studiati.\n\n3.1.1 Elementi Fondamentali della Spiegazione Scientifica\nLa filosofia della scienza ha individuato tre elementi chiave di una spiegazione scientifica:\n\nExplanandum: il fenomeno da spiegare. Ad esempio, “si è verificata una crisi petrolifera nel 1973.”\nExplanans: un insieme di affermazioni che spiegano il fenomeno. Per esempio, “gli stati membri dell’OAPEC hanno imposto un embargo sul petrolio in risposta al sostegno degli Stati Uniti a Israele nella guerra del Kippur.”\nLegame esplicativo: i principi o le leggi che descrivono il meccanismo sottostante, ossia il modo in cui l’explanans causa l’explanandum. Nel caso dell’embargo, il legame potrebbe essere: “gli stati dell’OAPEC usarono il petrolio come strumento politico per influenzare la politica estera degli Stati Uniti.”\n\nI modelli scientifici incorporano questi elementi, rappresentando una metodologia per ottenere spiegazioni scientifiche. Essi includono il fenomeno da spiegare, i fattori causali rilevanti e i meccanismi che collegano i fattori all’esito. A differenza dei modelli puramente descrittivi o predittivi, i modelli scientifici in psicologia sono progettati per rispondere a domande causali, facilitando la comprensione e il controllo dei fenomeni.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#modelli-psicologici",
    "href": "chapters/key_notions/01_key_notions.html#modelli-psicologici",
    "title": "3  Concetti chiave",
    "section": "3.2 Modelli Psicologici",
    "text": "3.2 Modelli Psicologici\nUn modello è una rappresentazione matematica semplificata di un fenomeno reale. È composto da un insieme di equazioni e ipotesi che definiscono la struttura probabilistica e le relazioni tra le variabili, cercando di cogliere gli aspetti essenziali del fenomeno senza includerne ogni dettaglio. Esistono spesso diversi modelli applicabili a uno stesso problema, e il compito della scienza dei dati è identificare quello che meglio si adatta ai dati, soddisfacendo criteri di validità e accuratezza.\nI modelli psicologici sono strumenti concettuali per descrivere, spiegare e prevedere il comportamento umano e i processi mentali. Un buon modello psicologico dovrebbe avere alcune caratteristiche fondamentali:\n\nCoerenza descrittiva: Il modello deve rappresentare in modo logico e coerente il fenomeno studiato, catturando gli aspetti chiave del processo psicologico e organizzando le osservazioni in una struttura comprensibile.\nCapacità predittiva: Un modello efficace deve essere in grado di fare previsioni accurate sui futuri sviluppi del fenomeno. Questa capacità non solo ne aumenta l’utilità, ma permette anche di testarne la validità.\nSupporto empirico: Le ipotesi e le previsioni del modello devono essere confermate da dati raccolti attraverso ricerche sistematiche e rigorose.\nFalsificabilità: Un modello scientifico deve poter essere testato e, se necessario, confutato con l’osservazione e l’esperimento. Questo principio assicura che il modello rimanga aperto alla revisione e al miglioramento in base a nuove evidenze.\nParsimonia: Il modello dovrebbe spiegare il fenomeno nel modo più semplice possibile, evitando complessità inutili.\nGeneralizzabilità: Deve essere applicabile a una vasta gamma di situazioni e contesti, non limitandosi a casi specifici o condizioni sperimentali particolari.\nUtilità pratica: Un modello efficace dovrebbe fornire spunti utili per interventi, terapie o applicazioni nel mondo reale.\n\nLa modellazione in psicologia affronta sfide uniche dovute alla natura soggettiva e variabile dell’esperienza umana. I ricercatori devono bilanciare la precisione scientifica con la flessibilità necessaria per cogliere la complessità dei fenomeni psicologici, considerando al contempo i limiti etici della sperimentazione e le potenziali implicazioni sociali dei loro modelli.\nL’analisi dei dati, attraverso tecniche statistiche, è il mezzo per valutare un modello psicologico. Oltre a stabilire se il modello riesce a spiegare i dati osservati, l’analisi verifica la capacità del modello di fare previsioni su dati non ancora raccolti. In questo modo, la modellazione non solo consente di comprendere i fenomeni psicologici ma permette anche di prevedere e, in certi casi, influenzare il comportamento e i processi mentali.\n\n3.2.1 Rappresentare i Fenomeni per Ragionare e Comunicare\nLa spiegazione scientifica, oltre a chiarire i meccanismi causali, serve anche a fornire un linguaggio per ragionare sui fenomeni e per condividere la conoscenza. In psicologia, la costruzione di modelli scientifici permette di rappresentare i fenomeni attraverso variabili, funzioni e parametri, fornendo un vocabolario per descrivere componenti, dipendenze e proprietà dei fenomeni. Un modello semplice e chiaro consente di emulare il comportamento del fenomeno senza necessità di simulazioni complesse, facilitando la comunicazione e l’intuizione.\nUn aspetto importante della spiegazione scientifica è la possibilità di utilizzare i modelli per stimolare l’intuizione e generare nuove domande. La comprensione dei fenomeni attraverso una rappresentazione scientifica accessibile permette di formulare ipotesi, collegare concetti, e trasferire conoscenze da un campo all’altro.\nIn sintesi, la spiegazione scientifica va oltre la mera previsione: mira a fornire una comprensione completa dei fenomeni, basata su nessi causali e su un linguaggio formale per ragionare e comunicare. I modelli scientifici non solo predicono eventi, ma spiegano come e perché questi eventi si verificano, offrendo una struttura con cui intervenire e influenzare i fenomeni stessi.\nNell’analisi dei dati bayesiana, questa attenzione alle cause e agli effetti trova un’applicazione naturale. La possibilità di aggiornare le proprie credenze alla luce di nuove informazioni consente di costruire modelli che non si limitano alla descrizione o alla previsione, ma che forniscono spiegazioni coerenti e profonde dei fenomeni, aiutando a sviluppare teorie sempre più raffinate e applicabili.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#ruolo-dellanalisi-dei-dati",
    "href": "chapters/key_notions/01_key_notions.html#ruolo-dellanalisi-dei-dati",
    "title": "3  Concetti chiave",
    "section": "3.3 Ruolo dell’Analisi dei Dati",
    "text": "3.3 Ruolo dell’Analisi dei Dati\nL’analisi dei dati riveste un ruolo centrale nelle scienze, specialmente in psicologia, per due ragioni principali:\n\nRiassumere grandi quantità di informazioni: consente di sintetizzare dati complessi in statistiche descrittive, grafici e altre rappresentazioni che rendono i dati accessibili e comprensibili. Questo processo evidenzia tendenze generali, variazioni e anomalie, facilitando l’identificazione di schemi comportamentali e differenze tra gruppi.\nVerificare le predizioni di un modello scientifico: permette di confrontare le aspettative teoriche con i dati osservati, valutando la validità delle ipotesi sottostanti. Questa verifica contribuisce direttamente all’avanzamento della conoscenza scientifica, sostenendo, modificando o confutando una teoria.\n\nSebbene l’analisi dei dati possa portare alla scoperta di correlazioni o schemi interessanti, questi risultati, senza una teoria, offrono solo una comprensione limitata. Per esempio, rilevare che due variabili psicologiche sono correlate non fornisce informazioni sulla natura di questa relazione o sul motivo per cui esiste. Per interpretare e attribuire un significato a queste osservazioni, è necessario un quadro teorico che le contestualizzi e proponga meccanismi causali o esplicativi.\n\n3.3.1 Carattere Multidisciplinare dell’Analisi dei Dati\nL’analisi dei dati si situa all’intersezione di tre discipline principali: statistica, teoria della probabilità e informatica. Ciascuna contribuisce con strumenti e approcci specifici essenziali per comprendere i dati, estrarre conoscenza e generare nuove ipotesi scientifiche.\n\nStatistica: offre tecniche per raccogliere, analizzare e interpretare i dati, fornendo strumenti descrittivi e inferenziali utili per trarre conclusioni e prendere decisioni.\nTeoria della probabilità: fornisce la base matematica della statistica, consentendo di modellare e quantificare l’incertezza e di comprendere i fenomeni aleatori che caratterizzano molte osservazioni in psicologia.\nInformatica: supporta l’analisi attraverso strumenti per la gestione, l’elaborazione e la visualizzazione di grandi quantità di dati. La programmazione consente di sviluppare modelli avanzati e gestire dataset complessi.\n\nQuesta natura multidisciplinare riflette la complessità dell’analisi dei dati e la necessità di integrare diverse competenze per affrontare le sfide scientifiche contemporanee.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#concetti-chiave-nellanalisi-dei-dati",
    "href": "chapters/key_notions/01_key_notions.html#concetti-chiave-nellanalisi-dei-dati",
    "title": "3  Concetti chiave",
    "section": "3.4 Concetti Chiave nell’Analisi dei Dati",
    "text": "3.4 Concetti Chiave nell’Analisi dei Dati\nPer condurre un’analisi dei dati efficace, è fondamentale comprendere alcuni concetti chiave.\n\n3.4.1 Popolazioni e Campioni\nIn ogni analisi dei dati, è fondamentale identificare la popolazione di interesse, l’insieme completo di entità o individui che rappresentano il fenomeno studiato. In psicologia, ad esempio, si può voler studiare il benessere in una popolazione generale o in una sotto-popolazione specifica, come gli individui che hanno subito un evento stressante.\nPer ottenere informazioni dettagliate su una popolazione, si utilizzano campioni: sottoinsiemi rappresentativi dai quali si possono fare inferenze sull’intera popolazione. La rappresentatività del campione è cruciale, poiché un campione non rappresentativo può portare a conclusioni errate e limitare la generalizzabilità dei risultati.\n\n\n3.4.2 Bias nella Raccolta Dati\nI bias nella raccolta e interpretazione dei dati possono influenzare profondamente i risultati di uno studio. Capire chi ha raccolto i dati, come e con quali finalità, è fondamentale per garantire una corretta interpretazione. I dati non sono mai neutri e le intenzioni che ne guidano la raccolta spesso ne influenzano l’interpretazione (Murray & Carr, 2024; Nobles, 2000)\n\n\n\nTabella creata da Ellie Murray.\n\n\n\n\n3.4.3 Variabili e Costanti\nNell’analisi statistica, le variabili rappresentano le caratteristiche osservate che possono assumere diversi valori (numerici o categorici). Al contrario, le costanti sono valori che rimangono fissi in un dato contesto. Si distinguono poi le variabili indipendenti (o predittive), che influenzano le variabili dipendenti, e le variabili dipendenti, che rappresentano gli esiti di interesse.\n\n\n3.4.4 Effetti\nIn statistica, un effetto misura il cambiamento osservato nelle variabili dipendenti in relazione alle variabili indipendenti. Ad esempio, l’efficacia di una terapia può essere valutata misurando la differenza nei sintomi prima e dopo il trattamento (Huntington-Klein, 2021).\n\n\n3.4.5 Stima e Inferenza\n\n3.4.5.1 Stima\nLa stima statistica consente di ottenere informazioni su una popolazione a partire da un campione. Si utilizzano statistiche campionarie (come la media campionaria) per stimare i parametri della popolazione (come la media vera della popolazione).\nGli stimatori devono possedere proprietà come:\n\nconsistenza: la stima converge al vero valore del parametro all’aumentare della dimensione del campione;\nnon distorsione: il valore atteso dello stimatore è uguale al vero valore del parametro;\nefficienza: lo stimatore ha la minor varianza possibile.\n\nL’accuratezza della stima dipende da vari fattori, tra cui la dimensione e la rappresentatività del campione, la variabilità nella popolazione e il metodo di campionamento utilizzato.\n\n\n\n3.4.6 Inferenza Statistica\nDopo aver ottenuto le stime, l’inferenza statistica permette di trarre conclusioni più generali sulla popolazione. Essa consente di valutare ipotesi specifiche o rispondere a domande di ricerca basate sui dati raccolti.\nAd esempio, se abbiamo stimato la media del rendimento accademico in un campione di studenti, l’inferenza statistica ci consente di quantificare l’incertezza riguardo alla differenza di rendimento tra maschi e femmine all’interno della popolazione più ampia. In questo modo, l’inferenza statistica ci fornisce gli strumenti per fare previsioni e trarre conclusioni su fenomeni che riguardano l’intera popolazione.\nEsistono due approcci principali.\nL’inferenza bayesiana:\n\nSi basa sul teorema di Bayes;\nUtilizza probabilità a priori, che riflettono conoscenze o credenze iniziali su un fenomeno;\nAggiorna queste probabilità con nuovi dati per ottenere probabilità a posteriori;\nFornisce una interpretazione delle probabilità come gradi di credenza soggettivi.\n\nL’approccio frequentista:\n\nSi fonda sulla frequenza relativa di eventi osservati in esperimenti ripetuti;\nUtilizza strumenti come il test di ipotesi nulla e gli intervalli di confidenza per trarre conclusioni;\nNon fa uso di probabilità a priori, concentrandosi esclusivamente sui dati osservati.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#le-sfide-dellinferenza-statistica-in-psicologia",
    "href": "chapters/key_notions/01_key_notions.html#le-sfide-dellinferenza-statistica-in-psicologia",
    "title": "3  Concetti chiave",
    "section": "3.5 Le Sfide dell’Inferenza Statistica in Psicologia",
    "text": "3.5 Le Sfide dell’Inferenza Statistica in Psicologia\nSecondo (gelman2020regression?), l’inferenza statistica in psicologia affronta tre sfide principali:\n\nGeneralizzare dai campioni alla popolazione: Questa sfida è strettamente legata al problema del campionamento di comodo, spesso usato in psicologia, ma presente in quasi tutte le applicazioni dell’inferenza statistica. La difficoltà risiede nel trarre conclusioni affidabili su una popolazione più ampia partendo da un campione limitato e, a volte, non rappresentativo.\nGeneralizzare dal gruppo trattato al gruppo di controllo: Questa sfida riguarda l’inferenza causale, un aspetto centrale per determinare l’efficacia dei trattamenti psicologici. L’obiettivo è stabilire se i risultati osservati nel gruppo trattato possano essere applicati al gruppo di controllo o ad altre popolazioni, permettendo una valutazione valida dell’effetto del trattamento.\nGeneralizzare dalle misurazioni osservate ai costrutti sottostanti: In psicologia, i dati raccolti non corrispondono mai perfettamente ai costrutti teorici di interesse. La sfida è inferire questi costrutti latenti dai dati osservati, che rappresentano spesso solo un’approssimazione imperfetta.\n\nQueste sfide evidenziano la complessità dell’inferenza in psicologia e la necessità di metodologie robuste per affrontarle.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#riflessioni-conclusive",
    "href": "chapters/key_notions/01_key_notions.html#riflessioni-conclusive",
    "title": "3  Concetti chiave",
    "section": "3.6 Riflessioni Conclusive",
    "text": "3.6 Riflessioni Conclusive\nIn psicologia, le teorie forniscono ipotesi testabili che spiegano il “come” e il “perché” di determinati fenomeni mentali e comportamentali. Una teoria robusta permette di formulare previsioni chiare e specifiche, che possono essere verificate empiricamente attraverso l’analisi dei dati. Ad esempio, una teoria sull’ansia potrebbe prevedere che, in un compito di esposizione graduale a stimoli ansiogeni, il livello di ansia diminuisca progressivamente. Senza una teoria che spieghi perché questo dovrebbe accadere, tale osservazione rimane solo un dato descrittivo, privo di valore esplicativo o predittivo.\nL’analisi dei dati diventa davvero potente quando è integrata a una teoria. Senza teoria, i dati possono descrivere fenomeni ma non spiegare i meccanismi sottostanti. La teoria fornisce il contesto interpretativo, orientando la raccolta e l’analisi dei dati, e permettendo una comprensione profonda dei fenomeni psicologici.\nUn esempio è l’uso della data science per analizzare l’efficacia di un trattamento psicoterapeutico. I dati possono mostrarci una diminuzione dei sintomi in seguito alla terapia, ma è solo la teoria alla base del trattamento che fornisce un quadro interpretativo per questo miglioramento, proponendo i meccanismi per cui il trattamento riduce i sintomi. La teoria orienta quindi l’analisi e permette di interpretare i dati in un contesto scientifico.\nSviluppare una teoria in psicologia è complesso a causa della notevole variabilità umana. Un buon modello psicologico deve prevedere con precisione i comportamenti osservabili e rappresentare i processi mentali latenti. Queste previsioni devono essere testabili e falsificabili (Eronen & Bringmann, 2021).\nLa relazione tra teoria e analisi dei dati è dinamica e iterativa. I modelli e le teorie si evolvono grazie alla verifica empirica. Se i dati non supportano le previsioni di una teoria, essa viene modificata o sostituita, favorendo l’avanzamento scientifico.\nIn conclusione, la teoria e l’analisi dei dati sono complementari e interdipendenti. L’analisi dei dati offre gli strumenti per testare e affinare le teorie psicologiche, mentre la teoria dà significato e contesto ai dati, rendendo possibile una comprensione profonda e utile dei fenomeni psicologici.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#bibliografia",
    "href": "chapters/key_notions/01_key_notions.html#bibliografia",
    "title": "3  Concetti chiave",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nEronen, M. I., & Bringmann, L. F. (2021). The theory crisis in psychology: How to move forward. Perspectives on Psychological Science, 16(4), 779–788.\n\n\nHuntington-Klein, N. (2021). The effect: An introduction to research design and causality. Chapman; Hall/CRC.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nMurray, E. J., & Carr, K. C. (2024). Measuring Racial Sentiment Using Social Media Is Harder Than It Seems. Epidemiology, 35(1), 60–63.\n\n\nNobles, M. (2000). Shades of citizenship: Race and the census in modern politics. Stanford University Press.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_measurement.html",
    "href": "chapters/key_notions/02_measurement.html",
    "title": "4  La misurazione in psicologia",
    "section": "",
    "text": "4.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nLa scienza si avvale di modelli per interpretare i dati, ma opera sempre con teorie incomplete e misurazioni soggette a errori. Di conseguenza, è fondamentale riconoscere le incertezze quando si cerca di estrarre informazioni dalle misurazioni utilizzando i nostri modelli. Nessuna misurazione, spiegazione o previsione è perfettamente accurata e precisa, e non possiamo mai conoscere con esattezza l’entità dei loro errori.\nQuesta incertezza viene catturata in tre equazioni fondamentali. La prima è l’Equazione di Misurazione, che riconosce l’errore osservativo: \\(y = z + \\varepsilon_y\\), dove \\(y\\) rappresenta il valore misurato, \\(z\\) il valore reale e \\(\\varepsilon_y\\) l’errore di misurazione. La seconda è l’Equazione di Modellazione, che esprime la presenza di un diverso tipo di errore: \\(z = f(x, \\theta) + \\varepsilon_\\text{model}\\), dove \\(f\\) è il modello, \\(x\\) sono le condizioni ambientali per cui eseguiamo il modello, \\(\\theta\\) sono i valori dei parametri del modello e \\(\\varepsilon_\\text{model}\\) rappresenta l’errore del modello, che sorge perché \\(f\\), \\(x\\) e \\(\\theta\\) saranno tutti in qualche misura imprecisi.\nCombinando queste due equazioni, otteniamo l’Equazione della Scienza: \\(y = f(x, \\theta) + \\varepsilon_\\text{model} + \\varepsilon_y\\). La scienza è il tentativo di spiegare le osservazioni \\(y\\) utilizzando un modello \\(f\\), cercando di minimizzare l’errore di misurazione \\(\\varepsilon_y\\) e l’errore del modello \\(\\varepsilon_\\text{model}\\), in modo che il modello possa essere utilizzato per fare previsioni sul mondo reale (\\(z\\)). L’approccio bayesiano alla scienza riconosce e quantifica le incertezze su tutti e sei gli elementi dell’Equazione della Scienza: \\(y\\), \\(f\\), \\(x\\), \\(\\theta\\), \\(\\varepsilon_\\text{model}\\) e \\(\\varepsilon_y\\).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_measurement.html#la-teoria-della-misurazione",
    "href": "chapters/key_notions/02_measurement.html#la-teoria-della-misurazione",
    "title": "4  La misurazione in psicologia",
    "section": "4.2 La teoria della Misurazione",
    "text": "4.2 La teoria della Misurazione\nLa teoria della misurazione, oggetto di questo capitolo, si concentra sull’errore di misurazione e sull’equazione fondamentale \\(y = z + \\varepsilon_y\\). Questa equazione può essere esaminata da tre prospettive distinte. La prima concerne l’affidabilità della misura, rappresentata dal termine \\(\\varepsilon_y\\). La psicometria, branca dedicata alla teoria della misurazione psicologica, si occupa di quantificare l’affidabilità delle misure psicologiche attraverso metodi come la Teoria Classica dei Test e la Teoria di Risposta all’Item.\nLa seconda prospettiva riguarda la validità delle misure psicologiche, ovvero quanto adeguatamente la misura \\(y\\) rappresenti il costrutto \\(z\\). Questo aspetto, più complesso dell’affidabilità, non può essere risolto meramente con metodi statistici, ma richiede una profonda comprensione delle teorie psicologiche e della loro capacità di descrivere e prevedere i fenomeni psicologici.\nLa terza prospettiva si concentra sulle procedure di assegnazione dei valori a \\(y\\), esplorando quali metodi (questionari, interviste, esperimenti) siano più appropriati e come valutarne l’adeguatezza.\n\n4.2.1 Costrutti Psicologici\nLa teoria della misurazione sottolinea l’importanza di distinguere tra la procedura di misurazione e il costrutto che si intende misurare. Ad esempio, mentre la temperatura è un costrutto, il termometro è lo strumento di misurazione. Analogamente, l’abilità matematica è un costrutto, mentre un test di matematica è la procedura per misurarla.\nNelle scienze psicologiche e sociali, la misurazione presenta sfide uniche rispetto alle scienze fisiche, poiché i costrutti in esame sono spesso astratti e non direttamente osservabili. Ciò richiede una particolare attenzione alla validità e all’affidabilità degli strumenti di misurazione, nonché una costante riflessione sulle limitazioni e le potenziali fonti di errore.\nIl capitolo introduce concetti fondamentali relativi alla misurazione quantitativa delle caratteristiche psicologiche, con un focus sulla teoria delle scale di misura di Stevens (1946). Questa teoria fornisce un quadro concettuale per comprendere i diversi tipi di scale di misurazione e le operazioni matematiche appropriate per ciascuna. Inoltre, vengono esplorate alcune procedure di scaling psicologico, ovvero l’assegnazione di numeri all’intensità di fenomeni psicologici.\n\n\n4.2.2 Scaling Psicologico\nLo scaling psicologico si occupa della trasformazione dei dati empirici raccolti durante uno studio psicologico in misure o punteggi che rappresentino accuratamente le caratteristiche psicologiche oggetto di indagine.\nScaling di Guttman. Uno dei metodi di scaling più noti è lo «Scaling di Guttman», che viene utilizzato per rappresentare relazioni ordinate tra gli elementi di una scala. Ad esempio, in un questionario sui sintomi dell’ansia, le domande possono essere disposte in ordine di intensità crescente dei sintomi. Secondo il modello di Guttman, se un partecipante risponde “sì” a una domanda che riflette un sintomo più intenso, ci si aspetta che abbia risposto “sì” anche a tutte le domande precedenti, che rappresentano sintomi di intensità minore. Questo approccio consente di costruire una scala che riflette in modo sistematico e coerente la gravità dei sintomi.\nScaling Thurstoniano. Lo «Scaling Thurstoniano» è un metodo utilizzato per misurare preferenze o giudizi soggettivi. Ad esempio, per valutare la preferenza tra diversi tipi di cibi, i partecipanti confrontano due cibi alla volta ed esprimono una preferenza. Le risposte vengono poi utilizzate per assegnare punteggi che riflettono la preferenza media per ciascun cibo.\nQuestionari Likert. I questionari Likert richiedono ai partecipanti di esprimere il loro grado di accordo con una serie di affermazioni su una scala a più livelli, che va da «fortemente in disaccordo» a «fortemente d’accordo». I punteggi ottenuti vengono sommati per rappresentare la posizione complessiva dell’individuo rispetto all’oggetto di studio.\n\n\n4.2.3 Metodi di Valutazione delle Scale Psicologiche\nPer valutare le proprietà delle scale psicologiche, vengono utilizzati vari metodi. Ad esempio, l’affidabilità delle misure può essere analizzata utilizzando il coefficiente alpha di Cronbach o il coefficiente Omega di McDonald, entrambi utilizzati per misurare la coerenza interna delle risposte ai diversi item di un questionario. Inoltre, la validità delle scale può essere esaminata confrontando i risultati ottenuti con misure simili o attraverso analisi statistiche che verificano se la scala cattura accuratamente il costrutto psicologico che si intende misurare. La validità di costrutto è particolarmente cruciale, poiché riguarda la capacità della scala di misurare effettivamente il concetto psicologico che si intende esplorare.\n\n\n4.2.4 Prospettive Moderne\nNegli ultimi anni, il dibattito sulla misurazione psicologica si è arricchito di nuove prospettive, grazie all’avvento di tecnologie avanzate e all’integrazione di approcci interdisciplinari. Ecco alcune delle tendenze più rilevanti.\nTeoria della Risposta agli Item. La Teoria della Risposta agli Item (IRT) ha guadagnato popolarità per la sua capacità di fornire stime più precise delle abilità latenti rispetto ai modelli classici. La IRT considera la probabilità che un individuo risponda correttamente a un item in funzione della sua abilità e delle caratteristiche dell’item stesso, offrendo una visione più dettagliata delle proprietà psicometriche degli strumenti di misurazione.\nApprocci Bayesiani. Gli approcci bayesiani stanno rivoluzionando il campo della psicometria, permettendo di incorporare informazioni a priori nelle stime e di aggiornare le credenze sulla base di nuovi dati. Questi metodi sono particolarmente utili per affrontare la complessità e l’incertezza inerenti alla misurazione psicologica.\nAnalisi di Rete. L’analisi di rete è un’altra metodologia emergente che vede i costrutti psicologici non come variabili latenti indipendenti, ma come reti di sintomi interconnessi. Questo approccio può offrire nuove intuizioni sulla struttura delle psicopatologie e sulla dinamica dei sintomi.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_measurement.html#le-scale-di-misurazione",
    "href": "chapters/key_notions/02_measurement.html#le-scale-di-misurazione",
    "title": "4  La misurazione in psicologia",
    "section": "4.3 Le scale di misurazione",
    "text": "4.3 Le scale di misurazione\nLe scale di misurazione sono strumenti fondamentali per assegnare numeri ai dati osservati, rappresentando le proprietà psicologiche. La teoria delle scale di Stevens Stevens (1946) identifica quattro tipi di scale di misurazione: nominali, ordinali, a intervalli e di rapporti. Ognuna di queste scale consente di effettuare operazioni aritmetiche diverse, poiché ciascuna di esse è in grado di “catturare” solo alcune delle proprietà dei fenomeni psicologici che si intende misurare.\n\n\n\nScale di misurazione.\n\n\n\n4.3.1 Scala nominale\nILa scala nominale è il livello di misurazione più semplice e corrisponde ad una tassonomia o classificazione delle categorie che utilizziamo per descrivere i fenomeni psicologici. I simboli o numeri che costituiscono questa scala rappresentano i nomi delle categorie e non hanno alcun valore numerico intrinseco. Con la scala nominale possiamo solo distinguere se una caratteristica psicologica è uguale o diversa da un’altra.\nI dati raccolti con la scala nominale sono suddivisi in categorie qualitative e mutuamente esclusive, in cui ogni dato appartiene ad una sola categoria. In questa scala, esiste solo la relazione di equivalenza tra le misure delle unità di studio: gli elementi del campione appartenenti a classi diverse sono differenti, mentre tutti quelli della stessa classe sono tra loro equivalenti.\nL’unica operazione algebrica consentita dalla scala nominale è quella di contare le unità di studio che appartengono ad ogni categoria e il numero totale di categorie. Di conseguenza, la descrizione dei dati avviene tramite le frequenze assolute e le frequenze relative.\nDalla scala nominale è possibile costruire altre scale nominali equivalenti alla prima, trasformando i valori della scala di partenza in modo tale da cambiare i nomi delle categorie, ma lasciando inalterata la suddivisione delle unità di studio nelle medesime classi di equivalenza. In altre parole, cambiando i nomi delle categorie di una variabile misurata su scala nominale, si ottiene una nuova variabile esattamente equivalente alla prima.\n\n\n4.3.2 Scala ordinale\nLa scala ordinale mantiene la caratteristica della scala nominale di classificare ogni unità di misura all’interno di una singola categoria, ma introduce la relazione di ordinamento tra le categorie. In quanto basata su una relazione di ordine, una scala ordinale descrive solo il rango di ordine tra le categorie e non fornisce informazioni sulla distanza tra di esse. Non ci dice, ad esempio, se la distanza tra le categorie \\(a\\) e \\(b\\) è uguale, maggiore o minore della distanza tra le categorie \\(b\\) e \\(c\\).\nUn esempio classico di scala ordinale è quello della scala Mohs per la determinazione della durezza dei minerali. Per stabilire la durezza dei minerali si usa il criterio empirico della scalfittura. Vengono stabiliti livelli di durezza crescente da 1 a 10 con riferimento a dieci minerali: talco, gesso, calcite, fluorite, apatite, ortoclasio, quarzo, topazio, corindone e diamante. Un minerale appartenente ad uno di questi livelli se scalfisce quello di livello inferiore ed è scalfito da quello di livello superiore.\n\n\n\nLa scala di durezza dei minerali di Mohs. Un oggetto è considerato più duro di X se graffia X. Sono incluse anche misure di durezza relativa utilizzando uno sclerometro, da cui emerge la non linearità della scala di Mohs (Burchard, 2004).\n\n\n\n\n4.3.3 Scala ad intervalli\nLa scala ad intervalli di misurazione include le proprietà della scala nominale e della scala ordinale e permette di misurare le distanze tra le coppie di unità statistiche in termini di un intervallo costante, chiamato “unità di misura”, a cui viene attribuito il valore “1”. L’origine della scala, ovvero il punto zero, è scelta arbitrariamente e non indica l’assenza della proprietà che si sta misurando. Ciò significa che la scala ad intervalli consente anche valori negativi e lo zero non viene attribuito all’unità statistica in cui la proprietà risulta assente.\nLa scala ad intervalli equivalenti consente l’esecuzione di operazioni algebriche basate sulla differenza tra i numeri associati ai diversi punti della scala, operazioni algebriche non possibili con le scale di misura nominale o ordinale. Tuttavia, il limite della scala ad intervalli è che non consente di calcolare il rapporto tra coppie di misure. È possibile affermare la differenza tra \\(a\\) e \\(b\\) come la metà della differenza tra \\(c\\) e \\(d\\) o che le due differenze sono uguali, ma non è possibile affermare che \\(a\\) abbia una proprietà misurata in quantità doppia rispetto a \\(b\\). In altre parole, non è possibile stabilire rapporti diretti tra le misure ottenute. Solo le differenze tra le modalità permettono tutte le operazioni aritmetiche, come la somma, l’elevazione a potenza o la divisione, che sono alla base della statistica inferenziale.\nNelle scale ad intervalli equivalenti, l’unità di misura è arbitraria e può essere cambiata attraverso una dilatazione, ovvero la moltiplicazione di tutti i valori della scala per una costante positiva. Inoltre, la traslazione, ovvero l’aggiunta di una costante a tutti i valori della scala, è ammessa poiché non altera le differenze tra i valori della scala. La scala rimane invariata rispetto a traslazioni e dilatazioni e dunque le uniche trasformazioni ammissibili sono le trasformazioni lineari:\n\\[\ny' = a + by, \\quad b &gt; 0.\n\\]\nInfatti, l’uguaglianza dei rapporti fra gli intervalli rimane invariata a seguito di una trasformazione lineare.\nEsempio di scala ad intervalli è la temperatura misurata in gradi Celsius o Fahrenheit, ma non Kelvin. Come per la scala nominale, è possibile stabilire se due modalità sono uguali o diverse: 30\\(^\\circ\\)C \\(\\neq\\) 20\\(^\\circ\\)C. Come per la scala ordinale è possibile mettere due modalità in una relazione d’ordine: 30\\(^\\circ\\)C \\(&gt;\\) 20\\(^\\circ\\)C. In aggiunta ai casi precedenti, però, è possibile definire una unità di misura per cui è possibile dire che tra 30\\(^\\circ\\)C e 20\\(^\\circ\\)C c’è una differenza di 30\\(^\\circ\\) - 20\\(^\\circ\\) = 10\\(^\\circ\\)C. I valori di temperatura, oltre a poter essere ordinati secondo l’intensità del fenomeno, godono della proprietà che le differenze tra loro sono direttamente confrontabili e quantificabili.\nIl limite della scala ad intervalli è quello di non consentire il calcolo del rapporto tra coppie di misure. Ad esempio, una temperatura di 80\\(^\\circ\\)C non è il doppio di una di 40\\(^\\circ\\)C. Se infatti esprimiamo le stesse temperature nei termini della scala Fahrenheit, allora i due valori non saranno in rapporto di 1 a 2 tra loro. Infatti, 20\\(^\\circ\\)C = 68\\(^\\circ\\)F e 40\\(^\\circ\\)C = 104\\(^\\circ\\)F. Questo significa che la relazione “il doppio di” che avevamo individuato in precedenza si applicava ai numeri della scala centigrada, ma non alla proprietà misurata (cioè la temperatura). La decisione di che scala usare (Centigrada vs. Fahrenheit) è arbitraria. Ma questa arbitrarietà non deve influenzare le inferenze che traiamo dai dati. Queste inferenze, infatti, devono dirci qualcosa a proposito della realtà empirica e non possono in nessun modo essere condizionate dalle nostre scelte arbitrarie che ci portano a scegliere la scala Centigrada piuttosto che quella Fahrenheit.\nConsideriamo ora l’aspetto invariante di una trasformazione lineare, ovvero l’uguaglianza dei rapporti fra intervalli. Prendiamo in esame, ad esempio, tre temperature: \\(20^\\circ C = 68^\\circ F\\), \\(15^\\circ C = 59^\\circ F\\), \\(10^\\circ C = 50 ^\\circ F\\).\nÈ facile rendersi conto del fatto che i rapporti fra intervalli restano costanti indipendentemente dall’unità di misura che è stata scelta:\n\\[\n  \\frac{20^\\circ C - 10^\\circ C}{20^\\circ C - 15^\\circ C} =\n  \\frac{68^\\circ F - 50^\\circ F}{68^\\circ F-59^\\circ F} = 2.\n\\]\n\n\n4.3.4 Scala di rapporti\nNella scala a rapporti equivalenti, lo zero non è arbitrario e rappresenta l’elemento che ha intensità nulla rispetto alla proprietà misurata. Per costruire questa scala, si associa il numero 0 all’elemento con intensità nulla e si sceglie un’unità di misura \\(u\\). Ad ogni elemento si assegna un numero \\(a\\) definito come \\(a=d/u\\), dove \\(d\\) rappresenta la distanza dall’origine. In questo modo, i numeri assegnati riflettono le differenze e i rapporti tra le intensità della proprietà misurata.\nIn questa scala, è possibile effettuare operazioni aritmetiche non solo sulle differenze tra i valori della scala, ma anche sui valori stessi della scala. L’unica scelta arbitraria è l’unità di misura, ma lo zero deve sempre rappresentare l’intensità nulla della proprietà considerata.\nLe trasformazioni ammissibili in questa scala sono chiamate trasformazioni di similarità e sono del tipo \\(y' = by\\), dove \\(b&gt;0\\). In questa scala, i rapporti tra i valori rimangono invariati dopo le trasformazioni. In altre parole, se rapportiamo due valori originali e due valori trasformati, il rapporto rimane lo stesso: \\(\\frac{y_i}{y_j} = \\frac{y'_i}{y'_j}\\).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_measurement.html#gerarchia-dei-livelli-delle-scale-di-misurazione",
    "href": "chapters/key_notions/02_measurement.html#gerarchia-dei-livelli-delle-scale-di-misurazione",
    "title": "4  La misurazione in psicologia",
    "section": "4.4 Gerarchia dei livelli delle scale di misurazione",
    "text": "4.4 Gerarchia dei livelli delle scale di misurazione\nSecondo Stevens (1946), esiste una gerarchia dei livelli delle scale di misurazione, denominati “livelli di scala”. Questi livelli sono organizzati in modo gerarchico, in cui la scala nominale rappresenta il livello più basso della misurazione, mentre la scala a rapporti equivalenti rappresenta il livello più alto.\n\nLa scala nominale è il livello più elementare, in cui le categorie o le etichette vengono assegnate agli oggetti o agli individui senza alcuna valutazione di grandezza o ordine.\nAl livello successivo si trova la scala ordinale, in cui le categorie sono ordinate in base a una qualche qualità o caratteristica. Qui, è possibile stabilire un ordine di preferenza o gerarchia tra le categorie, ma non è possibile quantificare la differenza tra di esse in modo preciso.\nLa scala intervallo rappresenta un livello successivo, in cui le categorie sono ordinate e la differenza tra di esse è quantificabile in modo preciso. In questa scala, è possibile effettuare operazioni matematiche come l’addizione e la sottrazione tra i valori, ma non è possibile stabilire un vero e proprio punto zero significativo.\nInfine, la scala a rapporti equivalenti rappresenta il livello più alto. In questa scala, le categorie sono ordinate, la differenza tra di esse è quantificabile in modo preciso e esiste un punto zero assoluto che rappresenta l’assenza totale della grandezza misurata. Questo livello di scala permette di effettuare tutte le operazioni matematiche, compresa la moltiplicazione e la divisione.\n\nPassando da un livello di misurazione ad uno più alto aumenta il numero di operazioni aritmetiche che possono essere compiute sui valori della scala, come indicato nella figura seguente.\n\n\n\nRelazioni tra i livelli di misurazione.\n\n\nPer ciò che riguarda le trasformazioni ammissibili, più il livello di scala è basso, più le funzioni sono generali (sono minori cioè i vincoli per passare da una rappresentazione numerica ad un’altra equivalente). Salendo la gerarchia, la natura delle funzioni di trasformazione si fa più restrittiva.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_measurement.html#variabili-discrete-o-continue",
    "href": "chapters/key_notions/02_measurement.html#variabili-discrete-o-continue",
    "title": "4  La misurazione in psicologia",
    "section": "4.5 Variabili discrete o continue",
    "text": "4.5 Variabili discrete o continue\nLe variabili possono essere classificate come variabili a livello di intervalli o di rapporti e possono essere sia discrete che continue.\n\nLe variabili discrete assumono valori specifici ma non possono assumere valori intermedi. Una volta che l’elenco dei valori accettabili è stato definito, non vi sono casi che si trovano tra questi valori. In genere, le variabili discrete assumono valori interi, come il numero di eventi, il numero di persone o il numero di oggetti.\nD’altra parte, le variabili continue possono assumere qualsiasi valore all’interno di un intervallo specificato. Teoricamente, ciò significa che è possibile utilizzare frazioni e decimali per ottenere qualsiasi grado di precisione.\n\n\n\n\nVariabili discrete e continue.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_measurement.html#comprendere-gli-errori-nella-misurazione",
    "href": "chapters/key_notions/02_measurement.html#comprendere-gli-errori-nella-misurazione",
    "title": "4  La misurazione in psicologia",
    "section": "4.6 Comprendere gli errori nella misurazione",
    "text": "4.6 Comprendere gli errori nella misurazione\nGli errori di misurazione possono essere casuali o sistematici. Gli errori casuali sono fluttuazioni aleatorie, mentre gli errori sistematici sono costanti e derivano da problemi nel metodo di misurazione o negli strumenti.\n\n4.6.1 Precisione e Accuratezza\nLa precisione indica la coerenza tra misurazioni ripetute, mentre l’accuratezza si riferisce alla vicinanza del valore misurato al valore reale. Entrambi i concetti sono cruciali per l’assessment psicometrico.\nUtilizzando l’analogia del tiro al bersaglio, si può avere una serie di colpi vicini tra loro ma lontani dal centro (precisione senza accuratezza) oppure colpi distribuiti in modo sparso ma in media vicini al centro (accuratezza senza precisione).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_measurement.html#assessment-psicometrico",
    "href": "chapters/key_notions/02_measurement.html#assessment-psicometrico",
    "title": "4  La misurazione in psicologia",
    "section": "4.7 Assessment psicometrico",
    "text": "4.7 Assessment psicometrico\nL’assessment psicometrico valuta la qualità delle misurazioni psicologiche, considerando la validità e l’affidabilità.\n\n4.7.1 Validità nella Misurazione Psicologica\nLa validità è una proprietà psicometrica fondamentale dei test psicologici. Secondo gli Standards for Educational and Psychological Testing (2014), la validità si riferisce al grado in cui evidenza e teoria supportano le interpretazioni dei punteggi dei test per gli usi proposti. Questo concetto evidenzia che la validità riguarda sia il significato dei punteggi sia il loro utilizzo, rendendola “la considerazione più fondamentale nello sviluppo e nella valutazione dei test”.\n\n\n4.7.2 Evoluzione del Concetto di Validità\nTradizionalmente, la validità era suddivisa in tre categorie:\n\nValidità di Contenuto: Si riferisce alla corrispondenza tra il contenuto degli item di un test e il dominio dell’attributo psicologico che il test intende misurare. È importante che gli item siano pertinenti e rappresentativi dell’attributo misurato.\nValidità di Criterio: Valuta il grado di concordanza tra i risultati ottenuti tramite lo strumento di misurazione e i risultati ottenuti da altri strumenti che misurano lo stesso costrutto o da un criterio esterno. Include validità concorrente e predittiva.\nValidità di Costrutto: Riguarda il grado in cui un test misura effettivamente il costrutto che si intende misurare. Si suddivide in validità convergente (accordo con strumenti che misurano lo stesso costrutto) e validità divergente (capacità di discriminare tra costrutti diversi).\n\nLa moderna teoria della validità non adotta più questa visione tripartita. Gli Standards del 2014 descrivono la validità come un concetto unitario, dove diverse forme di evidenza concorrono a supportare l’interpretazione dei punteggi del test per il loro utilizzo previsto.\n\n\n4.7.3 Tipologie di Prove di Validità\nGli Standards del 2014 identificano cinque categorie principali di prove di validità:\n\nProve Basate sul Contenuto del Test: Valutano quanto il contenuto del test rappresenti adeguatamente il dominio del costrutto da misurare.\nProve Basate sui Processi di Risposta: Analizzano se i processi cognitivi e comportamentali degli esaminandi riflettono il costrutto valutato.\nProve Basate sulla Struttura Interna: Esaminano la coerenza tra gli elementi del test e la struttura teorica del costrutto. L’analisi fattoriale è uno strumento chiave in questo contesto.\nProve Basate sulle Relazioni con Altre Variabili: Studiano la correlazione tra i punteggi del test e altre variabili teoricamente correlate, utilizzando metodi come la validità convergente e divergente.\nProve Basate sulle Conseguenze del Test: Considerano le implicazioni e gli effetti dell’uso del test, sia intenzionali che non intenzionali.\n\n\n\n4.7.4 Minacce alla Validità\nLa validità può essere compromessa quando un test non misura integralmente il costrutto di interesse (sotto-rappresentazione del costrutto) o quando include varianza estranea al costrutto. Inoltre, fattori esterni come l’ansia o la bassa motivazione degli esaminandi, e deviazioni nelle procedure di amministrazione e valutazione, possono influenzare negativamente la validità delle interpretazioni dei risultati.\n\n\n4.7.5 Integrazione delle Prove di Validità\nLa validità di un test si costruisce attraverso l’integrazione di diverse linee di evidenza. Ogni interpretazione o uso di un test deve essere validato specificamente, richiedendo una valutazione continua e accurata delle prove disponibili. Questo processo implica la costruzione di un argomento di validità che consideri attentamente la qualità tecnica del test e l’adeguatezza delle sue interpretazioni per gli scopi previsti.\nIn conclusione, la validità è un concetto complesso e integrato che richiede un’analisi continua e multidimensionale delle evidenze. La moderna teoria della validità enfatizza l’importanza di considerare diverse forme di evidenza per supportare le interpretazioni dei punteggi dei test, garantendo che siano utilizzati in modo appropriato e significativo. Gli sviluppatori e gli utilizzatori di test devono impegnarsi a valutare costantemente la validità per assicurare misurazioni psicologiche accurate e affidabili.\n\n\n4.7.6 Affidabilità\nL’affidabilità concerne la consistenza e stabilità delle misurazioni, verificata attraverso metodi come l’affidabilità test-retest, inter-rater, intra-rater e l’affidabilità interna.\n\nAffidabilità Test-Retest: Questa forma di affidabilità verifica la consistenza delle misurazioni nel tempo. Se un individuo viene testato in due momenti diversi, i risultati dovrebbero essere simili, assumendo che non ci siano stati cambiamenti significativi nel costrutto misurato.\nAffidabilità Inter-rater: In questo caso, l’affidabilità è determinata dalla concordanza tra le valutazioni di diversi esaminatori. Ad esempio, se più psicologi dovessero valutare un individuo utilizzando lo stesso strumento, le loro valutazioni dovrebbero essere simili.\nAffidabilità Intra-rater: Questa misura dell’affidabilità si riferisce alla consistenza delle valutazioni dello stesso esaminatore in momenti diversi.\nAffidabilità Interna: Si riferisce alla coerenza delle risposte all’interno dello stesso test. Ad esempio, se un test misura un costrutto come l’ansia, gli item che misurano l’ansia dovrebbero correlare positivamente l’uno con l’altro. Un modo comune per valutare l’affidabilità interna è utilizzare il coefficiente \\(\\omega\\) di McDonald.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_measurement.html#commenti-e-considerazioni-finali",
    "href": "chapters/key_notions/02_measurement.html#commenti-e-considerazioni-finali",
    "title": "4  La misurazione in psicologia",
    "section": "4.8 Commenti e considerazioni finali",
    "text": "4.8 Commenti e considerazioni finali\nLa teoria della misurazione è fondamentale nella ricerca empirica per valutare l’attendibilità e la validità delle misurazioni. È cruciale valutare l’errore nella misurazione per garantire la precisione e l’accuratezza delle misure. L’assessment psicometrico si occupa di valutare la qualità delle misurazioni psicologiche, considerando l’affidabilità e la validità per garantire misure accurate dei costrutti teorici. Le moderne tecnologie e metodologie stanno continuamente arricchendo questo campo, offrendo strumenti sempre più raffinati per la comprensione delle caratteristiche psicologiche.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_measurement.html#bibliografia",
    "href": "chapters/key_notions/02_measurement.html#bibliografia",
    "title": "4  La misurazione in psicologia",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nLilienfeld, S. O., & Strother, A. N. (2020). Psychological measurement and the replication crisis: Four sacred cows. Canadian Psychology/Psychologie Canadienne, 61(4), 281–288.\n\n\nMaul, A., Irribarra, D. T., & Wilson, M. (2016). On the philosophical foundations of psychological measurement. Measurement, 79, 311–320.\n\n\nStevens, S. S. (1946). On the theory of scales of measurement. Science, 103(2684), 677–680.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_data_analysis.html",
    "href": "chapters/key_notions/03_data_analysis.html",
    "title": "5  L’analisi dei dati psicologici",
    "section": "",
    "text": "Introduzione\nPrerequisiti\nConcetti e competenze chiave\nNel panorama contemporaneo delle scienze sociali e della psicologia, gli ultimi due decenni hanno visto l’emergere di una profonda trasformazione metodologica ed epistemologica. Questo movimento, caratterizzato da concetti chiave quali “Credibility Revolution” (Angrist & Pischke, 2010), “Causal Revolution” (Pearl & Mackenzie, 2018) e “Replication Crisis” (Collaboration, 2015), ha determinato un cambiamento paradigmatico nelle pratiche delle scienze sociali e, in particolare, della psicologia (Korbmacher et al., 2023). Questa transizione verso quella che Munger (2023) definisce “Science versione 2” è stata motivata dalle lacune metodologiche precedenti e ha catalizzato l’adozione di approcci più rigorosi e replicabili.\nLa genesi di questa Riforma è radicata nella constatazione di problematiche metodologiche pervasive, tra cui la proliferazione di falsi positivi (Simmons et al., 2011), l’abuso dei “gradi di libertà dei ricercatori” (Gelman & Loken, 2013), e l’inadeguatezza delle pratiche statistiche tradizionali (Gelman & Loken, 2014). Fenomeni come il p-hacking, l’uso di campioni sottodimensionati (Button et al., 2013), e la mancanza di trasparenza nei metodi di ricerca hanno contribuito a minare la credibilità delle scoperte psicologiche (Ioannidis, 2005; Meehl, 1967), portando alla cosiddetta “Replication Crisis” (Baker, 2016; Bishop, 2019) – si veda il ?sec-crisis.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>L'analisi dei dati psicologici</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_data_analysis.html#lapproccio-bayesiano",
    "href": "chapters/key_notions/03_data_analysis.html#lapproccio-bayesiano",
    "title": "5  L’analisi dei dati psicologici",
    "section": "5.1 L’Approccio Bayesiano",
    "text": "5.1 L’Approccio Bayesiano\nIn risposta a queste sfide, l’approccio bayesiano è emerso come un paradigma statistico fondamentale nella “Credibility Revolution”. Contrariamente all’inferenza frequentista basata sul Test dell’Ipotesi Nulla, la statistica bayesiana offre un framework più flessibile e intuitivo per l’analisi dei dati e l’inferenza causale. Il principio cardine dell’approccio bayesiano, l’aggiornamento delle distribuzioni di probabilità a priori (priors) alla luce di nuove evidenze, si allinea perfettamente con l’obiettivo di una scienza cumulativa e auto-correttiva.\nL’adozione di metodi bayesiani in psicologia comporta diversi vantaggi significativi:\n\nQuantificazione dell’incertezza: L’inferenza bayesiana fornisce distribuzioni di probabilità posteriori complete per i parametri di interesse, offrendo una rappresentazione più ricca e sfumata dell’incertezza rispetto agli intervalli di confidenza frequentisti.\nIncorporazione di conoscenze pregresse: Le priors bayesiane consentono l’integrazione formale di conoscenze precedenti nel processo inferenziale, promuovendo un approccio cumulativo alla ricerca.\nRobustezza alle pratiche di ricerca discutibili: I metodi bayesiani sono meno suscettibili a pratiche come il p-hacking, poiché l’inferenza si basa sull’intera distribuzione posteriore piuttosto che su soglie arbitrarie di significatività.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>L'analisi dei dati psicologici</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_data_analysis.html#lapproccio-bayesiano-nella-ricerca",
    "href": "chapters/key_notions/03_data_analysis.html#lapproccio-bayesiano-nella-ricerca",
    "title": "5  L’analisi dei dati psicologici",
    "section": "5.2 L’approccio bayesiano nella ricerca",
    "text": "5.2 L’approccio bayesiano nella ricerca\nL’impiego delle statistiche bayesiane nella ricerca psicologica presenta notevoli vantaggi rispetto ad altri metodi statistici tradizionali, come il test di significatività dell’ipotesi nulla. Un punto di forza importante risiede nella sua indipendenza dalla teoria dei grandi campioni, rendendolo particolarmente adatto per gli studi psicologici che spesso si basano su campioni di dimensioni ridotte (Larson et al., 2023).\nLa ricerca psicologica è frequentemente caratterizzata da campioni limitati, dovuti a diversi fattori quali la bassa prevalenza di determinate condizioni, le difficoltà nel reclutamento dei partecipanti e le complessità nelle procedure di valutazione. Questi campioni di piccole dimensioni sono intrinsecamente soggetti a una maggiore eterogeneità, che si manifesta nella variabilità del fenotipo comportamentale delle condizioni psicologiche esaminate e nella discrepanza tra le stime degli effetti in diversi studi. Tale eterogeneità può condurre a stime degli effetti distorte e scarsamente riproducibili.\nL’approccio bayesiano offre una soluzione efficace a queste problematiche. In primo luogo, consente di valutare l’adeguatezza della dimensione del campione attraverso un’analisi della sensibilità dei risultati rispetto alla specificazione delle distribuzioni a priori. In secondo luogo, permette di ottenere risultati precisi anche con campioni ridotti, a condizione che le conoscenze a priori siano accurate e ben definite.\nUn ulteriore vantaggio dell’approccio bayesiano è la sua capacità di ottimizzare l’uso dei campioni di partecipanti, favorendo un’inclusione equa delle popolazioni diversificate. Questo è particolarmente rilevante per gruppi spesso sottorappresentati, come le minoranze etniche. Le statistiche bayesiane aiutano a superare questa sfida evitando di esercitare una pressione eccessiva su questi gruppi per aumentarne la partecipazione, permettendo così una ricerca più equa e rappresentativa.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>L'analisi dei dati psicologici</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_data_analysis.html#modellazione-formale",
    "href": "chapters/key_notions/03_data_analysis.html#modellazione-formale",
    "title": "5  L’analisi dei dati psicologici",
    "section": "5.3 Modellazione Formale",
    "text": "5.3 Modellazione Formale\nLa “Credibility Revolution” ha catalizzato l’integrazione della Data Science nelle pratiche di ricerca psicologica. L’adozione di pipeline di analisi dei dati riproducibili, l’uso di controllo di versione, e la condivisione di dati e codice sono diventati standard de facto nella comunità scientifica. Questi strumenti non solo migliorano la trasparenza e la replicabilità della ricerca, ma facilitano anche la collaborazione e l’accumulo di conoscenze nel campo.\nParallelamente, si è osservato un rinnovato interesse per la modellazione formale in psicologia, che consente non solo la verifica ma anche lo sviluppo di modelli dei meccanismi sottostanti ai fenomeni psicologici (Oberauer & Lewandowsky, 2019; Van Dongen et al., 2024). Questo approccio supera la mera descrizione delle associazioni tra variabili, che era tipica della pratica dominante dell’ANOVA nel contesto pre-riforma.\nLa modellazione bayesiana si presta particolarmente bene a questo approccio, offrendo un framework unificato per la specificazione di modelli formali, l’incorporazione di incertezza parametrica, e la valutazione dell’evidenza empirica. Attraverso tecniche come il confronto tra modelli bayesiano e l’analisi di sensibilità, i ricercatori possono valutare rigorosamente la plausibilità relativa di diverse teorie psicologiche.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>L'analisi dei dati psicologici</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_data_analysis.html#riflessioni-epistemologiche",
    "href": "chapters/key_notions/03_data_analysis.html#riflessioni-epistemologiche",
    "title": "5  L’analisi dei dati psicologici",
    "section": "5.4 Riflessioni Epistemologiche",
    "text": "5.4 Riflessioni Epistemologiche\nL’adozione di metodi bayesiani e della Data Science in psicologia deve essere accompagnata da una profonda riflessione epistemologica. Come sottolineato da George Box\n\ntutti i modelli sono sbagliati, ma alcuni sono utili.\n\nQuesta massima risuona particolarmente nel contesto della ricerca psicologica, dove i fenomeni di interesse sono spesso complessi e multifattoriali.\nL’approccio bayesiano, con la sua enfasi sull’aggiornamento iterativo delle credenze alla luce di nuove evidenze, si allinea naturalmente con una visione della scienza come processo di apprendimento continuo piuttosto che come ricerca di verità assolute. Questa prospettiva riconosce i limiti intrinseci dei nostri modelli e delle nostre teorie, pur valorizzandone l’utilità euristica e predittiva (si veda la discussione nella ?sec-poetic-validity).\nIn particolare, McElreath (2020) sottolinea l’importanza di riconoscere la dualità tra il “mondo del modello” e il mondo reale più ampio che cerchiamo di comprendere. Questa consapevolezza è cruciale per evitare la reificazione dei nostri modelli statistici e per mantenere una prospettiva critica sulle nostre inferenze.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>L'analisi dei dati psicologici</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_data_analysis.html#conclusione",
    "href": "chapters/key_notions/03_data_analysis.html#conclusione",
    "title": "5  L’analisi dei dati psicologici",
    "section": "5.5 Conclusione",
    "text": "5.5 Conclusione\nL’integrazione dell’approccio bayesiano e della data science nella ricerca psicologica rappresenta una risposta promettente alle sfide poste dalla “Replication Crisis”. Offrendo un framework coerente per la modellazione formale, l’inferenza statistica e l’incorporazione di conoscenze pregresse, questi approcci promettono di elevare il rigore e la credibilità della ricerca psicologica. Tuttavia, è fondamentale che l’adozione di questi metodi sia accompagnata da una adeguata consapevolezza metodologica ed epistemologica – si veda, ad esempio, il ?sec-causal-inference-regr.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>L'analisi dei dati psicologici</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_data_analysis.html#bibliografia",
    "href": "chapters/key_notions/03_data_analysis.html#bibliografia",
    "title": "5  L’analisi dei dati psicologici",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAngrist, J. D., & Pischke, J.-S. (2010). The credibility revolution in empirical economics: How better research design is taking the con out of econometrics. Journal of economic perspectives, 24(2), 3–30.\n\n\nBaker, M. (2016). 1,500 scientists lift the lid on reproducibility. Nature, 533(7604).\n\n\nBishop, D. (2019). The psychology of experimental psychologists: Overcoming cognitive constraints to improve research.\n\n\nButton, K. S., Ioannidis, J. P., Mokrysz, C., Nosek, B. A., Flint, J., Robinson, E. S., & Munafò, M. R. (2013). Power failure: why small sample size undermines the reliability of neuroscience. Nature Reviews Neuroscience, 14(5), 365–376.\n\n\nCollaboration, O. S. (2015). Estimating the reproducibility of psychological science. Science, 349(6251), aac4716.\n\n\nGelman, A., & Loken, E. (2013). The garden of forking paths: Why multiple comparisons can be a problem, even when there is no «fishing expedition» or «p-hacking» and the research hypothesis was posited ahead of time. Department of Statistics, Columbia University, 348(1-17), 3.\n\n\nGelman, A., & Loken, E. (2014). The statistical crisis in science. American scientist, 102(6), 460–465.\n\n\nIoannidis, J. P. (2005). Why most published research findings are false. PLoS medicine, 2(8), e124.\n\n\nKorbmacher, M., Azevedo, F., Pennington, C. R., Hartmann, H., Pownall, M., Schmidt, K., Elsherif, M., Breznau, N., Robertson, O., Kalandadze, T., et al. (2023). The replication crisis has led to positive structural, procedural, and community changes. Communications Psychology, 1(1), 3.\n\n\nLabatut, B. (2021). Quando abbiamo smesso di capire il mondo. Adelphi Edizioni spa.\n\n\nLarson, C., Kaplan, D., Girolamo, T., Kover, S. T., & Eigsti, I.-M. (2023). A Bayesian statistics tutorial for clinical research: Prior distributions and meaningful results for small clinical samples. Journal of Clinical Psychology, 79(11), 2602–2624.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nMeehl, P. E. (1967). Theory-testing in psychology and physics: A methodological paradox. Philosophy of science, 34(2), 103–115.\n\n\nMunger, K. (2023). Temporal validity as meta-science. Research & Politics, 10(3), 20531680231187271.\n\n\nOberauer, K., & Lewandowsky, S. (2019). Addressing the theory crisis in psychology. Psychonomic Bulletin & Review, 26, 1596–1618.\n\n\nPearl, J., & Mackenzie, D. (2018). The book of why: the new science of cause and effect. Basic books.\n\n\nSimmons, J. P., Nelson, L. D., & Simonsohn, U. (2011). False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant. Psychological science, 22(11), 1359–1366.\n\n\nVan Dongen, N., Bork, R. van, Finnemann, A., Haslbeck, J., Maas, H. L. van der, Robinaugh, D. J., Ron, J. de, Sprenger, J., & Borsboom, D. (2024). Productive explanation: A framework for evaluating explanations in psychological science. Psychological Review.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>L'analisi dei dati psicologici</span>"
    ]
  },
  {
    "objectID": "chapters/R/introduction_r_lang.html",
    "href": "chapters/R/introduction_r_lang.html",
    "title": "Introduzione",
    "section": "",
    "text": "R è uno dei linguaggi di programmazione più utilizzati per l’analisi dei dati, apprezzato per la sua flessibilità, potenza e il supporto offerto da una vasta comunità di utenti e sviluppatori. Nato come progetto open-source agli inizi degli anni ’90, R è stato concepito specificamente per rispondere alle esigenze di analisi statistica e visualizzazione grafica, diventando rapidamente uno strumento essenziale nel panorama accademico e scientifico.\nR si distingue per la sua capacità di gestire, manipolare e analizzare grandi quantità di dati. Il linguaggio offre un ecosistema ricchissimo di funzionalità che spaziano dalla modellazione lineare e non lineare all’analisi delle serie temporali, includendo tecniche avanzate di classificazione e clustering. Tale versatilità copre praticamente ogni possibile esigenza di analisi statistica, e grazie a una libreria pressoché infinita di pacchetti disponibili, gli utenti possono estendere ulteriormente le capacità del linguaggio per soddisfare necessità specifiche e settoriali.\nUno degli aspetti più apprezzati di R è la sua capacità di creare grafici e visualizzazioni di alta qualità. Con strumenti come quelli offerti dai pacchetti ggplot2 e plotly, R permette di realizzare rappresentazioni grafiche personalizzate e immediatamente pronte per la pubblicazione, come istogrammi, scatterplot e visualizzazioni interattive. Questi strumenti grafici ricoprono un ruolo cruciale nella comunicazione scientifica, rendendo i dati complessi più comprensibili e accessibili.\nIn psicologia e nelle scienze sociali, R è particolarmente utile grazie alle sue capacità avanzate di analisi statistica e visualizzazione. Permette di affrontare analisi sofisticate, come modelli di regressione, analisi fattoriale, e metodi per dati longitudinali, rendendolo uno strumento indispensabile per chi si occupa di ricerca. La sua flessibilità lo rende inoltre ideale per adattarsi a dataset eterogenei e complessi, spesso caratteristici di queste discipline.\nImparare R non significa solo acquisire competenze tecniche, ma anche aprire le porte a nuove possibilità di analisi e ricerca. Grazie al suo continuo sviluppo e alla natura open-source, R è in costante evoluzione, garantendo strumenti sempre aggiornati per affrontare le sfide più attuali nel campo della scienza dei dati.\nIn questo percorso introduttivo, esploreremo le basi del linguaggio R, muovendoci dalla gestione basilare dei dati fino alla creazione di grafici complessi e alla realizzazione di analisi statistiche articolate.",
    "crumbs": [
      "R",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html",
    "href": "chapters/R/01_r_syntax.html",
    "title": "6  Introduzione a R e RStudio",
    "section": "",
    "text": "6.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nNegli ultimi anni, la crisi della replicabilità ha messo in luce problemi significativi nella scienza: molte analisi non possono essere riprodotte, minando la fiducia nei risultati pubblicati (Nosek et al., 2022). Per affrontare questa sfida, è fondamentale adottare strumenti che promuovano trasparenza, riproducibilità e rigore metodologico. R si distingue come uno strumento ideale per soddisfare queste esigenze, grazie a tre punti di forza principali:\nA differenza di software con interfacce grafiche (GUI), che spesso introducono errori nascosti e rendono difficile documentare il flusso di lavoro, R favorisce un approccio basato su codice esplicito. Questo approccio:\nUtilizzare R non significa solo apprendere uno strumento tecnico, ma adottare un approccio scientifico moderno e replicabile. Lavorare in R risponde alle richieste di una ricerca affidabile e contribuisce a contrastare la crisi della replicabilità, favorendo analisi trasparenti, rigorose e comunicabili.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduzione a R e RStudio</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#introduzione",
    "href": "chapters/R/01_r_syntax.html#introduzione",
    "title": "6  Introduzione a R e RStudio",
    "section": "",
    "text": "Scripting e documentazione trasparente. Ogni analisi in R viene realizzata attraverso script che documentano in modo esplicito tutti i passaggi. Questo approccio offre numerosi vantaggi:\n\nGli script possono essere salvati, condivisi e rivisti, garantendo che ogni aspetto del processo analitico sia accessibile e riproducibile.\nLa possibilità di eseguire gli stessi script con nuovi dati consente di verificare i risultati originali o applicare l’analisi in contesti differenti.\n\nFlessibilità e personalizzazione. R fornisce un ambiente altamente flessibile, che permette di:\n\nAdattare i flussi di lavoro a problemi specifici o a nuovi set di dati.\nSfruttare una vasta libreria di pacchetti che coprono metodi statistici avanzati, visualizzazione dei dati e machine learning.\nSviluppare funzioni personalizzate per rispondere a esigenze analitiche uniche.\n\nIntegrazione con strumenti di reporting. R si integra perfettamente con strumenti come R Markdown e Quarto, che consentono di combinare analisi, codice e risultati in un unico documento dinamico. Questo approccio offre:\n\nLa possibilità di creare report automatici, aggiornabili semplicemente modificando i dati sottostanti.\nUn formato unificato che include testo descrittivo, codice e output (grafici, tabelle, statistiche), facilitando la comunicazione scientifica.\n\n\n\n\nElimina ambiguità, poiché ogni operazione è descritta chiaramente nello script.\nIncrementa la verificabilità, consentendo a terzi di esaminare ogni passaggio dell’analisi.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduzione a R e RStudio</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#installare-r-e-rstudio",
    "href": "chapters/R/01_r_syntax.html#installare-r-e-rstudio",
    "title": "6  Introduzione a R e RStudio",
    "section": "6.2 Installare R e RStudio",
    "text": "6.2 Installare R e RStudio\n\nScarica e installa R\nVai al sito ufficiale di CRAN (https://cran.r-project.org/), scegli la versione per il tuo sistema operativo (Windows, Mac o Linux) e segui le istruzioni di installazione.\nScarica e installa RStudio\nDopo aver installato R, scarica RStudio dal sito ufficiale (https://posit.co/download/rstudio-desktop/). Scegli la versione gratuita “RStudio Desktop” e segui le istruzioni per il tuo sistema operativo.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduzione a R e RStudio</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#panoramica-sullinterfaccia-di-rstudio",
    "href": "chapters/R/01_r_syntax.html#panoramica-sullinterfaccia-di-rstudio",
    "title": "6  Introduzione a R e RStudio",
    "section": "6.3 Panoramica sull’interfaccia di RStudio",
    "text": "6.3 Panoramica sull’interfaccia di RStudio\nRStudio rende l’uso di R più intuitivo grazie alla sua interfaccia divisa in quattro pannelli principali:\n\nPannello degli script: Qui puoi scrivere e modificare i tuoi script, cioè sequenze di comandi salvabili per analisi ripetibili e organizzate.\nConsole: Esegue i comandi scritti direttamente o lanciati dagli script, mostrando risultati, messaggi e errori.\nPannello dell’ambiente: Mostra i dataset, le variabili e gli oggetti caricati nella sessione di lavoro, permettendoti di gestire facilmente i dati.\nPannello grafici/aiuto/file: Visualizza grafici, fornisce accesso alla documentazione di R e consente di navigare tra file e cartelle sul tuo sistema.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduzione a R e RStudio</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#creare-un-nuovo-progetto-in-rstudio",
    "href": "chapters/R/01_r_syntax.html#creare-un-nuovo-progetto-in-rstudio",
    "title": "6  Introduzione a R e RStudio",
    "section": "6.4 Creare un Nuovo Progetto in RStudio",
    "text": "6.4 Creare un Nuovo Progetto in RStudio\nAvviare un nuovo progetto\nDal menu di RStudio, seleziona File &gt; New Project… per creare un nuovo progetto. I progetti in RStudio sono uno strumento efficace per organizzare il lavoro relativo a una specifica analisi o domanda di ricerca. All’interno di un progetto puoi raccogliere script, file di dati e output, mantenendo tutto ben strutturato.\nScegliere la posizione del progetto\nPuoi creare una nuova directory dedicata al progetto oppure associare il progetto a una directory esistente. Organizzare i progetti in cartelle dedicate aiuta a mantenere i file in ordine e a utilizzare percorsi relativi, rendendo il tuo lavoro più facile da condividere con collaboratori e più portabile tra diversi sistemi.\nQuesta organizzazione è particolarmente utile per evitare confusione e assicurarsi che tutti i file necessari siano facilmente accessibili e collegati al progetto corretto.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduzione a R e RStudio</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#concetti-di-base-nella-programmazione-in-r",
    "href": "chapters/R/01_r_syntax.html#concetti-di-base-nella-programmazione-in-r",
    "title": "6  Introduzione a R e RStudio",
    "section": "6.5 Concetti di Base nella Programmazione in R",
    "text": "6.5 Concetti di Base nella Programmazione in R\nIniziare a usare R, soprattutto per chi si avvicina per la prima volta a questo linguaggio nel contesto della psicologia, significa comprendere i concetti fondamentali che ne costituiscono la base. Questo capitolo introduce i principi essenziali della programmazione in R, tra cui:\n\nLa comprensione della sintassi di R.\nLa familiarizzazione con i principali tipi di dati e strutture.\nL’acquisizione delle operazioni di base.\n\nQuesti concetti sono fondamentali per manipolare efficacemente i dati e condurre analisi statistiche, rappresentando il punto di partenza per sfruttare al meglio le potenzialità di R.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduzione a R e RStudio</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#oggetti-in-r",
    "href": "chapters/R/01_r_syntax.html#oggetti-in-r",
    "title": "6  Introduzione a R e RStudio",
    "section": "6.6 Oggetti in R",
    "text": "6.6 Oggetti in R\nIn R, tutto è un oggetto: dai numeri o stringhe di testo semplici, fino a strutture più complesse come grafici, riassunti di analisi statistiche o script che eseguono compiti specifici. Creare e assegnare valori agli oggetti è fondamentale per lavorare in R.\n\n6.6.1 Creare oggetti\nPer creare un oggetto, basta assegnargli un nome e un valore usando l’operatore di assegnazione &lt;-:\n\nmy_obj &lt;- 48\n\nIn questo esempio, abbiamo creato un oggetto chiamato my_obj e gli abbiamo assegnato il valore 48. Anche l’operatore = può essere usato, ma è considerato una cattiva pratica.\nPer visualizzare il valore di un oggetto, basta scriverne il nome:\n\nmy_obj\n#&gt; [1] 48\n\nGli oggetti creati vengono memorizzati nell’ambiente di lavoro. In RStudio, puoi visualizzarli nella scheda Environment e ottenere dettagli come tipo, lunghezza e valore.\nÈ possibile assegnare a un oggetto anche una stringa di testo, racchiudendola tra virgolette:\n\nmy_obj2 &lt;- \"R è fantastico\"\nmy_obj2\n#&gt; [1] \"R è fantastico\"\n\nSe dimentichi le virgolette, R mostrerà un errore.\nPer modificare il valore di un oggetto esistente, basta riassegnarlo:\n\nmy_obj2 &lt;- 1024\n\nOra il tipo di my_obj2 è cambiato da carattere a numerico. È anche possibile usare oggetti per crearne di nuovi:\n\nmy_obj3 &lt;- my_obj + my_obj2\nmy_obj3\n#&gt; [1] 1072\n\nSe provi a sommare oggetti di tipo diverso, R restituirà un errore:\nchar_obj &lt;- \"ciao\"\nchar_obj2 &lt;- \"mondo\"\nchar_obj3 &lt;- char_obj + char_obj2\n#&gt; Error in char_obj + char_obj2 : non-numeric argument to binary operator\nQuando incontri errori come questo, chiedi a AI la spiegazione del messaggio, per esempio: “non-numeric argument to binary operator error + r”. Un errore comune è anche:\nmy_obj &lt;- 48\nmy_obj4 &lt;- my_obj + no_obj\n#&gt; Error: object 'no_obj' not found\nR segnala che no_obj non è stato definito e, di conseguenza, l’oggetto my_obj4 non è stato creato.\n\n\n6.6.2 Nomi degli oggetti\nDare un nome agli oggetti può sembrare banale, ma è importante scegliere nomi brevi e informativi. Usa un formato coerente, come:\n\nSnake case: output_summary\nDot case: output.summary\nCamel case: outputSummary\n\nEvita di iniziare i nomi con numeri (es. 2my_variable) o caratteri speciali (&, ^, /, ecc.). Inoltre, non usare parole riservate (es. TRUE, NA) o nomi di funzioni già esistenti (es. data).\nEsempio da evitare:\ndata &lt;- read.table(\"mydatafile\", header = TRUE) # `data` è già una funzione!",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduzione a R e RStudio</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#commenti",
    "href": "chapters/R/01_r_syntax.html#commenti",
    "title": "6  Introduzione a R e RStudio",
    "section": "6.7 Commenti",
    "text": "6.7 Commenti\nI commenti nel linguaggio di programmazione (in questo caso R) sono parti del codice che il linguaggio stesso ignora completamente, ovvero non vengono eseguite. La loro funzione principale è aiutare il programmatore a chiarire cosa fanno le diverse parti del codice, rendendolo più comprensibile sia a sé stessi sia ad altri. In R, come si può osservare nell’esempio sopra, i commenti iniziano con il simbolo #. Tutto ciò che segue il simbolo # sulla stessa riga viene ignorato durante l’esecuzione del codice.\nÈ una buona pratica commentare frequentemente il codice, soprattutto nei punti in cui le decisioni prese non risultano immediatamente evidenti. I commenti dovrebbero spiegare perché si sta facendo qualcosa, piuttosto che come viene fatto: il “come” è già descritto dal codice stesso.\nAd esempio, invece di scrivere un commento come:\n# Assegno 42 alla variabile x\nx &lt;- 42\nè più utile spiegare il contesto o la motivazione:\n# Valore iniziale scelto per semplificare i calcoli successivi\nx &lt;- 42\nQuesto approccio aiuta chiunque legga il codice (incluso il futuro te stesso!) a comprendere le intenzioni alla base delle scelte fatte, riducendo il tempo necessario per interpretarlo o modificarlo. Un codice ben commentato è quindi non solo più comprensibile, ma anche più facile da mantenere e riutilizzare.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduzione a R e RStudio</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#usare-le-funzioni-in-r",
    "href": "chapters/R/01_r_syntax.html#usare-le-funzioni-in-r",
    "title": "6  Introduzione a R e RStudio",
    "section": "6.8 Usare le funzioni in R",
    "text": "6.8 Usare le funzioni in R\nFino ad ora abbiamo creato oggetti semplici assegnando loro direttamente un valore. Con l’aumento dell’esperienza in R, potresti voler creare oggetti più complessi. Per aiutarti, R offre numerose funzioni già disponibili nella sua installazione di base, e altre possono essere aggiunte installando pacchetti. Una funzione è un insieme di istruzioni che eseguono un compito specifico. Inoltre, è possibile creare funzioni personalizzate.\n\n6.8.1 La funzione c() per creare vettori\nLa prima funzione utile da imparare è c(), che serve a concatenare valori in un vettore. Ad esempio:\n\nmy_vec &lt;- c(2, 3, 1, 6, 4, 3, 3, 7)\n\nQuesto codice crea un oggetto chiamato my_vec che contiene una sequenza di numeri. Alcuni concetti fondamentali sulle funzioni in R:\n\nNome e parentesi: Le funzioni in R sono sempre seguite da parentesi tonde ().\nArgomenti: Gli elementi passati alla funzione (tra le parentesi) ne personalizzano il comportamento e sono separati da virgole.\n\nPer vedere il contenuto del vettore:\n\nmy_vec\n#&gt; [1] 2 3 1 6 4 3 3 7\n\n\n\n6.8.2 Funzioni per analizzare vettori\nPuoi utilizzare altre funzioni per calcolare statistiche sul vettore:\n\nmean(my_vec)    # Media\n#&gt; [1] 3.62\n\n\nvar(my_vec)     # Varianza\n#&gt; [1] 3.98\n\n\nsd(my_vec)      # Deviazione standard\n#&gt; [1] 2\n\n\nlength(my_vec)  # Numero di elementi\n#&gt; [1] 8\n\nPuoi anche salvare i risultati in nuovi oggetti per riutilizzarli:\n\nvec_mean &lt;- mean(my_vec)\nvec_mean\n#&gt; [1] 3.62\n\n\n\n6.8.3 Creare sequenze regolari\nPer creare sequenze di numeri in passi regolari, puoi usare i seguenti comandi.\nSimbolo : per sequenze semplici:\n\nmy_seq &lt;- 1:10\nmy_seq\n#&gt;  [1]  1  2  3  4  5  6  7  8  9 10\n\nFunzione seq() per maggiore controllo:\n\nmy_seq2 &lt;- seq(from = 1, to = 5, by = 0.5)\nmy_seq2\n#&gt; [1] 1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0\n\n\n\n6.8.4 Ripetere valori\nPuoi ripetere valori o sequenze con la funzione rep().\nRipetere un valore:\n\nmy_seq3 &lt;- rep(2, times = 10)\nmy_seq3\n#&gt;  [1] 2 2 2 2 2 2 2 2 2 2\n\nRipetere una sequenza:\n\nmy_seq5 &lt;- rep(1:5, times = 3)\n\nRipetere ogni elemento di una sequenza:\n\nmy_seq6 &lt;- rep(1:5, each = 3)\nmy_seq6\n#&gt;  [1] 1 1 1 2 2 2 3 3 3 4 4 4 5 5 5\n\n\n\n6.8.5 Annidare funzioni\nÈ possibile combinare funzioni per creare comandi più complessi, come nell’esempio:\n\nmy_seq7 &lt;- rep(c(3, 1, 10, 7), each = 3)\nmy_seq7\n#&gt;  [1]  3  3  3  1  1  1 10 10 10  7  7  7\n\nPer maggiore leggibilità, puoi separare i passaggi:\n\nin_vec &lt;- c(3, 1, 10, 7)\nmy_seq7 &lt;- rep(in_vec, each = 3)\nmy_seq7\n#&gt;  [1]  3  3  3  1  1  1 10 10 10  7  7  7\n\nQuesta pratica facilita la comprensione del codice e lo rende più chiaro.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduzione a R e RStudio</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#lavorare-con-i-vettori-in-r",
    "href": "chapters/R/01_r_syntax.html#lavorare-con-i-vettori-in-r",
    "title": "6  Introduzione a R e RStudio",
    "section": "6.9 Lavorare con i vettori in R",
    "text": "6.9 Lavorare con i vettori in R\nIn R, i vettori sono uno degli elementi fondamentali per manipolare, riassumere e ordinare i dati. Qui trovi una panoramica su come estrarre, sostituire, ordinare, lavorare con dati mancanti e sfruttare la vettorizzazione dei vettori.\n\n6.9.1 Estrarre elementi da un vettore\nPuoi estrarre uno o più elementi da un vettore usando le parentesi quadre [ ].\nPer posizione: Specifica la posizione degli elementi.\n\nmy_vec &lt;- c(2, 3, 1, 6, 4, 3, 3, 7)\nmy_vec[3]  # Terzo elemento\n#&gt; [1] 1\n\n\nmy_vec[c(1, 5, 6)]  # Elementi 1°, 5° e 6°\n#&gt; [1] 2 4 3\n\n\nmy_vec[3:8]  # Da 3° a 8°\n#&gt; [1] 1 6 4 3 3 7\n\nCon condizioni logiche: Usa espressioni logiche per selezionare elementi.\n\nmy_vec[my_vec &gt; 4]  # Elementi &gt; 4\n#&gt; [1] 6 7\n\n\nmy_vec[my_vec &lt;= 4]  # Elementi ≤ 4\n#&gt; [1] 2 3 1 4 3 3\n\n\nmy_vec[my_vec != 4]  # Elementi diversi da 4\n#&gt; [1] 2 3 1 6 3 3 7\n\nOperatori logici: Combina condizioni con & (AND) e | (OR).\n\nmy_vec[my_vec &gt; 2 & my_vec &lt; 6]  # Tra 2 e 6\n#&gt; [1] 3 4 3 3\n\n\n\n6.9.2 Sostituire elementi in un vettore\nPuoi modificare i valori di un vettore usando [ ] e l’operatore &lt;-.\nUn singolo elemento:\n\nmy_vec[4] &lt;- 500  # Cambia il 4° elemento\nmy_vec\n#&gt; [1]   2   3   1 500   4   3   3   7\n\nPiù elementi:\n\nmy_vec[c(6, 7)] &lt;- 100  # Cambia il 6° e 7° elemento\nmy_vec\n#&gt; [1]   2   3   1 500   4 100 100   7\n\nCon condizioni logiche:\n\nmy_vec[my_vec &lt;= 4] &lt;- 1000  # Cambia valori ≤ 4\nmy_vec\n#&gt; [1] 1000 1000 1000  500 1000  100  100    7\n\n\n\n6.9.3 Ordinare un vettore\nDal più piccolo al più grande:\n\nvec_sort &lt;- sort(my_vec)\nvec_sort\n#&gt; [1]    7  100  100  500 1000 1000 1000 1000\n\nDal più grande al più piccolo:\n\nvec_sort2 &lt;- sort(my_vec, decreasing = TRUE)\nvec_sort2\n#&gt; [1] 1000 1000 1000 1000  500  100  100    7\n\nOrdinare un vettore in base a un altro:\n\nheight &lt;- c(180, 155, 160, 167, 181)\np.names &lt;- c(\"Joanna\", \"Charlotte\", \"Helen\", \"Karen\", \"Amy\")\nheight_ord &lt;- order(height)\nnames_ord &lt;- p.names[height_ord]\nnames_ord\n#&gt; [1] \"Charlotte\" \"Helen\"     \"Karen\"     \"Joanna\"    \"Amy\"\n\n\n\n6.9.4 Operazioni vettoriali (vettorizzazione)\nLe funzioni in R sono vettorizzate, cioè operano automaticamente su tutti gli elementi di un vettore senza bisogno di un ciclo.\nOperazioni aritmetiche:\n\nmy_vec2 &lt;- c(3, 5, 7, 1, 9, 20)\nmy_vec2 * 5  # Moltiplica ogni elemento per 5\n#&gt; [1]  15  25  35   5  45 100\n\nOperazioni tra vettori:\n\nmy_vec3 &lt;- c(17, 15, 13, 19, 11, 0)\nmy_vec2 + my_vec3  # Somma due vettori\n#&gt; [1] 20 20 20 20 20 20\n\nRiciclo (recycling): Attenzione quando i vettori hanno lunghezze diverse.\n\nmy_vec4 &lt;- c(1, 2)\nmy_vec2 + my_vec4  # R ricicla gli elementi del vettore più corto\n#&gt; [1]  4  7  8  3 10 22\n\n\n\n6.9.5 Gestire dati mancanti (NA)\nR rappresenta i dati mancanti con NA. La gestione dei dati mancanti dipende dalla funzione utilizzata.\nCalcolo con dati mancanti:\n\ntemp &lt;- c(7.2, NA, 7.1, 6.9, 6.5, 5.8, 5.8, 5.5, NA, 5.5)\nmean(temp)  # Restituisce NA\n#&gt; [1] NA\n\n\nmean(temp, na.rm = TRUE)  # Ignora i valori mancanti\n#&gt; [1] 6.29\n\nNota: na.rm = TRUE è un argomento comune per ignorare i NA, ma non tutte le funzioni lo supportano. Consulta la documentazione della funzione per verificare come gestisce i dati mancanti.\nIn conclusione, manipolare vettori è un’abilità essenziale in R. Dalla selezione e modifica degli elementi all’ordinamento e gestione di dati mancanti, queste tecniche sono alla base dell’analisi dei dati in R.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduzione a R e RStudio</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#i-dati-in-r",
    "href": "chapters/R/01_r_syntax.html#i-dati-in-r",
    "title": "6  Introduzione a R e RStudio",
    "section": "6.10 I dati in R",
    "text": "6.10 I dati in R\nIn R, i dati possono essere rappresentati in diversi tipi e strutture. Comprendere come gestirli è fondamentale per manipolare, analizzare e riassumere i dataset più complessi.\n\n6.10.1 Tipi di dati in R\nR supporta diversi tipi di dati:\n\nNumeric: Numeri decimali (es. 2.5).\nInteger: Numeri interi (es. 3).\nLogical: Valori booleani (TRUE o FALSE) e NA per dati mancanti.\nCharacter: Stringhe di testo (es. \"hello\").\nFactor: Variabili categoriche (es. livelli come \"low\", \"medium\", \"high\").\n\nPuoi verificare il tipo di un oggetto con class() e controllare se appartiene a un tipo specifico con funzioni come is.numeric(). È anche possibile convertire un tipo in un altro con funzioni come as.character().\n\n\n6.10.2 Strutture di dati in R\nVettori: Contengono dati dello stesso tipo (es. numeri, stringhe o logici).\n\nmy_vec &lt;- c(1, 2, 3)\nmy_vec\n#&gt; [1] 1 2 3\n\nMatrici e array: Strutture bidimensionali (matrici) o multidimensionali (array) con dati dello stesso tipo.\nCreare una matrice:\n\nmy_mat &lt;- matrix(1:12, nrow = 3, byrow = TRUE)\nmy_mat\n#&gt;      [,1] [,2] [,3] [,4]\n#&gt; [1,]    1    2    3    4\n#&gt; [2,]    5    6    7    8\n#&gt; [3,]    9   10   11   12\n\nOperazioni utili:\n\nTrasposizione: t(my_mat)\nDiagonale: diag(my_mat)\nMoltiplicazione matriciale: mat1 %*% mat2\n\nListe: Possono contenere elementi di tipi diversi, inclusi vettori, matrici o altre liste.\n\nmy_list &lt;- list(\n  numbers = c(1, 2), \n  text = \"hello\", \n  mat = matrix(1:4, nrow = 2)\n)\nmy_list$numbers  # Accedi agli elementi con il nome\n#&gt; [1] 1 2\n\nData frame: Strutture bidimensionali che possono contenere colonne di tipi diversi. Ideale per dataset strutturati.\nCreare un data frame:\n\nheight &lt;- c(180, 155, 160)\nweight &lt;- c(65, 50, 52)\nnames &lt;- c(\"Joanna\", \"Charlotte\", \"Helen\")\n\ndataf &lt;- data.frame(height = height, weight = weight, names = names)\nstr(dataf)  # Mostra la struttura del data frame\n#&gt; 'data.frame':    3 obs. of  3 variables:\n#&gt;  $ height: num  180 155 160\n#&gt;  $ weight: num  65 50 52\n#&gt;  $ names : chr  \"Joanna\" \"Charlotte\" \"Helen\"\n\nPer convertire le stringhe in fattori durante la creazione:\n\ndataf &lt;- data.frame(\n  height = height, \n  weight = weight, \n  names = names, \n  stringsAsFactors = TRUE\n)\n\ndataf\n#&gt;   height weight     names\n#&gt; 1    180     65    Joanna\n#&gt; 2    155     50 Charlotte\n#&gt; 3    160     52     Helen\n\n\n\n6.10.3 Operazioni utili sui data frame\n\nVerificare dimensioni: dim(dataf)\nVisualizzare struttura: str(dataf)\nAccedere a colonne: dataf$height",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduzione a R e RStudio</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#operazioni-di-base-in-r",
    "href": "chapters/R/01_r_syntax.html#operazioni-di-base-in-r",
    "title": "6  Introduzione a R e RStudio",
    "section": "6.11 Operazioni di Base in R",
    "text": "6.11 Operazioni di Base in R\n\n6.11.1 Operazioni Aritmetiche\nR supporta le classiche operazioni aritmetiche come somma (+), sottrazione (-), moltiplicazione (*), divisione (/) ed esponenziazione (^).\n\n# Somma\n3 + 2\n#&gt; [1] 5\n# Moltiplicazione\n3 * 2\n#&gt; [1] 6\n\n\n\n6.11.2 Operazioni Logiche\nLe operazioni logiche in R includono:\n\n&: “and” logico\n\n|: “or” logico\n\n!: “not” logico\n\n&gt;: maggiore di\n\n&lt;: minore di\n\n==: uguale a\n\n!=: diverso da\n\nEsempi:\n\n# Maggiore di\n3 &gt; 2\n#&gt; [1] TRUE\n# Uguale a\n3 == 2\n#&gt; [1] FALSE",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduzione a R e RStudio</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#estrazione-di-sottoinsiemi-di-oggetti-in-r",
    "href": "chapters/R/01_r_syntax.html#estrazione-di-sottoinsiemi-di-oggetti-in-r",
    "title": "6  Introduzione a R e RStudio",
    "section": "6.12 Estrazione di Sottoinsiemi di Oggetti in R",
    "text": "6.12 Estrazione di Sottoinsiemi di Oggetti in R\nIn R esistono tre operatori principali per estrarre sottoinsiemi di oggetti:\n\nOperatore [ ]\nQuesto operatore restituisce sempre un oggetto della stessa classe dell’originale. È utile per selezionare più elementi da un oggetto. È importante chiudere l’estrazione con ].\nOperatore [[ ]]\nQuesto operatore viene utilizzato per estrarre elementi da liste o data frame. A differenza di [ ], permette di estrarre un solo elemento alla volta e la classe dell’oggetto restituito non sarà necessariamente una lista o un data frame. L’estrazione va chiusa con ]].\nOperatore $\nCome visto in precedenza, questo operatore serve per estrarre elementi da una lista o un data frame utilizzando il loro nome letterale. Il comportamento semantico è simile a quello di [[ ]].\n\n\n6.12.1 Esempi Pratici\nSelezione di colonne in un data frame:\n\niris[, 1:3] |&gt; head()\n#&gt;   Sepal.Length Sepal.Width Petal.Length\n#&gt; 1          5.1         3.5          1.4\n#&gt; 2          4.9         3.0          1.4\n#&gt; 3          4.7         3.2          1.3\n#&gt; 4          4.6         3.1          1.5\n#&gt; 5          5.0         3.6          1.4\n#&gt; 6          5.4         3.9          1.7\n\nRestituisce le prime tre colonne del dataset iris.\nSelezione di colonne specifiche per nome:\n\niris[, c('Sepal.Length', 'Petal.Length')] |&gt; \n  head()  # Nomi delle colonne\n#&gt;   Sepal.Length Petal.Length\n#&gt; 1          5.1          1.4\n#&gt; 2          4.9          1.4\n#&gt; 3          4.7          1.3\n#&gt; 4          4.6          1.5\n#&gt; 5          5.0          1.4\n#&gt; 6          5.4          1.7\n\nSelezione di una singola colonna:\n\niris[, 'Petal.Length'] |&gt; head()\n#&gt; [1] 1.4 1.4 1.3 1.5 1.4 1.7\n\nSelezione di righe specifiche:\n\niris[c(1, 3), ]\n#&gt;   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n#&gt; 1          5.1         3.5          1.4         0.2  setosa\n#&gt; 3          4.7         3.2          1.3         0.2  setosa\n\nRestituisce le righe 1 e 3.\nFiltraggio logico di righe:\n\niris[iris$Species == 'versicolor', ] |&gt; head()\n#&gt;    Sepal.Length Sepal.Width Petal.Length Petal.Width    Species\n#&gt; 51          7.0         3.2          4.7         1.4 versicolor\n#&gt; 52          6.4         3.2          4.5         1.5 versicolor\n#&gt; 53          6.9         3.1          4.9         1.5 versicolor\n#&gt; 54          5.5         2.3          4.0         1.3 versicolor\n#&gt; 55          6.5         2.8          4.6         1.5 versicolor\n#&gt; 56          5.7         2.8          4.5         1.3 versicolor\n\nRestituisce le righe con Species uguale a “versicolor”. Numero di righe e colonne del sottoinsieme:\n\ndim(iris[iris$Species == 'versicolor', ])\n#&gt; [1] 50  5\n\n\n\n6.12.2 Filtraggio Avanzato con Operatori Logici\nGli operatori logici & (AND), | (OR) e ! (NOT) permettono un filtraggio più sofisticato.\nEsempio: Filtrare le osservazioni di specie “versicolor” con lunghezza del sepalo non superiore a 5.0:\n\niris[(iris$Species == 'versicolor') & (iris$Sepal.Length &lt;= 5.0), ]\n#&gt;    Sepal.Length Sepal.Width Petal.Length Petal.Width    Species\n#&gt; 58          4.9         2.4          3.3           1 versicolor\n#&gt; 61          5.0         2.0          3.5           1 versicolor\n#&gt; 94          5.0         2.3          3.3           1 versicolor\n\nNumero di osservazioni trovate:\n\ndim(iris[(iris$Species == 'versicolor') & (iris$Sepal.Length &lt;= 5.0), ])\n#&gt; [1] 3 5",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduzione a R e RStudio</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#riflessioni-conclusive",
    "href": "chapters/R/01_r_syntax.html#riflessioni-conclusive",
    "title": "6  Introduzione a R e RStudio",
    "section": "6.13 Riflessioni Conclusive",
    "text": "6.13 Riflessioni Conclusive\nR non è soltanto un linguaggio di programmazione per la statistica, ma rappresenta una filosofia che si fonda su tre principi chiave: apertura, collaborazione e avanzamento della conoscenza scientifica.\nPer chi si avvicina a R, sia nel campo della comunicazione sia in altri ambiti, cogliere questa filosofia è essenziale per apprezzarne appieno il valore. R promuove non solo competenze tecniche, ma anche un impegno verso pratiche di ricerca trasparente e riproducibile, che costituiscono un pilastro fondamentale per una scienza rigorosa e affidabile.\n\n6.13.1 La Filosofia di R\nOpen Source\nR è un software open source, liberamente accessibile a tutti. Questo significa che chiunque può visualizzarne, modificarne e distribuirne il codice sorgente, promuovendo un ambiente trasparente e collaborativo. Essendo gratuito, R garantisce accessibilità a ricercatori di tutto il mondo, indipendentemente dal budget o dal supporto istituzionale. Inoltre, grazie alla sua natura aperta, R beneficia del contributo collettivo di una comunità globale eterogenea.\nContributi della Comunità\nLa comunità di R è uno dei suoi punti di forza principali. Statistici, ricercatori e data scientist di diverse discipline arricchiscono continuamente R sviluppando pacchetti: raccolte di funzioni, dati e codice che ampliano le sue funzionalità. Questa collaborazione ha portato alla creazione di migliaia di pacchetti che coprono tecniche statistiche, metodi grafici e strumenti per la manipolazione dei dati, rendendo R uno strumento sempre più versatile e adatto a un’ampia gamma di esigenze di ricerca.\n\n\n6.13.2 La Ricerca Riproducibile e il Ruolo di R\nLa ricerca riproducibile consiste nel condurre studi in modo tale che altri possano replicarne i risultati utilizzando gli stessi dati e seguendo la stessa metodologia. Questo approccio è cruciale per la validazione delle scoperte scientifiche, permettendo la verifica dei risultati e la costruzione di nuove conoscenze su basi solide.\nR facilita la ricerca riproducibile grazie a:\n\nUn ecosistema completo di pacchetti per l’analisi dei dati e la generazione di report dinamici.\n\nStrumenti come R Markdown e Quarto, che permettono di integrare testo descrittivo e codice R in un unico documento. Questa integrazione consente di documentare ogni fase del processo di ricerca—dalla pulizia dei dati all’analisi e alla presentazione dei risultati—garantendo trasparenza e replicabilità.\n\nIn conclusione, comprendere la filosofia open source di R e il suo ruolo nella promozione della ricerca riproducibile fornisce un quadro chiaro del motivo per cui R è diventato uno strumento essenziale per ricercatori e statistici di diverse discipline. Per chi opera in psicologia, sfruttare le potenzialità di R significa produrre risultati di ricerca più trasparenti, replicabili e credibili, contribuendo alla robustezza e affidabilità della conoscenza scientifica nel settore.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduzione a R e RStudio</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/R/01_r_syntax.html#informazioni-sullambiente-di-sviluppo",
    "title": "6  Introduzione a R e RStudio",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2 ggpubr_0.6.0     \n#&gt;  [5] ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0   bayesplot_1.11.1 \n#&gt;  [9] psych_2.4.6.26    scales_1.3.0      markdown_1.13     knitr_1.49       \n#&gt; [13] lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4      \n#&gt; [17] purrr_1.0.2       readr_2.1.5       tidyr_1.3.1       tibble_3.2.1     \n#&gt; [21] ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      xfun_0.49         htmlwidgets_1.6.4 rstatix_0.7.2    \n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    fansi_1.0.6       pacman_0.5.1     \n#&gt; [13] pkgconfig_2.0.3   lifecycle_1.0.4   compiler_4.4.2    farver_2.1.2     \n#&gt; [17] munsell_0.5.1     mnormt_2.1.1      carData_3.0-5     httpuv_1.6.15    \n#&gt; [21] htmltools_0.5.8.1 yaml_2.3.10       Formula_1.2-5     car_3.1-3        \n#&gt; [25] pillar_1.9.0      later_1.4.1       abind_1.4-8       nlme_3.1-166     \n#&gt; [29] mime_0.12         tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4    \n#&gt; [33] rprojroot_2.0.4   fastmap_1.2.0     grid_4.4.2        colorspace_2.1-1 \n#&gt; [37] cli_3.6.3         magrittr_2.0.3    utf8_1.2.4        broom_1.0.7      \n#&gt; [41] withr_3.0.2       backports_1.5.0   promises_1.3.2    timechange_0.3.0 \n#&gt; [45] rmarkdown_2.29    ggsignif_0.6.4    hms_1.1.3         shiny_1.9.1      \n#&gt; [49] evaluate_1.0.1    miniUI_0.1.1.1    rlang_1.1.4       Rcpp_1.0.13-1    \n#&gt; [53] xtable_1.8-4      glue_1.8.0        jsonlite_1.8.9    R6_2.5.1",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduzione a R e RStudio</span>"
    ]
  },
  {
    "objectID": "chapters/R/01_r_syntax.html#bibliografia",
    "href": "chapters/R/01_r_syntax.html#bibliografia",
    "title": "6  Introduzione a R e RStudio",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nNosek, B. A., Hardwicke, T. E., Moshontz, H., Allard, A., Corker, K. S., Dreber, A., Fidler, F., Hilgard, J., Kline Struhl, M., Nuijten, M. B., et al. (2022). Replicability, robustness, and reproducibility in psychological science. Annual Review of Psychology, 73(1), 719–748.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduzione a R e RStudio</span>"
    ]
  },
  {
    "objectID": "chapters/R/02_r_programming.html",
    "href": "chapters/R/02_r_programming.html",
    "title": "7  Programmazione in R",
    "section": "",
    "text": "7.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nIn questo capitolo esploreremo tre strumenti fondamentali per la scrittura di codice in R: le funzioni, le istruzioni condizionali e i cicli. Questi elementi costituiscono la base per sviluppare script flessibili, efficienti e riutilizzabili, essenziali per ogni programmatore o analista che utilizza R.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/02_r_programming.html#funzioni",
    "href": "chapters/R/02_r_programming.html#funzioni",
    "title": "7  Programmazione in R",
    "section": "7.2 Funzioni",
    "text": "7.2 Funzioni\nR mette a disposizione una vasta gamma di funzioni integrate per l’analisi statistica, la manipolazione dei dati e la visualizzazione grafica.\nEsempi di funzioni comuni:\n\n# Sommare numeri\nsum(1, 2, 3)\n#&gt; [1] 6\n\n\n# Creare un grafico\nplot(1:10, 1:10)\n\n\n\n\n\n\n\n\nIn sintesi, una funzione è un blocco di codice progettato per eseguire un’operazione specifica. Puoi immaginarla come una “macchina”: fornisci un input, la funzione elabora i dati e restituisce un output.\n\n7.2.1 Creare Funzioni Personalizzate\nLa creazione di funzioni personalizzate in R rappresenta uno strumento fondamentale per migliorare il processo di programmazione, in particolare quando si tratta di operazioni ripetitive. Le funzioni consentono di rendere il codice più leggibile, efficiente e facile da riutilizzare, contribuendo a una gestione più organizzata e chiara delle operazioni da svolgere.\nUtilizzare funzioni personalizzate porta diversi vantaggi.\n\nIn primo luogo, permette di assegnare un nome descrittivo al blocco di codice che rappresenta l’operazione. Questo rende più intuitivo comprendere cosa fa la funzione, anche a distanza di tempo o per chiunque non abbia scritto originariamente il codice.\nIn secondo luogo, le funzioni facilitano la manutenzione: eventuali modifiche possono essere apportate in un unico punto, evitando di dover aggiornare manualmente tutte le occorrenze del codice e riducendo così il rischio di errori.\nUn ulteriore vantaggio consiste nella prevenzione degli errori tipici del copia-e-incolla, un approccio che può introdurre inconsistenze o dimenticanze nei programmi più complessi.\nInfine, le funzioni personalizzate favoriscono il riutilizzo del codice, rendendolo applicabile in più progetti o contesti senza la necessità di riscriverlo ogni volta.\n\nÈ importante sapere quando è opportuno scrivere una funzione. Una buona regola pratica è questa: se hai copiato e incollato lo stesso blocco di codice più di due volte, probabilmente è il momento di considerare la creazione di una funzione. Questo approccio permette di semplificare il lavoro e di costruire codice più pulito, scalabile e professionale. Creare una funzione non è solo un esercizio di programmazione, ma una scelta strategica per gestire il lavoro in modo più efficace e sostenibile nel lungo periodo.\n\n\n7.2.2 Sintassi di una Funzione\nLa struttura di una funzione in R è la seguente:\nnome_funzione &lt;- function(argomenti) {\n  # Corpo della funzione\n  codice\n  risultato\n}\n\nnome_funzione: Nome descrittivo della funzione.\n\nargomenti: I parametri che la funzione utilizza.\n\ncodice: Le operazioni che la funzione esegue.\n\nrisultato: Il valore restituito dalla funzione (se non specificato, R restituisce l’ultimo valore calcolato).\n\n\nEsempio 7.1 Supponiamo di voler creare una funzione che sommi due numeri:\n\nsomma_due &lt;- function(a, b) {\n    a + b\n}\n\nPer utilizzarla:\n\nsomma_due(5, 3)\n#&gt; [1] 8\n\n\nQuesto approccio permette di scrivere codice più organizzato, comprensibile e facile da gestire.\n\n\n7.2.3 Tre Tipi di Funzioni\nSeguendo Wickham et al. (2023), esaminiamo tre tipi di funzioni:\n\nFunzioni per vettori: accettano uno o più vettori come input e restituiscono un vettore.\nFunzioni per data frame: accettano un data frame e restituiscono un altro data frame.\nFunzioni per grafici: accettano un data frame e restituiscono un grafico.\n\n\n7.2.3.1 Funzioni per Vettori\nSupponiamo di voler riscalare i valori di diverse colonne di un data frame tra 0 e 1. Scriviamo la funzione rescale01. La funzione seguente riscalerà un vettore tra 0 e 1:\n\nrescale01 &lt;- function(x) {\n    rng &lt;- range(x, na.rm = TRUE)\n    (x - rng[1]) / (rng[2] - rng[1])\n}\n\n\nEsempio 7.2  \n\ndf &lt;- tibble(\n    x = c(3, 2, 6, 3, 1),\n    y = c(2, 3, 3, 2, 5),\n    grp = c(\"a\", \"a\", \"b\", \"b\", \"a\")\n)\n\ndf |&gt;\n    mutate(across(where(is.numeric), rescale01))\n#&gt; # A tibble: 5 × 3\n#&gt;       x     y grp  \n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;\n#&gt; 1   0.4 0     a    \n#&gt; 2   0.2 0.333 a    \n#&gt; 3   1   0.333 b    \n#&gt; 4   0.4 0     b    \n#&gt; 5   0   1     a\n\n\n\n\n7.2.3.2 Funzioni per Data Frame\nPoniamoci il problema di creare una funzione per riassumere variabili. Un esempio di funzione che calcola statistiche di base:\n\nsummary_stats &lt;- function(data, var) {\n    data |&gt; summarize(\n        min = min({{ var }}, na.rm = TRUE),\n        mean = mean({{ var }}, na.rm = TRUE),\n        max = max({{ var }}, na.rm = TRUE),\n        .groups = \"drop\"\n    )\n}\n\n\nEsempio 7.3  \n\nsummary_stats(df, x)\n#&gt; # A tibble: 1 × 3\n#&gt;     min  mean   max\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1     3     6\n\nSi noti la selezione dinamica con {} (embracing). Se devi passare nomi di variabili come argomenti, usa { }:\n\ngrouped_mean &lt;- function(df, group_var, mean_var) {\n    df |&gt;\n        group_by({{ group_var }}) |&gt;\n        summarize(mean = mean({{ mean_var }}, na.rm = TRUE))\n}\n\n\ngrouped_mean(df, grp, y)\n#&gt; # A tibble: 2 × 2\n#&gt;   grp    mean\n#&gt;   &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1 a      3.33\n#&gt; 2 b      2.5\n\n\n\n\n7.2.3.3 Funzioni per Grafici\nCreare un istogramma personalizzato.\n\nmy_histogram &lt;- function(df, var, binwidth = NULL) {\n    df |&gt;\n        ggplot(aes(x = {{ var }})) +\n        geom_histogram(binwidth = binwidth)\n}\n\n\nEsempio 7.4  \n\ndiamonds |&gt;\n    my_histogram(carat, 0.1)\n\n\n\n\n\n\n\n\n\n\n\n\n7.2.4 Stile e Nomenclatura\nÈ consigliato di usare nomi di funzioni chiari e descrittivi, preferibilmente verbi (es. compute_mean()). Inoltre, è importante mantenere una struttura leggibile, con spazi coerenti e indentazione.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/02_r_programming.html#istruzioni-condizionali-in-r",
    "href": "chapters/R/02_r_programming.html#istruzioni-condizionali-in-r",
    "title": "7  Programmazione in R",
    "section": "7.3 Istruzioni Condizionali in R",
    "text": "7.3 Istruzioni Condizionali in R\nLe istruzioni condizionali permettono di introdurre logica nel tuo codice. Ad esempio, l’operazione x * y si limita a moltiplicare i valori di x e y, senza alcuna logica aggiunta. Con le istruzioni condizionali, puoi dire al programma di eseguire diverse operazioni a seconda che una condizione sia vera (TRUE) o falsa (FALSE).\nL’istruzione condizionale più comune in R è if. Può essere letta come: “Se la condizione è vera, esegui un’azione”. Con else, si estende la logica: “Se la condizione è vera, fai qualcosa; altrimenti fai qualcos’altro”.\nLa struttura generale è questa:\nif (condizione) {\n  # Codice eseguito se la condizione è TRUE\n} else {\n  # Codice eseguito se la condizione è FALSE\n}\nImmagina questa situazione:\n\nUn programmatore riceve la richiesta: “Vai al negozio e compra una confezione di latte, e se hanno le uova, prendi sei confezioni di latte”.\nIl programmatore torna con sei confezioni di latte.\nIl partner chiede: “Perché hai comprato sei confezioni di latte?”\nRisposta: “Perché c’erano le uova”.\n\nIl problema qui sta nell’interpretazione condizionale: se ci sono uova (condizione vera), si doveva prendere una confezione di latte e anche sei uova.\nIn R, questo può essere scritto così:\n\neggs &lt;- TRUE # Indica se il negozio ha le uova\n\nif (eggs == TRUE) {\n    n_milk &lt;- 6 # Prendi 6 confezioni di latte\n} else {\n    n_milk &lt;- 1 # Prendi 1 confezione di latte\n}\n\nn_milk\n#&gt; [1] 6\n\nQuesto codice però ha lo stesso errore della barzelletta: il focus è sul latte, non sulle uova.\n\n7.3.1 Uso di ifelse()\nUn’alternativa più compatta a if e else è la funzione ifelse(), utile soprattutto per vettori. Ad esempio:\n\neggs &lt;- TRUE\nn_milk &lt;- ifelse(eggs == TRUE, yes = 6, no = 1)\n\nn_milk\n#&gt; [1] 6\n\nLa logica è: “Se ci sono uova, assegna 6 a n_milk; altrimenti assegna 1”. Questo approccio è utile per evitare codice ripetitivo.\n\n\n7.3.2 Creare una funzione con istruzioni condizionali\nLe istruzioni condizionali possono essere racchiuse in una funzione per rendere il codice più flessibile e riutilizzabile. Ecco come trasformare l’esempio sopra in una funzione:\n\nmilk &lt;- function(eggs) {\n    if (eggs == TRUE) {\n        6\n    } else {\n        1\n    }\n}\n\nmilk(eggs = TRUE)\n#&gt; [1] 6\n\nOra possiamo chiamare la funzione con eggs = TRUE o eggs = FALSE per determinare quante confezioni di latte prendere.\nIn conclusione, le istruzioni condizionali come if, else e ifelse() sono strumenti fondamentali per introdurre logica e controllo nel tuo codice. Puoi usarle per prendere decisioni, gestire errori e rendere il tuo codice più flessibile ed efficiente. Creare funzioni che incorporano queste istruzioni è un passo fondamentale per scrivere codice ordinato e riutilizzabile.\n\n\n7.3.3 Combinare operatori logici in R\nFinora abbiamo creato funzioni abbastanza semplici e mirate. Ora proviamo a realizzare una funzione leggermente più complessa. Immaginiamo di voler determinare se una persona ha avuto una buona giornata basandoci su due criteri:\n\nLivello di stress: basso (TRUE) o alto (FALSE).\nLivello di supporto sociale percepito: alto (TRUE) o basso (FALSE).\n\nVogliamo creare una funzione che prenda questi due fattori e restituisca un messaggio che descrive come potrebbe essere stata la giornata della persona.\nEcco come possiamo costruire la funzione:\n\ngood_day &lt;- function(low_stress, high_support) {\n    if (low_stress == TRUE && high_support == TRUE) {\n        \"Giornata fantastica! Ti senti calmo e supportato.\"\n    } else if (low_stress == FALSE && high_support == TRUE) {\n        \"Il supporto sociale ti aiuta a gestire lo stress elevato.\"\n    } else if (low_stress == TRUE && high_support == FALSE) {\n        \"Nonostante lo stress sia basso, la mancanza di supporto sociale pesa.\"\n    } else if (low_stress == FALSE && high_support == FALSE) {\n        \"Giornata difficile: stress elevato e poco supporto sociale.\"\n    }\n}\n\nEsempi di utilizzo\nCaso 1: Stress basso e supporto sociale alto\n\ngood_day(low_stress = TRUE, high_support = TRUE)\n#&gt; [1] \"Giornata fantastica! Ti senti calmo e supportato.\"\n\nCaso 2: Stress elevato e supporto sociale alto.\n\ngood_day(FALSE, TRUE)\n#&gt; [1] \"Il supporto sociale ti aiuta a gestire lo stress elevato.\"\n\nCaso 3: Stress basso e supporto sociale basso.\n\ngood_day(TRUE, FALSE)\n#&gt; [1] \"Nonostante lo stress sia basso, la mancanza di supporto sociale pesa.\"\n\nCaso 4: Stress elevato e supporto sociale basso.\n\ngood_day(FALSE, FALSE)\n#&gt; [1] \"Giornata difficile: stress elevato e poco supporto sociale.\"\n\nLa funzione considera tutte le combinazioni di stress e supporto sociale:\n\nStress basso e supporto alto: giornata ideale.\nStress elevato e supporto alto: il supporto aiuta a mitigare lo stress.\nStress basso e supporto basso: la mancanza di supporto rovina una situazione potenzialmente buona.\nStress elevato e supporto basso: la situazione peggiore.\n\nNell’esempio abbiamo usato i seguenti operatori logici:\n\n&& (AND logico): Entrambe le condizioni devono essere vere.\n== (uguale a): Verifica se una variabile è vera o falsa.\n\nAd esempio, questa condizione:\nif (low_stress == TRUE && high_support == TRUE)\nverifica se il livello di stress è basso e il supporto sociale è alto.\nIn conclusione, questa funzione dimostra come combinare condizioni logiche complesse utilizzando operatori logici come && (AND) e || (OR). Grazie a questi strumenti, possiamo gestire facilmente logiche più articolate, mantenendo il codice leggibile e funzionale.\n\n\n7.3.4 Gli operatori logici in R\nGli operatori logici sono essenziali per definire le condizioni nelle istruzioni if. Ecco una tabella riassuntiva con i principali operatori:\n\n\n\n\n\n\n\n\n\nOperatore\nDescrizione tecnica\nSignificato\nEsempio\n\n\n\n\n&&\nAND logico\nEntrambe le condizioni devono essere vere\nif(cond1 == test && cond2 == test)\n\n\n||\nOR logico\nAlmeno una condizione deve essere vera\nif(cond1 == test || cond2 == test)\n\n\n&lt;\nMinore di\nX è minore di Y\nif(X &lt; Y)\n\n\n&gt;\nMaggiore di\nX è maggiore di Y\nif(X &gt; Y)\n\n\n&lt;=\nMinore o uguale a\nX è minore o uguale a Y\nif(X &lt;= Y)\n\n\n&gt;=\nMaggiore o uguale a\nX è maggiore o uguale a Y\nif(X &gt;= Y)\n\n\n==\nUguale a\nX è uguale a Y\nif(X == Y)\n\n\n!=\nDiverso da\nX è diverso da Y\nif(X != Y)",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/02_r_programming.html#cicli-in-r",
    "href": "chapters/R/02_r_programming.html#cicli-in-r",
    "title": "7  Programmazione in R",
    "section": "7.4 Cicli in R",
    "text": "7.4 Cicli in R\nR è particolarmente efficace nell’eseguire attività ripetitive. Quando dobbiamo ripetere un’operazione più volte, possiamo utilizzare un ciclo. I cicli eseguono un insieme di istruzioni per un numero specifico di volte o fino a quando una determinata condizione non è soddisfatta.\nIn R esistono tre tipi principali di cicli:\n\nCiclo for: ripete un’operazione per un numero definito di iterazioni.\nCiclo while: continua a eseguire le istruzioni fino a quando una condizione logica è soddisfatta.\nCiclo repeat: itera indefinitamente fino a quando non viene esplicitamente interrotto con un’istruzione break.\n\nI cicli sono strumenti essenziali in tutti i linguaggi di programmazione, ma in R il loro utilizzo dovrebbe essere valutato attentamente, poiché spesso esistono alternative più efficienti come le funzioni della famiglia apply.\n\n7.4.1 Il ciclo for\nIl ciclo for è il più utilizzato per eseguire un’operazione un numero definito di volte. Ecco un esempio base:\n\nfor (i in 1:5) {\n    print(i)\n}\n#&gt; [1] 1\n#&gt; [1] 2\n#&gt; [1] 3\n#&gt; [1] 4\n#&gt; [1] 5\n\nCome funziona?\n\nL’indice i prende il primo valore della sequenza 1:5 (cioè 1).\nIl corpo del ciclo, ovvero il codice tra { }, viene eseguito.\nAl termine di ogni iterazione, i assume il valore successivo nella sequenza, e il processo si ripete fino all’ultimo valore (5 in questo caso).\n\nAggiungere logica nel corpo del ciclo\nPossiamo aggiungere operazioni all’interno del ciclo, come ad esempio sommare 1 a ogni valore:\n\nfor (i in 1:5) {\n    print(i + 1)\n}\n#&gt; [1] 2\n#&gt; [1] 3\n#&gt; [1] 4\n#&gt; [1] 5\n#&gt; [1] 6\n\n\n\n7.4.2 Il ciclo while\nIl ciclo while continua a eseguire le istruzioni fino a quando una condizione logica è soddisfatta. Ecco un esempio:\n\ni &lt;- 0\nwhile (i &lt;= 4) {\n    i &lt;- i + 1\n    print(i)\n}\n#&gt; [1] 1\n#&gt; [1] 2\n#&gt; [1] 3\n#&gt; [1] 4\n#&gt; [1] 5\n\nCome funziona?\n\nLa condizione logica (i &lt;= 4) viene verificata prima di ogni iterazione.\nSe la condizione è vera, il ciclo esegue il codice tra { }.\nQuando la condizione diventa falsa (i &gt; 4), il ciclo si interrompe.\n\n\n\n7.4.3 Ciclo repeat\nIl ciclo repeat esegue il codice indefinitamente, a meno che non venga interrotto con un’istruzione break:\n\ni &lt;- 0\nrepeat {\n    i &lt;- i + 1\n    print(i)\n    if (i &gt;= 5) {\n        break\n    }\n}\n#&gt; [1] 1\n#&gt; [1] 2\n#&gt; [1] 3\n#&gt; [1] 4\n#&gt; [1] 5\n\nQuando usarlo?\nIl ciclo repeat è raro e viene utilizzato solo in situazioni molto particolari. Nella maggior parte dei casi, for o while sono più adatti.\n\n\n7.4.4 Evitare i cicli: la famiglia di funzioni apply\nI cicli in R sono relativamente lenti, specialmente con dataset di grandi dimensioni. Quando possibile, è preferibile usare funzioni della famiglia apply per ottenere lo stesso risultato in modo più efficiente e con meno rischi di errore.\n\n7.4.4.1 La funzione lapply()\nlapply() esegue una funzione su ciascun elemento di una lista o vettore e restituisce una lista con i risultati.\nEsempio:\n\nlapply(0:4, function(a) {\n    a + 1\n})\n#&gt; [[1]]\n#&gt; [1] 1\n#&gt; \n#&gt; [[2]]\n#&gt; [1] 2\n#&gt; \n#&gt; [[3]]\n#&gt; [1] 3\n#&gt; \n#&gt; [[4]]\n#&gt; [1] 4\n#&gt; \n#&gt; [[5]]\n#&gt; [1] 5\n\n\n\n7.4.4.2 La funzione sapply()\nlapply() restituisce una lista, ma se vuoi un vettore come output, usa sapply():\n\nsapply(0:4, function(a) {\n    a + 1\n})\n#&gt; [1] 1 2 3 4 5\n\n\n\n\n7.4.5 Quando usare i cicli?\nI cicli sono utili quando:\n\nDevi simulare modelli complessi (es. modelli ricorsivi).\nHai bisogno di operazioni che dipendono dai risultati delle iterazioni precedenti.\n\nIn tutti gli altri casi, considera alternative come apply(), lapply() o funzioni simili per un codice più efficiente e meno soggetto a errori.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/02_r_programming.html#linee-guida-per-scrivere-codice",
    "href": "chapters/R/02_r_programming.html#linee-guida-per-scrivere-codice",
    "title": "7  Programmazione in R",
    "section": "7.5 Linee Guida per Scrivere Codice",
    "text": "7.5 Linee Guida per Scrivere Codice\nDi seguito trovi alcune linee guida per scrivere codice chiaro, conciso e riutilizzabile:\n\nEvita di ripeterti: Segui il principio Don’t Repeat Yourself (DRY). Scrivi funzioni e utilizza funzioni come map (per applicare un pezzo di codice iterativamente a tutti gli elementi di un oggetto) per evitare di copiare e incollare variazioni minime dello stesso codice in più parti del progetto.\nSegui uno stile coerente: Adotta una guida di stile per mantenere uniformità nel tuo codice. Per R, raccomandiamo la guida di stile del “tidyverse”, scritta da Hadley Wickham. Questa guida, derivata dalla Google R Style Guide, fornisce istruzioni dettagliate su sintassi del codice, nomi delle variabili, spaziature, indentazioni, commenti, convenzioni per scrivere funzioni, utilizzo delle pipe (metodo per concatenare funzioni), e altro ancora.\nCommenta abbondantemente: Usa i commenti (ad esempio, con #) per spiegare perché ogni parte del codice è necessaria e cosa fa. I commenti rendono il codice più leggibile e facilitano la manutenzione futura.\nTesta il tuo codice: Ogni volta che scrivi codice, verifica che funzioni come previsto. Puoi farlo scrivendo funzioni di test specifiche o controllando manualmente che l’output corrisponda alle aspettative. Abituati a pensare a eventuali edge cases (casi limite) in cui il tuo codice potrebbe non comportarsi come previsto.\nEsegui una revisione del codice: Quando possibile, fai revisionare il tuo codice da un’altra persona per individuare errori e incoerenze. Se non hai nessuno a disposizione, puoi rivedere il tuo codice autonomamente: rileggendo con attenzione, è sorprendente il numero di errori che si possono individuare!\n\nSeguendo queste linee guida, potrai scrivere codice più robusto, leggibile e facile da mantenere nel tempo.1",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/02_r_programming.html#riflessioni-conclusive",
    "href": "chapters/R/02_r_programming.html#riflessioni-conclusive",
    "title": "7  Programmazione in R",
    "section": "7.6 Riflessioni Conclusive",
    "text": "7.6 Riflessioni Conclusive\nScrivere funzioni è un passaggio essenziale per migliorare la leggibilità, l’efficienza e la riutilizzabilità del codice. Funzioni ben progettate semplificano le modifiche, riducono errori e rendono il lavoro più chiaro, sia per te stesso che per i collaboratori futuri. Se trovi che stai copiando e incollando codice più volte, è il momento di pensare a creare una funzione.\nLe istruzioni condizionali, come if, else e ifelse(), sono fondamentali per introdurre logica e controllo nel codice. Permettono di gestire scenari diversi e prendere decisioni dinamiche, migliorando la flessibilità e l’efficienza dei tuoi script. Combinando queste istruzioni con operatori logici come && e ||, puoi affrontare situazioni complesse con un codice chiaro e leggibile.\nI cicli sono potenti strumenti per eseguire operazioni ripetitive, ma in R il loro utilizzo dovrebbe essere limitato ai casi in cui non esistono alternative più efficienti. Le funzioni apply() e simili rappresentano spesso un’opzione migliore per manipolare dati in modo più rapido e leggibile.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/02_r_programming.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/R/02_r_programming.html#informazioni-sullambiente-di-sviluppo",
    "title": "7  Programmazione in R",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2 ggpubr_0.6.0     \n#&gt;  [5] ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0   bayesplot_1.11.1 \n#&gt;  [9] psych_2.4.6.26    scales_1.3.0      markdown_1.13     knitr_1.49       \n#&gt; [13] lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4      \n#&gt; [17] purrr_1.0.2       readr_2.1.5       tidyr_1.3.1       tibble_3.2.1     \n#&gt; [21] ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      xfun_0.49         htmlwidgets_1.6.4 rstatix_0.7.2    \n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    fansi_1.0.6       pacman_0.5.1     \n#&gt; [13] pkgconfig_2.0.3   lifecycle_1.0.4   compiler_4.4.2    farver_2.1.2     \n#&gt; [17] munsell_0.5.1     mnormt_2.1.1      carData_3.0-5     httpuv_1.6.15    \n#&gt; [21] htmltools_0.5.8.1 yaml_2.3.10       Formula_1.2-5     car_3.1-3        \n#&gt; [25] pillar_1.9.0      later_1.4.1       abind_1.4-8       nlme_3.1-166     \n#&gt; [29] mime_0.12         tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4    \n#&gt; [33] labeling_0.4.3    rprojroot_2.0.4   fastmap_1.2.0     grid_4.4.2       \n#&gt; [37] colorspace_2.1-1  cli_3.6.3         magrittr_2.0.3    utf8_1.2.4       \n#&gt; [41] broom_1.0.7       withr_3.0.2       backports_1.5.0   promises_1.3.2   \n#&gt; [45] timechange_0.3.0  rmarkdown_2.29    ggsignif_0.6.4    hms_1.1.3        \n#&gt; [49] shiny_1.9.1       evaluate_1.0.1    miniUI_0.1.1.1    rlang_1.1.4      \n#&gt; [53] Rcpp_1.0.13-1     xtable_1.8-4      glue_1.8.0        jsonlite_1.8.9   \n#&gt; [57] R6_2.5.1",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/02_r_programming.html#bibliografia",
    "href": "chapters/R/02_r_programming.html#bibliografia",
    "title": "7  Programmazione in R",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nWickham, H., Çetinkaya-Rundel, M., & Grolemund, G. (2023). R for data science. \"O’Reilly Media, Inc.\".",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/02_r_programming.html#footnotes",
    "href": "chapters/R/02_r_programming.html#footnotes",
    "title": "7  Programmazione in R",
    "section": "",
    "text": "Un’ottima introduzione alle regole di stile per un progetto di analisi dei dati è fornita in questo capitolo.↩︎",
    "crumbs": [
      "R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_packages.html",
    "href": "chapters/R/03_r_packages.html",
    "title": "8  Pacchetti in R",
    "section": "",
    "text": "8.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nI pacchetti R sono estensioni del linguaggio di programmazione statistica R. Questi pacchetti forniscono una raccolta di risorse che possono essere utilizzate per ampliare le funzionalità di base di R. Ogni pacchetto generalmente include:\nI pacchetti R sono distribuiti e installati attraverso repository centralizzati, il più noto dei quali è CRAN (Comprehensive R Archive Network). CRAN garantisce la qualità e l’affidabilità dei pacchetti, sottoponendoli a controlli rigorosi prima della pubblicazione.\nLa vasta disponibilità di pacchetti è una delle ragioni principali della popolarità di R.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pacchetti in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_packages.html#introduzione",
    "href": "chapters/R/03_r_packages.html#introduzione",
    "title": "8  Pacchetti in R",
    "section": "",
    "text": "Codice: funzioni e script scritti in R (e talvolta in altri linguaggi come C++ o Fortran) che implementano specifiche analisi o strumenti.\nDati: dataset di esempio o utili per testare e dimostrare le funzionalità del pacchetto.\nDocumentazione: file descrittivi che spiegano come utilizzare il pacchetto, spesso in formato manuale o vignette (tutorial pratici).",
    "crumbs": [
      "R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pacchetti in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_packages.html#installare-i-pacchetti-r",
    "href": "chapters/R/03_r_packages.html#installare-i-pacchetti-r",
    "title": "8  Pacchetti in R",
    "section": "8.2 Installare i Pacchetti R",
    "text": "8.2 Installare i Pacchetti R\nQuando installi R, vengono installati automaticamente alcuni pacchetti base. Tuttavia, hai la possibilità di aggiungere ulteriori pacchetti che trovi utili per i tuoi scopi. Questi pacchetti sono memorizzati sui server di R (mirror), e l’installazione di un nuovo pacchetto richiede una connessione internet al mirror CRAN che hai scelto durante l’installazione di R.\nPer installare un pacchetto, utilizza il comando:\ninstall.packages(\"&lt;nome_pacchetto&gt;\")\nSostituisci &lt;nome_pacchetto&gt; con il nome del pacchetto che desideri installare. Ad esempio, se vuoi installare il pacchetto rio (utile per importare i dati in R), puoi digitare:\ninstall.packages(\"rio\")   # Non dimenticare le virgolette!",
    "crumbs": [
      "R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pacchetti in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_packages.html#caricamento-di-un-pacchetto",
    "href": "chapters/R/03_r_packages.html#caricamento-di-un-pacchetto",
    "title": "8  Pacchetti in R",
    "section": "8.3 Caricamento di un pacchetto",
    "text": "8.3 Caricamento di un pacchetto\nOgni volta che avvii una nuova sessione di R, se desideri utilizzare un pacchetto, devi caricarlo manualmente. Questo si fa con il comando library(). Ad esempio, dopo aver installato rio, per utilizzarlo digita:\nlibrary(rio)   # Nota: le virgolette non sono necessarie, ma puoi usarle se preferisci.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pacchetti in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/03_r_packages.html#utilizzo-delle-funzioni-di-un-pacchetto-senza-caricarlo",
    "href": "chapters/R/03_r_packages.html#utilizzo-delle-funzioni-di-un-pacchetto-senza-caricarlo",
    "title": "8  Pacchetti in R",
    "section": "8.4 Utilizzo delle funzioni di un pacchetto senza caricarlo",
    "text": "8.4 Utilizzo delle funzioni di un pacchetto senza caricarlo\nSe hai bisogno di utilizzare una funzione specifica di un pacchetto, ma sai che la userai solo una volta, puoi evitare di caricare l’intero pacchetto con library(). Ad esempio, invece di scrivere:\nlibrary(nome_pacchetto)\nfunzione(x = 2, sd = 3)\npuoi accedere direttamente alla funzione usando l’operatore :::\nnome_pacchetto::funzione(x = 2, sd = 3)\nQuesto approccio è utile per funzioni che usi raramente o una sola volta. Personalmente, utilizzo :: anche quando ho già caricato il pacchetto, per ricordare a “me del futuro” da quale pacchetto proviene una determinata funzione. Questo può rendere il codice più leggibile e comprensibile nel tempo.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pacchetti in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/04_quarto.html",
    "href": "chapters/R/04_quarto.html",
    "title": "9  Quarto",
    "section": "",
    "text": "9.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nQuarto si inserisce nella tradizione del literate programming, un approccio introdotto da Donald Knuth negli anni ’80. Il literate programming nasce con l’idea di combinare codice e testo descrittivo in un unico documento, rendendo il programma non solo eseguibile ma anche leggibile e comprensibile agli esseri umani. Questo approccio mira a superare la separazione tra codice e documentazione, permettendo di spiegare non solo come un programma funziona, ma anche perché è stato scritto in un certo modo.\nQuesta filosofia è particolarmente rilevante nella scienza dei dati e nell’analisi statistica, dove la riproducibilità e la trasparenza sono fondamentali. In questo contesto, strumenti come Quarto giocano un ruolo chiave, permettendo di integrare codice, risultati e narrazione in un unico documento. Con Quarto, è possibile produrre report, articoli, presentazioni e altri output in diversi formati (HTML, PDF, Word, ecc.), combinando testi interpretativi, risultati numerici e grafici.\nQuarto si distingue per la sua flessibilità e per il supporto a diversi linguaggi di programmazione, tra cui R, Python e Julia. Questo strumento può essere utilizzato in tre modi principali:\nPur non essendo un pacchetto R, Quarto è uno strumento CLI (Command Line Interface). Tuttavia, grazie a RStudio, l’installazione e l’utilizzo di Quarto sono gestiti automaticamente, rendendolo accessibile anche a chi ha meno familiarità con il terminale.\nQuarto rappresenta quindi una naturale evoluzione del concetto di literate programming, combinando praticità e rigore scientifico in un unico ambiente di lavoro.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "chapters/R/04_quarto.html#introduzione",
    "href": "chapters/R/04_quarto.html#introduzione",
    "title": "9  Quarto",
    "section": "",
    "text": "Presentare conclusioni: condividere i risultati senza esporre il codice sottostante.\nDocumentare il processo analitico: includere sia il codice che i risultati per garantire trasparenza e riproducibilità.\nAnnotare l’analisi: integrare interpretazioni e decisioni prese durante il lavoro analitico.\n\n\n\n\n9.1.1 Creare un documento Quarto\nUn file Quarto ha estensione .qmd e segue questa struttura:\n\nQuesto file include:\n\nUn’intestazione YAML (metadati del documento).\nBlocchi di codice delimitati da ```.\nTesto scritto in Markdown con formattazioni semplici come titoli (# Titolo), corsivi (*testo*), ecc.\n\n\n\n9.1.2 Editor visivo e sorgente\n\nEditor visivo: simile a Google Docs, offre un’interfaccia WYSIWYM (What You See Is What You Mean). Consente di inserire facilmente immagini, tabelle, citazioni e altro.\nEditor sorgente: consente un controllo diretto sul Markdown, utile per debug e personalizzazioni avanzate.\n\n\n\n9.1.3 Blocchi di codice\nI blocchi di codice (chiamati “chunks”) eseguono codice e visualizzano i risultati. Ogni chunk è delimitato da ``` e può includere opzioni specifiche:\n#| label: esempio\n#| echo: false\n1 + 1\nLe opzioni più comuni includono:\n\necho: false (nasconde il codice nel report),\neval: false (non esegue il codice),\nmessage: false e warning: false (nasconde messaggi o avvisi).\n\n\n\n9.1.4 Figure\nLe figure possono essere generate tramite codice (es. ggplot()) o inserite come file esterni. Le opzioni più comuni per il controllo delle dimensioni sono:\n\nfig-width e fig-height (dimensioni della figura in pollici),\nout-width (percentuale di larghezza del documento),\nfig-asp (rapporto d’aspetto, es. 0.618 per il rapporto aureo).\n\nEsempio:\n#| fig-width: 6\nggplot(data, aes(x, y)) + geom_point()\n\n\n9.1.5 Tabelle\nLe tabelle possono essere stampate direttamente o personalizzate con funzioni come knitr::kable() o pacchetti come gt:\n\nknitr::kable(head(mtcars))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\n\n\n\n\nMazda RX4\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\nMazda RX4 Wag\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\nDatsun 710\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\nHornet 4 Drive\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\nHornet Sportabout\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\nValiant\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n\n\n\n9.1.6 Caching\nPer velocizzare i documenti con calcoli complessi, Quarto supporta la memorizzazione dei risultati:\n\ncache: true salva i risultati di un chunk, evitando di ricalcolarli se il codice non cambia.\ndependson specifica dipendenze tra chunk.\n\n\n\n9.1.7 Citazioni e bibliografie in Quarto\nQuarto supporta la generazione automatica di citazioni e bibliografie in formati personalizzati, come lo stile APA. Per includere riferimenti, è necessario creare un file .bib (ad esempio, references.bib) che contenga le citazioni in formato BibTeX. Puoi ottenere queste citazioni direttamente da Google Scholar o altri database accademici. Ecco un esempio:\n@article{ceccarini2024age,\n  title={Age-dependent changes in the anger superiority effect: Evidence from a visual search task},\n  author={Ceccarini, Francesco and Colpizzi, Ilaria and Caudek, Corrado},\n  journal={Psychonomic Bulletin \\& Review},\n  pages={1--10},\n  year={2024},\n  publisher={Springer}\n}\n\n9.1.7.1 Configurazione del file YAML\nNel file .qmd, aggiungi le seguenti righe all’intestazione YAML per collegare il file references.bib e configurare lo stile bibliografico:\nbibliography: references.bib\nbiblio-style: apalike\ncsl: apa.csl\n\nbibliography: specifica il percorso del file .bib (in questo esempio si assume che si trovi nella stessa cartella del file Quarto).\nbiblio-style: imposta lo stile delle citazioni (ad esempio, apalike per uno stile simile all’APA).\ncsl: permette di utilizzare uno stile di citazione personalizzato (es., apa.csl), che puoi scaricare facilmente da siti come Zotero Style Repository.\n\n\n\n9.1.7.2 Citazioni Inline\nAll’interno di un documento .qmd, le citazioni vengono aggiunte utilizzando il simbolo @ seguito dall’identificativo della citazione specificato nel file .bib. Ad esempio:\n... come evidenziato da @ceccarini2024age, si osserva che...\nQuarto genera automaticamente la bibliografia, includendo solo i riferimenti effettivamente citati nel documento. La bibliografia viene aggiunta alla fine del file renderizzato (ad esempio, in formato HTML o PDF).\nAd esempio, nel caso di un documento .qmd, il testo sopra sarà visualizzato così:\n\n… come evidenziato da Ceccarini et al. (2024), si osserva che…\n\nLa citazione completa sarà inclusa automaticamente nella bibliografia, posizionata alla fine della pagina web o del documento finale.1",
    "crumbs": [
      "R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "chapters/R/04_quarto.html#riflessioni-conclusive",
    "href": "chapters/R/04_quarto.html#riflessioni-conclusive",
    "title": "9  Quarto",
    "section": "9.2 Riflessioni Conclusive",
    "text": "9.2 Riflessioni Conclusive\nQuarto è uno strumento potente per la creazione di documenti riproducibili e ben strutturati, integrando codice, risultati e testo descrittivo in un unico file. Questa introduzione dovrebbe essere sufficiente per iniziare a lavorare con Quarto, ma c’è ancora molto da imparare. Il modo migliore per rimanere aggiornati è consultare il sito ufficiale di Quarto: https://quarto.org.\nUn argomento importante che non abbiamo trattato qui riguarda i dettagli di come comunicare in modo accurato le proprie idee agli altri. Per migliorare le proprie capacità di scrittura, Wickham et al. (2023) consigliano due libri: Style: Lessons in Clarity and Grace di Joseph M. Williams & Joseph Bizup, e The Sense of Structure: Writing from the Reader’s Perspective di George Gopen. Una serie di brevi articoli sulla scrittura sono offerti da George Gopen e sono disponibili su https://www.georgegopen.com/litigation-articles.html.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "chapters/R/04_quarto.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/R/04_quarto.html#informazioni-sullambiente-di-sviluppo",
    "title": "9  Quarto",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2 ggpubr_0.6.0     \n#&gt;  [5] ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0   bayesplot_1.11.1 \n#&gt;  [9] psych_2.4.6.26    scales_1.3.0      markdown_1.13     knitr_1.49       \n#&gt; [13] lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4      \n#&gt; [17] purrr_1.0.2       readr_2.1.5       tidyr_1.3.1       tibble_3.2.1     \n#&gt; [21] ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      xfun_0.49         htmlwidgets_1.6.4 rstatix_0.7.2    \n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    fansi_1.0.6       pacman_0.5.1     \n#&gt; [13] pkgconfig_2.0.3   lifecycle_1.0.4   compiler_4.4.2    farver_2.1.2     \n#&gt; [17] munsell_0.5.1     mnormt_2.1.1      carData_3.0-5     httpuv_1.6.15    \n#&gt; [21] htmltools_0.5.8.1 yaml_2.3.10       Formula_1.2-5     car_3.1-3        \n#&gt; [25] pillar_1.9.0      later_1.4.1       abind_1.4-8       nlme_3.1-166     \n#&gt; [29] mime_0.12         tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4    \n#&gt; [33] rprojroot_2.0.4   fastmap_1.2.0     grid_4.4.2        colorspace_2.1-1 \n#&gt; [37] cli_3.6.3         magrittr_2.0.3    utf8_1.2.4        broom_1.0.7      \n#&gt; [41] withr_3.0.2       backports_1.5.0   promises_1.3.2    timechange_0.3.0 \n#&gt; [45] rmarkdown_2.29    ggsignif_0.6.4    hms_1.1.3         shiny_1.9.1      \n#&gt; [49] evaluate_1.0.1    miniUI_0.1.1.1    rlang_1.1.4       Rcpp_1.0.13-1    \n#&gt; [53] xtable_1.8-4      glue_1.8.0        jsonlite_1.8.9    R6_2.5.1",
    "crumbs": [
      "R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "chapters/R/04_quarto.html#bibliografia",
    "href": "chapters/R/04_quarto.html#bibliografia",
    "title": "9  Quarto",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nCeccarini, F., Colpizzi, I., & Caudek, C. (2024). Age-dependent changes in the anger superiority effect: Evidence from a visual search task. Psychonomic Bulletin & Review, 1–10.\n\n\nWickham, H., Çetinkaya-Rundel, M., & Grolemund, G. (2023). R for data science. \"O’Reilly Media, Inc.\".",
    "crumbs": [
      "R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "chapters/R/04_quarto.html#footnotes",
    "href": "chapters/R/04_quarto.html#footnotes",
    "title": "9  Quarto",
    "section": "",
    "text": "Si noti la citazione Ceccarini et al. (2024) nella bibliografia della presente pagina web.↩︎",
    "crumbs": [
      "R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_environment.html",
    "href": "chapters/R/05_environment.html",
    "title": "10  L’ambiente di programmazione in R",
    "section": "",
    "text": "10.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nProgrammare presuppone necessariamente un ambiente di programmazione. Una cattiva gestione di questo ambiente può causare il malfunzionamento degli script, rendendo fondamentale imparare a gestirlo correttamente.\nL’ambiente può influenzare persino il comportamento delle funzioni più basilari. Considera il seguente esempio:\nQuesto potrebbe produrre il seguente output:\nTuttavia, modificando l’opzione di larghezza in R, il comportamento cambia:\nIn questo caso, l’output potrebbe essere:\nLa differenza è dovuta a un’opzione dell’ambiente, width, che regola il numero massimo di caratteri visualizzati per ogni riga.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>L'ambiente di programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_environment.html#introduzione",
    "href": "chapters/R/05_environment.html#introduzione",
    "title": "10  L’ambiente di programmazione in R",
    "section": "",
    "text": "Nota: In R, il termine “ambiente” ha un significato specifico, riferendosi allo spazio di lavoro in cui gli oggetti vengono memorizzati durante una sessione. In questo capitolo, tuttavia, il termine si riferisce allo stato complessivo del tuo computer mentre programmi, inclusa l’organizzazione dei file, la versione di R che stai usando e altre impostazioni.\n\n\nprint(1:9)\n\n[1] 1 2 3 4 5 6 7 8 9\n\n# Dopo aver modificato options(width)\noptions(width = 10)\nprint(1:9)\n\n[1] 1 2 3\n[4] 4 5 6\n[7] 7 8 9",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>L'ambiente di programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_environment.html#file-system",
    "href": "chapters/R/05_environment.html#file-system",
    "title": "10  L’ambiente di programmazione in R",
    "section": "10.2 File system",
    "text": "10.2 File system\nPrima di iniziare a organizzare un progetto in R, è fondamentale seguire alcune linee guida per strutturare e nominare i file in modo efficace. Spesso si tende a sottovalutare l’importanza di una buona organizzazione, ma adottare un sistema coerente può far risparmiare tempo prezioso nella ricerca e gestione dei progetti passati. Danielle Navarro ha creato una presentazione sulla struttura dei progetti, nella quale propone tre principi fondamentali per la gestione dei file:\n\nEssere gentili per le macchine.\nEssere gentili per gli esseri umani.\nFacilitare l’ordinamento e la ricerca.\n\n\n10.2.1 Essere gentili con le macchine\nLe macchine possono confondersi con spazi, caratteri speciali (come ^.*?+|$“), e lettere accentate. Per evitare problemi:\n\nUsa solo lettere minuscole, numeri, trattini _ o -.\nEvita caratteri speciali e spazi nei nomi dei file.\nUsa estensioni coerenti, come .R per gli script R.\n\nEsempi:\n# Buono\nprogetto01_analisi_dati.R\n\n# Cattivo\nProgetto \"Analisi Dati\".R\n\n\n10.2.2 Essere gentili con gli umani\nGli esseri umani hanno bisogno di contesto. Evita nomi vaghi e usa descrizioni significative.\n# Buono\nanalisi01_statistiche_descrittive.R\nnote02_intro_modello.docx\n\n# Cattivo\n01.R\nappunti.docx\n\n\n\n\n\n\nImportante\n\n\n\nEvitate categoricamente l’uso di spazi nei nomi di file, cartelle o oggetti in R. Anche se il sistema operativo potrebbe consentirlo, questa pratica può generare problemi futuri, complicare il debugging e rendere il codice meno leggibile e portabile. Per evitare questi inconvenienti, adottate sempre nomi privi di spazi, preferendo separatori come trattini bassi (_) o trattini (-).\n\n\n\n\n10.2.3 Facilitare l’ordinamento e la ricerca\nSe i nomi dei file includono date, usa sempre il formato YYYY-MM-DD per permettere un ordinamento automatico.\n# Buono\n2024-01-01_analisi.R\n2024-02-15_riassunto.docx\n\n# Cattivo\n1-gennaio-2024.R\nriassunto-15-02-2024.docx\nSe devi ordinare i file in base a qualcosa di diverso dalle date, usa numeri con lo zero iniziale per mantenere l’ordine.\nreading01_shakespeare_romeo-and-juliet.docx\nreading02_shakespeare_romeo-and-juliet.docx\n...\nreading11_shakespeare_romeo-and-juliet.docx\nnotes01_shakespeare_romeo-and-juliet.docx\n...",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>L'ambiente di programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_environment.html#versioni-di-r-e-pacchetti",
    "href": "chapters/R/05_environment.html#versioni-di-r-e-pacchetti",
    "title": "10  L’ambiente di programmazione in R",
    "section": "10.3 Versioni di R e pacchetti",
    "text": "10.3 Versioni di R e pacchetti\nAggiornare regolarmente R e i pacchetti è essenziale per evitare bug e sfruttare le nuove funzionalità. Ecco alcune buone pratiche:\n\nEsegui update.packages() ogni poche settimane per aggiornare i pacchetti.\nAggiorna la versione di R ogni pochi mesi. Su Windows puoi usare il pacchetto installr, mentre su altri sistemi puoi scaricare l’ultima versione dal sito ufficiale di R.\nMantieni aggiornato anche il sistema operativo.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>L'ambiente di programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_environment.html#progetti-in-r",
    "href": "chapters/R/05_environment.html#progetti-in-r",
    "title": "10  L’ambiente di programmazione in R",
    "section": "10.4 Progetti in R",
    "text": "10.4 Progetti in R\nSe hai seguito i consigli finora, avrai creato una cartella per tutti i tuoi progetti di programmazione e la tua installazione di R sarà aggiornata. Ora è il momento di organizzare i tuoi progetti in R.\n\n10.4.1 Percorsi Assoluti e Relativi\nUn percorso assoluto parte dalla directory principale del tuo computer (ad esempio, / su Linux/MacOS o C:/ su Windows) e indica in modo completo e univoco la posizione di un file o di una cartella. Un percorso relativo, invece, parte dalla directory corrente del progetto o dalla directory di lavoro impostata e descrive la posizione di un file in relazione a questa.\nAd esempio, il percorso assoluto del file utilizzato per generare questa pagina HTML potrebbe essere ottenuto così:\n\nfs::path_abs(\"05_environment.qmd\")\n#&gt; /Users/corradocaudek/_repositories/psicometria-r/chapters/R/05_environment.qmd\n\nSe il progetto si trova nella cartella psicometria-r, possiamo utilizzare la funzione here() del pacchetto here per indicare la posizione del file 05_environment.qmd in modo relativo. Ecco un esempio:\nfile.exists(here::here(\"chapters\", \"R\", \"05_environment.qmd\"))\nIn questo caso, il file 05_environment.qmd è contenuto nella cartella chapters/R, che si trova all’interno della directory principale del progetto. Grazie a here(), non è necessario specificare manualmente la posizione del progetto: questa funzione identifica automaticamente la directory principale e consente di indicare solo il percorso relativo del file rispetto ad essa. In altre parole, puoi riferirti al file 05_environment.qmd semplicemente fornendo il percorso relativo all’interno della struttura del progetto, lasciando a here() il compito di gestire il contesto globale.\n\n10.4.1.1 Perché preferire i percorsi relativi?\nL’utilizzo di percorsi relativi con here() offre numerosi vantaggi:\n\nPortabilità: Il codice diventa più semplice da condividere, poiché non dipende dalla struttura delle directory specifica del computer su cui è stato scritto.\nOrganizzazione: Favorisce una struttura chiara e coerente all’interno del progetto, rendendo più facile individuare e accedere ai file.\nAffidabilità: Riduce il rischio di errori dovuti a percorsi assoluti errati, soprattutto quando il progetto viene spostato o condiviso.\n\n\n\n10.4.1.2 Buone pratiche\n\nUsare sempre percorsi relativi: Questo assicura che il progetto sia facilmente eseguibile su altri sistemi senza necessità di modifiche ai percorsi.\nImpostare una struttura coerente del progetto: Organizzare i file in cartelle ben definite (ad esempio, data, scripts, outputs) facilita l’uso di percorsi relativi.\n\nIn sintesi, specificare i percorsi relativi rispetto alla directory principale del progetto è una buona pratica essenziale per garantire portabilità, organizzazione e riproducibilità del lavoro.\n\n\n\n10.4.2 Creare un progetto in R\nUn progetto R è semplicemente una cartella con un file .Rproj. Puoi crearne uno con RStudio o con il pacchetto usethis.\nIn RStudio:\n\nVai su File &gt; New Project.\nSeleziona New Directory &gt; New Project.\nDai un nome al progetto e scegli la sua posizione.\n\nCon usethis:\nusethis::create_project(\"path/alla/cartella\")\nEsempio:\nusethis::create_project(\"/Users/corradocaudek/_repositories\")\nVedremo nel Capitolo 12 come organizzare i file all’interno di un progetto.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>L'ambiente di programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_environment.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/R/05_environment.html#informazioni-sullambiente-di-sviluppo",
    "title": "10  L’ambiente di programmazione in R",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2 ggpubr_0.6.0     \n#&gt;  [5] ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0   bayesplot_1.11.1 \n#&gt;  [9] psych_2.4.6.26    scales_1.3.0      markdown_1.13     knitr_1.49       \n#&gt; [13] lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4      \n#&gt; [17] purrr_1.0.2       readr_2.1.5       tidyr_1.3.1       tibble_3.2.1     \n#&gt; [21] ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      xfun_0.49         htmlwidgets_1.6.4 rstatix_0.7.2    \n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    fansi_1.0.6       pacman_0.5.1     \n#&gt; [13] pkgconfig_2.0.3   lifecycle_1.0.4   compiler_4.4.2    farver_2.1.2     \n#&gt; [17] munsell_0.5.1     mnormt_2.1.1      carData_3.0-5     httpuv_1.6.15    \n#&gt; [21] htmltools_0.5.8.1 yaml_2.3.10       Formula_1.2-5     crayon_1.5.3     \n#&gt; [25] car_3.1-3         pillar_1.9.0      later_1.4.1       abind_1.4-8      \n#&gt; [29] nlme_3.1-166      mime_0.12         tidyselect_1.2.1  digest_0.6.37    \n#&gt; [33] stringi_1.8.4     rprojroot_2.0.4   fastmap_1.2.0     grid_4.4.2       \n#&gt; [37] colorspace_2.1-1  cli_3.6.3         magrittr_2.0.3    utf8_1.2.4       \n#&gt; [41] broom_1.0.7       withr_3.0.2       backports_1.5.0   promises_1.3.2   \n#&gt; [45] timechange_0.3.0  rmarkdown_2.29    ggsignif_0.6.4    hms_1.1.3        \n#&gt; [49] shiny_1.9.1       evaluate_1.0.1    miniUI_0.1.1.1    rlang_1.1.4      \n#&gt; [53] Rcpp_1.0.13-1     xtable_1.8-4      glue_1.8.0        jsonlite_1.8.9   \n#&gt; [57] R6_2.5.1          fs_1.6.5",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>L'ambiente di programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/05_environment.html#bibliografia",
    "href": "chapters/R/05_environment.html#bibliografia",
    "title": "10  L’ambiente di programmazione in R",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nYu, B., & Barter, R. L. (2024). Veridical data science: The practice of responsible data analysis and decision making. MIT Press.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>L'ambiente di programmazione in R</span>"
    ]
  },
  {
    "objectID": "chapters/R/06_ai.html",
    "href": "chapters/R/06_ai.html",
    "title": "11  Utilizzo di strumenti AI per la programmazione",
    "section": "",
    "text": "11.1 Introduzione\nIl panorama della programmazione sta vivendo una trasformazione radicale grazie all’avvento degli strumenti di intelligenza artificiale (AI). Questi assistenti innovativi stanno ridefinendo il modo in cui sviluppatori, ricercatori e studenti affrontano la scrittura e la comprensione del codice, con un impatto particolarmente significativo nell’ecosistema di linguaggi come R.\nL’intelligenza artificiale offre una nuova generazione di strumenti che superano i tradizionali ambienti di sviluppo. Piattaforme come ChatGPT, Google Gemini e Claude.ai sono capaci di generare codice, spiegare concetti complessi e supportare gli sviluppatori in modi prima inimmaginabili. Nell’ambiente di R, soluzioni come il pacchetto gptstudio integrano direttamente l’AI in strumenti come RStudio, aprendo nuove possibilità per l’analisi dei dati e lo sviluppo di modelli statistici.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Utilizzo di strumenti AI per la programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/06_ai.html#potenzialità-e-sfide-dellai",
    "href": "chapters/R/06_ai.html#potenzialità-e-sfide-dellai",
    "title": "11  Utilizzo di strumenti AI per la programmazione",
    "section": "11.2 Potenzialità e Sfide dell’AI",
    "text": "11.2 Potenzialità e Sfide dell’AI\nGli strumenti di intelligenza artificiale stanno rivoluzionando la programmazione in R, ma presentano anche alcune sfide. I modelli di linguaggio di grandi dimensioni (LLM) possono accelerare significativamente i flussi di lavoro, ma presentano anche alcune limitazioni intrinseche. Possono generare codice inesatto, introdurre bias involontari o produrre contenuti che richiedono una verifica accurata.\nGli strumenti di intelligenza artificiale possono fornire supporto in molteplici aree:\n\nSupporto Concettuale: Gli LLM si rivelano particolarmente utili nell’affrontare domande complesse relative a metodi statistici, algoritmi e approcci di analisi dei dati. La qualità delle risposte migliora significativamente quando le domande vengono formulate in modo chiaro e dettagliato.\nGenerazione e Completamento del Codice: Questi strumenti possono assistere gli sviluppatori nella scrittura di codice, suggerendo completamenti, identificando potenziali errori e persino generando interi script basati su descrizioni testuali.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Utilizzo di strumenti AI per la programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/06_ai.html#panoramica-comparativa-dei-principali-strumenti-ai",
    "href": "chapters/R/06_ai.html#panoramica-comparativa-dei-principali-strumenti-ai",
    "title": "11  Utilizzo di strumenti AI per la programmazione",
    "section": "11.3 Panoramica Comparativa dei Principali Strumenti AI",
    "text": "11.3 Panoramica Comparativa dei Principali Strumenti AI\n\nClaude.ai (Anthropic): Si distingue per l’affidabilità e la coerenza delle risposte. Accessibile tramite un’interfaccia web gratuita, combina una notevole capacità di comprensione contestuale con la generazione efficace di codice, rendendolo uno strumento versatile e intuitivo. -Gemini (Google): Apprezzato per la velocità e la sintesi delle risposte, è particolarmente adatto per chi cerca risultati rapidi. Tuttavia, può talvolta mostrare una mancanza di approfondimento nell’analisi, limitandone l’efficacia per compiti più complessi.\nChatGPT (OpenAI): Riconosciuto come uno standard di riferimento nella qualità delle risposte, si distingue per la capacità di affrontare una vasta gamma di argomenti con precisione. Inoltre, offre flessibilità d’uso grazie all’integrazione con diversi add-in e strumenti di terze parti, ampliandone le potenzialità in vari contesti applicativi.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Utilizzo di strumenti AI per la programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/06_ai.html#considerazioni-etiche-e-pratiche",
    "href": "chapters/R/06_ai.html#considerazioni-etiche-e-pratiche",
    "title": "11  Utilizzo di strumenti AI per la programmazione",
    "section": "11.4 Considerazioni Etiche e Pratiche",
    "text": "11.4 Considerazioni Etiche e Pratiche\nL’adozione di strumenti di intelligenza artificiale solleva questioni etiche fondamentali che richiedono una riflessione critica:\n\nTrasparenza: I dataset utilizzati per addestrare questi modelli sono spesso opachi e poco documentati, sollevando interrogativi sulla loro composizione e potenziali bias.\nEquità di Accesso: Nonostante le potenzialità rivoluzionarie, l’accesso a questi strumenti non è uniformemente distribuito, creando potenziali disuguaglianze nel mondo della ricerca e dello sviluppo.\nResponsabilità: Rimane poco chiaro come attribuire la responsabilità per i risultati generati da questi sistemi di intelligenza artificiale.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Utilizzo di strumenti AI per la programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/06_ai.html#conclusioni",
    "href": "chapters/R/06_ai.html#conclusioni",
    "title": "11  Utilizzo di strumenti AI per la programmazione",
    "section": "11.5 Conclusioni",
    "text": "11.5 Conclusioni\nGli strumenti AI stanno trasformando la programmazione, offrendo un supporto senza precedenti per la risoluzione di problemi complessi e la generazione di codice. Tuttavia, il loro utilizzo deve essere accompagnato da un approccio critico per verificare i risultati e valutare le implicazioni etiche.\nL’intelligenza artificiale non sostituirà gli sviluppatori, ma si affermerà come un alleato indispensabile per ampliare la creatività e le competenze umane, ridefinendo il modo in cui affrontiamo le sfide del futuro (Bonnefon et al., 2024; Liu & Li, 2024).",
    "crumbs": [
      "R",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Utilizzo di strumenti AI per la programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/R/06_ai.html#bibliografia",
    "href": "chapters/R/06_ai.html#bibliografia",
    "title": "11  Utilizzo di strumenti AI per la programmazione",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBonnefon, J.-F., Rahwan, I., & Shariff, A. (2024). The moral psychology of Artificial Intelligence. Annual Review of Psychology, 75(1), 653–675.\n\n\nLiu, J., & Li, S. (2024). Toward Artificial Intelligence-Human Paired Programming: A Review of the Educational Applications and Research on Artificial Intelligence Code-Generation Tools. Journal of Educational Computing Research, 07356331241240460.",
    "crumbs": [
      "R",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Utilizzo di strumenti AI per la programmazione</span>"
    ]
  },
  {
    "objectID": "chapters/eda/introduction_eda.html",
    "href": "chapters/eda/introduction_eda.html",
    "title": "Introduzione",
    "section": "",
    "text": "Dopo aver acquisito un dataset, è fondamentale comprendere a fondo le caratteristiche dei dati in esso contenuti. Sebbene le statistiche descrittive e altre misure numeriche siano spesso efficaci per ottenere una visione d’insieme, talvolta è un’immagine a valere più di mille parole.\nIn questa sezione della dispensa, esploreremo alcuni concetti chiave della statistica descrittiva. Oltre a fornire definizioni teoriche, presenteremo istruzioni pratiche in Python per condurre analisi statistiche su dati reali. Il capitolo si concluderà con una riflessione critica sui limiti di un approccio epistemologico basato esclusivamente sull’analisi delle associazioni tra variabili, evidenziando l’importanza di indagare le cause sottostanti ai fenomeni osservati.",
    "crumbs": [
      "EDA",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html",
    "href": "chapters/eda/01_project_structure.html",
    "title": "12  Le fasi del progetto di analisi dei dati",
    "section": "",
    "text": "12.1 Introduzione\nUna gestione accurata ed efficace dei dati è fondamentale, soprattutto in discipline come la psicologia, dove l’analisi di dataset complessi è una componente centrale della ricerca. Assicurare che i dati siano raccolti con precisione, organizzati in modo chiaro e facilmente accessibili per analisi e verifiche è essenziale per preservare l’integrità del lavoro scientifico e promuovere la sua riproducibilità. Una gestione rigorosa dei dati garantisce qualità e affidabilità durante tutte le fasi del progetto, dalla raccolta alla documentazione dei processi di elaborazione e delle eventuali modifiche apportate.\nDati ben organizzati e documentati non solo semplificano e rendono più efficiente il processo di analisi, ma riducono anche il rischio di errori, migliorando l’utilizzabilità e l’interpretazione delle informazioni. Questo aspetto è particolarmente rilevante quando si lavora con dataset provenienti da fonti eterogenee o con strutture complesse. Inoltre, la trasparenza e la completezza nella gestione dei dati rappresentano una condizione imprescindibile per garantire la riproducibilità della ricerca, pilastro fondamentale della scienza.\nLa possibilità per altri ricercatori di replicare i risultati utilizzando gli stessi dati e metodi rafforza la credibilità delle conclusioni e contribuisce a costruire un progresso scientifico condiviso e solido. Una gestione dei dati responsabile, dunque, non è solo una buona pratica, ma una necessità per la produzione di conoscenze affidabili e sostenibili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#capacità-di-gestione-dei-dati-in-r",
    "href": "chapters/eda/01_project_structure.html#capacità-di-gestione-dei-dati-in-r",
    "title": "12  Le fasi del progetto di analisi dei dati",
    "section": "12.2 Capacità di Gestione dei Dati in R",
    "text": "12.2 Capacità di Gestione dei Dati in R\nR è uno strumento potente e versatile, progettato per supportare ogni fase del ciclo di vita dei dati, dalla raccolta alla documentazione, rendendolo indispensabile per chiunque lavori con dati complessi.\n\nImportazione ed esportazione dei dati: Con pacchetti come readr e rio, R facilita l’importazione di dati da diverse fonti, tra cui file CSV, database e API web, e consente l’esportazione in formati adatti a diversi utilizzi.\nPulizia e preparazione dei dati: Pacchetti come dplyr, tidyr e stringr offrono strumenti intuitivi e potenti per manipolare, trasformare e preparare i dati in modo efficiente, rendendoli pronti per l’analisi.\nEsplorazione e sintesi: R, attraverso pacchetti come dplyr e ggplot2, permette di calcolare statistiche descrittive, individuare pattern significativi e visualizzare distribuzioni e relazioni in modo chiaro e informativo.\nDocumentazione dinamica: Grazie a strumenti come R Markdown e Quarto, è possibile creare documenti interattivi che integrano codice, analisi, testo esplicativo e risultati, promuovendo la riproducibilità e la trasparenza del lavoro.\nControllo delle versioni: L’integrazione di Git in RStudio offre un sistema di gestione delle versioni che consente di monitorare modifiche, collaborare con altri e garantire la tracciabilità del processo analitico.\n\nQueste funzionalità rendono R uno strumento essenziale per gestire i dati in modo organizzato, trasparente e ottimale, facilitando analisi rigorose e riproducibili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#configurare-lambiente-r",
    "href": "chapters/eda/01_project_structure.html#configurare-lambiente-r",
    "title": "12  Le fasi del progetto di analisi dei dati",
    "section": "12.3 Configurare l’Ambiente R",
    "text": "12.3 Configurare l’Ambiente R\nPer sfruttare al meglio le potenzialità di R, è essenziale configurare correttamente RStudio e integrare i pacchetti fondamentali per la gestione dei dati. Una configurazione adeguata favorisce la riproducibilità e l’organizzazione del lavoro.\n\n12.3.1 Workspace e Cronologia\nAccedi a Tools &gt; Global Options &gt; General e modifica le seguenti impostazioni:\n\nDisabilita l’opzione Restore .RData into workspace at startup.\n\nImposta Save workspace to .RData on exit su Never.\n\nQueste configurazioni incoraggiano una gestione basata sugli script, rendendo il lavoro più trasparente e riducendo conflitti tra sessioni diverse. Ogni analisi sarà così chiaramente documentata nello script, evitando dipendenze da file temporanei o precedenti sessioni.\n\n\n12.3.2 Pacchetti Essenziali\nR è composto da un modulo base che fornisce le funzionalità fondamentali del linguaggio, ma la sua potenza deriva dall’enorme ecosistema di pacchetti aggiuntivi. Questi pacchetti possono essere caricati secondo necessità. Per questo corso, utilizzeremo regolarmente i seguenti pacchetti:\n\nhere: per una gestione ordinata dei percorsi relativi, evitando problemi legati ai percorsi assoluti.\n\ntidyverse: una raccolta di pacchetti per manipolazione, analisi e visualizzazione dei dati, che include dplyr, tidyr, ggplot2 e altri strumenti indispensabili.\n\nAssicurati di installarli e caricarli all’inizio di ogni script con i comandi:\n# install.packages(c(\"here\", \"tidyverse\")) \n# è solo necessario installarli una volta\nlibrary(here)\nlibrary(tidyverse)\n\n\n12.3.3 Gestione dei Progetti\nI progetti in RStudio rappresentano uno strumento chiave per mantenere il lavoro organizzato. Utilizzare i progetti consente di lavorare in ambienti separati, dove ogni progetto ha la propria directory dedicata.\nPer creare un nuovo progetto:\n1. Vai su File &gt; New Project.\n2. Seleziona una directory specifica per il progetto.\n3. Salva tutti i file correlati (script, dati, risultati) all’interno della directory del progetto.\nQuesto approccio facilita la navigazione e previene errori derivanti dall’uso di file non correlati. Ogni progetto diventa così un’unità autonoma, ideale per mantenere ordine e coerenza nel lavoro.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#il-ciclo-di-vita-di-un-progetto-di-data-science",
    "href": "chapters/eda/01_project_structure.html#il-ciclo-di-vita-di-un-progetto-di-data-science",
    "title": "12  Le fasi del progetto di analisi dei dati",
    "section": "12.4 Il Ciclo di Vita di un Progetto di Data Science",
    "text": "12.4 Il Ciclo di Vita di un Progetto di Data Science\nI progetti di analisi dei dati seguono solitamente queste fasi (Yu & Barter, 2024):\n\nFormulazione del problema e raccolta dei dati: Definizione delle domande di ricerca e acquisizione dei dataset.\nPulizia, preprocessing e analisi esplorativa: Preparazione dei dati per l’analisi attraverso trasformazioni e sintesi.\nAnalisi predittiva e/o inferenziale: (Opzionale) Modelli statistici o predittivi per rispondere alle domande di ricerca.\nValutazione dei risultati: Interpretazione e verifica delle conclusioni tratte.\nComunicazione dei risultati: Presentazione dei risultati in forma visiva e narrativa.\n\nNon tutti i progetti includono la fase 3, ma quasi tutti attraversano le altre fasi, rendendo essenziale un approccio organizzato e ben strutturato.\n\n12.4.1 Fase 1: Formulazione del Problema e Raccolta dei Dati\nLa formulazione di una domanda di ricerca chiara e precisa è il primo passo per qualsiasi progetto di data science. È fondamentale che la domanda sia costruita in modo tale da poter essere risolta tramite l’analisi dei dati disponibili. Spesso, la domanda iniziale può risultare troppo vaga o irrealizzabile, rendendo necessario un processo di revisione per adattarla alle informazioni a disposizione. Questo approccio assicura che i dati raccolti o utilizzati siano adeguati per rispondere efficacemente al problema di ricerca.\nLa raccolta dei dati rappresenta una fase altrettanto cruciale del processo. In alcuni casi, i progetti sfruttano dati esistenti provenienti da repository pubblici, database interni o esperimenti passati; in altri, è necessaria una nuova raccolta di dati. Per evitare problematiche future, è essenziale pianificare con attenzione le analisi statistiche da effettuare prima di raccogliere i dati. In assenza di questa pianificazione, si rischia di ottenere dataset inadatti, privi di informazioni cruciali o non conformi alle assunzioni richieste dai modelli statistici previsti.\nUn altro aspetto chiave della raccolta dei dati è comprendere appieno i processi e le metodologie utilizzate per acquisirli. È fondamentale analizzare e documentare le tecniche impiegate, le procedure seguite e i potenziali bias che potrebbero influenzare i risultati. Questa consapevolezza contribuisce a garantire che le misure ottenute siano affidabili e che eventuali limitazioni siano considerate durante l’analisi.\n\n\n12.4.2 Fase 2: Pulizia dei Dati e Analisi Esplorativa\n\n12.4.2.1 Importare i Dati in R\nIn ogni dataset, i dati sono generalmente organizzati in una matrice in cui ogni colonna rappresenta una variabile e ogni riga un’osservazione. Le variabili possono essere suddivise in diverse categorie: quantitative (continue o discrete), qualitative (nominali o ordinali), temporali (date e orari) e testuali (strutturate o non strutturate). La dimensionalità del dataset, cioè il numero di variabili, può influenzare notevolmente la complessità dell’analisi, soprattutto quando si lavora con dati ad alta dimensionalità (tipicamente oltre 100 variabili).\nPer lavorare con questi dati in R, il primo passo è importare i file in un oggetto chiamato data frame, una struttura tabellare che organizza i dati in modo pronto per l’elaborazione e la visualizzazione. Il pacchetto rio semplifica notevolmente questo processo con la funzione import(), che consente di caricare dati da diversi formati (ad esempio, .csv, .xlsx, .json) senza dover ricordare funzioni specifiche per ogni tipo di file.\nQuando si utilizza un progetto in RStudio, è buona pratica organizzare i file in una struttura chiara con sotto-cartelle dedicate, come una per i dati grezzi e una per quelli processati. Utilizzare percorsi relativi, resi semplici dal pacchetto here, permette di mantenere i progetti portabili e ben organizzati. Ad esempio, per importare un file nome_file.csv contenuto nella cartella data/raw, si può usare il comando:\nlibrary(here)\nlibrary(rio)\n\ndati &lt;- import(here(\"data\", \"raw\", \"nome_file.csv\"))\nAnalogamente, l’esportazione dei dati elaborati può essere effettuata con rio::export(), specificando il percorso relativo in cui salvare il file:\nexport(my_data, here(\"data\", \"processed\", \"nome_file.csv\"))\nQueste pratiche non solo assicurano che i file siano salvati nella posizione corretta, ma promuovono anche un workflow organizzato, rendendo più facile condividere e replicare i progetti. Inoltre, strumenti come here e rio migliorano l’efficienza, semplificando il lavoro con dataset complessi e formati diversi.\nIn conclusione, una gestione accurata dei dati è il fondamento di un’analisi robusta e riproducibile. Pianificare attentamente la raccolta dei dati, organizzarli in modo strutturato e utilizzare strumenti adeguati per l’importazione e l’esportazione sono passaggi indispensabili per garantire il successo del progetto.\n\n\n12.4.2.2 Pulizia dei Dati\nDopo aver definito la domanda della ricerca e avere raccolto i dati rilevanti, è il momento di pulire i dati. Un dataset pulito è ordinato, formattato in modo appropriato e ha voci non ambigue. La fase iniziale di pulizia dei dati consiste nell’identificare problemi con i dati (come formattazioni anomale e valori non validi) e modificarli in modo che i valori siano validi e formattati in modo comprensibile sia per il computer che per noi. La pulizia dei dati è una fase estremamente importante di un progetto di data science perché non solo aiuta a garantire che i dati siano interpretati correttamente dal computer, ma aiuta anche a sviluppare una comprensione dettagliata delle informazioni contenute nei dati e delle loro limitazioni.\nL’obiettivo della pulizia dei dati è creare una versione dei dati che rifletta nella maniera più fedele possibile la realtà e che sia interpretata correttamente dal computer. Per garantire che il computer utilizzi fedelmente le informazioni contenute nei dati, è necessario modificare i dati (scrivendo codice, non modificando il file dati grezzo stesso) in modo che siano in linea con ciò che il computer “si aspetta”. Tuttavia, il processo di pulizia dei dati è necessariamente soggettivo e comporta fare assunzioni sulle quantità reali sottostanti misurate e decisioni su quali modifiche siano le più sensate.\n\n\n12.4.2.3 Preprocessing\nIl preprocessing si riferisce al processo di modifica dei dati puliti per soddisfare i requisiti di un algoritmo specifico che si desidera applicare. Ad esempio, se si utilizza un algoritmo che richiede che le variabili siano sulla stessa scala, potrebbe essere necessario trasformarle, oppure, se si utilizza un algoritmo che non consente valori mancanti, potrebbe essere necessario imputarli o rimuoverli. Durante il preprocessing, potrebbe essere utile anche definire nuove caratteristiche/variabili utilizzando le informazioni esistenti nei dati, se si ritiene che queste possano essere utili per l’analisi.\nCome per la pulizia dei dati, non esiste un unico modo corretto per pre-elaborare un dataset, e la procedura finale comporta tipicamente una serie di decisioni che dovrebbero essere documentate nel codice e nei file di documentazione.\n\n\n12.4.2.4 Analisi Esplorativa dei Dati\nDopo l’acquisizione dei dati, si procede con un’Analisi Esplorativa dei Dati (EDA - Exploratory Data Analysis). Questa fase iniziale mira a far familiarizzare il ricercatore con il dataset e a scoprire pattern nascosti. Si realizza attraverso:\n\nLa costruzione di tabelle di frequenza e contingenza.\nIl calcolo di statistiche descrittive (come indici di posizione, dispersione e forma della distribuzione).\nLa creazione di rappresentazioni grafiche preliminari.\n\nL’EDA permette di generare ipotesi sui dati e di guidare le successive analisi statistiche.\n\n\n\n12.4.3 Fase 3: Analisi Predittiva e Inferenziale\nMolte domande nella data science si presentano come problemi di inferenza e/o previsione, in cui l’obiettivo principale è utilizzare dati osservati, passati o presenti, per descrivere le caratteristiche di una popolazione più ampia o per fare previsioni su dati futuri non ancora disponibili. Questo tipo di analisi è spesso orientato a supportare decisioni nel mondo reale.\n\n\n12.4.4 Fase 4: Valutazione dei Risultati\nIn questa fase, i risultati ottenuti vengono analizzati alla luce della domanda di ricerca iniziale. Si procede a una valutazione sia quantitativa, attraverso l’applicazione di tecniche statistiche appropriate, sia qualitativa, attraverso un’attenta riflessione critica.\n\n\n12.4.5 Fase 5: Comunicazione dei Risultati\nL’ultima fase di un progetto di analisi dei dati consiste nel condividere i risultati con un pubblico più ampio, il che richiede la preparazione di materiali comunicativi chiari e concisi. L’obiettivo è trasformare i risultati dell’analisi in informazioni utili per supportare il processo decisionale. Questo può includere la stesura di un articolo scientifico, la creazione di un report per un team di lavoro, o la preparazione di una presentazione con diapositive.\nLa comunicazione deve essere adattata al pubblico di riferimento. Non si deve dare per scontato che il pubblico abbia familiarità con il progetto: è fondamentale spiegare l’analisi e le visualizzazioni in modo chiaro e dettagliato. Anche se per il ricercatore il messaggio principale di una figura o diapositiva può sembrare ovvio, è sempre una buona pratica guidare il pubblico nella sua interpretazione, evitando l’uso di gergo tecnico complesso.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#organizzazione-del-progetto",
    "href": "chapters/eda/01_project_structure.html#organizzazione-del-progetto",
    "title": "12  Le fasi del progetto di analisi dei dati",
    "section": "12.5 Organizzazione del Progetto",
    "text": "12.5 Organizzazione del Progetto\nUn requisito fondamentale per un progetto di analisi dei dati è organizzare in modo efficiente i file sul proprio computer. Questo include i file dei dati, il codice e la documentazione del progetto. Tutti questi elementi dovrebbero essere raccolti all’interno di una singola cartella dedicata al progetto.\n\n12.5.1 Home Directory\nIn RStudio, è possibile creare un file chiamato nome_del_progetto.Rproj, che consente di configurare automaticamente la home directory del progetto, ovvero la cartella principale da cui R avvia il lavoro relativo al progetto. Per utilizzare questa funzionalità, è sufficiente aprire RStudio cliccando direttamente sul file nome_del_progetto.Rproj.\nLa home directory rappresenta il punto di riferimento principale per tutte le operazioni del progetto, come il caricamento di file, il salvataggio degli output e la gestione delle risorse.\nGrazie a questa configurazione, è possibile utilizzare percorsi relativi per accedere ai file all’interno del progetto. I percorsi relativi si basano sempre sulla cartella principale del progetto, il che rende il codice più portabile e adattabile. In pratica, chiunque scarichi il tuo progetto sarà in grado di eseguirlo senza dover modificare manualmente i percorsi dei file. Questo approccio migliora la condivisione e garantisce una maggiore riproducibilità del tuo lavoro.\n\n\n12.5.2 Struttura di un Progetto\nYu & Barter (2024) propone il seguente template per la struttura di un progetto:\n\nLe due cartelle principali sono:\n\ndata/: contiene il dataset grezzo (ad esempio, data.csv) e una sottocartella con documentazione relativa ai dati, come metadati e codebook.\ndslc_documentation/: raccoglie i file di documentazione e codice necessari per le varie fasi del progetto. Questi possono essere file .qmd (per Quarto, in R) o .ipynb (per Jupyter Notebook, in Python), utilizzati per condurre ed esplorare le analisi. I file sono prefissati da un numero per mantenerli in ordine cronologico. All’interno di questa cartella, è presente una sottocartella functions/, che contiene script .R (per R) o .py (per Python) con funzioni utili per le diverse analisi.\n\nUn file README.md descrive la struttura del progetto e riassume il contenuto di ogni file.\nUn’organizzazione come quella proposta da Yu & Barter (2024) offre un notevole vantaggio: permette di specificare i percorsi dei file in modo relativo, utilizzando come radice la cartella del progetto. Questo rende il progetto facilmente trasferibile e condivisibile tra diversi utenti o computer.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#riflessioni-conclusive",
    "href": "chapters/eda/01_project_structure.html#riflessioni-conclusive",
    "title": "12  Le fasi del progetto di analisi dei dati",
    "section": "12.6 Riflessioni Conclusive",
    "text": "12.6 Riflessioni Conclusive\nLa forza e la bellezza del codice risiedono nella sua riusabilità: una volta scritto, può essere applicato infinite volte per ottenere risultati coerenti. Se configurato correttamente, lo stesso codice applicato agli stessi dati produrrà sempre gli stessi risultati. Questo principio, noto come riproducibilità computazionale, è fondamentale per garantire la trasparenza e l’affidabilità del lavoro scientifico.\nLa riproducibilità offre numerosi vantaggi:\n\nMonitorare le modifiche del progetto\nLa possibilità di riprodurre il lavoro semplifica il monitoraggio delle evoluzioni e dei cambiamenti nel progetto. Questo consente di comprendere come il progetto si è sviluppato nel tempo, facilitando il confronto tra diverse versioni o approcci.\nRiprodurre il proprio lavoro\nIl primo beneficiario della riproducibilità sei tu stesso. Essere in grado di replicare i propri risultati è essenziale, soprattutto se in futuro sarà necessario rivedere o approfondire il lavoro. La riproducibilità garantisce che le analisi possano essere riprese con facilità e senza ambiguità.\nCostruire su basi solide\nAltri ricercatori possono utilizzare il tuo lavoro come punto di partenza, espandendolo o applicandolo a nuovi contesti. La condivisione di codice riproducibile non solo favorisce la collaborazione, ma contribuisce a creare un corpo di conoscenze più robusto e condiviso.\n\nTuttavia, rendere il codice riproducibile non è sempre semplice. Richiede attenzione nella documentazione, un’organizzazione chiara del progetto e strumenti adeguati per garantire che l’ambiente di lavoro sia stabile e replicabile. In questo capitolo, abbiamo esplorato alcune strategie e tecniche per raggiungere questi obiettivi.\n\n\n\n\n\n\nNota\n\n\n\nUn problema cruciale nella psicologia contemporanea è la crisi di replicabilità, che evidenzia come molti risultati di ricerca non siano replicabili (Collaboration, 2015). La riproducibilità computazionale, pur avendo un obiettivo più ristretto, si concentra sulla possibilità di ottenere gli stessi risultati applicando lo stesso codice agli stessi dati. Questo approccio, sebbene non risolva interamente la crisi, rappresenta un passo fondamentale verso una scienza più trasparente e rigorosa.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/01_project_structure.html#informazioni-sullambiente-di-sviluppo",
    "title": "12  Le fasi del progetto di analisi dei dati",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2 ggpubr_0.6.0     \n#&gt;  [5] ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0   bayesplot_1.11.1 \n#&gt;  [9] psych_2.4.6.26    scales_1.3.0      markdown_1.13     knitr_1.49       \n#&gt; [13] lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4      \n#&gt; [17] purrr_1.0.2       readr_2.1.5       tidyr_1.3.1       tibble_3.2.1     \n#&gt; [21] ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      xfun_0.49         htmlwidgets_1.6.4 rstatix_0.7.2    \n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    fansi_1.0.6       pacman_0.5.1     \n#&gt; [13] pkgconfig_2.0.3   lifecycle_1.0.4   compiler_4.4.2    farver_2.1.2     \n#&gt; [17] munsell_0.5.1     mnormt_2.1.1      carData_3.0-5     httpuv_1.6.15    \n#&gt; [21] htmltools_0.5.8.1 yaml_2.3.10       Formula_1.2-5     car_3.1-3        \n#&gt; [25] pillar_1.9.0      later_1.4.1       abind_1.4-8       nlme_3.1-166     \n#&gt; [29] mime_0.12         tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4    \n#&gt; [33] rprojroot_2.0.4   fastmap_1.2.0     grid_4.4.2        colorspace_2.1-1 \n#&gt; [37] cli_3.6.3         magrittr_2.0.3    utf8_1.2.4        broom_1.0.7      \n#&gt; [41] withr_3.0.2       backports_1.5.0   promises_1.3.2    timechange_0.3.0 \n#&gt; [45] rmarkdown_2.29    ggsignif_0.6.4    hms_1.1.3         shiny_1.9.1      \n#&gt; [49] evaluate_1.0.1    miniUI_0.1.1.1    rlang_1.1.4       Rcpp_1.0.13-1    \n#&gt; [53] xtable_1.8-4      glue_1.8.0        jsonlite_1.8.9    R6_2.5.1",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#bibliografia",
    "href": "chapters/eda/01_project_structure.html#bibliografia",
    "title": "12  Le fasi del progetto di analisi dei dati",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nCollaboration, O. S. (2015). Estimating the reproducibility of psychological science. Science, 349(6251), aac4716.\n\n\nYu, B., & Barter, R. L. (2024). Veridical data science: The practice of responsible data analysis and decision making. MIT Press.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html",
    "href": "chapters/eda/02_data_cleaning.html",
    "title": "13  Flusso di lavoro per la pulizia dei dati",
    "section": "",
    "text": "13.1 Introduzione\nNonostante la fase più interessante di un progetto di analisi dei dati sia quella in cui si riesce a rispondere alla domanda che ha dato avvio all’indagine, gran parte del tempo di un analista è in realtà dedicata a una fase preliminare: la pulizia e il preprocessing dei dati, operazioni che vengono svolte ancor prima dell’analisi esplorativa.\nIn questo capitolo, esamineremo un caso concreto di data cleaning e preprocessing, seguendo il tutorial di Crystal Lewis. Il problema viene presentato come segue:\nCrystal Lewis elenca i seguenti passaggi da seguire nel processo di data cleaning:\nSebbene l’ordine di questi passaggi sia flessibile e possa essere adattato alle esigenze specifiche, c’è un passaggio che non dovrebbe mai essere saltato: il primo, ovvero la revisione dei dati. Senza una revisione preliminare, l’analista rischia di sprecare ore a pulire i dati per poi scoprire che mancano dei partecipanti, che i dati non sono organizzati come previsto o, peggio ancora, che sta lavorando con i dati sbagliati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#introduzione",
    "href": "chapters/eda/02_data_cleaning.html#introduzione",
    "title": "13  Flusso di lavoro per la pulizia dei dati",
    "section": "",
    "text": "I am managing data for a longitudinal randomized controlled trial (RCT) study. For this RCT, schools are randomized to either a treatment or control group. Students who are in a treatment school receive a program to boost their math self-efficacy. Data is collected on all students in two waves (wave 1 is in the fall of a school year, and wave 2 is collected in the spring). At this point in time, we have collected wave 1 of our student survey on a paper form and we set up a data entry database for staff to enter the information into. Data has been double-entered, checked for entry errors, and has been exported in a csv format (“w1_mathproj_stu_svy_raw.csv”) to a folder (called “data”) where it is waiting to be cleaned.\n\n\n\nRevisione dei dati.\nRegolazione del numero di casi.\nDe-identificazione dei dati.\nEliminazione delle colonne irrilevanti.\nDivisione delle colonne, se necessario.\nRidenominazione delle variabili.\nTrasformazione/normalizzazione delle variabili.\nStandardizzazione delle variabili.\nAggiornamento dei tipi di variabili, se necessario.\nRicodifica delle variabili.\nCreazione di eventuali variabili necessarie.\nGestione dei valori mancanti, se necessario.\nAggiunta di metadati, se necessario.\nValidazione dei dati.\nFusione e/o unione dei dati, se necessario.\nTrasformazione dei dati, se necessario.\nSalvataggio dei dati puliti.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#tutorial",
    "href": "chapters/eda/02_data_cleaning.html#tutorial",
    "title": "13  Flusso di lavoro per la pulizia dei dati",
    "section": "13.2 Tutorial",
    "text": "13.2 Tutorial\nQuesto tutorial segue i passaggi descritti da Crystal Lewis per illustrare le buone pratiche nella gestione e pulizia dei dati.\n\n13.2.1 Organizzazione dei Dati\nUn principio fondamentale nella gestione dei dati è preservare l’integrità dei dati grezzi. I dati originali non devono mai essere modificati direttamente. È quindi consigliabile strutturare i dati in una directory denominata data, suddivisa in due sottocartelle:\n\nraw: contiene i dati originali, mantenuti inalterati.\n\nprocessed: destinata ai dati ripuliti e preprocessati.\n\nAd esempio, importiamo i dati da un file denominato w1_mathproj_stu_svy_raw.csv per avviare il processo di pulizia. Tutte le operazioni dovranno essere effettuate utilizzando percorsi relativi alla home directory del progetto, che definiremo come primo passo.\n\n\n13.2.2 Passaggi del Tutorial\n\n13.2.2.1 Importare e Esaminare i Dati\nImportiamo i dati utilizzando la libreria rio e visualizziamo una panoramica per verificarne la corretta importazione:\n\n# Importa i dati\nsvy &lt;- rio::import(here::here(\"data\", \"w1_mathproj_stu_svy_raw.csv\"))\n\n# Esamina la struttura del dataset\nglimpse(svy)\n#&gt; Rows: 6\n#&gt; Columns: 7\n#&gt; $ stu_id      &lt;int&gt; 1347, 1368, 1377, 1387, 1347, 1399\n#&gt; $ svy_date    &lt;IDate&gt; 2023-02-13, 2023-02-13, 2023-02-13, 2023-02-13, 2023-02…\n#&gt; $ grade_level &lt;int&gt; 9, 10, 9, 11, 9, 12\n#&gt; $ math1       &lt;int&gt; 2, 3, 4, 3, 2, 4\n#&gt; $ math2       &lt;chr&gt; \"1\", \"2\", \"\\n4\", \"3\", \"2\", \"1\"\n#&gt; $ math3       &lt;int&gt; 3, 2, 4, NA, 4, 3\n#&gt; $ math4       &lt;int&gt; 3, 2, 4, NA, 2, 1\n\nPer controllare visivamente i dati, possiamo esaminare le prime e le ultime righe del data frame:\n\n# Visualizza le prime righe\nsvy |&gt; \n  head()\n#&gt;   stu_id   svy_date grade_level math1 math2 math3 math4\n#&gt; 1   1347 2023-02-13           9     2     1     3     3\n#&gt; 2   1368 2023-02-13          10     3     2     2     2\n#&gt; 3   1377 2023-02-13           9     4   \\n4     4     4\n#&gt; 4   1387 2023-02-13          11     3     3    NA    NA\n#&gt; 5   1347 2023-02-14           9     2     2     4     2\n#&gt; 6   1399 2023-02-14          12     4     1     3     1\n\n# Visualizza le ultime righe\nsvy |&gt; \n  tail()\n#&gt;   stu_id   svy_date grade_level math1 math2 math3 math4\n#&gt; 1   1347 2023-02-13           9     2     1     3     3\n#&gt; 2   1368 2023-02-13          10     3     2     2     2\n#&gt; 3   1377 2023-02-13           9     4   \\n4     4     4\n#&gt; 4   1387 2023-02-13          11     3     3    NA    NA\n#&gt; 5   1347 2023-02-14           9     2     2     4     2\n#&gt; 6   1399 2023-02-14          12     4     1     3     1\n\n\n\n13.2.2.2 Individuare e Rimuovere i Duplicati\nIn questa fase, eseguiamo alcune modifiche necessarie al data frame, come rimuovere duplicati e ordinare i dati:\n\nVerifica duplicati: controlliamo i record duplicati nel dataset.\nRimuovi duplicati: manteniamo solo la prima occorrenza.\nOrdina per data: organizziamo i record in ordine crescente rispetto alla variabile svy_date.\nEsamina i dati puliti: controlliamo il risultato delle modifiche.\n\n\n# Identifica i duplicati basati su 'stu_id'\nduplicates &lt;- \n  svy[duplicated(svy$stu_id) | duplicated(svy$stu_id, fromLast = TRUE), ]\n\n# Ordina per 'svy_date' in ordine crescente\nsvy &lt;- svy[order(svy$svy_date), ]\n\n# Rimuove i duplicati mantenendo la prima occorrenza\nsvy &lt;- svy[!duplicated(svy$stu_id), ]\n\n# Visualizza i duplicati trovati\nprint(duplicates)\n#&gt;   stu_id   svy_date grade_level math1 math2 math3 math4\n#&gt; 1   1347 2023-02-13           9     2     1     3     3\n#&gt; 5   1347 2023-02-14           9     2     2     4     2\n\n# Esamina il dataset finale\nprint(svy)\n#&gt;   stu_id   svy_date grade_level math1 math2 math3 math4\n#&gt; 1   1347 2023-02-13           9     2     1     3     3\n#&gt; 2   1368 2023-02-13          10     3     2     2     2\n#&gt; 3   1377 2023-02-13           9     4   \\n4     4     4\n#&gt; 4   1387 2023-02-13          11     3     3    NA    NA\n#&gt; 6   1399 2023-02-14          12     4     1     3     1\n\nVerifichiamo le dimensioni del dataset pulito per assicurarci che le operazioni siano state eseguite correttamente:\n\n# Controlla il numero di righe e colonne\nsvy |&gt; \n  dim()\n#&gt; [1] 5 7\n\n\n\n13.2.2.3 De-identificazione dei Dati\n\n# Rimuovi la colonna 'svy_date'\nsvy &lt;- svy |&gt;\n  dplyr::select(-svy_date)\n\n# Mostra i nomi delle colonne rimaste\nnames(svy)\n#&gt; [1] \"stu_id\"      \"grade_level\" \"math1\"       \"math2\"       \"math3\"      \n#&gt; [6] \"math4\"\n\n\n\n13.2.2.4 Rimuovere le Colonne non Necessarie\nNel caso presente, la rimozione di colonne non è necessaria. Tuttavia, in molti progetti di analisi dei dati, soprattutto quando i dati vengono raccolti utilizzando software di terze parti o strumenti specifici per esperimenti psicologici, è comune trovarsi con colonne che non sono pertinenti allo studio in corso.\nQueste colonne possono includere dati come identificatori interni, timestamp generati automaticamente, informazioni di debug, o variabili che non sono rilevanti per l’analisi che si intende condurre. Quando tali colonne sono irrilevanti per la ricerca, possono essere rimosse per semplificare il dataset e ridurre il rischio di confusione o errori durante l’analisi. Rimuovere le colonne non necessarie non solo rende il dataset più gestibile, ma aiuta anche a focalizzare l’analisi sulle variabili che realmente importano per rispondere alle domande di ricerca.\n\n\n13.2.2.5 Dividere le Colonne Secondo Necessità\nNel caso presente, questa operazione non è necessaria. Tuttavia, se si lavora con un dataset che include una colonna chiamata “NomeCompleto”, contenente sia il nome che il cognome di uno studente, è buona pratica separare questa colonna in due colonne distinte, “Nome” e “Cognome”. Questa suddivisione facilita l’analisi e la manipolazione dei dati, rendendoli più organizzati e accessibili.\n\n\n13.2.2.6 Rinominare le Colonne\nÈ importante assegnare nomi chiari alle colonne del dataset. Utilizzare nomi di variabili comprensibili aiuta a rendere l’analisi dei dati più intuitiva e a ridurre il rischio di errori interpretativi.\nEsempi di buone pratiche:\n\nEvita nomi di colonne come “x” o acronimi incomprensibili. Questi possono creare confusione durante l’analisi, specialmente se il dataset viene condiviso con altri ricercatori o se viene ripreso dopo un lungo periodo di tempo.\nInvece, cerca di utilizzare nomi di variabili che descrivano chiaramente il contenuto della colonna. Ad esempio, invece di “x1” o “VAR123”, un nome come “ansia_base” o “liv_autoefficacia” è molto più comprensibile e immediato.\nPer i nomi composti, utilizza un separatore come il trattino basso _. Ad esempio, se stai lavorando con dati relativi a un test psicologico, potresti avere colonne chiamate “test_ansia_pre” e “test_ansia_post” per indicare i risultati del test di ansia prima e dopo un intervento.\n\nEsempi di nomi di colonne ben scelti:\n\nNome generico: TS, AE\n\nNome migliore: tempo_studio, auto_efficacia\n\nNome generico: S1, S2\n\nNome migliore: stress_situazione1, stress_situazione2\n\nNome generico: Q1, Q2\n\nNome migliore: qualità_sonno_sett1, qualità_sonno_sett2\n\n\n\n\n13.2.2.7 Trasformare le Variabili\nNel caso presente non si applica, ma è un passo importante in molte analisi dei dati.\nEsempi di trasformazione delle variabili:\n\nLogaritmo di una variabile: Immaginiamo di avere una variabile che misura i tempi di reazione dei partecipanti a un esperimento. Se i tempi di reazione hanno una distribuzione fortemente asimmetrica (con alcuni valori molto elevati), potrebbe essere utile applicare una trasformazione logaritmica per rendere la distribuzione più simmetrica e migliorare l’interpretabilità dei risultati.\nCodifica delle variabili categoriche: Se è presente una variabile categorica come il “tipo di intervento” con valori come “cognitivo”, “comportamentale” e “farmacologico”, potrebbe essere necessario trasformare questa variabile in variabili dummy (ad esempio, intervento_cognitivo, intervento_comportamentale, intervento_farmacologico), dove ogni variabile assume il valore 0 o 1 a seconda della presenza o meno di quel tipo di intervento. Questo è utile quando si utilizzano tecniche di regressione.\n\n\n\n13.2.2.8 Standardizzare / Normalizzare le Variabili\nNel caso presente non si applica, ma è un passo importante in molte analisi dei dati.\nEsempi di standardizzazione delle variabili:\n\nStandardizzazione dei punteggi: Supponiamo di avere una variabile che misura il livello di ansia su una scala da 0 a 100. Se desideriamo confrontare i livelli di ansia tra diversi gruppi o includere questa variabile in un modello di regressione, potrebbe essere utile standardizzare i punteggi (cioè, sottrarre la media e dividere per la deviazione standard) per ottenere una variabile con media 0 e deviazione standard 1. Questo processo rende i punteggi comparabili e facilita l’interpretazione dei coefficienti in un modello di regressione.\nNormalizzazione delle variabili: Se hai dati su diverse variabili come “ore di sonno”, “livello di stress” e “auto-efficacia”, e queste variabili hanno scale molto diverse, potrebbe essere utile normalizzarle (ad esempio, ridimensionarle tutte su una scala da 0 a 1) per garantire che abbiano lo stesso peso in un’analisi multivariata.\n\nTrasformare e standardizzare le variabili sono passaggi cruciali in molte analisi psicologiche, specialmente quando si confrontano dati provenienti da diverse fonti o gruppi. Questi processi aiutano a garantire che le variabili siano trattate in modo appropriato e che i risultati dell’analisi siano validi e interpretabili.\n\n\n13.2.2.9 Aggiornare i Tipi delle Variabili\nNel caso presente non è necessario. Supponiamo invece di avere una colonna in un dataset psicologico che contiene punteggi di un questionario, ma i dati sono stati importati come stringhe (testo) invece che come numeri. Per eseguire calcoli statistici, sarà necessario convertire questa colonna da stringa a numerico.\nIn R, si potrebbe usare il seguente codice:\n\n# Supponiamo di avere un data frame chiamato 'df' con una colonna 'punteggio' importata come carattere\ndf$punteggio &lt;- as.numeric(df$punteggio)\n\n# Ora la colonna 'punteggio' è stata convertita in un tipo numerico ed è possibile eseguire calcoli su di essa\n\nIn questo esempio, la funzione as.numeric() viene utilizzata per convertire la colonna punteggio in un formato numerico, permettendo di eseguire analisi quantitative sui dati.\nUn altro caso molto comune si verifica quando si importano dati da file Excel. Spesso capita che, all’interno di una cella di una colonna che dovrebbe contenere solo valori numerici, venga inserito erroneamente uno o più caratteri alfanumerici. Di conseguenza, l’intera colonna viene interpretata come di tipo alfanumerico, anche se i valori dovrebbero essere numerici. In questi casi, è fondamentale individuare la cella problematica, correggere il valore errato, e poi riconvertire l’intera colonna da alfanumerica a numerica.\n\n\n13.2.2.10 Ricodificare le Variabili\nAnche se in questo caso non è necessario, la ricodifica delle variabili è una pratica molto comune nelle analisi dei dati psicologici.\nPer esempio, consideriamo una variabile categoriale con modalità descritte da stringhe poco comprensibili, che vengono ricodificate con nomi più chiari e comprensibili.\nSupponiamo di avere un DataFrame chiamato df con una colonna tipo_intervento che contiene le modalità \"CT\", \"BT\", e \"MT\" per rappresentare rispettivamente “Terapia Cognitiva”, “Terapia Comportamentale” e “Terapia Mista”. Queste abbreviazioni potrebbero non essere immediatamente chiare a chiunque analizzi i dati, quindi decidiamo di ricodificarle con nomi più espliciti. Ecco come farlo in R:\n\n# Supponiamo di avere un tibble chiamato 'df' con una colonna 'tipo_intervento'\ndf &lt;- tibble(tipo_intervento = c(\"CT\", \"BT\", \"MT\", \"CT\", \"BT\"))\n\n# Ricodifica delle modalità della variabile 'tipo_intervento' in nomi più comprensibili\ndf &lt;- df %&gt;%\n  mutate(tipo_intervento_ricodificato = dplyr::recode(\n    tipo_intervento,\n    \"CT\" = \"Terapia Cognitiva\",\n    \"BT\" = \"Terapia Comportamentale\",\n    \"MT\" = \"Terapia Mista\"\n  ))\n\n# Mostra il tibble con la nuova colonna ricodificata\nprint(df)\n\n\n\n13.2.2.11 Aggiungere Nuove Variabili nel Data Frame\nNel caso presente non è richiesto, ma aggiungere nuove variabili a un DataFrame è un’operazione comune durante l’analisi dei dati. Un esempio è il calcolo dell’indice di massa corporea (BMI).\nSupponiamo di avere un DataFrame chiamato df che contiene le colonne peso_kg (peso in chilogrammi) e altezza_m (altezza in metri) per ciascun partecipante a uno studio psicologico. Per arricchire il dataset, possiamo calcolare il BMI per ogni partecipante e aggiungerlo come una nuova variabile.\nIl BMI si calcola con la formula:\n\\[ \\text{BMI} = \\frac{\\text{peso in kg}}{\\text{altezza in metri}^2} .\\]\nEcco come aggiungere la nuova colonna.\n\n# Supponiamo di avere un tibble chiamato 'df' con le colonne 'peso_kg' e 'altezza_m'\ndf &lt;- tibble(\n  peso_kg = c(70, 85, 60, 95),\n  altezza_m = c(1.75, 1.80, 1.65, 1.90)\n)\n\n# Calcola il BMI e aggiungilo come una nuova colonna 'BMI'\ndf &lt;- df %&gt;%\n  mutate(BMI = peso_kg / (altezza_m^2))\n\n# Mostra il tibble con la nuova variabile aggiunta\nprint(df)\n#&gt; # A tibble: 4 × 3\n#&gt;   peso_kg altezza_m   BMI\n#&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1      70      1.75  22.9\n#&gt; 2      85      1.8   26.2\n#&gt; 3      60      1.65  22.0\n#&gt; 4      95      1.9   26.3\n\n\n\n13.2.2.12 Affrontare il Problema dei Dati Mancanti\nL’imputazione è una tecnica utilizzata per gestire i dati mancanti in un dataset, un problema comune in molte analisi. Lasciare i valori mancanti nel DataFrame può compromettere la qualità dell’analisi, poiché molti algoritmi statistici non sono in grado di gestire direttamente i dati incompleti, portando a risultati distorti o poco affidabili.\nI valori mancanti possono causare diversi problemi:\n\nBias dei risultati: I dati mancanti possono introdurre un bias nelle stime se i valori mancanti non sono distribuiti in modo casuale.\nRiduzione della potenza statistica: Quando si eliminano le righe con dati mancanti (rimozione listwise), si riduce la dimensione del campione, diminuendo la potenza dell’analisi.\nImpossibilità di utilizzare alcuni algoritmi: Molti algoritmi di statistica richiedono che tutti i valori siano presenti per eseguire correttamente i calcoli.\n\nEsistono vari approcci per affrontare i dati mancanti:\n\nImputazione Semplice:\n\nMedia/Mediana: Un metodo comune e semplice è sostituire i valori mancanti con la media o la mediana della colonna. Questo metodo è facile da implementare, ma può ridurre la variabilità dei dati e portare a una sottostima della varianza.\nMode (moda): Per le variabili categoriche, è possibile sostituire i valori mancanti con la moda (il valore più frequente). Tuttavia, questo può portare a una distorsione se la distribuzione dei dati è molto eterogenea.\n\nImputazione Multipla:\n\nRegressione Iterativa: L’imputazione multipla, come implementata con algoritmi come IterativeImputer, è una procedura più sofisticata che predice i valori mancanti in modo iterativo utilizzando un modello basato sulle altre variabili del dataset. Questa tecnica tiene conto delle relazioni tra le variabili, migliorando l’accuratezza delle imputazioni rispetto ai metodi semplici.\nL’imputazione multipla conserva la variabilità nei dati e riduce il bias, fornendo stime più accurate rispetto ai metodi di imputazione semplice.\n\n\nL’imputazione dei dati mancanti è essenziale per garantire che l’analisi statistica sia accurata e robusta. Sebbene i metodi semplici come la sostituzione con la media possano essere utili in alcuni casi, l’imputazione multipla offre un approccio più completo e sofisticato, particolarmente utile quando si desidera preservare le relazioni tra le variabili e mantenere l’integrità statistica del dataset. Questo argomento verrà ulteriormente discusso nel ?sec-missing-data.\nApplichiamo la procedura dell’imputazione multipla al caso presente.\n\n# Supponiamo di avere un data frame chiamato 'd'\nd &lt;- svy %&gt;% as_tibble()\n\n# Mantieni l'indice originale \noriginal_index &lt;- rownames(d)\n\n# Converti solo le colonne numeriche relative ai punteggi in numerico per l'imputazione\nnumeric_columns &lt;- c(\"math1\", \"math2\", \"math3\", \"math4\")\nd &lt;- d %&gt;%\n  mutate(across(all_of(numeric_columns), as.numeric))\n\n# Applica mice per l'imputazione multipla\nimputed &lt;- mice(d[numeric_columns], m = 1, maxit = 10, method = \"norm.predict\", seed = 0)\n#&gt; \n#&gt;  iter imp variable\n#&gt;   1   1  math3  math4\n#&gt;   2   1  math3  math4\n#&gt;   3   1  math3  math4\n#&gt;   4   1  math3  math4\n#&gt;   5   1  math3  math4\n#&gt;   6   1  math3  math4\n#&gt;   7   1  math3  math4\n#&gt;   8   1  math3  math4\n#&gt;   9   1  math3  math4\n#&gt;   10   1  math3  math4\n#&gt; Warning: Number of logged events: 2\n\n# Estrai il dataset imputato\ndf_imputed &lt;- complete(imputed)\n\n# Arrotonda i valori imputati ai numeri interi più vicini\ndf_imputed &lt;- df_imputed %&gt;%\n  mutate(across(everything(), round))\n\n# Inserisci i valori imputati e arrotondati nel data frame originale\nd[numeric_columns] &lt;- df_imputed\n\n# Mostra il data frame dopo l'imputazione e l'arrotondamento\ncat(\"\\nDataFrame dopo l'imputazione e l'arrotondamento:\\n\")\n#&gt; \n#&gt; DataFrame dopo l'imputazione e l'arrotondamento:\nprint(d)\n#&gt; # A tibble: 5 × 6\n#&gt;   stu_id grade_level math1 math2 math3 math4\n#&gt;    &lt;int&gt;       &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1   1347           9     2     1     3     3\n#&gt; 2   1368          10     3     2     2     2\n#&gt; 3   1377           9     4     4     4     4\n#&gt; 4   1387          11     3     3     2     3\n#&gt; 5   1399          12     4     1     3     1\n\nPer eseguire l’imputazione multipla in R, utilizziamo il pacchetto mice, uno strumento avanzato per gestire i valori mancanti nei dati. Questo approccio si basa su metodi di regressione iterativa, in cui ogni valore mancante viene stimato utilizzando un modello predittivo che considera tutte le altre variabili presenti nel dataset.\n\nSelezione delle colonne numeriche per l’imputazione:\n\nAbbiamo identificato le colonne numeriche che richiedono l’imputazione (math1, math2, math3, math4).\n\nImputazione Multipla con mice:\n\nIl pacchetto mice utilizza un processo iterativo per stimare i valori mancanti. Ogni variabile con valori mancanti viene modellata a turno come una funzione delle altre variabili, utilizzando metodi specifici (ad esempio, regressione lineare o modelli bayesiani).\nL’imputazione iterativa procede in cicli successivi. Durante ogni ciclo, i valori mancanti di una variabile vengono stimati utilizzando le imputazioni correnti delle altre variabili.\nParametro maxit=10: Il processo iterativo viene ripetuto fino a un massimo di 10 volte, o fino al raggiungimento della convergenza (stabilità dei valori imputati).\n\nApplicazione e Arrotondamento:\n\nDopo l’imputazione, i valori stimati vengono reinseriti nel dataset. Per le variabili numeriche che rappresentano conteggi o valori discreti, i valori imputati sono stati arrotondati al numero intero più vicino.\n\nRisultato:\n\nIl dataset risultante non contiene più valori mancanti nelle colonne numeriche specificate (math1, math2, math3, math4), poiché questi sono stati imputati utilizzando le relazioni con le altre variabili del dataset.\n\n\nIn sintesi, l’imputazione multipla con mice è una tecnica potente per gestire i valori mancanti senza eliminare intere righe o colonne. Questo approccio preserva le relazioni tra variabili, garantendo che l’inferenza statistica rimanga accurata e valida. Nel nostro caso, abbiamo utilizzato un modello predittivo iterativo per stimare i valori mancanti basandoci sulle informazioni fornite dalle altre variabili. Questo metodo aumenta la qualità dei dati e consente analisi più robuste e affidabili.\n\n\n13.2.2.13 Aggiungere i Metadati\nI metadati sono informazioni che descrivono i dati stessi, come etichette di variabili, etichette di valori, informazioni sull’origine dei dati, unità di misura e altro ancora. Questi metadati sono essenziali per comprendere, documentare e condividere correttamente un dataset.\nIn R, i metadati sono gestiti in modo molto dettagliato e strutturato attraverso pacchetti come haven, labelled, e Hmisc. Questi pacchetti consentono di associare etichette ai dati, come etichette di variabili e di valori, e persino di gestire i valori mancanti con etichette specifiche.\n\nEtichette di variabili: Si possono aggiungere direttamente alle colonne di un DataFrame usando funzioni come labelled::set_variable_labels().\nEtichette di valori: Possono essere aggiunte a variabili categoriali utilizzando labelled::labelled().\nValori mancanti: In R, è possibile etichettare specifici valori come mancanti usando labelled::na_values&lt;-.\n\nQuesti strumenti rendono molto facile documentare un dataset all’interno del processo di analisi, assicurando che tutte le informazioni critiche sui dati siano facilmente accessibili e ben documentate.\n\n# Creazione del dataset\nsvy &lt;- tibble(\n  stu_id = c(1347, 1368, 1377, 1387, 1399),\n  grade_level = c(9, 10, 9, 11, 12),\n  math1 = c(2, 3, 4, 3, 4),\n  math2 = c(1, 2, 4, 3, 1),\n  math3 = c(3.0, 2.0, 4.0, NA, 3.0),\n  math4 = c(3.0, 2.0, 4.0, NA, 1.0),\n  int = c(1, 0, 1, 0, 1)\n)\n\n# Definizione delle etichette di valore per le variabili math1:math4\nvalue_labels_math &lt;- set_names(\n  as.numeric(names(c(\n    `1` = \"strongly disagree\",\n    `2` = \"disagree\",\n    `3` = \"agree\",\n    `4` = \"strongly agree\"\n  ))),\n  c(\"strongly disagree\", \"disagree\", \"agree\", \"strongly agree\")\n)\n\n# Aggiunta delle etichette di valore alle colonne math1:math4\nsvy &lt;- svy %&gt;%\n  mutate(across(starts_with(\"math\"), ~ labelled(., labels = value_labels_math)))\n\n# Verifica delle etichette\nval_labels(svy$math1)\n#&gt; strongly disagree          disagree             agree    strongly agree \n#&gt;                 1                 2                 3                 4\n\n\n\n13.2.2.14 Validazione dei Dati\nLa validazione dei dati è un passaggio fondamentale per garantire che il dataset soddisfi i criteri previsti e sia pronto per le analisi successive. Questo processo include il controllo della coerenza e della correttezza dei dati in base a specifiche regole definite dal dizionario dei dati. Alcune verifiche comuni includono:\n\nUnicità delle righe: Assicurarsi che ogni riga sia unica, verificando l’assenza di ID duplicati.\nValidità degli ID: Controllare che gli ID rientrino in un intervallo previsto (es. numerico).\nValori accettabili nelle variabili categoriali: Verificare che variabili come grade_level, int e le colonne math contengano esclusivamente valori appartenenti a un set di valori validi.\n\nIl pacchetto pointblank fornisce strumenti flessibili e intuitivi per eseguire verifiche di validazione e generare report dettagliati. Questo pacchetto consente di:\n\nDefinire le regole di validazione: Specificare controlli come unicità, intervalli di valori e appartenenza a insiemi predefiniti.\nEseguire i controlli: Applicare le regole di validazione su un dataset per identificare eventuali discrepanze.\nGenerare report interattivi: Creare un riepilogo chiaro e visivo dei controlli, evidenziando eventuali errori o anomalie.\n\nCon pointblank, è possibile integrare la validazione dei dati come parte di un workflow strutturato, garantendo la qualità dei dati in modo sistematico e ripetibile.\n\ncreate_agent(svy) %&gt;%\n  rows_distinct(columns = vars(stu_id)) %&gt;%\n  col_vals_between(columns = c(stu_id), \n                   left = 1300, right = 1400, na_pass = TRUE) %&gt;%\n  col_vals_in_set(columns = c(grade_level), \n                  set = c(9, 10, 11, 12, NA)) %&gt;%\n  col_vals_in_set(columns = c(int),\n                  set = c(0, 1, NA)) %&gt;%\n  col_vals_in_set(columns = c(math1:math4),\n                  set = c(1, 2, 3, 4, NA)) %&gt;%\n  interrogate()\n\n\n\n\n\n\n\nPointblank Validation\n\n\n\n\n[2024-12-05|06:45:59]\n\n\ntibble svy\n\n\n\n\n\n\nSTEP\nCOLUMNS\nVALUES\nTBL\nEVAL\nUNITS\nPASS\nFAIL\nW\nS\nN\nEXT\n\n\n\n\n\n\n1\n\n\n\n\nrows_distinct\n\n         \n\n\n rows_distinct()\n\n\n▮stu_id\n\n—\n\n\n      \n\n\n✓\n5\n5\n1\n0\n0\n—\n—\n—\n—\n\n\n\n\n2\n\n\n\n\ncol_vals_between\n\n     \n\n\n col_vals_between()\n\n\n▮stu_id\n\n\n[1,300, 1,400]\n\n\n\n      \n\n\n✓\n5\n5\n1\n0\n0\n—\n—\n—\n—\n\n\n\n\n3\n\n\n\n\ncol_vals_in_set\n\n     \n\n\n col_vals_in_set()\n\n\n▮grade_level\n\n\n9, 10, 11, 12, NA\n\n\n\n      \n\n\n✓\n5\n5\n1\n0\n0\n—\n—\n—\n—\n\n\n\n\n4\n\n\n\n\ncol_vals_in_set\n\n     \n\n\n col_vals_in_set()\n\n\n▮int\n\n\n0, 1, NA\n\n\n\n      \n\n\n✓\n5\n5\n1\n0\n0\n—\n—\n—\n—\n\n\n\n\n5\n\n\n\n\ncol_vals_in_set\n\n     \n\n\n col_vals_in_set()\n\n\n▮math1\n\n\n1, 2, 3, 4, NA\n\n\n\n      \n\n\n✓\n5\n5\n1\n0\n0\n—\n—\n—\n—\n\n\n\n\n6\n\n\n\n\ncol_vals_in_set\n\n     \n\n\n col_vals_in_set()\n\n\n▮math2\n\n\n1, 2, 3, 4, NA\n\n\n\n      \n\n\n✓\n5\n5\n1\n0\n0\n—\n—\n—\n—\n\n\n\n\n7\n\n\n\n\ncol_vals_in_set\n\n     \n\n\n col_vals_in_set()\n\n\n▮math3\n\n\n1, 2, 3, 4, NA\n\n\n\n      \n\n\n✓\n5\n5\n1\n0\n0\n—\n—\n—\n—\n\n\n\n\n8\n\n\n\n\ncol_vals_in_set\n\n     \n\n\n col_vals_in_set()\n\n\n▮math4\n\n\n1, 2, 3, 4, NA\n\n\n\n      \n\n\n✓\n5\n5\n1\n0\n0\n—\n—\n—\n—\n\n\n\n2024-12-05 06:45:59 CET &lt; 1 s 2024-12-05 06:45:59 CET\n\n\n\n\n\n\n\n\nIl dataset ripulito soddisfa tutte le aspettative delineate da Crystal Lewis.\n\nCompleto: Tutti i dati raccolti sono stati inseriti e/o recuperati. Non dovrebbero esserci dati estranei che non appartengono al dataset (come duplicati o partecipanti non autorizzati).\nValido: Le variabili rispettano i vincoli definiti nel tuo dizionario dei dati. Ricorda che il dizionario dei dati specifica i nomi delle variabili, i tipi, i range, le categorie e altre informazioni attese.\nAccurato: Sebbene non sia sempre possibile determinare l’accuratezza dei valori durante il processo di pulizia dei dati (ovvero, se un valore è realmente corretto o meno), in alcuni casi è possibile valutarla sulla base della conoscenza pregressa riguardante quel partecipante o caso specifico.\nCoerente: I valori sono allineati tra le varie fonti. Ad esempio, la data di nascita raccolta attraverso un sondaggio studentesco dovrebbe avere un formato corrispondere alla data di nascita raccolta dal distretto scolastico.\nUniforme: I dati sono standardizzati attraverso i moduli e nel tempo. Ad esempio, lo stato di partecipazione ai programmi di pranzo gratuito o a prezzo ridotto è sempre fornito come una variabile numerica con la stessa rappresentazione, oppure il nome della scuola è sempre scritto in modo coerente in tutto il dataset.\nDe-identificato: Tutte le informazioni personali identificabili (PII) sono state rimosse dal dataset per proteggere la riservatezza dei partecipanti (se richiesto dal comitato etico/consenso informato).\nInterpretabile: I dati hanno nomi di variabili leggibili sia da umani che dal computer, e sono presenti etichette di variabili e valori laddove necessario per facilitare l’interpretazione.\nAnalizzabile: Il dataset è in un formato rettangolare (righe e colonne), leggibile dal computer e conforme alle regole di base della struttura dei dati.\n\nUna volta completati i 14 passaggi precedenti, è possibile esportare questo dataset ripulito nella cartella processed per le successive analisi statistiche.\n\n\n13.2.2.15 Unire e/o aggiungere dati se necessario\nIn questo passaggio, è possibile unire o aggiungere colonne o righe presenti in file diversi. È importante eseguire nuovamente i controlli di validazione dopo l’unione/aggiunta di nuovi dati.\n\n\n13.2.2.16 Trasformare i dati se necessario\nEsistono vari motivi per cui potrebbe essere utile memorizzare i dati in formato long o wide. In questo passaggio, è possibile ristrutturare i dati secondo le esigenze.\n\n\n13.2.2.17 Salvare il dataset pulito finale\nL’ultimo passaggio del processo di pulizia consiste nell’esportare o salvare il dataset pulito. Come accennato in precedenza, può essere utile esportare/salvare il dataset in più di un formato di file (ad esempio, un file .csv e un file .parquet).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#organizzazione-dei-file-e-informazioni-aggiuntive",
    "href": "chapters/eda/02_data_cleaning.html#organizzazione-dei-file-e-informazioni-aggiuntive",
    "title": "13  Flusso di lavoro per la pulizia dei dati",
    "section": "13.3 Organizzazione dei file e informazioni aggiuntive",
    "text": "13.3 Organizzazione dei file e informazioni aggiuntive\nInfine, è essenziale includere una documentazione adeguata per garantire che le informazioni siano interpretate correttamente, sia da altri utenti che da te stesso, se dovessi tornare a lavorare su questo progetto in futuro. La documentazione minima da fornire dovrebbe includere:\n\nDocumentazione a livello di progetto: Questa sezione fornisce informazioni contestuali sul perché e come i dati sono stati raccolti. È utile per chiunque voglia comprendere lo scopo e la metodologia del progetto.\nMetadati a livello di progetto: Se condividi i dati in un repository pubblico o privato, è importante includere metadati a livello di progetto. Questi metadati forniscono informazioni dettagliate che facilitano la ricerca, la comprensione e la consultabilità dei dati. I metadati a livello di progetto possono includere descrizioni generali del progetto, parole chiave, e riferimenti bibliografici.\nDizionario dei dati: Un documento che descrive tutte le variabili presenti nel dataset, inclusi i loro nomi, tipi, range di valori, categorie e qualsiasi altra informazione rilevante. Questo strumento è fondamentale per chiunque voglia comprendere o analizzare i dati.\nREADME: Un file che fornisce una panoramica rapida dei file inclusi nel progetto, spiegando cosa contengono e come sono interconnessi. Il README è spesso il primo documento consultato e serve a orientare l’utente tra i vari file e risorse del progetto. Questa documentazione non solo aiuta a mantenere il progetto organizzato, ma è anche cruciale per facilitare la collaborazione e l’archiviazione a lungo termine.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#dizionario-dei-dati",
    "href": "chapters/eda/02_data_cleaning.html#dizionario-dei-dati",
    "title": "13  Flusso di lavoro per la pulizia dei dati",
    "section": "13.4 Dizionario dei Dati",
    "text": "13.4 Dizionario dei Dati\nApprofondiamo qui il problema della creazione del Dizionario dei dati.\nUn dizionario dei dati è un documento che descrive le caratteristiche di ciascuna variabile in un dataset. Include informazioni come il nome della variabile, il tipo di dato, il range di valori, le categorie (per le variabili categoriche), e altre informazioni rilevanti. Questo strumento è essenziale per comprendere e analizzare correttamente il dataset.\nSi presti particolare attenzione alle guide di stile per la denominazione delle variabili e la codifica dei valori delle risposte.\n\n13.4.1 Esempio in R\nEcco come tradurre i passi per creare un dizionario dei dati in R, utilizzando il pacchetto tibble per creare il dizionario e writexl o readr per esportarlo in formato .xlsx o .csv.\n\nIdentificare le variabili: Elencare tutte le variabili presenti nel dataset.\nDescrivere ogni variabile: Per ciascuna variabile, definire il tipo (ad esempio, integer, numeric, character), il range di valori accettabili o le categorie, e fornire una descrizione chiara.\nSalvare il dizionario dei dati: Il dizionario può essere salvato in un file .csv o .xlsx per una facile consultazione.\n\nCreeremo un dizionario dei dati per un dataset di esempio e lo salveremo sia in formato CSV che Excel.\n\nlibrary(tibble)\nlibrary(readr)\nlibrary(writexl)\n\n# Creazione del Dizionario dei Dati\ndata_dict &lt;- tibble(\n  `Variable Name` = c(\n    \"stu_id\",\n    \"svy_date\",\n    \"grade_level\",\n    \"math1\",\n    \"math2\",\n    \"math3\",\n    \"math4\"\n  ),\n  `Type` = c(\n    \"integer\",\n    \"datetime\",\n    \"integer\",\n    \"integer\",\n    \"integer\",\n    \"numeric\",\n    \"numeric\"\n  ),\n  `Description` = c(\n    \"Student ID\",\n    \"Survey Date\",\n    \"Grade Level\",\n    \"Math Response 1 (1: Strongly Disagree, 4: Strongly Agree)\",\n    \"Math Response 2 (1: Strongly Disagree, 4: Strongly Agree)\",\n    \"Math Response 3 (1: Strongly Disagree, 4: Strongly Agree)\",\n    \"Math Response 4 (1: Strongly Disagree, 4: Strongly Agree)\"\n  ),\n  `Range/Values` = c(\n    \"1347-1399\",\n    \"2023-02-13 to 2023-02-14\",\n    \"9-12\",\n    \"1-4\",\n    \"1-4\",\n    \"1.0-4.0 (NA allowed)\",\n    \"1.0-4.0 (NA allowed)\"\n  )\n)\n\n# Visualizza il Dizionario dei Dati\nprint(data_dict)\n\n# Salva il Dizionario dei Dati in un file CSV\nwrite_csv(data_dict, \"data_dictionary.csv\")\n\n# Salva il Dizionario dei Dati in un file Excel\nwrite_xlsx(data_dict, \"data_dictionary.xlsx\")\n\nOutput Atteso: file CSV (data_dictionary.csv).\n\n\n\n\n\n\n\n\n\nVariable Name\nType\nDescription\nRange/Values\n\n\n\n\nstu_id\ninteger\nStudent ID\n1347-1399\n\n\nsvy_date\ndatetime\nSurvey Date\n2023-02-13 to 2023-02-14\n\n\ngrade_level\ninteger\nGrade Level\n9-12\n\n\nmath1\ninteger\nMath Response 1 (1: Strongly Disagree, 4: Strongly Agree)\n1-4\n\n\nmath2\ninteger\nMath Response 2 (1: Strongly Disagree, 4: Strongly Agree)\n1-4\n\n\nmath3\nnumeric\nMath Response 3 (1: Strongly Disagree, 4: Strongly Agree)\n1.0-4.0 (NA allowed)\n\n\nmath4\nnumeric\nMath Response 4 (1: Strongly Disagree, 4: Strongly Agree)\n1.0-4.0 (NA allowed)\n\n\n\n\nDocumentazione: Il dizionario dei dati offre una descrizione chiara e standardizzata, utile per analisi successive e per la condivisione del dataset.\nSalvataggio multiplo: I formati .csv e .xlsx garantiscono la massima compatibilità con altri software e sistemi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#riflessioni-conclusive",
    "href": "chapters/eda/02_data_cleaning.html#riflessioni-conclusive",
    "title": "13  Flusso di lavoro per la pulizia dei dati",
    "section": "13.5 Riflessioni Conclusive",
    "text": "13.5 Riflessioni Conclusive\nNel processo di analisi dei dati, la fase di pulizia e pre-elaborazione è cruciale per garantire la qualità e l’integrità dei risultati finali. Sebbene questa fase possa sembrare meno interessante rispetto all’analisi vera e propria, essa costituisce la base su cui si costruiscono tutte le successive elaborazioni e interpretazioni. Attraverso una serie di passaggi strutturati, come quelli illustrati in questo capitolo, è possibile trasformare dati grezzi e disordinati in un dataset pulito, coerente e pronto per l’analisi. La cura nella gestione dei dati, dalla rimozione di duplicati alla creazione di un dizionario dei dati, è fondamentale per ottenere risultati affidabili e riproducibili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/02_data_cleaning.html#informazioni-sullambiente-di-sviluppo",
    "title": "13  Flusso di lavoro per la pulizia dei dati",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pointblank_0.12.2 haven_2.5.4       labelled_2.13.0   mice_3.17.0      \n#&gt;  [5] MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2 ggpubr_0.6.0     \n#&gt;  [9] ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0   bayesplot_1.11.1 \n#&gt; [13] psych_2.4.6.26    scales_1.3.0      markdown_1.13     knitr_1.49       \n#&gt; [17] lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4      \n#&gt; [21] purrr_1.0.2       readr_2.1.5       tidyr_1.3.1       tibble_3.2.1     \n#&gt; [25] ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] mnormt_2.1.1      rlang_1.1.4       magrittr_2.0.3    compiler_4.4.2   \n#&gt;  [5] vctrs_0.6.5       pkgconfig_2.0.3   shape_1.4.6.1     fastmap_1.2.0    \n#&gt;  [9] backports_1.5.0   utf8_1.2.4        promises_1.3.2    blastula_0.3.5   \n#&gt; [13] rmarkdown_2.29    tzdb_0.4.0        nloptr_2.1.1      xfun_0.49        \n#&gt; [17] glmnet_4.1-8      jomo_2.7-6        jsonlite_1.8.9    later_1.4.1      \n#&gt; [21] pan_1.9           broom_1.0.7       parallel_4.4.2    R6_2.5.1         \n#&gt; [25] stringi_1.8.4     car_3.1-3         boot_1.3-31       rpart_4.1.23     \n#&gt; [29] Rcpp_1.0.13-1     iterators_1.0.14  base64enc_0.1-3   pacman_0.5.1     \n#&gt; [33] R.utils_2.12.3    httpuv_1.6.15     Matrix_1.7-1      splines_4.4.2    \n#&gt; [37] nnet_7.3-19       timechange_0.3.0  tidyselect_1.2.1  abind_1.4-8      \n#&gt; [41] yaml_2.3.10       codetools_0.2-20  miniUI_0.1.1.1    lattice_0.22-6   \n#&gt; [45] shiny_1.9.1       withr_3.0.2       evaluate_1.0.1    survival_3.7-0   \n#&gt; [49] xml2_1.3.6        pillar_1.9.0      carData_3.0-5     foreach_1.5.2    \n#&gt; [53] generics_0.1.3    rprojroot_2.0.4   hms_1.1.3         commonmark_1.9.2 \n#&gt; [57] munsell_0.5.1     minqa_1.2.8       xtable_1.8-4      glue_1.8.0       \n#&gt; [61] tools_4.4.2       data.table_1.16.2 lme4_1.1-35.5     ggsignif_0.6.4   \n#&gt; [65] grid_4.4.2        colorspace_2.1-1  nlme_3.1-166      Formula_1.2-5    \n#&gt; [69] cli_3.6.3         fansi_1.0.6       gt_0.11.1         gtable_0.3.6     \n#&gt; [73] R.methodsS3_1.8.2 rstatix_0.7.2     sass_0.4.9.9000   digest_0.6.37    \n#&gt; [77] htmlwidgets_1.6.4 farver_2.1.2      R.oo_1.27.0       htmltools_0.5.8.1\n#&gt; [81] lifecycle_1.0.4   mitml_0.4-5       mime_0.12",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#bibliografia",
    "href": "chapters/eda/02_data_cleaning.html#bibliografia",
    "title": "13  Flusso di lavoro per la pulizia dei dati",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBuchanan, E. M., Crain, S. E., Cunningham, A. L., Johnson, H. R., Stash, H., Papadatou-Pastou, M., Isager, P. M., Carlsson, R., & Aczel, B. (2021). Getting started creating data dictionaries: How to create a shareable data set. Advances in Methods and Practices in Psychological Science, 4(1), 2515245920928007.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_dplyr.html",
    "href": "chapters/eda/03_dplyr.html",
    "title": "14  Data wrangling",
    "section": "",
    "text": "14.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nL’obiettivo di questo capitolo è fornire un’introduzione alle funzioni principali del linguaggio R per le operazioni di data wrangling, cioè per il preprocessing e la pulizia dei dati. In R, queste operazioni sono strettamente legate al concetto di “data tidying”, che si riferisce all’organizzazione sistematica dei dati per facilitare l’analisi.\nPer comprendere meglio il concetto di “data tidying”, possiamo rifarci a una citazione tratta dal testo di riferimento R for Data Science (2e):\nL’essenza del “data tidying” è organizzare i dati in un formato che sia facile da gestire e analizzare. Anche se gli stessi dati possono essere rappresentati in vari modi, non tutte le rappresentazioni sono ugualmente efficienti o facili da usare. Un dataset “tidy” segue tre principi fondamentali che lo rendono particolarmente pratico:\nI pacchetti R come dplyr, ggplot2 e gli altri pacchetti del tidyverse sono progettati specificamente per lavorare con dati in formato “tidy”, permettendo agli utenti di eseguire operazioni di manipolazione e visualizzazione in modo più intuitivo ed efficiente.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Data wrangling</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_dplyr.html#introduzione",
    "href": "chapters/eda/03_dplyr.html#introduzione",
    "title": "14  Data wrangling",
    "section": "",
    "text": "“Happy families are all alike; every unhappy family is unhappy in its own way.”\n— Leo Tolstoy\n\n\n“Tidy datasets are all alike, but every messy dataset is messy in its own way.”\n— Hadley Wickham\n\n\n\nOgni variabile è una colonna: ogni colonna nel dataset rappresenta una singola variabile.\nOgni osservazione è una riga: ogni riga nel dataset rappresenta un’unica osservazione.\nOgni valore è una cella: ogni cella del dataset contiene un singolo valore.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Data wrangling</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_dplyr.html#pipe",
    "href": "chapters/eda/03_dplyr.html#pipe",
    "title": "14  Data wrangling",
    "section": "14.2 Pipe",
    "text": "14.2 Pipe\nSia il pacchetto tidyr che il pacchetto dplyr utilizzano l’operatore pipe, che in R può essere rappresentato da due notazioni principali: |&gt; (introdotto nativamente in R a partire dalla versione 4.1.0) e %&gt;% (introdotto dal pacchetto magrittr, ampiamente utilizzato in tidyverse). Entrambi gli operatori permettono di concatenare in modo efficiente una serie di operazioni, ma presentano alcune differenze che meritano attenzione.\n\n14.2.1 Cosa Fa la Pipe?\nLa pipe è uno strumento potente che permette di collegare in modo diretto l’output di una funzione come input della funzione successiva. Questo approccio:\n\nRiduce la necessità di creare variabili intermedie.\nMigliora la leggibilità del codice.\nRende il flusso delle operazioni più chiaro e lineare.\n\nOgni funzione applicata con la pipe riceve automaticamente l’output della funzione precedente come suo primo argomento. Ciò consente di scrivere sequenze di operazioni in un formato compatto e intuitivo.\nEcco un esempio pratico:\n\n# Utilizzo della pipe per trasformare un dataset\nlibrary(dplyr)\n\ndf &lt;- data.frame(\n  id = 1:5,\n  value = c(10, 20, 30, 40, 50)\n)\n\n# Filtra i dati, seleziona colonne e calcola nuovi valori\ndf_clean &lt;- df |&gt;\n  dplyr::filter(value &gt; 20) |&gt;\n  dplyr::select(id, value) |&gt;\n  mutate(squared_value = value^2)\n\nIn questa sequenza, il dataset originale df viene filtrato, le colonne desiderate vengono selezionate e viene aggiunta una nuova colonna con il valore al quadrato.\n\nhead(df_clean)\n#&gt;   id value squared_value\n#&gt; 1  3    30           900\n#&gt; 2  4    40          1600\n#&gt; 3  5    50          2500\n\nIn sintesi, la pipe è uno strumento fondamentale per scrivere codice R moderno e leggibile, indipendentemente dal fatto che si utilizzi |&gt; o %&gt;%.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Data wrangling</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_dplyr.html#verbi",
    "href": "chapters/eda/03_dplyr.html#verbi",
    "title": "14  Data wrangling",
    "section": "14.3 Verbi",
    "text": "14.3 Verbi\nLe funzioni principali (“verbi) di dplyr sono le seguenti:\n\n\n\n\n\n\n\nVerbo dplyr\nDescrizione\n\n\n\n\nselect()\nSeleziona colonne\n\n\nfilter()\nFiltra righe\n\n\narrange()\nRiordina o organizza le righe\n\n\nmutate()\nCrea nuove colonne\n\n\nsummarise()\nRiassume i valori\n\n\ngroup_by()\nConsente di eseguire operazioni di gruppo\n\n\n\nI verbi di dplyr sono suddivisi in quattro gruppi, in base all’elemento su cui operano: righe, colonne, gruppi o tabelle.\nInoltre, le diverse funzioni bind_ e _joins permettono di combinare più tibbles (ovvero, data frame) in uno solo.\nPer introdurre il processo di “data tidying”, in questo tutorial utilizzeremo il dataset msleep.\n\ndata(msleep)\ndim(msleep)\n#&gt; [1] 83 11\n\nEsaminiamo i dati:\n\nglimpse(msleep)\n#&gt; Rows: 83\n#&gt; Columns: 11\n#&gt; $ name         &lt;chr&gt; \"Cheetah\", \"Owl monkey\", \"Mountain beaver\", \"Greater s…\n#&gt; $ genus        &lt;chr&gt; \"Acinonyx\", \"Aotus\", \"Aplodontia\", \"Blarina\", \"Bos\", \"…\n#&gt; $ vore         &lt;chr&gt; \"carni\", \"omni\", \"herbi\", \"omni\", \"herbi\", \"herbi\", \"c…\n#&gt; $ order        &lt;chr&gt; \"Carnivora\", \"Primates\", \"Rodentia\", \"Soricomorpha\", \"…\n#&gt; $ conservation &lt;chr&gt; \"lc\", NA, \"nt\", \"lc\", \"domesticated\", NA, \"vu\", NA, \"d…\n#&gt; $ sleep_total  &lt;dbl&gt; 12.1, 17.0, 14.4, 14.9, 4.0, 14.4, 8.7, 7.0, 10.1, 3.0…\n#&gt; $ sleep_rem    &lt;dbl&gt; NA, 1.8, 2.4, 2.3, 0.7, 2.2, 1.4, NA, 2.9, NA, 0.6, 0.…\n#&gt; $ sleep_cycle  &lt;dbl&gt; NA, NA, NA, 0.1333333, 0.6666667, 0.7666667, 0.3833333…\n#&gt; $ awake        &lt;dbl&gt; 11.9, 7.0, 9.6, 9.1, 20.0, 9.6, 15.3, 17.0, 13.9, 21.0…\n#&gt; $ brainwt      &lt;dbl&gt; NA, 0.01550, NA, 0.00029, 0.42300, NA, NA, NA, 0.07000…\n#&gt; $ bodywt       &lt;dbl&gt; 50.000, 0.480, 1.350, 0.019, 600.000, 3.850, 20.490, 0…\n\nLe colonne, nell’ordine, corrispondono a quanto segue:\n\n\n\nNome colonna\nDescrizione\n\n\n\n\nname\nNome comune\n\n\ngenus\nRango tassonomico\n\n\nvore\nCarnivoro, onnivoro o erbivoro?\n\n\norder\nRango tassonomico\n\n\nconservation\nStato di conservazione del mammifero\n\n\nsleep_total\nQuantità totale di sonno, in ore\n\n\nsleep_rem\nSonno REM, in ore\n\n\nsleep_cycle\nDurata del ciclo di sonno, in ore\n\n\nawake\nQuantità di tempo trascorso sveglio, in ore\n\n\nbrainwt\nPeso del cervello, in chilogrammi\n\n\nbodywt\nPeso corporeo, in chilogrammi",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Data wrangling</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_dplyr.html#righe",
    "href": "chapters/eda/03_dplyr.html#righe",
    "title": "14  Data wrangling",
    "section": "14.4 Righe",
    "text": "14.4 Righe\nI verbi più importanti che operano sulle righe di un dataset sono filter(), che seleziona le righe da includere senza modificarne l’ordine, e arrange(), che cambia l’ordine delle righe senza alterare la selezione delle righe presenti.\n\nmsleep |&gt;\n    dplyr::filter(sleep_total &lt; 4) |&gt;\n    arrange(sleep_total)\n#&gt; # A tibble: 9 × 11\n#&gt;   name            genus         vore  order          conservation sleep_total\n#&gt;   &lt;chr&gt;           &lt;chr&gt;         &lt;chr&gt; &lt;chr&gt;          &lt;chr&gt;              &lt;dbl&gt;\n#&gt; 1 Giraffe         Giraffa       herbi Artiodactyla   cd                   1.9\n#&gt; 2 Pilot whale     Globicephalus carni Cetacea        cd                   2.7\n#&gt; 3 Horse           Equus         herbi Perissodactyla domesticated         2.9\n#&gt; 4 Roe deer        Capreolus     herbi Artiodactyla   lc                   3  \n#&gt; 5 Donkey          Equus         herbi Perissodactyla domesticated         3.1\n#&gt; 6 African elepha… Loxodonta     herbi Proboscidea    vu                   3.3\n#&gt; # ℹ 3 more rows\n#&gt; # ℹ 5 more variables: sleep_rem &lt;dbl&gt;, sleep_cycle &lt;dbl&gt;, awake &lt;dbl&gt;, …\n\nPossiamo usare filter() speficicano più di una condizione logica.\n\nmsleep |&gt;\n    dplyr::filter((sleep_total &lt; 4 & bodywt &gt; 100) | brainwt &gt; 1) |&gt;\n    arrange(sleep_total)\n#&gt; # A tibble: 7 × 11\n#&gt;   name            genus         vore  order          conservation sleep_total\n#&gt;   &lt;chr&gt;           &lt;chr&gt;         &lt;chr&gt; &lt;chr&gt;          &lt;chr&gt;              &lt;dbl&gt;\n#&gt; 1 Giraffe         Giraffa       herbi Artiodactyla   cd                   1.9\n#&gt; 2 Pilot whale     Globicephalus carni Cetacea        cd                   2.7\n#&gt; 3 Horse           Equus         herbi Perissodactyla domesticated         2.9\n#&gt; 4 Donkey          Equus         herbi Perissodactyla domesticated         3.1\n#&gt; 5 African elepha… Loxodonta     herbi Proboscidea    vu                   3.3\n#&gt; 6 Asian elephant  Elephas       herbi Proboscidea    en                   3.9\n#&gt; # ℹ 1 more row\n#&gt; # ℹ 5 more variables: sleep_rem &lt;dbl&gt;, sleep_cycle &lt;dbl&gt;, awake &lt;dbl&gt;, …",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Data wrangling</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_dplyr.html#colonne",
    "href": "chapters/eda/03_dplyr.html#colonne",
    "title": "14  Data wrangling",
    "section": "14.5 Colonne",
    "text": "14.5 Colonne\nEsistono quattro verbi principali che modificano le colonne di un dataset senza cambiare le righe:\n\nrelocate() cambia la posizione delle colonne;\nrename() modifica i nomi delle colonne;\nselect() seleziona le colonne da includere o escludere;\nmutate() crea nuove colonne a partire da quelle esistenti.\n\n\nmsleep2 &lt;- msleep |&gt;\n    mutate(\n        rem_prop = sleep_rem / sleep_total * 100\n    ) |&gt;\n    dplyr::select(name, vore, rem_prop, sleep_total) |&gt;\n    arrange(desc(rem_prop))\n\nglimpse(msleep2)\n#&gt; Rows: 83\n#&gt; Columns: 4\n#&gt; $ name        &lt;chr&gt; \"European hedgehog\", \"Thick-tailed opposum\", \"Giant arm…\n#&gt; $ vore        &lt;chr&gt; \"omni\", \"carni\", \"insecti\", \"omni\", \"carni\", \"omni\", \"o…\n#&gt; $ rem_prop    &lt;dbl&gt; 34.65347, 34.02062, 33.70166, 29.21348, 28.71287, 27.22…\n#&gt; $ sleep_total &lt;dbl&gt; 10.1, 19.4, 18.1, 8.9, 10.1, 18.0, 9.1, 10.3, 12.5, 8.4…\n\nIn questo esempio, utilizziamo mutate() per creare una nuova colonna rem_prop che rappresenta la percentuale di sonno REM sul totale del sonno. Successivamente, select() viene utilizzato per scegliere solo alcune colonne del dataset, e infine desc(rem_prop) ordina i valori di rem_prop in ordine decrescente, dal valore maggiore a quello minore.\nPer cambiare il nome di una colonna possiamo usare rename(). Inoltre, possiamo cambiare l’ordine delle variabili con relocate().\n\nmsleep2 |&gt;\n    rename(rem_perc = rem_prop) |&gt;\n    relocate(rem_perc, .before = name)\n#&gt; # A tibble: 83 × 4\n#&gt;   rem_perc name                   vore    sleep_total\n#&gt;      &lt;dbl&gt; &lt;chr&gt;                  &lt;chr&gt;         &lt;dbl&gt;\n#&gt; 1     34.7 European hedgehog      omni           10.1\n#&gt; 2     34.0 Thick-tailed opposum   carni          19.4\n#&gt; 3     33.7 Giant armadillo        insecti        18.1\n#&gt; 4     29.2 Tree shrew             omni            8.9\n#&gt; 5     28.7 Dog                    carni          10.1\n#&gt; 6     27.2 North American Opossum omni           18  \n#&gt; # ℹ 77 more rows",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Data wrangling</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_dplyr.html#gruppi",
    "href": "chapters/eda/03_dplyr.html#gruppi",
    "title": "14  Data wrangling",
    "section": "14.6 Gruppi",
    "text": "14.6 Gruppi\nIl verbo group_by() viene utilizzato per suddividere un dataset in gruppi, in base a una o più variabili, che siano rilevanti per l’analisi. Questo permette di eseguire operazioni di sintesi su ciascun gruppo separatamente, ottenendo informazioni aggregate.\nAd esempio, nel codice seguente:\n\nmsleep |&gt;\n    group_by(order) |&gt;\n    summarise(\n        avg_sleep = mean(sleep_total),\n        min_sleep = min(sleep_total),\n        max_sleep = max(sleep_total),\n        total = n()\n    ) |&gt;\n    arrange(desc(avg_sleep))\n#&gt; # A tibble: 19 × 5\n#&gt;   order           avg_sleep min_sleep max_sleep total\n#&gt;   &lt;chr&gt;               &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;int&gt;\n#&gt; 1 Chiroptera           19.8      19.7      19.9     2\n#&gt; 2 Didelphimorphia      18.7      18        19.4     2\n#&gt; 3 Cingulata            17.8      17.4      18.1     2\n#&gt; 4 Afrosoricida         15.6      15.6      15.6     1\n#&gt; 5 Pilosa               14.4      14.4      14.4     1\n#&gt; 6 Rodentia             12.5       7        16.6    22\n#&gt; # ℹ 13 more rows\n\n\ngroup_by(order) suddivide il dataset msleep in gruppi, ciascuno corrispondente a un valore distinto della variabile order.\nSuccessivamente, summarise() calcola diverse statistiche per ogni gruppo:\n\navg_sleep è la media del totale del sonno (sleep_total) all’interno di ciascun gruppo.\nmin_sleep è il valore minimo di sleep_total in ogni gruppo.\nmax_sleep è il valore massimo di sleep_total in ogni gruppo.\ntotal è il numero di osservazioni (o righe) per ciascun gruppo, calcolato con la funzione n().\n\nInfine, arrange(desc(avg_sleep)) ordina i risultati in ordine decrescente in base alla media del sonno totale (avg_sleep), mostrando prima i gruppi con la media di sonno più alta.\n\nQuesto tipo di approccio è utile quando si vuole analizzare come cambiano le caratteristiche dei dati a seconda dei gruppi specifici, fornendo una visione più dettagliata e significativa.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Data wrangling</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_dplyr.html#dati-mancanti",
    "href": "chapters/eda/03_dplyr.html#dati-mancanti",
    "title": "14  Data wrangling",
    "section": "14.7 Dati mancanti",
    "text": "14.7 Dati mancanti\nNel dataset ci sono celle che contengono valori mancanti, indicati come NA. Questi rappresentano misurazioni per le quali i dati non sono stati registrati.\nPer ottenere una panoramica dei dati, inclusi i valori mancanti, possiamo utilizzare il comando:\n\nsummary(msleep)\n#&gt;      name              genus               vore              order          \n#&gt;  Length:83          Length:83          Length:83          Length:83         \n#&gt;  Class :character   Class :character   Class :character   Class :character  \n#&gt;  Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n#&gt;                                                                             \n#&gt;                                                                             \n#&gt;                                                                             \n#&gt;                                                                             \n#&gt;  conservation        sleep_total      sleep_rem      sleep_cycle    \n#&gt;  Length:83          Min.   : 1.90   Min.   :0.100   Min.   :0.1167  \n#&gt;  Class :character   1st Qu.: 7.85   1st Qu.:0.900   1st Qu.:0.1833  \n#&gt;  Mode  :character   Median :10.10   Median :1.500   Median :0.3333  \n#&gt;                     Mean   :10.43   Mean   :1.875   Mean   :0.4396  \n#&gt;                     3rd Qu.:13.75   3rd Qu.:2.400   3rd Qu.:0.5792  \n#&gt;                     Max.   :19.90   Max.   :6.600   Max.   :1.5000  \n#&gt;                                     NA's   :22      NA's   :51      \n#&gt;      awake          brainwt            bodywt        \n#&gt;  Min.   : 4.10   Min.   :0.00014   Min.   :   0.005  \n#&gt;  1st Qu.:10.25   1st Qu.:0.00290   1st Qu.:   0.174  \n#&gt;  Median :13.90   Median :0.01240   Median :   1.670  \n#&gt;  Mean   :13.57   Mean   :0.28158   Mean   : 166.136  \n#&gt;  3rd Qu.:16.15   3rd Qu.:0.12550   3rd Qu.:  41.750  \n#&gt;  Max.   :22.10   Max.   :5.71200   Max.   :6654.000  \n#&gt;                  NA's   :27\n\nPer visualizzare il pattern di dati mancanti, ovvero come la mancanza di una variabile possa influenzare la mancanza di altre, si può usare:\n\nmd.pattern(msleep, rotate.names = TRUE)\n#&gt;    name genus order sleep_total awake bodywt vore sleep_rem brainwt\n#&gt; 20    1     1     1           1     1      1    1         1       1\n#&gt; 9     1     1     1           1     1      1    1         1       1\n#&gt; 9     1     1     1           1     1      1    1         1       1\n#&gt; 5     1     1     1           1     1      1    1         1       1\n#&gt; 1     1     1     1           1     1      1    1         1       0\n#&gt; 10    1     1     1           1     1      1    1         1       0\n#&gt; 1     1     1     1           1     1      1    1         1       0\n#&gt; 1     1     1     1           1     1      1    1         1       0\n#&gt; 5     1     1     1           1     1      1    1         0       1\n#&gt; 3     1     1     1           1     1      1    1         0       1\n#&gt; 7     1     1     1           1     1      1    1         0       0\n#&gt; 5     1     1     1           1     1      1    1         0       0\n#&gt; 2     1     1     1           1     1      1    0         1       1\n#&gt; 1     1     1     1           1     1      1    0         1       1\n#&gt; 2     1     1     1           1     1      1    0         1       1\n#&gt; 2     1     1     1           1     1      1    0         0       0\n#&gt;       0     0     0           0     0      0    7        22      27\n#&gt;    conservation sleep_cycle    \n#&gt; 20            1           1   0\n#&gt; 9             1           0   1\n#&gt; 9             0           1   1\n#&gt; 5             0           0   2\n#&gt; 1             1           1   1\n#&gt; 10            1           0   2\n#&gt; 1             0           1   2\n#&gt; 1             0           0   3\n#&gt; 5             1           0   2\n#&gt; 3             0           0   3\n#&gt; 7             1           0   3\n#&gt; 5             0           0   4\n#&gt; 2             1           0   2\n#&gt; 1             0           1   2\n#&gt; 2             0           0   3\n#&gt; 2             0           0   5\n#&gt;              29          51 136\n\n\n\n\n\n\n\n\nIl modo più semplice per gestire i valori mancanti è l’analisi dei casi completi (complete case analysis), che esclude dall’analisi le osservazioni con valori mancanti e utilizza solo quelle con tutte le variabili registrate. Questo approccio può essere implementato come segue:\n\nmsleep_comp &lt;- msleep |&gt;\n    drop_na()\ndim(msleep_comp)\n#&gt; [1] 20 11\n\nTuttavia, per il dataset in questione, questa strategia non è adeguata, poiché si passa da 83 osservazioni iniziali a solo 20 righe dopo aver eliminato i dati mancanti.\nUn approccio più utile è l’utilizzo di metodi di imputazione (imputation methods). Uno di questi è l’imputazione semplice (single imputation, SI), dove il valore mancante viene sostituito dalla media della variabile corrispondente. Questo tipo di imputazione può essere eseguito come segue:\n\nimp &lt;- mice(msleep, method = \"mean\", m = 1, maxit = 1, print = FALSE)\n#&gt; Warning: Number of logged events: 6\ncomplete(imp) |&gt;\n    summary()\n#&gt;      name              genus               vore              order          \n#&gt;  Length:83          Length:83          Length:83          Length:83         \n#&gt;  Class :character   Class :character   Class :character   Class :character  \n#&gt;  Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n#&gt;                                                                             \n#&gt;                                                                             \n#&gt;                                                                             \n#&gt;  conservation        sleep_total      sleep_rem      sleep_cycle    \n#&gt;  Length:83          Min.   : 1.90   Min.   :0.100   Min.   :0.1167  \n#&gt;  Class :character   1st Qu.: 7.85   1st Qu.:1.150   1st Qu.:0.4167  \n#&gt;  Mode  :character   Median :10.10   Median :1.875   Median :0.4396  \n#&gt;                     Mean   :10.43   Mean   :1.875   Mean   :0.4396  \n#&gt;                     3rd Qu.:13.75   3rd Qu.:2.200   3rd Qu.:0.4396  \n#&gt;                     Max.   :19.90   Max.   :6.600   Max.   :1.5000  \n#&gt;      awake          brainwt            bodywt        \n#&gt;  Min.   : 4.10   Min.   :0.00014   Min.   :   0.005  \n#&gt;  1st Qu.:10.25   1st Qu.:0.00635   1st Qu.:   0.174  \n#&gt;  Median :13.90   Median :0.11500   Median :   1.670  \n#&gt;  Mean   :13.57   Mean   :0.28158   Mean   : 166.136  \n#&gt;  3rd Qu.:16.15   3rd Qu.:0.28158   3rd Qu.:  41.750  \n#&gt;  Max.   :22.10   Max.   :5.71200   Max.   :6654.000\n\nTuttavia, uno dei problemi dell’imputazione media è che tende a ridurre la varianza e a rendere le stime dell’errore standard meno accurate, generando bias verso il basso.\nUn metodo più sofisticato è l’imputazione multipla (multiple imputation, MI). Questa tecnica genera più imputazioni, creando diversi dataset completi. Per ciascuno di questi dataset, è possibile effettuare l’analisi desiderata e, al termine, combinare i risultati ottenuti dai vari dataset imputati per ottenere un risultato finale più robusto. Un esempio di questa tecnica utilizza il metodo di predictive mean matching (metodo = “pmm”), che sfrutta i valori vicini nei dati come imputazioni:\n\nimp2 &lt;- mice(msleep, method = \"pmm\", m = 1, maxit = 100, print = FALSE)\n#&gt; Warning: Number of logged events: 6\ncomplete(imp2) |&gt;\n    summary()\n#&gt;      name              genus               vore              order          \n#&gt;  Length:83          Length:83          Length:83          Length:83         \n#&gt;  Class :character   Class :character   Class :character   Class :character  \n#&gt;  Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n#&gt;                                                                             \n#&gt;                                                                             \n#&gt;                                                                             \n#&gt;  conservation        sleep_total      sleep_rem      sleep_cycle    \n#&gt;  Length:83          Min.   : 1.90   Min.   :0.100   Min.   :0.1167  \n#&gt;  Class :character   1st Qu.: 7.85   1st Qu.:0.900   1st Qu.:0.1833  \n#&gt;  Mode  :character   Median :10.10   Median :1.500   Median :0.3333  \n#&gt;                     Mean   :10.43   Mean   :1.843   Mean   :0.4502  \n#&gt;                     3rd Qu.:13.75   3rd Qu.:2.400   3rd Qu.:0.6667  \n#&gt;                     Max.   :19.90   Max.   :6.600   Max.   :1.5000  \n#&gt;      awake          brainwt            bodywt        \n#&gt;  Min.   : 4.10   Min.   :0.00014   Min.   :   0.005  \n#&gt;  1st Qu.:10.25   1st Qu.:0.00260   1st Qu.:   0.174  \n#&gt;  Median :13.90   Median :0.01210   Median :   1.670  \n#&gt;  Mean   :13.57   Mean   :0.23634   Mean   : 166.136  \n#&gt;  3rd Qu.:16.15   3rd Qu.:0.13600   3rd Qu.:  41.750  \n#&gt;  Max.   :22.10   Max.   :5.71200   Max.   :6654.000\n\nL’imputazione multipla, grazie alla sua capacità di considerare la variabilità tra le diverse imputazioni, fornisce stime più accurate rispetto all’imputazione media semplice, riducendo il rischio di bias e fornendo risultati più affidabili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Data wrangling</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_dplyr.html#considerazioni-conclusive",
    "href": "chapters/eda/03_dplyr.html#considerazioni-conclusive",
    "title": "14  Data wrangling",
    "section": "14.8 Considerazioni Conclusive",
    "text": "14.8 Considerazioni Conclusive\nIl data wrangling è una delle fasi più importanti in qualsiasi pipeline di analisi dei dati. In questo capitolo abbiamo introdotto l’uso del pacchetto tidyverse di R per la manipolazione dei dati e il suo utilizzo in scenari di base. Tuttavia, il tidyverse è un ecosistema ampio e qui abbiamo trattato solo gli elementi fondamentali. Per approfondire, si consiglia di consultare ulteriori risorse come quelle disponibili sul sito web del tidyverse e il libro R for Data Science (2e), di cui esiste anche una traduzione italiana.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Data wrangling</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_dplyr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/03_dplyr.html#informazioni-sullambiente-di-sviluppo",
    "title": "14  Data wrangling",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] missForest_1.5    mice_3.16.0       MASS_7.3-61       viridis_0.6.5    \n#&gt;  [5] viridisLite_0.4.2 ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3    \n#&gt;  [9] patchwork_1.3.0   bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0     \n#&gt; [13] markdown_1.13     knitr_1.49        lubridate_1.9.3   forcats_1.0.0    \n#&gt; [17] stringr_1.5.1     dplyr_1.1.4       purrr_1.0.2       readr_2.1.5      \n#&gt; [21] tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0  \n#&gt; [25] rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] mnormt_2.1.1         rlang_1.1.4          magrittr_2.0.3      \n#&gt;  [4] compiler_4.4.2       vctrs_0.6.5          pkgconfig_2.0.3     \n#&gt;  [7] shape_1.4.6.1        fastmap_1.2.0        backports_1.5.0     \n#&gt; [10] utf8_1.2.4           promises_1.3.1       rmarkdown_2.29      \n#&gt; [13] tzdb_0.4.0           nloptr_2.1.1         itertools_0.1-3     \n#&gt; [16] xfun_0.49            glmnet_4.1-8         jomo_2.7-6          \n#&gt; [19] randomForest_4.7-1.2 jsonlite_1.8.9       later_1.4.0         \n#&gt; [22] pan_1.9              broom_1.0.7          parallel_4.4.2      \n#&gt; [25] R6_2.5.1             stringi_1.8.4        car_3.1-3           \n#&gt; [28] boot_1.3-31          rpart_4.1.23         Rcpp_1.0.13-1       \n#&gt; [31] iterators_1.0.14     pacman_0.5.1         httpuv_1.6.15       \n#&gt; [34] Matrix_1.7-1         splines_4.4.2        nnet_7.3-19         \n#&gt; [37] timechange_0.3.0     tidyselect_1.2.1     abind_1.4-8         \n#&gt; [40] yaml_2.3.10          codetools_0.2-20     miniUI_0.1.1.1      \n#&gt; [43] doRNG_1.8.6          lattice_0.22-6       shiny_1.9.1         \n#&gt; [46] withr_3.0.2          evaluate_1.0.1       survival_3.7-0      \n#&gt; [49] pillar_1.9.0         carData_3.0-5        rngtools_1.5.2      \n#&gt; [52] foreach_1.5.2        generics_0.1.3       rprojroot_2.0.4     \n#&gt; [55] hms_1.1.3            munsell_0.5.1        minqa_1.2.8         \n#&gt; [58] xtable_1.8-4         glue_1.8.0           tools_4.4.2         \n#&gt; [61] lme4_1.1-35.5        ggsignif_0.6.4       grid_4.4.2          \n#&gt; [64] colorspace_2.1-1     nlme_3.1-166         Formula_1.2-5       \n#&gt; [67] cli_3.6.3            fansi_1.0.6          gtable_0.3.6        \n#&gt; [70] rstatix_0.7.2        digest_0.6.37        htmlwidgets_1.6.4   \n#&gt; [73] farver_2.1.2         htmltools_0.5.8.1    lifecycle_1.0.4     \n#&gt; [76] mitml_0.4-5          mime_0.12",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Data wrangling</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html",
    "href": "chapters/eda/04_exploring_qualitative_data.html",
    "title": "15  Esplorare i dati qualitativi",
    "section": "",
    "text": "15.1 Introduzione\nIn questo capitolo ci concentreremo sull’analisi dei dati qualitativi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#il-dataset-penguins",
    "href": "chapters/eda/04_exploring_qualitative_data.html#il-dataset-penguins",
    "title": "15  Esplorare i dati qualitativi",
    "section": "15.2 Il dataset penguins",
    "text": "15.2 Il dataset penguins\nPer fornire esempi pratici, in questo capitolo utilizzeremo il dataset palmerpenguins, messo a disposizione da Allison Horst. I dati sono stati raccolti e resi disponibili da Dr. Kristen Gorman e dalla Palmer Station, parte del programma di ricerca ecologica a lungo termine Long Term Ecological Research Network. Il dataset contiene informazioni su 344 pinguini, appartenenti a 3 diverse specie, raccolte su 3 isole dell’arcipelago di Palmer, in Antartide. Per semplicità, i dati sono organizzati nel file penguins.csv.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#importare-i-dati",
    "href": "chapters/eda/04_exploring_qualitative_data.html#importare-i-dati",
    "title": "15  Esplorare i dati qualitativi",
    "section": "15.3 Importare i Dati",
    "text": "15.3 Importare i Dati\nPossiamo caricare i dati grezzi dal file penguins.csv in un DataFrame con il seguente comando:\n\nd &lt;- rio::import(here::here(\"data\", \"penguins.csv\"))\n\nEsaminiamo i dati.\n\nglimpse(d)\n#&gt; Rows: 344\n#&gt; Columns: 8\n#&gt; $ species           &lt;chr&gt; \"Adelie\", \"Adelie\", \"Adelie\", \"Adelie\", \"Adelie\",…\n#&gt; $ island            &lt;chr&gt; \"Torgersen\", \"Torgersen\", \"Torgersen\", \"Torgersen…\n#&gt; $ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.…\n#&gt; $ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.…\n#&gt; $ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, …\n#&gt; $ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 347…\n#&gt; $ sex               &lt;chr&gt; \"male\", \"female\", \"female\", NA, \"female\", \"male\",…\n#&gt; $ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2…\n\n\nd |&gt; \n  head()\n#&gt;   species    island bill_length_mm bill_depth_mm flipper_length_mm\n#&gt; 1  Adelie Torgersen           39.1          18.7               181\n#&gt; 2  Adelie Torgersen           39.5          17.4               186\n#&gt; 3  Adelie Torgersen           40.3          18.0               195\n#&gt; 4  Adelie Torgersen             NA            NA                NA\n#&gt; 5  Adelie Torgersen           36.7          19.3               193\n#&gt; 6  Adelie Torgersen           39.3          20.6               190\n#&gt;   body_mass_g    sex year\n#&gt; 1        3750   male 2007\n#&gt; 2        3800 female 2007\n#&gt; 3        3250 female 2007\n#&gt; 4          NA   &lt;NA&gt; 2007\n#&gt; 5        3450 female 2007\n#&gt; 6        3650   male 2007\n\nPer semplicità, rimuoviamo le righe con valori mancanti con la seguente istruzione:\n\ndf &lt;- d |&gt;\n  drop_na()\n\n\ndf |&gt; \n  summary()\n#&gt;    species             island          bill_length_mm  bill_depth_mm  \n#&gt;  Length:333         Length:333         Min.   :32.10   Min.   :13.10  \n#&gt;  Class :character   Class :character   1st Qu.:39.50   1st Qu.:15.60  \n#&gt;  Mode  :character   Mode  :character   Median :44.50   Median :17.30  \n#&gt;                                        Mean   :43.99   Mean   :17.16  \n#&gt;                                        3rd Qu.:48.60   3rd Qu.:18.70  \n#&gt;                                        Max.   :59.60   Max.   :21.50  \n#&gt;  flipper_length_mm  body_mass_g       sex                 year     \n#&gt;  Min.   :172       Min.   :2700   Length:333         Min.   :2007  \n#&gt;  1st Qu.:190       1st Qu.:3550   Class :character   1st Qu.:2007  \n#&gt;  Median :197       Median :4050   Mode  :character   Median :2008  \n#&gt;  Mean   :201       Mean   :4207                      Mean   :2008  \n#&gt;  3rd Qu.:213       3rd Qu.:4775                      3rd Qu.:2009  \n#&gt;  Max.   :231       Max.   :6300                      Max.   :2009",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#tabelle-di-contingenza",
    "href": "chapters/eda/04_exploring_qualitative_data.html#tabelle-di-contingenza",
    "title": "15  Esplorare i dati qualitativi",
    "section": "15.4 Tabelle di Contingenza",
    "text": "15.4 Tabelle di Contingenza\nUna tabella di contingenza è uno strumento utilizzato per riassumere i dati di due variabili categoriali, ovvero variabili qualitative che assumono valori all’interno di un insieme finito di categorie. In una tabella di contingenza, ogni cella mostra quante volte si è verificata una combinazione specifica di categorie per le due variabili considerate.\nPer esempio, se prendiamo in esame due variabili categoriali come “island” e “species” all’interno di un DataFrame df, ciascuna delle quali rappresenta rispettivamente l’isola di provenienza e la specie dei pinguini, possiamo costruire una tabella che mostra quante volte ciascuna combinazione di “island” e “species” appare nel nostro campione. In altre parole, la tabella di contingenza ci permette di vedere quante osservazioni ci sono per ogni combinazione di categorie tra queste due variabili.\n\ntable(df$island, df$species)\n#&gt;            \n#&gt;             Adelie Chinstrap Gentoo\n#&gt;   Biscoe        44         0    119\n#&gt;   Dream         55        68      0\n#&gt;   Torgersen     47         0      0\n\nQuesta tabella di contingenza mostra la distribuzione di tre specie di pinguini (Adelie, Chinstrap, Gentoo) rispetto a tre isole (Biscoe, Dream, Torgersen). Ogni cella rappresenta il numero di pinguini di una determinata specie presenti su ciascuna isola. Ecco un’interpretazione dettagliata:\n\nIsola Biscoe: Qui troviamo 44 pinguini della specie Adelie e 119 pinguini della specie Gentoo, mentre non sono presenti pinguini Chinstrap.\nIsola Dream: Questa isola ospita 55 pinguini Adelie e 68 pinguini Chinstrap, ma nessun pinguino della specie Gentoo.\nIsola Torgersen: Su quest’isola sono presenti solo 47 pinguini della specie Adelie, e nessun pinguino delle specie Chinstrap o Gentoo.\n\nPossiamo dunque commentare dicendo:\n\nLa specie Adelie è distribuita su tutte e tre le isole, con numeri notevoli sia su Biscoe (44), Dream (55), che Torgersen (47).\nLa specie Chinstrap si trova solo sull’isola Dream (68 esemplari) e non è presente sulle altre due isole.\nLa specie Gentoo si trova esclusivamente sull’isola Biscoe (119 esemplari), non essendo presente su Dream e Torgersen.\n\nQuesto suggerisce una distribuzione geografica specifica delle diverse specie di pinguini, con alcune specie limitate a determinate isole e altre distribuite più ampiamente.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#grafico-a-barre",
    "href": "chapters/eda/04_exploring_qualitative_data.html#grafico-a-barre",
    "title": "15  Esplorare i dati qualitativi",
    "section": "15.5 Grafico a barre",
    "text": "15.5 Grafico a barre\n\n15.5.1 Grafico a Barre con una Singola Variabile\nUn grafico a barre è uno strumento comunemente utilizzato per rappresentare visivamente una singola variabile categoriale. Questo tipo di grafico mostra le diverse categorie su uno degli assi (solitamente l’asse orizzontale) e utilizza barre di altezza proporzionale per rappresentare la frequenza o il conteggio di ciascuna categoria sull’altro asse (solitamente l’asse verticale).\nAd esempio, in un dataset che contiene informazioni su diverse specie di pinguini, un grafico a barre potrebbe mostrare il numero di pinguini per ciascuna specie. Le specie vengono visualizzate come etichette lungo l’asse delle ascisse, mentre l’altezza delle barre rappresenta il numero di pinguini osservati per ciascuna specie.\nIl grafico a barre consente di confrontare le dimensioni delle categorie in modo semplice e intuitivo.\nPer i dati in esame, creiamo un grafico a barre che rappresenta il numero totale di pinguini per isola.\n\nggplot(df, aes(x = island)) +\n  geom_bar(alpha = 0.5) +\n  ggtitle(\"Numero totale di pinguini per isola\") +\n  xlab(\"Isola\") +\n  ylab(\"Numero di pinguini\")\n\n\n\n\n\n\n\n\nUn secondo grafico a barre mostra il numero totale di pinguini per specie.\n\nggplot(df, aes(x = species)) +\n  geom_bar(alpha = 0.5) +\n  ggtitle(\"Numero totale di pinguini per specie\") +\n  xlab(\"Specie\") +\n  ylab(\"Numero di pinguini\")\n\n\n\n\n\n\n\n\n\n\n15.5.2 Grafico a Barre con Due Variabili\nÈ possibile visualizzare contemporaneamente le distribuzioni di due variabili categoriali utilizzando un grafico a barre. Questo tipo di grafico è particolarmente utile per esaminare la relazione tra due variabili categoriali.\nIn un grafico a barre con due variabili, una delle variabili viene rappresentata sull’asse orizzontale come categoria principale, mentre la seconda variabile è distinta tramite colori diversi o barre impilate. In questo modo, possiamo confrontare facilmente le frequenze o le proporzioni delle categorie della prima variabile, osservando allo stesso tempo come sono distribuite le categorie della seconda variabile all’interno di ciascuna categoria principale.\nAd esempio, visualizziamo il numero di pinguini per specie e isola. A qusto fine possiamo creare un grafico a barre dove le isole sono rappresentate sull’asse delle ascisse e i diversi colori delle barre mostrano la distribuzione delle specie su ciascuna isola. Questo approccio consente di esplorare come le due variabili categoriali (specie e isola) interagiscono visivamente.\n\nggplot(df, aes(x = island, fill = species)) +\n  geom_bar(position = \"stack\") +\n  ggtitle(\"Numero di pinguini per specie e isola\") +\n  xlab(\"Isola\") +\n  ylab(\"Numero di pinguini\") +\n  labs(fill = \"Specie\")\n\n\n\n\n\n\n\n\nIn alternativa, è possibile creare un grafico a barre dove le specie sono rappresentate sull’asse delle ascisse e i diversi colori delle barre mostrano la distribuzione delle isole per ciascuna specie.\n\nggplot(df, aes(x = species, fill = island)) +\n  geom_bar(position = \"stack\") +\n  ggtitle(\"Numero di pinguini per isola e specie\") +\n  xlab(\"Specie\") +\n  ylab(\"Numero di pinguini\") +\n  labs(fill = \"Isola\")\n\n\n\n\n\n\n\n\nIn alternativa all’uso delle frequenze assolute, possiamo rappresentare i dati utilizzando le frequenze relative. Questo approccio permette di confrontare meglio le categorie indipendentemente dal numero totale di osservazioni. Nella figura seguente, ad esempio, viene mostrata la proporzione di pinguini di ciascuna specie per ogni isola, evidenziando la distribuzione relativa delle specie su ogni isola, anziché il conteggio assoluto. Questa rappresentazione aiuta a visualizzare le differenze nella composizione delle specie, anche se il numero complessivo di pinguini varia tra le isole.\n\nggplot(df, aes(x = island, fill = species)) +\n  geom_bar(position = \"fill\") +\n  ggtitle(\"Proporzione di pinguini per specie e isola\") +\n  xlab(\"Isola\") +\n  ylab(\"Proporzione\") +\n  labs(fill = \"Specie\")",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#mosaic-plots",
    "href": "chapters/eda/04_exploring_qualitative_data.html#mosaic-plots",
    "title": "15  Esplorare i dati qualitativi",
    "section": "15.6 Mosaic plots",
    "text": "15.6 Mosaic plots\nIl Mosaic plot è una tecnica di visualizzazione particolarmente adatta per rappresentare tabelle di contingenza. Questo tipo di grafico somiglia a un grafico a barre impilate standard, ma con un vantaggio importante: oltre a visualizzare la suddivisione interna delle categorie, permette di vedere anche le dimensioni relative dei gruppi della variabile principale.\nIn altre parole, il Mosaic plot non solo mostra come si distribuiscono le categorie di una variabile secondaria all’interno di ogni gruppo della variabile principale, ma fornisce anche un’idea visiva della grandezza complessiva dei gruppi. Questo lo rende uno strumento utile per analizzare e interpretare le relazioni tra due variabili categoriali, evidenziando sia la proporzione all’interno di ciascun gruppo, sia la grandezza relativa tra i gruppi stessi.\n\nmosaic(~ species + island, data = df, main = \"Mosaic Plot of Species and Island\")",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#proporzioni-di-riga-e-colonna",
    "href": "chapters/eda/04_exploring_qualitative_data.html#proporzioni-di-riga-e-colonna",
    "title": "15  Esplorare i dati qualitativi",
    "section": "15.7 Proporzioni di Riga e Colonna",
    "text": "15.7 Proporzioni di Riga e Colonna\nNelle sezioni precedenti abbiamo esaminato la visualizzazione di due variabili categoriali utilizzando grafici a barre e Mosaic plot. Tuttavia, non abbiamo ancora discusso come vengono calcolate le proporzioni mostrate in questi grafici. In questa sezione ci concentreremo sulla suddivisione frazionaria di una variabile rispetto a un’altra, esplorando come possiamo modificare la nostra tabella di contingenza per ottenere una visione più dettagliata delle proporzioni.\nQuesto ci permetterà di comprendere meglio le relazioni tra le due variabili, visualizzando non solo i conteggi assoluti, ma anche le proporzioni relative per riga o per colonna. Le proporzioni di riga mostrano la distribuzione di una variabile all’interno delle categorie di un’altra, mentre le proporzioni di colonna evidenziano la distribuzione inversa.\nCalcoliamo le proporzioni di specie per isola.\n\n# Calcola le proporzioni di riga\nrow_proportions &lt;- df |&gt; \n  count(island, species) |&gt; \n  group_by(island) |&gt; \n  mutate(proportion = n / sum(n)) |&gt; \n  pivot_wider(names_from = species, values_from = proportion, values_fill = 0)\n\n# Aggiungi una colonna \"Totale\" che rappresenta il totale di ciascuna riga\nrow_proportions_with_total &lt;- row_proportions |&gt; \n  mutate(Totale = rowSums(across(where(is.numeric))))\n\n# Mostra la tabella con proporzioni di riga e il totale\nprint(row_proportions_with_total)\n#&gt; # A tibble: 5 × 6\n#&gt; # Groups:   island [3]\n#&gt;   island        n Adelie Gentoo Chinstrap Totale\n#&gt;   &lt;chr&gt;     &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1 Biscoe       44  0.270  0         0       44.3\n#&gt; 2 Biscoe      119  0      0.730     0      120. \n#&gt; 3 Dream        55  0.447  0         0       55.4\n#&gt; 4 Dream        68  0      0         0.553   68.6\n#&gt; 5 Torgersen    47  1      0         0       48\n\nCalcoliamo nuovamente le proporzioni, ma questa volta in funzione delle colonne (per isola).\n\n# Calcola la tabella di contingenza\ncontingency_table &lt;- xtabs(~ island + species, data = df)\n\n# Calcola le proporzioni di colonna\ncolumn_proportions &lt;- prop.table(contingency_table, margin = 2)\n\n# Aggiungi una riga \"Totale\" con la somma di ciascuna colonna\ncolumn_proportions_with_total &lt;- rbind(\n  column_proportions, Totale = colSums(column_proportions)\n)\n\n# Mostra la tabella con proporzioni di colonna e il totale\nprint(column_proportions_with_total)\n#&gt;              Adelie Chinstrap Gentoo\n#&gt; Biscoe    0.3013699         0      1\n#&gt; Dream     0.3767123         1      0\n#&gt; Torgersen 0.3219178         0      0\n#&gt; Totale    1.0000000         1      1",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#confronto-tra-gruppi",
    "href": "chapters/eda/04_exploring_qualitative_data.html#confronto-tra-gruppi",
    "title": "15  Esplorare i dati qualitativi",
    "section": "15.8 Confronto tra Gruppi",
    "text": "15.8 Confronto tra Gruppi\nAlcune delle analisi più interessanti emergono confrontando i dati numerici tra diversi gruppi. In questa sezione approfondiremo alcune delle tecniche che abbiamo già esplorato per visualizzare i dati numerici di più gruppi su uno stesso grafico e introdurremo nuovi metodi per confrontare i dati numerici tra gruppi. Queste tecniche ci permetteranno di osservare meglio le differenze e le somiglianze tra gruppi, mettendo in evidenza tendenze, variazioni e altre caratteristiche rilevanti.\nQui consideriamo due variabili qualitative. Creiamo un grafico a barre per confrontare la distribuzione del genere per specie.\n\nggplot(df, aes(x = species, fill = sex)) +\n  geom_bar(position = \"dodge\") +\n  ggtitle(\"Distribuzione del genere per specie\") +\n  xlab(\"Specie\") +\n  ylab(\"Conteggio\")\n\n\n\n\n\n\n\n\nSpesso, i confronti più interessanti riguardano come una variabile numerica varia in base a una o più categorie. Questo tipo di analisi ci aiuta a capire differenze tra gruppi e a individuare modelli o tendenze.\nNel grafico seguente, confrontiamo la distribuzione del peso corporeo (body_mass_g) in base alla specie e al genere. Le aree colorate rappresentano come si distribuisce il peso per maschi e femmine all’interno di ciascuna specie. Le linee più strette al centro delle aree colorate aggiungono ulteriori dettagli, mostrando i valori più comuni e come si concentrano i dati per ciascun gruppo.\n\nggplot(df, aes(x = species, y = body_mass_g, fill = sex)) +\n  geom_violin(position = position_dodge(width = 0.9), alpha = 0.5) +\n  geom_boxplot(position = position_dodge(width = 0.9), width = 0.2, alpha = 0.8) +\n  ggtitle(\"Distribuzione della massa corporea\\nin base alla specie e al genere\") +\n  xlab(\"Specie\") +\n  ylab(\"Massa corporea (g)\") +\n  labs(fill = \"Genere\")\n\n\n\n\n\n\n\n\n\nAree colorate (grafico a violino):\n\nRappresentano l’intera distribuzione dei pesi per ogni gruppo (specie e genere). Più l’area è larga in un punto, maggiore è il numero di pinguini con quel peso.\n\nLinee strette al centro (boxplot):\n\nForniscono un riassunto visivo dei dati, mostrando dove i pesi si concentrano maggiormente e quanto variano all’interno di ciascun gruppo.\n\nCosa possiamo osservare:\n\nPossiamo vedere facilmente se i maschi e le femmine di una stessa specie tendono ad avere pesi simili o differenti, e se c’è una certa sovrapposizione tra i due gruppi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/04_exploring_qualitative_data.html#informazioni-sullambiente-di-sviluppo",
    "title": "15  Esplorare i dati qualitativi",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] grid      stats     graphics  grDevices utils     datasets  methods  \n#&gt; [8] base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] vcd_1.4-13        MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2\n#&gt;  [5] ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0  \n#&gt;  [9] bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0      markdown_1.13    \n#&gt; [13] knitr_1.49        lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1    \n#&gt; [17] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#&gt; [21] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [25] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      xfun_0.49         htmlwidgets_1.6.4 rstatix_0.7.2    \n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    fansi_1.0.6       pacman_0.5.1     \n#&gt; [13] R.oo_1.27.0       pkgconfig_2.0.3   data.table_1.16.2 lifecycle_1.0.4  \n#&gt; [17] compiler_4.4.2    farver_2.1.2      munsell_0.5.1     mnormt_2.1.1     \n#&gt; [21] carData_3.0-5     httpuv_1.6.15     htmltools_0.5.8.1 yaml_2.3.10      \n#&gt; [25] Formula_1.2-5     car_3.1-3         pillar_1.9.0      later_1.4.1      \n#&gt; [29] R.utils_2.12.3    abind_1.4-8       nlme_3.1-166      mime_0.12        \n#&gt; [33] tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4     labeling_0.4.3   \n#&gt; [37] rprojroot_2.0.4   fastmap_1.2.0     colorspace_2.1-1  cli_3.6.3        \n#&gt; [41] magrittr_2.0.3    utf8_1.2.4        broom_1.0.7       withr_3.0.2      \n#&gt; [45] backports_1.5.0   promises_1.3.2    timechange_0.3.0  rmarkdown_2.29   \n#&gt; [49] ggsignif_0.6.4    R.methodsS3_1.8.2 zoo_1.8-12        hms_1.1.3        \n#&gt; [53] shiny_1.9.1       evaluate_1.0.1    lmtest_0.9-40     miniUI_0.1.1.1   \n#&gt; [57] rlang_1.1.4       Rcpp_1.0.13-1     xtable_1.8-4      glue_1.8.0       \n#&gt; [61] jsonlite_1.8.9    R6_2.5.1",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html",
    "href": "chapters/eda/05_exploring_numeric_data.html",
    "title": "16  Esplorare i dati numerici",
    "section": "",
    "text": "Introduzione\nIn questo capitolo ci concentreremo sull’analisi dei dati numerici. In particolare, esamineremo le distribuzioni di frequenza e i quantili, insieme alle tecniche di visualizzazione più comuni, come l’istogramma, l’istogramma smussato e il box-plot. Tratteremo sia gli aspetti computazionali che quelli interpretativi di queste misure, fornendo strumenti utili non solo per una comprensione personale, ma anche per la comunicazione efficace dei risultati, in particolare con chi utilizza questi dati per prendere decisioni pratiche nel mondo reale.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#i-dati-sulle-aspettative-negative-nella-depressione",
    "href": "chapters/eda/05_exploring_numeric_data.html#i-dati-sulle-aspettative-negative-nella-depressione",
    "title": "16  Esplorare i dati numerici",
    "section": "16.1 I dati sulle aspettative negative nella depressione",
    "text": "16.1 I dati sulle aspettative negative nella depressione\nConsideriamo i dati relativi alle aspettative negative, individuate come un meccanismo chiave nel mantenimento della depressione (Zetsche et al., 2019). Supponiamo di voler analizzare la distribuzione di una singola variabile quantitativa.\nImportiamo i dati:\n\ndf = rio::import(here::here(\"data\", \"data.mood.csv\"))\n\nPer questo esercizio, ci concentreremo sulle colonne esm_id (il codice del soggetto), group (il gruppo) e bdi (il valore BDI-II).\n\ndf &lt;- df |&gt; \n  dplyr::select(\"esm_id\", \"group\", \"bdi\")\ndf |&gt; \n  head()\n#&gt;   esm_id group bdi\n#&gt; 1     10   mdd  25\n#&gt; 2     10   mdd  25\n#&gt; 3     10   mdd  25\n#&gt; 4     10   mdd  25\n#&gt; 5     10   mdd  25\n#&gt; 6     10   mdd  25\n\nSe elenchiamo le modalità presenti in group utilizzando il metodo unique(), scopriamo che corrispondono a mdd (pazienti) e ctl (controlli sani).\n\ndf$group |&gt; \n  unique()\n#&gt; [1] \"mdd\" \"ctl\"\n\nRimuoviamo i duplicati per ottenere un unico valore BDI-II per ogni soggetto:\n\ndf &lt;- df[!duplicated(df), ]\n\nVerifichiamo di avere ottenuto il risultato desiderato.\n\ndim(df)\n#&gt; [1] 67  3\n\n\nhead(df)\n#&gt;    esm_id group bdi\n#&gt; 1      10   mdd  25\n#&gt; 15      9   mdd  30\n#&gt; 30      6   mdd  26\n#&gt; 46      7   mdd  35\n#&gt; 65     12   mdd  44\n#&gt; 83     16   mdd  30\n\nSi noti che il nuovo DataFrame (con 67 righe) conserva il “nome” delle righe (ovvero, l’indice di riga) del DataFrame originario (con 1188 righe). Per esempio, il secondo soggetto (con codice identificativo 9) si trova sulla seconda riga del DataFrame, ma il suo indice di riga è 15. Questo non ha nessuna conseguenza perché non useremo l’indice di riga nelle analisi seguenti.\nEliminiamo eventuali valori mancanti:\n\ndf &lt;- df[!is.na(df$bdi), ]\n\nOtteniamo così il DataFrame finale per gli scopi presenti (66 righe e 3 colonne):\n\ndim(df)\n#&gt; [1] 66  3\n\nStampiamo i valori BDI-II presentandoli ordinati dal più piccolo al più grande:\n\ndf$bdi |&gt; \n  sort()\n#&gt;  [1]  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  1  1  1  1  1\n#&gt; [25]  1  2  2  2  2  3  3  3  5  7  9 12 19 22 22 24 25 25 26 26 26 27 27 28\n#&gt; [49] 28 30 30 30 31 31 33 33 34 35 35 35 36 39 41 43 43 44\n\nNel linguaggio statistico, un’osservazione rappresenta l’informazione raccolta da un singolo individuo o entità che partecipa allo studio. Nel caso del dataset utilizzato da Zetsche et al. (2019), l’unità di osservazione è costituita dai partecipanti allo studio. Ogni riga del DataFrame, denominato df, corrisponde quindi a un individuo distinto incluso nell’analisi.\nLe variabili, invece, riflettono le diverse caratteristiche degli individui o delle entità considerate. Per i dati in esame, questo concetto si esprime così:\n\nOgni colonna di df rappresenta una variabile che descrive una specifica proprietà comune ai partecipanti.\nLe variabili sono identificate da etichette nelle colonne, come esa_id (l’identificativo del soggetto), mdd (il gruppo di appartenenza), e bdi (il punteggio del test BDI-II).\n\nIn termini simbolisi, per indicare una singola osservazione della variabile generica \\(X\\), si utilizza la notazione \\(X_i\\), dove \\(i\\) rappresenta l’indice dell’osservazione. Questo implica che abbiamo un valore diverso di \\(X\\) per ogni differente \\(i\\). Nel caso presente, con 67 osservazioni, \\(i\\) varia da 1 a 67. Così, per rappresentare la seconda osservazione (quella con \\(i=2\\)), useremo la notazione \\(X_2\\).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#distribuzioni-di-frequenza",
    "href": "chapters/eda/05_exploring_numeric_data.html#distribuzioni-di-frequenza",
    "title": "16  Esplorare i dati numerici",
    "section": "16.2 Distribuzioni di frequenza",
    "text": "16.2 Distribuzioni di frequenza\nCome osservato nell’output della sezione precedente, i dati grezzi non forniscono un’interpretazione immediata. Per rendere i dati più comprensibili e sintetici, è utile costruire una distribuzione di frequenza.\nUna distribuzione di frequenza mostra quante volte i valori di una variabile si verificano all’interno di intervalli specifici. Nel caso dei punteggi BDI-II, possiamo raggruppare i punteggi in quattro classi:\n\n0–13: depressione minima\n14–19: depressione lieve-moderata\n20–28: depressione moderata-severa\n29–63: depressione severa\n\nOgni classe, denotata come \\(\\Delta_i\\), rappresenta un intervallo di valori, definito come \\([a_i, b_i)\\) (aperto a destra) o \\((a_i, b_i]\\) (aperto a sinistra), dove \\(a_i\\) e \\(b_i\\) sono rispettivamente il limite inferiore e superiore della classe. A ciascuna classe si associa un’ampiezza, data da \\(b_i - a_i\\), e un valore centrale, indicato con \\(\\bar{x}_i\\). Poiché ogni osservazione \\(x_i\\) appartiene a una sola classe \\(\\Delta_i\\), possiamo calcolare le seguenti quantità:\n\nFrequenza assoluta \\(n_i\\): il numero di osservazioni che rientrano nella classe \\(\\Delta_i\\).\n\nProprietà: \\(n_1 + n_2 + \\dots + n_m = n\\), dove \\(n\\) è il numero totale di osservazioni.\n\nFrequenza relativa \\(f_i\\): la proporzione di osservazioni in ciascuna classe, calcolata come \\(f_i = n_i/n\\).\n\nProprietà: \\(f_1 + f_2 + \\dots + f_m = 1\\).\n\nFrequenza cumulata \\(N_i\\): il numero totale di osservazioni che rientrano nelle classi fino alla \\(i\\)-esima inclusa, calcolata come \\(N_i = \\sum_{j=1}^i n_j\\).\nFrequenza cumulata relativa \\(F_i\\): la somma delle frequenze relative fino alla \\(i\\)-esima classe, data da \\(F_i = \\frac{N_i}{n} = \\sum_{j=1}^i f_j\\).\n\nQueste misure permettono di riassumere in modo efficace la distribuzione dei punteggi e facilitano l’interpretazione delle caratteristiche del campione.\n\n16.2.1 Frequenze Assolute e Relative\nPer ottenere la distribuzione di frequenza assoluta e relativa dei valori BDI-II nel dataset di zetsche_2019future, è necessario aggiungere al DataFrame df una colonna contenente una variabile categoriale che classifichi ciascuna osservazione in una delle quattro classi che descrivono la gravità della depressione. Questo risultato si ottiene utilizzando la funzione cut().\nNella funzione cut():\n\nIl primo argomento, x, è un vettore unidimensionale (ad esempio, un vettore di tipo numeric o una colonna di un DataFrame) che contiene i dati da classificare.\nIl secondo argomento, breaks, definisce gli intervalli delle classi, specificandone i limiti inferiori e superiori.\nL’argomento include.lowest = TRUE garantisce che il limite inferiore dell’intervallo più basso sia incluso nella classificazione. Nel nostro caso, questo è particolarmente utile per assicurare che i valori uguali al limite inferiore siano assegnati correttamente.\n\nDi seguito, il codice per aggiungere la variabile categoriale al DataFrame:\n\n# Creare una variabile categoriale per classi di depressione\ndf &lt;- df %&gt;% \n  mutate(\n    bdi_class = cut(\n      bdi, \n      breaks = c(0, 13.5, 19.5, 28.5, 63),\n      include.lowest = TRUE\n    )\n  )\n\nQuesto codice suddivide i valori della variabile bdi in quattro intervalli corrispondenti ai livelli di gravità della depressione:\n\n0–13: depressione minima\n14–19: depressione lieve-moderata\n20–28: depressione moderata-severa\n29–63: depressione severa\n\nOgni osservazione verrà assegnata al corrispondente intervallo, creando così una nuova colonna bdi_class nel DataFrame df.\n\n16.2.1.1 Frequenze assolute\n\ntable(df$bdi_class)\n#&gt; \n#&gt;    [0,13.5] (13.5,19.5] (19.5,28.5]   (28.5,63] \n#&gt;          36           1          12          17\n\n\n\n16.2.1.2 Frequenze relative\n\nprop.table(table(df$bdi_class))\n#&gt; \n#&gt;    [0,13.5] (13.5,19.5] (19.5,28.5]   (28.5,63] \n#&gt;      0.5455      0.0152      0.1818      0.2576\n\n\n\n\n16.2.2 Distribuzioni congiunte\nLe variabili possono anche essere analizzate insieme tramite le distribuzioni congiunte di frequenze. Queste distribuzioni rappresentano l’insieme delle frequenze assolute o relative ad ogni possibile combinazione di valori delle variabili. Ad esempio, se l’insieme di variabili \\(V\\) è composto da due variabili, \\(X\\) e \\(Y\\), ciascuna delle quali può assumere due valori, 1 e 2, allora una possibile distribuzione congiunta di frequenze relative per \\(V\\) potrebbe essere espressa come \\(f(X = 1, Y = 1) = 0.2\\), \\(f(X = 1, Y = 2) = 0.1\\), \\(f(X = 2, Y = 1) = 0.5\\), e \\(f(X = 2, Y = 2) = 0.2\\). Come nel caso delle distribuzioni di frequenze relative di una singola variabile, le frequenze relative di una distribuzione congiunta devono sommare a 1.\nPer i dati dell’esempio precedente, la funzione prop.table() può essere utilizzata anche per produrre questo tipo di tabella: basta indicare le serie corrispondenti alle variabili considerate come valori degli argomenti bdi_class e group.\n\nprop.table(table(df$bdi_class, df$group))\n#&gt;              \n#&gt;                  ctl    mdd\n#&gt;   [0,13.5]    0.5455 0.0000\n#&gt;   (13.5,19.5] 0.0000 0.0152\n#&gt;   (19.5,28.5] 0.0000 0.1818\n#&gt;   (28.5,63]   0.0000 0.2576",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#istogramma",
    "href": "chapters/eda/05_exploring_numeric_data.html#istogramma",
    "title": "16  Esplorare i dati numerici",
    "section": "16.3 Istogramma",
    "text": "16.3 Istogramma\nUn istogramma rappresenta graficamente una distribuzione di frequenze. Un istogramma mostra sulle ascisse i limiti delle classi \\(\\Delta_i\\) e sulle ordinate la densità della frequenza relativa della variabile \\(X\\) nella classe \\(\\Delta_i\\). La densità della frequenza relativa è misurata dalla funzione costante a tratti \\(\\varphi_n(x)= \\frac{f_i}{b_i-a_i}\\), dove \\(f_i\\) è la frequenza relativa della classe \\(\\Delta_i\\) e \\(b_i - a_i\\) rappresenta l’ampiezza della classe. In questo modo, l’area del rettangolo associato alla classe \\(\\Delta_i\\) sull’istogramma sarà proporzionale alla frequenza relativa \\(f_i\\). È importante notare che l’area totale dell’istogramma delle frequenze relative è uguale a 1.0, poiché rappresenta la somma delle aree dei singoli rettangoli.\nPer fare un esempio, costruiamo un istogramma per i valori BDI-II di Zetsche et al. (2019). Con i quattro intervalli individuati dai cut-off del BDI-II creo una prima versione dell’istogramma – si notino le frequenze assolute sull’asse delle ordinate.\n\nggplot(df, aes(x = bdi)) +\n  geom_histogram(\n    breaks = c(0, 13.5, 19.5, 28.5, 63),\n    aes(y = ..density..),\n    fill = \"blue\", \n    alpha = 0.5\n  ) +\n  labs(title = \"Istogramma delle frequenze relative\", x = \"BDI-II\", y = \"Densità\")\n#&gt; Warning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `after_stat(density)` instead.\n\n\n\n\n\n\n\n\nAnche se nel caso presente è sensato usare ampiezze diverse per gli intervalli delle classi, in generale gli istogrammi si costruiscono utilizzando intervalli riportati sulle ascisse con un’ampiezza uguale.\n\nggplot(df, aes(x = bdi)) +\n  geom_histogram(\n    aes(y = ..density..),\n    fill = \"blue\", \n    alpha = 0.5\n  ) +\n  labs(title = \"Istogramma delle frequenze relative\", x = \"BDI-II\", y = \"Densità\")\n#&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#kernel-density-plot",
    "href": "chapters/eda/05_exploring_numeric_data.html#kernel-density-plot",
    "title": "16  Esplorare i dati numerici",
    "section": "16.4 Kernel density plot",
    "text": "16.4 Kernel density plot\nConfrontando le due figure precedenti, emerge chiaramente una limitazione dell’istogramma: la sua forma dipende dall’arbitrarietà con cui vengono scelti il numero e l’ampiezza delle classi, rendendo difficile interpretare correttamente la distribuzione dei dati.\nPer superare questa difficoltà, possiamo utilizzare una tecnica alternativa chiamata stima della densità kernel (KDE) – si veda l’?sec-kde. Mentre l’istogramma utilizza barre per rappresentare i dati, la KDE crea un profilo smussato che fornisce una visione più continua e meno dipendente dall’arbitrarietà delle classi.\nImmaginiamo un istogramma con classi di ampiezza molto piccola, tanto da avere una curva continua invece di barre discrete. Questo è ciò che fa la KDE: smussa il profilo dell’istogramma per ottenere una rappresentazione continua dei dati. Invece di utilizzare barre, la KDE posiziona una piccola curva (detta kernel) su ogni osservazione nel dataset. Queste curve possono essere gaussiane (a forma di campana) o di altro tipo. Ogni kernel ha un’altezza e una larghezza determinate da parametri di smussamento (o bandwidth), che controllano quanto deve essere larga e alta la curva. Tutte le curve kernel vengono sommate per creare una singola curva complessiva. Questa curva rappresenta la densità dei dati, mostrando come i dati sono distribuiti lungo il range dei valori.\nLa curva risultante dal KDE mostra la proporzione di casi per ciascun intervallo di valori. L’area sotto la curva in un determinato intervallo rappresenta la proporzione di casi della distribuzione che ricadono in quell’intervallo. Per esempio, se un intervallo ha un’area maggiore sotto la curva rispetto ad altri, significa che in quell’intervallo c’è una maggiore concentrazione di dati.\nLa curva di densità ottenuta tramite KDE fornisce dunque un’idea chiara di come i dati sono distribuiti senza dipendere dall’arbitrarietà della scelta delle classi dell’istogramma.\nCrediamo un kernel density plot per ciascuno dei due gruppi di valori BDI-II riportati da Zetsche et al. (2019).\n\nggplot(df, aes(x = bdi, fill = group)) +\n  geom_density(alpha = 0.5) +\n  labs(title = \"Curva di densità KDE\", x = \"BDI-II\", y = \"Densità\")",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#consigli-per-creare-visualizzazioni-di-dati-efficaci",
    "href": "chapters/eda/05_exploring_numeric_data.html#consigli-per-creare-visualizzazioni-di-dati-efficaci",
    "title": "16  Esplorare i dati numerici",
    "section": "16.5 Consigli per Creare Visualizzazioni di Dati Efficaci",
    "text": "16.5 Consigli per Creare Visualizzazioni di Dati Efficaci\nEcco alcuni suggerimenti per creare visualizzazioni di dati esplicative, efficaci e di qualità adatta alle presentazioni:\n\nMessaggio chiaro: Assicurati che il grafico trasmetta un messaggio chiaro e immediato (ad esempio, “Il livello di benessere psicologico dei partecipanti aumenta nel tempo”).\nUso del colore:\n\nUtilizza i colori in modo ponderato e con moderazione.\nNon eccedere nell’uso dei colori solo perché è possibile farlo.\nLimita l’uso a non più di cinque o sei colori in una singola figura.\nVerifica che le scelte cromatiche non distorcano le conclusioni della figura.\nEvita l’uso contemporaneo di rosso e verde nello stesso grafico, poiché queste tonalità sono difficili da distinguere per le persone daltoniche.\n\nGuidare l’attenzione:\n\nUtilizza dimensioni, colori e testo per guidare l’attenzione del pubblico.\nEvidenzia elementi particolari del grafico per enfatizzare punti chiave.\n\nGestione del sovraccarico visivo:\n\nUtilizza la trasparenza per ridurre il “sovrapplotting” (che si verifica quando ci sono molti elementi sovrapposti nel grafico, come punti o linee, rendendo difficile individuare i pattern).\nQuesta tecnica è particolarmente utile quando si visualizza una grande quantità di dati.\nSe il dataset è molto ampio e l’aggiunta di trasparenza non è sufficiente, considera la visualizzazione di un sottocampione dei dati (un campione casuale di punti dati, scelto senza sostituzione). Questa tecnica è nota come sottocampionamento.\n\nElementi testuali:\n\nI titoli, le etichette degli assi e il testo delle legende devono essere chiari e facilmente comprensibili.\nGli elementi della legenda dovrebbero essere ordinati in modo logico e coerente.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#forma-di-una-distribuzione",
    "href": "chapters/eda/05_exploring_numeric_data.html#forma-di-una-distribuzione",
    "title": "16  Esplorare i dati numerici",
    "section": "16.6 Forma di una Distribuzione",
    "text": "16.6 Forma di una Distribuzione\nIn statistica, la forma di una distribuzione descrive come i dati sono distribuiti intorno ai valori centrali. Si distingue tra distribuzioni simmetriche e asimmetriche, e tra distribuzioni unimodali e multimodali. Un’illustrazione grafica è fornita nella figura seguente. Nel pannello 1, la distribuzione è unimodale con asimmetria negativa; nel pannello 2, la distribuzione è unimodale con asimmetria positiva; nel pannello 3, la distribuzione è simmetrica e unimodale; nel pannello 4, la distribuzione è bimodale.\n\n\n\nDistribuzioni\n\n\nIl grafico della densità di kernel (Kernel Density Plot) dei valori BDI-II nel campione di Zetsche et al. (2019) è bimodale. Questo indica che le osservazioni della distribuzione si raggruppano in due cluster distinti: un gruppo di osservazioni tende ad avere valori BDI-II bassi, mentre l’altro gruppo tende ad avere valori BDI-II alti. Questi due cluster di osservazioni corrispondono al gruppo di controllo e al gruppo clinico nel campione di dati esaminato da Zetsche et al. (2019).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#indici-di-posizione",
    "href": "chapters/eda/05_exploring_numeric_data.html#indici-di-posizione",
    "title": "16  Esplorare i dati numerici",
    "section": "16.7 Indici di posizione",
    "text": "16.7 Indici di posizione\n\n16.7.1 Quantili\nLa distribuzione dei valori BDI-II di Zetsche et al. (2019) può essere sintetizzata attraverso l’uso dei quantili, che sono valori caratteristici che suddividono i dati in parti ugualmente numerose. I quartili sono tre quantili specifici: il primo quartile, \\(q_1\\), divide i dati in due parti, lasciando a sinistra il 25% del campione; il secondo quartile, \\(q_2\\), corrisponde alla mediana e divide i dati in due parti uguali; il terzo quartile lascia a sinistra il 75% del campione.\nInoltre, ci sono altri indici di posizione chiamati decili e percentili che suddividono i dati in parti di dimensioni uguali a 10% e 1%, rispettivamente.\nPer calcolare i quantili, i dati vengono prima ordinati in modo crescente e poi viene determinato il valore di \\(np\\), dove \\(n\\) è la dimensione del campione e \\(p\\) è l’ordine del quantile. Se \\(np\\) non è un intero, il valore del quantile corrisponde al valore del dato che si trova alla posizione successiva alla parte intera di \\(np\\). Se \\(np\\) è un intero, il valore del quantile corrisponde alla media dei dati nelle posizioni \\(k\\) e \\(k+1\\), dove \\(k\\) è la parte intera di \\(np\\).\nGli indici di posizione possono essere utilizzati per creare un box-plot, una rappresentazione grafica della distribuzione dei dati che è molto popolare e può essere utilizzata in alternativa ad un istogramma.\nAd esempio, per calcolare la mediana della distribuzione dei nove soggetti con un unico episodio di depressione maggiore del campione clinico di Zetsche et al. (2019), si determina il valore di \\(np = 9 \\cdot 0.5 = 4.5\\), che non è un intero. Pertanto, il valore del secondo quartile è pari al valore del dato che si trova alla posizione successiva alla parte intera di \\(np\\), ovvero \\(q_2 = x_{4 + 1} = 27\\). Per calcolare il quantile di ordine \\(2/3\\), si determina il valore di \\(np = 9 \\cdot 2/3 = 6\\), che è un intero. Quindi, il valore del quantile corrisponde alla media dei dati nelle posizioni \\(6\\) e \\(7\\), ovvero \\(q_{\\frac{2}{3}} = \\frac{1}{2} (x_{6} + x_{7}) = \\frac{1}{2} (33 + 33) = 33\\).\nUsiamo quantile() per trovare la soluzione dell’esercizio precedente.\n\nx = c(19, 26, 27, 28, 28, 33, 33, 41, 43)\nquantile(x, 2 / 3)\n#&gt; 66.66667% \n#&gt;        33",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#mostrare-i-dati",
    "href": "chapters/eda/05_exploring_numeric_data.html#mostrare-i-dati",
    "title": "16  Esplorare i dati numerici",
    "section": "16.8 Mostrare i dati",
    "text": "16.8 Mostrare i dati\n\n16.8.1 Diagramma a scatola\nIl box plot è uno strumento grafico che visualizza la dispersione di una distribuzione. Per creare un box plot, si disegna un rettangolo (la “scatola”) di altezza arbitraria, basato sulla distanza interquartile (IQR), che corrisponde alla differenza tra il terzo quartile (\\(q_{0.75}\\)) e il primo quartile (\\(q_{0.25}\\)). La mediana (\\(q_{0.5}\\)) è rappresentata da una linea all’interno del rettangolo.\nAi lati della scatola, vengono tracciati due segmenti di retta, detti “baffi”, che rappresentano i valori adiacenti inferiore e superiore. Il valore adiacente inferiore è il valore più basso tra le osservazioni che è maggiore o uguale al primo quartile meno 1.5 volte la distanza interquartile. Il valore adiacente superiore è il valore più alto tra le osservazioni che è minore o uguale al terzo quartile più 1.5 volte la distanza interquartile.\nSe ci sono dei valori che cadono al di fuori dei valori adiacenti, vengono chiamati “valori anomali” e sono rappresentati individualmente nel box plot per evidenziare la loro presenza e posizione. In questo modo, il box plot fornisce una rappresentazione visiva della distribuzione dei dati, permettendo di individuare facilmente eventuali valori anomali e di comprendere la dispersione dei dati.\n\nUtilizziamo un box-plot per rappresentare graficamente la distribuzione dei punteggi BDI-II nel gruppo dei pazienti e nel gruppo di controllo.\n\nggplot(df, aes(x = group, y = bdi)) +\n  geom_boxplot() +\n  labs(title = \"Box plot per gruppo\", x = \"Gruppo\", y = \"BDI-II\")\n\n\n\n\n\n\n\n\nUn risultato migliore si ottiene utilizzando un grafico a violino (violin plot) e includendo anche i dati grezzi.\n\n\n16.8.2 Grafico a Violino\nI grafici a violino combinano le caratteristiche dei box plot e dei grafici di densità di kernel (KDE plot) per offrire una rappresentazione più dettagliata dei dati. A questi grafici vengono sovrapposti i dati grezzi, fornendo una visione completa della distribuzione e delle caratteristiche dei dati.\n\nggplot(df, aes(x = group, y = bdi)) +\n  geom_violin(fill = \"lightgray\", color = \"black\") +\n  geom_jitter(width = 0.2, color = \"red\", alpha = 0.6) +\n  labs(\n    title = \"Violin plot con overlay dei punti grezzi\",\n    x = \"Gruppo\", \n    y = \"BDI-II\"\n  )",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#riflessioni-conclusive",
    "href": "chapters/eda/05_exploring_numeric_data.html#riflessioni-conclusive",
    "title": "16  Esplorare i dati numerici",
    "section": "16.9 Riflessioni Conclusive",
    "text": "16.9 Riflessioni Conclusive\nAbbiamo esplorato diverse tecniche per sintetizzare e visualizzare i dati, includendo distribuzioni di frequenze, istogrammi e grafici di densità. Questi strumenti sono essenziali per comprendere meglio i dati e presentare risultati in modo chiaro e informativo.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/05_exploring_numeric_data.html#informazioni-sullambiente-di-sviluppo",
    "title": "16  Esplorare i dati numerici",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2 ggpubr_0.6.0     \n#&gt;  [5] ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0   bayesplot_1.11.1 \n#&gt;  [9] psych_2.4.6.26    scales_1.3.0      markdown_1.13     knitr_1.49       \n#&gt; [13] lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4      \n#&gt; [17] purrr_1.0.2       readr_2.1.5       tidyr_1.3.1       tibble_3.2.1     \n#&gt; [21] ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      xfun_0.49         htmlwidgets_1.6.4 rstatix_0.7.2    \n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    fansi_1.0.6       pacman_0.5.1     \n#&gt; [13] R.oo_1.27.0       pkgconfig_2.0.3   data.table_1.16.2 lifecycle_1.0.4  \n#&gt; [17] compiler_4.4.2    farver_2.1.2      munsell_0.5.1     mnormt_2.1.1     \n#&gt; [21] carData_3.0-5     httpuv_1.6.15     htmltools_0.5.8.1 yaml_2.3.10      \n#&gt; [25] Formula_1.2-5     car_3.1-3         pillar_1.9.0      later_1.4.1      \n#&gt; [29] R.utils_2.12.3    abind_1.4-8       nlme_3.1-166      mime_0.12        \n#&gt; [33] tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4     labeling_0.4.3   \n#&gt; [37] rprojroot_2.0.4   fastmap_1.2.0     grid_4.4.2        colorspace_2.1-1 \n#&gt; [41] cli_3.6.3         magrittr_2.0.3    utf8_1.2.4        broom_1.0.7      \n#&gt; [45] withr_3.0.2       backports_1.5.0   promises_1.3.2    timechange_0.3.0 \n#&gt; [49] rmarkdown_2.29    ggsignif_0.6.4    R.methodsS3_1.8.2 hms_1.1.3        \n#&gt; [53] shiny_1.9.1       evaluate_1.0.1    miniUI_0.1.1.1    rlang_1.1.4      \n#&gt; [57] Rcpp_1.0.13-1     xtable_1.8-4      glue_1.8.0        jsonlite_1.8.9   \n#&gt; [61] R6_2.5.1",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#bibliografia",
    "href": "chapters/eda/05_exploring_numeric_data.html#bibliografia",
    "title": "16  Esplorare i dati numerici",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nZetsche, U., Buerkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: biased or realistic? Journal of Abnormal Psychology, 128(7), 678–688.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html",
    "href": "chapters/eda/06_data_visualization.html",
    "title": "17  Principi della visualizzazione dei dati",
    "section": "",
    "text": "Introduzione\nPrerequisiti\nConcetti e competenze chiave\nIn questo capitolo verranno introdotti i principi fondamentali della visualizzazione dei dati, accompagnati da una descrizione concisa. Per un approfondimento su ciascun principio, si rimanda al capitolo Data Visualization del libro Introduction to Data Science.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#codificare-i-dati-attraverso-segnali-visivi",
    "href": "chapters/eda/06_data_visualization.html#codificare-i-dati-attraverso-segnali-visivi",
    "title": "17  Principi della visualizzazione dei dati",
    "section": "17.1 Codificare i dati attraverso segnali visivi",
    "text": "17.1 Codificare i dati attraverso segnali visivi\nIniziamo con una panoramica dei principali segnali visivi utilizzati per codificare i dati: posizione, lunghezza, angoli, area, luminosità e tonalità del colore. Tra questi, posizione e lunghezza sono i segnali visivi più efficaci e intuitivi, poiché il cervello umano è particolarmente abile nel riconoscere variazioni spaziali. Questo rende la posizione e la lunghezza strumenti potenti per la rappresentazione quantitativa. In altre parole, le persone riescono a confrontare con maggiore precisione altezze e lunghezze (come le barre in un barplot) rispetto ad angoli o aree (come in un grafico a torta).\nAngoli e aree, sebbene comunemente usati, sono segnali visivi meno efficaci. Grafici come i pie chart, che si basano su angoli e aree per rappresentare quantità, risultano spesso meno precisi e più difficili da interpretare, specialmente quando le differenze sono piccole. Anche l’uso dell’area, ad esempio nei bubble plot, può distorcere la percezione delle differenze tra i dati, a meno che non venga gestita correttamente. Anche se l’area di una bolla può essere proporzionale al valore rappresentato, la percezione umana tende a sovrastimare le differenze tra aree più grandi.\nLuminosità e tonalità del colore sono utili per rappresentare variabili qualitative o categoriali, ma possono risultare difficili da interpretare quando si tratta di confrontare quantità precise. Tuttavia, il colore gioca un ruolo cruciale nelle visualizzazioni multidimensionali, come le heatmap, dove è necessario rappresentare più di due variabili contemporaneamente. È importante, però, usare il colore con attenzione, soprattutto per garantire l’accessibilità a persone con problemi di daltonismo.\nLe tabelle sono utili quando si ha una quantità limitata di dati e si richiede una precisione numerica rigorosa. Tuttavia, per set di dati più grandi o per evidenziare tendenze e differenze, i grafici (come i barplot) sono generalmente più efficaci. Le tabelle non offrono lo stesso impatto visivo immediato e rendono più difficile l’individuazione di pattern complessi.\n\n17.1.1 Ulteriori considerazioni sulla scelta della visualizzazione\nLa scelta della visualizzazione più appropriata dipende sia dalla natura dei dati che dallo scopo della comunicazione. Per esempio:\n\nBarplot o dot plot sono ideali per confrontare valori quantitativi tra categorie.\nIstogrammi, boxplot e raincloud plots sono più adatti per descrivere la distribuzione di dati continui e fare confronti tra categorie.\nGrafici di dispersione (scatter plot) sono eccellenti per esplorare relazioni tra due variabili continue.\n\nLa chiarezza e la leggibilità sono principi fondamentali nella creazione di visualizzazioni efficaci. L’aggiunta di elementi visivi eccessivi, come decorazioni superflue o troppi colori, può distrarre dal messaggio principale. Un buon grafico deve essere semplice, ma allo stesso tempo completo, includendo solo gli elementi visivi necessari per trasmettere il messaggio desiderato.\nIn conclusione, scegliere i segnali visivi adeguati e il tipo di grafico più appropriato non solo migliora l’accuratezza della comunicazione, ma rende le informazioni più accessibili e comprensibili per il pubblico.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#quando-includere-lo-zero",
    "href": "chapters/eda/06_data_visualization.html#quando-includere-lo-zero",
    "title": "17  Principi della visualizzazione dei dati",
    "section": "17.2 Quando includere lo zero",
    "text": "17.2 Quando includere lo zero\nQuando si usa la lunghezza come segnale visivo, come nei barplot, è essenziale che l’asse parta da zero. Non farlo può essere fuorviante e far sembrare le differenze più grandi di quanto non siano in realtà. Questo errore viene spesso sfruttato nei media per esagerare differenze apparentemente significative.\nTuttavia, quando si usa la posizione (ad esempio in un grafico a dispersione), non è sempre necessario includere lo zero, soprattutto se l’interesse principale è il confronto tra gruppi rispetto alla variabilità interna.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#evitare-le-distorsioni",
    "href": "chapters/eda/06_data_visualization.html#evitare-le-distorsioni",
    "title": "17  Principi della visualizzazione dei dati",
    "section": "17.3 Evitare le distorsioni",
    "text": "17.3 Evitare le distorsioni\nUna distorsione comune si verifica quando le differenze tra quantità sono rappresentate utilizzando aree, come nei bubble plot, dove il raggio dei cerchi è proporzionale al dato. Il problema è che, poiché l’area di un cerchio è proporzionale al quadrato del raggio, le differenze sembrano molto più ampie di quanto siano realmente. Per evitare queste distorsioni, è meglio utilizzare la posizione o la lunghezza, come in un grafico a barre, per confrontare direttamente le quantità.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#ordinare-le-categorie",
    "href": "chapters/eda/06_data_visualization.html#ordinare-le-categorie",
    "title": "17  Principi della visualizzazione dei dati",
    "section": "17.4 Ordinare le categorie",
    "text": "17.4 Ordinare le categorie\nQuando si visualizzano categorie, come nei barplot o nei boxplot, è opportuno ordinarle in base al valore della variabile di interesse, anziché in ordine alfabetico. Questo aiuta a evidenziare pattern significativi e facilita il confronto tra categorie.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#evitare-i-dynamite-plots",
    "href": "chapters/eda/06_data_visualization.html#evitare-i-dynamite-plots",
    "title": "17  Principi della visualizzazione dei dati",
    "section": "17.5 Evitare i Dynamite Plots",
    "text": "17.5 Evitare i Dynamite Plots\nI dynamite plots, che mostrano la media e l’errore standard (o la deviazione standard), sono spesso utilizzati in psicologia ma sono fuorvianti. Questi grafici tendono a esagerare le differenze e possono indurre false interpretazioni. È preferibile mostrare tutti i dati, ad esempio tramite un dot plot, che fornisce un’immagine più chiara della distribuzione dei dati (Butler, 2022).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#facilitare-i-confronti",
    "href": "chapters/eda/06_data_visualization.html#facilitare-i-confronti",
    "title": "17  Principi della visualizzazione dei dati",
    "section": "17.6 Facilitare i confronti",
    "text": "17.6 Facilitare i confronti\nQuando si confrontano due distribuzioni, come in un istogramma, è fondamentale mantenere gli stessi assi per entrambi i grafici. Se le distribuzioni sono presentate su assi con scale diverse, il confronto diventa difficile e potrebbe portare a conclusioni errate. Allineare i grafici verticalmente o orizzontalmente consente di percepire più facilmente le differenze tra i gruppi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#trasformazioni-logaritmiche",
    "href": "chapters/eda/06_data_visualization.html#trasformazioni-logaritmiche",
    "title": "17  Principi della visualizzazione dei dati",
    "section": "17.7 Trasformazioni logaritmiche",
    "text": "17.7 Trasformazioni logaritmiche\nLe trasformazioni logaritmiche sono utili quando si lavora con dati distribuiti su più ordini di grandezza o quando le variazioni tra le quantità sono moltiplicative (West, 2022). L’uso della scala logaritmica in un grafico a barre o a dispersione può ridurre le distorsioni visive e migliorare l’interpretazione dei dati. Questo approccio è particolarmente utile quando alcuni valori estremi potrebbero dominare il grafico, nascondendo dettagli rilevanti.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#codificare-una-terza-variabile",
    "href": "chapters/eda/06_data_visualization.html#codificare-una-terza-variabile",
    "title": "17  Principi della visualizzazione dei dati",
    "section": "17.8 Codificare una terza variabile",
    "text": "17.8 Codificare una terza variabile\nPer rappresentare tre variabili, è possibile utilizzare un grafico di dispersione con variabili codificate attraverso dimensioni aggiuntive come il colore, la dimensione o la forma dei punti. Ad esempio, in un grafico che confronta aspettativa di vita e reddito, la dimensione dei punti potrebbe rappresentare la popolazione e il colore la regione geografica. Quando si utilizza il colore per rappresentare una variabile, è importante scegliere palette cromatiche accessibili anche per chi è affetto da daltonismo, evitando combinazioni problematiche come rosso-verde.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#evitare-pseudo-tre-dimensioni",
    "href": "chapters/eda/06_data_visualization.html#evitare-pseudo-tre-dimensioni",
    "title": "17  Principi della visualizzazione dei dati",
    "section": "17.9 Evitare pseudo-tre dimensioni",
    "text": "17.9 Evitare pseudo-tre dimensioni\nGrafici tridimensionali, come barre o pie chart 3D, spesso aggiungono confusione senza fornire informazioni aggiuntive significative. Sebbene visivamente accattivanti, questi grafici distorcono la percezione e rendono difficile l’interpretazione accurata dei dati. È preferibile mantenere le visualizzazioni bidimensionali, a meno che la terza dimensione non rappresenti effettivamente una variabile aggiuntiva.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#scegliere-il-numero-giusto-di-cifre-significative",
    "href": "chapters/eda/06_data_visualization.html#scegliere-il-numero-giusto-di-cifre-significative",
    "title": "17  Principi della visualizzazione dei dati",
    "section": "17.10 Scegliere il numero giusto di cifre significative",
    "text": "17.10 Scegliere il numero giusto di cifre significative\nÈ importante evitare l’uso di troppe cifre decimali nelle tabelle e nei grafici. Spesso, una o due cifre significative sono sufficienti per rappresentare accuratamente i dati, mentre l’aggiunta di cifre inutili può confondere il lettore e dare un falso senso di precisione. Limitiamoci a mostrare solo le cifre necessarie per trasmettere il messaggio in modo chiaro.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#conoscere-il-pubblico",
    "href": "chapters/eda/06_data_visualization.html#conoscere-il-pubblico",
    "title": "17  Principi della visualizzazione dei dati",
    "section": "17.11 Conoscere il pubblico",
    "text": "17.11 Conoscere il pubblico\nInfine, è fondamentale adattare la visualizzazione dei dati al pubblico di riferimento. Grafici progettati per l’analisi esplorativa interna possono contenere dettagli tecnici complessi, ma quando si comunica a un pubblico più ampio o non specializzato, è necessario semplificare. Ad esempio, utilizzare una scala logaritmica può essere utile per un pubblico esperto, ma confondere un pubblico generale. In questi casi, mantenere la scala lineare e spiegare chiaramente i dati aiuta a evitare malintesi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#riflessioni-conclusive",
    "href": "chapters/eda/06_data_visualization.html#riflessioni-conclusive",
    "title": "17  Principi della visualizzazione dei dati",
    "section": "17.12 Riflessioni Conclusive",
    "text": "17.12 Riflessioni Conclusive\nI principi di visualizzazione dei dati trattati in questo capitolo sono strumenti fondamentali per garantire chiarezza e accuratezza nella rappresentazione delle informazioni. Scelte appropriate di grafici, segnali visivi e trasformazioni facilitano la comprensione, riducendo la possibilità di distorsioni o interpretazioni errate.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#bibliografia",
    "href": "chapters/eda/06_data_visualization.html#bibliografia",
    "title": "17  Principi della visualizzazione dei dati",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nButler, R. C. (2022). Popularity leads to bad habits: Alternatives to «the statistics» routine of significance,«alphabet soup» and dynamite plots. In Annals of Applied Biology (Fasc. 2; Vol. 180, pp. 182–195). Wiley Online Library.\n\n\nHealy, K. (2018). Data visualization: a practical introduction. Princeton University Press.\n\n\nWest, R. M. (2022). Best practice in statistics: The use of log transformation. Annals of Clinical Biochemistry, 59(3), 162–165.\n\n\nWickham, H., Çetinkaya-Rundel, M., & Grolemund, G. (2023). R for data science. \"O’Reilly Media, Inc.\".\n\n\nWilke, C. O. (2019). Fundamentals of data visualization: a primer on making informative and compelling figures. O’Reilly Media.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html",
    "href": "chapters/eda/07_loc_scale.html",
    "title": "18  Indicatori di tendenza centrale e variabilità",
    "section": "",
    "text": "18.1 Introduzione\nLa visualizzazione grafica dei dati rappresenta il pilastro fondamentale di ogni analisi quantitativa. Grazie alle rappresentazioni grafiche adeguate, è possibile individuare importanti caratteristiche di una distribuzione, quali la simmetria o l’asimmetria, nonché la presenza di una o più mode. Successivamente, al fine di descrivere sinteticamente le principali caratteristiche dei dati, si rende necessario l’utilizzo di specifici indici numerici. In questo capitolo, verranno presentati i principali indicatori della statistica descrittiva.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#indici-di-tendenza-centrale",
    "href": "chapters/eda/07_loc_scale.html#indici-di-tendenza-centrale",
    "title": "18  Indicatori di tendenza centrale e variabilità",
    "section": "18.2 Indici di Tendenza Centrale",
    "text": "18.2 Indici di Tendenza Centrale\nGli indici di tendenza centrale sono misure statistiche che cercano di rappresentare un valore tipico o centrale all’interno di un insieme di dati. Sono utilizzati per ottenere una comprensione immediata della distribuzione dei dati senza dover analizzare l’intero insieme. Gli indici di tendenza centrale sono fondamentali nell’analisi statistica, in quanto forniscono una sintesi semplice e comprensibile delle caratteristiche principali di un insieme di dati. I principali indici di tendenza centrale sono:\n\nMedia: La media è la somma di tutti i valori divisa per il numero totale di valori. È spesso utilizzata come misura generale di tendenza centrale, ma è sensibile agli estremi (valori molto alti o molto bassi).\nMediana: La mediana è il valore che divide l’insieme di dati in due parti uguali. A differenza della media, non è influenzata da valori estremi ed è quindi più robusta in presenza di outlier.\nModa: La moda è il valore che appare più frequentemente in un insieme di dati. In alcuni casi, può non essere presente o esserci più di una moda.\n\nLa scelta dell’indice di tendenza centrale appropriato dipende dalla natura dei dati e dall’obiettivo dell’analisi. Ad esempio, la mediana potrebbe essere preferita alla media se l’insieme di dati contiene valori anomali che potrebbero distorcere la rappresentazione centrale. La conoscenza e l’applicazione corretta di questi indici possono fornire una preziosa intuizione sulle caratteristiche centrali di una distribuzione di dati.\n\n18.2.1 Media\nLa media aritmetica di un insieme di valori rappresenta il punto centrale o il baricentro della distribuzione dei dati. È calcolata come la somma di tutti i valori divisa per il numero totale di valori, ed è espressa dalla formula:\n\\[\n\\bar{x}=\\frac{1}{n}\\sum_{i=1}^n x_i,\n\\tag{18.1}\\]\ndove \\(x_i\\) rappresenta i valori nell’insieme, \\(n\\) è il numero totale di valori, e \\(\\sum\\) indica la sommatoria.\n\n18.2.1.1 Proprietà della Media\nUna proprietà fondamentale della media è che la somma degli scarti di ciascun valore dalla media è zero:\n\\[\n\\sum_{i=1}^n (x_i - \\bar{x}) = 0.\\notag\n\\tag{18.2}\\]\nInfatti,\n\\[\n\\begin{aligned}\n\\sum_{i=1}^n (x_i - \\bar{x}) &= \\sum_i x_i - \\sum_i \\bar{x}\\notag\\\\\n&= \\sum_i x_i - n \\bar{x}\\notag\\\\\n&= \\sum_i x_i - \\sum_i x_i = 0.\\notag\n\\end{aligned}\n\\]\nQuesta proprietà implica che i dati sono equamente distribuiti intorno alla media.\n\n\n18.2.1.2 La media come Centro di Gravità dell’Istogramma\nLa media aritmetica può essere interpretata come il centro di gravità o il punto di equilibrio della distribuzione dei dati. In termini fisici, il centro di gravità è il punto in cui la massa di un sistema è equilibrata o concentrata.\nIn termini statistici, possiamo considerare la media come il punto in cui la distribuzione dei dati è in equilibrio. Ogni valore dell’insieme di dati può essere visto come un punto materiale con una massa proporzionale al suo valore. Se immaginiamo questi punti disposti su una linea, con valori più grandi a destra e più piccoli a sinistra, la media corrisponderà esattamente al punto in cui la distribuzione sarebbe in equilibrio.\n\n\n18.2.1.3 Principio dei Minimi Quadrati\nLa posizione della media minimizza la somma delle distanze quadrate dai dati, un principio noto come “metodo dei minimi quadrati”. Matematicamente, questo si traduce nel fatto che la somma dei quadrati degli scarti tra ciascun valore e la media è minima. Questo principio è alla base dell’analisi statistica dei modelli di regressione e conferma l’interpretazione della media come centro di gravità dell’istogramma.\n\n\n18.2.1.4 Calcolo della Media con R\nPer calcolare la media di un piccolo numero di valori in Python, possiamo utilizzare la somma di questi valori e dividerla per il numero totale di elementi. Consideriamo ad esempio i valori 12, 44, 21, 62, 24:\n\n(12 + 44 + 21 + 62 + 24) / 5\n#&gt; [1] 32.6\n\novvero\n\nx &lt;- c(12, 44, 21, 62, 24)\nmean(x)\n#&gt; [1] 32.6\n\n\n\n18.2.1.5 Le Proporzioni Sono Medie\nSe una collezione consiste solo di uni e zeri, allora la somma della collezione è il numero di uni in essa, e la media della collezione è la proporzione di uni.\n\nzero_one &lt;- c(1, 1, 1, 0)\nresult &lt;- mean(zero_one)\nresult\n#&gt; [1] 0.75\n\nÈ possibile sostituire 1 con il valore booleano True e 0 con False:\n\nmean(c(TRUE, TRUE, TRUE, FALSE))\n#&gt; [1] 0.75\n\n\n\n18.2.1.6 Limiti della Media Aritmetica\nLa media aritmetica, tuttavia, ha alcune limitazioni: non sempre è l’indice più adeguato per descrivere accuratamente la tendenza centrale della distribuzione, specialmente quando si verificano asimmetrie o valori anomali (outlier). In queste situazioni, è più indicato utilizzare la mediana o la media spuntata (come spiegheremo successivamente).\n\n\n18.2.1.7 Medie per Gruppi\nMolto spesso però i nostri dati sono contenuti in file e inserire i dati manualmente non è fattibile. Per fare un esempio, considereremo i dati del Progetto STAR, contenuti nel file STAR.csv, che rappresentano un’importante indagine sulle prestazioni degli studenti in relazione alla dimensione delle classi. Negli anni ’80, i legislatori del Tennessee considerarono la possibilità di ridurre le dimensioni delle classi per migliorare il rendimento degli studenti. Al fine di prendere decisioni informate, commissionarono lo studio multimilionario “Progetto Student-Teacher Achievement Ratio” (Project STAR). Lo studio coinvolgeva bambini della scuola materna assegnati casualmente a classi piccole, con 13-17 studenti, o classi di dimensioni regolari, con 22-25 studenti, fino alla fine della terza elementare. I ricercatori hanno seguito il progresso degli studenti nel tempo, concentrandosi su variabili di risultato, come i punteggi dei test standardizzati di lettura (reading) e matematica (math) alla terza elementare, oltre ai tassi di diploma di scuola superiore (graduated, con valore 1 per sì e 0 per no).\nPoniamoci il problema di calcolare la media dei punteggi math calcolata separatamente per i due gruppi di studenti: coloro che hanno completato la scuola superiore e coloro che non l’hanno completata.\nProcediamo all’importazione dei dati per iniziare l’analisi.\n\ndf &lt;- rio::import(here::here(\"data\", \"STAR.csv\"))\ndf |&gt; \n  head()\n#&gt;   classtype reading math graduated\n#&gt; 1     small     578  610         1\n#&gt; 2   regular     612  612         1\n#&gt; 3   regular     583  606         1\n#&gt; 4     small     661  648         1\n#&gt; 5     small     614  636         1\n#&gt; 6   regular     610  603         0\n\nEsaminiamo la numerosità di ciascun gruppo.\n\ndf |&gt; \n  group_by(graduated) |&gt; \n  summarize(count = n())\n#&gt; # A tibble: 2 × 2\n#&gt;   graduated count\n#&gt;       &lt;int&gt; &lt;int&gt;\n#&gt; 1         0   166\n#&gt; 2         1  1108\n\nOra procediamo al calcolo delle medie dei punteggi math all’interno dei due gruppi. Per rendere la risposta più concisa, useremo la funzione round() per stampare solo 2 valori decimali.\n\ndf |&gt; \n  group_by(graduated) |&gt; \n  summarise(\n    mean_math = round(mean(math, na.rm = TRUE), 2)\n  )\n#&gt; # A tibble: 2 × 2\n#&gt;   graduated mean_math\n#&gt;       &lt;int&gt;     &lt;dbl&gt;\n#&gt; 1         0      607.\n#&gt; 2         1      635.\n\n\n\n\n18.2.2 Media Spuntata\nLa media spuntata, indicata come \\(\\bar{x}_t\\) o trimmed mean, è un metodo di calcolo della media che prevede l’eliminazione di una determinata percentuale di dati estremi prima di effettuare la media aritmetica. Solitamente, viene eliminato il 10% dei dati, ovvero il 5% all’inizio e alla fine della distribuzione. Per ottenere la media spuntata, i dati vengono ordinati in modo crescente, \\(x_1 \\leq x_2 \\leq x_3 \\leq \\dots \\leq x_n\\), e quindi viene eliminato il primo 5% e l’ultimo 5% dei dati nella sequenza ordinata. Infine, la media spuntata è calcolata come la media aritmetica dei dati rimanenti. Questo approccio è utile quando ci sono valori anomali o quando la distribuzione è asimmetrica e la media aritmetica non rappresenta adeguatamente la tendenza centrale dei dati.\nA titolo di esempio, procediamo al calcolo della media spuntata dei valori math per i due gruppi definiti dalla variabile graduated, escludendo il 10% dei valori più estremi.\n\nglimpse(df)\n#&gt; Rows: 1,274\n#&gt; Columns: 4\n#&gt; $ classtype &lt;chr&gt; \"small\", \"regular\", \"regular\", \"small\", \"small\", \"regular…\n#&gt; $ reading   &lt;int&gt; 578, 612, 583, 661, 614, 610, 595, 665, 616, 624, 593, 59…\n#&gt; $ math      &lt;int&gt; 610, 612, 606, 648, 636, 603, 610, 631, 636, 626, 601, 56…\n#&gt; $ graduated &lt;int&gt; 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, …\n\n\nnot_graduated &lt;- df[df$graduated == 0, \"math\"]\nmean(not_graduated, trim = 0.10, na.rm = TRUE)\n#&gt; [1] 606\n\n\nnot_graduated &lt;- df[df$graduated == 1, \"math\"]\nmean(not_graduated, trim = 0.10, na.rm = TRUE)\n#&gt; [1] 634\n\n\n\n18.2.3 Quantili\nIl quantile non interpolato di ordine \\(p\\) \\((0 &lt; p &lt; 1)\\) rappresenta il valore che divide la distribuzione dei dati in modo tale che una frazione \\(p\\) dei dati si trovi al di sotto di esso.\nLa formula per calcolare il quantile non interpolato è la seguente:\n\\[\n    q_p = x_{(k)},\n\\]\ndove \\(x_{(k)}\\) è l’elemento \\(k\\)-esimo nell’insieme di dati ordinato in modo crescente, e \\(k\\) è calcolato come:\n\\[\nk = \\lceil p \\cdot n \\rceil,\n\\]\ndove \\(n\\) è il numero totale di dati nel campione, e \\(\\lceil \\cdot \\rceil\\) rappresenta la funzione di arrotondamento all’intero successivo. In questa definizione, il quantile non interpolato corrisponde al valore effettivo nell’insieme di dati, senza effettuare alcuna interpolazione tra i valori circostanti.\nAd esempio, consideriamo il seguente insieme di dati: \\(\\{ 15, 20, 23, 25, 28, 30, 35, 40, 45, 50 \\}\\). Supponiamo di voler calcolare il quantile non interpolato di ordine \\(p = 0.3\\) (cioè il 30° percentile).\nOrdiniamo i dati in modo crescente: \\(\\{ 15, 20, 23, 25, 28, 30, 35, 40, 45, 50 \\}.\\) Calcoliamo \\(k\\) utilizzando la formula \\(k = \\lceil p \\cdot n \\rceil\\), dove \\(n\\) è il numero totale di dati nel campione. Nel nostro caso, \\(n = 10\\) e \\(p = 0.3\\):\n\\[\nk = \\lceil 0.3 \\cdot 10 \\rceil = \\lceil 3 \\rceil = 3.\n\\]\nIl quantile non interpolato corrisponde al valore \\(x_{(k)}\\), ovvero l’elemento \\(k\\)-esimo nell’insieme ordinato: \\(q_{0.3} = x_{(3)} = 23.\\)\nOltre al quantile non interpolato, esiste anche il concetto di quantile interpolato. A differenza del quantile non interpolato, il quantile interpolato può essere calcolato anche per percentili che non corrispondono esattamente a valori presenti nell’insieme di dati. Per ottenere il valore del quantile interpolato, viene utilizzato un procedimento di interpolazione lineare tra i valori adiacenti. In genere, il calcolo del quantile interpolato viene eseguito mediante l’uso di software dedicati.\nOra, procediamo al calcolo dei quantili di ordine 0.10 e 0.90 per i valori math all’interno dei due gruppi. I quantili sono dei valori che dividono la distribuzione dei dati in parti specifiche. Ad esempio, il quantile di ordine 0.10 corrisponde al valore al di sotto del quale si trova il 10% dei dati, mentre il quantile di ordine 0.90 rappresenta il valore al di sotto del quale si trova il 90% dei dati.\nCalcoliamo i quantili di ordine 0.1 e 0.9 della distribuzione dei punteggi math nei due gruppi definiti dalla variabile graduated.\n\n# Quantili di ordine 0.1 e 0.9 per il gruppo di studenti che hanno completato \n# la scuola superiore\nquantile(df[df$graduated == 1, \"math\"], probs = c(0.1, 0.9))\n#&gt; 10% 90% \n#&gt; 588 684\n\n\n# Quantili di ordine 0.1 e 0.9 per il gruppo di studenti che non hanno \n# completato la scuola superiore\nquantile(df[df$graduated == 0, \"math\"], probs = c(0.1, 0.9))\n#&gt; 10% 90% \n#&gt; 564 651\n\n\n\n18.2.4 Moda e Mediana\nIn precedenza abbiamo già incontrato altri due popolari indici di tendenza centrale: la moda (Mo), che rappresenta il valore centrale della classe con la frequenza massima (in alcune distribuzioni può esserci più di una moda, rendendola multimodale e facendo perdere a questo indice il suo significato di indicatore di tendenza centrale); e la mediana (\\(\\tilde{x}\\)), che rappresenta il valore corrispondente al quantile di ordine 0.5 della distribuzione.\n\n\n18.2.5 Quando Usare Media, Moda, Mediana\nLa moda può essere utilizzata per dati a livello nominale o ordinale ed è l’unica tra le tre statistiche che può essere calcolata in questi casi.\nLa media, d’altra parte, è una buona misura di tendenza centrale solo se la distribuzione dei dati è simmetrica, ossia se i valori sono distribuiti uniformemente a sinistra e a destra della media. Tuttavia, se ci sono valori anomali o se la distribuzione è asimmetrica, la media può essere influenzata in modo significativo e, pertanto, potrebbe non essere la scelta migliore come misura di tendenza centrale.\nIn queste situazioni, la mediana può fornire una misura migliore di tendenza centrale rispetto alla media poiché è meno influenzata dai valori anomali e si basa esclusivamente sul valore centrale dell’insieme di dati. Di conseguenza, la scelta tra media e mediana dipende dal tipo di distribuzione dei dati e dagli obiettivi dell’analisi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#indici-di-dispersione",
    "href": "chapters/eda/07_loc_scale.html#indici-di-dispersione",
    "title": "18  Indicatori di tendenza centrale e variabilità",
    "section": "18.3 Indici di Dispersione",
    "text": "18.3 Indici di Dispersione\nLe misure di posizione descritte in precedenza, come le medie e gli indici di posizione, offrono una sintesi dei dati mettendo in evidenza la tendenza centrale delle osservazioni. Tuttavia, trascurano un aspetto importante della distribuzione dei dati: la variabilità dei valori numerici della variabile statistica. Pertanto, è essenziale completare la descrizione della distribuzione di una variabile statistica utilizzando anche indicatori che valutino la dispersione delle unità statistiche. In questo modo, otterremo una visione più completa e approfondita delle caratteristiche del campione analizzato.\n\n18.3.1 Indici Basati sull’Ordinamento dei Dati\nPer valutare la variabilità dei dati, è possibile utilizzare indici basati sull’ordinamento dei dati. L’indice più semplice è l’intervallo di variazione, che corrisponde alla differenza tra il valore massimo e il valore minimo di una distribuzione di dati. Tuttavia, questo indice ha il limite di essere calcolato basandosi solo su due valori della distribuzione, e non tiene conto di tutte le informazioni disponibili. Inoltre, l’intervallo di variazione può essere fortemente influenzato dalla presenza di valori anomali.\nUn altro indice basato sull’ordinamento dei dati è la differenza interquartile, già incontrata in precedenza. Anche se questo indice utilizza più informazioni rispetto all’intervallo di variazione, presenta comunque il limite di essere calcolato basandosi solo su due valori della distribuzione, ossia il primo quartile \\(Q_1\\) e il terzo quartile \\(Q_3\\).\nPer valutare la variabilità in modo più completo, è necessario utilizzare altri indici di variabilità che tengano conto di tutti i dati disponibili. In questo modo, si otterrà una valutazione più accurata della dispersione dei valori nella distribuzione e si potranno individuare eventuali pattern o tendenze nascoste.\n\n\n18.3.2 Varianza\nDate le limitazioni delle statistiche descritte in precedenza, è più comune utilizzare una misura di variabilità che tenga conto della dispersione dei dati rispetto a un indice di tendenza centrale. La varianza è la misura di variabilità più utilizzata per valutare la variabilità di una variabile statistica. Essa è definita come la media dei quadrati degli scarti \\(x_i - \\bar{x}\\) tra ogni valore e la media della distribuzione, come segue:\n\\[\n\\begin{equation}\nS^2 = \\frac{1}{n} \\sum_{i=1}^n (x_i - \\bar{x})^2.\n\\end{equation}\n\\tag{18.3}\\]\nLa varianza è una misura di dispersione più completa rispetto a quelle descritte in precedenza. Tuttavia, è appropriata solo nel caso di distribuzioni simmetriche ed è fortemente influenzata dai valori anomali, come altre misure di dispersione. Inoltre, la varianza è espressa in un’unità di misura che è il quadrato dell’unità di misura dei dati originali, pertanto, potrebbe non essere facilmente interpretata in modo intuitivo.\nCalcoliamo la varianza dei valori math per i dati del progetto STAR. Applicando l’equazione della varianza, otteniamo:\n\nsum((df$math - mean(df$math))^2) / length(df$math)\n#&gt; [1] 1507\n\nPiù semplicemente, possiamo usare la funzione var():\n\nvar(df$math) * (length(df$math) -1) / length(df$math)\n#&gt; [1] 1507\n\n\n18.3.2.1 Stima della Varianza della Popolazione\nSi noti il denominatore della formula della varianza. Nell’Equazione 18.3, ho utilizzato \\(n\\) come denominatore (l’ampiezza campionaria, ovvero il numero di osservazioni nel campione). In questo modo, otteniamo la varianza come statistica descrittiva del campione. Tuttavia, è possibile utilizzare \\(n-1\\) come denominatore alternativo:\n\\[\n\\begin{equation}\ns^2 = \\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\bar{x})^2\n\\end{equation}\n\\tag{18.4}\\]\nIn questo secondo caso, otteniamo la varianza come stimatore della varianza della popolazione. Si può dimostrare che l’Equazione 18.4 fornisce una stima corretta (ovvero, non distorta) della varianza della popolazione da cui abbiamo ottenuto il campione, mentre l’Equazione 18.3 fornisce (in media) una stima troppo piccola della varianza della popolazione. Si presti attenzione alla notazione: \\(S^2\\) rappresenta la varianza come statistica descrittiva, mentre \\(s^2\\) rappresenta la varianza come stimatore.\nPer illustrare questo punto, svolgiamo una simulazione. Consideriamo la distribuzione dei punteggi del quoziente di intelligenza (QI). I valori del QI seguono una particolare distribuzione chiamata distribuzione normale, con media 100 e deviazione standard 15. La forma di questa distribuzione è illustrata nella figura seguente.\n\n# Define parameters\nx &lt;- seq(100 - 4 * 15, 100 + 4 * 15, by = 0.001)\nmu &lt;- 100\nsigma &lt;- 15\n\n# Compute the PDF\npdf &lt;- dnorm(x, mean = mu, sd = sigma)\n\n# Plot using ggplot2\ndata &lt;- tibble(x = x, pdf = pdf)\nggplot(data, aes(x = x, y = pdf)) +\n  geom_line() +\n  labs(\n    x = \"QI\", \n    y = \"Densità\", \n    title = \"Distribuzione del QI nella popolazione\"\n  ) \n\n\n\n\n\n\n\n\nSupponiamo di estrarre un campione casuale di 4 osservazioni dalla popolazione del quoziente di intelligenza – in altre parole, supponiamo di misurare il quoziente di intelligenza di 4 persone prese a caso dalla popolazione.\n\nset.seed(123) \nx &lt;- rnorm(4, mean = 100, sd = 15)\nprint(x)\n#&gt; [1]  91.6  96.5 123.4 101.1\n\nCalcoliamo la varianza usando \\(n\\) al denominatore. Si noti che la vera varianza del quoziente di intelligenza è \\(15^2\\) = 225.\n\nvar(x)\n#&gt; [1] 197\n\nConsideriamo ora 10 campioni casuali del QI, ciascuno di ampiezza 4.\n\nmu &lt;- 100\nsigma &lt;- 15\nsize &lt;- 4\nniter &lt;- 10\nrandom_samples &lt;- list()\n\nset.seed(123) \n\nfor (i in 1:niter) {\n  one_sample &lt;- rnorm(size, mean = mu, sd = sigma)\n  random_samples[[i]] &lt;- one_sample\n}\n\nIl primo campione è\n\nrandom_samples[1]\n#&gt; [[1]]\n#&gt; [1]  91.6  96.5 123.4 101.1\n\nIl decimo campione è\n\nrandom_samples[10]\n#&gt; [[1]]\n#&gt; [1] 108.3  99.1  95.4  94.3\n\nStampiamo i valori di tutti i 10 campioni.\n\nrs &lt;- do.call(rbind, random_samples)\nrs\n#&gt;        [,1]  [,2]  [,3]  [,4]\n#&gt;  [1,]  91.6  96.5 123.4 101.1\n#&gt;  [2,] 101.9 125.7 106.9  81.0\n#&gt;  [3,]  89.7  93.3 118.4 105.4\n#&gt;  [4,] 106.0 101.7  91.7 126.8\n#&gt;  [5,] 107.5  70.5 110.5  92.9\n#&gt;  [6,]  84.0  96.7  84.6  89.1\n#&gt;  [7,]  90.6  74.7 112.6 102.3\n#&gt;  [8,]  82.9 118.8 106.4  95.6\n#&gt;  [9,] 113.4 113.2 112.3 110.3\n#&gt; [10,] 108.3  99.1  95.4  94.3\n\nPer ciascun campione (ovvero, per ciascuna riga della matrice precedente), calcoliamo la varianza usando la formula con \\(n\\) al denominatore. Otteniamo così 10 stime della varianza della popolazione del QI.\n\nx_var &lt;- apply(rs, 1, var)  # Applica la funzione var su ciascuna riga\nprint(x_var)\n#&gt;  [1] 196.94 337.54 168.55 218.68 333.48  34.52 264.38 234.08   1.97  40.47\n\nNotiamo due cose:\n\nle stime sono molto diverse tra loro; questo fenomeno è noto con il nome di variabilità campionaria;\nin media le stime sono troppo piccole.\n\nPer aumentare la sicurezza riguardo al secondo punto menzionato in precedenza, ripeteremo la simulazione utilizzando un numero di iterazioni maggiore.\n\nmu &lt;- 100\nsigma &lt;- 15\nsize &lt;- 4\nniter &lt;- 10000\nrandom_samples &lt;- list()\n\nset.seed(123) # Replace 123 with your desired seed for reproducibility\n\nfor (i in 1:niter) {\n  one_sample &lt;- rnorm(size, mean = mu, sd = sigma)\n  random_samples[[i]] &lt;- one_sample\n}\n\nrs &lt;- do.call(rbind, random_samples)\nx_var &lt;- apply(rs, 1, var) * (size - 1) / size  # Adjust for population variance (ddof = 0)\n\nEsaminiamo la distribuzione dei valori ottenuti.\n\n# Create a data frame for plotting\ndata &lt;- data.frame(x_var = x_var)\n\n# Plot the histogram using ggplot2\nggplot(data, aes(x = x_var)) +\n  geom_histogram(alpha = 0.5, fill = \"blue\") +\n  labs(\n    x = \"Varianza\", \n    y = \"Frequenza\", \n    title = \"Varianza del QI in campioni di n = 4\"\n  )\n#&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nLa stima più verosimile della varianza del QI è dato dalla media di questa distribuzione.\n\nmean(x_var)\n#&gt; [1] 169\n\nSi noti che il nostro spospetto è stato confermato: il valore medio della stima della varianza ottenuta con l’Equazione 18.3 è troppo piccolo rispetto al valore corretto di \\(15^2 = 225\\).\nRipetiamo ora la simulazione usando la formula della varianza con \\(n-1\\) al denominatore.\n\nset.seed(123) \n\nmu &lt;- 100\nsigma &lt;- 15\nsize &lt;- 4\nniter &lt;- 10000\nrandom_samples &lt;- list()\n\nfor (i in 1:niter) {\n  one_sample &lt;- rnorm(size, mean = mu, sd = sigma)\n  random_samples[[i]] &lt;- one_sample\n}\n\nrs &lt;- do.call(rbind, random_samples)\nx_var &lt;- apply(rs, 1, var)  # ddof = 1 is default for var in R\n\nmean(x_var)\n#&gt; [1] 225\n\nNel secondo caso, se utilizziamo \\(n-1\\) come denominatore per calcolare la stima della varianza, il valore atteso di questa stima è molto vicino al valore corretto di 225. Se il numero di campioni fosse infinito, i due valori sarebbero identici.\nIn conclusione, le due formule della varianza hanno scopi diversi. La formula della varianza con \\(n\\) al denominatore viene utilizzata come statistica descrittiva per descrivere la variabilità di un particolare campione di osservazioni. D’altro canto, la formula della varianza con \\(n-1\\) al denominatore viene utilizzata come stimatore per ottenere la migliore stima della varianza della popolazione da cui quel campione è stato estratto.\n\n\n\n18.3.3 Deviazione standard\nPer interpretare la varianza in modo più intuitivo, si può calcolare la deviazione standard (o scarto quadratico medio o scarto tipo) prendendo la radice quadrata della varianza. La deviazione standard è espressa nell’unità di misura originaria dei dati, a differenza della varianza che è espressa nel quadrato dell’unità di misura dei dati. La deviazione standard fornisce una misura della dispersione dei dati attorno alla media, rendendo più facile la comprensione della variabilità dei dati.\nLa deviazione standard (o scarto quadratico medio, o scarto tipo) è definita come:\n\\[\ns^2 = \\sqrt{(n-1)^{-1} \\sum_{i=1}^n (x_i - \\bar{x})^2}.\n\\tag{18.5}\\]\nQuando tutte le osservazioni sono uguali, \\(s = 0\\), altrimenti \\(s &gt; 0\\).\n\n\n\n\n\n\nNota\n\n\n\nIl termine standard deviation è stato introdotto in statistica da Pearson nel 1894 assieme alla lettera greca \\(\\sigma\\) che lo rappresenta. Il termine italiano “deviazione standard” ne è la traduzione più utilizzata nel linguaggio comune; il termine dell’Ente Nazionale Italiano di Unificazione è tuttavia “scarto tipo”, definito come la radice quadrata positiva della varianza.\n\n\nLa deviazione standard \\(s\\) dovrebbe essere utilizzata solo quando la media è una misura appropriata per descrivere il centro della distribuzione, ad esempio nel caso di distribuzioni simmetriche. Tuttavia, è importante tener conto che, come la media \\(\\bar{x}\\), anche la deviazione standard è fortemente influenzata dalla presenza di dati anomali, ovvero pochi valori che si discostano notevolmente dalla media rispetto agli altri dati della distribuzione. In presenza di dati anomali, la deviazione standard può risultare ingannevole e non rappresentare accuratamente la variabilità complessiva della distribuzione. Pertanto, è fondamentale considerare attentamente il contesto e le caratteristiche dei dati prima di utilizzare la deviazione standard come misura di dispersione. In alcune situazioni, potrebbe essere più appropriato ricorrere a misure di dispersione robuste o ad altre statistiche descrittive per caratterizzare la variabilità dei dati in modo più accurato e affidabile.\nPer fare un esempio, calcoliamo la deviazione standard per i valori math del campione di dati del progetto STAR. Applicando l’Equazione 18.5, per tutto il campione abbiamo\n\nsd(df$math)\n#&gt; [1] 38.8\n\nPer ciascun gruppo, abbiamo:\n\ndf |&gt; \n  group_by(graduated) |&gt; \n  summarise(std_math = sd(math, na.rm = TRUE)) \n#&gt; # A tibble: 2 × 2\n#&gt;   graduated std_math\n#&gt;       &lt;int&gt;    &lt;dbl&gt;\n#&gt; 1         0     34.1\n#&gt; 2         1     38.1\n\n\n18.3.3.1 Interpretazione\nLa deviazione standard può essere interpretata in modo semplice: essa rappresenta la dispersione dei dati rispetto alla media aritmetica. È simile allo scarto semplice medio campionario, cioè alla media aritmetica dei valori assoluti degli scarti tra ciascuna osservazione e la media, anche se non è identica. La deviazione standard ci fornisce un’indicazione di quanto, in media, le singole osservazioni si discostino dal centro della distribuzione.\nPer verificare l’interpretazione della deviazione standard, utilizziamo i valori math del campione di dati del progetto STAR.\n\nsd(df$math)\n#&gt; [1] 38.8\n\nLa deviazione standard calcolata per questi dati è \\(\\approx 38.8\\). Questo valore ci indica che, in media, ogni osservazione si discosta di circa 38.8 punti dalla media aritmetica dei punteggi math. Maggiore è il valore della deviazione standard, maggiore è la dispersione dei dati attorno alla media, mentre un valore più piccolo indica che i dati sono più concentrati vicino alla media. La deviazione standard ci offre quindi una misura quantitativa della variabilità dei dati nella distribuzione.\nPer questi dati, lo scarto semplice medio campionario è\n\nmean(abs(df$math - mean(df$math, na.rm = TRUE)), na.rm = TRUE)\n#&gt; [1] 31\n\nSi noti che i due valori sono simili, ma non identici.\n\n\n\n18.3.4 Deviazione Mediana Assoluta\nUna misura robusta della dispersione statistica di un campione è la deviazione mediana assoluta (Median Absolute Deviation, MAD) definita come la mediana del valore assoluto delle deviazioni dei dati dalla mediana. Matematicamente, la formula per calcolare la MAD è:\n\\[\n\\text{MAD} = \\text{median} \\left( |X_i - \\text{median}(X)| \\right)\n\\tag{18.6}\\]\nLa deviazione mediana assoluta è particolarmente utile quando si affrontano distribuzioni con presenza di dati anomali o asimmetrie, poiché è meno influenzata da questi valori estremi rispetto alla deviazione standard.\nQuando i dati seguono una distribuzione gaussiana (normale), esiste una relazione specifica tra MAD e la deviazione standard (si veda il Capitolo {ref}cont-rv-distr-notebook). In una distribuzione normale, la MAD è proporzionale alla deviazione standard. La costante di proporzionalità dipende dalla forma esatta della distribuzione normale, ma in generale, la relazione è data da:\n\\[\n\\sigma \\approx k \\times \\text{MAD},\n\\]\ndove:\n\n\\(\\sigma\\) è la deviazione standard.\nMAD è la Mediana della Deviazione Assoluta.\n\\(k\\) è una costante che, per una distribuzione normale, è tipicamente presa come circa 1.4826.\n\nQuesta costante di 1.4826 è derivata dal fatto che, in una distribuzione normale, circa il 50% dei valori si trova entro 0.6745 deviazioni standard dalla media. Quindi, per convertire la MAD (basata sulla mediana) nella deviazione standard (basata sulla media), si usa il reciproco di 0.6745, che è approssimativamente 1.4826.\nLa formula completa per convertire la MAD in una stima della deviazione standard in una distribuzione normale è:\n\\[\n\\sigma \\approx 1.4826 \\times \\text{MAD}\n\\]\nQuesta relazione è utile per stimare la deviazione standard in modo più robusto, specialmente quando si sospetta la presenza di outlier o si ha a che fare con campioni piccoli. Di conseguenza, molti software restituiscono il valore MAD moltiplicato per questa costante per fornire un’indicazione più intuitiva della variabilità dei dati. Tuttavia, è importante notare che questa relazione si mantiene accurata solo per le distribuzioni che sono effettivamente normali. In presenza di distribuzioni fortemente asimmetriche o con elevati outlier, la deviazione standard e la MAD possono fornire indicazioni molto diverse sulla variabilità dei dati.\nPer verificare questo principio, calcoliamo la deviazione mediana assoluta dei valori math del campione di dati del progetto STAR.\n\n1.4826 * median(abs(df$math - median(df$math, na.rm = TRUE)), na.rm = TRUE)\n#&gt; [1] 41.5\n\nIn questo caso, la MAD per i punteggi di matematica è simile alla deviazione standard.\n\nsd(df$math)\n#&gt; [1] 38.8\n\nInfatti, la distribuzione dei punteggi math è approssimativamente gaussiana.\n\nggplot(df, aes(x = math)) +\n  geom_density(alpha = 0.5) +\n  labs(\n    x = \"math\", \n    y = \"Frequenza\", \n    title = \"Distribuzione dei Punteggi di Matematica\"\n  )\n\n\n\n\n\n\n\n\nVerifichiamo nuovamente il principio usando un campione di dati estratto da una popolazione normale. Usiamo, ad esempio, la distribuzione \\(\\mathcal{N}(100, 15)\\):\n\nset.seed(123) \nx &lt;- rnorm(10000, mean = 100, sd = 15)\n1.4826 * median(abs(x - median(x)))\n#&gt; [1] 14.9\n\n\n\n18.3.5 Quando Usare Deviazione Standard e MAD\nLa deviazione standard e la MAD sono entrambe misure di dispersione che forniscono informazioni su quanto i dati in un insieme si discostano dalla tendenza centrale. Tuttavia, ci sono alcune differenze tra le due misure e situazioni in cui può essere più appropriato utilizzare una rispetto all’altra.\n\nDeviazione standard: Questa misura è particolarmente utile per descrivere la dispersione dei dati in una distribuzione normale. La deviazione standard è una scelta appropriata se si vuole sapere quanto i dati sono distribuiti intorno alla media, o se si vuole confrontare la dispersione di due o più set di dati. Tuttavia, la deviazione standard è fortemente influenzata dalla presenza di dati anomali, e questo può rappresentare una limitazione in casi in cui sono presenti valori estremi nell’insieme di dati.\nDeviazione mediana assoluta (MAD): La MAD è meno sensibile ai valori anomali rispetto alla deviazione standard, il che la rende una scelta migliore quando ci sono valori anomali nell’insieme di dati. Inoltre, la MAD può essere una buona scelta quando si lavora con dati non normalmente distribuiti, poiché non assume una distribuzione specifica dei dati. La MAD è calcolata utilizzando la mediana e i valori assoluti delle deviazioni dei dati dalla mediana, il che la rende una misura robusta di dispersione.\n\nIn sintesi, se si sta lavorando con dati normalmente distribuiti, la deviazione standard è la misura di dispersione più appropriata. Se si lavora con dati non normalmente distribuiti o si hanno valori anomali nell’insieme di dati, la MAD può essere una scelta migliore. In ogni caso, la scelta tra le due misure dipende dal tipo di dati che si sta analizzando e dall’obiettivo dell’analisi.\n\n\n18.3.6 Indici di Variabilità Relativi\nA volte può essere necessario confrontare la variabilità di grandezze incommensurabili, ovvero di caratteri misurati con differenti unità di misura. In queste situazioni, le misure di variabilità descritte in precedenza diventano inadeguate poiché dipendono dall’unità di misura utilizzata. Per superare questo problema, si ricorre a specifici numeri adimensionali chiamati indici relativi di variabilità.\nIl più importante di questi indici è il coefficiente di variazione (\\(C_v\\)), definito come il rapporto tra la deviazione standard (\\(\\sigma\\)) e la media dei dati (\\(\\bar{x}\\)):\n\\[\nC_v = \\frac{\\sigma}{\\bar{x}}.\n\\tag{18.7}\\]\nIl coefficiente di variazione è un numero puro e permette di confrontare la variabilità di distribuzioni con unità di misura diverse.\nUn altro indice relativo di variabilità è la differenza interquartile rapportata a uno dei tre quartili (primo quartile, terzo quartile o mediana). Questo indice è definito come:\n\\[\n\\frac{x_{0.75} - x_{0.25}}{x_{0.25}}, \\qquad \\frac{x_{0.75} - x_{0.25}}{x_{0.75}}, \\qquad \\frac{x_{0.75} - x_{0.25}}{x_{0.50}}.\n\\]\nQuesti indici relativi di variabilità forniscono una misura adimensionale della dispersione dei dati, rendendo possibile il confronto tra grandezze con diverse unità di misura e facilitando l’analisi delle differenze di variabilità tra i dati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#la-fallacia-ergodica",
    "href": "chapters/eda/07_loc_scale.html#la-fallacia-ergodica",
    "title": "18  Indicatori di tendenza centrale e variabilità",
    "section": "18.4 La Fallacia Ergodica",
    "text": "18.4 La Fallacia Ergodica\nSebbene il concetto di “media” possa sembrare chiaro, ciò non implica che il suo utilizzo non presenti delle problematiche nell’ambito della pratica psicologica. Un aspetto su cui vale la pena soffermarsi è ciò che viene definito “fallacia ergodica”.\nIl concetto di “fallacia ergodica” (Speelman et al., 2024) si riferisce all’errore compiuto dai ricercatori quando assumono che le caratteristiche medie di un gruppo di individui possano essere applicate a ciascun individuo all’interno di quel gruppo, senza considerare le differenze individuali o le variazioni nel tempo. Questa fallacia emerge dalla pratica comune nella ricerca psicologica di raccogliere dati aggregati da gruppi di persone per stimare parametri della popolazione, al fine di confrontare comportamenti in condizioni diverse o esplorare associazioni tra diverse misurazioni della stessa persona.\nIl problema di questo approccio è che l’uso dei risultati basati sul gruppo per caratterizzare le caratteristiche degli individui o per estrapolare a persone simili a quelle del gruppo è ingiustificato, poiché le medie di gruppo possono fornire informazioni solo sui risultati collettivi, come la performance media del gruppo, e non consentono di fare affermazioni accurate sugli individui che compongono quel gruppo. La fallacia ergodica si basa sull’assunzione che per utilizzare legittimamente una statistica aggregata (ad esempio, la media) derivata da un gruppo per descrivere un individuo di quel gruppo, due condizioni devono essere soddisfatte: gli individui devono essere così simili da essere praticamente interscambiabili, e le caratteristiche degli individui devono essere temporalmente stabili.\nTuttavia, i fenomeni e i processi psicologici di interesse per i ricercatori sono per natura non uniformi tra gli individui e variabili nel tempo, sia all’interno degli individui che tra di loro. Di conseguenza, i risultati ottenuti dalla media di misure di comportamenti, cognizioni o stati emotivi di più individui non descrivono accuratamente nessuno di quegli individui in un dato momento, né possono tenere conto dei cambiamenti in quelle variabili per un individuo nel tempo.\nSpeelman et al. (2024) osservano che la stragrande maggioranza degli articoli che hanno analizzato include conclusioni nelle sezioni degli Abstract e/o delle Discussioni che implicano che i risultati trovati con dati aggregati di gruppo si applichino anche agli individui in quei gruppi e/o si applichino agli individui nella popolazione. Questa pratica riflette la fallacia ergodica, che consiste nell’assumere che i campioni siano sistemi ergodici quando non lo sono.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#riflessioni-conclusive",
    "href": "chapters/eda/07_loc_scale.html#riflessioni-conclusive",
    "title": "18  Indicatori di tendenza centrale e variabilità",
    "section": "18.5 Riflessioni Conclusive",
    "text": "18.5 Riflessioni Conclusive\nLe statistiche descrittive ci permettono di ottenere indicatori sintetici che riassumono i dati di una popolazione o di un campione estratto da essa. Questi indicatori includono misure di tendenza centrale, come la media, la mediana e la moda, che ci forniscono informazioni sulla posizione centrale dei dati rispetto alla distribuzione. Inoltre, ci sono gli indici di dispersione, come la deviazione standard e la varianza, che ci indicano quanto i dati si disperdono attorno alla tendenza centrale. Questi indici ci aiutano a comprendere quanto i valori si discostano dalla media, e quindi ci forniscono un’idea della variabilità dei dati. In conclusione, le statistiche descrittive ci offrono un quadro sintetico delle caratteristiche principali dei dati, consentendoci di comprendere meglio la loro distribuzione e variabilità.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/07_loc_scale.html#informazioni-sullambiente-di-sviluppo",
    "title": "18  Indicatori di tendenza centrale e variabilità",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] grid      stats     graphics  grDevices utils     datasets  methods  \n#&gt; [8] base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] vcd_1.4-13        MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2\n#&gt;  [5] ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0  \n#&gt;  [9] bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0      markdown_1.13    \n#&gt; [13] knitr_1.49        lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1    \n#&gt; [17] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#&gt; [21] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [25] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      xfun_0.49         htmlwidgets_1.6.4 rstatix_0.7.2    \n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    fansi_1.0.6       pacman_0.5.1     \n#&gt; [13] R.oo_1.27.0       pkgconfig_2.0.3   data.table_1.16.2 lifecycle_1.0.4  \n#&gt; [17] compiler_4.4.2    farver_2.1.2      munsell_0.5.1     mnormt_2.1.1     \n#&gt; [21] carData_3.0-5     httpuv_1.6.15     htmltools_0.5.8.1 Formula_1.2-5    \n#&gt; [25] car_3.1-3         pillar_1.9.0      later_1.4.1       R.utils_2.12.3   \n#&gt; [29] abind_1.4-8       nlme_3.1-166      mime_0.12         tidyselect_1.2.1 \n#&gt; [33] digest_0.6.37     stringi_1.8.4     labeling_0.4.3    rprojroot_2.0.4  \n#&gt; [37] fastmap_1.2.0     colorspace_2.1-1  cli_3.6.3         magrittr_2.0.3   \n#&gt; [41] utf8_1.2.4        broom_1.0.7       withr_3.0.2       promises_1.3.2   \n#&gt; [45] backports_1.5.0   timechange_0.3.0  rmarkdown_2.29    ggsignif_0.6.4   \n#&gt; [49] R.methodsS3_1.8.2 zoo_1.8-12        hms_1.1.3         shiny_1.9.1      \n#&gt; [53] evaluate_1.0.1    lmtest_0.9-40     miniUI_0.1.1.1    rlang_1.1.4      \n#&gt; [57] Rcpp_1.0.13-1     xtable_1.8-4      glue_1.8.0        jsonlite_1.8.9   \n#&gt; [61] R6_2.5.1",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#bibliografia",
    "href": "chapters/eda/07_loc_scale.html#bibliografia",
    "title": "18  Indicatori di tendenza centrale e variabilità",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nSpeelman, C. P., Parker, L., Rapley, B. J., & McGann, M. (2024). Most Psychological Researchers Assume Their Samples Are Ergodic: Evidence From a Year of Articles in Three Major Journals. Collabra: Psychology, 10(1).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html",
    "href": "chapters/eda/08_correlation.html",
    "title": "19  Relazioni tra variabili",
    "section": "",
    "text": "19.1 Introduzione\nNonostante sia un’operazione di base, l’analisi delle associazioni tra variabili rappresenta uno degli aspetti più controversi nell’ambito dell’analisi dei dati psicologici. Sebbene possa sembrare un passaggio naturale dopo l’analisi univariata, questo processo solleva numerose questioni metodologiche e concettuali.\nTradizionalmente, in psicologia, l’analisi delle associazioni tra variabili è stata considerata come l’obiettivo finale del processo di ricerca. Questa visione si basa sull’idea che la descrizione delle relazioni tra variabili fornisca una spiegazione esaustiva dei fenomeni psicologici. Tale approccio trova le sue radici storiche nel pensiero di Karl Pearson (1911), il quale sosteneva che la spiegazione scientifica si esaurisse una volta delineate le associazioni tra le variabili osservate:\nSebbene sia indubbio che rispondere alla seconda domanda posta da Pearson sia relativamente semplice, è altresì evidente che la nostra comprensione di un fenomeno non può dipendere unicamente dalle informazioni fornite dalle correlazioni.\nIn contrasto con questa visione tradizionale, la “Causal Revolution” propone un paradigma radicalmente diverso secondo il quale le associazioni tra variabili sono considerate come epifenomeni, mentre l’obiettivo principale della ricerca è l’identificazione e la comprensione delle relazioni causali: per comprendere veramente i fenomeni psicologici è essenziale indagare le cause sottostanti, andando oltre la mera descrizione delle associazioni.\nLa discussione dei metodi utilizzati per individuare le relazioni causali sarà trattata successivamente. In questo capitolo, ci concentreremo sui concetti statistici fondamentali necessari per descrivere le associazioni lineari tra variabili. È importante sottolineare che, sebbene esistano indici statistici per quantificare associazioni non lineari, la maggior parte degli psicologi si limita all’utilizzo di indici lineari.\nNel linguaggio comune, termini come “dipendenza”, “associazione” e “correlazione” vengono spesso usati in modo intercambiabile. Tuttavia, da un punto di vista tecnico, è importante distinguere questi concetti:\nÈ cruciale comprendere che non tutte le associazioni sono correlazioni e, soprattutto, che la correlazione non implica necessariamente causalità. Questa distinzione è fondamentale per interpretare correttamente i dati e evitare conclusioni errate sulle relazioni tra variabili.\nIn questo capitolo, esamineremo due misure statistiche fondamentali per valutare la relazione lineare tra due variabili: la covarianza e la correlazione. Questi indici ci permettono di descrivere il grado e la direzione dell’associazione lineare tra variabili, quantificando come queste variano congiuntamente.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#introduzione",
    "href": "chapters/eda/08_correlation.html#introduzione",
    "title": "19  Relazioni tra variabili",
    "section": "",
    "text": "Quanto spesso, quando è stato osservato un nuovo fenomeno, sentiamo che viene posta la domanda: ‘qual è la sua causa?’. Questa è una domanda a cui potrebbe essere assolutamente impossibile rispondere. Invece, può essere più facile rispondere alla domanda: ‘in che misura altri fenomeni sono associati con esso?’. Dalla risposta a questa seconda domanda possono risultare molte preziose conoscenze.\n\n\n\n\n\n\nAssociazione: questo termine indica una relazione generale tra variabili, dove la conoscenza del valore di una variabile fornisce informazioni su un’altra.\nCorrelazione: descrive una relazione specifica e quantificabile, indicando se due variabili tendono a variare insieme in modo sistematico. Ad esempio, in una correlazione positiva, se \\(X &gt; \\mu_X\\), è probabile che anche \\(Y &gt; \\mu_Y\\). La correlazione specifica il segno e l’intensità di una relazione lineare.\nDipendenza: indica una relazione causale tra le variabili, dove la variazione della variabile causale porta probabilisticamente alla variazione della variabile dipendente.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#i-dati-grezzi",
    "href": "chapters/eda/08_correlation.html#i-dati-grezzi",
    "title": "19  Relazioni tra variabili",
    "section": "19.2 I dati grezzi",
    "text": "19.2 I dati grezzi\nPer illustrare la correlazione e la covarianza, analizzeremo i dati raccolti da Zetsche et al. (2019) in uno studio che indaga le aspettative negative come meccanismo chiave nel mantenimento e nella reiterazione della depressione. Nello specifico, i ricercatori si sono proposti di determinare se gli individui depressi sviluppano aspettative accurate riguardo al loro umore futuro o se tali aspettative sono distortamente negative.\nUno dei loro studi ha coinvolto un campione di 30 soggetti con almeno un episodio depressivo maggiore, confrontati con un gruppo di controllo composto da 37 individui sani. La misurazione del livello di depressione è stata effettuata tramite il Beck Depression Inventory (BDI-II).\nIl BDI-II è uno strumento di autovalutazione utilizzato per valutare la gravità della depressione in adulti e adolescenti. Il test è stato sviluppato per identificare e misurare l’intensità dei sintomi depressivi sperimentati nelle ultime due settimane. I 21 item del test sono valutati su una scala a 4 punti, dove 0 rappresenta il grado più basso e 3 il grado più elevato di sintomatologia depressiva.\nNell’esercizio successivo, ci proponiamo di analizzare i punteggi di depressione BDI-II nel campione di dati fornito da Zetsche et al. (2019).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#definizione-delle-relazioni-tra-variabili",
    "href": "chapters/eda/08_correlation.html#definizione-delle-relazioni-tra-variabili",
    "title": "19  Relazioni tra variabili",
    "section": "19.3 Definizione delle relazioni tra variabili",
    "text": "19.3 Definizione delle relazioni tra variabili\nNel contesto delle indagini statistiche, spesso non ci limitiamo a esaminare la distribuzione di una singola variabile. Invece, il nostro interesse si concentra sulla relazione che emerge nei dati tra due o più variabili. Ma cosa significa esattamente quando diciamo che due variabili hanno una relazione?\nPer comprendere ciò, prendiamo ad esempio l’altezza e l’età tra un gruppo di bambini. In generale, è possibile notare che all’aumentare dell’età di un bambino, aumenta anche la sua altezza. Pertanto, conoscere l’età di un bambino, ad esempio tredici anni, e l’età di un altro, sei anni, ci fornisce un’indicazione su quale dei due bambini sia più alto.\nNel linguaggio statistico, definiamo questa relazione tra altezza e età come positiva, il che significa che all’aumentare dei valori di una delle variabili (in questo caso, l’età), ci aspettiamo di vedere valori più elevati anche nell’altra variabile (l’altezza). Tuttavia, esistono anche relazioni negative, in cui l’aumento di una variabile è associato a un diminuzione dell’altra (ad esempio, più età è correlata a meno pianto).\nNon si tratta solo di relazioni positive o negative; ci sono anche situazioni in cui le variabili non hanno alcuna relazione tra loro, definendo così una relazione nulla. Inoltre, le relazioni possono variare nel tempo, passando da positive a negative o da fortemente positive a appena positiva. In alcuni casi, una delle variabili può essere categorica, rendendo difficile parlare di “maggioranza” o “minoranza” ma piuttosto di “differente” (ad esempio, i bambini più grandi potrebbero semplicemente avere diverse preferenze rispetto ai bambini più piccoli, senza necessariamente essere “migliori” o “peggiori”).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#sec-scatter-plot",
    "href": "chapters/eda/08_correlation.html#sec-scatter-plot",
    "title": "19  Relazioni tra variabili",
    "section": "19.4 Grafico a dispersione",
    "text": "19.4 Grafico a dispersione\nIl metodo più diretto per visualizzare la relazione tra due variabili continue è tramite un grafico a dispersione, comunemente noto come “scatterplot”. Questo tipo di diagramma rappresenta le coppie di dati ottenute da due variabili, posizionandole sull’asse delle ascisse (orizzontale) e delle ordinate (verticale).\nPer rendere l’idea più chiara, consideriamo i dati dello studio condotto da Zetsche et al. (2019), in cui i ricercatori hanno utilizzato due scale psicometriche, il Beck Depression Inventory II (BDI-II) e la Center for Epidemiologic Studies Depression Scale (CES-D), per misurare il livello di depressione nei partecipanti. Il BDI-II è uno strumento di autovalutazione che valuta la presenza e l’intensità dei sintomi depressivi in pazienti adulti e adolescenti con diagnosi psichiatrica, mentre la CES-D è una scala di autovalutazione progettata per misurare i sintomi depressivi sperimentati nella settimana precedente nella popolazione generale, in particolare negli adolescenti e nei giovani adulti. Poiché entrambe le scale misurano lo stesso costrutto, ovvero la depressione, ci aspettiamo una relazione tra i punteggi ottenuti dal BDI-II e dalla CES-D. Un diagramma a dispersione ci consente di esaminare questa relazione in modo visuale e intuitivo.\n\n# Leggi i dati dal file CSV\ndf &lt;- rio::import(here::here(\"data\", \"data.mood.csv\"))\n\n# Seleziona le colonne di interesse\ndf &lt;- df |&gt;\n  dplyr::select(\"esm_id\", \"group\", \"bdi\", \"cesd_sum\")\n\n# Rimuovi le righe duplicate\ndf &lt;- df[!duplicated(df), ]\n\n# Rimuovi le righe con valori mancanti nella colonna \"bdi\"\ndf &lt;- df[!is.na(df$bdi), ]\n\nPosizionando i valori del BDI-II sull’asse delle ascisse e quelli del CES-D sull’asse delle ordinate, ogni punto sul grafico rappresenta un individuo, di cui conosciamo il livello di depressione misurato dalle due scale. È evidente che i valori delle scale BDI-II e CES-D non possono coincidere per due motivi principali: (1) la presenza di errori di misurazione e (2) l’utilizzo di unità di misura arbitrarie per le due variabili. L’errore di misurazione è una componente inevitabile che influisce in parte su qualsiasi misurazione, ed è particolarmente rilevante in psicologia, dove la precisione degli strumenti di misurazione è generalmente inferiore rispetto ad altre discipline, come la fisica. Il secondo motivo per cui i valori delle scale BDI-II e CES-D non possono essere identici è che l’unità di misura della depressione è una questione arbitraria e non standardizzata. Tuttavia, nonostante le differenze dovute agli errori di misurazione e all’uso di unità di misura diverse, ci aspettiamo che, se le due scale misurano lo stesso costrutto (la depressione), i valori prodotti dalle due scale dovrebbero essere associati linearmente tra di loro. Per comprendere meglio il concetto di “associazione lineare”, è possibile esaminare i dati attraverso l’utilizzo di un diagramma a dispersione.\n\n\n\n\n\n\n\n\n\nOsservando il grafico a dispersione, è evidente che i dati mostrano una tendenza a distribuirsi in modo approssimativamente lineare. In termini statistici, ciò suggerisce una relazione di associazione lineare tra i punteggi CES-D e BDI-II.\nTuttavia, è importante notare che la relazione lineare tra le due variabili è lontana dall’essere perfetta. In una relazione lineare perfetta, tutti i punti nel grafico sarebbero allineati in modo preciso lungo una retta. Nella realtà, la dispersione dei punti dal comportamento lineare ideale è evidente.\nDi conseguenza, sorge la necessità di quantificare numericamente la forza e la direzione della relazione lineare tra le due variabili e di misurare quanto i punti si discostino da una relazione lineare ideale. Esistono vari indici statistici a disposizione per raggiungere questo obiettivo.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#covarianza",
    "href": "chapters/eda/08_correlation.html#covarianza",
    "title": "19  Relazioni tra variabili",
    "section": "19.5 Covarianza",
    "text": "19.5 Covarianza\nIniziamo a considerare il più importante di tali indici, chiamato covarianza. In realtà la definizione di questo indice non ci sorprenderà più di tanto in quanto, in una forma solo apparentemente diversa, l’abbiamo già incontrata in precedenza. Ci ricordiamo infatti che la varianza di una generica variabile \\(X\\) è definita come la media degli scarti quadratici di ciascuna osservazione dalla media:\n\\[\nS_{XX} = \\frac{1}{n} \\sum_{i=1}^n(X_i - \\bar{X}) (X_i - \\bar{X}).\n\\]\nLa varianza viene talvolta descritta come la “covarianza di una variabile con sé stessa”. Adesso facciamo un passo ulteriore. Invece di valutare la dispersione di una sola variabile, ci chiediamo come due variabili \\(X\\) e \\(Y\\) “variano insieme” (co-variano). È facile capire come una risposta a tale domanda possa essere fornita da una semplice trasformazione della formula precedente che diventa:\n\\[\nS_{XY} = \\frac{1}{n} \\sum_{i=1}^n(X_i - \\bar{X}) (Y_i - \\bar{Y}).\n\\tag{19.1}\\]\nL’Equazione 19.1 ci fornisce la definizione della covarianza.\n\n19.5.1 Interpretazione\nPer capire il significato dell’Equazione 19.1, supponiamo di dividere il grafico riportato nella Sezione 19.4 in quattro quadranti definiti da una retta verticale passante per la media dei valori BDI-II e da una retta orizzontale passante per la media dei valori CES-D. Numeriamo i quadranti partendo da quello in basso a sinistra e muovendoci in senso antiorario.\nSe prevalgono punti nel I e III quadrante, allora la nuvola di punti avrà un andamento crescente (per cui a valori bassi di \\(X\\) tendono ad associarsi valori bassi di \\(Y\\) e a valori elevati di \\(X\\) tendono ad associarsi valori elevati di \\(Y\\)) e la covarianza avrà segno positivo. Mentre se prevalgono punti nel II e IV quadrante la nuvola di punti avrà un andamento decrescente (per cui a valori bassi di \\(X\\) tendono ad associarsi valori elevati di \\(Y\\) e a valori elevati di \\(X\\) tendono ad associarsi valori bassi di \\(Y\\)) e la covarianza avrà segno negativo. Dunque, il segno della covarianza ci informa sulla direzione della relazione lineare tra due variabili: l’associazione lineare si dice positiva se la covarianza è positiva, negativa se la covarianza è negativa.\nEsercizio. Implemento l’Equazione 19.1 in R.\n\ncov_value &lt;- function(x, y) {\n  mean_x &lt;- sum(x) / length(x)\n  mean_y &lt;- sum(y) / length(y)\n\n  sub_x &lt;- x - mean_x\n  sub_y &lt;- y - mean_y\n\n  sum_value &lt;- sum(sub_y * sub_x)\n  denom &lt;- length(x)\n\n  cov &lt;- sum_value / denom\n  return(cov)\n}\n\nPer i dati mostrati nel diagramma, la covarianza tra BDI-II e CESD è 207.4\n\nx &lt;- df$bdi\ny &lt;- df$cesd_sum\n\ncov_value(x, y)\n#&gt; [1] 207\n\nOppure, in maniera più semplice:\n\nmean((x - mean(x)) * (y - mean(y)))\n#&gt; [1] 207\n\nLo stesso risultato si ottiene con la funzione cov:\n\ncov(x, y) * (length(x) - 1) / length(x)\n#&gt; [1] 207\n\nLa funzione cov(x, y) calcola la covarianza tra due array, x e y utilizzando \\(n-1\\) al denominatore.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#correlazione",
    "href": "chapters/eda/08_correlation.html#correlazione",
    "title": "19  Relazioni tra variabili",
    "section": "19.6 Correlazione",
    "text": "19.6 Correlazione\nLa direzione della relazione tra le variabili è indicata dal segno della covarianza, ma il valore assoluto di questo indice non fornisce informazioni utili poiché dipende dall’unità di misura delle variabili. Ad esempio, considerando l’altezza e il peso delle persone, la covarianza sarà più grande se l’altezza è misurata in millimetri e il peso in grammi, rispetto al caso in cui l’altezza è in metri e il peso in chilogrammi. Pertanto, per descrivere la forza e la direzione della relazione lineare tra due variabili in modo adimensionale, si utilizza l’indice di correlazione.\nLa correlazione è ottenuta standardizzando la covarianza tramite la divisione delle deviazioni standard (\\(s_X\\), \\(s_Y\\)) delle due variabili:\n\\[\nr = \\frac{S_{XY}}{S_X S_Y}.\n\\tag{19.2}\\]\nLa quantità che si ottiene dall’Equazione 19.2 viene chiamata correlazione di Bravais-Pearson (dal nome degli autori che, indipendentemente l’uno dall’altro, l’hanno introdotta).\nIn maniera equivalente, per una lista di coppie di valori \\((x_1, y_1), \\dots, (x_n, y_n)\\), il coefficiente di correlazione è definito come la media del prodotto dei valori standardizzati:\n\\[\nr = \\frac{1}{n} \\sum_{i=1}^{n} \\left( \\frac{x_i - \\bar{x}}{\\sigma_x} \\right) \\left( \\frac{y_i - \\bar{y}}{\\sigma_y} \\right),\n\\tag{19.3}\\]\ndove \\(\\bar{x}\\) e \\(\\bar{y}\\) rappresentano, rispettivamente, le medie dei valori \\(x\\) e \\(y\\), e \\(\\sigma_x\\) e \\(\\sigma_y\\) sono le rispettive deviazioni standard.\nNell’Equazione 19.3, i valori \\(x_i\\) e \\(y_i\\) vengono prima standardizzati sottraendo la media e dividendo per la deviazione standard, e poi si calcola la media del prodotto di questi valori standardizzati.\n\n19.6.1 Proprietà\nIl coefficiente di correlazione ha le seguenti proprietà:\n\nha lo stesso segno della covarianza, dato che si ottiene dividendo la covarianza per due numeri positivi;\nè un numero puro, cioè non dipende dall’unità di misura delle variabili;\nassume valori compresi tra -1 e +1.\n\n\n\n19.6.2 Interpretazione\nAll’indice di correlazione possiamo assegnare la seguente interpretazione:\n\n\\(r_{XY} = -1\\) \\(\\rightarrow\\) perfetta relazione negativa: tutti i punti si trovano esattamente su una retta con pendenza negativa (dal quadrante in alto a sinistra al quadrante in basso a destra);\n\\(r_{XY} = +1\\) \\(\\rightarrow\\) perfetta relazione positiva: tutti i punti si trovano esattamente su una retta con pendenza positiva (dal quadrante in basso a sinistra al quadrante in alto a destra);\n\\(-1 &lt; r_{XY} &lt; +1\\) \\(\\rightarrow\\) presenza di una relazione lineare di intensità diversa;\n\\(r_{XY} = 0\\) \\(\\rightarrow\\) assenza di relazione lineare tra \\(X\\) e \\(Y\\).\n\nEsercizio. Per i dati riportati nel diagramma della sezione {ref}sec-zetsche-scatter, la covarianza è 207.4. Il segno positivo della covarianza ci dice che tra le due variabili c’è un’associazione lineare positiva. Per capire quale sia l’intensità della relazione lineare calcoliamo la correlazione. Essendo le deviazioni standard del BDI-II e del CES-D rispettavamente uguali a 15.37 e 14.93, la correlazione diventa uguale a \\(\\frac{207.426}{15.38 \\cdot 14.93} = 0.904.\\) Tale valore è prossimo a 1.0, il che vuol dire che i punti del diagramma a dispersione non si discostano troppo da una retta con una pendenza positiva.\nTroviamo la correlazione con la funzione corrcoef():\n\ncor(x, y)\n#&gt; [1] 0.904\n\nReplichiamo il risultato implementando l’eq. {eq}eq-cor-def:\n\ns_xy &lt;- mean((x - mean(x)) * (y - mean(y)))\ns_x &lt;- sqrt(mean((x - mean(x))^2)) # Deviazione standard popolazione\ns_y &lt;- sqrt(mean((y - mean(y))^2)) # Deviazione standard popolazione\nr_xy &lt;- s_xy / (s_x * s_y)\nprint(r_xy)\n#&gt; [1] 0.904\n\nUn altro modo ancora per trovare la correlazione tra i punteggi BDI-II e CESD è quello di applicare l’Equazione 19.3:\n\nz_x &lt;- (x - mean(x)) / sqrt(mean((x - mean(x))^2)) \n# Standardizzazione con deviazione standard popolazione\nz_y &lt;- (y - mean(y)) / sqrt(mean((y - mean(y))^2)) \n# Standardizzazione con deviazione standard popolazione\nmean(z_x * z_y)\n#&gt; [1] 0.904\n\nEsempio. Un uso interessante delle correlazioni viene fatto in un recente articolo di Guilbeault et al. (2024). Il concetto di “gender bias” si riferisce alla tendenza sistematica di favorire un sesso rispetto all’altro, spesso a scapito delle donne. Lo studio di Guilbeault et al. (2024) analizza come le immagini online influenzino la diffusione su vasta scala di questo preconcetto di genere.\nAttraverso un vasto insieme di immagini e testi raccolti online, gli autori dimostrano che sia le misurazioni basate sulle immagini che quelle basate sui testi catturano la frequenza con cui varie categorie sociali sono associate a rappresentazioni di genere, valutate su una scala da -1 (femminile) a 1 (maschile), con 0 che indica una neutralità di genere. Questo consente di quantificare il preconcetto di genere come una forma di bias statistico lungo tre dimensioni: la tendenza delle categorie sociali ad associarsi a un genere specifico nelle immagini e nei testi, la rappresentazione relativa delle donne rispetto agli uomini in tutte le categorie sociali nelle immagini e nei testi, e il confronto tra le associazioni di genere nei dati delle immagini e dei testi con la distribuzione empirica delle donne e degli uomini nella società. Il lavoro di Guilbeault et al. (2024) evidenzia che il preconcetto di genere è molto più evidente nelle immagini rispetto ai testi, come mostrato nella {numref}gender-bias-1-fig C.\nSi noti che, nel grafico della {numref}gender-bias-1-fig C, ogni punto può essere interpretato come una misura di correlazione. La misura utilizzata da Guilbeault et al. (2024) riflette il grado di associazione tra le categorie sociali e le rappresentazioni di genere presenti nelle immagini e nei testi analizzati. Quando la misura è vicina a +1, indica una forte associazione positiva tra una categoria sociale specifica e una rappresentazione di genere maschile, mentre un valore vicino a -1 indica una forte associazione negativa con una rappresentazione di genere femminile. Un valore di 0, invece, suggerisce che non vi è alcuna associazione tra la categoria sociale considerata e un genere specifico, indicando una sorta di neutralità di genere. In sostanza, questa misura di frequenza può essere interpretata come una correlazione che riflette la tendenza delle categorie sociali a essere rappresentate in un modo o nell’altro nelle immagini e nei testi analizzati, rispetto ai concetti di genere femminile e maschile.\n\n\n\nIl preconcetto di genere è più prevalente nelle immagini online (da Google Immagini) e nei testi online (da Google News). A. La correlazione tra le associazioni di genere nelle immagini da Google Immagini e nei testi da Google News per tutte le categorie sociali (n = 2.986), organizzate per decili. B. La forza dell’associazione di genere in queste immagini e testi online per tutte le categorie (n = 2.986), suddivisa in base al fatto che queste categorie siano inclinate verso il femminile o il maschile. C. Le associazioni di genere per un campione di occupazioni secondo queste immagini e testi online; questo campione è stato selezionato manualmente per evidenziare i tipi di categorie sociali e preconcetti di genere esaminati. (Figura tratta da Guilbeault et al. (2024)).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#correlazione-di-spearman",
    "href": "chapters/eda/08_correlation.html#correlazione-di-spearman",
    "title": "19  Relazioni tra variabili",
    "section": "19.7 Correlazione di Spearman",
    "text": "19.7 Correlazione di Spearman\nUn’alternativa per valutare la relazione lineare tra due variabili è il coefficiente di correlazione di Spearman, che si basa esclusivamente sull’ordine dei dati e non sugli specifici valori. Questo indice di associazione è particolarmente adatto quando gli psicologi sono in grado di misurare solo le relazioni di ordine tra diverse modalità di risposta dei soggetti, ma non l’intensità della risposta stessa. Tali variabili psicologiche che presentano questa caratteristica sono definite come “ordinali”.\n\n\n\n\n\n\nNota\n\n\n\nÈ importante ricordare che, nel caso di una variabile ordinale, non è possibile utilizzare le statistiche descrittive convenzionali come la media e la varianza per sintetizzare le osservazioni. Tuttavia, è possibile riassumere le osservazioni attraverso una distribuzione di frequenze delle diverse modalità di risposta. Come abbiamo appena visto, la direzione e l’intensità dell’associazione tra due variabili ordinali possono essere descritte utilizzando il coefficiente di correlazione di Spearman.\n\n\nPer fornire un esempio, consideriamo due variabili di scala ordinale e calcoliamo la correlazione di Spearman tra di esse.\n\ncor.test(c(1, 2, 3, 4, 5), c(5, 6, 7, 8, 7), method = \"spearman\")\n#&gt; Warning in cor.test.default(c(1, 2, 3, 4, 5), c(5, 6, 7, 8, 7), method =\n#&gt; \"spearman\"): Impossibile calcolare p-value esatti in presenza di ties\n#&gt; \n#&gt;  Spearman's rank correlation rho\n#&gt; \n#&gt; data:  c(1, 2, 3, 4, 5) and c(5, 6, 7, 8, 7)\n#&gt; S = 4, p-value = 0.09\n#&gt; alternative hypothesis: true rho is not equal to 0\n#&gt; sample estimates:\n#&gt;   rho \n#&gt; 0.821",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#oltre-la-correlazione-e-la-covarianza-quando-lassociazione-tra-variabili-è-più-complessa",
    "href": "chapters/eda/08_correlation.html#oltre-la-correlazione-e-la-covarianza-quando-lassociazione-tra-variabili-è-più-complessa",
    "title": "19  Relazioni tra variabili",
    "section": "19.8 Oltre la correlazione e la covarianza: quando l’associazione tra variabili è più complessa",
    "text": "19.8 Oltre la correlazione e la covarianza: quando l’associazione tra variabili è più complessa\nIn questo capitolo abbiamo introdotto due misure fondamentali per descrivere la relazione tra due variabili: covarianza e correlazione. La covarianza fornisce un’indicazione del modo in cui due variabili si discostano congiuntamente dalle proprie medie, mentre la correlazione ne standardizza i valori, permettendo un confronto più immediato tra diverse coppie di variabili e garantendo un indice compreso tra -1 e +1. Una correlazione vicina a +1 indica una forte relazione lineare positiva, vicina a -1 una forte relazione lineare negativa, mentre un valore vicino a 0 segnala l’assenza di una chiara relazione lineare.\nTuttavia, è cruciale comprendere che la correlazione descrive esclusivamente la dimensione lineare della relazione tra due variabili. Questo significa che una correlazione nulla (pari a zero) non implica affatto che non vi sia alcuna relazione tra le variabili, ma semplicemente che non esiste una relazione lineare. Possono esistere relazioni non lineari anche molto forti, non catturate da questo indice. Inoltre, altre situazioni possono trarre in inganno, come nei casi in cui i dati siano raggruppati in sottogruppi con proprietà differenti o siano frutto di particolari processi di selezione.\n\n19.8.1 Correlazione nulla e relazioni non lineari\nUna correlazione pari a zero può nascondere relazioni non lineari anche molto marcate. Per esempio, se una variabile Y aumenta solo quando X è molto alta o molto bassa, ma rimane costante per valori intermedi di X, questa curva a “U” può generare una correlazione vicina allo zero, pur esistendo un forte legame non lineare.\nUn esempio illustrativo è fornito dal cosiddetto Datasaurus Dozen, un insieme di tredici dataset con la stessa media, deviazione standard e correlazione tra le variabili, ma con distribuzioni visivamente e strutturalmente molto diverse. In ognuno di questi dataset la correlazione di Pearson è pari a zero, ma l’ispezione grafica rivela pattern e forme ben definite. Questo ci ricorda che è sempre bene accompagnare le misure numeriche con una visualizzazione grafica dei dati.\n\ndatasaurus_data &lt;- read.csv(\"../../data/datasaurus.csv\")\n\ndatasaurus_summary &lt;- datasaurus_data %&gt;%\n  group_by(dataset) %&gt;%\n  summarise(\n    x_count = n(),\n    x_mean = mean(x, na.rm = TRUE),\n    x_std = sd(x, na.rm = TRUE),\n    y_count = n(),\n    y_mean = mean(y, na.rm = TRUE),\n    y_std = sd(y, na.rm = TRUE)\n  )\n\ndatasaurus_summary\n#&gt; # A tibble: 13 × 7\n#&gt;   dataset  x_count x_mean x_std y_count y_mean y_std\n#&gt;   &lt;chr&gt;      &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 away         142   54.3  16.8     142   47.8  26.9\n#&gt; 2 bullseye     142   54.3  16.8     142   47.8  26.9\n#&gt; 3 circle       142   54.3  16.8     142   47.8  26.9\n#&gt; 4 dino         142   54.3  16.8     142   47.8  26.9\n#&gt; 5 dots         142   54.3  16.8     142   47.8  26.9\n#&gt; 6 h_lines      142   54.3  16.8     142   47.8  26.9\n#&gt; # ℹ 7 more rows\n\n\ndatasaurus_data |&gt;\n  ggplot(aes(x = x, y = y)) +\n  geom_point(alpha = 0.7) +\n  facet_wrap(~dataset, nrow = 4, ncol = 4) +\n  labs(x = NULL, y = NULL)\n\n\n\n\n\n\n\n\nTutti questi esempi rafforzano l’idea che l’assenza di correlazione lineare non significa assenza di relazione: potremmo avere strutture curve, pattern complessi o punti anomali (outlier) capaci di modificare radicalmente la forma della relazione tra le variabili.\nOltre alle relazioni non lineari, esistono situazioni in cui la correlazione, da sola, può fornire un’immagine distorta dei dati. Tra queste ricordiamo due fenomeni noti come il paradosso di Simpson e il paradosso di Berkson.\n\n\n19.8.2 Paradosso di Simpson\nIl paradosso di Simpson si verifica quando, guardando i dati raggruppati per sottogruppi, si osserva una certa relazione tra due variabili, ma aggregando i dati di tutti i sottogruppi insieme emerge una relazione opposta. In altre parole, la tendenza che appare quando si considerano i dati divisi per gruppi scompare o si inverte quando si esamina l’intero campione senza tenere conto della suddivisione in sottogruppi.\nImmaginiamo di avere due dipartimenti universitari, A e B. All’interno di ciascun dipartimento, la relazione tra il voto di laurea (X) e la performance in un successivo programma di specializzazione (Y) è positiva: all’aumentare del voto di laurea aumenta, in media, la performance nella scuola di specializzazione.\nTuttavia, supponiamo che il Dipartimento A abbia in generale voti di laurea mediamente più bassi, ma ottime performance nella specializzazione; mentre il Dipartimento B abbia voti di laurea mediamente più alti, ma performance alla specializzazione un po’ più basse. Se uniamo tutti gli studenti dei due dipartimenti senza considerarne l’appartenenza, potremmo osservare una relazione negativa tra voto di laurea e performance, sovvertendo le conclusioni tratte guardando ai singoli sottogruppi.\nEcco come possiamo simulare questi dati in R:\n\nset.seed(123)\n\n# Numero di osservazioni per dipartimento\nn &lt;- 100\n\n# Dipartimento A:\n# Voti di laurea (X) più bassi, ma performance (Y) più alta.\n# Creiamo un legame positivo tra X e Y all'interno di A.\nX_A &lt;- rnorm(n, mean = 50, sd = 5)    # Voti laurea mediamente più bassi\nY_A &lt;- X_A + rnorm(n, mean = 20, sd = 5) # Performance alta e correlata positivamente con X\n\n# Dipartimento B:\n# Voti di laurea (X) più alti, ma performance (Y) più bassa.\n# Anche qui creiamo un legame positivo tra X e Y all'interno di B, \n# ma con un offset tale che globalmente i voti alti coincidano con performance minori.\nX_B &lt;- rnorm(n, mean = 60, sd = 5)    # Voti laurea mediamente più alti\nY_B &lt;- X_B - rnorm(n, mean = 10, sd = 5) # Performance più bassa ma comunque correlata positivamente con X all’interno di B\n\n# Creiamo un dataframe con tutti i dati\ndipartimento &lt;- c(rep(\"A\", n), rep(\"B\", n))\nX &lt;- c(X_A, X_B)\nY &lt;- c(Y_A, Y_B)\ndati &lt;- data.frame(dipartimento, X, Y)\n\n# Correlazioni all'interno dei dipartimenti\ncat(\"Correlazione nel Dipartimento A:\", cor(X_A, Y_A), \"\\n\")\n#&gt; Correlazione nel Dipartimento A: 0.667\ncat(\"Correlazione nel Dipartimento B:\", cor(X_B, Y_B), \"\\n\")\n#&gt; Correlazione nel Dipartimento B: 0.693\n\n# Correlazione sull'intero dataset (senza distinguere i dipartimenti)\ncat(\"Correlazione globale:\", cor(X, Y), \"\\n\")\n#&gt; Correlazione globale: -0.335\n\n# Visualizziamo i dati\nggplot(dati, aes(x = X, y = Y, color = dipartimento)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(\n    title = \"Paradosso di Simpson\",\n    x = \"Voto di laurea\", \n    y = \"Performance nella specializzazione\"\n  ) \n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nAll’interno del Dipartimento A: la correlazione tra voto di laurea (X) e performance (Y) è positiva. Ciò significa che, per gli studenti di A, avere un voto di laurea più alto è associato a una performance maggiore nella specializzazione.\nAll’interno del Dipartimento B: la correlazione tra X e Y è anch’essa positiva, indicando che anche nel secondo dipartimento voti più alti tendono ad accompagnarsi a performance più alte.\nConsiderando entrambi i dipartimenti insieme: a causa delle differenze nei livelli medi di X e Y tra i dipartimenti, unendo i dati senza distinguere il gruppo di appartenenza otteniamo una correlazione globale negativa. Questo significa che, ignorando la suddivisione in dipartimenti, sembra che aumentare il voto di laurea sia associato a una diminuzione della performance nella specializzazione — una conclusione opposta a quella tratta dall’analisi separata dei due sottogruppi.\n\nQuesto è un esempio concreto del paradosso di Simpson: la relazione osservata in sottogruppi omogenei si inverte quando si aggregano i dati, mettendo in guardia sulla necessità di considerare con attenzione la struttura dei dati e i fattori confondenti prima di trarre conclusioni.\n\n\n19.8.3 Paradosso di Berkson\nIl paradosso di Berkson è un fenomeno legato alla selezione del campione. Se il dataset non è rappresentativo della popolazione generale, la relazione osservata può risultare artificiale o opposta a quella esistente su un campione più ampio. Per esempio, analizzando solo ciclisti professionisti, potremmo non vedere alcuna relazione tra VO2 max e probabilità di vincere una gara, poiché tutti hanno già superato una certa soglia di VO2 max. Considerando la popolazione generale, invece, potrebbe emergere chiaramente una relazione positiva tra questi due fattori. Questo paradosso evidenzia l’importanza di considerare il processo di selezione dei dati e di chiedersi se il campione analizzato sia adeguato a rispondere alla domanda di ricerca.\n\n\n19.8.4 Limiti delle statistiche riassuntive semplici\nUn esempio particolarmente famoso che dimostra i limiti delle semplici statistiche descrittive — come media, deviazione standard e correlazione — è il quartetto di Anscombe. Questo insieme di quattro piccoli dataset possiede identiche medie, varianze e correlazioni tra variabili, ma rappresenta relazioni estremamente differenti tra X e Y (Anscombe, 1973).\nImportiamo il dataset anscombe già disponibile nel pacchetto datasets di R:\n\ndata(\"anscombe\")\n\nanscombe |&gt; \n  head()\n#&gt;   x1 x2 x3 x4   y1   y2    y3   y4\n#&gt; 1 10 10 10  8 8.04 9.14  7.46 6.58\n#&gt; 2  8  8  8  8 6.95 8.14  6.77 5.76\n#&gt; 3 13 13 13  8 7.58 8.74 12.74 7.71\n#&gt; 4  9  9  9  8 8.81 8.77  7.11 8.84\n#&gt; 5 11 11 11  8 8.33 9.26  7.81 8.47\n#&gt; 6 14 14 14  8 9.96 8.10  8.84 7.04\n\nIl dataset anscombe contiene quattro serie di dati (x1, y1), (x2, y2), (x3, y3) e (x4, y4), ognuna costituita da 11 coppie di valori (x, y). Per comprendere meglio le loro caratteristiche, iniziamo calcolando alcune statistiche descrittive. La funzione apply() consente di applicare una funzione (ad esempio, mean) a tutte le colonne di un data frame. Usandola sulle colonne di anscombe, otteniamo le medie di ciascuna delle otto variabili (le quattro x e le quattro y):\n\napply(anscombe, MARGIN = 2, mean)\n#&gt;  x1  x2  x3  x4  y1  y2  y3  y4 \n#&gt; 9.0 9.0 9.0 9.0 7.5 7.5 7.5 7.5\n\nOsserviamo che le medie delle quattro variabili x sono identiche fino a sei cifre decimali, e le medie delle quattro variabili y differiscono solo in modo trascurabile (circa lo 0.01%). Analogamente, se calcoliamo le deviazioni standard per ciascuna variabile, notiamo una notevole somiglianza:\n\napply(anscombe, MARGIN = 2, sd)\n#&gt;   x1   x2   x3   x4   y1   y2   y3   y4 \n#&gt; 3.32 3.32 3.32 3.32 2.03 2.03 2.03 2.03\n\nAnche in questo caso, le deviazioni standard per le x coincidono fino alla sesta cifra decimale, mentre quelle delle y differiscono di meno dello 0.06%. Inoltre, se calcoliamo i coefficienti di correlazione tra x e y in ognuno dei quattro dataset, scopriamo che sono quasi identici:\n\n# Calcoliamo la correlazione per ciascuna coppia (x1,y1), (x2,y2), (x3,y3), (x4,y4)\nfor (i in 1:4) {\n  x_var &lt;- anscombe[[paste0(\"x\", i)]]\n  y_var &lt;- anscombe[[paste0(\"y\", i)]]\n  \n  corr_value &lt;- cor(x_var, y_var)\n  cat(\"Correlazione tra x\", i, \"e y\", i, \":\", corr_value, \"\\n\")\n}\n#&gt; Correlazione tra x 1 e y 1 : 0.816 \n#&gt; Correlazione tra x 2 e y 2 : 0.816 \n#&gt; Correlazione tra x 3 e y 3 : 0.816 \n#&gt; Correlazione tra x 4 e y 4 : 0.817\n\nSe ci limitassimo a guardare queste statistiche (media, deviazione standard, correlazione), potremmo facilmente essere indotti a concludere che i quattro dataset sono tra loro sostanzialmente indistinguibili. Tuttavia, la realtà è molto diversa. Le statistiche descrittive, prese da sole, non offrono una visione completa e possono nascondere importanti differenze nella struttura dei dati.\nQuesta differenza diventa evidente non appena decidiamo di visualizzare i dati. La rappresentazione grafica fornisce informazioni che non emergono dalle sole statistiche riassuntive:\n\nanscombe_m &lt;- tibble()\n\nfor (i in 1:4) {\n  anscombe_m &lt;- rbind(\n    anscombe_m, tibble(set = i, x = anscombe[, i], y = anscombe[, i + 4])\n  )\n}\n\nggplot(anscombe_m, aes(x, y)) +\n  geom_point(size = 5, color = \"red\", fill = \"orange\", shape = 21) +\n  geom_smooth(method = \"lm\", fill = NA, fullrange = TRUE) +\n  facet_wrap(~set, ncol = 2)\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nOsservando i grafici, notiamo subito che i quattro dataset sono profondamente diversi:\n\nDataset 1: Qui la relazione tra x e y è approssimativamente lineare, e la correlazione riflette in modo appropriato il legame tra le due variabili.\nDataset 2: Sebbene la correlazione sia simile a quella del Dataset 1, i dati mostrano una relazione curvilinea e non lineare. La semplice correlazione lineare non ne cattura la forma.\nDataset 3: La presenza di un singolo outlier distorce la percezione della relazione tra le variabili, altrimenti lineare. La correlazione alta è influenzata in modo sproporzionato da questo punto anomalo.\nDataset 4: Qui i dati non mostrano alcuna relazione lineare. La correlazione elevata è il frutto di un pattern fortemente atipico (ad esempio, una sola coppia di punti allineata).\n\nIl quartetto di Anscombe mette in luce un principio fondamentale: statistiche descrittive come media, deviazione standard e correlazione non sono sempre sufficienti per comprendere la natura dei dati. La visualizzazione grafica è essenziale per cogliere relazioni, pattern non lineari, outlier e altre caratteristiche che le semplici statistiche non riescono a rivelare. In definitiva, questo esempio dimostra che analizzare i dati soltanto attraverso poche statistiche di sintesi può portare a conclusioni fuorvianti, mentre l’integrazione con la rappresentazione grafica fornisce una visione più completa e accurata.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#riflessioni-conclusive",
    "href": "chapters/eda/08_correlation.html#riflessioni-conclusive",
    "title": "19  Relazioni tra variabili",
    "section": "19.9 Riflessioni Conclusive",
    "text": "19.9 Riflessioni Conclusive\nLa covarianza e la correlazione sono strumenti preziosi per capire l’intensità e la direzione lineare di una relazione tra due variabili. Tuttavia, non dobbiamo confondere la loro semplicità con completezza d’informazione. Una correlazione nulla non implica assenza di relazione, ma solo assenza di una relazione lineare. Inoltre, il paradosso di Simpson e il paradosso di Berkson dimostrano che la semplice osservazione di correlazioni può essere fuorviante se non si tiene conto della struttura dei dati o del processo di selezione del campione.\nInfine, esempi come il quartetto di Anscombe sottolineano quanto sia fondamentale accompagnare le statistiche riassuntive con analisi grafiche e un’attenzione costante ai possibili pattern non lineari, agli outlier e alle caratteristiche peculiari del dataset. Nel prossimo capitolo esamineremo approcci che consentono di avvicinarsi alla comprensione causale dei fenomeni, andando oltre la semplice osservazione dell’associazione tra variabili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/08_correlation.html#informazioni-sullambiente-di-sviluppo",
    "title": "19  Relazioni tra variabili",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2 ggpubr_0.6.0     \n#&gt;  [5] ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0   bayesplot_1.11.1 \n#&gt;  [9] psych_2.4.6.26    scales_1.3.0      markdown_1.13     knitr_1.49       \n#&gt; [13] lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4      \n#&gt; [17] purrr_1.0.2       readr_2.1.5       tidyr_1.3.1       tibble_3.2.1     \n#&gt; [21] ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      xfun_0.49         htmlwidgets_1.6.4 rstatix_0.7.2    \n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    fansi_1.0.6       pacman_0.5.1     \n#&gt; [13] R.oo_1.27.0       pkgconfig_2.0.3   Matrix_1.7-1      data.table_1.16.2\n#&gt; [17] lifecycle_1.0.4   compiler_4.4.2    farver_2.1.2      munsell_0.5.1    \n#&gt; [21] mnormt_2.1.1      carData_3.0-5     httpuv_1.6.15     htmltools_0.5.8.1\n#&gt; [25] yaml_2.3.10       Formula_1.2-5     car_3.1-3         pillar_1.9.0     \n#&gt; [29] later_1.4.1       R.utils_2.12.3    abind_1.4-8       nlme_3.1-166     \n#&gt; [33] mime_0.12         tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4    \n#&gt; [37] splines_4.4.2     labeling_0.4.3    rprojroot_2.0.4   fastmap_1.2.0    \n#&gt; [41] grid_4.4.2        colorspace_2.1-1  cli_3.6.3         magrittr_2.0.3   \n#&gt; [45] utf8_1.2.4        broom_1.0.7       withr_3.0.2       backports_1.5.0  \n#&gt; [49] promises_1.3.2    timechange_0.3.0  rmarkdown_2.29    ggsignif_0.6.4   \n#&gt; [53] R.methodsS3_1.8.2 hms_1.1.3         shiny_1.9.1       evaluate_1.0.1   \n#&gt; [57] miniUI_0.1.1.1    mgcv_1.9-1        rlang_1.1.4       Rcpp_1.0.13-1    \n#&gt; [61] xtable_1.8-4      glue_1.8.0        jsonlite_1.8.9    R6_2.5.1",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#bibliografia",
    "href": "chapters/eda/08_correlation.html#bibliografia",
    "title": "19  Relazioni tra variabili",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAnscombe, F. J. (1973). Graphs in statistical analysis. The American Statistician, 27(1), 17–21.\n\n\nHamaker, E. (2024). The curious case of the cross-sectional correlation. Multivariate Behavioral Research, 59(6), 1111–1122.\n\n\nZetsche, U., Buerkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: biased or realistic? Journal of Abnormal Psychology, 128(7), 678–688.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html",
    "href": "chapters/eda/09_causality.html",
    "title": "20  Causalità dai dati osservazionali",
    "section": "",
    "text": "20.1 Introduzione\nLa pura osservazione dei dati può rivelare correlazioni e pattern nei dati, ma senza un’indagine sulle cause che stanno alla base di tali correlazioni, le conclusioni tratte possono essere fuorvianti o incomplete.\nRichard McElreath, nel suo libro “Statistical Rethinking” (McElreath, 2020), utilizza l’analogia dei Golem - creature potenti ma prive di saggezza - per descrivere un approccio metodologico che è stato a lungo predominante in psicologia. Questo approccio si basa esclusivamente sull’analisi delle associazioni statistiche tra variabili, trascurando considerazioni più profonde sulla causalità.\nIl metodo in questione si concentra principalmente sul test delle ipotesi nulle, senza stabilire una chiara connessione tra le domande di ricerca riguardanti relazioni causali e i test statistici impiegati. Questa disconnessione è evidente nella figura successiva, tratta da un manuale di analisi dati di impostazione frequentista, che illustra la procedura raccomandata dai sostenitori di questo approccio per descrivere le associazioni tra variabili.\nÈ importante notare come tale procedura non fornisca strumenti utili per identificare le effettive cause sottostanti ai fenomeni osservati. Questa limitazione metodologica è stata identificata come uno dei fattori principali che hanno contribuito alla crisi di replicabilità nella ricerca psicologica, come approfondito nel ?sec-crisis. L’approccio descritto, pur essendo potente nell’individuare correlazioni, manca della “saggezza” necessaria per distinguere tra semplici associazioni e vere relazioni causali, analogamente ai Golem della metafora di McElreath.\nUn problema evidenziato da McElreath (2020) è che processi causali completamente distinti possono generare la stessa distribuzione di risultati osservati. Pertanto, un approccio focalizzato esclusivamente sull’analisi delle associazioni mediante il test dell’ipotesi nulla non è in grado di distinguere tra questi diversi scenari, come spiegato nel ?sec-causal-inference-regr.\nL’approccio frequentista, che si limita a descrivere le associazioni tra le variabili, ha una scarsa capacità di rilevare le caratteristiche cruciali dei fenomeni studiati e tende a produrre un alto tasso di falsi positivi (Zwet et al., 2023). È invece necessario utilizzare una metodologia che non si limiti a confutare ipotesi nulle, ma sia in grado di sviluppare modelli causali che rispondano direttamente alle domande di ricerca. In questo capitolo, ci concentreremo sull’introduzione dei concetti fondamentali dell’analisi causale.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#introduzione",
    "href": "chapters/eda/09_causality.html#introduzione",
    "title": "20  Causalità dai dati osservazionali",
    "section": "",
    "text": "Esempio di albero decisionale per la selezione di una procedura statistica appropriata. Iniziando dall’alto, l’utente risponde a una serie di domande riguardanti la misurazione e l’intento, arrivando infine al nome di una procedura. Sono possibili molti alberi decisionali simili. (Figura tratta da McElreath (2020)).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#cosè-la-causalità",
    "href": "chapters/eda/09_causality.html#cosè-la-causalità",
    "title": "20  Causalità dai dati osservazionali",
    "section": "20.2 Cos’è la causalità?",
    "text": "20.2 Cos’è la causalità?\nHardt & Recht (2022) introducono il concetto di causalità distinguendo tra osservazione e azione. Ciò che vediamo nell’osservazione passiva è il modo in cui le persone seguono i loro comportamenti abituali, le loro inclinazioni naturali, proiettando lo stato del mondo su un insieme di caratteristiche che abbiamo scelto di evidenziare. Tuttavia, le domande più importanti spesso non riguardano semplici osservazioni.\n\nNon ci basta sapere che le persone che praticano regolarmente attività fisica soffrono meno d’ansia; vogliamo capire se l’attività fisica riduce effettivamente i livelli d’ansia.\nNon ci accontentiamo di osservare che chi segue una terapia cognitivo-comportamentale (CBT) presenta meno sintomi depressivi; desideriamo verificare se la CBT riduce realmente questi sintomi.\nNon ci limitiamo a constatare che l’uso frequente dei social media è associato a un calo del benessere mentale; vogliamo determinare se l’uso intensivo dei social media causa effettivamente una diminuzione del benessere mentale.\n\nAlla base, il ragionamento causale è un quadro concettuale per affrontare domande sugli effetti di azioni o interventi ipotetici. Una volta compreso quale sia l’effetto di un’azione, possiamo invertire la domanda e chiederci quale azione plausibile abbia causato un determinato evento.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#effetto-causale",
    "href": "chapters/eda/09_causality.html#effetto-causale",
    "title": "20  Causalità dai dati osservazionali",
    "section": "20.3 Effetto Causale",
    "text": "20.3 Effetto Causale\nSebbene non esista una definizione univoca di causalità, possiamo concettualizzarla in modo pratico: diciamo che X causa Y se, intervenendo e modificando il valore di X (il trattamento), la distribuzione di Y cambia di conseguenza. Questa definizione sottolinea l’importanza cruciale dell’azione o dell’intervento nel determinare una relazione causale.\nQuando X è una variabile binaria, rappresentante la presenza o l’assenza del trattamento, la conseguenza dell’intervento su X è denominata effetto medio del trattamento. Questo ci indica quanto il trattamento (azione X = 1) aumenta l’aspettativa di Y rispetto all’assenza di trattamento (azione X = 0).\nÈ importante notare che gli effetti causali sono quantità relative alla popolazione. Si riferiscono a effetti mediati sull’intera popolazione in esame. Tuttavia, spesso l’effetto del trattamento può variare significativamente da un individuo all’altro o tra gruppi di individui. In questi casi, parliamo di effetti di trattamento eterogenei.\nPer chiarire questo concetto, consideriamo un esempio concreto: supponiamo che la terapia cognitivo-comportamentale (CBT) riduca l’ansia. Se un gruppo di persone ansiose non riceve alcun trattamento, i loro livelli d’ansia rimarranno presumibilmente invariati. Se invece interveniamo introducendo la CBT (modificando così il valore di X), i livelli d’ansia nel gruppo tenderanno a diminuire (cambiando quindi il valore di Y). Questo esempio illustra la distinzione tra semplice correlazione, basata sull’osservazione passiva, e causalità, che implica un’azione o un intervento.\nLa definizione di causalità può essere applicata anche per collegare variabili apparentemente distanti. Ad esempio, l’autoefficacia potrebbe non avere un effetto causale diretto sulle prestazioni accademiche. Tuttavia, se aumentiamo l’autoefficacia attraverso interventi mirati, è probabile che osserviamo un miglioramento nell’impegno allo studio. Questo aumento dell’impegno, a sua volta, tende a migliorare le prestazioni accademiche. Di conseguenza, possiamo affermare che l’autoefficacia influisce indirettamente sulle prestazioni accademiche attraverso una catena causale.\nÈ importante precisare che affermiamo l’esistenza di una relazione causale tra X e Y anche quando modificare X non porta necessariamente a un cambiamento immediato o deterministico in Y, ma altera la probabilità che Y si verifichi in un certo modo, modificando quindi la distribuzione di Y. Questa prospettiva probabilistica della causalità è particolarmente rilevante in campi come la psicologia, dove le relazioni tra variabili sono spesso complesse e influenzate da molteplici fattori.\n\n20.3.1 I Limiti dell’Osservazione\nPer comprendere i limiti dell’osservazione passiva, e quindi la necessità di comprendere le relazioni causali sottostanti, Hardt & Recht (2022) si riferiscono all’esempio storico delle ammissioni ai corsi di laurea dell’Università della California, Berkeley, nel 1973. In quell’anno, 12,763 candidati furono considerati per l’ammissione in uno dei 101 dipartimenti o major interdipartimentali. Di questi, 4,321 erano donne e 8,442 erano uomini. I dati mostrano che circa il 35% delle donne fu ammesso, rispetto al 44% degli uomini. Test di significatività statistica indicano che questa differenza non è attribuibile al caso, suggerendo una disparità nei tassi di ammissione tra i generi.\nUna tendenza simile si osserva quando si analizzano le decisioni aggregate di ammissione nei sei maggiori dipartimenti. Il tasso di ammissione complessivo per gli uomini era di circa il 44%, mentre per le donne era solo il 30%, un’altra differenza significativa. Tuttavia, poiché i dipartimenti hanno autonomia nelle loro decisioni di ammissione, è utile esaminare il possibile bias di genere a livello di singolo dipartimento.\nUomini\n\n\n\nDipartimento\nCandidati\nAmmessi (%)\n\n\n\n\nA\n825\n62\n\n\nB\n520\n60\n\n\nC\n325\n37\n\n\nD\n417\n33\n\n\nE\n191\n28\n\n\nF\n373\n6\n\n\n\nDonne\n\n\n\nDipartimento\nCandidati\nAmmessi (%)\n\n\n\n\nA\n108\n82\n\n\nB\n25\n68\n\n\nC\n593\n34\n\n\nD\n375\n35\n\n\nE\n393\n24\n\n\nF\n341\n7\n\n\n\nDall’osservazione di questi dati, emerge che quattro dei sei maggiori dipartimenti mostrano un tasso di ammissione più elevato per le donne, mentre due mostrano un tasso più elevato per gli uomini. Tuttavia, questi due dipartimenti non possono giustificare la sostanziale differenza nei tassi di ammissione osservata nei dati aggregati. Questo suggerisce che la tendenza generale di un tasso di ammissione più alto per gli uomini sembra invertita quando i dati sono disaggregati per dipartimento.\nQuesto fenomeno è noto come paradosso di Simpson, un paradosso statistico in cui una tendenza che appare in sottopopolazioni si inverte o scompare quando i dati vengono aggregati. Nel contesto attuale, il paradosso di Simpson si manifesta nel fatto che, mentre i dati aggregati sembrano indicare una discriminazione di genere contro le donne, l’analisi dei dati disaggregati per dipartimento rivela che in alcuni casi le donne sono favorite in termini di ammissioni.\nLa domanda fondamentale è se questi dati indicano effettivamente un problema di discriminazione di genere o se, come suggerito dallo studio originale, il bias di genere nelle ammissioni fosse principalmente dovuto al fatto che “le donne sono indirizzate dalla loro socializzazione e istruzione verso campi di studio generalmente più affollati, meno produttivi in termini di completamento dei diplomi, meno finanziati e che spesso offrono prospettive professionali peggiori.” In altre parole, il problema risiederebbe in differenze sistemiche e strutturali tra i campi di studio scelti dalle donne e quelli scelti dagli uomini.\nIl paradosso di Simpson crea disagio proprio perché l’intuizione suggerisce che una tendenza valida per tutte le sottopopolazioni dovrebbe esserlo anche a livello aggregato. Tuttavia, questo paradosso evidenzia un errore comune nell’interpretazione delle probabilità condizionate: confondere l’osservazione passiva con l’analisi causale. I dati che abbiamo rappresentano solo un’istantanea del comportamento normale di uomini e donne che si candidavano per l’ammissione a UC Berkeley nel 1973.\nNon possiamo trarre conclusioni definitive da questi dati. Possiamo solo riconoscere che l’analisi iniziale solleva ulteriori domande, come ad esempio la necessità di progettare nuovi studi per raccogliere dati più completi, che potrebbero portare a conclusioni più definitive. In alternativa, potremmo discutere su quale scenario sia più verosimile in base alle nostre convinzioni e alle notre ipotesi sul mondo.\nL’inferenza causale può essere utile in entrambi i casi. Da un lato, può guidare la progettazione di nuovi studi, aiutandoci a scegliere quali variabili includere, quali escludere e quali mantenere costanti. Dall’altro, i modelli causali possono fungere da meccanismo per incorporare le conoscenze scientifiche del dominio e passare da ipotesi plausibili a conclusioni plausibili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#variabili-confondenti",
    "href": "chapters/eda/09_causality.html#variabili-confondenti",
    "title": "20  Causalità dai dati osservazionali",
    "section": "20.4 Variabili confondenti",
    "text": "20.4 Variabili confondenti\nSebbene gli esperimenti controllati offrano un elevato grado di certezza nell’identificazione di queste relazioni, molte domande di ricerca non possono essere affrontate sperimentalmente a causa di limitazioni etiche o pratiche. In questi casi, i ricercatori ricorrono a disegni osservazionali, che offrono maggiore flessibilità e applicabilità. Tuttavia, l’uso di dati osservazionali comporta una sfida significativa: la difficoltà di trarre conclusioni causali affidabili.\nAl centro di questa complessità si trovano le variabili confondenti. Possiamo dire che una variabile confondente è presente quando l’associazione osservata tra due variabili X e Y non riflette accuratamente la vera relazione causale tra di esse. In altre parole, la variabile confondente influenza sia X che Y, creando l’apparenza di una relazione diretta tra le due che potrebbe essere fuorviante o inesatta.\nNegli studi osservazionali, se le variabili confondenti non vengono misurate e controllate adeguatamente, possono distorcere le stime degli effetti causali, introducendo bias nei risultati e impedendo di riflettere il vero valore dell’effetto. In pratica, la presenza di variabili confondenti può portare a conclusioni errate quando si confrontano semplicemente i risultati osservati in diversi gruppi. Ciò che si osserva nei dati potrebbe non corrispondere a ciò che accadrebbe se si potesse manipolare direttamente la variabile di interesse in un esperimento controllato.\nUn approccio apparentemente semplice per affrontare questo problema potrebbe essere quello di controllare statisticamente tutte le variabili confondenti. In questo metodo, si stima l’effetto di X su Y separatamente in ogni segmento della popolazione definito da una condizione Z = z per ogni possibile valore di z. Successivamente, si calcola la media di questi effetti stimati nelle sottopopolazioni, ponderandoli per la probabilità di Z = z nella popolazione. Tuttavia, questo metodo presenta due difficoltà fondamentali: richiede la conoscenza di tutte le possibili variabili confondenti e la capacità di misurare ciascuna di esse, cosa che spesso non è praticabile.\nIl controllo delle variabili confondenti è cruciale per stabilire relazioni causali, poiché permette di isolare gli effetti delle variabili indipendenti da quelli delle variabili confondenti che potrebbero influenzare le variabili dipendenti. Esistono due principali metodologie di controllo:\n\nIl controllo sperimentale, implementato attraverso il disegno sperimentale e basato principalmente sulla randomizzazione.\nIl controllo statistico, applicato durante l’analisi dei dati, con l’obiettivo di neutralizzare o quantificare l’influenza delle variabili estranee.\n\nA causa di queste difficoltà, l’inferenza causale basata su dati osservazionali è spesso considerata problematica, dando origine al famoso detto “la correlazione non implica causalità”. Tuttavia, è importante notare che in alcune circostanze, è possibile fare inferenze causali anche a partire da dati osservazionali.\nL’obiettivo dell’analisi causale moderna è proprio quello di fornire gli strumenti concettuali e metodologici per affrontare queste sfide. Attraverso l’uso di tecniche avanzate come i modelli causali strutturali, i grafi aciclici diretti (DAG) e i metodi di identificazione degli effetti causali, i ricercatori possono spesso superare le limitazioni dei dati osservazionali e trarre conclusioni causali più robuste.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#modelli-causali-strutturali",
    "href": "chapters/eda/09_causality.html#modelli-causali-strutturali",
    "title": "20  Causalità dai dati osservazionali",
    "section": "20.5 Modelli Causali Strutturali",
    "text": "20.5 Modelli Causali Strutturali\nI modelli causali sono strumenti essenziali per l’analisi dei dati osservazionali, poiché consentono di rappresentare il processo sottostante a un fenomeno e di prevedere gli effetti di un intervento. Questi modelli non solo permettono di anticipare le conseguenze di una causa, ma offrono anche la possibilità di esplorare scenari controfattuali, immaginando esiti alternativi che si sarebbero potuti verificare in presenza di decisioni diverse.\nUn modello causale strutturale (Structural Causal Model, SCM) è un approccio che rappresenta le relazioni causali tra variabili. Esso si basa su una serie di assegnazioni che, partendo da variabili di rumore indipendenti (note anche come variabili esogene), generano una distribuzione di probabilità congiunta.\nLe variabili di rumore indipendenti svolgono un ruolo cruciale negli SCM. Esse rappresentano fonti di incertezza o variabilità all’interno del sistema e non sono influenzate da altre variabili del modello. Queste variabili sono mutuamente indipendenti, il che significa che il loro valore non fornisce informazioni sul valore delle altre.\nLa costruzione di un SCM segue una sequenza specifica: si parte dalle variabili di rumore indipendenti, si applicano una serie di assegnazioni che descrivono gli effetti causali delle variabili esogene su altre variabili, e si genera progressivamente un insieme di variabili casuali che dà origine a una distribuzione congiunta.\nIl principale vantaggio di un SCM risiede nella sua duplice natura: da un lato, fornisce una distribuzione di probabilità congiunta delle variabili, e dall’altro, descrive il processo generativo che porta alla formazione di tale distribuzione, partendo dalle variabili di rumore elementari.\nQuesta struttura consente non solo di modellare le relazioni probabilistiche tra le variabili, ma anche di rappresentare in modo esplicito i meccanismi causali che le governano.\nI SCM possono essere rappresentati graficamente attraverso Grafi Aciclici Direzionati (Directed Acyclic Graphs, DAG). Questi DAG visualizzano le relazioni causali tra le variabili all’interno di un SCM, facilitando l’identificazione delle variabili confondenti e il loro impatto sull’analisi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#bias-da-variabile-omessa",
    "href": "chapters/eda/09_causality.html#bias-da-variabile-omessa",
    "title": "20  Causalità dai dati osservazionali",
    "section": "20.6 Bias da Variabile Omessa",
    "text": "20.6 Bias da Variabile Omessa\nPossiamo introdurre i DAG facendo riferiento al bias da variabile omessa (Omitted Variable Bias, o OVB; Wilms et al. (2021)). Come discusso da Byrnes & Dee (2024), l’omissione dall’analisi statistica di variabili confondenti note ma non misurate, o sconosciute e non misurate, può portare a stime errate della magnitudine degli effetti, errori nel segno delle stime (stimatori distorti), correlazioni spurie, e al mascheramento delle vere relazioni causali.\nUn illustrazione di questa situazione è fornita nella Figura 20.1. La figura mostra tre DAG che illustrano diversi scenari in cui le variabili non osservate non influenzano i risultati del modello o potrebbero creare problemi a causa della confusione. Una variabile di risposta di interesse (Y) è causata sia da una variabile misurata (X) che da una variabile non misurata (U). Nel pannello di sinistra, la variabile non osservata (U) non è una variabile confondente. Nel pannello centrale, la variabile non osservata (U) è una variabile confondente e causa il bias da variabile omessa. Nel pannello di destra la variabile non osservata (U) causa il bias da variabile omessa in maniera indiretta.\n\n\n\n\n\n\nFigura 20.1: Nel pannello di sinistra, X e U sono non correlate, quindi la mancata inclusione di U in un modello statistico aumenterebbe l’errore standard della stima (riducendo la precisione del modello) ma non porterebbe a bias nella stima dell’effetto di X su Y. Tuttavia, se U influenza anche X come nel pannello centrale, o se U e X sono influenzati da un fattore comune Z come nel pannello di destra, allora omettere U da un modello statistico causa il bias da variabile omessa nella stima dell’effetto di X su Y. I casi illustrati dal pannello centrale e dal pannello di destra sono esempi di sistemi in cui le cause comuni di confusione (U e Z rispettivamente) devono essere controllate per effettuare inferenze causali non distorte (la figura è ispirata da Byrnes & Dee (2024)).\n\n\n\nAffrontare i problemi creati dalle variabili confondenti non misurate rappresenta una sfida primaria nell’inferenza causale dai dati osservazionali. A differenza dell’errore di misurazione nelle variabili predittive, che produce un bias costante verso lo zero e può essere corretto o modellato (McElreath, 2020; Schennach, 2016), con l’OVB non possiamo conoscere la grandezza o la direzione del bias senza conoscere tutte le possibili variabili confondenti e le loro relazioni nel sistema.\nNonostante queste sfide, non è necessario abbandonare l’uso dei dati osservazionali per l’inferenza causale in psicologia. È invece necessario ricorrere all’adozione delle tecniche dei SCM per potere comunque svolgere l’inferenza causale.\nÈ evidente che questo approccio porterà a conclusioni inevitabilmente parziali, destinate ad essere perfezionate da studi successivi. Tuttavia, tale metodologia offre il vantaggio di esplicitare il “modello generativo dei dati”, ovvero la struttura causale sottostante ai fenomeni psicologici oggetto di studio.\nI progressi nella ricerca empirica conducono a una maggiore comprensione e, di conseguenza, a modifiche nelle ipotesi sui meccanismi causali. Questo processo rappresenta un’evoluzione della conoscenza scientifica. Tale sviluppo è reso possibile proprio perché le ipotesi causali sono formulate in termini di modelli formali, che descrivono in modo preciso i meccanismi ipotizzati.\nAl contrario, limitarsi alla mera descrizione delle associazioni tra variabili non consente questo tipo di avanzamento conoscitivo. La formulazione di modelli causali espliciti permette infatti di testare, raffinare e, se necessario, rivedere le ipotesi sui meccanismi sottostanti ai fenomeni osservati, portando a una comprensione più profonda e dinamica dei processi psicologici.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#grafi-aciclici-diretti",
    "href": "chapters/eda/09_causality.html#grafi-aciclici-diretti",
    "title": "20  Causalità dai dati osservazionali",
    "section": "20.7 Grafi Aciclici Diretti",
    "text": "20.7 Grafi Aciclici Diretti\nI DAG sono uno strumento fondamentale per l’inferenza causale, offrendo una rappresentazione visiva delle relazioni causali ipotizzate tra variabili. Questi grafi sono definiti “diretti” perché le variabili, rappresentate da nodi, sono collegate da frecce orientate anziché da semplici linee. Sono inoltre chiamati “aciclici” poiché non è possibile tornare a un nodo di partenza seguendo il percorso delle frecce.\nIn un DAG, una freccia che va da X a Y indica un’influenza probabilistica di X su Y. La terminologia delle relazioni all’interno del grafo è importante: il nodo di origine di una freccia è chiamato “genitore”, mentre il nodo di destinazione è detto “figlio”. Quando è possibile raggiungere un nodo B partendo da un nodo A seguendo una successione di frecce, A è definito “antenato” di B, e B è considerato “discendente” di A.\nI DAG consentono di distinguere chiaramente tra cause dirette e indirette. Una causa diretta è rappresentata da un nodo genitore, mentre una causa indiretta può essere qualsiasi antenato di un nodo nel grafo causale. Questa struttura permette di differenziare efficacemente causa ed effetto basandosi sulla posizione relativa dei nodi all’interno del grafo, ovvero se un nodo è antenato o discendente di un altro.\nQuesti grafi sono particolarmente utili per identificare variabili confondenti, basandosi sulla teoria sviluppata da Judea Pearl (Pearl, 2009). È cruciale rappresentare in un DAG tutte le possibili relazioni causali, poiché l’assenza di una freccia tra due nodi implica la certezza dell’assenza di una relazione causale diretta tra le variabili corrispondenti.\nNella teoria dei DAG, due concetti fondamentali sono la d-separazione e il criterio del back-door.\n\n20.7.1 La d-separazione\nLa d-separazione ci aiuta a determinare quando due variabili in un grafo causale sono indipendenti condizionatamente a un insieme di altre variabili. Questo concetto è cruciale per comprendere come l’informazione o l’influenza si propaga tra le variabili in un modello causale.\nIn termini più semplici, la d-separazione ci permette di identificare se esiste un “blocco” nel flusso di informazioni tra due variabili, dato un certo insieme di altre variabili (che chiameremo Λ). Quando due variabili sono d-separate da Λ, significa che non c’è flusso di informazioni tra di loro, condizionatamente a Λ.\nPer comprendere meglio la d-separazione, consideriamo tre situazioni principali che possono verificarsi in un DAG:\n\nCatena (X → Z → Y): In questo caso, Z è un mediatore tra X e Y. Se Z appartiene all’insieme Λ (cioè, se controlliamo o condizioniamo su Z), blocchiamo il flusso di informazioni da X a Y attraverso questo percorso. Per esempio, se X è “esercizio fisico”, Z è “pressione sanguigna” e Y è “rischio di malattie cardiache”, controllando per la pressione sanguigna (Z) blocchiamo il percorso attraverso il quale l’esercizio fisico influenza il rischio di malattie cardiache.\nFork (X ← Z → Y): Qui, Z è una causa comune sia di X che di Y. Se Z appartiene a Λ, blocchiamo la correlazione spuria tra X e Y che deriva dalla loro causa comune. Per esempio, se Z è “status socioeconomico”, X è “livello di istruzione” e Y è “stato di salute”, controllando per lo status socioeconomico (Z) eliminiamo la correlazione apparente tra istruzione e salute che potrebbe derivare dal fatto che entrambe sono influenzate dallo status socioeconomico.\nCollider (X → Z ← Y): In questa situazione, Z è un effetto comune di X e Y. Sorprendentemente, se né Z né i suoi discendenti appartengono a Λ, il percorso è già bloccato. Controllare per Z (o i suoi discendenti) in realtà aprirebbe un percorso tra X e Y, creando una correlazione spuria. Per esempio, se X è “intelligenza”, Y è “bellezza” e Z è “successo in una carriera di attore”, controllare per il successo nella carriera di attore (Z) creerebbe una correlazione apparente tra intelligenza e bellezza, anche se queste potrebbero essere indipendenti nella popolazione generale.\n\nIn sintesi, la d-separazione ci permette di determinare, dato un certo insieme di variabili Λ, se due variabili X e Y sono indipendenti condizionatamente a Λ. Questo ci aiuta a identificare quali variabili dobbiamo controllare (e quali non dobbiamo controllare) per ottenere stime causali non distorte, facilitando così l’inferenza causale corretta. La d-separazione è quindi uno strumento potente che ci permette di leggere le indipendenze condizionali direttamente dal grafo, senza dover fare calcoli probabilistici complessi.\n\n\n20.7.2 Il criterio del back-door\nIl criterio del back-door consente di identificare un insieme di variabili che, se controllate adeguatamente, permettono di stimare gli effetti causali in modo non distorto. L’obiettivo principale di questo criterio è eliminare l’influenza di percorsi non causali tra la variabile di esposizione (causa potenziale) e l’outcome (effetto), mantenendo aperto solo il percorso causale diretto di interesse.\nIn questo contesto, due variabili sono considerate “confuse” se esiste tra di esse un percorso di tipo back-door. Un back-door path da X a Y è definito come qualsiasi percorso che inizia da X con una freccia entrante in X. Per esempio, consideriamo il seguente percorso:\nX ← A → B ← C → Y\nIn questo caso, il percorso rappresenta un flusso di informazioni da X a Y che non è causale, ma potrebbe creare l’apparenza di una relazione causale.\nPer “deconfondere” una coppia di variabili, è necessario selezionare un insieme di variabili (chiamato back-door set) che “blocchi” tutti i back-door paths tra i due nodi di interesse. Il blocco di questi percorsi avviene in modi diversi a seconda della struttura del percorso:\n\nUn back-door path che coinvolge una catena di variabili (ad esempio, A → B → C) può essere bloccato controllando per la variabile intermedia (in questo caso, B).\nUn percorso che coinvolge un “collider” (una variabile che riceve frecce da entrambe le direzioni, come in A → B ← C) è naturalmente bloccato e non permette il flusso di informazioni.\n\nÈ importante notare che bisogna prestare attenzione a non aprire involontariamente un flusso di informazioni attraverso un collider. Questo può accadere se si condiziona l’analisi sul collider stesso o su un suo discendente, il che potrebbe erroneamente aprire il percorso e introdurre bias nell’analisi.\n\n\n\n\n\n\nPunti chiave\n\n\n\n\nIl criterio del back-door aiuta a identificare il set minimale di variabili da controllare.\nNon tutte le variabili associate sia all’esposizione che all’outcome devono essere controllate; solo quelle che creano percorsi back-door.\nIn alcuni casi, potrebbe non essere necessario controllare alcuna variabile (se non ci sono percorsi back-door aperti).\nIn altri casi, potrebbe essere impossibile bloccare tutti i percorsi back-door con le variabili disponibili, indicando che l’effetto causale non può essere identificato con i dati a disposizione.\n\nUtilizzando il criterio del back-door in combinazione con i DAG, i ricercatori possono fare scelte più informate su quali variabili includere nelle loro analisi, migliorando così la validità delle loro inferenze causali.\n\n\n\n\n20.7.3 Applicazioni\nConsideriamo nuovamente la struttura causale illustrata nella Figura 20.1, pannello centrale. Dopo aver costruito un DAG come descritto nella sezione precedente, è possibile identificare le potenziali fonti di bias da variabili omesse, inclusi i confondenti non misurati (ad esempio, U). Non controllare per le variabili confondenti apre una “back-door” permettendo alla variazione confondente di influenzare la relazione tra la variabile causale e la variabile di risposta di interesse attraverso un percorso non valutato (Pearl, 2009). In altre parole, omettere una variabile confondente come U nella Figura 20.1 (pannello centrale) in un’analisi statistica significa che questa viene incorporata nel termine di errore del modello statistico, insieme alle fonti di errore casuali. La Figura 20.2 illustra le conseguenze di un confondente U che ha un effetto positivo su X ma un effetto negativo su Y. Se adattiamo un modello come mostrato nella Figura 20.2 bi, l’effetto stimato di X su Y è positivo quando si controlla per U. Tuttavia, se non si controlla per U, come mostrato nella Figura 20.2 bii, U viene incorporato nel termine di errore, inducendo una correlazione tra l’errore e X, come illustrato nella Figura 20.2 biii, portando a una stima errata. Pertanto, il termine di errore del modello e X risultano correlati, il che viola un’assunzione fondamentale dei modelli lineari (ovvero, il teorema di Gauss-Markov; Abdallah et al., 2015; Antonakis et al., 2010). Questo produce una stima errata, evidenziata in blu.\n\n\n\n\n\n\nFigura 20.2: Una visualizzazione del bias da variabile omessa e delle conseguenze per l’inferenza causale. (A) mostra un DAG di un sistema in cui X ha un effetto positivo su Y, e una variabile confondente U ha un effetto positivo su Y ma un effetto negativo su X. Le variabili non osservate (cioè non misurate) sono rappresentate in ellissi, come la variabile U e il termine di errore e nel pannello B. (B) illustra diverse stime del DAG in (A) utilizzando un’analisi del percorso. Vedi Box 1 per una breve spiegazione delle principali differenze tra DAG e diagrammi dei percorsi. Presumiamo che U non sia misurata. In (Bi), presumiamo di poter misurare e controllare U, rappresentata dalla freccia a doppia testa tra U e X, che rappresenta la correlazione tra le due variabili considerata dal modello. La variabile non misurata e è la fonte residua di variazione che si presume non sia correlata con nessun predittore. La freccia rossa rappresenta il percorso stimato. Al contrario, (Bii) e (Biii) rappresentano la realtà, dove non abbiamo una misurazione di U e non la controlliamo nel modello dei percorsi. Il ricercatore pensa di adattare il modello in (Bii) ma in realtà sta adattando il modello in (Biii), dove il termine di errore non è solo e, ma la somma di e e la variazione dovuta alla variabile omessa U. A causa di ciò, c’è un percorso diretto dal termine di errore del modello a X (e quindi X è endogeno). (C) mostra le relazioni stimate risultanti dai modelli in (Bi) rispetto a (Bii). Le linee rappresentano la relazione stimata tra X e Y dai rispettivi modelli. La linea rossa è la vera relazione causale, stimata da (Bi), mentre la linea blu contiene il bias da variabile omessa, poiché non si tiene conto della variabile confondente U, come stimato dal modello in Bii/Biii (Figura tratta da Byrnes & Dee (2024)).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#commenti-e-considerazioni-finali",
    "href": "chapters/eda/09_causality.html#commenti-e-considerazioni-finali",
    "title": "20  Causalità dai dati osservazionali",
    "section": "20.8 Commenti e Considerazioni Finali",
    "text": "20.8 Commenti e Considerazioni Finali\nI diagrammi causali sono uno dei primi strumenti per identificare il bias da variabili omesse (Pearl, 1995; Pearl et al., 2016). I diagrammi causali, sotto forma di DAG, visualizzano la nostra comprensione delle relazioni causali e delle variabili confondenti all’interno di un sistema. In questo modo, i DAG chiariscono in modo trasparente le assunzioni dietro le affermazioni causali derivate dai dati e mostrano le potenziali fonti di bias derivanti da variabili confondenti.\nÈ fondamentale che i DAG includano tutte le cause comuni di un predittore e della risposta di interesse, comprendendo tutte le variabili confondenti misurate e non misurate. Questo significa che l’inferenza causale è possibile solo quando il ricercatore dispone di adeguate conoscenze del dominio.\nDopo aver costruito un DAG, è possibile determinare le potenziali fonti di bias da variabili omesse, incluse quelle derivanti da variabili confondenti non misurate (es., U nella figura fig-byrnes-dee-1, pannello centrale). Non controllare le variabili confondenti apre una “back-door” per la variazione confondente, permettendo a quest’ultima di fluire tra la variabile causale e la variabile di risposta di interesse attraverso un percorso non valutato (Pearl, 2009).\nPertanto, un diagramma causale è un primo passo fondamentale per identificare potenziali bias da variabili omesse. I DAG giustificano anche la scelta delle variabili di controllo, rendendo trasparenti le assunzioni che un ricercatore fa su come funziona il sistema oggetto di studio.\nÈ importante notare che i DAG possono essere incorretti o non includere variabili confondenti sconosciute. Infatti, un DAG rappresenta solo la comprensione attuale e le assunzioni del ricercatore riguardo alle relazioni causali all’interno di un sistema.\nUn sommario ironico di questi concetti è fornito nella vignetta di xkcd.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#bibliografia",
    "href": "chapters/eda/09_causality.html#bibliografia",
    "title": "20  Causalità dai dati osservazionali",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlexander, R. (2023). Telling Stories with Data: With Applications in R. Chapman; Hall/CRC.\n\n\nByrnes, J. E., & Dee, L. E. (2024). Causal inference with observational data and unobserved confounding variables. bioRxiv, 2024–2002.\n\n\nHardt, M., & Recht, B. (2022). Patterns, Predictions, and Actions: Foundations of Machine Learning. Princeton University Press.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nPearl, J. (1995). Causal diagrams for empirical research. Biometrika, 82(4), 669–688.\n\n\nPearl, J. (2009). Causality. Cambridge University Press.\n\n\nPearl, J., Glymour, M., & Jewell, N. P. (2016). Causal inference in statistics: A primer. John Wiley & Sons.\n\n\nRiederer, E. (2021). Causal design patterns for data analysts. https://emilyriederer.netlify.app/post/causal-design-patterns/\n\n\nSchennach, S. M. (2016). Recent advances in the measurement error literature. Annual Review of Economics, 8(1), 341–377.\n\n\nWilms, R., Mäthner, E., Winnen, L., & Lanwehr, R. (2021). Omitted variable bias: A threat to estimating causal relationships. Methods in Psychology, 5, 100075.\n\n\nZwet, E. van, Gelman, A., Greenland, S., Imbens, G., Schwab, S., & Goodman, S. N. (2023). A New Look at P Values for Randomized Clinical Trials. NEJM Evidence, 3(1), EVIDoa2300003.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html",
    "href": "chapters/eda/10_estimand.html",
    "title": "21  Estimandi teorici e estimandi empirici",
    "section": "",
    "text": "21.1 Introduzione\nNei capitoli precedenti abbiamo illustrato diverse tecniche di analisi esplorativa dei dati, utili per sintetizzare ampie quantità di informazioni, rappresentare le distribuzioni delle variabili e descriverne le relazioni. In tali esempi, abbiamo dato per scontato che le variabili fossero state misurate correttamente con lo scopo di rispondere a una determinata domanda teorica. È però fondamentale interrogarsi sul legame tra le quantità che vogliamo stimare (estimandi) e la teoria che guida lo studio. Per approfondire questo aspetto, esamineremo l’articolo di Lundberg et al. (2021), “What Is Your Estimand? Defining the Target Quantity Connects Statistical Evidence to Theory”, che mette in luce quanto sia importante definire con precisione l’estimando chiave di una ricerca.\nL’estimando è la quantità che uno studio intende stimare e rappresenta il ponte tra la teoria e l’evidenza statistica. Gli autori suggeriscono un approccio metodologico in tre fasi:\nQuesto approccio consente di chiarire come le informazioni ottenute dai dati rispondano a una ben precisa domanda teorica. In breve, Lundberg et al. (2021) invitano i ricercatori a definire l’estimando teorico in modo indipendente dai modelli statistici impiegati, così da evidenziare il nesso logico fra teoria ed evidenza empirica.\nIn altre parole, non basta limitarsi a verificare se un coefficiente di regressione è “significativamente diverso da zero” basandosi solo sul modello statistico. È necessario distinguere l’obiettivo teorico della ricerca (ad esempio, studiare l’apprendimento associativo) dal modo in cui questo obiettivo viene tradotto in una misura osservabile. Un esempio concreto è fornito dal modello di Rescorla-Wagner, applicato a compiti di Probabilistic Reversal Learning (PRL): l’estimando empirico potrebbe corrispondere a parametri come il tasso di apprendimento \\(\\alpha\\) o la temperatura inversa \\(\\beta\\). Questi parametri riflettono quanto i partecipanti modifichino i valori associati agli stimoli o regolino la strategia di scelta (esplorazione rispetto a sfruttamento), come descritto nella sezione ?sec-rescorla-wagner.\nÈ importante notare che l’estimando empirico può essere stimato in modi diversi, utilizzando modelli, metodi di stima e disegni sperimentali vari. Il modello di Rescorla-Wagner è solo una possibile rappresentazione dell’apprendimento associativo, e i suoi parametri possono essere ricavati con procedure differenti. Di conseguenza, il valore numerico che descrive la capacità di apprendimento associativo dipende dal modello, dalla tecnica di stima e dal contesto sperimentale.\nIn conclusione, Lundberg et al. (2021) sottolineano l’importanza di definire l’estimando teorico prima di qualsiasi analisi, e di giustificare in modo chiaro la scelta dello specifico estimando empirico e della strategia di stima adottata. Così facendo, si evidenzia il legame tra teoria e dati, rendendo più trasparenti, coerenti e riproducibili i processi di inferenza statistica.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#introduzione",
    "href": "chapters/eda/10_estimand.html#introduzione",
    "title": "21  Estimandi teorici e estimandi empirici",
    "section": "",
    "text": "Definire un estimando teorico, collegato esplicitamente alla teoria che guida la ricerca.\nTradurre l’estimando teorico in un estimando empirico, cioè una misura concreta, ottenuta dai dati osservabili, che richiede l’adozione di specifiche assunzioni di identificazione.\nStimare l’estimando empirico utilizzando procedure statistiche appropriate, in modo da ricavare inferenze solide a partire dai dati.\n\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\nIn italiano, la traduzione comunemente usata di “estimand” nella letteratura scientifica è estimando. Questo termine viene utilizzato per riferirsi alla quantità o al parametro che si desidera stimare in un’analisi statistica.\nStimatore, invece, è la traduzione di “estimator” e si riferisce alla regola o alla funzione utilizzata per calcolare una stima basata sui dati osservati. Quindi, “estimando” e “stimatore” sono termini distinti: l’“estimando” è l’oggetto dell’inferenza statistica, mentre lo “stimatore” è il metodo o la formula usata per ottenere l’inferenza.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#limiti-dellapproccio-attuale",
    "href": "chapters/eda/10_estimand.html#limiti-dellapproccio-attuale",
    "title": "21  Estimandi teorici e estimandi empirici",
    "section": "21.2 Limiti dell’Approccio Attuale",
    "text": "21.2 Limiti dell’Approccio Attuale\nLundberg et al. (2021) osservano che spesso i ricercatori sociali omettono il passaggio cruciale della definizione dell’estimando, concentrandosi direttamente sui dati e sulle procedure statistiche. Questo approccio può causare una mancanza di chiarezza riguardo a ciò che si intende effettivamente stimare, limitando anche l’uso di modelli statistici alternativi che potrebbero essere più adatti a rispondere alla domanda di ricerca. Sebbene Lundberg et al. (2021) facciano riferimento alla letteratura sociologica, questi stessi argomenti sono applicabili anche alla psicologia.\nIl problema del collegamento tra estimandi teorici ed empirici (si veda la figura seguente) può essere illustrato con un esempio in psicologia riguardante l’intelligenza. La distinzione tra estimandi teorici ed empirici è cruciale: gli estimandi teorici possono includere quantità non osservabili, come i costrutti latenti, ad esempio l’intelligenza come concetto astratto. Gli estimandi empirici, invece, riguardano esclusivamente dati osservabili, come i punteggi ottenuti in un test di intelligenza.\nNel caso dell’intelligenza, la scelta dell’estimando teorico richiede un’argomentazione sostanziale riguardo alla teoria dell’intelligenza adottata e agli obiettivi della ricerca. Ad esempio, se si vuole studiare l’intelligenza generale (fattore g), bisogna chiarire come questo costrutto viene teoricamente definito e perché è rilevante per lo studio.\nD’altra parte, la scelta dell’estimando empirico richiede un’argomentazione concettuale su come i dati osservabili, come i risultati dei test di intelligenza, possano rappresentare il costrutto latente di interesse. È necessario spiegare quali dati vengono utilizzati per inferire il costrutto teorico e quali assunzioni si fanno riguardo al rapporto tra le misure osservate e il costrutto latente.\nInfine, la scelta delle strategie di stima, come l’uso di modelli di equazioni strutturali per stimare l’intelligenza generale da diversi test, è una decisione separata, che può essere in parte guidata dai dati disponibili e dalle caratteristiche della misurazione. Separare chiaramente questi passaggi aiuta i ricercatori a fare scelte informate e fondate, consente ai lettori di valutare in modo critico le affermazioni fatte e permette alla comunità scientifica di costruire su basi solide per futuri sviluppi della ricerca.\n\n\n\nTre Scelte Critiche nelle Argomentazioni delle Scienze Sociali Quantitative. La prima scelta riguarda gli estimandi teorici, che definiscono gli obiettivi dell’inferenza. È necessario un argomento che colleghi gli estimandi teorici alla teoria più ampia. La seconda scelta riguarda gli estimandi empirici, che collegano questi obiettivi ai dati osservabili. Questo collegamento richiede delle assunzioni sostanziali, che possono essere formalizzate attraverso grafici aciclici diretti. La terza scelta riguarda le strategie di stima, che determinano come verranno effettivamente utilizzati i dati. La selezione delle strategie di stima si basa sui dati disponibili (figura tratta da Lundberg et al. (2021)).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#definizione-dellestimando-teorico",
    "href": "chapters/eda/10_estimand.html#definizione-dellestimando-teorico",
    "title": "21  Estimandi teorici e estimandi empirici",
    "section": "21.3 Definizione dell’Estimando Teorico",
    "text": "21.3 Definizione dell’Estimando Teorico\nLa definizione dell’estimando teorico è cruciale per determinare la natura dello studio perché specifica chiaramente quale tipo di relazione tra le variabili stiamo cercando di indagare. In altre parole, l’estimando teorico indica se lo studio mira a descrivere, prevedere o stabilire una relazione causale. Vediamo come questo funziona in pratica con esempi legati all’intelligenza e all’allenamento cognitivo.\n\n21.3.1 Estimando Teorico in uno Studio Descrittivo\nUno studio descrittivo ha come obiettivo semplicemente quello di caratterizzare o descrivere una certa realtà o fenomeno senza inferire relazioni di causa-effetto. In questo caso, l’estimando teorico potrebbe essere una misura che riassume una caratteristica della popolazione.\nEsempio: Qual è il punteggio medio di intelligenza tra le persone che hanno partecipato a un programma di allenamento cognitivo rispetto a quelle che non l’hanno fatto?\nEstimando Teorico: La differenza media nei punteggi di intelligenza tra i due gruppi. Questo tipo di estimando descrive la distribuzione dei punteggi di intelligenza nei gruppi, ma non implica che l’allenamento abbia causato le differenze osservate.\n\n\n21.3.2 Estimando Teorico in uno Studio Predittivo\nUno studio predittivo si concentra sulla capacità di prevedere un risultato basato su dati osservabili. Qui, l’estimando teorico riguarda la capacità del modello di predire correttamente i risultati futuri, ma senza implicazioni causali.\nEsempio: In che misura la partecipazione a un programma di allenamento cognitivo può prevedere il punteggio di intelligenza futuro di una persona?\nEstimando Teorico: La previsione del punteggio di intelligenza basata sulla partecipazione all’allenamento cognitivo. Questo estimando si basa su modelli statistici che utilizzano variabili osservabili per fare previsioni, ma non determinano la causalità tra allenamento e punteggi di intelligenza.\n\n\n21.3.3 Estimando Teorico in uno Studio Causale\nUno studio causale cerca di stabilire un nesso diretto di causa-effetto tra variabili. L’estimando teorico in questo caso riguarda l’effetto diretto di una variabile indipendente su una variabile dipendente, tenendo conto di altre variabili confondenti.\nEsempio: L’allenamento cognitivo causa un aumento nei punteggi di intelligenza?\nEstimando Teorico: La differenza media nei punteggi di intelligenza che si attribuisce direttamente all’effetto dell’allenamento cognitivo, controllando per tutte le altre variabili confondenti. Questo estimando implica l’uso di un disegno di ricerca che isola l’effetto dell’allenamento, come un esperimento con assegnazione casuale.\n\n\n21.3.4 L’Estimando Teorico Chiarisce la Natura dello Studio\nDefinire l’estimando teorico in modo preciso aiuta a chiarire la natura dello studio perché specifica esattamente quale relazione tra le variabili viene studiata:\n\nStudi Descrittivi: L’estimando teorico è una semplice descrizione di dati, come una media o una differenza, senza inferire causalità.\nStudi Predittivi: L’estimando teorico si concentra sulla capacità di un modello di fare previsioni basate sui dati, senza implicazioni causali.\nStudi Causali: L’estimando teorico cerca di determinare l’effetto diretto di una variabile su un’altra, richiedendo un disegno di studio che possa controllare variabili confondenti per isolare la causalità.\n\nIn sintesi, l’estimando teorico orienta il ricercatore nel definire chiaramente se lo scopo dello studio è descrittivo, predittivo o causale, e guida il disegno dello studio e l’analisi dei dati di conseguenza.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#importanza-dei-dag-nel-contesto-degli-estimandi-teorici",
    "href": "chapters/eda/10_estimand.html#importanza-dei-dag-nel-contesto-degli-estimandi-teorici",
    "title": "21  Estimandi teorici e estimandi empirici",
    "section": "21.4 Importanza dei DAG nel Contesto degli Estimandi Teorici",
    "text": "21.4 Importanza dei DAG nel Contesto degli Estimandi Teorici\nNella figura 2 dell’articolo di Lundberg et al. (2021), i Grafici Aciclici Diretti (DAG) vengono utilizzati per illustrare le relazioni causali tra variabili all’interno di uno studio. I DAG sono strumenti visivi che aiutano i ricercatori a rappresentare e comprendere le assunzioni causali sottostanti ai loro studi, fornendo una chiara rappresentazione grafica di come le variabili si influenzano a vicenda. Questo è particolarmente importante quando si definiscono estimandi teorici, perché i DAG consentono di identificare chiaramente le variabili confondenti e di stabilire le relazioni di causalità.\nI DAG possono contribuire alla definizione degli estimandi teorici in molti modi.\n\nChiarificazione delle Relazioni Causali: I DAG aiutano a chiarire quali variabili sono considerate come cause potenziali e quali come effetti. Questo è fondamentale per definire l’estimando teorico, soprattutto in uno studio causale, dove è importante distinguere tra correlazione e causalità. Ad esempio, se si studia l’effetto dell’allenamento cognitivo sull’intelligenza, un DAG può mostrare come l’allenamento influisce direttamente sull’intelligenza, identificando al contempo variabili confondenti come il background educativo o la motivazione.\nIdentificazione delle Variabili Confondenti: Uno dei principali vantaggi dell’utilizzo dei DAG è la loro capacità di identificare le variabili confondenti che possono influenzare entrambe le variabili di interesse. Nel contesto degli estimandi teorici, riconoscere e controllare queste variabili confondenti è cruciale per stabilire una relazione causale valida. Ad esempio, un DAG potrebbe rivelare che la motivazione personale influisce sia sulla partecipazione all’allenamento cognitivo che sui punteggi di intelligenza, indicando che questa variabile deve essere controllata per ottenere un estimando causale corretto.\nGuida nella Costruzione del Disegno di Ricerca: I DAG sono strumenti utili nella pianificazione del disegno di ricerca perché aiutano a determinare quali variabili devono essere misurate e controllate. Definendo chiaramente le relazioni tra le variabili, i ricercatori possono progettare esperimenti o studi osservazionali che minimizzano i bias e migliorano la validità interna dello studio. Ad esempio, un DAG può suggerire la necessità di randomizzare l’assegnazione all’allenamento cognitivo per garantire che l’effetto osservato sui punteggi di intelligenza sia realmente causato dall’allenamento e non da un’altra variabile.\nSupporto nella Selezione delle Strategie di Stima: Una volta definite le relazioni tra le variabili attraverso un DAG, i ricercatori possono scegliere strategie di stima appropriate per gli estimandi teorici ed empirici. Per esempio, se un DAG indica che non ci sono percorsi diretti tra alcune variabili, si possono utilizzare metodi statistici che presuppongono l’indipendenza condizionale, come la regressione lineare o i modelli di equazioni strutturali.\n\nIn sintesi, nel contesto della definizione degli estimandi teorici, i DAG sono strumenti essenziali che consentono ai ricercatori di visualizzare e comprendere le relazioni causali e le variabili confondenti all’interno di uno studio. Essi facilitano la costruzione di disegni di ricerca solidi, la selezione di strategie di stima appropriate e la comunicazione chiara delle assunzioni causali sottostanti. Utilizzando i DAG, i ricercatori possono garantire che gli estimandi teorici siano ben definiti e che le inferenze tratte dai dati siano valide e affidabili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#collegamento-tra-estimando-teorico-ed-empirico",
    "href": "chapters/eda/10_estimand.html#collegamento-tra-estimando-teorico-ed-empirico",
    "title": "21  Estimandi teorici e estimandi empirici",
    "section": "21.5 Collegamento tra Estimando Teorico ed Empirico",
    "text": "21.5 Collegamento tra Estimando Teorico ed Empirico\nLundberg et al. (2021) sottolineano l’importanza di collegare chiaramente l’estimando teorico all’estimando empirico, utilizzando assunzioni sostanziali e metodi appropriati per garantire che le conclusioni tratte dai dati siano valide.\nEstimando Empirico: L’estimando empirico è la quantità che viene effettivamente calcolata dai dati osservati. Mentre l’estimando teorico rappresenta l’obiettivo concettuale dello studio (come l’effetto dell’allenamento cognitivo sull’intelligenza), l’estimando empirico è ciò che viene effettivamente misurato nel contesto dei dati disponibili.\nPer tradurre un estimando teorico in uno empirico, è essenziale formulare assunzioni che rendano possibile l’inferenza causale. Queste assunzioni possono essere formalizzate attraverso l’uso dei Grafici Aciclici Diretti (DAG) per garantire che le variabili confondenti siano adeguatamente controllate. L’identificazione corretta assicura che le conclusioni derivate dai dati osservati siano valide rispetto all’effetto causale che si sta cercando di stimare.\nConsideriamo uno studio psicologico sull’effetto dell’allenamento cognitivo sui punteggi di intelligenza:\n\nEstimando Teorico: Il nostro obiettivo teorico potrebbe essere stimare l’effetto causale dell’allenamento cognitivo sull’aumento del punteggio di intelligenza in una popolazione adulta. L’estimando teorico qui sarebbe la differenza media nei punteggi di intelligenza tra gli individui che hanno partecipato all’allenamento e quelli che non lo hanno fatto, supponendo che l’unica differenza tra i gruppi sia l’allenamento stesso.\nEstimando Empirico: Per passare all’estimando empirico, dobbiamo considerare cosa possiamo effettivamente misurare. Supponiamo di avere dati da un campione di adulti, alcuni dei quali hanno partecipato all’allenamento cognitivo e altri no. L’estimando empirico potrebbe essere la differenza osservata nei punteggi di intelligenza tra questi due gruppi nel campione disponibile.\nAssunzioni per l’Identificazione:\n\nAssunzione di Nessuna Confusione (No Confounding): Dobbiamo assumere che non vi siano variabili non misurate che influenzano sia la partecipazione all’allenamento che i punteggi di intelligenza. Per esempio, la motivazione personale potrebbe influenzare sia la decisione di partecipare all’allenamento che il punteggio di intelligenza. Se questa variabile non è controllata, l’estimando empirico potrebbe sovrastimare o sottostimare l’effetto dell’allenamento.\nAssunzione di Non-Interferenza (Stable Unit Treatment Value Assumption, SUTVA): Dobbiamo assumere che la partecipazione di un individuo all’allenamento non influisca sui punteggi di intelligenza di altri individui. Questa assunzione potrebbe essere violata, ad esempio, se i partecipanti condividono tecniche apprese con amici che non hanno partecipato.\n\nUtilizzo dei DAG per la Chiarificazione:\n\nUn DAG può aiutare a visualizzare queste assunzioni mostrando le relazioni tra le variabili. In un DAG ben costruito, l’allenamento cognitivo influenzerebbe direttamente il punteggio di intelligenza, mentre altre variabili come l’educazione o la motivazione sarebbero rappresentate come confondenti da controllare. Se il DAG indica che ci sono variabili confondenti che non possiamo osservare o misurare, dovremo usare metodi statistici specifici, come i modelli di equazioni strutturali o l’uso di variabili strumentali, per isolare l’effetto dell’allenamento cognitivo.\n\n\nIn sintesi, collegare correttamente l’estimando teorico a uno empirico è un passo cruciale per garantire la validità delle inferenze causali in uno studio. Utilizzando l’esempio relativo all’effetto dell’allenamento cognitivo sull’intelligenza, possiamo vedere come le assunzioni sostanziali e gli strumenti come i DAG siano essenziali per identificare correttamente le relazioni causali e assicurare che i risultati siano interpretabili in modo affidabile.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#dedurre-lestimando-empirico-dai-dati-osservati",
    "href": "chapters/eda/10_estimand.html#dedurre-lestimando-empirico-dai-dati-osservati",
    "title": "21  Estimandi teorici e estimandi empirici",
    "section": "21.6 Dedurre l’Estimando Empirico dai Dati Osservati",
    "text": "21.6 Dedurre l’Estimando Empirico dai Dati Osservati\nDopo aver chiaramente definito l’estimando teorico e stabilito il collegamento con l’estimando empirico attraverso l’identificazione, il passo successivo è utilizzare tecniche statistiche per ottenere stime valide dai dati raccolti.\nRiprendiamo l’esempio psicologico sull’effetto dell’allenamento cognitivo sui punteggi di intelligenza per illustrare come l’approccio bayesiano può essere utilizzato per stimare l’estimando empirico:\n\nDefinizione dell’Estimando Empirico:\n\nL’estimando empirico in questo contesto è la differenza media nei punteggi di intelligenza tra il gruppo di individui che ha partecipato all’allenamento cognitivo e il gruppo che non ha partecipato.\n\nStrategie di Stima Appropriate:\n\nRegressione Lineare: Se ipotizziamo che i punteggi di intelligenza dipendano linearmente dalla partecipazione all’allenamento cognitivo e da altre variabili confondenti controllate, potremmo utilizzare una regressione lineare per stimare l’effetto dell’allenamento. In questa regressione, la partecipazione all’allenamento sarebbe una variabile indipendente, e i punteggi di intelligenza la variabile dipendente.\nMatching: Se i dati disponibili includono molte variabili confondenti misurate, potremmo utilizzare una tecnica di matching per creare coppie di individui simili (matchati) tra i gruppi di trattamento e controllo, basati su queste variabili. Questo metodo aiuta a bilanciare le differenze tra i gruppi che potrebbero influenzare i risultati, cercando di rendere le stime dell’effetto più affidabili.\nPropensity Score Matching: Invece di confrontare direttamente individui basandosi su caratteristiche osservabili, possiamo calcolare un punteggio di propensione per ciascun individuo, che rappresenta la probabilità di partecipare all’allenamento in base alle covariate osservate. Gli individui con punteggi di propensione simili vengono quindi confrontati, aiutando a controllare per le variabili confondenti.\nModelli di Equazioni Strutturali (SEM): Se ci sono molteplici relazioni tra variabili latenti e osservate, un modello di equazioni strutturali può essere utilizzato per stimare simultaneamente questi effetti complessi e isolare l’effetto diretto dell’allenamento cognitivo sui punteggi di intelligenza.\nRandomizzazione: In un disegno sperimentale ideale, l’assegnazione casuale dell’allenamento cognitivo elimina l’influenza delle variabili confondenti, permettendo una stima non distorta dell’effetto causale. Se i dati derivano da un esperimento randomizzato, potremmo semplicemente confrontare le medie dei due gruppi.\n\nInterpreting the Results:\n\nStime Non Distorte: Utilizzando la strategia di stima appropriata, possiamo ottenere una stima non distorta dell’effetto dell’allenamento cognitivo sui punteggi di intelligenza. Ad esempio, se utilizziamo una regressione lineare e controlliamo correttamente per tutte le variabili confondenti, l’effetto stimato rappresenterà l’effetto causale dell’allenamento.\n\n\nLa fase di stima è cruciale per trasformare i dati osservati in stime valide dell’estimando empirico. Nel contesto psicologico dell’allenamento cognitivo e dell’intelligenza, la scelta della strategia di stima appropriata dipende dalle assunzioni fatte sulla causalità e dalla natura dei dati disponibili. Utilizzando tecniche come la regressione, il matching, o i modelli di equazioni strutturali, i ricercatori possono ottenere stime precise e affidabili, garantendo che le conclusioni tratte siano valide e scientificamente robuste.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#implicazioni-per-la-ricerca",
    "href": "chapters/eda/10_estimand.html#implicazioni-per-la-ricerca",
    "title": "21  Estimandi teorici e estimandi empirici",
    "section": "21.7 Implicazioni per la Ricerca",
    "text": "21.7 Implicazioni per la Ricerca\nLundberg et al. (2021) sottolineano l’importanza di una chiara comunicazione e dell’uso del framework presentato per migliorare la pratica della ricerca quantitativa.\n\n21.7.1 Importanza della Trasparenza e della Chiarezza nella Ricerca\nGli autori sottolineano che per garantire la validità e la replicabilità dei risultati di ricerca, è fondamentale che i ricercatori siano trasparenti e chiari su tutte le fasi del loro lavoro. Questo significa esplicitare le assunzioni fatte, il modo in cui l’estimando teorico è stato tradotto in un estimando empirico, e come i dati sono stati analizzati.\nPer esempio, in uno studio sull’effetto di una terapia cognitivo-comportamentale (CBT) sui livelli di ansia, è essenziale che i ricercatori definiscano chiaramente l’estimando teorico, ad esempio, “l’effetto medio della CBT sulla riduzione dell’ansia nella popolazione target di adulti con disturbo d’ansia generalizzato”. Devono poi descrivere come questo estimando è stato misurato empiricamente, ad esempio, utilizzando questionari standardizzati per l’ansia prima e dopo l’intervento. Infine, devono spiegare le assunzioni fatte e le tecniche utilizzate per l’analisi dei dati, come un modello bayesiano per gestire la variabilità individuale nella risposta alla terapia.\n\n\n21.7.2 Benefici dell’Utilizzo di Estimandi Chiaramente Definiti\nL’articolo discute come l’uso di estimandi chiaramente definiti può migliorare la comprensione dei risultati e facilitare il confronto tra studi diversi. Quando i ricercatori definiscono in modo preciso ciò che stanno stimando, diventa più facile per altri replicare lo studio, confrontare risultati e costruire un corpus di conoscenza cumulativo.\nPer esempio, consideriamo due studi sull’efficacia di diversi tipi di training di memoria per migliorare le funzioni cognitive negli anziani. Se entrambi gli studi definiscono chiaramente il loro estimando teorico (ad esempio, “l’effetto del training di memoria verbale sul punteggio del test di memoria a lungo termine”) e empirico (ad esempio, “la differenza media nei punteggi del test di memoria tra il gruppo che ha ricevuto il training e un gruppo di controllo”), sarà più semplice confrontare i risultati e capire quale tipo di training è più efficace.\n\n\n21.7.3 Adattabilità e Flessibilità del Framework\nIl framework proposto dagli autori è adattabile a diversi contesti di ricerca, permettendo ai ricercatori di applicare questi principi in una varietà di studi quantitativi, indipendentemente dal dominio specifico.\nPer esempio, in uno studio che esplora l’effetto della privazione del sonno sulla capacità di attenzione nei bambini, il framework potrebbe essere utilizzato per definire l’estimando teorico come “l’effetto della privazione di 8 ore di sonno sulla capacità di mantenere l’attenzione in attività ripetitive”, e l’estimando empirico potrebbe essere “la differenza media nei punteggi di attenzione tra bambini che hanno dormito 8 ore e quelli che non hanno dormito”. Questo approccio garantisce che le conclusioni siano fondate su basi metodologiche solide e che altri ricercatori possano replicare lo studio per verificare i risultati.\n\n\n21.7.4 Implicazioni per la Ricerca Futura\nL’adozione del framework proposto da Lundberg et al. (2021) per la definizione degli estimandi teorici ed empirici, la chiara identificazione delle assunzioni e l’utilizzo di metodi di stima appropriati può migliorare la qualità e l’affidabilità della ricerca quantitativa nella psicologia e nelle scienze sociali. Questo approccio promuove una pratica di ricerca più rigorosa e trasparente.\nSe la comunità psicologica integrasse questo framework, studi sugli interventi psicologici, come quelli sulla terapia cognitivo-comportamentale (CBT) discusso nell’esempio sopra, potrebbero diventare più comparabili e replicabili. Ciò migliorerebbe la nostra comprensione dell’efficacia e dei limiti di tali interventi. Ad esempio, definendo chiaramente cosa si intende per “efficacia” della CBT (come la riduzione del punteggio su una scala di ansia standardizzata) e utilizzando metodi bayesiani per incorporare dati preesistenti e nuove osservazioni, è possibile ottenere stime più robuste e interpretabili. Queste stime rifletterebbero meglio l’efficacia reale della terapia nella pratica clinica.\nLe proposte di Lundberg et al. (2021) sono in linea con le raccomandazioni di altri studiosi. Andrew Gelman, ad esempio, sottolinea spesso l’importanza di definire con precisione cosa si sta cercando di stimare in un’analisi statistica. Gelman sostiene che una definizione vaga o mal definita dell’estimando teorico può portare a interpretazioni errate e conclusioni fuorvianti. La chiara definizione dell’estimando teorico, come evidenziato nell’articolo di Lundberg et al., è cruciale per determinare se uno studio è descrittivo, predittivo o causale, e per comprendere la natura dell’inferenza da trarre dai dati (Gelman & Imbens, 2013).\nSia McElreath (2020), nel suo testo “Statistical Rethinking,” sia Andrew Gelman, enfatizzano l’importanza dell’utilizzo dei Grafici Aciclici Diretti (DAG) per rappresentare visivamente le assunzioni causali e le relazioni tra variabili in un modello statistico. Questo tipo di approccio aiuta i ricercatori a identificare variabili confondenti e a chiarire le relazioni causali, migliorando così la validità delle inferenze.\nGelman discute anche frequentemente l’importanza della trasparenza nella comunicazione dei risultati di ricerca, un principio centrale anche nell’articolo di Lundberg et al. Egli insiste sul fatto che i ricercatori dovrebbero essere espliciti riguardo alle assunzioni fatte, ai metodi utilizzati e alle limitazioni dei loro studi (Gelman et al., 1995).\nIn sintesi, sia Lundberg et al. che altri ricercatori evidenziano l’importanza di una chiara definizione degli estimandi, dell’uso dei DAG per rappresentare le assunzioni causali e della scelta di strategie di stima appropriate. L’approccio bayesiano, in particolare, offre un metodo potente e flessibile per gestire l’incertezza e aggiornare le inferenze alla luce di nuove evidenze. Adottando queste pratiche, i ricercatori nelle scienze sociali e nella psicologia possono migliorare la validità, la replicabilità e la trasparenza delle loro ricerche, contribuendo a una conoscenza scientifica più solida e affidabile.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#riflessioni-conclusive",
    "href": "chapters/eda/10_estimand.html#riflessioni-conclusive",
    "title": "21  Estimandi teorici e estimandi empirici",
    "section": "21.8 Riflessioni Conclusive",
    "text": "21.8 Riflessioni Conclusive\nIn questo capitolo abbiamo esaminato l’importanza della definizione dell’estimando in uno studio quantitativo, come evidenziato nell’articolo di Lundberg et al. (2021). Il concetto centrale è la distinzione tra estimando teorico ed estimando empirico e il loro collegamento, che facilita l’interpretazione dei risultati e rende l’inferenza statistica più rigorosa.\nL’articolo propone un framework strutturato in tre fasi principali:\n\nDefinire un estimando teorico collegato alla teoria sottostante.\nTradurre questo estimando in un estimando empirico, basato su dati osservabili e assunzioni di identificazione.\nScegliere le strategie di stima adeguate per ottenere stime affidabili.\n\nL’adozione di questo approccio consente di migliorare la chiarezza e la trasparenza nella ricerca, rendendo più facili il confronto tra studi diversi e la replicabilità dei risultati. La corretta definizione dell’estimando guida l’intero processo di ricerca, dalla progettazione dello studio alla scelta delle tecniche di stima e all’interpretazione dei risultati, garantendo che la teoria e le evidenze empiriche siano strettamente collegate.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#bibliografia",
    "href": "chapters/eda/10_estimand.html#bibliografia",
    "title": "21  Estimandi teorici e estimandi empirici",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (1995). Bayesian data analysis. Chapman; Hall/CRC.\n\n\nGelman, A., & Imbens, G. (2013). Why ask why? Forward causal inference and reverse causal questions. National Bureau of Economic Research.\n\n\nLundberg, I., Johnson, R., & Stewart, B. M. (2021). What is your estimand? Defining the target quantity connects statistical evidence to theory. American Sociological Review, 86(3), 532–565.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html",
    "href": "chapters/eda/11_outlier.html",
    "title": "22  Outlier",
    "section": "",
    "text": "22.1 Introduzione\nI dati raccolti nella vita reale spesso contengono osservazioni che, se confrontate con la maggior parte della popolazione, risultano “anomale” o “estreme”. Queste osservazioni, comunemente note come outlier, possono avere cause diverse: ad esempio, potrebbero provenire da un processo generativo differente, oppure essere semplicemente casi estremi ma comunque possibili. Definire i confini tra ciò che è “normale” e ciò che è “anormale” non è semplice.\nUna gestione non adeguata degli outlier può influenzare considerevolmente le stime statistiche, introducendo bias negli effetti misurati e riducendo la capacità predittiva dei modelli. È quindi importante affrontare il problema degli outlier con criteri chiari e strategie riproducibili. Tuttavia, nonostante siano disponibili linee guida consolidate, molti ricercatori non trattano gli outlier in modo coerente, o utilizzano approcci non appropriati (Simmons et al., 2011).\nUno dei motivi potrebbe essere la scarsa consapevolezza delle raccomandazioni esistenti o la difficoltà ad implementarle con il proprio software di analisi. In questo capitolo mostreremo come seguire le buone pratiche correnti per la rilevazione automatica e riproducibile degli outlier (Statistical Outlier Detection, SOD) in R utilizzando il pacchetto {performance} (Lüdecke et al. 2021).\nIl materiale di questo capitolo riassume l’articolo di Thériault et al. (2024).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#identificare-gli-outlier",
    "href": "chapters/eda/11_outlier.html#identificare-gli-outlier",
    "title": "22  Outlier",
    "section": "22.2 Identificare gli Outlier",
    "text": "22.2 Identificare gli Outlier\nMolti ricercatori cercano di identificare gli outlier utilizzando metodi basati sulla media (ad esempio, z-score tradizionali). Tuttavia, questi metodi non sono robusti, poiché sia la media sia la deviazione standard sono sensibili agli stessi outlier e presuppongono una distribuzione normale. Le linee guida attuali raccomandano invece metodi robusti, come quelli che si basano sulla mediana anziché sulla media (Leys et al., 2019).\nLa scelta del metodo di rilevazione outlier dipende però da vari fattori. In alcuni casi potrebbe bastare un’ispezione visiva, ma spesso si preferiscono soluzioni algoritmiche. Inoltre, il metodo da utilizzare può variare in base al tipo di test statistico o al modello di interesse. Ad esempio, nei modelli di regressione ha senso ricercare outlier che non si adattano bene al modello (outlier “model-based”), mentre altre volte si considera la distanza di una singola osservazione dal “centro” della distribuzione (outlier “distribution-based”). Queste strategie possono essere univariate (un’unica variabile) o multivariate (più variabili contemporaneamente).\nIn assenza di metodi ad hoc per modelli complessi (ad es. SEM), può essere utile cercare outlier multivariati. Per test semplici (inferenze su una media, o sul confronto tra medie, o sulle correlazioni), possono essere sufficienti metodi univariati, pur essendo meno flessibili e talvolta più inclini a falsi positivi.\nÈ importante ricordare che qualsiasi scelta resta soggettiva e dev’essere documentata in modo trasparente e riproducibile (Leys et al., 2019). Idealmente, le decisioni andrebbero prese prima della raccolta dei dati (ad esempio in una preregistrazione) e poi riportate chiaramente nell’articolo, menzionando ogni eventuale deviazione dal piano originale.\nNelle sezioni successive illustreremo vari metodi e forniremo esempi di codice R per implementarli.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#outlier-univariati",
    "href": "chapters/eda/11_outlier.html#outlier-univariati",
    "title": "22  Outlier",
    "section": "22.3 Outlier Univariati",
    "text": "22.3 Outlier Univariati\nUn approccio comune è individuare outlier in base alla distanza dal “centro” della distribuzione di una singola variabile. Il metodo dei z-score tradizionali, basati sulla media, non è robusto. Si raccomanda invece di usare la mediana e la Median Absolute Deviation (MAD) (Leys et al., 2019).\nLa funzione check_outliers() del pacchetto {performance}, con method = \"zscore_robust\", consente di individuare outlier secondo questo criterio. Ad esempio, il threshold predefinito è pari a ±3.29 MAD, ma può essere modificato.\nDi seguito un esempio con il dataset mtcars, disponibile in R. Prima creiamo degli outlier artificiali, poi utilizziamo check_outliers().\n\nhead(mtcars)\n#&gt;                    mpg cyl disp  hp drat   wt qsec vs am gear carb\n#&gt; Mazda RX4         21.0   6  160 110 3.90 2.62 16.5  0  1    4    4\n#&gt; Mazda RX4 Wag     21.0   6  160 110 3.90 2.88 17.0  0  1    4    4\n#&gt; Datsun 710        22.8   4  108  93 3.85 2.32 18.6  1  1    4    1\n#&gt; Hornet 4 Drive    21.4   6  258 110 3.08 3.21 19.4  1  0    3    1\n#&gt; Hornet Sportabout 18.7   8  360 175 3.15 3.44 17.0  0  0    3    2\n#&gt; Valiant           18.1   6  225 105 2.76 3.46 20.2  1  0    3    1\n\n\n# Create some artificial outliers and an ID column\ndata &lt;- rbind(mtcars[1:4], 42, 55)\ndata &lt;- cbind(car = row.names(data), data)\n\noutliers &lt;- check_outliers(data, method = \"zscore_robust\", ID = \"car\")\noutliers\n#&gt; 2 outliers detected: cases 33, 34.\n#&gt; - Based on the following method and threshold: zscore_robust (3.291).\n#&gt; - For variables: mpg, cyl, disp, hp.\n#&gt; \n#&gt; -----------------------------------------------------------------------------\n#&gt;  \n#&gt; The following observations were considered outliers for two or more\n#&gt;   variables by at least one of the selected methods:\n#&gt; \n#&gt;   Row car n_Zscore_robust\n#&gt; 1  33  33               2\n#&gt; 2  34  34               2\n#&gt; \n#&gt; -----------------------------------------------------------------------------\n#&gt; Outliers per variable (zscore_robust): \n#&gt; \n#&gt; $mpg\n#&gt;    Row car Distance_Zscore_robust\n#&gt; 33  33  33                   3.71\n#&gt; 34  34  34                   5.85\n#&gt; \n#&gt; $cyl\n#&gt;    Row car Distance_Zscore_robust\n#&gt; 33  33  33                   12.1\n#&gt; 34  34  34                   16.5\n\nQuesti due outlier aggiunti artificialmente vengono rilevati correttamente. Per escluderli dal dataset principale:\n\nwhich(outliers) \n#&gt; [1] 33 34\n# Restituisce i numeri di riga degli outlier\n\n\ndata_clean &lt;- data[-which(outliers), ]\n\nÈ anche possibile visualizzare gli outlier graficamente:\n\nplot(outliers)\n\n\n\n\n\n\n\n\nOltre al metodo MAD, check_outliers() supporta anche altri approcci univariati (basati su IQR, intervalli a densità più alta, ecc.).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#outlier-multivariati",
    "href": "chapters/eda/11_outlier.html#outlier-multivariati",
    "title": "22  Outlier",
    "section": "22.4 Outlier Multivariati",
    "text": "22.4 Outlier Multivariati\nQuando si analizzano più variabili contemporaneamente (ad esempio altezza e peso di un gruppo di persone), può risultare complesso stabilire quali osservazioni siano davvero “fuori dal comune” rispetto alla maggioranza. In questo contesto, la distanza di Mahalanobis offre un modo per individuare outlier multivariati, cioè osservazioni che si discostano notevolmente dal “centro” dei dati considerati nel loro insieme, anziché analizzare ogni variabile separatamente.\nPer comprendere intuitivamente la distanza di Mahalanobis, immaginate di avere una nube di punti che rappresentano individui, ciascuno con i propri valori di altezza e peso. Il “centro” di questa nube è un punto ideale che rappresenta una sorta di media multivariata (tenendo conto sia dell’altezza sia del peso). La distanza di Mahalanobis misura quanto ogni singolo individuo si allontana da questo centro, considerando la variabilità congiunta delle variabili (ad esempio, la correlazione tra altezza e peso). Se un individuo presenta caratteristiche molto diverse rispetto alla maggioranza, la sua distanza di Mahalanobis sarà elevata, segnalando un potenziale outlier.\nTuttavia, la versione classica di questa misura non è particolarmente robusta: la presenza stessa di outlier può distorcere il calcolo del “centro” e della variabilità complessiva, rendendo meno affidabile l’individuazione di altri valori anomali. Per questo motivo, si preferisce utilizzare una variante più resistente, la Minimum Covariance Determinant (MCD), che diminuisce l’influenza degli outlier stessi nel processo di identificazione.\nAll’interno del pacchetto {performance} in R, è possibile applicare questa variante robusta utilizzando la funzione check_outliers() con l’argomento method = \"mcd\". In questo modo, è possibile individuare gli outlier multivariati in maniera più solida e coerente, anche quando si lavora con dati fortemente influenzati da valori estremi.\n\noutliers &lt;- performance::check_outliers(data, method = \"mcd\", verbose = FALSE)\noutliers\n#&gt; 2 outliers detected: cases 33, 34.\n#&gt; - Based on the following method and threshold: mcd (20).\n#&gt; - For variables: mpg, cyl, disp, hp.\n\nSi possono poi visualizzare questi outlier:\n\nplot(outliers)\n\n\n\n\n\n\n\n\nSono disponibili anche altre varianti multivariate documentate nella help page della funzione.\n\n22.4.1 Outlier Basati sul Modello (Model-Based)\nQuando si impiega un modello di regressione, lo scopo principale è capire la relazione tra una o più variabili predittive (ad esempio, il numero di ore di studio) e una variabile di esito (ad esempio, il punteggio a un test). In questi contesti, può capitare che alcuni punti dati, pur essendo veri e propri dati raccolti, esercitino un’influenza eccessiva sulle stime dei parametri del modello, alterando in modo significativo i risultati dell’analisi. Queste osservazioni vengono definite outlier “model-based” proprio perché il criterio per individuarle non è un semplice confronto con la media o la mediana, bensì con le previsioni del modello stesso.\nIn pratica, per ciascuna osservazione si verifica quanto i risultati previsti dal modello (le stime dei valori di esito) cambierebbero se quella specifica osservazione venisse rimossa. Se togliendo uno specifico caso il modello cambia notevolmente, allora quell’osservazione è considerata un outlier model-based. L’idea è che non ci limitiamo a guardare quanto un singolo valore sia “lontano” dagli altri in termini di distribuzione, ma verifichiamo quanto quel valore “tira” i risultati del modello nella sua direzione.\nIl pacchetto {performance} in R fornisce due metodi per individuare questo tipo di outlier. Per i modelli di regressione classici (ad esempio quelli stimati con la funzione lm() in R), è possibile utilizzare Cook’s distance (method = \"cook\"). Cook’s distance misura quanto i risultati del modello si modificherebbero rimuovendo singolarmente ogni osservazione, identificando così i casi che hanno un effetto sproporzionato sulle stime.\nPer i modelli bayesiani, che utilizzano un approccio probabilistico diverso dal classico, è disponibile invece una metrica chiamata Pareto (method = \"pareto\"). Questo indicatore è ottimizzato per valutare la sensibilità dei modelli bayesiani ad alcune osservazioni estreme, segnalando quelle che hanno un impatto potenzialmente troppo forte sulle inferenze.\nIn sintesi, utilizzare un approccio model-based significa considerare gli outlier non soltanto come valori numerici insoliti, ma come casi che, modificando eccessivamente la forma o le conclusioni del modello, ne compromettono la stabilità e l’affidabilità. L’approccio offerto da {performance} permette così di individuare queste osservazioni “critiche” in modo più mirato e consapevole.\n\nmodel &lt;- lm(disp ~ mpg * hp, data = data)\noutliers &lt;- check_outliers(model, method = \"cook\")\noutliers\n#&gt; 2 outliers detected: cases 31, 34.\n#&gt; - Based on the following method and threshold: cook (0.806).\n#&gt; - For variable: (Whole model).\n\nIn questo modo si individuano outlier che hanno un’elevata influenza sul modello.\n\n\n\n\n\n\nTabella di Riferimento\n\n\n\n\n\n\n\n\n\n\n\n\nTipo di Analisi\nMetodo Outlier\nThreshold Suggerito\nCodice\n\n\n\n\nRegressione supportata (lm)\nModel-based (Cook)\nCook: qf(0.5, ...)\ncheck_outliers(model, method=\"cook\")\n\n\nSEM o modello non supportato\nMultivariato (MCD)\nMCD: qchisq(1-0.001, df)\ncheck_outliers(data, method=\"mcd\")\n\n\nTest semplici (t, correlazioni)\nUnivariato (robust z)\n±~3.29 (MAD)\ncheck_outliers(data, method=\"zscore_robust\")\n\n\n\n\n\n\n\n22.4.2 Cook’s Distance vs. MCD\nLeys et al. (2018) suggeriscono di preferire la MCD alla Cook’s distance in presenza di molti outlier, poiché quest’ultima valuta l’impatto della rimozione di un’osservazione alla volta, rischiando così di lasciare il modello ancora “contaminato” da altre osservazioni anomale. D’altro canto, i metodi basati sulla distribuzione possono risultare eccessivamente rigorosi, segnalando come outlier anche casi estremi ma perfettamente in linea con il modello teorico. Quando disponibili, i metodi model-based forniscono dunque una prospettiva più informativa.\n\n\n22.4.3 Approccio Composito (Composite Outlier Score)\nIl pacchetto {performance} permette di combinare diversi metodi per ottenere un punteggio composito, aumentando l’affidabilità della classificazione degli outlier. Ad esempio:\n\noutliers &lt;- check_outliers(\n  model, \n  method = c(\"zscore_robust\", \"mcd\", \"cook\"), \n  verbose = FALSE\n)\nwhich(outliers)\n#&gt; [1] 31 33 34\n\nSi ottengono così osservazioni ritenute outlier da almeno la metà dei metodi utilizzati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#gestione-degli-outlier",
    "href": "chapters/eda/11_outlier.html#gestione-degli-outlier",
    "title": "22  Outlier",
    "section": "22.5 Gestione degli Outlier",
    "text": "22.5 Gestione degli Outlier\nDopo l’identificazione, come gestire gli outlier? Leys et al. (2019) distinguono tra outlier dovuti a errori (da correggere o rimuovere), outlier interessanti (potenzialmente rilevanti dal punto di vista teorico) e outlier casuali (da mantenere se compatibili con la distribuzione di interesse).\nSe gli outlier appartengono realmente alla distribuzione di interesse, vanno mantenuti. Se però provengono da un’altra distribuzione o compromettono la robustezza dei risultati, potrebbe essere giustificata la loro rimozione. In alcuni casi, si può utilizzare la “winsorizzazione”, cioè ridurre i valori estremi entro soglie stabilite, per conservare potenza statistica.\nNel pacchetto easystats, la funzione winsorize() di {datawizard} semplifica questo compito:\n\nwinsorized_data &lt;- winsorize(\n  data, \n  method = \"zscore\", \n  robust = TRUE, \n  threshold = 3\n)",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#importanza-della-trasparenza",
    "href": "chapters/eda/11_outlier.html#importanza-della-trasparenza",
    "title": "22  Outlier",
    "section": "22.6 Importanza della Trasparenza",
    "text": "22.6 Importanza della Trasparenza\nQualunque decisione va documentata chiaramente: quanti outlier sono stati individuati, con quale metodo, a quale threshold, come sono stati gestiti, e preferibilmente con il codice R utilizzato. La preregistrazione e la condivisione dei dati e del codice (ad es. su OSF) sono pratiche consigliate per garantire riproducibilità e trasparenza.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#riflessioni-conclusive",
    "href": "chapters/eda/11_outlier.html#riflessioni-conclusive",
    "title": "22  Outlier",
    "section": "22.7 Riflessioni Conclusive",
    "text": "22.7 Riflessioni Conclusive\nAbbiamo mostrato come identificare gli outlier in modo coerente e trasparente utilizzando la funzione check_outliers() del pacchetto {performance}, allineandoci alle buone pratiche correnti. Tuttavia, la buona pratica non si limita alla scelta degli algoritmi: è fondamentale anche preregistrare le decisioni, essere coerenti, trasparenti e fornire giustificazioni. Speriamo che queste linee guida e gli esempi di codice facilitino l’implementazione di procedure corrette e riproducibili per il trattamento degli outlier.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/11_outlier.html#informazioni-sullambiente-di-sviluppo",
    "title": "22  Outlier",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] datawizard_0.13.0  see_0.9.0          performance_0.12.4\n#&gt;  [4] MASS_7.3-61        viridis_0.6.5      viridisLite_0.4.2 \n#&gt;  [7] ggpubr_0.6.0       ggExtra_0.10.1     gridExtra_2.3     \n#&gt; [10] patchwork_1.3.0    bayesplot_1.11.1   psych_2.4.6.26    \n#&gt; [13] scales_1.3.0       markdown_1.13      knitr_1.49        \n#&gt; [16] lubridate_1.9.3    forcats_1.0.0      stringr_1.5.1     \n#&gt; [19] dplyr_1.1.4        purrr_1.0.2        readr_2.1.5       \n#&gt; [22] tidyr_1.3.1        tibble_3.2.1       ggplot2_3.5.1     \n#&gt; [25] tidyverse_2.0.0    rio_1.2.3          here_1.0.1        \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      xfun_0.49         htmlwidgets_1.6.4 insight_1.0.0    \n#&gt;  [5] rstatix_0.7.2     lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5      \n#&gt;  [9] tools_4.4.2       generics_0.1.3    parallel_4.4.2    fansi_1.0.6      \n#&gt; [13] pacman_0.5.1      pkgconfig_2.0.3   lifecycle_1.0.4   compiler_4.4.2   \n#&gt; [17] farver_2.1.2      munsell_0.5.1     mnormt_2.1.1      carData_3.0-5    \n#&gt; [21] httpuv_1.6.15     htmltools_0.5.8.1 Formula_1.2-5     car_3.1-3        \n#&gt; [25] pillar_1.9.0      later_1.4.1       abind_1.4-8       nlme_3.1-166     \n#&gt; [29] mime_0.12         tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4    \n#&gt; [33] labeling_0.4.3    rprojroot_2.0.4   fastmap_1.2.0     grid_4.4.2       \n#&gt; [37] colorspace_2.1-1  cli_3.6.3         magrittr_2.0.3    utf8_1.2.4       \n#&gt; [41] broom_1.0.7       withr_3.0.2       promises_1.3.2    backports_1.5.0  \n#&gt; [45] timechange_0.3.0  rmarkdown_2.29    ggsignif_0.6.4    hms_1.1.3        \n#&gt; [49] shiny_1.9.1       evaluate_1.0.1    miniUI_0.1.1.1    rlang_1.1.4      \n#&gt; [53] Rcpp_1.0.13-1     xtable_1.8-4      glue_1.8.0        jsonlite_1.8.9   \n#&gt; [57] R6_2.5.1",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/11_outlier.html#bibliografia",
    "href": "chapters/eda/11_outlier.html#bibliografia",
    "title": "22  Outlier",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nLeys, C., Delacre, M., Mora, Y. L., Lakens, D., & Ley, C. (2019). How to classify, detect, and manage univariate and multivariate outliers, with emphasis on pre-registration. International Review of Social Psychology, 32(1).\n\n\nLeys, C., Klein, O., Dominicy, Y., & Ley, C. (2018). Detecting multivariate outliers: Use a robust variant of the Mahalanobis distance. Journal of Experimental Social Psychology, 74, 150–156.\n\n\nSimmons, J. P., Nelson, L. D., & Simonsohn, U. (2011). False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant. Psychological science, 22(11), 1359–1366.\n\n\nThériault, R., Ben-Shachar, M. S., Patil, I., Lüdecke, D., Wiernik, B. M., & Makowski, D. (2024). Check your outliers! An introduction to identifying statistical outliers in R with easystats. Behavior Research Methods, 56(4), 4162–4172.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Outlier</span>"
    ]
  },
  {
    "objectID": "chapters/eda/12_gauss.html",
    "href": "chapters/eda/12_gauss.html",
    "title": "23  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "",
    "text": "23.1 Introduzione\nNell’analisi dei dati numerici, un aspetto cruciale da affrontare è l’imprecisione delle misurazioni, una caratteristica intrinseca dei dati reali. Anche in condizioni ottimali, le misure sono soggette a incertezze: i dati rappresentano sempre una stima approssimativa della realtà, accurata solo entro un certo margine (ad esempio, pochi punti percentuali). Inoltre, in molti contesti, come quelli demografici, commerciali o sociali, i dati possono essere arrotondati intenzionalmente o risultare imprecisi a causa di stime indirette, incompletezza delle informazioni o altri fattori.\nRiconoscere e gestire questa incertezza è una componente essenziale del processo analitico. Gli strumenti statistici forniscono un framework formale per descrivere e quantificare l’incertezza, consentendo di trarre inferenze robuste dai dati. Tra le distribuzioni di probabilità, la distribuzione normale (o gaussiana) occupa un posto centrale per la sua ubiquità e versatilità. Spesso rappresentata dalla caratteristica “curva a campana,” questa distribuzione è utilizzata per descrivere molte variabili naturali. Quando i dati approssimano una distribuzione normale, gran parte dei valori si concentra intorno alla media, con una diminuzione progressiva della probabilità di valori estremi.\nUna delle proprietà più utili della distribuzione normale è la possibilità di esprimere affermazioni quantitative rigorose. Ad esempio, si può calcolare la probabilità che un valore cada entro un determinato intervallo dalla media utilizzando parametri semplici come media (\\(\\mu\\)) e deviazione standard (\\(\\sigma\\)):\npnorm(1) - pnorm(-1)\n#&gt; [1] 0.683\npnorm(3) - pnorm(-3)\n#&gt; [1] 0.997\nQuesti calcoli costituiscono la base della “regola delle tre sigma,” una strategia utilizzata per identificare valori anomali (outlier), come discusso nel Capitolo 22. Tuttavia, tale regola può risultare fuorviante se i dati non seguono effettivamente una distribuzione normale.\nLa densità della distribuzione normale è definita dalla formula:\n\\[\np(x) = \\frac{1}{\\sqrt{2\\pi}\\,\\sigma} \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right),\n\\]\ndove \\(\\mu\\) rappresenta la media e \\(\\sigma\\) la deviazione standard. Conoscere questi due parametri permette di calcolare proprietà fondamentali della distribuzione e di stimare probabilità associate a intervalli specifici.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/12_gauss.html#introduzione",
    "href": "chapters/eda/12_gauss.html#introduzione",
    "title": "23  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "",
    "text": "Circa il 68.3% dei valori cade entro una deviazione standard dalla media:\n\n\n\nCirca il 99.7% cade entro tre deviazioni standard:\n\n\n\n\n\n\n\n23.1.1 Gaussianità e Inferenza Statistica\nLa distribuzione normale è particolarmente rilevante per molti metodi statistici, in particolare nell’approccio frequentista. Gran parte dei test di ipotesi e delle procedure inferenziali assume che i dati siano distribuiti normalmente, una condizione necessaria per derivare formalmente i risultati di molti test. Ad esempio, i test t di Student e l’ANOVA richiedono la normalità delle variabili o dei residui. Quando questa assunzione è soddisfatta, tali strumenti offrono inferenze precise e affidabili.\nTuttavia, se i dati non sono gaussiani, molti test perdono validità. Sebbene si siano proposti approcci che dimostrano la robustezza di alcuni test a deviazioni moderate dalla normalità (Shatz, 2024), tale robustezza non è garantita in tutte le situazioni. Inoltre, l’enfasi sui valori-p complica la questione, poiché violazioni dell’assunzione di normalità possono compromettere l’interpretazione di questi indicatori.\nUna strategia comune per affrontare la non-gaussianità è l’applicazione di trasformazioni dei dati, come la trasformazione logaritmica o quella della radice quadrata, per avvicinare i dati alla distribuzione normale (Osborne, 2002). Ad esempio, distribuzioni asimmetriche come quelle dei tempi di reazione possono essere rese più gaussiane attraverso trasformazioni adeguate, rendendo applicabili i test frequentisti standard. Tuttavia, l’uso delle trasformazioni ha un costo: la perdita di interpretabilità. Se i dati originali avevano un significato chiaro e intuitivo, la trasformazione può rendere i risultati più difficili da collegare al fenomeno studiato.\nIn questo capitolo, esploreremo come verificare se i dati seguono una distribuzione normale, discuteremo l’impatto di questa assunzione sui metodi frequentisti e valuteremo il ruolo delle trasformazioni. Il nostro obiettivo è fornire al data analyst una guida pratica per decidere come trattare i dati non gaussiani, considerando sia i vantaggi che i limiti di ciascun approccio.\n\n\n23.1.2 L’assunzione di Gaussianità: Quando è valida?\nSebbene la distribuzione normale sia spesso un buon modello per i dati numerici, non è sempre una rappresentazione adeguata. Questo può dipendere da caratteristiche intrinseche dei dati, come asimmetrie, code lunghe o la presenza di valori anomali. Valutare l’appropriatezza dell’assunzione di normalità è un passaggio critico in qualsiasi analisi statistica.\nPer diagnosticare la normalità, presenteremo tre strumenti grafici:\n\nIstogrammi, una visualizzazione semplice ma spesso limitata.\nGrafici di densità, che forniscono un confronto più fluido rispetto agli istogrammi.\nQQ-plot (Quantile-Quantile plot), uno strumento visivo particolarmente efficace per rilevare deviazioni dalla normalità.\n\nQuesti strumenti possono anche essere affiancati da test formali per consentire una diagnosi robusta e guidare le decisioni sul trattamento dei dati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/12_gauss.html#istogramma",
    "href": "chapters/eda/12_gauss.html#istogramma",
    "title": "23  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "23.2 Istogramma",
    "text": "23.2 Istogramma\nPer illustrare il concetto, utilizziamo un set di dati simulati che hanno proprietà simili a quelle dei tempi di reazione. Creeremo un istogramma e vi sovrapporremo la curva di densità normale calcolata in base ai dati.\n\n# Dati simulati di tempi di reazione\nset.seed(123)\nrt &lt;- c(rexp(100, rate = 0.2), 50, 60) # Aggiunti valori estremi\n\n# Calcolare la media e la deviazione standard per sovrapporre la densità normale\nmean_rt &lt;- mean(rt, na.rm = TRUE)\nsd_rt &lt;- sd(rt, na.rm = TRUE)\n\n# Creare l'istogramma e sovrapporre la densità normale\nggplot(tibble(rt=rt), aes(x = rt)) +\n  geom_histogram(\n    aes(y = ..density..),\n    bins = 30, color = \"black\", fill = \"lightblue\"\n  ) +\n  stat_function(\n    fun = dnorm,\n    args = list(mean = mean_rt, sd = sd_rt),\n    color = \"red\", size = 1\n  ) +\n  labs(\n    title = \"Istogramma dei Tempi di Reazione\\ne Densità Normale\",\n    x = \"Tempi di Reazione\",\n    y = \"Densità\"\n  )\n#&gt; Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `linewidth` instead.\n#&gt; Warning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `after_stat(density)` instead.\n\n\n\n\n\n\n\n\nL’istogramma mostra la distribuzione empirica dei dati, mentre la curva rossa rappresenta la densità normale con la stessa media e deviazione standard. Nel nostro caso, è evidente una discrepanza tra la distribuzione empirica e la densità normale, indicando che l’assunzione di normalità non è appropriata.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/12_gauss.html#grafico-di-densità",
    "href": "chapters/eda/12_gauss.html#grafico-di-densità",
    "title": "23  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "23.3 Grafico di densità",
    "text": "23.3 Grafico di densità\nUn grafico di densità è una versione lisciata dell’istogramma che facilita il confronto con la distribuzione normale. Utilizzando il dataset precedente, possiamo creare un grafico di densità sovrapposto alla curva gaussiana.\n\nggplot(tibble(rt=rt), aes(x = rt)) +\n  geom_density(color = \"blue\", fill = \"lightblue\", alpha = 0.5) +\n  stat_function(\n    fun = dnorm,\n    args = list(mean = mean_rt, sd = sd_rt),\n    color = \"red\", size = 1\n  ) +\n  labs(\n    title = \"Grafico di Densità del Peso dei Pulcini e\\nDensità Normale\",\n    x = \"Peso\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\n\nAnche questa rappresentazione rende chiaro come l’assunzione di normalità non sia appropriata.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/12_gauss.html#diagramma-quantile-quantile",
    "href": "chapters/eda/12_gauss.html#diagramma-quantile-quantile",
    "title": "23  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "23.4 Diagramma quantile-quantile",
    "text": "23.4 Diagramma quantile-quantile\nIl diagramma quantile-quantile (QQ-plot) è lo strumento più utile per analizzare visivamente la conformità di un dataset a una distribuzione teorica, in particolare alla distribuzione normale. Il QQ-plot è una tecnica essenziale per chi lavora con dati che si presume seguano una distribuzione specifica, e rappresenta un passaggio cruciale in molte analisi statistiche, soprattutto per verificare l’assunto di normalità.\nUn QQ-plot permette di:\n\nValutare graficamente la normalità dei dati: Se i punti nel diagramma seguono approssimativamente una linea retta, i dati possono essere considerati normalmente distribuiti. In caso contrario, il QQ-plot rivela deviazioni dalla normalità, come code pesanti o asimmetrie.\nConfrontare distribuzioni: Il QQ-plot non si limita solo alla distribuzione normale, ma può essere utilizzato per confrontare la distribuzione del campione con qualsiasi distribuzione teorica, facilitando l’analisi di dati con forme di distribuzione complesse.\nIdentificare outlier: Gli outlier nei dati saranno visibili come punti che si discostano significativamente dalla linea retta del QQ-plot.\n\nIl QQ-plot è costruito tracciando i quantili del campione contro i quantili teorici di una distribuzione di riferimento. L’interpretazione è piuttosto semplice:\n\nSe il campione segue la distribuzione teorica, i punti nel QQ-plot si allineano lungo una linea retta di pendenza 1 (e intercetta 0 nel caso di distribuzione normale standardizzata).\nLa deviazione dalla linea retta indica differenze nella distribuzione del campione rispetto alla distribuzione teorica:\n\nIntercetta diversa da 0: indica che la media del campione differisce dalla media della distribuzione teorica.\nPendenza diversa da 1: indica una differenza nella varianza tra il campione e la distribuzione teorica.\nCurve: indicano deviazioni sistematiche, come code pesanti o distribuzioni asimmetriche.\n\n\nNella discussione seguente, costruiremo e analizzeremo QQ-plot per tre casi tipici:\n\nCampione con stessa media e varianza della distribuzione teorica.\nCampione con media diversa ma stessa varianza.\nCampione con media e varianza diverse.\n\nSimuleremo i dati, li ordineremo, calcoleremo manualmente i quantili teorici e infine utilizzeremo librerie specializzate per replicare e confrontare i risultati. Questo approccio pratico ci permetterà di comprendere a fondo l’utilità e il funzionamento del QQ-plot.\n\n23.4.1 Comprendere e Costruire un QQ-Plot (Distribuzione Normale)\nUn QQ-plot (Quantile-Quantile plot) è uno strumento grafico utilizzato per confrontare la distribuzione di un campione con una distribuzione teorica, spesso la distribuzione normale. Il QQ-plot aiuta a visualizzare se un dataset segue una distribuzione specifica, tracciando i quantili del campione contro i quantili della distribuzione teorica.\n\n\n23.4.2 Passi per Costruire un QQ-Plot\n\nOrdinare i Dati: Disporre i dati del campione in ordine crescente.\nDeterminare i Quantili Teorici: Per una distribuzione normale, i quantili corrispondono all’inverso della funzione di distribuzione cumulativa (CDF) della distribuzione normale.\nConfrontare i Quantili: Tracciare i quantili del campione rispetto ai quantili della distribuzione teorica. Se il campione proviene dalla distribuzione teorica, i punti dovrebbero trovarsi approssimativamente su una linea retta.\n\n\n\n23.4.3 Caso 1: Campione con Stessa Media e Varianza della Distribuzione Normale\nSupponiamo che il campione provenga da una distribuzione normale \\(N(\\mu = 0, \\sigma^2 = 1)\\), esattamente come la distribuzione teorica.\n\n23.4.3.1 Simulazione dei Dati\nIniziamo simulando un piccolo dataset da \\(N(0, 1)\\):\n\n# Generiamo 20 punti dati da N(0, 1)\nset.seed(42)  # Per garantire la riproducibilità\ndati_campione &lt;- rnorm(20, mean = 0, sd = 1)\n\n# Ordiniamo i dati del campione\ncampione_ordinato &lt;- sort(dati_campione)\n\n# Calcoliamo i quantili teorici da N(0, 1)\nquantili_teorici &lt;- qnorm((seq(1, 20) - 0.5) / 20)\n\n# Tracciamo il QQ-plot\nplot(quantili_teorici, campione_ordinato,\n     xlab = \"Quantili Teorici\", ylab = \"Quantili del Campione\",\n     main = \"QQ-Plot: Stessa Media e Varianza\", pch = 16)\nabline(0, 1, col = \"red\", lwd = 2)  # Linea y = x\n\n\n\n\n\n\n\n\nIn questo caso, i punti del QQ-plot dovrebbero allinearsi alla linea rossa, indicando che la distribuzione del campione corrisponde a quella teorica.\n\n\n\n\n23.4.4 Caso 2: Campione con Media Diversa (Intercetta ≠ 0)\nSimuliamo un campione da \\(N(2, 1)\\), con una media diversa ma la stessa varianza:\n\n# Generiamo 20 punti dati da N(2, 1)\ndati_campione_media_spostata &lt;- rnorm(20, mean = 2, sd = 1)\n\n# Ordiniamo i dati del campione\ncampione_ordinato_media_spostata &lt;- sort(dati_campione_media_spostata)\n\n# Tracciamo il QQ-plot\nplot(quantili_teorici, campione_ordinato_media_spostata,\n     xlab = \"Quantili Teorici\", ylab = \"Quantili del Campione\",\n     main = \"QQ-Plot: Media Diversa (Intercetta ≠ 0)\", pch = 16)\nabline(0, 1, col = \"red\", lwd = 2)  # Linea y = x\n\n\n\n\n\n\n\n\nIn questo caso, i punti dovrebbero seguire una linea retta ma essere spostati verticalmente, indicando una media diversa (intercetta ≠ 0).\n\n\n\n23.4.5 Caso 3: Campione con Media e Varianza Diverse (Pendenza ≠ 1)\nSimuliamo un campione da \\(N(2, 2^2)\\), con una media e una varianza diverse:\n\n# Generiamo 20 punti dati da N(2, 2^2)\ndati_campione_varianza_spostata &lt;- rnorm(20, mean = 2, sd = 2)\n\n# Ordiniamo i dati del campione\ncampione_ordinato_varianza_spostata &lt;- sort(dati_campione_varianza_spostata)\n\n# Tracciamo il QQ-plot\nplot(quantili_teorici, campione_ordinato_varianza_spostata,\n     xlab = \"Quantili Teorici\", ylab = \"Quantili del Campione\",\n     main = \"QQ-Plot: Media e Varianza Diverse (Pendenza ≠ 1)\", pch = 16)\nabline(0, 1, col = \"red\", lwd = 2)  # Linea y = x\n\n\n\n\n\n\n\n\nIn questo caso, i punti si discosteranno sia verticalmente (per la media diversa) sia rispetto alla pendenza della linea (per la varianza diversa).\n\n\n\n23.4.6 Calcolo Manuale del QQ-Plot\nPer ciascun caso sopra, i passaggi sono i seguenti:\n\nOrdinamento dei dati del campione: Questo fornisce i quantili del campione.\nCalcolo dei quantili teorici: Utilizzando la funzione inversa della CDF per la distribuzione normale.\n\nEsempio in R:\n\n# Calcolo manuale dei quantili teorici\nquantili_teorici_manuali &lt;- function(n) {\n  sapply(1:n, function(i) qnorm((i - 0.5) / n))\n}\n\nn &lt;- length(dati_campione)\nquantili_teorici_calcolati &lt;- quantili_teorici_manuali(n)\nquantili_teorici_calcolati\n#&gt;  [1] -1.9600 -1.4395 -1.1503 -0.9346 -0.7554 -0.5978 -0.4538 -0.3186 -0.1891\n#&gt; [10] -0.0627  0.0627  0.1891  0.3186  0.4538  0.5978  0.7554  0.9346  1.1503\n#&gt; [19]  1.4395  1.9600\n\n\n\n\n23.4.7 Utilizzo di Funzioni Specializzate\nIn R, il pacchetto base offre la funzione qqnorm() per generare QQ-plot. Ad esempio:\n\n# Generazione del QQ-plot con qqnorm\nqqnorm(dati_campione, main = \"QQ-Plot: Stessa Media e Varianza\")\nqqline(dati_campione, col = \"red\", lwd = 2)  # Linea di riferimento\n\n\n\n\n\n\n\n\nPossiamo ripetere lo stesso per i campioni con media e varianza spostate.\n\nQuesto approccio fornisce un’analisi completa della corrispondenza tra distribuzioni teoriche e campioni simulati utilizzando QQ-plot.\nPer concludere, esaminiamo la distribuzione dei tempi di reazione simulati con il qq-plot.\n\nqqnorm(rt, main = \"Tempi di Reazione\")\n\n\n\n\n\n\n\n\nIl diagramma quantile-quantile rende molto chiaro che la distribuzione del peso dei pulcini non è gaussiana.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/12_gauss.html#valutare-la-normalità-test-statistici",
    "href": "chapters/eda/12_gauss.html#valutare-la-normalità-test-statistici",
    "title": "23  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "23.5 Valutare la Normalità: Test Statistici",
    "text": "23.5 Valutare la Normalità: Test Statistici\nSebbene esistano numerosi test statistici formali per valutare la conformità dei dati alla distribuzione normale, questi sono spesso troppo conservativi o sensibili a lievi deviazioni, e nella pratica sono frequentemente sostituiti da metodi visivi più flessibili ed efficaci.\nIn R sono disponibili diversi test per verificare la normalità dei dati. Di seguito presentiamo i più comuni, insieme a un esempio pratico basato sul dataset ChickWeight.\n\n23.5.1 Test di Shapiro-Wilk\nIl test di Shapiro-Wilk è uno dei test più utilizzati per verificare la normalità. Valuta l’ipotesi nulla che i dati seguano una distribuzione normale.\n\nshapiro_test &lt;- shapiro.test(rt)\nshapiro_test\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  rt\n#&gt; W = 0.6, p-value = 5e-16\n\n\nIl p-value è inferiore a 0.05 → Rifiutiamo l’ipotesi nulla, i dati non sono normali.\nIl p-value è maggiore di 0.05 → Non rifiutiamo l’ipotesi nulla, i dati possono essere considerati normali.\n\n\n\n23.5.2 Test di Kolmogorov-Smirnov\nQuesto test confronta la distribuzione cumulativa dei dati con una distribuzione teorica, come la normale. Tuttavia, è meno sensibile rispetto al test di Shapiro-Wilk.\n\nks_test &lt;- ks.test(\n  rt, \n  \"pnorm\", \n  mean = mean(rt), \n  sd = sd(rt)\n)\nks_test\n#&gt; \n#&gt;  Asymptotic one-sample Kolmogorov-Smirnov test\n#&gt; \n#&gt; data:  rt\n#&gt; D = 0.3, p-value = 5e-06\n#&gt; alternative hypothesis: two-sided\n\nIl test di Kolmogorov-Smirnov è più adatto per grandi dataset, ma è noto per essere eccessivamente conservativo.\n\n\n23.5.3 Limitazioni dei test statistici\nNonostante la loro precisione formale, i test statistici per la normalità notevoli limitazioni:\n\nEccessiva sensibilità ai grandi campioni: Quando il campione è ampio, anche lievi deviazioni dalla normalità, non rilevanti per l’analisi, possono portare a un risultato di non-normalità.\nMancanza di sensibilità nei piccoli campioni: Con campioni ridotti, i test possono mancare di potere statistico, portando a falsi negativi (ovvero, non rilevare deviazioni significative dalla normalità).\n\n\nset.seed(123)\nshapiro.test(rchisq(20, 4))\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  rchisq(20, 4)\n#&gt; W = 0.9, p-value = 0.3\n\nIn questo esempio, vediamo come, con un campione di 20 osservazioni da una distribuzione \\(\\chi^2_4\\) si produca un falso negativo.\n\nDifficoltà interpretative: Un p-value elevato non implica che i dati siano esattamente normali; semplicemente, non c’è evidenza sufficiente per rifiutare l’ipotesi di normalità.\n\nI metodi visivi, sebbene meno formali, sono spesso più pratici ed efficaci per diagnosticare deviazioni dalla normalità.I metodi visivi sono preferibili sono preferibili perché\n\nforniscono una diagnosi immediata, che consente di identificare deviazioni rilevanti senza dipendere da un p-value.\nrivelano non solo se i dati non sono normali, ma anche come e dove differiscono dalla normalità (ad esempio, asimmetria o code pesanti).\noffrono indicazioni utili anche in presenza di grandi campioni, dove i test statistici possono risultare eccessivamente conservativi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/12_gauss.html#trasformazione-dei-dati-affrontare-la-non-normalità",
    "href": "chapters/eda/12_gauss.html#trasformazione-dei-dati-affrontare-la-non-normalità",
    "title": "23  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "23.6 Trasformazione dei dati: affrontare la non-normalità",
    "text": "23.6 Trasformazione dei dati: affrontare la non-normalità\nQuando i dati non rispettano l’assunzione di normalità, è possibile utilizzare diverse strategie per affrontare questa violazione. Una delle più comuni è l’uso di trasformazioni dei dati, che permettono di adattare la distribuzione dei dati a una forma più vicina a quella normale, mantenendo comunque la validità dell’analisi che richiede l’assunzione di normalità. Due approcci comuni sono Winsorizing e trimming.\n\n23.6.1 Winsorizing e Trimming\nQuesti metodi si concentrano sulla gestione degli outlier, ossia valori estremi che possono distorcere la distribuzione dei dati. Entrambi gli approcci presumono che la non-normalità sia dovuta a dati contaminanti e agiscono in modo differente:\n\nWinsorizing: Sostituisce i valori estremi con valori meno estremi, come i percentili limite della distribuzione.\nTrimming: Rimuove completamente i valori estremi dalla distribuzione.\n\nConsideriamo i seguenti dati di esempio:\n\ndati &lt;- c(\n  1.0, 2.2, 3.0, 3.1, 4.0, 4.0, 4.1, 5.3, 6.5, 8.3,\n  10.9, 20.4, 21.4, 34.\n)\n\n# Winsorizing al 20%\ndati_winsorized &lt;- winsorize(\n  dati,\n  method = \"percentile\", percentile = 20\n)\nprint(dati_winsorized)\n#&gt;  [1]  3.0  3.0  3.0  3.1  4.0  4.0  4.1  5.3  6.5  8.3 10.9 20.4 20.4 20.4\n\n\n# Trimming al 20%\ndati_trimmed &lt;- dati[\n  dati &gt;= quantile(dati, 0.2) & dati &lt;= quantile(dati, 0.8)\n]\nprint(dati_trimmed)\n#&gt; [1]  3.1  4.0  4.0  4.1  5.3  6.5  8.3 10.9\n\n\nDati Winsorized: I valori estremi (inferiori e superiori ai percentili 20° e 80°) sono sostituiti dai valori limite.\nDati Trimmed: I valori fuori dai percentili 20° e 80° sono completamente rimossi.\n\nQuesti metodi riducono l’impatto degli outlier, ma possono introdurre bias se i valori estremi sono effettivamente parte della popolazione target.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/12_gauss.html#trasformazioni-comuni",
    "href": "chapters/eda/12_gauss.html#trasformazioni-comuni",
    "title": "23  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "23.7 Trasformazioni comuni",
    "text": "23.7 Trasformazioni comuni\nQuando i dati non rispettano l’assunzione di normalità, è possibile applicare trasformazioni matematiche per modificarne la forma e migliorare l’adattamento a una distribuzione normale. Di seguito, presentiamo le trasformazioni più utilizzate.\nTrasformazione logaritmica.\nLa trasformazione logaritmica è particolarmente utile per variabili con asimmetria positiva (code lunghe a destra), come i tempi di reazione.\n\n# Trasformazione logaritmica\ndati_log &lt;- log(rt)\nplot(density(dati_log), main = \"Densità dei dati log-transformati\")\n\n\n\n\n\n\n\n\nTrasformazione radice quadrata.\nAdatta per variabili di conteggio o proporzioni con valori vicini a zero.\n\ndati_sqrt &lt;- sqrt(rt)\nplot(density(dati_sqrt), main = \"Densità dei dati trasformati con radice quadrata\")\n\n\n\n\n\n\n\n\nTrasformazione inversa.\nEfficace per dati con forte asimmetria positiva, ma può complicare l’interpretazione.\n\ndati_inv &lt;- 1 / rt\nplot(density(dati_inv), main = \"Densità dei dati trasformati inversamente\")\n\n\n\n\n\n\n\n\nTrasformazione Box-Cox.\nLa trasformazione Box-Cox è una tecnica parametrica che generalizza le precedenti. Utilizza il massimo della verosimiglianza per determinare la trasformazione ottimale per normalizzare i dati. La funzione di trasformazione dipende da un parametro \\(\\lambda\\):\n\\[\ny(\\lambda) =\n\\begin{cases}\n\\frac{y^\\lambda - 1}{\\lambda} & \\text{se } \\lambda \\neq 0, \\\\\n\\log(y) & \\text{se } \\lambda = 0.\n\\end{cases}\n\\]\n\nb &lt;- boxcox(lm(rt ~ 1))\n\n\n\n\n\n\n\n\n\n# Exact lambda\nlambda &lt;- b$x[which.max(b$y)]\nlambda\n#&gt; [1] 0.182\n\nTrasformiamo i dati utilizzando lambda.\n\nrt_boxcox &lt;- (rt^lambda - 1) / lambda\nrt_boxcox |&gt; head()\n#&gt; [1]  1.645  1.168  2.261 -1.568 -1.133  0.479\n\n\nplot(\n  density(rt_boxcox), \n  main = \"Densità dei dati trasformati con Box-Cox\"\n)\n\n\n\n\n\n\n\n\n\n# Generazione del QQ-plot con qqnorm\nqqnorm(rt_boxcox, main = \"QQ-Plot\")\nqqline(rt_boxcox, col = \"red\", lwd = 2) \n\n\n\n\n\n\n\n\n\n\n23.7.1 Pro e contro delle trasformazioni\nVantaggi:\nLe trasformazioni dei dati offrono molteplici benefici nell’analisi statistica. In primo luogo, possono migliorare l’aderenza alla normalità, un requisito fondamentale per l’applicazione di molti test statistici. Inoltre, contribuiscono a stabilizzare la varianza e a mitigare l’impatto dei valori estremi, riducendo il rischio che questi ultimi influenzino eccessivamente i risultati. Tali vantaggi migliorano la robustezza e l’accuratezza delle analisi.\nSvantaggi:\nNonostante i benefici, le trasformazioni presentano limitazioni rilevanti. La perdita di interpretabilità è uno degli aspetti più critici: i risultati su dati trasformati possono risultare meno intuitivi. Ad esempio, in un modello di regressione applicato a dati trasformati con il logaritmo, il coefficiente rappresenta un cambiamento percentuale anziché assoluto, rendendo l’interpretazione meno diretta per i non esperti.\nInoltre, l’applicazione di una trasformazione deve essere attentamente motivata in base alla natura dei dati e agli obiettivi dell’analisi. Una trasformazione inappropriata può introdurre distorsioni indesiderate, compromettendo la validità dei risultati e portando a conclusioni fuorvianti. Per questo motivo, è essenziale valutare attentamente i costi e i benefici della trasformazione nel contesto specifico della ricerca.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/12_gauss.html#riflessioni-conclusive",
    "href": "chapters/eda/12_gauss.html#riflessioni-conclusive",
    "title": "23  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "23.8 Riflessioni Conclusive",
    "text": "23.8 Riflessioni Conclusive\nLa verifica della normalità dei dati e l’eventuale utilizzo di trasformazioni matematiche costituiscono fasi fondamentali nell’analisi statistica. Sebbene i test formali (come Shapiro-Wilk o Kolmogorov-Smirnov) offrano una valutazione strutturata, essi possono risultare troppo sensibili, portando a rigettare l’assunto di normalità anche in presenza di lievi deviazioni non rilevanti dal punto di vista pratico. In questi casi, l’impiego di strumenti visivi—come istogrammi, grafici di densità o QQ-plot—si rivela spesso più informativo e flessibile, consentendo di individuare la natura e l’entità delle deviazioni.\nLe trasformazioni dei dati rappresentano una strategia utile per normalizzare la distribuzione, ma richiedono una scelta oculata. È essenziale verificare che la trasformazione adottata non comprometta il significato teorico della variabile in esame. Quando l’interpretabilità risulta compromessa, potrebbe essere preferibile ricorrere a metodi robusti o modelli alternativi (ad esempio, approcci bayesiani) che non presuppongono la normalità. In definitiva, la decisione finale dipenderà dal contesto di ricerca, dalla natura dei dati e dagli obiettivi analitici, privilegiando sempre un equilibrio tra rigore statistico e interpretabilità dei risultati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/12_gauss.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/12_gauss.html#informazioni-sullambiente-di-sviluppo",
    "title": "23  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] datawizard_0.13.0 MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2\n#&gt;  [5] ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0  \n#&gt;  [9] bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0      markdown_1.13    \n#&gt; [13] knitr_1.49        lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1    \n#&gt; [17] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#&gt; [21] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [25] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      xfun_0.49         htmlwidgets_1.6.4 insight_1.0.0    \n#&gt;  [5] rstatix_0.7.2     lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5      \n#&gt;  [9] tools_4.4.2       generics_0.1.3    parallel_4.4.2    fansi_1.0.6      \n#&gt; [13] pacman_0.5.1      pkgconfig_2.0.3   lifecycle_1.0.4   compiler_4.4.2   \n#&gt; [17] farver_2.1.2      munsell_0.5.1     mnormt_2.1.1      carData_3.0-5    \n#&gt; [21] httpuv_1.6.15     htmltools_0.5.8.1 yaml_2.3.10       Formula_1.2-5    \n#&gt; [25] car_3.1-3         pillar_1.9.0      later_1.4.1       abind_1.4-8      \n#&gt; [29] nlme_3.1-166      mime_0.12         tidyselect_1.2.1  digest_0.6.37    \n#&gt; [33] stringi_1.8.4     labeling_0.4.3    rprojroot_2.0.4   fastmap_1.2.0    \n#&gt; [37] grid_4.4.2        colorspace_2.1-1  cli_3.6.3         magrittr_2.0.3   \n#&gt; [41] utf8_1.2.4        broom_1.0.7       withr_3.0.2       backports_1.5.0  \n#&gt; [45] promises_1.3.2    timechange_0.3.0  rmarkdown_2.29    ggsignif_0.6.4   \n#&gt; [49] hms_1.1.3         shiny_1.9.1       evaluate_1.0.1    miniUI_0.1.1.1   \n#&gt; [53] rlang_1.1.4       Rcpp_1.0.13-1     xtable_1.8-4      glue_1.8.0       \n#&gt; [57] jsonlite_1.8.9    R6_2.5.1",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/12_gauss.html#bibliografia",
    "href": "chapters/eda/12_gauss.html#bibliografia",
    "title": "23  Assunzione di gaussianità e trasformazioni dei dati",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nOsborne, J. (2002). Notes on the use of data transformations. Practical Assessment, Research, and Evaluation, 8(1).\n\n\nShatz, I. (2024). Assumption-checking rather than (just) testing: The importance of visualization and effect size in statistical diagnostics. Behavior Research Methods, 56(2), 826–845.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Assunzione di gaussianità e trasformazioni dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/13_pixi.html",
    "href": "chapters/eda/13_pixi.html",
    "title": "24  Flusso di lavoro riproducibile",
    "section": "",
    "text": "24.1 Introduzione\nIn questo capitolo esploreremo gli strumenti essenziali per garantire che il flusso di lavoro di un progetto di analisi dei dati in R sia pienamente riproducibile.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Flusso di lavoro riproducibile</span>"
    ]
  },
  {
    "objectID": "chapters/eda/13_pixi.html#analisi-e-flussi-di-lavoro-riproducibili",
    "href": "chapters/eda/13_pixi.html#analisi-e-flussi-di-lavoro-riproducibili",
    "title": "24  Flusso di lavoro riproducibile",
    "section": "24.2 Analisi e Flussi di Lavoro Riproducibili",
    "text": "24.2 Analisi e Flussi di Lavoro Riproducibili\nLa possibilità di confermare ripetutamente i risultati scientifici attraverso la replica è un principio fondamentale della scienza. Questo concetto si basa sull’idea che una verità scientifica debba resistere a ulteriori indagini da parte di altri osservatori. In ambito scientifico, è utile distinguere due aspetti legati alla replica: replicabilità e riproducibilità.\n\nReplicabilità: si riferisce alla capacità di ottenere risultati simili con dati diversi, ma seguendo lo stesso protocollo sperimentale.\nRiproducibilità: indica la capacità di ottenere gli stessi risultati utilizzando gli stessi dati e lo stesso metodo di analisi, sia dalla stessa persona che da altri.\n\n\n24.2.1 Riproducibilità dei Dati\nLa replicazione di esperimenti fisici può presentare difficoltà pratiche significative. Tuttavia, anche riprodurre semplicemente un’analisi dei dati, che sembra un compito più semplice, è spesso problematico per molteplici ragioni. Tradizionalmente, i ricercatori annotavano scrupolosamente i dettagli sperimentali nei loro taccuini di laboratorio, consentendo di replicare l’esperimento. Oggi, strumenti software moderni permettono di applicare lo stesso principio alla riproduzione dei dati: tutto il necessario per rifare l’analisi deve essere documentato in modo chiaro e centralizzato.\nQuesti strumenti non solo facilitano la ripetizione dell’analisi, ma permettono anche di migliorarla e applicarla facilmente a nuovi dati. Tuttavia, per essere riproducibile, l’analisi deve essere scritta in modo appropriato, utilizzando ambienti di programmazione statistica come R o Python, che permettono l’automazione del processo. Al contrario, software come i fogli di calcolo non sono adatti a garantire riproducibilità, perché legano i comandi a celle specifiche, rendendo l’adattamento a nuovi dati complesso e soggetto a errori.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Flusso di lavoro riproducibile</span>"
    ]
  },
  {
    "objectID": "chapters/eda/13_pixi.html#la-crisi-della-replicazione-e-la-riproducibilità",
    "href": "chapters/eda/13_pixi.html#la-crisi-della-replicazione-e-la-riproducibilità",
    "title": "24  Flusso di lavoro riproducibile",
    "section": "24.3 La Crisi della Replicazione e la Riproducibilità",
    "text": "24.3 La Crisi della Replicazione e la Riproducibilità\nLa crisi della replicazione evidenzia un problema crescente nella scienza moderna: molti studi pubblicati, anche sottoposti a peer review, non sono replicabili. Studi come quello di Ioannidis (2005) e Baker (2016) denunciano che molte ricerche sperimentali e statistiche non resistono alla verifica di altri ricercatori. Questo significa che, nonostante l’apparente validità dei risultati, spesso non è possibile raggiungere le stesse conclusioni ripetendo lo studio.\nTra le cause di questa crisi figurano problematiche complesse come la molteplicità e i percorsi analitici alternativi (il cosiddetto garden of forking paths). Tuttavia, indipendentemente da queste difficoltà, un’analisi riproducibile è un requisito minimo per garantire la validità dei risultati.\n\n\n\n\n\n\nNota\n\n\n\nUn problema che compromette la solidità delle conclusioni di molti studi è stato definito da Andrew Gelman, della Columbia University, come il garden of forking paths (giardino dei sentieri che si biforcano). La maggior parte delle analisi richiede una serie di decisioni su come codificare i dati, identificare i fattori rilevanti e formulare (e successivamente rivedere) i modelli prima di arrivare alle analisi finali. Questo processo implica spesso l’esame dei dati per costruire una rappresentazione parsimoniosa. Ad esempio, un predittore continuo potrebbe essere suddiviso arbitrariamente in gruppi per valutare la relazione con l’esito, oppure alcune variabili potrebbero essere incluse o escluse da un modello di regressione durante una fase esplorativa.\nQuesto approccio tende a favorire risultati dei test di ipotesi che sono distorti verso il rigetto dell’ipotesi nulla, poiché le decisioni prese durante il processo possono privilegiare segnali più forti (o p-value più piccoli) rispetto ad altre alternative. Nella maggior parte dei problemi di data science, questo rappresenta una sfida importante che solleva dubbi sulla riproducibilità dei risultati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Flusso di lavoro riproducibile</span>"
    ]
  },
  {
    "objectID": "chapters/eda/13_pixi.html#elementi-chiave-per-un-workflow-riproducibile",
    "href": "chapters/eda/13_pixi.html#elementi-chiave-per-un-workflow-riproducibile",
    "title": "24  Flusso di lavoro riproducibile",
    "section": "24.4 Elementi chiave per un workflow riproducibile",
    "text": "24.4 Elementi chiave per un workflow riproducibile\nUn flusso di lavoro riproducibile si compone di tre elementi fondamentali:\n\nAmbienti di programmazione statistica scriptabili: software come R o Python consentono di automatizzare le analisi e ridurre gli errori manuali.\nAnalisi riproducibili: basate sull’approccio della literate programming, dove codice e documentazione sono integrati per garantire trasparenza e comprensione.\nControllo di versione: sistemi come Git e piattaforme come GitHub permettono di monitorare e documentare i cambiamenti, favorendo la collaborazione e la tracciabilità.\n\nIntegrare questi componenti nella pratica quotidiana non solo migliora la qualità delle analisi, ma contribuisce a rafforzare la fiducia nella scienza.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Flusso di lavoro riproducibile</span>"
    ]
  },
  {
    "objectID": "chapters/eda/13_pixi.html#gestione-del-workflow",
    "href": "chapters/eda/13_pixi.html#gestione-del-workflow",
    "title": "24  Flusso di lavoro riproducibile",
    "section": "24.5 Gestione del Workflow",
    "text": "24.5 Gestione del Workflow\nL’utilizzo di R per scrivere script che documentano le analisi dei dati è un importante passo avanti verso la riproducibilità, ma non garantisce automaticamente che il progetto possa essere replicato con successo da altri ricercatori. A conferma di ciò, uno studio condotto da Obels et al. (2020) ha analizzato la condivisione di dati e codice per articoli pubblicati come Registered Reports nella letteratura psicologica tra il 2014 e il 2018. Tentando di riprodurre i risultati principali di ciascun articolo, hanno osservato quanto segue:\n\n“Abbiamo esaminato dati e script condivisi per i Registered Reports pubblicati nella letteratura psicologica dal 2014 al 2018 e tentato di riprodurre computazionalmente i risultati principali di ciascun articolo. Dei 62 articoli che soddisfacevano i nostri criteri di inclusione, 41 mettevano a disposizione i dati e 37 gli script di analisi. Dati e codice erano condivisi per 36 articoli. Siamo riusciti a eseguire gli script per 31 analisi e a riprodurre i risultati principali di 21 articoli. Sebbene la percentuale di articoli con dati e codice condivisi (58%) e quella degli articoli riproducibili computazionalmente (58%) siano relativamente alte rispetto ad altri studi, c’è un evidente margine di miglioramento.”\n\nQuesti risultati evidenziano come, anche con dati e codice disponibili, la riproducibilità non sia garantita. Gli script possono essere incompleti o l’ambiente di sviluppo originale potrebbe non essere replicabile da altri ricercatori.\n\n24.5.1 Strumenti per la Gestione del Workflow\nPer migliorare la riproducibilità, esistono diversi strumenti per la gestione del workflow, che permettono di strutturare i progetti in modo chiaro e ripetibile:\n\nMake: uno strumento storico per sistemi Unix, noto per la sua portabilità e la presenza predefinita su molti sistemi.\nSnakemake: popolare in biologia, offre flessibilità nella gestione di workflow complessi.\ntargets: specifico per R, consente una gestione semplice ed efficace di workflow riproducibili in progetti di analisi dati.\nPixi: un workflow manager innovativo basato sull’ecosistema Conda.\n\nQuesti strumenti aiutano a coordinare i diversi passaggi di un’analisi, mantenendo traccia dei file e garantendo che ogni fase del processo sia ripetibile.\n\n24.5.1.1 Limiti degli Strumenti di Workflow Management\nL’adozione di strumenti per la gestione del workflow richiede un certo investimento iniziale. Oltre a scrivere gli script per l’analisi dei dati, è necessario sviluppare ulteriori script per definire il workflow, riorganizzando il progetto per garantire riproducibilità. Questo processo può rendere più complesso il debug e le modifiche successive, motivo per cui alcuni ricercatori possono trovare impegnativo integrare tali strumenti.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Flusso di lavoro riproducibile</span>"
    ]
  },
  {
    "objectID": "chapters/eda/13_pixi.html#funzioni-e-astrazione",
    "href": "chapters/eda/13_pixi.html#funzioni-e-astrazione",
    "title": "24  Flusso di lavoro riproducibile",
    "section": "24.6 Funzioni e Astrazione",
    "text": "24.6 Funzioni e Astrazione\nIl pacchetto targets è uno strumento per R che semplifica la gestione dei workflow riproducibili. La sua utilità emerge soprattutto nei progetti complessi, dove il codice può diventare lungo e difficile da gestire.\n\n24.6.1 Gestione di codice lungo e complesso\nNel contesto di analisi dati, il codice può includere diverse sezioni che svolgono compiti specifici e spesso ripetuti, come l’importazione dei dati, la pulizia, l’analisi e la generazione di report. Man mano che il progetto cresce, tenere traccia delle diverse parti del codice e farle funzionare in sequenza può diventare complicato.\nUn codice ben scritto deve essere chiaro e comunicare il suo scopo in modo efficace. La trasparenza aumenta la possibilità che il codice sia compreso, sia dagli altri ricercatori sia da te stesso in futuro.\nUn modo efficace per affrontare la complessità è suddividere il codice in funzioni, utilizzando il concetto di astrazione per ridurre la complessità e migliorare la leggibilità.\n\n\n24.6.2 Funzioni: Gestire la Complessità\nUna funzione è un blocco di codice che realizza un compito specifico. Le funzioni permettono di evitare ripetizioni, rendendo il codice più compatto e leggibile. In R esistono molte funzioni integrate, come mean() per calcolare la media aritmetica, ma, come abbiamo visto in precedenza, è possibile scrivere funzioni personalizzate per compiti specifici.\nLe funzioni devono essere il più generali possibile per favorirne il riutilizzo in diversi progetti.\n\n\n24.6.3 Il Concetto di Astrazione\nL’astrazione consiste nel suddividere il codice complesso in compiti più piccoli e specifici, delegando i dettagli a funzioni. Questo approccio semplifica la struttura del codice principale (main script), rendendolo più leggibile e autoesplicativo (Filazzola & Lortie, 2022).\nNel main script, le funzioni sono richiamate in sequenza, mentre i dettagli sono “nascosti” nei file che contengono le definizioni delle funzioni. Ad esempio:\n\n24.6.3.1 Main Script:\nlibrary(tidyverse)\nlibrary(here)\n\nsource(\"R/functions.R\")\n\n# Importa e pulisci i dati\nraw_data &lt;- read_csv(here(\"data/raw_data.csv\"))\ncleaned_data &lt;- clean_data(raw_data)\n\n# Modello\nmy_model &lt;- fit_model(data = cleaned_data, response = \"Value\", predictor = \"Gradient\")\nsummary(my_model)\n\n# Grafico\nmy_plot &lt;- make_plot(cleaned_data)\n\n\n24.6.3.2 Script delle Funzioni:\nclean_data &lt;- function(data){\n  data |&gt; \n    filter(!is.na(Value)) |&gt; \n    mutate(Gradient = recode(Gradient, \"C\" = \"Control\", \"B\" = \"Treatment\")) |&gt; \n    filter(Taxon == \"SpeciesA\")\n}\n\nfit_model &lt;- function(data, response, predictor){\n  lm(as.formula(paste(response, \"~\", predictor)), data = data)\n}\n\nmake_plot &lt;- function(data){\n  ggplot(data, aes(x = Gradient, y = Value)) +\n    geom_boxplot()\n}\nQuesta separazione migliora la leggibilità, la modularità e la riutilizzabilità del codice.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Flusso di lavoro riproducibile</span>"
    ]
  },
  {
    "objectID": "chapters/eda/13_pixi.html#introduzione-a-targets",
    "href": "chapters/eda/13_pixi.html#introduzione-a-targets",
    "title": "24  Flusso di lavoro riproducibile",
    "section": "24.7 Introduzione a targets",
    "text": "24.7 Introduzione a targets\ntargets è uno strumento per la gestione di pipeline in R, progettato per coordinare i diversi passaggi di un’analisi dati. Permette di automatizzare e ottimizzare il workflow, gestire le dipendenze tra i vari step, e tenere traccia degli oggetti obsoleti che necessitano di essere aggiornati. Una delle sue caratteristiche chiave è la capacità di evitare inutili ripetizioni, riducendo i tempi di esecuzione.\nIn una pipeline di targets, ogni passaggio rappresenta un “target”, che può essere un oggetto R come un dataset, un modello o una figura. Ogni target è generato da una funzione e la pipeline viene orchestrata da uno script principale chiamato _targets.R, che tiene traccia delle dipendenze tra i target e ne garantisce l’esecuzione nell’ordine corretto.\nQuesta struttura è coerente con il concetto di astrazione: suddividere il codice complesso in compiti più semplici e ben definiti.\n\n24.7.1 Quando utilizzare targets?\n\nCodice complesso o con lunghi tempi di esecuzione: Quando il codice richiede molto tempo per essere elaborato, targets evita di rieseguire le parti già aggiornate e supporta l’elaborazione in parallelo, ottimizzando i tempi di calcolo.\n\nWorkflow con dipendenze tra i passaggi: Se il flusso di lavoro include step interconnessi, targets semplifica la gestione delle dipendenze, garantendo che ogni step sia eseguito nell’ordine corretto.\n\nRiproducibilità dell’analisi: Automatizza il controllo dell’allineamento tra codice, dati e risultati, assicurando che il workflow sia sempre coerente e riproducibile.\n\nIn breve, targets consente di creare pipeline di analisi dati riproducibili e scalabili, migliorando l’efficienza e la gestione del workflow in R. Per un approfondimento pratico, è possibile consultare il tutorial disponibile nella pagina web The {targets} R package user manual.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Flusso di lavoro riproducibile</span>"
    ]
  },
  {
    "objectID": "chapters/eda/13_pixi.html#pixi",
    "href": "chapters/eda/13_pixi.html#pixi",
    "title": "24  Flusso di lavoro riproducibile",
    "section": "24.8 Pixi",
    "text": "24.8 Pixi\nOltre a targets, vale la pena citare Pixi, un moderno workflow manager progettato per semplificare la gestione dei flussi di lavoro nei progetti di analisi dati. Pixi si distingue per la sua semplicità d’uso e la capacità di affrontare le sfide legate alla riproducibilità e all’organizzazione di progetti complessi.\nPixi è un gestore di pacchetti rapido e versatile, basato sull’ecosistema Conda, che facilita la creazione e la gestione di ambienti di sviluppo su piattaforme come Windows, macOS e Linux. Supporta un’ampia gamma di linguaggi di programmazione, tra cui Python, R, C/C++, Rust e Ruby, offrendo una grande flessibilità per progetti interdisciplinari. Una delle sue caratteristiche principali è la possibilità di creare ambienti riproducibili senza la complessità aggiuntiva di strumenti come Docker, riducendo così i tempi e gli sforzi necessari per configurare e mantenere il progetto.\nCon Pixi, una configurazione iniziale ben organizzata permette di concentrare le energie sull’analisi dei dati e sulla produzione di risultati, garantendo al contempo un workflow riproducibile e ben strutturato. Questo lo rende uno strumento ideale per migliorare l’efficienza e l’affidabilità dei progetti di analisi dati.\n\n24.8.1 Installazione di Pixi\nPer utilizzare Pixi, è necessario avere installati R, RStudio e Pixi stesso. L’installazione di Pixi è semplice seguendo le indicazioni ufficiali. Per installare Pixi, è sufficiente eseguire il seguente comando nel terminale:\ncurl -fsSL https://pixi.sh/install.sh | bash\n\n\n24.8.2 Struttura del Progetto\nImmaginiamo che il progetto segua questa struttura organizzativa:\ndata-analysis-project/\n│\n├── pixi.toml               # File di configurazione Pixi\n├── pixi.lock               # Lockfile per le dipendenze\n│\n├── data/                   # Directory per i dati\n│   ├── raw/                # Dati grezzi\n│   └── processed/          # Dati processati\n│\n├── src/                    # Codice sorgente in R\n│   ├── data_cleaning.R     # Script per pulizia dei dati\n│   ├── analysis.R          # Script per analisi\n│   └── visualization.R     # Script per visualizzazioni\n│\n├── reports/                # Report e output\n│   ├── figures/            # Figure generate\n│   └── report.Rmd          # Report in R Markdown\n│\n└── README.md               # Documentazione del progetto\n\n\n\n24.8.3 Configurazione di Pixi\nPer configurare Pixi, si crea un file pixi.toml nella directory principale del progetto:\n[project]\nname = \"r-data-analysis\"\ndescription = \"Progetto di analisi dati con R\"\nauthors = [\"Tuo Nome &lt;tua.email@example.com&gt;\"]\nchannels = [\"conda-forge\"]\nplatforms = [\"osx-64\", \"linux-64\",\"win-64\"]\n\n[dependencies]\nr-base = \"&gt;=4.3,&lt;5\"\nr-tidyverse = \"*\"\nr-rio= \"*\"\nr-knitr = \"*\"\nr-rmarkdown = \"*\"\nr-here = \"*\"\n\n[tasks]\nclean = \"rm -rf reports/figures/* data/processed/*\"\ndata-prep = \"Rscript src/data_cleaning.R\"\nanalysis = \"Rscript src/analysis.R\"\nreport = \"Rscript -e 'rmarkdown::render(\\\"reports/report.Rmd\\\")'\"\nall = { depends-on = [\"clean\", \"data-prep\", \"analysis\", \"report\"] }\n\n\n24.8.4 Script di Pulizia Dati (src/data_cleaning.R)\nUno script per pulire e organizzare i dati grezzi:\nlibrary(readr)\nlibrary(dplyr)\n\n# Caricamento dati grezzi\nraw_data &lt;- read_csv(\"data/raw/dati_esempio.csv\")\n\n# Pulizia e trasformazione dei dati\ncleaned_data &lt;- raw_data %&gt;%\n  filter(!is.na(valore)) %&gt;%\n  mutate(categoria = factor(categoria)) %&gt;%\n  group_by(categoria) %&gt;%\n  summarise(media = mean(valore, na.rm = TRUE))\n\n# Salvataggio dei dati processati\nwrite_csv(cleaned_data, \"data/processed/dati_puliti.csv\")\n\n\n24.8.5 Script di Analisi (src/analysis.R)\nUno script per eseguire analisi statistiche e creare visualizzazioni:\nlibrary(readr)\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# Caricamento dei dati processati\ndati &lt;- read_csv(\"data/processed/dati_puliti.csv\")\n\n# Analisi statistica\nrisultati_analisi &lt;- dati %&gt;%\n  group_by(categoria) %&gt;%\n  summarise(\n    media = mean(media),\n    deviazione_standard = sd(media)\n  )\n\n# Salvataggio dei risultati\nwrite_csv(risultati_analisi, \"reports/risultati_analisi.csv\")\n\n# Creazione di un grafico\ngrafico &lt;- ggplot(dati, aes(x = categoria, y = media)) +\n  geom_bar(stat = \"identity\") +\n  ggtitle(\"Media per Categoria\")\n\n# Salvataggio del grafico\nggsave(\"reports/figures/media_categoria.png\", plot = grafico)\n\n\n24.8.6 Creazione di un Report (reports/report.Rmd)\nUn report generato con R Markdown per presentare i risultati dell’analisi:\n---\ntitle: \"Report di Analisi dei Dati\"\noutput: html_document\n---\n\n## Risultati dell'Analisi\n\n```\nlibrary(readr)\nlibrary(knitr)\nrisultati &lt;- read_csv(\"reports/risultati_analisi.csv\")\nkable(risultati)\n```\n\n## Grafico delle Medie per Categoria\n\n![Media per Categoria](figures/media_categoria.png)\n\n\n24.8.7 Esecuzione del Workflow con Pixi\nUna volta installato Pixi, puoi inizializzare un nuovo progetto con:\n# Inizializzazione del progetto\npixi init\nPer installare le dipendenze specificate in in pixi.toml, esegui:\n# Installazione delle dipendenze specificate in pixi.toml\npixi install\nQuesto comando crea un file pixi.lock che elenca tutte le dipendenze del progetto, garantendo che l’ambiente possa essere ricreato in modo identico su diverse macchine.\nPer eseguire le attività definite, utilizza:\npixi run data-prep\npixi run analysis\npixi run report\nOppure, per eseguire tutte le attività in sequenza:\npixi run all\nIl codice utilizzato in questo tutorial è disponibile nel repository GitHub dedicato.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Flusso di lavoro riproducibile</span>"
    ]
  },
  {
    "objectID": "chapters/eda/13_pixi.html#riflessioni-conclusive",
    "href": "chapters/eda/13_pixi.html#riflessioni-conclusive",
    "title": "24  Flusso di lavoro riproducibile",
    "section": "24.9 Riflessioni Conclusive",
    "text": "24.9 Riflessioni Conclusive\nStrumenti di workflow management come targets e Pixi offrono soluzioni efficaci per semplificare e ottimizzare la gestione dei progetti di analisi dati in R. Automatizzando i flussi di lavoro, questi strumenti garantiscono riproducibilità, coerenza e organizzazione, riducendo la possibilità di errori. Una configurazione iniziale ben strutturata consente di focalizzarsi sull’analisi e sull’interpretazione dei dati, massimizzando l’efficienza e migliorando la qualità complessiva del processo.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Flusso di lavoro riproducibile</span>"
    ]
  },
  {
    "objectID": "chapters/eda/13_pixi.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/13_pixi.html#informazioni-sullambiente-di-sviluppo",
    "title": "24  Flusso di lavoro riproducibile",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2 ggpubr_0.6.0     \n#&gt;  [5] ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0   bayesplot_1.11.1 \n#&gt;  [9] psych_2.4.6.26    scales_1.3.0      markdown_1.13     knitr_1.49       \n#&gt; [13] lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4      \n#&gt; [17] purrr_1.0.2       readr_2.1.5       tidyr_1.3.1       tibble_3.2.1     \n#&gt; [21] ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      xfun_0.49         htmlwidgets_1.6.4 rstatix_0.7.2    \n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    fansi_1.0.6       pacman_0.5.1     \n#&gt; [13] pkgconfig_2.0.3   lifecycle_1.0.4   compiler_4.4.2    farver_2.1.2     \n#&gt; [17] munsell_0.5.1     mnormt_2.1.1      carData_3.0-5     httpuv_1.6.15    \n#&gt; [21] htmltools_0.5.8.1 Formula_1.2-5     car_3.1-3         pillar_1.9.0     \n#&gt; [25] later_1.4.1       abind_1.4-8       nlme_3.1-166      mime_0.12        \n#&gt; [29] tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4     rprojroot_2.0.4  \n#&gt; [33] fastmap_1.2.0     grid_4.4.2        colorspace_2.1-1  cli_3.6.3        \n#&gt; [37] magrittr_2.0.3    utf8_1.2.4        broom_1.0.7       withr_3.0.2      \n#&gt; [41] promises_1.3.2    backports_1.5.0   timechange_0.3.0  rmarkdown_2.29   \n#&gt; [45] ggsignif_0.6.4    hms_1.1.3         shiny_1.9.1       evaluate_1.0.1   \n#&gt; [49] miniUI_0.1.1.1    rlang_1.1.4       Rcpp_1.0.13-1     xtable_1.8-4     \n#&gt; [53] glue_1.8.0        jsonlite_1.8.9    R6_2.5.1",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Flusso di lavoro riproducibile</span>"
    ]
  },
  {
    "objectID": "chapters/eda/13_pixi.html#bibliografia",
    "href": "chapters/eda/13_pixi.html#bibliografia",
    "title": "24  Flusso di lavoro riproducibile",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBaker, M. (2016). 1,500 scientists lift the lid on reproducibility. Nature, 533(7604).\n\n\nFilazzola, A., & Lortie, C. (2022). A call for clean code to effectively communicate science. Methods in Ecology and Evolution, 13(10), 2119–2128.\n\n\nIoannidis, J. P. (2005). Why most published research findings are false. PLoS medicine, 2(8), e124.\n\n\nObels, P., Lakens, D., Coles, N. A., Gottfried, J., & Green, S. A. (2020). Analysis of open data and computational reproducibility in registered reports in psychology. Advances in Methods and Practices in Psychological Science, 3(2), 229–237.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Flusso di lavoro riproducibile</span>"
    ]
  },
  {
    "objectID": "chapters/probability/introduction_probability.html",
    "href": "chapters/probability/introduction_probability.html",
    "title": "Introduzione",
    "section": "",
    "text": "Questa sezione della dispensa introduce la teoria della probabilità, una componente essenziale per la ricerca scientifica. Nell’ambito della scienza, l’inferenza induttiva è di fondamentale importanza, e la probabilità svolge un ruolo cruciale in questo processo. Sebbene non possiamo ottenere una certezza assoluta riguardo alla veridicità di un’ipotesi o teoria, possiamo assegnare loro un grado di certezza probabilistica. L’approccio bayesiano utilizza la probabilità per quantificare il grado di fiducia che possiamo attribuire a una determinata proposizione.\nL’inferenza statistica bayesiana mira a quantificare la fiducia nell’ipotesi \\(H\\) dopo aver osservato un dato di evidenza \\(O\\). Per affrontare adeguatamente l’inferenza statistica bayesiana, è quindi essenziale avere una solida comprensione della teoria delle probabilità, almeno nei suoi concetti fondamentali.\nIn questa sezione esamineremo le definizioni di probabilità, la probabilità condizionale e il teorema di Bayes. Approfondiremo inoltre le proprietà delle variabili casuali e le principali distribuzioni di massa e densità di probabilità. Concluderemo presentando la funzione di verosimiglianza, un concetto fondamentale sia nell’inferenza bayesiana sia nell’inferenza frequentista.",
    "crumbs": [
      "Probabilità",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html",
    "href": "chapters/probability/01_intro_prob.html",
    "title": "25  Interpretazione della probabilità",
    "section": "",
    "text": "25.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nNel corso di questo capitolo, esploreremo varie concezioni della probabilità, tra cui la visione classica, frequentista e bayesiana. Inoltre, introdurremo la simulazione con Python per una migliore comprensione della legge dei grandi numeri, un concetto fondamentale nell’ambito della probabilità. Iniziamo introducendo il concetto di causalità.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#introduzione",
    "href": "chapters/probability/01_intro_prob.html#introduzione",
    "title": "25  Interpretazione della probabilità",
    "section": "",
    "text": "“La probabilità è il concetto più importante nella scienza moderna, soprattutto considerando che nessuno ha la minima idea di cosa significhi davvero.” (Attribuito a Bertrand Russell, 1929)\n\n\n\n25.1.1 Il Concetto di Casualità e la Teoria della Probabilità\nLa casualità emerge ogni volta che ci troviamo in una situazione caratterizzata da incertezza, in cui non possiamo prevedere con certezza l’esito di un evento. Questo concetto è fondamentale in molteplici contesti, dai giochi d’azzardo alla ricerca scientifica, e rappresenta un modello che ci aiuta a gestire l’imprevedibilità intrinseca in molti fenomeni. La casualità è il nostro modo di comprendere ciò che è incerto, permettendoci di trattare e quantificare eventi che, pur non potendo essere previsti singolarmente, seguono comunque schemi riconoscibili.\n\n\n25.1.2 L’Urna come Modello di Casualità\nUn modo semplice ma efficace per rappresentare la casualità è il classico modello dell’urna. Immaginiamo un’urna contenente numerose palline identiche, ciascuna numerata consecutivamente. Supponiamo che ogni pallina abbia la stessa probabilità di essere estratta. Definiremo quindi l’estrazione come “casuale”, perché ogni pallina ha uguali possibilità di essere selezionata. In questo contesto, non possiamo anticipare quale pallina verrà estratta, ma sappiamo che ognuna ha la stessa probabilità di esserlo.\nQuesto modello apparentemente semplice, basato sull’equivalenza delle probabilità, rappresenta in realtà l’essenza della casualità. Ci consente di estendere questo concetto per spiegare situazioni molto più complesse, dove possiamo applicare il principio della casualità a fenomeni ben oltre l’estrazione di palline, come il comportamento umano o i risultati di un esperimento scientifico.\n\n\n25.1.3 Applicazioni del Concetto di Casualità\nLa casualità trova applicazione in diversi ambiti, e il modello dell’urna offre una base di comprensione per i seguenti contesti:\n\nGiochi d’azzardo: Per garantire un ambiente “equo” per i giocatori, si cerca di fare in modo che ogni numero o risultato abbia la stessa probabilità di verificarsi. La casualità è qui fondamentale per assicurare che nessun risultato sia predeterminato.\nIndagini statistiche: Nei sondaggi o nelle ricerche demografiche, il campionamento casuale consente di ottenere un campione rappresentativo di una popolazione più ampia, riducendo il rischio di bias di selezione e offrendo inferenze generalizzabili.\nSperimentazione scientifica: La randomizzazione è utilizzata per distribuire casualmente i partecipanti tra i diversi gruppi sperimentali, permettendo così di controllare variabili confondenti e assicurare che le differenze osservate siano imputabili all’intervento e non ad altri fattori.\nCrittografia: Molti sistemi di sicurezza informatica si basano sulla generazione di numeri casuali per creare chiavi crittografiche robuste, che risultino difficili da prevedere e quindi da decifrare.\nSimulazioni: In vari campi scientifici, come la fisica o la psicologia, i modelli basati sulla casualità permettono di simulare sistemi complessi e di fare previsioni sugli esiti possibili.\n\n\n\n25.1.4 Dalla Casualità alla Teoria della Probabilità\nIl concetto di casualità rappresenta il fondamento della teoria della probabilità, che fornisce gli strumenti matematici per quantificare e analizzare rigorosamente l’incertezza. La teoria della probabilità, infatti, consente di trasformare la nostra intuizione della casualità in un modello matematico, attraverso il quale possiamo fare previsioni, calcolare rischi e prendere decisioni in condizioni di incertezza.\nIn particolare, la teoria della probabilità ci permette di:\n\nQuantificare l’incertezza: Assegnando un valore numerico a ciascun esito possibile, possiamo esprimere in modo preciso quanto riteniamo probabile ciascun risultato.\nCombinare informazioni: Attraverso regole matematiche come la somma e il prodotto delle probabilità, possiamo calcolare la probabilità di eventi complessi derivati da eventi più semplici.\nAggiornare le credenze: Quando emergono nuove informazioni, la teoria della probabilità (soprattutto in ambito bayesiano) ci fornisce metodi per aggiornare le nostre stime di probabilità in modo coerente e razionale.\nPrendere decisioni informate: La probabilità ci aiuta a valutare rischi e benefici attesi in situazioni incerte, orientando le nostre scelte in maniera ottimale.\n\n\n\n25.1.5 L’Importanza della Quantificazione dell’Incertezza\nQuantificare l’incertezza attraverso la teoria della probabilità è cruciale in molti campi:\n\nRicerca scientifica: La probabilità permette di valutare la solidità dell’evidenza raccolta a supporto di un’ipotesi.\nPsicologia: In ambito clinico e sperimentale, la probabilità aiuta a valutare l’efficacia dei trattamenti e a prendere decisioni informate su interventi terapeutici.\nEconomia e finanza: La teoria della probabilità è fondamentale per la gestione del rischio e la valutazione di investimenti.\nPrevisioni meteorologiche: Permette di comunicare l’incertezza legata alle previsioni, dando una stima del margine di errore.\n\nIn sintesi, il concetto di casualità e la teoria della probabilità costituiscono strumenti potenti per navigare un mondo intrinsecamente incerto. Forniscono un linguaggio preciso per descrivere l’incertezza e un quadro rigoroso per ragionare su di essa. Comprendere questi concetti è essenziale non solo per matematici o statistici, ma per chiunque desideri prendere decisioni razionali in condizioni di incertezza, che si tratti di ricercatori, psicologi o cittadini comuni.\nNei capitoli seguenti, esploreremo in dettaglio come questi concetti si applicano all’analisi dei dati, con un focus particolare sull’approccio bayesiano. Questo metodo offre un modo naturale e intuitivo di ragionare sull’incertezza, aggiornando progressivamente le conoscenze alla luce di nuove evidenze.\n\n\n25.1.6 Storia e Definizioni della Probabilità\nLa probabilità è un concetto cardine nella matematica e nelle scienze, utilizzato per misurare l’incertezza e studiare fenomeni aleatori. Nel corso del tempo, la sua definizione si è evoluta, passando da intuizioni di tipo qualitativo a formulazioni formali e rigorose.\nLa probabilità nasce dal bisogno di distinguere gli eventi deterministici, il cui esito è prevedibile, da quelli casuali, caratterizzati dall’imprevedibilità. Un evento deterministico, almeno in teoria, produce sempre lo stesso risultato nelle stesse condizioni, mentre un evento casuale ha esiti che non possiamo prevedere con certezza. Questa distinzione ha portato alla necessità di quantificare l’incertezza associata agli eventi casuali, utilizzando il concetto di probabilità.\n\n\n25.1.7 Fonti dell’Incertezza\nL’incertezza nei fenomeni casuali può derivare da due fonti principali:\n\nIncertezza epistemica: Questa forma di incertezza è legata alla nostra conoscenza limitata. Ad esempio, in un esperimento scientifico complesso, la nostra impossibilità di controllare tutte le variabili può introdurre incertezza nei risultati.\nIncertezza ontologica: Si riferisce alla casualità intrinseca di alcuni fenomeni, come in fisica quantistica, dove l’indeterminazione sembra essere una caratteristica fondamentale della realtà stessa. Un esempio intuitivo è il lancio di un dado: indipendentemente da quanto conosciamo le condizioni, non possiamo prevedere con assoluta precisione il risultato.\n\nIl fisico danese Niels Bohr ha offerto un’interpretazione illuminante su questo tema: la fisica, secondo Bohr, non mira a rivelare una verità assoluta sulla natura, ma a capire cosa possiamo dire su di essa. Questa visione riconosce che l’incertezza – sia epistemica che ontologica – riflette i limiti del nostro linguaggio e delle nostre conoscenze. Questo approccio si allinea bene con l’interpretazione soggettiva della probabilità, secondo la quale la probabilità rappresenta il grado di fiducia che un individuo ha riguardo al verificarsi di un evento, basata sulle informazioni di cui dispone.\n\n\n25.1.8 Assiomatizzazione della Probabilità\nNel 1933, il matematico Andrey Kolmogorov fornì una definizione formale della probabilità, introducendo un sistema assiomatico che costituì la base della moderna teoria della probabilità. Questa formulazione ha trasformato la probabilità in una disciplina matematica rigorosa, offrendo uno strumento essenziale per quantificare l’incertezza in contesti scientifici. Da semplice metodo per analizzare i giochi d’azzardo nel XVII secolo, la probabilità è diventata una pietra miliare del ragionamento scientifico, fornendo un linguaggio universale per descrivere e analizzare l’incertezza in numerosi campi del sapere.\n\n\n25.1.9 Interpretazioni Frequentiste e Bayesiane\nLe due principali interpretazioni della probabilità sono:\n\nInterpretazione frequentista: In questo approccio, la probabilità di un evento è definita come il limite della frequenza relativa con cui l’evento si verifica in una lunga serie di esperimenti identici. Questa visione oggettiva considera la probabilità come una proprietà intrinseca del fenomeno, indipendente dalle informazioni dell’osservatore.\nInterpretazione bayesiana: Al contrario, la probabilità è vista come una credenza soggettiva sul verificarsi di un evento. In questa visione, la probabilità rappresenta il grado di fiducia di un osservatore, dipendente dalle informazioni disponibili e dal contesto. L’approccio bayesiano permette quindi di aggiornare le stime probabilistiche man mano che nuove evidenze vengono acquisite, rendendo la probabilità una misura flessibile della conoscenza.\n\n\n\n25.1.10 La Storia della Probabilità\nLa probabilità moderna nacque da una domanda posta da Antoine Gombaud (Chevalier de Méré) a Blaise Pascal nel XVII secolo su come dividere equamente le puntate di un gioco d’azzardo interrotto.\n\n25.1.10.1 Il Problema dei Punti\nIl problema può essere riassunto come segue:\n\nImmaginiamo due persone, A e B, che partecipano a un gioco in cui il primo che vince sei round consecutivi ottiene un premio. Dopo sei round, A ha vinto cinque round e B uno. Poiché il gioco si interrompe prima di assegnare il premio, come dovrebbero dividere il premio in modo equo?\n\nQuesta domanda diede origine a una corrispondenza tra Pascal e Fermat, che svilupparono una soluzione matematica basata sulle probabilità di vittoria per ciascun giocatore. Se, per esempio, A aveva una probabilità del 97% di vincere, mentre B una del 3%, sembrava equo assegnare il 97% del premio ad A. La loro corrispondenza ispirò l’opera di Christian Huygens, “De Ratiociniis in Ludo Aleae” (1657), che rimase un riferimento in probabilità per mezzo secolo.\n\n\n25.1.10.2 Sviluppi Successivi\nNel 1713, Jacob Bernoulli pubblicò postumo “L’Arte della Congettura”, introducendo la legge dei grandi numeri e ponendo le basi per l’applicazione della probabilità al di fuori dei giochi d’azzardo, ad esempio nello studio della mortalità e della giustizia penale.\n\n\n\n25.1.11 Interpretazione Classica\nLa definizione classica di probabilità fu proposta da Pierre-Simon Laplace (1749-1827), che basò il concetto sul calcolo combinatorio. Secondo Laplace, la probabilità di un evento è data dal rapporto tra i casi favorevoli e il numero totale di casi possibili, assumendo che tutti siano equiprobabili. Ad esempio, la probabilità di ottenere un “3” lanciando un dado è \\(\\frac{1}{6}\\), poiché solo uno dei sei risultati è favorevole. Tuttavia, questa definizione è limitata, poiché si basa sull’assunzione che ogni evento sia equiprobabile, il che non è sempre vero. Inoltre, è parzialmente circolare, poiché presuppone una conoscenza implicita del concetto di probabilità.\n\n\n25.1.12 Interpretazione Frequentista\nL’approccio frequentista, nato dalla necessità di evitare le limitazioni dell’interpretazione classica, definisce la probabilità come il limite della frequenza relativa con cui un evento si verifica in una serie infinita di prove. Per esempio, la probabilità di ottenere “testa” in un lancio di moneta può essere stimata come la frequenza relativa di “testa” sul totale dei lanci, quando il numero di lanci tende all’infinito. Questa definizione è utile, ma impraticabile in molte situazioni, poiché richiede un numero infinito di ripetizioni e assume che gli eventi futuri siano identici a quelli passati.\n\ncoin_flips &lt;- function(n, run_label) {\n  # Genera un vettore di 0 e 1 dove 1 rappresenta \"testa\" e 0 \"croce\"\n  # usando una distribuzione binomiale.\n  heads &lt;- rbinom(n, 1, 0.5)\n  \n  # Calcola la proporzione cumulativa di teste.\n  flips &lt;- seq(1, n)\n  proportion_heads &lt;- cumsum(heads) / flips\n  \n  # Crea un data frame per un facile accesso e visualizzazione dei dati.\n  df &lt;- data.frame(flips = flips, proportion_heads = proportion_heads, run = run_label)\n  \n  return(df)\n}\n\nn &lt;- 1000\n\ndf &lt;- do.call(rbind, lapply(1:4, function(i) coin_flips(n, paste0(\"run\", i))))\n\nggplot(df, aes(x = flips, y = proportion_heads, color = run)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n25.1.13 La Legge dei Grandi Numeri\nLa simulazione precedente fornisce un esempio della Legge dei grandi numeri. La Legge dei Grandi Numeri afferma che, man mano che il numero di esperimenti casuali ripetuti aumenta, la stima della probabilità di un evento \\(P(Y=y)\\) diventa sempre più accurata.\nIl teorema sostiene che, con l’aumento del numero di ripetizioni di un esperimento casuale, la media dei risultati osservati tende a convergere al valore atteso teorico della variabile casuale. In altre parole, la media empirica dei risultati osservati si avvicina sempre di più al valore medio teorico.\nQuesta legge è cruciale perché garantisce che, con un numero sufficientemente grande di prove, la stima empirica della probabilità di un evento si avvicina al valore reale. Questo rende le stime probabilistiche più precise e affidabili.\nDal punto di vista pratico, la Legge dei Grandi Numeri consente di utilizzare modelli probabilistici per interpretare fenomeni reali. Anche se le osservazioni singole possono variare in modo casuale, la media delle osservazioni su un ampio numero di ripetizioni rifletterà fedelmente le probabilità teoriche.\nFormalmente, data una serie di variabili casuali indipendenti \\(X_1, X_2, \\ldots, X_n\\), ciascuna con media \\(\\mu\\), la Legge dei Grandi Numeri è espressa come:\n\\[\n\\lim_{{n \\to \\infty}} P\\left(\\left|\\frac{X_1 + X_2 + \\ldots + X_n}{n} - \\mu\\right| &lt; \\epsilon\\right) = 1,\n\\]\ndove \\(\\epsilon\\) è un valore positivo arbitrariamente piccolo e \\(P(\\cdot)\\) indica la probabilità. Questo significa che, con un numero molto grande di ripetizioni, la media campionaria osservata sarà vicina alla media teorica attesa, permettendo inferenze affidabili sulla probabilità degli eventi.\nIn sintesi, la Legge dei Grandi Numeri assicura che, aumentando il numero di prove, le stime empiriche delle probabilità diventano sempre più precise, allineandosi con i valori teorici attesi.\n\n25.1.13.1 Problema del caso singolo\nNell’ambito dell’approccio frequentista alla probabilità, basato sulla concezione delle frequenze relative di eventi osservati su lunghe serie di ripetizioni, emerge un limite concettuale nel trattare la probabilità di eventi singolari e non ripetibili. Secondo questa prospettiva, infatti, non risulta rigorosamente appropriato discutere di probabilità relative a eventi unici e non replicabili nel tempo. Esempi emblematici di tali eventi includono la possibilità che Alcaraz vinca contro Djokovic nella finale di Wimbledon del 2023 o che si verifichi pioggia a Firenze il giorno di Ferragosto del 2024. Questi scenari, essendo unici e circoscritti a un preciso momento storico, sfuggono alla logica frequentista che richiede, per definizione, la possibilità di osservazione ripetuta degli eventi per valutarne la probabilità. Nonostante ciò, nel linguaggio comune non specialistico, è comune l’uso del termine “probabilità” per riferirsi anche a tali eventi specifici e non ripetibili, evidenziando così una discrepanza tra l’uso tecnico e quello colloquiale del concetto di probabilità.\n\n\n\n25.1.14 Collegamento tra probabilità e statistica\nDurante gli anni ’20 del Novecento, Ronald A. Fisher propose un nuovo framework teorico per l’inferenza statistica, basato sulla concettualizzazione della frequenza. Fisher introdusse concetti chiave come la massima verosimiglianza, i test di significatività, i metodi di campionamento, l’analisi della varianza e il disegno sperimentale.\nNegli anni ’30, Jerzy Neyman ed Egon Pearson fecero ulteriori progressi nel campo con lo sviluppo di una teoria della decisione statistica, basata sul principio della verosimiglianza e sull’interpretazione frequentista della probabilità. Definirono due tipologie di errori decisionali e utilizzarono il test di significatività di Fisher, interpretando i valori-\\(p\\) come indicatori dei tassi di errore a lungo termine.\n\n\n25.1.15 La riscoperta dei metodi Monte Carlo Markov chain\nFisher assunse una prospettiva critica nei confronti della “probabilità inversa” (ossia, i metodi bayesiani), nonostante questa fosse stata la metodologia predominante per l’inferenza statistica per quasi un secolo e mezzo. Il suo approccio frequentista ebbe un profondo impatto sullo sviluppo della statistica sia teorica che sperimentale, contribuendo a un decremento nell’utilizzo dell’inferenza basata sul metodo della probabilità inversa, originariamente proposto da Laplace.\nNel 1939, il libro di Harold Jeffreys intitolato “Theory of Probability” rappresentò una delle prime esposizioni moderne dei metodi bayesiani. Tuttavia, la rinascita del framework bayesiano fu rinviata fino alla scoperta dei metodi Monte Carlo Markov chain alla fine degli anni ’80. Questi metodi hanno reso fattibile il calcolo di risultati precedentemente non ottenibili, consentendo un rinnovato interesse e sviluppo nei metodi bayesiani. Per una storia dell’approccio bayesiano, si veda Bayesian Methods: General Background oppure Philosophy of Statistics.\n\n\n25.1.16 Interpretazione soggettivista\nUna visione alternativa della probabilità la considera come una credenza soggettiva. Finetti (1970) ha proposto un’interpretazione in cui la probabilità non è vista come una caratteristica oggettiva degli eventi, ma piuttosto come una misura della credenza soggettiva, suggerendo di trattare \\(p(·)\\) come una probabilità soggettiva. È interessante notare che de Finetti era un soggettivista radicale. Infatti, la frase di apertura del suo trattato in due volumi sulla probabilità afferma che “La probabilità non esiste”, intendendo che la probabilità non ha uno status oggettivo, ma rappresenta piuttosto la quantificazione della nostra esperienza di incertezza. Riteneva che l’idea di una probabilità esterna all’individuo, con uno status oggettivo, fosse pura superstizione, paragonabile al credere in “Etere cosmico, Spazio e Tempo assoluti, …, o Fate e Streghe…”. Secondo de Finetti, “… esistono solo probabilità soggettive - cioè, il grado di credenza nell’occorrenza di un evento attribuito da una determinata persona in un dato momento con un dato insieme di informazioni.”\nCome sottolineato da Press (2009), la prima menzione della probabilità come grado di credenza soggettiva fu fatta da Ramsey (1926), ed è questa nozione di probabilità come credenza soggettiva che ha portato a una notevole resistenza alle idee bayesiane. Una trattazione dettagliata degli assiomi della probabilità soggettiva si trova in Fishburn (1986).\nLa denominazione “soggettivo” legata alla probabilità potrebbe risultare infelice, poiché potrebbe suggerire un ragionamento vago o non scientifico. Lindley (2013) condivide queste riserve, proponendo l’alternativa “probabilità personale” rispetto a “probabilità soggettiva”. Analogamente, Howson & Urbach (2006) preferiscono utilizzare l’espressione “probabilità epistemica”, che riflette il grado di incertezza di un individuo di fronte al problema trattato. In sostanza, la probabilità epistemica si riferisce all’incertezza personale riguardo a variabili sconosciute. Questa terminologia viene adottata anche nel testo di Kaplan (2023), fornendo un linguaggio più neutro per discutere di questi concetti.\nVa inoltre notato che l’interpretazione soggettiva si adatta bene a eventi singoli, permettendo di esprimere una convinzione su eventi specifici, come la probabilità di pioggia in un dato giorno o l’esito di una competizione sportiva.\n\n\n\n\n\n\nNota\n\n\n\nPer chi desidera approfondire, il primo capitolo del testo Bernoulli’s Fallacy (Clayton, 2021) offre un’introduzione molto leggibile alle tematiche della definizione della probabilità nella storia della scienza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#commenti-e-considerazioni-finali",
    "href": "chapters/probability/01_intro_prob.html#commenti-e-considerazioni-finali",
    "title": "25  Interpretazione della probabilità",
    "section": "25.2 Commenti e Considerazioni Finali",
    "text": "25.2 Commenti e Considerazioni Finali\nIn questo capitolo, abbiamo esplorato il significato filosofico della nozione di probabilità e introdotto la simulazione come metodo per approssimare le probabilità empiriche quando non è possibile ottenere soluzioni analitiche.\nNel prossimo capitolo, esamineremo la probabilità dal punto di vista matematico.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/01_intro_prob.html#informazioni-sullambiente-di-sviluppo",
    "title": "25  Interpretazione della probabilità",
    "section": "25.3 Informazioni sull’Ambiente di Sviluppo",
    "text": "25.3 Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2 ggpubr_0.6.0     \n#&gt;  [5] ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0   bayesplot_1.11.1 \n#&gt;  [9] psych_2.4.6.26    scales_1.3.0      markdown_1.13     knitr_1.49       \n#&gt; [13] lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4      \n#&gt; [17] purrr_1.0.2       readr_2.1.5       tidyr_1.3.1       tibble_3.2.1     \n#&gt; [21] ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      xfun_0.49         htmlwidgets_1.6.4 rstatix_0.7.2    \n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    fansi_1.0.6       pacman_0.5.1     \n#&gt; [13] pkgconfig_2.0.3   lifecycle_1.0.4   compiler_4.4.2    farver_2.1.2     \n#&gt; [17] munsell_0.5.1     mnormt_2.1.1      carData_3.0-5     httpuv_1.6.15    \n#&gt; [21] htmltools_0.5.8.1 yaml_2.3.10       Formula_1.2-5     car_3.1-3        \n#&gt; [25] pillar_1.9.0      later_1.4.0       abind_1.4-8       nlme_3.1-166     \n#&gt; [29] mime_0.12         tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4    \n#&gt; [33] labeling_0.4.3    rprojroot_2.0.4   fastmap_1.2.0     grid_4.4.2       \n#&gt; [37] colorspace_2.1-1  cli_3.6.3         magrittr_2.0.3    utf8_1.2.4       \n#&gt; [41] broom_1.0.7       withr_3.0.2       backports_1.5.0   promises_1.3.1   \n#&gt; [45] timechange_0.3.0  rmarkdown_2.29    ggsignif_0.6.4    hms_1.1.3        \n#&gt; [49] shiny_1.9.1       evaluate_1.0.1    miniUI_0.1.1.1    rlang_1.1.4      \n#&gt; [53] Rcpp_1.0.13-1     xtable_1.8-4      glue_1.8.0        jsonlite_1.8.9   \n#&gt; [57] R6_2.5.1",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#bibliografia",
    "href": "chapters/probability/01_intro_prob.html#bibliografia",
    "title": "25  Interpretazione della probabilità",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nClayton, A. (2021). Bernoulli’s Fallacy: Statistical Illogic and the Crisis of Modern Science. Columbia University Press.\n\n\nFinetti, B. de. (1970). Teoria delle probabilità (pp. VIII, 350–769). G. Einaudi.\n\n\nFishburn, P. C. (1986). The axioms of subjective probability. Statistical Science, 1(3), 335–345.\n\n\nHowson, C., & Urbach, P. (2006). Scientific reasoning: the Bayesian approach. Open Court Publishing.\n\n\nKaplan, D. (2023). Bayesian statistics for the social sciences. Guilford Publications.\n\n\nLindley, D. V. (2013). Understanding uncertainty. John Wiley & Sons.\n\n\nPress, S. J. (2009). Subjective and objective Bayesian statistics: Principles, models, and applications. John Wiley & Sons.\n\n\nRamsey, F. P. (1926). Truth and probability. In Readings in Formal Epistemology: Sourcebook (pp. 21–45). Springer.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html",
    "href": "chapters/probability/02_prob_spaces.html",
    "title": "26  Misura di Probabilità",
    "section": "",
    "text": "26.1 Introduzione alle Probabilità: Origine e Definizione\nPrerequisiti\nConcetti e Competenze Chiave\nDa dove derivano matematicamente i numeri che chiamiamo “probabilità”? Per rispondere, in questo capitolo faremo riferimento alla trattazione di Michael Betancourt. Questo capitolo offre una versione semplificata del suo lavoro, mantenendo la notazione e le figure originali.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Misura di Probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html#insiemi-finiti",
    "href": "chapters/probability/02_prob_spaces.html#insiemi-finiti",
    "title": "26  Misura di Probabilità",
    "section": "26.2 Insiemi Finiti",
    "text": "26.2 Insiemi Finiti\nPer semplificare, Betancourt introduce i fondamenti della teoria della probabilità utilizzando uno spazio campionario composto da un numero finito di elementi.\nUn insieme finito è costituito da un numero finito di elementi distinti,\n\\[\nX = \\{x_1, ..., x_N\\}.\n\\]\nQui, l’indice numerico serve a distinguere gli \\(N\\) elementi individuali, senza implicare necessariamente un ordine particolare tra di essi. Per evitare qualsiasi presunzione di ordine, Betancourt utilizza il seguente insieme arbitrario di cinque elementi quale esempio:\n\\[\nX = \\{\\Box, \\clubsuit, \\diamondsuit, \\heartsuit, \\spadesuit\\}.\n\\]\n\n\n\n\n\n\nFigura 26.1: Un insieme finito contiene un numero finito di elementi. Questo particolare insieme ne contiene cinque.\n\n\n\nNelle applicazioni pratiche della teoria della probabilità, gli elementi astratti \\(x_{n}\\) rappresentano oggetti concreti. Tuttavia, in questo capitolo, ci si concentrerà esclusivamente sui concetti matematici, evitando qualsiasi interpretazione particolare. Quando l’insieme \\(X\\) rappresenta tutti gli oggetti di interesse in una data applicazione, viene denominato spazio campionario. Una volta definito lo spazio campionario, possiamo organizzare e manipolare i suoi elementi in vari modi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Misura di Probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html#sottoinsiemi",
    "href": "chapters/probability/02_prob_spaces.html#sottoinsiemi",
    "title": "26  Misura di Probabilità",
    "section": "26.3 Sottoinsiemi",
    "text": "26.3 Sottoinsiemi\nUn sottoinsieme di \\(X\\) è qualsiasi collezione di elementi in \\(X\\). Per evitare ambiguità, Betancourt usa le lettere romane minuscole \\(x\\) per indicare un elemento variabile nello spazio campionario \\(X\\) e le lettere minuscole sans serif \\(\\mathsf{x}\\) per indicare un sottoinsieme variabile.\nAd esempio, \\(\\mathsf{x} = \\{\\Box, \\diamondsuit, \\heartsuit\\}\\) è un sottoinsieme di \\(X = \\{\\Box, \\clubsuit, \\diamondsuit, \\heartsuit, \\spadesuit\\}\\). Importante notare che nel concetto di sottoinsieme non esiste la nozione di molteplicità, solo di appartenenza: un sottoinsieme può includere un elemento \\(x_{n}\\) ma non può includerlo più volte.\n\n\n\n\n\n\nFigura 26.2: Un sottoinsieme \\(\\mathsf{x} \\subset X\\) è qualsiasi collezione di elementi dallo spazio campionario \\(X\\). Qui \\(\\mathsf{x} = \\{\\Box, \\diamondsuit, \\heartsuit\\}\\) contiene solo tre dei cinque elementi in $X = {, , , , }.\n\n\n\nSe \\(\\mathsf{x}\\) è un sottoinsieme dello spazio campionario \\(X\\) allora scriviamo \\(\\mathsf{x} \\subset X\\). Quando \\(\\mathsf{x}\\) contiene tutti gli elementi di \\(X\\), ovvero \\(\\mathsf{x} = X\\), allora scriviamo \\(\\mathsf{x} \\subseteq X\\).\nIndipendentemente da quanti elementi un insieme finito \\(X\\) contiene, possiamo sempre costruire tre tipi speciali di sottoinsiemi. L’insieme vuoto \\(\\emptyset = \\{\\}\\) non contiene alcun elemento. D’altra parte, l’intero insieme stesso può essere considerato un sottoinsieme contenente tutti gli elementi. Un sottoinsieme contenente un singolo elemento è denotato \\(\\{ x_{n} \\}\\) ed è chiamato insieme atomico.\nCi sono\n\\[\n{N \\choose n} = \\frac{ N! }{ n! (N - n)!}\n\\]\nmodi per selezionare \\(n\\) elementi da un insieme finito di \\(N\\) elementi totali, e quindi \\({N \\choose n}\\) sottoinsiemi totali di dimensione \\(n\\). Ad esempio, esiste un solo sottoinsieme che non contiene alcun elemento,\n\\[\n{N \\choose 0} = \\frac{ N! }{ 0! (N - 0)!} = \\frac{ N! }{ N! } = 1,\n\\]\ned è l’insieme vuoto. Allo stesso modo, esiste un solo sottoinsieme che contiene tutti gli elementi,\n\\[\n{N \\choose N} = \\frac{ N! }{ N! (N - N)!} = \\frac{ N! }{ N! } = 1,\n\\]\ned è l’insieme completo stesso. D’altra parte, ci sono\n\\[\n{N \\choose 1} = \\frac{ N! }{ 1! (N - 1)!} = N\n\\]\ninsiemi atomici distinti che contengono un solo elemento, uno per ciascun elemento in \\(X\\).\nContando tutti i sottoinsiemi di tutte le dimensioni possibili si ottiene\n\\[\n\\sum_{n = 0}^{N} {N \\choose n} = 2^{N}\n\\]\nsottoinsiemi possibili che possiamo costruire da un insieme finito con \\(N\\) elementi.\nLa collezione di tutti i sottoinsiemi è essa stessa un insieme finito con \\(2^{N}\\) elementi. Chiamiamo questo insieme insieme potenza di \\(X\\) e lo denotiamo \\(2^{X}\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Misura di Probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html#operazioni-sui-sottoinsiemi",
    "href": "chapters/probability/02_prob_spaces.html#operazioni-sui-sottoinsiemi",
    "title": "26  Misura di Probabilità",
    "section": "26.4 Operazioni sui Sottoinsiemi",
    "text": "26.4 Operazioni sui Sottoinsiemi\nPossiamo sempre costruire sottoinsiemi elemento per elemento, ma possiamo anche costruirli manipolando sottoinsiemi esistenti.\nAd esempio, dato un sottoinsieme \\(\\mathsf{x} \\subset X\\) possiamo costruire il suo complemento raccogliendo tutti gli elementi in \\(X\\) che non sono già in \\(\\mathsf{x}\\). L’insieme atomico \\(\\mathsf{x} = \\{ \\diamondsuit \\}\\) contiene l’unico elemento \\(\\diamondsuit\\) e il suo complemento contiene i rimanenti elementi \\[\n\\mathsf{x}^{c} = \\{ \\Box, \\clubsuit, \\heartsuit, \\spadesuit \\}.\n\\] Per costruzione, il complemento dell’insieme vuoto è l’intero insieme, \\(\\emptyset^{c} = X\\), e il complemento dell’insieme completo è l’insieme vuoto, \\(X^{c} = \\emptyset\\).\n\n\n\n\n\n\nFigura 26.3: Il complemento di un sottoinsieme \\(\\mathsf{x}\\) è il sottoinsieme \\(\\mathsf{x}^{c}\\) costituito da tutti gli elementi nello spazio campionario che non sono in \\(\\mathsf{x}\\).\n\n\n\nAd esempio, applicando l’operatore di complemento al sottoinsieme \\(\\mathsf{x} = \\{ \\clubsuit, \\spadesuit \\}\\) otteniamo \\[\n\\mathsf{x}^{c}\n= \\{ \\clubsuit, \\spadesuit \\}^{c}\n= \\{ \\Box, \\diamondsuit, \\heartsuit \\}.\n\\]\nPossiamo anche costruire sottoinsiemi da più di un sottoinsieme. Consideriamo, ad esempio, due sottoinsiemi \\(\\mathsf{x}_1 = \\{ \\Box, \\heartsuit \\}\\) e \\(\\mathsf{x}_2 = \\{ \\Box, \\spadesuit \\}\\). La collezione di tutti gli elementi che sono contenuti in uno qualsiasi dei due sottoinsiemi è essa stessa un sottoinsieme, \\[\n\\{ \\Box, \\heartsuit, \\spadesuit \\} \\subset X,\n\\] così come la collezione di tutti gli elementi che sono contenuti in entrambi i sottoinsiemi, \\[\n\\{ \\Box \\} \\subset X.\n\\] Questi sottoinsiemi derivati sono chiamati rispettivamente unione, \\[\n\\mathsf{x}_1 \\cup \\mathsf{x}_2\n= \\{ \\Box, \\heartsuit \\} \\cup \\{ \\Box, \\spadesuit \\}\n= \\{ \\Box, \\heartsuit, \\spadesuit \\},\n\\] e intersezione, \\[\n\\mathsf{x}_1 \\cap \\mathsf{x}_2\n= \\{ \\Box, \\heartsuit \\} \\cap \\{ \\Box, \\spadesuit \\}\n= \\{ \\Box \\}.\n\\]\n\n\n\n\n\n\nFigura 26.4: Possiamo manipolare due sottoinsiemi in vari modi per ottenere un nuovo sottoinsieme.\n\n\n\n\n\n\n\n\n\nFigura 26.5: L’unione di due sottoinsiemi, \\(\\mathsf{x}_1 \\cup \\mathsf{x}_2\\), è un sottoinsieme contenente tutti gli elementi di entrambi i sottoinsiemi in input. D’altra parte, l’intersezione di due sottoinsiemi, \\(\\mathsf{x}_1 \\cap \\mathsf{x}_2\\), è un sottoinsieme contenente solo gli elementi che compaiono in entrambi i sottoinsiemi in input.\n\n\n\nDue sottoinsiemi sono disgiunti se non condividono alcun elemento; in questo caso la loro intersezione è l’insieme vuoto, \\[\n\\mathsf{x}_{1} \\cap \\mathsf{x}_{2} = \\emptyset.\n\\] L’unione e l’intersezione di un sottoinsieme con se stesso restituiscono quel sottoinsieme, \\[\n\\mathsf{x} \\cup \\mathsf{x} = \\mathsf{x} \\cap \\mathsf{x} = \\mathsf{x}.\n\\] Poiché l’insieme vuoto non contiene alcun elemento, la sua unione con qualsiasi sottoinsieme restituisce quel sottoinsieme, \\[\n\\mathsf{x} \\cup \\emptyset = \\emptyset \\cup \\mathsf{x} = \\mathsf{x},\n\\] e la sua intersezione con qualsiasi sottoinsieme restituisce l’insieme vuoto, \\[\n\\mathsf{x} \\cap \\emptyset = \\emptyset \\cap \\mathsf{x} = \\emptyset.\n\\] Allo stesso modo, l’unione di un sottoinsieme con l’insieme completo restituisce l’insieme completo, \\[\n\\mathsf{x} \\cup X = X \\cup \\mathsf{x} = X,\n\\] e l’intersezione di un sottoinsieme con l’insieme completo restituisce quel sottoinsieme, \\[\n\\mathsf{x} \\cap X = X \\cap \\mathsf{x} = \\mathsf{x}.\n\\]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Misura di Probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html#misura-e-probabilità-sugli-elementi",
    "href": "chapters/probability/02_prob_spaces.html#misura-e-probabilità-sugli-elementi",
    "title": "26  Misura di Probabilità",
    "section": "26.5 Misura e Probabilità sugli Elementi",
    "text": "26.5 Misura e Probabilità sugli Elementi\nDa un punto di vista matematico, la teoria della misura riguarda l’allocazione coerente di una qualche quantità astratta attraverso lo spazio campionario. Consideriamo un serbatoio (il termine standard in questo contesto sarebbe “misura totale” o “massa totale”) di una qualche quantità positiva, continua e conservata, \\(M \\in [0, \\infty]\\). Poiché \\(M\\) è conservato, qualsiasi quantità \\(m_{n}\\) che viene allocata all’elemento \\(x_{n} \\in X\\) deve essere detratta dal serbatoio, lasciando meno da allocare agli altri elementi.\nUn caso particolare si verifica quando il contenuto totale del serbatoio \\(M\\) è infinito. In questo scenario, possiamo allocare una quantità infinita dal serbatoio pur avendo ancora una quantità infinita rimanente. Allo stesso tempo, allocare una quantità infinita può esaurire completamente il serbatoio o lasciare qualsiasi quantità finita residua. L’infinito è un concetto matematicamente complesso da trattare.\n\n\n\n\n\n\nFigura 26.6: La teoria della misura riguarda l’allocazione di una qualche quantità continua e positiva \\(M\\) sugli elementi individuali dello spazio campionario.\n\n\n\nUn’allocazione esaustiva di \\(M\\) su tutto lo spazio campionario assicura che il serbatoio sia completamente svuotato. In altre parole, l’intero valore di \\(M\\) deve essere distribuito tra gli elementi \\(x_{n} \\in X\\).\nPer illustrare questo concetto, consideriamo il nostro spazio campionario dimostrativo \\(X = \\{\\Box, \\clubsuit, \\diamondsuit, \\heartsuit, \\spadesuit \\}\\). Il processo di allocazione può essere descritto come segue:\n\nAllocchiamo \\(m_\\Box\\) a \\(\\Box\\), lasciando \\(M - m_\\Box\\) nel serbatoio.\nAssegniamo \\(m_\\clubsuit\\) a \\(\\clubsuit\\), riducendo ulteriormente il contenuto del serbatoio a \\(M - m_\\Box - m_\\clubsuit\\).\nContinuiamo questo processo per \\(\\diamondsuit\\) e \\(\\heartsuit\\).\nInfine, per svuotare completamente il serbatoio, dobbiamo allocare tutto ciò che rimane a \\(\\spadesuit\\).\n\nMatematicamente, l’ammontare finale allocato a \\(\\spadesuit\\) sarà:\n\\[\nM - m_{\\Box} - m_{\\clubsuit} - m_{\\diamondsuit} - m_{\\heartsuit}.\n\\]\nQuesta allocazione finale assicura che la somma di tutte le quantità distribuite sia esattamente uguale a \\(M\\), svuotando così completamente il serbatoio.\n\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c)\n\n\n\n\n\n\n\n\n\n\n\n(d)\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n(e)\n\n\n\n\n\n \n\n\n\n\nFigura 26.7: Poiché la quantità totale \\(M\\) è conservata, ogni allocazione \\(m_{n}\\) a un elemento \\(x_{n} \\in X\\) riduce la quantità disponibile per l’allocazione agli altri elementi. Un’allocazione esaustiva non lascia nulla nel serbatoio iniziale dopo che ciascun elemento ha ricevuto la sua allocazione.\n\n\n\nUna misura è qualsiasi allocazione coerente della quantità \\(M\\) agli elementi di uno spazio campionario. Matematicamente, qualsiasi misura su un insieme finito può essere caratterizzata da \\(N\\) numeri \\[\n\\mu = \\{ m_{1}, \\ldots, m_{N} \\}\n\\] che soddisfano \\[\n0 \\le m_{n}\n\\] e \\[\n\\sum_{n = 1}^{N} m_{n} = M.\n\\] Ad esempio, qualsiasi misura sui cinque elementi dell’insieme \\(X = \\{\\Box, \\clubsuit, \\diamondsuit, \\heartsuit, \\spadesuit\\}\\) è specificata da cinque numeri positivi \\(\\{ m_\\Box, m_\\clubsuit, m_\\diamondsuit, m_\\heartsuit, m_\\spadesuit \\}\\) che soddisfano \\[\nm_\\Box + m_\\clubsuit + m_\\diamondsuit + m_\\heartsuit + m_\\spadesuit = M.\n\\]\n\n\n\n\n\n\nFigura 26.8: Una misura \\(\\mu\\) su un insieme finito \\(X\\) è qualsiasi allocazione coerente di \\(M\\) agli elementi $x_{n} X. Ogni misura può essere caratterizzata da \\(N\\) numeri \\(m_{n}\\) che sommano a \\(M\\), o equivalentemente una funzione che mappa ogni elemento \\(x_{n}\\) alla sua misura allocata \\(m_{n}\\).\n\n\n\nPiù grande è \\(m_{n}\\), più di \\(M\\) viene allocato all’elemento \\(x_{n}\\). Seguendo questa terminologia, chiameremo anche \\(M\\) come la misura totale e \\(m_{n}\\) come la misura allocata a \\(x_{n}\\).\nIn questa discussione, ci occuperemo solo di misure finite, dove la misura totale \\(M\\) è un numero positivo e finito (\\(0 \\leq M \\leq \\infty\\)). Non tratteremo il caso di misure infinite (\\(M = \\infty\\)), poiché richiede considerazioni più complesse che vanno oltre lo scopo di questa trattazione.\nUna misura \\(\\mu\\) su uno spazio campionario \\(X\\) può essere vista come una funzione che assegna un valore numerico non negativo (la misura) a ogni elemento dello spazio:\n\\[\n\\begin{alignat*}{6}\n\\mu :\\; & X & &\\rightarrow& \\; & [0, \\infty] &\n\\\\\n& x_{n} & &\\mapsto& & m_{n} = \\mu(x_{n}) &,\n\\end{alignat*}\n\\] dove:\n\n\\(X\\) è lo spazio campionario,\n\\(x_n\\) è un elemento di \\(X\\),\n\\(m_n\\) è la misura assegnata a \\(x_n\\).\n\nQuesto approccio funzionale ci permette di considerare ogni elemento dello spazio campionario separatamente, valutando \\(\\mu(x_{n})\\) per ciascun \\(x_{n}\\), invece di dover gestire tutte le allocazioni contemporaneamente.\nÈ importante notare che esistono molti modi diversi per distribuire una misura totale \\(M\\) tra gli elementi di un insieme finito. L’insieme di tutte le possibili misure su \\(X\\) si indica con \\(\\mathcal{M}(X)\\).\nAll’interno di questa collezione ci sono alcuni esempi notevoli. Ad esempio, una misura singolare alloca la misura totale \\(M\\) a un singolo elemento, lasciando il resto con niente. D’altra parte, una misura uniforme alloca la stessa misura \\(M / N\\) a ciascun elemento. Su insiemi finiti ci sono \\(N\\) misure singolari distinte, una per ciascun elemento distinto, e una misura uniforme unica.\n\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\n\nFigura 26.9: Una misura singolare (a) alloca la misura totale a un singolo elemento, mentre la misura uniforme (b) distribuisce la misura totale uniformemente a ciascun elemento.\n\n\n\nLe misure finite sono una categoria particolarmente importante nel campo della teoria della misura. Una misura si definisce finita quando la sua misura totale \\(M\\) è un numero positivo e limitato, ovvero \\(0 &lt; M &lt; \\infty\\).\nL’importanza delle misure finite risiede nella possibilità di esprimere le allocazioni in termini relativi anziché assoluti. Questo significa che possiamo rappresentare la misura di ciascun elemento come una frazione o una percentuale della misura totale, invece di usare il valore assoluto. Invece di considerare la misura assoluta allocata a ciascun elemento \\(m_{n}\\), possiamo considerare la proporzione della misura totale allocata a ciascun elemento \\[\np_{n} = m_{n} / M.\n\\] Per costruzione, le proporzioni sono confinate all’intervallo unitario \\([0, 1]\\). Come per qualsiasi quantità che assume valori in \\([0, 1]\\), possiamo rappresentare le proporzioni altrettanto bene con decimali, ad esempio \\(p_{n} = 0.2\\), e percentuali, \\(p_{n} = 20\\%\\).\nQuesto approccio relativo offre diversi vantaggi: permette di confrontare facilmente l’importanza relativa di diversi elementi, facilita la comprensione della distribuzione della misura sull’intero spazio campionario e consente di normalizzare misure diverse, rendendo più semplice il confronto tra sistemi diversi. In sintesi, le misure finite ci permettono di passare da una visione “assoluta” a una “relativa” della distribuzione della misura, offrendo una prospettiva più intuitiva e utile per l’analisi.\n\n\n\n\n\n\nFigura 26.10: Ogni misura finita può essere caratterizzata da un’allocazione proporzionale.\n\n\n\nIn altre parole, una misura proporzionale definisce la funzione \\[\n\\begin{alignat*}{6}\n\\pi :\\; & X & &\\rightarrow& \\; & [0, 1] &\n\\\\\n& x_{n} & &\\mapsto& & p_{n} = \\pi(x_{n}) &\n\\end{alignat*}\n\\] con \\[\n0 \\le p_{n} \\le 1\n\\] e \\[\n\\sum_{n = 1}^{N} p_{n} = 1.\n\\] Una collezione di variabili \\(\\{ p_{1}, \\ldots, p_{N} \\}\\) che soddisfano queste proprietà è chiamata simplex.\n\n\n\n\n\n\nFigura 26.11: Un’allocazione proporzionale è anche conosciuta come distribuzione di probabilità.\n\n\n\nPiù importante, una misura proporzionale \\(\\pi\\) è anche conosciuta come distribuzione di probabilità, e le allocazioni proporzionali \\(p_{n}\\) sono chiamate probabilità. Sebbene il termine “probabilità” sia spesso carico di significati interpretativi e filosofici, la sua struttura matematica è piuttosto semplice: su un insieme finito, una probabilità rappresenta semplicemente la proporzione di una quantità finita assegnata a ciascun elemento individuale.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Misura di Probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html#misura-e-probabilità-sui-sottoinsiemi",
    "href": "chapters/probability/02_prob_spaces.html#misura-e-probabilità-sui-sottoinsiemi",
    "title": "26  Misura di Probabilità",
    "section": "26.6 Misura e Probabilità sui Sottoinsiemi",
    "text": "26.6 Misura e Probabilità sui Sottoinsiemi\nSugli insiemi finiti, qualsiasi allocazione, sia assoluta che proporzionale, agli elementi individuali \\(x \\in X\\) determina anche un’allocazione per i sottoinsiemi \\(\\mathsf{x} \\in 2^{X}\\). La misura assegnata a un sottoinsieme è semplicemente la somma delle misure assegnate agli elementi che lo compongono. Ad esempio, la misura assegnata al sottoinsieme \\(\\mathsf{x} = \\{ \\Box, \\clubsuit, \\heartsuit \\}\\) è \\(m_{\\Box} + m_{\\clubsuit} + m_{\\heartsuit}\\).\n\n\n\n\n\n\nFigura 26.12: Su un insieme finito, un’allocazione sugli elementi individuali definisce anche un’allocazione su qualsiasi sottoinsieme.\n\n\n\nPer costruzione, qualsiasi misura sui sottoinsiemi e distribuzione di probabilità soddisfano una serie di proprietà utili. Ad esempio, per qualsiasi misura \\[\n\\mu( \\emptyset ) = 0\n\\] e \\[\n\\mu( X ) = \\sum_{n = 1}^{N} \\mu(x_{n}) = M,\n\\] mentre per qualsiasi distribuzione di probabilità abbiamo \\(\\pi( \\emptyset ) = 0\\) e \\(\\pi( X ) = 1\\).\nLe allocazioni sui sottoinsiemi si combinano in modo naturale con le operazioni sui sottoinsiemi. Consideriamo, ad esempio, i due sottoinsiemi disgiunti \\(\\mathsf{x}_{1} = \\{ \\Box, \\diamondsuit \\}\\) e \\(\\mathsf{x}_{2} = \\{ \\clubsuit, \\spadesuit \\}\\). Poiché i due sottoinsiemi sono disgiunti, la loro unione include semplicemente tutti i loro elementi:\n\\[\n\\mathsf{x}_{1} \\cup \\mathsf{x}_{2}\n=\n\\{ \\Box, \\diamondsuit \\} \\cup \\{ \\clubsuit, \\spadesuit \\}\n=\n\\{ \\Box, \\clubsuit, \\diamondsuit, \\spadesuit \\},\n\\]\ne la misura di questa unione è solo la somma delle misure dei due sottoinsiemi:\n\\[\n\\begin{align*}\n\\mu ( \\mathsf{x}_{1} \\cup \\mathsf{x}_{2} )\n&=\n\\mu ( \\{ \\Box, \\clubsuit, \\diamondsuit, \\spadesuit \\} )\n\\\\\n&=\nm_{\\Box} + m_{\\clubsuit} + m_{\\diamondsuit} + m_{\\spadesuit}\n\\\\\n&=\n( m_{\\Box} + m_{\\diamondsuit} ) + ( m_{\\clubsuit} + m_{\\spadesuit} )\n\\\\\n&=\n\\mu( \\mathsf{x}_{1} ) + \\mu( \\mathsf{x}_{2} ).\n\\end{align*}\n\\]\nPiù in generale, per qualsiasi collezione di sottoinsiemi\n\\[\n\\mathsf{x}_{1}, \\ldots, \\mathsf{x}_{K}\n\\]\nche sono reciprocamente disgiunti,\n\\[\n\\mathsf{x}_{k} \\cap \\mathsf{x}_{k'} = \\emptyset \\quad \\text{per} \\quad k \\ne k',\n\\]\nabbiamo\n\\[\n\\mu ( \\cup_{k = 1}^{K} \\mathsf{x}_{k} )\n=\n\\sum_{k = 1}^{K} \\mu ( \\mathsf{x}_{k} ).\n\\]\nIn altre parole, se possiamo scomporre un sottoinsieme in una collezione di sottoinsiemi più piccoli e disgiunti, possiamo anche scomporre la misura allocata a quel sottoinsieme iniziale nelle misure allocate ai sottoinsiemi componenti. Questa proprietà di coerenza è chiamata additività.\nUn sottoinsieme \\(\\mathsf{x}\\) e il suo complemento \\(\\mathsf{x}^{c}\\) sono sempre disgiunti, ovvero \\(\\mathsf{x} \\cap \\mathsf{x}^{c} = \\emptyset\\). Allo stesso tempo, la loro unione copre l’intero insieme: \\(\\mathsf{x} \\cup \\mathsf{x}^{c} = X\\). Di conseguenza, l’additività implica che:\n\\[\n\\begin{align*}\nM &= \\mu (X) \\\\\n  &= \\mu ( \\mathsf{x} \\cup \\mathsf{x}^{c} ) \\\\\n  &= \\mu ( \\mathsf{x} ) + \\mu ( \\mathsf{x}^{c} ),\n\\end{align*}\n\\]\nda cui segue che:\n\\[\n\\mu ( \\mathsf{x}^{c} ) = M - \\mu ( \\mathsf{x} ).\n\\]\nIn altre parole, la misura assegnata al complemento di un sottoinsieme è la misura totale meno la misura assegnata a quel sottoinsieme. Per le distribuzioni di probabilità, questo concetto è ancora più evidente:\n\\[\n\\pi ( \\mathsf{x}^{c} ) = 1 - \\pi ( \\mathsf{x} ).\n\\]\nQuando due sottoinsiemi si sovrappongono, dobbiamo considerare che la somma delle loro misure \\(\\mu (\\mathsf{x}_{1} ) + \\mu ( \\mathsf{x}_{2} )\\) conta due volte la misura degli elementi condivisi tra di essi. Ad esempio, se \\(\\mathsf{x}_{1} = \\{ \\Box, \\heartsuit \\}\\) e \\(\\mathsf{x}_{2} = \\{ \\Box, \\spadesuit \\}\\), allora l’unione include l’elemento sovrapposto \\(\\Box\\) solo una volta:\n\\[\n\\mathsf{x}_{1} \\cup \\mathsf{x}_{2} = \\{ \\Box, \\heartsuit \\} \\cup \\{ \\Box, \\spadesuit \\} = \\{ \\Box, \\heartsuit, \\spadesuit \\}.\n\\]\nDi conseguenza:\n\\[\n\\begin{align*}\n\\mu( \\mathsf{x}_{1} \\cup \\mathsf{x}_{2} ) &= \\mu( \\{ \\Box, \\heartsuit, \\spadesuit \\} ) \\\\\n&= m_{\\Box} + m_{\\heartsuit} + m_{\\spadesuit}.\n\\end{align*}\n\\]\nSommando le misure allocate ai due sottoinsiemi individualmente, tuttavia, otteniamo:\n\\[\n\\begin{align*}\n\\mu( \\mathsf{x}_{1} ) + \\mu ( \\mathsf{x}_{2} ) &= (m_{\\Box} + m_{\\heartsuit} ) + ( m_{\\Box} + m_{\\spadesuit} ) \\\\\n&= m_{\\Box} + m_{\\Box} + m_{\\heartsuit} + m_{\\spadesuit} \\\\\n&= m_{\\Box} + \\mu( \\mathsf{x}_{1} \\cup \\mathsf{x}_{2} ).\n\\end{align*}\n\\]\nL’elemento che viene contato due volte è esattamente l’unico elemento nell’intersezione dei due sottoinsiemi:\n\\[\nm_{\\Box} = \\mu( \\{ \\Box \\} ) = \\mu( \\mathsf{x}_{1} \\cap \\mathsf{x}_{2} ).\n\\]\nIn altre parole, possiamo scrivere:\n\\[\n\\mu( \\mathsf{x}_{1} ) + \\mu ( \\mathsf{x}_{2} ) = \\mu( \\mathsf{x}_{1} \\cup \\mathsf{x}_{2} ) + \\mu( \\mathsf{x}_{1} \\cap \\mathsf{x}_{2} ).\n\\]\nQuesta relazione vale per qualsiasi due sottoinsiemi, indipendentemente dalla loro sovrapposizione.\n\n\n\n\n\n\nFigura 26.13: Quando due sottoinsiemi si sovrappongono, la misura allocata a ciascuno conta doppio la misura allocata a qualsiasi elemento sovrapposto, qui \\(\\Box\\), ma la misura allocata alla loro unione no. Questo risulta in una relazione importante tra le misure allocate ai due sottoinsiemi, la misura allocata alla loro unione e la misura allocata alla loro intersezione.\n\n\n\nQueste proprietà dei sottoinsiemi ci permettono di costruire una misura in molti modi diversi, ciascuno dei quali può essere utile in circostanze diverse. Questa flessibilità è molto comoda quando si applica la teoria della misura e la teoria della probabilità nella pratica.\nAd esempio, possiamo specificare una misura in due modi principali:\n\nAllocazione globale: possiamo assegnare le misure a tutti gli elementi individuali contemporaneamente. Questo metodo considera l’intero insieme fin dall’inizio e assegna una misura a ciascun elemento.\n\n\n\n\n\n\n\nFigura 26.14: Le misure possono essere costruite specificando le allocazioni degli elementi individuali tutte insieme.\n\n\n\n\nAllocazione locale: possiamo assegnare la misura a ciascun elemento uno alla volta. Questo metodo permette di concentrarsi su un elemento alla volta, aggiungendo gradualmente le misure agli altri elementi.\n\n\n\n\n\n\n\nFigura 26.15: Allo stesso tempo, le misure possono essere costruite specificando le allocazioni degli elementi individuali uno alla volta.\n\n\n\nInoltre, non è sempre necessario partire dalle allocazioni individuali. Un altro metodo consiste nel:\n\nAllocazione iterativa: possiamo iniziare allocando la misura totale a sottoinsiemi disgiunti e poi affinare iterativamente questa allocazione suddividendo i sottoinsiemi in parti sempre più piccole fino a raggiungere gli elementi individuali.\n\n\n\n\n\n\n\nFigura 26.16: Le misure possono anche essere costruite allocando la misura totale a sottoinsiemi disgiunti e poi raffinando iterativamente tale allocazione a sottoinsiemi sempre più piccoli.\n\n\n\nQuesta flessibilità nelle modalità di costruzione delle misure è particolarmente utile perché permette di adattare l’approccio alle specifiche necessità del problema in questione. Ad esempio, nella pratica, potremmo trovare più semplice allocare inizialmente misure a grandi gruppi di elementi e poi suddividere questi gruppi, oppure potremmo voler assegnare le misure a ciascun elemento uno per uno a seconda delle esigenze del contesto.\nInfine, la definizione di misura sui sottoinsiemi \\(\\mu : 2^{X} \\rightarrow [0, \\infty]\\) è cruciale per estendere la teoria della misura oltre gli insiemi finiti. Questa estensione è necessaria per definire misure in modo coerente su insiemi matematicamente più complessi, come la retta reale.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Misura di Probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html#riflessioni-conclusive",
    "href": "chapters/probability/02_prob_spaces.html#riflessioni-conclusive",
    "title": "26  Misura di Probabilità",
    "section": "26.7 Riflessioni Conclusive",
    "text": "26.7 Riflessioni Conclusive\nIl significato applicativo delle nozioni di misura e distribuzione di probabilità è centrale per comprendere come utilizzare questi concetti nella pratica, in particolare nella statistica bayesiana. Il punto cruciale è capire cosa rappresenta \\(M\\), la “misura totale”. Nelle applicazioni bayesiane, \\(M\\) rappresenta la nostra certezza complessiva.\nQuando si lavora con distribuzioni di probabilità, stiamo effettivamente allocando questa certezza complessiva tra diversi eventi possibili. Una distribuzione (di massa) di probabilità è quindi l’allocazione relativa della nostra certezza tra un insieme di eventi disgiunti. Ogni probabilità individuale, \\(p_n\\), rappresenta la proporzione della nostra certezza totale che assegniamo a un particolare evento.\nNella teoria bayesiana, la “misura totale” \\(M\\) è interpretata come la somma totale delle probabilità, che è sempre uguale a 1. Questo riflette il fatto che la somma delle nostre certezze relative per tutti gli eventi possibili deve essere completa: siamo completamente certi che uno degli eventi nel nostro spazio campionario si verificherà.\nQuando creiamo una distribuzione di probabilità, stiamo dividendo questa certezza totale tra i vari eventi possibili nel nostro spazio campionario. Ad esempio, se stiamo analizzando un problema con cinque possibili esiti distinti, dobbiamo allocare l’intera certezza (pari a 1) tra questi esiti. Ogni valore di probabilità \\(p_n\\) rappresenta la frazione della nostra certezza totale che attribuiamo a un particolare esito.\nLe nozioni di misura e distribuzione di probabilità trovano numerose applicazioni pratiche. Ad esempio:\n\nInferenza bayesiana: Utilizziamo distribuzioni di probabilità per rappresentare le nostre incertezze sui parametri di interesse. Dopo aver osservato i dati, aggiorniamo queste distribuzioni tramite il teorema di Bayes.\nModellizzazione probabilistica: Costruiamo modelli che descrivono il comportamento di sistemi complessi assegnando probabilità agli eventi possibili. Questo ci permette di fare previsioni e prendere decisioni informate basate sulle probabilità assegnate.\n\nIn conclusione, le nozioni di misura e distribuzione di probabilità sono strumenti potenti per allocare e manipolare la nostra certezza tra diversi eventi possibili. Comprendere questi concetti è fondamentale per comprendere le applicazioni della teoria della probabilità e della statistica bayesiana. La “misura totale” \\(M\\) rappresenta la nostra certezza complessiva, e le distribuzioni di probabilità ci permettono di distribuire questa certezza in modo coerente e informato tra gli eventi possibili.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Misura di Probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html",
    "href": "chapters/probability/03_prob_on_general_spaces.html",
    "title": "27  Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra",
    "section": "",
    "text": "27.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nNel Capitolo 26 abbiamo introdotto la teoria della misura e della probabilità su insiemi con un numero finito di elementi. Tuttavia, molti degli spazi matematici che incontriamo nelle applicazioni pratiche, come gli interi e la retta reale, non hanno un numero finito di elementi, ma piuttosto un numero numerabile infinito o addirittura non numerabile infinito di elementi. Sfortunatamente, estendere la teoria della misura e della probabilità a spazi più generali come questi non è sempre semplice.\nSenza entrare nei dettagli, è stato dimostrato che la forma più generale della teoria della misura e della probabilità applicabile a qualsiasi spazio matematico è chiamata \\(\\sigma\\)-algebra. In questo capitolo, forniremo un’introduzione intuitiva ai vincoli delle \\(\\sigma\\)-algebre ed esamineremo alcune notevoli applicazioni. In particolare, introdurremo i concetti di variabile casuale, funzioni di massa di probabilità e funzioni di ripartizione.\nQuesti concetti sono fondamentali per comprendere come la probabilità e la misura possono essere utilizzate in contesti più complessi, permettendo di estendere le nostre analisi a insiemi infiniti e spazi continui, che sono comuni nelle applicazioni psicologiche.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#sigma-algebra",
    "href": "chapters/probability/03_prob_on_general_spaces.html#sigma-algebra",
    "title": "27  Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra",
    "section": "27.2 \\(\\sigma\\)-Algebra",
    "text": "27.2 \\(\\sigma\\)-Algebra\nUna \\(\\sigma\\)-algebra è una struttura matematica che permette di definire in modo coerente quali sottoinsiemi di un insieme sono “misurabili”.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#definizione-di-sigma-algebra",
    "href": "chapters/probability/03_prob_on_general_spaces.html#definizione-di-sigma-algebra",
    "title": "27  Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra",
    "section": "27.3 Definizione di \\(\\sigma\\)-Algebra",
    "text": "27.3 Definizione di \\(\\sigma\\)-Algebra\nUna \\(\\sigma\\)-algebra è una collezione di sottoinsiemi di uno spazio \\(X\\) che soddisfa le seguenti proprietà:\n\nChiusura rispetto al complemento: Se un sottoinsieme \\(A\\) appartiene alla \\(\\sigma\\)-algebra \\(\\mathcal{F}\\), allora anche il suo complemento \\(A^c\\) appartiene a \\(\\mathcal{F}\\). Questo significa che se \\(\\mathcal{F}\\) contiene un certo sottoinsieme, deve contenere anche tutti gli elementi che non sono in quel sottoinsieme.\nChiusura rispetto alle unioni numerabili: Se una sequenza numerabile di sottoinsiemi \\(A_1, A_2, A_3, \\ldots\\) appartiene alla \\(\\sigma\\)-algebra \\(\\mathcal{F}\\), allora anche l’unione di tutti questi sottoinsiemi appartiene a \\(\\mathcal{F}\\). Questo implica che se \\(\\mathcal{F}\\) contiene una serie di sottoinsiemi, deve contenere anche il loro insieme unito.\nInclusione dello spazio campionario: Lo spazio campionario \\(X\\) stesso deve appartenere alla \\(\\sigma\\)-algebra \\(\\mathcal{F}\\). In altre parole, l’intero insieme \\(X\\) è considerato un sottoinsieme misurabile.\n\nLa chiusura in questo contesto significa che la collezione \\(\\mathcal{F}\\) è stabile rispetto a determinate operazioni insiemistiche. In particolare, se si applicano le operazioni di complemento o di unione numerabile a elementi della \\(\\sigma\\)-algebra, i risultati di queste operazioni rimarranno all’interno della stessa \\(\\sigma\\)-algebra. Questo garantisce che la \\(\\sigma\\)-algebra non “perda” elementi a causa di queste operazioni, mantenendo così la coerenza e la completezza della collezione di sottoinsiemi.\n\n27.3.1 Spazio Misurabile\nUn insieme dotato di una \\(\\sigma\\)-algebra, \\((X, \\mathcal{X})\\), è detto spazio misurabile. Gli elementi di una \\(\\sigma\\)-algebra sono noti come sottoinsiemi misurabili, mentre i sottoinsiemi non appartenenti alla \\(\\sigma\\)-algebra sono detti non misurabili. La distinzione tra sottoinsiemi misurabili e non misurabili è cruciale per evitare comportamenti anomali e controintuitivi nella teoria della misura e della probabilità.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#gli-assiomi-di-kolmogorov",
    "href": "chapters/probability/03_prob_on_general_spaces.html#gli-assiomi-di-kolmogorov",
    "title": "27  Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra",
    "section": "27.4 Gli Assiomi di Kolmogorov",
    "text": "27.4 Gli Assiomi di Kolmogorov\nI tre assiomi di Kolmogorov definiscono le proprietà fondamentali di una misura di probabilità e richiedono l’esistenza di una \\(\\sigma\\)-algebra.\n\nNon negatività: Per qualsiasi evento \\(A\\) nello spazio campionario \\(\\Omega\\), la probabilità di \\(A\\) è non negativa. \\[\nP(A) \\geq 0.\n\\]\nNormalizzazione: La probabilità dell’intero spazio campionario \\(\\Omega\\) è 1. \\[\nP(\\Omega) = 1.\n\\]\nAdditività numerabile: Per qualsiasi sequenza numerabile di eventi mutuamente esclusivi \\(A_1, A_2, A_3, \\ldots\\), la probabilità della loro unione è la somma delle loro probabilità. \\[\nP\\left(\\bigcup_{i=1}^{\\infty} A_i\\right) = \\sum_{i=1}^{\\infty} P(A_i).\n\\]\n\n\n27.4.1 Connessione tra gli Assiomi di Kolmogorov e le \\(\\sigma\\)-Algebre\nGli assiomi di Kolmogorov sono definiti rispetto a una misura di probabilità \\(P\\) su uno spazio campionario \\(\\Omega\\) e implicano l’esistenza di una \\(\\sigma\\)-algebra \\(\\mathcal{F}\\). La \\(\\sigma\\)-algebra \\(\\mathcal{F}\\) è la collezione di eventi (sottoinsiemi di \\(\\Omega\\)) per i quali la misura di probabilità \\(P\\) è definita.\n\nNon negatività garantisce che \\(P\\) assegni un valore non negativo a ogni evento nella \\(\\sigma\\)-algebra.\nNormalizzazione garantisce che \\(P(\\Omega) = 1\\), assicurando che \\(\\Omega\\) sia un elemento della \\(\\sigma\\)-algebra.\nAdditività numerabile garantisce che la \\(\\sigma\\)-algebra sia chiusa rispetto alle unioni numerabili di insiemi disgiunti.\n\nIn sintesi, gli assiomi di Kolmogorov richiedono una \\(\\sigma\\)-algebra come struttura all’interno della quale queste proprietà valgono. La \\(\\sigma\\)-algebra è quindi la collezione di eventi per i quali la misura di probabilità è ben definita e coerente con gli assiomi di Kolmogorov.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#probabilità",
    "href": "chapters/probability/03_prob_on_general_spaces.html#probabilità",
    "title": "27  Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra",
    "section": "27.5 Probabilità",
    "text": "27.5 Probabilità\nUna volta definiti gli assiomi di Kolmogorov, è possibile introdurre la definizione di probabilità.\nLa probabilità di un evento è una misura numerica che indica la possibilità che tale evento si verifichi, in accordo con gli assiomi di Kolmogorov.\n\nSe \\(P(A) = 0\\), l’evento \\(A\\) è impossibile.\nSe \\(P(A) = 1\\), l’evento \\(A\\) è certo.\n\nPer denotare la probabilità che un evento \\(A\\) non si verifichi, si usa la notazione \\(P(A^c)\\), dove: \\[\nP(A^c) = 1 - P(A).\n\\]\n\n27.5.1 Proprietà Derivate dagli Assiomi di Kolmogorov\nAlcune proprietà importanti derivate dagli assiomi includono:\n\n\\(P(\\varnothing) = 0\\),\nSe \\(A \\subset B\\), allora \\(P(A) \\leq P(B)\\),\n\\(0 \\leq P(A) \\leq 1\\),\n\\(P(A^c) = 1 - P(A)\\),\nSe \\(A \\cap B = \\varnothing\\), allora \\(P(A \\cup B) = P(A) + P(B)\\).\n\n\n\n27.5.2 Regole di Addizione per Eventi\nPer eventi non mutuamente esclusivi, la probabilità della loro unione è data da: \\[\nP(A \\cup B) = P(A) + P(B) - P(A \\cap B).\n\\]\nUtilizzando il terzo assioma della probabilità, si ottiene: \\[\nP(A \\cup B) = P(A \\cap B^c) + P(B \\cap A^c) + P(A \\cap B).\n\\]\nQuando \\(A\\) e \\(B\\) sono mutuamente esclusivi, \\(P(A \\cap B) = 0\\), e quindi: \\[\nP(A \\cup B) = P(A) + P(B).\n\\]\nLa legge della probabilità totale permette di scrivere: \\[\nP(A) = P(A \\cap B) + P(A \\cap B^c),\n\\] e analogamente per \\(B\\): \\[\nP(B) = P(B \\cap A) + P(B \\cap A^c).\n\\]\nIn conclusione, gli assiomi di Kolmogorov forniscono la base per definire la probabilità su una \\(\\sigma\\)-algebra, garantendo che le proprietà fondamentali della probabilità siano rispettate e che la probabilità sia ben definita per una collezione coerente di sottoinsiemi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#probabilità-e-calcolo-combinatorio",
    "href": "chapters/probability/03_prob_on_general_spaces.html#probabilità-e-calcolo-combinatorio",
    "title": "27  Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra",
    "section": "27.6 Probabilità e Calcolo Combinatorio",
    "text": "27.6 Probabilità e Calcolo Combinatorio\nI problemi scolastici più comuni sulle probabilità richiedono l’uso del calcolo combinatorio. La struttura generale di questi problemi è sempre la stessa: dobbiamo contare il numero di modi in cui un evento compatibile con l’evento di “successo” definito dal problema si realizza e poi trovare la proporzione di tali eventi rispetto a tutti gli eventi possibili (inclusi quelli di “insuccesso”) che possono verificarsi nello spazio campionario. Questi problemi presentano due difficoltà principali:\n\nTrasformare la descrizione verbale del problema in una formulazione matematica chiara, suddividendo gli eventi possibili nello spazio campionario in base alle condizioni di successo e insuccesso definite dal problema.\nContare il numero di successi e il numero totale di eventi.\n\nPer risolvere questi problemi, dobbiamo utilizzare tecniche del calcolo combinatorio, come le permutazioni e le combinazioni, che ci permettono di contare in modo preciso il numero di possibilità.\nConsideriamo un esempio semplice e intuitivo per chiarire il concetto. Supponiamo di avere una scatola con 10 palline numerate da 1 a 10. Vogliamo calcolare la probabilità di estrarre una pallina con un numero pari.\n\nDefinizione degli eventi: In questo caso, l’evento di “successo” è l’estrazione di una pallina con un numero pari.\n\nEventi di successo: {2, 4, 6, 8, 10}\nEventi totali: {1, 2, 3, 4, 5, 6, 7, 8, 9, 10}\n\nConteggio delle possibilità:\n\nNumero di eventi di successo: 5\nNumero totale di eventi: 10\n\nCalcolo della probabilità: \\[\nP(\\text{numero pari}) = \\frac{\\text{numero di eventi di successo}}{\\text{numero totale di eventi}} = \\frac{5}{10} = 0.5.\n\\]\n\nPer problemi più complessi, come il calcolo della probabilità di ottenere una determinata combinazione di carte da un mazzo o di formare un particolare gruppo di persone da una popolazione più grande, utilizziamo strumenti del calcolo combinatorio.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#il-problema-dei-fratelli-bernoulli",
    "href": "chapters/probability/03_prob_on_general_spaces.html#il-problema-dei-fratelli-bernoulli",
    "title": "27  Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra",
    "section": "27.7 Il Problema dei Fratelli Bernoulli",
    "text": "27.7 Il Problema dei Fratelli Bernoulli\nLa soluzione dei problemi di probabilità non è sempre semplice e nella storia della matematica ci sono molti esempi di celebri matematici che hanno commesso errori. Uno di questi aneddoti riguarda Jakob Bernoulli, uno dei pionieri della teoria della probabilità.\nJakob Bernoulli si interessò al calcolo delle probabilità mentre cercava di formalizzare le leggi del caso nel suo libro “Ars Conjectandi”, pubblicato postumo nel 1713. Uno dei problemi che affrontò riguardava il calcolo della probabilità di ottenere almeno una testa in 8 lanci di una moneta equa. Nonostante il suo approccio iniziale fosse corretto, Bernoulli commise un errore nel calcolo combinatorio durante il processo.\nPer risolvere il problema di calcolare la probabilità di ottenere almeno una testa in 8 lanci, bisogna considerare la probabilità complementare, ovvero la probabilità di non ottenere alcuna testa (ottenere solo croci) in 8 lanci, e poi sottrarla da 1:\n\nCalcolo della probabilità complementare: La probabilità di ottenere solo croci in un singolo lancio è \\(\\frac{1}{2}\\). La probabilità di ottenere solo croci in 8 lanci consecutivi è: \\[\n\\left(\\frac{1}{2}\\right)^8 = \\frac{1}{256}.\n\\]\nCalcolo della probabilità di ottenere almeno una testa: \\[\nP(\\text{almeno una testa}) = 1 - P(\\text{nessuna testa}) = 1 - \\frac{1}{256} = \\frac{255}{256}.\n\\]\n\nJakob Bernoulli commise un errore nel calcolo combinatorio che lo portò a una soluzione errata. Egli sottostimò la probabilità di ottenere almeno una testa, probabilmente a causa di un errore nel conteggio delle possibili combinazioni di successi e insuccessi.\nQuesto errore fu successivamente corretto da altri matematici, tra cui suo nipote Daniel Bernoulli, che dimostrarono il metodo corretto per risolvere tali problemi utilizzando il calcolo combinatorio in modo appropriato.\nLa storia del calcolo combinatorio e della probabilità è ricca di aneddoti, come quello di Jakob Bernoulli, che mettono in luce quanto i problemi di probabilità possano essere estremamente controintuitivi, persino per i grandi matematici. Oggi, grazie al lavoro e alle correzioni apportate dai matematici del passato, siamo in grado di risolvere molti di questi problemi con maggiore facilità. La teoria della probabilità, come molte altre discipline scientifiche, è il risultato di un lungo processo di sviluppo e comprensione, che ha richiesto tempo e sforzi considerevoli.\nUna delle sfide della probabilità è che spesso i problemi non si prestano a soluzioni immediate o intuitive. Tuttavia, esistono due approcci fondamentali per affrontarli. Il primo consiste nell’applicare i teoremi della teoria della probabilità, un metodo che, come abbiamo visto, può risultare controintuitivo. Il secondo approccio è quello della simulazione Monte Carlo, che consente di ottenere una soluzione approssimata, ma molto vicina al valore reale, seguendo una procedura più intuitiva. Il nome di questo metodo deriva dal famoso Casinò di Monte Carlo a Monaco, ma possiamo semplicemente riferirci ad esso come metodo di simulazione.\nLa simulazione Monte Carlo è una classe generale di metodi stocastici, in contrasto con i metodi deterministici, utilizzati per risolvere approssimativamente problemi analitici attraverso la generazione casuale delle quantità di interesse. Tra i metodi comunemente utilizzati troviamo il campionamento con reinserimento, in cui la stessa unità può essere selezionata più volte, e il campionamento senza reinserimento, in cui ogni unità può essere selezionata una sola volta. Questi strumenti offrono un potente mezzo per affrontare problemi complessi in modo pratico e accessibile.\n\nEsempio 27.1 Consideriamo il seguente esercizio che presenta un “classico” problema di calcolo delle probabilità.\n“Un’urna contiene 10 palline rosse, 10 palline blu e 20 palline verdi. Se si estraggono 5 palline a caso senza reinserimento, qual è la probabilità che venga selezionata almeno una pallina di ciascun colore?”\nLa soluzione al problema consiste nel contare il numero di modi in cui possono verificarsi gli eventi incompatibili con la condizione richiesta, dividere per il numero totale di modi in cui 5 palline possono essere estratte da un’urna con 40 palline, e sottrarre tale risultato da 1.\nIniziamo dal denominatore (“in quanti modi possono essere estratte 5 palline da un’urna che ne contiene 40”). La soluzione è data dal coefficiente binomiale: \\(\\binom{40}{5}\\).\nDobbiamo poi enumerare tutti i casi incompatibili con la condizione espressa dal problema; al numeratore avremo quindi: (modi di ottenere nessuna pallina rossa) + (modi di ottenere nessuna pallina blu) + (modi di ottenere nessuna pallina verde) - (modi di ottenere nessuna pallina rossa o blu) - (modi di ottenere nessuna pallina rossa o verde) - (modi di ottenere nessuna pallina blu o verde).\nLa soluzione è dunque:\n\\[\nP(\\text{almeno una rossa, blu e verde}) = \\frac{\n\\binom{30}{5} + \\binom{30}{5} + \\binom{20}{5} - \\binom{20}{5} - \\binom{10}{5} - \\binom{10}{5}\n}{\\binom{40}{5}}.\n\\]\nSvolgiamo i calcoli usando Python.\n\n# Funzione per calcolare il coefficiente binomiale\nchoose &lt;- function(n, k) {\n  factorial(n) / (factorial(k) * factorial(n - k))\n}\n\n# Calcoli\nno_red &lt;- choose(30, 5)\nno_blue &lt;- choose(30, 5)\nno_green &lt;- choose(20, 5)\n\n# Modi per estrarre 5 palline senza ottenere due colori specifici\nno_red_blue &lt;- choose(20, 5)\nno_red_green &lt;- choose(10, 5)\nno_blue_green &lt;- choose(10, 5)\n\n# Modi totali per estrarre 5 palline in generale\ntotal_ways &lt;- choose(40, 5)\n\n# Probabilità di estrarre almeno 1 pallina di ciascun colore\nprob_real &lt;- 1 - (no_red + no_blue + no_green - no_red_blue - no_red_green - no_blue_green) / total_ways\nprob_real\n#&gt; [1] 0.5676223\n\nLo stesso risultato si ottiene con una simulazione.\n\nset.seed(12345)\n\n# Creare un'urna con le palline\nurn &lt;- c(rep(\"red\", 10), rep(\"blue\", 10), rep(\"green\", 20))\n\n# Numero di simulazioni\nsimulations &lt;- 100000\n\ncount &lt;- 0\nfor (i in 1:simulations) {\n  # Estrarre 5 palline dall'urna\n  draw &lt;- sample(urn, 5, replace = FALSE)\n  \n  # Verificare se c'è almeno una pallina di ogni colore (red, blue, green)\n  if (\"red\" %in% draw && \"blue\" %in% draw && \"green\" %in% draw) {\n    count &lt;- count + 1\n  }\n}\n\n# Calcolare la probabilità simulata\nprob_simulated &lt;- count / simulations\nprob_simulated\n#&gt; [1] 0.56813\n\n\nIl metodo di simulazione consente di risolvere problemi che implicano il calcolo delle probabilità relative a vari eventi generati dal lancio dei dadi.\n\nEsempio 27.2 Nel caso del lancio di un dado, è facile calcolare la probabilità di ottenere un 1 o un 5. Questa probabilità è \\(\\frac{2}{6}\\). Tuttavia, quando lanciamo due dadi, la situazione si complica perché ci interessa ottenere almeno un 1 o un 5, e c’è la possibilità di ottenere entrambi. Invece di calcolare direttamente questa probabilità, possiamo considerare la probabilità di non ottenere né un 1 né un 5 e sottrarla da 1. Con 2 dadi, la probabilità di non ottenere né un 1 né un 5 è \\(\\frac{4}{6}\\) o \\(\\frac{2}{3}\\) per ogni dado. Per calcolare la probabilità congiunta, possiamo moltiplicare la probabilità per ciascun dado: \\(1 - (\\frac{2}{3} \\times \\frac{2}{3}) = 0.555\\). Questo significa che c’è il 55% di probabilità di ottenere almeno un 1 o un 5 quando si lanciano 2 dadi.\nInvece di calcolare matematicamente la probabilità di ottenere almeno un 1 o un 5, possiamo utilizzare il metodo Monte Carlo, simulando un grande numero di lanci di dadi e ottenendo la risposta attraverso un approccio di forza bruta. Ecco il procedimento generale:\n\nLancia 2 dadi per 100.000 volte (o per il numero di volte che preferisci).\nConta quante volte appare almeno un 1 o un 5 in ciascun lancio.\nDividi questo conteggio per 100.000. Questa sarà la probabilità.\n\n\nset.seed(12345) # Imposta il seme per la riproducibilità\n\n# Numero di simulazioni\nsimulations &lt;- 100000\nsuccess_count &lt;- 0\n\n# Simulazione dei lanci\nfor (i in 1:simulations) {\n  # Lancia due dadi\n  dice_rolls &lt;- sample(1:6, 2, replace = TRUE)\n  \n  # Verifica se c'è almeno un 1 o un 5\n  if (1 %in% dice_rolls || 5 %in% dice_rolls) {\n    success_count &lt;- success_count + 1\n  }\n}\n\n# Calcola la probabilità simulata\nprobability &lt;- success_count / simulations\ncat(sprintf(\"La probabilità di ottenere almeno un 1 o un 5 è: %.3f\\n\", probability))\n#&gt; La probabilità di ottenere almeno un 1 o un 5 è: 0.557\n\n\nUsiamo un ciclo for per simulare i lanci. In ogni iterazione, generiamo due numeri casuali tra 1 e 6, che rappresentano i risultati dei due dadi.\nControlliamo se in ciascun lancio appare almeno un 1 o un 5. Se è così, incrementiamo il contatore success_count.\nAlla fine, la probabilità viene calcolata dividendo success_count per il numero totale di simulazioni, e poi stampiamo il risultato.\n\nQuesto approccio, basato sulla simulazione, permette di ottenere un’ottima approssimazione della probabilità in modo intuitivo, senza dover ricorrere a calcoli matematici complessi.\nÈ facile cambiare la simulazione per consdierare il caso di un numero maggiore di dadi. Per esempio, per il caso del lancio di tre dadi, basta modificare il codice in modo che vengano lanciati tre dadi invece di due. Questo si ottiene cambiando range(2) in range(3) nel ciclo che genera i lanci dei dadi. Questa modifica consente di calcolare la probabilità di ottenere almeno un 1 o un 5 con tre dadi, utilizzando lo stesso approccio basato sulla simulazione.\nQuesto approccio basato sulla simulazione è anche al centro della statistica bayesiana moderna. Poiché il calcolo degli integrali complessi necessari per determinare le distribuzioni posteriori è estremamente difficile, possiamo impiegare processi di Markov Chain Monte Carlo (MCMC) per esplorare lo spazio plausibile della distribuzione posteriore, fino a raggiungere una convergenza su un valore stabile.\n\n\nEsempio 27.3 Il problema dei compleanni, generalmente attribuito a Richard von Mises, è un noto esempio controintuitivo di calcolo delle probabilità che utilizza il calcolo combinatorio, in particolare le permutazioni. Il problema chiede quanti individui sono necessari affinché la probabilità che almeno due persone abbiano lo stesso compleanno superi il 50%, assumendo che ogni giorno dell’anno sia ugualmente probabile come compleanno. Sorprendentemente, la risposta è solo 23 persone, molto meno di quanto la maggior parte delle persone immagina.\nPer risolvere il problema dei compleanni utilizzando le permutazioni, consideriamo la seguente relazione:\n\\[\n\\begin{align*}\nP(\\text{almeno due persone hanno lo stesso compleanno}) &= \\\\\n1 - P(\\text{nessuno ha lo stesso compleanno}).\n\\end{align*}\n\\]\nQuesta uguaglianza è valida perché l’evento “nessuno ha lo stesso compleanno” è il complemento dell’evento “almeno due persone hanno lo stesso compleanno”. Pertanto, dobbiamo calcolare la probabilità che nessuno abbia lo stesso compleanno.\nSia \\(k\\) il numero di persone. Per calcolare la probabilità che nessuno abbia lo stesso compleanno, dobbiamo contare il numero di modi in cui \\(k\\) persone possono avere compleanni diversi. Poiché ogni compleanno è ugualmente probabile, possiamo usare le permutazioni per contare il numero di modi in cui \\(k\\) compleanni unici possono essere disposti su 365 giorni:\n\\[\n365P_k = \\frac{365!}{(365 - k)!}.\n\\]\nDividiamo questo numero per il numero totale di elementi nello spazio campionario, che è il numero totale di modi in cui \\(k\\) compleanni possono essere disposti su 365 giorni:\n\\[\n365^k.\n\\]\nQuindi, la probabilità che nessuno abbia lo stesso compleanno è:\n\\[\nP(\\text{nessuno ha lo stesso compleanno}) = \\frac{365P_k}{365^k} = \\frac{365!}{365^k (365 - k)!}.\n\\]\nUsando questa formula, la probabilità che almeno due persone abbiano lo stesso compleanno è:\n\\[\nP(\\text{almeno due persone hanno lo stesso compleanno}) = 1 - \\frac{365!}{365^k (365 - k)!}.\n\\]\nIn sintesi, calcolando questa probabilità, si scopre che bastano solo 23 persone affinché la probabilità che almeno due di loro abbiano lo stesso compleanno superi il 50%, un risultato sorprendente rispetto all’intuizione comune.\n\n# Funzione per calcolare la probabilità\nbirthday &lt;- function(k) {\n  logdenom &lt;- k * log(365) + lgamma(365 - k + 1) # log denominatore\n  lognumer &lt;- lgamma(366) # log numeratore\n  pr &lt;- 1 - exp(lognumer - logdenom) # trasformazione inversa\n  return(pr)\n}\n\n# Calcola la probabilità per k persone\nk &lt;- 1:50\nbday &lt;- sapply(k, birthday)\n\n# Plot dei risultati\nggplot(data.frame(k = k, bday = bday), aes(x = k, y = bday)) +\n  geom_line(marker = \"o\", alpha = 0.5) +\n  geom_point(alpha = 0.5) +\n  geom_hline(yintercept = 0.5, linetype = \"dashed\", color = \"gray\") +\n  labs(\n    x = \"Numero di persone\",\n    y = \"Probabilità che almeno due persone\\nabbiano lo stesso compleanno\",\n    title = \"Probabilità del Problema dei Compleanni\"\n  ) +\n  xlim(0, 50) +\n  ylim(0, 1)\n#&gt; Warning in geom_line(marker = \"o\", alpha = 0.5): Ignoring unknown\n#&gt; parameters: `marker`\n\n# Probabilità per 20-25 persone\nbday[20:25]\n#&gt; [1] 0.4114384 0.4436883 0.4756953 0.5072972 0.5383443 0.5686997\n\n\n\n\n\n\n\n\nOsserviamo che quando il numero di persone è 23, la probabilità che almeno due persone abbiano lo stesso compleanno supera 0.5. Quando il numero di persone è più di 50, questa probabilità è quasi 1.\n\n\nEsempio 27.4 In precedenza, abbiamo derivato la soluzione analitica esatta per il problema dei compleanni, ma possiamo ottenere una soluzione approssimata in modo più intuitivo utilizzando il metodo della simulazione Monte Carlo.\nPer affrontare il problema dei compleanni, campioniamo \\(k\\) compleanni, che potrebbero non essere unici, tra i 365 giorni dell’anno e verifichiamo se i \\(k\\) compleanni campionati sono tutti diversi. Utilizziamo il campionamento con reinserimento, poiché ogni giorno dei 365 ha la stessa probabilità di essere scelto, indipendentemente dai giorni estratti in precedenza. In altre parole, il fatto che una persona sia nata in un determinato giorno dell’anno non esclude che qualcun altro possa essere nato nello stesso giorno.\nDopo aver ripetuto questa procedura di campionamento molte volte, calcoliamo la frazione di simulazioni in cui almeno due compleanni coincidono. Questa frazione serve come stima della probabilità cercata. Questa procedura di simulazione è intuitiva perché riproduce il processo di generazione dei dati descritto nel problema dei compleanni.\nPer implementare il campionamento con o senza reinserimento in Python, utilizziamo la funzione numpy.random.choice. Nel caso del campionamento con reinserimento, impostiamo l’argomento replace su True. Il campionamento senza reinserimento significa che, una volta campionato un elemento, questo non sarà disponibile per estrazioni successive.\n\nset.seed(12345) # Imposta il seme per la riproducibilità\n\nk &lt;- 23  # Numero di persone\nsims &lt;- 1000  # Numero di simulazioni\nevent &lt;- 0  # Contatore eventi\n\n# Simulazioni per stimare la probabilità\nfor (i in 1:sims) {\n  days &lt;- sample(1:365, k, replace = TRUE)\n  unique_days &lt;- unique(days)\n  if (length(unique_days) &lt; k) {\n    event &lt;- event + 1\n  }\n}\n\n# Frazione di prove in cui almeno due compleanni sono uguali\nanswer &lt;- event / sims\ncat(sprintf(\"Stima della probabilità: %.6f\\n\", answer))\n#&gt; Stima della probabilità: 0.526000\n\n# Aumentare il numero di simulazioni a un milione per maggiore accuratezza\nsims_large &lt;- 1000000\nevent_large &lt;- 0\n\nfor (i in 1:sims_large) {\n  days &lt;- sample(1:365, k, replace = TRUE)\n  unique_days &lt;- unique(days)\n  if (length(unique_days) &lt; k) {\n    event_large &lt;- event_large + 1\n  }\n}\n\nanswer_large &lt;- event_large / sims_large\ncat(sprintf(\"Stima con un milione di simulazioni: %.6f\\n\", answer_large))\n#&gt; Stima con un milione di simulazioni: 0.506565\n\nNel codice sopra, abbiamo impostato il numero di simulazioni a un milione. Osserviamo che quando il numero di persone è 23, la probabilità che almeno due persone abbiano lo stesso compleanno è superiore a 0.5. Quando il numero di persone supera 50, questa probabilità è vicina a 1.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#le-assunzioni-nella-soluzione-dei-problemi",
    "href": "chapters/probability/03_prob_on_general_spaces.html#le-assunzioni-nella-soluzione-dei-problemi",
    "title": "27  Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra",
    "section": "27.8 Le Assunzioni nella Soluzione dei Problemi",
    "text": "27.8 Le Assunzioni nella Soluzione dei Problemi\nNella realtà, i compleanni non seguono una distribuzione uniforme. Una soluzione migliore al problema dei compleanni sarebbe quella di estrarre i compleanni dalla distribuzione effettiva piuttosto che da una distribuzione uniforme in cui ogni giorno ha la stessa probabilità. Non esiste un metodo matematico standard per calcolare questa probabilità; l’unico modo per farlo è attraverso la simulazione.\nNegli Stati Uniti, il CDC e la Social Security Administration monitorano il numero di nascite giornaliere. Nel 2016, FiveThirtyEight ha pubblicato un articolo sulle frequenze giornaliere di nascita e ha reso disponibili i dati in un file CSV su GitHub. Utilizzando il codice fornito da Andrew Heiss, possiamo caricare quei dati e calcolare le probabilità giornaliere dei compleanni negli Stati Uniti.\n\n# Leggi i dati\nbirths_1994_1999 &lt;- read_csv(\n  \"https://raw.githubusercontent.com/fivethirtyeight/data/master/births/US_births_1994-2003_CDC_NCHS.csv\"\n) %&gt;%\n  filter(year &lt; 2000)\n#&gt; Rows: 3652 Columns: 5\n#&gt; ── Column specification ─────────────────────────────────────────────────────\n#&gt; Delimiter: \",\"\n#&gt; dbl (5): year, month, date_of_month, day_of_week, births\n#&gt; \n#&gt; ℹ Use `spec()` to retrieve the full column specification for this data.\n#&gt; ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nbirths_2000_2014 &lt;- read_csv(\n  \"https://raw.githubusercontent.com/fivethirtyeight/data/master/births/US_births_2000-2014_SSA.csv\"\n)\n#&gt; Rows: 5479 Columns: 5\n#&gt; ── Column specification ─────────────────────────────────────────────────────\n#&gt; Delimiter: \",\"\n#&gt; dbl (5): year, month, date_of_month, day_of_week, births\n#&gt; \n#&gt; ℹ Use `spec()` to retrieve the full column specification for this data.\n#&gt; ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Unisci i dataset\nbirths_combined &lt;- bind_rows(births_1994_1999, births_2000_2014)\n\n# Crea la colonna 'full_date' con un anno fittizio 2024 per mantenere la corretta relazione giorno/mese\nbirths_combined &lt;- births_combined %&gt;%\n  mutate(\n    full_date = make_date(2024, month, date_of_month),\n    day_of_year = yday(full_date),\n    month_categorical = month.name[month]\n  )\n\n# Calcola la media delle nascite per ciascun giorno del mese per ogni mese\navg_births_month_day &lt;- births_combined %&gt;%\n  group_by(month_categorical, date_of_month) %&gt;%\n  summarise(avg_births = mean(births, na.rm = TRUE)) %&gt;%\n  ungroup()\n#&gt; `summarise()` has grouped output by 'month_categorical'. You can override\n#&gt; using the `.groups` argument.\n\n# Correggi l'ordine dei mesi per l'asse Y\navg_births_month_day &lt;- avg_births_month_day %&gt;%\n  mutate(month_categorical = factor(month_categorical, levels = month.name))\n\n# Crea una matrice per la heatmap\navg_births_pivot &lt;- dcast(\n  avg_births_month_day,\n  month_categorical ~ date_of_month,\n  value.var = \"avg_births\"\n)\n\nggplot(avg_births_month_day, aes(x = date_of_month, y = month_categorical, fill = avg_births)) +\n  geom_tile() +\n  scale_fill_distiller(palette = \"Spectral\", name = \"Average births\") +\n  labs(\n    title = \"Average births per day\",\n    subtitle = \"1994–2014\",\n    x = \"\",\n    y = \"\"\n  ) +\n  theme_minimal() +\n  theme(axis.text.y = element_text(angle = 0, hjust = 1))\n\n\n\n\n\n\n\n\nSi noti che i dati rivelano alcuni pattern evidenti:\n\nNessuno sembra voler avere figli durante le festività di Natale o Capodanno. Il giorno di Natale, la vigilia di Natale e il giorno di Capodanno presentano il numero medio di nascite più basso.\nAnche la vigilia di Capodanno, Halloween, il 4 luglio, il 1° aprile e l’intera settimana del Ringraziamento mostrano medie particolarmente basse.\nIl 13 di ogni mese registra leggermente meno nascite rispetto alla media—la colonna relativa al giorno 13 è particolarmente evidente in questo contesto.\nI giorni con il numero medio di nascite più alto si trovano a metà settembre, dal 9 al 20, ad eccezione dell’11 settembre.\n\nImmagino che in Italia i pattern siano, almeno in parte, diversi.\nNon è l’obiettivo qui riformulare la soluzione del problema dei compleanni utilizzando la distribuzione effettiva delle nascite piuttosto che quella uniforme, ma piuttosto sottolineare che le procedure di risoluzione dei problemi si basano su assunzioni—nel caso del problema dei compleanni, l’assunzione che la distribuzione dei compleanni sia uniforme, quando in realtà non lo è. Le soluzioni che otteniamo nei problemi probabilistici descrivono le regolarità osservabili nel mondo empirico tanto meglio quanto più sono ragionevoli le assunzioni formulate.\nIn tutti i modelli probabilistici (e quindi, in tutti i modelli scientifici, dato che esistono solo modelli probabilistici) è fondamentale prestare particolare attenzione alla plausibilità delle assunzioni su cui tali modelli si basano.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#commenti-e-considerazioni-finali",
    "href": "chapters/probability/03_prob_on_general_spaces.html#commenti-e-considerazioni-finali",
    "title": "27  Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra",
    "section": "27.9 Commenti e considerazioni finali",
    "text": "27.9 Commenti e considerazioni finali\nLa teoria delle probabilità è un pilastro fondamentale della statistica, con applicazioni pratiche in numerosi campi, tra cui la psicologia. Comprendere le probabilità ci consente di prendere decisioni informate in situazioni di incertezza e di formulare previsioni affidabili. Una solida conoscenza delle basi della probabilità ci permette di affrontare una vasta gamma di problemi e di fare scelte ponderate basate sulla probabilità dei vari esiti possibili. Tuttavia, è importante ricordare che i modelli probabilistici sono solo approssimazioni della realtà e possono essere influenzati da semplificazioni o dalle limitazioni dei dati disponibili. Pertanto, è fondamentale interpretare i risultati con cautela e avere piena consapevolezza delle assunzioni che sottendono le analisi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#esercizi",
    "href": "chapters/probability/03_prob_on_general_spaces.html#esercizi",
    "title": "27  Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra",
    "section": "27.10 Esercizi",
    "text": "27.10 Esercizi\n\nEsercizio 27.1 Supponiamo di dover formare una commissione di 5 psicologi su un gruppo di 20 persone (10 psicologi clinici e 10 psicologi del lavoro). Qual è la probabilità che almeno 2 psicologi clinici siano nella commissione? Risolvi il problema usando una simulazione Monte Carlo.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/03_prob_on_general_spaces.html#informazioni-sullambiente-di-sviluppo",
    "title": "27  Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] reshape2_1.4.4    MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2\n#&gt;  [5] ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0  \n#&gt;  [9] bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0      markdown_1.13    \n#&gt; [13] knitr_1.49        lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1    \n#&gt; [17] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#&gt; [21] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [25] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6       xfun_0.49          htmlwidgets_1.6.4 \n#&gt;  [4] rstatix_0.7.2      lattice_0.22-6     tzdb_0.4.0        \n#&gt;  [7] vctrs_0.6.5        tools_4.4.2        generics_0.1.3    \n#&gt; [10] curl_6.0.1         parallel_4.4.2     fansi_1.0.6       \n#&gt; [13] pacman_0.5.1       pkgconfig_2.0.3    RColorBrewer_1.1-3\n#&gt; [16] lifecycle_1.0.4    compiler_4.4.2     farver_2.1.2      \n#&gt; [19] munsell_0.5.1      mnormt_2.1.1       carData_3.0-5     \n#&gt; [22] httpuv_1.6.15      htmltools_0.5.8.1  yaml_2.3.10       \n#&gt; [25] Formula_1.2-5      crayon_1.5.3       car_3.1-3         \n#&gt; [28] pillar_1.9.0       later_1.4.0        abind_1.4-8       \n#&gt; [31] nlme_3.1-166       mime_0.12          tidyselect_1.2.1  \n#&gt; [34] digest_0.6.37      stringi_1.8.4      labeling_0.4.3    \n#&gt; [37] rprojroot_2.0.4    fastmap_1.2.0      grid_4.4.2        \n#&gt; [40] colorspace_2.1-1   cli_3.6.3          magrittr_2.0.3    \n#&gt; [43] utf8_1.2.4         broom_1.0.7        withr_3.0.2       \n#&gt; [46] backports_1.5.0    promises_1.3.1     bit64_4.5.2       \n#&gt; [49] timechange_0.3.0   rmarkdown_2.29     bit_4.5.0         \n#&gt; [52] ggsignif_0.6.4     hms_1.1.3          shiny_1.9.1       \n#&gt; [55] evaluate_1.0.1     miniUI_0.1.1.1     rlang_1.1.4       \n#&gt; [58] Rcpp_1.0.13-1      xtable_1.8-4       glue_1.8.0        \n#&gt; [61] vroom_1.6.5        jsonlite_1.8.9     plyr_1.8.9        \n#&gt; [64] R6_2.5.1",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html",
    "href": "chapters/probability/04_conditional_prob.html",
    "title": "28  Probabilità condizionata",
    "section": "",
    "text": "28.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nIn questo capitolo esploreremo alcuni concetti chiave per una comprensione approfondita dell’aggiornamento bayesiano:\nQuesti concetti sono fondamentali per navigare nel processo di inferenza bayesiana e per comprendere come le probabilità si aggiornano in risposta a nuove informazioni. Inoltre, esamineremo i principali teoremi legati alla probabilità condizionata.\nPreparazione del Notebook\nLa probabilità è un linguaggio che ci consente di esprimere il nostro grado di credenza o incertezza riguardo all’occorrenza di eventi futuri. Questo concetto è strettamente legato all’idea di probabilità condizionata, che è fondamentale nella teoria della probabilità.\nLa probabilità condizionata si riferisce al calcolo della probabilità di un evento, tenendo conto che un altro evento si è già verificato. Questo concetto è cruciale perché riflette come aggiorniamo le nostre credenze alla luce di nuove evidenze o informazioni. Per esempio, immaginiamo di voler stimare la probabilità di pioggia per domani. La nostra stima iniziale cambia se oggi osserviamo un cielo nuvoloso. Il fatto che oggi sia nuvoloso “condiziona” la nostra valutazione della probabilità di pioggia per domani.\nQuesto processo di aggiornamento delle nostre credenze in base a nuove osservazioni è continuo. Una nuova evidenza coerente con una credenza esistente potrebbe rafforzarla, mentre un’osservazione inaspettata potrebbe metterla in discussione. La probabilità condizionata non è solo un concetto teorico, ma ha applicazioni pratiche sia nella vita quotidiana che in ambito scientifico. In realtà, si potrebbe argomentare che tutte le probabilità sono in qualche modo condizionate da un certo contesto o da informazioni preesistenti, anche se non sempre lo specifichiamo esplicitamente.\nIn sintesi, la probabilità condizionata ci fornisce un framework per comprendere e quantificare come le nostre credenze dovrebbero evolversi man mano che acquisiamo nuove informazioni, rendendo il concetto di probabilità uno strumento dinamico e potente per gestire l’incertezza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#indipendenza-stocastica",
    "href": "chapters/probability/04_conditional_prob.html#indipendenza-stocastica",
    "title": "28  Probabilità condizionata",
    "section": "28.2 Indipendenza Stocastica",
    "text": "28.2 Indipendenza Stocastica\nNel contesto della probabilità condizionata, il concetto di indipendenza gioca un ruolo fondamentale. Questa caratteristica permette di semplificare notevolmente il calcolo delle probabilità in molti problemi, evidenziando come la conoscenza di un evento non fornisca alcuna informazione aggiuntiva sull’altro.\n\n28.2.1 Indipendenza di Due Eventi\nDue eventi \\(A\\) e \\(B\\) sono detti indipendenti se il verificarsi di uno non influenza la probabilità di verificarsi dell’altro. Formalmente, questa condizione è espressa come:\n\\[\\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\mathbb{P}(B),\\]\ndove \\(\\mathbb{P}(A \\cap B)\\) rappresenta la probabilità che entrambi gli eventi \\(A\\) e \\(B\\) si verifichino simultaneamente.\nSe questa condizione è soddisfatta, scriviamo \\(A \\text{ ⫫ } B\\), il che significa “A è indipendente da B”.\n\n\n28.2.2 Indipendenza di un Insieme di Eventi\nL’indipendenza stocastica è un concetto fondamentale nell’applicazione della probabilità in campo statistico. Un insieme di eventi \\(\\{ A_i : i \\in I \\}\\) è detto indipendente se per ogni sottoinsieme finito \\(J\\) di \\(I\\), la probabilità dell’intersezione degli eventi nel sottoinsieme \\(J\\) è uguale al prodotto delle loro singole probabilità. Formalmente:\n\\[\\mathbb{P} \\left( \\cap_{i \\in J} A_i \\right) = \\prod_{i \\in J} \\mathbb{P}(A_i).\\]\nQuesto significa che ogni combinazione finita di eventi nell’insieme è indipendente.\nL’indipendenza può essere assunta o derivata a seconda del contesto. In alcuni modelli o situazioni, assumiamo che certi eventi siano indipendenti perché questa assunzione semplifica i calcoli o riflette una conoscenza previa. In altri casi, l’indipendenza può essere derivata dai dati o da altre proprietà del modello.\n\n\n28.2.3 Eventi Disgiunti e Indipendenza\nEventi disgiunti (o mutuamente esclusivi) sono quelli che non possono verificarsi simultaneamente, cioè \\(\\mathbb{P}(A \\cap B) = 0\\). Se due eventi disgiunti hanno una probabilità positiva di verificarsi, allora non possono essere indipendenti. Questo perché per eventi disgiunti con \\(\\mathbb{P}(A) &gt; 0\\) e \\(\\mathbb{P}(B) &gt; 0\\), l’equazione di indipendenza \\(\\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\mathbb{P}(B)\\) non può essere soddisfatta, dato che \\(\\mathbb{P}(A \\cap B) = 0\\) e \\(\\mathbb{P}(A) \\mathbb{P}(B) &gt; 0\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#sec-v",
    "href": "chapters/probability/04_conditional_prob.html#sec-v",
    "title": "28  Probabilità condizionata",
    "section": "28.3 Probabilità condizionata su altri eventi",
    "text": "28.3 Probabilità condizionata su altri eventi\nLa probabilità di un evento è intrinsecamente condizionata dal nostro stato di informazione. In presenza di un determinato insieme di informazioni, attribuiamo a un evento una probabilità specifica di occorrenza. Tuttavia, qualora il nostro stato informativo subisca una modifica, anche la probabilità associata all’evento verrà corrispondentemente aggiornata.\nIn realtà, tutte le probabilità possono essere intese come probabilità condizionate, anche quando la variabile o l’evento condizionante non è esplicitamente specificato. Ciò implica che le probabilità sono sempre contestualizzate e dipendono dal set informativo disponibile in un dato scenario.\nQuesto quadro concettuale ci induce a considerare le probabilità come una ‘misura di plausibilità’ che riflette la nostra conoscenza corrente del sistema o del fenomeno sotto indagine. A seguito dell’acquisizione di nuove informazioni o di cambiamenti nel contesto, la nostra misura di plausibilità, e quindi la probabilità attribuita agli eventi, può essere rivista.\n\nTeorema 28.1 Siano \\(A\\) e \\(B\\) due eventi definiti su uno spazio campionario \\(S\\). Supponendo che l’evento \\(B\\) si verifichi, la probabilità condizionata di \\(A\\) dato \\(B\\) è data da\n\\[\nP(A \\mid B) = \\frac{P(A \\cap B)}{P(B)}, \\quad \\text{per}\\, P(B) &gt; 0,\n\\tag{28.1}\\]\ndove \\(P(A \\cap B)\\) rappresenta la probabilità congiunta dei due eventi, ovvero la probabilità che entrambi si verifichino.\n\nNell’Equazione 28.1, \\(P(A \\cap B)\\) è la probabilità congiunta che entrambi gli eventi si verifichino, mentre \\(P(B)\\) è la probabilità marginale dell’evento \\(B\\). Riorganizzando i termini, otteniamo la regola della moltiplicazione:\n\\[\nP(A \\cap B) = P(A \\mid B)P(B) = P(B \\mid A)P(A).\n\\]\nUtilizzando questa regola, possiamo derivare una forma alternativa della legge della probabilità totale:\n\\[\nP(A) = P(A \\mid B)P(B) + P(A \\mid B^c)P(B^c).\n\\]\nDove \\(B^c\\) rappresenta il complemento dell’evento \\(B\\).\nÈ importante notare che \\(P(A \\mid B)\\) non è definita se \\(P(B) = 0\\).\nLa probabilità condizionata può essere interpretata come una ricalibrazione dello spazio campionario da \\(S\\) a \\(B\\). Per spazi campionari discreti, la probabilità condizionata è espressa come\n\\[\nP(A \\mid B) = \\frac{| A \\cap B |}{| B |}.\n\\]\n\nEsempio 28.1 Lanciamo due dadi equilibrati e vogliamo calcolare la probabilità che la somma dei punteggi ottenuti sia minore di 8.\nInizialmente, quando non abbiamo ulteriori informazioni, possiamo calcolare la probabilità in modo tradizionale. Ci sono 21 risultati possibili con somma minore di 8. Poiché ci sono 36 possibili combinazioni di lancio dei due dadi, la probabilità di ottenere una somma minore di 8 è 21/36, che equivale a circa 0.58.\nSupponiamo ora di sapere che la somma del lancio di due dadi ha prodotto un risultato dispari. In questo caso, ci sono solo 18 possibili combinazioni di lancio dei due dadi (dato che abbiamo escluso i risultati pari). Tra essi, vi sono 12 risultati che soddisfano la condizione per cui la somma è minore di 8. Quindi, la probabilità di ottenere una somma minore di 8 cambia da circa 0.58 a 12/18, ovvero 0.67 quando consideriamo l’informazione aggiuntiva del risultato dispari.\nSvolgiamo il problema in Python.\n\nr &lt;- 1:6\nsample &lt;- expand.grid(i = r, j = r)\nsample\n#&gt;    i j\n#&gt; 1  1 1\n#&gt; 2  2 1\n#&gt; 3  3 1\n#&gt; 4  4 1\n#&gt; 5  5 1\n#&gt; 6  6 1\n#&gt; 7  1 2\n#&gt; 8  2 2\n#&gt; 9  3 2\n#&gt; 10 4 2\n#&gt; 11 5 2\n#&gt; 12 6 2\n#&gt; 13 1 3\n#&gt; 14 2 3\n#&gt; 15 3 3\n#&gt; 16 4 3\n#&gt; 17 5 3\n#&gt; 18 6 3\n#&gt; 19 1 4\n#&gt; 20 2 4\n#&gt; 21 3 4\n#&gt; 22 4 4\n#&gt; 23 5 4\n#&gt; 24 6 4\n#&gt; 25 1 5\n#&gt; 26 2 5\n#&gt; 27 3 5\n#&gt; 28 4 5\n#&gt; 29 5 5\n#&gt; 30 6 5\n#&gt; 31 1 6\n#&gt; 32 2 6\n#&gt; 33 3 6\n#&gt; 34 4 6\n#&gt; 35 5 6\n#&gt; 36 6 6\n\n\nevent &lt;- subset(sample, i + j &lt; 8)\ncat(nrow(event), \"/\", nrow(sample), \"\\n\")\n#&gt; 21 / 36\n\n\nsample_odd &lt;- subset(sample, (i + j) %% 2 != 0)\nsample_odd\n#&gt;    i j\n#&gt; 2  2 1\n#&gt; 4  4 1\n#&gt; 6  6 1\n#&gt; 7  1 2\n#&gt; 9  3 2\n#&gt; 11 5 2\n#&gt; 14 2 3\n#&gt; 16 4 3\n#&gt; 18 6 3\n#&gt; 19 1 4\n#&gt; 21 3 4\n#&gt; 23 5 4\n#&gt; 26 2 5\n#&gt; 28 4 5\n#&gt; 30 6 5\n#&gt; 31 1 6\n#&gt; 33 3 6\n#&gt; 35 5 6\n\n\nevent &lt;- subset(sample_odd, i + j &lt; 8)\ncat(nrow(event), \"/\", nrow(sample_odd), \"\\n\")\n#&gt; 12 / 18\n\nSe applichiamo l’Equazione 28.1, abbiamo: \\(P(A \\cap B)\\) = 12/36, \\(P(B)\\) = 18/36 e\n\\[\nP(A \\mid B) = \\frac{12}{18}.\n\\]\nQuesto esempio illustra come la probabilità di un evento possa variare in base alle informazioni aggiuntive di cui disponiamo. Nel secondo caso, avendo l’informazione che la somma è dispari, la probabilità di ottenere una somma minore di 8 aumenta notevolmente rispetto al caso iniziale in cui non avevamo questa informazione.\n\n\nEsempio 28.2 Consideriamo uno screening per la diagnosi precoce del tumore mammario utilizzando un test con determinate caratteristiche:\n\nSensibilità del test: 90%. Questo significa che il test classifica correttamente come positivo il 90% delle donne colpite dal cancro al seno.\nSpecificità del test: 90%. Ciò indica che il test classifica correttamente come negativo il 90% delle donne che non hanno il cancro al seno.\nPrevalenza del cancro al seno nella popolazione sottoposta allo screening: 1% (0.01). Questo è il 1% delle donne che ha effettivamente il cancro al seno, mentre il restante 99% (0.99) non ne è affetto.\n\nOra cerchiamo di rispondere alle seguenti domande:\n\nQual è la probabilità che una donna scelta a caso ottenga una mammografia positiva? Poiché il 1% delle donne ha il cancro al seno, la probabilità di ottenere una mammografia positiva (test positivo) è pari alla sensibilità del test, ovvero 0.90 (cioè 90%).\nSe la mammografia è positiva, qual è la probabilità che vi sia effettivamente un tumore al seno?\n\nPer risolvere questo problema, consideriamo un campione di 1000 donne sottoposte al test di screening per il tumore al seno. Di queste 1000 donne:\n\n10 donne (1% del campione) hanno effettivamente il cancro al seno. Per queste 10 donne con il cancro, il test darà un risultato positivo (vera positività) in 9 casi (90%).\nPer le restanti 990 donne (99% del campione) che non hanno il cancro al seno, il test darà un risultato positivo (falsa positività) in 99 casi (10%).\n\nQuesta situazione può essere rappresentata graficamente nel seguente modo:\n\n\n\n\n\n\nFigura 28.1: Esiti della mammografia per 1000 donne.\n\n\n\nCombinando i due risultati precedenti, vediamo che il test dà un risultato positivo per 9 donne che hanno effettivamente il cancro al seno e per 99 donne che non lo hanno, per un totale di 108 risultati positivi su 1000. Pertanto, la probabilità di ottenere un risultato positivo al test è \\(\\frac{108}{1000}\\) = 0.108.\nTuttavia, tra le 108 donne che hanno ottenuto un risultato positivo al test, solo 9 hanno effettivamente il cancro al seno. Quindi, la probabilità di avere il cancro al seno, dato un risultato positivo al test, è pari a \\(\\frac{9}{108}\\) = 0.083, corrispondente all’8.3%.\nIn questo esempio, la probabilità dell’evento “ottenere un risultato positivo al test” è una probabilità non condizionata, poiché calcoliamo semplicemente la proporzione di risultati positivi nel campione totale. D’altra parte, la probabilità dell’evento “avere il cancro al seno, dato che il test ha prodotto un risultato positivo” è una probabilità condizionata, poiché calcoliamo la proporzione delle donne con il cancro al seno tra quelle che hanno ottenuto un risultato positivo al test.\nQuesto esempio illustra come la conoscenza di ulteriori informazioni (il risultato positivo al test) può influenzare la probabilità di un evento (avere il cancro al seno), mostrando chiaramente la differenza tra probabilità condizionate e non condizionate.\n\n\nEsempio 28.3 Il problema di Monty Hall è diventato famoso grazie alla rubrica tenuta da Marilyn vos Savant nella rivista Parade, che rispose alla seguente lettera, pubblicata il 9 settembre 1990:\n\n“Supponiamo che tu sia in un quiz televisivo, e ti venga data la scelta tra tre porte. Dietro una delle porte c’è un’auto, dietro le altre due ci sono delle capre. Tu scegli una porta, diciamo la numero 1, e il conduttore, che sa cosa c’è dietro ogni porta, apre un’altra porta, diciamo la numero 3, che contiene una capra. Il conduttore ti chiede quindi se vuoi cambiare la tua scelta e passare alla porta numero 2. È vantaggioso cambiare la scelta?” Craig. F. Whitaker, Columbia, MD\n\nLa situazione descritta nella lettera è simile a quella che i concorrenti affrontavano nel quiz televisivo degli anni ’70 Let’s Make a Deal, condotto da Monty Hall e Carol Merrill. Marilyn rispose che il concorrente dovrebbe cambiare la scelta, poiché se l’auto è dietro una delle due porte non scelte (il che è due volte più probabile rispetto alla porta inizialmente scelta), il concorrente vince cambiando porta. Tuttavia, la sua risposta suscitò una reazione a catena, con molte lettere, persino da parte di matematici, che affermavano che avesse torto. Questo episodio diede origine al problema di Monty Hall e innescò migliaia di ore di dibattiti.\nQuesto incidente sottolinea un aspetto fondamentale della probabilità: spesso, l’intuizione porta a conclusioni completamente errate. Fino a quando non si affinano le capacità nel trattare problemi di probabilità, un approccio rigoroso e sistematico è utile per evitare errori.\nChiarire il Problema\nLa lettera originale di Craig Whitaker è un po’ vaga, quindi dobbiamo fare delle ipotesi per poter modellare formalmente il gioco. Supponiamo che:\n\nL’auto sia nascosta in modo casuale ed equiprobabile dietro una delle tre porte.\nIl giocatore scelga una delle tre porte in modo casuale, indipendentemente dalla posizione dell’auto.\nDopo che il giocatore ha scelto una porta, il conduttore apre un’altra porta, che contiene una capra, e offre al giocatore la possibilità di mantenere la scelta o cambiarla.\nSe il conduttore ha la possibilità di scegliere quale porta aprire (ossia, se ci sono due capre disponibili), sceglie casualmente quale porta aprire.\n\nCon queste assunzioni, possiamo affrontare la domanda: “Qual è la probabilità che un giocatore che cambia porta vinca l’auto?”\nIl Metodo in Quattro Passi\nOgni problema di probabilità riguarda un esperimento o un processo casuale. In questi casi, il problema può essere suddiviso in quattro fasi distinte.\nPasso 1: Trovare lo Spazio Campionario\nIl primo passo è identificare tutti i possibili esiti dell’esperimento. Nel problema di Monty Hall, ci sono tre quantità determinate casualmente:\n\nLa porta che nasconde l’auto.\nLa porta scelta inizialmente dal giocatore.\nLa porta che il conduttore apre per rivelare una capra.\n\nUn diagramma ad albero può aiutarci a visualizzare il problema, dato che il numero di esiti non è troppo grande e la struttura è semplice. Il primo evento casuale è la posizione dell’auto, che rappresentiamo con tre rami in un albero. Ogni ramo corrisponde a una delle porte. La seconda quantità casuale è la porta scelta dal giocatore, rappresentata nel secondo livello dell’albero, e la terza quantità casuale è la porta che il conduttore apre, mostrata nel terzo livello.\nEcco un esempio di diagramma ad albero in Python che rappresenta questa situazione:\n\n\n\n\n\n\nFigura 28.2: Il diagramma ad albero per il Problema di Monty Hall mostra le probabilità associate a ogni possibile esito. I pesi sugli archi rappresentano la probabilità di seguire quel particolare percorso, dato che ci troviamo nel nodo padre. Ad esempio, se l’auto si trova dietro la porta A, la probabilità che il giocatore scelga inizialmente la porta B è pari a 1/3. La colonna più a destra del diagramma mostra la probabilità di ciascun esito finale. Ogni probabilità di esito è calcolata moltiplicando le probabilità lungo il percorso che parte dalla radice (auto dietro una certa porta) e termina alla foglia (esito finale) (Figura tratta da Lehman, Leighton e Meyer, 2018).\n\n\n\nNel diagramma ad albero, i rami rappresentano le possibili combinazioni delle porte, e le foglie rappresentano gli esiti dell’esperimento. Ogni foglia dell’albero rappresenta un esito dello spazio campionario, che nel nostro caso è composto da 12 esiti. Per esempio, (Car A, Pick B, Reveal C).\nPasso 2: Definire gli Eventi di Interesse\nL’evento di interesse è “il giocatore vince cambiando porta”. Questo significa che, se la porta scelta dal giocatore inizialmente non contiene l’auto, e il giocatore decide di cambiare porta, allora vincerà. Gli esiti favorevoli sono quelli in cui la porta inizialmente scelta dal giocatore non nasconde l’auto, e cambiando porta il giocatore sceglie correttamente la porta che nasconde l’auto.\nGli esiti che soddisfano questa condizione sono:\n\n(Car A, Pick B, Reveal C)\n(Car A, Pick C, Reveal B)\n(Car B, Pick A, Reveal C)\n(Car B, Pick C, Reveal A)\n(Car C, Pick A, Reveal B)\n(Car C, Pick B, Reveal A)\n\nQuesti esiti sono 6 in totale.\nPasso 3: Calcolare le Probabilità degli Esiti\nOgni esito ha una certa probabilità di verificarsi. Il modo per determinare la probabilità di ciascun esito è moltiplicare le probabilità lungo il percorso nell’albero.\nEsempio di calcolo per l’esito (Car A, Pick B, Reveal C):\n\nLa probabilità che l’auto sia dietro la porta A è \\(\\frac{1}{3}\\).\nLa probabilità che il giocatore scelga la porta B è \\(\\frac{1}{3}\\).\nLa probabilità che il conduttore apra la porta C (che contiene una capra) è \\(1\\) (poiché il conduttore deve aprire una porta con una capra, e la porta C è l’unica possibile).\n\nLa probabilità totale per questo esito è:\n\\[\nP(\\text{Car A, Pick B, Reveal C}) = \\frac{1}{3} \\times \\frac{1}{3} \\times 1 = \\frac{1}{9}.\n\\]\nProcedendo in modo simile per tutti gli altri esiti, otteniamo le probabilità per tutti i 12 esiti.\nPasso 4: Calcolare le Probabilità degli Eventi\nLa probabilità di vincere cambiando porta è data dalla somma delle probabilità degli esiti favorevoli elencati sopra.\n\\[\n\\begin{aligned}\nP&(\\text{vincere cambiando porta}) = \\notag \\\\\n&\\quad P(\\text{Car A, Pick B, Reveal C}) + P(\\text{Car A, Pick C, Reveal B}) + \\notag\\\\  \n&\\quad P(\\text{Car B, Pick A, Reveal C}) + \\dots \\notag\n\\end{aligned}\n\\]\n\\[\n= \\frac{1}{9} + \\frac{1}{9} + \\frac{1}{9} + \\frac{1}{9} + \\frac{1}{9} + \\frac{1}{9} = \\frac{6}{9} = \\frac{2}{3}.\n\\]\nLa probabilità di vincere mantenendo la scelta originale è semplicemente il complemento:\n\\[\nP(\\text{vincere mantenendo la scelta}) = 1 - P(\\text{vincere cambiando porta}) = 1 - \\frac{2}{3} = \\frac{1}{3}.\n\\]\nLa conclusione è che il giocatore ha una probabilità di vincere pari a \\(\\frac{2}{3}\\) se cambia porta, contro una probabilità di \\(\\frac{1}{3}\\) se mantiene la sua scelta iniziale. Cambiare porta è quindi la strategia vincente. Questo risultato controintuitivo è il motivo per cui il problema di Monty Hall ha causato tanta confusione inizialmente.\nIl problema di Monty Hall è un classico esempio di probabilità condizionata perché la probabilità di vincere l’auto dipende da informazioni aggiuntive ottenute durante il gioco, cioè la porta che il conduttore apre. Inizialmente, la probabilità di trovare l’auto dietro la porta scelta dal giocatore è \\(\\frac{1}{3}\\), mentre la probabilità che l’auto sia dietro una delle altre due porte è \\(\\frac{2}{3}\\).\nQuando il conduttore apre una porta mostrando una capra, fornisce nuove informazioni che cambiano le probabilità. Questa nuova informazione condiziona la probabilità che l’auto sia dietro la porta non scelta dal giocatore, facendo sì che la probabilità di vincere cambiando porta diventi \\(\\frac{2}{3}\\). Quindi, il problema di Monty Hall è un esempio di probabilità condizionata perché l’aggiornamento delle probabilità dipende da un evento intermedio (la scelta della porta aperta dal conduttore).\n\n\nEsempio 28.4 Per confermare il risultato inaspettato del Problema di Monty Hall, è possibile eseguire una simulazione. In questa simulazione, consideriamo due scenari: uno in cui il concorrente mantiene la sua scelta iniziale e un altro in cui cambia la sua scelta dopo che Monty Hall ha svelato una capra. Ripetendo questa simulazione migliaia di volte, possiamo confrontare i risultati empirici e confermare come effettivamente il cambiamento di scelta aumenti le probabilità del concorrente di vincere l’automobile.\nDi seguito è riportato lo script di una simulazione progettata per illustrare il paradosso di Monty Hall.\n\nset.seed(123)  # For reproducibility\n\nporte &lt;- c(\"capra1\", \"capra2\", \"macchina\")  # Define the game\ncounter &lt;- 0\ncontatore_cambio &lt;- 0\nn &lt;- 10000\nporta_vincente &lt;- \"macchina\"\n\nfor (i in 1:n) {\n  scelta_casuale &lt;- sample(porte, 1)\n  porte_rimaste &lt;- porte[porte != scelta_casuale]\n  porta_rivelata &lt;- sample(porte_rimaste[porte_rimaste != porta_vincente], 1)\n  porta_alternativa &lt;- porte[porte != scelta_casuale & porte != porta_rivelata]\n  \n  if (\"macchina\" %in% porta_alternativa) {\n    contatore_cambio &lt;- contatore_cambio + 1\n  }\n  \n  if (scelta_casuale == \"macchina\") {\n    counter &lt;- counter + 1\n  }\n}\n\ncat(counter / n, \"\\n\")  # Proportion of wins without changing the door\n#&gt; 0.3342\ncat(contatore_cambio / n, \"\\n\")  # Proportion of wins by changing the door\n#&gt; 0.6658\n\nLa simulazione mostra che, effettivamente, la probabilità di vincere la macchina aumenta quando il concorrente sceglie di cambiare porta.\n\n\n28.3.1 Il paradosso di Simpson\nNel campo della probabilità condizionata, uno dei fenomeni più interessanti e, nel contempo, più controintuitivi, è rappresentato dal paradosso di Simpson. Il paradosso di Simpson è un fenomeno statistico in cui una tendenza che appare in diversi gruppi separati di dati scompare o si inverte quando i dati vengono combinati. Questo paradosso mette in luce l’importanza di considerare le variabili confondenti e di analizzare i dati con attenzione per evitare conclusioni errate.\n\nEsempio 28.5 Due psicoterapeuti, Rossi e Bianchi, praticano due tipi di terapie: terapia per disturbi d’ansia e coaching per migliorare le prestazioni lavorative. Ogni terapia può avere un esito positivo o negativo.\nI rispettivi bilanci dei due terapeuti sono riportati nelle seguenti tabelle.\nRossi\n\n\n\nTipo di terapia\nSuccesso\nFallimento\n\n\n\n\nDisturbi d’ansia\n70\n20\n\n\nCoaching lavorativo\n10\n0\n\n\nTotale\n80\n20\n\n\n\nBianchi\n\n\n\nTipo di terapia\nSuccesso\nFallimento\n\n\n\n\nDisturbi d’ansia\n2\n8\n\n\nCoaching lavorativo\n81\n9\n\n\nTotale\n83\n17\n\n\n\nRossi ha un tasso di successo superiore a Bianchi nella terapia per i disturbi d’ansia: 70 su 90 rispetto a 2 su 10. Anche nel coaching lavorativo, Rossi ha un tasso di successo superiore: 10 su 10 rispetto a 81 su 90. Tuttavia, se aggregiamo i dati dei due tipi di terapia per confrontare i tassi di successo globali, Rossi è efficace in 80 su 100 terapie, mentre Bianchi in 83 su 100: il tasso di successo globale di Bianchi risulta superiore!\nQuesto fenomeno è un esempio del paradosso di Simpson, dove una tendenza osservata in diversi gruppi si inverte quando i gruppi sono combinati.\nPer essere più precisi, possiamo calcolare i tassi di successo per ciascun terapeuta e per ciascun tipo di terapia, oltre al tasso di successo globale.\n\nRossi\n\nTasso di successo in terapia per disturbi d’ansia: \\(\\frac{70}{70+20} = \\frac{70}{90} \\approx 0.778\\)\nTasso di successo in coaching lavorativo: \\(\\frac{10}{10+0} = \\frac{10}{10} = 1\\)\nTasso di successo globale: \\(\\frac{70+10}{70+20+10+0} = \\frac{80}{100} = 0.8\\)\n\nBianchi\n\nTasso di successo in terapia per disturbi d’ansia: \\(\\frac{2}{2+8} = \\frac{2}{10} = 0.2\\)\nTasso di successo in coaching lavorativo: \\(\\frac{81}{81+9} = \\frac{81}{90} \\approx 0.9\\)\nTasso di successo globale: \\(\\frac{2+81}{2+8+81+9} = \\frac{83}{100} = 0.83\\)\n\n\nQuello che sta succedendo è che Rossi, presumibilmente a causa della sua reputazione come terapeuta più esperto, sta effettuando un numero maggiore di terapie per disturbi d’ansia, che sono intrinsecamente più complesse e con una probabilità di successo variabile rispetto al coaching lavorativo. Il suo tasso di successo globale è inferiore non a causa di una minore abilità in un particolare tipo di terapia, ma perché una frazione maggiore delle sue terapie riguarda casi più complessi.\nL’aggregazione dei dati tra diversi tipi di terapia presenta un quadro fuorviante delle abilità dei terapeuti perché perdiamo l’informazione su quale terapeuta tende a effettuare quale tipo di terapia. Quando sospettiamo la presenza di variabili di confondimento, come ad esempio il tipo di terapia in questo contesto, è fondamentale analizzare i dati in modo disaggregato per comprendere con precisione la dinamica in atto.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#teorema-della-probabilità-composta",
    "href": "chapters/probability/04_conditional_prob.html#teorema-della-probabilità-composta",
    "title": "28  Probabilità condizionata",
    "section": "28.4 Teorema della probabilità composta",
    "text": "28.4 Teorema della probabilità composta\nÈ possibile scrivere l’Equazione 28.1 nella forma:\n\\[\nP(A \\cap B) = P(B)P(A \\mid B) = P(A)P(B \\mid A).\n\\tag{28.2}\\]\nQuesto secondo modo di scrivere l’Equazione 28.1 è chiamato teorema della probabilità composta (o regola moltiplicativa, o regola della catena). La legge della probabilità composta ci dice che la probabilità che si verifichino contemporaneamente due eventi \\(A\\) e \\(B\\) è pari alla probabilità di uno dei due eventi moltiplicata per la probabilità dell’altro evento condizionata al verificarsi del primo.\nL’l’Equazione 28.2 si estende al caso di \\(n\\) eventi \\(A_1, \\dots, A_n\\) nella forma seguente:\n\\[\nP\\left( \\bigcap_{k=1}^n A_k \\right) = \\prod_{k=1}^n P\\left(  A_k  \\ \\Biggl\\lvert \\ \\bigcap_{j=1}^{k-1} A_j \\right).\n\\tag{28.3}\\]\nPer esempio, nel caso di quattro eventi abbiamo\n\\[\n\\begin{split}\nP(&A_1 \\cap A_2 \\cap A_3 \\cap A_4) =  \\\\\n& P(A_1) \\cdot P(A_2 \\mid A_1) \\cdot  P(A_3 \\mid A_1 \\cap A_2) \\cdot P(A_4 \\mid A_1 \\cap A_2 \\cap A_{3}).\\notag\n\\end{split}\n\\]\n\nEsempio 28.6 Per fare un esempio, consideriamo il problema seguente. Da un’urna contenente 6 palline bianche e 4 nere si estrae una pallina per volta, senza reintrodurla nell’urna. Indichiamo con \\(B_i\\) l’evento: “esce una pallina bianca alla \\(i\\)-esima estrazione” e con \\(N_i\\) l’estrazione di una pallina nera. L’evento: “escono due palline bianche nelle prime due estrazioni” è rappresentato dalla intersezione \\(\\{B_1 \\cap B_2\\}\\) e, per l’Equazione 28.2, la sua probabilità vale\n\\[\nP(B_1 \\cap B_2) = P(B_1)P(B_2 \\mid B_1).\n\\]\n\\(P(B_1)\\) vale 6/10, perché nella prima estrazione \\(\\Omega\\) è costituito da 10 elementi: 6 palline bianche e 4 nere. La probabilità condizionata \\(P(B_2 \\mid B_1)\\) vale 5/9, perché nella seconda estrazione, se è verificato l’evento \\(B_1\\), lo spazio campionario consiste di 5 palline bianche e 4 nere. Si ricava pertanto:\n\\[\nP(B_1 \\cap B_2) = \\frac{6}{10} \\cdot \\frac{5}{9} = \\frac{1}{3}.\n\\]\nIn modo analogo si ha che\n\\[\nP(N_1 \\cap N_2) = P(N_1)P(N_2 \\mid N_1) = \\frac{4}{10} \\cdot \\frac{3}{9} = \\frac{4}{30}.\n\\]\nSe l’esperimento consiste nell’estrazione successiva di 3 palline, la probabilità che queste siano tutte bianche, per l’Equazione 28.3, vale\n\\[\n\\begin{aligned}\nP(B_1 \\cap B_2 \\cap B_3) &=P(B_1)P(B_2 \\mid B_1)P(B_3 \\mid B_1 \\cap B_2) \\notag\\\\\n&=\\frac{6}{10}\\cdot\\frac{5}{9} \\cdot\\frac{4}{8} \\notag\\\\\n&= \\frac{1}{6}.\n\\end{aligned}\n\\]\nLa probabilità dell’estrazione di tre palline nere è invece:\n\\[\n\\begin{aligned}\nP(N_1 \\cap N_2 \\cap N_3) &= P(N_1)P(N_2 \\mid N_1)P(N_3 \\mid N_1 \\cap N_2)\\notag\\\\\n&= \\frac{4}{10} \\cdot \\frac{3}{9} \\cdot \\frac{2}{8} \\notag\\\\\n&= \\frac{1}{30}.\\notag\n\\end{aligned}\n\\]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#il-teorema-della-probabilità-totale",
    "href": "chapters/probability/04_conditional_prob.html#il-teorema-della-probabilità-totale",
    "title": "28  Probabilità condizionata",
    "section": "28.5 Il teorema della probabilità totale",
    "text": "28.5 Il teorema della probabilità totale\nIl teorema della probabilità totale (detto anche teorema delle partizioni) afferma che se abbiamo una partizione di uno spazio campionario \\(\\Omega\\) in \\(n\\) eventi mutualmente esclusivi e tali che la loro unione formi \\(\\Omega\\), allora la probabilità di un qualsiasi evento in \\(\\Omega\\) può essere calcolata sommando la probabilità dell’evento su ciascun sottoinsieme della partizione, pesata in base alla probabilità del sottoinsieme.\nIn altre parole, se \\(H_1, H_2, \\dots, H_n\\) sono eventi mutualmente esclusivi e tali che \\(\\bigcup_{i=1}^n H_i = \\Omega\\), allora per ogni evento \\(E \\subseteq \\Omega\\), la probabilità di \\(E\\) è data dalla formula:\n\\[\nP(E) = \\sum_{i=1}^n P(E \\mid H_i)P(H_i),\n\\tag{28.4}\\]\ndove \\(P(E \\mid H_i)\\) rappresenta la probabilità condizionata di \\(E\\) dato che si è verificato l’evento \\(H_i\\), e \\(P(H_i)\\) è la probabilità dell’evento \\(H_i\\).\nIl teorema della probabilità totale riveste un ruolo fondamentale in quanto fornisce il denominatore nel teorema di Bayes, svolgendo la funzione di costante di normalizzazione. Questa costante di normalizzazione è di vitale importanza per assicurare che la distribuzione a posteriori sia una distribuzione di probabilità valida. Per ulteriori dettagli e approfondimenti, è possibile fare riferimento al ?sec-subj-prop.\nNell’ambito della probabilità discreta, questo teorema viene usato quando abbiamo una partizione dello spazio campionario e vogliamo calcolare la probabilità di un evento, sfruttando le probabilità dei singoli eventi della partizione. Il caso più semplice è quello di una partizione dello spazio campione in due sottoinsiemi: \\(P(E) = P(E \\cap H_1) + P(E \\cap H_2)\\).\n\n\n\n\n\n\nFigura 28.3: Partizione dello spazio campionario per il teorema di Bayes.\n\n\n\nIn tali circostanza abbiamo che\n\\[\nP(E) = P(E \\mid H_1) P(H_1) + P(E \\mid H_2) P(H_2).\n\\]\nL’Equazione 28.4 è utile per calcolare \\(P(E)\\), se \\(P(E \\mid H_i)\\) e \\(P(H_i)\\) sono facili da trovare.\n\nEsempio 28.7 Abbiamo tre urne, ciascuna delle quali contiene 100 palline:\n\nUrna 1: 75 palline rosse e 25 palline blu,\nUrna 2: 60 palline rosse e 40 palline blu,\nUrna 3: 45 palline rosse e 55 palline blu.\n\nUna pallina viene estratta a caso da un’urna anch’essa scelta a caso. Qual è la probabilità che la pallina estratta sia di colore rosso?\nSia \\(R\\) l’evento “la pallina estratta è rossa” e sia \\(U_i\\) l’evento che corrisponde alla scelta dell’\\(i\\)-esima urna. Sappiamo che\n\\[\nP(R \\mid U_1) = 0.75, \\quad P(R \\mid U_2) = 0.60, \\quad P(R \\mid U_3) = 0.45.\n\\]\nGli eventi \\(U_1\\), \\(U_2\\) e \\(U_3\\) costituiscono una partizione dello spazio campione in quanto \\(U_1\\), \\(U_2\\) e \\(U_3\\) sono eventi mutualmente esclusivi ed esaustivi, ovvero \\(P(U_1 \\cup U_2 \\cup U_3) = 1.0\\). In base al teorema della probabilità totale, la probabilità di estrarre una pallina rossa è dunque\n\\[\n\\begin{split}\nP(R) &= P(R \\mid U_1)P(U_1) + P(R \\mid U_2)P(U_2) + P(R \\mid U_3)P(U_3) \\\\\n&= 0.75 \\cdot \\frac{1}{3}+0.60 \\cdot \\frac{1}{3}+0.45 \\cdot \\frac{1}{3} \\\\\n&=0.60.\n\\end{split}\n\\]\n\n\n28.5.1 Indipendenza e probabilità condizionata\nL’indipendenza tra due eventi \\(A\\) e \\(B\\) può essere espressa in modo intuitivo utilizzando la probabilità condizionata. Se \\(A\\) e \\(B\\) sono indipendenti, il verificarsi di uno degli eventi non influisce sulla probabilità del verificarsi dell’altro. In altre parole, la probabilità che \\(A\\) accada non cambia se sappiamo che \\(B\\) è avvenuto, e viceversa.\nPossiamo esprimere questa idea con le seguenti equazioni:\n\\[\nP(A \\mid B) = \\frac{P(A \\cap B)}{P(B)} = P(A),\n\\]\n\\[\nP(B \\mid A) = \\frac{P(A \\cap B)}{P(A)} = P(B).\n\\]\nQuindi, due eventi \\(A\\) e \\(B\\) sono indipendenti se soddisfano le condizioni:\n\\[\nP(A \\mid B) = P(A),\n\\]\n\\[\nP(B \\mid A) = P(B).\n\\]\nQuesto significa che la probabilità di \\(A\\) rimane invariata indipendentemente dal fatto che \\(B\\) sia accaduto o meno, e lo stesso vale per \\(B\\).\n\n28.5.1.1 Indipendenza di Tre Eventi\nTre eventi \\(A\\), \\(B\\) e \\(C\\) sono indipendenti se soddisfano le seguenti condizioni:\n\\[\n\\begin{align}\nP(A \\cap B) &= P(A) P(B), \\\\\nP(A \\cap C) &= P(A) P(C), \\\\\nP(B \\cap C) &= P(B) P(C), \\\\\nP(A \\cap B \\cap C) &= P(A) P(B) P(C).\n\\end{align}\n\\]\nLe prime tre condizioni verificano l’indipendenza a due a due, ovvero l’indipendenza di ciascuna coppia di eventi. Tuttavia, per essere completamente indipendenti, deve essere soddisfatta anche l’ultima condizione, che riguarda l’intersezione di tutti e tre gli eventi. Solo se tutte queste condizioni sono soddisfatte possiamo dire che \\(A\\), \\(B\\) e \\(C\\) sono completamente indipendenti.\nIn sintesi, l’indipendenza tra eventi implica che la conoscenza del verificarsi di uno non fornisce alcuna informazione sulla probabilità del verificarsi degli altri.\n\nEsempio 28.8 Consideriamo un esempio utilizzando un mazzo di 52 carte. Ogni seme contiene 13 carte e ci sono 4 regine in totale. Definiamo i seguenti eventi:\n\nEvento A: pescare una carta di picche,\nEvento B: pescare una regina.\n\nProbabilità con un mazzo completo\nIn un mazzo completo, la probabilità di pescare una carta di picche (\\(P(A)\\)) è \\(\\frac{13}{52} = \\frac{1}{4}\\), poiché ci sono 13 picche su 52 carte totali. La probabilità di pescare una regina (\\(P(B)\\)) è \\(\\frac{4}{52} = \\frac{1}{13}\\), poiché ci sono 4 regine su 52 carte.\nOra consideriamo la probabilità congiunta di pescare la regina di picche (\\(P(AB)\\)). Poiché esiste solo una regina di picche nel mazzo, la probabilità di pescare questa specifica carta è \\(\\frac{1}{52}\\).\nSecondo la definizione di indipendenza, se gli eventi \\(A\\) e \\(B\\) sono indipendenti, allora:\n\\[ P(AB) = P(A)P(B) \\]\nCalcoliamo \\(P(A)P(B)\\):\n\\[ P(A)P(B) = \\left( \\frac{1}{4} \\right) \\left( \\frac{1}{13} \\right) = \\frac{1}{52} \\]\nPoiché \\(P(AB) = \\frac{1}{52}\\) è uguale a \\(P(A)P(B)\\), possiamo affermare che gli eventi \\(A\\) e \\(B\\) sono indipendenti con un mazzo completo di 52 carte.\nProbabilità dopo la rimozione di una carta\nConsideriamo ora un mazzo con una carta in meno, ad esempio il due di quadri, riducendo il numero totale di carte a 51. Ricalcoliamo le probabilità con questo mazzo ridotto:\nLa probabilità di pescare la regina di picche (\\(P(AB)\\)) è ora \\(\\frac{1}{51}\\), poiché ci sono 51 carte nel mazzo.\nRicalcoliamo anche \\(P(A)\\) e \\(P(B)\\):\n\n\\(P(A)\\) diventa \\(\\frac{13}{51}\\), poiché ci sono ancora 13 picche, ma su 51 carte.\n\\(P(B)\\) diventa \\(\\frac{4}{51}\\), poiché ci sono ancora 4 regine, ma su 51 carte.\n\nOra calcoliamo il prodotto \\(P(A)P(B)\\) con queste nuove probabilità:\n\\[ P(A)P(B) = \\left( \\frac{13}{51} \\right) \\left( \\frac{4}{51} \\right) = \\frac{52}{2601} \\]\nConfrontiamo \\(P(AB)\\) e \\(P(A)P(B)\\):\n\\[ \\frac{1}{51} \\neq \\frac{52}{2601} \\]\nPoiché \\(\\frac{1}{51} \\neq \\frac{52}{2601}\\), gli eventi \\(A\\) e \\(B\\) non sono più indipendenti dopo la rimozione del due di quadri.\nQuesto esempio mostra come l’indipendenza tra due eventi dipenda dal contesto. Con un mazzo completo, i due eventi sono indipendenti. Tuttavia, rimuovendo una carta dal mazzo, le probabilità cambiano e gli eventi non sono più indipendenti. Questo evidenzia l’importanza di considerare la composizione e le condizioni iniziali quando si analizzano probabilità e indipendenza. Modifiche nella composizione del mazzo possono alterare le probabilità, influenzando le relazioni di indipendenza tra eventi specifici.\nIn generale, l’indipendenza tra due eventi significa che la probabilità di uno non è influenzata dal verificarsi dell’altro. Questo concetto è cruciale per analisi probabilistiche e modelli statistici più complessi.\n\n\nEsempio 28.9 Nel lancio di due dadi non truccati, si considerino gli eventi: \\(A\\) = “esce un 1 o un 2 nel primo lancio” e \\(B\\) = “il punteggio totale è 8”. Gli eventi \\(A\\) e \\(B\\) sono indipendenti?\nCalcoliamo \\(P(A)\\):\n\nr &lt;- 1:6\nsample &lt;- expand.grid(i = r, j = r)\nA &lt;- subset(sample, i == 1 | i == 2)\nprint(A)\n#&gt;    i j\n#&gt; 1  1 1\n#&gt; 2  2 1\n#&gt; 7  1 2\n#&gt; 8  2 2\n#&gt; 13 1 3\n#&gt; 14 2 3\n#&gt; 19 1 4\n#&gt; 20 2 4\n#&gt; 25 1 5\n#&gt; 26 2 5\n#&gt; 31 1 6\n#&gt; 32 2 6\ncat(nrow(A), \"/\", nrow(sample), \"\\n\")\n#&gt; 12 / 36\n\nCalcoliamo \\(P(B)\\):\n\nB &lt;- subset(sample, i + j == 8)\nprint(B)\n#&gt;    i j\n#&gt; 12 6 2\n#&gt; 17 5 3\n#&gt; 22 4 4\n#&gt; 27 3 5\n#&gt; 32 2 6\ncat(nrow(B), \"/\", nrow(sample), \"\\n\")\n#&gt; 5 / 36\n\nCalcoliamo \\(P(A \\cap B)\\):\n\nI &lt;- subset(sample, (i == 1 | i == 2) & (i + j == 8))\nprint(I)\n#&gt;    i j\n#&gt; 32 2 6\ncat(nrow(I), \"/\", nrow(sample), \"\\n\")\n#&gt; 1 / 36\n\nGli eventi \\(A\\) e \\(B\\) non sono statisticamente indipendenti dato che \\(P(A \\cap B) \\neq P(A)P(B)\\):\n\n12/36 * 5/36 == 1/36\n#&gt; [1] FALSE",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#riflessioni-conclusive",
    "href": "chapters/probability/04_conditional_prob.html#riflessioni-conclusive",
    "title": "28  Probabilità condizionata",
    "section": "28.6 Riflessioni Conclusive",
    "text": "28.6 Riflessioni Conclusive\nLa probabilità condizionata riveste un ruolo fondamentale in statistica, poiché consente di definire con precisione il concetto di indipendenza statistica. Uno degli aspetti cruciali dell’analisi statistica è la valutazione dell’associazione tra due variabili. In questo capitolo, ci siamo focalizzati sul concetto di indipendenza, che indica l’assenza di relazione tra le variabili. Tuttavia, in futuro esploreremo come effettuare inferenze sulla correlazione tra variabili, ovvero come determinare se esiste una relazione statistica credibile tra di esse.\nIl concetto di probabilità condizionata ci permette di enunciare due regole fondamentali della probabilità:\n\nLa regola della congiunzione (regola del “e” o del prodotto):\n\\[\nP(A \\cap B\\,|\\,C) = P(A\\,|\\,C) \\times P(B\\,|\\,A, C) = P(B\\,|\\,C) \\times P(A\\,|\\,B, C).\n\\]\nLa regola della disgiunzione (regola del “o” o della somma):\n\\[\nP(A \\cup B\\,|\\,C) = P(A\\,|\\,C) + P(B\\,|\\,C) - P(A \\cap B\\,|\\,C).\n\\]\n\nUn’altra importante regola della probabilità è la legge della probabilità totale, che gioca un ruolo cruciale nel teorema di Bayes.\nNel contesto dell’inferenza bayesiana, il condizionamento è uno strumento essenziale. Questo approccio statistico utilizza il condizionamento per rivedere e aggiornare le credenze o incertezze riguardo a determinate ipotesi, basandosi sull’introduzione di nuove informazioni.\nIn sintesi, la probabilità condizionata non solo è fondamentale per comprendere l’indipendenza statistica, ma anche per applicare metodi inferenziali avanzati come l’inferenza bayesiana. Questa forma di inferenza ci permette di aggiornare continuamente le nostre conoscenze e credenze alla luce di nuove informazioni, rendendo il processo decisionale statistico dinamico e adattabile.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/04_conditional_prob.html#informazioni-sullambiente-di-sviluppo",
    "title": "28  Probabilità condizionata",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.16.0       MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2\n#&gt;  [5] ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0  \n#&gt;  [9] bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0      markdown_1.13    \n#&gt; [13] knitr_1.49        lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1    \n#&gt; [17] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#&gt; [21] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [25] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1  farver_2.1.2      fastmap_1.2.0     pacman_0.5.1     \n#&gt;  [5] promises_1.3.1    rpart_4.1.23      digest_0.6.37     timechange_0.3.0 \n#&gt;  [9] mime_0.12         lifecycle_1.0.4   survival_3.7-0    magrittr_2.0.3   \n#&gt; [13] compiler_4.4.2    rlang_1.1.4       tools_4.4.2       utf8_1.2.4       \n#&gt; [17] yaml_2.3.10       ggsignif_0.6.4    htmlwidgets_1.6.4 mnormt_2.1.1     \n#&gt; [21] abind_1.4-8       miniUI_0.1.1.1    withr_3.0.2       nnet_7.3-19      \n#&gt; [25] grid_4.4.2        fansi_1.0.6       jomo_2.7-6        xtable_1.8-4     \n#&gt; [29] colorspace_2.1-1  iterators_1.0.14  cli_3.6.3         rmarkdown_2.29   \n#&gt; [33] generics_0.1.3    tzdb_0.4.0        minqa_1.2.8       splines_4.4.2    \n#&gt; [37] parallel_4.4.2    vctrs_0.6.5       boot_1.3-31       glmnet_4.1-8     \n#&gt; [41] Matrix_1.7-1      jsonlite_1.8.9    carData_3.0-5     car_3.1-3        \n#&gt; [45] hms_1.1.3         mitml_0.4-5       rstatix_0.7.2     Formula_1.2-5    \n#&gt; [49] foreach_1.5.2     glue_1.8.0        pan_1.9           nloptr_2.1.1     \n#&gt; [53] codetools_0.2-20  stringi_1.8.4     gtable_0.3.6      shape_1.4.6.1    \n#&gt; [57] later_1.4.0       lme4_1.1-35.5     munsell_0.5.1     pillar_1.9.0     \n#&gt; [61] htmltools_0.5.8.1 R6_2.5.1          rprojroot_2.0.4   evaluate_1.0.1   \n#&gt; [65] shiny_1.9.1       lattice_0.22-6    backports_1.5.0   broom_1.0.7      \n#&gt; [69] httpuv_1.6.15     Rcpp_1.0.13-1     nlme_3.1-166      xfun_0.49        \n#&gt; [73] pkgconfig_2.0.3",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_random_var.html",
    "href": "chapters/probability/05_random_var.html",
    "title": "29  Variabili casuali",
    "section": "",
    "text": "29.1 Introduzione\nPrerequisiti\nPrima di procedere con il presente capitolo, è essenziale leggere l’?sec-calculus.\nConcetti e competenze chiave\nPreparazione del Notebook\nFinora, ci siamo concentrati sulle probabilità degli eventi. Ad esempio, abbiamo calcolato la probabilità di vincere il gioco di Monty Hall o di avere una rara condizione medica dato che il test è risultato positivo. Ma, in molti casi, vorremmo sapere di più. Ad esempio, quanti concorrenti devono giocare al gioco di Monty Hall fino a quando uno di loro finalmente vince? Quanto durerà questa condizione? Quanto perderò giocando d’azzardo con un dado sbilanciato tutta la notte? Per rispondere a queste domande, dobbiamo lavorare con le variabili casuali. In questo capitolo, introduciamo le variabili casuali e le loro proprietà.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_random_var.html#definizione",
    "href": "chapters/probability/05_random_var.html#definizione",
    "title": "29  Variabili casuali",
    "section": "29.2 Definizione",
    "text": "29.2 Definizione\nLe variabili casuali sono risultati numerici derivanti da processi aleatori. Esse ci consentono di trasformare risultati qualitativi (ad esempio \\(X = \\{\\Box, \\clubsuit, \\diamondsuit, \\heartsuit, \\spadesuit\\}\\)) in valori numerici, semplificando così l’analisi matematica.\nFormalmente, una variabile casuale è definita come una funzione che associa ogni elemento di uno spazio campionario \\(S\\) a un valore in un sottoinsieme dei numeri reali \\(\\mathbb{R}\\). Questa definizione consente di esprimere numericamente gli esiti di un fenomeno aleatorio, associando un valore specifico a ciascun possibile risultato dell’esperimento.\n\nEsempio 29.1 Un esempio è la variabile casuale \\(X\\), che rappresenta il risultato del lancio di un dado. Se definiamo \\(X = 1\\) per indicare che il risultato del lancio è un numero dispari (1, 3 o 5) e \\(X = 0\\) per indicare che il risultato è un numero pari (2, 4 o 6), abbiamo trasformato un’osservazione fisica (il lancio del dado) in un valore numerico che rappresenta una determinata categoria di eventi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_random_var.html#tipologie-di-variabili-casuali",
    "href": "chapters/probability/05_random_var.html#tipologie-di-variabili-casuali",
    "title": "29  Variabili casuali",
    "section": "29.3 Tipologie di Variabili Casuali",
    "text": "29.3 Tipologie di Variabili Casuali\nLe variabili casuali possono essere suddivise in due categorie principali: discrete e continue. Una variabile casuale discreta assume valori all’interno di un insieme finito o al massimo numerabile, il che significa che i suoi possibili esiti possono essere contati, anche se l’insieme è infinito. Al contrario, una variabile casuale continua può assumere un’infinità di valori all’interno di un intervallo, essendo in grado di coprire ogni punto di quell’intervallo senza interruzioni.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_random_var.html#convenzioni-notazionali",
    "href": "chapters/probability/05_random_var.html#convenzioni-notazionali",
    "title": "29  Variabili casuali",
    "section": "29.4 Convenzioni Notazionali",
    "text": "29.4 Convenzioni Notazionali\nNella teoria della probabilità, è usuale adottare una specifica convenzione di notazione per le variabili casuali e i loro esiti. Comunemente, si utilizzano le lettere maiuscole, come \\(X\\), per indicare una variabile casuale, ovvero un concetto che rappresenta una serie di possibili esiti di un fenomeno aleatorio. D’altro canto, la corrispondente lettera minuscola, \\(x\\) nel nostro esempio, è impiegata per denotare una specifica realizzazione o un esito particolare che la variabile casuale può assumere. Questa distinzione aiuta a chiarire se si sta parlando della variabile casuale nel suo insieme (\\(X\\)) o di un suo specifico valore (\\(x\\)).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_random_var.html#variabili-casuali-multiple",
    "href": "chapters/probability/05_random_var.html#variabili-casuali-multiple",
    "title": "29  Variabili casuali",
    "section": "29.5 Variabili casuali multiple",
    "text": "29.5 Variabili casuali multiple\nNella teoria della probabilità, le variabili casuali spesso interagiscono o si combinano tra loro. Consideriamo l’esempio di tre lanci di una moneta bilanciata, rappresentati da variabili casuali indipendenti \\(X_1\\), \\(X_2\\), e \\(X_3\\). Per ogni lancio:\n\n\\(P(X_n = 1)\\) (testa) = 0.5,\n\\(P(X_n = 0)\\) (croce) = 0.5,\n\ndove \\(n = 1, 2, 3\\).\nCombinando queste variabili, possiamo creare nuove variabili casuali. Ad esempio, definiamo \\(Z\\) come la somma dei risultati:\n\\[\nZ = X_1 + X_2 + X_3.\n\\]\n\\(Z\\) è una variabile casuale discreta che rappresenta il numero totale di teste ottenute nei tre lanci. I suoi possibili valori sono 0, 1, 2, e 3.\nQuesto esempio illustra come variabili casuali indipendenti possano essere combinate per creare nuove variabili casuali.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_random_var.html#sec-fun-mass-prob",
    "href": "chapters/probability/05_random_var.html#sec-fun-mass-prob",
    "title": "29  Variabili casuali",
    "section": "29.6 Distribuzione di Probabilità",
    "text": "29.6 Distribuzione di Probabilità\nLa distribuzione di probabilità è un concetto fondamentale nella teoria della probabilità, che descrive come le probabilità si distribuiscono tra i possibili esiti di una variabile casuale. La sua rappresentazione varia a seconda che si tratti di variabili casuali discrete o continue.\n\n29.6.1 Variabili Casuali Discrete\nPer le variabili casuali discrete, che assumono valori specifici e contabili, la distribuzione di probabilità è rappresentata dalla funzione di massa di probabilità, indicata come \\(P(\\cdot)\\).\n\n29.6.1.1 Funzione di Massa di Probabilità\nLa funzione di massa di probabilità assegna una probabilità precisa a ciascun possibile esito della variabile casuale discreta. Ad esempio, per il lancio di un dado equilibrato:\n\\(P(Y = 1) = \\frac{1}{6}\\).\nQuesto significa che la probabilità di ottenere “1” in un singolo lancio è 1/6.\n\n\n29.6.1.2 Istogrammi per Variabili Discrete\nGli istogrammi sono strumenti visivi efficaci per rappresentare la distribuzione di probabilità delle variabili casuali discrete. Per queste variabili, possiamo impostare ciascun bin dell’istogramma in modo che copra un singolo valore della variabile casuale. L’altezza di ogni bin corrisponde alla probabilità di quel valore specifico.\nGli istogrammi ci permettono di identificare rapidamente caratteristiche importanti della distribuzione, come:\n\nunimodalità: concentrazione attorno a un singolo punto;\nmultimodalità: concentrazione attorno a più punti;\nsimmetria o asimmetria della distribuzione;\ndispersione dei valori.\n\n\n\n\n29.6.2 Variabili Casuali Continue\nPer le variabili casuali continue, che possono assumere un’infinità di valori in un intervallo, si utilizza la funzione di densità di probabilità, indicata come \\(p(\\cdot)\\).\n\n29.6.2.1 Funzione di Densità di Probabilità\nLa funzione di densità di probabilità non assegna probabilità a singoli valori (che sarebbe zero per una variabile continua), ma determina la probabilità che la variabile si trovi all’interno di un intervallo specifico.\n\n\n29.6.2.2 Istogrammi per Variabili Continue\nAnche per le variabili continue possiamo usare istogrammi, ma in questo caso i bin devono sempre coprire intervalli di valori. Riducendo progressivamente la larghezza dei bin, il profilo dell’istogramma tende a coincidere con la funzione di densità di probabilità della variabile casuale.\n\n\n\n29.6.3 Supporto della Variabile Casuale\nIl supporto di una variabile casuale è l’insieme di tutti i valori che la variabile può effettivamente assumere. Ad esempio:\n\nper un dado a sei facce: {1, 2, 3, 4, 5, 6};\nper una distribuzione gaussiana: l’intero insieme dei numeri reali.\n\n\n\n29.6.4 Assegnazione di Probabilità\n\nPer variabili discrete: si specifica la probabilità di ogni possibile valore.\nPer variabili continue: si utilizza la densità di probabilità per calcolare la probabilità di intervalli di valori.\n\nLa distribuzione di probabilità, sia per variabili discrete che continue, fornisce una descrizione completa del comportamento probabilistico della variabile casuale, permettendo analisi e previsioni accurate in vari campi di applicazione.\n\nEsempio 29.2 Consideriamo l’esperimento casuale costituito dal lancio di due dadi equilibrati. Definiamo la variabile casuale \\(X\\) come la somma dei punti ottenuti dai due dadi.\nLo spazio campionario \\(S\\) è l’insieme di tutte le possibili coppie ordinate \\((a,b)\\), dove \\(a\\) e \\(b\\) rappresentano i risultati del primo e del secondo dado rispettivamente:\n\\[\nS = {(1,1), (1,2), ..., (1,6), (2,1), (2,2), ..., (2,6), ..., (6,1), (6,2), ..., (6,6)}.\n\\]\nIn totale, ci sono 6 × 6 = 36 possibili esiti.\nLa variabile casuale \\(X\\) è definita come la somma dei punti dei due dadi. Quindi:\n\\[\nX = a + b, \\quad \\text{dove } (a,b) \\in S.\n\\]\n\\(X\\) può assumere valori interi da 2 (1+1) a 12 (6+6).\nLa distribuzione della variabile casuale \\(X\\) è una funzione che associa a ogni possibile valore di \\(X\\) la sua probabilità. In questo caso, poiché \\(X\\) è discreta, usiamo una funzione di massa di probabilità.\nPer calcolare la probabilità di ogni valore di \\(X\\), contiamo il numero di casi favorevoli e lo dividiamo per il numero totale di casi possibili (36).\n\n\n\n\n\n\n\n\n\nX\nCasi favorevoli\nNumero di casi\nProbabilità P(X = x)\n\n\n\n\n2\n(1,1)\n1\n1/36\n\n\n3\n(1,2), (2,1)\n2\n2/36 = 1/18\n\n\n4\n(1,3), (2,2), (3,1)\n3\n3/36 = 1/12\n\n\n5\n(1,4), (2,3), (3,2), (4,1)\n4\n4/36 = 1/9\n\n\n6\n(1,5), (2,4), (3,3), (4,2), (5,1)\n5\n5/36\n\n\n7\n(1,6), (2,5), (3,4), (4,3), (5,2), (6,1)\n6\n6/36 = 1/6\n\n\n8\n(2,6), (3,5), (4,4), (5,3), (6,2)\n5\n5/36\n\n\n9\n(3,6), (4,5), (5,4), (6,3)\n4\n4/36 = 1/9\n\n\n10\n(4,6), (5,5), (6,4)\n3\n3/36 = 1/12\n\n\n11\n(5,6), (6,5)\n2\n2/36 = 1/18\n\n\n12\n(6,6)\n1\n1/36\n\n\n\nQuesta tabella rappresenta la distribuzione completa della variabile casuale \\(X\\).\nIn conclusione, la distribuzione di una variabile casuale discreta, come nell’esempio della somma dei punti di due dadi, fornisce una descrizione completa delle proprietà probabilistiche della variabile. Essa associa a ogni possibile valore della variabile la sua probabilità di verificarsi.\nIn questo caso, la distribuzione ci dice, per esempio, che la probabilità di ottenere una somma di 7 è 1/6, la più alta tra tutti i possibili risultati. Questo è dovuto al fatto che ci sono più combinazioni che producono una somma di 7 rispetto a qualsiasi altro risultato.\nLa distribuzione ci permette di rispondere a domande come:\n\nQual è la probabilità di ottenere una somma pari? (Sommando le probabilità di 2, 4, 6, 8, 10, 12).\nQual è la probabilità di ottenere una somma maggiore o uguale a 10? (Sommando le probabilità di 10, 11, 12).\n\nLa distribuzione di massa di probabilità della variabile casuale \\(X\\) può essere rappresentata visivamente utilizzando un istogramma. Un istogramma permette di vedere immediatamente la probabilità associata a ciascun valore di \\(X\\), rendendo chiaro quali risultati sono più probabili e quali lo sono meno.\nLe istruzioni Python necessarie per generare questo istogramma sono fornite di seguito.\n\n\n# Valori possibili della variabile casuale X\nvalori_X &lt;- c(2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12)\n\n# Probabilità associate a ciascun valore di X\nprobabilita_X &lt;- c(\n  1 / 36,\n  2 / 36,\n  3 / 36,\n  4 / 36,\n  5 / 36,\n  6 / 36,\n  5 / 36,\n  4 / 36,\n  3 / 36,\n  2 / 36,\n  1 / 36\n)\n\n# Creazione dell'istogramma\nbarplot(\n  probabilita_X,\n  names.arg = valori_X,\n  col = rgb(0, 0, 1, alpha = 0.5),\n  border = \"black\",\n  xlab = \"Valore della variabile casuale X\",\n  ylab = \"Probabilità P(X = x)\",\n  main = \"Distribuzione di Massa di Probabilità della Variabile Casuale X\"\n)",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_random_var.html#funzione-di-distribuzione-cumulativa-cdf",
    "href": "chapters/probability/05_random_var.html#funzione-di-distribuzione-cumulativa-cdf",
    "title": "29  Variabili casuali",
    "section": "29.7 Funzione di Distribuzione Cumulativa (CDF)",
    "text": "29.7 Funzione di Distribuzione Cumulativa (CDF)\nLa Funzione di Distribuzione Cumulativa (CDF) è uno strumento fondamentale nella teoria della probabilità per descrivere la distribuzione di una variabile casuale.\n\n29.7.1 Definizione\nPer una variabile casuale \\(X\\), la funzione di distribuzione cumulativa \\(F(x)\\) è definita come:\n\\[\nF(x) = P(X \\leq x),\n\\]\ndove:\n\n\\(X\\) è la variabile casuale.\n\\(P(X \\leq x)\\) rappresenta la probabilità che \\(X\\) assuma un valore minore o uguale a \\(x\\).\n\nIn altre parole, \\(F(x)\\) quantifica la probabilità cumulativa dall’estremo inferiore dello spazio di probabilità fino al punto \\(x\\).\n\n\n29.7.2 Proprietà della CDF\n\nMonotonia non decrescente:\n\nPer \\(x_1 &lt; x_2\\), \\(F(x_1) \\leq F(x_2)\\).\nLa CDF non diminuisce mai quando ci si sposta da sinistra a destra lungo l’asse \\(x\\).\n\nNormalizzazione:\n\n\\(\\lim_{{x \\to -\\infty}} F(x) = 0 \\quad \\text{e} \\quad \\lim_{{x \\to +\\infty}} F(x) = 1\\).\nLa CDF parte da 0 quando \\(x\\) tende a \\(-\\infty\\) e raggiunge 1 quando \\(x\\) tende a \\(+\\infty\\).\n\nContinuità a destra:\n\n\\(F(x) = \\lim_{{y \\to x^+}} F(y)\\).\nLa CDF è continua da destra, il che significa che non presenta salti improvvisi quando ci si avvicina a un punto da destra.\n\n\n\n\n29.7.3 CDF per Variabili Casuali Discrete\nPer una variabile casuale discreta \\(X\\), la CDF (anche chiamata funzione di ripartizione cumulativa) è definita come:\n\\[\nF(x) = P(X \\leq x) = \\sum_{x_i \\leq x} P(X = x_i),\n\\]\ndove la somma è calcolata su tutti i valori \\(x_i\\) minori o uguali a \\(x\\).\n\n\n29.7.4 Importanza e Applicazioni\n\nLa CDF offre una rappresentazione visiva di come le probabilità si accumulano lungo l’intero intervallo dei possibili valori della variabile casuale.\nLa CDF permette di calcolare facilmente la probabilità che \\(X\\) cada in un intervallo specifico:\n\n\\[\nP(a &lt; X \\leq b) = F(b) - F(a).\n\\]\n\nLa CDF è utilizzata in vari metodi di generazione di variabili casuali, come il metodo della trasformazione inversa.\nLe CDF facilitano il confronto tra diverse distribuzioni di probabilità, consentendo di valutare differenze nelle loro caratteristiche cumulative.\n\nIn conclusione, la CDF è uno strumento versatile e potente che fornisce una descrizione completa della distribuzione di probabilità di una variabile casuale, sia essa discreta o continua.\n\nEsempio 29.3 Nel caso del lancio di due dadi, con la variabile casuale \\(Z\\) definita come la somma dei loro valori, la funzione di distribuzione cumulativa \\(F(z)\\) può essere illustrata come segue:\n\n\n\n\\(z\\)\n\\(P(Z = z)\\)\n\\(F(z)\\)\n\n\n\n\n2\n\\(\\frac{1}{36}\\)\n\\(\\frac{1}{36}\\)\n\n\n3\n\\(\\frac{2}{36}\\)\n\\(\\frac{3}{36}\\)\n\n\n4\n\\(\\frac{3}{36}\\)\n\\(\\frac{6}{36}\\)\n\n\n5\n\\(\\frac{4}{36}\\)\n\\(\\frac{10}{36}\\)\n\n\n6\n\\(\\frac{5}{36}\\)\n\\(\\frac{15}{36}\\)\n\n\n7\n\\(\\frac{6}{36}\\)\n\\(\\frac{21}{36}\\)\n\n\n8\n\\(\\frac{5}{36}\\)\n\\(\\frac{26}{36}\\)\n\n\n9\n\\(\\frac{4}{36}\\)\n\\(\\frac{30}{36}\\)\n\n\n10\n\\(\\frac{3}{36}\\)\n\\(\\frac{33}{36}\\)\n\n\n11\n\\(\\frac{2}{36}\\)\n\\(\\frac{35}{36}\\)\n\n\n12\n\\(\\frac{1}{36}\\)\n\\(\\frac{36}{36}\\)\n\n\n\nIn questa tabella:\n\n\\(P(Z = z)\\) rappresenta la probabilità che la somma dei due dadi sia esattamente \\(z\\).\n\\(F(z)\\) è la funzione di distribuzione cumulativa, che fornisce la probabilità che la somma \\(Z\\) sia minore o uguale a \\(z\\).\n\nQuesta tabella mostra come le probabilità cumulative si accumulano per la variabile casuale \\(Z\\), evidenziando la distribuzione delle somme possibili quando si lanciano due dadi. Ad esempio, \\(F(7) = \\frac{21}{36}\\) indica che la probabilità che la somma sia 7 o inferiore è \\(\\frac{21}{36}\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_random_var.html#trovare-la-distribuzione-di-probabilità-attraverso-una-simulazione",
    "href": "chapters/probability/05_random_var.html#trovare-la-distribuzione-di-probabilità-attraverso-una-simulazione",
    "title": "29  Variabili casuali",
    "section": "29.8 Trovare la Distribuzione di Probabilità attraverso una Simulazione",
    "text": "29.8 Trovare la Distribuzione di Probabilità attraverso una Simulazione\nLa distribuzione di probabilità teorica per il lancio di due dadi può essere calcolata analiticamente, ma un’alternativa altrettanto valida è ottenere una stima empirica tramite simulazione. Questo approccio consiste nel ripetere l’esperimento casuale un numero elevato di volte e analizzare le frequenze relative dei risultati ottenuti. Aumentando il numero di simulazioni, la distribuzione empirica tende a convergere verso quella teorica.\nDi seguito vedremo come implementare una simulazione in R per calcolare la distribuzione empirica di probabilità dei risultati ottenuti sommando i punteggi di due dadi.\n\nEsempio 29.4 Iniziamo definendo una funzione che simula il lancio di un dado a sei facce, restituendo un valore casuale tra 1 e 6.\n\n# Funzione per simulare il lancio di un dado\nroll_die &lt;- function() {\n  sample(1:6, size = 1)\n}\n\nPossiamo ora definire una funzione che calcola la somma dei valori di due dadi lanciati simultaneamente. La funzione accetta come argomento il numero di ripetizioni da effettuare e restituisce un vettore contenente i risultati.\n\n# Funzione per simulare il lancio di due dadi per n volte\nroll_two_dice &lt;- function(n) {\n  map_dbl(1:n, ~ roll_die() + roll_die())\n}\n\nUtilizziamo la funzione appena definita per simulare 100.000 lanci di due dadi. Memorizziamo i risultati in un oggetto res e visualizziamo i primi 20 valori.\n\n# Numero di simulazioni\nnrolls &lt;- 100000\n\n# Simula i risultati del lancio di due dadi\nres &lt;- roll_two_dice(nrolls)\n\n# Visualizza i primi 20 risultati\ncat(res[1:20], \"\\n\")\n#&gt; 6 2 6 4 5 6 10 4 4 4 9 10 6 7 3 8 9 6 10 7\n\nUtilizzando il tidyverse, possiamo creare un DataFrame contenente i risultati della simulazione e calcolare la distribuzione empirica delle probabilità. Per fare ciò, calcoliamo le frequenze assolute dei risultati, le normalizziamo dividendo per il numero totale di simulazioni e assicuriamo che siano rappresentati tutti i possibili valori (da 2 a 12).\n\n# Converti i risultati in un DataFrame (tibble)\ndf &lt;- tibble(y = res)\n\n# Calcola la distribuzione empirica delle probabilità\nempirical_probs &lt;- df %&gt;%\n  count(y) %&gt;%                             # Calcola le frequenze assolute\n  complete(y = 2:12, fill = list(n = 0)) %&gt;% # Assicura che tutti i valori siano inclusi\n  mutate(prob = n / nrolls)                # Calcola le probabilità relative\n\n# Visualizza la distribuzione empirica\nempirical_probs %&gt;%\n  dplyr::select(y, prob)\n#&gt; # A tibble: 11 × 2\n#&gt;       y   prob\n#&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1     2 0.0282\n#&gt; 2     3 0.0566\n#&gt; 3     4 0.0849\n#&gt; 4     5 0.111 \n#&gt; 5     6 0.139 \n#&gt; 6     7 0.165 \n#&gt; # ℹ 5 more rows\n\nIl risultato finale è una tabella che mostra i valori possibili (da 2 a 12) e la loro probabilità empirica stimata. Questa distribuzione empirica dovrebbe essere molto simile alla distribuzione teorica, specialmente considerando un numero elevato di simulazioni.\nQuesto approccio dimostra come sia possibile utilizzare la simulazione per approssimare distribuzioni di probabilità, una tecnica particolarmente utile quando la soluzione analitica non è immediatamente disponibile.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_random_var.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/05_random_var.html#informazioni-sullambiente-di-sviluppo",
    "title": "29  Variabili casuali",
    "section": "29.9 Informazioni sull’Ambiente di Sviluppo",
    "text": "29.9 Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.16.0       MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2\n#&gt;  [5] ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0  \n#&gt;  [9] bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0      markdown_1.13    \n#&gt; [13] knitr_1.49        lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1    \n#&gt; [17] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#&gt; [21] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [25] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1  farver_2.1.2      fastmap_1.2.0     pacman_0.5.1     \n#&gt;  [5] promises_1.3.1    rpart_4.1.23      digest_0.6.37     timechange_0.3.0 \n#&gt;  [9] mime_0.12         lifecycle_1.0.4   survival_3.7-0    magrittr_2.0.3   \n#&gt; [13] compiler_4.4.2    rlang_1.1.4       tools_4.4.2       utf8_1.2.4       \n#&gt; [17] yaml_2.3.10       ggsignif_0.6.4    htmlwidgets_1.6.4 mnormt_2.1.1     \n#&gt; [21] abind_1.4-8       miniUI_0.1.1.1    withr_3.0.2       nnet_7.3-19      \n#&gt; [25] grid_4.4.2        fansi_1.0.6       jomo_2.7-6        xtable_1.8-4     \n#&gt; [29] colorspace_2.1-1  iterators_1.0.14  cli_3.6.3         rmarkdown_2.29   \n#&gt; [33] generics_0.1.3    tzdb_0.4.0        minqa_1.2.8       splines_4.4.2    \n#&gt; [37] parallel_4.4.2    vctrs_0.6.5       boot_1.3-31       glmnet_4.1-8     \n#&gt; [41] Matrix_1.7-1      jsonlite_1.8.9    carData_3.0-5     car_3.1-3        \n#&gt; [45] hms_1.1.3         mitml_0.4-5       rstatix_0.7.2     Formula_1.2-5    \n#&gt; [49] foreach_1.5.2     glue_1.8.0        pan_1.9           nloptr_2.1.1     \n#&gt; [53] codetools_0.2-20  stringi_1.8.4     gtable_0.3.6      shape_1.4.6.1    \n#&gt; [57] later_1.4.0       lme4_1.1-35.5     munsell_0.5.1     pillar_1.9.0     \n#&gt; [61] htmltools_0.5.8.1 R6_2.5.1          rprojroot_2.0.4   evaluate_1.0.1   \n#&gt; [65] shiny_1.9.1       lattice_0.22-6    backports_1.5.0   broom_1.0.7      \n#&gt; [69] httpuv_1.6.15     Rcpp_1.0.13-1     nlme_3.1-166      xfun_0.49        \n#&gt; [73] pkgconfig_2.0.3",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html",
    "href": "chapters/probability/06_expval_var.html",
    "title": "30  Proprietà delle variabili casuali",
    "section": "",
    "text": "30.1 Introduzione\nPrerequisiti\nPrima di affrontare il presente capitolo, è essenziale leggere la sezione ?sec-calculus.\nConcetti e Competenze Chiave\nPreparazione del Notebook\nSintetizzare la distribuzione di una variabile casuale attraverso indicatori caratteristici è spesso molto utile. Questi indicatori consentono di cogliere le principali proprietà della distribuzione, come la posizione centrale (ovvero il “baricentro”) e la variabilità (ossia la dispersione attorno al centro). In questo modo, è possibile ottenere una descrizione sintetica e significativa della distribuzione di probabilità della variabile casuale.\nIn questo capitolo, introdurremo i concetti fondamentali di valore atteso e varianza di una variabile casuale, che sono strumenti essenziali per comprendere e riassumere le proprietà di una distribuzione probabilistica.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html#valore-atteso",
    "href": "chapters/probability/06_expval_var.html#valore-atteso",
    "title": "30  Proprietà delle variabili casuali",
    "section": "30.2 Valore Atteso",
    "text": "30.2 Valore Atteso\nQuando vogliamo comprendere il comportamento tipico di una variabile casuale, ci interessa spesso determinare il suo “valore tipico”. Tuttavia, questa nozione può essere interpretata in diversi modi:\n\nMedia: La somma dei valori divisa per il numero dei valori.\nMediana: Il valore centrale della distribuzione, quando i dati sono ordinati in senso crescente o decrescente.\nModa: Il valore che si verifica con maggiore frequenza.\n\nAd esempio, per il set di valori \\(\\{3, 1, 4, 1, 5\\}\\), la media è \\(\\frac{3+1+4+1+5}{5} = 2.8\\), la mediana è 3, e la moda è 1. Tuttavia, quando ci occupiamo di variabili casuali, anziché di semplici sequenze di numeri, diventa necessario chiarire cosa intendiamo per “valore tipico” in questo contesto. Questo ci porta alla definizione formale del valore atteso.\n\nDefinizione 30.1 Sia \\(X\\) una variabile casuale discreta che assume i valori \\(x_1, \\dots, x_n\\) con probabilità \\(P(X = x_i) = p(x_i)\\). Il valore atteso di \\(X\\), denotato con \\(\\mathbb{E}(X)\\), è definito come:\n\\[\n\\mathbb{E}(X) = \\sum_{i=1}^n x_i \\cdot p(x_i).\n\\]\n\nIn altre parole, il valore atteso (noto anche come speranza matematica o aspettazione) di una variabile casuale è la somma di tutti i valori che la variabile può assumere, ciascuno ponderato dalla probabilità con cui esso si verifica.\n\nEsempio 30.1 Calcoliamo il valore atteso della variabile casuale \\(X\\) corrispondente al lancio di una moneta equilibrata, dove testa corrisponde a \\(X = 1\\) e croce corrisponde a \\(X = 0\\):\n\\[\n\\mathbb{E}(X) = \\sum_{i=1}^{2} x_i \\cdot P(x_i) = 0 \\cdot \\frac{1}{2} + 1 \\cdot \\frac{1}{2} = 0.5.\n\\]\n\n\nEsempio 30.2 Calcoliamo il valore atteso della variabile casuale \\(X\\) che rappresenta la somma dei punti ottenuti dal lancio di due dadi equilibrati a sei facce.\nCome abbiamo visto nel ?sec-prob-intro-random-var, \\(X\\) può assumere i valori [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] con una distribuzione di massa di probabilità pari a [1/36, 2/36, 3/36, 4/36, 5/36, 6/36, 5/36, 4/36, 3/36, 2/36, 1/36]. Applicando la formula del valore atteso, otteniamo:\n\\[\n\\mathbb{E}(X) = \\sum_{i=1}^{11} x_i \\cdot P(x_i) = 2 \\cdot \\frac{1}{36} + 3 \\cdot \\frac{2}{36} + \\dots + 12 \\cdot \\frac{1}{36} = 7.0.\n\\]\n\n\nEsempio 30.3 Vediamo ora come eseguire i calcoli del valore atteso utilizzando R. Per prima cosa, definiamo i valori della variabile casuale:\n\nx &lt;- 2:12\nx\n#&gt;  [1]  2  3  4  5  6  7  8  9 10 11 12\n\nSuccessivamente, calcoliamo la distribuzione di massa della variabile casuale.\n\n# Definire il range dei valori dei dadi\nr &lt;- 1:6\nsample &lt;- expand.grid(i = r, j = r)  # Tutte le combinazioni dei valori dei due dadi\n\n# Calcolare la distribuzione di probabilità\npx &lt;- numeric()\n\nfor (sum_value in 2:12) {\n  event &lt;- subset(sample, i + j == sum_value)  # Filtra le combinazioni che sommano a 'sum_value'\n  px &lt;- c(px, nrow(event) / nrow(sample))  # Calcola la probabilità\n}\n\npx\n#&gt;  [1] 0.02777778 0.05555556 0.08333333 0.11111111 0.13888889 0.16666667\n#&gt;  [7] 0.13888889 0.11111111 0.08333333 0.05555556 0.02777778\n\nOra, possiamo calcolare il valore atteso di \\(X\\) utilizzando la formula del valore atteso per variabili casuali discrete:\n\nex &lt;- sum(x * px)\nround(ex, 3)\n#&gt; [1] 7\n\nIn alternativa, possiamo utilizzare un approccio più diretto utilizzando le funzioni per la definizione di distribuzioni discrete in R. In questo caso, definiamo manualmente la distribuzione:\n\nx &lt;- 2:12\npx &lt;- c(1/36, 2/36, 3/36, 4/36, 5/36, 6/36, 5/36, 4/36, 3/36, 2/36, 1/36)\n\n# Calcoliamo il valore atteso direttamente:\nx_ev &lt;- sum(x * px)\nround(x_ev, 3)\n#&gt; [1] 7\n\nQuesti metodi dimostrano come sia possibile calcolare il valore atteso di una variabile casuale sia attraverso un approccio diretto, sia utilizzando R.\n\n\n30.2.1 Interpretazione\nIl valore atteso di una variabile casuale corrisponde alla media aritmetica di un ampio numero di realizzazioni indipendenti della variabile stessa.\nPer chiarire questo concetto, consideriamo nuovamente l’esempio del lancio di due dadi bilanciati a sei facce, dove la variabile casuale \\(X\\) rappresenta la “somma dei due dadi”. Per interpretare il valore atteso, possiamo simulare un grande numero di realizzazioni indipendenti di \\(X\\) utilizzando la funzione np.random.choice() della libreria NumPy. Questa funzione permette di generare campioni casuali basati sui valori della variabile casuale, sul numero di ripetizioni indipendenti (qui 1.000.000) e sulla distribuzione di massa di probabilità associata:\n\nset.seed(123)  # Per rendere i risultati riproducibili\nx_samples &lt;- sample(x, size = 1e6, replace = TRUE, prob = px)\n\nL’istruzione sample(x, size = 1e6, replace = TRUE, prob = px)) utilizza R per generare un array di 1.000.000 di elementi (specificato dal parametro size), selezionati casualmente dall’array x secondo le probabilità specificate nell’array px.\nQuando il numero di realizzazioni indipendenti è sufficientemente grande, la media aritmetica dei campioni generati si avvicina al valore atteso della variabile casuale:\n\nmean(x_samples) |&gt;\n  round(3)\n#&gt; [1] 6.998\n\nQuesto risultato conferma che, con un numero elevato di simulazioni, la media aritmetica dei valori ottenuti fornisce una buona approssimazione del valore atteso teorico di \\(X\\).\n\n\n30.2.2 Proprietà del Valore Atteso\nUna delle proprietà più importanti del valore atteso è la sua linearità: il valore atteso della somma di due variabili casuali è uguale alla somma dei loro rispettivi valori attesi:\n\\[\n\\mathbb{E}(X + Y) = \\mathbb{E}(X) + \\mathbb{E}(Y).\n\\tag{30.1}\\]\nQuesta proprietà, espressa dalla formula sopra, è intuitiva quando \\(X\\) e \\(Y\\) sono variabili casuali indipendenti, ma è valida anche nel caso in cui \\(X\\) e \\(Y\\) siano correlate.\nInoltre, se moltiplichiamo una variabile casuale per una costante \\(c\\), il valore atteso del prodotto è uguale alla costante moltiplicata per il valore atteso della variabile casuale:\n\\[\n\\mathbb{E}(cY) = c \\mathbb{E}(Y).\n\\tag{30.2}\\]\nQuesta proprietà ci dice che una costante può essere “estratta” dall’operatore di valore atteso, e si applica a qualunque numero di variabili casuali.\nUn’altra proprietà significativa riguarda il prodotto di variabili casuali indipendenti. Se \\(X\\) e \\(Y\\) sono indipendenti, allora il valore atteso del loro prodotto è uguale al prodotto dei loro valori attesi:\n\\[\n\\mathbb{E}(XY) = \\mathbb{E}(X) \\mathbb{E}(Y).\n\\tag{30.3}\\]\nInfine, consideriamo la media aritmetica \\(\\bar{X} = \\frac{X_1 + \\ldots + X_n}{n}\\) di \\(n\\) variabili casuali indipendenti con la stessa distribuzione e con valore atteso \\(\\mu\\). Il valore atteso della media aritmetica è:\n\\[\n\\mathbb{E}(\\bar{X}) = \\frac{1}{n} \\left(\\mathbb{E}(X_1) + \\dots + \\mathbb{E}(X_n)\\right) = \\frac{1}{n} \\cdot n \\cdot \\mathbb{E}(X) = \\mu.\n\\]\nQuesto risultato conferma che la media aritmetica di un campione di variabili casuali indipendenti ha lo stesso valore atteso della distribuzione originaria, rendendo il valore atteso uno strumento cruciale per l’analisi statistica e probabilistica.\n\nEsempio 30.4 Consideriamo il seguente esperimento casuale. Sia \\(Y\\) il numero che si ottiene dal lancio di un dado equilibrato a sei facce e \\(Y\\) il numero di teste prodotto dal lancio di una moneta equilibrata (0 oppure 1). Troviamo il valore atteso di \\(X+Y\\).\nPer risolvere il problema iniziamo a costruire lo spazio campione dell’esperimento casuale.\n\n\n\n\n\n\n\n\n\n\n\n\n\\(x /\\ y\\)\n1\n2\n3\n4\n5\n6\n\n\n\n\n0\n(0, 1)\n(0, 2)\n(0, 3)\n(0, 4)\n(0, 5)\n(0, 6)\n\n\n1\n(1, 1)\n(1, 2)\n(1, 3)\n(1, 4)\n(1, 5)\n(1, 6)\n\n\n\novvero\n\n\n\n\\(x /\\ y\\)\n1\n2\n3\n4\n5\n6\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\nIl risultato del lancio del dado è indipendente dal risultato del lancio della moneta. Pertanto, ciascun evento elementare dello spazio campione avrà la stessa probabilità di verificarsi, ovvero \\(P(\\omega) = \\frac{1}{12}\\). Il valore atteso di \\(X+Y\\) è dunque uguale a:\n\\[\n\\mathbb{E}(X+Y) = 1 \\cdot \\frac{1}{12} + 2 \\cdot \\frac{1}{12} + \\dots + 7 \\cdot \\frac{1}{12} = 4.0.\n\\]\nSi ottiene lo stesso risultato usando l’Equazione 30.1:\n\\[\n\\mathbb{E}(X+Y) = \\mathbb{E}(X) + E(Y) = 3.5 + 0.5 = 4.0.\n\\]\n\n\nEsempio 30.5 Svolgiamo ora l’esercizio in R\n\ncoin &lt;- 0:1  # Valori della moneta: testa (0) e croce (1)\ndie &lt;- 1:6   # Valori del dado: da 1 a 6\n\n# Creazione del campione come combinazione di valori (moneta, dado)\nsample &lt;- expand.grid(coin = coin, die = die)\nprint(sample)\n#&gt;    coin die\n#&gt; 1     0   1\n#&gt; 2     1   1\n#&gt; 3     0   2\n#&gt; 4     1   2\n#&gt; 5     0   3\n#&gt; 6     1   3\n#&gt; 7     0   4\n#&gt; 8     1   4\n#&gt; 9     0   5\n#&gt; 10    1   5\n#&gt; 11    0   6\n#&gt; 12    1   6\n\n\npx &lt;- numeric()  # Vettore per memorizzare le probabilità\n\nfor (i in 1:7) {\n  # Filtrare le combinazioni in cui la somma è uguale a 'i'\n  event &lt;- subset(sample, coin + die == i)\n  # Calcolare la probabilità\n  prob &lt;- nrow(event) / nrow(sample)\n  px &lt;- c(px, prob)\n  \n  # Stampare la probabilità\n  cat(sprintf(\"P(X + Y = %d) = %d / %d\\n\", i, nrow(event), nrow(sample)))\n}\n#&gt; P(X + Y = 1) = 1 / 12\n#&gt; P(X + Y = 2) = 2 / 12\n#&gt; P(X + Y = 3) = 2 / 12\n#&gt; P(X + Y = 4) = 2 / 12\n#&gt; P(X + Y = 5) = 2 / 12\n#&gt; P(X + Y = 6) = 2 / 12\n#&gt; P(X + Y = 7) = 1 / 12\n\n\nx &lt;- 1:7  # Valori della variabile casuale (somma di moneta e dado)\nexpected_value &lt;- sum(x * px)\nexpected_value\n#&gt; [1] 4\n\n\n\nEsempio 30.6 Consideriamo le variabili casuali \\(X\\) e \\(Y\\) definite nel caso del lancio di tre monete equilibrate, dove \\(X\\) conta il numero delle teste nei tre lanci e \\(Y\\) conta il numero delle teste al primo lancio. Si calcoli il valore atteso di \\(Z = X \\cdot Y\\).\nLa distribuzione di probabilità congiunta \\(P(X, Y)\\) è fornita nella tabella seguente.\n\n\n\n\\(x /\\ y\\)\n0\n1\n\\(p(Y)\\)\n\n\n\n\n0\n1/8\n0\n1/8\n\n\n1\n2/8\n1/8\n3/8\n\n\n2\n1/8\n2/8\n3/8\n\n\n3\n0\n1/8\n1/8\n\n\n\\(p(y)\\)\n4/8\n4/8\n1.0\n\n\n\nIl calcolo del valore atteso di \\(XY\\) si riduce a\n\\[\n\\mathbb{E}(Z) = 1 \\cdot \\frac{1}{8} + 2 \\cdot \\frac{2}{8} + 3 \\cdot \\frac{1}{8} = 1.0.\n\\]\nSi noti che le variabili casuali \\(Y\\) e \\(Y\\) non sono indipendenti. Dunque non possiamo usare l’Equazione 30.3. Infatti, il valore atteso di \\(X\\) è\n\\[\n\\mathbb{E}(X) = 1 \\cdot \\frac{3}{8} + 2 \\cdot \\frac{3}{8} + 3 \\cdot \\frac{1}{8} = 1.5\n\\]\ne il valore atteso di \\(Y\\) è\n\\[\n\\mathbb{E}(Y) = 0 \\cdot \\frac{4}{8} + 1 \\cdot \\frac{4}{8} = 0.5.\n\\]\nPerciò\n\\[\n1.5 \\cdot 0.5 \\neq 1.0.\n\\]\n\n\n\n30.2.3 Variabili casuali continue\nNel caso di una variabile casuale continua \\(X\\), il valore atteso è definito come:\n\\[\n\\mathbb{E}(X) = \\int_{-\\infty}^{+\\infty} x \\cdot p(x) \\, \\mathrm{d}x.\n\\]\nAnche in questo contesto, il valore atteso rappresenta una media ponderata dei valori di \\(x\\), dove ogni possibile valore di \\(x\\) è ponderato in base alla densità di probabilità \\(p(x)\\).\nL’integrale può essere interpretato analogamente a una somma continua, in cui \\(x\\) rappresenta la posizione delle barre infinitamente strette di un istogramma, e \\(p(x)\\) rappresenta l’altezza di tali barre. La notazione \\(\\int_{-\\infty}^{+\\infty}\\) indica che si sta sommando il contributo di ogni valore possibile di \\(x\\) lungo l’intero asse reale.\nQuesta interpretazione rende chiaro come l’integrale calcoli una somma ponderata che si estende su tutti i possibili valori di \\(x\\), fornendo una misura centrale della distribuzione della variabile casuale continua. Per ulteriori dettagli sulla notazione dell’integrale, si veda l’?sec-calculus.\n\n30.2.3.1 Moda\nUn’altra misura di tendenza centrale delle variabili casuali continue è la moda. La moda di \\(Y\\) individua il valore \\(y\\) più plausibile, ovvero il valore \\(y\\) che massimizza la funzione di densità \\(p(y)\\):\n\\[\nMo(Y) = \\text{argmax}_y p(y).\n\\tag{30.4}\\]\n\n\n\n\n\n\nNota\n\n\n\nLa notazione \\(\\text{argmax}_y p(y)\\) significa: il valore \\(y\\) tale per cui la funzione \\(p(y)\\) assume il suo valore massimo.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html#varianza",
    "href": "chapters/probability/06_expval_var.html#varianza",
    "title": "30  Proprietà delle variabili casuali",
    "section": "30.3 Varianza",
    "text": "30.3 Varianza\nDopo il valore atteso, la seconda proprietà più importante di una variabile casuale è la varianza.\n\nDefinizione 30.2 Se \\(X\\) è una variabile casuale discreta con distribuzione \\(p(x)\\), la varianza di \\(X\\), denotata con \\(\\mathbb{V}(X)\\), è definita come:\n\\[\n\\mathbb{V}(X) = \\mathbb{E}\\Big[\\big(X - \\mathbb{E}(X)\\big)^2\\Big].\n\\tag{30.5}\\]\n\nIn altre parole, la varianza misura la deviazione media quadratica dei valori della variabile rispetto alla sua media. Se denotiamo il valore atteso di \\(X\\) con \\(\\mu = \\mathbb{E}(X)\\), la varianza \\(\\mathbb{V}(X)\\) diventa il valore atteso di \\((X - \\mu)^2\\).\n\n30.3.1 Interpretazione della Varianza\nLa varianza rappresenta una misura della “dispersione” dei valori di \\(X\\) intorno al suo valore atteso. Quando calcoliamo la varianza, stiamo effettivamente misurando quanto i valori di \\(X\\) tendono a differire dalla media \\(\\mu\\).\nPer capire meglio, consideriamo la variabile casuale \\(X - \\mathbb{E}(X)\\), detta scarto o deviazione dalla media. Questa variabile rappresenta le “distanze” tra i valori di \\(X\\) e il valore atteso \\(\\mathbb{E}(X)\\). Tuttavia, poiché lo scarto può essere positivo o negativo, la media dello scarto è sempre zero, il che lo rende inadatto a quantificare la dispersione.\nPer risolvere questo problema, eleviamo al quadrato gli scarti, ottenendo \\((X - \\mathbb{E}(X))^2\\), che rende tutte le deviazioni positive. La varianza è quindi la media di questi scarti al quadrato, fornendo una misura efficace della dispersione complessiva dei valori di \\(X\\) rispetto alla sua media.\nQuesto concetto è fondamentale per comprendere la variabilità di una distribuzione e per applicare strumenti statistici che richiedono una conoscenza approfondita della distribuzione dei dati.\n\nEsempio 30.7 Posta \\(S\\) uguale alla somma dei punti ottenuti nel lancio di due dadi equilibrati, si calcoli la varianza di \\(S\\).\nLa variabile casuale \\(S\\) ha la seguente distribuzione di probabilità:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(s\\)\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n\n\\(P(S = s)\\)\n\\(\\frac{1}{36}\\)\n\\(\\frac{2}{36}\\)\n\\(\\frac{3}{36}\\)\n\\(\\frac{4}{36}\\)\n\\(\\frac{5}{36}\\)\n\\(\\frac{6}{36}\\)\n\\(\\frac{5}{36}\\)\n\\(\\frac{4}{36}\\)\n\\(\\frac{3}{36}\\)\n\\(\\frac{2}{36}\\)\n\\(\\frac{1}{36}\\)\n\n\n\nEssendo \\(\\mathbb{E}(S) = 7\\), la varianza diventa\n\\[\n\\begin{align}\n\\mathbb{V}(S) &= \\sum \\left(s - \\mathbb{E}(S)\\right)^2 \\cdot P(s) \\notag\\\\\n&= (2 - 7)^2 \\cdot \\frac{1}{36} + (3-7)^2 \\cdot \\frac{3}{36} + \\dots + (12 - 7)^2 \\cdot \\frac{1}{36} \\notag\\\\\n&= 5.8333.\\notag\n\\end{align}\n\\]\n\n\nEsempio 30.8 Svolgiamo l’esercizio in R\n\n# Definire i valori di x e le loro probabilità px\nx &lt;- 2:12\npx &lt;- c(\n  1 / 36, 2 / 36, 3 / 36, 4 / 36, 5 / 36, 6 / 36,\n  5 / 36, 4 / 36, 3 / 36, 2 / 36, 1 / 36\n)\n\n# Calcolare il valore atteso\nex &lt;- sum(x * px)\nex\n#&gt; [1] 7\n\nApplichiamo l’Equazione 30.5:\n\n# Calcolo della varianza utilizzando la definizione\nvariance &lt;- sum((x - ex)^2 * px)\nvariance\n#&gt; [1] 5.833333\n\nUsiamo la funzione var() di rv_discrete:\n\n# Calcolo della varianza con pesi\nvariance_check &lt;- weighted.mean((x - ex)^2, w = px)\nvariance_check\n#&gt; [1] 5.833333\n\n\n\n\n30.3.2 Formula Alternativa per la Varianza\nEsiste un metodo più semplice e diretto per calcolare la varianza di una variabile casuale \\(X\\):\n\\[\n\\begin{align}\n\\mathbb{E}\\Big[\\big(X - \\mathbb{E}(X)\\big)^2\\Big] &= \\mathbb{E}\\big(X^2 - 2Y\\mathbb{E}(X) + \\mathbb{E}(X)^2\\big) \\notag\\\\\n&= \\mathbb{E}(X^2) - 2\\mathbb{E}(Y)\\mathbb{E}(X) + \\mathbb{E}(X)^2,\n\\end{align}\n\\]\ndove \\(\\mathbb{E}(X)\\) è una costante. Semplificando ulteriormente, otteniamo:\n\\[\n\\mathbb{V}(X) = \\mathbb{E}(X^2) - \\big(\\mathbb{E}(X)\\big)^2.\n\\tag{30.6}\\]\nIn altre parole, la varianza è data dalla differenza tra la media dei quadrati dei valori di \\(X\\) e il quadrato della media di \\(X\\).\nQuesta formula è utile perché permette di calcolare la varianza senza dover prima determinare lo scarto quadratico medio per ciascun valore di \\(X\\). Invece, si può calcolare direttamente la media dei quadrati e sottrarre il quadrato della media, il che spesso semplifica i calcoli e riduce il rischio di errori.\n\nEsempio 30.9 Consideriamo la variabile casuale \\(X\\) che corrisponde al numero di teste che si osservano nel lancio di una moneta truccata con probabilità di testa uguale a 0.8. Si trovi la varianza di \\(Y\\).\nIl valore atteso di \\(X\\) è\n\\[\n\\mathbb{E}(X) = 0 \\cdot 0.2 + 1 \\cdot 0.8 = 0.8.\n\\]\nUsando la formula tradizionale della varianza otteniamo:\n\\[\n\\mathbb{V}(X) = (0 - 0.8)^2 \\cdot 0.2 + (1 - 0.8)^2 \\cdot 0.8 = 0.16.\n\\]\nLo stesso risultato si trova con la formula alternativa della varianza. Il valore atteso di \\(X^2\\) è\n\\[\n\\mathbb{E}(X^2) = 0^2 \\cdot 0.2 + 1^2 \\cdot 0.8 = 0.8.\n\\]\ne la varianza diventa\n\\[\n\\mathbb{V}(X) = \\mathbb{E}(X^2) - \\big(\\mathbb{E}(Y) \\big)^2 = 0.8 - 0.8^2 = 0.16.\n\\]\n\n\nEsempio 30.10 Svolgiamo l’esercizio in R:\n\n# Definire i valori di x e le probabilità px\nx &lt;- c(0, 1)\npx &lt;- c(0.2, 0.8)\n\n# Calcolare il risultato\nresult &lt;- sum(x^2 * px) - (sum(x * px))^2\nresult\n#&gt; [1] 0.16\n\n\n\n\n30.3.3 Proprietà\nSegno della varianza. La varianza di una variabile aleatoria non è mai negativa, ed è zero solamente quando la variabile assume un solo valore.\nInvarianza per traslazione. La varianza è invariante per traslazione, che lascia fisse le distanze dalla media, e cambia quadraticamente per riscalamento:\n\\[\n\\mathbb{V}(a + bX) = b^2\\mathbb{V}(X).\n\\]\nDimostrazione. Iniziamo a scrivere\n\\[\n(aX+b)-{\\mathbb{E}}[aX+b]=aX+b-a{\\mathbb{E}}[X]-b=a(X-{\\mathbb  {E}}[X]).\n\\]\nQuindi\n\\[\n\\sigma _{{aX+b}}^{2}={\\mathbb{E}}[a^{2}(X-{\\mathbb  {E}}[X])^{2}]=a^{2}\\sigma _{X}^{2}.\n\\]\nEsaminiamo una dimostrazione numerica.\n\n# Definire i valori di x\nx &lt;- c(2, 1, 4, 7)\n\n# Calcolare y\ny &lt;- 100 + 2 * x\n\n# Verificare la relazione tra le varianze\nresult &lt;- var(y) == 2^2 * var(x)\nresult\n#&gt; [1] TRUE\n\nVarianza della somma di due variabili indipendenti. La varianza della somma di due variabili indipendenti o anche solo incorrelate è pari alla somma delle loro varianze:\n\\[\n\\mathbb{V}(X+Y) = \\mathbb{V}(X) + \\mathbb{V}(Y).\n\\]\nDimostrazione. Se \\(\\mathbb{E}(X) = \\mathbb{E}(Y) = 0\\), allora \\(\\mathbb{E}(X+Y) = 0\\) e\n\\[\\mathbb{V}(X+Y) = \\mathbb{E}((X+Y)^2) = \\mathbb{E}(X^2) + 2 \\mathbb{E}(XY) + \\mathbb{E}(Y^2).\\]\nSiccome le variabili sono indipendenti risulta \\(\\mathbb{E}(XY) = \\mathbb{E}(X)\\mathbb{E}(Y) = 0\\).\nVarianza della differenza di due variabili indipendenti. La varianza della differenza di due variabili indipendenti è pari alla somma delle loro varianze:\n\\[\n\\mathbb{V}(X-Y) = \\mathbb{V}(X) + \\mathbb{V}(Y).\n\\]\nDimostrazione.\n\\[\n\\mathbb{V}(X-Y) = \\mathbb{V}(X +(-Y)) = \\mathbb{V}(X) + \\mathbb{V}(-Y) = \\mathbb{V}(X) + \\mathbb{V}(Y).\n\\]\nVarianza della somma di due variabili non indipendenti. Se \\(X\\) e \\(Y\\) non sono indipendenti, la formula viene corretta dalla loro covarianza:\n\\[\n\\mathbb{V}(X+Y) = \\mathbb{V}(X) + \\mathbb{V}(Y) + 2 Cov(X,Y),\n\\]\ndove \\(Cov(X,Y) = \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y)\\).\nUna dimostrazione numerica di questo principio è fornita sotto.\n\n# Definire i valori di x e y\nx &lt;- c(2, 1, 4, 7)\ny &lt;- c(1, 3, 5, 11)\n\n# Calcolare la varianza di x + y con ddof = 0\nvar_x_y &lt;- mean((x + y - mean(x + y))^2)\nvar_x_y\n#&gt; [1] 35.25\n\n\n# Definire i valori di x e y\nx &lt;- c(2, 1, 4, 7)\ny &lt;- c(1, 3, 5, 11)\n\n# Calcolo della varianza combinata\nresult &lt;- mean((x - mean(x))^2) + \n          mean((y - mean(y))^2) + \n          2 * cov(x, y) * (length(x) - 1) / length(x)\nresult\n#&gt; [1] 35.25\n\nVarianza della media di variabili indipendenti. La media aritmetica \\(\\textstyle {\\bar  {X}}={\\frac  {X_{1}+\\ldots +X_{n}}{n}}\\) di \\(n\\) variabili casuali indipendenti aventi la medesima distribuzione, ha varianza\n\\[\n\\mathbb{V}(\\bar{X}) = \\frac{1}{n^2} \\mathbb{V}(X_1)+ \\dots \\mathbb{V}(X_n) = \\frac{1}{n^2} n \\mathbb{V}(X) = \\frac{1}{n} \\mathbb{V}(X).\n\\]\nIl principio precedente è illustrato dalla seguente simulazione.\n\n# Creare la popolazione\nset.seed(123)  # Per riproducibilità\npopulation &lt;- rnorm(10000, mean = 50, sd = 10)\n\n# Definire dimensione del campione e numero di campioni\nsample_size &lt;- 30\nnum_samples &lt;- 100000\n\n# Creare un vettore per memorizzare le medie campionarie\nsample_means &lt;- numeric(num_samples)\n\n# Generare i campioni e calcolare le medie\nfor (i in 1:num_samples) {\n  sample &lt;- sample(population, size = sample_size, replace = TRUE)\n  sample_means[i] &lt;- mean(sample)\n}\n\n# Calcolare la varianza delle medie campionarie\nsampling_dist_mean_var &lt;- var(sample_means) * ((num_samples - 1) / num_samples)  # ddof = 0\nsampling_dist_mean_var\n#&gt; [1] 3.330581\n\nIl valore teorico della varianza della distribuzione campionaria della media è\n\n10^2 / 30\n#&gt; [1] 3.333333\n\n\n\n30.3.4 Variabili casuali continue\nPer una variabile casuale continua \\(X\\), la varianza è definita come:\n\\[\n\\mathbb{V}(X) = \\int_{-\\infty}^{+\\infty} \\large[x - \\mathbb{E}(X)\\large]^2 p(x) \\,\\operatorname {d}\\!x.\n\\tag{30.7}\\]\nAnalogamente al caso discreto, la varianza di una variabile casuale continua \\(X\\) una misura della dispersione, ovvero la “distanza” media quadratica attesa dei valori \\(x\\) rispetto alla loro media \\(\\mathbb{E}(X)\\). In altre parole, la varianza quantifica quanto i valori della variabile casuale si discostano tipicamente dal loro valore medio.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html#deviazione-standard",
    "href": "chapters/probability/06_expval_var.html#deviazione-standard",
    "title": "30  Proprietà delle variabili casuali",
    "section": "30.4 Deviazione Standard",
    "text": "30.4 Deviazione Standard\nQuando si lavora con le varianze, i valori sono elevati al quadrato, il che può rendere i numeri significativamente più grandi (o più piccoli) rispetto ai dati originali. Per riportare questi valori all’unità di misura della scala originale, si prende la radice quadrata della varianza. Il risultato ottenuto è chiamato deviazione standard ed è comunemente indicato con la lettera greca \\(\\sigma\\).\n\nDefinizione 30.3 La deviazione standard, o scarto quadratico medio, è definita come la radice quadrata della varianza:\n\\[\n\\sigma_X = \\sqrt{\\mathbb{V}(X)}.\n\\]\n\nCome nella statistica descrittiva, la deviazione standard di una variabile casuale fornisce una misura della dispersione, ossia la “distanza” tipica o prevista dei valori \\(x\\) rispetto alla loro media.\n\nEsempio 30.11 Per i dadi equilibrati dell’esempio precedente, la deviazione standard della variabile casuale \\(S\\) è pari a \\(\\sqrt{5.833} = 2.415\\). Questo valore indica quanto i risultati della somma dei due dadi tendono a variare attorno alla loro media.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html#standardizzazione",
    "href": "chapters/probability/06_expval_var.html#standardizzazione",
    "title": "30  Proprietà delle variabili casuali",
    "section": "30.5 Standardizzazione",
    "text": "30.5 Standardizzazione\n\nDefinizione 30.4 Data una variabile casuale \\(X\\), si dice variabile standardizzata di \\(X\\) l’espressione\n\\[\nZ = \\frac{X - \\mathbb{E}(X)}{\\sigma_X}.\n\\tag{30.8}\\]\n\nSolitamente, una variabile standardizzata viene denotata con la lettera \\(Z\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html#il-teorema-di-chebyshev",
    "href": "chapters/probability/06_expval_var.html#il-teorema-di-chebyshev",
    "title": "30  Proprietà delle variabili casuali",
    "section": "30.6 Il Teorema di Chebyshev",
    "text": "30.6 Il Teorema di Chebyshev\nIl Teorema di Chebyshev ci permette di stimare la probabilità che una variabile aleatoria si discosti dal suo valore atteso (media) di una certa quantità. In altre parole, ci fornisce un limite superiore alla probabilità che una variabile aleatoria assuma valori “estremi”.\nIl teorema di Chebyshev afferma che, per qualsiasi variabile aleatoria X con media E(X) e varianza Var(X), e per qualsiasi numero reale k &gt; 0, si ha:\n\\[\nP(|X - E(X)| ≥ kσ) ≤ 1/k^2,\n\\]\ndove:\n\nP(|X - E(X)| ≥ kσ) è la probabilità che lo scarto assoluto tra X e la sua media sia maggiore o uguale a k volte la deviazione standard (σ).\nσ è la radice quadrata della varianza, ovvero la deviazione standard.\n\nCosa ci dice questo teorema?\n\nLimite superiore: Il teorema ci fornisce un limite superiore alla probabilità che una variabile aleatoria si discosti dalla sua media di più di k deviazioni standard.\nQualsiasi distribuzione: La bellezza di questo teorema è che vale per qualsiasi distribuzione di probabilità, a patto che la media e la varianza esistano.\nUtilizzo: Il teorema di Chebyshev è molto utile quando non conosciamo la distribuzione esatta di una variabile aleatoria, ma conosciamo la sua media e la sua varianza.\n\nIn sintesi, il teorema di Chebyshev ci fornisce un limite superiore alla probabilità che una variabile aleatoria si discosti dalla sua media di una certa quantità, in base alla sua varianza. Il teorema di Chebyshev ci permette quindi di fare inferenze sulla distribuzione di una variabile aleatoria anche quando abbiamo informazioni limitate.\n\nEsempio 30.12 Supponiamo di avere una variabile aleatoria X con media 100 e varianza 25. Vogliamo stimare la probabilità che X assuma valori al di fuori dell’intervallo [90, 110]. In questo caso, k = 2 (poiché 10 è uguale a 2 volte la deviazione standard, che è 5). Applicando il teorema di Chebyshev, otteniamo:\nP(|X - 100| ≥ 10) ≤ 1/2^2 = 0.25\nQuindi, possiamo affermare con certezza che al massimo il 25% dei valori di X saranno al di fuori dell’intervallo [90, 110].",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html#momenti-di-variabili-casuali",
    "href": "chapters/probability/06_expval_var.html#momenti-di-variabili-casuali",
    "title": "30  Proprietà delle variabili casuali",
    "section": "30.7 Momenti di variabili casuali",
    "text": "30.7 Momenti di variabili casuali\n\nDefinizione 30.5 Si chiama momento di ordine \\(q\\) di una v.c. \\(X\\), dotata di densità \\(p(x)\\), la quantità\n\\[\n\\mathbb{E}(X^q) = \\int_{-\\infty}^{+\\infty} x^q p(x) \\; dx.\n\\tag{30.9}\\]\nSe \\(X\\) è una v.c. discreta, i suoi momenti valgono:\n\\[\n\\mathbb{E}(X^q) = \\sum_i x_i^q P(x_i),\n\\tag{30.10}\\]\ndove:\n\n\\(E(X^q)\\) rappresenta il valore atteso di \\(X\\) elevato alla \\(q\\)-esima potenza.\n\\(x_i\\) sono i possibili valori della variabile discreta.\n\\(P(x_i)\\) è la probabilità associata a ciascun valore discreto.\n\n\nI momenti sono parametri statistici che forniscono informazioni importanti sulle caratteristiche di una variabile casuale. Tra questi, i più noti e utilizzati sono:\n\nIl momento del primo ordine (\\(q\\) = 1): corrisponde al valore atteso (o media) della variabile casuale \\(X\\).\nIl momento del secondo ordine (\\(q\\) = 2): quando calcolato rispetto alla media, corrisponde alla varianza.\n\nPer i momenti di ordine superiore al primo, è comune calcolarli rispetto al valore medio di \\(X\\). Questo si ottiene applicando una traslazione: \\(x_0 = x − \\mathbb{E}(X)\\), dove \\(x_0\\) rappresenta lo scarto dalla media. In particolare, il momento centrale del secondo ordine, calcolato con questa traslazione, corrisponde alla definizione di varianza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html#alcuni-esempi-in-r",
    "href": "chapters/probability/06_expval_var.html#alcuni-esempi-in-r",
    "title": "30  Proprietà delle variabili casuali",
    "section": "30.8 Alcuni esempi in R",
    "text": "30.8 Alcuni esempi in R\nIn R, possiamo calcolare il valore atteso e la varianza di variabili casuali discrete utilizzando vettori di valori e probabilità.\nConsideriamo una variabile casuale \\(X\\) che rappresenta i valori ottenuti dal lancio di un dado non equilibrato, con valori possibili da 0 a 6, e con la seguente distribuzione di massa di probabilità: 0.1, 0.2, 0.3, 0.1, 0.1, 0.0, 0.2.\nIniziamo a definire un vettore che contiene i valori della v.c.:\n\nx &lt;- 0:6\nprint(x)\n#&gt; [1] 0 1 2 3 4 5 6\n\nIl vettore px conterrà le probabilità associate ai valori x:\n\npx &lt;- c(0.1, 0.2, 0.3, 0.1, 0.1, 0.0, 0.2)\nprint(px)\n#&gt; [1] 0.1 0.2 0.3 0.1 0.1 0.0 0.2\n\nControlliamo che la somma sia 1:\n\nsum(px)\n#&gt; [1] 1\n\nCalcoliamo il valore atteso di \\(X\\) implementando la formula del valore atteso utilizzando i vettori x e px:\n\nx_ev &lt;- sum(x * px)\nx_ev\n#&gt; [1] 2.7\n\nCalcoliamo la varianza di \\(X\\) usando i vettori x e px:\n\nx_var &lt;- sum((x - x_ev)^2 * px)\nx_var\n#&gt; [1] 3.81\n\nCalcoliamo la deviazione standard di \\(X\\) prendendo la radice quadrata della varianza:\n\nx_sd &lt;- sqrt(x_var)\nx_sd\n#&gt; [1] 1.951922\n\nPer rappresentare graficamente la distribuzione di massa, possiamo usare ggplot2:\n\ndf &lt;- data.frame(x = x, pmf = px)\nggplot(df, aes(x = x, y = pmf)) +\n  geom_point(color = \"#832F2B\", size = 3) +\n  geom_segment(aes(xend = x, yend = 0), linewidth = 1) +\n  labs(title = \"Distribuzione di massa di probabilità\", \n       x = \"Valori\", y = \"Probabilità\")\n\n\n\n\n\n\n\n\nQuesto codice calcola il valore atteso, la varianza e la deviazione standard di una variabile casuale discreta e rappresenta graficamente la distribuzione di massa, tutto in R.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html#riflessioni-conclusive",
    "href": "chapters/probability/06_expval_var.html#riflessioni-conclusive",
    "title": "30  Proprietà delle variabili casuali",
    "section": "30.9 Riflessioni Conclusive",
    "text": "30.9 Riflessioni Conclusive\nIn conclusione, i concetti di valore atteso e varianza sono fondamentali per comprendere il comportamento delle variabili casuali. Il valore atteso fornisce una misura centrale, rappresentando il “valore tipico” che ci si aspetta di osservare, mentre la varianza quantifica la dispersione dei valori attorno a questa media, offrendo una visione più completa della distribuzione. Questi strumenti sono essenziali per l’analisi e la modellizzazione statistica, fornendo le basi per valutare e interpretare la variabilità nei fenomeni aleatori.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/06_expval_var.html#informazioni-sullambiente-di-sviluppo",
    "title": "30  Proprietà delle variabili casuali",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.16.0       MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2\n#&gt;  [5] ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0  \n#&gt;  [9] bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0      markdown_1.13    \n#&gt; [13] knitr_1.49        lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1    \n#&gt; [17] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#&gt; [21] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [25] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1  farver_2.1.2      fastmap_1.2.0     pacman_0.5.1     \n#&gt;  [5] promises_1.3.1    rpart_4.1.23      digest_0.6.37     timechange_0.3.0 \n#&gt;  [9] mime_0.12         lifecycle_1.0.4   survival_3.7-0    magrittr_2.0.3   \n#&gt; [13] compiler_4.4.2    rlang_1.1.4       tools_4.4.2       utf8_1.2.4       \n#&gt; [17] yaml_2.3.10       ggsignif_0.6.4    labeling_0.4.3    htmlwidgets_1.6.4\n#&gt; [21] mnormt_2.1.1      abind_1.4-8       miniUI_0.1.1.1    withr_3.0.2      \n#&gt; [25] nnet_7.3-19       grid_4.4.2        fansi_1.0.6       jomo_2.7-6       \n#&gt; [29] xtable_1.8-4      colorspace_2.1-1  iterators_1.0.14  cli_3.6.3        \n#&gt; [33] rmarkdown_2.29    generics_0.1.3    tzdb_0.4.0        minqa_1.2.8      \n#&gt; [37] splines_4.4.2     parallel_4.4.2    vctrs_0.6.5       boot_1.3-31      \n#&gt; [41] glmnet_4.1-8      Matrix_1.7-1      jsonlite_1.8.9    carData_3.0-5    \n#&gt; [45] car_3.1-3         hms_1.1.3         mitml_0.4-5       rstatix_0.7.2    \n#&gt; [49] Formula_1.2-5     foreach_1.5.2     glue_1.8.0        pan_1.9          \n#&gt; [53] nloptr_2.1.1      codetools_0.2-20  stringi_1.8.4     gtable_0.3.6     \n#&gt; [57] shape_1.4.6.1     later_1.4.0       lme4_1.1-35.5     munsell_0.5.1    \n#&gt; [61] pillar_1.9.0      htmltools_0.5.8.1 R6_2.5.1          rprojroot_2.0.4  \n#&gt; [65] evaluate_1.0.1    shiny_1.9.1       lattice_0.22-6    backports_1.5.0  \n#&gt; [69] broom_1.0.7       httpuv_1.6.15     Rcpp_1.0.13-1     nlme_3.1-166     \n#&gt; [73] xfun_0.49         pkgconfig_2.0.3",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_bayes_theorem.html",
    "href": "chapters/probability/07_bayes_theorem.html",
    "title": "31  Il teorema di Bayes",
    "section": "",
    "text": "31.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nIl teorema di Bayes offre una soluzione ottimale ai problemi induttivi, che spaziano dall’identificazione della struttura tridimensionale del mondo basata su dati sensoriali limitati, all’inferenza dei pensieri altrui a partire dal loro comportamento. Questa regola si rivela particolarmente utile in situazioni in cui i dati osservati sono insufficienti per distinguere in modo definitivo tra diverse ipotesi.\nNonostante ciò, tutte le previsioni basate su questo metodo mantengono un certo grado di incertezza. Anche se l’universo fosse completamente deterministico, la nostra conoscenza di esso rimarrebbe imperfetta: non possiamo conoscere la posizione e lo stato di ogni singola particella che lo compone. Le informazioni a nostra disposizione sono inevitabilmente parziali e imprecise, ottenute attraverso i nostri sensi limitati.\nLa vita reale non è paragonabile a una partita di scacchi, un gioco con informazioni perfette che può essere “risolto” in linea di principio. Assomiglia piuttosto al poker, dove le decisioni vengono prese utilizzando le informazioni limitate a disposizione dei giocatori. Questo capitolo si concentra sull’equazione che ci permette di fare proprio questo: il teorema di Bayes. Esso descrive come modifichiamo le nostre convinzioni riguardo a un’ipotesi in una situazione in cui i dati disponibili non consentono una decisione certa.\nQuesto processo è noto come inferenza induttiva, che ci permette di trarre conclusioni generali da dati specifici e limitati. Il teorema di Bayes fornisce quindi un framework matematico per aggiornare le nostre credenze alla luce di nuove evidenze, permettendoci di prendere decisioni informate in un mondo caratterizzato dall’incertezza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_bayes_theorem.html#la-regola-di-bayes",
    "href": "chapters/probability/07_bayes_theorem.html#la-regola-di-bayes",
    "title": "31  Il teorema di Bayes",
    "section": "32.1 La Regola di Bayes",
    "text": "32.1 La Regola di Bayes\nL’inferenza bayesiana si basa su una formula fondamentale nota come regola di Bayes. Sebbene possa sembrare un semplice risultato della teoria delle probabilità, la sua applicazione ha implicazioni profonde in molti campi, inclusa la scienza cognitiva e l’apprendimento automatico. Supponiamo di avere due variabili casuali, \\(A\\) e \\(B\\). Un principio della probabilità, chiamato regola della catena, ci consente di esprimere la probabilità congiunta di queste due variabili \\(P(a, b)\\) come il prodotto della probabilità condizionale di \\(A\\) dato \\(B\\), e la probabilità marginale di \\(B\\). In termini formali:\n\\[\nP(a, b) = P(a \\mid b) P(b).\n\\tag{32.1}\\]\nNon vi è nulla di speciale nel trattare \\(A\\) prima di \\(B\\); possiamo infatti anche scrivere:\n\\[\nP(a, b) = P(b \\mid a) P(a).\n\\tag{32.2}\\]\nDalle due equazioni precedenti, possiamo derivare la regola di Bayes riorganizzando i termini:\n\\[\nP(b \\mid a) = \\frac{P(a \\mid b) P(b)}{P(a)}.\n\\tag{32.3}\\]\nQuesta espressione, nota come regola di Bayes, ci permette di calcolare la probabilità condizionale di \\(b\\) dato \\(a\\), usando la probabilità condizionale opposta \\(P(a \\mid b)\\), la probabilità a priori \\(P(b)\\), e la probabilità marginale \\(P(a)\\).\n\n32.1.1 Applicazioni della Regola di Bayes\nLa forza della regola di Bayes si manifesta pienamente quando la applichiamo a un contesto di inferenza. Supponiamo di avere un agente che tenta di inferire quale processo ha generato alcuni dati \\(d\\). Lasciamo che \\(h\\) rappresenti un’ipotesi su tale processo. L’agente usa le probabilità per rappresentare il grado di credenza in \\(h\\) e in altre ipotesi alternative \\(h'\\), e indichiamo con \\(P(h)\\) la probabilità a priori dell’ipotesi \\(h\\), ovvero la credenza che l’agente attribuisce a \\(h\\) prima di osservare i dati.\nA questo punto, l’agente vuole aggiornare questa credenza alla luce dei nuovi dati \\(d\\), ottenendo la probabilità a posteriori \\(P(h \\mid d)\\). Usando la regola di Bayes, possiamo calcolare questa probabilità nel seguente modo:\n\\[\nP(h \\mid d) = \\frac{P(d \\mid h) P(h)}{P(d)}.\n\\tag{32.4}\\]\nQui, \\(P(d \\mid h)\\) rappresenta la verosimiglianza, ovvero la probabilità di osservare i dati \\(d\\) supponendo che l’ipotesi \\(h\\) sia vera. La verosimiglianza gioca un ruolo cruciale nell’aggiornamento delle nostre credenze: essa “ri-pesa” ogni ipotesi in base alla sua capacità di predire i dati osservati.\n\n\n32.1.2 La Marginalizzazione\nLa teoria delle probabilità ci permette anche di calcolare la probabilità marginale associata a una singola variabile sommando o integrando su altre variabili in una distribuzione congiunta. Ad esempio, la probabilità marginale di \\(b\\) è data da:\n\\[\nP(b) = \\sum_a P(a, b).\n\\]\nQuesto processo è chiamato marginalizzazione. Utilizzando questo principio, possiamo riscrivere la regola di Bayes in un formato che include esplicitamente la somma su tutte le ipotesi alternative \\(h' \\in H\\) considerate dall’agente:\n\\[\nP(h \\mid d) = \\frac{P(d \\mid h) P(h)}{\\sum_{h' \\in H} P(d \\mid h') P(h')}.\n\\tag{32.5}\\]\nIn questo caso, \\(H\\) rappresenta l’insieme di tutte le ipotesi possibili, a volte chiamato spazio delle ipotesi, e la somma al denominatore assicura che le probabilità a posteriori siano normalizzate, cioè che la loro somma sia pari a uno.\n\n\n\n\n\n\n\n\n\n\n\n32.1.3 Estensione al Caso Continuo\nQuando le ipotesi non sono discrete ma fanno parte di un continuum, la formula di Bayes assume una forma integrale:\n\\[\nP(h_i \\mid d) = \\frac{P(d \\mid h_i) \\cdot P(h_i)}{\\int P(d \\mid H) \\cdot P(H) \\, dH}.\n\\tag{32.6}\\]\nIn questo caso, l’integrale nel denominatore somma tutte le ipotesi possibili, ponderandole per le loro probabilità a priori e verosimiglianze. Questo permette di aggiornare le credenze anche per ipotesi continue.\n\n\n32.1.4 Componenti Chiave della Formula di Bayes\nLa formula di Bayes si basa su tre elementi principali:\n\nProbabilità a Priori \\(P(h_i)\\): Questa rappresenta la credenza iniziale sull’ipotesi \\(h_i\\), prima di osservare i dati. È una stima preliminare basata su informazioni preesistenti.\nVerosimiglianza \\(P(d \\mid h_i)\\): Indica la probabilità di osservare i dati \\(d\\), dato che l’ipotesi \\(h_i\\) sia vera. Questa componente quantifica quanto l’ipotesi predice correttamente i dati osservati.\nProbabilità a Posteriori \\(P(h_i \\mid d)\\): Questa è la credenza aggiornata in \\(h_i\\), dopo aver considerato l’evidenza \\(d\\). È il prodotto della probabilità a priori e della verosimiglianza, normalizzato in modo che tutte le ipotesi abbiano probabilità totale pari a uno.\n\nIn conclusione, la regola di Bayes fornisce un quadro potente per aggiornare le credenze in modo coerente e sistematico man mano che si accumulano nuove informazioni, permettendo di affinare le nostre decisioni e previsioni.\nGrazie alla regola di Bayes, possiamo aggiornare costantemente le nostre credenze man mano che nuove informazioni diventano disponibili. Questo processo dinamico di aggiornamento ci permette di affinare le nostre convinzioni e le nostre previsioni, rendendo il modello bayesiano particolarmente utile nelle situazioni in cui le informazioni sono incomplete o incerte. Questo approccio non solo ci consente di prendere decisioni più informate, ma ci permette anche di sviluppare modelli più accurati della realtà basati sulle evidenze.\n\n\n32.1.5 Applicazioni dei modelli bayesiani\nCome discusso da Griffiths et al. (2024), negli ultimi anni, i modelli bayesiani hanno acquisito un’importanza crescente in vari campi delle scienze cognitive. Questi modelli sono stati applicati allo studio dell’apprendimento animale (Courville, Daw, & Touretzky, 2006), dell’apprendimento induttivo umano e della generalizzazione (Tenenbaum, Griffiths, & Kemp, 2006), della percezione visiva (Yuille & Kersten, 2006), del controllo motorio (Kording & Wolpert, 2006), della memoria semantica (Steyvers, Griffiths, & Dennis, 2006), dell’acquisizione e del processamento del linguaggio (Chater & Manning, 2006; Xu & Tenenbaum, in press), del ragionamento simbolico (Oaksford & Chater, 2001), dell’apprendimento causale (Steyvers, Tenenbaum, Wagenmakers, & Blum, 2003; Griffiths & Tenenbaum, 2005, 2007a), e della cognizione sociale (Baker, Tenenbaum, & Saxe, 2007), tra molti altri argomenti.\nDietro questi diversi programmi di ricerca emerge una domanda centrale: come fa la mente umana ad andare oltre i dati dell’esperienza? In altre parole, come riesce la mente a costruire modelli complessi e astratti del mondo, partendo solo da dati sparsi e rumorosi, osservati attraverso i nostri sensi? La risposta proposta dall’approccio bayesiano è che la mente umana utilizza un processo di inferenza probabilistica per aggiornare le proprie credenze sulla base delle nuove evidenze, creando così modelli del mondo sempre più accurati e raffinati.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_bayes_theorem.html#alcuni-esempi",
    "href": "chapters/probability/07_bayes_theorem.html#alcuni-esempi",
    "title": "31  Il teorema di Bayes",
    "section": "32.2 Alcuni esempi",
    "text": "32.2 Alcuni esempi\n\nEsempio 32.1 Il modo più comune per spiegare il teorema di Bayes è attraverso i test medici. Prendiamo come esempio il caso della mammografia e la diagnosi del cancro al seno che abbiamo già discusso in precedenza.\nSupponiamo di avere un test di mammografia con una sensibilità del 90% e una specificità del 90%. Questo significa che:\n\nIn presenza di cancro al seno, la probabilità che il test lo rilevi correttamente è del 90%.\nIn assenza di cancro al seno, la probabilità che il test confermi correttamente l’assenza della malattia è del 90%.\n\nIn altri termini, il test ha un tasso di falsi negativi del 10% e un tasso di falsi positivi anch’esso del 10%.\nDefiniamo due ipotesi:\n\n\\(M^+\\): presenza della malattia\n\\(M^-\\): assenza della malattia\n\nL’evidenza è rappresentata dal risultato positivo di un test di mammografia, che indichiamo con \\(T^+\\).\nApplicando il teorema di Bayes, possiamo calcolare la probabilità di avere il cancro al seno dato un risultato positivo al test, come segue:\n\\[\nP(M^+ \\mid T^+) = \\frac{P(T^+ \\mid M^+) \\cdot P(M^+)}{P(T^+ \\mid M^+) \\cdot P(M^+) + P(T^+ \\mid M^-) \\cdot P(M^-)},\n\\]\ndove:\n\n\\(P(M^+ \\mid T^+)\\) è la probabilità di avere il cancro (\\(M^+\\)) dato un risultato positivo al test (\\(T^+\\)).\n\\(P(T^+ \\mid M^+)\\) rappresenta la sensibilità del test, ovvero la probabilità che il test risulti positivo in presenza effettiva del cancro. In questo caso, è pari a 0.90.\n\\(P(M^+)\\) è la probabilità a priori che una persona abbia il cancro, ovvero la prevalenza della malattia nella popolazione.\n\\(P(T^+ \\mid M^-)\\) indica la probabilità di un falso positivo, cioè la probabilità che il test risulti positivo in assenza di cancro. Con una specificità del 90%, questa probabilità si calcola come:\n\\[\nP(T^+ \\mid M^-) = 1 - \\text{Specificità} = 1 - 0.90 = 0.10\n\\]\nQuesto significa che c’è una probabilità del 10% che il test diagnostichi erroneamente la presenza del cancro in una persona sana.\n\\(P(M^-)\\) è la probabilità a priori che una persona non sia affetta da cancro prima di effettuare il test.\n\nQuesta formulazione del teorema di Bayes ci permette di calcolare la probabilità effettiva di avere il cancro al seno, dato un risultato positivo al test di mammografia, tenendo conto sia della sensibilità e specificità del test, sia della prevalenza della malattia nella popolazione.\nInserendo nella formula i del problema, otteniamo:\n\\[\n\\begin{align}\nP(M^+ \\mid T^+) &= \\frac{0.9 \\cdot 0.01}{0.9 \\cdot 0.01 + 0.1 \\cdot 0.99} \\notag\\\\\n&= \\frac{9}{108} \\notag\\\\\n&\\approx 0.083.\\notag\n\\end{align}\n\\]\nI calcoli effettuati evidenziano come, in presenza di una mammografia positiva ottenuta con un test avente sensibilità e specificità pari al 90%, la probabilità di effettiva positività al tumore al seno si attesta intorno all’8.3%. Tale risultato conferma quanto precedentemente ottenuto nel ?sec-cond-prob, attraverso un metodo di calcolo alternativo.\n\n\n32.2.1 Il Valore Predittivo di un Test di Laboratorio\nPer semplicità, possiamo riscrivere il teorema di Bayes in due modi distinti per calcolare ciò che viene chiamato valore predittivo del test positivo e valore predittivo del test negativo.\nLa comprensione di tre elementi è fondamentale per questo calcolo: la prevalenza della malattia, la sensibilità e la specificità del test.\n\nPrevalenza: Si riferisce alla percentuale di individui in una popolazione affetti da una certa malattia in un determinato momento. Viene espressa come percentuale o frazione della popolazione. Per esempio, una prevalenza dello 0,5% indica che su mille persone, cinque sono affette dalla malattia.\nSensibilità: Indica la capacità del test di identificare correttamente la malattia negli individui malati. Viene calcolata come la frazione di veri positivi (individui malati correttamente identificati) sul totale degli individui malati. La formula della sensibilità (\\(Sens\\)) è la seguente:\n\\[ \\text{Sensibilità} = \\frac{TP}{TP + FN}, \\]\ndove \\(TP\\) rappresenta i veri positivi e \\(FN\\) i falsi negativi. Pertanto, la sensibilità misura la probabilità che il test risulti positivo se la malattia è effettivamente presente.\nSpecificità: Misura la capacità del test di riconoscere gli individui sani, producendo un risultato negativo per chi non è affetto dalla malattia. Si calcola come la frazione di veri negativi (individui sani correttamente identificati) sul totale degli individui sani. La specificità (\\(Spec\\)) si definisce come:\n\\[ \\text{Specificità} = \\frac{TN}{TN + FP}, \\]\ndove \\(TN\\) sono i veri negativi e \\(FP\\) i falsi positivi. Così, la specificità rappresenta la probabilità che il test risulti negativo in assenza della malattia.\n\nQuesta tabella riassume la terminologia:\n\n\n\n\n\n\n\n\n\n\n\\(T^+\\)\n\\(T^-\\)\nTotale\n\n\n\n\n\\(M^+\\)\n\\(P(T^+ \\cap M^+)\\)  (Sensibilità)\n\\(P(T^- \\cap M^+)\\)  (1 - Sensibilità)\n\\(P(M^+)\\)\n\n\n\\(M^-\\)\n\\(P(T^+ \\cap M^-)\\)  (1 - Specificità)\n\\(P(T^- \\cap M^-)\\)  (Specificità)\n\\(P(M^-)\\)\n\n\nTotale\n\\(P(T^+)\\)\n\\(P(T^-)\\)\n1\n\n\n\ndove \\(T^+\\) e \\(T^-\\) indicano rispettivamente un risultato positivo o negativo del test, mentre \\(M^+\\) e \\(M^-\\) la presenza o assenza effettiva della malattia. In questa tabella, i totali marginali rappresentano:\n\nTotale per \\(M^+\\) e \\(M^-\\) (ultima colonna): La probabilità totale di avere la malattia (\\(P(M^+)\\)) e la probabilità totale di non avere la malattia (\\(P(M^-)\\)), rispettivamente. Questi valori sono calcolati sommando le probabilità all’interno di ciascuna riga.\nTotale per \\(T^+\\) e \\(T^-\\) (ultima riga): La probabilità totale di un risultato positivo al test (\\(P(T^+)\\)) e la probabilità totale di un risultato negativo al test (\\(P(T^-)\\)), rispettivamente. Questi valori sono calcolati sommando le probabilità all’interno di ciascuna colonna.\nTotale generale (angolo in basso a destra): La somma di tutte le probabilità, che per definizione è 1, rappresentando l’intera popolazione o il set di casi considerati.\n\nMediante il teorema di Bayes, possiamo usare queste informazioni per stimare la probabilità post-test di avere o non avere la malattia basandoci sul risultato del test.\nIl valore predittivo positivo (VPP) del test, cioè la probabilità post-test che un individuo sia malato dato un risultato positivo del test, è calcolato come:\n\\[\nP(M^+ \\mid T^+) = \\frac{P(T^+ \\mid M^+) \\cdot P(M^+)}{P(T^+ \\mid M^+) \\cdot P(M^+) + P(T^+ \\mid M^-) \\cdot P(M^-)}.\n\\]\novvero,\n\\[ VPP = \\frac{(\\text{Sensibilità} \\times \\text{Prevalenza})}{(\\text{Sensibilità} \\times \\text{Prevalenza}) + (1 - \\text{Specificità}) \\times (1 - \\text{Prevalenza})} \\]\nAnalogamente, il valore predittivo negativo (VPN), che è la probabilità che un individuo non sia malato dato un risultato negativo del test, si calcola come:\n\\[\nP(M^- \\mid T^-) = \\frac{P(T^- \\mid M^-) \\cdot (1 - P(M^+))}{P(T^- \\mid M^-) \\cdot (1 - P(M^+)) + P(T^- \\mid M^+) \\cdot P(M^+)}.\n\\]\novvero,\n\\[ NPV = \\frac{\\text{Specificità} \\cdot (1 - \\text{Prevalenza})}{\\text{Specificità} \\cdot (1 - \\text{Prevalenza}) + (1 - \\text{Sensibilità}) \\cdot \\text{Prevalenza}}. \\]\n\nEsempio 32.2 Implementiamo le formule del valore predittivo positivo e del valore predittivo negativo del test in Python e usiamo gli stessi dati dell’esercizio precedente.\n\npositive_predictive_value_of_diagnostic_test &lt;- function(sens, spec, prev) {\n  (sens * prev) / (sens * prev + (1 - spec) * (1 - prev))\n}\n\nnegative_predictive_value_of_diagnostic_test &lt;- function(sens, spec, prev) {\n  (spec * (1 - prev)) / (spec * (1 - prev) + (1 - sens) * prev)\n}\n\nInseriamo i dati del problema.\n\nsens = 0.9  # sensibilità\nspec = 0.9  # specificità\nprev = 0.01  # prevalenza\n\nIl valore predittivo del test positivo è:\n\nres_pos &lt;- positive_predictive_value_of_diagnostic_test(sens, spec, prev)\ncat(sprintf(\"P(M+ | T+) = %.3f\\n\", res_pos))\n#&gt; P(M+ | T+) = 0.083\n\nIl valore predittivo del test negativo è:\n\nres_neg &lt;- negative_predictive_value_of_diagnostic_test(sens, spec, prev)\ncat(sprintf(\"P(M- | T-) = %.3f\\n\", res_neg))\n#&gt; P(M- | T-) = 0.999\n\n\n\nEsempio 32.3 La simulazione seguente ha lo scopo di aiutare a visualizzare il teorema di Bayes, utilizzando come esempio gli stessi dati della mammografia che abbiamo analizzato in precedenza.\n\n# Parametri\nsensitivity &lt;- 0.90  # Sensibilità del test (P(T+ | M+))\nspecificity &lt;- 0.90  # Specificità del test (P(T- | M-))\nprev_cancer &lt;- 0.01  # Prevalenza (P(M+))\n\n# Simulazione per una popolazione di 100.000 persone\nN_mammography &lt;- 100000\n\n# Generazione del campione casuale\nset.seed(123)\noutcome_mammography &lt;- sample(\n  c(\"Cancer\", \"Healthy\"), \n  N_mammography, \n  replace = TRUE, \n  prob = c(prev_cancer, 1 - prev_cancer)\n)\n\n# Conteggio delle persone con e senza cancro\nN_C &lt;- sum(outcome_mammography == \"Cancer\")\nN_H &lt;- sum(outcome_mammography == \"Healthy\")\n\n# Simulazione dei risultati del test\ntest_mammography &lt;- character(N_mammography)\ntest_mammography[outcome_mammography == \"Cancer\"] &lt;- sample(\n  c(\"+\", \"-\"), \n  N_C, \n  replace = TRUE, \n  prob = c(sensitivity, 1 - sensitivity)\n)\ntest_mammography[outcome_mammography == \"Healthy\"] &lt;- sample(\n  c(\"-\", \"+\"), \n  N_H, \n  replace = TRUE, \n  prob = c(specificity, 1 - specificity)\n)\n\n# Creazione di un data frame per memorizzare i risultati\ndf_mammography &lt;- tibble(\n  outcome = outcome_mammography,\n  test = test_mammography\n)\n\n# Creazione di una tabella di contingenza\ncontingency_table_mammography &lt;- df_mammography %&gt;%\n  count(outcome, test) %&gt;%\n  pivot_wider(names_from = test, values_from = n, values_fill = 0)\n\ncontingency_table_mammography\n#&gt; # A tibble: 2 × 3\n#&gt;   outcome   `+`   `-`\n#&gt;   &lt;chr&gt;   &lt;int&gt; &lt;int&gt;\n#&gt; 1 Cancer    911   114\n#&gt; 2 Healthy  9897 89078\n\n\n# Calcolo delle probabilità basate sulla tabella di contingenza\n\n# Veri positivi (cancro e risultato positivo al test)\ntrue_positives &lt;- contingency_table_mammography %&gt;%\n  filter(outcome == \"Cancer\") %&gt;%\n  pull(`+`)\n\n# Falsi positivi (sani e risultato positivo al test)\nfalse_positives &lt;- contingency_table_mammography %&gt;%\n  filter(outcome == \"Healthy\") %&gt;%\n  pull(`+`)\n\n# Frequenza totale dei risultati positivi\ntotal_positives &lt;- true_positives + false_positives\n\n# Applicazione del teorema di Bayes sui dati simulati\nP_M_given_T &lt;- true_positives / total_positives\nP_M_given_T\n#&gt; [1] 0.08428942\n\nUtilizzando i dati della simulazione, la probabilità che una persona abbia il cancro al seno dato un risultato positivo al test è molto vicina al valore teorico calcolato in precedenza (circa 8.3%). Se eseguissimo la simulazione nuovamente, il valore ottenuto potrebbe variare leggermente a causa della casualità intrinseca nel campionamento. Tuttavia, ripetendo la simulazione molte volte, i risultati tenderanno a convergere verso il valore teorico, grazie alla legge dei grandi numeri. Questo conferma che il modello teorico è coerente con i risultati simulati.\n\n\nEsempio 32.4 Poniamoci il problema di capire quanto sia affidabile un test per l’HIV. Per fare questo, utilizzeremo le seguenti informazioni (Petersen, 2024):\n\nTasso di base dell’HIV (P(HIV)): 0.3% (0.003). Questa è la probabilità che una persona nella popolazione generale abbia l’HIV.\nSensibilità del test (P(Test+ HIV)): 95% (0.95). Questa è la probabilità che il test risulti positivo se la persona ha effettivamente l’HIV.\nSpecificità del test (P(Test- ¬HIV)): 99.28% (0.9928). Questa è la probabilità che il test risulti negativo se la persona non ha l’HIV.\n\nCalcolo della probabilità di HIV dato un test positivo.\nPer calcolare la probabilità di avere l’HIV dato un test positivo (P(HIV Test+)), utilizziamo il teorema di Bayes:\n\\[\nP(HIV \\mid Test+) = \\frac{P(Test+ \\mid HIV) \\times P(HIV)}{P(Test+)}.\n\\]\nAbbiamo bisogno di calcolare il denominatore, ovvero la probabilità complessiva di ottenere un test positivo (P(Test+)). Questo valore include sia i veri positivi che i falsi positivi:\n\\[\nP(Test+) = P(Test+ \\mid HIV) \\times P(HIV) + P(Test+ \\mid \\neg HIV) \\times P(\\neg HIV),\n\\]\ndove:\n\n\\(P(Test+ \\mid \\neg HIV) = 1 - P(Test- \\mid \\neg HIV) = 1 - 0.9928 = 0.0072\\) (tasso di falsi positivi),\n\\(P(\\neg HIV) = 1 - P(HIV) = 1 - 0.003 = 0.997\\).\n\nCalcoliamo \\(P(Test+)\\):\n\\[\nP(Test+) = (0.95 \\times 0.003) + (0.0072 \\times 0.997) \\approx 0.010027.\n\\]\nOra possiamo calcolare \\(P(HIV \\mid Test+)\\):\n\\[\nP(HIV \\mid Test+) = \\frac{0.95 \\times 0.003}{0.010027} \\approx 0.2844 \\text{ o 28.44\\%}.\n\\]\nQuindi, se il test risulta positivo, la probabilità di avere l’HIV è circa il 28.44%.\nCalcolo della probabilità di un secondo test positivo.\nDopo un primo test positivo, la probabilità di avere l’HIV è aumentata al 28.44%. Ora calcoleremo la probabilità che un secondo test risulti positivo e la conseguente probabilità di avere l’HIV dopo due test positivi consecutivi.\nPer calcolare \\(P(\\text{Secondo Test+})\\), consideriamo due scenari:\n\nLa persona ha effettivamente l’HIV:\n\nProbabilità: \\(P(HIV \\mid Test+) = 0.2844\\).\nProbabilità di un test positivo: \\(P(\\text{Test+} \\mid HIV) = 0.95\\) (sensibilità del test).\n\nLa persona non ha l’HIV:\n\nProbabilità: \\(P(\\neg HIV \\mid Test+) = 1 - P(HIV \\mid Test+) = 0.7156\\).\nProbabilità di un test positivo: \\(P(\\text{Test+} \\mid \\neg HIV) = 0.0072\\) (tasso di falsi positivi).\n\n\nUtilizziamo la formula della probabilità totale:\n\\[\n\\begin{aligned}\nP(\\text{Secondo Test+}) &= P(\\text{Test+} \\mid HIV) \\times P(HIV \\mid Test+) + \\\\\n&\\quad P(\\text{Test+} \\mid \\neg HIV) \\times P(\\neg HIV \\mid Test+).\n\\end{aligned}\n\\]\nSostituendo i valori:\n\\[\nP(\\text{Secondo Test+}) = (0.95 \\times 0.2844) + (0.0072 \\times 0.7156) \\approx 0.2753.\n\\]\nApplichiamo nuovamente il teorema di Bayes per calcolare la probabilità di avere l’HIV dopo un secondo test positivo:\n\\[\nP(HIV \\mid \\text{Secondo Test+}) = \\frac{P(\\text{Secondo Test+} \\mid HIV) \\times P(HIV \\mid Test+)}{P(\\text{Secondo Test+})}.\n\\]\nSostituendo i valori:\n\\[\nP(HIV \\mid \\text{Secondo Test+}) = \\frac{0.95 \\times 0.2844}{0.2753} \\approx 0.981.\n\\]\nDopo un secondo test positivo, la probabilità di avere l’HIV aumenta significativamente, passando dal 28.44% al 98.1%. Questo aumento drastico dimostra l’importanza di:\n\nConsiderare il tasso di base (prevalenza) nella popolazione.\nAggiornare progressivamente le probabilità con nuove evidenze.\nInterpretare i risultati di test diagnostici multipli in modo bayesiano.\n\nL’analisi evidenzia come l’accumulo di evidenze attraverso test ripetuti, in linea con i principi del teorema di Bayes, possa portare a una stima molto più accurata della probabilità di avere una condizione medica, riducendo significativamente l’incertezza iniziale.\n\n\nEsempio 32.5 Consideriamo ora un altro esempio relativo ai test medici e analizziamo i risultati del test antigenico rapido per il virus SARS-CoV-2 alla luce del teorema di Bayes. Questo test può essere eseguito mediante tampone nasale, tampone naso-orofaringeo o campione di saliva. L’Istituto Superiore di Sanità, nel documento pubblicato il 5 novembre 2020, sottolinea che, fino a quel momento, i dati disponibili sui vari test erano quelli forniti dai produttori: la sensibilità varia tra il 70% e l’86%, mentre la specificità si attesta tra il 95% e il 97%.\nPrendiamo un esempio specifico: nella settimana tra il 17 e il 23 marzo 2023, in Italia, il numero di individui positivi al virus è stato stimato essere di 138.599 (fonte: Il Sole 24 Ore). Questo dato corrisponde a una prevalenza di circa lo 0,2% su una popolazione totale di circa 59 milioni di persone.\n\n prev = 138599 / 59000000\n prev\n#&gt; [1] 0.002349136\n\nL’obiettivo è determinare la probabilità di essere effettivamente affetti da Covid-19, dato un risultato positivo al test antigenico rapido, ossia \\(P(M^+ \\mid T^+)\\). Per raggiungere questo scopo, useremo la formula relativa al valore predittivo positivo del test.\n\n# Calcolo della sensibilità e specificità medie\nsens &lt;- (0.7 + 0.86) / 2  # sensibilità\nspec &lt;- (0.95 + 0.97) / 2 # specificità\n\n# Calcolo del valore predittivo positivo\nres_pos &lt;- positive_predictive_value_of_diagnostic_test(sens, spec, prev)\ncat(sprintf(\"P(M+ | T+) = %.3f\\n\", res_pos))\n#&gt; P(M+ | T+) = 0.044\n\nPertanto, se il risultato del tampone è positivo, la probabilità di essere effettivamente affetti da Covid-19 è solo del 4.4%.\nSe la prevalenza fosse 100 volte superiore (cioè, pari al 23.5%), la probabilità di avere il Covid-19, dato un risultato positivo del tampone, aumenterebbe notevolmente e sarebbe pari a circa l’86%.\n\n# Calcolo della prevalenza aumentata di 100 volte\nprev &lt;- 138599 / 59000000 * 100\n\n# Calcolo del valore predittivo positivo\nres_pos &lt;- positive_predictive_value_of_diagnostic_test(sens, spec, prev)\ncat(sprintf(\"P(M+ | T+) = %.3f\\n\", res_pos))\n#&gt; P(M+ | T+) = 0.857\n\nSe il risultato del test fosse negativo, considerando la prevalenza stimata del Covid-19 nella settimana dal 17 al 23 marzo 2023, la probabilità di non essere infetto sarebbe del 99.9%.\n\n# Calcolo della sensibilità, specificità e prevalenza\nsens &lt;- (0.7 + 0.86) / 2  # sensibilità\nspec &lt;- (0.95 + 0.97) / 2  # specificità\nprev &lt;- 138599 / 59000000  # prevalenza\n\n# Calcolo del valore predittivo negativo\nres_neg &lt;- negative_predictive_value_of_diagnostic_test(sens, spec, prev)\ncat(sprintf(\"P(M- | T-) = %.3f\\n\", res_neg))\n#&gt; P(M- | T-) = 0.999\n\nTuttavia, un’esito del genere non dovrebbe sorprenderci, considerando che la prevalenza della malattia è molto bassa; in altre parole, il risultato negativo conferma una situazione già presunta prima di sottoporsi al test. Il vero ostacolo, specialmente nel caso di malattie rare come il Covid-19 in quel periodo specifico, non risiede tanto nell’asserire l’assenza della malattia quanto piuttosto nel confermarne la presenza.\n\n\nEsempio 32.6 Consideriamo le persone in attesa di un figlio. Il teorema di Bayes gioca un ruolo cruciale nell’interpretazione dei test prenatali non invasivi (NIPT), un esame del sangue materno usato per rilevare anomalie cromosomiche fetali. Sebbene il NIPT sia spesso pubblicizzato con un’accuratezza del 99%, la sua affidabilità varia significativamente a seconda della condizione testata e della popolazione esaminata.\nParametri chiave del NIPT:\n\nSensibilità:\n\nSindrome di Down: 99%\nSindrome di Edwards: 97%\nSindrome di Patau: 91%\n\nSpecificità: circa 99.9% per tutte le condizioni citate\nPrevalenza nelle nascite:\n\nSindrome di Down: 1 su 700 (0.14%)\nSindrome di Edwards: 1 su 5,000 (0.02%)\nSindrome di Patau: 1 su 10,000 (0.01%)\n\n\nNonostante l’alta sensibilità e specificità, il VPP può essere sorprendentemente basso, soprattutto nella popolazione generale. Questo implica che molti risultati positivi potrebbero essere falsi positivi, in particolare per le condizioni più rare.\nPer calcolare il VPP, utilizziamo il teorema di Bayes:\n\\[ VPP = \\frac{(\\text{Sensibilità} \\times \\text{Prevalenza})}{(\\text{Sensibilità} \\times \\text{Prevalenza}) + (1 - \\text{Specificità}) \\times (1 - \\text{Prevalenza})} \\]\nApplicando questa formula alla popolazione generale:\n\nSindrome di Down: \\[ VPP = \\frac{(0.99 \\times 0.0014)}{(0.99 \\times 0.0014) + (1 - 0.999) \\times (1 - 0.0014)} \\approx 58\\% \\]\nSindrome di Edwards: \\[ VPP = \\frac{(0.97 \\times 0.0002)}{(0.97 \\times 0.0002) + (1 - 0.999) \\times (1 - 0.0002)} \\approx 16.2\\% \\]\nSindrome di Patau: \\[ VPP = \\frac{(0.91 \\times 0.0001)}{(0.91 \\times 0.0001) + (1 - 0.999) \\times (1 - 0.0001)} \\approx 8.3\\% \\]\n\nQuesti calcoli rivelano VPP molto bassi, specialmente per condizioni molto rare come la sindrome di Patau. Anche in questo caso, dunque, il teorema di Bayes ci mostra che la probabilità che un risultato positivo sia effettivamente corretto dipende non solo dall’accuratezza del test, ma anche dalla prevalenza della condizione nella popolazione testata. Per questo motivo, il NIPT risulta più affidabile nelle categorie ad alto rischio.\nIn conclusione, mentre il NIPT è uno strumento prezioso per lo screening prenatale, è fondamentale interpretare i risultati con cautela, considerando il contesto specifico di ogni paziente e la prevalenza della condizione nella popolazione di riferimento.\n\n\nEsempio 32.7 Il teorema di Bayes non è rilevante solo in medicina. In ambito legale è presente un fenomeno noto come la Fallacia del Procuratore. La “fallacia del procuratore” è un errore logico che si verifica quando si confonde la probabilità di un evento dato un certo risultato con la probabilità di quel risultato dato l’evento. In ambito legale, si tratta spesso di confondere la probabilità di ottenere un risultato di un test (ad esempio, una corrispondenza del DNA) se una persona è innocente, con la probabilità che una persona sia innocente dato che il test ha mostrato una corrispondenza.\nSupponiamo di avere i seguenti parametri per un test del DNA:\n\nSensibilità: 99% (probabilità di identificare correttamente il colpevole).\nSpecificità: 99.99997% (probabilità di identificare correttamente un innocente).\nPrevalenza: 1 su 65 milioni (probabilità a priori che una persona qualsiasi sia il colpevole, data una popolazione di 65 milioni).\n\nImmaginiamo che ci sia stato un crimine e che un campione di DNA sia stato trovato sulla scena del crimine. Il campione è confrontato con il DNA di una persona nel database.\nSvolgiamo i calcoli:\n\nProbabilità a Priori (Prevalenza):\n\nLa prevalenza \\(P(C)\\) che una persona casuale sia il colpevole è \\(\\frac{1}{65.000.000}\\).\n\nSensibilità e Specificità:\n\nSensibilità \\(P(T+|C) = 0.99\\).\nSpecificità \\(P(T-|I) = 0.9999997\\).\n\nProbabilità del Test Positivo:\n\nProbabilità di ottenere un test positivo \\(P(T+)\\) è la somma della probabilità di ottenere un positivo dai veri colpevoli e dai falsi positivi:\n\n\n\\[ P(T+) = P(T+|C) \\cdot P(C) + P(T+|I) \\cdot P(I), \\]\n\ndove \\(P(T+|I)\\) è \\(1 - \\text{Specificità}\\) e \\(P(I)\\) è la probabilità di essere innocente (\\(1 - P(C)\\)).\n\n\\[ P(T+) = 0.99 \\cdot \\frac{1}{65.000.000} + (1 - 0.9999997) \\cdot \\frac{64.999.999}{65.000.000} \\]\n\\[ P(T+) \\approx 0.99 \\cdot 1.5385 \\times 10^{-8} + 0.0000003 \\cdot 0.9999999 \\]\n\\[ P(T+) \\approx 1.5231 \\times 10^{-8} + 2.9999997 \\times 10^{-7} \\]\n\\[ P(T+) \\approx 3.1523 \\times 10^{-7} \\]\n\nProbabilità Condizionale che il Sospetto sia Colpevole Dato un Test Positivo:\n\nUtilizzando il teorema di Bayes:\n\n\n\\[ P(C|T+) = \\frac{P(T+|C) \\cdot P(C)}{P(T+)} \\]\n\\[ P(C|T+) = \\frac{0.99 \\cdot \\frac{1}{65.000.000}}{3.1523 \\times 10^{-7}} \\]\n\\[ P(C|T+) = \\frac{0.99 \\times 1.5385 \\times 10^{-8}}{3.1523 \\times 10^{-7}} \\]\n\\[ P(C|T+) \\approx 0.0483 \\]\nQuindi, la probabilità che il sospetto sia effettivamente il colpevole, dato che il test del DNA è positivo, è circa 4.83%, nonostante l’alta specificità del test.\nIn sintesi, quando si afferma che c’è solo una probabilità su 3 milioni che il sospetto sia innocente (ovvero la specificità), si commette la fallacia del procuratore. In realtà, la probabilità che il sospetto sia colpevole, data una corrispondenza del DNA, è molto inferiore, come dimostrato nell’esempio numerico (circa 4.83%).\nQuesta fallacia può portare a errori giudiziari perché non si considera la bassa prevalenza del colpevole nella popolazione generale e si confonde la specificità del test con la probabilità condizionale di colpevolezza. In altre parole, non si riconosce che le due domande ‘Quanto è probabile che il DNA di una persona corrisponda al campione, se è innocente?’ e ‘Quanto è probabile che qualcuno sia innocente, dato che il suo DNA corrisponde al campione?’ non sono equivalenti. È come confondere ‘Quanto è probabile che un determinato essere umano sia il papa?’ con ‘Quanto è probabile che il papa sia un essere umano?’.\n\n\nEsempio 32.8 Due dadi equi vengono lanciati e ti viene detto che la somma dei loro punteggi è 9. Qual è la distribuzione a posteriori dei punteggi di ciascun dado? (Questo esempio è tratto da Taylan Cemgil ed è discusso da Barber (2012)).\nIndichiamo il punteggio del dado \\(a\\) con \\(s_a\\), dove \\(\\text{dom}(s_a) = \\{1,2,3,4,5,6\\}\\), e in modo simile per \\(s_b\\). Le tre variabili coinvolte sono quindi \\(s_a\\), \\(s_b\\) e la somma totale, \\(t = s_a + s_b\\). Un modello per queste tre variabili assume la forma:\n\\[\np(t, s_a, s_b) = p(t | s_a, s_b) p(s_a, s_b),\n\\]\ndove:\n\nLikelihood: \\(p(t | s_a, s_b)\\) rappresenta la probabilità che la somma dei dadi sia \\(t\\) dato \\(s_a\\) e \\(s_b\\).\nPrior: \\(p(s_a, s_b)\\) è la probabilità congiunta dei punteggi \\(s_a\\) e \\(s_b\\) senza conoscere la somma \\(t\\).\n\nAssumiamo che i dadi siano equi e indipendenti, quindi la probabilità congiunta \\(p(s_a, s_b)\\) è il prodotto delle distribuzioni uniformi di \\(s_a\\) e \\(s_b\\):\n\\[\np(s_a, s_b) = p(s_a) p(s_b) = \\frac{1}{6} \\times \\frac{1}{6} = \\frac{1}{36}.\n\\]\nIl termine di likelihood è dato da:\n\\[\np(t | s_a, s_b) = I[t = s_a + s_b],\n\\]\ndove \\(I[A]\\) è la funzione indicatrice che vale 1 se la condizione \\(A\\) è vera e 0 altrimenti.\nAbbiamo che \\(p(t = 9 | s_a, s_b)\\) è 1 se la somma di \\(s_a\\) e \\(s_b\\) è 9, altrimenti è 0. Quindi la likelihood è data dalla seguente tabella:\n\n\n\n\\(s_b\\) \\\n1\n2\n3\n4\n5\n6\n\n\n\n\n\\(s_a\\)\n\n\n\n\n\n\n\n\n1\n0\n0\n0\n0\n0\n0\n\n\n2\n0\n0\n0\n0\n0\n0\n\n\n3\n0\n0\n0\n0\n0\n1\n\n\n4\n0\n0\n0\n0\n1\n0\n\n\n5\n0\n0\n0\n1\n0\n0\n\n\n6\n0\n0\n1\n0\n0\n0\n\n\n\nLe combinazioni possibili sono quindi \\((3,6), (4,5), (5,4), (6,3)\\).\nLa distribuzione a posteriori dei punteggi dei dadi, data la somma \\(t = 9\\), si calcola con:\n\\[\np(s_a, s_b | t = 9) = \\frac{p(t = 9 | s_a, s_b) p(s_a) p(s_b)}{p(t = 9)}.\n\\]\nIl denominatore \\(p(t = 9)\\) è la somma dei termini non nulli del numeratore:\n\\[\np(t = 9) = \\sum_{s_a, s_b} p(t = 9 | s_a, s_b) p(s_a) p(s_b) = 4 \\times \\frac{1}{36} = \\frac{1}{9}.\n\\]\nQuindi, la distribuzione a posteriori è:\n\n\n\n\\(s_b\\) \\\n1\n2\n3\n4\n5\n6\n\n\n\n\n\\(s_a\\)\n\n\n\n\n\n\n\n\n1\n0\n0\n0\n0\n0\n0\n\n\n2\n0\n0\n0\n0\n0\n0\n\n\n3\n0\n0\n0\n0\n0\n1/4\n\n\n4\n0\n0\n0\n0\n1/4\n0\n\n\n5\n0\n0\n0\n1/4\n0\n0\n\n\n6\n0\n0\n1/4\n0\n0\n0\n\n\n\nIn questo caso, le uniche combinazioni con probabilità non nulla sono quelle in cui la somma è 9, e ciascuna di queste ha probabilità \\(1/4\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_bayes_theorem.html#probabilità-inversa",
    "href": "chapters/probability/07_bayes_theorem.html#probabilità-inversa",
    "title": "31  Il teorema di Bayes",
    "section": "32.3 Probabilità Inversa",
    "text": "32.3 Probabilità Inversa\nGli esempi precedenti evidenziano la differenza tra due domande fondamentali. La prima è: “Qual è la probabilità di osservare un determinato risultato, supponendo che una certa ipotesi sia vera?” La seconda, invece, è: “Qual è la probabilità che un’ipotesi sia vera, dato il risultato osservato?”\nUn esempio che risponde alla prima domanda potrebbe essere questo: supponiamo che la probabilità di ottenere testa nel lancio di una moneta sia 0,5 (ipotesi). Qual è la probabilità di ottenere 0 teste in cinque lanci?\nPer la seconda domanda, un esempio potrebbe essere: supponiamo di aver ottenuto 0 teste in 5 lanci di una moneta (evidenza). Qual è la probabilità che la moneta sia effettivamente bilanciata, alla luce di questa osservazione?\nPer molto tempo, lo studio della probabilità si è concentrato principalmente sulla prima domanda. Tuttavia, nel XVIII secolo, il reverendo Thomas Bayes iniziò a riflettere sulla seconda domanda, dando origine a quello che oggi chiamiamo probabilità inversa.\nQuesto approccio ha generato numerose controversie nella storia della statistica, in gran parte perché influenza molti ambiti. Ad esempio, possiamo chiederci: quanto è probabile che un’ipotesi scientifica sia vera, dato il risultato di un esperimento? Per stimare questa probabilità — un compito che molti scienziati ritengono essenziale per la statistica moderna — è necessario fare uso del teorema di Bayes e delle probabilità a priori.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_bayes_theorem.html#riflessioni-conclusive",
    "href": "chapters/probability/07_bayes_theorem.html#riflessioni-conclusive",
    "title": "31  Il teorema di Bayes",
    "section": "32.4 Riflessioni Conclusive",
    "text": "32.4 Riflessioni Conclusive\nIn questo capitolo abbiamo esplorato vari esempi, principalmente nel campo medico e forense, per illustrare come il teorema di Bayes permetta di combinare le informazioni derivate dalle osservazioni con le conoscenze precedenti (priori), aggiornando così il nostro grado di convinzione rispetto a un’ipotesi. Il teorema di Bayes fornisce un meccanismo razionale, noto come “aggiornamento bayesiano”, che ci consente di ricalibrare le nostre convinzioni iniziali alla luce di nuove evidenze.\nUna lezione fondamentale che il teorema di Bayes ci insegna, sia nella ricerca scientifica che nella vita quotidiana, è che spesso non ci interessa tanto conoscere la probabilità che qualcosa accada assumendo vera un’ipotesi, quanto piuttosto la probabilità che un’ipotesi sia vera, dato che abbiamo osservato una certa evidenza. In altre parole, la forza del teorema di Bayes sta nella sua capacità di affrontare direttamente il problema inverso, cioè come dedurre la verità di un’ipotesi a partire dalle osservazioni.\nIl framework bayesiano per l’inferenza probabilistica offre un approccio generale per comprendere come i problemi di induzione possano essere risolti in linea di principio e, forse, anche come possano essere affrontati dalla mente umana.\nIn questo capitolo ci siamo concentrati sull’applicazione del teorema di Bayes utilizzando probabilità puntuali. Tuttavia, il teorema esprime pienamente il suo potenziale quando sia l’evidenza che i gradi di certezza a priori delle ipotesi sono rappresentati attraverso distribuzioni di probabilità continue. Questo sarà l’argomento centrale nel ?sec-bayes-workflow, dove approfondiremo il flusso di lavoro bayesiano e l’uso di distribuzioni continue nell’aggiornamento bayesiano.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_bayes_theorem.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/07_bayes_theorem.html#informazioni-sullambiente-di-sviluppo",
    "title": "31  Il teorema di Bayes",
    "section": "32.5 Informazioni sull’Ambiente di Sviluppo",
    "text": "32.5 Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] latex2exp_0.9.6   mice_3.16.0       MASS_7.3-61       viridis_0.6.5    \n#&gt;  [5] viridisLite_0.4.2 ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3    \n#&gt;  [9] patchwork_1.3.0   bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0     \n#&gt; [13] markdown_1.13     knitr_1.49        lubridate_1.9.3   forcats_1.0.0    \n#&gt; [17] stringr_1.5.1     dplyr_1.1.4       purrr_1.0.2       readr_2.1.5      \n#&gt; [21] tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0  \n#&gt; [25] rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1  farver_2.1.2      fastmap_1.2.0     pacman_0.5.1     \n#&gt;  [5] promises_1.3.1    rpart_4.1.23      digest_0.6.37     timechange_0.3.0 \n#&gt;  [9] mime_0.12         lifecycle_1.0.4   survival_3.7-0    magrittr_2.0.3   \n#&gt; [13] compiler_4.4.2    rlang_1.1.4       tools_4.4.2       utf8_1.2.4       \n#&gt; [17] yaml_2.3.10       ggsignif_0.6.4    labeling_0.4.3    htmlwidgets_1.6.4\n#&gt; [21] mnormt_2.1.1      abind_1.4-8       miniUI_0.1.1.1    withr_3.0.2      \n#&gt; [25] nnet_7.3-19       grid_4.4.2        fansi_1.0.6       jomo_2.7-6       \n#&gt; [29] xtable_1.8-4      colorspace_2.1-1  iterators_1.0.14  cli_3.6.3        \n#&gt; [33] rmarkdown_2.29    generics_0.1.3    tzdb_0.4.0        minqa_1.2.8      \n#&gt; [37] splines_4.4.2     parallel_4.4.2    vctrs_0.6.5       boot_1.3-31      \n#&gt; [41] glmnet_4.1-8      Matrix_1.7-1      jsonlite_1.8.9    carData_3.0-5    \n#&gt; [45] car_3.1-3         hms_1.1.3         mitml_0.4-5       rstatix_0.7.2    \n#&gt; [49] Formula_1.2-5     foreach_1.5.2     glue_1.8.0        pan_1.9          \n#&gt; [53] nloptr_2.1.1      codetools_0.2-20  stringi_1.8.4     gtable_0.3.6     \n#&gt; [57] shape_1.4.6.1     later_1.4.0       lme4_1.1-35.5     munsell_0.5.1    \n#&gt; [61] pillar_1.9.0      htmltools_0.5.8.1 R6_2.5.1          rprojroot_2.0.4  \n#&gt; [65] evaluate_1.0.1    shiny_1.9.1       lattice_0.22-6    backports_1.5.0  \n#&gt; [69] broom_1.0.7       httpuv_1.6.15     Rcpp_1.0.13-1     nlme_3.1-166     \n#&gt; [73] xfun_0.49         pkgconfig_2.0.3",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_bayes_theorem.html#bibliografia",
    "href": "chapters/probability/07_bayes_theorem.html#bibliografia",
    "title": "31  Il teorema di Bayes",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBarber, D. (2012). Bayesian reasoning and machine learning. Cambridge University Press.\n\n\nChivers, T. (2024). Everything is Predictable: How Bayesian Statistics Explain Our World. Simon; Schuster.\n\n\nGriffiths, T. L., Chater, N., & Tenenbaum, J. B. (2024). Bayesian models of cognition: reverse engineering the mind. MIT Press.\n\n\nPetersen, I. T. (2024). Principles of psychological assessment: With applied examples in R. CRC Press.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html",
    "href": "chapters/probability/08_sampling_distr.html",
    "title": "32  Stime, stimatori e parametri",
    "section": "",
    "text": "32.1 Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nPreparazione del Notebook\nIn questo capitolo, approfondiremo il concetto di distribuzione campionaria che costituisce uno dei pilastri dell’inferenza statistica frequentista. La distribuzione campionaria ci permette di comprendere come le stime dei parametri della popolazione, come la media o la varianza, cambiano da campione a campione. In particolare, la distribuzione campionaria ci consente di stabilire delle proprietà probabilistiche delle stime campionarie, come ad esempio la loro media e la loro varianza. Queste proprietà verranno utilizzate per costruire gli strumenti fondamentali dell’inferenza frequentista: gli intervalli di fiducia e i test di ipotesi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#popolazione-e-campioni",
    "href": "chapters/probability/08_sampling_distr.html#popolazione-e-campioni",
    "title": "32  Stime, stimatori e parametri",
    "section": "32.2 Popolazione e campioni",
    "text": "32.2 Popolazione e campioni\nNell’analisi dei dati, l’obiettivo spesso è comprendere una quantità specifica a livello di popolazione, ma in genere abbiamo accesso solo a un campione di osservazioni. La quantità sconosciuta che vogliamo determinare viene chiamata parametro. Quando usiamo i dati del campione per calcolare una misura di questo parametro, la misura ottenuta è chiamata stima, e la formula che utilizziamo per ottenerla è conosciuta come stimatore. In termini formali, uno stimatore è una funzione dei dati osservati, utilizzata per fornire un’approssimazione del parametro di interesse.\nIn pratica, quando analizziamo un campione di dati, il nostro obiettivo è inferire determinate proprietà della popolazione intera dalla quale il campione è stato tratto. Il parametro è l’indicatore numerico di queste proprietà, ma poiché spesso non possiamo calcolarlo direttamente sulla popolazione, ricorriamo alle osservazioni del campione per stimarlo. La stima, quindi, rappresenta il valore approssimato del parametro ottenuto dal campione, mentre lo stimatore è la regola o la formula matematica che usiamo per arrivare a questa approssimazione.\nÈ importante riconoscere che le stime possono non corrispondere esattamente ai parametri che vogliamo comprendere. In altre parole, le stime sono solo approssimazioni del parametro a causa della natura aleatoria del campionamento.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#la-relazione-tra-stime-e-parametri",
    "href": "chapters/probability/08_sampling_distr.html#la-relazione-tra-stime-e-parametri",
    "title": "32  Stime, stimatori e parametri",
    "section": "32.3 La relazione tra stime e parametri",
    "text": "32.3 La relazione tra stime e parametri\nIn questo capitolo, ci concentreremo sulla relazione tra le stime ottenute dai campioni e i parametri reali della popolazione, esplorando in particolare la connessione tra la media di un campione e la media della popolazione, denotata con \\(\\mu\\). Il nostro obiettivo è capire e caratterizzare l’incertezza che deriva dalla natura aleatoria delle stime, e per farlo, adotteremo l’approccio frequentista, facendo uso di un importante strumento statistico chiamato distribuzione campionaria.\n\n32.3.1 Distribuzione campionaria\nPer illustrare il concetto di distribuzione campionaria, possiamo iniziare considerando un caso semplice e specifico: una popolazione finita di dimensioni ridotte. Sebbene stiamo esaminando un caso particolare, è fondamentale notare che le proprietà e i principi che analizzeremo in questo contesto sono perfettamente applicabili a popolazioni di qualsiasi dimensione.\nLa distribuzione campionaria ci dà una visione della variazione che potremmo aspettarci nelle stime derivate da diversi campioni estratti dalla stessa popolazione. Ogni volta che preleviamo un campione, otteniamo una stima diversa per il parametro di interesse (come la media). La distribuzione campionaria ci mostra come queste stime sono distribuite e ci aiuta a comprendere quanto siano affidabili.\nIn termini pratici, se vogliamo calcolare la media della popolazione, non possiamo farlo direttamente (a meno di non avere accesso all’intera popolazione). Invece, possiamo estrarre un campione casuale e calcolare la media del campione come stima di \\(\\mu\\). Tuttavia, un altro campione fornirà una stima leggermente diversa. La distribuzione campionaria ci aiuta a capire quanto queste stime varino da campione a campione e ci fornisce un quadro completo dell’incertezza legata al processo di stima.\nNella simulazione seguente, ipotizziamo la seguente popolazione:\n\nx &lt;- c(2, 4.5, 5, 5.5)\nx\n#&gt; [1] 2.0 4.5 5.0 5.5\n\nL’istogramma seguente descrive la distribuzione di frequenza della popolazione.\n\nggplot(data.frame(x = x), aes(x)) +\n  geom_histogram(\n    bins = 5,\n    aes(y = ..density..)\n  )\n#&gt; Warning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `after_stat(density)` instead.\n\n\n\n\n\n\n\n\nStampiamo gli intervalli utilizzati per l’istogramma.\n\n# Calcolo degli intervalli e delle frequenze per l'istogramma\nhist_data &lt;- hist(x, breaks = 5, plot = FALSE)\n\n# Stampa degli intervalli e delle frequenze relative\ncat(\"Intervalli utilizzati per l'istogramma:\", hist_data$breaks, \"\\n\")\n#&gt; Intervalli utilizzati per l'istogramma: 2 2.5 3 3.5 4 4.5 5 5.5\ncat(\"Frequenze relative utilizzate per l'istogramma:\", hist_data$density, \"\\n\")\n#&gt; Frequenze relative utilizzate per l'istogramma: 0.5 0 0 0 0.5 0.5 0.5\n\n# Calcolo delle frequenze assolute\nhist_data_abs &lt;- hist(x, breaks = 5, plot = FALSE)\n\n# Stampa delle frequenze assolute\ncat(\"Frequenze assolute utilizzate per l'istogramma:\", hist_data_abs$counts, \"\\n\")\n#&gt; Frequenze assolute utilizzate per l'istogramma: 1 0 0 0 1 1 1\n\nCalcoliamo la media e la varianza della popolazione.\n\n# Calcolo della media e della varianza della popolazione\nmean_x &lt;- mean(x)\nvar_x &lt;- var(x) * ((length(x) - 1) / length(x)) # Varianza popolazione\nc(mean_x, var_x)\n#&gt; [1] 4.2500 1.8125\n\nSupponiamo ora di voler considerare l’estrazione di tutti i possibili campioni di dimensione (n = 2) da una popolazione rappresentata dal vettore x. Per fare ciò, possiamo fare uso della funzione expand.grid in R, che permette di generare tutte le combinazioni possibili di valori con ripetizione.\nUtilizzando expand.grid, otteniamo un data.frame in cui ogni riga rappresenta una coppia di valori possibili. La struttura risultante contiene tutte le combinazioni in cui ogni valore nel vettore x può essere abbinato a se stesso o a un altro valore nel vettore. Convertendo il risultato in una matrice, otteniamo una rappresentazione simile a un array NumPy, con 16 righe e 2 colonne, che rappresenta tutte le possibili coppie formate dai valori del vettore x.\nQuesto approccio è coerente con un concetto matematico fondamentale: se stiamo scegliendo 2 elementi da un insieme di 4, e ogni elemento può essere scelto più di una volta (ossia con ripetizione), il numero totale di possibili combinazioni sarà (4^2 = 16). Questo si spiega dal fatto che ci sono 4 scelte per il primo elemento e 4 scelte per il secondo elemento, risultando in un totale di (4 = 16) possibili coppie.\n\n# Creare tutte le combinazioni possibili di valori\nsamples &lt;- expand.grid(x, x)\nsamples &lt;- as.matrix(samples)  # Convertire in matrice\nprint(samples)\n#&gt;       Var1 Var2\n#&gt;  [1,]  2.0  2.0\n#&gt;  [2,]  4.5  2.0\n#&gt;  [3,]  5.0  2.0\n#&gt;  [4,]  5.5  2.0\n#&gt;  [5,]  2.0  4.5\n#&gt;  [6,]  4.5  4.5\n#&gt;  [7,]  5.0  4.5\n#&gt;  [8,]  5.5  4.5\n#&gt;  [9,]  2.0  5.0\n#&gt; [10,]  4.5  5.0\n#&gt; [11,]  5.0  5.0\n#&gt; [12,]  5.5  5.0\n#&gt; [13,]  2.0  5.5\n#&gt; [14,]  4.5  5.5\n#&gt; [15,]  5.0  5.5\n#&gt; [16,]  5.5  5.5\n\nLa matrice samples è bidimensionale, dove ogni riga rappresenta una coppia di valori. Per calcolare la media di ogni campione di ampiezza (n = 2), possiamo utilizzare la funzione rowMeans, che calcola la media per ogni riga di una matrice. In questo modo, otteniamo un vettore contenente la media di ciascuna coppia di valori. Questo insieme di valori costituisce la distribuzione campionaria delle medie dei campioni di ampiezza (n = 2) che possono essere estratti dalla popolazione x.\n\n# Calcolare la media di ciascun campione\nmeans &lt;- rowMeans(samples)\nprint(means)\n#&gt;  [1] 2.00 3.25 3.50 3.75 3.25 4.50 4.75 5.00 3.50 4.75 5.00 5.25 3.75 5.00\n#&gt; [15] 5.25 5.50\n\nLa funzione rowMeans(samples) calcola la media per ogni riga della matrice samples. Una rappresentazione grafica della distribuzione campionaria dei campioni di ampiezza (n = 2) che possono essere estratti dalla popolazione x è fornita qui sotto.\n\n# Istogramma delle medie campionarie\nggplot(data.frame(means), aes(x = means)) +\n  geom_histogram(\n    bins = 5,\n    aes(y = ..density..)\n)\n\n\n\n\n\n\n\n\nMostriamo qui nuovamente la lista di tutti i possibili campioni di ampiezza 2 insieme alla media di ciascun campione.\n\n# Creare un data frame con i campioni e le loro medie\ndf &lt;- data.frame(\n  Samples = apply(samples, 1, paste, collapse = \", \"),\n  x_bar = rowMeans(samples)\n)\nprint(df)\n#&gt;     Samples x_bar\n#&gt; 1      2, 2  2.00\n#&gt; 2    4.5, 2  3.25\n#&gt; 3      5, 2  3.50\n#&gt; 4    5.5, 2  3.75\n#&gt; 5    2, 4.5  3.25\n#&gt; 6  4.5, 4.5  4.50\n#&gt; 7    5, 4.5  4.75\n#&gt; 8  5.5, 4.5  5.00\n#&gt; 9      2, 5  3.50\n#&gt; 10   4.5, 5  4.75\n#&gt; 11     5, 5  5.00\n#&gt; 12   5.5, 5  5.25\n#&gt; 13   2, 5.5  3.75\n#&gt; 14 4.5, 5.5  5.00\n#&gt; 15   5, 5.5  5.25\n#&gt; 16 5.5, 5.5  5.50\n\nProcediamo ora al calcolo della media della distribuzione campionaria delle medie di campioni di ampiezza (n = 2) che possono essere estratti dalla popolazione x.\n\n# Calcolare la media delle medie campionarie\nmean_of_means &lt;- mean(means)\nprint(mean_of_means)\n#&gt; [1] 4.25\n\n\n\n32.3.2 Valore atteso della media campionaria\nSupponiamo che $ X_1, X_2, , X_n $ siano variabili aleatorie iid con valore atteso $ $ e varianza $ ^2 $. Vogliamo trovare il valore atteso della media campionaria:\n\\[\n\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i\n\\]\nEcco la dimostrazione:\n\\[\n\\begin{align*}\n\\mathbb{E}(\\bar{X}) & = \\mathbb{E}\\left(\\frac{1}{n} \\sum_{i=1}^n X_i\\right) \\\\\n& = \\frac{1}{n} \\mathbb{E}\\left(\\sum_{i=1}^n X_i\\right) \\\\\n& = \\frac{1}{n} \\sum_{i=1}^n \\mathbb{E}(X_i) \\\\\n& = \\frac{1}{n} \\sum_{i=1}^n \\mu \\\\\n& = \\frac{1}{n} \\cdot n \\cdot \\mu \\\\\n& = \\mu\n\\end{align*}\n\\]\nQuindi, il valore atteso della media campionaria di $ n $ variabili iid è uguale al valore atteso di ciascuna variabile singola, che in questo caso è $ $.\nVerifichiamo che ciò sia vero nel nostro caso specifico.\n\nmean(x)\n#&gt; [1] 4.25\nmean(means)\n#&gt; [1] 4.25\n\n\n\n32.3.3 Varianza della media campionaria\nDato che le variabili \\(X_1, X_2, \\ldots, X_n\\) sono indipendenti ed identicamente distribuite (iid) con valore atteso \\(\\mu\\) e varianza \\(\\sigma^2\\), possiamo calcolare la varianza della media campionaria \\(\\bar{X}\\) come segue:\n\\[\n\\begin{align*}\n\\text{Var}(\\bar{X}) & = \\text{Var}\\left(\\frac{1}{n} \\sum_{i=1}^n X_i\\right) \\\\\n& = \\frac{1}{n^2} \\text{Var}\\left(\\sum_{i=1}^n X_i\\right) \\\\\n& = \\frac{1}{n^2} \\sum_{i=1}^n \\text{Var}(X_i) \\quad \\text{(dato che le $X_i$ sono indipendenti, i termini incrociati si annullano)} \\\\\n& = \\frac{1}{n^2} \\sum_{i=1}^n \\sigma^2 \\\\\n& = \\frac{1}{n^2} \\cdot n \\cdot \\sigma^2 \\\\\n& = \\frac{\\sigma^2}{n}\n\\end{align*}\n\\]\nQuindi, la varianza della media campionaria di \\(n\\) variabili iid è uguale alla varianza di ciascuna variabile singola divisa per \\(n\\), che in questo caso è \\(\\sigma^2/n\\).\nPer l’esempio in discussione, il valore della varianza delle medie dei campioni è dunque pari a\n\nvar(x) * ((length(x) - 1)/ length(x)) / 2\n#&gt; [1] 0.90625\n\nLo stesso risultato si ottiene facendo la media delle 16 medie che abbiamo trovato in precedenza.\n\nvar(means) * ((length(means) - 1)/ length(means))\n#&gt; [1] 0.90625\n\nConsideriamo ora un particolare campione. Per esempio\n\nobserved_sample = c(5, 5.5)\nprint(observed_sample)\n#&gt; [1] 5.0 5.5\n\nTroviamo la media del campione:\n\nsample_mean = mean(observed_sample)\nprint(sample_mean)\n#&gt; [1] 5.25\n\nLa media del campione è diversa dalla media della popolazione (\\(\\mu\\) = 4.25).\nTroviamo la deviazione standard del campione:\n\nsample_sd = sqrt(var(observed_sample)/2)\nprint(sample_sd)\n#&gt; [1] 0.25\n\nLa deviazione standard del campione è diversa dalla deviazione standard della popolazione:\n\nsqrt(var(x) * (length(x) - 1)/length(x))\n#&gt; [1] 1.346291\n\nIn conclusione, possiamo sottolineare due risultati centrali che emergono dall’analisi delle medie campionarie:\n\nMedia delle medie campionarie e media della popolazione: La media della distribuzione delle medie campionarie è identica alla media della popolazione. In termini matematici, questo significa che il valore atteso della media dei campioni (con ripetizione) da una popolazione (finita o infinita) con media $ $ è:\n\n\\[\n   \\mathbb{E}(\\bar{X}_n) = \\mu.\n\\]\n\nVarianza delle medie campionarie e varianza della popolazione: La varianza della distribuzione delle medie campionarie è inferiore alla varianza della popolazione e, precisamente, è pari alla varianza della popolazione divisa per la dimensione del campione:\n\n\\[\n   \\mathbb{V}(\\bar{X}_n) = \\frac{\\sigma^2}{n}.\n\\]\nQuesti risultati, che abbiamo verificato empiricamente attraverso la simulazione, ci offrono una comprensione profonda del comportamento delle medie campionarie.\nInoltre, è importante notare che il comportamento della distribuzione delle medie campionarie dipende dalla forma della distribuzione della popolazione stessa:\n\nSe la popolazione segue una distribuzione normale, allora la distribuzione delle medie dei campioni sarà anch’essa normale.\nSe la popolazione non segue una distribuzione normale, il teorema del limite centrale entra in gioco, assicurando che, man mano che le dimensioni del campione aumentano, la distribuzione delle medie dei campioni converga a una distribuzione normale.\n\nQuesti principi sono fondamentali in statistica e forniscono la base per molte tecniche di inferenza e modellazione.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#errore-standard-e-rappresentazione-dellincertezza-inferenziale",
    "href": "chapters/probability/08_sampling_distr.html#errore-standard-e-rappresentazione-dellincertezza-inferenziale",
    "title": "32  Stime, stimatori e parametri",
    "section": "32.4 Errore standard e rappresentazione dell’incertezza inferenziale",
    "text": "32.4 Errore standard e rappresentazione dell’incertezza inferenziale\nNella statistica inferenziale, l’errore standard è una misura frequentemente utilizzata per rappresentare l’incertezza legata a un parametro stimato, conosciuta anche come incertezza inferenziale. L’errore standard quantifica quanto possa variare la stima di una statistica da un campione all’altro; un errore standard minore indica una stima più precisa, mentre uno maggiore implica maggiore incertezza. Spesso, le rappresentazioni grafiche includono gli errori standard nella forma di “media più o meno uno (o due) errori standard.” Questa espressione fornisce una gamma di valori entro cui è plausibile che ricada il valore vero del parametro della popolazione.\nL’uso dell’errore standard nei grafici non è soltanto una convenzione; esso è uno strumento per quantificare e visualizzare l’incertezza inferenziale. Contribuisce alla comprensione dell’affidabilità delle stime ottenute dai dati campionari, permettendo di valutare quanto le stime possano variare se si prendesse un altro campione dalla stessa popolazione. Tuttavia, è importante notare che questo utilizzo dell’errore standard può essere problematico (Ward & Mann, 2022).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#legge-dei-grandi-numeri",
    "href": "chapters/probability/08_sampling_distr.html#legge-dei-grandi-numeri",
    "title": "32  Stime, stimatori e parametri",
    "section": "32.5 Legge dei Grandi Numeri",
    "text": "32.5 Legge dei Grandi Numeri\nLa Legge dei Grandi Numeri (LLN) è un principio fondamentale della teoria delle probabilità che stabilisce come, incrementando il numero \\(n\\) di osservazioni, la media campionaria \\(\\bar{X}_n\\) tenda asintoticamente alla media teorica \\(\\mu\\). La LLN si articola in due varianti: la versione “forte” e quella “debole”, le quali differiscono per il tipo di convergenza verso la media attesa.\n\n32.5.1 Versione Forte della Legge dei Grandi Numeri (SLLN)\nLa SLLN afferma che la media campionaria $ {X}_n $ converge quasi certamente alla media teorica \\(\\mu\\), ovvero la convergenza avviene con probabilità 1. Questo implica che, per quasi ogni possibile sequenza di eventi nell’insieme campionario \\(S\\), \\(\\bar{X}_n(s)\\) tende a \\(\\mu\\), ad eccezione di un insieme di eventi \\(B_0\\) la cui probabilità è zero. In termini tecnici, si dice che \\(\\bar{X}_n\\) converge a \\(\\mu\\) “quasi certamente”.\n\n\n32.5.2 Versione Debole della Legge dei Grandi Numeri (WLLN)\nLa WLLN afferma che, per ogni \\(\\epsilon &gt; 0\\), la probabilità che la media campionaria \\(\\bar{X}_n\\) si discosti da \\(\\mu\\) di una quantità maggiore di \\(\\epsilon\\) tende a zero all’aumentare di \\(n\\). Questo fenomeno è definito come convergenza in probabilità verso la media teorica \\(\\mu\\).\n\n\n32.5.3 Implicazioni e Applicazioni\nLa Legge dei Grandi Numeri riveste un ruolo cruciale nel campo delle simulazioni, della statistica e, più in generale, nelle discipline scientifiche. La generazione di dati attraverso numerose repliche indipendenti di un esperimento, sia in ambito simulativo che empirico, implica l’utilizzo della media campionaria come stima affidabile della media teorica della variabile di interesse. In pratica, la LLN fornisce una base teorica per l’affidabilità delle stime medie ottenute da grandi campioni di dati, sottolineando come, a fronte di un numero elevato di osservazioni, le fluttuazioni casuali tendano ad annullarsi, convergendo verso un valore stabile e prevedibile.\n\nEsempio 32.1 Siano \\(X_1, X_2, \\ldots\\) variabili aleatorie indipendenti e identicamente distribuite secondo una distribuzione di Bernoulli con parametro \\(1/2\\). Interpretando gli \\(X_j\\) come indicatori di “Testa” in una sequenza di lanci di una moneta equa, \\(\\bar{X}_n\\) rappresenta la proporzione di “Testa” dopo \\(n\\) lanci. La Legge Forte dei Grandi Numeri (SLLN) afferma che, con probabilità 1, la sequenza di variabili aleatorie \\(\\bar{X}_1, \\bar{X}_2, \\bar{X}_3, \\ldots\\) convergerà a \\(1/2\\) quando si cristallizza in una sequenza di numeri reali. Matematicamente parlando, esistono scenari improbabili come una sequenza infinita di “Testa” (HHHHHH…) o sequenze irregolari come HHTHHTHHTHHT…, ma queste hanno una probabilità collettiva di zero di verificarsi. La Legge Debole dei Grandi Numeri (WLLN) stabilisce che, per ogni \\(\\epsilon &gt; 0\\), la probabilità che \\(\\bar{X}_n\\) sia distante più di \\(\\epsilon\\) da \\(1/2\\) può essere resa arbitrariamente piccola aumentando \\(n\\).\nCome illustrazione, abbiamo simulato sei sequenze di lanci di una moneta equa e, per ciascuna sequenza, abbiamo calcolato \\(\\bar{X}_n\\) in funzione di \\(n\\). Ovviamente, nella realtà non possiamo effettuare un numero infinito di lanci, quindi ci siamo fermati dopo 300 lanci. Il grafico seguente mostra \\(\\bar{X}_n\\) in funzione di $ n $ per ciascuna delle sei sequenze. All’inizio, notiamo una certa variazione nella proporzione cumulativa di “Testa”. Tuttavia, con l’aumentare del numero di lanci, la varianza $ ({X}_n) $ diminuisce progressivamente e \\(\\bar{X}_n\\) tende a \\(1/2\\).\n\n# Numero di sequenze\nnum_sequences &lt;- 6\n# Numero di lanci\nnum_tosses &lt;- 300\n\n# Creare un data frame per contenere i risultati\nresults &lt;- data.frame(Toss = numeric(), Proportion = numeric(), Sequence = character())\n\n# Loop attraverso ciascuna sequenza\nfor (i in 1:num_sequences) {\n  # Generare una sequenza di lanci di moneta equa (Testa=1, Croce=0)\n  coin_tosses &lt;- sample(c(0, 1), num_tosses, replace = TRUE)\n  \n  # Calcolare la proporzione cumulativa di Teste\n  running_proportion &lt;- cumsum(coin_tosses) / seq_along(coin_tosses)\n  \n  # Aggiungere i risultati al data frame\n  results &lt;- rbind(\n    results,\n    data.frame(\n      Toss = seq_along(coin_tosses),\n      Proportion = running_proportion,\n      Sequence = paste(\"Sequence\", i)\n    )\n  )\n}\n\n# Creare il grafico con ggplot2\nggplot(results, aes(x = Toss, y = Proportion, color = Sequence)) +\n  geom_line() +\n  geom_hline(yintercept = 0.5, color = \"red\", linetype = \"dashed\") +\n  labs(\n    x = \"Number of Tosses\",\n    y = \"Running Proportion of Heads\",\n    title = \"Running Proportion of Heads in Six Sequences of Fair Coin Tosses\",\n    color = \"Sequence\"\n  )",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#teorema-del-limite-centrale",
    "href": "chapters/probability/08_sampling_distr.html#teorema-del-limite-centrale",
    "title": "32  Stime, stimatori e parametri",
    "section": "32.6 Teorema del Limite Centrale",
    "text": "32.6 Teorema del Limite Centrale\nIl teorema del limite centrale è un risultato fondamentale in statistica che è stato dimostrato per la prima volta da Laplace nel 1812. Esso fornisce una spiegazione matematica per il motivo per cui la distribuzione normale appare così frequentemente nei fenomeni naturali. Ecco la formulazione essenziale.\nSupponiamo di avere una sequenza di variabili aleatorie indipendenti ed identicamente distribuite (i.i.d.), \\(Y = Y_1, \\dots, Y_i, \\ldots, Y_n\\), ciascuna con valore atteso \\(\\mathbb{E}(Y_i) = \\mu\\) e deviazione standard \\(SD(Y_i) = \\sigma\\). Definiamo una nuova variabile casuale come la media aritmetica di queste variabili:\n\\[\nZ = \\frac{1}{n} \\sum_{i=1}^n Y_i.\n\\]\nAllora, quando \\(n\\) tende all’infinito, la distribuzione di \\(Z\\) convergerà a una distribuzione normale con media \\(\\mu\\) e deviazione standard ridotta di un fattore \\(\\frac{1}{\\sqrt{n}}\\):\n\\[\np_Z(z) \\rightarrow \\mathcal{N}\\left(z \\ \\Bigg| \\ \\mu, \\, \\frac{\\sigma}{\\sqrt{n}}\\right).\n\\]\n\n32.6.1 Significato e generalizzazione\nIl TLC non si applica solo alle variabili casuali con la stessa distribuzione, ma può essere esteso a variabili casuali indipendenti con aspettative e varianze finite. La potenza del teorema sta nella sua capacità di descrivere fenomeni che sono il risultato di molteplici effetti additivi indipendenti. Anche se questi effetti possono avere distribuzioni diverse, la loro somma tende a una distribuzione normale.\nAd esempio, l’altezza degli esseri umani adulti può essere vista come la somma di molti fattori genetici e ambientali indipendenti. Indipendentemente dalla distribuzione individuale di questi fattori, la loro combinazione tende a formare una distribuzione normale. Questa universalità rende la distribuzione normale una buona approssimazione per molti fenomeni naturali.\n\nEsempio 32.2 Per visualizzare il TLC in azione, si può condurre una simulazione. Immaginiamo una popolazione distribuita in maniera uniforme. Estraiamo 300 campioni di dimensione \\(n\\) = 30 da questa popolazione e osserviamo come la distribuzione campionaria di tali medie converga a una distribuzione normale. Questa simulazione fornirà un’illustrazione concreta dell’efficacia del TLC nell’approssimare distribuzioni reali.\n\n# Set the random seed for reproducibility\nset.seed(42)\n\n# Generate a non-normally distributed population\npopulation &lt;- runif(5000, min = 0, max = 1)\n\n# Create a histogram of the population\npar(mfrow = c(1, 2))  # Set up a 1x2 grid for plotting\n\n# Plot the histogram of the population\nhist(population, breaks = 30, prob = TRUE, main = \"Population Distribution\",\n     xlab = \"Value\", col = \"lightblue\")\n\n# Step 2 and 3: Draw random samples and calculate sample means\nsample_size &lt;- 30\nnum_samples &lt;- 300\n\n# Empty vector to store sample means\nsample_means &lt;- c()\n\nfor (i in 1:num_samples) {\n  # Take a random sample\n  sample &lt;- sample(population, size = sample_size, replace = TRUE)\n  \n  # Calculate the mean of the sample\n  sample_means[i] &lt;- mean(sample)\n}\n\n# For sample\nx_bar &lt;- mean(sample_means)\nstd &lt;- sd(sample_means)\n\nprint('Sample Mean and Variance')\n#&gt; [1] \"Sample Mean and Variance\"\nprint(x_bar)\n#&gt; [1] 0.5010222\nprint(std**2)\n#&gt; [1] 0.002745131\n\n# For Population\nmu &lt;- mean(population)\nsigma &lt;- sd(population)\n\nprint('Population Mean and Variance')\n#&gt; [1] \"Population Mean and Variance\"\nprint(mu)\n#&gt; [1] 0.5031668\nprint((sigma**2)/sample_size)\n#&gt; [1] 0.002823829\n\n# Plot the histogram of sample means\nhist(sample_means, breaks = 30, prob = TRUE, main = \"Distribution of Sample Means\",\n     xlab = \"Sample Mean\", col = \"lightgreen\")\n\n# Overlay density curves\ncurve(dnorm(x, mean = x_bar, sd = std), col = \"black\", lwd = 2, add = TRUE)\n\n# Add labels and legends\nlegend(\"topright\", legend = c(\"Distribution Curve\"),\n       col = c(\"black\"), lwd = 2)\n\n# Reset the plot layout\npar(mfrow = c(1, 1))\n\n\n\n\n\n\n\n\n\nIn conclusione, il teorema del limite centrale (TLC) stabilisce che, a meno che non si stia lavorando con campioni estremamente piccoli, è possibile approssimare con buona precisione la distribuzione campionaria della media dei campioni utilizzando la distribuzione Normale. Questo vale indipendentemente dalla forma specifica della distribuzione della popolazione da cui sono tratti i campioni. In altre parole, quando si lavora con campioni di dimensioni sufficienti, il TLC offre una formula concreta per descrivere la forma della distribuzione campionaria della media dei campioni. Ciò avviene anche se non si hanno informazioni dettagliate sulla popolazione, come la media \\(\\mu\\) e la deviazione standard \\(\\sigma\\), ed è espresso dalla relazione \\(\\bar{X} \\sim \\mathcal{N}(\\mu, \\sigma/\\sqrt{n})\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#distribuzioni-campionarie-di-altre-statistiche",
    "href": "chapters/probability/08_sampling_distr.html#distribuzioni-campionarie-di-altre-statistiche",
    "title": "32  Stime, stimatori e parametri",
    "section": "32.7 Distribuzioni campionarie di altre statistiche",
    "text": "32.7 Distribuzioni campionarie di altre statistiche\nIn precedenza abbiamo descritto la distribuzione campionaria della media dei campioni. Ma ovviamente è possibile costruire la distribuzione campionaria di altre statistiche campionarie. Ad esempio, la figura seguente mostra l’approssimazione empirica della distribuzione campionaria del valore massimo del campione. È chiaro che, se da ciascun campione estraiamo il valore massimo, il valore atteso della distribuzione campionaria di questa statistica sarà maggiore della media della popolazione.\n\n# Definire una distribuzione normale con media 100 e deviazione standard 15\nmu &lt;- 100\nsigma &lt;- 15\nx &lt;- seq(mu - 3 * sigma, mu + 3 * sigma, length.out = 100)\ny &lt;- dnorm(x, mean = mu, sd = sigma)\n\n# Simulare 10.000 esperimenti con 5 soggetti ciascuno e trovare il massimo punteggio per ciascun esperimento\nset.seed(123)  # Per riproducibilità\nsample_maxes &lt;- replicate(10000, max(rnorm(5, mean = mu, sd = sigma)))\n\n# Creare un istogramma della distribuzione dei massimi campionari insieme alla distribuzione della popolazione\n\n# Creare il data frame per il grafico\ndata &lt;- data.frame(SampleMaxes = sample_maxes)\ndensity_data &lt;- data.frame(x = x, y = y)\n\nggplot(data, aes(x = SampleMaxes)) +\n  geom_histogram(\n    aes(y = ..density..),\n    bins = 30,\n    alpha = 0.7\n  ) +\n  geom_line(data = density_data, aes(x = x, y = y), size = 1) +\n  labs(\n    title = \"Distribuzione dei massimi campionari\",\n    x = \"Massimo campionario\",\n    y = \"Densità\"\n  ) \n#&gt; Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\nLa distribuzione campionaria della varianza dei campioni è particolarmente interessante. Usiamo la formula della statistica descrittiva, ovvero\n\\[\nS^2 = \\frac{\\sum_{i=1}^n (Y_i - \\bar{Y})^2}{n}.\n\\]\nUna volta compresa la procedura, possiamo creare un grafico che rappresenta l’approssimazione empirica della distribuzione campionaria della varianza dei punteggi del quoziente di intelligenza. Sapendo che la varianza della popolazione è uguale a \\(15^2\\), abbiamo utilizzato la simulazione per stimare la varianza della popolazione. Tuttavia, il risultato ottenuto è stato interessante: in media, l’utilizzo della formula precedente ha portato a una stima della varianza della popolazione troppo piccola. Gli statistici chiamano questa discrepanza distorsione, ovvero quando il valore atteso di uno stimatore non coincide con il parametro.\n\n# Definire una distribuzione normale con media 100 e deviazione standard 15\nmu &lt;- 100\nsigma &lt;- 15\nx &lt;- seq(0, 30, length.out = 100)\ny &lt;- dnorm(x, mean = mu, sd = sigma)\n\n# Simulare 10.000 esperimenti con 5 soggetti ciascuno e calcolare la varianza per ciascun esperimento\nset.seed(123)  # Per riproducibilità\nsample_vars &lt;- replicate(10000, var(rnorm(5, mean = mu, sd = sigma)))\n\n# Creare un istogramma della distribuzione delle varianze campionarie\n\ndata &lt;- data.frame(SampleVars = sample_vars)\n\nggplot(data, aes(x = SampleVars)) +\n  geom_histogram(\n    aes(y = ..density..),\n    bins = 30,\n    alpha = 0.7\n  ) +\n  labs(\n    title = \"Distribuzione delle varianze campionarie\",\n    x = \"Varianza campionaria\",\n    y = \"Densità\"\n  ) \n\n\n\n\n\n\n\n\n\n# Calcolare la media delle varianze campionarie\nmean(sample_vars)\n#&gt; [1] 225.8211\n\nAbbiamo già visto come questo problema trova una semplice soluzione nel momento in cui usiamo \\(n-1\\) al denominatore.\n\n# Definire una distribuzione normale con media 100 e deviazione standard 15\nmu &lt;- 100\nsigma &lt;- 15\nx &lt;- seq(0, 30, length.out = 100)\ny &lt;- dnorm(x, mean = mu, sd = sigma)\n\n# Simulare 10.000 esperimenti con 5 soggetti ciascuno e calcolare la varianza corretta per ciascun esperimento\nset.seed(123)  # Per riproducibilità\nsample_vars &lt;- replicate(10000, var(rnorm(5, mean = mu, sd = sigma)))\n\n# Creare un istogramma della distribuzione delle varianze campionarie\ndata &lt;- data.frame(SampleVars = sample_vars)\n\nggplot(data, aes(x = SampleVars)) +\n  geom_histogram(\n    aes(y = ..density..),\n    bins = 30,\n    alpha = 0.7\n  ) +\n  labs(\n    title = \"Distribuzione delle varianze campionarie\",\n    x = \"Varianza campionaria\",\n    y = \"Densità\"\n  ) \n\n\n\n\n\n\n\n\n\n# Calcolare la media delle varianze campionarie\nmean(sample_vars)\n#&gt; [1] 225.8211\n\nLa differenza tra la stima di un parametro e il valore vero del parametro è chiamata errore della stima. Uno stimatore si dice non distorto (unbiased) se la media delle sue stime su molteplici campioni ipotetici è uguale al valore del parametro che si vuole stimare. In altre parole, l’errore medio di stima è zero.\nIn questo capitolo abbiamo visto che \\(\\frac{\\sum_{i=1}^n{X_i}}{n}\\) è uno stimatore non distorto di \\(\\mu\\) e che \\(\\frac{\\sum_{i=1}^n{(^2)}}{n-1}\\) è uno stimatore non distorto di \\(\\sigma^2\\). Questo significa che tali stimatori hanno una distribuzione campionaria centrata sul vero valore del parametro.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#riflessioni-conclusive",
    "href": "chapters/probability/08_sampling_distr.html#riflessioni-conclusive",
    "title": "32  Stime, stimatori e parametri",
    "section": "32.8 Riflessioni Conclusive",
    "text": "32.8 Riflessioni Conclusive\nIn generale, i parametri della popolazione sono sconosciuti, ma possiamo stimarli utilizzando le informazioni del campione. Di seguito viene presentata una tabella che riassume i simboli comuni utilizzati per indicare le quantità note e sconosciute nel contesto dell’inferenza statistica. Questo ci aiuterà a tenere traccia di ciò che sappiamo e ciò che non sappiamo.\n\n\n\n\n\n\n\n\nSimbolo\nNome\nÈ qualcosa che conosciamo?\n\n\n\n\n\\(s\\)\nDeviazione standard del campione\nSì, la calcoliamo dai dati grezzi\n\n\n\\(\\sigma\\)\nDeviazione standard della popolazione\nNo, tranne in casi particolari o nelle simulazioni\n\n\n\\(\\hat{\\sigma}\\)\nStima della deviazione standard della popolazione\nSì, ma non è uguale a \\(\\sigma\\)\n\n\n\\(s^2\\)\nVarianza del campione\nSì, la calcoliamo dai dati grezzi\n\n\n\\(\\sigma^2\\)\nVarianza della popolazione\nNo, tranne in casi particolari o nelle simulazioni\n\n\n\\(\\hat{\\sigma}^2\\)\nStima della varianza della popolazione\nSì, ma non è uguale a \\(\\sigma^2\\)\n\n\n\nUtilizzando le informazioni di un campione casuale di ampiezza \\(n\\):\n\nLa stima migliore che possiamo ottenere per la media \\(\\mu\\) della popolazione è la media del campione \\(\\bar{Y}\\).\nLa stima migliore che possiamo ottenere per la varianza \\(\\sigma^2\\) della popolazione è:\n\n\\[\n\\hat{\\sigma}^2 = \\frac{1}{n-1} \\sum_{i=1}^n (Y_i - \\bar{Y})^2.\n\\]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/08_sampling_distr.html#informazioni-sullambiente-di-sviluppo",
    "title": "32  Stime, stimatori e parametri",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.16.0       MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2\n#&gt;  [5] ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0  \n#&gt;  [9] bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0      markdown_1.13    \n#&gt; [13] knitr_1.49        lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1    \n#&gt; [17] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#&gt; [21] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [25] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1  farver_2.1.2      fastmap_1.2.0     pacman_0.5.1     \n#&gt;  [5] promises_1.3.1    rpart_4.1.23      digest_0.6.37     timechange_0.3.0 \n#&gt;  [9] mime_0.12         lifecycle_1.0.4   survival_3.7-0    magrittr_2.0.3   \n#&gt; [13] compiler_4.4.2    rlang_1.1.4       tools_4.4.2       utf8_1.2.4       \n#&gt; [17] yaml_2.3.10       ggsignif_0.6.4    labeling_0.4.3    htmlwidgets_1.6.4\n#&gt; [21] mnormt_2.1.1      abind_1.4-8       miniUI_0.1.1.1    withr_3.0.2      \n#&gt; [25] nnet_7.3-19       grid_4.4.2        fansi_1.0.6       jomo_2.7-6       \n#&gt; [29] xtable_1.8-4      colorspace_2.1-1  iterators_1.0.14  cli_3.6.3        \n#&gt; [33] rmarkdown_2.29    generics_0.1.3    tzdb_0.4.0        minqa_1.2.8      \n#&gt; [37] splines_4.4.2     parallel_4.4.2    vctrs_0.6.5       boot_1.3-31      \n#&gt; [41] glmnet_4.1-8      Matrix_1.7-1      jsonlite_1.8.9    carData_3.0-5    \n#&gt; [45] car_3.1-3         hms_1.1.3         mitml_0.4-5       rstatix_0.7.2    \n#&gt; [49] Formula_1.2-5     foreach_1.5.2     glue_1.8.0        pan_1.9          \n#&gt; [53] nloptr_2.1.1      codetools_0.2-20  stringi_1.8.4     gtable_0.3.6     \n#&gt; [57] shape_1.4.6.1     later_1.4.0       lme4_1.1-35.5     munsell_0.5.1    \n#&gt; [61] pillar_1.9.0      htmltools_0.5.8.1 R6_2.5.1          rprojroot_2.0.4  \n#&gt; [65] evaluate_1.0.1    shiny_1.9.1       lattice_0.22-6    backports_1.5.0  \n#&gt; [69] broom_1.0.7       httpuv_1.6.15     Rcpp_1.0.13-1     nlme_3.1-166     \n#&gt; [73] xfun_0.49         pkgconfig_2.0.3",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#bibliografia",
    "href": "chapters/probability/08_sampling_distr.html#bibliografia",
    "title": "32  Stime, stimatori e parametri",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nWard, A., & Mann, T. (2022). Control yourself: Broad implications of narrowed attention. Perspectives on Psychological Science, 17(6), 1692–1703.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html",
    "href": "chapters/probability/09_joint_prob.html",
    "title": "33  Probabilità congiunta",
    "section": "",
    "text": "33.1 Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nPreparazione del Notebook\nIn questo capitolo ci proponiamo di analizzare in dettaglio il concetto di probabilità congiunta, focalizzando l’attenzione sul caso di variabili aleatorie discrete. La probabilità congiunta rappresenta la misura della probabilità che due o più eventi si verifichino simultaneamente.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#funzione-di-probabilità-congiunta",
    "href": "chapters/probability/09_joint_prob.html#funzione-di-probabilità-congiunta",
    "title": "33  Probabilità congiunta",
    "section": "33.2 Funzione di Probabilità Congiunta",
    "text": "33.2 Funzione di Probabilità Congiunta\nFinora abbiamo analizzato la probabilità associata a un singolo evento, o più precisamente, a un singolo valore assunto da una variabile aleatoria. Tuttavia, spesso siamo interessati a studiare la relazione tra due o più eventi. La funzione di probabilità congiunta ci permette di estendere il concetto di probabilità al caso di più variabili aleatorie, descrivendo la probabilità che queste assumano specifici valori contemporaneamente.\n\n33.2.1 Esempio: Lancio di Tre Monete Equilibrate\nPer comprendere meglio il concetto di probabilità congiunta, immaginiamo di lanciare tre monete. Tutti i possibili risultati di questo esperimento (ad esempio, tre teste, due teste e una croce, ecc.) costituiscono quello che chiamiamo spazio campionario. In questo caso, lo spazio campionario \\(\\Omega\\) è dato da:\n\\[\n\\Omega = \\{TTT, TTC, TCT, CTT, CCT, CTC, TCC, CCC\\},\n\\]\ndove \\(T\\) indica “testa” e \\(C\\) indica “croce”. Assumendo che ogni lancio sia indipendente dagli altri, ogni risultato nello spazio campionario \\(\\Omega\\) ha la stessa probabilità di verificarsi, ovvero \\(1/8\\).\nDefiniamo ora le seguenti variabili casuali sullo spazio campionario \\(\\Omega\\):\n\n\\(X \\in \\{0, 1, 2, 3\\}\\) rappresenta il numero totale di teste ottenute nei tre lanci.\n\\(Y \\in \\{0, 1\\}\\) indica se il primo lancio ha dato testa (\\(1\\)) oppure croce (\\(0\\)).\n\nLa tabella seguente mostra lo spazio campionario con i valori di \\(X\\) e \\(Y\\) associati a ciascun esito, insieme alla probabilità di ciascun evento \\(\\omega\\):\n\n\n\n\\(\\omega\\)\n\\(X\\)\n\\(Y\\)\n\\(P(\\omega)\\)\n\n\n\n\n\\(\\omega_1\\) = TTT\n3\n1\n1/8\n\n\n\\(\\omega_2\\) = TTC\n2\n1\n1/8\n\n\n\\(\\omega_3\\) = TCT\n2\n1\n1/8\n\n\n\\(\\omega_4\\) = CTT\n2\n0\n1/8\n\n\n\\(\\omega_5\\) = CCT\n1\n0\n1/8\n\n\n\\(\\omega_6\\) = CTC\n1\n0\n1/8\n\n\n\\(\\omega_7\\) = TCC\n1\n1\n1/8\n\n\n\\(\\omega_8\\) = CCC\n0\n0\n1/8\n\n\n\nOra possiamo determinare la probabilità congiunta per ogni coppia \\((X, Y)\\), che rappresenta la probabilità di ottenere un determinato numero di teste \\(X\\) e un determinato risultato per il primo lancio \\(Y\\). Ad esempio:\n\\[P(X=0, Y=0) = P(\\text{CCC}) = 1/8,\\]\ne così via per le altre coppie.\nLe probabilità congiunte per tutte le possibili combinazioni \\((X, Y)\\) sono calcolate come segue:\n\\[\n\\begin{aligned}\nP(X = 0, Y = 0) &= 1/8, \\\\\nP(X = 1, Y = 0) &= P(\\text{CCT}) + P(\\text{CTC}) = 1/4, \\\\\nP(X = 1, Y = 1) &= P(\\text{TCC}) = 1/8, \\\\\nP(X = 2, Y = 0) &= P(\\text{CTT}) = 1/8, \\\\\nP(X = 2, Y = 1) &= P(\\text{TTC}) + P(\\text{TCT}) = 1/4, \\\\\nP(X = 3, Y = 1) &= P(\\text{TTT}) = 1/8.\n\\end{aligned}\n\\]\nQueste probabilità costituiscono la distribuzione di probabilità congiunta delle variabili casuali \\(X\\) (numero di teste) e \\(Y\\) (testa al primo lancio). Questa distribuzione fornisce un quadro completo delle probabilità per tutte le combinazioni di risultati di queste due variabili.\n\n\n33.2.2 Definizione: Funzione di Probabilità Congiunta\nLa funzione di probabilità congiunta di due variabili casuali \\(X\\) e \\(Y\\) associa a ogni coppia \\((x, y)\\) una probabilità \\(P(X = x, Y = y)\\).\n\n\n33.2.3 Proprietà\nUna distribuzione di probabilità congiunta deve soddisfare:\n\n\\(0 \\leq P(x_i, y_j) \\leq 1\\) per ogni coppia \\((x_i, y_j)\\),\n\\(\\sum_{i} \\sum_{j} P(x_i, y_j) = 1\\), ovvero la somma delle probabilità su tutte le coppie deve essere 1.\n\n\n\n33.2.4 Calcolo della Probabilità di Eventi Specifici\nData la distribuzione di probabilità congiunta, possiamo determinare la probabilità di eventi definiti in termini delle variabili aleatorie \\(X\\) e \\(Y\\). Ad esempio, per trovare la probabilità che \\(X + Y \\leq 1\\), sommiamo le probabilità di tutte le coppie \\((x, y)\\) che soddisfano questa condizione, ottenendo \\(P(X+Y \\leq 1) = 3/8\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#marginalizzazione",
    "href": "chapters/probability/09_joint_prob.html#marginalizzazione",
    "title": "33  Probabilità congiunta",
    "section": "33.3 Marginalizzazione",
    "text": "33.3 Marginalizzazione\nImmagina di condurre uno studio sul livello di stress tra studenti universitari, raccogliendo dati su variabili come l’anno di corso, il genere, il supporto sociale e il livello di stress. Se desideri comprendere come il livello di stress varia in funzione dell’anno di corso, indipendentemente dal genere e dal supporto sociale, puoi utilizzare la marginalizzazione.\nLa marginalizzazione consente di ottenere una distribuzione di probabilità focalizzata su una o più variabili di interesse, “eliminando” dal calcolo le variabili non rilevanti. Nel nostro esempio, per ottenere la distribuzione marginale del livello di stress rispetto all’anno di corso, occorre sommare (o integrare, nel caso di variabili continue) le probabilità associate a tutte le combinazioni di genere e supporto sociale, mantenendo fisso l’anno di corso. In questo modo, otteniamo una distribuzione che descrive come il livello di stress varia solo in relazione all’anno di corso.\nIl termine “marginalizzazione” deriva dalle tabelle di contingenza: quando rappresentiamo una distribuzione di probabilità congiunta in una tabella, le probabilità marginali—che descrivono la distribuzione di una variabile indipendentemente dalle altre—si trovano nei margini della tabella (ovvero nelle righe e colonne finali).\n\n33.3.1 Formalizzazione della Marginalizzazione\nData una distribuzione di probabilità congiunta \\(P(X, Y)\\) di due variabili casuali \\(X\\) e \\(Y\\), possiamo ottenere la distribuzione marginale di \\(X\\) sommando tutte le probabilità associate a \\(Y\\). Formalmente:\n\\[\nP(X = x) = \\sum_y P(X = x, Y = y),\n\\]\ndove \\(P(X = x, Y = y)\\) rappresenta la probabilità congiunta di \\(X\\) e \\(Y\\). La marginalizzazione garantisce inoltre che le distribuzioni siano normalizzate, cioè che le somme delle probabilità marginali per ciascuna variabile siano uguali a 1:\n\\[\n\\sum_x P(X = x) = 1 \\quad \\text{e} \\quad \\sum_y P(Y = y) = 1.\n\\]\nNel caso di variabili continue, questa operazione di somma viene sostituita dall’integrazione.\nPer chiarire, consideriamo il seguente esempio. Supponiamo di studiare l’efficacia di una terapia cognitivo-comportamentale per l’ansia, includendo variabili come l’età dei partecipanti e il livello iniziale di ansia. Se vogliamo valutare l’efficacia della terapia a prescindere dall’età e dal livello di ansia iniziale, marginalizziamo rispetto a queste due variabili, ottenendo così una distribuzione che riflette solo l’associazione tra terapia e riduzione dell’ansia.\nIn sintesi, la marginalizzazione:\n\npermette di estrarre distribuzioni di probabilità per variabili specifiche, “dimenticando” quelle non rilevanti;\nconsiste nel sommare o integrare le probabilità attraverso tutte le possibili combinazioni delle variabili non rilevanti, concentrandosi su quelle di interesse.\n\nIn conclusione, la marginalizzazione è uno strumento essenziale per l’analisi statistica, facilitando lo studio delle relazioni tra variabili complesse e aiutandoci a isolare gli effetti delle variabili di interesse in modo rigoroso.\n\nEsempio 33.1 Per fare un esempio, prendiamo come riferimento l’esperimento del lancio di tre monete equilibrate descritto precedentemente. Per calcolare le probabilità marginali di \\(X\\) e \\(Y\\), sommiamo le probabilità congiunte su una dimensione. La probabilità marginale di \\(X\\), \\(P_X\\), si ottiene sommando le probabilità lungo le colonne per ciascun valore fisso di \\(X\\); analogamente, la probabilità marginale di \\(Y\\), \\(P_Y\\), si calcola sommando le probabilità lungo le righe per ciascun valore fisso di \\(Y\\).\nLa tabella seguente mostra la distribuzione di probabilità congiunta \\(P(X, Y)\\) e le probabilità marginali \\(P(X)\\) e \\(P(Y)\\):\n\n\n\n\\(x \\setminus y\\)\n0\n1\n\\(P(x)\\)\n\n\n\n\n0\n1/8\n0\n1/8\n\n\n1\n2/8\n1/8\n3/8\n\n\n2\n1/8\n2/8\n3/8\n\n\n3\n0\n1/8\n1/8\n\n\n\\(P(y)\\)\n4/8\n4/8\n1.0\n\n\n\n\n\n\n33.3.2 Marginalizzazione per Variabili Casuali Continue\nNell’ambito della statistica bayesiana, il concetto di marginalizzazione gioca un ruolo cruciale. Un esempio di equazione che emerge da questo processo è:\n\\[\np(y) = \\int_{\\theta} p(y, \\theta) \\, d\\theta = \\int_{\\theta} p(y \\mid \\theta) p(\\theta) \\, d\\theta,\n\\]\ndove \\(y\\) e \\(\\theta\\) sono variabili casuali continue, con \\(y\\) che rappresenta i dati osservati e \\(\\theta\\) i parametri di un modello statistico. Questa equazione illustra come, in un contesto continuo, la marginalizzazione possa essere vista come l’estensione dell’approccio discreto a un continuum di valori per le variabili in esame.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#indipendenza-tra-variabili-casuali",
    "href": "chapters/probability/09_joint_prob.html#indipendenza-tra-variabili-casuali",
    "title": "33  Probabilità congiunta",
    "section": "33.4 Indipendenza tra Variabili Casuali",
    "text": "33.4 Indipendenza tra Variabili Casuali\nL’indipendenza tra variabili casuali è un concetto fondamentale in statistica e probabilità, parallelo all’idea di indipendenza tra eventi. Due variabili casuali si considerano indipendenti quando l’informazione su una non altera in alcun modo la distribuzione di probabilità dell’altra. Questa sezione offre una formalizzazione dell’indipendenza tra due variabili casuali discrete, basata sulla loro distribuzione di probabilità congiunta.\n\n33.4.1 Definizione di Indipendenza\nDue variabili casuali \\(X\\) e \\(Y\\), con una distribuzione congiunta, sono definite indipendenti se, e solo se, per ogni coppia di valori \\((x, y)\\) si verifica che:\n\\[\nP_{X, Y}(x, y) = P_X(x) \\cdot P_Y(y).\n\\]\nIn termini pratici, ciò significa che se \\(X\\) e \\(Y\\) sono variabili casuali discrete indipendenti, la loro distribuzione di probabilità congiunta è il prodotto delle rispettive distribuzioni di probabilità marginali. Se invece \\(P_{X, Y}(x, y) \\neq P_X(x) \\cdot P_Y(y)\\), le variabili non sono indipendenti e si dicono associate o dipendenti.\nQuesto concetto si applica anche alle variabili casuali continue, mantenendo la stessa logica: l’indipendenza si verifica quando la funzione di densità congiunta è il prodotto delle funzioni di densità marginali.\n\n\n33.4.2 Associazione tra Variabili Casuali\nQuando due variabili casuali non sono indipendenti, si descrivono come associate o dipendenti. In questo contesto, è utile introdurre il concetto di covarianza (e correlazione) come misura del grado di associazione lineare tra due variabili casuali. La covarianza e la correlazione quantificano in che modo la variazione di una variabile è associata alla variazione dell’altra, fornendo un indice della loro interdipendenza lineare.\nRiepilogando, l’indipendenza tra variabili casuali è un concetto chiave per comprendere le relazioni tra fenomeni aleatori. Riconoscere se due variabili sono indipendenti o associate è fondamentale per l’analisi statistica e per la modellazione di relazioni causali o di correlazione tra variabili.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#covarianza",
    "href": "chapters/probability/09_joint_prob.html#covarianza",
    "title": "33  Probabilità congiunta",
    "section": "33.5 Covarianza",
    "text": "33.5 Covarianza\nLa covarianza è un parametro statistico che quantifica il grado e la direzione della relazione lineare tra due variabili casuali, \\(X\\) e \\(Y\\). In termini semplici, misura come le variazioni di una variabile si accompagnano a quelle dell’altra. Per esempio, considerando l’altezza e il peso di giraffe, scopriremmo che queste due misure tendono ad aumentare insieme, evidenziando così una covarianza positiva. La covarianza è denotata come \\(Cov(X, Y) = \\sigma_{xy}\\).\n\n33.5.1 Definizione di Covarianza\nLa covarianza tra due variabili casuali \\(X\\) e \\(Y\\) è definita come:\n\\[\nCov(X, Y) = \\mathbb{E}\\left[\\left(X - \\mathbb{E}[X]\\right) \\left(Y - \\mathbb{E}[Y]\\right)\\right],\n\\]\ndove \\(\\mathbb{E}[X]\\) e \\(\\mathbb{E}[Y]\\) rappresentano i valori attesi (o medie) di \\(X\\) ed \\(Y\\), rispettivamente.\nIn termini più espliciti, la covarianza può essere espressa come:\n\\[\nCov(X, Y) = \\sum_{(x, y) \\in \\Omega} (x - \\mu_X) (y - \\mu_Y) f(x, y),\n\\]\ndove \\(\\mu_X\\) e \\(\\mu_Y\\) sono le medie di \\(X\\) ed \\(Y\\), e \\(f(x, y)\\) è la funzione di probabilità congiunta delle variabili.\nQuesta definizione mostra una stretta analogia con la varianza, che è la covarianza di una variabile con se stessa:\n\\[\n\\mathbb{V}(X) = Cov(X, X).\n\\]\nInoltre, la covarianza può essere calcolata attraverso la relazione:\n\\[\nCov(X, Y) = \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y).\n\\]\n\n\n33.5.2 Dimostrazione\nLa formula alternativa per la covarianza si dimostra come segue:\n\\[\n\\begin{align}\nCov(X, Y) &= \\mathbb{E}\\left[\\left(X - \\mathbb{E}[X]\\right) \\left(Y - \\mathbb{E}[Y]\\right)\\right]\\\\\n&= \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y).\n\\end{align}\n\\]\n\n\n33.5.3 Esempio di Calcolo della Covarianza\nConsideriamo le variabili casuali \\(X\\) e \\(Y\\) con medie \\(\\mu_X = 1.5\\) e \\(\\mu_Y = 0.5\\). La covarianza di \\(X\\) e \\(Y\\) si calcola come:\n\\[\nCov(X, Y) = \\sum_{(x, y) \\in \\Omega} (x - \\mu_X) (y - \\mu_Y) f(x, y) = \\frac{1}{4}.\n\\]\nQuesto risultato si può ottenere anche dalla formula alternativa, calcolando prima \\(\\mathbb{E}(XY)\\):\n\\[\n\\mathbb{E}(XY) = 1.0.\n\\]\nAllora, la covarianza tra \\(X\\) e \\(Y\\) è:\n\\[\nCov(X, Y) = 1 - 1.5 \\cdot 0.5 = 0.25.\n\\]\n\nEsempio 33.2 Per calcolare la covarianza \\(Cov(X, Y)\\) in R, consideriamo l’esempio in cui \\(X\\) è il numero totale di teste che si ottiene dal lancio di tre monete equilibrate e \\(Y\\) è il risultato del primo lancio (testa = 1, croce = 0). Procediamo creando il prodotto cartesiano di tutti i possibili valori di \\(X\\) e \\(Y\\).\n\n# Creare il prodotto cartesiano di X (c3) e Y (c1)\nc3 &lt;- 0:3  # Numero totale di teste possibili\nc1 &lt;- 0:1  # Risultato del primo lancio (0 = croce, 1 = testa)\nsample &lt;- expand.grid(c1 = c1, c3 = c3)\nsample\n#&gt;   c1 c3\n#&gt; 1  0  0\n#&gt; 2  1  0\n#&gt; 3  0  1\n#&gt; 4  1  1\n#&gt; 5  0  2\n#&gt; 6  1  2\n#&gt; 7  0  3\n#&gt; 8  1  3\n\nIl primo numero di ogni coppia rappresenta il valore di \\(Y\\), mentre il secondo rappresenta il valore di \\(X\\). Tuttavia, queste coppie \\((X, Y)\\) non hanno tutte la stessa probabilità di verificarsi. La probabilità associata a ciascuna coppia è data dai seguenti valori: \\(1/8, 2/8, 1/8, 0, 0, 1/8, 2/8, 1/8\\). Questa è la distribuzione di massa di probabilità congiunta delle variabili casuali \\(X\\) e \\(Y\\). Applicando la formula per la covarianza:\n[ Cov(X, Y) = _{i=1}^n (X_i - E[X])(Y_i - E[Y]) P(X_i, Y_i) ]\nCalcoliamo la covarianza in R:\n\n# Probabilità di ogni coppia (X, Y)\npmf &lt;- c(1 / 8, 2 / 8, 1 / 8, 0, 0, 1 / 8, 2 / 8, 1 / 8)\n\n# Calcolo della covarianza\nres &lt;- c()\nfor (i in 1:nrow(sample)) {\n  res &lt;- c(res, (sample$c1[i] - 0.5) * (sample$c3[i] - 1.5) * pmf[i])\n}\n\n# Somma dei prodotti ponderati\ncovariance &lt;- sum(res)\ncovariance\n#&gt; [1] -0.125\n\nLa covarianza tra \\(X\\) e \\(Y\\) è dunque uguale a \\(-0.125\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#correlazione",
    "href": "chapters/probability/09_joint_prob.html#correlazione",
    "title": "33  Probabilità congiunta",
    "section": "33.6 Correlazione",
    "text": "33.6 Correlazione\nMentre la covarianza fornisce un’indicazione della tendenza di due variabili casuali a variare insieme, essa è influenzata dalle unità di misura delle variabili, rendendo difficile valutare l’intensità della loro relazione lineare. Per ovviare a questo, si utilizza la correlazione, che normalizza la covarianza attraverso le deviazioni standard delle variabili, offrendo così una misura standardizzata dell’associazione lineare tra di esse.\n\nDefinizione 33.1 Il coefficiente di correlazione tra due variabili casuali \\(X\\) e \\(Y\\), denotato come \\(\\rho(X,Y)\\) o \\(\\rho_{X,Y}\\), è definito come:\n\\[\n\\rho(X,Y) = \\frac{Cov(X,Y)}{\\sqrt{\\mathbb{V}(X)\\mathbb{V}(Y)}},\n\\]\ndove \\(\\mathbb{V}(X)\\) e \\(\\mathbb{V}(Y)\\) rappresentano le varianze di \\(X\\) e \\(Y\\), rispettivamente.\n\nIl coefficiente di correlazione \\(\\rho_{xy}\\) è un valore adimensionale, ovvero non dipende dalle unità di misura delle variabili, e varia nell’intervallo \\(-1 \\leq \\rho \\leq 1\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#proprietà-1",
    "href": "chapters/probability/09_joint_prob.html#proprietà-1",
    "title": "33  Probabilità congiunta",
    "section": "33.7 Proprietà",
    "text": "33.7 Proprietà\n\nCovarianza con una Costante: La covarianza tra una variabile aleatoria \\(X\\) e una costante \\(c\\) è sempre nulla: \\(Cov(c, X) = 0\\).\nSimmetria: La covarianza è simmetrica: \\(Cov(X,Y) = Cov(Y,X)\\).\nIntervallo di Correlazione: Il coefficiente di correlazione \\(\\rho\\) varia tra -1 e 1: \\(-1 \\leq \\rho(X,Y) \\leq 1\\).\nIndipendenza dalle Unità di Misura: La correlazione è indipendente dalle unità di misura: \\(\\rho(aX, bY) = \\rho(X,Y)\\) per ogni \\(a, b &gt; 0\\).\nRelazione Lineare Perfetta: Se \\(Y = a + bX\\) è una funzione lineare di \\(X\\), allora \\(\\rho(X,Y) = \\pm 1\\), a seconda del segno di \\(b\\).\nCovarianza e Costanti: La covarianza tra \\(X\\) e \\(Y\\), ciascuna moltiplicata per una costante, è \\(Cov(aX, bY) = ab \\, Cov(X,Y)\\).\nVarianza della Somma/Differenza: \\(\\mathbb{V}(X \\pm Y) = \\mathbb{V}(X) + \\mathbb{V}(Y) \\pm 2Cov(X,Y)\\).\nCovarianza e Somma di Variabili: \\(Cov(X + Y, Z) = Cov(X,Z) + Cov(Y,Z)\\).\nVarianza di una Somma di Variabili Aleatorie: Per variabili aleatorie \\(X_1, \\dots, X_n\\), si ha \\(\\mathbb{V}(\\sum_{i=1}^n X_i) = \\sum_{i=1}^n \\mathbb{V}(X_i) + 2\\sum_{i&lt;j} Cov(X_i, X_j)\\).\nCovarianza e Somme di Prodotti: \\(Cov(\\sum_{i=1}^n a_i X_i, \\sum_{j=1}^m b_j Y_j) = \\sum_{i=1}^n \\sum_{j=1}^m a_i b_j Cov(X_i, Y_j)\\).\nIndipendenza e Covarianza di Somme: Se \\(X_1, X_2, \\dots, X_n\\) sono indipendenti, allora \\(Cov(\\sum_{i=1}^n a_i X_i, \\sum_{j=1}^n b_j X_j) = \\sum_{i=1}^n a_i b_i \\mathbb{V}(X_i)\\).\n\n\n33.7.1 Incorrelazione\nDue variabili casuali \\(X\\) ed \\(Y\\) si dicono incorrelate, o linearmente indipendenti, se la loro covarianza è nulla:\n\\[\nCov(X,Y) = \\mathbb{E}[(X - \\mu_X)(Y - \\mu_Y)] = 0,\n\\]\nequivalente a dire che \\(\\rho_{XY} = 0\\) e \\(\\mathbb{E}(XY) = \\mathbb{E}(X)\\mathbb{E}(Y)\\).\nQuesta condizione indica una forma di indipendenza più debole rispetto all’indipendenza stocastica. Tuttavia, \\(Cov(X, Y) = 0\\) non implica necessariamente che \\(X\\) ed \\(Y\\) siano stocasticamente indipendenti.\n\nEsempio 33.3 Consideriamo una distribuzione di probabilità congiunta di due variabili aleatorie, \\(X\\) e \\(Y\\), definita come:\n\\[\nf_{XY}(x,y) = \\left\\{\n\\begin{array}{ll}\n\\frac{1}{4} & \\text{per } (x,y) \\in \\{(0,0), (1,1), (1, -1), (2,0) \\}, \\\\\n0 & \\text{altrimenti.}\n\\end{array}\n\\right.\n\\]\nQuesto implica che le variabili aleatorie \\(X\\) e \\(Y\\) assumono valori specifici con probabilità uniforme solo per determinate coppie \\((x, y)\\) e zero in tutti gli altri casi.\nDistribuzioni Marginali\nLa distribuzione marginale di \\(X\\) si ottiene sommando le probabilità congiunte su tutti i possibili valori di \\(Y\\), e viceversa per \\(Y\\). Le distribuzioni marginali risultano essere:\n\nPer \\(X\\):\n\\[\nf_X(x) = \\left\\{\n\\begin{array}{ll}\n\\frac{1}{4} & \\text{per } x=0, \\\\\n\\frac{1}{2} & \\text{per } x=1, \\\\\n\\frac{1}{4} & \\text{per } x=2.\n\\end{array}\n\\right.\n\\]\nPer \\(Y\\):\n\\[\nf_Y(y) = \\left\\{\n\\begin{array}{ll}\n\\frac{1}{4} & \\text{per } y=-1, \\\\\n\\frac{1}{2} & \\text{per } y=0, \\\\\n\\frac{1}{4} & \\text{per } y=1.\n\\end{array}\n\\right.\n\\]\n\nMedie e Varianze\nCalcoliamo ora le medie e le varianze di \\(X\\) e \\(Y\\):\n\nMedia di \\(X\\):\n\\[\n\\mathbb{E}(X) = 0 \\cdot \\frac{1}{4} + 1 \\cdot \\frac{1}{2} + 2 \\cdot \\frac{1}{4} = 1.\n\\]\nVarianza di \\(X\\):\n\\[\n\\mathbb{V}(X) = \\left(0^2 \\cdot \\frac{1}{4} + 1^2 \\cdot \\frac{1}{2} + 2^2 \\cdot \\frac{1}{4}\\right) - \\mathbb{E}(X)^2 = \\frac{3}{2} - 1 = \\frac{1}{2}.\n\\]\nMedia di \\(Y\\):\n\\[\n\\mathbb{E}(Y) = (-1) \\cdot \\frac{1}{4} + 0 \\cdot \\frac{1}{2} + 1 \\cdot \\frac{1}{4} = 0.\n\\]\nVarianza di \\(Y\\):\n\\[\n\\mathbb{V}(Y) = \\left((-1)^2 \\cdot \\frac{1}{4} + 0^2 \\cdot \\frac{1}{2} + 1^2 \\cdot \\frac{1}{4}\\right) - \\mathbb{E}(Y)^2 = \\frac{1}{2}.\n\\]\n\nCovarianza tra X e Y\nLa covarianza si calcola come:\n\\[\nCov(X,Y) = \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y),\n\\]\ndove \\(\\mathbb{E}(XY)\\) si trova sommando il prodotto delle coppie di valori \\((x, y)\\) per la loro probabilità congiunta:\n\\[\n\\mathbb{E}(XY) = 0.\n\\]\nDi conseguenza, la covarianza tra \\(X\\) e \\(Y\\) è zero:\n\\[\nCov(X,Y) = 0 - 1 \\cdot 0 = 0.\n\\]\nConclusioni\nSebbene \\(X\\) e \\(Y\\) siano incorrelate (covarianza nulla), ciò non implica la loro indipendenza. L’indipendenza richiede che la funzione di probabilità congiunta si possa esprimere come il prodotto delle funzioni di probabilità marginali per ogni \\(x\\) e \\(y\\), condizione che non si verifica in questo caso. Quindi, nonostante l’assenza di correlazione, \\(X\\) e \\(Y\\) non sono indipendenti, dimostrando che l’incorrelazione non garantisce l’indipendenza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#variabili-continue",
    "href": "chapters/probability/09_joint_prob.html#variabili-continue",
    "title": "33  Probabilità congiunta",
    "section": "33.8 Variabili continue",
    "text": "33.8 Variabili continue\nConsideriamo ora le distribuzioni di densità. Nella figura successiva, tratta da Martin (2024), vediamo una rappresentazione della relazione tra la probabilità congiunta \\(p(A,B)\\), le probabilità marginali \\(p(A)\\) e \\(p(B)\\), e le probabilità condizionali \\(p(A \\mid B)\\).\n\n\n\nDistribuzioni di densità (figura tratta da Martin (2024)).\n\n\n\nProbabilità congiunta \\(p(A,B)\\): rappresenta la probabilità che A e B assumano certi valori contemporaneamente. Per le variabili continue, questa è data dall’integrazione della funzione di densità congiunta su un’area o volume di interesse.\nProbabilità marginale \\(p(A)\\) e \\(p(B)\\): è la probabilità di osservare un particolare valore di A (o B) indipendentemente dal valore di B (o A). Si ottiene integrando la funzione di densità congiunta sull’intero intervallo di valori dell’altra variabile.\nProbabilità condizionale \\(p(A \\mid B)\\): esprime la probabilità di A dato B. Si calcola dividendo la probabilità congiunta per la probabilità marginale di B, applicando la definizione di probabilità condizionale anche nel contesto continuo.\n\nLa transizione dal trattamento delle variabili discrete a quello delle variabili continue richiede un cambiamento di strumenti matematici da somme ad integrali, ma i concetti fondamentali di probabilità congiunta, marginale e condizionale rimangono applicabili.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#riflessioni-conclusive",
    "href": "chapters/probability/09_joint_prob.html#riflessioni-conclusive",
    "title": "33  Probabilità congiunta",
    "section": "33.9 Riflessioni Conclusive",
    "text": "33.9 Riflessioni Conclusive\nIn alcune situazioni, ogni singolo elemento di una popolazione può essere associato a diverse variabili casuali. Ad esempio, consideriamo l’elenco di tutti gli studenti iscritti a un’università e immaginiamo di selezionare uno studente a caso per misurare la sua altezza e il suo peso. In questo caso, ogni individuo della popolazione è associato a due variabili casuali, l’altezza e il peso. Quando si hanno due o più variabili casuali associate ad ogni elemento di una popolazione, è possibile studiare la distribuzione congiunta di tali variabili casuali. In questo capitolo abbiamo esaminato come rappresentare la distribuzione di massa di probabilità congiunta di due variabili casuali discrete e come ottenere le distribuzioni marginali delle due variabili. Inoltre, abbiamo discusso i concetti di incorrelazione e indipendenza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/09_joint_prob.html#informazioni-sullambiente-di-sviluppo",
    "title": "33  Probabilità congiunta",
    "section": "33.10 Informazioni sull’Ambiente di Sviluppo",
    "text": "33.10 Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.16.0       MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2\n#&gt;  [5] ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0  \n#&gt;  [9] bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0      markdown_1.13    \n#&gt; [13] knitr_1.49        lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1    \n#&gt; [17] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#&gt; [21] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [25] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1  farver_2.1.2      fastmap_1.2.0     pacman_0.5.1     \n#&gt;  [5] promises_1.3.1    rpart_4.1.23      digest_0.6.37     timechange_0.3.0 \n#&gt;  [9] mime_0.12         lifecycle_1.0.4   survival_3.7-0    magrittr_2.0.3   \n#&gt; [13] compiler_4.4.2    rlang_1.1.4       tools_4.4.2       utf8_1.2.4       \n#&gt; [17] yaml_2.3.10       ggsignif_0.6.4    htmlwidgets_1.6.4 mnormt_2.1.1     \n#&gt; [21] abind_1.4-8       miniUI_0.1.1.1    withr_3.0.2       nnet_7.3-19      \n#&gt; [25] grid_4.4.2        fansi_1.0.6       jomo_2.7-6        xtable_1.8-4     \n#&gt; [29] colorspace_2.1-1  iterators_1.0.14  cli_3.6.3         rmarkdown_2.29   \n#&gt; [33] generics_0.1.3    tzdb_0.4.0        minqa_1.2.8       splines_4.4.2    \n#&gt; [37] parallel_4.4.2    vctrs_0.6.5       boot_1.3-31       glmnet_4.1-8     \n#&gt; [41] Matrix_1.7-1      jsonlite_1.8.9    carData_3.0-5     car_3.1-3        \n#&gt; [45] hms_1.1.3         mitml_0.4-5       rstatix_0.7.2     Formula_1.2-5    \n#&gt; [49] foreach_1.5.2     glue_1.8.0        pan_1.9           nloptr_2.1.1     \n#&gt; [53] codetools_0.2-20  stringi_1.8.4     gtable_0.3.6      shape_1.4.6.1    \n#&gt; [57] later_1.4.0       lme4_1.1-35.5     munsell_0.5.1     pillar_1.9.0     \n#&gt; [61] htmltools_0.5.8.1 R6_2.5.1          rprojroot_2.0.4   evaluate_1.0.1   \n#&gt; [65] shiny_1.9.1       lattice_0.22-6    backports_1.5.0   broom_1.0.7      \n#&gt; [69] httpuv_1.6.15     Rcpp_1.0.13-1     nlme_3.1-166      xfun_0.49        \n#&gt; [73] pkgconfig_2.0.3",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#bibliografia",
    "href": "chapters/probability/09_joint_prob.html#bibliografia",
    "title": "33  Probabilità congiunta",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nMartin, O. (2024). Bayesian analysis with python. Packt Publishing Ltd.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_density_func.html",
    "href": "chapters/probability/10_density_func.html",
    "title": "34  La funzione di densità di probabilità",
    "section": "",
    "text": "Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nPreparazione del Notebook\nIn precedenza abbiamo trattato solo variabili casuali discrete, ossia variabili che assumono solo valori interi. Tuttavia, se vogliamo rappresentare grandezze come lunghezze, volumi, distanze o qualsiasi altra proprietà continua del mondo fisico o psicologico, è necessario generalizzare l’approccio utilizzato finora.\nLe variabili casuali continue assumono valori reali, e l’insieme dei numeri reali è non numerabile in quanto è più grande dell’insieme degli interi.1 Le leggi della probabilità valgono sia per le variabili casuali discrete che per quelle continue. Tuttavia, la nozione di funzione di massa di probabilità deve essere sostituita dal suo equivalente continuo, la funzione di densità di probabilità. In questo capitolo, il nostro obiettivo è chiarire il significato di questa nozione.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>La funzione di densità di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_density_func.html#spinner-e-variabili-casuali-continue-uniformi",
    "href": "chapters/probability/10_density_func.html#spinner-e-variabili-casuali-continue-uniformi",
    "title": "34  La funzione di densità di probabilità",
    "section": "34.1 Spinner e variabili casuali continue uniformi",
    "text": "34.1 Spinner e variabili casuali continue uniformi\nConsideriamo l’esperimento casuale in cui facciamo ruotare ad alta velocità uno spinner simmetrico imperniato su un goniometro e osserviamo la posizione in cui si ferma, identificata dall’angolo acuto con segno tra il suo asse e l’asse orizzontale del goniometro. Denotiamo con \\(\\Theta\\) la variabile casuale corrispondente alla “pendenza dello spinner”. In questo contesto, l’assunzione che lo spinner sia simmetrico implica che, in ogni prova, la rotazione produce un angolo qualunque da 0 a 360 gradi con la stessa probabilità. In altre parole, un valore \\(\\Theta\\) compreso tra 0 e 36 gradi ha la stessa probabilità di essere osservato di un valore \\(\\Theta\\) compreso tra 200 e 236 gradi. Inoltre, dal momento che 36 gradi corrisponde a un decimo del percorso intorno al cerchio, la probabilità di ottenere un qualsiasi intervallo di 36 gradi sarà sempre uguale al 10%. Più precisamente, si ha \\(P(0 \\leq \\Theta \\leq 36) = \\frac{1}{10}\\) e \\(P(200 \\leq \\Theta \\leq 236) = \\frac{1}{10}\\).\nÈ importante sottolineare che le probabilità sopra menzionate non si riferiscono al fatto che la variabile casuale \\(\\Theta\\) assuma un valore specifico, ma piuttosto all’evento di osservare \\(\\Theta\\) in un intervallo di valori. In generale, la probabilità che la pendenza \\(\\Theta\\) cada in un intervallo specificato è data dalla frazione del cerchio rappresentata dall’intervallo, cioè \\(P(\\theta_1 \\leq \\Theta \\leq \\theta_2) = \\frac{\\theta_2 - \\theta_1}{360}\\), per ogni intervallo \\([\\theta_1, \\theta_2]\\) tale che \\(0 \\leq \\theta_1 \\leq \\theta_2 \\leq 360\\).\nNel caso di una variabile casuale continua, come l’angolo dello spinner, dunque, è facile capire come assegnare una probabilità all’evento in cui la variabile casuale assuma un valore compreso in un intervallo.\n\n34.1.1 Distribuzione uniforme\nL’esempio dello spinner rappresenta il “meccanismo generatore dei dati” della variabile casuale continua più semplice, ovvero la distribuzione continua uniforme. In teoria della probabilità, la distribuzione continua uniforme è una distribuzione di probabilità continua che assegna la stessa probabilità a tutti i punti appartenenti ad un intervallo [a, b] contenuto in un certo insieme.\nLa distribuzione uniforme continua definita sull’intervallo \\({\\displaystyle S=[a,b]\\subset \\mathbb {R}}\\) viene denotata con \\({\\displaystyle {\\mathcal {U}}(a,b)={\\mathcal {U}}([a,b])}\\). La sua densità di probabilità è\n\\[\nf(x) = \\frac{1}{b-a}, \\quad a \\leq x \\leq b\n\\]\ne 0 altrimenti. La distribuzione uniforme continua è caratterizzata dalla sua proprietà di equidistribuzione: tutti gli intervalli di pari lunghezza all’interno dell’intervallo [a, b] hanno la stessa probabilità. In altre parole, se \\({\\displaystyle [c,d]}\\) è un sottointervallo di \\({\\displaystyle [a,b]}\\), allora la probabilità che una variabile casuale continua con distribuzione uniforme in \\({\\displaystyle [a,b]}\\) cada in \\({\\displaystyle [c,d]}\\) è \\({\\displaystyle (d-c)/(b-a)}\\).\nSvolgiamo un esercizio con R in cui, per continuare il nostro esempio dello spinner, consideriamo una \\(\\mathcal {U}(0, 360)\\).\n\n# Definire i parametri della distribuzione uniforme\na &lt;- 0\nb &lt;- 360\nsize &lt;- 101\nx &lt;- seq(a, b, length.out = size)\ny &lt;- dunif(x, min = a, max = b)\n\ndata &lt;- data.frame(X = x, Density = y)\n\nggplot(data, aes(x = X, y = Density)) +\n  geom_line() +\n  labs(\n    x = \"X\",\n    y = \"Densità\",\n    title = \"Distribuzione Uniforme\"\n  ) \n\n\n\n\n\n\n\n\nGeneriamo 100,000 valori casuali di una v.c. \\(\\Theta \\sim \\mathcal {U}(0, 360)\\).\n\n# Generare dati da una distribuzione uniforme tra 0 e 360\ndata &lt;- runif(100000, min = 0, max = 360)\n\nL’istogramma delle 100,000 realizzazioni di \\(\\Theta\\) è il seguente.\n\ndf &lt;- data.frame(Theta = data)\n\nggplot(df, aes(x = Theta)) +\n  geom_histogram(\n    aes(y = ..density..),\n    bins = 30,\n    fill = \"blue\",\n    alpha = 0.5\n  ) +\n  labs(\n    x = expression(Theta ~ U(0, 360)),\n    y = \"Densità\",\n    title = \"Distribuzione uniforme\"\n  )\n#&gt; Warning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `after_stat(density)` instead.\n\n\n\n\n\n\n\n\nÈ chiaro che, all’aumentare del numero delle realizzazioni \\(\\Theta\\), il profilo dell’istogramma tenderà a diventare una linea retta. Ciò significa che la funzione di densità di una variabile casuale uniforme continua è una costante: \\(f(\\Theta) = c\\).\nDalla figura precedente vediamo che l’area sottesa alla funzione di densità è \\((b - a)\\cdot c\\). Dato che tale area deve essere unitaria, ovvero, \\((b - a) \\cdot c = 1\\), possiamo trovare \\(c\\) dividendo entrambi i termini per \\(b - a\\),\n\\[\nc  = \\frac{\\displaystyle{1}}{\\displaystyle b - a}.\n\\]\nOvvero, se \\(\\Theta \\sim \\mathcal{U}(a, b)\\), allora\n\\[\np_{\\Theta}(\\theta) = \\mathcal{U}(\\theta \\mid a, b),\n\\]\nladdove\n\\[\n\\mathcal{U}(\\theta \\mid a, b) = \\frac{1}{b - a}.\n\\]\nIn conclusione, la densità di una variabile casuale uniforme continua non dipende da \\(\\theta\\) – è costante e identica per ogni possibile valore \\(\\theta\\).\nIl valore atteso di \\(X \\sim \\mathcal {U}(a,b)\\) è dato da\n\\[\n\\mathbb{E} = \\frac{b - a}{2}.\n\\]\nNel caso della presente simulazione otteniamo\n\nmean(df$Theta)\n#&gt; [1] 180.2548\n\nSvolgiamo un altro semplice esercizio. Consideriamo una variabile casuale uniforme \\(X\\) definita sull’intervallo [0, 100]. Poniamoci il problema di trovare la probabilità \\(P(20 &lt; X &lt; 60)\\).\nPer trovare la soluzione è sufficiente calcolare l’area di un rettangolo di base \\(60 - 20 = 40\\) e di altezza 1/100. La probabilità cercata è dunque \\(P(20 &lt; X &lt; 60) = 40 \\cdot 0.01 = 0.4\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>La funzione di densità di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_density_func.html#il-paradosso-delle-variabili-casuali-continue",
    "href": "chapters/probability/10_density_func.html#il-paradosso-delle-variabili-casuali-continue",
    "title": "34  La funzione di densità di probabilità",
    "section": "34.2 Il paradosso delle variabili casuali continue",
    "text": "34.2 Il paradosso delle variabili casuali continue\nConsideriamo ora la probabilità che la variabile casuale continua assuma un valore specifico, come ad esempio una pendenza dello spinner esattamente uguale a 36 gradi. Sorprendentemente, la risposta è zero:\n\\[\nP(\\Theta = 36) = 0.\n\\]\nCiò è dovuto al fatto che se la probabilità di un valore specifico fosse maggiore di zero, allora ogni altro possibile valore dovrebbe avere la stessa probabilità, poiché abbiamo assunto che tutti i valori \\(\\Theta\\) sono egualmente probabili. Ma se sommiamo tutte queste probabilità, il totale sarebbe maggiore di uno, il che è impossibile.\nNel caso delle variabili casuali continue, dobbiamo quindi rinunciare all’idea che ogni singolo valore della variabile casuale possa avere una massa di probabilità maggiore di zero. Invece, una massa di probabilità viene assegnata alla realizzazione della variabile casuale in un intervallo di valori. Questo è ciò che differenzia le variabili casuali continue dalle variabili casuali discrete, dove ogni singolo valore ha una probabilità di massa non nulla. In sintesi, le variabili casuali continue non hanno una massa di probabilità, ma una densità di probabilità.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>La funzione di densità di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_density_func.html#dagli-istogrammi-alle-densità",
    "href": "chapters/probability/10_density_func.html#dagli-istogrammi-alle-densità",
    "title": "34  La funzione di densità di probabilità",
    "section": "34.3 Dagli istogrammi alle densità",
    "text": "34.3 Dagli istogrammi alle densità\nLe considerazioni precedenti ci fanno comprendere che, a differenza delle variabili casuali discrete, non esiste l’equivalente di una funzione di massa di probabilità per le variabili casuali continue. Invece, esiste una funzione di densità di probabilità che può essere definita in termini di una simulazione. Considerando un numero enorme di casi e facendo tendere l’ampiezza \\(\\Delta\\) di ciascuna classe a 0, il profilo dell’istogramma delle frequenze delle classi di ampiezza \\(\\Delta\\) tende a diventare una curva continua. Tale curva continua \\(f(x)\\) è detta funzione di densità di probabilità.\nIn un istogramma, l’area di ogni barra è proporzionale alla frequenza relativa delle osservazioni nell’intervallo considerato. Dato che tutti gli intervalli hanno la stessa ampiezza, l’altezza di ogni barra sarà proporzionale alla frequenza relativa delle osservazioni nell’intervallo. Nella simulazione, possiamo pensare all’area di ciascuna barra dell’istogramma come alla stima della probabilità che la variabile casuale assuma un valore nell’intervallo considerato. Con l’aumentare del numero di osservazioni \\(M\\), le probabilità stimate si avvicinano sempre di più ai valori effettivi della probabilità. Inoltre, all’aumentare del numero degli intervalli (quando l’ampiezza \\(\\Delta\\) dell’intervallo tende a 0), il profilo dell’istogramma tende a diventare una curva continua. Tale curva continua è appunto la funzione di densità di probabilità della variabile casuale.\nIn precedenza, nella statistica descrittiva, abbiamo già incontrato una rappresentazione che ha lo stesso significato della funzione di densità, ovvero il kernel density plot. La stima della densità del kernel (KDE), infatti, è un metodo non parametrico utilizzato per stimare la funzione di densità di probabilità di una variabile casuale.\nPer fare un esempio, generiamo 50 valori dalla distribuzione del quoziente di intelligenza. Stampiamo i primi 5 valori.\n\n# Definire i parametri della distribuzione normale\nmu &lt;- 100\nsigma &lt;- 15\nsize &lt;- 50\n\n# Generare i dati\nset.seed(123)  # Per riproducibilità\nx &lt;- rnorm(size, mean = mu, sd = sigma)\n\n# Mostrare i primi 5 valori\nhead(x, 5)\n#&gt; [1]  91.59287  96.54734 123.38062 101.05763 101.93932\n\nCreiamo ora un istogramma a cui sovrapponiamo la funzione di densità Normale con parametri corrispondenti alla media e deviazione standard del campione. Con poche osservazioni, non c’è una buona corrispondenza tra l’istogramma e la curva continua che abbiamo chiamato “funzione di densità”.\n\n# Calcolare la media e la deviazione standard dei dati\nmu &lt;- mean(x)\nstd &lt;- sd(x)\n\n# Creare un grafico dell'istogramma e della curva di densità\n\ndata_frame &lt;- data.frame(X = x)\nxmin &lt;- min(x)\nxmax &lt;- max(x)\ndensity_data &lt;- data.frame(\n  X = seq(xmin, xmax, length.out = 100),\n  Density = dnorm(seq(xmin, xmax, length.out = 100), mean = mu, sd = std)\n)\n\nggplot(data_frame, aes(x = X)) +\n  geom_histogram(\n    aes(y = ..density..),\n    bins = 25,\n    fill = \"blue\",\n    alpha = 0.6\n  ) +\n  geom_line(\n    data = density_data,\n    aes(x = X, y = Density),\n    color = \"black\",\n    size = 1\n  ) +\n  labs(\n    title = sprintf(\"Media e deviazione standard: %.2f e %.2f\", mu, std),\n    x = \"Valori\",\n    y = \"Densità\"\n  )\n#&gt; Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\nOra aumentiamo il numero di osservazioni. In questo caso consideriamo 20,000 valori del QI. Generiamo dunque una figura simile alla precedente, solo considerando un campione di dati più grande.\n\n# Generare dati normali\nsize &lt;- 10000\nset.seed(123)  # Per riproducibilità\nx &lt;- rnorm(size, mean = mu, sd = std)\n\n# Calcolare la media e la deviazione standard dei dati\nmu &lt;- mean(x)\nstd &lt;- sd(x)\n\n# Creare il grafico dell'istogramma e della curva di densità\n\ndata_frame &lt;- data.frame(X = x)\nxmin &lt;- min(x)\nxmax &lt;- max(x)\ndensity_data &lt;- data.frame(\n  X = seq(xmin, xmax, length.out = 100),\n  Density = dnorm(seq(xmin, xmax, length.out = 100), mean = mu, sd = std)\n)\n\nggplot(data_frame, aes(x = X)) +\n  geom_histogram(\n    aes(y = ..density..),\n    bins = 50,\n    fill = \"blue\",\n    alpha = 0.6\n  ) +\n  geom_line(\n    data = density_data,\n    aes(x = X, y = Density),\n    color = \"black\",\n    size = 1\n  ) +\n  labs(\n    title = sprintf(\"Media e deviazione standard: %.2f e %.2f\", mu, std),\n    x = \"Valori\",\n    y = \"Densità\"\n  )\n\n\n\n\n\n\n\n\nOra vediamo che c’è una corrispondenza molto buona tra il profilo dell’istogramma e la curva continua. Questo ci consente la seguente interpretazione: la funzione di densità è una curva che approssima il profilo di un istogramma, quando consideriamo un grande numero di osservazioni. In altre parole, una funzione di densità non è altro che un (profilo di un) istogramma nel caso di un numero infinito di osservazioni e intervalli di ampiezza \\(\\Delta\\) infinitamente piccoli.\nIn un istogramma, l’area di ciascuna barra è proporzionale alla frequenza relativa delle osservazioni in quel’intervallo. Perché tutti gli intervalli hanno la stessa ampiezza, anche l’altezza di ciascuna barra sarà proporzionale alla frequenza relativa delle osservazioni in quel’intervallo.\nNella simulazione, possiamo pensare all’area di ciascuna barra dell’istogramma come alla stima della probabilità che la variabile casuale assuma un valore compreso nell’intervallo considerato. All’aumentare del numero \\(M\\) di osservazioni, le probabilità stimate si avvicinano sempre di più ai veri valori della probabilità. All’aumentare del numero degli intervalli (quando l’ampiezza \\(\\Delta\\) dell’intervallo \\(\\rightarrow\\) 0), il profilo dell’istogramma tende a diventare una curva continua. Tale curva continua è la funzione di densità di probabilità della variabile casuale.\nNella statistica descrittiva abbiamo già incontrato una rappresentazione che ha lo stesso significato della funzione di densità, ovvero il kernel density plot. La stima della densità del kernel (KDE), infatti, è un metodo non parametrico per stimare la funzione di densità di probabilità di una variabile casuale.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>La funzione di densità di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_density_func.html#interpretazioni-bayesiana-e-frequentista-della-funzione-di-densità-di-probabilità-pdf",
    "href": "chapters/probability/10_density_func.html#interpretazioni-bayesiana-e-frequentista-della-funzione-di-densità-di-probabilità-pdf",
    "title": "34  La funzione di densità di probabilità",
    "section": "34.4 Interpretazioni Bayesiana e Frequentista della Funzione di Densità di Probabilità (PDF)",
    "text": "34.4 Interpretazioni Bayesiana e Frequentista della Funzione di Densità di Probabilità (PDF)\nAbbiamo introdotto la funzione di densità di probabilità come limite del profilo di un istogramma, una descrizione intuitiva e utile per comprendere il concetto di densità. Questa interpretazione corrisponde, tuttavia, alla visione frequentista della densità di probabilità. Nella statistica Bayesiana, l’interpretazione è diversa e merita una spiegazione separata.\nNell’approccio Bayesiano, un parametro è considerato una “variabile casuale” che segue una distribuzione di valori, anziché un valore fisso. La Figura 34.1, vedi 34.1 illustra le diverse interpretazioni di una PDF per una quantità reale \\(x\\). Queste interpretazioni valgono sia che \\(x\\) rappresenti un parametro incognito sia che si tratti di un dato osservato.\nNel pannello di sinistra, vediamo l’interpretazione frequentista di \\(p(x)\\): la PDF rappresenta una collezione ipotetica di ripetizioni di esperimenti, in cui \\(x\\) può assumere diversi valori. La PDF corrisponde quindi a un istogramma limite di questi valori, distribuiti secondo \\(p(x)\\).\nIl pannello di destra, invece, raffigura l’interpretazione Bayesiana, in cui la PDF rappresenta l’incertezza sul valore di \\(x\\) per un singolo caso specifico. In questo caso, la probabilità si distribuisce lungo i possibili valori che \\(x\\) potrebbe assumere, visualizzata dalla sfumatura lungo l’asse \\(x\\).\nIn altre parole, nell’interpretazione frequentista, è il valore di \\(x\\) a essere distribuito in \\(p(x)\\) (attraverso ripetizioni dell’esperimento), mentre nell’interpretazione Bayesiana è la probabilità stessa a distribuirsi sui possibili valori di \\(x\\) nel caso analizzato. Una PDF Bayesiana può essere vista come analoga a una densità di materia \\(\\rho(x)\\) in meccanica classica: è la probabilità che si distribuisce lungo i possibili valori, e non i valori stessi di \\(x\\).\n\n\n\n\n\n\nFigura 34.1: Interpretazioni frequentista e bayesiana di una PDF (curva blu) per una quantità reale \\(x\\). A sinistra: interpretazione frequentista come istogramma limite dei valori di \\(x\\) nelle ripetizioni; i valori di \\(x\\) sono distribuiti secondo la PDF. A destra: interpretazione bayesiana, con \\(x\\) che assume un valore fisso ma incerto per il caso specifico (rappresentato dal punto sull’asse \\(x\\)), con la probabilità distribuita sui valori possibili (raffigurata con una sfumatura lungo l’asse \\(x\\)). (Figura tratta da Loredo & Wolpert, 2024)",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>La funzione di densità di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_density_func.html#funzione-di-densità-di-probabilità",
    "href": "chapters/probability/10_density_func.html#funzione-di-densità-di-probabilità",
    "title": "34  La funzione di densità di probabilità",
    "section": "34.5 Funzione di densità di probabilità",
    "text": "34.5 Funzione di densità di probabilità\nDa un punto di vista matematico, l’intuizione precedente si può esprimere nel modo seguente.\nPer descrivere le probabilità che possono essere associate ad una variabile casuale continua \\(X\\) è necessario definire una funzione \\(p(X)\\) che deve soddisfare le seguenti due proprietà:\n\n\\(p(x) \\geq 0, \\forall x\\), ovvero, l’ordinata della funzione di densità è 0 o positiva;\n\\(\\int_{-\\infty}^{\\infty} p(x) \\,\\operatorname {d}\\!x = 1\\), ovvero, l’area sottesa dalla \\(p(x)\\) è unitaria2;\n\\(p(a &lt; x &lt; b) = \\int_a^b p(x) \\,\\operatorname {d}\\!x\\), se \\(a \\leq b\\), ovvero, l’area sottesa dalla \\(p(y)\\) tra due punti \\(a\\) e \\(b\\) corrisponde alla probabilità che la v.c. \\(x\\) assuma un valore compresto tra questi due estremi.\n\nInterpretazione. È possibile che \\(p(x) &gt; 1\\), quindi una densità di probabilità non può essere interpretata come una probabilità. Piuttosto, la densità \\(p(x)\\) può essere utilizzata per confrontare la credibilità relativa che può essere assegnata a diversi valori \\(x\\). Considerata una variabile casuale \\(X\\) di cui è disponibile un insieme di realizzazioni, possiamo dire che, se consideriamo due valori \\(x_k\\) e \\(x_l\\) con \\(p(x_k) &gt; p(x_l)\\), allora possiamo concludere che è più credibile, in termini relativi, osservare realizzazioni \\(X\\) nell’intorno di \\(x_k\\) piuttosto che nell’intorno di \\(x_l\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>La funzione di densità di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_density_func.html#la-funzione-di-ripartizione-per-una-variabile-casuale-continua",
    "href": "chapters/probability/10_density_func.html#la-funzione-di-ripartizione-per-una-variabile-casuale-continua",
    "title": "34  La funzione di densità di probabilità",
    "section": "34.6 La funzione di ripartizione per una variabile casuale continua",
    "text": "34.6 La funzione di ripartizione per una variabile casuale continua\nPer le variabili casuali continue, la funzione di ripartizione (ovvero, la distribuzione cumulativa) è definita esattamente come nel caso delle variabili casuali discrete:\n\\[\nF_{\\Theta}(\\theta) = P(\\Theta \\leq \\theta).\n\\]\nCioè, è la probabilità che la variabile casuale \\(\\Theta\\) assuma un valore minore di o uguale a \\(\\theta\\).\nCome nel caso discreto, la funzione di ripartizione di una v.c. continua può essere utilizzata per calcolare la probabilità che la v.c. assuma valori in un certo intervallo.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>La funzione di densità di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_density_func.html#riflessioni-conclusive",
    "href": "chapters/probability/10_density_func.html#riflessioni-conclusive",
    "title": "34  La funzione di densità di probabilità",
    "section": "34.7 Riflessioni Conclusive",
    "text": "34.7 Riflessioni Conclusive\nLa funzione di densità di probabilità (PDF) è uno strumento fondamentale per descrivere distribuzioni di variabili continue. Un principio essenziale alla base di questa funzione è che la probabilità che una variabile aleatoria continua assuma un valore esatto è pari a zero. Matematicamente, ciò deriva dal fatto che l’area sotto la curva di densità in un punto singolo è sempre zero.\nQuesta concezione implica due conseguenze importanti:\n\nLa probabilità può essere calcolata solo per intervalli di valori, non per punti specifici.\nEventi con probabilità zero non sono necessariamente impossibili.\n\nDa questa seconda implicazione emerge un apparente paradosso: come possiamo conciliare il fatto che eventi osservabili (ad esempio, colpire il centro esatto di un bersaglio) abbiano probabilità zero?\nQuesto paradosso solleva due domande cruciali:\n\nÈ possibile confrontare le “possibilità” di eventi diversi che hanno tutti probabilità zero?\nCome può l’unione di infiniti eventi con probabilità zero (ogni punto specifico di un intervallo) dare origine a un evento certo (scegliere un punto qualsiasi nell’intervallo)?\n\nIl “paradosso della probabilità zero” richiama alla mente il famoso paradosso di Zenone sulla freccia: se in ogni istante la freccia è ferma, come può essa muoversi? In entrambi i casi, siamo posti di fronte a una sfida concettuale: come può una somma di “nulla” (eventi con probabilità zero) dare origine a “qualcosa” (un evento con probabilità certa)?\nUna soluzione moderna a questo enigma è emersa negli anni ’60 con il lavoro di Abraham Robinson sugli infinitesimi. Gli infinitesimi sono numeri infinitamente piccoli ma non nulli, che esistono tra zero e qualsiasi numero positivo reale. Questa teoria consente di assegnare probabilità infinitesimali a eventi che, nella teoria classica, avrebbero probabilità zero.\nApplicando questa idea al nostro paradosso, possiamo concludere che:\n\nLa probabilità di colpire un punto specifico non è zero, ma infinitesimale.\nLa probabilità di colpire uno tra due punti specifici è maggiore di quella di colpire un singolo punto, anche se la differenza è infinitesimale.\n\nQuesto approccio risolve il paradosso permettendo di distinguere tra eventi che nella teoria classica erano tutti assegnati a probabilità zero. Inoltre, spiega come l’unione di molti eventi con probabilità infinitesimale possa portare a un evento con probabilità uno.\nL’introduzione degli infinitesimi non è solo un artificio matematico, ma rappresenta un ritorno alle idee originarie di Newton e Leibniz, fornendo una base rigorosa per trattare l’infinitamente piccolo in matematica. Questa teoria offre un nuovo modo di concepire concetti come l’infinito e la continuità, con applicazioni che si estendono ben oltre la teoria della probabilità.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>La funzione di densità di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_density_func.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/10_density_func.html#informazioni-sullambiente-di-sviluppo",
    "title": "34  La funzione di densità di probabilità",
    "section": "34.8 Informazioni sull’Ambiente di Sviluppo",
    "text": "34.8 Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.16.0       MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2\n#&gt;  [5] ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0  \n#&gt;  [9] bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0      markdown_1.13    \n#&gt; [13] knitr_1.49        lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1    \n#&gt; [17] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#&gt; [21] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [25] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1  farver_2.1.2      fastmap_1.2.0     pacman_0.5.1     \n#&gt;  [5] promises_1.3.1    rpart_4.1.23      digest_0.6.37     timechange_0.3.0 \n#&gt;  [9] mime_0.12         lifecycle_1.0.4   survival_3.7-0    magrittr_2.0.3   \n#&gt; [13] compiler_4.4.2    rlang_1.1.4       tools_4.4.2       utf8_1.2.4       \n#&gt; [17] yaml_2.3.10       ggsignif_0.6.4    labeling_0.4.3    htmlwidgets_1.6.4\n#&gt; [21] mnormt_2.1.1      abind_1.4-8       miniUI_0.1.1.1    withr_3.0.2      \n#&gt; [25] nnet_7.3-19       grid_4.4.2        fansi_1.0.6       jomo_2.7-6       \n#&gt; [29] xtable_1.8-4      colorspace_2.1-1  iterators_1.0.14  cli_3.6.3        \n#&gt; [33] rmarkdown_2.29    generics_0.1.3    tzdb_0.4.0        minqa_1.2.8      \n#&gt; [37] splines_4.4.2     parallel_4.4.2    vctrs_0.6.5       boot_1.3-31      \n#&gt; [41] glmnet_4.1-8      Matrix_1.7-1      jsonlite_1.8.9    carData_3.0-5    \n#&gt; [45] car_3.1-3         hms_1.1.3         mitml_0.4-5       rstatix_0.7.2    \n#&gt; [49] Formula_1.2-5     foreach_1.5.2     glue_1.8.0        pan_1.9          \n#&gt; [53] nloptr_2.1.1      codetools_0.2-20  stringi_1.8.4     gtable_0.3.6     \n#&gt; [57] shape_1.4.6.1     later_1.4.0       lme4_1.1-35.5     munsell_0.5.1    \n#&gt; [61] pillar_1.9.0      htmltools_0.5.8.1 R6_2.5.1          rprojroot_2.0.4  \n#&gt; [65] evaluate_1.0.1    shiny_1.9.1       lattice_0.22-6    backports_1.5.0  \n#&gt; [69] broom_1.0.7       httpuv_1.6.15     Rcpp_1.0.13-1     nlme_3.1-166     \n#&gt; [73] xfun_0.49         pkgconfig_2.0.3",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>La funzione di densità di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_density_func.html#bibliografia",
    "href": "chapters/probability/10_density_func.html#bibliografia",
    "title": "34  La funzione di densità di probabilità",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nLoredo, T. J., & Wolpert, R. L. (2024). Bayesian inference: more than Bayes’s theorem. Frontiers in Astronomy and Space Sciences, 11, 1326926.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>La funzione di densità di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_density_func.html#footnotes",
    "href": "chapters/probability/10_density_func.html#footnotes",
    "title": "34  La funzione di densità di probabilità",
    "section": "",
    "text": "Georg Cantor dimostrò che era impossibile mappare uno a uno i reali negli interi, dimostrando così che l’insieme dei reali è non numerabile.↩︎\nPer quel che riguarda la notazione dell’integrale, ovvero \\(\\int_x \\,\\operatorname {d}\\!x\\), rimando alla discussione di S.P. Thompson: https://calculusmadeeasy.org/1.html↩︎",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>La funzione di densità di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html",
    "href": "chapters/probability/11_discr_rv_distr.html",
    "title": "35  Distribuzioni di v.c. discrete",
    "section": "",
    "text": "35.1 Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nPreparazione del Notebook\nLa previsione è un processo che ci permette di formulare ipotesi su eventi incerti, sfruttando le regolarità osservate nei processi naturali, sociali e psicologici. Uno degli obiettivi principali della data science è proprio quello di prevedere fenomeni di cui non abbiamo ancora certezza, inclusi, ma non limitati a, eventi futuri.\nLa capacità di fare previsioni senza considerare ogni possibile risultato dipende dalla conoscenza della popolazione di riferimento. Gli esseri umani organizzano e rappresentano questa conoscenza in vari modi. In questo capitolo, esploreremo le implicazioni di un approccio specifico alla rappresentazione delle popolazioni: le distribuzioni di probabilità.\nSupponiamo di avere una distribuzione di probabilità \\(p(x)\\) associata a una variabile casuale \\(X\\). Consideriamo che questa distribuzione rappresenti la variabilità osservata all’interno di una popolazione. Se selezionassimo un’istanza in modo uniforme e casuale dalla popolazione, quale valore della variabile \\(X\\) dovremmo aspettarci? Ci aspettiamo che un campione estratto casualmente dalla popolazione segua la distribuzione \\(p(x)\\). In altre parole, questa distribuzione è ciò che definiamo un modello statistico, o più semplicemente, un modello della popolazione. Il termine “modello” sottolinea che la distribuzione non è la popolazione stessa, ma una rappresentazione astratta che utilizziamo per fare previsioni.\nIn particolare, ci concentreremo sulle distribuzioni di probabilità discrete, essenziali per comprendere i fenomeni aleatori che presentano un numero finito o numerabile di esiti. Queste distribuzioni sono cruciali nella modellazione e nell’analisi di eventi che si verificano in contesti discreti, fornendo le basi per una comprensione più profonda delle dinamiche probabilistiche che governano tali fenomeni.\nOgni distribuzione di probabilità è caratterizzata da uno o più parametri, che consentono di controllare specifici aspetti della distribuzione stessa. Esploreremo diverse distribuzioni discrete, ciascuna con le sue caratteristiche e applicazioni:\nIn sintesi, attraverso lo studio di queste distribuzioni, acquisiremo gli strumenti necessari per analizzare e prevedere una vasta gamma di situazioni reali.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#introduzione",
    "href": "chapters/probability/11_discr_rv_distr.html#introduzione",
    "title": "35  Distribuzioni di v.c. discrete",
    "section": "",
    "text": "Distribuzione di Bernoulli\n\nRappresenta esperimenti con due possibili esiti: “successo” o “insuccesso”\nCostituisce il nucleo dei processi Bernoulliani\nParametro chiave: probabilità di successo in ciascuna prova\n\nDistribuzione Binomiale\n\nDescrive il numero totale di successi in un numero fisso di prove Bernoulliane\nNasce dalla somma di prove Bernoulliane indipendenti\nParametri: probabilità di successo in ciascuna prova e numero totale di prove\n\nDistribuzione di Poisson\n\nModella eventi rari o che si verificano su intervalli di tempo o spazio variabili\nAdatta quando il numero di prove è una variabile casuale\nParametro: tasso medio di successo per unità di tempo o spazio\n\nDistribuzione Beta-Binomiale\n\nUtilizzata quando la probabilità di successo in una serie di prove Bernoulliane non è costante\nOffre una rappresentazione più flessibile rispetto alla distribuzione binomiale\nParametri: derivati dalla distribuzione Beta sottostante\n\nDistribuzione Uniforme Discreta\n\nOgni evento all’interno di un determinato intervallo finito ha la stessa probabilità\nUtile quando non ci sono motivi per privilegiare un risultato rispetto a un altro\nNon dipende da parametri una volta stabilito il supporto della distribuzione",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#distribuzione-di-bernoulli",
    "href": "chapters/probability/11_discr_rv_distr.html#distribuzione-di-bernoulli",
    "title": "35  Distribuzioni di v.c. discrete",
    "section": "35.2 Distribuzione di Bernoulli",
    "text": "35.2 Distribuzione di Bernoulli\nIn statistica, un esperimento che ammette solo due esiti possibili è modellato attraverso quella che viene chiamata “prova Bernoulliana”. Un esempio tipico è il lancio di una moneta, che può dare come risultato testa o croce.\n\nDefinizione 35.1 Una variabile casuale \\(X\\) che assume valori in \\(\\{0, 1\\}\\) è detta variabile di Bernoulli. La sua distribuzione di probabilità è definita come:\n\\[\nP(X \\mid \\theta) =\n  \\begin{cases}\n    p     & \\text{se $X = 1$ (successo)}, \\\\\n    1 - p & \\text{se $X = 0$ (insuccesso)},\n  \\end{cases}\n\\]\ndove \\(0 \\leq p \\leq 1\\). Il parametro \\(p\\) rappresenta la probabilità del “successo” (\\(X = 1\\)), mentre \\(1 - p\\) è la probabilità dell’“insuccesso” (\\(X = 0\\)).\n\nLa distribuzione di Bernoulli descrive quindi un contesto in cui la probabilità di osservare l’esito 1 è \\(p\\) e quella di osservare l’esito 0 è \\(1 - p\\). Viene utilizzata per modellare situazioni binarie, come una risposta “sì” o “no”, oppure un “successo” o “insuccesso”.\nCalcolando il valore atteso e la varianza, otteniamo:\n\\[\n\\begin{align}\n\\mathbb{E}(X) &= 0 \\cdot P(X=0) + 1 \\cdot P(X=1) = p, \\\\\n\\mathbb{V}(X) &= (0 - p)^2 \\cdot P(X=0) + (1 - p)^2 \\cdot P(X=1) = p(1-p).\n\\end{align}\n\\tag{35.1}\\]\nEsplicitando ulteriormente la formula della varianza con \\(P(YX=0) = 1 - p\\) e \\(P(X=1) = p\\), abbiamo:\n\\[ \\mathbb{V}(X) = (0 - p)^2 \\cdot (1 - p) + (1 - p)^2 \\cdot p \\]\nCalcoliamo ora le singole parti dell’espressione: 1. \\((0 - p)^2 = p^2\\) 2. \\((1 - p)^2 = 1 - 2p + p^2\\)\nSostituendo queste espressioni nell’equazione della varianza, otteniamo:\n\\[ \\mathbb{V}(X) = p^2 \\cdot (1 - p) + (1 - 2p + p^2) \\cdot p \\]\n\\[ \\mathbb{V}(X) = p^2 - p^3 + p - 2p^2 + p^3 \\]\nSemplificando:\n\\[ \\mathbb{V}(X) = p - p^2 \\]\n\\[ \\mathbb{V}(X) = p(1-p). \\]\nIn sintesi, la varianza di una variabile aleatoria binaria \\(X\\), distribuita secondo Bernoulli con parametro \\(p\\), è data da \\(p(1-p)\\). Tale risultato mostra come la varianza massima si ottenga per \\(p = 0.5\\), condizione che corrisponde alla massima incertezza intrinseca nel processo, ossia quando la probabilità di successo eguaglia quella di insuccesso.\n\n# Valori di p tra 0 e 1\np &lt;- seq(0, 1, length.out = 100)\n\n# Varianza della distribuzione di Bernoulli è p * (1 - p)\nvariance &lt;- p * (1 - p)\n\n# Grafico\nplot(p, variance, type = \"l\", col = \"blue\", lwd = 2, \n     xlab = expression(p), ylab = \"Varianza\", \n     main = \"Varianza di una Variabile Bernoulliana in funzione di p\")\n\n\n\n\n\n\n\n\nPer indicare che la variabile casuale \\(X\\) segue una distribuzione Bernoulliana di parametro \\(p\\) Utilizziamo la notazione \\(X \\sim \\mathcal{Bern}(p)\\), o in maniera equivalente \\(\\mathcal{Bern}(X \\mid p)\\).\nAd esempio, nel caso del lancio di una moneta equilibrata, la variabile di Bernoulli assume i valori \\(0\\) e \\(1\\) con uguale probabilità di \\(\\frac{1}{2}\\). Pertanto, la funzione di massa di probabilità assegna una probabilità di \\(\\frac{1}{2}\\) sia per \\(X = 0\\) che per \\(X = 1\\), mentre la funzione di distribuzione cumulativa risulta essere \\(\\frac{1}{2}\\) per \\(X = 0\\) e \\(1\\) per \\(X = 1\\).\nGeneriamo dei valori casuali dalla distribuzione di Bernoulli. Iniziamo con un singolo valore:\n\n# Probabilità di successo\np &lt;- 0.5\n\n# Genera un singolo valore\nbernoulli_sample &lt;- rbinom(n = 1, size = 1, prob = p)\nprint(bernoulli_sample)\n#&gt; [1] 1\n\n# Genera un campione di 10 valori\nbernoulli_sample &lt;- rbinom(n = 10, size = 1, prob = p)\nprint(bernoulli_sample)\n#&gt;  [1] 1 0 1 1 1 1 0 1 1 0",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#distribuzione-binomiale",
    "href": "chapters/probability/11_discr_rv_distr.html#distribuzione-binomiale",
    "title": "35  Distribuzioni di v.c. discrete",
    "section": "35.3 Distribuzione Binomiale",
    "text": "35.3 Distribuzione Binomiale\nLa distribuzione binomiale è una distribuzione di probabilità discreta che modella il numero di successi \\(y\\) in un numero fissato \\(n\\) di prove di Bernoulli indipendenti e identiche, dove ciascuna prova ha solo due esiti possibili: “successo” (rappresentato da “1”) con probabilità \\(p\\) o “insuccesso” (rappresentato da “0”) con probabilità \\(1 - p\\). La notazione utilizzata è la seguente:\n\\[\nY \\sim \\mathcal{Binom}(n, p).\n\\]\n\nDefinizione 35.2 La distribuzione binomiale descrive la probabilità di osservare esattamente \\(y\\) successi in \\(n\\) prove di Bernoulli indipendenti:\n\\[\nP(Y = y) = \\binom{n}{y} p^{y} (1 - p)^{n - y} = \\frac{n!}{y!(n - y)!} p^{y} (1 - p)^{n - y},\n\\tag{35.2}\\]\ndove \\(\\binom{n}{y}\\), noto come coefficiente binomiale, rappresenta il numero di modi possibili per ottenere \\(y\\) successi in \\(n\\) prove, e \\(p\\) è la probabilità di successo in ciascuna prova.\n\nLa distribuzione binomiale si presta bene a esempi classici come il lancio ripetuto di una moneta o l’estrazione di biglie da un’urna. Ad esempio, nel caso del lancio di una moneta, questa distribuzione descrive la probabilità di ottenere un determinato numero di “teste” in un certo numero di lanci, con ogni lancio che segue una distribuzione di Bernoulli con probabilità di successo \\(p\\).\nUna caratteristica interessante della distribuzione binomiale è la sua proprietà di riproducibilità: se due variabili casuali indipendenti, \\(y_1\\) e \\(y_2\\), seguono entrambe distribuzioni binomiali con lo stesso parametro \\(p\\), ma con un diverso numero di prove (\\(n_1\\) e \\(n_2\\)), la loro somma, \\(y = y_1 + y_2\\), sarà ancora distribuita binomialmente, con parametri \\(n_1 + n_2\\) e \\(p\\).\n\n35.3.1 Calcolo delle Probabilità\nPer chiarire il calcolo delle probabilità nella distribuzione binomiale, consideriamo una serie di prove di Bernoulli. Supponiamo di avere \\(n\\) prove, con \\(y\\) successi. La configurazione di questi risultati può essere rappresentata come:\n\\[\n\\overbrace{SS\\dots S}^\\text{$y$ successi} \\overbrace{II\\dots I}^\\text{$n - y$ insuccessi}\n\\]\nLa probabilità di ottenere esattamente \\(y\\) successi in una sequenza specifica di prove è pari a:\n\\[\np^y \\cdot (1 - p)^{n - y},\n\\]\ndove \\(p^y\\) è la probabilità di ottenere \\(y\\) successi, e \\((1 - p)^{n - y}\\) è la probabilità di ottenere \\(n - y\\) insuccessi.\nTuttavia, siamo interessati alla probabilità complessiva di ottenere esattamente \\(y\\) successi in qualsiasi ordine. Il numero di modi in cui ciò può avvenire è dato dal coefficiente binomiale \\(\\binom{n}{y}\\), che rappresenta tutte le possibili disposizioni dei successi e degli insuccessi nelle \\(n\\) prove.\nQuindi, moltiplicando la probabilità di una singola sequenza per il numero di sequenze possibili, otteniamo la probabilità di osservare esattamente \\(y\\) successi:\n\\[\nP(Y = y) = \\binom{n}{y} p^y (1 - p)^{n - y}.\n\\]\nQuesto risultato corrisponde alla formula della distribuzione binomiale.\n\n\n35.3.2 Applicazioni Pratiche della Distribuzione Binomiale\nConsideriamo un esempio pratico per illustrare l’applicazione della distribuzione binomiale. Supponiamo di osservare 2 successi in 4 prove Bernoulliane, dove la probabilità di successo in ogni prova è \\(p = 0.2\\). La probabilità di ottenere questo risultato specifico è calcolata utilizzando l’eq. {eq}eq-binom-distr:\n\\[\nP(Y=2) = \\frac{4!}{2!(4-2)!} \\cdot 0.2^{2} \\cdot (1-0.2)^{4-2} = 0.1536.\n\\]\nQuesto calcolo può essere replicato in Python. Utilizzando il modulo math, possiamo calcolare direttamente:\n\n# Parametri\nn &lt;- 4\np &lt;- 0.2\ny &lt;- 2\n\n# Probabilità di ottenere esattamente y successi\nprob &lt;- choose(n, y) * p^y * (1 - p)^(n - y)\nprint(prob)\n#&gt; [1] 0.1536\n\nIn alternativa, possiamo sfruttare la libreria SciPy per eseguire calcoli analoghi. SciPy offre una vasta gamma di funzioni per la gestione delle distribuzioni statistiche, tra cui la distribuzione binomiale.\n\n# Probabilità di ottenere esattamente y successi\nprob &lt;- choose(n, y) * p^y * (1 - p)^(n - y)\nprint(prob)\n#&gt; [1] 0.1536\n\nUtilizzando dbinom(y, n, p), possiamo trovare le probabilità per ogni possibile valore \\(y\\) in una distribuzione binomiale di parametri \\(n = 4\\) e \\(\\theta = 0.2\\):\n\n# Usando la funzione dbinom\nprob &lt;- dbinom(x = y, size = n, prob = p)\nprint(prob)\n#&gt; [1] 0.1536\n\nVisualizziamo la distribuzione di massa di probabilità:\n\ny &lt;- 0:n  # Numero di successi\nprobabilities &lt;- dbinom(y, size = n, prob = p)  # Probabilità associate\n\n# Preparare i dati in un data frame\ndf &lt;- data.frame(Successi = y, Probabilità = probabilities)\n\ndf |&gt; \n  ggplot(aes(x = Successi, y = Probabilità)) +\n    geom_segment(aes(xend = Successi, yend = 0), lwd = 1.2, color = \"blue\") +\n    geom_point(size = 3, color = \"blue\") +\n    labs(\n      x = \"Numero di Successi y\",\n      y = \"Probabilità\",\n      title = paste(\"Distribuzione Binomiale: n =\", n, \", p =\", p)\n  )\n\n\n\n\n\n\n\n\nUn campione casuale si ottiene con rbinom():\n\nset.seed(42)\nsamples &lt;- rbinom(n = 30, size = 5, prob = 0.5)\nprint(samples)\n#&gt;  [1] 4 4 2 4 3 3 3 1 3 3 2 3 4 2 2 4 5 1 2 3 4 1 5 4 1 3 2 4 2 4\n\nPer esplorare ulteriormente, consideriamo la distribuzione di probabilità di diverse distribuzioni binomiali per due valori di \\(n\\) e \\(\\theta\\). La seguente visualizzazione mostra come cambia la distribuzione al variare di \\(\\theta\\):\n\n# Parametri\nn &lt;- 20\np_values &lt;- seq(0.3, 0.9, by = 0.3) # Valori di probabilità\ny &lt;- 0:25 # Numero di successi\n\n# Creazione di un data frame per tutte le distribuzioni\ndf &lt;- data.frame()\n\nfor (p in p_values) {\n  binom_dist &lt;- dbinom(y, size = n, prob = p)\n  df &lt;- rbind(df, data.frame(y = y, Prob = binom_dist, p = factor(p)))\n}\n\n# Grafico con ggplot2\ndf |&gt; \n  ggplot(aes(x = y, y = Prob, color = p)) +\n    geom_point() +\n    geom_line() +\n    labs(\n      x = \"Numero di successi y\", \n      y = \"Probabilità\",\n      title = \"Distribuzione binomiale al variare di p\",\n      color = expression(theta)\n  )\n\n\n\n\n\n\n\n\nConsideriamo un altro esempio. Lanciando \\(5\\) volte una moneta onesta, qual è la probabilità che esca testa almeno due volte? Troviamo la soluzione usando stats.binom.pmf().\n\n# Calcolo della somma delle probabilità\nresult &lt;- dbinom(2, size = 5, prob = 0.5) +\n          dbinom(3, size = 5, prob = 0.5) +\n          dbinom(4, size = 5, prob = 0.5) +\n          dbinom(5, size = 5, prob = 0.5)\n\nprint(result)\n#&gt; [1] 0.8125\n\nOppure, in modo più compatto:\n\n# Valori di interesse\nresult &lt;- sum(dbinom(2:5, size = 5, prob = 0.5))\nprint(result)\n#&gt; [1] 0.8125\n\nRappresentiamo graficamente la funzione di ripartizione per una Binomiale di ordine \\(n\\) = 5 e \\(\\theta\\) = 0.5.\n\n# Parametri\nn &lt;- 5\np &lt;- 0.5\ny &lt;- 0:n\n\n# Calcolo della funzione di ripartizione cumulativa\ncdf_values &lt;- pbinom(y, size = n, prob = p)\n\n# Creazione del data frame per ggplot2\ndf &lt;- data.frame(y = y, cdf = cdf_values)\n\n# Grafico\ndf |&gt; \n  ggplot(aes(x = y, y = cdf)) +\n    geom_line() +\n    geom_point() +\n    geom_hline(yintercept = 1, color = \"black\", alpha = 0.7, linetype = \"dashed\") +\n    labs(\n      title = paste(\"Funzione di ripartizione binomiale: n =\", n, \", p =\", p),\n      x = \"y\",\n      y = \"Probabilità\"\n    )\n\n\n\n\n\n\n\n\nUn’altra funzione utile è quella che permette di trovare il numero di successi associato a una data probabilità cumulativa nella coda sinistra di una distribuzione binomiale. Questo si ottiene utilizzando la funzione qbinom, che rappresenta l’inversa della funzione di distribuzione cumulativa (CDF).\nAd esempio, consideriamo una distribuzione binomiale con \\(n = 5\\) prove e probabilità di successo \\(p = 0.5\\). Supponiamo di voler calcolare il numero minimo di successi per cui la probabilità cumulativa è almeno \\(1 - 0.8125 = 0.1875\\). Possiamo farlo nel seguente modo:\n\n# Probabilità target\ntarget_probability &lt;- 1 - 0.8125\n\n# Numero di successi corrispondente alla probabilità target\nresult &lt;- qbinom(target_probability, size = 5, prob = 0.5)\n\nprint(result)\n#&gt; [1] 1\n\nIn questo esempio, il valore restituito è \\(1\\), che indica che almeno 1 successo soddisfa la condizione di una probabilità cumulativa di \\(0.1875\\).\n\n\n35.3.3 Altro esempio\nConsideriamo ora una distribuzione binomiale con \\(n = 10\\) prove e probabilità di successo \\(p = 0.2\\). Per calcolare la probabilità cumulativa \\(P(Y \\leq 4)\\), ovvero la probabilità di ottenere al massimo 4 successi su 10 tentativi, possiamo utilizzare la funzione pbinom:\n\n# Calcolo della probabilità cumulativa\ntarget_probability &lt;- pbinom(4, size = 10, prob = 0.2)\nprint(target_probability)\n#&gt; [1] 0.9672065\n\nIl risultato rappresenta la probabilità cumulativa associata a 4 o meno successi.\nSe invece vogliamo determinare il numero di successi corrispondente a questa probabilità cumulativa, possiamo utilizzare la funzione inversa qbinom:\n\n# Calcolo del numero di successi associato alla probabilità cumulativa\nresult &lt;- qbinom(target_probability, size = 10, prob = 0.2)\nprint(result)\n#&gt; [1] 4\n\nIn questo caso, il valore restituito rappresenta il numero massimo di successi \\(Y\\) per cui la probabilità cumulativa è uguale o inferiore a \\(target\\_probability\\). Questo è particolarmente utile per interpretare i risultati di una distribuzione binomiale in termini di successi associati a determinate probabilità cumulative.\n\n\n35.3.4 Valore atteso e deviazione standard\nLa media (numero atteso di successi in \\(n\\) prove) e la deviazione standard di una distribuzione binomiale si calcolano nel seguente modo:\n\\[\n\\begin{align}\n\\mu    &= np,  \\notag \\\\\n\\sigma &= \\sqrt{np(1-p)}.\n\\end{align}\n\\tag{35.3}\\]\nDimostrazione. Dato che \\(Y\\) rappresenta la somma di \\(n\\) prove di Bernoulli indipendenti \\(Y_i\\), possiamo scrivere:\n\\[\n\\begin{align}\n\\mathbb{E}(Y) &= \\mathbb{E}\\left( \\sum_{i=1}^n Y_i \\right) = \\sum_{i=1}^n \\mathbb{E}(Y_i) = np, \\\\\n\\mathbb{V}(Y) &= \\mathbb{V} \\left( \\sum_{i=1}^n Y_i \\right) = \\sum_{i=1}^n \\mathbb{V}(Y_i) = np(1-p).\n\\end{align}\n\\]\nPertanto, la deviazione standard è data da \\(\\sigma = \\sqrt{np(1-p)}\\).\nPer esempio, prendiamo in considerazione il caso di un esperimento in cui vengono lanciate quattro monete, ciascuna con una probabilità di ottenere testa (successo) pari a \\(p = 0.2\\). Calcoliamo il valore atteso e la varianza per questo esperimento.\nIl valore atteso, \\(\\mu\\), rappresenta il numero medio di teste che ci aspettiamo di ottenere in ciascun lancio. Per la distribuzione binomiale, questo è dato da \\(\\mu = n p\\), dove \\(n\\) è il numero di prove (lanci di monete). Nel nostro caso, con \\(n = 4\\) e \\(p = 0.2\\), abbiamo:\n\\[\n\\mu = n p = 4 \\times 0.2 = 0.8.\n\\]\nQuesto significa che, in media, ci aspettiamo di ottenere circa 0.8 teste per ogni serie di quattro lanci.\nPer quanto riguarda la varianza, che misura quanto i risultati individuali tendono a differire dalla media, nella distribuzione binomiale è calcolata come \\(n p (1-p)\\). Pertanto, per il nostro esperimento:\n\\[\n\\text{Varianza} = n p (1-p) = 4 \\times 0.2 \\times (1 - 0.2) = 0.64.\n\\]\nLa varianza di 0.64 suggerisce una certa dispersione intorno al valore medio di 0.8 teste.\nPer confermare queste aspettative teoriche, possiamo eseguire una simulazione. Creiamo una serie di esperimenti simulati in cui lanciamo quattro monete per un gran numero di volte, registrando il numero di teste ottenute in ogni serie. Calcoliamo poi la media e la varianza dei risultati ottenuti per vedere quanto si avvicinano ai valori teorici calcolati.\n\nset.seed(42)\n\n# Genera un campione di 1.000.000 di valori dalla distribuzione binomiale\nx &lt;- rbinom(n = 1000000, size = 4, prob = 0.2)\n\n\nmean(x)\n#&gt; [1] 0.800212\n\n\nvar(x)\n#&gt; [1] 0.6389574\n\n\n\n35.3.5 Funzioni R associate alle distribuzioni di probabilità\nLa seguente tabella riassume le funzioni di R utilizzate per manipolare le distribuzioni di probabilità, illustrando i casi della distribuzione Binomiale e della Normale.\n\n\n\n\n\n\n\n\nTipo\nEsempio: Binomiale (\\(y \\mid n, p\\))\nEsempio: Normale (\\(y \\mid \\mu, \\sigma\\))\n\n\n\n\nFunzione di verosimiglianza\ndbinom(y, size = n, prob = p)\ndnorm(y, mean = μ, sd = σ)\n\n\nProb \\(Y = y\\)\ndbinom(y, size = n, prob = p)\nNon definita (variabili continue hanno pdf, non pmf)\n\n\nProb \\(Y \\geq y, Y \\leq y, y_1 &lt; Y &lt; y_2\\)\npbinom(y, size = n, prob = p) o 1 - pbinom(y - 1, ...)\npnorm(y, mean = μ, sd = σ) o 1 - pnorm(y, ...)\n\n\nInversa della CDF\nqbinom(q, size = n, prob = p)\nqnorm(q, mean = μ, sd = σ)\n\n\nGenerazione di dati simulati\nrbinom(n, size = trials, prob = p)\nrnorm(n, mean = μ, sd = σ)\n\n\n\nIn seguito, useremo altre distribuzioni come Uniforme, Beta, ecc., ognuna delle quali ha un proprio insieme di funzioni disponibili in R. La sintassi segue uno schema generale comune:\n\nd*: Calcola la funzione di densità di probabilità (per distribuzioni continue) o di massa (per distribuzioni discrete). Esempi: dbinom, dnorm.\np*: Calcola la funzione di ripartizione cumulativa (CDF). Esempi: pbinom, pnorm.\nq*: Calcola l’inversa della funzione di ripartizione cumulativa (quantile function). Esempi: qbinom, qnorm.\nr*: Genera campioni casuali secondo una determinata distribuzione. Esempi: rbinom, rnorm.\n\n\nEsercizio 35.1  \n\nCalcolare la probabilità di esattamente \\(y = 3\\) successi su \\(n = 5\\) prove con \\(p = 0.5\\):\n\n\ndbinom(3, size = 5, prob = 0.5)\n#&gt; [1] 0.3125\n\n\nCalcolare la probabilità cumulativa \\(P(Y \\leq 3)\\):\n\n\npbinom(3, size = 5, prob = 0.5)\n#&gt; [1] 0.8125\n\n\nCalcolare il valore minimo \\(y\\) tale che \\(P(Y \\leq y) \\geq 0.9\\):\n\n\nqbinom(0.9, size = 5, prob = 0.5)\n#&gt; [1] 4\n\n\nGenerare un campione di 100 numeri casuali da una distribuzione binomiale:\n\n\nrbinom(100, size = 5, prob = 0.5)\n#&gt;   [1] 2 2 4 1 3 2 3 2 2 2 3 3 3 3 1 4 1 1 0 2 2 2 4 1 2 3 3 1 5 2 3 3 0 3 2 3\n#&gt;  [37] 4 2 3 3 3 3 1 5 3 3 2 3 1 2 1 3 3 2 2 4 1 4 2 3 1 4 2 2 3 4 1 1 4 2 3 2\n#&gt;  [73] 3 3 3 1 4 4 3 3 4 3 3 3 2 2 3 3 2 4 4 3 2 2 0 3 1 3 1 2",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#distribuzione-discreta-uniforme",
    "href": "chapters/probability/11_discr_rv_distr.html#distribuzione-discreta-uniforme",
    "title": "35  Distribuzioni di v.c. discrete",
    "section": "35.4 Distribuzione Discreta Uniforme",
    "text": "35.4 Distribuzione Discreta Uniforme\nLa distribuzione discreta uniforme è un tipo particolare di distribuzione di probabilità, dove ogni risultato in un insieme finito e discreto \\(S\\) ha la stessa probabilità \\(p\\) di verificarsi. Questa distribuzione è caratterizzata dalla sua semplicità e dalla sua proprietà fondamentale di equiprobabilità.\nConsideriamo un esempio pratico con una variabile casuale discreta \\(X\\), che può assumere valori nell’insieme \\(\\{1, 2, \\dots, N\\}\\). Un’istanza classica di questa distribuzione si verifica quando si sceglie casualmente un numero intero tra 1 e \\(N\\), inclusi. Se \\(X\\) rappresenta il numero selezionato, allora la somma delle probabilità di tutti i possibili valori di \\(X\\) deve totalizzare 1, come indicato dalla formula di normalizzazione:\n\\[\n\\sum_{i=1}^N P(X_i) = Np = 1.\n\\]\nDi conseguenza, la probabilità che \\(X\\) assuma un valore specifico \\(x\\) è uniformemente distribuita:\n\\[\nP(X = x) = \\frac{1}{N},\n\\]\nindicando che ogni evento ha la stessa probabilità di verificarsi.\nIl valore atteso, o la media, di \\(X\\) ci dà un’idea del risultato medio atteso e si calcola come:\n\\[\n\\mathbb{E}(X) = \\sum_{x=1}^N x \\cdot \\frac{1}{N} = \\frac{1}{N} \\cdot \\sum_{x=1}^N x.\n\\]\nA questo punto, dobbiamo calcolare la somma \\(\\sum_{x=1}^{N} x\\), che è la somma dei primi \\(N\\) numeri naturali. Questa somma è data dalla formula:\n\\[\n\\sum_{x=1}^{N} x = \\frac{N(N + 1)}{2}.\n\\]\nSostituendo questa formula nel nostro calcolo del valore atteso, otteniamo:\n\\[\n\\mathbb{E}(X) = \\frac{1}{N} \\cdot \\frac{N(N + 1)}{2} = \\frac{N + 1}{2}.\n\\]\nQuindi, abbiamo dimostrato che il valore atteso $ (X) $ per una variabile casuale \\(X\\) che assume valori interi uniformemente distribuiti da 1 a \\(N\\) è \\(\\frac{N + 1}{2}\\).\nPer determinare quanto i valori di \\(X\\) si disperdono attorno al valore medio, calcoliamo la varianza. Il primo passo è calcolare \\(\\mathbb{E}(X^2)\\), il valore atteso del quadrato di \\(X\\). Per una variabile casuale discreta uniforme, questo si ottiene moltiplicando ogni valore al quadrato per la sua probabilità (che è \\(1/N\\) per tutti i valori) e sommando i risultati:\n\\[\n\\mathbb{E}(X^2) = \\frac{1}{N} \\cdot \\sum_{x=1}^N x^2\n\\]\nUsando l’identità per la somma dei quadrati dei primi \\(N\\) numeri naturali:\n\\[\n1^2 + 2^2 + \\dots + N^2 = \\frac{N(N + 1)(2N + 1)}{6}\n\\]\npossiamo sostituirla per trovare \\(\\mathbb{E}(X^2)\\):\n\\[\n\\mathbb{E}(X^2) = \\frac{1}{N} \\cdot \\frac{N(N + 1)(2N + 1)}{6} = \\frac{(N + 1)(2N + 1)}{6}\n\\]\nLa varianza di \\(X\\), denotata con \\(\\mathbb{V}(X)\\), si calcola usando la formula:\n\\[\n\\mathbb{V}(X) = \\mathbb{E}(X^2) - [\\mathbb{E}(X)]^2\n\\]\nAbbiamo già stabilito che \\(\\mathbb{E}(X) = \\frac{N + 1}{2}\\) e \\(\\mathbb{E}(X^2) = \\frac{(N + 1)(2N + 1)}{6}\\). Sostituendo questi valori nella formula della varianza, otteniamo:\n\\[\n\\mathbb{V}(X) = \\frac{(N + 1)(2N + 1)}{6} - \\left(\\frac{N + 1}{2}\\right)^2\n\\]\nPer semplicare l’espressione della varianza, dobbiamo sottrarre il quadrato di \\(\\mathbb{E}(X)\\) da \\(\\mathbb{E}(X^2)\\):\n\\[\n\\begin{align*}\n\\mathbb{V}(X) &= \\frac{(N + 1)(2N + 1)}{6} - \\left(\\frac{N + 1}{2}\\right)^2 \\\\\n&= \\frac{(N + 1)(2N + 1)}{6} - \\frac{(N + 1)^2}{4} \\\\\n&= \\frac{2(N + 1)(2N + 1)}{12} - \\frac{3(N + 1)^2}{12} \\\\\n&= \\frac{(N + 1)(2(2N + 1) - 3(N + 1))}{12} \\\\\n&= \\frac{(N + 1)(4N + 2 - 3N - 3)}{12} \\\\\n&= \\frac{(N + 1)(N - 1)}{12}\n\\end{align*}\n\\]\nQuindi, la varianza \\(\\mathbb{V}(X)\\) di una variabile casuale uniforme discreta \\(X\\) che assume valori da 1 a \\(N\\) è \\(\\frac{(N + 1)(N - 1)}{12}\\), il che mostra come la dispersione dei valori attorno al loro valore medio dipenda dalla grandezza di \\(N\\). Questa formula fornisce la varianza di una variabile casuale in una distribuzione discreta uniforme, offrendo una misura quantitativa della dispersione dei valori attorno al loro valore medio.\n\n35.4.1 Distribuzione di Poisson\nLa distribuzione di Poisson è utilizzata per modellare il numero di eventi che si verificano in un determinato intervallo di tempo o spazio, con eventi indipendenti e un tasso costante di occorrenza.\nLa funzione di massa di probabilità (PMF) è data da:\n\\[\nP(Y = y \\mid \\lambda) = \\frac{\\lambda^y \\cdot e^{-\\lambda}}{y!}, \\quad y = 0, 1, 2, \\ldots\n\\]\ndove \\(\\lambda\\) rappresenta il tasso medio di eventi e \\(y\\) è il numero di eventi.\n\n35.4.1.1 Proprietà principali\n\nMedia: \\(\\mathbb{E}[Y] = \\lambda\\)\nVarianza: \\(\\text{Var}(Y) = \\lambda\\)\n\nDi seguito, presentiamo esempi di calcolo e simulazione con R.\n\n\n35.4.1.2 Grafico della distribuzione di Poisson con \\(\\lambda = 2\\)\n\n# Parametro lambda\nlambda &lt;- 2\n\n# Valori di y (numero di eventi)\ny &lt;- 0:10\n\n# Calcolo delle probabilità\nprobabilities &lt;- dpois(y, lambda = lambda)\n\n# Grafico della funzione di massa di probabilità\nbarplot(probabilities, names.arg = y, col = \"blue\", \n        xlab = \"Numero di eventi (k)\", ylab = \"Probabilità\", \n        main = \"Distribuzione di Massa di Probabilità di Poisson\")\n\n\n\n\n\n\n\n\n\n\n35.4.1.3 Calcolo della probabilità per un numero specifico di eventi\nPer calcolare la probabilità di osservare esattamente 3 eventi con \\(\\lambda = 2\\):\n\nprob &lt;- dpois(3, lambda = 2)\nprint(prob)\n#&gt; [1] 0.180447\n\n\n\n35.4.1.4 Calcolo della probabilità cumulativa \\(P(Y \\leq 3)\\)\nPer calcolare \\(P(Y \\leq 3)\\), la probabilità cumulativa:\n\ncum_prob &lt;- ppois(3, lambda = 2)\nprint(cum_prob)\n#&gt; [1] 0.8571235\n\n\n\n35.4.1.5 Trovare il quantile corrispondente a una probabilità data\nPer trovare il numero massimo di eventi per cui la probabilità cumulativa è al massimo \\(0.8125\\):\n\nquantile &lt;- qpois(0.8125, lambda = 2)\nprint(quantile)\n#&gt; [1] 3\n\n\n\n35.4.1.6 Generazione di numeri casuali\nPer generare un campione di 1.000.000 di osservazioni da una distribuzione di Poisson con \\(\\lambda = 2\\):\n\nset.seed(42)\nsample &lt;- rpois(1000000, lambda = 2)\n\n# Calcolo di media e varianza del campione\nmean_sample &lt;- mean(sample)\nvar_sample &lt;- var(sample)\n\nprint(mean_sample)\n#&gt; [1] 1.999915\nprint(var_sample)\n#&gt; [1] 1.996043\n\n\nEsercizio 35.2 Consideriamo un ospedale con una media storica di 4,5 nascite al giorno. Qual è la probabilità che nascano esattamente 6 bambini in un giorno?\n\n# Calcolo della probabilità\nlambda &lt;- 4.5\nprob &lt;- dpois(6, lambda = lambda)\nprint(prob)\n#&gt; [1] 0.1281201\n\nSimuliamo 365 giorni di nascite e confrontiamo la proporzione di giorni con esattamente 6 nascite:\n\nset.seed(42)\nn_days &lt;- 365\nsimulated_births &lt;- rpois(n_days, lambda = lambda)\n\n# Proporzione di giorni con esattamente 6 nascite\nproportion_six_births &lt;- mean(simulated_births == 6)\nprint(proportion_six_births)\n#&gt; [1] 0.139726\n\nIstogramma delle nascite simulate:\n\nhist(simulated_births, breaks = seq(-0.5, max(simulated_births) + 0.5, by = 1), \n     col = \"blue\", xlab = \"Numero di nascite per giorno\", \n     ylab = \"Frequenza\", main = \"365 nascite simulate (Poisson)\")\n\n\n\n\n\n\n\n\nProbabilità di più di 6 nascite in un giorno. Per calcolare la probabilità teorica \\(P(Y &gt; 6)\\):\n\nprob_more_than_six &lt;- 1 - ppois(6, lambda = lambda)\nprint(prob_more_than_six)\n#&gt; [1] 0.1689494\n\nProporzione simulata di più di 6 nascite:\n\nproportion_more_than_six &lt;- mean(simulated_births &gt; 6)\nprint(proportion_more_than_six)\n#&gt; [1] 0.169863",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#distribuzione-beta-binomiale",
    "href": "chapters/probability/11_discr_rv_distr.html#distribuzione-beta-binomiale",
    "title": "35  Distribuzioni di v.c. discrete",
    "section": "35.5 Distribuzione Beta-Binomiale",
    "text": "35.5 Distribuzione Beta-Binomiale\nLa distribuzione beta-binomiale rappresenta una estensione della distribuzione binomiale che tiene conto della variabilità nella probabilità di successo tra i vari tentativi. Viene descritta da tre parametri principali: \\(N\\), \\(\\alpha\\) e \\(\\beta\\).\nNel dettaglio, la funzione di massa di probabilità per la distribuzione beta-binomiale è data da:\n\\[\n\\text{BetaBinomiale}(y | N, \\alpha, \\beta) = \\binom{N}{y} \\cdot \\frac{B(y + \\alpha, N - y + \\beta)}{B(\\alpha, \\beta)},\n\\tag{35.4}\\]\ndove:\n\n\\(y\\) indica il numero di successi osservati.\n\\(N\\) rappresenta il numero totale di tentativi.\n\\(\\alpha\\) e \\(\\beta\\) sono i parametri della distribuzione beta, che modellano la variabilità nella probabilità di successo tra i tentativi.\n\nLa funzione \\(B(u, v)\\), nota come funzione beta, è definita tramite l’uso della funzione gamma \\(\\Gamma\\), secondo la formula:\n\\[\nB(u, v) = \\frac{\\Gamma(u) \\Gamma(v)}{\\Gamma(u + v)},\n\\]\ndove la funzione gamma \\(\\Gamma\\) generalizza il concetto di fattoriale a numeri reali e complessi.\nL’importanza della distribuzione beta-binomiale deriva dalla sua capacità di modellare situazioni in cui la probabilità di successo non è fissa, ma segue una distribuzione di probabilità, specificatamente una distribuzione beta. Ciò la rende particolarmente adatta per applicazioni in cui le probabilità di successo cambiano in maniera incerta da un tentativo all’altro, come può avvenire in contesti di ricerca clinica o in studi comportamentali. Rispetto alla distribuzione binomiale, che assume una probabilità di successo costante per tutti i tentativi, la beta-binomiale offre una rappresentazione più realistica e flessibile per dati empirici che presentano variabilità nelle probabilità di successo.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#la-distribuzione-categorica",
    "href": "chapters/probability/11_discr_rv_distr.html#la-distribuzione-categorica",
    "title": "35  Distribuzioni di v.c. discrete",
    "section": "35.6 La Distribuzione Categorica",
    "text": "35.6 La Distribuzione Categorica\nLa distribuzione categorica è una distribuzione di probabilità discreta utilizzata per modellare eventi con più esiti distinti e non ordinati. È una generalizzazione della distribuzione Bernoulliana, che si limita a due esiti (successo e fallimento), ed è utile in situazioni in cui un evento può produrre uno tra molti esiti, ciascuno con una probabilità associata.\n\n35.6.1 Definizione e Funzione di Massa di Probabilità\nLa distribuzione categorica può essere caratterizzata dalla sua funzione di massa di probabilità (PMF):\n\\[\np(X = x) = \\mathcal{Categorical}(X \\mid p) = \\prod_{k=1}^K p_k^{I_{x=k}},\n\\]\ndove:\n\n\\(K\\) è il numero di esiti possibili,\n\\(p_k\\) è la probabilità associata al \\(k\\)-esimo esito,\n\\(I_{x=k}\\) è una funzione indicatrice che vale 1 se \\(x = k\\) e 0 altrimenti.\n\nLe probabilità \\(p_k\\) formano un vettore:\n\\[\np =\n\\begin{pmatrix}\np_1\\\\\np_2\\\\\n\\dots \\\\\np_K\n\\end{pmatrix},\n\\]\nche soddisfa la condizione:\n\\[\n\\sum_{k=1}^K p_k = 1.\n\\]\nIn altre parole, la somma delle probabilità di tutti i possibili esiti è pari a 1, come richiesto da qualsiasi distribuzione di probabilità.\n\n\n35.6.2 Proprietà Principali\n\nEsiti Multipli: La distribuzione categorica è adatta per modellare eventi con più di due esiti distinti. Un esempio classico è il lancio di un dado a sei facce, dove ciascun esito ha una probabilità di \\(\\frac{1}{6}\\) nel caso di un dado equo.\nGeneralizzazione della Distribuzione Bernoulliana: La distribuzione categorica è una generalizzazione della distribuzione Bernoulliana. In particolare, la distribuzione Bernoulliana rappresenta un caso speciale della distribuzione categorica con due sole categorie (\\(K = 2\\)), come il risultato di un lancio di una moneta (testa o croce).\nProbabilità in Forma di Simplex: Le probabilità degli esiti nella distribuzione categorica sono rappresentate da un vettore simplex. Un simplex è un vettore di probabilità non negative che sommano a 1, rispettando la condizione fondamentale delle distribuzioni di probabilità.\n\n\n\n35.6.3 Utilizzo della Distribuzione Categorica in Stan\nIn Stan, la distribuzione categorica è impiegata per modellare la probabilità di un singolo esito tra diversi possibili risultati. Questo è particolarmente utile in contesti come le catene di Markov, dove ogni stato può evolvere verso uno tra molti altri stati con una certa probabilità.\nAd esempio, supponiamo di avere una matrice di transizione \\(P\\) che descrive le probabilità di passaggio tra stati in una catena di Markov. Ogni riga della matrice \\(P\\) rappresenta una distribuzione categorica, in cui le voci corrispondono alle probabilità di transizione dallo stato corrente agli stati successivi. La distribuzione categorical può essere utilizzata per modellare la probabilità di osservare una specifica transizione.\nConsideriamo un esempio pratico: se uno studente si trova nello stato \\(A\\) al tempo \\(t\\), e le probabilità di transizione agli stati \\(A\\), \\(B\\) e \\(C\\) sono rispettivamente \\(0.7\\), \\(0.2\\) e \\(0.1\\), possiamo modellare la probabilità che l’evento successivo sia una transizione verso uno di questi stati usando la distribuzione categorica:\n\\[\nX \\sim \\text{categorical}(0.7, 0.2, 0.1)\n\\]\nQui, la variabile aleatoria \\(X\\) segue una distribuzione categorical con le probabilità assegnate ai tre possibili esiti (stati \\(A\\), \\(B\\), e \\(C\\)). Questo consente di simulare il prossimo stato in base alle probabilità specificate.\n\n35.6.3.1 Applicazione nelle Catene di Markov\nLa distribuzione categorical è particolarmente efficace nei modelli di catene di Markov, dove descrive le transizioni tra stati in un sistema dinamico. Ogni transizione tra stati è trattata come un evento discreto con più esiti possibili, ciascuno con la propria probabilità. Questo approccio è utile per modellare sistemi con molteplici stati e transizioni complesse, garantendo flessibilità e precisione nella simulazione delle dinamiche del sistema.\nIn sintesi, la distribuzione categorica in Stan permette di modellare eventi con molteplici esiti in modo semplice ed efficace, rendendola uno strumento prezioso per descrivere fenomeni dinamici, come le catene di Markov o qualsiasi altro processo con transizioni probabilistiche tra stati.\nDi seguito, esaminiamo come simulare una distribuzione categorica utilizzando numpy e come creare un istogramma per visualizzare la distribuzione di massa:\n\n# Definire le probabilità della distribuzione categorica\nprobabilities &lt;- c(0.6, 0.3, 0.1)  # Le probabilità per ciascun esito\n\n# Definire le categorie\ncategories &lt;- c(\"A\", \"B\", \"C\")\n\n# Numero di campioni da generare\nn_samples &lt;- 1000\n\n# Simulare la distribuzione categorica\nset.seed(123)  # Per riproducibilità\nsamples &lt;- sample(categories, size = n_samples, replace = TRUE, prob = probabilities)\n\nggplot(data.frame(samples = samples), aes(x = samples)) +\n  geom_bar(fill = \"skyblue\", color = \"black\") +\n  scale_x_discrete(labels = categories) +\n  labs(\n    x = \"Categorie\", \n    y = \"Frequenza\", \n    title = \"Istogramma della Distribuzione Categorica Simulata\"\n) \n\n\n\n\n\n\n\n\nConcludiamo chiarendo la relazione tra la distribuzione categorica e quella multinomiale.\nLa distribuzione categorica descrive l’esito di una singola prova con \\(K\\) categorie, ciascuna con una probabilità associata. È una generalizzazione della distribuzione Bernoulliana, che prevede solo due esiti (successo o fallimento).\n\nEsercizio 35.3 Lanciare un dado a sei facce una volta. Ciascuna faccia ha una probabilità di \\(\\frac{1}{6}\\).\nLa distribuzione multinomiale estende la distribuzione binomiale a più categorie e descrive il numero di esiti su un insieme di prove indipendenti che seguono una distribuzione categorica.\n\n\nEsercizio 35.4 Lanciare un dado dieci volte e contare quante volte appare ciascuna faccia.\nLa distribuzione categorica è un caso particolare della multinomiale quando si effettua una sola prova (\\(n = 1\\)). Nella distribuzione categorica otteniamo un singolo esito, mentre nella multinomiale otteniamo un conteggio di esiti su più prove.\n\n\n\n\n35.6.4 Implementazioni in R\n\nsample: Permette di campionare da una distribuzione categorica, restituendo uno o più esiti in base alle probabilità specificate. Ad esempio:\nsample(categories, size = n, replace = TRUE, prob = probabilities)\nDove categories è un vettore di esiti, n è il numero di campioni, e probabilities definisce le probabilità associate a ciascun esito.\nrmultinom: Funzione per la distribuzione multinomiale. Può essere utilizzata per simulare una distribuzione categorica impostando il numero di prove ( n = 1 ). Ad esempio:\nrmultinom(1, size = 1, prob = probabilities)\nQui, probabilities specifica le probabilità per ciascun esito. Restituisce il numero di successi per ciascuna categoria in una matrice.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#la-distribuzione-geometrica",
    "href": "chapters/probability/11_discr_rv_distr.html#la-distribuzione-geometrica",
    "title": "35  Distribuzioni di v.c. discrete",
    "section": "35.7 La Distribuzione Geometrica",
    "text": "35.7 La Distribuzione Geometrica\nLa distribuzione geometrica è una distribuzione discreta che modella il numero di tentativi necessari per ottenere il primo successo in una sequenza di prove Bernoulliane indipendenti. Ogni prova ha due possibili esiti: successo (con probabilità \\(p\\)) o fallimento (con probabilità \\(1 - p\\)).\nIn termini pratici, la distribuzione geometrica può essere utilizzata per rispondere alla domanda: “Quante prove falliscono prima di ottenere il primo successo?”.\n\n35.7.1 Funzione di Massa di Probabilità\nLa funzione di massa di probabilità (PMF) della distribuzione geometrica è definita come:\n\\[\nP(X = k) = (1 - p)^{k-1} \\cdot p\n\\]\ndove:\n\n\\(X\\) è il numero di tentativi fino al primo successo (incluso il tentativo in cui si ottiene il successo).\n\\(p\\) è la probabilità di successo in ogni prova.\n\\(k\\) è il numero di prove necessarie per ottenere il primo successo (un numero intero positivo, \\(k \\geq 1\\)).\n\n\n\n35.7.2 Proprietà della Distribuzione Geometrica\n\nValore Atteso (Media): La media del numero di prove fino al primo successo è data da:\n\n\\[\n\\mathbb{E}[X] = \\frac{1}{p}.\n\\]\nQuesto significa che, in media, ci si aspetta di avere \\(\\frac{1}{p}\\) prove prima di ottenere un successo.\n\nVarianza: La varianza della distribuzione geometrica è:\n\n\\[\n\\text{Var}(X) = \\frac{1 - p}{p^2}.\n\\]\n\nMemoria Assente: La distribuzione geometrica ha una proprietà interessante chiamata “assenza di memoria”. Ciò significa che, dato che non si è verificato alcun successo fino a un certo punto, la probabilità di successo nelle prove future è indipendente dal passato e rimane sempre \\(p\\).\n\n\n\n35.7.3 Applicazione nel Modello\nAd esempio, supponiamo di voler modellare quanti giorni passano prima che un animale venga adottato in un rifugio. Se la probabilità giornaliera di essere adottato è \\(p\\), la distribuzione geometrica può dirci quanto tempo ci aspettiamo prima che l’adozione avvenga. Se, ad esempio, \\(p = 0.2\\), significa che c’è il 20% di probabilità di adozione ogni giorno, e possiamo modellare il numero di giorni fino all’adozione usando una distribuzione geometrica.\nNel nostro modello di adozione, stiamo utilizzando la distribuzione geometrica per modellare i giorni fino all’adozione. La probabilità \\(p\\) rappresenta la probabilità giornaliera che un animale venga adottato, e la distribuzione geometrica ci permette di modellare il numero di giorni fino a quando avviene il successo (adozione).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#riflessioni-conclusive",
    "href": "chapters/probability/11_discr_rv_distr.html#riflessioni-conclusive",
    "title": "35  Distribuzioni di v.c. discrete",
    "section": "35.8 Riflessioni Conclusive",
    "text": "35.8 Riflessioni Conclusive\nIn questo capitolo, abbiamo esplorato diverse distribuzioni discrete fondamentali, ciascuna con le sue specifiche applicazioni e peculiarità. Abbiamo iniziato con la distribuzione Bernoulliana, che modella esperimenti con due possibili esiti, come il lancio di una moneta. Abbiamo poi approfondito la distribuzione Binomiale, una generalizzazione della Bernoulliana, che si focalizza sul conteggio del numero di successi in un dato numero di prove indipendenti.\nAbbiamo anche esaminato la distribuzione Beta-Binomiale, che estende ulteriormente il modello Binomiale incorporando la variabilità nella probabilità di successo, e la distribuzione di Poisson, utilizzata per modellare il numero di eventi che si verificano in un intervallo di tempo o spazio, quando questi eventi sono rari e indipendenti.\nInfine, abbiamo discusso la distribuzione Discreta Uniforme, che attribuisce la stessa probabilità a ogni evento in un insieme finito e discreto. Questa distribuzione è particolarmente utile quando non abbiamo ragioni per assegnare probabilità diverse ai diversi esiti.\nQueste distribuzioni formano il cuore dell’analisi statistica discreta e trovano applicazione in un’ampia gamma di settori. In particolare, nel contesto dell’analisi bayesiana, la comprensione della distribuzione Binomiale e Beta-Binomiale è cruciale, poiché queste distribuzioni forniscono le basi per l’aggiornamento bayesiano, un concetto chiave che sarà esplorato nei capitoli successivi.\nPer coloro interessati a tecniche più avanzate, la generazione di valori casuali a partire da queste distribuzioni è trattata nell’appendice {ref}rng-appendix. Questa sezione fornisce strumenti e approfondimenti utili per l’applicazione pratica di questi modelli probabilistici.\nIn conclusione, le distribuzioni discrete forniscono strumenti essenziali e versatili per modellare e analizzare fenomeni caratterizzati da eventi distinti e quantificabili. La comprensione approfondita di queste distribuzioni è cruciale per chiunque desideri esplorare il vasto campo della probabilità e della statistica.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#esercizi",
    "href": "chapters/probability/11_discr_rv_distr.html#esercizi",
    "title": "35  Distribuzioni di v.c. discrete",
    "section": "35.9 Esercizi",
    "text": "35.9 Esercizi\n\nEsercizio 35.5 Per ciascuna delle distribuzioni di massa di probabilità discusse, utilizza Python per:\n\ncreare un grafico della funzione, scegliendo opportunamente i parametri;\nestrarre un campione di 1000 valori casuali dalla distribuzione e visualizzarlo con un istogramma;\ncalcolare la media e la deviazione standard dei campioni e confrontarle con i valori teorici attesi;\nstimare l’intervallo centrale del 94% utilizzando i campioni simulati;\ndeterminare i quantili della distribuzione per gli ordini 0.05, 0.25, 0.75 e 0.95;\nscegliendo un valore della distribuzione pari alla media più una deviazione standard, calcolare la probabilità che la variabile aleatoria assuma un valore minore o uguale a questo valore.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/11_discr_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "title": "35  Distribuzioni di v.c. discrete",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Zagreb\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.16.0       MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2\n#&gt;  [5] ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0  \n#&gt;  [9] bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0      markdown_1.13    \n#&gt; [13] knitr_1.49        lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1    \n#&gt; [17] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#&gt; [21] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [25] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1  farver_2.1.2      fastmap_1.2.0     pacman_0.5.1     \n#&gt;  [5] promises_1.3.1    rpart_4.1.23      digest_0.6.37     timechange_0.3.0 \n#&gt;  [9] mime_0.12         lifecycle_1.0.4   survival_3.7-0    magrittr_2.0.3   \n#&gt; [13] compiler_4.4.2    rlang_1.1.4       tools_4.4.2       utf8_1.2.4       \n#&gt; [17] yaml_2.3.10       ggsignif_0.6.4    labeling_0.4.3    htmlwidgets_1.6.4\n#&gt; [21] mnormt_2.1.1      abind_1.4-8       miniUI_0.1.1.1    withr_3.0.2      \n#&gt; [25] nnet_7.3-19       grid_4.4.2        fansi_1.0.6       jomo_2.7-6       \n#&gt; [29] xtable_1.8-4      colorspace_2.1-1  iterators_1.0.14  cli_3.6.3        \n#&gt; [33] rmarkdown_2.29    generics_0.1.3    tzdb_0.4.0        minqa_1.2.8      \n#&gt; [37] splines_4.4.2     parallel_4.4.2    vctrs_0.6.5       boot_1.3-31      \n#&gt; [41] glmnet_4.1-8      Matrix_1.7-1      jsonlite_1.8.9    carData_3.0-5    \n#&gt; [45] car_3.1-3         hms_1.1.3         mitml_0.4-5       rstatix_0.7.2    \n#&gt; [49] Formula_1.2-5     foreach_1.5.2     glue_1.8.0        pan_1.9          \n#&gt; [53] nloptr_2.1.1      codetools_0.2-20  stringi_1.8.4     gtable_0.3.6     \n#&gt; [57] shape_1.4.6.1     later_1.4.0       lme4_1.1-35.5     munsell_0.5.1    \n#&gt; [61] pillar_1.9.0      htmltools_0.5.8.1 R6_2.5.1          rprojroot_2.0.4  \n#&gt; [65] evaluate_1.0.1    shiny_1.9.1       lattice_0.22-6    backports_1.5.0  \n#&gt; [69] broom_1.0.7       httpuv_1.6.15     Rcpp_1.0.13-1     nlme_3.1-166     \n#&gt; [73] xfun_0.49         pkgconfig_2.0.3",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html",
    "href": "chapters/probability/12_cont_rv_distr.html",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "",
    "text": "36.1 Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nPreparazione del Notebook\nAnalogamente a quanto avviene per le variabili casuali discrete, anche per le variabili casuali continue possiamo rappresentare la variabilità all’interno di una popolazione attraverso un modello statistico, ma in questo caso utilizziamo le densità di probabilità – si veda il ?sec-density-function. Mentre le distribuzioni di probabilità discrete si applicano a fenomeni con un numero finito o numerabile di esiti, le densità di probabilità sono fondamentali per descrivere variabili che possono assumere un continuum di valori.\nLa funzione di densità di probabilità \\(f(x)\\) associata a una variabile casuale continua \\(X\\) rappresenta la distribuzione della probabilità all’interno della popolazione. Questa funzione non fornisce la probabilità esatta di un singolo valore, ma piuttosto la probabilità di osservare valori di \\(X\\) all’interno di un intervallo specifico. Così come per le distribuzioni discrete, anche le densità di probabilità costituiscono un modello della popolazione, una rappresentazione matematica che ci consente di fare previsioni e di comprendere meglio i fenomeni aleatori continui.\nIniziamo con la distribuzione continua uniforme.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#introduzione",
    "href": "chapters/probability/12_cont_rv_distr.html#introduzione",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "",
    "text": "36.1.1 Distribuzione Uniforme\nLa distribuzione uniforme è una delle più semplici funzioni di densità di probabilità. Consideriamo di nuovo l’esperimento dello spinner introdotto in precedenza. Simuliamo 20 valori che potrebbero essere ottenuti facendo ruotare lo spinner e li rappresentiamo con un istogramma.\n\n36.1.1.1 Simulazione di 20 valori\n\n# Simulazione di 20 valori\nset.seed(123)\nspinner_results &lt;- runif(20, min = 0, max = 360)\nprint(spinner_results)\n#&gt;  [1] 103.52791 283.78985 147.23169 317.88627 338.56822  16.40034 190.11798\n#&gt;  [8] 321.27086 198.51661 164.38130 344.46000 163.20030 243.92543 206.14802\n#&gt; [15]  37.05289 323.93699  88.59158  15.14143 118.05146 343.62131\n\nggplot(data.frame(Valori = spinner_results), aes(x = Valori)) +\n  geom_histogram(binwidth = 10, fill = \"skyblue\", color = \"black\", alpha = 0.5) +\n  labs(x = \"Risultato dello spinner\", y = \"Frequenza relativa\",\n       title = \"Istogramma dei risultati (20 simulazioni)\") \n\n\n\n\n\n\n\n\nNonostante possiamo pensare che ogni risultato tra 0 e 360 sia ugualmente probabile, l’istogramma non lo suggerisce chiaramente con solo 20 osservazioni. Simuliamo ora 100.000 ripetizioni.\n\n\n36.1.1.2 Simulazione di 100.000 valori\n\n# Simulazione di 100.000 valori\nspinner_results_large &lt;- runif(100000, min = 0, max = 360)\n\n# Istogramma\nggplot(data.frame(Valori = spinner_results_large), aes(x = Valori)) +\n  geom_histogram(binwidth = 10, fill = \"skyblue\", color = \"black\", alpha = 0.5) +\n  labs(x = \"Risultato dello spinner\", y = \"Frequenza relativa\",\n       title = \"Istogramma dei risultati (100.000 simulazioni)\") \n\n\n\n\n\n\n\n\nIn questo caso, anche se ci sono variazioni nelle altezze delle barre (bin di ampiezza pari a 10), la forma generale dell’istogramma appare piuttosto uniforme su tutto l’intervallo \\([0, 360]\\). Con un numero enorme di risultati, l’istogramma si avvicinerebbe alla funzione di densità uniforme mostrata di seguito.\n\n\n36.1.1.3 Funzione di densità uniforme\n\n# Curva della funzione di densità uniforme\nx &lt;- seq(0, 360, length.out = 100)\ndensity_uniform &lt;- dunif(x, min = 0, max = 360)\n\nggplot(data.frame(x = x, y = density_uniform), aes(x = x, y = y)) +\n  geom_line(size = 1, color = \"blue\") +\n  labs(x = \"x\", y = \"p(x)\", title = \"Funzione di densità uniforme\") \n#&gt; Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\nQuando la variabile casuale \\(X\\) è continua, come nel caso dello spinner, la probabilità è rappresentata da una curva, la funzione di densità di probabilità. Poiché lo spinner copre l’intervallo \\([0, 360]\\), la probabilità che \\(X\\) sia compreso in questo intervallo è pari a 1. La densità costante è quindi:\n\n1 / 360\n#&gt; [1] 0.002777778\n\n\n\n36.1.1.4 Probabilità in un intervallo specifico\nLa probabilità di ottenere un valore tra 150 e 250, \\(P(150 &lt; X &lt; 250)\\), è data dall’area sottesa alla curva in quell’intervallo. L’altezza della curva è \\(1/360\\), mentre la base è \\(250 - 150 = 100\\). Quindi:\n\n100 * (1 / 360)\n#&gt; [1] 0.2777778\n\nPer calcolare la probabilità, si possono utilizzare le funzioni di distribuzione cumulative:\n\npunif(250, min = 0, max = 360) - punif(150, min = 0, max = 360)\n#&gt; [1] 0.2777778\n\n\n\n36.1.1.5 Visualizzazione dell’intervallo di probabilità\n\n# Visualizzazione della probabilità nell'intervallo [150, 250]\nx &lt;- seq(0, 360, length.out = 1000)\nfx &lt;- dunif(x, min = 0, max = 360)\n\nggplot(data.frame(x = x, fx = fx), aes(x = x, y = fx)) +\n  geom_line(size = 1, color = \"blue\") +\n  geom_area(data = subset(data.frame(x = x, fx = fx), x &gt;= 150 & x &lt;= 250),\n            aes(x = x, y = fx), fill = \"gray\", alpha = 0.5) +\n  labs(x = \"x\", y = \"p(x)\", title = \"Probabilità per l'intervallo [150, 250]\")\n\n\n\n\n\n\n\n\nIn maniera più formale possiamo dire che la distribuzione continua uniforme è una distribuzione di probabilità continua che assegna lo stesso grado di fiducia a tutti i possibili valori di una variabile definita in un certo intervallo \\(S=[a,b]\\subset {\\mathbb  {R}}\\). La distribuzione continua uniforme viene indicata con \\({\\mathcal  {U}}(a,b)={\\mathcal  {U}}([a,b])\\). Come intervallo \\([a,b]\\) viene spesso preso l’intervallo unitario \\(I=[0,1]\\).\nLa densità di probabilità di una variabile casuale continua uniforme \\({\\mathcal  {U}}(a,b)\\) è\n\\[\nf(x)={\\frac  {1}{b-a}} \\quad \\text{su}\\; [a, b].\n\\]\nIl suo valore attesto è\n\\[\n\\displaystyle E(X)={\\frac {1}{2}}(b+a).\n\\]\nLa sua varianza è\n\\[\nV(X)={\\frac {1}{12}}(b-a)^{2}.\n\\]\nIn R, è possibile manipolare la distribuzione uniforme utilizzando le funzioni della famiglia runif, dunif, punif e qunif. Di default, queste funzioni lavorano con la distribuzione uniforme standard \\(\\mathcal{U}(0,1)\\).\n\n\n\n36.1.2 Funzione di densità di probabilità (PDF)\nLa funzione dunif() calcola l’ordinata della funzione di densità per i valori di input specificati. Per esempio, esaminiamo la densità di \\(\\mathcal{U}(0,1)\\) per i valori 0.5, 0.8 e 1.2. Ci aspettiamo di ottenere 1 per i primi due valori e 0 per 1.2, che è fuori dall’intervallo \\([0, 1]\\).\n\ndunif(c(0.5, 0.8, 1.2), min = 0, max = 1)\n#&gt; [1] 1 1 0\n\n\n\n36.1.3 Funzione di ripartizione (CDF)\nLa funzione punif() restituisce il valore della funzione di ripartizione. Per esempio, per \\(\\mathcal{U}(0,1)\\) nei punti 0.5 e 0.8:\n\npunif(c(0.5, 0.8), min = 0, max = 1)\n#&gt; [1] 0.5 0.8\n\n\n\n36.1.4 Calcolo della probabilità in un intervallo\nUtilizzando la funzione di ripartizione, possiamo calcolare la probabilità che la variabile casuale continua assuma un valore in un intervallo specificato. Per esempio, per \\(\\mathcal{U}(0,1)\\) troviamo \\(P(0.5 &lt; X &lt; 0.8)\\):\n\npunif(0.8, min = 0, max = 1) - punif(0.5, min = 0, max = 1)\n#&gt; [1] 0.3\n\n\n\n36.1.5 Calcolo dei quantili\nLa funzione qunif() restituisce i quantili della distribuzione uniforme, ovvero il valore della variabile casuale \\(X\\) in corrispondenza del valore della funzione di ripartizione fornito in input. Per esempio, troviamo i quantili di ordine 0.5 e 0.8 di \\(\\mathcal{U}(0,1)\\):\n\nqunif(c(0.5, 0.8), min = 0, max = 1)\n#&gt; [1] 0.5 0.8\n\n\n\n36.1.6 Simulazione di valori casuali\nLa funzione runif() consente di generare numeri casuali dalla distribuzione uniforme. Per esempio, simuliamo 5 valori casuali da \\(\\mathcal{U}(0,1)\\):\n\nset.seed(123)  # Per la riproducibilità\nrunif(5, min = 0, max = 1)\n#&gt; [1] 0.2875775 0.7883051 0.4089769 0.8830174 0.9404673\n\n\n\n36.1.7 Valore atteso\nPer verificare il valore atteso di 100,000 realizzazioni di \\(\\mathcal{U}(0,1)\\):\n\nmean(runif(100000, min = 0, max = 1))\n#&gt; [1] 0.4992833\n\n\n\n36.1.8 Varianza\nPer calcolare la varianza di 100,000 realizzazioni di \\(\\mathcal{U}(0,1)\\):\n\nvar(runif(100000, min = 0, max = 1))\n#&gt; [1] 0.08342307\n\nConfrontiamo il valore teorico della varianza per \\(\\mathcal{U}(0,1)\\), che è \\(1/12\\):\n\n1 / 12\n#&gt; [1] 0.08333333\n\nIn conclusione, le funzioni della famiglia runif, dunif, punif e qunif in R consentono di manipolare e analizzare la distribuzione uniforme.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-esponenziale",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-esponenziale",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "36.2 Distribuzione esponenziale",
    "text": "36.2 Distribuzione esponenziale\nUn’altra distribuzione di densità molto semplice è la distribuzione esponenziale. La distribuzione esponenziale viene spesso utilizzata per modellare il tempo trascorso prima che un evento si verifichi (tempo di attesa).\nLa distribuzione esponenziale è l’unica distribuzione di probabilità continua che possiede la proprietà di assenza di memoria. Ad esempio, ipotizziamo che il tempo necessario affinché un bicchiere da vino si rompa dopo il primo utilizzo segua una distribuzione esponenziale. Supponiamo inoltre che ci sia un bicchiere da vino che non si è rotto dopo 3 anni dal primo utilizzo. L’assenza di memoria significa che la probabilità che questo bicchiere da vino non si rompa nel prossimo anno è la stessa della probabilità che un altro bicchiere da vino nuovo non si rompa nel primo anno di utilizzo.\nChiamiamo \\(X\\) il tempo di attesa. Sia \\(\\mu = \\mathbb{E}(X)\\) il tempo di attesa medio. La funzione di densità esponenziale è\n\\[\nf(x) = \\lambda {\\rm e}^{-\\lambda x}, \\quad \\text{con} \\; \\lambda = 1/\\mu,\\, \\lambda &gt; 0,\\, x &gt; 0,\n\\tag{36.1}\\]\novvero\n\\[\nf(x) = \\frac{1}{\\mu} {\\rm e}^{-x/\\mu}.\n\\]\nLa media di una distribuzione esponenziale è\n\\[\nE(X) = \\frac{1}{\\lambda}.\n\\]\nLa varianza di una distribuzione esponenziale è\n\\[\nV(X) = \\mu = \\frac{1}{\\lambda^2}.\n\\]\nLa deviazione standard è dunque uguale alla media:\n\\[\n\\sigma_X = \\frac{1}{\\lambda} = \\mu.\n\\]\nAd esempio, il tempo di attesa della pubblicazione del voto di un esame scritto segue una distribuzione esponenziale. Supponiamo che, in questo Corso di Laurea, il tempo di attesa medio per conoscere il risultato di un esame scritto sia di 4 giorni. La funzione esponenziale diventa\n\\[\nf(x) = \\frac{1}{4} \\exp^{-x/4}.\n\\]\n\n36.2.1 Grafico della funzione di densità esponenziale\nLa densità esponenziale è definita da \\(f(x) = \\lambda e^{-\\lambda x}\\). In R, possiamo disegnarla con:\n\n# Parametri della distribuzione\nmu &lt;- 4  # Media\nlambda &lt;- 1 / mu  # Tasso (1 / media)\nstdev &lt;- 1 / lambda  # Deviazione standard\n\n# Generare valori per x\nx &lt;- seq(0, 20, by = 0.01)\n\n# Calcolare la densità\npdf &lt;- dexp(x, rate = lambda)\n\n# Grafico della densità\nggplot(data.frame(x, pdf), aes(x = x, y = pdf)) +\n  geom_line(size = 1, color = \"blue\") +\n  labs(x = \"x\", y = \"f(x)\", title = \"Funzione di densità della distribuzione esponenziale\") \n\n\n\n\n\n\n\n\n\n\n36.2.2 Probabilità che \\(X \\leq 1.5\\)\nLa probabilità \\(P(X \\leq 1.5)\\) è calcolata con la funzione di ripartizione pexp():\n\n# Probabilità che X &lt;= 1.5\npexp(1.5, rate = lambda)\n#&gt; [1] 0.3127107\n\nVisualizzazione dell’area sottesa:\n\nggplot(data.frame(x, pdf), aes(x = x, y = pdf)) +\n  geom_line(size = 1, color = \"blue\") +\n  geom_area(data = subset(data.frame(x, pdf), x &lt;= 1.5), aes(x = x, y = pdf), fill = \"gray\", alpha = 0.5) +\n  labs(x = \"x\", y = \"f(x)\", title = \"Probabilità P(X &lt;= 1.5)\") \n\n\n\n\n\n\n\n\n\n\n36.2.3 Probabilità che \\(1 \\leq X \\leq 6\\)\nLa probabilità \\(P(1 \\leq X \\leq 6)\\) si calcola come differenza di funzioni di ripartizione:\n\n# Probabilità che 1 &lt;= X &lt;= 6\npexp(6, rate = lambda) - pexp(1, rate = lambda)\n#&gt; [1] 0.5556706\n\nVisualizzazione dell’area sottesa:\n\nggplot(data.frame(x, pdf), aes(x = x, y = pdf)) +\n  geom_line(size = 1, color = \"blue\") +\n  geom_area(data = subset(data.frame(x, pdf), x &gt;= 1 & x &lt;= 6), aes(x = x, y = pdf), fill = \"gray\", alpha = 0.5) +\n  labs(x = \"x\", y = \"f(x)\", title = \"Probabilità P(1 &lt;= X &lt;= 6)\")\n\n\n\n\n\n\n\n\n\n\n36.2.4 Probabilità che \\(X \\geq 5.5\\)\nLa probabilità \\(P(X \\geq 5.5)\\) si ottiene con l’evento complementare \\(1 - P(X \\leq 5.5)\\) oppure con 1 - pexp():\n\n# Complemento\n1 - pexp(5.5, rate = lambda)\n#&gt; [1] 0.2528396\n\n# Alternativa con funzione di sopravvivenza\npexp(5.5, rate = lambda, lower.tail = FALSE)\n#&gt; [1] 0.2528396\n\nVisualizzazione dell’area sottesa:\n\nggplot(data.frame(x, pdf), aes(x = x, y = pdf)) +\n  geom_line(size = 1, color = \"blue\") +\n  geom_area(data = subset(data.frame(x, pdf), x &gt;= 5.5), aes(x = x, y = pdf), fill = \"gray\", alpha = 0.5) +\n  labs(x = \"x\", y = \"f(x)\", title = \"Probabilità P(X &gt;= 5.5)\") \n\n\n\n\n\n\n\n\n\n\n36.2.5 Istogramma di valori simulati\nSimuliamo 1.000.000 di valori casuali da una distribuzione esponenziale con parametro \\(\\lambda = 1/4\\), quindi costruiamo l’istogramma sovrapponendo la densità teorica.\n\n# Simulazione di valori casuali\nset.seed(123)\nsamples &lt;- rexp(1000000, rate = lambda)\n\n# Istogramma con densità sovrapposta\nggplot(data.frame(samples), aes(x = samples)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 100, fill = \"skyblue\", color = \"black\", alpha = 0.5) +\n  geom_line(data = data.frame(x, pdf), aes(x = x, y = pdf), color = \"red\", size = 1) +\n  xlim(0, 20) +\n  labs(x = \"Tempo di attesa\", y = \"Frequenza relativa\",\n       title = \"Istogramma dei valori simulati con densità teorica\")\n#&gt; Warning: Removed 6631 rows containing non-finite outside the scale range\n#&gt; (`stat_bin()`).\n#&gt; Warning: Removed 2 rows containing missing values or values outside the scale range\n#&gt; (`geom_bar()`).\n\n\n\n\n\n\n\n\nQuesti esempi replicano tutte le funzionalità dell’implementazione Python utilizzando R e producono grafici chiari e ben definiti.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-gaussiana",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-gaussiana",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "36.3 Distribuzione Gaussiana",
    "text": "36.3 Distribuzione Gaussiana\nLa più importante distribuzione di densità è la Gaussiana. Non c’è un’unica distribuzione gaussiana (o Normale): la distribuzione gaussiana è una famiglia di distribuzioni. Tali distribuzioni sono dette “gaussiane” in onore di Carl Friedrich Gauss (uno dei più grandi matematici della storia il quale, tra le altre cose, scoprì l’utilità di tale funzione di densità per descrivere gli errori di misurazione). Adolphe Quetelet, il padre delle scienze sociali quantitative, fu il primo ad applicare tale funzione di densità alle misurazioni dell’uomo. Karl Pearson usò per primo il termine “distribuzione normale” anche se ammise che questa espressione “ha lo svantaggio di indurre le persone a credere che le altre distribuzioni, in un senso o nell’altro, non siano normali.”\n\n36.3.1 Limite delle distribuzioni binomiali\nIniziamo con un un breve excursus storico. Nel 1733, Abraham de Moivre notò che, aumentando il numero di prove di una distribuzione binomiale, la distribuzione risultante diventava quasi simmetrica e a forma campanulare. Per esempio, con 10 prove e una probabilità di successo di 0.9, la distribuzione è chiaramente asimmetrica.\n\n# Parametri\nn &lt;- 10\np &lt;- 0.9\n\n# Calcolare la distribuzione binomiale\nr_values &lt;- 0:n\ndist &lt;- dbinom(r_values, size = n, prob = p)\n\n# Grafico\nggplot(data.frame(Successi = r_values, Probabilità = dist), aes(x = Successi, y = Probabilità)) +\n  geom_bar(stat = \"identity\", fill = \"skyblue\", color = \"black\") +\n  labs(title = \"Distribuzione Binomiale: n = 10, p = 0.9\", x = \"Numero di Successi\", y = \"Probabilità\") \n\n\n\n\n\n\n\n\nQuando il numero di prove N viene aumentato di un fattore di 100 a N = 1000, mantenendo costante la probabilità di successo del 90%, si osserva che la distribuzione assume una forma campanulare quasi simmetrica. Questa osservazione porta a una scoperta di de Moivre: quando N diventa grande, la funzione gaussiana, nonostante rappresenti la densità di variabili casuali continue, offre una buona approssimazione alla funzione di massa di probabilità binomiale.\n\n# Parametri aggiornati\nn &lt;- 1000\n\n# Calcolare la distribuzione\nr_values &lt;- 850:950  # Intervallo per una migliore visualizzazione\ndist &lt;- dbinom(r_values, size = n, prob = p)\n\n# Grafico\nggplot(data.frame(Successi = r_values, Probabilità = dist), aes(x = Successi, y = Probabilità)) +\n  geom_bar(stat = \"identity\", fill = \"skyblue\", color = \"black\") +\n  labs(\n    title = \"Distribuzione Binomiale: n = 1000, p = 0.9\", \n    x = \"Numero di Successi\", \n    y = \"Probabilità\"\n  ) \n\n\n\n\n\n\n\n\nLa distribuzione Normale fu scoperta da Gauss nel 1809. Il Paragrafo successivo illustra come si possa giungere alla Normale mediante una simulazione.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#la-normale-prodotta-con-una-simulazione",
    "href": "chapters/probability/12_cont_rv_distr.html#la-normale-prodotta-con-una-simulazione",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "36.4 La Normale prodotta con una simulazione",
    "text": "36.4 La Normale prodotta con una simulazione\nIl libro “Rethinking Statistics” di McElreath (2020) spiega come sia possibile ottenere la distribuzione normale attraverso una simulazione. Immaginiamo di avere duemila persone che si trovano allineate su una linea di partenza. Quando viene dato il segnale di partenza, ogni persona lancia una moneta e compie un passo avanti o indietro a seconda del risultato del lancio. La lunghezza di ogni passo può variare da 0 a 1 metro. Ogni persona lancia la moneta 16 volte e quindi compie 16 passi.\nI risultati ottenuti da una serie di passeggiate casuali si traducono in varie distanze dall’origine, che è il punto da cui si parte, contrassegnato come zero, dopo un numero specificato di passi. Queste distanze sono rappresentate numericamente. Al termine di queste passeggiate, non è possibile determinare la posizione esatta di ogni individuo, ma è possibile descrivere accuratamente le caratteristiche della distribuzione delle 1000 distanze dall’origine.\nAd esempio, è possibile prevedere con precisione la frazione di individui che si sono mossi verso in avanti o indietro, o la proporzione di persone che si troveranno a una distanza specifica dal punto di partenza, come a 1.5 metri dall’origine. Queste previsioni sono fattibili perché la distribuzione delle distanze segue una distribuzione Normale.\nIl codice presentato di seguito genera passeggiate casuali utilizzando un generatore di numeri casuali e ne traccia i percorsi risultanti. Il codice inizia inizializzando un oggetto generatore di numeri casuali con la funzione np.random.default_rng() della libreria numpy. Questo generatore sarà usato per produrre numeri casuali uniformemente distribuiti tra -1 e 1, simulando così il lancio di una moneta.\nLa variabile steps specifica il numero di passi per ogni passeggiata casuale, mentre repetitions indica il numero di passeggiate da generare. La variabile show_steps è un elenco di numeri di passi in cui il codice traccerà linee verticali sul grafico.\nSuccessivamente, il codice crea un array bidimensionale di NumPy chiamato x con righe pari a steps + 1 e colonne pari a repetitions. La prima colonna di questo array è riempita di zeri, e le colonne rimanenti sono riempite con la somma cumulativa dei passi, ottenuti da numeri casuali uniformemente distribuiti generati dal generatore di numeri casuali. Questo array verrà utilizzato per memorizzare le posizioni della passeggiata casuale ad ogni passo.\nIl codice poi prepara una figura per tracciare tutte le passeggiate casuali. Il codice traccia anche la prima passeggiata casuale in nero.\n\n# Parametri\nnumero_passi &lt;- 16\nripetizioni &lt;- 1000\npunti_da_evidenziare &lt;- c(4, 8, 16)\n\n# Generare passeggiate casuali\nset.seed(123)\nx &lt;- matrix(0, nrow = numero_passi + 1, ncol = ripetizioni)\n\nfor (i in 1:ripetizioni) {\n  passi &lt;- runif(numero_passi, min = -1, max = 1)\n  x[-1, i] &lt;- cumsum(passi)\n}\n\n# Grafico delle passeggiate casuali\ndf &lt;- data.frame(\n  Passo = rep(0:numero_passi, times = ripetizioni), \n  Distanza = as.vector(x)\n)\n\n# Grafico delle passeggiate casuali\nggplot(\n  df, \n  aes(\n    x = Passo, \n    y = Distanza, \n    group = rep(1:ripetizioni, each = numero_passi + 1))\n  ) +\n  geom_line(color = \"blue\", alpha = 0.05) +\n  geom_line(\n    data = data.frame(Passo = 0:numero_passi, Distanza = x[, 1], group = 1), \n    aes(x = Passo, y = Distanza, group = group), color = \"black\") +\n  geom_vline(\n    xintercept = punti_da_evidenziare, \n    linetype = \"dashed\", \n    color = \"black\", \n    alpha = 0.5) +\n  labs(\n    title = \"Passeggiate Casuali\", \n    x = \"Numero di Passi\", \n    y = \"Distanza dall'Origine\"\n  ) \n\n\n\n\n\n\n\n\nIl grafico riportato qui sotto visualizza la distribuzione dei passi a partire dalla linea mediana dopo 4, 8 e 16 lanci di moneta/passi. Quello che si nota è che, man mano che procediamo nel numero di passi, le densità iniziano a somigliare alla curva a campana associata alle distribuzioni Gaussiane.\n\ndensities &lt;- lapply(punti_da_evidenziare, function(step) {\n  data.frame(Posizione = x[step + 1, ], Passo = step)\n})\n\ndensities &lt;- bind_rows(densities)\n\nggplot(densities, aes(x = Posizione, fill = as.factor(Passo))) +\n  geom_density(alpha = 0.6) +\n  facet_wrap(~ Passo, scales = \"free\") +\n  labs(\n    title = \"Densità delle Posizioni\",\n    x = \"Posizione\",\n    y = \"Densità\",\n    fill = \"Passo\"  # Etichetta per la legenda\n  ) +\n  theme(\n    legend.position = \"bottom\"  # Sposta la legenda in basso\n  )\n\n\n\n\n\n\n\n\nLa chiarezza dell’informazione presentata nei grafici precedenti può essere migliorata utilizzando un KDE plot.\n\n# Generare i dati\nposizioni &lt;- apply(matrix(runif(numero_passi * ripetizioni, min = -1, max = 1), nrow = numero_passi), 2, sum)\n\n# Calcolare media e deviazione standard\nmedia &lt;- mean(posizioni)\ndev_std &lt;- sd(posizioni)\n\n# Generare la curva normale\nvalori &lt;- seq(min(posizioni), max(posizioni), length.out = 1000)\ndensità_normale &lt;- dnorm(valori, mean = media, sd = dev_std)\n\n# Grafico\nggplot(data.frame(Posizione = posizioni), aes(x = Posizione)) +\n  geom_density(fill = \"skyblue\", alpha = 0.5) +\n  geom_line(data = data.frame(Posizione = valori, Densità = densità_normale), aes(x = Posizione, y = Densità), color = \"red\", linetype = \"dashed\") +\n  labs(title = \"Confronto tra Passeggiate Casuali e Normale\", x = \"Posizione\", y = \"Densità\") \n\n\n\n\n\n\n\n\nQuesta simulazione in luce un principio fondamentale della teoria delle probabilità: ogni processo che coinvolge la somma di una sequenza di valori casuali, tutti estratti dalla stessa distribuzione, inevitabilmente tende verso una distribuzione normale, comunemente conosciuta come curva gaussiana. Questa tendenza si verifica indipendentemente dalla configurazione iniziale della distribuzione di partenza, che può essere uniforme, come nell’esempio menzionato, o di qualsiasi altro tipo. La forma specifica della distribuzione iniziale influisce sulla velocità con cui si verifica questa convergenza verso il comportamento gaussiano, con variazioni significative nella velocità di convergenza: alcuni processi possono manifestare una convergenza lenta, mentre altri possono convergere estremamente rapidamente. Un esempio emblematico di questo fenomeno è rappresentato dal dispositivo conosciuto come Galton box, il quale offre una rappresentazione visiva e fisica di come la somma di valori casuali generi una distribuzione normale.\nUn modo per razionalizzare la distribuzione Gaussiana è quello di pensare alle medie. Qualunque sia il valore medio della distribuzione di origine, ogni campione da essa può essere considerato una fluttuazione rispetto a quel valore medio. Tuttavia, quando sommiamo queste fluttuazioni insieme, esse si annullano a vicenda. E, facendo ciò, queste fluttuazioni convergono eventualmente alla media delle osservazioni collettive. Non importa quale sia la forma della distribuzione sottostante. A seconda della forma, le somme cumulative convergeranno inevitabilmente sulla media, alcune distribuzioni più lentamente di altre.\nDal punto di vista formale, possiamo definire una variabile casuale continua \\(Y\\) come avente una distribuzione normale se la sua densità di probabilità è distribuita secondo la seguente equazione\n\\[\nf(y; \\mu, \\sigma) = {1 \\over {\\sigma\\sqrt{2\\pi} }} \\exp \\left\\{-\\frac{(y -  \\mu)^2}{2 \\sigma^2} \\right\\},\n\\tag{36.2}\\]\ndove \\(\\mu \\in \\mathbb{R}\\) e \\(\\sigma &gt; 0\\) sono i parametri della distribuzione.\nLa densità normale è unimodale e simmetrica con una caratteristica forma a campana e con il punto di massima densità in corrispondenza di \\(\\mu\\).\nIl significato dei parametri \\(\\mu\\) e \\(\\sigma\\) che appaiono nell’eq. {eq}eq-normal-formula viene chiarito dalla dimostrazione che\n\\[\n\\mathbb{E}(Y) = \\mu, \\qquad \\mathbb{V}(Y) = \\sigma^2.\n\\]\nLa rappresentazione grafica di quattro densità Normali con medie -1, -0.5, 0, 1 e con deviazioni standard 0.25, 0.5, 1 e 2 è fornita nella figura seguente.\n\n# Definire l'intervallo di x\nx &lt;- seq(-5, 6, by = 0.001)\n\n# Parametri della distribuzione normale\nmus &lt;- c(-1.0, -0.5, 0.0, 1.0)\nsigmas &lt;- c(0.25, 0.5, 1, 2)\n\n# Creare un data frame per tutte le combinazioni di mu e sigma\ndata &lt;- do.call(rbind, lapply(1:length(mus), function(i) {\n  data.frame(\n    x = x,\n    f_x = dnorm(x, mean = mus[i], sd = sigmas[i]),\n    mu = mus[i],\n    sigma = sigmas[i]\n  )\n}))\n\n# Grafico\nggplot(data, aes(x = x, y = f_x, color = factor(mu), linetype = factor(sigma))) +\n  geom_line(size = 1) +\n  labs(\n    x = \"x\",\n    y = \"f(x)\",\n    color = expression(mu),\n    linetype = expression(sigma),\n    title = \"Distribuzioni Normali con Diversi Parametri\"\n  ) +\n  theme(legend.position = \"top\")\n\n\n\n\n\n\n\n\n\n36.4.1 Concentrazione\nÈ istruttivo osservare il grado di concentrazione della distribuzione Normale attorno alla media:\n\\[\n\\begin{align}\nP(\\mu - \\sigma &lt; Y &lt; \\mu + \\sigma) &= P (-1 &lt; Z &lt; 1) \\simeq 0.683, \\notag\\\\\nP(\\mu - 2\\sigma &lt; Y &lt; \\mu + 2\\sigma) &= P (-2 &lt; Z &lt; 2) \\simeq 0.956, \\notag\\\\\nP(\\mu - 3\\sigma &lt; Y &lt; \\mu + 3\\sigma) &= P (-3 &lt; Z &lt; 3) \\simeq 0.997. \\notag\n\\end{align}\n\\]\nSi noti come un dato la cui distanza dalla media è superiore a 3 volte la deviazione standard presenti un carattere di eccezionalità perché meno del 0.3% dei dati della distribuzione Normale presentano questa caratteristica.\nPer indicare la distribuzione Normale si usa la notazione \\(\\mathcal{N}(\\mu, \\sigma)\\).\n\n\n36.4.2 Funzione di ripartizione\nIl valore della funzione di ripartizione di \\(Y\\) nel punto \\(y\\) è l’area sottesa alla curva di densità \\(f(y)\\) nella semiretta \\((-\\infty, y]\\). Non esiste alcuna funzione elementare per la funzione di ripartizione\n\\[\nF(y) = \\int_{-\\infty}^y {1 \\over {\\sigma\\sqrt{2\\pi} }} \\exp \\left\\{-\\frac{(y - \\mu)^2}{2\\sigma^2} \\right\\} dy,\n\\] (eq-gaussian-rip-formula)\npertanto le probabilità \\(P(Y &lt; y)\\) vengono calcolate mediante integrazione numerica approssimata. I valori della funzione di ripartizione di una variabile casuale Normale sono dunque forniti da un software.\nEcco l’equivalente in R utilizzando le funzioni per la distribuzione normale e il pacchetto ggplot2 per i grafici.\n\n\n36.4.3 Generazione di Valori Casuali\nIn R, la funzione rnorm() genera valori casuali dalla distribuzione normale. Ad esempio, per ottenere un singolo valore casuale dalla \\(\\mathcal{N}(100, 15)\\):\n\n# Generare un singolo valore casuale\nset.seed(123)  # Per la riproducibilità\nrnorm(1, mean = 100, sd = 15)\n#&gt; [1] 91.59287\n\nPer estrarre 10 valori casuali dalla stessa distribuzione:\n\n# Generare 10 valori casuali\nset.seed(123)\nqi &lt;- rnorm(10, mean = 100, sd = 15)\nprint(qi)\n#&gt;  [1]  91.59287  96.54734 123.38062 101.05763 101.93932 125.72597 106.91374\n#&gt;  [8]  81.02408  89.69721  93.31507\n\n\n\n36.4.4 Funzione di Ripartizione (CDF)\nPer calcolare la probabilità che un’osservazione casuale abbia un valore minore o uguale a 115, utilizziamo pnorm():\n\n# Probabilità che X &lt;= 115\npnorm(115, mean = 100, sd = 15)\n#&gt; [1] 0.8413447\n\n\n\n36.4.5 Visualizzazione dell’Area Sottesa alla Funzione di Densità\nPossiamo visualizzare l’area sottesa utilizzando ggplot2:\n\n# Parametri\nmu &lt;- 100\nsigma &lt;- 15\n\n# Intervallo di x\nx &lt;- seq(mu - 3 * sigma, mu + 3 * sigma, length.out = 1000)\n\n# Densità\nfx &lt;- dnorm(x, mean = mu, sd = sigma)\n\n# Grafico\nggplot(data.frame(x, fx), aes(x = x, y = fx)) +\n  geom_line(color = \"blue\") +\n  geom_area(\n    data = subset(data.frame(x, fx), x &lt;= 115), \n    aes(x = x, y = fx), fill = \"gray\", alpha = 0.5\n  ) +\n  labs(title = \"Funzione di Densità Normale\", x = \"x\", y = \"f(x)\") \n\n\n\n\n\n\n\n\n\n\n36.4.6 Calcolo dell’Integrale con integrate\nPossiamo calcolare l’area sotto la curva manualmente utilizzando la funzione integrate:\n\n# Definizione della funzione gaussiana\ngaussian &lt;- function(x, mu, sigma) {\n  (1 / (sqrt(2 * pi) * sigma)) * exp(-((x - mu)^2) / (2 * sigma^2))\n}\n\n# Calcolo dell'area\nresult &lt;- integrate(gaussian, lower = -Inf, upper = 115, mu = 100, sigma = 15)\nprint(paste(\"Il risultato è\", result$value, \"con errore\", result$abs.error))\n#&gt; [1] \"Il risultato è 0.84134474610298 con errore 3.76616994661114e-06\"\n\n\n\n36.4.7 Proporzione di Valori Maggiori di 130\nCalcoliamo \\(P(X &gt; 130)\\) utilizzando il complementare della funzione di ripartizione:\n\n# Probabilità che X &gt; 130\n1 - pnorm(130, mean = 100, sd = 15)\n#&gt; [1] 0.02275013\n\nPossiamo anche utilizzare la funzione di sopravvivenza 1 - pnorm():\n\n# Funzione di sopravvivenza\npnorm(130, mean = 100, sd = 15, lower.tail = FALSE)\n#&gt; [1] 0.02275013\n\nVisualizzazione:\n\nggplot(data.frame(x, fx), aes(x = x, y = fx)) +\n  geom_line(color = \"blue\") +\n  geom_area(\n    data = subset(data.frame(x, fx), x &gt;= 130), \n    aes(x = x, y = fx), fill = \"gray\", alpha = 0.5\n  ) +\n  labs(title = \"Area Sottesa per X &gt;= 130\", x = \"x\", y = \"f(x)\") \n\n\n\n\n\n\n\n\n\n\n36.4.8 Funzione di Quantile (PPF)\nLa funzione qnorm() restituisce il quantile della distribuzione normale. Ad esempio:\n\n# Quantile corrispondente al 97.725%\nqnorm(1 - 0.022750131948179195, mean = 100, sd = 15)\n#&gt; [1] 130\n\nIn conclusione, le funzioni rnorm, dnorm, pnorm, e qnorm in R forniscono gli strumenti necessari per manipolare la distribuzione normale.\n\n\n36.4.9 Distribuzione Normale standard\nLa distribuzione Normale di parametri \\(\\mu = 0\\) e \\(\\sigma = 1\\) viene detta distribuzione Normale standard. La famiglia Normale è l’insieme avente come elementi tutte le distribuzioni Normali con parametri \\(\\mu\\) e \\(\\sigma\\) diversi. Tutte le distribuzioni Normali si ottengono dalla Normale standard mediante una trasformazione lineare: se \\(Y \\sim \\mathcal{N}(\\mu_Y, \\sigma_Y)\\) allora\n\\[\nX = a + b Y \\sim \\mathcal{N}(\\mu_X = a+b \\mu_Y, \\sigma_X = \\left|b\\right|\\sigma_Y).\n\\]\nL’area sottesa alla curva di densità di \\(\\mathcal{N}(\\mu, \\sigma)\\) nella semiretta \\((-\\infty, y]\\) è uguale all’area sottesa alla densità Normale standard nella semiretta \\((-\\infty, z]\\), in cui \\(z = (y -\\mu_Y )/\\sigma_Y\\) è il punteggio standard di \\(Y\\). Per la simmetria della distribuzione, l’area sottesa nella semiretta \\([1, \\infty)\\) è uguale all’area sottesa nella semiretta \\((-\\infty, 1]\\) e quest’ultima coincide con \\(F(-1)\\). Analogamente, l’area sottesa nell’intervallo \\([y_a, y_b]\\), con \\(y_a &lt; y_b\\), è pari a \\(F(z_b) - F(z_a)\\), dove \\(z_a\\) e \\(z_b\\) sono i punteggi standard di \\(y_a\\) e \\(y_b\\).\nSi ha anche il problema inverso rispetto a quello del calcolo delle aree: dato un numero \\(0 \\leq p \\leq 1\\), il problema è quello di determinare un numero \\(z \\in \\mathbb{R}\\) tale che \\(P(Z &lt; z) = p\\). Il valore \\(z\\) cercato è detto quantile di ordine \\(p\\) della Normale standard e può essere trovato mediante un software.\nSupponiamo che l’altezza degli individui adulti segua la distribuzione Normale di media \\(\\mu = 1.7\\) m e deviazione standard \\(\\sigma = 0.1\\) m. Vogliamo sapere la proporzione di individui adulti con un’altezza compresa tra \\(1.7\\) e \\(1.8\\) m.\nIl problema ci chiede di trovare l’area sottesa alla distribuzione \\(\\mathcal{N}(\\mu = 1.7, \\sigma = 0.1)\\) nell’intervallo \\([1.7, 1.8]\\):\n\n# Parametri della distribuzione\nmu &lt;- 1.7\nsigma &lt;- 0.1\n\n# Calcolare la probabilità cumulativa\nprob &lt;- pnorm(1.8, mean = mu, sd = sigma) - pnorm(1.7, mean = mu, sd = sigma)\nprint(prob)\n#&gt; [1] 0.3413447\n\n\n# Generare dati\nx &lt;- seq(mu - 3 * sigma, mu + 3 * sigma, length.out = 1000)\nfx &lt;- dnorm(x, mean = mu, sd = sigma)\n\n# Creare il grafico\nggplot(data.frame(x, fx), aes(x = x, y = fx)) +\n  geom_line(color = \"blue\") +\n  geom_area(data = subset(data.frame(x, fx), x &gt;= 1.7 & x &lt;= 1.8), \n            aes(x = x, y = fx), fill = \"gray\", alpha = 0.5) +\n  labs(title = \"Funzione di Densità Normale\", \n       x = \"Altezza (m)\", \n       y = \"Densità\")\n\n\n\n\n\n\n\n\nIn maniera equivalente, possiamo standardizzare i valori che delimitano l’intervallo considerato e utilizzare la funzione di ripartizione della normale standardizzata. I limiti inferiore e superiore dell’intervallo sono\n\\[\nz_{\\text{inf}} = \\frac{1.7 - 1.7}{0.1} = 0, \\quad z_{\\text{sup}} = \\frac{1.8 - 1.7}{0.1} = 1.0,\n\\]\nquindi otteniamo\n\n# Standardizzazione\nz_inf &lt;- (1.7 - mu) / sigma\nz_sup &lt;- (1.8 - mu) / sigma\n\n# Calcolo con la normale standardizzata\nprob_standard &lt;- pnorm(z_sup, mean = 0, sd = 1) - pnorm(z_inf, mean = 0, sd = 1)\nprint(prob_standard)\n#&gt; [1] 0.3413447\n\nIl modo più semplice per risolvere questo problema resta comunque quello di rendersi conto che la probabilità richiesta non è altro che la metà dell’area sottesa dalle distribuzioni Normali nell’intervallo \\([\\mu - \\sigma, \\mu + \\sigma]\\), ovvero \\(0.683/2\\).\nConsideriamo ora la visualizzazione della PDF, la CDF e l’inverso della CDF della distribuzione normale.\n\n# Parametri della distribuzione\nmu &lt;- 100\nsigma &lt;- 15\n\n# Generare intervalli di valori\nx &lt;- seq(mu - 3 * sigma, mu + 3 * sigma, length.out = 1000)\nprobabilities &lt;- seq(0.01, 0.99, length.out = 100)\n\n# Calcolo delle funzioni\npdf &lt;- dnorm(x, mean = mu, sd = sigma)\ncdf &lt;- pnorm(x, mean = mu, sd = sigma)\nppf &lt;- qnorm(probabilities, mean = mu, sd = sigma)\n\n# Creare i grafici con ggplot2\nlibrary(gridExtra)\n\n# Grafico della PDF\npdf_plot &lt;- ggplot(data.frame(x, pdf), aes(x = x, y = pdf)) +\n  geom_line(color = \"blue\") +\n  labs(title = \"PDF\", x = \"Valori\", y = \"Probabilità\")\n\n# Grafico della CDF\ncdf_plot &lt;- ggplot(data.frame(x, cdf), aes(x = x, y = cdf)) +\n  geom_line(color = \"orange\") +\n  labs(title = \"CDF\", x = \"Valori\", y = \"Cumulativa\")\n\n# Grafico dell'inversa della CDF\nppf_plot &lt;- ggplot(data.frame(Probabilità = probabilities, Valori = ppf), aes(x = Probabilità, y = Valori)) +\n  geom_line(color = \"green\") +\n  labs(title = \"Inverse CDF\", x = \"Probabilità\", y = \"Valori\") \n\n# Mostrare i grafici\ngrid.arrange(pdf_plot, cdf_plot, ppf_plot, ncol = 3)\n\n\n\n\n\n\n\n\nDovrebbe essere chiaro dalla figura che queste sono tre diverse modalità di osservare la stessa informazione.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-chi-quadrato",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-chi-quadrato",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "36.5 Distribuzione Chi-quadrato",
    "text": "36.5 Distribuzione Chi-quadrato\nDalla Normale deriva la distribuzione \\(\\chi^2\\). La distribuzione \\(\\chi^2_{~k}\\) con \\(k\\) gradi di libertà descrive la variabile casuale\n\\[\nZ_1^2 + Z_2^2 + \\dots + Z_k^2,\n\\]\ndove \\(Z_1, Z_2, \\dots, Z_k\\) sono variabili casuali i.i.d. che seguono la distribuzione Normale standard \\(\\mathcal{N}(0, 1)\\). La variabile casuale chi-quadrato dipende dal parametro intero positivo \\(\\nu = k\\) che ne identifica il numero di gradi di libertà. La densità di probabilità di \\(\\chi^2_{~\\nu}\\) è\n\\[\nf(x) = C_{\\nu} x^{\\nu/2-1} \\exp (-x/2), \\qquad \\text{se } x &gt; 0,\n\\]\ndove \\(C_{\\nu}\\) è una costante positiva.\n\n36.5.1 Grafico delle Distribuzioni Chi-Quadrato per Vari Valori di \\(\\nu\\)\nIn R, utilizziamo dchisq() per calcolare la funzione di densità della distribuzione chi-quadrato e ggplot2 per creare il grafico.\n\n# Intervallo di x\nx &lt;- seq(0, 40, by = 0.1)\n\n# Valori di gradi di libertà\nnus &lt;- c(2, 4, 8, 16)\n\n# Creazione del data frame per il grafico\ndata &lt;- do.call(rbind, lapply(nus, function(nu) {\n  data.frame(x = x, f_x = dchisq(x, df = nu), nu = as.factor(nu))\n}))\n\n# Grafico\nggplot(data, aes(x = x, y = f_x, color = nu)) +\n  geom_line(size = 1) +\n  labs(\n    title = \"Distribuzioni Chi-Quadrato per Diversi Valori di \\u03bd\",\n    x = \"x\",\n    y = \"f(x)\",\n    color = expression(nu)\n  ) \n\n\n\n\n\n\n\n\n\n\n36.5.2 Proprietà della Distribuzione Chi-Quadrato\n\nAsimmetria: La distribuzione \\(\\chi^2_{\\nu}\\) è asimmetrica.\nMedia: Il valore atteso di una variabile \\(\\chi^2_{\\nu}\\) è uguale a \\(\\nu\\).\nVarianza: La varianza è pari a \\(2\\nu\\).\nConvergenza: Per \\(k \\to \\infty\\), \\(\\chi^2_{\\nu} \\to \\mathcal{N}(\\nu, 2\\nu)\\).\nSomma di variabili: La somma di variabili \\(\\chi^2_{\\nu}\\) indipendenti con gradi di libertà diversi segue una distribuzione \\(\\chi^2_{m}\\), dove \\(m\\) è la somma dei gradi di libertà.\n\n\n\n36.5.3 Esempio con \\(\\chi^2_5\\)\n\n36.5.3.1 Densità della Distribuzione \\(\\chi^2_5\\)\n\n# Parametri\ndf &lt;- 5\nx &lt;- seq(0, 20, length.out = 200)\n\n# Calcolare la densità\npdf &lt;- dchisq(x, df = df)\n\n# Grafico\nggplot(data.frame(x, pdf), aes(x = x, y = pdf)) +\n  geom_line(color = \"blue\", size = 1) +\n  labs(\n    title = \"Distribuzione Chi-Quadrato (\\u03bd=5)\",\n    x = \"x\",\n    y = \"PDF\"\n  ) \n\n\n\n\n\n\n\n\n\n\n36.5.3.2 Generazione di Valori Casuali\nIn R, utilizziamo rchisq() per generare valori casuali dalla distribuzione chi-quadrato.\n\n# Generare 1.000.000 di valori casuali\nset.seed(123)  # Per riproducibilità\nx_samples &lt;- rchisq(1000000, df = df)\n\n# Mostrare i primi 20 valori\nhead(x_samples, 20)\n#&gt;  [1]  2.5718020  8.0747086  0.6485141  4.3740386 10.3216603  5.4098898\n#&gt;  [7]  1.2220565  0.6062728  8.2114143  5.0824402  5.2138617  4.3191833\n#&gt; [13]  2.5823235  8.5003495  6.6757373  3.8440466  2.7745098  3.4127394\n#&gt; [19]  1.6243638  3.7620351\n\n\n\n36.5.3.3 Calcolo della Media\nLa media teorica della distribuzione chi-quadrato è uguale a \\(\\nu\\). Verifichiamo empiricamente:\n\n# Calcolare la media\nmean(x_samples)\n#&gt; [1] 4.997691\n\n\n36.5.3.3.1 Calcolo della Varianza\nLa varianza teorica della distribuzione chi-quadrato è \\(2\\nu\\). Verifichiamo empiricamente:\n\n# Calcolare la varianza\nvar(x_samples)\n#&gt; [1] 9.990927\n\nIn conclusione,\n\nla distribuzione chi-quadrato è asimmetrica e converge alla distribuzione normale per valori elevati di \\(\\nu\\),\nla media e la varianza empiriche dei valori generati sono vicine ai valori teorici, verificando le proprietà della distribuzione.\n\nEcco la riscrittura del testo e del codice in R:",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-t-di-student",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-t-di-student",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "36.6 Distribuzione \\(t\\) di Student",
    "text": "36.6 Distribuzione \\(t\\) di Student\nDalle distribuzioni Normale e Chi-quadrato deriva un’altra distribuzione molto nota, la \\(t\\) di Student. Se \\(Z \\sim \\mathcal{N}(0, 1)\\) e \\(W \\sim \\chi^2_{\\nu}\\) sono due variabili casuali indipendenti, allora il rapporto\n\\[\nT = \\frac{Z}{\\Big( \\frac{W}{\\nu}\\Big)^{\\frac{1}{2}}}\n\\]\ndefinisce la distribuzione \\(t\\) di Student con \\(\\nu\\) gradi di libertà. Si usa scrivere \\(T \\sim t_{\\nu}\\). L’andamento della distribuzione \\(t\\) di Student è simile a quello della distribuzione Normale, ma ha una dispersione maggiore (ha le code più pesanti di una Normale, ovvero ha una varianza maggiore di 1).\nLa seguente mostra alcune distribuzioni \\(t\\) di Student variando il parametro \\(\\nu\\).\n\nx &lt;- seq(-5, 5, by = 0.1)\nnus &lt;- c(1, 2, 5, 30)\n\ndf &lt;- data.frame(\n  x = rep(x, length(nus) + 1),\n  density = c(\n    sapply(nus, function(nu) dt(x, df = nu)), dnorm(x, mean = 0, sd = 1)\n  ),\n  distribution = factor(\n    rep(c(paste0(\"t (ν = \", nus, \")\"), \"N(μ = 0, σ = 1)\"), each = length(x))\n  )\n)\n\nggplot(df, aes(x = x, y = density, color = distribution)) +\n  geom_line(size = 1) +\n  labs(\n    x = \"x\", \n    y = \"f(x)\", \n    title = \"Distribuzione t di Student e Normale\"\n  ) +\n  theme(legend.position = \"top\")\n\n\n\n\n\n\n\n\n\n36.6.1 Proprietà\nLa variabile casuale \\(t\\) di Student soddisfa le seguenti proprietà:\n\nPer \\(\\nu \\rightarrow \\infty\\), \\(t_{\\nu}\\) tende alla normale standard \\(\\mathcal{N}(0, 1)\\).\nLa densità della \\(t_{\\nu}\\) è una funzione simmetrica con valore atteso nullo.\nPer \\(\\nu &gt; 2\\), la varianza della \\(t_{\\nu}\\) vale \\(\\nu / (\\nu - 2)\\); pertanto è sempre maggiore di 1 e tende a 1 per \\(\\nu \\rightarrow \\infty\\).\n\nCalcoliamo il valore della funzione di ripartizione di ordine 0.025 nel caso di una \\(t_{30}\\):\n\nqt(0.025, df = 30)\n#&gt; [1] -2.042272\n\nAumentiamo i gradi di libertà (\\(\\nu\\) = 1000):\n\nqt(0.025, df = 1000)\n#&gt; [1] -1.962339\n\nQuesto valore è quasi identico a quello della Normale standardizzata:\n\nqnorm(0.025, mean = 0, sd = 1)\n#&gt; [1] -1.959964\n\nLa ragione per cui il quantile della distribuzione \\(t\\) con \\(\\nu = 30\\) è maggiore (in valore assoluto) del quantile omotetico della distribuzione Normale Standard è che la distribuzione \\(t\\) ha una varianza maggiore rispetto alla distribuzione Normale Standard.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#funzione-beta-di-eulero",
    "href": "chapters/probability/12_cont_rv_distr.html#funzione-beta-di-eulero",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "36.7 Funzione Beta di Eulero",
    "text": "36.7 Funzione Beta di Eulero\nLa funzione Beta di Eulero è una funzione matematica, non una densità di probabilità. La menzioniamo qui perché viene utilizzata nella densità di probabilità Beta. La funzione Beta di Eulero, comunemente indicata con il simbolo \\(B(\\alpha, \\beta)\\), si può scrivere in molti modi diversi; per i nostri scopi la presentiamo così:\n\\[\nB(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}\\,,\n\\]\ndove \\(\\Gamma(x)\\) è la funzione Gamma, ovvero il fattoriale discendente, cioè\n\\[\n(x-1)(x-2)\\ldots (x-n+1)\\notag\\,.\n\\]\nPer esempio, posti \\(\\alpha = 3\\) e \\(\\beta = 9\\), la funzione Beta di Eulero assume il valore:\n\nalpha &lt;- 3\nbeta &lt;- 9\n\nbeta_function &lt;- gamma(alpha) * gamma(beta) / gamma(alpha + beta)\nbeta_function\n#&gt; [1] 0.002020202\n\nLo stesso risultato si ottiene usando direttamente la funzione beta in R:\n\nbeta(alpha, beta)\n#&gt; [1] 0.002020202\n\nOppure calcolandolo manualmente:\n\n(factorial(alpha - 1) * factorial(beta - 1)) / factorial(alpha + beta - 1)\n#&gt; [1] 0.002020202",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-beta",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-beta",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "36.8 Distribuzione Beta",
    "text": "36.8 Distribuzione Beta\nLa distribuzione di probabilità Beta, denotata comunemente come \\(Beta(\\alpha, \\beta)\\), è utilizzata per modellare fenomeni che sono espressi in percentuali o proporzioni. Un aspetto cruciale di questa distribuzione è la sua definizione esclusiva nell’intervallo \\((0, 1)\\). In pratica, ciò significa che essa considera valori compresi strettamente tra 0 e 1, escludendo sia lo 0 che l’1 come estremi.\n\n36.8.1 Definizione Formale\nConsideriamo una variabile casuale \\(\\theta\\), la quale può assumere qualunque valore nell’intervallo aperto \\((0, 1)\\). Se diciamo che \\(\\theta\\) segue una distribuzione Beta con parametri \\(\\alpha\\) e \\(\\beta\\) (indicato come \\(\\theta \\sim \\text{Beta}(\\alpha, \\beta)\\)), intendiamo che la sua funzione di densità è descritta dalla seguente formula:\n\\[\n\\text{Beta}(\\theta \\mid \\alpha, \\beta) = \\frac{1}{B(\\alpha, \\beta)}\\theta^{\\alpha-1} (1-\\theta)^{\\beta-1} =  \\frac{\\Gamma(\\alpha+ \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\theta^{\\alpha-1} (1-\\theta)^{\\beta-1} \\quad \\text{per } \\theta \\in (0, 1)\\,,\n\\]\ndove \\(B(\\alpha, \\beta)\\) è la funzione beta di Eulero, definita come \\(\\frac{\\Gamma(\\alpha) \\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}\\).\n\n\n36.8.2 I Parametri \\(\\alpha\\) e \\(\\beta\\)\nI parametri \\(\\alpha\\) e \\(\\beta\\) giocano un ruolo cruciale nella distribuzione Beta, influenzando direttamente la sua forma e il suo comportamento. È essenziale che entrambi questi parametri siano positivi.\n\n\n36.8.3 Intuizione e Collegamento con la Distribuzione Binomiale\nLa distribuzione Beta può essere meglio compresa quando la si osserva in relazione con la distribuzione binomiale. Mentre la distribuzione binomiale modella il numero di successi in una serie di prove, la distribuzione Beta si focalizza sulla probabilità di successo in queste prove.\nNel contesto della distribuzione binomiale, la probabilità di successo è un parametro fisso; nella distribuzione Beta, questa probabilità diventa una variabile aleatoria.\n\n\n36.8.4 Interpretazione dei Parametri \\(\\alpha\\) e \\(\\beta\\)\nI parametri \\(\\alpha\\) e \\(\\beta\\) possono essere interpretati come rappresentanti il numero di successi e insuccessi, rispettivamente. Questa interpretazione è analoga ai termini \\(n\\) e \\(n-x\\) nella distribuzione binomiale.\nLa scelta di \\(\\alpha\\) e \\(\\beta\\) dipende dall’aspettativa iniziale della probabilità di successo: - Se si presume un’alta probabilità di successo (ad esempio, 90%), si potrebbe scegliere \\(\\alpha = 90\\) e \\(\\beta = 10\\). - Al contrario, per una bassa aspettativa di successo, si potrebbe impostare \\(\\alpha = 10\\) e \\(\\beta = 90\\).\nUn aumento di \\(\\alpha\\) (successi) sposta la distribuzione verso destra, mentre un aumento di \\(\\beta\\) (insuccessi) la sposta verso sinistra. Inoltre, se sia \\(\\alpha\\) sia \\(\\beta\\) aumentano, la distribuzione diventa più stretta, indicando una maggiore certezza.\nQuesta interpretazione consente di utilizzare la distribuzione Beta per esprimere le nostre credenze a priori riguardo a una sequenza di prove di Bernoulli, dove il rapporto tra successi e tentativi totali è dato da:\n\\[\n\\frac{\\text{Numero di successi}}{\\text{Numero di successi} + \\text{Numero di insuccessi}} = \\frac{\\alpha}{\\alpha + \\beta}\\notag\\,.\n\\]\nAl variare di \\(\\alpha\\) e \\(\\beta\\) si ottengono molte distribuzioni di forma diversa; un’illustrazione è fornita dalla seguente GIF animata.\nLa figura seguente mostra la distribuzione \\(Beta(x \\mid \\alpha, \\beta)\\) per \\(\\alpha\\) = 0.5, 5.0, 1.0, 2.0, 2.0 e \\(\\beta\\) = 5, 1.0, 3.0, 2.0, 5.0.\n\n# Define the parameters\nx &lt;- seq(0, 1, length.out = 200)\nalphas &lt;- c(0.5, 5.0, 1.0, 2.0, 2.0)\nbetas &lt;- c(0.5, 1.0, 3.0, 2.0, 5.0)\n\n# Create a data frame for plotting\ndf &lt;- do.call(rbind, lapply(1:length(alphas), function(i) {\n  data.frame(\n    x = x,\n    density = dbeta(x, alphas[i], betas[i]),\n    label = paste0(\"α = \", alphas[i], \", β = \", betas[i])\n  )\n}))\n\nggplot(df, aes(x = x, y = density, color = label)) +\n  geom_line(size = 1) +\n  labs(\n    x = \"x\",\n    y = \"f(x)\",\n    title = \"Distribuzioni Beta\"\n  ) +\n  ylim(0, 4.5) +\n  theme(\n    legend.title = element_blank(),\n    legend.position = \"top\"\n  )\n#&gt; Warning: Removed 6 rows containing missing values or values outside the scale range\n#&gt; (`geom_line()`).\n\n\n\n\n\n\n\n\n\n\n36.8.5 Costante di normalizzazione\nLa relazione \\(\\frac{1}{B(\\alpha, \\beta)} = \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\) definisce il reciproco della funzione Beta di Eulero, \\(B(\\alpha, \\beta)\\), come una costante di normalizzazione. Qui, \\(\\Gamma(\\cdot)\\) denota la funzione Gamma di Eulero. Questa costante di normalizzazione garantisce che\n\\[\n\\int_0^1 \\theta^{\\alpha-1} (1-\\theta)^{\\beta-1} d\\theta = 1\\,,\n\\]\nper \\(\\alpha, \\beta &gt; 0\\). Questa integrazione conferma che \\(\\theta^{\\alpha-1} (1-\\theta)^{\\beta-1}\\), quando moltiplicata per la costante di normalizzazione, forma una densità di probabilità che si estende sull’intervallo \\([0,1]\\), con l’area sottesa dalla curva (l’integrale) uguale a 1.\nAd esempio, con \\(\\alpha = 3\\) e \\(\\beta = 9\\), possiamo calcolare il risultato integrando la funzione \\((p^{\\alpha - 1} \\cdot (1 - p)^{\\beta - 1})\\) su \\([0, 1]\\), usando la funzione integrate in R:\n\n# Definizione della funzione da integrare\nintegrand &lt;- function(p, a, b) {\n  p^(a - 1) * (1 - p)^(b - 1)\n}\n\n# Parametri\na &lt;- 3\nb &lt;- 9\n\n# Calcolo dell'integrale\nresult &lt;- integrate(integrand, lower = 0, upper = 1, a = a, b = b)\nresult$value  # Valore dell'integrale\n#&gt; [1] 0.002020202\n\nOtteniamo lo stesso risultato calcolando esplicitamente la funzione Beta di Eulero:\n\n# Calcolo usando la funzione Gamma\nresult_gamma &lt;- gamma(a) * gamma(b) / gamma(a + b)\nresult_gamma\n#&gt; [1] 0.002020202\n\nOppure utilizzando la funzione beta già disponibile in R:\n\n# Calcolo con la funzione beta\nresult_beta &lt;- beta(a, b)\nresult_beta\n#&gt; [1] 0.002020202\n\nQuesti approcci mostrano che i diversi metodi producono lo stesso valore per la funzione Beta di Eulero.\n\n\n36.8.6 Proprietà\nIl valore atteso, la moda e la varianza di una densità di probabilità Beta sono dati dalle seguenti equazioni:\n\\[\n\\mathbb{E}(\\theta) = \\frac{\\alpha}{\\alpha+\\beta}\\,,\n\\] (eq-beta-mean)\n\\[\nMo(\\theta) = \\frac{\\alpha-1}{\\alpha+\\beta-2}\\,,\n\\] (eq-beta-mode)\n\\[\n\\mathbb{V}(\\theta) = \\frac{\\alpha \\beta}{(\\alpha+\\beta)^2 (\\alpha+\\beta+1)}\\,.\n\\] (eq-beta-var)\nUsando le formule precedenti, possiamo definire una funzione beta_mean_mode_variance() in R per calcolare la media, la moda e la varianza di una distribuzione di probabilità Beta:\n\n# Funzione per calcolare media, moda e varianza della distribuzione Beta\nbeta_mean_mode_variance &lt;- function(alpha, beta) {\n  mean &lt;- alpha / (alpha + beta)\n  mode &lt;- ifelse(alpha &gt; 1 & beta &gt; 1, (alpha - 1) / (alpha + beta - 2), NA) # Moda definita solo per alpha, beta &gt; 1\n  variance &lt;- (alpha * beta) / ((alpha + beta)^2 * (alpha + beta + 1))\n  list(mean = mean, mode = mode, variance = variance)\n}\n\n# Esempio di utilizzo\nalpha &lt;- 7\nbeta &lt;- 3\nresult &lt;- beta_mean_mode_variance(alpha, beta)\n\n# Stampa dei risultati\ncat(sprintf(\"Mean: %.2f, Mode: %.2f, Variance: %.4f\\n\", result$mean, result$mode, result$variance))\n#&gt; Mean: 0.70, Mode: 0.75, Variance: 0.0191\n\n\n\n36.8.7 Risultati\nLa funzione calcola: - Media: \\(\\mu = \\frac{\\alpha}{\\alpha + \\beta}\\), - Moda: \\(\\frac{\\alpha - 1}{\\alpha + \\beta - 2}\\) (definita solo per \\(\\alpha &gt; 1\\) e \\(\\beta &gt; 1\\)), - Varianza: \\(\\frac{\\alpha \\cdot \\beta}{(\\alpha + \\beta)^2 \\cdot (\\alpha + \\beta + 1)}\\).\nSe \\(\\alpha\\) o \\(\\beta\\) sono inferiori o uguali a 1, la moda non è definita.\n\n\n36.8.8 Distribuzione a priori coniugata\nLa distribuzione Beta rappresenta una prior coniugata ottimale per una gamma di distribuzioni legate a eventi di successo e fallimento, quali le distribuzioni Bernoulli, Binomiale, Binomiale Negativa e Geometrica, nell’ambito dell’inferenza Bayesiana. Questa caratteristica di prior coniugata rende il calcolo della distribuzione a posteriori particolarmente efficiente, poiché permette di bypassare onerose computazioni numeriche tipicamente associate all’inferenza Bayesiana.\nPrendiamo, ad esempio, il caso in cui la distribuzione Beta, espressa come Beta(α, β), venga adottata come prior nel contesto di una distribuzione Binomiale. Questa scelta metodologica ci assicura che la distribuzione a posteriori manterrà la forma funzionale della distribuzione Beta. Ciò significa che, una volta raccolti i dati, l’aggiornamento a posteriori può essere eseguito semplicemente aggiungendo il numero di successi osservati (x) e il numero di fallimenti (n-x) ai parametri α e β del prior, rispettivamente. In tal modo, si ottiene una distribuzione a posteriori Beta con parametri aggiornati (α+x, β+n-x), senza la necessità di compiere la moltiplicazione tra la funzione di verosimiglianza e il prior.\n\n\n\n\n\n\nAvviso\n\n\n\nÈ importante prestare attenzione all’uso del termine “Beta” in questo contesto, poiché assume significati differenti a seconda del riferimento: - La distribuzione Beta, che descrive una distribuzione di probabilità continua. - La funzione Beta, una funzione matematica speciale. - Il parametro β, che insieme ad α, definisce i parametri specifici della distribuzione Beta.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-di-cauchy",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-di-cauchy",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "36.9 Distribuzione di Cauchy",
    "text": "36.9 Distribuzione di Cauchy\nLa distribuzione di Cauchy è un caso speciale della distribuzione di \\(t\\) di Student con 1 grado di libertà. È definita da una densità di probabilità che corrisponde alla seguente funzione, dipendente da due parametri \\(\\alpha\\) e \\(\\beta\\),\n\\[\nf(x \\mid \\alpha, \\beta) = \\frac{1}{\\pi \\beta \\left[1 + \\left( \\frac{x - \\alpha}{\\beta} \\right)^2\\right]}.\n\\tag{36.3}\\]\nIl grafico mostra alcune distribuzioni di Cauchy con \\(\\alpha\\) = 0., 0., 0., -2.0 e \\(\\beta\\) = .5, 1., 2., 1.0.\n\n# Definire i parametri\nx &lt;- seq(-5, 5, length.out = 500)\nalphas &lt;- c(0.0, 0.0, 0.0, -2.0)\nbetas &lt;- c(0.5, 1.0, 2.0, 1.0)\n\n# Creare un data frame per i risultati\ndf &lt;- do.call(rbind, lapply(1:length(alphas), function(i) {\n  data.frame(\n    x = x,\n    density = dcauchy(x, location = alphas[i], scale = betas[i]),\n    label = paste0(\"α = \", alphas[i], \", β = \", betas[i])\n  )\n}))\n\nggplot(df, aes(x = x, y = density, color = label)) +\n  geom_line(size = 1) +\n  labs(\n    x = \"x\",\n    y = \"f(x)\",\n    title = \"Distribuzioni di Cauchy con diversi parametri\"\n  ) +\n  theme(\n    legend.title = element_blank(),\n    legend.position = \"top\"\n  )",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-gamma",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-gamma",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "36.10 Distribuzione Gamma",
    "text": "36.10 Distribuzione Gamma\nLa distribuzione Gamma è ampiamente utilizzata nella statistica bayesiana come distribuzione a priori per parametri che sono strettamente positivi, come tassi o varianze. È particolarmente utile nella modellazione di variabili che rappresentano tempi di attesa o qualsiasi altra quantità che può assumere solo valori positivi. La densità di probabilità Gamma gioca un ruolo fondamentale nella modellazione del tempo di attesa per l’occorrenza di un certo numero di eventi indipendenti e rari, rendendola adatta per processi di Poisson generalizzati.\nLa distribuzione Gamma può essere vista come una generalizzazione della distribuzione esponenziale. Più precisamente, la distribuzione esponenziale è un caso speciale della distribuzione Gamma. Se sommiamo \\(n\\) variabili casuali indipendenti, ciascuna delle quali segue una distribuzione esponenziale con parametro \\(\\lambda\\), il risultato segue una distribuzione Gamma con parametri \\(n\\) (numero di variabili sommate) e \\(\\lambda\\) (tasso esponenziale). Questo si formalizza come:\n\\[\n\\text{Gamma}(n, \\lambda) = \\sum_{i=1}^n \\text{Esponenziale}(\\lambda).\n\\]\nIn particolare, la distribuzione Gamma con parametro di forma 1, ovvero \\(\\text{Gamma}(1, \\lambda)\\), corrisponde esattamente a una distribuzione esponenziale con parametro \\(\\lambda\\), cioè:\n\\[\n\\text{Gamma}(1, \\lambda) = \\text{Esponenziale}(\\lambda).\n\\]\nLa distribuzione Gamma è anche legata alla distribuzione normale in alcuni contesti. Sebbene non vi sia una relazione diretta e semplice tra una distribuzione Gamma e una normale, un caso specifico è quando il parametro di forma \\(n\\) è molto grande (cioè \\(n \\to \\infty\\)). In questo caso, la distribuzione Gamma può essere approssimata da una distribuzione normale tramite il teorema del limite centrale. Più precisamente, quando \\(n\\) è grande, una Gamma di parametri \\(n\\) e \\(\\lambda\\) converge approssimativamente a una normale con media \\(n/\\lambda\\) e varianza \\(n/\\lambda^2\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#parametrizzazione",
    "href": "chapters/probability/12_cont_rv_distr.html#parametrizzazione",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "36.11 Parametrizzazione",
    "text": "36.11 Parametrizzazione\nLa distribuzione Gamma è caratterizzata da due parametri principali: \\(\\alpha\\) e \\(\\beta\\), noti rispettivamente come parametro di forma e parametro di tasso (o, alternativamente, si può usare \\(\\theta = \\frac{1}{\\beta}\\), il parametro di scala).\n\n36.11.1 Parametro di forma (\\(\\alpha\\))\nIl parametro di forma, \\(\\alpha\\), determina la forma generale della curva della distribuzione:\n\nSe \\(\\alpha = 1\\), la distribuzione Gamma si riduce a una distribuzione esponenziale, con la funzione di densità \\(f(x) = \\beta e^{-\\beta x}\\).\nSe \\(\\alpha &gt; 1\\), la distribuzione presenta un picco (modalità) attorno a \\((\\alpha - 1) \\cdot \\theta\\), indicando una distribuzione più concentrata attorno a un valore medio.\nSe \\(\\alpha &lt; 1\\), la distribuzione è inclinata verso destra, con una coda lunga che si estende verso valori più bassi, mostrando una maggiore probabilità di valori piccoli di \\(x\\).\n\nIl parametro \\(\\alpha\\) può essere interpretato come il numero di “eventi” che ci si aspetta si verifichino prima di raggiungere un certo tempo di attesa, in contesti di modelli di Poisson generalizzati. Ad esempio, se la distribuzione Gamma modella il tempo di attesa per l’arrivo di un certo numero di eventi, \\(\\alpha\\) indica il numero di eventi attesi.\nMan mano che \\(\\alpha\\) aumenta, la distribuzione si sposta verso destra e diventa più simmetrica. Per valori alti di \\(\\alpha\\), la distribuzione Gamma si avvicina a una distribuzione normale.\n\n\n36.11.2 Parametro di scala (\\(\\theta\\)) o tasso (\\(\\beta\\))\nIl parametro \\(\\theta\\) (o, alternativamente, \\(\\beta\\)) controlla la scala temporale o la larghezza della distribuzione:\n\nIl parametro di scala \\(\\theta\\) è inversamente proporzionale al parametro di tasso \\(\\beta\\). Un valore più grande di \\(\\theta\\) (o un valore più piccolo di \\(\\beta\\)) produce una curva più piatta, indicando una maggiore variabilità (dispersione) nel tempo di attesa.\nUn valore più piccolo di \\(\\theta\\) (o più grande di \\(\\beta\\)) rende la curva più appuntita, indicando una minore variabilità.\n\nNel contesto del tempo di attesa, \\(\\theta\\) agisce come un fattore di scala: un valore grande di \\(\\theta\\) indica un periodo di tempo più lungo tra gli eventi, mentre un valore piccolo di \\(\\theta\\) indica un periodo di tempo più breve.\n\n\n36.11.3 Formula della funzione di densità di probabilità\nLa funzione di densità di probabilità (PDF) della distribuzione Gamma è data da:\n\\[\nf(x \\mid \\alpha, \\theta) = \\frac{x^{\\alpha-1} e^{-\\frac{x}{\\theta}}}{\\theta^\\alpha \\Gamma(\\alpha)},\n\\]\ndove:\n\n\\(x\\) è la variabile casuale continua, con \\(x &gt; 0\\),\n\\(\\alpha\\) è il parametro di forma,\n\\(\\theta\\) è il parametro di scala (alternativamente si può usare \\(\\beta = \\frac{1}{\\theta}\\), il parametro di tasso),\n\\(\\Gamma(\\alpha)\\) è la funzione Gamma di Eulero, che generalizza il fattoriale per numeri reali e complessi. Per numeri interi \\(n\\), si ha \\(\\Gamma(n) = (n-1)!\\), ma per argomenti generali \\(\\alpha\\), la funzione Gamma è definita come:\n\n\\[\n\\Gamma(\\alpha) = \\int_0^\\infty x^{\\alpha-1} e^{-x} dx.\n\\]\n\n\n36.11.4 Media e varianza della distribuzione Gamma\nLe espressioni per la media e la varianza della distribuzione Gamma in funzione di \\(\\alpha\\) e \\(\\theta\\) (o \\(\\beta\\)) sono:\n\nMedia (\\(\\mu\\)):\n\n\\[\n\\mu = \\alpha \\cdot \\theta = \\frac{\\alpha}{\\beta}.\n\\]\n\nVarianza (\\(\\sigma^2\\)): \\[\n\\sigma^2 = \\alpha \\cdot \\theta^2 = \\frac{\\alpha}{\\beta^2}.\n\\]\n\nIn sintesi, il parametro di forma \\(\\alpha\\) controlla la forma generale della distribuzione, mentre il parametro di scala \\(\\theta\\) (o tasso \\(\\beta\\)) regola la dispersione o variabilità. Questa parametrizzazione è largamente utilizzata, in particolare nella statistica bayesiana, dove la distribuzione Gamma può servire da distribuzione a priori per parametri positivi, come varianze o tassi di processi stocastici.\nPer esempio, qui è riportata la distribuzione Gamma di parametri \\(\\alpha\\) = 3 e \\(\\beta\\) = 5/3.\n\n\n36.11.5 Calcolo della Media e della Deviazione Standard per la Distribuzione Gamma\nLa distribuzione Gamma è definita dai parametri \\(\\alpha\\) (shape) e \\(\\beta\\) (rate). La media e la deviazione standard della distribuzione possono essere calcolate come segue:\n\nMedia: \\(\\mu = \\frac{\\alpha}{\\beta}\\)\nDeviazione Standard: \\(\\sigma = \\sqrt{\\frac{\\alpha}{\\beta^2}}\\)\n\n\n36.11.5.1 Calcolo in R\n\n# Parametri della distribuzione Gamma\nalpha &lt;- 3\nbeta &lt;- 5 / 3\n\n# Calcolo della media\nmean &lt;- alpha / beta\ncat(\"Mean:\", mean, \"\\n\")\n#&gt; Mean: 1.8\n\n# Calcolo della deviazione standard\nsigma &lt;- sqrt(alpha / beta^2)\ncat(\"Standard Deviation:\", sigma, \"\\n\")\n#&gt; Standard Deviation: 1.03923\n\n\n\n\n36.11.6 Generazione di Dati dalla Distribuzione Gamma e Visualizzazione\n\n36.11.6.1 Generazione di dati\nIn R, possiamo utilizzare la funzione rgamma() per generare dati da una distribuzione Gamma specificando i parametri shape (\\(\\alpha\\)) e rate (\\(\\beta\\)).\n\n\n36.11.6.2 Plot della Distribuzione\n\n# Generazione di dati\nset.seed(123)  # Per riproducibilità\ndata &lt;- rgamma(100000, shape = alpha, rate = beta)\n\n# Creazione di un data frame per ggplot\ndf &lt;- data.frame(values = data)\n\n# Istogramma dei dati generati\nggplot(df, aes(x = values)) +\n  geom_histogram(aes(y = ..density..), bins = 30, fill = \"green\", alpha = 0.6) +\n  stat_function(fun = function(x) dgamma(x, shape = alpha, rate = beta),\n                color = \"red\", size = 1, linetype = \"solid\") +\n  labs(\n    x = \"Valore\",\n    y = \"Densità di probabilità\",\n    title = \"Distribuzione Gamma con α=3 e β=5/3\"\n  ) \n#&gt; Warning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `after_stat(density)` instead.\n\n\n\n\n\n\n\n\nSpiegazione del Codice.\n\nCalcolo della media e della deviazione standard:\n\nLa media è calcolata come il rapporto tra i parametri \\(\\alpha\\) e \\(\\beta\\).\nLa deviazione standard è la radice quadrata del rapporto tra \\(\\alpha\\) e \\(\\beta^2\\).\n\nGenerazione dei dati:\n\nrgamma(n, shape, rate) genera \\(n\\) osservazioni dalla distribuzione Gamma specificata.\n\nVisualizzazione:\n\nL’istogramma rappresenta i dati generati.\nLa funzione dgamma(x, shape, rate) calcola la densità teorica, che viene tracciata sopra l’istogramma per confrontare i dati simulati con la distribuzione teorica.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-esponenziale-1",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-esponenziale-1",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "36.12 Distribuzione Esponenziale",
    "text": "36.12 Distribuzione Esponenziale\nLa distribuzione esponenziale è una distribuzione di probabilità continua che descrive la “durata di vita” di un fenomeno che non invecchia (ossia la distribuzione esponenziale è priva di memoria).\nLa distribuzione esponenziale (o di Laplace) può anche essere ricavata come la distribuzione di probabilità di una variabile aleatoria definita come somma dei quadrati di due variabili aleatorie normali standardizzate (ossia con valore atteso zero e varianza unitaria); dunque è riconducibile a un caso particolare di distribuzione del chi-quadro, essendo, quest’ultima, la distribuzione di probabilità della variabile aleatoria costruita come la somma dei quadrati di \\(n\\) variabili aleatorie indipendenti normali e standardizzate.\nLa distribuzione esponenziale con parametro \\({\\displaystyle \\lambda &gt;0}\\), ha funzione di densità di probabilità:\n\\[\n{\\displaystyle f(x;\\lambda )={\\begin{cases}\\lambda e^{-\\lambda x}&x&gt;0,\\\\0&x\\leq 0.\\end{cases}}}.\n\\]\nUna variabile aleatoria con distribuzione esponenziale di parametro \\({\\displaystyle \\lambda }\\) ha\n\nvalore atteso \\({\\displaystyle E[X]=1/\\lambda }\\),\nvarianza \\({\\displaystyle {\\text{Var}}(X)=1/\\lambda ^{2}}.\\)\n\nPer fare un esempio, consideriamo il punteggio totale della scala psicologica di Kessler (K6), una misura standardizzata utilizzata dal NHIS per lo screening del disagio psicologico. La K6 include sei item relativi alla sintomatologia depressiva e ansiosa e valuta il disagio psicologico aspecifico degli ultimi 30 giorni. Gli item sono valutati su una scala Likert a 5 punti, che va da “mai” (=0) a “sempre” (=4). I punteggi totali variano da 0 a 24. Secondo Tomitaka et al. (2019), il punteggio totale della K6 segue una distribuzione esponenziale, con punteggi di cut-off per disagio psicologico moderato e grave corrispondenti a punteggi di 5 e 13, rispettivamente. Dallo studio emerge che il punteggio medio del totale della K6 nella popolazione americana è di 2.5. La corrispondente distribuzione esponenziale è rappresentata di seguito.\n\n# Parametri della distribuzione Esponenziale\nmean &lt;- 2.5\nlambda &lt;- 1 / mean  # Lambda è l'inverso della media\n\n# Creazione del vettore x\nx &lt;- seq(0.001, 22, length.out = 100)\n\n# Calcolo della densità\npdf &lt;- dexp(x, rate = lambda)\n\n# Creazione del data frame per ggplot\ndf &lt;- data.frame(x = x, pdf = pdf)\n\n# Tracciamento del grafico\nlibrary(ggplot2)\nggplot(df, aes(x = x, y = pdf)) +\n  geom_line(color = \"blue\", size = 1) +\n  labs(\n    x = \"x\",\n    y = \"f(x)\",\n    title = \"Distribuzione Esponenziale\"\n  ) +\n  annotate(\"text\", x = 10, y = max(pdf)/2, label = paste0(\"λ = \", round(lambda, 2)), size = 5, color = \"blue\")",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#riflessioni-conclusive-in-r",
    "href": "chapters/probability/12_cont_rv_distr.html#riflessioni-conclusive-in-r",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "36.13 Riflessioni Conclusive in R",
    "text": "36.13 Riflessioni Conclusive in R\nLa statistica bayesiana utilizza le distribuzioni di probabilità per la stima dei parametri e dell’incertezza. Possiamo considerare le distribuzioni di probabilità come “mattoncini” con cui costruire modelli statistici, dai più semplici ai più complessi. R offre strumenti per generare campioni casuali e calcolare densità, probabilità cumulate, e quantili per molte distribuzioni di probabilità.\n\n36.13.1 Generazione di Campioni\nIn R, possiamo generare campioni da diverse distribuzioni utilizzando le funzioni rnorm, runif, rt, rbeta, e rgamma. Ad esempio:\nDistribuzione Normale:\nset.seed(42)  # Per garantire la riproducibilità\nmedia &lt;- 0\ndeviazione_standard &lt;- 1\ncampione_normale &lt;- rnorm(100, mean = media, sd = deviazione_standard)\nDistribuzione Uniforme:\na &lt;- 0\nb &lt;- 10\ncampione_uniforme &lt;- runif(100, min = a, max = b)\nDistribuzione t di Student:\ngradi_libertà &lt;- 10\ncampione_t &lt;- rt(100, df = gradi_libertà)\nDistribuzione Beta:\nalpha &lt;- 2\nbeta_param &lt;- 5\ncampione_beta &lt;- rbeta(100, shape1 = alpha, shape2 = beta_param)\nDistribuzione Gamma:\nforma &lt;- 2\nscala &lt;- 1\ncampione_gamma &lt;- rgamma(100, shape = forma, rate = 1 / scala)\n\n\n36.13.1.1 Calcolo della Densità\nPossiamo calcolare la densità utilizzando le funzioni dnorm, dunif, dt, dbeta, e dgamma. Ad esempio:\nDistribuzione Normale:\nx &lt;- seq(media - 4 * deviazione_standard, media + 4 * deviazione_standard, length.out = 100)\npdf_normale &lt;- dnorm(x, mean = media, sd = deviazione_standard)\nDistribuzione Uniforme:\nx &lt;- seq(a, b, length.out = 100)\npdf_uniforme &lt;- dunif(x, min = a, max = b)\nDistribuzione t di Student:\nx &lt;- seq(-5, 5, length.out = 100)\npdf_t &lt;- dt(x, df = gradi_libertà)\nDistribuzione Beta:\nx &lt;- seq(0, 1, length.out = 100)\npdf_beta &lt;- dbeta(x, shape1 = alpha, shape2 = beta_param)\nDistribuzione Gamma:\nx &lt;- seq(0, 10, length.out = 100)\npdf_gamma &lt;- dgamma(x, shape = forma, rate = 1 / scala)\n\n\n\n36.13.1.2 Calcolo dei Quantili\nI quantili si calcolano con le funzioni qnorm, qunif, qt, qbeta, e qgamma. Ad esempio:\nDistribuzione Normale:\nprobabilità &lt;- 0.5\nquantile_normale &lt;- qnorm(probabilità, mean = media, sd = deviazione_standard)\nDistribuzione Uniforme:\nquantile_uniforme &lt;- qunif(probabilità, min = a, max = b)\nDistribuzione t di Student:\nquantile_t &lt;- qt(probabilità, df = gradi_libertà)\nDistribuzione Beta:\nquantile_beta &lt;- qbeta(probabilità, shape1 = alpha, shape2 = beta_param)\nDistribuzione Gamma:\nquantile_gamma &lt;- qgamma(probabilità, shape = forma, rate = 1 / scala)\n\n\n\n36.13.1.3 Calcolo delle Probabilità Cumulate\nLe probabilità cumulate si calcolano con le funzioni pnorm, punif, pt, pbeta, e pgamma. Ad esempio:\nDistribuzione Normale:\nquantile &lt;- 0\nprobabilità_normale &lt;- pnorm(quantile, mean = media, sd = deviazione_standard)\nDistribuzione Uniforme:\nprobabilità_uniforme &lt;- punif(quantile, min = a, max = b)\nDistribuzione t di Student:\nprobabilità_t &lt;- pt(quantile, df = gradi_libertà)\nDistribuzione Beta:\nprobabilità_beta &lt;- pbeta(quantile, shape1 = alpha, shape2 = beta_param)\nDistribuzione Gamma:\nprobabilità_gamma &lt;- pgamma(quantile, shape = forma, rate = 1 / scala)\n\nCon questi strumenti, R consente di generare, visualizzare e analizzare campioni da una vasta gamma di distribuzioni di probabilità, fornendo un potente supporto all’inferenza bayesiana e alla modellazione statistica.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#esercizi",
    "href": "chapters/probability/12_cont_rv_distr.html#esercizi",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "36.14 Esercizi",
    "text": "36.14 Esercizi\n\nEsercizio 36.1 Per ciascuna delle distribuzioni di massa di probabilità discusse, utilizza R per:\n\ncreare un grafico della funzione, scegliendo opportunamente i parametri;\nestrarre un campione di 1000 valori casuali dalla distribuzione e visualizzarlo con un istogramma;\ncalcolare la media e la deviazione standard dei campioni e confrontarle con i valori teorici attesi;\nstimare l’intervallo centrale del 94% utilizzando i campioni simulati;\ndeterminare i quantili della distribuzione per gli ordini 0.05, 0.25, 0.75 e 0.95;\nscegliendo un valore della distribuzione pari alla media più una deviazione standard, calcolare la probabilità che la variabile aleatoria assuma un valore minore o uguale a questo valore.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/12_cont_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.16.0       MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2\n#&gt;  [5] ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0  \n#&gt;  [9] bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0      markdown_1.13    \n#&gt; [13] knitr_1.49        lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1    \n#&gt; [17] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#&gt; [21] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [25] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1  farver_2.1.2      fastmap_1.2.0     pacman_0.5.1     \n#&gt;  [5] promises_1.3.1    rpart_4.1.23      digest_0.6.37     timechange_0.3.0 \n#&gt;  [9] mime_0.12         lifecycle_1.0.4   survival_3.7-0    magrittr_2.0.3   \n#&gt; [13] compiler_4.4.2    rlang_1.1.4       tools_4.4.2       utf8_1.2.4       \n#&gt; [17] yaml_2.3.10       ggsignif_0.6.4    labeling_0.4.3    htmlwidgets_1.6.4\n#&gt; [21] mnormt_2.1.1      abind_1.4-8       miniUI_0.1.1.1    withr_3.0.2      \n#&gt; [25] nnet_7.3-19       grid_4.4.2        fansi_1.0.6       jomo_2.7-6       \n#&gt; [29] xtable_1.8-4      colorspace_2.1-1  iterators_1.0.14  cli_3.6.3        \n#&gt; [33] rmarkdown_2.29    generics_0.1.3    tzdb_0.4.0        minqa_1.2.8      \n#&gt; [37] splines_4.4.2     parallel_4.4.2    vctrs_0.6.5       boot_1.3-31      \n#&gt; [41] glmnet_4.1-8      Matrix_1.7-1      jsonlite_1.8.9    carData_3.0-5    \n#&gt; [45] car_3.1-3         hms_1.1.3         mitml_0.4-5       rstatix_0.7.2    \n#&gt; [49] Formula_1.2-5     foreach_1.5.2     glue_1.8.0        pan_1.9          \n#&gt; [53] nloptr_2.1.1      codetools_0.2-20  stringi_1.8.4     gtable_0.3.6     \n#&gt; [57] shape_1.4.6.1     later_1.4.0       lme4_1.1-35.5     munsell_0.5.1    \n#&gt; [61] pillar_1.9.0      htmltools_0.5.8.1 R6_2.5.1          rprojroot_2.0.4  \n#&gt; [65] evaluate_1.0.1    shiny_1.9.1       lattice_0.22-6    backports_1.5.0  \n#&gt; [69] broom_1.0.7       httpuv_1.6.15     Rcpp_1.0.13-1     nlme_3.1-166     \n#&gt; [73] xfun_0.49         pkgconfig_2.0.3",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#bibliografia",
    "href": "chapters/probability/12_cont_rv_distr.html#bibliografia",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nTomitaka, S., Kawasaki, Y., Ide, K., Akutagawa, M., Ono, Y., & Furukawa, T. A. (2019). Distribution of psychological distress is stable in recent decades and follows an exponential pattern in the US population. Scientific reports, 9(1), 11982.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_likelihood.html",
    "href": "chapters/probability/13_likelihood.html",
    "title": "37  La verosimiglianza",
    "section": "",
    "text": "37.1 Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nPreparazione del Notebook\nI ricercatori utilizzano modelli con diverse strutture funzionali per descrivere e prevedere il comportamento dei dati. La scelta del modello più adatto si basa sul confronto tra le previsioni teoriche e i dati osservati: il modello che produce previsioni più vicine ai dati osservati viene considerato il migliore per rappresentare il fenomeno studiato. In questo processo, la funzione di verosimiglianza svolge un ruolo centrale, quantificando la probabilità che i dati osservati siano compatibili con un modello specifico e i suoi parametri.\nLa funzione di verosimiglianza rappresenta il meccanismo generativo dei dati, collegando i parametri del modello alle osservazioni empiriche. Tuttavia, essa non costituisce da sola un modello scientifico completo. Un modello scientifico include infatti altri elementi, come i priori (in un approccio bayesiano), che rappresentano le ipotesi iniziali sui parametri prima dell’osservazione dei dati, e la modellazione dell’errore di misurazione, che tiene conto delle imperfezioni nei dati raccolti.\nIn un approccio bayesiano, i priori si combinano con la verosimiglianza per generare la distribuzione a posteriori, che aggiorna le conoscenze sui parametri alla luce dei dati osservati. Questo passaggio è cruciale per il confronto tra modelli, poiché i priori possono influenzare significativamente le conclusioni.\nUn modello scientifico può anche includere la modellazione dell’errore di misurazione per spiegare le discrepanze tra i dati osservati e il processo reale. Questo aspetto è fondamentale per garantire che il modello sia in grado di catturare sia le osservazioni che le loro imprecisioni.\nIn sintesi, la funzione di verosimiglianza descrive come i dati potrebbero essere generati da un modello dato un insieme di parametri, ma un modello scientifico completo include ulteriori componenti, come i priori e la modellazione dell’errore, per rendere la rappresentazione del fenomeno più accurata. Questo capitolo si propone di approfondire il concetto di verosimiglianza e il suo ruolo nell’inferenza statistica.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_likelihood.html#il-principio-della-verosimiglianza-e-la-sua-formalizzazione",
    "href": "chapters/probability/13_likelihood.html#il-principio-della-verosimiglianza-e-la-sua-formalizzazione",
    "title": "37  La verosimiglianza",
    "section": "37.2 Il Principio della Verosimiglianza e la sua Formalizzazione",
    "text": "37.2 Il Principio della Verosimiglianza e la sua Formalizzazione\nLa funzione di verosimiglianza è strettamente collegata alla funzione di densità (o massa) di probabilità, ma i due concetti hanno interpretazioni distinte:\n\nLa funzione di densità di probabilità descrive la probabilità di osservare un determinato insieme di dati, assumendo che i parametri siano noti e fissi.\nLa funzione di verosimiglianza considera i dati osservati come fissi e varia i parametri, valutando quanto ciascun valore dei parametri spieghi i dati.\n\nLa relazione tra queste due funzioni può essere formalizzata come segue:\n\\[\nL(\\theta \\mid y) \\propto p(y \\mid \\theta),\n\\]\ndove \\(L(\\theta \\mid y)\\) è la verosimiglianza dei parametri \\(\\theta\\) dati i dati \\(y\\), e \\(p(y \\mid \\theta)\\) rappresenta la probabilità di osservare i dati \\(y\\) dato un certo \\(\\theta\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_likelihood.html#verosimiglianza-binomiale",
    "href": "chapters/probability/13_likelihood.html#verosimiglianza-binomiale",
    "title": "37  La verosimiglianza",
    "section": "37.3 Verosimiglianza Binomiale",
    "text": "37.3 Verosimiglianza Binomiale\nConsideriamo un esempio pratico: il lancio di una moneta. Supponiamo di osservare 23 teste su 30 lanci. La probabilità di osservare esattamente questo risultato, data una probabilità di successo \\(\\theta\\), può essere calcolata utilizzando la funzione di massa della distribuzione binomiale:\n\\[\nP(Y = y) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n - y},\n\\]\ndove:\n\n\\(n\\) è il numero totale di lanci,\n\\(y\\) è il numero di successi osservati,\n\\(\\theta\\) è la probabilità di successo per ogni lancio.\n\nLa funzione di verosimiglianza, invece, si concentra sull’identificazione dei valori di \\(\\theta\\) che meglio spiegano i dati osservati. Per la distribuzione binomiale, la funzione di verosimiglianza si scrive come:\n\\[\n\\mathcal{L}(\\theta \\mid y) = \\theta^y (1 - \\theta)^{n - y}.\n\\]\nQui, il coefficiente binomiale \\(\\binom{n}{y}\\) può essere omesso perché non dipende da \\(\\theta\\) e quindi non influisce sulla stima del parametro.\n\n37.3.1 Verosimiglianza per il Lancio di una Moneta\nSupponiamo che:\n\n\\(n = 30\\) (numero di lanci),\n\\(y = 23\\) (numero di teste osservate).\n\nLa funzione di verosimiglianza diventa:\n\\[\n\\mathcal{L}(\\theta \\mid y) = \\theta^{23} (1 - \\theta)^7.\n\\]\nQuesto ci permette di calcolare la verosimiglianza per diversi valori di \\(\\theta\\), determinando quale valore rende i dati osservati più plausibili. Ad esempio, possiamo simulare 100 valori equidistanti di \\(\\theta\\) nell’intervallo ([0, 1]) e calcolare la funzione di verosimiglianza per ciascun valore.\nIn R, possiamo calcolare la funzione di verosimiglianza per \\(n = 30\\), \\(y = 23\\), e una griglia di valori di \\(\\theta\\) come segue:\n\n# Parametri\nn &lt;- 30\ny &lt;- 23\n\n# Definizione dei valori di theta\ntheta &lt;- seq(0, 1, length.out = 100)\n\n# Calcolo della verosimiglianza\nlikelihood &lt;- theta^y * (1 - theta)^(n - y)\n\n# Visualizzazione della funzione di verosimiglianza\nggplot(\n  data.frame(theta, likelihood), \n  aes(x = theta, y = likelihood)) +\n  geom_line(color = \"blue\") +\n  labs(\n    title = \"Funzione di Verosimiglianza\",\n    x = \"Valore di θ\",\n    y = \"Verosimiglianza\"\n  ) \n\n\n\n\n\n\n\n\n\n\n37.3.2 Interpretazione della Verosimiglianza\n\nValore di \\(\\theta\\): La funzione di verosimiglianza indica quali valori di \\(\\theta\\) sono più plausibili dati i dati osservati.\nStima di Massima Verosimiglianza (MLE): Il valore di \\(\\theta\\) che massimizza la funzione di verosimiglianza è detto stima di massima verosimiglianza. Nel nostro esempio, possiamo individuare questo valore esplorando numericamente i punti di massimo della curva.\n\nIn pratica, per identificare numericamente il valore ottimale di \\(\\theta\\), si può utilizzare un approccio computazionale che identifica il massimo della verosimiglianza.\n\n# Calcolo delle probabilità binomiali\nl &lt;- dbinom(y, size = n, prob = theta)\n\n# Individuazione dell'indice massimo\nmax_index &lt;- which.max(l)\n\n# Recupero del valore corrispondente di theta\ntheta[max_index]\n#&gt; [1] 0.768\n\nSpiegazione:\n\ndbinom(y, size = n, prob = theta) calcola la probabilità binomiale per ogni valore di theta.\nwhich.max(l) restituisce l’indice del valore massimo nella distribuzione di probabilità calcolata.\ntheta[max_index] seleziona il valore di theta corrispondente all’indice massimo.\n\nQuesto approccio illustra come la funzione di verosimiglianza aiuti a stimare parametri incogniti e a valutare la plausibilità relativa di diversi modelli statistici, basandosi esclusivamente sui dati osservati.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_likelihood.html#la-funzione-di-log-verosimiglianza",
    "href": "chapters/probability/13_likelihood.html#la-funzione-di-log-verosimiglianza",
    "title": "37  La verosimiglianza",
    "section": "37.4 La Funzione di Log-Verosimiglianza",
    "text": "37.4 La Funzione di Log-Verosimiglianza\nLa log-verosimiglianza è il logaritmo naturale della funzione di verosimiglianza:\n\\[\n\\ell(\\theta) = \\log \\mathcal{L}(\\theta \\mid y).\n\\]\nQuesta trasformazione è utile per semplificare i calcoli e migliorare la stabilità numerica, specialmente con dataset di grandi dimensioni.\nEsempio grafico per i valori di log-verosimiglianza:\n\n# Parametri\nn &lt;- 30\nr &lt;- 23\n\n# Genera la sequenza per theta\ntheta &lt;- seq(0, 1, length.out = 100)\n\n# Calcolo della log-verosimiglianza\nlog_likelihood &lt;- dbinom(r, size = n, prob = theta, log = TRUE)\n\n# Creazione del grafico\nplot(\n  theta, log_likelihood, type = \"l\",\n  main = \"Funzione di log-verosimiglianza\",\n  xlab = \"Valore della variabile casuale theta [0, 1]\",\n  ylab = \"Log-verosimiglianza\"\n)\n\n\n\n\n\n\n\n\nIl massimo della log-verosimiglianza replica il risultato trovato in precedenza con la funzione di verosimiglianza.\n\n# Calcolo della log-verosimiglianza per ogni valore di theta\nlog_likelihood &lt;- dbinom(r, size = n, prob = theta, log = TRUE)\n\n# Trova l'indice del valore massimo\nmax_index &lt;- which.max(log_likelihood)\n\n# Valore di theta corrispondente al massimo\ntheta[max_index]\n#&gt; [1] 0.768",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_likelihood.html#verosimiglianza-congiunta",
    "href": "chapters/probability/13_likelihood.html#verosimiglianza-congiunta",
    "title": "37  La verosimiglianza",
    "section": "37.5 Verosimiglianza Congiunta",
    "text": "37.5 Verosimiglianza Congiunta\nNell’inferenza statistica basata sulla verosimiglianza, è comune incontrare situazioni in cui si dispone di più osservazioni indipendenti, tutte generate dallo stesso processo probabilistico. Ad esempio, raccogliamo un insieme di dati $ Y = [y_1, y_2, , y_n] $, dove ciascun valore è osservato indipendentemente e segue la stessa distribuzione binomiale. Questo scenario, noto come condizione di indipendenza e identica distribuzione (IID), è frequente nelle applicazioni pratiche.\n\n37.5.1 Calcolo della Verosimiglianza Congiunta\nPer considerare congiuntamente tutte le osservazioni, calcoliamo la probabilità congiunta di osservare $ y_1, y_2, , y_n $, data una comune probabilità di successo \\(\\theta\\). Grazie all’indipendenza delle osservazioni, questa probabilità si esprime come il prodotto delle probabilità individuali:\n\\[\np(y_1, y_2, \\ldots, y_n \\mid \\theta) = \\prod_{i=1}^{n} p(y_i \\mid \\theta) = \\prod_{i=1}^{n} \\text{Binomiale}(y_i \\mid \\theta).\n\\]\nLa verosimiglianza congiunta è quindi:\n\\[\n\\mathcal{L}(\\theta \\mid Y) = \\prod_{i=1}^{n} \\mathcal{L}(\\theta \\mid y_i) = \\prod_{i=1}^{n} p(y_i \\mid \\theta).\n\\]\nQuesta funzione misura la plausibilità complessiva del parametro \\(\\theta\\) rispetto all’intero insieme di dati \\(Y\\). Il valore di \\(\\theta\\) che massimizza la verosimiglianza congiunta è noto come stimatore di massima verosimiglianza (MLE) e rappresenta il parametro che rende i dati osservati più plausibili.\n\n\n37.5.2 Log-Verosimiglianza Congiunta\nPoiché il prodotto delle probabilità può diventare numericamente instabile, lavoriamo spesso con la log-verosimiglianza, che trasforma il prodotto in una somma:\n\\[\n\\log \\mathcal{L}(\\theta \\mid Y) = \\sum_{i=1}^{n} \\log p(y_i \\mid \\theta).\n\\]\nIn un esempio pratico con dati raggruppati, consideriamo quattro gruppi di osservazioni binomiali indipendenti:\n\nGruppo 1: 30 prove con 23 successi\nGruppo 2: 28 prove con 20 successi\nGruppo 3: 40 prove con 29 successi\nGruppo 4: 36 prove con 29 successi\n\nLa log-verosimiglianza congiunta è:\n\\[\n\\log \\mathcal{L}(\\theta) = \\sum_{i=1}^{4} \\left[ y_i \\log(\\theta) + (n_i - y_i) \\log(1 - \\theta) \\right],\n\\]\ndove $ n_i $ e $ y_i $ rappresentano rispettivamente il numero di prove e di successi nel gruppo \\(i\\)-esimo.\n\n\n37.5.3 Implementazione in R\nPer calcolare la log-verosimiglianza congiunta, definiamo una funzione che accetta \\(\\theta\\) e i dati dei gruppi:\n\nlog_verosimiglianza_congiunta &lt;- function(theta, dati) {\n  # Evita valori problematici per log(0)\n  theta &lt;- pmax(pmin(theta, 1 - 1e-10), 1e-10)\n  \n  # Calcolo della log-verosimiglianza\n  log_likelihood &lt;- 0\n  for (gruppo in dati) {\n    n &lt;- gruppo[1]\n    y &lt;- gruppo[2]\n    log_likelihood &lt;- log_likelihood + y * log(theta) + (n - y) * log(1 - theta)\n  }\n  \n  return(-log_likelihood) # Negativo per ottimizzazione\n}\n\nI dati dei gruppi sono rappresentati come segue:\n\ndati_gruppi &lt;- list(c(30, 23), c(28, 20), c(40, 29), c(36, 29))\n\n\n\n37.5.4 Ottimizzazione per trovare \\(\\theta\\)\nUtilizziamo l’algoritmo di ottimizzazione optim per stimare il valore di \\(\\theta\\) che massimizza la log-verosimiglianza:\n\nresult &lt;- optim(\n  par = 0.5,                        # Valore iniziale\n  fn = log_verosimiglianza_congiunta, \n  dati = dati_gruppi,               # Dati\n  method = \"L-BFGS-B\",              # Metodo con vincoli\n  lower = 0,                        # Limite inferiore\n  upper = 1                         # Limite superiore\n)\n\n# Valore ottimale di theta\nresult$par\n#&gt; [1] 0.754\n\n\n\n37.5.5 Visualizzazione della log-verosimiglianza\nCalcoliamo e tracciamo la log-verosimiglianza negativa per un intervallo di valori di \\(\\theta\\):\n\ntheta_values &lt;- seq(0.01, 0.99, length.out = 100)\n\nlog_likelihood_values &lt;- sapply(theta_values, function(theta) {\n  log_verosimiglianza_congiunta(theta, dati_gruppi)\n})\n\nggplot(\n  data.frame(theta = theta_values, log_likelihood = log_likelihood_values), \n  aes(x = theta, y = log_likelihood)) +\n  geom_line(color = \"blue\") +\n  labs(\n    title = \"Funzione di Log-verosimiglianza Congiunta\",\n    x = \"Theta\",\n    y = \"Log-verosimiglianza Negativa\"\n  ) \n\n\n\n\n\n\n\n\nIn conclusione, l’analisi della verosimiglianza congiunta consente di stimare con precisione il parametro \\(\\theta\\) considerando tutte le osservazioni contemporaneamente. La log-verosimiglianza, grazie alla sua stabilità numerica e alla semplicità di calcolo, è uno strumento potente per l’inferenza statistica. Utilizzando tecniche di ottimizzazione, possiamo identificare il valore di \\(\\theta\\) che meglio spiega i dati osservati, ottenendo stime affidabili anche in contesti complessi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_likelihood.html#la-verosimiglianza-marginale",
    "href": "chapters/probability/13_likelihood.html#la-verosimiglianza-marginale",
    "title": "37  La verosimiglianza",
    "section": "37.6 La Verosimiglianza Marginale",
    "text": "37.6 La Verosimiglianza Marginale\nLa verosimiglianza marginale è un concetto fondamentale nell’inferenza bayesiana. Essa permette di calcolare la probabilità complessiva di osservare un determinato risultato, tenendo conto di tutte le possibili incertezze sui parametri del modello. Questo è particolarmente rilevante quando il parametro di interesse, \\(\\theta\\), non è considerato un valore fisso, ma è descritto da una distribuzione di probabilità.\nIn pratica, la verosimiglianza marginale valuta la compatibilità dei dati con il modello, integrando su tutti i possibili valori di \\(\\theta\\), ciascuno pesato dalla sua probabilità a priori.\n\n37.6.1 Caso con Parametri Discreti\nConsideriamo un esempio semplice in cui \\(\\theta\\) può assumere un insieme discreto di valori. Ad esempio, in una sequenza di prove binomiali con \\(k = 7\\) successi su \\(n = 10\\) prove, e con \\(\\theta \\in \\{0.1, 0.5, 0.9\\}\\), la verosimiglianza marginale è calcolata come:\n\\[\np(k = 7 \\mid n = 10) = \\sum_{\\theta \\in \\{0.1, 0.5, 0.9\\}} \\binom{10}{7} \\theta^7 (1 - \\theta)^3 p(\\theta),\n\\]\ndove \\(p(\\theta)\\) rappresenta la probabilità a priori associata a ciascun valore discreto di \\(\\theta\\). In questo caso, la verosimiglianza marginale è la somma delle probabilità di osservare i dati, pesata dalla probabilità a priori di ciascun valore di \\(\\theta\\).\n\n\n37.6.2 Caso con Parametri Continui\nNella maggior parte delle applicazioni, \\(\\theta\\) varia continuamente all’interno di un intervallo, ad esempio \\([0, 1]\\) per un parametro binomiale. In tal caso, la verosimiglianza marginale è calcolata mediante un’integrazione:\n\\[\np(k = 7 \\mid n = 10) = \\int_{0}^{1} \\binom{10}{7} \\theta^7 (1 - \\theta)^3 p(\\theta) \\, d\\theta,\n\\]\ndove \\(p(\\theta)\\) è la densità a priori di \\(\\theta\\). Questa formula combina le probabilità condizionali dei dati dati \\(\\theta\\) con le probabilità a priori, integrando su tutti i possibili valori di \\(\\theta\\).\n\n\n37.6.3 Calcolo Numerico della Verosimiglianza Marginale\nPer calcolare la verosimiglianza marginale con \\(\\theta\\) continuo, possiamo utilizzare l’integrazione numerica. In R, il pacchetto stats offre strumenti utili come la funzione integrate. Ecco un esempio concreto:\n\n# Definizione della funzione di verosimiglianza\nlikelihood &lt;- function(theta) {\n  dbinom(x = 7, size = 10, prob = theta)\n}\n\n# Calcolo della verosimiglianza marginale con integrazione numerica\nmarginal_likelihood &lt;- integrate(likelihood, lower = 0, upper = 1)$value\n\n# Stampa del risultato\ncat(\"La verosimiglianza marginale è:\", marginal_likelihood, \"\\n\")\n#&gt; La verosimiglianza marginale è: 0.0909\n\n\n\n37.6.4 Interpretazione della Verosimiglianza Marginale\nLa verosimiglianza marginale rappresenta la capacità complessiva del modello di spiegare i dati, tenendo conto dell’incertezza sui parametri. Dal punto di vista geometrico, può essere interpretata come l’area sottesa alla funzione di verosimiglianza ponderata dalla distribuzione a priori di \\(\\theta\\).\nTuttavia, è importante chiarire che la verosimiglianza marginale non è una probabilità dei dati dato un valore specifico di \\(\\theta\\). Piuttosto, essa considera tutte le possibili incertezze sui parametri, fornendo una misura complessiva della compatibilità del modello con i dati.\n\n\n37.6.5 Ruolo nell’Inferenza Bayesiana\nLa verosimiglianza marginale assume un ruolo chiave nell’inferenza bayesiana come fattore di normalizzazione nella formula di Bayes:\n\\[\np(\\theta \\mid D) = \\frac{p(D \\mid \\theta) p(\\theta)}{p(D)},\n\\]\ndove \\(p(D)\\), ossia la verosimiglianza marginale, garantisce che la distribuzione posteriore \\(p(\\theta \\mid D)\\) sia una distribuzione di probabilità valida, con un’area totale pari a 1.\nIn conclusione, la verosimiglianza marginale è uno strumento fondamentale per valutare il modello nel suo complesso, integrando informazioni sui parametri e sulla loro incertezza. In particolare:\n\nPer parametri discreti, si calcola sommando le probabilità di ciascun valore di \\(\\theta\\), ponderate dalla loro probabilità a priori.\nPer parametri continui, si utilizza l’integrazione per ottenere una misura globale della compatibilità del modello con i dati.\n\nQuesta misura non solo consente di confrontare modelli diversi, ma garantisce anche la validità della distribuzione a posteriori nell’inferenza bayesiana. Grazie a strumenti computazionali, possiamo calcolare la verosimiglianza marginale anche in situazioni complesse, fornendo una base solida per analisi statistiche rigorose e flessibili.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_likelihood.html#modello-gaussiano-e-verosimiglianza",
    "href": "chapters/probability/13_likelihood.html#modello-gaussiano-e-verosimiglianza",
    "title": "37  La verosimiglianza",
    "section": "37.7 Modello Gaussiano e Verosimiglianza",
    "text": "37.7 Modello Gaussiano e Verosimiglianza\nIn questa sezione analizziamo il caso di una distribuzione gaussiana per calcolare la funzione di verosimiglianza. Inizieremo con una singola osservazione e successivamente estenderemo l’analisi a un insieme di osservazioni indipendenti e identicamente distribuite (IID).\n\n37.7.1 Caso di una Singola Osservazione\nConsideriamo una singola osservazione $ y $, ad esempio il Quoziente Intellettivo (QI) di un individuo, che supponiamo seguire una distribuzione normale. La funzione di verosimiglianza per $ y $ esprime la plausibilità di diversi valori del parametro \\(\\mu\\) (media), dato il valore osservato, assumendo che la deviazione standard \\(\\sigma\\) sia nota.\n\n37.7.1.1 Definizione della Verosimiglianza\nLa funzione di densità di probabilità gaussiana è definita come:\n\\[\nf(y \\mid \\mu, \\sigma) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(-\\frac{(y-\\mu)^2}{2\\sigma^2}\\right),\n\\]\ndove \\(y\\) è il valore osservato, \\(\\mu\\) è la media e \\(\\sigma\\) è la deviazione standard.\n\n\n37.7.1.2 Esempio con R\nSupponiamo di osservare un valore $ y = 114 $ e di assumere che \\(\\sigma = 15\\). Esploriamo i valori di \\(\\mu\\) in un intervallo compreso tra 70 e 160 per determinare quale valore massimizza la verosimiglianza.\n\n# Parametri iniziali\ny_obs &lt;- 114\nsigma &lt;- 15\nmu_values &lt;- seq(70, 160, length.out = 1000)\n\n# Calcolo della funzione di verosimiglianza\nlikelihood &lt;- dnorm(y_obs, mean = mu_values, sd = sigma)\n\n# Visualizzazione della funzione di verosimiglianza\nlibrary(ggplot2)\nggplot(data.frame(mu = mu_values, likelihood = likelihood), aes(x = mu, y = likelihood)) +\n  geom_line(color = \"blue\") +\n  labs(\n    title = \"Funzione di Verosimiglianza per QI = 114\",\n    x = \"Valore di μ (media)\",\n    y = \"Verosimiglianza\"\n  )\n\n\n\n\n\n\n\n\n\n\n37.7.1.3 Calcolo del Valore Ottimale\nPer determinare il valore di \\(\\mu\\) che massimizza la verosimiglianza, individuiamo il massimo della curva.\n\n# Identificazione del massimo\nmu_optimal &lt;- mu_values[which.max(likelihood)]\ncat(\"Il valore ottimale di μ è:\", mu_optimal, \"\\n\")\n#&gt; Il valore ottimale di μ è: 114\n\nIl valore di \\(\\mu\\) che massimizza la verosimiglianza è $ = 114 $, coincidente con il valore osservato.\n\n\n\n37.7.2 Log-Verosimiglianza\nIn alternativa, possiamo lavorare con la log-verosimiglianza, una trasformazione utile per semplificare i calcoli numerici e migliorare la stabilità computazionale:\n\\[\n\\log L(\\mu \\mid y, \\sigma) = -\\frac{1}{2} \\log(2\\pi) - \\log(\\sigma) - \\frac{(y - \\mu)^2}{2\\sigma^2}.\n\\]\nQuesta funzione è equivalente alla funzione di verosimiglianza per determinare il valore di \\(\\mu\\) che meglio si adatta ai dati.\n\n37.7.2.1 Calcolo della Log-Verosimiglianza con R\n\n# Funzione di log-verosimiglianza negativa\nnegative_log_likelihood &lt;- function(mu, y, sigma) {\n  0.5 * log(2 * pi) + log(sigma) + ((y - mu)^2) / (2 * sigma^2)\n}\n\n# Ottimizzazione per trovare il massimo della log-verosimiglianza\nresult &lt;- optim(\n  par = 100,  # Valore iniziale per μ\n  fn = negative_log_likelihood,\n  y = y_obs,\n  sigma = sigma,\n  method = \"L-BFGS-B\",\n  lower = 70,\n  upper = 160\n)\n\n# Risultato dell'ottimizzazione\nmu_max_loglik &lt;- result$par\ncat(\"Il valore ottimale di μ basato sulla log-verosimiglianza è:\", mu_max_loglik, \"\\n\")\n#&gt; Il valore ottimale di μ basato sulla log-verosimiglianza è: 114\n\nIl valore di \\(\\mu\\) che massimizza la log-verosimiglianza è $ = 114 $, confermando che, in presenza di una singola osservazione, il valore ottimale coincide con l’osservazione stessa.\nIn conclusione, l’analisi della funzione di verosimiglianza nel caso gaussiano mostra che:\n\nLa funzione di verosimiglianza rappresenta la plausibilità dei parametri del modello dato il valore osservato.\nLa log-verosimiglianza è una trasformazione utile per calcoli più stabili e semplificati.\nNel caso di una singola osservazione e deviazione standard nota, il valore di \\(\\mu\\) che massimizza la verosimiglianza coincide con il valore osservato \\(y\\).\n\n\n\n\n37.7.3 Campione Indipendente di Osservazioni da una Distribuzione Normale\nConsideriamo un campione composto da \\(n\\) osservazioni indipendenti e identicamente distribuite (IID), ognuna derivante da una distribuzione normale con media \\(\\mu\\) e deviazione standard \\(\\sigma\\). La distribuzione è rappresentata da:\n\\[\nX \\sim N(\\mu, \\sigma^2),\n\\]\ndove \\(y_i\\) indica ogni osservazione del campione.\nLa densità di probabilità congiunta per il campione è il prodotto delle densità delle singole osservazioni:\n\\[\np(y_1, y_2, \\ldots, y_n \\mid \\mu, \\sigma) = \\prod_{i=1}^n p(y_i \\mid \\mu, \\sigma).\n\\]\nDi conseguenza, la funzione di verosimiglianza è:\n\\[\n\\mathcal{L}(\\mu, \\sigma \\mid y) = \\prod_{i=1}^n \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp \\left( -\\frac{(y_i - \\mu)^2}{2\\sigma^2} \\right).\n\\]\nPer semplificare i calcoli, si considera il logaritmo della funzione di verosimiglianza:\n\\[\n\\log \\mathcal{L}(\\mu, \\sigma \\mid y) = -\\frac{n}{2} \\log(2\\pi) - n \\log(\\sigma) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^n (y_i - \\mu)^2.\n\\]\n\n37.7.3.1 Esempio Pratico\nSupponiamo di misurare i punteggi del BDI-II su un campione di 30 partecipanti. I dati sono i seguenti:\n\n# Dati osservati\ny &lt;- c(\n  26, 35, 30, 25, 44, 30, 33, 43, 22, 43, \n  24, 19, 39, 31, 25, 28, 35, 30, 26, 31, \n  41, 36, 26, 35, 33, 28, 27, 34, 27, 22\n)\n\nAssumiamo che la deviazione standard \\(\\sigma\\) sia nota e pari alla deviazione standard campionaria (\\(\\sigma = 6.50\\)).\nDefiniamo una funzione per calcolare la log-verosimiglianza dato un valore di \\(\\mu\\):\n\nlog_likelihood &lt;- function(mu, y, sigma) {\n  n &lt;- length(y)\n  term1 &lt;- -n * log(sigma) - n * log(sqrt(2 * pi))\n  term2 &lt;- -sum((y - mu)^2) / (2 * sigma^2)\n  return(term1 + term2)\n}\n\nDefiniamo un intervallo per \\(\\mu\\), centrato sulla media campionaria:\n\n# Parametri\nsigma &lt;- 6.50\nmu_range &lt;- seq(mean(y) - 2 * sigma, mean(y) + 2 * sigma, length.out = 1000)\n\n# Calcolo della log-verosimiglianza per ogni valore di mu\nlog_lik_values &lt;- sapply(mu_range, log_likelihood, y = y, sigma = sigma)\n\nTracciamo la funzione di log-verosimiglianza per i diversi valori di \\(\\mu\\):\n\nggplot(\n  data.frame(mu = mu_range, log_likelihood = log_lik_values), \n  aes(x = mu, y = log_likelihood)) +\n  geom_line(color = \"blue\") +\n  labs(\n    title = \"Funzione di Log-Verosimiglianza\",\n    x = \"Valore di μ\",\n    y = \"Log-Verosimiglianza\"\n  ) +\n  geom_vline(xintercept = mean(y), linetype = \"dashed\", color = \"red\", alpha = 0.7) \n\n\n\n\n\n\n\n\nUtilizziamo l’ottimizzazione numerica per trovare il valore di \\(\\mu\\) che massimizza la log-verosimiglianza:\n\n# Definizione della funzione negativa per l'ottimizzazione\nnegative_log_likelihood &lt;- function(mu, y, sigma) {\n  -log_likelihood(mu, y, sigma)\n}\n\n# Ottimizzazione\nresult &lt;- optim(\n  par = mean(y),  # Punto di partenza\n  fn = negative_log_likelihood,\n  y = y,\n  sigma = sigma,\n  method = \"L-BFGS-B\",\n  lower = min(mu_range),\n  upper = max(mu_range)\n)\n\n# Risultato\nmu_optimal &lt;- result$par\ncat(\"Il valore ottimale di μ è:\", mu_optimal, \"\\n\")\n#&gt; Il valore ottimale di μ è: 30.9\n\nInterpretazione dei risultati:\n\nStima di Massima Verosimiglianza (MLE): La media campionaria \\(\\bar{y}\\) rappresenta la stima di massima verosimiglianza (MLE) per \\(\\mu\\). Questo risultato è coerente con la proprietà della distribuzione normale.\nCurva della Log-Verosimiglianza: La curva mostra la “plausibilità relativa” dei diversi valori di \\(\\mu\\) alla luce dei dati osservati.\nOttimizzazione Numerica: Il valore di \\(\\mu\\) che massimizza la funzione di log-verosimiglianza è il valore che meglio spiega i dati osservati.\n\nIn conclusione, la log-verosimiglianza è uno strumento essenziale per stimare i parametri di una distribuzione normale:\n\nLa stima di massima verosimiglianza per \\(\\mu\\) coincide con la media campionaria.\nVisualizzare la log-verosimiglianza aiuta a comprendere la plausibilità dei parametri.\nL’ottimizzazione numerica fornisce una soluzione precisa ed efficiente per trovare il massimo della log-verosimiglianza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_likelihood.html#riflessioni-conclusive",
    "href": "chapters/probability/13_likelihood.html#riflessioni-conclusive",
    "title": "37  La verosimiglianza",
    "section": "37.8 Riflessioni Conclusive",
    "text": "37.8 Riflessioni Conclusive\nLa funzione di verosimiglianza rappresenta un elemento cruciale che collega i dati osservati ai parametri di un modello statistico. Essa fornisce una misura della plausibilità dei dati in relazione a diversi valori possibili dei parametri del modello. La strutturazione di una funzione di verosimiglianza richiede la considerazione di tre componenti fondamentali: il modello statistico che si presume abbia generato i dati, l’insieme di valori possibili per i parametri di tale modello e le osservazioni empiriche che effettivamente abbiamo a disposizione.\nLa funzione di verosimiglianza è centrale nella pratica dell’inferenza statistica. Essa ci permette di quantificare quanto bene differenti set di parametri potrebbero aver generato i dati osservati. Questo è fondamentale sia per la selezione del modello che per la stima dei parametri, e pertanto è indispensabile per un’analisi dati rigorosa e per un’interpretazione accurata dei risultati.\nUn’applicazione pratica e illustrativa dei principi esposti in questo capitolo è fornita nella sezione sul modello Rescorla-Wagner, che è un esempio di come la teoria della verosimiglianza possa essere applicata per affrontare questioni empiriche in psicologia.\nIn sintesi, la comprensione e l’applicazione appropriata della funzione di verosimiglianza sono passaggi essenziali nel processo di analisi dati. Essa costituisce uno strumento indispensabile per chi è impegnato nella ricerca empirica e nell’interpretazione di dati complessi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_likelihood.html#esercizi",
    "href": "chapters/probability/13_likelihood.html#esercizi",
    "title": "37  La verosimiglianza",
    "section": "37.9 Esercizi",
    "text": "37.9 Esercizi\n\nEsercizio 37.1 Spiega ciascuno dei concetti seguenti con una frase:\n\nprobabilità.\nfunzione di massa di probabilità.\nfunzione di densità di probabilità.\ndistribuzione di probabilità.\ndistribuzione di probabilità discreta.\ndistribuzione di probabilità continua.\nfunzione di distribuzione cumulativa (cdf).\nverosimiglianza\n\n\n\n\n\n\n\n\nAvviso\n\n\n\nAll’esame ti verrà chiesto di:\n\nCalcolare la funzione di verosimiglianza binomiale e riportare il valore della funzione in corrispondenza di specifici valori \\(\\theta\\).\nCalcolare la funzione di verosimiglianza del modello gaussiano, per \\(\\sigma\\) noto, e riportare il valore della funzione in corrispondenza di specifici valori \\(\\mu\\).\nCalcolare la stima di massima verosimiglianza.\nRispondere a domande che implicano una adeguata comprensione del concetto di funzione di verosimiglianza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_likelihood.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/13_likelihood.html#informazioni-sullambiente-di-sviluppo",
    "title": "37  La verosimiglianza",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] pointblank_0.12.2 haven_2.5.4       labelled_2.13.0   mice_3.17.0      \n#&gt;  [5] MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2 ggpubr_0.6.0     \n#&gt;  [9] ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0   bayesplot_1.11.1 \n#&gt; [13] psych_2.4.6.26    scales_1.3.0      markdown_1.13     knitr_1.49       \n#&gt; [17] lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4      \n#&gt; [21] purrr_1.0.2       readr_2.1.5       tidyr_1.3.1       tibble_3.2.1     \n#&gt; [25] ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] mnormt_2.1.1      rlang_1.1.4       magrittr_2.0.3    compiler_4.4.2   \n#&gt;  [5] vctrs_0.6.5       pkgconfig_2.0.3   shape_1.4.6.1     fastmap_1.2.0    \n#&gt;  [9] backports_1.5.0   labeling_0.4.3    utf8_1.2.4        promises_1.3.2   \n#&gt; [13] blastula_0.3.5    rmarkdown_2.29    tzdb_0.4.0        nloptr_2.1.1     \n#&gt; [17] xfun_0.49         glmnet_4.1-8      jomo_2.7-6        jsonlite_1.8.9   \n#&gt; [21] later_1.4.1       pan_1.9           broom_1.0.7       parallel_4.4.2   \n#&gt; [25] R6_2.5.1          stringi_1.8.4     car_3.1-3         boot_1.3-31      \n#&gt; [29] rpart_4.1.23      Rcpp_1.0.13-1     iterators_1.0.14  pacman_0.5.1     \n#&gt; [33] httpuv_1.6.15     Matrix_1.7-1      splines_4.4.2     nnet_7.3-19      \n#&gt; [37] timechange_0.3.0  tidyselect_1.2.1  abind_1.4-8       yaml_2.3.10      \n#&gt; [41] codetools_0.2-20  miniUI_0.1.1.1    lattice_0.22-6    shiny_1.9.1      \n#&gt; [45] withr_3.0.2       evaluate_1.0.1    survival_3.7-0    pillar_1.9.0     \n#&gt; [49] carData_3.0-5     foreach_1.5.2     generics_0.1.3    rprojroot_2.0.4  \n#&gt; [53] hms_1.1.3         munsell_0.5.1     minqa_1.2.8       xtable_1.8-4     \n#&gt; [57] glue_1.8.0        tools_4.4.2       lme4_1.1-35.5     ggsignif_0.6.4   \n#&gt; [61] grid_4.4.2        colorspace_2.1-1  nlme_3.1-166      Formula_1.2-5    \n#&gt; [65] cli_3.6.3         fansi_1.0.6       gtable_0.3.6      rstatix_0.7.2    \n#&gt; [69] digest_0.6.37     htmlwidgets_1.6.4 farver_2.1.2      htmltools_0.5.8.1\n#&gt; [73] lifecycle_1.0.4   mitml_0.4-5       mime_0.12",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_simulation.html",
    "href": "chapters/probability/14_simulation.html",
    "title": "38  Simulazioni",
    "section": "",
    "text": "38.1 Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nPreparazione del Notebook\nIn questo capitolo, discuteremo alcuni esercizi di simulazione presentati da Gelman et al. (2021) nel quinto capitolo del loro libro. Gli autori sottolineano che simulare variabili casuali è essenziale nelle statistiche applicate per diversi motivi:",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_simulation.html#introduzione",
    "href": "chapters/probability/14_simulation.html#introduzione",
    "title": "38  Simulazioni",
    "section": "",
    "text": "Comprensione della variazione casuale: I modelli di probabilità imitano la variabilità del mondo reale. La simulazione aiuta a sviluppare intuizioni sulle oscillazioni casuali nel breve termine e sui loro effetti nel lungo termine.\nDistribuzione campionaria: Simulare dati consente di approssimare la distribuzione campionaria, trasferendo questa approssimazione alle stime e alle procedure statistiche.\nPrevisioni probabilistiche: I modelli di regressione producono previsioni probabilistiche. La simulazione è il metodo più generale per rappresentare l’incertezza nelle previsioni.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_simulation.html#esempio-1-quante-bambine-su-400-nascite",
    "href": "chapters/probability/14_simulation.html#esempio-1-quante-bambine-su-400-nascite",
    "title": "38  Simulazioni",
    "section": "38.2 Esempio 1: Quante bambine su 400 nascite?",
    "text": "38.2 Esempio 1: Quante bambine su 400 nascite?\nSupponiamo che la probabilità di nascita di una bambina sia \\(p\\) = 0.488. Se in un ospedale nascono 400 bambini in un anno, quante saranno bambine? Possiamo simulare questo processo usando una distribuzione binomiale, ripetendo la simulazione 10,000 volte.\n\n# Numero di simulazioni\nn_sims &lt;- 10000\n\n# Probabilità di nascita di una bambina\np_girl &lt;- 0.488\n\n# Simulazione del numero di bambine\nset.seed(123)\nn_girls &lt;- rbinom(n_sims, size = 400, prob = p_girl)\n\n# Visualizzazione dell'istogramma\nggplot(data.frame(n_girls), aes(x = n_girls)) +\n  geom_histogram(binwidth = 5, fill = \"blue\", color = \"black\", alpha = 0.6) +\n  labs(\n    title = \"Distribuzione del Numero di Bambine su 400 Nascite\",\n    x = \"Numero di Bambine\",\n    y = \"Frequenza\"\n  )",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_simulation.html#simulazione-di-probabilità-continue",
    "href": "chapters/probability/14_simulation.html#simulazione-di-probabilità-continue",
    "title": "38  Simulazioni",
    "section": "38.3 Simulazione di probabilità continue",
    "text": "38.3 Simulazione di probabilità continue\nGelman et al. (2021) dimostrano come sia possibile incorporare anche distribuzioni di probabilità continue nei tipi di simulazioni discusse nella sezione precedente. Forniscono il seguente esempio di un modello misto discreto/continuo: il 52% degli adulti negli Stati Uniti sono donne e il 48% sono uomini. L’altezza degli uomini segue approssimativamente una distribuzione normale con una media di 69.1 pollici e una deviazione standard di 2.9 pollici; per le donne, la media è 63.7 pollici e la deviazione standard è 2.7 pollici. Ecco il codice per generare l’altezza di un adulto scelto casualmente:\n\nsimulate_height &lt;- function(N) {\n  gender &lt;- rbinom(N, size = 1, prob = 0.48) # 1 = uomo, 0 = donna\n  height &lt;- ifelse(\n    gender == 1,\n    rnorm(N, mean = 69.1, sd = 2.9),\n    rnorm(N, mean = 63.7, sd = 2.7)\n  )\n  return(mean(height))\n}\n\nSupponiamo di selezionare 10 adulti a caso. Cosa possiamo dire della loro altezza media?\n\nset.seed(123)\nn_sims &lt;- 10000\navg_heights &lt;- replicate(n_sims, simulate_height(10))\n\n# Visualizzazione dell'istogramma\nggplot(data.frame(avg_heights), aes(x = avg_heights)) +\n  geom_histogram(binwidth = 0.2, fill = \"blue\", color = \"black\", alpha = 0.6) +\n  labs(\n    title = \"Distribuzione dell'Altezza Media di 10 Adulti\",\n    x = \"Altezza Media\",\n    y = \"Frequenza\"\n  )",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_simulation.html#sommario-di-una-simulazione-con-media-e-mediana",
    "href": "chapters/probability/14_simulation.html#sommario-di-una-simulazione-con-media-e-mediana",
    "title": "38  Simulazioni",
    "section": "38.4 Sommario di una simulazione con media e mediana",
    "text": "38.4 Sommario di una simulazione con media e mediana\nQuando le nostre distribuzioni sono costruite come simulazioni al computer, può essere conveniente riassumerle in qualche modo. Tipicamente, riassumiamo la posizione di una distribuzione con la sua media o mediana.\nLa variazione nella distribuzione è tipicamente riassunta dalla deviazione standard, ma spesso preferiamo usare la deviazione mediana assoluta. Se la mediana di un insieme di simulazioni \\(z_1, \\ldots, z_n\\) è \\(M\\), allora la deviazione mediana assoluta è:\n\\[ \\text{mad} = \\text{mediana}_{n} |z_i - M| \\]\nTuttavia, poiché siamo abituati a lavorare con le deviazioni standard, quando calcoliamo la deviazione mediana assoluta, la riscaliamo moltiplicandola per 1.483, il che riproduce la deviazione standard nel caso speciale della distribuzione normale:\n\\[ 1.483 * \\text{median}(|y - \\text{median}(z)|) \\]\nPreferiamo tipicamente i riassunti basati sulla mediana perché sono più stabili computazionalmente, e riscaliamo il riassunto basato sulla mediana della variazione come descritto sopra in modo da essere comparabile alla deviazione standard, che sappiamo già interpretare nella pratica statistica usuale.\nEcco come implementare quanto sopra in R per i dati relativi all’altezza media di 10 adulti.\n\n# Calcolo della media e mediana\nmean_avg_height &lt;- mean(avg_heights)\nmedian_avg_height &lt;- median(avg_heights)\n\n# Calcolo della deviazione standard\nsd_avg_height &lt;- sd(avg_heights)\n\n# Calcolo della MAD (Deviazione Mediana Assoluta)\nmad_avg_height &lt;- median(abs(avg_heights - median_avg_height)) * 1.483\n\n# Risultati\ncat(\"Mean:\", mean_avg_height, \"\\n\")\n#&gt; Mean: 66.3\ncat(\"Median:\", median_avg_height, \"\\n\")\n#&gt; Median: 66.3\ncat(\"Standard Deviation:\", sd_avg_height, \"\\n\")\n#&gt; Standard Deviation: 1.23\ncat(\"MAD (scaled):\", mad_avg_height, \"\\n\")\n#&gt; MAD (scaled): 1.23\n\n\n38.4.1 Intervalli di Incertezza\nPer rappresentare l’incertezza, possiamo calcolare intervalli centrali al 50% e al 95%.\n\n# Intervalli di incertezza\nlower_50 &lt;- quantile(avg_heights, 0.25)\nupper_50 &lt;- quantile(avg_heights, 0.75)\n\nlower_95 &lt;- quantile(avg_heights, 0.025)\nupper_95 &lt;- quantile(avg_heights, 0.975)\n\ncat(\"50% Interval:\", lower_50, \"-\", upper_50, \"\\n\")\n#&gt; 50% Interval: 65.5 - 67.1\ncat(\"95% Interval:\", lower_95, \"-\", upper_95, \"\\n\")\n#&gt; 95% Interval: 63.9 - 68.8\n\nEcco come interpretarli.\nIntervallo centrale al 50%.\n\nContiene i valori centrali che coprono il 50% della distribuzione. Questo intervallo si estende dal primo quartile (25° percentile) al terzo quartile (75° percentile).\nIndica la fascia di valori in cui si trovano i risultati “più comuni” o tipici. È una misura di variabilità concentrata nella parte centrale della distribuzione, meno sensibile a valori estremi.\n\nPer le altezze medie simulate di 10 adulti, un intervallo centrale al 50% che va da 65 a 67 pollici indica che metà delle medie osservate si trova in questo intervallo.\n\n\nIntervallo centrale al 95%.\n\nContiene il 95% della distribuzione simulata, lasciando solo il 2.5% dei valori al di sotto e il 2.5% al di sopra dell’intervallo. Questo intervallo si calcola tra il 2.5° percentile e il 97.5° percentile.\nIndica una fascia più ampia che cattura quasi tutti i valori plausibili, inclusi quelli meno probabili ma comunque possibili.\n\nPer le altezze medie simulate, un intervallo al 95% che va da 64 a 68 pollici significa che, in quasi tutte le simulazioni, l’altezza media si trova in questo intervallo, con poche eccezioni.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_simulation.html#commenti-e-considerazioni-finali",
    "href": "chapters/probability/14_simulation.html#commenti-e-considerazioni-finali",
    "title": "38  Simulazioni",
    "section": "38.5 Commenti e Considerazioni Finali",
    "text": "38.5 Commenti e Considerazioni Finali\nLo scopo della simulazione di dati fittizi non è fornire intuizioni sui dati o sul problema reale in esame, ma piuttosto valutare le proprietà dei metodi statistici utilizzati, partendo da un modello generativo ipotizzato. Le simulazioni sono cruciali nella pratica della ricerca. Molti autori suggeriscono che dovrebbero essere eseguite prima di raccogliere i dati di uno studio, per valutare, tra le altre cose, se la dimensione campionaria prevista fornisce un potere statistico sufficiente per rispondere alla domanda della ricerca (Gelman & Brown, 2024).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_simulation.html#esercizi",
    "href": "chapters/probability/14_simulation.html#esercizi",
    "title": "38  Simulazioni",
    "section": "38.6 Esercizi",
    "text": "38.6 Esercizi\n\nEsercizio 38.1 Immagina il caso di 220 studenti che devono sostenere tre prove in itinere in un corso. Il voto finale è la media dei voti ottenuti in queste tre prove. Le distribuzioni dei voti per le prove sono descritte come segue:\n\nPrima prova: I voti sono distribuiti secondo una gaussiana con media 24. Il 15% degli studenti ottiene un voto inferiore a 18.\nSeconda prova: I voti sono distribuiti secondo una gaussiana con media 25. Il 10% degli studenti ottiene un voto inferiore a 18.\nTerza prova: I voti sono distribuiti secondo una gaussiana con media 26. Solo il 5% degli studenti ottiene un voto inferiore a 18.\n\nDei 220 studenti iniziali:\n\nIl 10% non partecipa alla prima prova.\nUn ulteriore 5% non partecipa alla seconda prova.\n\nPer ottenere il voto finale, uno studente deve partecipare a tutte e tre le prove.\nUtilizzando una simulazione, trova la media finale dei voti e calcola l’intervallo di incertezza al 90% per la stima della media.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_simulation.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/14_simulation.html#informazioni-sullambiente-di-sviluppo",
    "title": "38  Simulazioni",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2 ggpubr_0.6.0     \n#&gt;  [5] ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0   bayesplot_1.11.1 \n#&gt;  [9] psych_2.4.6.26    scales_1.3.0      markdown_1.13     knitr_1.49       \n#&gt; [13] lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4      \n#&gt; [17] purrr_1.0.2       readr_2.1.5       tidyr_1.3.1       tibble_3.2.1     \n#&gt; [21] ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      xfun_0.49         htmlwidgets_1.6.4 rstatix_0.7.2    \n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    fansi_1.0.6       pacman_0.5.1     \n#&gt; [13] pkgconfig_2.0.3   lifecycle_1.0.4   compiler_4.4.2    farver_2.1.2     \n#&gt; [17] munsell_0.5.1     mnormt_2.1.1      carData_3.0-5     httpuv_1.6.15    \n#&gt; [21] htmltools_0.5.8.1 yaml_2.3.10       Formula_1.2-5     car_3.1-3        \n#&gt; [25] pillar_1.9.0      later_1.4.1       abind_1.4-8       nlme_3.1-166     \n#&gt; [29] mime_0.12         tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4    \n#&gt; [33] labeling_0.4.3    rprojroot_2.0.4   fastmap_1.2.0     grid_4.4.2       \n#&gt; [37] colorspace_2.1-1  cli_3.6.3         magrittr_2.0.3    utf8_1.2.4       \n#&gt; [41] broom_1.0.7       withr_3.0.2       backports_1.5.0   promises_1.3.2   \n#&gt; [45] timechange_0.3.0  rmarkdown_2.29    ggsignif_0.6.4    hms_1.1.3        \n#&gt; [49] shiny_1.9.1       evaluate_1.0.1    miniUI_0.1.1.1    rlang_1.1.4      \n#&gt; [53] Rcpp_1.0.13-1     xtable_1.8-4      glue_1.8.0        jsonlite_1.8.9   \n#&gt; [57] R6_2.5.1",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_simulation.html#bibliografia",
    "href": "chapters/probability/14_simulation.html#bibliografia",
    "title": "38  Simulazioni",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., & Brown, N. J. (2024). How statistical challenges and misreadings of the literature combine to produce unreplicable science: An example from psychology.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/introduction_bayes_inference.html",
    "href": "chapters/bayesian_inference/introduction_bayes_inference.html",
    "title": "Introduzione",
    "section": "",
    "text": "In questa sezione della dispensa, esamineremo l’inferenza bayesiana applicata a modelli statistici in cui si stima un unico parametro scalare, cioè quando l’estimando \\(\\theta\\) è unidimensionale. In questo capitolo, consideriamo quattro modelli unidimensionali fondamentali e ampiamente utilizzati: il modello binomiale, il modello normale, il modello di Poisson e il modello esponenziale. Approfondiremo il processo di aggiornamento bayesiano, analizzando due metodi principali per derivare la distribuzione a posteriori: l’approssimazione numerica attraverso il metodo basato su griglia e l’utilizzo delle distribuzioni coniugate, in cui una specifica combinazione di distribuzione a priori e verosimiglianza consente una derivazione analitica della distribuzione a posteriori. Inoltre, considereremo l’influenza della scelta della distribuzione a priori sulla distribuzione a posteriori e discuteremo le tecniche utili per sintetizzare e interpretare quest’ultima in modo efficace.",
    "crumbs": [
      "Inferenza",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html",
    "href": "chapters/bayesian_inference/01_intro_bayes.html",
    "title": "39  La quantificazione dell’incertezza",
    "section": "",
    "text": "39.1 Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nPreparazione del Notebook\nL’approccio bayesiano alla statistica non si limita all’applicazione del Teorema di Bayes, ma si caratterizza per una gestione rigorosa dell’incertezza e per la rappresentazione delle soluzioni attraverso distribuzioni di probabilità. Il processo di modellazione bayesiana, noto come workflow bayesiano (Baribault & Collins, 2023), si articola in più fasi: dalla costruzione del modello, all’applicazione del Teorema di Bayes, fino all’analisi critica dei risultati. Questo ciclo iterativo permette un apprendimento continuo, migliorando progressivamente le stime e adattandole alle nuove evidenze che emergono.\nL’obiettivo dell’approccio bayesiano non è quello di raggiungere una verità assoluta, ma di aggiornare razionalmente le credenze su una determinata ipotesi, integrando progressivamente nuove informazioni. Questo approccio è particolarmente utile in psicologia, dove i fenomeni analizzati sono complessi e le misurazioni soggette a molte fonti di incertezza.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#introduzione",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#introduzione",
    "title": "39  La quantificazione dell’incertezza",
    "section": "",
    "text": "“Quindi non avete una sola risposta alle vostre domande?”\n“Adson, se l’avessi insegnerei teologia a Parigi.”\n“A Parigi hanno sempre la risposta vera?”\n“Mai,” disse Guglielmo, “ma sono molto sicuri dei loro errori.”\n(Umberto Eco: Il Nome della Rosa)",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#il-valore-dellincertezza",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#il-valore-dellincertezza",
    "title": "39  La quantificazione dell’incertezza",
    "section": "39.2 Il Valore dell’Incertezza",
    "text": "39.2 Il Valore dell’Incertezza\nIn psicologia e in altre scienze sociali, l’informazione è spesso incompleta, e le variabili di interesse sono latenti o difficili da osservare direttamente. L’inferenza bayesiana offre un quadro metodologico per rappresentare e affrontare questa incertezza, permettendo di modellare ciò che non si conosce come una variabile aleatoria che può essere aggiornata man mano che si acquisiscono nuovi dati (Jaynes, 2003).\nDiversamente dai modelli deterministici, che assumono la possibilità di prevedere i risultati con certezza date tutte le informazioni, i modelli bayesiani accolgono e gestiscono l’incertezza, caratteristica fondamentale in psicologia. Molti fenomeni psicologici coinvolgono variabili latenti – come l’ansia, la motivazione o l’autostima – che non possono essere osservate direttamente. L’approccio bayesiano consente di rappresentare tali variabili in modo flessibile, integrando evidenze precedenti con i dati attuali.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#interpretazione-frequentista-vs.-bayesiana-dellincertezza",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#interpretazione-frequentista-vs.-bayesiana-dellincertezza",
    "title": "39  La quantificazione dell’incertezza",
    "section": "39.3 Interpretazione Frequentista vs. Bayesiana dell’Incertezza",
    "text": "39.3 Interpretazione Frequentista vs. Bayesiana dell’Incertezza\n\nInterpretazione Frequentista: Immaginiamo di misurare la frequenza di un evento psicologico, come un livello di ansia oltre una certa soglia, in un grande campione di individui simili. Secondo i frequentisti, si potrebbe interpretare l’incertezza come la frequenza relativa dell’evento in situazioni simili nel lungo periodo. Tuttavia, questa interpretazione presenta due problemi principali: non è possibile osservare un evento infinite volte in condizioni identiche, e il “gruppo di riferimento” (o reference class) – cioè, le condizioni simili rilevanti – può essere difficile da definire precisamente.\nInterpretazione Bayesiana: Un’interpretazione bayesiana dell’incertezza riguarda invece il grado di credenza soggettiva. Supponiamo che uno psicologo creda con il 10% di fiducia che un individuo avrà un punteggio d’ansia superiore a una certa soglia. Questo grado di fiducia può essere aggiornato man mano che si raccolgono nuove informazioni, utilizzando il Teorema di Bayes per calcolare probabilità a posteriori. A differenza dell’approccio frequentista, l’incertezza bayesiana descrive una credenza soggettiva che può essere costantemente aggiornata.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#esempi-psicologici-dellinferenza-bayesiana",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#esempi-psicologici-dellinferenza-bayesiana",
    "title": "39  La quantificazione dell’incertezza",
    "section": "39.4 Esempi Psicologici dell’Inferenza Bayesiana",
    "text": "39.4 Esempi Psicologici dell’Inferenza Bayesiana\nEsempio 1: Misurare l’Ansia con Questionari\nQuando si misura l’ansia tramite un questionario, la stima è soggetta a incertezza per vari motivi: 1. Risposte Soggettive: L’interpretazione delle domande può variare tra individui e può essere influenzata dallo stato d’animo. 2. Misurazioni Incomplete: Un questionario può non cogliere tutte le sfumature dell’ansia. 3. Rumore nei Dati: Errori minori, come distrazioni durante la compilazione, possono influire sulla precisione dei risultati.\nCon l’approccio bayesiano, è possibile combinare credenze a priori basate su ricerche precedenti con i dati raccolti per ottenere una stima aggiornata. Ad esempio, se si dispone di una distribuzione di probabilità iniziale sull’ansia, questa distribuzione può essere aggiornata man mano che si raccolgono più dati, permettendo una stima più accurata del livello di ansia effettivo.\nEsempio 2: Effetto del Rinforzo Negativo sulla Motivazione\nConsideriamo uno studio sull’effetto del rinforzo negativo sulla motivazione in un compito. La “motivazione interna” è una variabile latente, non osservabile direttamente. Possiamo inferirla, però, tramite misure indirette, come il tempo trascorso sul compito o la velocità di risposta. Un modello bayesiano consente di collegare queste variabili osservabili alla motivazione latente, rappresentando l’incertezza sia nella variabilità individuale sia nell’effetto del rinforzo negativo. Man mano che vengono raccolti nuovi dati, il modello bayesiano aggiorna le stime di motivazione e permette di esprimere in modo rigoroso la probabilità che un cambiamento osservato sia effettivamente dovuto al rinforzo negativo.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#inferenza-bayesiana-e-incertezza-nelle-stime",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#inferenza-bayesiana-e-incertezza-nelle-stime",
    "title": "39  La quantificazione dell’incertezza",
    "section": "39.5 Inferenza Bayesiana e Incertezza nelle Stime",
    "text": "39.5 Inferenza Bayesiana e Incertezza nelle Stime\nL’inferenza bayesiana utilizza le probabilità per aggiornare le credenze sui parametri di un modello basandosi sui dati osservati. Queste credenze sono rappresentate da distribuzioni di probabilità, e l’ampiezza di queste distribuzioni riflette l’incertezza associata alle stime. In psicologia, dove spesso si lavora con campioni limitati e misurazioni indirette di variabili latenti, questa gestione dell’incertezza è fondamentale per interpretare i risultati in modo robusto e realistico.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#il-modello-bayesiano",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#il-modello-bayesiano",
    "title": "39  La quantificazione dell’incertezza",
    "section": "39.6 Il Modello Bayesiano",
    "text": "39.6 Il Modello Bayesiano\nUn modello statistico combina una distribuzione probabilistica con ipotesi sui parametri per descrivere un fenomeno osservato. Ad esempio, possiamo modellare il lancio di una moneta equa con un modello binomiale, in cui la probabilità \\(\\theta\\) è fissata a 0.5, oppure modellare l’altezza degli uomini italiani con un modello normale, in cui \\(\\mu\\) è 183 cm e \\(\\sigma\\) è 5 cm. In termini bayesiani, il modello statistico include tre componenti principali:\n\nDistribuzione a Priori (Prior): Rappresenta le credenze iniziali sui valori dei parametri del modello, informate da ricerche precedenti o da assunzioni neutre.\nVerosimiglianza (Likelihood): Descrive la probabilità di osservare i dati dati i parametri del modello, riflettendo il processo che genera i dati.\nDistribuzione a Posteriori (Posterior): È la distribuzione aggiornata dei parametri dopo aver osservato i dati, ottenuta combinando la prior e la verosimiglianza mediante il teorema di Bayes. La posterior rappresenta la conoscenza aggiornata dopo aver integrato le informazioni fornite dai dati.\n\nLa modellazione bayesiana descrive il processo generativo che ha prodotto i dati osservati, incorporando l’incertezza nei parametri e aggiornando continuamente le stime man mano che emergono nuovi dati. Questo approccio è particolarmente utile in contesti come la psicologia, dove i fenomeni complessi e le variabili latenti rendono necessario modellare l’incertezza in modo esplicito.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#componenti-chiave-della-modellazione-probabilistica",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#componenti-chiave-della-modellazione-probabilistica",
    "title": "39  La quantificazione dell’incertezza",
    "section": "39.7 Componenti Chiave della Modellazione Probabilistica",
    "text": "39.7 Componenti Chiave della Modellazione Probabilistica\n\nVariabili Aleatorie: Quantità incerte che assumono diversi valori secondo una distribuzione di probabilità. Ad esempio, il livello di depressione di un paziente può essere trattato come una variabile aleatoria.\nDistribuzioni di Probabilità: Descrivono come i valori di una variabile aleatoria sono distribuiti. Ad esempio, una distribuzione normale può essere utilizzata per modellare la variabilità dell’ansia in una popolazione.\nInferenza Bayesiana: Aggiorna la distribuzione di probabilità delle variabili di interesse sulla base dei nuovi dati, migliorando progressivamente le stime.\n\nEsempio: Inferenza sul Livello di Depressione\nIn uno studio clinico sulla depressione, possiamo utilizzare l’inferenza bayesiana per stimare il livello di depressione di un paziente partendo da una distribuzione a priori informata da studi precedenti. Ogni nuovo dato raccolto (come punteggi a questionari o osservazioni) permette di aggiornare questa stima, affinando progressivamente la comprensione del fenomeno.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#il-potere-dellaggiornamento-bayesiano",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#il-potere-dellaggiornamento-bayesiano",
    "title": "39  La quantificazione dell’incertezza",
    "section": "39.8 Il Potere dell’Aggiornamento Bayesiano",
    "text": "39.8 Il Potere dell’Aggiornamento Bayesiano\nIl vero punto di forza della modellazione bayesiana risiede nella sua capacità di aggiornare continuamente le credenze sui parametri del modello man mano che si raccolgono nuovi dati. Questo processo iterativo, basato sul teorema di Bayes, consente di integrare sia le credenze iniziali (a priori) sia le evidenze empiriche (verosimiglianza) per ottenere stime sempre più precise.\nEsempio Intuitivo: Il Globo Terrestre\nUn esempio intuitivo per spiegare l’aggiornamento bayesiano è quello proposto da McElreath (2020). Supponiamo di voler stimare la proporzione della superficie terrestre coperta d’acqua. L’esperimento consiste nel lanciare un globo terrestre in aria, afferrarlo e osservare se la superficie sotto il dito è acqua o terra. Dopo ogni osservazione, possiamo aggiornare le nostre credenze sulla proporzione d’acqua (p).\nIniziamo con una distribuzione a priori che assegna la stessa probabilità a tutti i valori possibili di \\(p\\) (proporzione d’acqua). Dopo il primo lancio, in cui osserviamo acqua (“W”), la probabilità che \\(p\\) sia zero diminuisce, mentre quella che \\(p\\) sia maggiore aumenta. Man mano che raccogliamo più dati, la distribuzione si aggiorna, riducendo l’incertezza e convergendo verso una stima più precisa di \\(p\\).\nCon l’aumento dei dati osservati, la distribuzione a posteriori si concentra sempre di più attorno ai valori di \\(p\\) che meglio spiegano i dati. Questo processo rappresenta il continuo affinamento delle stime bayesiane, che diventano più accurate man mano che le evidenze si accumulano.\nIn sintesi, l’aggiornamento bayesiano fornisce un quadro flessibile e sistematico per trattare l’incertezza e integrare nuove informazioni. È particolarmente utile nelle scienze psicologiche e sociali, dove la complessità e la variabilità dei fenomeni rendono difficile ottenere stime precise. Questo approccio consente di migliorare costantemente la comprensione dei fenomeni, adattando le credenze man mano che emergono nuovi dati.\n\n#&gt; Warning in plot.window(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in plot.xy(xy, type, ...): parametro grafico \"alpha\" non valido\n#&gt; Warning in axis(side = side, at = at, labels = labels, ...): parametro\n#&gt; grafico \"alpha\" non valido\n#&gt; Warning in axis(side = side, at = at, labels = labels, ...): parametro\n#&gt; grafico \"alpha\" non valido\n#&gt; Warning in box(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in title(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in plot.window(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in plot.xy(xy, type, ...): parametro grafico \"alpha\" non valido\n#&gt; Warning in axis(side = side, at = at, labels = labels, ...): parametro\n#&gt; grafico \"alpha\" non valido\n#&gt; Warning in axis(side = side, at = at, labels = labels, ...): parametro\n#&gt; grafico \"alpha\" non valido\n#&gt; Warning in box(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in title(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in plot.window(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in plot.xy(xy, type, ...): parametro grafico \"alpha\" non valido\n#&gt; Warning in axis(side = side, at = at, labels = labels, ...): parametro\n#&gt; grafico \"alpha\" non valido\n#&gt; Warning in axis(side = side, at = at, labels = labels, ...): parametro\n#&gt; grafico \"alpha\" non valido\n#&gt; Warning in box(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in title(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in plot.window(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in plot.xy(xy, type, ...): parametro grafico \"alpha\" non valido\n#&gt; Warning in axis(side = side, at = at, labels = labels, ...): parametro\n#&gt; grafico \"alpha\" non valido\n#&gt; Warning in axis(side = side, at = at, labels = labels, ...): parametro\n#&gt; grafico \"alpha\" non valido\n#&gt; Warning in box(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in title(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in plot.window(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in plot.xy(xy, type, ...): parametro grafico \"alpha\" non valido\n#&gt; Warning in axis(side = side, at = at, labels = labels, ...): parametro\n#&gt; grafico \"alpha\" non valido\n#&gt; Warning in axis(side = side, at = at, labels = labels, ...): parametro\n#&gt; grafico \"alpha\" non valido\n#&gt; Warning in box(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in title(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in plot.window(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in plot.xy(xy, type, ...): parametro grafico \"alpha\" non valido\n#&gt; Warning in axis(side = side, at = at, labels = labels, ...): parametro\n#&gt; grafico \"alpha\" non valido\n#&gt; Warning in axis(side = side, at = at, labels = labels, ...): parametro\n#&gt; grafico \"alpha\" non valido\n#&gt; Warning in box(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in title(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in plot.window(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in plot.xy(xy, type, ...): parametro grafico \"alpha\" non valido\n#&gt; Warning in axis(side = side, at = at, labels = labels, ...): parametro\n#&gt; grafico \"alpha\" non valido\n#&gt; Warning in axis(side = side, at = at, labels = labels, ...): parametro\n#&gt; grafico \"alpha\" non valido\n#&gt; Warning in box(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in title(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in plot.window(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in plot.xy(xy, type, ...): parametro grafico \"alpha\" non valido\n#&gt; Warning in axis(side = side, at = at, labels = labels, ...): parametro\n#&gt; grafico \"alpha\" non valido\n#&gt; Warning in axis(side = side, at = at, labels = labels, ...): parametro\n#&gt; grafico \"alpha\" non valido\n#&gt; Warning in box(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in title(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in plot.window(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in plot.xy(xy, type, ...): parametro grafico \"alpha\" non valido\n#&gt; Warning in axis(side = side, at = at, labels = labels, ...): parametro\n#&gt; grafico \"alpha\" non valido\n#&gt; Warning in axis(side = side, at = at, labels = labels, ...): parametro\n#&gt; grafico \"alpha\" non valido\n#&gt; Warning in box(...): parametro grafico \"alpha\" non valido\n#&gt; Warning in title(...): parametro grafico \"alpha\" non valido\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIl grafico precedente illustra un processo di aggiornamento bayesiano, in cui vengono progressivamente aggiornate le credenze sulla proporzione di superficie coperta d’acqua (\\(p\\)) del globo terrestre, man mano che vengono raccolti nuovi dati.\nL’esperimento prevede il lancio di un globo terrestre per osservare se la superficie sotto il dito è acqua (“W”) o terra (“L”). Dopo ogni lancio, le probabilità sui possibili valori di \\(p\\) vengono aggiornate sulla base delle osservazioni, utilizzando il teorema di Bayes. Il processo è visualizzato attraverso una serie di grafici, organizzati in una griglia 3x3, con ogni pannello che rappresenta un’osservazione aggiuntiva.\n\nLinee tratteggiate: Ogni curva tratteggiata in un pannello rappresenta la distribuzione di probabilità a posteriori (posterior) derivata dal pannello precedente. In altre parole, questa è la distribuzione che incorpora tutte le osservazioni fino a quel momento.\nLinee continue: Ogni curva continua rappresenta la nuova distribuzione a posteriori, aggiornata dopo aver aggiunto una nuova osservazione. Questa curva combina la distribuzione a priori (che coincide con la curva tratteggiata dal pannello precedente) e la nuova evidenza.\n\n\nPrimo Pannello (Osservazione: W)\n\nLa prima osservazione è “acqua” (W). La distribuzione a priori è uniforme, poiché non ci sono informazioni iniziali. Dopo aver osservato acqua, la distribuzione a posteriori si aggiorna: la probabilità che \\(p = 0\\) (nessuna acqua) è ora zero, e la curva si sposta verso destra, indicando che è più probabile che \\(p\\) sia maggiore di 0.\n\nSecondo Pannello (Osservazione: L)\n\nLa seconda osservazione è “terra” (L). La curva si sposta leggermente verso sinistra, poiché è ora meno probabile che \\(p\\) sia molto alto (vicino a 1). La probabilità che \\(p\\) sia 0.5 diventa massima, in quanto abbiamo osservato una volta acqua e una volta terra.\n\nTerzo Pannello (Osservazione: W)\n\nIl terzo lancio produce di nuovo acqua. La curva si sposta nuovamente verso destra, con un picco vicino a \\(p = 0.75\\), riflettendo che abbiamo osservato acqua due volte su tre. La distribuzione si aggiorna in base alla nuova evidenza.\n\nPannelli Successivi\n\nOgni nuovo pannello segue lo stesso schema: la distribuzione a priori (linea tratteggiata) viene aggiornata con la nuova osservazione (linea continua). Se viene osservata acqua (W), il picco della distribuzione si sposta a destra; se viene osservata terra (L), il picco si sposta a sinistra. In ogni caso, la curva diventa progressivamente più “appuntita”, indicando che l’incertezza sulla vera proporzione di acqua diminuisce con l’aumentare del numero di osservazioni.\n\n\nL’aspetto fondamentale dell’approccio bayesiano è che ogni distribuzione a posteriori aggiornata (linea continua) diventa la nuova distribuzione a priori per la successiva osservazione. Questo processo iterativo permette di apprendere progressivamente dai dati, integrando ogni nuova informazione per affinare la stima di \\(p\\). Alla fine, la distribuzione diventa sempre più concentrata intorno al valore più probabile di \\(p\\), man mano che raccogliamo più dati.\nIn conclusione, l’esempio illustra come l’aggiornamento bayesiano modifichi le nostre credenze sulla proporzione d’acqua (\\(p\\)) sulla superficie del globo, basandosi sulle osservazioni raccolte. Ogni curva rappresenta la sintesi delle conoscenze attuali, combinando le osservazioni precedenti con l’ultima evidenza raccolta. Il grafico dimostra visivamente come l’approccio bayesiano consenta di trattare l’incertezza e aggiornare le stime in modo coerente e progressivo.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#il-processo-generatore-dei-dati",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#il-processo-generatore-dei-dati",
    "title": "39  La quantificazione dell’incertezza",
    "section": "39.9 Il Processo Generatore dei Dati",
    "text": "39.9 Il Processo Generatore dei Dati\nNel contesto dell’aggiornamento bayesiano, è fondamentale fare un’assunzione su quale modello statistico descriva il processo generatore dei dati, ossia il meccanismo che collega i parametri sconosciuti ai dati osservati. Questo modello è rappresentato dalla funzione di verosimiglianza, che descrive la probabilità di osservare i dati per ogni possibile valore del parametro incognito. Ad esempio, nel caso di esperimenti bernoulliani come quello dei lanci del globo, ogni prova può risultare in un successo (acqua) o in un fallimento (terra), e l’obiettivo è stimare la probabilità di successo, \\(\\theta\\).\nIl processo generatore dei dati per questo tipo di esperimento è ben descritto da una distribuzione binomiale, che modella il numero di successi osservati in una serie di prove indipendenti, ciascuna caratterizzata dalla stessa probabilità \\(\\theta\\). In questo contesto, \\(\\theta\\) rappresenta la proporzione di superficie coperta d’acqua sul globo, e l’assunzione chiave è che essa rimanga costante durante l’intero esperimento.\n\n\n\n\n\n\nFigura 39.1: Gli stessi dati possono essere coerenti con diverse ipotesi riguardanti il processo che li ha generati(Figura tratta da Freiesleben & Molnar, 2024).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#aggiornamento-bayesiano-e-processo-generatore",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#aggiornamento-bayesiano-e-processo-generatore",
    "title": "39  La quantificazione dell’incertezza",
    "section": "39.10 Aggiornamento Bayesiano e Processo Generatore",
    "text": "39.10 Aggiornamento Bayesiano e Processo Generatore\nL’aggiornamento bayesiano permette di modificare le nostre credenze riguardo al valore del parametro \\(\\theta\\) man mano che osserviamo nuovi dati. Il punto di partenza è una distribuzione a priori su \\(\\theta\\), che può riflettere la nostra ignoranza (ad esempio, una distribuzione uniforme, che assegna uguale probabilità a tutti i valori di \\(\\theta\\) tra 0 e 1) o conoscenze preesistenti. Nel nostro esempio con il globo, possiamo iniziare con una distribuzione a priori uniforme, che indica che ogni proporzione di acqua è inizialmente considerata ugualmente probabile.\nMan mano che raccogliamo dati (ad esempio, 6 successi su 9 lanci), applichiamo il Teorema di Bayes per combinare la distribuzione a priori con la verosimiglianza dei dati osservati, ottenendo una distribuzione a posteriori che rappresenta le nostre credenze aggiornate su \\(\\theta\\). La distribuzione a posteriori riflette le informazioni aggiunte dai dati e fornisce una stima aggiornata e più precisa di \\(\\theta\\).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#interpretazione-della-distribuzione-a-posteriori",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#interpretazione-della-distribuzione-a-posteriori",
    "title": "39  La quantificazione dell’incertezza",
    "section": "39.11 Interpretazione della Distribuzione a Posteriori",
    "text": "39.11 Interpretazione della Distribuzione a Posteriori\nLa distribuzione a posteriori ci permette di fare inferenze più solide su \\(\\theta\\). In particolare, possiamo calcolare:\n\nModa: Il valore di \\(\\theta\\) con la massima probabilità, che indica la stima più plausibile.\nMedia o Mediana: Altre misure riassuntive della distribuzione a posteriori, che possono fornire ulteriori informazioni sull’intervallo di valori probabili per \\(\\theta\\).\n\nL’incertezza sulla stima è rappresentata dall’ampiezza della distribuzione a posteriori. Se la distribuzione è stretta, significa che l’incertezza è bassa, mentre una distribuzione più ampia indica una maggiore incertezza. Con l’aumento dei dati osservati, la distribuzione tende a concentrarsi intorno a un intervallo ristretto, riducendo l’incertezza e migliorando la precisione della stima.\nNel caso del globo, ad esempio, se osserviamo che la distribuzione a posteriori ha un picco vicino a \\(\\theta = 0.67\\), possiamo concludere che la probabilità più plausibile per la proporzione di acqua sul globo è circa 67%. Inoltre, se la distribuzione a posteriori è stretta, possiamo essere più sicuri di questa stima, mentre se è più ampia, la nostra incertezza sarà maggiore.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#influenza-delle-distribuzioni-a-priori",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#influenza-delle-distribuzioni-a-priori",
    "title": "39  La quantificazione dell’incertezza",
    "section": "39.12 Influenza delle Distribuzioni a Priori",
    "text": "39.12 Influenza delle Distribuzioni a Priori\nIn questo esempio, abbiamo utilizzato una distribuzione a priori uniforme, che esprime una totale mancanza di conoscenza iniziale su \\(\\theta\\). Tuttavia, in contesti in cui abbiamo informazioni preesistenti, è possibile utilizzare distribuzioni a priori più informative. Ad esempio, se sappiamo da studi precedenti che circa il 70% della superficie terrestre è coperta d’acqua, possiamo utilizzare una distribuzione a priori che rifletta questa conoscenza. Questo tipo di distribuzione a priori informativa può rendere l’aggiornamento bayesiano più efficiente, portando a stime più precise con meno dati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#vantaggi-dellaggiornamento-bayesiano",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#vantaggi-dellaggiornamento-bayesiano",
    "title": "39  La quantificazione dell’incertezza",
    "section": "39.13 Vantaggi dell’Aggiornamento Bayesiano",
    "text": "39.13 Vantaggi dell’Aggiornamento Bayesiano\nUno dei principali vantaggi dell’approccio bayesiano è che ogni nuova osservazione aggiorna automaticamente le credenze preesistenti, integrando le informazioni precedenti con i nuovi dati. Questo processo consente un apprendimento iterativo e progressivo, che diventa più efficiente man mano che si accumulano dati. Inoltre, la flessibilità nella scelta della distribuzione a priori consente al ricercatore di adattare l’inferenza bayesiana al contesto specifico, migliorando ulteriormente la precisione delle stime.\nIn sintesi, il processo generatore dei dati, modellato tramite la verosimiglianza, gioca un ruolo centrale nell’aggiornamento bayesiano. Nel caso del globo, abbiamo modellato il fenomeno utilizzando una distribuzione binomiale e, attraverso l’applicazione del Teorema di Bayes, abbiamo aggiornato progressivamente le nostre credenze sulla proporzione di acqua osservata. Il risultato è una stima sempre più precisa di \\(\\theta\\), con una distribuzione a posteriori che riflette sia le osservazioni passate sia le nuove evidenze, riducendo progressivamente l’incertezza.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#riflessioni-conclusive",
    "title": "39  La quantificazione dell’incertezza",
    "section": "39.14 Riflessioni Conclusive",
    "text": "39.14 Riflessioni Conclusive\nNegli ultimi anni, i metodi bayesiani stanno acquisendo sempre più importanza nel campo dell’inferenza statistica, anche in discipline come la psicologia. Questa diffusione è favorita dall’accesso a risorse educative e a testi fondamentali, come quelli di Albert & Hu (2019), Johnson et al. (2022), McElreath (2020) e Kruschke (2014), che hanno reso la modellizzazione bayesiana più accessibile, chiarendo i concetti centrali in modo pratico e comprensibile.\nL’approccio bayesiano si distingue dalla metodologia frequentista tradizionale per la sua capacità di trattare i parametri di interesse come quantità probabilistiche. Invece di considerare i parametri come valori fissi e sconosciuti (come avviene nel paradigma frequentista), il bayesianesimo assegna ai parametri una distribuzione a priori, che rappresenta le credenze iniziali del ricercatore. Man mano che nuovi dati vengono raccolti, queste credenze vengono aggiornate tramite il teorema di Bayes, portando a una distribuzione a posteriori che riflette sia le informazioni pregresse sia l’evidenza empirica. Questa distribuzione aggiornata consente di esprimere l’incertezza sui parametri in modo più completo e informato.\nUno dei principali vantaggi dell’approccio bayesiano è la sua capacità di combinare conoscenze pregresse con nuove osservazioni in modo fluido e sistematico. Ogni nuova informazione arricchisce e raffina le stime, rendendole più accurate e interpretabili nel contesto del problema specifico. Questo non solo migliora la precisione delle inferenze, ma permette anche una migliore comprensione dell’incertezza che circonda i parametri studiati.\nIn definitiva, l’inferenza bayesiana non è solo uno strumento analitico, ma un approccio dinamico che incoraggia un’interazione continua tra teoria ed evidenza. Offrendo una flessibilità unica e una gestione esplicita dell’incertezza, il bayesianesimo si rivela un metodo potente per supportare il processo decisionale in contesti complessi, rendendo le sue applicazioni particolarmente rilevanti in campi come la psicologia, dove l’incertezza è una componente inevitabile dell’analisi dei dati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#informazioni-sullambiente-di-sviluppo",
    "title": "39  La quantificazione dell’incertezza",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.16.0       MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2\n#&gt;  [5] ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0  \n#&gt;  [9] bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0      markdown_1.13    \n#&gt; [13] knitr_1.49        lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1    \n#&gt; [17] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#&gt; [21] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [25] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1  farver_2.1.2      fastmap_1.2.0     pacman_0.5.1     \n#&gt;  [5] promises_1.3.1    rpart_4.1.23      digest_0.6.37     timechange_0.3.0 \n#&gt;  [9] mime_0.12         lifecycle_1.0.4   survival_3.7-0    magrittr_2.0.3   \n#&gt; [13] compiler_4.4.2    rlang_1.1.4       tools_4.4.2       utf8_1.2.4       \n#&gt; [17] yaml_2.3.10       ggsignif_0.6.4    htmlwidgets_1.6.4 mnormt_2.1.1     \n#&gt; [21] abind_1.4-8       miniUI_0.1.1.1    withr_3.0.2       nnet_7.3-19      \n#&gt; [25] grid_4.4.2        fansi_1.0.6       jomo_2.7-6        xtable_1.8-4     \n#&gt; [29] colorspace_2.1-1  iterators_1.0.14  cli_3.6.3         rmarkdown_2.29   \n#&gt; [33] generics_0.1.3    tzdb_0.4.0        minqa_1.2.8       splines_4.4.2    \n#&gt; [37] parallel_4.4.2    vctrs_0.6.5       boot_1.3-31       glmnet_4.1-8     \n#&gt; [41] Matrix_1.7-1      jsonlite_1.8.9    carData_3.0-5     car_3.1-3        \n#&gt; [45] hms_1.1.3         mitml_0.4-5       rstatix_0.7.2     Formula_1.2-5    \n#&gt; [49] foreach_1.5.2     glue_1.8.0        pan_1.9           nloptr_2.1.1     \n#&gt; [53] codetools_0.2-20  stringi_1.8.4     gtable_0.3.6      shape_1.4.6.1    \n#&gt; [57] later_1.4.0       lme4_1.1-35.5     munsell_0.5.1     pillar_1.9.0     \n#&gt; [61] htmltools_0.5.8.1 R6_2.5.1          rprojroot_2.0.4   evaluate_1.0.1   \n#&gt; [65] shiny_1.9.1       lattice_0.22-6    backports_1.5.0   broom_1.0.7      \n#&gt; [69] httpuv_1.6.15     Rcpp_1.0.13-1     nlme_3.1-166      xfun_0.49        \n#&gt; [73] pkgconfig_2.0.3",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#bibliografia",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#bibliografia",
    "title": "39  La quantificazione dell’incertezza",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlbert, J., & Hu, J. (2019). Probability and Bayesian Modeling. CRC Press.\n\n\nBaribault, B., & Collins, A. G. (2023). Troubleshooting Bayesian cognitive models. Psychological Methods.\n\n\nFreiesleben, T., & Molnar, C. (2024). Supervised Machine Learning for Science: How to stop worrying and love your black box. https://ml-science-book.com/\n\n\nGoligher, E. C., Heath, A., & Harhay, M. O. (2024). Bayesian statistics for clinical research. The Lancet, 404(10457), 1067–1076. https://doi.org/10.1016/S0140-6736(24)00055-9\n\n\nJaynes, E. T. (2003). Probability theory: The logic of science. Cambridge University Press.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nKruschke, J. (2014). Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan. Academic Press.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html",
    "title": "40  Inferenza bayesiana",
    "section": "",
    "text": "40.1 Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nPreparazione del Notebook\nQuesto capitolo approfondisce i concetti introdotti nel capitolo precedente, presentando l’aggiornamento bayesiano in modo più formale e dettagliato.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html#paradigma-bayesiano",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html#paradigma-bayesiano",
    "title": "40  Inferenza bayesiana",
    "section": "40.2 Paradigma Bayesiano",
    "text": "40.2 Paradigma Bayesiano\nL’approccio bayesiano alla statistica si fonda sull’idea di rappresentare la conoscenza a priori sui parametri che governano un fenomeno attraverso distribuzioni di probabilità. Queste distribuzioni a priori riflettono le credenze iniziali del ricercatore riguardo ai parametri, prima di osservare i dati. Quando nuovi dati vengono raccolti, l’informazione fornita da tali dati viene integrata nel modello tramite la funzione di verosimiglianza, che rappresenta la probabilità di osservare quei dati dati i parametri ipotizzati.\nAttraverso l’applicazione del Teorema di Bayes, le credenze a priori vengono aggiornate combinando la distribuzione a priori con la verosimiglianza dei dati. Questo processo produce la distribuzione a posteriori, che rappresenta una nuova e più informata stima dei parametri, tenendo conto sia delle credenze iniziali sia dei dati osservati.\nL’approccio bayesiano richiede un cambiamento di prospettiva rispetto ai metodi classici di stima dei parametri. Non ci si limita più a trovare un singolo valore “ottimale” per i parametri del modello. Invece, l’obiettivo è determinare l’intera distribuzione a posteriori dei parametri, che descrive in modo completo lo stato di conoscenza attuale. Solo questa distribuzione fornisce una rappresentazione adeguata dell’incertezza associata ai parametri, permettendo di quantificare non solo quali valori sono più probabili, ma anche l’ampiezza dell’incertezza su tali stime.\n\n40.2.1 Vantaggi dell’Approccio Bayesiano\nUn aspetto distintivo dell’inferenza bayesiana è la sua capacità di gestire l’incertezza in modo esplicito. Invece di limitarsi a una singola stima puntuale, l’approccio bayesiano considera l’intero spettro di valori possibili per i parametri e le loro rispettive probabilità. Questo consente una rappresentazione più ricca delle informazioni disponibili e una valutazione più robusta delle ipotesi.\nInoltre, l’approccio bayesiano è altamente flessibile, permettendo di incorporare informazioni precedenti sotto forma di distribuzioni a priori. In contesti in cui si dispone di conoscenze pregresse, come dati di studi precedenti o teorie consolidate, questa caratteristica offre un vantaggio notevole rispetto agli approcci frequentisti, che non integrano facilmente tali informazioni.\nIn conclusione, il paradigma bayesiano offre una visione più ampia e completa dell’incertezza e della variabilità dei parametri rispetto ai metodi tradizionali, rappresentando un quadro teorico e pratico fondamentale per l’inferenza statistica e la modellazione.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html#densità-di-probabilità",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html#densità-di-probabilità",
    "title": "40  Inferenza bayesiana",
    "section": "40.3 Densità di Probabilità",
    "text": "40.3 Densità di Probabilità\nNei capitoli precedenti abbiamo esaminato alcuni esempi di funzioni di densità di probabilità (PDF). Ma quali sono le caratteristiche generali di una PDF?\nSe \\(X\\) è una variabile casuale con una funzione di densità di probabilità \\(p(x)\\), la probabilità che \\(X\\) assuma un valore nell’intervallo \\((a, b)\\) può essere calcolata come:\n\\[\np(X \\in (a,b)) = \\int_a^b p(x)dx.\n\\]\nPer variabili discrete, l’integrazione si trasforma in una somma.\n\n40.3.1 Le Regole di Somma e Prodotto\nDate due variabili casuali continue \\(x\\) e \\(y\\), le regole di somma e prodotto per le densità di probabilità si esprimono come:\n\\[\n\\begin{align*}\np(y) = \\int p(x,y)dx \\quad &\\text{- regola della somma},\\\\\np(x,y) = p(y|x) p(x) = p(x|y) p(y) \\quad &\\text{- regola del prodotto}.\n\\end{align*}\n\\]\nLa probabilità \\(p(y)\\) è chiamata probabilità marginale.\nLa regola del prodotto specifica che la distribuzione congiunta di due variabili può essere espressa come il prodotto di una distribuzione condizionata \\(p(y \\mid x)\\) e una distribuzione marginale \\(p(x)\\), o viceversa.\n\n\n40.3.2 La Distribuzione Marginale\nLa distribuzione marginale si riferisce alla distribuzione di probabilità di una variabile quando si tiene conto di tutte le possibili variazioni dell’altra variabile in una distribuzione congiunta. In altre parole, essa descrive la probabilità di una variabile indipendentemente dall’altra.\nConsideriamo due variabili correlate, \\(x\\) e \\(y\\). Possiamo esprimere la relazione tra di esse con la regola del prodotto:\n\\[\np(x, y) = p(y \\mid x)p(x),\n\\]\ndove \\(p(y \\mid x)\\) è la probabilità di \\(y\\) dato un certo valore di \\(x\\), e \\(p(x)\\) è la distribuzione di probabilità di \\(x\\).\nPer ottenere la distribuzione marginale di \\(y\\), dobbiamo sommare o integrare \\(p(y \\mid x)\\) su tutti i possibili valori di \\(x\\):\n\\[\np(y) = \\int p(y \\mid x)p(x)dx.\n\\]\nIn questo modo, la distribuzione marginale di \\(y\\) rappresenta la probabilità di \\(y\\), tenendo conto di tutte le possibili variazioni di \\(x\\).\n\n\n40.3.3 Il Teorema di Bayes\nDalla regola di prodotto, e sfruttando la proprietà di simmetria \\(p(x \\mid y)p(y) = p(y \\mid x)p(x)\\), deriviamo immediatamente la regola di Bayes:\n\\[\np(y \\mid x) = \\frac{p(x \\mid y)p(y)}{p(x)} = \\frac{p(x \\mid y)p(y)}{\\int p(x \\mid y)p(y)dy}.\n\\]\nQuesta formula è l’elemento chiave nell’inferenza bayesiana, poiché definisce la densità a posteriori di \\(y\\), \\(p(y \\mid x)\\), dopo aver incorporato l’informazione \\(x\\) attraverso il modello di probabilità condizionata \\(p(x \\mid y)\\). La probabilità marginale di \\(x\\), \\(p(x)\\), funge da costante di normalizzazione, garantendo che \\(p(y \\mid x)\\) sia una corretta funzione di densità di probabilità.\n\n\n40.3.4 Modellizzazione e Inferenza Bayesiana\nLa modellizzazione bayesiana consiste nel descrivere matematicamente tutti i dati osservabili \\(y\\) e i parametri non osservabili, detti anche parametri “latenti” \\(\\theta\\), definendo la distribuzione congiunta di dati e parametri \\(p(y, \\theta)\\).\nSi costruiscono modelli probabilistici per le quantità osservate condizionate ai parametri \\(p(y \\mid \\theta)\\) e per le quantità non osservate, rappresentate dalla distribuzione a priori \\(p(\\theta)\\), che rappresenta le nostre conoscenze precedenti sui parametri. Questi due elementi vengono combinati, seguendo la regola del prodotto, per formare una distribuzione congiunta:\n\\[\np(y, \\theta) = p(y \\mid \\theta)p(\\theta).\n\\]\n\n\n40.3.5 Il Modello Osservazionale\nLa funzione\n\\[\np(y \\mid \\theta)\n\\]\nè un modello probabilistico dei dati osservati che mette in relazione \\(y\\) con i parametri sconosciuti \\(\\theta\\) che vogliamo stimare. Questo modello rappresenta l’evidenza fornita dai dati e costituisce la principale fonte di informazione. In questo contesto, viene chiamato funzione di verosimiglianza (likelihood). È importante notare che la funzione di verosimiglianza nel contesto bayesiano non è diversa da quella utilizzata nell’approccio frequentista: in entrambi i casi collega i dati osservati ai parametri sconosciuti.\n\n\n40.3.6 La Distribuzione a Priori\nLa distribuzione\n\\[\np(\\theta)\n\\]\nrappresenta la distribuzione a priori dei parametri, che codifica le conoscenze preesistenti sui parametri stessi. Questa distribuzione a priori può essere informativa o non informativa, a seconda della quantità di informazioni affidabili che si possiedono sui parametri. Uno degli aspetti principali che differenziano l’approccio bayesiano da quello frequentista è l’uso delle distribuzioni di probabilità per i parametri sconosciuti. Queste distribuzioni vengono poi combinate con la funzione di verosimiglianza per ottenere una distribuzione a posteriori, che incorpora sia le informazioni precedenti che le evidenze fornite dai nuovi dati.\n\n\n40.3.7 Inferenza sui Parametri\nOttenere la distribuzione a posteriori dei parametri sconosciuti è l’elemento centrale dell’approccio bayesiano. Riformulando la regola di Bayes in termini di \\(y\\) e \\(\\theta\\), otteniamo una formula che ci mostra come calcolare la distribuzione a posteriori:\n\\[\np(\\theta \\mid y) = \\frac{p(y \\mid \\theta)p(\\theta)}{p(y)} = \\frac{p(y \\mid \\theta)p(\\theta)}{\\int p(y \\mid \\theta)p(\\theta) d\\theta}.\n\\]\nIl denominatore della regola di Bayes,\n\\[\np(y) = \\int p(y \\mid \\theta)p(\\theta) d \\theta,\n\\]\nè chiamato verosimiglianza marginale, poiché integra la verosimiglianza rispetto all’informazione a priori sui parametri. Questa quantità è anche nota come evidenza del modello e serve a normalizzare la distribuzione a posteriori, rendendola una vera distribuzione di probabilità. L’inferenza finale sarà un compromesso tra l’evidenza fornita dai dati e l’informazione a priori disponibile.\n\n\n40.3.8 Inferenza bayesiana in sintesi: verosimiglianza, prior, posteriore\nPer riassumere, ecco tutti i componenti fondamentali dell’inferenza bayesiana.\nIl teorema di Bayes, espresso in termini di dati \\(y\\) e parametri del modello \\(\\theta\\), è\n\\[\np(\\theta \\mid y) = \\frac{p(y \\mid \\theta)p(\\theta)}{p(y)},\n\\]\ndove:\n\nIl denominatore \\(p(y)\\) è la costante di normalizzazione o evidenza.\n\\(p(\\theta)\\) rappresenta il prior, ovvero le credenze iniziali sui parametri.\n\\(p(y \\mid \\theta)\\) è la verosimiglianza, che collega i dati osservati ai parametri del modello.\n\\(p(\\theta \\mid y)\\) è la distribuzione a posteriori, che rappresenta le credenze aggiornate sui parametri dopo aver osservato i dati.\n\nLa distribuzione a posteriori riassume il nostro stato di credenza sui possibili valori di \\(\\theta\\), aggiornato sulla base delle evidenze fornite dai dati.\nSi noti che \\(p(y)\\) non dipende dai parametri \\(\\theta\\). Pertanto, in molte situazioni pratiche, è sufficiente calcolare la distribuzione a posteriori fino a una costante. Per questo motivo, spesso la regola di Bayes viene riassunta come:\n\\[p(\\theta \\mid y) \\propto p(y \\mid \\theta)p(\\theta).\\]\nIn questa forma, si ignora il denominatore poiché è una costante (indipendente da \\(\\theta\\)).\n\n\n40.3.9 Il Ruolo dei Priors\nUna delle caratteristiche distintive dell’approccio bayesiano è l’incorporazione delle conoscenze a priori riguardo ai parametri del modello. Dichiarare questi priors ci obbliga a esplicitare tutte le assunzioni che facciamo sulla struttura del modello e sui suoi parametri. Allo stesso tempo, i priors sono spesso oggetto di critica nell’inferenza bayesiana a causa della soggettività che possono introdurre.\nTuttavia, l’inferenza bayesiana offre alcuni vantaggi meno evidenti a prima vista, tra cui:\n\nla capacità di lavorare efficacemente con piccoli set di dati,\nla capacità di eseguire la regolarizzazione del modello.\n\nQuesti aspetti rendono l’approccio bayesiano particolarmente utile in situazioni in cui i dati sono scarsi o le assunzioni esplicite sul modello possono contribuire a migliorare le previsioni.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html#inferenza-predittiva",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html#inferenza-predittiva",
    "title": "40  Inferenza bayesiana",
    "section": "40.4 Inferenza Predittiva",
    "text": "40.4 Inferenza Predittiva\nLa distribuzione a posteriori dei parametri può essere utilizzata per modellare l’incertezza nelle previsioni \\(\\tilde{y}\\) relative a nuove osservazioni. La distribuzione predittiva a posteriori di \\(\\tilde{y}\\) si ottiene marginalizzando la distribuzione congiunta delle previsioni \\(\\tilde{y}\\) e dei parametri \\(\\theta\\) rispetto ai parametri del modello:\n\\[\np(\\tilde{y} \\mid y) = \\int p(\\tilde{y}, \\theta \\mid y)d \\theta = \\int p(\\tilde{y} \\mid \\theta, y)p(\\theta|y)d\\theta.\n\\]\nIn questo modo, la distribuzione predittiva può essere vista come una media delle previsioni del modello \\(p(\\tilde{y} \\mid \\theta, y)\\) ponderata sulla distribuzione a posteriori dei parametri del modello \\(p(\\theta \\mid y)\\). Questo consente di incorporare l’incertezza sui parametri nel processo di previsione, rendendo le stime più robuste.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html#come-possiamo-eseguire-linferenza-bayesiana",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html#come-possiamo-eseguire-linferenza-bayesiana",
    "title": "40  Inferenza bayesiana",
    "section": "40.5 Come possiamo eseguire l’inferenza bayesiana?",
    "text": "40.5 Come possiamo eseguire l’inferenza bayesiana?\nEsistono due approcci principali per determinare la distribuzione posteriore:\n\nApproccio Analitico (o Coniugato): Questo metodo è applicabile quando la distribuzione a priori scelta e la funzione di verosimiglianza appartengono alla stessa famiglia di distribuzioni, definite coniugate. In questi casi, la distribuzione posteriore può essere calcolata analiticamente, ovvero attraverso formule matematiche esatte. L’approccio coniugato è computazionalmente efficiente ma presenta una limitazione significativa: è applicabile solo in situazioni in cui si può assumere una coniugazione tra la distribuzione a priori e la verosimiglianza. Di conseguenza, trova un impiego limitato nelle analisi di dati reali, dove spesso le assunzioni di coniugazione risultano troppo restrittive.\nApproccio Numerico: Quando non è possibile ottenere una forma analitica chiusa per la distribuzione posteriore, a causa della complessità del modello o della mancanza di coniugazione tra la distribuzione a priori e la verosimiglianza, si ricorre a metodi numerici. Questi algoritmi consentono di ottenere una stima approssimata, ma spesso accurata, della distribuzione posteriore.\n\n\n40.5.1 Metodi Numerici\nLe catene di Markov Monte Carlo (MCMC) sono una classe di algoritmi ampiamente utilizzati in questo contesto. Essi costruiscono una catena di Markov che converge alla distribuzione posteriore desiderata. Tra i metodi MCMC più comuni troviamo:\n\nMetropolis-Hastings: Un algoritmo generale che consente di campionare da una vasta gamma di distribuzioni posteriori.\nGibbs Sampling: Un caso particolare di Metropolis-Hastings, particolarmente efficiente quando la distribuzione congiunta è difficile da campionare direttamente, ma le distribuzioni condizionali sono note.\n\nOltre alle MCMC, esistono altre tecniche numeriche:\n\nVariational Bayes: Questo approccio consiste nel trovare la distribuzione \\(q(z)\\) che meglio approssima la distribuzione posteriore \\(p(z \\mid x)\\), secondo un criterio di divergenza (ad esempio, la divergenza di Kullback-Leibler). L’obiettivo è trasformare il problema di inferenza esatta in un problema di ottimizzazione. Variational Bayes offre spesso una soluzione più veloce rispetto alle MCMC, ma l’approssimazione può essere meno accurata in alcuni casi.\nLaplace approximation: Questa tecnica consiste nell’approssimare la distribuzione posteriore con una distribuzione normale centrata sul massimo a posteriori (MAP) e con matrice di covarianza pari all’inverso della matrice di Hessiano negativa calcolata nel MAP. L’approssimazione di Laplace è computazionalmente efficiente, ma è valida solo localmente attorno al MAP e può portare a stime inaccurate della varianza posteriore.\n\nVantaggi:\n\nVersatilità: L’approccio numerico è applicabile a una vasta gamma di modelli e distribuzioni.\nFlessibilità: Consente di incorporare facilmente informazioni a priori complesse.\n\nSvantaggi:\n\nCosto computazionale: Può richiedere un tempo di calcolo considerevole, soprattutto per modelli complessi o grandi dataset.\nTuning: La scelta dei parametri degli algoritmi MCMC (ad esempio, la proposta iniziale) può influenzare la convergenza e l’efficienza del campionamento.\n\nIn sintesi, l’approccio numerico offre una soluzione generale e flessibile per l’inferenza bayesiana, ma richiede una maggiore attenzione alla scelta degli algoritmi e alla valutazione della convergenza delle catene.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html#programmazione-probabilistica",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html#programmazione-probabilistica",
    "title": "40  Inferenza bayesiana",
    "section": "40.6 Programmazione Probabilistica",
    "text": "40.6 Programmazione Probabilistica\nI linguaggi di programmazione probabilistica (PPL) rappresentano un’importante innovazione nella modellazione bayesiana, facilitando l’uso di tecniche di approssimazione numerica per stimare le distribuzioni posteriori. Grazie ai PPL, la modellizzazione probabilistica diventa più accessibile, riducendo le barriere tecniche e computazionali. Questi strumenti consentono di definire modelli in modo dichiarativo, descrivendo le relazioni tra le variabili in termini probabilistici senza doversi occupare dei dettagli algoritmici sottostanti. In altre parole, i PPL permettono ai ricercatori di concentrarsi sull’espressione del modello, lasciando ai linguaggi il compito di gestire l’implementazione computazionale.\nTra i PPL più utilizzati troviamo:\n\nStan: Uno dei linguaggi più popolari, noto per la sua efficienza e flessibilità.\nPyMC: Molto utilizzato nell’ecosistema Python, offre un’interfaccia user-friendly per la modellazione bayesiana.\nTensorFlow: Un framework che combina un approccio probabilistico con le reti neurali.\n\n\n40.6.1 Vantaggi della Programmazione Probabilistica in Psicologia\nLa programmazione probabilistica offre numerosi vantaggi per la ricerca psicologica, in particolare per l’analisi di processi complessi come l’apprendimento, le emozioni e il comportamento. Alcuni dei principali vantaggi includono:\n\nFlessibilità: I PPL, come Stan, Pyro, Numpyro, PyMC e Turing.jl, offrono un quadro flessibile per la definizione e la personalizzazione dei modelli probabilistici. In psicologia, questa flessibilità è cruciale, poiché i modelli devono adattarsi a una vasta gamma di processi mentali e comportamentali che variano tra individui e contesti.\nQuantificazione dell’Incertezza: La programmazione probabilistica permette di rappresentare esplicitamente e quantificare l’incertezza, un aspetto fondamentale in psicologia, dove molte variabili di interesse, come stati emotivi o atteggiamenti, sono latenti e soggette a incertezza. Incorporare questa incertezza nei modelli consente di ottenere stime più realistiche e affidabili.\nValidazione del Modello: I PPL facilitano la validazione dei modelli psicologici, consentendo ai ricercatori di confrontare le previsioni dei modelli con i dati osservati. Tecniche come i posterior predictive checks permettono di valutare la qualità e l’affidabilità del modello, contribuendo a una maggiore solidità delle conclusioni.\nModellazione Gerarchica: Molti studi psicologici raccolgono dati a più livelli (ad esempio, misurazioni ripetute per individuo, sessioni sperimentali, contesti diversi). I PPL semplificano la costruzione e l’analisi di modelli gerarchici, catturando la variabilità sia intra- che inter-individuale.\nSelezione e Confronto dei Modelli: In psicologia è spesso necessario confrontare modelli con strutture diverse o ipotesi alternative. I PPL permettono di confrontare le capacità predittive dei modelli in modo sistematico e rigoroso, supportando la scelta del modello più adatto basandosi sull’accuratezza predittiva e non solo sulla complessità.\nComunicazione Trasparente: La programmazione probabilistica favorisce la trasparenza nella modellizzazione. I ricercatori possono specificare chiaramente le assunzioni del modello, i prior e le funzioni di verosimiglianza, rendendo più facile la comunicazione e la collaborazione con altri esperti.\nLibrerie Estensibili: I PPL offrono librerie estese e strumenti avanzati per lo sviluppo di modelli, l’inferenza e la visualizzazione. Questo riduce il carico computazionale e di implementazione, rendendo più agevole l’analisi di dati complessi tipici della psicologia sperimentale e clinica.\n\n\n\n40.6.2 Come Funzionano i PPL?\nI linguaggi di programmazione probabilistica richiedono semplicemente la descrizione del modello probabilistico. Successivamente, utilizzano algoritmi di inferenza, come le catene di Markov Monte Carlo (MCMC) o l’inferenza variazionale, per stimare la distribuzione posteriore delle variabili di interesse. Ciò consente ai ricercatori di ottenere stime delle variabili sconosciute e di valutare l’incertezza associata.\nIn conclusione, i linguaggi di programmazione probabilistica hanno trasformato il modo in cui affrontiamo l’inferenza bayesiana, rendendola più accessibile e potente. Grazie alla loro semplicità d’uso e alla potenza computazionale, i PPL hanno reso l’inferenza bayesiana uno strumento sempre più diffuso in molte discipline, inclusa la psicologia. Questo approccio facilita la modellazione di fenomeni complessi e l’analisi rigorosa di dati, offrendo un metodo efficace per rispondere a domande di ricerca psicologica in modo trasparente e accurato.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html#notazione",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html#notazione",
    "title": "40  Inferenza bayesiana",
    "section": "40.7 Notazione",
    "text": "40.7 Notazione\nIn seguito, utilizzeremo \\(y\\) per rappresentare i dati osservati e \\(\\theta\\) per indicare i parametri sconosciuti di un modello statistico. Entrambi, \\(y\\) e \\(\\theta\\), saranno trattati come variabili casuali. Utilizzeremo \\(x\\) per denotare le quantità note, come i predittori di un modello lineare.\nÈ comune scrivere modelli statistici utilizzando la seguente notazione:\n\\[\n\\begin{aligned}\ny & \\sim \\mathrm{normal}(\\mu, \\sigma) \\\\\n\\mu & \\sim \\mathrm{normal}(0, 10) \\\\\n\\sigma & \\sim \\mathrm{normal}^+(\\sigma \\mid  0, 1),\n\\end{aligned}\n\\]\ndove il simbolo \\(\\sim\\) è chiamato tilde (\\sim in LaTeX).\nIn generale, possiamo leggere \\(\\sim\\) come “è distribuito come”, e questa notazione è usata come una scorciatoia per definire distribuzioni. L’esempio sopra può essere scritto anche come:\n\\[\n\\begin{aligned}\n   p(y \\mid \\mu, \\sigma) & = \\mathrm{normal}(y \\mid  \\mu, \\sigma)\\\\\n   p(\\mu) & = \\mathrm{normal}(\\mu \\mid 0, 10)\\\\\n   p(\\sigma) & = \\mathrm{normal}^+(\\sigma \\mid  0, 1).\n\\end{aligned}\n\\]",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html#addendum-la-verosimiglianza-marginale",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html#addendum-la-verosimiglianza-marginale",
    "title": "40  Inferenza bayesiana",
    "section": "40.8 Addendum: La Verosimiglianza Marginale",
    "text": "40.8 Addendum: La Verosimiglianza Marginale\nNella discussione precedente, abbiamo introdotto la verosimiglianza marginale \\(p(y)\\) come una costante di normalizzazione. Ma perché è così importante normalizzare la distribuzione posteriore? La verosimiglianza marginale rappresenta la probabilità dei dati osservati, integrata su tutti i possibili valori del parametro \\(\\theta\\). In altre parole, esprime la probabilità di osservare i dati senza fare riferimento a un particolare valore del parametro.\nPer comprendere intuitivamente, immagina di voler stimare la temperatura media di una stanza. Usando un termometro, ottieni una misurazione, ma sei consapevole che variabili come la posizione del termometro o l’ora del giorno potrebbero influenzare la lettura. La verosimiglianza marginale è equivalente a considerare la probabilità di ottenere una certa misurazione, prendendo in considerazione tutte queste possibili variabili.\nSenza la normalizzazione, la somma delle probabilità assegnate ai diversi valori del parametro non sarebbe uguale a 1, il che significherebbe che non avremmo una distribuzione di probabilità valida. Questo renderebbe difficile interpretare correttamente i risultati. La verosimiglianza marginale agisce come una costante di normalizzazione, garantendo che l’area sotto la curva della distribuzione posteriore sia esattamente pari a 1, come richiesto da una distribuzione di probabilità.\nLa verosimiglianza marginale si calcola integrando (o sommando, nel caso di parametri discreti) la funzione di verosimiglianza rispetto a tutti i possibili valori del parametro, pesando ciascun valore con la sua probabilità a priori.\nConsideriamo un esempio con una variabile casuale binomiale \\(Y\\), la cui funzione di massa di probabilità (PMF) \\(p(Y)\\) dipende dal parametro \\(\\theta\\). Supponiamo che \\(\\theta\\) possa assumere uno tra tre valori specifici: 0.1, 0.5 o 0.9, ciascuno con una probabilità a priori di \\(\\frac{1}{3}\\).\nSe i dati indicano \\(n = 10\\) prove e \\(k = 7\\) successi, la funzione di verosimiglianza è data da:\n\\[\np(k = 7, n = 10 \\mid \\theta) = \\binom{10}{7} \\theta^7 (1 - \\theta)^3.\n\\]\nPer calcolare la verosimiglianza marginale \\(p(k = 7, n = 10)\\), marginalizziamo su \\(\\theta\\), valutando la verosimiglianza per ciascun valore di \\(\\theta\\), moltiplicando per la probabilità a priori di ciascun \\(\\theta\\), e sommando i risultati:\n\\[\np(k = 7, n = 10) = \\sum_{i=1}^{3} p(k = 7, n = 10 \\mid \\theta_i) \\cdot p(\\theta_i).\n\\]\nSostituendo i valori di \\(\\theta\\) e le probabilità corrispondenti:\n\\[\np(k = 7, n = 10) = \\frac{1}{3} \\binom{10}{7} 0.1^7 (1 - 0.1)^3 + \\frac{1}{3} \\binom{10}{7} 0.5^7 (1 - 0.5)^3 + \\frac{1}{3} \\binom{10}{7} 0.9^7 (1 - 0.9)^3.\n\\]\nQuesto calcolo dimostra come la marginalizzazione su \\(\\theta\\) incorpori tutte le sue possibili variazioni, ottenendo una stima complessiva che tiene conto dell’incertezza su \\(\\theta\\).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html#implementazione-in-r",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html#implementazione-in-r",
    "title": "40  Inferenza bayesiana",
    "section": "40.9 Implementazione in R",
    "text": "40.9 Implementazione in R\nPer calcolare la verosimiglianza marginale in R, possiamo distinguere tra il caso discreto (in cui \\(\\theta\\) assume valori specifici) e il caso continuo (in cui \\(\\theta\\) è trattato come una variabile continua su un intervallo). Per il caso discreto, sommiamo direttamente i contributi della funzione di verosimiglianza pesati dalla probabilità a priori. Per il caso continuo, utilizziamo l’integrazione numerica.\n\n40.9.1 Caso discreto\nNel caso in cui \\(\\theta\\) assuma valori discreti, possiamo implementare il calcolo della verosimiglianza marginale sommando i prodotti della verosimiglianza \\(p(k \\mid \\theta)\\) e della probabilità a priori \\(p(\\theta)\\):\n\n# Funzione di verosimiglianza per il caso binomiale\nlikelihood_binomial &lt;- function(theta, k, n) {\n  return(choose(n, k) * (theta^k) * ((1 - theta)^(n - k)))\n}\n\n# Valori di theta e probabilità a priori\ntheta_values &lt;- c(0.1, 0.5, 0.9)\nprior &lt;- rep(1 / length(theta_values), length(theta_values)) # Prior uniforme\nk &lt;- 7\nn &lt;- 10\n\n# Calcolo della verosimiglianza marginale discreta\nmarginal_likelihood_discrete &lt;- sum(prior * sapply(theta_values, likelihood_binomial, k = k, n = n))\n\ncat(sprintf(\"Likelihood Marginale (discreta): %.4f\\n\", marginal_likelihood_discrete))\n#&gt; Likelihood Marginale (discreta): 0.0582\n\nIl risultato rappresenta la verosimiglianza marginale calcolata sommando i contributi discreti.\n\n\n40.9.2 Caso continuo\nNel caso in cui \\(\\theta\\) sia una variabile continua definita su \\([0, 1]\\), utilizziamo l’integrazione numerica per calcolare la verosimiglianza marginale. L’approccio assume una distribuzione a priori uniforme su \\([0, 1]\\) (se non diversamente specificato):\n\n# Funzione per il calcolo della verosimiglianza marginale continua\nlikelihood_binomial_continuous &lt;- function(theta, k, n) {\n  # La verosimiglianza è 0 per valori di theta fuori dall'intervallo [0, 1]\n  theta[theta &lt; 0 | theta &gt; 1] &lt;- 0\n  return(choose(n, k) * (theta^k) * ((1 - theta)^(n - k)))\n}\n\n# Parametri\nk &lt;- 7\nn &lt;- 10\n\n# Calcolo dell'integrale numerico\nmarginal_likelihood_continuous &lt;- \n  integrate(\n    function(theta) likelihood_binomial_continuous(theta, k, n), \n    lower = 0, \n    upper = 1\n  )$value\n\ncat(\n  sprintf(\n    \"Likelihood Marginale (continua): %.4f\\n\", \n    marginal_likelihood_continuous)\n)\n#&gt; Likelihood Marginale (continua): 0.0909\n\nQui l’integrazione numerica restituisce la verosimiglianza marginale considerando \\(\\theta\\) come una variabile continua.\n\n\n40.9.3 Caso continuo con prior Beta\nPer utilizzare una distribuzione a priori diversa (ad esempio, una distribuzione Beta), è necessario moltiplicare la funzione di verosimiglianza per la densità della distribuzione a priori:\n\n# Funzione prior Beta\nprior_beta &lt;- function(theta, alpha, beta) {\n  return(dbeta(theta, alpha, beta))\n}\n\n# Funzione combinata di verosimiglianza e prior\nlikelihood_with_beta_prior &lt;- function(theta, k, n, alpha_prior, beta_prior) {\n  # La verosimiglianza è 0 per valori di theta fuori dall'intervallo [0, 1]\n  valid_theta &lt;- (theta &gt;= 0 & theta &lt;= 1)\n  likelihood &lt;- ifelse(valid_theta, choose(n, k) * (theta^k) * ((1 - theta)^(n - k)), 0)\n  prior &lt;- ifelse(valid_theta, prior_beta(theta, alpha_prior, beta_prior), 0)\n  return(likelihood * prior)\n}\n\n# Parametri\nalpha_prior &lt;- 2\nbeta_prior &lt;- 2\nk &lt;- 7\nn &lt;- 10\n\n# Calcolo dell'integrale numerico con prior Beta\nmarginal_likelihood_continuous_beta &lt;- integrate(\n  function(theta) likelihood_with_beta_prior(theta, k, n, alpha_prior, beta_prior),\n  lower = 0, upper = 1\n)$value\n\ncat(sprintf(\"Likelihood Marginale con prior Beta: %.4f\\n\", marginal_likelihood_continuous_beta))\n#&gt; Likelihood Marginale con prior Beta: 0.1119\n\nIn questo caso, la distribuzione a priori Beta(2,2) dà maggiore peso ai valori centrali di \\(\\theta\\), riflettendo una conoscenza a priori che privilegia valori intermedi. Il calcolo combina la verosimiglianza e il prior per fornire una verosimiglianza marginale ponderata.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html#riflessioni-conclusive",
    "title": "40  Inferenza bayesiana",
    "section": "40.10 Riflessioni Conclusive",
    "text": "40.10 Riflessioni Conclusive\nAl cuore della ricerca scientifica c’è una domanda del tipo: “dimmi qualcosa sulla variabile \\(\\theta\\) dato che ho osservato i dati \\(D\\) e ho una certa conoscenza del meccanismo sottostante che genera i dati”. La regola di Bayes fornisce la seguente risposta:\n\\[\np(\\theta \\mid D) = \\frac{p(D \\mid\\theta) p(\\theta)}{p(D)} = \\frac{p(D \\mid \\theta) p(\\theta)}{\\int_\\theta p(D \\mid\\theta) p(\\theta) d\\theta}.\n\\]\nQuesta equazione mostra come, partendo da un modello generativo \\(p(D \\mid\\theta)\\) dei dati osservati e abbinato a una credenza a priori \\(p(\\theta)\\) su quali valori della variabile \\(\\theta\\) siano plausibili, possiamo inferire la distribuzione a posteriori \\(p(\\theta \\mid D)\\) della variabile alla luce dei dati osservati.\nLa stima MAP (Massimo A Posteriori), che corrisponde al valore di \\(\\theta\\) che massimizza la distribuzione a posteriori, rappresenta una stima puntuale del parametro:\n\\[\n\\theta^* = \\arg \\max_\\theta p(\\theta \\mid D).\n\\]\nNel caso di un prior non informativo (piatto), la stima MAP coincide con la stima di massima verosimiglianza, ovvero il valore di \\(\\theta\\) che massimizza la probabilità che il modello generi i dati osservati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html#informazioni-sullambiente-di-sviluppo",
    "title": "40  Inferenza bayesiana",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.16.0       MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2\n#&gt;  [5] ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0  \n#&gt;  [9] bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0      markdown_1.13    \n#&gt; [13] knitr_1.49        lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1    \n#&gt; [17] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#&gt; [21] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [25] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1  farver_2.1.2      fastmap_1.2.0     pacman_0.5.1     \n#&gt;  [5] promises_1.3.1    rpart_4.1.23      digest_0.6.37     timechange_0.3.0 \n#&gt;  [9] mime_0.12         lifecycle_1.0.4   survival_3.7-0    magrittr_2.0.3   \n#&gt; [13] compiler_4.4.2    rlang_1.1.4       tools_4.4.2       utf8_1.2.4       \n#&gt; [17] yaml_2.3.10       ggsignif_0.6.4    htmlwidgets_1.6.4 mnormt_2.1.1     \n#&gt; [21] abind_1.4-8       miniUI_0.1.1.1    withr_3.0.2       nnet_7.3-19      \n#&gt; [25] grid_4.4.2        fansi_1.0.6       jomo_2.7-6        xtable_1.8-4     \n#&gt; [29] colorspace_2.1-1  iterators_1.0.14  cli_3.6.3         rmarkdown_2.29   \n#&gt; [33] generics_0.1.3    tzdb_0.4.0        minqa_1.2.8       splines_4.4.2    \n#&gt; [37] parallel_4.4.2    vctrs_0.6.5       boot_1.3-31       glmnet_4.1-8     \n#&gt; [41] Matrix_1.7-1      jsonlite_1.8.9    carData_3.0-5     car_3.1-3        \n#&gt; [45] hms_1.1.3         mitml_0.4-5       rstatix_0.7.2     Formula_1.2-5    \n#&gt; [49] foreach_1.5.2     glue_1.8.0        pan_1.9           nloptr_2.1.1     \n#&gt; [53] codetools_0.2-20  stringi_1.8.4     gtable_0.3.6      shape_1.4.6.1    \n#&gt; [57] later_1.4.0       lme4_1.1-35.5     munsell_0.5.1     pillar_1.9.0     \n#&gt; [61] htmltools_0.5.8.1 R6_2.5.1          rprojroot_2.0.4   evaluate_1.0.1   \n#&gt; [65] shiny_1.9.1       lattice_0.22-6    backports_1.5.0   broom_1.0.7      \n#&gt; [69] httpuv_1.6.15     Rcpp_1.0.13-1     nlme_3.1-166      xfun_0.49        \n#&gt; [73] pkgconfig_2.0.3",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html#bibliografia",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html#bibliografia",
    "title": "40  Inferenza bayesiana",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html",
    "href": "chapters/bayesian_inference/03_subj_prop.html",
    "title": "41  Pensare ad una proporzione in termini soggettivi",
    "section": "",
    "text": "Introduzione\nPrerequisiti\nLeggere il settimo capitolo del libro di Albert & Hu (2019).\nConcetti e Competenze Chiave\nPreparazione del Notebook\nL’inferenza bayesiana è un metodo di inferenza statistica che utilizza la probabilità per aggiornare le credenze sui parametri di un modello, sulla base di nuove evidenze o dati osservati. Essa fornisce un quadro concettuale per stimare variabili sconosciute, tenendo conto dell’incertezza. Attraverso un modello che descrive le dipendenze tra variabili aleatorie, la teoria della probabilità può essere impiegata per inferire tutte le quantità sconosciute. In questo approccio, tutte le incertezze, sia nelle osservazioni che nei parametri del modello, sono trattate come distribuzioni di probabilità.\nIn sintesi, l’inferenza bayesiana è il processo di deduzione delle proprietà di una distribuzione di probabilità a partire dai dati, utilizzando il teorema di Bayes. Questo processo incorpora l’idea che la probabilità rappresenti una misura della fiducia su una previsione o un risultato.\nQuesto capitolo ha lo scopo di esplorare in dettaglio il concetto di aggiornamento bayesiano, illustrandolo con un esempio concreto in un contesto semplificato. L’obiettivo è dimostrare come le credenze preesistenti sulla probabilità di un parametro \\(\\theta\\) possano essere aggiornate attraverso l’osservazione di nuovi dati.\nIl primo passo nell’inferenza bayesiana consiste nel rappresentare le credenze iniziali, formulate prima di raccogliere i dati, tramite una distribuzione a priori. La distribuzione a priori riflette le nostre conoscenze o ipotesi preesistenti su \\(\\theta\\) e può variare in base al contesto o alle informazioni pregresse disponibili.\nUna volta ottenuti nuovi dati, il passaggio successivo è l’aggiornamento delle credenze tramite la distribuzione a posteriori. Questo aggiornamento si ottiene moltiplicando la distribuzione a priori per la verosimiglianza dei dati osservati, il che riflette quanto i dati supportino un determinato valore di \\(\\theta\\). Il prodotto di questi due termini fornisce una misura delle credenze aggiornate, che viene successivamente normalizzata per garantire che il risultato sia una distribuzione di probabilità valida (ovvero, che l’area sotto la curva sia pari a 1).\nIl capitolo si concentra sul modello binomiale. Questo modello è utilizzato per stimare una proporzione sconosciuta basata su una serie di dati binari \\(y_1, \\ldots, y_n\\), ciascuno dei quali può assumere valore 0 o 1.\nInizieremo esplorando un esempio in cui la distribuzione a priori di \\(\\theta\\) è discreta, un caso in cui i valori possibili di \\(\\theta\\) sono limitati a un insieme finito di opzioni. Successivamente, discuteremo scenari in cui la distribuzione a priori è continua, ampliando il modello per affrontare casi più complessi e realistici. Questo approccio progressivo consente di acquisire una comprensione graduale dei concetti centrali dell’inferenza bayesiana e del loro utilizzo pratico nel contesto di problemi statistici reali.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#introduzione",
    "href": "chapters/bayesian_inference/03_subj_prop.html#introduzione",
    "title": "41  Pensare ad una proporzione in termini soggettivi",
    "section": "",
    "text": "L’unica cosa rilevante è l’incertezza – il grado della nostra conoscenza e ignoranza. Il fatto che gli eventi considerati siano in qualche modo determinati, o conosciuti da altre persone, non ha alcuna importanza.\n(Bruno deFinetti)",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#verosimiglianza-binomiale",
    "href": "chapters/bayesian_inference/03_subj_prop.html#verosimiglianza-binomiale",
    "title": "41  Pensare ad una proporzione in termini soggettivi",
    "section": "41.1 Verosimiglianza Binomiale",
    "text": "41.1 Verosimiglianza Binomiale\nLa distribuzione binomiale offre un modello naturale per dati che derivano da una sequenza di \\(n\\) prove indipendenti e identicamente distribuite, dove ciascuna prova dà origine a uno dei due possibili esiti, convenzionalmente etichettati come ‘successo’ e ‘fallimento’. Grazie al fatto che le prove sono iid, i dati possono essere riassunti dal numero totale di successi nelle \\(n\\) prove, che denotiamo con \\(y\\). Il parametro \\(\\theta\\) rappresenta la proporzione di successi nella popolazione o, equivalentemente, la probabilità di successo in ciascuna prova. Il modello di campionamento binomiale è:\n\\[\np(y \\mid \\theta) = \\text{Bin}(y \\mid n, \\theta) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n-y},\n\\]\ndove nella parte sinistra dell’equazione non si indica la dipendenza da \\(n\\) perché viene considerato parte del disegno sperimentale e fissato; tutte le probabilità discusse per questo problema sono considerate condizionate su \\(n\\), cioè assumono che il numero totale di prove sia fissato e noto.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#applicazione-specifica-del-modello-binomiale",
    "href": "chapters/bayesian_inference/03_subj_prop.html#applicazione-specifica-del-modello-binomiale",
    "title": "41  Pensare ad una proporzione in termini soggettivi",
    "section": "41.2 Applicazione Specifica del Modello Binomiale",
    "text": "41.2 Applicazione Specifica del Modello Binomiale\nIn questo capitolo, esaminiamo un’applicazione specifica del modello binomiale per valutare la prestazione di un partecipante in un classico esperimento di psicologia, noto come Go/No-Go task (Shiffrin & Schneider, 1977). In questo tipo di compito, ai partecipanti viene richiesto di rispondere a determinati stimoli (prove Go) e di trattenere la risposta ad altri stimoli (prove No-Go). Ad esempio, i partecipanti possono vedere una serie di lettere presentate su uno schermo e devono premere un pulsante quando vedono qualsiasi lettera tranne una specifica lettera bersaglio (ad esempio, la lettera “X”). In questo esperimento, ogni prova rappresenta un evento di tipo bernoulliano con due possibili esiti: o il partecipante risponde correttamente o commette un errore. I ricercatori analizzano la percentuale di risposte corrette e di inibizioni, concentrandosi in particolare sulla capacità del partecipante di controllare l’impulso di rispondere durante le prove No-Go.\nConsideriamo un piccolo numero di prove No-Go di un partecipante, dove i risultati sono: 1, 0, 1, 1, 1, 0, 1, 0, 1. Qui, il valore “1” indica che il partecipante è stato in grado di inibire la risposta, mentre “0” indica che non è riuscito a farlo. L’obiettivo dell’analisi è quantificare l’incertezza nella stima di \\(\\theta\\), che rappresenta la proporzione di risposte corrette nel compito No-Go, ovvero la capacità inibitoria del partecipante.\nConsideriamo questi dati come una sequenza di 9 prove bernoulliane indipendenti. Utilizzando il modello binomiale, stimiamo la probabilità \\(\\theta\\) che il partecipante riesca a controllare il proprio impulso di rispondere durante le prove No-Go e quantifichiamo l’incertezza associata a questa stima.\n\n41.2.1 Processo di Lavoro\nMcElreath (2020) descrive il flusso lavoro bayesiano nel modo seguente.\n\nDefinire un Modello Generativo per i Dati: Un modello generativo descrive il processo attraverso il quale i dati vengono prodotti. Nel contesto del compito No-Go, consideriamo ogni prova come un processo di Bernoulli con due possibili esiti: una prestazione corretta, ovvero l’inibizione della risposta (rappresentata da 1), oppure una prestazione errata, ovvero la mancata inibizione della risposta (rappresentata da 0). Definiamo \\(\\theta\\) come la probabilità di ottenere una prestazione corretta nel compito No-Go. Il modello generativo per questi dati può essere formalizzato come:\n\\[\nX_i \\sim \\text{Bernoulli}(\\theta),\n\\]\ndove \\(i = 1, 2, \\dots, 9\\) e \\(X_i\\) assume il valore 1 in caso di prestazione corretta e 0 in caso di prestazione errata nel compito No-Go.\nDefinire uno Stimatore per il Parametro di Interesse: Uno stimatore è una regola o una formula che utilizza i dati campionari per fornire una stima del parametro di interesse. Nel nostro caso, lo stimatore di interesse è la probabilità \\(\\theta\\) di inibire correttamente la risposta durante le prove No-Go. L’obiettivo è non solo calcolare questa probabilità, ma anche quantificare l’incertezza associata alla stima di \\(\\theta\\), basandoci sui dati raccolti.\nSviluppare un Metodo Statistico per la Stima del Parametro di Interesse: Per stimare \\(\\theta\\), utilizziamo l’approccio bayesiano. In statistica bayesiana, si parte da una distribuzione a priori che rappresenta le nostre convinzioni iniziali su \\(\\theta\\), e poi si aggiorna questa distribuzione alla luce dei dati osservati per ottenere una distribuzione a posteriori. Nel contesto di un modello Bernoulli/Binomiale, una scelta comune per la distribuzione a priori è la distribuzione Beta. In questo caso, iniziamo con una distribuzione a priori non informativa, \\(\\text{Beta}(1, 1)\\), che corrisponde a una distribuzione uniforme su \\(\\theta\\).\nLa verosimiglianza dei nostri dati (6 “successi”, 3 “insuccessi”) è data dalla distribuzione binomiale:\n\\[\nL(p) = {9 \\choose 6} \\theta^{6} (1-\\theta)^{3}.\n\\]\nUtilizziamo il teorema di Bayes per combinare priori e verosimiglianza e ottenere la distribuzione a posteriori:\n\\[\n\\text{Posteriore} \\propto \\text{Verosimiglianza} \\times \\text{Priori}\n\\]\nValidazione del Modello tramite Simulazioni:\nPrima di analizzare i dati reali, eseguiamo una simulazione predittiva a priori per verificare se il modello è in grado di generare dati plausibili. Successivamente, dopo aver adattato il modello ai dati osservati, conduciamo una simulazione predittiva a posteriori per valutare la capacità del modello di riprodurre dati simili a quelli effettivamente osservati.\nAnalisi e Sintesi dei Risultati:\nInfine, analizziamo i dati reali calcolando la distribuzione a posteriori, tipicamente tramite metodi computazionali come il Monte Carlo a catene di Markov (MCMC). Riassumiamo questa distribuzione per fare inferenze su \\(\\theta\\), utilizzando statistiche descrittive come la media, la mediana e gli intervalli di credibilità.\n\nNel corso di questo capitolo, illustreremo come generare numericamente la distribuzione a posteriori, mentre nei capitoli successivi approfondiremo ulteriormente le varie fasi del flusso di lavoro proposto da McElreath (2020).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#metodo-basato-su-griglia-nellaggiornamento-bayesiano",
    "href": "chapters/bayesian_inference/03_subj_prop.html#metodo-basato-su-griglia-nellaggiornamento-bayesiano",
    "title": "41  Pensare ad una proporzione in termini soggettivi",
    "section": "41.3 Metodo Basato su Griglia nell’Aggiornamento Bayesiano",
    "text": "41.3 Metodo Basato su Griglia nell’Aggiornamento Bayesiano\nDopo aver discusso l’aggiornamento bayesiano e come permette di raffinare le nostre convinzioni preesistenti alla luce di nuove evidenze, esploreremo ora una tecnica specifica per realizzare questo aggiornamento: il metodo basato su griglia.\nIl metodo basato su griglia è un approccio semplice e intuitivo per stimare la distribuzione a posteriori, particolarmente utile quando non sono disponibili soluzioni analitiche esatte o si desidera evitare l’uso di algoritmi computazionali complessi. La procedura si articola nei seguenti passi:\n\nSelezione di un intervallo per il parametro: Basandosi sulle convinzioni a priori, si definisce un intervallo ragionevole per il parametro di interesse.\nCreazione di una griglia di punti: Su questo intervallo, si distribuiscono una serie di punti, di solito equidistanti tra loro.\nCalcolo della posteriori per ogni punto: Per ogni punto della griglia, si moltiplica la verosimiglianza per il prior corrispondente.\nNormalizzazione dei risultati: Per garantire che la somma delle probabilità sia pari a 1, si normalizzano i valori ottenuti dividendo ciascun punto per l’area totale sottesa dalla curva della distribuzione a posteriori.\n\nAttraverso questo metodo, si ottiene una rappresentazione approssimativa ma illustrativa della distribuzione a posteriori. Questo approccio offre un modo accessibile per visualizzare e comprendere il processo di aggiornamento bayesiano.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-discreta",
    "href": "chapters/bayesian_inference/03_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-discreta",
    "title": "41  Pensare ad una proporzione in termini soggettivi",
    "section": "41.4 Aggiornamento Bayesiano con una Distribuzione a Priori Discreta",
    "text": "41.4 Aggiornamento Bayesiano con una Distribuzione a Priori Discreta\n\n41.4.1 Distribuzione a priori\nQuando non disponiamo di informazioni specifiche preliminari su \\(\\theta\\), potremmo inizialmente assegnare un valore di 0.5, suggerendo una probabilità a priori uniforme tra le due alternative (la capacità di inibire la risposta e la mancanza di questa capacità in una prova del compito Go/No-Go). Tuttavia, questo valore non rappresenta adeguatamente l’intero spettro della nostra incertezza iniziale.\nPer riflettere meglio questa incertezza, utilizziamo una distribuzione a priori discreta, che assegna una probabilità distinta a ciascun valore plausibile di \\(\\theta\\). Questo approccio ci permette di quantificare le nostre convinzioni preliminari sulla distribuzione di questi valori.\nSupponiamo di considerare undici possibili valori per \\(\\theta\\), che variano da 0 a 1 con incrementi di 0.1. Possiamo attribuire a ciascun valore una probabilità a priori uguale, creando così una distribuzione uniforme, oppure scegliere una distribuzione non uniforme che meglio rifletta le nostre aspettative sui valori di \\(\\theta\\) più probabili.\nDopo aver osservato i dati — nel nostro caso, 6 successi in 9 prove — applichiamo il teorema di Bayes per trasformare la distribuzione a priori in una distribuzione a posteriori. Questo processo consiste nel combinare la probabilità a priori di \\(\\theta\\) con la verosimiglianza dei dati per produrre una probabilità a posteriori aggiornata per \\(\\theta\\).\n\n\n41.4.2 Distribuzione a Posteriori in R\nLa distribuzione a posteriori combina le informazioni a priori con i dati osservati, aggiornando le nostre credenze riguardo al parametro \\(\\theta\\). Vediamo passo passo come implementare il calcolo della distribuzione a posteriori e delle relative quantità in R, partendo dalla rappresentazione discreta di \\(\\theta\\).\n\n41.4.2.1 1. Definizione di \\(\\theta\\)\nIniziamo definendo un insieme discreto di valori per \\(\\theta\\).\n\ntheta &lt;- seq(0, 1, by = 0.1)\ntheta\n#&gt;  [1] 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0\n\n\n\n41.4.2.2 2. Distribuzione a Priori Uniforme\nSe non abbiamo motivi per preferire alcuni valori di \\(\\theta\\), assegniamo probabilità uguali a tutti i valori. Standardizziamo la distribuzione affinché le probabilità si sommino a 1.\n\nunif_prior &lt;- rep(1 / length(theta), length(theta))\nprint(unif_prior)\n#&gt;  [1] 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n#&gt;  [7] 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n\n\nsum(unif_prior) # Verifica che le probabilità sommino a 1\n#&gt; [1] 1\n\nVisualizziamo questa distribuzione a priori uniforme:\n\nplot(\n  theta, \n  unif_prior, \n  type = \"h\", \n  lwd = 2, \n  main = \"Distribuzione a Priori (Uniforme)\",\n  xlab = expression(theta), \n  ylab = \"Probabilità\"\n)\n\n\n\n\n\n\n\n\n\n\n41.4.2.3 3. Distribuzione a Priori Non Uniforme\nSe riteniamo più probabili i valori centrali di \\(\\theta\\), definiamo una distribuzione a priori discreta non uniforme:\n\nnot_unif_prior &lt;- \n  c(0, 0.05, 0.05, 0.05, 0.175, 0.175, 0.175, 0.175, 0.05, 0.05, 0.05)\nplot(\n  theta, \n  not_unif_prior, \n  type = \"h\", \n  lwd = 2, \n  main = \"Distribuzione a Priori (Non Uniforme)\",\n  xlab = expression(theta), \n  ylab = \"Probabilità\"\n)\n\n\n\n\n\n\n\n\n\n\n41.4.2.4 4. Calcolo della Verosimiglianza\nLa funzione di verosimiglianza per il modello binomiale è definita come segue:\n\nlikelihood &lt;- dbinom(6, size = 9, prob = theta)\n\n\nlikelihood &lt;- likelihood / sum(likelihood) # Normalizzazione\n\n\nplot(\n  theta, \n  likelihood, \n  type = \"h\",\n  lwd = 2, \n  main = \"Funzione di Verosimiglianza\",\n  xlab = expression(theta), \n  ylab = expression(L(theta))\n)\n\n\n\n\n\n\n\n\n\n\n41.4.2.5 5. Distribuzione a Posteriori\nLa distribuzione a posteriori si calcola moltiplicando elemento per elemento la distribuzione a priori e la verosimiglianza, quindi dividendo per la probabilità marginale dei dati (normalizzazione).\n\npost &lt;- (not_unif_prior * likelihood) / sum(not_unif_prior * likelihood)\nprint(post)\n#&gt;  [1] 0.000000e+00 2.118359e-05 9.521865e-04 7.265973e-03 8.998163e-02\n#&gt;  [6] 1.986416e-01 3.036880e-01 3.230667e-01 6.093994e-02 1.544284e-02\n#&gt; [11] 0.000000e+00\n\n\nsum(post) # Verifica che sommi a 1\n#&gt; [1] 1\n\nVisualizziamo la distribuzione a posteriori:\n\nplot(\n  theta, \n  post, \n  type = \"h\", \n  lwd = 2, \n  main = \"Distribuzione a Posteriori\",\n  xlab = expression(theta), \n  ylab = expression(f(theta))\n)\n\n\n\n\n\n\n\n\n\n\n41.4.2.6 6. Quantità a Posteriori\n\nMedia a Posteriori: Calcolata come il valore atteso di \\(\\theta\\) sotto la distribuzione a posteriori.\n\n\nposterior_mean &lt;- sum(theta * post)\nposterior_mean\n#&gt; [1] 0.6086958\n\n\nVarianza a Posteriori: Calcolata come la varianza della distribuzione a posteriori.\n\n\nposterior_variance &lt;- sum((theta^2) * post) - posterior_mean^2\nposterior_variance\n#&gt; [1] 0.01337977\n\n\nModa a Posteriori: Il valore di \\(\\theta\\) con la probabilità più alta.\n\n\nposterior_mode &lt;- theta[which.max(post)]\nposterior_mode\n#&gt; [1] 0.7\n\nIn sintesi, abbiamo calcolato la distribuzione a posteriori di \\(\\theta\\) utilizzando una distribuzione a priori discreta non uniforme e osservando 6 successi su 9 prove. Abbiamo derivato quantità statistiche come media, varianza e moda a posteriori. Questo processo dimostra come l’inferenza bayesiana aggiorni le credenze a priori in base ai dati osservati, offrendo una visione quantitativamente informata del parametro \\(\\theta\\).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-continua-in-r",
    "href": "chapters/bayesian_inference/03_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-continua-in-r",
    "title": "41  Pensare ad una proporzione in termini soggettivi",
    "section": "41.5 Aggiornamento Bayesiano con una Distribuzione a Priori Continua in R",
    "text": "41.5 Aggiornamento Bayesiano con una Distribuzione a Priori Continua in R\nPassiamo ora all’aggiornamento bayesiano utilizzando una distribuzione a priori continua, in particolare la distribuzione Beta. Questo approccio è particolarmente utile poiché consente di rappresentare \\(\\theta\\) come una variabile continua definita nell’intervallo [0, 1].\n\n41.5.1 Definizione della Distribuzione Beta\nIniziamo con una distribuzione Beta simmetrica, Beta(2, 2), e calcoliamo la sua densità di probabilità su un intervallo continuo di valori \\(\\theta\\).\n\n# Parametri della distribuzione Beta\nalpha &lt;- 2\nbeta &lt;- 2\n\n# Valori di theta\ntheta &lt;- seq(0, 1, length.out = 1000)\n\n# Densità di probabilità della distribuzione Beta\npdf &lt;- dbeta(theta, alpha, beta)\n\n# Grafico della distribuzione Beta\nplot(theta, pdf, type = \"l\", col = \"blue\", lwd = 2,\n     main = \"Funzione di Densità di Probabilità Beta(2, 2)\",\n     xlab = expression(theta), ylab = \"Densità\")\n\n\n\n\n\n\n\n\n\n\n41.5.2 Distribuzione a Priori Non Simmetrica\nConsideriamo una distribuzione a priori non simmetrica, Beta(2, 5), per rappresentare credenze che privilegiano valori bassi di \\(\\theta\\).\n\n# Parametri della distribuzione Beta non simmetrica\nalpha &lt;- 2\nbeta &lt;- 5\n\n# Densità di probabilità\npdf &lt;- dbeta(theta, alpha, beta)\n\n# Grafico della distribuzione Beta(2, 5)\nplot(theta, pdf, type = \"l\", col = \"red\", lwd = 2,\n     main = \"Funzione di Densità di Probabilità Beta(2, 5)\",\n     xlab = expression(theta), ylab = \"Densità\")\n\n\n\n\n\n\n\n\n\n\n41.5.3 Verosimiglianza\nConsideriamo un esperimento con 9 prove e 6 successi, modellato con una distribuzione binomiale. Calcoliamo la funzione di verosimiglianza normalizzata.\n\n# Parametri dell'esperimento\nn &lt;- 9\nk &lt;- 6\n\n# Calcolo della verosimiglianza\nlikelihood &lt;- dbinom(k, size = n, prob = theta)\nlikelihood &lt;- likelihood / sum(likelihood) # Normalizzazione\n\n# Grafico della verosimiglianza\nplot(theta, likelihood, type = \"l\", col = \"green\", lwd = 2,\n     main = \"Funzione di Verosimiglianza\",\n     xlab = expression(theta), ylab = \"Densità\")\n\n\n\n\n\n\n\n\n\n\n41.5.4 Distribuzione a Posteriori\nLa distribuzione a posteriori si ottiene moltiplicando la distribuzione a priori per la verosimiglianza e normalizzando il risultato.\n\n# Calcolo della distribuzione a priori Beta(2, 5)\nprior &lt;- dbeta(theta, shape1 = 2, shape2 = 5)\nprior &lt;- prior / sum(prior)\n\n# Calcolo della distribuzione a posteriori\nposterior &lt;- (prior * likelihood) / sum(prior * likelihood)\n\n\n# Grafico delle distribuzioni\nplot(theta, prior, type = \"l\", col = \"red\", lwd = 2, ylim = c(0, max(posterior)),\n     main = \"Distribuzioni Bayesiane\",\n     xlab = expression(theta), ylab = \"Densità\")\nlines(theta, likelihood, col = \"green\", lwd = 2)\nlines(theta, posterior, col = \"purple\", lwd = 2)\nlegend(\"topright\", legend = c(\"Prior\", \"Likelihood\", \"Posterior\"),\n       col = c(\"red\", \"green\", \"purple\"), lwd = 2)\n\n\n\n\n\n\n\n\n\n\n41.5.5 Quantità a Posteriori\nCalcoliamo alcune quantità riassuntive dalla distribuzione a posteriori.\n\nMedia a Posteriori\n\n\nposterior_mean &lt;- sum(theta * posterior)\nposterior_mean\n#&gt; [1] 0.5\n\n\nDeviazione Standard a Posteriori\n\n\nposterior_sd &lt;- sqrt(sum((theta^2) * posterior) - posterior_mean^2)\nposterior_sd\n#&gt; [1] 0.1212678\n\n\nModa a Posteriori\n\n\nposterior_mode &lt;- theta[which.max(posterior)]\nposterior_mode\n#&gt; [1] 0.5005005\n\n\n\n41.5.6 Campionamento dalla Distribuzione a Posteriori\nPossiamo generare campioni casuali dalla distribuzione a posteriori per effettuare inferenze.\n\n# Campionamento casuale\nset.seed(123)\nsamples &lt;- sample(theta, size = 10000, prob = posterior, replace = TRUE)\n\n# Grafico dei campioni\nhist(samples, breaks = 50, col = \"purple\", probability = TRUE,\n     main = \"Distribuzione dei Campioni dalla Posteriori\",\n     xlab = expression(theta))\nlines(density(samples), col = \"blue\", lwd = 2)\n\n\n\n\n\n\n\n\n\n41.5.6.1 Intervalli di Credibilità\nCalcoliamo l’intervallo di credibilità al 94%.\n\ncredible_interval &lt;- quantile(samples, probs = c(0.03, 0.97))\ncredible_interval\n#&gt;        3%       97% \n#&gt; 0.2742442 0.7277277\n\nSe desideriamo calcolare l’intervallo di densità più alta (HPDI), possiamo utilizzare pacchetti aggiuntivi come HDInterval.\n\n# Calcolo HPDI (richiede il pacchetto HDInterval)\nhdi(samples, credMass = 0.94)\n#&gt;     lower     upper \n#&gt; 0.2712713 0.7237237 \n#&gt; attr(,\"credMass\")\n#&gt; [1] 0.94\n\nIn sintesi, questo approccio dimostra l’applicazione del metodo bayesiano con distribuzioni a priori continue, utilizzando sia formule analitiche che campionamento. I risultati mostrano come possiamo ottenere credenze aggiornate su \\(\\theta\\) e riassumerle con quantità come media, moda e intervalli di credibilità.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#metodo-basato-su-griglia",
    "href": "chapters/bayesian_inference/03_subj_prop.html#metodo-basato-su-griglia",
    "title": "41  Pensare ad una proporzione in termini soggettivi",
    "section": "41.6 Metodo basato su griglia",
    "text": "41.6 Metodo basato su griglia\nIl metodo utilizzato in questo capitolo per generare la distribuzione a posteriori è noto come metodo basato su griglia. Questo metodo numerico esatto si basa sul calcolo della distribuzione a posteriori mediante una griglia di punti uniformemente spaziati. Nonostante la maggior parte dei parametri sia continua, l’approssimazione della distribuzione a posteriori può essere ottenuta considerando soltanto una griglia finita di valori dei parametri. Il metodo segue quattro fasi:\n\nFissare una griglia discreta di possibili valori dei parametri.\nValutare la distribuzione a priori e la funzione di verosimiglianza per ciascun valore della griglia.\nCalcolare l’approssimazione della densità a posteriori, ottenuta moltiplicando la distribuzione a priori per la funzione di verosimiglianza per ciascun valore della griglia e normalizzando i prodotti in modo che la loro somma sia uguale a 1.\nSelezionare \\(n\\) valori casuali dalla griglia per ottenere un campione casuale della densità a posteriori normalizzata.\n\nQuesto metodo può essere potenziato aumentando il numero di punti nella griglia, ma il limite principale risiede nel fatto che all’aumentare della dimensionalità dello spazio dei parametri, il numero di punti necessari per una stima accurata cresce in modo esponenziale, rendendo il metodo impraticabile per problemi complessi.\nIn sintesi, l’approccio basato sulla griglia è intuitivo e non richiede competenze di programmazione avanzate per l’implementazione. Inoltre, fornisce un risultato che può essere considerato, per tutti gli scopi pratici, come un campione casuale estratto dalla distribuzione di probabilità a posteriori condizionata ai dati. Tuttavia, questo metodo è limitato a causa della maledizione della dimensionalità1, il che significa che può essere applicato soltanto a modelli statistici semplici con non più di due parametri. Di conseguenza, in pratica, è spesso sostituito da altre tecniche più efficienti, poiché i modelli impiegati in psicologia richiedono frequentemente la stima di centinaia o anche migliaia di parametri.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/03_subj_prop.html#riflessioni-conclusive",
    "title": "41  Pensare ad una proporzione in termini soggettivi",
    "section": "41.7 Riflessioni Conclusive",
    "text": "41.7 Riflessioni Conclusive\nIn questo capitolo, abbiamo esplorato l’aggiornamento bayesiano utilizzando una distribuzione a priori discreta, accennando brevemente al caso delle distribuzioni a priori continue. Quando si affrontano scenari con distribuzioni a priori continue, l’elaborazione della distribuzione a posteriori generalmente richiede la risoluzione di un integrale che, nella maggior parte dei casi, non ammette una soluzione analitica. Tuttavia, ci sono eccezioni notevoli, come nell’inferenza relativa alle proporzioni, dove la distribuzione a priori è modellata come una distribuzione Beta e la funzione di verosimiglianza segue una distribuzione binomiale. In queste circostanze particolari, è possibile derivare analiticamente la distribuzione a posteriori. L’analisi dettagliata di questo caso sarà trattata nel capitolo successivo.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#esercizi",
    "href": "chapters/bayesian_inference/03_subj_prop.html#esercizi",
    "title": "41  Pensare ad una proporzione in termini soggettivi",
    "section": "41.8 Esercizi",
    "text": "41.8 Esercizi\n\nEsercizio 41.1 Viene chieso di calcolare la distribuzione a posteriori della probabilità che uno studio condivida i materiali di ricerca utilizzando il metodo basato su griglia. Si utilizzeranno dati reali per motivare e costruire una distribuzione a priori discretizzata.\nIn uno studio sull’analisi delle pratiche di trasparenza e riproducibilità nella ricerca in psicologia, Hardwicke et al. (2022) hanno riportato che la condivisione dei materiali di ricerca è stata rilevata nel 14% dei casi (26 su 183 studi), con un intervallo di confidenza al 95% pari a [10%, 19%]. Questo suggerisce che la condivisione di materiali è rara.\nIspirandoti ai risultati di questo studio, costruisci una distribuzione a priori per la probabilità \\(\\theta\\) che uno studio condivida i materiali di ricerca. Per semplicità, discretizza \\(\\theta\\) in 10 livelli equispaziati: \\(0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95\\).\nAttribuisci le seguenti probabilità a priori ai 10 livelli, basandoti sull’informazione che la condivisione dei materiali è un evento raro ma non trascurabile: \\(0.05, 0.20, 0.30, 0.15, 0.10, 0.08, 0.05, 0.03, 0.02, 0.02\\).\nSupponiamo che siano stati osservati 20 studi su 100 che hanno condiviso i materiali di ricerca. Calcola la distribuzione a posteriori utilizzando il metodo basato su griglia. Calcola la media della distribuzione a posteriori e l’intervallo di credibilità al 89%.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/03_subj_prop.html#informazioni-sullambiente-di-sviluppo",
    "title": "41  Pensare ad una proporzione in termini soggettivi",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] HDInterval_0.2.4  mice_3.16.0       MASS_7.3-61       viridis_0.6.5    \n#&gt;  [5] viridisLite_0.4.2 ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3    \n#&gt;  [9] patchwork_1.3.0   bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0     \n#&gt; [13] markdown_1.13     knitr_1.49        lubridate_1.9.3   forcats_1.0.0    \n#&gt; [17] stringr_1.5.1     dplyr_1.1.4       purrr_1.0.2       readr_2.1.5      \n#&gt; [21] tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0  \n#&gt; [25] rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1  farver_2.1.2      fastmap_1.2.0     pacman_0.5.1     \n#&gt;  [5] promises_1.3.1    rpart_4.1.23      digest_0.6.37     timechange_0.3.0 \n#&gt;  [9] mime_0.12         lifecycle_1.0.4   survival_3.7-0    magrittr_2.0.3   \n#&gt; [13] compiler_4.4.2    rlang_1.1.4       tools_4.4.2       utf8_1.2.4       \n#&gt; [17] yaml_2.3.10       ggsignif_0.6.4    htmlwidgets_1.6.4 mnormt_2.1.1     \n#&gt; [21] abind_1.4-8       miniUI_0.1.1.1    withr_3.0.2       nnet_7.3-19      \n#&gt; [25] grid_4.4.2        fansi_1.0.6       jomo_2.7-6        xtable_1.8-4     \n#&gt; [29] colorspace_2.1-1  iterators_1.0.14  cli_3.6.3         rmarkdown_2.29   \n#&gt; [33] generics_0.1.3    tzdb_0.4.0        minqa_1.2.8       splines_4.4.2    \n#&gt; [37] parallel_4.4.2    vctrs_0.6.5       boot_1.3-31       glmnet_4.1-8     \n#&gt; [41] Matrix_1.7-1      jsonlite_1.8.9    carData_3.0-5     car_3.1-3        \n#&gt; [45] hms_1.1.3         mitml_0.4-5       rstatix_0.7.2     Formula_1.2-5    \n#&gt; [49] foreach_1.5.2     glue_1.8.0        pan_1.9           nloptr_2.1.1     \n#&gt; [53] codetools_0.2-20  stringi_1.8.4     gtable_0.3.6      shape_1.4.6.1    \n#&gt; [57] later_1.4.0       lme4_1.1-35.5     munsell_0.5.1     pillar_1.9.0     \n#&gt; [61] htmltools_0.5.8.1 R6_2.5.1          rprojroot_2.0.4   evaluate_1.0.1   \n#&gt; [65] shiny_1.9.1       lattice_0.22-6    backports_1.5.0   broom_1.0.7      \n#&gt; [69] httpuv_1.6.15     Rcpp_1.0.13-1     nlme_3.1-166      xfun_0.49        \n#&gt; [73] pkgconfig_2.0.3",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#bibliografia",
    "href": "chapters/bayesian_inference/03_subj_prop.html#bibliografia",
    "title": "41  Pensare ad una proporzione in termini soggettivi",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlbert, J., & Hu, J. (2019). Probability and Bayesian Modeling. CRC Press.\n\n\nHardwicke, T. E., Thibault, R. T., Kosie, J. E., Wallach, J. D., Kidwell, M. C., & Ioannidis, J. P. (2022). Estimating the prevalence of transparency and reproducibility-related research practices in psychology (2014–2017). Perspectives on Psychological Science, 17(1), 239–251.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nShiffrin, R. M., & Schneider, W. (1977). Controlled and automatic human information processing: II. Perceptual learning, automatic attending and a general theory. Psychological Review, 84(2), 127–190.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#footnotes",
    "href": "chapters/bayesian_inference/03_subj_prop.html#footnotes",
    "title": "41  Pensare ad una proporzione in termini soggettivi",
    "section": "",
    "text": "Per comprendere la maledizione della dimensionalità, possiamo considerare l’esempio di una griglia di 100 punti equispaziati. Nel caso di un solo parametro, sarebbe necessario calcolare solo 100 valori. Tuttavia, se abbiamo due parametri, il numero di valori da calcolare diventa \\(100^2\\). Se invece abbiamo 10 parametri, il numero di valori da calcolare sarebbe di \\(10^{10}\\). È evidente che la quantità di calcoli richiesta diventa troppo grande persino per un computer molto potente. Pertanto, per modelli che richiedono la stima di un numero significativo di parametri, è necessario utilizzare un approccio diverso.↩︎",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_grid_gauss.html",
    "href": "chapters/bayesian_inference/04_grid_gauss.html",
    "title": "42  Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "",
    "text": "42.1 Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nPreparazione del Notebook\nIn questo capitolo, estenderemo la discussione precedente sul calcolo della distribuzione a posteriori utilizzando il metodo basato su griglia, applicandolo questa volta a un caso con verosimiglianza gaussiana. In particolare, ci concentreremo su come costruire un modello gaussiano per descrivere l’intelligenza.\nImmaginiamo di condurre uno studio sulla plusdotazione, considerando l’approccio psicometrico. Secondo questo approccio, una persona è considerata plusdotata se ha un QI (Quoziente Intellettivo) di 130 o superiore (Robinson, Zigler, & Gallagher, 2000). Anche se l’uso di un QI di 130 come soglia è il criterio più comune, non è universalmente accettato. L’intelligenza nei bambini plusdotati non è solo superiore rispetto a quella dei loro pari, ma è qualitativamente diversa (Lubart & Zenasni, 2010). I bambini plusdotati tendono a mostrare caratteristiche come un vocabolario ampio, un linguaggio molto sviluppato, processi di ragionamento avanzati, eccellente memoria, vasti interessi, forte curiosità, empatia, capacità di leadership, abilità visive elevate, impegno in situazioni sfidanti e un forte senso di giustizia (Song & Porath, 2005).\nNella simulazione che seguirà, assumeremo che i dati provengano da una distribuzione normale. Per semplicità, considereremo che la deviazione standard sia nota e pari a 5. Il parametro della media sarà l’oggetto della nostra inferenza.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_grid_gauss.html#dati",
    "href": "chapters/bayesian_inference/04_grid_gauss.html#dati",
    "title": "42  Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "42.2 Dati",
    "text": "42.2 Dati\nSupponiamo di avere un campione di 10 osservazioni. I dati saranno generati casualmente da una distribuzione normale con media 130 e deviazione standard 5.\n\nset.seed(123) # Per la riproducibilità\nvera_media &lt;- 130 # Media vera\nsigma_conosciuta &lt;- 5 # Deviazione standard conosciuta\ndimensione_campione &lt;- 10 # Dimensione del campione\n\n# Generare un campione\ncampione &lt;- round(rnorm(n = dimensione_campione, mean = vera_media, sd = sigma_conosciuta))\ncampione\n#&gt;  [1] 127 129 138 130 131 139 132 124 127 128",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_grid_gauss.html#griglia",
    "href": "chapters/bayesian_inference/04_grid_gauss.html#griglia",
    "title": "42  Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "42.3 Griglia",
    "text": "42.3 Griglia\nCreiamo ora una griglia di 100 valori compresi tra 110 e 150.\n\nmu_griglia &lt;- seq(110, 150, length.out = 100)\nmu_griglia\n#&gt;   [1] 110.0000 110.4040 110.8081 111.2121 111.6162 112.0202 112.4242 112.8283\n#&gt;   [9] 113.2323 113.6364 114.0404 114.4444 114.8485 115.2525 115.6566 116.0606\n#&gt;  [17] 116.4646 116.8687 117.2727 117.6768 118.0808 118.4848 118.8889 119.2929\n#&gt;  [25] 119.6970 120.1010 120.5051 120.9091 121.3131 121.7172 122.1212 122.5253\n#&gt;  [33] 122.9293 123.3333 123.7374 124.1414 124.5455 124.9495 125.3535 125.7576\n#&gt;  [41] 126.1616 126.5657 126.9697 127.3737 127.7778 128.1818 128.5859 128.9899\n#&gt;  [49] 129.3939 129.7980 130.2020 130.6061 131.0101 131.4141 131.8182 132.2222\n#&gt;  [57] 132.6263 133.0303 133.4343 133.8384 134.2424 134.6465 135.0505 135.4545\n#&gt;  [65] 135.8586 136.2626 136.6667 137.0707 137.4747 137.8788 138.2828 138.6869\n#&gt;  [73] 139.0909 139.4949 139.8990 140.3030 140.7071 141.1111 141.5152 141.9192\n#&gt;  [81] 142.3232 142.7273 143.1313 143.5354 143.9394 144.3434 144.7475 145.1515\n#&gt;  [89] 145.5556 145.9596 146.3636 146.7677 147.1717 147.5758 147.9798 148.3838\n#&gt;  [97] 148.7879 149.1919 149.5960 150.0000",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_grid_gauss.html#calcolo-della-verosimiglianza",
    "href": "chapters/bayesian_inference/04_grid_gauss.html#calcolo-della-verosimiglianza",
    "title": "42  Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "42.4 Calcolo della Verosimiglianza",
    "text": "42.4 Calcolo della Verosimiglianza\nPer ogni valore della griglia, calcoliamo la verosimiglianza complessiva come prodotto delle densità di probabilità.\n\nlikelihood &lt;- sapply(mu_griglia, function(mu) {\n    prod(dnorm(campione, mean = mu, sd = sigma_conosciuta))\n})\nlikelihood\n#&gt;   [1] 5.288265e-50 1.406074e-48 3.502225e-47 8.171857e-46 1.786234e-44\n#&gt;   [6] 3.657602e-43 7.016097e-42 1.260769e-40 2.122346e-39 3.346861e-38\n#&gt;  [11] 4.944244e-37 6.842315e-36 8.870476e-35 1.077288e-33 1.225624e-32\n#&gt;  [16] 1.306242e-31 1.304159e-30 1.219772e-29 1.068728e-28 8.771964e-28\n#&gt;  [21] 6.744771e-27 4.858233e-26 3.278161e-25 2.072159e-24 1.227034e-23\n#&gt;  [26] 6.806612e-23 3.537091e-22 1.721877e-21 7.852337e-21 3.354568e-20\n#&gt;  [31] 1.342502e-19 5.033084e-19 1.767641e-18 5.815606e-18 1.792407e-17\n#&gt;  [36] 5.175103e-17 1.399724e-16 3.546552e-16 8.418043e-16 1.871789e-15\n#&gt;  [41] 3.898910e-15 7.608000e-15 1.390716e-14 2.381483e-14 3.820297e-14\n#&gt;  [46] 5.741000e-14 8.082000e-14 1.065837e-13 1.316752e-13 1.523904e-13\n#&gt;  [51] 1.652160e-13 1.677982e-13 1.596480e-13 1.422920e-13 1.188059e-13\n#&gt;  [56] 9.292587e-14 6.808884e-14 4.673649e-14 3.005225e-14 1.810251e-14\n#&gt;  [61] 1.021507e-14 5.399888e-15 2.674046e-15 1.240492e-15 5.390880e-16\n#&gt;  [66] 2.194655e-16 8.369771e-17 2.990211e-17 1.000762e-17 3.137622e-18\n#&gt;  [71] 9.215336e-19 2.535494e-19 6.535139e-20 1.577930e-20 3.569124e-21\n#&gt;  [76] 7.562690e-22 1.501176e-22 2.791438e-23 4.862561e-24 7.934926e-25\n#&gt;  [81] 1.213002e-25 1.737085e-26 2.330351e-27 2.928616e-28 3.447817e-29\n#&gt;  [86] 3.802480e-30 3.928533e-31 3.802198e-32 3.447306e-33 2.927964e-34\n#&gt;  [91] 2.329659e-35 1.736441e-36 1.212462e-37 7.930807e-39 4.859676e-40\n#&gt;  [96] 2.789575e-41 1.500063e-42 7.556522e-44 3.565949e-45 1.576410e-46",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_grid_gauss.html#calcolo-della-distribuzione-a-posteriori",
    "href": "chapters/bayesian_inference/04_grid_gauss.html#calcolo-della-distribuzione-a-posteriori",
    "title": "42  Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "42.5 Calcolo della Distribuzione a Posteriori",
    "text": "42.5 Calcolo della Distribuzione a Posteriori\nImpostiamo una prior uniforme e calcoliamo la distribuzione a posteriori normalizzata.\n\nprior &lt;- rep(1, length(mu_griglia)) # Prior uniforme\nposterior_non_norm &lt;- likelihood * prior\nposterior &lt;- posterior_non_norm / sum(posterior_non_norm) # Normalizzazione\n\nVisualizzazione:\n\nplot(mu_griglia, posterior,\n    type = \"l\", main = \"Distribuzione a Posteriori della Media\",\n    xlab = \"Media\", ylab = \"Probabilità\"\n)\n\n\n\n\n\n\n\n\n\n42.5.1 Aggiunta di una Prior Informativa\nUsiamo una prior gaussiana con media 140 e deviazione standard 3.\n\nprior &lt;- dnorm(mu_griglia, mean = 140, sd = 3)\n\nposterior_non_norm &lt;- likelihood * prior\nposterior &lt;- posterior_non_norm / sum(posterior_non_norm)\n\n# Grafico\nplot(mu_griglia, posterior,\n    type = \"l\", col = \"blue\", lwd = 2,\n    main = \"Distribuzione a Posteriori e Prior della Media\",\n    xlab = \"Media\", ylab = \"Densità\"\n)\nlines(mu_griglia, prior / sum(prior), col = \"red\", lty = 2)\nlegend(\"topright\", legend = c(\"Posterior\", \"Prior\"), col = c(\"blue\", \"red\"), lty = c(1, 2))",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_grid_gauss.html#campionamento-dalla-posterior",
    "href": "chapters/bayesian_inference/04_grid_gauss.html#campionamento-dalla-posterior",
    "title": "42  Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "42.6 Campionamento dalla Posterior",
    "text": "42.6 Campionamento dalla Posterior\nGeneriamo un campione dalla distribuzione a posteriori.\n\nset.seed(123)\nindice_campionato &lt;- sample(1:length(mu_griglia), size = 1000, replace = TRUE, prob = posterior)\nmedia_campionata &lt;- mu_griglia[indice_campionato]\n\n# Istogramma dei campioni\nhist(media_campionata,\n    main = \"Campionamento dalla Posterior\", xlab = \"Media\",\n    breaks = 20, col = \"lightblue\", border = \"white\"\n)\n\n# Media e intervallo di credibilità\nmean(media_campionata)\n#&gt; [1] 132.5737\nquantile(media_campionata, c(0.03, 0.97))\n#&gt;       3%      97% \n#&gt; 130.2020 135.4545",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_grid_gauss.html#calcolo-della-log-verosimiglianza",
    "href": "chapters/bayesian_inference/04_grid_gauss.html#calcolo-della-log-verosimiglianza",
    "title": "42  Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "42.7 Calcolo della Log-Verosimiglianza",
    "text": "42.7 Calcolo della Log-Verosimiglianza\nUtilizziamo i logaritmi per migliorare la stabilità numerica.\n\nlog_likelihood &lt;- sapply(mu_griglia, function(mu) {\n    sum(dnorm(campione, mean = mu, sd = sigma_conosciuta, log = TRUE))\n})\n\nlog_prior &lt;- dnorm(mu_griglia, mean = 140, sd = 3, log = TRUE)\n\nlog_posterior_non_norm &lt;- log_likelihood + log_prior\nlog_posterior &lt;- log_posterior_non_norm - max(log_posterior_non_norm) # Stabilizzazione\nposterior &lt;- exp(log_posterior) / sum(exp(log_posterior))\n\n# Grafico\nplot(mu_griglia, posterior,\n    type = \"l\", col = \"darkgreen\", lwd = 2,\n    main = \"Distribuzione a Posteriori con Log-Verosimiglianza\",\n    xlab = \"Media\", ylab = \"Probabilità\"\n)",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_grid_gauss.html#estensione-alla-deviazione-standard-ignota",
    "href": "chapters/bayesian_inference/04_grid_gauss.html#estensione-alla-deviazione-standard-ignota",
    "title": "42  Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "42.8 Estensione alla Deviazione Standard Ignota",
    "text": "42.8 Estensione alla Deviazione Standard Ignota\nPer una griglia bidimensionale di valori di \\(\\mu\\) e \\(\\sigma\\):\n\n# Define the grid for mu and sigma\nmu_griglia &lt;- seq(110, 150, length.out = 100)\nsigma_griglia &lt;- seq(1, 10, length.out = 50)\n\n# Create combinations of mu and sigma using expand.grid\ngrid &lt;- expand.grid(mu = mu_griglia, sigma = sigma_griglia)\n\n# Compute the log-likelihood for each combination of mu and sigma\nlog_likelihood &lt;- apply(grid, 1, function(params) {\n    mu &lt;- params[1]\n    sigma &lt;- params[2]\n    sum(dnorm(campione, mean = mu, sd = sigma, log = TRUE))\n})\n\n# Reshape log-likelihood into a matrix\nlog_likelihood_2d &lt;- matrix(log_likelihood, nrow = length(mu_griglia), ncol = length(sigma_griglia))\n\n# Compute priors for mu and sigma\nlog_prior_mu &lt;- dnorm(mu_griglia, mean = 140, sd = 5, log = TRUE)\nlog_prior_sigma &lt;- dnorm(sigma_griglia, mean = 5, sd = 2, log = TRUE)\n\n# Combine priors into a grid\nlog_prior_2d &lt;- outer(log_prior_mu, log_prior_sigma, \"+\")\n\n# Compute log-posterior\nlog_posterior_2d &lt;- log_likelihood_2d + log_prior_2d\nlog_posterior_2d &lt;- log_posterior_2d - max(log_posterior_2d) # Stabilize\nposterior_2d &lt;- exp(log_posterior_2d)\nposterior_2d &lt;- posterior_2d / sum(posterior_2d) # Normalize\n\n# Convert posterior_2d to a data frame for visualization\nlibrary(reshape2)\nposterior_df &lt;- melt(posterior_2d)\nnames(posterior_df) &lt;- c(\"mu_idx\", \"sigma_idx\", \"posterior\")\nposterior_df$mu &lt;- mu_griglia[posterior_df$mu_idx]\nposterior_df$sigma &lt;- sigma_griglia[posterior_df$sigma_idx]\n\n# Plot the posterior distribution\nlibrary(ggplot2)\nggplot(posterior_df, aes(x = mu, y = sigma, fill = posterior)) +\n    geom_tile() +\n    scale_fill_viridis_c() +\n    labs(\n        title = \"Distribuzione a Posteriori Bidimensionale\",\n        x = \"Media ($\\\\mu$)\", y = \"Deviazione Standard ($\\\\sigma$)\"\n    )",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_grid_gauss.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/04_grid_gauss.html#riflessioni-conclusive",
    "title": "42  Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "42.9 Riflessioni Conclusive",
    "text": "42.9 Riflessioni Conclusive\nQuando si passa alla stima simultanea di più parametri, come la media (\\(\\mu\\)) e la deviazione standard (\\(\\sigma\\)), l’analisi diventa notevolmente più complessa. Questo perché occorre considerare un numero molto maggiore di combinazioni di parametri rispetto alla stima di un solo parametro, aumentando così il carico computazionale. Inoltre, la scelta delle priors per ciascun parametro richiede particolare attenzione, poiché queste influenzeranno in modo diretto le stime a posteriori.\nIn scenari dove lo spazio dei parametri è multidimensionale o quando l’esplorazione della griglia diventa impraticabile, l’uso di metodi avanzati come il campionamento di Markov Chain Monte Carlo (MCMC) diventa indispensabile. Questi metodi permettono di campionare in modo efficiente dalla distribuzione a posteriori, senza la necessità di esplorare esplicitamente ogni combinazione possibile di parametri, rendendo l’analisi più gestibile anche in contesti complessi.\nIn conclusione, l’estensione dell’approccio bayesiano a problemi con più parametri sconosciuti richiede un’attenzione ancora maggiore nella definizione dello spazio dei parametri, nella selezione delle priors appropriate e nel calcolo delle distribuzioni a posteriori. L’adozione di tecniche come l’MCMC può facilitare questo processo, permettendo di affrontare in modo efficiente problemi che altrimenti sarebbero proibitivi dal punto di vista computazionale.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_grid_gauss.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/04_grid_gauss.html#informazioni-sullambiente-di-sviluppo",
    "title": "42  Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] reshape2_1.4.4    MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2\n#&gt;  [5] ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0  \n#&gt;  [9] bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0      markdown_1.13    \n#&gt; [13] knitr_1.49        lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1    \n#&gt; [17] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#&gt; [21] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [25] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      xfun_0.49         htmlwidgets_1.6.4 rstatix_0.7.2    \n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    fansi_1.0.6       pacman_0.5.1     \n#&gt; [13] pkgconfig_2.0.3   lifecycle_1.0.4   compiler_4.4.2    farver_2.1.2     \n#&gt; [17] munsell_0.5.1     mnormt_2.1.1      carData_3.0-5     httpuv_1.6.15    \n#&gt; [21] htmltools_0.5.8.1 yaml_2.3.10       Formula_1.2-5     car_3.1-3        \n#&gt; [25] pillar_1.9.0      later_1.4.0       abind_1.4-8       nlme_3.1-166     \n#&gt; [29] mime_0.12         tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4    \n#&gt; [33] labeling_0.4.3    rprojroot_2.0.4   fastmap_1.2.0     grid_4.4.2       \n#&gt; [37] colorspace_2.1-1  cli_3.6.3         magrittr_2.0.3    utf8_1.2.4       \n#&gt; [41] broom_1.0.7       withr_3.0.2       backports_1.5.0   promises_1.3.1   \n#&gt; [45] timechange_0.3.0  rmarkdown_2.29    ggsignif_0.6.4    hms_1.1.3        \n#&gt; [49] shiny_1.9.1       evaluate_1.0.1    miniUI_0.1.1.1    rlang_1.1.4      \n#&gt; [53] Rcpp_1.0.13-1     xtable_1.8-4      glue_1.8.0        jsonlite_1.8.9   \n#&gt; [57] plyr_1.8.9        R6_2.5.1",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families_1.html",
    "href": "chapters/bayesian_inference/05_conjugate_families_1.html",
    "title": "43  Distribuzioni coniugate (1)",
    "section": "",
    "text": "43.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nIn questo capitolo, esploriamo il concetto di distribuzioni a priori coniugate e il loro ruolo nell’inferenza bayesiana. Utilizzando il modello beta-binomiale come esempio paradigmatico, dimostreremo come queste distribuzioni semplifichino l’analisi attraverso calcoli analitici diretti. L’uso di una distribuzione a priori coniugata non solo rende l’inferenza più agevole, ma fornisce anche una chiara visione del modo in cui le credenze a priori influenzano le conclusioni.\nPer favorire la comprensione, procederemo in tre fasi principali:",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families_1.html#introduzione",
    "href": "chapters/bayesian_inference/05_conjugate_families_1.html#introduzione",
    "title": "43  Distribuzioni coniugate (1)",
    "section": "",
    "text": "Introduzione del modello beta-binomiale.\nAnalisi della distribuzione Beta e del suo ruolo come distribuzione a priori.\nDescrizione del processo di aggiornamento bayesiano e dei vantaggi derivanti dall’uso di distribuzioni coniugate.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families_1.html#il-modello-beta-binomiale",
    "href": "chapters/bayesian_inference/05_conjugate_families_1.html#il-modello-beta-binomiale",
    "title": "43  Distribuzioni coniugate (1)",
    "section": "43.2 Il Modello Beta-Binomiale",
    "text": "43.2 Il Modello Beta-Binomiale\nIl modello beta-binomiale è un esempio classico per analizzare una proporzione \\(\\theta\\), ossia la probabilità di successo in una sequenza di prove binarie (ad esempio, successo/fallimento). Supponiamo di osservare \\(y\\) successi su \\(n\\) prove, dove ogni prova è indipendente e con la stessa probabilità di successo \\(\\theta\\), che appartiene all’intervallo \\([0,1]\\).\nLa funzione di verosimiglianza, basata sulla distribuzione binomiale, è espressa come:\n\\[\n\\text{Bin}(y \\mid n, \\theta) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n - y},\n\\]\ndove \\(\\binom{n}{y}\\) è il coefficiente binomiale che conta il numero di modi in cui \\(y\\) successi possono verificarsi in \\(n\\) prove.\nPer modellare la nostra conoscenza preliminare su \\(\\theta\\), scegliamo una distribuzione a priori Beta, che rappresenta un’ampia gamma di credenze iniziali con parametri flessibili.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families_1.html#la-distribuzione-beta-un-prior-flessibile",
    "href": "chapters/bayesian_inference/05_conjugate_families_1.html#la-distribuzione-beta-un-prior-flessibile",
    "title": "43  Distribuzioni coniugate (1)",
    "section": "43.3 La Distribuzione Beta: Un Prior Flessibile",
    "text": "43.3 La Distribuzione Beta: Un Prior Flessibile\nLa distribuzione Beta è definita come:\n\\[\n\\text{Beta}(\\theta \\mid \\alpha, \\beta) = \\frac{1}{B(\\alpha, \\beta)} \\theta^{\\alpha - 1} (1 - \\theta)^{\\beta - 1}, \\quad \\text{con } \\theta \\in (0, 1),\n\\]\ndove:\n\n\\(\\alpha &gt; 0\\) e \\(\\beta &gt; 0\\) sono i iperparametri, che determinano la forma della distribuzione.\n\\(B(\\alpha, \\beta)\\) è la funzione Beta di Eulero, calcolata come:\n\\[\n  B(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)},\n  \\]\ndove \\(\\Gamma(x)\\) è la funzione Gamma, una generalizzazione del fattoriale.\n\n\n43.3.1 Interpretazione Intuitiva di \\(\\alpha\\) e \\(\\beta\\)\nNel contesto bayesiano:\n\n\\(\\alpha -1\\) rappresenta il numero ipotetico di “successi” a priori.\n\\(\\beta -1\\) rappresenta il numero ipotetico di “fallimenti” a priori.\n\nAd esempio:\n\nUna distribuzione Beta(1, 1) è uniforme (0 successi a priori e 0 fallimenti), indicando totale incertezza iniziale (assenza di credenze informate).\nUna distribuzione Beta(10, 20) rappresenta una conoscenza a priori basata su 9 successi e 19 fallimenti ipotizzati, indicando una convinzione iniziale relativamente solida, poiché deriva da un totale di 28 osservazioni virtuali che riflettono le credenze precedenti.\n\nQuesta interpretazione consente di calibrare le credenze a priori in base all’evidenza disponibile o alla fiducia nella stima.\n\n\n43.3.2 Flessibilità della Distribuzione Beta\nLa distribuzione Beta è estremamente versatile:\n\nForma: Valori diversi di \\(\\alpha\\) e \\(\\beta\\) producono distribuzioni simmetriche, asimmetriche o uniformi.\nForza del prior: Valori elevati di \\(\\alpha\\) e \\(\\beta\\) riducono la varianza, riflettendo credenze più forti.\n\nQuesta flessibilità rende la distribuzione Beta una scelta ideale per rappresentare credenze iniziali su proporzioni.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families_1.html#aggiornamento-bayesiano",
    "href": "chapters/bayesian_inference/05_conjugate_families_1.html#aggiornamento-bayesiano",
    "title": "43  Distribuzioni coniugate (1)",
    "section": "43.4 Aggiornamento Bayesiano",
    "text": "43.4 Aggiornamento Bayesiano\nL’aggiornamento bayesiano combina le informazioni iniziali (priori) con i dati osservati (verosimiglianza) per produrre una nuova distribuzione delle credenze (posteriori). Nel caso del modello beta-binomiale, questo processo è particolarmente semplice grazie alla “coniugazione”: il prior Beta e la verosimiglianza Binomiale producono una distribuzione a posteriori che appartiene ancora alla famiglia Beta.\n\n43.4.1 Problema\nSe osserviamo \\(y\\) successi su \\(n\\) prove, vogliamo aggiornare il nostro prior Beta con i dati osservati per ottenere una distribuzione a posteriori Beta. I parametri aggiornati della distribuzione a posteriori sono:\n\\[\n\\alpha' = \\alpha + y, \\quad \\beta' = \\beta + n - y.\n\\]\nVediamo in dettaglio come si arriva a questo risultato.\n\n\n43.4.2 Passaggi dell’Aggiornamento Bayesiano\n1. Formula di Bayes\nLa regola di Bayes afferma che:\n\\[\n\\text{Posterior} \\propto \\text{Prior} \\times \\text{Verosimiglianza},\n\\]\ndove \\(\\propto\\) indica “proporzionale a”. Qui ci concentriamo sui termini che dipendono dal parametro di interesse, \\(\\theta\\), la probabilità di successo.\n2. Espressione del Prior\nIl prior è una distribuzione Beta, definita come:\n\\[\n\\text{Prior} = \\theta^{\\alpha-1} (1-\\theta)^{\\beta-1},\n\\]\ndove:\n\n\\(\\theta\\) rappresenta la probabilità di successo,\n\\(\\alpha\\) e \\(\\beta\\) sono parametri che descrivono le nostre convinzioni iniziali:\n\n\\(\\alpha\\): il numero di successi attesi prima di osservare i dati,\n\\(\\beta\\): il numero di insuccessi attesi prima di osservare i dati.\n\n\n3. Espressione della Verosimiglianza\nLa verosimiglianza è data dalla distribuzione Binomiale, che rappresenta la probabilità di osservare \\(y\\) successi su \\(n\\) prove:\n\\[\n\\text{Verosimiglianza} = \\theta^y (1-\\theta)^{n-y},\n\\]\ndove:\n\n\\(y\\) è il numero di successi osservati,\n\\(n\\) è il numero totale di prove,\n\\(\\theta\\) è la probabilità di successo (il parametro che stiamo aggiornando).\n\n4. Moltiplicazione di Prior e Verosimiglianza\nCombinando prior e verosimiglianza, otteniamo:\n\\[\n\\text{Posterior} \\propto \\underbrace{\\theta^{\\alpha-1} (1-\\theta)^{\\beta-1}}_{\\text{Prior}} \\times \\underbrace{\\theta^y (1-\\theta)^{n-y}}_{\\text{Verosimiglianza}}.\n\\]\n5. Raggruppamento dei termini\nMoltiplicando i termini simili, raggruppiamo gli esponenti di \\(\\theta\\) e \\(1-\\theta\\):\n\\[\n\\text{Posterior} \\propto \\theta^{(\\alpha-1) + y} (1-\\theta)^{(\\beta-1) + (n-y)}.\n\\]\n6. Forma finale\nSemplificando gli esponenti:\n\\[\n\\text{Posterior} \\propto \\theta^{\\alpha + y - 1} (1-\\theta)^{\\beta + n - y - 1}.\n\\]\nQuesta è la forma di una distribuzione Beta con nuovi parametri:\n\\[\n\\alpha' = \\alpha + y, \\quad \\beta' = \\beta + n - y.\n\\]\n7. Normalizzazione\nPer trasformare questa espressione in una distribuzione di probabilità vera e propria, dobbiamo dividere per una costante di normalizzazione. La funzione Beta, \\(B(\\alpha', \\beta')\\), normalizza la distribuzione:\n\\[\np(\\theta | y, n) = \\frac{\\theta^{\\alpha' - 1} (1-\\theta)^{\\beta' - 1}}{B(\\alpha', \\beta')},\n\\]\ndove \\(B(\\alpha', \\beta')\\) è definita come:\n\\[\nB(\\alpha', \\beta') = \\int_0^1 \\theta^{\\alpha' - 1} (1-\\theta)^{\\beta' - 1} \\, d\\theta.\n\\]\nTuttavia, non dobbiamo calcolarla esplicitamente poiché sappiamo già che il risultato è una distribuzione Beta.\n8. Parametri aggiornati\nIn conclusione, i parametri aggiornati sono:\n\nNuovo \\(\\alpha'\\): \\(\\alpha + y\\), che somma al vecchio \\(\\alpha\\) il numero di successi osservati (\\(y\\)).\nNuovo \\(\\beta'\\): \\(\\beta + n - y\\), che somma al vecchio \\(\\beta\\) il numero di insuccessi osservati (\\(n-y\\)).\n\n\n\n43.4.3 Vantaggi del Modello Beta-Binomiale\nIl modello beta-binomiale presenta diversi vantaggi:\n\nSemplicità analitica: La distribuzione a posteriori appartiene alla stessa famiglia della distribuzione a priori, evitando calcoli complessi.\nInterpretazione trasparente: L’aggiornamento dei parametri \\(\\alpha\\) e \\(\\beta\\) mostra chiaramente come i dati influenzino le credenze.\n\nNonostante la semplicità, le distribuzioni a priori coniugate non sempre rappresentano credenze realistiche. Tecniche moderne come il campionamento Monte Carlo consentono di usare distribuzioni a priori più complesse, ma il modello beta-binomiale rimane un esempio didattico fondamentale per comprendere l’inferenza bayesiana.\nIn conclusione, il modello beta-binomiale illustra chiaramente come le distribuzioni a priori coniugate possano semplificare l’inferenza bayesiana e fornire una comprensione intuitiva dell’interazione tra prior e dati. Questo modello rappresenta un punto di partenza ideale per approfondire l’approccio bayesiano e prepararsi a concetti più avanzati.\n\nEsempio 43.1 In un esempio ispirato da McElreath (2020) nel suo libro “Statistical Rethinking”, consideriamo un esperimento dove otteniamo 6 successi (indicati come “acqua”) su un totale di 9 prove (immaginate come lanci di un mappamondo). La verosimiglianza binomiale per questo esperimento è data da:\n\\[\n\\theta^y (1-\\theta)^{n-y},\n\\]\ndove \\(y = 6\\) è il numero di successi e \\(n = 9\\) è il numero totale di prove.\nSe scegliamo una distribuzione a priori Beta con parametri \\(\\alpha = 2\\) e \\(\\beta = 2\\), possiamo utilizzare l’aggiornamento bayesiano per calcolare i parametri della distribuzione a posteriori, dato l’esito delle nostre prove. L’applicazione del teorema di Bayes porta a una distribuzione a posteriori Beta con i parametri aggiornati \\(\\alpha' = \\alpha + y = 8\\) e \\(\\beta' = \\beta + n - y = 5\\).\nOra, vediamo come visualizzare le tre distribuzioni di interesse: la distribuzione a priori Beta(\\(2, 2\\)), la verosimiglianza binomiale per \\(y=6\\) e \\(n=9\\), e la distribuzione a posteriori Beta(\\(8, 5\\)).\n\n# Definizione dei parametri\nalpha_prior &lt;- 2\nbeta_prior &lt;- 2\ny &lt;- 6\nn &lt;- 9\n\n# Parametri della distribuzione a posteriori\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + n - y\n\n# Creiamo una sequenza di valori di theta\ntheta &lt;- seq(0, 1, length.out = 1000) # Maggiore risoluzione\n\n# Calcoliamo le PDF\nprior_pdf &lt;- dbeta(theta, shape1 = alpha_prior, shape2 = beta_prior)\nlikelihood &lt;- theta^y * (1 - theta)^(n - y)\n\n# Normalizziamo la verosimiglianza usando il metodo trapezoidale\nlikelihood_integral &lt;- sum(likelihood) * (theta[2] - theta[1]) # Approssimazione numerica dell'integrale\nnormalized_likelihood &lt;- likelihood / likelihood_integral\n\nposterior_pdf &lt;- dbeta(theta, shape1 = alpha_post, shape2 = beta_post)\n\n# Disegniamo le distribuzioni\nplot(theta, prior_pdf,\n    type = \"l\", col = \"blue\", lwd = 2,\n    ylim = c(0, max(c(prior_pdf, normalized_likelihood, posterior_pdf))),\n    xlab = expression(theta), ylab = \"Densità\",\n    main = \"Distribuzioni Prior, Likelihood e Posterior\"\n)\nlines(theta, normalized_likelihood, col = \"green\", lwd = 2, lty = 2)\nlines(theta, posterior_pdf, col = \"red\", lwd = 2)\nlegend(\"topleft\",\n    legend = c(\n        sprintf(\"Prior Beta(%d, %d)\", alpha_prior, beta_prior),\n        \"Likelihood (normalizzata)\",\n        sprintf(\"Posterior Beta(%d, %d)\", alpha_post, beta_post)\n    ),\n    col = c(\"blue\", \"green\", \"red\"),\n    lty = c(1, 2, 1), lwd = 2\n)\n\n\n\n\n\n\n\n\nIn questo codice, la funzione trapezoid viene usata per calcolare l’integrale della funzione di verosimiglianza non normalizzata su θ, fornendo il fattore di normalizzazione. Dividendo la funzione di verosimiglianza per questo fattore, otteniamo una funzione di verosimiglianza normalizzata, il cui integrale su [0, 1] è uguale a 1. La normalizzazione della verosimiglianza è eseguita solo a scopo di visualizzazione, per facilitare il confronto tra le curve.\n\n\nEsempio 43.2 Esaminiamo ora un esempio discuso da Johnson et al. (2022). In uno studio molto famoso, Stanley Milgram ha studiato la propensione delle persone a obbedire agli ordini delle figure di autorità, anche quando tali ordini potrebbero danneggiare altre persone (Milgram 1963). Nell’articolo, Milgram descrive lo studio come\n\nconsistente nell’ordinare a un soggetto ingenuo di somministrare una scossa elettrica a una vittima. Viene utilizzato un generatore di scosse simulato, con 30 livelli di tensione chiaramente contrassegnati che vanno da IS a 450 volt. Lo strumento porta delle designazioni verbali che vanno da Scossa Lieve a Pericolo: Scossa Grave. Le risposte della vittima, che è un complice addestrato dell’esperimentatore, sono standardizzate. Gli ordini di somministrare scosse vengono dati al soggetto ingenuo nel contesto di un ‘esperimento di apprendimento’ apparentemente organizzato per studiare gli effetti della punizione sulla memoria. Man mano che l’esperimento procede, al soggetto ingenuo viene ordinato di somministrare scosse sempre più intense alla vittima, fino al punto di raggiungere il livello contrassegnato Pericolo: Scossa Grave.\n\nIn altre parole, ai partecipanti allo studio veniva dato il compito di testare un altro partecipante (che in realtà era un attore addestrato) sulla loro capacità di memorizzare una serie di item. Se l’attore non ricordava un item, al partecipante veniva ordinato di somministrare una scossa all’attore e di aumentare il livello della scossa con ogni fallimento successivo. I partecipanti non erano consapevoli del fatto che le scosse fossero finte e che l’attore stesse solo fingendo di provare dolore dalla scossa.\nNello studio di Milgram, 26 partecipanti su 40 hanno somministrato scosse al livello “Pericolo: Scossa Grave”. Il problema richiede di costruire la distribuzione a posteriori della probabilità \\(\\theta\\) di infliggere una scossa a l livello “Pericolo: Scossa Grave”, ipotizzando che uno studio precedente aveva stabilito che \\(\\theta\\) segue una distribuzione Beta(1, 10).\nIniziamo a fornire una rappresentazione grafica della distribuzione a priori.\n\n# Impostazione dei parametri della distribuzione Beta\nalpha &lt;- 1\nbeta_val &lt;- 10\n\n# Creazione di valori x per il plot\nx_values &lt;- seq(0, 1, length.out = 1000)\n\n# Calcolo della densità di probabilità per ogni valore di x\nbeta_pdf &lt;- dbeta(x_values, shape1 = alpha, shape2 = beta_val)\n\n# Plot della densità di probabilità\ncolor_fill &lt;- \"#b97c7c\"\nplot(x_values, beta_pdf,\n    type = \"l\", col = color_fill, lwd = 2,\n    main = \"Distribuzione Beta(1, 10)\",\n    xlab = \"x\", ylab = \"Densità di probabilità\"\n)\nlegend(\"topright\", legend = \"Beta(1, 10)\", col = color_fill, lwd = 2)\n\n\n\n\n\n\n\n\nLa distribuzione a posteriori segue una distribuzione Beta con parametri aggiornati:\n\ny &lt;- 26\nn &lt;- 40\n\nalpha_prior &lt;- 1\nbeta_prior &lt;- 10\n\nalpha_post &lt;- alpha_prior + y\nbeta_post &lt;- beta_prior + n - y\n\nalpha_post\n#&gt; [1] 27\nbeta_post\n#&gt; [1] 24\n\nCreazione di un grafico per la distribuzione a posteriori:\n\n# Creazione di valori x per il plot\nx_values &lt;- seq(0, 1, length.out = 1000)\n\n# Calcolo della densità di probabilità per ogni valore di x\nbeta_pdf &lt;- dbeta(x_values, alpha_post, beta_post)\n\n# Plot della densità di probabilità\nplot(x_values, beta_pdf,\n    type = \"l\", col = \"blue\", lwd = 2,\n    main = \"Distribuzione Beta(27, 24)\", xlab = expression(theta), ylab = \"Densità di probabilità\"\n)\nlegend(\"topright\", legend = \"Beta(27, 24)\", col = \"blue\", lwd = 2)\n\n\n\n\n\n\n\n\nCalcolo della media a posteriori di \\(\\theta\\):\n\nalpha_post / (alpha_post + beta_post)\n#&gt; [1] 0.5294118\n\nCalcolo della moda a posteriori:\n\n(alpha_post - 1) / (alpha_post + beta_post - 2)\n#&gt; [1] 0.5306122\n\nCalcolo della probabilità che \\(\\theta &gt; 0.6\\):\n\npbeta(0.6, alpha_post, beta_post, lower.tail = FALSE)\n#&gt; [1] 0.1561683\n\nOvvero:\n\n1 - pbeta(0.6, alpha_post, beta_post)\n#&gt; [1] 0.1561683\n\nEseguiamo il problema utilizzando il metodo basato su griglia. Definiamo la griglia di interesse:\n\ntheta &lt;- seq(0, 1, length.out = 100)\n\nCreiamo la distribuzione a priori:\n\nprior &lt;- dbeta(theta, alpha_prior, beta_prior)\n\nplot(theta, prior / sum(prior),\n    type = \"h\", col = \"blue\", lwd = 2,\n    main = \"Distribuzione a priori\", xlab = expression(theta), ylab = \"Probabilità\"\n)\n\n\n\n\n\n\n\n\nCreiamo la verosimiglianza:\n\nlk &lt;- dbinom(y, n, theta)\n\nplot(theta, lk / sum(lk),\n    type = \"h\", col = \"red\", lwd = 2,\n    main = \"Verosimiglianza\", xlab = expression(theta), ylab = \"Probabilità\"\n)\n\n\n\n\n\n\n\n\nCalcoliamo la distribuzione a posteriori:\n\npost &lt;- (prior * lk) / sum(prior * lk)\n\nplot(theta, post,\n    type = \"h\", col = \"green\", lwd = 2,\n    main = \"Distribuzione a posteriori\", xlab = expression(theta), ylab = \"Probabilità\"\n)\n\n\n\n\n\n\n\n\nEstrazione di un campione dalla distribuzione a posteriori:\n\nsamples &lt;- sample(theta, size = 1e6, replace = TRUE, prob = post)\n\nTroviamo la media a posteriori:\n\nmean(samples)\n#&gt; [1] 0.5294755\n\nCalcoliamo la probabilità che \\(\\theta &gt; 0.6\\):\n\nmean(samples &gt; 0.6)\n#&gt; [1] 0.152728\n\nQuesto codice mantiene la struttura logica del problema e produce risultati equivalenti utilizzando R.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families_1.html#principali-distribuzioni-coniugate",
    "href": "chapters/bayesian_inference/05_conjugate_families_1.html#principali-distribuzioni-coniugate",
    "title": "43  Distribuzioni coniugate (1)",
    "section": "43.5 Principali distribuzioni coniugate",
    "text": "43.5 Principali distribuzioni coniugate\nEsistono altre combinazioni di verosimiglianza e distribuzione a priori che producono una distribuzione a posteriori con la stessa forma della distribuzione a priori. Ecco alcune delle più note coniugazioni tra modelli statistici e distribuzioni a priori:\n\nNel modello Normale-Normale \\(\\mathcal{N}(\\mu, \\sigma^2_0)\\), la distribuzione a priori è \\(\\mathcal{N}(\\mu_0, \\tau^2)\\) e la distribuzione a posteriori è \\(\\mathcal{N}\\left(\\frac{\\mu_0\\sigma^2 + \\bar{y}n\\tau^2}{\\sigma^2 + n\\tau^2}, \\frac{\\sigma^2\\tau^2}{\\sigma^2 + n\\tau^2} \\right)\\).\nNel modello Poisson-gamma \\(\\text{Po}(\\theta)\\), la distribuzione a priori è \\(\\Gamma(\\lambda, \\delta)\\) e la distribuzione a posteriori è \\(\\Gamma(\\lambda + n \\bar{y}, \\delta +n)\\).\nNel modello esponenziale \\(\\text{Exp}(\\theta)\\), la distribuzione a priori è \\(\\Gamma(\\lambda, \\delta)\\) e la distribuzione a posteriori è \\(\\Gamma(\\lambda + n, \\delta +n\\bar{y})\\).\nNel modello uniforme-Pareto \\(\\text{U}(0, \\theta)\\), la distribuzione a priori è \\(\\text{Pa}(\\alpha, \\varepsilon)\\) e la distribuzione a posteriori è \\(\\text{Pa}(\\alpha + n, \\max(y_{(n)}, \\varepsilon))\\).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families_1.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/05_conjugate_families_1.html#riflessioni-conclusive",
    "title": "43  Distribuzioni coniugate (1)",
    "section": "43.6 Riflessioni Conclusive",
    "text": "43.6 Riflessioni Conclusive\nIn conclusione, l’utilizzo di priori coniugati presenta vantaggi e svantaggi. Cominciamo con i vantaggi principali. Il principale vantaggio dell’adozione di distribuzioni a priori coniugate risiede nella loro capacità di rendere l’analisi della distribuzione a posteriori trattabile da un punto di vista analitico. Ad esempio, nel corso di questo capitolo abbiamo esaminato come sia possibile formulare la distribuzione a posteriori in seguito a un esperimento composto da una serie di prove di Bernoulli (con una verosimiglianza binomiale), utilizzando una distribuzione Beta sia per la prior che per il posteriore.\nTuttavia, è cruciale riconoscere che i modelli basati sul concetto di famiglie coniugate presentano delle limitazioni intrinseche. Le distribuzioni coniugate a priori sono disponibili solamente per distribuzioni di verosimiglianza di base e relativamente semplici. Per modelli complessi e più realistici, la ricerca di priori coniugati diventa spesso un compito estremamente arduo, limitando quindi la loro utilità. Inoltre, anche quando le distribuzioni a priori coniugate sono disponibili, un modello che ne fa uso potrebbe non essere sufficientemente flessibile per adattarsi alle nostre credenze iniziali. Ad esempio, un modello basato su una distribuzione normale è sempre unimodale e simmetrico rispetto alla media \\(\\mu\\). Tuttavia, se le nostre conoscenze iniziali non sono simmetriche o non seguono una distribuzione unimodale, la scelta di una distribuzione a priori normale potrebbe non risultare la più adeguata (Johnson et al., 2022).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families_1.html#esercizi",
    "href": "chapters/bayesian_inference/05_conjugate_families_1.html#esercizi",
    "title": "43  Distribuzioni coniugate (1)",
    "section": "43.7 Esercizi",
    "text": "43.7 Esercizi\n\nEsercizio 43.1 Si consideri lo studio “An excess of positive results: Comparing the standard psychology literature with registered reports” di Scheel et al. (2021). In questo lavoro, gli autori confrontano il tasso di risultati positivi \\(\\theta\\) ottenuti in studi psicologici pubblicati senza preregistrazione con quelli pubblicati con preregistrazione. Si utilizzi il tasso di successo riportato negli studi preregistrati per costruire una distribuzione a priori per il parametro \\(\\theta\\).\nSecondo i risultati degli studi preregistrati, gli autori riscontrano un tasso di successo del 43.66%, con un intervallo di confidenza al 95% [CI] = [31.91, 55.95]. Sulla base di questi dati, si costruisca una distribuzione beta come distribuzione a priori per \\(\\theta\\), seguendo il metodo illustrato da Johnson et al. (2022).\nSuccessivamente, utilizzando questa distribuzione beta come distribuzione a priori, si determini la distribuzione a posteriori utilizzando il metodo delle famiglie coniugate per due scenari distinti, basati su 152 studi osservati: (a) Un tasso di successo del 60% (b) Un tasso di successo del 96% (come riportato per gli studi non preregistrati da Scheel et al. (2021)).\nInfine, si commentino i risultati derivanti dall’analisi delle distribuzioni a posteriori ottenute per entrambi gli scenari.\n\n\nEsercizio 43.2 Tra i fattori che possono influenzare il rapporto tra i sessi alla nascita c’è la condizione materna di placenta previa, una condizione insolita della gravidanza in cui la placenta è impiantata in basso nell’utero, impedendo un normale parto vaginale del feto. Uno studio condotto in Germania ha esaminato il sesso dei neonati in casi di placenta previa e ha riscontrato che, su un totale di 980 nascite, 437 erano femmine.\nQuanta evidenza fornisce questo studio a supporto dell’ipotesi che la proporzione di nascite femminili nella popolazione di placenta previa sia inferiore a 0.485, che rappresenta la proporzione di nascite femminili nella popolazione generale? (Esercizio tratto da Gelman et al. (1995))\n\n\nEsercizio 43.3 Per valutare la sensibilità della soluzione precedente alla scelta della distribuzione a priori, ripetere l’esercizio utilizzando come distribuzione a priori per la proporzione di nascite femminili una distribuzione Beta(48.5, 51.5). Questa distribuzione è centrata su 0.485 e concentra la maggior parte della sua massa nell’intervallo [0.385, 0.585]. Interpretare i risultati ottenuti.\n\n\nEsercizio 43.4 In uno studio recente, Gori et al. (2024) hanno esaminato un campione di 202 adulti italiani e hanno riscontrato una prevalenza di mancini del 6.4%. Una meta-analisi di Papadatou-Pastou et al. (2020), condotta su un totale di 2,396,170 soggetti, riporta che la proporzione di mancini varia tra il 9.3% e il 18.1%, a seconda di come viene misurata la lateralità manuale. Inoltre, Papadatou-Pastou et al. (2020) mostrano che la prevalenza della lateralità manuale varia tra i paesi e nel tempo. Considerata questa incertezza, si determini la distribuzione a posteriori che combina i dati dello studio di Gori et al. (2024) con le informazioni pregresse fornite da Papadatou-Pastou et al. (2020). Le informazioni di Papadatou-Pastou et al. (2020) possono essere espresse in termini di una distribuzione Beta(8, 60).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families_1.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/05_conjugate_families_1.html#informazioni-sullambiente-di-sviluppo",
    "title": "43  Distribuzioni coniugate (1)",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.16.0       MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2\n#&gt;  [5] ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0  \n#&gt;  [9] bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0      markdown_1.13    \n#&gt; [13] knitr_1.49        lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1    \n#&gt; [17] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#&gt; [21] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [25] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1  farver_2.1.2      fastmap_1.2.0     pacman_0.5.1     \n#&gt;  [5] promises_1.3.1    rpart_4.1.23      digest_0.6.37     timechange_0.3.0 \n#&gt;  [9] mime_0.12         lifecycle_1.0.4   survival_3.7-0    magrittr_2.0.3   \n#&gt; [13] compiler_4.4.2    rlang_1.1.4       tools_4.4.2       utf8_1.2.4       \n#&gt; [17] yaml_2.3.10       ggsignif_0.6.4    htmlwidgets_1.6.4 mnormt_2.1.1     \n#&gt; [21] abind_1.4-8       miniUI_0.1.1.1    withr_3.0.2       nnet_7.3-19      \n#&gt; [25] grid_4.4.2        fansi_1.0.6       jomo_2.7-6        xtable_1.8-4     \n#&gt; [29] colorspace_2.1-1  iterators_1.0.14  cli_3.6.3         rmarkdown_2.29   \n#&gt; [33] generics_0.1.3    tzdb_0.4.0        minqa_1.2.8       splines_4.4.2    \n#&gt; [37] parallel_4.4.2    vctrs_0.6.5       boot_1.3-31       glmnet_4.1-8     \n#&gt; [41] Matrix_1.7-1      jsonlite_1.8.9    carData_3.0-5     car_3.1-3        \n#&gt; [45] hms_1.1.3         mitml_0.4-5       rstatix_0.7.2     Formula_1.2-5    \n#&gt; [49] foreach_1.5.2     glue_1.8.0        pan_1.9           nloptr_2.1.1     \n#&gt; [53] codetools_0.2-20  stringi_1.8.4     gtable_0.3.6      shape_1.4.6.1    \n#&gt; [57] later_1.4.0       lme4_1.1-35.5     munsell_0.5.1     pillar_1.9.0     \n#&gt; [61] htmltools_0.5.8.1 R6_2.5.1          rprojroot_2.0.4   evaluate_1.0.1   \n#&gt; [65] shiny_1.9.1       lattice_0.22-6    backports_1.5.0   broom_1.0.7      \n#&gt; [69] httpuv_1.6.15     Rcpp_1.0.13-1     nlme_3.1-166      xfun_0.49        \n#&gt; [73] pkgconfig_2.0.3",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families_1.html#bibliografia",
    "href": "chapters/bayesian_inference/05_conjugate_families_1.html#bibliografia",
    "title": "43  Distribuzioni coniugate (1)",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (1995). Bayesian data analysis. Chapman; Hall/CRC.\n\n\nGori, B., Grippo, A., Focardi, M., & Lolli, F. (2024). The Italian version of Edinburgh Handedness Inventory: Translation, transcultural adaptation, and validation in healthy subjects. Laterality, 29(2), 151–168.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nPapadatou-Pastou, M., Ntolka, E., Schmitz, J., Martin, M., Munafò, M. R., Ocklenburg, S., & Paracchini, S. (2020). Human handedness: A meta-analysis. Psychological bulletin, 146(6), 481–524.\n\n\nScheel, A. M., Schijen, M. R., & Lakens, D. (2021). An excess of positive results: Comparing the standard psychology literature with registered reports. Advances in Methods and Practices in Psychological Science, 4(2), 25152459211007467.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_conjugate_families_2.html",
    "href": "chapters/bayesian_inference/06_conjugate_families_2.html",
    "title": "44  Distribuzioni coniugate (2)",
    "section": "",
    "text": "44.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nLa statistica bayesiana ci permette di aggiornare le nostre credenze iniziali o conoscenze a priori sulla distribuzione di un parametro (in questo caso, la media della popolazione) in base ai dati osservati. Questo processo di aggiornamento ci porta a ottenere una distribuzione a posteriori che riflette una nuova comprensione del parametro, integrata con le informazioni fornite dal campione.\nIl concetto fondamentale è che, attraverso l’aggiornamento bayesiano, l’incertezza sulla stima del parametro si riduce. Questo è dovuto al fatto che l’informazione aggiuntiva fornita dai dati osservati consente di “restringere” la distribuzione a posteriori rispetto alla distribuzione a priori, riducendo così la varianza (o deviazione standard) della distribuzione del parametro di interesse.\nIn questo capitolo, approfondiremo il tema delle famiglie coniugate (Capitolo 43), focalizzandoci sul modello normale-normale. Una caratteristica distintiva di questo modello è la sua capacità di auto-coniugazione rispetto a una funzione di verosimiglianza gaussiana. In termini più semplici, se la funzione di verosimiglianza segue una distribuzione gaussiana, l’adozione di una distribuzione a priori gaussiana per la media garantisce che anche la distribuzione a posteriori mantenga la sua forma gaussiana.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_conjugate_families_2.html#perché-usare-la-distribuzione-normale",
    "href": "chapters/bayesian_inference/06_conjugate_families_2.html#perché-usare-la-distribuzione-normale",
    "title": "44  Distribuzioni coniugate (2)",
    "section": "44.2 Perché Usare la Distribuzione Normale?",
    "text": "44.2 Perché Usare la Distribuzione Normale?\nSpesso, quando la distribuzione a posteriori è nota per essere unimodale e simmetrica, possiamo modellarla efficacemente con una distribuzione normale, anche se sappiamo che la sua forma è solo approssimativamente normale. Nei casi in cui il ricercatore abbia un’idea approssimativa di dove sia centrato un parametro sconosciuto, la distribuzione normale fornisce un metodo utile per modellare questa stima, permettendo di descrivere il livello di incertezza tramite il termine di varianza della distribuzione normale. Questa convenienza può offrire buone approssimazioni alla densità a posteriori desiderata, con la consapevolezza che, con l’aumentare dei dati osservati, tali assunzioni perdono di importanza.\nCome dimostrato di seguito, il modello normale bayesiano possiede proprietà frequentiste desiderabili. Sebbene l’enfasi nell’analisi bayesiana non sia sulle stime puntuali, si può dimostrare che, con campioni sempre più grandi, la media della distribuzione a posteriori bayesiana si avvicina alla stima di massima verosimiglianza. Questa proprietà esiste perché la distribuzione a posteriori è un compromesso ponderato tra la distribuzione a priori specificata dall’utente, che in questo capitolo è normale, e la funzione di verosimiglianza derivata dai dati, anch’essa normale in questo capitolo. Con l’aumentare delle dimensioni del campione, la verosimiglianza diventa sempre più dominante in questa ponderazione.\nNel caso di una media normale, illustrato qui, la varianza della distribuzione di campionamento frequentista diminuisce con l’aumento della dimensione del campione. Nel contesto bayesiano, la riduzione della varianza media dalla funzione di verosimiglianza alla fine prevale anche su una varianza a priori deliberatamente grande. Pertanto, se si prevede che la dimensione del dataset sia grande, i ricercatori possono permettersi di essere liberali nella specificazione della varianza a priori.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_conjugate_families_2.html#distribuzione-a-posteriori-in-un-contesto-normale-con-varianza-nota",
    "href": "chapters/bayesian_inference/06_conjugate_families_2.html#distribuzione-a-posteriori-in-un-contesto-normale-con-varianza-nota",
    "title": "44  Distribuzioni coniugate (2)",
    "section": "44.3 Distribuzione a Posteriori in un Contesto Normale con Varianza Nota",
    "text": "44.3 Distribuzione a Posteriori in un Contesto Normale con Varianza Nota\nConsideriamo un insieme di dati \\(y = [y_1, y_2, \\ldots, y_n]\\), composto da \\(n\\) osservazioni indipendenti e identicamente distribuite (i.i.d.) secondo una distribuzione normale \\(\\mathcal{N}(\\mu, \\sigma^2)\\). In questo scenario, il nostro obiettivo è stimare il valore del parametro \\(\\mu\\), che rappresenta la media della popolazione da cui provengono i dati.\n\n44.3.1 Distribuzione a Priori\nNell’approccio bayesiano, assumiamo una conoscenza iniziale sul parametro \\(\\mu\\) mediante una distribuzione a priori. In questo caso, utilizziamo una distribuzione normale coniugata, ovvero una distribuzione normale con media \\(\\mu_0\\) e varianza \\(\\sigma_0^2\\). Questa scelta riflette la nostra incertezza iniziale su \\(\\mu\\).\n\n\n44.3.2 Funzione di Verosimiglianza\nLa funzione di verosimiglianza, denotata da \\(p(y | \\mu, \\sigma)\\), rappresenta la probabilità di osservare i dati \\(y\\) dato il valore del parametro \\(\\mu\\) e la varianza nota \\(\\sigma^2\\). Per una distribuzione normale i.i.d., la funzione di verosimiglianza è data da:\n\\[\np(y | \\mu, \\sigma) = \\prod_{i=1}^n \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp\\left(-\\frac{(y_i - \\mu)^2}{2\\sigma^2}\\right).\n\\]\n\n\n44.3.3 Teorema di Bayes e Distribuzione a Posteriori\nIl teorema di Bayes combina la distribuzione a priori con la funzione di verosimiglianza per ottenere la distribuzione a posteriori del parametro \\(\\mu\\), data l’evidenza osservata \\(y\\):\n\\[\np(\\mu | y) = \\frac{ p(y | \\mu) p(\\mu) }{ p(y) }.\n\\]\nPoiché la distribuzione a priori e la funzione di verosimiglianza sono entrambe distribuzioni normali, la distribuzione a posteriori risulterà anch’essa una distribuzione normale con media a posteriori \\(\\mu_p\\) e varianza a posteriori \\(\\sigma_p^2\\).\n\n\n44.3.4 Formula per la Media a Posteriori (\\(\\mu_p\\))\nLa media a posteriori \\(\\mu_p\\) rappresenta la stima aggiornata del parametro \\(\\mu\\) alla luce delle informazioni contenute nei dati osservati. La sua formula è:\n\\[\n\\mu_p = \\frac{\\frac{1}{\\sigma_0^2} \\mu_0 + \\frac{n}{\\sigma^2} \\bar{y}}{\\frac{1}{\\sigma_0^2} + \\frac{n}{\\sigma^2}},\n\\]\ndove \\(\\bar{y}\\) rappresenta la media campionaria:\n\\[\n\\bar{y} = \\frac{\\sum_{i=1}^n y_i}{n}.\n\\]\nOsserviamo che \\(\\mu_p\\) è una combinazione ponderata tra la media a priori \\(\\mu_0\\) e la media campionaria \\(\\bar{y}\\). Il peso di \\(\\bar{y}\\) aumenta con il numero di osservazioni \\(n\\), mentre il peso di \\(\\mu_0\\) diminuisce. Questo riflette il fatto che con più dati, la nostra fiducia nella media campionaria cresce, mentre l’incertezza a priori diminuisce.\n\n\n44.3.5 Formula per la Varianza a Posteriori (\\(\\sigma_p^2\\))\nLa varianza a posteriori \\(\\sigma_p^2\\) rappresenta l’incertezza residua sulla stima del parametro \\(\\mu\\) dopo aver incorporato le informazioni dai dati. La sua formula è:\n\\[\n\\sigma_p^2 = \\frac{1}{\\frac{1}{\\sigma_0^2} + \\frac{n}{\\sigma^2}}.\n\\]\nRispetto alla varianza a priori \\(\\sigma_0^2\\), la varianza a posteriori \\(\\sigma_p^2\\) è sempre inferiore o uguale. In altre parole, l’incertezza sulla stima di \\(\\mu\\) si riduce con l’aumentare del numero di osservazioni. La varianza a posteriori rappresenta un bilanciamento tra l’incertezza a priori (\\(\\sigma_0^2\\)) e l’informazione derivata dai dati (\\(\\sigma^2/n\\)).\nIn sintesi, nel caso normale-normale con varianza nota, la distribuzione a posteriori risulta essere una distribuzione normale con una media e una varianza che riflettono un’integrazione bilanciata tra l’informazione a priori e quella ottenuta dai dati osservati. Questo approccio garantisce una stima aggiornata e affinata del parametro \\(\\mu\\) che migliora con l’aumento del numero di osservazioni.\n\nEsempio 44.1 I test standard di QI sono progettati per misurare l’intelligenza con una media di 100 e una deviazione standard di 15. Tuttavia, si dice anche che questi test presentino bias culturali che favoriscono alcuni gruppi rispetto ad altri. Un’ulteriore complicazione si verifica quando i punteggi di QI vengono aggregati a livello nazionale, poiché le caratteristiche interne ai paesi vengono mascherate. Questo esempio analizza i dati di QI raccolti a livello internazionale (Lynn e Vanhanen, 2001) per 80 paesi da fonti nazionali pubblicate e discussi da Gill (2015). L’idea chiave nella descrizione della distribuzione a posteriori è se le differenze tra le nazioni alterano la parametrizzazione prevista.\nI dati di Lynn e Vanhanen (2001) sono forniti di seguito:\n\n\n\n\n\n\n\n\n\n\n\n\n\nPaese\nIQ\nPaese\nIQ\nPaese\nIQ\nPaese\nIQ\n\n\n\n\nArgentina\n96\nAustralia\n98\nAustria\n102\nBarbados\n78\n\n\nBelgium\n100\nBrazil\n87\nBulgaria\n93\nCanada\n97\n\n\nChina\n100\nCongo (Br.)\n73\nCongo (Zr.)\n65\nCroatia\n90\n\n\nCuba\n85\nCzech Repub.\n97\nDenmark\n98\nEcuador\n80\n\n\nEgypt\n83\nEq. Guinea\n59\nEthiopia\n63\nFiji\n84\n\n\nFinland\n97\nFrance\n98\nGermany\n102\nGhana\n71\n\n\nGreece\n92\nGuatemala\n79\nGuinea\n66\nHong Kong\n107\n\n\nHungary\n99\nIndia\n81\nIndonesia\n89\nIran\n84\n\n\nIraq\n87\nIreland\n93\nIsrael\n94\nItaly\n102\n\n\nJamaica\n72\nJapan\n105\nKenya\n72\nKorea (S.)\n106\n\n\nLebanon\n86\nMalaysia\n92\nMarshall I.\n84\nMexico\n87\n\n\nMorocco\n85\nNepal\n78\nNetherlands\n102\nNew Zealand\n100\n\n\nNigeria\n67\nNorway\n98\nPeru\n90\nPhilippines\n86\n\n\nPoland\n99\nPortugal\n95\nPuerto Rico\n84\nQatar\n78\n\n\nRomania\n94\nRussia\n96\nSamoa\n87\nSierra Leone\n64\n\n\nSingapore\n103\nSlovakia\n96\nSlovenia\n95\nSouth Africa\n72\n\n\nSpain\n97\nSudan\n72\nSuriname\n89\nSweden\n101\n\n\nSwitzerland\n101\nTaiwan\n104\nTanzania\n72\nThailand\n91\n\n\nTonga\n87\nTurkey\n90\nUganda\n73\nU.K.\n100\n\n\nU.S.\n98\nUruguay\n96\nZambia\n77\nZimbabwe\n66\n\n\n\nImplementiamo le informazioni necessarie in Python.\n\n# Dati IQ delle 80 nazioni\niq &lt;- c(\n  96, 100, 100, 85, 83, 97, 92, 99, 87, 72, 86, 85, 67, 99, 94, 103, 97, 101, 87, 98,\n  87, 73, 97, 59, 98, 79, 81, 93, 105, 92, 78, 98, 95, 96, 72, 104, 90, 96, 98, 102,\n  78, 90, 63, 84, 84, 107, 86, 102, 106, 94, 102, 72, 101, 89, 72, 101, 91, 100, 100,\n  66, 107, 86, 78, 84, 78, 64, 72, 101, 91, 100, 67, 86\n)\n\n\n# Numero di osservazioni\nn &lt;- length(iq)\n\n# Media campionaria\ny_bar &lt;- mean(iq)\n\n# Deviazione standard nota\nsigma &lt;- 15\n\n# Parametri a priori\nmu_0 &lt;- 100\nsigma_0 &lt;- 15\n\nCalcoliamo la media a posteriori con la formula discussa in precedenza\n\\[\n\\mu_p = \\frac{\\frac{1}{\\sigma_0^2}\\mu_0 + \\frac{n}{\\sigma^2}\\bar{y}}{\\frac {1}{\\sigma_0^2} + \\frac{n}{\\sigma^2}}\n\\]\ndove:\n\n\\(\\mu_0\\) è la media a priori\n\\(\\sigma_0\\) è la deviazione standard a priori\n\\(n\\) è il numero di osservazioni\n\\(\\sigma\\) è la deviazione standard delle osservazioni (nota)\n\\(\\bar{y}\\) è la media campionaria\n\n\nmu_p &lt;- ((1 / sigma_0^2) * mu_0 + (n / sigma^2) * y_bar) /\n  ((1 / sigma_0^2) + (n / sigma^2))\nprint(paste(\"Media a posteriori (mu_p):\", round(mu_p, 2)))\n#&gt; [1] \"Media a posteriori (mu_p): 89.36\"\n\nCalcoliamo la varianza a posteriori\n\\[\n\\sigma_p^2 = \\frac{1}{\\frac {1}{\\sigma_0^2}+ \\frac{n}{\\sigma^2}}\n\\]\n\nsigma_p_sq &lt;- 1 / ((1 / sigma_0^2) + (n / sigma^2))\nsigma_p &lt;- sqrt(sigma_p_sq)\nprint(paste(\"Varianza a posteriori (sigma_p_sq):\", round(sigma_p_sq, 2)))\n#&gt; [1] \"Varianza a posteriori (sigma_p_sq): 3.08\"\n\nGeneriamo una rappresentazione grafica della distribuzione a posteriori della media del IQ sulla base dei dati osservati, avendo assunto mu_0 = 100 e sigma_0 = 15 per la distribuzione a priori.\n\n# Definizione dei valori sull'asse x\nx &lt;- seq(mu_p - 4 * sigma_p, mu_p + 4 * sigma_p, length.out = 1000)\n\n# Calcolo della densità di probabilità\npdf &lt;- dnorm(x, mean = mu_p, sd = sigma_p)\n\n# Creazione del grafico\nggplot(data.frame(x = x, pdf = pdf), aes(x = x, y = pdf)) +\n  geom_line(color = \"blue\", size = 1) +\n  geom_area(aes(fill = \"Posterior\"), alpha = 0.2) +\n  scale_fill_manual(values = c(\"blue\")) +\n  labs(\n    title = \"Distribuzione a Posteriori\",\n    x = \"Media del Quoziente di Intelligenza\",\n    y = \"Densità di probabilità\"\n  )\n#&gt; Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\nL’analisi condotta mediante un modello bayesiano basato sulla distribuzione normale ha prodotto un risultato interessante: la media stimata della distribuzione a posteriori del QI si attesta a 89.36, un valore sensibilmente inferiore ai 100 punti previsti come media standard.\nTuttavia, per un’interpretazione completa di questo dato, è fondamentale adottare un approccio critico che consideri alcuni aspetti cruciali:\n\nLa media a posteriori è ottenuta aggregando i dati QI di 80 nazioni diverse. Questo processo può innescare un effetto di aggregazione, dove la media “smussata” risultante non rispecchia accuratamente la distribuzione del QI a livello individuale in ogni singola nazione. Di conseguenza, le differenze tra le nazioni in termini di QI medio e variabilità potrebbero essere mascherate da questa media aggregata.\nÈ importante sottolineare che la media a posteriori viene calcolata utilizzando dati non ponderati per ogni nazione. Ciò significa che nazioni con popolazioni più piccole, anche se con punteggi QI mediamente più alti o più bassi, hanno lo stesso impatto sulla media aggregata rispetto a nazioni con popolazioni più grandi. Questo aspetto potrebbe ulteriormente distorcere la rappresentazione della vera distribuzione globale del QI.\nLa deviazione osservata dalla media standard di 100 potrebbe non riflettere esclusivamente differenze nell’intelligenza media tra le nazioni, ma anche differenze nei contesti sanitari, sociologici e politici in cui i test sono stati somministrati. Fattori quali l’accesso all’istruzione, la qualità della nutrizione e l’esposizione a stimoli cognitivi possono influenzare i punteggi QI ottenuti e contribuire alla variabilità osservata tra le nazioni.\nInoltre, è fondamentale considerare la possibilità di un bias culturale intrinseco allo strumento stesso. I test del QI sono stati originariamente progettati per un contesto specifico (paese industrializzato di lingua inglese) e potrebbero non essere adatti o culturalmente sensibili a contesti differenti. Questo potrebbe portare a una sottostima dei punteggi QI in alcune nazioni e influenzare la media a posteriori aggregata.\n\nQuesti risultati evidenziano l’importanza di un’attenta considerazione dei fattori metodologici quando si interpretano dati di test del QI a livello trans-culturale. L’effetto di aggregazione, l’utilizzo di medie non ponderate, le differenze nei contesti e il potenziale bias culturale richiedono un’analisi più approfondita che consideri questi fattori e utilizzi metodi statistici più sofisticati per ottenere una comprensione più completa delle differenze nel QI tra le nazioni.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_conjugate_families_2.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/06_conjugate_families_2.html#riflessioni-conclusive",
    "title": "44  Distribuzioni coniugate (2)",
    "section": "44.4 Riflessioni Conclusive",
    "text": "44.4 Riflessioni Conclusive\nIn questo capitolo, abbiamo approfondito il meccanismo dell’aggiornamento bayesiano attraverso l’implementazione del modello normale-normale. Il processo inizia definendo una distribuzione a priori per \\(\\mu\\), specificata da una media \\(\\mu_0\\) e una varianza \\(\\sigma_0^2\\). Dopo l’acquisizione di nuovi dati, ipotizzando che seguano una distribuzione Normale con media campionaria \\(\\bar{y}\\) e varianza nota \\(\\sigma^2\\), implementiamo il teorema normale-normale per derivare la distribuzione a posteriori del parametro.\nLa media della distribuzione a posteriori, denotata come \\(\\mu_{\\text{post}}\\), si configura come una media ponderata tra la media a priori \\(\\mu_0\\) e la media campionaria \\(\\bar{y}\\), dove il peso assegnato a ciascuna media è determinato dalle rispettive varianze \\(\\sigma_0^2\\) e \\(\\sigma^2\\) della distribuzione a priori e dei dati osservati. Analogamente, la varianza a posteriori \\(\\sigma_{\\text{post}}^2\\) è determinata utilizzando un’espressione che incorpora entrambe le varianze.\nIn sintesi, l’adozione del modello normale-normale in un contesto bayesiano facilita il calcolo delle distribuzioni a posteriori, grazie alla scelta di una distribuzione a priori Normale che mantiene la proprietà di coniugatezza, semplificando così l’intero processo analitico.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_conjugate_families_2.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/06_conjugate_families_2.html#informazioni-sullambiente-di-sviluppo",
    "title": "44  Distribuzioni coniugate (2)",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.16.0       MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2\n#&gt;  [5] ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0  \n#&gt;  [9] bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0      markdown_1.13    \n#&gt; [13] knitr_1.49        lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1    \n#&gt; [17] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#&gt; [21] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [25] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1  farver_2.1.2      fastmap_1.2.0     pacman_0.5.1     \n#&gt;  [5] promises_1.3.1    rpart_4.1.23      digest_0.6.37     timechange_0.3.0 \n#&gt;  [9] mime_0.12         lifecycle_1.0.4   survival_3.7-0    magrittr_2.0.3   \n#&gt; [13] compiler_4.4.2    rlang_1.1.4       tools_4.4.2       utf8_1.2.4       \n#&gt; [17] yaml_2.3.10       ggsignif_0.6.4    labeling_0.4.3    htmlwidgets_1.6.4\n#&gt; [21] mnormt_2.1.1      abind_1.4-8       miniUI_0.1.1.1    withr_3.0.2      \n#&gt; [25] nnet_7.3-19       grid_4.4.2        fansi_1.0.6       jomo_2.7-6       \n#&gt; [29] xtable_1.8-4      colorspace_2.1-1  iterators_1.0.14  cli_3.6.3        \n#&gt; [33] rmarkdown_2.29    generics_0.1.3    tzdb_0.4.0        minqa_1.2.8      \n#&gt; [37] splines_4.4.2     parallel_4.4.2    vctrs_0.6.5       boot_1.3-31      \n#&gt; [41] glmnet_4.1-8      Matrix_1.7-1      jsonlite_1.8.9    carData_3.0-5    \n#&gt; [45] car_3.1-3         hms_1.1.3         mitml_0.4-5       rstatix_0.7.2    \n#&gt; [49] Formula_1.2-5     foreach_1.5.2     glue_1.8.0        pan_1.9          \n#&gt; [53] nloptr_2.1.1      codetools_0.2-20  stringi_1.8.4     gtable_0.3.6     \n#&gt; [57] shape_1.4.6.1     later_1.4.0       lme4_1.1-35.5     munsell_0.5.1    \n#&gt; [61] pillar_1.9.0      htmltools_0.5.8.1 R6_2.5.1          rprojroot_2.0.4  \n#&gt; [65] evaluate_1.0.1    shiny_1.9.1       lattice_0.22-6    backports_1.5.0  \n#&gt; [69] broom_1.0.7       httpuv_1.6.15     Rcpp_1.0.13-1     nlme_3.1-166     \n#&gt; [73] xfun_0.49         pkgconfig_2.0.3",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_conjugate_families_2.html#bibliografia",
    "href": "chapters/bayesian_inference/06_conjugate_families_2.html#bibliografia",
    "title": "44  Distribuzioni coniugate (2)",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGill, J. (2015). Bayesian methods: A social and behavioral sciences approach (3rd Edition). Chapman; Hall/CRC.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_summary_posterior.html",
    "href": "chapters/bayesian_inference/07_summary_posterior.html",
    "title": "45  Sintesi a posteriori",
    "section": "",
    "text": "45.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nIn questo capitolo, concentriamo la nostra attenzione sulla sintesi dell’informazione racchiusa nella distribuzione a posteriori, la quale rappresenta il nostro livello di incertezza riguardo al parametro o ai parametri incogniti oggetto dell’inferenza.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_summary_posterior.html#riepilogo-numerico",
    "href": "chapters/bayesian_inference/07_summary_posterior.html#riepilogo-numerico",
    "title": "45  Sintesi a posteriori",
    "section": "45.2 Riepilogo numerico",
    "text": "45.2 Riepilogo numerico\nLa distribuzione a posteriori contiene in sé tutte le informazioni disponibili sui potenziali valori del parametro. Nel caso di un parametro unidimensionale o bidimensionale, possiamo rappresentare la distribuzione a posteriori mediante un grafico \\(p(\\theta \\mid y)\\).\nTuttavia, quando ci troviamo di fronte a vettori di parametri con più di due dimensioni, risulta vantaggioso eseguire una sintesi numerica della distribuzione a posteriori. Possiamo distinguere due forme di sintesi numerica della distribuzione a posteriori:\n\nStima puntuale;\nIntervallo di credibilità.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_summary_posterior.html#stima-puntuale",
    "href": "chapters/bayesian_inference/07_summary_posterior.html#stima-puntuale",
    "title": "45  Sintesi a posteriori",
    "section": "45.3 Stima puntuale",
    "text": "45.3 Stima puntuale\nNel contesto dell’inferenza bayesiana, il processo di stima del valore più credibile del parametro \\(\\theta\\) tramite la distribuzione a posteriori si avvale di tre statistiche: la moda, la mediana e la media, la cui scelta è guidata dalla forma della distribuzione a posteriori. Queste statistiche sono utilizzate per ottenere una stima puntuale della tendenza centrale della distribuzione a posteriori, che a sua volta fornisce il “valore più credibile” del parametro. Questo valore rappresenta la stima a cui attribuiamo il massimo grado di fiducia soggettiva, basandoci sui dati osservati e sulle nostre credenze a priori.\n\nModa (Massimo a posteriori, MAP):\nLa moda rappresenta il valore più probabile di un parametro, ovvero quello che massimizza la distribuzione a posteriori. Questo valore è noto come “massimo a posteriori” (MAP). La stima MAP prende origine dalla stima di massima verosimiglianza (MLE), che cerca il valore di \\(\\theta\\), denotato come \\(\\hat{\\theta}_{ML}\\), che massimizza la funzione di verosimiglianza \\(L(\\theta \\mid y)\\):\n\n\\[\n\\hat{\\theta}_{ML} = \\arg \\max_\\theta L(\\theta \\mid y).\n\\]\nNell’inferenza bayesiana, \\(\\theta\\) è considerato una variabile casuale, e si specifica una distribuzione a priori su \\(\\theta\\) per riflettere l’incertezza sul suo valore. Integrando l’informazione a priori nella funzione di verosimiglianza, si ottiene la formula per la stima MAP:\n\\[\n\\hat{\\theta}_{MAP} = \\arg \\max_\\theta L(\\theta \\mid y)p(\\theta).\n\\]\nQuesta formula evidenzia che la stima MAP corrisponde al valore che massimizza la densità a posteriori di \\(\\theta\\) dati i dati osservati \\(y\\), ovvero il valore che rappresenta la moda della distribuzione a posteriori.\nSebbene il concetto di MAP sia intuitivo, presenta diversi problemi che ne limitano l’uso nella pratica.\nLa prima difficoltà è di tipo computazionale: con i metodi MCMC comunemente utilizzati per stimare le distribuzioni a posteriori, è molto difficile individuare con precisione la posizione esatta del MAP nello spazio delle distribuzioni posteriori.\nIl secondo problema è legato all’uso dell’inferenza bayesiana in modelli complessi e in situazioni non asintotiche. In questi casi, la verosimiglianza o la distribuzione a posteriori possono avere forme irregolari o non normali. Se la distribuzione a posteriori è molto asimmetrica, il MAP potrebbe non rappresentare adeguatamente dove si concentra la maggior parte della probabilità. Di conseguenza, il MAP non sempre fornisce un’idea accurata del comportamento complessivo della distribuzione a posteriori.\n\nMedia a posteriori:\n\nLa media a posteriori è il valore atteso del parametro \\(\\theta\\), calcolato sulla base della distribuzione a posteriori. In termini matematici, nel caso continuo, è espressa dalla formula:\n\\[\nE(\\theta \\mid y) = \\int_{-\\infty}^{\\infty} \\theta \\, p(\\theta \\mid y) \\, d\\theta.\n\\]\n\nMediana:\n\nLa mediana è il valore del parametro per cui il 50% della massa di probabilità a posteriori si distribuisce equamente a sinistra e a destra. È una misura robusta della tendenza centrale, particolarmente utile in presenza di distribuzioni asimmetriche o multimodali, dove la moda potrebbe non fornire una stima accurata del valore più probabile del parametro.\nPer valutare l’incertezza associata al parametro \\(\\theta\\), è utile calcolare la varianza a posteriori. Questa varianza è basata sulla tendenza centrale definita dalla media a posteriori, e la sua radice quadrata fornisce la deviazione standard a posteriori, che misura l’incertezza a posteriori relativa a \\(\\theta\\), espressa nelle stesse unità di misura dei dati. La formula per la varianza a posteriori è data da:\n\\[\nV(\\theta|y) = E[((\\theta - E[(\\theta|y)])^2 |y) = \\int_{-\\infty}^{\\infty} (\\theta - E[\\theta | y])^2 p(\\theta | y) d\\theta = E[\\theta^2 |y] - E[\\theta|y]^2.\n\\]\nIn sintesi, la media, la moda e la mediana a posteriori, insieme alla varianza a posteriori, forniscono una descrizione comprensiva del comportamento della distribuzione a posteriori di \\(\\theta\\), permettendoci di derivare stime puntuali e misurare l’incertezza associata a \\(\\theta\\) in modo informativo.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_summary_posterior.html#intervallo-di-credibilità",
    "href": "chapters/bayesian_inference/07_summary_posterior.html#intervallo-di-credibilità",
    "title": "45  Sintesi a posteriori",
    "section": "45.4 Intervallo di credibilità",
    "text": "45.4 Intervallo di credibilità\nNell’inferenza bayesiana, l’intervallo di credibilità è uno strumento utilizzato per definire un intervallo che contiene una determinata percentuale della massa della distribuzione a posteriori del parametro \\(\\theta\\). Questo intervallo riflette l’incertezza associata alla stima del parametro: un intervallo più ampio suggerisce una maggiore incertezza. Lo scopo principale dell’intervallo di credibilità è fornire una misura quantitativa dell’incertezza riguardante \\(\\theta\\).\nA differenza degli intervalli di confidenza frequentisti, non esiste un unico intervallo di credibilità per un dato livello di confidenza \\((1 - \\alpha) \\cdot 100\\%\\). In effetti, è possibile costruire un numero infinito di tali intervalli. Per questo motivo, è necessario stabilire criteri aggiuntivi per selezionare l’intervallo di credibilità più appropriato. Tra le opzioni più comuni ci sono l’intervallo di credibilità simmetrico e l’intervallo di massima densità posteriore (HPD).\n\nIntervallo di Credibilità Simmetrico:\n\nQuesto tipo di intervallo è centrato rispetto al punto di stima puntuale. Se \\(\\hat{\\theta}\\) rappresenta la stima del parametro, l’intervallo simmetrico avrà la forma \\((\\hat{\\theta} - a, \\hat{\\theta} + a)\\), dove \\(a\\) è un valore positivo scelto in modo tale che la massa totale inclusa sia pari a \\((1 - \\alpha)\\). Più formalmente, un intervallo di credibilità simmetrico al livello \\(\\alpha\\) può essere espresso come:\n\\[\nI_{\\alpha} = [q_{\\alpha/2}, q_{1 - \\alpha/2}],\n\\]\ndove \\(q_z\\) rappresenta il quantile \\(z\\) della distribuzione a posteriori. Ad esempio, un intervallo di credibilità simmetrico al 94% sarà:\n\\[\nI_{0.06} = [q_{0.03}, q_{0.97}],\n\\]\ndove il 3% della massa a posteriori si trova in ciascuna delle due code della distribuzione.\n\nIntervallo di Credibilità Più Stretto (Intervallo di Massima Densità Posteriore, HPD):\n\nL’intervallo di massima densità posteriore (HPD) è l’intervallo più stretto possibile che contiene il \\((1 - \\alpha) \\cdot 100\\%\\) della massa a posteriori. A differenza dell’intervallo simmetrico, l’HPD include tutti i valori di \\(\\theta\\) che hanno la maggiore densità a posteriori. Per costruirlo, si disegna una linea orizzontale sulla distribuzione a posteriori e si regola l’altezza della linea in modo che l’area sotto la curva corrisponda a \\((1 - \\alpha)\\). L’HPD risulta essere il più stretto tra tutti gli intervalli possibili per lo stesso livello di confidenza. Nel caso di una distribuzione a posteriori unimodale e simmetrica, l’HPD coincide con l’intervallo di credibilità simmetrico.\n\n45.4.1 Interpretazione\nIl calcolo degli intervalli di credibilità, in particolare dell’intervallo di massima densità posteriore (HPD), richiede spesso l’uso di software statistici avanzati. Questo perché determinare manualmente tali intervalli può essere complicato, soprattutto nei modelli bayesiani con distribuzioni posteriori complesse o quando sono necessarie simulazioni numeriche per stimare la distribuzione a posteriori.\nUn aspetto cruciale dell’inferenza bayesiana riguarda l’interpretazione dell’incertezza. Nel contesto frequentista, si considera il parametro, come ad esempio la media della popolazione \\(\\mu\\), come un valore fisso ma sconosciuto. L’inferenza frequentista si basa sull’immaginare un numero infinito di campioni ripetuti dalla popolazione. Per ogni campione, si può calcolare una media campionaria \\(\\bar{x}\\) e formare un intervallo di confidenza al \\(100(1-\\alpha)\\%\\). L’interpretazione corretta in termini frequentisti è che, nel lungo periodo, il \\(100(1-\\alpha)\\%\\) degli intervalli di confidenza costruiti con questo metodo conterrà il vero valore del parametro \\(\\mu\\). Tuttavia, per un singolo intervallo calcolato, la probabilità che contenga effettivamente \\(\\mu\\) è o 0 o 1, poiché \\(\\mu\\) è considerato un valore fisso.\nNel framework bayesiano, invece, il parametro è trattato come una variabile aleatoria con una distribuzione di probabilità. Campionando dalla distribuzione a posteriori dei parametri, possiamo ottenere quantili che ci permettono di calcolare direttamente la probabilità che un parametro rientri in un determinato intervallo. Ad esempio, un intervallo di credibilità al 95% indica che c’è una probabilità del 95% che il parametro sia contenuto all’interno di quell’intervallo, data l’evidenza osservata. Questa interpretazione differisce profondamente da quella frequentista e risulta più intuitiva, poiché riflette direttamente il grado di incertezza che abbiamo riguardo al parametro.\nIn sintesi, mentre l’intervallo di confidenza frequentista riguarda la ripetizione ipotetica del campionamento, l’intervallo di credibilità bayesiano fornisce una misura diretta dell’incertezza attuale sul valore di un parametro, basata sui dati osservati e sulle informazioni a priori. Questo approccio è spesso considerato più vicino al senso comune quando si tratta di interpretare la probabilità associata ai parametri.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_summary_posterior.html#verifica-di-ipotesi-bayesiana",
    "href": "chapters/bayesian_inference/07_summary_posterior.html#verifica-di-ipotesi-bayesiana",
    "title": "45  Sintesi a posteriori",
    "section": "45.5 Verifica di ipotesi bayesiana",
    "text": "45.5 Verifica di ipotesi bayesiana\nL’inferenza bayesiana può essere applicata anche nel contesto della verifica di ipotesi, in un approccio noto come verifica di ipotesi bayesiana. In questo tipo di inferenza, l’obiettivo è valutare la plausibilità che un parametro \\(\\theta\\) assuma valori all’interno di un determinato intervallo. Ad esempio, possiamo voler sapere quanto è probabile che \\(\\theta\\) sia maggiore di 0.5 o che rientri in un intervallo specifico, come [0.5, 1.0].\nIn questo approccio, si calcola la probabilità a posteriori che \\(\\theta\\) si trovi all’interno dell’intervallo di interesse. Questa probabilità viene ottenuta integrando la distribuzione a posteriori su tale intervallo. Quindi, invece di rifiutare o accettare un’ipotesi come nel test di ipotesi frequentista, la verifica di ipotesi bayesiana fornisce una misura diretta della probabilità che un parametro rientri in un intervallo specifico, dato l’evidenza osservata e le informazioni a priori.\nIn altre parole, questo approccio consente di quantificare la nostra incertezza rispetto all’affermazione che \\(\\theta\\) rientri in un certo intervallo, fornendo una probabilità che rappresenta direttamente la plausibilità di quell’ipotesi.\n\nEsempio 45.1 Per illustrare l’approccio bayesiano, consideriamo i dati relativi ai punteggi del BDI-II (Beck Depression Inventory - Second Edition) di 30 soggetti clinici, come riportato nello studio condotto da Zetsche et al. (2019). Il BDI-II è uno strumento per valutare la gravità dei sintomi depressivi.\nI punteggi del BDI-II per i 30 soggetti sono:\n\n# Dati del BDI-II\nbdi &lt;- c(\n  26, 35, 30, 25, 44, 30, 33, 43, 22, 43, \n  24, 19, 39, 31, 25, 28, 35, 30, 26, 31, \n  41, 36, 26, 35, 33, 28, 27, 34, 27, 22\n)\nbdi\n#&gt;  [1] 26 35 30 25 44 30 33 43 22 43 24 19 39 31 25 28 35 30 26 31 41 36 26 35\n#&gt; [25] 33 28 27 34 27 22\n\nUn punteggio BDI-II \\(\\geq 30\\) indica un livello grave di depressione. Nel nostro campione, 17 pazienti su 30 manifestano un livello grave:\n\n# Conteggio di depressione grave\nsum(bdi &gt;= 30)\n#&gt; [1] 17\n\n\n45.5.1 Stima della Distribuzione a Posteriori\nSupponiamo di voler stimare la probabilità \\(\\theta\\) di depressione grave nei pazienti clinici utilizzando una distribuzione a priori \\(Beta(8, 2)\\). I dati possono essere visti come una sequenza di prove Bernoulliane indipendenti, dove la presenza di depressione grave è un “successo”. La verosimiglianza è quindi binomiale con parametri \\(n = 30\\) e \\(y = 17\\).\nCon una distribuzione a priori \\(Beta(8, 2)\\), la distribuzione a posteriori di \\(\\theta\\) sarà:\n\\[\n\\text{Beta}(\\alpha = 8 + 17, \\beta = 2 + 30 - 17) = \\text{Beta}(25, 15).\n\\]\n\n45.5.1.1 Tracciamo la Distribuzione a Posteriori\n\n# Parametri della distribuzione Beta\nalpha &lt;- 25\nbeta &lt;- 15\n\n# Calcolo della densità per valori di theta\ntheta &lt;- seq(0, 1, length.out = 200)\nposterior_density &lt;- dbeta(theta, alpha, beta)\n\n# Grafico della distribuzione a posteriori\nggplot(data = data.frame(theta, posterior_density), aes(x = theta, y = posterior_density)) +\n  geom_line(color = \"blue\") +\n  labs(\n    title = \"Distribuzione a Posteriori Beta(25, 15)\",\n    x = expression(theta),\n    y = \"Densità di probabilità\"\n  ) \n\n\n\n\n\n\n\n\n\n\n\n\n45.5.2 Stime Puntuali\n\nMedia a Posteriori\nLa media della distribuzione a posteriori è calcolata come:\n\n\\[\n\\mathbb{E}(\\theta | y = 17) = \\frac{\\alpha}{\\alpha + \\beta} = \\frac{25}{25 + 15} = 0.625.\n\\]\nIn R:\n\n# Calcolo della media a posteriori\nposterior_mean &lt;- alpha / (alpha + beta)\nposterior_mean\n#&gt; [1] 0.625\n\n\nModa a Posteriori (MAP)\nLa moda della distribuzione a posteriori è:\n\n\\[\nMo(\\theta | y = 17) = \\frac{\\alpha - 1}{\\alpha + \\beta - 2} = \\frac{25 - 1}{25 + 15 - 2} = 0.6316.\n\\]\nIn R:\n\n# Calcolo della moda a posteriori\nposterior_mode &lt;- (alpha - 1) / (alpha + beta - 2)\nposterior_mode\n#&gt; [1] 0.6315789\n\n\nMediana a Posteriori\nLa mediana si ottiene utilizzando la funzione di distribuzione cumulativa inversa:\n\n\n# Calcolo della mediana a posteriori\nposterior_median &lt;- qbeta(0.5, alpha, beta)\nposterior_median\n#&gt; [1] 0.6271031\n\n\n\n\n45.5.3 Intervallo di Credibilità\nL’intervallo di credibilità simmetrico al 94% è dato dai percentili 3% e 97%:\n\n# Intervallo di credibilità simmetrico al 94%\ncred_interval &lt;- qbeta(c(0.03, 0.97), alpha, beta)\ncred_interval\n#&gt; [1] 0.4781026 0.7612891\n\nPossiamo interpretare questo intervallo come segue: c’è una certezza soggettiva del 94% che \\(\\theta\\) sia compreso tra 0.478 e 0.761.\n\n\n\n45.5.4 Verifica di Ipotesi Bayesiana\nInfine, calcoliamo la probabilità che \\(\\theta &gt; 0.5\\):\n\\[\nP(\\theta &gt; 0.5 | y = 17) = \\int_{0.5}^1 f(\\theta | y = 17) d\\theta.\n\\]\nIn R:\n\n# Probabilità P(theta &gt; 0.5)\nprob_theta_greater_0_5 &lt;- pbeta(0.5, alpha, beta, lower.tail = FALSE)\nprob_theta_greater_0_5\n#&gt; [1] 0.9459355\n\nIn conclusione, utilizzando un approccio bayesiano, abbiamo stimato la distribuzione a posteriori di \\(\\theta\\), ottenuto stime puntuali e costruito intervalli di credibilità. Abbiamo inoltre calcolato la probabilità che \\(\\theta\\) superi una soglia specifica, mostrando la flessibilità e l’interpretabilità delle analisi bayesiane.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_summary_posterior.html#sintesi-della-distribuzione-a-posteriori-questioni-multivariate",
    "href": "chapters/bayesian_inference/07_summary_posterior.html#sintesi-della-distribuzione-a-posteriori-questioni-multivariate",
    "title": "45  Sintesi a posteriori",
    "section": "45.6 Sintesi della distribuzione a posteriori: questioni multivariate",
    "text": "45.6 Sintesi della distribuzione a posteriori: questioni multivariate\nQuando si affronta un’analisi bayesiana con più parametri, la complessità aumenta. Le principali difficoltà riguardano le interazioni tra i parametri e il modo in cui queste influenzano le distribuzioni marginali. Questi fattori possono complicare notevolmente la sintesi della distribuzione a posteriori e, se non considerati attentamente, possono portare a interpretazioni errate.\n\n45.6.1 Correlazioni nascoste e distribuzioni marginali\nUn problema comune nelle analisi con più parametri è rappresentato dalle correlazioni tra i parametri. Le distribuzioni marginali a posteriori, spesso riportate nei riassunti statistici, possono essere molto fuorvianti se considerate isolatamente. Quando i parametri sono fortemente correlati, le distribuzioni marginali possono apparire piatte o poco informative, inducendo a pensare che non ci sia molta informazione nella verosimiglianza.\nTuttavia, le correlazioni tra parametri possono restringere notevolmente lo spazio delle combinazioni plausibili, escludendo vaste aree dello spazio dei parametri. Questo significa che, nonostante le marginali possano sembrare non informative, l’analisi congiunta dei parametri può rivelare una struttura sottostante che riduce l’incertezza su specifiche combinazioni. Pertanto, è essenziale esaminare le correlazioni congiunte tra i parametri per ottenere una visione più completa dell’incertezza.\nCon un numero maggiore di parametri, anche i grafici di correlazione bidimensionali possono diventare limitati, poiché potrebbero esistere correlazioni di ordine superiore che non emergono in rappresentazioni a due dimensioni.\n\n\n45.6.2 Correlazioni non lineari\nUn’altra difficoltà significativa riguarda le correlazioni non lineari tra i parametri. Quando queste correlazioni sono presenti, il massimo delle distribuzioni marginali non coincide necessariamente con il massimo della distribuzione congiunta. Per esempio, se due parametri presentano una correlazione complessa, come una forma a “banana”, il massimo delle distribuzioni marginali potrebbe trovarsi in una posizione diversa rispetto al massimo globale della distribuzione congiunta.\nQuesto fenomeno rende più difficile sintetizzare correttamente la distribuzione a posteriori. In tali casi, la stima del massimo a posteriori (MAP) o altri riassunti, come gli intervalli di credibilità (CI) o gli intervalli di massima densità a posteriori (HPD), calcolati sulle marginali, potrebbero essere fuorvianti. Quando la distribuzione a posteriori è asimmetrica nello spazio multivariato, le distribuzioni marginali non catturano adeguatamente le relazioni tra i parametri. Questa è una fonte comune di confusione, poiché si tende a sottovalutare l’importanza della struttura multivariata nella distribuzione a posteriori.\n\n\n45.6.3 Strategie per affrontare queste sfide\n\nConfronto tra distribuzioni predittive:\n\nConfrontare la distribuzione predittiva a priori con quella a posteriori offre una visione più completa della riduzione dell’incertezza.\nQuesto approccio è particolarmente utile in presenza di parametri multipli e correlazioni complesse, poiché la distribuzione predittiva a posteriori incorpora le interazioni tra i parametri, fornendo una rappresentazione più accurata della plausibilità dei diversi valori parametrici.\n\nAnalisi congiunta:\n\nEsaminare le distribuzioni congiunte dei parametri, oltre alle distribuzioni marginali.\nUtilizzare grafici di dispersione bivariati o multivariati per visualizzare le relazioni tra i parametri.\nTecniche avanzate di visualizzazione, come i pair plots o le heatmap, possono essere utili per esplorare relazioni in spazi ad alta dimensionalità.\n\nMisure di dipendenza:\n\nUtilizzare misure di dipendenza non lineare, come la correlazione di Spearman o l’informazione mutua, che possono catturare relazioni complesse che le misure lineari tradizionali potrebbero non rilevare.\n\nAnalisi di sensibilità:\n\nCondurre un’analisi di sensibilità per valutare come i cambiamenti in un parametro influenzano gli altri parametri e le previsioni del modello. Questo permette di capire meglio le relazioni tra i parametri e il loro impatto sulle inferenze.\n\nTecniche di riduzione della dimensionalità:\n\nQuando ci sono molti parametri, l’uso di metodi come l’analisi delle componenti principali (PCA) può aiutare a identificare strutture latenti e ridurre la complessità del problema, facilitando l’interpretazione dei risultati.\n\n\nIn sintesi, l’analisi multivariata in un contesto bayesiano richiede particolare attenzione nella sintesi delle distribuzioni a posteriori. Le distribuzioni marginali possono fornire informazioni utili, ma spesso nascondono importanti correlazioni e strutture di dipendenza tra i parametri. Un’analisi completa dovrebbe combinare l’esame delle marginali con una valutazione attenta delle relazioni congiunte tra i parametri, utilizzando tecniche di visualizzazione e misure di dipendenza adeguate. Questo approccio integrato permette di comprendere più a fondo la distribuzione a posteriori e di trarre inferenze più robuste e accurate.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_summary_posterior.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/07_summary_posterior.html#riflessioni-conclusive",
    "title": "45  Sintesi a posteriori",
    "section": "45.7 Riflessioni Conclusive",
    "text": "45.7 Riflessioni Conclusive\nIn conclusione, la distribuzione a posteriori rappresenta la nostra conoscenza aggiornata sui parametri sconosciuti. L’impiego delle statistiche descrittive e l’analisi degli intervalli di credibilità contribuiscono a tracciare un quadro completo della distribuzione a posteriori e delle nostre inferenze riguardo al parametro di interesse.\nLe stime puntuali, ottenute attraverso statistiche descrittive come media, mediana o moda a posteriori, offrono una singola valutazione numerica del parametro ignoto. Gli intervalli di credibilità forniscono un intervallo di valori all’interno del quale si ritiene, con un certo grado di probabilità soggettiva, che il parametro incognito possa rientrare. Questi intervalli quantificano l’incertezza associata al parametro e consentono di esprimere il livello di fiducia soggettiva riguardo ai possibili valori del parametro dopo l’analisi dei dati. Abbiamo inoltre esaminato il concetto di test di ipotesi bayesiano, il quale può essere condotto agevolmente calcolando l’area appropriata sotto la distribuzione a posteriori, in accordo con l’ipotesi in questione.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_summary_posterior.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/07_summary_posterior.html#informazioni-sullambiente-di-sviluppo",
    "title": "45  Sintesi a posteriori",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.17.0       MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2\n#&gt;  [5] ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0  \n#&gt;  [9] bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0      markdown_1.13    \n#&gt; [13] knitr_1.49        lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1    \n#&gt; [17] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#&gt; [21] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [25] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1  farver_2.1.2      fastmap_1.2.0     pacman_0.5.1     \n#&gt;  [5] promises_1.3.2    rpart_4.1.23      digest_0.6.37     timechange_0.3.0 \n#&gt;  [9] mime_0.12         lifecycle_1.0.4   survival_3.7-0    magrittr_2.0.3   \n#&gt; [13] compiler_4.4.2    rlang_1.1.4       tools_4.4.2       utf8_1.2.4       \n#&gt; [17] yaml_2.3.10       ggsignif_0.6.4    labeling_0.4.3    htmlwidgets_1.6.4\n#&gt; [21] mnormt_2.1.1      abind_1.4-8       miniUI_0.1.1.1    withr_3.0.2      \n#&gt; [25] nnet_7.3-19       grid_4.4.2        fansi_1.0.6       jomo_2.7-6       \n#&gt; [29] xtable_1.8-4      colorspace_2.1-1  iterators_1.0.14  cli_3.6.3        \n#&gt; [33] rmarkdown_2.29    generics_0.1.3    tzdb_0.4.0        minqa_1.2.8      \n#&gt; [37] splines_4.4.2     parallel_4.4.2    vctrs_0.6.5       boot_1.3-31      \n#&gt; [41] glmnet_4.1-8      Matrix_1.7-1      jsonlite_1.8.9    carData_3.0-5    \n#&gt; [45] car_3.1-3         hms_1.1.3         mitml_0.4-5       rstatix_0.7.2    \n#&gt; [49] Formula_1.2-5     foreach_1.5.2     glue_1.8.0        pan_1.9          \n#&gt; [53] nloptr_2.1.1      codetools_0.2-20  stringi_1.8.4     gtable_0.3.6     \n#&gt; [57] shape_1.4.6.1     later_1.4.1       lme4_1.1-35.5     munsell_0.5.1    \n#&gt; [61] pillar_1.9.0      htmltools_0.5.8.1 R6_2.5.1          rprojroot_2.0.4  \n#&gt; [65] evaluate_1.0.1    shiny_1.9.1       lattice_0.22-6    backports_1.5.0  \n#&gt; [69] broom_1.0.7       httpuv_1.6.15     Rcpp_1.0.13-1     nlme_3.1-166     \n#&gt; [73] xfun_0.49         pkgconfig_2.0.3",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_summary_posterior.html#bibliografia",
    "href": "chapters/bayesian_inference/07_summary_posterior.html#bibliografia",
    "title": "45  Sintesi a posteriori",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nZetsche, U., Buerkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: biased or realistic? Journal of Abnormal Psychology, 128(7), 678–688.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html",
    "title": "46  L’influenza della distribuzione a priori",
    "section": "",
    "text": "46.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nConsideriamo un semplice scenario medico: un paziente si presenta dal dottore con un mal di testa. Il medico, per formulare una diagnosi accurata, dovrà considerare diversi fattori. Possiamo immaginare due medici con approcci leggermente differenti:\nQuale dei due medici è in grado di fornire una diagnosi più precisa? La risposta risiede nel concetto di probabilità a priori (o semplicemente prior), ovvero le credenze che un individuo ha su un evento prima di osservare nuovi dati.\nNel contesto medico, la storia clinica del paziente rappresenta una preziosa fonte di informazioni a priori. Conoscere gli antecedenti sanitari di un individuo permette al medico di formulare ipotesi più plausibili sulla causa del mal di testa. In termini bayesiani, i priori agiscono come una sorta di “lente” attraverso cui vengono interpretati i nuovi dati (in questo caso, i risultati dei test).\nQuando prendiamo decisioni nella vita quotidiana, utilizziamo costantemente le nostre conoscenze pregresse per interpretare nuove informazioni. Ad esempio, se vediamo una persona che indossa un camice bianco in un ospedale, inferiamo che si tratti di un medico, basandoci sulla nostra esperienza e sulle associazioni mentali che abbiamo costruito nel tempo. Questo processo di inferenza è molto simile a quello che avviene nell’aggiornamento bayesiano.\nLa scelta dei priori ha un impatto fondamentale sulla qualità delle inferenze che possiamo trarre dai dati. Questo capitolo si focalizza sull’importanza e sulle implicazioni che derivano dalla scelta dei priori sul processo di aggiornamento bayesiano. Per illustrare questi concetti, esamineremo alcuni esempi discussi da Johnson et al. (2022).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#introduzione",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#introduzione",
    "title": "46  L’influenza della distribuzione a priori",
    "section": "",
    "text": "Medico 1: Si basa principalmente sui risultati di test specifici, senza considerare una storia clinica pregressa del paziente.\nMedico 2: Oltre ai test, tiene conto della storia clinica del paziente, cercando di individuare eventuali fattori di rischio o condizioni preesistenti che potrebbero essere correlate al mal di testa.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#la-distribuzione-a-priori",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#la-distribuzione-a-priori",
    "title": "46  L’influenza della distribuzione a priori",
    "section": "46.2 La Distribuzione a Priori",
    "text": "46.2 La Distribuzione a Priori\nLa distribuzione a priori gioca un ruolo centrale nell’approccio bayesiano, poiché rappresenta le nostre conoscenze pregresse o le ipotesi sui parametri del modello prima di osservare i dati. Questo concetto è fondamentale perché permette di integrare le informazioni disponibili in precedenza con i dati osservati, fornendo così una stima più precisa e robusta dei parametri. Le distribuzioni a priori possono variare a seconda del grado di certezza che si attribuisce ai valori dei parametri.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#tipologie-di-distribuzioni-a-priori",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#tipologie-di-distribuzioni-a-priori",
    "title": "46  L’influenza della distribuzione a priori",
    "section": "46.3 Tipologie di Distribuzioni a Priori",
    "text": "46.3 Tipologie di Distribuzioni a Priori\nLa scelta della distribuzione a priori (nota come elicitazione della prior) è uno dei passaggi cruciali nell’analisi bayesiana ed è spesso vista come la fase più controversa, poiché è considerata “soggettiva”. Tuttavia, è importante sottolineare che la scelta della prior non è necessariamente soggettiva. A differenza dell’approccio frequentista, l’approccio bayesiano incoraggia la raccolta e l’integrazione di tutte le informazioni conosciute sul parametro in anticipo. Questo può essere fatto in modo oggettivo, basandosi su evidenze pregresse o raccomandazioni consolidate.\nEsistono tre principali categorie di distribuzioni a priori.\n\nDistribuzioni a Priori Non Informative. Le distribuzioni a priori non informative sono caratterizzate da una totale mancanza di conoscenza pregressa e assegnano la stessa credibilità a tutti i valori dei parametri. Un esempio comune di distribuzione a priori non informativa è la distribuzione uniforme, basata sul “Principio della Ragione Insufficiente” formulato da Laplace. Secondo questo principio, in assenza di evidenze rilevanti pregresse, tutte le possibili configurazioni dei parametri sono considerate equiprobabili.\nDistribuzioni a Priori Debolmente Informative. Le distribuzioni a priori debolmente informative consentendo di integrare una quantità limitata di informazioni pregresse nei modelli statistici. Queste distribuzioni sono progettate per riflettere le nostre assunzioni su quali possono essere i valori “ragionevoli” dei parametri del modello, tenendo conto delle incertezze presenti nell’analisi. L’uso di informazioni a priori debolmente informative può contribuire a migliorare la stabilità dell’analisi senza influenzare in modo significativo le conclusioni derivate da essa.\nLe distribuzioni a priori debolmente informative hanno la caratteristica di non “spostare” in modo significativo la distribuzione a posteriori in una direzione specifica. In altre parole, sono centrate su valori “neutri” dei parametri. Ad esempio, quando si trattano parametri che possono assumere valori positivi o negativi, la distribuzione a priori debolmente informativa potrebbe essere centrata sullo zero. Nel caso di parametri che rappresentano proporzioni, essa potrebbe essere centrata su 0.5.\nTuttavia, ciò che rende queste distribuzioni debolmente informative è la specifica definizione di un intervallo “plausibile” di valori dei parametri. Questo intervallo indica quali valori dei parametri sono considerati plausibili e quali sono invece considerati implausibili. Ad esempio, una distribuzione a priori debolmente informativa potrebbe suggerire che valori estremamente grandi o estremamente bassi dei parametri sono poco plausibili, concentrandosi su un intervallo più stretto di valori considerati ragionevoli.\nIn sintesi, le distribuzioni a priori debolmente informative sono utilizzate per incorporare informazioni pregresse limitate nei modelli bayesiani, contribuendo a stabilizzare le stime dei parametri senza influenzare in modo significativo le conclusioni derivate dai dati. Queste distribuzioni definiscono un intervallo plausibile di valori dei parametri, aiutando a guidare l’analisi verso soluzioni più verosimili senza imporre vincoli eccessivi sui risultati.\nDistribuzioni a Priori Informativa. Le conoscenze pregresse, acquisite attraverso ricerche precedenti, pareri esperti o una combinazione di entrambi, possono essere meticolosamente integrate nel processo di analisi mediante l’incorporazione nelle distribuzioni a priori. Queste distribuzioni sono comunemente conosciute come distribuzioni a priori informative. Esse rappresentano un mezzo per codificare in modo sistematico informazioni concrete e rilevanti che possono avere un notevole impatto sull’analisi statistica, fornendo una solida base di conoscenza su cui fondare l’inferenza bayesiana.\nLe distribuzioni a priori informative possono derivare da una vasta gamma di fonti, comprese ricerche pregresse, pareri di esperti nel campo e altre fonti affidabili. Questo approccio offre un metodo strutturato per integrare in modo coerente le conoscenze pregresse nel processo di analisi statistica. L’incorporazione di queste informazioni aggiuntive contribuisce notevolmente a migliorare la robustezza e l’accuratezza delle conclusioni derivate dai dati, fornendo una solida base empirica su cui basare le stime dei parametri del modello e le decisioni basate sull’analisi bayesiana.\nNell’ambito della ricerca psicologica, l’utilizzo di distribuzioni a priori informative è attualmente poco diffuso, tuttavia emergono segnali che all’interno della comunità statistica sta crescendo l’interesse per questa pratica, considerandola come un avanzamento promettente nel campo della data science.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#limportanza-della-prior-in-base-ai-dati",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#limportanza-della-prior-in-base-ai-dati",
    "title": "46  L’influenza della distribuzione a priori",
    "section": "46.4 L’importanza della Prior in base ai Dati",
    "text": "46.4 L’importanza della Prior in base ai Dati\nUn aspetto cruciale da considerare è che l’influenza della prior diminuisce all’aumentare del numero di dati osservati. In altre parole, con un numero infinito di dati, la verosimiglianza diventa estremamente precisa (o “affilata”), rendendo la scelta della prior irrilevante, a patto che la prior non assegni probabilità zero a regioni dello spazio parametri dove la verosimiglianza è positiva.\nTuttavia, la prior assume un’importanza fondamentale quando si lavora con dataset di piccole dimensioni. In questi casi, la distribuzione a priori può avere un’influenza significativa sulle stime, poiché i dati da soli non sono sufficienti per ottenere stime precise.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#effetti-del-cambiamento-di-scala-dei-parametri",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#effetti-del-cambiamento-di-scala-dei-parametri",
    "title": "46  L’influenza della distribuzione a priori",
    "section": "46.5 Effetti del Cambiamento di Scala dei Parametri",
    "text": "46.5 Effetti del Cambiamento di Scala dei Parametri\nUn altro aspetto da tenere a mente è che le priors possono cambiare quando si modificano le scale dei parametri. Se un parametro viene riscalato, ad esempio passando da metri a chilometri, anche la prior deve essere riscalata di conseguenza per mantenere la coerenza dell’inferenza.\n\n46.5.1 Scala e invariabilità della scelta delle distribuzioni a priori\nLa scelta delle distribuzioni a priori non informative non è sempre banale e non può sempre essere rappresentata da una prior piatta. Per capire questo concetto, è fondamentale comprendere il ruolo della scala. Vediamo un esempio per chiarire meglio questo aspetto.\nImmaginiamo di avere un dataset che contiene la media dei diametri di alcuni alberi, e vogliamo stimare la media di questi diametri utilizzando un metodo bayesiano. Prima di osservare i dati, dobbiamo specificare la nostra distribuzione a priori, poiché non vogliamo che i dati influenzino la nostra scelta. Supponiamo di scegliere una distribuzione a priori piatta tra 1 cm e 10 cm, per evitare di introdurre bias:\n\n# Creazione di un vettore da 1 a 5\nvalori &lt;- 1:5\n# Creazione di un vettore di 5 elementi, tutti uguali a 1/5\npesoPrior &lt;- rep(1/5, 5)\n# Mostra i risultati\npesoPrior\n#&gt; [1] 0.2 0.2 0.2 0.2 0.2\n\nIn questo caso, stiamo assegnando la stessa probabilità a ciascun diametro compreso tra 1 e 10 cm, senza dare più peso a un valore rispetto a un altro. Questa sembra una scelta ragionevole e “non informativa”, poiché non stiamo preferendo nessun diametro in particolare.\nOra, supponiamo di voler modificare leggermente la nostra analisi e di misurare la grandezza degli alberi in termini di area basale (cioè la sezione trasversale dell’albero alla base), che è proporzionale al quadrato del diametro (cioè \\(x^2\\)). Poiché abbiamo già specificato la nostra distribuzione a priori in termini di diametro, dovremmo trasformare questa distribuzione in modo coerente con la nuova scala (area basale).\nIl problema che emerge è il seguente: quando riscaliamo l’asse \\(x\\) per riflettere l’area basale (cioè, passiamo da cm a cm\\(^2\\)), i valori più grandi diventano più ampi (poiché l’area cresce con il quadrato del diametro), mentre i valori più piccoli diventano più stretti. Se vogliamo mantenere la stessa distribuzione a priori in termini di probabilità, dobbiamo modificare il peso di ciascun valore.\nDi conseguenza, una distribuzione a priori che inizialmente era piatta (uguale per tutti i valori di diametro) non rimane piatta dopo la trasformazione in area basale. I valori più grandi ora hanno un peso minore, mentre i valori più piccoli hanno un peso maggiore. Questo dimostra che una distribuzione a priori non può essere piatta per tutte le possibili trasformazioni dei parametri.\n\n\n46.5.2 Il concetto di invariabilità della scala\nUna delle chiavi per definire correttamente le distribuzioni a priori non informative è l’invariabilità rispetto alle trasformazioni dei parametri. Se possiamo scegliere liberamente come rappresentare i parametri (ad esempio, in termini di diametro o area basale), la nostra distribuzione a priori dovrebbe essere definita in modo che sia coerente indipendentemente dalla scala scelta.\n\n\n46.5.3 Attenzione alle trasformazioni dei parametri\nUn secondo messaggio importante riguarda la cautela nelle trasformazioni dei parametri nell’analisi bayesiana. Quando cambiamo i parametri del nostro modello, non stiamo semplicemente osservando un singolo valore, ma una distribuzione intera. La forma di questa distribuzione può cambiare notevolmente con la trasformazione dei parametri.\nAd esempio, se si sta conducendo uno studio psicologico e si vuole misurare un parametro legato alla gravità di un disturbo (ad esempio, la gravità della depressione su una scala numerica), e poi si decide di trasformare la scala in un’unità diversa (ad esempio, un punteggio quadratico per evidenziare differenze estreme), la distribuzione a priori che sembrava ragionevole prima della trasformazione potrebbe non esserlo più dopo. Questo significa che bisogna prestare attenzione a come si scelgono le priors e come queste si comportano sotto diverse rappresentazioni del problema.\nIn conclusione, la scelta delle distribuzioni a priori non può essere fatta superficialmente. Deve essere considerata con attenzione, tenendo conto delle possibili trasformazioni dei parametri e assicurandosi che le priors siano coerenti rispetto alla scala scelta. Questo rende evidente che le priors non informative non sono sempre piatte, e la loro scelta deve tenere conto della struttura del problema e delle variabili coinvolte.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#scelte-predefinite-per-le-distribuzioni-a-priori-non-informative",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#scelte-predefinite-per-le-distribuzioni-a-priori-non-informative",
    "title": "46  L’influenza della distribuzione a priori",
    "section": "46.6 Scelte predefinite per le distribuzioni a priori non informative",
    "text": "46.6 Scelte predefinite per le distribuzioni a priori non informative\nUna delle domande più ricorrenti nell’inferenza bayesiana riguarda la scelta delle distribuzioni a priori non informative. La risposta, però, è piuttosto complessa: non esiste una soluzione generalmente accettata. Questo è particolarmente importante perché, mentre le priors informative possono essere basate su conoscenze pregresse, una prior non informativa deve essere scelta con cura per evitare di influenzare eccessivamente i risultati.\nUna delle proposte più famose, che soddisfa molte delle proprietà desiderabili, è la prior di Jeffreys, definita come:\n\\[\np(\\phi) \\propto \\sqrt{ \\det (F(\\phi)) },\n\\]\ndove \\(F(\\phi)\\) è la matrice di informazione di Fisher, che misura quanto la verosimiglianza cambia quando variano i parametri. La prior di Jeffreys ha due caratteristiche fondamentali:\n\nInvarianza rispetto alla riscalatura dei parametri: Ciò significa che se trasformiamo la scala del parametro, la prior si adatta automaticamente, rimanendo coerente con il problema.\nProporzionalità all’influenza dei parametri sulla verosimiglianza: Parametri che influenzano maggiormente la verosimiglianza hanno una prior più informativa.\n\nQuesti aspetti sembrano coprire molti dei criteri comunemente accettati per la scelta delle distribuzioni a priori non informative. Tuttavia, la prior di Jeffreys presenta alcuni problemi nei modelli multivariati e gerarchici, il che limita la sua applicabilità come soluzione universale.\n\n46.6.1 Scelte predefinite comuni per le priors non informative\nNonostante le difficoltà legate alla prior di Jeffreys, sono emerse alcune scelte predefinite comuni per le priors non informative, basate su intuizioni derivanti proprio da questa distribuzione. Di seguito sono elencate alcune di queste scelte:\n\nParametri di scala (es. coefficiente angolare o intercetta in una regressione):\n\nPer i parametri di scala, che influenzano l’output in modo lineare, si utilizzano comunemente priors piatte o quasi piatte. Queste possono essere distribuzioni uniformi con limiti fissati o, più comunemente, una distribuzione normale ampia.\nUn esempio di prior modificata è l’uso di una normalità centrata su un valore neutro, come 0, per ottenere l’analogo bayesiano della regressione Lasso o Ridge, che introduce una penalizzazione sui parametri (Park & Casella, 2008; Kyung et al., 2010).\n\nSe questa penalizzazione è lieve, si parla di priors debolmente regolarizzanti.\nSe è forte, si parla di priors di riduzione (shrinkage), che possono essere fisse o adattative:\n\nShrinkage fisso: la forza della riduzione (ad es. controllata dalla deviazione standard nella prior normale) rimane costante.\nShrinkage adattativo: la prior di riduzione si adatta tramite un iperparametro (hyperprior), il che consente al modello di decidere autonomamente la forza della riduzione.\n\n\n\nParametri di varianza (es. la deviazione standard in una regressione lineare):\n\nPer i parametri di varianza, si utilizzano spesso priors che decrescono all’aumentare del valore. Un esempio classico è la prior di Jeffrey’s, che per la varianza assume la forma \\(1/x\\), oppure la distribuzione inversa-gamma, molto comune per via della sua proprietà di coniugazione, che semplifica il calcolo bayesiano.\n\nIperparametri di varianza nei modelli gerarchici:\n\nNei modelli gerarchici, gli iperparametri di varianza vengono trattati con priors decrescenti come l’inversa-gamma o la distribuzione half-t (Gelman, 2006). Queste priors sono progettate per gestire la varianza tra gruppi in modo efficace.\n\nDistribuzioni binomiali:\n\nPer una distribuzione binomiale, la prior di Jeffreys corrisponde a una distribuzione Beta(1/2, 1/2), che è considerata una buona scelta predefinita non informativa. Questo tipo di prior assegna un peso equo alle possibili probabilità di successo, riflettendo una distribuzione equilibrata senza favorire un particolare risultato.\n\n\n\n\n46.6.2 Attenzione alle trasformazioni dei parametri\nUn aspetto importante da considerare nell’uso delle priors non informative è che la loro forma può cambiare significativamente in seguito a trasformazioni dei parametri. Per esempio, passando dalla scala lineare alla scala quadratica di un parametro, la prior può assumere una forma diversa e introdurre involontariamente un bias. Pertanto, è essenziale prestare attenzione a come i parametri sono scalati e trasformati nel modello.\n\n\n46.6.3 Analisi di sensibilità\nInfine, quando si è incerti sulla scelta della prior, un buon approccio consiste nel condurre un’analisi di sensibilità. Questa tecnica prevede di variare la prior e osservare come ciò influenzi i risultati. Se i risultati sono robusti rispetto a diverse scelte di prior, ciò suggerisce che la prior scelta non sta influenzando in modo eccessivo l’inferenza finale. Questo è particolarmente utile nei casi in cui si dispone di pochi dati, situazione in cui la prior può avere un impatto maggiore.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#priori-coniugate",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#priori-coniugate",
    "title": "46  L’influenza della distribuzione a priori",
    "section": "46.7 Priori coniugate",
    "text": "46.7 Priori coniugate\nUna distribuzione a priori è detta coniugata rispetto a una funzione di verosimiglianza se la distribuzione a posteriori risultante ha la stessa forma funzionale della distribuzione a priori. In altre parole, la distribuzione a priori e quella a posteriori appartengono alla stessa famiglia di distribuzioni. Questo è particolarmente utile perché, quando si usano priori coniugate, si ottiene una distribuzione a posteriori che può essere espressa in forma chiusa, rendendo possibile risolverla analiticamente.\nUn esempio tipico è quello delle funzioni di verosimiglianza appartenenti alla famiglia esponenziale, per le quali esiste sempre una distribuzione a priori coniugata. Questo è uno dei motivi per cui le distribuzioni della famiglia esponenziale sono così rilevanti: in modelli semplici, l’uso di una prior coniugata consente di ottenere una soluzione analitica per la distribuzione a posteriori, noto come modello coniugato-esponenziale.\nTradizionalmente, si preferiva specificare priori coniugate quando possibile, proprio per la semplicità analitica che garantivano. Tuttavia, l’importanza delle priors coniugate è diminuita con l’evoluzione dei metodi di campionamento. Oggi, la maggior parte dei campionatori moderni (come i metodi MCMC) non richiede più la coniugazione per funzionare in modo efficiente, e l’uso di priors non coniugate è diventato comune senza compromettere la qualità delle stime.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#simulazioni",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#simulazioni",
    "title": "46  L’influenza della distribuzione a priori",
    "section": "46.8 Simulazioni",
    "text": "46.8 Simulazioni\nIn questa sezione, esploriamo come le distribuzioni a priori influenzano la distribuzione a posteriori attraverso una serie di simulazioni. La formula di Bayes, \\(p(\\theta \\mid y) \\propto p(\\theta) \\times p(y \\mid \\theta)\\), evidenzia come la distribuzione a posteriori sia il risultato della combinazione tra la distribuzione a priori e la funzione di verosimiglianza basata sui dati osservati. Se abbiamo le valutazioni puntuali della verosimiglianza e della distribuzione a priori, possiamo moltiplicarle punto per punto per ottenere la distribuzione a posteriori.\n\n46.8.1 Verosimiglianza Binomiale con Distribuzioni a Priori Arbitrari\nConsideriamo un caso in cui la verosimiglianza è binomiale, ma utilizziamo distribuzioni a priori non coniugate. Supponiamo che i dati consistano in 6 successi su 9 prove di tipo bernoulliano. Confronteremo l’effetto di tre distribuzioni a priori diverse sulla distribuzione a posteriori e analizzeremo come ciascuna influisce sull’inferenza finale.\n\n46.8.1.1 Creazione della Griglia e Calcolo della Verosimiglianza\nIniziamo definendo una griglia di valori per \\(\\theta\\) e calcolando la verosimiglianza a ciascun punto della griglia.\n\n# Dati\nsuccess &lt;- 6\ntosses &lt;- 9\n\n# Griglia di valori per theta\ngrid_points &lt;- 100\np_grid &lt;- seq(0, 1, length.out = grid_points)\n\n# Verosimiglianza binomiale\nlikelihood &lt;- dbinom(success, tosses, p_grid)\n\n\n\n46.8.1.2 Funzione per Calcolare e Visualizzare la Posteriori\nDefiniamo una funzione che calcola la distribuzione a posteriori in base alla verosimiglianza e al priore fornito. La funzione visualizza anche il priore, la verosimiglianza e la distribuzione a posteriori.\n\ncomputePosterior &lt;- function(likelihood, prior, p_grid) {\n  # Calcolo della distribuzione a posteriori non normalizzata\n  unstd_posterior &lt;- likelihood * prior\n  \n  # Normalizzazione\n  posterior &lt;- unstd_posterior / sum(unstd_posterior)\n  \n  # Visualizzazione\n  par(mfrow = c(1, 3))\n  plot(\n    p_grid, \n    prior, \n    type = \"l\", \n    main = \"Prior\", \n    xlab = expression(theta), \n    ylab = \"Densità\"\n  )\n  plot(\n    p_grid, \n    likelihood, \n    type = \"l\", \n    main = \"Likelihood\", \n    xlab = expression(theta), \n    ylab = \"Densità\"\n  )\n  plot(\n    p_grid, \n    posterior, \n    type = \"l\", \n    main = \"Posterior\", \n    xlab = expression(theta), \n    ylab = \"Densità\"\n  )\n  \n  return(posterior)\n}\n\n\n\n\n\n46.8.2 Esempio 1: Priore Uniforme\nIl nostro primo priore è una distribuzione uniforme: \\(p(\\theta) = 1\\). Questo riflette una completa mancanza di informazioni a priori sulla probabilità di successo \\(\\theta\\).\n\n# Priore uniforme\nprior1 &lt;- rep(1, grid_points)\n\n# Calcolo e visualizzazione della distribuzione a posteriori\nposterior1 &lt;- computePosterior(likelihood, prior1, p_grid)\n\n\n\n\n\n\n\n\nCome previsto, la distribuzione a posteriori coincide con la verosimiglianza (a parte un fattore di scala), poiché non abbiamo aggiunto informazioni.\n\n\n\n46.8.3 Esempio 2: Priore a Gradino\nIl secondo priore è una funzione a gradino che riflette la convinzione che \\(\\theta\\) sia almeno \\(0.5\\). Questo priore esprime la credenza che il successo (“testa”) sia più probabile, ma non specifica di quanto.\n\n# Priore a gradino\nprior2 &lt;- ifelse(p_grid &gt;= 0.5, 1, 0)\n\n# Calcolo e visualizzazione della distribuzione a posteriori\nposterior2 &lt;- computePosterior(likelihood, prior2, p_grid)\n\n\n\n\n\n\n\n\nLa distribuzione a posteriori risultante esclude completamente i valori di \\(\\theta\\) inferiori a 0.5, coerentemente con le ipotesi del priore.\n\n\n\n46.8.4 Esempio 3: Priore Esponenziale\nIl terzo priore è una distribuzione centrata su 0.5, con un rapido decadimento esponenziale su entrambi i lati. Questo priore riflette la convinzione che \\(\\theta\\) sia vicina a 0.5.\n\n# Priore esponenziale\nprior3 &lt;- exp(-5 * abs(p_grid - 0.5))\n\n# Calcolo e visualizzazione della distribuzione a posteriori\nposterior3 &lt;- computePosterior(likelihood, prior3, p_grid)\n\n\n\n\n\n\n\n\nQuesto priore “attrare” la distribuzione a posteriori verso 0.5, a meno che i dati non forniscano evidenze contrarie molto forti.\n\n\n\n46.8.5 Analisi del Modello Beta-Binomiale\nConsideriamo ora il caso coniugato, in cui il priore è una distribuzione Beta e i dati seguono una distribuzione Binomiale.\nDefiniamo una funzione per visualizzare le distribuzioni del modello Beta-Binomiale: priore, verosimiglianza e posteriore.\n\nplot_beta_binomial &lt;- function(alpha, beta, y = NULL, n = NULL) {\n  # Griglia di valori per theta\n  theta &lt;- seq(0, 1, length.out = 100)\n  \n  # Priore\n  prior_density &lt;- dbeta(theta, alpha, beta)\n  \n  # Verosimiglianza scalata\n  if (!is.null(y) && !is.null(n)) {\n    likelihood &lt;- dbinom(y, n, theta)\n    scaled_likelihood &lt;- likelihood / max(likelihood)\n    posterior_alpha &lt;- alpha + y\n    posterior_beta &lt;- beta + n - y\n    posterior_density &lt;- dbeta(theta, posterior_alpha, posterior_beta)\n  }\n  \n  # Grafico\n  plot(\n    theta, \n    prior_density, \n    type = \"l\", \n    col = \"blue\", \n    ylim = c(0, max(prior_density, posterior_density)), \n    main = \"Beta-Binomial Model\", \n    xlab = expression(theta), \n    ylab = \"Density\"\n  )\n  if (!is.null(y) && !is.null(n)) {\n    lines(theta, scaled_likelihood, col = \"orange\", lwd = 2)\n    lines(theta, posterior_density, col = \"green\", lwd = 2)\n    legend(\n      \"topright\", \n      legend = c(\"Prior\", \"Likelihood (scaled)\", \"Posterior\"), \n      col = c(\"blue\", \"orange\", \"green\"), \n      lty = 1, \n      bty = \"n\")\n  }\n}\n\n\n46.8.5.1 Priore Uniforme\n\nplot_beta_binomial(alpha = 1, beta = 1, y = 15, n = 20)\n\n\n\n\n\n\n\n\n\n\n46.8.5.2 Priore Informativo (Beta(2, 2))\n\nplot_beta_binomial(alpha = 2, beta = 2, y = 15, n = 20)\n\n\n\n\n\n\n\n\n\n\n46.8.5.3 Priore Fortemente Informativo (Beta(2, 5))\n\nplot_beta_binomial(alpha = 2, beta = 5, y = 15, n = 20)\n\n\n\n\n\n\n\n\nIn conclusione, abbiamo esplorato come i priori influenzano la distribuzione a posteriori in contesti binomiali, dimostrando che l’influenza del priore è maggiore nei campioni piccoli e diminuisce con campioni di grandi dimensioni. L’analisi bayesiana consente un’integrazione flessibile delle conoscenze pregresse con i dati osservati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#connessione-tra-intuizioni-e-teoria",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#connessione-tra-intuizioni-e-teoria",
    "title": "46  L’influenza della distribuzione a priori",
    "section": "46.9 Connessione tra Intuizioni e Teoria",
    "text": "46.9 Connessione tra Intuizioni e Teoria\nL’equilibrio tra la distribuzione a priori e le evidenze provenienti dai dati, come dimostrato negli esempi precedenti, non solo rispecchia le nostre intuizioni, ma rappresenta anche una necessità matematica. Questo concetto diventa chiaro esaminando la formula del valore atteso della distribuzione a posteriori nel contesto del caso beta-binomiale, che può essere riscritta come segue:\n\\[\n\\begin{align}\n\\mathbb{E}_{\\text{post}} &[\\text{Beta}(\\alpha + y, \\beta + n - y)] = \\frac{\\alpha + y}{\\alpha + \\beta + n} \\\\\n&= \\frac{a+b}{a+b+n} \\cdot \\frac{a}{a+b} + \\frac{n}{a+b+n} \\cdot \\frac{y}{n}.\n\\end{align}\n\\]\nL’equazione precedente rivela che il valore atteso a posteriori si ottiene come una media ponderata tra il valore atteso a priori \\(\\left( \\frac{\\alpha}{\\alpha+\\beta}\\right)\\) e la proporzione osservata dei successi \\(\\left(\\frac{y}{n}\\right)\\). I pesi sono dati da \\(\\left( \\frac{\\alpha+\\beta}{\\alpha+\\beta+n}\\right)\\) e \\(\\left( \\frac{n}{\\alpha+\\beta+n}\\right)\\). Pertanto, quando il numero di osservazioni \\(n\\) è significativo rispetto alla somma dei parametri \\(\\alpha + \\beta\\), la distribuzione a posteriori sarà principalmente influenzata dai dati osservati e in minor misura dalle credenze a priori. Al contrario, se \\(n\\) è piccolo rispetto a \\(\\alpha + \\beta\\), i dati avranno un peso inferiore rispetto alle credenze a priori.\nQueste considerazioni indicano come scegliere i parametri \\(\\alpha\\) e \\(\\beta\\): se desideriamo rappresentare una totale ignoranza sul fenomeno, una scelta coerente è \\(\\alpha = \\beta = 1\\) (attribuiamo uguale credibilità a ogni valore di \\(\\theta\\)). Se, invece, possediamo forti credenze a priori, possiamo selezionare \\(\\alpha\\) in modo da eguagliare il valore atteso a priori, mentre \\(\\alpha + \\beta\\) rifletterà l’importanza attribuita all’informazione a priori: maggiore è il valore di \\(\\alpha + \\beta\\), maggiore sarà il numero di dati necessari per influenzare significativamente la distribuzione a posteriori rispetto a quella a priori. In situazioni in cui \\(n\\) è considerevolmente grande, la distribuzione a posteriori avrà un impatto ridotto sulla distribuzione a priori, a meno che non si facciano scelte estreme per i parametri a priori.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#conflitto-tra-prior-e-verosimiglianza",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#conflitto-tra-prior-e-verosimiglianza",
    "title": "46  L’influenza della distribuzione a priori",
    "section": "46.10 Conflitto tra Prior e Verosimiglianza",
    "text": "46.10 Conflitto tra Prior e Verosimiglianza\nEsaminiamo ora un altro esempio proposto da McElreath:\n\nLesson: Don’t trust intuition, for even simple prior+likelihood scenarios defy it. Four examples below, each producing radically different posteriors. Can you guess what each does?\n\n\nNella figura successiva vediamo la risposta alla domanda precedente.\n\nMcElreath descrive le caratteristiche di quattro diversi modelli in cui si combinano distribuzioni normali (Gaussiane) e Student-t (con 2 gradi di libertà) per il prior e la likelihood. La distribuzione gaussiana ha code molto sottili, mentre quella di Student-t ha code più spesse.\n\nIn Alto a Sinistra: Prior Normale, Likelihood Normale\n\ny ~ Normal(mu,1)\nmu ~ Normal(10,1)\n\nIn questo scenario classico di aggiornamento bayesiano, il posterior risulta essere un compromesso tra il prior e la likelihood. La distribuzione normale, con le sue code sottili, contribuisce a un aggiornamento più “prevedibile” e concentrato attorno al valore medio.\nIn Alto a Destra: Prior Student, Likelihood Student (df=2)\n\ny ~ Student(2,mu,1)\nmu ~ Student(2,10,1)\n\nIn questo caso, entrambe le distribuzioni hanno code più spesse. La presenza di “extra massa” nelle code significa che ciascuna distribuzione trova il modo dell’altra più plausibile, portando a una media che non rappresenta il miglior “compromesso”. Questo scenario risulta in una maggiore incertezza e un posterior meno definito.\nIn Basso a Sinistra: Prior Student, Likelihood Normale\n\ny ~ Normal(mu,1)\nmu ~ Student(2,10,1)\n\nQui, la likelihood normale, con le sue code sottili, tende a dominare. Essa è molto scettica nei confronti del prior con code spesse, ma il prior di Student-t non è sorpreso dalla likelihood. Questo porta a un posterior che è più influenzato dalla likelihood normale.\nIn Basso a Destra: Prior Normale, Likelihood Student\n\ny ~ Student(2,mu,1)\nmu ~ Normal(10,1)\n\nIn questo ultimo scenario, è il prior normale a dominare. Il ragionamento è simile a quello del caso precedente, ma in senso inverso. Il prior normale, con le sue code sottili, impone una maggiore influenza sul posterior, rendendolo meno influenzato dalle code più spesse della likelihood di Student-t.\n\nIn sintesi, la combinazione di queste due distribuzioni in diversi modi porta a risultati di aggiornamento bayesiano molto differenti, a seconda di quale tra prior e likelihood abbia le code più spesse e quindi eserciti una maggiore influenza sul posterior.\nIn conclusione, questo esercizio mostra come, ad eccezione del caso gaussiano, i risultati non sono affatto intuitivi. Pertanto, in contesti come questi, affidarsi esclusivamente alle proprie intuizioni non è una scelta consigliabile. È invece fondamentale procedere con l’esecuzione dei calcoli.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#riflessioni-conclusive",
    "title": "46  L’influenza della distribuzione a priori",
    "section": "46.11 Riflessioni Conclusive",
    "text": "46.11 Riflessioni Conclusive\nLa scelta della distribuzione a priori è uno degli aspetti più cruciali nell’inferenza bayesiana. Da un lato, le priors non informative possono essere utilizzate per minimizzare l’influenza delle conoscenze pregresse, permettendo ai dati osservati di guidare l’inferenza. Dall’altro, le priors informative sono estremamente utili quando si dispone di informazioni affidabili sui parametri, consentendo una stima più precisa. È importante ricordare che, con un gran numero di dati, l’influenza della prior tende a ridursi, mentre nei contesti con pochi dati la scelta della prior può avere un impatto significativo.\nUn aspetto essenziale dell’approccio bayesiano, come evidenziato nell’esempio di Johnson (2022), è che il processo di aggiornamento bayesiano riflette il modo in cui le persone ragionano intuitivamente: di fronte a evidenze deboli, le credenze rimangono stabili, mentre nuove informazioni robuste portano a un aggiornamento significativo delle credenze. Questo meccanismo formalizza in modo quantitativo e rigoroso le intuizioni che utilizziamo quotidianamente. Al contrario, l’approccio frequentista ignora le conoscenze pregresse, il che può portare a cambiamenti nelle inferenze senza tener conto delle credenze già esistenti.\nTuttavia, come evidenziato dagli esempi di McElreath, la situazione può essere più complessa nei modelli non coniugati, dove l’intuizione può fallire nel prevedere correttamente la distribuzione a posteriori. Questo ci ricorda che il contesto e la struttura del modello giocano un ruolo determinante nell’inferenza bayesiana.\n\n46.11.1 Il Ruolo della Prior nella Regolarizzazione\nNel contesto bayesiano, le distribuzioni a priori debolmente informative fungono da meccanismo di regolarizzazione, limitando l’influenza delle osservazioni estreme e garantendo inferenze più stabili. Questo approccio è ormai ampiamente accettato nella comunità statistica, poiché permette di ottenere risultati più prudenti senza introdurre un forte bias.\n\n\n46.11.2 L’Importanza dei Prior Informativi\nNegli ultimi anni, l’uso di priori informativi ha guadagnato maggiore attenzione, soprattutto grazie all’integrazione delle conoscenze esperte nel processo inferenziale. Questa pratica, nota come elicitazione della conoscenza esperta, richiede un rigoroso approccio metodologico per evitare bias cognitivi e assicurare che le informazioni pregresse siano incorporate in modo accurato. Questo è particolarmente rilevante in campi come la psicologia, dove spesso la base teorica è incerta, e l’elicitazione esperta può contribuire a migliorare la solidità delle analisi bayesiane (O’Hagan, 2019).\n\n\n46.11.3 Conclusioni Finali\nIn conclusione, la scelta delle prior deve essere ponderata attentamente in base alla disponibilità di dati e al contesto dell’analisi. Sebbene l’uso di priors non informative possa sembrare una scelta “neutra”, è spesso sub-ottimale. Le priors debolmente informative rappresentano lo standard attuale, poiché favoriscono un’inferenza più robusta grazie alla loro capacità di regolarizzare l’influenza dei dati. Infine, l’uso di priori informativi, sviluppati attraverso protocolli rigorosi di elicitazione esperta, è una frontiera in crescita nell’analisi bayesiana, poiché consente di sfruttare al meglio le conoscenze pregresse per migliorare la qualità delle inferenze e ridurre l’incertezza.\nQuesto approccio, che bilancia conoscenza pregressa e nuovi dati, permette di sviluppare modelli bayesiani più solidi e informati, riflettendo accuratamente sia l’incertezza sia la competenza specifica del dominio di studio.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#informazioni-sullambiente-di-sviluppo",
    "title": "46  L’influenza della distribuzione a priori",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.17.0       MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2\n#&gt;  [5] ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0  \n#&gt;  [9] bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0      markdown_1.13    \n#&gt; [13] knitr_1.49        lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1    \n#&gt; [17] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#&gt; [21] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [25] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1  farver_2.1.2      fastmap_1.2.0     pacman_0.5.1     \n#&gt;  [5] promises_1.3.2    rpart_4.1.23      digest_0.6.37     timechange_0.3.0 \n#&gt;  [9] mime_0.12         lifecycle_1.0.4   survival_3.7-0    magrittr_2.0.3   \n#&gt; [13] compiler_4.4.2    rlang_1.1.4       tools_4.4.2       utf8_1.2.4       \n#&gt; [17] yaml_2.3.10       ggsignif_0.6.4    htmlwidgets_1.6.4 mnormt_2.1.1     \n#&gt; [21] abind_1.4-8       miniUI_0.1.1.1    withr_3.0.2       nnet_7.3-19      \n#&gt; [25] grid_4.4.2        fansi_1.0.6       jomo_2.7-6        xtable_1.8-4     \n#&gt; [29] colorspace_2.1-1  iterators_1.0.14  cli_3.6.3         rmarkdown_2.29   \n#&gt; [33] generics_0.1.3    tzdb_0.4.0        minqa_1.2.8       splines_4.4.2    \n#&gt; [37] parallel_4.4.2    vctrs_0.6.5       boot_1.3-31       glmnet_4.1-8     \n#&gt; [41] Matrix_1.7-1      jsonlite_1.8.9    carData_3.0-5     car_3.1-3        \n#&gt; [45] hms_1.1.3         mitml_0.4-5       rstatix_0.7.2     Formula_1.2-5    \n#&gt; [49] foreach_1.5.2     glue_1.8.0        pan_1.9           nloptr_2.1.1     \n#&gt; [53] codetools_0.2-20  stringi_1.8.4     gtable_0.3.6      shape_1.4.6.1    \n#&gt; [57] later_1.4.1       lme4_1.1-35.5     munsell_0.5.1     pillar_1.9.0     \n#&gt; [61] htmltools_0.5.8.1 R6_2.5.1          rprojroot_2.0.4   evaluate_1.0.1   \n#&gt; [65] shiny_1.9.1       lattice_0.22-6    backports_1.5.0   broom_1.0.7      \n#&gt; [69] httpuv_1.6.15     Rcpp_1.0.13-1     nlme_3.1-166      xfun_0.49        \n#&gt; [73] pkgconfig_2.0.3",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#bibliografia",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#bibliografia",
    "title": "46  L’influenza della distribuzione a priori",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nGelman, A. (2006). Prior distributions for variance parameters in hierarchical models (comment on article by Browne and Draper). Bayesian Analysis, 1(3), 515–534. https://doi.org/10.1214/06-BA117A\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nO’Hagan, A. (2019). Expert knowledge elicitation: subjective but scientific. The American Statistician, 73(sup1), 69–81.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_gamma_poisson_model.html",
    "href": "chapters/bayesian_inference/09_gamma_poisson_model.html",
    "title": "47  Modello coniugato Gamma-Poisson",
    "section": "",
    "text": "47.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nIn psicologia, le variabili di conteggio (\\(y\\)), che indicano il numero di occorrenze di un evento, trovano ampio impiego in diversi ambiti. Ad esempio, sono usate per quantificare la frequenza dei sintomi di un disturbo o per analizzare le frequenze delle parole negli studi di psicolinguistica. Queste variabili, assumendo valori discreti, richiedono modelli statistici specifici.\nQuesto capitolo si focalizza sulla stima del tasso medio di incidenza (\\(\\lambda_i\\)) di tali eventi, ovvero sul numero medio di occorrenze per unità di misura. Adotteremo un approccio bayesiano, utilizzando il modello di Poisson per descrivere la distribuzione di probabilità delle variabili di conteggio. In particolare, esploreremo la derivazione analitica della distribuzione a posteriori del parametro \\(\\lambda_i\\), considerando una distribuzione a priori Gamma. Successivamente, verificheremo la validità dei risultati analitici mediante simulazioni Monte Carlo.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_gamma_poisson_model.html#distribuzione-di-poisson",
    "href": "chapters/bayesian_inference/09_gamma_poisson_model.html#distribuzione-di-poisson",
    "title": "47  Modello coniugato Gamma-Poisson",
    "section": "47.2 Distribuzione di Poisson",
    "text": "47.2 Distribuzione di Poisson\nLa distribuzione di Poisson è un modello probabilistico utilizzato per descrivere il numero di eventi che si verificano in un intervallo di tempo o spazio fisso, partendo dall’assunto che tali eventi si verifichino con una frequenza media costante e in modo indipendente rispetto al tempo trascorso dall’ultimo evento. Se un dato \\(y\\) segue una distribuzione di Poisson con parametro \\(\\lambda\\), allora la probabilità di osservare un singolo valore \\(y_i\\) è data da:\n\\[\nf(y_i \\mid \\lambda) = \\frac{e^{-\\lambda} \\lambda^{y_i}}{y_i!},\n\\]\ndove \\(\\lambda &gt; 0\\) rappresenta la frequenza media di occorrenza degli eventi e \\(y_i\\) è il numero di eventi osservati. La distribuzione di Poisson ha la caratteristica che sia il valore atteso che la varianza di una variabile casuale \\(Y\\) che segue questa distribuzione sono pari a \\(\\lambda\\), cioè \\(E(Y) = \\lambda\\) e \\(\\text{Var}(Y) = \\lambda\\).\n\n47.2.1 Simulazione\nPer capire meglio come funziona la distribuzione di Poisson, immaginiamo un paziente con un disturbo ossessivo-compulsivo. Supponiamo che in media questo paziente ripeta un’azione compulsiva 2 volte ogni ora. In questo caso, il parametro della distribuzione di Poisson è λ = 2.\nLa probabilità di osservare esattamente \\(k\\) eventi in un’ora è calcolata dalla formula:\n\\[\nf(k | \\lambda) = \\frac{e^{-\\lambda} \\lambda^k}{k!}.\n\\]\nNel caso specifico con \\(\\lambda = 2\\), le probabilità per i primi valori di \\(k\\) sono:\n\nLa probabilità di osservare 0 eventi in un’ora è \\(\\frac{e^{-2} \\cdot 2^0}{0!} = e^{-2} \\approx 0{.}1353\\).\nLa probabilità di osservare 1 evento in un’ora è \\(\\frac{e^{-2} \\cdot 2^1}{1!} = 2e^{-2} \\approx 0{.}2707\\).\nLa probabilità di osservare 2 eventi in un’ora è \\(\\frac{e^{-2} \\cdot 2^2}{2!} = 2e^{-2} \\approx 0{.}2707\\).\nE così via per \\(k = 3\\), \\(k = 4\\), \\(\\dots\\)\n\nQuesto esempio illustra come la distribuzione di Poisson possa essere utilizzata per modellare il numero di eventi rari che si verificano in un intervallo temporale fisso, con una frequenza media nota.\nSvolgiamo ora i calcoli utilizzando la funzione dpois in R:\n\nlam_true &lt;- 2\n# Creazione di un vettore di valori da 0 a 9\nk_values &lt;- 0:9\n\n# Calcolo delle probabilità per ogni valore in k_values\nprobabilities &lt;- dpois(k_values, lambda = lam_true)\n\n# Stampa delle probabilità\nfor (i in seq_along(k_values)) {\n  cat(sprintf(\"Probabilità di %d eventi: %.4f\\n\", k_values[i], probabilities[i]))\n}\n#&gt; Probabilità di 0 eventi: 0.1353\n#&gt; Probabilità di 1 eventi: 0.2707\n#&gt; Probabilità di 2 eventi: 0.2707\n#&gt; Probabilità di 3 eventi: 0.1804\n#&gt; Probabilità di 4 eventi: 0.0902\n#&gt; Probabilità di 5 eventi: 0.0361\n#&gt; Probabilità di 6 eventi: 0.0120\n#&gt; Probabilità di 7 eventi: 0.0034\n#&gt; Probabilità di 8 eventi: 0.0009\n#&gt; Probabilità di 9 eventi: 0.0002\n\n\n\n47.2.2 Creazione del grafico della funzione di massa di probabilità\nIl seguente codice R genera il grafico della funzione di massa di probabilità (PMF) di una distribuzione di Poisson con parametro \\(\\lambda = 2\\):\n\n# Definiamo il parametro lambda\nlambd &lt;- 2\n\n# Generiamo i valori sull'asse x (numero di eventi)\nx &lt;- 0:9  # Possiamo aumentare o diminuire il range a seconda delle esigenze\n\n# Calcoliamo le probabilità corrispondenti utilizzando la funzione dpois\ny &lt;- dpois(x, lambda = lambd)\n\n# Creiamo il grafico a barre\nbarplot(\n  height = y,\n  names.arg = x,\n  col = \"lightblue\",\n  xlab = \"Numero di eventi\",\n  ylab = \"Probabilità\",\n  main = \"Distribuzione di Poisson (λ = 2)\"\n)",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_gamma_poisson_model.html#verosimiglianza-per-un-campione-di-osservazioni",
    "href": "chapters/bayesian_inference/09_gamma_poisson_model.html#verosimiglianza-per-un-campione-di-osservazioni",
    "title": "47  Modello coniugato Gamma-Poisson",
    "section": "47.3 Verosimiglianza per un Campione di Osservazioni",
    "text": "47.3 Verosimiglianza per un Campione di Osservazioni\nConsideriamo un campione di \\(n\\) osservazioni indipendenti e identicamente distribuite, \\(y_1, y_2, \\dots, y_n\\), tratto da una distribuzione di Poisson con parametro \\(\\lambda\\). La funzione di verosimiglianza \\(f(y \\mid \\lambda)\\) rappresenta la probabilità congiunta di osservare esattamente questi valori dato un particolare valore di \\(\\lambda\\).\nMatematicamente, la verosimiglianza si esprime come:\n\\[\nf(y \\mid \\lambda) = \\prod_{i=1}^{n} \\frac{e^{-\\lambda} \\lambda^{y_i}}{y_i!}\n= \\frac{e^{-n\\lambda} \\lambda^{\\sum_{i=1}^n y_i}}{\\prod_{i=1}^{n} y_i!}.\n\\]\nQuesta funzione misura la compatibilità tra i dati osservati e un dato valore di \\(\\lambda\\). Valori di \\(\\lambda\\) che rendono più alta la verosimiglianza sono quelli che meglio spiegano i dati osservati.\nLa funzione di verosimiglianza descrive quanto sia plausibile un valore specifico di \\(\\lambda\\) dato il campione di dati osservati \\(y_1, y_2, \\dots, y_n\\). Per ogni possibile valore di \\(\\lambda\\), la funzione fornisce una misura della compatibilità tra il valore ipotizzato e i dati. In altre parole, essa risponde alla domanda: quanto bene questo valore di \\(\\lambda\\) spiega i dati osservati?\nPer semplificare i calcoli ed evitare problemi di overflow numerico, è comune utilizzare il logaritmo naturale della funzione di verosimiglianza, chiamato log-verosimiglianza. La log-verosimiglianza per il modello di Poisson si ottiene come:\n\\[\n\\log f(y \\mid \\lambda) = -n\\lambda + \\left(\\sum_{i=1}^n y_i \\right) \\log \\lambda - \\sum_{i=1}^n \\log(y_i!).\n\\]\nL’uso del logaritmo trasforma il prodotto nella somma, facilitando le analisi e la stima dei parametri.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_gamma_poisson_model.html#distribuzione-gamma",
    "href": "chapters/bayesian_inference/09_gamma_poisson_model.html#distribuzione-gamma",
    "title": "47  Modello coniugato Gamma-Poisson",
    "section": "47.4 Distribuzione Gamma",
    "text": "47.4 Distribuzione Gamma\nLa distribuzione Gamma riveste un ruolo centrale nel modello coniugato Gamma-Poisson, poiché funge da distribuzione a priori per il parametro di tasso \\(\\lambda\\) della distribuzione di Poisson. La sua scelta è motivata dalla proprietà di coniugatezza, che consente di ottenere una distribuzione a posteriori appartenente alla stessa famiglia della prior, semplificando significativamente i calcoli inferenziali e aggiornando in modo diretto le credenze alla luce dei dati osservati.\nLa funzione di densità della distribuzione Gamma è definita come:\n\\[\nf(x \\mid \\alpha, \\beta) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} x^{\\alpha - 1} e^{-\\beta x},\n\\]\ndove:\n\n\\(\\alpha\\) (detto parametro di forma) determina la forma della distribuzione: valori più elevati di \\(\\alpha\\) tendono a rendere la distribuzione più simmetrica;\n\\(\\beta\\) (detto parametro di tasso o scala inversa) controlla la scala: valori più elevati di \\(\\beta\\) concentrano maggiormente la massa di probabilità vicino all’origine.\n\nAd esempio:\n\nUna distribuzione Gamma con \\(\\alpha = 2\\) e \\(\\beta = 3\\) rappresenta un processo in cui eventi relativamente rari si verificano occasionalmente.\nUna distribuzione Gamma con \\(\\alpha = 10\\) e \\(\\beta = 1\\) descrive un processo più regolare, con eventi che si verificano con maggiore frequenza e prevedibilità.\n\n\n\n\n\n\n\nNota\n\n\n\nIn R, la parametrizzazione della distribuzione Gamma utilizza direttamente il parametro \\(\\beta\\) come tasso (\\(rate\\)), che è l’inverso del parametro di scala (\\(scale = 1 / \\beta\\)) utilizzato in Scipy.\n\n\nPer calcolare la densità di probabilità in R, si utilizza:\ndgamma(x, shape = alpha, rate = beta)\n\n# Definizione dei parametri\nalpha &lt;- 2\nbeta &lt;- 3\n\n# Generazione dei valori di x\nx &lt;- seq(0, 3, length.out = 500)\n\n# Calcolo della densità di probabilità\npdf &lt;- dgamma(x, shape = alpha, rate = beta)\n\n# Creazione del grafico\nplot(\n  x, pdf,\n  type = \"l\",\n  col = \"blue\",\n  lwd = 2,\n  xlab = \"x\",\n  ylab = \"Densità di probabilità\",\n  main = expression(\"Distribuzione Gamma (\" ~ alpha == 2 ~ \",\" ~ beta == 3 ~ \")\")\n)\ngrid()\n\n\n\n\n\n\n\n\nQuesto grafico mostra la densità di una distribuzione Gamma con \\(\\alpha = 2\\) e \\(\\beta = 3\\), calcolata su un intervallo \\([0, 3]\\).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_gamma_poisson_model.html#metodo-basato-su-griglia",
    "href": "chapters/bayesian_inference/09_gamma_poisson_model.html#metodo-basato-su-griglia",
    "title": "47  Modello coniugato Gamma-Poisson",
    "section": "47.5 Metodo Basato su Griglia",
    "text": "47.5 Metodo Basato su Griglia\nSupponiamo di voler calcolare la distribuzione a posteriori del parametro \\(\\lambda\\) di un modello di Poisson, con una distribuzione a priori Gamma. Utilizziamo un approccio numerico basato sulla discretizzazione dello spazio dei parametri.\nConsideriamo i seguenti dati osservati:\n\n# Dati osservati\ny &lt;- c(2, 1, 3, 2, 2, 1, 1, 1)\n\nAdotteremo questa distribuzione a priori:\n\n# Parametri della distribuzione a priori Gamma\nalpha_prior &lt;- 9\nbeta_prior &lt;- 2\n\n# Griglia dei valori di lambda\nlambda_grid &lt;- seq(0.01, 10, length.out = 1000)\n\n# Calcolo della densità della distribuzione a priori\nprior &lt;- dgamma(lambda_grid, shape = alpha_prior, rate = beta_prior)\n\n# Plot della distribuzione a priori\nplot(\n  lambda_grid, prior, type = \"l\", col = \"blue\",\n  xlab = expression(lambda),\n  ylab = \"Densità di probabilità\",\n  main = \"Distribuzione Gamma a Priori\"\n)\nabline(v = alpha_prior / beta_prior, col = \"red\", lty = 2, lwd = 2)\nabline(v = mean(y), col = \"green\", lty = 2, lwd = 2)\nlegend(\"topright\", legend = c(\"Media Gamma\", \"Media Campionaria\"),\n       col = c(\"red\", \"green\"), lty = 2, lwd = 2)\ngrid()\n\n\n\n\n\n\n\n\nCalcoliamo la verosimiglianza:\n\n# Inizializzazione della verosimiglianza\nlikelihood &lt;- rep(1, length(lambda_grid))\n\n# Calcolo iterativo della verosimiglianza\nfor (yi in y) {\n  likelihood &lt;- likelihood * dpois(yi, lambda = lambda_grid)\n}\n\nCalcoliamo la distribuzione a posteriori non normalizzata:\n\nposterior_unnormalized &lt;- likelihood * prior\n\nNormalizzazione della distribuzione a posteriori:\n\n# Fattore di normalizzazione\nnormalization_factor &lt;- sum(posterior_unnormalized * diff(lambda_grid)[1])\n\n# Distribuzione a posteriori normalizzata\nposterior &lt;- posterior_unnormalized / normalization_factor\n\nCreiamo un grafico delle distribuzioni a priori e a posteriori:\n\nplot(\n  lambda_grid, posterior, type = \"l\", col = \"blue\",\n  xlab = expression(lambda),\n  ylab = \"Densità di probabilità\",\n  main = \"Distribuzione a Posteriori di Lambda\"\n)\nlines(lambda_grid, prior, col = \"red\", lty = 2, lwd = 2)\nlegend(\"topright\", legend = c(\"Posteriori\", \"A Priori\"),\n       col = c(\"blue\", \"red\"), lty = c(1, 2), lwd = 2)\ngrid()\n\n\n\n\n\n\n\n\nIn conclusione,\n\nla distribuzione a posteriori è spostata a sinistra rispetto a quella a priori, indicando che i dati suggeriscono un valore più basso per \\(\\lambda\\).\nla distribuzione a posteriori è più stretta rispetto a quella a priori, indicando una riduzione dell’incertezza.\n\nQuesto approccio numerico consente di esplorare come le osservazioni aggiornano la nostra credenza sul parametro \\(\\lambda\\), evidenziando la potenza del metodo bayesiano.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_gamma_poisson_model.html#modello-coniugato-gamma-poission",
    "href": "chapters/bayesian_inference/09_gamma_poisson_model.html#modello-coniugato-gamma-poission",
    "title": "47  Modello coniugato Gamma-Poisson",
    "section": "47.6 Modello Coniugato Gamma-Poission",
    "text": "47.6 Modello Coniugato Gamma-Poission\nPer calcolare analiticamente la distribuzione a posteriori nel contesto di un modello gamma-Poisson possiamo seguire un processo diretto. Il modello Gamma-Poisson è coniugato, il che significa che la distribuzione a posteriori sarà ancora una distribuzione Gamma.\nSeguendo il teorema di Bayes, possiamo scrivere la distribuzione a posteriori come:\n\\(f(\\lambda \\mid y) \\propto f(y \\mid \\lambda) \\cdot f(\\lambda) ,\\)\ndove \\(f(\\lambda \\mid y)\\) è la distribuzione a posteriori, \\(f(y \\mid \\lambda)\\) è la verosimiglianza e \\(f(\\lambda)\\) è la distribuzione a priori.\nDefiniamo la verosimiglianza (distribuzione di Poisson):\n\\(f(y \\mid \\lambda) = \\prod_{i=1}^n \\frac{e^{-\\lambda}\\lambda^{y_i}}{y_i!} = \\frac{e^{-n\\lambda}\\lambda^{\\sum_{i=1}^n y_i}}{\\prod_{i=1}^n y_i!}.\\)\nDefiniamo la distribuzione a priori (distribuzione Gamma):\n\\(f(\\lambda) = \\frac{b^a}{\\Gamma(a)}\\lambda^{a-1}e^{-b\\lambda}.\\)\nOra, moltiplichiamo la verosimiglianza per la distribuzione a priori:\n\\(f(\\lambda|y) \\propto \\frac{e^{-n\\lambda}\\lambda^{\\sum_{i=1}^n y_i}}{\\prod_{i=1}^n y_i!} \\cdot \\frac{b^a}{\\Gamma(a)}\\lambda^{a-1}e^{-b\\lambda}.\\)\nSemplifichiamo, eliminando i termini costanti (che non dipendono da \\(\\lambda\\)):\n\\(f(\\lambda \\mid y) \\propto e^{-n\\lambda}\\lambda^{\\sum_{i=1}^n y_i} \\cdot \\lambda^{a-1}e^{-b\\lambda}.\\)\nRaggruppiamo i termini:\n\\(f(\\lambda|y) \\propto \\lambda^{\\sum_{i=1}^n y_i} \\cdot \\lambda^{a-1} \\cdot e^{-n\\lambda} \\cdot e^{-b\\lambda}.\\)\nSemplifichiamo ulteriormente:\n\\(f(\\lambda \\mid y) \\propto \\lambda^{\\sum_{i=1}^n y_i + a - 1} \\cdot e^{-(n+b)\\lambda}.\\)\nRiconosciamo che questa è la forma di una distribuzione Gamma con nuovi parametri:\n\\(f(\\lambda \\mid y) \\propto \\lambda^{(\\sum_{i=1}^n y_i + a) - 1} \\cdot e^{-(n+b)\\lambda}.\\)\nQuindi, la distribuzione a posteriori è una Gamma con parametri:\n\n\\(\\alpha_{post} = a + \\sum_{i=1}^n y_i\\),\n\\(\\beta_{post} = b + n\\),\n\ndove:\n\n\\(a\\) e \\(b\\) sono i parametri della distribuzione Gamma a priori,\n\\(\\sum_{i=1}^n y_i\\) è la somma di tutte le osservazioni,\n\\(n\\) è il numero di osservazioni.\n\nQuesta derivazione mostra come la distribuzione a posteriori mantiene la forma di una Gamma, ma con parametri aggiornati che incorporano l’informazione dai dati osservati.\nConsideriamo nuovamente l’esempio precedente. Utilizzando i parametri aggiornati, rappresentiamo graficamente la distribuzione a posteriori:\n\n# Parametri aggiornati della distribuzione a posteriori Gamma\nalpha_post &lt;- alpha_prior + sum(y)\nbeta_post &lt;- beta_prior + length(y)\n\n# Distribuzione a posteriori analitica\nposterior_analytic &lt;- dgamma(lambda_grid, shape = alpha_post, rate = beta_post)\n\n# Plot della distribuzione a posteriori analitica\nplot(\n  lambda_grid, posterior_analytic, type = \"l\", col = \"blue\",\n  xlab = expression(lambda),\n  ylab = \"Densità di probabilità\",\n  main = \"Distribuzione a Posteriori Analitica Gamma-Poisson\"\n)\nabline(v = alpha_post / beta_post, col = \"red\", lty = 2) # Media a posteriori\nlegend(\n  \"topright\",\n  legend = c(\"Distribuzione a Posteriori\", \"Media a Posteriori\"),\n  col = c(\"blue\", \"red\"),\n  lty = c(1, 2)\n)\n\n\n\n\n\n\n\n\nIl grafico mostra la distribuzione a posteriori analitica del parametro di tasso \\(\\lambda\\) di un modello di Poisson, ottenuta utilizzando una distribuzione a priori Gamma e aggiornando i parametri alla luce dei dati osservati. La distribuzione a posteriori è calcolata come una Gamma aggiornata con i parametri \\(\\alpha_{\\text{post}}\\) e \\(\\beta_{\\text{post}}\\), e rappresenta la nostra conoscenza aggiornata dopo aver visto i dati. I risultati analitici concordano con quelli ottenuti tramite simulazione.\nProcediamo ora con il calcolo della soluzione analitica per la media della distribuzione a posteriori del parametro \\(\\lambda\\):\n\n# Media della distribuzione a posteriori\nposterior_mean &lt;- alpha_post / beta_post\ncat(sprintf(\"Media a Posteriori = %.3f\\n\", posterior_mean))\n#&gt; Media a Posteriori = 2.200\n\n# Parametri della distribuzione a posteriori\ncat(sprintf(\"Shape (α) = %.1f\\n\", alpha_post))\n#&gt; Shape (α) = 22.0\ncat(sprintf(\"Rate (β) = %.1f\\n\", beta_post))\n#&gt; Rate (β) = 10.0\n\nPossiamo calcolare la probabilità di qualsiasi evento di interesse. Per esempio, ci possiamo chiedere quale sia la probabilità di osservare più di 3 compulsioni per ora:\n\n# Probabilità di osservare più di 3 eventi\nprob_y_greater_than_3 &lt;- 1 - pgamma(3, shape = alpha_post, rate = beta_post)\ncat(sprintf(\"Probabilità di osservare più di 3 eventi = %.3f\\n\", prob_y_greater_than_3))\n#&gt; Probabilità di osservare più di 3 eventi = 0.054",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_gamma_poisson_model.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/09_gamma_poisson_model.html#riflessioni-conclusive",
    "title": "47  Modello coniugato Gamma-Poisson",
    "section": "47.7 Riflessioni Conclusive",
    "text": "47.7 Riflessioni Conclusive\nIl modello Gamma-Poisson offre un framework robusto per l’inferenza bayesiana su dati di conteggio in psicologia. Partendo da una distribuzione a priori Gamma, che rappresenta la nostra conoscenza iniziale sul tasso medio, siamo in grado di aggiornare questa conoscenza alla luce dei dati osservati, ottenendo una distribuzione a posteriori che riflette in modo più preciso la realtà sottostante. Questo approccio permette di quantificare l’incertezza associata alle nostre stime e di prendere decisioni informate sulla base dei dati disponibili.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_gamma_poisson_model.html#esercizi",
    "href": "chapters/bayesian_inference/09_gamma_poisson_model.html#esercizi",
    "title": "47  Modello coniugato Gamma-Poisson",
    "section": "47.8 Esercizi",
    "text": "47.8 Esercizi\n\nEsercizio 47.1 Consideriamo uno studio longitudinale su coppie, dove i partecipanti registrano quotidianamente la frequenza con cui nascondono il loro comportamento di fumo al partner. Basandoci sui dati di Scholz et al. (2021), assumiamo che il tasso medio di nascondere il fumo sia di 1.52 volte al giorno. Supponiamo di avere i seguenti dati giornalieri per un partecipante:\n\nGiorno 1: 2 volte.\nGiorno 2: 0 volte.\nGiorno 3: 1 volta.\nGiorno 4: 3 volte.\n\nUtilizzare un modello Gamma-Poisson per stimare la distribuzione a posteriori del tasso individuale di nascondere il fumo per un partecipante specifico, dato il suo insieme di osservazioni giornaliere.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_gamma_poisson_model.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/09_gamma_poisson_model.html#informazioni-sullambiente-di-sviluppo",
    "title": "47  Modello coniugato Gamma-Poisson",
    "section": "47.9 Informazioni sull’Ambiente di Sviluppo",
    "text": "47.9 Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.17.0       MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2\n#&gt;  [5] ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0  \n#&gt;  [9] bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0      markdown_1.13    \n#&gt; [13] knitr_1.49        lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1    \n#&gt; [17] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#&gt; [21] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [25] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1  farver_2.1.2      fastmap_1.2.0     pacman_0.5.1     \n#&gt;  [5] promises_1.3.2    rpart_4.1.23      digest_0.6.37     timechange_0.3.0 \n#&gt;  [9] mime_0.12         lifecycle_1.0.4   survival_3.7-0    magrittr_2.0.3   \n#&gt; [13] compiler_4.4.2    rlang_1.1.4       tools_4.4.2       utf8_1.2.4       \n#&gt; [17] yaml_2.3.10       ggsignif_0.6.4    htmlwidgets_1.6.4 mnormt_2.1.1     \n#&gt; [21] abind_1.4-8       miniUI_0.1.1.1    withr_3.0.2       nnet_7.3-19      \n#&gt; [25] grid_4.4.2        fansi_1.0.6       jomo_2.7-6        xtable_1.8-4     \n#&gt; [29] colorspace_2.1-1  iterators_1.0.14  cli_3.6.3         rmarkdown_2.29   \n#&gt; [33] generics_0.1.3    tzdb_0.4.0        minqa_1.2.8       splines_4.4.2    \n#&gt; [37] parallel_4.4.2    vctrs_0.6.5       boot_1.3-31       glmnet_4.1-8     \n#&gt; [41] Matrix_1.7-1      jsonlite_1.8.9    carData_3.0-5     car_3.1-3        \n#&gt; [45] hms_1.1.3         mitml_0.4-5       rstatix_0.7.2     Formula_1.2-5    \n#&gt; [49] foreach_1.5.2     glue_1.8.0        pan_1.9           nloptr_2.1.1     \n#&gt; [53] codetools_0.2-20  stringi_1.8.4     gtable_0.3.6      shape_1.4.6.1    \n#&gt; [57] later_1.4.1       lme4_1.1-35.5     munsell_0.5.1     pillar_1.9.0     \n#&gt; [61] htmltools_0.5.8.1 R6_2.5.1          rprojroot_2.0.4   evaluate_1.0.1   \n#&gt; [65] shiny_1.9.1       lattice_0.22-6    backports_1.5.0   broom_1.0.7      \n#&gt; [69] httpuv_1.6.15     Rcpp_1.0.13-1     nlme_3.1-166      xfun_0.49        \n#&gt; [73] pkgconfig_2.0.3",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_gamma_poisson_model.html#bibliografia",
    "href": "chapters/bayesian_inference/09_gamma_poisson_model.html#bibliografia",
    "title": "47  Modello coniugato Gamma-Poisson",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nScholz, U., Stadler, G., Berli, C., Lüscher, J., & Knoll, N. (2021). How do people experience and respond to social control from their partner? Three daily diary studies. Frontiers in Psychology, 11, 613546.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_gamma_exponential_model.html",
    "href": "chapters/bayesian_inference/10_gamma_exponential_model.html",
    "title": "48  Modello gamma-esponenziale",
    "section": "",
    "text": "48.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nNell’inferenza bayesiana, il modello coniugato Gamma-Esponenziale rappresenta un approccio analitico efficace per l’analisi di dati che seguono una distribuzione esponenziale. Questa distribuzione è comunemente utilizzata per modellare i tempi di attesa tra eventi in processi di Poisson, come ad esempio gli intervalli tra arrivi in un sistema a coda o la durata di eventi psicologici.\nConsideriamo, ad esempio, un esperimento in psicologia in cui si misurano i tempi di insorgenza di episodi di ansia in seguito a un evento stressante. In questo caso, si può ipotizzare che i tempi di insorgenza siano distribuiti esponenzialmente. Il parametro \\(\\lambda\\) della distribuzione esponenziale rappresenta il tasso medio con cui si verificano gli episodi di ansia.\nIl modello coniugato Gamma-Esponenziale consente di stimare il parametro \\(\\lambda\\) utilizzando i dati osservati. La distribuzione a priori Gamma viene utilizzata per rappresentare l’incertezza iniziale su \\(\\lambda\\), mentre la distribuzione esponenziale modella i dati osservati. Grazie a questa coniugazione, l’aggiornamento delle credenze sul parametro \\(\\lambda\\) avviene in modo semplice e analitico, permettendo di ottenere una stima bayesiana del tasso medio di occorrenza degli episodi di ansia, fornendo così una descrizione probabilistica accurata del fenomeno in esame.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Modello gamma-esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_gamma_exponential_model.html#introduzione",
    "href": "chapters/bayesian_inference/10_gamma_exponential_model.html#introduzione",
    "title": "48  Modello gamma-esponenziale",
    "section": "",
    "text": "48.1.1 Il Modello Matematico\nCaso singolo. Supponiamo di osservare un singolo tempo di attesa \\(y_1\\) prima che si verifichi un evento, come un episodio di disagio psicologico. Assumiamo che questo tempo di attesa segua una distribuzione esponenziale con parametro \\(\\lambda\\). La funzione di densità di probabilità (pdf) della distribuzione esponenziale è data da:\n\\[\nf(y_1 \\mid \\lambda) = \\lambda e^{-\\lambda y_1},\n\\]\ndove:\n\n\\(y_1\\) rappresenta il tempo di attesa,\n\\(\\lambda\\) è il parametro della distribuzione, che rappresenta il tasso medio con cui gli eventi si verificano per unità di tempo.\n\nIn questa distribuzione, \\(\\lambda\\) è il tasso di occorrenza o tasso di decadimento, ed è l’inverso del tempo medio di attesa. Più precisamente:\n\nIl tempo medio di attesa è il valore medio del tempo che trascorre prima che l’evento si verifichi (ad esempio, quanto tempo ci si aspetta in media prima che arrivi un autobus).\nIl parametro \\(\\lambda\\) rappresenta la frequenza con cui l’evento si verifica per unità di tempo, e quindi \\(\\lambda = \\frac{1}{\\text{tempo medio}}\\).\n\nPertanto, nella funzione esponenziale \\(f(y_1 \\mid \\lambda) = \\lambda e^{-\\lambda y_1}\\), il parametro \\(\\lambda\\) è inversamente proporzionale al tempo medio di attesa: più grande è \\(\\lambda\\), più breve è il tempo medio di attesa tra gli eventi.\nQuesta funzione descrive la probabilità di osservare un tempo di attesa esattamente uguale a \\(y_1\\), dato un valore specifico di \\(\\lambda\\). Per la distribuzione esponenziale, la media è \\(\\frac{1}{\\lambda}\\) e la varianza è \\(\\frac{1}{\\lambda^2}\\), il che riflette l’influenza del tasso \\(\\lambda\\) sulla dispersione dei tempi di attesa.\nPer fare un esempio, supponiamo che il tempo medio di attesa sia 2 ore. In questo caso, il parametro \\(\\lambda\\) (l’inverso del tempo medio di attesa) è \\(\\frac{1}{2}\\).\n\n# Parametro lambda (l'inverso del tempo medio di attesa)\nlambda_value &lt;- 1 / 2\n\nDisegniamo la funzione di densità esponenziale per tempi di attesa compresi tra 0 e 10 ore.\n\n# Creazione dei valori di y1 su cui valutare la funzione\ny1_values &lt;- seq(0, 10, length.out = 500)  # Intervallo da 0 a 10 ore\n\n# Definizione della funzione di densità esponenziale\nexponential_density &lt;- function(y1, lambda_value) {\n  lambda_value * exp(-lambda_value * y1)\n}\n\n# Calcolo dei valori di f(y1 | lambda)\nf_values &lt;- exponential_density(y1_values, lambda_value)\n\n# Creazione del grafico\nplot(\n  y1_values, f_values, type = \"l\", col = \"blue\",\n  main = expression(paste(\"Funzione di Densità Esponenziale con \", lambda, \" = 1/2\")),\n  xlab = \"Tempo di attesa (ore)\", ylab = \"Densità\"\n)\nlegend(\"topright\", legend = expression(f(y[1] ~ \"|\" ~ lambda) == lambda ~ e^(-lambda * y[1])),\n       col = \"blue\", lty = 1, bty = \"n\")\n\n\n\n\n\n\n\n\nQuesto codice crea un grafico della funzione di densità esponenziale per \\(\\lambda = 1/2\\) e tempi di attesa compresi tra 0 e 10 ore.\nIl caso di \\(n\\) osservazioni indipendenti. Consideriamo ora un campione di \\(n\\) osservazioni indipendenti \\(y_1, y_2, \\dots, y_n\\). L’indipendenza tra le osservazioni implica che il tempo di attesa osservato per un evento non influisce sulla probabilità di osservare altri tempi di attesa.\nPoiché le osservazioni sono indipendenti, la probabilità congiunta di osservare tutti i tempi di attesa nel campione è il prodotto delle probabilità individuali. Di conseguenza, la funzione di verosimiglianza per l’intero campione è data da:\n\\[\nf(y_1, y_2, \\dots, y_n \\mid \\lambda) = f(y_1 \\mid \\lambda) \\cdot f(y_2 \\mid \\lambda) \\cdot \\dots \\cdot f(y_n \\mid \\lambda).\n\\]\nSostituendo la funzione di densità della distribuzione esponenziale per ciascuna osservazione, otteniamo:\n\\[\nf(y \\mid \\lambda) = \\lambda e^{-\\lambda y_1} \\cdot \\lambda e^{-\\lambda y_2} \\cdot \\dots \\cdot \\lambda e^{-\\lambda y_n}.\n\\]\nRaccogliendo i termini comuni, possiamo riscrivere la funzione di verosimiglianza come:\n\\[\nf(y \\mid \\lambda) = \\lambda^n e^{-\\lambda (y_1 + y_2 + \\dots + y_n)}.\n\\]\nUtilizzando la notazione di sommatoria, possiamo esprimere la funzione di verosimiglianza in modo compatto come:\n\\[\nf(y \\mid \\lambda) = \\lambda^n e^{-\\lambda \\sum_{i=1}^{n} y_i}.\n\\]\nLa funzione di verosimiglianza \\(f(y \\mid \\lambda)\\) rappresenta la probabilità di osservare il campione \\(y_1, y_2, \\dots, y_n\\) dato un particolare valore del parametro \\(\\lambda\\). Un valore più alto della verosimiglianza indica una maggiore plausibilità del valore di \\(\\lambda\\), dato il campione osservato.\nSpesso è più conveniente lavorare con il logaritmo della funzione di verosimiglianza, poiché il logaritmo trasforma i prodotti in somme, semplificando i calcoli. Il logaritmo della funzione di verosimiglianza è:\n\\[\n\\log L(\\lambda \\mid y_1, y_2, \\dots, y_n) = n \\log \\lambda - \\lambda \\sum_{i=1}^{n} y_i.\n\\]\nQuesta forma semplificata della log-verosimiglianza è utile per stimare il parametro \\(\\lambda\\) tramite tecniche come la massimizzazione della verosimiglianza.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Modello gamma-esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_gamma_exponential_model.html#aggiornare-le-nostre-credenze-con-linferenza-bayesiana",
    "href": "chapters/bayesian_inference/10_gamma_exponential_model.html#aggiornare-le-nostre-credenze-con-linferenza-bayesiana",
    "title": "48  Modello gamma-esponenziale",
    "section": "48.2 Aggiornare le Nostre Credenze con l’Inferenza Bayesiana",
    "text": "48.2 Aggiornare le Nostre Credenze con l’Inferenza Bayesiana\nNell’approccio bayesiano, non consideriamo solo i dati, ma anche le nostre conoscenze a priori sul parametro \\(\\lambda\\). Assegniamo a \\(\\lambda\\) una distribuzione a priori, tipicamente una distribuzione Gamma. Combinando la verosimiglianza con la distribuzione a priori, otteniamo la distribuzione a posteriori di \\(\\lambda\\), che rappresenta la nostra conoscenza aggiornata alla luce dei dati. La proprietà della coniugazione assicura che la distribuzione a posteriori sia anch’essa una Gamma, facilitando i calcoli.\nPer fare un esempio concreto, simuleremo un campione di dati. Immaginiamo di raccogliere dati che rappresentano il tempo, misurato in ore, che intercorre tra episodi di ansia in individui con disturbi d’ansia. La distribuzione esponenziale può essere utilizzata per modellare questo tempo di attesa tra un episodio di ansia e il successivo. Ad esempio, possiamo ipotizzare che, una volta concluso un episodio, l’insorgenza del prossimo segua un processo stocastico con un tasso costante, indipendentemente dal tempo trascorso dall’episodio precedente. In questo contesto, il parametro \\(\\lambda\\) della distribuzione esponenziale rappresenta il tasso medio di occorrenza degli episodi di ansia, ossia quanti episodi ci si aspetta in media in una certa unità di tempo (ad esempio, in un giorno).\nSe \\(\\lambda\\) è elevato, ciò indica che gli episodi di ansia sono più frequenti, con tempi di attesa più brevi tra un episodio e l’altro.\n\n# Impostiamo il seed per rendere i risultati riproducibili\nset.seed(42)\n\n# Parametro medio (tempo medio di attesa in ore)\nmean_time &lt;- 3.0\nlambda_param &lt;- 1 / mean_time  # Parametro lambda per la distribuzione esponenziale\n\n# Numero di osservazioni nel campione\nn &lt;- 15\n\n# Generazione del campione casuale\ny &lt;- round(rexp(n, rate = lambda_param))\ny\n#&gt;  [1] 1 2 1 0 1 4 1 1 4 2 4 7 0 0 4\n\nImmaginiamo che questi dati rappresentino il tempo di attesa in ore tra episodi di ansia in 15 individui con disturbi d’ansia. Il tempo di attesa medio è:\n\nmean_time_observed &lt;- mean(y)\nmean_time_observed\n#&gt; [1] 2.133333\n\nIl tasso di occorrenza, \\(\\lambda\\), calcolato sulla base dei dati osservati è:\n\nlambda_estimated &lt;- 1 / mean_time_observed\nlambda_estimated\n#&gt; [1] 0.46875\n\nOra possiamo procedere a trovare la distribuzione a posteriori per il tasso di occorrenza \\(\\lambda\\).\n\n48.2.1 Passi per definire un prior debolmente informativo\nIl primo passo consiste nel definire una distribuzione a priori per \\(\\lambda\\), il tasso di occorrenza degli episodi di ansia in individui con disturbi d’ansia. Se disponiamo di poche informazioni a priori riguardo al valore di \\(\\lambda\\), possiamo adottare una distribuzione a priori debolmente informativa. Un prior debolmente informativo ha lo scopo di esercitare una minima influenza sull’inferenza, consentendo ai dati osservati di guidare principalmente la stima del parametro.\nLa distribuzione a priori coniugata per la distribuzione esponenziale è la distribuzione Gamma. Un prior debolmente informativo per \\(\\lambda\\) potrebbe essere impostato in modo tale da riflettere una conoscenza vaga, con una media che rappresenta un tempo di attesa ragionevole (basato su qualche informazione preliminare o ipotesi generale), ma con una varianza ampia, in modo da non vincolare eccessivamente l’inferenza.\nSupponiamo di voler impostare una distribuzione a priori per il tasso di occorrenza \\(\\lambda\\), in modo tale che il tempo medio di attesa sia 3.33 ore, con una deviazione standard ampia, ad esempio 5 ore. Poiché \\(\\lambda\\) rappresenta il tasso di occorrenza (ovvero l’inverso del tempo medio di attesa), dobbiamo applicare la distribuzione Gamma ai valori di \\(\\lambda\\), non direttamente ai tempi di attesa.\nI parametri della distribuzione Gamma, \\(\\alpha\\) (forma) e \\(\\beta\\) (tasso), sono dati da:\n\n\\(\\alpha_{\\text{prior}} = 0.45\\)\n\\(\\beta_{\\text{prior}} = 1.5\\)\n\nVerifichiamo che questi parametri corrispondano alla media e alla varianza desiderate.\n\n# Parametri della distribuzione Gamma\nalpha_prior &lt;- 0.45  # Forma\nbeta_prior &lt;- 1.5    # Tasso (inverso della scala)\n\n# Calcolo della media e della varianza della distribuzione Gamma per λ\nmean_lambda &lt;- alpha_prior / beta_prior\nvariance_lambda &lt;- alpha_prior / (beta_prior^2)\n\n# Calcolo della media del tempo di attesa (E[Y] = 1 / E[λ])\nmean_waiting_time &lt;- 1 / mean_lambda\n\n# Stampiamo la media e la varianza di λ e del tempo di attesa\ncat(\"Media di λ:\", mean_lambda, \"\\n\")\n#&gt; Media di λ: 0.3\ncat(\"Varianza di λ:\", variance_lambda, \"\\n\")\n#&gt; Varianza di λ: 0.2\ncat(\"Media del tempo di attesa:\", mean_waiting_time, \"ore\\n\")\n#&gt; Media del tempo di attesa: 3.333333 ore\n\nLa media del tempo di attesa è 3.33 ore, come desiderato. La varianza del tempo di attesa richiede un calcolo più complesso e non è semplicemente l’inverso della varianza di \\(\\lambda\\).\n\n\n48.2.2 Visualizzazione della Distribuzione a Priori\nDisegniamo la funzione di densità della distribuzione Gamma per \\(\\lambda\\), utilizzando i parametri specificati.\n\n# Creazione dei valori x per il grafico\nx &lt;- seq(0, 2, length.out = 500)\n\n# Funzione di densità della distribuzione Gamma con i parametri dati\ngamma_pdf &lt;- dgamma(x, shape = alpha_prior, rate = beta_prior)\n\n# Creazione del grafico\nplot(x, gamma_pdf, type = \"l\", col = \"blue\", lwd = 2,\n     main = bquote(\"Funzione di Densità Gamma con \" ~ alpha == .(alpha_prior) ~ \",\" ~ beta == .(beta_prior)),\n     xlab = expression(lambda),\n     ylab = \"Densità di probabilità\")\nlegend(\n  \"topright\", \n  legend = \"Distribuzione a Priori\", \n  col = \"blue\", \n  lty = 1, \n  lwd = 2, \n  bty = \"n\"\n)",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Modello gamma-esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_gamma_exponential_model.html#metodo-basato-su-griglia",
    "href": "chapters/bayesian_inference/10_gamma_exponential_model.html#metodo-basato-su-griglia",
    "title": "48  Modello gamma-esponenziale",
    "section": "48.3 Metodo Basato su Griglia",
    "text": "48.3 Metodo Basato su Griglia\nPoniamoci l’obiettivo di utilizzare il metodo basato su griglia per derivare la distribuzione a posteriori del parametro \\(\\lambda\\) della distribuzione esponenziale. Iniziamo creando una griglia per \\(\\lambda\\) nell’intervallo [0.01, 2].\n\n# Evitiamo zero per evitare divisione per zero\nlambda_grid &lt;- seq(0.01, 2, length.out = 1000)\n\n\n48.3.1 Calcolo della Distribuzione a Priori\n\n# Calcolo della distribuzione a priori\nprior &lt;- dgamma(lambda_grid, shape = alpha_prior, rate = beta_prior)\n\n\n\n48.3.2 Calcolo della Verosimiglianza\nImmaginiamo di avere i seguenti dati, che rappresentano i tempi di attesa (in ore) tra episodi di ansia per 15 individui:\n\n# Impostiamo il seed per rendere i risultati riproducibili\nset.seed(42)\n\n# Parametro medio (tempo medio di attesa in ore)\nmean_time &lt;- 3.0\nlambda_param &lt;- 1 / mean_time  # Parametro λ per la distribuzione esponenziale\n\n# Numero di osservazioni nel campione\nn &lt;- 15\n\n# Generazione del campione casuale\ny &lt;- round(rexp(n, rate = lambda_param))\ny\n#&gt;  [1] 1 2 1 0 1 4 1 1 4 2 4 7 0 0 4\n\nCalcoliamo la log-verosimiglianza per ciascun valore di \\(\\lambda\\) nella griglia:\n\n# Calcolo della log-verosimiglianza per ciascun valore di lambda\nlog_likelihood &lt;- sapply(\n  lambda_grid, \n  function(lam) sum(dexp(y, rate = lam, log = TRUE))\n)\n\n\n\n48.3.3 Calcolo della Distribuzione a Posteriori\nCalcoliamo la distribuzione a posteriori non normalizzata in logaritmo per evitare problemi di underflow numerico:\n\n# Calcolo del log-posteriori non normalizzato\nlog_posterior_unnormalized &lt;- log_likelihood + log(prior)\n\n# Normalizzazione per stabilità numerica\nlog_posterior_unnormalized &lt;- log_posterior_unnormalized - max(log_posterior_unnormalized)\n\n# Convertiamo in scala normale\nposterior_unnormalized &lt;- exp(log_posterior_unnormalized)\n\nNormalizziamo la distribuzione a posteriori:\n\n# Calcolo del passo nella griglia\ndelta_lambda &lt;- diff(lambda_grid)[1]  # Assumendo che la griglia sia equispaziata\n\n# Normalizzazione della distribuzione a posteriori\nposterior &lt;- \n  posterior_unnormalized / sum(posterior_unnormalized * delta_lambda)\n\n\n\n48.3.4 Visualizzazione dei Risultati\n\n# Grafico della distribuzione a posteriori e a priori\nplot(lambda_grid, posterior, type = \"l\", col = \"blue\", lwd = 2,\n     xlab = expression(lambda), ylab = \"Densità di probabilità\",\n     main = \"Distribuzione a Posteriori di λ\")\nlines(lambda_grid, prior, col = \"red\", lwd = 2, lty = 2)\nlegend(\"topright\", legend = c(\"Posteriori\", \"Priori\"),\n       col = c(\"blue\", \"red\"), lty = c(1, 2), lwd = 2, bty = \"n\")\n\n\n\n\n\n\n\n\nDal grafico, possiamo osservare come la distribuzione a posteriori di \\(\\lambda\\) sia aggiornata rispetto alla distribuzione a priori in base ai dati osservati. La distribuzione a posteriori riflette sia le informazioni a priori sia l’evidenza fornita dai dati, fornendo una stima aggiornata del tasso di occorrenza degli episodi di ansia.\n\n\n48.3.5 Calcolo della Media e Varianza Posteriori\nPossiamo calcolare la media e la varianza a posteriori di \\(\\lambda\\) utilizzando la distribuzione a posteriori calcolata sulla griglia.\n\n# Calcolo della media a posteriori di λ\nposterior_mean_lambda &lt;- sum(lambda_grid * posterior * delta_lambda)\n\n# Calcolo della varianza a posteriori di λ\nposterior_variance_lambda &lt;- \n  sum((lambda_grid - posterior_mean_lambda)^2 * posterior * delta_lambda)\n\n# Stampiamo i risultati\ncat(\"Media a posteriori di λ:\", posterior_mean_lambda, \"\\n\")\n#&gt; Media a posteriori di λ: 0.461194\ncat(\"Varianza a posteriori di λ:\", posterior_variance_lambda, \"\\n\")\n#&gt; Varianza a posteriori di λ: 0.01376699\n\n\n\n48.3.6 Stima del Tempo di Attesa Medio a Posteriori\nUtilizzando la media a posteriori di \\(\\lambda\\), possiamo stimare il tempo di attesa medio a posteriori:\n\n# Stima del tempo di attesa medio a posteriori\nposterior_mean_waiting_time &lt;- 1 / posterior_mean_lambda\ncat(\"Tempo di attesa medio a posteriori:\", posterior_mean_waiting_time, \"ore\\n\")\n#&gt; Tempo di attesa medio a posteriori: 2.168285 ore\n\nIn conclusione, attraverso il metodo basato su griglia, abbiamo derivato la distribuzione a posteriori del tasso di occorrenza \\(\\lambda\\), tenendo conto della nostra conoscenza a priori e dei dati osservati. Questo approccio ci permette di aggiornare le nostre credenze su \\(\\lambda\\) in modo coerente con l’evidenza empirica, fornendo stime più accurate e affidabili.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Modello gamma-esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_gamma_exponential_model.html#modello-coniugato-gamma-esponenziale",
    "href": "chapters/bayesian_inference/10_gamma_exponential_model.html#modello-coniugato-gamma-esponenziale",
    "title": "48  Modello gamma-esponenziale",
    "section": "48.4 Modello Coniugato Gamma-Esponenziale",
    "text": "48.4 Modello Coniugato Gamma-Esponenziale\nQuando utilizziamo una distribuzione \\(\\text{Gamma}(\\alpha, \\beta)\\) come distribuzione coniugata a priori, la distribuzione a posteriori risulta anch’essa essere una distribuzione Gamma, con parametri aggiornati \\(\\alpha + n\\) e \\(\\beta + \\sum_{i=1}^{n} x_{i}\\).\nIn altre parole, se il parametro \\(\\lambda\\) della distribuzione esponenziale segue una distribuzione a priori Gamma con parametri \\(\\alpha\\) e \\(\\beta\\), allora, dopo aver osservato un campione di \\(n\\) osservazioni \\(x_1, x_2, \\dots, x_n\\), la distribuzione a posteriori di \\(\\lambda\\) sarà ancora una distribuzione Gamma, ma con i parametri aggiornati:\n\\[\n\\lambda \\mid x \\sim \\text{Gamma}(\\alpha + n, \\beta + \\sum_{i=1}^{n} x_{i}).\n\\]\nQuesto aggiornamento dei parametri è una conseguenza della proprietà coniugata della distribuzione Gamma rispetto alla distribuzione esponenziale.\n\n48.4.1 Dimostrazione del Modello Coniugato Gamma-Esponenziale\nPer dimostrare questo risultato, partiamo dal teorema di Bayes:\n\\[\nf(\\lambda \\mid x) \\propto f(x \\mid \\lambda) \\cdot f(\\lambda),\n\\]\ndove \\(f(\\lambda \\mid x)\\) è la distribuzione a posteriori di \\(\\lambda\\) dato il campione \\(x\\), \\(f(x \\mid \\lambda)\\) è la verosimiglianza basata sul campione \\(x\\), e \\(f(\\lambda)\\) è la distribuzione a priori di \\(\\lambda\\).\nLa funzione di verosimiglianza per un campione di \\(n\\) osservazioni indipendenti \\(x_1, x_2, \\dots, x_n\\), che seguono una distribuzione esponenziale con parametro \\(\\lambda\\), è data da:\n\\[\nf(x \\mid \\lambda) = \\prod_{i=1}^{n} \\lambda e^{-\\lambda x_i} = \\lambda^n e^{-\\lambda \\sum_{i=1}^{n} x_i}.\n\\]\nSupponiamo che il parametro \\(\\lambda\\) segua una distribuzione a priori Gamma con parametri \\(\\alpha\\) e \\(\\beta\\):\n\\[\nf(\\lambda) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} \\lambda^{\\alpha - 1} e^{-\\beta \\lambda}.\n\\]\nMoltiplicando la verosimiglianza per la distribuzione a priori, otteniamo la distribuzione a posteriori:\n\\[\nf(\\lambda \\mid x) \\propto \\lambda^n e^{-\\lambda \\sum_{i=1}^{n} x_i} \\cdot \\lambda^{\\alpha - 1} e^{-\\beta \\lambda}.\n\\]\nSemplificando, si ottiene:\n\\[\nf(\\lambda \\mid x) \\propto \\lambda^{n + \\alpha - 1} e^{-\\lambda \\left(\\beta + \\sum_{i=1}^{n} x_i\\right)}.\n\\]\nQuesta espressione corrisponde alla forma di una distribuzione Gamma con parametri aggiornati:\n\nparametro della forma (alpha): \\(\\alpha_{\\text{post}} = \\alpha + n\\);\nparametro della scala (beta): \\(\\beta_{\\text{post}} = \\beta + \\sum_{i=1}^{n} x_i\\).\n\nQuindi, la distribuzione a posteriori di \\(\\lambda\\) dato il campione \\(x\\) segue una distribuzione Gamma con parametri aggiornati:\n\\[\n\\lambda \\mid x \\sim \\text{Gamma}(\\alpha + n, \\beta + \\sum_{i=1}^{n} x_i).\n\\]\nQuesta derivazione mostra come l’informazione contenuta nei dati osservati venga incorporata nei parametri della distribuzione a posteriori, mantenendo la forma della distribuzione a priori grazie alla proprietà coniugata.\n\n\n48.4.2 Calcolo dei Parametri Aggiornati\nPer il caso dell’esempio in discussione:\n\nIl numero di osservazioni nel campione \\(n\\) è 15;\nLa somma delle osservazioni nel campione è:\n\n\\[\n\\sum_{i=1}^{n} y_i = 1 + 9 + 4 + 3 + 1 + 1 + 0 + 6 + 3 + 4 + 0 + 11 + 5 + 1 + 1 = 50.\n\\]\nLa distribuzione a posteriori per \\(\\lambda\\) segue una distribuzione Gamma aggiornata con i seguenti parametri:\n\\[\n\\alpha_{\\text{post}} = \\alpha_{\\text{prior}} + n,\n\\]\n\\[\n\\beta_{\\text{post}} = \\beta_{\\text{prior}} + \\sum_{i=1}^{n} y_i.\n\\]\nUsando i valori \\(\\alpha_{\\text{prior}} = 0.009\\) e \\(\\beta_{\\text{prior}} = 0.03\\), otteniamo:\n\\[\n\\alpha_{\\text{post}} = 0.009 + 15 = 15.009,\n\\]\n\\[\n\\beta_{\\text{post}} = 0.03 + 50 = 50.03.\n\\]\n\n# Dati iniziali\nalpha_prior &lt;- 0.009\nbeta_prior &lt;- 0.03\nn &lt;- 15\ny &lt;- c(1, 9, 4, 3, 1, 1, 0, 6, 3, 4, 0, 11, 5, 1, 1)\nsum_y &lt;- sum(y)\n\n# Parametri aggiornati\nalpha_post &lt;- alpha_prior + n\nbeta_post &lt;- beta_prior + sum_y\n\n# Stampa dei parametri aggiornati\ncat(sprintf(\"alpha_post = %.3f; beta_post = %.3f\\n\", alpha_post, beta_post))\n#&gt; alpha_post = 15.009; beta_post = 50.030\n\nGeneriamo il grafico della distribuzione a posteriori.\n\n# Griglia di valori di lambda per il grafico\nlambda_grid &lt;- seq(0, 2, length.out = 1000)\n\n# Calcolo della densità della distribuzione Gamma a posteriori\nposterior_pdf &lt;- dgamma(lambda_grid, shape = alpha_post, rate = beta_post)\n\n# Creazione del grafico\nplot(\n  lambda_grid, posterior_pdf, type = \"l\", col = \"blue\", lwd = 2,\n  main = bquote(\"Distribuzione Gamma a Posteriori con \" ~ alpha[post] == \n                  .(alpha_post) ~ \",\" ~ beta[post] == .(beta_post)),\n  xlab = expression(lambda), ylab = \"Densità di probabilità\"\n)\nlegend(\n  \"topright\", \n  legend = bquote(Gamma(alpha[post] == .(alpha_post) ~ \",\" ~ beta[post] == .(beta_post))),\n  col = \"blue\", \n  lty = 1, \n  lwd = 2, \n  bty = \"n\"\n)\n\n\n\n\n\n\n\n\n\n\n48.4.3 Calcolo della Media e della Varianza a Posteriori\nLa media e la varianza della distribuzione a posteriori sono calcolate come:\n\\[\n\\text{E}[\\lambda \\mid y] = \\frac{\\alpha_{\\text{post}}}{\\beta_{\\text{post}}},\n\\]\n\\[\n\\text{Var}[\\lambda \\mid y] = \\frac{\\alpha_{\\text{post}}}{\\beta_{\\text{post}}^2}.\n\\]\nIn R:\n\n# Calcolo della media e della varianza a posteriori\nposterior_mean &lt;- alpha_post / beta_post\nposterior_variance &lt;- alpha_post / (beta_post^2)\n\n# Stampa dei risultati\ncat(sprintf(\"Media a posteriori di λ: %.3f\\n\", posterior_mean))\n#&gt; Media a posteriori di λ: 0.300\ncat(sprintf(\"Varianza a posteriori di λ: %.6f\\n\", posterior_variance))\n#&gt; Varianza a posteriori di λ: 0.005996\n\nLa distribuzione a posteriori di \\(\\lambda\\) è aggiornata in base ai dati osservati e al prior. La media a posteriori rappresenta la stima del tasso di occorrenza degli episodi di ansia, mentre la varianza riflette l’incertezza nella stima.\n\nMedia a Posteriori: La media a posteriori di \\(\\lambda\\) è circa 0.3, indicando un tasso di occorrenza medio di 0.3 episodi per ora.\nVarianza a Posteriori: La varianza di 0.006 riflette una moderata incertezza nella stima di \\(\\lambda\\).\n\nQuesti risultati evidenziano come la distribuzione Gamma aggiornata combini informazioni a priori e dati osservati per ottenere stime robuste del tasso di occorrenza \\(\\lambda\\).\n\n\n48.4.4 Trasformazione della media e della varianza\nPer interpretare questi risultati in termini di tempi di attesa, dobbiamo trasformare i valori sulla scala inversa, cioè passare dal tasso \\(\\lambda\\) ai tempi di attesa \\(T = \\frac{1}{\\lambda}\\).\nLa media del tempo di attesa \\(T\\) è l’inverso della media del tasso di occorrenza \\(\\lambda\\). Pertanto, la media dei tempi di attesa sarà:\n\\[\n\\text{E}[T \\mid y] = \\frac{1}{\\text{E}[\\lambda \\mid y]} = \\frac{1}{0.3} \\approx 3.33 \\, \\text{ore}.\n\\]\nPer la varianza del tempo di attesa, dobbiamo applicare una trasformazione più complessa. La varianza del tempo di attesa \\(T\\) è legata alla varianza di \\(\\lambda\\) da:\n\\[\n\\text{Var}(T) = \\frac{\\text{Var}[\\lambda \\mid y]}{(\\text{E}[\\lambda \\mid y])^4}.\n\\]\nSostituendo i valori calcolati per la varianza e la media di \\(\\lambda\\), otteniamo:\n\\[\n\\text{Var}(T) \\approx \\frac{0.006}{(0.3)^4} \\approx 24.59 \\, \\text{ore}.\n\\]\nIn conclusione,\n\nla media del tempo di attesa a posteriori è di circa 3.33 ore;\nla varianza del tempo di attesa a posteriori è di circa 24.59 ore, che indica una certa dispersione dei tempi di attesa, con alcuni episodi che possono verificarsi molto più rapidamente o più lentamente rispetto alla media. Si noti che la distribuzione a posteriori è più concentrata rispetto al prior, poiché incorpora l’informazione aggiuntiva proveniente dai dati osservati.\n\nQuesta trasformazione ci permette di interpretare i risultati sulla scala dei tempi di attesa, che è più intuitiva per descrivere fenomeni psicologici come l’insorgenza di episodi di ansia.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Modello gamma-esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_gamma_exponential_model.html#applicazioni",
    "href": "chapters/bayesian_inference/10_gamma_exponential_model.html#applicazioni",
    "title": "48  Modello gamma-esponenziale",
    "section": "48.5 Applicazioni",
    "text": "48.5 Applicazioni\nUna volta ottenuta la distribuzione a posteriori per λ, possiamo utilizzarla per rispondere a domande probabilistiche relative ai tempi di attesa tra episodi di ansia. Questo approccio ci consente di calcolare probabilità aggiornate alla luce dei dati osservati, rispecchiando meglio l’incertezza e le informazioni disponibili. Ad esempio, possiamo stimare la probabilità di osservare tempi di attesa compresi tra 2 e 5 ore.\nPer risolvere questo problema possiamo usare il metodo Monte Carlo:\n\nGeneriamo un gran numero di campioni dalla distribuzione Gamma a posteriori di \\(\\lambda\\), usando i parametri \\(\\alpha_{\\text{posteriori}}\\) e \\(\\beta_{\\text{posteriori}}\\).\nConvertiamo ciascun \\(\\lambda\\) campionato in un tempo di attesa \\(T = \\frac{1}{\\lambda}\\).\nCalcoliamo le probabilità richieste (ad esempio, \\(P(T &gt; 2)\\) e \\(P(T &lt; 5)\\)) semplicemente contando le proporzioni di campioni che soddisfano tali condizioni.\n\n\n48.5.1 Simulazione con Monte Carlo\nUtilizziamo i parametri posteriori della distribuzione Gamma per simulare campioni di \\(\\lambda\\) e calcolare la probabilità che il tempo di attesa tra due episodi di ansia sia compreso tra 2 e 5 ore.\n\n# Parametri posteriori per la distribuzione Gamma\nalpha_post &lt;- 15.009\nbeta_post &lt;- 50.03\n\n# Numero di campioni da generare\nn_samples &lt;- 100000\n\n# Simulazione di campioni dalla distribuzione Gamma per λ\nlambda_samples &lt;- rgamma(n_samples, shape = alpha_post, rate = beta_post)\n\n# Conversione dei campioni di λ in tempi di attesa T = 1/λ\nwaiting_time_samples &lt;- 1 / lambda_samples\n\n# Calcolo della probabilità che il tempo di attesa sia compreso tra 2 e 5 ore\nprob_between_2_and_5_mc &lt;- mean(waiting_time_samples &gt;= 2 & waiting_time_samples &lt;= 5)\n\n# Stampa del risultato\ncat(sprintf(\"Probabilità che il tempo di attesa sia tra 2 e 5 ore: %.4f\\n\", prob_between_2_and_5_mc))\n#&gt; Probabilità che il tempo di attesa sia tra 2 e 5 ore: 0.9027\n\nLa probabilità che il tempo di attesa tra due episodi di ansia sia compreso tra 2 e 5 ore è di circa 0.9029, ovvero il 90.3%. Questa stima si basa su campioni simulati dalla distribuzione a posteriori di \\(\\lambda\\), trasformati nei corrispondenti tempi di attesa. L’approccio Monte Carlo è utile per calcolare probabilità che coinvolgono trasformazioni non lineari, come nel caso del tempo di attesa.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Modello gamma-esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_gamma_exponential_model.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/10_gamma_exponential_model.html#riflessioni-conclusive",
    "title": "48  Modello gamma-esponenziale",
    "section": "48.6 Riflessioni Conclusive",
    "text": "48.6 Riflessioni Conclusive\nIl modello esponenziale si rivela uno strumento utile e versatile nella ricerca psicologica, in particolare per la modellazione di fenomeni caratterizzati da tempi di attesa o durate di eventi. È applicabile in vari contesti, tra cui l’analisi dei tempi di reazione, lo studio degli intervalli tra episodi di ansia o depressione e, più in generale, in tutti quei processi psicologici che possono essere descritti come il tempo trascorso fino al verificarsi di un evento.\nUn aspetto particolarmente vantaggioso dell’uso di modelli basati sulla distribuzione esponenziale nell’inferenza bayesiana è la possibilità di utilizzare le famiglie coniugate. Nella famiglia coniugata Gamma-Esponenziale, la distribuzione a priori Gamma per il tasso \\(\\lambda\\) si aggiorna in modo analitico quando si osservano nuovi dati esponenziali. Questo rende i calcoli bayesiani particolarmente efficienti e semplici da implementare, poiché la distribuzione a posteriori rimane della stessa forma della distribuzione a priori (ossia, una Gamma). Tale proprietà coniugata consente di ottenere una stima aggiornata del tasso \\(\\lambda\\) e di fare inferenze accurate sui tempi di attesa futuri.\nLa combinazione tra la distribuzione esponenziale e il prior Gamma non solo semplifica l’inferenza, ma fornisce anche una struttura interpretativa chiara. Ad esempio, il parametro \\(\\lambda\\), che rappresenta il tasso di occorrenza di un fenomeno, viene aggiornato sulla base dell’evidenza osservata, consentendo una stima dinamica della frequenza con cui gli episodi si verificano. Questo approccio bayesiano offre un’interpretazione probabilistica naturale dei tempi di attesa futuri, rispecchiando l’incertezza presente nei dati.\nInoltre, grazie alla flessibilità del metodo Monte Carlo, è possibile simulare campioni dalla distribuzione a posteriori di \\(\\lambda\\) e ottenere stime precise per una vasta gamma di probabilità, come la probabilità che il tempo di attesa sia compreso tra intervalli specifici. Questo approccio simulativo permette di rispondere a domande specifiche relative ai processi psicologici, ad esempio la probabilità che un episodio di ansia duri più di un certo numero di ore.\nIn conclusione, il modello esponenziale, integrato in un framework bayesiano con famiglie coniugate, rappresenta un utile strumento per la ricerca psicologica. Offre un modo rigoroso per modellare e analizzare dati su tempi di attesa e durate, fornendo al contempo una base solida per l’inferenza e la previsione dei processi psicologici.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Modello gamma-esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_gamma_exponential_model.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/10_gamma_exponential_model.html#informazioni-sullambiente-di-sviluppo",
    "title": "48  Modello gamma-esponenziale",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.17.0       MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2\n#&gt;  [5] ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0  \n#&gt;  [9] bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0      markdown_1.13    \n#&gt; [13] knitr_1.49        lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1    \n#&gt; [17] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#&gt; [21] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [25] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1  farver_2.1.2      fastmap_1.2.0     pacman_0.5.1     \n#&gt;  [5] promises_1.3.2    rpart_4.1.23      digest_0.6.37     timechange_0.3.0 \n#&gt;  [9] mime_0.12         lifecycle_1.0.4   survival_3.7-0    magrittr_2.0.3   \n#&gt; [13] compiler_4.4.2    rlang_1.1.4       tools_4.4.2       utf8_1.2.4       \n#&gt; [17] yaml_2.3.10       ggsignif_0.6.4    htmlwidgets_1.6.4 mnormt_2.1.1     \n#&gt; [21] abind_1.4-8       miniUI_0.1.1.1    withr_3.0.2       nnet_7.3-19      \n#&gt; [25] grid_4.4.2        fansi_1.0.6       jomo_2.7-6        xtable_1.8-4     \n#&gt; [29] colorspace_2.1-1  iterators_1.0.14  cli_3.6.3         rmarkdown_2.29   \n#&gt; [33] generics_0.1.3    tzdb_0.4.0        minqa_1.2.8       splines_4.4.2    \n#&gt; [37] parallel_4.4.2    vctrs_0.6.5       boot_1.3-31       glmnet_4.1-8     \n#&gt; [41] Matrix_1.7-1      jsonlite_1.8.9    carData_3.0-5     car_3.1-3        \n#&gt; [45] hms_1.1.3         mitml_0.4-5       rstatix_0.7.2     Formula_1.2-5    \n#&gt; [49] foreach_1.5.2     glue_1.8.0        pan_1.9           nloptr_2.1.1     \n#&gt; [53] codetools_0.2-20  stringi_1.8.4     gtable_0.3.6      shape_1.4.6.1    \n#&gt; [57] later_1.4.1       lme4_1.1-35.5     munsell_0.5.1     pillar_1.9.0     \n#&gt; [61] htmltools_0.5.8.1 R6_2.5.1          rprojroot_2.0.4   evaluate_1.0.1   \n#&gt; [65] shiny_1.9.1       lattice_0.22-6    backports_1.5.0   broom_1.0.7      \n#&gt; [69] httpuv_1.6.15     Rcpp_1.0.13-1     nlme_3.1-166      xfun_0.49        \n#&gt; [73] pkgconfig_2.0.3",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Modello gamma-esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_post_pred_distr.html",
    "href": "chapters/bayesian_inference/11_post_pred_distr.html",
    "title": "49  Distribuzione predittiva a posteriori",
    "section": "",
    "text": "49.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nIn questo capitolo esploreremo il concetto di distribuzione predittiva a posteriori, concentrandoci sul caso discreto. Per rendere il tema accessibile e intuitivo, utilizzeremo come esempio esplicativo il classico problema del sacchetto di monete (bag of coins), che permette di visualizzare chiaramente il processo di inferenza bayesiana.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_post_pred_distr.html#previsioni-su-eventi-futuri",
    "href": "chapters/bayesian_inference/11_post_pred_distr.html#previsioni-su-eventi-futuri",
    "title": "49  Distribuzione predittiva a posteriori",
    "section": "49.2 Previsioni su Eventi Futuri",
    "text": "49.2 Previsioni su Eventi Futuri\nLa distribuzione predittiva a posteriori è un elemento centrale nell’inferenza bayesiana. Essa rappresenta la probabilità di eventi futuri calcolata sulla base delle osservazioni raccolte e delle nostre convinzioni aggiornate (a posteriori). In altre parole, consente di fare previsioni tenendo conto sia dei dati osservati che dell’incertezza residua nei parametri del modello.\n\n49.2.1 Definizione Formale\nSupponiamo di avere un insieme di dati osservati \\(y = \\{y_1, y_2, \\ldots, y_n\\}\\), generati da un modello che dipende da un parametro sconosciuto \\(\\theta\\). Inizialmente, le nostre conoscenze su \\(\\theta\\) sono rappresentate dalla distribuzione a priori \\(p(\\theta)\\). Dopo aver osservato i dati, possiamo aggiornare la nostra conoscenza su \\(\\theta\\) mediante la distribuzione a posteriori \\(p(\\theta | y)\\), calcolata con la formula di Bayes:\n\\[\np(\\theta | y) = \\frac{p(y | \\theta) p(\\theta)}{p(y)},\n\\]\ndove:\n\n\\(p(\\theta | y)\\) è la distribuzione a posteriori del parametro \\(\\theta\\);\n\\(p(y | \\theta)\\) è la verosimiglianza, cioè la probabilità di osservare i dati dati i parametri;\n\\(p(\\theta)\\) è la distribuzione a priori di \\(\\theta\\);\n\\(p(y)\\) è l’evidenza, ovvero la probabilità totale dei dati osservati.\n\nPer fare previsioni su un nuovo dato \\(\\tilde{y}\\), usiamo la distribuzione predittiva a posteriori, che combina tutte le possibili ipotesi sui parametri \\(\\theta\\), pesate per le loro probabilità a posteriori:\n\\[\np(\\tilde{y} | y) = \\int p(\\tilde{y} | \\theta) p(\\theta | y) \\, d\\theta.\n\\]\nNel caso discreto, l’integrale diventa una somma:\n\\[\np(\\tilde{y} | y) = \\sum_{\\theta} p(\\tilde{y} | \\theta) p(\\theta | y).\n\\]\nQuesta espressione incorpora la nostra incertezza sui parametri, permettendoci di fare previsioni più robuste e coerenti.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_post_pred_distr.html#il-sacchetto-di-monete",
    "href": "chapters/bayesian_inference/11_post_pred_distr.html#il-sacchetto-di-monete",
    "title": "49  Distribuzione predittiva a posteriori",
    "section": "49.3 Il Sacchetto di Monete",
    "text": "49.3 Il Sacchetto di Monete\nIl problema del sacchetto di monete fornisce un esempio pratico per comprendere la distribuzione predittiva a posteriori. Immaginiamo di avere un sacchetto contenente tre tipi di monete:\n\nMoneta di Tipo 0: Dà sempre “croce” (probabilità di “testa” = 0).\nMoneta di Tipo 1: È una moneta equa (probabilità di “testa” = 0.5 e di “croce” = 0.5).\nMoneta di Tipo 2: Dà sempre “testa” (probabilità di “testa” = 1).\n\nSupponiamo di scegliere una moneta a caso dal sacchetto e di lanciarla quattro volte, ottenendo sempre “croce”. Vogliamo calcolare la probabilità di ottenere “croce” al quinto lancio, utilizzando la distribuzione predittiva a posteriori.\n\n\n49.3.1 Passo 1: Probabilità Iniziali (A Priori)\nPrima di osservare i risultati dei lanci, non abbiamo informazioni su quale tipo di moneta sia stato estratto. Attribuiamo quindi una probabilità uniforme (a priori) a ciascun tipo di moneta:\n\n\\(P(\\text{Tipo 0}) = \\frac{1}{3}\\);\n\\(P(\\text{Tipo 1}) = \\frac{1}{3}\\);\n\\(P(\\text{Tipo 2}) = \\frac{1}{3}\\).\n\n\n\n\n49.3.2 Passo 2: Osservare i Risultati e Aggiornare le Probabilità\nDopo aver osservato quattro lanci consecutivi che hanno dato “croce”, possiamo aggiornare le probabilità sui tipi di moneta utilizzando la formula di Bayes.\n\nMoneta di Tipo 0: La probabilità di osservare quattro “croce” è 1, dato che questa moneta dà sempre “croce”.\nMoneta di Tipo 1: La probabilità di osservare quattro “croce” consecutivi è \\((0.5)^4 = 0.0625\\).\nMoneta di Tipo 2: La probabilità di osservare quattro “croce” è 0, dato che questa moneta dà sempre “testa”.\n\nUsiamo la formula di Bayes per calcolare le probabilità posteriori. Supponiamo che \\(D\\) rappresenti il dato osservato (“croce, croce, croce, croce”). La probabilità totale \\(P(D)\\) è:\n\\[\nP(D) = P(D | \\text{Tipo 0}) P(\\text{Tipo 0}) + P(D | \\text{Tipo 1}) P(\\text{Tipo 1}) + P(D | \\text{Tipo 2}) P(\\text{Tipo 2}),\n\\]\ncioè:\n\\[\nP(D) = 1 \\cdot \\frac{1}{3} + 0.0625 \\cdot \\frac{1}{3} + 0 \\cdot \\frac{1}{3} = \\frac{1.0625}{3}.\n\\]\nLe probabilità posteriori diventano quindi:\n\n\\(P(\\text{Tipo 0} | D) = \\frac{1 \\cdot \\frac{1}{3}}{\\frac{1.0625}{3}} = \\frac{1}{1.0625} \\approx 0.941\\);\n\\(P(\\text{Tipo 1} | D) = \\frac{0.0625 \\cdot \\frac{1}{3}}{\\frac{1.0625}{3}} = \\frac{0.0625}{1.0625} \\approx 0.059\\);\n\\(P(\\text{Tipo 2} | D) = 0\\).\n\n\n\n\n49.3.3 Passo 3: Predire il Risultato del Quinto Lancio\nLa probabilità di ottenere “croce” al quinto lancio è calcolata combinando le probabilità posteriori con la probabilità di “croce” per ciascun tipo di moneta:\n\\[\nP(\\text{croce al quinto lancio} | D) = P(\\text{Tipo 0} | D) \\cdot 1 + P(\\text{Tipo 1} | D) \\cdot 0.5 + P(\\text{Tipo 2} | D) \\cdot 0.\n\\]\nInserendo i valori calcolati:\n\\[\nP(\\text{croce al quinto lancio} | D) = 0.941 \\cdot 1 + 0.059 \\cdot 0.5 + 0 \\cdot 0 = 0.9705.\n\\]",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_post_pred_distr.html#interpretazione",
    "href": "chapters/bayesian_inference/11_post_pred_distr.html#interpretazione",
    "title": "49  Distribuzione predittiva a posteriori",
    "section": "49.4 Interpretazione",
    "text": "49.4 Interpretazione\nLa distribuzione predittiva a posteriori combina la nostra incertezza sui parametri con le osservazioni passate, fornendo una stima robusta per eventi futuri. In questo esempio, la probabilità di ottenere “croce” al quinto lancio è alta (\\(0.9705\\)), poiché le osservazioni precedenti indicano una forte probabilità che la moneta scelta sia di Tipo 0.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_post_pred_distr.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/11_post_pred_distr.html#riflessioni-conclusive",
    "title": "49  Distribuzione predittiva a posteriori",
    "section": "49.5 Riflessioni Conclusive",
    "text": "49.5 Riflessioni Conclusive\nIl problema del sacchetto di monete illustra come la distribuzione predittiva a posteriori permetta di fare previsioni integrate e coerenti, aggiornando sistematicamente le credenze iniziali con le evidenze osservate. Questo approccio evidenzia la potenza dell’inferenza bayesiana nel gestire l’incertezza e nel fornire previsioni informate.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_post_pred_distr.html#esercizi",
    "href": "chapters/bayesian_inference/11_post_pred_distr.html#esercizi",
    "title": "49  Distribuzione predittiva a posteriori",
    "section": "49.6 Esercizi",
    "text": "49.6 Esercizi\n\nEsercizio 49.1 Utilizzando un set di dati diverso, ovvero tre “testa” seguite da una “croce”, calcola la distribuzione predittiva a posteriori per il prossimo lancio.\n\n\nEsercizio 49.2 Consideriamo un modello in cui ci sono tre tipi di monete, ognuna con una probabilità diversa di dare “testa” o “croce”:\n\nMoneta di Tipo 0: Questa moneta dà sempre “croce”. La probabilità di ottenere “testa” è 0.\nMoneta di Tipo 1: Questa moneta ha una probabilità di 0.7 di ottenere “testa” e 0.3 di ottenere “croce”.\nMoneta di Tipo 2: Questa moneta dà sempre “testa”. La probabilità di ottenere “testa” è 1.\n\nNel sacchetto ci sono: 2 monete di tipo 0, 1 moneta di tipo 1 e 1 moneta di tipo 2. Supponiamo di osservare la sequenza croce, testa, croce. Vogliamo calcolare la probabilità di ottenere “croce” al quarto lancio.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/introduction_mcmc.html",
    "href": "chapters/mcmc/introduction_mcmc.html",
    "title": "Introduzione",
    "section": "",
    "text": "In questa sezione della dispensa, ci concentreremo sulle procedure Monte Carlo a catena di Markov, con particolare attenzione all’algoritmo di Metropolis, che consente di approssimare la distribuzione a posteriori quando non è possibile ottenere una soluzione analitica. Esploreremo il concetto di predizione bayesiana, fondamentale per la costruzione della distribuzione predittiva a posteriori, e discuteremo anche la distribuzione predittiva a priori. Applicheremo l’inferenza bayesiana a diversi contesti, tra cui la stima di una proporzione, il confronto tra due proporzioni, la stima di una media da una distribuzione normale e il confronto tra due medie. Esamineremo inoltre il modello bayesiano di Poisson per l’analisi delle frequenze. Infine, introdurremo il modello gerarchico bayesiano, uno strumento potente per affrontare situazioni in cui le osservazioni sono strutturate su diversi livelli di incertezza.",
    "crumbs": [
      "MCMC",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html",
    "href": "chapters/mcmc/01_metropolis.html",
    "title": "50  L’algoritmo di Metropolis-Hastings",
    "section": "",
    "text": "50.1 Introduzione\nIn precedenza, abbiamo esplorato diversi esempi di inferenza bayesiana riguardanti la distribuzione a posteriori di un singolo parametro, come nel caso del modello bernoulliano. Abbiamo anche trattato metodi come l’approssimazione tramite griglia e l’utilizzo dei priori coniugati per ottenere o approssimare la distribuzione a posteriori. In questo capitolo, ci concentreremo sul metodo di simulazione Monte Carlo a Catena di Markov (MCMC).\nIl metodo MCMC è una tecnica computazionale utilizzata per approssimare distribuzioni di probabilità complesse, generando una sequenza di campioni (correlati) attraverso una catena di Markov, in cui ogni campione viene ottenuto tramite una transizione iterativa con probabilità attentamente progettate.\nIl metodo MCMC rappresenta l’approccio moderno per approssimare distribuzioni a posteriori complesse. L’idea di base è simile al concetto di considerare la distribuzione a posteriori come una popolazione da cui estraiamo campioni ripetutamente. Con un numero sufficientemente grande di campioni (ad esempio 1000), la distribuzione del campione si avvicina molto alla distribuzione della popolazione, consentendo stime affidabili dei parametri incogniti.\nUna differenza rispetto all’analogia precedente è che i campioni generati con MCMC sono correlati: se il primo campione ha un valore alto, anche il successivo ha maggiori probabilità di essere alto. Questo accade perché non abbiamo un modo diretto per estrarre campioni dalla distribuzione a posteriori, che spesso ha una forma molto complessa; utilizziamo invece algoritmi che ci permettono di arrivarci indirettamente. La correlazione tra i campioni non rappresenta un problema rilevante, ma rende necessario estrarre un numero maggiore di campioni per compensare questa correlazione e ottenere stime accurate.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#il-denominatore-bayesiano",
    "href": "chapters/mcmc/01_metropolis.html#il-denominatore-bayesiano",
    "title": "50  L’algoritmo di Metropolis-Hastings",
    "section": "50.2 Il denominatore bayesiano",
    "text": "50.2 Il denominatore bayesiano\nNell’approccio bayesiano, l’obiettivo principale è determinare la distribuzione a posteriori \\(p(\\theta \\mid y)\\) di un parametro \\(\\theta\\), utilizzando i dati osservati \\(y\\) e la distribuzione a priori \\(p(\\theta)\\). Questo si ottiene attraverso il teorema di Bayes:\n\\[\np(\\theta \\mid y) = \\frac{p(y \\mid \\theta) p(\\theta)}{\\int p(y \\mid \\theta) p(\\theta) d\\theta}.\n\\]\nIl denominatore \\(\\int p(y \\mid \\theta) p(\\theta) d\\theta\\) rappresenta la probabilità marginale di \\(y\\), chiamata evidenza. Tale integrale garantisce che \\(p(\\theta \\mid y)\\) sia una distribuzione di probabilità valida. Tuttavia, il calcolo di questo integrale è spesso complesso, soprattutto in modelli articolati o ad alta dimensionalità, rendendo difficile ottenere una rappresentazione esplicita della distribuzione a posteriori.\nUna possibile semplificazione analitica è l’uso di distribuzioni a priori coniugate, che offrono una soluzione esatta per la distribuzione a posteriori. Tuttavia, questo approccio è limitato a casi specifici e impone forti vincoli sulla scelta delle distribuzioni a priori e delle verosimiglianze.\nUn approccio più generale è ricorrere a soluzioni numeriche. In precedenza abbiamo discusso il metodo di campionamento a griglia. Tuttavia, i metodi di campionamento a griglia, sebbene efficaci per modelli con pochi parametri, diventano impraticabili man mano che il numero di parametri aumenta, poiché richiedono una copertura densa dell’intero spazio parametrico. Di conseguenza, per modelli più complessi e con più parametri, si rende necessario un metodo che possa esplorare lo spazio dei parametri in maniera più efficiente.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#il-metodo-monte-carlo-e-le-sue-limitazioni",
    "href": "chapters/mcmc/01_metropolis.html#il-metodo-monte-carlo-e-le-sue-limitazioni",
    "title": "50  L’algoritmo di Metropolis-Hastings",
    "section": "50.3 Il metodo Monte Carlo e le sue limitazioni",
    "text": "50.3 Il metodo Monte Carlo e le sue limitazioni\nIl metodo Monte Carlo fornisce una soluzione a questo problema generando campioni casuali dalla distribuzione a posteriori \\(p(\\theta \\mid y)\\). L’idea centrale è semplice: se possiamo generare un numero sufficiente di campioni casuali dalla distribuzione a posteriori, possiamo usare questi campioni per stimare le proprietà d’interesse, come la media o la varianza del parametro \\(\\theta\\). Questa procedura ci permette di evitare il calcolo diretto dell’integrale complicato nel denominatore del teorema di Bayes.\nPer esempio, se fossimo in grado di generare una serie di campioni \\(\\theta^{(1)}, \\theta^{(2)}, \\dots, \\theta^{(T)}\\) dalla distribuzione a posteriori, potremmo approssimare il valore atteso di \\(\\theta\\) con la media campionaria:\n\\[\n\\mathbb{E}[\\theta] \\approx \\frac{1}{T} \\sum_{t=1}^T \\theta^{(t)}.\n\\]\nTuttavia, un problema significativo nei metodi Monte Carlo tradizionali è che generare campioni indipendenti dalla distribuzione a posteriori non è semplice, soprattutto quando questa distribuzione ha una forma complessa, è multimodale o definita su spazi di alta dimensionalità. Le regioni di alta densità, che contribuiscono maggiormente al valore dell’integrale, possono essere difficili da individuare e campionare adeguatamente. Per ottenere una buona copertura dello spazio dei parametri, sarebbe necessario generare un numero enorme di campioni, rendendo il metodo Monte Carlo inefficiente e computazionalmente oneroso.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#perché-i-metodi-mcmc-sono-necessari",
    "href": "chapters/mcmc/01_metropolis.html#perché-i-metodi-mcmc-sono-necessari",
    "title": "50  L’algoritmo di Metropolis-Hastings",
    "section": "50.4 Perché i metodi MCMC sono necessari",
    "text": "50.4 Perché i metodi MCMC sono necessari\nÈ qui che entrano in gioco i Metodi Monte Carlo a Catena di Markov (MCMC). Questi metodi risolvono il problema generando campioni dipendenti dalla distribuzione a posteriori, sfruttando la struttura di una catena di Markov. A differenza dei campioni indipendenti utilizzati nei metodi Monte Carlo tradizionali, i metodi MCMC costruiscono una sequenza di campioni, in cui ciascun campione dipende dal precedente. Questa dipendenza permette di esplorare in modo più efficiente le regioni di alta densità della distribuzione a posteriori, riducendo il numero di campioni necessari per ottenere stime accurate.\nIn pratica, MCMC consente di evitare di campionare inutilmente da regioni di bassa densità, concentrandosi invece sulle aree più rilevanti della distribuzione. Questo approccio è particolarmente potente nei contesti ad alta dimensionalità o in presenza di distribuzioni multimodali, dove i metodi Monte Carlo tradizionali risulterebbero inefficaci o richiederebbero un numero sproporzionato di campioni.\nIn sintesi, i metodi Monte Carlo classici sono limitati quando si tratta di campionare da distribuzioni complesse e multidimensionali. I metodi MCMC, invece, offrono una soluzione efficiente e flessibile, permettendo di esplorare le distribuzioni a posteriori anche in contesti complessi, senza la necessità di campionare indipendentemente ogni punto. Nel prossimo paragrafo introdurremo i concetti fondamentali delle catene di Markov e vedremo come queste vengono utilizzate nei metodi MCMC per campionare efficacemente da distribuzioni a posteriori difficili da trattare analiticamente.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#le-catene-di-markov",
    "href": "chapters/mcmc/01_metropolis.html#le-catene-di-markov",
    "title": "50  L’algoritmo di Metropolis-Hastings",
    "section": "50.5 Le Catene di Markov",
    "text": "50.5 Le Catene di Markov\nLe catene di Markov, introdotte da Andrey Markov nel 1906, rappresentano un’estensione della legge dei grandi numeri per descrivere sequenze di variabili casuali non indipendenti (per maggiori dettagli, si veda l’?sec-appendix-markov-first-order). Nella statistica tradizionale, si lavora spesso con sequenze di variabili casuali indipendenti e identicamente distribuite (i.i.d.), come \\(X_0, X_1, \\ldots, X_n, \\ldots\\), dove ogni variabile è indipendente dalle altre e segue la stessa distribuzione. Tuttavia, nei modelli più realistici che descrivono fenomeni complessi, l’indipendenza tra variabili è un’assunzione troppo rigida e spesso irrealistica.\nLe catene di Markov superano questo limite introducendo una dipendenza locale, detta dipendenza a un passo, formalizzata nella cosiddetta proprietà di Markov. Secondo questa proprietà, il valore futuro di una variabile casuale \\(X_{n+1}\\) dipende unicamente dal valore attuale \\(X_n\\), ignorando tutta la storia precedente della catena. Questo permette di semplificare notevolmente i calcoli relativi alle probabilità condizionali. La proprietà di Markov è formalmente espressa come:\n\\[\nP(X_{n+1} = j | X_n = i, X_{n-1} = i_{n-1}, \\ldots, X_0 = i_0) = P(X_{n+1} = j | X_n = i).\n\\]\nIn altre parole, la previsione di un evento futuro dipende soltanto dallo stato attuale e non da tutti gli eventi precedenti, semplificando così il processo di modellazione. Questa caratteristica rende le catene di Markov particolarmente utili per descrivere sistemi dinamici in cui gli eventi successivi sono influenzati solo dallo stato immediatamente precedente.\n\n50.5.1 Catene di Markov e Metodi MCMC\nLe catene di Markov sono fondamentali nei metodi Monte Carlo a Catena di Markov (MCMC) perché forniscono un modo efficiente per generare sequenze di campioni che approssimano distribuzioni di probabilità complesse. Mentre i metodi Monte Carlo classici generano campioni indipendenti, i metodi MCMC costruiscono una sequenza di campioni dipendenti attraverso una catena di Markov, in cui ciascun campione è ottenuto in base al campione precedente. Questo approccio consente di concentrarsi sulle regioni di alta probabilità della distribuzione, migliorando l’efficienza del campionamento.\nPer esempio, consideriamo una distribuzione di probabilità \\(P(x_1, x_2, ..., x_n)\\) definita su un insieme di variabili \\(x_1, x_2, ..., x_n\\). Nei metodi MCMC, si genera una sequenza di configurazioni \\(\\{x(0)\\}, \\{x(1)\\}, \\{x(2)\\}, \\dots\\), tale che la frequenza con cui ogni configurazione \\(\\{x\\}\\) viene visitata è proporzionale alla sua probabilità \\(P(x)\\). In questo modo, le configurazioni più probabili vengono visitate più spesso, garantendo che l’algoritmo converga alla distribuzione di interesse.\n\n\n50.5.2 Condizioni fondamentali per le Catene di Markov\nAffinché un algoritmo MCMC funzioni correttamente e converga alla distribuzione desiderata, la catena di Markov deve soddisfare alcune condizioni fondamentali:\n\nProprietà di Markov: La prossima configurazione dipende solo dalla configurazione attuale, non dalla storia passata. Questo garantisce che l’evoluzione della catena sia “locale” e non influenzata dagli stati remoti.\nIrriducibilità: Ogni configurazione della catena può essere raggiunta da qualsiasi altra in un numero finito di passi. Ciò assicura che l’intero spazio dei parametri possa essere esplorato.\nAperiodicità: La catena non segue cicli fissi e non ritorna sistematicamente allo stesso stato dopo un certo numero di passi. Questo garantisce che la catena possa esplorare lo spazio dei parametri in modo casuale.\nCondizione di bilanciamento dettagliato: La probabilità di passare da uno stato a un altro deve essere bilanciata dalla probabilità di tornare allo stato iniziale, assicurando così che la distribuzione di equilibrio della catena sia proprio la distribuzione a posteriori desiderata.\n\n\n\n50.5.3 Algoritmi MCMC\nEsistono diversi algoritmi basati su MCMC, ognuno con caratteristiche specifiche:\n\nMetropolis-Hastings: Questo è uno degli algoritmi più noti. Si basa sulla generazione di una configurazione proposta che viene accettata o rifiutata in base a un criterio di probabilità. Se la configurazione proposta ha una probabilità più alta, viene accettata; se ha una probabilità più bassa, può essere accettata con una certa probabilità, che dipende dal rapporto tra le probabilità delle due configurazioni.\nGibbs Sampling: In questo algoritmo, le variabili vengono aggiornate una alla volta, campionando ogni variabile dalla sua distribuzione condizionale data la configurazione corrente delle altre variabili. È particolarmente utile quando le distribuzioni condizionali sono note o facili da campionare.\nHamiltonian Monte Carlo (HMC): Utilizza principi della meccanica hamiltoniana per esplorare lo spazio dei parametri in modo più efficiente, considerando non solo le probabilità, ma anche le “forze” che muovono i campioni attraverso lo spazio dei parametri. Questo approccio è particolarmente vantaggioso per modelli complessi e ad alta dimensionalità, poiché consente di generare campioni lontani dallo stato corrente senza ricorrere a piccoli passi.\n\nIn sintesi, le catene di Markov forniscono il fondamento teorico e pratico per i metodi MCMC, offrendo un modo efficiente per esplorare lo spazio dei parametri nei modelli complessi. Grazie alle proprietà specifiche delle catene di Markov, i metodi MCMC permettono di affrontare problemi di inferenza bayesiana che sarebbero intrattabili con approcci analitici o con i metodi Monte Carlo classici. Essendo flessibili e potenti, le catene di Markov continueranno a essere uno strumento fondamentale nella statistica e nella scienza dei dati.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#estrazione-di-campioni-dalla-distribuzione-a-posteriori",
    "href": "chapters/mcmc/01_metropolis.html#estrazione-di-campioni-dalla-distribuzione-a-posteriori",
    "title": "50  L’algoritmo di Metropolis-Hastings",
    "section": "50.6 Estrazione di campioni dalla distribuzione a posteriori",
    "text": "50.6 Estrazione di campioni dalla distribuzione a posteriori\nIn questo capitolo presenteremo l’algoritmo di Metropolis, che è uno dei più semplici e potenti metodi MCMC. Sfruttando la struttura delle catene di Markov, esplora in modo efficiente lo spazio dei parametri, permettendo di ottenere campioni dalla distribuzione a posteriori anche in casi complessi, dove i metodi analitici falliscono. In sostanza, il MCMC genera un gran numero di valori per il parametro \\(\\theta\\) che, nel loro insieme, approssimano la distribuzione di interesse \\(p(\\theta \\mid y)\\). A questo fine, il capitolo è strutturato in varie sezioni che facilitano la comprensione progressiva del tema.\n\nInizieremo discutendo di come la distribuzione a posteriori possa essere approssimata mediante tecniche di simulazione convenzionali. Questa prima parte presuppone che la distribuzione target, o “a posteriori,” sia già conosciuta o disponibile per l’analisi.\nIn seguito, passeremo a illustrare come l’algoritmo di Metropolis possa essere utilizzato per affrontare situazioni in cui la distribuzione a posteriori non è direttamente nota. In questi casi, spesso abbiamo a disposizione informazioni riguardanti la distribuzione a priori e la funzione di verosimiglianza, che possono essere utilizzate per ottenere un’approssimazione efficace della distribuzione a posteriori.\n\nA titolo esemplificativo, utilizzeremo il dataset moma_sample.csv, il quale costituisce un campione casuale di 100 artisti provenienti dal Museo di Arte Moderna di New York (MoMA) e contiene diverse informazioni relative a ciascun artista.\nIl nostro interesse è focalizzato sulla determinazione della probabilità che un artista presente nel MoMA appartenga alla generazione X o a una generazione successiva (nati dopo il 1965). Questa probabilità sarà indicata come \\(\\pi\\).\nImportiamo i dati.\n\nmoma_sample &lt;- rio::import(here::here(\"data\", \"moma_sample.csv\"))\n\nEsaminiamo le prime cinque righe del DataFrame.\n\nmoma_sample |&gt; \n  head()\n#&gt;                artist  country birth death alive  genx gender count\n#&gt; 1        Ad Gerritsen    dutch  1940  2015 FALSE FALSE   male     1\n#&gt; 2 Kirstine Roepstorff   danish  1972    NA  TRUE  TRUE female     3\n#&gt; 3    Lisa Baumgardner american  1958  2015 FALSE FALSE female     2\n#&gt; 4         David Bates american  1952    NA  TRUE FALSE   male     1\n#&gt; 5          Simon Levy american  1946    NA  TRUE FALSE   male     1\n#&gt; 6      Pierre Mercure canadian  1927  1966 FALSE FALSE   male     8\n#&gt;   year_acquired_min year_acquired_max\n#&gt; 1              1981              1981\n#&gt; 2              2005              2005\n#&gt; 3              2016              2016\n#&gt; 4              2001              2001\n#&gt; 5              2012              2012\n#&gt; 6              2008              2008\n\nDai dati osserviamo che solo 14 artisti su 100 appartengono alla generazione X o a una generazione successiva.\n\n# Calcoliamo la distribuzione delle generazioni\nresult &lt;- table(moma_sample$genx)\nresult\n#&gt; \n#&gt; FALSE  TRUE \n#&gt;    86    14\n\nIl valore campionato \\(y = 14\\) riflette le caratteristiche del campione che è stato osservato. Tuttavia, poiché il MOMA contiene opere di migliaia di artisti, sorge una domanda riguardante il vero valore di \\(\\theta\\) (la probabilità di appartenere alla generazione X o a una generazione successiva) all’interno di questa popolazione.\nPossiamo interpretare i dati \\(y = 14\\) come l’esito di una variabile casuale Binomiale con parametri \\(N = 100\\) e \\(\\theta\\) sconosciuto.\nSupponiamo che le nostre credenze pregresse riguardo a \\(\\theta\\) possano essere modellate attraverso una distribuzione Beta(4, 6).\nSfruttando le proprietà delle distribuzioni coniugate, possiamo calcolare esattamente la distribuzione a posteriori:\n# Y ~ Binomiale(100, π)\n# θ ~ Beta(4, 6)\n# Posteriori: θ | (Y = 14) ~ Beta(4 + 14, 6 + 100 - 14) → Beta(18, 92)\nNella figura seguente, è rappresentata la distribuzione a posteriori del parametro \\(\\theta\\), insieme alla distribuzione a priori specificata.\n\n# Generiamo la sequenza dei valori per θ\nx &lt;- seq(0, 1, length.out = 1000)\n\n# Calcoliamo le densità della prior e della posterior\nprior_density &lt;- dbeta(x, 4, 6)\nposterior_density &lt;- dbeta(x, 18, 92)\n\n# Creiamo il grafico\nplot(\n  x, prior_density,\n  type = \"l\", col = \"blue\", lwd = 2,\n  ylim = c(0, max(c(prior_density, posterior_density))),\n  xlab = \"Valore del Parametro\",\n  ylab = \"Densità\",\n  main = \"Densità a Priori e a Posteriori\"\n)\nlines(x, posterior_density, col = \"red\", lwd = 2)\npolygon(\n  c(x, rev(x)), c(prior_density, rep(0, length(x))),\n  col = adjustcolor(\"blue\", alpha.f = 0.5), border = NA\n)\npolygon(\n  c(x, rev(x)), c(posterior_density, rep(0, length(x))),\n  col = adjustcolor(\"red\", alpha.f = 0.5), border = NA\n)\nlegend(\"topright\",\n  legend = c(\"Prior: Beta(4, 6)\", \"Posterior: Beta(18, 92)\"),\n  fill = c(\n    adjustcolor(\"blue\", alpha.f = 0.5),\n    adjustcolor(\"red\", alpha.f = 0.5)\n  ), border = NA\n)\n\n\n\n\n\n\n\n\nIn questo grafico, la curva blu rappresenta la distribuzione a priori \\(\\text{Beta}(4, 6)\\), mentre la curva rossa mostra la distribuzione a posteriori \\(\\text{Beta}(18, 92)\\). La sovrapposizione delle aree evidenzia come l’evidenza fornita dai dati modifichi la conoscenza iniziale sul parametro \\(\\theta\\).\nSe vogliamo conoscere il valore della media a posteriori di \\(\\theta\\), il risultato esatto è\n\\[\n\\bar{\\theta}_{post} = \\frac{\\alpha}{\\alpha + \\beta} = \\frac{18}{18 + 92} \\approx 0.1636.\n\\]\n\n50.6.1 Simulazione con distribuzione target nota\nUsiamo ora una simulazione numerica per stimare la media a posteriori di \\(\\theta\\). Conoscendo la forma della distribuzione a posteriori \\(Beta(18, 92)\\), possiamo generare un campione di osservazioni casuali da questa distribuzione. Successivamente, calcoliamo la media delle osservazioni ottenute per ottenere un’approssimazione della media a posteriori.\nSe vogliamo ottenere un risultato approssimato con un numero limitato di campioni (ad esempio, 10), possiamo utilizzare la seguente simulazione:\n\n# Generiamo 10 campioni dalla distribuzione Beta(18, 92)\nset.seed(1)  # Per riproducibilità\ny &lt;- rbeta(10, shape1 = 18, shape2 = 92)\ny\n#&gt;  [1] 0.1396391 0.1711479 0.1319196 0.1773551 0.1324770 0.1843693 0.1962862\n#&gt;  [8] 0.1517042 0.2418334 0.1799960\n\n\n# Calcoliamo la media dei campioni\nmean(y)\n#&gt; [1] 0.1706728\n\nTuttavia, con soli 10 campioni, l’approssimazione potrebbe non essere molto accurata. Aumentando il numero di campioni, ad esempio a 10.000, possiamo ottenere una stima molto più precisa:\n\n# Generiamo 10.000 campioni e calcoliamo la media\nset.seed(123)  # Per riproducibilità\nmean(rbeta(10000, shape1 = 18, shape2 = 92))\n#&gt; [1] 0.1637428\n\nQuando il numero di campioni dalla distribuzione a posteriori diventa molto grande, la media campionaria converge al valore atteso della distribuzione della popolazione. Questo principio non si applica solo alla media, ma anche ad altre statistiche descrittive come la moda e la varianza.\nÈ importante sottolineare che l’applicazione della simulazione di Monte Carlo è efficace per calcolare distribuzioni a posteriori solo quando conosciamo la distribuzione stessa e possiamo utilizzare funzioni Python per estrarre campioni casuali da tale distribuzione. Ciò è stato possibile nel caso della distribuzione a posteriori \\(Beta(18, 92)\\).\nTuttavia, questa situazione ideale non si verifica sempre nella pratica, poiché le distribuzioni a priori coniugate alla verosimiglianza sono spesso rare. Per esempio, nel caso di una verosimiglianza binomiale e una distribuzione a priori gaussiana, l’espressione\n\\[\np(\\theta \\mid y) = \\frac{\\mathrm{e}^{-(\\theta - 1 / 2)^2} \\theta^y (1 - \\theta)^{n - y}} {\\int_0^1 \\mathrm{e}^{-(t - 1 / 2)^2} t^y (1 - t)^{n - y} dt}\n\\]\nrende impossibile calcolare analiticamente la distribuzione a posteriori di \\(\\theta\\), precludendo quindi l’utilizzo diretto di Python per generare campioni casuali.\nIn queste circostanze, però, è possibile ottenere campioni casuali dalla distribuzione a posteriori mediante l’uso di metodi Monte Carlo basati su Catena di Markov (MCMC). Gli algoritmi MCMC, come ad esempio l’algoritmo Metropolis, costituiscono una classe di metodi che consentono di estrarre campioni casuali dalla distribuzione a posteriori senza richiedere la conoscenza della sua rappresentazione analitica. Le tecniche MCMC sono ampiamente adottate per risolvere problemi di inferenza bayesiana e rappresentano il principale strumento computazionale per ottenere stime approssimate di distribuzioni a posteriori in situazioni complesse e non analiticamente trattabili.\n\n\n50.6.2 Algoritmo di Metropolis\nL’algoritmo di Metropolis appartiene alla famiglia dei metodi Monte Carlo basati su catene di Markov (MCMC), sfruttando le proprietà di queste catene per generare campioni da una distribuzione target. Il suo obiettivo principale è di esplorare lo spazio dei parametri in modo efficiente, producendo campioni che approssimano la distribuzione a posteriori di interesse.\n\n\n50.6.3 Principio di Funzionamento\nL’algoritmo inizia da un valore iniziale per i parametri e, in ogni iterazione, genera un nuovo campione tramite una distribuzione di proposta (solitamente una distribuzione normale centrata sul valore corrente). Successivamente, decide se accettare il nuovo campione in base al confronto tra le densità posteriori del nuovo campione e di quello precedente. Questa accettazione avviene in modo probabilistico, favorendo campioni con una densità più alta ma consentendo anche l’accettazione di campioni peggiori per evitare che la catena rimanga bloccata in minimi locali.\n\n\n50.6.4 Burn-in e Convergenza\nPoiché i primi campioni potrebbero non rappresentare bene la distribuzione target, si esclude spesso una porzione iniziale della catena (fase di burn-in). Con il progredire delle iterazioni, i campioni si distribuiscono in accordo con la distribuzione stazionaria desiderata, indipendentemente dallo stato iniziale scelto. Questo processo permette di esplorare lo spazio dei parametri in modo efficiente.\n\n\n50.6.5 Meccanismo di Accettazione e Rifiuto\nL’algoritmo di Metropolis bilancia due esigenze opposte:\n\nEsplorazione di nuove aree dello spazio dei parametri.\nSfruttamento delle informazioni già acquisite dai campioni precedenti.\n\nUtilizzando una regola probabilistica per accettare campioni peggiori (con minore densità a posteriori), l’algoritmo evita di restare intrappolato in minimi locali, esplorando così in modo più completo l’intera distribuzione.\n\n\n50.6.6 Passaggi Fondamentali dell’Algoritmo di Metropolis\n\nScelta di uno stato iniziale \\(\\theta_1\\) e impostazione del contatore \\(t = 1\\).\n\nQuesto è il punto di partenza della catena, dove \\(\\theta_1\\) rappresenta il primo campione.\n\nProposta di un nuovo campione \\(\\theta_p\\).\n\nUn nuovo valore \\(\\theta_p\\) viene generato da una distribuzione di proposta \\(g(\\theta_p \\mid \\theta_t)\\), solitamente una distribuzione normale centrata sul campione corrente \\(\\theta_t\\) con una deviazione standard \\(\\tau\\) che controlla l’ampiezza dei passi.\n\nVerifica dei vincoli del campione proposto.\n\nSe il nuovo campione deve rispettare dei vincoli (ad esempio, essere compreso tra 0 e 1 per probabilità), campioni non validi vengono automaticamente rifiutati.\n\nCalcolo del rapporto di accettazione \\(\\alpha\\).\n\nSi calcola \\(\\alpha = \\frac{p(\\theta_p \\mid y)}{p(\\theta_t \\mid y)}\\), che rappresenta il rapporto tra le densità a posteriori del nuovo campione \\(\\theta_p\\) e del campione corrente \\(\\theta_t\\). Questo valore guida la decisione di accettazione.\n\nDecisione di accettazione.\n\nSe \\(\\alpha \\geq 1\\), il nuovo campione \\(\\theta_p\\) viene accettato incondizionatamente.\nSe \\(\\alpha &lt; 1\\), il campione \\(\\theta_p\\) viene accettato con probabilità \\(\\alpha\\). In caso di rifiuto, si mantiene il campione corrente \\(\\theta_t\\) per la prossima iterazione.\n\nRipetizione del processo.\n\nSi ripetono i passaggi dal 2 al 5 fino a ottenere il numero desiderato di campioni.\n\n\n\n\n50.6.7 Dettagli Aggiuntivi\n\nDistribuzione di proposta: La distribuzione di proposta \\(g(\\theta_p \\mid \\theta_t)\\) genera nuovi campioni attorno a \\(\\theta_t\\). Tipicamente si usa una normale \\(N(\\theta_t, \\tau)\\), dove \\(\\tau\\) controlla quanto il nuovo campione si discosta da quello corrente. Scegliere un \\(\\tau\\) troppo piccolo può rendere l’esplorazione lenta, mentre un \\(\\tau\\) troppo grande può far rifiutare troppi campioni, riducendo l’efficienza.\nRapporto di accettazione \\(\\alpha\\): Se il nuovo campione ha una densità a posteriori maggiore del campione corrente, viene sempre accettato. Se ha una densità inferiore, viene accettato con probabilità \\(\\alpha\\), il che consente di esplorare anche regioni meno probabili della distribuzione.\nAccettazione probabilistica: Accettare campioni peggiori occasionalmente aiuta l’algoritmo a evitare di bloccarsi in minimi locali. Questo è uno dei punti di forza dell’algoritmo di Metropolis, che garantisce una buona esplorazione dello spazio dei parametri.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#esempio-di-implementazione",
    "href": "chapters/mcmc/01_metropolis.html#esempio-di-implementazione",
    "title": "50  L’algoritmo di Metropolis-Hastings",
    "section": "50.7 Esempio di Implementazione",
    "text": "50.7 Esempio di Implementazione\nPer questa simulazione, adattiamo l’approccio proposto da Elizaveta Semenova, implementando l’algoritmo di Metropolis-Hastings in R. Cominciamo definendo alcune funzioni fondamentali.\nDefiniamo una funzione prior che calcola la densità della distribuzione Beta(4, 6) per un dato valore di \\(\\theta\\):\n\n# Definizione della distribuzione a priori (Beta(4, 6))\nprior &lt;- function(p) {\n  dbeta(p, shape1 = 4, shape2 = 6)\n}\n\nDefiniamo la funzione likelihood, che calcola la densità della verosimiglianza binomiale per 14 successi su 100 prove:\n\n# Definizione della funzione di verosimiglianza (Binomiale \n# con y = 14 su n = 100)\nlikelihood &lt;- function(p) {\n  y &lt;- 14\n  n &lt;- 100\n  dbinom(y, size = n, prob = p)\n}\n\nDefiniamo la funzione posterior, che calcola la densità della distribuzione a posteriori non normalizzata come prodotto tra la distribuzione a priori e la verosimiglianza:\n\n# Definizione della distribuzione a posteriori (non normalizzata)\nposterior &lt;- function(p) {\n  likelihood(p) * prior(p)\n}\n\nLa distribuzione proposta sarà una distribuzione normale centrata sullo stato corrente con una deviazione standard specificata:\n\n# Distribuzione proposta (normale centrata sullo stato corrente)\nproposal_distribution &lt;- function(current_state, proposal_sigma) {\n  rnorm(1, mean = current_state, sd = proposal_sigma)\n}\n\nDefiniamo infine la distribuzione target, che corrisponde alla distribuzione a posteriori:\n\n# Distribuzione target, equivalente alla distribuzione a posteriori\ntarget_distribution &lt;- function(p) {\n  posterior(p)\n}\n\nProcediamo ora con l’implementazione dell’algoritmo di Metropolis-Hastings, considerando i dati relativi agli artisti della Generazione X presenti al MoMA. La distribuzione a priori per \\(\\theta\\) è modellata come una Beta(4, 6).\n\n# Algoritmo di Metropolis-Hastings\nmetropolis_hastings &lt;- function(num_samples, initial_state, proposal_sigma) {\n  # Inizializza lo stato corrente e la lista dei campioni\n  samples &lt;- numeric(num_samples)\n  current_state &lt;- initial_state\n\n  for (i in seq_len(num_samples)) {\n    # Proponi un nuovo stato dalla distribuzione proposta\n    proposed_state &lt;- proposal_distribution(current_state, proposal_sigma)\n\n    # Verifica che il valore proposto sia tra 0 e 1\n    if (proposed_state &gt;= 0 && proposed_state &lt;= 1) {\n      # Calcola il rapporto di accettazione\n      acceptance_ratio &lt;- min(\n        1,\n        target_distribution(proposed_state) / target_distribution(current_state)\n      )\n\n      # Accetta o rifiuta lo stato proposto\n      if (runif(1) &lt; acceptance_ratio) {\n        current_state &lt;- proposed_state\n      }\n    }\n\n    # Registra lo stato corrente (accettato o rifiutato)\n    samples[i] &lt;- current_state\n  }\n\n  return(samples)\n}\n\n\n\n\n\n\n\nPunti Chiave dell’Algoritmo\n\n\n\n\nGenerazione dei nuovi stati: Ogni nuovo stato viene proposto campionando da una distribuzione normale centrata sullo stato corrente. Questo approccio consente un’esplorazione sistematica dello spazio dei parametri.\n\nControllo dei limiti: Gli stati proposti devono rientrare nell’intervallo [0, 1], poiché rappresentano probabilità. Questo assicura che i valori generati siano validi nel contesto dell’analisi.\n\nRapporto di accettazione: La decisione di accettare o rifiutare un nuovo stato è basata sul confronto tra la densità a posteriori del nuovo stato e quella dello stato corrente. Stati più probabili vengono sempre accettati, mentre quelli meno probabili sono accettati con una probabilità proporzionale.\n\nMemorizzazione degli stati: Ogni iterazione salva lo stato corrente, sia che il nuovo stato venga accettato sia che venga rifiutato, garantendo una catena continua di valori.\n\n\n\nQuesta implementazione fornisce una stima robusta della distribuzione a posteriori utilizzando una combinazione di una distribuzione a priori e dei dati osservati.\nLa distribuzione normale utilizzata per la proposta è simmetrica, soddisfacendo i requisiti dell’algoritmo di Metropolis. Questa simmetria garantisce che la probabilità di proporre uno stato \\(\\theta_p\\) partendo da \\(\\theta_t\\) sia uguale alla probabilità inversa, assicurando l’equilibrio dettagliato necessario per la corretta convergenza della catena Markoviana.\n\n50.7.1 Esecuzione dell’Algoritmo\n\n# Parametri dell'algoritmo\nnum_samples &lt;- 10000\ninitial_state &lt;- 0.5\nproposal_sigma &lt;- 0.1\n\n# Esecuzione del campionamento\nset.seed(123)  # Per riproducibilità\nsamples &lt;- metropolis_hastings(num_samples, initial_state, proposal_sigma)\n\n\n\n50.7.2 Analisi dei Risultati\nScartiamo i primi 5000 campioni per considerare solo quelli generati dopo il burn-in:\n\nburnin &lt;- floor(num_samples * 0.5)\npost_burnin_samples &lt;- samples[-seq_len(burnin)]\n\nCalcoliamo la media e la deviazione standard dei campioni:\n\n# Media a posteriori\nmean(post_burnin_samples)\n#&gt; [1] 0.1630511\n\n# Deviazione standard a posteriori\nsd(post_burnin_samples)\n#&gt; [1] 0.03535041\n\nVisualizziamo l’evoluzione della catena per i primi 200 campioni e per quelli post-burn-in:\n\n# Trace plot dei primi 200 campioni\nplot(\n  samples[1:200], \n  type = \"l\", \n  main = \"Trace Plot (Primi 200 Campioni)\",\n  xlab = \"Iterazioni\", \n  ylab = expression(theta)\n)\n\n\n\n\n\n\n\n\n\n# Trace plot dopo il burn-in\nplot(\n  post_burnin_samples, \n  type = \"l\", \n  main = \"Trace Plot (Post Burn-in)\",\n  xlab = \"Iterazioni\", \n  ylab = expression(theta)\n)\n\n\n\n\n\n\n\n\nSovrapponiamo la distribuzione analitica \\(\\text{Beta}(18, 92)\\) all’istogramma dei campioni post-burn-in:\n\n# Istogramma e distribuzione analitica\nhist(\n  post_burnin_samples, \n  breaks = 20, \n  probability = TRUE, \n  col = \"lightblue\",\n  main = \"Istogramma e Distribuzione Posteriori\", \n  xlab = expression(theta)\n)\ncurve(\n  dbeta(x, 18, 92), \n  add = TRUE, \n  col = \"red\", \n  lwd = 2\n)\nlegend(\n  \"topright\", \n  legend = c(\"Istogramma MCMC\", \"Beta(18, 92)\"),\n  col = c(\"lightblue\", \"red\"), lwd = 2, fill = c(\"lightblue\", NA)\n)\n\n\n\n\n\n\n\n\nCalcoliamo l’intervallo di credibilità al 94%:\n\nquantile(post_burnin_samples, probs = c(0.03, 0.97))\n#&gt;        3%       97% \n#&gt; 0.1020092 0.2347237\n\nQuesta implementazione in R dimostra come utilizzare l’algoritmo di Metropolis per stimare una distribuzione a posteriori e analizzare i risultati in modo dettagliato e riproducibile.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#catene-di-markov-e-convergenza",
    "href": "chapters/mcmc/01_metropolis.html#catene-di-markov-e-convergenza",
    "title": "50  L’algoritmo di Metropolis-Hastings",
    "section": "50.8 Catene di Markov e Convergenza",
    "text": "50.8 Catene di Markov e Convergenza\nNell’ambito delle simulazioni Monte Carlo, una catena rappresenta una sequenza di valori campionati dall’algoritmo durante le sue iterazioni. Ogni valore nella catena corrisponde a un possibile stato del sistema che stiamo modellando. In altre parole, una catena traccia il percorso che l’algoritmo segue nello spazio dei parametri, esplorando le diverse configurazioni possibili.\nPer verificare se l’algoritmo ha raggiunto la convergenza e se i campioni generati rappresentano effettivamente la distribuzione di interesse, è utile eseguire multiple catene. Ogni catena parte da un punto iniziale diverso nello spazio dei parametri.\nI vantaggi delle multiple catene:\n\nDiagnostica della convergenza: Confrontando le diverse catene, possiamo valutare se si stabilizzano verso la stessa distribuzione. Se le catene si mescolano bene, ovvero si intersecano frequentemente nel grafico dei valori campionati (trace plot), è un forte indicatore di convergenza.\nRobustezza: L’utilizzo di multiple catene rende l’analisi meno sensibile alla scelta del punto di partenza. Se una singola catena potesse rimanere “intrappolata” in una regione dello spazio dei parametri, multiple catene aumentano la probabilità di esplorare lo spazio in modo più completo.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#diagnostiche-della-soluzione-mcmc",
    "href": "chapters/mcmc/01_metropolis.html#diagnostiche-della-soluzione-mcmc",
    "title": "50  L’algoritmo di Metropolis-Hastings",
    "section": "50.9 Diagnostiche della soluzione MCMC",
    "text": "50.9 Diagnostiche della soluzione MCMC\n\n50.9.1 Stazionarietà e Convergenza\nUn aspetto cruciale nell’analisi delle catene di Markov MCMC è la convergenza alla distribuzione stazionaria. Intuitivamente, la catena converge quando i campioni generati rappresentano fedelmente la distribuzione di interesse, indipendentemente dal punto di partenza. Questo fenomeno è spesso indicato come “mixing”.\n\n50.9.1.1 Valutazione Visuale: Trace Plots e Grafici di Densità\n\nTrace Plots: Questi grafici visualizzano l’evoluzione dei parametri nel tempo. Una catena convergente mostra tracce stabili e senza trend evidenti. Tracce irregolari o con andamenti sistematici suggeriscono problemi di convergenza.\nGrafici di Densità: Confrontando i grafici di densità dei campioni con la distribuzione teorica, è possibile valutare visivamente se la catena sta esplorando adeguatamente lo spazio dei parametri. Una buona convergenza si manifesta con una sovrapposizione significativa tra i due grafici.\n\nSegni di Convergenza:\n\nStabilità: I valori campionati oscillano attorno a un valore medio costante, senza trend marcati.\nOmogeneità: La variabilità dei campioni rimane relativamente uniforme nel tempo.\nAssenza di Periodicità: Non si osservano pattern ciclici o ripetitivi.\n\nIn sintesi, i trace plots e i grafici di densità offrono strumenti visivi rapidi per valutare la convergenza di una catena di Markov MCMC. Una convergenza soddisfacente è fondamentale per garantire la validità delle inferenze statistiche basate sui campioni generati.\n\n\n\n50.9.2 Autocorrelazione nelle catene di Markov MCMC\nA differenza dei generatori di numeri casuali indipendenti, gli algoritmi MCMC producono una sequenza di campioni correlati. Ogni valore campionato dipende da quello precedente, formando una catena di Markov. Questa interdipendenza è un aspetto fondamentale dell’MCMC.\nL’autocorrelazione quantifica il grado di dipendenza tra valori distanti di una certa quantità (detta lag) nella catena. Un’alta autocorrelazione a lag bassi indica una forte dipendenza tra campioni successivi. Al contrario, una rapida diminuzione dell’autocorrelazione al crescere del lag suggerisce che la catena “miscela” bene, ovvero esplora lo spazio dei parametri in modo efficiente.\n\nLag 1: Misura la correlazione tra valori consecutivi nella catena.\nLag 2: Misura la correlazione tra valori separati da un passo intermedio.\nLag k: Generalizza il concetto ai valori separati da k passi.\n\nUn correlogramma è un grafico che mostra l’autocorrelazione in funzione del lag. Un decadimento rapido dell’autocorrelazione verso zero indica una buona convergenza della catena.\nL’autocorrelazione di ordine \\(k\\) è data da \\(\\rho_k\\) e può essere stimata come:\n\\[\n\\begin{align}\n\\rho_k &= \\frac{Cov(\\theta_m, \\theta_{m+k})}{Var(\\theta_m)}\\notag\\\\\n&= \\frac{\\sum_{m=1}^{n-k}(\\theta_m - \\bar{\\theta})(\\theta_{m-k} - \\bar{\\theta})}{\\sum_{m=1}^{n-k}(\\theta_m - \\bar{\\theta})^2} \\qquad\\text{con }\\quad \\bar{\\theta} = \\frac{1}{n}\\sum_{m=1}^{n}\\theta_m.\n\\end{align}\n\\tag{50.1}\\]\n\n\n50.9.3 Esempio di Simulazione di Dati Autocorrelati\nPer fare un esempio pratico, creiamo un vettore di dati autocorrelati:\n\n# Creiamo un vettore di dati\nx &lt;- c(22, 24, 25, 25, 28, 29, 34, 37, 40, 44, 51, 48, 47, 50, 51)\nx\n#&gt;  [1] 22 24 25 25 28 29 34 37 40 44 51 48 47 50 51\n\n\n50.9.3.1 Calcolo dell’Autocorrelazione\nL’autocorrelazione di ordine 1 è la correlazione tra ciascun elemento e il successivo nella sequenza. In R possiamo utilizzare la funzione acf() per calcolare l’autocorrelazione.\n\n# Calcolo dell'autocorrelazione\nacf_values &lt;- acf(x, plot = FALSE)\nacf_values\n#&gt; \n#&gt; Autocorrelations of series 'x', by lag\n#&gt; \n#&gt;      0      1      2      3      4      5      6      7      8      9     10 \n#&gt;  1.000  0.832  0.656  0.491  0.279  0.031 -0.165 -0.304 -0.401 -0.458 -0.450 \n#&gt;     11 \n#&gt; -0.369\n\nNell’esempio, il vettore x rappresenta una serie temporale di 15 elementi. Il calcolo dell’autocorrelazione restituisce i seguenti valori per i primi ritardi (lag):\n\n0.8317: autocorrelazione di ordine 1 (lag = 1),\n0.6563: autocorrelazione di ordine 2 (lag = 2),\n0.4910: autocorrelazione di ordine 3 (lag = 3),\necc.\n\n\n\n50.9.3.2 Specifica del Numero di Ritardi (Lag)\nPossiamo limitare il numero di ritardi calcolati utilizzando l’argomento lag.max nella funzione acf():\n\n# Calcolo dell'autocorrelazione per i primi 4 lag\nacf(x, lag.max = 4, plot = FALSE)\n#&gt; \n#&gt; Autocorrelations of series 'x', by lag\n#&gt; \n#&gt;     0     1     2     3     4 \n#&gt; 1.000 0.832 0.656 0.491 0.279\n\n\n\n50.9.3.3 Grafico della Funzione di Autocorrelazione (Correlogramma)\nIn R possiamo creare un correlogramma con la funzione acf():\n\n# Correlogramma per la serie temporale\nacf(x, main = \"Correlogramma della Serie Temporale\", lag.max = 9)\n\n\n\n\n\n\n\n\n\n\n\n50.9.4 Analisi della Catena di Markov\nApplichiamo lo stesso approccio alla catena di Markov ottenuta precedentemente, considerando i campioni post burn-in:\n\n# Definizione dei campioni post burn-in\npost_burnin_samples &lt;- samples[-seq_len(burnin)]\n\n# Correlogramma per i campioni post burn-in\nacf(\n  post_burnin_samples, \n  main = \"Correlogramma della Catena Post Burn-in\", \n  lag.max = 9\n)\n\n\n\n\n\n\n\n\nIn situazioni ideali, l’autocorrelazione diminuisce rapidamente, diventando insignificante per piccoli lag. Questo comportamento è un’indicazione del “mixing” efficace della catena, ossia della sua convergenza alla distribuzione stazionaria.\n\n\n50.9.5 Sottocampionamento (Thinning)\nPer ridurre l’autocorrelazione, possiamo applicare una strategia di sottocampionamento (thinning), memorizzando solo ogni \\(m\\)-esimo campione.\n\n# Sottocampionamento con un fattore di 5\nthin &lt;- 5\nsampsthin &lt;- \n  post_burnin_samples[seq(1, length(post_burnin_samples), by = thin)]\n\n# Correlogramma per i campioni sottocampionati\nacf(\n  sampsthin, \n  main = \"Correlogramma con Sottocampionamento (Thinning)\", \n  lag.max = 9\n)\n\n\n\n\n\n\n\n\nIn conclusione, il correlogramma con thinning mostra che l’autocorrelazione diminuisce più rapidamente rispetto ai campioni originali, suggerendo che la strategia di sottocampionamento è efficace nel migliorare l’indipendenza tra i campioni successivi. Questo migliora la qualità delle inferenze basate sulla catena di Markov.\n\n50.9.5.1 Tasso di accettazione\nQuando si utilizza l’algoritmo Metropolis, è importante monitorare il tasso di accettazione e assicurarsi che sia nell’intervallo ottimale. Se si accetta quasi sempre il candidato proposto, probabilmente significa che, in ogni iterazione, la catena salta solo di un piccolo passo (in modo che il rapporto di accettazione sia vicino a 1 ogni volta). Di conseguenza, la catena impiegherà molte iterazioni per raggiungere altre regioni della distribuzione stazionaria e i campioni consecutivi saranno molto fortemente correlati. D’altra parte, se il tasso di accettazione è molto basso, la catena rimarrà bloccata nella stessa posizione per molte iterazioni prima di spostarsi verso uno stato diverso. Per l’algoritmo Metropolis base con un singolo parametro con una distribuzione proposta Gaussiana normale, un tasso di accettazione ottimale è compreso tra il 40% e il 50%.\n\n\n\n50.9.6 Test Statistici per la Convergenza\nOltre agli approcci grafici, esistono test statistici specifici che possono aiutare a determinare se la catena ha raggiunto uno stato stazionario.\n\n50.9.6.1 Test di Geweke\nIl test di Geweke è una procedura che confronta le medie di due segmenti della catena di campionamento, tipicamente il primo 10% e l’ultimo 50% dei campioni, dopo aver escluso un iniziale periodo di “burn-in” (una fase iniziale durante la quale la catena potrebbe non essere ancora convergente). La premessa di base è che, se la catena è in uno stato stazionario, le medie di questi due segmenti dovrebbero essere sostanzialmente uguali. Differenze significative tra queste medie possono indicare che la catena non ha ancora raggiunto la convergenza.\n\n\n50.9.6.2 Geweke Z-score\nUna variante del test di Geweke è lo z-score di Geweke, che offre un modo quantitativo per valutare le differenze tra i segmenti della catena. Questo test calcola uno z-score che confronta le medie dei due segmenti tenendo conto della varianza. Un valore di z-score:\n\nAl di sotto di 2 (in valore assoluto) suggerisce che non ci sono differenze significative tra i segmenti, indicando che la catena potrebbe essere in stato stazionario.\nSuperiore a 2 (in valore assoluto) indica che esiste una differenza significativa tra i segmenti, suggerendo che la catena non ha raggiunto la convergenza e potrebbe essere necessario un periodo di burn-in più esteso.\n\nEntrambi i metodi forniscono strumenti utili per valutare la convergenza delle catene MCMC. È importante notare che nessun test può garantire con certezza la convergenza, ma l’utilizzo congiunto di approcci grafici e test statistici può offrire una buona indicazione dello stato della catena.\n\n\n\n50.9.7 Dimensione del campione effettiva (ESS)\nLa correlazione tra campioni consecutivi in una catena MCMC riduce l’informazione effettiva contenuta in ogni iterazione. La dimensione del campione effettiva (ESS) quantifica questa perdita di informazione dovuta alla dipendenza tra i campioni, stimando il numero equivalente di campioni indipendenti. Un valore basso di ESS indica una forte correlazione tra i campioni e una convergenza più lenta della catena.\nL’ESS descrive l’efficacia del campionamento dipendente in termini di campioni indipendenti estratti dalla stessa distribuzione. Rappresenta un indicatore dell’efficienza del campionamento e dell’autocorrelazione della catena.\nLa formula per stimare la dimensione del campione effettiva (ESS) di una catena di Markov è:\n\\[\n\\text{ESS} = \\frac{N}{1 + 2 \\sum_{t=1}^{T} \\rho_t},\n\\]\ndove:\n\n\\(N\\) è il numero totale di campioni nella catena,\n\\(T\\) è il lag, ovvero il numero massimo di termini di autocorrelazione considerati,\n\\(\\rho_t\\) è l’autocorrelazione al lag \\(t\\), ossia la correlazione tra due campioni consecutivi separati da \\(t\\) iterazioni.\n\nIn pratica, \\(T\\) viene scelto in modo tale che \\(\\rho_T\\) sia sufficientemente piccolo, indicando che l’autocorrelazione è quasi svanita. La somma \\(\\sum_{t=1}^T \\rho_t\\) viene quindi troncata approssimativamente a \\(T\\), poiché i contributi delle autocorrelazioni successive diventano trascurabili.\n\n\n50.9.8 Calcolo della Statistica di Gelman-Rubin (\\(\\hat{R}\\))\nPer calcolare la statistica di Gelman-Rubin (spesso indicata come \\(\\hat{R}\\)), è necessario eseguire più catene e confrontare la variabilità all’interno di ciascuna catena con la variabilità tra le catene. Ecco i passaggi per calcolare \\(\\hat{R}\\):\n\nEsegui \\(m\\) catene di Markov di lunghezza \\(n\\), dove \\(m\\) è solitamente maggiore di 1.\nPer ciascun parametro scalare \\(\\theta\\), calcola la varianza all’interno delle catene (\\(W\\)) e la varianza tra le catene (\\(B\\)).\nCalcola la varianza combinata \\(\\hat{V}\\) come media ponderata delle varianze all’interno delle catene.\nCalcola il fattore di riduzione della scala potenziale \\(\\hat{R}\\) come la radice quadrata del rapporto tra la varianza combinata \\(\\hat{V}\\) e la varianza all’interno delle catene \\(W\\):\n\n\\[\n\\hat{R} = \\sqrt{\\frac{\\hat{V}}{W}}.\n\\]\n\nSe \\(\\hat{R}\\) è vicino a 1, ciò indica che le catene sono in convergenza.\n\nLa statistica di Gelman-Rubin \\(\\hat{R}\\) è una misura di convergenza per le catene di Markov. Essa quantifica il grado di accordo tra più catene, fornendo uno strumento diagnostico per valutare la convergenza nelle simulazioni MCMC.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#vantaggi-del-campionamento-mcmc-rispetto-alle-soluzioni-analitiche",
    "href": "chapters/mcmc/01_metropolis.html#vantaggi-del-campionamento-mcmc-rispetto-alle-soluzioni-analitiche",
    "title": "50  L’algoritmo di Metropolis-Hastings",
    "section": "50.10 Vantaggi del Campionamento MCMC rispetto alle Soluzioni Analitiche",
    "text": "50.10 Vantaggi del Campionamento MCMC rispetto alle Soluzioni Analitiche\nIl campionamento MCMC offre notevoli vantaggi pratici rispetto alle soluzioni analitiche nella statistica bayesiana, in particolare quando si tratta di manipolare distribuzioni a posteriori. Sebbene l’impossibilità di calcolare analiticamente la distribuzione a posteriori sia spesso la motivazione principale per l’uso di MCMC, i benefici di questo approccio si estendono ben oltre questa necessità (Bürkner, 2024).\n\n50.10.1 Facilità di Manipolazione e Flessibilità\nIl vantaggio chiave del campionamento MCMC risiede nella semplicità con cui si possono manipolare i campioni ottenuti. Mentre le densità calcolate analiticamente possono richiedere trasformazioni matematiche complesse, i campioni MCMC possono essere facilmente trasformati con operazioni dirette. Questa flessibilità si manifesta in diversi aspetti:\n\nTrasformazioni di Variabili: Consideriamo un caso in cui siamo interessati alla varianza residua (\\(\\sigma^2\\)) in un modello, ma abbiamo campioni solo della deviazione standard residua (\\(\\sigma\\)). Con il campionamento MCMC, la trasformazione è immediata:\n\n\\[\n(\\sigma^{(s)})^2 = \\sigma^{2(s)},\n\\]\ndove \\(s\\) indica il singolo campione. Questa operazione si traduce semplicemente nell’elevare al quadrato ogni campione di \\(\\sigma\\), ottenendo direttamente campioni validi di \\(\\sigma^2\\). In contrasto, con una densità analitica di \\(\\sigma\\), la trasformazione richiederebbe l’applicazione dell’aggiustamento del Jacobiano, un processo matematicamente più complesso.\n\nCombinazione di Parametri: Il MCMC semplifica notevolmente la combinazione di parametri in modelli statistici. Per una quantità \\(\\theta\\) che dipende da parametri \\(\\beta_1\\) e \\(\\beta_2\\) attraverso una funzione \\(f\\), possiamo calcolare:\n\n\\[\n\\theta^{(s)} = f(\\beta_1^{(s)}, \\beta_2^{(s)}).\n\\]\nQuesta operazione si estende facilmente a combinazioni complesse e funzioni non lineari, contrastando nettamente con la complessità di derivare analiticamente la distribuzione di \\(\\theta\\).\nIn conclusione, il campionamento MCMC non è solo una necessità quando le soluzioni analitiche sono introvabili, ma offre vantaggi in termini di facilità di manipolazione, flessibilità computazionale e applicabilità pratica.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#caso-normale-normale-con-soluzione-analitica",
    "href": "chapters/mcmc/01_metropolis.html#caso-normale-normale-con-soluzione-analitica",
    "title": "50  L’algoritmo di Metropolis-Hastings",
    "section": "50.11 Caso Normale-Normale con Soluzione Analitica",
    "text": "50.11 Caso Normale-Normale con Soluzione Analitica\nConsideriamo un caso normale-normale per cui possiamo derivare una soluzione analitica. Supponiamo che il prior sia distribuito secondo \\(\\mathcal{N}(30, 5^2)\\).\nDefiniamo le funzioni per il prior, la verosimiglianza e il posterior non normalizzato.\n\n# Prior: Normal(30, 5^2)\nprior &lt;- function(mu) {\n  dnorm(mu, mean = 30, sd = 5)\n}\n\n# Likelihood: Normal(mu, sigma^2) con sigma calcolata dai dati\nlikelihood &lt;- function(mu, data) {\n  sigma &lt;- sd(data)  # Deviazione standard dei dati\n  prod(dnorm(data, mean = mu, sd = sigma))\n}\n\n# Posterior non normalizzato\nposterior &lt;- function(mu, data) {\n  likelihood(mu, data) * prior(mu)\n}\n\nImplementiamo l’algoritmo di Metropolis per il caso normale-normale:\n\n# Algoritmo di Metropolis\nmetropolis_for_normal &lt;- function(nsamp, xinit, data) {\n  samples &lt;- numeric(nsamp)\n  x_prev &lt;- xinit\n  \n  for (i in seq_len(nsamp)) {\n    x_star &lt;- rnorm(1, mean = x_prev, sd = 0.5)  # Proposta\n    if (runif(1) &lt; min(1, posterior(x_star, data) / posterior(x_prev, data))) {\n      x_prev &lt;- x_star\n    }\n    samples[i] &lt;- x_prev\n  }\n  \n  samples\n}\n\nUtilizziamo un campione di 30 valori BDI-II forniti da Zetsche et al. (2019):\n\n# Dati osservati\ny &lt;- c(\n  26, 35, 30, 25, 44, 30, 33, 43, 22, 43, 24, 19, 39, 31, 25, \n  28, 35, 30, 26, 31, 41, 36, 26, 35, 33, 28, 27, 34, 27, 22\n)\n\nEsecuzione dell’algoritmo:\n\nsamples &lt;- metropolis_for_normal(100000, mean(y), y)\n\nNel caso normale-normale, il posterior può essere calcolato analiticamente come segue:\n\n# Parametri del prior\nmu_prior &lt;- 30\nstd_prior &lt;- 5\nvar_prior &lt;- std_prior^2\n\n# Calcolo dei parametri posterior\nn &lt;- length(y)\nsum_y &lt;- sum(y)\nvar_data &lt;- var(y)\n\nmu_post &lt;- (mu_prior / var_prior + sum_y / var_data) / (1 / var_prior + n / var_data)\nvar_post &lt;- 1 / (1 / var_prior + n / var_data)\nstd_post &lt;- sqrt(var_post)\n\nmu_post\n#&gt; [1] 30.882\nstd_post\n#&gt; [1] 1.172601\n\nVisualizziamo i risultati con un istogramma dei campioni MCMC e la curva della distribuzione analitica:\n\n# Campioni post burn-in\nburnin &lt;- floor(length(samples) * 0.5)\npost_samples &lt;- samples[-seq_len(burnin)]\n\n# Dati per la curva analitica\nx &lt;- seq(mu_post - 4 * std_post, mu_post + 4 * std_post, length.out = 1000)\nanalytical_posterior &lt;- dnorm(x, mean = mu_post, sd = std_post)\n\n# Creazione del grafico\nggplot() +\n  geom_histogram(aes(x = post_samples, y = ..density..), bins = 30, fill = \"blue\", alpha = 0.4) +\n  geom_line(aes(x = x, y = analytical_posterior), color = \"red\", size = 1) +\n  labs(title = \"Distribuzione Posterior: MCMC vs Analitico\",\n       x = expression(mu), y = \"Densità\") \n#&gt; Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `linewidth` instead.\n#&gt; Warning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `after_stat(density)` instead.\n\n\n\n\n\n\n\n\nTroviamo le proprietà del Posterior derivato con MCMC:\n\nmean(samples)\n#&gt; [1] 30.91375\n\n\nsd(samples)\n#&gt; [1] 1.176889\n\nIn conclusione, questo esempio mostra come applicare l’algoritmo di Metropolis per stimare una distribuzione a posteriori e come confrontare i risultati del sampling con la soluzione analitica, confermando la coerenza tra le due tecniche.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#riflessioni-conclusive",
    "href": "chapters/mcmc/01_metropolis.html#riflessioni-conclusive",
    "title": "50  L’algoritmo di Metropolis-Hastings",
    "section": "50.12 Riflessioni Conclusive",
    "text": "50.12 Riflessioni Conclusive\nIn molti casi, la distribuzione a posteriori dei parametri di un modello statistico non ha una forma analitica risolvibile. Per affrontare questa limitazione, si utilizzano metodi Monte Carlo basati su catene di Markov (MCMC). Questi algoritmi permettono di campionare efficacemente dalla distribuzione a posteriori, anche per modelli complessi, generando una sequenza di valori che approssima la distribuzione desiderata. L’algoritmo di Metropolis-Hastings (Hastings, 1970), un’estensione dell’algoritmo di Metropolis originale (Metropolis et al., 1953), è uno dei metodi MCMC più ampiamente utilizzati.\nIn sintesi, l’algoritmo segue questi passaggi principali:\n\nGenerazione del nuovo stato proposto: Si crea un nuovo stato vicino a quello corrente utilizzando una distribuzione di proposta.\nConfronto tra densità posteriori: Si confrontano le densità a posteriori del nuovo stato proposto e dello stato corrente.\nAccettazione probabilistica: Il nuovo stato viene sempre accettato se ha una densità posteriore maggiore, oppure accettato con una certa probabilità se ha una densità minore.\nBurn-in e tasso di accettazione: I primi campioni vengono scartati (fase di burn-in) per garantire che la catena abbia raggiunto la distribuzione stazionaria, e si monitora il tasso di accettazione per ottimizzare l’efficienza del campionamento.\n\nQuesto approccio consente di ottenere campioni che approssimano la distribuzione a posteriori, ma l’algoritmo di Metropolis può presentare limiti di efficienza, soprattutto per problemi ad alta dimensionalità o distribuzioni con geometrie complesse. Un aspetto cruciale è il tasso di accettazione, che rappresenta il rapporto tra il numero di proposte accettate e il numero totale di proposte. Un tasso troppo basso può indicare che la catena esplora lo spazio dei parametri in modo inefficiente, mentre un tasso troppo alto può segnalare che i passi effettuati sono troppo piccoli per consentire una buona esplorazione.\nRispetto alle varianti più moderne, l’algoritmo di Metropolis tende a essere meno efficiente. Metodi come il No-U-Turn Sampler (NUTS) e l’Hamiltonian Monte Carlo (HMC) offrono miglioramenti significativi, specialmente in spazi di parametri di grandi dimensioni. NUTS, ad esempio, viene utilizzato in strumenti avanzati come Stan e PyMC (Hoffman et al., 2014), permettendo un’esplorazione più rapida e accurata della distribuzione a posteriori.\nTra gli altri algoritmi MCMC degni di nota troviamo il campionatore di Gibbs (Geman & Geman, 1984) e l’Hamiltonian Monte Carlo (Duane et al., 1987). Questi metodi, insieme a Metropolis-Hastings, formano la base di numerose tecniche moderne per il campionamento da distribuzioni complesse. Per un approfondimento dettagliato sulle tecniche MCMC, si consiglia di consultare Hanada & Matsuura (2022).",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/01_metropolis.html#informazioni-sullambiente-di-sviluppo",
    "title": "50  L’algoritmo di Metropolis-Hastings",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] cmdstanr_0.8.1.9000 MASS_7.3-61         viridis_0.6.5      \n#&gt;  [4] viridisLite_0.4.2   ggpubr_0.6.0        ggExtra_0.10.1     \n#&gt;  [7] gridExtra_2.3       patchwork_1.3.0     bayesplot_1.11.1   \n#&gt; [10] psych_2.4.6.26      scales_1.3.0        markdown_1.13      \n#&gt; [13] knitr_1.49          lubridate_1.9.3     forcats_1.0.0      \n#&gt; [16] stringr_1.5.1       dplyr_1.1.4         purrr_1.0.2        \n#&gt; [19] readr_2.1.5         tidyr_1.3.1         tibble_3.2.1       \n#&gt; [22] ggplot2_3.5.1       tidyverse_2.0.0     rio_1.2.3          \n#&gt; [25] here_1.0.1         \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1     farver_2.1.2         R.utils_2.12.3      \n#&gt;  [4] fastmap_1.2.0        tensorA_0.36.2.1     pacman_0.5.1        \n#&gt;  [7] promises_1.3.2       digest_0.6.37        timechange_0.3.0    \n#&gt; [10] mime_0.12            lifecycle_1.0.4      processx_3.8.4      \n#&gt; [13] magrittr_2.0.3       posterior_1.6.0      compiler_4.4.2      \n#&gt; [16] rlang_1.1.4          tools_4.4.2          utf8_1.2.4          \n#&gt; [19] data.table_1.16.2    ggsignif_0.6.4       labeling_0.4.3      \n#&gt; [22] htmlwidgets_1.6.4    mnormt_2.1.1         abind_1.4-8         \n#&gt; [25] miniUI_0.1.1.1       withr_3.0.2          R.oo_1.27.0         \n#&gt; [28] grid_4.4.2           fansi_1.0.6          xtable_1.8-4        \n#&gt; [31] colorspace_2.1-1     cli_3.6.3            rmarkdown_2.29      \n#&gt; [34] generics_0.1.3       tzdb_0.4.0           parallel_4.4.2      \n#&gt; [37] vctrs_0.6.5          jsonlite_1.8.9       carData_3.0-5       \n#&gt; [40] car_3.1-3            hms_1.1.3            rstatix_0.7.2       \n#&gt; [43] Formula_1.2-5        glue_1.8.0           ps_1.8.1            \n#&gt; [46] distributional_0.5.0 stringi_1.8.4        gtable_0.3.6        \n#&gt; [49] later_1.4.1          munsell_0.5.1        pillar_1.9.0        \n#&gt; [52] htmltools_0.5.8.1    R6_2.5.1             rprojroot_2.0.4     \n#&gt; [55] evaluate_1.0.1       shiny_1.9.1          lattice_0.22-6      \n#&gt; [58] R.methodsS3_1.8.2    backports_1.5.0      broom_1.0.7         \n#&gt; [61] httpuv_1.6.15        Rcpp_1.0.13-1        nlme_3.1-166        \n#&gt; [64] checkmate_2.3.2      xfun_0.49            pkgconfig_2.0.3",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#bibliografia",
    "href": "chapters/mcmc/01_metropolis.html#bibliografia",
    "title": "50  L’algoritmo di Metropolis-Hastings",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBürkner, P.-C. (2024). The brms Book: Applied Bayesian Regression Modelling Using R and Stan (Early Draft). https://paulbuerkner.com/software/brms-book\n\n\nDuane, S., Kennedy, A. D., Pendleton, B. J., & Roweth, D. (1987). Hybrid monte carlo. Physics letters B, 195(2), 216–222.\n\n\nGeman, S., & Geman, D. (1984). Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images. IEEE Transactions on pattern analysis and machine intelligence, 6, 721–741.\n\n\nHanada, M., & Matsuura, S. (2022). MCMC from Scratch. Springer.\n\n\nHastings, W. K. (1970). Monte Carlo sampling methods using Markov chains and their applications. Biometrika, 57(1), 97–109.\n\n\nHoffman, M. D., Gelman, A., et al. (2014). The No-U-Turn sampler: adaptively setting path lengths in Hamiltonian Monte Carlo. Journal of Machine Learning Research, 15(1), 1593–1623.\n\n\nMetropolis, N., Rosenbluth, A. W., Rosenbluth, M. N., Teller, A. H., & Teller, E. (1953). Equation of state calculations by fast computing machines. The Journal of Chemical Physics, 21(6), 1087–1092.\n\n\nZetsche, U., Buerkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: biased or realistic? Journal of Abnormal Psychology, 128(7), 678–688.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>L'algoritmo di Metropolis-Hastings</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html",
    "href": "chapters/mcmc/02_ppl.html",
    "title": "51  Linguaggi di programmazione probabilistici",
    "section": "",
    "text": "51.1 Cos’è la programmazione probabilistica\nPrerequisiti\nConcetti e competenze chiave\nLa programmazione probabilistica è un paradigma della programmazione informatica che consente di creare modelli e algoritmi capaci di gestire l’incertezza e la casualità. Combina i principi della teoria delle probabilità con la programmazione, permettendo di costruire sistemi in grado di ragionare su dati incerti e di prendere decisioni informate. Questo approccio consente di esprimere modelli complessi in modo naturale e intuitivo, facilitando il processo di inferenza bayesiana.\nLa programmazione probabilistica si colloca all’intersezione tra algoritmi di machine learning, statistica e linguaggi di programmazione. I suoi obiettivi principali sono semplificare il processo di inferenza e automatizzarlo.\nLa gerarchia logica generale della programmazione probabilistica può essere vista così:\nInferenza → Sistema di programmazione probabilistica → Linguaggio di programmazione probabilistica → Modelli → Applicazioni",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html#perché-abbiamo-bisogno-della-programmazione-probabilistica",
    "href": "chapters/mcmc/02_ppl.html#perché-abbiamo-bisogno-della-programmazione-probabilistica",
    "title": "51  Linguaggi di programmazione probabilistici",
    "section": "51.2 Perché abbiamo bisogno della programmazione probabilistica?",
    "text": "51.2 Perché abbiamo bisogno della programmazione probabilistica?\nScrivere un proprio campionatore per l’inferenza bayesiana è un compito estremamente difficile. Richiede competenze matematiche avanzate e una profonda conoscenza degli algoritmi di campionamento (sia MCMC che approssimati). Inoltre, ci sono numerosi problemi potenziali legati alla stabilità numerica e ai costi computazionali. Questo significa che per riuscirci bisogna essere allo stesso tempo degli ottimi sviluppatori e degli esperti statistici.\nÈ però possibile delegare tutti questi compiti a un sistema che li automatizzi, permettendoci di concentrarci sulla risoluzione dei problemi scientifici.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html#linguaggi-di-programmazione-probabilistica-ppls",
    "href": "chapters/mcmc/02_ppl.html#linguaggi-di-programmazione-probabilistica-ppls",
    "title": "51  Linguaggi di programmazione probabilistici",
    "section": "51.3 Linguaggi di programmazione probabilistica (PPLs)",
    "text": "51.3 Linguaggi di programmazione probabilistica (PPLs)\nIn questa sezione esamineremo il panorama moderno dei linguaggi di programmazione probabilistica (PPLs) e, nella sezione successiva, esploreremo le funzionalità di uno di questi, Stan.\nUn PPL ci consente di formalizzare un modello bayesiano e di eseguire l’inferenza grazie a potenti algoritmi. L’utente deve solo definire il modello, scegliere un campionatore (se necessario) e “premere il pulsante dell’inferenza”.\nIn generale, ciò che si richiede da un linguaggio di programmazione probabilistica è la capacità di: - estrarre valori casuali da distribuzioni; - condizionare i valori delle variabili su osservazioni (dati).\nAlcuni dei primi linguaggi e strumenti di programmazione probabilistica, come BUGS e WinBUGS, hanno aperto la strada, offrendo tre capacità chiave:\n\nrandom: per creare variabili casuali,\nconstraint: per vincolare variabili ai dati osservati,\ninfer: per restituire la distribuzione di una variabile.\n\nL’elenco dei linguaggi di programmazione probabilistica attualmente esistenti è molto lungo e in continua crescita. Ecco alcuni esempi:\n\nBUGS, WinBUGS, JAGS,\nStan,\nPyMC3, PyMC4, PyMC,\nNimble,\nPyro, NumPyro,\nEdward, TensorFlow Probability, Edward 2,\nGen,\nTuring,\nStheno,\nSOSS,\nOmega,\nInfer.NET.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html#come-scegliere-un-ppl",
    "href": "chapters/mcmc/02_ppl.html#come-scegliere-un-ppl",
    "title": "51  Linguaggi di programmazione probabilistici",
    "section": "51.4 Come scegliere un PPL?",
    "text": "51.4 Come scegliere un PPL?\nDal punto di vista pratico, come si può decidere quale linguaggio di programmazione probabilistica scegliere? Ecco alcuni fattori chiave da considerare:\n\nFunzionalità: valuta il linguaggio in base alla disponibilità di un ampio range di distribuzioni probabilistiche e campionatori.\nPersonalizzazione: verifica se il PPL permette di definire distribuzioni e campionatori personalizzati.\nPerformance: alcuni PPL offrono ottimizzazioni o capacità di elaborazione parallela per migliorare le prestazioni.\nDocumentazione: la disponibilità di risorse ben documentate, come guide, tutorial e documentazione ufficiale, può avere un grande impatto sulla tua curva di apprendimento e produttività.\nSupporto della comunità: una comunità attiva e di supporto può essere una risorsa preziosa quando incontri difficoltà o hai domande. Forum, gruppi di discussione e contenuti condivisi dagli utenti possono offrire soluzioni e suggerimenti.\nIntegrazione: valuta se il PPL si integra facilmente con altri strumenti e framework che potresti utilizzare nel tuo progetto. La compatibilità con librerie per la manipolazione dei dati, la visualizzazione o il machine learning può semplificare il flusso di lavoro.\n\nQuesti criteri ci aiutano a scegliere il PPL più adatto alle nostre esigenze.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_language.html",
    "href": "chapters/mcmc/03_stan_language.html",
    "title": "52  Linguaggio Stan",
    "section": "",
    "text": "52.1 Introduzione\nStan è un linguaggio di programmazione probabilistica (PPL) progettato per l’inferenza bayesiana su modelli complessi. Tra le sue caratteristiche principali, Stan implementa un algoritmo avanzato chiamato No-U-Turn Sampler (NUTS), che ottimizza il metodo Hamiltonian Monte Carlo (HMC). Questa tecnica rappresenta un’evoluzione rispetto all’algoritmo di Metropolis (Capitolo 50), tradizionalmente utilizzato per generare campioni da distribuzioni a posteriori. Sebbene entrambi gli approcci producano lo stesso risultato finale, NUTS riduce drasticamente il numero di iterazioni necessarie per raggiungere la convergenza, soprattutto nei modelli ad alta dimensionalità.\nDal punto di vista concettuale, NUTS e Metropolis mirano a costruire una catena di Markov che converga alla distribuzione a posteriori target. Tuttavia, NUTS lo fa in modo molto più efficiente, rendendolo la scelta preferita quando si analizzano modelli complessi. Stan combina questa efficienza con un’interfaccia flessibile, compatibile con diverse piattaforme come R, Python e Julia. In questo corso, useremo cmdstanr, l’interfaccia R per Stan. Oltre a cmdstanr, esistono altre interfacce come CmdStanPy per Python e Stan.jl per Julia, che facilitano l’integrazione di Stan nei flussi di lavoro di programmazione.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_language.html#stan-e-la-programmazione-probabilistica",
    "href": "chapters/mcmc/03_stan_language.html#stan-e-la-programmazione-probabilistica",
    "title": "52  Linguaggio Stan",
    "section": "52.2 Stan e la Programmazione Probabilistica",
    "text": "52.2 Stan e la Programmazione Probabilistica\nLa programmazione probabilistica unisce principi di statistica bayesiana e linguaggi di programmazione, semplificando lo sviluppo di modelli complessi. In un linguaggio PPL come Stan, l’utente deve solo specificare le distribuzioni a priori e la funzione di verosimiglianza. L’inferenza viene poi gestita automaticamente dal linguaggio, che utilizza metodi avanzati di campionamento come NUTS per produrre campioni dalla distribuzione a posteriori.\nUn programma Stan è strutturato in blocchi. Ogni blocco ha una funzione specifica, come dichiarare i dati (data), definire i parametri (parameters), specificare la densità del modello (model) e generare quantità derivate (generated quantities). Questa struttura modulare rende Stan intuitivo e adattabile a un’ampia gamma di applicazioni.\nLe variabili in Stan devono essere dichiarate con tipi specifici (int per interi, real per numeri reali, vector per vettori, ecc.) e possono avere vincoli, come lower=0 o upper=1, per garantire che i loro valori rispettino determinati limiti. Questo approccio, noto come tipizzazione statica, rende i programmi Stan robusti e meno soggetti a errori.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_language.html#esecuzione-di-stan-con-cmdstanr",
    "href": "chapters/mcmc/03_stan_language.html#esecuzione-di-stan-con-cmdstanr",
    "title": "52  Linguaggio Stan",
    "section": "52.3 Esecuzione di Stan con CmdStanR",
    "text": "52.3 Esecuzione di Stan con CmdStanR\nPer eseguire un modello Stan, utilizzeremo qui l’interfaccia cmdstanr, che integra CmdStan in R. L’esempio seguente illustra come generare dati simulati da una distribuzione binomiale e analizzare un problema inverso, stimando il parametro di successo \\(\\theta\\).\n\n52.3.1 Simulazione in Avanti\nLa simulazione in avanti consiste nel generare dati simulati da un modello probabilistico noto. Supponiamo di voler simulare i risultati di uno studio con \\(N = 100\\) prove e una probabilità di successo \\(\\theta = 0.3\\). Il codice Stan per questa simulazione è il seguente:\ndata {\n  int&lt;lower=0&gt; N;                   // Numero di prove\n  real&lt;lower=0, upper=1&gt; theta;     // Probabilità di successo\n}\ngenerated quantities {\n  int&lt;lower=0, upper=N&gt; y;          // Numero di successi\n  y = binomial_rng(N, theta);\n}\nPer eseguire il modello in R con cmdstanr dobbiamo compilare il modello:\n\nmodel1 &lt;- cmdstan_model(here(\"stan\", \"binomial-rng.stan\"))\n\nDefinire i dati:\n\ndata_list &lt;- list(N = 100, theta = 0.3)\n\nEseguire il campionamento:\n\nfit1 &lt;- model1$sample(\n  data = data_list, \n  fixed_param = TRUE, \n  seed = 123,\n  show_messages = FALSE )\n\nEstrazione dei risultati:\n\ny_samples &lt;- fit1$draws(variables = \"y\", format = \"matrix\")[, 1]\ny_samples\n#&gt; # A draws_matrix: 1000 iterations, 4 chains, and 1 variables\n#&gt;     variable\n#&gt; draw  y\n#&gt;   1  28\n#&gt;   2  34\n#&gt;   3  31\n#&gt;   4  29\n#&gt;   5  26\n#&gt;   6  25\n#&gt;   7  31\n#&gt;   8  28\n#&gt;   9  30\n#&gt;   10 36\n#&gt; # ... with 3990 more draws\n\nLa simulazione in avanti ci permette di generare dati simulati per esplorare il comportamento del modello sotto specifiche ipotesi sui parametri.\n\n\n52.3.2 Problema Inverso\nNel problema inverso, l’obiettivo è stimare i parametri di un modello a partire dai dati osservati.\nSupponiamo di analizzare la proporzione di artisti della Generazione X presenti al MoMA, dove 14 artisti su 100 appartengono a questa generazione. Utilizzeremo una distribuzione Beta(4, 6) come prior per il parametro \\(\\theta\\), la probabilità che un artista appartenga alla Generazione X. Il modello Stan corrispondente è il seguente:\ndata {\n  int&lt;lower=0&gt; N;                // Numero di osservazioni\n  int&lt;lower=0, upper=N&gt; y;       // Numero di successi\n  real&lt;lower=0&gt; alpha_prior;     // Parametro alpha del prior Beta\n  real&lt;lower=0&gt; beta_prior;      // Parametro beta del prior Beta\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; theta;  // Probabilità di successo\n}\nmodel {\n  theta ~ beta(alpha_prior, beta_prior);  // Prior\n  y ~ binomial(N, theta);                 // Verosimiglianza\n}\nSupponiamo di osservare 14 successi su 100 prove e vogliamo stimare la probabilità di successo \\(\\theta\\). In questo esempio, imponiamo su \\(\\theta\\) un prior debolmente informativo, Beta(2, 2).\nPer eseguire il modello e stimare \\(\\theta\\) dobbiamo specificare i dati in un formato appropriato per Stan:\n\nstan_data &lt;- list(\n  N = 100, \n  y = 14, \n  alpha_prior = 2, \n  beta_prior = 2\n)\n\nCompiliamo il modello:\n\nmodel2 &lt;- cmdstan_model(here(\"stan\", \"moma_model.stan\"))\n\nEseguiamo il campionamento:\n\nfit2 &lt;- model2$sample(\n  data = stan_data, \n  iter_warmup = 2000, \n  iter_sampling = 2000, \n  seed = 42,\n  show_messages = FALSE \n)\n\nIl metodo sample() esegue il modello Stan utilizzando un algoritmo a campionamento iterativo (di solito Hamiltonian Monte Carlo). Durante il burn-in (prime iterazioni), i campioni potrebbero non rappresentare accuratamente la distribuzione a posteriori. Questi campioni iniziali vengono scartati e solo quelli successivi sono utilizzati per costruire stime dalla distribuzione a posteriori.\nRecuperiamo i campioni di theta dall’oggetto fit2:\n\ntheta2_samples &lt;- fit2$draws(variables = \"theta\", format = \"array\")\ndim(theta2_samples)\n#&gt; [1] 2000    4    1\n\nQuesto indica la struttura dell’array estratto dal modello Stan. Significa che il campionamento ha prodotto 2000 iterazioni per ciascuna delle 4 catene. L’ultimo valore (1) rappresenta il numero di variabili monitorate nel modello (in questo caso, una sola variabile). Quindi, il formato dell’array è (iterazioni, catene, variabili).\n\ntheta2_samples |&gt; \n  glimpse()\n#&gt;  'draws_array' num [1:2000, 1:4, 1] 0.132 0.144 0.134 0.143 0.116 ...\n#&gt;  - attr(*, \"dimnames\")=List of 3\n#&gt;   ..$ iteration: chr [1:2000] \"1\" \"2\" \"3\" \"4\" ...\n#&gt;   ..$ chain    : chr [1:4] \"1\" \"2\" \"3\" \"4\"\n#&gt;   ..$ variable : chr \"theta\"\n\nPer maneggiare più facilmente i campioni a posteriori possiamo convertire l’oggetto theta2_samples in un vettore:\n\ntheta2_vector &lt;- as.vector(theta2_samples)\nlength(theta2_vector)\n#&gt; [1] 8000\n\n\ntheta2_vector |&gt; \n  head()\n#&gt; [1] 0.132 0.144 0.134 0.143 0.116 0.211\n\nPer analizzare i campioni generati, possiamo utilizzare istogrammi e tracce MCMC.. Creiamo un istogramma della distribuzione a posteriori di \\(\\theta\\):\n\nggplot(data.frame(theta = theta2_vector), aes(x = theta)) +\n  geom_histogram(bins = 30, fill = \"blue\", color = \"black\", alpha = 0.5) +\n  labs(\n    title = \"Distribuzione a Posteriori di Theta\",\n    x = \"Theta\",\n    y = \"Frequenza\"\n  )\n\n\n\n\n\n\n\n\nLo stesso risultato può essere ottenuto con le funzioni di bayesplot che prende come argomento l’oggetto fit2, senza bisogno di altre trasformazioni:\n\nmcmc_hist(fit2$draws(\"theta\"))\n#&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nQuesto grafico ci permette di visualizzare la distribuzione a posteriori, valutando sia la modalità (valore più probabile) che l’incertezza (larghezza della distribuzione):\n\nse l’istogramma mostra una distribuzione stretta attorno a un valore, significa che c’è poca incertezza nella stima di \\(\\theta\\).\nuna distribuzione ampia indica maggiore incertezza, suggerendo che i dati osservati non forniscono una stima precisa di \\(\\theta\\).\n\nSi noti come la stima putuale a posteriori e l’intervallo di credibilità riproducono i valori ottenuti utilizzando l’algoritmo di Metropolis (Capitolo 50).\nIn alternativa, è possibile visualizzare la distribuzione a posteriori di theta utilizzando stime della densità kernel al posto degli istogrammi, distinguendo i risultati per ciascuna catena:\n\nbayesplot::mcmc_dens_overlay(fit2$draws(\"theta\"))\n\n\n\n\n\n\n\n\nUsando la funzione mcmc_trace() possiamo ottenere un trace plot di theta:\n\n bayesplot::mcmc_trace(fit2$draws(\"theta\"), n_warmup=2000)\n\n\n\n\n\n\n\n\n\nbayesplot::mcmc_intervals(fit2$draws(\"theta\"), prob_outer = 0.94)",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_language.html#diagnostiche-di-campionamento",
    "href": "chapters/mcmc/03_stan_language.html#diagnostiche-di-campionamento",
    "title": "52  Linguaggio Stan",
    "section": "52.4 Diagnostiche di Campionamento",
    "text": "52.4 Diagnostiche di Campionamento\nPer valutare la qualità del campionamento, possiamo utilizzare la statistica \\(\\widehat{R}\\).\n\nrhats &lt;- rhat(fit2$draws(\"theta\"))\nprint(rhats)\n#&gt; [1] 1\n\n\nbayesplot::mcmc_rhat(rhats)\n\n\n\n\n\n\n\n\nUn valore di \\(\\widehat{R}\\) vicino a 1 indica che le catene sono convergenti.\nÈ anche possibile considerare il numero effettivo di campioni (\\(N_{\\text{eff}}\\)): un \\(N_{\\text{eff}}\\) elevato suggerisce una stima precisa dei parametri.\n\nfit2$summary()\n#&gt; # A tibble: 2 × 10\n#&gt;   variable    mean  median     sd    mad       q5     q95  rhat ess_bulk\n#&gt;   &lt;chr&gt;      &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 lp__     -45.2   -44.9   0.731  0.324  -46.6    -44.7    1.00    3699.\n#&gt; 2 theta      0.153   0.152 0.0354 0.0353   0.0991   0.215  1.00    2553.\n#&gt; # ℹ 1 more variable: ess_tail &lt;dbl&gt;\n\nLe colonne dell’output di summary() rappresentano:\n\nmean e median: Media e mediana della distribuzione a posteriori. Per theta, la media è 0.153 e la mediana è simile (0.152), suggerendo una distribuzione abbastanza simmetrica.\nsd: Deviazione standard della distribuzione (0.0354 per theta).\nmad: Deviazione assoluta mediana, una misura di dispersione robusta (simile alla deviazione standard in questo caso).\nq5 e q95: Quantili al 5% e al 95%, che definiscono un intervallo di credibilità al 90% per theta (\\([0.0991, 0.215]\\)).\nrhat: Statistica di convergenza. Un valore di 1 indica che le catene sono ben miscelate e hanno raggiunto la convergenza.\ness_bulk: Dimensione campionaria effettiva, che misura il numero di campioni indipendenti. È alta per entrambe le variabili (3699 per lp__ e 2553 per theta), segnalando un’efficienza del campionamento.\n\n\n52.4.1 Dimensione del Campione Effettivo ed Errore Monte Carlo\nQuando si utilizzano metodi basati su catene di Markov (MCMC), i campioni successivi possono essere correlati. La dimensione del campione effettivo (\\(N_{\\text{eff}}\\)) misura il numero di campioni indipendenti equivalenti e viene calcolata come:\n\\[\nN_{\\text{eff}} = \\frac{M}{\\text{IAT}},\n\\]\ndove \\(\\text{IAT}\\) è il tempo di autocorrelazione integrata. Un \\(N_{\\text{eff}}\\) elevato indica che il campionamento è efficace, riducendo l’errore Monte Carlo. Stan riporta anche l’errore standard MCMC per ogni parametro, dato da:\n\\[\n\\text{mcmc-se} = \\frac{\\text{sd}[\\Theta \\mid Y = y]}{\\sqrt{N_{\\text{eff}}}}.\n\\]\nQuesto valore riflette la precisione delle stime ottenute.\n\n\n52.4.2 Divergenze, max_treedepth e Efficienza\nLa qualità del campionamento viene ulteriormente verificata mediante la funzione diagnostic_summary():\n\nfit2$diagnostic_summary()\n#&gt; $num_divergent\n#&gt; [1] 0 0 0 0\n#&gt; \n#&gt; $num_max_treedepth\n#&gt; [1] 0 0 0 0\n#&gt; \n#&gt; $ebfmi\n#&gt; [1] 1.18 1.03 1.13 1.14\n\n\nnum_divergent: Mostra il numero di transizioni divergenti per ciascuna catena. Valori pari a 0 indicano che non ci sono stati problemi di campionamento (assenza di transizioni divergenti).\nnum_max_treedepth: Indica il numero di transizioni che hanno raggiunto la profondità massima dell’albero in NUTS. Valori pari a 0 segnalano che il modello è stato esplorato correttamente senza limitazioni imposte dalla profondità dell’albero.\nebfmi: Efficienza dell’Hamiltonian Monte Carlo calcolata tramite il Energy Bayesian Fraction of Missing Information (EBFMI). Tutti i valori sono superiori a 1, indicando un campionamento efficace e nessun problema con l’esplorazione dello spazio dei parametri.\n\nNel caso presente, i risultati ottenuti mostrano che il campionamento è stato efficace:\n\nLe catene hanno convergenza (\\(\\hat{R} = 1\\)).\nNon ci sono stati problemi tecnici come transizioni divergenti o massima profondità raggiunta.\nLe diagnostiche di efficienza (\\(N_{\\text{eff}}\\), EBFMI) confermano un campionamento affidabile.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_language.html#verifica-dei-priors",
    "href": "chapters/mcmc/03_stan_language.html#verifica-dei-priors",
    "title": "52  Linguaggio Stan",
    "section": "52.5 Verifica dei Priors",
    "text": "52.5 Verifica dei Priors\nPossiamo verificare se i nostri priors sono adeguati calcolando la probabilità a priori dei parametri di interesse. Ad esempio, nel nostro campione, sappiamo che la proporzione di artisti appartenenti alla Generazione X è 0.14. È importante che i priors consentano configurazioni ragionevoli dei dati ma escludano scenari chiaramente assurdi, basandosi sulla nostra esperienza del dominio. Per verificare se i nostri priors soddisfano questo requisito, possiamo effettuare un prior predictive check.\nPer condurre un prior predictive check, utilizziamo lo stesso modello usato in precedenza, inseriamo i parametri di interesse nel blocco generated_quantities e rimuoviamo il termine relativo alla distribuzione di campionamento (ossia la verosimiglianza) dal modello. Senza la verosimiglianza, i parametri non vengono adattati ai dati e vengono quindi campionati dalla loro distribuzione a priori. Il codice Stan rimane identico a quello finale, ma senza la riga y ~ binomial(N, theta);. Un trucco utile per semplificare i prior predictive check è aggiungere uno switch compute_likelihood ai dati, come mostrato di seguito:\nif (compute_likelihood == 1)\n  y ~ binomial(N, theta);\nCompilazione del modello:\n\nmodel3 &lt;- cmdstan_model(here(\"stan\", \"moma_model_prior.stan\"))\n\n\nmodel3$print()\n#&gt; data {\n#&gt;   int&lt;lower=0&gt; N;\n#&gt;   int&lt;lower=0, upper=N&gt; y;\n#&gt;   int&lt;lower=0&gt; alpha_prior;\n#&gt;   int&lt;lower=0&gt; beta_prior;\n#&gt;   int&lt;lower=0, upper=1&gt; compute_likelihood; // Flag to control likelihood inclusion\n#&gt; }\n#&gt; parameters {\n#&gt;   real&lt;lower=0, upper=1&gt; theta;\n#&gt; }\n#&gt; model {\n#&gt;   theta ~ beta(alpha_prior, beta_prior); // Prior for theta\n#&gt;   \n#&gt;   if (compute_likelihood == 1) {\n#&gt;     y ~ binomial(N, theta); // Likelihood is only included if compute_likelihood == 1\n#&gt;   }\n#&gt; }\n#&gt; generated quantities {\n#&gt;   int&lt;lower=0, upper=N&gt; y_rep;\n#&gt;   int&lt;lower=0, upper=1&gt; theta_gt_025 = theta &gt; 0.25; // Indicator if theta &gt; 0.25\n#&gt;   y_rep = binomial_rng(N, theta); // Simulated data for posterior predictive check\n#&gt; }\n\nQuesto ci consente di utilizzare lo stesso file Stan per eseguire sia i prior predictive check che l’inferenza, semplicemente modificando il valore di compute_likelihood.\nDefiniamo il dizionario dei dati:\n\nstan_data3 &lt;- list(\n  N = 9, # Number of trials\n  y = 0, # Placeholder, not used during prior predictive checks\n  alpha_prior = 2,\n  beta_prior = 2,\n  compute_likelihood = 0 \n  # Set to 0 to disable likelihood for prior predictive check\n)\n\nEseguiamo il campionamento utilizzando solo la distribuzione a priori:\n\n# Campionamento dalla distribuzione a priori (compute_likelihood settato a 0)\nfit3 = model3$sample(\n  data=stan_data3,\n  chains=4,\n  iter_warmup=500,\n  iter_sampling=1000,\n  seed=123,\n  show_message=FALSE\n)\n\nEstraiamo i campioni a priori per il parametro \\(\\theta\\):\n\ntheta3_samples &lt;- as.vector(\n  fit3$draws(variables = \"theta\", format = \"array\")\n)\n\nInfine, creiamo un istogramma per visualizzare la distribuzione a priori di \\(\\theta\\):\n\n# Conversione dei campioni in un vettore per ggplot2\ntheta3_vector &lt;- as.vector(theta3_samples)\n\n# Creazione dell'istogramma\nggplot(data.frame(theta = theta3_vector), aes(x = theta)) +\n  geom_histogram(bins = 30, alpha = 0.5) +\n  labs(\n    title = \"Istogramma della distribuzione a priori di theta\",\n    x = \"Valori di theta\",\n    y = \"Frequenza\"\n  )\n\n\n\n\n\n\n\n\nIn conclusione, osserviamo che la distribuzione a priori per \\(\\theta\\) include la proporzione campionaria, ma la maggior parte della massa di probabilità si concentra su valori più elevati. Questo suggerisce che la scelta della distribuzione Beta come prior potrebbe non essere completamente ottimale per rappresentare il parametro in questione. Sarà necessario valutare se un prior diverso potrebbe migliorare l’inferenza, garantendo una rappresentazione più accurata delle conoscenze a priori e dei dati osservati.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_language.html#stime-puntuali-bayesiane",
    "href": "chapters/mcmc/03_stan_language.html#stime-puntuali-bayesiane",
    "title": "52  Linguaggio Stan",
    "section": "52.6 Stime Puntuali Bayesiane",
    "text": "52.6 Stime Puntuali Bayesiane\nIn un contesto bayesiano, una stima puntuale di un parametro \\(\\Theta\\), condizionata sui dati osservati \\(Y = y\\), è un valore singolo \\(\\hat{\\theta} \\in \\mathbb{R}^D\\) che sintetizza la distribuzione a posteriori \\(p(\\theta \\mid y)\\). La stima puntuale non cattura tutta l’incertezza, ma rappresenta un riassunto della distribuzione a posteriori. Nella statistica, la notazione \\(\\hat{\\theta}\\) è convenzionale per indicare una stima di \\(\\theta\\). Esistono diverse modalità di stima puntuale, ognuna delle quali minimizza una specifica funzione di perdita. Di seguito, esaminiamo la media posteriori, la mediana posteriori e la moda posteriori, discutendo anche le loro proprietà e il loro uso pratico.\n\n52.6.1 Stimatore della Media Posteriori\nLo stimatore della media posteriori è uno dei più comuni in ambito bayesiano. La media posteriori è definita come:\n\\[\n\\widehat{\\theta} = \\mathbb{E}[\\Theta \\mid Y = y] = \\int_{\\Theta} \\theta \\cdot p(\\theta \\mid y) \\, \\mathrm{d}\\theta.\n\\]\nIn pratica, la media è calcolata come la media campionaria dei campioni \\(\\theta^{(m)}\\) estratti dalla distribuzione a posteriori, ovvero:\n\\[\n\\widehat{\\theta} \\approx \\frac{1}{M} \\sum_{m=1}^M \\theta^{(m)},\n\\]\ndove \\(\\theta^{(m)} \\sim p(\\theta \\mid y)\\). Questo metodo sfrutta l’aspettativa condizionale, un concetto chiave dell’inferenza bayesiana. In R, la media posteriori può essere calcolata con:\n\ntheta_hat &lt;- mean(theta2_vector)\ntheta_hat\n#&gt; [1] 0.153\n\nOppure possiamo usare la funzione summary() applicata all’oggetto fit2:\n\nfit2$summary()\n#&gt; # A tibble: 2 × 10\n#&gt;   variable    mean  median     sd    mad       q5     q95  rhat ess_bulk\n#&gt;   &lt;chr&gt;      &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 lp__     -45.2   -44.9   0.731  0.324  -46.6    -44.7    1.00    3699.\n#&gt; 2 theta      0.153   0.152 0.0354 0.0353   0.0991   0.215  1.00    2553.\n#&gt; # ℹ 1 more variable: ess_tail &lt;dbl&gt;\n\n\n\n52.6.2 Stimatore della Mediana Posteriori\nUn’altra stima puntuale è la mediana posteriori, \\(\\theta^+\\). Essa è definita come il valore che divide la distribuzione a posteriori in due parti uguali, cioè:\n\\[\n\\Pr[\\Theta \\leq \\theta^+] = \\frac{1}{2}.\n\\]\nLa mediana posteriori è calcolata ordinando i campioni e identificando il punto centrale. In R, può essere calcolata con:\n\ntheta_plus &lt;- median(theta2_vector)\ntheta_plus\n#&gt; [1] 0.152\n\nSe la distribuzione a posteriori è simmetrica, media e mediana coincideranno o saranno molto simili. Tuttavia, per distribuzioni asimmetriche, la mediana è più robusta, in quanto minimizza l’errore assoluto atteso rispetto alla media.\n\n\n52.6.3 Stimatore della Moda Posteriori\nLa moda posteriori rappresenta il valore di \\(\\theta\\) che massimizza la densità a posteriori. Formalmente, è definita come:\n\\[\n\\theta^* = \\operatorname{arg\\,max}_\\theta p(\\theta \\mid y).\n\\]\nQuesta stima, spesso chiamata Maximum A Posteriori (MAP), si focalizza sul punto più probabile della distribuzione. Tuttavia, la moda non tiene conto della variabilità e non minimizza una funzione di perdita basata sui valori veri dei parametri. È meno comune rispetto a media e mediana, soprattutto per distribuzioni non unimodali o altamente asimmetriche.\n\n\n52.6.4 Proprietà degli Stimatori Bayesiani\nOgni stimatore presenta vantaggi e limitazioni:\n\nLa media posteriori minimizza l’errore quadratico medio atteso. Tuttavia, è sensibile ai valori estremi, specialmente per distribuzioni con code ampie.\nLa mediana posteriori minimizza l’errore assoluto atteso, rendendola più robusta ai valori anomali.\nLa moda posteriori non considera l’incertezza, ma è utile per individuare il valore più probabile.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_language.html#quantili-e-intervalli-di-credibilità",
    "href": "chapters/mcmc/03_stan_language.html#quantili-e-intervalli-di-credibilità",
    "title": "52  Linguaggio Stan",
    "section": "52.7 Quantili e Intervalli di Credibilità",
    "text": "52.7 Quantili e Intervalli di Credibilità\nI quantili offrono una descrizione dettagliata della distribuzione a posteriori, fornendo informazioni sulle sue diverse sezioni. Gli intervalli di credibilità, in particolare, rappresentano una porzione specificata della massa di probabilità della distribuzione. Ad esempio, un intervallo di credibilità al 90% è delimitato dai quantili al 5% e al 95%, che includono il 90% della massa di probabilità totale, lasciando il 5% fuori da ciascun lato.\n\n52.7.1 Calcolo dei Quantili con quantile()\nIn R, i quantili possono essere calcolati direttamente sui campioni estratti dalla distribuzione a posteriori:\n\nquantile_05 &lt;- quantile(theta2_vector, 0.05)\nquantile_95 &lt;- quantile(theta2_vector, 0.95)\nc(quantile_05, quantile_95)\n#&gt;     5%    95% \n#&gt; 0.0991 0.2153\n\nQuesto calcolo restituisce i limiti inferiori e superiori dell’intervallo di credibilità al 90% della distribuzione di \\(\\theta\\), con il 5% della probabilità distribuito rispettivamente sotto e sopra l’intervallo.\n\n\n52.7.2 Uso di posterior_interval() con rstanarm\nUn metodo alternativo è utilizzare la funzione posterior_interval() del pacchetto rstanarm, che calcola automaticamente gli intervalli di credibilità. Tuttavia, questa funzione richiede che i campioni siano forniti in formato matrice. Pertanto, è necessario estrarre i campioni come matrice da un oggetto di cmdstanr.\nEcco il processo completo:\n\nEstrazione dei Campioni come Matrice\n\nUsiamo l’opzione format = \"matrix\" per convertire i campioni estratti in una matrice compatibile con posterior_interval():\n\ntheta_draws_matrix &lt;- fit2$draws(\"theta\", format = \"matrix\")\n\n\nCalcolo degli Intervalli di Credibilità\n\nUna volta convertiti i campioni, possiamo calcolare l’intervallo di credibilità al 90% con:\n\nrstanarm::posterior_interval(theta_draws_matrix, prob = 0.90)\n#&gt;           5%   95%\n#&gt; theta 0.0991 0.215\n\n\nAlternative con Altri Pacchetti\n\nÈ possibile eseguire il calcolo in modo simile usando il pacchetto rstantools:\n\nrstantools::posterior_interval(\n  fit2$draws(\"theta\", format = \"matrix\"), \n  prob = 0.90\n)\n#&gt;           5%   95%\n#&gt; theta 0.0991 0.215\n\nIn sintesi, entrambi i metodi — quantile() e posterior_interval() — forniscono una stima accurata degli intervalli di credibilità. Il primo approccio offre flessibilità ed è utile per analisi rapide, mentre il secondo è più strutturato e fornisce un’interfaccia standardizzata per analisi bayesiane avanzate.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_language.html#riflessioni-conclusive",
    "href": "chapters/mcmc/03_stan_language.html#riflessioni-conclusive",
    "title": "52  Linguaggio Stan",
    "section": "52.8 Riflessioni Conclusive",
    "text": "52.8 Riflessioni Conclusive\nStan, grazie alla sua implementazione dell’algoritmo NUTS, offre un framework potente e flessibile per l’inferenza bayesiana. Attraverso una combinazione di modelli probabilistici ben strutturati, diagnostica avanzata e strumenti di visualizzazione, è possibile affrontare con successo problemi complessi, dalle simulazioni in avanti alle stime inverse dei parametri.\nAbbiamo visto come il pacchetto bayesplot offra varie funzioni per visualizzare le distribuzioni a posteriori dei parametri del modello.\nLa scelta dello stimatore dipende dal contesto e dalle proprietà della distribuzione a posteriori. La media è preferita per la sua capacità di minimizzare l’errore quadratico medio, mentre la mediana è utile per la sua robustezza. La moda può essere utile per individuare il valore più probabile, ma è meno comune nell’analisi bayesiana. La comprensione del bias, dell’errore Monte Carlo e della dimensione del campione effettivo è cruciale per valutare la qualità delle stime e interpretare correttamente i risultati.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_language.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/03_stan_language.html#informazioni-sullambiente-di-sviluppo",
    "title": "52  Linguaggio Stan",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] see_0.9.0           report_0.5.9        parameters_0.24.0  \n#&gt;  [4] performance_0.12.4  modelbased_0.8.9    insight_1.0.0      \n#&gt;  [7] effectsize_0.8.9    datawizard_0.13.0   correlation_0.8.6  \n#&gt; [10] bayestestR_0.15.0   easystats_0.7.3     posterior_1.6.0    \n#&gt; [13] cmdstanr_0.8.1.9000 MASS_7.3-61         viridis_0.6.5      \n#&gt; [16] viridisLite_0.4.2   ggpubr_0.6.0        ggExtra_0.10.1     \n#&gt; [19] gridExtra_2.3       patchwork_1.3.0     bayesplot_1.11.1   \n#&gt; [22] psych_2.4.6.26      scales_1.3.0        markdown_1.13      \n#&gt; [25] knitr_1.49          lubridate_1.9.3     forcats_1.0.0      \n#&gt; [28] stringr_1.5.1       dplyr_1.1.4         purrr_1.0.2        \n#&gt; [31] readr_2.1.5         tidyr_1.3.1         tibble_3.2.1       \n#&gt; [34] ggplot2_3.5.1       tidyverse_2.0.0     rio_1.2.3          \n#&gt; [37] here_1.0.1         \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;   [1] tensorA_0.36.2.1     rstudioapi_0.17.1    jsonlite_1.8.9      \n#&gt;   [4] magrittr_2.0.3       TH.data_1.1-2        estimability_1.5.1  \n#&gt;   [7] nloptr_2.1.1         farver_2.1.2         rmarkdown_2.29      \n#&gt;  [10] vctrs_0.6.5          minqa_1.2.8          base64enc_0.1-3     \n#&gt;  [13] rstatix_0.7.2        htmltools_0.5.8.1    curl_6.0.1          \n#&gt;  [16] distributional_0.5.0 broom_1.0.7          Formula_1.2-5       \n#&gt;  [19] StanHeaders_2.32.10  htmlwidgets_1.6.4    plyr_1.8.9          \n#&gt;  [22] sandwich_3.1-1       emmeans_1.10.5       zoo_1.8-12          \n#&gt;  [25] igraph_2.1.1         mime_0.12            lifecycle_1.0.4     \n#&gt;  [28] pkgconfig_2.0.3      colourpicker_1.3.0   Matrix_1.7-1        \n#&gt;  [31] R6_2.5.1             fastmap_1.2.0        shiny_1.9.1         \n#&gt;  [34] digest_0.6.37        colorspace_2.1-1     ps_1.8.1            \n#&gt;  [37] rprojroot_2.0.4      crosstalk_1.2.1      labeling_0.4.3      \n#&gt;  [40] fansi_1.0.6          timechange_0.3.0     abind_1.4-8         \n#&gt;  [43] compiler_4.4.2       withr_3.0.2          inline_0.3.20       \n#&gt;  [46] backports_1.5.0      shinystan_2.6.0      carData_3.0-5       \n#&gt;  [49] QuickJSR_1.4.0       pkgbuild_1.4.5       ggsignif_0.6.4      \n#&gt;  [52] loo_2.8.0            gtools_3.9.5         tools_4.4.2         \n#&gt;  [55] httpuv_1.6.15        threejs_0.3.3        glue_1.8.0          \n#&gt;  [58] nlme_3.1-166         promises_1.3.2       grid_4.4.2          \n#&gt;  [61] checkmate_2.3.2      reshape2_1.4.4       generics_0.1.3      \n#&gt;  [64] gtable_0.3.6         tzdb_0.4.0           data.table_1.16.2   \n#&gt;  [67] hms_1.1.3            car_3.1-3            utf8_1.2.4          \n#&gt;  [70] pillar_1.9.0         later_1.4.1          splines_4.4.2       \n#&gt;  [73] lattice_0.22-6       survival_3.7-0       tidyselect_1.2.1    \n#&gt;  [76] miniUI_0.1.1.1       V8_6.0.0             stats4_4.4.2        \n#&gt;  [79] xfun_0.49            rstanarm_2.32.1      matrixStats_1.4.1   \n#&gt;  [82] rstan_2.32.6         DT_0.33              stringi_1.8.4       \n#&gt;  [85] boot_1.3-31          yaml_2.3.10          pacman_0.5.1        \n#&gt;  [88] evaluate_1.0.1       codetools_0.2-20     cli_3.6.3           \n#&gt;  [91] RcppParallel_5.1.9   shinythemes_1.2.0    xtable_1.8-4        \n#&gt;  [94] munsell_0.5.1        processx_3.8.4       Rcpp_1.0.13-1       \n#&gt;  [97] coda_0.19-4.1        parallel_4.4.2       rstantools_2.4.0    \n#&gt; [100] dygraphs_1.1.1.6     lme4_1.1-35.5        mvtnorm_1.3-2       \n#&gt; [103] xts_0.14.1           rlang_1.1.4          multcomp_1.4-26     \n#&gt; [106] mnormt_2.1.1         shinyjs_2.1.0",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html",
    "href": "chapters/mcmc/04_stan_summary_posterior.html",
    "title": "53  Metodi di sintesi della distribuzione a posteriori",
    "section": "",
    "text": "53.1 Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nPreparazione del Notebook\nL’obiettivo di questo capitolo è illustrare come sintetizzare una distribuzione a posteriori ottenuta attraverso il campionamento MCMC (Markov Chain Monte Carlo). Questa tecnica è fondamentale nell’inferenza bayesiana moderna, permettendo di comprendere e interpretare i parametri di interesse in modo probabilistico.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#introduzione",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#introduzione",
    "title": "53  Metodi di sintesi della distribuzione a posteriori",
    "section": "",
    "text": "53.1.1 Cos’è la Distribuzione a Posteriori?\nLa distribuzione a posteriori rappresenta la nostra conoscenza aggiornata sui parametri di interesse. Essa combina l’informazione iniziale (distribuzione a priori) con le evidenze empiriche (dati osservati) attraverso il modello statistico. È un concetto chiave che distingue l’approccio bayesiano dall’inferenza classica.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#sintesi-della-distribuzione-a-posteriori",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#sintesi-della-distribuzione-a-posteriori",
    "title": "53  Metodi di sintesi della distribuzione a posteriori",
    "section": "53.2 Sintesi della Distribuzione a Posteriori",
    "text": "53.2 Sintesi della Distribuzione a Posteriori\nIl risultato di un’analisi bayesiana è una distribuzione a posteriori, contenente tutte le informazioni sui parametri dati un modello e un insieme di dati. Pertanto, riassumere la distribuzione a posteriori significa sintetizzare le conseguenze logiche del modello e dei dati analizzati. È prassi comune riportare, per ciascun parametro, una misura di posizione centrale (come la media, la moda o la mediana) per fornire un’idea della localizzazione della distribuzione, accompagnata da una misura di dispersione, quale la deviazione standard, per quantificare l’incertezza delle stime. La deviazione standard è adeguata per distribuzioni simili alla normale, ma può risultare fuorviante per distribuzioni di altra natura, come quelle asimmetriche.\nPer riassumere la dispersione di una distribuzione a posteriori, si utilizza spesso l’Intervallo di Densità Più Alta (HDI, Highest-Density Interval). L’HDI è l’intervallo più breve che contiene una data porzione della densità di probabilità. Ad esempio, se diciamo che l’HDI al 95% per un’analisi è [2, 5], intendiamo che, secondo i nostri dati e modello, il parametro in questione si trova tra 2 e 5 con una probabilità di 0.95. Non vi è nulla di particolare nella scelta del 95%, del 50% o di qualsiasi altro valore; siamo liberi di scegliere, ad esempio, l’intervallo HDI all’89% o al 94% secondo le nostre preferenze. Idealmente, le giustificazioni per queste scelte dovrebbero dipendere dal contesto e non essere automatiche, ma è accettabile stabilire un valore comune come il 95%.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#campionamento-con-stan",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#campionamento-con-stan",
    "title": "53  Metodi di sintesi della distribuzione a posteriori",
    "section": "53.3 Campionamento con Stan",
    "text": "53.3 Campionamento con Stan\nA scopo illustrativo, immaginiamo di aver condotto un’analisi campionando casualmente 100 opere dal Museum of Modern Art (MoMA) e di aver riscontrato che 14 sono di artisti della Generazione X. Utilizzeremo un modello Beta-Binomiale per affrontare questo problema. Il parametro θ rappresenterà la proporzione di artisti della Generazione X. Adotteremo una distribuzione a priori Beta(4, 6), che riflette un’aspettativa iniziale basata su conoscenze pregresse. I dati osservati (14 opere su 100) verranno utilizzati per aggiornare questa distribuzione iniziale.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#implementazione-in-stan",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#implementazione-in-stan",
    "title": "53  Metodi di sintesi della distribuzione a posteriori",
    "section": "53.4 Implementazione in Stan",
    "text": "53.4 Implementazione in Stan\nIl seguente codice Stan definisce il nostro modello probabilistico:\n\n# Path to the Stan file\nstan_file &lt;- here::here(\"stan\", \"moma.stan\")\n\n# Create a CmdStanModel object\nmod &lt;- cmdstan_model(stan_file)\n\n\nmod$print()\n#&gt; data {\n#&gt;   int&lt;lower=0&gt; N;           // Numero totale di prove\n#&gt;   int&lt;lower=0&gt; y;           // Numero di successi osservati\n#&gt;   real&lt;lower=0&gt; alpha_prior; // Parametro alpha della distribuzione Beta a priori\n#&gt;   real&lt;lower=0&gt; beta_prior;  // Parametro beta della distribuzione Beta a priori\n#&gt; }\n#&gt; \n#&gt; parameters {\n#&gt;   real&lt;lower=0, upper=1&gt; theta; // Probabilità di successo\n#&gt; }\n#&gt; \n#&gt; model {\n#&gt;   // Distribuzione a priori Beta\n#&gt;   theta ~ beta(alpha_prior, beta_prior);\n#&gt;   \n#&gt;   // Likelihood binomiale\n#&gt;   y ~ binomial(N, theta);\n#&gt; }\n#&gt; \n#&gt; generated quantities {\n#&gt;   real log_lik; // Log-verosimiglianza\n#&gt;   log_lik = binomial_lpmf(y | N, theta);\n#&gt; }\n\nProcediamo con l’implementazione pratica del modello per stimare la proporzione di artisti della Generazione X (θ) al MoMA.\nDefiniamo i dati osservati e i parametri della distribuzione a priori:\n\nN &lt;- 100\ny &lt;- 14\n\nstan_data &lt;- list(\n  N = N,\n  y = y,\n  alpha_prior = 4,\n  beta_prior = 6\n)\n\nEseguiamo il campionamento utilizzando il modello compilato in precedenza:\n\nfit &lt;- mod$sample(\n  data = stan_data,\n  seed = 123,\n  chains = 4,\n  parallel_chains = 4,\n  iter_sampling = 2000, \n  iter_warmup = 2000,\n  show_messages = FALSE\n)\n\nPer evitare di dover ripetere il campionamento (che può essere computazionalmente costoso), possiamo salvare l’oggetto fit su disco utilizzando la funzione qsave() del pacchetto qs. Questo garantisce un caricamento rapido e senza perdita di dati.\n\n# Save the object to a file.\nqs::qsave(x = fit, file = \"fit_moma.qs\")\n\nSe in seguito vogliamo analizzare i risultati senza dover ripetere il campionamento, possiamo leggere l’oggetto salvato direttamente nel nostro ambiente R:\n\n# Read the object.\nfit2 &lt;- qs::qread(\"fit_moma.qs\")\n\nL’oggetto fit2 è identico a fit e contiene tutte le informazioni relative al modello, ai parametri, ai campioni e ai metadati.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#analisi-della-distribuzione-a-posteriori",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#analisi-della-distribuzione-a-posteriori",
    "title": "53  Metodi di sintesi della distribuzione a posteriori",
    "section": "53.5 Analisi della distribuzione a posteriori",
    "text": "53.5 Analisi della distribuzione a posteriori\nLa distribuzione a posteriori rappresenta la nostra conoscenza aggiornata riguardo al valore del parametro \\(\\theta\\) dopo aver osservato i dati. Combina le nostre credenze a priori riguardo al parametro (la distribuzione a priori) con le nuove evidenze fornite dai dati osservati (la funzione di verosimiglianza) per ottenere una nuova distribuzione che riflette la nostra comprensione aggiornata del parametro, ovvero la distribuzione a posteriori.\nLa distribuzione a posteriori ci dice quanto sia probabile ogni possibile valore del parametro alla luce dei dati osservati. Un picco stretto indica che i dati sono molto informativi rispetto al parametro, portando a una maggiore certezza nella sua stima. Un picco largo, invece, indica maggiore incertezza.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#esaminare-i-valori-della-distribuzione-a-posteriori",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#esaminare-i-valori-della-distribuzione-a-posteriori",
    "title": "53  Metodi di sintesi della distribuzione a posteriori",
    "section": "53.6 Esaminare i Valori della Distribuzione a Posteriori",
    "text": "53.6 Esaminare i Valori della Distribuzione a Posteriori\nDopo aver eseguito il campionamento con Stan, possiamo esaminare i valori della distribuzione a posteriori accedendo ai campioni generati.\n\n53.6.1 Estrarre i Campioni in un Oggetto draws_array\nIl metodo fit$draws() restituisce i campioni in un oggetto tridimensionale del tipo draws_array, che fa parte del pacchetto posterior.\n\n# Estrazione dei campioni posteriori in formato array (default)\ndraws_arr &lt;- fit2$draws()  \nstr(draws_arr)  # Struttura dell'oggetto\n#&gt;  'draws_array' num [1:2000, 1:4, 1:3] -50 -49.7 -49 -49.1 -51.4 ...\n#&gt;  - attr(*, \"dimnames\")=List of 3\n#&gt;   ..$ iteration: chr [1:2000] \"1\" \"2\" \"3\" \"4\" ...\n#&gt;   ..$ chain    : chr [1:4] \"1\" \"2\" \"3\" \"4\"\n#&gt;   ..$ variable : chr [1:3] \"lp__\" \"theta\" \"log_lik\"\n\nL’output sarà un array 3D con le dimensioni iterazioni × catene × variabili, ovvero il formato standard per i campioni MCMC.\nPer verificare le dimensioni dell’array:\n\ndim(draws_arr)\n#&gt; [1] 2000    4    3\n\nAd esempio, se l’output di dim(draws_arr) restituisce (2000, 4, 3), le dimensioni si riferiscono a:\n\n2000: Numero di iterazioni di campionamento per ciascuna catena, specificato dall’argomento iter_sampling = 2000 durante il campionamento.\n4: Numero di catene eseguite in parallelo, specificato da chains = 4.\n3: Numero di parametri o quantità campionate, inclusi:\n\nParametri definiti nel blocco parameters del modello Stan.\nQuantità trasformate (transformed parameters).\nQuantità generate (generated quantities).\n\n\n\n\n53.6.2 Interpretazione della Struttura\nL’array 3D permette di accedere ai campioni in modo organizzato:\n\nPrima dimensione: Iterazioni per ciascuna catena (es. draws_arr[1,,] restituisce i valori della prima iterazione di tutte le catene).\nSeconda dimensione: Catene (es. draws_arr[,1,] restituisce tutti i campioni della prima catena).\nTerza dimensione: Variabili campionate (es. draws_arr[,,1] restituisce i valori della prima variabile in tutte le iterazioni e catene).\n\n\n\n53.6.3 Accesso ai Parametri\nPer accedere ai campioni di un parametro specifico, possiamo utilizzare il nome del parametro con il metodo fit$draws(format = \"matrix\") o fit$draws(format = \"df\").\n\n# Estrazione dei campioni in formato data frame\ndraws_df &lt;- fit2$draws(format = \"df\")\n\n# Visualizza i primi campioni della variabile \"theta\"\nhead(draws_df$theta)\n#&gt; [1] 0.1187770 0.1252060 0.1680210 0.1477010 0.0971118 0.0866890\n\n\n\n53.6.4 Sintesi dei Campioni\nPer riassumere i campioni della distribuzione a posteriori:\n\nfit2$summary()\n#&gt; # A tibble: 3 × 10\n#&gt;   variable    mean  median     sd    mad      q5     q95  rhat ess_bulk\n#&gt;   &lt;chr&gt;      &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 lp__     -49.5   -49.2   0.697  0.292  -50.9   -49.0    1.00    3699.\n#&gt; 2 theta      0.164   0.162 0.0345 0.0339   0.112   0.225  1.00    2813.\n#&gt; 3 log_lik   -2.78   -2.46  0.827  0.397   -4.48   -2.17   1.00    3803.\n#&gt; # ℹ 1 more variable: ess_tail &lt;dbl&gt;\n\n\n\n53.6.5 Vantaggi del Formato draws_array\nIl formato draws_array è particolarmente utile per:\n\nAnalisi avanzate: Permette di accedere direttamente a specifiche iterazioni, catene e parametri.\nVisualizzazioni: È compatibile con funzioni di plotting del pacchetto bayesplot.\nControlli diagnostici: Facilita l’analisi della convergenza e della miscelazione delle catene.\n\nCon questa struttura, possiamo esplorare in dettaglio la distribuzione a posteriori generata dal modello Stan.\n\nfit2$metadata()$model_params\n#&gt; [1] \"lp__\"    \"theta\"   \"log_lik\"\n\nRecuperiamo i campioni posteriori per theta:\n\ndraws_df &lt;- fit2$draws(format = \"df\")\nhead(draws_df)\n#&gt; # A draws_df: 6 iterations, 1 chains, and 3 variables\n#&gt;   lp__ theta log_lik\n#&gt; 1  -50 0.119    -2.4\n#&gt; 2  -50 0.125    -2.3\n#&gt; 3  -49 0.168    -2.5\n#&gt; 4  -49 0.148    -2.2\n#&gt; 5  -51 0.097    -3.1\n#&gt; 6  -52 0.087    -3.7\n#&gt; # ... hidden reserved variables {'.chain', '.iteration', '.draw'}\n\n\ndraws_df$theta |&gt;\n  head()\n#&gt; [1] 0.1187770 0.1252060 0.1680210 0.1477010 0.0971118 0.0866890\n\n\nlength(draws_df$theta)\n#&gt; [1] 8000\n\nGeneriamo un istogramma della distribuzione a posteriori di theta:\n\ndraws_df |&gt;\n  ggplot(aes(theta)) +\n  geom_histogram()\n#&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nIn alternativa, possiamo passare l’oggetto fit$draws(\"theta\") alla funzione mcmc_hist() di bayesplot:\n\nmcmc_hist(fit2$draws(\"theta\"))\n#&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nOppure possiamo usare la funzione mcmc_dens_overlay():\n\nmcmc_dens_overlay(fit2$draws(\"theta\"))\n\n\n\n\n\n\n\n\nLa traccia del campionamento si ottiene nel modo seguente:\n\nmcmc_trace(fit2$draws(\"theta\"))\n\n\n\n\n\n\n\n\nConfrontiamo la distribuzione a posteriori con la distribuzione a priori di \\(\\theta\\).\n\n# Parameters of the Beta distribution\nalpha &lt;- 4\nbeta_param &lt;- 6\n\n# Create a data frame for the prior Beta distribution\nx &lt;- seq(0, 1, length.out = 1000)\nprior_pdf &lt;- dbeta(x, alpha, beta_param)\nprior_df &lt;- data.frame(theta = x, density = prior_pdf, distribution = \"Prior\")\n\n# Extract posterior draws of theta and calculate density\nposterior_theta &lt;- as.vector(fit2$draws(\"theta\")) # Assuming `fit2$draws(\"theta\")` works\nposterior_density &lt;- density(posterior_theta)\nposterior_df &lt;- data.frame(\n  theta = posterior_density$x,\n  density = posterior_density$y,\n  distribution = \"Posterior\"\n)\n\n# Combine the prior and posterior data\ncombined_df &lt;- bind_rows(prior_df, posterior_df)\n\n# Plot using ggplot2\nggplot(combined_df, aes(x = theta, y = density, color = distribution)) +\n  geom_line(size = 1.2) +\n  labs(\n    x = expression(theta),\n    y = \"Density\",\n    title = \"Prior and Posterior Distributions\"\n  ) +\n  scale_color_manual(\n    values = c(\"Prior\" = \"black\", \"Posterior\" = \"red\"),\n    name = \"Distribution\"\n  ) +\n  theme(\n    legend.position = \"top\",\n    plot.title = element_text(hjust = 0.5)\n  )\n#&gt; Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\nNel caso presente, la distribuzione a posteriori differisce in maniera importante dalla distribuzione a priori. Ciò indica che i dati hanno avuto un forte impatto sulle nostre credenze riguardo al valore del parametro.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#intervallo-di-credibilità",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#intervallo-di-credibilità",
    "title": "53  Metodi di sintesi della distribuzione a posteriori",
    "section": "53.7 Intervallo di Credibilità",
    "text": "53.7 Intervallo di Credibilità\nGli intervalli di credibilità sono uno strumento fondamentale nell’inferenza bayesiana per riassumere l’incertezza sui parametri stimati. Esistono due metodi principali per calcolare gli intervalli di credibilità:\n\nHighest Density Interval (HDI): definisce l’intervallo più stretto che contiene la probabilità specificata, includendo le aree di maggiore densità della distribuzione a posteriori.\nEqual-tailed Interval (ETI): lascia una probabilità uguale (ad esempio, il 2,5% per un intervallo al 95%) in entrambe le code della distribuzione.\n\nQuesti metodi producono risultati identici in caso di distribuzioni simmetriche ma differiscono per distribuzioni asimmetriche. Di seguito vediamo come interpretare e calcolare questi intervalli.\nDistribuzione Simmetrica\nCon una distribuzione a posteriori simmetrica, come quella normale, gli intervalli HDI ed ETI coincidono.\nEsempio di calcolo:\n\n# Genera una distribuzione normale\nposterior &lt;- distribution_normal(1000)\n\n# Calcola HDI ed ETI\nci_hdi &lt;- ci(posterior, method = \"HDI\")\nci_eti &lt;- ci(posterior, method = \"ETI\")\n\n# Visualizza la distribuzione con i limiti degli intervalli\nout &lt;- estimate_density(posterior, extend = TRUE)\nggplot(out, aes(x = x, y = y)) +\n  geom_area(fill = \"orange\") +\n  # HDI in blu\n  geom_vline(xintercept = ci_hdi$CI_low, color = \"royalblue\", linewidth = 3) +\n  geom_vline(xintercept = ci_hdi$CI_high, color = \"royalblue\", linewidth = 3) +\n  # ETI in rosso\n  geom_vline(xintercept = ci_eti$CI_low, color = \"red\", linewidth = 1) +\n  geom_vline(xintercept = ci_eti$CI_high, color = \"red\", linewidth = 1)\n\n\n\n\n\n\n\n\nDistribuzione Asimmetrica\nQuando la distribuzione a posteriori è asimmetrica, come una distribuzione beta, l’HDI è generalmente più stretto rispetto all’ETI poiché privilegia le regioni di maggiore densità.\nEsempio di calcolo:\n\n# Genera una distribuzione beta\nposterior &lt;- distribution_beta(1000, 6, 2)\n\n# Calcola HDI ed ETI\nci_hdi &lt;- ci(posterior, method = \"HDI\")\nci_eti &lt;- ci(posterior, method = \"ETI\")\n\n# Visualizza la distribuzione con i limiti degli intervalli\nout &lt;- estimate_density(posterior, extend = TRUE)\nggplot(out, aes(x = x, y = y)) +\n  geom_area(fill = \"orange\") +\n  # HDI in blu\n  geom_vline(xintercept = ci_hdi$CI_low, color = \"royalblue\", linewidth = 3) +\n  geom_vline(xintercept = ci_hdi$CI_high, color = \"royalblue\", linewidth = 3) +\n  # ETI in rosso\n  geom_vline(xintercept = ci_eti$CI_low, color = \"red\", linewidth = 1) +\n  geom_vline(xintercept = ci_eti$CI_high, color = \"red\", linewidth = 1)\n\n\n\n\n\n\n\n\n\n53.7.1 Interpretazione dell’Intervallo di Credibilità\nL’intervallo di credibilità bayesiano offre una chiara interpretazione probabilistica: dato il modello e i dati, c’è una probabilità specificata (ad esempio, il 94%) che il parametro si trovi all’interno dell’intervallo calcolato.\n\n\n53.7.2 Calcolo degli intervalli in R\n\nHDI:\n\n\nbayestestR::ci(fit2$draws(\"theta\"), method = \"HDI\")\n#&gt; Highest Density Interval\n#&gt; \n#&gt; Parameter |      95% HDI\n#&gt; ------------------------\n#&gt; theta     | [0.10, 0.23]\n\n\nETI:\n\n\nbayestestR::ci(fit2$draws(\"theta\"), method = \"ETI\")\n#&gt; Equal-Tailed Interval\n#&gt; \n#&gt; Parameter |      95% ETI\n#&gt; ------------------------\n#&gt; theta     | [0.10, 0.24]\n\n\n\n53.7.3 Visualizzazione grafica\nUtilizzando il pacchetto bayesplot possiamo rappresentare la distribuzione a posteriori con l’HDI:\n\nmcmc_areas(fit2$draws(\"theta\"), \n           prob = 0.94) +  # Specifica il livello dell'HDI\n  ggtitle(\"Distribuzione a Posteriori di Theta con HDI al 94%\") +\n  xlab(expression(theta)) +\n  ylab(\"Densità\")\n\n\n\n\n\n\n\n\n\n\n53.7.4 Confronto con gli Intervalli di Confidenza Frequentisti\nGli intervalli di credibilità bayesiani si distinguono nettamente dagli intervalli di confidenza frequentisti. Mentre gli intervalli frequentisti si basano su una prospettiva a lungo termine (ovvero, il 95% degli intervalli costruiti su infiniti campioni includerebbe il vero valore), gli intervalli bayesiani:\n\nHanno una chiara interpretazione probabilistica: dato il modello e i dati, indicano direttamente la probabilità che il parametro sia nell’intervallo.\nIncorporano credenze a priori, combinate con l’evidenza fornita dai dati.\n\n\n\n53.7.5 Scelta del Livello dell’Intervallo (89% vs 95%)\nUna discussione comune nell’inferenza bayesiana riguarda il livello predefinito degli intervalli. Sebbene il 95% sia un valore convenzionale mutuato dal frequentismo, alcune evidenze suggeriscono che livelli più bassi (ad esempio, 89%) possano essere più stabili per le distribuzioni a posteriori, specialmente con un numero limitato di campioni posteriori (Kruschke, 2014).\n\nVantaggi del 95%:\n\nRelazione intuitiva con la deviazione standard.\nMaggiore probabilità di includere 0, rendendo le analisi più conservative.\n\nVantaggi dell’89%:\n\nMaggiore stabilità con campioni posteriori limitati.\nEvita l’arbitrarietà del valore 95% (McElreath, 2018).\n\n\nIn conclusione, la scelta tra HDI e ETI, così come il livello dell’intervallo, dipende dagli obiettivi e dal contesto dell’analisi. Gli intervalli di credibilità offrono un approccio flessibile e intuitivo per sintetizzare l’incertezza, adattandosi alle esigenze di analisi sia esplorative che confermative.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#test-di-ipotesi-bayesiane",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#test-di-ipotesi-bayesiane",
    "title": "53  Metodi di sintesi della distribuzione a posteriori",
    "section": "53.8 Test di Ipotesi Bayesiane",
    "text": "53.8 Test di Ipotesi Bayesiane\nIn alcune situazioni, descrivere semplicemente la distribuzione a posteriori potrebbe non essere sufficiente. Potremmo dover prendere decisioni pratiche basate sulle inferenze, traducendo stime continue in scelte binarie. Ad esempio, possiamo voler determinare se una terapia è efficace, se un intervento ha avuto successo, o se una proporzione supera una soglia di rilevanza pratica.\nSupponiamo di voler verificare se, nel Museum of Modern Art (MoMA), gli artisti della generazione X (nati tra il 1965 e il 1980) rappresentano meno del 10% del corpus esposto. Analizzando un campione casuale di 100 opere e utilizzando un prior basato su convinzioni pregresse, stimiamo la distribuzione a posteriori della proporzione di artisti, \\(\\theta\\). L’intervallo di credibilità (Credible Interval, CI) al 94% risulta compreso tra 0.104 e 0.235.\nLa nostra ipotesi iniziale è che la proporzione di artisti della generazione X sia inferiore al 10%, cioè \\(\\theta &lt; 0.1\\). Tuttavia, il fatto che l’intero intervallo di credibilità al 94% si trovi sopra la soglia del 10% contraddice questa ipotesi. Per quantificare ulteriormente la compatibilità dei dati con questa ipotesi, calcoliamo la probabilità a posteriori che \\(\\theta &lt; 0.1\\).\n\nfit2$summary(\"theta\", pr_lt_01 = ~ mean(. &lt;= 0.1))\n#&gt; # A tibble: 1 × 2\n#&gt;   variable pr_lt_01\n#&gt;   &lt;chr&gt;       &lt;dbl&gt;\n#&gt; 1 theta      0.0213\n\nLa probabilità a posteriori che \\(\\theta &lt; 0.1\\)** è molto bassa, ovvero \\(P(\\theta &lt; 0.1) = 0.0213\\), fornendo ulteriori evidenze contro l’ipotesi che gli artisti della generazione X rappresentino meno del 10% del corpus esposto.\nIn sintesi, sulla base dei dati e del modello, l’ipotesi che gli artisti della generazione X rappresentino meno del 10% non è supportata. Al contrario, i dati indicano, con un livello di certezza soggettiva del 94%, che la proporzione di artisti appartenenti a questa generazione è molto probabilmente superiore al 10%.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#riflessioni-conclusive",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#riflessioni-conclusive",
    "title": "53  Metodi di sintesi della distribuzione a posteriori",
    "section": "53.9 Riflessioni conclusive",
    "text": "53.9 Riflessioni conclusive\nLa crescente popolarità dei metodi bayesiani in psicologia e nelle scienze sociali è stata fortemente influenzata dalla (ri)scoperta di algoritmi numerici capaci di stimare le distribuzioni a posteriori dei parametri del modello a partire dai dati osservati. Prima di questi sviluppi, ottenere misure riassuntive delle distribuzioni a posteriori, soprattutto per modelli complessi con molti parametri, era praticamente impossibile.\nQuesto capitolo fornisce un’introduzione a cmdstanr, che permette di compilare ed eseguire modelli probabilistici espressi in linguaggio Stan. Grazie a questa tecnologia, è possibile generare una stima della distribuzione a posteriori attraverso il campionamento Markov Chain Monte Carlo (MCMC), rivoluzionando la capacità di effettuare inferenze bayesiane e rendendo l’analisi di modelli complessi più accessibile e gestibile.\nInoltre, nel capitolo sono state presentate diverse strategie per la trasformazione della distribuzione a posteriori e sono state esplorate modalità per ottenere intervalli di credibilità. Successivamente, è stata discussa l’analisi delle ipotesi a posteriori, che consente di confrontare due ipotesi contrapposte riguardanti il parametro \\(\\theta\\).",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#informazioni-sullambiente-di-sviluppo",
    "title": "53  Metodi di sintesi della distribuzione a posteriori",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] see_0.9.0           insight_1.0.0       bayestestR_0.15.0  \n#&gt;  [4] rstanarm_2.32.1     Rcpp_1.0.13-1       qs_0.27.2          \n#&gt;  [7] posterior_1.6.0     cmdstanr_0.8.1.9000 MASS_7.3-61        \n#&gt; [10] viridis_0.6.5       viridisLite_0.4.2   ggpubr_0.6.0       \n#&gt; [13] ggExtra_0.10.1      gridExtra_2.3       patchwork_1.3.0    \n#&gt; [16] bayesplot_1.11.1    psych_2.4.6.26      scales_1.3.0       \n#&gt; [19] markdown_1.13       knitr_1.49          lubridate_1.9.3    \n#&gt; [22] forcats_1.0.0       stringr_1.5.1       dplyr_1.1.4        \n#&gt; [25] purrr_1.0.2         readr_2.1.5         tidyr_1.3.1        \n#&gt; [28] tibble_3.2.1        ggplot2_3.5.1       tidyverse_2.0.0    \n#&gt; [31] rio_1.2.3           here_1.0.1         \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;   [1] tensorA_0.36.2.1     jsonlite_1.8.9       datawizard_0.13.0   \n#&gt;   [4] magrittr_2.0.3       nloptr_2.1.1         farver_2.1.2        \n#&gt;   [7] rmarkdown_2.29       vctrs_0.6.5          minqa_1.2.8         \n#&gt;  [10] base64enc_0.1-3      rstatix_0.7.2        htmltools_0.5.8.1   \n#&gt;  [13] distributional_0.5.0 curl_6.0.1           broom_1.0.7         \n#&gt;  [16] Formula_1.2-5        StanHeaders_2.32.10  htmlwidgets_1.6.4   \n#&gt;  [19] plyr_1.8.9           zoo_1.8-12           igraph_2.1.1        \n#&gt;  [22] mime_0.12            lifecycle_1.0.4      pkgconfig_2.0.3     \n#&gt;  [25] colourpicker_1.3.0   Matrix_1.7-1         R6_2.5.1            \n#&gt;  [28] fastmap_1.2.0        shiny_1.9.1          digest_0.6.37       \n#&gt;  [31] colorspace_2.1-1     ps_1.8.1             rprojroot_2.0.4     \n#&gt;  [34] crosstalk_1.2.1      labeling_0.4.3       fansi_1.0.6         \n#&gt;  [37] timechange_0.3.0     abind_1.4-8          compiler_4.4.2      \n#&gt;  [40] withr_3.0.2          backports_1.5.0      inline_0.3.20       \n#&gt;  [43] shinystan_2.6.0      carData_3.0-5        QuickJSR_1.4.0      \n#&gt;  [46] pkgbuild_1.4.5       ggsignif_0.6.4       gtools_3.9.5        \n#&gt;  [49] loo_2.8.0            tools_4.4.2          httpuv_1.6.15       \n#&gt;  [52] threejs_0.3.3        glue_1.8.0           nlme_3.1-166        \n#&gt;  [55] promises_1.3.2       grid_4.4.2           checkmate_2.3.2     \n#&gt;  [58] reshape2_1.4.4       generics_0.1.3       gtable_0.3.6        \n#&gt;  [61] tzdb_0.4.0           data.table_1.16.2    RApiSerialize_0.1.4 \n#&gt;  [64] hms_1.1.3            stringfish_0.16.0    car_3.1-3           \n#&gt;  [67] utf8_1.2.4           pillar_1.9.0         later_1.4.1         \n#&gt;  [70] splines_4.4.2        lattice_0.22-6       survival_3.7-0      \n#&gt;  [73] tidyselect_1.2.1     miniUI_0.1.1.1       V8_6.0.0            \n#&gt;  [76] stats4_4.4.2         xfun_0.49            matrixStats_1.4.1   \n#&gt;  [79] DT_0.33              rstan_2.32.6         stringi_1.8.4       \n#&gt;  [82] boot_1.3-31          yaml_2.3.10          pacman_0.5.1        \n#&gt;  [85] evaluate_1.0.1       codetools_0.2-20     cli_3.6.3           \n#&gt;  [88] RcppParallel_5.1.9   shinythemes_1.2.0    xtable_1.8-4        \n#&gt;  [91] munsell_0.5.1        processx_3.8.4       parallel_4.4.2      \n#&gt;  [94] rstantools_2.4.0     dygraphs_1.1.1.6     lme4_1.1-35.5       \n#&gt;  [97] ggridges_0.5.6       xts_0.14.1           rlang_1.1.4         \n#&gt; [100] mnormt_2.1.1         shinyjs_2.1.0",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio.html",
    "href": "chapters/mcmc/08_stan_odds_ratio.html",
    "title": "54  Analisi bayesiana dell’odds-ratio",
    "section": "",
    "text": "54.1 Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nPreparazione del Notebook\nIn questo capitolo, esploreremo l’applicazione degli strumenti statistici descritti nei capitoli precedenti all’analisi bayesiana di due proporzioni. Inizieremo definendo i concetti di odds, odds ratio e logit. Successivamente, mostreremo come effettuare l’analisi bayesiana per il confronto tra due proporzioni.\nUn rapporto di odds (OR) è una misura di associazione tra un’esposizione (o un certo gruppo o una certa conditione) e un risultato. L’OR rappresenta gli odds che si verifichi un risultato dato un’esposizione particolare, confrontate con gli odds del risultato che si verifica in assenza di tale esposizione.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio.html#odds",
    "href": "chapters/mcmc/08_stan_odds_ratio.html#odds",
    "title": "54  Analisi bayesiana dell’odds-ratio",
    "section": "54.2 Odds",
    "text": "54.2 Odds\nIl termine “odds” rappresenta il rapporto tra la probabilità che un evento si verifichi e la probabilità che l’evento opposto si verifichi. Matematicamente, l’odds può essere calcolato come:\n\\[\n\\text{odds} = \\frac{\\pi}{1-\\pi},\n\\]\ndove \\(\\pi\\) rappresenta la probabilità dell’evento di interesse.\nMentre una probabilità \\(\\pi\\) è sempre compresa tra 0 e 1, gli odds possono variare da 0 a infinito. Per comprendere meglio gli odds lungo questo spettro, consideriamo tre diversi scenari in cui \\(\\pi\\) rappresenta la probabilità di un evento.\nSe la probabilità di un evento è \\(\\pi = \\frac{2}{3}\\), allora la probabilità che l’evento non si verifichi è \\(1 - \\pi = \\frac{1}{3}\\) e gli odds del verificarsi dell’evento sono:\n\\[\n\\text{odds} = \\frac{2/3}{1-2/3} = 2.\n\\]\nQuesto significa che la probabilità che l’evento si verifichi è il doppio della probabilità che non si verifichi.\nSe, invece, la probabilità dell’evento è \\(\\pi = \\frac{1}{3}\\), allora gli odds che l’evento si verifichi sono la metà rispetto agli odds che non si verifichi:\n\\[\n\\text{odds} = \\frac{1/3}{1-1/3} = \\frac{1}{2}.\n\\]\nInfine, se la probabilità dell’evento è \\(\\pi = \\frac{1}{2}\\), allora gli odds dell’evento sono pari a 1:\n\\[\n\\text{odds} = \\frac{1/2}{1-1/2} = 1.\n\\]\n\n54.2.1 Interpretazione\nGli odds possono essere interpretati nel modo seguente. Consideriamo un evento di interesse con probabilità \\(\\pi \\in [0, 1]\\) e gli odds corrispondenti \\(\\frac{\\pi}{1-\\pi} \\in [0, \\infty)\\). Confrontando gli odds con il valore 1, possiamo ottenere una prospettiva sull’incertezza dell’evento:\n\nGli odds di un evento sono inferiori a 1 se e solo se le probabilità dell’evento sono inferiori al 50-50, cioè \\(\\pi &lt; 0.5\\).\nGli odds di un evento sono uguali a 1 se e solo se le probabilità dell’evento sono del 50-50, cioè \\(\\pi = 0.5\\).\nGli odds di un evento sono superiori a 1 se e solo se le probabilità dell’evento sono superiori al 50-50, cioè \\(\\pi &gt; 0.5\\).\n\nUno dei motivi per preferire l’uso dell’odds rispetto alla probabilità, nonostante quest’ultima sia un concetto più intuitivo, risiede nel fatto che quando le probabilità si avvicinano ai valori estremi (cioè 0 o 1), è più facile rilevare e apprezzare le differenze tra gli odds piuttosto che le differenze tra le probabilità.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio.html#odds-ratio",
    "href": "chapters/mcmc/08_stan_odds_ratio.html#odds-ratio",
    "title": "54  Analisi bayesiana dell’odds-ratio",
    "section": "54.3 Odds Ratio",
    "text": "54.3 Odds Ratio\nQuando abbiamo una variabile di interesse espressa come proporzione, possiamo confrontare i gruppi utilizzando l’odds ratio. L’odds ratio rappresenta il rapporto tra gli odds di un evento in un gruppo e gli odds dello stesso evento in un secondo gruppo:\n\\[\nOR = \\frac{odds_1}{odds_2} = \\frac{p_1/(1-p_1)}{p_2/(1-p_2)}.\n\\]\nInterpretazione:\n\nOR = 1: l’appartenenza al gruppo non influenza il risultato;\nOR &gt; 1: l’appartenenza al gruppo specificato al numeratore dell’OR aumenta la probabilità dell’evento rispetto al gruppo specificato al denominatore;\nOR &lt; 1: l’appartenenza al gruppo specificato al numeratore dell’OR riduce la probabilità dell’evento rispetto al gruppo specificato al denominatore.\n\nL’odds ratio è particolarmente utile quando vogliamo confrontare due gruppi e vedere come l’appartenenza a uno di essi influenza la probabilità di un certo evento. Ad esempio, consideriamo uno studio psicologico in cui stiamo valutando l’efficacia di una terapia comportamentale per ridurre l’ansia. Possiamo suddividere i partecipanti allo studio in due gruppi: quelli che sono stati sottoposti al trattamento (gruppo di trattamento) e quelli che non sono stati sottoposti al trattamento (gruppo di controllo).\nCalcolando l’odds ratio tra il gruppo di trattamento e il gruppo di controllo, possiamo capire se la terapia ha aumentato o ridotto la probabilità di riduzione dell’ansia. Se l’odds ratio è maggiore di 1, significa che la terapia ha aumentato le probabilità di riduzione dell’ansia; se è inferiore a 1, significa che il trattamento ha ridotto le probabilità di riduzione dell’ansia. L’odds ratio ci fornisce quindi una misura dell’effetto della terapia rispetto al controllo.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio.html#logaritmo-dellodds-ratio",
    "href": "chapters/mcmc/08_stan_odds_ratio.html#logaritmo-dellodds-ratio",
    "title": "54  Analisi bayesiana dell’odds-ratio",
    "section": "54.4 Logaritmo dell’Odds Ratio",
    "text": "54.4 Logaritmo dell’Odds Ratio\nIl logaritmo dell’odds ratio è una trasformazione matematica molto utilizzata nell’analisi statistica, specialmente nella regressione logistica. Essa permette di rendere l’odds ratio interpretabile su una scala lineare, semplificando l’analisi e l’interpretazione dei risultati.\nLa formula per calcolare il logaritmo dell’odds ratio è la seguente:\n\\[\n\\text{logit}(OR) = \\log(OR) = \\log\\left(\\frac{odds_1}{odds_2}\\right).\n\\]\nIn altre parole, il logaritmo dell’odds ratio è il logaritmo naturale del rapporto tra gli odds di un evento nel primo gruppo e gli odds dello stesso evento nel secondo gruppo.\n\n54.4.1 Interpretazione\nL’interpretazione del logaritmo dell’odds ratio è più intuitiva rispetto all’odds ratio stesso. Una variazione di una unità nel logaritmo dell’odds ratio corrisponde a un cambiamento costante nell’odds ratio stesso.\nSe il logaritmo dell’odds ratio è positivo, significa che l’odds dell’evento nel primo gruppo è maggiore rispetto al secondo gruppo. Più il valore del logaritmo dell’odds ratio si avvicina a zero, più l’odds dell’evento nei due gruppi si avvicina a essere simile.\nSe, invece, il logaritmo dell’odds ratio è negativo, l’odds dell’evento nel primo gruppo è inferiore rispetto al secondo gruppo. Un valore di logaritmo dell’odds ratio vicino a zero indica che l’odds dell’evento è simile nei due gruppi.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio.html#analisi-bayesiana-delle-proporzioni",
    "href": "chapters/mcmc/08_stan_odds_ratio.html#analisi-bayesiana-delle-proporzioni",
    "title": "54  Analisi bayesiana dell’odds-ratio",
    "section": "54.5 Analisi bayesiana delle proporzioni",
    "text": "54.5 Analisi bayesiana delle proporzioni\nUna volta compresi i concetti di odds, odds ratio e logit, possiamo procedere all’analisi bayesiana delle proporzioni. Questo approccio consente di confrontare le proporzioni di due gruppi, ottenendo stime delle probabilità a posteriori e degli intervalli di credibilità.\nL’analisi bayesiana si basa sull’applicazione del teorema di Bayes per aggiornare le conoscenze a priori con l’evidenza fornita dai dati osservati. Questo permette di ottenere una distribuzione a posteriori delle quantità di interesse, come l’odds ratio.\nIn questo capitolo, analizzeremo un set di dati fittizio ispirato a un classico esperimento di etologia descritto da Hoffmann et al. (2022). Von Frisch (1914) ha voluto verificare se le api possiedono la visione dei colori confrontando il comportamento di due gruppi di api. L’esperimento si compone di una fase di addestramento e di una fase di test.\nNella fase di addestramento, le api del gruppo sperimentale vengono esposte a un disco blu e a un disco verde. Solo il disco blu è ricoperto di una soluzione zuccherina, molto appetita dalle api. Il gruppo di controllo, invece, non riceve alcun addestramento.\nNella fase di test, la soluzione zuccherina viene rimossa dal disco blu e si osserva il comportamento di entrambi i gruppi. Se le api del gruppo sperimentale hanno appreso che solo il disco blu contiene la soluzione zuccherina e sono in grado di distinguere tra il blu e il verde, dovrebbero preferire esplorare il disco blu piuttosto che quello verde durante la fase di test.\nIl ricercatore osserva che in 130 casi su 200, le api del gruppo sperimentale continuano ad avvicinarsi al disco blu dopo la rimozione della soluzione zuccherina. Le api del gruppo di controllo, che non sono state addestrate, si avvicinano al disco blu 100 volte su 200.\nPer confrontare il comportamento delle api nelle due condizioni, useremo l’odds ratio, così da confrontare le probabilità dell’evento critico (scelta del disco blu) tra i due gruppi.\nCalcoliamo la proporzione delle api che scelgono il disco blu nella condizione sperimentale:\n\\[\np_e = \\frac{130}{200} = 0.65\n\\]\nCalcoliamo gli odds nella condizione sperimentale:\n\\[\n\\text{odds}_e = \\frac{p_e}{1 - p_e} \\approx 1.86\n\\]\nQuesto ci indica che, nel gruppo sperimentale, ci sono circa 1.86 “successi” (ossia la scelta del disco blu) per ogni “insuccesso” (scelta del disco verde).\nProcediamo calcolando gli odds nella condizione di controllo:\n\\[\np_c = \\frac{100}{200} = 0.5\n\\]\n\\[\n\\text{odds}_c = \\frac{p_c}{1 - p_c} = 1.0\n\\]\nQuesto ci indica che, nel gruppo di controllo, il numero di “successi” e “insuccessi” è uguale.\nInfine, confrontiamo gli odds tra la condizione sperimentale e la condizione di controllo per calcolare l’odds ratio (OR):\n\\[\n\\text{OR} = \\frac{\\text{odds}_e}{\\text{odds}_c} = 1.86\n\\]\nGli odds di scelta del disco blu aumentano di circa 1.86 volte nel gruppo sperimentale rispetto al gruppo di controllo.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio.html#analisi-bayesiana-dellodds-ratio",
    "href": "chapters/mcmc/08_stan_odds_ratio.html#analisi-bayesiana-dellodds-ratio",
    "title": "54  Analisi bayesiana dell’odds-ratio",
    "section": "54.6 Analisi Bayesiana dell’Odds Ratio",
    "text": "54.6 Analisi Bayesiana dell’Odds Ratio\nNella nostra analisi, ci focalizziamo sull’Odds Ratio (OR) per valutare la differenza nel comportamento di scelta delle api nelle due condizioni dell’esperimento discusso. L’OR fornisce una stima puntuale della differenza basata sul nostro campione specifico. Tuttavia, per realizzare un’inferenza statistica robusta, è essenziale considerare l’incertezza nelle nostre stime, caratterizzata attraverso la distribuzione a posteriori.\nL’analisi bayesiana si basa sull’applicazione del teorema di Bayes per aggiornare le nostre conoscenze a priori con l’evidenza fornita dai dati osservati. Questo ci permette di ottenere una distribuzione a posteriori delle quantità di interesse, come l’odds ratio.\nPer affrontare questa questione, adottiamo un approccio bayesiano, costruendo la distribuzione a posteriori dell’OR. A partire da questa distribuzione, determiniamo un intervallo di credibilità del 90%, che rappresenta l’intervallo entro il quale, con il 90% di confidenza, possiamo aspettarci che ricada il vero valore dell’OR della popolazione.\nSe questo intervallo non include il valore 1, disponiamo di una solida evidenza (con un livello di credibilità del 90%) che la differenza tra le due condizioni esaminate corrisponde a una differenza reale nella popolazione, il che suggerisce che non si tratta di un artefatto generato dalla nostra incertezza. In altre parole, possiamo affermare con ragionevole certezza che le api dispongono di una visione cromatica.\nD’altro canto, se l’intervallo di credibilità includesse il valore 1, ciò indicherebbe che la differenza osservata nel nostro campione potrebbe non riflettere una differenza significativa nella popolazione generale, suggerendo che potrebbe essere una peculiarità del nostro campione specifico.\nL’analisi bayesiana e il calcolo dell’intervallo di credibilità verranno condotti utilizzando cmdstanpy, che ci permette di implementare modelli bayesiani in modo efficiente e rigoroso. Utilizzeremo una distribuzione a priori debolmente informativa per l’OR, in modo da non influenzare eccessivamente i risultati con assunzioni preliminari.\nUna volta ottenuta la distribuzione a posteriori dell’OR, possiamo calcolare il nostro intervallo di credibilità del 90%. Questo intervallo fornirà una rappresentazione della nostra incertezza riguardo il vero valore dell’OR nella popolazione. Se il nostro intervallo di credibilità esclude il valore 1, possiamo concludere che esiste una differenza significativa tra i due gruppi, confermando che le api possono distinguere i colori e preferire il disco blu.\nIn sintesi, l’approccio bayesiano non solo ci permette di stimare l’OR, ma anche di quantificare la nostra incertezza e fare inferenze più solide e informative sulla capacità delle api di distinguere tra colori.\n\n54.6.1 Likelihood\nLa likelihood del modello descrive la probabilità di osservare i dati dati i parametri del modello. Nel nostro caso, abbiamo due gruppi con eventi binomiali.\nPer il gruppo 1:\n\\[\ny_1 \\sim \\text{Binomiale}(N_1, \\theta_1).\n\\]\nPer il gruppo 2:\n\\[\ny_2 \\sim \\text{Binomiale}(N_2, \\theta_2).\n\\]\n\n\n54.6.2 Priors\nI priors del modello descrivono le nostre convinzioni iniziali sui parametri prima di osservare i dati. Nel nostro caso, i parametri \\(\\theta_1\\) e \\(\\theta_2\\) seguono una distribuzione Beta(2, 2).\nPer \\(\\theta_1\\):\n\\[\n\\theta_1 \\sim \\text{Beta}(2, 2).\n\\]\nPer \\(\\theta_2\\):\n\\[\n\\theta_2 \\sim \\text{Beta}(2, 2).\n\\]\nCompiliamo e stampiamo il modello Stan.\n\n# Path to the Stan file\nstan_file &lt;- here::here(\"stan\", \"odds-ratio.stan\")\n\n# Create a CmdStanModel object\nmod &lt;- cmdstan_model(stan_file)\n\n\nmod$print()\n#&gt; //  Comparison of two groups with Binomial\n#&gt; data {\n#&gt;   int&lt;lower=0&gt; N1; // number of experiments in group 1\n#&gt;   int&lt;lower=0&gt; y1; // number of events in group 1\n#&gt;   int&lt;lower=0&gt; N2; // number of experiments in group 2\n#&gt;   int&lt;lower=0&gt; y2; // number of events in group 2\n#&gt; }\n#&gt; parameters {\n#&gt;   real&lt;lower=0, upper=1&gt; theta1; // probability of event in group 1\n#&gt;   real&lt;lower=0, upper=1&gt; theta2; // probability of event in group 2\n#&gt; }\n#&gt; model {\n#&gt;   // model block creates the log density to be sampled\n#&gt;   theta1 ~ beta(2, 2); // prior\n#&gt;   theta2 ~ beta(2, 2); // prior\n#&gt;   y1 ~ binomial(N1, theta1); // observation model / likelihood\n#&gt;   y2 ~ binomial(N2, theta2); // observation model / likelihood\n#&gt; }\n#&gt; generated quantities {\n#&gt;   real oddsratio = (theta1 / (1 - theta1)) / (theta2 / (1 - theta2));\n#&gt; }\n\nNel blocco generated quantities, calcoliamo l’odds ratio:\n\\[\n\\text{oddsratio} = \\frac{\\theta_1 / (1 - \\theta_1)}{\\theta_2 / (1 - \\theta_2)}.\n\\]\nQuesto rapporto delle odds ci dà una misura della forza dell’associazione tra l’evento e i gruppi.\nIn sintesi, il modello bayesiano utilizza i dati osservati per aggiornare le nostre convinzioni iniziali sui parametri \\(\\theta_1\\) e \\(\\theta_2\\), fornendo una distribuzione a posteriori che riflette sia le informazioni a priori sia le evidenze empiriche.\nCreiamo un dizionario che contiene i dati.\n\nn1 &lt;- 200\ny1 &lt;- 130\nn2 &lt;- 200\ny2 &lt;- 100\n\nstan_data &lt;- list(\n  N1 = n1,\n  y1 = y1,\n  N2 = n2,\n  y2 = y2\n)\n\nEseguiamo il campionamento.\n\nfit &lt;- mod$sample(\n  data = stan_data,\n  seed = 123,\n  chains = 4,\n  parallel_chains = 4,\n  iter_sampling = 5000, \n  iter_warmup = 2000,\n  adapt_delta = 0.99,\n  show_messages = FALSE\n)\n\nEstraiamo la distribuzione a posteriori dell’odds ratio e generiamo un istogramma.\n\nor_draws &lt;- fit$draws(variables = \"oddsratio\", format = \"array\")\n\n\nmcmc_hist(\n  or_draws,\n  binwidth = NULL, # Automatically choose binwidth\n  freq = FALSE     # Plot density instead of frequencies\n) +\n  ggtitle(\"Istogramma della distribuzione a posteriori di OR\") +\n  xlab(\"Valori\") +\n  ylab(\"Frequenza\")\n#&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nLa distribuzione posteriore del rapporto degli odds è il modo più semplice e accurato per descrivere la differenza tra i due gruppi. Nel caso presente, notiamo che vi è un’elevata probabilità che la differenza tra i due gruppi sia affidabile e relativamente grande.\nUn sommario della distribuzione a posteriori dell’odds ratio si ottine nel modo seguente.\n\nfit$summary()\n#&gt; # A tibble: 4 × 10\n#&gt;   variable      mean   median     sd    mad       q5      q95  rhat ess_bulk\n#&gt;   &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 lp__      -275.    -275.    0.976  0.710  -277.    -274.     1.00    7085.\n#&gt; 2 theta1       0.647    0.648 0.0334 0.0341    0.592    0.701  1.00   10382.\n#&gt; 3 theta2       0.500    0.500 0.0345 0.0349    0.443    0.556  1.00   10901.\n#&gt; 4 oddsratio    1.88     1.84  0.385  0.374     1.32     2.57   1.00   10385.\n#&gt; # ℹ 1 more variable: ess_tail &lt;dbl&gt;\n\nPossiamo determinare la probabilità che il rapporto di probabilità (odds ratio) superi 1. Per farlo, è sufficiente analizzare gli 8000 campioni della distribuzione posteriore dell’odds ratio\n\ndim(or_draws)\n#&gt; [1] 5000    4    1\n\ne calcolare la proporzione di questi che presenta un valore maggiore di 1:\n\nfit$summary(\"oddsratio\", pr_gt_one = ~ mean(. &gt; 1.0))\n#&gt; # A tibble: 1 × 2\n#&gt;   variable  pr_gt_one\n#&gt;   &lt;chr&gt;         &lt;dbl&gt;\n#&gt; 1 oddsratio     0.999",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio.html#diagnostica-delle-catene-markoviane",
    "href": "chapters/mcmc/08_stan_odds_ratio.html#diagnostica-delle-catene-markoviane",
    "title": "54  Analisi bayesiana dell’odds-ratio",
    "section": "54.7 Diagnostica delle catene markoviane",
    "text": "54.7 Diagnostica delle catene markoviane\nPrima di esaminare i risultati, eseguiamo la diagnostica delle catene markoviane.\n\n54.7.1 Mixing\nIl trace plot precedente dimostra un buon mixing. Questo è evidenza che il campionamento MCMC ha raggiunto uno stato stazionario.\n\nmcmc_trace(or_draws) +\n  ggtitle(\"Trace Plot for 'oddsratio'\")\n\n\n\n\n\n\n\n\n\n\n54.7.2 Numerosità campionaria effettiva\nQuando si utilizzano metodi di campionamento MCMC, è ragionevole chiedersi se un particolare campione estratto dalla distribuzione a posteriori sia sufficientemente grande per calcolare con sicurezza le quantità di interesse, come una media o un HDI. Questo non è qualcosa che possiamo rispondere direttamente guardando solo il numero di punti della catena MCMC, e il motivo è che i campioni ottenuti dai metodi MCMC hanno un certo grado di autocorrelazione, quindi la quantità effettiva di informazioni contenute in quel campione sarà inferiore a quella che otterremmo da un campione iid della stessa dimensione. Possiamo pensare alla dimensione del campione effettivo (ESS) come a un stimatore che tiene conto dell’autocorrelazione e fornisce il numero di estrazioni che avremmo se il nostro campione fosse effettivamente iid.\nPer le catene buone, solitamente, il valore della dimensione del campione effettivo sarà inferiore al numero di campioni. Ma l’ESS può essere in realtà più grande del numero di campioni estratti. Quando si utilizza il campionatore NUTS, valori di ESS maggiori del numero totale di campioni possono verificarsi per parametri le cui distribuzioni posteriori sono vicine alla Gaussiana e che sono quasi indipendenti da altri parametri nel modello.\nNell’output di PyCM si considera ESS_BULK. Un euristica è che deve essere almeno uguale a 400. Nel caso presente questo si verifica, quindi il valore ESS_BULK non fornisce alcuna evidenza di cattivo mixing.\n\n\n54.7.3 R hat\nIn condizioni molto generali, i metodi di Markov chain Monte Carlo hanno garanzie teoriche che otterranno la risposta corretta indipendentemente dal punto di partenza. Sfortunatamente, tali garanzie sono valide solo per campioni infiniti. Quindi, nella pratica, abbiamo bisogno di modi per stimare la convergenza per campioni finiti. Un’idea diffusa è quella di generare più di una catena, partendo da punti molto diversi e quindi controllare le catene risultanti per vedere se sembrano simili tra loro. Questa nozione intuitiva può essere formalizzata in un indicatore numerico noto come R-hat. Esistono molte versioni di questo stimatore, poiché è stato perfezionato nel corso degli anni. In origine il R-hat veniva interpretato come la sovrastima della varianza dovuta al campionamento MCMC finito. Ciò significa che se si continua a campionare all’infinito si dovrebbe ottenere una riduzione della varianza della stima di un fattore R-hat. E quindi il nome “fattore di riduzione potenziale della scala” (potential scale reduction factor), con il valore target di 1 che significa che aumentare il numero di campioni non ridurrà ulteriormente la varianza della stima. Tuttavia, nella pratica è meglio pensarlo solo come uno strumento diagnostico senza cercare di sovra-interpretarlo.\nL’R-hat per il parametro theta viene calcolato come la deviazione standard di tutti i campioni di theta, ovvero includendo tutte le catene insieme, diviso per la radice quadratica media delle deviazioni standard separate all’interno della catena. Il calcolo effettivo è un po’ più complesso ma l’idea generale è questa. Idealmente dovremmo ottenere un valore di 1, poiché la varianza tra le catene dovrebbe essere la stessa della varianza all’interno della catena. Da un punto di vista pratico, valori di R-hat inferiori a 1.1 sono considerati sicuri.\nNel caso presente questo si verifica. Possiamo ottenere R hat nel modo seguente:\n\n# Extract the summary including R-hat\nsummary &lt;- fit$summary()\n\n# Extract R-hat values\nrhat_values &lt;- summary$rhat\n\n# Print R-hat values\nprint(rhat_values)\n#&gt; [1] 1.000647 1.000385 1.000449 1.000297\n\nIl valore di \\(\\hat{R}\\), al massimo, raggiunge il valore di 1.001. Essendo il valore molto simile a 1 nel caso presente, possiamo dire che non ci sono evidenza di assenza di convergenza.\n\n\n54.7.4 Errore standard di Monte Carlo\nQuando si utilizzano metodi MCMC introduciamo un ulteriore livello di incertezza poiché stiamo approssimando la posteriore con un numero finito di campioni. Possiamo stimare la quantità di errore introdotta utilizzando l’errore standard di Monte Carlo (MCSE). L’MCSE tiene conto del fatto che i campioni non sono veramente indipendenti l’uno dall’altro e sono in realtà calcolati dall’ESS. Mentre i valori di ESS e R-hat sono indipendenti dalla scala dei parametri, la statistica MCSE non lo è. Se vogliamo riportare il valore di un parametro stimato al secondo decimale, dobbiamo essere sicuri che MCSE sia al di sotto del secondo decimale altrimenti, finiremo, erroneamente, per riportare una precisione superiore a quella che abbiamo realmente. Dovremmo controllare MCSE solo una volta che siamo sicuri che ESS sia abbastanza alto e R-hat sia abbastanza basso; altrimenti, MCSE non è utile.\nNel nostro caso il MCSE è sufficientemente piccolo.\n\n# Extract posterior draws\ndraws &lt;- fit$draws()\n\n# Summarize the draws, including MCSE\nsummary &lt;- summarize_draws(draws, \"mean\", \"mcse_mean\")\n\n# Print the summary including MCSE\nprint(summary)\n#&gt; # A tibble: 4 × 3\n#&gt;   variable      mean mcse_mean\n#&gt;   &lt;chr&gt;        &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 lp__      -275.     0.0120  \n#&gt; 2 theta1       0.647  0.000328\n#&gt; 3 theta2       0.500  0.000331\n#&gt; 4 oddsratio    1.88   0.00381\n\nL’errore standard di Monte Carlo ci informa della precisione della stima ottenuta usando il metodo MCMC. Non possiamo riportare una precisione dei risultati maggiore di quella indicata dalla MCSE. Pertanto, per il caso presente relativo all’Odds Ratio (OR), possiamo affermare che la precisione massima raggiungibile è limitata a due decimali.\n\n\n54.7.5 Autocorrelazione\nL’autocorrelazione riduce la quantità effettiva di informazioni contenute in un campione e quindi è qualcosa che vogliamo mantenere al minimo. Possiamo ispezionare direttamente l’autocorrelazione con az.plot_autocorr.\n\n# Extract posterior draws for 'oddsratio'\noddsratio_draws &lt;- fit$draws(variables = \"oddsratio\", format = \"matrix\")\n\n# Create an autocorrelation plot\nmcmc_acf(oddsratio_draws) +\n  ggtitle(\"Autocorrelation Plot for 'oddsratio'\")\n\n\n\n\n\n\n\n\n\n\n54.7.6 Rank Plots\nI grafici dei ranghi sono un altro strumento diagnostico visivo che possiamo utilizzare per confrontare il comportamento del campionamento sia all’interno che tra le catene. I grafici dei ranghi, in parole semplici, sono istogrammi dei campioni della distribuzione a posteriori espressi in termini di ranghi. Nei grafici dei ranghi, i ranghi sono calcolati combinando prima tutte le catene ma poi rappresentando i risultati separatamente per ogni catena. Se tutte le catene stimano la stessa distribuzione, ci aspettiamo che i ranghi abbiano una distribuzione uniforme. Inoltre, se i grafici dei ranghi di tutte le catene sembrano simili, ciò indica un buon mix delle catene.\nPossiamo ottenere i grafici dei ranghi con az.plot_rank.\n\nmcmc_rank_hist(oddsratio_draws) +\n  ggtitle(\"Rank Histogram for 'oddsratio'\")\n\n\n\n\n\n\n\n\nPossiamo vedere nella figura che i ranghi sono molto simili ad una distribuzione uniforme e che tutte le catene sono simili tra loro senza alcuno scostamento distintivo.\n\n\n54.7.7 Divergenza\nPer diagnosticare il funzionamento di un campionatore, abbiamo finora analizzato i campioni generati. Un altro approccio fondamentale consiste nel monitorare i meccanismi interni del metodo di campionamento. Una delle diagnosi più importanti in questo contesto è rappresentata dal concetto di divergenza, particolarmente rilevante nei metodi Hamiltonian Monte Carlo (HMC). Le divergenze (o transizioni divergenti) sono un segnale sensibile che indica potenziali problemi nella geometria del modello o nel campionamento. Queste diagnosi sono complementari agli altri controlli descritti in precedenza.\n\n54.7.7.1 Che cosa sono le transizioni divergenti?\nLe transizioni divergenti si verificano quando il metodo HMC non riesce a esplorare efficacemente la distribuzione a posteriori. Ciò accade, ad esempio, in presenza di geometrie complesse come regioni strette e allungate della distribuzione, dove il campionatore fatica a seguire il gradiente. Le transizioni divergenti sono quindi un’indicazione che il modello potrebbe necessitare di una riformulazione o di parametri di campionamento più adeguati (come un maggiore adapt_delta).\nCmdStan consente di rilevare queste transizioni e riporta il numero di divergenze per ciascuna catena durante il campionamento. Un risultato ottimale è zero divergenze, poiché ciò indica che il campionatore ha esplorato la distribuzione senza difficoltà.\n\n\n54.7.7.2 Diagnosi delle divergenze\nPer eseguire questa diagnosi, possiamo utilizzare il metodo fit$diagnostic_summary(), che restituisce un riepilogo dei principali indicatori diagnostici. Vediamo i valori restituiti nel caso specifico:\n\nfit$diagnostic_summary()\n#&gt; $num_divergent\n#&gt; [1] 0 0 0 0\n#&gt; \n#&gt; $num_max_treedepth\n#&gt; [1] 0 0 0 0\n#&gt; \n#&gt; $ebfmi\n#&gt; [1] 1.035259 1.051684 1.005021 1.068711\n\nI valori diagnostici restituiti sono i seguenti:\n\n$num_divergent:\n\nQuesto valore indica il numero di transizioni divergenti per ciascuna catena.\nCaso corrente: Tutte le catene riportano 0 transizioni divergenti. Ciò significa che il campionatore è stato in grado di esplorare la distribuzione a posteriori senza difficoltà, suggerendo che il modello è ben specificato e che non ci sono problemi nella geometria della distribuzione.\n\n$num_max_treedepth:\n\nQuesto valore rappresenta il numero di volte in cui una catena ha raggiunto la massima profondità dell’albero durante il campionamento NUTS (No-U-Turn Sampler).\nRaggiungere frequentemente la profondità massima potrebbe indicare inefficienza nel campionamento.\nCaso corrente: Nessuna catena ha raggiunto la massima profondità, il che significa che il campionatore è stato efficiente e non sono necessarie modifiche al parametro max_treedepth.\n\n$ebfmi (Energy Bayesian Fraction of Missing Information):\n\nL’E-BFMI misura l’efficienza del campionamento in relazione all’energia Hamiltoniana. Valori inferiori a 0.3 indicano problemi di esplorazione della distribuzione a posteriori.\nCaso corrente: Tutte le catene presentano valori di E-BFMI superiori a 1, indicando un’ottima esplorazione della distribuzione e l’assenza di problemi nella geometria del modello.\n\n\nIn sintesi, i risultati diagnostici indicano che il campionamento MCMC è stato eseguito correttamente e senza problemi:\n\n0 transizioni divergenti: Il modello è ben specificato e la distribuzione a posteriori è stata esplorata in modo efficace.\n0 superamenti della profondità dell’albero: Il campionatore è stato efficiente.\nE-BFMI &gt; 1: L’energia Hamiltoniana è stata esplorata in modo ottimale, senza segni di inefficienza.\n\nQuesti risultati ci consentono di procedere con fiducia nell’analisi dei risultati, poiché non vi sono evidenze di problematiche legate al campionamento o alla geometria del modello.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio.html#interpretazione-dei-risultati",
    "href": "chapters/mcmc/08_stan_odds_ratio.html#interpretazione-dei-risultati",
    "title": "54  Analisi bayesiana dell’odds-ratio",
    "section": "54.8 Interpretazione dei Risultati",
    "text": "54.8 Interpretazione dei Risultati\nI risultati della diagnosi delle catene Markoviane non evidenziano problematiche relative alla convergenza dell’algoritmo né discrepanze nel modello statistico adottato, permettendoci di procedere con l’analisi dei risultati ottenuti.\nL’analisi ha determinato un valore a posteriori per l’OR di 1.88, accompagnato da un intervallo di credibilità del 94% compreso tra 1.20 e 2.60. Poiché questo intervallo non include il valore 1, possiamo affermare, con un grado di certezza del 94%, che il comportamento delle api differisce nelle due condizioni sperimentali. Questo fornisce evidenza a supporto dell’ipotesi che le api dispongano di una visione cromatica.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio.html#riflessioni-conclusive",
    "href": "chapters/mcmc/08_stan_odds_ratio.html#riflessioni-conclusive",
    "title": "54  Analisi bayesiana dell’odds-ratio",
    "section": "54.9 Riflessioni Conclusive",
    "text": "54.9 Riflessioni Conclusive\nIn questo capitolo, abbiamo esplorato come applicare un approccio bayesiano per analizzare e interpretare l’odds ratio tra due proporzioni. Attraverso l’uso del modello statistico, siamo stati in grado di stimare la distribuzione a posteriori dell’odds ratio e di calcolare l’intervallo di credibilità.\nI risultati ottenuti, supportati da un controllo diagnostico delle catene Markoviane, indicano che la differenza osservata tra i due gruppi è credibile e supportata dai dati. L’odds ratio stimato e il relativo intervallo di credibilità escludono il valore 1, suggerendo una differenza coerente tra i gruppi analizzati. L’approccio bayesiano si è dimostrato efficace, non solo per stimare i parametri di interesse, ma anche per quantificare l’incertezza associata a tali stime.\nIn sintesi, l’analisi bayesiana dell’odds ratio ha permesso di rispondere alla domanda di ricerca, confermando che le api mostrano comportamenti coerenti con una capacità di distinzione cromatica. L’approccio presentato in questo capitolo può essere esteso ad altre applicazioni, offrendo una struttura versatile per il confronto tra proporzioni in diversi contesti sperimentali.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/08_stan_odds_ratio.html#informazioni-sullambiente-di-sviluppo",
    "title": "54  Analisi bayesiana dell’odds-ratio",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] posterior_1.6.0     cmdstanr_0.8.1.9000 MASS_7.3-61        \n#&gt;  [4] viridis_0.6.5       viridisLite_0.4.2   ggpubr_0.6.0       \n#&gt;  [7] ggExtra_0.10.1      gridExtra_2.3       patchwork_1.3.0    \n#&gt; [10] bayesplot_1.11.1    psych_2.4.6.26      scales_1.3.0       \n#&gt; [13] markdown_1.13       knitr_1.49          lubridate_1.9.3    \n#&gt; [16] forcats_1.0.0       stringr_1.5.1       dplyr_1.1.4        \n#&gt; [19] purrr_1.0.2         readr_2.1.5         tidyr_1.3.1        \n#&gt; [22] tibble_3.2.1        ggplot2_3.5.1       tidyverse_2.0.0    \n#&gt; [25] rio_1.2.3           here_1.0.1         \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1     farver_2.1.2         fastmap_1.2.0       \n#&gt;  [4] tensorA_0.36.2.1     pacman_0.5.1         promises_1.3.2      \n#&gt;  [7] digest_0.6.37        timechange_0.3.0     mime_0.12           \n#&gt; [10] lifecycle_1.0.4      processx_3.8.4       magrittr_2.0.3      \n#&gt; [13] compiler_4.4.2       rlang_1.1.4          tools_4.4.2         \n#&gt; [16] utf8_1.2.4           yaml_2.3.10          data.table_1.16.2   \n#&gt; [19] ggsignif_0.6.4       labeling_0.4.3       htmlwidgets_1.6.4   \n#&gt; [22] mnormt_2.1.1         plyr_1.8.9           abind_1.4-8         \n#&gt; [25] miniUI_0.1.1.1       withr_3.0.2          grid_4.4.2          \n#&gt; [28] fansi_1.0.6          xtable_1.8-4         colorspace_2.1-1    \n#&gt; [31] cli_3.6.3            rmarkdown_2.29       generics_0.1.3      \n#&gt; [34] reshape2_1.4.4       tzdb_0.4.0           parallel_4.4.2      \n#&gt; [37] matrixStats_1.4.1    vctrs_0.6.5          jsonlite_1.8.9      \n#&gt; [40] carData_3.0-5        car_3.1-3            hms_1.1.3           \n#&gt; [43] rstatix_0.7.2        Formula_1.2-5        glue_1.8.0          \n#&gt; [46] ps_1.8.1             distributional_0.5.0 stringi_1.8.4       \n#&gt; [49] gtable_0.3.6         later_1.4.1          munsell_0.5.1       \n#&gt; [52] pillar_1.9.0         htmltools_0.5.8.1    R6_2.5.1            \n#&gt; [55] rprojroot_2.0.4      evaluate_1.0.1       shiny_1.9.1         \n#&gt; [58] lattice_0.22-6       backports_1.5.0      broom_1.0.7         \n#&gt; [61] httpuv_1.6.15        Rcpp_1.0.13-1        nlme_3.1-166        \n#&gt; [64] checkmate_2.3.2      xfun_0.49            pkgconfig_2.0.3",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio.html#bibliografia",
    "href": "chapters/mcmc/08_stan_odds_ratio.html#bibliografia",
    "title": "54  Analisi bayesiana dell’odds-ratio",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nHoffmann, T., Hofman, A., & Wagenmakers, E.-J. (2022). Bayesian tests of two proportions: A tutorial with R and JASP. Methodology, 18(4), 239–277.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/11_stan_poisson_model_1.html",
    "href": "chapters/mcmc/11_stan_poisson_model_1.html",
    "title": "55  Modello di Poisson (1)",
    "section": "",
    "text": "55.1 Introduzione\nNel Capitolo 47, abbiamo analizzato un problema di inferenza bayesiana utilizzando il modello gamma-poisson. La distribuzione a posteriori è stata calcolata sia tramite il metodo basato su griglia, sia attraverso la derivazione analitica, sfruttando la proprietà di coniugatezza tra la distribuzione di Poisson (verosimiglianza) e la distribuzione Gamma (priori). In questo capitolo, introduciamo un approccio più generale e flessibile: utilizzeremo Stan, un linguaggio per il calcolo probabilistico, per affrontare lo stesso problema.\nStan consente di modellare distribuzioni complesse, eseguire campionamenti MCMC (Markov Chain Monte Carlo) e ottenere stime robuste dei parametri. A differenza dell’approccio analitico, l’uso di Stan è particolarmente utile quando la coniugatezza non è garantita o il modello diventa troppo complesso per una soluzione esatta.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Modello di Poisson (1)</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/11_stan_poisson_model_1.html#modello-di-poisson-con-stan",
    "href": "chapters/mcmc/11_stan_poisson_model_1.html#modello-di-poisson-con-stan",
    "title": "55  Modello di Poisson (1)",
    "section": "55.2 Modello di Poisson con Stan",
    "text": "55.2 Modello di Poisson con Stan\nRiconsideriamo il problema già discusso nel Capitolo 47. I dati a disposizione rappresentano una sequenza di osservazioni di un processo di conteggio, per esempio il numero di eventi (compulsioni, visite o chiamate) registrati in un determinato intervallo di tempo. Le osservazioni sono le seguenti:\n\ny &lt;- c(2, 1, 3, 2, 2, 1, 1, 1)\n\nQuesta serie di dati rappresenta \\(N = 8\\) osservazioni del numero di eventi in otto intervalli di tempo. Il nostro obiettivo è stimare il tasso medio di occorrenza, \\(\\lambda\\), utilizzando un approccio bayesiano.\nPer modellare il processo, assumiamo che le osservazioni seguano una distribuzione di Poisson con parametro \\(\\lambda\\), il tasso medio di occorrenza per unità di tempo. La distribuzione di Poisson è definita come:\n\\[\nP(y_i | \\lambda) = \\frac{\\lambda^{y_i} e^{-\\lambda}}{y_i!}, \\quad y_i \\in \\mathbb{N}, \\ \\lambda &gt; 0\n\\]\nA priori, assumiamo che il parametro \\(\\lambda\\) segua una distribuzione Gamma, scelta per la sua coniugatezza rispetto alla Poisson. La distribuzione Gamma è definita da due parametri, \\(\\alpha_{\\text{prior}}\\) e \\(\\beta_{\\text{prior}}\\), che modellano rispettivamente il tasso medio e la dispersione della distribuzione:\n\\[\np(\\lambda) = \\frac{\\beta_{\\text{prior}}^{\\alpha_{\\text{prior}}}}{\\Gamma(\\alpha_{\\text{prior}})} \\lambda^{\\alpha_{\\text{prior}} - 1} e^{-\\beta_{\\text{prior}} \\lambda}, \\quad \\lambda &gt; 0\n\\]\nPer il nostro modello, scegliamo:\n\n\\(\\alpha_{\\text{prior}} = 9\\): rappresenta la “forza” della nostra conoscenza a priori.\n\\(\\beta_{\\text{prior}} = 2\\): rappresenta il livello di concentrazione dei valori attesi attorno a un tasso medio.\n\n\n55.2.1 Specifica del Modello in Stan\nIn Stan, definiamo il modello con una sezione di dati, una sezione per i parametri, e una per il modello stesso:\ndata {\n  int&lt;lower=0&gt; N; // numero di osservazioni\n  array[N] int&lt;lower=0&gt; y; // dati osservati\n  real&lt;lower=0&gt; alpha_prior; // parametro alpha della priori Gamma\n  real&lt;lower=0&gt; beta_prior; // parametro beta della priori Gamma\n}\nparameters {\n  real&lt;lower=0&gt; lambda; // parametro di interesse\n}\nmodel {\n  // Priori\n  lambda ~ gamma(alpha_prior, beta_prior);\n  \n  // Verosimiglianza\n  y ~ poisson(lambda);\n}\ngenerated quantities {\n  real alpha_post = alpha_prior + sum(y);\n  real beta_post = beta_prior + N;\n}\n\n\n55.2.2 Creazione del Modello in R\nPer iniziare, utilizziamo cmdstanr per compilare il modello Stan. Il file .stan è salvato nella directory del progetto.\n\nstan_file &lt;- here::here(\"stan\", \"gamma_poisson_mcmc.stan\")\nmod &lt;- cmdstan_model(stan_file)\n\nA questo punto, il modello è pronto per l’esecuzione con i dati preparati, che includono il numero di osservazioni \\(N\\), i dati stessi \\(y\\), e i parametri della distribuzione a priori.\nSistemiamo i dati nel formato richiesto da Stan.\n\n# Preparazione dei dati in R\nN &lt;- length(y)\nalpha_prior &lt;- 9\nbeta_prior &lt;- 2\n\n# Preparazione dei dati per Stan\nstan_data &lt;- list(N = N, y = y, alpha_prior = alpha_prior, beta_prior = beta_prior)\n\n# Stampa del contenuto di stan_data\nprint(stan_data)\n#&gt; $N\n#&gt; [1] 8\n#&gt; \n#&gt; $y\n#&gt; [1] 2 1 3 2 2 1 1 1\n#&gt; \n#&gt; $alpha_prior\n#&gt; [1] 9\n#&gt; \n#&gt; $beta_prior\n#&gt; [1] 2\n\n\n55.2.2.1 Campionamento MCMC\nEseguiamo il campionamento.\n\nfit &lt;- mod$sample(\n  data = stan_data,\n  seed = 123,\n  chains = 4,\n  parallel_chains = 4,\n  iter_sampling = 3000, \n  iter_warmup = 2000,\n  # adapt_delta = 0.99,\n  show_messages = FALSE\n)\n\n\n\n55.2.2.2 Distribuzione a Posteriori\nEstraiamo un campione casuale dalla distribuzione a posteriori di lambda.\n\nlambda_samples &lt;- fit$draws(variables = \"lambda\", format = \"array\")\n\nCalcoliamo i parametri della Gamma a posteriori teorica.\n\nalpha_post &lt;- alpha_prior + sum(y)\nbeta_post &lt;- beta_prior + N\n\nCreiamo un istogramma con i campioni della distribuzione a posteriori di \\(\\lambda\\) e sovrapposta la densità teorica della distribuzione a posteriori.\n\nlambda_samples &lt;- as.vector(lambda_samples)\n\n# Create a dataframe with lambda_samples\nlambda_samples_df &lt;- data.frame(lambda_samples = lambda_samples)\n\n# Generate the plot\nggplot(lambda_samples_df, aes(x = lambda_samples)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 50, fill = \"blue\", alpha = 0.7) +\n  stat_function(\n    fun = function(x) dgamma(x, shape = alpha_post, rate = beta_post),\n    color = \"red\",\n    linewidth = 1.2\n  ) +\n  ggtitle(\"Distribuzione a posteriori di lambda\") +\n  xlab(\"lambda\") +\n  ylab(\"Densità\") +\n  annotate(\n    \"text\",\n    x = max(lambda_samples) * 0.95,\n    y = max(dgamma(lambda_samples, shape = alpha_post, rate = beta_post)) * 0.95,\n    label = paste0(\"alpha_post = \", round(alpha_post, 2), \"\\n\",\n                   \"beta_post = \", round(beta_post, 2)),\n    hjust = 1,\n    vjust = 1,\n    size = 5,\n    color = \"black\"\n  ) \n\n\n\n\n\n\n\n\nOtteniamo un sommario della distribuzione a posteriori dei parametri del modello.\n\nfit$summary()\n#&gt; # A tibble: 4 × 10\n#&gt;   variable    mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 lp__       -5.16  -4.88 0.703 0.313 -6.53 -4.66  1.00    5832.    7229.\n#&gt; 2 lambda      2.20   2.17 0.469 0.465  1.50  3.04  1.00    4667.    6266.\n#&gt; 3 alpha_post 22     22    0     0     22    22    NA         NA       NA \n#&gt; 4 beta_post  10     10    0     0     10    10    NA         NA       NA\n\nGeneriamo l’intervallo di credibilità al 94% per la distribuzione a posteriori del parametro lambda.\n\n# Calcolo dell'intervallo di credibilità al 94%\ncredibility_interval &lt;- quantile(lambda_samples, probs = c(0.03, 0.97))\n\n# Visualizzazione dell'intervallo\nprint(credibility_interval)\n#&gt;       3%      97% \n#&gt; 1.422154 3.177465\n\nIn sintesi, analizzando i dati disponibili e utilizzando una distribuzione a priori Gamma(9, 2), possiamo affermare con un grado di certezza soggettivo del 94% che il tasso stimato di occorrenza dell’evento considerato sia di 2.2 compulsioni all’ora, con un intervallo di credibilità compreso tra 1.4 e 3.1.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Modello di Poisson (1)</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/11_stan_poisson_model_1.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/11_stan_poisson_model_1.html#informazioni-sullambiente-di-sviluppo",
    "title": "55  Modello di Poisson (1)",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] posterior_1.6.0     cmdstanr_0.8.1.9000 MASS_7.3-61        \n#&gt;  [4] viridis_0.6.5       viridisLite_0.4.2   ggpubr_0.6.0       \n#&gt;  [7] ggExtra_0.10.1      gridExtra_2.3       patchwork_1.3.0    \n#&gt; [10] bayesplot_1.11.1    psych_2.4.6.26      scales_1.3.0       \n#&gt; [13] markdown_1.13       knitr_1.49          lubridate_1.9.3    \n#&gt; [16] forcats_1.0.0       stringr_1.5.1       dplyr_1.1.4        \n#&gt; [19] purrr_1.0.2         readr_2.1.5         tidyr_1.3.1        \n#&gt; [22] tibble_3.2.1        ggplot2_3.5.1       tidyverse_2.0.0    \n#&gt; [25] rio_1.2.3           here_1.0.1         \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tensorA_0.36.2.1     gtable_0.3.6         xfun_0.49           \n#&gt;  [4] htmlwidgets_1.6.4    processx_3.8.4       rstatix_0.7.2       \n#&gt;  [7] lattice_0.22-6       tzdb_0.4.0           ps_1.8.1            \n#&gt; [10] vctrs_0.6.5          tools_4.4.2          generics_0.1.3      \n#&gt; [13] parallel_4.4.2       fansi_1.0.6          pacman_0.5.1        \n#&gt; [16] pkgconfig_2.0.3      data.table_1.16.2    checkmate_2.3.2     \n#&gt; [19] distributional_0.5.0 lifecycle_1.0.4      compiler_4.4.2      \n#&gt; [22] farver_2.1.2         munsell_0.5.1        mnormt_2.1.1        \n#&gt; [25] carData_3.0-5        httpuv_1.6.15        htmltools_0.5.8.1   \n#&gt; [28] yaml_2.3.10          Formula_1.2-5        car_3.1-3           \n#&gt; [31] pillar_1.9.0         later_1.4.1          abind_1.4-8         \n#&gt; [34] nlme_3.1-166         mime_0.12            tidyselect_1.2.1    \n#&gt; [37] digest_0.6.37        stringi_1.8.4        labeling_0.4.3      \n#&gt; [40] rprojroot_2.0.4      fastmap_1.2.0        grid_4.4.2          \n#&gt; [43] colorspace_2.1-1     cli_3.6.3            magrittr_2.0.3      \n#&gt; [46] utf8_1.2.4           broom_1.0.7          withr_3.0.2         \n#&gt; [49] backports_1.5.0      promises_1.3.2       timechange_0.3.0    \n#&gt; [52] rmarkdown_2.29       matrixStats_1.4.1    ggsignif_0.6.4      \n#&gt; [55] hms_1.1.3            shiny_1.9.1          evaluate_1.0.1      \n#&gt; [58] miniUI_0.1.1.1       rlang_1.1.4          Rcpp_1.0.13-1       \n#&gt; [61] xtable_1.8-4         glue_1.8.0           jsonlite_1.8.9      \n#&gt; [64] R6_2.5.1",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Modello di Poisson (1)</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/18_cmdstanr_intro.html",
    "href": "chapters/mcmc/18_cmdstanr_intro.html",
    "title": "56  Introduzione a CmdStanR",
    "section": "",
    "text": "56.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nRiprendiamo l’analisi dei dati fittizi di un compito Go/No-go, in cui sono state registrate 6 risposte corrette su 9 prove, già discussa in precedenza. In questa sezione, utilizzeremo il pacchetto cmdstanr in R, invece di cmdstanpy in Python, per eseguire l’analisi. L’obiettivo di questo capitolo è mostrare come utilizzare CmdStan attraverso il linguaggio R, offrendo un’alternativa all’uso di Python.\nIn R, i dati vengono salvati in una lista, che equivale a un dizionario in Python.\ndata_list &lt;- list(\n    \"N\" = 9,\n    \"y\" = 6\n)\nSuccessivamente, specifichiamo il percorso del file contenente lo script Stan. È importante notare che lo script Stan rimane identico indipendentemente dall’interfaccia utilizzata, sia essa R o Python.\nfile &lt;- file.path(here::here(\"stan\", \"go_nogo_model.stan\"))\nfile\n\n[1] \"/Users/corradocaudek/_repositories/psicometria-r/stan/go_nogo_model.stan\"",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>Introduzione a CmdStanR</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/18_cmdstanr_intro.html#compilazione-del-modello",
    "href": "chapters/mcmc/18_cmdstanr_intro.html#compilazione-del-modello",
    "title": "56  Introduzione a CmdStanR",
    "section": "56.2 Compilazione del modello",
    "text": "56.2 Compilazione del modello\nPer compilare il modello, utilizziamo la funzione cmdstan_model(), che crea un nuovo oggetto CmdStanModel a partire da un file contenente un programma Stan.\n\nmod &lt;- cmdstan_model(file)\n\nDopo aver compilato il modello, possiamo stamparne le informazioni.\n\nmod$print()\n\ndata {\n  int&lt;lower=1&gt; N;\n  int&lt;lower=0&gt; y;\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; p;\n}\nmodel {\n  y ~ binomial(N, p); // Likelihood\n  p ~ beta(1, 1); // Prior\n}\ngenerated quantities {\n  int&lt;lower=0, upper=1&gt; p_gt_chance = p &gt; 0.5;\n}",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>Introduzione a CmdStanR</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/18_cmdstanr_intro.html#esecuzione-dellalgoritmo-mcmc",
    "href": "chapters/mcmc/18_cmdstanr_intro.html#esecuzione-dellalgoritmo-mcmc",
    "title": "56  Introduzione a CmdStanR",
    "section": "56.3 Esecuzione dell’algoritmo MCMC",
    "text": "56.3 Esecuzione dell’algoritmo MCMC\nIl metodo $sample() sugli oggetti CmdStanModel esegue l’algoritmo MCMC predefinito di Stan. L’argomento data accetta una lista di oggetti R con nomi specificati.\n\nfit &lt;- mod$sample(\n    data = data_list,\n    seed = 123,\n    chains = 4,\n    parallel_chains = 4\n)",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>Introduzione a CmdStanR</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/18_cmdstanr_intro.html#statistiche-riassuntive-del-posterior",
    "href": "chapters/mcmc/18_cmdstanr_intro.html#statistiche-riassuntive-del-posterior",
    "title": "56  Introduzione a CmdStanR",
    "section": "56.4 Statistiche riassuntive del posterior",
    "text": "56.4 Statistiche riassuntive del posterior\nIl metodo $summary() chiama la funzione summarise_draws() dal pacchetto posterior. Il primo argomento specifica le variabili da riassumere, e gli argomenti successivi sono passati a posterior::summarise_draws() per specificare quali statistiche calcolare, l’uso di più core, ecc.\n\nfit$summary(variables = c(\"p\"))\n\n# A tibble: 1 × 10\n  variable  mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n  &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 p        0.636  0.647 0.141 0.148 0.389 0.854  1.00    1372.    1351.\n\n\nÈ possibile utilizzare una formula per riassumere funzioni arbitrarie, come ad esempio la probabilità che \\(p\\) sia minore o uguale a 0.5.\n\nfit$summary(\"p\", pr_lt_half = ~ mean(. &lt;= 0.5))\n\n# A tibble: 1 × 2\n  variable pr_lt_half\n  &lt;chr&gt;         &lt;dbl&gt;\n1 p             0.176",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>Introduzione a CmdStanR</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/18_cmdstanr_intro.html#estrazione-dei-campioni-posteriori",
    "href": "chapters/mcmc/18_cmdstanr_intro.html#estrazione-dei-campioni-posteriori",
    "title": "56  Introduzione a CmdStanR",
    "section": "56.5 Estrazione dei campioni posteriori",
    "text": "56.5 Estrazione dei campioni posteriori\n\n56.5.1 Estrazione dei campioni\nIl metodo $draws() può essere utilizzato per estrarre i campioni posteriori in formati supportati dal pacchetto posterior. Qui dimostriamo i formati draws_array e draws_df.\n\n# default is a 3-D draws_array object from the posterior package\n# iterations x chains x variables\ndraws_arr &lt;- fit$draws() # or format=\"array\"\nstr(draws_arr)\n\n 'draws_array' num [1:1000, 1:4, 1:3] -7.21 -8.34 -9.16 -7.22 -7.21 ...\n - attr(*, \"dimnames\")=List of 3\n  ..$ iteration: chr [1:1000] \"1\" \"2\" \"3\" \"4\" ...\n  ..$ chain    : chr [1:4] \"1\" \"2\" \"3\" \"4\"\n  ..$ variable : chr [1:3] \"lp__\" \"p\" \"p_gt_chance\"\n\n\nOppure, possiamo usare as_draws_df() per creare un data frame:\n\ndraws &lt;- as_draws_df(fit)\nhead(draws)\n\n# A draws_df: 6 iterations, 1 chains, and 3 variables\n  lp__    p p_gt_chance\n1 -7.2 0.63           1\n2 -8.3 0.41           0\n3 -9.2 0.34           0\n4 -7.2 0.66           1\n5 -7.2 0.63           1\n6 -7.2 0.64           1\n# ... hidden reserved variables {'.chain', '.iteration', '.draw'}\n\n\nLo stesso risultato si ottiene nel modo seguente:\n\ndraws_df &lt;- as_draws_df(draws_arr)\nhead(draws_df)\n\n# A draws_df: 6 iterations, 1 chains, and 3 variables\n  lp__    p p_gt_chance\n1 -7.2 0.63           1\n2 -8.3 0.41           0\n3 -9.2 0.34           0\n4 -7.2 0.66           1\n5 -7.2 0.63           1\n6 -7.2 0.64           1\n# ... hidden reserved variables {'.chain', '.iteration', '.draw'}\n\n\nUna volta creato un data frame, possiamo facilmente calcolare le statistiche descrittive. Per esempio:\n\ndraws_df$p |&gt;\n    mean()\n\n[1] 0.6364032\n\n\nIn questo modo possiamo calcolare la probabilità che, ad esempio, \\(p\\) sia compreso tra 0.5 e 0.75:\n\ndraws_df |&gt;\n    summarise(\n        p_between_0.5_and_0.75 = mean(p &gt; 0.5 & p &lt; 0.75)\n    )\n\n# A tibble: 1 × 1\n  p_between_0.5_and_0.75\n                   &lt;dbl&gt;\n1                  0.595\n\n\n\npartion_vector &lt;- c(\"italic(p)&lt;0.5\", \"{0.5&lt;italic(p)}&lt;0.75\", \"lower~80*'%'\", \"middle~80*'%'\")\n\ndraws_df |&gt;\n    mutate(\n        `italic(p)&lt;0.5` = p &lt; 0.5,\n        `{0.5&lt;italic(p)}&lt;0.75` = p &gt; 0.5 & p &lt; 0.75,\n        `lower~80*'%'` = p &lt; quantile(p, probs = 0.8),\n        `middle~80*'%'` = p &gt; quantile(p, probs = 0.1) & p &lt; quantile(p, probs = 0.9)\n    ) |&gt;\n    pivot_longer(cols = `italic(p)&lt;0.5`:`middle~80*'%'`) |&gt;\n    mutate(name = factor(name, levels = partion_vector)) |&gt;\n    ggplot(aes(x = p, fill = value)) +\n    geom_histogram(boundary = 0, binwidth = 0.01) +\n    scale_x_continuous(expression(proportion ~ water ~ (italic(p))), limits = 0:1) +\n    scale_y_continuous(NULL, breaks = NULL) +\n    scale_fill_viridis_d(end = 0.6, breaks = NULL) +\n    facet_wrap(~name, labeller = label_parsed)\n\nWarning: Dropping 'draws_df' class as required metadata was removed.\n\n\n\n\n\n\n\n\n\n\n\n56.5.2 Visualizzazione dei campioni\nVisualizzare le distribuzioni posteriori è semplice: basta passare l’oggetto restituito dal metodo $draws() direttamente alle funzioni di plotting del pacchetto bayesplot.\n\nmcmc_hist(fit$draws(\"p\"))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>Introduzione a CmdStanR</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/18_cmdstanr_intro.html#diagnostica-del-campionatore",
    "href": "chapters/mcmc/18_cmdstanr_intro.html#diagnostica-del-campionatore",
    "title": "56  Introduzione a CmdStanR",
    "section": "56.6 Diagnostica del campionatore",
    "text": "56.6 Diagnostica del campionatore\nIl metodo $sampler_diagnostics() estrae i valori dei parametri del campionatore (come treedepth__, divergent__, ecc.) in formati supportati dal pacchetto posterior.\n\nstr(fit$sampler_diagnostics(format = \"df\"))\n\ndraws_df [4,000 × 9] (S3: draws_df/draws/tbl_df/tbl/data.frame)\n $ treedepth__  : num [1:4000] 2 1 1 2 1 2 2 1 1 2 ...\n $ divergent__  : num [1:4000] 0 0 0 0 0 0 0 0 0 0 ...\n $ energy__     : num [1:4000] 7.21 8.57 9.3 9.06 7.23 ...\n $ accept_stat__: num [1:4000] 1 0.762 0.816 1 0.999 ...\n $ stepsize__   : num [1:4000] 0.937 0.937 0.937 0.937 0.937 ...\n $ n_leapfrog__ : num [1:4000] 3 3 1 3 3 3 3 1 1 3 ...\n $ .chain       : int [1:4000] 1 1 1 1 1 1 1 1 1 1 ...\n $ .iteration   : int [1:4000] 1 2 3 4 5 6 7 8 9 10 ...\n $ .draw        : int [1:4000] 1 2 3 4 5 6 7 8 9 10 ...\n\n\n\nfit$diagnostic_summary()\n\n$num_divergent\n[1] 0 0 0 0\n\n$num_max_treedepth\n[1] 0 0 0 0\n\n$ebfmi\n[1] 1.1950436 0.9774677 1.2009506 0.9659775\n\n\nQuesto processo consente di esaminare in dettaglio le prestazioni del campionatore e di verificare eventuali problemi o inefficienze durante l’esecuzione del modello.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>Introduzione a CmdStanR</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/18_cmdstanr_intro.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/18_cmdstanr_intro.html#informazioni-sullambiente-di-sviluppo",
    "title": "56  Introduzione a CmdStanR",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n\nR version 4.4.2 (2024-10-31)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Sequoia 15.1.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n\nlocale:\n[1] C/UTF-8/C/C/C/C\n\ntime zone: Europe/Rome\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] here_1.0.1          bayesplot_1.11.1    posterior_1.6.0    \n [4] cmdstanr_0.8.1.9000 lubridate_1.9.3     forcats_1.0.0      \n [7] stringr_1.5.1       dplyr_1.1.4         purrr_1.0.2        \n[10] readr_2.1.5         tidyr_1.3.1         tibble_3.2.1       \n[13] ggplot2_3.5.1       tidyverse_2.0.0    \n\nloaded via a namespace (and not attached):\n [1] tensorA_0.36.2.1     utf8_1.2.4           generics_0.1.3      \n [4] stringi_1.8.4        hms_1.1.3            digest_0.6.37       \n [7] magrittr_2.0.3       evaluate_1.0.1       grid_4.4.2          \n[10] timechange_0.3.0     fastmap_1.2.0        plyr_1.8.9          \n[13] rprojroot_2.0.4      jsonlite_1.8.9       processx_3.8.4      \n[16] backports_1.5.0      ps_1.8.1             fansi_1.0.6         \n[19] viridisLite_0.4.2    scales_1.3.0         abind_1.4-8         \n[22] cli_3.6.3            rlang_1.1.4          munsell_0.5.1       \n[25] withr_3.0.2          yaml_2.3.10          tools_4.4.2         \n[28] reshape2_1.4.4       tzdb_0.4.0           checkmate_2.3.2     \n[31] colorspace_2.1-1     vctrs_0.6.5          R6_2.5.1            \n[34] matrixStats_1.4.1    lifecycle_1.0.4      htmlwidgets_1.6.4   \n[37] pkgconfig_2.0.3      pillar_1.9.0         gtable_0.3.6        \n[40] Rcpp_1.0.13-1        data.table_1.16.2    glue_1.8.0          \n[43] xfun_0.49            tidyselect_1.2.1     knitr_1.49          \n[46] farver_2.1.2         htmltools_0.5.8.1    labeling_0.4.3      \n[49] rmarkdown_2.29       compiler_4.4.2       distributional_0.5.0",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>Introduzione a CmdStanR</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/introduction_linear_models.html",
    "href": "chapters/linear_models/introduction_linear_models.html",
    "title": "Introduzione",
    "section": "",
    "text": "Bibliografia\nIn questa sezione esploreremo un approccio all’analisi dei dati basato sull’uso della regressione lineare, esaminandolo dalla prospettiva dell’inferenza bayesiana. La regressione è un metodo che consente ai ricercatori di riassumere come le previsioni o i valori medi di un risultato variano tra individui definiti da un insieme di predittori.\nCome indicato da (gelman2020regression?), alcuni degli usi più importanti della regressione sono:\nIn tutti questi scenari, è cruciale che il modello di regressione includa tutte le variabili rilevanti. Ad esempio, in uno studio sull’efficacia di una terapia per la depressione negli anziani, è essenziale includere fattori come l’età, le condizioni di salute preesistenti e il supporto sociale. Omettere questi predittori potrebbe portare a stime inaccurate e conclusioni fuorvianti sull’effettiva efficacia del trattamento in questa popolazione specifica.",
    "crumbs": [
      "Regressione",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/linear_models/00_lin_mod_frequentist.html",
    "href": "chapters/linear_models/00_lin_mod_frequentist.html",
    "title": "57  La regressione lineare bivariata: un approccio frequentista",
    "section": "",
    "text": "57.1 Introduzione\nI modelli lineari sono stati impiegati in molteplici contesti per lungo tempo. Come descritto da Stigler (1986), il metodo dei minimi quadrati, una tecnica per adattare una regressione lineare bivariata, veniva già utilizzato nel XVIII secolo per affrontare problemi di analisi dei dati in astronomia. Ad esempio, questo metodo era impiegato per determinare il moto della Luna e per riconciliare i movimenti non periodici di Giove e Saturno. All’epoca, gli astronomi erano tra i primi a sentirsi a proprio agio nell’uso di tali metodi, poiché raccoglievano personalmente le loro osservazioni e sapevano che le condizioni di raccolta dei dati erano omogenee, anche se i valori osservati potevano differire. Questo contrastava con l’approccio più cauto delle scienze sociali, dove la riluttanza a combinare dati eterogenei ritardava l’adozione dei modelli lineari (Stigler, 1986).\nIn questo capitolo verrà introdotto il modello di regressione lineare bivariata secondo l’approccio frequentista. Questo modello consente di predire una variabile continua \\(y\\) a partire da un unico predittore continuo \\(x\\), utilizzando una relazione lineare. La relazione tra le due variabili è descritta dall’equazione della retta di regressione:\n\\[\ny_i = a + b x_i + e_i, \\quad i = 1, \\dots, n,\n\\]\ndove \\(a\\) rappresenta l’intercetta, \\(b\\) la pendenza della retta (coefficiente di regressione) e \\(e_i\\) l’errore residuo per ciascuna osservazione.\nSaranno illustrati i seguenti aspetti:",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/00_lin_mod_frequentist.html#introduzione",
    "href": "chapters/linear_models/00_lin_mod_frequentist.html#introduzione",
    "title": "57  La regressione lineare bivariata: un approccio frequentista",
    "section": "",
    "text": "Stima dei coefficienti di regressione: Come calcolare \\(a\\) e \\(b\\).\nInterpretazione dei coefficienti: Il significato pratico di \\(a\\) e \\(b\\) nella descrizione della relazione tra \\(x\\) e \\(y\\).\nValutazione del modello: Come misurare la bontà di adattamento del modello ai dati osservati, attraverso indicatori come l’indice di determinazione (\\(R^2\\)) e l’analisi dei residui.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/00_lin_mod_frequentist.html#la-predizione-dellintelligenza",
    "href": "chapters/linear_models/00_lin_mod_frequentist.html#la-predizione-dellintelligenza",
    "title": "57  La regressione lineare bivariata: un approccio frequentista",
    "section": "57.2 La Predizione dell’Intelligenza",
    "text": "57.2 La Predizione dell’Intelligenza\nNella presente discussione, esamineremo i dati kidiq che consistono in una raccolta di dati provenienti da una survey su donne adulte americane e i loro figli, selezionati da un sotto-campione del National Longitudinal Survey of Youth (Gelman et al., 2021).\nNello specifico, ci concentreremo sulla relazione tra il punteggio di intelligenza del bambino (kid_score) e quello della madre (mom_iq). Ci proponiamo di valutare se e in quale misura l’intelligenza della madre possa prevedere l’intelligenza del bambino. Per fare ciò, inizieremo ad importare i dati nell’ambiente R.\n\n# Caricamento dei dati\nkidiq &lt;- rio::import(here::here(\"data\", \"kidiq.dta\"))\n\n\n# Anteprima dei dati\nhead(kidiq)\n#&gt;   kid_score mom_hs mom_iq mom_work mom_age\n#&gt; 1        65      1  121.1        4      27\n#&gt; 2        98      1   89.4        4      25\n#&gt; 3        85      1  115.4        4      27\n#&gt; 4        83      1   99.4        3      25\n#&gt; 5       115      1   92.7        4      27\n#&gt; 6        98      0  107.9        1      18\n\nUn diagramma a dispersione per i dati di questo campione suggerisce la presenza di un’associazione positiva tra l’intelligenza del bambino (kid_score) e l’intelligenza della madre (mom_iq).\n\nggplot(kidiq, aes(x = mom_iq, y = kid_score)) +\n  geom_point(alpha = 0.4) +\n  labs(x = \"QI della madre\", y = \"QI del bambino\") +\n  ggtitle(\"Diagramma a dispersione\")",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/00_lin_mod_frequentist.html#stima-del-modello-di-regressione-lineare",
    "href": "chapters/linear_models/00_lin_mod_frequentist.html#stima-del-modello-di-regressione-lineare",
    "title": "57  La regressione lineare bivariata: un approccio frequentista",
    "section": "57.3 Stima del modello di regressione lineare",
    "text": "57.3 Stima del modello di regressione lineare\nCalcoliamo i coefficienti della retta di regressione utilizzando la funzione lm.\n\n# Modello di regressione lineare\nmod &lt;- lm(kid_score ~ mom_iq, data = kidiq)\n\n\n# Coefficienti stimati\ncoef(mod)\n#&gt; (Intercept)      mom_iq \n#&gt;       25.80        0.61\n\nCi sono però infinite rette che, in linea di principio, possono essere usate per “approssimare” la nube di punti nel diagramma a dispersione. È dunque necessario introdurre dei vincoli per selezionare una di queste possibili rette. Il vincolo che viene introdotto dal modello di regressione è quello di costringere la retta a passare per il punto \\((\\bar{x}, \\bar{y})\\).\n\nggplot(kidiq, aes(x = mom_iq, y = kid_score)) +\n  geom_point(alpha = 0.4) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"blue\") +\n  labs(x = \"QI della madre\", y = \"QI del bambino\") +\n  ggtitle(\"Retta di regressione\")\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nUna retta di regressione che passa per il punto medio \\((\\bar{x}, \\bar{y})\\) (che rappresenta il centro di massa dei dati) è preferibile dal punto di vista statistico poiché minimizza la somma dei quadrati degli errori residui.\nIl campione è costituito da \\(n\\) coppie di osservazioni (\\(x, y\\)). Per ciascuna coppia di valori \\(x_i, y_i\\), il modello di regressione si aspetta che il valore \\(y_i\\) sia associato al corrispondente valore \\(x_i\\) come indicato dalla seguente equazione:\n\\[\n\\begin{equation}\n\\mathbb{E}(y_i) = a + b x_i .\n\\end{equation}\n\\]\nI valori \\(y_i\\) corrispondono, nell’esempio che stiamo discutendo, alla variabile kid_score. I primi 10 valori della variabile \\(y\\) sono i seguenti:\n\nkidiq$kid_score[0:10]\n#&gt;  [1]  65  98  85  83 115  98  69 106 102  95\n\nPer fare riferimento a ciascuna osservazione usiamo l’indice \\(i\\). Quindi, ad esempio, \\(y_2\\) è uguale a\n\nkidiq$kid_score[2]\n#&gt; [1] 98\n\nIl modello di regressione lineare bivariata, rappresentato dall’equazione \\(y_i = a + b x_i + e_i\\), descrive la relazione tra le variabili \\(x\\) e \\(y\\), dove \\(y\\) è la variabile dipendente (nel nostro esempio, la variabile kid_score) e \\(x\\) è la variabile indipendente (nel nostro esempio, la variabile mom_iq). Il valore di \\(y\\) è la somma di due componenti: la componente deterministica, \\(\\hat{y}_i = a + b x_i\\), e la componente aleatoria, \\(e_i\\). La componente deterministica rappresenta la porzione della \\(y\\) che è prevedibile conoscendo il valore di \\(x\\), mentre la componente aleatoria rappresenta la porzione della \\(y\\) che non è prevedibile dal modello.\nIl modello lineare cerca di trovare i coefficienti \\(a\\) e \\(b\\) che permettono di prevedere la componente deterministica di \\(y\\) conoscendo il valore di \\(x\\). Tuttavia, poiché la retta è solo un’approssimazione della relazione tra \\(x\\) e \\(y\\), la componente deterministica rappresenta solo una stima approssimata della vera relazione tra le due variabili.\nPer valutare l’accuratezza del modello di regressione lineare, è necessario calcolare il residuo \\(e_i = y_i - (a + b x_i)\\), ovvero la differenza tra il valore osservato di \\(y\\) e il valore previsto dal modello, \\(\\hat{y}\\). La dimensione del residuo indica quanto la componente aleatoria contribuisce al valore osservato di \\(y\\).\nIl modello di regressione lineare ha tre obiettivi (Fox, 2015):\n\nil primo è quello di trovare i coefficienti \\(a\\) e \\(b\\) che permettono di prevedere la componente deterministica di \\(y\\) conoscendo il valore di \\(x\\);\nil secondo obiettivo è quello di valutare l’accuratezza della predizione fornita dal modello di regressione lineare;\ninfine, il terzo obiettivo è quello dell’inferenza, ovvero quello di capire quali relazioni esistono tra la relazione tra \\(x\\) e \\(y\\) osservata nel campione e la relazione tra le due variabili nella popolazione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/00_lin_mod_frequentist.html#stima-dei-coefficienti-di-regressione",
    "href": "chapters/linear_models/00_lin_mod_frequentist.html#stima-dei-coefficienti-di-regressione",
    "title": "57  La regressione lineare bivariata: un approccio frequentista",
    "section": "57.4 Stima dei coefficienti di regressione",
    "text": "57.4 Stima dei coefficienti di regressione\nIn breve, stiamo cercando di descrivere una relazione tra due variabili, il QI della madre e il QI del bambino, utilizzando un modello di regressione lineare. L’equazione lineare che descrive la relazione tra le due variabili è della forma \\(\\hat{y}_i = a_i + bx_i\\), dove \\(\\hat{y}_i\\) rappresenta la previsione per il QI del bambino \\(i\\)-esimo, \\(a_i\\) e \\(b\\) sono i coefficienti di regressione che vogliamo trovare e \\(x_i\\) è il QI della madre del bambino \\(i\\)-esimo.\nPer trovare i coefficienti di regressione, dobbiamo introdurre dei vincoli per limitare lo spazio delle possibili soluzioni. Il primo vincolo è che la retta di regressione deve passare per il baricentro del grafico a dispersione. Il secondo vincolo è che vogliamo minimizzare la somma dei quadrati dei residui, ovvero la differenza tra il valore osservato e il valore previsto dal modello. I coefficienti di regressione che soddisfano questi vincoli si chiamano coefficienti dei minimi quadrati.\nIl problema di trovare i coefficienti di regressione \\(a\\) e \\(b\\) che minimizzano la somma dei quadrati dei residui ha una soluzione analitica. Questa soluzione si ottiene trovando il punto di minimo di una superficie tridimensionale che rappresenta la somma dei quadrati dei residui. Il punto di minimo è quello per cui il piano tangente alla superficie nelle due direzioni \\(a\\) e \\(b\\) è piatto, cioè le derivate parziali rispetto ad \\(a\\) e \\(b\\) sono uguali a zero. In pratica, ciò significa risolvere un sistema di equazioni lineari con due incognite \\(a\\) e \\(b\\), noto come equazioni normali.\nLa soluzione delle equazioni normali ci fornisce i coefficienti di regressione stimati, che minimizzano la somma dei quadrati dei residui. La formula per il coefficiente \\(a\\) è\n\\[\na = \\bar{y} - b \\bar{x}.\n\\]\nLa formula per il coefficiente \\(b\\) è\n\\[\nb = \\frac{Cov(x, y)}{Var(x)},\n\\]\ndove \\(\\bar{x}\\) e \\(\\bar{y}\\) sono le medie delle variabili \\(x\\) e \\(y\\), \\(Cov(x,y)\\) è la covarianza tra \\(x\\) e \\(y\\) e \\(Var(x)\\) è la varianza di \\(x\\).\nQueste equazioni rappresentano la stima dei minimi quadrati dei coefficienti di regressione che ci permettono di trovare la retta che minimizza la somma dei quadrati dei residui.\n\n57.4.1 Calcolo manuale dei coefficienti di regressione\nPer calcolare i coefficienti di regressione \\(a\\) (intercetta) e \\(b\\) (pendenza), utilizziamo la covarianza e la varianza:\n\n# Calcolo manuale dei coefficienti\ncov_xy &lt;- cov(kidiq$kid_score, kidiq$mom_iq)  # Covarianza tra le due variabili\nvar_x &lt;- var(kidiq$mom_iq)  # Varianza della variabile indipendente\nb &lt;- cov_xy / var_x  # Pendenza (coefficiente b)\nb\n#&gt; [1] 0.61\n\n\n# Intercetta (coefficiente a)\na &lt;- mean(kidiq$kid_score) - b * mean(kidiq$mom_iq)\na\n#&gt; [1] 25.8\n\n\n\n57.4.2 Interpretazione\nIl coefficiente \\(a\\) indica l’intercetta della retta di regressione nel diagramma a dispersione. Questo valore rappresenta il punto in cui la retta di regressione interseca l’asse \\(y\\) del sistema di assi cartesiani. Tuttavia, in questo caso specifico, il valore di \\(a\\) non è di particolare interesse poiché corrisponde al valore della retta di regressione quando l’intelligenza della madre è pari a 0, il che non ha senso nella situazione reale. Successivamente, vedremo come è possibile trasformare i dati per fornire un’interpretazione utile del coefficiente \\(a\\).\nInvece, il coefficiente \\(b\\) indica la pendenza della retta di regressione, ovvero di quanto aumenta (se \\(b\\) è positivo) o diminuisce (se \\(b\\) è negativo) la retta di regressione in corrispondenza di un aumento di 1 punto della variabile \\(x\\). Nel caso specifico del QI delle madri e dei loro figli, il coefficiente \\(b\\) ci indica che un aumento di 1 punto del QI delle madri è associato, in media, a un aumento di 0.61 punti del QI dei loro figli.\nIn pratica, il modello di regressione lineare cerca di prevedere le medie dei punteggi del QI dei figli in base al QI delle madri. Ciò significa che non è in grado di prevedere esattamente il punteggio di ciascun bambino in funzione del QI della madre, ma solo una stima della media dei punteggi dei figli quando il QI delle madri aumenta o diminuisce di un punto.\nIl coefficiente \\(b\\) ci dice di quanto aumenta (o diminuisce) in media il QI dei figli per ogni unità di aumento (o diminuzione) del QI della madre. Nel nostro caso, se il QI della madre aumenta di un punto, il QI dei figli aumenta in media di 0.61 punti.\nÈ importante comprendere che il modello statistico di regressione lineare non è in grado di prevedere il valore preciso di ogni singolo bambino, ma solo una stima della media dei punteggi del QI dei figli quando il QI delle madri aumenta o diminuisce. Questa stima è basata su una distribuzione di valori possibili che si chiama distribuzione condizionata \\(p(y \\mid x_i)\\).\nUna rappresentazione grafica del valore predetto dal modello di regressione, \\(\\hat{y}_i = a + bx_i\\) è stato fornito in precedenza. Il diagramma presenta ciascun valore \\(\\hat{y}_i = a + b x_i\\) in funzione di \\(x_i\\). I valori predetti dal modello di regressione sono i punti che stanno sulla retta di regressione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/00_lin_mod_frequentist.html#residui",
    "href": "chapters/linear_models/00_lin_mod_frequentist.html#residui",
    "title": "57  La regressione lineare bivariata: un approccio frequentista",
    "section": "57.5 Residui",
    "text": "57.5 Residui\nIn precedenza abbiamo detto che il residuo, ovvero la componente di ciascuna osservazione \\(y_i\\) che non viene predetta dal modello di regressione, corrisponde alla distanza verticale tra il valore \\(y_i\\) osservato e il valore \\(\\hat{y}_i\\) predetto dal modello di regressione:\n\\[\ne_i = y_i - (a + b x_i).\n\\]\nPer fare un esempio numerico, consideriamo il punteggio osservato del QI del primo bambino.\n\nkidiq$kid_score[1]\n#&gt; [1] 65\n\nIl QI della madre è\n\nkidiq$mom_iq[1]\n#&gt; [1] 121\n\nPer questo bambino, il valore predetto dal modello di regressione è\n\na + b * kidiq$mom_iq[1]\n#&gt; [1] 99.7\n\nL’errore che compiamo per predire il QI del bambino utilizzando il modello di regressione (ovvero, il residuo) è\n\nkidiq$kid_score[1] - (a + b * kidiq$mom_iq[1])\n#&gt; [1] -34.7\n\nPer tutte le osservazioni abbiamo\n\nres &lt;- kidiq$kid_score - (a + b * kidiq$mom_iq)\n\nÈ una proprietà del modello di regressione (calcolato con il metodo dei minimi quadrati) che la somma dei residui sia uguale a zero.\n\nsum(res)\n#&gt; [1] 1.44e-11\n\nQuesto significa che ogni valore osservato \\(y_i\\) viene scomposto dal modello di regressione in due componenti distinte. La componente deterministica \\(\\hat{y}_i\\), che è predicibile da \\(x_i\\), è data da \\(\\hat{y}_i = a + b x_i\\). Il residuo, invece, è dato da \\(e_i = y_i - \\hat{y}_i\\). La somma di queste due componenti, ovviamente, riproduce il valore osservato.\n\n# Creazione di un data frame con i valori calcolati\ndf &lt;- data.frame(\n  kid_score = kidiq$kid_score,\n  mom_iq = kidiq$mom_iq,\n  y_hat = a + b * kidiq$mom_iq,\n  e = kidiq$kid_score - (a + b * kidiq$mom_iq),\n  y_hat_plus_e = (a + b * kidiq$mom_iq) + (kidiq$kid_score - (a + b * kidiq$mom_iq))\n)\n\n# Visualizzazione dei primi 6 valori\nhead(df)\n#&gt;   kid_score mom_iq y_hat      e y_hat_plus_e\n#&gt; 1        65  121.1  99.7 -34.68           65\n#&gt; 2        98   89.4  80.3  17.69           98\n#&gt; 3        85  115.4  96.2 -11.22           85\n#&gt; 4        83   99.4  86.5  -3.46           83\n#&gt; 5       115   92.7  82.4  32.63          115\n#&gt; 6        98  107.9  91.6   6.38           98",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/00_lin_mod_frequentist.html#trasformazione-dei-dati",
    "href": "chapters/linear_models/00_lin_mod_frequentist.html#trasformazione-dei-dati",
    "title": "57  La regressione lineare bivariata: un approccio frequentista",
    "section": "57.6 Trasformazione dei dati",
    "text": "57.6 Trasformazione dei dati\nIn generale, per variabili a livello di scala ad intervalli, l’intercetta del modello di regressione lineare non ha un’interpretazione utile. Questo perché l’intercetta indica il valore atteso di \\(y\\) quando \\(x = 0\\), ma in caso di variabili a scala di intervalli, il valore “0” di \\(x\\) è arbitrario e non corrisponde ad un “assenza” della variabile \\(x\\). Ad esempio, un QI della madre pari a 0 non indica un’assenza di intelligenza, ma solo un valore arbitrario del test usato per misurare il QI. Quindi, sapere il valore medio del QI dei bambini quando il QI della madre è 0 non è di alcun interesse.\nPer fornire all’intercetta del modello di regressione un’interpretazione più utile, dobbiamo trasformare le osservazioni di \\(x\\). Per esempio, esprimiamo \\(x\\) come differenza dalla media. Chiamiamo questa nuova variabile \\(xd\\):\n\nkidiq$xd &lt;- kidiq$mom_iq - mean(kidiq$mom_iq)\n\nkidiq |&gt; \n  head()\n#&gt;   kid_score mom_hs mom_iq mom_work mom_age     xd\n#&gt; 1        65      1  121.1        4      27  21.12\n#&gt; 2        98      1   89.4        4      25 -10.64\n#&gt; 3        85      1  115.4        4      27  15.44\n#&gt; 4        83      1   99.4        3      25  -0.55\n#&gt; 5       115      1   92.7        4      27  -7.25\n#&gt; 6        98      0  107.9        1      18   7.90\n\nSe ora usiamo le coppie di osservazioni \\((xd_i, y_i)\\), il diagramma a dispersione assume la forma seguente.\n\n# Aggiungiamo una nuova variabile centrata (scarti dalla media)\nkidiq &lt;- kidiq %&gt;%\n  mutate(xd = mom_iq - mean(mom_iq))\n\n# Calcolo della retta di regressione\nb &lt;- cov(kidiq$xd, kidiq$kid_score) / var(kidiq$xd)\na &lt;- mean(kidiq$kid_score) - b * mean(kidiq$xd)\n\n# Grafico con ggplot2\nggplot(kidiq, aes(x = xd, y = kid_score)) +\n  geom_point(alpha = 0.4) +  # Punti del grafico\n  geom_abline(intercept = a, slope = b, color = \"blue\") +  # Retta di regressione\n  labs(\n    x = \"QI della madre (scarti dalla media)\", \n    y = \"QI del bambino\"\n  ) +\n  ggtitle(\"Retta di regressione sui dati centrati\")\n\n\n\n\n\n\n\n\nIn pratica, abbiamo spostato tutti i punti del grafico lungo l’asse delle \\(x\\), in modo tale che la media dei valori di \\(x\\) sia uguale a 0. Questo non ha cambiato la forma dei punti nel grafico, ma ha solo spostato l’origine dell’asse \\(x\\). La pendenza della linea di regressione tra \\(x\\) e \\(y\\) rimane la stessa, sia per i dati originali che per quelli trasformati. L’unica cosa che cambia è il valore dell’intercetta della linea di regressione, che ora ha un’interpretazione più significativa.\n\nfm1 &lt;- lm(kid_score ~ xd, data = kidiq)\ncoef(fm1)\n#&gt; (Intercept)          xd \n#&gt;       86.80        0.61\n\nL’intercetta rappresenta il punto in cui la retta di regressione incontra l’asse \\(y\\) nel diagramma a dispersione. Nel caso dei dati trasformati, abbiamo spostato la nube di punti lungo l’asse \\(x\\) di una quantità pari a \\(x - \\bar{x}\\), ma le relazioni spaziali tra i punti rimangono invariate. Pertanto, la pendenza della retta di regressione non cambia rispetto ai dati non trasformati. Tuttavia, il valore dell’intercetta viene influenzato dalla trasformazione. In particolare, poiché \\(xd = 0\\) corrisponde a \\(x = \\bar{x}\\) nei dati grezzi, l’intercetta del modello di regressione lineare calcolata sui dati trasformati corrisponde al valore atteso di \\(y\\) quando \\(x\\) assume il valore medio sulla scala dei dati grezzi. In altre parole, l’intercetta del modello di regressione lineare sui dati trasformati rappresenta il valore atteso del QI dei bambini corrispondente al QI medio delle madri.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/00_lin_mod_frequentist.html#il-metodo-dei-minimi-quadrati",
    "href": "chapters/linear_models/00_lin_mod_frequentist.html#il-metodo-dei-minimi-quadrati",
    "title": "57  La regressione lineare bivariata: un approccio frequentista",
    "section": "57.7 Il metodo dei minimi quadrati",
    "text": "57.7 Il metodo dei minimi quadrati\nPer stimare i coefficienti \\(a\\) e \\(b\\), possiamo minimizzare la somma dei quadrati dei residui tra i valori osservati \\(y_i\\) e quelli previsti \\(a + b x_i\\).\nIniziamo con il creare una griglia per i valori di \\(b\\). Supponiamo che il valore di \\(a\\) sia noto (\\(a = 25.79978\\)). Usiamo R per creare una griglia di valori possibili per \\(b\\).\n\n# Griglia di valori per b\nb_grid &lt;- seq(0, 1, length.out = 1001)\na &lt;- 25.79978  # Intercetta nota\n\nDefiniamo ora una funzione che calcola la somma dei quadrati dei residui (\\(SSE\\)) per ciascun valore di \\(b\\).\n\n# Funzione per la somma dei quadrati dei residui\nsse &lt;- function(a, b, x, y) {\n  sum((y - (a + b * x))^2)\n}\n\nApplichiamo la funzione sse alla griglia di valori \\(b\\) per calcolare la somma dei quadrati dei residui per ogni valore di \\(b\\).\n\n# Calcolo di SSE per ciascun valore di b\nsse_vals &lt;- sapply(b_grid, function(b) sse(a, b, kidiq$mom_iq, kidiq$kid_score))\n\nTracciamo un grafico che mostra la somma dei quadrati dei residui (\\(SSE\\)) in funzione dei valori di \\(b\\), evidenziando il minimo.\n\n# Identificazione del valore di b che minimizza SSE\nb_min &lt;- b_grid[which.min(sse_vals)]\n\n# Grafico\nplot(\n  b_grid, sse_vals, type = \"l\", col = \"blue\", lwd = 2,\n  xlab = expression(paste(\"Possibili valori di \", hat(beta))),\n  ylab = \"Somma dei quadrati dei residui (SSE)\",\n  main = \"Minimizzazione dei residui quadratici\"\n)\npoints(b_min, min(sse_vals), pch = 19, col = \"red\")\nlegend(\"topright\", legend = expression(hat(beta)), col = \"red\", pch = 19)\n\n\n\n\n\n\n\n\nInfine, identifichiamo il valore di \\(b\\) che minimizza la somma dei quadrati dei residui.\n\nb_min\n#&gt; [1] 0.61\n\nCon questa simulazione, abbiamo stimato il coefficiente \\(b\\) minimizzando la somma dei quadrati dei residui. Questo approccio può essere esteso per stimare simultaneamente entrambi i coefficienti (\\(a\\) e \\(b\\)) utilizzando metodi di ottimizzazione più avanzati, come optim in R.\n\noptim_result &lt;- optim(\n  par = c(a = 25, b = 0.5),  # Valori iniziali\n  fn = function(params) {\n    a &lt;- params[1]\n    b &lt;- params[2]\n    sse(a, b, kidiq$mom_iq, kidiq$kid_score)\n  }\n)\n\n# Coefficienti stimati\noptim_result$par\n#&gt;     a     b \n#&gt; 25.79  0.61\n\nQuesta simulazione illustra come, tramite il metodo dei minimi quadrati, sia possibile stimare i parametri di un modello bivariato di regressione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/00_lin_mod_frequentist.html#lerrore-standard-della-regressione",
    "href": "chapters/linear_models/00_lin_mod_frequentist.html#lerrore-standard-della-regressione",
    "title": "57  La regressione lineare bivariata: un approccio frequentista",
    "section": "57.8 L’errore standard della regressione",
    "text": "57.8 L’errore standard della regressione\nIl secondo obiettivo del modello di regressione lineare è quello di misurare quanto della variabilità di \\(y\\) possa essere spiegata dalla variabilità di \\(x\\) per ogni osservazione. L’indice di bontà di adattamento del modello viene fornito dalla deviazione standard dei residui, chiamata anche “errore standard della stima” (o errore standard della regressione), \\(s_e\\). Per calcolare \\(s_e\\), si sommano i quadrati dei residui \\(e_i\\) per ogni osservazione e si divide per \\(n-2\\), dove \\(n\\) rappresenta la numerosità del campione e \\(2\\) il numero di coefficienti stimati nel modello di regressione. Si prende poi la radice quadrata del risultato. L’indice \\(s_e\\) possiede la stessa unità di misura di \\(y\\) ed è una stima della deviazione standard dei residui nella popolazione.\nIllustriamo il calcolo di \\(s_e\\) con i dati a disposizione. I residui \\(e\\) possono essere calcolati sottraendo ai valori osservati \\(y_i\\) i valori predetti dal modello \\(a + b x_i\\):\n\n# Calcolo dei residui\ne &lt;- kidiq$kid_score - (a + b * kidiq$mom_iq)\n\n# Mostriamo i primi 10 residui\nhead(e, 10)\n#&gt;  [1] -34.68  17.69 -11.22  -3.46  32.63   6.38 -41.52   3.86  26.41  11.21\n\nCalcoliamo il valore medio assoluto dei residui per avere un’indicazione della deviazione media rispetto alla retta di regressione.\n\n# Media assoluta dei residui\nmean(abs(e))\n#&gt; [1] 14.5\n\nL’errore standard della stima \\(s_e\\) si calcola come la radice quadrata della somma dei quadrati dei residui divisa per \\(n-2\\):\n\n# Calcolo di s_e\nse &lt;- sqrt(sum(e^2) / (length(e) - 2))\nse\n#&gt; [1] 18.3\n\nNotiamo che il valore medio assoluto dei residui e l’errore standard \\(s_e\\) non sono identici, ma hanno lo stesso ordine di grandezza. \\(s_e\\) è una misura più rigorosa della deviazione standard dei residui.\nQuesta analisi dimostra come \\(s_e\\) consenta di valutare quanto le previsioni del modello si discostino (in media) dai dati osservati.\n\n57.8.1 Sottostima dell’Errore nel Modello di Regressione\nCome discusso da Gelman et al. (2021), la radice quadrata media dei residui, calcolata come\n\\[\n\\sqrt{\\frac{1}{n} \\sum_{i=1}^n \\big(y_i - (\\hat{a} + \\hat{b}x_i)\\big)^2},\n\\]\ntende a sottostimare la deviazione standard \\(\\sigma\\) dell’errore nel modello di regressione. Questa sottostima è dovuta al fenomeno del sovradimensionamento, dato che i parametri \\(a\\) e \\(b\\) sono stimati utilizzando gli stessi \\(n\\) punti dati su cui vengono calcolati i residui. In altre parole, i residui non sono del tutto indipendenti dal modello.\nUn approccio alternativo per valutare l’errore predittivo e mitigare il problema del sovradimensionamento è la validazione incrociata. In particolare, l’approccio leave-one-out (LOOCV) offre una soluzione semplice ed efficace. Questo metodo consiste nell’adattare il modello \\(n\\) volte, escludendo ogni volta un punto dati, adattando il modello ai rimanenti \\(n-1\\) punti, e utilizzando tale modello per predire l’osservazione esclusa.\n\n57.8.1.1 Procedura Leave-One-Out:\n\nPer \\(i = 1, \\ldots, n\\):\n\nAdatta il modello \\(y = a + bx + \\text{errore}\\) ai \\(n-1\\) punti dati \\((x, y)_j, j \\neq i\\). Denomina i coefficienti stimati come \\(\\hat{a}_{-i}\\) e \\(\\hat{b}_{-i}\\).\nCalcola il residuo validato incrociato:\n\\[\nr_{\\text{CV}} = y_i - (\\hat{a}_{-i} + \\hat{b}_{-i} x_i).\n\\]\nSalva il residuo al quadrato per il calcolo successivo.\n\nCalcola infine la stima di \\(\\sigma_{\\text{CV}}\\) come:\n\\[\n\\sigma_{\\text{CV}} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n r_{\\text{CV}}^2}.\n\\]\n\n\n\n57.8.1.2 Applicazione Pratica:\nEcco un esempio applicato al modello che predice l’intelligenza del bambino (\\(\\texttt{kid\\_score}\\)) in funzione dell’intelligenza della madre (\\(\\texttt{mom\\_iq}\\)) utilizzando il dataset kidiq.\n\noptions(round = 5)\n\n# Array per salvare i residui validati incrociati\nresiduals_cv &lt;- numeric(nrow(kidiq))\n\n# Loop per la validazione incrociata leave-one-out\nfor (i in 1:nrow(kidiq)) {\n  # Dati di training escludendo l'i-esimo punto\n  train_data &lt;- kidiq[-i, ]\n  test_data &lt;- kidiq[i, ]\n  \n  # Addestramento del modello\n  model &lt;- lm(kid_score ~ mom_iq, data = train_data)\n  \n  # Predizione sull'i-esimo punto\n  y_pred &lt;- predict(model, newdata = test_data)\n  \n  # Calcolo del residuo validato incrociato\n  residual_cv &lt;- test_data$kid_score - y_pred\n  residuals_cv[i] &lt;- residual_cv^2\n}\n\n# Calcolo di sigma_cv\nsigma_cv &lt;- sqrt(mean(residuals_cv))\n\ncat(\"Stima di σ_CV:\", sigma_cv, \"\\n\")\n#&gt; Stima di σ_CV: 18.3\n\n\n\n57.8.1.3 Confronto con la Stima Tradizionale\nCalcoliamo la stima tradizionale di \\(\\sigma\\) utilizzando il modello completo e confrontiamola con \\(\\sigma_{\\text{CV}}\\).\n\n# Modello completo\nfm2 &lt;- lm(kid_score ~ mom_iq, data = kidiq)\n\n# Stima tradizionale dell'errore standard della regressione\nres &lt;- summary(fm2)\ncat(\"Errore standard della regressione (tradizionale):\", res$sigma, \"\\n\")\n#&gt; Errore standard della regressione (tradizionale): 18.3\n\nLa stima tradizionale di \\(\\sigma\\) si basa sulla seguente formula:\n\\[\n\\hat{\\sigma}_e = \\sqrt{\\frac{\\sum_{i=1}^n (e_i - \\bar{e})^2}{n - p}},\n\\]\ndove \\(e_i\\) sono i residui del modello e \\(p = 2\\) è il numero di parametri stimati (\\(a\\) e \\(b\\)).\n\n\n57.8.1.4 Interpretazione\nNel caso analizzato, i valori stimati di \\(\\sigma_{\\text{CV}}\\) e \\(\\hat{\\sigma}_e\\) tradizionale possono risultare molto simili. Tuttavia, in generale, la stima di \\(\\sigma_{\\text{CV}}\\) tende a essere leggermente superiore, in quanto riflette meglio l’errore predittivo su dati non utilizzati per adattare il modello. Questo rende \\(\\sigma_{\\text{CV}}\\) una misura più robusta e conservativa dell’incertezza del modello.\nLa validazione incrociata, e in particolare l’approccio LOOCV, rappresenta uno strumento importante per valutare le performance predittive di un modello di regressione e per ottenere stime più affidabili della deviazione standard dell’errore.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/00_lin_mod_frequentist.html#indice-di-determinazione",
    "href": "chapters/linear_models/00_lin_mod_frequentist.html#indice-di-determinazione",
    "title": "57  La regressione lineare bivariata: un approccio frequentista",
    "section": "57.9 Indice di determinazione",
    "text": "57.9 Indice di determinazione\nUn importante risultato dell’analisi di regressione riguarda la scomposizione della varianza della variabile dipendente \\(y\\) in due componenti: la varianza spiegata dal modello e la varianza residua. Questa scomposizione è descritta mediante l’indice di determinazione \\(R^2\\), che fornisce una misura della bontà di adattamento del modello ai dati del campione.\nPer una generica osservazione \\(x_i, y_i\\), la deviazione di \\(y_i\\) rispetto alla media \\(\\bar{y}\\) può essere espressa come la somma di due componenti: il residuo \\(e_i=y_i- \\hat{y}_i\\) e lo scarto di \\(\\hat{y}_i\\) rispetto alla media \\(\\bar{y}\\):\n\\[\ny_i - \\bar{y} = (y_i- \\hat{y}_i) + (\\hat{y}_i - \\bar{y}) = e_i + (\\hat{y}_i - \\bar{y}).\n\\]\nLa varianza totale di \\(y\\) può quindi essere scritta come:\n\\[\n\\sum_{i=1}^{n}(y_i - \\bar{y})^2 = \\sum_{i=1}^{n}(e_i + (\\hat{y}_i - \\bar{y}))^2.\n\\]\nSviluppando il quadrato e sommando, si ottiene:\n\\[\n\\sum_{i=1}^{n}(y_i - \\bar{y})^2 = \\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2 + \\sum_{i=1}^{n}(\\hat{y}_i - \\bar{y})^2.\n\\]\nIl primo termine rappresenta la varianza residua, mentre il secondo termine rappresenta la varianza spiegata dal modello. L’indice di determinazione \\(R^2\\) è definito come il rapporto tra la varianza spiegata e la varianza totale:\n\\[\nR^2 = \\frac{\\sum_{i=1}^{n}(\\hat{y}_i - \\bar{y})^2}{\\sum_{i=1}^{n}(y_i - \\bar{y})^2}.\n\\]\nQuesto indice varia tra 0 e 1 e indica la frazione di varianza totale di \\(y\\) spiegata dal modello di regressione lineare. Un valore alto di \\(R^2\\) indica che il modello di regressione lineare si adatta bene ai dati, in quanto una grande parte della varianza di \\(y\\) è spiegata dalla variabile indipendente \\(x\\).\nPer l’esempio in discussione, possiamo calcolare la devianza totale, la devianza spiegata e l’indice di determinazione \\(R^2\\) come segue:\nLa devianza totale misura la variabilità complessiva dei punteggi osservati \\(y\\) rispetto alla loro media:\n\n# Devianza totale\ndev_t &lt;- sum((kidiq$kid_score - mean(kidiq$kid_score))^2)\ndev_t\n#&gt; [1] 180386\n\nLa devianza spiegata misura la variabilità che il modello è in grado di spiegare, considerando i valori predetti \\(a + b x\\):\n\n# Devianza spiegata\ndev_r &lt;- sum(((a + b * kidiq$mom_iq) - mean(kidiq$kid_score))^2)\ndev_r\n#&gt; [1] 36249\n\nL’indice \\(R^2\\) è il rapporto tra la devianza spiegata e la devianza totale, e indica la frazione della variabilità totale che è spiegata dal modello di regressione:\n\n# Indice di determinazione\nR2 &lt;- dev_r / dev_t\nround(R2, 3)\n#&gt; [1] 0.201\n\nPer verificare i calcoli, utilizziamo il modello di regressione lineare in R e leggiamo \\(R^2\\) direttamente dal sommario del modello:\n\n# Modello di regressione lineare\nmod &lt;- lm(kid_score ~ mom_iq, data = kidiq)\n\n# Sommario del modello per leggere R^2\nsummary(mod)$r.squared\n#&gt; [1] 0.201\n\nIl risultato mostra che circa il 20% della variabilità nei punteggi del QI dei bambini è spiegabile conoscendo il QI delle madri. Questo significa che il modello cattura una porzione rilevante della relazione, ma lascia anche spazio a fattori non inclusi nel modello che influenzano il QI dei bambini.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/00_lin_mod_frequentist.html#inferenza-sul-modello-di-regressione",
    "href": "chapters/linear_models/00_lin_mod_frequentist.html#inferenza-sul-modello-di-regressione",
    "title": "57  La regressione lineare bivariata: un approccio frequentista",
    "section": "57.10 Inferenza sul modello di regressione",
    "text": "57.10 Inferenza sul modello di regressione\nIl terzo obiettivo del modello di regressione è l’inferenza. Nell’approccio frequentista, l’inferenza viene effettuata calcolando la distribuzione campionaria dei parametri e gli intervalli di fiducia per i parametri. Ad esempio, se si vuole determinare se la pendenza della retta di regressione è maggiore di zero, si calcola l’intervallo di fiducia al 95% per il parametro \\(\\beta\\). Se l’intervallo non include lo zero e se il limite inferiore dell’intervallo è maggiore di zero, si conclude che c’è evidenza di un’associazione lineare positiva tra \\(x\\) e \\(y\\) con un grado di confidenza del 95%.1 Il prossimo capitolo spiegherà come effettuare l’inferenza sui coefficienti del modello di regressione lineare in un contesto bayesiano.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/00_lin_mod_frequentist.html#riflessioni-conclusive",
    "href": "chapters/linear_models/00_lin_mod_frequentist.html#riflessioni-conclusive",
    "title": "57  La regressione lineare bivariata: un approccio frequentista",
    "section": "57.11 Riflessioni Conclusive",
    "text": "57.11 Riflessioni Conclusive\nIl modello lineare bivariato è uno strumento fondamentale nell’analisi delle relazioni tra due variabili e rappresenta una pietra miliare dell’approccio frequentista. Questo capitolo ha mostrato come il modello consenta di quantificare il grado di associazione tra una variabile indipendente \\(x\\) e una variabile dipendente \\(y\\), utilizzando una relazione lineare.\nGrazie all’approccio frequentista, abbiamo imparato a stimare i coefficienti \\(a\\) (intercetta) e \\(b\\) (pendenza) attraverso il metodo dei minimi quadrati, che minimizza la somma dei quadrati dei residui per trovare la retta che meglio approssima i dati osservati. Inoltre, l’indice di determinazione (\\(R^2\\)) ci ha permesso di valutare la bontà di adattamento del modello e di quantificare quanta parte della variabilità di \\(y\\) è spiegata dalla variabile \\(x\\).\nIn pratica, il modello lineare bivariato consente di rispondere a domande fondamentali, come:\n\nSe il valore della variabile indipendente aumenta o diminuisce, come si comporta la variabile dipendente?\nQual è l’intensità e il segno della relazione tra le due variabili?\n\nLa semplicità del modello lo rendono uno strumento utile non solo per descrivere e analizzare relazioni tra variabili, ma anche per effettuare previsioni. Pur limitandosi a un singolo predittore, il modello lineare bivariato fornisce una base per comprendere relazioni più complesse, come quelle coinvolgenti più variabili indipendenti (regressione multivariata).\nL’approccio frequentista offre una metodologia consolidata per stimare i parametri e valutare il modello, fornendo inferenze utili per analisi pratiche e decisioni informate. Con una solida comprensione di questi concetti, si è pronti a esplorare modelli lineari più complessi e a estendere queste tecniche a scenari più articolati.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/00_lin_mod_frequentist.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/00_lin_mod_frequentist.html#informazioni-sullambiente-di-sviluppo",
    "title": "57  La regressione lineare bivariata: un approccio frequentista",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] broom_1.0.7       MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2\n#&gt;  [5] ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0  \n#&gt;  [9] bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0      markdown_1.13    \n#&gt; [13] knitr_1.49        lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1    \n#&gt; [17] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#&gt; [21] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [25] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      xfun_0.49         htmlwidgets_1.6.4 rstatix_0.7.2    \n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    fansi_1.0.6       pacman_0.5.1     \n#&gt; [13] R.oo_1.27.0       pkgconfig_2.0.3   Matrix_1.7-1      lifecycle_1.0.4  \n#&gt; [17] compiler_4.4.2    farver_2.1.2      munsell_0.5.1     mnormt_2.1.1     \n#&gt; [21] carData_3.0-5     httpuv_1.6.15     htmltools_0.5.8.1 Formula_1.2-5    \n#&gt; [25] car_3.1-3         pillar_1.9.0      later_1.4.1       R.utils_2.12.3   \n#&gt; [29] abind_1.4-8       nlme_3.1-166      mime_0.12         tidyselect_1.2.1 \n#&gt; [33] digest_0.6.37     stringi_1.8.4     splines_4.4.2     labeling_0.4.3   \n#&gt; [37] rprojroot_2.0.4   fastmap_1.2.0     grid_4.4.2        colorspace_2.1-1 \n#&gt; [41] cli_3.6.3         magrittr_2.0.3    utf8_1.2.4        withr_3.0.2      \n#&gt; [45] promises_1.3.2    backports_1.5.0   timechange_0.3.0  rmarkdown_2.29   \n#&gt; [49] ggsignif_0.6.4    R.methodsS3_1.8.2 hms_1.1.3         shiny_1.9.1      \n#&gt; [53] evaluate_1.0.1    haven_2.5.4       miniUI_0.1.1.1    mgcv_1.9-1       \n#&gt; [57] rlang_1.1.4       Rcpp_1.0.13-1     xtable_1.8-4      glue_1.8.0       \n#&gt; [61] jsonlite_1.8.9    R6_2.5.1",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/00_lin_mod_frequentist.html#bibliografia",
    "href": "chapters/linear_models/00_lin_mod_frequentist.html#bibliografia",
    "title": "57  La regressione lineare bivariata: un approccio frequentista",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nCaudek, C., & Luccio, R. (2001). Statistica per psicologi (III rist. 2023, Vol. 11, p. 320). Laterza.\n\n\nFox, J. (2015). Applied regression analysis and generalized linear models. Sage publications.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.\n\n\nStigler, S. (1986). The History of Statistics. Belknap Harvard.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/00_lin_mod_frequentist.html#footnotes",
    "href": "chapters/linear_models/00_lin_mod_frequentist.html#footnotes",
    "title": "57  La regressione lineare bivariata: un approccio frequentista",
    "section": "",
    "text": "Per un approfondimento sull’approccio frequentista alla regressione, si veda, per esempio, Caudek & Luccio (2001).↩︎",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>La regressione lineare bivariata: un approccio frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayes.html",
    "href": "chapters/linear_models/01_reglin_bayes.html",
    "title": "58  Modello bayesiano di regressione lineare bivariata",
    "section": "",
    "text": "58.1 Introduzione\nIn questa sezione della dispensa, esploreremo il modello di regressione lineare bivariata bayesiano, confrontandolo con l’approccio frequentista. Questi modelli statistici sono impiegati principalmente per due finalità: inferenza e previsione. Mentre la previsione mira a descrivere le associazioni tra le variabili, l’inferenza si focalizza sul delineare relazioni causali tramite un modello lineare. È importante notare che, sebbene la capacità predittiva di un modello possa essere verificata empiricamente, l’uso della regressione per dedurre causalità richiede una rigorosa progettazione sperimentale o quasi-sperimentale, nonché una solida base di giustificazioni per le ipotesi utilizzate. Bisogna inoltre tenere presente che l’analisi di regressione costituisce una forma di media ponderata, e pertanto i suoi risultati possono essere influenzati da bias e specificità del dataset utilizzato.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayes.html#modello-di-regressione-bayesiano",
    "href": "chapters/linear_models/01_reglin_bayes.html#modello-di-regressione-bayesiano",
    "title": "58  Modello bayesiano di regressione lineare bivariata",
    "section": "58.2 Modello di Regressione Bayesiano",
    "text": "58.2 Modello di Regressione Bayesiano\nDopo aver confermato che il modello di regressione recupera in modo affidabile i valori teorici dell’intercetta e della pendenza della retta di regressione, procediamo ora ad applicare il modello a dataset reali. L’approccio bayesiano si distingue dai metodi dei minimi quadrati o della massima verosimiglianza in quanto non si limita a determinare i parametri che meglio si adattano ai dati osservati secondo un criterio prefissato. Al contrario, integra queste stime con informazioni a priori sui parametri stessi, combinando la verosimiglianza dei dati con una distribuzione a priori che rappresenta le ipotesi o le conoscenze preesistenti. In questo modo, l’inferenza bayesiana diventa un processo di aggiornamento delle credenze: la distribuzione a posteriori dei parametri riflette la conoscenza aggiornata dopo aver osservato i dati. A differenza dei metodi classici che forniscono stime puntuali, l’inferenza bayesiana produce distribuzioni a posteriori che esprimono la probabilità di ogni possibile valore dei parametri, considerando l’incertezza complessiva nel modello.\nNel contesto di un modello lineare bayesiano, adottiamo le seguenti convenzioni: le variabili di risposta sono indicate con \\(y\\), le variabili predittive (note anche come covariate o caratteristiche) con \\(x\\), e l’indice di osservazione con \\(i\\), che va da 1 al numero totale di osservazioni. La verosimiglianza di un semplice modello lineare (gaussiano) si può esprimere come:\n\\[\ny_i \\sim Normale(\\mu_i, \\sigma),\n\\]\ndove \\(\\mu_i = b_0 + b_1x_i\\). La distribuzione normale univariata è definita in termini di media e deviazione standard.\nNel modello bayesiano lineare, i parametri principali sono l’intercetta \\(b_0\\) e il coefficiente \\(b_1\\) associato alla variabile predittiva. Questi parametri insieme formano il predittore lineare \\(\\mu\\). Il parametro \\(\\sigma\\) rappresenta la deviazione standard residua, ovvero la variabilità che non può essere spiegata dal modello lineare e che cattura l’errore o il “rumore” presente nei dati.\nPer esempio, se desideriamo modellare la relazione tra ansia di stato (\\(y\\)) e Tense Arousal (\\(x\\)), l’approccio bayesiano permette di strutturare il modello in modo simile a quanto fatto con i metodi classici. Anche qui, si assume che gli errori siano indipendenti tra loro, distribuiti normalmente con media zero e varianza costante \\(\\sigma^2\\). Tuttavia, l’approccio bayesiano consente anche di specificare distribuzioni a priori per i parametri del modello (\\(b_0\\), \\(b_1\\), \\(\\sigma\\)), che rappresentano la conoscenza iniziale sui parametri prima di osservare i dati.\nDopo aver raccolto i dati, si utilizza il teorema di Bayes per aggiornare queste distribuzioni a priori e ottenere le distribuzioni a posteriori dei parametri. Le distribuzioni a posteriori combinano l’informazione fornita dai dati con le credenze iniziali, offrendo stime dei parametri che riflettono sia l’evidenza empirica che le conoscenze preesistenti, garantendo un’inferenza più robusta e flessibile.\n\n58.2.1 Verosimiglianza\nNel modello di regressione lineare bayesiano bivariato, la verosimiglianza che descrive la relazione tra ansia di stato (y) e Tense Arousal (x) assume che: \\[ y \\sim Normale(\\alpha + \\beta x, \\sigma) \\] Questo implica che i valori osservati di y sono distribuiti normalmente attorno alla retta di regressione \\(\\alpha + \\beta x\\), con una deviazione standard \\(\\sigma\\). In altre parole, ogni osservazione di y è una combinazione lineare dell’intercetta \\(\\alpha\\), del coefficiente \\(\\beta\\) che moltiplica la variabile predittiva x, e di un termine di errore distribuito normalmente.\n\n\n58.2.2 Distribuzioni a Priori\nPer implementare l’approccio bayesiano, definiamo delle distribuzioni a priori per i parametri \\(\\alpha\\), \\(\\beta\\), e \\(\\sigma\\). Anche se è possibile utilizzare delle distribuzioni a priori uniformi, che esprimono una mancanza di conoscenza specifica o una neutralità nelle credenze iniziali sui valori di questi parametri, questa pratica è scoraggiata. È invece consigliato, in assenza di informazioni preliminari, di utilizzare dei prior debolmente informativi:\n\\[ \\alpha \\sim \\mathcal{N}(0, 2.5), \\]\n\\[\n\\beta \\sim \\mathcal{N}(0, 2.5),\n\\]\n\\[\n\\sigma \\sim \\text{Cauchy}(0, 2.5)\n\\]\n\n\n58.2.3 Distribuzioni a Posteriori\nLe distribuzioni a posteriori sono ottenute combinando la verosimiglianza con le distribuzioni a priori mediante il teorema di Bayes. Queste distribuzioni a posteriori riflettono il nostro stato di conoscenza sui parametri dopo aver osservato i dati, incorporando sia le informazioni contenute nei dati che le credenze iniziali espresse dalle distribuzioni a priori. L’approccio bayesiano non solo fornisce stime dei parametri, ma anche una quantificazione dell’incertezza associata a queste stime, rendendo il metodo particolarmente utile in situazioni con dati limitati o incertezza rilevante.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayes.html#adattare-una-retta-di-regressione-a-dati-simulati",
    "href": "chapters/linear_models/01_reglin_bayes.html#adattare-una-retta-di-regressione-a-dati-simulati",
    "title": "58  Modello bayesiano di regressione lineare bivariata",
    "section": "58.3 Adattare una Retta di Regressione a Dati Simulati",
    "text": "58.3 Adattare una Retta di Regressione a Dati Simulati\nSimuliamo 200 osservazioni di \\(x\\) e \\(y\\), dove \\(y\\) è generato seguendo i parametri specificati. Questo ci permette di modellare e comprendere in modo più completo e robusto la relazione tra ansia di stato e Tense Arousal, integrando informazioni preesistenti con nuove evidenze empiriche.\nIn sintesi, il modello di regressione bayesiano può essere riassunto come segue. La verosimiglianza è data da:\n\\[\ny_i \\sim \\mathcal{N}(\\alpha + \\beta \\cdot x_i; \\sigma)\n\\]\nDefiniamo i parametri e simuliamo i dati.\n\nset.seed(123)\n\n# Definizione delle variabili\nx &lt;- 1:20\nn &lt;- length(x)\na &lt;- 0.2\nb &lt;- 0.3\nsigma &lt;- 0.5\n\n# Generazione di y\ny &lt;- a + b * x + sigma * rnorm(n)\n\n# Creazione del dataframe\nfake &lt;- tibble(x = x, y = y)\nhead(fake)\n#&gt; # A tibble: 6 × 2\n#&gt;       x     y\n#&gt;   &lt;int&gt; &lt;dbl&gt;\n#&gt; 1     1 0.220\n#&gt; 2     2 0.685\n#&gt; 3     3 1.88 \n#&gt; 4     4 1.44 \n#&gt; 5     5 1.76 \n#&gt; 6     6 2.86\n\nAdattiamo quindi ai dati un modello di regressione bayesiano utilizzando {cmdstanr}. Scriviamo il modello in un file Stan. Salviamo il file come linear-regression.stan e compiliamo il modello:\n\nmodel &lt;- cmdstan_model(\nhere::here(\"stan\", \"linear-regression.stan\")\n)\n\nIl modello ha questa forma:\n\nmodel$print()\n#&gt; // all data should be scaled to mean 0 and std 1:\n#&gt; data {\n#&gt;   int&lt;lower=1&gt; N;\n#&gt;   vector[N] x;\n#&gt;   vector[N] y;\n#&gt; }\n#&gt; parameters {\n#&gt;   real alpha;\n#&gt;   real beta;\n#&gt;   real&lt;lower=0&gt; sigma;\n#&gt; }\n#&gt; model {\n#&gt;   y ~ normal(alpha + beta * x, sigma);\n#&gt;   alpha ~ normal(0, 2.5);\n#&gt;   beta ~ normal(0, 2.5);\n#&gt;   sigma ~ cauchy(0, 2.5);\n#&gt; }\n#&gt; generated quantities {\n#&gt;   vector[N] log_lik;\n#&gt;   vector[N] y_rep;\n#&gt;   for (n in 1:N) {\n#&gt;     log_lik[n] = normal_lpdf(y[n] | alpha + beta * x[n], sigma);\n#&gt;     y_rep[n] = normal_rng(alpha + beta * x[n], sigma);\n#&gt;   }\n#&gt; }\n\nPrepariamo i dati nel formato appropriato per Stan:\n\nstan_data &lt;- list(\n  N = nrow(fake),\n  x = fake$x,\n  y = fake$y\n)\n\nEseguiamo il campionamento:\n\nfit &lt;- model$sample(\n  data = stan_data,\n  seed = 123,\n  iter_warmup = 2000,\n  iter_sampling = 2000,\n  show_message = FALSE\n)\n\nSintesi dei risultati:\n\nfit$summary(variables = c(\"alpha\", \"beta\", \"sigma\"))\n#&gt; # A tibble: 3 × 10\n#&gt;   variable  mean median     sd    mad      q5   q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 alpha    0.349  0.351 0.256  0.239  -0.0692 0.763  1.00    2650.    2722.\n#&gt; 2 beta     0.292  0.292 0.0213 0.0199  0.258  0.328  1.00    2727.    2404.\n#&gt; 3 sigma    0.535  0.518 0.102  0.0908  0.399  0.726  1.00    2914.    3110.\n\nDisegniamo un diagramma a dispersione con la retta di regressione stimata.\n\n# Estrazione dei parametri stimati\nposterior_summary &lt;- fit$summary(c(\"alpha\", \"beta\"))\nalpha_hat &lt;- posterior_summary$mean[1]\nbeta_hat &lt;- posterior_summary$mean[2]\n# Scatterplot con la retta di regressione\nggplot(fake, aes(x = x, y = y)) +\n  geom_point(color = \"blue\") +\n  geom_abline(intercept = alpha_hat, slope = beta_hat, color = \"red\") +\n  labs(\n  title = \"Scatterplot con Retta di Regressione Stimata\",\n  x = \"x\", \n  y = \"y\"\n)\n\n\n\n\n\n\n\n\nConfrontiamo le stime ottenute con i valori reali dei parametri simulati. L’intercetta è stata stimata attorno a 0.2, con un’incertezza che varia tra 0.15 e 0.30. Questo risultato rientra negli intervalli di credibilità previsti e non sorprende, confermando l’accuratezza del modello. Analogamente, per la pendenza \\(b\\), l’intervallo di credibilità al 95% include il valore reale simulato, dimostrando come le stime bayesiane riflettano accuratamente l’incertezza sui parametri, anche con campioni di dimensioni ridotte.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayes.html#funzione-brm-per-semplificare-linterazione-con-stan",
    "href": "chapters/linear_models/01_reglin_bayes.html#funzione-brm-per-semplificare-linterazione-con-stan",
    "title": "58  Modello bayesiano di regressione lineare bivariata",
    "section": "58.4 Funzione brm() per semplificare l’interazione con Stan",
    "text": "58.4 Funzione brm() per semplificare l’interazione con Stan\nPer facilitare l’interazione con Stan, senza dover utilizzare direttamente cmdstan, possiamo ricorrere a un’interfaccia di livello più alto: la funzione brm() del pacchetto brms. Questa funzione permette di definire e stimare modelli bayesiani in modo più immediato. Se non specificati, brm() utilizzerà dei prior non informativi per impostazione predefinita. Tuttavia, in questo esempio, impostiamo manualmente gli stessi prior dei parametri già utilizzati nel modello implementato con cmdstan, assicurando coerenza tra gli approcci.\n\nM1 &lt;- brm(\n  bf(y ~ 1 + x, center = FALSE), # Modello con intercetta (1) e covariata x\n  data = fake, # Dataframe contenente i dati\n  family = gaussian(), # Distribuzione della variabile dipendente\n  prior = c(\n    prior(normal(0, 2.5), class = \"b\", coef = \"Intercept\"), # Prior per alpha\n    prior(normal(0, 2.5), class = \"b\", coef = \"x\"), # Prior per beta\n    prior(cauchy(0, 2.5), class = \"sigma\") # Prior per sigma\n  ),\n  seed = 123, \n  backend = \"cmdstanr\"\n)\n\nLe stime a posteriori si possono visualizzare nel modo seguente:\n\nsummary(M1)\n#&gt;  Family: gaussian \n#&gt;   Links: mu = identity; sigma = identity \n#&gt; Formula: y ~ 1 + x \n#&gt;    Data: fake (Number of observations: 20) \n#&gt;   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#&gt;          total post-warmup draws = 4000\n#&gt; \n#&gt; Regression Coefficients:\n#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; Intercept     0.36      0.24    -0.12     0.82 1.00     1447     1704\n#&gt; x             0.29      0.02     0.25     0.33 1.00     1393     1615\n#&gt; \n#&gt; Further Distributional Parameters:\n#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#&gt; sigma     0.53      0.10     0.38     0.75 1.00     1633     1616\n#&gt; \n#&gt; Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential\n#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).\n\nSi osserva che le stime a posteriori ottenute sono molto simili a quelle fornite da CmdStan. Utilizzando le funzioni del pacchetto bayesplot, possiamo visualizzare le tracce dei parametri tramite la funzione traceplot. Questo strumento permette di esaminare graficamente la convergenza e la distribuzione delle stime nel corso delle iterazioni, facilitando l’analisi della qualità dell’inferenza bayesiana.\n\nmcmc_trace(M1)\n\n\n\n\n\n\n\n\nL’aspetto delle catene, simile a un “bruco sfocato” (fuzzy caterpillar), suggerisce che le catene si mescolano bene e convergono verso una distribuzione comune. Inoltre, possiamo valutare i valori di Rhat per ciascun parametro. È prassi comune considerare che valori di Rhat inferiori a 1.05 indicano una buona convergenza. Il pacchetto bayesplot facilita il calcolo di queste metriche, rendendo più accessibile l’analisi della convergenza delle stime.\n\nrhats &lt;- rhat(M1)\nmcmc_rhat(rhats)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayes.html#effective-sample-size-ess",
    "href": "chapters/linear_models/01_reglin_bayes.html#effective-sample-size-ess",
    "title": "58  Modello bayesiano di regressione lineare bivariata",
    "section": "58.5 Effective Sample Size (ESS)",
    "text": "58.5 Effective Sample Size (ESS)\nESS stima il numero di campioni indipendenti ottenuti dalla distribuzione a posteriori per un determinato parametro. Questo indicatore è fondamentale perché le catene di Markov possono presentare autocorrelazione, che potrebbe distorcere le stime dei parametri. Utilizzando il pacchetto bayesplot, possiamo visualizzare il rapporto tra la dimensione campionaria efficace e il numero totale di campioni raccolti. Un rapporto più alto suggerisce stime più affidabili. Una soglia critica è rappresentata da rapporti inferiori a 0.1, che potrebbero indicare potenziali problemi nelle stime.\n\neff_ratio &lt;- neff_ratio(M1)\nmcmc_neff(eff_ratio)\n\n\n\n\n\n\n\n\nInoltre, possiamo valutare l’autocorrelazione dei campioni per capire meglio nostre catene:\n\nmcmc_acf(M1)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayes.html#verifiche-predittive-a-posteriori",
    "href": "chapters/linear_models/01_reglin_bayes.html#verifiche-predittive-a-posteriori",
    "title": "58  Modello bayesiano di regressione lineare bivariata",
    "section": "58.6 Verifiche Predittive a Posteriori",
    "text": "58.6 Verifiche Predittive a Posteriori\nUn vantaggio particolarmente potente dell’inferenza bayesiana è la capacità di effettuare verifiche predittive a posteriori. Queste verifiche sono cruciali per valutare quanto accuratamente il nostro modello possa generare dati che somigliano a quelli osservati. Se il modello è correttamente specificato, i dati simulati a partire dalla distribuzione a posteriori dovrebbero riflettere fedelmente i dati reali, confermando così l’adeguatezza del modello.\n\npp_check(M1)\n#&gt; Using 10 posterior draws for ppc type 'dens_overlay' by default.\n\n\n\n\n\n\n\n\nMaggiore è la vicinanza tra i valori generati (\\(y_{rep}\\)) e i dati osservati (\\(y\\)), maggiore sarà l’adeguatezza del modello a rappresentare la realtà osservata.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayes.html#simulazione-di-livelli-di-copertura",
    "href": "chapters/linear_models/01_reglin_bayes.html#simulazione-di-livelli-di-copertura",
    "title": "58  Modello bayesiano di regressione lineare bivariata",
    "section": "58.7 Simulazione di Livelli di Copertura",
    "text": "58.7 Simulazione di Livelli di Copertura\nVerifichiamo la copertura degli intervalli di credibilità al 95% attraverso simulazioni ripetute.\n\nset.seed(42)\n# Parametri veri\na_true &lt;- 0.2\nb_true &lt;- 0.3\nsigma_true &lt;- 0.5\n# Numero di simulazioni\nnum_simulations &lt;- 1000\n# Conteggio delle coperture\ncoverage_a &lt;- 0\ncoverage_b &lt;- 0\nfor (i in 1:num_simulations) {\n  # Generazione dei dati\n  x &lt;- 1:20\n  y &lt;- a_true + b_true * x + sigma_true * rnorm(length(x))\n  # Adattamento del modello\n  fit &lt;- lm(y ~ x)\n  ci &lt;- confint(fit) # Intervalli di confidenza\n  # Verifica delle coperture\n  if (ci[1,1] &lt;= a_true & ci[1, 2] &gt;= a_true) {\n    coverage_a &lt;- coverage_a + 1\n  }\n  if (ci[2,1] &lt;= b_true & ci[2, 2] &gt;= b_true) {\n    coverage_b &lt;- coverage_b + 1\n  }\n}\n\n\n# Risultati\ncat(\"Coverage for a:\", coverage_a / num_simulations, \"\\n\")\n#&gt; Coverage for a: 0.952\ncat(\"Coverage for b:\", coverage_b / num_simulations, \"\\n\")\n#&gt; Coverage for b: 0.955\n\nI risultati mostrano che i livelli di copertura empirici dell’approccio frequentista si avvicinano a quelli teorici previsti.\n\n# Definizione dei parametri\nset.seed(23)\nn_fake &lt;- 1000\ncover_68 &lt;- rep(NA, n_fake)\ncover_95 &lt;- rep(NA, n_fake)\na &lt;- 0.2 # Intercetta vera\nb &lt;- 0.3 # Pendenza vera\nsigma &lt;- 0.5 # Deviazione standard vera\nx &lt;- 1:20 # Variabile indipendente\nn &lt;- length(x) # Numero di osservazioni\n\n# Ciclo per simulazioni\nfor (s in 1:n_fake) {\n  # Generazione dei dati\n  y &lt;- a + b * x + rnorm(n, 0, sigma)\n  fake &lt;- data.frame(x = x, y = y)\n\n  # Adattamento del modello con brms\n  fit &lt;- brm(\n    bf(y ~ 1 + x, center = FALSE),\n    data = fake,\n    family = gaussian(),\n    prior = c(\n      prior(normal(0, 2.5), class = \"b\", coef = \"Intercept\"), # Prior per alpha\n      prior(normal(0, 2.5), class = \"b\", coef = \"x\"), # Prior per beta\n      prior(cauchy(0, 2.5), class = \"sigma\") # Prior per sigma\n    ),\n    seed = 42,\n    iter = 2000, \n    chains = 2, \n    refresh = 0, # Suppress console output\n    backend = \"cmdstanr\"\n  )\n\n  # Estrazione dei coefficienti stimati e delle deviazioni standard\n  posterior_summary &lt;- summary(fit)$fixed\n  b_hat &lt;- posterior_summary[\"x\", \"Estimate\"]\n  b_se &lt;- posterior_summary[\"x\", \"Est.Error\"]\n\n  # Calcolo della copertura\n  cover_68[s] &lt;- abs(b - b_hat) &lt; b_se\n  cover_95[s] &lt;- abs(b - b_hat) &lt; 2 * b_se\n}\n\n\n# Summarize the coverage results\nmean_cover_68 &lt;- mean(cover_68, na.rm = TRUE)\nmean_cover_95 &lt;- mean(cover_95, na.rm = TRUE)\ncat(\"Coverage for 68% interval:\", mean_cover_68, \"\\n\")\n#&gt; Coverage for 68% interval: 0.701\ncat(\"Coverage for 95% interval:\", mean_cover_95, \"\\n\")\n#&gt; Coverage for 95% interval: 0.954\n\nQuesta seconda simulazione mostra come anche i livelli di copertura empirici dell’approccio bayesiano si avvicinano a quelli teorici previsti.\nQuesto conferma la validià degli intervalli stimati tramite il modello bayesiano e frequentista.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayes.html#confronti-non-effetti",
    "href": "chapters/linear_models/01_reglin_bayes.html#confronti-non-effetti",
    "title": "58  Modello bayesiano di regressione lineare bivariata",
    "section": "58.8 Confronti, non Effetti",
    "text": "58.8 Confronti, non Effetti\nGelman et al. (2021) sottolineano che i coefficienti di regressione sono spesso denominati “effetti”, ma questa terminologia può trarre in inganno. Gli “effetti”, infatti, implicano una relazione causale. Tuttavia, ciò che un modello di regressione stima non è necessariamente un effetto causale, ma piuttosto un pattern osservazionale. In particolare, ciò che osserviamo è che la media della variabile dipendente nella sottopopolazione con \\(X = x + 1\\) è spesso maggiore o minore (a seconda del segno di \\(\\beta\\)) rispetto alla media della sottopopolazione con \\(X = x\\).\nLa regressione è uno strumento matematico utilizzato principalmente per fare previsioni. I coefficienti di regressione devono quindi essere interpretati come confronti medi. Solo in circostanze specifiche, quando la regressione descrive un processo causale ben definito, è possibile interpretarli come effetti. Tuttavia, questa interpretazione causale deve essere giustificata dal disegno dello studio e non può essere dedotta unicamente dall’uso del modello statistico.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayes.html#riflessioni-conclusive",
    "href": "chapters/linear_models/01_reglin_bayes.html#riflessioni-conclusive",
    "title": "58  Modello bayesiano di regressione lineare bivariata",
    "section": "58.9 Riflessioni Conclusive",
    "text": "58.9 Riflessioni Conclusive\nIn questo capitolo, abbiamo adottato una prospettiva bayesiana per stimare i parametri di un modello di regressione bivariato, cogliendo l’opportunità di riflettere sulla natura e sul ruolo dei modelli statistici nella ricerca scientifica, e in particolare nell’ambito psicologico. Come sottolineato da Alexander (2023), i modelli statistici non sono strumenti per scoprire una verità assoluta, bensì mezzi per interpretare e dare significato ai dati a nostra disposizione. In questa ottica, i modelli non vanno intesi come riproduzioni fedeli della realtà, ma piuttosto come “lenti” che ci permettono di mettere a fuoco e comprendere, almeno in parte, il mondo che ci circonda.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayes.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/01_reglin_bayes.html#informazioni-sullambiente-di-sviluppo",
    "title": "58  Modello bayesiano di regressione lineare bivariata",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] rstan_2.32.6        StanHeaders_2.32.10 brms_2.22.0        \n#&gt;  [4] Rcpp_1.0.13-1       see_0.9.0           posterior_1.6.0    \n#&gt;  [7] cmdstanr_0.8.1.9000 MASS_7.3-61         viridis_0.6.5      \n#&gt; [10] viridisLite_0.4.2   ggpubr_0.6.0        ggExtra_0.10.1     \n#&gt; [13] gridExtra_2.3       patchwork_1.3.0     bayesplot_1.11.1   \n#&gt; [16] psych_2.4.6.26      scales_1.3.0        markdown_1.13      \n#&gt; [19] knitr_1.49          lubridate_1.9.3     forcats_1.0.0      \n#&gt; [22] stringr_1.5.1       dplyr_1.1.4         purrr_1.0.2        \n#&gt; [25] readr_2.1.5         tidyr_1.3.1         tibble_3.2.1       \n#&gt; [28] ggplot2_3.5.1       tidyverse_2.0.0     rio_1.2.3          \n#&gt; [31] here_1.0.1         \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] mnormt_2.1.1         inline_0.3.20        sandwich_3.1-1      \n#&gt;  [4] rlang_1.1.4          magrittr_2.0.3       multcomp_1.4-26     \n#&gt;  [7] matrixStats_1.4.1    compiler_4.4.2       loo_2.8.0           \n#&gt; [10] reshape2_1.4.4       vctrs_0.6.5          pkgconfig_2.0.3     \n#&gt; [13] fastmap_1.2.0        backports_1.5.0      labeling_0.4.3      \n#&gt; [16] utf8_1.2.4           promises_1.3.2       rmarkdown_2.29      \n#&gt; [19] tzdb_0.4.0           ps_1.8.1             xfun_0.49           \n#&gt; [22] jsonlite_1.8.9       later_1.4.1          broom_1.0.7         \n#&gt; [25] parallel_4.4.2       R6_2.5.1             stringi_1.8.4       \n#&gt; [28] car_3.1-3            estimability_1.5.1   zoo_1.8-12          \n#&gt; [31] pacman_0.5.1         splines_4.4.2        httpuv_1.6.15       \n#&gt; [34] Matrix_1.7-1         timechange_0.3.0     tidyselect_1.2.1    \n#&gt; [37] abind_1.4-8          yaml_2.3.10          codetools_0.2-20    \n#&gt; [40] miniUI_0.1.1.1       curl_6.0.1           processx_3.8.4      \n#&gt; [43] pkgbuild_1.4.5       plyr_1.8.9           lattice_0.22-6      \n#&gt; [46] shiny_1.9.1          withr_3.0.2          bridgesampling_1.1-2\n#&gt; [49] coda_0.19-4.1        evaluate_1.0.1       survival_3.7-0      \n#&gt; [52] RcppParallel_5.1.9   pillar_1.9.0         carData_3.0-5       \n#&gt; [55] tensorA_0.36.2.1     stats4_4.4.2         checkmate_2.3.2     \n#&gt; [58] distributional_0.5.0 generics_0.1.3       rprojroot_2.0.4     \n#&gt; [61] hms_1.1.3            rstantools_2.4.0     munsell_0.5.1       \n#&gt; [64] xtable_1.8-4         glue_1.8.0           emmeans_1.10.5      \n#&gt; [67] tools_4.4.2          data.table_1.16.2    ggsignif_0.6.4      \n#&gt; [70] mvtnorm_1.3-2        grid_4.4.2           QuickJSR_1.4.0      \n#&gt; [73] colorspace_2.1-1     nlme_3.1-166         Formula_1.2-5       \n#&gt; [76] cli_3.6.3            fansi_1.0.6          Brobdingnag_1.2-9   \n#&gt; [79] V8_6.0.0             gtable_0.3.6         rstatix_0.7.2       \n#&gt; [82] digest_0.6.37        TH.data_1.1-2        htmlwidgets_1.6.4   \n#&gt; [85] farver_2.1.2         htmltools_0.5.8.1    lifecycle_1.0.4     \n#&gt; [88] mime_0.12",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayes.html#bibliografia",
    "href": "chapters/linear_models/01_reglin_bayes.html#bibliografia",
    "title": "58  Modello bayesiano di regressione lineare bivariata",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAlexander, R. (2023). Telling Stories with Data: With Applications in R. Chapman; Hall/CRC.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/causal_inference/01_rct.html",
    "href": "chapters/causal_inference/01_rct.html",
    "title": "59  Trial controllati randomizzati",
    "section": "",
    "text": "Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nPreparazione del Notebook\nNel campo della psicologia, come in molte altre discipline scientifiche, la ricerca della causalità è fondamentale per comprendere i fenomeni umani e sviluppare interventi efficaci. Mentre la filosofia ha dibattuto per secoli sulla natura della causalità, la ricerca moderna ha fornito strumenti pratici per affrontare questa questione complessa. Tra questi, i trial controllati randomizzati (RCT) emergono come un metodo particolarmente potente e affidabile.\nGli RCT rappresentano un ponte tra la complessità teorica della causalità e la sua applicazione pratica nella ricerca. Questo approccio, pionieristicamente sviluppato da studiosi come Neyman (1923) e Rubin (1974), permette ai ricercatori di stabilire relazioni causali con un alto grado di confidenza, grazie all’uso attento della randomizzazione e dell’analisi statistica.\nQuesto capitolo, che segue la trattazione presentata nel testo Causal Inference: A Statistical Learning Approach di Stefan Wager, offre una panoramica sintetica delle stime statistiche e dell’inferenza nei trial controllati randomizzati. Quando disponibili, le prove derivate dagli RCT sono spesso considerate il “gold standard” delle evidenze statistiche; pertanto, i metodi per studiare gli RCT costituiscono la base degli strumenti statistici per l’inferenza causale. Inoltre, molti dei disegni di studio osservazionali ampiamente utilizzati, anche in psicologia, si ispirano agli RCT. Di conseguenza, questo capitolo funge anche da punto di partenza per le discussioni successive sulle stime e sull’inferenza negli studi osservazionali.",
    "crumbs": [
      "Causalità",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Trial controllati randomizzati</span>"
    ]
  },
  {
    "objectID": "chapters/causal_inference/01_rct.html#concetti-fondamentali-negli-rct",
    "href": "chapters/causal_inference/01_rct.html#concetti-fondamentali-negli-rct",
    "title": "59  Trial controllati randomizzati",
    "section": "59.1 Concetti Fondamentali negli RCT",
    "text": "59.1 Concetti Fondamentali negli RCT\n\n59.1.1 Effetti del Trattamento\nNel contesto degli RCT in psicologia, il “trattamento” potrebbe essere un intervento terapeutico, un programma educativo, o qualsiasi altra variabile manipolata dai ricercatori. L’obiettivo principale è determinare l’effetto di questo trattamento su una o più variabili di risultato.\n\n\n59.1.2 Effetti medi del trattamento (ATE e SATE)\nQuando si vuole studiare l’effetto di un trattamento, una delle sfide principali è quella di capire come cambierebbe l’outcome se a una persona venisse somministrato un trattamento diverso da quello effettivamente ricevuto. Questo concetto è formalizzato nell’effetto causale individuale, che è la differenza tra il risultato osservabile se una persona riceve il trattamento (\\(Y_i(1)\\)) e il risultato se non lo riceve (\\(Y_i(0)\\)). Questa differenza si esprime come:\n\\[\n\\theta_i = Y_i(1) - Y_i(0).\n\\]\nTuttavia, poiché per ogni individuo possiamo osservare solo uno di questi due risultati (non possiamo sapere cosa sarebbe successo se avessero ricevuto un trattamento diverso), non possiamo mai conoscere direttamente l’effetto individuale.\nPer superare questo problema, si ricorre alla media degli effetti del trattamento su un gruppo di persone, ovvero all’effetto medio del trattamento. Questo può essere definito in due modi:\n\nEffetto Medio Campionario del Trattamento (SATE - Sample Average Treatment Effect), che è la media degli effetti del trattamento nel campione:\n\n\\[\n\\hat{\\theta} = \\frac{1}{n} \\sum_{i=1}^{n} (Y_i(1) - Y_i(0)).\n\\]\n\nEffetto Medio del Trattamento nella Popolazione (ATE - Average Treatment Effect), che è la media dell’effetto del trattamento in un’intera popolazione da cui è tratto il campione:\n\n\\[\n\\tau = \\mathbb{E}_P[Y_i(1) - Y_i(0)].\n\\]\nQueste definizioni permettono di stimare l’effetto medio del trattamento anche senza osservare gli effetti individuali per ogni persona.\n\n\n59.1.3 Stima tramite differenza delle medie\nUn metodo comune per stimare l’ATE in un trial randomizzato è usare la differenza tra le medie degli outcome tra il gruppo trattato e il gruppo di controllo. Questo metodo funziona in modo molto intuitivo: calcoliamo la media dei risultati per il gruppo che ha ricevuto il trattamento e la media per il gruppo che non l’ha ricevuto, quindi sottraiamo queste due medie:\n\\[\n\\hat{\\tau}_{DM} = \\frac{1}{n_1} \\sum_{i: W_i = 1} Y_i - \\frac{1}{n_0} \\sum_{i: W_i = 0} Y_i,\n\\]\ndove \\(n_1\\) è il numero di individui che hanno ricevuto il trattamento (gruppo trattato) e \\(n_0\\) è il numero di individui che non lo hanno ricevuto (gruppo di controllo).\nQuesto stimatore è non distorto se il trattamento è stato assegnato in modo casuale. Ciò significa che, in media, la stima dell’ATE fornita dalla differenza delle medie sarà corretta.\n\n\n59.1.4 Teorema del limite centrale e intervalli di confidenza\nPer dare una misura dell’incertezza della stima dell’ATE in termini frequentisti, possiamo applicare il teorema del limite centrale (TLC). Questo teorema afferma che, se il campione è sufficientemente grande e i partecipanti sono selezionati in modo indipendente da una popolazione, la distribuzione della stima dell’ATE tende a seguire una distribuzione normale, con media pari all’ATE vero e una certa varianza:\n\\[\n\\sqrt{n} (\\hat{\\tau}_{DM} - \\tau) \\sim N(0, V_{DM}),\n\\]\ndove \\(V_{DM}\\) rappresenta la varianza asintotica della differenza tra le medie. Questo ci permette di costruire un intervallo di confidenza per l’ATE:\n\\[\n\\hat{\\tau}_{DM} \\pm z_{\\alpha/2} \\sqrt{\\frac{\\hat{V}_{DM}}{n}}.\n\\]\nQui, \\(z_{\\alpha/2}\\) è il valore critico dalla distribuzione normale standard (ad esempio, per un livello di confidenza del 95%, \\(z_{0.025} = 1.96\\)). L’intervallo di confidenza fornisce una stima dell’ATE insieme a una misura della sua incertezza. Se l’intervallo è stretto, abbiamo una maggiore fiducia nella stima; se è largo, la stima è più incerta.\n\n\n59.1.5 Aggiustamenti per regressione\nGli aggiustamenti per regressione permettono di migliorare la precisione della stima dell’ATE includendo informazioni aggiuntive, come covariate pre-trattamento, nel modello. L’idea di base è che, oltre al trattamento, altre variabili (covariate) potrebbero influenzare l’outcome. Quindi, includere queste covariate può aiutarci a spiegare meglio le differenze negli outcome e a ridurre la varianza della stima dell’ATE.\nVediamo passo per passo come funziona:\n\n59.1.5.1 Modello di regressione con covariate\nSi usa una regressione lineare che modella l’outcome \\(Y_i\\) in funzione del trattamento \\(W_i\\) e delle covariate \\(X_i\\):\n\\[\nY_i = \\alpha + W_i \\tau + X_i \\beta + W_i X_i \\gamma + \\epsilon_i,\n\\]\n\n\\(Y_i\\): l’outcome dell’individuo \\(i\\).\n\\(W_i\\): il trattamento (1 se l’individuo è trattato, 0 se non lo è).\n\\(X_i\\): le covariate pre-trattamento (es. età, genere).\n\\(\\alpha\\): l’intercetta, cioè il valore dell’outcome medio quando \\(W_i = 0\\) e \\(X_i = 0\\).\n\\(\\tau\\): il parametro che rappresenta l’effetto medio del trattamento (ATE), che vogliamo stimare.\n\\(\\beta\\): il vettore di parametri associati alle covariate, che misura quanto le covariate influenzano l’outcome.\n\\(\\gamma\\): il vettore di parametri di interazione tra trattamento e covariate (cioè quanto l’effetto del trattamento varia in funzione delle covariate).\n\\(\\epsilon_i\\): l’errore, che rappresenta le variazioni non spiegate dal modello.\n\n\n\n59.1.5.2 Aggiustamento per covariate\nLa regressione permette di aggiustare gli outcome per le covariate \\(X_i\\), separando l’effetto delle covariate dall’effetto del trattamento. Questo è utile perché riduce la “rumorosità” dei dati e rende più facile identificare l’effetto del trattamento \\(\\tau\\).\n\n\n59.1.5.3 Stima dell’ATE\nUna volta stimati i coefficienti del modello tramite una regressione (solitamente con il metodo dei minimi quadrati), possiamo calcolare la stima dell’ATE.\nIl trucco è che possiamo usare i risultati della regressione per predire quale sarebbe stato l’outcome di ciascun individuo sotto entrambi i livelli del trattamento (\\(W_i = 1\\) e \\(W_i = 0\\)):\n\nPer stimare l’outcome atteso se tutti gli individui fossero trattati (\\(W_i = 1\\)):\n\\[\n\\hat{Y}_i(1) = \\hat{\\alpha}(1) + X_i \\hat{\\beta}(1).\n\\]\nPer stimare l’outcome atteso se nessun individuo fosse trattato (\\(W_i = 0\\)):\n\\[\n\\hat{Y}_i(0) = \\hat{\\alpha}(0) + X_i \\hat{\\beta}(0).\n\\]\n\ndove:\n\n\\(\\hat{\\alpha}(1)\\) e \\(\\hat{\\alpha}(0)\\) sono gli intercept stimati per i trattati e non trattati.\n\\(\\hat{\\beta}(1)\\) e \\(\\hat{\\beta}(0)\\) sono i coefficienti stimati per le covariate nei due gruppi.\n\nL’effetto medio del trattamento (ATE) si ottiene quindi come la differenza media tra questi due outcome previsti:\n\\[\n\\hat{\\tau}_{IREG} = \\frac{1}{n} \\sum_{i=1}^{n} \\left[ \\hat{Y}_i(1) - \\hat{Y}_i(0) \\right].\n\\]\nIn pratica, l’algoritmo di regressione ti permette di stimare quale sarebbe stato l’outcome atteso per ciascun individuo se fossero stati trattati o meno, tenendo conto delle loro caratteristiche (covariate). La differenza media tra questi due scenari fornisce una stima più precisa dell’ATE.\n\n\n59.1.5.4 Vantaggio dell’aggiustamento\nL’uso delle covariate nel modello aiuta a ridurre la varianza della stima dell’ATE, poiché le covariate possono spiegare parte della variabilità negli outcome. Ciò significa che, rispetto al semplice confronto delle medie tra trattati e non trattati, l’aggiustamento per covariate porta a una stima più precisa, soprattutto quando le covariate hanno una forte influenza sugli outcome.\nIn conclusione, l’aggiustamento per regressione permette di stimare l’ATE in modo più efficiente, migliorando la precisione senza introdurre distorsioni, anche quando la relazione tra le covariate e gli outcome non è perfettamente lineare.\n\n\n\n59.1.6 Confronto tra stimatori\nIl metodo della differenza delle medie è semplice da implementare, ma non ottimale in termini di efficienza statistica, poiché non sfrutta completamente le informazioni disponibili. Al contrario, l’aggiustamento per regressione migliora l’efficienza statistica riducendo la varianza della stima, senza introdurre distorsioni. In particolare, lo stimatore con regressione può essere sempre uguale o migliore (in termini di varianza) rispetto alla differenza delle medie, e questa riduzione della varianza diventa più significativa quando le covariate hanno una forte influenza sugli outcome.\nIn sintesi, l’uso della regressione per aggiustare i risultati è vantaggioso perché permette di utilizzare tutte le informazioni disponibili (inclusi i dati pre-trattamento), migliorando la precisione delle stime senza compromettere la validità delle inferenze.\nQuesti concetti sono fondamentali per comprendere come condurre inferenze causali in modo robusto, specialmente nei contesti sperimentali come i trial randomizzati.",
    "crumbs": [
      "Causalità",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Trial controllati randomizzati</span>"
    ]
  },
  {
    "objectID": "chapters/causal_inference/01_rct.html#simulazione",
    "href": "chapters/causal_inference/01_rct.html#simulazione",
    "title": "59  Trial controllati randomizzati",
    "section": "59.2 Simulazione",
    "text": "59.2 Simulazione\nIn questo esempio, supponiamo di avere:\n\nUna variabile di trattamento (0 o 1),\nDue covariate (\\(X_1\\), \\(X_2\\)) che influenzano l’outcome,\nUn effetto causale del trattamento.\n\nUseremo una regressione per stimare l’ATE aggiustando per le covariate.\n\n# Imposta il seme per la riproducibilità\nnp.random.seed(42)\n\n# Numero di osservazioni\nn = 500\n\n# Generiamo due covariate indipendenti\nX1 = np.random.normal(50, 10, size=n)  # Covariata 1\nX2 = np.random.normal(30, 5, size=n)  # Covariata 2\n\n# Variabile di trattamento casuale (0 o 1)\ntreatment = np.random.binomial(1, 0.5, size=n)\n\n# Effetti veri delle covariate sugli outcome\nbeta_X1 = 2.0\nbeta_X2 = -1.5\n\n# Effetto del trattamento sull'outcome\ntreatment_effect = 5.0\n\n# Generiamo l'outcome vero includendo il trattamento e le covariate\n# Outcome simulato: Y = 5*T + 2*X1 - 1.5*X2 + errore\noutcome = (\n    treatment_effect * treatment\n    + beta_X1 * X1\n    + beta_X2 * X2\n    + np.random.normal(0, 5, size=n)\n)\n\n# Creiamo un DataFrame per contenere i dati\ndata = pd.DataFrame({\"Treatment\": treatment, \"X1\": X1, \"X2\": X2, \"Outcome\": outcome})\n\n# Mostra un'anteprima dei dati\nprint(data.head())\n\n   Treatment         X1         X2    Outcome\n0          0  54.967142  34.630888  56.161344\n1          0  48.617357  39.547083  38.837491\n2          1  56.476885  23.007162  76.707396\n3          1  65.230299  32.814846  81.380258\n4          0  47.658466  26.746787  61.198821\n\n\n\n59.2.1 Stima dell’ATE senza aggiustamento (Differenza tra le medie)\nLa differenza tra le medie può essere calcolata confrontando l’outcome medio per il gruppo trattato e il gruppo non trattato.\n\n# Calcolo della differenza tra le medie\nmean_treated = data[data[\"Treatment\"] == 1][\"Outcome\"].mean()\nmean_control = data[data[\"Treatment\"] == 0][\"Outcome\"].mean()\n\nate_naive = mean_treated - mean_control\nprint(f\"ATE senza aggiustamento (differenza tra le medie): {ate_naive:.2f}\")\n\nATE senza aggiustamento (differenza tra le medie): 9.59\n\n\n\n\n59.2.2 Aggiustamento per regressione\nOra eseguiamo una regressione lineare che include il trattamento e le covariate. Utilizziamo pingouin o statsmodels per eseguire la regressione e stimare l’ATE.\n\n# Aggiunta di un'intercetta al modello\nX = sm.add_constant(data[[\"Treatment\", \"X1\", \"X2\"]])\n\n# Eseguiamo la regressione con statsmodels\nmodel = sm.OLS(data[\"Outcome\"], X).fit()\n\n# Mostriamo i risultati della regressione\nprint(model.summary())\n\n# Estrarre il coefficiente del trattamento, che rappresenta l'ATE aggiustato\nate_adjusted = model.params[\"Treatment\"]\nprint(f\"\\nATE con aggiustamento per le covariate: {ate_adjusted:.2f}\")\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                Outcome   R-squared:                       0.952\nModel:                            OLS   Adj. R-squared:                  0.951\nMethod:                 Least Squares   F-statistic:                     3261.\nDate:                Sat, 21 Sep 2024   Prob (F-statistic):               0.00\nTime:                        08:18:33   Log-Likelihood:                -1501.2\nNo. Observations:                 500   AIC:                             3010.\nDf Residuals:                     496   BIC:                             3027.\nDf Model:                           3                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -0.0830      1.843     -0.045      0.964      -3.704       3.538\nTreatment      5.9935      0.439     13.648      0.000       5.131       6.856\nX1             1.9780      0.022     88.112      0.000       1.934       2.022\nX2            -1.4672      0.045    -32.658      0.000      -1.555      -1.379\n==============================================================================\nOmnibus:                        0.174   Durbin-Watson:                   1.952\nProb(Omnibus):                  0.917   Jarque-Bera (JB):                0.263\nSkew:                          -0.033   Prob(JB):                        0.877\nKurtosis:                       2.910   Cond. No.                         498.\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\nATE con aggiustamento per le covariate: 5.99\n\n\n\n\n59.2.3 Interpretazione dei risultati\n\nATE senza aggiustamento (Differenza tra le medie): Questa stima riflette l’effetto medio del trattamento senza tener conto delle covariate.\nATE con aggiustamento per covariate: Questa stima corregge per le differenze nelle covariate \\(X_1\\) e \\(X_2\\) tra i gruppi trattati e non trattati, fornendo una stima più precisa dell’effetto causale del trattamento (nella popolazione, l’ATE simulato era pari a 5).\n\nQuesto esempio mostra come possiamo simulare una popolazione con covariate che influenzano l’outcome e come utilizzare una regressione per aggiustare queste covariate quando stimiamo l’effetto del trattamento (ATE).",
    "crumbs": [
      "Causalità",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Trial controllati randomizzati</span>"
    ]
  },
  {
    "objectID": "chapters/causal_inference/01_rct.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/causal_inference/01_rct.html#informazioni-sullambiente-di-sviluppo",
    "title": "59  Trial controllati randomizzati",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Wed Jul 17 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\npandas    : 2.2.2\nscipy     : 1.14.0\nseaborn   : 0.13.2\narviz     : 0.18.0\nmatplotlib: 3.9.1\nnumpy     : 1.26.4\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nNeyman, J. (1923). Sur les applications de la théorie des probabilités aux experiences agricoles: Essai des principes. Roczniki Nauk Rolniczych, 10(1), 1–51.\n\n\nRubin, D. B. (1974). Estimating causal effects of treatments in randomized and nonrandomized studies. Journal of educational Psychology, 66(5), 688–701.",
    "crumbs": [
      "Causalità",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Trial controllati randomizzati</span>"
    ]
  },
  {
    "objectID": "chapters/glm/introduction_glm.html",
    "href": "chapters/glm/introduction_glm.html",
    "title": "Introduzione",
    "section": "",
    "text": "In questa sezione esploreremo i modelli statistici che vanno oltre la regressione lineare, ossia quelli che fanno ipotesi distributive non gaussiane per la componente stocastica del modello, considerano una relazione non lineare tra il valore atteso della variabile di risposta e i predittori, e indeboliscono l’assunzione di indipendenza tra le osservazioni.",
    "crumbs": [
      "GLM",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/entropy/introduction_entropy.html",
    "href": "chapters/entropy/introduction_entropy.html",
    "title": "Introduzione",
    "section": "",
    "text": "In questa sezione della dispensa, esploreremo il tema cruciale della validazione di un modello statistico e del confronto tra modelli. Vedremo come sia necessario trovare un equilibrio tra due dimensioni: la capacità del modello di predire accuratamente i dati osservati nel campione e la sua capacità di generalizzarsi a campioni diversi.",
    "crumbs": [
      "Entropia",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html",
    "href": "chapters/entropy/01_entropy.html",
    "title": "60  Entropia",
    "section": "",
    "text": "60.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nIn questo capitolo, descriveremo il concetto di entropia, una misura fondamentale sviluppata nell’ambito della teoria dell’informazione. L’entropia ci permette di quantificare l’incertezza associata a una distribuzione di probabilità e, di conseguenza, la quantità di informazione che un evento ci fornisce.\nL’entropia è legata alla nostra capacità di prevedere l’esito di un evento: più un risultato è imprevedibile, maggiore sarà l’entropia. In termini più generali, l’entropia di una variabile casuale misura quanto è incerto o “sorprendente” il valore che essa assumerà in media. Se ogni possibile esito ha la stessa probabilità di verificarsi, l’entropia sarà massima. Se invece alcuni esiti sono molto più probabili di altri, l’entropia diminuirà, poiché l’incertezza complessiva è ridotta.\nUn’intuizione sull’entropia può essere ottenuta considerando il seguente esempio. Pensiamo a un sacchetto di palline colorate. Se il sacchetto contiene solo palline di un unico colore, possiamo essere sicuri di quale pallina estrarremo ogni volta. Non c’è alcuna incertezza o sorpresa, quindi l’entropia è pari a zero. Tuttavia, se il sacchetto contiene un numero uguale di palline di diversi colori, ogni estrazione è un’incognita: l’incertezza è massima e, di conseguenza, lo è anche l’entropia.\nIl concetto di entropia va ben oltre questo semplice esempio. Esso si applica a qualunque situazione in cui ci sia un insieme di risultati possibili con probabilità diverse. In questo capitolo, ci concentreremo sul significato matematico dell’entropia, esplorando come può essere calcolata per diverse distribuzioni di probabilità e come essa si collega alla quantità di informazione che un sistema può fornire. Inizieremo con esempi semplici, come l’entropia di una moneta equa o di un dado, per poi estendere il concetto a situazioni più complesse.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#introduzione",
    "href": "chapters/entropy/01_entropy.html#introduzione",
    "title": "60  Entropia",
    "section": "",
    "text": "Information is the resolution of uncertainty.\n(Shannon C, 1948)",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#che-cosè-linformazione",
    "href": "chapters/entropy/01_entropy.html#che-cosè-linformazione",
    "title": "60  Entropia",
    "section": "60.2 Che cos’è l’Informazione?",
    "text": "60.2 Che cos’è l’Informazione?\nL’informazione è solitamente misurata in bit, e un bit di informazione permette di scegliere tra due alternative ugualmente probabili. La parola bit deriva da binary digit (cioè uno zero o un uno).\nPer capire come l’informazione possa essere misurata in bit, consideriamo il seguente esempio discusso da Stone (2022). Immagina di trovarti ad un incrocio e di dover scegliere una strada tra due possibilità. Ogni volta che incontri un incrocio, devi prendere una decisione: andare a destra o a sinistra. Ogni decisione può essere rappresentata da un bit di informazione: 0 per sinistra, 1 per destra.\nConsideriamo un percorso con più incroci, come quello rappresentato nell’immagine. Ogni percorso completo può essere codificato da una sequenza di bit, dove ogni bit corrisponde ad una decisione presa in un incrocio. Ad esempio, per raggiungere il punto D011, la sequenza di bit corretta è 011.\n\n# Definizione degli archi e delle etichette\nedges &lt;- data.frame(\n  from = c(\n    \"A\", \"A\", \"B0\", \"B0\", \"B1\", \"B1\",\n    \"C00\", \"C00\", \"C01\", \"C01\", \"C10\", \"C10\", \"C11\", \"C11\"\n  ),\n  to = c(\n    \"B0\", \"B1\", \"C00\", \"C01\", \"C10\", \"C11\",\n    \"D000\", \"D001\", \"D010\", \"D011\", \"D100\", \"D101\", \"D110\", \"D111\"\n  ),\n  label = c(\n    \"0\", \"1\", \"0\", \"1\", \"0\", \"1\",\n    \"0\", \"1\", \"0\", \"1\", \"0\", \"1\", \"0\", \"1\"\n  )\n)\n\n# Creazione del grafo diretto\nG &lt;- graph_from_data_frame(edges, directed = TRUE)\n\n# Visualizzazione del grafo usando ggraph\nggraph(G, layout = \"dendrogram\", circular = FALSE) +\n  geom_edge_link(\n    aes(label = label),\n    angle_calc = \"along\", label_dodge = unit(2, \"mm\"),\n    arrow = arrow(length = unit(4, \"mm\"), type = \"closed\")\n  ) +\n  geom_node_point(size = 5, color = \"lightblue\") +\n  geom_node_text(aes(label = name), repel = TRUE, size = 3.5) +\n  labs(title = \"Albero delle possibilità per 3 bit di informazione\") +\n  theme(plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"))\n\n\n\n\n\n\n\n\nQuanti bit sono necessari per identificare una destinazione specifica?\nOgni bit raddoppia il numero di possibili percorsi. Quindi, se abbiamo \\(n\\) bit, possiamo identificare \\(2^n\\) destinazioni distinte. Viceversa, se conosciamo il numero di destinazioni \\(m\\), possiamo calcolare il numero di bit necessari utilizzando la formula:\n\\[\nn = \\log_2 m.\n\\]\nNel nostro esempio, abbiamo 8 destinazioni finali. Pertanto, sono necessari \\(\\log_2 8 = 3\\) bit per identificarne una in modo univoco.\nCosa rappresenta un bit in questo contesto?\nUn bit rappresenta un’unità elementare di informazione. In questo caso, ogni bit risponde alla domanda: “Devo andare a destra o a sinistra?”.\nPerché utilizziamo i logaritmi?\nIl logaritmo in base 2 ci permette di calcolare l’esponente a cui elevare 2 per ottenere un dato numero. In altre parole, ci dice quanti bit sono necessari per rappresentare un certo numero di destinazioni. Per l’esempio considerato, per arrivare a \\(D011\\) partendo da \\(A\\), sono necessarie 3 domande la cui risposta binaria è destra/sinistra.\nIn sintesi, esiste una relazione diretta tra il numero di bit di informazione e il numero di possibili destinazioni in un percorso decisionale binario. Ogni bit ci permette di fare una scelta tra due alternative, raddoppiando così il numero di possibili percorsi.\nPer ricapitolare:\n\nAbbiamo visto che per raggiungere il punto D011 partendo da A, abbiamo bisogno di prendere tre decisioni binarie (sinistra o destra) in corrispondenza di tre incroci.\nOgni decisione binaria può essere rappresentata da un bit (0 o 1). Quindi, per l’intero percorso, abbiamo bisogno di una sequenza di tre bit: 011.\nPer rispondere alla domanda “Come andare da A a D011?”, abbiamo dunque bisogno di 3 bit di informazione.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#la-sorpresa-e-linformazione-di-shannon",
    "href": "chapters/entropy/01_entropy.html#la-sorpresa-e-linformazione-di-shannon",
    "title": "60  Entropia",
    "section": "60.3 La Sorpresa e l’Informazione di Shannon",
    "text": "60.3 La Sorpresa e l’Informazione di Shannon\nNel primo esempio, abbiamo visto come l’informazione possa essere misurata in bit, dove ogni bit corrisponde a una decisione binaria che ci aiuta a raggiungere una destinazione specifica in un percorso. Tuttavia, la quantità di informazione può variare anche in base alla probabilità con cui certi eventi o scelte si verificano. È qui che entra in gioco il concetto di informazione di Shannon, che prende in considerazione la sorpresa associata a un risultato.\nImmaginiamo, ad esempio, di avere una moneta che cade testa il 90% delle volte. Poiché il risultato “testa” è molto probabile, non ci sorprenderebbe molto ottenerlo. Al contrario, il risultato “croce”, che accade solo il 10% delle volte, ci sorprenderà di più. Più improbabile è un risultato, maggiore sarà la sorpresa nel vederlo.\nIn termini di informazione, possiamo dire che risultati meno probabili forniscono più informazione, perché ci sorprendono di più. Una prima idea per misurare questa sorpresa è definirla come inversamente proporzionale alla probabilità del risultato: \\(1/p(x)\\). Tuttavia, Shannon ha dimostrato che è più utile esprimere la sorpresa come il logaritmo di \\(1/p(x)\\). Questo ci porta alla definizione dell’informazione di Shannon, che si misura in bit (se usiamo il logaritmo in base 2, lo stesso utilizzato per misurare i percorsi nel primo esempio). L’informazione di Shannon per un risultato \\(x\\) è quindi:\n\\[\nh(x) = \\log_2 \\frac{1}{p(x)} = -\\log_2 p(x) \\text{ bit}.\n\\tag{60.1}\\]\nIn questo modo, vediamo che l’informazione associata a un evento dipende dalla sua probabilità: eventi meno probabili portano più informazione, e viceversa.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#sorpresa-e-probabilità",
    "href": "chapters/entropy/01_entropy.html#sorpresa-e-probabilità",
    "title": "60  Entropia",
    "section": "60.4 Sorpresa e Probabilità",
    "text": "60.4 Sorpresa e Probabilità\nPer comprendere pienamente la sorpresa, dobbiamo conoscere le probabilità dei diversi risultati. Questo significa che l’informazione di Shannon dipende dalla distribuzione di probabilità \\(p(X)\\) della variabile aleatoria \\(X\\). In altre parole, per misurare quanta informazione otteniamo da un risultato, dobbiamo sapere quanto è probabile ciascun possibile esito.\nUn modo per stimare queste probabilità è osservare i risultati di un esperimento ripetuto nel tempo. Utilizzando le osservazioni, possiamo stimare la probabilità di ciascun risultato e quindi calcolare l’informazione di Shannon associata. Questo approccio ci permette di collegare il concetto di informazione misurata in bit (come nel primo esempio sugli incroci) con la sorpresa generata da eventi più o meno probabili.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#entropia-come-media-dellinformazione-di-shannon",
    "href": "chapters/entropy/01_entropy.html#entropia-come-media-dellinformazione-di-shannon",
    "title": "60  Entropia",
    "section": "60.5 Entropia come Media dell’Informazione di Shannon",
    "text": "60.5 Entropia come Media dell’Informazione di Shannon\nQuando si lavora con fenomeni aleatori, spesso non ci interessa solo la sorpresa associata a un singolo risultato, ma piuttosto la sorpresa media che si può ottenere considerando tutti i possibili risultati di una variabile. Questa sorpresa media è chiamata entropia e si indica con \\(H(X)\\). L’entropia ci dà una misura della quantità di incertezza (o informazione potenziale) contenuta in una variabile aleatoria \\(X\\), la cui distribuzione di probabilità è data da \\(p(X)\\).\nL’entropia rappresenta quindi la quantità media di informazione che otteniamo osservando i risultati della variabile \\(X\\). Se, ad esempio, lanciamo una moneta molte volte, l’entropia della distribuzione dei risultati riflette la media delle informazioni di Shannon ottenute da ciascun lancio. In altre parole, ci dice quanto ci aspettiamo di “imparare” in media da ogni lancio.\nMatematicamente, l’entropia può essere approssimata dalla media delle informazioni di Shannon associate a ciascun possibile risultato \\(x_i\\):\n\\[\nH(X) \\approx \\frac{1}{n} \\sum_{i=1}^{n} h(x_i).\n\\tag{60.2}\\]\nIn questa formula, \\(h(x_i)\\) è l’informazione di Shannon di un singolo risultato \\(x_i\\), come discusso in precedenza. L’entropia, quindi, non si riferisce a un evento specifico, ma alla sorpresa media che ci aspettiamo quando osserviamo ripetutamente una variabile aleatoria. Più equilibrata è la distribuzione delle probabilità dei risultati (ad esempio, se tutti i risultati sono ugualmente probabili), maggiore sarà l’entropia, perché ciascun risultato fornisce una quantità simile di informazione. Al contrario, se alcuni risultati sono molto più probabili di altri (ad esempio, una moneta truccata che dà quasi sempre “testa”), l’entropia sarà minore, poiché otteniamo meno informazione da ogni osservazione.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#entropia-di-una-moneta-equa",
    "href": "chapters/entropy/01_entropy.html#entropia-di-una-moneta-equa",
    "title": "60  Entropia",
    "section": "60.6 Entropia di una Moneta Equa",
    "text": "60.6 Entropia di una Moneta Equa\nSe una moneta è equa, allora \\(p(x_h) = 0.5\\) e la sorpresa di osservare una testa è\n\\[\n\\begin{align}\nh(x_h) &= \\log_2 \\frac{1}{p(x_h)} \\notag\\\\\n       &= \\log_2(1/0.5) = 1 \\text{ bit}.\\notag\n\\end{align}\n\\]\nDato che \\(p(x_t) = 0.5\\), la sorpresa di osservare una testa (o una croce) è di un bit.\nPossiamo trovare la sorpresa media lanciando la moneta, diciamo, 100 volte, misurando la sorpresa di ogni risultato e poi calcolando la media dei 100 risultati. Se lanciamo una moneta 100 volte, ci aspettiamo di osservare testa circa 50 volte e croce circa 50 volte. Se osserviamo esattamente 50 teste e 50 croci, la quantità media di sorpresa diventa\n\\[\n\\begin{align}\nH(X) &= \\frac{1}{100} \\left( \\sum_{i=1}^{50} \\log_2 \\frac{1}{p(x_h)} + \\sum_{i=1}^{50} \\log_2 \\frac{1}{p(x_t)} \\right)\\notag\\\\\n&=1 \\text{ bit per lancio della moneta}\\notag.\n\\end{align}\n\\]\nIn sintesi, poiché la quantità di sorpresa o informazione di Shannon fornita dall’osservazione del risultato di ogni lancio di questa moneta equa è di un bit, ne segue che l’informazione media \\(H(X)\\) di ogni lancio è anch’essa di un bit.\n\n60.6.1 Interpretazione dell’Entropia (1)\nSe consideriamo una distribuzione di probabilità uniforme, una variabile con entropia \\(H(X)\\) espressa in bit fornisce sufficiente informazione (nel senso della teoria dell’informazione di Shannon) per distinguere tra \\(m = 2^{H(X)}\\) alternative ugualmente probabili. In altre parole, l’entropia misura la quantità di informazione contenuta in una variabile, esprimendola in termini di quante scelte ugualmente probabili sono possibili per quella variabile.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#entropia-di-una-moneta-sbilanciata",
    "href": "chapters/entropy/01_entropy.html#entropia-di-una-moneta-sbilanciata",
    "title": "60  Entropia",
    "section": "60.7 Entropia di una moneta sbilanciata",
    "text": "60.7 Entropia di una moneta sbilanciata\nUna moneta sbilanciata ha una quantità media di informazione (o incertezza) inferiore rispetto a una moneta equa.\nLa sorpresa associata a testa è:\n\\[\nh(\\text{testa}) = \\log\\left(\\frac{1}{0.9}\\right) = 0.15 \\text{ bit},\n\\]\nmentre la sorpresa associata a croce è maggiore:\n\\[\nh(\\text{croce}) = \\log\\left(\\frac{1}{0.1}\\right) = 3.32 \\text{ bit}.\n\\]\n\n60.7.1 Interpretazione dell’Entropia (2)\nSe immaginiamo di lanciare la moneta tante volte, la sorpresa media o entropia di questa moneta, considerando considerando \\(p(\\text{testa}) = 0.9\\) e \\(p(\\text{croce}) = 0.1\\), è:\n\\[H(X) = 0.9 \\log_2 \\frac{1}{0.9} + 0.1 \\log_2 \\frac{1}{0.1} = 0.469 \\text{ bit per lancio}.\\]\nL’incertezza media per questa moneta sbilanciata è dunque inferiore a quella di una moneta equa (che ha un’entropia di 1 bit), anche se l’incertezza associata all’esito meno probabile (croce) è maggiore (3.32 bit) rispetto a quella di una moneta equa (1 bit). In generale, nessuna moneta sbilanciata può avere un’entropia media maggiore di quella di una moneta equa.\nPoiché \\(p(\\text{testa}) = 0.9\\) e \\(p(\\text{croce}) = 0.1\\), possiamo scrivere la formula dell’entropia come:\n\\[\nH(X) = p(\\text{testa}) \\log\\left(\\frac{1}{p(\\text{testa})}\\right) + p(\\text{croce}) \\log\\left(\\frac{1}{p(\\text{croce})}\\right) = 0.469 \\text{ bit per lancio}.\n\\]\nPer semplificare ulteriormente, possiamo rappresentare l’entropia sommando sui due possibili esiti (testa e croce):\n\\[\nH(X) = \\sum_{i=1}^{2} p(x_i) \\log\\left(\\frac{1}{p(x_i)}\\right) = 0.469 \\text{ bit per lancio}.\n\\]\nQuesta entropia di 0.469 bit implica che l’informazione contenuta in 1.000 lanci di questa moneta potrebbe essere rappresentata usando solo 469 bit binari, cioè \\(1000 \\times 0.469\\).\nPossiamo interpretare questo risultato considerando l’entropia nei termini di un numero di alternative ugualmente probabili. La variabile \\(X\\), che rappresenta il lancio della moneta, potrebbe essere vista come equivalente a una variabile che può assumere:\n\\[\nm = 2^{H(X)} = 2^{0.469} \\approx 1.38 \\text{ valori equiprobabili}.\n\\]\nA prima vista, questo risultato può sembrare strano, dato che stiamo considerando una moneta, che ha solo due esiti possibili. Tuttavia, interpretare l’entropia nei termini di un numero equivalente di valori ugualmente probabili ci offre un’intuizione sull’informazione rappresentata da una variabile. Un modo per pensare a questo concetto è di immaginare che una moneta con entropia \\(H(X) = 0.469\\) bit abbia la stessa quantità di incertezza di un dado ipotetico con 1.38 facce.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#caratteristiche-dellentropia",
    "href": "chapters/entropy/01_entropy.html#caratteristiche-dellentropia",
    "title": "60  Entropia",
    "section": "60.8 Caratteristiche dell’Entropia",
    "text": "60.8 Caratteristiche dell’Entropia\n\nEntropia Massima: L’entropia raggiunge il suo valore massimo quando tutti gli esiti di un evento hanno la stessa probabilità di verificarsi. In questa situazione, l’incertezza è massima, poiché nessun indizio ci permette di prevedere quale sarà il risultato. Questo rappresenta il massimo grado di imprevedibilità.\nEntropia Minima: L’entropia è minima quando l’esito di un evento è completamente certo (con probabilità pari a 1) o impossibile (con probabilità pari a 0). In questi casi, non esiste incertezza né sorpresa, e quindi non c’è alcuna informazione aggiuntiva da ottenere osservando il risultato.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#additività-dellentropia-per-eventi-indipendenti",
    "href": "chapters/entropy/01_entropy.html#additività-dellentropia-per-eventi-indipendenti",
    "title": "60  Entropia",
    "section": "60.9 Additività dell’Entropia per Eventi Indipendenti",
    "text": "60.9 Additività dell’Entropia per Eventi Indipendenti\nL’entropia è additiva nel caso di eventi indipendenti. Ciò significa che, se si verificano due o più eventi indipendenti, l’entropia totale della loro combinazione è pari alla somma delle entropie di ciascun evento considerato singolarmente. Questa proprietà deriva dall’additività dei logaritmi, che permette di sommare le entropie individuali per ottenere l’entropia complessiva.\n\n60.9.1 Stimare l’Entropia da una Distribuzione di Probabilità\nConsideriamo una variabile casuale discreta \\(X\\), che rappresenta una serie di eventi distinti, ciascuno con una probabilità associata. Per una variabile discreta \\(X\\) con possibili valori \\(x_1, x_2, \\dots, x_n\\) e una funzione di massa di probabilità \\(p(x) = \\Pr\\{X = x\\}\\), l’entropia \\(H(X)\\) misura l’incertezza complessiva associata a questa distribuzione di probabilità e si calcola con la formula:\n\\[\n\\begin{equation}\nH(X) = -\\sum_{x \\in X} p(x) \\log_2 p(x).\n\\end{equation}\n\\tag{60.3}\\]\nIn questo contesto, l’entropia \\(H(X)\\) rappresenta l’incertezza media relativa alla collezione di eventi descritti dalla variabile \\(X\\). La formula fornisce una somma pesata delle sorprese associate a ciascun esito, dove la sorpresa di un risultato \\(x\\) dipende dalla sua improbabilità, calcolata come \\(-\\log_2 p(x)\\). Il segno negativo è necessario perché i logaritmi di probabilità, essendo inferiori a 1, sono negativi; il segno negativo li trasforma in valori positivi, che rappresentano correttamente la sorpresa o l’informazione associata.\nOgni termine della somma, \\(-p(x) \\log_2 p(x)\\), esprime la quantità di informazione o sorpresa relativa a un singolo evento, ponderata dalla sua probabilità \\(p(x)\\). Quanto più uniformemente distribuite sono le probabilità degli eventi, tanto maggiore sarà l’entropia complessiva. Al contrario, se uno o più eventi sono molto più probabili rispetto agli altri, l’entropia sarà inferiore, riflettendo una minore incertezza.\nIn sintesi, l’entropia \\(H(X)\\) misura l’incertezza complessiva associata alla distribuzione di probabilità di una variabile casuale discreta \\(X\\). Essa quantifica la sorpresa media che ci si può aspettare quando si osserva un evento estratto casualmente da questa collezione.\n\nEsempio 60.1 Supponiamo di avere un dado con otto facce. Ci sono \\(m = 8\\) esiti possibili:\n\\[\nA_x = \\{1,2,3,4,5,6,7,8\\}.\n\\]\nPoiché il dado è equo, tutti gli otto esiti hanno la stessa probabilità di \\(p(x) = 1/8\\), definendo così una distribuzione di probabilità uniforme:\n\\[\np(X) = \\left\\{\\frac{1}{8}, \\frac{1}{8}, \\frac{1}{8}, \\frac{1}{8}, \\frac{1}{8}, \\frac{1}{8}, \\frac{1}{8}, \\frac{1}{8}\\right\\}.\n\\]\nL’entropia di questa distribuzione può essere calcolata come:\n\\[\nH(X) = - \\sum_{i=1}^{8} \\frac{1}{8} \\log_2 \\frac{1}{8} = \\log_2 8 = 3 \\text{ bit}.\n\\]\nPoiché l’informazione associata a ciascun esito è esattamente 3 bit, anche l’entropia media è di 3 bit, che rappresenta l’incertezza complessiva della variabile \\(X\\).\nDato che \\(X\\) ha un’entropia di \\(H(X) = 3\\) bit, possiamo dire che \\(X\\) può rappresentare fino a:\n\\[\nm = 2^{H(X)} = 2^3 = 8\n\\]\nesiti equiprobabili.\n\n\nEsempio 60.2 Sia \\(X\\) una variabile casuale discreta che può assumere i valori \\(a, b, c,\\) e \\(d\\) con una distribuzione di probabilità di massa \\(p(a) = \\frac{1}{2}\\), \\(p(b) = \\frac{1}{4}\\), \\(p(c) = \\frac{1}{8}\\), e \\(p(d) = \\frac{1}{8}\\), rispettivamente. L’entropia di \\(X\\), che misura l’incertezza associata alla distribuzione di probabilità, è calcolata come:\n\\[\nH(X) = -\\left(\\frac{1}{2} \\log_2 \\frac{1}{2} + \\frac{1}{4} \\log_2 \\frac{1}{4} + \\frac{1}{8} \\log_2 \\frac{1}{8} + \\frac{1}{8} \\log_2 \\frac{1}{8}\\right).\n\\]\nCalcolando i singoli termini, otteniamo:\n\\[\nH(X) = -\\left(\\frac{1}{2} \\cdot (-1) + \\frac{1}{4} \\cdot (-2) + \\frac{1}{8} \\cdot (-3) + \\frac{1}{8} \\cdot (-3)\\right) = \\frac{7}{4} \\text{ bits}.\n\\]\nÈ importante notare che l’entropia \\(H(X)\\) dipende esclusivamente dalla distribuzione di probabilità dei valori di \\(X\\) e non dai valori stessi.\n\n\n\n60.9.2 Stimare l’Entropia in un Campione di Osservazioni\nL’entropia può essere calcolata non solo per distribuzioni teoriche, ma anche per campioni di dati osservati. In questo caso, l’entropia ci fornisce una misura di quanto sia incerta o imprevedibile la distribuzione dei valori all’interno del campione.\n\nEsempio 60.3 Per comprendere meglio questo concetto, possiamo calcolare l’entropia associata a insiemi di osservazioni. Consideriamo i due vettori seguenti:\n\\[\n\\begin{align}\nx &= \\{1, 2, 3, 3, 3, 3, 2, 1, 3, 3, 2, 1, 1, 4, 4, 3, 1, 2\\}, \\notag\\\\\ny &= \\{3, 4, 1, 1, 1, 1, 4, 3, 1, 1, 4, 3, 3, 2, 2, 1, 3, 4\\}. \\notag\n\\end{align}\n\\]\nTroviamo l’entropia associata a ciascuno di essi.\n\n# Definisco i vettori\nx &lt;- c(1, 2, 3, 3, 3, 3, 2, 1, 3, 3, 2, 1, 1, 4, 4, 3, 1, 2)\ny &lt;- c(3, 4, 1, 1, 1, 1, 4, 3, 1, 1, 4, 3, 3, 2, 2, 1, 3, 4)\n\n# Calcolo il numero di occorrenze di ciascun valore\nx_counts &lt;- table(x)\ny_counts &lt;- table(y)\n\n# Calcolo le probabilità\nx_probabilities &lt;- as.numeric(x_counts) / length(x)\ny_probabilities &lt;- as.numeric(y_counts) / length(y)\n\n# Funzione per calcolare l'entropia\ncalculate_entropy &lt;- function(probabilities) {\n  -sum(probabilities * log2(probabilities))\n}\n\n# Calcolo manualmente l'entropia\nx_entropy &lt;- calculate_entropy(x_probabilities)\ny_entropy &lt;- calculate_entropy(y_probabilities)\n\n# Risultati\nlist(x_entropy = x_entropy, y_entropy = y_entropy)\n#&gt; $x_entropy\n#&gt; [1] 1.87764\n#&gt; \n#&gt; $y_entropy\n#&gt; [1] 1.87764\n\nEntrambi i vettori hanno la stessa entropia di 1.8776 bit.\n\n\nEsempio 60.4 Consideriamo un gioco con due giocatori. In questo gioco, vengono considerate solo le 13 carte del seme di quadri da un mazzo standard di 52 carte, e si suppone che ognuna di queste carte abbia la stessa probabilità di essere scelta. Il primo giocatore sceglie una carta tra le 13 carte di quadri. Il secondo giocatore deve indovinare quale carta di quadri è stata scelta facendo domande a cui il primo giocatore risponderà esclusivamente con “sì” o “no”. L’obiettivo è determinare il numero minimo di domande necessarie per identificare esattamente la carta scelta.\nIn questa situazione, la scelta del primo giocatore può essere rappresentata come un vettore one-hot di dimensione 13: \\(X = (x_1, \\dots, x_{13}) \\in \\{0, 1\\}^{13}\\), dove esattamente un elemento \\(x_i\\) è uguale a 1 (indica la carta scelta), mentre gli altri sono uguali a 0. Quindi ci sono 13 possibili scelte.\nL’incertezza associata alla scelta casuale di una carta tra le 13 disponibili è quantificata dall’entropia. Poiché tutte le carte hanno la stessa probabilità di essere selezionate, l’entropia della distribuzione uniforme è data dalla formula:\n\\[\nH(X) = \\log_2 13 \\approx 3.7 \\text{ bit}.\n\\]\nQuesta quantità rappresenta l’incertezza iniziale, ovvero il numero di bit di informazione necessari per determinare esattamente quale delle 13 carte è stata scelta.\nOgni risposta data dal primo giocatore (“sì” o “no”) fornisce 1 bit di informazione, poiché riduce il numero di possibilità di circa la metà. Dato che l’incertezza iniziale è di circa 3.7 bit, il numero minimo di domande necessarie è:\n\\[\n\\frac{3.7}{1} = 3.7 \\text{ risposte},\n\\]\nche in pratica significa che saranno necessarie almeno 4 domande per determinare con certezza la carta scelta.\nPer esempio, possiamo dividere il set iniziale \\(E^{(0)}\\), formato dalle 13 carte di quadri, in due sottoinsiemi:\n\\[\nE_1^{(0)} = \\{1, 2, 3, 4, 5, 6, 7\\}, \\quad E_2^{(0)} = \\{8, 9, 10, 11, 12, 13\\}.\n\\]\nLa prima domanda potrebbe essere: “La carta scelta si trova in \\(E_1^{(0)}\\)?”.\n\nSe la risposta è sì, eliminiamo \\(E_2^{(0)}\\);\nSe la risposta è no, eliminiamo \\(E_1^{(0)}\\).\n\nIn entrambi i casi, ci resta un nuovo set \\(E^{(1)}\\) contenente al massimo 7 carte. Ripetiamo il processo dividendo nuovamente in due sottoinsiemi. Nel caso peggiore, possiamo dividere \\(E^{(1)}\\) in:\n\\[\nE_1^{(1)} = \\{1, 2, 3, 4\\}, \\quad E_2^{(1)} = \\{5, 6, 7\\},\n\\]\ne chiedere se la carta scelta è in \\(E_1^{(1)}\\).\nDopo ogni domanda, riduciamo progressivamente il set di possibili carte fino ad arrivare a una singola carta. Con la quarta domanda possiamo determinare esattamente quale carta è stata scelta.\nIn questo modo, abbiamo confermato che il numero minimo di domande per identificare la carta è 4, dato che l’entropia iniziale della scelta tra 13 carte è di circa 3.7 bit.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#entropia-di-una-variabile-casuale-continua",
    "href": "chapters/entropy/01_entropy.html#entropia-di-una-variabile-casuale-continua",
    "title": "60  Entropia",
    "section": "60.10 Entropia di una Variabile Casuale Continua",
    "text": "60.10 Entropia di una Variabile Casuale Continua\nNel caso delle variabili casuali continue, il concetto di entropia viene generalizzato sostituendo la somma con un integrale. Questo è necessario perché le variabili continue possono assumere un numero infinito di valori all’interno di un intervallo.\nPer una variabile casuale continua \\(X\\) con una funzione di densità di probabilità \\(p(x)\\), l’entropia (nota anche come entropia differenziale) è definita dalla seguente formula:\n\\[ H(X) = -\\int p(x) \\log_2(p(x)) \\, dx, \\]\ndove:\n\n\\(p(x)\\) è la funzione di densità di probabilità di \\(X\\),\nl’integrale è calcolato su tutto il dominio di \\(X\\).\n\nL’entropia di una variabile casuale continua fornisce una misura dell’incertezza o della sorpresa associata alla distribuzione della variabile. Come nel caso discreto, l’entropia continua quantifica l’incertezza associata a \\(X\\). Una PDF molto concentrata (ad esempio, una distribuzione con picchi stretti) implica bassa entropia, poiché l’evento è più prevedibile. Una PDF distribuita uniformemente implica alta entropia, poiché l’evento è meno prevedibile.\nIl segno negativo assicura che l’entropia sia una quantità positiva, in quanto \\(\\log_2(p(x))\\) è negativo per \\(p(x)\\) compreso tra 0 e 1.\nEsempi relativi al calcolo dell’entropia nel caso di variabili continue sono fornite nel ?sec-entropy-rv-cont.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#la-codifica-huffman",
    "href": "chapters/entropy/01_entropy.html#la-codifica-huffman",
    "title": "60  Entropia",
    "section": "60.11 La Codifica Huffman",
    "text": "60.11 La Codifica Huffman\nLa codifica Huffman è un metodo utilizzato per rappresentare gli esiti di una variabile casuale in un formato binario, ottimizzando la lunghezza del codice necessario per descrivere questi esiti. Questo algoritmo crea una rappresentazione binaria che permette di comprimere i dati senza perdita di informazioni, utilizzando una codifica efficiente basata sulla frequenza dei simboli.\nNella codifica Huffman, i simboli più frequenti sono rappresentati da codici binari più brevi, mentre i simboli meno frequenti sono rappresentati da codici più lunghi. Questo approccio assicura che la lunghezza media del codice per rappresentare una sequenza di simboli sia la più corta possibile, ottimizzando così lo spazio necessario per la memorizzazione o la trasmissione dei dati. In questo modo, la codifica Huffman riesce a ridurre la quantità di bit necessari per codificare una variabile casuale, rispettando il principio della teoria dell’informazione che lega la probabilità di un simbolo alla lunghezza del codice a esso associato.\nLa codifica Huffman può essere descritta nel modo seguente.\n\nCreazione della lista di simboli e frequenze:\n\nIn questa fase, si analizza il testo o i dati da comprimere.\nSi conta quante volte appare ogni simbolo (che può essere un carattere, una parola, o qualsiasi unità di informazione).\nSi crea una tabella che elenca ogni simbolo unico e la sua frequenza di apparizione.\nPer esempio, in un testo, potremmo avere: A: 10, B: 5, C: 12, D: 3, E: 15.\n\nCostruzione dell’albero binario:\n\nSi inizia creando un nodo foglia per ogni simbolo. Ogni nodo contiene il simbolo e la sua frequenza.\nPoi si segue questo processo iterativo:\n\nSi selezionano i due nodi con le frequenze più basse.\nSi crea un nuovo nodo padre che ha questi due come figli.\nLa frequenza del nuovo nodo padre è la somma delle frequenze dei figli.\nSi aggiunge questo nuovo nodo all’insieme dei nodi disponibili.\nSi ripete finché non rimane un solo nodo (la radice dell’albero).\n\nDurante questo processo, i simboli più frequenti tendono a rimanere vicini alla radice, mentre quelli meno frequenti si trovano più in profondità nell’albero.\n\nAssegnazione dei codici:\n\nUna volta costruito l’albero, si assegna un bit ‘0’ a ogni ramo sinistro e un bit ‘1’ a ogni ramo destro.\nPer trovare il codice di un simbolo, si parte dalla radice e si segue il percorso fino alla foglia corrispondente, registrando i bit incontrati lungo il cammino.\nI simboli più frequenti avranno codici più corti (più vicini alla radice), mentre quelli meno frequenti avranno codici più lunghi.\n\n\nIn conclusione, la codifica Huffman è un metodo di compressione dei dati che utilizza le proprietà della probabilità e della teoria dell’informazione per creare una rappresentazione binaria ottimizzata, riducendo così la quantità di dati necessari per rappresentare una sequenza di simboli.\n\nEsempio 60.5 Supponiamo di avere questi simboli e le loro rispettive frequenze:\n\nA: 20\nB: 10\nC: 8\nD: 5\n\nVogliamo generare i codici di Huffman per ciascun simbolo, ottimizzando la rappresentazione dei dati affinché i simboli più frequenti abbiano codici più brevi.\nPassaggi per creare l’albero di Huffman:\n\nCreazione dei nodi foglia\nCreiamo un nodo foglia per ogni simbolo, dove il numero rappresenta la frequenza:\n\n(A:20), (B:10), (C:8), (D:5)\n\nCostruzione dell’albero\nCombiniamo i due nodi con le frequenze più basse e ripetiamo fino a ottenere un unico albero:\n\nCombiniamo D (5) e C (8): il nuovo nodo avrà una frequenza pari alla somma delle due, ovvero 13.\nRisultato: ((D:5, C:8):13)\nCombiniamo il nodo appena creato (D,C:13) con B (10): il nuovo nodo avrà frequenza 23.\nRisultato: (B:10, (D:5, C:8):13):23\nCombiniamo il nodo appena creato (B,(D,C):23) con A (20): il nuovo nodo sarà la radice dell’albero con frequenza totale 43.\nRisultato: (A:20, (B:10, (D:5, C:8):13):23):43\n\n\nAlbero di Huffman risultante\nL’albero finale sarà:\n       (43)\n      /    \\\n    (20)   (23)\n     |     /   \\\n     A   (10)  (13)\n          |    /  \\\n          B   (5) (8)\n              |    |\n              D    C\nCosa rappresentano i numeri nei nodi?\n\nNei nodi foglia (es. A, B, C, D), il numero rappresenta la frequenza di quel simbolo.\nNei nodi interni, il numero rappresenta la somma delle frequenze dei nodi figli. Ad esempio:\n\nIl nodo 13 rappresenta la somma delle frequenze di C (8) e D (5).\nIl nodo 23 rappresenta la somma delle frequenze di B (10) e (D,C:13).\n\n\nGenerazione dei codici\nPer generare i codici di Huffman, seguiamo queste regole:\n\nOgni volta che scendiamo a sinistra, aggiungiamo uno 0 al codice.\nOgni volta che scendiamo a destra, aggiungiamo un 1.\n\nDall’albero otteniamo:\n\nA: 0 (si raggiunge scendendo a sinistra dalla radice)\nB: 10 (si raggiunge scendendo a destra, poi a sinistra)\nD: 110 (si raggiunge scendendo a destra, poi a destra, infine a sinistra)\nC: 111 (si raggiunge scendendo a destra, poi a destra, infine a destra)\n\nIn conclusione, questo esempio mostra come la codifica di Huffman assegna codici più brevi ai simboli più frequenti (es. A) e codici più lunghi ai simboli meno frequenti (es. C e D). Il risultato ottimizza la lunghezza totale del messaggio codificato.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#lentropia-come-lunghezza-media-del-codice-binario",
    "href": "chapters/entropy/01_entropy.html#lentropia-come-lunghezza-media-del-codice-binario",
    "title": "60  Entropia",
    "section": "60.12 L’Entropia come Lunghezza Media del Codice Binario",
    "text": "60.12 L’Entropia come Lunghezza Media del Codice Binario\nL’entropia, in termini di teoria dell’informazione, rappresenta la quantità media di informazione necessaria per descrivere gli esiti di una variabile casuale. In altre parole, può essere interpretata come la lunghezza media del codice binario utilizzato per rappresentare questi esiti, tenendo conto delle loro probabilità.\nConsideriamo una variabile casuale discreta \\(X\\) che può assumere quattro valori: \\(A, B, C,\\) e \\(D\\), con le seguenti probabilità:\n\n\\(p(A) = 0.4\\)\n\\(p(B) = 0.3\\)\n\\(p(C) = 0.2\\)\n\\(p(D) = 0.1\\)\n\nUtilizzando la codifica Huffman per questa variabile casuale, otteniamo i seguenti codici binari:\n\n\\(A\\) = “0”\n\\(B\\) = “10”\n\\(C\\) = “110”\n\\(D\\) = “111”\n\nLa lunghezza media del codice in bit può essere calcolata come segue:\n\\[\n\\begin{align}\n\\text{Lunghezza media} &= p(A) \\times \\text{lunghezza di } A + p(B) \\times \\text{lunghezza di } B\\notag \\\\\n&\\quad + p(C) \\times \\text{lunghezza di } C\\notag + p(D) \\times \\text{lunghezza di } D\\notag.\n\\end{align}\n\\]\nSostituendo i valori delle probabilità e le lunghezze dei codici:\n\\[\n\\begin{align}\n\\text{Lunghezza media} &= (0.4 \\times 1) + (0.3 \\times 2) + (0.2 \\times 3) + (0.1 \\times 3)\\notag\\\\\n&= 0.4 + 0.6 + 0.6 + 0.3 = 1.9 \\text{ bit}.\\notag\n\\end{align}\n\\]\nPossiamo replicare questo risultato usando una funzione R:\n\nhuffman_encoding &lt;- function(probabilities) {\n  # Creazione della coda con priorità (min-heap) per costruire\n  # l'albero di Huffman\n  heap &lt;- lapply(\n    names(probabilities), function(symbol) {\n      list(\n        weight = probabilities[[symbol]],\n        nodes = list(list(symbol = symbol, code = \"\"))\n      )\n    }\n  )\n\n  # Funzione per ordinare la heap in base ai pesi\n  sort_heap &lt;- function(heap) {\n    heap[order(sapply(heap, function(x) x$weight))]\n  }\n  heap &lt;- sort_heap(heap)\n\n  # Costruzione dell'albero di Huffman\n  while (length(heap) &gt; 1) {\n    # Estrarre i due nodi con peso minimo\n    lo &lt;- heap[[1]]\n    hi &lt;- heap[[2]]\n    heap &lt;- heap[-(1:2)]\n\n    # Aggiornare i codici per i simboli nei nodi estratti\n    lo$nodes &lt;- lapply(\n      lo$nodes,\n      function(node) {\n        node$code &lt;- paste0(\"0\", node$code)\n        node\n      }\n    )\n\n    hi$nodes &lt;- lapply(\n      hi$nodes,\n      function(node) {\n        node$code &lt;- paste0(\"1\", node$code)\n        node\n      }\n    )\n\n    # Aggiungere il nuovo nodo combinato alla heap\n    new_node &lt;- list(\n      weight = lo$weight + hi$weight,\n      nodes = c(lo$nodes, hi$nodes)\n    )\n    heap &lt;- c(heap, list(new_node))\n    heap &lt;- sort_heap(heap)\n  }\n\n  # Estrazione del dizionario dei codici di Huffman\n  huffman_dict &lt;- heap[[1]]$nodes\n  huffman_dict &lt;- huffman_dict[\n    order(\n      sapply(huffman_dict, function(node) nchar(node$code))\n    )\n  ]\n\n  # Calcolo della lunghezza media del codice\n  avg_length &lt;- sum(\n    sapply(\n      huffman_dict, function(node) {\n        probabilities[[node$symbol]] * nchar(node$code)\n      }\n    )\n  )\n\n  list(avg_length = avg_length, huffman_dict = huffman_dict)\n}\n\n\n# Distribuzione di probabilità di una variabile casuale discreta\nprobabilities &lt;- list(A = 0.4, B = 0.3, C = 0.2, D = 0.1)\n\n# Calcolo della lunghezza media del codice di Huffman\nresult &lt;- huffman_encoding(probabilities)\n\n# Visualizzazione dei risultati\ncat(\n  sprintf(\n    \"Lunghezza media del codice di Huffman: %.2f bit/simbolo\\n\",\n    result$avg_length\n  )\n)\n#&gt; Lunghezza media del codice di Huffman: 1.90 bit/simbolo\n\ncat(\"Codici di Huffman per ciascun simbolo:\\n\")\n#&gt; Codici di Huffman per ciascun simbolo:\n\nfor (node in result$huffman_dict) {\n  cat(sprintf(\"%s: %s\\n\", node$symbol, node$code))\n}\n#&gt; A: 0\n#&gt; B: 10\n#&gt; D: 110\n#&gt; C: 111\n\nCalcoliamo ora l’entropia \\(H(X)\\) della variabile casuale \\(X\\):\n\\[\n\\begin{align}\nH(X) &= -\\sum p(x) \\log_2 p(x) \\notag\\\\\n     &= -(0.4 \\log_2 0.4 + 0.3 \\log_2 0.3 + 0.2 \\log_2 0.2 + 0.1 \\log_2 0.1)\\notag\\\\\n     &= 1.8465 \\text{ bit}.\n\\end{align}\n\\]\nIn questo esempio, l’entropia è \\(H(X) = 1.8465\\) bit. La lunghezza media del codice Huffman calcolata è di \\(1.9\\) bit, un valore molto vicino all’entropia. Questo ci permette di interpretare l’entropia come la lunghezza media teorica minima del codice binario necessario per rappresentare la variabile casuale \\(X\\). Possiamo affermare che la codifica di Huffman è quasi ottimale, poiché si avvicina molto al limite inferiore stabilito dall’entropia. In altre parole, l’entropia rappresenta effettivamente la lunghezza minima media del codice binario necessaria per descrivere la distribuzione di probabilità di una variabile casuale.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#applicazioni-psicologiche",
    "href": "chapters/entropy/01_entropy.html#applicazioni-psicologiche",
    "title": "60  Entropia",
    "section": "60.13 Applicazioni Psicologiche",
    "text": "60.13 Applicazioni Psicologiche\nUn esempio di applicazione dell’entropia dell’informazione in psicologia riguarda dell’effetto della sorpresa nello studio dell’umore. La sorpresa, o entropia, è stata documentata sia in laboratorio che in contesti naturali come un fattore che influenza le emozioni. Ad esempio, Spector (1956) osservò l’effetto della probabilità a priori sulla soddisfazione dei soggetti in risposta a una promozione lavorativa. I risultati indicano che gli esiti meno probabili a priori (e quindi più sorprendenti quando si verificano) hanno un impatto maggiore sull’umore. In altre parole, quando un evento inatteso e sorprendente si verifica, esso tende a influenzare l’umore in modo più forte rispetto a eventi previsti e probabili.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#riflessioni-conclusive",
    "href": "chapters/entropy/01_entropy.html#riflessioni-conclusive",
    "title": "60  Entropia",
    "section": "60.14 Riflessioni Conclusive",
    "text": "60.14 Riflessioni Conclusive\nIn questo capitolo, abbiamo esplorato il concetto di entropia, sottolineando il suo ruolo cruciale nella quantificazione dell’incertezza all’interno delle distribuzioni di probabilità. Nel prossimo capitolo, vedremo come l’entropia possa essere utilizzata per valutare la “distanza” tra un modello teorico e i dati empirici. A tal fine, introdurremo la divergenza di Kullback-Leibler, una misura che quantifica le discrepanze tra due distribuzioni di probabilità.\nConcludiamo il capitolo con una riflessione tratta da Paradoxes in probability theory and mathematical statistics di Gabor Székely, che ci ricorda come la quantificazione dell’informazione non sia sempre un processo lineare o intuitivo:\n\nThe last paradox in this book is a quotation from my late professor Alfréd Rényi. “Since I started to deal with information theory I have often meditated upon the conciseness of poems; how can a single line of verse contain far more ‘information’ than a highly concise telegram of the same length. The surprising richness of meaning of literary works seems to be in contradiction with the laws of information theory. The key to this paradox is, I think, the notion of ‘resonance’. The writer does not merely give us information, but also plays on the strings of the language with such virtuosity, that our mind, and even the subconscious self resonate. A poet can recall chains of ideas, emotions and memories with a wellturned word. In this sense, writing is magic.”\n\nQuesta citazione ci invita a riflettere sulla natura dell’informazione. Ci ricorda che, mentre la teoria dell’informazione fornisce strumenti potenti per quantificare e analizzare l’incertezza e la complessità, esistono forme di comunicazione e espressione che trascendono le misure puramente quantitative. La “risonanza” di cui parla Rényi suggerisce che l’impatto e il significato dell’informazione possono dipendere non solo dal suo contenuto oggettivo, ma anche dal modo in cui essa interagisce con le nostre esperienze, emozioni e conoscenze pregresse.\nQuesta prospettiva ci incoraggia a mantenere un approccio critico nell’applicazione dei concetti di teoria dell’informazione, riconoscendo sia il loro potere analitico che i loro limiti intrinseci nell’interpretazione di fenomeni complessi.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/entropy/01_entropy.html#informazioni-sullambiente-di-sviluppo",
    "title": "60  Entropia",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] ggrepel_0.9.6     ggraph_2.2.1      igraph_2.1.1      MASS_7.3-61      \n#&gt;  [5] viridis_0.6.5     viridisLite_0.4.2 ggpubr_0.6.0      ggExtra_0.10.1   \n#&gt;  [9] gridExtra_2.3     patchwork_1.3.0   bayesplot_1.11.1  psych_2.4.6.26   \n#&gt; [13] scales_1.3.0      markdown_1.13     knitr_1.49        lubridate_1.9.3  \n#&gt; [17] forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4       purrr_1.0.2      \n#&gt; [21] readr_2.1.5       tidyr_1.3.1       tibble_3.2.1      ggplot2_3.5.1    \n#&gt; [25] tidyverse_2.0.0   rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1   farver_2.1.2       fastmap_1.2.0     \n#&gt;  [4] tweenr_2.0.3       pacman_0.5.1       promises_1.3.1    \n#&gt;  [7] digest_0.6.37      timechange_0.3.0   mime_0.12         \n#&gt; [10] lifecycle_1.0.4    magrittr_2.0.3     compiler_4.4.2    \n#&gt; [13] rlang_1.1.4        tools_4.4.2        utf8_1.2.4        \n#&gt; [16] yaml_2.3.10        ggsignif_0.6.4     labeling_0.4.3    \n#&gt; [19] graphlayouts_1.2.1 htmlwidgets_1.6.4  mnormt_2.1.1      \n#&gt; [22] abind_1.4-8        miniUI_0.1.1.1     withr_3.0.2       \n#&gt; [25] grid_4.4.2         polyclip_1.10-7    fansi_1.0.6       \n#&gt; [28] xtable_1.8-4       colorspace_2.1-1   cli_3.6.3         \n#&gt; [31] rmarkdown_2.29     generics_0.1.3     tzdb_0.4.0        \n#&gt; [34] cachem_1.1.0       ggforce_0.4.2      parallel_4.4.2    \n#&gt; [37] vctrs_0.6.5        jsonlite_1.8.9     carData_3.0-5     \n#&gt; [40] car_3.1-3          hms_1.1.3          rstatix_0.7.2     \n#&gt; [43] Formula_1.2-5      glue_1.8.0         stringi_1.8.4     \n#&gt; [46] gtable_0.3.6       later_1.4.0        munsell_0.5.1     \n#&gt; [49] pillar_1.9.0       htmltools_0.5.8.1  R6_2.5.1          \n#&gt; [52] tidygraph_1.3.1    rprojroot_2.0.4    evaluate_1.0.1    \n#&gt; [55] shiny_1.9.1        lattice_0.22-6     backports_1.5.0   \n#&gt; [58] memoise_2.0.1      broom_1.0.7        httpuv_1.6.15     \n#&gt; [61] Rcpp_1.0.13-1      nlme_3.1-166       xfun_0.49         \n#&gt; [64] pkgconfig_2.0.3",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#bibliografia",
    "href": "chapters/entropy/01_entropy.html#bibliografia",
    "title": "60  Entropia",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nSpector, A. J. (1956). Expectations, fulfillment, and morale. The Journal of Abnormal and Social Psychology, 52(1), 51–56.\n\n\nStone, J. V. (2022). Information theory: a tutorial introduction, 2nd edition.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/introduction_dynamic_models.html",
    "href": "chapters/dynamic_models/introduction_dynamic_models.html",
    "title": "Introduzione",
    "section": "",
    "text": "Bibliografia\nPrerequisiti\nUno degli sviluppi più significativi nella psicologia contemporanea è l’uso di teorie formali per formulare ipotesi sui meccanismi che sottendono i fenomeni psicologici. I modelli matematici sono strumenti essenziali per concettualizzare la cognizione umana e prevedere i comportamenti osservabili. Questi modelli cercano di fornire una formalizzazione matematica dei processi cognitivi, mappando i costrutti cognitivi latenti sui parametri del modello e descrivendo come questi producono i dati osservati.\nLa maggior parte dei modelli cognitivi tradizionali tratta i dati umani come osservazioni indipendenti e identicamente distribuite (IID). Questa assunzione implica che tali modelli spesso trascurano le variazioni temporali dei costrutti cognitivi latenti. Tuttavia, questi costrutti sono intrinsecamente dinamici, indipendentemente dalla scala temporale considerata. Negli esperimenti psicologici, le capacità cognitive sono influenzate non solo dalle richieste esterne del compito, ma anche dai processi mentali interni e dagli stati cerebrali che cambiano nel tempo. Le fluttuazioni sistematiche e non sistematiche che ne derivano possono avere diverse spiegazioni, come la fatica, la pratica, la divagazione mentale o fattori motivazionali. Come evidenziato da Schumacher et al. (2023), i meccanismi cognitivi dovrebbero essere trattati come sistemi dinamici complessi, e i modelli cognitivi dovrebbero tenere conto delle dinamiche dei loro componenti per comprendere appieno e catturare la ricca struttura dei dati empirici umani.\nLa teoria dei sistemi dinamici (Dynamic Systems Theory, DST) fornisce un quadro concettuale per comprendere i fenomeni psicologici come processi complessi, non lineari e spesso auto-organizzanti che si evolvono nel tempo. In psicologia, la DST sottolinea come il comportamento e la cognizione emergano dalle interazioni di molteplici componenti sia all’interno di un individuo sia tra l’individuo e il suo ambiente. Di seguito, presenteremo alcuni esempi di fenomeni psicologici che possono essere compresi attraverso la lente dei sistemi dinamici.\nApprendimento per rinforzo. L’apprendimento per rinforzo è un processo attraverso cui gli individui apprendono a modificare il proprio comportamento in base alle conseguenze che ne derivano. In termini di sistemi dinamici, l’apprendimento per rinforzo può essere visto come un processo adattativo in cui le decisioni di un individuo vengono continuamente aggiornate e migliorate attraverso l’interazione con l’ambiente. In questo contesto, le ricompense (o rinforzi positivi) e le punizioni (o rinforzi negativi) giocano un ruolo cruciale nel modellare il comportamento futuro, creando un ciclo di feedback che rafforza o indebolisce determinate azioni. Ad esempio, un comportamento che porta a una ricompensa tende a essere ripetuto, mentre un comportamento che porta a una punizione tende a essere evitato. Questo meccanismo di apprendimento, che può essere descritto matematicamente attraverso modelli probabilistici, permette di predire come un individuo possa modificare il proprio comportamento in situazioni diverse, sulla base delle esperienze passate e delle aspettative future. I modelli di apprendimento per rinforzo, come il modello di Rescorla-Wagner, sono stati ampiamente utilizzati in psicologia per spiegare non solo comportamenti semplici come il condizionamento classico e operante, ma anche fenomeni più complessi come la dipendenza, i disturbi d’ansia e i disturbi dell’umore. In questi casi, le aspettative disadattive e i bias cognitivi possono essere visti come il risultato di un apprendimento per rinforzo anomalo, in cui le associazioni tra stimoli e conseguenze sono distorte o esagerate. Studi recenti in psichiatria computazionale utilizzano questi modelli per sviluppare interventi terapeutici più efficaci, mirati a ristrutturare le associazioni disfunzionali e promuovere schemi di apprendimento più adattivi.\nRegolazione delle emozioni. La regolazione delle emozioni implica l’interazione dinamica di processi fisiologici, cognitivi e comportamentali. Ad esempio, il modo in cui una persona regola le proprie emozioni in risposta a un evento stressante può essere influenzato da diversi fattori, come esperienze precedenti, contesto attuale, stati fisiologici (come frequenza cardiaca o livelli ormonali) e valutazioni cognitive. Nel tempo, questi componenti possono interagire in modo non lineare, creando circuiti di retroazione. Ad esempio, una persona potrebbe inizialmente cercare di sopprimere le proprie emozioni, il che potrebbe portare a un aumento dell’eccitazione fisiologica, intensificando così l’emozione che stava cercando di regolare.\nAttaccamento e relazioni sociali. Anche gli stili di attaccamento e le relazioni sociali sono sistemi dinamici. La teoria dell’attaccamento descrive come le prime relazioni con i caregiver influenzino le dinamiche interpersonali per tutta la vita. Queste relazioni possono essere viste come sistemi in cui i comportamenti, le emozioni e le cognizioni di una persona influenzano continuamente e sono influenzati da quelli degli altri. Ad esempio, in una relazione genitore-figlio, il comportamento del bambino può influenzare le risposte del genitore, che a loro volta modellano il comportamento e gli stati emotivi futuri del bambino, creando un ciclo di retroazione che evolve nel tempo.\nSviluppo cognitivo. Lo sviluppo cognitivo, soprattutto nei bambini, viene spesso modellato come un sistema dinamico. La teoria dello sviluppo cognitivo di Jean Piaget, sebbene non esplicitamente in termini di DST, può essere reinterpretata in questo modo. Ad esempio, il processo di raggiungimento dell’equilibrio cognitivo comporta interazioni continue tra le strutture di conoscenza esistenti del bambino (schemi) e le nuove esperienze. Questo processo è dinamico perché il sistema cognitivo del bambino si adatta e si riorganizza costantemente in risposta a nuove informazioni, il che può portare a cambiamenti qualitativi nel pensiero.\nControllo motorio e coordinazione. Lo sviluppo e il controllo delle azioni motorie, come camminare o afferrare, sono esempi classici di sistemi dinamici. Il controllo motorio coinvolge il coordinamento di numerosi muscoli, circuiti di retroazione sensoriale e aggiustamenti basati sull’ambiente. L’approccio dei sistemi dinamici allo sviluppo motorio enfatizza come i comportamenti motori emergano dall’auto-organizzazione di molteplici sistemi interagenti, come componenti neurali, muscolari e percettivi. Imparare a camminare, ad esempio, non è solo un’accumulazione lineare di forza ed equilibrio, ma comporta cambiamenti non lineari nel coordinamento muscolare, nell’integrazione sensoriale e nei processi di retroazione.\nDecision making e problem solving. Il processo decisionale e la risoluzione dei problemi coinvolgono l’integrazione di molteplici fattori cognitivi ed emotivi che cambiano nel tempo. La natura dinamica di questi processi è evidente in come le decisioni iniziali possano portare a cambiamenti negli obiettivi, nel comportamento di ricerca delle informazioni e negli stati emotivi, che a loro volta influenzano le decisioni successive. Ad esempio, quando si prende una decisione in condizioni di incertezza, i livelli di fiducia di una persona, le reazioni emotive e le interpretazioni di nuove informazioni possono interagire dinamicamente, creando un modello fluttuante di comportamento decisionale.\nSalute mentale e psicopatologia. La salute mentale e la psicopatologia possono essere comprese anche da una prospettiva di sistemi dinamici. I disturbi come la depressione o l’ansia non sono visti come entità statiche, ma come schemi dinamici di cognizione, emozione e comportamento che evolvono nel tempo. Ad esempio, i sintomi depressivi possono creare un ciclo di retroazione in cui i pensieri negativi portano a una ridotta attività, che a sua volta porta a pensieri ed emozioni ancora più negativi, perpetuando il ciclo. Comprendere la psicopatologia come un sistema dinamico aiuta a sviluppare interventi che mirano a questi cicli di retroazione e promuovono schemi più adattivi.\nSviluppo del linguaggio. Lo sviluppo del linguaggio è un altro ambito in cui la teoria dei sistemi dinamici è applicabile. L’acquisizione del linguaggio nei bambini implica l’interazione di molteplici fattori, come la conoscenza fonologica, sintattica e semantica, nonché l’interazione sociale e le esperienze percettive. Lo sviluppo del linguaggio non è un’accumulazione lineare di vocabolario e regole grammaticali; piuttosto, emerge dall’interazione dinamica di questi fattori mentre i bambini interagiscono con il loro ambiente e i caregiver, portando a cambiamenti qualitativi nelle capacità linguistiche nel tempo.\nDinamiche di gruppo e influenza sociale. Il comportamento di gruppo e l’influenza sociale sono fenomeni che possono essere modellati come sistemi dinamici. Nei gruppi sociali, i comportamenti e gli atteggiamenti individuali possono influenzare gli altri, portando a cambiamenti nelle norme e nelle dinamiche di gruppo. Questi cambiamenti possono quindi influenzare di nuovo i comportamenti individuali, creando un ciclo di retroazione. Ad esempio, in un contesto di gruppo, l’emergere di un leader o la diffusione di una particolare opinione può portare a cambiamenti nel comportamento del gruppo che sono dinamici e talvolta imprevedibili.\nAutoregolazione e funzioni esecutive. L’autoregolazione e le funzioni esecutive coinvolgono la capacità di controllare l’attenzione, le emozioni e i comportamenti per raggiungere obiettivi a lungo termine. Questi processi sono dinamici perché implicano il monitoraggio continuo e l’aggiustamento delle azioni sulla base del feedback dall’ambiente. Ad esempio, rimanere concentrati su un compito implica regolare dinamicamente l’attenzione in risposta alle distrazioni, il che richiede l’integrazione di molteplici processi cognitivi come la memoria di lavoro, l’inibizione e la pianificazione.\nApprendimento e memoria. L’apprendimento e la memoria sono anche processi intrinsecamente dinamici. La codifica, l’immagazzinamento e il recupero dei ricordi coinvolgono l’interazione di molteplici sistemi neurali e cognitivi che cambiano nel tempo. Ad esempio, il processo di consolidamento della memoria, in cui i ricordi a breve termine vengono stabilizzati in ricordi a lungo termine, è dinamico e può essere influenzato da vari fattori come il sonno, lo stato emotivo e le esperienze successive.\nIn questa sezione della dispensa, forniremo un’introduzione ai modelli dinamici, con particolare attenzione ai modelli di apprendimento per rinforzo. Questi modelli sono utilizzati in psicologia per spiegare i bias cognitivi in varie patologie, tra cui la depressione, i disturbi alimentari e il disturbo ossessivo-compulsivo. Questo campo di studio all’avanguardia, noto come psichiatria computazionale, non si limita agli esempi citati ma esplora una vasta gamma di applicazioni. In particolare, introdurremo uno dei modelli più famosi in questo contesto: il modello di apprendimento associativo di Rescorla-Wagner. Questo modello descrive come gli organismi apprendano a prevedere eventi attraverso l’associazione tra stimoli, fornendo una spiegazione quantitativa di come si sviluppano e si modificano le aspettative basate sull’esperienza. In psicologia, il modello di Rescorla-Wagner è utilizzato per comprendere come gli individui apprendano dalle conseguenze delle loro azioni e come questo apprendimento possa essere influenzato da fattori cognitivi e affettivi, contribuendo così alla nostra comprensione dei meccanismi alla base di diverse condizioni psicopatologiche.",
    "crumbs": [
      "Dinamiche",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/introduction_dynamic_models.html#bibliografia",
    "href": "chapters/dynamic_models/introduction_dynamic_models.html#bibliografia",
    "title": "Introduzione",
    "section": "",
    "text": "Hayes, S. C., Hofmann, S. G., Stanton, C. E., Carpenter, J. K., Sanford, B. T., Curtiss, J. E., & Ciarrochi, J. (2019). The role of the individual in the coming era of process-based therapy. Behaviour Research and Therapy, 117, 40–53.\n\n\nSchumacher, L., Bürkner, P.-C., Voss, A., Köthe, U., & Radev, S. T. (2023). Neural superstatistics for Bayesian estimation of dynamic cognitive models. Scientific Reports, 13(1), 13778.",
    "crumbs": [
      "Dinamiche",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/introduction_cognitive_models.html",
    "href": "chapters/cognitive_models/introduction_cognitive_models.html",
    "title": "Introduzione",
    "section": "",
    "text": "I Modelli Computazionali della Cognizione\nComprendere la cognizione umana è stato uno dei principali obiettivi della ricerca psicologica per oltre un secolo. Gli approcci matematici allo studio della cognizione risalgono già al XIX secolo, quando ricercatori come Ernst Heinrich Weber svilupparono modelli matematici per descrivere fenomeni percettivi, come l’effetto della “differenza appena percepibile”, che descrive il modo in cui gli esseri umani percepiscono le differenze tra gli oggetti (Raymond & Rutherford, 2012). Tuttavia, fu solo con l’avvento dell’informatica teorica e dei computer digitali nel XX secolo che la psicologia computazionale emerse come un campo a sé stante. La nascita del computer digitale permise agli psicologi cognitivi di sviluppare formalismi matematici e modelli computazionali che descrivevano la cognizione come un fenomeno di elaborazione delle informazioni, in modo simile a come operano i computer digitali. Ricercatori come George Miller, Allen Newell, Herbert Simon e Frank Rosenblatt applicarono metodi computazionali allo studio della percezione, del linguaggio e della risoluzione dei problemi, gettando le basi per questo campo emergente (Boden, 2008). La psicologia computazionale ha offerto un approccio alternativo allo studio della mente, basato su algoritmi e simulazioni al computer, anziché su correlazioni e sperimentazioni in laboratorio, i paradigmi predominanti all’epoca, come osservato dal presidente dell’American Psychological Association, Lee Cronbach (Cronbach, 1957).\nNel primo quarto del XXI secolo, il campo dei modelli computazionali della cognizione sta vivendo una crescita rapida in un mondo dove nazioni e giganti tecnologici competono per scoprire i segreti dell’intelligenza umana e artificiale. In questa introduzione, offro una panoramica storica degli approcci computazionali in scienza cognitiva, evidenziando l’importanza e la prospettiva unica di questi metodi nello studio del pensiero e del comportamento umano. Adotterò una prospettiva storica, concentrandomi su una narrazione ad alto livello dell’evoluzione del campo, piuttosto che su numerosi esempi individuali di modelli computazionali (Boden, 2008).",
    "crumbs": [
      "Modelli cognitivi",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/introduction_cognitive_models.html#la-scienza-cognitiva-computazionale",
    "href": "chapters/cognitive_models/introduction_cognitive_models.html#la-scienza-cognitiva-computazionale",
    "title": "Introduzione",
    "section": "La Scienza Cognitiva Computazionale",
    "text": "La Scienza Cognitiva Computazionale\nNonostante l’importanza dei modelli computazionali, la scienza cognitiva computazionale ha impiegato molto tempo a consolidarsi tra i paradigmi principali nello studio della mente e del comportamento. Durante la prima metà del XX secolo, lo studio della mente era visto con sospetto da molti, data la nostra incapacità di accedere direttamente ai suoi contenuti (Skinner, 1965; Watson, 1913). Concetti come “coscienza” o “memoria” sono entità che i ricercatori possono misurare solo indirettamente osservando il comportamento delle persone, ma non esiste un modo per “toccare” o “vedere” un frammento di memoria nella mente di qualcuno. Questi sono eventi privati, esperienze soggettive, entità inaccessibili di costituzione eterea. Sebbene all’epoca fossimo in grado di osservare e misurare i pattern di attività elettrica nel cervello, trovare una corrispondenza diretta tra tali pattern e un particolare frammento di memoria era quanto mai ambiguo.\nL’invenzione del computer digitale è stata quindi rivoluzionaria per gli psicologi cognitivi, poiché ha fornito un esempio fisico di qualcosa che poteva fare molte delle cose che fa la mente umana: aritmetica, logica, memorizzazione di informazioni, e altro ancora. Dopo tutto, è possibile costruire, toccare e vedere un computer digitale. Si sa esattamente dove un’informazione viene elaborata e memorizzata. È difficile osservare un computer digitale in azione e non notare la somiglianza con i meccanismi interni della mente umana.",
    "crumbs": [
      "Modelli cognitivi",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/introduction_cognitive_models.html#oltre-le-reti-neurali",
    "href": "chapters/cognitive_models/introduction_cognitive_models.html#oltre-le-reti-neurali",
    "title": "Introduzione",
    "section": "Oltre le Reti Neurali",
    "text": "Oltre le Reti Neurali\nSebbene le reti neurali abbiano avuto un ruolo di primo piano nello sviluppo della scienza cognitiva computazionale, i modelli computazionali della cognizione non si limitano a queste. In realtà, esistono diversi approcci modellistici, ciascuno con le proprie specificità e aree di applicazione. I modelli simbolici, ad esempio, descrivono la cognizione umana come il risultato della manipolazione di simboli, basandosi su logica formale e linguistica. I modelli probabilistici, invece, utilizzano la teoria delle probabilità per descrivere il ragionamento umano in condizioni di incertezza.\nNel corso degli anni, questi approcci si sono evoluti e spesso integrati tra loro, portando allo sviluppo di modelli ibridi che combinano elementi simbolici, connessionisti e probabilistici. La psichiatria computazionale, in particolare, ha tratto vantaggio da questo approccio integrato, utilizzando modelli che possono adattarsi a diverse scale di analisi, dai circuiti neuronali ai comportamenti osservabili, per fornire una visione più completa dei disturbi mentali.",
    "crumbs": [
      "Modelli cognitivi",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/introduction_cognitive_models.html#la-psichiatria-computazionale",
    "href": "chapters/cognitive_models/introduction_cognitive_models.html#la-psichiatria-computazionale",
    "title": "Introduzione",
    "section": "La Psichiatria Computazionale",
    "text": "La Psichiatria Computazionale\nLa psichiatria computazional è un campo emergente utilizza modelli matematici e computazionali per comprendere i meccanismi mentali e comportamentali che stanno alla base dei disturbi mentali. L’approccio computazionale in psichiatria cerca di modellare in modo preciso le alterazioni nei processi cognitivi e decisionali che possono caratterizzare patologie come la schizofrenia, la depressione e i disturbi d’ansia.\nUn esempio emblematico di questo approccio è il lavoro di Michael Frank, che ha sviluppato modelli computazionali per comprendere i processi di apprendimento e decisione nei disturbi mentali. Frank ha esplorato come i modelli computazionali possano essere utilizzati per comprendere il funzionamento dei circuiti neuronali associati al rinforzo e alla punizione, e come alterazioni in questi circuiti possano contribuire a diverse manifestazioni psicopatologiche (Hitchcock et al., 2022). Ad esempio, i suoi studi sui meccanismi di rinforzo e sulla modulazione dopaminergica hanno fornito nuove prospettive sul funzionamento della malattia di Parkinson e sui disturbi compulsivi, mettendo in luce come alterazioni nei circuiti di rinforzo possano influenzare le decisioni e i comportamenti.",
    "crumbs": [
      "Modelli cognitivi",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/introduction_cognitive_models.html#conclusioni",
    "href": "chapters/cognitive_models/introduction_cognitive_models.html#conclusioni",
    "title": "Introduzione",
    "section": "Conclusioni",
    "text": "Conclusioni\nI modelli computazionali della cognizione hanno una lunga tradizione, iniziata nella prima metà del XX secolo come un intreccio di teoria computazionale e psicologia cognitiva. Nel tempo, sono emersi quattro principali approcci all’interno di questa prospettiva: modelli basati su simboli, modelli basati su connessionismi, modelli ibridi e modelli basati su probabilità. L’approccio computazionale ha contribuito a migliorare e ampliare la nostra comprensione della cognizione e del comportamento umano. Le recenti avanzate nella disponibilità di risorse computazionali e di dati, insieme all’interesse pubblico e privato nello sviluppo di tecnologie di intelligenza artificiale, forniscono un contesto fertile per la crescita e il consolidamento della prospettiva computazionale nelle scienze cognitive e nella psichiatria.",
    "crumbs": [
      "Modelli cognitivi",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/introduction_cognitive_models.html#bibliografia",
    "href": "chapters/cognitive_models/introduction_cognitive_models.html#bibliografia",
    "title": "Introduzione",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nBoden, M. A. (2008). An evaluation of computational modeling in cognitive science.\n\n\nCronbach, L. J. (1957). The two disciplines of scientific psychology. American psychologist, 12(11), 671–684.\n\n\nHitchcock, P. F., Fried, E. I., & Frank, M. J. (2022). Computational psychiatry needs time and context. Annual review of psychology, 73(1), 243–270.\n\n\nSkinner, B. F. (1965). Science and human behavior. Simon; Schuster.\n\n\nWatson, J. B. (1913). Psychology as the behaviorist views it. Psychological review, 20(2), 158.",
    "crumbs": [
      "Modelli cognitivi",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/introduction_frequentist_inference.html",
    "href": "chapters/frequentist_inference/introduction_frequentist_inference.html",
    "title": "Introduzione",
    "section": "",
    "text": "Nell’inferenza statistica esistono due approcci principali: la statistica frequentista e la statistica bayesiana. Entrambi i metodi permettono di trarre conclusioni sulla popolazione di interesse analizzando i dati, stimare quantità sconosciute, fare previsioni e testare ipotesi. Tuttavia, differiscono nell’interpretazione della probabilità e nell’integrazione di conoscenze precedenti ed evidenze.\nLa statistica bayesiana interpreta la probabilità come una misura di convinzione o grado di certezza riguardo a un evento. Questo approccio consente di incorporare conoscenze pregresse ed evidenze nell’analisi statistica utilizzando il teorema di Bayes. In questo contesto, il valore vero di un parametro della popolazione è trattato come una variabile casuale, che viene costantemente aggiornata man mano che nuovi dati vengono raccolti. Ciò porta alla formazione di una distribuzione completa nello spazio dei parametri, nota come distribuzione a posteriori, utilizzabile per fare previsioni probabilistiche e quantificare l’incertezza associata.\nD’altra parte, la statistica frequentista interpreta la probabilità come la frequenza relativa a lungo termine di un evento in un numero infinito di prove. Questo approccio si basa sull’idea che il vero valore di un parametro della popolazione sia fisso ma sconosciuto e debba essere stimato dai dati. In questo contesto, le inferenze statistiche vengono ottenute dai dati osservati utilizzando varie tecniche statistiche e facendo alcune assunzioni riguardo al processo sottostante che genera i dati.\nIn questa sezione della dispensa esamineremo i metodi frequentisti della stima puntuale, degli intervalli di confidenza e del test di ipotesi.",
    "crumbs": [
      "Frequentismo",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html",
    "title": "61  Introduzione all’inferenza frequentista",
    "section": "",
    "text": "61.1 Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nPreparazione del Notebook\nCi sono due approcci principali per l’inferenza statistica: la statistica frequentista e la statistica bayesiana. Questi metodi consentono di fare conclusioni sulla popolazione di interesse attraverso l’analisi dei dati. Entrambi gli approcci sono usati per stimare quantità sconosciute, fare previsioni e testare ipotesi, ma differiscono nella loro interpretazione della probabilità e in come integrano le conoscenze precedenti ed evidenze.\nNella statistica frequentista, la probabilità viene interpretata come la frequenza relativa a lungo termine di un evento in un numero infinito di prove. Questo approccio si basa sull’idea che il vero valore di un parametro della popolazione sia fisso, ma sconosciuto e debba essere stimato dai dati. In questo contesto, le inferenze statistiche vengono ottenute a partire dai dati osservati, mediante l’utilizzo di tecniche come la stima puntuale, gli intervalli di confidenza e il test di ipotesi, e facendo alcune assunzioni riguardo al processo sottostante che genera i dati.\nD’altra parte, la statistica bayesiana interpreta la probabilità come una misura di convinzione o grado di certezza riguardo a un evento (Jaynes, 2003). Questo approccio consente di incorporare conoscenze pregresse ed evidenze nell’analisi statistica attraverso l’uso del teorema di Bayes. In questo contesto, il vero valore di un parametro della popolazione è trattato come una variabile casuale e viene continuamente aggiornato man mano che vengono raccolti nuovi dati. Ciò porta alla formazione di una distribuzione completa nello spazio dei parametri, nota come distribuzione a posteriori, che può essere utilizzata per fare previsioni probabilistiche e quantificare l’incertezza associata.\nIn questo capitolo, approfondiremo il concetto di distribuzione campionaria che costituisce uno dei pilastri dell’inferenza statistica frequentista. La distribuzione campionaria ci permette di comprendere come le stime dei parametri della popolazione, come la media o la varianza, cambiano da campione a campione. In particolare, la distribuzione campionaria ci consente di stabilire delle proprietà probabilistiche delle stime campionarie, come ad esempio la loro media e la loro varianza. Queste proprietà sono utili per costruire gli intervalli di fiducia e i test di ipotesi che costituiscono gli strumenti principali dell’inferenza statistica frequentista.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#i-frequentisti-sono-razzisti",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#i-frequentisti-sono-razzisti",
    "title": "61  Introduzione all’inferenza frequentista",
    "section": "61.2 I Frequentisti sono Razzisti?",
    "text": "61.2 I Frequentisti sono Razzisti?\nNel ?sec-bayes_theorem, abbiamo esaminato le origini storiche e il contesto culturale che ha contribuito all’interpretazione applicativa del teorema di Bayes fornita da Richard Price. Queste origini sono legate alle idee alla base della rivoluzione americana, rappresentando quello che potremmo definire il “lato luminoso” del liberalismo moderno.\nLe origini culturali dell’approccio frequentista, invece, sono diametralmente opposte e strettamente connesse a quella che potremmo chiamare la “parte oscura” della modernità. Si potrebbe dire che l’avversione per la soggettività abbia guidato l’ascesa del frequentismo.\nFrancis Galton (1822-1911) fu un uomo straordinario sotto molti aspetti. Cugino di Charles Darwin e medico qualificato, ereditò una fortuna che gli permise di dedicarsi liberamente ai suoi interessi. Esplorò l’Africa, ricevendo una medaglia dalla Royal Geographical Society, e diede un importante contributo alla meteorologia, notando per primo il fenomeno degli “anticicloni”. Tuttavia, il suo contributo più significativo riguardò l’uso della statistica nello studio degli esseri umani, in particolare nell’analisi della trasmissione ereditaria del talento.\nGalton trascorse gran parte della sua carriera all’University College di Londra, dove fece numerose scoperte. Tra queste, un importante contributo riguardava la distribuzione normale. Fu anche il primo a spiegare il concetto che oggi conosciamo come “regressione verso la media”, da lui chiamato “regressione verso la mediocrità”.\nIl suo interesse per l’ereditarietà del talento portò Francis Galton a scrivere il libro Hereditary Genius, in cui analizzava come individui brillanti tendessero a concentrarsi in specifiche famiglie. Fu lui a coniare l’espressione “nature and nurture” per riferirsi ai due fattori fondamentali che influenzano lo sviluppo umano: l’ereditarietà (ciò che oggi chiamiamo genetica) e l’ambiente.\nTuttavia, Galton non si limitò a osservare e documentare la distribuzione dell’intelligenza. Il suo obiettivo era ambizioso e controverso: creare una scienza per il “miglioramento della specie umana”, che egli chiamò “eugenetica”. Promuoveva l’idea di incoraggiare la riproduzione tra le famiglie considerate di maggior successo e, al contrario, di scoraggiarla tra quelle ritenute meno fortunate.\nVa però sottolineato che Galton abbracciava idee profondamente razziste. In una lettera pubblicata sul Times di Londra, descrisse gli africani come “inferiori” e li definì “selvaggi pigri e chiacchieroni”. Gli arabi, secondo lui, erano “poco più che consumatori della produzione altrui”. Proponeva inoltre di consegnare l’Africa orientale ai cinesi, che giudicava “inclini alla menzogna e alla servilità” ma anche, a suo dire, “naturalmente industriosi e amanti dell’ordine”. Per Galton, gli anglosassoni rappresentavano la razza migliore esistente, sebbene ritenesse che gli antichi ateniesi fossero stati il vertice dell’umanità.\nIl lavoro di Galton ispirò una generazione successiva di statistici, in particolare Karl Pearson (1857-1936) e Ronald Fisher (1890-1962). Come Galton, Fisher e Pearson erano brillanti, ma condividevano anche le sue idee razziste, considerate inaccettabili sia per gli standard attuali che per quelli del loro tempo.\nKarl Pearson, poliedrico studioso e innovatore, divenne professore di matematica applicata all’UCL nel 1885, seguendo le orme di Francis Galton. Dopo la morte di quest’ultimo, ereditò la cattedra di eugenetica, istituita e finanziata da Galton stesso. Pearson fondò la rivista di statistica Biometrika e diede un contributo fondamentale alla disciplina, sviluppando il test del chi quadrato e coniando il termine “deviazione standard”.\nRonald Fisher, più giovane, succedette a Pearson come professore di eugenetica presso l’UCL. Considerato un gigante della teoria statistica, Fisher contribuì in modo decisivo allo sviluppo della disciplina, inventando o perfezionando strumenti fondamentali come l’analisi della varianza (ANOVA), il concetto di “significatività statistica” e il metodo della massima verosimiglianza (MLE).\nTutti questi ricercatori cercarono di allontanare la statistica dall’approccio soggettivo di Laplace e Bayes. Come Galton, sia Pearson che Fisher erano convinti sostenitori dell’eugenetica.\nÈ interessante riflettere su quanto le idee di Galton, Pearson e Fisher sull’eugenetica possano aver influenzato le loro visioni scientifiche. Secondo alcuni studiosi, la storia della statistica e quella dell’eugenetica sono strettamente intrecciate. Fisher, e in misura minore Pearson, rigettavano il bayesianesimo perché desideravano conferire un fondamento apparentemente “oggettivo” alle loro idee eugenetiche. Se fosse stata la scienza a “dimostrare” che alcune razze erano inferiori ad altre, o che la riproduzione tra i poveri dovesse essere scoraggiata, queste teorie sarebbero state presentate come indiscutibili. Il bayesianesimo, con la sua componente intrinseca di soggettività, rappresentava una minaccia a questa pretesa di oggettività.\nQuanto dovremmo considerare le implicazioni storiche ed etiche quando valutiamo la statistica frequentista? Chivers (2024) risponde così: è indubbio che una parte dell’ideologia razziale nazista possa essere ricondotta a Galton senza troppe difficoltà. Tuttavia, questa riflessione, per quanto cruciale dal punto di vista storico ed etico, non è direttamente rilevante in ambito strettamente statistico. La domanda fondamentale rimane: “Quale approccio è corretto?” o, meglio ancora, “Quale approccio è più utile?”, anziché chiedersi “Quale approccio ha avuto i sostenitori più discutibili?”.\nPur riconoscendo il valore di questa risposta in termini di focalizzazione sulla metodologia, ritengo che sia intrinsecamente inadeguata. Consideriamo uno scenario ipotetico: supponiamo che in una “torre d’avorio” – che sia la statistica, l’accademia o la scienza in generale – la teoria A risulti più efficace della teoria B. Tuttavia, al di fuori di questo contesto isolato, la teoria A comporta conseguenze etiche inaccettabili, mentre la teoria B no. Dovremmo davvero accettare A semplicemente perché funziona meglio in un sistema chiuso e teorico? La mia risposta è un categorico no.\nLe cosiddette “torri d’avorio” sono costruzioni ideologiche che non rispecchiano la realtà. Non esiste una netta separazione tra “dentro” e “fuori”: scienza ed etica non operano in compartimenti stagni, ma interagiscono costantemente. L’idea di giudicare una teoria esclusivamente sulla base della sua efficacia all’interno di un contesto limitato ignora le sue implicazioni più ampie e potenzialmente dannose.\nNel caso specifico del frequentismo, è evidente – come dimostreremo in seguito – che questo approccio non solo presenta implicazioni etiche problematiche, ma è anche intrinsecamente fallace dal punto di vista metodologico. La sua supposta efficacia in un ambito ristretto è un’illusione che non regge a un’analisi critica più ampia. Non possiamo, né dobbiamo, separare l’efficacia teorica dalle conseguenze pratiche ed etiche. Il frequentismo fallisce su entrambi i fronti: morale e scientifico. Difenderlo, quindi, risulta insostenibile in ogni contesto.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#stime-stimatori-e-parametri",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#stime-stimatori-e-parametri",
    "title": "61  Introduzione all’inferenza frequentista",
    "section": "61.3 Stime, stimatori e parametri",
    "text": "61.3 Stime, stimatori e parametri\nSpostiamo ora il discorso da un piano culturale ad un piano strettamente statistico. Consideriamo il concetto di stima statistica.\nQuando si analizzano i dati, solitamente si è interessati a una quantità a livello di popolazione; tuttavia, di solito si ha accesso solo a un campione di osservazioni. La quantità sconosciuta di nostro interesse viene chiamata parametro. La statistica che calcoliamo utilizzando i dati del campione viene chiamata stima, e la formula che la produce viene chiamata stimatore. Formalmente, uno stimatore è una funzione dei dati osservati utilizzata per produrre una stima di un parametro.\nIn altre parole, quando analizziamo un campione di dati, vogliamo inferire alcune proprietà della popolazione di cui il campione è rappresentativo. Il parametro rappresenta la misura di tali proprietà, ma spesso non è possibile calcolarlo direttamente sulla popolazione. Pertanto, lo stimiamo utilizzando le osservazioni del campione. La stima è quindi l’approssimazione del valore del parametro che otteniamo dal nostro campione, mentre lo stimatore è la formula matematica utilizzata per calcolare questa stima.\nTuttavia, le stime non sono necessariamente identiche ai parametri di nostro interesse. Le stime presentano una certa incertezza dovuta alla variabilità del campionamento. In questo capitolo esamineremo come l’approccio frequentista quantifica l’incertezza nelle nostre stime, in modo da poter trarre conclusioni sul parametro.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#distribuzione-campionaria",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#distribuzione-campionaria",
    "title": "61  Introduzione all’inferenza frequentista",
    "section": "61.4 Distribuzione campionaria",
    "text": "61.4 Distribuzione campionaria\nIn questo capitolo esploreremo come la media di un campione casuale può essere utilizzata per stimare la media \\(\\mu\\) di una popolazione. Per valutare l’incertezza di questa stima, ci avvaliamo del concetto di distribuzione campionaria, un’importante idea dell’approccio frequentista.\nPer introdurre il concetto, utilizzeremo una popolazione finita di piccole dimensioni, pur sapendo che le proprietà illustrate valgono anche per popolazioni di dimensioni maggiori.\n\n61.4.1 Esempio introduttivo\nConsideriamo la seguente popolazione:\n\nx &lt;- c(2, 4.5, 5, 5.5)\nx\n#&gt; [1] 2.0 4.5 5.0 5.5\n\nL’istogramma sottostante rappresenta la distribuzione di frequenza della popolazione:\n\nhist(\n  x, breaks = 5, \n  freq = FALSE, \n  main = \"Distribuzione della popolazione\", \n  xlab = \"Valori\"\n)\n\n\n\n\n\n\n\n\nCalcoliamo la media e la varianza della popolazione:\n\nmean(x)  # Media\n#&gt; [1] 4.25\nvar(x)   # Varianza\n#&gt; [1] 2.416667\n\n\n\n61.4.2 Campionamento\nSupponiamo ora di estrarre tutti i possibili campioni di dimensione \\(n = 2\\) dalla popolazione. Per generare queste combinazioni:\n\nsamples &lt;- expand.grid(x, x)\nsamples\n#&gt;    Var1 Var2\n#&gt; 1   2.0  2.0\n#&gt; 2   4.5  2.0\n#&gt; 3   5.0  2.0\n#&gt; 4   5.5  2.0\n#&gt; 5   2.0  4.5\n#&gt; 6   4.5  4.5\n#&gt; 7   5.0  4.5\n#&gt; 8   5.5  4.5\n#&gt; 9   2.0  5.0\n#&gt; 10  4.5  5.0\n#&gt; 11  5.0  5.0\n#&gt; 12  5.5  5.0\n#&gt; 13  2.0  5.5\n#&gt; 14  4.5  5.5\n#&gt; 15  5.0  5.5\n#&gt; 16  5.5  5.5\n\nOgni riga rappresenta un campione possibile. Calcoliamo il numero totale di campioni:\n\nnrow(samples)\n#&gt; [1] 16\n\nOra calcoliamo la media di ciascun campione, ottenendo la distribuzione campionaria delle medie per \\(n = 2\\):\n\nsample_means &lt;- rowMeans(samples)\nsample_means\n#&gt;  [1] 2.00 3.25 3.50 3.75 3.25 4.50 4.75 5.00 3.50 4.75 5.00 5.25 3.75 5.00\n#&gt; [15] 5.25 5.50\n\n\n\n61.4.3 Visualizzazione della distribuzione campionaria\nPossiamo rappresentare graficamente questa distribuzione:\n\nhist(\n  sample_means, \n  breaks = 5, \n  freq = FALSE, \n  main = \"Distribuzione campionaria delle medie (n = 2)\", \n  xlab = \"Media campionaria\"\n)\n\n\n\n\n\n\n\n\n\n\n61.4.4 Verifiche teoriche\n\n61.4.4.1 Media della distribuzione campionaria\nLa media della distribuzione campionaria deve essere uguale alla media della popolazione:\n\nmean(x)  # Media della popolazione\n#&gt; [1] 4.25\nmean(sample_means)  # Media della distribuzione campionaria\n#&gt; [1] 4.25\n\n\n\n61.4.4.2 Varianza della distribuzione campionaria\nLa varianza della distribuzione campionaria deve essere pari alla varianza della popolazione divisa per \\(n\\):\n\n# Evito la divisione per (n - 1)\nvariance &lt;- function(x) {\n  mean((x - mean(x))^2)\n}\n\n\nvariance(x) / 2  # Varianza teorica\n#&gt; [1] 0.90625\nvariance(sample_means)  # Varianza empirica\n#&gt; [1] 0.90625\n\n\n\n\n61.4.5 Esempio di campione osservato\nConsideriamo un singolo campione, ad esempio \\(\\{5, 5.5\\}\\):\n\nobserved_sample &lt;- c(5, 5.5)\nobserved_sample\n#&gt; [1] 5.0 5.5\n\nTroviamo la sua media e deviazione standard:\n\nmean(observed_sample)  # Media del campione\n#&gt; [1] 5.25\nsqrt(variance(observed_sample))    # Deviazione standard del campione\n#&gt; [1] 0.25\n\nConfrontiamo questi valori con quelli della popolazione:\n\nmean(x)  # Media della popolazione\n#&gt; [1] 4.25\nsqrt(variance(x))     # Deviazione standard della popolazione\n#&gt; [1] 1.346291\n\nIn conclusione, dalla simulazione emergono due risultati fondamentali:\n\nLa media della distribuzione campionaria coincide con la media della popolazione. Questo significa che, se si considera la media \\(\\bar{X}_n\\) di campioni casuali di ampiezza \\(n\\), il valore atteso di \\(\\bar{X}_n\\) è uguale alla media della popolazione \\(\\mu\\). Formalmente:\n\\[\n\\mathbb{E}(\\bar{X}_n) = \\frac{1}{n} \\mathbb{E}(S_n) = \\frac{1}{n} n \\mu = \\mu,\n\\] dove \\(\\mathbb{E}(\\cdot)\\) rappresenta il valore atteso e \\(S_n\\) la somma delle osservazioni nel campione.\nLa varianza della distribuzione campionaria è inferiore alla varianza della popolazione. In particolare, la varianza delle medie campionarie è data dalla varianza della popolazione divisa per l’ampiezza del campione, ovvero:\n\\[\n\\mathbb{V}(\\bar{X}) = \\frac{\\sigma^2}{n}.\n\\]\n\n\n\n\n\n\n\nNota\n\n\n\nIl secondo risultato sopra può essere dimostrato come segue.\nSia \\(X_1, X_2, \\dots, X_n\\) un campione casuale di \\(n\\) osservazioni indipendenti estratte da una popolazione con media \\(\\mu\\) e varianza \\(\\sigma^2\\). La media campionaria è definita come:\n\\[\n\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i.\n\\]\nPer definizione, la varianza di \\(\\bar{X}\\) è:\n\\[\n\\mathbb{V}(\\bar{X}) = \\mathbb{V}\\left(\\frac{1}{n} \\sum_{i=1}^n X_i\\right).\n\\]\nPoiché una costante moltiplicata da una variabile aleatoria può essere “estratta” dalla varianza, otteniamo:\n\\[\n\\mathbb{V}(\\bar{X}) = \\frac{1}{n^2} \\mathbb{V}\\left(\\sum_{i=1}^n X_i\\right).\n\\]\nOra dobbiamo calcolare \\(\\mathbb{V}\\left(\\sum_{i=1}^n X_i\\right)\\). Le variabili \\(X_1, X_2, \\dots, X_n\\) sono indipendenti, quindi la varianza della somma è la somma delle varianze:\n\\[\n\\mathbb{V}\\left(\\sum_{i=1}^n X_i\\right) = \\sum_{i=1}^n \\mathbb{V}(X_i).\n\\]\nPoiché tutte le variabili \\(X_i\\) hanno la stessa varianza \\(\\sigma^2\\):\n\\[\n\\mathbb{V}\\left(\\sum_{i=1}^n X_i\\right) = n \\sigma^2.\n\\]\nSostituendo nella formula precedente, otteniamo:\n\\[\n\\mathbb{V}(\\bar{X}) = \\frac{1}{n^2} \\cdot n \\sigma^2 = \\frac{\\sigma^2}{n}.\n\\]\nIn generale, dunque, per un campione di ampiezza \\(n\\), vale la relazione \\(\\mathbb{V}(\\bar{X}) = \\frac{\\sigma^2}{n}\\).\n\n\n\n\n61.4.6 Proprietà della distribuzione campionaria\nInfine, osserviamo una proprietà fondamentale della distribuzione campionaria:\n\nSe la popolazione segue una distribuzione normale, allora anche la distribuzione delle medie campionarie seguirà una distribuzione normale, indipendentemente dall’ampiezza del campione.\nSe invece la popolazione non segue una distribuzione normale, il teorema del limite centrale garantisce che, all’aumentare della dimensione del campione \\(n\\), la distribuzione campionaria delle medie tenderà a una distribuzione normale.\n\nQueste proprietà sono centrali in molti metodi statistici, poiché consentono di fare inferenza sulla popolazione utilizzando campioni.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#teorema-del-limite-centrale",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#teorema-del-limite-centrale",
    "title": "61  Introduzione all’inferenza frequentista",
    "section": "61.5 Teorema del Limite Centrale",
    "text": "61.5 Teorema del Limite Centrale\nEsaminiamo ora più in dettaglio il Teorema del Limite Centrale (TLC). Nel 1812, Laplace dimostrò il TLC, che afferma che la somma di una sequenza di variabili casuali indipendenti tende a distribuirsi secondo una distribuzione Normale. Inoltre, il TLC stabilisce i parametri della distribuzione Normale risultante in base ai valori attesi e alle varianze delle variabili casuali sommate.\n\nTeorema 61.1 Si supponga che \\(Y = Y_1, \\dots, Y_i, \\ldots, Y_n\\) sia una sequenza di v.a. i.i.d. (variabili aleatorie identicamente distribuite e indipendenti) con \\(\\mathbb{E}(Y_i) = \\mu\\) e \\(SD(Y_i) = \\sigma\\). Si definisca una nuova variabile casuale come:\n\\[\nZ = \\frac{1}{n} \\sum_{i=1}^n Y_i.\n\\]\nCon \\(n \\rightarrow \\infty\\), \\(Z\\) tenderà a seguire una distribuzione Normale con lo stesso valore atteso di \\(Y_i\\) e una deviazione standard ridotta di un fattore pari a \\(\\frac{1}{\\sqrt{n}}\\):\n\\[\np_Z(z) \\rightarrow \\mathcal{N}\\left(z \\ \\Bigg| \\ \\mu, \\, \\frac{\\sigma}{\\sqrt{n}} \\right).\n\\]\n\nIl TLC può essere generalizzato a variabili casuali che non sono identicamente distribuite, a condizione che siano indipendenti e abbiano aspettative e varianze finite. Molti fenomeni naturali, come l’altezza degli adulti, sono il risultato di una combinazione di effetti additivi relativamente piccoli. Questi effetti, indipendentemente dalla loro distribuzione individuale, tendono a portare alla normalità della distribuzione risultante. Questa è la ragione per cui la distribuzione normale fornisce una buona approssimazione per la distribuzione di molti fenomeni naturali.\n\n61.5.1 Illustrazione del TLC\nPer dimostrare il Teorema del Limite Centrale, consideriamo una popolazione iniziale con una distribuzione fortemente asimmetrica: una distribuzione Beta con parametri \\(\\alpha = 2\\) e \\(\\beta = 1\\). Estraiamo 50.000 campioni casuali di ampiezza \\(n\\) da questa popolazione e costruiamo la distribuzione campionaria delle medie.\nDefiniamo una funzione per simulare e visualizzare la distribuzione campionaria per diversi valori di \\(n\\):\n\n# Parametri della distribuzione Beta\nalpha &lt;- 2\nbeta &lt;- 1\n\n# Funzione per simulare e visualizzare la distribuzione campionaria\nplot_samples &lt;- function(n) {\n  # Media e deviazione standard della distribuzione Beta\n  mu &lt;- alpha / (alpha + beta)\n  sigma &lt;- sqrt(alpha * beta / ((alpha + beta)^2 * (alpha + beta + 1)))\n  \n  # Generazione di 50.000 campioni casuali di dimensione n\n  sample_means &lt;- replicate(50000, mean(rbeta(n, alpha, beta)))\n  \n  # Dati per la distribuzione normale teorica\n  x &lt;- seq(mu - 3 * sigma, mu + 3 * sigma, length.out = 100)\n  y &lt;- dnorm(x, mean = mu, sd = sigma / sqrt(n))\n  \n  # Creazione del grafico\n  hist(\n    sample_means, \n    breaks = 50, \n    probability = TRUE, \n    main = paste(\"Ampiezza campionaria =\", n), \n    xlab = \"Media campionaria\", \n    ylab = \"Densità\"\n  )\n  lines(x, y, col = \"black\", lwd = 2)\n}\n\n\n\n61.5.2 Visualizzazione per diverse dimensioni campionarie\n\nAmpiezza campionaria \\(n = 1\\)\n\nSe \\(n = 1\\), la distribuzione campionaria delle medie coincide con la popolazione di partenza.\n\nplot_samples(1)\n\n\n\n\n\n\n\n\n\nAmpiezza campionaria \\(n = 2\\)\n\nPer \\(n = 2\\), la distribuzione delle medie dei campioni inizia ad avvicinarsi alla normalità.\n\nplot_samples(2)\n\n\n\n\n\n\n\n\n\nAmpiezza campionaria \\(n = 4\\)\n\nPer \\(n = 4\\), l’approssimazione alla distribuzione normale migliora.\n\nplot_samples(4)\n\n\n\n\n\n\n\n\n\nAmpiezza campionaria \\(n = 30\\)\n\nPer \\(n = 30\\), la distribuzione campionaria delle medie è ben approssimata dalla normale.\n\nplot_samples(30)\n\n\n\n\n\n\n\n\nIn conclusione, il Teorema del Limite Centrale (TLC) afferma che, indipendentemente dalla forma della distribuzione della popolazione:\n\nPer campioni di dimensione sufficiente, la distribuzione campionaria delle medie \\(\\bar{X}\\) tende a una distribuzione normale.\nLa media \\(\\mu\\) e la deviazione standard \\(\\sigma\\) della popolazione determinano la distribuzione delle medie campionarie come segue:\n\\[\n\\bar{X} \\sim \\mathcal{N}(\\mu, \\sigma / \\sqrt{n}),\n\\]\ndove \\(n\\) è l’ampiezza del campione.\n\nQuesta proprietà ha implicazioni fondamentali:\n\nLa normalità emergente giustifica l’uso della distribuzione normale anche quando i dati non sono inizialmente normali.\nIl TLC fornisce una formula esplicita per calcolare l’errore standard \\(\\sigma / \\sqrt{n}\\), che quantifica la precisione della media campionaria come stima della media della popolazione.\n\n\n\n61.5.3 Applicazioni in psicologia\nMolti fenomeni psicologici che misuriamo (ad esempio, il QI come media di molte abilità cognitive) derivano dalla media di più variabili, e quindi seguono la distribuzione normale grazie al TLC. Questo spiega perché la distribuzione normale appare così frequentemente nei dati sperimentali di psicologia e in molte altre discipline scientifiche.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#distribuzioni-campionarie-di-altre-statistiche",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#distribuzioni-campionarie-di-altre-statistiche",
    "title": "61  Introduzione all’inferenza frequentista",
    "section": "61.6 Distribuzioni campionarie di altre statistiche",
    "text": "61.6 Distribuzioni campionarie di altre statistiche\nAbbiamo già analizzato la distribuzione campionaria della media dei campioni. Tuttavia, è possibile costruire distribuzioni campionarie per altre statistiche campionarie. Ad esempio, consideriamo la distribuzione campionaria del valore massimo e della varianza.\n\n61.6.1 Distribuzione campionaria del valore massimo\nSupponiamo di avere una popolazione normalmente distribuita con media \\(\\mu = 100\\) e deviazione standard \\(\\sigma = 15\\). Generiamo 10.000 campioni casuali di ampiezza \\(n = 5\\) e calcoliamo il valore massimo per ogni campione.\n\n61.6.1.1 Simulazione e visualizzazione\n\nset.seed(123)  # Per risultati riproducibili\n\n# Parametri della distribuzione\nmu &lt;- 100\nsigma &lt;- 15\n\n# Simulazione: calcolo del valore massimo per ciascun campione\nn_samples &lt;- 10000\nsample_maxes &lt;- replicate(\n  n_samples, \n  max(rnorm(5, mean = mu, sd = sigma))\n)\n\n# Istogramma della distribuzione campionaria del valore massimo\nhist(\n  sample_maxes, \n  breaks = 50, \n  probability = TRUE, \n  main = \"Distribuzione campionaria del valore massimo\",\n  xlab = \"Valore massimo\", \n  ylab = \"Densità\"\n)\n\n# Sovrapposizione della distribuzione normale della popolazione\ncurve(dnorm(x, mean = mu, sd = sigma), add = TRUE, col = \"black\", lwd = 2)\n\n\n\n\n\n\n\n\nOsserviamo che il valore atteso della distribuzione campionaria del massimo è maggiore della media della popolazione \\(\\mu\\).\n\n\n\n61.6.2 Distribuzione campionaria della varianza\nUn’altra statistica interessante è la varianza campionaria. La formula della varianza campionaria, basata sulla statistica descrittiva, è:\n\\[\nS^2 = \\frac{\\sum_{i=1}^n (Y_i - \\bar{Y})^2}{n}.\n\\]\nCalcoliamo la distribuzione campionaria della varianza per campioni di ampiezza \\(n = 5\\).\n\n61.6.2.1 Simulazione e visualizzazione\n\nset.seed(123)\n\n# Simulazione: calcolo della varianza per ciascun campione\nsample_vars &lt;- replicate(\n  n_samples, \n  variance(rnorm(5, mean = mu, sd = sigma))\n)\n\n# Istogramma della distribuzione campionaria della varianza\nhist(\n  sample_vars, \n  breaks = 50, \n  probability = TRUE, \n  main = \"Distribuzione campionaria della varianza\",\n  xlab = \"Varianza\", ylab = \"Densità\"\n)\n\n\n\n\n\n\n\n\n\n# Media empirica della varianza campionaria\nmean(sample_vars)\n#&gt; [1] 180.6569\n\nSappiamo che la varianza della popolazione è \\(\\sigma^2 = 15^2 = 225\\). Tuttavia, il valore medio empirico delle varianze campionarie calcolate con \\(S^2\\) risulta minore di 225. Questo avviene perché lo stimatore \\(S^2\\) è distorto.\n\n\n\n61.6.3 Correzione della distorsione\nPer eliminare la distorsione, utilizziamo il seguente stimatore della varianza della popolazione:\n\\[\ns^2 = \\frac{\\sum_{i=1}^n (Y_i - \\bar{Y})^2}{n-1}.\n\\]\n\n61.6.3.1 Verifica con simulazione\n\nset.seed(123)\n\n# Simulazione: calcolo della varianza con la correzione\nsample_vars_unbiased &lt;- replicate(\n  n_samples, \n  var(rnorm(5, mean = mu, sd = sigma))\n)\n\n# Istogramma della distribuzione campionaria della varianza corretta\nhist(\n  sample_vars_unbiased, \n  breaks = 50, \n  probability = TRUE, \n  main = \"Distribuzione campionaria della varianza (corretta)\",\n  xlab = \"Varianza\", \n  ylab = \"Densità\"\n)\n\n\n\n\n\n\n\n\n\n# Media empirica della varianza corretta\nmean(sample_vars_unbiased)\n#&gt; [1] 225.8211\n\nCon questo stimatore, la media della distribuzione campionaria coincide con la varianza reale della popolazione \\(\\sigma^2 = 225\\).\nIn conclusione:\n\nLa distribuzione campionaria del massimo mostra che il valore massimo dei campioni è, in media, maggiore della media della popolazione.\nLa varianza campionaria non corretta (\\(S^2\\)) è uno stimatore distorto, poiché il suo valore atteso non coincide con la varianza della popolazione.\nLo stimatore corretto \\(s^2\\), che utilizza il divisore \\(n - 1\\), elimina la distorsione e fornisce una stima non distorta della varianza della popolazione.\n\nIn generale, uno stimatore è considerato non distorto quando il valore atteso delle sue stime coincide con il valore reale del parametro. Nel caso della media campionaria e della varianza corretta, entrambi gli stimatori sono non distorti.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#riflessioni-conclusive",
    "title": "61  Introduzione all’inferenza frequentista",
    "section": "61.7 Riflessioni Conclusive",
    "text": "61.7 Riflessioni Conclusive\nIn generale, i parametri della popolazione sono sconosciuti, ma possiamo stimarli utilizzando le informazioni del campione. Di seguito viene presentata una tabella che riassume i simboli comuni utilizzati per indicare le quantità note e sconosciute nel contesto dell’inferenza statistica. Questo ci aiuterà a tenere traccia di ciò che sappiamo e ciò che non sappiamo.\n\n\n\n\n\n\n\n\nSimbolo\nNome\nÈ qualcosa che conosciamo?\n\n\n\n\n\\(s\\)\nDeviazione standard del campione\nSì, la calcoliamo dai dati grezzi\n\n\n\\(\\sigma\\)\nDeviazione standard della popolazione\nNo, tranne in casi particolari o nelle simulazioni\n\n\n\\(\\hat{\\sigma}\\)\nStima della deviazione standard della popolazione\nSì, ma non è uguale a \\(\\sigma\\)\n\n\n\\(s^2\\)\nVarianza del campione\nSì, la calcoliamo dai dati grezzi\n\n\n\\(\\sigma^2\\)\nVarianza della popolazione\nNo, tranne in casi particolari o nelle simulazioni\n\n\n\\(\\hat{\\sigma}^2\\)\nStima della varianza della popolazione\nSì, ma non è uguale a \\(\\sigma^2\\)\n\n\n\n\nUtilizzando le informazioni di un campione casuale di ampiezza \\(n\\):\n\nLa stima migliore che possiamo ottenere per la media \\(\\mu\\) della popolazione è la media del campione \\(\\bar{Y}\\).\nLa stima migliore che possiamo ottenere per la varianza \\(\\sigma^2\\) della popolazione è:\n\n\\[\n\\hat{\\sigma}^2 = \\frac{1}{n-1} \\sum_{i=1}^n (Y_i - \\bar{Y})^2.\n\\]",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#informazioni-sullambiente-di-sviluppo",
    "title": "61  Introduzione all’inferenza frequentista",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] mice_3.16.0       MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2\n#&gt;  [5] ggpubr_0.6.0      ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0  \n#&gt;  [9] bayesplot_1.11.1  psych_2.4.6.26    scales_1.3.0      markdown_1.13    \n#&gt; [13] knitr_1.49        lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1    \n#&gt; [17] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n#&gt; [21] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3        \n#&gt; [25] here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tidyselect_1.2.1  farver_2.1.2      fastmap_1.2.0     pacman_0.5.1     \n#&gt;  [5] promises_1.3.1    rpart_4.1.23      digest_0.6.37     timechange_0.3.0 \n#&gt;  [9] mime_0.12         lifecycle_1.0.4   survival_3.7-0    magrittr_2.0.3   \n#&gt; [13] compiler_4.4.2    rlang_1.1.4       tools_4.4.2       utf8_1.2.4       \n#&gt; [17] yaml_2.3.10       ggsignif_0.6.4    htmlwidgets_1.6.4 mnormt_2.1.1     \n#&gt; [21] abind_1.4-8       miniUI_0.1.1.1    withr_3.0.2       nnet_7.3-19      \n#&gt; [25] grid_4.4.2        fansi_1.0.6       jomo_2.7-6        xtable_1.8-4     \n#&gt; [29] colorspace_2.1-1  iterators_1.0.14  cli_3.6.3         rmarkdown_2.29   \n#&gt; [33] generics_0.1.3    tzdb_0.4.0        minqa_1.2.8       splines_4.4.2    \n#&gt; [37] parallel_4.4.2    vctrs_0.6.5       boot_1.3-31       glmnet_4.1-8     \n#&gt; [41] Matrix_1.7-1      jsonlite_1.8.9    carData_3.0-5     car_3.1-3        \n#&gt; [45] hms_1.1.3         mitml_0.4-5       rstatix_0.7.2     Formula_1.2-5    \n#&gt; [49] foreach_1.5.2     glue_1.8.0        pan_1.9           nloptr_2.1.1     \n#&gt; [53] codetools_0.2-20  stringi_1.8.4     gtable_0.3.6      shape_1.4.6.1    \n#&gt; [57] later_1.4.0       lme4_1.1-35.5     munsell_0.5.1     pillar_1.9.0     \n#&gt; [61] htmltools_0.5.8.1 R6_2.5.1          rprojroot_2.0.4   evaluate_1.0.1   \n#&gt; [65] shiny_1.9.1       lattice_0.22-6    backports_1.5.0   broom_1.0.7      \n#&gt; [69] httpuv_1.6.15     Rcpp_1.0.13-1     nlme_3.1-166      xfun_0.49        \n#&gt; [73] pkgconfig_2.0.3",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#bibliografia",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#bibliografia",
    "title": "61  Introduzione all’inferenza frequentista",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nChivers, T. (2024). Everything is Predictable: How Bayesian Statistics Explain Our World. Simon; Schuster.\n\n\nJaynes, E. T. (2003). Probability theory: The logic of science. Cambridge University Press.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html",
    "href": "chapters/frequentist_inference/02_conf_interv.html",
    "title": "62  Intervallo di confidenza",
    "section": "",
    "text": "62.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nGli intervalli di confidenza sono uno strumento fondamentale nell’inferenza statistica frequentista. Essi consentono di stimare un parametro sconosciuto di una popolazione, come la media \\(\\mu\\), tenendo conto dell’incertezza derivante dal fatto che la stima si basa su un campione. Questo materiale didattico si propone di spiegare in modo dettagliato e chiaro la costruzione di un intervallo di confidenza per la media di una popolazione, sia nel caso di varianza nota sia in quello di varianza incognita.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Intervallo di confidenza</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#inferenza-statistica-frequentista-e-media-campionaria",
    "href": "chapters/frequentist_inference/02_conf_interv.html#inferenza-statistica-frequentista-e-media-campionaria",
    "title": "62  Intervallo di confidenza",
    "section": "62.2 Inferenza Statistica Frequentista e Media Campionaria",
    "text": "62.2 Inferenza Statistica Frequentista e Media Campionaria\nQuando estraiamo un campione casuale semplice \\(X_1, X_2, \\dots, X_n\\) da una popolazione con media \\(\\mu\\) e varianza \\(\\sigma^2\\), la media campionaria \\(\\bar{X}\\) è definita come:\n\\[\n\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i.\n\\]\nLa media campionaria \\(\\bar{X}\\) è una variabile casuale perché dipende dai valori osservati nel campione, che sono essi stessi casuali. Le proprietà della media campionaria sono le seguenti:\n\nMedia della distribuzione campionaria: \\(E[\\bar{X}] = \\mu\\). La media campionaria è uno stimatore non distorto della media della popolazione.\nVarianza della distribuzione campionaria: \\(\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n}\\). Questo significa che la precisione di \\(\\bar{X}\\) come stima di \\(\\mu\\) aumenta con il numero di osservazioni \\(n\\).\n\nQueste proprietà sono fondamentali per calcolare un intervallo di confidenza, poiché ci permettono di descrivere la distribuzione di \\(\\bar{X}\\).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Intervallo di confidenza</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#intervallo-di-confidenza-per-la-media-caso-di-varianza-nota",
    "href": "chapters/frequentist_inference/02_conf_interv.html#intervallo-di-confidenza-per-la-media-caso-di-varianza-nota",
    "title": "62  Intervallo di confidenza",
    "section": "62.3 Intervallo di Confidenza per la Media: Caso di Varianza Nota",
    "text": "62.3 Intervallo di Confidenza per la Media: Caso di Varianza Nota\nSupponiamo che la popolazione sia distribuita normalmente con media \\(\\mu\\) e varianza \\(\\sigma^2\\), e che \\(\\sigma^2\\) sia nota. La distribuzione della media campionaria \\(\\bar{X}\\) è anch’essa normale:\n\\[\n\\bar{X} \\sim \\mathcal{N}\\left(\\mu, \\frac{\\sigma^2}{n}\\right).\n\\]\n\n62.3.1 Passo 1: Standardizzazione della Media Campionaria\nPer lavorare con una distribuzione normale standard (media 0 e varianza 1), standardizziamo \\(\\bar{X}\\) utilizzando la formula:\n\\[\nZ = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}}.\n\\]\nQui, \\(\\sigma / \\sqrt{n}\\) è la deviazione standard della distribuzione campionaria di \\(\\bar{X}\\).\nDopo questa trasformazione, la variabile \\(Z\\) segue una distribuzione normale standard:\n\\[\nZ \\sim \\mathcal{N}(0, 1).\n\\]\n\n\n62.3.2 Passo 2: Determinazione del Livello di Confidenza\nScegliamo un livello di confidenza \\(\\gamma\\), ad esempio \\(\\gamma = 0.95\\). Per una distribuzione normale standard, troviamo il valore critico \\(z\\) tale che la probabilità tra \\(-z\\) e \\(+z\\) sia pari al livello di confidenza:\n\\[\nP(-z \\leq Z \\leq z) = \\gamma.\n\\]\nPer un livello di confidenza del 95%, \\(z \\approx 1.96\\).\n\n\n62.3.3 Passo 3: Formulazione dell’Intervallo di Confidenza\nPartiamo dalla probabilità per \\(Z\\):\n\\[\nP(-z \\leq Z \\leq z) = \\gamma.\n\\]\nSostituiamo la definizione di \\(Z\\):\n\\[\nP\\left(-z \\leq \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}} \\leq z\\right) = \\gamma.\n\\]\nMoltiplichiamo tutti i membri per \\(\\sigma / \\sqrt{n}\\) per rimuovere il denominatore:\n\\[\nP\\left(-z \\cdot \\frac{\\sigma}{\\sqrt{n}} \\leq \\bar{X} - \\mu \\leq z \\cdot \\frac{\\sigma}{\\sqrt{n}}\\right) = \\gamma.\n\\]\nAggiungiamo \\(\\mu\\) a tutti i membri per isolare \\(\\mu\\):\n\\[\nP\\left(\\bar{X} - z \\cdot \\frac{\\sigma}{\\sqrt{n}} \\leq \\mu \\leq \\bar{X} + z \\cdot \\frac{\\sigma}{\\sqrt{n}}\\right) = \\gamma.\n\\]\n\n\n62.3.4 Passo 4: Limiti dell’Intervallo di Confidenza\nDefiniamo i limiti inferiore e superiore dell’intervallo di confidenza:\n\\[\n\\hat{a} = \\bar{X} - z \\cdot \\frac{\\sigma}{\\sqrt{n}}, \\quad \\hat{b} = \\bar{X} + z \\cdot \\frac{\\sigma}{\\sqrt{n}}.\n\\]\nL’intervallo di confidenza per \\(\\mu\\) è quindi:\n\\[\n(\\hat{a}, \\hat{b}) = \\left(\\bar{X} - z \\cdot \\frac{\\sigma}{\\sqrt{n}}, \\bar{X} + z \\cdot \\frac{\\sigma}{\\sqrt{n}}\\right).\n\\]",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Intervallo di confidenza</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#intervallo-di-confidenza-per-la-media-caso-di-varianza-incognita",
    "href": "chapters/frequentist_inference/02_conf_interv.html#intervallo-di-confidenza-per-la-media-caso-di-varianza-incognita",
    "title": "62  Intervallo di confidenza",
    "section": "62.4 Intervallo di Confidenza per la Media: Caso di Varianza Incognita",
    "text": "62.4 Intervallo di Confidenza per la Media: Caso di Varianza Incognita\nNella maggior parte dei casi pratici, la varianza \\(\\sigma^2\\) non è nota. In questi casi, stimiamo \\(\\sigma\\) con la deviazione standard campionaria \\(s\\) e utilizziamo la distribuzione t di Student, che tiene conto dell’incertezza aggiuntiva.\n\n62.4.1 Passo 1: Distribuzione t di Student\nLa statistica che seguiamo è:\n\\[\nT = \\frac{\\bar{X} - \\mu}{s / \\sqrt{n}},\n\\]\ndove \\(T\\) segue una distribuzione t con \\(n-1\\) gradi di libertà.\n\n\n62.4.2 Passo 2: Costruzione dell’Intervallo di Confidenza\nAnalogamente al caso precedente, costruiamo l’intervallo partendo da:\n\\[\nP(-t^\\ast \\leq T \\leq t^\\ast) = \\gamma,\n\\]\ndove \\(t^\\ast\\) è il valore critico della distribuzione t per il livello di confidenza \\(\\gamma\\) e \\(n-1\\) gradi di libertà.\nSostituendo \\(T\\):\n\\[\nP\\left(-t^\\ast \\leq \\frac{\\bar{X} - \\mu}{s / \\sqrt{n}} \\leq t^\\ast\\right) = \\gamma.\n\\]\nMoltiplichiamo per \\(s / \\sqrt{n}\\):\n\\[\nP\\left(-t^\\ast \\cdot \\frac{s}{\\sqrt{n}} \\leq \\bar{X} - \\mu \\leq t^\\ast \\cdot \\frac{s}{\\sqrt{n}}\\right) = \\gamma.\n\\]\nAggiungiamo \\(\\mu\\):\n\\[\nP\\left(\\bar{X} - t^\\ast \\cdot \\frac{s}{\\sqrt{n}} \\leq \\mu \\leq \\bar{X} + t^\\ast \\cdot \\frac{s}{\\sqrt{n}}\\right) = \\gamma.\n\\]\n\n\n62.4.3 Passo 3: Limiti dell’Intervallo\nI limiti dell’intervallo sono:\n\\[\n\\hat{a} = \\bar{X} - t^\\ast \\cdot \\frac{s}{\\sqrt{n}}, \\quad \\hat{b} = \\bar{X} + t^\\ast \\cdot \\frac{s}{\\sqrt{n}}.\n\\]\nIn conclusione, gli intervalli di confidenza forniscono un modo per quantificare l’incertezza nelle stime di parametri sconosciuti. La loro costruzione dipende dalla distribuzione campionaria dello stimatore e dall’informazione disponibile sulla varianza.\n\n\n62.4.4 Applicabilità e Limitazioni\n\nIl metodo presuppone che la popolazione segua una distribuzione normale e è valido anche per campioni di piccole dimensioni (ad esempio, \\(n &lt; 30\\)) prelevati da tale popolazione.\nSe la popolazione non è normalmente distribuita e la dimensione del campione è ridotta, questo metodo potrebbe non essere idoneo.\nTuttavia, per campioni di grandi dimensioni (\\(n \\geq 30\\)), questo approccio rimane valido per la stima dell’intervallo di confidenza grazie al teorema del limite centrale, che si applica anche a popolazioni con distribuzioni non normali.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Intervallo di confidenza</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#livello-di-copertura",
    "href": "chapters/frequentist_inference/02_conf_interv.html#livello-di-copertura",
    "title": "62  Intervallo di confidenza",
    "section": "62.5 Livello di Copertura",
    "text": "62.5 Livello di Copertura\nPer interpretare correttamente gli intervalli di fiducia è fondamentale considerare il concetto di “livello di copertura”. Questo livello indica la frequenza con cui l’intervallo di fiducia include il valore reale del parametro della popolazione, in una serie di esperimenti ripetuti.\nEsempio di Livello di Copertura:\n\nSe il livello di copertura è del 95%, significa che, nel lungo periodo, il 95% degli intervalli di fiducia costruiti conterrà il valore vero del parametro.\nImportante: Questo non implica che ci sia una probabilità del 95% che il valore vero del parametro cada in un particolare intervallo di fiducia. Infatti, il parametro della popolazione è un valore fisso e non soggetto a probabilità; piuttosto, l’incertezza risiede nell’intervallo di fiducia stesso.\n\nCome Funziona la Copertura:\n\nNel contesto frequentista, la “probabilità” si riferisce alla frequenza a lungo termine di un certo evento in un gran numero di ripetizioni dell’esperimento.\nNel caso degli intervalli di fiducia, l’“esperimento” è l’estrazione di un campione dalla popolazione, e l’“evento” è la generazione di un intervallo di fiducia che contiene il valore vero del parametro.\nIl livello di copertura, generalmente indicato come \\(1-\\alpha\\), rappresenta la probabilità a lungo termine che intervalli di fiducia costruiti con questa metodologia includano il vero valore del parametro.\n\n\n62.5.1 Simulazione\n\nPer illustrare questo concetto, eseguiamo una simulazione con la popolazione degli adulti maschi italiani, assunta come normalmente distribuita con media 175 cm e varianza 49 cm².\nEseguiamo 1000 ripetizioni di un esperimento, estraendo ogni volta un campione di 30 individui.\nPer ciascun campione, calcoliamo l’intervallo di fiducia al 95% usando la formula:\n\n\\[\n\\bar{X} \\pm t \\frac{s}{\\sqrt{n}},\n\\]\ndove \\(\\bar{X}\\) è la media campionaria, \\(s\\) è la deviazione standard campionaria e \\(t\\) è il valore critico della distribuzione t-Student per \\(n-1\\) gradi di libertà al livello di significatività \\(\\alpha/2 = 0.025\\). - Registriamo i limiti di ciascun intervallo e controlliamo quanti di essi includono effettivamente il vero valore medio della popolazione.\nAttraverso questa simulazione, possiamo visualizzare concretamente il concetto di livello di copertura e la sua importanza nella statistica frequentista.\nIn questa simulazione, genereremo 1000 campioni casuali di dimensione \\(n = 30\\) da una distribuzione normale con media \\(\\mu = 175\\) e deviazione standard \\(\\sigma = 7\\). Successivamente, calcoleremo gli intervalli di confidenza al 95% per ciascun campione e valuteremo il livello di copertura.\n\nset.seed(123)  # Per riproducibilità\n\n# Parametri della distribuzione\nmu &lt;- 175\nsigma &lt;- 7\nn &lt;- 30\nn_samples &lt;- 1000\n\n# Generazione dei campioni\nsamples &lt;- replicate(n_samples, rnorm(n, mean = mu, sd = sigma))\ndim(samples)  # Verifica dimensioni: 30 righe per 1000 colonne\n#&gt; [1]   30 1000\n\nIl primo campione di ampiezza \\(n = 30\\) che abbiamo ottenuto è il seguente:\n\nsamples[, 1]  # Primo campione\n#&gt;  [1] 171.0767 173.3888 185.9110 175.4936 175.9050 187.0055 178.2264 166.1446\n#&gt;  [9] 170.1920 171.8804 183.5686 177.5187 177.8054 175.7748 171.1091 187.5084\n#&gt; [17] 178.4850 161.2337 179.9095 171.6905 167.5252 173.4742 167.8180 169.8978\n#&gt; [25] 170.6247 163.1931 180.8645 176.0736 167.0330 183.7767\n\nStampiamo le medie dei primi dieci campioni:\n\nsample_means &lt;- colMeans(samples)  # Medie di tutti i campioni\nsample_means[1:10]  # Prime dieci medie\n#&gt;  [1] 174.6703 176.2484 175.1709 174.3428 173.7149 176.0760 175.1029 174.3725\n#&gt;  [9] 175.3554 177.3568\n\nTroviamo il valore critico della distribuzione \\(t\\) di Student con \\(n - 1\\) gradi di libertà e livello di confidenza del 95% (\\(\\alpha = 0.05\\)):\n\nalpha &lt;- 0.05\nt_critical &lt;- qt(1 - alpha / 2, df = n - 1)  # Valore critico\nt_critical\n#&gt; [1] 2.04523\n\nUtilizzando il valore critico \\(t\\), calcoliamo 1000 intervalli di confidenza per la media della popolazione:\n\n# Calcolo della deviazione standard campionaria\nsample_sds &lt;- apply(samples, 2, sd)\n\n# Ampiezza degli intervalli\ninterval_width &lt;- t_critical * sample_sds / sqrt(n)\n\n# Limiti degli intervalli di confidenza\nCI_low &lt;- sample_means - interval_width\nCI_high &lt;- sample_means + interval_width\n\nTroviamo il livello di copertura, ovvero la proporzione di intervalli di confidenza che contengono il vero valore della media della popolazione \\(\\mu\\):\n\ncoverage &lt;- mean(CI_low &lt; mu & mu &lt; CI_high)  # Proporzione di copertura\ncoverage\n#&gt; [1] 0.956\n\nIn conclusione, ripetendo la simulazione per 1000 campioni, abbiamo ottenuto un livello di copertura molto vicino al valore nominale di \\(1 - \\alpha = 0.95\\). Questo risultato dimostra che, con un campione di dimensione \\(n = 30\\), gli intervalli di confidenza al 95% calcolati utilizzando la distribuzione \\(t\\) di Student forniscono stime accurate della media della popolazione.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Intervallo di confidenza</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#il-concetto-di-livello-di-confidenza",
    "href": "chapters/frequentist_inference/02_conf_interv.html#il-concetto-di-livello-di-confidenza",
    "title": "62  Intervallo di confidenza",
    "section": "62.6 Il Concetto di Livello di Confidenza",
    "text": "62.6 Il Concetto di Livello di Confidenza\nGli intervalli di confidenza sono range di valori che, con una certa sicurezza statistica, si ritiene includano il parametro di interesse.\nSecondo l’approccio frequentista, l’intervallo di confidenza si deve considerare come una metodologia:\n\nSe ripetiamo l’esperimento (estrarre un campione e calcolare l’intervallo di confidenza) molte volte, il metodo produce un intervallo che coprirà il valore vero del parametro nel 95% dei casi, assumendo un livello di confidenza del 95%.\n\n\n62.6.1 Un Malinteso Comune nell’Interpretazione degli Intervalli di Confidenza\nÈ inesatto affermare che un determinato intervallo di confidenza contenga il valore vero di un parametro con una probabilità del 95%. Questo è un errore diffuso, persino tra i ricercatori, che spesso interpretano l’intervallo di confidenza come indicativo della probabilità che il parametro (ad esempio, la media della popolazione \\(\\mu\\)) si trovi effettivamente all’interno di un dato intervallo (es. \\([\\hat{a}, \\hat{b}]\\)).\nLa descrizione corretta è la seguente:\n\n“La metodologia impiegata per calcolare l’intervallo \\([\\hat{a}, \\hat{b}]\\) ha il 95% di probabilità di generare un intervallo che include il vero valore del parametro”.\nCiò significa che l’intervallo di confidenza non esprime una probabilità circa la posizione precisa del parametro, ma riflette la probabilità che la procedura adottata per determinarlo generi un intervallo che lo includa.\n\nIn conclusione, l’intervallo di confidenza ci fornisce una garanzia statistica riguardo alla affidabilità del metodo usato per la sua stima, piuttosto che sulla esatta ubicazione del parametro in questione.\n\n\n62.6.2 Fraintendimenti Comuni sugli Intervalli di Confidenza\nNel loro lavoro, Hoekstra et al. (2014) evidenziano come, nonostante l’ampio riconoscimento dei limiti dei test di ipotesi nulle, gli intervalli di confidenza siano spesso consigliati per l’inferenza statistica. Anche l’American Psychological Association (APA) suggerisce che gli intervalli di confidenza siano “in generale, la migliore strategia di reportistica”. Tuttavia, Hoekstra et al. (2014) sottolineano che queste raccomandazioni non considerano la difficoltà nel fornire una corretta interpretazione degli intervalli di confidenza.\nPer indagare l’interpretazione degli intervalli di confidenza, Hoekstra et al. (2014) hanno condotto uno studio con due domande principali:\n\nQuanto frequentemente intervalli di confidenza sono mal interpretati da studenti e ricercatori?\nL’esperienza nella ricerca riduce le interpretazioni errate degli intervalli di confidenza?\n\nPrima di presentare lo studio, {cite}hoekstra2014robust ricordano qual è l’interpretazione corretta degli intervalli di confidenza.\n\nA CI is a numerical interval constructed around the estimate of a parameter. Such an interval does not, however, directly indicate a property of the parameter; instead, it indicates a property of the procedure, as is typical for a frequentist technique. Specifically, we may find that a particular procedure, when used repeatedly across a series of hypothetical data sets (i.e., the sample space), yields intervals that contain the true parameter value in 95% of the cases. When such a procedure is applied to a particular data set, the resulting interval is said to be a 95% CI. The key point is that the CIs do not provide for a statement about the parameter as it relates to the particular sample at hand; instead, they provide for a statement about the performance of the procedure of drawing such intervals in repeated use. Hence, it is incorrect to interpret a CI as the probability that the true value is within the interval (e.g., Berger & Wolpert, 1988). As is the case with \\(p\\)-values, CIs do not allow one to make probability statements about parameters or hypotheses.\n\nNel loro studio, Hoekstra et al. (2014) hanno presentato un questionario a 596 partecipanti, tra cui studenti universitari e ricercatori, con le seguenti affermazioni riguardanti l’interpretazione degli intervalli di confidenza.\n\nProfessor Bumbledorf conducts an experiment, analyzes the data, and reports: “The 95% confidence interval for the mean ranges from 0.1 to 0.4.” Please mark each of the statements below as ‘true’ or ‘false’.\n\n\n\nThe probability that the true mean is greater than 0 is at least 95%.\nThe probability that the true mean equals 0 is smaller than 5%.\nThe “null hypothesis” that the true mean equals 0 is likely to be incorrect.\nThere is a 95% probability that the true mean lies between 0.1 and 0.4.\nWe can be 95% confident that the true mean lies between 0.1 and 0.4.\nIf we were to repeat the experiment over and over, then 95% of the time the true mean falls between 0.1 and 0.4.\n\n\nSorprendentemente, anche se tutte le sei affermazioni nel questionario sono errate, molti partecipanti hanno concordato con esse. I risultati mostrano che, in media, i partecipanti hanno concordato con circa 3.5 affermazioni errate su 6. Non è stata rilevata una differenza di rilievo nell’interpretazione degli intervalli di confidenza tra studenti e ricercatori, suggerendo che l’esperienza nella ricerca non migliora la comprensione di questo concetto.\nI risultati indicano che molte persone interpretano erroneamente gli intervalli di confidenza, e che anche l’esperienza nella ricerca non garantisce una migliore comprensione. Questo solleva dubbi sull’efficacia degli intervalli di confidenza frequentisti e suggerisce che gli “intervalli di credibilità” bayesiani possano rappresentare un’alternativa più vantaggiosa. Quest’ultimi tendono ad essere più intuitivi e di più facile interpretazione corretta.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Intervallo di confidenza</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#confronto-tra-intervalli-frequentisti-e-bayesiani",
    "href": "chapters/frequentist_inference/02_conf_interv.html#confronto-tra-intervalli-frequentisti-e-bayesiani",
    "title": "62  Intervallo di confidenza",
    "section": "62.7 Confronto tra Intervalli Frequentisti e Bayesiani",
    "text": "62.7 Confronto tra Intervalli Frequentisti e Bayesiani\nConcludiamo questo capitolo esaminando le differenze tra l’intervallo di confidenza frequentista e l’intervallo di credibilità bayesiano, utilizzando lo stesso set di dati per entrambi i calcoli.\n\n62.7.1 Intervallo di confidenza frequentista\nImmaginiamo di avere un gruppo di 20 osservazioni relative alla performance in un test cognitivo. Il nostro obiettivo è stimare la media della popolazione da cui queste osservazioni sono tratte. Supponiamo che i dati provengano da una distribuzione normale con media \\(\\mu = 50\\) e deviazione standard \\(\\sigma = 10\\).\n\nset.seed(123)  # Per risultati riproducibili\n\n# Parametri della popolazione\nsample_size &lt;- 20\nmu &lt;- 50\nsigma &lt;- 10\n\n# Simulazione del campione\nsample_data &lt;- rnorm(sample_size, mean = mu, sd = sigma)\nprint(sample_data)\n#&gt;  [1] 44.39524 47.69823 65.58708 50.70508 51.29288 67.15065 54.60916 37.34939\n#&gt;  [9] 43.13147 45.54338 62.24082 53.59814 54.00771 51.10683 44.44159 67.86913\n#&gt; [17] 54.97850 30.33383 57.01356 45.27209\n\nVisualizziamo la distribuzione dei dati:\n\nhist(\n  sample_data, \n  probability = TRUE, \n  main = \"Distribuzione dei dati campionari\", \n  xlab = \"Valori\", \n  ylab = \"Densità\"\n)\n\n\n\n\n\n\n\n\nLa media campionaria (\\(\\hat{\\mu}\\)) viene calcolata come:\n\\[\n\\hat{\\mu} = \\frac{1}{n} \\sum_{i=1}^n X_i\n\\]\nIn R:\n\nsample_mean &lt;- mean(sample_data)\nsample_mean\n#&gt; [1] 51.41624\n\nLa deviazione standard campionaria (\\(s\\)) si calcola come:\n\\[\ns = \\sqrt{\\frac{\\sum_{i=1}^n (X_i - \\bar{X})^2}{n-1}}\n\\]\nIn R:\n\nvariance &lt;- function(x) {\n  sum((x - mean(x))^2) / length(x)\n}\n\nsample_sd &lt;- sqrt(variance(sample_data))  # Deviazione standard campionaria\nsample_sd\n#&gt; [1] 9.480369\n\nL’errore standard della media (\\(SE\\)) è:\n\\[\nSE = \\frac{s}{\\sqrt{n}}\n\\]\nIn R:\n\nstandard_error &lt;- sample_sd / sqrt(sample_size)\nstandard_error\n#&gt; [1] 2.119875\n\nUn intervallo di confidenza è definito come:\n\\[\n\\bar{X} \\pm t_{\\text{critico}} \\cdot SE\n\\]\ndove \\(t_{\\text{critico}}\\) è il valore critico della distribuzione \\(t\\) di Student per un livello di confidenza del 95% (\\(\\alpha = 0.05\\)) e \\(n-1\\) gradi di libertà. In R:\n\nalpha &lt;- 0.05\ndf &lt;- sample_size - 1\nt_critical &lt;- qt(1 - alpha / 2, df)\nt_critical\n#&gt; [1] 2.093024\n\nCalcoliamo il margine di errore:\n\nmargin_of_error &lt;- t_critical * standard_error\nmargin_of_error\n#&gt; [1] 4.436949\n\nCalcoliamo i limiti inferiore e superiore dell’intervallo di confidenza:\n\nconfidence_interval &lt;- \n  c(sample_mean - margin_of_error, sample_mean + margin_of_error)\nconfidence_interval\n#&gt; [1] 46.97929 55.85319\n\nPossiamo interpretare questo risultato dicendo che la procedura utilizzata per calcolare l’intervallo include il valore vero della media della popolazione nel 95% dei casi.\nCreiamo un grafico per mostrare la distribuzione dei dati, la media campionaria e l’intervallo di confidenza:\n\nhist(\n  sample_data, \n  probability = TRUE, \n  main = \"Intervallo di Confidenza per la Media\", \n  xlab = \"Valori\", \n  ylab = \"Densità\"\n)\nabline(v = sample_mean, col = \"blue\", lwd = 2, lty = 2)  # Media campionaria\nabline(v = confidence_interval, col = \"darkgreen\", lwd = 2)  # Limiti dell'intervallo\nlegend(\n  \"topright\", \n  legend = c(\"Media campionaria\", \"Intervallo di Confidenza\"),\n  col = c(\"blue\", \"darkgreen\"), \n  lty = c(2, 1), \n  lwd = 2\n)\n\n\n\n\n\n\n\n\nQuesta simulazione mostra come calcolare e interpretare un intervallo di confidenza frequentista per la media della popolazione utilizzando un campione di dimensione \\(n = 20\\).\n\n\n62.7.2 Intervallo di Credibilità Bayesiano\nPer determinare l’intervallo di credibilità bayesiano, utilizziamo un modello Bayesiano che assume una distribuzione normale per i dati osservati. Le distribuzioni a priori sono scelte in modo da riflettere una conoscenza preliminare vaga e non informativa:\n\nDistribuzione a priori di \\(\\mu\\): Normale centrata su \\(\\mu_0 = 0\\) con deviazione standard ampia (\\(\\sigma_0 = 200\\)).\nDistribuzione a priori di \\(\\sigma\\): Normale troncata positiva (\\(\\text{HalfNormal}\\)) con deviazione standard di 100.\n\nQueste scelte sono progettate per minimizzare l’introduzione di bias, mantenendo l’analisi conservativa.\nPrepariamo i dati:\n\n# Simulazione dei dati\nset.seed(123)\nsample_data &lt;- rnorm(20, mean = 50, sd = 10)\n\n# Preparazione dei dati per Stan\nstan_data &lt;- list(\n  N = length(sample_data),\n  Y = sample_data\n)\n\nCompiliamo il modello:\n\n# Path to the Stan file\nstan_file &lt;- here::here(\"chapters\", \"frequentist_inference\", \"bayesian_model.stan\")\n\n# Create a CmdStanModel object\nmod &lt;- cmdstan_model(stan_file)\n\n\nmod$print()\n#&gt; data {\n#&gt;   int&lt;lower=1&gt; N;        // Numero di osservazioni\n#&gt;   vector[N] Y;           // Dati osservati\n#&gt; }\n#&gt; parameters {\n#&gt;   real mu;               // Media della popolazione\n#&gt;   real&lt;lower=0&gt; sigma;   // Deviazione standard della popolazione\n#&gt; }\n#&gt; model {\n#&gt;   mu ~ normal(0, 200);               // Prior debole per mu\n#&gt;   sigma ~ normal(0, 100) T[0, ];     // Prior HalfNormal per sigma\n#&gt;   Y ~ normal(mu, sigma);             // Likelihood\n#&gt; }\n\nEseguiamo il campionamento:\n\nfit &lt;- mod$sample(\n  data = stan_data,\n  seed = 123,\n  chains = 4,\n  parallel_chains = 4,\n  iter_sampling = 2000,\n  iter_warmup = 1000,\n  show_messages = FALSE\n)\n\nEstraiamo i risultati:\n\nposterior &lt;- fit$draws()\n\nCalcoliamo l’intervallo di credibilità al 95%:\n\nposterior_summary &lt;- \n  fit$summary(\n    c(\"mu\", \"sigma\"), ~quantile(.x, probs = c(0.025, 0.5, 0.975))\n  )\n\nposterior_summary\n#&gt; # A tibble: 2 × 4\n#&gt;   variable `2.5%` `50%` `97.5%`\n#&gt;   &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 mu        46.6   51.4    56.2\n#&gt; 2 sigma      7.58  10.2    14.8\n\nL’intervallo di credibilità calcolato fornisce una gamma di valori entro cui si trova il parametro \\(\\mu\\) con un grado di credenza del 95%, date le informazioni a priori e i dati osservati.\n\n\n62.7.3 Confronto tra i Due Approcci\nIntervallo di Credibilità Bayesiano:\n\nRappresenta il grado di credenza (posteriori) che il parametro \\(\\mu\\) si trovi all’interno dell’intervallo calcolato.\nDipende sia dai dati osservati sia dalle distribuzioni a priori utilizzate nel modello, che possono influenzare il risultato in base alla loro specificità o vaghezza.\n\nIntervallo di Confidenza Frequentista:\n\nNon esprime la probabilità che il parametro \\(\\mu\\) appartenga a un determinato intervallo.\nSi riferisce invece alla procedura di costruzione dell’intervallo: se il campionamento fosse ripetuto infinite volte, il 95% degli intervalli costruiti conterrebbe il vero valore di \\(\\mu\\).\n\nIn sintesi:\n\nL’intervallo di credibilità bayesiano fornisce una stima probabilistica diretta e interpretabile della posizione di \\(\\mu\\), basata su dati osservati e informazioni a priori.\nL’intervallo di confidenza frequentista, invece, valuta la affidabilità della procedura nel lungo termine, senza fare affermazioni dirette sulla probabilità che il parametro rientri nell’intervallo specifico.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Intervallo di confidenza</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/02_conf_interv.html#riflessioni-conclusive",
    "title": "62  Intervallo di confidenza",
    "section": "62.8 Riflessioni Conclusive",
    "text": "62.8 Riflessioni Conclusive\nCome sottolineato da Hoekstra et al. (2014), è comune riscontrare fraintendimenti riguardo agli intervalli di fiducia. Il “livello di confidenza del 95%” è da interpretarsi come la probabilità a lungo termine che, in una serie di intervalli di fiducia calcolati, il 95% di essi includa il vero valore del parametro sconosciuto. Tuttavia, per un singolo intervallo di fiducia, non è possibile dichiarare con sicurezza che questo contenga effettivamente il parametro di interesse. In altre parole, la certezza sulla presenza del parametro sconosciuto all’interno di un dato intervallo di fiducia non è garantita per ogni singolo caso analizzato.\nÈ inoltre inesatto presumere che esista un legame diretto tra la varianza e la media di un campione, ipotizzando che un intervallo di fiducia più ristretto implichi maggiore precisione. Nella prospettiva frequentista, la “precisione” è strettamente legata al livello di copertura a lungo termine assicurato dal metodo usato per creare gli intervalli di fiducia. Questo concetto non si applica al singolo intervallo di fiducia osservato. Dunque, un intervallo di fiducia che si presenta estremamente ristretto potrebbe in realtà essere significativamente lontano dal valore vero del parametro non noto.\nÈ importante sottolineare che l’approccio frequentista offre un metodo per calcolare gli intervalli di confidenza per una vasta gamma di statistiche. Questo include, ad esempio, la stima dell’intervallo di confidenza per la differenza tra due medie, per una proporzione o per la differenza tra due proporzioni. Ecco le formule per calcolare gli intervalli di confidenza per i casi menzionati:\nIntervallo di confidenza per la differenza tra due medie.\nSe abbiamo due campioni indipendenti di dimensione \\(n_1\\) e \\(n_2\\), con medie \\(\\bar{x}_1\\) e \\(\\bar{x}_2\\) e deviazioni standard \\(s_1\\) e \\(s_2\\), l’intervallo di confidenza per la differenza tra le medie è calcolato come:\n\\[\n(\\bar{x}_1 - \\bar{x}_2) \\pm t_{\\alpha/2} \\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}},\n\\]\ndove \\(t_{\\alpha/2}\\) è il valore critico della distribuzione t di Student con \\(\\alpha/2\\) di probabilità di coda e gradi di libertà \\(df = n_1 + n_2 - 2\\).\nIntervallo di confidenza per una proporzione.\nPer stimare l’intervallo di confidenza per una proporzione \\(p\\) in un campione binomiale di dimensione \\(n\\), la formula è:\n\\[\n\\hat{p} \\pm z_{\\alpha/2} \\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}},\n\\]\ndove \\(\\hat{p}\\) è la proporzione campionaria e \\(z_{\\alpha/2}\\) è il valore critico della distribuzione normale standard con \\(\\alpha/2\\) di probabilità di coda.\nIntervallo di confidenza per la differenza tra due proporzioni.\nPer stimare l’intervallo di confidenza per la differenza tra due proporzioni \\(p_1\\) e \\(p_2\\) in due campioni binomiali di dimensioni \\(n_1\\) e \\(n_2\\), la formula è:\n\\[\n(\\hat{p}_1 - \\hat{p}_2) \\pm z_{\\alpha/2} \\sqrt{\\frac{\\hat{p}_1(1 - \\hat{p}_1)}{n_1} + \\frac{\\hat{p}_2(1 - \\hat{p}_2)}{n_2}},\n\\]\ndove \\(\\hat{p}_1\\) e \\(\\hat{p}_2\\) sono le proporzioni campionarie e \\(z_{\\alpha/2}\\) è il valore critico della distribuzione normale standard con \\(\\alpha/2\\) di probabilità di coda.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Intervallo di confidenza</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/02_conf_interv.html#informazioni-sullambiente-di-sviluppo",
    "title": "62  Intervallo di confidenza",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] cmdstanr_0.8.1.9000 MASS_7.3-61         viridis_0.6.5      \n#&gt;  [4] viridisLite_0.4.2   ggpubr_0.6.0        ggExtra_0.10.1     \n#&gt;  [7] gridExtra_2.3       patchwork_1.3.0     bayesplot_1.11.1   \n#&gt; [10] psych_2.4.6.26      scales_1.3.0        markdown_1.13      \n#&gt; [13] knitr_1.49          lubridate_1.9.3     forcats_1.0.0      \n#&gt; [16] stringr_1.5.1       dplyr_1.1.4         purrr_1.0.2        \n#&gt; [19] readr_2.1.5         tidyr_1.3.1         tibble_3.2.1       \n#&gt; [22] ggplot2_3.5.1       tidyverse_2.0.0     rio_1.2.3          \n#&gt; [25] here_1.0.1         \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tensorA_0.36.2.1     gtable_0.3.6         xfun_0.49           \n#&gt;  [4] htmlwidgets_1.6.4    processx_3.8.4       rstatix_0.7.2       \n#&gt;  [7] lattice_0.22-6       tzdb_0.4.0           ps_1.8.1            \n#&gt; [10] vctrs_0.6.5          tools_4.4.2          generics_0.1.3      \n#&gt; [13] parallel_4.4.2       fansi_1.0.6          pacman_0.5.1        \n#&gt; [16] pkgconfig_2.0.3      data.table_1.16.2    checkmate_2.3.2     \n#&gt; [19] distributional_0.5.0 lifecycle_1.0.4      compiler_4.4.2      \n#&gt; [22] farver_2.1.2         munsell_0.5.1        mnormt_2.1.1        \n#&gt; [25] carData_3.0-5        httpuv_1.6.15        htmltools_0.5.8.1   \n#&gt; [28] yaml_2.3.10          Formula_1.2-5        car_3.1-3           \n#&gt; [31] pillar_1.9.0         later_1.4.0          abind_1.4-8         \n#&gt; [34] nlme_3.1-166         mime_0.12            posterior_1.6.0     \n#&gt; [37] tidyselect_1.2.1     digest_0.6.37        stringi_1.8.4       \n#&gt; [40] rprojroot_2.0.4      fastmap_1.2.0        grid_4.4.2          \n#&gt; [43] colorspace_2.1-1     cli_3.6.3            magrittr_2.0.3      \n#&gt; [46] utf8_1.2.4           broom_1.0.7          withr_3.0.2         \n#&gt; [49] backports_1.5.0      promises_1.3.1       timechange_0.3.0    \n#&gt; [52] rmarkdown_2.29       ggsignif_0.6.4       hms_1.1.3           \n#&gt; [55] shiny_1.9.1          evaluate_1.0.1       miniUI_0.1.1.1      \n#&gt; [58] rlang_1.1.4          Rcpp_1.0.13-1        xtable_1.8-4        \n#&gt; [61] glue_1.8.0           jsonlite_1.8.9       R6_2.5.1",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Intervallo di confidenza</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#bibliografia",
    "href": "chapters/frequentist_inference/02_conf_interv.html#bibliografia",
    "title": "62  Intervallo di confidenza",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nHoekstra, R., Morey, R. D., Rouder, J. N., & Wagenmakers, E.-J. (2014). Robust misinterpretation of confidence intervals. Psychonomic Bulletin & Review, 21(5), 1157–1164.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Intervallo di confidenza</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html",
    "href": "chapters/frequentist_inference/03_sample_size.html",
    "title": "63  La grandezza del campione",
    "section": "",
    "text": "63.1 Introduzione\nPrerequisiti\nConcetti e competenze chiave\nPreparazione del Notebook\nLa scelta della dimensione campionaria è cruciale per garantire che i risultati di uno studio siano affidabili, bilanciando precisione e costi. In questo capitolo, analizzeremo come calcolare la dimensione campionaria necessaria per stimare la media di una popolazione con un margine di errore prefissato e un determinato livello di confidenza. Utilizzeremo un esempio psicologico per illustrare il processo e fornire implementazioni in R.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#la-logica-dietro-la-scelta-della-dimensione-campionaria",
    "href": "chapters/frequentist_inference/03_sample_size.html#la-logica-dietro-la-scelta-della-dimensione-campionaria",
    "title": "63  La grandezza del campione",
    "section": "63.2 La Logica Dietro la Scelta della Dimensione Campionaria",
    "text": "63.2 La Logica Dietro la Scelta della Dimensione Campionaria\nIn psicologia, stimare la media di una variabile (ad esempio, il punteggio medio di una scala psicometrica) è un’operazione comune. Campioni più grandi garantiscono:\n\nStime più precise: La varianza dell’estimatore diminuisce con l’aumentare della dimensione campionaria.\nMaggiore fiducia nei risultati: Il margine di errore si restringe.\n\nTuttavia, i campioni più grandi comportano costi più elevati in termini di tempo e risorse. Pertanto, il problema si riduce spesso a determinare il campione più piccolo che garantisce la precisione richiesta.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#calcolo-della-dimensione-campionaria-derivazione-della-formula",
    "href": "chapters/frequentist_inference/03_sample_size.html#calcolo-della-dimensione-campionaria-derivazione-della-formula",
    "title": "63  La grandezza del campione",
    "section": "63.3 Calcolo della Dimensione Campionaria: Derivazione della Formula",
    "text": "63.3 Calcolo della Dimensione Campionaria: Derivazione della Formula\nPer campioni sufficientemente grandi, la media stimata \\(\\bar{X}\\) segue una distribuzione normale:\n\\[\n\\bar{X} \\sim \\mathcal{N}\\left(\\mu, \\frac{\\sigma^2}{n}\\right),\n\\]\ndove \\(n\\) è la dimensione del campione, \\(\\mu\\) è la vera media della popolazione e \\(\\sigma^2\\) è la varianza della popolazione.\nIl nostro obiettivo è trovare la dimensione campionaria \\(n\\) tale che:\n\\[\nP\\left(|\\bar{X} - \\mu| &lt; E\\right) \\geq 0.95,\n\\]\ndove:\n\n\\(\\bar{X}\\) è la media campionaria,\n\\(\\mu\\) è la media della popolazione,\n\\(E\\) è il margine di errore massimo accettabile.\n\nSappiamo che, per il teorema centrale del limite o per le proprietà della distribuzione normale:\n\\[\n\\bar{X} \\sim \\mathcal{N}\\left(\\mu, \\frac{\\sigma^2}{n}\\right),\n\\]\ndove \\(\\sigma^2\\) è la varianza della popolazione e \\(n\\) è la dimensione campionaria.\nPer trasformare in termini della variabile standardizzata \\(Z\\), utilizziamo:\n\\[\nZ = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}},\n\\]\nche implica:\n\\[\n\\bar{X} \\sim \\mathcal{N}\\left(0, 1\\right).\n\\]\nPertanto, la probabilità richiesta si riscrive:\n\\[\nP\\left(|\\bar{X} - \\mu| &lt; E\\right) = P\\left(|Z| &lt; z_{0.025}\\right),\n\\]\ndove \\(z_{0.025} = 1.96\\) è il quantile superiore della distribuzione normale standard, corrispondente a un livello di confidenza del \\(95\\%\\).\nDalla definizione della variabile standardizzata:\n\\[\nZ = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}},\n\\]\npossiamo ricavare la relazione per il margine di errore:\n\\[\n|\\bar{X} - \\mu| &lt; E \\implies Z = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}} \\implies |\\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}}| &lt; \\frac{E}{\\sigma / \\sqrt{n}}.\n\\]\nSostituendo la condizione \\(|Z| &lt; z_{0.025}\\), otteniamo:\n\\[\n\\frac{E}{\\sigma / \\sqrt{n}} = z_{0.025}.\n\\]\nMoltiplichiamo entrambi i membri per \\(\\sigma / \\sqrt{n}\\):\n\\[\nE = z_{0.025} \\cdot \\frac{\\sigma}{\\sqrt{n}}.\n\\]\nIsoliamo \\(\\sqrt{n}\\) dividendo entrambi i membri per \\(z_{0.025} \\cdot \\sigma\\):\n\\[\n\\sqrt{n} = \\frac{z_{0.025} \\cdot \\sigma}{E}.\n\\]\nPer ottenere \\(n\\), eleviamo entrambi i membri al quadrato:\n\\[\nn = \\left(\\frac{z_{0.025} \\cdot \\sigma}{E}\\right)^2.\n\\]\nIn conclusione, la dimensione campionaria minima \\(n\\) necessaria per soddisfare il margine di errore \\(E\\) e il livello di confidenza richiesto è:\n\\[\nn = \\left(\\frac{z_{0.025} \\cdot \\sigma}{E}\\right)^2.\n\\]",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#stima-della-media-del-punteggio-di-autostima",
    "href": "chapters/frequentist_inference/03_sample_size.html#stima-della-media-del-punteggio-di-autostima",
    "title": "63  La grandezza del campione",
    "section": "63.4 Stima della Media del Punteggio di Autostima",
    "text": "63.4 Stima della Media del Punteggio di Autostima\nPer fare un esempio, immaginiamo di voler stimare la media del punteggio di autostima in una popolazione di giovani adulti. Utilizziamo la Rosenberg Self-Esteem Scale (RSES), che assegna un punteggio compreso tra 0 e 30.\nDettagli del problema:\n\nDeviazione standard del punteggio: \\(\\sigma = 6\\) (stimata da studi precedenti).\nMargine di errore massimo accettabile: \\(E = 2\\).\nLivello di confidenza: \\(95\\%\\).\n\nImplementiamo in R la formula derivata in precedenza.\n\n# Parametri del problema\nsigma &lt;- 6     # Deviazione standard del punteggio RSES\nE &lt;- 2         # Margine di errore desiderato\nz_alpha &lt;- qnorm(0.975)  # Quantile superiore della distribuzione normale (95% confidenza)\n\n# Calcolo della dimensione campionaria\nn &lt;- (z_alpha * sigma / E)^2\nn &lt;- ceiling(n)  # Arrotondamento all'intero successivo\nn\n#&gt; [1] 35\n\nIn conclusione, la dimensione campionaria minima necessaria per stimare la media del punteggio di autostima con un margine di errore massimo di 2 punti e un livello di confidenza del 95% è \\(n = 35\\).\n\n63.4.1 Approfondimenti\n\nPrecisione e Livello di Confidenza\nAumentando \\(n\\), la varianza di \\(\\bar{X}\\) diminuisce:\n\\[\n\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n}.\n\\]\nQuesto restringe l’intervallo di confidenza e migliora la precisione.\nCosto e Praticità\nUn campione più grande aumenta i costi. È importante trovare il giusto compromesso tra precisione e fattibilità.\nAdattamento ad Altri Livelli di Confidenza\nPer altri livelli di confidenza, basta modificare il quantile \\(z_{\\alpha/2}\\). Ad esempio, per un livello di confidenza del 99%, \\(z_{0.005} \\approx 2.576\\).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/03_sample_size.html#riflessioni-conclusive",
    "title": "63  La grandezza del campione",
    "section": "63.5 Riflessioni Conclusive",
    "text": "63.5 Riflessioni Conclusive\nDeterminare la dimensione del campione è essenziale per ogni studio psicologico. Un approccio matematico rigoroso ci permette di bilanciare la precisione delle stime con i vincoli di risorse.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_sample_size.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/03_sample_size.html#informazioni-sullambiente-di-sviluppo",
    "title": "63  La grandezza del campione",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] MASS_7.3-61       viridis_0.6.5     viridisLite_0.4.2 ggpubr_0.6.0     \n#&gt;  [5] ggExtra_0.10.1    gridExtra_2.3     patchwork_1.3.0   bayesplot_1.11.1 \n#&gt;  [9] psych_2.4.6.26    scales_1.3.0      markdown_1.13     knitr_1.49       \n#&gt; [13] lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1     dplyr_1.1.4      \n#&gt; [17] purrr_1.0.2       readr_2.1.5       tidyr_1.3.1       tibble_3.2.1     \n#&gt; [21] ggplot2_3.5.1     tidyverse_2.0.0   rio_1.2.3         here_1.0.1       \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] gtable_0.3.6      xfun_0.49         htmlwidgets_1.6.4 rstatix_0.7.2    \n#&gt;  [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.4.2      \n#&gt;  [9] generics_0.1.3    parallel_4.4.2    fansi_1.0.6       pacman_0.5.1     \n#&gt; [13] pkgconfig_2.0.3   lifecycle_1.0.4   compiler_4.4.2    farver_2.1.2     \n#&gt; [17] munsell_0.5.1     mnormt_2.1.1      carData_3.0-5     httpuv_1.6.15    \n#&gt; [21] htmltools_0.5.8.1 yaml_2.3.10       Formula_1.2-5     car_3.1-3        \n#&gt; [25] pillar_1.9.0      later_1.4.0       abind_1.4-8       nlme_3.1-166     \n#&gt; [29] mime_0.12         tidyselect_1.2.1  digest_0.6.37     stringi_1.8.4    \n#&gt; [33] rprojroot_2.0.4   fastmap_1.2.0     grid_4.4.2        colorspace_2.1-1 \n#&gt; [37] cli_3.6.3         magrittr_2.0.3    utf8_1.2.4        broom_1.0.7      \n#&gt; [41] withr_3.0.2       backports_1.5.0   promises_1.3.1    timechange_0.3.0 \n#&gt; [45] rmarkdown_2.29    ggsignif_0.6.4    hms_1.1.3         shiny_1.9.1      \n#&gt; [49] evaluate_1.0.1    miniUI_0.1.1.1    rlang_1.1.4       Rcpp_1.0.13-1    \n#&gt; [53] xtable_1.8-4      glue_1.8.0        jsonlite_1.8.9    R6_2.5.1",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>La grandezza del campione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/introduction_replication_crisis.html",
    "href": "chapters/replication_crisis/introduction_replication_crisis.html",
    "title": "Introduzione",
    "section": "",
    "text": "Bibliografia\nIn psicologia, nelle scienze sociali e in altre discipline è in corso una Riforma Metodologica, scaturita da una profonda crisi che ha colpito la scienza contemporanea: la crisi di replicazione dei risultati delle ricerche. Un esempio emblematico è rappresentato dal sito Retraction Watch, che monitora le ritrattazioni di studi scientifici. Questa crisi mina la credibilità della ricerca scientifica e ha spinto a una revisione radicale delle metodologie alla base delle scienze psicologiche e di altre discipline affini (Korbmacher et al., 2023). Le cause della crisi di replicazione sono molteplici: frodi, pratiche di ricerca scorrette e incentivi distorti offerti dal sistema accademico. Una delle cause più rilevanti per un corso sull’analisi dei dati psicologici è l’uso delle tecniche inferenziali di stampo frequentista, che ha contribuito alla proliferazione di pubblicazioni contenenti falsi positivi.\nUn articolo di Altmejd et al. (2019) identifica alcuni fattori semplici ma altamente predittivi della replicabilità degli studi: il campione era di dimensioni adeguate? I ricercatori hanno ottenuto un risultato appena sotto la soglia di significatività di p = 0.05? (Spesso un articolo può rivendicare un risultato “significativo” se questa soglia viene raggiunta, e molti utilizzano vari trucchi statistici per superare tale limite.) Lo studio ha rilevato un effetto sull’intera popolazione studiata o ha individuato un “effetto di interazione” (ad esempio, un effetto presente solo in un segmento più piccolo della popolazione), che è molto meno probabile che si riproduca?\nÈ emerso inoltre che prevedere la replicazione di uno studio è sorprendentemente semplice. Non è necessario un approfondimento della metodologia statistica né un esame rigoroso dei dati, né tantomeno una scrupolosa analisi delle teorie più esoteriche per individuare errori sottili: questi articoli presentano problemi evidenti, a livello superficiale. Uno studio pubblicato su Nature ha coinvolto scienziati in una scommessa su quali studi di scienze sociali sarebbero stati replicati. Camerer et al. (2018) ha scoperto che le previsioni degli scienziati in questo mercato delle scommesse erano estremamente accurate nel determinare quali articoli avrebbero avuto successo nella replicazione.\nUlteriori ricerche hanno dimostrato che non è nemmeno necessario consultare esperti del settore per indovinare quali studi resisteranno a un esame rigoroso. Uno studio di Hoogeveen et al. (2020) ha coinvolto partecipanti senza un background professionale nelle scienze sociali, chiedendo loro di leggere articoli di psicologia e prevedere se questi si sarebbero replicati. “I non-esperti senza una formazione professionale nelle scienze sociali sono in grado di prevedere la replicabilità degli studi con una precisione superiore al caso,” conclude lo studio, “basandosi esclusivamente su semplici descrizioni verbali degli studi.”\nSebbene i non esperti non siano stati altrettanto precisi nelle loro previsioni rispetto agli scienziati nello studio pubblicato su Nature, il fatto che siano comunque riusciti a individuare molte replicazioni fallite suggerisce che molti di questi studi presentano difetti evidenti, riconoscibili anche da chi non è un addetto ai lavori.\nLa pubblicazione di un articolo peer-reviewed non rappresenta l’ultimo passo del processo scientifico. Dopo la pubblicazione, altri studi potrebbero citare l’articolo originale, diffondendo eventuali errori o fraintendimenti. Uno studio di Yang et al. (2020) mostra che non esiste alcuna correlazione tra la replicabilità di uno studio e la sua frequenza di citazione. “Gli studi falliti si diffondono nella letteratura scientifica con la stessa rapidità degli studi replicabili,” affermano Yang et al. (2020). Questo solleva una domanda: se gli scienziati sono abbastanza bravi nel prevedere se uno studio si replicherà, perché sono altrettanto inclini a citare studi non replicabili quanto quelli validi?\nQueste considerazioni suggeriscono che la crisi di replicazione non richiede solo una revisione metodologica, ma è il sintomo di un sistema scientifico che necessita di un ripensamento più ampio. Le riviste scientifiche non sono sufficientemente responsabili per la pubblicazione di articoli discutibili, e il sistema accademico promuove incentivi distorti. In alcuni casi, la cultura accademica sembra addirittura incentivare la produzione di ricerche di bassa qualità. La pressione a pubblicare un elevato numero di articoli favorisce chi riesce a farlo rapidamente, spesso ricorrendo a “scorciatoie”. Di conseguenza, si è creato un sistema in cui gli incentivi continuano a promuovere la cattiva ricerca, nonostante si comprenda sempre meglio cosa costituisca una ricerca di qualità.\nIn questa sezione della dispensa, ci concentreremo su uno dei problemi che stanno alla base della crisi della riproducibilità dei risultati della ricerca, ovvero i limiti dell’inferenza frequentista (Baker, 2016). Analizzeremo gli errori di tipo S e di tipo M, concetti introdotti da Gelman & Carlin (2014), che hanno contribuito a migliorare la comprensione dei limiti della statistica frequentista. Inoltre, discuteremo alcuni possibili metodi per affrontare la crisi e le implicazioni che derivano dall’integrità della ricerca.",
    "crumbs": [
      "Crisi",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/introduction_replication_crisis.html#bibliografia",
    "href": "chapters/replication_crisis/introduction_replication_crisis.html#bibliografia",
    "title": "Introduzione",
    "section": "",
    "text": "Altmejd, A., Dreber, A., Forsell, E., Huber, J., Imai, T., Johannesson, M., Kirchler, M., Nave, G., & Camerer, C. (2019). Predicting the replicability of social science lab experiments. PloS one, 14(12), e0225826.\n\n\nBaker, M. (2016). Reproducibility Crisis. Nature, 533(7604), 452–454.\n\n\nCamerer, C. F., Dreber, A., Holzmeister, F., Ho, T.-H., Huber, J., Johannesson, M., Kirchler, M., Nave, G., Nosek, B. A., Pfeiffer, T., et al. (2018). Evaluating the replicability of social science experiments in Nature and Science between 2010 and 2015. Nature human behaviour, 2(9), 637–644.\n\n\nGelman, A., & Carlin, J. (2014). Beyond Power Calculations: Assessing Type S (Sign) and Type M (Magnitude) Errors. Perspectives on Psychological Science, 9(6), 641–651.\n\n\nHoogeveen, S., Sarafoglou, A., & Wagenmakers, E.-J. (2020). Laypeople can predict which social-science studies will be replicated successfully. Advances in Methods and Practices in Psychological Science, 3(3), 267–285.\n\n\nKorbmacher, M., Azevedo, F., Pennington, C. R., Hartmann, H., Pownall, M., Schmidt, K., Elsherif, M., Breznau, N., Robertson, O., Kalandadze, T., et al. (2023). The replication crisis has led to positive structural, procedural, and community changes. Communications Psychology, 1(1), 3.\n\n\nYang, Y., Youyou, W., & Uzzi, B. (2020). Estimating the deep replicability of scientific findings using human and artificial intelligence. Proceedings of the National Academy of Sciences, 117(20), 10762–10768.",
    "crumbs": [
      "Crisi",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html",
    "href": "chapters/replication_crisis/01_crisis.html",
    "title": "64  La crisi della replicazione",
    "section": "",
    "text": "Introduzione\nQuesto capitolo introduce la crisi di replicazione dei risultati della ricerca in psicologia, esplorando le cause principali di questo fenomeno e mettendo in evidenza il ruolo che l’approccio statistico frequentista ha avuto nel contribuire a questa crisi.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#feeling-the-future",
    "href": "chapters/replication_crisis/01_crisis.html#feeling-the-future",
    "title": "64  La crisi della replicazione",
    "section": "64.1 Feeling the Future",
    "text": "64.1 Feeling the Future\nIl 2011 ha rappresentato un punto di svolta per la comunità scientifica, segnando l’inizio della cosiddetta “crisi della replicazione”. Questo fenomeno, pur non influenzando direttamente la vita quotidiana della maggior parte delle persone, inclusi molti psicologi, ha avuto profonde ripercussioni sul mondo della ricerca, specialmente in psicologia, il campo più colpito. Per coloro con una conoscenza anche solo basilare della statistica, e che erano più interessati alla ricerca della verità che all’accumulo di citazioni o all’avanzamento di carriera, il 2011 è stato percepito come un vero e proprio “Anno Zero”. Questo momento cruciale ha messo in luce problemi fondamentali nei metodi di ricerca e nell’interpretazione dei risultati, avviando un processo di ripensamento delle pratiche scientifiche che è ancora in corso.\n\n64.1.1 La Scoperta di Frodi e Risultati Controversi\n\n64.1.1.1 Il Caso Diederik Stapel\nUno dei primi segnali della crisi fu la scoperta della frode scientifica commessa da Diederik Stapel, una stella nascente della psicologia sociale e professore presso l’Università di Tilburg nei Paesi Bassi, aveva attirato l’attenzione con una serie di articoli sensazionali: uno suggeriva che mangiare carne rendeva le persone più antisociali; un altro sosteneva che le persone sono più inclini al razzismo se l’ambiente circostante è pieno di rifiuti. Tuttavia, si scoprì che per quegli studi, e molti altri, non aveva mai condotto gli esperimenti né raccolto i dati. Li aveva semplicemente inventati. A volte le frodi accadono. Stapel fu scoperto (alla fine), licenziato e decine dei suoi articoli furono ritirati.\n\n\n64.1.1.2 Lo Studio “Feeling the Future” di Daryl Bem\nNello stesso anno, Daryl Bem della Cornell University pubblicò uno studio intitolato “Feeling the Future” (Bem, 2011), che avrebbe scosso ulteriormente le fondamenta della psicologia sociale. Lo studio di Bem si inseriva nella tradizione degli esperimenti di “priming”, una tecnica ampiamente utilizzata in psicologia sociale dagli anni ’70. Gli esperimenti di priming tipicamente coinvolgevano studenti universitari, remunerati con modeste somme o crediti accademici. I partecipanti venivano esposti a determinati concetti per poi osservare come questi influenzassero il loro comportamento successivo. Un celebre esempio è lo studio di John Bargh del 1996, che dimostrò come l’esposizione a parole associate all’età avanzata inducesse i soggetti a camminare più lentamente (Bargh et al., 1996). Un altro studio del 2006 rivelò che il priming con concetti legati al denaro rendeva le persone meno propense ad aiutare gli altri. Questi studi sembravano dimostrare una straordinaria malleabilità della mente umana, suggerendo che il nostro comportamento potesse essere inconsciamente manipolato da sottili segnali ambientali. Tuttavia, lo studio di Bem introdusse un elemento nuovo in questo paradigma sperimentale.\nTra i vari esperimenti condotti da Bem, uno in particolare si distingueva. I soggetti venivano esposti a una parola con connotazione positiva o negativa e successivamente dovevano valutare rapidamente la piacevolezza di alcune immagini. Fin qui, nulla di insolito. La svolta radicale consisteva nel fatto che in metà delle prove, il priming avveniva dopo che i soggetti avevano già visto e valutato l’immagine (Bem, 2011).\nSorprendentemente, i risultati mostravano che il priming funzionava anche in queste condizioni: i partecipanti erano più veloci a giudicare piacevoli le immagini quando successivamente venivano esposti a una parola positiva. Questo effetto risultava statisticamente significativo, con un p-value di 0.01, sufficiente secondo gli standard correnti per rifiutare l’ipotesi nulla.\nBem interpretò questi risultati come prova della chiaroveggenza, una conclusione che suscitò notevoli controversie e ridicolizzò la psicologia. Gli altri otto esperimenti dello studio, tutti basati su classici paradigmi della psicologia sociale con l’ordine temporale invertito, mostrarono risultati altrettanto significativi.\nQuesti risultati ponevano la comunità scientifica di fronte a un dilemma: accettare l’esistenza di fenomeni paranormali o mettere in discussione le pratiche statistiche e metodologiche consolidate nella disciplina. Bem stesso continua a sostenere la validità dei suoi risultati come prova dell’esistenza di capacità precognitive.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#pratiche-di-ricerca-disoneste-e-loro-conseguenze",
    "href": "chapters/replication_crisis/01_crisis.html#pratiche-di-ricerca-disoneste-e-loro-conseguenze",
    "title": "64  La crisi della replicazione",
    "section": "64.2 Pratiche di Ricerca Disoneste e Loro Conseguenze",
    "text": "64.2 Pratiche di Ricerca Disoneste e Loro Conseguenze\nLo studio di Bem, che portava a conclusioni insensate, si rivelò un catalizzatore per un esame critico delle pratiche di ricerca in psicologia, innescando un dibattito che avrebbe avuto profonde ripercussioni sull’intera disciplina (Ritchie et al., 2012).\nGià nel 2005, John Ioannidis dell’Università di Stanford aveva previsto la crisi imminente nel suo articolo “Why Most Published Research Findings Are False” (Ioannidis, 2005). Il nucleo della critica di Ioannidis riguardava l’approccio interpretativo dei dati sperimentali. Secondo la sua analisi, il problema fondamentale risiedeva nel fatto che molti scienziati non valutavano correttamente la probabilità che la loro ipotesi fosse vera alla luce dei dati raccolti. Al contrario, seguendo l’approccio tradizionale ispirato ai lavori di Bernoulli e Fisher, si concentravano sulla probabilità di ottenere i dati osservati nell’ipotesi che la loro teoria fosse falsa.\n\n64.2.1 P-hacking e HARKing\nLa psicologia, come molte altre discipline scientifiche, si trova spesso a confrontarsi con le “questionable research practices” (pratiche di ricerca discutibili), ovvero quell’insieme di comportamenti o azioni adottate dai ricercatori durante il processo di conduzione e comunicazione della ricerca scientifica che possono compromettere l’integrità e l’affidabilità dei risultati ottenuti. Queste pratiche includono il “P-hacking”, in cui i ricercatori manipolano i dati o le analisi statistiche per ottenere risultati significativi; il “HARKing” (Hypothesizing After Results are Known), in cui le ipotesi vengono formulate retrospettivamente per adattarsi ai risultati ottenuti; e la “presentazione selettiva dei risultati”, dove vengono presentati solo i risultati che supportano le ipotesi, tralasciando quelli non significativi o contraddittori.\nLa pressione per ottenere risultati “statisticamente significativi”, insieme all’uso di campioni di piccole dimensioni, porta alla proliferazione di falsi positivi come conseguenza dell’adozione di pratiche di ricerca discutibili. Simmons, Nelson e Simonsohn hanno dimostrato come, attraverso l’impiego di tali pratiche, sia semplice ottenere risultati statisticamente significativi (Nelson et al., 2018).\nL’uso di queste pratiche è molto diffuso nella ricerca e l’approccio statistico frequentista è particolarmente vulnerabile a tali manipolazioni.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#la-cultura-della-frode-nel-sistema-accademico",
    "href": "chapters/replication_crisis/01_crisis.html#la-cultura-della-frode-nel-sistema-accademico",
    "title": "64  La crisi della replicazione",
    "section": "64.3 La Cultura della Frode nel Sistema Accademico",
    "text": "64.3 La Cultura della Frode nel Sistema Accademico\nIl sistema accademico stesso, con i suoi incentivi alla pubblicazione e al finanziamento, incoraggia indirettamente queste pratiche.\n\n64.3.1 Il Caso Brian Wansink\nUn caso emblematico è quello di Brian Wansink, ex ricercatore di spicco alla Cornell University, che ricevette cospicui finanziamenti federali durante l’amministrazione Obama. I suoi studi sul comportamento alimentare, come quello sugli uomini che mangiano di più in presenza di donne o sull’effetto dei nomi “attraenti” dati alle verdure sul consumo da parte dei bambini, attirarono grande attenzione mediatica ma si rivelarono in seguito non replicabili. Le conseguenze per Wansink furono severe: diciotto suoi articoli furono ritirati, sette ricevettero “espressioni di preoccupazione”, e quindici furono corretti. Nel 2019, Wansink si dimise da Cornell dopo essere stato giudicato colpevole di cattiva condotta scientifica.\n\n\n64.3.2 Il Caso Sylvain Lesné\nUn altro esempio rilevante riguarda Sylvain Lesné e i suoi coautori che, nel 2006, pubblicarono su Nature un importante articolo sul morbo di Alzheimer. Questo lavoro era fondamentale per lo sviluppo dell’ipotesi amiloide, un meccanismo proposto per spiegare come la malattia affligge le sue vittime. La ricerca sulla malattia di Alzheimer, che colpisce oltre 50 milioni di persone nel mondo, ha ricevuto oltre un miliardo di dollari in finanziamenti governativi fino al 2022, incoraggiata da studi come quello di Lesné.\nNel 2022, il neuroscienziato Matthew Schrag scoprì immagini manipolate in questo e in molti altri articoli di Lesné, inclusi quelli che sostenevano l’ipotesi amiloide. Le immagini erano state manualmente modificate e accorpate per mostrare falsamente supporto alle ipotesi degli articoli. Queste frodi passarono inosservate attraverso i processi di peer review formali di Nature e di altre sei riviste accademiche, venendo infine scoperte solo tramite canali non ufficiali.\nLe conseguenze di queste scoperte furono lente e frammentarie. Gli altri coautori dell’articolo del 2006 alla fine accettarono di ritirarlo, ma non Lesné stesso. La lentezza della risposta a queste evidenze di frode, e il fatto che Lesné continui a essere finanziato dal National Institutes of Health e impiegato presso l’Università del Minnesota, dimostra un fallimento sistemico nell’affrontare la cattiva condotta scientifica.\n\n\n64.3.3 Altri Casi di Rilievo\nHo controllato il contenuto e ho notato che ci sono effettivamente alcune ripetizioni e inconsistenze. Hai ragione nel sospettare che i casi di Dan Ariely e Francesca Gino siano stati trattati separatamente, mentre in realtà sono parte dello stesso scandalo. Inoltre, il caso di Marc Tessier-Lavigne è menzionato due volte. Ecco una versione riscritta e migliorata del testo:\nNel mondo accademico, recenti scandali hanno messo in luce il problema della frode scientifica e le sue conseguenze spesso limitate per i responsabili. Ecco alcuni casi emblematici:\n\nMarc Tessier-Lavigne, ex presidente della Stanford University: Nel 2023, fu costretto a dimettersi dopo la rivelazione di dati falsificati in sue ricerche precedenti presso Genentech. Nonostante lo scandalo, Tessier-Lavigne ha subito conseguenze minime, diventando successivamente CEO di una nuova azienda di ricerca farmacologica. Lo scandalo fu portato alla luce grazie all’indagine condotta da Theo Baker, uno studente diciassettenne di Stanford.\nDan Ariely e Francesca Gino: Questi due rinomati psicologi, noti per le loro ricerche sulla disonestà e il comportamento non etico, sono stati coinvolti in uno scandalo di frode scientifica.\n\nDan Ariely, nel 2021, fu implicato nella fabbricazione di dati in un articolo del 2012 sulla disonestà.\nFrancesca Gino, docente presso la Harvard Business School, è stata accusata di aver presentato lavori contenenti risultati falsificati. Il sito del Dipartimento ora riporta che è in “administrative leave”.\n\n\nL’inefficacia delle istituzioni accademiche nel gestire la frode scientifica riflette una corruzione culturale sistemica. Gli incentivi attuali favoriscono la pubblicazione di risultati positivi e innovativi, spesso a scapito dell’integrità scientifica. Gli studiosi che resistono a queste pressioni rischiano di essere emarginati, mentre chi adotta pratiche discutibili per ottenere risultati desiderati viene spesso premiato con finanziamenti, promozioni e prestigio accademico. In sintesi, la crisi della riproducibilità e la cultura della frode sono problemi diffusi e profondamente radicati nel mondo accademico.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#il-progetto-di-riproducibilità",
    "href": "chapters/replication_crisis/01_crisis.html#il-progetto-di-riproducibilità",
    "title": "64  La crisi della replicazione",
    "section": "64.4 Il Progetto di Riproducibilità",
    "text": "64.4 Il Progetto di Riproducibilità\n\n64.4.1 L’Iniziativa di Brian Nosek\nNel 2011, Brian Nosek dell’Università della Virginia avviò il Progetto di Riproducibilità (Collaboration, 2015), coinvolgendo 270 ricercatori nel tentativo di replicare cento studi di psicologia. L’obiettivo era ripetere gli esperimenti originali, utilizzando gli stessi metodi ma con nuovi campioni, per verificare la solidità e la replicabilità dei risultati precedentemente pubblicati.\nI risultati di questo imponente lavoro, pubblicati nel 2015, furono a dir poco sconvolgenti. Dei cento studi esaminati, ben novantasette avevano inizialmente riportato risultati statisticamente significativi. Tuttavia, il team di Nosek riuscì a replicare questi risultati solo in trentasei casi. Non solo: le dimensioni degli effetti nelle replicazioni risultarono, in media, dimezzate rispetto agli studi originali. Inoltre, più della metà di queste dimensioni degli effetti cadeva al di fuori degli intervalli di confidenza al 95% riportati nei lavori originali.\n\n\n64.4.2 Studi Successivi\nQuesti risultati sono stati ulteriormente corroborati da numerosi studi successivi, tra cui una ricerca più recente basata su tecniche di machine learning, che ha esaminato studi di psicologia pubblicati in sei importanti riviste nell’arco di vent’anni. Questa ricerca suggerisce che poco più della metà di questi articoli di psicologia non supererebbe i test di replicazione (Youyou et al., 2023). Discipline come la psicologia sociale sono state oggetto di particolare preoccupazione, con un tasso di replicazione del solo 25% riportato dal Progetto di Riproducibilità (Collaboration, 2015). Questo dato è in linea con il lavoro di Youyou et al. (2023), che ha mostrato come la replicabilità degli articoli di psicologia vari considerevolmente per sottocampo, con la psicologia sociale che mostra un tasso di replicazione stimato del 37%, un risultato leggermente più incoraggiante rispetto a quanto riportato in precedenza, ma ancora tra i più bassi dei sottocampi esaminati. Altri settori come la psicologia dello sviluppo, cognitiva e clinica hanno mostrato tassi di replicazione stimati rispettivamente del 36%, 42% e 44%, mentre aree come la psicologia delle organizzazioni e della personalità hanno mostrato tassi leggermente più incoraggianti (50% e 55%, rispettivamente). Complessivamente, le evidenze suggeriscono che le preoccupazioni diffuse sulla robustezza e replicabilità dei risultati della ricerca psicologica siano fondate. Sebbene il problema non sia limitato esclusivamente alla psicologia, le questioni rilevate in questo campo hanno ricevuto notevole attenzione a causa dell’apparente portata del fenomeno.\nQuesti risultati confermavano in modo drammatico le previsioni formulate anni prima da John Ioannidis e Dennis Lindley. Le loro avvertenze riguardo alla possibilità che una larga parte, se non la maggioranza, dei risultati scientifici pubblicati potesse essere falsa, si rivelavano ora profetiche.\nIl Progetto di Riproducibilità di Nosek ha segnato un punto di svolta nel dibattito sulla crisi della replicazione in psicologia e, più in generale, nelle scienze sociali e biomediche. Ha evidenziato non solo la fragilità di molti risultati ritenuti consolidati, ma anche la necessità di un riesame critico delle pratiche di ricerca e pubblicazione scientifica. Questo ripensamento delle metodologie scientifiche è ancora in atto.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#cause-profonde-della-crisi-della-replicazione",
    "href": "chapters/replication_crisis/01_crisis.html#cause-profonde-della-crisi-della-replicazione",
    "title": "64  La crisi della replicazione",
    "section": "64.5 Cause Profonde della Crisi della Replicazione",
    "text": "64.5 Cause Profonde della Crisi della Replicazione\nLa crisi della replicazione in psicologia e in altre scienze ha radici profonde e non può essere attribuita esclusivamente a pratiche di ricerca disoneste. Diverse cause immediate sono state identificate, tra cui:\n\nPressione a pubblicare (“publish or perish”): L’intensa pressione sui ricercatori a pubblicare prolificamente è un fattore importante che può contribuire a molti dei problemi legati alla crisi della replicazione. La cultura del “publish or perish” mette i ricercatori sotto stress continuo per produrre risultati significativi e pubblicarli rapidamente (Gopalakrishna et al., 2022; Grimes et al., 2018).\nRicerca della novità a ogni costo e incentivi accademici distorti: La ricerca di risultati innovativi e il valore eccessivo attribuito alle scoperte significative incentivano pratiche di ricerca distorte. Questo include la sovrarappresentazione dei risultati positivi e la mancanza di rigore metodologico (Ferguson & Heene, 2012; Ware & Munafò, 2015).\nBassa potenza statistica e scarsità di sforzi di replicazione: Molti studi soffrono di bassa potenza statistica, il che rende difficile ottenere risultati affidabili. Inoltre, la mancanza di sforzi di replicazione contribuisce a mantenere e diffondere risultati non replicabili.\nMancanza di trasparenza nella reportistica: La reportistica selettiva e la flessibilità non dichiarata nei metodi e nei dati sono pratiche comuni che compromettono l’integrità scientifica. Inoltre, la riluttanza a condividere dati e materiali e il bias di pubblicazione, per cui i risultati nulli hanno meno probabilità di essere pubblicati rispetto a quelli statisticamente significativi, aggravano il problema (Bruton et al., 2020; Nosek et al., 2012).\n\n\n64.5.1 La Probabilità Inversa\nOltre a questi fattori, alcuni studiosi sostengono che la radice della crisi della replicazione sia ancora più profonda e risieda nell’approccio statistico stesso, ampiamente adottato dalla comunità scientifica (Chivers, 2024; Gelman & Loken, 2014; Loken & Gelman, 2017). Questo punto di vista suggerisce che le difficoltà nella replicazione dei risultati non siano solo il prodotto di comportamenti individuali discutibili, ma derivino in larga parte da un’interpretazione e un’applicazione problematica dei metodi statistici.\nPer comprendere meglio questa questione, dobbiamo tornare alle basi della statistica inferenziale. L’approccio frequentista, dominante nella ricerca scientifica, si basa sulle probabilità di campionamento. Questo metodo, che risale a Jakob Bernoulli nel XVIII secolo, calcola la probabilità di osservare certi dati assumendo che una determinata ipotesi sia vera. Il famoso “p-value” è un esempio di questa logica: esso indica la probabilità di ottenere risultati estremi quanto o più estremi di quelli osservati, supponendo che l’ipotesi nulla sia vera.\nTuttavia, questo approccio ha un limite fondamentale: non ci dice direttamente quanto è probabile che la nostra ipotesi sia vera alla luce dei dati raccolti. In altre parole, non fornisce una “probabilità inferenziale”, cioè la probabilità che l’ipotesi sia corretta in base ai risultati ottenuti. Qui entra in gioco l’approccio bayesiano. Il teorema di Bayes offre un metodo per calcolare proprio questa probabilità inferenziale. L’approccio bayesiano tiene conto non solo dei dati osservati, ma anche delle conoscenze pregresse (le “prior”) relative all’ipotesi in esame.\nLa differenza tra questi due approcci è cruciale. Mentre il p-value ci dice quanto sono improbabili i nostri dati se l’ipotesi nulla è vera, l’approccio bayesiano ci fornisce la probabilità che la nostra ipotesi sia vera alla luce dei dati raccolti e delle conoscenze precedenti.\n\n\n64.5.2 Implicazioni per la Pratica Scientifica\nQuesta distinzione ha implicazioni profonde per la pratica scientifica. L’uso esclusivo dell’approccio frequentista può portare a sovrastimare la forza delle evidenze a favore di un’ipotesi, specialmente quando si lavora con campioni piccoli o si conducono molti test statistici, come spesso accade in psicologia.\nAlcune soluzioni proposte per affrontare la crisi della replicazione includono:\n\nAbbassare la soglia di significatività statistica, rendendo più difficile dichiarare un risultato “significativo”.\nRichiedere la preregistrazione delle ipotesi per prevenire l’HARKing (Hypothesizing After Results are Known).\nFar sì che le riviste accettino gli articoli basandosi sui metodi piuttosto che sui risultati, per evitare il bias verso la pubblicazione di risultati solo “positivi” o “nuovi”.\n\nTuttavia, queste soluzioni, pur utili, non affrontano il problema fondamentale dell’interpretazione delle evidenze statistiche. L’adozione di un approccio bayesiano offre una soluzione più radicale, fornendo un quadro più completo e realistico della forza delle evidenze a favore o contro un’ipotesi scientifica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#guardare-i-dati",
    "href": "chapters/replication_crisis/01_crisis.html#guardare-i-dati",
    "title": "64  La crisi della replicazione",
    "section": "64.6 Guardare i Dati",
    "text": "64.6 Guardare i Dati\nConsideriamo una simulazione, ispirata da Lakens (2015), che illustra come una pratica apparentemente innocua – osservare i risultati man mano che vengono raccolti nell’approccio frequentista – possa avere conseguenze significative sulle conclusioni di uno studio. In particolare, questa pratica può influire sulla probabilità di ottenere un risultato statisticamente significativo.\nNella simulazione seguente, due campioni casuali vengono estratti dalla stessa popolazione normale di partenza. Di conseguenza, l’“ipotesi nulla” è vera: non c’è differenza tra le medie delle popolazioni. Tuttavia, a causa della variabilità campionaria, il p-valore risulta fortemente influenzato da ogni singola osservazione aggiunta al campione.\n\nsimulate_t_tests &lt;- function(seed, max_sample_size, mu = 0, sigma = 1) {\n  set.seed(seed)\n\n  # Intervallo di grandezza campionaria\n  sample_sizes &lt;- seq(2, max_sample_size, by = 2)\n  p_values &lt;- numeric(length(sample_sizes))\n\n  # Genera due campioni grandi iniziali da una distribuzione normale\n  full_sample1 &lt;- rnorm(max_sample_size, mean = mu, sd = sigma)\n  full_sample2 &lt;- rnorm(max_sample_size, mean = mu, sd = sigma)\n\n  # Simulazione\n  for (i in seq_along(sample_sizes)) {\n    n &lt;- sample_sizes[i]\n\n    # Estrai sottoinsiemi incrementali dai campioni completi\n    sample1 &lt;- full_sample1[1:n]\n    sample2 &lt;- full_sample2[1:n]\n\n    # Esegui il t-test per il confronto delle medie di due gruppi indipendenti\n    t_test &lt;- t.test(sample1, sample2, var.equal = TRUE)\n    p_values[i] &lt;- t_test$p.value\n  }\n\n  # Crea il grafico del p-valore in funzione della grandezza campionaria\n  plot(\n    sample_sizes, p_values, type = \"l\", col = \"#b97c7c\",\n    xlab = \"Grandezza Campionaria\", ylab = \"P-valore\",\n    main = \"P-valore in funzione della grandezza campionaria\"\n  )\n  abline(h = 0.05, col = \"#8f2727\", lty = 2, lwd = 1.5)\n  legend(\"topright\", legend = \"Significatività a 0.05\", col = \"#8f2727\", lty = 2, cex = 0.8)\n}\n\nNelle due simulazioni seguenti, osserviamo come il p-valore cambi progressivamente aumentando la dimensione dei campioni casuali da \\(n = 2\\) a \\(n = 300\\). È evidente come il p-valore vari drasticamente con l’aggiunta di nuove osservazioni ai campioni. Inoltre, in alcune configurazioni, il p-valore può scendere al di sotto della soglia critica di 0.05 per puro caso. Se un ricercatore interrompesse la raccolta dei dati in quel momento, otterrebbe un risultato “statisticamente significativo”, pur avendo campioni estratti dalla stessa popolazione.\n\nsimulate_t_tests(seed = 1234, max_sample_size = 300, mu = 0, sigma = 2)\nsimulate_t_tests(seed = 2, max_sample_size = 300, mu = 0, sigma = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuesta simulazione mette in evidenza una limitazione fondamentale dell’approccio frequentista: ogni test statistico considera esclusivamente i dati del campione corrente, ignorando le conoscenze accumulate in precedenza. Questo rende il processo decisionale estremamente volatile, poiché, teoricamente, ad ogni nuovo studio si “dimentica” tutta l’informazione derivante dagli studi precedenti.\n\n64.6.1 Analisi Bayesiana\nL’approccio bayesiano offre una soluzione elegante a questo problema. Nel framework bayesiano, la distribuzione a posteriori (cioè, la nostra convinzione aggiornata dopo aver osservato i dati) bilancia sempre l’informazione a priori (ciò che sapevamo prima dell’esperimento) con la verosimiglianza (ciò che i dati ci dicono). Questo equilibrio è particolarmente prezioso quando i dati sono deboli o contengono molto rumore, come nel caso dei dati della simulazione che stiamo discutendo. In tali situazioni, l’informazione a priori assume un ruolo più rilevante, impedendo conclusioni affrettate basate su dati poco informativi.\nPer illustrare questa differenza, consideriamo l’analisi bayesiana dei dati simulati in precedenza. Se questi dati vengono analizzati con l’approccio frequentista, forniscono un risultato “statisticamente significativo”, suggerendo una differenza tra i due gruppi.\nTuttavia, analizzando gli stessi dati con un approccio bayesiano, otteniamo un intervallo di credibilità al 95% compreso tra -0.52 e 1.12. Poiché questo intervallo include lo zero, possiamo affermare, con un livello di certezza soggettiva del 95%, che non c’è una differenza sostanziale tra le medie delle due popolazioni da cui sono stati estratti i campioni.\nQuesta discrepanza nei risultati evidenzia un punto cruciale: l’approccio bayesiano è più resistente ai falsi positivi in presenza di dati rumorosi o campioni piccoli. Invece di forzare una decisione binaria (significativo/non significativo) basata su una soglia arbitraria, l’analisi bayesiana fornisce una rappresentazione più sfumata e realistica dell’incertezza associata alle nostre conclusioni.\nInoltre, l’approccio bayesiano offre il vantaggio di essere cumulativo: ogni nuovo studio non parte da zero, ma incorpora naturalmente le conoscenze precedenti attraverso la distribuzione a priori.\n\n# Imposta il seme per la riproducibilità\nset.seed(12)\n\n# Parametri della distribuzione normale\nmu &lt;- 0\nsigma &lt;- 2\nmax_sample_size &lt;- 50\n\n# Genera due campioni indipendenti\nfull_sample1 &lt;- rnorm(max_sample_size, mean = mu, sd = sigma)\nfull_sample2 &lt;- rnorm(max_sample_size, mean = mu, sd = sigma)\n\n\n# Prepara i dati per Stan\nstan_data &lt;- list(\n  N1 = length(full_sample1),\n  N2 = length(full_sample2),\n  y1 = full_sample1,\n  y2 = full_sample2\n)\n\n# Visualizza i dati preparati\nprint(stan_data)\n#&gt; $N1\n#&gt; [1] 50\n#&gt; \n#&gt; $N2\n#&gt; [1] 50\n#&gt; \n#&gt; $y1\n#&gt;  [1] -2.96113519  3.15433894 -1.91348896 -1.84001050 -3.99528419 -0.54459209\n#&gt;  [7] -0.63069742 -1.25651047 -0.21292777  0.85602960 -1.55543916 -2.58776460\n#&gt; [13] -1.55913302  0.02390352 -0.30483248 -1.40692851  2.37775831  0.68102454\n#&gt; [19]  1.01393634 -0.58661030  0.44728283  4.01440291  2.02395824 -0.60491849\n#&gt; [25] -2.05048968 -0.53476966 -0.39821132  0.26224519  0.29159979  0.72412944\n#&gt; [31]  1.34796233  4.14407154 -1.08205730 -2.14098432 -0.74491346 -0.97028271\n#&gt; [37]  0.54956836 -0.95902512  1.59621065 -2.00890240  0.20996847 -2.31198578\n#&gt; [43]  1.15626925 -3.19125131 -0.61700731  0.89893184 -1.95410657  0.37999572\n#&gt; [49]  1.46290671 -0.98519822\n#&gt; \n#&gt; $y2\n#&gt;  [1] -0.085369824 -0.225341153  0.913654495  4.040669684 -2.101780125\n#&gt;  [6]  1.469304212  1.078499488 -2.628545594 -0.500077444  0.628409193\n#&gt; [11]  0.813093387  1.988841200  1.711536864  0.394257834  1.668650075\n#&gt; [16]  1.693580305  3.908210509 -4.298520003  1.942240539  2.290123147\n#&gt; [21] -1.050801252  0.500640206 -0.858813223 -0.365039244 -0.206620933\n#&gt; [26] -1.267676406 -2.542107574 -0.767900788  1.033511605 -0.355937088\n#&gt; [31]  0.008516077 -2.548119102 -0.404220677  2.328931759 -0.046758817\n#&gt; [36]  1.794313500 -0.353448910  2.227418155 -1.083777719 -1.926796664\n#&gt; [41]  0.752896799 -1.969347593  1.795118805  0.258525067  2.067405961\n#&gt; [46] -0.684578547  0.904562513 -1.389475884 -0.478027182 -2.014597919\n\n\n# Path to the Stan file\nstan_file &lt;- here::here(\"stan\", \"two_means_diff.stan\")\n\n# Create a CmdStanModel object\nmod &lt;- cmdstan_model(stan_file)\nmod$code() # Stampa il codice del modello\n#&gt;  [1] \"data {\"                                                                \n#&gt;  [2] \"  int&lt;lower=0&gt; N1; // Numero di osservazioni nel gruppo 1\"             \n#&gt;  [3] \"  int&lt;lower=0&gt; N2; // Numero di osservazioni nel gruppo 2\"             \n#&gt;  [4] \"  vector[N1] y1; // Dati del gruppo 1\"                                 \n#&gt;  [5] \"  vector[N2] y2; // Dati del gruppo 2\"                                 \n#&gt;  [6] \"}\"                                                                     \n#&gt;  [7] \"parameters {\"                                                          \n#&gt;  [8] \"  real mu1; // Media del gruppo 1\"                                     \n#&gt;  [9] \"  real delta; // Differenza tra le medie\"                              \n#&gt; [10] \"  real&lt;lower=0&gt; sigma; // Deviazione standard comune\"                  \n#&gt; [11] \"  real&lt;lower=0&gt; nu; // Gradi di libertà per la distribuzione t\"        \n#&gt; [12] \"}\"                                                                     \n#&gt; [13] \"transformed parameters {\"                                              \n#&gt; [14] \"  real mu2; // Media del gruppo 2\"                                     \n#&gt; [15] \"  mu2 = mu1 + delta;\"                                                  \n#&gt; [16] \"}\"                                                                     \n#&gt; [17] \"model {\"                                                               \n#&gt; [18] \"  // Priori\"                                                           \n#&gt; [19] \"  mu1 ~ normal(0, 5);\"                                                 \n#&gt; [20] \"  delta ~ normal(0, 2); // Priore su delta\"                            \n#&gt; [21] \"  sigma ~ cauchy(0, 5);\"                                               \n#&gt; [22] \"  nu ~ gamma(2, 0.1); // Priore sulla t-student\"                       \n#&gt; [23] \"  \"                                                                    \n#&gt; [24] \"  // Verosimiglianza\"                                                  \n#&gt; [25] \"  y1 ~ student_t(nu, mu1, sigma);\"                                     \n#&gt; [26] \"  y2 ~ student_t(nu, mu2, sigma);\"                                     \n#&gt; [27] \"}\"                                                                     \n#&gt; [28] \"generated quantities {\"                                                \n#&gt; [29] \"  real diff; // Differenza tra le medie (alias di delta per chiarezza)\"\n#&gt; [30] \"  diff = delta;\"                                                       \n#&gt; [31] \"}\"\n\nEsegui il campionamento:\n\nfit &lt;- mod$sample(\n  data = stan_data,\n  seed = 123,\n  chains = 4,\n  iter_sampling = 2000,\n  iter_warmup = 1000,\n  show_messages = FALSE\n)\n\nRiassumi i risultati per mu1, mu2 e delta:\n\nfit_summary &lt;- fit$summary(variables = c(\"mu1\", \"mu2\", \"delta\"))\nprint(fit_summary)\n#&gt; # A tibble: 3 × 10\n#&gt;   variable   mean median    sd   mad      q5    q95  rhat ess_bulk ess_tail\n#&gt;   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 mu1      -0.313 -0.312 0.241 0.238 -0.707  0.0818  1.00    5378.    5491.\n#&gt; 2 mu2       0.164  0.166 0.246 0.248 -0.235  0.568   1.00    9428.    6234.\n#&gt; 3 delta     0.477  0.474 0.341 0.344 -0.0887 1.04    1.00    5155.    5260.\n\nEstrai i campioni di delta:\n\ndelta_samples &lt;- fit$draws(variables = \"delta\", format = \"matrix\")[, 1]\n\nDisegna la distribuzione a posteriori di delta:\n\ndelta_df &lt;- data.frame(delta = delta_samples)\n\nggplot(delta_df, aes(x = delta)) +\n  geom_histogram(aes(y = ..density..), bins = 30, fill = \"#b97c7c\", alpha = 0.75) +\n  geom_vline(\n    xintercept = mean(delta_samples),\n    linetype = \"dashed\",\n    linewidth = 1.2,\n    label = paste(\"Mean:\", round(mean(delta_samples), 2))\n  ) +\n  labs(\n    x = \"delta\",\n    y = \"Density\",\n    title = \"Posterior distribution of delta\"\n  ) \n#&gt; Warning in geom_vline(xintercept = mean(delta_samples), linetype = \"dashed\",\n#&gt; : Ignoring unknown parameters: `label`\n#&gt; Warning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `after_stat(density)` instead.\n\n\n\n\n\n\n\n\nPuoi calcolare l’intervallo di credibilità usando per un intervallo al 95%:\n\nquantile(delta_samples, probs = c(0.025, 0.975))\n#&gt;       2.5%      97.5% \n#&gt; -0.1872254  1.1552680",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#il-giardino-dei-sentieri-che-si-biforcano",
    "href": "chapters/replication_crisis/01_crisis.html#il-giardino-dei-sentieri-che-si-biforcano",
    "title": "64  La crisi della replicazione",
    "section": "64.7 Il Giardino dei Sentieri che si Biforcano",
    "text": "64.7 Il Giardino dei Sentieri che si Biforcano\nLo psicologo Paul Meehl condusse uno studio su un campione di cinquantasettamila studenti delle scuole superiori del Minnesota, indagando su variabili quali religione, abitudini nel tempo libero, ordine di nascita, numero di fratelli, piani post-diploma e numerosi altri aspetti (Meehl, 2012). Complessivamente, le diverse risposte dei partecipanti potevano essere combinate in 990 modi distinti, permettendo analisi del tipo: “Gli studenti appassionati di cucina hanno una maggiore probabilità di essere figli unici?” o “Gli studenti provenienti da famiglie battiste sono più inclini a partecipare a club politici scolastici?”. Meehl evidenziò che, analizzando i dati, il 92% di queste possibili combinazioni risultava in correlazioni statisticamente significative. Queste differenze, sebbene reali, presumibilmente derivano da cause multifattoriali e complesse.\nAndrew Gelman ha denominato questo fenomeno “Il Giardino dei Sentieri che si Biforcano” [Garden of Forking Paths; Gelman & Loken (2013)], riferendosi ai molteplici gradi di libertà a disposizione del ricercatore nell’analisi dei dati. Come nell’esempio di Meehl, è possibile esaminare le differenze intergruppo (se questo è l’oggetto di interesse) da molteplici prospettive. Con un campione sufficientemente ampio, alcune di queste differenze risulteranno “statisticamente significative”. Ciò indica che, in quello specifico campione, quel particolare aspetto dei dati è rilevante. Tuttavia, questa differenza “statisticamente significativa” non sarà necessariamente generalizzabile ad un altro campione, il quale presenterà le proprie idiosincrasie.\nIn altri termini, come sottolineato da Gelman, l’approccio basato sul test dell’ipotesi nulla si limita a “descrivere il rumore”. Da un punto di vista teorico, simili esercizi statistici risultano privi di valore euristico e non contribuiscono in nessun modo all’avanzamento delle conoscenze sul fenomeno oggetto di studio.\nIn un’ottica di inferenza statistica, questo problema è riconducibile al concetto di “p-hacking” o “data dredging”, dove l’esplorazione esaustiva di molteplici ipotesi statistiche su un singolo set di dati può portare a falsi positivi e a una sovrastima della significatività statistica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#garbage-in-garbage-out",
    "href": "chapters/replication_crisis/01_crisis.html#garbage-in-garbage-out",
    "title": "64  La crisi della replicazione",
    "section": "64.8 Garbage In, Garbage Out",
    "text": "64.8 Garbage In, Garbage Out\nLa natura della statistica frequentista impone di prendere una decisione dicotomica: o si rifiuta l’ipotesi nulla o non la si rifiuta. Ciò implica che o esiste un effetto reale, oppure non esiste. Con un campione abbastanza grande, è inevitabile trovare qualche effetto, anche se di minima entità.\nUn approccio bayesiano, invece, permette di stimare la dimensione dell’effetto e di fornire una distribuzione di probabilità. Una distribuzione di probabilità è una rappresentazione grafica delle diverse possibilità che potrebbero verificarsi. In questo contesto, si tratta della “probabilità inversa”, ovvero della plausibilità dell’ipotesi alla luce dei dati osservati e delle conoscenze pregresse. Qui, il parametro \\(\\delta\\) rappresenta la differenza tra le due medie ed è il parametro di interesse. Le credenze precedenti su \\(\\delta\\) sono espresse tramite una distribuzione a priori: in questo caso, una distribuzione Normale centrata su 0 con una deviazione standard di 2. La distribuzione a posteriori rappresenta la nostra conoscenza aggiornata su \\(\\delta\\) dopo l’aggiornamento bayesiano. Il parametro \\(\\delta\\) è la nostra ipotesi sulla differenza tra le due medie, e l’inferenza bayesiana riguarda il cambiamento della nostra credenza dopo aver osservato i dati.\nL’approccio frequentista, al contrario, produce una decisione dicotomica che non modifica la nostra concezione dell’ipotesi dopo aver osservato i dati. Assume una determinata ipotesi come vera e verifica se i dati sono coerenti con essa. Tramite il concetto binario di “significatività statistica”, non si modificano le ipotesi di interesse, ma si accettano o si rifiutano le ipotesi nulle.\nSebbene l’approccio frequentista sia spesso considerato “ingenuo” da molti ricercatori, adottare l’approccio bayesiano non rappresenta una soluzione miracolosa ai problemi della scienza contemporanea. Risolve alcuni problemi, ma non altri. In particolare, non affronta la questione degli incentivi accademici che favoriscono la pubblicazione di un elevato numero di articoli, indipendentemente dalla loro qualità. Un principio fondamentale della ricerca è “Garbage in, garbage out”. Se i dati derivano da un disegno di ricerca fallace o poco creativo, se la ricerca non ha un solido fondamento teorico capace di avanzare le nostre conoscenze, o se la qualità delle misurazioni è insufficiente, i dati raccolti sono puro rumore. Nessun metodo statistico, nemmeno quello bayesiano, può trasformare la spazzatura in oro.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#esercizi",
    "href": "chapters/replication_crisis/01_crisis.html#esercizi",
    "title": "64  La crisi della replicazione",
    "section": "64.9 Esercizi",
    "text": "64.9 Esercizi\n\nEsercizio 64.1 Esistono numerosi esempi di ricerche che non riescono a essere replicate (posso citare anche uno studio di replicazione che ho condotto io stesso: Caudek et al. (2017)). Un recente caso emblematico è rappresentato dallo studio di Karataş & Cutright (2023) e dal successivo tentativo di replicazione condotto da Moore et al. (2024). Analizzando le quattro principali argomentazioni sollevate da Gelman & Brown (2024) per criticare lo studio di Aungle & Langer (2023), si offra un’interpretazione del perché lo studio di Karataş & Cutright (2023) non sia stato replicato con successo.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/replication_crisis/01_crisis.html#informazioni-sullambiente-di-sviluppo",
    "title": "64  La crisi della replicazione",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sequoia 15.1.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n#&gt; \n#&gt; locale:\n#&gt; [1] C/UTF-8/C/C/C/C\n#&gt; \n#&gt; time zone: Europe/Rome\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] posterior_1.6.0     cmdstanr_0.8.1.9000 MASS_7.3-61        \n#&gt;  [4] viridis_0.6.5       viridisLite_0.4.2   ggpubr_0.6.0       \n#&gt;  [7] ggExtra_0.10.1      gridExtra_2.3       patchwork_1.3.0    \n#&gt; [10] bayesplot_1.11.1    psych_2.4.6.26      scales_1.3.0       \n#&gt; [13] markdown_1.13       knitr_1.49          lubridate_1.9.3    \n#&gt; [16] forcats_1.0.0       stringr_1.5.1       dplyr_1.1.4        \n#&gt; [19] purrr_1.0.2         readr_2.1.5         tidyr_1.3.1        \n#&gt; [22] tibble_3.2.1        ggplot2_3.5.1       tidyverse_2.0.0    \n#&gt; [25] rio_1.2.3           here_1.0.1         \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] tensorA_0.36.2.1     gtable_0.3.6         xfun_0.49           \n#&gt;  [4] htmlwidgets_1.6.4    processx_3.8.4       rstatix_0.7.2       \n#&gt;  [7] lattice_0.22-6       tzdb_0.4.0           ps_1.8.1            \n#&gt; [10] vctrs_0.6.5          tools_4.4.2          generics_0.1.3      \n#&gt; [13] parallel_4.4.2       fansi_1.0.6          pacman_0.5.1        \n#&gt; [16] pkgconfig_2.0.3      data.table_1.16.2    checkmate_2.3.2     \n#&gt; [19] distributional_0.5.0 lifecycle_1.0.4      compiler_4.4.2      \n#&gt; [22] farver_2.1.2         munsell_0.5.1        mnormt_2.1.1        \n#&gt; [25] carData_3.0-5        httpuv_1.6.15        htmltools_0.5.8.1   \n#&gt; [28] yaml_2.3.10          Formula_1.2-5        car_3.1-3           \n#&gt; [31] pillar_1.9.0         later_1.4.1          abind_1.4-8         \n#&gt; [34] nlme_3.1-166         mime_0.12            tidyselect_1.2.1    \n#&gt; [37] digest_0.6.37        stringi_1.8.4        labeling_0.4.3      \n#&gt; [40] rprojroot_2.0.4      fastmap_1.2.0        grid_4.4.2          \n#&gt; [43] colorspace_2.1-1     cli_3.6.3            magrittr_2.0.3      \n#&gt; [46] utf8_1.2.4           broom_1.0.7          withr_3.0.2         \n#&gt; [49] backports_1.5.0      promises_1.3.2       timechange_0.3.0    \n#&gt; [52] rmarkdown_2.29       matrixStats_1.4.1    ggsignif_0.6.4      \n#&gt; [55] hms_1.1.3            shiny_1.9.1          evaluate_1.0.1      \n#&gt; [58] miniUI_0.1.1.1       rlang_1.1.4          Rcpp_1.0.13-1       \n#&gt; [61] xtable_1.8-4         glue_1.8.0           jsonlite_1.8.9      \n#&gt; [64] R6_2.5.1",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#bibliografia",
    "href": "chapters/replication_crisis/01_crisis.html#bibliografia",
    "title": "64  La crisi della replicazione",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nAungle, P., & Langer, E. (2023). Physical healing as a function of perceived time. Scientific Reports, 13(1), 22432.\n\n\nBargh, J. A., Chen, M., & Burrows, L. (1996). Automaticity of social behavior: Direct effects of trait construct and stereotype activation on action. Journal of personality and social psychology, 71(2), 230–244.\n\n\nBem, D. J. (2011). Feeling the future: experimental evidence for anomalous retroactive influences on cognition and affect. Journal of Personality and Social Psychology, 100(3), 407–425.\n\n\nBruton, S. V., Medlin, M., Brown, M., & Sacco, D. F. (2020). Personal motivations and systemic incentives: Scientists on questionable research practices. Science and Engineering Ethics, 26(3), 1531–1547.\n\n\nCaudek, C., Lorenzino, M., & Liperoti, R. (2017). Delta plots do not reveal response inhibition in lying. Consciousness and Cognition, 55, 232–244.\n\n\nChivers, T. (2024). Everything is Predictable: How Bayesian Statistics Explain Our World. Simon; Schuster.\n\n\nCollaboration, O. S. (2015). Estimating the reproducibility of psychological science. Science, 349(6251), aac4716.\n\n\nFerguson, C. J., & Heene, M. (2012). A vast graveyard of undead theories: Publication bias and psychological science’s aversion to the null. Perspectives on Psychological Science, 7(6), 555–561.\n\n\nGelman, A., & Brown, N. J. (2024). How statistical challenges and misreadings of the literature combine to produce unreplicable science: An example from psychology.\n\n\nGelman, A., & Loken, E. (2013). The garden of forking paths: Why multiple comparisons can be a problem, even when there is no «fishing expedition» or «p-hacking» and the research hypothesis was posited ahead of time. Department of Statistics, Columbia University, 348(1-17), 3.\n\n\nGelman, A., & Loken, E. (2014). The statistical crisis in science. American scientist, 102(6), 460–465.\n\n\nGopalakrishna, G., Ter Riet, G., Vink, G., Stoop, I., Wicherts, J. M., & Bouter, L. M. (2022). Prevalence of questionable research practices, research misconduct and their potential explanatory factors: A survey among academic researchers in The Netherlands. PloS one, 17(2), e0263023.\n\n\nGrimes, D. R., Bauch, C. T., & Ioannidis, J. P. (2018). Modelling science trustworthiness under publish or perish pressure. Royal Society open science, 5(1), 171511.\n\n\nIoannidis, J. P. (2005). Why most published research findings are false. PLoS medicine, 2(8), e124.\n\n\nKarataş, M., & Cutright, K. M. (2023). Thinking about God increases acceptance of artificial intelligence in decision-making. Proceedings of the National Academy of Sciences, 120(33), e2218961120.\n\n\nLakens, D. (2015). On the challenges of drawing conclusions from p-values just below 0.05. PeerJ, 3, e1142.\n\n\nLoken, E., & Gelman, A. (2017). Measurement Error and the Replication Crisis. Science, 355(6325), 584–585.\n\n\nMeehl, P. E. (2012). Why summaries of research on psychological theories are often uninterpretable. In Improving inquiry in social science (pp. 13–59). Routledge.\n\n\nMoore, D. A., Schroeder, J., Bailey, E. R., Gershon, R., Moore, J. E., & Simmons, J. P. (2024). Does thinking about God increase acceptance of artificial intelligence in decision-making? Proceedings of the National Academy of Sciences, 121(31), e2402315121.\n\n\nNelson, L. D., Simmons, J., & Simonsohn, U. (2018). Psychology’s renaissance. Annual review of psychology, 69(1), 511–534.\n\n\nNosek, B. A., Spies, J. R., & Motyl, M. (2012). Scientific utopia: II. Restructuring incentives and practices to promote truth over publishability. Perspectives on Psychological Science, 7(6), 615–631.\n\n\nRitchie, S. J., Wiseman, R., & French, C. C. (2012). Failing the future: Three unsuccessful attempts to replicate Bem’s ‘Retroactive Facilitation of Recall’Effect. PloS one, 7(3), e33423.\n\n\nWare, J. J., & Munafò, M. R. (2015). Significance chasing in research practice: causes, consequences and possible solutions. Addiction, 110(1), 4–8.\n\n\nYouyou, W., Yang, Y., & Uzzi, B. (2023). A discipline-wide investigation of the replicability of Psychology papers over the past two decades. Proceedings of the National Academy of Sciences, 120(6), e2208863120.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>La crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html",
    "title": "65  Limiti dell’inferenza frequentista",
    "section": "",
    "text": "Introduzione\nPrerequisiti\nConcetti e Competenze Chiave\nIn questa sezione della dispensa abbiamo esaminato il metodo “tradizionale” per il test di significatività dell’ipotesi nulla (NHST). Comprendere la logica alla base dell’approccio NHST è essenziale poiché questo è stato l’approccio predominante alla statistica inferenziale fin dalla sua introduzione all’inizio del XX secolo e la maggior parte dei ricercatori ancora si affida a questa procedura per analizzare i dati. Tuttavia, recentemente, l’approccio NHST è stato oggetto di aspre critiche, poiché molti ricercatori hanno iniziato a pensare che questo approccio possa creare più problemi di quanti ne risolva. Pertanto, è importante conoscere le critiche mosse alla procedura inferenziale NHST all’interno della comunità scientifica. In questa sezione esamineremo alcuni dei dubbi sorti riguardo a questo approccio.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#luso-del-valore-p-nel-mondo-della-ricerca",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#luso-del-valore-p-nel-mondo-della-ricerca",
    "title": "65  Limiti dell’inferenza frequentista",
    "section": "65.1 L’uso del valore-\\(p\\) nel mondo della ricerca",
    "text": "65.1 L’uso del valore-\\(p\\) nel mondo della ricerca\nNel suo articolo “Statistical Errors” (2014), Nuzzo evidenzia i limiti dell’approccio NHST nella pratica scientifica Nuzzo (2014). Infatti, sebbene il valore-\\(p\\) sia stato introdotto da Ronald Fisher negli anni ’20, egli non lo ha mai concepito come un test formale. Invece, Fisher lo considerava uno strumento informale per valutare se l’evidenza empirica fosse significativa in un senso colloquiale, ovvero meritevole di attenzione. In pratica, Fisher suggeriva di assumere un’ipotesi nulla e di calcolare la probabilità di osservare un risultato altrettanto estremo o più estremo di quello trovato, se il risultato fosse completamente dovuto alla sola variabilità campionaria. Sebbene sia possibile calcolare il valore-\\(p\\) tramite una procedura matematica, per Fisher esso era solo uno strumento da utilizzare all’interno di un processo decisionale non numerico, in grado di combinare le evidenze empiriche attuali con le conoscenze pregresse del ricercatore. In altre parole, il valore-\\(p\\) rappresentava uno strumento da utilizzare all’interno del processo decisionale, non la conclusione del processo decisionale stesso.\nVerso la fine degli anni ’20, Jerzy Neyman e Egon Pearson, rivali di Fisher, formalizzarono le procedure di decisione statistica con l’obiettivo di renderle “rigorose e oggettive”. In particolare, introdussero i concetti di potere statistico e di falso positivo, ma non utilizzarono la nozione di valore-\\(p\\) come aveva fatto Fisher.\nLe divergenze tra i tre autori portarono a un acceso dibattito, in cui Neyman criticò il lavoro di Fisher come matematicamente “peggiore dell’inutilità”, mentre Fisher definì l’approccio di Neyman “infantile” e “orribile per la libertà intellettuale dell’occidente”.\nDurante questo dibattito, altri autori iniziarono a scrivere manuali di statistica per fornire uno strumento di lavoro ai ricercatori. Poiché molti di questi autori non erano statistici e avevano solo una comprensione superficiale della distinzione tra i vari approcci, crearono un sistema ibrido che utilizzava il valore-\\(p\\) proposto da Fisher all’interno del “sistema rigoroso” proposto da Neyman e Pearson. È in questo contesto che la soglia di un valore-\\(p\\) pari a 0.05 venne definita come “statisticamente significativa”.\nTuttavia, dal punto di vista storico, il valore-\\(p\\) proposto da Fisher aveva un significato molto diverso da quello che viene attribuito oggi nel mondo della ricerca. Come abbiamo visto, il valore-\\(p\\) era solo uno strumento informale utilizzato da Fisher all’interno di un processo decisionale più ampio, e il suo uso all’interno del sistema ibrido creato dai manuali di statistica era privo di giustificazione e fondamento.\nNel 2016 l’American Statistical Association ha pubblicato un articolo nel quale si esprime una grande preoccupazione per l’uso inappropriato che viene fatto del valore-\\(p\\) nella pratica scientifica odierna Wasserstein & Lazar (2016):\n\n\\(P\\)-values do not measure the probability that the studied hypothesis is true, or the probability that the data were produced by random chance alone. Researchers often wish to turn a \\(p\\)-value into a statement about the truth of a null hypothesis, or about the probability that random chance produced the observed data. The \\(p\\)-value is neither. It is a statement about data in relation to a specified hypothetical explanation, and is not a statement about the explanation itself.\n\nL’articolo prosegue affermando che:\n\nScientific conclusions and business or policy decisions should not be based only on whether a \\(p\\)-value passes a specific threshold. Practices that reduce data analysis or scientific inference to mechanical “bright-line” rules (such as “\\(p &lt; 0.05\\)”) for justifying scientific claims or conclusions can lead to erroneous beliefs and poor decision making. A conclusion does not immediately become ‘true’ on one side of the divide and ‘false’ on the other. Researchers should bring many contextual factors into play to derive scientific inferences, including the design of a study, the quality of the measurements, the external evidence for the phenomenon under study, and the validity of assumptions that underlie the data analysis. Pragmatic considerations often require binary, ‘yes-no’ decisions, but this does not mean that \\(p\\)-values alone can ensure that a decision is correct or incorrect. The widespread use of “statistical significance” (generally interpreted as ) as a license for making a claim of a scientific finding (or implied truth) leads to considerable distortion of the scientific process.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#p-hacking",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#p-hacking",
    "title": "65  Limiti dell’inferenza frequentista",
    "section": "65.2 \\(P\\)-hacking",
    "text": "65.2 \\(P\\)-hacking\nLa pratica del \\(P\\)-hacking rappresenta la principale fallacia associata all’utilizzo del valore-\\(p\\) ed è nota anche come “\\(P\\)-hacking”, “data-dredging”, “snooping”, “fishing”, “significance-chasing” o “double-dipping”. Secondo Uri Simonsohn, docente presso l’Università della Pennsylvania, il \\(P\\)-hacking consiste nel tentativo di provare diverse ipotesi finché non si ottiene il risultato desiderato. Ad esempio, si potrebbe dire: “Quel risultato sembra essere stato ottenuto attraverso il \\(p\\)-hacking, gli autori hanno eliminato una delle condizioni in modo che il valore-\\(p\\) complessivo fosse inferiore a 0.05” oppure “Lei è una \\(p\\)-hacker, controlla sempre i dati mentre vengono raccolti”.\nQuesta pratica ha l’effetto di trasformare uno studio esplorativo, che dovrebbe essere sempre interpretato con cautela, in uno studio (apparentemente) confermativo, il cui risultato appare “robusto”, ma che in realtà ha una probabilità pressoché nulla di essere replicato in studi successivi. Secondo le simulazioni di Simonsohn, il cambiamento di poche decisioni nel processo di analisi dei dati può aumentare fino al 60% il tasso di falsi positivi in un singolo studio.\nIl \\(P\\)-hacking è diffuso soprattutto negli studi che tentano di dimostrare piccoli effetti usando dati molto rumorosi. Un’analisi della letteratura psicologica ha mostrato che i valori-\\(p\\) riportati dagli psicologi tendono a concentrarsi su valori appena superiori alla soglia minima dello 0.05. Questo risultato può essere interpretato come conseguenza della pratica del \\(P\\)-hacking: i ricercatori eseguono molteplici test statistici fino a trovare uno che risulta “statisticamente significativo” e poi riportano solo quello. Come mostra la figura seguente, questa pratica non riguarda solo la psicologia, ma è diffusa in tutti i campi della ricerca scientifica.\n\n\n\nDistribuzione dei valori-\\(p\\) nelle pubblicazioni scientifiche di economia, psicologia e biologia.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#critiche-al-valore-p",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#critiche-al-valore-p",
    "title": "65  Limiti dell’inferenza frequentista",
    "section": "65.3 Critiche al valore-\\(p\\)",
    "text": "65.3 Critiche al valore-\\(p\\)\nIl valore-\\(p\\) è stato paragonato a creature noiose e ostinate come le zanzare, ai vestiti nuovi dell’imperatore, ovvero alla tendenza di non voler riconoscere evidenti problemi, ma preferire di far finta di nulla, o ad un intellectual rake sterile, che non porta alcun frutto. Si è anche ironizzato sul fatto che la procedura di statistical hypothesis inference testing venga chiamata così solo per l’acronimo che produce.\nIl valore-\\(p\\) incoraggia un modo di pensare errato, spostando l’attenzione dal problema centrale della ricerca, ovvero la forza della manipolazione sperimentale, alla dimostrazione di una falsa ipotesi che si sa a priori essere falsa (l’ipotesi nulla). Ad esempio, uno studio con più di 19.000 individui ha dimostrato che coloro che incontrano il loro partner online hanno una probabilità minore di divorziare (\\(p &lt;\\) 0,002) e sono più soddisfatti della loro vita matrimoniale (\\(p &lt;\\) 0,001) rispetto a chi non si è conosciuto online. Questo può sembrare un risultato interessante, ma senza considerare la dimensione dell’effetto, ovvero il tasso di divorzio che scende dal 7.67% al 5.96% e l’aumento dell’indice di soddisfazione matrimoniale da 5.48 a 5.64 su una scala a sette punti, il risultato perde di interesse. In generale, la domanda cruciale non è “c’è un effetto o no?” ma piuttosto “qual è la dimensione dell’effetto?”.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#leffetto-sperimentale-è-esattamente-nullo",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#leffetto-sperimentale-è-esattamente-nullo",
    "title": "65  Limiti dell’inferenza frequentista",
    "section": "65.4 L’effetto sperimentale è esattamente nullo?",
    "text": "65.4 L’effetto sperimentale è esattamente nullo?\nUna delle critiche più frequenti alla logica di verifica delle ipotesi statistiche riguarda l’assunzione irrealistica che l’effetto della manipolazione sperimentale sia “esattamente” nullo. Ad esempio, la fisica ci insegna che lo spostamento di un grammo di massa in una stella distante qualche anno luce dalla Terra può influenzare il movimento delle molecole di un gas sulla Terra Borel (1914). Questo ci suggerisce che ogni manipolazione sperimentale produca, in qualche modo, un effetto. Pertanto, secondo Andrew Gelman, il problema non è dimostrare falsa l’ipotesi nulla, ovvero che la manipolazione sperimentale non produca alcun effetto, ma piuttosto valutare se la dimensione dell’effetto è sufficientemente grande da avere un impatto pratico e se l’effetto sia riproducibile. In questo senso, la logica di verifica dell’ipotesi nulla può essere problematica, soprattutto quando si lavora con piccoli campioni e piccoli effetti, come nella maggior parte degli studi in psicologia, poiché può portare ad una sovrastima della dimensione dell’effetto e ad una visione binaria del risultato (vero/falso), invece di concentrarsi sulla stima non distorta della dimensione effettiva dell’effetto.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#attenti-al-valore-p",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#attenti-al-valore-p",
    "title": "65  Limiti dell’inferenza frequentista",
    "section": "65.5 Attenti al valore-\\(p\\)!",
    "text": "65.5 Attenti al valore-\\(p\\)!\nConsideriamo il seguente problema. Eseguiamo un \\(t\\)-test per due campioni indipendenti e sottoponiamo a verifica l’ipotesi nulla dell’eguaglianza delle due medie. Sia \\(\\alpha = 0.05\\). Otteniamo un valore-\\(p\\) di \\(0.04\\). Qual è la probabilità che i due campioni siano tratti da distribuzioni con la stessa media?\n\n\\(19/20; \\quad\\) (b) \\(1/19; \\quad\\) (c) \\(1/20; \\quad\\) (d) \\(95/100; \\quad\\) (e) sconosciuta.\n\nLa risposta corretta è: (e) sconosciuta. La statistica frequentista definisce le probabilità dei dati condizionatamente alle ipotesi (assunte come vere). Non consente di stabilire la probabilità di un’ipotesi.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#la-crisi-della-riprodicibilità-dei-risultati-della-ricerca",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#la-crisi-della-riprodicibilità-dei-risultati-della-ricerca",
    "title": "65  Limiti dell’inferenza frequentista",
    "section": "65.6 La crisi della riprodicibilità dei risultati della ricerca",
    "text": "65.6 La crisi della riprodicibilità dei risultati della ricerca\nNegli ultimi anni, la mancanza di replicabilità dei risultati della ricerca - inclusa la ricerca psicologica - è diventata un tema di grande rilevanza. In questo contesto, è stato evidenziato che alcuni aspetti del metodo scientifico, in particolare il concetto di valore-p e la pratica di verificare la significatività dell’ipotesi nulla (NHST, Null Hypothesis Significance Testing), potrebbero contribuire a questa “crisi della ricerca scientifica”. Un’analisi più approfondita di questo problema è stata fornita da Gelman (2016), il quale sostiene che la pratica della NHST sia intrinsecamente problematica. Infatti, essa incoraggia il ricercatore a cercare di rigettare un’ipotesi “fantoccio” (straw-man) che è certamente falsa a priori o, almeno, poco interessante dal punto di vista scientifico, a favore di un’ipotesi alternativa che il ricercatore preferisce. In generale, sembra più ragionevole affermare che la differenza tra due condizioni sia molto piccola, piuttosto che affermare che sia esattamente uguale a zero.\nSpesso nei libri di statistica viene trasmesso il messaggio che la NHST sia una forma di “alchimia” che cerca di trasformare la casualità in una sorta di certezza, con l’uso di termini come “confidenza” e “significatività” Gelman (2016). Il processo di raccolta dei dati, analisi e inferenza statistica che ne segue viene poi riassunto in una conclusione espressa in termini di valore-p e di intervallo di confidenza che escludono lo zero. Tuttavia, ciò può dare l’impressione errata che il ricercatore abbia una comprensione completa delle proprietà del fenomeno in questione. Il problema principale della NHST è che spesso produce risultati “statisticamente significativi” in situazioni in cui le caratteristiche del fenomeno non giustificano la conclusione a cui il ricercatore arriva. Questo può portare alla non replicabilità dei risultati della ricerca.\nLa comunità degli statistici ha evidenziato come la non replicabilità dei risultati delle ricerche sia particolarmente evidente quando i ricercatori, utilizzando la metodologia NHST, giungono a conclusioni errate basate sull’osservazione di piccoli campioni con effetti di dimensioni ridotte. Queste condizioni, insieme ad altre, rendono estremamente problematica l’applicazione della NHST. Purtroppo, queste situazioni descrivono molte delle ricerche recenti in psicologia.\nLa statistica è stata definita come un metodo per prendere decisioni razionali in situazioni di incertezza. Gli statistici consigliano ai ricercatori di non solo diventare esperti nelle tecniche statistiche, ma anche di imparare a convivere con l’incertezza, nonostante la sempre crescente sofisticazione delle tecniche disponibili. Convivere con l’incertezza implica evitare di pensare che ottenere un valore-\\(p\\) “statisticamente significativo” significhi risolvere un problema scientifico. Come possiamo allora avere fiducia in ciò che abbiamo appreso dai dati? Una possibile strategia è la replicazione e la convalida esterna, ma nella ricerca in psicologia e nelle scienze sociali, questo può spesso essere difficile da perseguire a causa degli oneri elevati che comporta. Il problema di quali strumenti metodologici e metodi statistici siano più appropriati per indagare sui fenomeni psicologici, senza essere ingannati, rimane dunque un problema aperto.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#commenti-e-considerazioni-finali",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#commenti-e-considerazioni-finali",
    "title": "65  Limiti dell’inferenza frequentista",
    "section": "65.7 Commenti e considerazioni finali",
    "text": "65.7 Commenti e considerazioni finali\nNon possiamo concludere senza sottolineare la controversia che circonda la nozione di valore-\\(p\\). Pur essendo ancora ampiamente utilizzato e spesso interpretato erroneamente, il valore-\\(p\\) conferisce solo una patina di legittimità ai risultati di studi dubbi, incoraggia cattive pratiche di ricerca e promuove la produzione di falsi positivi. Inoltre, è difficile comprendere appieno il significato di questa nozione. Anche gli esperti, quando chiamati a fornire una definizione di valore-\\(p\\), spesso sbagliano la risposta. Ciò che i ricercatori vogliono sapere è se i risultati della ricerca sono corretti o meno, ma il valore-\\(p\\) non fornisce questa informazione. Non dice nulla sulla dimensione dell’effetto, sulla forza dell’evidenza o sulla probabilità che il risultato sia stato ottenuto casualmente. Quindi, qual è il suo significato? Stuart Buck risponde così:\n\nImagine that you have a coin that you suspect is weighted toward heads. (Your null hypothesis is then that the coin is fair.) You flip it 100 times and get more heads than tails. The \\(p\\)-value won’t tell you whether the coin is fair, but it will tell you the probability that you’d get at least as many heads as you did if the coin was fair. That’s it – nothing more.\n\nIn sintesi, possiamo concludere che il valore-\\(p\\) risponde a una domanda molto specifica che non ha alcuna rilevanza per la validità scientifica dei risultati della ricerca. In un’epoca in cui la crisi della riproducibilità dei risultati è sempre più evidente Baker (2016), il test dell’ipotesi nulla e gli intervalli di confidenza frequentisti sono stati identificati come una delle principali cause del problema, spingendo molti ricercatori a cercare soluzioni alternative.\n\n\n\n\nBaker, M. (2016). Reproducibility Crisis. Nature, 533(7604), 452–454.\n\n\nBorel, E. (1914). Introduction Géométrique. G. Villars, New York.\n\n\nGelman, A. (2016). Commentary on «Crisis in Science? Or Crisis in Statistics! Mixed Messages in Statistics with Impact on Science». Journal of Statistical Research, 48-50(1), 11–12.\n\n\nGoligher, E. C., Heath, A., & Harhay, M. O. (2024). Bayesian statistics for clinical research. The Lancet, 404(10457), 1067–1076. https://doi.org/10.1016/S0140-6736(24)00055-9\n\n\nNuzzo, R. (2014). Statistical Errors. Nature, 506(7487), 150–152.\n\n\nWasserstein, R. L., & Lazar, N. A. (2016). The ASA’s statement on p-values: context, process, and purpose. The American Statistician, 70(2), 129–133.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html",
    "href": "chapters/replication_crisis/06_changes.html",
    "title": "66  Riforma",
    "section": "",
    "text": "66.1 Introduzione\nLa crisi della riproducibilità ha portato a una profonda riflessione sullo stato della ricerca nelle scienze comportamentali, cognitive e sociali. La scoperta che molti studi pubblicati non erano replicabili ha scosso la fiducia nella ricerca scientifica e ha messo in evidenza le carenze metodologiche e strutturali che affliggono il sistema accademico. Di fronte a questa crisi, sono state avanzate diverse proposte di riforma volte a migliorare la qualità e l’affidabilità della ricerca scientifica.\nSecondo Korbmacher et al. (2023) sono neccessarie riforme strutturali, cambiamenti procedurali e cambiamenti nella comunità scientifica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#riforme-strutturali",
    "href": "chapters/replication_crisis/06_changes.html#riforme-strutturali",
    "title": "66  Riforma",
    "section": "66.2 Riforme Strutturali",
    "text": "66.2 Riforme Strutturali\n\n66.2.1 Integrazione della Riproducibilità nei Curriculum Educativi\nUna delle principali proposte per affrontare la crisi della riproducibilità è l’integrazione delle pratiche di riproducibilità nei curriculum educativi delle scienze psicologiche e affini. Attualmente, molti programmi di formazione non pongono sufficiente enfasi sull’importanza della replicabilità e della trasparenza nella ricerca. Incorporare queste tematiche nei corsi di metodologia della ricerca può sensibilizzare le nuove generazioni di ricercatori alla necessità di adottare pratiche più rigorose e trasparenti. Ad esempio, alcuni programmi universitari hanno iniziato a includere repliche di studi famosi come parte del percorso formativo degli studenti, offrendo loro l’opportunità di comprendere meglio i limiti e le potenzialità del processo scientifico.\n\n\n66.2.2 Incentivi per la Scienza Aperta\nOltre alla formazione, un altro aspetto cruciale è la riforma dei sistemi di incentivazione accademica. Tradizionalmente, il sistema accademico ha privilegiato la quantità di pubblicazioni e la novità dei risultati, piuttosto che la loro qualità e replicabilità. Per promuovere pratiche di scienza aperta, come la preregistrazione degli studi e la condivisione aperta dei dati, si propone l’introduzione di riconoscimenti ufficiali, come badge di “open science” o crediti accademici per la pubblicazione di rapporti registrati. Questi cambiamenti potrebbero favorire una maggiore adozione di pratiche che promuovono la trasparenza e rafforzano la fiducia nella ricerca scientifica.\nA tal proposito, è interessante considerare uno studio di Scheel et al. (2021). Gli autori hanno confrontato i risultati di rapporti registrati pubblicati (N = 71) con un campione casuale di studi ipotetico-deduttivi della letteratura standard (N = 152) in psicologia. Analizzando la prima ipotesi di ciascun articolo, hanno riscontrato che il 96% dei risultati nei rapporti standard erano positivi, contro solo il 44% nei rapporti registrati.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#cambiamenti-procedurali",
    "href": "chapters/replication_crisis/06_changes.html#cambiamenti-procedurali",
    "title": "66  Riforma",
    "section": "66.3 Cambiamenti Procedurali",
    "text": "66.3 Cambiamenti Procedurali\n\n66.3.1 Mercati di Previsione per la Credibilità della Ricerca\nI mercati di previsione sono stati proposti come uno strumento innovativo per valutare la credibilità della ricerca. In questi mercati, esperti e non esperti scommettono sulla probabilità che i risultati di determinati studi siano replicabili. Questo approccio ha dimostrato di avere un’elevata accuratezza nella classificazione della replicabilità degli studi, offrendo un metodo alternativo e complementare alla replicazione diretta. I mercati di previsione potrebbero essere particolarmente utili in contesti in cui la raccolta dati è costosa o difficile da realizzare, fornendo una prima indicazione sulla solidità dei risultati di ricerca.\n\n\n66.3.2 Strumenti di Valutazione Statistica\nUn’altra proposta riguarda l’adozione di nuovi strumenti di valutazione statistica per identificare e correggere il bias di pubblicazione e migliorare la potenza degli studi. Strumenti come la curva-p e la curva-z sono stati sviluppati per analizzare la distribuzione dei valori p e identificare eventuali distorsioni nei risultati pubblicati. Inoltre, alcuni studiosi hanno suggerito di abbassare il livello di significatività statistica standard da 0,05 a 0,005 per ridurre il tasso di falsi positivi e aumentare la robustezza dei risultati. Queste proposte, sebbene non risolutive, rappresentano passi importanti verso una maggiore precisione nelle analisi statistiche.\n\n\n66.3.3 Analisi Multiverso\nL’analisi multiverso è un’altra proposta innovativa che mira a gestire la molteplicità di scelte analitiche possibili in un singolo studio. Questa tecnica prevede l’esecuzione di molteplici analisi su uno stesso dataset, variando i parametri e le scelte metodologiche, per testare la stabilità dei risultati. L’adozione di questo approccio permette di evidenziare quanto i risultati siano sensibili alle scelte analitiche, contribuendo a una maggiore trasparenza e affidabilità nelle conclusioni tratte dagli studi.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#cambiamenti-nella-comunità",
    "href": "chapters/replication_crisis/06_changes.html#cambiamenti-nella-comunità",
    "title": "66  Riforma",
    "section": "66.4 Cambiamenti nella Comunità",
    "text": "66.4 Cambiamenti nella Comunità\n\n66.4.1 Big Team Science\nIl concetto di “Big Team Science” rappresenta un cambiamento significativo nella modalità di condurre ricerca. Questo approccio prevede la collaborazione su larga scala tra scienziati di diversi paesi e discipline, con l’obiettivo di replicare studi, raccogliere grandi campioni e condividere risorse. Questo modello di lavoro collettivo non solo aumenta l’efficienza della ricerca, ma promuove anche una maggiore diversità nei campioni e nei team di ricerca. Tuttavia, esistono anche criticità, come la possibilità di perpetuare disuguaglianze tra ricercatori di paesi sviluppati e in via di sviluppo, e la difficoltà nel riconoscere adeguatamente i contributi individuali all’interno di grandi consorzi.\n\n\n66.4.2 Collaborazioni Avversariali\nLe collaborazioni avversariali rappresentano un altro approccio interessante per migliorare la qualità della ricerca. In queste collaborazioni, ricercatori con visioni teoriche contrastanti lavorano insieme per progettare e condurre studi che testino le loro ipotesi in modo rigoroso. Questo tipo di collaborazione può ridurre i bias personali e promuovere un confronto costruttivo, portando a conclusioni più solide e condivise all’interno della comunità scientifica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#crisi-della-generalizzabilità",
    "href": "chapters/replication_crisis/06_changes.html#crisi-della-generalizzabilità",
    "title": "66  Riforma",
    "section": "66.5 Crisi della generalizzabilità",
    "text": "66.5 Crisi della generalizzabilità\nYarkoni (2022) affronta la questione critica della scarsa validità delle inferenze quantitative presenti nella letteratura psicologica pubblicata proponendo tre strategie principali che, se adottate, potrebbero migliorare significativamente la qualità della ricerca in psicologia.\n\n66.5.1 Do Something Else\nIl primo suggerimento dell’autore è quello di considerare la possibilità di abbandonare la ricerca psicologica quantitativa laddove risulti troppo difficile estrarre conclusioni significative e generalizzabili da effetti complessi e variabili. L’autore critica la tendenza nella psicologia (e in altre discipline) di concludere ogni contributo di ricerca con una nota positiva o “costruttiva”, indipendentemente dalla realtà delle evidenze raccolte. Secondo l’autore, non è realistico pensare che ogni domanda di ricerca meriti una risposta empirica, soprattutto quando le risorse necessarie per ottenere risultati minimamente informativi superano di gran lunga gli standard convenzionali. In queste circostanze, potrebbe essere più saggio riconoscere i limiti della ricerca e, in alcuni casi, scegliere percorsi di carriera alternativi, specialmente per i ricercatori alle prime armi, che potrebbero trovare prospettive di carriera migliori al di fuori dell’accademia.\n\n\n66.5.2 Abbracciare l’Analisi Qualitativa\nLa seconda opzione proposta è continuare a fare ricerca psicologica, ma abbandonando in gran parte i metodi statistici inferenziali a favore di metodi qualitativi. L’autore sostiene che gran parte di ciò che attualmente passa per scienza quantitativa in psicologia sia in realtà un’analisi qualitativa mascherata. Alcune teorie psicologiche, secondo l’autore, non traggono beneficio da un’analisi quantitativa poiché sono o troppo vaghe o troppo ovvie per essere falsificabili attraverso procedure statistiche. L’autore suggerisce che in molti casi l’analisi qualitativa potrebbe fornire risposte più profonde e significative rispetto a un approccio quantitativo superficiale, evitando così l’illusione di una precisione scientifica inesistente.\nIn un approccio qualitativo, i ricercatori potrebbero concentrarsi sulla descrizione e sull’esplorazione delle relazioni tra variabili senza cercare di trarre conclusioni causali definitive. L’autore menziona l’esempio della rivista Basic and Applied Social Psychology, che ha bandito l’uso dei p-value, come un esempio di come l’abbandono della statistica inferenziale possa essere gestito in modo costruttivo. Sebbene questa mossa sia stata accolta con scetticismo, l’autore suggerisce che, se affrontata correttamente, potrebbe essere un passo positivo verso una maggiore integrità nella ricerca psicologica.\n\n\n66.5.3 Adottare Standard Migliori\nLa terza e ultima strategia consiste nel migliorare gli standard della ricerca quantitativa in psicologia per renderla più rigorosa e affidabile. L’autore propone diverse pratiche che, se implementate, potrebbero migliorare la qualità e la validità delle inferenze psicologiche:\n\nInferenze più conservative: I ricercatori dovrebbero evitare di fare generalizzazioni ampie basate su dati limitati e dovrebbero esplicitamente indicare quando stanno speculando al di là dei dati disponibili. La formulazione di titoli di articoli e affermazioni dovrebbe riflettere in modo più accurato la portata dei risultati ottenuti.\nRicerca descrittiva: L’autore esorta a prendere più seriamente la ricerca descrittiva, che si concentra sulla caratterizzazione delle relazioni tra variabili senza ricorrere a spiegazioni causali. Questo tipo di ricerca può fornire un’importante base empirica che è spesso trascurata a favore di teorie semplificate e sovrastimate.\nModelli statistici più espansivi: I ricercatori dovrebbero abituarsi a utilizzare modelli statistici che considerino una più ampia gamma di variabili e fattori, oltre a includere effetti random per elementi come stimoli, compiti e siti di ricerca. Questo approccio richiede l’uso di modelli misti che permettano di gestire la complessità della realtà psicologica in modo più adeguato.\nProgettare con la variazione in mente: Yarkoni (2022) sostiene l’importanza di progettare studi che abbraccino la variabilità naturale delle condizioni sperimentali, piuttosto che cercare di controllare rigidamente ogni variabile. Questo approccio, sebbene più costoso in termini di risorse, permetterebbe di ottenere risultati più generalizzabili e utili.\nStime della varianza: Un maggiore enfasi dovrebbe essere posta sull’analisi dele componenti della varianza piuttosto che sulle stime puntuali. Questo permetterebbe di comprendere meglio l’importanza relativa delle diverse fonti di variazione nei dati e di pianificare studi futuri in modo più informato.\nPredizioni più rischiose: Yarkoni (2022) incoraggia i ricercatori a formulare predizioni teoriche che comportino un alto grado di rischio. Predizioni più precise e rischiose ridurrebbero le preoccupazioni sulla generalizzabilità, poiché solo modelli teorici accurati sarebbero in grado di fare previsioni con tale precisione.\nUtilità predittiva pratica: Infine, Yarkoni (2022) suggerisce un approccio più pragmatico che si concentri sull’utilità pratica delle predizioni piuttosto che su considerazione puramente teoriche. Invece di chiedersi se un fenomeno esiste, dovremmo chiederci se possiamo costruire modelli che predicano efficacemente comportamenti rilevanti in situazioni specifiche.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#sviluppare-teorie-formali",
    "href": "chapters/replication_crisis/06_changes.html#sviluppare-teorie-formali",
    "title": "66  Riforma",
    "section": "66.6 Sviluppare teorie formali",
    "text": "66.6 Sviluppare teorie formali\nOltre alle carenze metodologiche o statistiche, è stato spesso sottolineato che la crisi di replicabilità che affligge le scienze psicologiche trova le sue radici nella mancanza di un quadro teorico cumulativo. Senza un quadro teorico generale che generi ipotesi in diversi ambiti, i programmi empirici si sviluppano a partire da intuizioni personali e teorie popolari influenzate culturalmente. Fornendo strumenti per formulare previsioni chiare, anche attraverso l’uso di modelli formali, i quadri teorici stabiliscono aspettative che permettono di determinare se un nuovo risultato conferma le ricerche esistenti, integrandosi con esse, oppure se è inaspettato e, pertanto, richiede ulteriori verifiche e approfondimenti (Muthukrishna & Henrich, 2019).",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#riflessioni-conclusive",
    "href": "chapters/replication_crisis/06_changes.html#riflessioni-conclusive",
    "title": "66  Riforma",
    "section": "66.7 Riflessioni Conclusive",
    "text": "66.7 Riflessioni Conclusive\nL’ampio utilizzo dei test statistici frequentisti in psicologia risulta spesso fuorviante, poiché attribuisce un’apparenza di rigore scientifico a inferenze che, in realtà, sono principalmente qualitative. Si rende quindi necessaria una profonda riforma delle pratiche di ricerca, volta a promuovere una maggiore trasparenza e precisione, oltre a incoraggiare la disponibilità a mettere in discussione e abbandonare approcci metodologici che non superano una rigorosa analisi critica (Yarkoni, 2022).\nLa crisi di replicabilità ha spinto verso una serie di riforme con il potenziale di trasformare positivamente la ricerca psicologica. Tra queste iniziative vi sono la promozione della scienza aperta, l’adozione di standard metodologici più rigorosi e una maggiore attenzione a pratiche di ricerca che privilegiano la qualità e la replicabilità dei risultati rispetto alla loro quantità e novità. Sebbene questi cambiamenti possano sembrare meno spettacolari rispetto ai metodi attualmente utilizzati, essi rappresentano un percorso fondamentale per garantire la credibilità e la sostenibilità a lungo termine della disciplina.\nAffinché queste riforme abbiano un impatto duraturo, è essenziale un cambiamento strutturale a tutti i livelli della comunità scientifica:\n\nI ricercatori devono impegnarsi ad adottare pratiche più rigorose e trasparenti, privilegiando la solidità metodologica e la replicabilità dei loro studi.\nGli enti finanziatori devono incentivare la qualità e la replicabilità degli studi, piuttosto che premiare esclusivamente la produzione di risultati innovativi o appariscenti.\nLe istituzioni accademiche devono rivedere i criteri di valutazione del merito scientifico, dando maggior peso all’impatto a lungo termine delle ricerche e alla loro solidità metodologica.\nLe riviste scientifiche devono assicurarsi che i risultati pubblicati siano realmente robusti e generalizzabili, anziché limitarsi a privilegiare i risultati nuovi o sorprendenti.\n\nQuesti cambiamenti, sebbene complessi e talvolta impopolari, sono fondamentali per ristabilire la fiducia nel processo scientifico e per garantire che la ricerca psicologica continui a offrire contributi utili e affidabili nella comprensione della mente umana e del comportamento.\nIn conclusione, la sfida posta dalla crisi di replicabilità offre un’opportunità unica per ridefinire e rafforzare le fondamenta metodologiche della ricerca psicologica. Abbracciando questi cambiamenti, la psicologia può emergere come una disciplina più robusta, trasparente e affidabile, capace di fornire intuizioni utili e durature sul funzionamento della mente e del comportamento umano.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#bibliografia",
    "href": "chapters/replication_crisis/06_changes.html#bibliografia",
    "title": "66  Riforma",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nKorbmacher, M., Azevedo, F., Pennington, C. R., Hartmann, H., Pownall, M., Schmidt, K., Elsherif, M., Breznau, N., Robertson, O., Kalandadze, T., et al. (2023). The replication crisis has led to positive structural, procedural, and community changes. Communications Psychology, 1(1), 3.\n\n\nMuthukrishna, M., & Henrich, J. (2019). A problem in theory. Nature Human Behaviour, 3(3), 221–229.\n\n\nScheel, A. M., Schijen, M. R., & Lakens, D. (2021). An excess of positive results: Comparing the standard psychology literature with registered reports. Advances in Methods and Practices in Psychological Science, 4(2), 25152459211007467.\n\n\nYarkoni, T. (2022). The generalizability crisis. Behavioral and Brain Sciences, 45, e1.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Riforma</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_integrity.html",
    "href": "chapters/replication_crisis/07_integrity.html",
    "title": "67  Integrità della ricerca",
    "section": "",
    "text": "67.1 Introduzione\nL’integrità della ricerca si basa su principi e standard professionali che mirano a garantire l’affidabilità e la qualità della ricerca, distinguendosi dall’etica della ricerca, che si focalizza su principi morali. La condivisione dei dati, il consenso informato, e la trasparenza nelle pratiche di ricerca sono elementi chiave. I codici di condotta sono essenziali per orientare i comportamenti etici, tanto dei ricercatori quanto delle istituzioni. Le pratiche di ricerca discutibili, la fabbricazione e falsificazione dei dati, il plagio, e la gestione dei conflitti di interesse sono sfide da affrontare per mantenere l’integrità della ricerca. È fondamentale promuovere una cultura di ricerca che privilegi l’onestà, la trasparenza e il rispetto dei principi etici.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Integrità della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_integrity.html#standard-professionali-nei-codici-di-condotta-per-lintegrità-della-ricerca",
    "href": "chapters/replication_crisis/07_integrity.html#standard-professionali-nei-codici-di-condotta-per-lintegrità-della-ricerca",
    "title": "67  Integrità della ricerca",
    "section": "67.2 Standard Professionali nei Codici di Condotta per l’Integrità della Ricerca",
    "text": "67.2 Standard Professionali nei Codici di Condotta per l’Integrità della Ricerca\nNel campo della ricerca, è essenziale aderire a principi di condotta responsabile. Questi principi, comunemente definiti come buone pratiche di ricerca, stabiliscono gli standard professionali che mirano a ottimizzare qualità e affidabilità degli studi condotti. Se è vero che le idee di base su cosa costituisca una buona pratica di ricerca rimangono relativamente stabili nel tempo, la loro applicazione pratica si evolve in risposta ai cambiamenti sociali, politici e tecnologici. Un esempio lampante di questo adattamento è la crescente enfasi sulla condivisione dei dati di ricerca, facilitata oggi dall’esistenza di repository online gratuiti, che ha portato a un’aspettativa diffusa di massima trasparenza e accessibilità dei dati raccolti. Molto incoraggiata è anche la “buona pratica” corrispondente alla condivisione del codice utilizzato dai ricercatori per analizzare i dati raccolti.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Integrità della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_integrity.html#differenziazione-tra-integrità-e-etica-della-ricerca",
    "href": "chapters/replication_crisis/07_integrity.html#differenziazione-tra-integrità-e-etica-della-ricerca",
    "title": "67  Integrità della ricerca",
    "section": "67.3 Differenziazione tra Integrità e Etica della Ricerca",
    "text": "67.3 Differenziazione tra Integrità e Etica della Ricerca\nL’integrità della ricerca si fonda su standard professionali e si distingue nettamente dall’etica della ricerca, che si basa su principi morali quali l’autonomia, la beneficenza, la non-maleficenza e la giustizia. Questi ultimi si traducono in pratiche specifiche, come il consenso informato e la garanzia di verità e confidenzialità nei confronti dei partecipanti. L’adozione di tali principi etici implica l’obbligo per i ricercatori di evitare studi che possano arrecare danno o risultare eccessivamente onerosi per i soggetti coinvolti.\nI codici di condotta per l’integrità della ricerca variano leggermente tra le diverse fonti. Ad esempio, Il codice di condotta europeo per l’integrità della ricerca enfatizza l’importanza di principi come l’onestà, la trasparenza, l’accuratezza, la responsabilità, l’affidabilità, il rispetto e l’indipendenza. Questi principi sono interpretati in termini di comportamenti specifici attesi sia dai ricercatori sia dalle istituzioni di ricerca, come la condivisione dei dati di ricerca nel rispetto delle normative sulla protezione dei dati, come il GDPR europeo.\nUn esempio pratico della variazione degli standard nei codici di condotta è rappresentato dall’evoluzione della condivisione dei dati di ricerca. In precedenza, la condivisione dei dati poteva essere limitata dalla mancanza di infrastrutture adeguate. Oggi, l’accesso facilitato attraverso i repository online e la pressione esercitata dalle riviste scientifiche e dai finanziatori della ricerca hanno reso la condivisione dei dati una pratica standard, riflettendo un cambiamento verso una maggiore apertura e trasparenza nella ricerca.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Integrità della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_integrity.html#pressioni-e-sfide-nelladesione-ai-codici-di-condotta",
    "href": "chapters/replication_crisis/07_integrity.html#pressioni-e-sfide-nelladesione-ai-codici-di-condotta",
    "title": "67  Integrità della ricerca",
    "section": "67.4 Pressioni e Sfide nell’Adesione ai Codici di Condotta",
    "text": "67.4 Pressioni e Sfide nell’Adesione ai Codici di Condotta\nNonostante l’esistenza di questi codici, i ricercatori, specialmente quelli in fase iniziale della loro carriera, possono trovarsi sotto pressione da parte dei supervisori per adottare comportamenti che si discostano dagli standard stabiliti, spesso a causa della competitività nel campo scientifico e del sistema di valutazione basato sul numero di pubblicazioni. Queste dinamiche possono indurre a pratiche di ricerca discutibili (PRD), che includono la pubblicazione selettiva dei risultati e l’uso di analisi dei dati flessibili per aumentare artificialmente la probabilità di ottenere risultati statisticamente significativi.\nPer mantenere l’integrità della ricerca, è fondamentale creare un ambiente di lavoro che valorizzi l’apertura, l’inclusività e la discussione franca delle pressioni e delle sfide etiche. Questo implica non solo l’adesione ai codici di condotta esistenti ma anche l’impegno attivo delle istituzioni di ricerca nel promuovere la formazione etica e l’integrità tra i ricercatori. Attraverso un tale approccio, la comunità scientifica può aspirare a una ricerca di alta qualità che sia sia eticamente responsabile sia metodologicamente solida.\nÈ degno di nota che Nature, una delle riviste scientifiche più prestigiose al mondo, abbia recentemente promosso il gioco da tavolo Publish or Perish. La descrizione del gioco è particolarmente provocatoria:\n\n“Falsificare dati, screditare altri scienziati, pubblicare una montagna di articoli che ricevono una torre di citazioni: i cinici potrebbero descrivere questi come passi necessari per raggiungere il successo accademico.”\n\nQuesta mossa solleva importanti questioni sullo stato attuale della ricerca scientifica. Non solo il mondo accademico sembra fornire inventivi distorti, ma anche il sistema economico delle riviste scientifiche presenta una componente di monetizzazione che appare in conflitto con gli obiettivi fondamentali della ricerca scientifica. Questo porta all’accettazione di pratiche disoneste, perché funzionali allo status quo.\nIn questo panorama complesso, emergono voci di dissenso che auspicano e si impegnano per una riforma del mondo pragmatico della scienza (McElreath, 2020; Smaldino & McElreath, 2016). Questa situazione invita a una riflessione profonda sulla necessità di bilanciare la produttività accademica con l’etica e la qualità della ricerca, nonché sul ruolo delle riviste scientifiche nel plasmare il panorama della ricerca contemporanea.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Integrità della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_integrity.html#bibliografia",
    "href": "chapters/replication_crisis/07_integrity.html#bibliografia",
    "title": "67  Integrità della ricerca",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nSmaldino, P. E., & McElreath, R. (2016). The natural selection of bad science. Royal Society open science, 3(9), 160384.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Integrità della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html",
    "href": "chapters/epiloque/epiloque.html",
    "title": "Considerazioni Conclusive",
    "section": "",
    "text": "Limiti dell’Inferenza Frequentista\nL’inferenza bayesiana offre un modo rigoroso e trasparente per integrare conoscenze pregresse e dati empirici nell’analisi psicologica. A differenza degli approcci frequentisti, l’approccio bayesiano ci permette di quantificare l’incertezza e di costruire modelli che riflettono le nostre aspettative a priori. Questa flessibilità è particolarmente utile in psicologia, dove le teorie e le ipotesi giocano un ruolo fondamentale nella guida della ricerca. L’approccio bayesiano rende esplicita la nostra assunzione iniziale e ci permette di valutare l’impatto dei dati sulla nostra comprensione dei fenomeni psicologici.\nNel corso di questa trattazione, abbiamo esaminato i limiti dell’inferenza frequentista, in particolare quando viene impiegata come “filtro” per distinguere i risultati scientifici rilevanti da quelli trascurabili. L’eccessiva dipendenza dai valori-p è stata oggetto di critiche per la sua associazione con inferenze inadeguate; gli effetti possono essere notevolmente sovrastimati, talvolta persino nella direzione errata, quando la stima è vincolata alla significatività statistica in presenza di dati altamente variabili (Loken & Gelman, 2017).\nLa persistenza e la resistenza del valore-p come indicatore di significatività sono sorprendenti, nonostante le critiche di lunga data e i dibattiti sul suo uso improprio e sulla sua errata interpretazione (Gardner e Altman, 1986; Cohen, 1994; Anderson et al., 2000; Fidler et al., 2004; Finch et al., 2004). Il continuo uso di questa tenacia può offrire spunti su come tali indici, insieme alle euristiche utilizzate per interpretarli (ad esempio, l’assegnazione di soglie come 0.05, 0.01 e 0.001 per determinati livelli di significatività), siano adottati dai ricercatori per ottenere una comprensione intuitiva, sebbene eccessivamente semplificata, della struttura dei loro dati. Inoltre, l’uso di un simile indice risulta particolarmente rilevante in contesti che richiedono decisioni e relative giustificazioni (ad esempio, in ambito medico).\nPurtroppo, queste euristiche sono diventate estremamente rigide, e il raggiungimento della significatività si è trasformato in un obiettivo fine a se stesso, piuttosto che in uno strumento per comprendere i dati (Cohen, 1994; Kirk, 1996). Ciò è particolarmente problematico considerando che i valori-p possono essere utilizzati solo per rifiutare l’ipotesi nulla e non per accettarla come vera, poiché un risultato statisticamente non significativo non implica l’assenza di differenze tra gruppi o l’assenza di un effetto di un trattamento (Wagenmakers, 2007; Amrhein et al., 2019).\nI fraintendimenti e l’uso improprio dei valori-p, il cosiddetto “p-hacking” (Simmons et al., 2011), hanno incentivato pratiche scientifiche discutibili, contribuendo in modo rilevante alla crisi di riproducibilità nella scienza psicologica (Chambers et al., 2014; Szucs e Ioannidis, 2016).",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html#la-crisi-della-replicabilità",
    "href": "chapters/epiloque/epiloque.html#la-crisi-della-replicabilità",
    "title": "Considerazioni Conclusive",
    "section": "La Crisi della Replicabilità",
    "text": "La Crisi della Replicabilità\nLa crisi della replicabilità rappresenta una sfida non solo per la ricerca psicologica, ma anche per l’applicazione pratica delle sue teorie. Quando i risultati degli studi non possono essere replicati in contesti diversi, si mette in dubbio la validità e l’affidabilità delle teorie psicologiche su cui si basano gli interventi clinici e le politiche pubbliche. Questo non solo mina la fiducia nella scienza psicologica, ma limita anche la capacità dei professionisti di sviluppare trattamenti efficaci e basati sull’evidenza. Pertanto, è fondamentale che la comunità scientifica adotti pratiche di ricerca rigorose e trasparenti per garantire che le scoperte siano replicabili e applicabili nel mondo reale.",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html#come-uscirne",
    "href": "chapters/epiloque/epiloque.html#come-uscirne",
    "title": "Considerazioni Conclusive",
    "section": "Come uscirne?",
    "text": "Come uscirne?\nL’abbandono dell’inferenza frequentista a favore dei metodi bayesiani, per ragioni quali la maggiore flessibilità, una migliore accuratezza in presenza di dati rumorosi e campioni piccoli, una minore predisposizione agli errori di tipo I, la possibilità di incorporare conoscenze pregresse nell’analisi e la chiarezza e facilità di interpretazione dei risultati (Kruschke, 2010; Kruschke et al., 2012; Etz e Vandekerckhove, 2016; Wagenmakers et al., 2016, 2018; Dienes e Mclatchie, 2018), è una delle strategie proposte per affrontare la crisi della replicabilità nella ricerca psicologica. Tuttavia, sebbene questo cambiamento sia rilevante, non è sufficiente da solo. I problemi più profondi derivano anche da un sistema accademico caratterizzato da incentivi distorti, come la pressione a pubblicare risultati significativi, e dalla riluttanza delle riviste scientifiche a riconoscere e affrontare casi di frode o a ritirare articoli quando necessario.\nUna proposta su cui insiste molto McElreath (2020) è quella di passare da un approccio descrittivo della relazione tra variabili — tipico dei modelli lineari e dei modelli lineari generalizzati — a una prospettiva che miri a descrivere formalmente il meccanismo generatore dei dati sottostante al fenomeno in esame. In questo contesto, il ricercatore dovrebbe formulare ipotesi esplicite sul processo che genera i dati e fornire un test quantitativo di tali ipotesi. Questo approccio porta naturalmente alla pratica del confronto tra modelli, un metodo che abbiamo discusso in diversi capitoli di questo testo. Tale confronto può essere effettuato utilizzando tecniche come la validazione incrociata bayesiana Leave-One-Out (LOO), che permette di valutare la robustezza dei modelli e la loro capacità di generalizzare a nuovi dati. Ma si tengano anche a mente i limiti di tale approccio (Navarro, 2019).\nUn altro approccio attuale per superare la cosiddetta “junk science” (Calin-Jageman & Caldwell, 2014; Gelman & Weakliem, 2009; Jung et al., 2014), che troppo spesso affligge la psicologia e non solo, è la “rivoluzione causale”. Questo movimento si concentra sul tentativo di comprendere e identificare le relazioni causali in contesti naturali, superando l’arbitrarietà e l’artificialità degli esperimenti di laboratorio tradizionali. La “rivoluzione causale” ha molto in comune con l’approccio di McElreath (2020), poiché anche qui si richiede ai ricercatori di formulare ipotesi causali in maniera esplicita e di confrontare modelli alternativi che rappresentano diverse ipotesi sui rapporti causali. Questo approccio non solo migliora la comprensione dei fenomeni studiati, ma aumenta anche la credibilità e la replicabilità dei risultati scientifici.\nQuesti cambiamenti prevedono anche una profonda revisione dei metodi didattici e dei programmi dei corsi, in cui si insegna agli studenti come formulare inferenze basate sui dati empirici raccolti in psicologia. Questo tema è stato approfondito da studiosi come Mine Dogucu [Johnson et al. (2022); dogucu2022current; rosenberg2022making; dogucu2021web]. Come dovrebbe ormai essere evidente al lettore, il presente testo ha accettato questa sfida.",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html#conclusioni",
    "href": "chapters/epiloque/epiloque.html#conclusioni",
    "title": "Considerazioni Conclusive",
    "section": "Conclusioni",
    "text": "Conclusioni\nL’approccio bayesiano rappresenta una risorsa fondamentale per l’analisi dei dati psicologici, offrendo strumenti avanzati per gestire l’incertezza, integrare conoscenze pregresse e adattarsi a modelli complessi. La sua capacità di fornire previsioni robuste e aggiornare continuamente le ipotesi alla luce di nuovi dati lo rende particolarmente adatto per esplorare e comprendere la mente umana e il comportamento in tutte le loro sfaccettature.\nTuttavia, per affrontare la crisi della replicabilità e migliorare la qualità della ricerca scientifica in psicologia, non è sufficiente adottare esclusivamente metodi bayesiani. È essenziale combinare questi metodi con altre pratiche rigorose e principi metodologici solidi. Tra queste pratiche, la formalizzazione dei modelli generativi consente di descrivere chiaramente i processi sottostanti che generano i dati, migliorando la trasparenza e la validità delle inferenze. Inoltre, il confronto rigoroso tra modelli, ad esempio tramite tecniche di validazione incrociata, aiuta a determinare quale modello meglio rappresenta i dati e a evitare interpretazioni errate.\nInfine, l’adozione di una prospettiva causale esplicita è cruciale per identificare correttamente le relazioni di causa-effetto, evitando l’arbitrarietà e l’artificialità degli esperimenti tradizionali. Solo attraverso un approccio integrato, che combini l’inferenza bayesiana con queste pratiche metodologiche avanzate, sarà possibile progredire verso una scienza psicologica più affidabile e riproducibile, capace di fornire una comprensione più profonda e accurata del comportamento umano.",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html#bibliografia",
    "href": "chapters/epiloque/epiloque.html#bibliografia",
    "title": "Considerazioni Conclusive",
    "section": "Bibliografia",
    "text": "Bibliografia\n\n\n\n\nCalin-Jageman, R. J., & Caldwell, T. L. (2014). Replication of the superstition and performance study by Damisch, Stoberock, and Mussweiler (2010). Social Psychology.\n\n\nGelman, A., & Weakliem, D. (2009). Of beauty, sex and power: Too little attention has been paid to the statistical challenges in estimating small effects. American Scientist, 97(4), 310–316.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nJung, K., Shavitt, S., Viswanathan, M., & Hilbe, J. M. (2014). Female hurricanes are deadlier than male hurricanes. Proceedings of the National Academy of Sciences, 111(24), 8782–8787.\n\n\nLoken, E., & Gelman, A. (2017). Measurement Error and the Replication Crisis. Science, 355(6325), 584–585.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nNavarro, D. J. (2019). Between the devil and the deep blue sea: Tensions between scientific judgement and statistical model selection. Computational Brain & Behavior, 2(1), 28–34.",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/appendix/a02_shell.html",
    "href": "chapters/appendix/a02_shell.html",
    "title": "68  La Shell",
    "section": "",
    "text": "68.1 Che cos’è una Shell?\nUna shell è un programma che riceve comandi dall’utente tramite tastiera (o da file) e li passa al sistema operativo per l’esecuzione. Può essere accessibile tramite un terminale (o un emulatore di terminale).",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>La Shell</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a02_shell.html#che-cosè-una-shell",
    "href": "chapters/appendix/a02_shell.html#che-cosè-una-shell",
    "title": "68  La Shell",
    "section": "",
    "text": "68.1.1 Breve Storia della Shell\n\n1971: Ken Thompson di Bell Labs sviluppa la shell per UNIX.\n1977: Stephen Bourne introduce la Bourne shell (sh).\nDopo il 1977: Viene sviluppata la C shell (csh) e tcsh.\nBash: Sviluppata da Brian Fox come sostituto migliorato della Bourne shell.\n1990: Paul Falsted sviluppa Zsh, che diventa la shell predefinita per macOS dal 2019.\n\n\n\n68.1.2 Windows vs macOS/Linux\n\nWindows 10: È possibile utilizzare Bash attivando il Windows Subsystem for Linux. Tuttavia, l’ambiente preferito è solitamente PowerShell.\nmacOS/Linux: Zsh è la shell predefinita in entrambi i sistemi. È consigliabile sfruttare l’applicazione warp per un’esperienza utente moderna e ottimizzata.\n\n\n\n68.1.3 Comandi di Base Unix\n\npwd: Mostra il percorso della directory corrente.\nls: Elenca file e cartelle nella directory corrente.\ncd: Cambia directory. Senza argomenti, ti porta alla directory home.\nmkdir: Crea una nuova directory.\nrmdir: Rimuove una directory vuota.\nImportante: Evitare spazi nei nomi di file e cartelle.\n\n\n68.1.3.1 Gestione File\n\nmv: Rinomina o sposta file (usa \\ o '' per i nomi di file con spazi).\ncp: Copia file o cartelle (usa -r per le cartelle).\nrm: Rimuove file o cartelle (usa -i per confermare prima di eliminare).\n\n\n\n68.1.3.2 Visualizzazione e Manipolazione Contenuti dei File\n\nless / more: Visualizza il contenuto dei file con possibilità di navigazione.\ncat: Mostra l’intero contenuto di un file.\nhead: Mostra le prime righe di un file.\ntail: Mostra le ultime righe di un file.\n\n\n\n\n68.1.4 Comandi di Base PowerShell\nPer adattare i comandi Unix per l’utilizzo in PowerShell di Windows, molti dei comandi rimangono simili grazie alla natura cross-platform di PowerShell e alla sua flessibilità nel gestire sia gli stili di comando Unix che quelli tradizionali di Windows. Ecco come si traducono i comandi:\n\nGet-Location o semplicemente pwd: Mostra il percorso della directory corrente, simile a pwd in Unix.\nGet-ChildItem o semplicemente ls: Elenca file e cartelle nella directory corrente, equivalente a ls in Unix.\nSet-Location o semplicemente cd: Cambia directory. cd senza argomenti ti porta alla directory home in PowerShell con cd ~.\nNew-Item -ItemType Directory -Name 'nomeDirectory': Crea una nuova directory, simile a mkdir in Unix.\nRemove-Item -Path 'nomeDirectory' -Force: Rimuove una directory, anche se non vuota. Equivalente a rmdir in Unix, ma più potente perché può rimuovere anche directory con contenuti utilizzando il parametro -Force.\n\n\n68.1.4.1 Gestione File\n\nMove-Item -Path 'origine' -Destination 'destinazione': Rinomina o sposta file, equivalente a mv in Unix.\nCopy-Item -Path 'origine' -Destination 'destinazione': Copia file o cartelle, simile a cp in Unix. Usa -Recurse per copiare cartelle.\nRemove-Item -Path 'file' -Force: Rimuove file o cartelle, simile a rm in Unix. Usa -Force per rimuovere senza conferme e -Recurse per rimuovere cartelle con contenuti.\n\n\n\n68.1.4.2 Visualizzazione e Manipolazione Contenuti dei File\n\nGet-Content 'file' | More: Visualizza il contenuto dei file con possibilità di navigazione, simile a less/more in Unix.\nGet-Content 'file': Mostra l’intero contenuto di un file, equivalente a cat in Unix.\nGet-Content 'file' -Head &lt;numero&gt;: Mostra le prime righe di un file, simile a head in Unix.\nGet-Content 'file' -Tail &lt;numero&gt;: Mostra le ultime righe di un file, equivalente a tail in Unix.\n\n\n\n\n\n\n\nConsiglio\n\n\n\nÈ cruciale familiarizzarsi con l’utilizzo dei percorsi relativi per semplificare gli spostamenti tra le diverse directory. L’impiego dei percorsi relativi rende il processo di navigazione più intuitivo e meno incline agli errori.\n\nNomi Chiari e Concisi: Evitate di includere spazi nei nomi dei file e delle cartelle. Preferite l’utilizzo di trattini bassi (_) per separare le parole e mantenere una struttura leggibile e facilmente comprensibile.\nEvitare Caratteri Speciali: È importante evitare l’inserimento di caratteri speciali come asterischi (*), dollari ($), slash (/, \\), punti (.), virgole (,), punti e virgole (;), parentesi (()), parentesi quadre ([]), parentesi graffe ({}), ampersand (&), barre verticali (|), punti esclamativi (!), punti interrogativi (?) nei nomi dei file e delle cartelle. Talvolta, anche l’uso del trattino (-) può causare problemi; quindi è consigliabile evitarlo. Questi caratteri possono generare problemi di compatibilità con alcuni sistemi operativi o applicazioni, rendendo più complessa la gestione dei file.\nDifferenziazione tra Maiuscole e Minuscole: Unix distingue tra maiuscole e minuscole (tratta le lettere come oggetti distinti), mentre Windows non lo fa. Per evitare confusioni, è consigliabile adottare una politica conservativa: considerate i nomi che differiscono solo per la case delle lettere come distinti.\n\nSeguendo questi consigli, è possibile ottimizzare notevolmente l’organizzazione e la gestione dei propri file, migliorando l’efficienza del lavoro e riducendo il rischio di errori.\n\n\nCon la pratica, la riga di comando diventa uno strumento molto efficiente. Questa breve guida fornisce le basi per iniziare a esplorare e gestire i file dal terminale, offrendo una base di partenza per ulteriori apprendimenti. La familiarità con la shell è fondamentale nella data science.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>La Shell</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a10_math_symbols.html",
    "href": "chapters/appendix/a10_math_symbols.html",
    "title": "69  Simbologia di base",
    "section": "",
    "text": "Per una scrittura più sintetica possono essere utilizzati alcuni simboli matematici.\n\n\\(\\log(x)\\): il logaritmo naturale di \\(x\\).\nL’operatore logico booleano \\(\\land\\) significa “e” (congiunzione forte) mentre il connettivo di disgiunzione \\(\\lor\\) significa “o” (oppure) (congiunzione debole).\nIl quantificatore esistenziale \\(\\exists\\) vuol dire “esiste almeno un” e indica l’esistenza di almeno una istanza del concetto/oggetto indicato. Il quantificatore esistenziale di unicità \\(\\exists!\\) (“esiste soltanto un”) indica l’esistenza di esattamente una istanza del concetto/oggetto indicato. Il quantificatore esistenziale \\(\\nexists\\) nega l’esistenza del concetto/oggetto indicato.\nIl quantificatore universale \\(\\forall\\) vuol dire “per ogni.”\n\\(\\mathcal{A, S}\\): insiemi.\n\\(x \\in A\\): \\(x\\) è un elemento dell’insieme \\(A\\).\nL’implicazione logica “\\(\\Rightarrow\\)” significa “implica” (se …allora). \\(P \\Rightarrow Q\\) vuol dire che \\(P\\) è condizione sufficiente per la verità di \\(Q\\) e che \\(Q\\) è condizione necessaria per la verità di \\(P\\).\nL’equivalenza matematica “\\(\\iff\\)” significa “se e solo se” e indica una condizione necessaria e sufficiente, o corrispondenza biunivoca.\nIl simbolo \\(\\vert\\) si legge “tale che.”\nIl simbolo \\(\\triangleq\\) (o \\(:=\\)) si legge “uguale per definizione.”\nIl simbolo \\(\\Delta\\) indica la differenza fra due valori della variabile scritta a destra del simbolo.\nIl simbolo \\(\\propto\\) si legge “proporzionale a.”\nIl simbolo \\(\\approx\\) si legge “circa.”\nIl simbolo \\(\\in\\) della teoria degli insiemi vuol dire “appartiene” e indica l’appartenenza di un elemento ad un insieme. Il simbolo \\(\\notin\\) vuol dire “non appartiene.”\nIl simbolo \\(\\subseteq\\) si legge “è un sottoinsieme di” (può coincidere con l’insieme stesso). Il simbolo \\(\\subset\\) si legge “è un sottoinsieme proprio di.”\nIl simbolo \\(\\#\\) indica la cardinalità di un insieme.\nIl simbolo \\(\\cap\\) indica l’intersezione di due insiemi. Il simbolo \\(\\cup\\) indica l’unione di due insiemi.\nIl simbolo \\(\\emptyset\\) indica l’insieme vuoto o evento impossibile.\nIn matematica, \\(\\mbox{argmax}\\) identifica l’insieme dei punti per i quali una data funzione raggiunge il suo massimo. In altre parole, \\(\\mbox{argmax}_x f(x)\\) è l’insieme dei valori di \\(x\\) per i quali \\(f(x)\\) raggiunge il valore più alto.\n\\(a, c, \\alpha, \\gamma\\): scalari.\n\\(\\boldsymbol{x}, \\boldsymbol{y}\\): vettori.\n\\(\\boldsymbol{X}, \\boldsymbol{Y}\\): matrici.\n\\(X \\sim p\\): la variabile casuale \\(X\\) si distribuisce come \\(p\\).\n\\(p(\\cdot)\\): distribuzione di massa o di densità di probabilità.\n\\(p(y \\mid \\boldsymbol{x})\\): la probabilità o densità di \\(y\\) dato \\(\\boldsymbol{x}\\), ovvero \\(p(y = \\boldsymbol{Y} \\mid x = \\boldsymbol{X})\\).\n\\(f(x)\\): una funzione arbitraria di \\(x\\).\n\\(f(\\boldsymbol{X}; \\theta, \\gamma)\\): \\(f\\) è una funzione di \\(\\boldsymbol{X}\\) con parametri \\(\\theta, \\gamma\\). Questa notazione indica che \\(\\boldsymbol{X}\\) sono i dati che vengono passati ad un modello di parametri \\(\\theta, \\gamma\\).\n\\(\\mathcal{N}(\\mu, \\sigma^2)\\): distribuzione gaussiana di media \\(\\mu\\) e varianza \\(sigma^2\\).\n\\(\\mbox{Beta}(\\alpha, \\beta)\\): distribuzione Beta di parametri \\(\\alpha\\) e \\(\\beta\\).\n\\(\\mathcal{U}(a, b)\\): distribuzione uniforme con limite inferiore \\(a\\) e limite superiore \\(b\\).\n\\(\\mbox{Cauchy}(\\alpha, \\beta)\\): distribuzione di Cauchy di parametri \\(\\alpha\\) (posizione: media) e \\(\\beta\\) (scala: radice quadrata della varianza).\n\\(\\mathcal{B}(p)\\): distribuzione di Bernoulli di parametro \\(p\\) (probabilità di successo).\n\\(\\mbox{Bin}(n, p)\\): distribuzione binomiale di parametri \\(n\\) (numero di prove) e \\(p\\) (probabilità di successo).\n\\(\\mathbb{KL} (p \\mid\\mid q)\\): la divergenza di Kullback-Leibler da \\(p\\) a \\(q\\).",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>Simbologia di base</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html",
    "href": "chapters/appendix/a11_numbers.html",
    "title": "70  Numeri e intervalli",
    "section": "",
    "text": "70.1 Numeri binari\nI numeri binari costituiscono la forma più fondamentale di sistema numerico in informatica, essendo composto esclusivamente da due simboli, ovvero 0 e 1. Questo sistema è frequentemente impiegato per rappresentare dualità logiche, come vero/falso o presenza/assenza, in virtù della sua innata semplicità binaria. La sua applicazione è particolarmente efficace nell’elaborazione di dati per generare statistiche sintetiche in modo efficiente e rapido.\nImmaginiamo di porre la seguente domanda a 10 studenti: “Ti piacciono i mirtilli?” Le risposte potrebbero essere le seguenti:\nopinion &lt;- c(TRUE, FALSE, TRUE, TRUE, TRUE, FALSE, TRUE, TRUE, TRUE, FALSE)\nopinion\n\n [1]  TRUE FALSE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE FALSE\nIn questo caso, abbiamo utilizzato i numeri binari 0 e 1 per rappresentare risposte diverse, dove False indica “No” e True indica “Si”. Questa rappresentazione binaria ci consente di ottenere facilmente una panoramica delle preferenze degli studenti riguardo i mirtilli.\nIn Python True equivale a 1 e False a zero. Possiamo dunque calcolare la proporzione di risposte positive nel modo seguente:\nsum(opinion) / length(opinion)\n\n[1] 0.7",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-interi",
    "href": "chapters/appendix/a11_numbers.html#numeri-interi",
    "title": "70  Numeri e intervalli",
    "section": "70.2 Numeri interi",
    "text": "70.2 Numeri interi\nI numeri interi sono numeri privi di decimali e comprendono sia i numeri naturali utilizzati per il conteggio, come 1, 2, …, sia i numeri con il segno, necessari per rappresentare grandezze negative. L’insieme dei numeri naturali è indicato con il simbolo \\(\\mathbb{N}\\). L’insieme numerico dei numeri interi relativi si rappresenta come \\(\\mathbb{Z} = \\{0, \\pm 1, \\pm 2, \\dots \\}\\).",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-razionali",
    "href": "chapters/appendix/a11_numbers.html#numeri-razionali",
    "title": "70  Numeri e intervalli",
    "section": "70.3 Numeri razionali",
    "text": "70.3 Numeri razionali\nI numeri razionali sono numeri frazionari rappresentabili come \\(m/n\\), dove \\(m\\) e \\(n\\) sono numeri interi e \\(n\\) è diverso da zero. Gli elementi dell’insieme dei numeri razionali sono quindi dati da \\(\\mathbb{Q} = \\{\\frac{m}{n} \\,\\vert\\, m, n \\in \\mathbb{Z}, n \\neq 0\\}\\). È importante notare che l’insieme dei numeri naturali è incluso in quello dei numeri interi, che a sua volta è incluso in quello dei numeri razionali, ovvero \\(\\mathbb{N} \\subseteq \\mathbb{Z} \\subseteq \\mathbb{Q}\\). Per rappresentare solo i numeri razionali non negativi, utilizziamo il simbolo \\(\\mathbb{Q^+} = \\{q \\in \\mathbb{Q} \\,\\vert\\, q \\geq 0\\}\\).",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-irrazionali",
    "href": "chapters/appendix/a11_numbers.html#numeri-irrazionali",
    "title": "70  Numeri e intervalli",
    "section": "70.4 Numeri irrazionali",
    "text": "70.4 Numeri irrazionali\nTuttavia, alcune grandezze non possono essere esprimibili come numeri interi o razionali. Questi numeri sono noti come numeri irrazionali e sono rappresentati dall’insieme \\(\\mathbb{R}\\). Essi comprendono numeri illimitati e non periodici, che non possono essere scritti come frazioni. Ad esempio, \\(\\sqrt{2}\\), \\(\\sqrt{3}\\) e \\(\\pi = 3.141592\\ldots\\) sono esempi di numeri irrazionali.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-reali",
    "href": "chapters/appendix/a11_numbers.html#numeri-reali",
    "title": "70  Numeri e intervalli",
    "section": "70.5 Numeri reali",
    "text": "70.5 Numeri reali\nI numeri razionali rappresentano solo una parte dei punti sulla retta \\(r\\). Per rappresentare ogni possibile punto sulla retta, è necessario introdurre i numeri reali. L’insieme dei numeri reali comprende numeri positivi, negativi e nulli, e contiene come casi particolari i numeri interi, razionali e irrazionali. In statistica, il numero di decimali spesso indica il grado di precisione della misurazione.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#intervalli",
    "href": "chapters/appendix/a11_numbers.html#intervalli",
    "title": "70  Numeri e intervalli",
    "section": "70.6 Intervalli",
    "text": "70.6 Intervalli\nQuesto ci porta a esplorare gli intervalli, una struttura matematica che ci aiuta a definire sottoinsiemi specifici sulla retta numerica. Gli intervalli aperti, che escludono i punti di inizio e fine. D’altro canto, gli intervalli chiusi includono sia il punto di inizio che quello di fine, fornendo una copertura di valori senza tralasciare i confini. Le caratteristiche degli intervalli sono riportate nella tabella seguente.\n\n\n\nIntervallo\n\n\n\n\n\n\nchiuso\n\\([a, b]\\)\n\\(a \\leq x \\leq b\\)\n\n\naperto\n\\((a, b)\\)\n\\(a &lt; x &lt; b\\)\n\n\nchiuso a sinistra e aperto a destra\n\\([a, b)\\)\n\\(a \\leq x &lt; b\\)\n\n\naperto a sinistra e chiuso a destra\n\\((a, b]\\)\n\\(a &lt; x \\leq b\\)",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html",
    "href": "chapters/appendix/a12_sum_notation.html",
    "title": "71  Sommatorie",
    "section": "",
    "text": "71.1 Manipolazione di somme\nLe somme si incontrano costantemente in svariati contesti matematici e statistici quindi abbiamo bisogno di una notazione adeguata che ci consenta di gestirle. La somma dei primi \\(n\\) numeri interi può essere scritta come \\(1+2+\\dots+(n-1)+n\\), dove `\\(\\dots\\)’ ci dice di completare la sequenza definita dai termini che vengono prima e dopo. Ovviamente, una notazione come \\(1+7+\\dots+73.6\\) non avrebbe alcun senso senza qualche altro tipo di precisazione. In generale, nel seguito incontreremo delle somme nella forma\n\\[\nx_1+x_2+\\dots+x_n,\n\\]\ndove \\(x_n\\) è un numero che è stato definito altrove. La notazione precedente, che fa uso dei tre puntini di sospensione, è utile in alcuni contesti ma in altri risulta ambigua. Pertanto la notazione di uso corrente è del tipo\n\\[\n\\sum_{i=1}^n x_i\n\\] e si legge “sommatoria per \\(i\\) che va da \\(1\\) a \\(n\\) di \\(x_i\\)”. Il simbolo \\(\\sum\\) (lettera sigma maiuscola dell’alfabeto greco) indica l’operazione di somma, il simbolo \\(x_i\\) indica il generico addendo della sommatoria, le lettere \\(1\\) ed \\(n\\) indicano i cosiddetti estremi della sommatoria, ovvero l’intervallo (da \\(1\\) fino a \\(n\\) estremi inclusi) in cui deve variare l’indice \\(i\\) allorché si sommano gli addendi \\(x_i\\). Solitamente l’estremo inferiore è \\(1\\) ma potrebbe essere qualsiasi altri numero \\(m &lt; n\\). Quindi\n\\[\n\\sum_{i=1}^n x_i = x_1 + x_{2} + \\dots + x_{n}.\n\\]\nPer esempio, se i valori \\(x\\) sono \\(\\{3, 11, 4, 7\\}\\), si avrà\n\\[\n\\sum_{i=1}^4 x_i = 3+11+4+7 = 25\n\\]\nladdove \\(x_1 = 3\\), \\(x_2 = 11\\), eccetera. La quantità \\(x_i\\) nella formula precedente si dice l’argomento della sommatoria, mentre la variabile \\(i\\), che prende i valori naturali successivi indicati nel simbolo, si dice indice della sommatoria.\nLa notazione di sommatoria può anche essere fornita nella forma seguente\n\\[\n\\sum_{P(i)} x_i\n\\]\ndove \\(P(i)\\) è qualsiasi proposizione riguardante \\(i\\) che può essere vera o falsa. Quando è ovvio che si vogliono sommare tutti i valori di \\(n\\) osservazioni, la notazione può essere semplificata nel modo seguente: \\(\\sum_{i} x_i\\) oppure \\(\\sum x_i\\). Al posto di \\(i\\) si possono trovare altre lettere: \\(k, j, l, \\dots\\),.\nÈ conveniente utilizzare le seguenti regole per semplificare i calcoli che coinvolgono l’operatore della sommatoria.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html#manipolazione-di-somme",
    "href": "chapters/appendix/a12_sum_notation.html#manipolazione-di-somme",
    "title": "71  Sommatorie",
    "section": "",
    "text": "71.1.1 Proprietà 1\nLa sommatoria di \\(n\\) valori tutti pari alla stessa costante \\(a\\) è pari a \\(n\\) volte la costante stessa:\n\\[\n\\sum_{i=1}^{n} a = \\underbrace{a + a + \\dots + a} = {n\\text{ volte } a} = n a.\n\\]\n\n\n71.1.2 Proprietà 2 (proprietà distributiva)\nNel caso in cui l’argomento contenga una costante, è possibile riscrivere la sommatoria. Ad esempio con\n\\[\n\\sum_{i=1}^{n} a x_i = a x_1 + a x_2 + \\dots + a x_n\n\\]\nè possibile raccogliere la costante \\(a\\) e fare \\(a(x_1 +x_2 + \\dots + x_n)\\). Quindi possiamo scrivere\n\\[\n\\sum_{i=1}^{n} a x_i = a \\sum_{i=1}^{n} x_i.\n\\]\n\n\n71.1.3 Proprietà 3 (proprietà associativa)\nNel caso in cui\n\\[\n\\sum_{i=1}^{n} (a + x_i) = (a + x_1) + (a + x_1) + \\dots  (a + x_n)\n\\]\nsi ha che\n\\[\n\\sum_{i=1}^{n} (a + x_i) = n a + \\sum_{i=1}^{n} x_i.\n\\]\nÈ dunque chiaro che in generale possiamo scrivere\n\\[\n\\sum_{i=1}^{n} (x_i + y_i) = \\sum_{i=1}^{n} x_i + \\sum_{i=1}^{n} y_i.\n\\]\n\n\n71.1.4 Proprietà 4\nSe deve essere eseguita un’operazione algebrica (innalzamento a potenza, logaritmo, ecc.) sull’argomento della sommatoria, allora tale operazione algebrica deve essere eseguita prima della somma. Per esempio,\n\\[\n\\sum_{i=1}^{n} x_i^2 = x_1^2 + x_2^2 + \\dots + x_n^2 \\neq \\left(\\sum_{i=1}^{n} x_i \\right)^2.\n\\]\n\n\n71.1.5 Proprietà 5\nNel caso si voglia calcolare \\(\\sum_{i=1}^{n} x_i y_i\\), il prodotto tra i punteggi appaiati deve essere eseguito prima e la somma dopo:\n\\[\n\\sum_{i=1}^{n} x_i y_i = x_1 y_1 + x_2 y_2 + \\dots + x_n y_n,\n\\]\ninfatti, \\(a_1 b_1 + a_2 b_2 \\neq (a_1 + a_2)(b_1 + b_2)\\).",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html#doppia-sommatoria",
    "href": "chapters/appendix/a12_sum_notation.html#doppia-sommatoria",
    "title": "71  Sommatorie",
    "section": "71.2 Doppia sommatoria",
    "text": "71.2 Doppia sommatoria\nÈ possibile incontrare la seguente espressione in cui figurano una doppia sommatoria e un doppio indice:\n\\[\n\\sum_{i=1}^{n}\\sum_{j=1}^{m} x_{ij}.\n\\]\nLa doppia sommatoria comporta che per ogni valore dell’indice esterno, \\(i\\) da \\(1\\) ad \\(n\\), occorre sviluppare la seconda sommatoria per \\(j\\) da \\(1\\) ad \\(m\\). Quindi,\n\\[\n\\sum_{i=1}^{3}\\sum_{j=4}^{6} x_{ij} = (x_{1, 4} + x_{1, 5} + x_{1, 6}) + (x_{2, 4} + x_{2, 5} + x_{2, 6}) + (x_{3, 4} + x_{3, 5} + x_{3, 6}).\n\\]\nUn caso particolare interessante di doppia sommatoria è il seguente:\n\\[\n\\sum_{i=1}^{n}\\sum_{j=1}^{n} x_i y_j\n\\]\nSi può osservare che nella sommatoria interna (quella che dipende dall’indice \\(j\\)), la quantità \\(x_i\\) è costante, ovvero non dipende dall’indice (che è \\(j\\)). Allora possiamo estrarre \\(x_i\\) dall’operatore di sommatoria interna e scrivere\n\\[\n\\sum_{i=1}^{n} \\left( x_i \\sum_{j=1}^{n} y_j \\right).\n\\]\nAllo stesso modo si può osservare che nell’argomento della sommatoria esterna la quantità costituita dalla sommatoria in \\(j\\) non dipende dall’indice \\(i\\) e quindi questa quantità può essere estratta dalla sommatoria esterna. Si ottiene quindi\n\\[\n\\sum_{i=1}^{n}\\sum_{j=1}^{n} x_i y_j = \\sum_{i=1}^{n} \\left( x_i \\sum_{j=1}^{n} y_j \\right) = \\sum_{i=1}^{n} x_i \\sum_{j=1}^{n} y_j.\n\\]\nFacciamo un esercizio. Verifichiamo quanto detto sopra nel caso particolare di \\(x = \\{2, 3, 1\\}\\) e \\(y = \\{1, 4, 9\\}\\), svolgendo prima la doppia sommatoria per poi verificare che quanto così ottenuto sia uguale al prodotto delle due sommatorie.\n\\[\n\\begin{align}\n\\sum_{i=1}^3 \\sum_{j=1}^3 x_i y_j &= x_1y_1 + x_1y_2 + x_1y_3 +\nx_2y_1 + x_2y_2 + x_2y_3 +\nx_3y_1 + x_3y_2 + x_3y_3 \\notag\\\\\n&= 2 \\times (1+4+9) + 3 \\times (1+4+9) + 2 \\times (1+4+9) = 84,\\notag\n\\end{align}\n\\]\novvero\n\\[\n(2 + 3 + 1) \\times (1+4+9) = 84.\n\\]",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html",
    "href": "chapters/appendix/a13_sets.html",
    "title": "72  Insiemi",
    "section": "",
    "text": "72.1 Diagrammi di Eulero-Venn\nUn insieme (o collezione, classe, gruppo, …) è stato definito da Georg Cantor nel modo seguente:\nMentre non è rilevante la natura degli oggetti che costituiscono l’insieme, ciò che importa è distinguere se un dato oggetto appartenga o meno ad un insieme. Deve essere vera una delle due possibilità: il dato oggetto è un elemento dell’insieme considerato oppure non è elemento dell’insieme considerato. Due insiemi \\(A\\) e \\(B\\) si dicono uguali se sono formati dagli stessi elementi, anche se disposti in ordine diverso: \\(A=B\\). Due insiemi \\(A\\) e \\(B\\) si dicono diversi se non contengono gli stessi elementi: \\(A \\neq B\\). Ad esempio, i seguenti insiemi sono uguali:\n\\[\n\\{1, 2, 3\\} = \\{3, 1, 2\\} = \\{1, 3, 2\\}= \\{1, 1, 1, 2, 3, 3, 3\\}.\n\\]\nGli insiemi sono denotati da una lettera maiuscola, mentre le lettere minuscole, di solito, designano gli elementi di un insieme. Per esempio, un generico insieme \\(A\\) si indica con\n\\[\nA = \\{a_1, a_2, \\dots, a_n\\}, \\quad \\text{con } n &gt; 0.\n\\]\nLa scrittura \\(a \\in A\\) dice che \\(a\\) è un elemento di \\(A\\). Per dire che \\(b\\) non è un elemento di \\(A\\) si scrive \\(b \\notin A.\\)\nPer quegli insiemi i cui elementi soddisfano una certa proprietà che li caratterizza, tale proprietà può essere usata per descrivere più sinteticamente l’insieme:\n\\[\nA = \\{x ~\\vert~ \\text{proprietà posseduta da } x\\},\n\\]\nche si legge come “\\(A\\) è l’insieme degli elementi \\(x\\) per cui è vera la proprietà indicata.” Per esempio, per indicare l’insieme \\(A\\) delle coppie di numeri reali \\((x,y)\\) che appartengono alla parabola \\(y = x^2 + 1\\) si può scrivere:\n\\[\nA = \\{(x,y) ~\\vert~ y = x^2 + 1\\}.\n\\]\nDati due insiemi \\(A\\) e \\(B\\), diremo che \\(A\\) è un sottoinsieme di \\(B\\) se e solo se tutti gli elementi di \\(A\\) sono anche elementi di \\(B\\):\n\\[\nA \\subseteq B \\iff (\\forall x \\in A \\Rightarrow x \\in B).\n\\]\nSe esiste almeno un elemento di \\(B\\) che non appartiene ad \\(A\\) allora diremo che \\(A\\) è un sottoinsieme proprio di \\(B\\):\n\\[\nA \\subset B \\iff (A \\subseteq B, \\exists~ x \\in B ~\\vert~ x \\notin A).\n\\]\nUn altro insieme, detto insieme delle parti, o insieme potenza, che si associa all’insieme \\(A\\) è l’insieme di tutti i sottoinsiemi di \\(A\\), inclusi l’insieme vuoto e \\(A\\) stesso. Per esempio, per l’insieme \\(A = \\{a, b, c\\}\\), l’insieme delle parti è:\n\\[\n\\mathcal{P}(A) = \\{\n\\emptyset, \\{a\\}, \\{b\\}, \\{c\\},\n\\{a, b\\}, \\{a, c\\}, \\{c, b\\},\n\\{a, b, c\\}\n\\}.\n\\]\nI diagrammi di Venn sono uno strumento grafico molto utile per rappresentare gli insiemi e per verificare le proprietà delle operazioni tra di essi. Questi diagrammi prendono il nome dal matematico inglese del 19° secolo John Venn, anche se rappresentazioni simili erano già state utilizzate in precedenza da Leibniz e Eulero.\nI diagrammi di Venn rappresentano gli insiemi come regioni del piano delimitate da una curva chiusa. Nel caso di insiemi finiti, è possibile evidenziare alcuni elementi di un insieme tramite punti, e in alcuni casi possono essere evidenziati tutti gli elementi degli insiemi considerati.\nIn sostanza, questi diagrammi sono un modo visuale per rappresentare le proprietà degli insiemi e delle operazioni tra di essi. Sono uno strumento molto utile per visualizzare la relazione tra gli insiemi e per capire meglio come si combinano gli elementi all’interno di essi.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#appartenenza-ad-un-insieme",
    "href": "chapters/appendix/a13_sets.html#appartenenza-ad-un-insieme",
    "title": "72  Insiemi",
    "section": "72.2 Appartenenza ad un insieme",
    "text": "72.2 Appartenenza ad un insieme\nUsiamo ora R\n\nSet1 &lt;- c(1, 2)\nprint(Set1)\n\n[1] 1 2\n\nprint(class(Set1))\n\n[1] \"numeric\"\n\n\n\nmy_list &lt;- c(1, 2, 3, 4)\nmy_set_from_list &lt;- unique(my_list)\nprint(my_set_from_list)\n\n[1] 1 2 3 4\n\n\nL’appartenenza ad un insieme si verifica con %in%.\n\nmy_set &lt;- c(1, 3, 5)\nprint(\"Ecco il mio insieme:\")\n\n[1] \"Ecco il mio insieme:\"\n\nprint(my_set)\n\n[1] 1 3 5\n\nprint(\"1 appartiene all'insieme:\")\n\n[1] \"1 appartiene all'insieme:\"\n\nprint(1 %in% my_set)\n\n[1] TRUE\n\nprint(\"2 non appartiene all'insieme:\")\n\n[1] \"2 non appartiene all'insieme:\"\n\nprint(2 %in% my_set)\n\n[1] FALSE\n\nprint(\"4 NON appartiene all'insieme:\")\n\n[1] \"4 NON appartiene all'insieme:\"\n\nprint(!(4 %in% my_set))\n\n[1] TRUE",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#relazioni-tra-insiemi",
    "href": "chapters/appendix/a13_sets.html#relazioni-tra-insiemi",
    "title": "72  Insiemi",
    "section": "72.3 Relazioni tra insiemi",
    "text": "72.3 Relazioni tra insiemi\nEsaminiamo le funzioni Python per descrivere le relazioni tra insiemi. In particolare, dopo avere definito l’insieme universo e l’insieme vuoto, considereremo la relazione di inclusione che conduce al concetto di sottoinsieme. Analogamente si definisce il concetto di sovrainsieme. Mostreremo anche come valutare se due insiemi sono disgiunti (si dicono disgiunti gli insiemi con intersezione vuota).\n\nUniv &lt;- 0:10\nSuper &lt;- Univ[Univ %% 2 == 0]\nDisj &lt;- Univ[Univ %% 2 == 1]\nSub &lt;- c(4, 6)\nNull &lt;- Univ[Univ &gt; 10]\n\n\nprint(\"Insieme Universo (tutti gli interi positivi fino a 10):\")\n\n[1] \"Insieme Universo (tutti gli interi positivi fino a 10):\"\n\nprint(Univ)\n\n [1]  0  1  2  3  4  5  6  7  8  9 10\n\nprint(\"Tutti gli interi positivi pari fino a 10:\")\n\n[1] \"Tutti gli interi positivi pari fino a 10:\"\n\nprint(Super)\n\n[1]  0  2  4  6  8 10\n\nprint(\"Tutti gli interi positivi dispari fino a 10:\")\n\n[1] \"Tutti gli interi positivi dispari fino a 10:\"\n\nprint(Disj)\n\n[1] 1 3 5 7 9\n\nprint(\"Insieme di due elementi, 4 e 6:\")\n\n[1] \"Insieme di due elementi, 4 e 6:\"\n\nprint(Sub)\n\n[1] 4 6\n\nprint(\"Un insieme vuoto:\")\n\n[1] \"Un insieme vuoto:\"\n\nprint(Null)\n\ninteger(0)\n\n\n\nprint('È \"Super\" un sovrainsieme di \"Sub\"?')\n\n[1] \"È \\\"Super\\\" un sovrainsieme di \\\"Sub\\\"?\"\n\nprint(all(Sub %in% Super))\n\n[1] TRUE\n\nprint('È \"Super\" un sottoinsieme di \"Univ\"?')\n\n[1] \"È \\\"Super\\\" un sottoinsieme di \\\"Univ\\\"?\"\n\nprint(all(Super %in% Univ))\n\n[1] TRUE\n\nprint('È \"Sub\" un sovrainsieme di \"Super\"?')\n\n[1] \"È \\\"Sub\\\" un sovrainsieme di \\\"Super\\\"?\"\n\nprint(all(Super %in% Sub))\n\n[1] FALSE\n\nprint('Sono \"Super\" e \"Disj\" insiemi disgiunti?')\n\n[1] \"Sono \\\"Super\\\" e \\\"Disj\\\" insiemi disgiunti?\"\n\nprint(length(intersect(Super, Disj)) == 0)\n\n[1] TRUE",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#operazioni-tra-insiemi",
    "href": "chapters/appendix/a13_sets.html#operazioni-tra-insiemi",
    "title": "72  Insiemi",
    "section": "72.4 Operazioni tra insiemi",
    "text": "72.4 Operazioni tra insiemi\nSi definisce intersezione di \\(A\\) e \\(B\\) l’insieme \\(A \\cap B\\) di tutti gli elementi \\(x\\) che appartengono ad \\(A\\) e contemporaneamente a \\(B\\):\n\\[\nA \\cap B = \\{x ~\\vert~ x \\in A \\land x \\in B\\}.\n\\]\nSi definisce unione di \\(A\\) e \\(B\\) l’insieme \\(A \\cup B\\) di tutti gli elementi \\(x\\) che appartengono ad \\(A\\) o a \\(B\\), cioè\n\\[\nA \\cup B = \\{x ~\\vert~ x \\in A \\lor x \\in B\\}.\n\\]\nDifferenza. Si indica con \\(A \\setminus B\\) l’insieme degli elementi di \\(A\\) che non appartengono a \\(B\\):\n\\[\nA \\setminus B = \\{x ~\\vert~ x \\in A \\land x \\notin B\\}.\n\\]\nInsieme complementare. Nel caso che sia \\(B \\subseteq A\\), l’insieme differenza \\(A \\setminus B\\) è detto insieme complementare di \\(B\\) in \\(A\\) e si indica con \\(B^C\\).\nDato un insieme \\(S\\), una partizione di \\(S\\) è una collezione di sottoinsiemi di \\(S\\), \\(S_1, \\dots, S_k\\), tali che\n\\[\nS = S_1 \\cup S_2 \\cup \\dots S_k\n\\]\ne\n\\[\nS_i \\cap S_j, \\quad \\text{con } i \\neq j.\n\\]\nLa relazione tra unione, intersezione e insieme complementare è data dalle leggi di DeMorgan:\n\\[\n(A \\cup B)^c = A^c \\cap B^c,\n\\]\n\\[\n(A \\cap B)^c = A^c \\cup B^c.\n\\]\nIn tutte le seguenti figure, \\(S\\) è la regione delimitata dal rettangolo, \\(L\\) è la regione all’interno del cerchio di sinistra e \\(R\\) è la regione all’interno del cerchio di destra. La regione evidenziata mostra l’insieme indicato sotto ciascuna figura.\n\n\n\nDiagrammi di Venn\n\n\nI diagrammi di Eulero-Venn che illustrano le leggi di DeMorgan sono forniti nella figura seguente.\n\n\n\nLeggi di DeMorgan\n\n\nVediamo ora come si eseguono le operazioni tra insiemi con R.\nIntersezione.\n\nS1 &lt;- seq(1, 10, by = 3)\nS2 &lt;- 1:6\nS_intersection &lt;- intersect(S1, S2)\nprint(\"Intersezione di S1 e S2:\")\n\n[1] \"Intersezione di S1 e S2:\"\n\nprint(S_intersection)\n\n[1] 1 4\n\n\nUnione. Si noti che il connettivo logico | corrisponde all’unione.\n\nS_union &lt;- union(S1, S2)\nprint(\"Unione di S1 e S2:\")\n\n[1] \"Unione di S1 e S2:\"\n\nprint(S_union)\n\n[1]  1  4  7 10  2  3  5  6\n\n\nInsieme complementare.\n\nS &lt;- seq(0, 20, by = 2)\nS_complement &lt;- setdiff(0:20, S)\nprint(\"S è l'insieme dei numeri interi pari tra 0 e 20:\")\n\n[1] \"S è l'insieme dei numeri interi pari tra 0 e 20:\"\n\nprint(S)\n\n [1]  0  2  4  6  8 10 12 14 16 18 20\n\nprint(\"S_complement è l'insieme dei numeri interi dispari tra 0 e 20:\")\n\n[1] \"S_complement è l'insieme dei numeri interi dispari tra 0 e 20:\"\n\nprint(S_complement)\n\n [1]  1  3  5  7  9 11 13 15 17 19\n\n\n\nprint(\"È l'unione di S e S_complement uguale a tutti i numeri interi tra 0 e 20?\")\n\n[1] \"È l'unione di S e S_complement uguale a tutti i numeri interi tra 0 e 20?\"\n\nprint(setequal(union(S, S_complement), 0:20))\n\n[1] TRUE\n\n\nDifferenza tra insiemi.\n\nS1 &lt;- seq(0, 30, by = 3)\nS2 &lt;- seq(0, 30, by = 5)\nprint(\"Differenza tra S2 e S1:\")\n\n[1] \"Differenza tra S2 e S1:\"\n\nprint(setdiff(S2, S1))\n\n[1]  5 10 20 25\n\nprint(\"Differenza tra S1 e S2:\")\n\n[1] \"Differenza tra S1 e S2:\"\n\nprint(setdiff(S1, S2))\n\n[1]  3  6  9 12 18 21 24 27\n\n\nDifferenza simmetrica. La differenza simmetrica, indicata con il simbolo Δ, è un’operazione insiemistica definita come unione tra la differenza tra il primo e il secondo insieme e la differenza tra il secondo e il primo insieme. In modo equivalente, la differenza simmetrica equivale all’unione tra i due insiemi meno la loro intersezione.\n\nsym_diff &lt;- union(setdiff(S1, S2), setdiff(S2, S1))\nprint(\"Differenza simmetrica:\")\n\n[1] \"Differenza simmetrica:\"\n\nprint(sym_diff)\n\n [1]  3  6  9 12 18 21 24 27  5 10 20 25",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#coppie-ordinate-e-prodotto-cartesiano",
    "href": "chapters/appendix/a13_sets.html#coppie-ordinate-e-prodotto-cartesiano",
    "title": "72  Insiemi",
    "section": "72.5 Coppie ordinate e prodotto cartesiano",
    "text": "72.5 Coppie ordinate e prodotto cartesiano\nUna coppia ordinata \\((x,y)\\) è l’insieme i cui elementi sono \\(x \\in A\\) e \\(y \\in B\\) e nella quale \\(x\\) è la prima componente (o prima coordinata) e \\(y\\) la seconda. L’insieme di tutte le coppie ordinate costruite a partire dagli insiemi \\(A\\) e \\(B\\) viene detto prodotto cartesiano:\n\\[\nA \\times B = \\{(x, y) ~\\vert~ x \\in A \\land y \\in B\\}.\n\\]\nAd esempio, sia \\(A = \\{1, 2, 3\\}\\) e \\(B = \\{a, b\\}\\). Allora,\n\\[\n\\{1, 2\\} \\times \\{a, b, c\\} = \\{(1, a), (1, b), (1, c), (2, a), (2, b), (2, c)\\}.\n\\]\nPiù in generale, un prodotto cartesiano di \\(n\\) insiemi può essere rappresentato da un array di \\(n\\) dimensioni, dove ogni elemento è una ennupla o tupla ordinata (ovvero, una collezione o un elenco ordinato di \\(n\\) oggetti). Una n-pla ordinata si distingue da un insieme di \\(n\\) elementi in quanto fra gli elementi di un insieme non è dato alcun ordine. Inoltre gli elementi di una ennupla possono anche essere ripetuti. Essendo la n-pla un elenco ordinato, in generale di ogni suo elemento è possibile dire se sia il primo, il secondo, il terzo, eccetera, fino all’n-esimo. Il prodotto cartesiano prende il nome da René Descartes la cui formulazione della geometria analitica ha dato origine al concetto.\n\nA &lt;- c(\"a\", \"b\", \"c\")\nS &lt;- 1:3\ncartesian_product &lt;- expand.grid(A, S)\nprint(\"Prodotto cartesiano di A e S:\")\n\n[1] \"Prodotto cartesiano di A e S:\"\n\nprint(cartesian_product)\n\n  Var1 Var2\n1    a    1\n2    b    1\n3    c    1\n4    a    2\n5    b    2\n6    c    2\n7    a    3\n8    b    3\n9    c    3\n\n\nSi definisce cardinalità (o potenza) di un insieme finito il numero degli elementi dell’insieme. Viene indicata con \\(\\vert A\\vert, \\#(A)\\) o \\(\\text{c}(A)\\).\n\nprint(\"La cardinalità dell'insieme prodotto cartesiano è:\")\n\n[1] \"La cardinalità dell'insieme prodotto cartesiano è:\"\n\nprint(nrow(cartesian_product))\n\n[1] 9\n\n\nPotenza del prodotto cartesiano\n\nA &lt;- c(\"Head\", \"Tail\")\np2 &lt;- expand.grid(A, A)\nprint(\"Il quadrato dell'insieme A è un insieme che contiene:\")\n\n[1] \"Il quadrato dell'insieme A è un insieme che contiene:\"\n\nprint(nrow(p2))\n\n[1] 4\n\nprint(p2)\n\n  Var1 Var2\n1 Head Head\n2 Tail Head\n3 Head Tail\n4 Tail Tail\n\n\n\np3 &lt;- expand.grid(A, A, A)\nprint(\"L'insieme A elevato alla terza potenza è costituito da:\")\n\n[1] \"L'insieme A elevato alla terza potenza è costituito da:\"\n\nprint(nrow(p3))\n\n[1] 8\n\nprint(p3)\n\n  Var1 Var2 Var3\n1 Head Head Head\n2 Tail Head Head\n3 Head Tail Head\n4 Tail Tail Head\n5 Head Head Tail\n6 Tail Head Tail\n7 Head Tail Tail\n8 Tail Tail Tail",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html",
    "href": "chapters/appendix/a14_combinatorics.html",
    "title": "73  Calcolo combinatorio",
    "section": "",
    "text": "73.1 Introduzione al calcolo combinatorio con R\nIl calcolo combinatorio si occupa di determinare il numero di modi in cui è possibile combinare, ordinare o disporre elementi di uno o più insiemi, seguendo regole predefinite. Molti problemi di probabilità richiedono l’applicazione di tecniche combinatorie per calcolare le probabilità di eventi complessi. In questo capitolo, esploreremo le nozioni fondamentali del calcolo combinatorio, mettendo in relazione i suoi concetti con i vari metodi di campionamento dall’urna.\nVerranno introdotti i principi fondamentali del calcolo combinatorio, come il principio del prodotto e il principio della somma, insieme al modello dell’urna, che rappresenta un approccio classico per risolvere problemi di probabilità. Saranno inoltre esaminate le nozioni di permutazioni, disposizioni e combinazioni, collegandole ai diversi tipi di campionamento.\n# Caricamento delle librerie necessarie\nsuppressPackageStartupMessages({\n  library(gtools)\nlibrary(combinat)\n})",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#introduzione-al-calcolo-combinatorio-con-r",
    "href": "chapters/appendix/a14_combinatorics.html#introduzione-al-calcolo-combinatorio-con-r",
    "title": "73  Calcolo combinatorio",
    "section": "",
    "text": "73.1.1 Principio del prodotto\nIl principio del prodotto viene applicato quando un’operazione può essere suddivisa in più fasi indipendenti. Se al passo \\(i\\) ci sono \\(n_i\\) possibilità, il numero totale di combinazioni è il prodotto di tutte le possibilità:\n\\[\nn_{\\text{tot}} = n_1 \\cdot n_2 \\cdot \\dots \\cdot n_k\n\\]\n\nEsempio 73.1 Ho a disposizione 2 paia di scarpe, 3 paia di pantaloni e 5 magliette. In quanti modi posso vestirmi?\n\nscarpe &lt;- 2\npantaloni &lt;- 3\nmagliette &lt;- 5\nmodi_totali &lt;- scarpe * pantaloni * magliette\nmodi_totali\n\n[1] 30\n\n\n\n\nEsempio 73.2 In Minnesota, le targhe automobilistiche consistono in tre lettere (da A a Z) seguite da tre numeri (da 0 a 9). Qual è la proporzione di targhe che iniziano con “GZN”?\n\nn_targhe &lt;- 26^3 * 10^3\nn_gzn &lt;- 10^3\nproporzione &lt;- n_gzn / n_targhe\nproporzione\n\n[1] 5.689577e-05\n\n\n\n\n\n\n73.1.2 Principio della somma\nIl principio della somma si applica quando un insieme può essere suddiviso in sottoinsiemi disgiunti. Il numero totale di elementi è la somma degli elementi dei sottoinsiemi.\n\nEsempio 73.3 Quanti insiemi di due palline, ciascuna estratta da urne differenti, si possono formare?\n\nAB &lt;- 5 * 6\nAC &lt;- 5 * 3\nAD &lt;- 5 * 2\nBC &lt;- 6 * 3\nBD &lt;- 6 * 2\nCD &lt;- 3 * 2\n\ntotale_insiemi &lt;- AB + AC + AD + BC + BD + CD\ntotale_insiemi\n\n[1] 91\n\n\n\n\n\n\n73.1.3 Il modello dell’urna e i metodi di campionamento\nI problemi combinatori spesso si riducono a modelli di estrazione di palline da urne, con quattro principali varianti:\n\nCon ripetizione e ordine: ogni estrazione rimette la pallina nell’urna (campionamento Bernoulliano).\nSenza ripetizione e con ordine: ogni estrazione rimuove la pallina.\nCon ripetizione e senza ordine: si considerano le combinazioni, ignorando l’ordine.\nSenza ripetizione e senza ordine: si contano le combinazioni senza rimettere la pallina.\n\n\nEsempio 73.4 Campionamenti possibili da un’urna con elementi {a, b, c}.\n\nurna &lt;- c(\"a\", \"b\", \"c\")\n\nCon ripetizione e ordine:\n\ncampionamento1 &lt;- expand.grid(urna, urna)\nprint(campionamento1)\n\n  Var1 Var2\n1    a    a\n2    b    a\n3    c    a\n4    a    b\n5    b    b\n6    c    b\n7    a    c\n8    b    c\n9    c    c\n\n\nSenza ripetizione e con ordine:\n\ncampionamento2 &lt;- permutations(n = length(urna), r = 2, v = urna)\ncampionamento2\n\n     [,1] [,2]\n[1,] \"a\"  \"b\" \n[2,] \"a\"  \"c\" \n[3,] \"b\"  \"a\" \n[4,] \"b\"  \"c\" \n[5,] \"c\"  \"a\" \n[6,] \"c\"  \"b\" \n\n\nCon ripetizione e senza ordine:\n\ncampionamento3 &lt;- combinations(\n  n = length(urna), r = 2, v = urna, repeats.allowed = TRUE\n)\ncampionamento3\n\n     [,1] [,2]\n[1,] \"a\"  \"a\" \n[2,] \"a\"  \"b\" \n[3,] \"a\"  \"c\" \n[4,] \"b\"  \"b\" \n[5,] \"b\"  \"c\" \n[6,] \"c\"  \"c\" \n\n\nSenza ripetizione e senza ordine:\n\ncampionamento4 &lt;- combinations(n = length(urna), r = 2, v = urna)\ncampionamento4\n\n     [,1] [,2]\n[1,] \"a\"  \"b\" \n[2,] \"a\"  \"c\" \n[3,] \"b\"  \"c\" \n\n\n\n\n\n\n73.1.4 Permutazioni semplici\nLe permutazioni rappresentano tutte le disposizioni di \\(n\\) elementi distinti. Il loro numero è dato da:\n\\[\nP_n = n!\n\\]\n\nEsempio 73.5 Permutazioni dell’insieme \\(\\{a, b, c\\}\\).\n\nA &lt;- c(\"a\", \"b\", \"c\")\nperm &lt;- permutations(n = length(A), r = length(A), v = A)\nprint(perm)\n\n     [,1] [,2] [,3]\n[1,] \"a\"  \"b\"  \"c\" \n[2,] \"a\"  \"c\"  \"b\" \n[3,] \"b\"  \"a\"  \"c\" \n[4,] \"b\"  \"c\"  \"a\" \n[5,] \"c\"  \"a\"  \"b\" \n[6,] \"c\"  \"b\"  \"a\" \n\nnrow(perm)\n\n[1] 6\n\n\n\n\n\n\n73.1.5 Disposizioni semplici\nLe disposizioni sono sequenze ordinate di \\(k\\) elementi scelti da un insieme di \\(n\\) elementi distinti:\n\\[\nD_{n,k} = \\frac{n!}{(n-k)!}\n\\]\n\nEsempio 73.6 Disposizioni di 2 elementi da \\(\\{a, b, c\\}\\).\n\ndisp &lt;- permutations(n = 3, r = 2, v = A)\nprint(disp)\n\n     [,1] [,2]\n[1,] \"a\"  \"b\" \n[2,] \"a\"  \"c\" \n[3,] \"b\"  \"a\" \n[4,] \"b\"  \"c\" \n[5,] \"c\"  \"a\" \n[6,] \"c\"  \"b\" \n\nnrow(disp)\n\n[1] 6\n\n\n\nLe disposizioni semplici effettivamente corrispondono a un campionamento senza ripetizione e con ordine. Qui l’ordine degli elementi estratti è importante, e ogni elemento può essere estratto solo una volta.\n\n\n\n73.1.6 Combinazioni semplici\nLe combinazioni rappresentano i modi di scegliere \\(k\\) elementi da un insieme di \\(n\\) elementi senza considerare l’ordine:\n\\[\nC_{n,k} = \\binom{n}{k} = \\frac{n!}{k!(n-k)!}\n\\]\n\nEsempio 73.7 Combinazioni di 2 elementi da \\(\\{a, b, c\\}\\).\n\ncomb &lt;- combinations(n = 3, r = 2, v = A)\nprint(comb)\n\n     [,1] [,2]\n[1,] \"a\"  \"b\" \n[2,] \"a\"  \"c\" \n[3,] \"b\"  \"c\" \n\nnrow(comb)\n\n[1] 3\n\n\n\nLe combinazioni semplici corrispondono a un campionamento senza ripetizione e senza ordine. In questo caso, l’ordine degli elementi estratti non è rilevante, e ogni elemento può essere estratto solo una volta.\n\nQuesto capitolo ha illustrato i legami tra i metodi del calcolo combinatorio e le diverse modalità di campionamento, mostrando come implementare questi concetti in R per affrontare problemi pratici di probabilità e statistica.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a15_calculus.html",
    "href": "chapters/appendix/a15_calculus.html",
    "title": "74  Per liberarvi dai terrori preliminari",
    "section": "",
    "text": "74.1 Integrali\nFornisco qui la traduzione del capitolo Per liberarvi dai terrori preliminari di Calculus made easy.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a15_calculus.html#integrali",
    "href": "chapters/appendix/a15_calculus.html#integrali",
    "title": "74  Per liberarvi dai terrori preliminari",
    "section": "",
    "text": "Importante\n\n\n\nIl terrore preliminare, che impedisce a molti studenti anche solo di tentare di imparare l’analisi, può essere abolito una volta per tutte semplicemente affermando qual è il significato – in termini di buon senso – dei due simboli principali che sono usati nell’analisi matematica.\nQuesti terribili simboli sono:\n\n\\(d\\) che significa semplicemente “un po’ di”. Quindi \\(\\operatorname{d}\\!x\\) significa un po’ di \\(x\\); o \\(\\operatorname{d}\\!u\\) significa un po’ di \\(u\\). I matematici pensano che sia più educato dire “un elemento di” invece di “un po’ di”. Fai come ti pare. Ma scoprirai che questi piccoli pezzi (o elementi) possono essere considerati indefinitamente piccoli.\n\\(\\int\\) che è semplicemente una S allungata, e può essere chiamata (se volete) “la somma di”. Quindi \\(\\int \\operatorname{d}\\!x\\) significa la somma di tutti i pezzettini di \\(x\\); oppure \\(\\int \\operatorname{d}\\!t\\) significa la somma di tutti i pezzettini di \\(t\\). I matematici chiamano questo simbolo “l’integrale di”. Ora qualsiasi sciocco può vedere che se \\(x\\) è considerato come composto da tanti piccoli pezzetti, ognuno dei quali è chiamato \\(\\operatorname{d}\\!x\\), se li sommi tutti insieme ottieni la somma di tutti i \\(\\operatorname{d}\\!x\\), (che è la stessa cosa dell’insieme di \\(x\\)). La parola “integrale” significa semplicemente “il tutto”. Se pensi alla durata di un’ora, puoi (se vuoi) pensarla come suddivisa in 3600 piccoli pezzetti chiamati secondi. L’insieme dei 3600 pezzetti sommati fa un’ora. Quando vedrete un’espressione che inizia con questo simbolo terrificante, d’ora in poi saprete che è stato messo lì semplicemente per darvi l’istruzione che ora dovete eseguire (se potete) l’operazione di sommare tutti i piccoli pezzetti che sono indicati dai simboli che seguono.\n\nÈ tutto.\n\n\n\n74.1.1 Verifica con Simulazioni in R\nPer calcolare e visualizzare l’integrale di una funzione di densità, possiamo utilizzare R. Per fare un esempio, consideriamo la funzione di densità gaussiana. La funzione di densità gaussiana è definita dalla seguente formula:\n\\[\nf(x; \\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{-\\frac{(x - \\mu)^2}{2 \\sigma^2}}.\n\\]\nIn R:\n\ngaussian &lt;- function(x, mu, sigma) {\n  1 / (sigma * sqrt(2 * pi)) * exp(-((x - mu)^2) / (2 * sigma^2))\n}\n\nDefiniamo i parametri e generiamo i valori per il calcolo della funzione di densità su un intervallo:\n\nmu &lt;- 0      # Media\nsigma &lt;- 1   # Deviazione standard\na &lt;- -10     # Limite inferiore\nb &lt;- 10      # Limite superiore\nn &lt;- 10000   # Numero di punti\n\nx_range &lt;- seq(a, b, length.out = n)  # Valori x\nfx &lt;- gaussian(x_range, mu, sigma)   # Ordinata della funzione\n\nVisualizziamo la funzione:\n\nlibrary(ggplot2)\nlibrary(scales)\n\nggplot(data.frame(x = x_range, fx = fx), aes(x, fx)) +\n  geom_line(color = \"blue\") +\n  labs(\n    title = \"Funzione di densità gaussiana\", \n    x = \"x\", \n    y = \"f(x)\"\n  )\n\n\n\n\n\n\n\n\nCreiamo una funzione per approssimare l’integrale sommando i prodotti \\(\\Delta x \\cdot f(x)\\):\n\nintegral_approximation &lt;- function(f, a, b, n) {\n  delta &lt;- (b - a) / n\n  sum(delta * f)\n}\n\n# Calcolo dell'integrale approssimato\napprox &lt;- integral_approximation(fx, a, b, n)\napprox\n\n[1] 0.9999\n\n\nConfrontiamo il risultato con il calcolo fornito da R:\n\nintegrate(\n  function(x) gaussian(x, mu, sigma),\n  lower = a,\n  upper = b\n)\n\n1 with absolute error &lt; 7.4e-05\n\n\nCalcoliamo l’area sotto la curva in intervalli di interesse. Ad esempio, per \\([-1.96, 1.96]\\), che corrisponde al 95% dell’area nella distribuzione normale standard:\n\na &lt;- -1.96\nb &lt;- 1.96\nx_range &lt;- seq(a, b, length.out = n)\nfx &lt;- gaussian(x_range, mu, sigma)\n\napprox &lt;- integral_approximation(fx, a, b, n)\napprox\n\n[1] 0.9499321\n\n\nConfrontiamo con il risultato fornito da integrate():\n\nintegrate(\n  function(x) gaussian(x, mu, sigma),\n  lower = a,\n  upper = b\n)\n\n0.9500042 with absolute error &lt; 1e-11\n\n\nVerifichiamo l’area sotto la curva per \\([-1, 1]\\), che rappresenta circa il 68% dell’area totale:\n\na &lt;- -1.0\nb &lt;- 1.0\nx_range &lt;- seq(a, b, length.out = n)\nfx &lt;- gaussian(x_range, mu, sigma)\n\napprox &lt;- integral_approximation(fx, a, b, n)\napprox\n\n[1] 0.6826696\n\n\nConfronto:\n\nintegrate(\n  function(x) gaussian(x, mu, sigma),\n  lower = a,\n  upper = b\n)\n\n0.6826895 with absolute error &lt; 7.6e-15\n\n\nIn sintesi, questo approccio dimostra come calcolare l’integrale di una funzione di densità in un intervallo utilizzando sia un metodo approssimativo basato sulla somma dei rettangoli sia il metodo numerico integrato. In entrambi i casi, l’obiettivo è calcolare l’area sotto la curva, che corrisponde all’integrale della funzione di densità.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a15_calculus.html#logaritmi",
    "href": "chapters/appendix/a15_calculus.html#logaritmi",
    "title": "74  Per liberarvi dai terrori preliminari",
    "section": "74.2 Logaritmi",
    "text": "74.2 Logaritmi\nAggiungo alcune nozioni di base sui logaritmi. Il logaritmo è una funzione matematica che risponde alla domanda: “quante volte devo moltiplicare un certo numero (chiamato”base”) per ottenere un altro numero?” Matematicamente, questo è espresso come:\n\\[\n\\log_b(a) = x \\iff b^x = a\n\\]\nAd esempio, \\(\\log_2(8) = 3\\) perché \\(2^3 = 8\\).\nNel contesto dei logaritmi, i valori molto piccoli (compresi tra 0 e 1) diventano più grandi (in termini assoluti) e negativi quando applichiamo una funzione logaritmica. Questo è utile per stabilizzare i calcoli, specialmente quando lavoriamo con prodotti di numeri molto piccoli che potrebbero portare a problemi di underflow.\nPer esempio:\n\n\\(\\log(1) = 0\\)\n\\(\\log(0.1) = -1\\)\n\\(\\log(0.01) = -2\\)\n\\(\\log(0.001) = -3\\)\n\nCome si può vedere, i valori assoluti dei logaritmi crescono man mano che il numero originale si avvicina a zero.\nUna delle proprietà più utili dei logaritmi è che consentono di trasformare un prodotto in una somma:\n\\[\n\\log_b(a \\times c) = \\log_b(a) + \\log_b(c)\n\\]\nQuesta proprietà è estremamente utile in calcoli complessi, come nella statistica bayesiana, dove il prodotto di molte probabilità potrebbe diventare un numero molto piccolo e causare problemi numerici.\nUn’altra proprietà utile dei logaritmi è che un rapporto tra due numeri diventa la differenza dei loro logaritmi:\n\\[\n\\log_b\\left(\\frac{a}{c}\\right) = \\log_b(a) - \\log_b(c)\n\\]\nAnche questa proprietà è molto utilizzata in matematica, specialmente in situazioni in cui è necessario normalizzare i dati.\nIn sintesi, i logaritmi sono strumenti potenti per semplificare e stabilizzare i calcoli matematici. Essi consentono di lavorare più agevolmente con numeri molto grandi o molto piccoli e di trasformare operazioni complesse come prodotti e divisioni in somme e differenze, rendendo i calcoli più gestibili e meno inclini a errori numerici.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a44_montecarlo.html",
    "href": "chapters/appendix/a44_montecarlo.html",
    "title": "75  Simulazione Monte Carlo",
    "section": "",
    "text": "75.1 Funzioni in R\nIl Metodo Monte Carlo utilizza simulazioni casuali per risolvere problemi complessi. È applicato in numerosi ambiti per calcolare stime quando non è possibile ottenere soluzioni analitiche semplici.\nPer fare un esempio semplice, stimiamo π con il Metodo Monte Carlo. Per fare questo, calcoleremo approssimativamente π simulando il rapporto tra l’area di un cerchio e quella di un quadrato circoscritto.\nDefiniamo una funzione per verificare se un punto è all’interno del cerchio e una per stimare \\(\\pi\\) e generare una figura visualizzabile nel file HTML.\n# Funzione per verificare se un punto è dentro il cerchio\nin_circle &lt;- function(x, y, r) {\n  sqrt(x^2 + y^2) &lt;= r\n}\n\n# Funzione per stimare π e creare una figura\napprox_pi &lt;- function(r, n) {\n  # Genera punti casuali\n  points &lt;- data.frame(\n    x = runif(n, 0, r),\n    y = runif(n, 0, r)\n  )\n  \n  # Determina se i punti sono dentro il cerchio\n  points &lt;- points %&gt;%\n    mutate(in_circle = in_circle(x, y, r),\n           color = ifelse(in_circle, \"inside\", \"outside\"))\n  \n  # Conta i punti dentro il cerchio\n  count &lt;- sum(points$in_circle)\n  \n  # Calcola π\n  pi_approx &lt;- 4 * count / n\n  \n  # Genera il grafico\n  ggplot(points, aes(x, y, color = color)) +\n    geom_point(size = 1, alpha = 0.5) +\n    labs(\n      title = paste(\"Monte Carlo Approximation of π ≈\", round(pi_approx, 3)),\n      subtitle = paste(count, \"points inside the circle out of\", n, \"total points\"),\n      x = \"x\",\n      y = \"y\"\n    ) +\n    coord_equal() \n}\nEseguiamo la simulazione per diverse dimensioni del campione:\n# Simulazioni con diverse quantità di punti\nr &lt;- 1\nn_points &lt;- c(50, 500, 5000)\n\n# Ciclo per calcolare π e generare i grafici\nfor (n in n_points) {\n  cat(\"Stima di π con\", n, \"punti:\\n\")\n  print(approx_pi(r, n))\n}\n#&gt; Stima di π con 50 punti:\n#&gt; Stima di π con 500 punti:\n#&gt; Stima di π con 5000 punti:",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Simulazione Monte Carlo</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a44_montecarlo.html#simulazione-di-monte-carlo-in-stan",
    "href": "chapters/appendix/a44_montecarlo.html#simulazione-di-monte-carlo-in-stan",
    "title": "75  Simulazione Monte Carlo",
    "section": "75.2 Simulazione di Monte Carlo in Stan",
    "text": "75.2 Simulazione di Monte Carlo in Stan\nSimuliamo π utilizzando Stan, un potente strumento per la modellazione probabilistica. Definiamo il modello in Stan come segue:\ngenerated quantities {\n  real x = uniform_rng(0, 1);\n  real y = uniform_rng(0, 1);\n  int inside = x^2 + y^2 &lt;= 1;\n  real pi_estimate = 4 * inside;\n}\nUtilizziamo il pacchetto cmdstanr per compilare ed eseguire il modello Stan.\n\n# Definisce il modello Stan\nstan_code &lt;- \"\ngenerated quantities {\n  real x = uniform_rng(0, 1);\n  real y = uniform_rng(0, 1);\n  int inside = x^2 + y^2 &lt;= 1;\n  real pi_estimate = 4 * inside;\n}\n\"\n\n# Scrive il modello su un file temporaneo\nwriteLines(stan_code, con = \"monte_carlo_pi.stan\")\n\n# Compila il modello\nmodel &lt;- cmdstan_model(\"monte_carlo_pi.stan\")\n\n# Esegue il campionamento\nsamples &lt;- model$sample(\n  chains = 1, \n  iter_sampling = 10000, \n  iter_warmup = 0, \n  seed = 42, \n  fixed_param = TRUE, \n  show_messages = FALSE\n)\n\n# Analisi dei risultati\npi_samples &lt;- samples$draws(variables = \"pi_estimate\", format = \"df\")\n\n# Calcolo di π stimato\npi_est &lt;- mean(pi_samples$pi_estimate)\ncat(\"Stima di π:\", round(pi_est, 3), \"\\n\")\n#&gt; Stima di π: 3.148\n\nQuesta combinazione di R e Stan dimostra l’efficacia e la flessibilità del Metodo Monte Carlo e delle sue varianti. Sia per problemi semplici come la stima di \\(\\pi\\), sia per applicazioni più complesse come l’integrazione e l’importance sampling, questi strumenti offrono soluzioni potenti e scalabili.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Simulazione Monte Carlo</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a46_stan_lang.html",
    "href": "chapters/appendix/a46_stan_lang.html",
    "title": "76  Linguaggio Stan",
    "section": "",
    "text": "76.1 Interfaccia cmdstanr\nÈ possibile accedere al linguaggio Stan tramite diverse interfacce:\nInoltre, vengono fornite interfacce di livello superiore con i pacchetti che utilizzano Stan come backend, sia in Python che in Linguaggio \\(\\mathsf{R}\\):\nNegli esempi di questa dispensa verrà utilizzata l’interfaccia cmdstanr. CmdStanR è un’interfaccia R per Stan che consente di definire, eseguire e analizzare modelli bayesiani in modo semplice ed efficace. Questa libreria integra l’interfaccia a riga di comando di CmdStan con una serie di funzioni R intuitive, che permettono di gestire modelli, dati e risultati dell’inferenza a posteriori.\nPer installare CmdStanR, è possibile seguire la guida ufficiale disponibile a questo link.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a46_stan_lang.html#codice-stan",
    "href": "chapters/appendix/a46_stan_lang.html#codice-stan",
    "title": "76  Linguaggio Stan",
    "section": "76.2 Codice Stan",
    "text": "76.2 Codice Stan\nStan consente agli utenti di definire un modello bayesiano attraverso il linguaggio Stan. Questo modello, di solito, viene salvato in un file di testo con estensione .stan.\nIl codice Stan deve poi essere compilato. Il processo di compilazione di un modello in Stan avviene in due fasi: innanzitutto, Stan traduce il modello dal formato .stan in codice C++, il quale viene successivamente compilato in codice macchina.\nDopo la compilazione del modello (ovvero, dopo che il codice macchina è stato generato), l’utente può utilizzare l’interfaccia prescelta (per esempio, CmdStan) per campionare la distribuzione definita dal modello e per eseguire altri calcoli correlati al modello stesso.\nIl codice Stan è costituito da una serie di blocchi che vengono usati per specificare un modello statistico. In ordine, questi blocchi sono:\nfunctions {\n  // ... function declarations and definitions ...\n}\ndata {\n  // ... declarations ...\n}\ntransformed data {\n   // ... declarations ... statements ...\n}\nparameters {\n   // ... declarations ...\n}\ntransformed parameters {\n   // ... declarations ... statements ...\n}\nmodel {\n   // ... declarations ... statements ...\n}\ngenerated quantities {\n   // ... declarations ... statements ...\n}\nQuesti blocchi devono sempre essere in questo ordine, ma non tutti i programmi Stan richiedono tutti i blocchi.\n\n76.2.1 Blocco data\nNel blocco data vengono specificate le variabili di input utilizzate nel modello Stan. Per ogni variabile, è necessario definire il tipo di dato, le dimensioni e, se necessario, applicare vincoli sui valori che tali variabili possono assumere.\nEsempio di blocco data:\ndata {\n  int&lt;lower=0&gt; ntrials; // Numero di prove\n  int&lt;lower=0&gt; y;       // Successi osservati\n  real&lt;lower=0&gt; alpha_prior; // Parametro alpha per il prior Beta\n  real&lt;lower=0&gt; beta_prior;  // Parametro beta per il prior Beta\n}\nStan offre diversi tipi di dati per le variabili, tra cui:\n\nint: Rappresenta numeri interi senza parte decimale. Esempio: int N = 10;.\nreal: Rappresenta numeri reali, inclusi i decimali. Esempio: real pi = 3.14159;.\nvector: Un vettore unidimensionale di numeri reali. Esempio: vector[3] y;.\nmatrix: Una matrice bidimensionale di numeri reali. Esempio: matrix[2,3] A;.\narray: Tipo generico per contenere elementi di qualsiasi tipo, incluso array di array. Esempio: array[3] int my_array;.\n\n\n76.2.1.1 Dichiarazione di dimensioni e applicazione di vincoli\nQuando si dichiara una variabile, è essenziale specificarne le dimensioni e, se appropriato, applicare vincoli sui valori che può assumere. I vincoli più comuni sono:\n\nlower: Specifica il valore minimo.\nupper: Specifica il valore massimo.\n\nEsempio di variabile reale compresa tra 0 e 1:\nreal&lt;lower=0, upper=1&gt; x;\n\n\n\n76.2.2 Tipi di Dati in Stan\n\n76.2.2.1 Interi\nLe variabili intere vengono dichiarate con la parola chiave int. Per dichiarare un intero positivo, si aggiunge un vincolo inferiore:\nint&lt;lower=1&gt; N;\n\n\n76.2.2.2 Reali\nLe variabili reali, dichiarate con real, possono essere vincolate allo stesso modo degli interi:\nreal&lt;lower=0&gt; sigma;\n\n\n76.2.2.3 Tipi di Dati Vettoriali e Matriciali\n\nVector: Rappresenta una sequenza unidimensionale di numeri reali. Esempio: vector[3] u;.\nMatrix: Una matrice bidimensionale di numeri reali. Esempio: matrix[3, 3] A;.\n\nLe variabili vettoriali e matriciali possono contenere solo valori reali, non interi, e sono trattate come strutture dati distinte dagli array.\n\n76.2.2.3.1 Vettori\nI vettori in Stan sono vettori colonna. Esempio di vettore reale di lunghezza 3:\nvector[3] u;\n\n\n76.2.2.3.2 Matrici\nLe matrici vengono dichiarate specificando il numero di righe e colonne:\nmatrix[3, 3] A;\nmatrix[M, N] B;\nLe dimensioni devono essere definite come variabili intere nel blocco dati.\n\n\n\n76.2.2.4 Array\nGli array possono contenere variabili di qualsiasi tipo (inclusi array di array). Ad esempio, un array di interi:\narray[5] int n;\nGli array multidimensionali sono array di array. Un array bidimensionale di interi si dichiara così:\narray[3, 4] int a;\n\n\n\n76.2.3 Indicizzazione e Miscelazione dei Tipi\n\nStan indicizza vettori, matrici e array a partire da 1.\nNon è possibile assegnare tra loro variabili di tipo array, vettore o matrice, anche se hanno le stesse dimensioni.\n\n\n\n76.2.4 Liste in CmdStanR\nQuando si forniscono dati a Stan tramite CmdStanR, questi devono essere organizzati in una lista R. Ogni elemento della lista corrisponde a una variabile dichiarata nel blocco data di Stan, e il valore associato rappresenta i dati forniti al modello.\nEsempio di lista:\ndata_list &lt;- list(\n  ntrials = 100,\n  y = 45,\n  alpha_prior = 2.0,\n  beta_prior = 5.0\n)\nQuesta struttura consente di mappare correttamente i dati alle variabili definite nel modello Stan.\nIn Stan, ogni variabile deve avere un tipo di dato ben definito, con la possibilità di applicare vincoli per garantire validità e coerenza. I tipi principali includono numeri interi, numeri reali, vettori, matrici e array, ciascuno progettato per supportare operazioni specifiche e migliorare l’efficienza computazionale.\n\n\n76.2.5 Blocco parameters\nI parametri da stimare sono definiti all’interno del blocco parameters.\nAd esempio, consideriamo il seguente codice, dove viene dichiarata la variabile theta per rappresentare una probabilità. Si notino i vincoli che specificano che i valori possibili per theta devono essere contenuti nell’intervallo [0, 1].\nparameters {\n  real&lt;lower=0, upper=1&gt; theta; // Parametro stimato, limitato tra 0 e 1\n}\n\n\n76.2.6 Blocco model\nLa sezione model è il cuore di un modello Stan, dove si specificano le relazioni statistiche tra i dati osservati e i parametri incogniti. In questa sezione, si definisce la verosimiglianza, ovvero la distribuzione di probabilità dei dati condizionata dai parametri, e si assegnano le distribuzioni a priori ai parametri stessi.\n\nLa verosimiglianza modella il processo generativo dei dati. Essa descrive come i dati osservati si sarebbero potuti generare a partire da specifici valori dei parametri. In Stan, la verosimiglianza viene specificata utilizzando il simbolo ~ (tilde).\nLe distribuzioni a priori riflettono le nostre conoscenze o credenze a priori sui parametri prima di osservare i dati. Esse agiscono come regolarizzatori, prevenendo sovrastima o sottostima dei parametri.\n\nAd esempio, nel codice seguente\nmodel {\n  // Modello Beta-Binomiale\n  theta ~ beta(alpha_prior, beta_prior); // Distribuzione a priori di theta\n  y ~ binomial(ntrials, theta); // Verosimiglianza binomiale\n}\n\ntheta ~ beta(alpha_prior, beta_prior);: Questa riga assegna una distribuzione a priori Beta al parametro theta, con parametri di forma alpha_prior e beta_prior.\ny ~ binomial(ntrials, theta);: Questa riga specifica che i dati osservati y seguono una distribuzione binomiale con ntrials prove e probabilità di successo theta.\n\nIn generale, possiamo leggere il simbolo ~ come “è distribuito come”. Pertanto, l’esempio sopra può essere scritto anche come:\n\\[\np(\\theta \\mid \\alpha_p, \\beta_p) = \\text{Beta}(\\alpha_p, \\beta_p)\n\\]\ne\n\\[\np(y \\mid \\theta) = \\text{Binomiale}(y \\mid n, \\theta).\n\\]\nLa notazione compatta usata da Stan facilita la definizione delle relazioni probabilistiche nel modello.\nIn assenza di specifiche, Stan assume una distribuzione non informativa, ovvero una distribuzione a priori uniforme tra meno infinito e più infinito. Per ulteriori raccomandazioni sulle scelte delle distribuzioni a priori, è possibile consultare questo link.\nIn sintesi, la sezione model definisce il modello statistico completo, combinando la nostra conoscenza a priori sui parametri (attraverso le distribuzioni a priori) con le informazioni contenute nei dati (attraverso la verosimiglianza). Stan utilizza poi tecniche di inferenza Bayesiana per stimare i valori più probabili dei parametri alla luce dei dati osservati.\n\n\n76.2.7 Blocchi opzionali\nCi sono inoltre tre blocchi opzionali:\n\nIl blocco transformed data consente il pre-processing dei dati. È possibile trasformare i parametri del modello; solitamente ciò viene fatto nel caso dei modelli più avanzati per consentire un campionamento MCMC più efficiente.\nIl blocco transformed parameters consente la manipolazione dei parametri prima del calcolo della distribuzione a posteriori.\nIl blocco generated quantities consente il post-processing riguardante qualsiasi quantità che non fa parte del modello ma può essere calcolata a partire dai parametri del modello, per ogni iterazione dell’algoritmo. Esempi includono la generazione dei campioni a posteriori e le dimensioni degli effetti.\n\n\n\n76.2.8 Sintassi\nIl codice Stan richiede i punti e virgola (;) alla fine di ogni istruzione di assegnazione. Questo accade per le dichiarazioni dei dati, per le dichiarazioni dei parametri e ovunque si acceda ad un elemento di un tipo data e lo si assegni a qualcos’altro. I punti e virgola non sono invece richiesti all’inizio di un ciclo o di un’istruzione condizionale, dove non viene assegnato nulla.\nIn Stan, qualsiasi stringa che segue il marcatore // denota un commento e viene ignorata dal programma.\nUna descrizione dettagliata della sintassi del linguaggio Stan è disponibile al seguente link.",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a50_lin_fun.html",
    "href": "chapters/appendix/a50_lin_fun.html",
    "title": "77  La funzione lineare",
    "section": "",
    "text": "La funzione lineare è definita come:\n\\[\nf(x) = a + b x,\n\\]\ndove \\(a\\) e \\(b\\) sono costanti. Il grafico di questa funzione è una retta, dove il parametro \\(b\\) rappresenta il coefficiente angolare e il parametro \\(a\\) rappresenta l’intercetta con l’asse delle \\(y\\). In altre parole, la retta interseca l’asse \\(y\\) nel punto \\((0,a)\\) se \\(b \\neq 0\\).\nPossiamo dare un’interpretazione geometrica alle costanti \\(a\\) e \\(b\\) considerando la funzione:\n\\[\ny = b x.\n\\]\nQuesta funzione rappresenta un caso speciale, la proporzionalità diretta tra \\(x\\) e \\(y\\). Nel caso generale della funzione lineare:\n\\[\ny = a + b x,\n\\]\naggiungiamo una costante \\(a\\) a ciascun valore \\(y = b x\\). Nella funzione lineare, se il coefficiente \\(b\\) è positivo, il valore di \\(y\\) aumenta al crescere di \\(x\\); se \\(b\\) è negativo, il valore di \\(y\\) diminuisce al crescere di \\(x\\); se \\(b=0\\), la retta è orizzontale e il valore di \\(y\\) non varia al variare di \\(x\\).\nConsideriamo ora il coefficiente \\(b\\) in modo più dettagliato. Prendiamo un punto \\(x_0\\) e un incremento arbitrario \\(\\varepsilon\\), come mostrato nella figura. Le differenze \\(\\Delta x = (x_0 + \\varepsilon) - x_0\\) e \\(\\Delta y = f(x_0 + \\varepsilon) - f(x_0)\\) sono chiamate “incrementi” di \\(x\\) e \\(y\\). Il coefficiente angolare \\(b\\) è definito come il rapporto\n\\[\nb = \\frac{\\Delta y}{\\Delta x} = \\frac{f(x_0 + \\varepsilon) - f(x_0)}{(x_0 + \\varepsilon) - x_0},\n\\]\nindipendentemente dalla grandezza degli incrementi \\(\\Delta x\\) e \\(\\Delta y\\). Per dare un’interpretazione geometrica al coefficiente angolare (o pendenza) della retta, possiamo semplificare assumendo \\(\\Delta x = 1\\). In questo caso, \\(b\\) è uguale a \\(\\Delta y\\).\n\n\n\n\n\n\nFigura 77.1: La funzione lineare \\(y = a + bx\\).\n\n\n\nPossiamo dunque dire che la pendenza \\(b\\) di un retta è uguale all’incremento \\(\\Delta y\\) associato ad un incremento unitario nella \\(x\\).",
    "crumbs": [
      "Appendice",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>La funzione lineare</span>"
    ]
  }
]