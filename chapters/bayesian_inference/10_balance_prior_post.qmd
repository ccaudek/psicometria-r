# L'influenza della distribuzione a priori {#sec-bayes-inference-prior}

::: callout-important
## In questo capitolo imparerai a:

- Comprendere il ruolo e l'importanza dei prior nei modelli bayesiani:  
  - *Prior non informativi*, *debolmente informativi* e *informativi*.  
- Approfondire il concetto di *prior di Jeffreys* e il loro utilizzo.  
- Analizzare come i prior si comportano in relazione ai *cambiamenti di scala* delle variabili.  
- Comprendere l'uso dei *prior coniugati* e i vantaggi associati alla loro applicazione.  
- Eseguire un'*analisi di sensibilità* per valutare l'impatto delle scelte sui prior nei risultati finali.  
:::

::: callout-tip
## Prerequisiti

- Leggere il capitolo *Balance and Sequentiality in Bayesian Analyses* di *Bayes rules!*  [@Johnson2022bayesrules].
:::

::: callout-caution
## Preparazione del Notebook

```{r}
here::here("code", "_common.R") |> 
  source()

# Load packages
if (!requireNamespace("pacman")) install.packages("pacman")
pacman::p_load(mice)
```
:::


## Introduzione {.unnumbered .unlisted}

::: {.lead}
Consideriamo un tipico scenario di valutazione psicologica: uno psicologo clinico deve valutare la possibile presenza di sintomi depressivi in un paziente. Confrontiamo due approcci:

* *Psicologo 1*: basa la valutazione esclusivamente su un test psicometrico standardizzato; non considera altri fattori contestuali o anamnestici.
* *Psicologo 2*: integra i risultati del test con:
  - storia personale (eventi di vita recenti, stress cronico),
  - storia clinica (precedenti episodi depressivi),
  - fattori di rischio (familiarità, comorbidità).
:::

Quale approccio garantisce una valutazione più accurata?

La risposta risiede nel concetto fondamentale di *probabilità a priori* (o *prior*), che rappresenta l'insieme delle conoscenze e delle evidenze disponibili prima di raccogliere nuovi dati. Nel nostro esempio:

* la storia clinica del paziente (precedenti episodi, familiarità, fattori di rischio) costituisce un'informazione a priori essenziale,
* il test psicometrico fornisce invece i dati osservati (evidenza).

Nell'approccio bayesiano in psicologia clinica, il prior agisce come una lente di ingrandimento che:

* migliora la sensibilità diagnostica: contestualizza i punteggi dei test,
* riduce gli errori: evita interpretazioni letterali dei risultati,
* personalizza la valutazione: adatta l'interpretazione al caso specifico.

Tuttavia, è cruciale bilanciare:

* solidità del prior: deve basarsi su evidenze scientifiche e dati anamnestici accurati,
* rigidità del prior: un preconcetto troppo forte può distorcere l'interpretazione.

Questo meccanismo non riguarda solo i contesti clinici. Nella vita quotidiana ci affidiamo continuamente alle nostre conoscenze pregresse per interpretare nuove informazioni. Ad esempio, se in aula vediamo una persona con un libro di metodologia statistica aperto, siamo portati a pensare che sia uno studente di psicologia, basandoci sull’esperienza accumulata.

L’obiettivo di questo capitolo è mostrare quanto la scelta delle *priori* sia cruciale nel processo di aggiornamento bayesiano. In particolare vedremo:

* come le *priori* rappresentino le nostre ipotesi iniziali sui parametri;
* quali tipologie di *priori* possiamo utilizzare (non informative, debolmente informative, informative);
* in che modo la loro influenza cambia al variare della quantità di dati disponibili;
* perché la scala di misura dei parametri può modificare il significato della prior.


## La distribuzione a priori

La distribuzione a priori descrive ciò che sappiamo o ipotizziamo su un parametro *prima* di osservare i dati. In psicologia, questo significa poter integrare la conoscenza accumulata da studi precedenti o da esperienze cliniche nelle nostre analisi. Ad esempio, se stiamo studiando l’efficacia di un intervento di mindfulness sulla riduzione dell’ansia, potremmo già sapere da ricerche precedenti che l’effetto tipico si colloca intorno a una riduzione moderata dei sintomi. Una distribuzione a priori ben scelta ci consente di incorporare questa informazione e di rafforzare la plausibilità delle stime.


## Tipologie di distribuzioni a priori

La scelta della prior (nota come *elicitazione*) è uno dei passaggi più delicati dell’approccio bayesiano. Non va intesa come un atto puramente soggettivo: spesso può e deve basarsi su dati empirici e conoscenze consolidate.

Si distinguono tre categorie principali:

1. *Priori non informative.*
   Servono quando non abbiamo conoscenze pregresse. Assegnano la stessa credibilità a tutti i valori di un parametro.
   Esempio: se studiamo la correlazione tra due nuove variabili psicologiche mai indagate prima, potremmo iniziare assumendo che tutte le correlazioni da –1 a +1 siano ugualmente probabili.

2. *Priori debolmente informative.*
   Introducono ipotesi “di buon senso” senza imporre vincoli rigidi.
   Esempio: nella ricerca psicologica è improbabile che un trattamento aumenti l’ansia in modo enorme (ad es. di 10 deviazioni standard). Una prior debolmente informativa può limitare la stima a un intervallo plausibile (ad es. effetti compresi tra –2 e +2 deviazioni standard), escludendo valori assurdi.

3. *Priori informative.*
   Riflettono conoscenze specifiche derivanti da studi precedenti o meta-analisi.
   Esempio: se una meta-analisi mostra che gli interventi di terapia cognitivo-comportamentale riducono in media i sintomi depressivi con un effetto di circa 0.5 deviazioni standard, possiamo usare questa informazione per formulare una prior centrata intorno a 0.5.


## L’importanza della prior in base ai dati

Un principio fondamentale è che *più dati osserviamo, meno la prior influisce sulle stime*.
Se raccogliamo centinaia di osservazioni, la verosimiglianza domina l’inferenza, rendendo meno rilevante la scelta della prior. Viceversa, con pochi dati la prior può avere un peso notevole. Questo è frequente in psicologia quando lavoriamo con campioni ridotti, ad esempio con pazienti affetti da un disturbo raro. In tali casi, una prior ben scelta può rendere le stime più stabili e coerenti.


## Trasformazioni e scala dei parametri

Un punto spesso trascurato riguarda il fatto che le prior non sono “neutre” rispetto al cambiamento di scala. Ad esempio, se in uno studio sulla soddisfazione lavorativa esprimiamo un punteggio medio in una scala da 1 a 10, una prior uniforme su quella scala appare “piatta” e non informativa. Ma se trasformiamo la scala in percentuale (0–100), la stessa prior non rimane più uniforme. Questo mostra che una prior non può essere “piatta” per tutte le possibili rappresentazioni del parametro: occorre sempre riflettere su quale scala sia più significativa per il problema psicologico studiato.


## Priori coniugate e metodi moderni

Storicamente, i ricercatori preferivano usare *priori coniugate*, che semplificano i calcoli perché producono posteriori della stessa famiglia di distribuzioni. Ad esempio, la distribuzione Beta è coniugata alla Binomiale: se osserviamo il numero di successi in un test di memoria, una prior Beta consente di calcolare facilmente la posteriori. Oggi, grazie ai metodi di campionamento (ad esempio MCMC), non è più necessario limitarsi alle priors coniugate. Possiamo scegliere priors più flessibili, anche non coniugate, che meglio riflettono le conoscenze psicologiche disponibili.


## Simulazioni

Per comprendere meglio come le distribuzioni *a priori* influenzano le nostre conclusioni, possiamo usare delle simulazioni. La formula di Bayes

$$
p(\theta \mid y) \propto p(\theta) \times p(y \mid \theta)
$$

ci dice che la distribuzione *a posteriori* nasce dalla combinazione di due elementi:

* la distribuzione *a priori*, cioè ciò che crediamo prima di osservare i dati;
* la *verosimiglianza*, cioè quanto i dati osservati sono compatibili con ciascun valore possibile del parametro $\theta$.

In pratica, se abbiamo i valori della verosimiglianza e della prior su una griglia di possibili valori di $\theta$, possiamo moltiplicarli “punto per punto” e ottenere così la distribuzione *a posteriori*.


### Un esempio psicologico: tassi di risposta corretta

Immaginiamo di voler stimare la probabilità $\theta$ che uno studente risponda correttamente a una domanda di un test di memoria. Abbiamo osservato che, su 9 domande, lo studente ha risposto correttamente a 6. Questo può essere modellato con una *verosimiglianza binomiale*. Ora ci chiediamo: *come cambiano le nostre conclusioni se assumiamo priori differenti?*


### Passo 1: definire la verosimiglianza

```{r}
# Dati osservati: 6 risposte corrette su 9
success <- 6
tosses <- 9

# Griglia di possibili valori di theta
grid_points <- 100
p_grid <- seq(0, 1, length.out = grid_points)

# Verosimiglianza binomiale
likelihood <- dbinom(success, tosses, p_grid)
```

La verosimiglianza indica quali valori di $\theta$ (probabilità di risposta corretta) sono più compatibili con i dati. In questo caso, i valori intorno a 0.67 (6/9) hanno la probabilità più alta.


### Passo 2: funzione per calcolare e visualizzare la posterior

```{r}
computePosterior <- function(likelihood, prior, p_grid) {
  # Calcolo della posteriori non normalizzata
  unstd_posterior <- likelihood * prior
  # Normalizzazione
  posterior <- unstd_posterior / sum(unstd_posterior)
  
  # Preparazione dati per il grafico
  data <- tibble(
    theta = p_grid,
    Prior = prior,
    Likelihood = likelihood,
    Posterior = posterior
  ) |> 
    pivot_longer(cols = c(Prior, Likelihood, Posterior), 
                 names_to = "distribution", 
                 values_to = "density")
  
  # Grafico
  g <- ggplot(data, aes(x = theta, y = density, color = distribution)) +
    geom_line(size = 1.2) +
    facet_wrap(~distribution, scales = "free_y", ncol = 3) +
    labs(
      title = "Distribuzioni: Prior, Likelihood, e Posterior",
      x = expression(theta),
      y = "Densità"
    ) +
    theme(plot.title = element_text(hjust = 0.5),
          legend.position = "none",
          strip.text = element_text(size = 12, face = "bold"))
  
  print(g)
  return(posterior)
}
```

La funzione non solo calcola la distribuzione *a posteriori*, ma produce anche un grafico comparativo di prior, likelihood e posterior.


### Prior uniforme

```{r fig.width=8, fig.asp=0.5, out.width="100%", echo=TRUE}
prior1 <- rep(1, grid_points)
posterior1 <- computePosterior(likelihood, prior1, p_grid)
```

**Commento**: la prior uniforme assegna uguale credibilità a tutti i valori di $\theta$.
Il risultato è che la posteriori coincide quasi con la verosimiglianza: senza conoscenze pregresse, sono i dati (6 risposte corrette su 9) a guidare completamente l’inferenza.


### Prior a gradino

```{r fig.width=8, fig.asp=0.5, out.width="100%", echo=TRUE}
prior2 <- ifelse(p_grid >= 0.5, 1, 0)
posterior2 <- computePosterior(likelihood, prior2, p_grid)
```

**Commento**: qui assumiamo che $\theta$ non possa essere inferiore a 0.5 (cioè lo studente deve rispondere almeno come “a caso”).
La posteriori esclude quindi qualsiasi valore sotto 0.5, anche se la verosimiglianza avrebbe assegnato loro un po’ di probabilità.
Questo esempio mostra come una convinzione forte possa vincolare pesantemente le conclusioni.


### Prior esponenziale centrata su 0.5

```{r fig.width=8, fig.asp=0.5, out.width="100%", echo=TRUE}
prior3 <- exp(-5 * abs(p_grid - 0.5))
posterior3 <- computePosterior(likelihood, prior3, p_grid)
```

**Commento**: questa prior esprime l’idea che lo studente abbia circa il 50% di probabilità di rispondere correttamente. La posteriori viene “attirata” verso 0.5, pur tenendo conto dei dati (6 su 9 ≈ 0.67). Il risultato finale è un compromesso: né tutto nei dati, né tutto nella prior.

Questo esercizio mostra chiaramente il *ruolo delle prior*:

* con una prior piatta prevalgono i dati,
* con una prior vincolante (gradino) le ipotesi iniziali dominano,
* con una prior moderata (esponenziale) si ottiene un compromesso.

In psicologia, dove spesso i campioni sono piccoli, la scelta della prior può cambiare molto le conclusioni: un motivo in più per rendere trasparenti e motivate le ipotesi di partenza.


## Il caso coniugato: Beta-Binomiale

Un esempio classico in cui i calcoli diventano semplici è il modello *Beta-Binomiale*. La distribuzione Beta è coniugata alla Binomiale: ciò significa che la forma della posteriori rimane una Beta.

```{r}
plot_beta_binomial <- function(alpha, beta, y, n) {
  theta <- seq(0, 1, length.out = 100)
  prior_density <- dbeta(theta, alpha, beta)
  likelihood <- dbinom(y, n, theta)
  scaled_likelihood <- likelihood / max(likelihood)
  posterior_density <- dbeta(theta, alpha + y, beta + n - y)
  
  data <- tibble(
    theta = theta,
    Prior = prior_density,
    Likelihood = scaled_likelihood,
    Posterior = posterior_density
  ) |> 
    pivot_longer(cols = c(Prior, Likelihood, Posterior), 
                 names_to = "distribution", 
                 values_to = "density")
  
  ggplot(data, aes(x = theta, y = density, color = distribution)) +
    geom_line(size = 1.2) +
    labs(title = "Modello Beta-Binomiale",
         x = expression(theta), y = "Densità") +
    theme(plot.title = element_text(hjust = 0.5))
}

# Priore uniforme
plot_beta_binomial(alpha = 1, beta = 1, y = 6, n = 9)

# Priore informativo
plot_beta_binomial(alpha = 2, beta = 2, y = 6, n = 9)

# Priore fortemente informativo
plot_beta_binomial(alpha = 2, beta = 5, y = 6, n = 9)
```

Con un priore uniforme, i dati (6 su 9) guidano quasi interamente la stima. Con un priore più informativo, la posteriori si sposta nella direzione suggerita dalle credenze pregresse.

*In sintesi,* le simulazioni mostrano due punti chiave:

1. *Il peso della prior dipende dalla quantità di dati.* Con pochi dati (come i 9 tentativi del nostro studente), la prior può influenzare molto la stima. Con tanti dati, la verosimiglianza tende a prevalere.
2. *Le scelte di prior hanno senso solo se motivate.* In psicologia, una prior può derivare da ricerche precedenti (es. meta-analisi), da conoscenze teoriche (es. aspettarci che un trattamento riduca e non aumenti i sintomi) o da ipotesi ragionevoli.

L’approccio bayesiano ci permette quindi di integrare flessibilmente dati e conoscenze pregresse, arrivando a inferenze che sono al tempo stesso empiricamente fondate e teoricamente sensate.


## Connessione tra intuizioni e teoria

L’equilibrio tra ciò che crediamo *prima* (la distribuzione a priori) e ciò che osserviamo *dopo* (i dati) non è solo una metafora utile: è una vera e propria necessità matematica. Questo diventa evidente guardando al caso della distribuzione *Beta-Binomiale*, uno dei modelli più semplici e didattici.

Il valore atteso della distribuzione a posteriori può essere riscritto in questa forma:

$$
\begin{aligned}
\mathbb{E}_{\text{post}}[\theta] &= \frac{\alpha + y}{\alpha + \beta + n} \\[6pt]
&= \underbrace{\frac{\alpha+\beta}{\alpha+\beta+n}}_{\text{peso del priore}} \cdot 
\underbrace{\frac{\alpha}{\alpha+\beta}}_{\text{media a priori}}
\;+\;
\underbrace{\frac{n}{\alpha+\beta+n}}_{\text{peso dei dati}} \cdot 
\underbrace{\frac{y}{n}}_{\text{media osservata}} .
\end{aligned}
$$

Questa equazione ci mostra che il valore atteso a posteriori è sempre una *media ponderata* di due elementi:

1. la *media a priori* ($\alpha/(\alpha+\beta)$), cioè ciò che pensavamo prima di raccogliere i dati;
2. la *proporzione osservata* ($y/n$), cioè ciò che i dati suggeriscono.

I pesi che regolano il compromesso dipendono dal rapporto tra il numero di osservazioni $n$ e la somma $\alpha+\beta$ (che misura quanto “forte” è l’informazione contenuta nella prior).

* Se $n$ è molto grande, prevalgono i dati: la posteriori riflette quasi esclusivamente le osservazioni empiriche.
* Se $n$ è piccolo, prevale la prior: la stima finale risente molto delle convinzioni iniziali.


### Un’analogia psicologica

Pensiamo a uno psicologo che vuole stimare la probabilità che uno studente ricordi correttamente un concetto dopo una lezione.

* Se ha già osservato *centinaia di risposte* di quello studente, i dati domineranno l’inferenza, e la sua idea iniziale (la prior) conterà poco.
* Se invece ha visto solo *poche risposte*, tenderà ad affidarsi molto di più alle convinzioni iniziali (per esempio, che lo studente abbia in generale una buona memoria).


### Come scegliere i parametri

* Se vogliamo esprimere *completa incertezza*, possiamo usare $\alpha = \beta = 1$, che assegna la stessa probabilità a tutti i valori possibili di $\theta$ (da 0 a 1).
* Se abbiamo *informazioni pregresse* (es. da studi precedenti o da esperienza clinica), scegliamo $\alpha/(\alpha+\beta)$ in modo che coincida con il valore atteso a priori desiderato.
* La quantità $\alpha+\beta$ regola invece “quanto ci crediamo”: più è grande, più dati serviranno per spostare la nostra convinzione iniziale.

In sintesi, questa formulazione mostra in modo chiaro che l’approccio bayesiano è una combinazione bilanciata tra teoria e dati. Il risultato non è mai solo la nostra ipotesi iniziale, né solo l’evidenza empirica, ma un’integrazione delle due. Questo rende l’inferenza bayesiana particolarmente adatta alle scienze psicologiche, dove spesso lavoriamo con campioni piccoli e dove le conoscenze accumulate in precedenza sono preziose per guidare l’interpretazione dei dati.


## Conflitto tra prior e verosimiglianza

Consideriamo un esempio discusso da McElreath, che mette in luce un punto importante: anche in situazioni semplici, la combinazione tra distribuzione a priori e verosimiglianza può produrre risultati poco intuitivi.

> Lesson: Don't trust intuition, for even simple prior+likelihood scenarios defy it. Four examples below, each producing radically different posteriors. Can you guess what each does?

Nella prima figura McElreath invita a riflettere su quattro diversi casi:

![](../../figures/mcelreath_post_1.png){width="80%"}

Nella seconda figura mostra i risultati effettivi delle combinazioni di prior e likelihood:

![](../../figures/mcelreath_post_2.png){width="80%"}

L’idea centrale è confrontare il comportamento della distribuzione normale (con code sottili) e della distribuzione di Student-t con 2 gradi di libertà (con code molto più spesse). Le code indicano quanto la distribuzione attribuisce ancora una certa plausibilità a valori estremi.

1. *In Alto a Sinistra: Prior Normale, Likelihood Normale*

   - `y ~ Normal(mu,1)`
   - `mu ~ Normal(10,1)`

   Questo è lo scenario “classico”. La posteriori si colloca a metà strada tra prior e likelihood, bilanciando le due informazioni. L’aggiornamento è regolare e prevedibile: i dati spostano la nostra convinzione iniziale, ma senza sorprese.

2. *In Alto a Destra: Prior Student, Likelihood Student (df=2)*

   - `y ~ Student(2,mu,1)`
   - `mu ~ Student(2,10,1)`

   Qui entrambe le distribuzioni hanno code spesse. Ciò significa che attribuiscono alta plausibilità anche a valori molto lontani dal centro. Il risultato è che la posteriori diventa più incerta e “larga”, con un compromesso meno definito. Non esiste un punto centrale netto, ma piuttosto una distribuzione che riflette la forte apertura a valori estremi.

3. *In Basso a Sinistra: Prior Student, Likelihood Normale*

   - `y ~ Normal(mu,1)`
   - `mu ~ Student(2,10,1)`

   In questo caso, la likelihood normale (con code sottili) è molto rigida: penalizza i valori lontani. Il prior Student-t, invece, non è sorpreso da valori estremi. Il risultato è che la posteriori viene guidata soprattutto dalla likelihood normale, con un effetto limitato del prior.

4. *In Basso a Destra: Prior Normale, Likelihood Student*

   - `y ~ Student(2,mu,1)`
   - `mu ~ Normal(10,1)`
   
   Qui accade l’opposto: il prior normale, con le sue code sottili, esercita un’influenza dominante. La likelihood Student-t, che accetterebbe valori estremi, viene “corretta” dal prior, che restringe la plausibilità attorno al proprio centro.

In sintesi, questo esercizio mostra come il comportamento della posteriori dipenda in modo cruciale dalla forma relativa di prior e likelihood. Con prior e likelihood gaussiane, l’aggiornamento è intuitivo. Appena introduciamo distribuzioni con code spesse (Student-t), la dinamica cambia: a volte prevale la prior, a volte la likelihood, e il risultato può essere molto diverso da quello che ci aspetteremmo a intuito.

**Morale:** nell'analisi bayesiana non basta “affidarsi al buon senso”. Quando prior e likelihood hanno forme diverse, il risultato dell’aggiornamento può essere sorprendente. Per questo è sempre necessario eseguire i calcoli, non solo ragionare intuitivamente.


## Riflessioni conclusive {.unnumbered .unlisted}

La scelta della distribuzione *a priori* è uno degli aspetti più delicati e decisivi nell’inferenza bayesiana. Con una *prior non informativa*, lasciamo che siano i dati a guidare le conclusioni; con una *prior informativa*, possiamo invece sfruttare conoscenze pregresse per affinare le stime. È utile ricordare che, quando i dati sono numerosi, la prior ha un peso minore, mentre con campioni piccoli la sua influenza diventa cruciale.

Un punto di forza dell’approccio bayesiano, come sottolinea Johnson (2022), è che il meccanismo di aggiornamento riflette il nostro modo intuitivo di ragionare: di fronte a evidenze deboli, le credenze rimangono stabili; se le evidenze sono solide, le credenze vengono aggiornate in misura significativa. In questo senso, il metodo bayesiano formalizza in modo matematico un processo cognitivo che utilizziamo tutti i giorni. Al contrario, l’approccio frequentista ignora le conoscenze pregresse, rischiando di produrre inferenze che cambiano bruscamente senza tener conto del contesto.

Gli esempi discussi da McElreath mostrano però che non sempre l’intuizione è affidabile: nei modelli non coniugati, le interazioni tra prior e likelihood possono produrre posteriori sorprendenti. Ciò ricorda quanto il contesto e la struttura del modello siano determinanti nelle analisi bayesiane.

Un ruolo particolarmente rilevante è svolto dalle *priori debolmente informative*, oggi considerate lo standard in molte applicazioni. Esse agiscono come un meccanismo di regolarizzazione: limitano l’impatto di osservazioni estreme e favoriscono inferenze più stabili, senza introdurre un pregiudizio eccessivo.

Negli ultimi anni è cresciuto l’interesse per le *priori informative*, soprattutto attraverso procedure di *elicitazione esperta*. Si tratta di un approccio rigoroso volto a trasformare le conoscenze di ricercatori o clinici in distribuzioni utilizzabili nei modelli. In psicologia, dove spesso le basi teoriche sono incerte o i dati scarsi, questo strumento può rafforzare l’affidabilità delle analisi e ridurre l’incertezza \[@o2019expert].

In definitiva, la scelta della prior non dovrebbe mai essere trattata come un dettaglio tecnico. Una prior “piatta” può sembrare neutra, ma raramente lo è. Le *priori debolmente informative* rappresentano oggi un equilibrio efficace tra prudenza e robustezza, mentre le *priori informative*, se costruite con protocolli accurati, aprono la strada a un’integrazione sistematica della conoscenza pregressa. Questo bilanciamento tra dati nuovi e informazioni già disponibili consente di costruire modelli bayesiani più solidi, capaci di riflettere in modo realistico sia l’incertezza sia la competenza accumulata nel dominio di studio.


## Esercizi {.unnumbered .unlisted}

::: {.callout-important title="Problemi" collapse="true"}
L'obiettivo di questo esercizio è comprendere come la distribuzione a priori influenzi la distribuzione a posteriori a seconda della grandezza del campione. Utilizzeremo dati raccolti della *Satisfaction With Life Scale (SWLS)*, categorizzandoli in base a una soglia e analizzando la proporzione di risposte che superano tale soglia con un approccio bayesiano.

*Fase 1: Raccolta e categorizzazione dei dati*

1. Ogni studente utilizza i valori della scala SWLS che sono stati raccolti dal suo gruppo TPV.
2. Si sceglie una *soglia* arbitraria (ad esempio, un punteggio superiore a 20 indica "elevata soddisfazione").
3. Si calcola la proporzione di persone con punteggi superiori alla soglia:

   $$
   \hat{p} = \frac{k}{n}
   $$
   
   dove $k$ è il numero di persone con SWLS sopra la soglia e $n$ è la dimensione del campione (circa 15).

*Fase 2: Inferenza Bayesiana con un Prior Mediamente Informativo*

4. Si assume una distribuzione Beta come prior per la proporzione di persone con SWLS sopra la soglia:

   $$
   p \sim \text{Beta}(a, b)
   $$
   
   dove $a = 2$ e $b = 2$, un prior mediamente informativo (distribuzione simmetrica centrata su 0.5).
   
5. Si calcola la distribuzione a posteriori utilizzando la coniugazione della Beta con la distribuzione binomiale:

   $$
   p \mid D \sim \text{Beta}(a + k, b + n - k)
   $$
   
6. Si calcolano:

   - *Stima puntuale* della proporzione (valore atteso della Beta a posteriori):
   
     $$
     E[p \mid D] = \frac{a + k}{a + b + n}
     $$
     
   - *Intervallo di credibilità (CI al 95%)*, utilizzando i quantili della distribuzione Beta a posteriori.

*Fase 3: Analisi con un Campione Più Grande*

7. Si ripete lo stesso esercizio, ma immaginando che la stessa proporzione $\hat{p}$ provenga da un campione di *n = 1000*.

8. Si calcola la nuova distribuzione a posteriori:

   $$
   p \mid D \sim \text{Beta}(a + k', b + n' - k')
   $$
   con $k' = \hat{p} \times 1000$.
   
9. Si ricalcolano stima puntuale e intervallo di credibilità.

*Fase 4: Confronto e Interpretazione*

10. Si confrontano le due distribuzioni a posteriori:

    - Come cambia la varianza della distribuzione a posteriori?
    - Come cambia l'influenza del prior?
    - Qual è la differenza nella precisione della stima puntuale e dell'intervallo di credibilità?
    
11. Si discute come, all'aumentare del campione, l'influenza della distribuzione a priori diminuisce, facendo emergere il ruolo della likelihood.

*Consegna:*
caricare su Moodle il file .qmd compilato in pdf.
:::


## Informazioni sull'ambiente di sviluppo {.unnumbered .unlisted}

```{r}
sessionInfo()
```

## Bibliografia {.unnumbered .unlisted}
