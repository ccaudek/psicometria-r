# Inferenza bayesiana su una media {#sec-mcmc-one-mean}

::: callout-important
## In questo capitolo imparerai a

- fare inferenza sulla media di un campione.
:::

::: callout-tip
## Prerequisiti

- 
:::

::: .callout-caution
## Preparazione del Notebook

```{r}
here::here("code", "_common.R") |> 
  source()

# Load packages
if (!requireNamespace("pacman")) install.packages("pacman")
pacman::p_load(cmdstanr, posterior, bayestestR)
```
:::

## Introduzione 

L'obiettivo principale di questo capitolo è esaminare un contesto che abbiamo già preso in considerazione in precedenza: ci troviamo di fronte a un campione di dati misurati su una scala a intervalli o rapporti e desideriamo effettuare inferenze sulla media della popolazione da cui il campione è stato estratto. Tuttavia, anziché procedere con una derivazione analitica della distribuzione a posteriori della media della popolazione, in questo caso utilizzeremo i metodi MCMC con Stan.

## Il modello Normale

I priori coniugati Normali di una Normale non richiedono l'approssimazione numerica ottenuta mediante metodi MCMC. In questo capitolo, tuttavia, ripetiamo l'esercizio descritto nel @sec-bayesian-inference-conjugate-2 usando Stan.

### Un esempio concreto

Per applicare il modello Normale, utilizzeremo i dati del censimento parziale dell'area di Dobe dei !Kung San, raccolti attraverso interviste condotte da Nancy Howell alla fine degli anni '60. I !Kung San sono una suddivisione della popolazione San, che vive nel deserto del Kalahari, tra Namibia, Botswana e Angola, e mantengono un'economia basata su caccia e raccolta. Riprodurremo l'analisi descritta da @McElreath_rethinking, esaminando unicamente i valori dell'altezza di individui di età superiore ai 18 anni.

```{r}
df <- rio::import(here::here("data", "Howell_18.csv"))
df |> 
  head()
```

Il campione include 352 osservazioni:

```{r}
length(df$height)
```

```{r}
ggplot(df, aes(x = height)) +
  geom_histogram(binwidth = 5, color = "black", fill = "lightgray") +
  labs(title = "Istogramma di Height", x = "Altezza (cm)", y = "Frequenza")
```

La media dei valori dell'altezza nel campione è:

```{r}
mean(df$height)
```

con una deviazione standard pari a:

```{r}
sd(df$height)
```

### Modello di Base 

Impostiamo una distribuzione a priori $\mathcal{N}(181, 30)$ per il parametro $\mu$ e una distribuzione a priori $\mathcal{N}(0, 20)$ per il parametro $\sigma$. Seguendo @McElreath_rethinking, ho impostato la distribuzione a priori per $\mu$ sul valore della mia altezza, per incorporare nel modello le mie conoscenze precedenti rispetto ai valori dell'altezza.

Pertanto, il modello Normale si definisce nel modo seguente:

$$
\begin{align}
Y_i &\sim \mathcal{N}(\mu, \sigma) \notag\\
\mu &\sim \mathcal{N}(181, 30) \notag\\
\sigma &\sim \mathcal{N}(0, 20) \notag
\end{align}
$$

Con questa specifica del modello:

- La variabile casuale $Y_i$ segue una distribuzione normale con parametri $\mu$ e $\sigma$.
- Il parametro $\mu$ ha una distribuzione a priori normale con media 181 e deviazione standard 30.
- Il parametro $\sigma$ ha una distribuzione a priori normale con deviazione standard 20, troncata inferiormente a 0.

Per $\sigma$, la normale troncata con deviazione standard pari a 20 permette una grande variabilità, garantendo valori positivi per la deviazione standard della distribuzione normale di $Y_i$. I parametri $\mu$ e $\sigma$ sono sconosciuti e rappresentano l'oggetto dell'inferenza. 


```{r}
# Path to the Stan file
stan_file <- here::here("stan", "gaussian_height.stan")

# Create a CmdStanModel object
mod <- cmdstan_model(stan_file)
```

```{r}
mod$print()
```

Creaiamo un dizionario con i dati in formato appropriato per Stan:

```{r}
stan_data = list(
  N = length(df$height),
  y = df$height
)
```

Eseguiamo il campionamento:

```{r}
#| message: false
#| warning: false
#| output: false
#| 
fit <- mod$sample(
  data = stan_data,
  seed = 123,
  chains = 4,
  parallel_chains = 4,
  iter_sampling = 2000, 
  iter_warmup = 2000,
  show_messages = FALSE
)
```

Esaminiamo le distribuzioni a posteriori dei due parametri oggetto dell'inferenza insieme alle loro tracce (cioè i vettori dei campioni dei parametri $\mu$ e $\sigma$ prodotti dalla procedura di campionamento MCMC) mediante un *trace plot* .

```{r}
mcmc_trace(fit$draws(c("mu", "sigma")))
```
Gli istogrammi delle distribuzioni a posteriori si ottengono nel modo seguente:

```{r}
mcmc_hist(fit$draws(c("mu", "sigma")))
```


Una sintesi delle distribuzioni a posteriori dei parametri si ottiene nel modo seguente. 

```{r}
fit$summary(c("mu", "sigma"))
```

## Parametrizzazione Non Centrata

Nella versione precedente del modello Normale abbiamo specificato le distribuzioni a priori per i parametri oggetto dell'inferenza ($\mu$ e $\sigma$) sulla scala dei dati grezzi osservati, i quali hanno una media di 154.6 e una deviazione standard di 7.7. Sul parametro $\mu$ abbiamo imposto una distribuzione a priori normale con media 181 e deviazione standard 30, e sul parametro $\sigma$ abbiamo imposto una distribuzione a priori normale con media 0 e deviazione standard 20. Queste distribuzioni a priori sono specifiche per ciascun particolare campione che possiamo osservare. 

È possibile usare un approccio diverso, che consente di definire delle distribuzioni a priori sui parametri che sono indipendenti dal particolare campione che osserviamo. Questa procedura è chiamata "parametrizzazione non centrata" (*non-centered parametrization*). In questo modello, utilizziamo variabili latenti $\mu_{\text{raw}}$ e $\sigma_{\text{raw}}$, che seguono una distribuzione normale standard:

$$
\begin{align}
\mu_{\text{raw}} &\sim \mathcal{N}(0, 1) \notag\\
\sigma_{\text{raw}} &\sim \mathcal{N}(0, 1) \notag
\end{align}
$$

Queste variabili vengono poi trasformate per ottenere i parametri $\mu$ e $\sigma$ sulla scala originale:

$$
\begin{align}
\mu &= y_{\text{mean}} + y_{\text{sd}} \cdot \mu_{\text{raw}} \notag\\
\sigma &= y_{\text{sd}} \cdot \sigma_{\text{raw}} \notag
\end{align}
$$

dove:

- $y_{\text{mean}}$ è la media dei dati osservati $y$.
- $y_{\text{sd}}$ è la deviazione standard dei dati osservati $y$.

Di seguito è riportato il codice Stan per questo modello con la parametrizzazione non centrata:

```{r}
# Path to the Stan file
stan_file <- here::here("stan", "gaussian_ncp.stan")

# Create a CmdStanModel object
mod_ncp <- cmdstan_model(stan_file)
```

```{r}
mod_ncp$print()
```

Ecco una spiegazione dettagliata del modello Stan con parametrizzazione non centrata.

1. **Blocco Dati**:
   - `int<lower=1> N;`: Il numero totale di prove o osservazioni.
   - `vector[N] y;`: Il vettore dei punteggi osservati per ciascuna prova. Questi punteggi sono sulla loro scala originale e non standardizzati.

2. **Blocco Dati Trasformati**:
   - `real y_mean = mean(y);`: La media dei dati osservati `y`.
   - `real y_sd = sd(y);`: La deviazione standard dei dati osservati `y`.

3. **Blocco Parametri**:
   - `real mu_raw;`: Un parametro latente che segue una distribuzione normale standard.
   - `real<lower=0> sigma_raw;`: Un parametro latente che segue una distribuzione normale standard vincolata a essere positiva.

4. **Blocco Parametri Trasformati**:
   - `real mu;`: La media della distribuzione normale per `y` sulla sua scala originale.
   - `real<lower=0> sigma;`: La deviazione standard della distribuzione normale per `y` sulla sua scala originale.
   - Questi parametri trasformati sono definiti come:
     ```stan
     mu = y_mean + y_sd * mu_raw;
     sigma = y_sd * sigma_raw;
     ```

La **parametrizzazione non centrata** comporta la riparametrizzazione del modello in termini di variabili standardizzate (`mu_raw` e `sigma_raw`) e poi la loro trasformazione di nuovo sulla scala originale dei dati. Questo approccio spesso porta a una migliore efficienza di campionamento e proprietà di convergenza, specialmente nei modelli gerarchici.

1. **Parametri Latenti (`mu_raw` e `sigma_raw`)**:
   - `mu_raw ~ normal(0, 1);`: `mu_raw` è una variabile normale standardizzata.
   - `sigma_raw ~ normal(0, 1);`: `sigma_raw` è una variabile normale standardizzata vincolata a essere positiva.

2. **Trasformazione alla Scala Originale**:
   - `mu = y_mean + y_sd * mu_raw;`: Questo scala e trasla `mu_raw` alla posizione e scala dei dati osservati `y`.
   - `sigma = y_sd * sigma_raw;`: Questo scala `sigma_raw` alla scala dei dati osservati `y`.

La dichiarazione della verosimiglianza `y ~ normal(mu, sigma);` indica che i dati osservati `y` seguono una distribuzione normale con media `mu` e deviazione standard `sigma`. Ecco perché ha senso anche se `y` è sulla sua scala originale:

- **Dati Osservati sulla Scala Originale**: I dati osservati `y` sono sulla loro scala originale.
- **Parametri sulla Scala Originale**: I parametri `mu` e `sigma`, dopo la trasformazione nel blocco `transformed parameters`, sono anch'essi sulla scala originale di `y`.

Quindi, la dichiarazione `y ~ normal(mu, sigma);` specifica correttamente che i dati osservati `y` (sulla loro scala originale) sono modellati da una distribuzione normale con media `mu` e deviazione standard `sigma`, entrambe sulla scala originale di `y`.

Infine, il blocco `generated quantities` viene utilizzato per i controlli predittivi posteriori generando nuovi dati (`y_rep`) dalla distribuzione posteriore dei parametri (`mu` e `sigma`):

```
generated quantities {
    vector[N] y_rep;
    for (n in 1:N) {
        y_rep[n] = normal_rng(mu, sigma);
    }
}
```

- `y_rep`: Questo genera punti dati replicati dalla distribuzione normale con la media posteriore `mu` e la deviazione standard posteriore `sigma`. Questo ti permette di confrontare le previsioni del modello con i dati osservati per eseguire controlli predittivi posteriori.

Eseguiamo il campionamento MCMC per il modello che segue una parametrizzazione non centrata:

```{r}
#| message: false
#| warning: false
#| output: false
#| 
fit_ncp <- mod_ncp$sample(
  data = stan_data,
  seed = 123,
  chains = 4,
  parallel_chains = 4,
  iter_sampling = 2000, 
  iter_warmup = 2000,
  show_messages = FALSE
)
```

Esaminiamo la distribuzioni a posteriori e le tracce dei parametri $\mu$ e $\sigma$:

```{r}
mcmc_hist(fit_ncp$draws(c("mu", "sigma")))
```

```{r}
mcmc_trace(fit_ncp$draws(c("mu", "sigma")))
```

Otteniamo una sintesi delle distribuzioni a posteriori dei parametri:

```{r}
fit_ncp$summary(c("mu", "sigma"))
```

I risultati sono molto simili a quelli ottenuti in precedenza. 

## Posterior predictive check

Uno dei vantaggi del toolkit bayesiano è che una volta ottenuta la distribuzione a posteriori congiunta dei parametri p(θ|Y) è possibile utilizzarla per generare le previsioni p(Ỹ). Matematicamente, questo può essere fatto calcolando:

$$
p(\tilde{y} \mid y) = \int p(\tilde{y} \mid \theta) p(\theta \mid y) d\theta.
$$

Questa distribuzione è nota come distribuzione predittiva posteriore. È predittiva perché viene utilizzata per fare previsioni e posteriore perché è calcolata utilizzando la distribuzione posteriore. Quindi possiamo pensare a questa come la distribuzione dei dati futuri dati il modello e i dati osservati.

Utilizzando Stan è facile per ottenere campioni predittivi posteriori: non è necessario calcolare alcun integrale. Dobbiamo convertire l'oggetto creato dalla funzione `sample()` nel formato richesto da *{bayesplot}*. Estraiamo i dati prodotti dal modello `y_rep` e i dati osservati `y`:

```{r}
# Extract posterior predictive samples for y_rep
y_rep <- fit_ncp$draws(variables = "y_rep", format = "draws_matrix")

# Extract observed data
y_obs <- stan_data$y
```

Convertiamo `y_rep` in una matrice per compatibilità con *{bayesplot}*.

```{r}
# Convert y_rep to a matrix
y_rep_matrix <- as.matrix(y_rep)
```

Generiamo il posterior predictive chech plot:

```{r}
# Posterior predictive check plot
set.seed(123)
selected_indices <- sample(nrow(y_rep_matrix), 50)
ppc_dens_overlay(y = y_obs, yrep = y_rep_matrix[selected_indices, ])
```

Un uso comune della distribuzione predittiva posteriore è quello di eseguire controlli predittivi posteriori. Questi sono un insieme di test che possono essere utilizzati per verificare se il modello è una buona rappresentazione dei dati. Nella figura, la linea nera rappresenta una KDE (Kernel Density Estimation) dei dati, mentre le linee grigie sono KDE calcolate da ciascuno dei 50 campioni predittivi posteriori. Le linee grigie riflettono l'incertezza associata alla distribuzione dei dati previsti.

Dato che il tracciato del KDE plot è contenuto nell'insieme di profili dei KDE plot dei campioni predittivi a posteriori, si può concludere che il modello utilizzato offre una rappresentazione adeguata dei dati ed è utile per la maggior parte delle analisi. Tuttavia, è importante considerare che potrebbero esistere altri modelli in grado di adattarsi meglio all'intero dataset. Esploreremo ora come poter sviluppare un modello alternativo.

## Modello "robusto"

Non è necessario presupporre che i dati seguano una distribuzione gaussiana. Le lievi deviazioni dalla gaussianità possono essere considerate attraverso l'utilizzo della distribuzione t di Student, che è particolarmente utile quando queste deviazioni si manifestano nelle code della distribuzione, come sembra essere il caso in questa situazione. Pertanto, proponiamo di adottare un modello 'robusto', maggiormente adatto a gestire osservazioni che si discostano dalla normalità nelle code della distribuzione.

La distribuzione $t$ di Student è caratterizzata dal parametro $\nu$, noto come 'gradi di libertà'. Quando $\nu$ è pari o superiore a 30, la distribuzione t di Student diventa quasi indistinguibile da una distribuzione normale. 

```{r}
# Creare una funzione per generare dati di distribuzione t per un dato numero di gradi di libertà (nu)
generate_t_data <- function(nu, n = 1000) {
  x <- seq(-5, 5, length.out = n)
  y <- dt(x, df = nu)
  data.frame(x = x, y = y, nu = as.factor(nu))
}

# Valori di nu
nu_values <- c(1, 2, 10, Inf)  # Include infinito direttamente nella lista

# Genera i dati per ciascun nu
data_list <- lapply(nu_values, generate_t_data)
data <- do.call(rbind, data_list)

# Crea il grafico
p <- ggplot(data, aes(x = x, y = y, color = nu, group = nu)) +
  geom_line() +
  scale_color_manual(values = c("#F8766D", "#00BA38", "#619CFF", "black")) +  # Personalizza i colori
  labs(title = "Densità della Distribuzione t di Student",
       x = "x",
       y = "Densità",
       color = "Gradi di libertà ν")

# Stampa il grafico
print(p)
```

Tuttavia, le code della distribuzione t di Student risultano più pesanti rispetto a quelle della normale quando $\nu$ è basso. Pertanto, proponiamo di assegnare a $\nu$ una distribuzione a priori che concentri la maggior parte della sua massa su valori bassi, come ad esempio una distribuzione esponenziale con un parametro di rate pari a 1/30.

```{r}
# Definisci il parametro di rate per la distribuzione esponenziale
rate <- 1 / 30

# Genera campioni dalla distribuzione esponenziale
samples <- rexp(10000, rate = rate)

# Crea l'istogramma dei campioni
p <- ggplot(data.frame(Values = samples), aes(x = Values)) +
  geom_histogram(aes(y = ..density..), bins = 50, alpha = 0.75, fill = "lightgray") +
  ggtitle("Exponential Distribution (λ = 1/30)") +
  xlab("Values") +
  ylab("Density") +
  theme(legend.position = "none") + 
  geom_density(col = "black", size = 1) # Aggiunge una linea di densità per il confronto

# Visualizza il grafico
print(p)
```


```{r}
# Path to the Stan file
stan_file <- here::here("stan", "student-model.stan")

# Create a CmdStanModel object
mod_t <- cmdstan_model(stan_file)
```

```{r}
mod_t$print()
```

Eseguiamo il campionamento MCMC:

```{r}
#| message: false
#| warning: false
#| output: false
#| 
fit_t <- mod_t$sample(
  data = stan_data,
  seed = 123,
  chains = 4,
  parallel_chains = 4,
  iter_sampling = 2000, 
  iter_warmup = 2000,
  show_messages = FALSE
)
```

Esaminiamo la distribuzioni a posteriori e le tracce dei parametri $\mu$ e $\sigma$:

```{r}
mcmc_hist(fit_t$draws(c("mu", "sigma")))
```

```{r}
mcmc_trace(fit_t$draws(c("mu", "sigma")))
```

Generiamo la distribuzione predittiva a posteriori.

```{r}
# Extract posterior predictive samples for y_rep
y_rep <- fit_t$draws(variables = "y_rep", format = "draws_matrix")
# Convert y_rep to a matrix
y_rep_matrix <- as.matrix(y_rep)
# Posterior predictive check plot
selected_indices <- sample(nrow(y_rep_matrix), 50)
ppc_dens_overlay(y = y_obs, yrep = y_rep_matrix[selected_indices, ])
```

La figura illustra che la situazione è analoga a quella del caso gaussiano. Questo non è sorprendente, dato che i dati relativi all'altezza si distribuiscono in maniera gaussiana nella popolazione. Pertanto, l'impiego della distribuzione $t$ di Student o della distribuzione normale producono risultati sostanzialmente equivalenti in questo contesto. 

```{r}
fit_t$summary(c("mu", "sigma"))
```

## Riflessioni Conclusive

In questo capitolo abbiamo esplorato il metodo per calcolare l'intervallo di credibilità per la media di una variabile casuale normale utilizzando Stan. Inoltre, abbiamo illustrato come sia possibile ampliare l'inferenza sulla media utilizzando un modello robusto basato sulla distribuzione t di Student.

## Esercizi

::: {#exr-stan-normal-normal-1}

Utilizzando i dati dell'esempio sui bambini plusdotati discusso nella @sec-grid-gauss, impiegare Stan per replicare i risultati ottenuti con il metodo basato su griglia.

:::

## Informazioni sull'Ambiente di Sviluppo {.unnumbered} 

```{r}
sessionInfo()
```

## Bibliografia {.unnumbered}

