# Il modello di revisione degli obiettivi {#sec-dynamic-models-goal-updating}


Molti dei fenomeni studiati in psicologia non sono statici, ma si sviluppano e si trasformano nel tempo. L’apprendimento, l’adattamento agli errori, la regolazione degli obiettivi, l’emergere o la remissione di sintomi clinici sono tutti esempi di *processi dinamici*, in cui ciò che osserviamo in un dato momento è il risultato di una storia pregressa.

Eppure, la maggior parte degli strumenti statistici impiegati in psicologia tende a ignorare questa dimensione temporale. Confrontiamo medie, calcoliamo correlazioni o eseguiamo regressioni, spesso trattando le osservazioni come indipendenti tra loro. Questo approccio è utile per molte domande, ma inadeguato quando l’obiettivo è *comprendere l’evoluzione* di un comportamento o di uno stato psicologico.

Se vogliamo capire *come* le persone modificano i propri obiettivi, cambiano strategia, o si adattano nel tempo a esperienze positive e negative, abbiamo bisogno di un approccio che tenga conto della sequenza degli eventi. Serve un modello in grado di descrivere *le regole del cambiamento*.


## Perché abbiamo bisogno di modelli dinamici?

Un *modello dinamico* è una rappresentazione matematica che esplicita il modo in cui un sistema evolve nel tempo. La caratteristica distintiva di questi modelli è la presenza di *dipendenze temporali*: almeno una delle variabili dipende da valori passati, non solo da ciò che accade nel presente.

Questo è ciò che li differenzia dai modelli statici, dove ogni osservazione è trattata come indipendente dalle precedenti. Nei modelli dinamici, invece, esiste una *memoria* del passato, che influenza l’andamento futuro del processo.

Una classe importante di variabili in questo contesto è costituita dalle *variabili di stato* (in inglese: *state variables* o *stock variables*), che rappresentano il livello accumulato di una certa quantità nel tempo: un obiettivo personale, un livello di motivazione, una credenza, o un sintomo. Queste variabili si aggiornano a ogni passo temporale secondo una *regola di cambiamento*, definita in termini matematici.


### Come si costruisce un modello dinamico?

Formulare un modello dinamico significa tradurre in termini espliciti una teoria del cambiamento. I passaggi fondamentali sono:

1. **Identificare le variabili rilevanti**: quali sono gli elementi del sistema che vogliamo modellare?
2. **Stabilire le regole di aggiornamento**: come cambia ciascuna variabile nel tempo, in risposta a feedback o input esterni?
3. **Formalizzare il modello in equazioni**: trasformare le regole in una struttura matematica coerente.
4. **Valutare la validità del modello**: confrontare le sue previsioni con i dati osservati, usando metodi statistici appropriati.

Questo tipo di approccio è particolarmente utile in psicologia, dove spesso vogliamo spiegare *come* i comportamenti si modificano in seguito a un’esperienza, e non soltanto se due variabili sono associate.


## Un esempio concreto: il modello di revisione degli obiettivi

Per rendere più tangibile il concetto, consideriamo un caso molto studiato: la regolazione degli obiettivi in risposta al feedback.

Immaginiamo un esperimento in cui i partecipanti devono svolgere un compito ripetuto, come classificare correttamente coppie di immagini. Prima di ogni prova (trial), ciascun partecipante stabilisce un obiettivo soggettivo – ad esempio, essere più veloce o più preciso rispetto al tentativo precedente. Dopo ogni trial, riceve un feedback sulla performance ottenuta, che può portarlo a rivedere il proprio obiettivo per il tentativo successivo.

Questo processo – definizione dell’obiettivo, esecuzione, feedback, revisione dell’obiettivo – è iterativo e naturalmente dinamico. Un modello dinamico ben costruito può catturare con precisione questo ciclo di regolazione, permettendoci di stimare, ad esempio, quanto rapidamente una persona adatta le proprie aspirazioni in risposta al successo o al fallimento.

Nel resto del capitolo, vedremo come formalizzare questo tipo di processo e stimare i suoi parametri utilizzando un approccio bayesiano, con implementazione in Stan.


### Come formalizzare questo processo?

Una delle ipotesi più semplici – ma già molto utile – è che le persone modifichino i propri obiettivi in funzione della discrepanza tra ciò che hanno ottenuto (performance) e ciò che si erano prefissate (goal). Se la performance supera l’obiettivo, si tende ad alzare le aspettative; se è inferiore, si tende a ridurle.

Un modello dinamico lineare che cattura questa idea è stato proposto da @knight2023tutorial e si esprime con l’equazione:

$$
G_t = G_{t-1} + \alpha \cdot (P_{t-1} - G_{t-1}) + \beta
$$

dove:

* $G_t$ è il nuovo obiettivo fissato al trial $t$,
* $P_{t-1}$ è la performance osservata al trial precedente,
* $\alpha$ rappresenta la sensibilità alla discrepanza (quanto il goal viene aggiornato in risposta all’errore),
* $\beta$ rappresenta una spinta costante al cambiamento (es. una tendenza progressiva all’ambizione o una pressione esterna).

Questo modello è detto sample-level perché assume che tutti i partecipanti condividano gli stessi parametri $\alpha$ e $\beta$, stimati sull’intero campione.


### Illustrazione numerica del modello

Per chiarire il funzionamento del modello, consideriamo due scenari ipotetici.


#### Caso 1: Performance superiore all'obiettivo

* Obiettivo precedente: $G_{t-1} = 50$ punti.
* Performance effettiva: $P_{t-1} = 60$ punti.
* Parametri: $\alpha = 0.5$ (apprendimento moderato), $\beta = 2$ (lieve tendenza all'aumento).

Calcolo:

$$
G_t = 50 + 0.5 \cdot (60 - 50) + 2 = 50 + 5 + 2 = \mathbf{57}
$$

*Interpretazione:* il partecipante ha ottenuto più di quanto si aspettava. Di conseguenza, aumenta l’obiettivo, adattandosi alle proprie capacità.


#### Caso 2: Performance inferiore all'obiettivo

* Obiettivo precedente: $G_{t-1} = 50$ punti.
* Performance effettiva: $P_{t-1} = 40$ punti.
* Parametri invariati: $\alpha = 0.5$, $\beta = 2$.

Calcolo:

$$
G_t = 50 + 0.5 \cdot (40 - 50) + 2 = 50 - 5 + 2 = \mathbf{47}
$$

*Interpretazione:* nonostante la performance deludente, l’obiettivo non crolla del tutto. La spinta costante $\beta$ impedisce una regressione troppo marcata, riflettendo potenziali meccanismi di resilienza o auto-protezione motivazionale.


### Perché questo modello è importante?

Questo approccio modellistico è particolarmente rilevante nella ricerca psicologica, in quanto consente di tradurre processi cognitivi complessi in relazioni matematiche verificabili. La struttura dinamica proposta consente di indagare sistematicamente i meccanismi di regolazione degli obiettivi e offre diversi vantaggi sia dal punto di vista metodologico che da quello teorico.

In primo luogo, il modello consente di accertare se e in che misura gli individui modificano le proprie aspettative in risposta ai feedback ricevuti. Attraverso il parametro $\alpha$ è possibile quantificare con precisione la sensibilità individuale alle discrepanze tra le performance attese e quelle reali: valori più elevati indicano una maggiore prontezza nell'adeguare gli obiettivi.

Il parametro $\beta$ aggiunge un ulteriore livello di comprensione, rivelando eventuali tendenze sistemiche nella revisione degli obiettivi indipendenti dalla performance. Un valore costante e positivo di β potrebbe, ad esempio, riflettere una progressiva crescita dell'ambizione o l'effetto di fattori motivazionali esterni.

Oltre a descrivere il comportamento osservato, il modello si rivela prezioso anche per la sua capacità predittiva. Una volta stimati i parametri individuali, è possibile prevedere come un soggetto modificherà i propri obiettivi in risposta a specifici schemi di feedback, il che ha importanti implicazioni per la progettazione di interventi formativi o terapeutici.

Dal punto di vista teorico, consente di passare da affermazioni generiche (“le persone si adattano”) a *ipotesi formali* che possono essere confrontate con i dati.

Dal punto di vista applicativo, può essere utile in contesti educativi, clinici o lavorativi, per progettare interventi personalizzati volti a favorire un migliore adattamento agli errori o a incoraggiare una progressione realistica degli obiettivi.


## Estensioni del modello

Il modello sample-level fornisce un primo passo per descrivere il processo di aggiornamento degli obiettivi. Tuttavia, le sue assunzioni sono semplificative: tutti i partecipanti seguono *la stessa regola* con gli *stessi parametri*. In realtà, è probabile che le persone differiscano nel modo in cui regolano i propri obiettivi.

Per affrontare questa complessità, @knight2023tutorial propongono una serie di estensioni che aggiungono livelli di realismo e flessibilità.

### Modello a livello individuale

Si stima un valore distinto di \$\alpha\$ e \$\beta\$ per ogni partecipante:

* Permette di confrontare quanto i singoli siano più o meno sensibili al feedback.
* Offre una rappresentazione più fine delle differenze individuali.

### Modello gerarchico (multilevel)

I parametri individuali \$\alpha\_i\$, \$\beta\_i\$ sono modellati come estratti da una distribuzione comune (es. una normale):

* Cattura sia la variabilità individuale sia la tendenza generale del gruppo.
* Offre stime più stabili, grazie alla *condivisione d'informazione* (shrinkage).

### Modello per gruppi noti

I parametri sono stimati separatamente per gruppi sperimentali distinti (es. "approach" vs. "avoidance"):

* Permette di verificare se diverse condizioni influenzano il modo in cui gli obiettivi vengono aggiornati.

### Modello con gruppi latenti (mixture model)

Non si assumono gruppi a priori, ma il modello cerca *sottogruppi nascosti* che seguono dinamiche diverse:

* Utile per scoprire profili distinti di regolazione (es. adattatori rapidi vs. rigidi).

Queste estensioni non sono trattate nel presente capitolo, ma rappresentano evoluzioni naturali del modello base. Il lettore interessato può approfondirle nel capitoli successivi.

In sintesi: il modello sample-level è il punto di partenza. Le estensioni successive permettono di incorporare differenze individuali, confronti tra gruppi, e strutture latenti, mantenendo intatta la logica dinamica di base: *gli obiettivi cambiano nel tempo in risposta all’esperienza*.


## Stima dei parametri con Stan

Abbiamo visto che il modello dinamico proposto descrive come le persone aggiornano i propri obiettivi in funzione delle performance precedenti. Ma per trasformare questa idea in uno strumento utile per la ricerca empirica, dobbiamo *stimare* i parametri del modello – in particolare:

* $\alpha$: sensibilità alla discrepanza,
* $\beta$: tendenza sistematica al cambiamento,
* $\sigma$: variabilità residua non spiegata.

Per farlo, traduciamo l’equazione teorica in un *modello statistico* e utilizziamo un approccio bayesiano per stimare la distribuzione a posteriori dei parametri.

### Dal modello teorico al modello statistico

Partiamo dall’equazione di aggiornamento:

$$
G_t = G_{t-1} + \alpha (P_{t-1} - G_{t-1}) + \beta
$$

Per renderla statistica, aggiungiamo un termine di errore, assumendo che l’obiettivo osservato sia *una realizzazione rumorosa* del valore previsto:

$$
\text{Goal osservato} \sim \mathcal{N}(G_t, \sigma)
$$

In altre parole, assumiamo che il goal osservato sia distribuito normalmente attorno al valore previsto, con una certa variabilità $\sigma$.


### Perché usare l’inferenza bayesiana?

Il modello è *ricorsivo*: ogni valore dipende da quello precedente. Questo rende difficile (e spesso impossibile) stimare i parametri con metodi frequentisti standard. L’approccio bayesiano, invece, consente di trattare in modo naturale le dipendenze temporali e le incertezze nei parametri.

Usiamo quindi la piattaforma Stan, che permette di:

* specificare il modello in modo esplicito,
* definire le distribuzioni a priori,
* stimare la distribuzione a posteriori dei parametri usando algoritmi MCMC (Markov Chain Monte Carlo).

### Come funziona Stan?

Il motore MCMC di Stan genera migliaia di valori plausibili per ogni parametro, tenendo conto sia dei dati osservati che delle distribuzioni a priori. Il risultato è una *distribuzione a posteriori* da cui possiamo:

* calcolare medie e intervalli credibili,
* effettuare inferenze sui parametri,
* generare nuove osservazioni (posterior predictive checks).


### Esempio: implementazione del modello in Stan

Il codice Stan presentato nel capitolo segue esattamente la struttura logica del modello teorico:

* I dati in input sono il numero dei trial, i goal osservati e le performance.
* I parametri da stimare sono $\alpha$, $\beta$ e $\sigma$.
* La regola di aggiornamento è implementata in un ciclo `for`, trial per trial.
* La distribuzione normale collega il goal previsto a quello osservato.
* Un blocco aggiuntivo (`generated quantities`) consente di generare dati simulati a partire dai parametri stimati.

L’obiettivo non è solo stimare parametri, ma verificare se il modello è capace di riprodurre i dati osservati.


### Il codice Stan

Di seguito, riportiamo il modello completo implementato in Stan. Analizzeremo poi ciascuna parte.

```stan
// MODELLO PER L'AGGIORNAMENTO DEGLI OBIETTIVI BASATO SULLA PERFORMANCE PRECEDENTE

// ---------------------------
// BLOCCO DEI DATI: COSA FORNIAMO AL MODELLO
// ---------------------------
data {
  int Ntotal;                      // Numero totale di osservazioni (es. 600 trial)
  real trial[Ntotal];              // Numero del trial (es. 1, 2, 3, ..., 600)
  real observed_goal[Ntotal];      // Obiettivo desiderato osservato in ciascun trial
  real performance[Ntotal];        // Prestazione osservata in ciascun trial
}

// ---------------------------
// PARAMETRI DEL MODELLO: COSA VOGLIAMO STIMARE
// ---------------------------
parameters {
  real alpha;                      // Quanto il partecipante adatta il proprio obiettivo (apprendimento)
  real beta;                       // Tendenza generale a incrementare l’obiettivo (motivazione costante)
  real<lower=0> sigma;             // Variazione casuale attorno al goal previsto (rumore)
}

// ---------------------------
// MODELLO: COME SI SPIEGANO I DATI
// ---------------------------
model {
  real predicted_goal;             // Variabile temporanea per salvare la previsione del goal

  // --- PRIORS: aspettative iniziali sui parametri ---
  alpha ~ normal(0, 1);            // Alpha: in media 0, con incertezza (deviazione standard = 1)
  beta ~ normal(0, 1);             // Beta: idem
  sigma ~ normal(0, 1);            // Sigma: deviazione standard del rumore (deve essere positiva)

  // --- CICLO PER OGNI TRIAL ---
  for (i in 1:Ntotal) {

    // Caso speciale: primo trial → nessuna previsione, usiamo direttamente il dato osservato
    if (trial[i] == 1) {
      predicted_goal = observed_goal[i];
    }

    // Tutti i trial successivi → aggiornamento del goal basato sulla performance precedente
    if (trial[i] > 1) {
      predicted_goal += alpha * (performance[i - 1] - predicted_goal) + beta;
      // ↑ Questa è la "regola di apprendimento":
      // - Se la performance precedente è migliore del goal → l’obiettivo aumenta
      // - Se la performance è peggiore → l’obiettivo diminuisce
      // - Quanto cambia? Dipende da alpha (quanto il partecipante si adatta)
      // - A ogni passo si aggiunge anche un piccolo incremento costante (beta)
    }

    // Likelihood: assumiamo che il goal osservato sia vicino al goal previsto, con un po’ di rumore
    observed_goal[i] ~ normal(predicted_goal, sigma);
  }
}

// ---------------------------
// BLOCCO PER GENERARE PREVISIONI (non necessario, ma utile per valutare il modello)
// ---------------------------
generated quantities {
  real predicted_goal;              // Valore previsto dal modello
  real sampled_goal[Ntotal];        // Goal "simulati", generati dal modello

  for (i in 1:Ntotal) {
    if (trial[i] == 1) {
      predicted_goal = observed_goal[i];
    }
    if (trial[i] > 1) {
      predicted_goal += alpha * (performance[i - 1] - predicted_goal) + beta;
    }

    // Simuliamo un nuovo goal come se fosse stato osservato, aggiungendo variabilità
    sampled_goal[i] = normal_rng(predicted_goal, sigma);
  }
}
```

Questo modello statistico descrive come le persone modificano i propri obiettivi in base alle prestazioni passate.


### Struttura del Codice Stan

Il modello è organizzato in blocchi logici.


#### 1. Blocco `data`: Input del Modello

```stan
data {
  int Ntotal;                      // Numero totale di trial
  real trial[Ntotal];              // Numero del trial (da 1 a 10)
  real observed_goal[Ntotal];      // Obiettivo riportato nel trial
  real performance[Ntotal];        // Prestazione osservata nel trial
}
```

Qui definiamo i dati in input:

- `Ntotal`: numero totale di osservazioni
- Array di lunghezza `Ntotal` per:
  - Numero progressivo del trial,
  - Obiettivo dichiarato,
  - Prestazione osservata.


#### 2. Blocco parameters: Parametri da Stimare

Questi sono i *parametri del modello*. Stan cercherà di stimare per ciascuno *una distribuzione a posteriori*, compatibile con i dati e con le informazioni a priori.


```stan
parameters {
  real alpha;                      // Tasso di apprendimento (0 = nessun adattamento)
  real beta;                       // Tendenza base ad aumentare l'obiettivo
  real<lower=0> sigma;             // Variabilità non spiegata (sempre positiva)
}
```

Cosa rappresentano:

- `alpha`: Quanto la persona si adatta alla prestazione passata,
  - Valore positivo: aumenta obiettivi dopo buone prestazioni,
  - Valore negativo: comportamento opposto,
- `beta`: Tendenza costante ad aumentare/diminuire gli obiettivi,
- `sigma`: Rumore nei dati non spiegato dal modello.


#### 3. Blocco model: Cuore del Modello

```stan
model {
  real predicted_goal;             // Obiettivo previsto dal modello

  // Distribuzioni a priori (conoscenza iniziale)
  alpha ~ normal(0, 1);           // Prior debolmente informativo
  beta ~ normal(0, 1);
  sigma ~ normal(0, 1);

  // Logica di aggiornamento trial-per-trial
  for (i in 1:Ntotal) {
    if (trial[i] == 1) {
      // Caso iniziale: usiamo il primo dato osservato
      predicted_goal = observed_goal[i];
    } else {
      // Regola di aggiornamento:
      predicted_goal += alpha * (performance[i-1] - predicted_goal) + beta;
    }
    
    // Verosimiglianza (come i dati si relazionano al modello)
    observed_goal[i] ~ normal(predicted_goal, sigma);
  }
}
```

Per chiarire il funzionamento del modello, esaminiamo il loop `for`. Un *loop `for`* (in italiano: "ciclo per") è un meccanismo che ripete un blocco di istruzioni più volte, una per ogni elemento di un insieme.

Nel nostro caso:

```stan
for(i in 1:Ntotal){
  // codice che si ripete per ogni trial
}
```

Questo significa: *"Ripeti il codice che segue per ogni trial, dal primo fino all’ultimo (cioè fino a `Ntotal`, che in questo dataset vale 600)."*

Vediamo riga per riga cosa succede *per ogni trial `i`* (cioè ogni riga dei dati):

Primo trial: inizializzazione.

```stan
if(trial[i]==1){
  predicted_goal = observed_goal[i];
}
```

Se è il *primo trial* della sequenza (`trial[i]==1`), allora il modello *non fa alcuna previsione*, ma prende direttamente il goal osservato. Questo serve per *iniziare il processo di previsione* dal secondo trial in poi.

Trial successivi: aggiornamento del goal.

```stan
if(trial[i]>1){
  predicted_goal += alpha*(performance[i-1] - predicted_goal) + beta;
}
```

Se siamo *oltre il primo trial*, il modello *aggiorna la previsione del goal* usando la seguente formula:

$$
\text{predicted\_goal} = \text{predicted\_goal} + \alpha \cdot (\text{performance precedente} - \text{predicted\_goal}) + \beta
$$

Qui:

* `alpha` è quanto il partecipante *adatta il proprio obiettivo* sulla base della prestazione passata.
* `beta` è un *aggiustamento costante* (es., un incremento generale dell’ambizione).
* `performance[i-1]` è la prestazione *del trial precedente*.

In parole semplici: se la prestazione precedente è stata *migliore* del goal previsto, allora il nuovo obiettivo aumenta (e viceversa). L’intensità dell’aggiustamento dipende da `alpha`.

3. Valutazione del modello: confronto con i dati osservati.**

```stan
observed_goal[i] ~ normal(predicted_goal, sigma);
```

* Qui il modello *confronta la previsione (`predicted_goal`) con il goal osservato* effettivamente in quel trial.
* Lo fa *assumendo* che il goal osservato sia distribuito in modo normale (Gaussiano) attorno al goal previsto, con una certa variabilità (`sigma`).


#### 4. Blocco `generated quantities`: Simulazioni

Questo blocco viene eseguito *dopo* che il modello ha stimato i parametri ($\alpha$, $\beta$, $\sigma$).

* Prima, il modello trova le distribuzioni a posteriori di $\alpha$, $\beta$, $\sigma$ (basate sui dati osservati).
* Poi, utilizzando valori estratti a caso dalle distribuzioni a posteriori dei parametri del modello, genera nuove osservazioni (`sampled_goal`). 

**Quali valori di $\alpha$, $\beta$, $\sigma$ vengono usati?**

Il modello ha stimato una distribuzione a posteriori per ogni parametro. Quando viene eseguito `generated quantities`, viene estratto un valore casuale da queste distribuzioni posteriori e usato per generare `sampled_goal`. Quindi, per ogni iterazione del ciclo `for`, si usa un diverso set di valori ($\alpha$, $\beta$, $\sigma$).

**Come viene calcolato predicted_goal?**

Si usa la stessa logica del blocco model:

* Se `trial[i] == 1`, `predicted_goal = observed_goal[1]` (inizializzazione).
* Se `trial[i] > 1`, si aggiorna con:

  * `predicted_goal += alpha * (performance[i-1] - predicted_goal) + beta;`
  
Ma attenzione! Qui $\alpha$, $\beta$, $\sigma$ sono estratti dalla loro distribuzione a posteriori, non sono i valori "veri" (che non conosciamo).

**Come viene generato `sampled_goal[i]`?**

Una volta calcolato `predicted_goal`, si genera un nuovo dato casuale:

`sampled_goal[i] = normal_rng(predicted_goal, sigma);`

Anche in questo caso, `sigma` non è fisso ma, in ogni prova, viene estratto dalla sua distribuzione a posteriori.

**Ripetizione per molte iterazioni**

Questo processo viene ripetuto per migliaia di combinazioni di valori di $\alpha$, $\beta$, $\sigma$ estratti dalle loro distribuzioni a posteriori. Alla fine, avremo un insieme di valori  `sampled_goal` che rappresentano la variabilità delle previsioni del modello.

**A cosa serve sampled_goal?**

* *Posterior Predictive Checks:* Confrontiamo sampled_goal con i dati osservati per vedere se il modello è realistico.
* *Simulazioni future:* Possiamo usare sampled_goal per prevedere come si comporterebbe un nuovo partecipante con lo stesso meccanismo di apprendimento.


**Riassunto finale**

| **Concetto**               | **Spiegazione**                                                                 |
|----------------------------|---------------------------------------------------------------------------------|
| `alpha`, `beta`, `sigma`   | Sono estratti dalla loro distribuzione posteriore (non sono fissi).             |
| `predicted_goal`           | Calcolato con la stessa formula del modello, ma usando parametri casuali.       |
| `sampled_goal`             | Simulato da `normal_rng(predicted_goal, sigma)` (dove `sigma` è casuale).      |
| **Scopo**                  | Verificare se il modello può riprodurre dati simili a quelli osservati.         |


### Cosa otteniamo alla fine?

Dopo aver eseguito il modello in Stan, otteniamo tre risultati fondamentali:

1. **Distribuzioni posteriori dei parametri**
   Per ciascun parametro ($\alpha$, $\beta$, $\sigma$), Stan fornisce una stima della *distribuzione a posteriori*: un insieme di valori plausibili coerenti con i dati e con le assunzioni a priori.

2. **Indicatori di qualità della stima**
   Inclusi:

   * **$\hat{R}$** (R-hat): misura la convergenza tra catene MCMC; deve essere vicino a 1.
   * **$n_\text{eff}$**: numero efficace di campioni indipendenti, utile per valutare la precisione della stima.

3. **Quantità generate (simulazioni)**
   Se abbiamo incluso il blocco `generated quantities`, Stan restituisce anche *dati simulati* (es. `sampled_goal`) prodotti dal modello. Questi servono per verificare se il modello è capace di riprodurre pattern simili a quelli osservati.


## A cosa servono questi risultati?

Le distribuzioni a posteriori permettono di rispondere a domande sostantive, ad esempio:

* *Quanto si adattano i partecipanti alle performance precedenti?* → guardiamo i valori stimati di $\alpha$.
* *C’è una tendenza sistematica ad aumentare o ridurre l’ambizione?* → esaminiamo $\beta$.
* *Quanto è rumoroso il processo di aggiornamento?* → ci informa $\sigma$.

I dati simulati, invece, consentono di eseguire i cosiddetti *posterior predictive checks*: confrontiamo i dati generati dal modello con quelli osservati per valutarne la plausibilità.


## Riassunto finale

| **Elemento**           | **Significato**                                                                                                             |
| ---------------------- | --------------------------------------------------------------------------------------------------------------------------- |
| $\alpha$               | Sensibilità all’errore: quanto il partecipante modifica l’obiettivo in base alla discrepanza tra performance e aspettativa. |
| $\beta$                | Spinta costante al cambiamento: riflette una tendenza sistematica (es. ambizione crescente).                                |
| $\sigma$               | Rumore residuo: variabilità non spiegata dal modello.                                                                       |
| `sampled_goal`         | Goal simulati dal modello, usati per verificare la bontà delle previsioni.                                                  |
| `generated quantities` | Blocchi che permettono di generare dati sintetici secondo le regole del modello.                                            |


## Riflessioni Conclusive

Questo esempio mostra come una teoria psicologica – in questo caso, la regolazione degli obiettivi – possa essere:

* *formalizzata dinamicamente*, tramite equazioni che descrivono un processo nel tempo;
* *tradotta in un modello statistico*, usando l’inferenza bayesiana;
* *stimata con Stan*, per ottenere parametri interpretabili e verificare la coerenza tra teoria e dati.

L’approccio dinamico rappresenta un’evoluzione importante rispetto ai modelli statici, perché consente di studiare *come* un comportamento cambia, *quando*, e *in risposta a cosa*.

Il modello presentato in questo capitolo – nella sua forma più semplice – rappresenta un punto di partenza concreto per avvicinarsi a una psicologia più formale e processuale.

> Non ci accontentiamo più di dire che due variabili sono correlate. Vogliamo spiegare *come* si influenzano nel tempo, e con quali regole.

Questo modo di pensare porta con sé un cambiamento metodologico profondo. In linea con @knight2023tutorial, possiamo sintetizzare i passaggi chiave di questo approccio:

1. *Costruire un modello generativo.*
   Esplicitare le ipotesi su *come* i dati vengono generati, passo dopo passo.

2. *Tradurre il modello in un codice eseguibile.*
   Implementare la teoria in un linguaggio formale che possa essere stimato sui dati (es. Stan).

3. *Valutare la bontà del modello.*
   Non solo tramite indici di fit, ma anche confrontando dati osservati e simulati, ed eventualmente confrontando modelli alternativi.

Anche un modello apparentemente semplice, come quello presentato in questo articolo, può rivelarsi utile se soddisfa tre requisiti fondamentali: (1) poggia su basi teoriche esplicite e plausibili, (2) genera previsioni empiricamente verificabili e (3) può essere esteso per indagare nuove questioni di ricerca.

Il modello sample-level rappresenta infatti un punto di partenza che può essere arricchito in diverse direzioni: introducendo parametri individuali per catturare le differenze tra i soggetti, incorporando strutture gerarchiche per conciliare i diversi livelli di analisi o implementando modelli a gruppi latenti per identificare pattern non immediatamente evidenti nei dati.

Dal punto di vista didattico, questo esempio mostra come le teorie psicologiche possano essere tradotte in equazioni formali che possono essere simulate, testate e validate empiricamente. Questo approccio trasforma le ipotesi teoriche in affermazioni quantitative verificabili, superando l'analisi delle sole associazioni per abbracciare un'analisi dei processi.

In definitiva, la costruzione di modelli dinamici rappresenta un passo avanti verso una psicologia più rigorosa, che mira a spiegare i fenomeni anziché limitarsi a descriverli, contribuendo così allo sviluppo cumulativo della disciplina. Questo paradigma incoraggia i ricercatori a pensare in termini di meccanismi e processi sottostanti, gettando le basi per una scienza psicologica più matura e predittiva.


## Bibliografia {.unnumbered}

